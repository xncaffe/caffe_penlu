I0927 19:02:45.642997  3577 caffe.cpp:218] Using GPUs 0
I0927 19:02:45.678807  3577 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0927 19:02:45.902176  3577 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha2_eta1_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0927 19:02:45.902326  3577 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 19:02:45.905972  3577 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 19:02:45.905984  3577 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0927 19:02:45.906263  3577 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0927 19:02:45.906391  3577 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0927 19:02:45.907497  3577 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
I0927 19:02:45.908262  3577 layer_factory.hpp:77] Creating layer Data1
I0927 19:02:45.908347  3577 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0927 19:02:45.908366  3577 net.cpp:84] Creating Layer Data1
I0927 19:02:45.908372  3577 net.cpp:380] Data1 -> Data1
I0927 19:02:45.908390  3577 net.cpp:380] Data1 -> Data2
I0927 19:02:45.908398  3577 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0927 19:02:45.909765  3577 data_layer.cpp:45] output data size: 100,3,28,28
I0927 19:02:45.912030  3577 net.cpp:122] Setting up Data1
I0927 19:02:45.912044  3577 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0927 19:02:45.912047  3577 net.cpp:129] Top shape: 100 (100)
I0927 19:02:45.912050  3577 net.cpp:137] Memory required for data: 941200
I0927 19:02:45.912055  3577 layer_factory.hpp:77] Creating layer Convolution1
I0927 19:02:45.912075  3577 net.cpp:84] Creating Layer Convolution1
I0927 19:02:45.912078  3577 net.cpp:406] Convolution1 <- Data1
I0927 19:02:45.912086  3577 net.cpp:380] Convolution1 -> Convolution1
I0927 19:02:46.056326  3577 net.cpp:122] Setting up Convolution1
I0927 19:02:46.056351  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.056356  3577 net.cpp:137] Memory required for data: 5958800
I0927 19:02:46.056375  3577 layer_factory.hpp:77] Creating layer BatchNorm1
I0927 19:02:46.056403  3577 net.cpp:84] Creating Layer BatchNorm1
I0927 19:02:46.056411  3577 net.cpp:406] BatchNorm1 <- Convolution1
I0927 19:02:46.056452  3577 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0927 19:02:46.056615  3577 net.cpp:122] Setting up BatchNorm1
I0927 19:02:46.056623  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.056628  3577 net.cpp:137] Memory required for data: 10976400
I0927 19:02:46.056640  3577 layer_factory.hpp:77] Creating layer Scale1
I0927 19:02:46.056674  3577 net.cpp:84] Creating Layer Scale1
I0927 19:02:46.056679  3577 net.cpp:406] Scale1 <- Convolution1
I0927 19:02:46.056696  3577 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0927 19:02:46.056761  3577 layer_factory.hpp:77] Creating layer Scale1
I0927 19:02:46.056884  3577 net.cpp:122] Setting up Scale1
I0927 19:02:46.056890  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.056895  3577 net.cpp:137] Memory required for data: 15994000
I0927 19:02:46.056902  3577 layer_factory.hpp:77] Creating layer M2PELU1
I0927 19:02:46.056924  3577 net.cpp:84] Creating Layer M2PELU1
I0927 19:02:46.056928  3577 net.cpp:406] M2PELU1 <- Convolution1
I0927 19:02:46.056944  3577 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0927 19:02:46.057541  3577 net.cpp:122] Setting up M2PELU1
I0927 19:02:46.057552  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.057556  3577 net.cpp:137] Memory required for data: 21011600
I0927 19:02:46.057567  3577 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0927 19:02:46.057587  3577 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0927 19:02:46.057601  3577 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0927 19:02:46.057621  3577 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0927 19:02:46.057637  3577 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0927 19:02:46.057687  3577 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0927 19:02:46.057703  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.057719  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.057724  3577 net.cpp:137] Memory required for data: 31046800
I0927 19:02:46.057729  3577 layer_factory.hpp:77] Creating layer Convolution2
I0927 19:02:46.057754  3577 net.cpp:84] Creating Layer Convolution2
I0927 19:02:46.057770  3577 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0927 19:02:46.057777  3577 net.cpp:380] Convolution2 -> Convolution2
I0927 19:02:46.058667  3577 net.cpp:122] Setting up Convolution2
I0927 19:02:46.058678  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.058683  3577 net.cpp:137] Memory required for data: 36064400
I0927 19:02:46.058701  3577 layer_factory.hpp:77] Creating layer BatchNorm2
I0927 19:02:46.058723  3577 net.cpp:84] Creating Layer BatchNorm2
I0927 19:02:46.058737  3577 net.cpp:406] BatchNorm2 <- Convolution2
I0927 19:02:46.058754  3577 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0927 19:02:46.058892  3577 net.cpp:122] Setting up BatchNorm2
I0927 19:02:46.058899  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.058912  3577 net.cpp:137] Memory required for data: 41082000
I0927 19:02:46.058923  3577 layer_factory.hpp:77] Creating layer Scale2
I0927 19:02:46.058930  3577 net.cpp:84] Creating Layer Scale2
I0927 19:02:46.058935  3577 net.cpp:406] Scale2 <- Convolution2
I0927 19:02:46.058941  3577 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0927 19:02:46.058971  3577 layer_factory.hpp:77] Creating layer Scale2
I0927 19:02:46.059047  3577 net.cpp:122] Setting up Scale2
I0927 19:02:46.059054  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.059058  3577 net.cpp:137] Memory required for data: 46099600
I0927 19:02:46.059067  3577 layer_factory.hpp:77] Creating layer M2PELU2
I0927 19:02:46.059075  3577 net.cpp:84] Creating Layer M2PELU2
I0927 19:02:46.059080  3577 net.cpp:406] M2PELU2 <- Convolution2
I0927 19:02:46.059087  3577 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0927 19:02:46.059167  3577 net.cpp:122] Setting up M2PELU2
I0927 19:02:46.059175  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.059187  3577 net.cpp:137] Memory required for data: 51117200
I0927 19:02:46.059200  3577 layer_factory.hpp:77] Creating layer Convolution3
I0927 19:02:46.059209  3577 net.cpp:84] Creating Layer Convolution3
I0927 19:02:46.059214  3577 net.cpp:406] Convolution3 <- Convolution2
I0927 19:02:46.059221  3577 net.cpp:380] Convolution3 -> Convolution3
I0927 19:02:46.060091  3577 net.cpp:122] Setting up Convolution3
I0927 19:02:46.060102  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.060107  3577 net.cpp:137] Memory required for data: 56134800
I0927 19:02:46.060115  3577 layer_factory.hpp:77] Creating layer BatchNorm3
I0927 19:02:46.060125  3577 net.cpp:84] Creating Layer BatchNorm3
I0927 19:02:46.060130  3577 net.cpp:406] BatchNorm3 <- Convolution3
I0927 19:02:46.060137  3577 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0927 19:02:46.060267  3577 net.cpp:122] Setting up BatchNorm3
I0927 19:02:46.060276  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.060279  3577 net.cpp:137] Memory required for data: 61152400
I0927 19:02:46.060288  3577 layer_factory.hpp:77] Creating layer Scale3
I0927 19:02:46.060294  3577 net.cpp:84] Creating Layer Scale3
I0927 19:02:46.060300  3577 net.cpp:406] Scale3 <- Convolution3
I0927 19:02:46.060307  3577 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0927 19:02:46.060338  3577 layer_factory.hpp:77] Creating layer Scale3
I0927 19:02:46.060418  3577 net.cpp:122] Setting up Scale3
I0927 19:02:46.060425  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.060431  3577 net.cpp:137] Memory required for data: 66170000
I0927 19:02:46.060437  3577 layer_factory.hpp:77] Creating layer Eltwise1
I0927 19:02:46.060446  3577 net.cpp:84] Creating Layer Eltwise1
I0927 19:02:46.060451  3577 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0927 19:02:46.060456  3577 net.cpp:406] Eltwise1 <- Convolution3
I0927 19:02:46.060462  3577 net.cpp:380] Eltwise1 -> Eltwise1
I0927 19:02:46.060485  3577 net.cpp:122] Setting up Eltwise1
I0927 19:02:46.060492  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.060497  3577 net.cpp:137] Memory required for data: 71187600
I0927 19:02:46.060500  3577 layer_factory.hpp:77] Creating layer M2PELU3
I0927 19:02:46.060509  3577 net.cpp:84] Creating Layer M2PELU3
I0927 19:02:46.060513  3577 net.cpp:406] M2PELU3 <- Eltwise1
I0927 19:02:46.060520  3577 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0927 19:02:46.060603  3577 net.cpp:122] Setting up M2PELU3
I0927 19:02:46.060611  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.060614  3577 net.cpp:137] Memory required for data: 76205200
I0927 19:02:46.060621  3577 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0927 19:02:46.060628  3577 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0927 19:02:46.060633  3577 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0927 19:02:46.060638  3577 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0927 19:02:46.060648  3577 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0927 19:02:46.060675  3577 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0927 19:02:46.060683  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.060689  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.060694  3577 net.cpp:137] Memory required for data: 86240400
I0927 19:02:46.060698  3577 layer_factory.hpp:77] Creating layer Convolution4
I0927 19:02:46.060710  3577 net.cpp:84] Creating Layer Convolution4
I0927 19:02:46.060715  3577 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0927 19:02:46.060722  3577 net.cpp:380] Convolution4 -> Convolution4
I0927 19:02:46.061591  3577 net.cpp:122] Setting up Convolution4
I0927 19:02:46.061602  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.061607  3577 net.cpp:137] Memory required for data: 91258000
I0927 19:02:46.061615  3577 layer_factory.hpp:77] Creating layer BatchNorm4
I0927 19:02:46.061625  3577 net.cpp:84] Creating Layer BatchNorm4
I0927 19:02:46.061637  3577 net.cpp:406] BatchNorm4 <- Convolution4
I0927 19:02:46.061646  3577 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0927 19:02:46.061774  3577 net.cpp:122] Setting up BatchNorm4
I0927 19:02:46.061781  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.061785  3577 net.cpp:137] Memory required for data: 96275600
I0927 19:02:46.061794  3577 layer_factory.hpp:77] Creating layer Scale4
I0927 19:02:46.061802  3577 net.cpp:84] Creating Layer Scale4
I0927 19:02:46.061807  3577 net.cpp:406] Scale4 <- Convolution4
I0927 19:02:46.061813  3577 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0927 19:02:46.061844  3577 layer_factory.hpp:77] Creating layer Scale4
I0927 19:02:46.061924  3577 net.cpp:122] Setting up Scale4
I0927 19:02:46.061931  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.061935  3577 net.cpp:137] Memory required for data: 101293200
I0927 19:02:46.061947  3577 layer_factory.hpp:77] Creating layer M2PELU4
I0927 19:02:46.061955  3577 net.cpp:84] Creating Layer M2PELU4
I0927 19:02:46.061960  3577 net.cpp:406] M2PELU4 <- Convolution4
I0927 19:02:46.061969  3577 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0927 19:02:46.062052  3577 net.cpp:122] Setting up M2PELU4
I0927 19:02:46.062059  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.062063  3577 net.cpp:137] Memory required for data: 106310800
I0927 19:02:46.062070  3577 layer_factory.hpp:77] Creating layer Convolution5
I0927 19:02:46.062081  3577 net.cpp:84] Creating Layer Convolution5
I0927 19:02:46.062086  3577 net.cpp:406] Convolution5 <- Convolution4
I0927 19:02:46.062094  3577 net.cpp:380] Convolution5 -> Convolution5
I0927 19:02:46.062968  3577 net.cpp:122] Setting up Convolution5
I0927 19:02:46.062979  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.062984  3577 net.cpp:137] Memory required for data: 111328400
I0927 19:02:46.062991  3577 layer_factory.hpp:77] Creating layer BatchNorm5
I0927 19:02:46.063001  3577 net.cpp:84] Creating Layer BatchNorm5
I0927 19:02:46.063007  3577 net.cpp:406] BatchNorm5 <- Convolution5
I0927 19:02:46.063015  3577 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0927 19:02:46.063143  3577 net.cpp:122] Setting up BatchNorm5
I0927 19:02:46.063150  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.063154  3577 net.cpp:137] Memory required for data: 116346000
I0927 19:02:46.063163  3577 layer_factory.hpp:77] Creating layer Scale5
I0927 19:02:46.063171  3577 net.cpp:84] Creating Layer Scale5
I0927 19:02:46.063176  3577 net.cpp:406] Scale5 <- Convolution5
I0927 19:02:46.063184  3577 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0927 19:02:46.063215  3577 layer_factory.hpp:77] Creating layer Scale5
I0927 19:02:46.063297  3577 net.cpp:122] Setting up Scale5
I0927 19:02:46.063304  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.063308  3577 net.cpp:137] Memory required for data: 121363600
I0927 19:02:46.063315  3577 layer_factory.hpp:77] Creating layer Eltwise2
I0927 19:02:46.063324  3577 net.cpp:84] Creating Layer Eltwise2
I0927 19:02:46.063329  3577 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0927 19:02:46.063334  3577 net.cpp:406] Eltwise2 <- Convolution5
I0927 19:02:46.063340  3577 net.cpp:380] Eltwise2 -> Eltwise2
I0927 19:02:46.063362  3577 net.cpp:122] Setting up Eltwise2
I0927 19:02:46.063369  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.063374  3577 net.cpp:137] Memory required for data: 126381200
I0927 19:02:46.063379  3577 layer_factory.hpp:77] Creating layer M2PELU5
I0927 19:02:46.063388  3577 net.cpp:84] Creating Layer M2PELU5
I0927 19:02:46.063392  3577 net.cpp:406] M2PELU5 <- Eltwise2
I0927 19:02:46.063400  3577 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0927 19:02:46.063484  3577 net.cpp:122] Setting up M2PELU5
I0927 19:02:46.063491  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.063495  3577 net.cpp:137] Memory required for data: 131398800
I0927 19:02:46.063503  3577 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0927 19:02:46.063516  3577 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0927 19:02:46.063522  3577 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0927 19:02:46.063529  3577 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0927 19:02:46.063537  3577 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0927 19:02:46.063565  3577 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0927 19:02:46.063572  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.063578  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.063583  3577 net.cpp:137] Memory required for data: 141434000
I0927 19:02:46.063587  3577 layer_factory.hpp:77] Creating layer Convolution6
I0927 19:02:46.063597  3577 net.cpp:84] Creating Layer Convolution6
I0927 19:02:46.063602  3577 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0927 19:02:46.063611  3577 net.cpp:380] Convolution6 -> Convolution6
I0927 19:02:46.064486  3577 net.cpp:122] Setting up Convolution6
I0927 19:02:46.064497  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.064502  3577 net.cpp:137] Memory required for data: 146451600
I0927 19:02:46.064510  3577 layer_factory.hpp:77] Creating layer BatchNorm6
I0927 19:02:46.064520  3577 net.cpp:84] Creating Layer BatchNorm6
I0927 19:02:46.064525  3577 net.cpp:406] BatchNorm6 <- Convolution6
I0927 19:02:46.064532  3577 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0927 19:02:46.064664  3577 net.cpp:122] Setting up BatchNorm6
I0927 19:02:46.064671  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.064676  3577 net.cpp:137] Memory required for data: 151469200
I0927 19:02:46.064684  3577 layer_factory.hpp:77] Creating layer Scale6
I0927 19:02:46.064690  3577 net.cpp:84] Creating Layer Scale6
I0927 19:02:46.064695  3577 net.cpp:406] Scale6 <- Convolution6
I0927 19:02:46.064702  3577 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0927 19:02:46.064734  3577 layer_factory.hpp:77] Creating layer Scale6
I0927 19:02:46.064816  3577 net.cpp:122] Setting up Scale6
I0927 19:02:46.064824  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.064831  3577 net.cpp:137] Memory required for data: 156486800
I0927 19:02:46.064837  3577 layer_factory.hpp:77] Creating layer M2PELU6
I0927 19:02:46.064846  3577 net.cpp:84] Creating Layer M2PELU6
I0927 19:02:46.064849  3577 net.cpp:406] M2PELU6 <- Convolution6
I0927 19:02:46.064858  3577 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0927 19:02:46.064946  3577 net.cpp:122] Setting up M2PELU6
I0927 19:02:46.064954  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.064957  3577 net.cpp:137] Memory required for data: 161504400
I0927 19:02:46.064965  3577 layer_factory.hpp:77] Creating layer Convolution7
I0927 19:02:46.064975  3577 net.cpp:84] Creating Layer Convolution7
I0927 19:02:46.064980  3577 net.cpp:406] Convolution7 <- Convolution6
I0927 19:02:46.064988  3577 net.cpp:380] Convolution7 -> Convolution7
I0927 19:02:46.065539  3577 net.cpp:122] Setting up Convolution7
I0927 19:02:46.065551  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.065556  3577 net.cpp:137] Memory required for data: 166522000
I0927 19:02:46.065564  3577 layer_factory.hpp:77] Creating layer BatchNorm7
I0927 19:02:46.065572  3577 net.cpp:84] Creating Layer BatchNorm7
I0927 19:02:46.065577  3577 net.cpp:406] BatchNorm7 <- Convolution7
I0927 19:02:46.065585  3577 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0927 19:02:46.065717  3577 net.cpp:122] Setting up BatchNorm7
I0927 19:02:46.065726  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.065729  3577 net.cpp:137] Memory required for data: 171539600
I0927 19:02:46.065737  3577 layer_factory.hpp:77] Creating layer Scale7
I0927 19:02:46.065747  3577 net.cpp:84] Creating Layer Scale7
I0927 19:02:46.065752  3577 net.cpp:406] Scale7 <- Convolution7
I0927 19:02:46.065758  3577 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0927 19:02:46.065790  3577 layer_factory.hpp:77] Creating layer Scale7
I0927 19:02:46.065879  3577 net.cpp:122] Setting up Scale7
I0927 19:02:46.065887  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.065891  3577 net.cpp:137] Memory required for data: 176557200
I0927 19:02:46.065898  3577 layer_factory.hpp:77] Creating layer Eltwise3
I0927 19:02:46.065906  3577 net.cpp:84] Creating Layer Eltwise3
I0927 19:02:46.065910  3577 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0927 19:02:46.065915  3577 net.cpp:406] Eltwise3 <- Convolution7
I0927 19:02:46.065923  3577 net.cpp:380] Eltwise3 -> Eltwise3
I0927 19:02:46.065945  3577 net.cpp:122] Setting up Eltwise3
I0927 19:02:46.065951  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.065955  3577 net.cpp:137] Memory required for data: 181574800
I0927 19:02:46.065960  3577 layer_factory.hpp:77] Creating layer M2PELU7
I0927 19:02:46.065969  3577 net.cpp:84] Creating Layer M2PELU7
I0927 19:02:46.065973  3577 net.cpp:406] M2PELU7 <- Eltwise3
I0927 19:02:46.065981  3577 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0927 19:02:46.066067  3577 net.cpp:122] Setting up M2PELU7
I0927 19:02:46.066074  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.066078  3577 net.cpp:137] Memory required for data: 186592400
I0927 19:02:46.066085  3577 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0927 19:02:46.066094  3577 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0927 19:02:46.066098  3577 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0927 19:02:46.066104  3577 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0927 19:02:46.066112  3577 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0927 19:02:46.066141  3577 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0927 19:02:46.066148  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.066154  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.066159  3577 net.cpp:137] Memory required for data: 196627600
I0927 19:02:46.066162  3577 layer_factory.hpp:77] Creating layer Convolution8
I0927 19:02:46.066171  3577 net.cpp:84] Creating Layer Convolution8
I0927 19:02:46.066176  3577 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0927 19:02:46.066184  3577 net.cpp:380] Convolution8 -> Convolution8
I0927 19:02:46.067054  3577 net.cpp:122] Setting up Convolution8
I0927 19:02:46.067065  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.067070  3577 net.cpp:137] Memory required for data: 201645200
I0927 19:02:46.067085  3577 layer_factory.hpp:77] Creating layer BatchNorm8
I0927 19:02:46.067093  3577 net.cpp:84] Creating Layer BatchNorm8
I0927 19:02:46.067100  3577 net.cpp:406] BatchNorm8 <- Convolution8
I0927 19:02:46.067106  3577 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0927 19:02:46.067240  3577 net.cpp:122] Setting up BatchNorm8
I0927 19:02:46.067248  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.067252  3577 net.cpp:137] Memory required for data: 206662800
I0927 19:02:46.067262  3577 layer_factory.hpp:77] Creating layer Scale8
I0927 19:02:46.067270  3577 net.cpp:84] Creating Layer Scale8
I0927 19:02:46.067275  3577 net.cpp:406] Scale8 <- Convolution8
I0927 19:02:46.067281  3577 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0927 19:02:46.067313  3577 layer_factory.hpp:77] Creating layer Scale8
I0927 19:02:46.067396  3577 net.cpp:122] Setting up Scale8
I0927 19:02:46.067404  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.067409  3577 net.cpp:137] Memory required for data: 211680400
I0927 19:02:46.067416  3577 layer_factory.hpp:77] Creating layer M2PELU8
I0927 19:02:46.067426  3577 net.cpp:84] Creating Layer M2PELU8
I0927 19:02:46.067430  3577 net.cpp:406] M2PELU8 <- Convolution8
I0927 19:02:46.067437  3577 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0927 19:02:46.067523  3577 net.cpp:122] Setting up M2PELU8
I0927 19:02:46.067529  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.067533  3577 net.cpp:137] Memory required for data: 216698000
I0927 19:02:46.067540  3577 layer_factory.hpp:77] Creating layer Convolution9
I0927 19:02:46.067559  3577 net.cpp:84] Creating Layer Convolution9
I0927 19:02:46.067564  3577 net.cpp:406] Convolution9 <- Convolution8
I0927 19:02:46.067574  3577 net.cpp:380] Convolution9 -> Convolution9
I0927 19:02:46.068511  3577 net.cpp:122] Setting up Convolution9
I0927 19:02:46.068523  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.068527  3577 net.cpp:137] Memory required for data: 221715600
I0927 19:02:46.068545  3577 layer_factory.hpp:77] Creating layer BatchNorm9
I0927 19:02:46.068553  3577 net.cpp:84] Creating Layer BatchNorm9
I0927 19:02:46.068559  3577 net.cpp:406] BatchNorm9 <- Convolution9
I0927 19:02:46.068568  3577 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0927 19:02:46.068717  3577 net.cpp:122] Setting up BatchNorm9
I0927 19:02:46.068725  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.068729  3577 net.cpp:137] Memory required for data: 226733200
I0927 19:02:46.068739  3577 layer_factory.hpp:77] Creating layer Scale9
I0927 19:02:46.068747  3577 net.cpp:84] Creating Layer Scale9
I0927 19:02:46.068759  3577 net.cpp:406] Scale9 <- Convolution9
I0927 19:02:46.068778  3577 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0927 19:02:46.068809  3577 layer_factory.hpp:77] Creating layer Scale9
I0927 19:02:46.068892  3577 net.cpp:122] Setting up Scale9
I0927 19:02:46.068899  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.068903  3577 net.cpp:137] Memory required for data: 231750800
I0927 19:02:46.068912  3577 layer_factory.hpp:77] Creating layer Eltwise4
I0927 19:02:46.068919  3577 net.cpp:84] Creating Layer Eltwise4
I0927 19:02:46.068925  3577 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0927 19:02:46.068930  3577 net.cpp:406] Eltwise4 <- Convolution9
I0927 19:02:46.068938  3577 net.cpp:380] Eltwise4 -> Eltwise4
I0927 19:02:46.068958  3577 net.cpp:122] Setting up Eltwise4
I0927 19:02:46.068966  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.068971  3577 net.cpp:137] Memory required for data: 236768400
I0927 19:02:46.068975  3577 layer_factory.hpp:77] Creating layer M2PELU9
I0927 19:02:46.068984  3577 net.cpp:84] Creating Layer M2PELU9
I0927 19:02:46.068989  3577 net.cpp:406] M2PELU9 <- Eltwise4
I0927 19:02:46.068995  3577 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0927 19:02:46.069084  3577 net.cpp:122] Setting up M2PELU9
I0927 19:02:46.069092  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.069095  3577 net.cpp:137] Memory required for data: 241786000
I0927 19:02:46.069103  3577 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0927 19:02:46.069109  3577 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0927 19:02:46.069114  3577 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0927 19:02:46.069123  3577 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0927 19:02:46.069130  3577 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0927 19:02:46.069160  3577 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0927 19:02:46.069166  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.069172  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.069176  3577 net.cpp:137] Memory required for data: 251821200
I0927 19:02:46.069181  3577 layer_factory.hpp:77] Creating layer Convolution10
I0927 19:02:46.069191  3577 net.cpp:84] Creating Layer Convolution10
I0927 19:02:46.069196  3577 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0927 19:02:46.069205  3577 net.cpp:380] Convolution10 -> Convolution10
I0927 19:02:46.070121  3577 net.cpp:122] Setting up Convolution10
I0927 19:02:46.070132  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.070137  3577 net.cpp:137] Memory required for data: 256838800
I0927 19:02:46.070144  3577 layer_factory.hpp:77] Creating layer BatchNorm10
I0927 19:02:46.070154  3577 net.cpp:84] Creating Layer BatchNorm10
I0927 19:02:46.070159  3577 net.cpp:406] BatchNorm10 <- Convolution10
I0927 19:02:46.070166  3577 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0927 19:02:46.070307  3577 net.cpp:122] Setting up BatchNorm10
I0927 19:02:46.070314  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.070318  3577 net.cpp:137] Memory required for data: 261856400
I0927 19:02:46.070327  3577 layer_factory.hpp:77] Creating layer Scale10
I0927 19:02:46.070333  3577 net.cpp:84] Creating Layer Scale10
I0927 19:02:46.070339  3577 net.cpp:406] Scale10 <- Convolution10
I0927 19:02:46.070346  3577 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0927 19:02:46.070381  3577 layer_factory.hpp:77] Creating layer Scale10
I0927 19:02:46.070463  3577 net.cpp:122] Setting up Scale10
I0927 19:02:46.070472  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.070475  3577 net.cpp:137] Memory required for data: 266874000
I0927 19:02:46.070482  3577 layer_factory.hpp:77] Creating layer M2PELU10
I0927 19:02:46.070492  3577 net.cpp:84] Creating Layer M2PELU10
I0927 19:02:46.070497  3577 net.cpp:406] M2PELU10 <- Convolution10
I0927 19:02:46.070502  3577 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0927 19:02:46.070610  3577 net.cpp:122] Setting up M2PELU10
I0927 19:02:46.070618  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.070622  3577 net.cpp:137] Memory required for data: 271891600
I0927 19:02:46.070628  3577 layer_factory.hpp:77] Creating layer Convolution11
I0927 19:02:46.070639  3577 net.cpp:84] Creating Layer Convolution11
I0927 19:02:46.070644  3577 net.cpp:406] Convolution11 <- Convolution10
I0927 19:02:46.070652  3577 net.cpp:380] Convolution11 -> Convolution11
I0927 19:02:46.071523  3577 net.cpp:122] Setting up Convolution11
I0927 19:02:46.071534  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.071539  3577 net.cpp:137] Memory required for data: 276909200
I0927 19:02:46.071547  3577 layer_factory.hpp:77] Creating layer BatchNorm11
I0927 19:02:46.071557  3577 net.cpp:84] Creating Layer BatchNorm11
I0927 19:02:46.071563  3577 net.cpp:406] BatchNorm11 <- Convolution11
I0927 19:02:46.071569  3577 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0927 19:02:46.071702  3577 net.cpp:122] Setting up BatchNorm11
I0927 19:02:46.071708  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.071712  3577 net.cpp:137] Memory required for data: 281926800
I0927 19:02:46.071722  3577 layer_factory.hpp:77] Creating layer Scale11
I0927 19:02:46.071727  3577 net.cpp:84] Creating Layer Scale11
I0927 19:02:46.071732  3577 net.cpp:406] Scale11 <- Convolution11
I0927 19:02:46.071740  3577 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0927 19:02:46.071772  3577 layer_factory.hpp:77] Creating layer Scale11
I0927 19:02:46.071858  3577 net.cpp:122] Setting up Scale11
I0927 19:02:46.071866  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.071869  3577 net.cpp:137] Memory required for data: 286944400
I0927 19:02:46.071877  3577 layer_factory.hpp:77] Creating layer Eltwise5
I0927 19:02:46.071883  3577 net.cpp:84] Creating Layer Eltwise5
I0927 19:02:46.071888  3577 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0927 19:02:46.071894  3577 net.cpp:406] Eltwise5 <- Convolution11
I0927 19:02:46.071902  3577 net.cpp:380] Eltwise5 -> Eltwise5
I0927 19:02:46.071923  3577 net.cpp:122] Setting up Eltwise5
I0927 19:02:46.071930  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.071933  3577 net.cpp:137] Memory required for data: 291962000
I0927 19:02:46.071938  3577 layer_factory.hpp:77] Creating layer M2PELU11
I0927 19:02:46.071946  3577 net.cpp:84] Creating Layer M2PELU11
I0927 19:02:46.071950  3577 net.cpp:406] M2PELU11 <- Eltwise5
I0927 19:02:46.071957  3577 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0927 19:02:46.072048  3577 net.cpp:122] Setting up M2PELU11
I0927 19:02:46.072054  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.072058  3577 net.cpp:137] Memory required for data: 296979600
I0927 19:02:46.072065  3577 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0927 19:02:46.072073  3577 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0927 19:02:46.072084  3577 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0927 19:02:46.072091  3577 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0927 19:02:46.072099  3577 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0927 19:02:46.072129  3577 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0927 19:02:46.072136  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.072142  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.072146  3577 net.cpp:137] Memory required for data: 307014800
I0927 19:02:46.072150  3577 layer_factory.hpp:77] Creating layer Convolution12
I0927 19:02:46.072160  3577 net.cpp:84] Creating Layer Convolution12
I0927 19:02:46.072163  3577 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0927 19:02:46.072171  3577 net.cpp:380] Convolution12 -> Convolution12
I0927 19:02:46.073035  3577 net.cpp:122] Setting up Convolution12
I0927 19:02:46.073046  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.073051  3577 net.cpp:137] Memory required for data: 312032400
I0927 19:02:46.073060  3577 layer_factory.hpp:77] Creating layer BatchNorm12
I0927 19:02:46.073068  3577 net.cpp:84] Creating Layer BatchNorm12
I0927 19:02:46.073073  3577 net.cpp:406] BatchNorm12 <- Convolution12
I0927 19:02:46.073081  3577 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0927 19:02:46.073215  3577 net.cpp:122] Setting up BatchNorm12
I0927 19:02:46.073222  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.073227  3577 net.cpp:137] Memory required for data: 317050000
I0927 19:02:46.073235  3577 layer_factory.hpp:77] Creating layer Scale12
I0927 19:02:46.073241  3577 net.cpp:84] Creating Layer Scale12
I0927 19:02:46.073246  3577 net.cpp:406] Scale12 <- Convolution12
I0927 19:02:46.073252  3577 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0927 19:02:46.073285  3577 layer_factory.hpp:77] Creating layer Scale12
I0927 19:02:46.073367  3577 net.cpp:122] Setting up Scale12
I0927 19:02:46.073375  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.073379  3577 net.cpp:137] Memory required for data: 322067600
I0927 19:02:46.073385  3577 layer_factory.hpp:77] Creating layer M2PELU12
I0927 19:02:46.073395  3577 net.cpp:84] Creating Layer M2PELU12
I0927 19:02:46.073400  3577 net.cpp:406] M2PELU12 <- Convolution12
I0927 19:02:46.073405  3577 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0927 19:02:46.073494  3577 net.cpp:122] Setting up M2PELU12
I0927 19:02:46.073501  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.073505  3577 net.cpp:137] Memory required for data: 327085200
I0927 19:02:46.073513  3577 layer_factory.hpp:77] Creating layer Convolution13
I0927 19:02:46.073523  3577 net.cpp:84] Creating Layer Convolution13
I0927 19:02:46.073527  3577 net.cpp:406] Convolution13 <- Convolution12
I0927 19:02:46.073535  3577 net.cpp:380] Convolution13 -> Convolution13
I0927 19:02:46.074404  3577 net.cpp:122] Setting up Convolution13
I0927 19:02:46.074414  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.074419  3577 net.cpp:137] Memory required for data: 332102800
I0927 19:02:46.074425  3577 layer_factory.hpp:77] Creating layer BatchNorm13
I0927 19:02:46.074436  3577 net.cpp:84] Creating Layer BatchNorm13
I0927 19:02:46.074441  3577 net.cpp:406] BatchNorm13 <- Convolution13
I0927 19:02:46.074448  3577 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0927 19:02:46.074607  3577 net.cpp:122] Setting up BatchNorm13
I0927 19:02:46.074615  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.074620  3577 net.cpp:137] Memory required for data: 337120400
I0927 19:02:46.074628  3577 layer_factory.hpp:77] Creating layer Scale13
I0927 19:02:46.074635  3577 net.cpp:84] Creating Layer Scale13
I0927 19:02:46.074640  3577 net.cpp:406] Scale13 <- Convolution13
I0927 19:02:46.074647  3577 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0927 19:02:46.074679  3577 layer_factory.hpp:77] Creating layer Scale13
I0927 19:02:46.074764  3577 net.cpp:122] Setting up Scale13
I0927 19:02:46.074777  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.074782  3577 net.cpp:137] Memory required for data: 342138000
I0927 19:02:46.074790  3577 layer_factory.hpp:77] Creating layer Eltwise6
I0927 19:02:46.074797  3577 net.cpp:84] Creating Layer Eltwise6
I0927 19:02:46.074802  3577 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0927 19:02:46.074808  3577 net.cpp:406] Eltwise6 <- Convolution13
I0927 19:02:46.074818  3577 net.cpp:380] Eltwise6 -> Eltwise6
I0927 19:02:46.074841  3577 net.cpp:122] Setting up Eltwise6
I0927 19:02:46.074848  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.074852  3577 net.cpp:137] Memory required for data: 347155600
I0927 19:02:46.074857  3577 layer_factory.hpp:77] Creating layer M2PELU13
I0927 19:02:46.074870  3577 net.cpp:84] Creating Layer M2PELU13
I0927 19:02:46.074874  3577 net.cpp:406] M2PELU13 <- Eltwise6
I0927 19:02:46.074880  3577 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0927 19:02:46.074972  3577 net.cpp:122] Setting up M2PELU13
I0927 19:02:46.074980  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.074983  3577 net.cpp:137] Memory required for data: 352173200
I0927 19:02:46.074991  3577 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0927 19:02:46.074997  3577 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0927 19:02:46.075002  3577 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0927 19:02:46.075008  3577 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0927 19:02:46.075016  3577 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0927 19:02:46.075044  3577 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0927 19:02:46.075050  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.075055  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.075059  3577 net.cpp:137] Memory required for data: 362208400
I0927 19:02:46.075062  3577 layer_factory.hpp:77] Creating layer Convolution14
I0927 19:02:46.075068  3577 net.cpp:84] Creating Layer Convolution14
I0927 19:02:46.075072  3577 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0927 19:02:46.075075  3577 net.cpp:380] Convolution14 -> Convolution14
I0927 19:02:46.075943  3577 net.cpp:122] Setting up Convolution14
I0927 19:02:46.075953  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.075954  3577 net.cpp:137] Memory required for data: 367226000
I0927 19:02:46.075958  3577 layer_factory.hpp:77] Creating layer BatchNorm14
I0927 19:02:46.075964  3577 net.cpp:84] Creating Layer BatchNorm14
I0927 19:02:46.075968  3577 net.cpp:406] BatchNorm14 <- Convolution14
I0927 19:02:46.075970  3577 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0927 19:02:46.076100  3577 net.cpp:122] Setting up BatchNorm14
I0927 19:02:46.076104  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.076107  3577 net.cpp:137] Memory required for data: 372243600
I0927 19:02:46.076112  3577 layer_factory.hpp:77] Creating layer Scale14
I0927 19:02:46.076117  3577 net.cpp:84] Creating Layer Scale14
I0927 19:02:46.076118  3577 net.cpp:406] Scale14 <- Convolution14
I0927 19:02:46.076122  3577 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0927 19:02:46.076146  3577 layer_factory.hpp:77] Creating layer Scale14
I0927 19:02:46.076223  3577 net.cpp:122] Setting up Scale14
I0927 19:02:46.076228  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.076231  3577 net.cpp:137] Memory required for data: 377261200
I0927 19:02:46.076234  3577 layer_factory.hpp:77] Creating layer M2PELU14
I0927 19:02:46.076239  3577 net.cpp:84] Creating Layer M2PELU14
I0927 19:02:46.076241  3577 net.cpp:406] M2PELU14 <- Convolution14
I0927 19:02:46.076246  3577 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0927 19:02:46.076328  3577 net.cpp:122] Setting up M2PELU14
I0927 19:02:46.076333  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.076333  3577 net.cpp:137] Memory required for data: 382278800
I0927 19:02:46.076344  3577 layer_factory.hpp:77] Creating layer Convolution15
I0927 19:02:46.076351  3577 net.cpp:84] Creating Layer Convolution15
I0927 19:02:46.076354  3577 net.cpp:406] Convolution15 <- Convolution14
I0927 19:02:46.076359  3577 net.cpp:380] Convolution15 -> Convolution15
I0927 19:02:46.077216  3577 net.cpp:122] Setting up Convolution15
I0927 19:02:46.077224  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.077227  3577 net.cpp:137] Memory required for data: 387296400
I0927 19:02:46.077231  3577 layer_factory.hpp:77] Creating layer BatchNorm15
I0927 19:02:46.077236  3577 net.cpp:84] Creating Layer BatchNorm15
I0927 19:02:46.077239  3577 net.cpp:406] BatchNorm15 <- Convolution15
I0927 19:02:46.077244  3577 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0927 19:02:46.077373  3577 net.cpp:122] Setting up BatchNorm15
I0927 19:02:46.077378  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.077379  3577 net.cpp:137] Memory required for data: 392314000
I0927 19:02:46.077394  3577 layer_factory.hpp:77] Creating layer Scale15
I0927 19:02:46.077399  3577 net.cpp:84] Creating Layer Scale15
I0927 19:02:46.077400  3577 net.cpp:406] Scale15 <- Convolution15
I0927 19:02:46.077404  3577 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0927 19:02:46.077430  3577 layer_factory.hpp:77] Creating layer Scale15
I0927 19:02:46.077508  3577 net.cpp:122] Setting up Scale15
I0927 19:02:46.077512  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.077514  3577 net.cpp:137] Memory required for data: 397331600
I0927 19:02:46.077518  3577 layer_factory.hpp:77] Creating layer Eltwise7
I0927 19:02:46.077522  3577 net.cpp:84] Creating Layer Eltwise7
I0927 19:02:46.077524  3577 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0927 19:02:46.077527  3577 net.cpp:406] Eltwise7 <- Convolution15
I0927 19:02:46.077530  3577 net.cpp:380] Eltwise7 -> Eltwise7
I0927 19:02:46.077545  3577 net.cpp:122] Setting up Eltwise7
I0927 19:02:46.077548  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.077550  3577 net.cpp:137] Memory required for data: 402349200
I0927 19:02:46.077553  3577 layer_factory.hpp:77] Creating layer M2PELU15
I0927 19:02:46.077558  3577 net.cpp:84] Creating Layer M2PELU15
I0927 19:02:46.077560  3577 net.cpp:406] M2PELU15 <- Eltwise7
I0927 19:02:46.077564  3577 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0927 19:02:46.077646  3577 net.cpp:122] Setting up M2PELU15
I0927 19:02:46.077651  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.077652  3577 net.cpp:137] Memory required for data: 407366800
I0927 19:02:46.077656  3577 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0927 19:02:46.077659  3577 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0927 19:02:46.077661  3577 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0927 19:02:46.077666  3577 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0927 19:02:46.077669  3577 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0927 19:02:46.077690  3577 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0927 19:02:46.077693  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.077697  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.077698  3577 net.cpp:137] Memory required for data: 417402000
I0927 19:02:46.077700  3577 layer_factory.hpp:77] Creating layer Convolution16
I0927 19:02:46.077706  3577 net.cpp:84] Creating Layer Convolution16
I0927 19:02:46.077708  3577 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0927 19:02:46.077713  3577 net.cpp:380] Convolution16 -> Convolution16
I0927 19:02:46.078595  3577 net.cpp:122] Setting up Convolution16
I0927 19:02:46.078604  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.078606  3577 net.cpp:137] Memory required for data: 422419600
I0927 19:02:46.078610  3577 layer_factory.hpp:77] Creating layer BatchNorm16
I0927 19:02:46.078615  3577 net.cpp:84] Creating Layer BatchNorm16
I0927 19:02:46.078619  3577 net.cpp:406] BatchNorm16 <- Convolution16
I0927 19:02:46.078629  3577 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0927 19:02:46.078760  3577 net.cpp:122] Setting up BatchNorm16
I0927 19:02:46.078765  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.078768  3577 net.cpp:137] Memory required for data: 427437200
I0927 19:02:46.078773  3577 layer_factory.hpp:77] Creating layer Scale16
I0927 19:02:46.078776  3577 net.cpp:84] Creating Layer Scale16
I0927 19:02:46.078778  3577 net.cpp:406] Scale16 <- Convolution16
I0927 19:02:46.078783  3577 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0927 19:02:46.078807  3577 layer_factory.hpp:77] Creating layer Scale16
I0927 19:02:46.078881  3577 net.cpp:122] Setting up Scale16
I0927 19:02:46.078886  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.078887  3577 net.cpp:137] Memory required for data: 432454800
I0927 19:02:46.078891  3577 layer_factory.hpp:77] Creating layer M2PELU16
I0927 19:02:46.078896  3577 net.cpp:84] Creating Layer M2PELU16
I0927 19:02:46.078898  3577 net.cpp:406] M2PELU16 <- Convolution16
I0927 19:02:46.078902  3577 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0927 19:02:46.078985  3577 net.cpp:122] Setting up M2PELU16
I0927 19:02:46.078989  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.078991  3577 net.cpp:137] Memory required for data: 437472400
I0927 19:02:46.078994  3577 layer_factory.hpp:77] Creating layer Convolution17
I0927 19:02:46.079002  3577 net.cpp:84] Creating Layer Convolution17
I0927 19:02:46.079005  3577 net.cpp:406] Convolution17 <- Convolution16
I0927 19:02:46.079008  3577 net.cpp:380] Convolution17 -> Convolution17
I0927 19:02:46.079550  3577 net.cpp:122] Setting up Convolution17
I0927 19:02:46.079557  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.079560  3577 net.cpp:137] Memory required for data: 442490000
I0927 19:02:46.079565  3577 layer_factory.hpp:77] Creating layer BatchNorm17
I0927 19:02:46.079568  3577 net.cpp:84] Creating Layer BatchNorm17
I0927 19:02:46.079571  3577 net.cpp:406] BatchNorm17 <- Convolution17
I0927 19:02:46.079576  3577 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0927 19:02:46.079704  3577 net.cpp:122] Setting up BatchNorm17
I0927 19:02:46.079708  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.079710  3577 net.cpp:137] Memory required for data: 447507600
I0927 19:02:46.079715  3577 layer_factory.hpp:77] Creating layer Scale17
I0927 19:02:46.079718  3577 net.cpp:84] Creating Layer Scale17
I0927 19:02:46.079720  3577 net.cpp:406] Scale17 <- Convolution17
I0927 19:02:46.079723  3577 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0927 19:02:46.079748  3577 layer_factory.hpp:77] Creating layer Scale17
I0927 19:02:46.079824  3577 net.cpp:122] Setting up Scale17
I0927 19:02:46.079829  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.079831  3577 net.cpp:137] Memory required for data: 452525200
I0927 19:02:46.079834  3577 layer_factory.hpp:77] Creating layer Eltwise8
I0927 19:02:46.079838  3577 net.cpp:84] Creating Layer Eltwise8
I0927 19:02:46.079841  3577 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0927 19:02:46.079843  3577 net.cpp:406] Eltwise8 <- Convolution17
I0927 19:02:46.079847  3577 net.cpp:380] Eltwise8 -> Eltwise8
I0927 19:02:46.079862  3577 net.cpp:122] Setting up Eltwise8
I0927 19:02:46.079866  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.079869  3577 net.cpp:137] Memory required for data: 457542800
I0927 19:02:46.079870  3577 layer_factory.hpp:77] Creating layer M2PELU17
I0927 19:02:46.079874  3577 net.cpp:84] Creating Layer M2PELU17
I0927 19:02:46.079876  3577 net.cpp:406] M2PELU17 <- Eltwise8
I0927 19:02:46.079880  3577 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0927 19:02:46.079965  3577 net.cpp:122] Setting up M2PELU17
I0927 19:02:46.079969  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.079972  3577 net.cpp:137] Memory required for data: 462560400
I0927 19:02:46.079974  3577 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0927 19:02:46.079984  3577 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0927 19:02:46.079988  3577 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0927 19:02:46.079990  3577 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0927 19:02:46.079995  3577 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0927 19:02:46.080018  3577 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0927 19:02:46.080021  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.080024  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.080026  3577 net.cpp:137] Memory required for data: 472595600
I0927 19:02:46.080029  3577 layer_factory.hpp:77] Creating layer Convolution18
I0927 19:02:46.080034  3577 net.cpp:84] Creating Layer Convolution18
I0927 19:02:46.080036  3577 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0927 19:02:46.080040  3577 net.cpp:380] Convolution18 -> Convolution18
I0927 19:02:46.080895  3577 net.cpp:122] Setting up Convolution18
I0927 19:02:46.080904  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.080907  3577 net.cpp:137] Memory required for data: 477613200
I0927 19:02:46.080911  3577 layer_factory.hpp:77] Creating layer BatchNorm18
I0927 19:02:46.080917  3577 net.cpp:84] Creating Layer BatchNorm18
I0927 19:02:46.080919  3577 net.cpp:406] BatchNorm18 <- Convolution18
I0927 19:02:46.080924  3577 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0927 19:02:46.081053  3577 net.cpp:122] Setting up BatchNorm18
I0927 19:02:46.081058  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.081059  3577 net.cpp:137] Memory required for data: 482630800
I0927 19:02:46.081063  3577 layer_factory.hpp:77] Creating layer Scale18
I0927 19:02:46.081068  3577 net.cpp:84] Creating Layer Scale18
I0927 19:02:46.081070  3577 net.cpp:406] Scale18 <- Convolution18
I0927 19:02:46.081073  3577 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0927 19:02:46.081099  3577 layer_factory.hpp:77] Creating layer Scale18
I0927 19:02:46.081176  3577 net.cpp:122] Setting up Scale18
I0927 19:02:46.081181  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.081182  3577 net.cpp:137] Memory required for data: 487648400
I0927 19:02:46.081187  3577 layer_factory.hpp:77] Creating layer M2PELU18
I0927 19:02:46.081192  3577 net.cpp:84] Creating Layer M2PELU18
I0927 19:02:46.081193  3577 net.cpp:406] M2PELU18 <- Convolution18
I0927 19:02:46.081197  3577 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0927 19:02:46.081279  3577 net.cpp:122] Setting up M2PELU18
I0927 19:02:46.081284  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.081285  3577 net.cpp:137] Memory required for data: 492666000
I0927 19:02:46.081290  3577 layer_factory.hpp:77] Creating layer Convolution19
I0927 19:02:46.081295  3577 net.cpp:84] Creating Layer Convolution19
I0927 19:02:46.081298  3577 net.cpp:406] Convolution19 <- Convolution18
I0927 19:02:46.081301  3577 net.cpp:380] Convolution19 -> Convolution19
I0927 19:02:46.082175  3577 net.cpp:122] Setting up Convolution19
I0927 19:02:46.082183  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.082186  3577 net.cpp:137] Memory required for data: 497683600
I0927 19:02:46.082190  3577 layer_factory.hpp:77] Creating layer BatchNorm19
I0927 19:02:46.082195  3577 net.cpp:84] Creating Layer BatchNorm19
I0927 19:02:46.082197  3577 net.cpp:406] BatchNorm19 <- Convolution19
I0927 19:02:46.082201  3577 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0927 19:02:46.082331  3577 net.cpp:122] Setting up BatchNorm19
I0927 19:02:46.082348  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.082351  3577 net.cpp:137] Memory required for data: 502701200
I0927 19:02:46.082356  3577 layer_factory.hpp:77] Creating layer Scale19
I0927 19:02:46.082363  3577 net.cpp:84] Creating Layer Scale19
I0927 19:02:46.082368  3577 net.cpp:406] Scale19 <- Convolution19
I0927 19:02:46.082386  3577 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0927 19:02:46.082423  3577 layer_factory.hpp:77] Creating layer Scale19
I0927 19:02:46.082542  3577 net.cpp:122] Setting up Scale19
I0927 19:02:46.082548  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.082551  3577 net.cpp:137] Memory required for data: 507718800
I0927 19:02:46.082556  3577 layer_factory.hpp:77] Creating layer Eltwise9
I0927 19:02:46.082559  3577 net.cpp:84] Creating Layer Eltwise9
I0927 19:02:46.082561  3577 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0927 19:02:46.082564  3577 net.cpp:406] Eltwise9 <- Convolution19
I0927 19:02:46.082568  3577 net.cpp:380] Eltwise9 -> Eltwise9
I0927 19:02:46.082586  3577 net.cpp:122] Setting up Eltwise9
I0927 19:02:46.082589  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.082592  3577 net.cpp:137] Memory required for data: 512736400
I0927 19:02:46.082593  3577 layer_factory.hpp:77] Creating layer M2PELU19
I0927 19:02:46.082597  3577 net.cpp:84] Creating Layer M2PELU19
I0927 19:02:46.082600  3577 net.cpp:406] M2PELU19 <- Eltwise9
I0927 19:02:46.082604  3577 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0927 19:02:46.082690  3577 net.cpp:122] Setting up M2PELU19
I0927 19:02:46.082695  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.082697  3577 net.cpp:137] Memory required for data: 517754000
I0927 19:02:46.082700  3577 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0927 19:02:46.082705  3577 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0927 19:02:46.082707  3577 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0927 19:02:46.082710  3577 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0927 19:02:46.082715  3577 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0927 19:02:46.082738  3577 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0927 19:02:46.082741  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.082744  3577 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 19:02:46.082746  3577 net.cpp:137] Memory required for data: 527789200
I0927 19:02:46.082748  3577 layer_factory.hpp:77] Creating layer Convolution20
I0927 19:02:46.082753  3577 net.cpp:84] Creating Layer Convolution20
I0927 19:02:46.082756  3577 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0927 19:02:46.082761  3577 net.cpp:380] Convolution20 -> Convolution20
I0927 19:02:46.083972  3577 net.cpp:122] Setting up Convolution20
I0927 19:02:46.083981  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.083984  3577 net.cpp:137] Memory required for data: 530298000
I0927 19:02:46.083989  3577 layer_factory.hpp:77] Creating layer BatchNorm20
I0927 19:02:46.083994  3577 net.cpp:84] Creating Layer BatchNorm20
I0927 19:02:46.083997  3577 net.cpp:406] BatchNorm20 <- Convolution20
I0927 19:02:46.084002  3577 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0927 19:02:46.084152  3577 net.cpp:122] Setting up BatchNorm20
I0927 19:02:46.084156  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.084158  3577 net.cpp:137] Memory required for data: 532806800
I0927 19:02:46.084163  3577 layer_factory.hpp:77] Creating layer Scale20
I0927 19:02:46.084168  3577 net.cpp:84] Creating Layer Scale20
I0927 19:02:46.084170  3577 net.cpp:406] Scale20 <- Convolution20
I0927 19:02:46.084173  3577 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0927 19:02:46.084201  3577 layer_factory.hpp:77] Creating layer Scale20
I0927 19:02:46.084277  3577 net.cpp:122] Setting up Scale20
I0927 19:02:46.084282  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.084285  3577 net.cpp:137] Memory required for data: 535315600
I0927 19:02:46.084288  3577 layer_factory.hpp:77] Creating layer Convolution21
I0927 19:02:46.084295  3577 net.cpp:84] Creating Layer Convolution21
I0927 19:02:46.084298  3577 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0927 19:02:46.084302  3577 net.cpp:380] Convolution21 -> Convolution21
I0927 19:02:46.086037  3577 net.cpp:122] Setting up Convolution21
I0927 19:02:46.086046  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.086056  3577 net.cpp:137] Memory required for data: 537824400
I0927 19:02:46.086062  3577 layer_factory.hpp:77] Creating layer BatchNorm21
I0927 19:02:46.086068  3577 net.cpp:84] Creating Layer BatchNorm21
I0927 19:02:46.086071  3577 net.cpp:406] BatchNorm21 <- Convolution21
I0927 19:02:46.086076  3577 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0927 19:02:46.086298  3577 net.cpp:122] Setting up BatchNorm21
I0927 19:02:46.086302  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.086304  3577 net.cpp:137] Memory required for data: 540333200
I0927 19:02:46.086309  3577 layer_factory.hpp:77] Creating layer Scale21
I0927 19:02:46.086313  3577 net.cpp:84] Creating Layer Scale21
I0927 19:02:46.086316  3577 net.cpp:406] Scale21 <- Convolution21
I0927 19:02:46.086319  3577 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0927 19:02:46.086346  3577 layer_factory.hpp:77] Creating layer Scale21
I0927 19:02:46.086422  3577 net.cpp:122] Setting up Scale21
I0927 19:02:46.086427  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.086429  3577 net.cpp:137] Memory required for data: 542842000
I0927 19:02:46.086433  3577 layer_factory.hpp:77] Creating layer M2PELU20
I0927 19:02:46.086438  3577 net.cpp:84] Creating Layer M2PELU20
I0927 19:02:46.086441  3577 net.cpp:406] M2PELU20 <- Convolution21
I0927 19:02:46.086444  3577 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0927 19:02:46.086549  3577 net.cpp:122] Setting up M2PELU20
I0927 19:02:46.086563  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.086565  3577 net.cpp:137] Memory required for data: 545350800
I0927 19:02:46.086570  3577 layer_factory.hpp:77] Creating layer Convolution22
I0927 19:02:46.086576  3577 net.cpp:84] Creating Layer Convolution22
I0927 19:02:46.086578  3577 net.cpp:406] Convolution22 <- Convolution21
I0927 19:02:46.086591  3577 net.cpp:380] Convolution22 -> Convolution22
I0927 19:02:46.087642  3577 net.cpp:122] Setting up Convolution22
I0927 19:02:46.087651  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.087654  3577 net.cpp:137] Memory required for data: 547859600
I0927 19:02:46.087658  3577 layer_factory.hpp:77] Creating layer BatchNorm22
I0927 19:02:46.087663  3577 net.cpp:84] Creating Layer BatchNorm22
I0927 19:02:46.087666  3577 net.cpp:406] BatchNorm22 <- Convolution22
I0927 19:02:46.087669  3577 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0927 19:02:46.087803  3577 net.cpp:122] Setting up BatchNorm22
I0927 19:02:46.087808  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.087810  3577 net.cpp:137] Memory required for data: 550368400
I0927 19:02:46.087815  3577 layer_factory.hpp:77] Creating layer Scale22
I0927 19:02:46.087819  3577 net.cpp:84] Creating Layer Scale22
I0927 19:02:46.087821  3577 net.cpp:406] Scale22 <- Convolution22
I0927 19:02:46.087824  3577 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0927 19:02:46.087852  3577 layer_factory.hpp:77] Creating layer Scale22
I0927 19:02:46.087926  3577 net.cpp:122] Setting up Scale22
I0927 19:02:46.087930  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.087932  3577 net.cpp:137] Memory required for data: 552877200
I0927 19:02:46.087936  3577 layer_factory.hpp:77] Creating layer Eltwise10
I0927 19:02:46.087940  3577 net.cpp:84] Creating Layer Eltwise10
I0927 19:02:46.087942  3577 net.cpp:406] Eltwise10 <- Convolution20
I0927 19:02:46.087945  3577 net.cpp:406] Eltwise10 <- Convolution22
I0927 19:02:46.087949  3577 net.cpp:380] Eltwise10 -> Eltwise10
I0927 19:02:46.087965  3577 net.cpp:122] Setting up Eltwise10
I0927 19:02:46.087968  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.087970  3577 net.cpp:137] Memory required for data: 555386000
I0927 19:02:46.087972  3577 layer_factory.hpp:77] Creating layer M2PELU21
I0927 19:02:46.087977  3577 net.cpp:84] Creating Layer M2PELU21
I0927 19:02:46.087980  3577 net.cpp:406] M2PELU21 <- Eltwise10
I0927 19:02:46.087983  3577 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0927 19:02:46.088065  3577 net.cpp:122] Setting up M2PELU21
I0927 19:02:46.088076  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.088078  3577 net.cpp:137] Memory required for data: 557894800
I0927 19:02:46.088083  3577 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0927 19:02:46.088086  3577 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0927 19:02:46.088088  3577 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0927 19:02:46.088093  3577 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0927 19:02:46.088096  3577 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0927 19:02:46.088120  3577 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0927 19:02:46.088124  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.088127  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.088129  3577 net.cpp:137] Memory required for data: 562912400
I0927 19:02:46.088131  3577 layer_factory.hpp:77] Creating layer Convolution23
I0927 19:02:46.088137  3577 net.cpp:84] Creating Layer Convolution23
I0927 19:02:46.088140  3577 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0927 19:02:46.088143  3577 net.cpp:380] Convolution23 -> Convolution23
I0927 19:02:46.089468  3577 net.cpp:122] Setting up Convolution23
I0927 19:02:46.089476  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.089478  3577 net.cpp:137] Memory required for data: 565421200
I0927 19:02:46.089483  3577 layer_factory.hpp:77] Creating layer BatchNorm23
I0927 19:02:46.089488  3577 net.cpp:84] Creating Layer BatchNorm23
I0927 19:02:46.089491  3577 net.cpp:406] BatchNorm23 <- Convolution23
I0927 19:02:46.089494  3577 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0927 19:02:46.089630  3577 net.cpp:122] Setting up BatchNorm23
I0927 19:02:46.089635  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.089637  3577 net.cpp:137] Memory required for data: 567930000
I0927 19:02:46.089643  3577 layer_factory.hpp:77] Creating layer Scale23
I0927 19:02:46.089645  3577 net.cpp:84] Creating Layer Scale23
I0927 19:02:46.089648  3577 net.cpp:406] Scale23 <- Convolution23
I0927 19:02:46.089653  3577 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0927 19:02:46.089678  3577 layer_factory.hpp:77] Creating layer Scale23
I0927 19:02:46.089753  3577 net.cpp:122] Setting up Scale23
I0927 19:02:46.089757  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.089759  3577 net.cpp:137] Memory required for data: 570438800
I0927 19:02:46.089763  3577 layer_factory.hpp:77] Creating layer M2PELU22
I0927 19:02:46.089768  3577 net.cpp:84] Creating Layer M2PELU22
I0927 19:02:46.089771  3577 net.cpp:406] M2PELU22 <- Convolution23
I0927 19:02:46.089774  3577 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0927 19:02:46.089857  3577 net.cpp:122] Setting up M2PELU22
I0927 19:02:46.089862  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.089864  3577 net.cpp:137] Memory required for data: 572947600
I0927 19:02:46.089867  3577 layer_factory.hpp:77] Creating layer Convolution24
I0927 19:02:46.089874  3577 net.cpp:84] Creating Layer Convolution24
I0927 19:02:46.089876  3577 net.cpp:406] Convolution24 <- Convolution23
I0927 19:02:46.089880  3577 net.cpp:380] Convolution24 -> Convolution24
I0927 19:02:46.090914  3577 net.cpp:122] Setting up Convolution24
I0927 19:02:46.090922  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.090925  3577 net.cpp:137] Memory required for data: 575456400
I0927 19:02:46.090929  3577 layer_factory.hpp:77] Creating layer BatchNorm24
I0927 19:02:46.090934  3577 net.cpp:84] Creating Layer BatchNorm24
I0927 19:02:46.090937  3577 net.cpp:406] BatchNorm24 <- Convolution24
I0927 19:02:46.090940  3577 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0927 19:02:46.091074  3577 net.cpp:122] Setting up BatchNorm24
I0927 19:02:46.091078  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.091080  3577 net.cpp:137] Memory required for data: 577965200
I0927 19:02:46.091085  3577 layer_factory.hpp:77] Creating layer Scale24
I0927 19:02:46.091095  3577 net.cpp:84] Creating Layer Scale24
I0927 19:02:46.091099  3577 net.cpp:406] Scale24 <- Convolution24
I0927 19:02:46.091101  3577 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0927 19:02:46.091130  3577 layer_factory.hpp:77] Creating layer Scale24
I0927 19:02:46.091205  3577 net.cpp:122] Setting up Scale24
I0927 19:02:46.091209  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.091212  3577 net.cpp:137] Memory required for data: 580474000
I0927 19:02:46.091215  3577 layer_factory.hpp:77] Creating layer Eltwise11
I0927 19:02:46.091220  3577 net.cpp:84] Creating Layer Eltwise11
I0927 19:02:46.091223  3577 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0927 19:02:46.091225  3577 net.cpp:406] Eltwise11 <- Convolution24
I0927 19:02:46.091228  3577 net.cpp:380] Eltwise11 -> Eltwise11
I0927 19:02:46.091244  3577 net.cpp:122] Setting up Eltwise11
I0927 19:02:46.091248  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.091250  3577 net.cpp:137] Memory required for data: 582982800
I0927 19:02:46.091253  3577 layer_factory.hpp:77] Creating layer M2PELU23
I0927 19:02:46.091258  3577 net.cpp:84] Creating Layer M2PELU23
I0927 19:02:46.091259  3577 net.cpp:406] M2PELU23 <- Eltwise11
I0927 19:02:46.091262  3577 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0927 19:02:46.091343  3577 net.cpp:122] Setting up M2PELU23
I0927 19:02:46.091348  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.091351  3577 net.cpp:137] Memory required for data: 585491600
I0927 19:02:46.091354  3577 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0927 19:02:46.091357  3577 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0927 19:02:46.091359  3577 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0927 19:02:46.091363  3577 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0927 19:02:46.091367  3577 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0927 19:02:46.091392  3577 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0927 19:02:46.091394  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.091398  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.091399  3577 net.cpp:137] Memory required for data: 590509200
I0927 19:02:46.091401  3577 layer_factory.hpp:77] Creating layer Convolution25
I0927 19:02:46.091408  3577 net.cpp:84] Creating Layer Convolution25
I0927 19:02:46.091409  3577 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0927 19:02:46.091413  3577 net.cpp:380] Convolution25 -> Convolution25
I0927 19:02:46.092432  3577 net.cpp:122] Setting up Convolution25
I0927 19:02:46.092442  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.092454  3577 net.cpp:137] Memory required for data: 593018000
I0927 19:02:46.092458  3577 layer_factory.hpp:77] Creating layer BatchNorm25
I0927 19:02:46.092463  3577 net.cpp:84] Creating Layer BatchNorm25
I0927 19:02:46.092466  3577 net.cpp:406] BatchNorm25 <- Convolution25
I0927 19:02:46.092470  3577 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0927 19:02:46.092613  3577 net.cpp:122] Setting up BatchNorm25
I0927 19:02:46.092618  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.092620  3577 net.cpp:137] Memory required for data: 595526800
I0927 19:02:46.092624  3577 layer_factory.hpp:77] Creating layer Scale25
I0927 19:02:46.092628  3577 net.cpp:84] Creating Layer Scale25
I0927 19:02:46.092631  3577 net.cpp:406] Scale25 <- Convolution25
I0927 19:02:46.092634  3577 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0927 19:02:46.092660  3577 layer_factory.hpp:77] Creating layer Scale25
I0927 19:02:46.092736  3577 net.cpp:122] Setting up Scale25
I0927 19:02:46.092741  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.092742  3577 net.cpp:137] Memory required for data: 598035600
I0927 19:02:46.092746  3577 layer_factory.hpp:77] Creating layer M2PELU24
I0927 19:02:46.092751  3577 net.cpp:84] Creating Layer M2PELU24
I0927 19:02:46.092753  3577 net.cpp:406] M2PELU24 <- Convolution25
I0927 19:02:46.092763  3577 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0927 19:02:46.092847  3577 net.cpp:122] Setting up M2PELU24
I0927 19:02:46.092852  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.092854  3577 net.cpp:137] Memory required for data: 600544400
I0927 19:02:46.092857  3577 layer_factory.hpp:77] Creating layer Convolution26
I0927 19:02:46.092864  3577 net.cpp:84] Creating Layer Convolution26
I0927 19:02:46.092866  3577 net.cpp:406] Convolution26 <- Convolution25
I0927 19:02:46.092870  3577 net.cpp:380] Convolution26 -> Convolution26
I0927 19:02:46.093920  3577 net.cpp:122] Setting up Convolution26
I0927 19:02:46.093930  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.093932  3577 net.cpp:137] Memory required for data: 603053200
I0927 19:02:46.093936  3577 layer_factory.hpp:77] Creating layer BatchNorm26
I0927 19:02:46.093941  3577 net.cpp:84] Creating Layer BatchNorm26
I0927 19:02:46.093945  3577 net.cpp:406] BatchNorm26 <- Convolution26
I0927 19:02:46.093948  3577 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0927 19:02:46.094091  3577 net.cpp:122] Setting up BatchNorm26
I0927 19:02:46.094095  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.094097  3577 net.cpp:137] Memory required for data: 605562000
I0927 19:02:46.094102  3577 layer_factory.hpp:77] Creating layer Scale26
I0927 19:02:46.094106  3577 net.cpp:84] Creating Layer Scale26
I0927 19:02:46.094110  3577 net.cpp:406] Scale26 <- Convolution26
I0927 19:02:46.094112  3577 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0927 19:02:46.094139  3577 layer_factory.hpp:77] Creating layer Scale26
I0927 19:02:46.094214  3577 net.cpp:122] Setting up Scale26
I0927 19:02:46.094218  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.094220  3577 net.cpp:137] Memory required for data: 608070800
I0927 19:02:46.094224  3577 layer_factory.hpp:77] Creating layer Eltwise12
I0927 19:02:46.094228  3577 net.cpp:84] Creating Layer Eltwise12
I0927 19:02:46.094231  3577 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0927 19:02:46.094233  3577 net.cpp:406] Eltwise12 <- Convolution26
I0927 19:02:46.094238  3577 net.cpp:380] Eltwise12 -> Eltwise12
I0927 19:02:46.094252  3577 net.cpp:122] Setting up Eltwise12
I0927 19:02:46.094256  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.094259  3577 net.cpp:137] Memory required for data: 610579600
I0927 19:02:46.094260  3577 layer_factory.hpp:77] Creating layer M2PELU25
I0927 19:02:46.094265  3577 net.cpp:84] Creating Layer M2PELU25
I0927 19:02:46.094267  3577 net.cpp:406] M2PELU25 <- Eltwise12
I0927 19:02:46.094270  3577 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0927 19:02:46.094352  3577 net.cpp:122] Setting up M2PELU25
I0927 19:02:46.094357  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.094359  3577 net.cpp:137] Memory required for data: 613088400
I0927 19:02:46.094363  3577 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0927 19:02:46.094375  3577 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0927 19:02:46.094377  3577 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0927 19:02:46.094382  3577 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0927 19:02:46.094390  3577 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0927 19:02:46.094413  3577 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0927 19:02:46.094418  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.094419  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.094421  3577 net.cpp:137] Memory required for data: 618106000
I0927 19:02:46.094424  3577 layer_factory.hpp:77] Creating layer Convolution27
I0927 19:02:46.094430  3577 net.cpp:84] Creating Layer Convolution27
I0927 19:02:46.094434  3577 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0927 19:02:46.094436  3577 net.cpp:380] Convolution27 -> Convolution27
I0927 19:02:46.095160  3577 net.cpp:122] Setting up Convolution27
I0927 19:02:46.095168  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.095177  3577 net.cpp:137] Memory required for data: 620614800
I0927 19:02:46.095181  3577 layer_factory.hpp:77] Creating layer BatchNorm27
I0927 19:02:46.095186  3577 net.cpp:84] Creating Layer BatchNorm27
I0927 19:02:46.095188  3577 net.cpp:406] BatchNorm27 <- Convolution27
I0927 19:02:46.095194  3577 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0927 19:02:46.095329  3577 net.cpp:122] Setting up BatchNorm27
I0927 19:02:46.095333  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.095335  3577 net.cpp:137] Memory required for data: 623123600
I0927 19:02:46.095340  3577 layer_factory.hpp:77] Creating layer Scale27
I0927 19:02:46.095345  3577 net.cpp:84] Creating Layer Scale27
I0927 19:02:46.095346  3577 net.cpp:406] Scale27 <- Convolution27
I0927 19:02:46.095350  3577 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0927 19:02:46.095376  3577 layer_factory.hpp:77] Creating layer Scale27
I0927 19:02:46.095449  3577 net.cpp:122] Setting up Scale27
I0927 19:02:46.095453  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.095455  3577 net.cpp:137] Memory required for data: 625632400
I0927 19:02:46.095459  3577 layer_factory.hpp:77] Creating layer M2PELU26
I0927 19:02:46.095463  3577 net.cpp:84] Creating Layer M2PELU26
I0927 19:02:46.095466  3577 net.cpp:406] M2PELU26 <- Convolution27
I0927 19:02:46.095469  3577 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0927 19:02:46.095552  3577 net.cpp:122] Setting up M2PELU26
I0927 19:02:46.095556  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.095558  3577 net.cpp:137] Memory required for data: 628141200
I0927 19:02:46.095562  3577 layer_factory.hpp:77] Creating layer Convolution28
I0927 19:02:46.095569  3577 net.cpp:84] Creating Layer Convolution28
I0927 19:02:46.095571  3577 net.cpp:406] Convolution28 <- Convolution27
I0927 19:02:46.095576  3577 net.cpp:380] Convolution28 -> Convolution28
I0927 19:02:46.096597  3577 net.cpp:122] Setting up Convolution28
I0927 19:02:46.096606  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.096608  3577 net.cpp:137] Memory required for data: 630650000
I0927 19:02:46.096612  3577 layer_factory.hpp:77] Creating layer BatchNorm28
I0927 19:02:46.096617  3577 net.cpp:84] Creating Layer BatchNorm28
I0927 19:02:46.096621  3577 net.cpp:406] BatchNorm28 <- Convolution28
I0927 19:02:46.096624  3577 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0927 19:02:46.096757  3577 net.cpp:122] Setting up BatchNorm28
I0927 19:02:46.096761  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.096765  3577 net.cpp:137] Memory required for data: 633158800
I0927 19:02:46.096768  3577 layer_factory.hpp:77] Creating layer Scale28
I0927 19:02:46.096773  3577 net.cpp:84] Creating Layer Scale28
I0927 19:02:46.096776  3577 net.cpp:406] Scale28 <- Convolution28
I0927 19:02:46.096778  3577 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0927 19:02:46.096804  3577 layer_factory.hpp:77] Creating layer Scale28
I0927 19:02:46.096879  3577 net.cpp:122] Setting up Scale28
I0927 19:02:46.096884  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.096885  3577 net.cpp:137] Memory required for data: 635667600
I0927 19:02:46.096889  3577 layer_factory.hpp:77] Creating layer Eltwise13
I0927 19:02:46.096896  3577 net.cpp:84] Creating Layer Eltwise13
I0927 19:02:46.096899  3577 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0927 19:02:46.096901  3577 net.cpp:406] Eltwise13 <- Convolution28
I0927 19:02:46.096905  3577 net.cpp:380] Eltwise13 -> Eltwise13
I0927 19:02:46.096921  3577 net.cpp:122] Setting up Eltwise13
I0927 19:02:46.096925  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.096926  3577 net.cpp:137] Memory required for data: 638176400
I0927 19:02:46.096928  3577 layer_factory.hpp:77] Creating layer M2PELU27
I0927 19:02:46.096933  3577 net.cpp:84] Creating Layer M2PELU27
I0927 19:02:46.096936  3577 net.cpp:406] M2PELU27 <- Eltwise13
I0927 19:02:46.096940  3577 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0927 19:02:46.097030  3577 net.cpp:122] Setting up M2PELU27
I0927 19:02:46.097035  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.097038  3577 net.cpp:137] Memory required for data: 640685200
I0927 19:02:46.097040  3577 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0927 19:02:46.097044  3577 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0927 19:02:46.097046  3577 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0927 19:02:46.097050  3577 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0927 19:02:46.097054  3577 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0927 19:02:46.097077  3577 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0927 19:02:46.097081  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.097084  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.097086  3577 net.cpp:137] Memory required for data: 645702800
I0927 19:02:46.097088  3577 layer_factory.hpp:77] Creating layer Convolution29
I0927 19:02:46.097093  3577 net.cpp:84] Creating Layer Convolution29
I0927 19:02:46.097095  3577 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0927 19:02:46.097100  3577 net.cpp:380] Convolution29 -> Convolution29
I0927 19:02:46.098120  3577 net.cpp:122] Setting up Convolution29
I0927 19:02:46.098129  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.098132  3577 net.cpp:137] Memory required for data: 648211600
I0927 19:02:46.098136  3577 layer_factory.hpp:77] Creating layer BatchNorm29
I0927 19:02:46.098141  3577 net.cpp:84] Creating Layer BatchNorm29
I0927 19:02:46.098143  3577 net.cpp:406] BatchNorm29 <- Convolution29
I0927 19:02:46.098148  3577 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0927 19:02:46.098282  3577 net.cpp:122] Setting up BatchNorm29
I0927 19:02:46.098286  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.098289  3577 net.cpp:137] Memory required for data: 650720400
I0927 19:02:46.098294  3577 layer_factory.hpp:77] Creating layer Scale29
I0927 19:02:46.098297  3577 net.cpp:84] Creating Layer Scale29
I0927 19:02:46.098300  3577 net.cpp:406] Scale29 <- Convolution29
I0927 19:02:46.098304  3577 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0927 19:02:46.098330  3577 layer_factory.hpp:77] Creating layer Scale29
I0927 19:02:46.098405  3577 net.cpp:122] Setting up Scale29
I0927 19:02:46.098410  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.098412  3577 net.cpp:137] Memory required for data: 653229200
I0927 19:02:46.098433  3577 layer_factory.hpp:77] Creating layer M2PELU28
I0927 19:02:46.098438  3577 net.cpp:84] Creating Layer M2PELU28
I0927 19:02:46.098440  3577 net.cpp:406] M2PELU28 <- Convolution29
I0927 19:02:46.098443  3577 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0927 19:02:46.098544  3577 net.cpp:122] Setting up M2PELU28
I0927 19:02:46.098551  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.098553  3577 net.cpp:137] Memory required for data: 655738000
I0927 19:02:46.098567  3577 layer_factory.hpp:77] Creating layer Convolution30
I0927 19:02:46.098573  3577 net.cpp:84] Creating Layer Convolution30
I0927 19:02:46.098575  3577 net.cpp:406] Convolution30 <- Convolution29
I0927 19:02:46.098579  3577 net.cpp:380] Convolution30 -> Convolution30
I0927 19:02:46.099606  3577 net.cpp:122] Setting up Convolution30
I0927 19:02:46.099614  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.099617  3577 net.cpp:137] Memory required for data: 658246800
I0927 19:02:46.099622  3577 layer_factory.hpp:77] Creating layer BatchNorm30
I0927 19:02:46.099627  3577 net.cpp:84] Creating Layer BatchNorm30
I0927 19:02:46.099629  3577 net.cpp:406] BatchNorm30 <- Convolution30
I0927 19:02:46.099633  3577 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0927 19:02:46.099768  3577 net.cpp:122] Setting up BatchNorm30
I0927 19:02:46.099773  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.099776  3577 net.cpp:137] Memory required for data: 660755600
I0927 19:02:46.099786  3577 layer_factory.hpp:77] Creating layer Scale30
I0927 19:02:46.099791  3577 net.cpp:84] Creating Layer Scale30
I0927 19:02:46.099793  3577 net.cpp:406] Scale30 <- Convolution30
I0927 19:02:46.099797  3577 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0927 19:02:46.099825  3577 layer_factory.hpp:77] Creating layer Scale30
I0927 19:02:46.099902  3577 net.cpp:122] Setting up Scale30
I0927 19:02:46.099906  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.099908  3577 net.cpp:137] Memory required for data: 663264400
I0927 19:02:46.099912  3577 layer_factory.hpp:77] Creating layer Eltwise14
I0927 19:02:46.099916  3577 net.cpp:84] Creating Layer Eltwise14
I0927 19:02:46.099918  3577 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0927 19:02:46.099921  3577 net.cpp:406] Eltwise14 <- Convolution30
I0927 19:02:46.099925  3577 net.cpp:380] Eltwise14 -> Eltwise14
I0927 19:02:46.099941  3577 net.cpp:122] Setting up Eltwise14
I0927 19:02:46.099944  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.099946  3577 net.cpp:137] Memory required for data: 665773200
I0927 19:02:46.099948  3577 layer_factory.hpp:77] Creating layer M2PELU29
I0927 19:02:46.099953  3577 net.cpp:84] Creating Layer M2PELU29
I0927 19:02:46.099956  3577 net.cpp:406] M2PELU29 <- Eltwise14
I0927 19:02:46.099958  3577 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0927 19:02:46.100041  3577 net.cpp:122] Setting up M2PELU29
I0927 19:02:46.100046  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.100049  3577 net.cpp:137] Memory required for data: 668282000
I0927 19:02:46.100052  3577 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0927 19:02:46.100055  3577 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0927 19:02:46.100057  3577 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0927 19:02:46.100060  3577 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0927 19:02:46.100065  3577 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0927 19:02:46.100088  3577 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0927 19:02:46.100092  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.100095  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.100096  3577 net.cpp:137] Memory required for data: 673299600
I0927 19:02:46.100098  3577 layer_factory.hpp:77] Creating layer Convolution31
I0927 19:02:46.100105  3577 net.cpp:84] Creating Layer Convolution31
I0927 19:02:46.100107  3577 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0927 19:02:46.100111  3577 net.cpp:380] Convolution31 -> Convolution31
I0927 19:02:46.101135  3577 net.cpp:122] Setting up Convolution31
I0927 19:02:46.101143  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.101146  3577 net.cpp:137] Memory required for data: 675808400
I0927 19:02:46.101150  3577 layer_factory.hpp:77] Creating layer BatchNorm31
I0927 19:02:46.101155  3577 net.cpp:84] Creating Layer BatchNorm31
I0927 19:02:46.101158  3577 net.cpp:406] BatchNorm31 <- Convolution31
I0927 19:02:46.101162  3577 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0927 19:02:46.101297  3577 net.cpp:122] Setting up BatchNorm31
I0927 19:02:46.101301  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.101303  3577 net.cpp:137] Memory required for data: 678317200
I0927 19:02:46.101308  3577 layer_factory.hpp:77] Creating layer Scale31
I0927 19:02:46.101313  3577 net.cpp:84] Creating Layer Scale31
I0927 19:02:46.101315  3577 net.cpp:406] Scale31 <- Convolution31
I0927 19:02:46.101318  3577 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0927 19:02:46.101344  3577 layer_factory.hpp:77] Creating layer Scale31
I0927 19:02:46.101423  3577 net.cpp:122] Setting up Scale31
I0927 19:02:46.101428  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.101429  3577 net.cpp:137] Memory required for data: 680826000
I0927 19:02:46.101433  3577 layer_factory.hpp:77] Creating layer M2PELU30
I0927 19:02:46.101438  3577 net.cpp:84] Creating Layer M2PELU30
I0927 19:02:46.101449  3577 net.cpp:406] M2PELU30 <- Convolution31
I0927 19:02:46.101452  3577 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0927 19:02:46.101538  3577 net.cpp:122] Setting up M2PELU30
I0927 19:02:46.101543  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.101546  3577 net.cpp:137] Memory required for data: 683334800
I0927 19:02:46.101549  3577 layer_factory.hpp:77] Creating layer Convolution32
I0927 19:02:46.101555  3577 net.cpp:84] Creating Layer Convolution32
I0927 19:02:46.101558  3577 net.cpp:406] Convolution32 <- Convolution31
I0927 19:02:46.101562  3577 net.cpp:380] Convolution32 -> Convolution32
I0927 19:02:46.102654  3577 net.cpp:122] Setting up Convolution32
I0927 19:02:46.102664  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.102666  3577 net.cpp:137] Memory required for data: 685843600
I0927 19:02:46.102671  3577 layer_factory.hpp:77] Creating layer BatchNorm32
I0927 19:02:46.102685  3577 net.cpp:84] Creating Layer BatchNorm32
I0927 19:02:46.102689  3577 net.cpp:406] BatchNorm32 <- Convolution32
I0927 19:02:46.102692  3577 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0927 19:02:46.102839  3577 net.cpp:122] Setting up BatchNorm32
I0927 19:02:46.102843  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.102845  3577 net.cpp:137] Memory required for data: 688352400
I0927 19:02:46.102850  3577 layer_factory.hpp:77] Creating layer Scale32
I0927 19:02:46.102855  3577 net.cpp:84] Creating Layer Scale32
I0927 19:02:46.102857  3577 net.cpp:406] Scale32 <- Convolution32
I0927 19:02:46.102861  3577 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0927 19:02:46.102887  3577 layer_factory.hpp:77] Creating layer Scale32
I0927 19:02:46.102963  3577 net.cpp:122] Setting up Scale32
I0927 19:02:46.102968  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.102970  3577 net.cpp:137] Memory required for data: 690861200
I0927 19:02:46.102973  3577 layer_factory.hpp:77] Creating layer Eltwise15
I0927 19:02:46.102977  3577 net.cpp:84] Creating Layer Eltwise15
I0927 19:02:46.102980  3577 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0927 19:02:46.102983  3577 net.cpp:406] Eltwise15 <- Convolution32
I0927 19:02:46.102988  3577 net.cpp:380] Eltwise15 -> Eltwise15
I0927 19:02:46.103003  3577 net.cpp:122] Setting up Eltwise15
I0927 19:02:46.103006  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.103008  3577 net.cpp:137] Memory required for data: 693370000
I0927 19:02:46.103010  3577 layer_factory.hpp:77] Creating layer M2PELU31
I0927 19:02:46.103015  3577 net.cpp:84] Creating Layer M2PELU31
I0927 19:02:46.103018  3577 net.cpp:406] M2PELU31 <- Eltwise15
I0927 19:02:46.103021  3577 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0927 19:02:46.103106  3577 net.cpp:122] Setting up M2PELU31
I0927 19:02:46.103109  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.103111  3577 net.cpp:137] Memory required for data: 695878800
I0927 19:02:46.103116  3577 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0927 19:02:46.103118  3577 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0927 19:02:46.103121  3577 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0927 19:02:46.103124  3577 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0927 19:02:46.103128  3577 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0927 19:02:46.103152  3577 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0927 19:02:46.103155  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.103158  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.103160  3577 net.cpp:137] Memory required for data: 700896400
I0927 19:02:46.103163  3577 layer_factory.hpp:77] Creating layer Convolution33
I0927 19:02:46.103168  3577 net.cpp:84] Creating Layer Convolution33
I0927 19:02:46.103170  3577 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0927 19:02:46.103174  3577 net.cpp:380] Convolution33 -> Convolution33
I0927 19:02:46.104521  3577 net.cpp:122] Setting up Convolution33
I0927 19:02:46.104529  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.104532  3577 net.cpp:137] Memory required for data: 703405200
I0927 19:02:46.104537  3577 layer_factory.hpp:77] Creating layer BatchNorm33
I0927 19:02:46.104540  3577 net.cpp:84] Creating Layer BatchNorm33
I0927 19:02:46.104543  3577 net.cpp:406] BatchNorm33 <- Convolution33
I0927 19:02:46.104547  3577 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0927 19:02:46.104688  3577 net.cpp:122] Setting up BatchNorm33
I0927 19:02:46.104692  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.104694  3577 net.cpp:137] Memory required for data: 705914000
I0927 19:02:46.104699  3577 layer_factory.hpp:77] Creating layer Scale33
I0927 19:02:46.104703  3577 net.cpp:84] Creating Layer Scale33
I0927 19:02:46.104706  3577 net.cpp:406] Scale33 <- Convolution33
I0927 19:02:46.104709  3577 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0927 19:02:46.104735  3577 layer_factory.hpp:77] Creating layer Scale33
I0927 19:02:46.104815  3577 net.cpp:122] Setting up Scale33
I0927 19:02:46.104818  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.104820  3577 net.cpp:137] Memory required for data: 708422800
I0927 19:02:46.104825  3577 layer_factory.hpp:77] Creating layer M2PELU32
I0927 19:02:46.104830  3577 net.cpp:84] Creating Layer M2PELU32
I0927 19:02:46.104832  3577 net.cpp:406] M2PELU32 <- Convolution33
I0927 19:02:46.104835  3577 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0927 19:02:46.104920  3577 net.cpp:122] Setting up M2PELU32
I0927 19:02:46.104924  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.104926  3577 net.cpp:137] Memory required for data: 710931600
I0927 19:02:46.104930  3577 layer_factory.hpp:77] Creating layer Convolution34
I0927 19:02:46.104938  3577 net.cpp:84] Creating Layer Convolution34
I0927 19:02:46.104939  3577 net.cpp:406] Convolution34 <- Convolution33
I0927 19:02:46.104943  3577 net.cpp:380] Convolution34 -> Convolution34
I0927 19:02:46.105979  3577 net.cpp:122] Setting up Convolution34
I0927 19:02:46.105988  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.105991  3577 net.cpp:137] Memory required for data: 713440400
I0927 19:02:46.105995  3577 layer_factory.hpp:77] Creating layer BatchNorm34
I0927 19:02:46.106000  3577 net.cpp:84] Creating Layer BatchNorm34
I0927 19:02:46.106003  3577 net.cpp:406] BatchNorm34 <- Convolution34
I0927 19:02:46.106007  3577 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0927 19:02:46.106144  3577 net.cpp:122] Setting up BatchNorm34
I0927 19:02:46.106148  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.106150  3577 net.cpp:137] Memory required for data: 715949200
I0927 19:02:46.106155  3577 layer_factory.hpp:77] Creating layer Scale34
I0927 19:02:46.106159  3577 net.cpp:84] Creating Layer Scale34
I0927 19:02:46.106161  3577 net.cpp:406] Scale34 <- Convolution34
I0927 19:02:46.106164  3577 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0927 19:02:46.106191  3577 layer_factory.hpp:77] Creating layer Scale34
I0927 19:02:46.106268  3577 net.cpp:122] Setting up Scale34
I0927 19:02:46.106272  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.106274  3577 net.cpp:137] Memory required for data: 718458000
I0927 19:02:46.106278  3577 layer_factory.hpp:77] Creating layer Eltwise16
I0927 19:02:46.106282  3577 net.cpp:84] Creating Layer Eltwise16
I0927 19:02:46.106287  3577 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0927 19:02:46.106289  3577 net.cpp:406] Eltwise16 <- Convolution34
I0927 19:02:46.106292  3577 net.cpp:380] Eltwise16 -> Eltwise16
I0927 19:02:46.106308  3577 net.cpp:122] Setting up Eltwise16
I0927 19:02:46.106312  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.106313  3577 net.cpp:137] Memory required for data: 720966800
I0927 19:02:46.106315  3577 layer_factory.hpp:77] Creating layer M2PELU33
I0927 19:02:46.106320  3577 net.cpp:84] Creating Layer M2PELU33
I0927 19:02:46.106323  3577 net.cpp:406] M2PELU33 <- Eltwise16
I0927 19:02:46.106333  3577 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0927 19:02:46.106420  3577 net.cpp:122] Setting up M2PELU33
I0927 19:02:46.106425  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.106426  3577 net.cpp:137] Memory required for data: 723475600
I0927 19:02:46.106429  3577 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0927 19:02:46.106434  3577 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0927 19:02:46.106436  3577 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0927 19:02:46.106439  3577 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0927 19:02:46.106443  3577 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0927 19:02:46.106467  3577 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0927 19:02:46.106470  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.106472  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.106474  3577 net.cpp:137] Memory required for data: 728493200
I0927 19:02:46.106477  3577 layer_factory.hpp:77] Creating layer Convolution35
I0927 19:02:46.106483  3577 net.cpp:84] Creating Layer Convolution35
I0927 19:02:46.106485  3577 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0927 19:02:46.106489  3577 net.cpp:380] Convolution35 -> Convolution35
I0927 19:02:46.107573  3577 net.cpp:122] Setting up Convolution35
I0927 19:02:46.107581  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.107584  3577 net.cpp:137] Memory required for data: 731002000
I0927 19:02:46.107589  3577 layer_factory.hpp:77] Creating layer BatchNorm35
I0927 19:02:46.107594  3577 net.cpp:84] Creating Layer BatchNorm35
I0927 19:02:46.107596  3577 net.cpp:406] BatchNorm35 <- Convolution35
I0927 19:02:46.107600  3577 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0927 19:02:46.107739  3577 net.cpp:122] Setting up BatchNorm35
I0927 19:02:46.107744  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.107746  3577 net.cpp:137] Memory required for data: 733510800
I0927 19:02:46.107750  3577 layer_factory.hpp:77] Creating layer Scale35
I0927 19:02:46.107755  3577 net.cpp:84] Creating Layer Scale35
I0927 19:02:46.107758  3577 net.cpp:406] Scale35 <- Convolution35
I0927 19:02:46.107761  3577 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0927 19:02:46.107789  3577 layer_factory.hpp:77] Creating layer Scale35
I0927 19:02:46.107867  3577 net.cpp:122] Setting up Scale35
I0927 19:02:46.107872  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.107873  3577 net.cpp:137] Memory required for data: 736019600
I0927 19:02:46.107877  3577 layer_factory.hpp:77] Creating layer M2PELU34
I0927 19:02:46.107882  3577 net.cpp:84] Creating Layer M2PELU34
I0927 19:02:46.107884  3577 net.cpp:406] M2PELU34 <- Convolution35
I0927 19:02:46.107888  3577 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0927 19:02:46.107973  3577 net.cpp:122] Setting up M2PELU34
I0927 19:02:46.107978  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.107980  3577 net.cpp:137] Memory required for data: 738528400
I0927 19:02:46.107983  3577 layer_factory.hpp:77] Creating layer Convolution36
I0927 19:02:46.107990  3577 net.cpp:84] Creating Layer Convolution36
I0927 19:02:46.107992  3577 net.cpp:406] Convolution36 <- Convolution35
I0927 19:02:46.107997  3577 net.cpp:380] Convolution36 -> Convolution36
I0927 19:02:46.109037  3577 net.cpp:122] Setting up Convolution36
I0927 19:02:46.109045  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.109048  3577 net.cpp:137] Memory required for data: 741037200
I0927 19:02:46.109052  3577 layer_factory.hpp:77] Creating layer BatchNorm36
I0927 19:02:46.109058  3577 net.cpp:84] Creating Layer BatchNorm36
I0927 19:02:46.109061  3577 net.cpp:406] BatchNorm36 <- Convolution36
I0927 19:02:46.109064  3577 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0927 19:02:46.109203  3577 net.cpp:122] Setting up BatchNorm36
I0927 19:02:46.109208  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.109216  3577 net.cpp:137] Memory required for data: 743546000
I0927 19:02:46.109221  3577 layer_factory.hpp:77] Creating layer Scale36
I0927 19:02:46.109226  3577 net.cpp:84] Creating Layer Scale36
I0927 19:02:46.109228  3577 net.cpp:406] Scale36 <- Convolution36
I0927 19:02:46.109231  3577 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0927 19:02:46.109259  3577 layer_factory.hpp:77] Creating layer Scale36
I0927 19:02:46.109336  3577 net.cpp:122] Setting up Scale36
I0927 19:02:46.109340  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.109342  3577 net.cpp:137] Memory required for data: 746054800
I0927 19:02:46.109346  3577 layer_factory.hpp:77] Creating layer Eltwise17
I0927 19:02:46.109350  3577 net.cpp:84] Creating Layer Eltwise17
I0927 19:02:46.109352  3577 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0927 19:02:46.109355  3577 net.cpp:406] Eltwise17 <- Convolution36
I0927 19:02:46.109359  3577 net.cpp:380] Eltwise17 -> Eltwise17
I0927 19:02:46.109375  3577 net.cpp:122] Setting up Eltwise17
I0927 19:02:46.109378  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.109380  3577 net.cpp:137] Memory required for data: 748563600
I0927 19:02:46.109382  3577 layer_factory.hpp:77] Creating layer M2PELU35
I0927 19:02:46.109387  3577 net.cpp:84] Creating Layer M2PELU35
I0927 19:02:46.109390  3577 net.cpp:406] M2PELU35 <- Eltwise17
I0927 19:02:46.109393  3577 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0927 19:02:46.109477  3577 net.cpp:122] Setting up M2PELU35
I0927 19:02:46.109483  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.109484  3577 net.cpp:137] Memory required for data: 751072400
I0927 19:02:46.109488  3577 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0927 19:02:46.109493  3577 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0927 19:02:46.109494  3577 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0927 19:02:46.109498  3577 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0927 19:02:46.109501  3577 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0927 19:02:46.109524  3577 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0927 19:02:46.109529  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.109531  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.109532  3577 net.cpp:137] Memory required for data: 756090000
I0927 19:02:46.109534  3577 layer_factory.hpp:77] Creating layer Convolution37
I0927 19:02:46.109540  3577 net.cpp:84] Creating Layer Convolution37
I0927 19:02:46.109544  3577 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0927 19:02:46.109547  3577 net.cpp:380] Convolution37 -> Convolution37
I0927 19:02:46.110258  3577 net.cpp:122] Setting up Convolution37
I0927 19:02:46.110265  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.110268  3577 net.cpp:137] Memory required for data: 758598800
I0927 19:02:46.110272  3577 layer_factory.hpp:77] Creating layer BatchNorm37
I0927 19:02:46.110277  3577 net.cpp:84] Creating Layer BatchNorm37
I0927 19:02:46.110280  3577 net.cpp:406] BatchNorm37 <- Convolution37
I0927 19:02:46.110283  3577 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0927 19:02:46.110419  3577 net.cpp:122] Setting up BatchNorm37
I0927 19:02:46.110424  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.110425  3577 net.cpp:137] Memory required for data: 761107600
I0927 19:02:46.110430  3577 layer_factory.hpp:77] Creating layer Scale37
I0927 19:02:46.110433  3577 net.cpp:84] Creating Layer Scale37
I0927 19:02:46.110436  3577 net.cpp:406] Scale37 <- Convolution37
I0927 19:02:46.110440  3577 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0927 19:02:46.110466  3577 layer_factory.hpp:77] Creating layer Scale37
I0927 19:02:46.110568  3577 net.cpp:122] Setting up Scale37
I0927 19:02:46.110572  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.110574  3577 net.cpp:137] Memory required for data: 763616400
I0927 19:02:46.110579  3577 layer_factory.hpp:77] Creating layer M2PELU36
I0927 19:02:46.110590  3577 net.cpp:84] Creating Layer M2PELU36
I0927 19:02:46.110594  3577 net.cpp:406] M2PELU36 <- Convolution37
I0927 19:02:46.110596  3577 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0927 19:02:46.110682  3577 net.cpp:122] Setting up M2PELU36
I0927 19:02:46.110687  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.110689  3577 net.cpp:137] Memory required for data: 766125200
I0927 19:02:46.110692  3577 layer_factory.hpp:77] Creating layer Convolution38
I0927 19:02:46.110702  3577 net.cpp:84] Creating Layer Convolution38
I0927 19:02:46.110703  3577 net.cpp:406] Convolution38 <- Convolution37
I0927 19:02:46.110708  3577 net.cpp:380] Convolution38 -> Convolution38
I0927 19:02:46.111786  3577 net.cpp:122] Setting up Convolution38
I0927 19:02:46.111794  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.111798  3577 net.cpp:137] Memory required for data: 768634000
I0927 19:02:46.111801  3577 layer_factory.hpp:77] Creating layer BatchNorm38
I0927 19:02:46.111806  3577 net.cpp:84] Creating Layer BatchNorm38
I0927 19:02:46.111809  3577 net.cpp:406] BatchNorm38 <- Convolution38
I0927 19:02:46.111814  3577 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0927 19:02:46.111953  3577 net.cpp:122] Setting up BatchNorm38
I0927 19:02:46.111958  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.111960  3577 net.cpp:137] Memory required for data: 771142800
I0927 19:02:46.111964  3577 layer_factory.hpp:77] Creating layer Scale38
I0927 19:02:46.111968  3577 net.cpp:84] Creating Layer Scale38
I0927 19:02:46.111971  3577 net.cpp:406] Scale38 <- Convolution38
I0927 19:02:46.111975  3577 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0927 19:02:46.112001  3577 layer_factory.hpp:77] Creating layer Scale38
I0927 19:02:46.112087  3577 net.cpp:122] Setting up Scale38
I0927 19:02:46.112092  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.112093  3577 net.cpp:137] Memory required for data: 773651600
I0927 19:02:46.112097  3577 layer_factory.hpp:77] Creating layer Eltwise18
I0927 19:02:46.112100  3577 net.cpp:84] Creating Layer Eltwise18
I0927 19:02:46.112103  3577 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0927 19:02:46.112107  3577 net.cpp:406] Eltwise18 <- Convolution38
I0927 19:02:46.112109  3577 net.cpp:380] Eltwise18 -> Eltwise18
I0927 19:02:46.112125  3577 net.cpp:122] Setting up Eltwise18
I0927 19:02:46.112129  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.112131  3577 net.cpp:137] Memory required for data: 776160400
I0927 19:02:46.112133  3577 layer_factory.hpp:77] Creating layer M2PELU37
I0927 19:02:46.112138  3577 net.cpp:84] Creating Layer M2PELU37
I0927 19:02:46.112140  3577 net.cpp:406] M2PELU37 <- Eltwise18
I0927 19:02:46.112144  3577 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0927 19:02:46.112229  3577 net.cpp:122] Setting up M2PELU37
I0927 19:02:46.112233  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.112236  3577 net.cpp:137] Memory required for data: 778669200
I0927 19:02:46.112238  3577 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0927 19:02:46.112242  3577 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0927 19:02:46.112244  3577 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0927 19:02:46.112248  3577 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0927 19:02:46.112252  3577 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0927 19:02:46.112275  3577 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0927 19:02:46.112280  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.112282  3577 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 19:02:46.112284  3577 net.cpp:137] Memory required for data: 783686800
I0927 19:02:46.112287  3577 layer_factory.hpp:77] Creating layer Convolution39
I0927 19:02:46.112293  3577 net.cpp:84] Creating Layer Convolution39
I0927 19:02:46.112294  3577 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0927 19:02:46.112304  3577 net.cpp:380] Convolution39 -> Convolution39
I0927 19:02:46.113194  3577 net.cpp:122] Setting up Convolution39
I0927 19:02:46.113204  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.113205  3577 net.cpp:137] Memory required for data: 784941200
I0927 19:02:46.113210  3577 layer_factory.hpp:77] Creating layer BatchNorm39
I0927 19:02:46.113215  3577 net.cpp:84] Creating Layer BatchNorm39
I0927 19:02:46.113219  3577 net.cpp:406] BatchNorm39 <- Convolution39
I0927 19:02:46.113221  3577 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0927 19:02:46.113356  3577 net.cpp:122] Setting up BatchNorm39
I0927 19:02:46.113360  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.113363  3577 net.cpp:137] Memory required for data: 786195600
I0927 19:02:46.113368  3577 layer_factory.hpp:77] Creating layer Scale39
I0927 19:02:46.113371  3577 net.cpp:84] Creating Layer Scale39
I0927 19:02:46.113373  3577 net.cpp:406] Scale39 <- Convolution39
I0927 19:02:46.113376  3577 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0927 19:02:46.113404  3577 layer_factory.hpp:77] Creating layer Scale39
I0927 19:02:46.113481  3577 net.cpp:122] Setting up Scale39
I0927 19:02:46.113484  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.113487  3577 net.cpp:137] Memory required for data: 787450000
I0927 19:02:46.113492  3577 layer_factory.hpp:77] Creating layer Convolution40
I0927 19:02:46.113497  3577 net.cpp:84] Creating Layer Convolution40
I0927 19:02:46.113499  3577 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0927 19:02:46.113504  3577 net.cpp:380] Convolution40 -> Convolution40
I0927 19:02:46.115344  3577 net.cpp:122] Setting up Convolution40
I0927 19:02:46.115352  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.115355  3577 net.cpp:137] Memory required for data: 788704400
I0927 19:02:46.115360  3577 layer_factory.hpp:77] Creating layer BatchNorm40
I0927 19:02:46.115365  3577 net.cpp:84] Creating Layer BatchNorm40
I0927 19:02:46.115368  3577 net.cpp:406] BatchNorm40 <- Convolution40
I0927 19:02:46.115372  3577 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0927 19:02:46.115511  3577 net.cpp:122] Setting up BatchNorm40
I0927 19:02:46.115515  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.115517  3577 net.cpp:137] Memory required for data: 789958800
I0927 19:02:46.115522  3577 layer_factory.hpp:77] Creating layer Scale40
I0927 19:02:46.115527  3577 net.cpp:84] Creating Layer Scale40
I0927 19:02:46.115530  3577 net.cpp:406] Scale40 <- Convolution40
I0927 19:02:46.115532  3577 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0927 19:02:46.115561  3577 layer_factory.hpp:77] Creating layer Scale40
I0927 19:02:46.115640  3577 net.cpp:122] Setting up Scale40
I0927 19:02:46.115644  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.115646  3577 net.cpp:137] Memory required for data: 791213200
I0927 19:02:46.115650  3577 layer_factory.hpp:77] Creating layer M2PELU38
I0927 19:02:46.115655  3577 net.cpp:84] Creating Layer M2PELU38
I0927 19:02:46.115658  3577 net.cpp:406] M2PELU38 <- Convolution40
I0927 19:02:46.115662  3577 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0927 19:02:46.115751  3577 net.cpp:122] Setting up M2PELU38
I0927 19:02:46.115756  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.115757  3577 net.cpp:137] Memory required for data: 792467600
I0927 19:02:46.115761  3577 layer_factory.hpp:77] Creating layer Convolution41
I0927 19:02:46.115767  3577 net.cpp:84] Creating Layer Convolution41
I0927 19:02:46.115770  3577 net.cpp:406] Convolution41 <- Convolution40
I0927 19:02:46.115774  3577 net.cpp:380] Convolution41 -> Convolution41
I0927 19:02:46.117928  3577 net.cpp:122] Setting up Convolution41
I0927 19:02:46.117938  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.117940  3577 net.cpp:137] Memory required for data: 793722000
I0927 19:02:46.117944  3577 layer_factory.hpp:77] Creating layer BatchNorm41
I0927 19:02:46.117950  3577 net.cpp:84] Creating Layer BatchNorm41
I0927 19:02:46.117959  3577 net.cpp:406] BatchNorm41 <- Convolution41
I0927 19:02:46.117964  3577 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0927 19:02:46.118108  3577 net.cpp:122] Setting up BatchNorm41
I0927 19:02:46.118113  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.118115  3577 net.cpp:137] Memory required for data: 794976400
I0927 19:02:46.118120  3577 layer_factory.hpp:77] Creating layer Scale41
I0927 19:02:46.118125  3577 net.cpp:84] Creating Layer Scale41
I0927 19:02:46.118127  3577 net.cpp:406] Scale41 <- Convolution41
I0927 19:02:46.118130  3577 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0927 19:02:46.118160  3577 layer_factory.hpp:77] Creating layer Scale41
I0927 19:02:46.118239  3577 net.cpp:122] Setting up Scale41
I0927 19:02:46.118244  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.118247  3577 net.cpp:137] Memory required for data: 796230800
I0927 19:02:46.118250  3577 layer_factory.hpp:77] Creating layer Eltwise19
I0927 19:02:46.118255  3577 net.cpp:84] Creating Layer Eltwise19
I0927 19:02:46.118257  3577 net.cpp:406] Eltwise19 <- Convolution39
I0927 19:02:46.118260  3577 net.cpp:406] Eltwise19 <- Convolution41
I0927 19:02:46.118263  3577 net.cpp:380] Eltwise19 -> Eltwise19
I0927 19:02:46.118281  3577 net.cpp:122] Setting up Eltwise19
I0927 19:02:46.118284  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.118286  3577 net.cpp:137] Memory required for data: 797485200
I0927 19:02:46.118289  3577 layer_factory.hpp:77] Creating layer M2PELU39
I0927 19:02:46.118294  3577 net.cpp:84] Creating Layer M2PELU39
I0927 19:02:46.118296  3577 net.cpp:406] M2PELU39 <- Eltwise19
I0927 19:02:46.118299  3577 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0927 19:02:46.118401  3577 net.cpp:122] Setting up M2PELU39
I0927 19:02:46.118405  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.118407  3577 net.cpp:137] Memory required for data: 798739600
I0927 19:02:46.118410  3577 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0927 19:02:46.118414  3577 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0927 19:02:46.118417  3577 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0927 19:02:46.118420  3577 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0927 19:02:46.118427  3577 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0927 19:02:46.118480  3577 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0927 19:02:46.118487  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.118491  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.118494  3577 net.cpp:137] Memory required for data: 801248400
I0927 19:02:46.118495  3577 layer_factory.hpp:77] Creating layer Convolution42
I0927 19:02:46.118502  3577 net.cpp:84] Creating Layer Convolution42
I0927 19:02:46.118505  3577 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0927 19:02:46.118510  3577 net.cpp:380] Convolution42 -> Convolution42
I0927 19:02:46.120322  3577 net.cpp:122] Setting up Convolution42
I0927 19:02:46.120332  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.120333  3577 net.cpp:137] Memory required for data: 802502800
I0927 19:02:46.120338  3577 layer_factory.hpp:77] Creating layer BatchNorm42
I0927 19:02:46.120343  3577 net.cpp:84] Creating Layer BatchNorm42
I0927 19:02:46.120347  3577 net.cpp:406] BatchNorm42 <- Convolution42
I0927 19:02:46.120350  3577 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0927 19:02:46.120489  3577 net.cpp:122] Setting up BatchNorm42
I0927 19:02:46.120493  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.120496  3577 net.cpp:137] Memory required for data: 803757200
I0927 19:02:46.120501  3577 layer_factory.hpp:77] Creating layer Scale42
I0927 19:02:46.120506  3577 net.cpp:84] Creating Layer Scale42
I0927 19:02:46.120507  3577 net.cpp:406] Scale42 <- Convolution42
I0927 19:02:46.120510  3577 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0927 19:02:46.120538  3577 layer_factory.hpp:77] Creating layer Scale42
I0927 19:02:46.120627  3577 net.cpp:122] Setting up Scale42
I0927 19:02:46.120632  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.120635  3577 net.cpp:137] Memory required for data: 805011600
I0927 19:02:46.120638  3577 layer_factory.hpp:77] Creating layer M2PELU40
I0927 19:02:46.120643  3577 net.cpp:84] Creating Layer M2PELU40
I0927 19:02:46.120645  3577 net.cpp:406] M2PELU40 <- Convolution42
I0927 19:02:46.120649  3577 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0927 19:02:46.120735  3577 net.cpp:122] Setting up M2PELU40
I0927 19:02:46.120740  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.120743  3577 net.cpp:137] Memory required for data: 806266000
I0927 19:02:46.120746  3577 layer_factory.hpp:77] Creating layer Convolution43
I0927 19:02:46.120753  3577 net.cpp:84] Creating Layer Convolution43
I0927 19:02:46.120754  3577 net.cpp:406] Convolution43 <- Convolution42
I0927 19:02:46.120759  3577 net.cpp:380] Convolution43 -> Convolution43
I0927 19:02:46.123044  3577 net.cpp:122] Setting up Convolution43
I0927 19:02:46.123052  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.123055  3577 net.cpp:137] Memory required for data: 807520400
I0927 19:02:46.123060  3577 layer_factory.hpp:77] Creating layer BatchNorm43
I0927 19:02:46.123065  3577 net.cpp:84] Creating Layer BatchNorm43
I0927 19:02:46.123069  3577 net.cpp:406] BatchNorm43 <- Convolution43
I0927 19:02:46.123071  3577 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0927 19:02:46.123214  3577 net.cpp:122] Setting up BatchNorm43
I0927 19:02:46.123219  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.123220  3577 net.cpp:137] Memory required for data: 808774800
I0927 19:02:46.123224  3577 layer_factory.hpp:77] Creating layer Scale43
I0927 19:02:46.123229  3577 net.cpp:84] Creating Layer Scale43
I0927 19:02:46.123231  3577 net.cpp:406] Scale43 <- Convolution43
I0927 19:02:46.123234  3577 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0927 19:02:46.123262  3577 layer_factory.hpp:77] Creating layer Scale43
I0927 19:02:46.123342  3577 net.cpp:122] Setting up Scale43
I0927 19:02:46.123347  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.123348  3577 net.cpp:137] Memory required for data: 810029200
I0927 19:02:46.123353  3577 layer_factory.hpp:77] Creating layer Eltwise20
I0927 19:02:46.123358  3577 net.cpp:84] Creating Layer Eltwise20
I0927 19:02:46.123360  3577 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0927 19:02:46.123363  3577 net.cpp:406] Eltwise20 <- Convolution43
I0927 19:02:46.123366  3577 net.cpp:380] Eltwise20 -> Eltwise20
I0927 19:02:46.123383  3577 net.cpp:122] Setting up Eltwise20
I0927 19:02:46.123386  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.123389  3577 net.cpp:137] Memory required for data: 811283600
I0927 19:02:46.123390  3577 layer_factory.hpp:77] Creating layer M2PELU41
I0927 19:02:46.123394  3577 net.cpp:84] Creating Layer M2PELU41
I0927 19:02:46.123397  3577 net.cpp:406] M2PELU41 <- Eltwise20
I0927 19:02:46.123400  3577 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0927 19:02:46.123489  3577 net.cpp:122] Setting up M2PELU41
I0927 19:02:46.123493  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.123495  3577 net.cpp:137] Memory required for data: 812538000
I0927 19:02:46.123498  3577 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0927 19:02:46.123502  3577 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0927 19:02:46.123504  3577 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0927 19:02:46.123508  3577 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0927 19:02:46.123512  3577 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0927 19:02:46.123536  3577 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0927 19:02:46.123539  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.123543  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.123544  3577 net.cpp:137] Memory required for data: 815046800
I0927 19:02:46.123553  3577 layer_factory.hpp:77] Creating layer Convolution44
I0927 19:02:46.123558  3577 net.cpp:84] Creating Layer Convolution44
I0927 19:02:46.123561  3577 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0927 19:02:46.123566  3577 net.cpp:380] Convolution44 -> Convolution44
I0927 19:02:46.125241  3577 net.cpp:122] Setting up Convolution44
I0927 19:02:46.125249  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.125252  3577 net.cpp:137] Memory required for data: 816301200
I0927 19:02:46.125257  3577 layer_factory.hpp:77] Creating layer BatchNorm44
I0927 19:02:46.125262  3577 net.cpp:84] Creating Layer BatchNorm44
I0927 19:02:46.125264  3577 net.cpp:406] BatchNorm44 <- Convolution44
I0927 19:02:46.125267  3577 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0927 19:02:46.125413  3577 net.cpp:122] Setting up BatchNorm44
I0927 19:02:46.125417  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.125419  3577 net.cpp:137] Memory required for data: 817555600
I0927 19:02:46.125424  3577 layer_factory.hpp:77] Creating layer Scale44
I0927 19:02:46.125428  3577 net.cpp:84] Creating Layer Scale44
I0927 19:02:46.125432  3577 net.cpp:406] Scale44 <- Convolution44
I0927 19:02:46.125434  3577 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0927 19:02:46.125463  3577 layer_factory.hpp:77] Creating layer Scale44
I0927 19:02:46.125545  3577 net.cpp:122] Setting up Scale44
I0927 19:02:46.125550  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.125551  3577 net.cpp:137] Memory required for data: 818810000
I0927 19:02:46.125555  3577 layer_factory.hpp:77] Creating layer M2PELU42
I0927 19:02:46.125560  3577 net.cpp:84] Creating Layer M2PELU42
I0927 19:02:46.125561  3577 net.cpp:406] M2PELU42 <- Convolution44
I0927 19:02:46.125566  3577 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0927 19:02:46.125656  3577 net.cpp:122] Setting up M2PELU42
I0927 19:02:46.125661  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.125663  3577 net.cpp:137] Memory required for data: 820064400
I0927 19:02:46.125666  3577 layer_factory.hpp:77] Creating layer Convolution45
I0927 19:02:46.125674  3577 net.cpp:84] Creating Layer Convolution45
I0927 19:02:46.125676  3577 net.cpp:406] Convolution45 <- Convolution44
I0927 19:02:46.125680  3577 net.cpp:380] Convolution45 -> Convolution45
I0927 19:02:46.127671  3577 net.cpp:122] Setting up Convolution45
I0927 19:02:46.127679  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.127682  3577 net.cpp:137] Memory required for data: 821318800
I0927 19:02:46.127686  3577 layer_factory.hpp:77] Creating layer BatchNorm45
I0927 19:02:46.127691  3577 net.cpp:84] Creating Layer BatchNorm45
I0927 19:02:46.127693  3577 net.cpp:406] BatchNorm45 <- Convolution45
I0927 19:02:46.127698  3577 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0927 19:02:46.127843  3577 net.cpp:122] Setting up BatchNorm45
I0927 19:02:46.127847  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.127849  3577 net.cpp:137] Memory required for data: 822573200
I0927 19:02:46.127854  3577 layer_factory.hpp:77] Creating layer Scale45
I0927 19:02:46.127858  3577 net.cpp:84] Creating Layer Scale45
I0927 19:02:46.127861  3577 net.cpp:406] Scale45 <- Convolution45
I0927 19:02:46.127864  3577 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0927 19:02:46.127892  3577 layer_factory.hpp:77] Creating layer Scale45
I0927 19:02:46.127975  3577 net.cpp:122] Setting up Scale45
I0927 19:02:46.127979  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.127981  3577 net.cpp:137] Memory required for data: 823827600
I0927 19:02:46.127985  3577 layer_factory.hpp:77] Creating layer Eltwise21
I0927 19:02:46.127990  3577 net.cpp:84] Creating Layer Eltwise21
I0927 19:02:46.127992  3577 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0927 19:02:46.127995  3577 net.cpp:406] Eltwise21 <- Convolution45
I0927 19:02:46.127998  3577 net.cpp:380] Eltwise21 -> Eltwise21
I0927 19:02:46.128015  3577 net.cpp:122] Setting up Eltwise21
I0927 19:02:46.128021  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.128028  3577 net.cpp:137] Memory required for data: 825082000
I0927 19:02:46.128031  3577 layer_factory.hpp:77] Creating layer M2PELU43
I0927 19:02:46.128036  3577 net.cpp:84] Creating Layer M2PELU43
I0927 19:02:46.128037  3577 net.cpp:406] M2PELU43 <- Eltwise21
I0927 19:02:46.128041  3577 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0927 19:02:46.128134  3577 net.cpp:122] Setting up M2PELU43
I0927 19:02:46.128137  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.128139  3577 net.cpp:137] Memory required for data: 826336400
I0927 19:02:46.128144  3577 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0927 19:02:46.128147  3577 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0927 19:02:46.128149  3577 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0927 19:02:46.128154  3577 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0927 19:02:46.128157  3577 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0927 19:02:46.128181  3577 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0927 19:02:46.128185  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.128188  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.128190  3577 net.cpp:137] Memory required for data: 828845200
I0927 19:02:46.128192  3577 layer_factory.hpp:77] Creating layer Convolution46
I0927 19:02:46.128197  3577 net.cpp:84] Creating Layer Convolution46
I0927 19:02:46.128201  3577 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0927 19:02:46.128204  3577 net.cpp:380] Convolution46 -> Convolution46
I0927 19:02:46.129853  3577 net.cpp:122] Setting up Convolution46
I0927 19:02:46.129863  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.129864  3577 net.cpp:137] Memory required for data: 830099600
I0927 19:02:46.129869  3577 layer_factory.hpp:77] Creating layer BatchNorm46
I0927 19:02:46.129874  3577 net.cpp:84] Creating Layer BatchNorm46
I0927 19:02:46.129876  3577 net.cpp:406] BatchNorm46 <- Convolution46
I0927 19:02:46.129880  3577 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0927 19:02:46.130023  3577 net.cpp:122] Setting up BatchNorm46
I0927 19:02:46.130028  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.130030  3577 net.cpp:137] Memory required for data: 831354000
I0927 19:02:46.130034  3577 layer_factory.hpp:77] Creating layer Scale46
I0927 19:02:46.130038  3577 net.cpp:84] Creating Layer Scale46
I0927 19:02:46.130040  3577 net.cpp:406] Scale46 <- Convolution46
I0927 19:02:46.130043  3577 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0927 19:02:46.130072  3577 layer_factory.hpp:77] Creating layer Scale46
I0927 19:02:46.130152  3577 net.cpp:122] Setting up Scale46
I0927 19:02:46.130156  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.130158  3577 net.cpp:137] Memory required for data: 832608400
I0927 19:02:46.130162  3577 layer_factory.hpp:77] Creating layer M2PELU44
I0927 19:02:46.130167  3577 net.cpp:84] Creating Layer M2PELU44
I0927 19:02:46.130169  3577 net.cpp:406] M2PELU44 <- Convolution46
I0927 19:02:46.130173  3577 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0927 19:02:46.130261  3577 net.cpp:122] Setting up M2PELU44
I0927 19:02:46.130266  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.130269  3577 net.cpp:137] Memory required for data: 833862800
I0927 19:02:46.130271  3577 layer_factory.hpp:77] Creating layer Convolution47
I0927 19:02:46.130278  3577 net.cpp:84] Creating Layer Convolution47
I0927 19:02:46.130281  3577 net.cpp:406] Convolution47 <- Convolution46
I0927 19:02:46.130285  3577 net.cpp:380] Convolution47 -> Convolution47
I0927 19:02:46.131947  3577 net.cpp:122] Setting up Convolution47
I0927 19:02:46.131955  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.131958  3577 net.cpp:137] Memory required for data: 835117200
I0927 19:02:46.131963  3577 layer_factory.hpp:77] Creating layer BatchNorm47
I0927 19:02:46.131968  3577 net.cpp:84] Creating Layer BatchNorm47
I0927 19:02:46.131978  3577 net.cpp:406] BatchNorm47 <- Convolution47
I0927 19:02:46.131983  3577 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0927 19:02:46.132127  3577 net.cpp:122] Setting up BatchNorm47
I0927 19:02:46.132131  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.132133  3577 net.cpp:137] Memory required for data: 836371600
I0927 19:02:46.132138  3577 layer_factory.hpp:77] Creating layer Scale47
I0927 19:02:46.132143  3577 net.cpp:84] Creating Layer Scale47
I0927 19:02:46.132145  3577 net.cpp:406] Scale47 <- Convolution47
I0927 19:02:46.132148  3577 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0927 19:02:46.132175  3577 layer_factory.hpp:77] Creating layer Scale47
I0927 19:02:46.132256  3577 net.cpp:122] Setting up Scale47
I0927 19:02:46.132261  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.132262  3577 net.cpp:137] Memory required for data: 837626000
I0927 19:02:46.132266  3577 layer_factory.hpp:77] Creating layer Eltwise22
I0927 19:02:46.132270  3577 net.cpp:84] Creating Layer Eltwise22
I0927 19:02:46.132273  3577 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0927 19:02:46.132277  3577 net.cpp:406] Eltwise22 <- Convolution47
I0927 19:02:46.132279  3577 net.cpp:380] Eltwise22 -> Eltwise22
I0927 19:02:46.132297  3577 net.cpp:122] Setting up Eltwise22
I0927 19:02:46.132299  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.132302  3577 net.cpp:137] Memory required for data: 838880400
I0927 19:02:46.132303  3577 layer_factory.hpp:77] Creating layer M2PELU45
I0927 19:02:46.132308  3577 net.cpp:84] Creating Layer M2PELU45
I0927 19:02:46.132310  3577 net.cpp:406] M2PELU45 <- Eltwise22
I0927 19:02:46.132314  3577 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0927 19:02:46.132402  3577 net.cpp:122] Setting up M2PELU45
I0927 19:02:46.132406  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.132408  3577 net.cpp:137] Memory required for data: 840134800
I0927 19:02:46.132412  3577 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0927 19:02:46.132416  3577 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0927 19:02:46.132419  3577 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0927 19:02:46.132422  3577 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0927 19:02:46.132426  3577 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0927 19:02:46.132450  3577 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0927 19:02:46.132453  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.132457  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.132458  3577 net.cpp:137] Memory required for data: 842643600
I0927 19:02:46.132460  3577 layer_factory.hpp:77] Creating layer Convolution48
I0927 19:02:46.132467  3577 net.cpp:84] Creating Layer Convolution48
I0927 19:02:46.132468  3577 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0927 19:02:46.132472  3577 net.cpp:380] Convolution48 -> Convolution48
I0927 19:02:46.134106  3577 net.cpp:122] Setting up Convolution48
I0927 19:02:46.134115  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.134117  3577 net.cpp:137] Memory required for data: 843898000
I0927 19:02:46.134121  3577 layer_factory.hpp:77] Creating layer BatchNorm48
I0927 19:02:46.134127  3577 net.cpp:84] Creating Layer BatchNorm48
I0927 19:02:46.134130  3577 net.cpp:406] BatchNorm48 <- Convolution48
I0927 19:02:46.134133  3577 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0927 19:02:46.134276  3577 net.cpp:122] Setting up BatchNorm48
I0927 19:02:46.134281  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.134284  3577 net.cpp:137] Memory required for data: 845152400
I0927 19:02:46.134287  3577 layer_factory.hpp:77] Creating layer Scale48
I0927 19:02:46.134291  3577 net.cpp:84] Creating Layer Scale48
I0927 19:02:46.134294  3577 net.cpp:406] Scale48 <- Convolution48
I0927 19:02:46.134297  3577 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0927 19:02:46.134326  3577 layer_factory.hpp:77] Creating layer Scale48
I0927 19:02:46.134418  3577 net.cpp:122] Setting up Scale48
I0927 19:02:46.134423  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.134424  3577 net.cpp:137] Memory required for data: 846406800
I0927 19:02:46.134428  3577 layer_factory.hpp:77] Creating layer M2PELU46
I0927 19:02:46.134433  3577 net.cpp:84] Creating Layer M2PELU46
I0927 19:02:46.134436  3577 net.cpp:406] M2PELU46 <- Convolution48
I0927 19:02:46.134440  3577 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0927 19:02:46.134543  3577 net.cpp:122] Setting up M2PELU46
I0927 19:02:46.134548  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.134551  3577 net.cpp:137] Memory required for data: 847661200
I0927 19:02:46.134554  3577 layer_factory.hpp:77] Creating layer Convolution49
I0927 19:02:46.134569  3577 net.cpp:84] Creating Layer Convolution49
I0927 19:02:46.134572  3577 net.cpp:406] Convolution49 <- Convolution48
I0927 19:02:46.134577  3577 net.cpp:380] Convolution49 -> Convolution49
I0927 19:02:46.136533  3577 net.cpp:122] Setting up Convolution49
I0927 19:02:46.136541  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.136544  3577 net.cpp:137] Memory required for data: 848915600
I0927 19:02:46.136549  3577 layer_factory.hpp:77] Creating layer BatchNorm49
I0927 19:02:46.136554  3577 net.cpp:84] Creating Layer BatchNorm49
I0927 19:02:46.136556  3577 net.cpp:406] BatchNorm49 <- Convolution49
I0927 19:02:46.136560  3577 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0927 19:02:46.136708  3577 net.cpp:122] Setting up BatchNorm49
I0927 19:02:46.136711  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.136713  3577 net.cpp:137] Memory required for data: 850170000
I0927 19:02:46.136718  3577 layer_factory.hpp:77] Creating layer Scale49
I0927 19:02:46.136723  3577 net.cpp:84] Creating Layer Scale49
I0927 19:02:46.136725  3577 net.cpp:406] Scale49 <- Convolution49
I0927 19:02:46.136729  3577 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0927 19:02:46.136757  3577 layer_factory.hpp:77] Creating layer Scale49
I0927 19:02:46.136839  3577 net.cpp:122] Setting up Scale49
I0927 19:02:46.136843  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.136845  3577 net.cpp:137] Memory required for data: 851424400
I0927 19:02:46.136849  3577 layer_factory.hpp:77] Creating layer Eltwise23
I0927 19:02:46.136854  3577 net.cpp:84] Creating Layer Eltwise23
I0927 19:02:46.136857  3577 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0927 19:02:46.136859  3577 net.cpp:406] Eltwise23 <- Convolution49
I0927 19:02:46.136862  3577 net.cpp:380] Eltwise23 -> Eltwise23
I0927 19:02:46.136880  3577 net.cpp:122] Setting up Eltwise23
I0927 19:02:46.136883  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.136885  3577 net.cpp:137] Memory required for data: 852678800
I0927 19:02:46.136888  3577 layer_factory.hpp:77] Creating layer M2PELU47
I0927 19:02:46.136893  3577 net.cpp:84] Creating Layer M2PELU47
I0927 19:02:46.136894  3577 net.cpp:406] M2PELU47 <- Eltwise23
I0927 19:02:46.136898  3577 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0927 19:02:46.136986  3577 net.cpp:122] Setting up M2PELU47
I0927 19:02:46.136991  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.136992  3577 net.cpp:137] Memory required for data: 853933200
I0927 19:02:46.136996  3577 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0927 19:02:46.136999  3577 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0927 19:02:46.137002  3577 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0927 19:02:46.137006  3577 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0927 19:02:46.137010  3577 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0927 19:02:46.137034  3577 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0927 19:02:46.137038  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.137042  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.137043  3577 net.cpp:137] Memory required for data: 856442000
I0927 19:02:46.137051  3577 layer_factory.hpp:77] Creating layer Convolution50
I0927 19:02:46.137058  3577 net.cpp:84] Creating Layer Convolution50
I0927 19:02:46.137060  3577 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0927 19:02:46.137064  3577 net.cpp:380] Convolution50 -> Convolution50
I0927 19:02:46.138743  3577 net.cpp:122] Setting up Convolution50
I0927 19:02:46.138751  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.138754  3577 net.cpp:137] Memory required for data: 857696400
I0927 19:02:46.138758  3577 layer_factory.hpp:77] Creating layer BatchNorm50
I0927 19:02:46.138763  3577 net.cpp:84] Creating Layer BatchNorm50
I0927 19:02:46.138766  3577 net.cpp:406] BatchNorm50 <- Convolution50
I0927 19:02:46.138770  3577 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0927 19:02:46.138916  3577 net.cpp:122] Setting up BatchNorm50
I0927 19:02:46.138921  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.145468  3577 net.cpp:137] Memory required for data: 858950800
I0927 19:02:46.145480  3577 layer_factory.hpp:77] Creating layer Scale50
I0927 19:02:46.145488  3577 net.cpp:84] Creating Layer Scale50
I0927 19:02:46.145491  3577 net.cpp:406] Scale50 <- Convolution50
I0927 19:02:46.145499  3577 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0927 19:02:46.145545  3577 layer_factory.hpp:77] Creating layer Scale50
I0927 19:02:46.145648  3577 net.cpp:122] Setting up Scale50
I0927 19:02:46.145654  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.145656  3577 net.cpp:137] Memory required for data: 860205200
I0927 19:02:46.145660  3577 layer_factory.hpp:77] Creating layer M2PELU48
I0927 19:02:46.145665  3577 net.cpp:84] Creating Layer M2PELU48
I0927 19:02:46.145668  3577 net.cpp:406] M2PELU48 <- Convolution50
I0927 19:02:46.145673  3577 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0927 19:02:46.145774  3577 net.cpp:122] Setting up M2PELU48
I0927 19:02:46.145779  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.145781  3577 net.cpp:137] Memory required for data: 861459600
I0927 19:02:46.145786  3577 layer_factory.hpp:77] Creating layer Convolution51
I0927 19:02:46.145793  3577 net.cpp:84] Creating Layer Convolution51
I0927 19:02:46.145797  3577 net.cpp:406] Convolution51 <- Convolution50
I0927 19:02:46.145802  3577 net.cpp:380] Convolution51 -> Convolution51
I0927 19:02:46.148409  3577 net.cpp:122] Setting up Convolution51
I0927 19:02:46.148417  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.148421  3577 net.cpp:137] Memory required for data: 862714000
I0927 19:02:46.148424  3577 layer_factory.hpp:77] Creating layer BatchNorm51
I0927 19:02:46.148430  3577 net.cpp:84] Creating Layer BatchNorm51
I0927 19:02:46.148433  3577 net.cpp:406] BatchNorm51 <- Convolution51
I0927 19:02:46.148437  3577 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0927 19:02:46.148586  3577 net.cpp:122] Setting up BatchNorm51
I0927 19:02:46.148591  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.148592  3577 net.cpp:137] Memory required for data: 863968400
I0927 19:02:46.148597  3577 layer_factory.hpp:77] Creating layer Scale51
I0927 19:02:46.148602  3577 net.cpp:84] Creating Layer Scale51
I0927 19:02:46.148604  3577 net.cpp:406] Scale51 <- Convolution51
I0927 19:02:46.148607  3577 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0927 19:02:46.148636  3577 layer_factory.hpp:77] Creating layer Scale51
I0927 19:02:46.148721  3577 net.cpp:122] Setting up Scale51
I0927 19:02:46.148726  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.148728  3577 net.cpp:137] Memory required for data: 865222800
I0927 19:02:46.148732  3577 layer_factory.hpp:77] Creating layer Eltwise24
I0927 19:02:46.148736  3577 net.cpp:84] Creating Layer Eltwise24
I0927 19:02:46.148739  3577 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0927 19:02:46.148742  3577 net.cpp:406] Eltwise24 <- Convolution51
I0927 19:02:46.148746  3577 net.cpp:380] Eltwise24 -> Eltwise24
I0927 19:02:46.148764  3577 net.cpp:122] Setting up Eltwise24
I0927 19:02:46.148768  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.148777  3577 net.cpp:137] Memory required for data: 866477200
I0927 19:02:46.148778  3577 layer_factory.hpp:77] Creating layer M2PELU49
I0927 19:02:46.148783  3577 net.cpp:84] Creating Layer M2PELU49
I0927 19:02:46.148787  3577 net.cpp:406] M2PELU49 <- Eltwise24
I0927 19:02:46.148789  3577 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0927 19:02:46.148883  3577 net.cpp:122] Setting up M2PELU49
I0927 19:02:46.148887  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.148890  3577 net.cpp:137] Memory required for data: 867731600
I0927 19:02:46.148893  3577 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0927 19:02:46.148896  3577 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0927 19:02:46.148898  3577 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0927 19:02:46.148902  3577 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0927 19:02:46.148907  3577 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0927 19:02:46.148942  3577 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0927 19:02:46.148946  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.148948  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.148950  3577 net.cpp:137] Memory required for data: 870240400
I0927 19:02:46.148952  3577 layer_factory.hpp:77] Creating layer Convolution52
I0927 19:02:46.148959  3577 net.cpp:84] Creating Layer Convolution52
I0927 19:02:46.148972  3577 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0927 19:02:46.148977  3577 net.cpp:380] Convolution52 -> Convolution52
I0927 19:02:46.150873  3577 net.cpp:122] Setting up Convolution52
I0927 19:02:46.150882  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.150885  3577 net.cpp:137] Memory required for data: 871494800
I0927 19:02:46.150890  3577 layer_factory.hpp:77] Creating layer BatchNorm52
I0927 19:02:46.150894  3577 net.cpp:84] Creating Layer BatchNorm52
I0927 19:02:46.150897  3577 net.cpp:406] BatchNorm52 <- Convolution52
I0927 19:02:46.150902  3577 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0927 19:02:46.151048  3577 net.cpp:122] Setting up BatchNorm52
I0927 19:02:46.151053  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.151055  3577 net.cpp:137] Memory required for data: 872749200
I0927 19:02:46.151060  3577 layer_factory.hpp:77] Creating layer Scale52
I0927 19:02:46.151064  3577 net.cpp:84] Creating Layer Scale52
I0927 19:02:46.151067  3577 net.cpp:406] Scale52 <- Convolution52
I0927 19:02:46.151069  3577 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0927 19:02:46.151098  3577 layer_factory.hpp:77] Creating layer Scale52
I0927 19:02:46.151181  3577 net.cpp:122] Setting up Scale52
I0927 19:02:46.151186  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.151188  3577 net.cpp:137] Memory required for data: 874003600
I0927 19:02:46.151191  3577 layer_factory.hpp:77] Creating layer M2PELU50
I0927 19:02:46.151196  3577 net.cpp:84] Creating Layer M2PELU50
I0927 19:02:46.151198  3577 net.cpp:406] M2PELU50 <- Convolution52
I0927 19:02:46.151202  3577 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0927 19:02:46.151295  3577 net.cpp:122] Setting up M2PELU50
I0927 19:02:46.151299  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.151301  3577 net.cpp:137] Memory required for data: 875258000
I0927 19:02:46.151304  3577 layer_factory.hpp:77] Creating layer Convolution53
I0927 19:02:46.151326  3577 net.cpp:84] Creating Layer Convolution53
I0927 19:02:46.151329  3577 net.cpp:406] Convolution53 <- Convolution52
I0927 19:02:46.151334  3577 net.cpp:380] Convolution53 -> Convolution53
I0927 19:02:46.153301  3577 net.cpp:122] Setting up Convolution53
I0927 19:02:46.153311  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.153313  3577 net.cpp:137] Memory required for data: 876512400
I0927 19:02:46.153317  3577 layer_factory.hpp:77] Creating layer BatchNorm53
I0927 19:02:46.153323  3577 net.cpp:84] Creating Layer BatchNorm53
I0927 19:02:46.153332  3577 net.cpp:406] BatchNorm53 <- Convolution53
I0927 19:02:46.153337  3577 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0927 19:02:46.153486  3577 net.cpp:122] Setting up BatchNorm53
I0927 19:02:46.153491  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.153492  3577 net.cpp:137] Memory required for data: 877766800
I0927 19:02:46.153497  3577 layer_factory.hpp:77] Creating layer Scale53
I0927 19:02:46.153502  3577 net.cpp:84] Creating Layer Scale53
I0927 19:02:46.153504  3577 net.cpp:406] Scale53 <- Convolution53
I0927 19:02:46.153508  3577 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0927 19:02:46.153537  3577 layer_factory.hpp:77] Creating layer Scale53
I0927 19:02:46.153620  3577 net.cpp:122] Setting up Scale53
I0927 19:02:46.153625  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.153627  3577 net.cpp:137] Memory required for data: 879021200
I0927 19:02:46.153631  3577 layer_factory.hpp:77] Creating layer Eltwise25
I0927 19:02:46.153635  3577 net.cpp:84] Creating Layer Eltwise25
I0927 19:02:46.153637  3577 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0927 19:02:46.153640  3577 net.cpp:406] Eltwise25 <- Convolution53
I0927 19:02:46.153645  3577 net.cpp:380] Eltwise25 -> Eltwise25
I0927 19:02:46.153661  3577 net.cpp:122] Setting up Eltwise25
I0927 19:02:46.153664  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.153666  3577 net.cpp:137] Memory required for data: 880275600
I0927 19:02:46.153668  3577 layer_factory.hpp:77] Creating layer M2PELU51
I0927 19:02:46.153673  3577 net.cpp:84] Creating Layer M2PELU51
I0927 19:02:46.153676  3577 net.cpp:406] M2PELU51 <- Eltwise25
I0927 19:02:46.153679  3577 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0927 19:02:46.153769  3577 net.cpp:122] Setting up M2PELU51
I0927 19:02:46.153774  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.153776  3577 net.cpp:137] Memory required for data: 881530000
I0927 19:02:46.153779  3577 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0927 19:02:46.153784  3577 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0927 19:02:46.153785  3577 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0927 19:02:46.153789  3577 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0927 19:02:46.153792  3577 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0927 19:02:46.153817  3577 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0927 19:02:46.153820  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.153823  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.153825  3577 net.cpp:137] Memory required for data: 884038800
I0927 19:02:46.153827  3577 layer_factory.hpp:77] Creating layer Convolution54
I0927 19:02:46.153833  3577 net.cpp:84] Creating Layer Convolution54
I0927 19:02:46.153836  3577 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0927 19:02:46.153841  3577 net.cpp:380] Convolution54 -> Convolution54
I0927 19:02:46.156008  3577 net.cpp:122] Setting up Convolution54
I0927 19:02:46.156016  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.156018  3577 net.cpp:137] Memory required for data: 885293200
I0927 19:02:46.156023  3577 layer_factory.hpp:77] Creating layer BatchNorm54
I0927 19:02:46.156028  3577 net.cpp:84] Creating Layer BatchNorm54
I0927 19:02:46.156031  3577 net.cpp:406] BatchNorm54 <- Convolution54
I0927 19:02:46.156034  3577 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0927 19:02:46.156183  3577 net.cpp:122] Setting up BatchNorm54
I0927 19:02:46.156188  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.156189  3577 net.cpp:137] Memory required for data: 886547600
I0927 19:02:46.156194  3577 layer_factory.hpp:77] Creating layer Scale54
I0927 19:02:46.156198  3577 net.cpp:84] Creating Layer Scale54
I0927 19:02:46.156200  3577 net.cpp:406] Scale54 <- Convolution54
I0927 19:02:46.156203  3577 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0927 19:02:46.156235  3577 layer_factory.hpp:77] Creating layer Scale54
I0927 19:02:46.156327  3577 net.cpp:122] Setting up Scale54
I0927 19:02:46.156332  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.156334  3577 net.cpp:137] Memory required for data: 887802000
I0927 19:02:46.156338  3577 layer_factory.hpp:77] Creating layer M2PELU52
I0927 19:02:46.156343  3577 net.cpp:84] Creating Layer M2PELU52
I0927 19:02:46.156347  3577 net.cpp:406] M2PELU52 <- Convolution54
I0927 19:02:46.156350  3577 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0927 19:02:46.156442  3577 net.cpp:122] Setting up M2PELU52
I0927 19:02:46.156447  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.156450  3577 net.cpp:137] Memory required for data: 889056400
I0927 19:02:46.156452  3577 layer_factory.hpp:77] Creating layer Convolution55
I0927 19:02:46.156460  3577 net.cpp:84] Creating Layer Convolution55
I0927 19:02:46.156462  3577 net.cpp:406] Convolution55 <- Convolution54
I0927 19:02:46.156466  3577 net.cpp:380] Convolution55 -> Convolution55
I0927 19:02:46.158432  3577 net.cpp:122] Setting up Convolution55
I0927 19:02:46.158442  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.158444  3577 net.cpp:137] Memory required for data: 890310800
I0927 19:02:46.158449  3577 layer_factory.hpp:77] Creating layer BatchNorm55
I0927 19:02:46.158453  3577 net.cpp:84] Creating Layer BatchNorm55
I0927 19:02:46.158457  3577 net.cpp:406] BatchNorm55 <- Convolution55
I0927 19:02:46.158460  3577 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0927 19:02:46.158619  3577 net.cpp:122] Setting up BatchNorm55
I0927 19:02:46.158624  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.158627  3577 net.cpp:137] Memory required for data: 891565200
I0927 19:02:46.158632  3577 layer_factory.hpp:77] Creating layer Scale55
I0927 19:02:46.158635  3577 net.cpp:84] Creating Layer Scale55
I0927 19:02:46.158638  3577 net.cpp:406] Scale55 <- Convolution55
I0927 19:02:46.158643  3577 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0927 19:02:46.158671  3577 layer_factory.hpp:77] Creating layer Scale55
I0927 19:02:46.158757  3577 net.cpp:122] Setting up Scale55
I0927 19:02:46.158761  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.158763  3577 net.cpp:137] Memory required for data: 892819600
I0927 19:02:46.158767  3577 layer_factory.hpp:77] Creating layer Eltwise26
I0927 19:02:46.158771  3577 net.cpp:84] Creating Layer Eltwise26
I0927 19:02:46.158774  3577 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0927 19:02:46.158776  3577 net.cpp:406] Eltwise26 <- Convolution55
I0927 19:02:46.158780  3577 net.cpp:380] Eltwise26 -> Eltwise26
I0927 19:02:46.158798  3577 net.cpp:122] Setting up Eltwise26
I0927 19:02:46.158802  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.158804  3577 net.cpp:137] Memory required for data: 894074000
I0927 19:02:46.158807  3577 layer_factory.hpp:77] Creating layer M2PELU53
I0927 19:02:46.158810  3577 net.cpp:84] Creating Layer M2PELU53
I0927 19:02:46.158813  3577 net.cpp:406] M2PELU53 <- Eltwise26
I0927 19:02:46.158816  3577 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0927 19:02:46.158910  3577 net.cpp:122] Setting up M2PELU53
I0927 19:02:46.158915  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.158916  3577 net.cpp:137] Memory required for data: 895328400
I0927 19:02:46.158921  3577 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0927 19:02:46.158924  3577 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0927 19:02:46.158926  3577 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0927 19:02:46.158929  3577 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0927 19:02:46.158933  3577 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0927 19:02:46.158959  3577 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0927 19:02:46.158963  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.158965  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.158967  3577 net.cpp:137] Memory required for data: 897837200
I0927 19:02:46.158975  3577 layer_factory.hpp:77] Creating layer Convolution56
I0927 19:02:46.158982  3577 net.cpp:84] Creating Layer Convolution56
I0927 19:02:46.158984  3577 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0927 19:02:46.158990  3577 net.cpp:380] Convolution56 -> Convolution56
I0927 19:02:46.160660  3577 net.cpp:122] Setting up Convolution56
I0927 19:02:46.160668  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.160670  3577 net.cpp:137] Memory required for data: 899091600
I0927 19:02:46.160676  3577 layer_factory.hpp:77] Creating layer BatchNorm56
I0927 19:02:46.160681  3577 net.cpp:84] Creating Layer BatchNorm56
I0927 19:02:46.160682  3577 net.cpp:406] BatchNorm56 <- Convolution56
I0927 19:02:46.160686  3577 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0927 19:02:46.176339  3577 net.cpp:122] Setting up BatchNorm56
I0927 19:02:46.176349  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.176352  3577 net.cpp:137] Memory required for data: 900346000
I0927 19:02:46.176357  3577 layer_factory.hpp:77] Creating layer Scale56
I0927 19:02:46.176363  3577 net.cpp:84] Creating Layer Scale56
I0927 19:02:46.176367  3577 net.cpp:406] Scale56 <- Convolution56
I0927 19:02:46.176369  3577 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0927 19:02:46.176405  3577 layer_factory.hpp:77] Creating layer Scale56
I0927 19:02:46.176501  3577 net.cpp:122] Setting up Scale56
I0927 19:02:46.176506  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.176509  3577 net.cpp:137] Memory required for data: 901600400
I0927 19:02:46.176513  3577 layer_factory.hpp:77] Creating layer M2PELU54
I0927 19:02:46.176518  3577 net.cpp:84] Creating Layer M2PELU54
I0927 19:02:46.176520  3577 net.cpp:406] M2PELU54 <- Convolution56
I0927 19:02:46.176525  3577 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0927 19:02:46.176630  3577 net.cpp:122] Setting up M2PELU54
I0927 19:02:46.176635  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.176637  3577 net.cpp:137] Memory required for data: 902854800
I0927 19:02:46.176641  3577 layer_factory.hpp:77] Creating layer Convolution57
I0927 19:02:46.176651  3577 net.cpp:84] Creating Layer Convolution57
I0927 19:02:46.176652  3577 net.cpp:406] Convolution57 <- Convolution56
I0927 19:02:46.176657  3577 net.cpp:380] Convolution57 -> Convolution57
I0927 19:02:46.178433  3577 net.cpp:122] Setting up Convolution57
I0927 19:02:46.178442  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.178455  3577 net.cpp:137] Memory required for data: 904109200
I0927 19:02:46.178459  3577 layer_factory.hpp:77] Creating layer BatchNorm57
I0927 19:02:46.178465  3577 net.cpp:84] Creating Layer BatchNorm57
I0927 19:02:46.178467  3577 net.cpp:406] BatchNorm57 <- Convolution57
I0927 19:02:46.178472  3577 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0927 19:02:46.178731  3577 net.cpp:122] Setting up BatchNorm57
I0927 19:02:46.178740  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.178745  3577 net.cpp:137] Memory required for data: 905363600
I0927 19:02:46.178751  3577 layer_factory.hpp:77] Creating layer Scale57
I0927 19:02:46.178757  3577 net.cpp:84] Creating Layer Scale57
I0927 19:02:46.178761  3577 net.cpp:406] Scale57 <- Convolution57
I0927 19:02:46.178763  3577 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0927 19:02:46.178795  3577 layer_factory.hpp:77] Creating layer Scale57
I0927 19:02:46.178886  3577 net.cpp:122] Setting up Scale57
I0927 19:02:46.178891  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.178894  3577 net.cpp:137] Memory required for data: 906618000
I0927 19:02:46.178897  3577 layer_factory.hpp:77] Creating layer Eltwise27
I0927 19:02:46.178902  3577 net.cpp:84] Creating Layer Eltwise27
I0927 19:02:46.178905  3577 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0927 19:02:46.178908  3577 net.cpp:406] Eltwise27 <- Convolution57
I0927 19:02:46.178912  3577 net.cpp:380] Eltwise27 -> Eltwise27
I0927 19:02:46.178930  3577 net.cpp:122] Setting up Eltwise27
I0927 19:02:46.178941  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.178942  3577 net.cpp:137] Memory required for data: 907872400
I0927 19:02:46.178944  3577 layer_factory.hpp:77] Creating layer M2PELU55
I0927 19:02:46.178951  3577 net.cpp:84] Creating Layer M2PELU55
I0927 19:02:46.178952  3577 net.cpp:406] M2PELU55 <- Eltwise27
I0927 19:02:46.178956  3577 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0927 19:02:46.179054  3577 net.cpp:122] Setting up M2PELU55
I0927 19:02:46.179059  3577 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 19:02:46.179059  3577 net.cpp:137] Memory required for data: 909126800
I0927 19:02:46.179064  3577 layer_factory.hpp:77] Creating layer Pooling1
I0927 19:02:46.179069  3577 net.cpp:84] Creating Layer Pooling1
I0927 19:02:46.179071  3577 net.cpp:406] Pooling1 <- Eltwise27
I0927 19:02:46.179075  3577 net.cpp:380] Pooling1 -> Pooling1
I0927 19:02:46.179567  3577 net.cpp:122] Setting up Pooling1
I0927 19:02:46.179576  3577 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0927 19:02:46.179579  3577 net.cpp:137] Memory required for data: 909152400
I0927 19:02:46.179582  3577 layer_factory.hpp:77] Creating layer InnerProduct1
I0927 19:02:46.179591  3577 net.cpp:84] Creating Layer InnerProduct1
I0927 19:02:46.179594  3577 net.cpp:406] InnerProduct1 <- Pooling1
I0927 19:02:46.179600  3577 net.cpp:380] InnerProduct1 -> InnerProduct1
I0927 19:02:46.179746  3577 net.cpp:122] Setting up InnerProduct1
I0927 19:02:46.179752  3577 net.cpp:129] Top shape: 100 10 (1000)
I0927 19:02:46.179755  3577 net.cpp:137] Memory required for data: 909156400
I0927 19:02:46.179759  3577 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 19:02:46.179764  3577 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0927 19:02:46.179767  3577 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0927 19:02:46.179771  3577 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0927 19:02:46.179775  3577 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0927 19:02:46.179781  3577 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 19:02:46.179999  3577 net.cpp:122] Setting up SoftmaxWithLoss1
I0927 19:02:46.180006  3577 net.cpp:129] Top shape: (1)
I0927 19:02:46.180007  3577 net.cpp:132]     with loss weight 1
I0927 19:02:46.180022  3577 net.cpp:137] Memory required for data: 909156404
I0927 19:02:46.180023  3577 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0927 19:02:46.180027  3577 net.cpp:198] InnerProduct1 needs backward computation.
I0927 19:02:46.180028  3577 net.cpp:198] Pooling1 needs backward computation.
I0927 19:02:46.180032  3577 net.cpp:198] M2PELU55 needs backward computation.
I0927 19:02:46.180033  3577 net.cpp:198] Eltwise27 needs backward computation.
I0927 19:02:46.180035  3577 net.cpp:198] Scale57 needs backward computation.
I0927 19:02:46.180037  3577 net.cpp:198] BatchNorm57 needs backward computation.
I0927 19:02:46.180039  3577 net.cpp:198] Convolution57 needs backward computation.
I0927 19:02:46.180042  3577 net.cpp:198] M2PELU54 needs backward computation.
I0927 19:02:46.180043  3577 net.cpp:198] Scale56 needs backward computation.
I0927 19:02:46.180045  3577 net.cpp:198] BatchNorm56 needs backward computation.
I0927 19:02:46.180047  3577 net.cpp:198] Convolution56 needs backward computation.
I0927 19:02:46.180050  3577 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0927 19:02:46.180052  3577 net.cpp:198] M2PELU53 needs backward computation.
I0927 19:02:46.180054  3577 net.cpp:198] Eltwise26 needs backward computation.
I0927 19:02:46.180058  3577 net.cpp:198] Scale55 needs backward computation.
I0927 19:02:46.180059  3577 net.cpp:198] BatchNorm55 needs backward computation.
I0927 19:02:46.180061  3577 net.cpp:198] Convolution55 needs backward computation.
I0927 19:02:46.180063  3577 net.cpp:198] M2PELU52 needs backward computation.
I0927 19:02:46.180065  3577 net.cpp:198] Scale54 needs backward computation.
I0927 19:02:46.180068  3577 net.cpp:198] BatchNorm54 needs backward computation.
I0927 19:02:46.180069  3577 net.cpp:198] Convolution54 needs backward computation.
I0927 19:02:46.180078  3577 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0927 19:02:46.180080  3577 net.cpp:198] M2PELU51 needs backward computation.
I0927 19:02:46.180083  3577 net.cpp:198] Eltwise25 needs backward computation.
I0927 19:02:46.180085  3577 net.cpp:198] Scale53 needs backward computation.
I0927 19:02:46.180088  3577 net.cpp:198] BatchNorm53 needs backward computation.
I0927 19:02:46.180090  3577 net.cpp:198] Convolution53 needs backward computation.
I0927 19:02:46.180093  3577 net.cpp:198] M2PELU50 needs backward computation.
I0927 19:02:46.180094  3577 net.cpp:198] Scale52 needs backward computation.
I0927 19:02:46.180096  3577 net.cpp:198] BatchNorm52 needs backward computation.
I0927 19:02:46.180099  3577 net.cpp:198] Convolution52 needs backward computation.
I0927 19:02:46.180101  3577 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0927 19:02:46.180104  3577 net.cpp:198] M2PELU49 needs backward computation.
I0927 19:02:46.180106  3577 net.cpp:198] Eltwise24 needs backward computation.
I0927 19:02:46.180109  3577 net.cpp:198] Scale51 needs backward computation.
I0927 19:02:46.180111  3577 net.cpp:198] BatchNorm51 needs backward computation.
I0927 19:02:46.180114  3577 net.cpp:198] Convolution51 needs backward computation.
I0927 19:02:46.180115  3577 net.cpp:198] M2PELU48 needs backward computation.
I0927 19:02:46.180119  3577 net.cpp:198] Scale50 needs backward computation.
I0927 19:02:46.180120  3577 net.cpp:198] BatchNorm50 needs backward computation.
I0927 19:02:46.180122  3577 net.cpp:198] Convolution50 needs backward computation.
I0927 19:02:46.180125  3577 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0927 19:02:46.180127  3577 net.cpp:198] M2PELU47 needs backward computation.
I0927 19:02:46.180130  3577 net.cpp:198] Eltwise23 needs backward computation.
I0927 19:02:46.180132  3577 net.cpp:198] Scale49 needs backward computation.
I0927 19:02:46.180135  3577 net.cpp:198] BatchNorm49 needs backward computation.
I0927 19:02:46.180137  3577 net.cpp:198] Convolution49 needs backward computation.
I0927 19:02:46.180140  3577 net.cpp:198] M2PELU46 needs backward computation.
I0927 19:02:46.180141  3577 net.cpp:198] Scale48 needs backward computation.
I0927 19:02:46.180143  3577 net.cpp:198] BatchNorm48 needs backward computation.
I0927 19:02:46.180146  3577 net.cpp:198] Convolution48 needs backward computation.
I0927 19:02:46.180148  3577 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0927 19:02:46.180151  3577 net.cpp:198] M2PELU45 needs backward computation.
I0927 19:02:46.180153  3577 net.cpp:198] Eltwise22 needs backward computation.
I0927 19:02:46.180155  3577 net.cpp:198] Scale47 needs backward computation.
I0927 19:02:46.180158  3577 net.cpp:198] BatchNorm47 needs backward computation.
I0927 19:02:46.180160  3577 net.cpp:198] Convolution47 needs backward computation.
I0927 19:02:46.180162  3577 net.cpp:198] M2PELU44 needs backward computation.
I0927 19:02:46.180164  3577 net.cpp:198] Scale46 needs backward computation.
I0927 19:02:46.180167  3577 net.cpp:198] BatchNorm46 needs backward computation.
I0927 19:02:46.180169  3577 net.cpp:198] Convolution46 needs backward computation.
I0927 19:02:46.180171  3577 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0927 19:02:46.180174  3577 net.cpp:198] M2PELU43 needs backward computation.
I0927 19:02:46.180176  3577 net.cpp:198] Eltwise21 needs backward computation.
I0927 19:02:46.180179  3577 net.cpp:198] Scale45 needs backward computation.
I0927 19:02:46.180182  3577 net.cpp:198] BatchNorm45 needs backward computation.
I0927 19:02:46.180184  3577 net.cpp:198] Convolution45 needs backward computation.
I0927 19:02:46.180186  3577 net.cpp:198] M2PELU42 needs backward computation.
I0927 19:02:46.180189  3577 net.cpp:198] Scale44 needs backward computation.
I0927 19:02:46.180191  3577 net.cpp:198] BatchNorm44 needs backward computation.
I0927 19:02:46.180193  3577 net.cpp:198] Convolution44 needs backward computation.
I0927 19:02:46.180196  3577 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0927 19:02:46.180202  3577 net.cpp:198] M2PELU41 needs backward computation.
I0927 19:02:46.180204  3577 net.cpp:198] Eltwise20 needs backward computation.
I0927 19:02:46.180207  3577 net.cpp:198] Scale43 needs backward computation.
I0927 19:02:46.180209  3577 net.cpp:198] BatchNorm43 needs backward computation.
I0927 19:02:46.180212  3577 net.cpp:198] Convolution43 needs backward computation.
I0927 19:02:46.180223  3577 net.cpp:198] M2PELU40 needs backward computation.
I0927 19:02:46.180225  3577 net.cpp:198] Scale42 needs backward computation.
I0927 19:02:46.180227  3577 net.cpp:198] BatchNorm42 needs backward computation.
I0927 19:02:46.180229  3577 net.cpp:198] Convolution42 needs backward computation.
I0927 19:02:46.180233  3577 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0927 19:02:46.180234  3577 net.cpp:198] M2PELU39 needs backward computation.
I0927 19:02:46.180238  3577 net.cpp:198] Eltwise19 needs backward computation.
I0927 19:02:46.180240  3577 net.cpp:198] Scale41 needs backward computation.
I0927 19:02:46.180243  3577 net.cpp:198] BatchNorm41 needs backward computation.
I0927 19:02:46.180244  3577 net.cpp:198] Convolution41 needs backward computation.
I0927 19:02:46.180248  3577 net.cpp:198] M2PELU38 needs backward computation.
I0927 19:02:46.180249  3577 net.cpp:198] Scale40 needs backward computation.
I0927 19:02:46.180251  3577 net.cpp:198] BatchNorm40 needs backward computation.
I0927 19:02:46.180253  3577 net.cpp:198] Convolution40 needs backward computation.
I0927 19:02:46.180256  3577 net.cpp:198] Scale39 needs backward computation.
I0927 19:02:46.180258  3577 net.cpp:198] BatchNorm39 needs backward computation.
I0927 19:02:46.180260  3577 net.cpp:198] Convolution39 needs backward computation.
I0927 19:02:46.180263  3577 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0927 19:02:46.180265  3577 net.cpp:198] M2PELU37 needs backward computation.
I0927 19:02:46.180269  3577 net.cpp:198] Eltwise18 needs backward computation.
I0927 19:02:46.180272  3577 net.cpp:198] Scale38 needs backward computation.
I0927 19:02:46.180276  3577 net.cpp:198] BatchNorm38 needs backward computation.
I0927 19:02:46.180289  3577 net.cpp:198] Convolution38 needs backward computation.
I0927 19:02:46.180292  3577 net.cpp:198] M2PELU36 needs backward computation.
I0927 19:02:46.180295  3577 net.cpp:198] Scale37 needs backward computation.
I0927 19:02:46.180299  3577 net.cpp:198] BatchNorm37 needs backward computation.
I0927 19:02:46.180302  3577 net.cpp:198] Convolution37 needs backward computation.
I0927 19:02:46.180306  3577 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0927 19:02:46.180310  3577 net.cpp:198] M2PELU35 needs backward computation.
I0927 19:02:46.180312  3577 net.cpp:198] Eltwise17 needs backward computation.
I0927 19:02:46.180315  3577 net.cpp:198] Scale36 needs backward computation.
I0927 19:02:46.180317  3577 net.cpp:198] BatchNorm36 needs backward computation.
I0927 19:02:46.180320  3577 net.cpp:198] Convolution36 needs backward computation.
I0927 19:02:46.180321  3577 net.cpp:198] M2PELU34 needs backward computation.
I0927 19:02:46.180323  3577 net.cpp:198] Scale35 needs backward computation.
I0927 19:02:46.180325  3577 net.cpp:198] BatchNorm35 needs backward computation.
I0927 19:02:46.180327  3577 net.cpp:198] Convolution35 needs backward computation.
I0927 19:02:46.180330  3577 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0927 19:02:46.180332  3577 net.cpp:198] M2PELU33 needs backward computation.
I0927 19:02:46.180335  3577 net.cpp:198] Eltwise16 needs backward computation.
I0927 19:02:46.180336  3577 net.cpp:198] Scale34 needs backward computation.
I0927 19:02:46.180338  3577 net.cpp:198] BatchNorm34 needs backward computation.
I0927 19:02:46.180341  3577 net.cpp:198] Convolution34 needs backward computation.
I0927 19:02:46.180343  3577 net.cpp:198] M2PELU32 needs backward computation.
I0927 19:02:46.180346  3577 net.cpp:198] Scale33 needs backward computation.
I0927 19:02:46.180351  3577 net.cpp:198] BatchNorm33 needs backward computation.
I0927 19:02:46.180353  3577 net.cpp:198] Convolution33 needs backward computation.
I0927 19:02:46.180356  3577 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0927 19:02:46.180358  3577 net.cpp:198] M2PELU31 needs backward computation.
I0927 19:02:46.180361  3577 net.cpp:198] Eltwise15 needs backward computation.
I0927 19:02:46.180363  3577 net.cpp:198] Scale32 needs backward computation.
I0927 19:02:46.180366  3577 net.cpp:198] BatchNorm32 needs backward computation.
I0927 19:02:46.180367  3577 net.cpp:198] Convolution32 needs backward computation.
I0927 19:02:46.206790  3577 net.cpp:198] M2PELU30 needs backward computation.
I0927 19:02:46.206800  3577 net.cpp:198] Scale31 needs backward computation.
I0927 19:02:46.206804  3577 net.cpp:198] BatchNorm31 needs backward computation.
I0927 19:02:46.206809  3577 net.cpp:198] Convolution31 needs backward computation.
I0927 19:02:46.206814  3577 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0927 19:02:46.206820  3577 net.cpp:198] M2PELU29 needs backward computation.
I0927 19:02:46.206825  3577 net.cpp:198] Eltwise14 needs backward computation.
I0927 19:02:46.206830  3577 net.cpp:198] Scale30 needs backward computation.
I0927 19:02:46.206833  3577 net.cpp:198] BatchNorm30 needs backward computation.
I0927 19:02:46.206836  3577 net.cpp:198] Convolution30 needs backward computation.
I0927 19:02:46.206841  3577 net.cpp:198] M2PELU28 needs backward computation.
I0927 19:02:46.206845  3577 net.cpp:198] Scale29 needs backward computation.
I0927 19:02:46.206848  3577 net.cpp:198] BatchNorm29 needs backward computation.
I0927 19:02:46.206852  3577 net.cpp:198] Convolution29 needs backward computation.
I0927 19:02:46.206857  3577 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0927 19:02:46.206861  3577 net.cpp:198] M2PELU27 needs backward computation.
I0927 19:02:46.206866  3577 net.cpp:198] Eltwise13 needs backward computation.
I0927 19:02:46.206869  3577 net.cpp:198] Scale28 needs backward computation.
I0927 19:02:46.206873  3577 net.cpp:198] BatchNorm28 needs backward computation.
I0927 19:02:46.206877  3577 net.cpp:198] Convolution28 needs backward computation.
I0927 19:02:46.206881  3577 net.cpp:198] M2PELU26 needs backward computation.
I0927 19:02:46.206885  3577 net.cpp:198] Scale27 needs backward computation.
I0927 19:02:46.206889  3577 net.cpp:198] BatchNorm27 needs backward computation.
I0927 19:02:46.206892  3577 net.cpp:198] Convolution27 needs backward computation.
I0927 19:02:46.206895  3577 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0927 19:02:46.206898  3577 net.cpp:198] M2PELU25 needs backward computation.
I0927 19:02:46.206900  3577 net.cpp:198] Eltwise12 needs backward computation.
I0927 19:02:46.206903  3577 net.cpp:198] Scale26 needs backward computation.
I0927 19:02:46.206905  3577 net.cpp:198] BatchNorm26 needs backward computation.
I0927 19:02:46.206908  3577 net.cpp:198] Convolution26 needs backward computation.
I0927 19:02:46.206910  3577 net.cpp:198] M2PELU24 needs backward computation.
I0927 19:02:46.206913  3577 net.cpp:198] Scale25 needs backward computation.
I0927 19:02:46.206915  3577 net.cpp:198] BatchNorm25 needs backward computation.
I0927 19:02:46.206918  3577 net.cpp:198] Convolution25 needs backward computation.
I0927 19:02:46.206920  3577 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0927 19:02:46.206923  3577 net.cpp:198] M2PELU23 needs backward computation.
I0927 19:02:46.206925  3577 net.cpp:198] Eltwise11 needs backward computation.
I0927 19:02:46.206928  3577 net.cpp:198] Scale24 needs backward computation.
I0927 19:02:46.206930  3577 net.cpp:198] BatchNorm24 needs backward computation.
I0927 19:02:46.206933  3577 net.cpp:198] Convolution24 needs backward computation.
I0927 19:02:46.206935  3577 net.cpp:198] M2PELU22 needs backward computation.
I0927 19:02:46.206938  3577 net.cpp:198] Scale23 needs backward computation.
I0927 19:02:46.206946  3577 net.cpp:198] BatchNorm23 needs backward computation.
I0927 19:02:46.206949  3577 net.cpp:198] Convolution23 needs backward computation.
I0927 19:02:46.206953  3577 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0927 19:02:46.206954  3577 net.cpp:198] M2PELU21 needs backward computation.
I0927 19:02:46.206957  3577 net.cpp:198] Eltwise10 needs backward computation.
I0927 19:02:46.206960  3577 net.cpp:198] Scale22 needs backward computation.
I0927 19:02:46.206962  3577 net.cpp:198] BatchNorm22 needs backward computation.
I0927 19:02:46.206964  3577 net.cpp:198] Convolution22 needs backward computation.
I0927 19:02:46.206967  3577 net.cpp:198] M2PELU20 needs backward computation.
I0927 19:02:46.206970  3577 net.cpp:198] Scale21 needs backward computation.
I0927 19:02:46.206972  3577 net.cpp:198] BatchNorm21 needs backward computation.
I0927 19:02:46.206974  3577 net.cpp:198] Convolution21 needs backward computation.
I0927 19:02:46.206977  3577 net.cpp:198] Scale20 needs backward computation.
I0927 19:02:46.206980  3577 net.cpp:198] BatchNorm20 needs backward computation.
I0927 19:02:46.206982  3577 net.cpp:198] Convolution20 needs backward computation.
I0927 19:02:46.206985  3577 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0927 19:02:46.206987  3577 net.cpp:198] M2PELU19 needs backward computation.
I0927 19:02:46.206990  3577 net.cpp:198] Eltwise9 needs backward computation.
I0927 19:02:46.206993  3577 net.cpp:198] Scale19 needs backward computation.
I0927 19:02:46.206995  3577 net.cpp:198] BatchNorm19 needs backward computation.
I0927 19:02:46.206998  3577 net.cpp:198] Convolution19 needs backward computation.
I0927 19:02:46.207000  3577 net.cpp:198] M2PELU18 needs backward computation.
I0927 19:02:46.207003  3577 net.cpp:198] Scale18 needs backward computation.
I0927 19:02:46.207005  3577 net.cpp:198] BatchNorm18 needs backward computation.
I0927 19:02:46.207007  3577 net.cpp:198] Convolution18 needs backward computation.
I0927 19:02:46.207010  3577 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0927 19:02:46.207013  3577 net.cpp:198] M2PELU17 needs backward computation.
I0927 19:02:46.207015  3577 net.cpp:198] Eltwise8 needs backward computation.
I0927 19:02:46.207018  3577 net.cpp:198] Scale17 needs backward computation.
I0927 19:02:46.207021  3577 net.cpp:198] BatchNorm17 needs backward computation.
I0927 19:02:46.207024  3577 net.cpp:198] Convolution17 needs backward computation.
I0927 19:02:46.207026  3577 net.cpp:198] M2PELU16 needs backward computation.
I0927 19:02:46.207029  3577 net.cpp:198] Scale16 needs backward computation.
I0927 19:02:46.207031  3577 net.cpp:198] BatchNorm16 needs backward computation.
I0927 19:02:46.207034  3577 net.cpp:198] Convolution16 needs backward computation.
I0927 19:02:46.207036  3577 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0927 19:02:46.207039  3577 net.cpp:198] M2PELU15 needs backward computation.
I0927 19:02:46.207041  3577 net.cpp:198] Eltwise7 needs backward computation.
I0927 19:02:46.207044  3577 net.cpp:198] Scale15 needs backward computation.
I0927 19:02:46.207047  3577 net.cpp:198] BatchNorm15 needs backward computation.
I0927 19:02:46.207049  3577 net.cpp:198] Convolution15 needs backward computation.
I0927 19:02:46.207052  3577 net.cpp:198] M2PELU14 needs backward computation.
I0927 19:02:46.207054  3577 net.cpp:198] Scale14 needs backward computation.
I0927 19:02:46.207056  3577 net.cpp:198] BatchNorm14 needs backward computation.
I0927 19:02:46.207059  3577 net.cpp:198] Convolution14 needs backward computation.
I0927 19:02:46.207062  3577 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0927 19:02:46.207064  3577 net.cpp:198] M2PELU13 needs backward computation.
I0927 19:02:46.207067  3577 net.cpp:198] Eltwise6 needs backward computation.
I0927 19:02:46.207069  3577 net.cpp:198] Scale13 needs backward computation.
I0927 19:02:46.207072  3577 net.cpp:198] BatchNorm13 needs backward computation.
I0927 19:02:46.207074  3577 net.cpp:198] Convolution13 needs backward computation.
I0927 19:02:46.207082  3577 net.cpp:198] M2PELU12 needs backward computation.
I0927 19:02:46.207083  3577 net.cpp:198] Scale12 needs backward computation.
I0927 19:02:46.207087  3577 net.cpp:198] BatchNorm12 needs backward computation.
I0927 19:02:46.207088  3577 net.cpp:198] Convolution12 needs backward computation.
I0927 19:02:46.207092  3577 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0927 19:02:46.207093  3577 net.cpp:198] M2PELU11 needs backward computation.
I0927 19:02:46.207096  3577 net.cpp:198] Eltwise5 needs backward computation.
I0927 19:02:46.209113  3577 net.cpp:198] Scale11 needs backward computation.
I0927 19:02:46.209122  3577 net.cpp:198] BatchNorm11 needs backward computation.
I0927 19:02:46.209126  3577 net.cpp:198] Convolution11 needs backward computation.
I0927 19:02:46.209131  3577 net.cpp:198] M2PELU10 needs backward computation.
I0927 19:02:46.209134  3577 net.cpp:198] Scale10 needs backward computation.
I0927 19:02:46.209137  3577 net.cpp:198] BatchNorm10 needs backward computation.
I0927 19:02:46.209141  3577 net.cpp:198] Convolution10 needs backward computation.
I0927 19:02:46.209148  3577 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0927 19:02:46.209154  3577 net.cpp:198] M2PELU9 needs backward computation.
I0927 19:02:46.209158  3577 net.cpp:198] Eltwise4 needs backward computation.
I0927 19:02:46.209163  3577 net.cpp:198] Scale9 needs backward computation.
I0927 19:02:46.209167  3577 net.cpp:198] BatchNorm9 needs backward computation.
I0927 19:02:46.209172  3577 net.cpp:198] Convolution9 needs backward computation.
I0927 19:02:46.209174  3577 net.cpp:198] M2PELU8 needs backward computation.
I0927 19:02:46.209178  3577 net.cpp:198] Scale8 needs backward computation.
I0927 19:02:46.209182  3577 net.cpp:198] BatchNorm8 needs backward computation.
I0927 19:02:46.209185  3577 net.cpp:198] Convolution8 needs backward computation.
I0927 19:02:46.209190  3577 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0927 19:02:46.209194  3577 net.cpp:198] M2PELU7 needs backward computation.
I0927 19:02:46.209197  3577 net.cpp:198] Eltwise3 needs backward computation.
I0927 19:02:46.209203  3577 net.cpp:198] Scale7 needs backward computation.
I0927 19:02:46.209205  3577 net.cpp:198] BatchNorm7 needs backward computation.
I0927 19:02:46.209209  3577 net.cpp:198] Convolution7 needs backward computation.
I0927 19:02:46.209213  3577 net.cpp:198] M2PELU6 needs backward computation.
I0927 19:02:46.209214  3577 net.cpp:198] Scale6 needs backward computation.
I0927 19:02:46.209218  3577 net.cpp:198] BatchNorm6 needs backward computation.
I0927 19:02:46.209219  3577 net.cpp:198] Convolution6 needs backward computation.
I0927 19:02:46.209221  3577 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0927 19:02:46.209224  3577 net.cpp:198] M2PELU5 needs backward computation.
I0927 19:02:46.209226  3577 net.cpp:198] Eltwise2 needs backward computation.
I0927 19:02:46.209229  3577 net.cpp:198] Scale5 needs backward computation.
I0927 19:02:46.209233  3577 net.cpp:198] BatchNorm5 needs backward computation.
I0927 19:02:46.209234  3577 net.cpp:198] Convolution5 needs backward computation.
I0927 19:02:46.209236  3577 net.cpp:198] M2PELU4 needs backward computation.
I0927 19:02:46.209239  3577 net.cpp:198] Scale4 needs backward computation.
I0927 19:02:46.209241  3577 net.cpp:198] BatchNorm4 needs backward computation.
I0927 19:02:46.209244  3577 net.cpp:198] Convolution4 needs backward computation.
I0927 19:02:46.209245  3577 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0927 19:02:46.209249  3577 net.cpp:198] M2PELU3 needs backward computation.
I0927 19:02:46.209250  3577 net.cpp:198] Eltwise1 needs backward computation.
I0927 19:02:46.209254  3577 net.cpp:198] Scale3 needs backward computation.
I0927 19:02:46.209255  3577 net.cpp:198] BatchNorm3 needs backward computation.
I0927 19:02:46.209259  3577 net.cpp:198] Convolution3 needs backward computation.
I0927 19:02:46.209260  3577 net.cpp:198] M2PELU2 needs backward computation.
I0927 19:02:46.209269  3577 net.cpp:198] Scale2 needs backward computation.
I0927 19:02:46.209270  3577 net.cpp:198] BatchNorm2 needs backward computation.
I0927 19:02:46.209273  3577 net.cpp:198] Convolution2 needs backward computation.
I0927 19:02:46.209275  3577 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0927 19:02:46.209278  3577 net.cpp:198] M2PELU1 needs backward computation.
I0927 19:02:46.209280  3577 net.cpp:198] Scale1 needs backward computation.
I0927 19:02:46.209283  3577 net.cpp:198] BatchNorm1 needs backward computation.
I0927 19:02:46.209285  3577 net.cpp:198] Convolution1 needs backward computation.
I0927 19:02:46.209288  3577 net.cpp:200] Data1 does not need backward computation.
I0927 19:02:46.209290  3577 net.cpp:242] This network produces output SoftmaxWithLoss1
I0927 19:02:46.209379  3577 net.cpp:255] Network initialization done.
I0927 19:02:46.213773  3577 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 19:02:46.213786  3577 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0927 19:02:46.213791  3577 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_mpelu_train_test.prototxt
I0927 19:02:46.213984  3577 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0927 19:02:46.215179  3577 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      t
I0927 19:02:46.270596  3577 layer_factory.hpp:77] Creating layer Data1
I0927 19:02:46.270643  3577 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0927 19:02:46.270654  3577 net.cpp:84] Creating Layer Data1
I0927 19:02:46.270659  3577 net.cpp:380] Data1 -> Data1
I0927 19:02:46.270668  3577 net.cpp:380] Data1 -> Data2
I0927 19:02:46.270673  3577 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0927 19:02:46.270843  3577 data_layer.cpp:45] output data size: 100,3,32,32
I0927 19:02:46.275001  3577 net.cpp:122] Setting up Data1
I0927 19:02:46.275022  3577 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0927 19:02:46.275027  3577 net.cpp:129] Top shape: 100 (100)
I0927 19:02:46.275028  3577 net.cpp:137] Memory required for data: 1229200
I0927 19:02:46.275033  3577 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0927 19:02:46.275043  3577 net.cpp:84] Creating Layer Data2_Data1_1_split
I0927 19:02:46.275045  3577 net.cpp:406] Data2_Data1_1_split <- Data2
I0927 19:02:46.275050  3577 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0927 19:02:46.275058  3577 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0927 19:02:46.275143  3577 net.cpp:122] Setting up Data2_Data1_1_split
I0927 19:02:46.275149  3577 net.cpp:129] Top shape: 100 (100)
I0927 19:02:46.275152  3577 net.cpp:129] Top shape: 100 (100)
I0927 19:02:46.275154  3577 net.cpp:137] Memory required for data: 1230000
I0927 19:02:46.275156  3577 layer_factory.hpp:77] Creating layer Convolution1
I0927 19:02:46.275167  3577 net.cpp:84] Creating Layer Convolution1
I0927 19:02:46.275169  3577 net.cpp:406] Convolution1 <- Data1
I0927 19:02:46.275174  3577 net.cpp:380] Convolution1 -> Convolution1
I0927 19:02:46.276448  3577 net.cpp:122] Setting up Convolution1
I0927 19:02:46.276459  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.276461  3577 net.cpp:137] Memory required for data: 7783600
I0927 19:02:46.276470  3577 layer_factory.hpp:77] Creating layer BatchNorm1
I0927 19:02:46.276476  3577 net.cpp:84] Creating Layer BatchNorm1
I0927 19:02:46.276479  3577 net.cpp:406] BatchNorm1 <- Convolution1
I0927 19:02:46.276484  3577 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0927 19:02:46.276643  3577 net.cpp:122] Setting up BatchNorm1
I0927 19:02:46.276648  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.276651  3577 net.cpp:137] Memory required for data: 14337200
I0927 19:02:46.276662  3577 layer_factory.hpp:77] Creating layer Scale1
I0927 19:02:46.276670  3577 net.cpp:84] Creating Layer Scale1
I0927 19:02:46.276674  3577 net.cpp:406] Scale1 <- Convolution1
I0927 19:02:46.276676  3577 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0927 19:02:46.276711  3577 layer_factory.hpp:77] Creating layer Scale1
I0927 19:02:46.276801  3577 net.cpp:122] Setting up Scale1
I0927 19:02:46.276808  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.276810  3577 net.cpp:137] Memory required for data: 20890800
I0927 19:02:46.276814  3577 layer_factory.hpp:77] Creating layer M2PELU1
I0927 19:02:46.276821  3577 net.cpp:84] Creating Layer M2PELU1
I0927 19:02:46.276823  3577 net.cpp:406] M2PELU1 <- Convolution1
I0927 19:02:46.276828  3577 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0927 19:02:46.277456  3577 net.cpp:122] Setting up M2PELU1
I0927 19:02:46.277464  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.277467  3577 net.cpp:137] Memory required for data: 27444400
I0927 19:02:46.277474  3577 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0927 19:02:46.277480  3577 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0927 19:02:46.277483  3577 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0927 19:02:46.277487  3577 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0927 19:02:46.277493  3577 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0927 19:02:46.277523  3577 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0927 19:02:46.298079  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.298089  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.298094  3577 net.cpp:137] Memory required for data: 40551600
I0927 19:02:46.298099  3577 layer_factory.hpp:77] Creating layer Convolution2
I0927 19:02:46.298110  3577 net.cpp:84] Creating Layer Convolution2
I0927 19:02:46.298115  3577 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0927 19:02:46.298123  3577 net.cpp:380] Convolution2 -> Convolution2
I0927 19:02:46.299306  3577 net.cpp:122] Setting up Convolution2
I0927 19:02:46.299315  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.299319  3577 net.cpp:137] Memory required for data: 47105200
I0927 19:02:46.299324  3577 layer_factory.hpp:77] Creating layer BatchNorm2
I0927 19:02:46.299330  3577 net.cpp:84] Creating Layer BatchNorm2
I0927 19:02:46.299334  3577 net.cpp:406] BatchNorm2 <- Convolution2
I0927 19:02:46.299338  3577 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0927 19:02:46.299515  3577 net.cpp:122] Setting up BatchNorm2
I0927 19:02:46.299521  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.299523  3577 net.cpp:137] Memory required for data: 53658800
I0927 19:02:46.299536  3577 layer_factory.hpp:77] Creating layer Scale2
I0927 19:02:46.299542  3577 net.cpp:84] Creating Layer Scale2
I0927 19:02:46.299546  3577 net.cpp:406] Scale2 <- Convolution2
I0927 19:02:46.299549  3577 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0927 19:02:46.299587  3577 layer_factory.hpp:77] Creating layer Scale2
I0927 19:02:46.299728  3577 net.cpp:122] Setting up Scale2
I0927 19:02:46.299738  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.299743  3577 net.cpp:137] Memory required for data: 60212400
I0927 19:02:46.299751  3577 layer_factory.hpp:77] Creating layer M2PELU2
I0927 19:02:46.299760  3577 net.cpp:84] Creating Layer M2PELU2
I0927 19:02:46.299765  3577 net.cpp:406] M2PELU2 <- Convolution2
I0927 19:02:46.299772  3577 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0927 19:02:46.299897  3577 net.cpp:122] Setting up M2PELU2
I0927 19:02:46.299904  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.299906  3577 net.cpp:137] Memory required for data: 66766000
I0927 19:02:46.299914  3577 layer_factory.hpp:77] Creating layer Convolution3
I0927 19:02:46.299922  3577 net.cpp:84] Creating Layer Convolution3
I0927 19:02:46.299926  3577 net.cpp:406] Convolution3 <- Convolution2
I0927 19:02:46.299929  3577 net.cpp:380] Convolution3 -> Convolution3
I0927 19:02:46.301206  3577 net.cpp:122] Setting up Convolution3
I0927 19:02:46.301215  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.301218  3577 net.cpp:137] Memory required for data: 73319600
I0927 19:02:46.301223  3577 layer_factory.hpp:77] Creating layer BatchNorm3
I0927 19:02:46.301229  3577 net.cpp:84] Creating Layer BatchNorm3
I0927 19:02:46.301230  3577 net.cpp:406] BatchNorm3 <- Convolution3
I0927 19:02:46.301234  3577 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0927 19:02:46.301393  3577 net.cpp:122] Setting up BatchNorm3
I0927 19:02:46.301398  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.301400  3577 net.cpp:137] Memory required for data: 79873200
I0927 19:02:46.301405  3577 layer_factory.hpp:77] Creating layer Scale3
I0927 19:02:46.301409  3577 net.cpp:84] Creating Layer Scale3
I0927 19:02:46.301412  3577 net.cpp:406] Scale3 <- Convolution3
I0927 19:02:46.301415  3577 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0927 19:02:46.301446  3577 layer_factory.hpp:77] Creating layer Scale3
I0927 19:02:46.301533  3577 net.cpp:122] Setting up Scale3
I0927 19:02:46.301538  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.301540  3577 net.cpp:137] Memory required for data: 86426800
I0927 19:02:46.301544  3577 layer_factory.hpp:77] Creating layer Eltwise1
I0927 19:02:46.301551  3577 net.cpp:84] Creating Layer Eltwise1
I0927 19:02:46.301554  3577 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0927 19:02:46.301558  3577 net.cpp:406] Eltwise1 <- Convolution3
I0927 19:02:46.301560  3577 net.cpp:380] Eltwise1 -> Eltwise1
I0927 19:02:46.301591  3577 net.cpp:122] Setting up Eltwise1
I0927 19:02:46.301595  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.301597  3577 net.cpp:137] Memory required for data: 92980400
I0927 19:02:46.301599  3577 layer_factory.hpp:77] Creating layer M2PELU3
I0927 19:02:46.301605  3577 net.cpp:84] Creating Layer M2PELU3
I0927 19:02:46.301607  3577 net.cpp:406] M2PELU3 <- Eltwise1
I0927 19:02:46.301620  3577 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0927 19:02:46.301760  3577 net.cpp:122] Setting up M2PELU3
I0927 19:02:46.301766  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.301769  3577 net.cpp:137] Memory required for data: 99534000
I0927 19:02:46.301772  3577 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0927 19:02:46.301777  3577 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0927 19:02:46.301779  3577 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0927 19:02:46.301784  3577 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0927 19:02:46.301789  3577 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0927 19:02:46.301823  3577 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0927 19:02:46.301827  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.301831  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.301832  3577 net.cpp:137] Memory required for data: 112641200
I0927 19:02:46.301834  3577 layer_factory.hpp:77] Creating layer Convolution4
I0927 19:02:46.301842  3577 net.cpp:84] Creating Layer Convolution4
I0927 19:02:46.301844  3577 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0927 19:02:46.301848  3577 net.cpp:380] Convolution4 -> Convolution4
I0927 19:02:46.302906  3577 net.cpp:122] Setting up Convolution4
I0927 19:02:46.302916  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.302917  3577 net.cpp:137] Memory required for data: 119194800
I0927 19:02:46.302922  3577 layer_factory.hpp:77] Creating layer BatchNorm4
I0927 19:02:46.302927  3577 net.cpp:84] Creating Layer BatchNorm4
I0927 19:02:46.302930  3577 net.cpp:406] BatchNorm4 <- Convolution4
I0927 19:02:46.302934  3577 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0927 19:02:46.303093  3577 net.cpp:122] Setting up BatchNorm4
I0927 19:02:46.303098  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.303100  3577 net.cpp:137] Memory required for data: 125748400
I0927 19:02:46.303105  3577 layer_factory.hpp:77] Creating layer Scale4
I0927 19:02:46.303109  3577 net.cpp:84] Creating Layer Scale4
I0927 19:02:46.303112  3577 net.cpp:406] Scale4 <- Convolution4
I0927 19:02:46.303115  3577 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0927 19:02:46.303146  3577 layer_factory.hpp:77] Creating layer Scale4
I0927 19:02:46.303233  3577 net.cpp:122] Setting up Scale4
I0927 19:02:46.303238  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.303241  3577 net.cpp:137] Memory required for data: 132302000
I0927 19:02:46.303247  3577 layer_factory.hpp:77] Creating layer M2PELU4
I0927 19:02:46.303252  3577 net.cpp:84] Creating Layer M2PELU4
I0927 19:02:46.303254  3577 net.cpp:406] M2PELU4 <- Convolution4
I0927 19:02:46.303258  3577 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0927 19:02:46.303362  3577 net.cpp:122] Setting up M2PELU4
I0927 19:02:46.303366  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.303369  3577 net.cpp:137] Memory required for data: 138855600
I0927 19:02:46.303372  3577 layer_factory.hpp:77] Creating layer Convolution5
I0927 19:02:46.303380  3577 net.cpp:84] Creating Layer Convolution5
I0927 19:02:46.303382  3577 net.cpp:406] Convolution5 <- Convolution4
I0927 19:02:46.303386  3577 net.cpp:380] Convolution5 -> Convolution5
I0927 19:02:46.304348  3577 net.cpp:122] Setting up Convolution5
I0927 19:02:46.304356  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.304359  3577 net.cpp:137] Memory required for data: 145409200
I0927 19:02:46.304364  3577 layer_factory.hpp:77] Creating layer BatchNorm5
I0927 19:02:46.304369  3577 net.cpp:84] Creating Layer BatchNorm5
I0927 19:02:46.304373  3577 net.cpp:406] BatchNorm5 <- Convolution5
I0927 19:02:46.304376  3577 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0927 19:02:46.304536  3577 net.cpp:122] Setting up BatchNorm5
I0927 19:02:46.304541  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.304543  3577 net.cpp:137] Memory required for data: 151962800
I0927 19:02:46.304548  3577 layer_factory.hpp:77] Creating layer Scale5
I0927 19:02:46.304553  3577 net.cpp:84] Creating Layer Scale5
I0927 19:02:46.304554  3577 net.cpp:406] Scale5 <- Convolution5
I0927 19:02:46.304558  3577 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0927 19:02:46.304589  3577 layer_factory.hpp:77] Creating layer Scale5
I0927 19:02:46.304675  3577 net.cpp:122] Setting up Scale5
I0927 19:02:46.304680  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.304682  3577 net.cpp:137] Memory required for data: 158516400
I0927 19:02:46.304687  3577 layer_factory.hpp:77] Creating layer Eltwise2
I0927 19:02:46.304692  3577 net.cpp:84] Creating Layer Eltwise2
I0927 19:02:46.304693  3577 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0927 19:02:46.304702  3577 net.cpp:406] Eltwise2 <- Convolution5
I0927 19:02:46.304707  3577 net.cpp:380] Eltwise2 -> Eltwise2
I0927 19:02:46.304726  3577 net.cpp:122] Setting up Eltwise2
I0927 19:02:46.304730  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.304733  3577 net.cpp:137] Memory required for data: 165070000
I0927 19:02:46.304734  3577 layer_factory.hpp:77] Creating layer M2PELU5
I0927 19:02:46.304740  3577 net.cpp:84] Creating Layer M2PELU5
I0927 19:02:46.304742  3577 net.cpp:406] M2PELU5 <- Eltwise2
I0927 19:02:46.304745  3577 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0927 19:02:46.304849  3577 net.cpp:122] Setting up M2PELU5
I0927 19:02:46.304854  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.304857  3577 net.cpp:137] Memory required for data: 171623600
I0927 19:02:46.304860  3577 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0927 19:02:46.304864  3577 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0927 19:02:46.304867  3577 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0927 19:02:46.304869  3577 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0927 19:02:46.304873  3577 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0927 19:02:46.304903  3577 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0927 19:02:46.304906  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.304909  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.304911  3577 net.cpp:137] Memory required for data: 184730800
I0927 19:02:46.304913  3577 layer_factory.hpp:77] Creating layer Convolution6
I0927 19:02:46.304919  3577 net.cpp:84] Creating Layer Convolution6
I0927 19:02:46.304922  3577 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0927 19:02:46.304925  3577 net.cpp:380] Convolution6 -> Convolution6
I0927 19:02:46.305889  3577 net.cpp:122] Setting up Convolution6
I0927 19:02:46.305897  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.305901  3577 net.cpp:137] Memory required for data: 191284400
I0927 19:02:46.305904  3577 layer_factory.hpp:77] Creating layer BatchNorm6
I0927 19:02:46.305909  3577 net.cpp:84] Creating Layer BatchNorm6
I0927 19:02:46.305912  3577 net.cpp:406] BatchNorm6 <- Convolution6
I0927 19:02:46.305917  3577 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0927 19:02:46.306073  3577 net.cpp:122] Setting up BatchNorm6
I0927 19:02:46.306077  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.306079  3577 net.cpp:137] Memory required for data: 197838000
I0927 19:02:46.306084  3577 layer_factory.hpp:77] Creating layer Scale6
I0927 19:02:46.306088  3577 net.cpp:84] Creating Layer Scale6
I0927 19:02:46.306092  3577 net.cpp:406] Scale6 <- Convolution6
I0927 19:02:46.306095  3577 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0927 19:02:46.306125  3577 layer_factory.hpp:77] Creating layer Scale6
I0927 19:02:46.306211  3577 net.cpp:122] Setting up Scale6
I0927 19:02:46.306217  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.306219  3577 net.cpp:137] Memory required for data: 204391600
I0927 19:02:46.306223  3577 layer_factory.hpp:77] Creating layer M2PELU6
I0927 19:02:46.306228  3577 net.cpp:84] Creating Layer M2PELU6
I0927 19:02:46.306231  3577 net.cpp:406] M2PELU6 <- Convolution6
I0927 19:02:46.306234  3577 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0927 19:02:46.306337  3577 net.cpp:122] Setting up M2PELU6
I0927 19:02:46.306341  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.306344  3577 net.cpp:137] Memory required for data: 210945200
I0927 19:02:46.306347  3577 layer_factory.hpp:77] Creating layer Convolution7
I0927 19:02:46.306354  3577 net.cpp:84] Creating Layer Convolution7
I0927 19:02:46.306356  3577 net.cpp:406] Convolution7 <- Convolution6
I0927 19:02:46.306360  3577 net.cpp:380] Convolution7 -> Convolution7
I0927 19:02:46.307324  3577 net.cpp:122] Setting up Convolution7
I0927 19:02:46.307333  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.307343  3577 net.cpp:137] Memory required for data: 217498800
I0927 19:02:46.307348  3577 layer_factory.hpp:77] Creating layer BatchNorm7
I0927 19:02:46.307353  3577 net.cpp:84] Creating Layer BatchNorm7
I0927 19:02:46.307356  3577 net.cpp:406] BatchNorm7 <- Convolution7
I0927 19:02:46.307361  3577 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0927 19:02:46.307519  3577 net.cpp:122] Setting up BatchNorm7
I0927 19:02:46.307524  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.307526  3577 net.cpp:137] Memory required for data: 224052400
I0927 19:02:46.307531  3577 layer_factory.hpp:77] Creating layer Scale7
I0927 19:02:46.307535  3577 net.cpp:84] Creating Layer Scale7
I0927 19:02:46.307538  3577 net.cpp:406] Scale7 <- Convolution7
I0927 19:02:46.307541  3577 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0927 19:02:46.307572  3577 layer_factory.hpp:77] Creating layer Scale7
I0927 19:02:46.307660  3577 net.cpp:122] Setting up Scale7
I0927 19:02:46.307665  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.307667  3577 net.cpp:137] Memory required for data: 230606000
I0927 19:02:46.307672  3577 layer_factory.hpp:77] Creating layer Eltwise3
I0927 19:02:46.307674  3577 net.cpp:84] Creating Layer Eltwise3
I0927 19:02:46.307677  3577 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0927 19:02:46.307680  3577 net.cpp:406] Eltwise3 <- Convolution7
I0927 19:02:46.307684  3577 net.cpp:380] Eltwise3 -> Eltwise3
I0927 19:02:46.307701  3577 net.cpp:122] Setting up Eltwise3
I0927 19:02:46.307706  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.307708  3577 net.cpp:137] Memory required for data: 237159600
I0927 19:02:46.307710  3577 layer_factory.hpp:77] Creating layer M2PELU7
I0927 19:02:46.307714  3577 net.cpp:84] Creating Layer M2PELU7
I0927 19:02:46.307718  3577 net.cpp:406] M2PELU7 <- Eltwise3
I0927 19:02:46.307721  3577 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0927 19:02:46.307823  3577 net.cpp:122] Setting up M2PELU7
I0927 19:02:46.307828  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.307831  3577 net.cpp:137] Memory required for data: 243713200
I0927 19:02:46.307834  3577 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0927 19:02:46.307837  3577 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0927 19:02:46.307840  3577 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0927 19:02:46.307844  3577 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0927 19:02:46.307848  3577 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0927 19:02:46.307875  3577 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0927 19:02:46.307878  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.328747  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.328755  3577 net.cpp:137] Memory required for data: 256820400
I0927 19:02:46.328760  3577 layer_factory.hpp:77] Creating layer Convolution8
I0927 19:02:46.328773  3577 net.cpp:84] Creating Layer Convolution8
I0927 19:02:46.328778  3577 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0927 19:02:46.328785  3577 net.cpp:380] Convolution8 -> Convolution8
I0927 19:02:46.329851  3577 net.cpp:122] Setting up Convolution8
I0927 19:02:46.329861  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.329864  3577 net.cpp:137] Memory required for data: 263374000
I0927 19:02:46.329874  3577 layer_factory.hpp:77] Creating layer BatchNorm8
I0927 19:02:46.329880  3577 net.cpp:84] Creating Layer BatchNorm8
I0927 19:02:46.329883  3577 net.cpp:406] BatchNorm8 <- Convolution8
I0927 19:02:46.329887  3577 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0927 19:02:46.330063  3577 net.cpp:122] Setting up BatchNorm8
I0927 19:02:46.330070  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.330073  3577 net.cpp:137] Memory required for data: 269927600
I0927 19:02:46.330078  3577 layer_factory.hpp:77] Creating layer Scale8
I0927 19:02:46.330082  3577 net.cpp:84] Creating Layer Scale8
I0927 19:02:46.330092  3577 net.cpp:406] Scale8 <- Convolution8
I0927 19:02:46.330097  3577 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0927 19:02:46.330135  3577 layer_factory.hpp:77] Creating layer Scale8
I0927 19:02:46.330288  3577 net.cpp:122] Setting up Scale8
I0927 19:02:46.330298  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.330302  3577 net.cpp:137] Memory required for data: 276481200
I0927 19:02:46.330305  3577 layer_factory.hpp:77] Creating layer M2PELU8
I0927 19:02:46.330313  3577 net.cpp:84] Creating Layer M2PELU8
I0927 19:02:46.330318  3577 net.cpp:406] M2PELU8 <- Convolution8
I0927 19:02:46.330325  3577 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0927 19:02:46.330440  3577 net.cpp:122] Setting up M2PELU8
I0927 19:02:46.330446  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.330447  3577 net.cpp:137] Memory required for data: 283034800
I0927 19:02:46.330451  3577 layer_factory.hpp:77] Creating layer Convolution9
I0927 19:02:46.330458  3577 net.cpp:84] Creating Layer Convolution9
I0927 19:02:46.330461  3577 net.cpp:406] Convolution9 <- Convolution8
I0927 19:02:46.330466  3577 net.cpp:380] Convolution9 -> Convolution9
I0927 19:02:46.331509  3577 net.cpp:122] Setting up Convolution9
I0927 19:02:46.331519  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.331521  3577 net.cpp:137] Memory required for data: 289588400
I0927 19:02:46.331526  3577 layer_factory.hpp:77] Creating layer BatchNorm9
I0927 19:02:46.331532  3577 net.cpp:84] Creating Layer BatchNorm9
I0927 19:02:46.331534  3577 net.cpp:406] BatchNorm9 <- Convolution9
I0927 19:02:46.331538  3577 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0927 19:02:46.331701  3577 net.cpp:122] Setting up BatchNorm9
I0927 19:02:46.331706  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.331707  3577 net.cpp:137] Memory required for data: 296142000
I0927 19:02:46.331712  3577 layer_factory.hpp:77] Creating layer Scale9
I0927 19:02:46.331717  3577 net.cpp:84] Creating Layer Scale9
I0927 19:02:46.331719  3577 net.cpp:406] Scale9 <- Convolution9
I0927 19:02:46.331723  3577 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0927 19:02:46.331755  3577 layer_factory.hpp:77] Creating layer Scale9
I0927 19:02:46.331843  3577 net.cpp:122] Setting up Scale9
I0927 19:02:46.331847  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.331851  3577 net.cpp:137] Memory required for data: 302695600
I0927 19:02:46.331854  3577 layer_factory.hpp:77] Creating layer Eltwise4
I0927 19:02:46.331859  3577 net.cpp:84] Creating Layer Eltwise4
I0927 19:02:46.331861  3577 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0927 19:02:46.331864  3577 net.cpp:406] Eltwise4 <- Convolution9
I0927 19:02:46.331868  3577 net.cpp:380] Eltwise4 -> Eltwise4
I0927 19:02:46.331887  3577 net.cpp:122] Setting up Eltwise4
I0927 19:02:46.331892  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.331893  3577 net.cpp:137] Memory required for data: 309249200
I0927 19:02:46.331895  3577 layer_factory.hpp:77] Creating layer M2PELU9
I0927 19:02:46.331900  3577 net.cpp:84] Creating Layer M2PELU9
I0927 19:02:46.331903  3577 net.cpp:406] M2PELU9 <- Eltwise4
I0927 19:02:46.331907  3577 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0927 19:02:46.332012  3577 net.cpp:122] Setting up M2PELU9
I0927 19:02:46.332016  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.332018  3577 net.cpp:137] Memory required for data: 315802800
I0927 19:02:46.332022  3577 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0927 19:02:46.332026  3577 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0927 19:02:46.332028  3577 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0927 19:02:46.332032  3577 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0927 19:02:46.332036  3577 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0927 19:02:46.332063  3577 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0927 19:02:46.332067  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.332077  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.332079  3577 net.cpp:137] Memory required for data: 328910000
I0927 19:02:46.332082  3577 layer_factory.hpp:77] Creating layer Convolution10
I0927 19:02:46.332088  3577 net.cpp:84] Creating Layer Convolution10
I0927 19:02:46.332092  3577 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0927 19:02:46.332095  3577 net.cpp:380] Convolution10 -> Convolution10
I0927 19:02:46.333149  3577 net.cpp:122] Setting up Convolution10
I0927 19:02:46.333158  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.333161  3577 net.cpp:137] Memory required for data: 335463600
I0927 19:02:46.333165  3577 layer_factory.hpp:77] Creating layer BatchNorm10
I0927 19:02:46.333170  3577 net.cpp:84] Creating Layer BatchNorm10
I0927 19:02:46.333173  3577 net.cpp:406] BatchNorm10 <- Convolution10
I0927 19:02:46.333178  3577 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0927 19:02:46.333343  3577 net.cpp:122] Setting up BatchNorm10
I0927 19:02:46.333348  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.333350  3577 net.cpp:137] Memory required for data: 342017200
I0927 19:02:46.333355  3577 layer_factory.hpp:77] Creating layer Scale10
I0927 19:02:46.333359  3577 net.cpp:84] Creating Layer Scale10
I0927 19:02:46.333362  3577 net.cpp:406] Scale10 <- Convolution10
I0927 19:02:46.333365  3577 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0927 19:02:46.333398  3577 layer_factory.hpp:77] Creating layer Scale10
I0927 19:02:46.333489  3577 net.cpp:122] Setting up Scale10
I0927 19:02:46.333493  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.333495  3577 net.cpp:137] Memory required for data: 348570800
I0927 19:02:46.333499  3577 layer_factory.hpp:77] Creating layer M2PELU10
I0927 19:02:46.333505  3577 net.cpp:84] Creating Layer M2PELU10
I0927 19:02:46.333508  3577 net.cpp:406] M2PELU10 <- Convolution10
I0927 19:02:46.333511  3577 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0927 19:02:46.333617  3577 net.cpp:122] Setting up M2PELU10
I0927 19:02:46.333622  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.333624  3577 net.cpp:137] Memory required for data: 355124400
I0927 19:02:46.333628  3577 layer_factory.hpp:77] Creating layer Convolution11
I0927 19:02:46.333636  3577 net.cpp:84] Creating Layer Convolution11
I0927 19:02:46.333637  3577 net.cpp:406] Convolution11 <- Convolution10
I0927 19:02:46.333642  3577 net.cpp:380] Convolution11 -> Convolution11
I0927 19:02:46.334975  3577 net.cpp:122] Setting up Convolution11
I0927 19:02:46.334983  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.334985  3577 net.cpp:137] Memory required for data: 361678000
I0927 19:02:46.334991  3577 layer_factory.hpp:77] Creating layer BatchNorm11
I0927 19:02:46.334997  3577 net.cpp:84] Creating Layer BatchNorm11
I0927 19:02:46.335000  3577 net.cpp:406] BatchNorm11 <- Convolution11
I0927 19:02:46.335003  3577 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0927 19:02:46.335168  3577 net.cpp:122] Setting up BatchNorm11
I0927 19:02:46.335173  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.335175  3577 net.cpp:137] Memory required for data: 368231600
I0927 19:02:46.335180  3577 layer_factory.hpp:77] Creating layer Scale11
I0927 19:02:46.335186  3577 net.cpp:84] Creating Layer Scale11
I0927 19:02:46.335188  3577 net.cpp:406] Scale11 <- Convolution11
I0927 19:02:46.335191  3577 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0927 19:02:46.335223  3577 layer_factory.hpp:77] Creating layer Scale11
I0927 19:02:46.335314  3577 net.cpp:122] Setting up Scale11
I0927 19:02:46.335319  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.335321  3577 net.cpp:137] Memory required for data: 374785200
I0927 19:02:46.335325  3577 layer_factory.hpp:77] Creating layer Eltwise5
I0927 19:02:46.335330  3577 net.cpp:84] Creating Layer Eltwise5
I0927 19:02:46.335331  3577 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0927 19:02:46.335335  3577 net.cpp:406] Eltwise5 <- Convolution11
I0927 19:02:46.335345  3577 net.cpp:380] Eltwise5 -> Eltwise5
I0927 19:02:46.335366  3577 net.cpp:122] Setting up Eltwise5
I0927 19:02:46.335371  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.335373  3577 net.cpp:137] Memory required for data: 381338800
I0927 19:02:46.335376  3577 layer_factory.hpp:77] Creating layer M2PELU11
I0927 19:02:46.335381  3577 net.cpp:84] Creating Layer M2PELU11
I0927 19:02:46.335382  3577 net.cpp:406] M2PELU11 <- Eltwise5
I0927 19:02:46.335386  3577 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0927 19:02:46.335494  3577 net.cpp:122] Setting up M2PELU11
I0927 19:02:46.335499  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.335500  3577 net.cpp:137] Memory required for data: 387892400
I0927 19:02:46.335505  3577 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0927 19:02:46.335510  3577 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0927 19:02:46.335511  3577 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0927 19:02:46.335515  3577 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0927 19:02:46.335518  3577 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0927 19:02:46.335547  3577 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0927 19:02:46.335551  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.335554  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.335556  3577 net.cpp:137] Memory required for data: 400999600
I0927 19:02:46.335558  3577 layer_factory.hpp:77] Creating layer Convolution12
I0927 19:02:46.335564  3577 net.cpp:84] Creating Layer Convolution12
I0927 19:02:46.335566  3577 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0927 19:02:46.335572  3577 net.cpp:380] Convolution12 -> Convolution12
I0927 19:02:46.336578  3577 net.cpp:122] Setting up Convolution12
I0927 19:02:46.336587  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.336591  3577 net.cpp:137] Memory required for data: 407553200
I0927 19:02:46.336594  3577 layer_factory.hpp:77] Creating layer BatchNorm12
I0927 19:02:46.336601  3577 net.cpp:84] Creating Layer BatchNorm12
I0927 19:02:46.336602  3577 net.cpp:406] BatchNorm12 <- Convolution12
I0927 19:02:46.336607  3577 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0927 19:02:46.336769  3577 net.cpp:122] Setting up BatchNorm12
I0927 19:02:46.336774  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.336776  3577 net.cpp:137] Memory required for data: 414106800
I0927 19:02:46.336781  3577 layer_factory.hpp:77] Creating layer Scale12
I0927 19:02:46.336786  3577 net.cpp:84] Creating Layer Scale12
I0927 19:02:46.336788  3577 net.cpp:406] Scale12 <- Convolution12
I0927 19:02:46.336792  3577 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0927 19:02:46.336824  3577 layer_factory.hpp:77] Creating layer Scale12
I0927 19:02:46.336915  3577 net.cpp:122] Setting up Scale12
I0927 19:02:46.336920  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.336922  3577 net.cpp:137] Memory required for data: 420660400
I0927 19:02:46.336926  3577 layer_factory.hpp:77] Creating layer M2PELU12
I0927 19:02:46.336930  3577 net.cpp:84] Creating Layer M2PELU12
I0927 19:02:46.336935  3577 net.cpp:406] M2PELU12 <- Convolution12
I0927 19:02:46.336937  3577 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0927 19:02:46.337044  3577 net.cpp:122] Setting up M2PELU12
I0927 19:02:46.337049  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.337050  3577 net.cpp:137] Memory required for data: 427214000
I0927 19:02:46.337054  3577 layer_factory.hpp:77] Creating layer Convolution13
I0927 19:02:46.337059  3577 net.cpp:84] Creating Layer Convolution13
I0927 19:02:46.337062  3577 net.cpp:406] Convolution13 <- Convolution12
I0927 19:02:46.337066  3577 net.cpp:380] Convolution13 -> Convolution13
I0927 19:02:46.338068  3577 net.cpp:122] Setting up Convolution13
I0927 19:02:46.338078  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.338079  3577 net.cpp:137] Memory required for data: 433767600
I0927 19:02:46.338091  3577 layer_factory.hpp:77] Creating layer BatchNorm13
I0927 19:02:46.338098  3577 net.cpp:84] Creating Layer BatchNorm13
I0927 19:02:46.338100  3577 net.cpp:406] BatchNorm13 <- Convolution13
I0927 19:02:46.338104  3577 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0927 19:02:46.338268  3577 net.cpp:122] Setting up BatchNorm13
I0927 19:02:46.338274  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.338275  3577 net.cpp:137] Memory required for data: 440321200
I0927 19:02:46.338280  3577 layer_factory.hpp:77] Creating layer Scale13
I0927 19:02:46.338285  3577 net.cpp:84] Creating Layer Scale13
I0927 19:02:46.338289  3577 net.cpp:406] Scale13 <- Convolution13
I0927 19:02:46.338291  3577 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0927 19:02:46.338323  3577 layer_factory.hpp:77] Creating layer Scale13
I0927 19:02:46.338414  3577 net.cpp:122] Setting up Scale13
I0927 19:02:46.338418  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.338420  3577 net.cpp:137] Memory required for data: 446874800
I0927 19:02:46.338424  3577 layer_factory.hpp:77] Creating layer Eltwise6
I0927 19:02:46.338436  3577 net.cpp:84] Creating Layer Eltwise6
I0927 19:02:46.338439  3577 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0927 19:02:46.338443  3577 net.cpp:406] Eltwise6 <- Convolution13
I0927 19:02:46.338445  3577 net.cpp:380] Eltwise6 -> Eltwise6
I0927 19:02:46.338466  3577 net.cpp:122] Setting up Eltwise6
I0927 19:02:46.338470  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.338472  3577 net.cpp:137] Memory required for data: 453428400
I0927 19:02:46.338474  3577 layer_factory.hpp:77] Creating layer M2PELU13
I0927 19:02:46.338479  3577 net.cpp:84] Creating Layer M2PELU13
I0927 19:02:46.338481  3577 net.cpp:406] M2PELU13 <- Eltwise6
I0927 19:02:46.338485  3577 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0927 19:02:46.338599  3577 net.cpp:122] Setting up M2PELU13
I0927 19:02:46.338606  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.338608  3577 net.cpp:137] Memory required for data: 459982000
I0927 19:02:46.338613  3577 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0927 19:02:46.338616  3577 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0927 19:02:46.338618  3577 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0927 19:02:46.338623  3577 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0927 19:02:46.338626  3577 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0927 19:02:46.338654  3577 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0927 19:02:46.359246  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.359256  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.359261  3577 net.cpp:137] Memory required for data: 473089200
I0927 19:02:46.359266  3577 layer_factory.hpp:77] Creating layer Convolution14
I0927 19:02:46.359277  3577 net.cpp:84] Creating Layer Convolution14
I0927 19:02:46.359282  3577 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0927 19:02:46.359289  3577 net.cpp:380] Convolution14 -> Convolution14
I0927 19:02:46.360440  3577 net.cpp:122] Setting up Convolution14
I0927 19:02:46.360450  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.360452  3577 net.cpp:137] Memory required for data: 479642800
I0927 19:02:46.360457  3577 layer_factory.hpp:77] Creating layer BatchNorm14
I0927 19:02:46.360462  3577 net.cpp:84] Creating Layer BatchNorm14
I0927 19:02:46.360465  3577 net.cpp:406] BatchNorm14 <- Convolution14
I0927 19:02:46.360469  3577 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0927 19:02:46.360684  3577 net.cpp:122] Setting up BatchNorm14
I0927 19:02:46.360695  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.360700  3577 net.cpp:137] Memory required for data: 486196400
I0927 19:02:46.360709  3577 layer_factory.hpp:77] Creating layer Scale14
I0927 19:02:46.360716  3577 net.cpp:84] Creating Layer Scale14
I0927 19:02:46.360729  3577 net.cpp:406] Scale14 <- Convolution14
I0927 19:02:46.360734  3577 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0927 19:02:46.360781  3577 layer_factory.hpp:77] Creating layer Scale14
I0927 19:02:46.360877  3577 net.cpp:122] Setting up Scale14
I0927 19:02:46.360882  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.360884  3577 net.cpp:137] Memory required for data: 492750000
I0927 19:02:46.360888  3577 layer_factory.hpp:77] Creating layer M2PELU14
I0927 19:02:46.360894  3577 net.cpp:84] Creating Layer M2PELU14
I0927 19:02:46.360896  3577 net.cpp:406] M2PELU14 <- Convolution14
I0927 19:02:46.360900  3577 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0927 19:02:46.361007  3577 net.cpp:122] Setting up M2PELU14
I0927 19:02:46.361012  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.361014  3577 net.cpp:137] Memory required for data: 499303600
I0927 19:02:46.361018  3577 layer_factory.hpp:77] Creating layer Convolution15
I0927 19:02:46.361027  3577 net.cpp:84] Creating Layer Convolution15
I0927 19:02:46.361028  3577 net.cpp:406] Convolution15 <- Convolution14
I0927 19:02:46.361033  3577 net.cpp:380] Convolution15 -> Convolution15
I0927 19:02:46.362258  3577 net.cpp:122] Setting up Convolution15
I0927 19:02:46.362267  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.362270  3577 net.cpp:137] Memory required for data: 505857200
I0927 19:02:46.362274  3577 layer_factory.hpp:77] Creating layer BatchNorm15
I0927 19:02:46.362279  3577 net.cpp:84] Creating Layer BatchNorm15
I0927 19:02:46.362282  3577 net.cpp:406] BatchNorm15 <- Convolution15
I0927 19:02:46.362287  3577 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0927 19:02:46.362447  3577 net.cpp:122] Setting up BatchNorm15
I0927 19:02:46.362452  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.362454  3577 net.cpp:137] Memory required for data: 512410800
I0927 19:02:46.362468  3577 layer_factory.hpp:77] Creating layer Scale15
I0927 19:02:46.362473  3577 net.cpp:84] Creating Layer Scale15
I0927 19:02:46.362475  3577 net.cpp:406] Scale15 <- Convolution15
I0927 19:02:46.362479  3577 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0927 19:02:46.362512  3577 layer_factory.hpp:77] Creating layer Scale15
I0927 19:02:46.362654  3577 net.cpp:122] Setting up Scale15
I0927 19:02:46.362663  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.362666  3577 net.cpp:137] Memory required for data: 518964400
I0927 19:02:46.362670  3577 layer_factory.hpp:77] Creating layer Eltwise7
I0927 19:02:46.362678  3577 net.cpp:84] Creating Layer Eltwise7
I0927 19:02:46.362680  3577 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0927 19:02:46.362692  3577 net.cpp:406] Eltwise7 <- Convolution15
I0927 19:02:46.362696  3577 net.cpp:380] Eltwise7 -> Eltwise7
I0927 19:02:46.362716  3577 net.cpp:122] Setting up Eltwise7
I0927 19:02:46.362720  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.362722  3577 net.cpp:137] Memory required for data: 525518000
I0927 19:02:46.362725  3577 layer_factory.hpp:77] Creating layer M2PELU15
I0927 19:02:46.362730  3577 net.cpp:84] Creating Layer M2PELU15
I0927 19:02:46.362732  3577 net.cpp:406] M2PELU15 <- Eltwise7
I0927 19:02:46.362736  3577 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0927 19:02:46.362855  3577 net.cpp:122] Setting up M2PELU15
I0927 19:02:46.362860  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.362864  3577 net.cpp:137] Memory required for data: 532071600
I0927 19:02:46.362866  3577 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0927 19:02:46.362879  3577 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0927 19:02:46.362881  3577 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0927 19:02:46.362885  3577 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0927 19:02:46.362890  3577 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0927 19:02:46.362917  3577 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0927 19:02:46.362921  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.362931  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.362933  3577 net.cpp:137] Memory required for data: 545178800
I0927 19:02:46.362936  3577 layer_factory.hpp:77] Creating layer Convolution16
I0927 19:02:46.362942  3577 net.cpp:84] Creating Layer Convolution16
I0927 19:02:46.362944  3577 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0927 19:02:46.362949  3577 net.cpp:380] Convolution16 -> Convolution16
I0927 19:02:46.363625  3577 net.cpp:122] Setting up Convolution16
I0927 19:02:46.363632  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.363636  3577 net.cpp:137] Memory required for data: 551732400
I0927 19:02:46.363639  3577 layer_factory.hpp:77] Creating layer BatchNorm16
I0927 19:02:46.363644  3577 net.cpp:84] Creating Layer BatchNorm16
I0927 19:02:46.363647  3577 net.cpp:406] BatchNorm16 <- Convolution16
I0927 19:02:46.363651  3577 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0927 19:02:46.363809  3577 net.cpp:122] Setting up BatchNorm16
I0927 19:02:46.363814  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.363816  3577 net.cpp:137] Memory required for data: 558286000
I0927 19:02:46.363821  3577 layer_factory.hpp:77] Creating layer Scale16
I0927 19:02:46.363826  3577 net.cpp:84] Creating Layer Scale16
I0927 19:02:46.363827  3577 net.cpp:406] Scale16 <- Convolution16
I0927 19:02:46.363831  3577 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0927 19:02:46.363862  3577 layer_factory.hpp:77] Creating layer Scale16
I0927 19:02:46.363950  3577 net.cpp:122] Setting up Scale16
I0927 19:02:46.363955  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.363957  3577 net.cpp:137] Memory required for data: 564839600
I0927 19:02:46.363961  3577 layer_factory.hpp:77] Creating layer M2PELU16
I0927 19:02:46.363965  3577 net.cpp:84] Creating Layer M2PELU16
I0927 19:02:46.363968  3577 net.cpp:406] M2PELU16 <- Convolution16
I0927 19:02:46.363972  3577 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0927 19:02:46.364079  3577 net.cpp:122] Setting up M2PELU16
I0927 19:02:46.364084  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.364086  3577 net.cpp:137] Memory required for data: 571393200
I0927 19:02:46.364089  3577 layer_factory.hpp:77] Creating layer Convolution17
I0927 19:02:46.364096  3577 net.cpp:84] Creating Layer Convolution17
I0927 19:02:46.364099  3577 net.cpp:406] Convolution17 <- Convolution16
I0927 19:02:46.364104  3577 net.cpp:380] Convolution17 -> Convolution17
I0927 19:02:46.365069  3577 net.cpp:122] Setting up Convolution17
I0927 19:02:46.365077  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.365080  3577 net.cpp:137] Memory required for data: 577946800
I0927 19:02:46.365085  3577 layer_factory.hpp:77] Creating layer BatchNorm17
I0927 19:02:46.365090  3577 net.cpp:84] Creating Layer BatchNorm17
I0927 19:02:46.365092  3577 net.cpp:406] BatchNorm17 <- Convolution17
I0927 19:02:46.365097  3577 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0927 19:02:46.365257  3577 net.cpp:122] Setting up BatchNorm17
I0927 19:02:46.365262  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.365264  3577 net.cpp:137] Memory required for data: 584500400
I0927 19:02:46.365268  3577 layer_factory.hpp:77] Creating layer Scale17
I0927 19:02:46.365272  3577 net.cpp:84] Creating Layer Scale17
I0927 19:02:46.365275  3577 net.cpp:406] Scale17 <- Convolution17
I0927 19:02:46.365279  3577 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0927 19:02:46.365310  3577 layer_factory.hpp:77] Creating layer Scale17
I0927 19:02:46.365401  3577 net.cpp:122] Setting up Scale17
I0927 19:02:46.365404  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.365406  3577 net.cpp:137] Memory required for data: 591054000
I0927 19:02:46.365411  3577 layer_factory.hpp:77] Creating layer Eltwise8
I0927 19:02:46.365414  3577 net.cpp:84] Creating Layer Eltwise8
I0927 19:02:46.365417  3577 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0927 19:02:46.365427  3577 net.cpp:406] Eltwise8 <- Convolution17
I0927 19:02:46.365430  3577 net.cpp:380] Eltwise8 -> Eltwise8
I0927 19:02:46.365450  3577 net.cpp:122] Setting up Eltwise8
I0927 19:02:46.365454  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.365456  3577 net.cpp:137] Memory required for data: 597607600
I0927 19:02:46.365458  3577 layer_factory.hpp:77] Creating layer M2PELU17
I0927 19:02:46.365463  3577 net.cpp:84] Creating Layer M2PELU17
I0927 19:02:46.365466  3577 net.cpp:406] M2PELU17 <- Eltwise8
I0927 19:02:46.365469  3577 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0927 19:02:46.365576  3577 net.cpp:122] Setting up M2PELU17
I0927 19:02:46.365581  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.365582  3577 net.cpp:137] Memory required for data: 604161200
I0927 19:02:46.365586  3577 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0927 19:02:46.365591  3577 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0927 19:02:46.365592  3577 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0927 19:02:46.365597  3577 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0927 19:02:46.365600  3577 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0927 19:02:46.365628  3577 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0927 19:02:46.365633  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.365634  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.365636  3577 net.cpp:137] Memory required for data: 617268400
I0927 19:02:46.365638  3577 layer_factory.hpp:77] Creating layer Convolution18
I0927 19:02:46.365645  3577 net.cpp:84] Creating Layer Convolution18
I0927 19:02:46.365648  3577 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0927 19:02:46.365651  3577 net.cpp:380] Convolution18 -> Convolution18
I0927 19:02:46.366673  3577 net.cpp:122] Setting up Convolution18
I0927 19:02:46.366683  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.366685  3577 net.cpp:137] Memory required for data: 623822000
I0927 19:02:46.366690  3577 layer_factory.hpp:77] Creating layer BatchNorm18
I0927 19:02:46.366694  3577 net.cpp:84] Creating Layer BatchNorm18
I0927 19:02:46.366698  3577 net.cpp:406] BatchNorm18 <- Convolution18
I0927 19:02:46.366701  3577 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0927 19:02:46.366856  3577 net.cpp:122] Setting up BatchNorm18
I0927 19:02:46.366860  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.366863  3577 net.cpp:137] Memory required for data: 630375600
I0927 19:02:46.366868  3577 layer_factory.hpp:77] Creating layer Scale18
I0927 19:02:46.366873  3577 net.cpp:84] Creating Layer Scale18
I0927 19:02:46.366874  3577 net.cpp:406] Scale18 <- Convolution18
I0927 19:02:46.366878  3577 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0927 19:02:46.366909  3577 layer_factory.hpp:77] Creating layer Scale18
I0927 19:02:46.366997  3577 net.cpp:122] Setting up Scale18
I0927 19:02:46.367002  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.367003  3577 net.cpp:137] Memory required for data: 636929200
I0927 19:02:46.367007  3577 layer_factory.hpp:77] Creating layer M2PELU18
I0927 19:02:46.367012  3577 net.cpp:84] Creating Layer M2PELU18
I0927 19:02:46.367015  3577 net.cpp:406] M2PELU18 <- Convolution18
I0927 19:02:46.367018  3577 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0927 19:02:46.367126  3577 net.cpp:122] Setting up M2PELU18
I0927 19:02:46.367130  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.367132  3577 net.cpp:137] Memory required for data: 643482800
I0927 19:02:46.367136  3577 layer_factory.hpp:77] Creating layer Convolution19
I0927 19:02:46.367143  3577 net.cpp:84] Creating Layer Convolution19
I0927 19:02:46.367146  3577 net.cpp:406] Convolution19 <- Convolution18
I0927 19:02:46.367149  3577 net.cpp:380] Convolution19 -> Convolution19
I0927 19:02:46.368119  3577 net.cpp:122] Setting up Convolution19
I0927 19:02:46.368127  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.368135  3577 net.cpp:137] Memory required for data: 650036400
I0927 19:02:46.368140  3577 layer_factory.hpp:77] Creating layer BatchNorm19
I0927 19:02:46.368145  3577 net.cpp:84] Creating Layer BatchNorm19
I0927 19:02:46.368147  3577 net.cpp:406] BatchNorm19 <- Convolution19
I0927 19:02:46.368154  3577 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0927 19:02:46.368314  3577 net.cpp:122] Setting up BatchNorm19
I0927 19:02:46.368319  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.368320  3577 net.cpp:137] Memory required for data: 656590000
I0927 19:02:46.368325  3577 layer_factory.hpp:77] Creating layer Scale19
I0927 19:02:46.368330  3577 net.cpp:84] Creating Layer Scale19
I0927 19:02:46.368332  3577 net.cpp:406] Scale19 <- Convolution19
I0927 19:02:46.368335  3577 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0927 19:02:46.368367  3577 layer_factory.hpp:77] Creating layer Scale19
I0927 19:02:46.368456  3577 net.cpp:122] Setting up Scale19
I0927 19:02:46.368461  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.368463  3577 net.cpp:137] Memory required for data: 663143600
I0927 19:02:46.368468  3577 layer_factory.hpp:77] Creating layer Eltwise9
I0927 19:02:46.368471  3577 net.cpp:84] Creating Layer Eltwise9
I0927 19:02:46.368474  3577 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0927 19:02:46.368477  3577 net.cpp:406] Eltwise9 <- Convolution19
I0927 19:02:46.368480  3577 net.cpp:380] Eltwise9 -> Eltwise9
I0927 19:02:46.368500  3577 net.cpp:122] Setting up Eltwise9
I0927 19:02:46.368505  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.368505  3577 net.cpp:137] Memory required for data: 669697200
I0927 19:02:46.368507  3577 layer_factory.hpp:77] Creating layer M2PELU19
I0927 19:02:46.368512  3577 net.cpp:84] Creating Layer M2PELU19
I0927 19:02:46.368515  3577 net.cpp:406] M2PELU19 <- Eltwise9
I0927 19:02:46.368518  3577 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0927 19:02:46.368625  3577 net.cpp:122] Setting up M2PELU19
I0927 19:02:46.368631  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.368633  3577 net.cpp:137] Memory required for data: 676250800
I0927 19:02:46.368638  3577 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0927 19:02:46.368640  3577 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0927 19:02:46.368643  3577 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0927 19:02:46.368646  3577 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0927 19:02:46.389778  3577 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0927 19:02:46.389839  3577 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0927 19:02:46.389848  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.389853  3577 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 19:02:46.389858  3577 net.cpp:137] Memory required for data: 689358000
I0927 19:02:46.389861  3577 layer_factory.hpp:77] Creating layer Convolution20
I0927 19:02:46.389871  3577 net.cpp:84] Creating Layer Convolution20
I0927 19:02:46.389876  3577 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0927 19:02:46.389883  3577 net.cpp:380] Convolution20 -> Convolution20
I0927 19:02:46.390970  3577 net.cpp:122] Setting up Convolution20
I0927 19:02:46.390980  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.390983  3577 net.cpp:137] Memory required for data: 692634800
I0927 19:02:46.390987  3577 layer_factory.hpp:77] Creating layer BatchNorm20
I0927 19:02:46.390993  3577 net.cpp:84] Creating Layer BatchNorm20
I0927 19:02:46.390996  3577 net.cpp:406] BatchNorm20 <- Convolution20
I0927 19:02:46.391000  3577 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0927 19:02:46.391194  3577 net.cpp:122] Setting up BatchNorm20
I0927 19:02:46.391202  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.391204  3577 net.cpp:137] Memory required for data: 695911600
I0927 19:02:46.391211  3577 layer_factory.hpp:77] Creating layer Scale20
I0927 19:02:46.391214  3577 net.cpp:84] Creating Layer Scale20
I0927 19:02:46.391224  3577 net.cpp:406] Scale20 <- Convolution20
I0927 19:02:46.391229  3577 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0927 19:02:46.391264  3577 layer_factory.hpp:77] Creating layer Scale20
I0927 19:02:46.391358  3577 net.cpp:122] Setting up Scale20
I0927 19:02:46.391363  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.391366  3577 net.cpp:137] Memory required for data: 699188400
I0927 19:02:46.391369  3577 layer_factory.hpp:77] Creating layer Convolution21
I0927 19:02:46.391377  3577 net.cpp:84] Creating Layer Convolution21
I0927 19:02:46.391381  3577 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0927 19:02:46.391389  3577 net.cpp:380] Convolution21 -> Convolution21
I0927 19:02:46.392551  3577 net.cpp:122] Setting up Convolution21
I0927 19:02:46.392561  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.392565  3577 net.cpp:137] Memory required for data: 702465200
I0927 19:02:46.392570  3577 layer_factory.hpp:77] Creating layer BatchNorm21
I0927 19:02:46.392573  3577 net.cpp:84] Creating Layer BatchNorm21
I0927 19:02:46.392576  3577 net.cpp:406] BatchNorm21 <- Convolution21
I0927 19:02:46.392581  3577 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0927 19:02:46.392743  3577 net.cpp:122] Setting up BatchNorm21
I0927 19:02:46.392747  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.392750  3577 net.cpp:137] Memory required for data: 705742000
I0927 19:02:46.392755  3577 layer_factory.hpp:77] Creating layer Scale21
I0927 19:02:46.392760  3577 net.cpp:84] Creating Layer Scale21
I0927 19:02:46.392762  3577 net.cpp:406] Scale21 <- Convolution21
I0927 19:02:46.392765  3577 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0927 19:02:46.392798  3577 layer_factory.hpp:77] Creating layer Scale21
I0927 19:02:46.392895  3577 net.cpp:122] Setting up Scale21
I0927 19:02:46.392904  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.392907  3577 net.cpp:137] Memory required for data: 709018800
I0927 19:02:46.392912  3577 layer_factory.hpp:77] Creating layer M2PELU20
I0927 19:02:46.392920  3577 net.cpp:84] Creating Layer M2PELU20
I0927 19:02:46.392921  3577 net.cpp:406] M2PELU20 <- Convolution21
I0927 19:02:46.392925  3577 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0927 19:02:46.393030  3577 net.cpp:122] Setting up M2PELU20
I0927 19:02:46.393035  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.393038  3577 net.cpp:137] Memory required for data: 712295600
I0927 19:02:46.393041  3577 layer_factory.hpp:77] Creating layer Convolution22
I0927 19:02:46.393049  3577 net.cpp:84] Creating Layer Convolution22
I0927 19:02:46.393051  3577 net.cpp:406] Convolution22 <- Convolution21
I0927 19:02:46.393056  3577 net.cpp:380] Convolution22 -> Convolution22
I0927 19:02:46.394225  3577 net.cpp:122] Setting up Convolution22
I0927 19:02:46.394234  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.394237  3577 net.cpp:137] Memory required for data: 715572400
I0927 19:02:46.394243  3577 layer_factory.hpp:77] Creating layer BatchNorm22
I0927 19:02:46.394246  3577 net.cpp:84] Creating Layer BatchNorm22
I0927 19:02:46.394249  3577 net.cpp:406] BatchNorm22 <- Convolution22
I0927 19:02:46.394254  3577 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0927 19:02:46.394418  3577 net.cpp:122] Setting up BatchNorm22
I0927 19:02:46.394423  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.394424  3577 net.cpp:137] Memory required for data: 718849200
I0927 19:02:46.394429  3577 layer_factory.hpp:77] Creating layer Scale22
I0927 19:02:46.394433  3577 net.cpp:84] Creating Layer Scale22
I0927 19:02:46.394436  3577 net.cpp:406] Scale22 <- Convolution22
I0927 19:02:46.394439  3577 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0927 19:02:46.394472  3577 layer_factory.hpp:77] Creating layer Scale22
I0927 19:02:46.394580  3577 net.cpp:122] Setting up Scale22
I0927 19:02:46.394587  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.394588  3577 net.cpp:137] Memory required for data: 722126000
I0927 19:02:46.394598  3577 layer_factory.hpp:77] Creating layer Eltwise10
I0927 19:02:46.394603  3577 net.cpp:84] Creating Layer Eltwise10
I0927 19:02:46.394606  3577 net.cpp:406] Eltwise10 <- Convolution20
I0927 19:02:46.394609  3577 net.cpp:406] Eltwise10 <- Convolution22
I0927 19:02:46.394613  3577 net.cpp:380] Eltwise10 -> Eltwise10
I0927 19:02:46.394630  3577 net.cpp:122] Setting up Eltwise10
I0927 19:02:46.394634  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.394636  3577 net.cpp:137] Memory required for data: 725402800
I0927 19:02:46.394639  3577 layer_factory.hpp:77] Creating layer M2PELU21
I0927 19:02:46.394644  3577 net.cpp:84] Creating Layer M2PELU21
I0927 19:02:46.394646  3577 net.cpp:406] M2PELU21 <- Eltwise10
I0927 19:02:46.394649  3577 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0927 19:02:46.394752  3577 net.cpp:122] Setting up M2PELU21
I0927 19:02:46.394757  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.394758  3577 net.cpp:137] Memory required for data: 728679600
I0927 19:02:46.394762  3577 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0927 19:02:46.394767  3577 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0927 19:02:46.394768  3577 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0927 19:02:46.394773  3577 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0927 19:02:46.394776  3577 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0927 19:02:46.394805  3577 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0927 19:02:46.394809  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.394811  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.394814  3577 net.cpp:137] Memory required for data: 735233200
I0927 19:02:46.394816  3577 layer_factory.hpp:77] Creating layer Convolution23
I0927 19:02:46.394821  3577 net.cpp:84] Creating Layer Convolution23
I0927 19:02:46.394824  3577 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0927 19:02:46.394829  3577 net.cpp:380] Convolution23 -> Convolution23
I0927 19:02:46.395962  3577 net.cpp:122] Setting up Convolution23
I0927 19:02:46.395972  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.395974  3577 net.cpp:137] Memory required for data: 738510000
I0927 19:02:46.395978  3577 layer_factory.hpp:77] Creating layer BatchNorm23
I0927 19:02:46.395983  3577 net.cpp:84] Creating Layer BatchNorm23
I0927 19:02:46.395987  3577 net.cpp:406] BatchNorm23 <- Convolution23
I0927 19:02:46.395990  3577 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0927 19:02:46.396150  3577 net.cpp:122] Setting up BatchNorm23
I0927 19:02:46.396155  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.396157  3577 net.cpp:137] Memory required for data: 741786800
I0927 19:02:46.396162  3577 layer_factory.hpp:77] Creating layer Scale23
I0927 19:02:46.396167  3577 net.cpp:84] Creating Layer Scale23
I0927 19:02:46.396168  3577 net.cpp:406] Scale23 <- Convolution23
I0927 19:02:46.396172  3577 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0927 19:02:46.396204  3577 layer_factory.hpp:77] Creating layer Scale23
I0927 19:02:46.396296  3577 net.cpp:122] Setting up Scale23
I0927 19:02:46.396301  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.396302  3577 net.cpp:137] Memory required for data: 745063600
I0927 19:02:46.396306  3577 layer_factory.hpp:77] Creating layer M2PELU22
I0927 19:02:46.396311  3577 net.cpp:84] Creating Layer M2PELU22
I0927 19:02:46.396313  3577 net.cpp:406] M2PELU22 <- Convolution23
I0927 19:02:46.396317  3577 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0927 19:02:46.396415  3577 net.cpp:122] Setting up M2PELU22
I0927 19:02:46.396420  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.396421  3577 net.cpp:137] Memory required for data: 748340400
I0927 19:02:46.396425  3577 layer_factory.hpp:77] Creating layer Convolution24
I0927 19:02:46.396433  3577 net.cpp:84] Creating Layer Convolution24
I0927 19:02:46.396441  3577 net.cpp:406] Convolution24 <- Convolution23
I0927 19:02:46.396446  3577 net.cpp:380] Convolution24 -> Convolution24
I0927 19:02:46.397591  3577 net.cpp:122] Setting up Convolution24
I0927 19:02:46.397599  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.397603  3577 net.cpp:137] Memory required for data: 751617200
I0927 19:02:46.397606  3577 layer_factory.hpp:77] Creating layer BatchNorm24
I0927 19:02:46.397611  3577 net.cpp:84] Creating Layer BatchNorm24
I0927 19:02:46.397614  3577 net.cpp:406] BatchNorm24 <- Convolution24
I0927 19:02:46.397619  3577 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0927 19:02:46.398268  3577 net.cpp:122] Setting up BatchNorm24
I0927 19:02:46.398277  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.398279  3577 net.cpp:137] Memory required for data: 754894000
I0927 19:02:46.398285  3577 layer_factory.hpp:77] Creating layer Scale24
I0927 19:02:46.398289  3577 net.cpp:84] Creating Layer Scale24
I0927 19:02:46.398293  3577 net.cpp:406] Scale24 <- Convolution24
I0927 19:02:46.398295  3577 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0927 19:02:46.398324  3577 layer_factory.hpp:77] Creating layer Scale24
I0927 19:02:46.398397  3577 net.cpp:122] Setting up Scale24
I0927 19:02:46.398401  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.398404  3577 net.cpp:137] Memory required for data: 758170800
I0927 19:02:46.398408  3577 layer_factory.hpp:77] Creating layer Eltwise11
I0927 19:02:46.398411  3577 net.cpp:84] Creating Layer Eltwise11
I0927 19:02:46.398414  3577 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0927 19:02:46.398417  3577 net.cpp:406] Eltwise11 <- Convolution24
I0927 19:02:46.398421  3577 net.cpp:380] Eltwise11 -> Eltwise11
I0927 19:02:46.398432  3577 net.cpp:122] Setting up Eltwise11
I0927 19:02:46.398437  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.398438  3577 net.cpp:137] Memory required for data: 761447600
I0927 19:02:46.398440  3577 layer_factory.hpp:77] Creating layer M2PELU23
I0927 19:02:46.398445  3577 net.cpp:84] Creating Layer M2PELU23
I0927 19:02:46.398447  3577 net.cpp:406] M2PELU23 <- Eltwise11
I0927 19:02:46.398450  3577 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0927 19:02:46.398551  3577 net.cpp:122] Setting up M2PELU23
I0927 19:02:46.398567  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.398569  3577 net.cpp:137] Memory required for data: 764724400
I0927 19:02:46.398573  3577 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0927 19:02:46.398577  3577 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0927 19:02:46.398579  3577 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0927 19:02:46.398582  3577 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0927 19:02:46.398587  3577 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0927 19:02:46.398612  3577 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0927 19:02:46.398614  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.398617  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.398619  3577 net.cpp:137] Memory required for data: 771278000
I0927 19:02:46.398622  3577 layer_factory.hpp:77] Creating layer Convolution25
I0927 19:02:46.398628  3577 net.cpp:84] Creating Layer Convolution25
I0927 19:02:46.398632  3577 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0927 19:02:46.398635  3577 net.cpp:380] Convolution25 -> Convolution25
I0927 19:02:46.399792  3577 net.cpp:122] Setting up Convolution25
I0927 19:02:46.399801  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.399803  3577 net.cpp:137] Memory required for data: 774554800
I0927 19:02:46.399808  3577 layer_factory.hpp:77] Creating layer BatchNorm25
I0927 19:02:46.399813  3577 net.cpp:84] Creating Layer BatchNorm25
I0927 19:02:46.399816  3577 net.cpp:406] BatchNorm25 <- Convolution25
I0927 19:02:46.399821  3577 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0927 19:02:46.399950  3577 net.cpp:122] Setting up BatchNorm25
I0927 19:02:46.399961  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.399963  3577 net.cpp:137] Memory required for data: 777831600
I0927 19:02:46.399968  3577 layer_factory.hpp:77] Creating layer Scale25
I0927 19:02:46.399972  3577 net.cpp:84] Creating Layer Scale25
I0927 19:02:46.399976  3577 net.cpp:406] Scale25 <- Convolution25
I0927 19:02:46.399979  3577 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0927 19:02:46.400007  3577 layer_factory.hpp:77] Creating layer Scale25
I0927 19:02:46.400080  3577 net.cpp:122] Setting up Scale25
I0927 19:02:46.400084  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.400086  3577 net.cpp:137] Memory required for data: 781108400
I0927 19:02:46.400090  3577 layer_factory.hpp:77] Creating layer M2PELU24
I0927 19:02:46.400094  3577 net.cpp:84] Creating Layer M2PELU24
I0927 19:02:46.400096  3577 net.cpp:406] M2PELU24 <- Convolution25
I0927 19:02:46.400100  3577 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0927 19:02:46.400183  3577 net.cpp:122] Setting up M2PELU24
I0927 19:02:46.400187  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.400189  3577 net.cpp:137] Memory required for data: 784385200
I0927 19:02:46.400193  3577 layer_factory.hpp:77] Creating layer Convolution26
I0927 19:02:46.400202  3577 net.cpp:84] Creating Layer Convolution26
I0927 19:02:46.400203  3577 net.cpp:406] Convolution26 <- Convolution25
I0927 19:02:46.400208  3577 net.cpp:380] Convolution26 -> Convolution26
I0927 19:02:46.400992  3577 net.cpp:122] Setting up Convolution26
I0927 19:02:46.401000  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.401003  3577 net.cpp:137] Memory required for data: 787662000
I0927 19:02:46.401007  3577 layer_factory.hpp:77] Creating layer BatchNorm26
I0927 19:02:46.401012  3577 net.cpp:84] Creating Layer BatchNorm26
I0927 19:02:46.401015  3577 net.cpp:406] BatchNorm26 <- Convolution26
I0927 19:02:46.401018  3577 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0927 19:02:46.401149  3577 net.cpp:122] Setting up BatchNorm26
I0927 19:02:46.401154  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.401156  3577 net.cpp:137] Memory required for data: 790938800
I0927 19:02:46.401161  3577 layer_factory.hpp:77] Creating layer Scale26
I0927 19:02:46.401165  3577 net.cpp:84] Creating Layer Scale26
I0927 19:02:46.420547  3577 net.cpp:406] Scale26 <- Convolution26
I0927 19:02:46.420560  3577 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0927 19:02:46.420610  3577 layer_factory.hpp:77] Creating layer Scale26
I0927 19:02:46.420696  3577 net.cpp:122] Setting up Scale26
I0927 19:02:46.420702  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.420704  3577 net.cpp:137] Memory required for data: 794215600
I0927 19:02:46.420709  3577 layer_factory.hpp:77] Creating layer Eltwise12
I0927 19:02:46.420714  3577 net.cpp:84] Creating Layer Eltwise12
I0927 19:02:46.420717  3577 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0927 19:02:46.420720  3577 net.cpp:406] Eltwise12 <- Convolution26
I0927 19:02:46.420724  3577 net.cpp:380] Eltwise12 -> Eltwise12
I0927 19:02:46.420737  3577 net.cpp:122] Setting up Eltwise12
I0927 19:02:46.420742  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.420743  3577 net.cpp:137] Memory required for data: 797492400
I0927 19:02:46.420745  3577 layer_factory.hpp:77] Creating layer M2PELU25
I0927 19:02:46.420759  3577 net.cpp:84] Creating Layer M2PELU25
I0927 19:02:46.420763  3577 net.cpp:406] M2PELU25 <- Eltwise12
I0927 19:02:46.420765  3577 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0927 19:02:46.420861  3577 net.cpp:122] Setting up M2PELU25
I0927 19:02:46.420866  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.420868  3577 net.cpp:137] Memory required for data: 800769200
I0927 19:02:46.420872  3577 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0927 19:02:46.420877  3577 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0927 19:02:46.420881  3577 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0927 19:02:46.420892  3577 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0927 19:02:46.420897  3577 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0927 19:02:46.420925  3577 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0927 19:02:46.420929  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.420933  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.420934  3577 net.cpp:137] Memory required for data: 807322800
I0927 19:02:46.420938  3577 layer_factory.hpp:77] Creating layer Convolution27
I0927 19:02:46.420943  3577 net.cpp:84] Creating Layer Convolution27
I0927 19:02:46.420946  3577 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0927 19:02:46.420951  3577 net.cpp:380] Convolution27 -> Convolution27
I0927 19:02:46.422557  3577 net.cpp:122] Setting up Convolution27
I0927 19:02:46.422566  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.422569  3577 net.cpp:137] Memory required for data: 810599600
I0927 19:02:46.422574  3577 layer_factory.hpp:77] Creating layer BatchNorm27
I0927 19:02:46.422580  3577 net.cpp:84] Creating Layer BatchNorm27
I0927 19:02:46.422583  3577 net.cpp:406] BatchNorm27 <- Convolution27
I0927 19:02:46.422588  3577 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0927 19:02:46.422719  3577 net.cpp:122] Setting up BatchNorm27
I0927 19:02:46.422722  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.422724  3577 net.cpp:137] Memory required for data: 813876400
I0927 19:02:46.422729  3577 layer_factory.hpp:77] Creating layer Scale27
I0927 19:02:46.422734  3577 net.cpp:84] Creating Layer Scale27
I0927 19:02:46.422736  3577 net.cpp:406] Scale27 <- Convolution27
I0927 19:02:46.422740  3577 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0927 19:02:46.422766  3577 layer_factory.hpp:77] Creating layer Scale27
I0927 19:02:46.422840  3577 net.cpp:122] Setting up Scale27
I0927 19:02:46.422845  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.422847  3577 net.cpp:137] Memory required for data: 817153200
I0927 19:02:46.422852  3577 layer_factory.hpp:77] Creating layer M2PELU26
I0927 19:02:46.422855  3577 net.cpp:84] Creating Layer M2PELU26
I0927 19:02:46.422858  3577 net.cpp:406] M2PELU26 <- Convolution27
I0927 19:02:46.422863  3577 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0927 19:02:46.422946  3577 net.cpp:122] Setting up M2PELU26
I0927 19:02:46.422950  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.422953  3577 net.cpp:137] Memory required for data: 820430000
I0927 19:02:46.422956  3577 layer_factory.hpp:77] Creating layer Convolution28
I0927 19:02:46.422963  3577 net.cpp:84] Creating Layer Convolution28
I0927 19:02:46.422966  3577 net.cpp:406] Convolution28 <- Convolution27
I0927 19:02:46.422971  3577 net.cpp:380] Convolution28 -> Convolution28
I0927 19:02:46.424500  3577 net.cpp:122] Setting up Convolution28
I0927 19:02:46.424510  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.424513  3577 net.cpp:137] Memory required for data: 823706800
I0927 19:02:46.424518  3577 layer_factory.hpp:77] Creating layer BatchNorm28
I0927 19:02:46.424525  3577 net.cpp:84] Creating Layer BatchNorm28
I0927 19:02:46.424526  3577 net.cpp:406] BatchNorm28 <- Convolution28
I0927 19:02:46.424530  3577 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0927 19:02:46.424669  3577 net.cpp:122] Setting up BatchNorm28
I0927 19:02:46.424674  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.424675  3577 net.cpp:137] Memory required for data: 826983600
I0927 19:02:46.424680  3577 layer_factory.hpp:77] Creating layer Scale28
I0927 19:02:46.424685  3577 net.cpp:84] Creating Layer Scale28
I0927 19:02:46.424687  3577 net.cpp:406] Scale28 <- Convolution28
I0927 19:02:46.424690  3577 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0927 19:02:46.424720  3577 layer_factory.hpp:77] Creating layer Scale28
I0927 19:02:46.424798  3577 net.cpp:122] Setting up Scale28
I0927 19:02:46.424803  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.424813  3577 net.cpp:137] Memory required for data: 830260400
I0927 19:02:46.424818  3577 layer_factory.hpp:77] Creating layer Eltwise13
I0927 19:02:46.424823  3577 net.cpp:84] Creating Layer Eltwise13
I0927 19:02:46.424825  3577 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0927 19:02:46.424829  3577 net.cpp:406] Eltwise13 <- Convolution28
I0927 19:02:46.424832  3577 net.cpp:380] Eltwise13 -> Eltwise13
I0927 19:02:46.424845  3577 net.cpp:122] Setting up Eltwise13
I0927 19:02:46.424849  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.424851  3577 net.cpp:137] Memory required for data: 833537200
I0927 19:02:46.424854  3577 layer_factory.hpp:77] Creating layer M2PELU27
I0927 19:02:46.424860  3577 net.cpp:84] Creating Layer M2PELU27
I0927 19:02:46.424861  3577 net.cpp:406] M2PELU27 <- Eltwise13
I0927 19:02:46.424865  3577 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0927 19:02:46.424954  3577 net.cpp:122] Setting up M2PELU27
I0927 19:02:46.424959  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.424962  3577 net.cpp:137] Memory required for data: 836814000
I0927 19:02:46.424965  3577 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0927 19:02:46.424969  3577 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0927 19:02:46.424971  3577 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0927 19:02:46.424974  3577 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0927 19:02:46.424980  3577 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0927 19:02:46.425004  3577 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0927 19:02:46.425009  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.425010  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.425014  3577 net.cpp:137] Memory required for data: 843367600
I0927 19:02:46.425015  3577 layer_factory.hpp:77] Creating layer Convolution29
I0927 19:02:46.425020  3577 net.cpp:84] Creating Layer Convolution29
I0927 19:02:46.425024  3577 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0927 19:02:46.425029  3577 net.cpp:380] Convolution29 -> Convolution29
I0927 19:02:46.426156  3577 net.cpp:122] Setting up Convolution29
I0927 19:02:46.426165  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.426168  3577 net.cpp:137] Memory required for data: 846644400
I0927 19:02:46.426172  3577 layer_factory.hpp:77] Creating layer BatchNorm29
I0927 19:02:46.426178  3577 net.cpp:84] Creating Layer BatchNorm29
I0927 19:02:46.426182  3577 net.cpp:406] BatchNorm29 <- Convolution29
I0927 19:02:46.426185  3577 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0927 19:02:46.426318  3577 net.cpp:122] Setting up BatchNorm29
I0927 19:02:46.426323  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.426326  3577 net.cpp:137] Memory required for data: 849921200
I0927 19:02:46.426331  3577 layer_factory.hpp:77] Creating layer Scale29
I0927 19:02:46.426336  3577 net.cpp:84] Creating Layer Scale29
I0927 19:02:46.426337  3577 net.cpp:406] Scale29 <- Convolution29
I0927 19:02:46.426342  3577 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0927 19:02:46.426368  3577 layer_factory.hpp:77] Creating layer Scale29
I0927 19:02:46.426445  3577 net.cpp:122] Setting up Scale29
I0927 19:02:46.426450  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.426451  3577 net.cpp:137] Memory required for data: 853198000
I0927 19:02:46.426476  3577 layer_factory.hpp:77] Creating layer M2PELU28
I0927 19:02:46.426481  3577 net.cpp:84] Creating Layer M2PELU28
I0927 19:02:46.426484  3577 net.cpp:406] M2PELU28 <- Convolution29
I0927 19:02:46.426488  3577 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0927 19:02:46.426584  3577 net.cpp:122] Setting up M2PELU28
I0927 19:02:46.426589  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.426591  3577 net.cpp:137] Memory required for data: 856474800
I0927 19:02:46.426595  3577 layer_factory.hpp:77] Creating layer Convolution30
I0927 19:02:46.426609  3577 net.cpp:84] Creating Layer Convolution30
I0927 19:02:46.426612  3577 net.cpp:406] Convolution30 <- Convolution29
I0927 19:02:46.426617  3577 net.cpp:380] Convolution30 -> Convolution30
I0927 19:02:46.427748  3577 net.cpp:122] Setting up Convolution30
I0927 19:02:46.427757  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.427760  3577 net.cpp:137] Memory required for data: 859751600
I0927 19:02:46.427764  3577 layer_factory.hpp:77] Creating layer BatchNorm30
I0927 19:02:46.427770  3577 net.cpp:84] Creating Layer BatchNorm30
I0927 19:02:46.427773  3577 net.cpp:406] BatchNorm30 <- Convolution30
I0927 19:02:46.427778  3577 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0927 19:02:46.427908  3577 net.cpp:122] Setting up BatchNorm30
I0927 19:02:46.427913  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.427916  3577 net.cpp:137] Memory required for data: 863028400
I0927 19:02:46.427920  3577 layer_factory.hpp:77] Creating layer Scale30
I0927 19:02:46.427924  3577 net.cpp:84] Creating Layer Scale30
I0927 19:02:46.427927  3577 net.cpp:406] Scale30 <- Convolution30
I0927 19:02:46.427930  3577 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0927 19:02:46.427958  3577 layer_factory.hpp:77] Creating layer Scale30
I0927 19:02:46.428031  3577 net.cpp:122] Setting up Scale30
I0927 19:02:46.428036  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.428040  3577 net.cpp:137] Memory required for data: 866305200
I0927 19:02:46.428042  3577 layer_factory.hpp:77] Creating layer Eltwise14
I0927 19:02:46.428046  3577 net.cpp:84] Creating Layer Eltwise14
I0927 19:02:46.428050  3577 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0927 19:02:46.428052  3577 net.cpp:406] Eltwise14 <- Convolution30
I0927 19:02:46.428056  3577 net.cpp:380] Eltwise14 -> Eltwise14
I0927 19:02:46.428069  3577 net.cpp:122] Setting up Eltwise14
I0927 19:02:46.428072  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.428074  3577 net.cpp:137] Memory required for data: 869582000
I0927 19:02:46.428076  3577 layer_factory.hpp:77] Creating layer M2PELU29
I0927 19:02:46.428082  3577 net.cpp:84] Creating Layer M2PELU29
I0927 19:02:46.428084  3577 net.cpp:406] M2PELU29 <- Eltwise14
I0927 19:02:46.428087  3577 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0927 19:02:46.428176  3577 net.cpp:122] Setting up M2PELU29
I0927 19:02:46.428182  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.428184  3577 net.cpp:137] Memory required for data: 872858800
I0927 19:02:46.428187  3577 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0927 19:02:46.428191  3577 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0927 19:02:46.428194  3577 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0927 19:02:46.428197  3577 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0927 19:02:46.428201  3577 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0927 19:02:46.428225  3577 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0927 19:02:46.428230  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.428232  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.428234  3577 net.cpp:137] Memory required for data: 879412400
I0927 19:02:46.428236  3577 layer_factory.hpp:77] Creating layer Convolution31
I0927 19:02:46.428242  3577 net.cpp:84] Creating Layer Convolution31
I0927 19:02:46.428246  3577 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0927 19:02:46.428249  3577 net.cpp:380] Convolution31 -> Convolution31
I0927 19:02:46.429373  3577 net.cpp:122] Setting up Convolution31
I0927 19:02:46.429383  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.429385  3577 net.cpp:137] Memory required for data: 882689200
I0927 19:02:46.429389  3577 layer_factory.hpp:77] Creating layer BatchNorm31
I0927 19:02:46.429395  3577 net.cpp:84] Creating Layer BatchNorm31
I0927 19:02:46.429397  3577 net.cpp:406] BatchNorm31 <- Convolution31
I0927 19:02:46.429402  3577 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0927 19:02:46.429538  3577 net.cpp:122] Setting up BatchNorm31
I0927 19:02:46.429543  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.429545  3577 net.cpp:137] Memory required for data: 885966000
I0927 19:02:46.429550  3577 layer_factory.hpp:77] Creating layer Scale31
I0927 19:02:46.429554  3577 net.cpp:84] Creating Layer Scale31
I0927 19:02:46.429556  3577 net.cpp:406] Scale31 <- Convolution31
I0927 19:02:46.429560  3577 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0927 19:02:46.429587  3577 layer_factory.hpp:77] Creating layer Scale31
I0927 19:02:46.429662  3577 net.cpp:122] Setting up Scale31
I0927 19:02:46.429667  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.429669  3577 net.cpp:137] Memory required for data: 889242800
I0927 19:02:46.429673  3577 layer_factory.hpp:77] Creating layer M2PELU30
I0927 19:02:46.429678  3577 net.cpp:84] Creating Layer M2PELU30
I0927 19:02:46.429680  3577 net.cpp:406] M2PELU30 <- Convolution31
I0927 19:02:46.429685  3577 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0927 19:02:46.429769  3577 net.cpp:122] Setting up M2PELU30
I0927 19:02:46.429772  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.429774  3577 net.cpp:137] Memory required for data: 892519600
I0927 19:02:46.429778  3577 layer_factory.hpp:77] Creating layer Convolution32
I0927 19:02:46.429785  3577 net.cpp:84] Creating Layer Convolution32
I0927 19:02:46.429787  3577 net.cpp:406] Convolution32 <- Convolution31
I0927 19:02:46.429792  3577 net.cpp:380] Convolution32 -> Convolution32
I0927 19:02:46.430922  3577 net.cpp:122] Setting up Convolution32
I0927 19:02:46.430930  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.430933  3577 net.cpp:137] Memory required for data: 895796400
I0927 19:02:46.430938  3577 layer_factory.hpp:77] Creating layer BatchNorm32
I0927 19:02:46.430943  3577 net.cpp:84] Creating Layer BatchNorm32
I0927 19:02:46.430944  3577 net.cpp:406] BatchNorm32 <- Convolution32
I0927 19:02:46.430949  3577 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0927 19:02:46.431082  3577 net.cpp:122] Setting up BatchNorm32
I0927 19:02:46.431087  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.451535  3577 net.cpp:137] Memory required for data: 899073200
I0927 19:02:46.451551  3577 layer_factory.hpp:77] Creating layer Scale32
I0927 19:02:46.451558  3577 net.cpp:84] Creating Layer Scale32
I0927 19:02:46.451563  3577 net.cpp:406] Scale32 <- Convolution32
I0927 19:02:46.451570  3577 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0927 19:02:46.451616  3577 layer_factory.hpp:77] Creating layer Scale32
I0927 19:02:46.451702  3577 net.cpp:122] Setting up Scale32
I0927 19:02:46.451707  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.451709  3577 net.cpp:137] Memory required for data: 902350000
I0927 19:02:46.451714  3577 layer_factory.hpp:77] Creating layer Eltwise15
I0927 19:02:46.451719  3577 net.cpp:84] Creating Layer Eltwise15
I0927 19:02:46.451721  3577 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0927 19:02:46.451725  3577 net.cpp:406] Eltwise15 <- Convolution32
I0927 19:02:46.451730  3577 net.cpp:380] Eltwise15 -> Eltwise15
I0927 19:02:46.451742  3577 net.cpp:122] Setting up Eltwise15
I0927 19:02:46.451746  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.451748  3577 net.cpp:137] Memory required for data: 905626800
I0927 19:02:46.451750  3577 layer_factory.hpp:77] Creating layer M2PELU31
I0927 19:02:46.451756  3577 net.cpp:84] Creating Layer M2PELU31
I0927 19:02:46.451758  3577 net.cpp:406] M2PELU31 <- Eltwise15
I0927 19:02:46.451762  3577 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0927 19:02:46.451858  3577 net.cpp:122] Setting up M2PELU31
I0927 19:02:46.451861  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.451864  3577 net.cpp:137] Memory required for data: 908903600
I0927 19:02:46.451869  3577 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0927 19:02:46.451874  3577 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0927 19:02:46.451882  3577 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0927 19:02:46.451886  3577 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0927 19:02:46.451891  3577 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0927 19:02:46.451918  3577 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0927 19:02:46.451922  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.451925  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.451928  3577 net.cpp:137] Memory required for data: 915457200
I0927 19:02:46.451930  3577 layer_factory.hpp:77] Creating layer Convolution33
I0927 19:02:46.451937  3577 net.cpp:84] Creating Layer Convolution33
I0927 19:02:46.451941  3577 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0927 19:02:46.451944  3577 net.cpp:380] Convolution33 -> Convolution33
I0927 19:02:46.453199  3577 net.cpp:122] Setting up Convolution33
I0927 19:02:46.453208  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.453212  3577 net.cpp:137] Memory required for data: 918734000
I0927 19:02:46.453215  3577 layer_factory.hpp:77] Creating layer BatchNorm33
I0927 19:02:46.453222  3577 net.cpp:84] Creating Layer BatchNorm33
I0927 19:02:46.453224  3577 net.cpp:406] BatchNorm33 <- Convolution33
I0927 19:02:46.453228  3577 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0927 19:02:46.453368  3577 net.cpp:122] Setting up BatchNorm33
I0927 19:02:46.453373  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.453377  3577 net.cpp:137] Memory required for data: 922010800
I0927 19:02:46.453380  3577 layer_factory.hpp:77] Creating layer Scale33
I0927 19:02:46.453384  3577 net.cpp:84] Creating Layer Scale33
I0927 19:02:46.453387  3577 net.cpp:406] Scale33 <- Convolution33
I0927 19:02:46.453390  3577 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0927 19:02:46.453418  3577 layer_factory.hpp:77] Creating layer Scale33
I0927 19:02:46.453492  3577 net.cpp:122] Setting up Scale33
I0927 19:02:46.453496  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.453498  3577 net.cpp:137] Memory required for data: 925287600
I0927 19:02:46.453503  3577 layer_factory.hpp:77] Creating layer M2PELU32
I0927 19:02:46.453508  3577 net.cpp:84] Creating Layer M2PELU32
I0927 19:02:46.453510  3577 net.cpp:406] M2PELU32 <- Convolution33
I0927 19:02:46.453514  3577 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0927 19:02:46.453599  3577 net.cpp:122] Setting up M2PELU32
I0927 19:02:46.453604  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.453606  3577 net.cpp:137] Memory required for data: 928564400
I0927 19:02:46.453610  3577 layer_factory.hpp:77] Creating layer Convolution34
I0927 19:02:46.453616  3577 net.cpp:84] Creating Layer Convolution34
I0927 19:02:46.453619  3577 net.cpp:406] Convolution34 <- Convolution33
I0927 19:02:46.453624  3577 net.cpp:380] Convolution34 -> Convolution34
I0927 19:02:46.455471  3577 net.cpp:122] Setting up Convolution34
I0927 19:02:46.455483  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.455487  3577 net.cpp:137] Memory required for data: 931841200
I0927 19:02:46.455492  3577 layer_factory.hpp:77] Creating layer BatchNorm34
I0927 19:02:46.455497  3577 net.cpp:84] Creating Layer BatchNorm34
I0927 19:02:46.455499  3577 net.cpp:406] BatchNorm34 <- Convolution34
I0927 19:02:46.455503  3577 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0927 19:02:46.455639  3577 net.cpp:122] Setting up BatchNorm34
I0927 19:02:46.455646  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.455651  3577 net.cpp:137] Memory required for data: 935118000
I0927 19:02:46.455658  3577 layer_factory.hpp:77] Creating layer Scale34
I0927 19:02:46.455667  3577 net.cpp:84] Creating Layer Scale34
I0927 19:02:46.455670  3577 net.cpp:406] Scale34 <- Convolution34
I0927 19:02:46.455673  3577 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0927 19:02:46.455704  3577 layer_factory.hpp:77] Creating layer Scale34
I0927 19:02:46.455780  3577 net.cpp:122] Setting up Scale34
I0927 19:02:46.455792  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.455796  3577 net.cpp:137] Memory required for data: 938394800
I0927 19:02:46.455799  3577 layer_factory.hpp:77] Creating layer Eltwise16
I0927 19:02:46.455803  3577 net.cpp:84] Creating Layer Eltwise16
I0927 19:02:46.455806  3577 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0927 19:02:46.455811  3577 net.cpp:406] Eltwise16 <- Convolution34
I0927 19:02:46.455813  3577 net.cpp:380] Eltwise16 -> Eltwise16
I0927 19:02:46.455827  3577 net.cpp:122] Setting up Eltwise16
I0927 19:02:46.455832  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.455834  3577 net.cpp:137] Memory required for data: 941671600
I0927 19:02:46.455837  3577 layer_factory.hpp:77] Creating layer M2PELU33
I0927 19:02:46.455842  3577 net.cpp:84] Creating Layer M2PELU33
I0927 19:02:46.455844  3577 net.cpp:406] M2PELU33 <- Eltwise16
I0927 19:02:46.455847  3577 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0927 19:02:46.455934  3577 net.cpp:122] Setting up M2PELU33
I0927 19:02:46.455938  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.455940  3577 net.cpp:137] Memory required for data: 944948400
I0927 19:02:46.455943  3577 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0927 19:02:46.455947  3577 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0927 19:02:46.455950  3577 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0927 19:02:46.455955  3577 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0927 19:02:46.455958  3577 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0927 19:02:46.455981  3577 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0927 19:02:46.455984  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.455987  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.455989  3577 net.cpp:137] Memory required for data: 951502000
I0927 19:02:46.455991  3577 layer_factory.hpp:77] Creating layer Convolution35
I0927 19:02:46.456001  3577 net.cpp:84] Creating Layer Convolution35
I0927 19:02:46.456003  3577 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0927 19:02:46.456007  3577 net.cpp:380] Convolution35 -> Convolution35
I0927 19:02:46.457119  3577 net.cpp:122] Setting up Convolution35
I0927 19:02:46.457129  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.457131  3577 net.cpp:137] Memory required for data: 954778800
I0927 19:02:46.457135  3577 layer_factory.hpp:77] Creating layer BatchNorm35
I0927 19:02:46.457140  3577 net.cpp:84] Creating Layer BatchNorm35
I0927 19:02:46.457144  3577 net.cpp:406] BatchNorm35 <- Convolution35
I0927 19:02:46.457147  3577 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0927 19:02:46.457280  3577 net.cpp:122] Setting up BatchNorm35
I0927 19:02:46.457284  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.457286  3577 net.cpp:137] Memory required for data: 958055600
I0927 19:02:46.457291  3577 layer_factory.hpp:77] Creating layer Scale35
I0927 19:02:46.457296  3577 net.cpp:84] Creating Layer Scale35
I0927 19:02:46.457299  3577 net.cpp:406] Scale35 <- Convolution35
I0927 19:02:46.457303  3577 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0927 19:02:46.457330  3577 layer_factory.hpp:77] Creating layer Scale35
I0927 19:02:46.457406  3577 net.cpp:122] Setting up Scale35
I0927 19:02:46.457409  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.457412  3577 net.cpp:137] Memory required for data: 961332400
I0927 19:02:46.457415  3577 layer_factory.hpp:77] Creating layer M2PELU34
I0927 19:02:46.457420  3577 net.cpp:84] Creating Layer M2PELU34
I0927 19:02:46.457423  3577 net.cpp:406] M2PELU34 <- Convolution35
I0927 19:02:46.457427  3577 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0927 19:02:46.457507  3577 net.cpp:122] Setting up M2PELU34
I0927 19:02:46.457512  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.457515  3577 net.cpp:137] Memory required for data: 964609200
I0927 19:02:46.457525  3577 layer_factory.hpp:77] Creating layer Convolution36
I0927 19:02:46.457532  3577 net.cpp:84] Creating Layer Convolution36
I0927 19:02:46.457535  3577 net.cpp:406] Convolution36 <- Convolution35
I0927 19:02:46.457540  3577 net.cpp:380] Convolution36 -> Convolution36
I0927 19:02:46.458302  3577 net.cpp:122] Setting up Convolution36
I0927 19:02:46.458310  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.458312  3577 net.cpp:137] Memory required for data: 967886000
I0927 19:02:46.458317  3577 layer_factory.hpp:77] Creating layer BatchNorm36
I0927 19:02:46.458320  3577 net.cpp:84] Creating Layer BatchNorm36
I0927 19:02:46.458323  3577 net.cpp:406] BatchNorm36 <- Convolution36
I0927 19:02:46.458328  3577 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0927 19:02:46.458458  3577 net.cpp:122] Setting up BatchNorm36
I0927 19:02:46.458463  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.458465  3577 net.cpp:137] Memory required for data: 971162800
I0927 19:02:46.458469  3577 layer_factory.hpp:77] Creating layer Scale36
I0927 19:02:46.458473  3577 net.cpp:84] Creating Layer Scale36
I0927 19:02:46.458477  3577 net.cpp:406] Scale36 <- Convolution36
I0927 19:02:46.458479  3577 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0927 19:02:46.458506  3577 layer_factory.hpp:77] Creating layer Scale36
I0927 19:02:46.458590  3577 net.cpp:122] Setting up Scale36
I0927 19:02:46.458595  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.458596  3577 net.cpp:137] Memory required for data: 974439600
I0927 19:02:46.458600  3577 layer_factory.hpp:77] Creating layer Eltwise17
I0927 19:02:46.458606  3577 net.cpp:84] Creating Layer Eltwise17
I0927 19:02:46.458608  3577 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0927 19:02:46.458611  3577 net.cpp:406] Eltwise17 <- Convolution36
I0927 19:02:46.458614  3577 net.cpp:380] Eltwise17 -> Eltwise17
I0927 19:02:46.458626  3577 net.cpp:122] Setting up Eltwise17
I0927 19:02:46.458631  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.458632  3577 net.cpp:137] Memory required for data: 977716400
I0927 19:02:46.458634  3577 layer_factory.hpp:77] Creating layer M2PELU35
I0927 19:02:46.458640  3577 net.cpp:84] Creating Layer M2PELU35
I0927 19:02:46.458643  3577 net.cpp:406] M2PELU35 <- Eltwise17
I0927 19:02:46.458647  3577 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0927 19:02:46.458734  3577 net.cpp:122] Setting up M2PELU35
I0927 19:02:46.458739  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.458740  3577 net.cpp:137] Memory required for data: 980993200
I0927 19:02:46.458744  3577 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0927 19:02:46.458748  3577 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0927 19:02:46.458750  3577 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0927 19:02:46.458753  3577 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0927 19:02:46.458757  3577 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0927 19:02:46.458781  3577 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0927 19:02:46.458786  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.458788  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.458791  3577 net.cpp:137] Memory required for data: 987546800
I0927 19:02:46.458792  3577 layer_factory.hpp:77] Creating layer Convolution37
I0927 19:02:46.458798  3577 net.cpp:84] Creating Layer Convolution37
I0927 19:02:46.458801  3577 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0927 19:02:46.458804  3577 net.cpp:380] Convolution37 -> Convolution37
I0927 19:02:46.459903  3577 net.cpp:122] Setting up Convolution37
I0927 19:02:46.459911  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.459914  3577 net.cpp:137] Memory required for data: 990823600
I0927 19:02:46.459918  3577 layer_factory.hpp:77] Creating layer BatchNorm37
I0927 19:02:46.459923  3577 net.cpp:84] Creating Layer BatchNorm37
I0927 19:02:46.459926  3577 net.cpp:406] BatchNorm37 <- Convolution37
I0927 19:02:46.459938  3577 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0927 19:02:46.460072  3577 net.cpp:122] Setting up BatchNorm37
I0927 19:02:46.460077  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.460078  3577 net.cpp:137] Memory required for data: 994100400
I0927 19:02:46.460083  3577 layer_factory.hpp:77] Creating layer Scale37
I0927 19:02:46.460088  3577 net.cpp:84] Creating Layer Scale37
I0927 19:02:46.460089  3577 net.cpp:406] Scale37 <- Convolution37
I0927 19:02:46.460093  3577 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0927 19:02:46.460119  3577 layer_factory.hpp:77] Creating layer Scale37
I0927 19:02:46.460196  3577 net.cpp:122] Setting up Scale37
I0927 19:02:46.460199  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.460201  3577 net.cpp:137] Memory required for data: 997377200
I0927 19:02:46.460206  3577 layer_factory.hpp:77] Creating layer M2PELU36
I0927 19:02:46.460211  3577 net.cpp:84] Creating Layer M2PELU36
I0927 19:02:46.460213  3577 net.cpp:406] M2PELU36 <- Convolution37
I0927 19:02:46.460216  3577 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0927 19:02:46.460299  3577 net.cpp:122] Setting up M2PELU36
I0927 19:02:46.460304  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.460306  3577 net.cpp:137] Memory required for data: 1000654000
I0927 19:02:46.460310  3577 layer_factory.hpp:77] Creating layer Convolution38
I0927 19:02:46.460315  3577 net.cpp:84] Creating Layer Convolution38
I0927 19:02:46.460319  3577 net.cpp:406] Convolution38 <- Convolution37
I0927 19:02:46.460322  3577 net.cpp:380] Convolution38 -> Convolution38
I0927 19:02:46.461751  3577 net.cpp:122] Setting up Convolution38
I0927 19:02:46.461760  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.461762  3577 net.cpp:137] Memory required for data: 1003930800
I0927 19:02:46.461768  3577 layer_factory.hpp:77] Creating layer BatchNorm38
I0927 19:02:46.461773  3577 net.cpp:84] Creating Layer BatchNorm38
I0927 19:02:46.461776  3577 net.cpp:406] BatchNorm38 <- Convolution38
I0927 19:02:46.484823  3577 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0927 19:02:46.485030  3577 net.cpp:122] Setting up BatchNorm38
I0927 19:02:46.485038  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.485040  3577 net.cpp:137] Memory required for data: 1007207600
I0927 19:02:46.485046  3577 layer_factory.hpp:77] Creating layer Scale38
I0927 19:02:46.485052  3577 net.cpp:84] Creating Layer Scale38
I0927 19:02:46.485055  3577 net.cpp:406] Scale38 <- Convolution38
I0927 19:02:46.485059  3577 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0927 19:02:46.485091  3577 layer_factory.hpp:77] Creating layer Scale38
I0927 19:02:46.485175  3577 net.cpp:122] Setting up Scale38
I0927 19:02:46.485180  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.485183  3577 net.cpp:137] Memory required for data: 1010484400
I0927 19:02:46.485188  3577 layer_factory.hpp:77] Creating layer Eltwise18
I0927 19:02:46.485191  3577 net.cpp:84] Creating Layer Eltwise18
I0927 19:02:46.485194  3577 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0927 19:02:46.485198  3577 net.cpp:406] Eltwise18 <- Convolution38
I0927 19:02:46.485203  3577 net.cpp:380] Eltwise18 -> Eltwise18
I0927 19:02:46.485216  3577 net.cpp:122] Setting up Eltwise18
I0927 19:02:46.485220  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.485224  3577 net.cpp:137] Memory required for data: 1013761200
I0927 19:02:46.485225  3577 layer_factory.hpp:77] Creating layer M2PELU37
I0927 19:02:46.485230  3577 net.cpp:84] Creating Layer M2PELU37
I0927 19:02:46.485232  3577 net.cpp:406] M2PELU37 <- Eltwise18
I0927 19:02:46.485236  3577 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0927 19:02:46.485333  3577 net.cpp:122] Setting up M2PELU37
I0927 19:02:46.485337  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.485340  3577 net.cpp:137] Memory required for data: 1017038000
I0927 19:02:46.485344  3577 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0927 19:02:46.485354  3577 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0927 19:02:46.485358  3577 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0927 19:02:46.485363  3577 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0927 19:02:46.485368  3577 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0927 19:02:46.485394  3577 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0927 19:02:46.485397  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.485400  3577 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 19:02:46.485404  3577 net.cpp:137] Memory required for data: 1023591600
I0927 19:02:46.485405  3577 layer_factory.hpp:77] Creating layer Convolution39
I0927 19:02:46.485412  3577 net.cpp:84] Creating Layer Convolution39
I0927 19:02:46.485415  3577 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0927 19:02:46.485420  3577 net.cpp:380] Convolution39 -> Convolution39
I0927 19:02:46.486572  3577 net.cpp:122] Setting up Convolution39
I0927 19:02:46.486582  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.486585  3577 net.cpp:137] Memory required for data: 1025230000
I0927 19:02:46.486589  3577 layer_factory.hpp:77] Creating layer BatchNorm39
I0927 19:02:46.486595  3577 net.cpp:84] Creating Layer BatchNorm39
I0927 19:02:46.486598  3577 net.cpp:406] BatchNorm39 <- Convolution39
I0927 19:02:46.486601  3577 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0927 19:02:46.486739  3577 net.cpp:122] Setting up BatchNorm39
I0927 19:02:46.486744  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.486747  3577 net.cpp:137] Memory required for data: 1026868400
I0927 19:02:46.486752  3577 layer_factory.hpp:77] Creating layer Scale39
I0927 19:02:46.486754  3577 net.cpp:84] Creating Layer Scale39
I0927 19:02:46.486757  3577 net.cpp:406] Scale39 <- Convolution39
I0927 19:02:46.486760  3577 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0927 19:02:46.486788  3577 layer_factory.hpp:77] Creating layer Scale39
I0927 19:02:46.486865  3577 net.cpp:122] Setting up Scale39
I0927 19:02:46.486870  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.486871  3577 net.cpp:137] Memory required for data: 1028506800
I0927 19:02:46.486876  3577 layer_factory.hpp:77] Creating layer Convolution40
I0927 19:02:46.486882  3577 net.cpp:84] Creating Layer Convolution40
I0927 19:02:46.486884  3577 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0927 19:02:46.486891  3577 net.cpp:380] Convolution40 -> Convolution40
I0927 19:02:46.488226  3577 net.cpp:122] Setting up Convolution40
I0927 19:02:46.488235  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.488240  3577 net.cpp:137] Memory required for data: 1030145200
I0927 19:02:46.488243  3577 layer_factory.hpp:77] Creating layer BatchNorm40
I0927 19:02:46.488248  3577 net.cpp:84] Creating Layer BatchNorm40
I0927 19:02:46.488251  3577 net.cpp:406] BatchNorm40 <- Convolution40
I0927 19:02:46.488255  3577 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0927 19:02:46.488392  3577 net.cpp:122] Setting up BatchNorm40
I0927 19:02:46.488397  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.488399  3577 net.cpp:137] Memory required for data: 1031783600
I0927 19:02:46.488404  3577 layer_factory.hpp:77] Creating layer Scale40
I0927 19:02:46.488409  3577 net.cpp:84] Creating Layer Scale40
I0927 19:02:46.488410  3577 net.cpp:406] Scale40 <- Convolution40
I0927 19:02:46.488414  3577 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0927 19:02:46.488441  3577 layer_factory.hpp:77] Creating layer Scale40
I0927 19:02:46.488518  3577 net.cpp:122] Setting up Scale40
I0927 19:02:46.488523  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.488525  3577 net.cpp:137] Memory required for data: 1033422000
I0927 19:02:46.488528  3577 layer_factory.hpp:77] Creating layer M2PELU38
I0927 19:02:46.488533  3577 net.cpp:84] Creating Layer M2PELU38
I0927 19:02:46.488535  3577 net.cpp:406] M2PELU38 <- Convolution40
I0927 19:02:46.488546  3577 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0927 19:02:46.488641  3577 net.cpp:122] Setting up M2PELU38
I0927 19:02:46.488646  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.488647  3577 net.cpp:137] Memory required for data: 1035060400
I0927 19:02:46.488651  3577 layer_factory.hpp:77] Creating layer Convolution41
I0927 19:02:46.488658  3577 net.cpp:84] Creating Layer Convolution41
I0927 19:02:46.488662  3577 net.cpp:406] Convolution41 <- Convolution40
I0927 19:02:46.488665  3577 net.cpp:380] Convolution41 -> Convolution41
I0927 19:02:46.490397  3577 net.cpp:122] Setting up Convolution41
I0927 19:02:46.490406  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.490408  3577 net.cpp:137] Memory required for data: 1036698800
I0927 19:02:46.490412  3577 layer_factory.hpp:77] Creating layer BatchNorm41
I0927 19:02:46.490418  3577 net.cpp:84] Creating Layer BatchNorm41
I0927 19:02:46.490420  3577 net.cpp:406] BatchNorm41 <- Convolution41
I0927 19:02:46.490425  3577 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0927 19:02:46.490566  3577 net.cpp:122] Setting up BatchNorm41
I0927 19:02:46.490571  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.490573  3577 net.cpp:137] Memory required for data: 1038337200
I0927 19:02:46.490578  3577 layer_factory.hpp:77] Creating layer Scale41
I0927 19:02:46.490583  3577 net.cpp:84] Creating Layer Scale41
I0927 19:02:46.490586  3577 net.cpp:406] Scale41 <- Convolution41
I0927 19:02:46.490589  3577 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0927 19:02:46.490617  3577 layer_factory.hpp:77] Creating layer Scale41
I0927 19:02:46.490695  3577 net.cpp:122] Setting up Scale41
I0927 19:02:46.490700  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.490702  3577 net.cpp:137] Memory required for data: 1039975600
I0927 19:02:46.490706  3577 layer_factory.hpp:77] Creating layer Eltwise19
I0927 19:02:46.490711  3577 net.cpp:84] Creating Layer Eltwise19
I0927 19:02:46.490715  3577 net.cpp:406] Eltwise19 <- Convolution39
I0927 19:02:46.490717  3577 net.cpp:406] Eltwise19 <- Convolution41
I0927 19:02:46.490721  3577 net.cpp:380] Eltwise19 -> Eltwise19
I0927 19:02:46.490738  3577 net.cpp:122] Setting up Eltwise19
I0927 19:02:46.490741  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.490743  3577 net.cpp:137] Memory required for data: 1041614000
I0927 19:02:46.490746  3577 layer_factory.hpp:77] Creating layer M2PELU39
I0927 19:02:46.490751  3577 net.cpp:84] Creating Layer M2PELU39
I0927 19:02:46.490753  3577 net.cpp:406] M2PELU39 <- Eltwise19
I0927 19:02:46.490756  3577 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0927 19:02:46.490846  3577 net.cpp:122] Setting up M2PELU39
I0927 19:02:46.490851  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.490854  3577 net.cpp:137] Memory required for data: 1043252400
I0927 19:02:46.490856  3577 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0927 19:02:46.490860  3577 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0927 19:02:46.490862  3577 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0927 19:02:46.490866  3577 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0927 19:02:46.490870  3577 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0927 19:02:46.490895  3577 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0927 19:02:46.490898  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.490901  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.490903  3577 net.cpp:137] Memory required for data: 1046529200
I0927 19:02:46.490906  3577 layer_factory.hpp:77] Creating layer Convolution42
I0927 19:02:46.490911  3577 net.cpp:84] Creating Layer Convolution42
I0927 19:02:46.490914  3577 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0927 19:02:46.490918  3577 net.cpp:380] Convolution42 -> Convolution42
I0927 19:02:46.492650  3577 net.cpp:122] Setting up Convolution42
I0927 19:02:46.492658  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.492667  3577 net.cpp:137] Memory required for data: 1048167600
I0927 19:02:46.492672  3577 layer_factory.hpp:77] Creating layer BatchNorm42
I0927 19:02:46.492677  3577 net.cpp:84] Creating Layer BatchNorm42
I0927 19:02:46.492681  3577 net.cpp:406] BatchNorm42 <- Convolution42
I0927 19:02:46.492686  3577 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0927 19:02:46.492822  3577 net.cpp:122] Setting up BatchNorm42
I0927 19:02:46.492826  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.492828  3577 net.cpp:137] Memory required for data: 1049806000
I0927 19:02:46.492833  3577 layer_factory.hpp:77] Creating layer Scale42
I0927 19:02:46.492837  3577 net.cpp:84] Creating Layer Scale42
I0927 19:02:46.492839  3577 net.cpp:406] Scale42 <- Convolution42
I0927 19:02:46.492842  3577 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0927 19:02:46.492871  3577 layer_factory.hpp:77] Creating layer Scale42
I0927 19:02:46.492949  3577 net.cpp:122] Setting up Scale42
I0927 19:02:46.492952  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.492955  3577 net.cpp:137] Memory required for data: 1051444400
I0927 19:02:46.492959  3577 layer_factory.hpp:77] Creating layer M2PELU40
I0927 19:02:46.492964  3577 net.cpp:84] Creating Layer M2PELU40
I0927 19:02:46.492965  3577 net.cpp:406] M2PELU40 <- Convolution42
I0927 19:02:46.492969  3577 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0927 19:02:46.493059  3577 net.cpp:122] Setting up M2PELU40
I0927 19:02:46.493063  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.493065  3577 net.cpp:137] Memory required for data: 1053082800
I0927 19:02:46.493069  3577 layer_factory.hpp:77] Creating layer Convolution43
I0927 19:02:46.493077  3577 net.cpp:84] Creating Layer Convolution43
I0927 19:02:46.493078  3577 net.cpp:406] Convolution43 <- Convolution42
I0927 19:02:46.493083  3577 net.cpp:380] Convolution43 -> Convolution43
I0927 19:02:46.494814  3577 net.cpp:122] Setting up Convolution43
I0927 19:02:46.494823  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.494827  3577 net.cpp:137] Memory required for data: 1054721200
I0927 19:02:46.494830  3577 layer_factory.hpp:77] Creating layer BatchNorm43
I0927 19:02:46.494835  3577 net.cpp:84] Creating Layer BatchNorm43
I0927 19:02:46.494838  3577 net.cpp:406] BatchNorm43 <- Convolution43
I0927 19:02:46.494843  3577 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0927 19:02:46.494982  3577 net.cpp:122] Setting up BatchNorm43
I0927 19:02:46.494987  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.494989  3577 net.cpp:137] Memory required for data: 1056359600
I0927 19:02:46.494994  3577 layer_factory.hpp:77] Creating layer Scale43
I0927 19:02:46.494999  3577 net.cpp:84] Creating Layer Scale43
I0927 19:02:46.495002  3577 net.cpp:406] Scale43 <- Convolution43
I0927 19:02:46.495005  3577 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0927 19:02:46.495033  3577 layer_factory.hpp:77] Creating layer Scale43
I0927 19:02:46.495111  3577 net.cpp:122] Setting up Scale43
I0927 19:02:46.495115  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.495117  3577 net.cpp:137] Memory required for data: 1057998000
I0927 19:02:46.495121  3577 layer_factory.hpp:77] Creating layer Eltwise20
I0927 19:02:46.495126  3577 net.cpp:84] Creating Layer Eltwise20
I0927 19:02:46.495128  3577 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0927 19:02:46.495131  3577 net.cpp:406] Eltwise20 <- Convolution43
I0927 19:02:46.495136  3577 net.cpp:380] Eltwise20 -> Eltwise20
I0927 19:02:46.495151  3577 net.cpp:122] Setting up Eltwise20
I0927 19:02:46.495156  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.495157  3577 net.cpp:137] Memory required for data: 1059636400
I0927 19:02:46.495159  3577 layer_factory.hpp:77] Creating layer M2PELU41
I0927 19:02:46.495164  3577 net.cpp:84] Creating Layer M2PELU41
I0927 19:02:46.495167  3577 net.cpp:406] M2PELU41 <- Eltwise20
I0927 19:02:46.495170  3577 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0927 19:02:46.495261  3577 net.cpp:122] Setting up M2PELU41
I0927 19:02:46.495272  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.495275  3577 net.cpp:137] Memory required for data: 1061274800
I0927 19:02:46.495278  3577 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0927 19:02:46.495282  3577 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0927 19:02:46.495285  3577 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0927 19:02:46.495290  3577 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0927 19:02:46.495293  3577 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0927 19:02:46.495318  3577 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0927 19:02:46.495322  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.495326  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.495327  3577 net.cpp:137] Memory required for data: 1064551600
I0927 19:02:46.495329  3577 layer_factory.hpp:77] Creating layer Convolution44
I0927 19:02:46.495335  3577 net.cpp:84] Creating Layer Convolution44
I0927 19:02:46.495338  3577 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0927 19:02:46.495342  3577 net.cpp:380] Convolution44 -> Convolution44
I0927 19:02:46.497395  3577 net.cpp:122] Setting up Convolution44
I0927 19:02:46.497403  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.497406  3577 net.cpp:137] Memory required for data: 1066190000
I0927 19:02:46.497411  3577 layer_factory.hpp:77] Creating layer BatchNorm44
I0927 19:02:46.497416  3577 net.cpp:84] Creating Layer BatchNorm44
I0927 19:02:46.497418  3577 net.cpp:406] BatchNorm44 <- Convolution44
I0927 19:02:46.497422  3577 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0927 19:02:46.497565  3577 net.cpp:122] Setting up BatchNorm44
I0927 19:02:46.497570  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.497571  3577 net.cpp:137] Memory required for data: 1067828400
I0927 19:02:46.512977  3577 layer_factory.hpp:77] Creating layer Scale44
I0927 19:02:46.512990  3577 net.cpp:84] Creating Layer Scale44
I0927 19:02:46.512995  3577 net.cpp:406] Scale44 <- Convolution44
I0927 19:02:46.513000  3577 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0927 19:02:46.513043  3577 layer_factory.hpp:77] Creating layer Scale44
I0927 19:02:46.513136  3577 net.cpp:122] Setting up Scale44
I0927 19:02:46.513141  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.513144  3577 net.cpp:137] Memory required for data: 1069466800
I0927 19:02:46.513149  3577 layer_factory.hpp:77] Creating layer M2PELU42
I0927 19:02:46.513154  3577 net.cpp:84] Creating Layer M2PELU42
I0927 19:02:46.513156  3577 net.cpp:406] M2PELU42 <- Convolution44
I0927 19:02:46.513160  3577 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0927 19:02:46.513262  3577 net.cpp:122] Setting up M2PELU42
I0927 19:02:46.513267  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.513269  3577 net.cpp:137] Memory required for data: 1071105200
I0927 19:02:46.513274  3577 layer_factory.hpp:77] Creating layer Convolution45
I0927 19:02:46.513281  3577 net.cpp:84] Creating Layer Convolution45
I0927 19:02:46.513284  3577 net.cpp:406] Convolution45 <- Convolution44
I0927 19:02:46.513289  3577 net.cpp:380] Convolution45 -> Convolution45
I0927 19:02:46.515271  3577 net.cpp:122] Setting up Convolution45
I0927 19:02:46.515282  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.515285  3577 net.cpp:137] Memory required for data: 1072743600
I0927 19:02:46.515290  3577 layer_factory.hpp:77] Creating layer BatchNorm45
I0927 19:02:46.515293  3577 net.cpp:84] Creating Layer BatchNorm45
I0927 19:02:46.515296  3577 net.cpp:406] BatchNorm45 <- Convolution45
I0927 19:02:46.515301  3577 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0927 19:02:46.515465  3577 net.cpp:122] Setting up BatchNorm45
I0927 19:02:46.515470  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.515472  3577 net.cpp:137] Memory required for data: 1074382000
I0927 19:02:46.515476  3577 layer_factory.hpp:77] Creating layer Scale45
I0927 19:02:46.515487  3577 net.cpp:84] Creating Layer Scale45
I0927 19:02:46.515491  3577 net.cpp:406] Scale45 <- Convolution45
I0927 19:02:46.515496  3577 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0927 19:02:46.515524  3577 layer_factory.hpp:77] Creating layer Scale45
I0927 19:02:46.515628  3577 net.cpp:122] Setting up Scale45
I0927 19:02:46.515645  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.515647  3577 net.cpp:137] Memory required for data: 1076020400
I0927 19:02:46.515655  3577 layer_factory.hpp:77] Creating layer Eltwise21
I0927 19:02:46.515661  3577 net.cpp:84] Creating Layer Eltwise21
I0927 19:02:46.515664  3577 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0927 19:02:46.515669  3577 net.cpp:406] Eltwise21 <- Convolution45
I0927 19:02:46.515678  3577 net.cpp:380] Eltwise21 -> Eltwise21
I0927 19:02:46.515704  3577 net.cpp:122] Setting up Eltwise21
I0927 19:02:46.515710  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.515712  3577 net.cpp:137] Memory required for data: 1077658800
I0927 19:02:46.515715  3577 layer_factory.hpp:77] Creating layer M2PELU43
I0927 19:02:46.515719  3577 net.cpp:84] Creating Layer M2PELU43
I0927 19:02:46.515722  3577 net.cpp:406] M2PELU43 <- Eltwise21
I0927 19:02:46.515727  3577 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0927 19:02:46.515820  3577 net.cpp:122] Setting up M2PELU43
I0927 19:02:46.515825  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.515827  3577 net.cpp:137] Memory required for data: 1079297200
I0927 19:02:46.515831  3577 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0927 19:02:46.515835  3577 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0927 19:02:46.515837  3577 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0927 19:02:46.515841  3577 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0927 19:02:46.515846  3577 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0927 19:02:46.515871  3577 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0927 19:02:46.515873  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.515877  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.515878  3577 net.cpp:137] Memory required for data: 1082574000
I0927 19:02:46.515880  3577 layer_factory.hpp:77] Creating layer Convolution46
I0927 19:02:46.515887  3577 net.cpp:84] Creating Layer Convolution46
I0927 19:02:46.515889  3577 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0927 19:02:46.515893  3577 net.cpp:380] Convolution46 -> Convolution46
I0927 19:02:46.517648  3577 net.cpp:122] Setting up Convolution46
I0927 19:02:46.517657  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.517659  3577 net.cpp:137] Memory required for data: 1084212400
I0927 19:02:46.517664  3577 layer_factory.hpp:77] Creating layer BatchNorm46
I0927 19:02:46.517669  3577 net.cpp:84] Creating Layer BatchNorm46
I0927 19:02:46.517673  3577 net.cpp:406] BatchNorm46 <- Convolution46
I0927 19:02:46.517676  3577 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0927 19:02:46.517819  3577 net.cpp:122] Setting up BatchNorm46
I0927 19:02:46.517823  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.517825  3577 net.cpp:137] Memory required for data: 1085850800
I0927 19:02:46.517830  3577 layer_factory.hpp:77] Creating layer Scale46
I0927 19:02:46.517834  3577 net.cpp:84] Creating Layer Scale46
I0927 19:02:46.517838  3577 net.cpp:406] Scale46 <- Convolution46
I0927 19:02:46.517840  3577 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0927 19:02:46.517869  3577 layer_factory.hpp:77] Creating layer Scale46
I0927 19:02:46.517951  3577 net.cpp:122] Setting up Scale46
I0927 19:02:46.517954  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.517956  3577 net.cpp:137] Memory required for data: 1087489200
I0927 19:02:46.517961  3577 layer_factory.hpp:77] Creating layer M2PELU44
I0927 19:02:46.517966  3577 net.cpp:84] Creating Layer M2PELU44
I0927 19:02:46.517968  3577 net.cpp:406] M2PELU44 <- Convolution46
I0927 19:02:46.517979  3577 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0927 19:02:46.518074  3577 net.cpp:122] Setting up M2PELU44
I0927 19:02:46.518077  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.518079  3577 net.cpp:137] Memory required for data: 1089127600
I0927 19:02:46.518084  3577 layer_factory.hpp:77] Creating layer Convolution47
I0927 19:02:46.518090  3577 net.cpp:84] Creating Layer Convolution47
I0927 19:02:46.518092  3577 net.cpp:406] Convolution47 <- Convolution46
I0927 19:02:46.518098  3577 net.cpp:380] Convolution47 -> Convolution47
I0927 19:02:46.519827  3577 net.cpp:122] Setting up Convolution47
I0927 19:02:46.519836  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.519839  3577 net.cpp:137] Memory required for data: 1090766000
I0927 19:02:46.519842  3577 layer_factory.hpp:77] Creating layer BatchNorm47
I0927 19:02:46.519848  3577 net.cpp:84] Creating Layer BatchNorm47
I0927 19:02:46.519851  3577 net.cpp:406] BatchNorm47 <- Convolution47
I0927 19:02:46.519855  3577 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0927 19:02:46.519991  3577 net.cpp:122] Setting up BatchNorm47
I0927 19:02:46.519995  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.519997  3577 net.cpp:137] Memory required for data: 1092404400
I0927 19:02:46.520002  3577 layer_factory.hpp:77] Creating layer Scale47
I0927 19:02:46.520007  3577 net.cpp:84] Creating Layer Scale47
I0927 19:02:46.520010  3577 net.cpp:406] Scale47 <- Convolution47
I0927 19:02:46.520014  3577 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0927 19:02:46.520041  3577 layer_factory.hpp:77] Creating layer Scale47
I0927 19:02:46.520118  3577 net.cpp:122] Setting up Scale47
I0927 19:02:46.520123  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.520125  3577 net.cpp:137] Memory required for data: 1094042800
I0927 19:02:46.520129  3577 layer_factory.hpp:77] Creating layer Eltwise22
I0927 19:02:46.520134  3577 net.cpp:84] Creating Layer Eltwise22
I0927 19:02:46.520136  3577 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0927 19:02:46.520140  3577 net.cpp:406] Eltwise22 <- Convolution47
I0927 19:02:46.520143  3577 net.cpp:380] Eltwise22 -> Eltwise22
I0927 19:02:46.520160  3577 net.cpp:122] Setting up Eltwise22
I0927 19:02:46.520164  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.520165  3577 net.cpp:137] Memory required for data: 1095681200
I0927 19:02:46.520167  3577 layer_factory.hpp:77] Creating layer M2PELU45
I0927 19:02:46.520172  3577 net.cpp:84] Creating Layer M2PELU45
I0927 19:02:46.520175  3577 net.cpp:406] M2PELU45 <- Eltwise22
I0927 19:02:46.520179  3577 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0927 19:02:46.520269  3577 net.cpp:122] Setting up M2PELU45
I0927 19:02:46.520274  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.520277  3577 net.cpp:137] Memory required for data: 1097319600
I0927 19:02:46.520280  3577 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0927 19:02:46.520284  3577 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0927 19:02:46.520287  3577 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0927 19:02:46.520290  3577 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0927 19:02:46.520294  3577 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0927 19:02:46.520318  3577 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0927 19:02:46.520323  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.520325  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.520328  3577 net.cpp:137] Memory required for data: 1100596400
I0927 19:02:46.520329  3577 layer_factory.hpp:77] Creating layer Convolution48
I0927 19:02:46.520334  3577 net.cpp:84] Creating Layer Convolution48
I0927 19:02:46.520337  3577 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0927 19:02:46.520341  3577 net.cpp:380] Convolution48 -> Convolution48
I0927 19:02:46.522375  3577 net.cpp:122] Setting up Convolution48
I0927 19:02:46.522384  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.522393  3577 net.cpp:137] Memory required for data: 1102234800
I0927 19:02:46.522398  3577 layer_factory.hpp:77] Creating layer BatchNorm48
I0927 19:02:46.522405  3577 net.cpp:84] Creating Layer BatchNorm48
I0927 19:02:46.522408  3577 net.cpp:406] BatchNorm48 <- Convolution48
I0927 19:02:46.522413  3577 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0927 19:02:46.522560  3577 net.cpp:122] Setting up BatchNorm48
I0927 19:02:46.522567  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.522568  3577 net.cpp:137] Memory required for data: 1103873200
I0927 19:02:46.522573  3577 layer_factory.hpp:77] Creating layer Scale48
I0927 19:02:46.522578  3577 net.cpp:84] Creating Layer Scale48
I0927 19:02:46.522579  3577 net.cpp:406] Scale48 <- Convolution48
I0927 19:02:46.522583  3577 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0927 19:02:46.522611  3577 layer_factory.hpp:77] Creating layer Scale48
I0927 19:02:46.522692  3577 net.cpp:122] Setting up Scale48
I0927 19:02:46.522696  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.522698  3577 net.cpp:137] Memory required for data: 1105511600
I0927 19:02:46.522702  3577 layer_factory.hpp:77] Creating layer M2PELU46
I0927 19:02:46.522707  3577 net.cpp:84] Creating Layer M2PELU46
I0927 19:02:46.522711  3577 net.cpp:406] M2PELU46 <- Convolution48
I0927 19:02:46.522714  3577 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0927 19:02:46.522805  3577 net.cpp:122] Setting up M2PELU46
I0927 19:02:46.522810  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.522812  3577 net.cpp:137] Memory required for data: 1107150000
I0927 19:02:46.522815  3577 layer_factory.hpp:77] Creating layer Convolution49
I0927 19:02:46.522822  3577 net.cpp:84] Creating Layer Convolution49
I0927 19:02:46.522825  3577 net.cpp:406] Convolution49 <- Convolution48
I0927 19:02:46.522830  3577 net.cpp:380] Convolution49 -> Convolution49
I0927 19:02:46.524884  3577 net.cpp:122] Setting up Convolution49
I0927 19:02:46.524893  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.524896  3577 net.cpp:137] Memory required for data: 1108788400
I0927 19:02:46.524900  3577 layer_factory.hpp:77] Creating layer BatchNorm49
I0927 19:02:46.524905  3577 net.cpp:84] Creating Layer BatchNorm49
I0927 19:02:46.524909  3577 net.cpp:406] BatchNorm49 <- Convolution49
I0927 19:02:46.524912  3577 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0927 19:02:46.525051  3577 net.cpp:122] Setting up BatchNorm49
I0927 19:02:46.525056  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.525058  3577 net.cpp:137] Memory required for data: 1110426800
I0927 19:02:46.525063  3577 layer_factory.hpp:77] Creating layer Scale49
I0927 19:02:46.525068  3577 net.cpp:84] Creating Layer Scale49
I0927 19:02:46.525070  3577 net.cpp:406] Scale49 <- Convolution49
I0927 19:02:46.525074  3577 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0927 19:02:46.525101  3577 layer_factory.hpp:77] Creating layer Scale49
I0927 19:02:46.525182  3577 net.cpp:122] Setting up Scale49
I0927 19:02:46.525185  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.525187  3577 net.cpp:137] Memory required for data: 1112065200
I0927 19:02:46.525192  3577 layer_factory.hpp:77] Creating layer Eltwise23
I0927 19:02:46.525197  3577 net.cpp:84] Creating Layer Eltwise23
I0927 19:02:46.525200  3577 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0927 19:02:46.525203  3577 net.cpp:406] Eltwise23 <- Convolution49
I0927 19:02:46.525207  3577 net.cpp:380] Eltwise23 -> Eltwise23
I0927 19:02:46.525224  3577 net.cpp:122] Setting up Eltwise23
I0927 19:02:46.525228  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.525230  3577 net.cpp:137] Memory required for data: 1113703600
I0927 19:02:46.525233  3577 layer_factory.hpp:77] Creating layer M2PELU47
I0927 19:02:46.525238  3577 net.cpp:84] Creating Layer M2PELU47
I0927 19:02:46.525240  3577 net.cpp:406] M2PELU47 <- Eltwise23
I0927 19:02:46.525243  3577 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0927 19:02:46.525344  3577 net.cpp:122] Setting up M2PELU47
I0927 19:02:46.525349  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.525352  3577 net.cpp:137] Memory required for data: 1115342000
I0927 19:02:46.525355  3577 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0927 19:02:46.525360  3577 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0927 19:02:46.525362  3577 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0927 19:02:46.525367  3577 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0927 19:02:46.525372  3577 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0927 19:02:46.525395  3577 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0927 19:02:46.525399  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.525403  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.525404  3577 net.cpp:137] Memory required for data: 1118618800
I0927 19:02:46.525406  3577 layer_factory.hpp:77] Creating layer Convolution50
I0927 19:02:46.525411  3577 net.cpp:84] Creating Layer Convolution50
I0927 19:02:46.525414  3577 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0927 19:02:46.525418  3577 net.cpp:380] Convolution50 -> Convolution50
I0927 19:02:46.527976  3577 net.cpp:122] Setting up Convolution50
I0927 19:02:46.527986  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.527988  3577 net.cpp:137] Memory required for data: 1120257200
I0927 19:02:46.527993  3577 layer_factory.hpp:77] Creating layer BatchNorm50
I0927 19:02:46.527997  3577 net.cpp:84] Creating Layer BatchNorm50
I0927 19:02:46.528000  3577 net.cpp:406] BatchNorm50 <- Convolution50
I0927 19:02:46.528004  3577 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0927 19:02:46.543978  3577 net.cpp:122] Setting up BatchNorm50
I0927 19:02:46.543987  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.543990  3577 net.cpp:137] Memory required for data: 1121895600
I0927 19:02:46.543997  3577 layer_factory.hpp:77] Creating layer Scale50
I0927 19:02:46.544001  3577 net.cpp:84] Creating Layer Scale50
I0927 19:02:46.544004  3577 net.cpp:406] Scale50 <- Convolution50
I0927 19:02:46.544008  3577 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0927 19:02:46.544041  3577 layer_factory.hpp:77] Creating layer Scale50
I0927 19:02:46.544129  3577 net.cpp:122] Setting up Scale50
I0927 19:02:46.544134  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.544137  3577 net.cpp:137] Memory required for data: 1123534000
I0927 19:02:46.544140  3577 layer_factory.hpp:77] Creating layer M2PELU48
I0927 19:02:46.544145  3577 net.cpp:84] Creating Layer M2PELU48
I0927 19:02:46.544148  3577 net.cpp:406] M2PELU48 <- Convolution50
I0927 19:02:46.544152  3577 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0927 19:02:46.544253  3577 net.cpp:122] Setting up M2PELU48
I0927 19:02:46.544258  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.544260  3577 net.cpp:137] Memory required for data: 1125172400
I0927 19:02:46.544265  3577 layer_factory.hpp:77] Creating layer Convolution51
I0927 19:02:46.544273  3577 net.cpp:84] Creating Layer Convolution51
I0927 19:02:46.544275  3577 net.cpp:406] Convolution51 <- Convolution50
I0927 19:02:46.544281  3577 net.cpp:380] Convolution51 -> Convolution51
I0927 19:02:46.546511  3577 net.cpp:122] Setting up Convolution51
I0927 19:02:46.546528  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.546533  3577 net.cpp:137] Memory required for data: 1126810800
I0927 19:02:46.546538  3577 layer_factory.hpp:77] Creating layer BatchNorm51
I0927 19:02:46.546555  3577 net.cpp:84] Creating Layer BatchNorm51
I0927 19:02:46.546557  3577 net.cpp:406] BatchNorm51 <- Convolution51
I0927 19:02:46.546561  3577 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0927 19:02:46.546702  3577 net.cpp:122] Setting up BatchNorm51
I0927 19:02:46.546706  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.546708  3577 net.cpp:137] Memory required for data: 1128449200
I0927 19:02:46.546720  3577 layer_factory.hpp:77] Creating layer Scale51
I0927 19:02:46.546725  3577 net.cpp:84] Creating Layer Scale51
I0927 19:02:46.546728  3577 net.cpp:406] Scale51 <- Convolution51
I0927 19:02:46.546731  3577 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0927 19:02:46.546761  3577 layer_factory.hpp:77] Creating layer Scale51
I0927 19:02:46.546840  3577 net.cpp:122] Setting up Scale51
I0927 19:02:46.546845  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.546847  3577 net.cpp:137] Memory required for data: 1130087600
I0927 19:02:46.546851  3577 layer_factory.hpp:77] Creating layer Eltwise24
I0927 19:02:46.546855  3577 net.cpp:84] Creating Layer Eltwise24
I0927 19:02:46.546859  3577 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0927 19:02:46.546860  3577 net.cpp:406] Eltwise24 <- Convolution51
I0927 19:02:46.546865  3577 net.cpp:380] Eltwise24 -> Eltwise24
I0927 19:02:46.546881  3577 net.cpp:122] Setting up Eltwise24
I0927 19:02:46.546885  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.546886  3577 net.cpp:137] Memory required for data: 1131726000
I0927 19:02:46.546888  3577 layer_factory.hpp:77] Creating layer M2PELU49
I0927 19:02:46.546895  3577 net.cpp:84] Creating Layer M2PELU49
I0927 19:02:46.546896  3577 net.cpp:406] M2PELU49 <- Eltwise24
I0927 19:02:46.546900  3577 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0927 19:02:46.546991  3577 net.cpp:122] Setting up M2PELU49
I0927 19:02:46.546995  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.546998  3577 net.cpp:137] Memory required for data: 1133364400
I0927 19:02:46.547001  3577 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0927 19:02:46.547004  3577 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0927 19:02:46.547008  3577 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0927 19:02:46.547011  3577 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0927 19:02:46.547015  3577 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0927 19:02:46.547049  3577 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0927 19:02:46.547052  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.547055  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.547057  3577 net.cpp:137] Memory required for data: 1136641200
I0927 19:02:46.547060  3577 layer_factory.hpp:77] Creating layer Convolution52
I0927 19:02:46.547065  3577 net.cpp:84] Creating Layer Convolution52
I0927 19:02:46.547067  3577 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0927 19:02:46.547072  3577 net.cpp:380] Convolution52 -> Convolution52
I0927 19:02:46.549211  3577 net.cpp:122] Setting up Convolution52
I0927 19:02:46.549221  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.549223  3577 net.cpp:137] Memory required for data: 1138279600
I0927 19:02:46.549228  3577 layer_factory.hpp:77] Creating layer BatchNorm52
I0927 19:02:46.549233  3577 net.cpp:84] Creating Layer BatchNorm52
I0927 19:02:46.549237  3577 net.cpp:406] BatchNorm52 <- Convolution52
I0927 19:02:46.549240  3577 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0927 19:02:46.549384  3577 net.cpp:122] Setting up BatchNorm52
I0927 19:02:46.549389  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.549391  3577 net.cpp:137] Memory required for data: 1139918000
I0927 19:02:46.549396  3577 layer_factory.hpp:77] Creating layer Scale52
I0927 19:02:46.549399  3577 net.cpp:84] Creating Layer Scale52
I0927 19:02:46.549402  3577 net.cpp:406] Scale52 <- Convolution52
I0927 19:02:46.549405  3577 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0927 19:02:46.549434  3577 layer_factory.hpp:77] Creating layer Scale52
I0927 19:02:46.549516  3577 net.cpp:122] Setting up Scale52
I0927 19:02:46.549520  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.549522  3577 net.cpp:137] Memory required for data: 1141556400
I0927 19:02:46.549526  3577 layer_factory.hpp:77] Creating layer M2PELU50
I0927 19:02:46.549547  3577 net.cpp:84] Creating Layer M2PELU50
I0927 19:02:46.549556  3577 net.cpp:406] M2PELU50 <- Convolution52
I0927 19:02:46.549561  3577 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0927 19:02:46.549659  3577 net.cpp:122] Setting up M2PELU50
I0927 19:02:46.549664  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.549665  3577 net.cpp:137] Memory required for data: 1143194800
I0927 19:02:46.549669  3577 layer_factory.hpp:77] Creating layer Convolution53
I0927 19:02:46.549676  3577 net.cpp:84] Creating Layer Convolution53
I0927 19:02:46.549679  3577 net.cpp:406] Convolution53 <- Convolution52
I0927 19:02:46.549682  3577 net.cpp:380] Convolution53 -> Convolution53
I0927 19:02:46.551419  3577 net.cpp:122] Setting up Convolution53
I0927 19:02:46.551429  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.551430  3577 net.cpp:137] Memory required for data: 1144833200
I0927 19:02:46.551435  3577 layer_factory.hpp:77] Creating layer BatchNorm53
I0927 19:02:46.551440  3577 net.cpp:84] Creating Layer BatchNorm53
I0927 19:02:46.551443  3577 net.cpp:406] BatchNorm53 <- Convolution53
I0927 19:02:46.551447  3577 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0927 19:02:46.551587  3577 net.cpp:122] Setting up BatchNorm53
I0927 19:02:46.551591  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.551594  3577 net.cpp:137] Memory required for data: 1146471600
I0927 19:02:46.551599  3577 layer_factory.hpp:77] Creating layer Scale53
I0927 19:02:46.551602  3577 net.cpp:84] Creating Layer Scale53
I0927 19:02:46.551605  3577 net.cpp:406] Scale53 <- Convolution53
I0927 19:02:46.551609  3577 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0927 19:02:46.551636  3577 layer_factory.hpp:77] Creating layer Scale53
I0927 19:02:46.551718  3577 net.cpp:122] Setting up Scale53
I0927 19:02:46.551723  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.551724  3577 net.cpp:137] Memory required for data: 1148110000
I0927 19:02:46.551728  3577 layer_factory.hpp:77] Creating layer Eltwise25
I0927 19:02:46.551733  3577 net.cpp:84] Creating Layer Eltwise25
I0927 19:02:46.551735  3577 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0927 19:02:46.551738  3577 net.cpp:406] Eltwise25 <- Convolution53
I0927 19:02:46.551743  3577 net.cpp:380] Eltwise25 -> Eltwise25
I0927 19:02:46.551759  3577 net.cpp:122] Setting up Eltwise25
I0927 19:02:46.551761  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.551764  3577 net.cpp:137] Memory required for data: 1149748400
I0927 19:02:46.551765  3577 layer_factory.hpp:77] Creating layer M2PELU51
I0927 19:02:46.551770  3577 net.cpp:84] Creating Layer M2PELU51
I0927 19:02:46.551774  3577 net.cpp:406] M2PELU51 <- Eltwise25
I0927 19:02:46.551776  3577 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0927 19:02:46.551868  3577 net.cpp:122] Setting up M2PELU51
I0927 19:02:46.551872  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.551874  3577 net.cpp:137] Memory required for data: 1151386800
I0927 19:02:46.551878  3577 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0927 19:02:46.551882  3577 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0927 19:02:46.551884  3577 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0927 19:02:46.551888  3577 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0927 19:02:46.551892  3577 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0927 19:02:46.551915  3577 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0927 19:02:46.551919  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.551923  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.551924  3577 net.cpp:137] Memory required for data: 1154663600
I0927 19:02:46.551926  3577 layer_factory.hpp:77] Creating layer Convolution54
I0927 19:02:46.551933  3577 net.cpp:84] Creating Layer Convolution54
I0927 19:02:46.551934  3577 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0927 19:02:46.551939  3577 net.cpp:380] Convolution54 -> Convolution54
I0927 19:02:46.553982  3577 net.cpp:122] Setting up Convolution54
I0927 19:02:46.553995  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.553998  3577 net.cpp:137] Memory required for data: 1156302000
I0927 19:02:46.554003  3577 layer_factory.hpp:77] Creating layer BatchNorm54
I0927 19:02:46.554008  3577 net.cpp:84] Creating Layer BatchNorm54
I0927 19:02:46.554011  3577 net.cpp:406] BatchNorm54 <- Convolution54
I0927 19:02:46.554014  3577 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0927 19:02:46.554160  3577 net.cpp:122] Setting up BatchNorm54
I0927 19:02:46.554165  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.554167  3577 net.cpp:137] Memory required for data: 1157940400
I0927 19:02:46.554172  3577 layer_factory.hpp:77] Creating layer Scale54
I0927 19:02:46.554175  3577 net.cpp:84] Creating Layer Scale54
I0927 19:02:46.554178  3577 net.cpp:406] Scale54 <- Convolution54
I0927 19:02:46.554181  3577 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0927 19:02:46.554210  3577 layer_factory.hpp:77] Creating layer Scale54
I0927 19:02:46.554291  3577 net.cpp:122] Setting up Scale54
I0927 19:02:46.554296  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.554297  3577 net.cpp:137] Memory required for data: 1159578800
I0927 19:02:46.554301  3577 layer_factory.hpp:77] Creating layer M2PELU52
I0927 19:02:46.554306  3577 net.cpp:84] Creating Layer M2PELU52
I0927 19:02:46.554309  3577 net.cpp:406] M2PELU52 <- Convolution54
I0927 19:02:46.554312  3577 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0927 19:02:46.554406  3577 net.cpp:122] Setting up M2PELU52
I0927 19:02:46.554410  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.554412  3577 net.cpp:137] Memory required for data: 1161217200
I0927 19:02:46.554416  3577 layer_factory.hpp:77] Creating layer Convolution55
I0927 19:02:46.554424  3577 net.cpp:84] Creating Layer Convolution55
I0927 19:02:46.554425  3577 net.cpp:406] Convolution55 <- Convolution54
I0927 19:02:46.554431  3577 net.cpp:380] Convolution55 -> Convolution55
I0927 19:02:46.556174  3577 net.cpp:122] Setting up Convolution55
I0927 19:02:46.556181  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.556185  3577 net.cpp:137] Memory required for data: 1162855600
I0927 19:02:46.556188  3577 layer_factory.hpp:77] Creating layer BatchNorm55
I0927 19:02:46.556193  3577 net.cpp:84] Creating Layer BatchNorm55
I0927 19:02:46.556196  3577 net.cpp:406] BatchNorm55 <- Convolution55
I0927 19:02:46.556200  3577 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0927 19:02:46.556341  3577 net.cpp:122] Setting up BatchNorm55
I0927 19:02:46.556345  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.556347  3577 net.cpp:137] Memory required for data: 1164494000
I0927 19:02:46.556352  3577 layer_factory.hpp:77] Creating layer Scale55
I0927 19:02:46.556356  3577 net.cpp:84] Creating Layer Scale55
I0927 19:02:46.556358  3577 net.cpp:406] Scale55 <- Convolution55
I0927 19:02:46.556362  3577 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0927 19:02:46.556391  3577 layer_factory.hpp:77] Creating layer Scale55
I0927 19:02:46.556473  3577 net.cpp:122] Setting up Scale55
I0927 19:02:46.556478  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.556479  3577 net.cpp:137] Memory required for data: 1166132400
I0927 19:02:46.556483  3577 layer_factory.hpp:77] Creating layer Eltwise26
I0927 19:02:46.556488  3577 net.cpp:84] Creating Layer Eltwise26
I0927 19:02:46.556490  3577 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0927 19:02:46.556494  3577 net.cpp:406] Eltwise26 <- Convolution55
I0927 19:02:46.556498  3577 net.cpp:380] Eltwise26 -> Eltwise26
I0927 19:02:46.556514  3577 net.cpp:122] Setting up Eltwise26
I0927 19:02:46.556519  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.556520  3577 net.cpp:137] Memory required for data: 1167770800
I0927 19:02:46.556522  3577 layer_factory.hpp:77] Creating layer M2PELU53
I0927 19:02:46.556526  3577 net.cpp:84] Creating Layer M2PELU53
I0927 19:02:46.556529  3577 net.cpp:406] M2PELU53 <- Eltwise26
I0927 19:02:46.556540  3577 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0927 19:02:46.556634  3577 net.cpp:122] Setting up M2PELU53
I0927 19:02:46.556639  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.556641  3577 net.cpp:137] Memory required for data: 1169409200
I0927 19:02:46.556644  3577 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0927 19:02:46.556649  3577 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0927 19:02:46.556651  3577 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0927 19:02:46.556654  3577 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0927 19:02:46.556658  3577 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0927 19:02:46.556684  3577 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0927 19:02:46.556687  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.556690  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.556691  3577 net.cpp:137] Memory required for data: 1172686000
I0927 19:02:46.556694  3577 layer_factory.hpp:77] Creating layer Convolution56
I0927 19:02:46.556699  3577 net.cpp:84] Creating Layer Convolution56
I0927 19:02:46.556701  3577 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0927 19:02:46.556706  3577 net.cpp:380] Convolution56 -> Convolution56
I0927 19:02:46.558384  3577 net.cpp:122] Setting up Convolution56
I0927 19:02:46.558393  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.558394  3577 net.cpp:137] Memory required for data: 1174324400
I0927 19:02:46.558399  3577 layer_factory.hpp:77] Creating layer BatchNorm56
I0927 19:02:46.574497  3577 net.cpp:84] Creating Layer BatchNorm56
I0927 19:02:46.574507  3577 net.cpp:406] BatchNorm56 <- Convolution56
I0927 19:02:46.574512  3577 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0927 19:02:46.574692  3577 net.cpp:122] Setting up BatchNorm56
I0927 19:02:46.574698  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.574702  3577 net.cpp:137] Memory required for data: 1175962800
I0927 19:02:46.574707  3577 layer_factory.hpp:77] Creating layer Scale56
I0927 19:02:46.574712  3577 net.cpp:84] Creating Layer Scale56
I0927 19:02:46.574714  3577 net.cpp:406] Scale56 <- Convolution56
I0927 19:02:46.574718  3577 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0927 19:02:46.574751  3577 layer_factory.hpp:77] Creating layer Scale56
I0927 19:02:46.574841  3577 net.cpp:122] Setting up Scale56
I0927 19:02:46.574846  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.574848  3577 net.cpp:137] Memory required for data: 1177601200
I0927 19:02:46.574852  3577 layer_factory.hpp:77] Creating layer M2PELU54
I0927 19:02:46.574858  3577 net.cpp:84] Creating Layer M2PELU54
I0927 19:02:46.574862  3577 net.cpp:406] M2PELU54 <- Convolution56
I0927 19:02:46.574865  3577 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0927 19:02:46.574968  3577 net.cpp:122] Setting up M2PELU54
I0927 19:02:46.574973  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.574975  3577 net.cpp:137] Memory required for data: 1179239600
I0927 19:02:46.574980  3577 layer_factory.hpp:77] Creating layer Convolution57
I0927 19:02:46.574986  3577 net.cpp:84] Creating Layer Convolution57
I0927 19:02:46.574990  3577 net.cpp:406] Convolution57 <- Convolution56
I0927 19:02:46.574995  3577 net.cpp:380] Convolution57 -> Convolution57
I0927 19:02:46.577142  3577 net.cpp:122] Setting up Convolution57
I0927 19:02:46.577150  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.577153  3577 net.cpp:137] Memory required for data: 1180878000
I0927 19:02:46.577158  3577 layer_factory.hpp:77] Creating layer BatchNorm57
I0927 19:02:46.577164  3577 net.cpp:84] Creating Layer BatchNorm57
I0927 19:02:46.577168  3577 net.cpp:406] BatchNorm57 <- Convolution57
I0927 19:02:46.577172  3577 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0927 19:02:46.577318  3577 net.cpp:122] Setting up BatchNorm57
I0927 19:02:46.577323  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.577325  3577 net.cpp:137] Memory required for data: 1182516400
I0927 19:02:46.577337  3577 layer_factory.hpp:77] Creating layer Scale57
I0927 19:02:46.577343  3577 net.cpp:84] Creating Layer Scale57
I0927 19:02:46.577347  3577 net.cpp:406] Scale57 <- Convolution57
I0927 19:02:46.577350  3577 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0927 19:02:46.577380  3577 layer_factory.hpp:77] Creating layer Scale57
I0927 19:02:46.577464  3577 net.cpp:122] Setting up Scale57
I0927 19:02:46.577469  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.577471  3577 net.cpp:137] Memory required for data: 1184154800
I0927 19:02:46.577474  3577 layer_factory.hpp:77] Creating layer Eltwise27
I0927 19:02:46.577479  3577 net.cpp:84] Creating Layer Eltwise27
I0927 19:02:46.577482  3577 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0927 19:02:46.577486  3577 net.cpp:406] Eltwise27 <- Convolution57
I0927 19:02:46.577489  3577 net.cpp:380] Eltwise27 -> Eltwise27
I0927 19:02:46.577507  3577 net.cpp:122] Setting up Eltwise27
I0927 19:02:46.577510  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.577512  3577 net.cpp:137] Memory required for data: 1185793200
I0927 19:02:46.577514  3577 layer_factory.hpp:77] Creating layer M2PELU55
I0927 19:02:46.577520  3577 net.cpp:84] Creating Layer M2PELU55
I0927 19:02:46.577522  3577 net.cpp:406] M2PELU55 <- Eltwise27
I0927 19:02:46.577525  3577 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0927 19:02:46.577622  3577 net.cpp:122] Setting up M2PELU55
I0927 19:02:46.577627  3577 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 19:02:46.577630  3577 net.cpp:137] Memory required for data: 1187431600
I0927 19:02:46.577633  3577 layer_factory.hpp:77] Creating layer Pooling1
I0927 19:02:46.577637  3577 net.cpp:84] Creating Layer Pooling1
I0927 19:02:46.577639  3577 net.cpp:406] Pooling1 <- Eltwise27
I0927 19:02:46.577643  3577 net.cpp:380] Pooling1 -> Pooling1
I0927 19:02:46.578306  3577 net.cpp:122] Setting up Pooling1
I0927 19:02:46.578315  3577 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0927 19:02:46.578318  3577 net.cpp:137] Memory required for data: 1187457200
I0927 19:02:46.578320  3577 layer_factory.hpp:77] Creating layer InnerProduct1
I0927 19:02:46.578327  3577 net.cpp:84] Creating Layer InnerProduct1
I0927 19:02:46.578330  3577 net.cpp:406] InnerProduct1 <- Pooling1
I0927 19:02:46.578333  3577 net.cpp:380] InnerProduct1 -> InnerProduct1
I0927 19:02:46.578459  3577 net.cpp:122] Setting up InnerProduct1
I0927 19:02:46.578464  3577 net.cpp:129] Top shape: 100 10 (1000)
I0927 19:02:46.578465  3577 net.cpp:137] Memory required for data: 1187461200
I0927 19:02:46.578478  3577 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0927 19:02:46.578482  3577 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0927 19:02:46.578485  3577 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0927 19:02:46.578488  3577 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0927 19:02:46.578493  3577 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0927 19:02:46.578543  3577 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0927 19:02:46.578552  3577 net.cpp:129] Top shape: 100 10 (1000)
I0927 19:02:46.578557  3577 net.cpp:129] Top shape: 100 10 (1000)
I0927 19:02:46.578569  3577 net.cpp:137] Memory required for data: 1187469200
I0927 19:02:46.578573  3577 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 19:02:46.578578  3577 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0927 19:02:46.578582  3577 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0927 19:02:46.578586  3577 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0927 19:02:46.578589  3577 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0927 19:02:46.578594  3577 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 19:02:46.578802  3577 net.cpp:122] Setting up SoftmaxWithLoss1
I0927 19:02:46.578809  3577 net.cpp:129] Top shape: (1)
I0927 19:02:46.578811  3577 net.cpp:132]     with loss weight 1
I0927 19:02:46.578824  3577 net.cpp:137] Memory required for data: 1187469204
I0927 19:02:46.578827  3577 layer_factory.hpp:77] Creating layer Accuracy1
I0927 19:02:46.578832  3577 net.cpp:84] Creating Layer Accuracy1
I0927 19:02:46.578835  3577 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0927 19:02:46.578838  3577 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0927 19:02:46.578842  3577 net.cpp:380] Accuracy1 -> Accuracy1
I0927 19:02:46.578848  3577 net.cpp:122] Setting up Accuracy1
I0927 19:02:46.578852  3577 net.cpp:129] Top shape: (1)
I0927 19:02:46.578855  3577 net.cpp:137] Memory required for data: 1187469208
I0927 19:02:46.578856  3577 net.cpp:200] Accuracy1 does not need backward computation.
I0927 19:02:46.578860  3577 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0927 19:02:46.578861  3577 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0927 19:02:46.578864  3577 net.cpp:198] InnerProduct1 needs backward computation.
I0927 19:02:46.578866  3577 net.cpp:198] Pooling1 needs backward computation.
I0927 19:02:46.578868  3577 net.cpp:198] M2PELU55 needs backward computation.
I0927 19:02:46.578871  3577 net.cpp:198] Eltwise27 needs backward computation.
I0927 19:02:46.578873  3577 net.cpp:198] Scale57 needs backward computation.
I0927 19:02:46.578876  3577 net.cpp:198] BatchNorm57 needs backward computation.
I0927 19:02:46.578877  3577 net.cpp:198] Convolution57 needs backward computation.
I0927 19:02:46.578879  3577 net.cpp:198] M2PELU54 needs backward computation.
I0927 19:02:46.578881  3577 net.cpp:198] Scale56 needs backward computation.
I0927 19:02:46.578883  3577 net.cpp:198] BatchNorm56 needs backward computation.
I0927 19:02:46.578886  3577 net.cpp:198] Convolution56 needs backward computation.
I0927 19:02:46.578888  3577 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0927 19:02:46.578891  3577 net.cpp:198] M2PELU53 needs backward computation.
I0927 19:02:46.578892  3577 net.cpp:198] Eltwise26 needs backward computation.
I0927 19:02:46.578896  3577 net.cpp:198] Scale55 needs backward computation.
I0927 19:02:46.578897  3577 net.cpp:198] BatchNorm55 needs backward computation.
I0927 19:02:46.578899  3577 net.cpp:198] Convolution55 needs backward computation.
I0927 19:02:46.578902  3577 net.cpp:198] M2PELU52 needs backward computation.
I0927 19:02:46.578903  3577 net.cpp:198] Scale54 needs backward computation.
I0927 19:02:46.578905  3577 net.cpp:198] BatchNorm54 needs backward computation.
I0927 19:02:46.578907  3577 net.cpp:198] Convolution54 needs backward computation.
I0927 19:02:46.578909  3577 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0927 19:02:46.578912  3577 net.cpp:198] M2PELU51 needs backward computation.
I0927 19:02:46.578913  3577 net.cpp:198] Eltwise25 needs backward computation.
I0927 19:02:46.578917  3577 net.cpp:198] Scale53 needs backward computation.
I0927 19:02:46.578918  3577 net.cpp:198] BatchNorm53 needs backward computation.
I0927 19:02:46.578920  3577 net.cpp:198] Convolution53 needs backward computation.
I0927 19:02:46.578922  3577 net.cpp:198] M2PELU50 needs backward computation.
I0927 19:02:46.578924  3577 net.cpp:198] Scale52 needs backward computation.
I0927 19:02:46.578927  3577 net.cpp:198] BatchNorm52 needs backward computation.
I0927 19:02:46.578928  3577 net.cpp:198] Convolution52 needs backward computation.
I0927 19:02:46.578930  3577 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0927 19:02:46.578933  3577 net.cpp:198] M2PELU49 needs backward computation.
I0927 19:02:46.578935  3577 net.cpp:198] Eltwise24 needs backward computation.
I0927 19:02:46.578938  3577 net.cpp:198] Scale51 needs backward computation.
I0927 19:02:46.578940  3577 net.cpp:198] BatchNorm51 needs backward computation.
I0927 19:02:46.578943  3577 net.cpp:198] Convolution51 needs backward computation.
I0927 19:02:46.578944  3577 net.cpp:198] M2PELU48 needs backward computation.
I0927 19:02:46.578946  3577 net.cpp:198] Scale50 needs backward computation.
I0927 19:02:46.578953  3577 net.cpp:198] BatchNorm50 needs backward computation.
I0927 19:02:46.578954  3577 net.cpp:198] Convolution50 needs backward computation.
I0927 19:02:46.578958  3577 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0927 19:02:46.578959  3577 net.cpp:198] M2PELU47 needs backward computation.
I0927 19:02:46.578961  3577 net.cpp:198] Eltwise23 needs backward computation.
I0927 19:02:46.578964  3577 net.cpp:198] Scale49 needs backward computation.
I0927 19:02:46.578966  3577 net.cpp:198] BatchNorm49 needs backward computation.
I0927 19:02:46.578969  3577 net.cpp:198] Convolution49 needs backward computation.
I0927 19:02:46.578971  3577 net.cpp:198] M2PELU46 needs backward computation.
I0927 19:02:46.578974  3577 net.cpp:198] Scale48 needs backward computation.
I0927 19:02:46.578976  3577 net.cpp:198] BatchNorm48 needs backward computation.
I0927 19:02:46.578979  3577 net.cpp:198] Convolution48 needs backward computation.
I0927 19:02:46.578980  3577 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0927 19:02:46.578984  3577 net.cpp:198] M2PELU45 needs backward computation.
I0927 19:02:46.578985  3577 net.cpp:198] Eltwise22 needs backward computation.
I0927 19:02:46.578987  3577 net.cpp:198] Scale47 needs backward computation.
I0927 19:02:46.578990  3577 net.cpp:198] BatchNorm47 needs backward computation.
I0927 19:02:46.578992  3577 net.cpp:198] Convolution47 needs backward computation.
I0927 19:02:46.578994  3577 net.cpp:198] M2PELU44 needs backward computation.
I0927 19:02:46.578996  3577 net.cpp:198] Scale46 needs backward computation.
I0927 19:02:46.578999  3577 net.cpp:198] BatchNorm46 needs backward computation.
I0927 19:02:46.579000  3577 net.cpp:198] Convolution46 needs backward computation.
I0927 19:02:46.579004  3577 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0927 19:02:46.579005  3577 net.cpp:198] M2PELU43 needs backward computation.
I0927 19:02:46.579007  3577 net.cpp:198] Eltwise21 needs backward computation.
I0927 19:02:46.579010  3577 net.cpp:198] Scale45 needs backward computation.
I0927 19:02:46.579012  3577 net.cpp:198] BatchNorm45 needs backward computation.
I0927 19:02:46.579015  3577 net.cpp:198] Convolution45 needs backward computation.
I0927 19:02:46.579016  3577 net.cpp:198] M2PELU42 needs backward computation.
I0927 19:02:46.579018  3577 net.cpp:198] Scale44 needs backward computation.
I0927 19:02:46.579020  3577 net.cpp:198] BatchNorm44 needs backward computation.
I0927 19:02:46.579023  3577 net.cpp:198] Convolution44 needs backward computation.
I0927 19:02:46.579025  3577 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0927 19:02:46.579027  3577 net.cpp:198] M2PELU41 needs backward computation.
I0927 19:02:46.579030  3577 net.cpp:198] Eltwise20 needs backward computation.
I0927 19:02:46.579032  3577 net.cpp:198] Scale43 needs backward computation.
I0927 19:02:46.579035  3577 net.cpp:198] BatchNorm43 needs backward computation.
I0927 19:02:46.579036  3577 net.cpp:198] Convolution43 needs backward computation.
I0927 19:02:46.579040  3577 net.cpp:198] M2PELU40 needs backward computation.
I0927 19:02:46.579041  3577 net.cpp:198] Scale42 needs backward computation.
I0927 19:02:46.579043  3577 net.cpp:198] BatchNorm42 needs backward computation.
I0927 19:02:46.579046  3577 net.cpp:198] Convolution42 needs backward computation.
I0927 19:02:46.579047  3577 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0927 19:02:46.579051  3577 net.cpp:198] M2PELU39 needs backward computation.
I0927 19:02:46.579052  3577 net.cpp:198] Eltwise19 needs backward computation.
I0927 19:02:46.579056  3577 net.cpp:198] Scale41 needs backward computation.
I0927 19:02:46.579057  3577 net.cpp:198] BatchNorm41 needs backward computation.
I0927 19:02:46.579059  3577 net.cpp:198] Convolution41 needs backward computation.
I0927 19:02:46.579062  3577 net.cpp:198] M2PELU38 needs backward computation.
I0927 19:02:46.579064  3577 net.cpp:198] Scale40 needs backward computation.
I0927 19:02:46.579066  3577 net.cpp:198] BatchNorm40 needs backward computation.
I0927 19:02:46.579071  3577 net.cpp:198] Convolution40 needs backward computation.
I0927 19:02:46.579074  3577 net.cpp:198] Scale39 needs backward computation.
I0927 19:02:46.579077  3577 net.cpp:198] BatchNorm39 needs backward computation.
I0927 19:02:46.579078  3577 net.cpp:198] Convolution39 needs backward computation.
I0927 19:02:46.579082  3577 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0927 19:02:46.579083  3577 net.cpp:198] M2PELU37 needs backward computation.
I0927 19:02:46.579087  3577 net.cpp:198] Eltwise18 needs backward computation.
I0927 19:02:46.579088  3577 net.cpp:198] Scale38 needs backward computation.
I0927 19:02:46.579092  3577 net.cpp:198] BatchNorm38 needs backward computation.
I0927 19:02:46.579093  3577 net.cpp:198] Convolution38 needs backward computation.
I0927 19:02:46.579095  3577 net.cpp:198] M2PELU36 needs backward computation.
I0927 19:02:46.579097  3577 net.cpp:198] Scale37 needs backward computation.
I0927 19:02:46.579099  3577 net.cpp:198] BatchNorm37 needs backward computation.
I0927 19:02:46.579102  3577 net.cpp:198] Convolution37 needs backward computation.
I0927 19:02:46.579104  3577 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0927 19:02:46.579107  3577 net.cpp:198] M2PELU35 needs backward computation.
I0927 19:02:46.579109  3577 net.cpp:198] Eltwise17 needs backward computation.
I0927 19:02:46.607509  3577 net.cpp:198] Scale36 needs backward computation.
I0927 19:02:46.607528  3577 net.cpp:198] BatchNorm36 needs backward computation.
I0927 19:02:46.607542  3577 net.cpp:198] Convolution36 needs backward computation.
I0927 19:02:46.607547  3577 net.cpp:198] M2PELU34 needs backward computation.
I0927 19:02:46.607550  3577 net.cpp:198] Scale35 needs backward computation.
I0927 19:02:46.607553  3577 net.cpp:198] BatchNorm35 needs backward computation.
I0927 19:02:46.607558  3577 net.cpp:198] Convolution35 needs backward computation.
I0927 19:02:46.607561  3577 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0927 19:02:46.607565  3577 net.cpp:198] M2PELU33 needs backward computation.
I0927 19:02:46.607569  3577 net.cpp:198] Eltwise16 needs backward computation.
I0927 19:02:46.607573  3577 net.cpp:198] Scale34 needs backward computation.
I0927 19:02:46.607578  3577 net.cpp:198] BatchNorm34 needs backward computation.
I0927 19:02:46.607580  3577 net.cpp:198] Convolution34 needs backward computation.
I0927 19:02:46.607584  3577 net.cpp:198] M2PELU32 needs backward computation.
I0927 19:02:46.607587  3577 net.cpp:198] Scale33 needs backward computation.
I0927 19:02:46.607591  3577 net.cpp:198] BatchNorm33 needs backward computation.
I0927 19:02:46.607594  3577 net.cpp:198] Convolution33 needs backward computation.
I0927 19:02:46.607599  3577 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0927 19:02:46.607602  3577 net.cpp:198] M2PELU31 needs backward computation.
I0927 19:02:46.607606  3577 net.cpp:198] Eltwise15 needs backward computation.
I0927 19:02:46.607610  3577 net.cpp:198] Scale32 needs backward computation.
I0927 19:02:46.607614  3577 net.cpp:198] BatchNorm32 needs backward computation.
I0927 19:02:46.607617  3577 net.cpp:198] Convolution32 needs backward computation.
I0927 19:02:46.607621  3577 net.cpp:198] M2PELU30 needs backward computation.
I0927 19:02:46.607625  3577 net.cpp:198] Scale31 needs backward computation.
I0927 19:02:46.607630  3577 net.cpp:198] BatchNorm31 needs backward computation.
I0927 19:02:46.607632  3577 net.cpp:198] Convolution31 needs backward computation.
I0927 19:02:46.607637  3577 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0927 19:02:46.607642  3577 net.cpp:198] M2PELU29 needs backward computation.
I0927 19:02:46.607646  3577 net.cpp:198] Eltwise14 needs backward computation.
I0927 19:02:46.607650  3577 net.cpp:198] Scale30 needs backward computation.
I0927 19:02:46.607653  3577 net.cpp:198] BatchNorm30 needs backward computation.
I0927 19:02:46.607657  3577 net.cpp:198] Convolution30 needs backward computation.
I0927 19:02:46.607668  3577 net.cpp:198] M2PELU28 needs backward computation.
I0927 19:02:46.607672  3577 net.cpp:198] Scale29 needs backward computation.
I0927 19:02:46.607676  3577 net.cpp:198] BatchNorm29 needs backward computation.
I0927 19:02:46.607679  3577 net.cpp:198] Convolution29 needs backward computation.
I0927 19:02:46.607682  3577 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0927 19:02:46.607684  3577 net.cpp:198] M2PELU27 needs backward computation.
I0927 19:02:46.607686  3577 net.cpp:198] Eltwise13 needs backward computation.
I0927 19:02:46.607689  3577 net.cpp:198] Scale28 needs backward computation.
I0927 19:02:46.607692  3577 net.cpp:198] BatchNorm28 needs backward computation.
I0927 19:02:46.607693  3577 net.cpp:198] Convolution28 needs backward computation.
I0927 19:02:46.607698  3577 net.cpp:198] M2PELU26 needs backward computation.
I0927 19:02:46.607700  3577 net.cpp:198] Scale27 needs backward computation.
I0927 19:02:46.607702  3577 net.cpp:198] BatchNorm27 needs backward computation.
I0927 19:02:46.607705  3577 net.cpp:198] Convolution27 needs backward computation.
I0927 19:02:46.607707  3577 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0927 19:02:46.607710  3577 net.cpp:198] M2PELU25 needs backward computation.
I0927 19:02:46.607712  3577 net.cpp:198] Eltwise12 needs backward computation.
I0927 19:02:46.607715  3577 net.cpp:198] Scale26 needs backward computation.
I0927 19:02:46.607717  3577 net.cpp:198] BatchNorm26 needs backward computation.
I0927 19:02:46.607719  3577 net.cpp:198] Convolution26 needs backward computation.
I0927 19:02:46.607722  3577 net.cpp:198] M2PELU24 needs backward computation.
I0927 19:02:46.607724  3577 net.cpp:198] Scale25 needs backward computation.
I0927 19:02:46.607727  3577 net.cpp:198] BatchNorm25 needs backward computation.
I0927 19:02:46.607728  3577 net.cpp:198] Convolution25 needs backward computation.
I0927 19:02:46.607730  3577 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0927 19:02:46.607733  3577 net.cpp:198] M2PELU23 needs backward computation.
I0927 19:02:46.607735  3577 net.cpp:198] Eltwise11 needs backward computation.
I0927 19:02:46.607738  3577 net.cpp:198] Scale24 needs backward computation.
I0927 19:02:46.607740  3577 net.cpp:198] BatchNorm24 needs backward computation.
I0927 19:02:46.607743  3577 net.cpp:198] Convolution24 needs backward computation.
I0927 19:02:46.607744  3577 net.cpp:198] M2PELU22 needs backward computation.
I0927 19:02:46.607748  3577 net.cpp:198] Scale23 needs backward computation.
I0927 19:02:46.607749  3577 net.cpp:198] BatchNorm23 needs backward computation.
I0927 19:02:46.607751  3577 net.cpp:198] Convolution23 needs backward computation.
I0927 19:02:46.607753  3577 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0927 19:02:46.607756  3577 net.cpp:198] M2PELU21 needs backward computation.
I0927 19:02:46.607758  3577 net.cpp:198] Eltwise10 needs backward computation.
I0927 19:02:46.607761  3577 net.cpp:198] Scale22 needs backward computation.
I0927 19:02:46.607764  3577 net.cpp:198] BatchNorm22 needs backward computation.
I0927 19:02:46.607765  3577 net.cpp:198] Convolution22 needs backward computation.
I0927 19:02:46.607767  3577 net.cpp:198] M2PELU20 needs backward computation.
I0927 19:02:46.607770  3577 net.cpp:198] Scale21 needs backward computation.
I0927 19:02:46.607772  3577 net.cpp:198] BatchNorm21 needs backward computation.
I0927 19:02:46.607774  3577 net.cpp:198] Convolution21 needs backward computation.
I0927 19:02:46.607777  3577 net.cpp:198] Scale20 needs backward computation.
I0927 19:02:46.607779  3577 net.cpp:198] BatchNorm20 needs backward computation.
I0927 19:02:46.607781  3577 net.cpp:198] Convolution20 needs backward computation.
I0927 19:02:46.607784  3577 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0927 19:02:46.607786  3577 net.cpp:198] M2PELU19 needs backward computation.
I0927 19:02:46.607789  3577 net.cpp:198] Eltwise9 needs backward computation.
I0927 19:02:46.607795  3577 net.cpp:198] Scale19 needs backward computation.
I0927 19:02:46.607797  3577 net.cpp:198] BatchNorm19 needs backward computation.
I0927 19:02:46.607800  3577 net.cpp:198] Convolution19 needs backward computation.
I0927 19:02:46.607802  3577 net.cpp:198] M2PELU18 needs backward computation.
I0927 19:02:46.607805  3577 net.cpp:198] Scale18 needs backward computation.
I0927 19:02:46.607806  3577 net.cpp:198] BatchNorm18 needs backward computation.
I0927 19:02:46.607808  3577 net.cpp:198] Convolution18 needs backward computation.
I0927 19:02:46.607811  3577 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0927 19:02:46.607813  3577 net.cpp:198] M2PELU17 needs backward computation.
I0927 19:02:46.607816  3577 net.cpp:198] Eltwise8 needs backward computation.
I0927 19:02:46.607818  3577 net.cpp:198] Scale17 needs backward computation.
I0927 19:02:46.607820  3577 net.cpp:198] BatchNorm17 needs backward computation.
I0927 19:02:46.607822  3577 net.cpp:198] Convolution17 needs backward computation.
I0927 19:02:46.607825  3577 net.cpp:198] M2PELU16 needs backward computation.
I0927 19:02:46.607827  3577 net.cpp:198] Scale16 needs backward computation.
I0927 19:02:46.607830  3577 net.cpp:198] BatchNorm16 needs backward computation.
I0927 19:02:46.607831  3577 net.cpp:198] Convolution16 needs backward computation.
I0927 19:02:46.607834  3577 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0927 19:02:46.607836  3577 net.cpp:198] M2PELU15 needs backward computation.
I0927 19:02:46.607838  3577 net.cpp:198] Eltwise7 needs backward computation.
I0927 19:02:46.607841  3577 net.cpp:198] Scale15 needs backward computation.
I0927 19:02:46.607843  3577 net.cpp:198] BatchNorm15 needs backward computation.
I0927 19:02:46.607846  3577 net.cpp:198] Convolution15 needs backward computation.
I0927 19:02:46.607848  3577 net.cpp:198] M2PELU14 needs backward computation.
I0927 19:02:46.607851  3577 net.cpp:198] Scale14 needs backward computation.
I0927 19:02:46.607852  3577 net.cpp:198] BatchNorm14 needs backward computation.
I0927 19:02:46.607856  3577 net.cpp:198] Convolution14 needs backward computation.
I0927 19:02:46.607857  3577 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0927 19:02:46.607861  3577 net.cpp:198] M2PELU13 needs backward computation.
I0927 19:02:46.607862  3577 net.cpp:198] Eltwise6 needs backward computation.
I0927 19:02:46.607866  3577 net.cpp:198] Scale13 needs backward computation.
I0927 19:02:46.607868  3577 net.cpp:198] BatchNorm13 needs backward computation.
I0927 19:02:46.607870  3577 net.cpp:198] Convolution13 needs backward computation.
I0927 19:02:46.607872  3577 net.cpp:198] M2PELU12 needs backward computation.
I0927 19:02:46.607874  3577 net.cpp:198] Scale12 needs backward computation.
I0927 19:02:46.607877  3577 net.cpp:198] BatchNorm12 needs backward computation.
I0927 19:02:46.607879  3577 net.cpp:198] Convolution12 needs backward computation.
I0927 19:02:46.607882  3577 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0927 19:02:46.607884  3577 net.cpp:198] M2PELU11 needs backward computation.
I0927 19:02:46.607887  3577 net.cpp:198] Eltwise5 needs backward computation.
I0927 19:02:46.607888  3577 net.cpp:198] Scale11 needs backward computation.
I0927 19:02:46.607892  3577 net.cpp:198] BatchNorm11 needs backward computation.
I0927 19:02:46.607893  3577 net.cpp:198] Convolution11 needs backward computation.
I0927 19:02:46.607895  3577 net.cpp:198] M2PELU10 needs backward computation.
I0927 19:02:46.607898  3577 net.cpp:198] Scale10 needs backward computation.
I0927 19:02:46.607900  3577 net.cpp:198] BatchNorm10 needs backward computation.
I0927 19:02:46.607903  3577 net.cpp:198] Convolution10 needs backward computation.
I0927 19:02:46.607905  3577 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0927 19:02:46.607908  3577 net.cpp:198] M2PELU9 needs backward computation.
I0927 19:02:46.607910  3577 net.cpp:198] Eltwise4 needs backward computation.
I0927 19:02:46.607913  3577 net.cpp:198] Scale9 needs backward computation.
I0927 19:02:46.607918  3577 net.cpp:198] BatchNorm9 needs backward computation.
I0927 19:02:46.607921  3577 net.cpp:198] Convolution9 needs backward computation.
I0927 19:02:46.607924  3577 net.cpp:198] M2PELU8 needs backward computation.
I0927 19:02:46.607926  3577 net.cpp:198] Scale8 needs backward computation.
I0927 19:02:46.607928  3577 net.cpp:198] BatchNorm8 needs backward computation.
I0927 19:02:46.607931  3577 net.cpp:198] Convolution8 needs backward computation.
I0927 19:02:46.607934  3577 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0927 19:02:46.607936  3577 net.cpp:198] M2PELU7 needs backward computation.
I0927 19:02:46.607939  3577 net.cpp:198] Eltwise3 needs backward computation.
I0927 19:02:46.607941  3577 net.cpp:198] Scale7 needs backward computation.
I0927 19:02:46.607944  3577 net.cpp:198] BatchNorm7 needs backward computation.
I0927 19:02:46.607946  3577 net.cpp:198] Convolution7 needs backward computation.
I0927 19:02:46.607949  3577 net.cpp:198] M2PELU6 needs backward computation.
I0927 19:02:46.607950  3577 net.cpp:198] Scale6 needs backward computation.
I0927 19:02:46.607954  3577 net.cpp:198] BatchNorm6 needs backward computation.
I0927 19:02:46.607955  3577 net.cpp:198] Convolution6 needs backward computation.
I0927 19:02:46.607959  3577 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0927 19:02:46.607960  3577 net.cpp:198] M2PELU5 needs backward computation.
I0927 19:02:46.607962  3577 net.cpp:198] Eltwise2 needs backward computation.
I0927 19:02:46.607965  3577 net.cpp:198] Scale5 needs backward computation.
I0927 19:02:46.607969  3577 net.cpp:198] BatchNorm5 needs backward computation.
I0927 19:02:46.607970  3577 net.cpp:198] Convolution5 needs backward computation.
I0927 19:02:46.607972  3577 net.cpp:198] M2PELU4 needs backward computation.
I0927 19:02:46.607975  3577 net.cpp:198] Scale4 needs backward computation.
I0927 19:02:46.607977  3577 net.cpp:198] BatchNorm4 needs backward computation.
I0927 19:02:46.607980  3577 net.cpp:198] Convolution4 needs backward computation.
I0927 19:02:46.607981  3577 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0927 19:02:46.607985  3577 net.cpp:198] M2PELU3 needs backward computation.
I0927 19:02:46.607986  3577 net.cpp:198] Eltwise1 needs backward computation.
I0927 19:02:46.607990  3577 net.cpp:198] Scale3 needs backward computation.
I0927 19:02:46.607991  3577 net.cpp:198] BatchNorm3 needs backward computation.
I0927 19:02:46.607995  3577 net.cpp:198] Convolution3 needs backward computation.
I0927 19:02:46.607996  3577 net.cpp:198] M2PELU2 needs backward computation.
I0927 19:02:46.607998  3577 net.cpp:198] Scale2 needs backward computation.
I0927 19:02:46.608001  3577 net.cpp:198] BatchNorm2 needs backward computation.
I0927 19:02:46.608003  3577 net.cpp:198] Convolution2 needs backward computation.
I0927 19:02:46.608006  3577 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0927 19:02:46.608008  3577 net.cpp:198] M2PELU1 needs backward computation.
I0927 19:02:46.608011  3577 net.cpp:198] Scale1 needs backward computation.
I0927 19:02:46.608012  3577 net.cpp:198] BatchNorm1 needs backward computation.
I0927 19:02:46.608014  3577 net.cpp:198] Convolution1 needs backward computation.
I0927 19:02:46.608017  3577 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0927 19:02:46.608021  3577 net.cpp:200] Data1 does not need backward computation.
I0927 19:02:46.608022  3577 net.cpp:242] This network produces output Accuracy1
I0927 19:02:46.608026  3577 net.cpp:242] This network produces output SoftmaxWithLoss1
I0927 19:02:46.608114  3577 net.cpp:255] Network initialization done.
I0927 19:02:46.608912  3577 solver.cpp:56] Solver scaffolding done.
I0927 19:02:46.621924  3577 caffe.cpp:248] Starting Optimization
I0927 19:02:46.621932  3577 solver.cpp:272] Solving resnet_cifar10
I0927 19:02:46.621934  3577 solver.cpp:273] Learning Rate Policy: multistep
I0927 19:02:46.628142  3577 solver.cpp:330] Iteration 0, Testing net (#0)
I0927 19:02:50.078311  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:02:50.218317  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0927 19:02:50.218344  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0927 19:02:50.415537  3577 solver.cpp:218] Iteration 0 (0 iter/s, 3.79351s/100 iters), loss = 2.30832
I0927 19:02:50.415567  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30832 (* 1 = 2.30832 loss)
I0927 19:02:50.415582  3577 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0927 19:03:04.619190  3577 solver.cpp:218] Iteration 100 (7.04052 iter/s, 14.2035s/100 iters), loss = 1.56744
I0927 19:03:04.619222  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.56744 (* 1 = 1.56744 loss)
I0927 19:03:04.619238  3577 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0927 19:03:18.822993  3577 solver.cpp:218] Iteration 200 (7.04043 iter/s, 14.2037s/100 iters), loss = 1.68054
I0927 19:03:18.823077  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.68054 (* 1 = 1.68054 loss)
I0927 19:03:18.823093  3577 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0927 19:03:33.027742  3577 solver.cpp:218] Iteration 300 (7.03999 iter/s, 14.2046s/100 iters), loss = 1.27122
I0927 19:03:33.027775  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27122 (* 1 = 1.27122 loss)
I0927 19:03:33.027789  3577 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0927 19:03:47.231983  3577 solver.cpp:218] Iteration 400 (7.04021 iter/s, 14.2041s/100 iters), loss = 1.06319
I0927 19:03:47.232014  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06319 (* 1 = 1.06319 loss)
I0927 19:03:47.232030  3577 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0927 19:04:00.738569  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:04:01.308403  3577 solver.cpp:330] Iteration 500, Testing net (#0)
I0927 19:04:04.679582  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:04:04.820267  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3768
I0927 19:04:04.820303  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.28002 (* 1 = 2.28002 loss)
I0927 19:04:04.961558  3577 solver.cpp:218] Iteration 500 (5.64033 iter/s, 17.7295s/100 iters), loss = 1.19004
I0927 19:04:04.961586  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.19004 (* 1 = 1.19004 loss)
I0927 19:04:04.961593  3577 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0927 19:04:19.163494  3577 solver.cpp:218] Iteration 600 (7.04134 iter/s, 14.2018s/100 iters), loss = 1.11121
I0927 19:04:19.163525  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11121 (* 1 = 1.11121 loss)
I0927 19:04:19.163532  3577 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0927 19:04:33.380831  3577 solver.cpp:218] Iteration 700 (7.03371 iter/s, 14.2172s/100 iters), loss = 1.06373
I0927 19:04:33.380947  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06373 (* 1 = 1.06373 loss)
I0927 19:04:33.380970  3577 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0927 19:04:47.599167  3577 solver.cpp:218] Iteration 800 (7.03326 iter/s, 14.2182s/100 iters), loss = 1.04645
I0927 19:04:47.599197  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04645 (* 1 = 1.04645 loss)
I0927 19:04:47.599203  3577 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0927 19:05:01.820919  3577 solver.cpp:218] Iteration 900 (7.03152 iter/s, 14.2217s/100 iters), loss = 0.815699
I0927 19:05:01.820960  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.815699 (* 1 = 0.815699 loss)
I0927 19:05:01.820966  3577 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0927 19:05:15.332439  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:05:15.901901  3577 solver.cpp:330] Iteration 1000, Testing net (#0)
I0927 19:05:19.272822  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:05:19.413964  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5505
I0927 19:05:19.414005  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2405 (* 1 = 1.2405 loss)
I0927 19:05:19.555285  3577 solver.cpp:218] Iteration 1000 (5.6388 iter/s, 17.7343s/100 iters), loss = 0.964907
I0927 19:05:19.555315  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.964907 (* 1 = 0.964907 loss)
I0927 19:05:19.555320  3577 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0927 19:05:33.772328  3577 solver.cpp:218] Iteration 1100 (7.03385 iter/s, 14.217s/100 iters), loss = 0.711798
I0927 19:05:33.772359  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.711798 (* 1 = 0.711798 loss)
I0927 19:05:33.772366  3577 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0927 19:05:47.996549  3577 solver.cpp:218] Iteration 1200 (7.0303 iter/s, 14.2241s/100 iters), loss = 0.767634
I0927 19:05:47.996670  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.767634 (* 1 = 0.767634 loss)
I0927 19:05:47.996687  3577 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0927 19:06:02.229740  3577 solver.cpp:218] Iteration 1300 (7.02591 iter/s, 14.233s/100 iters), loss = 0.895337
I0927 19:06:02.229782  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.895337 (* 1 = 0.895337 loss)
I0927 19:06:02.229789  3577 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0927 19:06:16.452792  3577 solver.cpp:218] Iteration 1400 (7.03089 iter/s, 14.223s/100 iters), loss = 0.686002
I0927 19:06:16.452841  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.686002 (* 1 = 0.686002 loss)
I0927 19:06:16.452848  3577 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0927 19:06:29.971237  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:06:30.541653  3577 solver.cpp:330] Iteration 1500, Testing net (#0)
I0927 19:06:33.913097  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:06:34.053841  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3677
I0927 19:06:34.053879  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.77602 (* 1 = 1.77602 loss)
I0927 19:06:34.195911  3577 solver.cpp:218] Iteration 1500 (5.63602 iter/s, 17.743s/100 iters), loss = 0.78632
I0927 19:06:34.195941  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.78632 (* 1 = 0.78632 loss)
I0927 19:06:34.195947  3577 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0927 19:06:48.420495  3577 solver.cpp:218] Iteration 1600 (7.03013 iter/s, 14.2245s/100 iters), loss = 0.505769
I0927 19:06:48.420532  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505769 (* 1 = 0.505769 loss)
I0927 19:06:48.420539  3577 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0927 19:07:02.642572  3577 solver.cpp:218] Iteration 1700 (7.03137 iter/s, 14.222s/100 iters), loss = 0.727394
I0927 19:07:02.642683  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.727394 (* 1 = 0.727394 loss)
I0927 19:07:02.642689  3577 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0927 19:07:16.873250  3577 solver.cpp:218] Iteration 1800 (7.02715 iter/s, 14.2305s/100 iters), loss = 0.741182
I0927 19:07:16.873291  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.741182 (* 1 = 0.741182 loss)
I0927 19:07:16.873297  3577 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0927 19:07:31.096465  3577 solver.cpp:218] Iteration 1900 (7.0308 iter/s, 14.2231s/100 iters), loss = 0.607488
I0927 19:07:31.096506  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.607488 (* 1 = 0.607488 loss)
I0927 19:07:31.096513  3577 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0927 19:07:44.614040  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:07:45.183658  3577 solver.cpp:330] Iteration 2000, Testing net (#0)
I0927 19:07:48.556123  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:07:48.697137  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2975
I0927 19:07:48.697173  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.98348 (* 1 = 1.98348 loss)
I0927 19:07:48.838254  3577 solver.cpp:218] Iteration 2000 (5.63644 iter/s, 17.7417s/100 iters), loss = 0.743
I0927 19:07:48.838282  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.743 (* 1 = 0.743 loss)
I0927 19:07:48.838289  3577 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0927 19:08:03.056941  3577 solver.cpp:218] Iteration 2100 (7.03304 iter/s, 14.2186s/100 iters), loss = 0.475693
I0927 19:08:03.056982  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.475693 (* 1 = 0.475693 loss)
I0927 19:08:03.056988  3577 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0927 19:08:17.279882  3577 solver.cpp:218] Iteration 2200 (7.03094 iter/s, 14.2228s/100 iters), loss = 0.513223
I0927 19:08:17.279999  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.513223 (* 1 = 0.513223 loss)
I0927 19:08:17.280017  3577 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0927 19:08:31.503015  3577 solver.cpp:218] Iteration 2300 (7.03088 iter/s, 14.223s/100 iters), loss = 0.706807
I0927 19:08:31.503057  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.706807 (* 1 = 0.706807 loss)
I0927 19:08:31.503063  3577 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0927 19:08:45.723937  3577 solver.cpp:218] Iteration 2400 (7.03194 iter/s, 14.2208s/100 iters), loss = 0.595046
I0927 19:08:45.723978  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.595046 (* 1 = 0.595046 loss)
I0927 19:08:45.723984  3577 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0927 19:08:59.241735  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:08:59.810950  3577 solver.cpp:330] Iteration 2500, Testing net (#0)
I0927 19:09:03.181674  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:09:03.322590  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3711
I0927 19:09:03.322626  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.03474 (* 1 = 2.03474 loss)
I0927 19:09:03.464490  3577 solver.cpp:218] Iteration 2500 (5.63683 iter/s, 17.7405s/100 iters), loss = 0.6249
I0927 19:09:03.464520  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.6249 (* 1 = 0.6249 loss)
I0927 19:09:03.464526  3577 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0927 19:09:17.700372  3577 solver.cpp:218] Iteration 2600 (7.02454 iter/s, 14.2358s/100 iters), loss = 0.57244
I0927 19:09:17.700404  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.57244 (* 1 = 0.57244 loss)
I0927 19:09:17.700410  3577 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0927 19:09:31.928407  3577 solver.cpp:218] Iteration 2700 (7.02842 iter/s, 14.2279s/100 iters), loss = 0.572836
I0927 19:09:31.928504  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.572836 (* 1 = 0.572836 loss)
I0927 19:09:31.928521  3577 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0927 19:09:46.150573  3577 solver.cpp:218] Iteration 2800 (7.03134 iter/s, 14.222s/100 iters), loss = 0.660178
I0927 19:09:46.150621  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.660178 (* 1 = 0.660178 loss)
I0927 19:09:46.150629  3577 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0927 19:10:00.378571  3577 solver.cpp:218] Iteration 2900 (7.02844 iter/s, 14.2279s/100 iters), loss = 0.486188
I0927 19:10:00.378609  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486188 (* 1 = 0.486188 loss)
I0927 19:10:00.378617  3577 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0927 19:10:13.896603  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:10:14.465806  3577 solver.cpp:330] Iteration 3000, Testing net (#0)
I0927 19:10:17.834751  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:10:17.975991  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.391
I0927 19:10:17.976027  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.85683 (* 1 = 1.85683 loss)
I0927 19:10:18.117776  3577 solver.cpp:218] Iteration 3000 (5.63726 iter/s, 17.7391s/100 iters), loss = 0.51146
I0927 19:10:18.117805  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51146 (* 1 = 0.51146 loss)
I0927 19:10:18.117812  3577 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0927 19:10:32.326941  3577 solver.cpp:218] Iteration 3100 (7.03775 iter/s, 14.2091s/100 iters), loss = 0.436899
I0927 19:10:32.326983  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436899 (* 1 = 0.436899 loss)
I0927 19:10:32.326989  3577 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0927 19:10:46.543799  3577 solver.cpp:218] Iteration 3200 (7.03395 iter/s, 14.2168s/100 iters), loss = 0.459283
I0927 19:10:46.543927  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459283 (* 1 = 0.459283 loss)
I0927 19:10:46.543946  3577 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0927 19:11:00.763586  3577 solver.cpp:218] Iteration 3300 (7.03254 iter/s, 14.2196s/100 iters), loss = 0.553798
I0927 19:11:00.763628  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.553798 (* 1 = 0.553798 loss)
I0927 19:11:00.763633  3577 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0927 19:11:14.986307  3577 solver.cpp:218] Iteration 3400 (7.03105 iter/s, 14.2226s/100 iters), loss = 0.516708
I0927 19:11:14.986348  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.516708 (* 1 = 0.516708 loss)
I0927 19:11:14.986354  3577 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0927 19:11:28.503136  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:11:29.074000  3577 solver.cpp:330] Iteration 3500, Testing net (#0)
I0927 19:11:32.442584  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:11:32.584062  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4189
I0927 19:11:32.584098  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.74618 (* 1 = 1.74618 loss)
I0927 19:11:32.725303  3577 solver.cpp:218] Iteration 3500 (5.63733 iter/s, 17.7389s/100 iters), loss = 0.407611
I0927 19:11:32.725332  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407611 (* 1 = 0.407611 loss)
I0927 19:11:32.725338  3577 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0927 19:11:46.951616  3577 solver.cpp:218] Iteration 3600 (7.02926 iter/s, 14.2262s/100 iters), loss = 0.442891
I0927 19:11:46.951656  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442891 (* 1 = 0.442891 loss)
I0927 19:11:46.951663  3577 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0927 19:12:01.184423  3577 solver.cpp:218] Iteration 3700 (7.02606 iter/s, 14.2327s/100 iters), loss = 0.388618
I0927 19:12:01.184510  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388618 (* 1 = 0.388618 loss)
I0927 19:12:01.184526  3577 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0927 19:12:15.410779  3577 solver.cpp:218] Iteration 3800 (7.02927 iter/s, 14.2262s/100 iters), loss = 0.464411
I0927 19:12:15.410821  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464411 (* 1 = 0.464411 loss)
I0927 19:12:15.410826  3577 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0927 19:12:29.637243  3577 solver.cpp:218] Iteration 3900 (7.0292 iter/s, 14.2264s/100 iters), loss = 0.50723
I0927 19:12:29.637284  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50723 (* 1 = 0.50723 loss)
I0927 19:12:29.637290  3577 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0927 19:12:43.161125  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:12:43.731689  3577 solver.cpp:330] Iteration 4000, Testing net (#0)
I0927 19:12:47.100965  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:12:47.241762  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3697
I0927 19:12:47.241798  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.93445 (* 1 = 1.93445 loss)
I0927 19:12:47.383054  3577 solver.cpp:218] Iteration 4000 (5.63516 iter/s, 17.7457s/100 iters), loss = 0.485441
I0927 19:12:47.383085  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.485441 (* 1 = 0.485441 loss)
I0927 19:12:47.383091  3577 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0927 19:13:01.605301  3577 solver.cpp:218] Iteration 4100 (7.03127 iter/s, 14.2222s/100 iters), loss = 0.410256
I0927 19:13:01.605331  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410256 (* 1 = 0.410256 loss)
I0927 19:13:01.605337  3577 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0927 19:13:15.830169  3577 solver.cpp:218] Iteration 4200 (7.02998 iter/s, 14.2248s/100 iters), loss = 0.418209
I0927 19:13:15.830289  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418209 (* 1 = 0.418209 loss)
I0927 19:13:15.830307  3577 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0927 19:13:30.058295  3577 solver.cpp:218] Iteration 4300 (7.02841 iter/s, 14.228s/100 iters), loss = 0.445723
I0927 19:13:30.058326  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445723 (* 1 = 0.445723 loss)
I0927 19:13:30.058331  3577 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0927 19:13:44.281148  3577 solver.cpp:218] Iteration 4400 (7.03097 iter/s, 14.2228s/100 iters), loss = 0.453962
I0927 19:13:44.281180  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453962 (* 1 = 0.453962 loss)
I0927 19:13:44.281188  3577 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0927 19:13:57.800814  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:13:58.371038  3577 solver.cpp:330] Iteration 4500, Testing net (#0)
I0927 19:14:01.740095  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:14:01.881201  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4602
I0927 19:14:01.881237  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48626 (* 1 = 1.48626 loss)
I0927 19:14:02.023349  3577 solver.cpp:218] Iteration 4500 (5.63631 iter/s, 17.7421s/100 iters), loss = 0.511577
I0927 19:14:02.023377  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511577 (* 1 = 0.511577 loss)
I0927 19:14:02.023385  3577 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0927 19:14:16.241116  3577 solver.cpp:218] Iteration 4600 (7.03349 iter/s, 14.2177s/100 iters), loss = 0.364143
I0927 19:14:16.241156  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364143 (* 1 = 0.364143 loss)
I0927 19:14:16.241163  3577 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0927 19:14:30.462290  3577 solver.cpp:218] Iteration 4700 (7.03181 iter/s, 14.2211s/100 iters), loss = 0.333093
I0927 19:14:30.462396  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333093 (* 1 = 0.333093 loss)
I0927 19:14:30.462404  3577 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0927 19:14:44.683274  3577 solver.cpp:218] Iteration 4800 (7.03193 iter/s, 14.2208s/100 iters), loss = 0.424185
I0927 19:14:44.683321  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424185 (* 1 = 0.424185 loss)
I0927 19:14:44.683328  3577 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0927 19:14:58.905876  3577 solver.cpp:218] Iteration 4900 (7.03111 iter/s, 14.2225s/100 iters), loss = 0.492268
I0927 19:14:58.905917  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492268 (* 1 = 0.492268 loss)
I0927 19:14:58.905923  3577 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0927 19:15:12.426235  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:15:12.994871  3577 solver.cpp:330] Iteration 5000, Testing net (#0)
I0927 19:15:16.361666  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:15:16.502387  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5786
I0927 19:15:16.502424  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14476 (* 1 = 1.14476 loss)
I0927 19:15:16.643712  3577 solver.cpp:218] Iteration 5000 (5.6377 iter/s, 17.7377s/100 iters), loss = 0.454201
I0927 19:15:16.643743  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454201 (* 1 = 0.454201 loss)
I0927 19:15:16.643749  3577 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0927 19:15:30.860502  3577 solver.cpp:218] Iteration 5100 (7.03399 iter/s, 14.2167s/100 iters), loss = 0.362161
I0927 19:15:30.860543  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362161 (* 1 = 0.362161 loss)
I0927 19:15:30.860548  3577 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0927 19:15:45.082379  3577 solver.cpp:218] Iteration 5200 (7.03146 iter/s, 14.2218s/100 iters), loss = 0.333671
I0927 19:15:45.082490  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333671 (* 1 = 0.333671 loss)
I0927 19:15:45.082497  3577 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0927 19:15:59.302503  3577 solver.cpp:218] Iteration 5300 (7.03236 iter/s, 14.22s/100 iters), loss = 0.468175
I0927 19:15:59.302547  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468175 (* 1 = 0.468175 loss)
I0927 19:15:59.302553  3577 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0927 19:16:13.530333  3577 solver.cpp:218] Iteration 5400 (7.02852 iter/s, 14.2277s/100 iters), loss = 0.410086
I0927 19:16:13.530380  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410086 (* 1 = 0.410086 loss)
I0927 19:16:13.530386  3577 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0927 19:16:27.047530  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:16:27.615591  3577 solver.cpp:330] Iteration 5500, Testing net (#0)
I0927 19:16:30.984791  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:16:31.125515  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6308
I0927 19:16:31.125552  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04627 (* 1 = 1.04627 loss)
I0927 19:16:31.267469  3577 solver.cpp:218] Iteration 5500 (5.63792 iter/s, 17.737s/100 iters), loss = 0.403251
I0927 19:16:31.267498  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403251 (* 1 = 0.403251 loss)
I0927 19:16:31.267504  3577 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0927 19:16:45.513726  3577 solver.cpp:218] Iteration 5600 (7.01942 iter/s, 14.2462s/100 iters), loss = 0.339567
I0927 19:16:45.513769  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339567 (* 1 = 0.339567 loss)
I0927 19:16:45.513774  3577 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0927 19:16:59.756918  3577 solver.cpp:218] Iteration 5700 (7.02094 iter/s, 14.2431s/100 iters), loss = 0.390722
I0927 19:16:59.757004  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390722 (* 1 = 0.390722 loss)
I0927 19:16:59.757021  3577 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0927 19:17:14.009037  3577 solver.cpp:218] Iteration 5800 (7.01656 iter/s, 14.252s/100 iters), loss = 0.444051
I0927 19:17:14.009079  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444051 (* 1 = 0.444051 loss)
I0927 19:17:14.009085  3577 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0927 19:17:28.259021  3577 solver.cpp:218] Iteration 5900 (7.01759 iter/s, 14.2499s/100 iters), loss = 0.459343
I0927 19:17:28.259052  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459343 (* 1 = 0.459343 loss)
I0927 19:17:28.259058  3577 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0927 19:17:41.799906  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:17:42.371137  3577 solver.cpp:330] Iteration 6000, Testing net (#0)
I0927 19:17:45.745085  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:17:45.886317  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.707
I0927 19:17:45.886343  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.868916 (* 1 = 0.868916 loss)
I0927 19:17:46.027529  3577 solver.cpp:218] Iteration 6000 (5.62796 iter/s, 17.7684s/100 iters), loss = 0.373031
I0927 19:17:46.027559  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373031 (* 1 = 0.373031 loss)
I0927 19:17:46.027566  3577 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0927 19:18:00.258401  3577 solver.cpp:218] Iteration 6100 (7.02703 iter/s, 14.2308s/100 iters), loss = 0.312921
I0927 19:18:00.258432  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312921 (* 1 = 0.312921 loss)
I0927 19:18:00.258440  3577 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0927 19:18:14.497308  3577 solver.cpp:218] Iteration 6200 (7.02305 iter/s, 14.2388s/100 iters), loss = 0.308553
I0927 19:18:14.497452  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308553 (* 1 = 0.308553 loss)
I0927 19:18:14.497459  3577 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0927 19:18:28.729058  3577 solver.cpp:218] Iteration 6300 (7.02663 iter/s, 14.2316s/100 iters), loss = 0.431976
I0927 19:18:28.729100  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431976 (* 1 = 0.431976 loss)
I0927 19:18:28.729106  3577 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0927 19:18:42.961668  3577 solver.cpp:218] Iteration 6400 (7.02616 iter/s, 14.2325s/100 iters), loss = 0.259466
I0927 19:18:42.961709  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259466 (* 1 = 0.259466 loss)
I0927 19:18:42.961714  3577 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0927 19:18:56.495069  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:18:57.064257  3577 solver.cpp:330] Iteration 6500, Testing net (#0)
I0927 19:19:00.440124  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:19:00.581434  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7354
I0927 19:19:00.581471  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.784557 (* 1 = 0.784557 loss)
I0927 19:19:00.722685  3577 solver.cpp:218] Iteration 6500 (5.63034 iter/s, 17.7609s/100 iters), loss = 0.322581
I0927 19:19:00.722714  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322581 (* 1 = 0.322581 loss)
I0927 19:19:00.722721  3577 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0927 19:19:14.966905  3577 solver.cpp:218] Iteration 6600 (7.02043 iter/s, 14.2441s/100 iters), loss = 0.344736
I0927 19:19:14.966945  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344736 (* 1 = 0.344736 loss)
I0927 19:19:14.966951  3577 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0927 19:19:29.212626  3577 solver.cpp:218] Iteration 6700 (7.01969 iter/s, 14.2456s/100 iters), loss = 0.346544
I0927 19:19:29.212715  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346544 (* 1 = 0.346544 loss)
I0927 19:19:29.212731  3577 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0927 19:19:43.459039  3577 solver.cpp:218] Iteration 6800 (7.01937 iter/s, 14.2463s/100 iters), loss = 0.304834
I0927 19:19:43.459081  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304834 (* 1 = 0.304834 loss)
I0927 19:19:43.459087  3577 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0927 19:19:57.708776  3577 solver.cpp:218] Iteration 6900 (7.01771 iter/s, 14.2497s/100 iters), loss = 0.379567
I0927 19:19:57.708818  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379568 (* 1 = 0.379568 loss)
I0927 19:19:57.708824  3577 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0927 19:20:11.251032  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:20:11.821789  3577 solver.cpp:330] Iteration 7000, Testing net (#0)
I0927 19:20:15.197037  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:20:15.337849  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7841
I0927 19:20:15.337887  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.690282 (* 1 = 0.690282 loss)
I0927 19:20:15.478953  3577 solver.cpp:218] Iteration 7000 (5.62744 iter/s, 17.7701s/100 iters), loss = 0.340418
I0927 19:20:15.478983  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340418 (* 1 = 0.340418 loss)
I0927 19:20:15.478989  3577 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0927 19:20:29.714002  3577 solver.cpp:218] Iteration 7100 (7.02495 iter/s, 14.235s/100 iters), loss = 0.265369
I0927 19:20:29.714032  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265369 (* 1 = 0.265369 loss)
I0927 19:20:29.714038  3577 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0927 19:20:43.953764  3577 solver.cpp:218] Iteration 7200 (7.02262 iter/s, 14.2397s/100 iters), loss = 0.299853
I0927 19:20:43.953881  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299853 (* 1 = 0.299853 loss)
I0927 19:20:43.953888  3577 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0927 19:20:58.192956  3577 solver.cpp:218] Iteration 7300 (7.02295 iter/s, 14.239s/100 iters), loss = 0.432394
I0927 19:20:58.192986  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432394 (* 1 = 0.432394 loss)
I0927 19:20:58.192992  3577 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0927 19:21:12.432657  3577 solver.cpp:218] Iteration 7400 (7.02266 iter/s, 14.2396s/100 iters), loss = 0.389389
I0927 19:21:12.432687  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389389 (* 1 = 0.389389 loss)
I0927 19:21:12.432693  3577 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0927 19:21:25.963312  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:21:26.533103  3577 solver.cpp:330] Iteration 7500, Testing net (#0)
I0927 19:21:29.906312  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:21:30.046882  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7324
I0927 19:21:30.046918  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.80606 (* 1 = 0.80606 loss)
I0927 19:21:30.188319  3577 solver.cpp:218] Iteration 7500 (5.63203 iter/s, 17.7556s/100 iters), loss = 0.25509
I0927 19:21:30.188350  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25509 (* 1 = 0.25509 loss)
I0927 19:21:30.188357  3577 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0927 19:21:44.429595  3577 solver.cpp:218] Iteration 7600 (7.02188 iter/s, 14.2412s/100 iters), loss = 0.389569
I0927 19:21:44.429636  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389569 (* 1 = 0.389569 loss)
I0927 19:21:44.429642  3577 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0927 19:21:58.675144  3577 solver.cpp:218] Iteration 7700 (7.01978 iter/s, 14.2455s/100 iters), loss = 0.340172
I0927 19:21:58.675277  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340172 (* 1 = 0.340172 loss)
I0927 19:21:58.675284  3577 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0927 19:22:12.917549  3577 solver.cpp:218] Iteration 7800 (7.02137 iter/s, 14.2422s/100 iters), loss = 0.286103
I0927 19:22:12.917589  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286103 (* 1 = 0.286103 loss)
I0927 19:22:12.917595  3577 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0927 19:22:27.165987  3577 solver.cpp:218] Iteration 7900 (7.01835 iter/s, 14.2484s/100 iters), loss = 0.387788
I0927 19:22:27.166026  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387788 (* 1 = 0.387788 loss)
I0927 19:22:27.166033  3577 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0927 19:22:40.701599  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:22:41.271200  3577 solver.cpp:330] Iteration 8000, Testing net (#0)
I0927 19:22:44.642803  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:22:44.783910  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6999
I0927 19:22:44.783936  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.878784 (* 1 = 0.878784 loss)
I0927 19:22:44.925216  3577 solver.cpp:218] Iteration 8000 (5.6309 iter/s, 17.7591s/100 iters), loss = 0.280347
I0927 19:22:44.925248  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280347 (* 1 = 0.280347 loss)
I0927 19:22:44.925254  3577 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0927 19:22:59.166656  3577 solver.cpp:218] Iteration 8100 (7.0218 iter/s, 14.2414s/100 iters), loss = 0.236834
I0927 19:22:59.166695  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236835 (* 1 = 0.236835 loss)
I0927 19:22:59.166702  3577 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0927 19:23:13.408059  3577 solver.cpp:218] Iteration 8200 (7.02182 iter/s, 14.2413s/100 iters), loss = 0.346532
I0927 19:23:13.408210  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346533 (* 1 = 0.346533 loss)
I0927 19:23:13.408228  3577 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0927 19:23:27.653486  3577 solver.cpp:218] Iteration 8300 (7.01989 iter/s, 14.2452s/100 iters), loss = 0.28561
I0927 19:23:27.653529  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28561 (* 1 = 0.28561 loss)
I0927 19:23:27.653535  3577 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0927 19:23:41.892419  3577 solver.cpp:218] Iteration 8400 (7.02304 iter/s, 14.2388s/100 iters), loss = 0.291038
I0927 19:23:41.892462  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291038 (* 1 = 0.291038 loss)
I0927 19:23:41.892468  3577 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0927 19:23:55.428338  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:23:55.997558  3577 solver.cpp:330] Iteration 8500, Testing net (#0)
I0927 19:23:59.371915  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:23:59.513216  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.743
I0927 19:23:59.513253  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.738266 (* 1 = 0.738266 loss)
I0927 19:23:59.655165  3577 solver.cpp:218] Iteration 8500 (5.62979 iter/s, 17.7627s/100 iters), loss = 0.34001
I0927 19:23:59.655195  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34001 (* 1 = 0.34001 loss)
I0927 19:23:59.655202  3577 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0927 19:24:13.890168  3577 solver.cpp:218] Iteration 8600 (7.02497 iter/s, 14.2349s/100 iters), loss = 0.370679
I0927 19:24:13.890210  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370679 (* 1 = 0.370679 loss)
I0927 19:24:13.890216  3577 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0927 19:24:28.127265  3577 solver.cpp:218] Iteration 8700 (7.02394 iter/s, 14.237s/100 iters), loss = 0.239787
I0927 19:24:28.127400  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239787 (* 1 = 0.239787 loss)
I0927 19:24:28.127408  3577 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0927 19:24:42.367178  3577 solver.cpp:218] Iteration 8800 (7.0226 iter/s, 14.2397s/100 iters), loss = 0.339895
I0927 19:24:42.367209  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339896 (* 1 = 0.339896 loss)
I0927 19:24:42.367215  3577 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0927 19:24:56.605301  3577 solver.cpp:218] Iteration 8900 (7.02343 iter/s, 14.2381s/100 iters), loss = 0.26117
I0927 19:24:56.605343  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26117 (* 1 = 0.26117 loss)
I0927 19:24:56.605350  3577 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0927 19:25:10.139056  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:25:10.708564  3577 solver.cpp:330] Iteration 9000, Testing net (#0)
I0927 19:25:14.082176  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:25:14.222995  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6592
I0927 19:25:14.223031  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02702 (* 1 = 1.02702 loss)
I0927 19:25:14.365357  3577 solver.cpp:218] Iteration 9000 (5.63064 iter/s, 17.76s/100 iters), loss = 0.270823
I0927 19:25:14.365387  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270823 (* 1 = 0.270823 loss)
I0927 19:25:14.365394  3577 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0927 19:25:28.601979  3577 solver.cpp:218] Iteration 9100 (7.02417 iter/s, 14.2366s/100 iters), loss = 0.321416
I0927 19:25:28.602020  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321416 (* 1 = 0.321416 loss)
I0927 19:25:28.602026  3577 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0927 19:25:42.845000  3577 solver.cpp:218] Iteration 9200 (7.02102 iter/s, 14.2429s/100 iters), loss = 0.351379
I0927 19:25:42.845098  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351379 (* 1 = 0.351379 loss)
I0927 19:25:42.845104  3577 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0927 19:25:57.084410  3577 solver.cpp:218] Iteration 9300 (7.02283 iter/s, 14.2393s/100 iters), loss = 0.2899
I0927 19:25:57.084441  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2899 (* 1 = 0.2899 loss)
I0927 19:25:57.084448  3577 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0927 19:26:11.327827  3577 solver.cpp:218] Iteration 9400 (7.02082 iter/s, 14.2433s/100 iters), loss = 0.212189
I0927 19:26:11.327868  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212189 (* 1 = 0.212189 loss)
I0927 19:26:11.327873  3577 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0927 19:26:24.859194  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:26:25.429128  3577 solver.cpp:330] Iteration 9500, Testing net (#0)
I0927 19:26:28.804111  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:26:28.944907  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7838
I0927 19:26:28.944943  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.66813 (* 1 = 0.66813 loss)
I0927 19:26:29.086670  3577 solver.cpp:218] Iteration 9500 (5.63103 iter/s, 17.7588s/100 iters), loss = 0.245563
I0927 19:26:29.086701  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245563 (* 1 = 0.245563 loss)
I0927 19:26:29.086707  3577 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0927 19:26:43.320235  3577 solver.cpp:218] Iteration 9600 (7.02568 iter/s, 14.2335s/100 iters), loss = 0.272011
I0927 19:26:43.320276  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272012 (* 1 = 0.272012 loss)
I0927 19:26:43.320281  3577 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0927 19:26:57.558547  3577 solver.cpp:218] Iteration 9700 (7.02334 iter/s, 14.2382s/100 iters), loss = 0.264442
I0927 19:26:57.558595  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264442 (* 1 = 0.264442 loss)
I0927 19:26:57.558603  3577 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0927 19:27:11.802261  3577 solver.cpp:218] Iteration 9800 (7.02068 iter/s, 14.2436s/100 iters), loss = 0.335719
I0927 19:27:11.802291  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335719 (* 1 = 0.335719 loss)
I0927 19:27:11.802297  3577 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0927 19:27:26.043709  3577 solver.cpp:218] Iteration 9900 (7.02179 iter/s, 14.2414s/100 iters), loss = 0.255318
I0927 19:27:26.043741  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255318 (* 1 = 0.255318 loss)
I0927 19:27:26.043747  3577 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0927 19:27:39.574403  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:27:40.145193  3577 solver.cpp:330] Iteration 10000, Testing net (#0)
I0927 19:27:43.519649  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:27:43.660737  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.753
I0927 19:27:43.660775  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.758038 (* 1 = 0.758038 loss)
I0927 19:27:43.802918  3577 solver.cpp:218] Iteration 10000 (5.63091 iter/s, 17.7591s/100 iters), loss = 0.275531
I0927 19:27:43.802949  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275531 (* 1 = 0.275531 loss)
I0927 19:27:43.802955  3577 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0927 19:27:58.041345  3577 solver.cpp:218] Iteration 10100 (7.02328 iter/s, 14.2384s/100 iters), loss = 0.282028
I0927 19:27:58.041386  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282028 (* 1 = 0.282028 loss)
I0927 19:27:58.041393  3577 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0927 19:28:12.286674  3577 solver.cpp:218] Iteration 10200 (7.01988 iter/s, 14.2452s/100 iters), loss = 0.313
I0927 19:28:12.286772  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313 (* 1 = 0.313 loss)
I0927 19:28:12.286779  3577 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0927 19:28:26.526582  3577 solver.cpp:218] Iteration 10300 (7.02259 iter/s, 14.2398s/100 iters), loss = 0.320827
I0927 19:28:26.526623  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320827 (* 1 = 0.320827 loss)
I0927 19:28:26.526628  3577 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0927 19:28:40.772256  3577 solver.cpp:218] Iteration 10400 (7.01971 iter/s, 14.2456s/100 iters), loss = 0.365066
I0927 19:28:40.772298  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365067 (* 1 = 0.365067 loss)
I0927 19:28:40.772305  3577 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0927 19:28:54.309247  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:28:54.879194  3577 solver.cpp:330] Iteration 10500, Testing net (#0)
I0927 19:28:58.253990  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:28:58.394716  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7855
I0927 19:28:58.394753  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.639766 (* 1 = 0.639766 loss)
I0927 19:28:58.537118  3577 solver.cpp:218] Iteration 10500 (5.62912 iter/s, 17.7648s/100 iters), loss = 0.240078
I0927 19:28:58.537150  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240078 (* 1 = 0.240078 loss)
I0927 19:28:58.537158  3577 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0927 19:29:12.784525  3577 solver.cpp:218] Iteration 10600 (7.01886 iter/s, 14.2473s/100 iters), loss = 0.272954
I0927 19:29:12.784567  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272954 (* 1 = 0.272954 loss)
I0927 19:29:12.784574  3577 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0927 19:29:27.030200  3577 solver.cpp:218] Iteration 10700 (7.01972 iter/s, 14.2456s/100 iters), loss = 0.192559
I0927 19:29:27.030297  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192559 (* 1 = 0.192559 loss)
I0927 19:29:27.030303  3577 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0927 19:29:41.273993  3577 solver.cpp:218] Iteration 10800 (7.02067 iter/s, 14.2437s/100 iters), loss = 0.31932
I0927 19:29:41.274034  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31932 (* 1 = 0.31932 loss)
I0927 19:29:41.274040  3577 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0927 19:29:55.516165  3577 solver.cpp:218] Iteration 10900 (7.02144 iter/s, 14.2421s/100 iters), loss = 0.295276
I0927 19:29:55.516193  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295277 (* 1 = 0.295277 loss)
I0927 19:29:55.516199  3577 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0927 19:30:09.056658  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:30:09.627780  3577 solver.cpp:330] Iteration 11000, Testing net (#0)
I0927 19:30:13.002843  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:30:13.144242  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7479
I0927 19:30:13.144279  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.825182 (* 1 = 0.825182 loss)
I0927 19:30:13.286041  3577 solver.cpp:218] Iteration 11000 (5.62752 iter/s, 17.7698s/100 iters), loss = 0.257706
I0927 19:30:13.286072  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257707 (* 1 = 0.257707 loss)
I0927 19:30:13.286077  3577 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0927 19:30:27.516811  3577 solver.cpp:218] Iteration 11100 (7.02706 iter/s, 14.2307s/100 iters), loss = 0.275411
I0927 19:30:27.516842  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275411 (* 1 = 0.275411 loss)
I0927 19:30:27.516849  3577 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0927 19:30:41.750102  3577 solver.cpp:218] Iteration 11200 (7.02582 iter/s, 14.2332s/100 iters), loss = 0.326436
I0927 19:30:41.750239  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326436 (* 1 = 0.326436 loss)
I0927 19:30:41.750247  3577 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0927 19:30:55.988101  3577 solver.cpp:218] Iteration 11300 (7.02354 iter/s, 14.2378s/100 iters), loss = 0.252943
I0927 19:30:55.988131  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252943 (* 1 = 0.252943 loss)
I0927 19:30:55.988137  3577 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0927 19:31:10.224164  3577 solver.cpp:218] Iteration 11400 (7.02445 iter/s, 14.236s/100 iters), loss = 0.364264
I0927 19:31:10.224205  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364264 (* 1 = 0.364264 loss)
I0927 19:31:10.224210  3577 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0927 19:31:23.756156  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:31:24.326339  3577 solver.cpp:330] Iteration 11500, Testing net (#0)
I0927 19:31:27.701354  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:31:27.842644  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6722
I0927 19:31:27.842681  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14947 (* 1 = 1.14947 loss)
I0927 19:31:27.984164  3577 solver.cpp:218] Iteration 11500 (5.63066 iter/s, 17.7599s/100 iters), loss = 0.224641
I0927 19:31:27.984194  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224641 (* 1 = 0.224641 loss)
I0927 19:31:27.984201  3577 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0927 19:31:42.221420  3577 solver.cpp:218] Iteration 11600 (7.02386 iter/s, 14.2372s/100 iters), loss = 0.221485
I0927 19:31:42.221460  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221485 (* 1 = 0.221485 loss)
I0927 19:31:42.221467  3577 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0927 19:31:56.464972  3577 solver.cpp:218] Iteration 11700 (7.02076 iter/s, 14.2435s/100 iters), loss = 0.224223
I0927 19:31:56.465095  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224223 (* 1 = 0.224223 loss)
I0927 19:31:56.465113  3577 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0927 19:32:10.707592  3577 solver.cpp:218] Iteration 11800 (7.02126 iter/s, 14.2425s/100 iters), loss = 0.281551
I0927 19:32:10.707634  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281551 (* 1 = 0.281551 loss)
I0927 19:32:10.707639  3577 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0927 19:32:24.948983  3577 solver.cpp:218] Iteration 11900 (7.02183 iter/s, 14.2413s/100 iters), loss = 0.379486
I0927 19:32:24.949024  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379486 (* 1 = 0.379486 loss)
I0927 19:32:24.949029  3577 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0927 19:32:38.482681  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:32:39.052968  3577 solver.cpp:330] Iteration 12000, Testing net (#0)
I0927 19:32:42.427721  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:32:42.568840  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8079
I0927 19:32:42.568876  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.582194 (* 1 = 0.582194 loss)
I0927 19:32:42.710430  3577 solver.cpp:218] Iteration 12000 (5.6302 iter/s, 17.7614s/100 iters), loss = 0.237118
I0927 19:32:42.710461  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237118 (* 1 = 0.237118 loss)
I0927 19:32:42.710467  3577 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0927 19:32:56.946132  3577 solver.cpp:218] Iteration 12100 (7.02463 iter/s, 14.2356s/100 iters), loss = 0.268215
I0927 19:32:56.946174  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268215 (* 1 = 0.268215 loss)
I0927 19:32:56.946180  3577 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0927 19:33:11.190922  3577 solver.cpp:218] Iteration 12200 (7.02015 iter/s, 14.2447s/100 iters), loss = 0.247212
I0927 19:33:11.191011  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247212 (* 1 = 0.247212 loss)
I0927 19:33:11.191028  3577 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0927 19:33:25.431186  3577 solver.cpp:218] Iteration 12300 (7.0224 iter/s, 14.2401s/100 iters), loss = 0.249555
I0927 19:33:25.431228  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249555 (* 1 = 0.249555 loss)
I0927 19:33:25.431233  3577 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0927 19:33:39.669700  3577 solver.cpp:218] Iteration 12400 (7.02324 iter/s, 14.2384s/100 iters), loss = 0.358009
I0927 19:33:39.669740  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358009 (* 1 = 0.358009 loss)
I0927 19:33:39.669746  3577 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0927 19:33:53.198518  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:33:53.770779  3577 solver.cpp:330] Iteration 12500, Testing net (#0)
I0927 19:33:57.145695  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:33:57.286553  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7428
I0927 19:33:57.286590  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.791836 (* 1 = 0.791836 loss)
I0927 19:33:57.428786  3577 solver.cpp:218] Iteration 12500 (5.63095 iter/s, 17.759s/100 iters), loss = 0.152505
I0927 19:33:57.428815  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152505 (* 1 = 0.152505 loss)
I0927 19:33:57.428822  3577 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0927 19:34:11.666396  3577 solver.cpp:218] Iteration 12600 (7.0237 iter/s, 14.2375s/100 iters), loss = 0.26156
I0927 19:34:11.666425  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26156 (* 1 = 0.26156 loss)
I0927 19:34:11.666430  3577 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0927 19:34:25.910919  3577 solver.cpp:218] Iteration 12700 (7.02028 iter/s, 14.2445s/100 iters), loss = 0.192048
I0927 19:34:25.911059  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192048 (* 1 = 0.192048 loss)
I0927 19:34:25.911067  3577 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0927 19:34:40.149963  3577 solver.cpp:218] Iteration 12800 (7.02303 iter/s, 14.2389s/100 iters), loss = 0.231266
I0927 19:34:40.149996  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231266 (* 1 = 0.231266 loss)
I0927 19:34:40.150002  3577 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0927 19:34:54.395637  3577 solver.cpp:218] Iteration 12900 (7.01971 iter/s, 14.2456s/100 iters), loss = 0.311619
I0927 19:34:54.395678  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311619 (* 1 = 0.311619 loss)
I0927 19:34:54.395684  3577 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0927 19:35:07.936281  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:35:08.506714  3577 solver.cpp:330] Iteration 13000, Testing net (#0)
I0927 19:35:11.882377  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:35:12.023629  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7483
I0927 19:35:12.023664  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.726776 (* 1 = 0.726776 loss)
I0927 19:35:12.165375  3577 solver.cpp:218] Iteration 13000 (5.62757 iter/s, 17.7696s/100 iters), loss = 0.201745
I0927 19:35:12.165406  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201745 (* 1 = 0.201745 loss)
I0927 19:35:12.165413  3577 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0927 19:35:26.404443  3577 solver.cpp:218] Iteration 13100 (7.02297 iter/s, 14.239s/100 iters), loss = 0.198285
I0927 19:35:26.404485  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198285 (* 1 = 0.198285 loss)
I0927 19:35:26.404491  3577 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0927 19:35:40.653743  3577 solver.cpp:218] Iteration 13200 (7.01793 iter/s, 14.2492s/100 iters), loss = 0.234465
I0927 19:35:40.653867  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234465 (* 1 = 0.234465 loss)
I0927 19:35:40.653873  3577 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0927 19:35:54.902145  3577 solver.cpp:218] Iteration 13300 (7.0184 iter/s, 14.2483s/100 iters), loss = 0.191697
I0927 19:35:54.902189  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191698 (* 1 = 0.191698 loss)
I0927 19:35:54.902194  3577 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0927 19:36:09.148705  3577 solver.cpp:218] Iteration 13400 (7.01928 iter/s, 14.2465s/100 iters), loss = 0.245884
I0927 19:36:09.148746  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245884 (* 1 = 0.245884 loss)
I0927 19:36:09.148752  3577 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0927 19:36:22.687813  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:36:23.258503  3577 solver.cpp:330] Iteration 13500, Testing net (#0)
I0927 19:36:26.633550  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:36:26.774507  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7704
I0927 19:36:26.774545  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.726045 (* 1 = 0.726045 loss)
I0927 19:36:26.916483  3577 solver.cpp:218] Iteration 13500 (5.62819 iter/s, 17.7677s/100 iters), loss = 0.19127
I0927 19:36:26.916513  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19127 (* 1 = 0.19127 loss)
I0927 19:36:26.916519  3577 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0927 19:36:41.158145  3577 solver.cpp:218] Iteration 13600 (7.02169 iter/s, 14.2416s/100 iters), loss = 0.26568
I0927 19:36:41.158176  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265681 (* 1 = 0.265681 loss)
I0927 19:36:41.158182  3577 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0927 19:36:55.395514  3577 solver.cpp:218] Iteration 13700 (7.02381 iter/s, 14.2373s/100 iters), loss = 0.253873
I0927 19:36:55.395640  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253873 (* 1 = 0.253873 loss)
I0927 19:36:55.395648  3577 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0927 19:37:09.640290  3577 solver.cpp:218] Iteration 13800 (7.0202 iter/s, 14.2446s/100 iters), loss = 0.191432
I0927 19:37:09.640332  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191433 (* 1 = 0.191433 loss)
I0927 19:37:09.640338  3577 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0927 19:37:23.880944  3577 solver.cpp:218] Iteration 13900 (7.02219 iter/s, 14.2406s/100 iters), loss = 0.334881
I0927 19:37:23.880973  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334881 (* 1 = 0.334881 loss)
I0927 19:37:23.880978  3577 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0927 19:37:37.409272  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:37:37.979482  3577 solver.cpp:330] Iteration 14000, Testing net (#0)
I0927 19:37:41.353947  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:37:41.494958  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7735
I0927 19:37:41.494994  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698279 (* 1 = 0.698279 loss)
I0927 19:37:41.636662  3577 solver.cpp:218] Iteration 14000 (5.63201 iter/s, 17.7556s/100 iters), loss = 0.217144
I0927 19:37:41.636693  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217144 (* 1 = 0.217144 loss)
I0927 19:37:41.636701  3577 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0927 19:37:55.869514  3577 solver.cpp:218] Iteration 14100 (7.02603 iter/s, 14.2328s/100 iters), loss = 0.249052
I0927 19:37:55.869545  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249052 (* 1 = 0.249052 loss)
I0927 19:37:55.869550  3577 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0927 19:38:10.105998  3577 solver.cpp:218] Iteration 14200 (7.02424 iter/s, 14.2364s/100 iters), loss = 0.251002
I0927 19:38:10.106130  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251002 (* 1 = 0.251002 loss)
I0927 19:38:10.106139  3577 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0927 19:38:24.337921  3577 solver.cpp:218] Iteration 14300 (7.02654 iter/s, 14.2318s/100 iters), loss = 0.239493
I0927 19:38:24.337963  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239493 (* 1 = 0.239493 loss)
I0927 19:38:24.337968  3577 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0927 19:38:38.570098  3577 solver.cpp:218] Iteration 14400 (7.02637 iter/s, 14.2321s/100 iters), loss = 0.195484
I0927 19:38:38.570140  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195484 (* 1 = 0.195484 loss)
I0927 19:38:38.570147  3577 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0927 19:38:52.094161  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:38:52.664836  3577 solver.cpp:330] Iteration 14500, Testing net (#0)
I0927 19:38:56.039536  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:38:56.180199  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6413
I0927 19:38:56.180238  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.3381 (* 1 = 1.3381 loss)
I0927 19:38:56.321807  3577 solver.cpp:218] Iteration 14500 (5.63329 iter/s, 17.7516s/100 iters), loss = 0.248686
I0927 19:38:56.321838  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248686 (* 1 = 0.248686 loss)
I0927 19:38:56.321844  3577 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0927 19:39:10.565644  3577 solver.cpp:218] Iteration 14600 (7.02061 iter/s, 14.2438s/100 iters), loss = 0.188822
I0927 19:39:10.565686  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188822 (* 1 = 0.188822 loss)
I0927 19:39:10.565691  3577 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0927 19:39:24.811856  3577 solver.cpp:218] Iteration 14700 (7.01945 iter/s, 14.2461s/100 iters), loss = 0.252974
I0927 19:39:24.811959  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252974 (* 1 = 0.252974 loss)
I0927 19:39:24.811965  3577 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0927 19:39:39.057868  3577 solver.cpp:218] Iteration 14800 (7.01957 iter/s, 14.2459s/100 iters), loss = 0.26786
I0927 19:39:39.057909  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26786 (* 1 = 0.26786 loss)
I0927 19:39:39.057914  3577 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0927 19:39:53.305943  3577 solver.cpp:218] Iteration 14900 (7.01853 iter/s, 14.248s/100 iters), loss = 0.220912
I0927 19:39:53.305985  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220912 (* 1 = 0.220912 loss)
I0927 19:39:53.305991  3577 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0927 19:40:06.842386  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:40:07.412959  3577 solver.cpp:330] Iteration 15000, Testing net (#0)
I0927 19:40:10.787591  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:40:10.928233  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7991
I0927 19:40:10.928270  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597933 (* 1 = 0.597933 loss)
I0927 19:40:11.069561  3577 solver.cpp:218] Iteration 15000 (5.62951 iter/s, 17.7635s/100 iters), loss = 0.242992
I0927 19:40:11.069591  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242992 (* 1 = 0.242992 loss)
I0927 19:40:11.069597  3577 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0927 19:40:25.303261  3577 solver.cpp:218] Iteration 15100 (7.02561 iter/s, 14.2336s/100 iters), loss = 0.249961
I0927 19:40:25.303303  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249961 (* 1 = 0.249961 loss)
I0927 19:40:25.303308  3577 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0927 19:40:39.539389  3577 solver.cpp:218] Iteration 15200 (7.02442 iter/s, 14.236s/100 iters), loss = 0.291391
I0927 19:40:39.539464  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291391 (* 1 = 0.291391 loss)
I0927 19:40:39.539471  3577 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0927 19:40:53.778255  3577 solver.cpp:218] Iteration 15300 (7.02308 iter/s, 14.2388s/100 iters), loss = 0.240264
I0927 19:40:53.778296  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240264 (* 1 = 0.240264 loss)
I0927 19:40:53.778302  3577 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0927 19:41:08.020027  3577 solver.cpp:218] Iteration 15400 (7.02164 iter/s, 14.2417s/100 iters), loss = 0.198542
I0927 19:41:08.020057  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198542 (* 1 = 0.198542 loss)
I0927 19:41:08.020062  3577 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0927 19:41:21.549994  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:41:22.119997  3577 solver.cpp:330] Iteration 15500, Testing net (#0)
I0927 19:41:25.493719  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:41:25.634660  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7989
I0927 19:41:25.634697  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.599091 (* 1 = 0.599091 loss)
I0927 19:41:25.776029  3577 solver.cpp:218] Iteration 15500 (5.63192 iter/s, 17.7559s/100 iters), loss = 0.182088
I0927 19:41:25.776060  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182088 (* 1 = 0.182088 loss)
I0927 19:41:25.776067  3577 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0927 19:41:40.011662  3577 solver.cpp:218] Iteration 15600 (7.02466 iter/s, 14.2356s/100 iters), loss = 0.199263
I0927 19:41:40.011703  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199263 (* 1 = 0.199263 loss)
I0927 19:41:40.011708  3577 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0927 19:41:54.251756  3577 solver.cpp:218] Iteration 15700 (7.02246 iter/s, 14.24s/100 iters), loss = 0.268974
I0927 19:41:54.251857  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268974 (* 1 = 0.268974 loss)
I0927 19:41:54.251864  3577 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0927 19:42:08.493682  3577 solver.cpp:218] Iteration 15800 (7.02159 iter/s, 14.2418s/100 iters), loss = 0.288485
I0927 19:42:08.493728  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288484 (* 1 = 0.288484 loss)
I0927 19:42:08.493736  3577 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0927 19:42:22.735935  3577 solver.cpp:218] Iteration 15900 (7.0214 iter/s, 14.2422s/100 iters), loss = 0.221341
I0927 19:42:22.735977  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221341 (* 1 = 0.221341 loss)
I0927 19:42:22.735982  3577 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0927 19:42:36.267392  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:42:36.838150  3577 solver.cpp:330] Iteration 16000, Testing net (#0)
I0927 19:42:40.213323  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:42:40.354187  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7651
I0927 19:42:40.354223  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.725347 (* 1 = 0.725347 loss)
I0927 19:42:40.494968  3577 solver.cpp:218] Iteration 16000 (5.63097 iter/s, 17.7589s/100 iters), loss = 0.219062
I0927 19:42:40.494999  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219061 (* 1 = 0.219061 loss)
I0927 19:42:40.495007  3577 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0927 19:42:54.749138  3577 solver.cpp:218] Iteration 16100 (7.01552 iter/s, 14.2541s/100 iters), loss = 0.153246
I0927 19:42:54.749181  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153246 (* 1 = 0.153246 loss)
I0927 19:42:54.749186  3577 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0927 19:43:08.996191  3577 solver.cpp:218] Iteration 16200 (7.01904 iter/s, 14.247s/100 iters), loss = 0.266136
I0927 19:43:08.996306  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266136 (* 1 = 0.266136 loss)
I0927 19:43:08.996322  3577 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0927 19:43:23.239141  3577 solver.cpp:218] Iteration 16300 (7.02109 iter/s, 14.2428s/100 iters), loss = 0.184492
I0927 19:43:23.239183  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184492 (* 1 = 0.184492 loss)
I0927 19:43:23.239188  3577 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0927 19:43:37.483906  3577 solver.cpp:218] Iteration 16400 (7.02016 iter/s, 14.2447s/100 iters), loss = 0.287987
I0927 19:43:37.483948  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287986 (* 1 = 0.287986 loss)
I0927 19:43:37.483953  3577 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0927 19:43:51.018375  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:43:51.589057  3577 solver.cpp:330] Iteration 16500, Testing net (#0)
I0927 19:43:54.962469  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:43:55.103530  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8047
I0927 19:43:55.103567  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.614987 (* 1 = 0.614987 loss)
I0927 19:43:55.244684  3577 solver.cpp:218] Iteration 16500 (5.63041 iter/s, 17.7607s/100 iters), loss = 0.137972
I0927 19:43:55.244714  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137972 (* 1 = 0.137972 loss)
I0927 19:43:55.244721  3577 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0927 19:44:09.479055  3577 solver.cpp:218] Iteration 16600 (7.02528 iter/s, 14.2343s/100 iters), loss = 0.199869
I0927 19:44:09.479087  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199869 (* 1 = 0.199869 loss)
I0927 19:44:09.479094  3577 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0927 19:44:23.719418  3577 solver.cpp:218] Iteration 16700 (7.02233 iter/s, 14.2403s/100 iters), loss = 0.269984
I0927 19:44:23.719538  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269984 (* 1 = 0.269984 loss)
I0927 19:44:23.719557  3577 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0927 19:44:37.962656  3577 solver.cpp:218] Iteration 16800 (7.02095 iter/s, 14.2431s/100 iters), loss = 0.266982
I0927 19:44:37.962698  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266982 (* 1 = 0.266982 loss)
I0927 19:44:37.962703  3577 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0927 19:44:52.198253  3577 solver.cpp:218] Iteration 16900 (7.02468 iter/s, 14.2355s/100 iters), loss = 0.206315
I0927 19:44:52.198295  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206315 (* 1 = 0.206315 loss)
I0927 19:44:52.198302  3577 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0927 19:45:05.739992  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:45:06.310102  3577 solver.cpp:330] Iteration 17000, Testing net (#0)
I0927 19:45:09.684967  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:45:09.826040  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7882
I0927 19:45:09.826076  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.64828 (* 1 = 0.64828 loss)
I0927 19:45:09.967649  3577 solver.cpp:218] Iteration 17000 (5.62768 iter/s, 17.7693s/100 iters), loss = 0.181175
I0927 19:45:09.967679  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181175 (* 1 = 0.181175 loss)
I0927 19:45:09.967686  3577 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0927 19:45:24.199782  3577 solver.cpp:218] Iteration 17100 (7.02639 iter/s, 14.2321s/100 iters), loss = 0.211084
I0927 19:45:24.199825  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211084 (* 1 = 0.211084 loss)
I0927 19:45:24.199831  3577 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0927 19:45:38.439354  3577 solver.cpp:218] Iteration 17200 (7.02272 iter/s, 14.2395s/100 iters), loss = 0.314419
I0927 19:45:38.439426  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314419 (* 1 = 0.314419 loss)
I0927 19:45:38.439433  3577 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0927 19:45:52.677330  3577 solver.cpp:218] Iteration 17300 (7.02352 iter/s, 14.2379s/100 iters), loss = 0.204836
I0927 19:45:52.677369  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204836 (* 1 = 0.204836 loss)
I0927 19:45:52.677376  3577 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0927 19:46:06.920775  3577 solver.cpp:218] Iteration 17400 (7.02081 iter/s, 14.2434s/100 iters), loss = 0.22177
I0927 19:46:06.920816  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22177 (* 1 = 0.22177 loss)
I0927 19:46:06.920821  3577 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0927 19:46:20.457798  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:46:21.027739  3577 solver.cpp:330] Iteration 17500, Testing net (#0)
I0927 19:46:24.402171  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:46:24.543198  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8195
I0927 19:46:24.543226  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.559819 (* 1 = 0.559819 loss)
I0927 19:46:24.684510  3577 solver.cpp:218] Iteration 17500 (5.62947 iter/s, 17.7637s/100 iters), loss = 0.206618
I0927 19:46:24.684540  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206618 (* 1 = 0.206618 loss)
I0927 19:46:24.684546  3577 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0927 19:46:38.920053  3577 solver.cpp:218] Iteration 17600 (7.0247 iter/s, 14.2355s/100 iters), loss = 0.205578
I0927 19:46:38.920094  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205578 (* 1 = 0.205578 loss)
I0927 19:46:38.920099  3577 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0927 19:46:53.161562  3577 solver.cpp:218] Iteration 17700 (7.02177 iter/s, 14.2414s/100 iters), loss = 0.274181
I0927 19:46:53.161672  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274181 (* 1 = 0.274181 loss)
I0927 19:46:53.161689  3577 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0927 19:47:07.404672  3577 solver.cpp:218] Iteration 17800 (7.02101 iter/s, 14.243s/100 iters), loss = 0.24308
I0927 19:47:07.404714  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24308 (* 1 = 0.24308 loss)
I0927 19:47:07.404721  3577 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0927 19:47:21.642705  3577 solver.cpp:218] Iteration 17900 (7.02348 iter/s, 14.2379s/100 iters), loss = 0.196314
I0927 19:47:21.642746  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196314 (* 1 = 0.196314 loss)
I0927 19:47:21.642752  3577 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0927 19:47:35.183910  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:47:35.754693  3577 solver.cpp:330] Iteration 18000, Testing net (#0)
I0927 19:47:39.128093  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:47:39.268751  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6913
I0927 19:47:39.268787  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11872 (* 1 = 1.11872 loss)
I0927 19:47:39.410110  3577 solver.cpp:218] Iteration 18000 (5.62831 iter/s, 17.7673s/100 iters), loss = 0.217499
I0927 19:47:39.410140  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217499 (* 1 = 0.217499 loss)
I0927 19:47:39.410146  3577 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0927 19:47:53.650871  3577 solver.cpp:218] Iteration 18100 (7.02213 iter/s, 14.2407s/100 iters), loss = 0.201466
I0927 19:47:53.650913  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201466 (* 1 = 0.201466 loss)
I0927 19:47:53.650918  3577 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0927 19:48:07.888020  3577 solver.cpp:218] Iteration 18200 (7.02392 iter/s, 14.2371s/100 iters), loss = 0.19135
I0927 19:48:07.888085  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19135 (* 1 = 0.19135 loss)
I0927 19:48:07.888101  3577 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0927 19:48:22.129127  3577 solver.cpp:218] Iteration 18300 (7.02198 iter/s, 14.241s/100 iters), loss = 0.196105
I0927 19:48:22.129169  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196105 (* 1 = 0.196105 loss)
I0927 19:48:22.129175  3577 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0927 19:48:36.371143  3577 solver.cpp:218] Iteration 18400 (7.02152 iter/s, 14.2419s/100 iters), loss = 0.176108
I0927 19:48:36.371175  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176108 (* 1 = 0.176108 loss)
I0927 19:48:36.371191  3577 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0927 19:48:49.900822  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:48:50.470242  3577 solver.cpp:330] Iteration 18500, Testing net (#0)
I0927 19:48:53.844599  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:48:53.985885  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6899
I0927 19:48:53.985921  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06319 (* 1 = 1.06319 loss)
I0927 19:48:54.126940  3577 solver.cpp:218] Iteration 18500 (5.63199 iter/s, 17.7557s/100 iters), loss = 0.193074
I0927 19:48:54.126969  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193074 (* 1 = 0.193074 loss)
I0927 19:48:54.126976  3577 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0927 19:49:08.375560  3577 solver.cpp:218] Iteration 18600 (7.01826 iter/s, 14.2486s/100 iters), loss = 0.349875
I0927 19:49:08.375591  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349876 (* 1 = 0.349876 loss)
I0927 19:49:08.375597  3577 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0927 19:49:22.619182  3577 solver.cpp:218] Iteration 18700 (7.02072 iter/s, 14.2436s/100 iters), loss = 0.253594
I0927 19:49:22.619303  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253594 (* 1 = 0.253594 loss)
I0927 19:49:22.619312  3577 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0927 19:49:36.861367  3577 solver.cpp:218] Iteration 18800 (7.02147 iter/s, 14.242s/100 iters), loss = 0.221575
I0927 19:49:36.861408  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221576 (* 1 = 0.221576 loss)
I0927 19:49:36.861414  3577 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0927 19:49:51.097470  3577 solver.cpp:218] Iteration 18900 (7.02443 iter/s, 14.236s/100 iters), loss = 0.230489
I0927 19:49:51.097512  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230489 (* 1 = 0.230489 loss)
I0927 19:49:51.097517  3577 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0927 19:50:04.631144  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:50:05.201956  3577 solver.cpp:330] Iteration 19000, Testing net (#0)
I0927 19:50:08.576422  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:50:08.717636  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7601
I0927 19:50:08.717674  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.82208 (* 1 = 0.82208 loss)
I0927 19:50:08.858933  3577 solver.cpp:218] Iteration 19000 (5.63019 iter/s, 17.7614s/100 iters), loss = 0.185967
I0927 19:50:08.858964  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185967 (* 1 = 0.185967 loss)
I0927 19:50:08.858970  3577 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0927 19:50:23.100149  3577 solver.cpp:218] Iteration 19100 (7.02191 iter/s, 14.2411s/100 iters), loss = 0.165744
I0927 19:50:23.100190  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165744 (* 1 = 0.165744 loss)
I0927 19:50:23.100196  3577 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0927 19:50:37.339035  3577 solver.cpp:218] Iteration 19200 (7.02306 iter/s, 14.2388s/100 iters), loss = 0.288202
I0927 19:50:37.339156  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288202 (* 1 = 0.288202 loss)
I0927 19:50:37.339164  3577 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0927 19:50:51.582453  3577 solver.cpp:218] Iteration 19300 (7.02086 iter/s, 14.2433s/100 iters), loss = 0.20571
I0927 19:50:51.582495  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20571 (* 1 = 0.20571 loss)
I0927 19:50:51.582501  3577 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0927 19:51:05.818477  3577 solver.cpp:218] Iteration 19400 (7.02447 iter/s, 14.2359s/100 iters), loss = 0.339704
I0927 19:51:05.818518  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339704 (* 1 = 0.339704 loss)
I0927 19:51:05.818527  3577 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0927 19:51:19.345136  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:51:19.914645  3577 solver.cpp:330] Iteration 19500, Testing net (#0)
I0927 19:51:23.288902  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:51:23.429657  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7579
I0927 19:51:23.429699  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.830769 (* 1 = 0.830769 loss)
I0927 19:51:23.570782  3577 solver.cpp:218] Iteration 19500 (5.6331 iter/s, 17.7522s/100 iters), loss = 0.157194
I0927 19:51:23.570812  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157194 (* 1 = 0.157194 loss)
I0927 19:51:23.570818  3577 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0927 19:51:37.810276  3577 solver.cpp:218] Iteration 19600 (7.02276 iter/s, 14.2394s/100 iters), loss = 0.232098
I0927 19:51:37.810318  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232098 (* 1 = 0.232098 loss)
I0927 19:51:37.810325  3577 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0927 19:51:52.056321  3577 solver.cpp:218] Iteration 19700 (7.01953 iter/s, 14.246s/100 iters), loss = 0.293594
I0927 19:51:52.056418  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293594 (* 1 = 0.293594 loss)
I0927 19:51:52.056434  3577 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0927 19:52:06.300998  3577 solver.cpp:218] Iteration 19800 (7.02023 iter/s, 14.2445s/100 iters), loss = 0.2464
I0927 19:52:06.301039  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2464 (* 1 = 0.2464 loss)
I0927 19:52:06.301045  3577 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0927 19:52:20.545130  3577 solver.cpp:218] Iteration 19900 (7.02047 iter/s, 14.2441s/100 iters), loss = 0.181505
I0927 19:52:20.545171  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181505 (* 1 = 0.181505 loss)
I0927 19:52:20.545177  3577 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0927 19:52:34.084023  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:52:34.655186  3577 solver.cpp:330] Iteration 20000, Testing net (#0)
I0927 19:52:38.028617  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:52:38.169306  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6537
I0927 19:52:38.169343  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.253 (* 1 = 1.253 loss)
I0927 19:52:38.311233  3577 solver.cpp:218] Iteration 20000 (5.62872 iter/s, 17.766s/100 iters), loss = 0.219436
I0927 19:52:38.311264  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219436 (* 1 = 0.219436 loss)
I0927 19:52:38.311270  3577 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0927 19:52:52.554930  3577 solver.cpp:218] Iteration 20100 (7.02069 iter/s, 14.2436s/100 iters), loss = 0.249401
I0927 19:52:52.554971  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249401 (* 1 = 0.249401 loss)
I0927 19:52:52.554977  3577 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0927 19:53:06.806092  3577 solver.cpp:218] Iteration 20200 (7.01701 iter/s, 14.2511s/100 iters), loss = 0.262976
I0927 19:53:06.806166  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262976 (* 1 = 0.262976 loss)
I0927 19:53:06.806174  3577 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0927 19:53:21.048300  3577 solver.cpp:218] Iteration 20300 (7.02144 iter/s, 14.2421s/100 iters), loss = 0.265157
I0927 19:53:21.048331  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265157 (* 1 = 0.265157 loss)
I0927 19:53:21.048336  3577 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0927 19:53:35.290547  3577 solver.cpp:218] Iteration 20400 (7.0214 iter/s, 14.2422s/100 iters), loss = 0.333185
I0927 19:53:35.290578  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333186 (* 1 = 0.333186 loss)
I0927 19:53:35.290585  3577 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0927 19:53:48.825911  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:53:49.395750  3577 solver.cpp:330] Iteration 20500, Testing net (#0)
I0927 19:53:52.769863  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:53:52.910694  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7891
I0927 19:53:52.910730  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.664983 (* 1 = 0.664983 loss)
I0927 19:53:53.052683  3577 solver.cpp:218] Iteration 20500 (5.62998 iter/s, 17.7621s/100 iters), loss = 0.207455
I0927 19:53:53.052713  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207455 (* 1 = 0.207455 loss)
I0927 19:53:53.052721  3577 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0927 19:54:07.289064  3577 solver.cpp:218] Iteration 20600 (7.02429 iter/s, 14.2363s/100 iters), loss = 0.173271
I0927 19:54:07.289106  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173271 (* 1 = 0.173271 loss)
I0927 19:54:07.289113  3577 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0927 19:54:21.523406  3577 solver.cpp:218] Iteration 20700 (7.0253 iter/s, 14.2343s/100 iters), loss = 0.257106
I0927 19:54:21.523557  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257106 (* 1 = 0.257106 loss)
I0927 19:54:21.523566  3577 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0927 19:54:35.762331  3577 solver.cpp:218] Iteration 20800 (7.02309 iter/s, 14.2387s/100 iters), loss = 0.203991
I0927 19:54:35.762372  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203991 (* 1 = 0.203991 loss)
I0927 19:54:35.762377  3577 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0927 19:54:50.002575  3577 solver.cpp:218] Iteration 20900 (7.02239 iter/s, 14.2402s/100 iters), loss = 0.173904
I0927 19:54:50.002617  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173904 (* 1 = 0.173904 loss)
I0927 19:54:50.002624  3577 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0927 19:55:03.532989  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:55:04.103713  3577 solver.cpp:330] Iteration 21000, Testing net (#0)
I0927 19:55:07.477555  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:55:07.618728  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7994
I0927 19:55:07.618765  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629954 (* 1 = 0.629954 loss)
I0927 19:55:07.760293  3577 solver.cpp:218] Iteration 21000 (5.63138 iter/s, 17.7576s/100 iters), loss = 0.146204
I0927 19:55:07.760324  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146204 (* 1 = 0.146204 loss)
I0927 19:55:07.760329  3577 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0927 19:55:21.997067  3577 solver.cpp:218] Iteration 21100 (7.0241 iter/s, 14.2367s/100 iters), loss = 0.228861
I0927 19:55:21.997110  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228861 (* 1 = 0.228861 loss)
I0927 19:55:21.997115  3577 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0927 19:55:36.230520  3577 solver.cpp:218] Iteration 21200 (7.02574 iter/s, 14.2334s/100 iters), loss = 0.204693
I0927 19:55:36.230656  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204693 (* 1 = 0.204693 loss)
I0927 19:55:36.230664  3577 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0927 19:55:50.464958  3577 solver.cpp:218] Iteration 21300 (7.02529 iter/s, 14.2343s/100 iters), loss = 0.19924
I0927 19:55:50.465000  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19924 (* 1 = 0.19924 loss)
I0927 19:55:50.465006  3577 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0927 19:56:04.701150  3577 solver.cpp:218] Iteration 21400 (7.02439 iter/s, 14.2361s/100 iters), loss = 0.209612
I0927 19:56:04.701192  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209613 (* 1 = 0.209613 loss)
I0927 19:56:04.701198  3577 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0927 19:56:18.223906  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:56:18.794107  3577 solver.cpp:330] Iteration 21500, Testing net (#0)
I0927 19:56:22.166497  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:56:22.307644  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7786
I0927 19:56:22.307679  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.679065 (* 1 = 0.679065 loss)
I0927 19:56:22.450433  3577 solver.cpp:218] Iteration 21500 (5.63406 iter/s, 17.7492s/100 iters), loss = 0.124653
I0927 19:56:22.450462  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124653 (* 1 = 0.124653 loss)
I0927 19:56:22.450469  3577 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0927 19:56:36.692330  3577 solver.cpp:218] Iteration 21600 (7.02157 iter/s, 14.2418s/100 iters), loss = 0.259931
I0927 19:56:36.692370  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259931 (* 1 = 0.259931 loss)
I0927 19:56:36.692376  3577 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0927 19:56:50.941015  3577 solver.cpp:218] Iteration 21700 (7.01823 iter/s, 14.2486s/100 iters), loss = 0.219342
I0927 19:56:50.941112  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219342 (* 1 = 0.219342 loss)
I0927 19:56:50.941118  3577 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0927 19:57:05.186610  3577 solver.cpp:218] Iteration 21800 (7.01978 iter/s, 14.2455s/100 iters), loss = 0.227326
I0927 19:57:05.186651  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227326 (* 1 = 0.227326 loss)
I0927 19:57:05.186656  3577 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0927 19:57:19.435194  3577 solver.cpp:218] Iteration 21900 (7.01828 iter/s, 14.2485s/100 iters), loss = 0.200316
I0927 19:57:19.435235  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200317 (* 1 = 0.200317 loss)
I0927 19:57:19.435240  3577 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0927 19:57:32.977650  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:57:33.549485  3577 solver.cpp:330] Iteration 22000, Testing net (#0)
I0927 19:57:36.923722  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:57:37.064359  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7922
I0927 19:57:37.064394  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.665041 (* 1 = 0.665041 loss)
I0927 19:57:37.206372  3577 solver.cpp:218] Iteration 22000 (5.62712 iter/s, 17.7711s/100 iters), loss = 0.212491
I0927 19:57:37.206403  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212491 (* 1 = 0.212491 loss)
I0927 19:57:37.206409  3577 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0927 19:57:51.441895  3577 solver.cpp:218] Iteration 22100 (7.02472 iter/s, 14.2355s/100 iters), loss = 0.123414
I0927 19:57:51.441937  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123414 (* 1 = 0.123414 loss)
I0927 19:57:51.441943  3577 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0927 19:58:05.687958  3577 solver.cpp:218] Iteration 22200 (7.01952 iter/s, 14.246s/100 iters), loss = 0.240268
I0927 19:58:05.688031  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240268 (* 1 = 0.240268 loss)
I0927 19:58:05.688038  3577 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0927 19:58:19.931134  3577 solver.cpp:218] Iteration 22300 (7.02096 iter/s, 14.2431s/100 iters), loss = 0.181274
I0927 19:58:19.931175  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181274 (* 1 = 0.181274 loss)
I0927 19:58:19.931181  3577 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0927 19:58:34.179729  3577 solver.cpp:218] Iteration 22400 (7.01828 iter/s, 14.2485s/100 iters), loss = 0.211272
I0927 19:58:34.179771  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211272 (* 1 = 0.211272 loss)
I0927 19:58:34.179776  3577 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0927 19:58:47.718518  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:58:48.288909  3577 solver.cpp:330] Iteration 22500, Testing net (#0)
I0927 19:58:51.659926  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 19:58:51.800595  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7753
I0927 19:58:51.800631  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.705937 (* 1 = 0.705937 loss)
I0927 19:58:51.941603  3577 solver.cpp:218] Iteration 22500 (5.63006 iter/s, 17.7618s/100 iters), loss = 0.154144
I0927 19:58:51.941632  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154144 (* 1 = 0.154144 loss)
I0927 19:58:51.941638  3577 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0927 19:59:06.176673  3577 solver.cpp:218] Iteration 22600 (7.02494 iter/s, 14.235s/100 iters), loss = 0.138757
I0927 19:59:06.176714  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138757 (* 1 = 0.138757 loss)
I0927 19:59:06.176720  3577 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0927 19:59:20.414845  3577 solver.cpp:218] Iteration 22700 (7.02341 iter/s, 14.2381s/100 iters), loss = 0.265613
I0927 19:59:20.414976  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265613 (* 1 = 0.265613 loss)
I0927 19:59:20.414994  3577 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0927 19:59:34.653512  3577 solver.cpp:218] Iteration 22800 (7.02321 iter/s, 14.2385s/100 iters), loss = 0.204781
I0927 19:59:34.653544  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204781 (* 1 = 0.204781 loss)
I0927 19:59:34.653550  3577 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0927 19:59:48.893486  3577 solver.cpp:218] Iteration 22900 (7.02252 iter/s, 14.2399s/100 iters), loss = 0.163023
I0927 19:59:48.893527  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163023 (* 1 = 0.163023 loss)
I0927 19:59:48.893533  3577 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0927 20:00:02.427959  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:00:02.998028  3577 solver.cpp:330] Iteration 23000, Testing net (#0)
I0927 20:00:06.371289  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:00:06.512480  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7707
I0927 20:00:06.512517  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.757266 (* 1 = 0.757266 loss)
I0927 20:00:06.654175  3577 solver.cpp:218] Iteration 23000 (5.63044 iter/s, 17.7606s/100 iters), loss = 0.134626
I0927 20:00:06.654206  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134626 (* 1 = 0.134626 loss)
I0927 20:00:06.654212  3577 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0927 20:00:20.887606  3577 solver.cpp:218] Iteration 23100 (7.02575 iter/s, 14.2334s/100 iters), loss = 0.194906
I0927 20:00:20.887637  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194906 (* 1 = 0.194906 loss)
I0927 20:00:20.887643  3577 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0927 20:00:35.125672  3577 solver.cpp:218] Iteration 23200 (7.02346 iter/s, 14.238s/100 iters), loss = 0.284073
I0927 20:00:35.125761  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284074 (* 1 = 0.284074 loss)
I0927 20:00:35.125778  3577 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0927 20:00:49.365191  3577 solver.cpp:218] Iteration 23300 (7.02277 iter/s, 14.2394s/100 iters), loss = 0.225147
I0927 20:00:49.365232  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225147 (* 1 = 0.225147 loss)
I0927 20:00:49.365238  3577 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0927 20:01:03.605837  3577 solver.cpp:218] Iteration 23400 (7.02219 iter/s, 14.2406s/100 iters), loss = 0.303418
I0927 20:01:03.605880  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303418 (* 1 = 0.303418 loss)
I0927 20:01:03.605885  3577 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0927 20:01:17.138419  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:01:17.708245  3577 solver.cpp:330] Iteration 23500, Testing net (#0)
I0927 20:01:21.080629  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:01:21.221596  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8326
I0927 20:01:21.221619  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.497999 (* 1 = 0.497999 loss)
I0927 20:01:21.363342  3577 solver.cpp:218] Iteration 23500 (5.63145 iter/s, 17.7574s/100 iters), loss = 0.229688
I0927 20:01:21.363371  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229688 (* 1 = 0.229688 loss)
I0927 20:01:21.363378  3577 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0927 20:01:35.588004  3577 solver.cpp:218] Iteration 23600 (7.03008 iter/s, 14.2246s/100 iters), loss = 0.229887
I0927 20:01:35.588047  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229887 (* 1 = 0.229887 loss)
I0927 20:01:35.588052  3577 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0927 20:01:49.818562  3577 solver.cpp:218] Iteration 23700 (7.02717 iter/s, 14.2305s/100 iters), loss = 0.194994
I0927 20:01:49.818658  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194994 (* 1 = 0.194994 loss)
I0927 20:01:49.818665  3577 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0927 20:02:04.046530  3577 solver.cpp:218] Iteration 23800 (7.02848 iter/s, 14.2278s/100 iters), loss = 0.183032
I0927 20:02:04.046571  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183032 (* 1 = 0.183032 loss)
I0927 20:02:04.046577  3577 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0927 20:02:18.275468  3577 solver.cpp:218] Iteration 23900 (7.02797 iter/s, 14.2289s/100 iters), loss = 0.201957
I0927 20:02:18.275511  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201957 (* 1 = 0.201957 loss)
I0927 20:02:18.275516  3577 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0927 20:02:31.804446  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:02:32.374342  3577 solver.cpp:330] Iteration 24000, Testing net (#0)
I0927 20:02:35.747311  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:02:35.888269  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6965
I0927 20:02:35.888306  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.17326 (* 1 = 1.17326 loss)
I0927 20:02:36.029656  3577 solver.cpp:218] Iteration 24000 (5.6325 iter/s, 17.7541s/100 iters), loss = 0.211398
I0927 20:02:36.029686  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211398 (* 1 = 0.211398 loss)
I0927 20:02:36.029692  3577 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0927 20:02:50.274680  3577 solver.cpp:218] Iteration 24100 (7.02003 iter/s, 14.245s/100 iters), loss = 0.172004
I0927 20:02:50.274724  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172004 (* 1 = 0.172004 loss)
I0927 20:02:50.274729  3577 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0927 20:03:04.519223  3577 solver.cpp:218] Iteration 24200 (7.02027 iter/s, 14.2445s/100 iters), loss = 0.175304
I0927 20:03:04.519297  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175304 (* 1 = 0.175304 loss)
I0927 20:03:04.519304  3577 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0927 20:03:18.767735  3577 solver.cpp:218] Iteration 24300 (7.01833 iter/s, 14.2484s/100 iters), loss = 0.178071
I0927 20:03:18.767777  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178071 (* 1 = 0.178071 loss)
I0927 20:03:18.767782  3577 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0927 20:03:33.015656  3577 solver.cpp:218] Iteration 24400 (7.01861 iter/s, 14.2478s/100 iters), loss = 0.20816
I0927 20:03:33.015688  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20816 (* 1 = 0.20816 loss)
I0927 20:03:33.015694  3577 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0927 20:03:46.554868  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:03:47.125080  3577 solver.cpp:330] Iteration 24500, Testing net (#0)
I0927 20:03:50.498289  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:03:50.638875  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6238
I0927 20:03:50.638911  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48205 (* 1 = 1.48205 loss)
I0927 20:03:50.780459  3577 solver.cpp:218] Iteration 24500 (5.62913 iter/s, 17.7647s/100 iters), loss = 0.13453
I0927 20:03:50.780489  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13453 (* 1 = 0.13453 loss)
I0927 20:03:50.780496  3577 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0927 20:04:05.012475  3577 solver.cpp:218] Iteration 24600 (7.02645 iter/s, 14.2319s/100 iters), loss = 0.232763
I0927 20:04:05.012517  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232763 (* 1 = 0.232763 loss)
I0927 20:04:05.012522  3577 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0927 20:04:19.252979  3577 solver.cpp:218] Iteration 24700 (7.02226 iter/s, 14.2404s/100 iters), loss = 0.327904
I0927 20:04:19.253111  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327904 (* 1 = 0.327904 loss)
I0927 20:04:19.253129  3577 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0927 20:04:33.496330  3577 solver.cpp:218] Iteration 24800 (7.0209 iter/s, 14.2432s/100 iters), loss = 0.281425
I0927 20:04:33.496371  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281425 (* 1 = 0.281425 loss)
I0927 20:04:33.496376  3577 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0927 20:04:47.742166  3577 solver.cpp:218] Iteration 24900 (7.01963 iter/s, 14.2458s/100 iters), loss = 0.109275
I0927 20:04:47.742208  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109275 (* 1 = 0.109275 loss)
I0927 20:04:47.742214  3577 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0927 20:05:01.284838  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:05:01.855654  3577 solver.cpp:330] Iteration 25000, Testing net (#0)
I0927 20:05:05.226413  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:05:05.366660  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7034
I0927 20:05:05.366698  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01169 (* 1 = 1.01169 loss)
I0927 20:05:05.507833  3577 solver.cpp:218] Iteration 25000 (5.62886 iter/s, 17.7656s/100 iters), loss = 0.174167
I0927 20:05:05.507863  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174167 (* 1 = 0.174167 loss)
I0927 20:05:05.507869  3577 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0927 20:05:19.747560  3577 solver.cpp:218] Iteration 25100 (7.02264 iter/s, 14.2397s/100 iters), loss = 0.23543
I0927 20:05:19.747607  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23543 (* 1 = 0.23543 loss)
I0927 20:05:19.747614  3577 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0927 20:05:33.989562  3577 solver.cpp:218] Iteration 25200 (7.02153 iter/s, 14.2419s/100 iters), loss = 0.177656
I0927 20:05:33.989667  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177656 (* 1 = 0.177656 loss)
I0927 20:05:33.989683  3577 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0927 20:05:48.223716  3577 solver.cpp:218] Iteration 25300 (7.02542 iter/s, 14.234s/100 iters), loss = 0.270883
I0927 20:05:48.223757  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270883 (* 1 = 0.270883 loss)
I0927 20:05:48.223762  3577 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0927 20:06:02.470224  3577 solver.cpp:218] Iteration 25400 (7.0193 iter/s, 14.2464s/100 iters), loss = 0.193943
I0927 20:06:02.470265  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193943 (* 1 = 0.193943 loss)
I0927 20:06:02.470271  3577 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0927 20:06:16.001641  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:06:16.569989  3577 solver.cpp:330] Iteration 25500, Testing net (#0)
I0927 20:06:19.941211  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:06:20.082159  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8001
I0927 20:06:20.082195  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.637878 (* 1 = 0.637878 loss)
I0927 20:06:20.223670  3577 solver.cpp:218] Iteration 25500 (5.63274 iter/s, 17.7534s/100 iters), loss = 0.119587
I0927 20:06:20.223701  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119587 (* 1 = 0.119587 loss)
I0927 20:06:20.223708  3577 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0927 20:06:34.464310  3577 solver.cpp:218] Iteration 25600 (7.02219 iter/s, 14.2406s/100 iters), loss = 0.142143
I0927 20:06:34.464352  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142143 (* 1 = 0.142143 loss)
I0927 20:06:34.464359  3577 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0927 20:06:48.706344  3577 solver.cpp:218] Iteration 25700 (7.02151 iter/s, 14.242s/100 iters), loss = 0.145255
I0927 20:06:48.706401  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145255 (* 1 = 0.145255 loss)
I0927 20:06:48.706418  3577 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0927 20:07:02.950222  3577 solver.cpp:218] Iteration 25800 (7.02061 iter/s, 14.2438s/100 iters), loss = 0.199997
I0927 20:07:02.950251  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199997 (* 1 = 0.199997 loss)
I0927 20:07:02.950258  3577 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0927 20:07:17.191565  3577 solver.cpp:218] Iteration 25900 (7.02184 iter/s, 14.2413s/100 iters), loss = 0.270756
I0927 20:07:17.191596  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270756 (* 1 = 0.270756 loss)
I0927 20:07:17.191601  3577 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0927 20:07:30.731484  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:07:31.301759  3577 solver.cpp:330] Iteration 26000, Testing net (#0)
I0927 20:07:34.673761  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:07:34.814646  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8412
I0927 20:07:34.814671  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.496714 (* 1 = 0.496714 loss)
I0927 20:07:34.956073  3577 solver.cpp:218] Iteration 26000 (5.62923 iter/s, 17.7644s/100 iters), loss = 0.148306
I0927 20:07:34.956104  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148306 (* 1 = 0.148306 loss)
I0927 20:07:34.956110  3577 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0927 20:07:49.196266  3577 solver.cpp:218] Iteration 26100 (7.02241 iter/s, 14.2401s/100 iters), loss = 0.264008
I0927 20:07:49.196307  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264008 (* 1 = 0.264008 loss)
I0927 20:07:49.196313  3577 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0927 20:08:03.444557  3577 solver.cpp:218] Iteration 26200 (7.01843 iter/s, 14.2482s/100 iters), loss = 0.224388
I0927 20:08:03.444666  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224388 (* 1 = 0.224388 loss)
I0927 20:08:03.444674  3577 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0927 20:08:17.683253  3577 solver.cpp:218] Iteration 26300 (7.02319 iter/s, 14.2386s/100 iters), loss = 0.220442
I0927 20:08:17.683281  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220442 (* 1 = 0.220442 loss)
I0927 20:08:17.683286  3577 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0927 20:08:31.931403  3577 solver.cpp:218] Iteration 26400 (7.01849 iter/s, 14.2481s/100 iters), loss = 0.268751
I0927 20:08:31.931434  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268751 (* 1 = 0.268751 loss)
I0927 20:08:31.931440  3577 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0927 20:08:45.470264  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:08:46.038969  3577 solver.cpp:330] Iteration 26500, Testing net (#0)
I0927 20:08:49.412288  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:08:49.553117  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8338
I0927 20:08:49.553153  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500711 (* 1 = 0.500711 loss)
I0927 20:08:49.694706  3577 solver.cpp:218] Iteration 26500 (5.62961 iter/s, 17.7632s/100 iters), loss = 0.187405
I0927 20:08:49.694736  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187405 (* 1 = 0.187405 loss)
I0927 20:08:49.694742  3577 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0927 20:09:03.924791  3577 solver.cpp:218] Iteration 26600 (7.0274 iter/s, 14.23s/100 iters), loss = 0.151656
I0927 20:09:03.924823  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151656 (* 1 = 0.151656 loss)
I0927 20:09:03.924829  3577 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0927 20:09:18.166546  3577 solver.cpp:218] Iteration 26700 (7.02164 iter/s, 14.2417s/100 iters), loss = 0.232424
I0927 20:09:18.166677  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232424 (* 1 = 0.232424 loss)
I0927 20:09:18.166685  3577 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0927 20:09:32.406627  3577 solver.cpp:218] Iteration 26800 (7.02251 iter/s, 14.2399s/100 iters), loss = 0.130183
I0927 20:09:32.406658  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130183 (* 1 = 0.130183 loss)
I0927 20:09:32.406664  3577 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0927 20:09:46.643422  3577 solver.cpp:218] Iteration 26900 (7.02409 iter/s, 14.2367s/100 iters), loss = 0.215482
I0927 20:09:46.643465  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215482 (* 1 = 0.215482 loss)
I0927 20:09:46.643470  3577 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0927 20:10:00.173034  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:10:00.743163  3577 solver.cpp:330] Iteration 27000, Testing net (#0)
I0927 20:10:04.113775  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:10:04.254786  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7539
I0927 20:10:04.254822  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.815492 (* 1 = 0.815492 loss)
I0927 20:10:04.395690  3577 solver.cpp:218] Iteration 27000 (5.63311 iter/s, 17.7522s/100 iters), loss = 0.206201
I0927 20:10:04.395720  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206201 (* 1 = 0.206201 loss)
I0927 20:10:04.395727  3577 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0927 20:10:18.628793  3577 solver.cpp:218] Iteration 27100 (7.02591 iter/s, 14.233s/100 iters), loss = 0.288252
I0927 20:10:18.628832  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288252 (* 1 = 0.288252 loss)
I0927 20:10:18.628839  3577 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0927 20:10:32.872395  3577 solver.cpp:218] Iteration 27200 (7.02074 iter/s, 14.2435s/100 iters), loss = 0.227571
I0927 20:10:32.872470  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227571 (* 1 = 0.227571 loss)
I0927 20:10:32.872488  3577 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0927 20:10:47.109441  3577 solver.cpp:218] Iteration 27300 (7.02398 iter/s, 14.2369s/100 iters), loss = 0.309231
I0927 20:10:47.109472  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309231 (* 1 = 0.309231 loss)
I0927 20:10:47.109478  3577 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0927 20:11:01.349947  3577 solver.cpp:218] Iteration 27400 (7.02226 iter/s, 14.2404s/100 iters), loss = 0.196007
I0927 20:11:01.349990  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196007 (* 1 = 0.196007 loss)
I0927 20:11:01.349995  3577 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0927 20:11:14.874842  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:11:15.444706  3577 solver.cpp:330] Iteration 27500, Testing net (#0)
I0927 20:11:18.816570  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:11:18.957419  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7751
I0927 20:11:18.957455  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.764847 (* 1 = 0.764847 loss)
I0927 20:11:19.099221  3577 solver.cpp:218] Iteration 27500 (5.63406 iter/s, 17.7492s/100 iters), loss = 0.171312
I0927 20:11:19.099251  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171312 (* 1 = 0.171312 loss)
I0927 20:11:19.099257  3577 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0927 20:11:33.338625  3577 solver.cpp:218] Iteration 27600 (7.0228 iter/s, 14.2393s/100 iters), loss = 0.342168
I0927 20:11:33.338656  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342168 (* 1 = 0.342168 loss)
I0927 20:11:33.338662  3577 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0927 20:11:47.582268  3577 solver.cpp:218] Iteration 27700 (7.02071 iter/s, 14.2436s/100 iters), loss = 0.219618
I0927 20:11:47.582403  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219618 (* 1 = 0.219618 loss)
I0927 20:11:47.582411  3577 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0927 20:12:01.829159  3577 solver.cpp:218] Iteration 27800 (7.01916 iter/s, 14.2467s/100 iters), loss = 0.215018
I0927 20:12:01.829190  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215018 (* 1 = 0.215018 loss)
I0927 20:12:01.829195  3577 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0927 20:12:16.073789  3577 solver.cpp:218] Iteration 27900 (7.02022 iter/s, 14.2446s/100 iters), loss = 0.249468
I0927 20:12:16.073830  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249468 (* 1 = 0.249468 loss)
I0927 20:12:16.073837  3577 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0927 20:12:29.608331  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:12:30.178903  3577 solver.cpp:330] Iteration 28000, Testing net (#0)
I0927 20:12:33.551369  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:12:33.692400  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7958
I0927 20:12:33.692437  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.646939 (* 1 = 0.646939 loss)
I0927 20:12:33.833937  3577 solver.cpp:218] Iteration 28000 (5.63061 iter/s, 17.7601s/100 iters), loss = 0.279566
I0927 20:12:33.833968  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279566 (* 1 = 0.279566 loss)
I0927 20:12:33.833974  3577 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0927 20:12:48.057750  3577 solver.cpp:218] Iteration 28100 (7.03052 iter/s, 14.2237s/100 iters), loss = 0.247594
I0927 20:12:48.057780  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247594 (* 1 = 0.247594 loss)
I0927 20:12:48.057786  3577 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0927 20:13:02.291301  3577 solver.cpp:218] Iteration 28200 (7.02569 iter/s, 14.2335s/100 iters), loss = 0.122904
I0927 20:13:02.291445  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122904 (* 1 = 0.122904 loss)
I0927 20:13:02.291452  3577 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0927 20:13:16.526795  3577 solver.cpp:218] Iteration 28300 (7.02478 iter/s, 14.2353s/100 iters), loss = 0.174196
I0927 20:13:16.526837  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174196 (* 1 = 0.174196 loss)
I0927 20:13:16.526842  3577 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0927 20:13:30.759501  3577 solver.cpp:218] Iteration 28400 (7.02611 iter/s, 14.2326s/100 iters), loss = 0.174445
I0927 20:13:30.759532  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174445 (* 1 = 0.174445 loss)
I0927 20:13:30.759537  3577 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0927 20:13:44.284206  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:13:44.853557  3577 solver.cpp:330] Iteration 28500, Testing net (#0)
I0927 20:13:48.225405  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:13:48.366688  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8048
I0927 20:13:48.366714  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619096 (* 1 = 0.619096 loss)
I0927 20:13:48.508241  3577 solver.cpp:218] Iteration 28500 (5.63423 iter/s, 17.7487s/100 iters), loss = 0.16538
I0927 20:13:48.508273  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165381 (* 1 = 0.165381 loss)
I0927 20:13:48.508280  3577 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0927 20:14:02.748584  3577 solver.cpp:218] Iteration 28600 (7.02234 iter/s, 14.2403s/100 iters), loss = 0.268123
I0927 20:14:02.748615  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268123 (* 1 = 0.268123 loss)
I0927 20:14:02.748620  3577 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0927 20:14:16.992931  3577 solver.cpp:218] Iteration 28700 (7.02036 iter/s, 14.2443s/100 iters), loss = 0.175944
I0927 20:14:16.993018  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175944 (* 1 = 0.175944 loss)
I0927 20:14:16.993026  3577 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0927 20:14:31.233381  3577 solver.cpp:218] Iteration 28800 (7.02231 iter/s, 14.2403s/100 iters), loss = 0.189565
I0927 20:14:31.233423  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189565 (* 1 = 0.189565 loss)
I0927 20:14:31.233428  3577 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0927 20:14:45.478009  3577 solver.cpp:218] Iteration 28900 (7.02023 iter/s, 14.2445s/100 iters), loss = 0.147189
I0927 20:14:45.478040  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147189 (* 1 = 0.147189 loss)
I0927 20:14:45.478055  3577 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0927 20:14:59.021903  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:14:59.591374  3577 solver.cpp:330] Iteration 29000, Testing net (#0)
I0927 20:15:02.964917  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:15:03.105634  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7248
I0927 20:15:03.105671  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.941208 (* 1 = 0.941208 loss)
I0927 20:15:03.247174  3577 solver.cpp:218] Iteration 29000 (5.62775 iter/s, 17.7691s/100 iters), loss = 0.139505
I0927 20:15:03.247205  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139505 (* 1 = 0.139505 loss)
I0927 20:15:03.247212  3577 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0927 20:15:17.474447  3577 solver.cpp:218] Iteration 29100 (7.02879 iter/s, 14.2272s/100 iters), loss = 0.16824
I0927 20:15:17.474489  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168241 (* 1 = 0.168241 loss)
I0927 20:15:17.474495  3577 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0927 20:15:31.709724  3577 solver.cpp:218] Iteration 29200 (7.02484 iter/s, 14.2352s/100 iters), loss = 0.281337
I0927 20:15:31.709846  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281337 (* 1 = 0.281337 loss)
I0927 20:15:31.709862  3577 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0927 20:15:45.945674  3577 solver.cpp:218] Iteration 29300 (7.02454 iter/s, 14.2358s/100 iters), loss = 0.251886
I0927 20:15:45.945716  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251886 (* 1 = 0.251886 loss)
I0927 20:15:45.945721  3577 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0927 20:16:00.183907  3577 solver.cpp:218] Iteration 29400 (7.02338 iter/s, 14.2382s/100 iters), loss = 0.216276
I0927 20:16:00.183939  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216276 (* 1 = 0.216276 loss)
I0927 20:16:00.183945  3577 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0927 20:16:13.716301  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:16:14.286629  3577 solver.cpp:330] Iteration 29500, Testing net (#0)
I0927 20:16:17.657762  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:16:17.798774  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8191
I0927 20:16:17.798810  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.559458 (* 1 = 0.559458 loss)
I0927 20:16:17.940630  3577 solver.cpp:218] Iteration 29500 (5.63169 iter/s, 17.7566s/100 iters), loss = 0.155353
I0927 20:16:17.940660  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155353 (* 1 = 0.155353 loss)
I0927 20:16:17.940667  3577 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0927 20:16:32.172560  3577 solver.cpp:218] Iteration 29600 (7.02649 iter/s, 14.2319s/100 iters), loss = 0.20375
I0927 20:16:32.172601  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20375 (* 1 = 0.20375 loss)
I0927 20:16:32.172607  3577 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0927 20:16:46.407583  3577 solver.cpp:218] Iteration 29700 (7.02496 iter/s, 14.2349s/100 iters), loss = 0.303041
I0927 20:16:46.407666  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303041 (* 1 = 0.303041 loss)
I0927 20:16:46.407682  3577 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0927 20:17:00.650667  3577 solver.cpp:218] Iteration 29800 (7.02101 iter/s, 14.243s/100 iters), loss = 0.208524
I0927 20:17:00.650710  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208524 (* 1 = 0.208524 loss)
I0927 20:17:00.650717  3577 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0927 20:17:14.890852  3577 solver.cpp:218] Iteration 29900 (7.02242 iter/s, 14.2401s/100 iters), loss = 0.281588
I0927 20:17:14.890893  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281588 (* 1 = 0.281588 loss)
I0927 20:17:14.890899  3577 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0927 20:17:28.420621  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:17:28.990895  3577 solver.cpp:330] Iteration 30000, Testing net (#0)
I0927 20:17:32.362104  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:17:32.502897  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7299
I0927 20:17:32.502929  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.922873 (* 1 = 0.922873 loss)
I0927 20:17:32.644599  3577 solver.cpp:218] Iteration 30000 (5.63264 iter/s, 17.7537s/100 iters), loss = 0.157533
I0927 20:17:32.644629  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157533 (* 1 = 0.157533 loss)
I0927 20:17:32.644636  3577 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0927 20:17:46.870103  3577 solver.cpp:218] Iteration 30100 (7.02966 iter/s, 14.2254s/100 iters), loss = 0.116853
I0927 20:17:46.870136  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116853 (* 1 = 0.116853 loss)
I0927 20:17:46.870151  3577 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0927 20:18:01.103874  3577 solver.cpp:218] Iteration 30200 (7.02558 iter/s, 14.2337s/100 iters), loss = 0.265338
I0927 20:18:01.104020  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265338 (* 1 = 0.265338 loss)
I0927 20:18:01.104028  3577 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0927 20:18:15.331921  3577 solver.cpp:218] Iteration 30300 (7.02846 iter/s, 14.2279s/100 iters), loss = 0.191638
I0927 20:18:15.331953  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191638 (* 1 = 0.191638 loss)
I0927 20:18:15.331959  3577 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0927 20:18:29.562494  3577 solver.cpp:218] Iteration 30400 (7.02716 iter/s, 14.2305s/100 iters), loss = 0.11969
I0927 20:18:29.562527  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11969 (* 1 = 0.11969 loss)
I0927 20:18:29.562533  3577 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0927 20:18:43.079505  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:18:43.649036  3577 solver.cpp:330] Iteration 30500, Testing net (#0)
I0927 20:18:47.019764  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:18:47.160504  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8039
I0927 20:18:47.160542  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.646552 (* 1 = 0.646552 loss)
I0927 20:18:47.301203  3577 solver.cpp:218] Iteration 30500 (5.63741 iter/s, 17.7386s/100 iters), loss = 0.102736
I0927 20:18:47.301234  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102736 (* 1 = 0.102736 loss)
I0927 20:18:47.301240  3577 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0927 20:19:01.544221  3577 solver.cpp:218] Iteration 30600 (7.02104 iter/s, 14.2429s/100 iters), loss = 0.181129
I0927 20:19:01.544252  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181129 (* 1 = 0.181129 loss)
I0927 20:19:01.544257  3577 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0927 20:19:15.783571  3577 solver.cpp:218] Iteration 30700 (7.02283 iter/s, 14.2393s/100 iters), loss = 0.199657
I0927 20:19:15.783706  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199657 (* 1 = 0.199657 loss)
I0927 20:19:15.783713  3577 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0927 20:19:30.030925  3577 solver.cpp:218] Iteration 30800 (7.01893 iter/s, 14.2472s/100 iters), loss = 0.157375
I0927 20:19:30.030966  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157375 (* 1 = 0.157375 loss)
I0927 20:19:30.030973  3577 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0927 20:19:44.268429  3577 solver.cpp:218] Iteration 30900 (7.02374 iter/s, 14.2374s/100 iters), loss = 0.144386
I0927 20:19:44.268461  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144386 (* 1 = 0.144386 loss)
I0927 20:19:44.268466  3577 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0927 20:19:57.798336  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:19:58.368924  3577 solver.cpp:330] Iteration 31000, Testing net (#0)
I0927 20:20:01.743194  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:20:01.884040  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7147
I0927 20:20:01.884078  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0075 (* 1 = 1.0075 loss)
I0927 20:20:02.025949  3577 solver.cpp:218] Iteration 31000 (5.63144 iter/s, 17.7574s/100 iters), loss = 0.155436
I0927 20:20:02.025979  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155436 (* 1 = 0.155436 loss)
I0927 20:20:02.025985  3577 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0927 20:20:16.253144  3577 solver.cpp:218] Iteration 31100 (7.02883 iter/s, 14.2271s/100 iters), loss = 0.10688
I0927 20:20:16.253186  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10688 (* 1 = 0.10688 loss)
I0927 20:20:16.253192  3577 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0927 20:20:30.484479  3577 solver.cpp:218] Iteration 31200 (7.02679 iter/s, 14.2313s/100 iters), loss = 0.212899
I0927 20:20:30.484623  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212899 (* 1 = 0.212899 loss)
I0927 20:20:30.484632  3577 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0927 20:20:44.719295  3577 solver.cpp:218] Iteration 31300 (7.02512 iter/s, 14.2346s/100 iters), loss = 0.119964
I0927 20:20:44.719336  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119964 (* 1 = 0.119964 loss)
I0927 20:20:44.719342  3577 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0927 20:20:58.952850  3577 solver.cpp:218] Iteration 31400 (7.02569 iter/s, 14.2335s/100 iters), loss = 0.166416
I0927 20:20:58.952893  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166416 (* 1 = 0.166416 loss)
I0927 20:20:58.952899  3577 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0927 20:21:12.484391  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:21:13.053330  3577 solver.cpp:330] Iteration 31500, Testing net (#0)
I0927 20:21:16.425462  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:21:16.566509  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7798
I0927 20:21:16.566546  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.720827 (* 1 = 0.720827 loss)
I0927 20:21:16.708201  3577 solver.cpp:218] Iteration 31500 (5.63213 iter/s, 17.7553s/100 iters), loss = 0.234309
I0927 20:21:16.708233  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234309 (* 1 = 0.234309 loss)
I0927 20:21:16.708240  3577 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0927 20:21:30.935078  3577 solver.cpp:218] Iteration 31600 (7.02899 iter/s, 14.2268s/100 iters), loss = 0.165104
I0927 20:21:30.935108  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165104 (* 1 = 0.165104 loss)
I0927 20:21:30.935114  3577 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0927 20:21:45.160919  3577 solver.cpp:218] Iteration 31700 (7.02949 iter/s, 14.2258s/100 iters), loss = 0.233166
I0927 20:21:45.161058  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233166 (* 1 = 0.233166 loss)
I0927 20:21:45.161067  3577 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0927 20:21:59.389937  3577 solver.cpp:218] Iteration 31800 (7.02798 iter/s, 14.2288s/100 iters), loss = 0.209054
I0927 20:21:59.389978  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209054 (* 1 = 0.209054 loss)
I0927 20:21:59.389984  3577 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0927 20:22:13.621359  3577 solver.cpp:218] Iteration 31900 (7.02674 iter/s, 14.2313s/100 iters), loss = 0.168987
I0927 20:22:13.621400  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168988 (* 1 = 0.168988 loss)
I0927 20:22:13.621405  3577 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0927 20:22:27.143489  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:22:27.712962  3577 solver.cpp:330] Iteration 32000, Testing net (#0)
I0927 20:22:31.086279  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:22:31.227475  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7442
I0927 20:22:31.227512  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.928281 (* 1 = 0.928281 loss)
I0927 20:22:31.369495  3577 solver.cpp:218] Iteration 32000 (5.63442 iter/s, 17.748s/100 iters), loss = 0.221063
I0927 20:22:31.369525  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221063 (* 1 = 0.221063 loss)
I0927 20:22:31.369531  3577 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0927 20:22:45.602459  3577 solver.cpp:218] Iteration 32100 (7.02598 iter/s, 14.2329s/100 iters), loss = 0.212419
I0927 20:22:45.602501  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21242 (* 1 = 0.21242 loss)
I0927 20:22:45.602506  3577 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0927 20:22:59.844053  3577 solver.cpp:218] Iteration 32200 (7.02173 iter/s, 14.2415s/100 iters), loss = 0.126529
I0927 20:22:59.844131  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126529 (* 1 = 0.126529 loss)
I0927 20:22:59.844138  3577 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0927 20:23:14.082720  3577 solver.cpp:218] Iteration 32300 (7.02319 iter/s, 14.2386s/100 iters), loss = 0.171181
I0927 20:23:14.082762  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171181 (* 1 = 0.171181 loss)
I0927 20:23:14.082767  3577 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0927 20:23:28.324878  3577 solver.cpp:218] Iteration 32400 (7.02145 iter/s, 14.2421s/100 iters), loss = 0.210166
I0927 20:23:28.324919  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210166 (* 1 = 0.210166 loss)
I0927 20:23:28.324925  3577 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0927 20:23:41.860707  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:23:42.431881  3577 solver.cpp:330] Iteration 32500, Testing net (#0)
I0927 20:23:45.803871  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:23:45.944777  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7908
I0927 20:23:45.944813  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.676076 (* 1 = 0.676076 loss)
I0927 20:23:46.086678  3577 solver.cpp:218] Iteration 32500 (5.63009 iter/s, 17.7617s/100 iters), loss = 0.0759209
I0927 20:23:46.086709  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.075921 (* 1 = 0.075921 loss)
I0927 20:23:46.086715  3577 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0927 20:24:00.316182  3577 solver.cpp:218] Iteration 32600 (7.02769 iter/s, 14.2294s/100 iters), loss = 0.204751
I0927 20:24:00.316213  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204751 (* 1 = 0.204751 loss)
I0927 20:24:00.316220  3577 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0927 20:24:14.547544  3577 solver.cpp:218] Iteration 32700 (7.02677 iter/s, 14.2313s/100 iters), loss = 0.358303
I0927 20:24:14.547672  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358303 (* 1 = 0.358303 loss)
I0927 20:24:14.547678  3577 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0927 20:24:28.785023  3577 solver.cpp:218] Iteration 32800 (7.02379 iter/s, 14.2373s/100 iters), loss = 0.164304
I0927 20:24:28.785066  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164304 (* 1 = 0.164304 loss)
I0927 20:24:28.785071  3577 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0927 20:24:43.021803  3577 solver.cpp:218] Iteration 32900 (7.0241 iter/s, 14.2367s/100 iters), loss = 0.129985
I0927 20:24:43.021844  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129985 (* 1 = 0.129985 loss)
I0927 20:24:43.021849  3577 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0927 20:24:56.549124  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:24:57.119509  3577 solver.cpp:330] Iteration 33000, Testing net (#0)
I0927 20:25:00.491940  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:25:00.632875  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7936
I0927 20:25:00.632912  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.677576 (* 1 = 0.677576 loss)
I0927 20:25:00.774469  3577 solver.cpp:218] Iteration 33000 (5.63298 iter/s, 17.7526s/100 iters), loss = 0.105223
I0927 20:25:00.774500  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105223 (* 1 = 0.105223 loss)
I0927 20:25:00.774507  3577 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0927 20:25:15.019848  3577 solver.cpp:218] Iteration 33100 (7.01986 iter/s, 14.2453s/100 iters), loss = 0.119258
I0927 20:25:15.019891  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119258 (* 1 = 0.119258 loss)
I0927 20:25:15.019896  3577 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0927 20:25:29.260490  3577 solver.cpp:218] Iteration 33200 (7.0222 iter/s, 14.2406s/100 iters), loss = 0.211624
I0927 20:25:29.260553  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211624 (* 1 = 0.211624 loss)
I0927 20:25:29.260561  3577 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0927 20:25:43.502562  3577 solver.cpp:218] Iteration 33300 (7.0215 iter/s, 14.242s/100 iters), loss = 0.173739
I0927 20:25:43.502604  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173739 (* 1 = 0.173739 loss)
I0927 20:25:43.502610  3577 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0927 20:25:57.745527  3577 solver.cpp:218] Iteration 33400 (7.02105 iter/s, 14.2429s/100 iters), loss = 0.114794
I0927 20:25:57.745568  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114794 (* 1 = 0.114794 loss)
I0927 20:25:57.745574  3577 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0927 20:26:11.277657  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:26:11.848428  3577 solver.cpp:330] Iteration 33500, Testing net (#0)
I0927 20:26:15.220916  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:26:15.362011  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7657
I0927 20:26:15.362048  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.707449 (* 1 = 0.707449 loss)
I0927 20:26:15.503499  3577 solver.cpp:218] Iteration 33500 (5.6313 iter/s, 17.7579s/100 iters), loss = 0.162347
I0927 20:26:15.503530  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162347 (* 1 = 0.162347 loss)
I0927 20:26:15.503536  3577 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0927 20:26:29.736135  3577 solver.cpp:218] Iteration 33600 (7.02616 iter/s, 14.2325s/100 iters), loss = 0.0874915
I0927 20:26:29.736177  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0874916 (* 1 = 0.0874916 loss)
I0927 20:26:29.736183  3577 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0927 20:26:44.053028  3577 solver.cpp:218] Iteration 33700 (6.9848 iter/s, 14.3168s/100 iters), loss = 0.293201
I0927 20:26:44.053124  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293201 (* 1 = 0.293201 loss)
I0927 20:26:44.053131  3577 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0927 20:26:58.275599  3577 solver.cpp:218] Iteration 33800 (7.03114 iter/s, 14.2224s/100 iters), loss = 0.145196
I0927 20:26:58.275640  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145196 (* 1 = 0.145196 loss)
I0927 20:26:58.275645  3577 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0927 20:27:12.503864  3577 solver.cpp:218] Iteration 33900 (7.0283 iter/s, 14.2282s/100 iters), loss = 0.161347
I0927 20:27:12.503906  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161347 (* 1 = 0.161347 loss)
I0927 20:27:12.503911  3577 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0927 20:27:26.024462  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:27:26.593192  3577 solver.cpp:330] Iteration 34000, Testing net (#0)
I0927 20:27:29.959770  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:27:30.099436  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8268
I0927 20:27:30.099473  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.571655 (* 1 = 0.571655 loss)
I0927 20:27:30.239573  3577 solver.cpp:218] Iteration 34000 (5.63837 iter/s, 17.7356s/100 iters), loss = 0.136957
I0927 20:27:30.239601  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136957 (* 1 = 0.136957 loss)
I0927 20:27:30.239609  3577 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0927 20:27:44.459758  3577 solver.cpp:218] Iteration 34100 (7.03229 iter/s, 14.2201s/100 iters), loss = 0.199061
I0927 20:27:44.459800  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199061 (* 1 = 0.199061 loss)
I0927 20:27:44.459805  3577 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0927 20:27:58.676686  3577 solver.cpp:218] Iteration 34200 (7.03391 iter/s, 14.2168s/100 iters), loss = 0.170205
I0927 20:27:58.676777  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170206 (* 1 = 0.170206 loss)
I0927 20:27:58.676784  3577 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0927 20:28:12.892387  3577 solver.cpp:218] Iteration 34300 (7.03454 iter/s, 14.2156s/100 iters), loss = 0.121535
I0927 20:28:12.892431  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121535 (* 1 = 0.121535 loss)
I0927 20:28:12.892436  3577 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0927 20:28:27.107427  3577 solver.cpp:218] Iteration 34400 (7.03484 iter/s, 14.215s/100 iters), loss = 0.13288
I0927 20:28:27.107468  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13288 (* 1 = 0.13288 loss)
I0927 20:28:27.107475  3577 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0927 20:28:40.620117  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:28:41.186508  3577 solver.cpp:330] Iteration 34500, Testing net (#0)
I0927 20:28:44.553445  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:28:44.693109  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8036
I0927 20:28:44.693145  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.613034 (* 1 = 0.613034 loss)
I0927 20:28:44.832777  3577 solver.cpp:218] Iteration 34500 (5.64167 iter/s, 17.7253s/100 iters), loss = 0.164701
I0927 20:28:44.832805  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164701 (* 1 = 0.164701 loss)
I0927 20:28:44.832813  3577 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0927 20:28:59.056496  3577 solver.cpp:218] Iteration 34600 (7.03054 iter/s, 14.2237s/100 iters), loss = 0.247338
I0927 20:28:59.056537  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247338 (* 1 = 0.247338 loss)
I0927 20:28:59.056543  3577 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0927 20:29:13.281330  3577 solver.cpp:218] Iteration 34700 (7.03 iter/s, 14.2248s/100 iters), loss = 0.129225
I0927 20:29:13.281437  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129225 (* 1 = 0.129225 loss)
I0927 20:29:13.281445  3577 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0927 20:29:27.506350  3577 solver.cpp:218] Iteration 34800 (7.02994 iter/s, 14.2249s/100 iters), loss = 0.208276
I0927 20:29:27.506392  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208276 (* 1 = 0.208276 loss)
I0927 20:29:27.506397  3577 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0927 20:29:41.730121  3577 solver.cpp:218] Iteration 34900 (7.03052 iter/s, 14.2237s/100 iters), loss = 0.225633
I0927 20:29:41.730163  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225633 (* 1 = 0.225633 loss)
I0927 20:29:41.730168  3577 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0927 20:29:55.246326  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:29:55.814446  3577 solver.cpp:330] Iteration 35000, Testing net (#0)
I0927 20:29:59.181417  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:29:59.320916  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.734
I0927 20:29:59.320952  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.836067 (* 1 = 0.836067 loss)
I0927 20:29:59.460367  3577 solver.cpp:218] Iteration 35000 (5.64011 iter/s, 17.7302s/100 iters), loss = 0.190598
I0927 20:29:59.460397  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190598 (* 1 = 0.190598 loss)
I0927 20:29:59.460403  3577 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0927 20:30:13.677269  3577 solver.cpp:218] Iteration 35100 (7.03392 iter/s, 14.2168s/100 iters), loss = 0.115412
I0927 20:30:13.677311  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115412 (* 1 = 0.115412 loss)
I0927 20:30:13.677317  3577 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0927 20:30:27.899152  3577 solver.cpp:218] Iteration 35200 (7.03146 iter/s, 14.2218s/100 iters), loss = 0.250582
I0927 20:30:27.899279  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250582 (* 1 = 0.250582 loss)
I0927 20:30:27.899286  3577 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0927 20:30:42.119657  3577 solver.cpp:218] Iteration 35300 (7.03218 iter/s, 14.2203s/100 iters), loss = 0.181067
I0927 20:30:42.119699  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181067 (* 1 = 0.181067 loss)
I0927 20:30:42.119704  3577 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0927 20:30:56.343819  3577 solver.cpp:218] Iteration 35400 (7.03033 iter/s, 14.2241s/100 iters), loss = 0.189761
I0927 20:30:56.343863  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189762 (* 1 = 0.189762 loss)
I0927 20:30:56.343868  3577 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0927 20:31:09.855020  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:31:10.423072  3577 solver.cpp:330] Iteration 35500, Testing net (#0)
I0927 20:31:13.790485  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:31:13.929980  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7931
I0927 20:31:13.930018  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.674884 (* 1 = 0.674884 loss)
I0927 20:31:14.069815  3577 solver.cpp:218] Iteration 35500 (5.64146 iter/s, 17.7259s/100 iters), loss = 0.221346
I0927 20:31:14.069844  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221346 (* 1 = 0.221346 loss)
I0927 20:31:14.069851  3577 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0927 20:31:28.305655  3577 solver.cpp:218] Iteration 35600 (7.02456 iter/s, 14.2358s/100 iters), loss = 0.130481
I0927 20:31:28.305696  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130481 (* 1 = 0.130481 loss)
I0927 20:31:28.305702  3577 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0927 20:31:42.539794  3577 solver.cpp:218] Iteration 35700 (7.0254 iter/s, 14.2341s/100 iters), loss = 0.202561
I0927 20:31:42.539896  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202561 (* 1 = 0.202561 loss)
I0927 20:31:42.539903  3577 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0927 20:31:56.775040  3577 solver.cpp:218] Iteration 35800 (7.02488 iter/s, 14.2351s/100 iters), loss = 0.175674
I0927 20:31:56.775082  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175674 (* 1 = 0.175674 loss)
I0927 20:31:56.775089  3577 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0927 20:32:11.008337  3577 solver.cpp:218] Iteration 35900 (7.02582 iter/s, 14.2332s/100 iters), loss = 0.218493
I0927 20:32:11.008379  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218493 (* 1 = 0.218493 loss)
I0927 20:32:11.008385  3577 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0927 20:32:24.538192  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:32:25.107008  3577 solver.cpp:330] Iteration 36000, Testing net (#0)
I0927 20:32:28.475062  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:32:28.614958  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7803
I0927 20:32:28.614994  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.676996 (* 1 = 0.676996 loss)
I0927 20:32:28.755115  3577 solver.cpp:218] Iteration 36000 (5.63485 iter/s, 17.7467s/100 iters), loss = 0.188698
I0927 20:32:28.755154  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188699 (* 1 = 0.188699 loss)
I0927 20:32:28.755162  3577 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0927 20:32:42.978739  3577 solver.cpp:218] Iteration 36100 (7.0306 iter/s, 14.2235s/100 iters), loss = 0.132737
I0927 20:32:42.978781  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132738 (* 1 = 0.132738 loss)
I0927 20:32:42.978786  3577 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0927 20:32:57.201800  3577 solver.cpp:218] Iteration 36200 (7.03088 iter/s, 14.223s/100 iters), loss = 0.180871
I0927 20:32:57.201900  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180871 (* 1 = 0.180871 loss)
I0927 20:32:57.201908  3577 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0927 20:33:11.427963  3577 solver.cpp:218] Iteration 36300 (7.02937 iter/s, 14.226s/100 iters), loss = 0.203988
I0927 20:33:11.428004  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203988 (* 1 = 0.203988 loss)
I0927 20:33:11.428009  3577 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0927 20:33:25.659034  3577 solver.cpp:218] Iteration 36400 (7.02692 iter/s, 14.231s/100 iters), loss = 0.159152
I0927 20:33:25.659075  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159152 (* 1 = 0.159152 loss)
I0927 20:33:25.659080  3577 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0927 20:33:39.175391  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:33:39.744920  3577 solver.cpp:330] Iteration 36500, Testing net (#0)
I0927 20:33:43.112540  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:33:43.251943  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8185
I0927 20:33:43.251979  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.561 (* 1 = 0.561 loss)
I0927 20:33:43.391680  3577 solver.cpp:218] Iteration 36500 (5.63934 iter/s, 17.7326s/100 iters), loss = 0.136427
I0927 20:33:43.391710  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136427 (* 1 = 0.136427 loss)
I0927 20:33:43.391716  3577 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0927 20:33:57.612459  3577 solver.cpp:218] Iteration 36600 (7.032 iter/s, 14.2207s/100 iters), loss = 0.209708
I0927 20:33:57.612502  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209708 (* 1 = 0.209708 loss)
I0927 20:33:57.612509  3577 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0927 20:34:11.839196  3577 solver.cpp:218] Iteration 36700 (7.02906 iter/s, 14.2267s/100 iters), loss = 0.215324
I0927 20:34:11.839303  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215324 (* 1 = 0.215324 loss)
I0927 20:34:11.839309  3577 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0927 20:34:26.066390  3577 solver.cpp:218] Iteration 36800 (7.02886 iter/s, 14.227s/100 iters), loss = 0.187413
I0927 20:34:26.066421  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187413 (* 1 = 0.187413 loss)
I0927 20:34:26.066426  3577 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0927 20:34:40.290423  3577 solver.cpp:218] Iteration 36900 (7.03039 iter/s, 14.224s/100 iters), loss = 0.0819429
I0927 20:34:40.290465  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.081943 (* 1 = 0.081943 loss)
I0927 20:34:40.290472  3577 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0927 20:34:53.808845  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:34:54.376757  3577 solver.cpp:330] Iteration 37000, Testing net (#0)
I0927 20:34:57.745398  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:34:57.884717  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7802
I0927 20:34:57.884754  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.730446 (* 1 = 0.730446 loss)
I0927 20:34:58.024618  3577 solver.cpp:218] Iteration 37000 (5.63885 iter/s, 17.7341s/100 iters), loss = 0.127117
I0927 20:34:58.024647  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127117 (* 1 = 0.127117 loss)
I0927 20:34:58.024653  3577 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0927 20:35:12.255694  3577 solver.cpp:218] Iteration 37100 (7.02691 iter/s, 14.231s/100 iters), loss = 0.176022
I0927 20:35:12.255736  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176022 (* 1 = 0.176022 loss)
I0927 20:35:12.255743  3577 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0927 20:35:26.485394  3577 solver.cpp:218] Iteration 37200 (7.0276 iter/s, 14.2296s/100 iters), loss = 0.220019
I0927 20:35:26.485493  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220019 (* 1 = 0.220019 loss)
I0927 20:35:26.485501  3577 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0927 20:35:40.719990  3577 solver.cpp:218] Iteration 37300 (7.02521 iter/s, 14.2345s/100 iters), loss = 0.11161
I0927 20:35:40.720022  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11161 (* 1 = 0.11161 loss)
I0927 20:35:40.720029  3577 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0927 20:35:54.946732  3577 solver.cpp:218] Iteration 37400 (7.02905 iter/s, 14.2267s/100 iters), loss = 0.155378
I0927 20:35:54.946763  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155378 (* 1 = 0.155378 loss)
I0927 20:35:54.946769  3577 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0927 20:36:08.468585  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:36:09.037799  3577 solver.cpp:330] Iteration 37500, Testing net (#0)
I0927 20:36:12.406332  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:36:12.545676  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8039
I0927 20:36:12.545714  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.675679 (* 1 = 0.675679 loss)
I0927 20:36:12.685392  3577 solver.cpp:218] Iteration 37500 (5.63743 iter/s, 17.7386s/100 iters), loss = 0.163097
I0927 20:36:12.685420  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163097 (* 1 = 0.163097 loss)
I0927 20:36:12.685426  3577 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0927 20:36:26.922261  3577 solver.cpp:218] Iteration 37600 (7.02405 iter/s, 14.2368s/100 iters), loss = 0.149281
I0927 20:36:26.922302  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149281 (* 1 = 0.149281 loss)
I0927 20:36:26.922308  3577 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0927 20:36:41.159379  3577 solver.cpp:218] Iteration 37700 (7.02393 iter/s, 14.237s/100 iters), loss = 0.25183
I0927 20:36:41.159476  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25183 (* 1 = 0.25183 loss)
I0927 20:36:41.159485  3577 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0927 20:36:55.395684  3577 solver.cpp:218] Iteration 37800 (7.02436 iter/s, 14.2362s/100 iters), loss = 0.231696
I0927 20:36:55.395712  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231696 (* 1 = 0.231696 loss)
I0927 20:36:55.395718  3577 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0927 20:37:09.630326  3577 solver.cpp:218] Iteration 37900 (7.02515 iter/s, 14.2346s/100 iters), loss = 0.11424
I0927 20:37:09.630367  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11424 (* 1 = 0.11424 loss)
I0927 20:37:09.630373  3577 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0927 20:37:23.158534  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:37:23.727638  3577 solver.cpp:330] Iteration 38000, Testing net (#0)
I0927 20:37:27.094504  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:37:27.234174  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7462
I0927 20:37:27.234200  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.884649 (* 1 = 0.884649 loss)
I0927 20:37:27.374254  3577 solver.cpp:218] Iteration 38000 (5.63576 iter/s, 17.7438s/100 iters), loss = 0.234382
I0927 20:37:27.374284  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234382 (* 1 = 0.234382 loss)
I0927 20:37:27.374290  3577 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0927 20:37:41.612962  3577 solver.cpp:218] Iteration 38100 (7.02314 iter/s, 14.2386s/100 iters), loss = 0.147706
I0927 20:37:41.612993  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147706 (* 1 = 0.147706 loss)
I0927 20:37:41.612999  3577 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0927 20:37:55.867959  3577 solver.cpp:218] Iteration 38200 (7.01512 iter/s, 14.2549s/100 iters), loss = 0.202423
I0927 20:37:55.868055  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202423 (* 1 = 0.202423 loss)
I0927 20:37:55.868073  3577 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0927 20:38:10.261862  3577 solver.cpp:218] Iteration 38300 (6.94745 iter/s, 14.3938s/100 iters), loss = 0.155634
I0927 20:38:10.261894  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155634 (* 1 = 0.155634 loss)
I0927 20:38:10.261900  3577 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0927 20:38:24.537058  3577 solver.cpp:218] Iteration 38400 (7.00519 iter/s, 14.2751s/100 iters), loss = 0.222839
I0927 20:38:24.537091  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222839 (* 1 = 0.222839 loss)
I0927 20:38:24.537098  3577 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0927 20:38:38.257217  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:38:38.828092  3577 solver.cpp:330] Iteration 38500, Testing net (#0)
I0927 20:38:42.206486  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:38:42.347472  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8152
I0927 20:38:42.347508  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.62882 (* 1 = 0.62882 loss)
I0927 20:38:42.488502  3577 solver.cpp:218] Iteration 38500 (5.57062 iter/s, 17.9513s/100 iters), loss = 0.202723
I0927 20:38:42.488530  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202723 (* 1 = 0.202723 loss)
I0927 20:38:42.488536  3577 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0927 20:38:56.763662  3577 solver.cpp:218] Iteration 38600 (7.00521 iter/s, 14.2751s/100 iters), loss = 0.204329
I0927 20:38:56.763695  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204329 (* 1 = 0.204329 loss)
I0927 20:38:56.763701  3577 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0927 20:39:11.098115  3577 solver.cpp:218] Iteration 38700 (6.97623 iter/s, 14.3344s/100 iters), loss = 0.182376
I0927 20:39:11.098212  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182377 (* 1 = 0.182377 loss)
I0927 20:39:11.098219  3577 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0927 20:39:25.752545  3577 solver.cpp:218] Iteration 38800 (6.82394 iter/s, 14.6543s/100 iters), loss = 0.12031
I0927 20:39:25.752593  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12031 (* 1 = 0.12031 loss)
I0927 20:39:25.752610  3577 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0927 20:39:40.163497  3577 solver.cpp:218] Iteration 38900 (6.93924 iter/s, 14.4108s/100 iters), loss = 0.114239
I0927 20:39:40.163528  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114239 (* 1 = 0.114239 loss)
I0927 20:39:40.163534  3577 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0927 20:39:53.750182  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:39:54.320683  3577 solver.cpp:330] Iteration 39000, Testing net (#0)
I0927 20:39:57.691217  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:39:57.832269  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7156
I0927 20:39:57.832306  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02893 (* 1 = 1.02893 loss)
I0927 20:39:57.972995  3577 solver.cpp:218] Iteration 39000 (5.61501 iter/s, 17.8094s/100 iters), loss = 0.129633
I0927 20:39:57.973026  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129633 (* 1 = 0.129633 loss)
I0927 20:39:57.973032  3577 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0927 20:40:12.204236  3577 solver.cpp:218] Iteration 39100 (7.02683 iter/s, 14.2312s/100 iters), loss = 0.147921
I0927 20:40:12.204264  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147921 (* 1 = 0.147921 loss)
I0927 20:40:12.204270  3577 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0927 20:40:26.437947  3577 solver.cpp:218] Iteration 39200 (7.02561 iter/s, 14.2336s/100 iters), loss = 0.21326
I0927 20:40:26.438066  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21326 (* 1 = 0.21326 loss)
I0927 20:40:26.438073  3577 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0927 20:40:40.677888  3577 solver.cpp:218] Iteration 39300 (7.02258 iter/s, 14.2398s/100 iters), loss = 0.140041
I0927 20:40:40.677930  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140041 (* 1 = 0.140041 loss)
I0927 20:40:40.677937  3577 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0927 20:40:54.911793  3577 solver.cpp:218] Iteration 39400 (7.02552 iter/s, 14.2338s/100 iters), loss = 0.161671
I0927 20:40:54.911835  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161671 (* 1 = 0.161671 loss)
I0927 20:40:54.911841  3577 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0927 20:41:08.442188  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:41:09.011265  3577 solver.cpp:330] Iteration 39500, Testing net (#0)
I0927 20:41:12.382994  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:41:12.523864  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7749
I0927 20:41:12.523890  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.699723 (* 1 = 0.699723 loss)
I0927 20:41:12.665343  3577 solver.cpp:218] Iteration 39500 (5.6327 iter/s, 17.7535s/100 iters), loss = 0.171638
I0927 20:41:12.665374  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171638 (* 1 = 0.171638 loss)
I0927 20:41:12.665380  3577 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0927 20:41:26.894649  3577 solver.cpp:218] Iteration 39600 (7.02778 iter/s, 14.2292s/100 iters), loss = 0.16282
I0927 20:41:26.894691  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16282 (* 1 = 0.16282 loss)
I0927 20:41:26.894696  3577 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0927 20:41:41.125722  3577 solver.cpp:218] Iteration 39700 (7.02692 iter/s, 14.231s/100 iters), loss = 0.238345
I0927 20:41:41.125805  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238345 (* 1 = 0.238345 loss)
I0927 20:41:41.125813  3577 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0927 20:41:55.357745  3577 solver.cpp:218] Iteration 39800 (7.02647 iter/s, 14.2319s/100 iters), loss = 0.175816
I0927 20:41:55.357776  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175816 (* 1 = 0.175816 loss)
I0927 20:41:55.357782  3577 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0927 20:42:09.592367  3577 solver.cpp:218] Iteration 39900 (7.02516 iter/s, 14.2346s/100 iters), loss = 0.212239
I0927 20:42:09.592408  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212239 (* 1 = 0.212239 loss)
I0927 20:42:09.592414  3577 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0927 20:42:23.117596  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:42:23.688344  3577 solver.cpp:330] Iteration 40000, Testing net (#0)
I0927 20:42:27.058573  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:42:27.199002  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7048
I0927 20:42:27.199038  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0941 (* 1 = 1.0941 loss)
I0927 20:42:27.340819  3577 solver.cpp:218] Iteration 40000 (5.63432 iter/s, 17.7484s/100 iters), loss = 0.121121
I0927 20:42:27.340849  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121121 (* 1 = 0.121121 loss)
I0927 20:42:27.340855  3577 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0927 20:42:27.340858  3577 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0927 20:42:41.570989  3577 solver.cpp:218] Iteration 40100 (7.02736 iter/s, 14.2301s/100 iters), loss = 0.159668
I0927 20:42:41.571032  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159668 (* 1 = 0.159668 loss)
I0927 20:42:41.571038  3577 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0927 20:42:55.803076  3577 solver.cpp:218] Iteration 40200 (7.02641 iter/s, 14.232s/100 iters), loss = 0.114226
I0927 20:42:55.803191  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114226 (* 1 = 0.114226 loss)
I0927 20:42:55.803198  3577 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0927 20:43:10.036331  3577 solver.cpp:218] Iteration 40300 (7.02587 iter/s, 14.2331s/100 iters), loss = 0.079828
I0927 20:43:10.036363  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0798282 (* 1 = 0.0798282 loss)
I0927 20:43:10.036370  3577 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0927 20:43:24.277086  3577 solver.cpp:218] Iteration 40400 (7.02213 iter/s, 14.2407s/100 iters), loss = 0.0554568
I0927 20:43:24.277117  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554569 (* 1 = 0.0554569 loss)
I0927 20:43:24.277122  3577 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0927 20:43:37.804769  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:43:38.375319  3577 solver.cpp:330] Iteration 40500, Testing net (#0)
I0927 20:43:41.747329  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:43:41.888365  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8984
I0927 20:43:41.888403  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302943 (* 1 = 0.302943 loss)
I0927 20:43:42.029687  3577 solver.cpp:218] Iteration 40500 (5.633 iter/s, 17.7525s/100 iters), loss = 0.0503239
I0927 20:43:42.029716  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050324 (* 1 = 0.050324 loss)
I0927 20:43:42.029722  3577 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0927 20:43:56.259214  3577 solver.cpp:218] Iteration 40600 (7.02768 iter/s, 14.2295s/100 iters), loss = 0.041147
I0927 20:43:56.259245  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411472 (* 1 = 0.0411472 loss)
I0927 20:43:56.259253  3577 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0927 20:44:10.496587  3577 solver.cpp:218] Iteration 40700 (7.0238 iter/s, 14.2373s/100 iters), loss = 0.0960048
I0927 20:44:10.496656  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.096005 (* 1 = 0.096005 loss)
I0927 20:44:10.496664  3577 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0927 20:44:24.733855  3577 solver.cpp:218] Iteration 40800 (7.02388 iter/s, 14.2372s/100 iters), loss = 0.0837157
I0927 20:44:24.733896  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0837158 (* 1 = 0.0837158 loss)
I0927 20:44:24.733901  3577 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0927 20:44:38.972180  3577 solver.cpp:218] Iteration 40900 (7.02334 iter/s, 14.2382s/100 iters), loss = 0.0165993
I0927 20:44:38.972223  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165994 (* 1 = 0.0165994 loss)
I0927 20:44:38.972229  3577 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0927 20:44:52.500749  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:44:53.071224  3577 solver.cpp:330] Iteration 41000, Testing net (#0)
I0927 20:44:56.443315  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:44:56.584130  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9092
I0927 20:44:56.584167  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.277494 (* 1 = 0.277494 loss)
I0927 20:44:56.725874  3577 solver.cpp:218] Iteration 41000 (5.63266 iter/s, 17.7536s/100 iters), loss = 0.0420802
I0927 20:44:56.725904  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420804 (* 1 = 0.0420804 loss)
I0927 20:44:56.725910  3577 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0927 20:45:10.960278  3577 solver.cpp:218] Iteration 41100 (7.02527 iter/s, 14.2343s/100 iters), loss = 0.0903568
I0927 20:45:10.960319  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.090357 (* 1 = 0.090357 loss)
I0927 20:45:10.960325  3577 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0927 20:45:25.197160  3577 solver.cpp:218] Iteration 41200 (7.02405 iter/s, 14.2368s/100 iters), loss = 0.0498289
I0927 20:45:25.197280  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0498291 (* 1 = 0.0498291 loss)
I0927 20:45:25.197288  3577 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0927 20:45:39.432411  3577 solver.cpp:218] Iteration 41300 (7.02489 iter/s, 14.2351s/100 iters), loss = 0.0452443
I0927 20:45:39.432452  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452445 (* 1 = 0.0452445 loss)
I0927 20:45:39.432458  3577 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0927 20:45:53.672307  3577 solver.cpp:218] Iteration 41400 (7.02256 iter/s, 14.2398s/100 iters), loss = 0.0713656
I0927 20:45:53.672348  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0713658 (* 1 = 0.0713658 loss)
I0927 20:45:53.672353  3577 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0927 20:46:07.204015  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:46:07.773108  3577 solver.cpp:330] Iteration 41500, Testing net (#0)
I0927 20:46:11.145040  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:46:11.286054  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I0927 20:46:11.286092  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.27209 (* 1 = 0.27209 loss)
I0927 20:46:11.428083  3577 solver.cpp:218] Iteration 41500 (5.632 iter/s, 17.7557s/100 iters), loss = 0.0385697
I0927 20:46:11.428114  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385699 (* 1 = 0.0385699 loss)
I0927 20:46:11.428122  3577 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0927 20:46:25.666750  3577 solver.cpp:218] Iteration 41600 (7.02316 iter/s, 14.2386s/100 iters), loss = 0.0379518
I0927 20:46:25.666792  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037952 (* 1 = 0.037952 loss)
I0927 20:46:25.666798  3577 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0927 20:46:39.908867  3577 solver.cpp:218] Iteration 41700 (7.02147 iter/s, 14.242s/100 iters), loss = 0.0945705
I0927 20:46:39.908943  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0945706 (* 1 = 0.0945706 loss)
I0927 20:46:39.908949  3577 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0927 20:46:54.150148  3577 solver.cpp:218] Iteration 41800 (7.0219 iter/s, 14.2412s/100 iters), loss = 0.025863
I0927 20:46:54.150190  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258631 (* 1 = 0.0258631 loss)
I0927 20:46:54.150197  3577 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0927 20:47:08.396428  3577 solver.cpp:218] Iteration 41900 (7.01942 iter/s, 14.2462s/100 iters), loss = 0.0221898
I0927 20:47:08.396458  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221899 (* 1 = 0.0221899 loss)
I0927 20:47:08.396464  3577 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0927 20:47:21.932468  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:47:22.502961  3577 solver.cpp:330] Iteration 42000, Testing net (#0)
I0927 20:47:25.876605  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:47:26.017810  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I0927 20:47:26.017848  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284266 (* 1 = 0.284266 loss)
I0927 20:47:26.159561  3577 solver.cpp:218] Iteration 42000 (5.62966 iter/s, 17.7631s/100 iters), loss = 0.0344823
I0927 20:47:26.159590  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344825 (* 1 = 0.0344825 loss)
I0927 20:47:26.159597  3577 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0927 20:47:40.398658  3577 solver.cpp:218] Iteration 42100 (7.02295 iter/s, 14.239s/100 iters), loss = 0.0670512
I0927 20:47:40.398699  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0670513 (* 1 = 0.0670513 loss)
I0927 20:47:40.398705  3577 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0927 20:47:54.636919  3577 solver.cpp:218] Iteration 42200 (7.02337 iter/s, 14.2382s/100 iters), loss = 0.0721384
I0927 20:47:54.637040  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721385 (* 1 = 0.0721385 loss)
I0927 20:47:54.637048  3577 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0927 20:48:08.874168  3577 solver.cpp:218] Iteration 42300 (7.0239 iter/s, 14.2371s/100 iters), loss = 0.0483407
I0927 20:48:08.874210  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483409 (* 1 = 0.0483409 loss)
I0927 20:48:08.874217  3577 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0927 20:48:23.112267  3577 solver.cpp:218] Iteration 42400 (7.02345 iter/s, 14.238s/100 iters), loss = 0.0197943
I0927 20:48:23.112296  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197944 (* 1 = 0.0197944 loss)
I0927 20:48:23.112303  3577 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0927 20:48:36.636926  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:48:37.206300  3577 solver.cpp:330] Iteration 42500, Testing net (#0)
I0927 20:48:40.579079  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:48:40.720096  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I0927 20:48:40.720132  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264395 (* 1 = 0.264395 loss)
I0927 20:48:40.861739  3577 solver.cpp:218] Iteration 42500 (5.63399 iter/s, 17.7494s/100 iters), loss = 0.0538076
I0927 20:48:40.861769  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538078 (* 1 = 0.0538078 loss)
I0927 20:48:40.861776  3577 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0927 20:48:55.102320  3577 solver.cpp:218] Iteration 42600 (7.02222 iter/s, 14.2405s/100 iters), loss = 0.070765
I0927 20:48:55.102362  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0707651 (* 1 = 0.0707651 loss)
I0927 20:48:55.102368  3577 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0927 20:49:09.336827  3577 solver.cpp:218] Iteration 42700 (7.02522 iter/s, 14.2344s/100 iters), loss = 0.0544033
I0927 20:49:09.336927  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0544034 (* 1 = 0.0544034 loss)
I0927 20:49:09.336935  3577 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0927 20:49:23.574033  3577 solver.cpp:218] Iteration 42800 (7.02391 iter/s, 14.2371s/100 iters), loss = 0.0183213
I0927 20:49:23.574074  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183214 (* 1 = 0.0183214 loss)
I0927 20:49:23.574080  3577 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0927 20:49:37.815083  3577 solver.cpp:218] Iteration 42900 (7.02199 iter/s, 14.241s/100 iters), loss = 0.0143328
I0927 20:49:37.815116  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143329 (* 1 = 0.0143329 loss)
I0927 20:49:37.815122  3577 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0927 20:49:51.350427  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:49:51.919720  3577 solver.cpp:330] Iteration 43000, Testing net (#0)
I0927 20:49:55.289839  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:49:55.430790  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I0927 20:49:55.430826  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270112 (* 1 = 0.270112 loss)
I0927 20:49:55.572780  3577 solver.cpp:218] Iteration 43000 (5.63139 iter/s, 17.7576s/100 iters), loss = 0.0223548
I0927 20:49:55.572810  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223549 (* 1 = 0.0223549 loss)
I0927 20:49:55.572816  3577 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0927 20:50:09.806053  3577 solver.cpp:218] Iteration 43100 (7.02582 iter/s, 14.2332s/100 iters), loss = 0.0241326
I0927 20:50:09.806083  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241328 (* 1 = 0.0241328 loss)
I0927 20:50:09.806089  3577 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0927 20:50:24.037923  3577 solver.cpp:218] Iteration 43200 (7.02652 iter/s, 14.2318s/100 iters), loss = 0.0481231
I0927 20:50:24.038040  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0481232 (* 1 = 0.0481232 loss)
I0927 20:50:24.038048  3577 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0927 20:50:38.270030  3577 solver.cpp:218] Iteration 43300 (7.02644 iter/s, 14.232s/100 iters), loss = 0.0327833
I0927 20:50:38.270061  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327835 (* 1 = 0.0327835 loss)
I0927 20:50:38.270067  3577 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0927 20:50:52.505146  3577 solver.cpp:218] Iteration 43400 (7.02491 iter/s, 14.235s/100 iters), loss = 0.0191753
I0927 20:50:52.505187  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191754 (* 1 = 0.0191754 loss)
I0927 20:50:52.505192  3577 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0927 20:51:06.030098  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:51:06.600194  3577 solver.cpp:330] Iteration 43500, Testing net (#0)
I0927 20:51:09.971866  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:51:10.112742  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I0927 20:51:10.112778  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291151 (* 1 = 0.291151 loss)
I0927 20:51:10.254726  3577 solver.cpp:218] Iteration 43500 (5.63396 iter/s, 17.7495s/100 iters), loss = 0.022126
I0927 20:51:10.254756  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221261 (* 1 = 0.0221261 loss)
I0927 20:51:10.254762  3577 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0927 20:51:24.491160  3577 solver.cpp:218] Iteration 43600 (7.02426 iter/s, 14.2364s/100 iters), loss = 0.043835
I0927 20:51:24.491201  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438351 (* 1 = 0.0438351 loss)
I0927 20:51:24.491207  3577 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0927 20:51:38.729068  3577 solver.cpp:218] Iteration 43700 (7.02354 iter/s, 14.2378s/100 iters), loss = 0.0511522
I0927 20:51:38.729185  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511523 (* 1 = 0.0511523 loss)
I0927 20:51:38.729202  3577 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0927 20:51:52.964129  3577 solver.cpp:218] Iteration 43800 (7.02499 iter/s, 14.2349s/100 iters), loss = 0.0117653
I0927 20:51:52.964171  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117655 (* 1 = 0.0117655 loss)
I0927 20:51:52.964177  3577 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0927 20:52:07.200958  3577 solver.cpp:218] Iteration 43900 (7.02408 iter/s, 14.2367s/100 iters), loss = 0.0289642
I0927 20:52:07.200999  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289644 (* 1 = 0.0289644 loss)
I0927 20:52:07.201005  3577 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0927 20:52:20.731864  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:52:21.302834  3577 solver.cpp:330] Iteration 44000, Testing net (#0)
I0927 20:52:24.675674  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:52:24.816548  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I0927 20:52:24.816584  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296308 (* 1 = 0.296308 loss)
I0927 20:52:24.958390  3577 solver.cpp:218] Iteration 44000 (5.63147 iter/s, 17.7573s/100 iters), loss = 0.0263068
I0927 20:52:24.958422  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263069 (* 1 = 0.0263069 loss)
I0927 20:52:24.958428  3577 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0927 20:52:39.194844  3577 solver.cpp:218] Iteration 44100 (7.02426 iter/s, 14.2364s/100 iters), loss = 0.0351027
I0927 20:52:39.194886  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351029 (* 1 = 0.0351029 loss)
I0927 20:52:39.194892  3577 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0927 20:52:53.429253  3577 solver.cpp:218] Iteration 44200 (7.02527 iter/s, 14.2343s/100 iters), loss = 0.0713581
I0927 20:52:53.429368  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0713583 (* 1 = 0.0713583 loss)
I0927 20:52:53.429388  3577 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0927 20:53:07.665572  3577 solver.cpp:218] Iteration 44300 (7.02436 iter/s, 14.2362s/100 iters), loss = 0.0136
I0927 20:53:07.665613  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136002 (* 1 = 0.0136002 loss)
I0927 20:53:07.665619  3577 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0927 20:53:21.898406  3577 solver.cpp:218] Iteration 44400 (7.02605 iter/s, 14.2327s/100 iters), loss = 0.0382412
I0927 20:53:21.898448  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382414 (* 1 = 0.0382414 loss)
I0927 20:53:21.898453  3577 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0927 20:53:35.430604  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:53:36.000027  3577 solver.cpp:330] Iteration 44500, Testing net (#0)
I0927 20:53:39.373642  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:53:39.514340  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I0927 20:53:39.514377  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279762 (* 1 = 0.279762 loss)
I0927 20:53:39.656234  3577 solver.cpp:218] Iteration 44500 (5.63135 iter/s, 17.7577s/100 iters), loss = 0.0404565
I0927 20:53:39.656263  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404567 (* 1 = 0.0404567 loss)
I0927 20:53:39.656270  3577 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0927 20:53:53.885010  3577 solver.cpp:218] Iteration 44600 (7.02805 iter/s, 14.2287s/100 iters), loss = 0.0222174
I0927 20:53:53.885051  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222176 (* 1 = 0.0222176 loss)
I0927 20:53:53.885056  3577 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0927 20:54:08.127013  3577 solver.cpp:218] Iteration 44700 (7.02152 iter/s, 14.2419s/100 iters), loss = 0.0548363
I0927 20:54:08.127115  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0548365 (* 1 = 0.0548365 loss)
I0927 20:54:08.127123  3577 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0927 20:54:22.368166  3577 solver.cpp:218] Iteration 44800 (7.02197 iter/s, 14.241s/100 iters), loss = 0.0287354
I0927 20:54:22.368207  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287357 (* 1 = 0.0287357 loss)
I0927 20:54:22.368213  3577 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0927 20:54:36.605053  3577 solver.cpp:218] Iteration 44900 (7.02405 iter/s, 14.2368s/100 iters), loss = 0.00605782
I0927 20:54:36.605093  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00605804 (* 1 = 0.00605804 loss)
I0927 20:54:36.605098  3577 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0927 20:54:50.134413  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:54:50.705178  3577 solver.cpp:330] Iteration 45000, Testing net (#0)
I0927 20:54:54.075587  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:54:54.217047  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I0927 20:54:54.217074  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273423 (* 1 = 0.273423 loss)
I0927 20:54:54.358685  3577 solver.cpp:218] Iteration 45000 (5.63268 iter/s, 17.7535s/100 iters), loss = 0.0274863
I0927 20:54:54.358713  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274865 (* 1 = 0.0274865 loss)
I0927 20:54:54.358721  3577 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0927 20:55:08.589684  3577 solver.cpp:218] Iteration 45100 (7.02695 iter/s, 14.2309s/100 iters), loss = 0.0186371
I0927 20:55:08.589715  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186373 (* 1 = 0.0186373 loss)
I0927 20:55:08.589720  3577 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0927 20:55:22.817261  3577 solver.cpp:218] Iteration 45200 (7.02864 iter/s, 14.2275s/100 iters), loss = 0.0402459
I0927 20:55:22.817337  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402462 (* 1 = 0.0402462 loss)
I0927 20:55:22.817344  3577 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0927 20:55:37.052238  3577 solver.cpp:218] Iteration 45300 (7.02501 iter/s, 14.2349s/100 iters), loss = 0.0115846
I0927 20:55:37.052269  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115848 (* 1 = 0.0115848 loss)
I0927 20:55:37.052275  3577 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0927 20:55:51.287096  3577 solver.cpp:218] Iteration 45400 (7.02504 iter/s, 14.2348s/100 iters), loss = 0.00306492
I0927 20:55:51.287137  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306512 (* 1 = 0.00306512 loss)
I0927 20:55:51.287143  3577 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0927 20:56:04.813038  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:56:05.381922  3577 solver.cpp:330] Iteration 45500, Testing net (#0)
I0927 20:56:08.753643  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:56:08.894402  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I0927 20:56:08.894438  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292019 (* 1 = 0.292019 loss)
I0927 20:56:09.036007  3577 solver.cpp:218] Iteration 45500 (5.63418 iter/s, 17.7488s/100 iters), loss = 0.0107744
I0927 20:56:09.036039  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107746 (* 1 = 0.0107746 loss)
I0927 20:56:09.036046  3577 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0927 20:56:23.272320  3577 solver.cpp:218] Iteration 45600 (7.02433 iter/s, 14.2362s/100 iters), loss = 0.0295282
I0927 20:56:23.272351  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295284 (* 1 = 0.0295284 loss)
I0927 20:56:23.272357  3577 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0927 20:56:37.516120  3577 solver.cpp:218] Iteration 45700 (7.02063 iter/s, 14.2437s/100 iters), loss = 0.0401767
I0927 20:56:37.516242  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401769 (* 1 = 0.0401769 loss)
I0927 20:56:37.516259  3577 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0927 20:56:51.758738  3577 solver.cpp:218] Iteration 45800 (7.02126 iter/s, 14.2425s/100 iters), loss = 0.00686402
I0927 20:56:51.758769  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00686422 (* 1 = 0.00686422 loss)
I0927 20:56:51.758775  3577 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0927 20:57:06.003650  3577 solver.cpp:218] Iteration 45900 (7.02008 iter/s, 14.2448s/100 iters), loss = 0.0172306
I0927 20:57:06.003682  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172308 (* 1 = 0.0172308 loss)
I0927 20:57:06.003689  3577 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0927 20:57:19.539952  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:57:20.109400  3577 solver.cpp:330] Iteration 46000, Testing net (#0)
I0927 20:57:23.482481  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:57:23.623247  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I0927 20:57:23.623284  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293507 (* 1 = 0.293507 loss)
I0927 20:57:23.765219  3577 solver.cpp:218] Iteration 46000 (5.63016 iter/s, 17.7615s/100 iters), loss = 0.0269966
I0927 20:57:23.765250  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269968 (* 1 = 0.0269968 loss)
I0927 20:57:23.765256  3577 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0927 20:57:38.007251  3577 solver.cpp:218] Iteration 46100 (7.02151 iter/s, 14.242s/100 iters), loss = 0.0511404
I0927 20:57:38.007295  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511406 (* 1 = 0.0511406 loss)
I0927 20:57:38.007302  3577 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0927 20:57:52.254636  3577 solver.cpp:218] Iteration 46200 (7.01887 iter/s, 14.2473s/100 iters), loss = 0.0996951
I0927 20:57:52.254768  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0996953 (* 1 = 0.0996953 loss)
I0927 20:57:52.254776  3577 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0927 20:58:06.502672  3577 solver.cpp:218] Iteration 46300 (7.01859 iter/s, 14.2479s/100 iters), loss = 0.00256913
I0927 20:58:06.502714  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256932 (* 1 = 0.00256932 loss)
I0927 20:58:06.502720  3577 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0927 20:58:20.749811  3577 solver.cpp:218] Iteration 46400 (7.01899 iter/s, 14.2471s/100 iters), loss = 0.018408
I0927 20:58:20.749842  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184082 (* 1 = 0.0184082 loss)
I0927 20:58:20.749850  3577 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0927 20:58:34.287418  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:58:34.858620  3577 solver.cpp:330] Iteration 46500, Testing net (#0)
I0927 20:58:38.230888  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:58:38.371862  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I0927 20:58:38.371898  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285197 (* 1 = 0.285197 loss)
I0927 20:58:38.513473  3577 solver.cpp:218] Iteration 46500 (5.6295 iter/s, 17.7636s/100 iters), loss = 0.0125861
I0927 20:58:38.513504  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125863 (* 1 = 0.0125863 loss)
I0927 20:58:38.513509  3577 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0927 20:58:52.751200  3577 solver.cpp:218] Iteration 46600 (7.02363 iter/s, 14.2377s/100 iters), loss = 0.0435844
I0927 20:58:52.751241  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0435846 (* 1 = 0.0435846 loss)
I0927 20:58:52.751247  3577 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0927 20:59:06.993665  3577 solver.cpp:218] Iteration 46700 (7.0213 iter/s, 14.2424s/100 iters), loss = 0.0482101
I0927 20:59:06.993755  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482103 (* 1 = 0.0482103 loss)
I0927 20:59:06.993772  3577 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0927 20:59:21.227870  3577 solver.cpp:218] Iteration 46800 (7.02539 iter/s, 14.2341s/100 iters), loss = 0.0103048
I0927 20:59:21.227913  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010305 (* 1 = 0.010305 loss)
I0927 20:59:21.227919  3577 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0927 20:59:35.465191  3577 solver.cpp:218] Iteration 46900 (7.02383 iter/s, 14.2372s/100 iters), loss = 0.0118013
I0927 20:59:35.465232  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118015 (* 1 = 0.0118015 loss)
I0927 20:59:35.465239  3577 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0927 20:59:48.997472  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:59:49.567816  3577 solver.cpp:330] Iteration 47000, Testing net (#0)
I0927 20:59:52.940712  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 20:59:53.082046  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I0927 20:59:53.082082  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291465 (* 1 = 0.291465 loss)
I0927 20:59:53.223719  3577 solver.cpp:218] Iteration 47000 (5.63113 iter/s, 17.7584s/100 iters), loss = 0.00554379
I0927 20:59:53.223748  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005544 (* 1 = 0.005544 loss)
I0927 20:59:53.223755  3577 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0927 21:00:07.458598  3577 solver.cpp:218] Iteration 47100 (7.02505 iter/s, 14.2348s/100 iters), loss = 0.0321787
I0927 21:00:07.458629  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321789 (* 1 = 0.0321789 loss)
I0927 21:00:07.458636  3577 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0927 21:00:21.689864  3577 solver.cpp:218] Iteration 47200 (7.02682 iter/s, 14.2312s/100 iters), loss = 0.0456246
I0927 21:00:21.690004  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456249 (* 1 = 0.0456249 loss)
I0927 21:00:21.690013  3577 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0927 21:00:35.922374  3577 solver.cpp:218] Iteration 47300 (7.02625 iter/s, 14.2323s/100 iters), loss = 0.0512248
I0927 21:00:35.922405  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.051225 (* 1 = 0.051225 loss)
I0927 21:00:35.922410  3577 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0927 21:00:50.154491  3577 solver.cpp:218] Iteration 47400 (7.02639 iter/s, 14.232s/100 iters), loss = 0.0108791
I0927 21:00:50.154525  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108793 (* 1 = 0.0108793 loss)
I0927 21:00:50.154532  3577 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0927 21:01:03.682492  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:01:04.252542  3577 solver.cpp:330] Iteration 47500, Testing net (#0)
I0927 21:01:07.623353  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:01:07.764509  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I0927 21:01:07.764546  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296807 (* 1 = 0.296807 loss)
I0927 21:01:07.906414  3577 solver.cpp:218] Iteration 47500 (5.63322 iter/s, 17.7518s/100 iters), loss = 0.0104655
I0927 21:01:07.906443  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104657 (* 1 = 0.0104657 loss)
I0927 21:01:07.906450  3577 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0927 21:01:22.138713  3577 solver.cpp:218] Iteration 47600 (7.02631 iter/s, 14.2322s/100 iters), loss = 0.0177217
I0927 21:01:22.138754  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177219 (* 1 = 0.0177219 loss)
I0927 21:01:22.138761  3577 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0927 21:01:36.376010  3577 solver.cpp:218] Iteration 47700 (7.02384 iter/s, 14.2372s/100 iters), loss = 0.0163543
I0927 21:01:36.376123  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163545 (* 1 = 0.0163545 loss)
I0927 21:01:36.376130  3577 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0927 21:01:50.612238  3577 solver.cpp:218] Iteration 47800 (7.02441 iter/s, 14.2361s/100 iters), loss = 0.0281508
I0927 21:01:50.612280  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028151 (* 1 = 0.028151 loss)
I0927 21:01:50.612287  3577 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0927 21:02:04.852869  3577 solver.cpp:218] Iteration 47900 (7.0222 iter/s, 14.2405s/100 iters), loss = 0.00876767
I0927 21:02:04.852900  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00876788 (* 1 = 0.00876788 loss)
I0927 21:02:04.852908  3577 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0927 21:02:18.385992  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:02:18.956838  3577 solver.cpp:330] Iteration 48000, Testing net (#0)
I0927 21:02:22.329763  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:02:22.470893  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I0927 21:02:22.470930  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295635 (* 1 = 0.295635 loss)
I0927 21:02:22.613018  3577 solver.cpp:218] Iteration 48000 (5.63061 iter/s, 17.7601s/100 iters), loss = 0.0164484
I0927 21:02:22.613049  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164486 (* 1 = 0.0164486 loss)
I0927 21:02:22.613055  3577 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0927 21:02:36.847573  3577 solver.cpp:218] Iteration 48100 (7.02519 iter/s, 14.2345s/100 iters), loss = 0.0173998
I0927 21:02:36.847604  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174 (* 1 = 0.0174 loss)
I0927 21:02:36.847609  3577 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0927 21:02:51.083315  3577 solver.cpp:218] Iteration 48200 (7.02461 iter/s, 14.2357s/100 iters), loss = 0.00958247
I0927 21:02:51.083421  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00958269 (* 1 = 0.00958269 loss)
I0927 21:02:51.083428  3577 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0927 21:03:05.322484  3577 solver.cpp:218] Iteration 48300 (7.02295 iter/s, 14.239s/100 iters), loss = 0.00269512
I0927 21:03:05.322527  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00269535 (* 1 = 0.00269535 loss)
I0927 21:03:05.322533  3577 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0927 21:03:19.557714  3577 solver.cpp:218] Iteration 48400 (7.02487 iter/s, 14.2351s/100 iters), loss = 0.05722
I0927 21:03:19.557756  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0572203 (* 1 = 0.0572203 loss)
I0927 21:03:19.557762  3577 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0927 21:03:33.083856  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:03:33.653749  3577 solver.cpp:330] Iteration 48500, Testing net (#0)
I0927 21:03:37.026191  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:03:37.166905  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I0927 21:03:37.166941  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302201 (* 1 = 0.302201 loss)
I0927 21:03:37.308558  3577 solver.cpp:218] Iteration 48500 (5.63356 iter/s, 17.7508s/100 iters), loss = 0.0105496
I0927 21:03:37.308588  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105499 (* 1 = 0.0105499 loss)
I0927 21:03:37.308595  3577 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0927 21:03:51.542374  3577 solver.cpp:218] Iteration 48600 (7.02556 iter/s, 14.2337s/100 iters), loss = 0.0200578
I0927 21:03:51.542417  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020058 (* 1 = 0.020058 loss)
I0927 21:03:51.542423  3577 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0927 21:04:05.775303  3577 solver.cpp:218] Iteration 48700 (7.026 iter/s, 14.2328s/100 iters), loss = 0.0296622
I0927 21:04:05.775393  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296624 (* 1 = 0.0296624 loss)
I0927 21:04:05.775409  3577 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0927 21:04:20.010833  3577 solver.cpp:218] Iteration 48800 (7.02474 iter/s, 14.2354s/100 iters), loss = 0.0185631
I0927 21:04:20.010871  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185633 (* 1 = 0.0185633 loss)
I0927 21:04:20.010879  3577 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0927 21:04:34.256204  3577 solver.cpp:218] Iteration 48900 (7.01986 iter/s, 14.2453s/100 iters), loss = 0.00633482
I0927 21:04:34.256245  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00633505 (* 1 = 0.00633505 loss)
I0927 21:04:34.256252  3577 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0927 21:04:47.788290  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:04:48.358755  3577 solver.cpp:330] Iteration 49000, Testing net (#0)
I0927 21:04:51.728992  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:04:51.870102  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I0927 21:04:51.870139  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306372 (* 1 = 0.306372 loss)
I0927 21:04:52.011556  3577 solver.cpp:218] Iteration 49000 (5.63213 iter/s, 17.7553s/100 iters), loss = 0.00564631
I0927 21:04:52.011585  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00564655 (* 1 = 0.00564655 loss)
I0927 21:04:52.011592  3577 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0927 21:05:06.248237  3577 solver.cpp:218] Iteration 49100 (7.02414 iter/s, 14.2366s/100 iters), loss = 0.00901341
I0927 21:05:06.248268  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00901365 (* 1 = 0.00901365 loss)
I0927 21:05:06.248275  3577 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0927 21:05:20.487460  3577 solver.cpp:218] Iteration 49200 (7.02289 iter/s, 14.2392s/100 iters), loss = 0.0348516
I0927 21:05:20.487601  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348518 (* 1 = 0.0348518 loss)
I0927 21:05:20.487609  3577 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0927 21:05:34.732637  3577 solver.cpp:218] Iteration 49300 (7.02001 iter/s, 14.245s/100 iters), loss = 0.0267926
I0927 21:05:34.732669  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267928 (* 1 = 0.0267928 loss)
I0927 21:05:34.732676  3577 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0927 21:05:48.971006  3577 solver.cpp:218] Iteration 49400 (7.02331 iter/s, 14.2383s/100 iters), loss = 0.0045355
I0927 21:05:48.971036  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453572 (* 1 = 0.00453572 loss)
I0927 21:05:48.971042  3577 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0927 21:06:02.500799  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:06:03.070927  3577 solver.cpp:330] Iteration 49500, Testing net (#0)
I0927 21:06:06.441764  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:06:06.582662  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I0927 21:06:06.582703  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309784 (* 1 = 0.309784 loss)
I0927 21:06:06.723819  3577 solver.cpp:218] Iteration 49500 (5.63294 iter/s, 17.7527s/100 iters), loss = 0.024113
I0927 21:06:06.723850  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241132 (* 1 = 0.0241132 loss)
I0927 21:06:06.723856  3577 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0927 21:06:20.956065  3577 solver.cpp:218] Iteration 49600 (7.02636 iter/s, 14.2321s/100 iters), loss = 0.00806133
I0927 21:06:20.956097  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00806155 (* 1 = 0.00806155 loss)
I0927 21:06:20.956104  3577 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0927 21:06:35.190973  3577 solver.cpp:218] Iteration 49700 (7.02502 iter/s, 14.2348s/100 iters), loss = 0.0255595
I0927 21:06:35.191094  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255598 (* 1 = 0.0255598 loss)
I0927 21:06:35.191112  3577 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0927 21:06:49.425945  3577 solver.cpp:218] Iteration 49800 (7.02503 iter/s, 14.2348s/100 iters), loss = 0.00695549
I0927 21:06:49.425976  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695572 (* 1 = 0.00695572 loss)
I0927 21:06:49.425981  3577 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0927 21:07:03.666760  3577 solver.cpp:218] Iteration 49900 (7.0221 iter/s, 14.2407s/100 iters), loss = 0.00218335
I0927 21:07:03.666802  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218358 (* 1 = 0.00218358 loss)
I0927 21:07:03.666807  3577 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0927 21:07:17.195935  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:07:17.765738  3577 solver.cpp:330] Iteration 50000, Testing net (#0)
I0927 21:07:21.136665  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:07:21.277952  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I0927 21:07:21.277988  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316119 (* 1 = 0.316119 loss)
I0927 21:07:21.418567  3577 solver.cpp:218] Iteration 50000 (5.63326 iter/s, 17.7517s/100 iters), loss = 0.00370822
I0927 21:07:21.418597  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370846 (* 1 = 0.00370846 loss)
I0927 21:07:21.418603  3577 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0927 21:07:35.657922  3577 solver.cpp:218] Iteration 50100 (7.02283 iter/s, 14.2393s/100 iters), loss = 0.01018
I0927 21:07:35.657953  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101803 (* 1 = 0.0101803 loss)
I0927 21:07:35.657959  3577 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0927 21:07:49.910135  3577 solver.cpp:218] Iteration 50200 (7.01649 iter/s, 14.2521s/100 iters), loss = 0.0205181
I0927 21:07:49.910210  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205184 (* 1 = 0.0205184 loss)
I0927 21:07:49.910218  3577 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0927 21:08:04.156415  3577 solver.cpp:218] Iteration 50300 (7.01943 iter/s, 14.2462s/100 iters), loss = 0.00618425
I0927 21:08:04.156456  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618449 (* 1 = 0.00618449 loss)
I0927 21:08:04.156462  3577 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0927 21:08:18.403394  3577 solver.cpp:218] Iteration 50400 (7.01907 iter/s, 14.2469s/100 iters), loss = 0.00199549
I0927 21:08:18.403435  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199573 (* 1 = 0.00199573 loss)
I0927 21:08:18.403441  3577 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0927 21:08:31.935536  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:08:32.505486  3577 solver.cpp:330] Iteration 50500, Testing net (#0)
I0927 21:08:35.877180  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:08:36.018240  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0927 21:08:36.018276  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311981 (* 1 = 0.311981 loss)
I0927 21:08:36.160014  3577 solver.cpp:218] Iteration 50500 (5.63173 iter/s, 17.7565s/100 iters), loss = 0.00627349
I0927 21:08:36.160043  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00627374 (* 1 = 0.00627374 loss)
I0927 21:08:36.160049  3577 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0927 21:08:50.385038  3577 solver.cpp:218] Iteration 50600 (7.0299 iter/s, 14.225s/100 iters), loss = 0.00360028
I0927 21:08:50.385069  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360054 (* 1 = 0.00360054 loss)
I0927 21:08:50.385076  3577 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0927 21:09:04.617722  3577 solver.cpp:218] Iteration 50700 (7.02612 iter/s, 14.2326s/100 iters), loss = 0.0119583
I0927 21:09:04.617812  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119585 (* 1 = 0.0119585 loss)
I0927 21:09:04.617828  3577 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0927 21:09:18.850095  3577 solver.cpp:218] Iteration 50800 (7.0263 iter/s, 14.2322s/100 iters), loss = 0.00267169
I0927 21:09:18.850136  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267194 (* 1 = 0.00267194 loss)
I0927 21:09:18.850142  3577 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0927 21:09:33.083377  3577 solver.cpp:218] Iteration 50900 (7.02583 iter/s, 14.2332s/100 iters), loss = 0.00410319
I0927 21:09:33.083408  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410344 (* 1 = 0.00410344 loss)
I0927 21:09:33.083415  3577 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0927 21:09:46.610816  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:09:47.179600  3577 solver.cpp:330] Iteration 51000, Testing net (#0)
I0927 21:09:50.550427  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:09:50.691606  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I0927 21:09:50.691643  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342381 (* 1 = 0.342381 loss)
I0927 21:09:50.833137  3577 solver.cpp:218] Iteration 51000 (5.6339 iter/s, 17.7497s/100 iters), loss = 0.0392458
I0927 21:09:50.833166  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039246 (* 1 = 0.039246 loss)
I0927 21:09:50.833173  3577 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0927 21:10:05.065536  3577 solver.cpp:218] Iteration 51100 (7.02626 iter/s, 14.2323s/100 iters), loss = 0.0389215
I0927 21:10:05.065567  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389217 (* 1 = 0.0389217 loss)
I0927 21:10:05.065572  3577 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0927 21:10:19.313421  3577 solver.cpp:218] Iteration 51200 (7.01862 iter/s, 14.2478s/100 iters), loss = 0.00838189
I0927 21:10:19.313490  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00838215 (* 1 = 0.00838215 loss)
I0927 21:10:19.313506  3577 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0927 21:10:33.553287  3577 solver.cpp:218] Iteration 51300 (7.02259 iter/s, 14.2398s/100 iters), loss = 0.00514566
I0927 21:10:33.553328  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514592 (* 1 = 0.00514592 loss)
I0927 21:10:33.553333  3577 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0927 21:10:47.791021  3577 solver.cpp:218] Iteration 51400 (7.02363 iter/s, 14.2377s/100 iters), loss = 0.00139575
I0927 21:10:47.791054  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139601 (* 1 = 0.00139601 loss)
I0927 21:10:47.791059  3577 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0927 21:11:01.320886  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:11:01.890506  3577 solver.cpp:330] Iteration 51500, Testing net (#0)
I0927 21:11:05.261842  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:11:05.402969  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I0927 21:11:05.403007  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323239 (* 1 = 0.323239 loss)
I0927 21:11:05.544279  3577 solver.cpp:218] Iteration 51500 (5.63279 iter/s, 17.7532s/100 iters), loss = 0.00153283
I0927 21:11:05.544311  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153308 (* 1 = 0.00153308 loss)
I0927 21:11:05.544317  3577 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0927 21:11:19.775228  3577 solver.cpp:218] Iteration 51600 (7.02697 iter/s, 14.2309s/100 iters), loss = 0.0276495
I0927 21:11:19.775270  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276497 (* 1 = 0.0276497 loss)
I0927 21:11:19.775275  3577 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0927 21:11:34.007918  3577 solver.cpp:218] Iteration 51700 (7.02612 iter/s, 14.2326s/100 iters), loss = 0.051521
I0927 21:11:34.008025  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515212 (* 1 = 0.0515212 loss)
I0927 21:11:34.008033  3577 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0927 21:11:48.240561  3577 solver.cpp:218] Iteration 51800 (7.02617 iter/s, 14.2325s/100 iters), loss = 0.00129633
I0927 21:11:48.240592  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129657 (* 1 = 0.00129657 loss)
I0927 21:11:48.240598  3577 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0927 21:12:02.475972  3577 solver.cpp:218] Iteration 51900 (7.02477 iter/s, 14.2353s/100 iters), loss = 0.0032174
I0927 21:12:02.476013  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321765 (* 1 = 0.00321765 loss)
I0927 21:12:02.476019  3577 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0927 21:12:16.005560  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:12:16.575544  3577 solver.cpp:330] Iteration 52000, Testing net (#0)
I0927 21:12:19.948079  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:12:20.089165  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I0927 21:12:20.089201  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324824 (* 1 = 0.324824 loss)
I0927 21:12:20.231182  3577 solver.cpp:218] Iteration 52000 (5.63218 iter/s, 17.7551s/100 iters), loss = 0.00628183
I0927 21:12:20.231211  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628208 (* 1 = 0.00628208 loss)
I0927 21:12:20.231218  3577 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0927 21:12:34.467468  3577 solver.cpp:218] Iteration 52100 (7.02434 iter/s, 14.2362s/100 iters), loss = 0.0346936
I0927 21:12:34.467509  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346939 (* 1 = 0.0346939 loss)
I0927 21:12:34.467514  3577 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0927 21:12:48.712453  3577 solver.cpp:218] Iteration 52200 (7.02005 iter/s, 14.2449s/100 iters), loss = 0.0155841
I0927 21:12:48.712574  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155843 (* 1 = 0.0155843 loss)
I0927 21:12:48.712591  3577 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0927 21:13:02.957650  3577 solver.cpp:218] Iteration 52300 (7.01998 iter/s, 14.245s/100 iters), loss = 0.00913673
I0927 21:13:02.957681  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00913698 (* 1 = 0.00913698 loss)
I0927 21:13:02.957687  3577 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0927 21:13:17.234171  3577 solver.cpp:218] Iteration 52400 (7.00454 iter/s, 14.2765s/100 iters), loss = 0.00914471
I0927 21:13:17.234213  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914496 (* 1 = 0.00914496 loss)
I0927 21:13:17.234220  3577 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0927 21:13:30.846467  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:13:31.419077  3577 solver.cpp:330] Iteration 52500, Testing net (#0)
I0927 21:13:34.807677  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:13:34.946641  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I0927 21:13:34.946677  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317576 (* 1 = 0.317576 loss)
I0927 21:13:35.088416  3577 solver.cpp:218] Iteration 52500 (5.60094 iter/s, 17.8542s/100 iters), loss = 0.0215054
I0927 21:13:35.088449  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215057 (* 1 = 0.0215057 loss)
I0927 21:13:35.088456  3577 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0927 21:13:49.426115  3577 solver.cpp:218] Iteration 52600 (6.97465 iter/s, 14.3376s/100 iters), loss = 0.018916
I0927 21:13:49.426146  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189163 (* 1 = 0.0189163 loss)
I0927 21:13:49.426151  3577 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0927 21:14:03.669900  3577 solver.cpp:218] Iteration 52700 (7.02064 iter/s, 14.2437s/100 iters), loss = 0.0261755
I0927 21:14:03.669983  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261758 (* 1 = 0.0261758 loss)
I0927 21:14:03.670001  3577 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0927 21:14:17.914675  3577 solver.cpp:218] Iteration 52800 (7.02018 iter/s, 14.2447s/100 iters), loss = 0.0039008
I0927 21:14:17.914717  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00390106 (* 1 = 0.00390106 loss)
I0927 21:14:17.914723  3577 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0927 21:14:32.155719  3577 solver.cpp:218] Iteration 52900 (7.022 iter/s, 14.241s/100 iters), loss = 0.00136071
I0927 21:14:32.155750  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136098 (* 1 = 0.00136098 loss)
I0927 21:14:32.155756  3577 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0927 21:14:45.686671  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:14:46.257282  3577 solver.cpp:330] Iteration 53000, Testing net (#0)
I0927 21:14:49.629158  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:14:49.770282  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I0927 21:14:49.770318  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32157 (* 1 = 0.32157 loss)
I0927 21:14:49.911897  3577 solver.cpp:218] Iteration 53000 (5.63187 iter/s, 17.7561s/100 iters), loss = 0.0244162
I0927 21:14:49.911929  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244164 (* 1 = 0.0244164 loss)
I0927 21:14:49.911936  3577 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0927 21:15:04.146055  3577 solver.cpp:218] Iteration 53100 (7.02539 iter/s, 14.2341s/100 iters), loss = 0.00699796
I0927 21:15:04.146096  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00699822 (* 1 = 0.00699822 loss)
I0927 21:15:04.146102  3577 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0927 21:15:18.392503  3577 solver.cpp:218] Iteration 53200 (7.01933 iter/s, 14.2464s/100 iters), loss = 0.00404912
I0927 21:15:18.392577  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404939 (* 1 = 0.00404939 loss)
I0927 21:15:18.392587  3577 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0927 21:15:32.637176  3577 solver.cpp:218] Iteration 53300 (7.02023 iter/s, 14.2446s/100 iters), loss = 0.0154846
I0927 21:15:32.637217  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154848 (* 1 = 0.0154848 loss)
I0927 21:15:32.637223  3577 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0927 21:15:46.880661  3577 solver.cpp:218] Iteration 53400 (7.02079 iter/s, 14.2434s/100 iters), loss = 0.000789184
I0927 21:15:46.880702  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000789449 (* 1 = 0.000789449 loss)
I0927 21:15:46.880710  3577 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0927 21:16:00.415345  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:16:00.986105  3577 solver.cpp:330] Iteration 53500, Testing net (#0)
I0927 21:16:04.355929  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:16:04.496887  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9173
I0927 21:16:04.496923  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332046 (* 1 = 0.332046 loss)
I0927 21:16:04.638001  3577 solver.cpp:218] Iteration 53500 (5.6315 iter/s, 17.7573s/100 iters), loss = 0.00341855
I0927 21:16:04.638033  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341881 (* 1 = 0.00341881 loss)
I0927 21:16:04.638041  3577 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0927 21:16:18.877073  3577 solver.cpp:218] Iteration 53600 (7.02296 iter/s, 14.239s/100 iters), loss = 0.00671567
I0927 21:16:18.877115  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671593 (* 1 = 0.00671593 loss)
I0927 21:16:18.877120  3577 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0927 21:16:33.109719  3577 solver.cpp:218] Iteration 53700 (7.02614 iter/s, 14.2326s/100 iters), loss = 0.020504
I0927 21:16:33.109803  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205042 (* 1 = 0.0205042 loss)
I0927 21:16:33.109819  3577 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0927 21:16:47.351073  3577 solver.cpp:218] Iteration 53800 (7.02186 iter/s, 14.2412s/100 iters), loss = 0.00374194
I0927 21:16:47.351115  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374218 (* 1 = 0.00374218 loss)
I0927 21:16:47.351121  3577 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0927 21:17:01.588701  3577 solver.cpp:218] Iteration 53900 (7.02368 iter/s, 14.2375s/100 iters), loss = 0.00404843
I0927 21:17:01.588742  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404868 (* 1 = 0.00404868 loss)
I0927 21:17:01.588749  3577 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0927 21:17:15.121390  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:17:15.692507  3577 solver.cpp:330] Iteration 54000, Testing net (#0)
I0927 21:17:19.064370  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:17:19.204931  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0927 21:17:19.204968  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329212 (* 1 = 0.329212 loss)
I0927 21:17:19.345938  3577 solver.cpp:218] Iteration 54000 (5.63153 iter/s, 17.7571s/100 iters), loss = 0.0021357
I0927 21:17:19.345970  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213595 (* 1 = 0.00213595 loss)
I0927 21:17:19.345978  3577 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0927 21:17:33.583734  3577 solver.cpp:218] Iteration 54100 (7.02359 iter/s, 14.2377s/100 iters), loss = 0.00482378
I0927 21:17:33.583773  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482403 (* 1 = 0.00482403 loss)
I0927 21:17:33.583780  3577 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0927 21:17:47.822228  3577 solver.cpp:218] Iteration 54200 (7.02325 iter/s, 14.2384s/100 iters), loss = 0.00272915
I0927 21:17:47.822319  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027294 (* 1 = 0.0027294 loss)
I0927 21:17:47.822335  3577 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0927 21:18:02.055757  3577 solver.cpp:218] Iteration 54300 (7.02573 iter/s, 14.2334s/100 iters), loss = 0.00319283
I0927 21:18:02.055797  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319309 (* 1 = 0.00319309 loss)
I0927 21:18:02.055804  3577 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0927 21:18:16.295233  3577 solver.cpp:218] Iteration 54400 (7.02277 iter/s, 14.2394s/100 iters), loss = 0.00864851
I0927 21:18:16.295264  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00864877 (* 1 = 0.00864877 loss)
I0927 21:18:16.295270  3577 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0927 21:18:29.823642  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:18:30.393697  3577 solver.cpp:330] Iteration 54500, Testing net (#0)
I0927 21:18:33.765259  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:18:33.906522  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0927 21:18:33.906558  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318751 (* 1 = 0.318751 loss)
I0927 21:18:34.048225  3577 solver.cpp:218] Iteration 54500 (5.63288 iter/s, 17.7529s/100 iters), loss = 0.0261639
I0927 21:18:34.048257  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261642 (* 1 = 0.0261642 loss)
I0927 21:18:34.048264  3577 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0927 21:18:48.279134  3577 solver.cpp:218] Iteration 54600 (7.02699 iter/s, 14.2308s/100 iters), loss = 0.00219524
I0927 21:18:48.279166  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021955 (* 1 = 0.0021955 loss)
I0927 21:18:48.279172  3577 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0927 21:19:02.512776  3577 solver.cpp:218] Iteration 54700 (7.02564 iter/s, 14.2336s/100 iters), loss = 0.0317842
I0927 21:19:02.512926  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317845 (* 1 = 0.0317845 loss)
I0927 21:19:02.512934  3577 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0927 21:19:16.749811  3577 solver.cpp:218] Iteration 54800 (7.02403 iter/s, 14.2368s/100 iters), loss = 0.00171832
I0927 21:19:16.749845  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171857 (* 1 = 0.00171857 loss)
I0927 21:19:16.749850  3577 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0927 21:19:30.988461  3577 solver.cpp:218] Iteration 54900 (7.02317 iter/s, 14.2386s/100 iters), loss = 0.00710001
I0927 21:19:30.988492  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710026 (* 1 = 0.00710026 loss)
I0927 21:19:30.988499  3577 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0927 21:19:44.521025  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:19:45.091536  3577 solver.cpp:330] Iteration 55000, Testing net (#0)
I0927 21:19:48.464417  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:19:48.605716  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.918
I0927 21:19:48.605744  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325624 (* 1 = 0.325624 loss)
I0927 21:19:48.747031  3577 solver.cpp:218] Iteration 55000 (5.63111 iter/s, 17.7585s/100 iters), loss = 0.0080718
I0927 21:19:48.747061  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00807205 (* 1 = 0.00807205 loss)
I0927 21:19:48.747067  3577 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0927 21:20:02.984067  3577 solver.cpp:218] Iteration 55100 (7.02397 iter/s, 14.237s/100 iters), loss = 0.0100542
I0927 21:20:02.984099  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100544 (* 1 = 0.0100544 loss)
I0927 21:20:02.984105  3577 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0927 21:20:17.220052  3577 solver.cpp:218] Iteration 55200 (7.02449 iter/s, 14.2359s/100 iters), loss = 0.017513
I0927 21:20:17.220172  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175133 (* 1 = 0.0175133 loss)
I0927 21:20:17.220190  3577 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0927 21:20:31.454397  3577 solver.cpp:218] Iteration 55300 (7.02534 iter/s, 14.2342s/100 iters), loss = 0.00616027
I0927 21:20:31.454438  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616052 (* 1 = 0.00616052 loss)
I0927 21:20:31.454444  3577 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0927 21:20:45.687934  3577 solver.cpp:218] Iteration 55400 (7.0257 iter/s, 14.2335s/100 iters), loss = 0.00814585
I0927 21:20:45.687965  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081461 (* 1 = 0.0081461 loss)
I0927 21:20:45.687971  3577 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0927 21:20:59.222812  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:20:59.793820  3577 solver.cpp:330] Iteration 55500, Testing net (#0)
I0927 21:21:03.165688  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:21:03.306445  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9181
I0927 21:21:03.306473  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330776 (* 1 = 0.330776 loss)
I0927 21:21:03.447927  3577 solver.cpp:218] Iteration 55500 (5.63066 iter/s, 17.7599s/100 iters), loss = 0.00664242
I0927 21:21:03.447958  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664266 (* 1 = 0.00664266 loss)
I0927 21:21:03.447965  3577 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0927 21:21:17.681489  3577 solver.cpp:218] Iteration 55600 (7.02568 iter/s, 14.2335s/100 iters), loss = 0.00440594
I0927 21:21:17.681521  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440618 (* 1 = 0.00440618 loss)
I0927 21:21:17.681527  3577 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0927 21:21:31.916319  3577 solver.cpp:218] Iteration 55700 (7.02506 iter/s, 14.2348s/100 iters), loss = 0.0150305
I0927 21:21:31.916396  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150307 (* 1 = 0.0150307 loss)
I0927 21:21:31.916404  3577 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0927 21:21:46.151130  3577 solver.cpp:218] Iteration 55800 (7.02509 iter/s, 14.2347s/100 iters), loss = 0.00402668
I0927 21:21:46.151160  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402691 (* 1 = 0.00402691 loss)
I0927 21:21:46.151166  3577 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0927 21:22:00.383615  3577 solver.cpp:218] Iteration 55900 (7.02621 iter/s, 14.2324s/100 iters), loss = 0.00208871
I0927 21:22:00.383644  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208895 (* 1 = 0.00208895 loss)
I0927 21:22:00.383651  3577 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0927 21:22:13.911989  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:22:14.482553  3577 solver.cpp:330] Iteration 56000, Testing net (#0)
I0927 21:22:17.852085  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:22:17.992903  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I0927 21:22:17.992930  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328894 (* 1 = 0.328894 loss)
I0927 21:22:18.134938  3577 solver.cpp:218] Iteration 56000 (5.63341 iter/s, 17.7512s/100 iters), loss = 0.00416914
I0927 21:22:18.134966  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416937 (* 1 = 0.00416937 loss)
I0927 21:22:18.134973  3577 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0927 21:22:32.367871  3577 solver.cpp:218] Iteration 56100 (7.02599 iter/s, 14.2329s/100 iters), loss = 0.0104406
I0927 21:22:32.367913  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104409 (* 1 = 0.0104409 loss)
I0927 21:22:32.367918  3577 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0927 21:22:46.607969  3577 solver.cpp:218] Iteration 56200 (7.02246 iter/s, 14.24s/100 iters), loss = 0.0181258
I0927 21:22:46.608105  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181261 (* 1 = 0.0181261 loss)
I0927 21:22:46.608113  3577 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0927 21:23:00.841830  3577 solver.cpp:218] Iteration 56300 (7.02559 iter/s, 14.2337s/100 iters), loss = 0.0132893
I0927 21:23:00.841861  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132895 (* 1 = 0.0132895 loss)
I0927 21:23:00.841867  3577 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0927 21:23:15.076664  3577 solver.cpp:218] Iteration 56400 (7.02505 iter/s, 14.2348s/100 iters), loss = 0.000862663
I0927 21:23:15.076707  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000862898 (* 1 = 0.000862898 loss)
I0927 21:23:15.076712  3577 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0927 21:23:28.606786  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:23:29.177141  3577 solver.cpp:330] Iteration 56500, Testing net (#0)
I0927 21:23:32.547703  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:23:32.688576  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0927 21:23:32.688604  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331384 (* 1 = 0.331384 loss)
I0927 21:23:32.830322  3577 solver.cpp:218] Iteration 56500 (5.63267 iter/s, 17.7536s/100 iters), loss = 0.00933722
I0927 21:23:32.830353  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00933746 (* 1 = 0.00933746 loss)
I0927 21:23:32.830358  3577 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0927 21:23:47.072268  3577 solver.cpp:218] Iteration 56600 (7.02155 iter/s, 14.2419s/100 iters), loss = 0.00563129
I0927 21:23:47.072300  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563153 (* 1 = 0.00563153 loss)
I0927 21:23:47.072306  3577 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0927 21:24:01.320379  3577 solver.cpp:218] Iteration 56700 (7.01851 iter/s, 14.248s/100 iters), loss = 0.00245556
I0927 21:24:01.320469  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245581 (* 1 = 0.00245581 loss)
I0927 21:24:01.320477  3577 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0927 21:24:15.568483  3577 solver.cpp:218] Iteration 56800 (7.01854 iter/s, 14.248s/100 iters), loss = 0.00736934
I0927 21:24:15.568514  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00736959 (* 1 = 0.00736959 loss)
I0927 21:24:15.568521  3577 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0927 21:24:29.812959  3577 solver.cpp:218] Iteration 56900 (7.0203 iter/s, 14.2444s/100 iters), loss = 0.00804109
I0927 21:24:29.813001  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00804134 (* 1 = 0.00804134 loss)
I0927 21:24:29.813006  3577 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0927 21:24:43.345115  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:24:43.916368  3577 solver.cpp:330] Iteration 57000, Testing net (#0)
I0927 21:24:47.287042  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:24:47.428405  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I0927 21:24:47.428431  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333333 (* 1 = 0.333333 loss)
I0927 21:24:47.569828  3577 solver.cpp:218] Iteration 57000 (5.63165 iter/s, 17.7568s/100 iters), loss = 0.00205426
I0927 21:24:47.569857  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205451 (* 1 = 0.00205451 loss)
I0927 21:24:47.569864  3577 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0927 21:25:01.809058  3577 solver.cpp:218] Iteration 57100 (7.02289 iter/s, 14.2392s/100 iters), loss = 0.00436649
I0927 21:25:01.809101  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436674 (* 1 = 0.00436674 loss)
I0927 21:25:01.809108  3577 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0927 21:25:16.048658  3577 solver.cpp:218] Iteration 57200 (7.02271 iter/s, 14.2395s/100 iters), loss = 0.00998179
I0927 21:25:16.048758  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00998204 (* 1 = 0.00998204 loss)
I0927 21:25:16.048764  3577 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0927 21:25:30.288864  3577 solver.cpp:218] Iteration 57300 (7.02244 iter/s, 14.2401s/100 iters), loss = 0.00234712
I0927 21:25:30.288895  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234736 (* 1 = 0.00234736 loss)
I0927 21:25:30.288902  3577 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0927 21:25:44.528641  3577 solver.cpp:218] Iteration 57400 (7.02262 iter/s, 14.2397s/100 iters), loss = 0.00152655
I0927 21:25:44.528684  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152679 (* 1 = 0.00152679 loss)
I0927 21:25:44.528690  3577 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0927 21:25:58.057433  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:25:58.628419  3577 solver.cpp:330] Iteration 57500, Testing net (#0)
I0927 21:26:02.000576  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:26:02.141316  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I0927 21:26:02.141343  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357679 (* 1 = 0.357679 loss)
I0927 21:26:02.283020  3577 solver.cpp:218] Iteration 57500 (5.63244 iter/s, 17.7543s/100 iters), loss = 0.00249651
I0927 21:26:02.283051  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249675 (* 1 = 0.00249675 loss)
I0927 21:26:02.283057  3577 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0927 21:26:16.526832  3577 solver.cpp:218] Iteration 57600 (7.02063 iter/s, 14.2437s/100 iters), loss = 0.00239327
I0927 21:26:16.526875  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239352 (* 1 = 0.00239352 loss)
I0927 21:26:16.526880  3577 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0927 21:26:30.779883  3577 solver.cpp:218] Iteration 57700 (7.01608 iter/s, 14.253s/100 iters), loss = 0.00357809
I0927 21:26:30.779963  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357833 (* 1 = 0.00357833 loss)
I0927 21:26:30.779973  3577 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0927 21:26:45.030961  3577 solver.cpp:218] Iteration 57800 (7.01707 iter/s, 14.251s/100 iters), loss = 0.00979369
I0927 21:26:45.031004  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00979393 (* 1 = 0.00979393 loss)
I0927 21:26:45.031010  3577 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0927 21:26:59.280339  3577 solver.cpp:218] Iteration 57900 (7.01789 iter/s, 14.2493s/100 iters), loss = 0.00588911
I0927 21:26:59.280381  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588935 (* 1 = 0.00588935 loss)
I0927 21:26:59.280387  3577 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0927 21:27:12.824443  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:27:13.395958  3577 solver.cpp:330] Iteration 58000, Testing net (#0)
I0927 21:27:16.767489  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:27:16.908385  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0927 21:27:16.908412  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322552 (* 1 = 0.322552 loss)
I0927 21:27:17.050213  3577 solver.cpp:218] Iteration 58000 (5.62753 iter/s, 17.7698s/100 iters), loss = 0.00140756
I0927 21:27:17.050245  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014078 (* 1 = 0.0014078 loss)
I0927 21:27:17.050251  3577 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0927 21:27:31.280796  3577 solver.cpp:218] Iteration 58100 (7.02715 iter/s, 14.2305s/100 iters), loss = 0.00258114
I0927 21:27:31.280838  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258138 (* 1 = 0.00258138 loss)
I0927 21:27:31.280843  3577 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0927 21:27:45.517400  3577 solver.cpp:218] Iteration 58200 (7.02419 iter/s, 14.2365s/100 iters), loss = 0.0177535
I0927 21:27:45.517475  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177538 (* 1 = 0.0177538 loss)
I0927 21:27:45.517495  3577 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0927 21:27:59.752678  3577 solver.cpp:218] Iteration 58300 (7.02486 iter/s, 14.2352s/100 iters), loss = 0.0121353
I0927 21:27:59.752719  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121355 (* 1 = 0.0121355 loss)
I0927 21:27:59.752725  3577 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0927 21:28:13.992334  3577 solver.cpp:218] Iteration 58400 (7.02268 iter/s, 14.2396s/100 iters), loss = 0.00631178
I0927 21:28:13.992377  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00631202 (* 1 = 0.00631202 loss)
I0927 21:28:13.992382  3577 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0927 21:28:27.520731  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:28:28.092336  3577 solver.cpp:330] Iteration 58500, Testing net (#0)
I0927 21:28:31.463557  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:28:31.604748  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9197
I0927 21:28:31.604789  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341383 (* 1 = 0.341383 loss)
I0927 21:28:31.746613  3577 solver.cpp:218] Iteration 58500 (5.63247 iter/s, 17.7542s/100 iters), loss = 0.00492773
I0927 21:28:31.746644  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492796 (* 1 = 0.00492796 loss)
I0927 21:28:31.746651  3577 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0927 21:28:45.980814  3577 solver.cpp:218] Iteration 58600 (7.02537 iter/s, 14.2341s/100 iters), loss = 0.00220819
I0927 21:28:45.980856  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220844 (* 1 = 0.00220844 loss)
I0927 21:28:45.980862  3577 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0927 21:29:00.218133  3577 solver.cpp:218] Iteration 58700 (7.02383 iter/s, 14.2372s/100 iters), loss = 0.0018826
I0927 21:29:00.218240  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188285 (* 1 = 0.00188285 loss)
I0927 21:29:00.218246  3577 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0927 21:29:14.451093  3577 solver.cpp:218] Iteration 58800 (7.02602 iter/s, 14.2328s/100 iters), loss = 0.00152691
I0927 21:29:14.451134  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152716 (* 1 = 0.00152716 loss)
I0927 21:29:14.451139  3577 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0927 21:29:28.683786  3577 solver.cpp:218] Iteration 58900 (7.02612 iter/s, 14.2326s/100 iters), loss = 0.00180774
I0927 21:29:28.683830  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180799 (* 1 = 0.00180799 loss)
I0927 21:29:28.683835  3577 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0927 21:29:42.215181  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:29:42.784051  3577 solver.cpp:330] Iteration 59000, Testing net (#0)
I0927 21:29:46.155436  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:29:46.296037  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I0927 21:29:46.296073  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364126 (* 1 = 0.364126 loss)
I0927 21:29:46.437815  3577 solver.cpp:218] Iteration 59000 (5.63255 iter/s, 17.7539s/100 iters), loss = 0.00431246
I0927 21:29:46.437845  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431271 (* 1 = 0.00431271 loss)
I0927 21:29:46.437851  3577 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0927 21:30:00.674017  3577 solver.cpp:218] Iteration 59100 (7.02438 iter/s, 14.2361s/100 iters), loss = 0.00978042
I0927 21:30:00.674057  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978068 (* 1 = 0.00978068 loss)
I0927 21:30:00.674063  3577 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0927 21:30:14.912997  3577 solver.cpp:218] Iteration 59200 (7.02302 iter/s, 14.2389s/100 iters), loss = 0.00530099
I0927 21:30:14.913067  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530125 (* 1 = 0.00530125 loss)
I0927 21:30:14.913074  3577 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0927 21:30:29.158359  3577 solver.cpp:218] Iteration 59300 (7.01988 iter/s, 14.2453s/100 iters), loss = 0.00172707
I0927 21:30:29.158390  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172733 (* 1 = 0.00172733 loss)
I0927 21:30:29.158396  3577 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0927 21:30:43.405478  3577 solver.cpp:218] Iteration 59400 (7.019 iter/s, 14.2471s/100 iters), loss = 0.00593081
I0927 21:30:43.405520  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00593106 (* 1 = 0.00593106 loss)
I0927 21:30:43.405526  3577 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0927 21:30:56.946880  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:30:57.517622  3577 solver.cpp:330] Iteration 59500, Testing net (#0)
I0927 21:31:00.890261  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:31:01.031625  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I0927 21:31:01.031661  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359806 (* 1 = 0.359806 loss)
I0927 21:31:01.172804  3577 solver.cpp:218] Iteration 59500 (5.62834 iter/s, 17.7672s/100 iters), loss = 0.00289916
I0927 21:31:01.172835  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289941 (* 1 = 0.00289941 loss)
I0927 21:31:01.172842  3577 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0927 21:31:15.412844  3577 solver.cpp:218] Iteration 59600 (7.02249 iter/s, 14.24s/100 iters), loss = 0.00278781
I0927 21:31:15.412885  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278807 (* 1 = 0.00278807 loss)
I0927 21:31:15.412891  3577 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0927 21:31:29.650652  3577 solver.cpp:218] Iteration 59700 (7.02359 iter/s, 14.2377s/100 iters), loss = 0.00484457
I0927 21:31:29.650794  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00484483 (* 1 = 0.00484483 loss)
I0927 21:31:29.650801  3577 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0927 21:31:43.888890  3577 solver.cpp:218] Iteration 59800 (7.02343 iter/s, 14.2381s/100 iters), loss = 0.00186938
I0927 21:31:43.888932  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186964 (* 1 = 0.00186964 loss)
I0927 21:31:43.888938  3577 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0927 21:31:58.128767  3577 solver.cpp:218] Iteration 59900 (7.02257 iter/s, 14.2398s/100 iters), loss = 0.00142164
I0927 21:31:58.128808  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014219 (* 1 = 0.0014219 loss)
I0927 21:31:58.128814  3577 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0927 21:32:11.671226  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:32:12.242449  3577 solver.cpp:330] Iteration 60000, Testing net (#0)
I0927 21:32:15.613437  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:32:15.754709  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I0927 21:32:15.754746  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340425 (* 1 = 0.340425 loss)
I0927 21:32:15.895962  3577 solver.cpp:218] Iteration 60000 (5.62838 iter/s, 17.7671s/100 iters), loss = 0.00253932
I0927 21:32:15.895992  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253957 (* 1 = 0.00253957 loss)
I0927 21:32:15.895998  3577 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0927 21:32:30.141515  3577 solver.cpp:218] Iteration 60100 (7.01977 iter/s, 14.2455s/100 iters), loss = 0.00991994
I0927 21:32:30.141557  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00992019 (* 1 = 0.00992019 loss)
I0927 21:32:30.141563  3577 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0927 21:32:44.392798  3577 solver.cpp:218] Iteration 60200 (7.01695 iter/s, 14.2512s/100 iters), loss = 0.00294205
I0927 21:32:44.392884  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029423 (* 1 = 0.0029423 loss)
I0927 21:32:44.392901  3577 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0927 21:32:58.649217  3577 solver.cpp:218] Iteration 60300 (7.01445 iter/s, 14.2563s/100 iters), loss = 0.000930473
I0927 21:32:58.649255  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000930723 (* 1 = 0.000930723 loss)
I0927 21:32:58.649262  3577 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0927 21:33:12.903324  3577 solver.cpp:218] Iteration 60400 (7.01556 iter/s, 14.254s/100 iters), loss = 0.000802273
I0927 21:33:12.903357  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000802522 (* 1 = 0.000802522 loss)
I0927 21:33:12.903365  3577 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0927 21:33:26.439824  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:33:27.010290  3577 solver.cpp:330] Iteration 60500, Testing net (#0)
I0927 21:33:30.382066  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:33:30.522675  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I0927 21:33:30.522711  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339369 (* 1 = 0.339369 loss)
I0927 21:33:30.664654  3577 solver.cpp:218] Iteration 60500 (5.63023 iter/s, 17.7612s/100 iters), loss = 0.0237503
I0927 21:33:30.664683  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237506 (* 1 = 0.0237506 loss)
I0927 21:33:30.664690  3577 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0927 21:33:44.900840  3577 solver.cpp:218] Iteration 60600 (7.02439 iter/s, 14.2361s/100 iters), loss = 0.00604538
I0927 21:33:44.900882  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00604564 (* 1 = 0.00604564 loss)
I0927 21:33:44.900888  3577 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0927 21:33:59.145908  3577 solver.cpp:218] Iteration 60700 (7.02001 iter/s, 14.245s/100 iters), loss = 0.0147641
I0927 21:33:59.146072  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147643 (* 1 = 0.0147643 loss)
I0927 21:33:59.146082  3577 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0927 21:34:13.389231  3577 solver.cpp:218] Iteration 60800 (7.02093 iter/s, 14.2431s/100 iters), loss = 0.00329715
I0927 21:34:13.389274  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032974 (* 1 = 0.0032974 loss)
I0927 21:34:13.389279  3577 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0927 21:34:27.635617  3577 solver.cpp:218] Iteration 60900 (7.01936 iter/s, 14.2463s/100 iters), loss = 0.00404061
I0927 21:34:27.635658  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404086 (* 1 = 0.00404086 loss)
I0927 21:34:27.635664  3577 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0927 21:34:41.171988  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:34:41.741859  3577 solver.cpp:330] Iteration 61000, Testing net (#0)
I0927 21:34:45.113201  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:34:45.253971  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I0927 21:34:45.254009  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345039 (* 1 = 0.345039 loss)
I0927 21:34:45.396507  3577 solver.cpp:218] Iteration 61000 (5.63038 iter/s, 17.7608s/100 iters), loss = 0.00177592
I0927 21:34:45.396536  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177616 (* 1 = 0.00177616 loss)
I0927 21:34:45.396544  3577 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0927 21:34:59.638761  3577 solver.cpp:218] Iteration 61100 (7.02139 iter/s, 14.2422s/100 iters), loss = 0.0121208
I0927 21:34:59.638792  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012121 (* 1 = 0.012121 loss)
I0927 21:34:59.638800  3577 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0927 21:35:13.880703  3577 solver.cpp:218] Iteration 61200 (7.02155 iter/s, 14.2419s/100 iters), loss = 0.00474028
I0927 21:35:13.880844  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474053 (* 1 = 0.00474053 loss)
I0927 21:35:13.880852  3577 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0927 21:35:28.114389  3577 solver.cpp:218] Iteration 61300 (7.02567 iter/s, 14.2335s/100 iters), loss = 0.00104613
I0927 21:35:28.114421  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104639 (* 1 = 0.00104639 loss)
I0927 21:35:28.114428  3577 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0927 21:35:42.348048  3577 solver.cpp:218] Iteration 61400 (7.02563 iter/s, 14.2336s/100 iters), loss = 0.00802409
I0927 21:35:42.348078  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00802434 (* 1 = 0.00802434 loss)
I0927 21:35:42.348084  3577 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0927 21:35:55.881220  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:35:56.451787  3577 solver.cpp:330] Iteration 61500, Testing net (#0)
I0927 21:35:59.823050  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:35:59.963876  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9181
I0927 21:35:59.963913  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350065 (* 1 = 0.350065 loss)
I0927 21:36:00.105450  3577 solver.cpp:218] Iteration 61500 (5.63148 iter/s, 17.7573s/100 iters), loss = 0.000430722
I0927 21:36:00.105480  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000430975 (* 1 = 0.000430975 loss)
I0927 21:36:00.105487  3577 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0927 21:36:14.338953  3577 solver.cpp:218] Iteration 61600 (7.02571 iter/s, 14.2334s/100 iters), loss = 0.00223018
I0927 21:36:14.338984  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223043 (* 1 = 0.00223043 loss)
I0927 21:36:14.338990  3577 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0927 21:36:28.580991  3577 solver.cpp:218] Iteration 61700 (7.0215 iter/s, 14.242s/100 iters), loss = 0.00300122
I0927 21:36:28.581142  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300146 (* 1 = 0.00300146 loss)
I0927 21:36:28.581152  3577 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0927 21:36:42.817487  3577 solver.cpp:218] Iteration 61800 (7.02429 iter/s, 14.2363s/100 iters), loss = 0.0104968
I0927 21:36:42.817534  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104971 (* 1 = 0.0104971 loss)
I0927 21:36:42.817541  3577 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0927 21:36:57.053959  3577 solver.cpp:218] Iteration 61900 (7.02425 iter/s, 14.2364s/100 iters), loss = 0.00595977
I0927 21:36:57.054003  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596001 (* 1 = 0.00596001 loss)
I0927 21:36:57.054008  3577 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0927 21:37:10.582427  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:37:11.152243  3577 solver.cpp:330] Iteration 62000, Testing net (#0)
I0927 21:37:14.523722  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:37:14.664618  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0927 21:37:14.664654  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342864 (* 1 = 0.342864 loss)
I0927 21:37:14.807096  3577 solver.cpp:218] Iteration 62000 (5.63284 iter/s, 17.753s/100 iters), loss = 0.009609
I0927 21:37:14.807127  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00960925 (* 1 = 0.00960925 loss)
I0927 21:37:14.807134  3577 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0927 21:37:29.035038  3577 solver.cpp:218] Iteration 62100 (7.02846 iter/s, 14.2279s/100 iters), loss = 0.00361072
I0927 21:37:29.035070  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361097 (* 1 = 0.00361097 loss)
I0927 21:37:29.035076  3577 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0927 21:37:43.274226  3577 solver.cpp:218] Iteration 62200 (7.02291 iter/s, 14.2391s/100 iters), loss = 0.00248177
I0927 21:37:43.274380  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248202 (* 1 = 0.00248202 loss)
I0927 21:37:43.274389  3577 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0927 21:37:57.509202  3577 solver.cpp:218] Iteration 62300 (7.02504 iter/s, 14.2348s/100 iters), loss = 0.000792613
I0927 21:37:57.509244  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000792858 (* 1 = 0.000792858 loss)
I0927 21:37:57.509250  3577 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0927 21:38:11.743940  3577 solver.cpp:218] Iteration 62400 (7.02511 iter/s, 14.2347s/100 iters), loss = 0.00150496
I0927 21:38:11.743981  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150521 (* 1 = 0.00150521 loss)
I0927 21:38:11.743988  3577 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0927 21:38:25.271122  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:38:25.840855  3577 solver.cpp:330] Iteration 62500, Testing net (#0)
I0927 21:38:29.212010  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:38:29.353101  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I0927 21:38:29.353137  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363797 (* 1 = 0.363797 loss)
I0927 21:38:29.494346  3577 solver.cpp:218] Iteration 62500 (5.6337 iter/s, 17.7503s/100 iters), loss = 0.00135003
I0927 21:38:29.494376  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135028 (* 1 = 0.00135028 loss)
I0927 21:38:29.494384  3577 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0927 21:38:43.743144  3577 solver.cpp:218] Iteration 62600 (7.01817 iter/s, 14.2487s/100 iters), loss = 0.00552913
I0927 21:38:43.743175  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552938 (* 1 = 0.00552938 loss)
I0927 21:38:43.743180  3577 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0927 21:38:57.993079  3577 solver.cpp:218] Iteration 62700 (7.01761 iter/s, 14.2499s/100 iters), loss = 0.00369115
I0927 21:38:57.993218  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369141 (* 1 = 0.00369141 loss)
I0927 21:38:57.993237  3577 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0927 21:39:12.232657  3577 solver.cpp:218] Iteration 62800 (7.02276 iter/s, 14.2394s/100 iters), loss = 0.00472527
I0927 21:39:12.232698  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472552 (* 1 = 0.00472552 loss)
I0927 21:39:12.232704  3577 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0927 21:39:26.470919  3577 solver.cpp:218] Iteration 62900 (7.02337 iter/s, 14.2382s/100 iters), loss = 0.00778464
I0927 21:39:26.470957  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00778489 (* 1 = 0.00778489 loss)
I0927 21:39:26.470964  3577 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0927 21:39:40.005678  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:39:40.575532  3577 solver.cpp:330] Iteration 63000, Testing net (#0)
I0927 21:39:43.947959  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:39:44.089076  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I0927 21:39:44.089112  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336834 (* 1 = 0.336834 loss)
I0927 21:39:44.230500  3577 solver.cpp:218] Iteration 63000 (5.63079 iter/s, 17.7595s/100 iters), loss = 0.00173657
I0927 21:39:44.230532  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173682 (* 1 = 0.00173682 loss)
I0927 21:39:44.230540  3577 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0927 21:39:58.461359  3577 solver.cpp:218] Iteration 63100 (7.02702 iter/s, 14.2308s/100 iters), loss = 0.00258704
I0927 21:39:58.461401  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025873 (* 1 = 0.0025873 loss)
I0927 21:39:58.461407  3577 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0927 21:40:12.692718  3577 solver.cpp:218] Iteration 63200 (7.02678 iter/s, 14.2313s/100 iters), loss = 0.00440809
I0927 21:40:12.692809  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440835 (* 1 = 0.00440835 loss)
I0927 21:40:12.692826  3577 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0927 21:40:26.926365  3577 solver.cpp:218] Iteration 63300 (7.02567 iter/s, 14.2335s/100 iters), loss = 0.00238997
I0927 21:40:26.926407  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239023 (* 1 = 0.00239023 loss)
I0927 21:40:26.926414  3577 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0927 21:40:41.175246  3577 solver.cpp:218] Iteration 63400 (7.01814 iter/s, 14.2488s/100 iters), loss = 0.00108324
I0927 21:40:41.175287  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108349 (* 1 = 0.00108349 loss)
I0927 21:40:41.175293  3577 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0927 21:40:54.715167  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:40:55.284847  3577 solver.cpp:330] Iteration 63500, Testing net (#0)
I0927 21:40:58.655324  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:40:58.796360  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0927 21:40:58.796396  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348873 (* 1 = 0.348873 loss)
I0927 21:40:58.937479  3577 solver.cpp:218] Iteration 63500 (5.62995 iter/s, 17.7621s/100 iters), loss = 0.00273758
I0927 21:40:58.937506  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273783 (* 1 = 0.00273783 loss)
I0927 21:40:58.937513  3577 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0927 21:41:13.173447  3577 solver.cpp:218] Iteration 63600 (7.0245 iter/s, 14.2359s/100 iters), loss = 0.00249838
I0927 21:41:13.173490  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249864 (* 1 = 0.00249864 loss)
I0927 21:41:13.173496  3577 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0927 21:41:27.421000  3577 solver.cpp:218] Iteration 63700 (7.01879 iter/s, 14.2475s/100 iters), loss = 0.000913761
I0927 21:41:27.421104  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000914016 (* 1 = 0.000914016 loss)
I0927 21:41:27.421121  3577 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0927 21:41:41.658105  3577 solver.cpp:218] Iteration 63800 (7.02397 iter/s, 14.237s/100 iters), loss = 0.00556945
I0927 21:41:41.658135  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556971 (* 1 = 0.00556971 loss)
I0927 21:41:41.658141  3577 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0927 21:41:55.908149  3577 solver.cpp:218] Iteration 63900 (7.01756 iter/s, 14.25s/100 iters), loss = 0.00142246
I0927 21:41:55.908191  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142271 (* 1 = 0.00142271 loss)
I0927 21:41:55.908197  3577 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0927 21:42:09.446739  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:42:10.017555  3577 solver.cpp:330] Iteration 64000, Testing net (#0)
I0927 21:42:13.386940  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:42:13.528093  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0927 21:42:13.528131  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344758 (* 1 = 0.344758 loss)
I0927 21:42:13.669106  3577 solver.cpp:218] Iteration 64000 (5.63035 iter/s, 17.7609s/100 iters), loss = 0.00420343
I0927 21:42:13.669137  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420368 (* 1 = 0.00420368 loss)
I0927 21:42:13.669144  3577 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0927 21:42:27.909267  3577 solver.cpp:218] Iteration 64100 (7.02243 iter/s, 14.2401s/100 iters), loss = 0.00160088
I0927 21:42:27.909309  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160113 (* 1 = 0.00160113 loss)
I0927 21:42:27.909315  3577 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0927 21:42:42.146523  3577 solver.cpp:218] Iteration 64200 (7.02386 iter/s, 14.2372s/100 iters), loss = 0.0294554
I0927 21:42:42.146636  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294557 (* 1 = 0.0294557 loss)
I0927 21:42:42.146653  3577 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0927 21:42:56.383656  3577 solver.cpp:218] Iteration 64300 (7.02396 iter/s, 14.237s/100 iters), loss = 0.00893457
I0927 21:42:56.383697  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00893482 (* 1 = 0.00893482 loss)
I0927 21:42:56.383703  3577 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0927 21:43:10.628613  3577 solver.cpp:218] Iteration 64400 (7.02007 iter/s, 14.2449s/100 iters), loss = 0.00155095
I0927 21:43:10.628645  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155119 (* 1 = 0.00155119 loss)
I0927 21:43:10.628651  3577 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0927 21:43:24.163341  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:43:24.733918  3577 solver.cpp:330] Iteration 64500, Testing net (#0)
I0927 21:43:28.105608  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:43:28.246807  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I0927 21:43:28.246834  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343478 (* 1 = 0.343478 loss)
I0927 21:43:28.388530  3577 solver.cpp:218] Iteration 64500 (5.63068 iter/s, 17.7598s/100 iters), loss = 0.0225386
I0927 21:43:28.388559  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225389 (* 1 = 0.0225389 loss)
I0927 21:43:28.388566  3577 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0927 21:43:42.626022  3577 solver.cpp:218] Iteration 64600 (7.02374 iter/s, 14.2374s/100 iters), loss = 0.00144417
I0927 21:43:42.626054  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144442 (* 1 = 0.00144442 loss)
I0927 21:43:42.626060  3577 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0927 21:43:56.862182  3577 solver.cpp:218] Iteration 64700 (7.0244 iter/s, 14.2361s/100 iters), loss = 0.00353721
I0927 21:43:56.862319  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353746 (* 1 = 0.00353746 loss)
I0927 21:43:56.862340  3577 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0927 21:44:11.097018  3577 solver.cpp:218] Iteration 64800 (7.0251 iter/s, 14.2347s/100 iters), loss = 0.00345963
I0927 21:44:11.097050  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345989 (* 1 = 0.00345989 loss)
I0927 21:44:11.097056  3577 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0927 21:44:25.341254  3577 solver.cpp:218] Iteration 64900 (7.02042 iter/s, 14.2442s/100 iters), loss = 0.00354575
I0927 21:44:25.341286  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003546 (* 1 = 0.003546 loss)
I0927 21:44:25.341295  3577 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0927 21:44:38.875501  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:44:39.444490  3577 solver.cpp:330] Iteration 65000, Testing net (#0)
I0927 21:44:42.815047  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:44:42.955487  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I0927 21:44:42.955513  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359737 (* 1 = 0.359737 loss)
I0927 21:44:43.097591  3577 solver.cpp:218] Iteration 65000 (5.63182 iter/s, 17.7563s/100 iters), loss = 0.00125614
I0927 21:44:43.097622  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125638 (* 1 = 0.00125638 loss)
I0927 21:44:43.097630  3577 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0927 21:44:57.339956  3577 solver.cpp:218] Iteration 65100 (7.02134 iter/s, 14.2423s/100 iters), loss = 0.00129735
I0927 21:44:57.339998  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012976 (* 1 = 0.0012976 loss)
I0927 21:44:57.340004  3577 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0927 21:45:11.581055  3577 solver.cpp:218] Iteration 65200 (7.02197 iter/s, 14.241s/100 iters), loss = 0.00324958
I0927 21:45:11.581153  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324982 (* 1 = 0.00324982 loss)
I0927 21:45:11.581171  3577 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0927 21:45:25.819478  3577 solver.cpp:218] Iteration 65300 (7.02332 iter/s, 14.2383s/100 iters), loss = 0.00785141
I0927 21:45:25.819511  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785165 (* 1 = 0.00785165 loss)
I0927 21:45:25.819527  3577 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0927 21:45:40.061975  3577 solver.cpp:218] Iteration 65400 (7.02128 iter/s, 14.2424s/100 iters), loss = 0.00304408
I0927 21:45:40.062007  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304432 (* 1 = 0.00304432 loss)
I0927 21:45:40.062023  3577 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0927 21:45:53.592393  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:45:54.162394  3577 solver.cpp:330] Iteration 65500, Testing net (#0)
I0927 21:45:57.533138  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:45:57.674000  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I0927 21:45:57.674037  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376656 (* 1 = 0.376656 loss)
I0927 21:45:57.816320  3577 solver.cpp:218] Iteration 65500 (5.63245 iter/s, 17.7543s/100 iters), loss = 0.0167424
I0927 21:45:57.816352  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167427 (* 1 = 0.0167427 loss)
I0927 21:45:57.816359  3577 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0927 21:46:12.052363  3577 solver.cpp:218] Iteration 65600 (7.02446 iter/s, 14.236s/100 iters), loss = 0.00445539
I0927 21:46:12.052405  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445565 (* 1 = 0.00445565 loss)
I0927 21:46:12.052410  3577 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0927 21:46:26.288991  3577 solver.cpp:218] Iteration 65700 (7.02418 iter/s, 14.2365s/100 iters), loss = 0.0232667
I0927 21:46:26.289129  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023267 (* 1 = 0.023267 loss)
I0927 21:46:26.289139  3577 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0927 21:46:40.527770  3577 solver.cpp:218] Iteration 65800 (7.02316 iter/s, 14.2386s/100 iters), loss = 0.00150571
I0927 21:46:40.527812  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150596 (* 1 = 0.00150596 loss)
I0927 21:46:40.527817  3577 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0927 21:46:54.771530  3577 solver.cpp:218] Iteration 65900 (7.02066 iter/s, 14.2437s/100 iters), loss = 0.000786197
I0927 21:46:54.771569  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000786443 (* 1 = 0.000786443 loss)
I0927 21:46:54.771577  3577 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0927 21:47:08.302191  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:47:08.873008  3577 solver.cpp:330] Iteration 66000, Testing net (#0)
I0927 21:47:12.243135  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:47:12.384352  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I0927 21:47:12.384389  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351757 (* 1 = 0.351757 loss)
I0927 21:47:12.525879  3577 solver.cpp:218] Iteration 66000 (5.63245 iter/s, 17.7543s/100 iters), loss = 0.00113952
I0927 21:47:12.525909  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113977 (* 1 = 0.00113977 loss)
I0927 21:47:12.525916  3577 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0927 21:47:26.765753  3577 solver.cpp:218] Iteration 66100 (7.02257 iter/s, 14.2398s/100 iters), loss = 0.0323825
I0927 21:47:26.765794  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323828 (* 1 = 0.0323828 loss)
I0927 21:47:26.765800  3577 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0927 21:47:41.004277  3577 solver.cpp:218] Iteration 66200 (7.02324 iter/s, 14.2384s/100 iters), loss = 0.00255878
I0927 21:47:41.004384  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255902 (* 1 = 0.00255902 loss)
I0927 21:47:41.004391  3577 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0927 21:47:55.241760  3577 solver.cpp:218] Iteration 66300 (7.02379 iter/s, 14.2373s/100 iters), loss = 0.00230965
I0927 21:47:55.241802  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023099 (* 1 = 0.0023099 loss)
I0927 21:47:55.241808  3577 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0927 21:48:09.491735  3577 solver.cpp:218] Iteration 66400 (7.01759 iter/s, 14.2499s/100 iters), loss = 0.00266942
I0927 21:48:09.491777  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266967 (* 1 = 0.00266967 loss)
I0927 21:48:09.491783  3577 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0927 21:48:23.028105  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:48:23.598709  3577 solver.cpp:330] Iteration 66500, Testing net (#0)
I0927 21:48:26.969856  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:48:27.110749  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I0927 21:48:27.110785  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352776 (* 1 = 0.352776 loss)
I0927 21:48:27.252048  3577 solver.cpp:218] Iteration 66500 (5.63056 iter/s, 17.7602s/100 iters), loss = 0.00419623
I0927 21:48:27.252077  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419648 (* 1 = 0.00419648 loss)
I0927 21:48:27.252084  3577 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0927 21:48:41.492621  3577 solver.cpp:218] Iteration 66600 (7.02223 iter/s, 14.2405s/100 iters), loss = 0.00349643
I0927 21:48:41.492662  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349668 (* 1 = 0.00349668 loss)
I0927 21:48:41.492668  3577 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0927 21:48:55.733397  3577 solver.cpp:218] Iteration 66700 (7.02213 iter/s, 14.2407s/100 iters), loss = 0.00930158
I0927 21:48:55.733556  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00930182 (* 1 = 0.00930182 loss)
I0927 21:48:55.733566  3577 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0927 21:49:09.976135  3577 solver.cpp:218] Iteration 66800 (7.02122 iter/s, 14.2425s/100 iters), loss = 0.0108391
I0927 21:49:09.976177  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108394 (* 1 = 0.0108394 loss)
I0927 21:49:09.976182  3577 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0927 21:49:24.214254  3577 solver.cpp:218] Iteration 66900 (7.02344 iter/s, 14.238s/100 iters), loss = 0.00283827
I0927 21:49:24.214294  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283851 (* 1 = 0.00283851 loss)
I0927 21:49:24.214300  3577 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0927 21:49:37.751211  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:49:38.320686  3577 solver.cpp:330] Iteration 67000, Testing net (#0)
I0927 21:49:41.692895  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:49:41.834183  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I0927 21:49:41.834219  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336248 (* 1 = 0.336248 loss)
I0927 21:49:41.975322  3577 solver.cpp:218] Iteration 67000 (5.63032 iter/s, 17.761s/100 iters), loss = 0.0129977
I0927 21:49:41.975350  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012998 (* 1 = 0.012998 loss)
I0927 21:49:41.975356  3577 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0927 21:49:56.195356  3577 solver.cpp:218] Iteration 67100 (7.03236 iter/s, 14.22s/100 iters), loss = 0.00251802
I0927 21:49:56.195399  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251826 (* 1 = 0.00251826 loss)
I0927 21:49:56.195405  3577 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0927 21:50:10.424628  3577 solver.cpp:218] Iteration 67200 (7.02781 iter/s, 14.2292s/100 iters), loss = 0.00523838
I0927 21:50:10.424739  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523863 (* 1 = 0.00523863 loss)
I0927 21:50:10.424746  3577 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0927 21:50:24.659840  3577 solver.cpp:218] Iteration 67300 (7.0249 iter/s, 14.2351s/100 iters), loss = 0.0021681
I0927 21:50:24.659883  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216834 (* 1 = 0.00216834 loss)
I0927 21:50:24.659888  3577 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0927 21:50:38.888931  3577 solver.cpp:218] Iteration 67400 (7.0279 iter/s, 14.229s/100 iters), loss = 0.00243477
I0927 21:50:38.888962  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243502 (* 1 = 0.00243502 loss)
I0927 21:50:38.888978  3577 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0927 21:50:52.411530  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:50:52.981722  3577 solver.cpp:330] Iteration 67500, Testing net (#0)
I0927 21:50:56.354015  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:50:56.494881  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I0927 21:50:56.494917  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348167 (* 1 = 0.348167 loss)
I0927 21:50:56.636842  3577 solver.cpp:218] Iteration 67500 (5.63449 iter/s, 17.7478s/100 iters), loss = 0.000591853
I0927 21:50:56.636873  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000592097 (* 1 = 0.000592097 loss)
I0927 21:50:56.636879  3577 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0927 21:51:10.869074  3577 solver.cpp:218] Iteration 67600 (7.02634 iter/s, 14.2322s/100 iters), loss = 0.00282759
I0927 21:51:10.869105  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282783 (* 1 = 0.00282783 loss)
I0927 21:51:10.869112  3577 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0927 21:51:25.100479  3577 solver.cpp:218] Iteration 67700 (7.02675 iter/s, 14.2313s/100 iters), loss = 0.0221747
I0927 21:51:25.100636  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022175 (* 1 = 0.022175 loss)
I0927 21:51:25.100654  3577 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0927 21:51:39.327930  3577 solver.cpp:218] Iteration 67800 (7.02876 iter/s, 14.2273s/100 iters), loss = 0.00342406
I0927 21:51:39.327971  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034243 (* 1 = 0.0034243 loss)
I0927 21:51:39.327977  3577 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0927 21:51:53.562978  3577 solver.cpp:218] Iteration 67900 (7.02496 iter/s, 14.235s/100 iters), loss = 0.00285679
I0927 21:51:53.563009  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285703 (* 1 = 0.00285703 loss)
I0927 21:51:53.563014  3577 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0927 21:52:07.090358  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:52:07.661308  3577 solver.cpp:330] Iteration 68000, Testing net (#0)
I0927 21:52:11.033458  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:52:11.174079  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0927 21:52:11.174126  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350899 (* 1 = 0.350899 loss)
I0927 21:52:11.315528  3577 solver.cpp:218] Iteration 68000 (5.63302 iter/s, 17.7525s/100 iters), loss = 0.00816074
I0927 21:52:11.315559  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00816098 (* 1 = 0.00816098 loss)
I0927 21:52:11.315567  3577 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0927 21:52:25.546918  3577 solver.cpp:218] Iteration 68100 (7.02676 iter/s, 14.2313s/100 iters), loss = 0.00169065
I0927 21:52:25.546959  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169089 (* 1 = 0.00169089 loss)
I0927 21:52:25.546965  3577 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0927 21:52:39.780640  3577 solver.cpp:218] Iteration 68200 (7.02561 iter/s, 14.2336s/100 iters), loss = 0.00322186
I0927 21:52:39.780772  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032221 (* 1 = 0.0032221 loss)
I0927 21:52:39.780781  3577 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0927 21:52:54.013882  3577 solver.cpp:218] Iteration 68300 (7.02588 iter/s, 14.2331s/100 iters), loss = 0.00646112
I0927 21:52:54.013924  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00646136 (* 1 = 0.00646136 loss)
I0927 21:52:54.013931  3577 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0927 21:53:08.247171  3577 solver.cpp:218] Iteration 68400 (7.02582 iter/s, 14.2332s/100 iters), loss = 0.000561327
I0927 21:53:08.247202  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000561561 (* 1 = 0.000561561 loss)
I0927 21:53:08.247208  3577 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0927 21:53:21.771769  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:53:22.342135  3577 solver.cpp:330] Iteration 68500, Testing net (#0)
I0927 21:53:25.713110  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:53:25.854193  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0927 21:53:25.854229  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355648 (* 1 = 0.355648 loss)
I0927 21:53:25.996343  3577 solver.cpp:218] Iteration 68500 (5.63409 iter/s, 17.7491s/100 iters), loss = 0.00140453
I0927 21:53:25.996374  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140477 (* 1 = 0.00140477 loss)
I0927 21:53:25.996381  3577 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0927 21:53:40.227111  3577 solver.cpp:218] Iteration 68600 (7.02706 iter/s, 14.2307s/100 iters), loss = 0.00261322
I0927 21:53:40.227152  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261345 (* 1 = 0.00261345 loss)
I0927 21:53:40.227157  3577 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0927 21:53:54.465332  3577 solver.cpp:218] Iteration 68700 (7.02339 iter/s, 14.2381s/100 iters), loss = 0.00966564
I0927 21:53:54.465482  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00966587 (* 1 = 0.00966587 loss)
I0927 21:53:54.465500  3577 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0927 21:54:08.704958  3577 solver.cpp:218] Iteration 68800 (7.02275 iter/s, 14.2394s/100 iters), loss = 0.00974546
I0927 21:54:08.705001  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00974569 (* 1 = 0.00974569 loss)
I0927 21:54:08.705008  3577 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0927 21:54:22.941879  3577 solver.cpp:218] Iteration 68900 (7.02403 iter/s, 14.2368s/100 iters), loss = 0.0026094
I0927 21:54:22.941921  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260964 (* 1 = 0.00260964 loss)
I0927 21:54:22.941927  3577 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0927 21:54:36.469420  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:54:37.039527  3577 solver.cpp:330] Iteration 69000, Testing net (#0)
I0927 21:54:40.409814  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:54:40.551196  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.918
I0927 21:54:40.551234  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358052 (* 1 = 0.358052 loss)
I0927 21:54:40.692397  3577 solver.cpp:218] Iteration 69000 (5.63367 iter/s, 17.7504s/100 iters), loss = 0.00084686
I0927 21:54:40.692428  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000847101 (* 1 = 0.000847101 loss)
I0927 21:54:40.692435  3577 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0927 21:54:54.929338  3577 solver.cpp:218] Iteration 69100 (7.02402 iter/s, 14.2369s/100 iters), loss = 0.00253331
I0927 21:54:54.929380  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253355 (* 1 = 0.00253355 loss)
I0927 21:54:54.929386  3577 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0927 21:55:09.169667  3577 solver.cpp:218] Iteration 69200 (7.02235 iter/s, 14.2402s/100 iters), loss = 0.00382346
I0927 21:55:09.169790  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038237 (* 1 = 0.0038237 loss)
I0927 21:55:09.169798  3577 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0927 21:55:23.415515  3577 solver.cpp:218] Iteration 69300 (7.01966 iter/s, 14.2457s/100 iters), loss = 0.00322511
I0927 21:55:23.415556  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322535 (* 1 = 0.00322535 loss)
I0927 21:55:23.415562  3577 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0927 21:55:37.657711  3577 solver.cpp:218] Iteration 69400 (7.02143 iter/s, 14.2421s/100 iters), loss = 0.00316839
I0927 21:55:37.657753  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316863 (* 1 = 0.00316863 loss)
I0927 21:55:37.657758  3577 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0927 21:55:51.188598  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:55:51.759362  3577 solver.cpp:330] Iteration 69500, Testing net (#0)
I0927 21:55:55.131085  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:55:55.271754  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0927 21:55:55.271790  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356497 (* 1 = 0.356497 loss)
I0927 21:55:55.413110  3577 solver.cpp:218] Iteration 69500 (5.63212 iter/s, 17.7553s/100 iters), loss = 0.00206255
I0927 21:55:55.413139  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206279 (* 1 = 0.00206279 loss)
I0927 21:55:55.413146  3577 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0927 21:56:09.639127  3577 solver.cpp:218] Iteration 69600 (7.02941 iter/s, 14.2259s/100 iters), loss = 0.00367928
I0927 21:56:09.639168  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367953 (* 1 = 0.00367953 loss)
I0927 21:56:09.639173  3577 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0927 21:56:23.875432  3577 solver.cpp:218] Iteration 69700 (7.02433 iter/s, 14.2362s/100 iters), loss = 0.013474
I0927 21:56:23.875581  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134742 (* 1 = 0.0134742 loss)
I0927 21:56:23.875588  3577 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0927 21:56:38.104691  3577 solver.cpp:218] Iteration 69800 (7.02786 iter/s, 14.2291s/100 iters), loss = 0.0012455
I0927 21:56:38.104733  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124574 (* 1 = 0.00124574 loss)
I0927 21:56:38.104739  3577 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0927 21:56:52.340782  3577 solver.cpp:218] Iteration 69900 (7.02444 iter/s, 14.236s/100 iters), loss = 0.00391291
I0927 21:56:52.340813  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391315 (* 1 = 0.00391315 loss)
I0927 21:56:52.340818  3577 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0927 21:57:05.863867  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:57:06.433106  3577 solver.cpp:330] Iteration 70000, Testing net (#0)
I0927 21:57:09.806174  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:57:09.947520  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0927 21:57:09.947546  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343835 (* 1 = 0.343835 loss)
I0927 21:57:10.089493  3577 solver.cpp:218] Iteration 70000 (5.63424 iter/s, 17.7486s/100 iters), loss = 0.0178698
I0927 21:57:10.089524  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178701 (* 1 = 0.0178701 loss)
I0927 21:57:10.089530  3577 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0927 21:57:24.332159  3577 solver.cpp:218] Iteration 70100 (7.02119 iter/s, 14.2426s/100 iters), loss = 0.0031257
I0927 21:57:24.332200  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312594 (* 1 = 0.00312594 loss)
I0927 21:57:24.332206  3577 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0927 21:57:38.569844  3577 solver.cpp:218] Iteration 70200 (7.02365 iter/s, 14.2376s/100 iters), loss = 0.00198048
I0927 21:57:38.569947  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198072 (* 1 = 0.00198072 loss)
I0927 21:57:38.569954  3577 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0927 21:57:52.813771  3577 solver.cpp:218] Iteration 70300 (7.02061 iter/s, 14.2438s/100 iters), loss = 0.00152635
I0927 21:57:52.813802  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152659 (* 1 = 0.00152659 loss)
I0927 21:57:52.813808  3577 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0927 21:58:07.062626  3577 solver.cpp:218] Iteration 70400 (7.01814 iter/s, 14.2488s/100 iters), loss = 0.0006517
I0927 21:58:07.062659  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00065193 (* 1 = 0.00065193 loss)
I0927 21:58:07.062664  3577 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0927 21:58:20.598093  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:58:21.168534  3577 solver.cpp:330] Iteration 70500, Testing net (#0)
I0927 21:58:24.540364  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:58:24.681511  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0927 21:58:24.681548  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346548 (* 1 = 0.346548 loss)
I0927 21:58:24.823530  3577 solver.cpp:218] Iteration 70500 (5.63037 iter/s, 17.7608s/100 iters), loss = 0.00234817
I0927 21:58:24.823559  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234839 (* 1 = 0.00234839 loss)
I0927 21:58:24.823566  3577 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0927 21:58:39.058837  3577 solver.cpp:218] Iteration 70600 (7.02482 iter/s, 14.2352s/100 iters), loss = 0.00370127
I0927 21:58:39.058871  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037015 (* 1 = 0.0037015 loss)
I0927 21:58:39.058876  3577 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0927 21:58:53.299964  3577 solver.cpp:218] Iteration 70700 (7.02195 iter/s, 14.2411s/100 iters), loss = 0.00303996
I0927 21:58:53.300086  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304018 (* 1 = 0.00304018 loss)
I0927 21:58:53.300092  3577 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0927 21:59:07.539731  3577 solver.cpp:218] Iteration 70800 (7.02266 iter/s, 14.2396s/100 iters), loss = 0.00407779
I0927 21:59:07.539772  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407802 (* 1 = 0.00407802 loss)
I0927 21:59:07.539778  3577 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0927 21:59:21.787634  3577 solver.cpp:218] Iteration 70900 (7.01862 iter/s, 14.2478s/100 iters), loss = 0.000740504
I0927 21:59:21.787668  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00074073 (* 1 = 0.00074073 loss)
I0927 21:59:21.787675  3577 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0927 21:59:35.316211  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:59:35.886896  3577 solver.cpp:330] Iteration 71000, Testing net (#0)
I0927 21:59:39.258395  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 21:59:39.399425  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I0927 21:59:39.399461  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355882 (* 1 = 0.355882 loss)
I0927 21:59:39.540949  3577 solver.cpp:218] Iteration 71000 (5.63278 iter/s, 17.7532s/100 iters), loss = 0.00287528
I0927 21:59:39.540980  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287551 (* 1 = 0.00287551 loss)
I0927 21:59:39.540987  3577 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0927 21:59:53.775785  3577 solver.cpp:218] Iteration 71100 (7.02505 iter/s, 14.2348s/100 iters), loss = 0.00722832
I0927 21:59:53.775827  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00722854 (* 1 = 0.00722854 loss)
I0927 21:59:53.775833  3577 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0927 22:00:08.014672  3577 solver.cpp:218] Iteration 71200 (7.02306 iter/s, 14.2388s/100 iters), loss = 0.00150845
I0927 22:00:08.014745  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150867 (* 1 = 0.00150867 loss)
I0927 22:00:08.014752  3577 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0927 22:00:22.259312  3577 solver.cpp:218] Iteration 71300 (7.02024 iter/s, 14.2445s/100 iters), loss = 0.000829532
I0927 22:00:22.259353  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000829754 (* 1 = 0.000829754 loss)
I0927 22:00:22.259359  3577 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0927 22:00:36.499797  3577 solver.cpp:218] Iteration 71400 (7.02227 iter/s, 14.2404s/100 iters), loss = 0.00309701
I0927 22:00:36.499828  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309724 (* 1 = 0.00309724 loss)
I0927 22:00:36.499833  3577 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0927 22:00:50.032923  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:00:50.601649  3577 solver.cpp:330] Iteration 71500, Testing net (#0)
I0927 22:00:53.975787  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:00:54.116958  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0927 22:00:54.116994  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357905 (* 1 = 0.357905 loss)
I0927 22:00:54.257910  3577 solver.cpp:218] Iteration 71500 (5.63125 iter/s, 17.758s/100 iters), loss = 0.00460441
I0927 22:00:54.257939  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460463 (* 1 = 0.00460463 loss)
I0927 22:00:54.257946  3577 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0927 22:01:08.494648  3577 solver.cpp:218] Iteration 71600 (7.02412 iter/s, 14.2367s/100 iters), loss = 0.00282675
I0927 22:01:08.494679  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282698 (* 1 = 0.00282698 loss)
I0927 22:01:08.494684  3577 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0927 22:01:22.733016  3577 solver.cpp:218] Iteration 71700 (7.02331 iter/s, 14.2383s/100 iters), loss = 0.0137222
I0927 22:01:22.733142  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137224 (* 1 = 0.0137224 loss)
I0927 22:01:22.733150  3577 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0927 22:01:36.973887  3577 solver.cpp:218] Iteration 71800 (7.02212 iter/s, 14.2407s/100 iters), loss = 0.00520762
I0927 22:01:36.973929  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520784 (* 1 = 0.00520784 loss)
I0927 22:01:36.973935  3577 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0927 22:01:51.219069  3577 solver.cpp:218] Iteration 71900 (7.01996 iter/s, 14.2451s/100 iters), loss = 0.00342556
I0927 22:01:51.219111  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342578 (* 1 = 0.00342578 loss)
I0927 22:01:51.219117  3577 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0927 22:02:04.752831  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:02:05.322784  3577 solver.cpp:330] Iteration 72000, Testing net (#0)
I0927 22:02:08.694352  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:02:08.835680  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I0927 22:02:08.835716  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369265 (* 1 = 0.369265 loss)
I0927 22:02:08.977052  3577 solver.cpp:218] Iteration 72000 (5.6313 iter/s, 17.7579s/100 iters), loss = 0.00303943
I0927 22:02:08.977084  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303965 (* 1 = 0.00303965 loss)
I0927 22:02:08.977090  3577 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0927 22:02:23.199131  3577 solver.cpp:218] Iteration 72100 (7.03136 iter/s, 14.222s/100 iters), loss = 0.00137932
I0927 22:02:23.199174  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137955 (* 1 = 0.00137955 loss)
I0927 22:02:23.199180  3577 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0927 22:02:37.429765  3577 solver.cpp:218] Iteration 72200 (7.02713 iter/s, 14.2306s/100 iters), loss = 0.00179672
I0927 22:02:37.429900  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179695 (* 1 = 0.00179695 loss)
I0927 22:02:37.429909  3577 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0927 22:02:51.657325  3577 solver.cpp:218] Iteration 72300 (7.0287 iter/s, 14.2274s/100 iters), loss = 0.000734999
I0927 22:02:51.657367  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000735225 (* 1 = 0.000735225 loss)
I0927 22:02:51.657373  3577 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0927 22:03:05.892523  3577 solver.cpp:218] Iteration 72400 (7.02488 iter/s, 14.2351s/100 iters), loss = 0.00257862
I0927 22:03:05.892565  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257884 (* 1 = 0.00257884 loss)
I0927 22:03:05.892570  3577 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0927 22:03:19.415513  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:03:19.986318  3577 solver.cpp:330] Iteration 72500, Testing net (#0)
I0927 22:03:23.357996  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:03:23.498749  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I0927 22:03:23.498787  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370049 (* 1 = 0.370049 loss)
I0927 22:03:23.640157  3577 solver.cpp:218] Iteration 72500 (5.63458 iter/s, 17.7475s/100 iters), loss = 0.00530198
I0927 22:03:23.640188  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530221 (* 1 = 0.00530221 loss)
I0927 22:03:23.640194  3577 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0927 22:03:37.879910  3577 solver.cpp:218] Iteration 72600 (7.02263 iter/s, 14.2397s/100 iters), loss = 0.00260479
I0927 22:03:37.879952  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260502 (* 1 = 0.00260502 loss)
I0927 22:03:37.879958  3577 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0927 22:03:52.122225  3577 solver.cpp:218] Iteration 72700 (7.02137 iter/s, 14.2422s/100 iters), loss = 0.00160189
I0927 22:03:52.122370  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160211 (* 1 = 0.00160211 loss)
I0927 22:03:52.122377  3577 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0927 22:04:06.362731  3577 solver.cpp:218] Iteration 72800 (7.02231 iter/s, 14.2403s/100 iters), loss = 0.00179378
I0927 22:04:06.362773  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001794 (* 1 = 0.001794 loss)
I0927 22:04:06.362779  3577 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0927 22:04:20.597766  3577 solver.cpp:218] Iteration 72900 (7.02496 iter/s, 14.235s/100 iters), loss = 0.00361809
I0927 22:04:20.597810  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361832 (* 1 = 0.00361832 loss)
I0927 22:04:20.597815  3577 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0927 22:04:34.127019  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:04:34.698683  3577 solver.cpp:330] Iteration 73000, Testing net (#0)
I0927 22:04:38.071660  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:04:38.212601  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I0927 22:04:38.212638  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362669 (* 1 = 0.362669 loss)
I0927 22:04:38.354754  3577 solver.cpp:218] Iteration 73000 (5.63161 iter/s, 17.7569s/100 iters), loss = 0.013135
I0927 22:04:38.354785  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131352 (* 1 = 0.0131352 loss)
I0927 22:04:38.354792  3577 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0927 22:04:52.593374  3577 solver.cpp:218] Iteration 73100 (7.02319 iter/s, 14.2385s/100 iters), loss = 0.00502745
I0927 22:04:52.593405  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502768 (* 1 = 0.00502768 loss)
I0927 22:04:52.593411  3577 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0927 22:05:06.832548  3577 solver.cpp:218] Iteration 73200 (7.02291 iter/s, 14.2391s/100 iters), loss = 0.0113403
I0927 22:05:06.832650  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113406 (* 1 = 0.0113406 loss)
I0927 22:05:06.832657  3577 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0927 22:05:21.069284  3577 solver.cpp:218] Iteration 73300 (7.02415 iter/s, 14.2366s/100 iters), loss = 0.0033378
I0927 22:05:21.069325  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333802 (* 1 = 0.00333802 loss)
I0927 22:05:21.069331  3577 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0927 22:05:35.308820  3577 solver.cpp:218] Iteration 73400 (7.02274 iter/s, 14.2395s/100 iters), loss = 0.00194342
I0927 22:05:35.308863  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194364 (* 1 = 0.00194364 loss)
I0927 22:05:35.308869  3577 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0927 22:05:48.840868  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:05:49.410327  3577 solver.cpp:330] Iteration 73500, Testing net (#0)
I0927 22:05:52.783726  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:05:52.924751  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0927 22:05:52.924787  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343187 (* 1 = 0.343187 loss)
I0927 22:05:53.066978  3577 solver.cpp:218] Iteration 73500 (5.63124 iter/s, 17.7581s/100 iters), loss = 0.0128757
I0927 22:05:53.067010  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012876 (* 1 = 0.012876 loss)
I0927 22:05:53.067018  3577 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0927 22:06:07.310458  3577 solver.cpp:218] Iteration 73600 (7.02079 iter/s, 14.2434s/100 iters), loss = 0.00286243
I0927 22:06:07.310500  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286265 (* 1 = 0.00286265 loss)
I0927 22:06:07.310506  3577 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0927 22:06:21.550336  3577 solver.cpp:218] Iteration 73700 (7.02257 iter/s, 14.2398s/100 iters), loss = 0.000788595
I0927 22:06:21.550499  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000788817 (* 1 = 0.000788817 loss)
I0927 22:06:21.550508  3577 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0927 22:06:35.794749  3577 solver.cpp:218] Iteration 73800 (7.02039 iter/s, 14.2442s/100 iters), loss = 0.0043973
I0927 22:06:35.794780  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439752 (* 1 = 0.00439752 loss)
I0927 22:06:35.794786  3577 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0927 22:06:50.039369  3577 solver.cpp:218] Iteration 73900 (7.02023 iter/s, 14.2445s/100 iters), loss = 0.00110452
I0927 22:06:50.039412  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110474 (* 1 = 0.00110474 loss)
I0927 22:06:50.039417  3577 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0927 22:07:03.575228  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:07:04.144680  3577 solver.cpp:330] Iteration 74000, Testing net (#0)
I0927 22:07:07.518074  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:07:07.659226  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I0927 22:07:07.659263  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367861 (* 1 = 0.367861 loss)
I0927 22:07:07.800920  3577 solver.cpp:218] Iteration 74000 (5.63017 iter/s, 17.7615s/100 iters), loss = 0.00595496
I0927 22:07:07.800951  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595518 (* 1 = 0.00595518 loss)
I0927 22:07:07.800956  3577 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0927 22:07:22.043130  3577 solver.cpp:218] Iteration 74100 (7.02142 iter/s, 14.2421s/100 iters), loss = 0.00171774
I0927 22:07:22.043160  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171796 (* 1 = 0.00171796 loss)
I0927 22:07:22.043166  3577 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0927 22:07:36.284442  3577 solver.cpp:218] Iteration 74200 (7.02186 iter/s, 14.2412s/100 iters), loss = 0.00186134
I0927 22:07:36.284548  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186156 (* 1 = 0.00186156 loss)
I0927 22:07:36.284554  3577 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0927 22:07:50.528982  3577 solver.cpp:218] Iteration 74300 (7.0203 iter/s, 14.2444s/100 iters), loss = 0.00606436
I0927 22:07:50.529026  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00606458 (* 1 = 0.00606458 loss)
I0927 22:07:50.529031  3577 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0927 22:08:04.771221  3577 solver.cpp:218] Iteration 74400 (7.02141 iter/s, 14.2422s/100 iters), loss = 0.0044798
I0927 22:08:04.771253  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448003 (* 1 = 0.00448003 loss)
I0927 22:08:04.771260  3577 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0927 22:08:18.307809  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:08:18.878609  3577 solver.cpp:330] Iteration 74500, Testing net (#0)
I0927 22:08:22.251816  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:08:22.392617  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I0927 22:08:22.392655  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391817 (* 1 = 0.391817 loss)
I0927 22:08:22.534698  3577 solver.cpp:218] Iteration 74500 (5.62955 iter/s, 17.7634s/100 iters), loss = 0.00106739
I0927 22:08:22.534730  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106762 (* 1 = 0.00106762 loss)
I0927 22:08:22.534737  3577 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0927 22:08:36.766101  3577 solver.cpp:218] Iteration 74600 (7.02675 iter/s, 14.2313s/100 iters), loss = 0.0291085
I0927 22:08:36.766132  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291087 (* 1 = 0.0291087 loss)
I0927 22:08:36.766139  3577 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0927 22:08:50.998339  3577 solver.cpp:218] Iteration 74700 (7.02634 iter/s, 14.2322s/100 iters), loss = 0.0103072
I0927 22:08:50.998456  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103074 (* 1 = 0.0103074 loss)
I0927 22:08:50.998464  3577 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0927 22:09:05.236805  3577 solver.cpp:218] Iteration 74800 (7.0233 iter/s, 14.2383s/100 iters), loss = 0.00144888
I0927 22:09:05.236845  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144911 (* 1 = 0.00144911 loss)
I0927 22:09:05.236851  3577 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0927 22:09:19.470140  3577 solver.cpp:218] Iteration 74900 (7.0258 iter/s, 14.2333s/100 iters), loss = 0.000740913
I0927 22:09:19.470172  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000741147 (* 1 = 0.000741147 loss)
I0927 22:09:19.470178  3577 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0927 22:09:32.997978  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:09:33.568200  3577 solver.cpp:330] Iteration 75000, Testing net (#0)
I0927 22:09:36.942189  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:09:37.082890  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0927 22:09:37.082927  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344853 (* 1 = 0.344853 loss)
I0927 22:09:37.224428  3577 solver.cpp:218] Iteration 75000 (5.63247 iter/s, 17.7542s/100 iters), loss = 0.0011663
I0927 22:09:37.224460  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116653 (* 1 = 0.00116653 loss)
I0927 22:09:37.224467  3577 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0927 22:09:51.465850  3577 solver.cpp:218] Iteration 75100 (7.0218 iter/s, 14.2414s/100 iters), loss = 0.00114005
I0927 22:09:51.465893  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114028 (* 1 = 0.00114028 loss)
I0927 22:09:51.465898  3577 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0927 22:10:05.713752  3577 solver.cpp:218] Iteration 75200 (7.01862 iter/s, 14.2478s/100 iters), loss = 0.000378532
I0927 22:10:05.713826  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000378767 (* 1 = 0.000378767 loss)
I0927 22:10:05.713834  3577 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0927 22:10:19.959568  3577 solver.cpp:218] Iteration 75300 (7.01966 iter/s, 14.2457s/100 iters), loss = 0.00516951
I0927 22:10:19.959611  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00516974 (* 1 = 0.00516974 loss)
I0927 22:10:19.959617  3577 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0927 22:10:34.210614  3577 solver.cpp:218] Iteration 75400 (7.01707 iter/s, 14.251s/100 iters), loss = 0.00207831
I0927 22:10:34.210647  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207855 (* 1 = 0.00207855 loss)
I0927 22:10:34.210654  3577 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0927 22:10:47.752614  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:10:48.323824  3577 solver.cpp:330] Iteration 75500, Testing net (#0)
I0927 22:10:51.696877  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:10:51.837872  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0927 22:10:51.837908  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347615 (* 1 = 0.347615 loss)
I0927 22:10:51.979631  3577 solver.cpp:218] Iteration 75500 (5.6278 iter/s, 17.7689s/100 iters), loss = 0.00435924
I0927 22:10:51.979663  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435947 (* 1 = 0.00435947 loss)
I0927 22:10:51.979671  3577 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0927 22:11:06.223392  3577 solver.cpp:218] Iteration 75600 (7.02065 iter/s, 14.2437s/100 iters), loss = 0.00709724
I0927 22:11:06.223433  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00709748 (* 1 = 0.00709748 loss)
I0927 22:11:06.223439  3577 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0927 22:11:20.466032  3577 solver.cpp:218] Iteration 75700 (7.02121 iter/s, 14.2426s/100 iters), loss = 0.00150029
I0927 22:11:20.466199  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150053 (* 1 = 0.00150053 loss)
I0927 22:11:20.466207  3577 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0927 22:11:34.711977  3577 solver.cpp:218] Iteration 75800 (7.01963 iter/s, 14.2458s/100 iters), loss = 0.00787482
I0927 22:11:34.712019  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00787506 (* 1 = 0.00787506 loss)
I0927 22:11:34.712025  3577 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0927 22:11:48.956670  3577 solver.cpp:218] Iteration 75900 (7.0202 iter/s, 14.2446s/100 iters), loss = 0.00139912
I0927 22:11:48.956712  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139936 (* 1 = 0.00139936 loss)
I0927 22:11:48.956718  3577 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0927 22:12:02.496670  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:12:03.066329  3577 solver.cpp:330] Iteration 76000, Testing net (#0)
I0927 22:12:06.438213  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:12:06.579234  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I0927 22:12:06.579262  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372508 (* 1 = 0.372508 loss)
I0927 22:12:06.720492  3577 solver.cpp:218] Iteration 76000 (5.62945 iter/s, 17.7637s/100 iters), loss = 0.0014316
I0927 22:12:06.720525  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143184 (* 1 = 0.00143184 loss)
I0927 22:12:06.720531  3577 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0927 22:12:20.954130  3577 solver.cpp:218] Iteration 76100 (7.02565 iter/s, 14.2336s/100 iters), loss = 0.00506256
I0927 22:12:20.954172  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050628 (* 1 = 0.0050628 loss)
I0927 22:12:20.954179  3577 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0927 22:12:35.195489  3577 solver.cpp:218] Iteration 76200 (7.02184 iter/s, 14.2413s/100 iters), loss = 0.0013155
I0927 22:12:35.195616  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131574 (* 1 = 0.00131574 loss)
I0927 22:12:35.195623  3577 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0927 22:12:49.433784  3577 solver.cpp:218] Iteration 76300 (7.02339 iter/s, 14.2381s/100 iters), loss = 0.0173194
I0927 22:12:49.433825  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173196 (* 1 = 0.0173196 loss)
I0927 22:12:49.433830  3577 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0927 22:13:03.668463  3577 solver.cpp:218] Iteration 76400 (7.02514 iter/s, 14.2346s/100 iters), loss = 0.0204128
I0927 22:13:03.668495  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020413 (* 1 = 0.020413 loss)
I0927 22:13:03.668501  3577 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0927 22:13:17.200176  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:13:17.770464  3577 solver.cpp:330] Iteration 76500, Testing net (#0)
I0927 22:13:21.142369  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:13:21.283223  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I0927 22:13:21.283260  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370006 (* 1 = 0.370006 loss)
I0927 22:13:21.424547  3577 solver.cpp:218] Iteration 76500 (5.6319 iter/s, 17.756s/100 iters), loss = 0.00820711
I0927 22:13:21.424578  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00820735 (* 1 = 0.00820735 loss)
I0927 22:13:21.424585  3577 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0927 22:13:35.669657  3577 solver.cpp:218] Iteration 76600 (7.01999 iter/s, 14.245s/100 iters), loss = 0.00897453
I0927 22:13:35.669689  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00897478 (* 1 = 0.00897478 loss)
I0927 22:13:35.669695  3577 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0927 22:13:49.915485  3577 solver.cpp:218] Iteration 76700 (7.01963 iter/s, 14.2458s/100 iters), loss = 0.000783306
I0927 22:13:49.915580  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000783559 (* 1 = 0.000783559 loss)
I0927 22:13:49.915588  3577 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0927 22:14:04.162704  3577 solver.cpp:218] Iteration 76800 (7.01898 iter/s, 14.2471s/100 iters), loss = 0.00156706
I0927 22:14:04.162736  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156731 (* 1 = 0.00156731 loss)
I0927 22:14:04.162744  3577 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0927 22:14:18.413311  3577 solver.cpp:218] Iteration 76900 (7.01728 iter/s, 14.2505s/100 iters), loss = 0.00281599
I0927 22:14:18.413341  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281623 (* 1 = 0.00281623 loss)
I0927 22:14:18.413357  3577 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0927 22:14:31.954581  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:14:32.525105  3577 solver.cpp:330] Iteration 77000, Testing net (#0)
I0927 22:14:35.898697  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:14:36.039484  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I0927 22:14:36.039520  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376106 (* 1 = 0.376106 loss)
I0927 22:14:36.180688  3577 solver.cpp:218] Iteration 77000 (5.62832 iter/s, 17.7673s/100 iters), loss = 0.00474963
I0927 22:14:36.180718  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474987 (* 1 = 0.00474987 loss)
I0927 22:14:36.180725  3577 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0927 22:14:50.414876  3577 solver.cpp:218] Iteration 77100 (7.02537 iter/s, 14.2341s/100 iters), loss = 0.00743822
I0927 22:14:50.414918  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00743846 (* 1 = 0.00743846 loss)
I0927 22:14:50.414924  3577 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0927 22:15:04.652324  3577 solver.cpp:218] Iteration 77200 (7.02377 iter/s, 14.2374s/100 iters), loss = 0.00137524
I0927 22:15:04.652454  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137548 (* 1 = 0.00137548 loss)
I0927 22:15:04.652462  3577 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0927 22:15:18.883273  3577 solver.cpp:218] Iteration 77300 (7.02701 iter/s, 14.2308s/100 iters), loss = 0.00429258
I0927 22:15:18.883306  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429282 (* 1 = 0.00429282 loss)
I0927 22:15:18.883311  3577 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0927 22:15:33.121111  3577 solver.cpp:218] Iteration 77400 (7.02357 iter/s, 14.2378s/100 iters), loss = 0.000449082
I0927 22:15:33.121153  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000449318 (* 1 = 0.000449318 loss)
I0927 22:15:33.121158  3577 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0927 22:15:46.647856  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:15:47.217792  3577 solver.cpp:330] Iteration 77500, Testing net (#0)
I0927 22:15:50.590313  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:15:50.731437  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I0927 22:15:50.731473  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387052 (* 1 = 0.387052 loss)
I0927 22:15:50.872797  3577 solver.cpp:218] Iteration 77500 (5.6333 iter/s, 17.7516s/100 iters), loss = 0.000681411
I0927 22:15:50.872825  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00068165 (* 1 = 0.00068165 loss)
I0927 22:15:50.872833  3577 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0927 22:16:05.112011  3577 solver.cpp:218] Iteration 77600 (7.02289 iter/s, 14.2391s/100 iters), loss = 0.00973213
I0927 22:16:05.112043  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00973236 (* 1 = 0.00973236 loss)
I0927 22:16:05.112059  3577 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0927 22:16:19.356706  3577 solver.cpp:218] Iteration 77700 (7.02019 iter/s, 14.2446s/100 iters), loss = 0.00950203
I0927 22:16:19.356845  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00950227 (* 1 = 0.00950227 loss)
I0927 22:16:19.356863  3577 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0927 22:16:33.600591  3577 solver.cpp:218] Iteration 77800 (7.02064 iter/s, 14.2437s/100 iters), loss = 0.00261233
I0927 22:16:33.600622  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261257 (* 1 = 0.00261257 loss)
I0927 22:16:33.600627  3577 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0927 22:16:47.843348  3577 solver.cpp:218] Iteration 77900 (7.02115 iter/s, 14.2427s/100 iters), loss = 0.0148874
I0927 22:16:47.843379  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148876 (* 1 = 0.0148876 loss)
I0927 22:16:47.843395  3577 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0927 22:17:01.377032  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:17:01.948508  3577 solver.cpp:330] Iteration 78000, Testing net (#0)
I0927 22:17:05.319144  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:17:05.460201  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I0927 22:17:05.460237  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351837 (* 1 = 0.351837 loss)
I0927 22:17:05.602448  3577 solver.cpp:218] Iteration 78000 (5.63094 iter/s, 17.759s/100 iters), loss = 0.0130361
I0927 22:17:05.602480  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130364 (* 1 = 0.0130364 loss)
I0927 22:17:05.602488  3577 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0927 22:17:19.835928  3577 solver.cpp:218] Iteration 78100 (7.02572 iter/s, 14.2334s/100 iters), loss = 0.000815961
I0927 22:17:19.835970  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000816196 (* 1 = 0.000816196 loss)
I0927 22:17:19.835976  3577 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0927 22:17:34.082588  3577 solver.cpp:218] Iteration 78200 (7.01923 iter/s, 14.2466s/100 iters), loss = 0.00220517
I0927 22:17:34.082686  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022054 (* 1 = 0.0022054 loss)
I0927 22:17:34.082695  3577 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0927 22:17:48.326248  3577 solver.cpp:218] Iteration 78300 (7.02073 iter/s, 14.2435s/100 iters), loss = 0.000428261
I0927 22:17:48.326287  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000428499 (* 1 = 0.000428499 loss)
I0927 22:17:48.326293  3577 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0927 22:18:02.573096  3577 solver.cpp:218] Iteration 78400 (7.01913 iter/s, 14.2468s/100 iters), loss = 0.00177582
I0927 22:18:02.573139  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177605 (* 1 = 0.00177605 loss)
I0927 22:18:02.573144  3577 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0927 22:18:16.107038  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:18:16.676664  3577 solver.cpp:330] Iteration 78500, Testing net (#0)
I0927 22:18:20.050261  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:18:20.191237  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I0927 22:18:20.191273  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363954 (* 1 = 0.363954 loss)
I0927 22:18:20.332653  3577 solver.cpp:218] Iteration 78500 (5.6308 iter/s, 17.7595s/100 iters), loss = 0.00181768
I0927 22:18:20.332684  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181792 (* 1 = 0.00181792 loss)
I0927 22:18:20.332690  3577 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0927 22:18:34.577431  3577 solver.cpp:218] Iteration 78600 (7.02015 iter/s, 14.2447s/100 iters), loss = 0.00542994
I0927 22:18:34.577464  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543018 (* 1 = 0.00543018 loss)
I0927 22:18:34.577471  3577 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0927 22:18:48.823809  3577 solver.cpp:218] Iteration 78700 (7.01936 iter/s, 14.2463s/100 iters), loss = 0.0202659
I0927 22:18:48.823966  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202661 (* 1 = 0.0202661 loss)
I0927 22:18:48.823984  3577 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0927 22:19:03.077846  3577 solver.cpp:218] Iteration 78800 (7.01565 iter/s, 14.2539s/100 iters), loss = 0.00363393
I0927 22:19:03.077879  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363417 (* 1 = 0.00363417 loss)
I0927 22:19:03.077886  3577 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0927 22:19:17.329042  3577 solver.cpp:218] Iteration 78900 (7.01699 iter/s, 14.2511s/100 iters), loss = 0.000955563
I0927 22:19:17.329084  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000955803 (* 1 = 0.000955803 loss)
I0927 22:19:17.329090  3577 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0927 22:19:30.868157  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:19:31.439157  3577 solver.cpp:330] Iteration 79000, Testing net (#0)
I0927 22:19:34.809783  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:19:34.950894  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I0927 22:19:34.950932  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38677 (* 1 = 0.38677 loss)
I0927 22:19:35.092681  3577 solver.cpp:218] Iteration 79000 (5.6295 iter/s, 17.7636s/100 iters), loss = 0.00528223
I0927 22:19:35.092712  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00528247 (* 1 = 0.00528247 loss)
I0927 22:19:35.092720  3577 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0927 22:19:49.330148  3577 solver.cpp:218] Iteration 79100 (7.02376 iter/s, 14.2374s/100 iters), loss = 0.000631554
I0927 22:19:49.330190  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000631801 (* 1 = 0.000631801 loss)
I0927 22:19:49.330196  3577 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0927 22:20:03.572798  3577 solver.cpp:218] Iteration 79200 (7.02121 iter/s, 14.2426s/100 iters), loss = 0.00281673
I0927 22:20:03.572903  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281697 (* 1 = 0.00281697 loss)
I0927 22:20:03.572921  3577 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0927 22:20:17.806669  3577 solver.cpp:218] Iteration 79300 (7.02556 iter/s, 14.2337s/100 iters), loss = 0.0104174
I0927 22:20:17.806699  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104176 (* 1 = 0.0104176 loss)
I0927 22:20:17.806704  3577 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0927 22:20:32.049099  3577 solver.cpp:218] Iteration 79400 (7.02131 iter/s, 14.2424s/100 iters), loss = 0.00320198
I0927 22:20:32.049136  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320222 (* 1 = 0.00320222 loss)
I0927 22:20:32.049144  3577 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0927 22:20:45.582084  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:20:46.151250  3577 solver.cpp:330] Iteration 79500, Testing net (#0)
I0927 22:20:49.524384  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:20:49.665364  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I0927 22:20:49.665400  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3923 (* 1 = 0.3923 loss)
I0927 22:20:49.806762  3577 solver.cpp:218] Iteration 79500 (5.6314 iter/s, 17.7576s/100 iters), loss = 0.00582384
I0927 22:20:49.806793  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00582408 (* 1 = 0.00582408 loss)
I0927 22:20:49.806800  3577 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0927 22:21:04.055248  3577 solver.cpp:218] Iteration 79600 (7.01833 iter/s, 14.2484s/100 iters), loss = 0.0106503
I0927 22:21:04.055279  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106505 (* 1 = 0.0106505 loss)
I0927 22:21:04.055284  3577 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0927 22:21:18.300772  3577 solver.cpp:218] Iteration 79700 (7.01978 iter/s, 14.2455s/100 iters), loss = 0.00442694
I0927 22:21:18.300899  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442718 (* 1 = 0.00442718 loss)
I0927 22:21:18.300916  3577 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0927 22:21:32.546386  3577 solver.cpp:218] Iteration 79800 (7.01979 iter/s, 14.2454s/100 iters), loss = 0.00106079
I0927 22:21:32.546427  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106103 (* 1 = 0.00106103 loss)
I0927 22:21:32.546433  3577 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0927 22:21:46.801092  3577 solver.cpp:218] Iteration 79900 (7.01527 iter/s, 14.2546s/100 iters), loss = 0.00532585
I0927 22:21:46.801134  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053261 (* 1 = 0.0053261 loss)
I0927 22:21:46.801141  3577 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0927 22:22:00.337901  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:22:00.908545  3577 solver.cpp:330] Iteration 80000, Testing net (#0)
I0927 22:22:04.279494  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:22:04.420940  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9076
I0927 22:22:04.420979  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.4196 (* 1 = 0.4196 loss)
I0927 22:22:04.562252  3577 solver.cpp:218] Iteration 80000 (5.63029 iter/s, 17.7611s/100 iters), loss = 0.0078975
I0927 22:22:04.562284  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00789775 (* 1 = 0.00789775 loss)
I0927 22:22:04.562290  3577 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0927 22:22:04.562294  3577 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0927 22:22:18.799815  3577 solver.cpp:218] Iteration 80100 (7.02371 iter/s, 14.2375s/100 iters), loss = 0.00277601
I0927 22:22:18.799862  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277625 (* 1 = 0.00277625 loss)
I0927 22:22:18.799870  3577 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0927 22:22:33.042085  3577 solver.cpp:218] Iteration 80200 (7.0214 iter/s, 14.2422s/100 iters), loss = 0.00832473
I0927 22:22:33.042188  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00832498 (* 1 = 0.00832498 loss)
I0927 22:22:33.042196  3577 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0927 22:22:47.283639  3577 solver.cpp:218] Iteration 80300 (7.02178 iter/s, 14.2414s/100 iters), loss = 0.000582485
I0927 22:22:47.283670  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000582736 (* 1 = 0.000582736 loss)
I0927 22:22:47.283676  3577 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0927 22:23:01.526499  3577 solver.cpp:218] Iteration 80400 (7.0211 iter/s, 14.2428s/100 iters), loss = 0.00170865
I0927 22:23:01.526553  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017089 (* 1 = 0.0017089 loss)
I0927 22:23:01.526561  3577 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0927 22:23:15.063436  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:23:15.633481  3577 solver.cpp:330] Iteration 80500, Testing net (#0)
I0927 22:23:19.006027  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:23:19.147166  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0927 22:23:19.147202  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347172 (* 1 = 0.347172 loss)
I0927 22:23:19.288642  3577 solver.cpp:218] Iteration 80500 (5.62998 iter/s, 17.7621s/100 iters), loss = 0.000274473
I0927 22:23:19.288673  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00027473 (* 1 = 0.00027473 loss)
I0927 22:23:19.288679  3577 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0927 22:23:33.531229  3577 solver.cpp:218] Iteration 80600 (7.02123 iter/s, 14.2425s/100 iters), loss = 0.000820963
I0927 22:23:33.531270  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000821221 (* 1 = 0.000821221 loss)
I0927 22:23:33.531276  3577 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0927 22:23:47.771958  3577 solver.cpp:218] Iteration 80700 (7.02215 iter/s, 14.2406s/100 iters), loss = 0.00251768
I0927 22:23:47.772091  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251794 (* 1 = 0.00251794 loss)
I0927 22:23:47.772099  3577 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0927 22:24:02.014116  3577 solver.cpp:218] Iteration 80800 (7.02149 iter/s, 14.242s/100 iters), loss = 0.000779254
I0927 22:24:02.014147  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000779516 (* 1 = 0.000779516 loss)
I0927 22:24:02.014153  3577 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0927 22:24:16.255389  3577 solver.cpp:218] Iteration 80900 (7.02188 iter/s, 14.2412s/100 iters), loss = 0.00573223
I0927 22:24:16.255431  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057325 (* 1 = 0.0057325 loss)
I0927 22:24:16.255437  3577 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0927 22:24:29.790570  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:24:30.361382  3577 solver.cpp:330] Iteration 81000, Testing net (#0)
I0927 22:24:33.735093  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:24:33.876327  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0927 22:24:33.876363  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339469 (* 1 = 0.339469 loss)
I0927 22:24:34.018309  3577 solver.cpp:218] Iteration 81000 (5.62973 iter/s, 17.7628s/100 iters), loss = 0.000589963
I0927 22:24:34.018340  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000590227 (* 1 = 0.000590227 loss)
I0927 22:24:34.018347  3577 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0927 22:24:48.248332  3577 solver.cpp:218] Iteration 81100 (7.02743 iter/s, 14.23s/100 iters), loss = 0.000793056
I0927 22:24:48.248374  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000793321 (* 1 = 0.000793321 loss)
I0927 22:24:48.248380  3577 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0927 22:25:02.479830  3577 solver.cpp:218] Iteration 81200 (7.02671 iter/s, 14.2314s/100 iters), loss = 0.00143628
I0927 22:25:02.479938  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143654 (* 1 = 0.00143654 loss)
I0927 22:25:02.479945  3577 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0927 22:25:16.713323  3577 solver.cpp:218] Iteration 81300 (7.02575 iter/s, 14.2333s/100 iters), loss = 0.000821784
I0927 22:25:16.713364  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000822049 (* 1 = 0.000822049 loss)
I0927 22:25:16.713371  3577 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0927 22:25:30.943764  3577 solver.cpp:218] Iteration 81400 (7.02723 iter/s, 14.2304s/100 iters), loss = 0.00188851
I0927 22:25:30.943807  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188878 (* 1 = 0.00188878 loss)
I0927 22:25:30.943814  3577 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0927 22:25:44.475045  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:25:45.044178  3577 solver.cpp:330] Iteration 81500, Testing net (#0)
I0927 22:25:48.416414  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:25:48.557124  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0927 22:25:48.557162  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33637 (* 1 = 0.33637 loss)
I0927 22:25:48.698678  3577 solver.cpp:218] Iteration 81500 (5.63227 iter/s, 17.7548s/100 iters), loss = 0.000675034
I0927 22:25:48.698707  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0006753 (* 1 = 0.0006753 loss)
I0927 22:25:48.698714  3577 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0927 22:26:02.934939  3577 solver.cpp:218] Iteration 81600 (7.02435 iter/s, 14.2362s/100 iters), loss = 0.00410984
I0927 22:26:02.934980  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411011 (* 1 = 0.00411011 loss)
I0927 22:26:02.934986  3577 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0927 22:26:17.173750  3577 solver.cpp:218] Iteration 81700 (7.0231 iter/s, 14.2387s/100 iters), loss = 0.00374148
I0927 22:26:17.173859  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374174 (* 1 = 0.00374174 loss)
I0927 22:26:17.173877  3577 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0927 22:26:31.412184  3577 solver.cpp:218] Iteration 81800 (7.02331 iter/s, 14.2383s/100 iters), loss = 0.000167387
I0927 22:26:31.412225  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00016765 (* 1 = 0.00016765 loss)
I0927 22:26:31.412231  3577 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0927 22:26:45.649834  3577 solver.cpp:218] Iteration 81900 (7.02367 iter/s, 14.2376s/100 iters), loss = 0.000659961
I0927 22:26:45.649876  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000660226 (* 1 = 0.000660226 loss)
I0927 22:26:45.649883  3577 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0927 22:26:59.179044  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:26:59.749373  3577 solver.cpp:330] Iteration 82000, Testing net (#0)
I0927 22:27:03.122197  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:27:03.263648  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0927 22:27:03.263684  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333305 (* 1 = 0.333305 loss)
I0927 22:27:03.405243  3577 solver.cpp:218] Iteration 82000 (5.63211 iter/s, 17.7553s/100 iters), loss = 0.00817219
I0927 22:27:03.405272  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00817246 (* 1 = 0.00817246 loss)
I0927 22:27:03.405278  3577 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0927 22:27:17.632606  3577 solver.cpp:218] Iteration 82100 (7.02874 iter/s, 14.2273s/100 iters), loss = 0.000691557
I0927 22:27:17.632645  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000691823 (* 1 = 0.000691823 loss)
I0927 22:27:17.632652  3577 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0927 22:27:31.860699  3577 solver.cpp:218] Iteration 82200 (7.02839 iter/s, 14.228s/100 iters), loss = 0.000561603
I0927 22:27:31.860815  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000561867 (* 1 = 0.000561867 loss)
I0927 22:27:31.860821  3577 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0927 22:27:46.089911  3577 solver.cpp:218] Iteration 82300 (7.02787 iter/s, 14.2291s/100 iters), loss = 0.00044531
I0927 22:27:46.089953  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000445574 (* 1 = 0.000445574 loss)
I0927 22:27:46.089958  3577 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0927 22:28:00.329990  3577 solver.cpp:218] Iteration 82400 (7.02247 iter/s, 14.24s/100 iters), loss = 0.000857156
I0927 22:28:00.330029  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000857422 (* 1 = 0.000857422 loss)
I0927 22:28:00.330036  3577 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0927 22:28:13.858144  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:28:14.427310  3577 solver.cpp:330] Iteration 82500, Testing net (#0)
I0927 22:28:17.801141  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:28:17.942229  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0927 22:28:17.942266  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335488 (* 1 = 0.335488 loss)
I0927 22:28:18.084002  3577 solver.cpp:218] Iteration 82500 (5.63256 iter/s, 17.7539s/100 iters), loss = 0.00274989
I0927 22:28:18.084033  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275015 (* 1 = 0.00275015 loss)
I0927 22:28:18.084040  3577 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0927 22:28:32.318789  3577 solver.cpp:218] Iteration 82600 (7.02508 iter/s, 14.2347s/100 iters), loss = 0.00362106
I0927 22:28:32.318820  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362131 (* 1 = 0.00362131 loss)
I0927 22:28:32.318826  3577 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0927 22:28:46.564440  3577 solver.cpp:218] Iteration 82700 (7.01972 iter/s, 14.2456s/100 iters), loss = 0.00156832
I0927 22:28:46.564571  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156858 (* 1 = 0.00156858 loss)
I0927 22:28:46.564590  3577 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0927 22:29:00.813596  3577 solver.cpp:218] Iteration 82800 (7.01804 iter/s, 14.249s/100 iters), loss = 0.0011309
I0927 22:29:00.813627  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113115 (* 1 = 0.00113115 loss)
I0927 22:29:00.813642  3577 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0927 22:29:15.049937  3577 solver.cpp:218] Iteration 82900 (7.02431 iter/s, 14.2363s/100 iters), loss = 0.000350803
I0927 22:29:15.049969  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000351055 (* 1 = 0.000351055 loss)
I0927 22:29:15.049974  3577 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0927 22:29:28.579268  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:29:29.149037  3577 solver.cpp:330] Iteration 83000, Testing net (#0)
I0927 22:29:32.521906  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:29:32.662689  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0927 22:29:32.662726  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334961 (* 1 = 0.334961 loss)
I0927 22:29:32.804708  3577 solver.cpp:218] Iteration 83000 (5.63231 iter/s, 17.7547s/100 iters), loss = 0.00232232
I0927 22:29:32.804739  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232257 (* 1 = 0.00232257 loss)
I0927 22:29:32.804747  3577 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0927 22:29:47.038348  3577 solver.cpp:218] Iteration 83100 (7.02564 iter/s, 14.2336s/100 iters), loss = 0.000526539
I0927 22:29:47.038391  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00052679 (* 1 = 0.00052679 loss)
I0927 22:29:47.038398  3577 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0927 22:30:01.276115  3577 solver.cpp:218] Iteration 83200 (7.02361 iter/s, 14.2377s/100 iters), loss = 0.00266411
I0927 22:30:01.276248  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266436 (* 1 = 0.00266436 loss)
I0927 22:30:01.276257  3577 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0927 22:30:15.506098  3577 solver.cpp:218] Iteration 83300 (7.02749 iter/s, 14.2298s/100 iters), loss = 0.00020848
I0927 22:30:15.506140  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00020873 (* 1 = 0.00020873 loss)
I0927 22:30:15.506146  3577 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0927 22:30:29.739284  3577 solver.cpp:218] Iteration 83400 (7.02587 iter/s, 14.2331s/100 iters), loss = 0.00206971
I0927 22:30:29.739326  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206996 (* 1 = 0.00206996 loss)
I0927 22:30:29.739331  3577 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0927 22:30:43.268227  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:30:43.838944  3577 solver.cpp:330] Iteration 83500, Testing net (#0)
I0927 22:30:47.209729  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:30:47.350994  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0927 22:30:47.351037  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333816 (* 1 = 0.333816 loss)
I0927 22:30:47.492413  3577 solver.cpp:218] Iteration 83500 (5.63284 iter/s, 17.753s/100 iters), loss = 0.000643443
I0927 22:30:47.492444  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00064369 (* 1 = 0.00064369 loss)
I0927 22:30:47.492451  3577 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0927 22:31:01.724336  3577 solver.cpp:218] Iteration 83600 (7.02649 iter/s, 14.2319s/100 iters), loss = 0.0010592
I0927 22:31:01.724378  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105944 (* 1 = 0.00105944 loss)
I0927 22:31:01.724385  3577 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0927 22:31:15.963683  3577 solver.cpp:218] Iteration 83700 (7.02283 iter/s, 14.2393s/100 iters), loss = 0.00695215
I0927 22:31:15.963817  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695239 (* 1 = 0.00695239 loss)
I0927 22:31:15.963835  3577 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0927 22:31:30.205785  3577 solver.cpp:218] Iteration 83800 (7.02151 iter/s, 14.2419s/100 iters), loss = 0.000673711
I0927 22:31:30.205827  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000673955 (* 1 = 0.000673955 loss)
I0927 22:31:30.205833  3577 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0927 22:31:44.451346  3577 solver.cpp:218] Iteration 83900 (7.01977 iter/s, 14.2455s/100 iters), loss = 0.000459185
I0927 22:31:44.451386  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000459429 (* 1 = 0.000459429 loss)
I0927 22:31:44.451392  3577 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0927 22:31:57.983417  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:31:58.552307  3577 solver.cpp:330] Iteration 84000, Testing net (#0)
I0927 22:32:01.925794  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:32:02.066756  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0927 22:32:02.066792  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333148 (* 1 = 0.333148 loss)
I0927 22:32:02.208411  3577 solver.cpp:218] Iteration 84000 (5.63159 iter/s, 17.757s/100 iters), loss = 0.000407564
I0927 22:32:02.208442  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000407809 (* 1 = 0.000407809 loss)
I0927 22:32:02.208449  3577 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0927 22:32:16.456171  3577 solver.cpp:218] Iteration 84100 (7.01868 iter/s, 14.2477s/100 iters), loss = 0.000579003
I0927 22:32:16.456212  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000579248 (* 1 = 0.000579248 loss)
I0927 22:32:16.456218  3577 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0927 22:32:30.703310  3577 solver.cpp:218] Iteration 84200 (7.01899 iter/s, 14.2471s/100 iters), loss = 0.00190356
I0927 22:32:30.703394  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190381 (* 1 = 0.00190381 loss)
I0927 22:32:30.703410  3577 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0927 22:32:44.952323  3577 solver.cpp:218] Iteration 84300 (7.01809 iter/s, 14.2489s/100 iters), loss = 0.00073357
I0927 22:32:44.952364  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000733813 (* 1 = 0.000733813 loss)
I0927 22:32:44.952370  3577 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0927 22:32:59.193648  3577 solver.cpp:218] Iteration 84400 (7.02186 iter/s, 14.2412s/100 iters), loss = 0.00170111
I0927 22:32:59.193689  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170136 (* 1 = 0.00170136 loss)
I0927 22:32:59.193696  3577 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0927 22:33:12.731974  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:33:13.302836  3577 solver.cpp:330] Iteration 84500, Testing net (#0)
I0927 22:33:16.674193  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:33:16.815197  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0927 22:33:16.815234  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333284 (* 1 = 0.333284 loss)
I0927 22:33:16.957382  3577 solver.cpp:218] Iteration 84500 (5.62947 iter/s, 17.7636s/100 iters), loss = 0.0123339
I0927 22:33:16.957412  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123341 (* 1 = 0.0123341 loss)
I0927 22:33:16.957418  3577 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0927 22:33:31.200603  3577 solver.cpp:218] Iteration 84600 (7.02092 iter/s, 14.2431s/100 iters), loss = 0.00301263
I0927 22:33:31.200644  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301288 (* 1 = 0.00301288 loss)
I0927 22:33:31.200650  3577 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0927 22:33:45.437988  3577 solver.cpp:218] Iteration 84700 (7.0238 iter/s, 14.2373s/100 iters), loss = 0.00134931
I0927 22:33:45.438107  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134955 (* 1 = 0.00134955 loss)
I0927 22:33:45.438115  3577 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0927 22:33:59.680950  3577 solver.cpp:218] Iteration 84800 (7.02109 iter/s, 14.2428s/100 iters), loss = 0.000538187
I0927 22:33:59.680982  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00053843 (* 1 = 0.00053843 loss)
I0927 22:33:59.680989  3577 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0927 22:34:13.921550  3577 solver.cpp:218] Iteration 84900 (7.02221 iter/s, 14.2405s/100 iters), loss = 0.00156003
I0927 22:34:13.921581  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156027 (* 1 = 0.00156027 loss)
I0927 22:34:13.921597  3577 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0927 22:34:27.452544  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:34:28.022891  3577 solver.cpp:330] Iteration 85000, Testing net (#0)
I0927 22:34:31.394637  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:34:31.535744  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0927 22:34:31.535771  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333805 (* 1 = 0.333805 loss)
I0927 22:34:31.676997  3577 solver.cpp:218] Iteration 85000 (5.6321 iter/s, 17.7554s/100 iters), loss = 0.000585001
I0927 22:34:31.677029  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000585242 (* 1 = 0.000585242 loss)
I0927 22:34:31.677037  3577 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0927 22:34:45.909991  3577 solver.cpp:218] Iteration 85100 (7.02596 iter/s, 14.2329s/100 iters), loss = 0.00173879
I0927 22:34:45.910033  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173903 (* 1 = 0.00173903 loss)
I0927 22:34:45.910039  3577 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0927 22:35:00.146205  3577 solver.cpp:218] Iteration 85200 (7.02438 iter/s, 14.2361s/100 iters), loss = 0.020171
I0927 22:35:00.146337  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201713 (* 1 = 0.0201713 loss)
I0927 22:35:00.146353  3577 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0927 22:35:14.381703  3577 solver.cpp:218] Iteration 85300 (7.02478 iter/s, 14.2353s/100 iters), loss = 0.00075943
I0927 22:35:14.381747  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00075967 (* 1 = 0.00075967 loss)
I0927 22:35:14.381752  3577 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0927 22:35:28.618419  3577 solver.cpp:218] Iteration 85400 (7.02413 iter/s, 14.2366s/100 iters), loss = 0.000937358
I0927 22:35:28.618461  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000937597 (* 1 = 0.000937597 loss)
I0927 22:35:28.618468  3577 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0927 22:35:42.142150  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:35:42.712651  3577 solver.cpp:330] Iteration 85500, Testing net (#0)
I0927 22:35:46.083241  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:35:46.224419  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0927 22:35:46.224447  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332651 (* 1 = 0.332651 loss)
I0927 22:35:46.365914  3577 solver.cpp:218] Iteration 85500 (5.63463 iter/s, 17.7474s/100 iters), loss = 0.000481381
I0927 22:35:46.365943  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00048162 (* 1 = 0.00048162 loss)
I0927 22:35:46.365950  3577 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0927 22:36:00.606349  3577 solver.cpp:218] Iteration 85600 (7.02229 iter/s, 14.2404s/100 iters), loss = 0.0011713
I0927 22:36:00.606391  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117154 (* 1 = 0.00117154 loss)
I0927 22:36:00.606396  3577 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0927 22:36:14.838011  3577 solver.cpp:218] Iteration 85700 (7.02663 iter/s, 14.2316s/100 iters), loss = 0.000611333
I0927 22:36:14.838105  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000611574 (* 1 = 0.000611574 loss)
I0927 22:36:14.838122  3577 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0927 22:36:29.076148  3577 solver.cpp:218] Iteration 85800 (7.02346 iter/s, 14.238s/100 iters), loss = 0.00155589
I0927 22:36:29.076179  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155613 (* 1 = 0.00155613 loss)
I0927 22:36:29.076184  3577 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0927 22:36:43.313088  3577 solver.cpp:218] Iteration 85900 (7.02401 iter/s, 14.2369s/100 iters), loss = 0.00229514
I0927 22:36:43.313118  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229538 (* 1 = 0.00229538 loss)
I0927 22:36:43.313124  3577 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0927 22:36:56.843226  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:36:57.412529  3577 solver.cpp:330] Iteration 86000, Testing net (#0)
I0927 22:37:00.785202  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:37:00.925969  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0927 22:37:00.925997  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334554 (* 1 = 0.334554 loss)
I0927 22:37:01.067576  3577 solver.cpp:218] Iteration 86000 (5.6324 iter/s, 17.7544s/100 iters), loss = 0.00110341
I0927 22:37:01.067607  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110365 (* 1 = 0.00110365 loss)
I0927 22:37:01.067613  3577 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0927 22:37:15.298218  3577 solver.cpp:218] Iteration 86100 (7.02712 iter/s, 14.2306s/100 iters), loss = 0.00133263
I0927 22:37:15.298249  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133287 (* 1 = 0.00133287 loss)
I0927 22:37:15.298254  3577 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0927 22:37:29.539654  3577 solver.cpp:218] Iteration 86200 (7.0218 iter/s, 14.2414s/100 iters), loss = 0.00206136
I0927 22:37:29.539811  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020616 (* 1 = 0.0020616 loss)
I0927 22:37:29.539819  3577 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0927 22:37:43.778189  3577 solver.cpp:218] Iteration 86300 (7.02329 iter/s, 14.2383s/100 iters), loss = 0.00108968
I0927 22:37:43.778232  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108992 (* 1 = 0.00108992 loss)
I0927 22:37:43.778239  3577 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0927 22:37:58.017478  3577 solver.cpp:218] Iteration 86400 (7.02286 iter/s, 14.2392s/100 iters), loss = 0.00126086
I0927 22:37:58.017520  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012611 (* 1 = 0.0012611 loss)
I0927 22:37:58.017525  3577 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0927 22:38:11.554005  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:38:12.123252  3577 solver.cpp:330] Iteration 86500, Testing net (#0)
I0927 22:38:15.495048  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:38:15.636209  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0927 22:38:15.636236  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333237 (* 1 = 0.333237 loss)
I0927 22:38:15.777318  3577 solver.cpp:218] Iteration 86500 (5.63071 iter/s, 17.7598s/100 iters), loss = 0.000627465
I0927 22:38:15.777348  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000627707 (* 1 = 0.000627707 loss)
I0927 22:38:15.777355  3577 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0927 22:38:30.006705  3577 solver.cpp:218] Iteration 86600 (7.02775 iter/s, 14.2293s/100 iters), loss = 0.0056876
I0927 22:38:30.006747  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568784 (* 1 = 0.00568784 loss)
I0927 22:38:30.006753  3577 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0927 22:38:44.249974  3577 solver.cpp:218] Iteration 86700 (7.0209 iter/s, 14.2432s/100 iters), loss = 0.00279475
I0927 22:38:44.250093  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279499 (* 1 = 0.00279499 loss)
I0927 22:38:44.250102  3577 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0927 22:38:58.488231  3577 solver.cpp:218] Iteration 86800 (7.02341 iter/s, 14.2381s/100 iters), loss = 0.00133913
I0927 22:38:58.488273  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133937 (* 1 = 0.00133937 loss)
I0927 22:38:58.488279  3577 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0927 22:39:12.730509  3577 solver.cpp:218] Iteration 86900 (7.02139 iter/s, 14.2422s/100 iters), loss = 0.000558361
I0927 22:39:12.730543  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000558599 (* 1 = 0.000558599 loss)
I0927 22:39:12.730550  3577 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0927 22:39:26.262661  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:39:26.833681  3577 solver.cpp:330] Iteration 87000, Testing net (#0)
I0927 22:39:30.204835  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:39:30.345933  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0927 22:39:30.345962  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33314 (* 1 = 0.33314 loss)
I0927 22:39:30.487996  3577 solver.cpp:218] Iteration 87000 (5.63145 iter/s, 17.7574s/100 iters), loss = 0.000281784
I0927 22:39:30.488025  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00028202 (* 1 = 0.00028202 loss)
I0927 22:39:30.488032  3577 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0927 22:39:44.713263  3577 solver.cpp:218] Iteration 87100 (7.02978 iter/s, 14.2252s/100 iters), loss = 0.00147645
I0927 22:39:44.713305  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147669 (* 1 = 0.00147669 loss)
I0927 22:39:44.713311  3577 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0927 22:39:58.940696  3577 solver.cpp:218] Iteration 87200 (7.02872 iter/s, 14.2274s/100 iters), loss = 0.000997937
I0927 22:39:58.940763  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000998174 (* 1 = 0.000998174 loss)
I0927 22:39:58.940770  3577 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0927 22:40:13.173733  3577 solver.cpp:218] Iteration 87300 (7.02596 iter/s, 14.2329s/100 iters), loss = 0.0049432
I0927 22:40:13.173775  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00494344 (* 1 = 0.00494344 loss)
I0927 22:40:13.173780  3577 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0927 22:40:27.409034  3577 solver.cpp:218] Iteration 87400 (7.02483 iter/s, 14.2352s/100 iters), loss = 0.000406709
I0927 22:40:27.409076  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000406945 (* 1 = 0.000406945 loss)
I0927 22:40:27.409082  3577 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0927 22:40:40.934532  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:40:41.503988  3577 solver.cpp:330] Iteration 87500, Testing net (#0)
I0927 22:40:44.876232  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:40:45.017174  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0927 22:40:45.017202  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33318 (* 1 = 0.33318 loss)
I0927 22:40:45.158411  3577 solver.cpp:218] Iteration 87500 (5.63403 iter/s, 17.7493s/100 iters), loss = 0.000200277
I0927 22:40:45.158440  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000200513 (* 1 = 0.000200513 loss)
I0927 22:40:45.158448  3577 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0927 22:40:59.394599  3577 solver.cpp:218] Iteration 87600 (7.02439 iter/s, 14.2361s/100 iters), loss = 0.00414826
I0927 22:40:59.394640  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414849 (* 1 = 0.00414849 loss)
I0927 22:40:59.394646  3577 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0927 22:41:13.634135  3577 solver.cpp:218] Iteration 87700 (7.02274 iter/s, 14.2395s/100 iters), loss = 0.00511446
I0927 22:41:13.634223  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051147 (* 1 = 0.0051147 loss)
I0927 22:41:13.634230  3577 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0927 22:41:27.875000  3577 solver.cpp:218] Iteration 87800 (7.02211 iter/s, 14.2407s/100 iters), loss = 0.002257
I0927 22:41:27.875041  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225723 (* 1 = 0.00225723 loss)
I0927 22:41:27.875046  3577 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0927 22:41:42.111410  3577 solver.cpp:218] Iteration 87900 (7.02428 iter/s, 14.2363s/100 iters), loss = 0.0015399
I0927 22:41:42.111441  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154014 (* 1 = 0.00154014 loss)
I0927 22:41:42.111448  3577 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0927 22:41:55.643128  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:41:56.213574  3577 solver.cpp:330] Iteration 88000, Testing net (#0)
I0927 22:41:59.585736  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:41:59.726970  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0927 22:41:59.727007  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333351 (* 1 = 0.333351 loss)
I0927 22:41:59.868149  3577 solver.cpp:218] Iteration 88000 (5.63169 iter/s, 17.7567s/100 iters), loss = 0.000384749
I0927 22:41:59.868180  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000384987 (* 1 = 0.000384987 loss)
I0927 22:41:59.868185  3577 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0927 22:42:14.096343  3577 solver.cpp:218] Iteration 88100 (7.02833 iter/s, 14.2281s/100 iters), loss = 0.000677046
I0927 22:42:14.096374  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000677285 (* 1 = 0.000677285 loss)
I0927 22:42:14.096380  3577 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0927 22:42:28.326444  3577 solver.cpp:218] Iteration 88200 (7.02739 iter/s, 14.23s/100 iters), loss = 0.00157409
I0927 22:42:28.326557  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157433 (* 1 = 0.00157433 loss)
I0927 22:42:28.326565  3577 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0927 22:42:42.561583  3577 solver.cpp:218] Iteration 88300 (7.02494 iter/s, 14.235s/100 iters), loss = 0.00103516
I0927 22:42:42.561616  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010354 (* 1 = 0.0010354 loss)
I0927 22:42:42.561621  3577 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0927 22:42:56.795017  3577 solver.cpp:218] Iteration 88400 (7.02575 iter/s, 14.2334s/100 iters), loss = 0.00114956
I0927 22:42:56.795049  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011498 (* 1 = 0.0011498 loss)
I0927 22:42:56.795055  3577 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0927 22:43:10.319638  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:43:10.889875  3577 solver.cpp:330] Iteration 88500, Testing net (#0)
I0927 22:43:14.263154  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:43:14.403992  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0927 22:43:14.404018  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332623 (* 1 = 0.332623 loss)
I0927 22:43:14.545491  3577 solver.cpp:218] Iteration 88500 (5.63368 iter/s, 17.7504s/100 iters), loss = 0.00125557
I0927 22:43:14.545521  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125581 (* 1 = 0.00125581 loss)
I0927 22:43:14.545527  3577 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0927 22:43:28.787390  3577 solver.cpp:218] Iteration 88600 (7.02157 iter/s, 14.2418s/100 iters), loss = 0.00062252
I0927 22:43:28.787422  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000622761 (* 1 = 0.000622761 loss)
I0927 22:43:28.787438  3577 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0927 22:43:43.026055  3577 solver.cpp:218] Iteration 88700 (7.02316 iter/s, 14.2386s/100 iters), loss = 0.00211347
I0927 22:43:43.026175  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211371 (* 1 = 0.00211371 loss)
I0927 22:43:43.026182  3577 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0927 22:43:57.263511  3577 solver.cpp:218] Iteration 88800 (7.02381 iter/s, 14.2373s/100 iters), loss = 0.000383379
I0927 22:43:57.263552  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00038362 (* 1 = 0.00038362 loss)
I0927 22:43:57.263558  3577 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0927 22:44:11.503715  3577 solver.cpp:218] Iteration 88900 (7.02241 iter/s, 14.2401s/100 iters), loss = 0.000691784
I0927 22:44:11.503747  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000692023 (* 1 = 0.000692023 loss)
I0927 22:44:11.503752  3577 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0927 22:44:25.033814  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:44:25.603466  3577 solver.cpp:330] Iteration 89000, Testing net (#0)
I0927 22:44:28.977995  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:44:29.118994  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0927 22:44:29.119030  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332803 (* 1 = 0.332803 loss)
I0927 22:44:29.261503  3577 solver.cpp:218] Iteration 89000 (5.63136 iter/s, 17.7577s/100 iters), loss = 0.00249903
I0927 22:44:29.261534  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249927 (* 1 = 0.00249927 loss)
I0927 22:44:29.261541  3577 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0927 22:44:43.495617  3577 solver.cpp:218] Iteration 89100 (7.02541 iter/s, 14.234s/100 iters), loss = 0.00154655
I0927 22:44:43.495658  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154679 (* 1 = 0.00154679 loss)
I0927 22:44:43.495664  3577 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0927 22:44:57.734467  3577 solver.cpp:218] Iteration 89200 (7.02308 iter/s, 14.2388s/100 iters), loss = 0.00349114
I0927 22:44:57.734575  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349138 (* 1 = 0.00349138 loss)
I0927 22:44:57.734594  3577 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0927 22:45:11.977007  3577 solver.cpp:218] Iteration 89300 (7.02129 iter/s, 14.2424s/100 iters), loss = 0.00066489
I0927 22:45:11.977051  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000665132 (* 1 = 0.000665132 loss)
I0927 22:45:11.977056  3577 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0927 22:45:26.216918  3577 solver.cpp:218] Iteration 89400 (7.02256 iter/s, 14.2398s/100 iters), loss = 0.00062113
I0927 22:45:26.216960  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000621372 (* 1 = 0.000621372 loss)
I0927 22:45:26.216966  3577 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0927 22:45:39.749665  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:45:40.320049  3577 solver.cpp:330] Iteration 89500, Testing net (#0)
I0927 22:45:43.691870  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:45:43.833036  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0927 22:45:43.833073  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333737 (* 1 = 0.333737 loss)
I0927 22:45:43.974529  3577 solver.cpp:218] Iteration 89500 (5.63142 iter/s, 17.7575s/100 iters), loss = 0.000154475
I0927 22:45:43.974560  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000154716 (* 1 = 0.000154716 loss)
I0927 22:45:43.974566  3577 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0927 22:45:58.215104  3577 solver.cpp:218] Iteration 89600 (7.02222 iter/s, 14.2405s/100 iters), loss = 0.00128469
I0927 22:45:58.215145  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128493 (* 1 = 0.00128493 loss)
I0927 22:45:58.215152  3577 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0927 22:46:12.459364  3577 solver.cpp:218] Iteration 89700 (7.02041 iter/s, 14.2442s/100 iters), loss = 0.000586998
I0927 22:46:12.459476  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000587237 (* 1 = 0.000587237 loss)
I0927 22:46:12.459492  3577 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0927 22:46:26.694742  3577 solver.cpp:218] Iteration 89800 (7.02482 iter/s, 14.2352s/100 iters), loss = 0.002549
I0927 22:46:26.694773  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254924 (* 1 = 0.00254924 loss)
I0927 22:46:26.694779  3577 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0927 22:46:40.927192  3577 solver.cpp:218] Iteration 89900 (7.02623 iter/s, 14.2324s/100 iters), loss = 0.00125609
I0927 22:46:40.927235  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125633 (* 1 = 0.00125633 loss)
I0927 22:46:40.927242  3577 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0927 22:46:54.452416  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:46:55.022195  3577 solver.cpp:330] Iteration 90000, Testing net (#0)
I0927 22:46:58.394088  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:46:58.534942  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0927 22:46:58.534981  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333962 (* 1 = 0.333962 loss)
I0927 22:46:58.676692  3577 solver.cpp:218] Iteration 90000 (5.63399 iter/s, 17.7494s/100 iters), loss = 0.000200861
I0927 22:46:58.676723  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000201102 (* 1 = 0.000201102 loss)
I0927 22:46:58.676729  3577 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0927 22:47:12.919309  3577 solver.cpp:218] Iteration 90100 (7.02121 iter/s, 14.2426s/100 iters), loss = 0.00197118
I0927 22:47:12.919351  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197142 (* 1 = 0.00197142 loss)
I0927 22:47:12.919358  3577 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0927 22:47:27.164628  3577 solver.cpp:218] Iteration 90200 (7.01989 iter/s, 14.2452s/100 iters), loss = 0.00239952
I0927 22:47:27.164783  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239976 (* 1 = 0.00239976 loss)
I0927 22:47:27.164791  3577 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0927 22:47:41.406934  3577 solver.cpp:218] Iteration 90300 (7.02143 iter/s, 14.2421s/100 iters), loss = 0.00076128
I0927 22:47:41.406976  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000761519 (* 1 = 0.000761519 loss)
I0927 22:47:41.406981  3577 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0927 22:47:55.656042  3577 solver.cpp:218] Iteration 90400 (7.01802 iter/s, 14.249s/100 iters), loss = 0.000579447
I0927 22:47:55.656083  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000579685 (* 1 = 0.000579685 loss)
I0927 22:47:55.656090  3577 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0927 22:48:09.197847  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:48:09.768134  3577 solver.cpp:330] Iteration 90500, Testing net (#0)
I0927 22:48:13.138931  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:48:13.279897  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0927 22:48:13.279923  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335099 (* 1 = 0.335099 loss)
I0927 22:48:13.421422  3577 solver.cpp:218] Iteration 90500 (5.62895 iter/s, 17.7653s/100 iters), loss = 0.000977708
I0927 22:48:13.421454  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000977947 (* 1 = 0.000977947 loss)
I0927 22:48:13.421460  3577 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0927 22:48:27.655177  3577 solver.cpp:218] Iteration 90600 (7.02561 iter/s, 14.2336s/100 iters), loss = 0.00208479
I0927 22:48:27.655208  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208503 (* 1 = 0.00208503 loss)
I0927 22:48:27.655213  3577 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0927 22:48:41.899066  3577 solver.cpp:218] Iteration 90700 (7.02059 iter/s, 14.2438s/100 iters), loss = 0.000895735
I0927 22:48:41.899152  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000895974 (* 1 = 0.000895974 loss)
I0927 22:48:41.899168  3577 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0927 22:48:56.142923  3577 solver.cpp:218] Iteration 90800 (7.02063 iter/s, 14.2437s/100 iters), loss = 0.000244398
I0927 22:48:56.142954  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000244637 (* 1 = 0.000244637 loss)
I0927 22:48:56.142971  3577 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0927 22:49:10.381897  3577 solver.cpp:218] Iteration 90900 (7.02301 iter/s, 14.2389s/100 iters), loss = 0.00226192
I0927 22:49:10.381929  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226216 (* 1 = 0.00226216 loss)
I0927 22:49:10.381945  3577 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0927 22:49:23.917170  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:49:24.486224  3577 solver.cpp:330] Iteration 91000, Testing net (#0)
I0927 22:49:27.856149  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:49:27.997339  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0927 22:49:27.997365  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335405 (* 1 = 0.335405 loss)
I0927 22:49:28.139699  3577 solver.cpp:218] Iteration 91000 (5.63135 iter/s, 17.7577s/100 iters), loss = 0.000438016
I0927 22:49:28.139729  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000438254 (* 1 = 0.000438254 loss)
I0927 22:49:28.139736  3577 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0927 22:49:42.377545  3577 solver.cpp:218] Iteration 91100 (7.02357 iter/s, 14.2378s/100 iters), loss = 0.000449496
I0927 22:49:42.377585  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000449732 (* 1 = 0.000449732 loss)
I0927 22:49:42.377591  3577 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0927 22:49:56.620770  3577 solver.cpp:218] Iteration 91200 (7.02092 iter/s, 14.2431s/100 iters), loss = 0.000925576
I0927 22:49:56.620909  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000925812 (* 1 = 0.000925812 loss)
I0927 22:49:56.620918  3577 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0927 22:50:10.866210  3577 solver.cpp:218] Iteration 91300 (7.01988 iter/s, 14.2453s/100 iters), loss = 0.00316749
I0927 22:50:10.866252  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316773 (* 1 = 0.00316773 loss)
I0927 22:50:10.866258  3577 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0927 22:50:25.105542  3577 solver.cpp:218] Iteration 91400 (7.02284 iter/s, 14.2393s/100 iters), loss = 0.000711365
I0927 22:50:25.105583  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000711602 (* 1 = 0.000711602 loss)
I0927 22:50:25.105589  3577 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0927 22:50:38.644448  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:50:39.214778  3577 solver.cpp:330] Iteration 91500, Testing net (#0)
I0927 22:50:42.585757  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:50:42.726682  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0927 22:50:42.726709  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33538 (* 1 = 0.33538 loss)
I0927 22:50:42.867959  3577 solver.cpp:218] Iteration 91500 (5.62989 iter/s, 17.7623s/100 iters), loss = 0.000650768
I0927 22:50:42.867990  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000651005 (* 1 = 0.000651005 loss)
I0927 22:50:42.867996  3577 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0927 22:50:57.093484  3577 solver.cpp:218] Iteration 91600 (7.02965 iter/s, 14.2255s/100 iters), loss = 0.00153632
I0927 22:50:57.093526  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153655 (* 1 = 0.00153655 loss)
I0927 22:50:57.093533  3577 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0927 22:51:11.333439  3577 solver.cpp:218] Iteration 91700 (7.02253 iter/s, 14.2399s/100 iters), loss = 0.00130996
I0927 22:51:11.333566  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013102 (* 1 = 0.0013102 loss)
I0927 22:51:11.333575  3577 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0927 22:51:25.569916  3577 solver.cpp:218] Iteration 91800 (7.02429 iter/s, 14.2363s/100 iters), loss = 0.000969159
I0927 22:51:25.569947  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000969393 (* 1 = 0.000969393 loss)
I0927 22:51:25.569953  3577 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0927 22:51:39.804747  3577 solver.cpp:218] Iteration 91900 (7.02506 iter/s, 14.2348s/100 iters), loss = 0.000431766
I0927 22:51:39.804780  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000431999 (* 1 = 0.000431999 loss)
I0927 22:51:39.804795  3577 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0927 22:51:53.333931  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:51:53.902942  3577 solver.cpp:330] Iteration 92000, Testing net (#0)
I0927 22:51:57.272545  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:51:57.413244  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0927 22:51:57.413280  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334251 (* 1 = 0.334251 loss)
I0927 22:51:57.555272  3577 solver.cpp:218] Iteration 92000 (5.63366 iter/s, 17.7505s/100 iters), loss = 0.000936501
I0927 22:51:57.555304  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000936735 (* 1 = 0.000936735 loss)
I0927 22:51:57.555310  3577 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0927 22:52:11.794288  3577 solver.cpp:218] Iteration 92100 (7.02299 iter/s, 14.2389s/100 iters), loss = 0.00457688
I0927 22:52:11.794329  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457712 (* 1 = 0.00457712 loss)
I0927 22:52:11.794335  3577 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0927 22:52:26.028234  3577 solver.cpp:218] Iteration 92200 (7.0255 iter/s, 14.2339s/100 iters), loss = 0.000943241
I0927 22:52:26.028295  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000943476 (* 1 = 0.000943476 loss)
I0927 22:52:26.028301  3577 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0927 22:52:40.263947  3577 solver.cpp:218] Iteration 92300 (7.02464 iter/s, 14.2356s/100 iters), loss = 0.00136321
I0927 22:52:40.263978  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136344 (* 1 = 0.00136344 loss)
I0927 22:52:40.263983  3577 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0927 22:52:54.503892  3577 solver.cpp:218] Iteration 92400 (7.02253 iter/s, 14.2399s/100 iters), loss = 0.00155109
I0927 22:52:54.503934  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155133 (* 1 = 0.00155133 loss)
I0927 22:52:54.503940  3577 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0927 22:53:08.034019  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:53:08.603174  3577 solver.cpp:330] Iteration 92500, Testing net (#0)
I0927 22:53:11.974270  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:53:12.115574  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0927 22:53:12.115615  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334259 (* 1 = 0.334259 loss)
I0927 22:53:12.256952  3577 solver.cpp:218] Iteration 92500 (5.63286 iter/s, 17.753s/100 iters), loss = 0.000344286
I0927 22:53:12.256983  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00034452 (* 1 = 0.00034452 loss)
I0927 22:53:12.256989  3577 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0927 22:53:26.489058  3577 solver.cpp:218] Iteration 92600 (7.0264 iter/s, 14.232s/100 iters), loss = 0.00117648
I0927 22:53:26.489089  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117672 (* 1 = 0.00117672 loss)
I0927 22:53:26.489094  3577 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0927 22:53:40.730070  3577 solver.cpp:218] Iteration 92700 (7.02201 iter/s, 14.2409s/100 iters), loss = 0.00823872
I0927 22:53:40.730206  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823896 (* 1 = 0.00823896 loss)
I0927 22:53:40.730214  3577 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0927 22:53:54.965311  3577 solver.cpp:218] Iteration 92800 (7.0249 iter/s, 14.2351s/100 iters), loss = 0.000498291
I0927 22:53:54.965353  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000498527 (* 1 = 0.000498527 loss)
I0927 22:53:54.965358  3577 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0927 22:54:09.209542  3577 solver.cpp:218] Iteration 92900 (7.02043 iter/s, 14.2441s/100 iters), loss = 0.0018189
I0927 22:54:09.209583  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181913 (* 1 = 0.00181913 loss)
I0927 22:54:09.209589  3577 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0927 22:54:22.738560  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:54:23.307782  3577 solver.cpp:330] Iteration 93000, Testing net (#0)
I0927 22:54:26.679504  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:54:26.820608  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0927 22:54:26.820652  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33435 (* 1 = 0.33435 loss)
I0927 22:54:26.962785  3577 solver.cpp:218] Iteration 93000 (5.6328 iter/s, 17.7532s/100 iters), loss = 0.000868649
I0927 22:54:26.962815  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000868884 (* 1 = 0.000868884 loss)
I0927 22:54:26.962821  3577 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0927 22:54:41.202503  3577 solver.cpp:218] Iteration 93100 (7.02265 iter/s, 14.2396s/100 iters), loss = 0.00745581
I0927 22:54:41.202546  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745605 (* 1 = 0.00745605 loss)
I0927 22:54:41.202553  3577 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0927 22:54:55.444200  3577 solver.cpp:218] Iteration 93200 (7.02168 iter/s, 14.2416s/100 iters), loss = 0.00291477
I0927 22:54:55.444278  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291501 (* 1 = 0.00291501 loss)
I0927 22:54:55.444285  3577 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0927 22:55:09.683187  3577 solver.cpp:218] Iteration 93300 (7.02303 iter/s, 14.2389s/100 iters), loss = 0.000401168
I0927 22:55:09.683218  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000401403 (* 1 = 0.000401403 loss)
I0927 22:55:09.683223  3577 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0927 22:55:23.925382  3577 solver.cpp:218] Iteration 93400 (7.02142 iter/s, 14.2421s/100 iters), loss = 0.000777958
I0927 22:55:23.925422  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000778192 (* 1 = 0.000778192 loss)
I0927 22:55:23.925427  3577 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0927 22:55:37.458843  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:55:38.027645  3577 solver.cpp:330] Iteration 93500, Testing net (#0)
I0927 22:55:41.400115  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:55:41.541368  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0927 22:55:41.541404  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334264 (* 1 = 0.334264 loss)
I0927 22:55:41.683329  3577 solver.cpp:218] Iteration 93500 (5.63131 iter/s, 17.7579s/100 iters), loss = 0.000780233
I0927 22:55:41.683360  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000780468 (* 1 = 0.000780468 loss)
I0927 22:55:41.683367  3577 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0927 22:55:55.911167  3577 solver.cpp:218] Iteration 93600 (7.02851 iter/s, 14.2278s/100 iters), loss = 0.00113779
I0927 22:55:55.911198  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113803 (* 1 = 0.00113803 loss)
I0927 22:55:55.911204  3577 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0927 22:56:10.149137  3577 solver.cpp:218] Iteration 93700 (7.02351 iter/s, 14.2379s/100 iters), loss = 0.00212513
I0927 22:56:10.149217  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212536 (* 1 = 0.00212536 loss)
I0927 22:56:10.149233  3577 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0927 22:56:24.387823  3577 solver.cpp:218] Iteration 93800 (7.02318 iter/s, 14.2386s/100 iters), loss = 0.002153
I0927 22:56:24.387863  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215324 (* 1 = 0.00215324 loss)
I0927 22:56:24.387869  3577 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0927 22:56:38.628163  3577 solver.cpp:218] Iteration 93900 (7.02234 iter/s, 14.2403s/100 iters), loss = 0.00177708
I0927 22:56:38.628204  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177731 (* 1 = 0.00177731 loss)
I0927 22:56:38.628211  3577 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0927 22:56:52.161109  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:56:52.730280  3577 solver.cpp:330] Iteration 94000, Testing net (#0)
I0927 22:56:56.103782  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:56:56.244763  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0927 22:56:56.244789  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333856 (* 1 = 0.333856 loss)
I0927 22:56:56.386749  3577 solver.cpp:218] Iteration 94000 (5.63111 iter/s, 17.7585s/100 iters), loss = 0.00164993
I0927 22:56:56.386778  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165017 (* 1 = 0.00165017 loss)
I0927 22:56:56.386785  3577 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0927 22:57:10.623493  3577 solver.cpp:218] Iteration 94100 (7.02411 iter/s, 14.2367s/100 iters), loss = 0.00167148
I0927 22:57:10.623524  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167172 (* 1 = 0.00167172 loss)
I0927 22:57:10.623530  3577 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0927 22:57:24.862009  3577 solver.cpp:218] Iteration 94200 (7.02324 iter/s, 14.2384s/100 iters), loss = 0.000530677
I0927 22:57:24.862071  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000530917 (* 1 = 0.000530917 loss)
I0927 22:57:24.862078  3577 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0927 22:57:39.099490  3577 solver.cpp:218] Iteration 94300 (7.02376 iter/s, 14.2374s/100 iters), loss = 0.00119817
I0927 22:57:39.099521  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119841 (* 1 = 0.00119841 loss)
I0927 22:57:39.099527  3577 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0927 22:57:53.341748  3577 solver.cpp:218] Iteration 94400 (7.02139 iter/s, 14.2422s/100 iters), loss = 0.00199321
I0927 22:57:53.341790  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199345 (* 1 = 0.00199345 loss)
I0927 22:57:53.341795  3577 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0927 22:58:06.872936  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:58:07.443102  3577 solver.cpp:330] Iteration 94500, Testing net (#0)
I0927 22:58:10.814414  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:58:10.955456  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0927 22:58:10.955493  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334549 (* 1 = 0.334549 loss)
I0927 22:58:11.097672  3577 solver.cpp:218] Iteration 94500 (5.63195 iter/s, 17.7558s/100 iters), loss = 0.000157569
I0927 22:58:11.097702  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000157809 (* 1 = 0.000157809 loss)
I0927 22:58:11.097708  3577 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0927 22:58:25.341385  3577 solver.cpp:218] Iteration 94600 (7.02068 iter/s, 14.2436s/100 iters), loss = 0.00145751
I0927 22:58:25.341428  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145775 (* 1 = 0.00145775 loss)
I0927 22:58:25.341434  3577 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0927 22:58:39.580896  3577 solver.cpp:218] Iteration 94700 (7.02275 iter/s, 14.2394s/100 iters), loss = 0.000928881
I0927 22:58:39.581032  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000929122 (* 1 = 0.000929122 loss)
I0927 22:58:39.581039  3577 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0927 22:58:53.820947  3577 solver.cpp:218] Iteration 94800 (7.02253 iter/s, 14.2399s/100 iters), loss = 0.00107165
I0927 22:58:53.820988  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010719 (* 1 = 0.0010719 loss)
I0927 22:58:53.820994  3577 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0927 22:59:08.063230  3577 solver.cpp:218] Iteration 94900 (7.02139 iter/s, 14.2422s/100 iters), loss = 0.00285523
I0927 22:59:08.063271  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285547 (* 1 = 0.00285547 loss)
I0927 22:59:08.063277  3577 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0927 22:59:21.604849  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:59:22.175747  3577 solver.cpp:330] Iteration 95000, Testing net (#0)
I0927 22:59:25.548880  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 22:59:25.689487  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0927 22:59:25.689523  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335779 (* 1 = 0.335779 loss)
I0927 22:59:25.831318  3577 solver.cpp:218] Iteration 95000 (5.62809 iter/s, 17.768s/100 iters), loss = 0.000591331
I0927 22:59:25.831351  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000591571 (* 1 = 0.000591571 loss)
I0927 22:59:25.831357  3577 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0927 22:59:40.067092  3577 solver.cpp:218] Iteration 95100 (7.02459 iter/s, 14.2357s/100 iters), loss = 0.00200736
I0927 22:59:40.067133  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020076 (* 1 = 0.0020076 loss)
I0927 22:59:40.067139  3577 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0927 22:59:54.311480  3577 solver.cpp:218] Iteration 95200 (7.02035 iter/s, 14.2443s/100 iters), loss = 0.00171169
I0927 22:59:54.311625  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171193 (* 1 = 0.00171193 loss)
I0927 22:59:54.311633  3577 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0927 23:00:08.552894  3577 solver.cpp:218] Iteration 95300 (7.02186 iter/s, 14.2412s/100 iters), loss = 0.000519416
I0927 23:00:08.552937  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000519657 (* 1 = 0.000519657 loss)
I0927 23:00:08.552942  3577 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0927 23:00:22.795475  3577 solver.cpp:218] Iteration 95400 (7.02124 iter/s, 14.2425s/100 iters), loss = 0.00136518
I0927 23:00:22.795517  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136542 (* 1 = 0.00136542 loss)
I0927 23:00:22.795523  3577 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0927 23:00:36.330950  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:00:36.901304  3577 solver.cpp:330] Iteration 95500, Testing net (#0)
I0927 23:00:40.271725  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:00:40.412463  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0927 23:00:40.412500  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333864 (* 1 = 0.333864 loss)
I0927 23:00:40.554265  3577 solver.cpp:218] Iteration 95500 (5.63104 iter/s, 17.7587s/100 iters), loss = 0.000191097
I0927 23:00:40.554296  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000191338 (* 1 = 0.000191338 loss)
I0927 23:00:40.554302  3577 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0927 23:00:54.786553  3577 solver.cpp:218] Iteration 95600 (7.02631 iter/s, 14.2322s/100 iters), loss = 0.00186152
I0927 23:00:54.786595  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186176 (* 1 = 0.00186176 loss)
I0927 23:00:54.786602  3577 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0927 23:01:09.021531  3577 solver.cpp:218] Iteration 95700 (7.02499 iter/s, 14.2349s/100 iters), loss = 0.00369317
I0927 23:01:09.021615  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369341 (* 1 = 0.00369341 loss)
I0927 23:01:09.021631  3577 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0927 23:01:23.260423  3577 solver.cpp:218] Iteration 95800 (7.02308 iter/s, 14.2388s/100 iters), loss = 0.000318251
I0927 23:01:23.260455  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00031849 (* 1 = 0.00031849 loss)
I0927 23:01:23.260462  3577 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0927 23:01:37.499763  3577 solver.cpp:218] Iteration 95900 (7.02283 iter/s, 14.2393s/100 iters), loss = 0.00145234
I0927 23:01:37.499805  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145258 (* 1 = 0.00145258 loss)
I0927 23:01:37.499810  3577 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0927 23:01:51.035236  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:01:51.604559  3577 solver.cpp:330] Iteration 96000, Testing net (#0)
I0927 23:01:54.977028  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:01:55.117892  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0927 23:01:55.117929  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334005 (* 1 = 0.334005 loss)
I0927 23:01:55.259655  3577 solver.cpp:218] Iteration 96000 (5.63069 iter/s, 17.7598s/100 iters), loss = 0.00122486
I0927 23:01:55.259686  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012251 (* 1 = 0.0012251 loss)
I0927 23:01:55.259693  3577 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0927 23:02:09.496170  3577 solver.cpp:218] Iteration 96100 (7.02423 iter/s, 14.2364s/100 iters), loss = 0.00131118
I0927 23:02:09.496212  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131142 (* 1 = 0.00131142 loss)
I0927 23:02:09.496218  3577 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0927 23:02:23.731812  3577 solver.cpp:218] Iteration 96200 (7.02466 iter/s, 14.2356s/100 iters), loss = 0.000872627
I0927 23:02:23.731878  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000872863 (* 1 = 0.000872863 loss)
I0927 23:02:23.731884  3577 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0927 23:02:37.962533  3577 solver.cpp:218] Iteration 96300 (7.0271 iter/s, 14.2306s/100 iters), loss = 0.00139065
I0927 23:02:37.962575  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139089 (* 1 = 0.00139089 loss)
I0927 23:02:37.962581  3577 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0927 23:02:52.198129  3577 solver.cpp:218] Iteration 96400 (7.02468 iter/s, 14.2355s/100 iters), loss = 0.0011337
I0927 23:02:52.198169  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113393 (* 1 = 0.00113393 loss)
I0927 23:02:52.198175  3577 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0927 23:03:05.728786  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:03:06.298734  3577 solver.cpp:330] Iteration 96500, Testing net (#0)
I0927 23:03:09.669657  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:03:09.810861  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0927 23:03:09.810904  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335075 (* 1 = 0.335075 loss)
I0927 23:03:09.951673  3577 solver.cpp:218] Iteration 96500 (5.63271 iter/s, 17.7535s/100 iters), loss = 0.000581378
I0927 23:03:09.951702  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000581616 (* 1 = 0.000581616 loss)
I0927 23:03:09.951709  3577 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0927 23:03:24.190795  3577 solver.cpp:218] Iteration 96600 (7.02294 iter/s, 14.239s/100 iters), loss = 0.002449
I0927 23:03:24.190837  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244923 (* 1 = 0.00244923 loss)
I0927 23:03:24.190842  3577 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0927 23:03:38.432479  3577 solver.cpp:218] Iteration 96700 (7.02168 iter/s, 14.2416s/100 iters), loss = 0.000747769
I0927 23:03:38.432567  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000748007 (* 1 = 0.000748007 loss)
I0927 23:03:38.432585  3577 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0927 23:03:52.671582  3577 solver.cpp:218] Iteration 96800 (7.02298 iter/s, 14.239s/100 iters), loss = 0.000360293
I0927 23:03:52.671625  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00036053 (* 1 = 0.00036053 loss)
I0927 23:03:52.671631  3577 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0927 23:04:06.923789  3577 solver.cpp:218] Iteration 96900 (7.0165 iter/s, 14.2521s/100 iters), loss = 0.000376052
I0927 23:04:06.923830  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00037629 (* 1 = 0.00037629 loss)
I0927 23:04:06.923836  3577 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0927 23:04:20.459059  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:04:21.029624  3577 solver.cpp:330] Iteration 97000, Testing net (#0)
I0927 23:04:24.402657  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:04:24.543409  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0927 23:04:24.543445  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334879 (* 1 = 0.334879 loss)
I0927 23:04:24.685175  3577 solver.cpp:218] Iteration 97000 (5.63022 iter/s, 17.7613s/100 iters), loss = 0.00205537
I0927 23:04:24.685206  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205561 (* 1 = 0.00205561 loss)
I0927 23:04:24.685214  3577 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0927 23:04:38.923274  3577 solver.cpp:218] Iteration 97100 (7.02345 iter/s, 14.238s/100 iters), loss = 0.000592813
I0927 23:04:38.923315  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000593049 (* 1 = 0.000593049 loss)
I0927 23:04:38.923321  3577 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0927 23:04:53.157115  3577 solver.cpp:218] Iteration 97200 (7.02555 iter/s, 14.2338s/100 iters), loss = 0.000930477
I0927 23:04:53.157227  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000930713 (* 1 = 0.000930713 loss)
I0927 23:04:53.157233  3577 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0927 23:05:07.393451  3577 solver.cpp:218] Iteration 97300 (7.02435 iter/s, 14.2362s/100 iters), loss = 0.000645804
I0927 23:05:07.393493  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000646041 (* 1 = 0.000646041 loss)
I0927 23:05:07.393499  3577 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0927 23:05:21.633426  3577 solver.cpp:218] Iteration 97400 (7.02253 iter/s, 14.2399s/100 iters), loss = 0.000245579
I0927 23:05:21.633467  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000245815 (* 1 = 0.000245815 loss)
I0927 23:05:21.633473  3577 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0927 23:05:35.159588  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:05:35.729734  3577 solver.cpp:330] Iteration 97500, Testing net (#0)
I0927 23:05:39.101353  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:05:39.242612  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I0927 23:05:39.242650  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333516 (* 1 = 0.333516 loss)
I0927 23:05:39.384248  3577 solver.cpp:218] Iteration 97500 (5.63357 iter/s, 17.7507s/100 iters), loss = 0.000286986
I0927 23:05:39.384279  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000287222 (* 1 = 0.000287222 loss)
I0927 23:05:39.384286  3577 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0927 23:05:53.621340  3577 solver.cpp:218] Iteration 97600 (7.02394 iter/s, 14.237s/100 iters), loss = 0.0022446
I0927 23:05:53.621382  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224483 (* 1 = 0.00224483 loss)
I0927 23:05:53.621388  3577 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0927 23:06:07.860502  3577 solver.cpp:218] Iteration 97700 (7.02293 iter/s, 14.2391s/100 iters), loss = 0.00432648
I0927 23:06:07.860581  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432672 (* 1 = 0.00432672 loss)
I0927 23:06:07.860599  3577 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0927 23:06:22.097542  3577 solver.cpp:218] Iteration 97800 (7.02399 iter/s, 14.2369s/100 iters), loss = 0.000482834
I0927 23:06:22.097584  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00048307 (* 1 = 0.00048307 loss)
I0927 23:06:22.097589  3577 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0927 23:06:36.342145  3577 solver.cpp:218] Iteration 97900 (7.02024 iter/s, 14.2445s/100 iters), loss = 0.000188235
I0927 23:06:36.342177  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00018847 (* 1 = 0.00018847 loss)
I0927 23:06:36.342183  3577 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0927 23:06:49.870718  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:06:50.440475  3577 solver.cpp:330] Iteration 98000, Testing net (#0)
I0927 23:06:53.811554  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:06:53.951781  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0927 23:06:53.951818  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333031 (* 1 = 0.333031 loss)
I0927 23:06:54.093520  3577 solver.cpp:218] Iteration 98000 (5.63339 iter/s, 17.7513s/100 iters), loss = 0.00144097
I0927 23:06:54.093551  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144121 (* 1 = 0.00144121 loss)
I0927 23:06:54.093559  3577 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0927 23:07:08.334208  3577 solver.cpp:218] Iteration 98100 (7.02217 iter/s, 14.2406s/100 iters), loss = 0.00209416
I0927 23:07:08.334239  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020944 (* 1 = 0.0020944 loss)
I0927 23:07:08.334245  3577 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0927 23:07:22.567824  3577 solver.cpp:218] Iteration 98200 (7.02566 iter/s, 14.2335s/100 iters), loss = 0.000701397
I0927 23:07:22.567940  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000701635 (* 1 = 0.000701635 loss)
I0927 23:07:22.567956  3577 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0927 23:07:36.810710  3577 solver.cpp:218] Iteration 98300 (7.02112 iter/s, 14.2427s/100 iters), loss = 0.00170554
I0927 23:07:36.810740  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170578 (* 1 = 0.00170578 loss)
I0927 23:07:36.810745  3577 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0927 23:07:51.053915  3577 solver.cpp:218] Iteration 98400 (7.02092 iter/s, 14.2431s/100 iters), loss = 0.000222039
I0927 23:07:51.053947  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000222276 (* 1 = 0.000222276 loss)
I0927 23:07:51.053953  3577 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0927 23:08:04.584332  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:08:05.154065  3577 solver.cpp:330] Iteration 98500, Testing net (#0)
I0927 23:08:08.526819  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:08:08.667634  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0927 23:08:08.667670  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334799 (* 1 = 0.334799 loss)
I0927 23:08:08.809365  3577 solver.cpp:218] Iteration 98500 (5.6321 iter/s, 17.7554s/100 iters), loss = 0.000943936
I0927 23:08:08.809394  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000944173 (* 1 = 0.000944173 loss)
I0927 23:08:08.809401  3577 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0927 23:08:23.046145  3577 solver.cpp:218] Iteration 98600 (7.02409 iter/s, 14.2367s/100 iters), loss = 0.00310632
I0927 23:08:23.046187  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310656 (* 1 = 0.00310656 loss)
I0927 23:08:23.046193  3577 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0927 23:08:37.284205  3577 solver.cpp:218] Iteration 98700 (7.02347 iter/s, 14.238s/100 iters), loss = 0.00109951
I0927 23:08:37.284325  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109974 (* 1 = 0.00109974 loss)
I0927 23:08:37.284343  3577 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0927 23:08:51.527060  3577 solver.cpp:218] Iteration 98800 (7.02114 iter/s, 14.2427s/100 iters), loss = 0.000367879
I0927 23:08:51.527102  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000368116 (* 1 = 0.000368116 loss)
I0927 23:08:51.527108  3577 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0927 23:09:05.764044  3577 solver.cpp:218] Iteration 98900 (7.024 iter/s, 14.2369s/100 iters), loss = 0.00153572
I0927 23:09:05.764086  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153595 (* 1 = 0.00153595 loss)
I0927 23:09:05.764092  3577 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0927 23:09:19.298979  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:09:19.868974  3577 solver.cpp:330] Iteration 99000, Testing net (#0)
I0927 23:09:23.239328  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:09:23.380416  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0927 23:09:23.380453  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335471 (* 1 = 0.335471 loss)
I0927 23:09:23.522039  3577 solver.cpp:218] Iteration 99000 (5.63129 iter/s, 17.7579s/100 iters), loss = 0.000486014
I0927 23:09:23.522069  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000486248 (* 1 = 0.000486248 loss)
I0927 23:09:23.522076  3577 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0927 23:09:37.762547  3577 solver.cpp:218] Iteration 99100 (7.02226 iter/s, 14.2404s/100 iters), loss = 0.00100688
I0927 23:09:37.762589  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100711 (* 1 = 0.00100711 loss)
I0927 23:09:37.762595  3577 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0927 23:09:52.009093  3577 solver.cpp:218] Iteration 99200 (7.01928 iter/s, 14.2465s/100 iters), loss = 0.00105944
I0927 23:09:52.009191  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105967 (* 1 = 0.00105967 loss)
I0927 23:09:52.009198  3577 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0927 23:10:06.248947  3577 solver.cpp:218] Iteration 99300 (7.02261 iter/s, 14.2397s/100 iters), loss = 0.000312652
I0927 23:10:06.248991  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000312884 (* 1 = 0.000312884 loss)
I0927 23:10:06.248996  3577 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0927 23:10:20.492542  3577 solver.cpp:218] Iteration 99400 (7.02074 iter/s, 14.2435s/100 iters), loss = 0.000918499
I0927 23:10:20.492573  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000918731 (* 1 = 0.000918731 loss)
I0927 23:10:20.492578  3577 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0927 23:10:34.034072  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:10:34.604383  3577 solver.cpp:330] Iteration 99500, Testing net (#0)
I0927 23:10:37.975788  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:10:38.116639  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0927 23:10:38.116677  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335207 (* 1 = 0.335207 loss)
I0927 23:10:38.258558  3577 solver.cpp:218] Iteration 99500 (5.62875 iter/s, 17.7659s/100 iters), loss = 0.00114516
I0927 23:10:38.258589  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114539 (* 1 = 0.00114539 loss)
I0927 23:10:38.258595  3577 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0927 23:10:52.488437  3577 solver.cpp:218] Iteration 99600 (7.0275 iter/s, 14.2298s/100 iters), loss = 0.00134999
I0927 23:10:52.488469  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135023 (* 1 = 0.00135023 loss)
I0927 23:10:52.488476  3577 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0927 23:11:06.722965  3577 solver.cpp:218] Iteration 99700 (7.02521 iter/s, 14.2345s/100 iters), loss = 0.000890437
I0927 23:11:06.723052  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000890671 (* 1 = 0.000890671 loss)
I0927 23:11:06.723068  3577 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0927 23:11:20.957731  3577 solver.cpp:218] Iteration 99800 (7.02511 iter/s, 14.2346s/100 iters), loss = 0.000766276
I0927 23:11:20.957772  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00076651 (* 1 = 0.00076651 loss)
I0927 23:11:20.957778  3577 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0927 23:11:35.188642  3577 solver.cpp:218] Iteration 99900 (7.027 iter/s, 14.2308s/100 iters), loss = 0.000694834
I0927 23:11:35.188685  3577 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000695068 (* 1 = 0.000695068 loss)
I0927 23:11:35.188691  3577 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0927 23:11:48.716456  3587 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:11:49.285537  3577 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha2_eta1_2decay_gauss_iter_100000.caffemodel
I0927 23:11:49.310781  3577 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha2_eta1_2decay_gauss_iter_100000.solverstate
I0927 23:11:49.351331  3577 solver.cpp:310] Iteration 100000, loss = 0.000731913
I0927 23:11:49.351353  3577 solver.cpp:330] Iteration 100000, Testing net (#0)
I0927 23:11:52.721580  3588 data_layer.cpp:73] Restarting data prefetching from start.
I0927 23:11:52.863019  3577 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I0927 23:11:52.863056  3577 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33532 (* 1 = 0.33532 loss)
I0927 23:11:52.863061  3577 solver.cpp:315] Optimization Done.
I0927 23:11:52.863064  3577 caffe.cpp:259] Optimization Done.
