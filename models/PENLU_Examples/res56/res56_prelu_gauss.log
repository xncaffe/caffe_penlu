I0925 20:26:02.043735  3547 caffe.cpp:218] Using GPUs 0
I0925 20:26:02.092787  3547 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0925 20:26:02.322316  3547 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_prelu_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_prelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0925 20:26:02.322464  3547 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_prelu_train_test.prototxt
I0925 20:26:02.325350  3547 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_prelu_train_test.prototxt
I0925 20:26:02.325362  3547 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0925 20:26:02.325561  3547 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0925 20:26:02.325660  3547 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0925 20:26:02.326486  3547 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU4"
  type: "PReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU5"
  type: "PReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU6"
  type: "PReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU7"
  type: "PReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU8"
  type: "PReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU9"
  type: "PReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU10"
  type: "PReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU11"
  type: "PReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU12"
  type: "PReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU13"
  type: "PReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU14"
  type: "PReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU15"
  type: "PReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU16"
  type: "PReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU17"
  type: "PReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU18"
  type: "PReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU19"
  type: "PReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU20"
  type: "PReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU21"
  type: "PReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU22"
  type: "PReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU23"
  type: "PReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU24"
  type: "PReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU25"
  type: "PReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU26"
  type: "PReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU27"
  type: "PReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU28"
  type: "PReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU29"
  type: "PReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU30"
  type: "PReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gauss
I0925 20:26:02.327365  3547 layer_factory.hpp:77] Creating layer Data1
I0925 20:26:02.327440  3547 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0925 20:26:02.327457  3547 net.cpp:84] Creating Layer Data1
I0925 20:26:02.327463  3547 net.cpp:380] Data1 -> Data1
I0925 20:26:02.327481  3547 net.cpp:380] Data1 -> Data2
I0925 20:26:02.327489  3547 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0925 20:26:02.328908  3547 data_layer.cpp:45] output data size: 100,3,28,28
I0925 20:26:02.331163  3547 net.cpp:122] Setting up Data1
I0925 20:26:02.331177  3547 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0925 20:26:02.331181  3547 net.cpp:129] Top shape: 100 (100)
I0925 20:26:02.331183  3547 net.cpp:137] Memory required for data: 941200
I0925 20:26:02.331190  3547 layer_factory.hpp:77] Creating layer Convolution1
I0925 20:26:02.331208  3547 net.cpp:84] Creating Layer Convolution1
I0925 20:26:02.331212  3547 net.cpp:406] Convolution1 <- Data1
I0925 20:26:02.331220  3547 net.cpp:380] Convolution1 -> Convolution1
I0925 20:26:02.478749  3547 net.cpp:122] Setting up Convolution1
I0925 20:26:02.478775  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.478780  3547 net.cpp:137] Memory required for data: 5958800
I0925 20:26:02.478793  3547 layer_factory.hpp:77] Creating layer BatchNorm1
I0925 20:26:02.478818  3547 net.cpp:84] Creating Layer BatchNorm1
I0925 20:26:02.478821  3547 net.cpp:406] BatchNorm1 <- Convolution1
I0925 20:26:02.478849  3547 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0925 20:26:02.478999  3547 net.cpp:122] Setting up BatchNorm1
I0925 20:26:02.479005  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.479007  3547 net.cpp:137] Memory required for data: 10976400
I0925 20:26:02.479015  3547 layer_factory.hpp:77] Creating layer Scale1
I0925 20:26:02.479023  3547 net.cpp:84] Creating Layer Scale1
I0925 20:26:02.479037  3547 net.cpp:406] Scale1 <- Convolution1
I0925 20:26:02.479040  3547 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0925 20:26:02.479104  3547 layer_factory.hpp:77] Creating layer Scale1
I0925 20:26:02.479213  3547 net.cpp:122] Setting up Scale1
I0925 20:26:02.479219  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.479221  3547 net.cpp:137] Memory required for data: 15994000
I0925 20:26:02.479226  3547 layer_factory.hpp:77] Creating layer PReLU1
I0925 20:26:02.479230  3547 net.cpp:84] Creating Layer PReLU1
I0925 20:26:02.479233  3547 net.cpp:406] PReLU1 <- Convolution1
I0925 20:26:02.479236  3547 net.cpp:367] PReLU1 -> Convolution1 (in-place)
I0925 20:26:02.479827  3547 net.cpp:122] Setting up PReLU1
I0925 20:26:02.479837  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.479840  3547 net.cpp:137] Memory required for data: 21011600
I0925 20:26:02.479843  3547 layer_factory.hpp:77] Creating layer Convolution1_PReLU1_0_split
I0925 20:26:02.479848  3547 net.cpp:84] Creating Layer Convolution1_PReLU1_0_split
I0925 20:26:02.479851  3547 net.cpp:406] Convolution1_PReLU1_0_split <- Convolution1
I0925 20:26:02.479854  3547 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_0
I0925 20:26:02.479869  3547 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_1
I0925 20:26:02.479918  3547 net.cpp:122] Setting up Convolution1_PReLU1_0_split
I0925 20:26:02.479923  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.479935  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.479938  3547 net.cpp:137] Memory required for data: 31046800
I0925 20:26:02.479940  3547 layer_factory.hpp:77] Creating layer Convolution2
I0925 20:26:02.479956  3547 net.cpp:84] Creating Layer Convolution2
I0925 20:26:02.479960  3547 net.cpp:406] Convolution2 <- Convolution1_PReLU1_0_split_0
I0925 20:26:02.479974  3547 net.cpp:380] Convolution2 -> Convolution2
I0925 20:26:02.480860  3547 net.cpp:122] Setting up Convolution2
I0925 20:26:02.480870  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.480873  3547 net.cpp:137] Memory required for data: 36064400
I0925 20:26:02.480880  3547 layer_factory.hpp:77] Creating layer BatchNorm2
I0925 20:26:02.480885  3547 net.cpp:84] Creating Layer BatchNorm2
I0925 20:26:02.480887  3547 net.cpp:406] BatchNorm2 <- Convolution2
I0925 20:26:02.480901  3547 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0925 20:26:02.481035  3547 net.cpp:122] Setting up BatchNorm2
I0925 20:26:02.481041  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.481043  3547 net.cpp:137] Memory required for data: 41082000
I0925 20:26:02.481048  3547 layer_factory.hpp:77] Creating layer Scale2
I0925 20:26:02.481053  3547 net.cpp:84] Creating Layer Scale2
I0925 20:26:02.481055  3547 net.cpp:406] Scale2 <- Convolution2
I0925 20:26:02.481058  3547 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0925 20:26:02.481117  3547 layer_factory.hpp:77] Creating layer Scale2
I0925 20:26:02.481233  3547 net.cpp:122] Setting up Scale2
I0925 20:26:02.481238  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.481240  3547 net.cpp:137] Memory required for data: 46099600
I0925 20:26:02.481245  3547 layer_factory.hpp:77] Creating layer PReLU2
I0925 20:26:02.481248  3547 net.cpp:84] Creating Layer PReLU2
I0925 20:26:02.481251  3547 net.cpp:406] PReLU2 <- Convolution2
I0925 20:26:02.481253  3547 net.cpp:367] PReLU2 -> Convolution2 (in-place)
I0925 20:26:02.481343  3547 net.cpp:122] Setting up PReLU2
I0925 20:26:02.481348  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.481359  3547 net.cpp:137] Memory required for data: 51117200
I0925 20:26:02.481364  3547 layer_factory.hpp:77] Creating layer Convolution3
I0925 20:26:02.481380  3547 net.cpp:84] Creating Layer Convolution3
I0925 20:26:02.481384  3547 net.cpp:406] Convolution3 <- Convolution2
I0925 20:26:02.481390  3547 net.cpp:380] Convolution3 -> Convolution3
I0925 20:26:02.482270  3547 net.cpp:122] Setting up Convolution3
I0925 20:26:02.482280  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.482283  3547 net.cpp:137] Memory required for data: 56134800
I0925 20:26:02.482290  3547 layer_factory.hpp:77] Creating layer BatchNorm3
I0925 20:26:02.482295  3547 net.cpp:84] Creating Layer BatchNorm3
I0925 20:26:02.482298  3547 net.cpp:406] BatchNorm3 <- Convolution3
I0925 20:26:02.482312  3547 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0925 20:26:02.482444  3547 net.cpp:122] Setting up BatchNorm3
I0925 20:26:02.482448  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.482451  3547 net.cpp:137] Memory required for data: 61152400
I0925 20:26:02.482455  3547 layer_factory.hpp:77] Creating layer Scale3
I0925 20:26:02.482461  3547 net.cpp:84] Creating Layer Scale3
I0925 20:26:02.482463  3547 net.cpp:406] Scale3 <- Convolution3
I0925 20:26:02.482466  3547 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0925 20:26:02.482511  3547 layer_factory.hpp:77] Creating layer Scale3
I0925 20:26:02.482604  3547 net.cpp:122] Setting up Scale3
I0925 20:26:02.482609  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.482611  3547 net.cpp:137] Memory required for data: 66170000
I0925 20:26:02.482615  3547 layer_factory.hpp:77] Creating layer Eltwise1
I0925 20:26:02.482622  3547 net.cpp:84] Creating Layer Eltwise1
I0925 20:26:02.482625  3547 net.cpp:406] Eltwise1 <- Convolution1_PReLU1_0_split_1
I0925 20:26:02.482627  3547 net.cpp:406] Eltwise1 <- Convolution3
I0925 20:26:02.482641  3547 net.cpp:380] Eltwise1 -> Eltwise1
I0925 20:26:02.482667  3547 net.cpp:122] Setting up Eltwise1
I0925 20:26:02.482672  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.482674  3547 net.cpp:137] Memory required for data: 71187600
I0925 20:26:02.482686  3547 layer_factory.hpp:77] Creating layer PReLU3
I0925 20:26:02.482691  3547 net.cpp:84] Creating Layer PReLU3
I0925 20:26:02.482693  3547 net.cpp:406] PReLU3 <- Eltwise1
I0925 20:26:02.482697  3547 net.cpp:367] PReLU3 -> Eltwise1 (in-place)
I0925 20:26:02.482764  3547 net.cpp:122] Setting up PReLU3
I0925 20:26:02.482770  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.482784  3547 net.cpp:137] Memory required for data: 76205200
I0925 20:26:02.482786  3547 layer_factory.hpp:77] Creating layer Eltwise1_PReLU3_0_split
I0925 20:26:02.482790  3547 net.cpp:84] Creating Layer Eltwise1_PReLU3_0_split
I0925 20:26:02.482794  3547 net.cpp:406] Eltwise1_PReLU3_0_split <- Eltwise1
I0925 20:26:02.482800  3547 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_0
I0925 20:26:02.482808  3547 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_1
I0925 20:26:02.482841  3547 net.cpp:122] Setting up Eltwise1_PReLU3_0_split
I0925 20:26:02.482846  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.482859  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.482861  3547 net.cpp:137] Memory required for data: 86240400
I0925 20:26:02.482864  3547 layer_factory.hpp:77] Creating layer Convolution4
I0925 20:26:02.482874  3547 net.cpp:84] Creating Layer Convolution4
I0925 20:26:02.482879  3547 net.cpp:406] Convolution4 <- Eltwise1_PReLU3_0_split_0
I0925 20:26:02.482884  3547 net.cpp:380] Convolution4 -> Convolution4
I0925 20:26:02.483721  3547 net.cpp:122] Setting up Convolution4
I0925 20:26:02.483731  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.483743  3547 net.cpp:137] Memory required for data: 91258000
I0925 20:26:02.483750  3547 layer_factory.hpp:77] Creating layer BatchNorm4
I0925 20:26:02.483757  3547 net.cpp:84] Creating Layer BatchNorm4
I0925 20:26:02.483759  3547 net.cpp:406] BatchNorm4 <- Convolution4
I0925 20:26:02.483772  3547 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0925 20:26:02.483896  3547 net.cpp:122] Setting up BatchNorm4
I0925 20:26:02.483902  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.483906  3547 net.cpp:137] Memory required for data: 96275600
I0925 20:26:02.483911  3547 layer_factory.hpp:77] Creating layer Scale4
I0925 20:26:02.483916  3547 net.cpp:84] Creating Layer Scale4
I0925 20:26:02.483922  3547 net.cpp:406] Scale4 <- Convolution4
I0925 20:26:02.483928  3547 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0925 20:26:02.483956  3547 layer_factory.hpp:77] Creating layer Scale4
I0925 20:26:02.484030  3547 net.cpp:122] Setting up Scale4
I0925 20:26:02.484035  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.484040  3547 net.cpp:137] Memory required for data: 101293200
I0925 20:26:02.484045  3547 layer_factory.hpp:77] Creating layer PReLU4
I0925 20:26:02.484050  3547 net.cpp:84] Creating Layer PReLU4
I0925 20:26:02.484055  3547 net.cpp:406] PReLU4 <- Convolution4
I0925 20:26:02.484061  3547 net.cpp:367] PReLU4 -> Convolution4 (in-place)
I0925 20:26:02.484119  3547 net.cpp:122] Setting up PReLU4
I0925 20:26:02.484125  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.484129  3547 net.cpp:137] Memory required for data: 106310800
I0925 20:26:02.484134  3547 layer_factory.hpp:77] Creating layer Convolution5
I0925 20:26:02.484143  3547 net.cpp:84] Creating Layer Convolution5
I0925 20:26:02.484146  3547 net.cpp:406] Convolution5 <- Convolution4
I0925 20:26:02.484151  3547 net.cpp:380] Convolution5 -> Convolution5
I0925 20:26:02.485015  3547 net.cpp:122] Setting up Convolution5
I0925 20:26:02.485026  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.485033  3547 net.cpp:137] Memory required for data: 111328400
I0925 20:26:02.485043  3547 layer_factory.hpp:77] Creating layer BatchNorm5
I0925 20:26:02.485049  3547 net.cpp:84] Creating Layer BatchNorm5
I0925 20:26:02.485054  3547 net.cpp:406] BatchNorm5 <- Convolution5
I0925 20:26:02.485059  3547 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0925 20:26:02.485179  3547 net.cpp:122] Setting up BatchNorm5
I0925 20:26:02.485185  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.485190  3547 net.cpp:137] Memory required for data: 116346000
I0925 20:26:02.485198  3547 layer_factory.hpp:77] Creating layer Scale5
I0925 20:26:02.485203  3547 net.cpp:84] Creating Layer Scale5
I0925 20:26:02.485206  3547 net.cpp:406] Scale5 <- Convolution5
I0925 20:26:02.485213  3547 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0925 20:26:02.485239  3547 layer_factory.hpp:77] Creating layer Scale5
I0925 20:26:02.485312  3547 net.cpp:122] Setting up Scale5
I0925 20:26:02.485318  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.485323  3547 net.cpp:137] Memory required for data: 121363600
I0925 20:26:02.485329  3547 layer_factory.hpp:77] Creating layer Eltwise2
I0925 20:26:02.485334  3547 net.cpp:84] Creating Layer Eltwise2
I0925 20:26:02.485338  3547 net.cpp:406] Eltwise2 <- Eltwise1_PReLU3_0_split_1
I0925 20:26:02.485344  3547 net.cpp:406] Eltwise2 <- Convolution5
I0925 20:26:02.485349  3547 net.cpp:380] Eltwise2 -> Eltwise2
I0925 20:26:02.485368  3547 net.cpp:122] Setting up Eltwise2
I0925 20:26:02.485373  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.485376  3547 net.cpp:137] Memory required for data: 126381200
I0925 20:26:02.485380  3547 layer_factory.hpp:77] Creating layer PReLU5
I0925 20:26:02.485385  3547 net.cpp:84] Creating Layer PReLU5
I0925 20:26:02.485390  3547 net.cpp:406] PReLU5 <- Eltwise2
I0925 20:26:02.485394  3547 net.cpp:367] PReLU5 -> Eltwise2 (in-place)
I0925 20:26:02.485455  3547 net.cpp:122] Setting up PReLU5
I0925 20:26:02.485460  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.485465  3547 net.cpp:137] Memory required for data: 131398800
I0925 20:26:02.485468  3547 layer_factory.hpp:77] Creating layer Eltwise2_PReLU5_0_split
I0925 20:26:02.485474  3547 net.cpp:84] Creating Layer Eltwise2_PReLU5_0_split
I0925 20:26:02.485486  3547 net.cpp:406] Eltwise2_PReLU5_0_split <- Eltwise2
I0925 20:26:02.485491  3547 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_0
I0925 20:26:02.485498  3547 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_1
I0925 20:26:02.485523  3547 net.cpp:122] Setting up Eltwise2_PReLU5_0_split
I0925 20:26:02.485528  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.485533  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.485538  3547 net.cpp:137] Memory required for data: 141434000
I0925 20:26:02.485541  3547 layer_factory.hpp:77] Creating layer Convolution6
I0925 20:26:02.485550  3547 net.cpp:84] Creating Layer Convolution6
I0925 20:26:02.485554  3547 net.cpp:406] Convolution6 <- Eltwise2_PReLU5_0_split_0
I0925 20:26:02.485559  3547 net.cpp:380] Convolution6 -> Convolution6
I0925 20:26:02.486403  3547 net.cpp:122] Setting up Convolution6
I0925 20:26:02.486414  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.486419  3547 net.cpp:137] Memory required for data: 146451600
I0925 20:26:02.486428  3547 layer_factory.hpp:77] Creating layer BatchNorm6
I0925 20:26:02.486433  3547 net.cpp:84] Creating Layer BatchNorm6
I0925 20:26:02.486438  3547 net.cpp:406] BatchNorm6 <- Convolution6
I0925 20:26:02.486444  3547 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0925 20:26:02.486567  3547 net.cpp:122] Setting up BatchNorm6
I0925 20:26:02.486574  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.486578  3547 net.cpp:137] Memory required for data: 151469200
I0925 20:26:02.486585  3547 layer_factory.hpp:77] Creating layer Scale6
I0925 20:26:02.486590  3547 net.cpp:84] Creating Layer Scale6
I0925 20:26:02.486595  3547 net.cpp:406] Scale6 <- Convolution6
I0925 20:26:02.486600  3547 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0925 20:26:02.486629  3547 layer_factory.hpp:77] Creating layer Scale6
I0925 20:26:02.486703  3547 net.cpp:122] Setting up Scale6
I0925 20:26:02.486709  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.486713  3547 net.cpp:137] Memory required for data: 156486800
I0925 20:26:02.486719  3547 layer_factory.hpp:77] Creating layer PReLU6
I0925 20:26:02.486724  3547 net.cpp:84] Creating Layer PReLU6
I0925 20:26:02.486729  3547 net.cpp:406] PReLU6 <- Convolution6
I0925 20:26:02.486734  3547 net.cpp:367] PReLU6 -> Convolution6 (in-place)
I0925 20:26:02.486795  3547 net.cpp:122] Setting up PReLU6
I0925 20:26:02.486801  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.486805  3547 net.cpp:137] Memory required for data: 161504400
I0925 20:26:02.486810  3547 layer_factory.hpp:77] Creating layer Convolution7
I0925 20:26:02.486819  3547 net.cpp:84] Creating Layer Convolution7
I0925 20:26:02.486822  3547 net.cpp:406] Convolution7 <- Convolution6
I0925 20:26:02.486827  3547 net.cpp:380] Convolution7 -> Convolution7
I0925 20:26:02.487347  3547 net.cpp:122] Setting up Convolution7
I0925 20:26:02.487357  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.487362  3547 net.cpp:137] Memory required for data: 166522000
I0925 20:26:02.487370  3547 layer_factory.hpp:77] Creating layer BatchNorm7
I0925 20:26:02.487375  3547 net.cpp:84] Creating Layer BatchNorm7
I0925 20:26:02.487380  3547 net.cpp:406] BatchNorm7 <- Convolution7
I0925 20:26:02.487385  3547 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0925 20:26:02.487509  3547 net.cpp:122] Setting up BatchNorm7
I0925 20:26:02.487514  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.487519  3547 net.cpp:137] Memory required for data: 171539600
I0925 20:26:02.487525  3547 layer_factory.hpp:77] Creating layer Scale7
I0925 20:26:02.487532  3547 net.cpp:84] Creating Layer Scale7
I0925 20:26:02.487536  3547 net.cpp:406] Scale7 <- Convolution7
I0925 20:26:02.487540  3547 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0925 20:26:02.487568  3547 layer_factory.hpp:77] Creating layer Scale7
I0925 20:26:02.487643  3547 net.cpp:122] Setting up Scale7
I0925 20:26:02.487655  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.487659  3547 net.cpp:137] Memory required for data: 176557200
I0925 20:26:02.487666  3547 layer_factory.hpp:77] Creating layer Eltwise3
I0925 20:26:02.487671  3547 net.cpp:84] Creating Layer Eltwise3
I0925 20:26:02.487675  3547 net.cpp:406] Eltwise3 <- Eltwise2_PReLU5_0_split_1
I0925 20:26:02.487680  3547 net.cpp:406] Eltwise3 <- Convolution7
I0925 20:26:02.487686  3547 net.cpp:380] Eltwise3 -> Eltwise3
I0925 20:26:02.487705  3547 net.cpp:122] Setting up Eltwise3
I0925 20:26:02.487710  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.487715  3547 net.cpp:137] Memory required for data: 181574800
I0925 20:26:02.487718  3547 layer_factory.hpp:77] Creating layer PReLU7
I0925 20:26:02.487723  3547 net.cpp:84] Creating Layer PReLU7
I0925 20:26:02.487728  3547 net.cpp:406] PReLU7 <- Eltwise3
I0925 20:26:02.487733  3547 net.cpp:367] PReLU7 -> Eltwise3 (in-place)
I0925 20:26:02.487792  3547 net.cpp:122] Setting up PReLU7
I0925 20:26:02.487798  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.487802  3547 net.cpp:137] Memory required for data: 186592400
I0925 20:26:02.487807  3547 layer_factory.hpp:77] Creating layer Eltwise3_PReLU7_0_split
I0925 20:26:02.487812  3547 net.cpp:84] Creating Layer Eltwise3_PReLU7_0_split
I0925 20:26:02.487817  3547 net.cpp:406] Eltwise3_PReLU7_0_split <- Eltwise3
I0925 20:26:02.487821  3547 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_0
I0925 20:26:02.487828  3547 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_1
I0925 20:26:02.487851  3547 net.cpp:122] Setting up Eltwise3_PReLU7_0_split
I0925 20:26:02.487856  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.487861  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.487866  3547 net.cpp:137] Memory required for data: 196627600
I0925 20:26:02.487869  3547 layer_factory.hpp:77] Creating layer Convolution8
I0925 20:26:02.487879  3547 net.cpp:84] Creating Layer Convolution8
I0925 20:26:02.487881  3547 net.cpp:406] Convolution8 <- Eltwise3_PReLU7_0_split_0
I0925 20:26:02.487887  3547 net.cpp:380] Convolution8 -> Convolution8
I0925 20:26:02.488759  3547 net.cpp:122] Setting up Convolution8
I0925 20:26:02.488770  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.488775  3547 net.cpp:137] Memory required for data: 201645200
I0925 20:26:02.488782  3547 layer_factory.hpp:77] Creating layer BatchNorm8
I0925 20:26:02.488790  3547 net.cpp:84] Creating Layer BatchNorm8
I0925 20:26:02.488793  3547 net.cpp:406] BatchNorm8 <- Convolution8
I0925 20:26:02.488800  3547 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0925 20:26:02.488932  3547 net.cpp:122] Setting up BatchNorm8
I0925 20:26:02.488939  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.488943  3547 net.cpp:137] Memory required for data: 206662800
I0925 20:26:02.488950  3547 layer_factory.hpp:77] Creating layer Scale8
I0925 20:26:02.488956  3547 net.cpp:84] Creating Layer Scale8
I0925 20:26:02.488960  3547 net.cpp:406] Scale8 <- Convolution8
I0925 20:26:02.488976  3547 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0925 20:26:02.489003  3547 layer_factory.hpp:77] Creating layer Scale8
I0925 20:26:02.489078  3547 net.cpp:122] Setting up Scale8
I0925 20:26:02.489084  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.489089  3547 net.cpp:137] Memory required for data: 211680400
I0925 20:26:02.489094  3547 layer_factory.hpp:77] Creating layer PReLU8
I0925 20:26:02.489099  3547 net.cpp:84] Creating Layer PReLU8
I0925 20:26:02.489104  3547 net.cpp:406] PReLU8 <- Convolution8
I0925 20:26:02.489109  3547 net.cpp:367] PReLU8 -> Convolution8 (in-place)
I0925 20:26:02.489169  3547 net.cpp:122] Setting up PReLU8
I0925 20:26:02.489176  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.489179  3547 net.cpp:137] Memory required for data: 216698000
I0925 20:26:02.489184  3547 layer_factory.hpp:77] Creating layer Convolution9
I0925 20:26:02.489193  3547 net.cpp:84] Creating Layer Convolution9
I0925 20:26:02.489203  3547 net.cpp:406] Convolution9 <- Convolution8
I0925 20:26:02.489210  3547 net.cpp:380] Convolution9 -> Convolution9
I0925 20:26:02.490084  3547 net.cpp:122] Setting up Convolution9
I0925 20:26:02.490095  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.490101  3547 net.cpp:137] Memory required for data: 221715600
I0925 20:26:02.490121  3547 layer_factory.hpp:77] Creating layer BatchNorm9
I0925 20:26:02.490128  3547 net.cpp:84] Creating Layer BatchNorm9
I0925 20:26:02.490133  3547 net.cpp:406] BatchNorm9 <- Convolution9
I0925 20:26:02.490137  3547 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0925 20:26:02.490275  3547 net.cpp:122] Setting up BatchNorm9
I0925 20:26:02.490281  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.490286  3547 net.cpp:137] Memory required for data: 226733200
I0925 20:26:02.490295  3547 layer_factory.hpp:77] Creating layer Scale9
I0925 20:26:02.490301  3547 net.cpp:84] Creating Layer Scale9
I0925 20:26:02.490305  3547 net.cpp:406] Scale9 <- Convolution9
I0925 20:26:02.490310  3547 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0925 20:26:02.490339  3547 layer_factory.hpp:77] Creating layer Scale9
I0925 20:26:02.490437  3547 net.cpp:122] Setting up Scale9
I0925 20:26:02.490443  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.490448  3547 net.cpp:137] Memory required for data: 231750800
I0925 20:26:02.490454  3547 layer_factory.hpp:77] Creating layer Eltwise4
I0925 20:26:02.490459  3547 net.cpp:84] Creating Layer Eltwise4
I0925 20:26:02.490464  3547 net.cpp:406] Eltwise4 <- Eltwise3_PReLU7_0_split_1
I0925 20:26:02.490469  3547 net.cpp:406] Eltwise4 <- Convolution9
I0925 20:26:02.490475  3547 net.cpp:380] Eltwise4 -> Eltwise4
I0925 20:26:02.490494  3547 net.cpp:122] Setting up Eltwise4
I0925 20:26:02.490499  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.490504  3547 net.cpp:137] Memory required for data: 236768400
I0925 20:26:02.490507  3547 layer_factory.hpp:77] Creating layer PReLU9
I0925 20:26:02.490514  3547 net.cpp:84] Creating Layer PReLU9
I0925 20:26:02.490517  3547 net.cpp:406] PReLU9 <- Eltwise4
I0925 20:26:02.490522  3547 net.cpp:367] PReLU9 -> Eltwise4 (in-place)
I0925 20:26:02.490592  3547 net.cpp:122] Setting up PReLU9
I0925 20:26:02.490597  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.490600  3547 net.cpp:137] Memory required for data: 241786000
I0925 20:26:02.490605  3547 layer_factory.hpp:77] Creating layer Eltwise4_PReLU9_0_split
I0925 20:26:02.490612  3547 net.cpp:84] Creating Layer Eltwise4_PReLU9_0_split
I0925 20:26:02.490617  3547 net.cpp:406] Eltwise4_PReLU9_0_split <- Eltwise4
I0925 20:26:02.490622  3547 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_0
I0925 20:26:02.490628  3547 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_1
I0925 20:26:02.490653  3547 net.cpp:122] Setting up Eltwise4_PReLU9_0_split
I0925 20:26:02.490658  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.490662  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.490666  3547 net.cpp:137] Memory required for data: 251821200
I0925 20:26:02.490670  3547 layer_factory.hpp:77] Creating layer Convolution10
I0925 20:26:02.490689  3547 net.cpp:84] Creating Layer Convolution10
I0925 20:26:02.490691  3547 net.cpp:406] Convolution10 <- Eltwise4_PReLU9_0_split_0
I0925 20:26:02.490706  3547 net.cpp:380] Convolution10 -> Convolution10
I0925 20:26:02.491601  3547 net.cpp:122] Setting up Convolution10
I0925 20:26:02.491611  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.491616  3547 net.cpp:137] Memory required for data: 256838800
I0925 20:26:02.491623  3547 layer_factory.hpp:77] Creating layer BatchNorm10
I0925 20:26:02.491631  3547 net.cpp:84] Creating Layer BatchNorm10
I0925 20:26:02.491634  3547 net.cpp:406] BatchNorm10 <- Convolution10
I0925 20:26:02.491639  3547 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0925 20:26:02.491762  3547 net.cpp:122] Setting up BatchNorm10
I0925 20:26:02.491775  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.491780  3547 net.cpp:137] Memory required for data: 261856400
I0925 20:26:02.491786  3547 layer_factory.hpp:77] Creating layer Scale10
I0925 20:26:02.491792  3547 net.cpp:84] Creating Layer Scale10
I0925 20:26:02.491796  3547 net.cpp:406] Scale10 <- Convolution10
I0925 20:26:02.491801  3547 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0925 20:26:02.491829  3547 layer_factory.hpp:77] Creating layer Scale10
I0925 20:26:02.491914  3547 net.cpp:122] Setting up Scale10
I0925 20:26:02.491920  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.491922  3547 net.cpp:137] Memory required for data: 266874000
I0925 20:26:02.491926  3547 layer_factory.hpp:77] Creating layer PReLU10
I0925 20:26:02.491930  3547 net.cpp:84] Creating Layer PReLU10
I0925 20:26:02.491932  3547 net.cpp:406] PReLU10 <- Convolution10
I0925 20:26:02.491945  3547 net.cpp:367] PReLU10 -> Convolution10 (in-place)
I0925 20:26:02.492036  3547 net.cpp:122] Setting up PReLU10
I0925 20:26:02.492043  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.492044  3547 net.cpp:137] Memory required for data: 271891600
I0925 20:26:02.492059  3547 layer_factory.hpp:77] Creating layer Convolution11
I0925 20:26:02.492066  3547 net.cpp:84] Creating Layer Convolution11
I0925 20:26:02.492070  3547 net.cpp:406] Convolution11 <- Convolution10
I0925 20:26:02.492074  3547 net.cpp:380] Convolution11 -> Convolution11
I0925 20:26:02.492980  3547 net.cpp:122] Setting up Convolution11
I0925 20:26:02.492990  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.492992  3547 net.cpp:137] Memory required for data: 276909200
I0925 20:26:02.493008  3547 layer_factory.hpp:77] Creating layer BatchNorm11
I0925 20:26:02.493015  3547 net.cpp:84] Creating Layer BatchNorm11
I0925 20:26:02.493018  3547 net.cpp:406] BatchNorm11 <- Convolution11
I0925 20:26:02.493021  3547 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0925 20:26:02.493155  3547 net.cpp:122] Setting up BatchNorm11
I0925 20:26:02.493160  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.493163  3547 net.cpp:137] Memory required for data: 281926800
I0925 20:26:02.493180  3547 layer_factory.hpp:77] Creating layer Scale11
I0925 20:26:02.493186  3547 net.cpp:84] Creating Layer Scale11
I0925 20:26:02.493190  3547 net.cpp:406] Scale11 <- Convolution11
I0925 20:26:02.493193  3547 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0925 20:26:02.493223  3547 layer_factory.hpp:77] Creating layer Scale11
I0925 20:26:02.493302  3547 net.cpp:122] Setting up Scale11
I0925 20:26:02.493309  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.493314  3547 net.cpp:137] Memory required for data: 286944400
I0925 20:26:02.493319  3547 layer_factory.hpp:77] Creating layer Eltwise5
I0925 20:26:02.493324  3547 net.cpp:84] Creating Layer Eltwise5
I0925 20:26:02.493327  3547 net.cpp:406] Eltwise5 <- Eltwise4_PReLU9_0_split_1
I0925 20:26:02.493331  3547 net.cpp:406] Eltwise5 <- Convolution11
I0925 20:26:02.493335  3547 net.cpp:380] Eltwise5 -> Eltwise5
I0925 20:26:02.493352  3547 net.cpp:122] Setting up Eltwise5
I0925 20:26:02.493357  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.493360  3547 net.cpp:137] Memory required for data: 291962000
I0925 20:26:02.493362  3547 layer_factory.hpp:77] Creating layer PReLU11
I0925 20:26:02.493366  3547 net.cpp:84] Creating Layer PReLU11
I0925 20:26:02.493369  3547 net.cpp:406] PReLU11 <- Eltwise5
I0925 20:26:02.493373  3547 net.cpp:367] PReLU11 -> Eltwise5 (in-place)
I0925 20:26:02.493435  3547 net.cpp:122] Setting up PReLU11
I0925 20:26:02.493440  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.493443  3547 net.cpp:137] Memory required for data: 296979600
I0925 20:26:02.493448  3547 layer_factory.hpp:77] Creating layer Eltwise5_PReLU11_0_split
I0925 20:26:02.493451  3547 net.cpp:84] Creating Layer Eltwise5_PReLU11_0_split
I0925 20:26:02.493454  3547 net.cpp:406] Eltwise5_PReLU11_0_split <- Eltwise5
I0925 20:26:02.493458  3547 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_0
I0925 20:26:02.493470  3547 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_1
I0925 20:26:02.493495  3547 net.cpp:122] Setting up Eltwise5_PReLU11_0_split
I0925 20:26:02.493500  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.493505  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.493506  3547 net.cpp:137] Memory required for data: 307014800
I0925 20:26:02.493508  3547 layer_factory.hpp:77] Creating layer Convolution12
I0925 20:26:02.493516  3547 net.cpp:84] Creating Layer Convolution12
I0925 20:26:02.493520  3547 net.cpp:406] Convolution12 <- Eltwise5_PReLU11_0_split_0
I0925 20:26:02.493523  3547 net.cpp:380] Convolution12 -> Convolution12
I0925 20:26:02.494400  3547 net.cpp:122] Setting up Convolution12
I0925 20:26:02.494410  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.494413  3547 net.cpp:137] Memory required for data: 312032400
I0925 20:26:02.494418  3547 layer_factory.hpp:77] Creating layer BatchNorm12
I0925 20:26:02.494424  3547 net.cpp:84] Creating Layer BatchNorm12
I0925 20:26:02.494427  3547 net.cpp:406] BatchNorm12 <- Convolution12
I0925 20:26:02.494431  3547 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0925 20:26:02.494562  3547 net.cpp:122] Setting up BatchNorm12
I0925 20:26:02.494567  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.494570  3547 net.cpp:137] Memory required for data: 317050000
I0925 20:26:02.494575  3547 layer_factory.hpp:77] Creating layer Scale12
I0925 20:26:02.494581  3547 net.cpp:84] Creating Layer Scale12
I0925 20:26:02.494585  3547 net.cpp:406] Scale12 <- Convolution12
I0925 20:26:02.494587  3547 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0925 20:26:02.494614  3547 layer_factory.hpp:77] Creating layer Scale12
I0925 20:26:02.494693  3547 net.cpp:122] Setting up Scale12
I0925 20:26:02.494699  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.494701  3547 net.cpp:137] Memory required for data: 322067600
I0925 20:26:02.494705  3547 layer_factory.hpp:77] Creating layer PReLU12
I0925 20:26:02.494709  3547 net.cpp:84] Creating Layer PReLU12
I0925 20:26:02.494714  3547 net.cpp:406] PReLU12 <- Convolution12
I0925 20:26:02.494716  3547 net.cpp:367] PReLU12 -> Convolution12 (in-place)
I0925 20:26:02.494779  3547 net.cpp:122] Setting up PReLU12
I0925 20:26:02.494784  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.494787  3547 net.cpp:137] Memory required for data: 327085200
I0925 20:26:02.494791  3547 layer_factory.hpp:77] Creating layer Convolution13
I0925 20:26:02.494798  3547 net.cpp:84] Creating Layer Convolution13
I0925 20:26:02.494801  3547 net.cpp:406] Convolution13 <- Convolution12
I0925 20:26:02.494805  3547 net.cpp:380] Convolution13 -> Convolution13
I0925 20:26:02.495682  3547 net.cpp:122] Setting up Convolution13
I0925 20:26:02.495693  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.495697  3547 net.cpp:137] Memory required for data: 332102800
I0925 20:26:02.495702  3547 layer_factory.hpp:77] Creating layer BatchNorm13
I0925 20:26:02.495707  3547 net.cpp:84] Creating Layer BatchNorm13
I0925 20:26:02.495712  3547 net.cpp:406] BatchNorm13 <- Convolution13
I0925 20:26:02.495714  3547 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0925 20:26:02.495847  3547 net.cpp:122] Setting up BatchNorm13
I0925 20:26:02.495852  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.495856  3547 net.cpp:137] Memory required for data: 337120400
I0925 20:26:02.495860  3547 layer_factory.hpp:77] Creating layer Scale13
I0925 20:26:02.495865  3547 net.cpp:84] Creating Layer Scale13
I0925 20:26:02.495869  3547 net.cpp:406] Scale13 <- Convolution13
I0925 20:26:02.495872  3547 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0925 20:26:02.495899  3547 layer_factory.hpp:77] Creating layer Scale13
I0925 20:26:02.495977  3547 net.cpp:122] Setting up Scale13
I0925 20:26:02.495982  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.495985  3547 net.cpp:137] Memory required for data: 342138000
I0925 20:26:02.495996  3547 layer_factory.hpp:77] Creating layer Eltwise6
I0925 20:26:02.496002  3547 net.cpp:84] Creating Layer Eltwise6
I0925 20:26:02.496006  3547 net.cpp:406] Eltwise6 <- Eltwise5_PReLU11_0_split_1
I0925 20:26:02.496009  3547 net.cpp:406] Eltwise6 <- Convolution13
I0925 20:26:02.496013  3547 net.cpp:380] Eltwise6 -> Eltwise6
I0925 20:26:02.496032  3547 net.cpp:122] Setting up Eltwise6
I0925 20:26:02.496038  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.496042  3547 net.cpp:137] Memory required for data: 347155600
I0925 20:26:02.496043  3547 layer_factory.hpp:77] Creating layer PReLU13
I0925 20:26:02.496050  3547 net.cpp:84] Creating Layer PReLU13
I0925 20:26:02.496053  3547 net.cpp:406] PReLU13 <- Eltwise6
I0925 20:26:02.496057  3547 net.cpp:367] PReLU13 -> Eltwise6 (in-place)
I0925 20:26:02.496120  3547 net.cpp:122] Setting up PReLU13
I0925 20:26:02.496125  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.496129  3547 net.cpp:137] Memory required for data: 352173200
I0925 20:26:02.496132  3547 layer_factory.hpp:77] Creating layer Eltwise6_PReLU13_0_split
I0925 20:26:02.496136  3547 net.cpp:84] Creating Layer Eltwise6_PReLU13_0_split
I0925 20:26:02.496140  3547 net.cpp:406] Eltwise6_PReLU13_0_split <- Eltwise6
I0925 20:26:02.496143  3547 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_0
I0925 20:26:02.496148  3547 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_1
I0925 20:26:02.496172  3547 net.cpp:122] Setting up Eltwise6_PReLU13_0_split
I0925 20:26:02.496176  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.496181  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.496183  3547 net.cpp:137] Memory required for data: 362208400
I0925 20:26:02.496186  3547 layer_factory.hpp:77] Creating layer Convolution14
I0925 20:26:02.496191  3547 net.cpp:84] Creating Layer Convolution14
I0925 20:26:02.496194  3547 net.cpp:406] Convolution14 <- Eltwise6_PReLU13_0_split_0
I0925 20:26:02.496198  3547 net.cpp:380] Convolution14 -> Convolution14
I0925 20:26:02.497077  3547 net.cpp:122] Setting up Convolution14
I0925 20:26:02.497087  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.497089  3547 net.cpp:137] Memory required for data: 367226000
I0925 20:26:02.497093  3547 layer_factory.hpp:77] Creating layer BatchNorm14
I0925 20:26:02.497098  3547 net.cpp:84] Creating Layer BatchNorm14
I0925 20:26:02.497100  3547 net.cpp:406] BatchNorm14 <- Convolution14
I0925 20:26:02.497104  3547 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0925 20:26:02.497231  3547 net.cpp:122] Setting up BatchNorm14
I0925 20:26:02.497236  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.497237  3547 net.cpp:137] Memory required for data: 372243600
I0925 20:26:02.497242  3547 layer_factory.hpp:77] Creating layer Scale14
I0925 20:26:02.497246  3547 net.cpp:84] Creating Layer Scale14
I0925 20:26:02.497249  3547 net.cpp:406] Scale14 <- Convolution14
I0925 20:26:02.497252  3547 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0925 20:26:02.497277  3547 layer_factory.hpp:77] Creating layer Scale14
I0925 20:26:02.497350  3547 net.cpp:122] Setting up Scale14
I0925 20:26:02.497355  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.497357  3547 net.cpp:137] Memory required for data: 377261200
I0925 20:26:02.497361  3547 layer_factory.hpp:77] Creating layer PReLU14
I0925 20:26:02.497364  3547 net.cpp:84] Creating Layer PReLU14
I0925 20:26:02.497367  3547 net.cpp:406] PReLU14 <- Convolution14
I0925 20:26:02.497370  3547 net.cpp:367] PReLU14 -> Convolution14 (in-place)
I0925 20:26:02.497429  3547 net.cpp:122] Setting up PReLU14
I0925 20:26:02.497434  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.497437  3547 net.cpp:137] Memory required for data: 382278800
I0925 20:26:02.497439  3547 layer_factory.hpp:77] Creating layer Convolution15
I0925 20:26:02.497445  3547 net.cpp:84] Creating Layer Convolution15
I0925 20:26:02.497448  3547 net.cpp:406] Convolution15 <- Convolution14
I0925 20:26:02.497458  3547 net.cpp:380] Convolution15 -> Convolution15
I0925 20:26:02.498308  3547 net.cpp:122] Setting up Convolution15
I0925 20:26:02.498317  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.498320  3547 net.cpp:137] Memory required for data: 387296400
I0925 20:26:02.498324  3547 layer_factory.hpp:77] Creating layer BatchNorm15
I0925 20:26:02.498329  3547 net.cpp:84] Creating Layer BatchNorm15
I0925 20:26:02.498332  3547 net.cpp:406] BatchNorm15 <- Convolution15
I0925 20:26:02.498335  3547 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0925 20:26:02.498461  3547 net.cpp:122] Setting up BatchNorm15
I0925 20:26:02.498464  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.498467  3547 net.cpp:137] Memory required for data: 392314000
I0925 20:26:02.498471  3547 layer_factory.hpp:77] Creating layer Scale15
I0925 20:26:02.498476  3547 net.cpp:84] Creating Layer Scale15
I0925 20:26:02.498478  3547 net.cpp:406] Scale15 <- Convolution15
I0925 20:26:02.498481  3547 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0925 20:26:02.498507  3547 layer_factory.hpp:77] Creating layer Scale15
I0925 20:26:02.498579  3547 net.cpp:122] Setting up Scale15
I0925 20:26:02.498584  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.498586  3547 net.cpp:137] Memory required for data: 397331600
I0925 20:26:02.498590  3547 layer_factory.hpp:77] Creating layer Eltwise7
I0925 20:26:02.498594  3547 net.cpp:84] Creating Layer Eltwise7
I0925 20:26:02.498596  3547 net.cpp:406] Eltwise7 <- Eltwise6_PReLU13_0_split_1
I0925 20:26:02.498600  3547 net.cpp:406] Eltwise7 <- Convolution15
I0925 20:26:02.498602  3547 net.cpp:380] Eltwise7 -> Eltwise7
I0925 20:26:02.498617  3547 net.cpp:122] Setting up Eltwise7
I0925 20:26:02.498620  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.498623  3547 net.cpp:137] Memory required for data: 402349200
I0925 20:26:02.498625  3547 layer_factory.hpp:77] Creating layer PReLU15
I0925 20:26:02.498630  3547 net.cpp:84] Creating Layer PReLU15
I0925 20:26:02.498631  3547 net.cpp:406] PReLU15 <- Eltwise7
I0925 20:26:02.498634  3547 net.cpp:367] PReLU15 -> Eltwise7 (in-place)
I0925 20:26:02.498694  3547 net.cpp:122] Setting up PReLU15
I0925 20:26:02.498698  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.498700  3547 net.cpp:137] Memory required for data: 407366800
I0925 20:26:02.498703  3547 layer_factory.hpp:77] Creating layer Eltwise7_PReLU15_0_split
I0925 20:26:02.498708  3547 net.cpp:84] Creating Layer Eltwise7_PReLU15_0_split
I0925 20:26:02.498709  3547 net.cpp:406] Eltwise7_PReLU15_0_split <- Eltwise7
I0925 20:26:02.498713  3547 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_0
I0925 20:26:02.498718  3547 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_1
I0925 20:26:02.498739  3547 net.cpp:122] Setting up Eltwise7_PReLU15_0_split
I0925 20:26:02.498742  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.498744  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.498746  3547 net.cpp:137] Memory required for data: 417402000
I0925 20:26:02.498749  3547 layer_factory.hpp:77] Creating layer Convolution16
I0925 20:26:02.498755  3547 net.cpp:84] Creating Layer Convolution16
I0925 20:26:02.498757  3547 net.cpp:406] Convolution16 <- Eltwise7_PReLU15_0_split_0
I0925 20:26:02.498761  3547 net.cpp:380] Convolution16 -> Convolution16
I0925 20:26:02.499626  3547 net.cpp:122] Setting up Convolution16
I0925 20:26:02.499635  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.499639  3547 net.cpp:137] Memory required for data: 422419600
I0925 20:26:02.499642  3547 layer_factory.hpp:77] Creating layer BatchNorm16
I0925 20:26:02.499647  3547 net.cpp:84] Creating Layer BatchNorm16
I0925 20:26:02.499650  3547 net.cpp:406] BatchNorm16 <- Convolution16
I0925 20:26:02.499653  3547 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0925 20:26:02.499778  3547 net.cpp:122] Setting up BatchNorm16
I0925 20:26:02.499788  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.499791  3547 net.cpp:137] Memory required for data: 427437200
I0925 20:26:02.499796  3547 layer_factory.hpp:77] Creating layer Scale16
I0925 20:26:02.499801  3547 net.cpp:84] Creating Layer Scale16
I0925 20:26:02.499804  3547 net.cpp:406] Scale16 <- Convolution16
I0925 20:26:02.499806  3547 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0925 20:26:02.499832  3547 layer_factory.hpp:77] Creating layer Scale16
I0925 20:26:02.499907  3547 net.cpp:122] Setting up Scale16
I0925 20:26:02.499910  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.499913  3547 net.cpp:137] Memory required for data: 432454800
I0925 20:26:02.499917  3547 layer_factory.hpp:77] Creating layer PReLU16
I0925 20:26:02.499920  3547 net.cpp:84] Creating Layer PReLU16
I0925 20:26:02.499922  3547 net.cpp:406] PReLU16 <- Convolution16
I0925 20:26:02.499925  3547 net.cpp:367] PReLU16 -> Convolution16 (in-place)
I0925 20:26:02.499985  3547 net.cpp:122] Setting up PReLU16
I0925 20:26:02.499989  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.499991  3547 net.cpp:137] Memory required for data: 437472400
I0925 20:26:02.499994  3547 layer_factory.hpp:77] Creating layer Convolution17
I0925 20:26:02.500000  3547 net.cpp:84] Creating Layer Convolution17
I0925 20:26:02.500003  3547 net.cpp:406] Convolution17 <- Convolution16
I0925 20:26:02.500007  3547 net.cpp:380] Convolution17 -> Convolution17
I0925 20:26:02.500555  3547 net.cpp:122] Setting up Convolution17
I0925 20:26:02.500562  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.500564  3547 net.cpp:137] Memory required for data: 442490000
I0925 20:26:02.500577  3547 layer_factory.hpp:77] Creating layer BatchNorm17
I0925 20:26:02.500581  3547 net.cpp:84] Creating Layer BatchNorm17
I0925 20:26:02.500584  3547 net.cpp:406] BatchNorm17 <- Convolution17
I0925 20:26:02.500588  3547 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0925 20:26:02.500711  3547 net.cpp:122] Setting up BatchNorm17
I0925 20:26:02.500716  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.500718  3547 net.cpp:137] Memory required for data: 447507600
I0925 20:26:02.500723  3547 layer_factory.hpp:77] Creating layer Scale17
I0925 20:26:02.500727  3547 net.cpp:84] Creating Layer Scale17
I0925 20:26:02.500730  3547 net.cpp:406] Scale17 <- Convolution17
I0925 20:26:02.500732  3547 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0925 20:26:02.500757  3547 layer_factory.hpp:77] Creating layer Scale17
I0925 20:26:02.500829  3547 net.cpp:122] Setting up Scale17
I0925 20:26:02.500833  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.500835  3547 net.cpp:137] Memory required for data: 452525200
I0925 20:26:02.500839  3547 layer_factory.hpp:77] Creating layer Eltwise8
I0925 20:26:02.500844  3547 net.cpp:84] Creating Layer Eltwise8
I0925 20:26:02.500846  3547 net.cpp:406] Eltwise8 <- Eltwise7_PReLU15_0_split_1
I0925 20:26:02.500849  3547 net.cpp:406] Eltwise8 <- Convolution17
I0925 20:26:02.500852  3547 net.cpp:380] Eltwise8 -> Eltwise8
I0925 20:26:02.500866  3547 net.cpp:122] Setting up Eltwise8
I0925 20:26:02.500870  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.500872  3547 net.cpp:137] Memory required for data: 457542800
I0925 20:26:02.500874  3547 layer_factory.hpp:77] Creating layer PReLU17
I0925 20:26:02.500877  3547 net.cpp:84] Creating Layer PReLU17
I0925 20:26:02.500880  3547 net.cpp:406] PReLU17 <- Eltwise8
I0925 20:26:02.500883  3547 net.cpp:367] PReLU17 -> Eltwise8 (in-place)
I0925 20:26:02.500941  3547 net.cpp:122] Setting up PReLU17
I0925 20:26:02.500946  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.500948  3547 net.cpp:137] Memory required for data: 462560400
I0925 20:26:02.500952  3547 layer_factory.hpp:77] Creating layer Eltwise8_PReLU17_0_split
I0925 20:26:02.500954  3547 net.cpp:84] Creating Layer Eltwise8_PReLU17_0_split
I0925 20:26:02.500957  3547 net.cpp:406] Eltwise8_PReLU17_0_split <- Eltwise8
I0925 20:26:02.500960  3547 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_0
I0925 20:26:02.500972  3547 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_1
I0925 20:26:02.500993  3547 net.cpp:122] Setting up Eltwise8_PReLU17_0_split
I0925 20:26:02.500998  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.501000  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.501003  3547 net.cpp:137] Memory required for data: 472595600
I0925 20:26:02.501004  3547 layer_factory.hpp:77] Creating layer Convolution18
I0925 20:26:02.501010  3547 net.cpp:84] Creating Layer Convolution18
I0925 20:26:02.501013  3547 net.cpp:406] Convolution18 <- Eltwise8_PReLU17_0_split_0
I0925 20:26:02.501018  3547 net.cpp:380] Convolution18 -> Convolution18
I0925 20:26:02.501854  3547 net.cpp:122] Setting up Convolution18
I0925 20:26:02.501863  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.501866  3547 net.cpp:137] Memory required for data: 477613200
I0925 20:26:02.501870  3547 layer_factory.hpp:77] Creating layer BatchNorm18
I0925 20:26:02.501875  3547 net.cpp:84] Creating Layer BatchNorm18
I0925 20:26:02.501878  3547 net.cpp:406] BatchNorm18 <- Convolution18
I0925 20:26:02.501881  3547 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0925 20:26:02.502004  3547 net.cpp:122] Setting up BatchNorm18
I0925 20:26:02.502008  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.502010  3547 net.cpp:137] Memory required for data: 482630800
I0925 20:26:02.502015  3547 layer_factory.hpp:77] Creating layer Scale18
I0925 20:26:02.502019  3547 net.cpp:84] Creating Layer Scale18
I0925 20:26:02.502022  3547 net.cpp:406] Scale18 <- Convolution18
I0925 20:26:02.502024  3547 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0925 20:26:02.502048  3547 layer_factory.hpp:77] Creating layer Scale18
I0925 20:26:02.502122  3547 net.cpp:122] Setting up Scale18
I0925 20:26:02.502126  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.502128  3547 net.cpp:137] Memory required for data: 487648400
I0925 20:26:02.502132  3547 layer_factory.hpp:77] Creating layer PReLU18
I0925 20:26:02.502136  3547 net.cpp:84] Creating Layer PReLU18
I0925 20:26:02.502138  3547 net.cpp:406] PReLU18 <- Convolution18
I0925 20:26:02.502141  3547 net.cpp:367] PReLU18 -> Convolution18 (in-place)
I0925 20:26:02.502202  3547 net.cpp:122] Setting up PReLU18
I0925 20:26:02.502205  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.502208  3547 net.cpp:137] Memory required for data: 492666000
I0925 20:26:02.502212  3547 layer_factory.hpp:77] Creating layer Convolution19
I0925 20:26:02.502218  3547 net.cpp:84] Creating Layer Convolution19
I0925 20:26:02.502219  3547 net.cpp:406] Convolution19 <- Convolution18
I0925 20:26:02.502223  3547 net.cpp:380] Convolution19 -> Convolution19
I0925 20:26:02.503079  3547 net.cpp:122] Setting up Convolution19
I0925 20:26:02.503087  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.503090  3547 net.cpp:137] Memory required for data: 497683600
I0925 20:26:02.503095  3547 layer_factory.hpp:77] Creating layer BatchNorm19
I0925 20:26:02.503099  3547 net.cpp:84] Creating Layer BatchNorm19
I0925 20:26:02.503103  3547 net.cpp:406] BatchNorm19 <- Convolution19
I0925 20:26:02.503106  3547 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0925 20:26:02.503231  3547 net.cpp:122] Setting up BatchNorm19
I0925 20:26:02.503234  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.503237  3547 net.cpp:137] Memory required for data: 502701200
I0925 20:26:02.503242  3547 layer_factory.hpp:77] Creating layer Scale19
I0925 20:26:02.503245  3547 net.cpp:84] Creating Layer Scale19
I0925 20:26:02.503248  3547 net.cpp:406] Scale19 <- Convolution19
I0925 20:26:02.503252  3547 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0925 20:26:02.503276  3547 layer_factory.hpp:77] Creating layer Scale19
I0925 20:26:02.503348  3547 net.cpp:122] Setting up Scale19
I0925 20:26:02.503352  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.503355  3547 net.cpp:137] Memory required for data: 507718800
I0925 20:26:02.503365  3547 layer_factory.hpp:77] Creating layer Eltwise9
I0925 20:26:02.503370  3547 net.cpp:84] Creating Layer Eltwise9
I0925 20:26:02.503372  3547 net.cpp:406] Eltwise9 <- Eltwise8_PReLU17_0_split_1
I0925 20:26:02.503376  3547 net.cpp:406] Eltwise9 <- Convolution19
I0925 20:26:02.503378  3547 net.cpp:380] Eltwise9 -> Eltwise9
I0925 20:26:02.503394  3547 net.cpp:122] Setting up Eltwise9
I0925 20:26:02.503398  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.503401  3547 net.cpp:137] Memory required for data: 512736400
I0925 20:26:02.503402  3547 layer_factory.hpp:77] Creating layer PReLU19
I0925 20:26:02.503407  3547 net.cpp:84] Creating Layer PReLU19
I0925 20:26:02.503408  3547 net.cpp:406] PReLU19 <- Eltwise9
I0925 20:26:02.503412  3547 net.cpp:367] PReLU19 -> Eltwise9 (in-place)
I0925 20:26:02.503471  3547 net.cpp:122] Setting up PReLU19
I0925 20:26:02.503475  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.503479  3547 net.cpp:137] Memory required for data: 517754000
I0925 20:26:02.503481  3547 layer_factory.hpp:77] Creating layer Eltwise9_PReLU19_0_split
I0925 20:26:02.503484  3547 net.cpp:84] Creating Layer Eltwise9_PReLU19_0_split
I0925 20:26:02.503487  3547 net.cpp:406] Eltwise9_PReLU19_0_split <- Eltwise9
I0925 20:26:02.503490  3547 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_0
I0925 20:26:02.503494  3547 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_1
I0925 20:26:02.503515  3547 net.cpp:122] Setting up Eltwise9_PReLU19_0_split
I0925 20:26:02.503520  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.503522  3547 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0925 20:26:02.503525  3547 net.cpp:137] Memory required for data: 527789200
I0925 20:26:02.503526  3547 layer_factory.hpp:77] Creating layer Convolution20
I0925 20:26:02.503532  3547 net.cpp:84] Creating Layer Convolution20
I0925 20:26:02.503535  3547 net.cpp:406] Convolution20 <- Eltwise9_PReLU19_0_split_0
I0925 20:26:02.503540  3547 net.cpp:380] Convolution20 -> Convolution20
I0925 20:26:02.504688  3547 net.cpp:122] Setting up Convolution20
I0925 20:26:02.504696  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.504699  3547 net.cpp:137] Memory required for data: 530298000
I0925 20:26:02.504704  3547 layer_factory.hpp:77] Creating layer BatchNorm20
I0925 20:26:02.504709  3547 net.cpp:84] Creating Layer BatchNorm20
I0925 20:26:02.504711  3547 net.cpp:406] BatchNorm20 <- Convolution20
I0925 20:26:02.504716  3547 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0925 20:26:02.504894  3547 net.cpp:122] Setting up BatchNorm20
I0925 20:26:02.504899  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.504902  3547 net.cpp:137] Memory required for data: 532806800
I0925 20:26:02.504907  3547 layer_factory.hpp:77] Creating layer Scale20
I0925 20:26:02.504911  3547 net.cpp:84] Creating Layer Scale20
I0925 20:26:02.504914  3547 net.cpp:406] Scale20 <- Convolution20
I0925 20:26:02.504916  3547 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0925 20:26:02.504941  3547 layer_factory.hpp:77] Creating layer Scale20
I0925 20:26:02.505012  3547 net.cpp:122] Setting up Scale20
I0925 20:26:02.505017  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.505018  3547 net.cpp:137] Memory required for data: 535315600
I0925 20:26:02.505023  3547 layer_factory.hpp:77] Creating layer Convolution21
I0925 20:26:02.505029  3547 net.cpp:84] Creating Layer Convolution21
I0925 20:26:02.505031  3547 net.cpp:406] Convolution21 <- Eltwise9_PReLU19_0_split_1
I0925 20:26:02.505035  3547 net.cpp:380] Convolution21 -> Convolution21
I0925 20:26:02.506654  3547 net.cpp:122] Setting up Convolution21
I0925 20:26:02.506664  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.506666  3547 net.cpp:137] Memory required for data: 537824400
I0925 20:26:02.506671  3547 layer_factory.hpp:77] Creating layer BatchNorm21
I0925 20:26:02.506675  3547 net.cpp:84] Creating Layer BatchNorm21
I0925 20:26:02.506685  3547 net.cpp:406] BatchNorm21 <- Convolution21
I0925 20:26:02.506690  3547 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0925 20:26:02.506819  3547 net.cpp:122] Setting up BatchNorm21
I0925 20:26:02.506824  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.506825  3547 net.cpp:137] Memory required for data: 540333200
I0925 20:26:02.506831  3547 layer_factory.hpp:77] Creating layer Scale21
I0925 20:26:02.506835  3547 net.cpp:84] Creating Layer Scale21
I0925 20:26:02.506837  3547 net.cpp:406] Scale21 <- Convolution21
I0925 20:26:02.506841  3547 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0925 20:26:02.506876  3547 layer_factory.hpp:77] Creating layer Scale21
I0925 20:26:02.506973  3547 net.cpp:122] Setting up Scale21
I0925 20:26:02.506979  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.506981  3547 net.cpp:137] Memory required for data: 542842000
I0925 20:26:02.506989  3547 layer_factory.hpp:77] Creating layer PReLU20
I0925 20:26:02.506994  3547 net.cpp:84] Creating Layer PReLU20
I0925 20:26:02.506999  3547 net.cpp:406] PReLU20 <- Convolution21
I0925 20:26:02.507004  3547 net.cpp:367] PReLU20 -> Convolution21 (in-place)
I0925 20:26:02.507078  3547 net.cpp:122] Setting up PReLU20
I0925 20:26:02.507083  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.507086  3547 net.cpp:137] Memory required for data: 545350800
I0925 20:26:02.507088  3547 layer_factory.hpp:77] Creating layer Convolution22
I0925 20:26:02.507095  3547 net.cpp:84] Creating Layer Convolution22
I0925 20:26:02.507098  3547 net.cpp:406] Convolution22 <- Convolution21
I0925 20:26:02.507102  3547 net.cpp:380] Convolution22 -> Convolution22
I0925 20:26:02.508182  3547 net.cpp:122] Setting up Convolution22
I0925 20:26:02.508189  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.508193  3547 net.cpp:137] Memory required for data: 547859600
I0925 20:26:02.508196  3547 layer_factory.hpp:77] Creating layer BatchNorm22
I0925 20:26:02.508201  3547 net.cpp:84] Creating Layer BatchNorm22
I0925 20:26:02.508203  3547 net.cpp:406] BatchNorm22 <- Convolution22
I0925 20:26:02.508208  3547 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0925 20:26:02.508339  3547 net.cpp:122] Setting up BatchNorm22
I0925 20:26:02.508343  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.508347  3547 net.cpp:137] Memory required for data: 550368400
I0925 20:26:02.508352  3547 layer_factory.hpp:77] Creating layer Scale22
I0925 20:26:02.508355  3547 net.cpp:84] Creating Layer Scale22
I0925 20:26:02.508358  3547 net.cpp:406] Scale22 <- Convolution22
I0925 20:26:02.508360  3547 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0925 20:26:02.508384  3547 layer_factory.hpp:77] Creating layer Scale22
I0925 20:26:02.508464  3547 net.cpp:122] Setting up Scale22
I0925 20:26:02.508468  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.508471  3547 net.cpp:137] Memory required for data: 552877200
I0925 20:26:02.508474  3547 layer_factory.hpp:77] Creating layer Eltwise10
I0925 20:26:02.508478  3547 net.cpp:84] Creating Layer Eltwise10
I0925 20:26:02.508481  3547 net.cpp:406] Eltwise10 <- Convolution20
I0925 20:26:02.508483  3547 net.cpp:406] Eltwise10 <- Convolution22
I0925 20:26:02.508486  3547 net.cpp:380] Eltwise10 -> Eltwise10
I0925 20:26:02.508517  3547 net.cpp:122] Setting up Eltwise10
I0925 20:26:02.508530  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.508533  3547 net.cpp:137] Memory required for data: 555386000
I0925 20:26:02.508535  3547 layer_factory.hpp:77] Creating layer PReLU21
I0925 20:26:02.508538  3547 net.cpp:84] Creating Layer PReLU21
I0925 20:26:02.508541  3547 net.cpp:406] PReLU21 <- Eltwise10
I0925 20:26:02.508553  3547 net.cpp:367] PReLU21 -> Eltwise10 (in-place)
I0925 20:26:02.508608  3547 net.cpp:122] Setting up PReLU21
I0925 20:26:02.508613  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.508615  3547 net.cpp:137] Memory required for data: 557894800
I0925 20:26:02.508618  3547 layer_factory.hpp:77] Creating layer Eltwise10_PReLU21_0_split
I0925 20:26:02.508630  3547 net.cpp:84] Creating Layer Eltwise10_PReLU21_0_split
I0925 20:26:02.508631  3547 net.cpp:406] Eltwise10_PReLU21_0_split <- Eltwise10
I0925 20:26:02.508635  3547 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_0
I0925 20:26:02.508649  3547 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_1
I0925 20:26:02.508671  3547 net.cpp:122] Setting up Eltwise10_PReLU21_0_split
I0925 20:26:02.508675  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.508678  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.508680  3547 net.cpp:137] Memory required for data: 562912400
I0925 20:26:02.508682  3547 layer_factory.hpp:77] Creating layer Convolution23
I0925 20:26:02.508697  3547 net.cpp:84] Creating Layer Convolution23
I0925 20:26:02.508699  3547 net.cpp:406] Convolution23 <- Eltwise10_PReLU21_0_split_0
I0925 20:26:02.508703  3547 net.cpp:380] Convolution23 -> Convolution23
I0925 20:26:02.510006  3547 net.cpp:122] Setting up Convolution23
I0925 20:26:02.510015  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.510017  3547 net.cpp:137] Memory required for data: 565421200
I0925 20:26:02.510022  3547 layer_factory.hpp:77] Creating layer BatchNorm23
I0925 20:26:02.510026  3547 net.cpp:84] Creating Layer BatchNorm23
I0925 20:26:02.510030  3547 net.cpp:406] BatchNorm23 <- Convolution23
I0925 20:26:02.510033  3547 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0925 20:26:02.510159  3547 net.cpp:122] Setting up BatchNorm23
I0925 20:26:02.510164  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.510165  3547 net.cpp:137] Memory required for data: 567930000
I0925 20:26:02.510170  3547 layer_factory.hpp:77] Creating layer Scale23
I0925 20:26:02.510175  3547 net.cpp:84] Creating Layer Scale23
I0925 20:26:02.510177  3547 net.cpp:406] Scale23 <- Convolution23
I0925 20:26:02.510180  3547 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0925 20:26:02.510205  3547 layer_factory.hpp:77] Creating layer Scale23
I0925 20:26:02.510274  3547 net.cpp:122] Setting up Scale23
I0925 20:26:02.510278  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.510280  3547 net.cpp:137] Memory required for data: 570438800
I0925 20:26:02.510284  3547 layer_factory.hpp:77] Creating layer PReLU22
I0925 20:26:02.510288  3547 net.cpp:84] Creating Layer PReLU22
I0925 20:26:02.510290  3547 net.cpp:406] PReLU22 <- Convolution23
I0925 20:26:02.510293  3547 net.cpp:367] PReLU22 -> Convolution23 (in-place)
I0925 20:26:02.510347  3547 net.cpp:122] Setting up PReLU22
I0925 20:26:02.510351  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.510354  3547 net.cpp:137] Memory required for data: 572947600
I0925 20:26:02.510356  3547 layer_factory.hpp:77] Creating layer Convolution24
I0925 20:26:02.510362  3547 net.cpp:84] Creating Layer Convolution24
I0925 20:26:02.510365  3547 net.cpp:406] Convolution24 <- Convolution23
I0925 20:26:02.510368  3547 net.cpp:380] Convolution24 -> Convolution24
I0925 20:26:02.511348  3547 net.cpp:122] Setting up Convolution24
I0925 20:26:02.511358  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.511359  3547 net.cpp:137] Memory required for data: 575456400
I0925 20:26:02.511364  3547 layer_factory.hpp:77] Creating layer BatchNorm24
I0925 20:26:02.511368  3547 net.cpp:84] Creating Layer BatchNorm24
I0925 20:26:02.511371  3547 net.cpp:406] BatchNorm24 <- Convolution24
I0925 20:26:02.511374  3547 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0925 20:26:02.511498  3547 net.cpp:122] Setting up BatchNorm24
I0925 20:26:02.511502  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.511504  3547 net.cpp:137] Memory required for data: 577965200
I0925 20:26:02.511509  3547 layer_factory.hpp:77] Creating layer Scale24
I0925 20:26:02.511513  3547 net.cpp:84] Creating Layer Scale24
I0925 20:26:02.511515  3547 net.cpp:406] Scale24 <- Convolution24
I0925 20:26:02.511518  3547 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0925 20:26:02.511543  3547 layer_factory.hpp:77] Creating layer Scale24
I0925 20:26:02.511621  3547 net.cpp:122] Setting up Scale24
I0925 20:26:02.511626  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.511628  3547 net.cpp:137] Memory required for data: 580474000
I0925 20:26:02.511632  3547 layer_factory.hpp:77] Creating layer Eltwise11
I0925 20:26:02.511636  3547 net.cpp:84] Creating Layer Eltwise11
I0925 20:26:02.511639  3547 net.cpp:406] Eltwise11 <- Eltwise10_PReLU21_0_split_1
I0925 20:26:02.511642  3547 net.cpp:406] Eltwise11 <- Convolution24
I0925 20:26:02.511646  3547 net.cpp:380] Eltwise11 -> Eltwise11
I0925 20:26:02.511660  3547 net.cpp:122] Setting up Eltwise11
I0925 20:26:02.511663  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.511665  3547 net.cpp:137] Memory required for data: 582982800
I0925 20:26:02.511668  3547 layer_factory.hpp:77] Creating layer PReLU23
I0925 20:26:02.511672  3547 net.cpp:84] Creating Layer PReLU23
I0925 20:26:02.511673  3547 net.cpp:406] PReLU23 <- Eltwise11
I0925 20:26:02.511677  3547 net.cpp:367] PReLU23 -> Eltwise11 (in-place)
I0925 20:26:02.511731  3547 net.cpp:122] Setting up PReLU23
I0925 20:26:02.511736  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.511739  3547 net.cpp:137] Memory required for data: 585491600
I0925 20:26:02.511741  3547 layer_factory.hpp:77] Creating layer Eltwise11_PReLU23_0_split
I0925 20:26:02.511744  3547 net.cpp:84] Creating Layer Eltwise11_PReLU23_0_split
I0925 20:26:02.511746  3547 net.cpp:406] Eltwise11_PReLU23_0_split <- Eltwise11
I0925 20:26:02.511749  3547 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_0
I0925 20:26:02.511754  3547 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_1
I0925 20:26:02.511775  3547 net.cpp:122] Setting up Eltwise11_PReLU23_0_split
I0925 20:26:02.511780  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.511782  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.511785  3547 net.cpp:137] Memory required for data: 590509200
I0925 20:26:02.511786  3547 layer_factory.hpp:77] Creating layer Convolution25
I0925 20:26:02.511791  3547 net.cpp:84] Creating Layer Convolution25
I0925 20:26:02.511795  3547 net.cpp:406] Convolution25 <- Eltwise11_PReLU23_0_split_0
I0925 20:26:02.511798  3547 net.cpp:380] Convolution25 -> Convolution25
I0925 20:26:02.512811  3547 net.cpp:122] Setting up Convolution25
I0925 20:26:02.512820  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.512822  3547 net.cpp:137] Memory required for data: 593018000
I0925 20:26:02.512826  3547 layer_factory.hpp:77] Creating layer BatchNorm25
I0925 20:26:02.512831  3547 net.cpp:84] Creating Layer BatchNorm25
I0925 20:26:02.512835  3547 net.cpp:406] BatchNorm25 <- Convolution25
I0925 20:26:02.512837  3547 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0925 20:26:02.512961  3547 net.cpp:122] Setting up BatchNorm25
I0925 20:26:02.512965  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.512969  3547 net.cpp:137] Memory required for data: 595526800
I0925 20:26:02.512972  3547 layer_factory.hpp:77] Creating layer Scale25
I0925 20:26:02.512976  3547 net.cpp:84] Creating Layer Scale25
I0925 20:26:02.512979  3547 net.cpp:406] Scale25 <- Convolution25
I0925 20:26:02.512981  3547 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0925 20:26:02.513006  3547 layer_factory.hpp:77] Creating layer Scale25
I0925 20:26:02.513077  3547 net.cpp:122] Setting up Scale25
I0925 20:26:02.513082  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.513083  3547 net.cpp:137] Memory required for data: 598035600
I0925 20:26:02.513087  3547 layer_factory.hpp:77] Creating layer PReLU24
I0925 20:26:02.513092  3547 net.cpp:84] Creating Layer PReLU24
I0925 20:26:02.513093  3547 net.cpp:406] PReLU24 <- Convolution25
I0925 20:26:02.513097  3547 net.cpp:367] PReLU24 -> Convolution25 (in-place)
I0925 20:26:02.513151  3547 net.cpp:122] Setting up PReLU24
I0925 20:26:02.513155  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.513157  3547 net.cpp:137] Memory required for data: 600544400
I0925 20:26:02.513166  3547 layer_factory.hpp:77] Creating layer Convolution26
I0925 20:26:02.513173  3547 net.cpp:84] Creating Layer Convolution26
I0925 20:26:02.513175  3547 net.cpp:406] Convolution26 <- Convolution25
I0925 20:26:02.513180  3547 net.cpp:380] Convolution26 -> Convolution26
I0925 20:26:02.514156  3547 net.cpp:122] Setting up Convolution26
I0925 20:26:02.514164  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.514168  3547 net.cpp:137] Memory required for data: 603053200
I0925 20:26:02.514171  3547 layer_factory.hpp:77] Creating layer BatchNorm26
I0925 20:26:02.514175  3547 net.cpp:84] Creating Layer BatchNorm26
I0925 20:26:02.514178  3547 net.cpp:406] BatchNorm26 <- Convolution26
I0925 20:26:02.514183  3547 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0925 20:26:02.514304  3547 net.cpp:122] Setting up BatchNorm26
I0925 20:26:02.514308  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.514310  3547 net.cpp:137] Memory required for data: 605562000
I0925 20:26:02.514315  3547 layer_factory.hpp:77] Creating layer Scale26
I0925 20:26:02.514319  3547 net.cpp:84] Creating Layer Scale26
I0925 20:26:02.514322  3547 net.cpp:406] Scale26 <- Convolution26
I0925 20:26:02.514324  3547 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0925 20:26:02.514348  3547 layer_factory.hpp:77] Creating layer Scale26
I0925 20:26:02.514420  3547 net.cpp:122] Setting up Scale26
I0925 20:26:02.514423  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.514425  3547 net.cpp:137] Memory required for data: 608070800
I0925 20:26:02.514430  3547 layer_factory.hpp:77] Creating layer Eltwise12
I0925 20:26:02.514434  3547 net.cpp:84] Creating Layer Eltwise12
I0925 20:26:02.514436  3547 net.cpp:406] Eltwise12 <- Eltwise11_PReLU23_0_split_1
I0925 20:26:02.514439  3547 net.cpp:406] Eltwise12 <- Convolution26
I0925 20:26:02.514442  3547 net.cpp:380] Eltwise12 -> Eltwise12
I0925 20:26:02.514457  3547 net.cpp:122] Setting up Eltwise12
I0925 20:26:02.514461  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.514462  3547 net.cpp:137] Memory required for data: 610579600
I0925 20:26:02.514464  3547 layer_factory.hpp:77] Creating layer PReLU25
I0925 20:26:02.514468  3547 net.cpp:84] Creating Layer PReLU25
I0925 20:26:02.514470  3547 net.cpp:406] PReLU25 <- Eltwise12
I0925 20:26:02.514473  3547 net.cpp:367] PReLU25 -> Eltwise12 (in-place)
I0925 20:26:02.514528  3547 net.cpp:122] Setting up PReLU25
I0925 20:26:02.514533  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.514534  3547 net.cpp:137] Memory required for data: 613088400
I0925 20:26:02.514538  3547 layer_factory.hpp:77] Creating layer Eltwise12_PReLU25_0_split
I0925 20:26:02.514546  3547 net.cpp:84] Creating Layer Eltwise12_PReLU25_0_split
I0925 20:26:02.514549  3547 net.cpp:406] Eltwise12_PReLU25_0_split <- Eltwise12
I0925 20:26:02.514552  3547 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_0
I0925 20:26:02.514560  3547 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_1
I0925 20:26:02.514582  3547 net.cpp:122] Setting up Eltwise12_PReLU25_0_split
I0925 20:26:02.514585  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.514588  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.514590  3547 net.cpp:137] Memory required for data: 618106000
I0925 20:26:02.514593  3547 layer_factory.hpp:77] Creating layer Convolution27
I0925 20:26:02.514600  3547 net.cpp:84] Creating Layer Convolution27
I0925 20:26:02.514601  3547 net.cpp:406] Convolution27 <- Eltwise12_PReLU25_0_split_0
I0925 20:26:02.514605  3547 net.cpp:380] Convolution27 -> Convolution27
I0925 20:26:02.515266  3547 net.cpp:122] Setting up Convolution27
I0925 20:26:02.515275  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.515276  3547 net.cpp:137] Memory required for data: 620614800
I0925 20:26:02.515280  3547 layer_factory.hpp:77] Creating layer BatchNorm27
I0925 20:26:02.515285  3547 net.cpp:84] Creating Layer BatchNorm27
I0925 20:26:02.515293  3547 net.cpp:406] BatchNorm27 <- Convolution27
I0925 20:26:02.515297  3547 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0925 20:26:02.515424  3547 net.cpp:122] Setting up BatchNorm27
I0925 20:26:02.515427  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.515429  3547 net.cpp:137] Memory required for data: 623123600
I0925 20:26:02.515434  3547 layer_factory.hpp:77] Creating layer Scale27
I0925 20:26:02.515439  3547 net.cpp:84] Creating Layer Scale27
I0925 20:26:02.515440  3547 net.cpp:406] Scale27 <- Convolution27
I0925 20:26:02.515444  3547 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0925 20:26:02.515467  3547 layer_factory.hpp:77] Creating layer Scale27
I0925 20:26:02.515538  3547 net.cpp:122] Setting up Scale27
I0925 20:26:02.515542  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.515544  3547 net.cpp:137] Memory required for data: 625632400
I0925 20:26:02.515548  3547 layer_factory.hpp:77] Creating layer PReLU26
I0925 20:26:02.515552  3547 net.cpp:84] Creating Layer PReLU26
I0925 20:26:02.515553  3547 net.cpp:406] PReLU26 <- Convolution27
I0925 20:26:02.515557  3547 net.cpp:367] PReLU26 -> Convolution27 (in-place)
I0925 20:26:02.515612  3547 net.cpp:122] Setting up PReLU26
I0925 20:26:02.515616  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.515619  3547 net.cpp:137] Memory required for data: 628141200
I0925 20:26:02.515622  3547 layer_factory.hpp:77] Creating layer Convolution28
I0925 20:26:02.515628  3547 net.cpp:84] Creating Layer Convolution28
I0925 20:26:02.515630  3547 net.cpp:406] Convolution28 <- Convolution27
I0925 20:26:02.515635  3547 net.cpp:380] Convolution28 -> Convolution28
I0925 20:26:02.516671  3547 net.cpp:122] Setting up Convolution28
I0925 20:26:02.516680  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.516683  3547 net.cpp:137] Memory required for data: 630650000
I0925 20:26:02.516688  3547 layer_factory.hpp:77] Creating layer BatchNorm28
I0925 20:26:02.516693  3547 net.cpp:84] Creating Layer BatchNorm28
I0925 20:26:02.516696  3547 net.cpp:406] BatchNorm28 <- Convolution28
I0925 20:26:02.516700  3547 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0925 20:26:02.516835  3547 net.cpp:122] Setting up BatchNorm28
I0925 20:26:02.516840  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.516842  3547 net.cpp:137] Memory required for data: 633158800
I0925 20:26:02.516847  3547 layer_factory.hpp:77] Creating layer Scale28
I0925 20:26:02.516852  3547 net.cpp:84] Creating Layer Scale28
I0925 20:26:02.516855  3547 net.cpp:406] Scale28 <- Convolution28
I0925 20:26:02.516857  3547 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0925 20:26:02.516885  3547 layer_factory.hpp:77] Creating layer Scale28
I0925 20:26:02.516960  3547 net.cpp:122] Setting up Scale28
I0925 20:26:02.516964  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.516968  3547 net.cpp:137] Memory required for data: 635667600
I0925 20:26:02.516971  3547 layer_factory.hpp:77] Creating layer Eltwise13
I0925 20:26:02.516975  3547 net.cpp:84] Creating Layer Eltwise13
I0925 20:26:02.516978  3547 net.cpp:406] Eltwise13 <- Eltwise12_PReLU25_0_split_1
I0925 20:26:02.516981  3547 net.cpp:406] Eltwise13 <- Convolution28
I0925 20:26:02.516984  3547 net.cpp:380] Eltwise13 -> Eltwise13
I0925 20:26:02.517000  3547 net.cpp:122] Setting up Eltwise13
I0925 20:26:02.517004  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.517006  3547 net.cpp:137] Memory required for data: 638176400
I0925 20:26:02.517009  3547 layer_factory.hpp:77] Creating layer PReLU27
I0925 20:26:02.517012  3547 net.cpp:84] Creating Layer PReLU27
I0925 20:26:02.517015  3547 net.cpp:406] PReLU27 <- Eltwise13
I0925 20:26:02.517019  3547 net.cpp:367] PReLU27 -> Eltwise13 (in-place)
I0925 20:26:02.517077  3547 net.cpp:122] Setting up PReLU27
I0925 20:26:02.517082  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.517084  3547 net.cpp:137] Memory required for data: 640685200
I0925 20:26:02.517087  3547 layer_factory.hpp:77] Creating layer Eltwise13_PReLU27_0_split
I0925 20:26:02.517098  3547 net.cpp:84] Creating Layer Eltwise13_PReLU27_0_split
I0925 20:26:02.517102  3547 net.cpp:406] Eltwise13_PReLU27_0_split <- Eltwise13
I0925 20:26:02.517105  3547 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_0
I0925 20:26:02.517110  3547 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_1
I0925 20:26:02.517134  3547 net.cpp:122] Setting up Eltwise13_PReLU27_0_split
I0925 20:26:02.517138  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.517141  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.517143  3547 net.cpp:137] Memory required for data: 645702800
I0925 20:26:02.517146  3547 layer_factory.hpp:77] Creating layer Convolution29
I0925 20:26:02.517153  3547 net.cpp:84] Creating Layer Convolution29
I0925 20:26:02.517155  3547 net.cpp:406] Convolution29 <- Eltwise13_PReLU27_0_split_0
I0925 20:26:02.517159  3547 net.cpp:380] Convolution29 -> Convolution29
I0925 20:26:02.518149  3547 net.cpp:122] Setting up Convolution29
I0925 20:26:02.518157  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.518160  3547 net.cpp:137] Memory required for data: 648211600
I0925 20:26:02.518164  3547 layer_factory.hpp:77] Creating layer BatchNorm29
I0925 20:26:02.518169  3547 net.cpp:84] Creating Layer BatchNorm29
I0925 20:26:02.518172  3547 net.cpp:406] BatchNorm29 <- Convolution29
I0925 20:26:02.518175  3547 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0925 20:26:02.518307  3547 net.cpp:122] Setting up BatchNorm29
I0925 20:26:02.518311  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.518314  3547 net.cpp:137] Memory required for data: 650720400
I0925 20:26:02.518318  3547 layer_factory.hpp:77] Creating layer Scale29
I0925 20:26:02.518322  3547 net.cpp:84] Creating Layer Scale29
I0925 20:26:02.518326  3547 net.cpp:406] Scale29 <- Convolution29
I0925 20:26:02.518328  3547 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0925 20:26:02.518354  3547 layer_factory.hpp:77] Creating layer Scale29
I0925 20:26:02.518427  3547 net.cpp:122] Setting up Scale29
I0925 20:26:02.518431  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.518435  3547 net.cpp:137] Memory required for data: 653229200
I0925 20:26:02.518438  3547 layer_factory.hpp:77] Creating layer PReLU28
I0925 20:26:02.518441  3547 net.cpp:84] Creating Layer PReLU28
I0925 20:26:02.518443  3547 net.cpp:406] PReLU28 <- Convolution29
I0925 20:26:02.518446  3547 net.cpp:367] PReLU28 -> Convolution29 (in-place)
I0925 20:26:02.518503  3547 net.cpp:122] Setting up PReLU28
I0925 20:26:02.518507  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.518510  3547 net.cpp:137] Memory required for data: 655738000
I0925 20:26:02.518513  3547 layer_factory.hpp:77] Creating layer Convolution30
I0925 20:26:02.518519  3547 net.cpp:84] Creating Layer Convolution30
I0925 20:26:02.518522  3547 net.cpp:406] Convolution30 <- Convolution29
I0925 20:26:02.518525  3547 net.cpp:380] Convolution30 -> Convolution30
I0925 20:26:02.519526  3547 net.cpp:122] Setting up Convolution30
I0925 20:26:02.519534  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.519537  3547 net.cpp:137] Memory required for data: 658246800
I0925 20:26:02.519541  3547 layer_factory.hpp:77] Creating layer BatchNorm30
I0925 20:26:02.519546  3547 net.cpp:84] Creating Layer BatchNorm30
I0925 20:26:02.519549  3547 net.cpp:406] BatchNorm30 <- Convolution30
I0925 20:26:02.519552  3547 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0925 20:26:02.519675  3547 net.cpp:122] Setting up BatchNorm30
I0925 20:26:02.519680  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.519682  3547 net.cpp:137] Memory required for data: 660755600
I0925 20:26:02.519686  3547 layer_factory.hpp:77] Creating layer Scale30
I0925 20:26:02.519690  3547 net.cpp:84] Creating Layer Scale30
I0925 20:26:02.519693  3547 net.cpp:406] Scale30 <- Convolution30
I0925 20:26:02.519696  3547 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0925 20:26:02.519728  3547 layer_factory.hpp:77] Creating layer Scale30
I0925 20:26:02.519801  3547 net.cpp:122] Setting up Scale30
I0925 20:26:02.519805  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.519807  3547 net.cpp:137] Memory required for data: 663264400
I0925 20:26:02.519811  3547 layer_factory.hpp:77] Creating layer Eltwise14
I0925 20:26:02.519815  3547 net.cpp:84] Creating Layer Eltwise14
I0925 20:26:02.519817  3547 net.cpp:406] Eltwise14 <- Eltwise13_PReLU27_0_split_1
I0925 20:26:02.519820  3547 net.cpp:406] Eltwise14 <- Convolution30
I0925 20:26:02.519824  3547 net.cpp:380] Eltwise14 -> Eltwise14
I0925 20:26:02.519839  3547 net.cpp:122] Setting up Eltwise14
I0925 20:26:02.519842  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.519845  3547 net.cpp:137] Memory required for data: 665773200
I0925 20:26:02.519846  3547 layer_factory.hpp:77] Creating layer PReLU29
I0925 20:26:02.519850  3547 net.cpp:84] Creating Layer PReLU29
I0925 20:26:02.519851  3547 net.cpp:406] PReLU29 <- Eltwise14
I0925 20:26:02.519855  3547 net.cpp:367] PReLU29 -> Eltwise14 (in-place)
I0925 20:26:02.519911  3547 net.cpp:122] Setting up PReLU29
I0925 20:26:02.519914  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.519917  3547 net.cpp:137] Memory required for data: 668282000
I0925 20:26:02.519919  3547 layer_factory.hpp:77] Creating layer Eltwise14_PReLU29_0_split
I0925 20:26:02.519923  3547 net.cpp:84] Creating Layer Eltwise14_PReLU29_0_split
I0925 20:26:02.519925  3547 net.cpp:406] Eltwise14_PReLU29_0_split <- Eltwise14
I0925 20:26:02.519928  3547 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_0
I0925 20:26:02.519933  3547 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_1
I0925 20:26:02.519954  3547 net.cpp:122] Setting up Eltwise14_PReLU29_0_split
I0925 20:26:02.519958  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.519960  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.519963  3547 net.cpp:137] Memory required for data: 673299600
I0925 20:26:02.519964  3547 layer_factory.hpp:77] Creating layer Convolution31
I0925 20:26:02.519969  3547 net.cpp:84] Creating Layer Convolution31
I0925 20:26:02.519973  3547 net.cpp:406] Convolution31 <- Eltwise14_PReLU29_0_split_0
I0925 20:26:02.519975  3547 net.cpp:380] Convolution31 -> Convolution31
I0925 20:26:02.520984  3547 net.cpp:122] Setting up Convolution31
I0925 20:26:02.520993  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.520997  3547 net.cpp:137] Memory required for data: 675808400
I0925 20:26:02.521000  3547 layer_factory.hpp:77] Creating layer BatchNorm31
I0925 20:26:02.521005  3547 net.cpp:84] Creating Layer BatchNorm31
I0925 20:26:02.521008  3547 net.cpp:406] BatchNorm31 <- Convolution31
I0925 20:26:02.521011  3547 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0925 20:26:02.521139  3547 net.cpp:122] Setting up BatchNorm31
I0925 20:26:02.521143  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.521147  3547 net.cpp:137] Memory required for data: 678317200
I0925 20:26:02.521150  3547 layer_factory.hpp:77] Creating layer Scale31
I0925 20:26:02.521154  3547 net.cpp:84] Creating Layer Scale31
I0925 20:26:02.521157  3547 net.cpp:406] Scale31 <- Convolution31
I0925 20:26:02.521160  3547 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0925 20:26:02.521185  3547 layer_factory.hpp:77] Creating layer Scale31
I0925 20:26:02.521257  3547 net.cpp:122] Setting up Scale31
I0925 20:26:02.521261  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.521265  3547 net.cpp:137] Memory required for data: 680826000
I0925 20:26:02.521267  3547 layer_factory.hpp:77] Creating layer PReLU30
I0925 20:26:02.521271  3547 net.cpp:84] Creating Layer PReLU30
I0925 20:26:02.521273  3547 net.cpp:406] PReLU30 <- Convolution31
I0925 20:26:02.521276  3547 net.cpp:367] PReLU30 -> Convolution31 (in-place)
I0925 20:26:02.521333  3547 net.cpp:122] Setting up PReLU30
I0925 20:26:02.521338  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.521347  3547 net.cpp:137] Memory required for data: 683334800
I0925 20:26:02.521350  3547 layer_factory.hpp:77] Creating layer Convolution32
I0925 20:26:02.521356  3547 net.cpp:84] Creating Layer Convolution32
I0925 20:26:02.521359  3547 net.cpp:406] Convolution32 <- Convolution31
I0925 20:26:02.521363  3547 net.cpp:380] Convolution32 -> Convolution32
I0925 20:26:02.522374  3547 net.cpp:122] Setting up Convolution32
I0925 20:26:02.522383  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.522385  3547 net.cpp:137] Memory required for data: 685843600
I0925 20:26:02.522390  3547 layer_factory.hpp:77] Creating layer BatchNorm32
I0925 20:26:02.522394  3547 net.cpp:84] Creating Layer BatchNorm32
I0925 20:26:02.522397  3547 net.cpp:406] BatchNorm32 <- Convolution32
I0925 20:26:02.522400  3547 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0925 20:26:02.522526  3547 net.cpp:122] Setting up BatchNorm32
I0925 20:26:02.522531  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.522532  3547 net.cpp:137] Memory required for data: 688352400
I0925 20:26:02.522537  3547 layer_factory.hpp:77] Creating layer Scale32
I0925 20:26:02.522541  3547 net.cpp:84] Creating Layer Scale32
I0925 20:26:02.522543  3547 net.cpp:406] Scale32 <- Convolution32
I0925 20:26:02.522547  3547 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0925 20:26:02.522572  3547 layer_factory.hpp:77] Creating layer Scale32
I0925 20:26:02.522644  3547 net.cpp:122] Setting up Scale32
I0925 20:26:02.522647  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.522650  3547 net.cpp:137] Memory required for data: 690861200
I0925 20:26:02.522653  3547 layer_factory.hpp:77] Creating layer Eltwise15
I0925 20:26:02.522657  3547 net.cpp:84] Creating Layer Eltwise15
I0925 20:26:02.522660  3547 net.cpp:406] Eltwise15 <- Eltwise14_PReLU29_0_split_1
I0925 20:26:02.522663  3547 net.cpp:406] Eltwise15 <- Convolution32
I0925 20:26:02.522666  3547 net.cpp:380] Eltwise15 -> Eltwise15
I0925 20:26:02.522681  3547 net.cpp:122] Setting up Eltwise15
I0925 20:26:02.522685  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.522686  3547 net.cpp:137] Memory required for data: 693370000
I0925 20:26:02.522689  3547 layer_factory.hpp:77] Creating layer PReLU31
I0925 20:26:02.522692  3547 net.cpp:84] Creating Layer PReLU31
I0925 20:26:02.522694  3547 net.cpp:406] PReLU31 <- Eltwise15
I0925 20:26:02.522697  3547 net.cpp:367] PReLU31 -> Eltwise15 (in-place)
I0925 20:26:02.522753  3547 net.cpp:122] Setting up PReLU31
I0925 20:26:02.522758  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.522760  3547 net.cpp:137] Memory required for data: 695878800
I0925 20:26:02.522763  3547 layer_factory.hpp:77] Creating layer Eltwise15_PReLU31_0_split
I0925 20:26:02.522766  3547 net.cpp:84] Creating Layer Eltwise15_PReLU31_0_split
I0925 20:26:02.522768  3547 net.cpp:406] Eltwise15_PReLU31_0_split <- Eltwise15
I0925 20:26:02.522771  3547 net.cpp:380] Eltwise15_PReLU31_0_split -> Eltwise15_PReLU31_0_split_0
I0925 20:26:02.522776  3547 net.cpp:380] Eltwise15_PReLU31_0_split -> Eltwise15_PReLU31_0_split_1
I0925 20:26:02.522797  3547 net.cpp:122] Setting up Eltwise15_PReLU31_0_split
I0925 20:26:02.522801  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.522804  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.522806  3547 net.cpp:137] Memory required for data: 700896400
I0925 20:26:02.522809  3547 layer_factory.hpp:77] Creating layer Convolution33
I0925 20:26:02.522814  3547 net.cpp:84] Creating Layer Convolution33
I0925 20:26:02.522816  3547 net.cpp:406] Convolution33 <- Eltwise15_PReLU31_0_split_0
I0925 20:26:02.522820  3547 net.cpp:380] Convolution33 -> Convolution33
I0925 20:26:02.524211  3547 net.cpp:122] Setting up Convolution33
I0925 20:26:02.524220  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.524224  3547 net.cpp:137] Memory required for data: 703405200
I0925 20:26:02.524245  3547 layer_factory.hpp:77] Creating layer BatchNorm33
I0925 20:26:02.524250  3547 net.cpp:84] Creating Layer BatchNorm33
I0925 20:26:02.524260  3547 net.cpp:406] BatchNorm33 <- Convolution33
I0925 20:26:02.524266  3547 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0925 20:26:02.524406  3547 net.cpp:122] Setting up BatchNorm33
I0925 20:26:02.524410  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.524413  3547 net.cpp:137] Memory required for data: 705914000
I0925 20:26:02.524417  3547 layer_factory.hpp:77] Creating layer Scale33
I0925 20:26:02.524421  3547 net.cpp:84] Creating Layer Scale33
I0925 20:26:02.524425  3547 net.cpp:406] Scale33 <- Convolution33
I0925 20:26:02.524427  3547 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0925 20:26:02.524452  3547 layer_factory.hpp:77] Creating layer Scale33
I0925 20:26:02.524552  3547 net.cpp:122] Setting up Scale33
I0925 20:26:02.524557  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.524559  3547 net.cpp:137] Memory required for data: 708422800
I0925 20:26:02.524564  3547 layer_factory.hpp:77] Creating layer PReLU32
I0925 20:26:02.524567  3547 net.cpp:84] Creating Layer PReLU32
I0925 20:26:02.524569  3547 net.cpp:406] PReLU32 <- Convolution33
I0925 20:26:02.524574  3547 net.cpp:367] PReLU32 -> Convolution33 (in-place)
I0925 20:26:02.524631  3547 net.cpp:122] Setting up PReLU32
I0925 20:26:02.524634  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.524637  3547 net.cpp:137] Memory required for data: 710931600
I0925 20:26:02.524641  3547 layer_factory.hpp:77] Creating layer Convolution34
I0925 20:26:02.524647  3547 net.cpp:84] Creating Layer Convolution34
I0925 20:26:02.524649  3547 net.cpp:406] Convolution34 <- Convolution33
I0925 20:26:02.524653  3547 net.cpp:380] Convolution34 -> Convolution34
I0925 20:26:02.525647  3547 net.cpp:122] Setting up Convolution34
I0925 20:26:02.525656  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.525660  3547 net.cpp:137] Memory required for data: 713440400
I0925 20:26:02.525663  3547 layer_factory.hpp:77] Creating layer BatchNorm34
I0925 20:26:02.525667  3547 net.cpp:84] Creating Layer BatchNorm34
I0925 20:26:02.525671  3547 net.cpp:406] BatchNorm34 <- Convolution34
I0925 20:26:02.525673  3547 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0925 20:26:02.525801  3547 net.cpp:122] Setting up BatchNorm34
I0925 20:26:02.525805  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.525807  3547 net.cpp:137] Memory required for data: 715949200
I0925 20:26:02.525812  3547 layer_factory.hpp:77] Creating layer Scale34
I0925 20:26:02.525816  3547 net.cpp:84] Creating Layer Scale34
I0925 20:26:02.525818  3547 net.cpp:406] Scale34 <- Convolution34
I0925 20:26:02.525821  3547 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0925 20:26:02.525846  3547 layer_factory.hpp:77] Creating layer Scale34
I0925 20:26:02.525918  3547 net.cpp:122] Setting up Scale34
I0925 20:26:02.525921  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.525923  3547 net.cpp:137] Memory required for data: 718458000
I0925 20:26:02.525928  3547 layer_factory.hpp:77] Creating layer Eltwise16
I0925 20:26:02.525931  3547 net.cpp:84] Creating Layer Eltwise16
I0925 20:26:02.525933  3547 net.cpp:406] Eltwise16 <- Eltwise15_PReLU31_0_split_1
I0925 20:26:02.525936  3547 net.cpp:406] Eltwise16 <- Convolution34
I0925 20:26:02.525939  3547 net.cpp:380] Eltwise16 -> Eltwise16
I0925 20:26:02.525954  3547 net.cpp:122] Setting up Eltwise16
I0925 20:26:02.525959  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.525960  3547 net.cpp:137] Memory required for data: 720966800
I0925 20:26:02.525962  3547 layer_factory.hpp:77] Creating layer PReLU33
I0925 20:26:02.525965  3547 net.cpp:84] Creating Layer PReLU33
I0925 20:26:02.525967  3547 net.cpp:406] PReLU33 <- Eltwise16
I0925 20:26:02.525970  3547 net.cpp:367] PReLU33 -> Eltwise16 (in-place)
I0925 20:26:02.526026  3547 net.cpp:122] Setting up PReLU33
I0925 20:26:02.526031  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.526033  3547 net.cpp:137] Memory required for data: 723475600
I0925 20:26:02.526036  3547 layer_factory.hpp:77] Creating layer Eltwise16_PReLU33_0_split
I0925 20:26:02.526046  3547 net.cpp:84] Creating Layer Eltwise16_PReLU33_0_split
I0925 20:26:02.526049  3547 net.cpp:406] Eltwise16_PReLU33_0_split <- Eltwise16
I0925 20:26:02.526052  3547 net.cpp:380] Eltwise16_PReLU33_0_split -> Eltwise16_PReLU33_0_split_0
I0925 20:26:02.526057  3547 net.cpp:380] Eltwise16_PReLU33_0_split -> Eltwise16_PReLU33_0_split_1
I0925 20:26:02.526079  3547 net.cpp:122] Setting up Eltwise16_PReLU33_0_split
I0925 20:26:02.526082  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.526085  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.526087  3547 net.cpp:137] Memory required for data: 728493200
I0925 20:26:02.526089  3547 layer_factory.hpp:77] Creating layer Convolution35
I0925 20:26:02.526095  3547 net.cpp:84] Creating Layer Convolution35
I0925 20:26:02.526098  3547 net.cpp:406] Convolution35 <- Eltwise16_PReLU33_0_split_0
I0925 20:26:02.526101  3547 net.cpp:380] Convolution35 -> Convolution35
I0925 20:26:02.527093  3547 net.cpp:122] Setting up Convolution35
I0925 20:26:02.527101  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.527104  3547 net.cpp:137] Memory required for data: 731002000
I0925 20:26:02.527108  3547 layer_factory.hpp:77] Creating layer BatchNorm35
I0925 20:26:02.527113  3547 net.cpp:84] Creating Layer BatchNorm35
I0925 20:26:02.527117  3547 net.cpp:406] BatchNorm35 <- Convolution35
I0925 20:26:02.527120  3547 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0925 20:26:02.527246  3547 net.cpp:122] Setting up BatchNorm35
I0925 20:26:02.527251  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.527253  3547 net.cpp:137] Memory required for data: 733510800
I0925 20:26:02.527258  3547 layer_factory.hpp:77] Creating layer Scale35
I0925 20:26:02.527262  3547 net.cpp:84] Creating Layer Scale35
I0925 20:26:02.527264  3547 net.cpp:406] Scale35 <- Convolution35
I0925 20:26:02.527267  3547 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0925 20:26:02.527292  3547 layer_factory.hpp:77] Creating layer Scale35
I0925 20:26:02.527364  3547 net.cpp:122] Setting up Scale35
I0925 20:26:02.527369  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.527370  3547 net.cpp:137] Memory required for data: 736019600
I0925 20:26:02.527374  3547 layer_factory.hpp:77] Creating layer PReLU34
I0925 20:26:02.527377  3547 net.cpp:84] Creating Layer PReLU34
I0925 20:26:02.527380  3547 net.cpp:406] PReLU34 <- Convolution35
I0925 20:26:02.527384  3547 net.cpp:367] PReLU34 -> Convolution35 (in-place)
I0925 20:26:02.527439  3547 net.cpp:122] Setting up PReLU34
I0925 20:26:02.527444  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.527446  3547 net.cpp:137] Memory required for data: 738528400
I0925 20:26:02.527449  3547 layer_factory.hpp:77] Creating layer Convolution36
I0925 20:26:02.527456  3547 net.cpp:84] Creating Layer Convolution36
I0925 20:26:02.527458  3547 net.cpp:406] Convolution36 <- Convolution35
I0925 20:26:02.527465  3547 net.cpp:380] Convolution36 -> Convolution36
I0925 20:26:02.528486  3547 net.cpp:122] Setting up Convolution36
I0925 20:26:02.528509  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.528512  3547 net.cpp:137] Memory required for data: 741037200
I0925 20:26:02.528517  3547 layer_factory.hpp:77] Creating layer BatchNorm36
I0925 20:26:02.528522  3547 net.cpp:84] Creating Layer BatchNorm36
I0925 20:26:02.528524  3547 net.cpp:406] BatchNorm36 <- Convolution36
I0925 20:26:02.528528  3547 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0925 20:26:02.528671  3547 net.cpp:122] Setting up BatchNorm36
I0925 20:26:02.528676  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.528677  3547 net.cpp:137] Memory required for data: 743546000
I0925 20:26:02.528682  3547 layer_factory.hpp:77] Creating layer Scale36
I0925 20:26:02.528687  3547 net.cpp:84] Creating Layer Scale36
I0925 20:26:02.528688  3547 net.cpp:406] Scale36 <- Convolution36
I0925 20:26:02.528692  3547 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0925 20:26:02.528726  3547 layer_factory.hpp:77] Creating layer Scale36
I0925 20:26:02.528802  3547 net.cpp:122] Setting up Scale36
I0925 20:26:02.528807  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.528810  3547 net.cpp:137] Memory required for data: 746054800
I0925 20:26:02.528812  3547 layer_factory.hpp:77] Creating layer Eltwise17
I0925 20:26:02.528816  3547 net.cpp:84] Creating Layer Eltwise17
I0925 20:26:02.528820  3547 net.cpp:406] Eltwise17 <- Eltwise16_PReLU33_0_split_1
I0925 20:26:02.528822  3547 net.cpp:406] Eltwise17 <- Convolution36
I0925 20:26:02.528825  3547 net.cpp:380] Eltwise17 -> Eltwise17
I0925 20:26:02.528841  3547 net.cpp:122] Setting up Eltwise17
I0925 20:26:02.528846  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.528847  3547 net.cpp:137] Memory required for data: 748563600
I0925 20:26:02.528849  3547 layer_factory.hpp:77] Creating layer PReLU35
I0925 20:26:02.528852  3547 net.cpp:84] Creating Layer PReLU35
I0925 20:26:02.528854  3547 net.cpp:406] PReLU35 <- Eltwise17
I0925 20:26:02.528858  3547 net.cpp:367] PReLU35 -> Eltwise17 (in-place)
I0925 20:26:02.528916  3547 net.cpp:122] Setting up PReLU35
I0925 20:26:02.528920  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.528923  3547 net.cpp:137] Memory required for data: 751072400
I0925 20:26:02.528925  3547 layer_factory.hpp:77] Creating layer Eltwise17_PReLU35_0_split
I0925 20:26:02.528929  3547 net.cpp:84] Creating Layer Eltwise17_PReLU35_0_split
I0925 20:26:02.528931  3547 net.cpp:406] Eltwise17_PReLU35_0_split <- Eltwise17
I0925 20:26:02.528934  3547 net.cpp:380] Eltwise17_PReLU35_0_split -> Eltwise17_PReLU35_0_split_0
I0925 20:26:02.528939  3547 net.cpp:380] Eltwise17_PReLU35_0_split -> Eltwise17_PReLU35_0_split_1
I0925 20:26:02.528962  3547 net.cpp:122] Setting up Eltwise17_PReLU35_0_split
I0925 20:26:02.528966  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.528969  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.528970  3547 net.cpp:137] Memory required for data: 756090000
I0925 20:26:02.528972  3547 layer_factory.hpp:77] Creating layer Convolution37
I0925 20:26:02.528978  3547 net.cpp:84] Creating Layer Convolution37
I0925 20:26:02.528981  3547 net.cpp:406] Convolution37 <- Eltwise17_PReLU35_0_split_0
I0925 20:26:02.528985  3547 net.cpp:380] Convolution37 -> Convolution37
I0925 20:26:02.529675  3547 net.cpp:122] Setting up Convolution37
I0925 20:26:02.529683  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.529685  3547 net.cpp:137] Memory required for data: 758598800
I0925 20:26:02.529690  3547 layer_factory.hpp:77] Creating layer BatchNorm37
I0925 20:26:02.529695  3547 net.cpp:84] Creating Layer BatchNorm37
I0925 20:26:02.529696  3547 net.cpp:406] BatchNorm37 <- Convolution37
I0925 20:26:02.529700  3547 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0925 20:26:02.529830  3547 net.cpp:122] Setting up BatchNorm37
I0925 20:26:02.529835  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.529836  3547 net.cpp:137] Memory required for data: 761107600
I0925 20:26:02.529841  3547 layer_factory.hpp:77] Creating layer Scale37
I0925 20:26:02.529845  3547 net.cpp:84] Creating Layer Scale37
I0925 20:26:02.529847  3547 net.cpp:406] Scale37 <- Convolution37
I0925 20:26:02.529850  3547 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0925 20:26:02.529876  3547 layer_factory.hpp:77] Creating layer Scale37
I0925 20:26:02.529952  3547 net.cpp:122] Setting up Scale37
I0925 20:26:02.529956  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.529958  3547 net.cpp:137] Memory required for data: 763616400
I0925 20:26:02.529963  3547 layer_factory.hpp:77] Creating layer PReLU36
I0925 20:26:02.529965  3547 net.cpp:84] Creating Layer PReLU36
I0925 20:26:02.529968  3547 net.cpp:406] PReLU36 <- Convolution37
I0925 20:26:02.529970  3547 net.cpp:367] PReLU36 -> Convolution37 (in-place)
I0925 20:26:02.530028  3547 net.cpp:122] Setting up PReLU36
I0925 20:26:02.530032  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.530040  3547 net.cpp:137] Memory required for data: 766125200
I0925 20:26:02.530043  3547 layer_factory.hpp:77] Creating layer Convolution38
I0925 20:26:02.530050  3547 net.cpp:84] Creating Layer Convolution38
I0925 20:26:02.530051  3547 net.cpp:406] Convolution38 <- Convolution37
I0925 20:26:02.530055  3547 net.cpp:380] Convolution38 -> Convolution38
I0925 20:26:02.531090  3547 net.cpp:122] Setting up Convolution38
I0925 20:26:02.531098  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.531101  3547 net.cpp:137] Memory required for data: 768634000
I0925 20:26:02.531105  3547 layer_factory.hpp:77] Creating layer BatchNorm38
I0925 20:26:02.531111  3547 net.cpp:84] Creating Layer BatchNorm38
I0925 20:26:02.531113  3547 net.cpp:406] BatchNorm38 <- Convolution38
I0925 20:26:02.531116  3547 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0925 20:26:02.531250  3547 net.cpp:122] Setting up BatchNorm38
I0925 20:26:02.531255  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.531256  3547 net.cpp:137] Memory required for data: 771142800
I0925 20:26:02.531261  3547 layer_factory.hpp:77] Creating layer Scale38
I0925 20:26:02.531265  3547 net.cpp:84] Creating Layer Scale38
I0925 20:26:02.531267  3547 net.cpp:406] Scale38 <- Convolution38
I0925 20:26:02.531270  3547 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0925 20:26:02.531297  3547 layer_factory.hpp:77] Creating layer Scale38
I0925 20:26:02.531371  3547 net.cpp:122] Setting up Scale38
I0925 20:26:02.531376  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.531378  3547 net.cpp:137] Memory required for data: 773651600
I0925 20:26:02.531381  3547 layer_factory.hpp:77] Creating layer Eltwise18
I0925 20:26:02.531386  3547 net.cpp:84] Creating Layer Eltwise18
I0925 20:26:02.531388  3547 net.cpp:406] Eltwise18 <- Eltwise17_PReLU35_0_split_1
I0925 20:26:02.531391  3547 net.cpp:406] Eltwise18 <- Convolution38
I0925 20:26:02.531394  3547 net.cpp:380] Eltwise18 -> Eltwise18
I0925 20:26:02.531410  3547 net.cpp:122] Setting up Eltwise18
I0925 20:26:02.531414  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.531415  3547 net.cpp:137] Memory required for data: 776160400
I0925 20:26:02.531417  3547 layer_factory.hpp:77] Creating layer PReLU37
I0925 20:26:02.531421  3547 net.cpp:84] Creating Layer PReLU37
I0925 20:26:02.531424  3547 net.cpp:406] PReLU37 <- Eltwise18
I0925 20:26:02.531426  3547 net.cpp:367] PReLU37 -> Eltwise18 (in-place)
I0925 20:26:02.531486  3547 net.cpp:122] Setting up PReLU37
I0925 20:26:02.531491  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.531492  3547 net.cpp:137] Memory required for data: 778669200
I0925 20:26:02.531494  3547 layer_factory.hpp:77] Creating layer Eltwise18_PReLU37_0_split
I0925 20:26:02.531498  3547 net.cpp:84] Creating Layer Eltwise18_PReLU37_0_split
I0925 20:26:02.531502  3547 net.cpp:406] Eltwise18_PReLU37_0_split <- Eltwise18
I0925 20:26:02.531504  3547 net.cpp:380] Eltwise18_PReLU37_0_split -> Eltwise18_PReLU37_0_split_0
I0925 20:26:02.531508  3547 net.cpp:380] Eltwise18_PReLU37_0_split -> Eltwise18_PReLU37_0_split_1
I0925 20:26:02.531532  3547 net.cpp:122] Setting up Eltwise18_PReLU37_0_split
I0925 20:26:02.531534  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.531538  3547 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0925 20:26:02.531539  3547 net.cpp:137] Memory required for data: 783686800
I0925 20:26:02.531541  3547 layer_factory.hpp:77] Creating layer Convolution39
I0925 20:26:02.531548  3547 net.cpp:84] Creating Layer Convolution39
I0925 20:26:02.531549  3547 net.cpp:406] Convolution39 <- Eltwise18_PReLU37_0_split_0
I0925 20:26:02.531554  3547 net.cpp:380] Convolution39 -> Convolution39
I0925 20:26:02.532421  3547 net.cpp:122] Setting up Convolution39
I0925 20:26:02.532429  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.532433  3547 net.cpp:137] Memory required for data: 784941200
I0925 20:26:02.532438  3547 layer_factory.hpp:77] Creating layer BatchNorm39
I0925 20:26:02.532441  3547 net.cpp:84] Creating Layer BatchNorm39
I0925 20:26:02.532450  3547 net.cpp:406] BatchNorm39 <- Convolution39
I0925 20:26:02.532454  3547 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0925 20:26:02.532615  3547 net.cpp:122] Setting up BatchNorm39
I0925 20:26:02.532621  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.532624  3547 net.cpp:137] Memory required for data: 786195600
I0925 20:26:02.532629  3547 layer_factory.hpp:77] Creating layer Scale39
I0925 20:26:02.532632  3547 net.cpp:84] Creating Layer Scale39
I0925 20:26:02.532634  3547 net.cpp:406] Scale39 <- Convolution39
I0925 20:26:02.532637  3547 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0925 20:26:02.532665  3547 layer_factory.hpp:77] Creating layer Scale39
I0925 20:26:02.532742  3547 net.cpp:122] Setting up Scale39
I0925 20:26:02.532747  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.532748  3547 net.cpp:137] Memory required for data: 787450000
I0925 20:26:02.532752  3547 layer_factory.hpp:77] Creating layer Convolution40
I0925 20:26:02.532758  3547 net.cpp:84] Creating Layer Convolution40
I0925 20:26:02.532762  3547 net.cpp:406] Convolution40 <- Eltwise18_PReLU37_0_split_1
I0925 20:26:02.532765  3547 net.cpp:380] Convolution40 -> Convolution40
I0925 20:26:02.534555  3547 net.cpp:122] Setting up Convolution40
I0925 20:26:02.534567  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.534570  3547 net.cpp:137] Memory required for data: 788704400
I0925 20:26:02.534575  3547 layer_factory.hpp:77] Creating layer BatchNorm40
I0925 20:26:02.534580  3547 net.cpp:84] Creating Layer BatchNorm40
I0925 20:26:02.534582  3547 net.cpp:406] BatchNorm40 <- Convolution40
I0925 20:26:02.534587  3547 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0925 20:26:02.534739  3547 net.cpp:122] Setting up BatchNorm40
I0925 20:26:02.534744  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.534745  3547 net.cpp:137] Memory required for data: 789958800
I0925 20:26:02.534750  3547 layer_factory.hpp:77] Creating layer Scale40
I0925 20:26:02.534755  3547 net.cpp:84] Creating Layer Scale40
I0925 20:26:02.534759  3547 net.cpp:406] Scale40 <- Convolution40
I0925 20:26:02.534761  3547 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0925 20:26:02.534791  3547 layer_factory.hpp:77] Creating layer Scale40
I0925 20:26:02.534876  3547 net.cpp:122] Setting up Scale40
I0925 20:26:02.534881  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.534883  3547 net.cpp:137] Memory required for data: 791213200
I0925 20:26:02.534888  3547 layer_factory.hpp:77] Creating layer PReLU38
I0925 20:26:02.534891  3547 net.cpp:84] Creating Layer PReLU38
I0925 20:26:02.534894  3547 net.cpp:406] PReLU38 <- Convolution40
I0925 20:26:02.534898  3547 net.cpp:367] PReLU38 -> Convolution40 (in-place)
I0925 20:26:02.534961  3547 net.cpp:122] Setting up PReLU38
I0925 20:26:02.534966  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.534968  3547 net.cpp:137] Memory required for data: 792467600
I0925 20:26:02.534971  3547 layer_factory.hpp:77] Creating layer Convolution41
I0925 20:26:02.534978  3547 net.cpp:84] Creating Layer Convolution41
I0925 20:26:02.534981  3547 net.cpp:406] Convolution41 <- Convolution40
I0925 20:26:02.534986  3547 net.cpp:380] Convolution41 -> Convolution41
I0925 20:26:02.536972  3547 net.cpp:122] Setting up Convolution41
I0925 20:26:02.536980  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.536983  3547 net.cpp:137] Memory required for data: 793722000
I0925 20:26:02.536988  3547 layer_factory.hpp:77] Creating layer BatchNorm41
I0925 20:26:02.536993  3547 net.cpp:84] Creating Layer BatchNorm41
I0925 20:26:02.536995  3547 net.cpp:406] BatchNorm41 <- Convolution41
I0925 20:26:02.536999  3547 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0925 20:26:02.537184  3547 net.cpp:122] Setting up BatchNorm41
I0925 20:26:02.537192  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.537196  3547 net.cpp:137] Memory required for data: 794976400
I0925 20:26:02.537204  3547 layer_factory.hpp:77] Creating layer Scale41
I0925 20:26:02.537221  3547 net.cpp:84] Creating Layer Scale41
I0925 20:26:02.537225  3547 net.cpp:406] Scale41 <- Convolution41
I0925 20:26:02.537228  3547 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0925 20:26:02.537258  3547 layer_factory.hpp:77] Creating layer Scale41
I0925 20:26:02.537338  3547 net.cpp:122] Setting up Scale41
I0925 20:26:02.537343  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.537345  3547 net.cpp:137] Memory required for data: 796230800
I0925 20:26:02.537349  3547 layer_factory.hpp:77] Creating layer Eltwise19
I0925 20:26:02.537353  3547 net.cpp:84] Creating Layer Eltwise19
I0925 20:26:02.537356  3547 net.cpp:406] Eltwise19 <- Convolution39
I0925 20:26:02.537359  3547 net.cpp:406] Eltwise19 <- Convolution41
I0925 20:26:02.537364  3547 net.cpp:380] Eltwise19 -> Eltwise19
I0925 20:26:02.537379  3547 net.cpp:122] Setting up Eltwise19
I0925 20:26:02.537382  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.537384  3547 net.cpp:137] Memory required for data: 797485200
I0925 20:26:02.537386  3547 layer_factory.hpp:77] Creating layer PReLU39
I0925 20:26:02.537391  3547 net.cpp:84] Creating Layer PReLU39
I0925 20:26:02.537394  3547 net.cpp:406] PReLU39 <- Eltwise19
I0925 20:26:02.537396  3547 net.cpp:367] PReLU39 -> Eltwise19 (in-place)
I0925 20:26:02.537456  3547 net.cpp:122] Setting up PReLU39
I0925 20:26:02.537461  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.537463  3547 net.cpp:137] Memory required for data: 798739600
I0925 20:26:02.537467  3547 layer_factory.hpp:77] Creating layer Eltwise19_PReLU39_0_split
I0925 20:26:02.537470  3547 net.cpp:84] Creating Layer Eltwise19_PReLU39_0_split
I0925 20:26:02.537472  3547 net.cpp:406] Eltwise19_PReLU39_0_split <- Eltwise19
I0925 20:26:02.537475  3547 net.cpp:380] Eltwise19_PReLU39_0_split -> Eltwise19_PReLU39_0_split_0
I0925 20:26:02.537479  3547 net.cpp:380] Eltwise19_PReLU39_0_split -> Eltwise19_PReLU39_0_split_1
I0925 20:26:02.537503  3547 net.cpp:122] Setting up Eltwise19_PReLU39_0_split
I0925 20:26:02.537508  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.537510  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.537513  3547 net.cpp:137] Memory required for data: 801248400
I0925 20:26:02.537514  3547 layer_factory.hpp:77] Creating layer Convolution42
I0925 20:26:02.537520  3547 net.cpp:84] Creating Layer Convolution42
I0925 20:26:02.537523  3547 net.cpp:406] Convolution42 <- Eltwise19_PReLU39_0_split_0
I0925 20:26:02.537528  3547 net.cpp:380] Convolution42 -> Convolution42
I0925 20:26:02.539572  3547 net.cpp:122] Setting up Convolution42
I0925 20:26:02.539582  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.539584  3547 net.cpp:137] Memory required for data: 802502800
I0925 20:26:02.539589  3547 layer_factory.hpp:77] Creating layer BatchNorm42
I0925 20:26:02.539593  3547 net.cpp:84] Creating Layer BatchNorm42
I0925 20:26:02.539597  3547 net.cpp:406] BatchNorm42 <- Convolution42
I0925 20:26:02.539600  3547 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0925 20:26:02.539736  3547 net.cpp:122] Setting up BatchNorm42
I0925 20:26:02.539741  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.539742  3547 net.cpp:137] Memory required for data: 803757200
I0925 20:26:02.539747  3547 layer_factory.hpp:77] Creating layer Scale42
I0925 20:26:02.539752  3547 net.cpp:84] Creating Layer Scale42
I0925 20:26:02.539753  3547 net.cpp:406] Scale42 <- Convolution42
I0925 20:26:02.539757  3547 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0925 20:26:02.539784  3547 layer_factory.hpp:77] Creating layer Scale42
I0925 20:26:02.539861  3547 net.cpp:122] Setting up Scale42
I0925 20:26:02.539866  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.539868  3547 net.cpp:137] Memory required for data: 805011600
I0925 20:26:02.539871  3547 layer_factory.hpp:77] Creating layer PReLU40
I0925 20:26:02.539877  3547 net.cpp:84] Creating Layer PReLU40
I0925 20:26:02.539880  3547 net.cpp:406] PReLU40 <- Convolution42
I0925 20:26:02.539890  3547 net.cpp:367] PReLU40 -> Convolution42 (in-place)
I0925 20:26:02.539952  3547 net.cpp:122] Setting up PReLU40
I0925 20:26:02.539957  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.539958  3547 net.cpp:137] Memory required for data: 806266000
I0925 20:26:02.539961  3547 layer_factory.hpp:77] Creating layer Convolution43
I0925 20:26:02.539966  3547 net.cpp:84] Creating Layer Convolution43
I0925 20:26:02.539969  3547 net.cpp:406] Convolution43 <- Convolution42
I0925 20:26:02.539973  3547 net.cpp:380] Convolution43 -> Convolution43
I0925 20:26:02.542392  3547 net.cpp:122] Setting up Convolution43
I0925 20:26:02.542402  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.542405  3547 net.cpp:137] Memory required for data: 807520400
I0925 20:26:02.542410  3547 layer_factory.hpp:77] Creating layer BatchNorm43
I0925 20:26:02.542415  3547 net.cpp:84] Creating Layer BatchNorm43
I0925 20:26:02.542418  3547 net.cpp:406] BatchNorm43 <- Convolution43
I0925 20:26:02.542423  3547 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0925 20:26:02.542565  3547 net.cpp:122] Setting up BatchNorm43
I0925 20:26:02.542570  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.542572  3547 net.cpp:137] Memory required for data: 808774800
I0925 20:26:02.542577  3547 layer_factory.hpp:77] Creating layer Scale43
I0925 20:26:02.542582  3547 net.cpp:84] Creating Layer Scale43
I0925 20:26:02.542583  3547 net.cpp:406] Scale43 <- Convolution43
I0925 20:26:02.542587  3547 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0925 20:26:02.542615  3547 layer_factory.hpp:77] Creating layer Scale43
I0925 20:26:02.542695  3547 net.cpp:122] Setting up Scale43
I0925 20:26:02.542701  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.542702  3547 net.cpp:137] Memory required for data: 810029200
I0925 20:26:02.542706  3547 layer_factory.hpp:77] Creating layer Eltwise20
I0925 20:26:02.542711  3547 net.cpp:84] Creating Layer Eltwise20
I0925 20:26:02.542713  3547 net.cpp:406] Eltwise20 <- Eltwise19_PReLU39_0_split_1
I0925 20:26:02.542716  3547 net.cpp:406] Eltwise20 <- Convolution43
I0925 20:26:02.542721  3547 net.cpp:380] Eltwise20 -> Eltwise20
I0925 20:26:02.542735  3547 net.cpp:122] Setting up Eltwise20
I0925 20:26:02.542740  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.542742  3547 net.cpp:137] Memory required for data: 811283600
I0925 20:26:02.542744  3547 layer_factory.hpp:77] Creating layer PReLU41
I0925 20:26:02.542747  3547 net.cpp:84] Creating Layer PReLU41
I0925 20:26:02.542750  3547 net.cpp:406] PReLU41 <- Eltwise20
I0925 20:26:02.542753  3547 net.cpp:367] PReLU41 -> Eltwise20 (in-place)
I0925 20:26:02.542815  3547 net.cpp:122] Setting up PReLU41
I0925 20:26:02.542819  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.542821  3547 net.cpp:137] Memory required for data: 812538000
I0925 20:26:02.542824  3547 layer_factory.hpp:77] Creating layer Eltwise20_PReLU41_0_split
I0925 20:26:02.542829  3547 net.cpp:84] Creating Layer Eltwise20_PReLU41_0_split
I0925 20:26:02.542831  3547 net.cpp:406] Eltwise20_PReLU41_0_split <- Eltwise20
I0925 20:26:02.542834  3547 net.cpp:380] Eltwise20_PReLU41_0_split -> Eltwise20_PReLU41_0_split_0
I0925 20:26:02.542839  3547 net.cpp:380] Eltwise20_PReLU41_0_split -> Eltwise20_PReLU41_0_split_1
I0925 20:26:02.542863  3547 net.cpp:122] Setting up Eltwise20_PReLU41_0_split
I0925 20:26:02.542866  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.542870  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.542871  3547 net.cpp:137] Memory required for data: 815046800
I0925 20:26:02.542873  3547 layer_factory.hpp:77] Creating layer Convolution44
I0925 20:26:02.542881  3547 net.cpp:84] Creating Layer Convolution44
I0925 20:26:02.542882  3547 net.cpp:406] Convolution44 <- Eltwise20_PReLU41_0_split_0
I0925 20:26:02.542887  3547 net.cpp:380] Convolution44 -> Convolution44
I0925 20:26:02.544567  3547 net.cpp:122] Setting up Convolution44
I0925 20:26:02.544576  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.544586  3547 net.cpp:137] Memory required for data: 816301200
I0925 20:26:02.544591  3547 layer_factory.hpp:77] Creating layer BatchNorm44
I0925 20:26:02.544596  3547 net.cpp:84] Creating Layer BatchNorm44
I0925 20:26:02.544600  3547 net.cpp:406] BatchNorm44 <- Convolution44
I0925 20:26:02.544603  3547 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0925 20:26:02.544744  3547 net.cpp:122] Setting up BatchNorm44
I0925 20:26:02.544749  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.544750  3547 net.cpp:137] Memory required for data: 817555600
I0925 20:26:02.544754  3547 layer_factory.hpp:77] Creating layer Scale44
I0925 20:26:02.544759  3547 net.cpp:84] Creating Layer Scale44
I0925 20:26:02.544761  3547 net.cpp:406] Scale44 <- Convolution44
I0925 20:26:02.544765  3547 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0925 20:26:02.544792  3547 layer_factory.hpp:77] Creating layer Scale44
I0925 20:26:02.544874  3547 net.cpp:122] Setting up Scale44
I0925 20:26:02.544879  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.544881  3547 net.cpp:137] Memory required for data: 818810000
I0925 20:26:02.544885  3547 layer_factory.hpp:77] Creating layer PReLU42
I0925 20:26:02.544889  3547 net.cpp:84] Creating Layer PReLU42
I0925 20:26:02.544891  3547 net.cpp:406] PReLU42 <- Convolution44
I0925 20:26:02.544895  3547 net.cpp:367] PReLU42 -> Convolution44 (in-place)
I0925 20:26:02.544958  3547 net.cpp:122] Setting up PReLU42
I0925 20:26:02.544963  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.544965  3547 net.cpp:137] Memory required for data: 820064400
I0925 20:26:02.544967  3547 layer_factory.hpp:77] Creating layer Convolution45
I0925 20:26:02.544975  3547 net.cpp:84] Creating Layer Convolution45
I0925 20:26:02.544976  3547 net.cpp:406] Convolution45 <- Convolution44
I0925 20:26:02.544981  3547 net.cpp:380] Convolution45 -> Convolution45
I0925 20:26:02.546949  3547 net.cpp:122] Setting up Convolution45
I0925 20:26:02.546958  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.546960  3547 net.cpp:137] Memory required for data: 821318800
I0925 20:26:02.546967  3547 layer_factory.hpp:77] Creating layer BatchNorm45
I0925 20:26:02.546972  3547 net.cpp:84] Creating Layer BatchNorm45
I0925 20:26:02.546973  3547 net.cpp:406] BatchNorm45 <- Convolution45
I0925 20:26:02.546977  3547 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0925 20:26:02.547123  3547 net.cpp:122] Setting up BatchNorm45
I0925 20:26:02.547128  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.547130  3547 net.cpp:137] Memory required for data: 822573200
I0925 20:26:02.547135  3547 layer_factory.hpp:77] Creating layer Scale45
I0925 20:26:02.547139  3547 net.cpp:84] Creating Layer Scale45
I0925 20:26:02.547142  3547 net.cpp:406] Scale45 <- Convolution45
I0925 20:26:02.547145  3547 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0925 20:26:02.547173  3547 layer_factory.hpp:77] Creating layer Scale45
I0925 20:26:02.547256  3547 net.cpp:122] Setting up Scale45
I0925 20:26:02.547261  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.547263  3547 net.cpp:137] Memory required for data: 823827600
I0925 20:26:02.547267  3547 layer_factory.hpp:77] Creating layer Eltwise21
I0925 20:26:02.547271  3547 net.cpp:84] Creating Layer Eltwise21
I0925 20:26:02.547273  3547 net.cpp:406] Eltwise21 <- Eltwise20_PReLU41_0_split_1
I0925 20:26:02.547276  3547 net.cpp:406] Eltwise21 <- Convolution45
I0925 20:26:02.547279  3547 net.cpp:380] Eltwise21 -> Eltwise21
I0925 20:26:02.547297  3547 net.cpp:122] Setting up Eltwise21
I0925 20:26:02.547300  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.547302  3547 net.cpp:137] Memory required for data: 825082000
I0925 20:26:02.547304  3547 layer_factory.hpp:77] Creating layer PReLU43
I0925 20:26:02.547308  3547 net.cpp:84] Creating Layer PReLU43
I0925 20:26:02.547312  3547 net.cpp:406] PReLU43 <- Eltwise21
I0925 20:26:02.547314  3547 net.cpp:367] PReLU43 -> Eltwise21 (in-place)
I0925 20:26:02.547384  3547 net.cpp:122] Setting up PReLU43
I0925 20:26:02.547394  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.547396  3547 net.cpp:137] Memory required for data: 826336400
I0925 20:26:02.547399  3547 layer_factory.hpp:77] Creating layer Eltwise21_PReLU43_0_split
I0925 20:26:02.547404  3547 net.cpp:84] Creating Layer Eltwise21_PReLU43_0_split
I0925 20:26:02.547405  3547 net.cpp:406] Eltwise21_PReLU43_0_split <- Eltwise21
I0925 20:26:02.547410  3547 net.cpp:380] Eltwise21_PReLU43_0_split -> Eltwise21_PReLU43_0_split_0
I0925 20:26:02.547413  3547 net.cpp:380] Eltwise21_PReLU43_0_split -> Eltwise21_PReLU43_0_split_1
I0925 20:26:02.547438  3547 net.cpp:122] Setting up Eltwise21_PReLU43_0_split
I0925 20:26:02.547442  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.547446  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.547447  3547 net.cpp:137] Memory required for data: 828845200
I0925 20:26:02.547449  3547 layer_factory.hpp:77] Creating layer Convolution46
I0925 20:26:02.547456  3547 net.cpp:84] Creating Layer Convolution46
I0925 20:26:02.547458  3547 net.cpp:406] Convolution46 <- Eltwise21_PReLU43_0_split_0
I0925 20:26:02.547462  3547 net.cpp:380] Convolution46 -> Convolution46
I0925 20:26:02.549134  3547 net.cpp:122] Setting up Convolution46
I0925 20:26:02.549144  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.549145  3547 net.cpp:137] Memory required for data: 830099600
I0925 20:26:02.549149  3547 layer_factory.hpp:77] Creating layer BatchNorm46
I0925 20:26:02.549154  3547 net.cpp:84] Creating Layer BatchNorm46
I0925 20:26:02.549156  3547 net.cpp:406] BatchNorm46 <- Convolution46
I0925 20:26:02.549161  3547 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0925 20:26:02.549300  3547 net.cpp:122] Setting up BatchNorm46
I0925 20:26:02.549305  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.549307  3547 net.cpp:137] Memory required for data: 831354000
I0925 20:26:02.549312  3547 layer_factory.hpp:77] Creating layer Scale46
I0925 20:26:02.549316  3547 net.cpp:84] Creating Layer Scale46
I0925 20:26:02.549319  3547 net.cpp:406] Scale46 <- Convolution46
I0925 20:26:02.549322  3547 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0925 20:26:02.549358  3547 layer_factory.hpp:77] Creating layer Scale46
I0925 20:26:02.549440  3547 net.cpp:122] Setting up Scale46
I0925 20:26:02.549445  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.549448  3547 net.cpp:137] Memory required for data: 832608400
I0925 20:26:02.549450  3547 layer_factory.hpp:77] Creating layer PReLU44
I0925 20:26:02.549454  3547 net.cpp:84] Creating Layer PReLU44
I0925 20:26:02.549456  3547 net.cpp:406] PReLU44 <- Convolution46
I0925 20:26:02.549460  3547 net.cpp:367] PReLU44 -> Convolution46 (in-place)
I0925 20:26:02.549523  3547 net.cpp:122] Setting up PReLU44
I0925 20:26:02.549527  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.549530  3547 net.cpp:137] Memory required for data: 833862800
I0925 20:26:02.549532  3547 layer_factory.hpp:77] Creating layer Convolution47
I0925 20:26:02.549538  3547 net.cpp:84] Creating Layer Convolution47
I0925 20:26:02.549541  3547 net.cpp:406] Convolution47 <- Convolution46
I0925 20:26:02.549546  3547 net.cpp:380] Convolution47 -> Convolution47
I0925 20:26:02.551278  3547 net.cpp:122] Setting up Convolution47
I0925 20:26:02.551287  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.551290  3547 net.cpp:137] Memory required for data: 835117200
I0925 20:26:02.551295  3547 layer_factory.hpp:77] Creating layer BatchNorm47
I0925 20:26:02.551301  3547 net.cpp:84] Creating Layer BatchNorm47
I0925 20:26:02.551304  3547 net.cpp:406] BatchNorm47 <- Convolution47
I0925 20:26:02.551308  3547 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0925 20:26:02.551458  3547 net.cpp:122] Setting up BatchNorm47
I0925 20:26:02.551463  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.551465  3547 net.cpp:137] Memory required for data: 836371600
I0925 20:26:02.551470  3547 layer_factory.hpp:77] Creating layer Scale47
I0925 20:26:02.551475  3547 net.cpp:84] Creating Layer Scale47
I0925 20:26:02.551483  3547 net.cpp:406] Scale47 <- Convolution47
I0925 20:26:02.551486  3547 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0925 20:26:02.551515  3547 layer_factory.hpp:77] Creating layer Scale47
I0925 20:26:02.551597  3547 net.cpp:122] Setting up Scale47
I0925 20:26:02.551601  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.551604  3547 net.cpp:137] Memory required for data: 837626000
I0925 20:26:02.551607  3547 layer_factory.hpp:77] Creating layer Eltwise22
I0925 20:26:02.551611  3547 net.cpp:84] Creating Layer Eltwise22
I0925 20:26:02.551614  3547 net.cpp:406] Eltwise22 <- Eltwise21_PReLU43_0_split_1
I0925 20:26:02.551617  3547 net.cpp:406] Eltwise22 <- Convolution47
I0925 20:26:02.551620  3547 net.cpp:380] Eltwise22 -> Eltwise22
I0925 20:26:02.551637  3547 net.cpp:122] Setting up Eltwise22
I0925 20:26:02.551641  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.551642  3547 net.cpp:137] Memory required for data: 838880400
I0925 20:26:02.551645  3547 layer_factory.hpp:77] Creating layer PReLU45
I0925 20:26:02.551648  3547 net.cpp:84] Creating Layer PReLU45
I0925 20:26:02.551651  3547 net.cpp:406] PReLU45 <- Eltwise22
I0925 20:26:02.551654  3547 net.cpp:367] PReLU45 -> Eltwise22 (in-place)
I0925 20:26:02.551715  3547 net.cpp:122] Setting up PReLU45
I0925 20:26:02.551719  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.551722  3547 net.cpp:137] Memory required for data: 840134800
I0925 20:26:02.551724  3547 layer_factory.hpp:77] Creating layer Eltwise22_PReLU45_0_split
I0925 20:26:02.551728  3547 net.cpp:84] Creating Layer Eltwise22_PReLU45_0_split
I0925 20:26:02.551730  3547 net.cpp:406] Eltwise22_PReLU45_0_split <- Eltwise22
I0925 20:26:02.551734  3547 net.cpp:380] Eltwise22_PReLU45_0_split -> Eltwise22_PReLU45_0_split_0
I0925 20:26:02.551738  3547 net.cpp:380] Eltwise22_PReLU45_0_split -> Eltwise22_PReLU45_0_split_1
I0925 20:26:02.551761  3547 net.cpp:122] Setting up Eltwise22_PReLU45_0_split
I0925 20:26:02.551765  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.551769  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.551770  3547 net.cpp:137] Memory required for data: 842643600
I0925 20:26:02.551772  3547 layer_factory.hpp:77] Creating layer Convolution48
I0925 20:26:02.551780  3547 net.cpp:84] Creating Layer Convolution48
I0925 20:26:02.551782  3547 net.cpp:406] Convolution48 <- Eltwise22_PReLU45_0_split_0
I0925 20:26:02.551786  3547 net.cpp:380] Convolution48 -> Convolution48
I0925 20:26:02.553449  3547 net.cpp:122] Setting up Convolution48
I0925 20:26:02.553458  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.553462  3547 net.cpp:137] Memory required for data: 843898000
I0925 20:26:02.553465  3547 layer_factory.hpp:77] Creating layer BatchNorm48
I0925 20:26:02.553470  3547 net.cpp:84] Creating Layer BatchNorm48
I0925 20:26:02.553473  3547 net.cpp:406] BatchNorm48 <- Convolution48
I0925 20:26:02.553478  3547 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0925 20:26:02.553620  3547 net.cpp:122] Setting up BatchNorm48
I0925 20:26:02.553624  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.553627  3547 net.cpp:137] Memory required for data: 845152400
I0925 20:26:02.553632  3547 layer_factory.hpp:77] Creating layer Scale48
I0925 20:26:02.553635  3547 net.cpp:84] Creating Layer Scale48
I0925 20:26:02.553637  3547 net.cpp:406] Scale48 <- Convolution48
I0925 20:26:02.553640  3547 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0925 20:26:02.553669  3547 layer_factory.hpp:77] Creating layer Scale48
I0925 20:26:02.553752  3547 net.cpp:122] Setting up Scale48
I0925 20:26:02.553756  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.553758  3547 net.cpp:137] Memory required for data: 846406800
I0925 20:26:02.553762  3547 layer_factory.hpp:77] Creating layer PReLU46
I0925 20:26:02.553766  3547 net.cpp:84] Creating Layer PReLU46
I0925 20:26:02.553769  3547 net.cpp:406] PReLU46 <- Convolution48
I0925 20:26:02.553772  3547 net.cpp:367] PReLU46 -> Convolution48 (in-place)
I0925 20:26:02.553843  3547 net.cpp:122] Setting up PReLU46
I0925 20:26:02.553848  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.553850  3547 net.cpp:137] Memory required for data: 847661200
I0925 20:26:02.553853  3547 layer_factory.hpp:77] Creating layer Convolution49
I0925 20:26:02.553858  3547 net.cpp:84] Creating Layer Convolution49
I0925 20:26:02.553861  3547 net.cpp:406] Convolution49 <- Convolution48
I0925 20:26:02.553865  3547 net.cpp:380] Convolution49 -> Convolution49
I0925 20:26:02.555824  3547 net.cpp:122] Setting up Convolution49
I0925 20:26:02.555832  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.555835  3547 net.cpp:137] Memory required for data: 848915600
I0925 20:26:02.555840  3547 layer_factory.hpp:77] Creating layer BatchNorm49
I0925 20:26:02.555845  3547 net.cpp:84] Creating Layer BatchNorm49
I0925 20:26:02.555847  3547 net.cpp:406] BatchNorm49 <- Convolution49
I0925 20:26:02.555850  3547 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0925 20:26:02.555995  3547 net.cpp:122] Setting up BatchNorm49
I0925 20:26:02.556000  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.556002  3547 net.cpp:137] Memory required for data: 850170000
I0925 20:26:02.556007  3547 layer_factory.hpp:77] Creating layer Scale49
I0925 20:26:02.556011  3547 net.cpp:84] Creating Layer Scale49
I0925 20:26:02.556015  3547 net.cpp:406] Scale49 <- Convolution49
I0925 20:26:02.556017  3547 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0925 20:26:02.556044  3547 layer_factory.hpp:77] Creating layer Scale49
I0925 20:26:02.556126  3547 net.cpp:122] Setting up Scale49
I0925 20:26:02.556131  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.556133  3547 net.cpp:137] Memory required for data: 851424400
I0925 20:26:02.556138  3547 layer_factory.hpp:77] Creating layer Eltwise23
I0925 20:26:02.556141  3547 net.cpp:84] Creating Layer Eltwise23
I0925 20:26:02.556144  3547 net.cpp:406] Eltwise23 <- Eltwise22_PReLU45_0_split_1
I0925 20:26:02.556147  3547 net.cpp:406] Eltwise23 <- Convolution49
I0925 20:26:02.556150  3547 net.cpp:380] Eltwise23 -> Eltwise23
I0925 20:26:02.556167  3547 net.cpp:122] Setting up Eltwise23
I0925 20:26:02.556171  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.556174  3547 net.cpp:137] Memory required for data: 852678800
I0925 20:26:02.556175  3547 layer_factory.hpp:77] Creating layer PReLU47
I0925 20:26:02.556179  3547 net.cpp:84] Creating Layer PReLU47
I0925 20:26:02.556181  3547 net.cpp:406] PReLU47 <- Eltwise23
I0925 20:26:02.556185  3547 net.cpp:367] PReLU47 -> Eltwise23 (in-place)
I0925 20:26:02.556246  3547 net.cpp:122] Setting up PReLU47
I0925 20:26:02.556251  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.556252  3547 net.cpp:137] Memory required for data: 853933200
I0925 20:26:02.556255  3547 layer_factory.hpp:77] Creating layer Eltwise23_PReLU47_0_split
I0925 20:26:02.556258  3547 net.cpp:84] Creating Layer Eltwise23_PReLU47_0_split
I0925 20:26:02.556260  3547 net.cpp:406] Eltwise23_PReLU47_0_split <- Eltwise23
I0925 20:26:02.556264  3547 net.cpp:380] Eltwise23_PReLU47_0_split -> Eltwise23_PReLU47_0_split_0
I0925 20:26:02.556268  3547 net.cpp:380] Eltwise23_PReLU47_0_split -> Eltwise23_PReLU47_0_split_1
I0925 20:26:02.556293  3547 net.cpp:122] Setting up Eltwise23_PReLU47_0_split
I0925 20:26:02.556295  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.556298  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.556300  3547 net.cpp:137] Memory required for data: 856442000
I0925 20:26:02.556303  3547 layer_factory.hpp:77] Creating layer Convolution50
I0925 20:26:02.556309  3547 net.cpp:84] Creating Layer Convolution50
I0925 20:26:02.556311  3547 net.cpp:406] Convolution50 <- Eltwise23_PReLU47_0_split_0
I0925 20:26:02.556315  3547 net.cpp:380] Convolution50 -> Convolution50
I0925 20:26:02.557997  3547 net.cpp:122] Setting up Convolution50
I0925 20:26:02.558007  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.558009  3547 net.cpp:137] Memory required for data: 857696400
I0925 20:26:02.558020  3547 layer_factory.hpp:77] Creating layer BatchNorm50
I0925 20:26:02.558027  3547 net.cpp:84] Creating Layer BatchNorm50
I0925 20:26:02.558029  3547 net.cpp:406] BatchNorm50 <- Convolution50
I0925 20:26:02.558033  3547 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0925 20:26:02.558176  3547 net.cpp:122] Setting up BatchNorm50
I0925 20:26:02.558182  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.558183  3547 net.cpp:137] Memory required for data: 858950800
I0925 20:26:02.558188  3547 layer_factory.hpp:77] Creating layer Scale50
I0925 20:26:02.558193  3547 net.cpp:84] Creating Layer Scale50
I0925 20:26:02.558195  3547 net.cpp:406] Scale50 <- Convolution50
I0925 20:26:02.558198  3547 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0925 20:26:02.558226  3547 layer_factory.hpp:77] Creating layer Scale50
I0925 20:26:02.558311  3547 net.cpp:122] Setting up Scale50
I0925 20:26:02.558316  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.567601  3547 net.cpp:137] Memory required for data: 860205200
I0925 20:26:02.567611  3547 layer_factory.hpp:77] Creating layer PReLU48
I0925 20:26:02.567617  3547 net.cpp:84] Creating Layer PReLU48
I0925 20:26:02.567622  3547 net.cpp:406] PReLU48 <- Convolution50
I0925 20:26:02.567628  3547 net.cpp:367] PReLU48 -> Convolution50 (in-place)
I0925 20:26:02.567716  3547 net.cpp:122] Setting up PReLU48
I0925 20:26:02.567723  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.567724  3547 net.cpp:137] Memory required for data: 861459600
I0925 20:26:02.567728  3547 layer_factory.hpp:77] Creating layer Convolution51
I0925 20:26:02.567734  3547 net.cpp:84] Creating Layer Convolution51
I0925 20:26:02.567736  3547 net.cpp:406] Convolution51 <- Convolution50
I0925 20:26:02.567742  3547 net.cpp:380] Convolution51 -> Convolution51
I0925 20:26:02.569949  3547 net.cpp:122] Setting up Convolution51
I0925 20:26:02.569959  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.569962  3547 net.cpp:137] Memory required for data: 862714000
I0925 20:26:02.569967  3547 layer_factory.hpp:77] Creating layer BatchNorm51
I0925 20:26:02.569972  3547 net.cpp:84] Creating Layer BatchNorm51
I0925 20:26:02.569975  3547 net.cpp:406] BatchNorm51 <- Convolution51
I0925 20:26:02.569981  3547 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0925 20:26:02.570183  3547 net.cpp:122] Setting up BatchNorm51
I0925 20:26:02.570188  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.570189  3547 net.cpp:137] Memory required for data: 863968400
I0925 20:26:02.570194  3547 layer_factory.hpp:77] Creating layer Scale51
I0925 20:26:02.570199  3547 net.cpp:84] Creating Layer Scale51
I0925 20:26:02.570201  3547 net.cpp:406] Scale51 <- Convolution51
I0925 20:26:02.570205  3547 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0925 20:26:02.570235  3547 layer_factory.hpp:77] Creating layer Scale51
I0925 20:26:02.570317  3547 net.cpp:122] Setting up Scale51
I0925 20:26:02.570322  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.570323  3547 net.cpp:137] Memory required for data: 865222800
I0925 20:26:02.570327  3547 layer_factory.hpp:77] Creating layer Eltwise24
I0925 20:26:02.570332  3547 net.cpp:84] Creating Layer Eltwise24
I0925 20:26:02.570334  3547 net.cpp:406] Eltwise24 <- Eltwise23_PReLU47_0_split_1
I0925 20:26:02.570338  3547 net.cpp:406] Eltwise24 <- Convolution51
I0925 20:26:02.570340  3547 net.cpp:380] Eltwise24 -> Eltwise24
I0925 20:26:02.570356  3547 net.cpp:122] Setting up Eltwise24
I0925 20:26:02.570360  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.570363  3547 net.cpp:137] Memory required for data: 866477200
I0925 20:26:02.570364  3547 layer_factory.hpp:77] Creating layer PReLU49
I0925 20:26:02.570369  3547 net.cpp:84] Creating Layer PReLU49
I0925 20:26:02.570370  3547 net.cpp:406] PReLU49 <- Eltwise24
I0925 20:26:02.570374  3547 net.cpp:367] PReLU49 -> Eltwise24 (in-place)
I0925 20:26:02.570436  3547 net.cpp:122] Setting up PReLU49
I0925 20:26:02.570441  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.570449  3547 net.cpp:137] Memory required for data: 867731600
I0925 20:26:02.570452  3547 layer_factory.hpp:77] Creating layer Eltwise24_PReLU49_0_split
I0925 20:26:02.570456  3547 net.cpp:84] Creating Layer Eltwise24_PReLU49_0_split
I0925 20:26:02.570458  3547 net.cpp:406] Eltwise24_PReLU49_0_split <- Eltwise24
I0925 20:26:02.570462  3547 net.cpp:380] Eltwise24_PReLU49_0_split -> Eltwise24_PReLU49_0_split_0
I0925 20:26:02.570466  3547 net.cpp:380] Eltwise24_PReLU49_0_split -> Eltwise24_PReLU49_0_split_1
I0925 20:26:02.570492  3547 net.cpp:122] Setting up Eltwise24_PReLU49_0_split
I0925 20:26:02.570495  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.570498  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.570500  3547 net.cpp:137] Memory required for data: 870240400
I0925 20:26:02.570502  3547 layer_factory.hpp:77] Creating layer Convolution52
I0925 20:26:02.570510  3547 net.cpp:84] Creating Layer Convolution52
I0925 20:26:02.570513  3547 net.cpp:406] Convolution52 <- Eltwise24_PReLU49_0_split_0
I0925 20:26:02.570516  3547 net.cpp:380] Convolution52 -> Convolution52
I0925 20:26:02.572258  3547 net.cpp:122] Setting up Convolution52
I0925 20:26:02.572268  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.572270  3547 net.cpp:137] Memory required for data: 871494800
I0925 20:26:02.572275  3547 layer_factory.hpp:77] Creating layer BatchNorm52
I0925 20:26:02.572280  3547 net.cpp:84] Creating Layer BatchNorm52
I0925 20:26:02.572283  3547 net.cpp:406] BatchNorm52 <- Convolution52
I0925 20:26:02.572288  3547 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0925 20:26:02.572432  3547 net.cpp:122] Setting up BatchNorm52
I0925 20:26:02.572438  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.572439  3547 net.cpp:137] Memory required for data: 872749200
I0925 20:26:02.572444  3547 layer_factory.hpp:77] Creating layer Scale52
I0925 20:26:02.572449  3547 net.cpp:84] Creating Layer Scale52
I0925 20:26:02.572451  3547 net.cpp:406] Scale52 <- Convolution52
I0925 20:26:02.572454  3547 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0925 20:26:02.572484  3547 layer_factory.hpp:77] Creating layer Scale52
I0925 20:26:02.572595  3547 net.cpp:122] Setting up Scale52
I0925 20:26:02.572600  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.572602  3547 net.cpp:137] Memory required for data: 874003600
I0925 20:26:02.572607  3547 layer_factory.hpp:77] Creating layer PReLU50
I0925 20:26:02.572610  3547 net.cpp:84] Creating Layer PReLU50
I0925 20:26:02.572613  3547 net.cpp:406] PReLU50 <- Convolution52
I0925 20:26:02.572616  3547 net.cpp:367] PReLU50 -> Convolution52 (in-place)
I0925 20:26:02.572680  3547 net.cpp:122] Setting up PReLU50
I0925 20:26:02.572685  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.572687  3547 net.cpp:137] Memory required for data: 875258000
I0925 20:26:02.572690  3547 layer_factory.hpp:77] Creating layer Convolution53
I0925 20:26:02.572715  3547 net.cpp:84] Creating Layer Convolution53
I0925 20:26:02.572718  3547 net.cpp:406] Convolution53 <- Convolution52
I0925 20:26:02.572722  3547 net.cpp:380] Convolution53 -> Convolution53
I0925 20:26:02.574703  3547 net.cpp:122] Setting up Convolution53
I0925 20:26:02.574713  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.574717  3547 net.cpp:137] Memory required for data: 876512400
I0925 20:26:02.574721  3547 layer_factory.hpp:77] Creating layer BatchNorm53
I0925 20:26:02.574726  3547 net.cpp:84] Creating Layer BatchNorm53
I0925 20:26:02.574729  3547 net.cpp:406] BatchNorm53 <- Convolution53
I0925 20:26:02.574733  3547 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0925 20:26:02.574878  3547 net.cpp:122] Setting up BatchNorm53
I0925 20:26:02.574883  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.574885  3547 net.cpp:137] Memory required for data: 877766800
I0925 20:26:02.574889  3547 layer_factory.hpp:77] Creating layer Scale53
I0925 20:26:02.574893  3547 net.cpp:84] Creating Layer Scale53
I0925 20:26:02.574903  3547 net.cpp:406] Scale53 <- Convolution53
I0925 20:26:02.574908  3547 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0925 20:26:02.574937  3547 layer_factory.hpp:77] Creating layer Scale53
I0925 20:26:02.575021  3547 net.cpp:122] Setting up Scale53
I0925 20:26:02.575026  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.575028  3547 net.cpp:137] Memory required for data: 879021200
I0925 20:26:02.575031  3547 layer_factory.hpp:77] Creating layer Eltwise25
I0925 20:26:02.575037  3547 net.cpp:84] Creating Layer Eltwise25
I0925 20:26:02.575039  3547 net.cpp:406] Eltwise25 <- Eltwise24_PReLU49_0_split_1
I0925 20:26:02.575042  3547 net.cpp:406] Eltwise25 <- Convolution53
I0925 20:26:02.575045  3547 net.cpp:380] Eltwise25 -> Eltwise25
I0925 20:26:02.575062  3547 net.cpp:122] Setting up Eltwise25
I0925 20:26:02.575067  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.575068  3547 net.cpp:137] Memory required for data: 880275600
I0925 20:26:02.575070  3547 layer_factory.hpp:77] Creating layer PReLU51
I0925 20:26:02.575074  3547 net.cpp:84] Creating Layer PReLU51
I0925 20:26:02.575076  3547 net.cpp:406] PReLU51 <- Eltwise25
I0925 20:26:02.575079  3547 net.cpp:367] PReLU51 -> Eltwise25 (in-place)
I0925 20:26:02.575142  3547 net.cpp:122] Setting up PReLU51
I0925 20:26:02.575146  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.575148  3547 net.cpp:137] Memory required for data: 881530000
I0925 20:26:02.575151  3547 layer_factory.hpp:77] Creating layer Eltwise25_PReLU51_0_split
I0925 20:26:02.575155  3547 net.cpp:84] Creating Layer Eltwise25_PReLU51_0_split
I0925 20:26:02.575158  3547 net.cpp:406] Eltwise25_PReLU51_0_split <- Eltwise25
I0925 20:26:02.575161  3547 net.cpp:380] Eltwise25_PReLU51_0_split -> Eltwise25_PReLU51_0_split_0
I0925 20:26:02.575165  3547 net.cpp:380] Eltwise25_PReLU51_0_split -> Eltwise25_PReLU51_0_split_1
I0925 20:26:02.575189  3547 net.cpp:122] Setting up Eltwise25_PReLU51_0_split
I0925 20:26:02.575193  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.575196  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.575197  3547 net.cpp:137] Memory required for data: 884038800
I0925 20:26:02.575199  3547 layer_factory.hpp:77] Creating layer Convolution54
I0925 20:26:02.575206  3547 net.cpp:84] Creating Layer Convolution54
I0925 20:26:02.575208  3547 net.cpp:406] Convolution54 <- Eltwise25_PReLU51_0_split_0
I0925 20:26:02.575212  3547 net.cpp:380] Convolution54 -> Convolution54
I0925 20:26:02.577420  3547 net.cpp:122] Setting up Convolution54
I0925 20:26:02.577430  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.577432  3547 net.cpp:137] Memory required for data: 885293200
I0925 20:26:02.577436  3547 layer_factory.hpp:77] Creating layer BatchNorm54
I0925 20:26:02.577442  3547 net.cpp:84] Creating Layer BatchNorm54
I0925 20:26:02.577445  3547 net.cpp:406] BatchNorm54 <- Convolution54
I0925 20:26:02.577450  3547 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0925 20:26:02.577590  3547 net.cpp:122] Setting up BatchNorm54
I0925 20:26:02.577595  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.577597  3547 net.cpp:137] Memory required for data: 886547600
I0925 20:26:02.577601  3547 layer_factory.hpp:77] Creating layer Scale54
I0925 20:26:02.577606  3547 net.cpp:84] Creating Layer Scale54
I0925 20:26:02.577608  3547 net.cpp:406] Scale54 <- Convolution54
I0925 20:26:02.577611  3547 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0925 20:26:02.577641  3547 layer_factory.hpp:77] Creating layer Scale54
I0925 20:26:02.577745  3547 net.cpp:122] Setting up Scale54
I0925 20:26:02.577750  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.577752  3547 net.cpp:137] Memory required for data: 887802000
I0925 20:26:02.577756  3547 layer_factory.hpp:77] Creating layer PReLU52
I0925 20:26:02.577760  3547 net.cpp:84] Creating Layer PReLU52
I0925 20:26:02.577762  3547 net.cpp:406] PReLU52 <- Convolution54
I0925 20:26:02.577766  3547 net.cpp:367] PReLU52 -> Convolution54 (in-place)
I0925 20:26:02.577831  3547 net.cpp:122] Setting up PReLU52
I0925 20:26:02.577841  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.577843  3547 net.cpp:137] Memory required for data: 889056400
I0925 20:26:02.577847  3547 layer_factory.hpp:77] Creating layer Convolution55
I0925 20:26:02.577853  3547 net.cpp:84] Creating Layer Convolution55
I0925 20:26:02.577855  3547 net.cpp:406] Convolution55 <- Convolution54
I0925 20:26:02.577859  3547 net.cpp:380] Convolution55 -> Convolution55
I0925 20:26:02.579804  3547 net.cpp:122] Setting up Convolution55
I0925 20:26:02.579813  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.579815  3547 net.cpp:137] Memory required for data: 890310800
I0925 20:26:02.579819  3547 layer_factory.hpp:77] Creating layer BatchNorm55
I0925 20:26:02.579826  3547 net.cpp:84] Creating Layer BatchNorm55
I0925 20:26:02.579828  3547 net.cpp:406] BatchNorm55 <- Convolution55
I0925 20:26:02.579833  3547 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0925 20:26:02.579982  3547 net.cpp:122] Setting up BatchNorm55
I0925 20:26:02.579987  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.579988  3547 net.cpp:137] Memory required for data: 891565200
I0925 20:26:02.579993  3547 layer_factory.hpp:77] Creating layer Scale55
I0925 20:26:02.579998  3547 net.cpp:84] Creating Layer Scale55
I0925 20:26:02.580000  3547 net.cpp:406] Scale55 <- Convolution55
I0925 20:26:02.580003  3547 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0925 20:26:02.580032  3547 layer_factory.hpp:77] Creating layer Scale55
I0925 20:26:02.580117  3547 net.cpp:122] Setting up Scale55
I0925 20:26:02.580121  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.580123  3547 net.cpp:137] Memory required for data: 892819600
I0925 20:26:02.580127  3547 layer_factory.hpp:77] Creating layer Eltwise26
I0925 20:26:02.580132  3547 net.cpp:84] Creating Layer Eltwise26
I0925 20:26:02.580134  3547 net.cpp:406] Eltwise26 <- Eltwise25_PReLU51_0_split_1
I0925 20:26:02.580137  3547 net.cpp:406] Eltwise26 <- Convolution55
I0925 20:26:02.580140  3547 net.cpp:380] Eltwise26 -> Eltwise26
I0925 20:26:02.580158  3547 net.cpp:122] Setting up Eltwise26
I0925 20:26:02.580163  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.580163  3547 net.cpp:137] Memory required for data: 894074000
I0925 20:26:02.580166  3547 layer_factory.hpp:77] Creating layer PReLU53
I0925 20:26:02.580169  3547 net.cpp:84] Creating Layer PReLU53
I0925 20:26:02.580171  3547 net.cpp:406] PReLU53 <- Eltwise26
I0925 20:26:02.580175  3547 net.cpp:367] PReLU53 -> Eltwise26 (in-place)
I0925 20:26:02.580240  3547 net.cpp:122] Setting up PReLU53
I0925 20:26:02.580245  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.580245  3547 net.cpp:137] Memory required for data: 895328400
I0925 20:26:02.580248  3547 layer_factory.hpp:77] Creating layer Eltwise26_PReLU53_0_split
I0925 20:26:02.580252  3547 net.cpp:84] Creating Layer Eltwise26_PReLU53_0_split
I0925 20:26:02.580255  3547 net.cpp:406] Eltwise26_PReLU53_0_split <- Eltwise26
I0925 20:26:02.580258  3547 net.cpp:380] Eltwise26_PReLU53_0_split -> Eltwise26_PReLU53_0_split_0
I0925 20:26:02.580262  3547 net.cpp:380] Eltwise26_PReLU53_0_split -> Eltwise26_PReLU53_0_split_1
I0925 20:26:02.580286  3547 net.cpp:122] Setting up Eltwise26_PReLU53_0_split
I0925 20:26:02.580291  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.580293  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.580296  3547 net.cpp:137] Memory required for data: 897837200
I0925 20:26:02.580297  3547 layer_factory.hpp:77] Creating layer Convolution56
I0925 20:26:02.580304  3547 net.cpp:84] Creating Layer Convolution56
I0925 20:26:02.580307  3547 net.cpp:406] Convolution56 <- Eltwise26_PReLU53_0_split_0
I0925 20:26:02.580310  3547 net.cpp:380] Convolution56 -> Convolution56
I0925 20:26:02.581991  3547 net.cpp:122] Setting up Convolution56
I0925 20:26:02.582000  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.582003  3547 net.cpp:137] Memory required for data: 899091600
I0925 20:26:02.582013  3547 layer_factory.hpp:77] Creating layer BatchNorm56
I0925 20:26:02.582020  3547 net.cpp:84] Creating Layer BatchNorm56
I0925 20:26:02.582022  3547 net.cpp:406] BatchNorm56 <- Convolution56
I0925 20:26:02.582026  3547 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0925 20:26:02.582177  3547 net.cpp:122] Setting up BatchNorm56
I0925 20:26:02.582181  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.582185  3547 net.cpp:137] Memory required for data: 900346000
I0925 20:26:02.582188  3547 layer_factory.hpp:77] Creating layer Scale56
I0925 20:26:02.582193  3547 net.cpp:84] Creating Layer Scale56
I0925 20:26:02.582195  3547 net.cpp:406] Scale56 <- Convolution56
I0925 20:26:02.582198  3547 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0925 20:26:02.582228  3547 layer_factory.hpp:77] Creating layer Scale56
I0925 20:26:02.598287  3547 net.cpp:122] Setting up Scale56
I0925 20:26:02.598294  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.598297  3547 net.cpp:137] Memory required for data: 901600400
I0925 20:26:02.598301  3547 layer_factory.hpp:77] Creating layer PReLU54
I0925 20:26:02.598305  3547 net.cpp:84] Creating Layer PReLU54
I0925 20:26:02.598309  3547 net.cpp:406] PReLU54 <- Convolution56
I0925 20:26:02.598312  3547 net.cpp:367] PReLU54 -> Convolution56 (in-place)
I0925 20:26:02.598387  3547 net.cpp:122] Setting up PReLU54
I0925 20:26:02.598392  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.598394  3547 net.cpp:137] Memory required for data: 902854800
I0925 20:26:02.598397  3547 layer_factory.hpp:77] Creating layer Convolution57
I0925 20:26:02.598403  3547 net.cpp:84] Creating Layer Convolution57
I0925 20:26:02.598407  3547 net.cpp:406] Convolution57 <- Convolution56
I0925 20:26:02.598412  3547 net.cpp:380] Convolution57 -> Convolution57
I0925 20:26:02.600250  3547 net.cpp:122] Setting up Convolution57
I0925 20:26:02.600258  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.600261  3547 net.cpp:137] Memory required for data: 904109200
I0925 20:26:02.600265  3547 layer_factory.hpp:77] Creating layer BatchNorm57
I0925 20:26:02.600271  3547 net.cpp:84] Creating Layer BatchNorm57
I0925 20:26:02.600275  3547 net.cpp:406] BatchNorm57 <- Convolution57
I0925 20:26:02.600277  3547 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0925 20:26:02.600462  3547 net.cpp:122] Setting up BatchNorm57
I0925 20:26:02.600467  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.600469  3547 net.cpp:137] Memory required for data: 905363600
I0925 20:26:02.600474  3547 layer_factory.hpp:77] Creating layer Scale57
I0925 20:26:02.600478  3547 net.cpp:84] Creating Layer Scale57
I0925 20:26:02.600481  3547 net.cpp:406] Scale57 <- Convolution57
I0925 20:26:02.600484  3547 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0925 20:26:02.600538  3547 layer_factory.hpp:77] Creating layer Scale57
I0925 20:26:02.600663  3547 net.cpp:122] Setting up Scale57
I0925 20:26:02.600669  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.600672  3547 net.cpp:137] Memory required for data: 906618000
I0925 20:26:02.600675  3547 layer_factory.hpp:77] Creating layer Eltwise27
I0925 20:26:02.600680  3547 net.cpp:84] Creating Layer Eltwise27
I0925 20:26:02.600683  3547 net.cpp:406] Eltwise27 <- Eltwise26_PReLU53_0_split_1
I0925 20:26:02.600687  3547 net.cpp:406] Eltwise27 <- Convolution57
I0925 20:26:02.600689  3547 net.cpp:380] Eltwise27 -> Eltwise27
I0925 20:26:02.600708  3547 net.cpp:122] Setting up Eltwise27
I0925 20:26:02.600711  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.600713  3547 net.cpp:137] Memory required for data: 907872400
I0925 20:26:02.600715  3547 layer_factory.hpp:77] Creating layer PReLU55
I0925 20:26:02.600719  3547 net.cpp:84] Creating Layer PReLU55
I0925 20:26:02.600721  3547 net.cpp:406] PReLU55 <- Eltwise27
I0925 20:26:02.600726  3547 net.cpp:367] PReLU55 -> Eltwise27 (in-place)
I0925 20:26:02.600791  3547 net.cpp:122] Setting up PReLU55
I0925 20:26:02.600796  3547 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0925 20:26:02.600805  3547 net.cpp:137] Memory required for data: 909126800
I0925 20:26:02.600808  3547 layer_factory.hpp:77] Creating layer Pooling1
I0925 20:26:02.600813  3547 net.cpp:84] Creating Layer Pooling1
I0925 20:26:02.600816  3547 net.cpp:406] Pooling1 <- Eltwise27
I0925 20:26:02.600819  3547 net.cpp:380] Pooling1 -> Pooling1
I0925 20:26:02.601285  3547 net.cpp:122] Setting up Pooling1
I0925 20:26:02.601294  3547 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0925 20:26:02.601296  3547 net.cpp:137] Memory required for data: 909152400
I0925 20:26:02.601299  3547 layer_factory.hpp:77] Creating layer InnerProduct1
I0925 20:26:02.601306  3547 net.cpp:84] Creating Layer InnerProduct1
I0925 20:26:02.601310  3547 net.cpp:406] InnerProduct1 <- Pooling1
I0925 20:26:02.601313  3547 net.cpp:380] InnerProduct1 -> InnerProduct1
I0925 20:26:02.601418  3547 net.cpp:122] Setting up InnerProduct1
I0925 20:26:02.601423  3547 net.cpp:129] Top shape: 100 10 (1000)
I0925 20:26:02.601425  3547 net.cpp:137] Memory required for data: 909156400
I0925 20:26:02.601428  3547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0925 20:26:02.601433  3547 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0925 20:26:02.601435  3547 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0925 20:26:02.601438  3547 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0925 20:26:02.601442  3547 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0925 20:26:02.601447  3547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0925 20:26:02.601665  3547 net.cpp:122] Setting up SoftmaxWithLoss1
I0925 20:26:02.601681  3547 net.cpp:129] Top shape: (1)
I0925 20:26:02.601685  3547 net.cpp:132]     with loss weight 1
I0925 20:26:02.601697  3547 net.cpp:137] Memory required for data: 909156404
I0925 20:26:02.601699  3547 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0925 20:26:02.601702  3547 net.cpp:198] InnerProduct1 needs backward computation.
I0925 20:26:02.601704  3547 net.cpp:198] Pooling1 needs backward computation.
I0925 20:26:02.601706  3547 net.cpp:198] PReLU55 needs backward computation.
I0925 20:26:02.601708  3547 net.cpp:198] Eltwise27 needs backward computation.
I0925 20:26:02.601711  3547 net.cpp:198] Scale57 needs backward computation.
I0925 20:26:02.601712  3547 net.cpp:198] BatchNorm57 needs backward computation.
I0925 20:26:02.601714  3547 net.cpp:198] Convolution57 needs backward computation.
I0925 20:26:02.601716  3547 net.cpp:198] PReLU54 needs backward computation.
I0925 20:26:02.601718  3547 net.cpp:198] Scale56 needs backward computation.
I0925 20:26:02.601721  3547 net.cpp:198] BatchNorm56 needs backward computation.
I0925 20:26:02.601722  3547 net.cpp:198] Convolution56 needs backward computation.
I0925 20:26:02.601724  3547 net.cpp:198] Eltwise26_PReLU53_0_split needs backward computation.
I0925 20:26:02.601727  3547 net.cpp:198] PReLU53 needs backward computation.
I0925 20:26:02.601728  3547 net.cpp:198] Eltwise26 needs backward computation.
I0925 20:26:02.601732  3547 net.cpp:198] Scale55 needs backward computation.
I0925 20:26:02.601733  3547 net.cpp:198] BatchNorm55 needs backward computation.
I0925 20:26:02.601735  3547 net.cpp:198] Convolution55 needs backward computation.
I0925 20:26:02.601737  3547 net.cpp:198] PReLU52 needs backward computation.
I0925 20:26:02.601739  3547 net.cpp:198] Scale54 needs backward computation.
I0925 20:26:02.601742  3547 net.cpp:198] BatchNorm54 needs backward computation.
I0925 20:26:02.601743  3547 net.cpp:198] Convolution54 needs backward computation.
I0925 20:26:02.601745  3547 net.cpp:198] Eltwise25_PReLU51_0_split needs backward computation.
I0925 20:26:02.601747  3547 net.cpp:198] PReLU51 needs backward computation.
I0925 20:26:02.601749  3547 net.cpp:198] Eltwise25 needs backward computation.
I0925 20:26:02.601752  3547 net.cpp:198] Scale53 needs backward computation.
I0925 20:26:02.601754  3547 net.cpp:198] BatchNorm53 needs backward computation.
I0925 20:26:02.601757  3547 net.cpp:198] Convolution53 needs backward computation.
I0925 20:26:02.601758  3547 net.cpp:198] PReLU50 needs backward computation.
I0925 20:26:02.601766  3547 net.cpp:198] Scale52 needs backward computation.
I0925 20:26:02.601769  3547 net.cpp:198] BatchNorm52 needs backward computation.
I0925 20:26:02.601771  3547 net.cpp:198] Convolution52 needs backward computation.
I0925 20:26:02.601773  3547 net.cpp:198] Eltwise24_PReLU49_0_split needs backward computation.
I0925 20:26:02.601775  3547 net.cpp:198] PReLU49 needs backward computation.
I0925 20:26:02.601778  3547 net.cpp:198] Eltwise24 needs backward computation.
I0925 20:26:02.601780  3547 net.cpp:198] Scale51 needs backward computation.
I0925 20:26:02.601783  3547 net.cpp:198] BatchNorm51 needs backward computation.
I0925 20:26:02.601784  3547 net.cpp:198] Convolution51 needs backward computation.
I0925 20:26:02.601786  3547 net.cpp:198] PReLU48 needs backward computation.
I0925 20:26:02.601789  3547 net.cpp:198] Scale50 needs backward computation.
I0925 20:26:02.601791  3547 net.cpp:198] BatchNorm50 needs backward computation.
I0925 20:26:02.601794  3547 net.cpp:198] Convolution50 needs backward computation.
I0925 20:26:02.601795  3547 net.cpp:198] Eltwise23_PReLU47_0_split needs backward computation.
I0925 20:26:02.601799  3547 net.cpp:198] PReLU47 needs backward computation.
I0925 20:26:02.601800  3547 net.cpp:198] Eltwise23 needs backward computation.
I0925 20:26:02.601802  3547 net.cpp:198] Scale49 needs backward computation.
I0925 20:26:02.601805  3547 net.cpp:198] BatchNorm49 needs backward computation.
I0925 20:26:02.601807  3547 net.cpp:198] Convolution49 needs backward computation.
I0925 20:26:02.601809  3547 net.cpp:198] PReLU46 needs backward computation.
I0925 20:26:02.601811  3547 net.cpp:198] Scale48 needs backward computation.
I0925 20:26:02.601814  3547 net.cpp:198] BatchNorm48 needs backward computation.
I0925 20:26:02.601815  3547 net.cpp:198] Convolution48 needs backward computation.
I0925 20:26:02.601819  3547 net.cpp:198] Eltwise22_PReLU45_0_split needs backward computation.
I0925 20:26:02.601820  3547 net.cpp:198] PReLU45 needs backward computation.
I0925 20:26:02.601822  3547 net.cpp:198] Eltwise22 needs backward computation.
I0925 20:26:02.601825  3547 net.cpp:198] Scale47 needs backward computation.
I0925 20:26:02.601827  3547 net.cpp:198] BatchNorm47 needs backward computation.
I0925 20:26:02.601830  3547 net.cpp:198] Convolution47 needs backward computation.
I0925 20:26:02.601832  3547 net.cpp:198] PReLU44 needs backward computation.
I0925 20:26:02.601835  3547 net.cpp:198] Scale46 needs backward computation.
I0925 20:26:02.601836  3547 net.cpp:198] BatchNorm46 needs backward computation.
I0925 20:26:02.601838  3547 net.cpp:198] Convolution46 needs backward computation.
I0925 20:26:02.601851  3547 net.cpp:198] Eltwise21_PReLU43_0_split needs backward computation.
I0925 20:26:02.601853  3547 net.cpp:198] PReLU43 needs backward computation.
I0925 20:26:02.601856  3547 net.cpp:198] Eltwise21 needs backward computation.
I0925 20:26:02.601858  3547 net.cpp:198] Scale45 needs backward computation.
I0925 20:26:02.601861  3547 net.cpp:198] BatchNorm45 needs backward computation.
I0925 20:26:02.601863  3547 net.cpp:198] Convolution45 needs backward computation.
I0925 20:26:02.601866  3547 net.cpp:198] PReLU42 needs backward computation.
I0925 20:26:02.601867  3547 net.cpp:198] Scale44 needs backward computation.
I0925 20:26:02.601869  3547 net.cpp:198] BatchNorm44 needs backward computation.
I0925 20:26:02.601872  3547 net.cpp:198] Convolution44 needs backward computation.
I0925 20:26:02.601874  3547 net.cpp:198] Eltwise20_PReLU41_0_split needs backward computation.
I0925 20:26:02.601876  3547 net.cpp:198] PReLU41 needs backward computation.
I0925 20:26:02.601878  3547 net.cpp:198] Eltwise20 needs backward computation.
I0925 20:26:02.601881  3547 net.cpp:198] Scale43 needs backward computation.
I0925 20:26:02.601884  3547 net.cpp:198] BatchNorm43 needs backward computation.
I0925 20:26:02.601886  3547 net.cpp:198] Convolution43 needs backward computation.
I0925 20:26:02.601889  3547 net.cpp:198] PReLU40 needs backward computation.
I0925 20:26:02.601891  3547 net.cpp:198] Scale42 needs backward computation.
I0925 20:26:02.601897  3547 net.cpp:198] BatchNorm42 needs backward computation.
I0925 20:26:02.601898  3547 net.cpp:198] Convolution42 needs backward computation.
I0925 20:26:02.601902  3547 net.cpp:198] Eltwise19_PReLU39_0_split needs backward computation.
I0925 20:26:02.601903  3547 net.cpp:198] PReLU39 needs backward computation.
I0925 20:26:02.601907  3547 net.cpp:198] Eltwise19 needs backward computation.
I0925 20:26:02.601908  3547 net.cpp:198] Scale41 needs backward computation.
I0925 20:26:02.601912  3547 net.cpp:198] BatchNorm41 needs backward computation.
I0925 20:26:02.601913  3547 net.cpp:198] Convolution41 needs backward computation.
I0925 20:26:02.601915  3547 net.cpp:198] PReLU38 needs backward computation.
I0925 20:26:02.601918  3547 net.cpp:198] Scale40 needs backward computation.
I0925 20:26:02.601920  3547 net.cpp:198] BatchNorm40 needs backward computation.
I0925 20:26:02.601932  3547 net.cpp:198] Convolution40 needs backward computation.
I0925 20:26:02.601934  3547 net.cpp:198] Scale39 needs backward computation.
I0925 20:26:02.601936  3547 net.cpp:198] BatchNorm39 needs backward computation.
I0925 20:26:02.601938  3547 net.cpp:198] Convolution39 needs backward computation.
I0925 20:26:02.601941  3547 net.cpp:198] Eltwise18_PReLU37_0_split needs backward computation.
I0925 20:26:02.601944  3547 net.cpp:198] PReLU37 needs backward computation.
I0925 20:26:02.601946  3547 net.cpp:198] Eltwise18 needs backward computation.
I0925 20:26:02.601949  3547 net.cpp:198] Scale38 needs backward computation.
I0925 20:26:02.601953  3547 net.cpp:198] BatchNorm38 needs backward computation.
I0925 20:26:02.601954  3547 net.cpp:198] Convolution38 needs backward computation.
I0925 20:26:02.601958  3547 net.cpp:198] PReLU36 needs backward computation.
I0925 20:26:02.601959  3547 net.cpp:198] Scale37 needs backward computation.
I0925 20:26:02.601961  3547 net.cpp:198] BatchNorm37 needs backward computation.
I0925 20:26:02.601963  3547 net.cpp:198] Convolution37 needs backward computation.
I0925 20:26:02.601965  3547 net.cpp:198] Eltwise17_PReLU35_0_split needs backward computation.
I0925 20:26:02.601969  3547 net.cpp:198] PReLU35 needs backward computation.
I0925 20:26:02.601970  3547 net.cpp:198] Eltwise17 needs backward computation.
I0925 20:26:02.601974  3547 net.cpp:198] Scale36 needs backward computation.
I0925 20:26:02.601975  3547 net.cpp:198] BatchNorm36 needs backward computation.
I0925 20:26:02.601977  3547 net.cpp:198] Convolution36 needs backward computation.
I0925 20:26:02.601980  3547 net.cpp:198] PReLU34 needs backward computation.
I0925 20:26:02.601982  3547 net.cpp:198] Scale35 needs backward computation.
I0925 20:26:02.601984  3547 net.cpp:198] BatchNorm35 needs backward computation.
I0925 20:26:02.601986  3547 net.cpp:198] Convolution35 needs backward computation.
I0925 20:26:02.601989  3547 net.cpp:198] Eltwise16_PReLU33_0_split needs backward computation.
I0925 20:26:02.601991  3547 net.cpp:198] PReLU33 needs backward computation.
I0925 20:26:02.601994  3547 net.cpp:198] Eltwise16 needs backward computation.
I0925 20:26:02.601996  3547 net.cpp:198] Scale34 needs backward computation.
I0925 20:26:02.601999  3547 net.cpp:198] BatchNorm34 needs backward computation.
I0925 20:26:02.602000  3547 net.cpp:198] Convolution34 needs backward computation.
I0925 20:26:02.602002  3547 net.cpp:198] PReLU32 needs backward computation.
I0925 20:26:02.602005  3547 net.cpp:198] Scale33 needs backward computation.
I0925 20:26:02.602007  3547 net.cpp:198] BatchNorm33 needs backward computation.
I0925 20:26:02.602010  3547 net.cpp:198] Convolution33 needs backward computation.
I0925 20:26:02.602011  3547 net.cpp:198] Eltwise15_PReLU31_0_split needs backward computation.
I0925 20:26:02.602015  3547 net.cpp:198] PReLU31 needs backward computation.
I0925 20:26:02.602016  3547 net.cpp:198] Eltwise15 needs backward computation.
I0925 20:26:02.602020  3547 net.cpp:198] Scale32 needs backward computation.
I0925 20:26:02.602021  3547 net.cpp:198] BatchNorm32 needs backward computation.
I0925 20:26:02.602027  3547 net.cpp:198] Convolution32 needs backward computation.
I0925 20:26:02.602030  3547 net.cpp:198] PReLU30 needs backward computation.
I0925 20:26:02.602032  3547 net.cpp:198] Scale31 needs backward computation.
I0925 20:26:02.602035  3547 net.cpp:198] BatchNorm31 needs backward computation.
I0925 20:26:02.602036  3547 net.cpp:198] Convolution31 needs backward computation.
I0925 20:26:02.602038  3547 net.cpp:198] Eltwise14_PReLU29_0_split needs backward computation.
I0925 20:26:02.602041  3547 net.cpp:198] PReLU29 needs backward computation.
I0925 20:26:02.602043  3547 net.cpp:198] Eltwise14 needs backward computation.
I0925 20:26:02.602046  3547 net.cpp:198] Scale30 needs backward computation.
I0925 20:26:02.628780  3547 net.cpp:198] BatchNorm30 needs backward computation.
I0925 20:26:02.628787  3547 net.cpp:198] Convolution30 needs backward computation.
I0925 20:26:02.628792  3547 net.cpp:198] PReLU28 needs backward computation.
I0925 20:26:02.628795  3547 net.cpp:198] Scale29 needs backward computation.
I0925 20:26:02.628799  3547 net.cpp:198] BatchNorm29 needs backward computation.
I0925 20:26:02.628803  3547 net.cpp:198] Convolution29 needs backward computation.
I0925 20:26:02.628808  3547 net.cpp:198] Eltwise13_PReLU27_0_split needs backward computation.
I0925 20:26:02.628813  3547 net.cpp:198] PReLU27 needs backward computation.
I0925 20:26:02.628816  3547 net.cpp:198] Eltwise13 needs backward computation.
I0925 20:26:02.628821  3547 net.cpp:198] Scale28 needs backward computation.
I0925 20:26:02.628825  3547 net.cpp:198] BatchNorm28 needs backward computation.
I0925 20:26:02.628829  3547 net.cpp:198] Convolution28 needs backward computation.
I0925 20:26:02.628834  3547 net.cpp:198] PReLU26 needs backward computation.
I0925 20:26:02.628837  3547 net.cpp:198] Scale27 needs backward computation.
I0925 20:26:02.628841  3547 net.cpp:198] BatchNorm27 needs backward computation.
I0925 20:26:02.628845  3547 net.cpp:198] Convolution27 needs backward computation.
I0925 20:26:02.628849  3547 net.cpp:198] Eltwise12_PReLU25_0_split needs backward computation.
I0925 20:26:02.628854  3547 net.cpp:198] PReLU25 needs backward computation.
I0925 20:26:02.628859  3547 net.cpp:198] Eltwise12 needs backward computation.
I0925 20:26:02.628861  3547 net.cpp:198] Scale26 needs backward computation.
I0925 20:26:02.628864  3547 net.cpp:198] BatchNorm26 needs backward computation.
I0925 20:26:02.628866  3547 net.cpp:198] Convolution26 needs backward computation.
I0925 20:26:02.628868  3547 net.cpp:198] PReLU24 needs backward computation.
I0925 20:26:02.628871  3547 net.cpp:198] Scale25 needs backward computation.
I0925 20:26:02.628873  3547 net.cpp:198] BatchNorm25 needs backward computation.
I0925 20:26:02.628875  3547 net.cpp:198] Convolution25 needs backward computation.
I0925 20:26:02.628878  3547 net.cpp:198] Eltwise11_PReLU23_0_split needs backward computation.
I0925 20:26:02.628881  3547 net.cpp:198] PReLU23 needs backward computation.
I0925 20:26:02.628883  3547 net.cpp:198] Eltwise11 needs backward computation.
I0925 20:26:02.628886  3547 net.cpp:198] Scale24 needs backward computation.
I0925 20:26:02.628891  3547 net.cpp:198] BatchNorm24 needs backward computation.
I0925 20:26:02.628895  3547 net.cpp:198] Convolution24 needs backward computation.
I0925 20:26:02.628896  3547 net.cpp:198] PReLU22 needs backward computation.
I0925 20:26:02.628899  3547 net.cpp:198] Scale23 needs backward computation.
I0925 20:26:02.628901  3547 net.cpp:198] BatchNorm23 needs backward computation.
I0925 20:26:02.628903  3547 net.cpp:198] Convolution23 needs backward computation.
I0925 20:26:02.628906  3547 net.cpp:198] Eltwise10_PReLU21_0_split needs backward computation.
I0925 20:26:02.628909  3547 net.cpp:198] PReLU21 needs backward computation.
I0925 20:26:02.628911  3547 net.cpp:198] Eltwise10 needs backward computation.
I0925 20:26:02.628914  3547 net.cpp:198] Scale22 needs backward computation.
I0925 20:26:02.628916  3547 net.cpp:198] BatchNorm22 needs backward computation.
I0925 20:26:02.628919  3547 net.cpp:198] Convolution22 needs backward computation.
I0925 20:26:02.628926  3547 net.cpp:198] PReLU20 needs backward computation.
I0925 20:26:02.628929  3547 net.cpp:198] Scale21 needs backward computation.
I0925 20:26:02.628931  3547 net.cpp:198] BatchNorm21 needs backward computation.
I0925 20:26:02.628934  3547 net.cpp:198] Convolution21 needs backward computation.
I0925 20:26:02.628937  3547 net.cpp:198] Scale20 needs backward computation.
I0925 20:26:02.628939  3547 net.cpp:198] BatchNorm20 needs backward computation.
I0925 20:26:02.628942  3547 net.cpp:198] Convolution20 needs backward computation.
I0925 20:26:02.628943  3547 net.cpp:198] Eltwise9_PReLU19_0_split needs backward computation.
I0925 20:26:02.628947  3547 net.cpp:198] PReLU19 needs backward computation.
I0925 20:26:02.628949  3547 net.cpp:198] Eltwise9 needs backward computation.
I0925 20:26:02.628952  3547 net.cpp:198] Scale19 needs backward computation.
I0925 20:26:02.628955  3547 net.cpp:198] BatchNorm19 needs backward computation.
I0925 20:26:02.628957  3547 net.cpp:198] Convolution19 needs backward computation.
I0925 20:26:02.628959  3547 net.cpp:198] PReLU18 needs backward computation.
I0925 20:26:02.628962  3547 net.cpp:198] Scale18 needs backward computation.
I0925 20:26:02.628964  3547 net.cpp:198] BatchNorm18 needs backward computation.
I0925 20:26:02.628968  3547 net.cpp:198] Convolution18 needs backward computation.
I0925 20:26:02.628969  3547 net.cpp:198] Eltwise8_PReLU17_0_split needs backward computation.
I0925 20:26:02.628973  3547 net.cpp:198] PReLU17 needs backward computation.
I0925 20:26:02.628974  3547 net.cpp:198] Eltwise8 needs backward computation.
I0925 20:26:02.628978  3547 net.cpp:198] Scale17 needs backward computation.
I0925 20:26:02.628979  3547 net.cpp:198] BatchNorm17 needs backward computation.
I0925 20:26:02.628983  3547 net.cpp:198] Convolution17 needs backward computation.
I0925 20:26:02.628984  3547 net.cpp:198] PReLU16 needs backward computation.
I0925 20:26:02.628988  3547 net.cpp:198] Scale16 needs backward computation.
I0925 20:26:02.628989  3547 net.cpp:198] BatchNorm16 needs backward computation.
I0925 20:26:02.628991  3547 net.cpp:198] Convolution16 needs backward computation.
I0925 20:26:02.628994  3547 net.cpp:198] Eltwise7_PReLU15_0_split needs backward computation.
I0925 20:26:02.628996  3547 net.cpp:198] PReLU15 needs backward computation.
I0925 20:26:02.628999  3547 net.cpp:198] Eltwise7 needs backward computation.
I0925 20:26:02.629003  3547 net.cpp:198] Scale15 needs backward computation.
I0925 20:26:02.629004  3547 net.cpp:198] BatchNorm15 needs backward computation.
I0925 20:26:02.629006  3547 net.cpp:198] Convolution15 needs backward computation.
I0925 20:26:02.629009  3547 net.cpp:198] PReLU14 needs backward computation.
I0925 20:26:02.629011  3547 net.cpp:198] Scale14 needs backward computation.
I0925 20:26:02.629014  3547 net.cpp:198] BatchNorm14 needs backward computation.
I0925 20:26:02.629016  3547 net.cpp:198] Convolution14 needs backward computation.
I0925 20:26:02.629019  3547 net.cpp:198] Eltwise6_PReLU13_0_split needs backward computation.
I0925 20:26:02.629021  3547 net.cpp:198] PReLU13 needs backward computation.
I0925 20:26:02.629024  3547 net.cpp:198] Eltwise6 needs backward computation.
I0925 20:26:02.629026  3547 net.cpp:198] Scale13 needs backward computation.
I0925 20:26:02.629029  3547 net.cpp:198] BatchNorm13 needs backward computation.
I0925 20:26:02.629031  3547 net.cpp:198] Convolution13 needs backward computation.
I0925 20:26:02.629034  3547 net.cpp:198] PReLU12 needs backward computation.
I0925 20:26:02.629036  3547 net.cpp:198] Scale12 needs backward computation.
I0925 20:26:02.629039  3547 net.cpp:198] BatchNorm12 needs backward computation.
I0925 20:26:02.629040  3547 net.cpp:198] Convolution12 needs backward computation.
I0925 20:26:02.629043  3547 net.cpp:198] Eltwise5_PReLU11_0_split needs backward computation.
I0925 20:26:02.629046  3547 net.cpp:198] PReLU11 needs backward computation.
I0925 20:26:02.629048  3547 net.cpp:198] Eltwise5 needs backward computation.
I0925 20:26:02.629051  3547 net.cpp:198] Scale11 needs backward computation.
I0925 20:26:02.629057  3547 net.cpp:198] BatchNorm11 needs backward computation.
I0925 20:26:02.629060  3547 net.cpp:198] Convolution11 needs backward computation.
I0925 20:26:02.629063  3547 net.cpp:198] PReLU10 needs backward computation.
I0925 20:26:02.629065  3547 net.cpp:198] Scale10 needs backward computation.
I0925 20:26:02.629067  3547 net.cpp:198] BatchNorm10 needs backward computation.
I0925 20:26:02.629070  3547 net.cpp:198] Convolution10 needs backward computation.
I0925 20:26:02.629072  3547 net.cpp:198] Eltwise4_PReLU9_0_split needs backward computation.
I0925 20:26:02.631100  3547 net.cpp:198] PReLU9 needs backward computation.
I0925 20:26:02.631110  3547 net.cpp:198] Eltwise4 needs backward computation.
I0925 20:26:02.631116  3547 net.cpp:198] Scale9 needs backward computation.
I0925 20:26:02.631120  3547 net.cpp:198] BatchNorm9 needs backward computation.
I0925 20:26:02.631122  3547 net.cpp:198] Convolution9 needs backward computation.
I0925 20:26:02.631125  3547 net.cpp:198] PReLU8 needs backward computation.
I0925 20:26:02.631129  3547 net.cpp:198] Scale8 needs backward computation.
I0925 20:26:02.631130  3547 net.cpp:198] BatchNorm8 needs backward computation.
I0925 20:26:02.631132  3547 net.cpp:198] Convolution8 needs backward computation.
I0925 20:26:02.631135  3547 net.cpp:198] Eltwise3_PReLU7_0_split needs backward computation.
I0925 20:26:02.631139  3547 net.cpp:198] PReLU7 needs backward computation.
I0925 20:26:02.631140  3547 net.cpp:198] Eltwise3 needs backward computation.
I0925 20:26:02.631145  3547 net.cpp:198] Scale7 needs backward computation.
I0925 20:26:02.631146  3547 net.cpp:198] BatchNorm7 needs backward computation.
I0925 20:26:02.631150  3547 net.cpp:198] Convolution7 needs backward computation.
I0925 20:26:02.631152  3547 net.cpp:198] PReLU6 needs backward computation.
I0925 20:26:02.631155  3547 net.cpp:198] Scale6 needs backward computation.
I0925 20:26:02.631156  3547 net.cpp:198] BatchNorm6 needs backward computation.
I0925 20:26:02.631160  3547 net.cpp:198] Convolution6 needs backward computation.
I0925 20:26:02.631162  3547 net.cpp:198] Eltwise2_PReLU5_0_split needs backward computation.
I0925 20:26:02.631165  3547 net.cpp:198] PReLU5 needs backward computation.
I0925 20:26:02.631167  3547 net.cpp:198] Eltwise2 needs backward computation.
I0925 20:26:02.631170  3547 net.cpp:198] Scale5 needs backward computation.
I0925 20:26:02.631172  3547 net.cpp:198] BatchNorm5 needs backward computation.
I0925 20:26:02.631175  3547 net.cpp:198] Convolution5 needs backward computation.
I0925 20:26:02.631177  3547 net.cpp:198] PReLU4 needs backward computation.
I0925 20:26:02.631181  3547 net.cpp:198] Scale4 needs backward computation.
I0925 20:26:02.631182  3547 net.cpp:198] BatchNorm4 needs backward computation.
I0925 20:26:02.631184  3547 net.cpp:198] Convolution4 needs backward computation.
I0925 20:26:02.631187  3547 net.cpp:198] Eltwise1_PReLU3_0_split needs backward computation.
I0925 20:26:02.631191  3547 net.cpp:198] PReLU3 needs backward computation.
I0925 20:26:02.631192  3547 net.cpp:198] Eltwise1 needs backward computation.
I0925 20:26:02.631197  3547 net.cpp:198] Scale3 needs backward computation.
I0925 20:26:02.631201  3547 net.cpp:198] BatchNorm3 needs backward computation.
I0925 20:26:02.631202  3547 net.cpp:198] Convolution3 needs backward computation.
I0925 20:26:02.631206  3547 net.cpp:198] PReLU2 needs backward computation.
I0925 20:26:02.631207  3547 net.cpp:198] Scale2 needs backward computation.
I0925 20:26:02.631211  3547 net.cpp:198] BatchNorm2 needs backward computation.
I0925 20:26:02.631212  3547 net.cpp:198] Convolution2 needs backward computation.
I0925 20:26:02.631216  3547 net.cpp:198] Convolution1_PReLU1_0_split needs backward computation.
I0925 20:26:02.631218  3547 net.cpp:198] PReLU1 needs backward computation.
I0925 20:26:02.631220  3547 net.cpp:198] Scale1 needs backward computation.
I0925 20:26:02.631222  3547 net.cpp:198] BatchNorm1 needs backward computation.
I0925 20:26:02.631225  3547 net.cpp:198] Convolution1 needs backward computation.
I0925 20:26:02.631234  3547 net.cpp:200] Data1 does not need backward computation.
I0925 20:26:02.631237  3547 net.cpp:242] This network produces output SoftmaxWithLoss1
I0925 20:26:02.631332  3547 net.cpp:255] Network initialization done.
I0925 20:26:02.635047  3547 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_prelu_train_test.prototxt
I0925 20:26:02.635061  3547 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0925 20:26:02.635066  3547 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_prelu_train_test.prototxt
I0925 20:26:02.635234  3547 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0925 20:26:02.636247  3547 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU4"
  type: "PReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU5"
  type: "PReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU6"
  type: "PReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU7"
  type: "PReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU8"
  type: "PReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU9"
  type: "PReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU10"
  type: "PReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU11"
  type: "PReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU12"
  type: "PReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU13"
  type: "PReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU14"
  type: "PReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU15"
  type: "PReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU16"
  type: "PReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU17"
  type: "PReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU18"
  type: "PReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU19"
  type: "PReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU20"
  type: "PReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU21"
  type: "PReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU22"
  type: "PReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU23"
  type: "PReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU24"
  type: "PReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU25"
  type: "PReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU26"
  type: "PReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU27"
  type: "PReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU28"
  type: "PReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU29"
  type: "PReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU30"
  type: "PReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "co
I0925 20:26:02.692673  3547 layer_factory.hpp:77] Creating layer Data1
I0925 20:26:02.692723  3547 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0925 20:26:02.692734  3547 net.cpp:84] Creating Layer Data1
I0925 20:26:02.692739  3547 net.cpp:380] Data1 -> Data1
I0925 20:26:02.692747  3547 net.cpp:380] Data1 -> Data2
I0925 20:26:02.692754  3547 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0925 20:26:02.692927  3547 data_layer.cpp:45] output data size: 100,3,32,32
I0925 20:26:02.697036  3547 net.cpp:122] Setting up Data1
I0925 20:26:02.697057  3547 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0925 20:26:02.697060  3547 net.cpp:129] Top shape: 100 (100)
I0925 20:26:02.697062  3547 net.cpp:137] Memory required for data: 1229200
I0925 20:26:02.697067  3547 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0925 20:26:02.697077  3547 net.cpp:84] Creating Layer Data2_Data1_1_split
I0925 20:26:02.697080  3547 net.cpp:406] Data2_Data1_1_split <- Data2
I0925 20:26:02.697084  3547 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0925 20:26:02.697091  3547 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0925 20:26:02.697165  3547 net.cpp:122] Setting up Data2_Data1_1_split
I0925 20:26:02.697171  3547 net.cpp:129] Top shape: 100 (100)
I0925 20:26:02.697175  3547 net.cpp:129] Top shape: 100 (100)
I0925 20:26:02.697176  3547 net.cpp:137] Memory required for data: 1230000
I0925 20:26:02.697180  3547 layer_factory.hpp:77] Creating layer Convolution1
I0925 20:26:02.697188  3547 net.cpp:84] Creating Layer Convolution1
I0925 20:26:02.697191  3547 net.cpp:406] Convolution1 <- Data1
I0925 20:26:02.697196  3547 net.cpp:380] Convolution1 -> Convolution1
I0925 20:26:02.698403  3547 net.cpp:122] Setting up Convolution1
I0925 20:26:02.698413  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.698431  3547 net.cpp:137] Memory required for data: 7783600
I0925 20:26:02.698439  3547 layer_factory.hpp:77] Creating layer BatchNorm1
I0925 20:26:02.698444  3547 net.cpp:84] Creating Layer BatchNorm1
I0925 20:26:02.698447  3547 net.cpp:406] BatchNorm1 <- Convolution1
I0925 20:26:02.698451  3547 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0925 20:26:02.698608  3547 net.cpp:122] Setting up BatchNorm1
I0925 20:26:02.698617  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.698619  3547 net.cpp:137] Memory required for data: 14337200
I0925 20:26:02.698628  3547 layer_factory.hpp:77] Creating layer Scale1
I0925 20:26:02.698634  3547 net.cpp:84] Creating Layer Scale1
I0925 20:26:02.698639  3547 net.cpp:406] Scale1 <- Convolution1
I0925 20:26:02.698644  3547 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0925 20:26:02.698684  3547 layer_factory.hpp:77] Creating layer Scale1
I0925 20:26:02.698771  3547 net.cpp:122] Setting up Scale1
I0925 20:26:02.698776  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.698778  3547 net.cpp:137] Memory required for data: 20890800
I0925 20:26:02.698782  3547 layer_factory.hpp:77] Creating layer PReLU1
I0925 20:26:02.698787  3547 net.cpp:84] Creating Layer PReLU1
I0925 20:26:02.698789  3547 net.cpp:406] PReLU1 <- Convolution1
I0925 20:26:02.698792  3547 net.cpp:367] PReLU1 -> Convolution1 (in-place)
I0925 20:26:02.699363  3547 net.cpp:122] Setting up PReLU1
I0925 20:26:02.699371  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.699374  3547 net.cpp:137] Memory required for data: 27444400
I0925 20:26:02.699378  3547 layer_factory.hpp:77] Creating layer Convolution1_PReLU1_0_split
I0925 20:26:02.699384  3547 net.cpp:84] Creating Layer Convolution1_PReLU1_0_split
I0925 20:26:02.699388  3547 net.cpp:406] Convolution1_PReLU1_0_split <- Convolution1
I0925 20:26:02.699390  3547 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_0
I0925 20:26:02.699395  3547 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_1
I0925 20:26:02.699424  3547 net.cpp:122] Setting up Convolution1_PReLU1_0_split
I0925 20:26:02.699429  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.720131  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.720135  3547 net.cpp:137] Memory required for data: 40551600
I0925 20:26:02.720139  3547 layer_factory.hpp:77] Creating layer Convolution2
I0925 20:26:02.720149  3547 net.cpp:84] Creating Layer Convolution2
I0925 20:26:02.720151  3547 net.cpp:406] Convolution2 <- Convolution1_PReLU1_0_split_0
I0925 20:26:02.720156  3547 net.cpp:380] Convolution2 -> Convolution2
I0925 20:26:02.721304  3547 net.cpp:122] Setting up Convolution2
I0925 20:26:02.721314  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.721318  3547 net.cpp:137] Memory required for data: 47105200
I0925 20:26:02.721325  3547 layer_factory.hpp:77] Creating layer BatchNorm2
I0925 20:26:02.721333  3547 net.cpp:84] Creating Layer BatchNorm2
I0925 20:26:02.721335  3547 net.cpp:406] BatchNorm2 <- Convolution2
I0925 20:26:02.721339  3547 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0925 20:26:02.721523  3547 net.cpp:122] Setting up BatchNorm2
I0925 20:26:02.721530  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.721532  3547 net.cpp:137] Memory required for data: 53658800
I0925 20:26:02.721539  3547 layer_factory.hpp:77] Creating layer Scale2
I0925 20:26:02.721544  3547 net.cpp:84] Creating Layer Scale2
I0925 20:26:02.721547  3547 net.cpp:406] Scale2 <- Convolution2
I0925 20:26:02.721551  3547 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0925 20:26:02.721588  3547 layer_factory.hpp:77] Creating layer Scale2
I0925 20:26:02.721693  3547 net.cpp:122] Setting up Scale2
I0925 20:26:02.721698  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.721701  3547 net.cpp:137] Memory required for data: 60212400
I0925 20:26:02.721705  3547 layer_factory.hpp:77] Creating layer PReLU2
I0925 20:26:02.721709  3547 net.cpp:84] Creating Layer PReLU2
I0925 20:26:02.721720  3547 net.cpp:406] PReLU2 <- Convolution2
I0925 20:26:02.721727  3547 net.cpp:367] PReLU2 -> Convolution2 (in-place)
I0925 20:26:02.721837  3547 net.cpp:122] Setting up PReLU2
I0925 20:26:02.721845  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.721848  3547 net.cpp:137] Memory required for data: 66766000
I0925 20:26:02.721851  3547 layer_factory.hpp:77] Creating layer Convolution3
I0925 20:26:02.721858  3547 net.cpp:84] Creating Layer Convolution3
I0925 20:26:02.721860  3547 net.cpp:406] Convolution3 <- Convolution2
I0925 20:26:02.721865  3547 net.cpp:380] Convolution3 -> Convolution3
I0925 20:26:02.723181  3547 net.cpp:122] Setting up Convolution3
I0925 20:26:02.723191  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.723193  3547 net.cpp:137] Memory required for data: 73319600
I0925 20:26:02.723201  3547 layer_factory.hpp:77] Creating layer BatchNorm3
I0925 20:26:02.723206  3547 net.cpp:84] Creating Layer BatchNorm3
I0925 20:26:02.723208  3547 net.cpp:406] BatchNorm3 <- Convolution3
I0925 20:26:02.723213  3547 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0925 20:26:02.723366  3547 net.cpp:122] Setting up BatchNorm3
I0925 20:26:02.723371  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.723372  3547 net.cpp:137] Memory required for data: 79873200
I0925 20:26:02.723376  3547 layer_factory.hpp:77] Creating layer Scale3
I0925 20:26:02.723381  3547 net.cpp:84] Creating Layer Scale3
I0925 20:26:02.723384  3547 net.cpp:406] Scale3 <- Convolution3
I0925 20:26:02.723387  3547 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0925 20:26:02.723417  3547 layer_factory.hpp:77] Creating layer Scale3
I0925 20:26:02.723503  3547 net.cpp:122] Setting up Scale3
I0925 20:26:02.723508  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.723510  3547 net.cpp:137] Memory required for data: 86426800
I0925 20:26:02.723513  3547 layer_factory.hpp:77] Creating layer Eltwise1
I0925 20:26:02.723518  3547 net.cpp:84] Creating Layer Eltwise1
I0925 20:26:02.723520  3547 net.cpp:406] Eltwise1 <- Convolution1_PReLU1_0_split_1
I0925 20:26:02.723523  3547 net.cpp:406] Eltwise1 <- Convolution3
I0925 20:26:02.723527  3547 net.cpp:380] Eltwise1 -> Eltwise1
I0925 20:26:02.723546  3547 net.cpp:122] Setting up Eltwise1
I0925 20:26:02.723549  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.723551  3547 net.cpp:137] Memory required for data: 92980400
I0925 20:26:02.723553  3547 layer_factory.hpp:77] Creating layer PReLU3
I0925 20:26:02.723557  3547 net.cpp:84] Creating Layer PReLU3
I0925 20:26:02.723561  3547 net.cpp:406] PReLU3 <- Eltwise1
I0925 20:26:02.723563  3547 net.cpp:367] PReLU3 -> Eltwise1 (in-place)
I0925 20:26:02.723636  3547 net.cpp:122] Setting up PReLU3
I0925 20:26:02.723640  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.723642  3547 net.cpp:137] Memory required for data: 99534000
I0925 20:26:02.723645  3547 layer_factory.hpp:77] Creating layer Eltwise1_PReLU3_0_split
I0925 20:26:02.723650  3547 net.cpp:84] Creating Layer Eltwise1_PReLU3_0_split
I0925 20:26:02.723652  3547 net.cpp:406] Eltwise1_PReLU3_0_split <- Eltwise1
I0925 20:26:02.723656  3547 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_0
I0925 20:26:02.723659  3547 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_1
I0925 20:26:02.723686  3547 net.cpp:122] Setting up Eltwise1_PReLU3_0_split
I0925 20:26:02.723690  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.723693  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.723695  3547 net.cpp:137] Memory required for data: 112641200
I0925 20:26:02.723697  3547 layer_factory.hpp:77] Creating layer Convolution4
I0925 20:26:02.723704  3547 net.cpp:84] Creating Layer Convolution4
I0925 20:26:02.723706  3547 net.cpp:406] Convolution4 <- Eltwise1_PReLU3_0_split_0
I0925 20:26:02.723711  3547 net.cpp:380] Convolution4 -> Convolution4
I0925 20:26:02.724697  3547 net.cpp:122] Setting up Convolution4
I0925 20:26:02.724706  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.724716  3547 net.cpp:137] Memory required for data: 119194800
I0925 20:26:02.724721  3547 layer_factory.hpp:77] Creating layer BatchNorm4
I0925 20:26:02.724726  3547 net.cpp:84] Creating Layer BatchNorm4
I0925 20:26:02.724730  3547 net.cpp:406] BatchNorm4 <- Convolution4
I0925 20:26:02.724741  3547 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0925 20:26:02.724897  3547 net.cpp:122] Setting up BatchNorm4
I0925 20:26:02.724901  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.724905  3547 net.cpp:137] Memory required for data: 125748400
I0925 20:26:02.724908  3547 layer_factory.hpp:77] Creating layer Scale4
I0925 20:26:02.724912  3547 net.cpp:84] Creating Layer Scale4
I0925 20:26:02.724915  3547 net.cpp:406] Scale4 <- Convolution4
I0925 20:26:02.724918  3547 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0925 20:26:02.724948  3547 layer_factory.hpp:77] Creating layer Scale4
I0925 20:26:02.725031  3547 net.cpp:122] Setting up Scale4
I0925 20:26:02.725036  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.725039  3547 net.cpp:137] Memory required for data: 132302000
I0925 20:26:02.725042  3547 layer_factory.hpp:77] Creating layer PReLU4
I0925 20:26:02.725046  3547 net.cpp:84] Creating Layer PReLU4
I0925 20:26:02.725049  3547 net.cpp:406] PReLU4 <- Convolution4
I0925 20:26:02.725051  3547 net.cpp:367] PReLU4 -> Convolution4 (in-place)
I0925 20:26:02.725123  3547 net.cpp:122] Setting up PReLU4
I0925 20:26:02.725127  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.725129  3547 net.cpp:137] Memory required for data: 138855600
I0925 20:26:02.725132  3547 layer_factory.hpp:77] Creating layer Convolution5
I0925 20:26:02.725139  3547 net.cpp:84] Creating Layer Convolution5
I0925 20:26:02.725142  3547 net.cpp:406] Convolution5 <- Convolution4
I0925 20:26:02.725145  3547 net.cpp:380] Convolution5 -> Convolution5
I0925 20:26:02.726079  3547 net.cpp:122] Setting up Convolution5
I0925 20:26:02.726089  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.726091  3547 net.cpp:137] Memory required for data: 145409200
I0925 20:26:02.726100  3547 layer_factory.hpp:77] Creating layer BatchNorm5
I0925 20:26:02.726104  3547 net.cpp:84] Creating Layer BatchNorm5
I0925 20:26:02.726107  3547 net.cpp:406] BatchNorm5 <- Convolution5
I0925 20:26:02.726110  3547 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0925 20:26:02.726259  3547 net.cpp:122] Setting up BatchNorm5
I0925 20:26:02.726264  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.726266  3547 net.cpp:137] Memory required for data: 151962800
I0925 20:26:02.726270  3547 layer_factory.hpp:77] Creating layer Scale5
I0925 20:26:02.726274  3547 net.cpp:84] Creating Layer Scale5
I0925 20:26:02.726277  3547 net.cpp:406] Scale5 <- Convolution5
I0925 20:26:02.726280  3547 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0925 20:26:02.726310  3547 layer_factory.hpp:77] Creating layer Scale5
I0925 20:26:02.726393  3547 net.cpp:122] Setting up Scale5
I0925 20:26:02.726397  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.726399  3547 net.cpp:137] Memory required for data: 158516400
I0925 20:26:02.726403  3547 layer_factory.hpp:77] Creating layer Eltwise2
I0925 20:26:02.726408  3547 net.cpp:84] Creating Layer Eltwise2
I0925 20:26:02.726410  3547 net.cpp:406] Eltwise2 <- Eltwise1_PReLU3_0_split_1
I0925 20:26:02.726413  3547 net.cpp:406] Eltwise2 <- Convolution5
I0925 20:26:02.726418  3547 net.cpp:380] Eltwise2 -> Eltwise2
I0925 20:26:02.726434  3547 net.cpp:122] Setting up Eltwise2
I0925 20:26:02.726438  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.726440  3547 net.cpp:137] Memory required for data: 165070000
I0925 20:26:02.726442  3547 layer_factory.hpp:77] Creating layer PReLU5
I0925 20:26:02.726447  3547 net.cpp:84] Creating Layer PReLU5
I0925 20:26:02.726449  3547 net.cpp:406] PReLU5 <- Eltwise2
I0925 20:26:02.726452  3547 net.cpp:367] PReLU5 -> Eltwise2 (in-place)
I0925 20:26:02.726523  3547 net.cpp:122] Setting up PReLU5
I0925 20:26:02.726533  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.726536  3547 net.cpp:137] Memory required for data: 171623600
I0925 20:26:02.726539  3547 layer_factory.hpp:77] Creating layer Eltwise2_PReLU5_0_split
I0925 20:26:02.726542  3547 net.cpp:84] Creating Layer Eltwise2_PReLU5_0_split
I0925 20:26:02.726546  3547 net.cpp:406] Eltwise2_PReLU5_0_split <- Eltwise2
I0925 20:26:02.726549  3547 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_0
I0925 20:26:02.726553  3547 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_1
I0925 20:26:02.726583  3547 net.cpp:122] Setting up Eltwise2_PReLU5_0_split
I0925 20:26:02.726585  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.726589  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.726591  3547 net.cpp:137] Memory required for data: 184730800
I0925 20:26:02.726594  3547 layer_factory.hpp:77] Creating layer Convolution6
I0925 20:26:02.726600  3547 net.cpp:84] Creating Layer Convolution6
I0925 20:26:02.726603  3547 net.cpp:406] Convolution6 <- Eltwise2_PReLU5_0_split_0
I0925 20:26:02.726606  3547 net.cpp:380] Convolution6 -> Convolution6
I0925 20:26:02.727537  3547 net.cpp:122] Setting up Convolution6
I0925 20:26:02.727546  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.727548  3547 net.cpp:137] Memory required for data: 191284400
I0925 20:26:02.727553  3547 layer_factory.hpp:77] Creating layer BatchNorm6
I0925 20:26:02.727560  3547 net.cpp:84] Creating Layer BatchNorm6
I0925 20:26:02.727561  3547 net.cpp:406] BatchNorm6 <- Convolution6
I0925 20:26:02.727566  3547 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0925 20:26:02.727715  3547 net.cpp:122] Setting up BatchNorm6
I0925 20:26:02.727720  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.727722  3547 net.cpp:137] Memory required for data: 197838000
I0925 20:26:02.727726  3547 layer_factory.hpp:77] Creating layer Scale6
I0925 20:26:02.727731  3547 net.cpp:84] Creating Layer Scale6
I0925 20:26:02.727733  3547 net.cpp:406] Scale6 <- Convolution6
I0925 20:26:02.727737  3547 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0925 20:26:02.727766  3547 layer_factory.hpp:77] Creating layer Scale6
I0925 20:26:02.727850  3547 net.cpp:122] Setting up Scale6
I0925 20:26:02.727854  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.727856  3547 net.cpp:137] Memory required for data: 204391600
I0925 20:26:02.727860  3547 layer_factory.hpp:77] Creating layer PReLU6
I0925 20:26:02.727864  3547 net.cpp:84] Creating Layer PReLU6
I0925 20:26:02.727865  3547 net.cpp:406] PReLU6 <- Convolution6
I0925 20:26:02.727869  3547 net.cpp:367] PReLU6 -> Convolution6 (in-place)
I0925 20:26:02.727941  3547 net.cpp:122] Setting up PReLU6
I0925 20:26:02.727946  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.727947  3547 net.cpp:137] Memory required for data: 210945200
I0925 20:26:02.727951  3547 layer_factory.hpp:77] Creating layer Convolution7
I0925 20:26:02.727957  3547 net.cpp:84] Creating Layer Convolution7
I0925 20:26:02.727959  3547 net.cpp:406] Convolution7 <- Convolution6
I0925 20:26:02.727963  3547 net.cpp:380] Convolution7 -> Convolution7
I0925 20:26:02.728930  3547 net.cpp:122] Setting up Convolution7
I0925 20:26:02.728940  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.728942  3547 net.cpp:137] Memory required for data: 217498800
I0925 20:26:02.728947  3547 layer_factory.hpp:77] Creating layer BatchNorm7
I0925 20:26:02.728953  3547 net.cpp:84] Creating Layer BatchNorm7
I0925 20:26:02.728956  3547 net.cpp:406] BatchNorm7 <- Convolution7
I0925 20:26:02.728960  3547 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0925 20:26:02.729113  3547 net.cpp:122] Setting up BatchNorm7
I0925 20:26:02.729117  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.729120  3547 net.cpp:137] Memory required for data: 224052400
I0925 20:26:02.729125  3547 layer_factory.hpp:77] Creating layer Scale7
I0925 20:26:02.729128  3547 net.cpp:84] Creating Layer Scale7
I0925 20:26:02.729137  3547 net.cpp:406] Scale7 <- Convolution7
I0925 20:26:02.729142  3547 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0925 20:26:02.729172  3547 layer_factory.hpp:77] Creating layer Scale7
I0925 20:26:02.729259  3547 net.cpp:122] Setting up Scale7
I0925 20:26:02.729264  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.729265  3547 net.cpp:137] Memory required for data: 230606000
I0925 20:26:02.729269  3547 layer_factory.hpp:77] Creating layer Eltwise3
I0925 20:26:02.729274  3547 net.cpp:84] Creating Layer Eltwise3
I0925 20:26:02.729276  3547 net.cpp:406] Eltwise3 <- Eltwise2_PReLU5_0_split_1
I0925 20:26:02.729279  3547 net.cpp:406] Eltwise3 <- Convolution7
I0925 20:26:02.729282  3547 net.cpp:380] Eltwise3 -> Eltwise3
I0925 20:26:02.729300  3547 net.cpp:122] Setting up Eltwise3
I0925 20:26:02.729303  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.729305  3547 net.cpp:137] Memory required for data: 237159600
I0925 20:26:02.729307  3547 layer_factory.hpp:77] Creating layer PReLU7
I0925 20:26:02.729311  3547 net.cpp:84] Creating Layer PReLU7
I0925 20:26:02.729313  3547 net.cpp:406] PReLU7 <- Eltwise3
I0925 20:26:02.729316  3547 net.cpp:367] PReLU7 -> Eltwise3 (in-place)
I0925 20:26:02.729389  3547 net.cpp:122] Setting up PReLU7
I0925 20:26:02.729394  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.729396  3547 net.cpp:137] Memory required for data: 243713200
I0925 20:26:02.729399  3547 layer_factory.hpp:77] Creating layer Eltwise3_PReLU7_0_split
I0925 20:26:02.729403  3547 net.cpp:84] Creating Layer Eltwise3_PReLU7_0_split
I0925 20:26:02.729405  3547 net.cpp:406] Eltwise3_PReLU7_0_split <- Eltwise3
I0925 20:26:02.729408  3547 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_0
I0925 20:26:02.729413  3547 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_1
I0925 20:26:02.729439  3547 net.cpp:122] Setting up Eltwise3_PReLU7_0_split
I0925 20:26:02.729444  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.729446  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.750865  3547 net.cpp:137] Memory required for data: 256820400
I0925 20:26:02.750876  3547 layer_factory.hpp:77] Creating layer Convolution8
I0925 20:26:02.750886  3547 net.cpp:84] Creating Layer Convolution8
I0925 20:26:02.750890  3547 net.cpp:406] Convolution8 <- Eltwise3_PReLU7_0_split_0
I0925 20:26:02.750895  3547 net.cpp:380] Convolution8 -> Convolution8
I0925 20:26:02.751952  3547 net.cpp:122] Setting up Convolution8
I0925 20:26:02.751963  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.751966  3547 net.cpp:137] Memory required for data: 263374000
I0925 20:26:02.751971  3547 layer_factory.hpp:77] Creating layer BatchNorm8
I0925 20:26:02.751976  3547 net.cpp:84] Creating Layer BatchNorm8
I0925 20:26:02.751979  3547 net.cpp:406] BatchNorm8 <- Convolution8
I0925 20:26:02.751983  3547 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0925 20:26:02.752173  3547 net.cpp:122] Setting up BatchNorm8
I0925 20:26:02.752179  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.752182  3547 net.cpp:137] Memory required for data: 269927600
I0925 20:26:02.752187  3547 layer_factory.hpp:77] Creating layer Scale8
I0925 20:26:02.752193  3547 net.cpp:84] Creating Layer Scale8
I0925 20:26:02.752195  3547 net.cpp:406] Scale8 <- Convolution8
I0925 20:26:02.752199  3547 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0925 20:26:02.752240  3547 layer_factory.hpp:77] Creating layer Scale8
I0925 20:26:02.752342  3547 net.cpp:122] Setting up Scale8
I0925 20:26:02.752360  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.752363  3547 net.cpp:137] Memory required for data: 276481200
I0925 20:26:02.752380  3547 layer_factory.hpp:77] Creating layer PReLU8
I0925 20:26:02.752387  3547 net.cpp:84] Creating Layer PReLU8
I0925 20:26:02.752401  3547 net.cpp:406] PReLU8 <- Convolution8
I0925 20:26:02.752406  3547 net.cpp:367] PReLU8 -> Convolution8 (in-place)
I0925 20:26:02.752490  3547 net.cpp:122] Setting up PReLU8
I0925 20:26:02.752512  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.752516  3547 net.cpp:137] Memory required for data: 283034800
I0925 20:26:02.752519  3547 layer_factory.hpp:77] Creating layer Convolution9
I0925 20:26:02.752526  3547 net.cpp:84] Creating Layer Convolution9
I0925 20:26:02.752529  3547 net.cpp:406] Convolution9 <- Convolution8
I0925 20:26:02.752533  3547 net.cpp:380] Convolution9 -> Convolution9
I0925 20:26:02.753648  3547 net.cpp:122] Setting up Convolution9
I0925 20:26:02.753657  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.753659  3547 net.cpp:137] Memory required for data: 289588400
I0925 20:26:02.753671  3547 layer_factory.hpp:77] Creating layer BatchNorm9
I0925 20:26:02.753677  3547 net.cpp:84] Creating Layer BatchNorm9
I0925 20:26:02.753679  3547 net.cpp:406] BatchNorm9 <- Convolution9
I0925 20:26:02.753684  3547 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0925 20:26:02.753839  3547 net.cpp:122] Setting up BatchNorm9
I0925 20:26:02.753844  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.753846  3547 net.cpp:137] Memory required for data: 296142000
I0925 20:26:02.753851  3547 layer_factory.hpp:77] Creating layer Scale9
I0925 20:26:02.753855  3547 net.cpp:84] Creating Layer Scale9
I0925 20:26:02.753857  3547 net.cpp:406] Scale9 <- Convolution9
I0925 20:26:02.753860  3547 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0925 20:26:02.753891  3547 layer_factory.hpp:77] Creating layer Scale9
I0925 20:26:02.753978  3547 net.cpp:122] Setting up Scale9
I0925 20:26:02.753983  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.753985  3547 net.cpp:137] Memory required for data: 302695600
I0925 20:26:02.753989  3547 layer_factory.hpp:77] Creating layer Eltwise4
I0925 20:26:02.753993  3547 net.cpp:84] Creating Layer Eltwise4
I0925 20:26:02.753995  3547 net.cpp:406] Eltwise4 <- Eltwise3_PReLU7_0_split_1
I0925 20:26:02.753998  3547 net.cpp:406] Eltwise4 <- Convolution9
I0925 20:26:02.754003  3547 net.cpp:380] Eltwise4 -> Eltwise4
I0925 20:26:02.754020  3547 net.cpp:122] Setting up Eltwise4
I0925 20:26:02.754024  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.754026  3547 net.cpp:137] Memory required for data: 309249200
I0925 20:26:02.754029  3547 layer_factory.hpp:77] Creating layer PReLU9
I0925 20:26:02.754034  3547 net.cpp:84] Creating Layer PReLU9
I0925 20:26:02.754036  3547 net.cpp:406] PReLU9 <- Eltwise4
I0925 20:26:02.754040  3547 net.cpp:367] PReLU9 -> Eltwise4 (in-place)
I0925 20:26:02.754117  3547 net.cpp:122] Setting up PReLU9
I0925 20:26:02.754122  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.754124  3547 net.cpp:137] Memory required for data: 315802800
I0925 20:26:02.754127  3547 layer_factory.hpp:77] Creating layer Eltwise4_PReLU9_0_split
I0925 20:26:02.754130  3547 net.cpp:84] Creating Layer Eltwise4_PReLU9_0_split
I0925 20:26:02.754133  3547 net.cpp:406] Eltwise4_PReLU9_0_split <- Eltwise4
I0925 20:26:02.754137  3547 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_0
I0925 20:26:02.754142  3547 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_1
I0925 20:26:02.754169  3547 net.cpp:122] Setting up Eltwise4_PReLU9_0_split
I0925 20:26:02.754173  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.754175  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.754178  3547 net.cpp:137] Memory required for data: 328910000
I0925 20:26:02.754179  3547 layer_factory.hpp:77] Creating layer Convolution10
I0925 20:26:02.754186  3547 net.cpp:84] Creating Layer Convolution10
I0925 20:26:02.754189  3547 net.cpp:406] Convolution10 <- Eltwise4_PReLU9_0_split_0
I0925 20:26:02.754194  3547 net.cpp:380] Convolution10 -> Convolution10
I0925 20:26:02.755213  3547 net.cpp:122] Setting up Convolution10
I0925 20:26:02.755223  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.755225  3547 net.cpp:137] Memory required for data: 335463600
I0925 20:26:02.755230  3547 layer_factory.hpp:77] Creating layer BatchNorm10
I0925 20:26:02.755244  3547 net.cpp:84] Creating Layer BatchNorm10
I0925 20:26:02.755246  3547 net.cpp:406] BatchNorm10 <- Convolution10
I0925 20:26:02.755250  3547 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0925 20:26:02.755406  3547 net.cpp:122] Setting up BatchNorm10
I0925 20:26:02.755411  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.755414  3547 net.cpp:137] Memory required for data: 342017200
I0925 20:26:02.755419  3547 layer_factory.hpp:77] Creating layer Scale10
I0925 20:26:02.755424  3547 net.cpp:84] Creating Layer Scale10
I0925 20:26:02.755426  3547 net.cpp:406] Scale10 <- Convolution10
I0925 20:26:02.755429  3547 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0925 20:26:02.755460  3547 layer_factory.hpp:77] Creating layer Scale10
I0925 20:26:02.755548  3547 net.cpp:122] Setting up Scale10
I0925 20:26:02.755553  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.755554  3547 net.cpp:137] Memory required for data: 348570800
I0925 20:26:02.755558  3547 layer_factory.hpp:77] Creating layer PReLU10
I0925 20:26:02.755563  3547 net.cpp:84] Creating Layer PReLU10
I0925 20:26:02.755564  3547 net.cpp:406] PReLU10 <- Convolution10
I0925 20:26:02.755568  3547 net.cpp:367] PReLU10 -> Convolution10 (in-place)
I0925 20:26:02.755642  3547 net.cpp:122] Setting up PReLU10
I0925 20:26:02.755647  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.755650  3547 net.cpp:137] Memory required for data: 355124400
I0925 20:26:02.755652  3547 layer_factory.hpp:77] Creating layer Convolution11
I0925 20:26:02.755659  3547 net.cpp:84] Creating Layer Convolution11
I0925 20:26:02.755661  3547 net.cpp:406] Convolution11 <- Convolution10
I0925 20:26:02.755666  3547 net.cpp:380] Convolution11 -> Convolution11
I0925 20:26:02.756963  3547 net.cpp:122] Setting up Convolution11
I0925 20:26:02.756971  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.756973  3547 net.cpp:137] Memory required for data: 361678000
I0925 20:26:02.756978  3547 layer_factory.hpp:77] Creating layer BatchNorm11
I0925 20:26:02.756984  3547 net.cpp:84] Creating Layer BatchNorm11
I0925 20:26:02.756986  3547 net.cpp:406] BatchNorm11 <- Convolution11
I0925 20:26:02.756990  3547 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0925 20:26:02.757148  3547 net.cpp:122] Setting up BatchNorm11
I0925 20:26:02.757153  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.757155  3547 net.cpp:137] Memory required for data: 368231600
I0925 20:26:02.757160  3547 layer_factory.hpp:77] Creating layer Scale11
I0925 20:26:02.757165  3547 net.cpp:84] Creating Layer Scale11
I0925 20:26:02.757167  3547 net.cpp:406] Scale11 <- Convolution11
I0925 20:26:02.757171  3547 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0925 20:26:02.757201  3547 layer_factory.hpp:77] Creating layer Scale11
I0925 20:26:02.757287  3547 net.cpp:122] Setting up Scale11
I0925 20:26:02.757292  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.757293  3547 net.cpp:137] Memory required for data: 374785200
I0925 20:26:02.757297  3547 layer_factory.hpp:77] Creating layer Eltwise5
I0925 20:26:02.757302  3547 net.cpp:84] Creating Layer Eltwise5
I0925 20:26:02.757304  3547 net.cpp:406] Eltwise5 <- Eltwise4_PReLU9_0_split_1
I0925 20:26:02.757308  3547 net.cpp:406] Eltwise5 <- Convolution11
I0925 20:26:02.757310  3547 net.cpp:380] Eltwise5 -> Eltwise5
I0925 20:26:02.757328  3547 net.cpp:122] Setting up Eltwise5
I0925 20:26:02.757333  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.757334  3547 net.cpp:137] Memory required for data: 381338800
I0925 20:26:02.757336  3547 layer_factory.hpp:77] Creating layer PReLU11
I0925 20:26:02.757340  3547 net.cpp:84] Creating Layer PReLU11
I0925 20:26:02.757342  3547 net.cpp:406] PReLU11 <- Eltwise5
I0925 20:26:02.757345  3547 net.cpp:367] PReLU11 -> Eltwise5 (in-place)
I0925 20:26:02.757416  3547 net.cpp:122] Setting up PReLU11
I0925 20:26:02.757421  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.757423  3547 net.cpp:137] Memory required for data: 387892400
I0925 20:26:02.757432  3547 layer_factory.hpp:77] Creating layer Eltwise5_PReLU11_0_split
I0925 20:26:02.757436  3547 net.cpp:84] Creating Layer Eltwise5_PReLU11_0_split
I0925 20:26:02.757438  3547 net.cpp:406] Eltwise5_PReLU11_0_split <- Eltwise5
I0925 20:26:02.757442  3547 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_0
I0925 20:26:02.757447  3547 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_1
I0925 20:26:02.757473  3547 net.cpp:122] Setting up Eltwise5_PReLU11_0_split
I0925 20:26:02.757477  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.757480  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.757483  3547 net.cpp:137] Memory required for data: 400999600
I0925 20:26:02.757484  3547 layer_factory.hpp:77] Creating layer Convolution12
I0925 20:26:02.757491  3547 net.cpp:84] Creating Layer Convolution12
I0925 20:26:02.757493  3547 net.cpp:406] Convolution12 <- Eltwise5_PReLU11_0_split_0
I0925 20:26:02.757498  3547 net.cpp:380] Convolution12 -> Convolution12
I0925 20:26:02.758448  3547 net.cpp:122] Setting up Convolution12
I0925 20:26:02.758457  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.758460  3547 net.cpp:137] Memory required for data: 407553200
I0925 20:26:02.758464  3547 layer_factory.hpp:77] Creating layer BatchNorm12
I0925 20:26:02.758469  3547 net.cpp:84] Creating Layer BatchNorm12
I0925 20:26:02.758471  3547 net.cpp:406] BatchNorm12 <- Convolution12
I0925 20:26:02.758476  3547 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0925 20:26:02.758630  3547 net.cpp:122] Setting up BatchNorm12
I0925 20:26:02.758635  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.758636  3547 net.cpp:137] Memory required for data: 414106800
I0925 20:26:02.758641  3547 layer_factory.hpp:77] Creating layer Scale12
I0925 20:26:02.758644  3547 net.cpp:84] Creating Layer Scale12
I0925 20:26:02.758647  3547 net.cpp:406] Scale12 <- Convolution12
I0925 20:26:02.758651  3547 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0925 20:26:02.758680  3547 layer_factory.hpp:77] Creating layer Scale12
I0925 20:26:02.758769  3547 net.cpp:122] Setting up Scale12
I0925 20:26:02.758772  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.758774  3547 net.cpp:137] Memory required for data: 420660400
I0925 20:26:02.758779  3547 layer_factory.hpp:77] Creating layer PReLU12
I0925 20:26:02.758781  3547 net.cpp:84] Creating Layer PReLU12
I0925 20:26:02.758783  3547 net.cpp:406] PReLU12 <- Convolution12
I0925 20:26:02.758786  3547 net.cpp:367] PReLU12 -> Convolution12 (in-place)
I0925 20:26:02.758859  3547 net.cpp:122] Setting up PReLU12
I0925 20:26:02.758864  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.758867  3547 net.cpp:137] Memory required for data: 427214000
I0925 20:26:02.758869  3547 layer_factory.hpp:77] Creating layer Convolution13
I0925 20:26:02.758875  3547 net.cpp:84] Creating Layer Convolution13
I0925 20:26:02.758877  3547 net.cpp:406] Convolution13 <- Convolution12
I0925 20:26:02.758882  3547 net.cpp:380] Convolution13 -> Convolution13
I0925 20:26:02.759829  3547 net.cpp:122] Setting up Convolution13
I0925 20:26:02.759836  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.759840  3547 net.cpp:137] Memory required for data: 433767600
I0925 20:26:02.759843  3547 layer_factory.hpp:77] Creating layer BatchNorm13
I0925 20:26:02.759850  3547 net.cpp:84] Creating Layer BatchNorm13
I0925 20:26:02.759851  3547 net.cpp:406] BatchNorm13 <- Convolution13
I0925 20:26:02.759855  3547 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0925 20:26:02.760007  3547 net.cpp:122] Setting up BatchNorm13
I0925 20:26:02.760011  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.760015  3547 net.cpp:137] Memory required for data: 440321200
I0925 20:26:02.760018  3547 layer_factory.hpp:77] Creating layer Scale13
I0925 20:26:02.760023  3547 net.cpp:84] Creating Layer Scale13
I0925 20:26:02.760026  3547 net.cpp:406] Scale13 <- Convolution13
I0925 20:26:02.760035  3547 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0925 20:26:02.760067  3547 layer_factory.hpp:77] Creating layer Scale13
I0925 20:26:02.760154  3547 net.cpp:122] Setting up Scale13
I0925 20:26:02.760157  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.760159  3547 net.cpp:137] Memory required for data: 446874800
I0925 20:26:02.760164  3547 layer_factory.hpp:77] Creating layer Eltwise6
I0925 20:26:02.760174  3547 net.cpp:84] Creating Layer Eltwise6
I0925 20:26:02.760175  3547 net.cpp:406] Eltwise6 <- Eltwise5_PReLU11_0_split_1
I0925 20:26:02.760179  3547 net.cpp:406] Eltwise6 <- Convolution13
I0925 20:26:02.760182  3547 net.cpp:380] Eltwise6 -> Eltwise6
I0925 20:26:02.760200  3547 net.cpp:122] Setting up Eltwise6
I0925 20:26:02.760203  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.760205  3547 net.cpp:137] Memory required for data: 453428400
I0925 20:26:02.760207  3547 layer_factory.hpp:77] Creating layer PReLU13
I0925 20:26:02.760212  3547 net.cpp:84] Creating Layer PReLU13
I0925 20:26:02.760215  3547 net.cpp:406] PReLU13 <- Eltwise6
I0925 20:26:02.760217  3547 net.cpp:367] PReLU13 -> Eltwise6 (in-place)
I0925 20:26:02.760291  3547 net.cpp:122] Setting up PReLU13
I0925 20:26:02.760295  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.760298  3547 net.cpp:137] Memory required for data: 459982000
I0925 20:26:02.760300  3547 layer_factory.hpp:77] Creating layer Eltwise6_PReLU13_0_split
I0925 20:26:02.760304  3547 net.cpp:84] Creating Layer Eltwise6_PReLU13_0_split
I0925 20:26:02.760306  3547 net.cpp:406] Eltwise6_PReLU13_0_split <- Eltwise6
I0925 20:26:02.760309  3547 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_0
I0925 20:26:02.760313  3547 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_1
I0925 20:26:02.760341  3547 net.cpp:122] Setting up Eltwise6_PReLU13_0_split
I0925 20:26:02.760344  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.760347  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.781388  3547 net.cpp:137] Memory required for data: 473089200
I0925 20:26:02.781399  3547 layer_factory.hpp:77] Creating layer Convolution14
I0925 20:26:02.781409  3547 net.cpp:84] Creating Layer Convolution14
I0925 20:26:02.781412  3547 net.cpp:406] Convolution14 <- Eltwise6_PReLU13_0_split_0
I0925 20:26:02.781419  3547 net.cpp:380] Convolution14 -> Convolution14
I0925 20:26:02.782488  3547 net.cpp:122] Setting up Convolution14
I0925 20:26:02.782498  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.782501  3547 net.cpp:137] Memory required for data: 479642800
I0925 20:26:02.782506  3547 layer_factory.hpp:77] Creating layer BatchNorm14
I0925 20:26:02.782512  3547 net.cpp:84] Creating Layer BatchNorm14
I0925 20:26:02.782516  3547 net.cpp:406] BatchNorm14 <- Convolution14
I0925 20:26:02.782519  3547 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0925 20:26:02.782711  3547 net.cpp:122] Setting up BatchNorm14
I0925 20:26:02.782718  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.782721  3547 net.cpp:137] Memory required for data: 486196400
I0925 20:26:02.782727  3547 layer_factory.hpp:77] Creating layer Scale14
I0925 20:26:02.782732  3547 net.cpp:84] Creating Layer Scale14
I0925 20:26:02.782734  3547 net.cpp:406] Scale14 <- Convolution14
I0925 20:26:02.782737  3547 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0925 20:26:02.782771  3547 layer_factory.hpp:77] Creating layer Scale14
I0925 20:26:02.782893  3547 net.cpp:122] Setting up Scale14
I0925 20:26:02.782901  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.782903  3547 net.cpp:137] Memory required for data: 492750000
I0925 20:26:02.782907  3547 layer_factory.hpp:77] Creating layer PReLU14
I0925 20:26:02.782912  3547 net.cpp:84] Creating Layer PReLU14
I0925 20:26:02.782915  3547 net.cpp:406] PReLU14 <- Convolution14
I0925 20:26:02.782918  3547 net.cpp:367] PReLU14 -> Convolution14 (in-place)
I0925 20:26:02.782997  3547 net.cpp:122] Setting up PReLU14
I0925 20:26:02.783002  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.783012  3547 net.cpp:137] Memory required for data: 499303600
I0925 20:26:02.783016  3547 layer_factory.hpp:77] Creating layer Convolution15
I0925 20:26:02.783023  3547 net.cpp:84] Creating Layer Convolution15
I0925 20:26:02.783026  3547 net.cpp:406] Convolution15 <- Convolution14
I0925 20:26:02.783030  3547 net.cpp:380] Convolution15 -> Convolution15
I0925 20:26:02.784287  3547 net.cpp:122] Setting up Convolution15
I0925 20:26:02.784296  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.784299  3547 net.cpp:137] Memory required for data: 505857200
I0925 20:26:02.784303  3547 layer_factory.hpp:77] Creating layer BatchNorm15
I0925 20:26:02.784308  3547 net.cpp:84] Creating Layer BatchNorm15
I0925 20:26:02.784310  3547 net.cpp:406] BatchNorm15 <- Convolution15
I0925 20:26:02.784315  3547 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0925 20:26:02.784478  3547 net.cpp:122] Setting up BatchNorm15
I0925 20:26:02.784483  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.784485  3547 net.cpp:137] Memory required for data: 512410800
I0925 20:26:02.784490  3547 layer_factory.hpp:77] Creating layer Scale15
I0925 20:26:02.784504  3547 net.cpp:84] Creating Layer Scale15
I0925 20:26:02.784507  3547 net.cpp:406] Scale15 <- Convolution15
I0925 20:26:02.784512  3547 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0925 20:26:02.784554  3547 layer_factory.hpp:77] Creating layer Scale15
I0925 20:26:02.784643  3547 net.cpp:122] Setting up Scale15
I0925 20:26:02.784648  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.784651  3547 net.cpp:137] Memory required for data: 518964400
I0925 20:26:02.784654  3547 layer_factory.hpp:77] Creating layer Eltwise7
I0925 20:26:02.784659  3547 net.cpp:84] Creating Layer Eltwise7
I0925 20:26:02.784662  3547 net.cpp:406] Eltwise7 <- Eltwise6_PReLU13_0_split_1
I0925 20:26:02.784665  3547 net.cpp:406] Eltwise7 <- Convolution15
I0925 20:26:02.784668  3547 net.cpp:380] Eltwise7 -> Eltwise7
I0925 20:26:02.784687  3547 net.cpp:122] Setting up Eltwise7
I0925 20:26:02.784690  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.784693  3547 net.cpp:137] Memory required for data: 525518000
I0925 20:26:02.784695  3547 layer_factory.hpp:77] Creating layer PReLU15
I0925 20:26:02.784698  3547 net.cpp:84] Creating Layer PReLU15
I0925 20:26:02.784700  3547 net.cpp:406] PReLU15 <- Eltwise7
I0925 20:26:02.784704  3547 net.cpp:367] PReLU15 -> Eltwise7 (in-place)
I0925 20:26:02.784780  3547 net.cpp:122] Setting up PReLU15
I0925 20:26:02.784785  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.784787  3547 net.cpp:137] Memory required for data: 532071600
I0925 20:26:02.784790  3547 layer_factory.hpp:77] Creating layer Eltwise7_PReLU15_0_split
I0925 20:26:02.784795  3547 net.cpp:84] Creating Layer Eltwise7_PReLU15_0_split
I0925 20:26:02.784796  3547 net.cpp:406] Eltwise7_PReLU15_0_split <- Eltwise7
I0925 20:26:02.784799  3547 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_0
I0925 20:26:02.784803  3547 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_1
I0925 20:26:02.784832  3547 net.cpp:122] Setting up Eltwise7_PReLU15_0_split
I0925 20:26:02.784844  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.784847  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.784849  3547 net.cpp:137] Memory required for data: 545178800
I0925 20:26:02.784852  3547 layer_factory.hpp:77] Creating layer Convolution16
I0925 20:26:02.784868  3547 net.cpp:84] Creating Layer Convolution16
I0925 20:26:02.784870  3547 net.cpp:406] Convolution16 <- Eltwise7_PReLU15_0_split_0
I0925 20:26:02.784875  3547 net.cpp:380] Convolution16 -> Convolution16
I0925 20:26:02.785526  3547 net.cpp:122] Setting up Convolution16
I0925 20:26:02.785533  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.785536  3547 net.cpp:137] Memory required for data: 551732400
I0925 20:26:02.785539  3547 layer_factory.hpp:77] Creating layer BatchNorm16
I0925 20:26:02.785552  3547 net.cpp:84] Creating Layer BatchNorm16
I0925 20:26:02.785554  3547 net.cpp:406] BatchNorm16 <- Convolution16
I0925 20:26:02.785558  3547 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0925 20:26:02.785714  3547 net.cpp:122] Setting up BatchNorm16
I0925 20:26:02.785719  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.785722  3547 net.cpp:137] Memory required for data: 558286000
I0925 20:26:02.785727  3547 layer_factory.hpp:77] Creating layer Scale16
I0925 20:26:02.785729  3547 net.cpp:84] Creating Layer Scale16
I0925 20:26:02.785732  3547 net.cpp:406] Scale16 <- Convolution16
I0925 20:26:02.785735  3547 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0925 20:26:02.785766  3547 layer_factory.hpp:77] Creating layer Scale16
I0925 20:26:02.785853  3547 net.cpp:122] Setting up Scale16
I0925 20:26:02.785857  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.785859  3547 net.cpp:137] Memory required for data: 564839600
I0925 20:26:02.785862  3547 layer_factory.hpp:77] Creating layer PReLU16
I0925 20:26:02.785867  3547 net.cpp:84] Creating Layer PReLU16
I0925 20:26:02.785869  3547 net.cpp:406] PReLU16 <- Convolution16
I0925 20:26:02.785872  3547 net.cpp:367] PReLU16 -> Convolution16 (in-place)
I0925 20:26:02.785945  3547 net.cpp:122] Setting up PReLU16
I0925 20:26:02.785950  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.785953  3547 net.cpp:137] Memory required for data: 571393200
I0925 20:26:02.785955  3547 layer_factory.hpp:77] Creating layer Convolution17
I0925 20:26:02.785961  3547 net.cpp:84] Creating Layer Convolution17
I0925 20:26:02.785964  3547 net.cpp:406] Convolution17 <- Convolution16
I0925 20:26:02.785967  3547 net.cpp:380] Convolution17 -> Convolution17
I0925 20:26:02.786913  3547 net.cpp:122] Setting up Convolution17
I0925 20:26:02.786922  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.786924  3547 net.cpp:137] Memory required for data: 577946800
I0925 20:26:02.786939  3547 layer_factory.hpp:77] Creating layer BatchNorm17
I0925 20:26:02.786945  3547 net.cpp:84] Creating Layer BatchNorm17
I0925 20:26:02.786947  3547 net.cpp:406] BatchNorm17 <- Convolution17
I0925 20:26:02.786952  3547 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0925 20:26:02.787106  3547 net.cpp:122] Setting up BatchNorm17
I0925 20:26:02.787111  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.787113  3547 net.cpp:137] Memory required for data: 584500400
I0925 20:26:02.787118  3547 layer_factory.hpp:77] Creating layer Scale17
I0925 20:26:02.787122  3547 net.cpp:84] Creating Layer Scale17
I0925 20:26:02.787124  3547 net.cpp:406] Scale17 <- Convolution17
I0925 20:26:02.787128  3547 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0925 20:26:02.787158  3547 layer_factory.hpp:77] Creating layer Scale17
I0925 20:26:02.787245  3547 net.cpp:122] Setting up Scale17
I0925 20:26:02.787251  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.787253  3547 net.cpp:137] Memory required for data: 591054000
I0925 20:26:02.787256  3547 layer_factory.hpp:77] Creating layer Eltwise8
I0925 20:26:02.787261  3547 net.cpp:84] Creating Layer Eltwise8
I0925 20:26:02.787263  3547 net.cpp:406] Eltwise8 <- Eltwise7_PReLU15_0_split_1
I0925 20:26:02.787266  3547 net.cpp:406] Eltwise8 <- Convolution17
I0925 20:26:02.787269  3547 net.cpp:380] Eltwise8 -> Eltwise8
I0925 20:26:02.787287  3547 net.cpp:122] Setting up Eltwise8
I0925 20:26:02.787292  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.787293  3547 net.cpp:137] Memory required for data: 597607600
I0925 20:26:02.787295  3547 layer_factory.hpp:77] Creating layer PReLU17
I0925 20:26:02.787299  3547 net.cpp:84] Creating Layer PReLU17
I0925 20:26:02.787302  3547 net.cpp:406] PReLU17 <- Eltwise8
I0925 20:26:02.787304  3547 net.cpp:367] PReLU17 -> Eltwise8 (in-place)
I0925 20:26:02.787379  3547 net.cpp:122] Setting up PReLU17
I0925 20:26:02.787384  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.787385  3547 net.cpp:137] Memory required for data: 604161200
I0925 20:26:02.787395  3547 layer_factory.hpp:77] Creating layer Eltwise8_PReLU17_0_split
I0925 20:26:02.787398  3547 net.cpp:84] Creating Layer Eltwise8_PReLU17_0_split
I0925 20:26:02.787400  3547 net.cpp:406] Eltwise8_PReLU17_0_split <- Eltwise8
I0925 20:26:02.787405  3547 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_0
I0925 20:26:02.787408  3547 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_1
I0925 20:26:02.787437  3547 net.cpp:122] Setting up Eltwise8_PReLU17_0_split
I0925 20:26:02.787442  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.787444  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.787446  3547 net.cpp:137] Memory required for data: 617268400
I0925 20:26:02.787448  3547 layer_factory.hpp:77] Creating layer Convolution18
I0925 20:26:02.787454  3547 net.cpp:84] Creating Layer Convolution18
I0925 20:26:02.787457  3547 net.cpp:406] Convolution18 <- Eltwise8_PReLU17_0_split_0
I0925 20:26:02.787461  3547 net.cpp:380] Convolution18 -> Convolution18
I0925 20:26:02.788440  3547 net.cpp:122] Setting up Convolution18
I0925 20:26:02.788450  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.788452  3547 net.cpp:137] Memory required for data: 623822000
I0925 20:26:02.788456  3547 layer_factory.hpp:77] Creating layer BatchNorm18
I0925 20:26:02.788461  3547 net.cpp:84] Creating Layer BatchNorm18
I0925 20:26:02.788465  3547 net.cpp:406] BatchNorm18 <- Convolution18
I0925 20:26:02.788467  3547 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0925 20:26:02.788653  3547 net.cpp:122] Setting up BatchNorm18
I0925 20:26:02.788658  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.788661  3547 net.cpp:137] Memory required for data: 630375600
I0925 20:26:02.788666  3547 layer_factory.hpp:77] Creating layer Scale18
I0925 20:26:02.788671  3547 net.cpp:84] Creating Layer Scale18
I0925 20:26:02.788673  3547 net.cpp:406] Scale18 <- Convolution18
I0925 20:26:02.788676  3547 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0925 20:26:02.788707  3547 layer_factory.hpp:77] Creating layer Scale18
I0925 20:26:02.788794  3547 net.cpp:122] Setting up Scale18
I0925 20:26:02.788800  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.788801  3547 net.cpp:137] Memory required for data: 636929200
I0925 20:26:02.788805  3547 layer_factory.hpp:77] Creating layer PReLU18
I0925 20:26:02.788810  3547 net.cpp:84] Creating Layer PReLU18
I0925 20:26:02.788811  3547 net.cpp:406] PReLU18 <- Convolution18
I0925 20:26:02.788815  3547 net.cpp:367] PReLU18 -> Convolution18 (in-place)
I0925 20:26:02.788890  3547 net.cpp:122] Setting up PReLU18
I0925 20:26:02.788895  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.788897  3547 net.cpp:137] Memory required for data: 643482800
I0925 20:26:02.788899  3547 layer_factory.hpp:77] Creating layer Convolution19
I0925 20:26:02.788906  3547 net.cpp:84] Creating Layer Convolution19
I0925 20:26:02.788908  3547 net.cpp:406] Convolution19 <- Convolution18
I0925 20:26:02.788913  3547 net.cpp:380] Convolution19 -> Convolution19
I0925 20:26:02.789860  3547 net.cpp:122] Setting up Convolution19
I0925 20:26:02.789870  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.789871  3547 net.cpp:137] Memory required for data: 650036400
I0925 20:26:02.789876  3547 layer_factory.hpp:77] Creating layer BatchNorm19
I0925 20:26:02.789881  3547 net.cpp:84] Creating Layer BatchNorm19
I0925 20:26:02.789883  3547 net.cpp:406] BatchNorm19 <- Convolution19
I0925 20:26:02.789887  3547 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0925 20:26:02.790043  3547 net.cpp:122] Setting up BatchNorm19
I0925 20:26:02.790048  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.790050  3547 net.cpp:137] Memory required for data: 656590000
I0925 20:26:02.790055  3547 layer_factory.hpp:77] Creating layer Scale19
I0925 20:26:02.790058  3547 net.cpp:84] Creating Layer Scale19
I0925 20:26:02.790061  3547 net.cpp:406] Scale19 <- Convolution19
I0925 20:26:02.790066  3547 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0925 20:26:02.790103  3547 layer_factory.hpp:77] Creating layer Scale19
I0925 20:26:02.790191  3547 net.cpp:122] Setting up Scale19
I0925 20:26:02.790196  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.790199  3547 net.cpp:137] Memory required for data: 663143600
I0925 20:26:02.790202  3547 layer_factory.hpp:77] Creating layer Eltwise9
I0925 20:26:02.790206  3547 net.cpp:84] Creating Layer Eltwise9
I0925 20:26:02.790208  3547 net.cpp:406] Eltwise9 <- Eltwise8_PReLU17_0_split_1
I0925 20:26:02.790211  3547 net.cpp:406] Eltwise9 <- Convolution19
I0925 20:26:02.790215  3547 net.cpp:380] Eltwise9 -> Eltwise9
I0925 20:26:02.790233  3547 net.cpp:122] Setting up Eltwise9
I0925 20:26:02.790237  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.790240  3547 net.cpp:137] Memory required for data: 669697200
I0925 20:26:02.790241  3547 layer_factory.hpp:77] Creating layer PReLU19
I0925 20:26:02.790246  3547 net.cpp:84] Creating Layer PReLU19
I0925 20:26:02.790248  3547 net.cpp:406] PReLU19 <- Eltwise9
I0925 20:26:02.790251  3547 net.cpp:367] PReLU19 -> Eltwise9 (in-place)
I0925 20:26:02.790324  3547 net.cpp:122] Setting up PReLU19
I0925 20:26:02.790329  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.790331  3547 net.cpp:137] Memory required for data: 676250800
I0925 20:26:02.790334  3547 layer_factory.hpp:77] Creating layer Eltwise9_PReLU19_0_split
I0925 20:26:02.790338  3547 net.cpp:84] Creating Layer Eltwise9_PReLU19_0_split
I0925 20:26:02.790340  3547 net.cpp:406] Eltwise9_PReLU19_0_split <- Eltwise9
I0925 20:26:02.790344  3547 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_0
I0925 20:26:02.790347  3547 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_1
I0925 20:26:02.790375  3547 net.cpp:122] Setting up Eltwise9_PReLU19_0_split
I0925 20:26:02.811847  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.811853  3547 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0925 20:26:02.811856  3547 net.cpp:137] Memory required for data: 689358000
I0925 20:26:02.811861  3547 layer_factory.hpp:77] Creating layer Convolution20
I0925 20:26:02.811873  3547 net.cpp:84] Creating Layer Convolution20
I0925 20:26:02.811878  3547 net.cpp:406] Convolution20 <- Eltwise9_PReLU19_0_split_0
I0925 20:26:02.811887  3547 net.cpp:380] Convolution20 -> Convolution20
I0925 20:26:02.812954  3547 net.cpp:122] Setting up Convolution20
I0925 20:26:02.812963  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.812966  3547 net.cpp:137] Memory required for data: 692634800
I0925 20:26:02.812971  3547 layer_factory.hpp:77] Creating layer BatchNorm20
I0925 20:26:02.812976  3547 net.cpp:84] Creating Layer BatchNorm20
I0925 20:26:02.812979  3547 net.cpp:406] BatchNorm20 <- Convolution20
I0925 20:26:02.812984  3547 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0925 20:26:02.813171  3547 net.cpp:122] Setting up BatchNorm20
I0925 20:26:02.813179  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.813180  3547 net.cpp:137] Memory required for data: 695911600
I0925 20:26:02.813186  3547 layer_factory.hpp:77] Creating layer Scale20
I0925 20:26:02.813190  3547 net.cpp:84] Creating Layer Scale20
I0925 20:26:02.813194  3547 net.cpp:406] Scale20 <- Convolution20
I0925 20:26:02.813197  3547 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0925 20:26:02.813241  3547 layer_factory.hpp:77] Creating layer Scale20
I0925 20:26:02.813377  3547 net.cpp:122] Setting up Scale20
I0925 20:26:02.813385  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.813386  3547 net.cpp:137] Memory required for data: 699188400
I0925 20:26:02.813390  3547 layer_factory.hpp:77] Creating layer Convolution21
I0925 20:26:02.813397  3547 net.cpp:84] Creating Layer Convolution21
I0925 20:26:02.813400  3547 net.cpp:406] Convolution21 <- Eltwise9_PReLU19_0_split_1
I0925 20:26:02.813405  3547 net.cpp:380] Convolution21 -> Convolution21
I0925 20:26:02.814576  3547 net.cpp:122] Setting up Convolution21
I0925 20:26:02.814592  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.814595  3547 net.cpp:137] Memory required for data: 702465200
I0925 20:26:02.814599  3547 layer_factory.hpp:77] Creating layer BatchNorm21
I0925 20:26:02.814604  3547 net.cpp:84] Creating Layer BatchNorm21
I0925 20:26:02.814617  3547 net.cpp:406] BatchNorm21 <- Convolution21
I0925 20:26:02.814621  3547 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0925 20:26:02.814800  3547 net.cpp:122] Setting up BatchNorm21
I0925 20:26:02.814805  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.814806  3547 net.cpp:137] Memory required for data: 705742000
I0925 20:26:02.814811  3547 layer_factory.hpp:77] Creating layer Scale21
I0925 20:26:02.814816  3547 net.cpp:84] Creating Layer Scale21
I0925 20:26:02.814818  3547 net.cpp:406] Scale21 <- Convolution21
I0925 20:26:02.814822  3547 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0925 20:26:02.814875  3547 layer_factory.hpp:77] Creating layer Scale21
I0925 20:26:02.814970  3547 net.cpp:122] Setting up Scale21
I0925 20:26:02.814973  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.814976  3547 net.cpp:137] Memory required for data: 709018800
I0925 20:26:02.814980  3547 layer_factory.hpp:77] Creating layer PReLU20
I0925 20:26:02.814985  3547 net.cpp:84] Creating Layer PReLU20
I0925 20:26:02.814986  3547 net.cpp:406] PReLU20 <- Convolution21
I0925 20:26:02.814990  3547 net.cpp:367] PReLU20 -> Convolution21 (in-place)
I0925 20:26:02.815060  3547 net.cpp:122] Setting up PReLU20
I0925 20:26:02.815074  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.815076  3547 net.cpp:137] Memory required for data: 712295600
I0925 20:26:02.815089  3547 layer_factory.hpp:77] Creating layer Convolution22
I0925 20:26:02.815096  3547 net.cpp:84] Creating Layer Convolution22
I0925 20:26:02.815099  3547 net.cpp:406] Convolution22 <- Convolution21
I0925 20:26:02.815104  3547 net.cpp:380] Convolution22 -> Convolution22
I0925 20:26:02.816265  3547 net.cpp:122] Setting up Convolution22
I0925 20:26:02.816274  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.816277  3547 net.cpp:137] Memory required for data: 715572400
I0925 20:26:02.816282  3547 layer_factory.hpp:77] Creating layer BatchNorm22
I0925 20:26:02.816287  3547 net.cpp:84] Creating Layer BatchNorm22
I0925 20:26:02.816290  3547 net.cpp:406] BatchNorm22 <- Convolution22
I0925 20:26:02.816293  3547 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0925 20:26:02.816452  3547 net.cpp:122] Setting up BatchNorm22
I0925 20:26:02.816457  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.816459  3547 net.cpp:137] Memory required for data: 718849200
I0925 20:26:02.816464  3547 layer_factory.hpp:77] Creating layer Scale22
I0925 20:26:02.816468  3547 net.cpp:84] Creating Layer Scale22
I0925 20:26:02.816470  3547 net.cpp:406] Scale22 <- Convolution22
I0925 20:26:02.816473  3547 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0925 20:26:02.816510  3547 layer_factory.hpp:77] Creating layer Scale22
I0925 20:26:02.816604  3547 net.cpp:122] Setting up Scale22
I0925 20:26:02.816609  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.816612  3547 net.cpp:137] Memory required for data: 722126000
I0925 20:26:02.816615  3547 layer_factory.hpp:77] Creating layer Eltwise10
I0925 20:26:02.816620  3547 net.cpp:84] Creating Layer Eltwise10
I0925 20:26:02.816622  3547 net.cpp:406] Eltwise10 <- Convolution20
I0925 20:26:02.816625  3547 net.cpp:406] Eltwise10 <- Convolution22
I0925 20:26:02.816629  3547 net.cpp:380] Eltwise10 -> Eltwise10
I0925 20:26:02.816645  3547 net.cpp:122] Setting up Eltwise10
I0925 20:26:02.816648  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.816650  3547 net.cpp:137] Memory required for data: 725402800
I0925 20:26:02.816653  3547 layer_factory.hpp:77] Creating layer PReLU21
I0925 20:26:02.816658  3547 net.cpp:84] Creating Layer PReLU21
I0925 20:26:02.816659  3547 net.cpp:406] PReLU21 <- Eltwise10
I0925 20:26:02.816663  3547 net.cpp:367] PReLU21 -> Eltwise10 (in-place)
I0925 20:26:02.816745  3547 net.cpp:122] Setting up PReLU21
I0925 20:26:02.816751  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.816753  3547 net.cpp:137] Memory required for data: 728679600
I0925 20:26:02.816756  3547 layer_factory.hpp:77] Creating layer Eltwise10_PReLU21_0_split
I0925 20:26:02.816761  3547 net.cpp:84] Creating Layer Eltwise10_PReLU21_0_split
I0925 20:26:02.816762  3547 net.cpp:406] Eltwise10_PReLU21_0_split <- Eltwise10
I0925 20:26:02.816766  3547 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_0
I0925 20:26:02.816771  3547 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_1
I0925 20:26:02.816802  3547 net.cpp:122] Setting up Eltwise10_PReLU21_0_split
I0925 20:26:02.816805  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.816808  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.816810  3547 net.cpp:137] Memory required for data: 735233200
I0925 20:26:02.816812  3547 layer_factory.hpp:77] Creating layer Convolution23
I0925 20:26:02.816819  3547 net.cpp:84] Creating Layer Convolution23
I0925 20:26:02.816821  3547 net.cpp:406] Convolution23 <- Eltwise10_PReLU21_0_split_0
I0925 20:26:02.816826  3547 net.cpp:380] Convolution23 -> Convolution23
I0925 20:26:02.817977  3547 net.cpp:122] Setting up Convolution23
I0925 20:26:02.817986  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.817989  3547 net.cpp:137] Memory required for data: 738510000
I0925 20:26:02.817994  3547 layer_factory.hpp:77] Creating layer BatchNorm23
I0925 20:26:02.817999  3547 net.cpp:84] Creating Layer BatchNorm23
I0925 20:26:02.818001  3547 net.cpp:406] BatchNorm23 <- Convolution23
I0925 20:26:02.818006  3547 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0925 20:26:02.818163  3547 net.cpp:122] Setting up BatchNorm23
I0925 20:26:02.818168  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.818171  3547 net.cpp:137] Memory required for data: 741786800
I0925 20:26:02.818176  3547 layer_factory.hpp:77] Creating layer Scale23
I0925 20:26:02.818181  3547 net.cpp:84] Creating Layer Scale23
I0925 20:26:02.818183  3547 net.cpp:406] Scale23 <- Convolution23
I0925 20:26:02.818186  3547 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0925 20:26:02.818218  3547 layer_factory.hpp:77] Creating layer Scale23
I0925 20:26:02.818310  3547 net.cpp:122] Setting up Scale23
I0925 20:26:02.818315  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.818317  3547 net.cpp:137] Memory required for data: 745063600
I0925 20:26:02.818321  3547 layer_factory.hpp:77] Creating layer PReLU22
I0925 20:26:02.818327  3547 net.cpp:84] Creating Layer PReLU22
I0925 20:26:02.818330  3547 net.cpp:406] PReLU22 <- Convolution23
I0925 20:26:02.818332  3547 net.cpp:367] PReLU22 -> Convolution23 (in-place)
I0925 20:26:02.818403  3547 net.cpp:122] Setting up PReLU22
I0925 20:26:02.818408  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.818410  3547 net.cpp:137] Memory required for data: 748340400
I0925 20:26:02.818413  3547 layer_factory.hpp:77] Creating layer Convolution24
I0925 20:26:02.818420  3547 net.cpp:84] Creating Layer Convolution24
I0925 20:26:02.818423  3547 net.cpp:406] Convolution24 <- Convolution23
I0925 20:26:02.818428  3547 net.cpp:380] Convolution24 -> Convolution24
I0925 20:26:02.819582  3547 net.cpp:122] Setting up Convolution24
I0925 20:26:02.819591  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.819593  3547 net.cpp:137] Memory required for data: 751617200
I0925 20:26:02.819597  3547 layer_factory.hpp:77] Creating layer BatchNorm24
I0925 20:26:02.819602  3547 net.cpp:84] Creating Layer BatchNorm24
I0925 20:26:02.819605  3547 net.cpp:406] BatchNorm24 <- Convolution24
I0925 20:26:02.819609  3547 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0925 20:26:02.819772  3547 net.cpp:122] Setting up BatchNorm24
I0925 20:26:02.819777  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.819779  3547 net.cpp:137] Memory required for data: 754894000
I0925 20:26:02.819790  3547 layer_factory.hpp:77] Creating layer Scale24
I0925 20:26:02.819795  3547 net.cpp:84] Creating Layer Scale24
I0925 20:26:02.819798  3547 net.cpp:406] Scale24 <- Convolution24
I0925 20:26:02.819802  3547 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0925 20:26:02.819835  3547 layer_factory.hpp:77] Creating layer Scale24
I0925 20:26:02.819928  3547 net.cpp:122] Setting up Scale24
I0925 20:26:02.819932  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.819934  3547 net.cpp:137] Memory required for data: 758170800
I0925 20:26:02.819938  3547 layer_factory.hpp:77] Creating layer Eltwise11
I0925 20:26:02.819943  3547 net.cpp:84] Creating Layer Eltwise11
I0925 20:26:02.819947  3547 net.cpp:406] Eltwise11 <- Eltwise10_PReLU21_0_split_1
I0925 20:26:02.819949  3547 net.cpp:406] Eltwise11 <- Convolution24
I0925 20:26:02.819952  3547 net.cpp:380] Eltwise11 -> Eltwise11
I0925 20:26:02.819967  3547 net.cpp:122] Setting up Eltwise11
I0925 20:26:02.819972  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.819973  3547 net.cpp:137] Memory required for data: 761447600
I0925 20:26:02.819977  3547 layer_factory.hpp:77] Creating layer PReLU23
I0925 20:26:02.819980  3547 net.cpp:84] Creating Layer PReLU23
I0925 20:26:02.819983  3547 net.cpp:406] PReLU23 <- Eltwise11
I0925 20:26:02.819985  3547 net.cpp:367] PReLU23 -> Eltwise11 (in-place)
I0925 20:26:02.820060  3547 net.cpp:122] Setting up PReLU23
I0925 20:26:02.820065  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.820067  3547 net.cpp:137] Memory required for data: 764724400
I0925 20:26:02.820070  3547 layer_factory.hpp:77] Creating layer Eltwise11_PReLU23_0_split
I0925 20:26:02.820075  3547 net.cpp:84] Creating Layer Eltwise11_PReLU23_0_split
I0925 20:26:02.820076  3547 net.cpp:406] Eltwise11_PReLU23_0_split <- Eltwise11
I0925 20:26:02.820080  3547 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_0
I0925 20:26:02.820086  3547 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_1
I0925 20:26:02.820113  3547 net.cpp:122] Setting up Eltwise11_PReLU23_0_split
I0925 20:26:02.820117  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.820121  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.820122  3547 net.cpp:137] Memory required for data: 771278000
I0925 20:26:02.820125  3547 layer_factory.hpp:77] Creating layer Convolution25
I0925 20:26:02.820132  3547 net.cpp:84] Creating Layer Convolution25
I0925 20:26:02.820135  3547 net.cpp:406] Convolution25 <- Eltwise11_PReLU23_0_split_0
I0925 20:26:02.820139  3547 net.cpp:380] Convolution25 -> Convolution25
I0925 20:26:02.821300  3547 net.cpp:122] Setting up Convolution25
I0925 20:26:02.821310  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.821312  3547 net.cpp:137] Memory required for data: 774554800
I0925 20:26:02.821316  3547 layer_factory.hpp:77] Creating layer BatchNorm25
I0925 20:26:02.821322  3547 net.cpp:84] Creating Layer BatchNorm25
I0925 20:26:02.821324  3547 net.cpp:406] BatchNorm25 <- Convolution25
I0925 20:26:02.821328  3547 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0925 20:26:02.821491  3547 net.cpp:122] Setting up BatchNorm25
I0925 20:26:02.821496  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.821497  3547 net.cpp:137] Memory required for data: 777831600
I0925 20:26:02.821502  3547 layer_factory.hpp:77] Creating layer Scale25
I0925 20:26:02.821507  3547 net.cpp:84] Creating Layer Scale25
I0925 20:26:02.821511  3547 net.cpp:406] Scale25 <- Convolution25
I0925 20:26:02.821513  3547 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0925 20:26:02.821547  3547 layer_factory.hpp:77] Creating layer Scale25
I0925 20:26:02.821642  3547 net.cpp:122] Setting up Scale25
I0925 20:26:02.821646  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.821650  3547 net.cpp:137] Memory required for data: 781108400
I0925 20:26:02.821653  3547 layer_factory.hpp:77] Creating layer PReLU24
I0925 20:26:02.821657  3547 net.cpp:84] Creating Layer PReLU24
I0925 20:26:02.821666  3547 net.cpp:406] PReLU24 <- Convolution25
I0925 20:26:02.821669  3547 net.cpp:367] PReLU24 -> Convolution25 (in-place)
I0925 20:26:02.821743  3547 net.cpp:122] Setting up PReLU24
I0925 20:26:02.821748  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.821750  3547 net.cpp:137] Memory required for data: 784385200
I0925 20:26:02.821753  3547 layer_factory.hpp:77] Creating layer Convolution26
I0925 20:26:02.821759  3547 net.cpp:84] Creating Layer Convolution26
I0925 20:26:02.821763  3547 net.cpp:406] Convolution26 <- Convolution25
I0925 20:26:02.821766  3547 net.cpp:380] Convolution26 -> Convolution26
I0925 20:26:02.822592  3547 net.cpp:122] Setting up Convolution26
I0925 20:26:02.822602  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.822603  3547 net.cpp:137] Memory required for data: 787662000
I0925 20:26:02.822608  3547 layer_factory.hpp:77] Creating layer BatchNorm26
I0925 20:26:02.822613  3547 net.cpp:84] Creating Layer BatchNorm26
I0925 20:26:02.822615  3547 net.cpp:406] BatchNorm26 <- Convolution26
I0925 20:26:02.822619  3547 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0925 20:26:02.822782  3547 net.cpp:122] Setting up BatchNorm26
I0925 20:26:02.822787  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.822788  3547 net.cpp:137] Memory required for data: 790938800
I0925 20:26:02.822793  3547 layer_factory.hpp:77] Creating layer Scale26
I0925 20:26:02.822798  3547 net.cpp:84] Creating Layer Scale26
I0925 20:26:02.822800  3547 net.cpp:406] Scale26 <- Convolution26
I0925 20:26:02.822803  3547 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0925 20:26:02.822836  3547 layer_factory.hpp:77] Creating layer Scale26
I0925 20:26:02.842967  3547 net.cpp:122] Setting up Scale26
I0925 20:26:02.842977  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.842979  3547 net.cpp:137] Memory required for data: 794215600
I0925 20:26:02.842984  3547 layer_factory.hpp:77] Creating layer Eltwise12
I0925 20:26:02.842989  3547 net.cpp:84] Creating Layer Eltwise12
I0925 20:26:02.842993  3547 net.cpp:406] Eltwise12 <- Eltwise11_PReLU23_0_split_1
I0925 20:26:02.842996  3547 net.cpp:406] Eltwise12 <- Convolution26
I0925 20:26:02.843000  3547 net.cpp:380] Eltwise12 -> Eltwise12
I0925 20:26:02.843019  3547 net.cpp:122] Setting up Eltwise12
I0925 20:26:02.843024  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.843025  3547 net.cpp:137] Memory required for data: 797492400
I0925 20:26:02.843027  3547 layer_factory.hpp:77] Creating layer PReLU25
I0925 20:26:02.843040  3547 net.cpp:84] Creating Layer PReLU25
I0925 20:26:02.843044  3547 net.cpp:406] PReLU25 <- Eltwise12
I0925 20:26:02.843047  3547 net.cpp:367] PReLU25 -> Eltwise12 (in-place)
I0925 20:26:02.843130  3547 net.cpp:122] Setting up PReLU25
I0925 20:26:02.843135  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.843137  3547 net.cpp:137] Memory required for data: 800769200
I0925 20:26:02.843142  3547 layer_factory.hpp:77] Creating layer Eltwise12_PReLU25_0_split
I0925 20:26:02.843147  3547 net.cpp:84] Creating Layer Eltwise12_PReLU25_0_split
I0925 20:26:02.843148  3547 net.cpp:406] Eltwise12_PReLU25_0_split <- Eltwise12
I0925 20:26:02.843152  3547 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_0
I0925 20:26:02.843156  3547 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_1
I0925 20:26:02.843189  3547 net.cpp:122] Setting up Eltwise12_PReLU25_0_split
I0925 20:26:02.843194  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.843196  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.843199  3547 net.cpp:137] Memory required for data: 807322800
I0925 20:26:02.843201  3547 layer_factory.hpp:77] Creating layer Convolution27
I0925 20:26:02.843209  3547 net.cpp:84] Creating Layer Convolution27
I0925 20:26:02.843211  3547 net.cpp:406] Convolution27 <- Eltwise12_PReLU25_0_split_0
I0925 20:26:02.843215  3547 net.cpp:380] Convolution27 -> Convolution27
I0925 20:26:02.844871  3547 net.cpp:122] Setting up Convolution27
I0925 20:26:02.844889  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.844892  3547 net.cpp:137] Memory required for data: 810599600
I0925 20:26:02.844897  3547 layer_factory.hpp:77] Creating layer BatchNorm27
I0925 20:26:02.844903  3547 net.cpp:84] Creating Layer BatchNorm27
I0925 20:26:02.844907  3547 net.cpp:406] BatchNorm27 <- Convolution27
I0925 20:26:02.844909  3547 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0925 20:26:02.845073  3547 net.cpp:122] Setting up BatchNorm27
I0925 20:26:02.845078  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.845080  3547 net.cpp:137] Memory required for data: 813876400
I0925 20:26:02.845085  3547 layer_factory.hpp:77] Creating layer Scale27
I0925 20:26:02.845091  3547 net.cpp:84] Creating Layer Scale27
I0925 20:26:02.845094  3547 net.cpp:406] Scale27 <- Convolution27
I0925 20:26:02.845098  3547 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0925 20:26:02.845132  3547 layer_factory.hpp:77] Creating layer Scale27
I0925 20:26:02.845227  3547 net.cpp:122] Setting up Scale27
I0925 20:26:02.845232  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.845233  3547 net.cpp:137] Memory required for data: 817153200
I0925 20:26:02.845237  3547 layer_factory.hpp:77] Creating layer PReLU26
I0925 20:26:02.845242  3547 net.cpp:84] Creating Layer PReLU26
I0925 20:26:02.845244  3547 net.cpp:406] PReLU26 <- Convolution27
I0925 20:26:02.845247  3547 net.cpp:367] PReLU26 -> Convolution27 (in-place)
I0925 20:26:02.845319  3547 net.cpp:122] Setting up PReLU26
I0925 20:26:02.845324  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.845326  3547 net.cpp:137] Memory required for data: 820430000
I0925 20:26:02.845329  3547 layer_factory.hpp:77] Creating layer Convolution28
I0925 20:26:02.845336  3547 net.cpp:84] Creating Layer Convolution28
I0925 20:26:02.845338  3547 net.cpp:406] Convolution28 <- Convolution27
I0925 20:26:02.845343  3547 net.cpp:380] Convolution28 -> Convolution28
I0925 20:26:02.846873  3547 net.cpp:122] Setting up Convolution28
I0925 20:26:02.846881  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.846884  3547 net.cpp:137] Memory required for data: 823706800
I0925 20:26:02.846889  3547 layer_factory.hpp:77] Creating layer BatchNorm28
I0925 20:26:02.846894  3547 net.cpp:84] Creating Layer BatchNorm28
I0925 20:26:02.846897  3547 net.cpp:406] BatchNorm28 <- Convolution28
I0925 20:26:02.846900  3547 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0925 20:26:02.847066  3547 net.cpp:122] Setting up BatchNorm28
I0925 20:26:02.847071  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.847074  3547 net.cpp:137] Memory required for data: 826983600
I0925 20:26:02.847079  3547 layer_factory.hpp:77] Creating layer Scale28
I0925 20:26:02.847084  3547 net.cpp:84] Creating Layer Scale28
I0925 20:26:02.847086  3547 net.cpp:406] Scale28 <- Convolution28
I0925 20:26:02.847090  3547 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0925 20:26:02.847123  3547 layer_factory.hpp:77] Creating layer Scale28
I0925 20:26:02.847728  3547 net.cpp:122] Setting up Scale28
I0925 20:26:02.847738  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.847740  3547 net.cpp:137] Memory required for data: 830260400
I0925 20:26:02.847744  3547 layer_factory.hpp:77] Creating layer Eltwise13
I0925 20:26:02.847750  3547 net.cpp:84] Creating Layer Eltwise13
I0925 20:26:02.847754  3547 net.cpp:406] Eltwise13 <- Eltwise12_PReLU25_0_split_1
I0925 20:26:02.847756  3547 net.cpp:406] Eltwise13 <- Convolution28
I0925 20:26:02.847760  3547 net.cpp:380] Eltwise13 -> Eltwise13
I0925 20:26:02.847774  3547 net.cpp:122] Setting up Eltwise13
I0925 20:26:02.847779  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.847780  3547 net.cpp:137] Memory required for data: 833537200
I0925 20:26:02.847782  3547 layer_factory.hpp:77] Creating layer PReLU27
I0925 20:26:02.847785  3547 net.cpp:84] Creating Layer PReLU27
I0925 20:26:02.847789  3547 net.cpp:406] PReLU27 <- Eltwise13
I0925 20:26:02.847791  3547 net.cpp:367] PReLU27 -> Eltwise13 (in-place)
I0925 20:26:02.847865  3547 net.cpp:122] Setting up PReLU27
I0925 20:26:02.847872  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.847873  3547 net.cpp:137] Memory required for data: 836814000
I0925 20:26:02.847877  3547 layer_factory.hpp:77] Creating layer Eltwise13_PReLU27_0_split
I0925 20:26:02.847882  3547 net.cpp:84] Creating Layer Eltwise13_PReLU27_0_split
I0925 20:26:02.847884  3547 net.cpp:406] Eltwise13_PReLU27_0_split <- Eltwise13
I0925 20:26:02.847887  3547 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_0
I0925 20:26:02.847892  3547 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_1
I0925 20:26:02.847915  3547 net.cpp:122] Setting up Eltwise13_PReLU27_0_split
I0925 20:26:02.847919  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.847921  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.847923  3547 net.cpp:137] Memory required for data: 843367600
I0925 20:26:02.847925  3547 layer_factory.hpp:77] Creating layer Convolution29
I0925 20:26:02.847934  3547 net.cpp:84] Creating Layer Convolution29
I0925 20:26:02.847936  3547 net.cpp:406] Convolution29 <- Eltwise13_PReLU27_0_split_0
I0925 20:26:02.847940  3547 net.cpp:380] Convolution29 -> Convolution29
I0925 20:26:02.849053  3547 net.cpp:122] Setting up Convolution29
I0925 20:26:02.849062  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.849064  3547 net.cpp:137] Memory required for data: 846644400
I0925 20:26:02.849069  3547 layer_factory.hpp:77] Creating layer BatchNorm29
I0925 20:26:02.849076  3547 net.cpp:84] Creating Layer BatchNorm29
I0925 20:26:02.849078  3547 net.cpp:406] BatchNorm29 <- Convolution29
I0925 20:26:02.849081  3547 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0925 20:26:02.849203  3547 net.cpp:122] Setting up BatchNorm29
I0925 20:26:02.849208  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.849210  3547 net.cpp:137] Memory required for data: 849921200
I0925 20:26:02.849215  3547 layer_factory.hpp:77] Creating layer Scale29
I0925 20:26:02.849220  3547 net.cpp:84] Creating Layer Scale29
I0925 20:26:02.849222  3547 net.cpp:406] Scale29 <- Convolution29
I0925 20:26:02.849225  3547 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0925 20:26:02.849251  3547 layer_factory.hpp:77] Creating layer Scale29
I0925 20:26:02.849321  3547 net.cpp:122] Setting up Scale29
I0925 20:26:02.849325  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.849328  3547 net.cpp:137] Memory required for data: 853198000
I0925 20:26:02.849331  3547 layer_factory.hpp:77] Creating layer PReLU28
I0925 20:26:02.849335  3547 net.cpp:84] Creating Layer PReLU28
I0925 20:26:02.849339  3547 net.cpp:406] PReLU28 <- Convolution29
I0925 20:26:02.849341  3547 net.cpp:367] PReLU28 -> Convolution29 (in-place)
I0925 20:26:02.849397  3547 net.cpp:122] Setting up PReLU28
I0925 20:26:02.849401  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.849403  3547 net.cpp:137] Memory required for data: 856474800
I0925 20:26:02.849406  3547 layer_factory.hpp:77] Creating layer Convolution30
I0925 20:26:02.849412  3547 net.cpp:84] Creating Layer Convolution30
I0925 20:26:02.849416  3547 net.cpp:406] Convolution30 <- Convolution29
I0925 20:26:02.849419  3547 net.cpp:380] Convolution30 -> Convolution30
I0925 20:26:02.850492  3547 net.cpp:122] Setting up Convolution30
I0925 20:26:02.850502  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.850503  3547 net.cpp:137] Memory required for data: 859751600
I0925 20:26:02.850508  3547 layer_factory.hpp:77] Creating layer BatchNorm30
I0925 20:26:02.850513  3547 net.cpp:84] Creating Layer BatchNorm30
I0925 20:26:02.850517  3547 net.cpp:406] BatchNorm30 <- Convolution30
I0925 20:26:02.850520  3547 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0925 20:26:02.850642  3547 net.cpp:122] Setting up BatchNorm30
I0925 20:26:02.850646  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.850648  3547 net.cpp:137] Memory required for data: 863028400
I0925 20:26:02.850659  3547 layer_factory.hpp:77] Creating layer Scale30
I0925 20:26:02.850664  3547 net.cpp:84] Creating Layer Scale30
I0925 20:26:02.850666  3547 net.cpp:406] Scale30 <- Convolution30
I0925 20:26:02.850670  3547 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0925 20:26:02.850697  3547 layer_factory.hpp:77] Creating layer Scale30
I0925 20:26:02.850766  3547 net.cpp:122] Setting up Scale30
I0925 20:26:02.850771  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.850774  3547 net.cpp:137] Memory required for data: 866305200
I0925 20:26:02.850777  3547 layer_factory.hpp:77] Creating layer Eltwise14
I0925 20:26:02.850781  3547 net.cpp:84] Creating Layer Eltwise14
I0925 20:26:02.850785  3547 net.cpp:406] Eltwise14 <- Eltwise13_PReLU27_0_split_1
I0925 20:26:02.850787  3547 net.cpp:406] Eltwise14 <- Convolution30
I0925 20:26:02.850790  3547 net.cpp:380] Eltwise14 -> Eltwise14
I0925 20:26:02.850802  3547 net.cpp:122] Setting up Eltwise14
I0925 20:26:02.850805  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.850807  3547 net.cpp:137] Memory required for data: 869582000
I0925 20:26:02.850810  3547 layer_factory.hpp:77] Creating layer PReLU29
I0925 20:26:02.850813  3547 net.cpp:84] Creating Layer PReLU29
I0925 20:26:02.850816  3547 net.cpp:406] PReLU29 <- Eltwise14
I0925 20:26:02.850818  3547 net.cpp:367] PReLU29 -> Eltwise14 (in-place)
I0925 20:26:02.850879  3547 net.cpp:122] Setting up PReLU29
I0925 20:26:02.850884  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.850886  3547 net.cpp:137] Memory required for data: 872858800
I0925 20:26:02.850889  3547 layer_factory.hpp:77] Creating layer Eltwise14_PReLU29_0_split
I0925 20:26:02.850893  3547 net.cpp:84] Creating Layer Eltwise14_PReLU29_0_split
I0925 20:26:02.850896  3547 net.cpp:406] Eltwise14_PReLU29_0_split <- Eltwise14
I0925 20:26:02.850899  3547 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_0
I0925 20:26:02.850903  3547 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_1
I0925 20:26:02.850926  3547 net.cpp:122] Setting up Eltwise14_PReLU29_0_split
I0925 20:26:02.850929  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.850932  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.850934  3547 net.cpp:137] Memory required for data: 879412400
I0925 20:26:02.850936  3547 layer_factory.hpp:77] Creating layer Convolution31
I0925 20:26:02.850944  3547 net.cpp:84] Creating Layer Convolution31
I0925 20:26:02.850945  3547 net.cpp:406] Convolution31 <- Eltwise14_PReLU29_0_split_0
I0925 20:26:02.850950  3547 net.cpp:380] Convolution31 -> Convolution31
I0925 20:26:02.852016  3547 net.cpp:122] Setting up Convolution31
I0925 20:26:02.852025  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.852027  3547 net.cpp:137] Memory required for data: 882689200
I0925 20:26:02.852031  3547 layer_factory.hpp:77] Creating layer BatchNorm31
I0925 20:26:02.852036  3547 net.cpp:84] Creating Layer BatchNorm31
I0925 20:26:02.852039  3547 net.cpp:406] BatchNorm31 <- Convolution31
I0925 20:26:02.852043  3547 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0925 20:26:02.852164  3547 net.cpp:122] Setting up BatchNorm31
I0925 20:26:02.852167  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.852169  3547 net.cpp:137] Memory required for data: 885966000
I0925 20:26:02.852174  3547 layer_factory.hpp:77] Creating layer Scale31
I0925 20:26:02.852180  3547 net.cpp:84] Creating Layer Scale31
I0925 20:26:02.852181  3547 net.cpp:406] Scale31 <- Convolution31
I0925 20:26:02.852185  3547 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0925 20:26:02.852210  3547 layer_factory.hpp:77] Creating layer Scale31
I0925 20:26:02.852282  3547 net.cpp:122] Setting up Scale31
I0925 20:26:02.852286  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.852288  3547 net.cpp:137] Memory required for data: 889242800
I0925 20:26:02.852291  3547 layer_factory.hpp:77] Creating layer PReLU30
I0925 20:26:02.852298  3547 net.cpp:84] Creating Layer PReLU30
I0925 20:26:02.852305  3547 net.cpp:406] PReLU30 <- Convolution31
I0925 20:26:02.852308  3547 net.cpp:367] PReLU30 -> Convolution31 (in-place)
I0925 20:26:02.852368  3547 net.cpp:122] Setting up PReLU30
I0925 20:26:02.852372  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.852375  3547 net.cpp:137] Memory required for data: 892519600
I0925 20:26:02.852377  3547 layer_factory.hpp:77] Creating layer Convolution32
I0925 20:26:02.852385  3547 net.cpp:84] Creating Layer Convolution32
I0925 20:26:02.852386  3547 net.cpp:406] Convolution32 <- Convolution31
I0925 20:26:02.852391  3547 net.cpp:380] Convolution32 -> Convolution32
I0925 20:26:02.853507  3547 net.cpp:122] Setting up Convolution32
I0925 20:26:02.853515  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.853518  3547 net.cpp:137] Memory required for data: 895796400
I0925 20:26:02.853523  3547 layer_factory.hpp:77] Creating layer BatchNorm32
I0925 20:26:02.853528  3547 net.cpp:84] Creating Layer BatchNorm32
I0925 20:26:02.853530  3547 net.cpp:406] BatchNorm32 <- Convolution32
I0925 20:26:02.853533  3547 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0925 20:26:02.853654  3547 net.cpp:122] Setting up BatchNorm32
I0925 20:26:02.853658  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.853660  3547 net.cpp:137] Memory required for data: 899073200
I0925 20:26:02.853665  3547 layer_factory.hpp:77] Creating layer Scale32
I0925 20:26:02.853669  3547 net.cpp:84] Creating Layer Scale32
I0925 20:26:02.853672  3547 net.cpp:406] Scale32 <- Convolution32
I0925 20:26:02.873859  3547 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0925 20:26:02.873906  3547 layer_factory.hpp:77] Creating layer Scale32
I0925 20:26:02.873991  3547 net.cpp:122] Setting up Scale32
I0925 20:26:02.873996  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.873999  3547 net.cpp:137] Memory required for data: 902350000
I0925 20:26:02.874003  3547 layer_factory.hpp:77] Creating layer Eltwise15
I0925 20:26:02.874009  3547 net.cpp:84] Creating Layer Eltwise15
I0925 20:26:02.874012  3547 net.cpp:406] Eltwise15 <- Eltwise14_PReLU29_0_split_1
I0925 20:26:02.874016  3547 net.cpp:406] Eltwise15 <- Convolution32
I0925 20:26:02.874019  3547 net.cpp:380] Eltwise15 -> Eltwise15
I0925 20:26:02.874032  3547 net.cpp:122] Setting up Eltwise15
I0925 20:26:02.874035  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.874037  3547 net.cpp:137] Memory required for data: 905626800
I0925 20:26:02.874039  3547 layer_factory.hpp:77] Creating layer PReLU31
I0925 20:26:02.874044  3547 net.cpp:84] Creating Layer PReLU31
I0925 20:26:02.874047  3547 net.cpp:406] PReLU31 <- Eltwise15
I0925 20:26:02.874050  3547 net.cpp:367] PReLU31 -> Eltwise15 (in-place)
I0925 20:26:02.874119  3547 net.cpp:122] Setting up PReLU31
I0925 20:26:02.874124  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.874125  3547 net.cpp:137] Memory required for data: 908903600
I0925 20:26:02.874130  3547 layer_factory.hpp:77] Creating layer Eltwise15_PReLU31_0_split
I0925 20:26:02.874132  3547 net.cpp:84] Creating Layer Eltwise15_PReLU31_0_split
I0925 20:26:02.874135  3547 net.cpp:406] Eltwise15_PReLU31_0_split <- Eltwise15
I0925 20:26:02.874140  3547 net.cpp:380] Eltwise15_PReLU31_0_split -> Eltwise15_PReLU31_0_split_0
I0925 20:26:02.874145  3547 net.cpp:380] Eltwise15_PReLU31_0_split -> Eltwise15_PReLU31_0_split_1
I0925 20:26:02.874169  3547 net.cpp:122] Setting up Eltwise15_PReLU31_0_split
I0925 20:26:02.874173  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.874176  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.874178  3547 net.cpp:137] Memory required for data: 915457200
I0925 20:26:02.874181  3547 layer_factory.hpp:77] Creating layer Convolution33
I0925 20:26:02.874187  3547 net.cpp:84] Creating Layer Convolution33
I0925 20:26:02.874191  3547 net.cpp:406] Convolution33 <- Eltwise15_PReLU31_0_split_0
I0925 20:26:02.874195  3547 net.cpp:380] Convolution33 -> Convolution33
I0925 20:26:02.875448  3547 net.cpp:122] Setting up Convolution33
I0925 20:26:02.875464  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.875468  3547 net.cpp:137] Memory required for data: 918734000
I0925 20:26:02.875509  3547 layer_factory.hpp:77] Creating layer BatchNorm33
I0925 20:26:02.875515  3547 net.cpp:84] Creating Layer BatchNorm33
I0925 20:26:02.875519  3547 net.cpp:406] BatchNorm33 <- Convolution33
I0925 20:26:02.875522  3547 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0925 20:26:02.875681  3547 net.cpp:122] Setting up BatchNorm33
I0925 20:26:02.875695  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.875697  3547 net.cpp:137] Memory required for data: 922010800
I0925 20:26:02.875702  3547 layer_factory.hpp:77] Creating layer Scale33
I0925 20:26:02.875706  3547 net.cpp:84] Creating Layer Scale33
I0925 20:26:02.875710  3547 net.cpp:406] Scale33 <- Convolution33
I0925 20:26:02.875712  3547 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0925 20:26:02.875738  3547 layer_factory.hpp:77] Creating layer Scale33
I0925 20:26:02.875810  3547 net.cpp:122] Setting up Scale33
I0925 20:26:02.875815  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.875818  3547 net.cpp:137] Memory required for data: 925287600
I0925 20:26:02.875821  3547 layer_factory.hpp:77] Creating layer PReLU32
I0925 20:26:02.875825  3547 net.cpp:84] Creating Layer PReLU32
I0925 20:26:02.875828  3547 net.cpp:406] PReLU32 <- Convolution33
I0925 20:26:02.875830  3547 net.cpp:367] PReLU32 -> Convolution33 (in-place)
I0925 20:26:02.875890  3547 net.cpp:122] Setting up PReLU32
I0925 20:26:02.875893  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.875895  3547 net.cpp:137] Memory required for data: 928564400
I0925 20:26:02.875898  3547 layer_factory.hpp:77] Creating layer Convolution34
I0925 20:26:02.875905  3547 net.cpp:84] Creating Layer Convolution34
I0925 20:26:02.875906  3547 net.cpp:406] Convolution34 <- Convolution33
I0925 20:26:02.875911  3547 net.cpp:380] Convolution34 -> Convolution34
I0925 20:26:02.877833  3547 net.cpp:122] Setting up Convolution34
I0925 20:26:02.877843  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.877846  3547 net.cpp:137] Memory required for data: 931841200
I0925 20:26:02.877851  3547 layer_factory.hpp:77] Creating layer BatchNorm34
I0925 20:26:02.877856  3547 net.cpp:84] Creating Layer BatchNorm34
I0925 20:26:02.877859  3547 net.cpp:406] BatchNorm34 <- Convolution34
I0925 20:26:02.877863  3547 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0925 20:26:02.878028  3547 net.cpp:122] Setting up BatchNorm34
I0925 20:26:02.878032  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.878034  3547 net.cpp:137] Memory required for data: 935118000
I0925 20:26:02.878039  3547 layer_factory.hpp:77] Creating layer Scale34
I0925 20:26:02.878043  3547 net.cpp:84] Creating Layer Scale34
I0925 20:26:02.878046  3547 net.cpp:406] Scale34 <- Convolution34
I0925 20:26:02.878048  3547 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0925 20:26:02.878077  3547 layer_factory.hpp:77] Creating layer Scale34
I0925 20:26:02.878149  3547 net.cpp:122] Setting up Scale34
I0925 20:26:02.878155  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.878157  3547 net.cpp:137] Memory required for data: 938394800
I0925 20:26:02.878161  3547 layer_factory.hpp:77] Creating layer Eltwise16
I0925 20:26:02.878165  3547 net.cpp:84] Creating Layer Eltwise16
I0925 20:26:02.878168  3547 net.cpp:406] Eltwise16 <- Eltwise15_PReLU31_0_split_1
I0925 20:26:02.878171  3547 net.cpp:406] Eltwise16 <- Convolution34
I0925 20:26:02.878175  3547 net.cpp:380] Eltwise16 -> Eltwise16
I0925 20:26:02.878186  3547 net.cpp:122] Setting up Eltwise16
I0925 20:26:02.878190  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.878192  3547 net.cpp:137] Memory required for data: 941671600
I0925 20:26:02.878195  3547 layer_factory.hpp:77] Creating layer PReLU33
I0925 20:26:02.878197  3547 net.cpp:84] Creating Layer PReLU33
I0925 20:26:02.878201  3547 net.cpp:406] PReLU33 <- Eltwise16
I0925 20:26:02.878211  3547 net.cpp:367] PReLU33 -> Eltwise16 (in-place)
I0925 20:26:02.878273  3547 net.cpp:122] Setting up PReLU33
I0925 20:26:02.878276  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.878278  3547 net.cpp:137] Memory required for data: 944948400
I0925 20:26:02.878281  3547 layer_factory.hpp:77] Creating layer Eltwise16_PReLU33_0_split
I0925 20:26:02.878286  3547 net.cpp:84] Creating Layer Eltwise16_PReLU33_0_split
I0925 20:26:02.878288  3547 net.cpp:406] Eltwise16_PReLU33_0_split <- Eltwise16
I0925 20:26:02.878291  3547 net.cpp:380] Eltwise16_PReLU33_0_split -> Eltwise16_PReLU33_0_split_0
I0925 20:26:02.878295  3547 net.cpp:380] Eltwise16_PReLU33_0_split -> Eltwise16_PReLU33_0_split_1
I0925 20:26:02.878319  3547 net.cpp:122] Setting up Eltwise16_PReLU33_0_split
I0925 20:26:02.878322  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.878325  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.878327  3547 net.cpp:137] Memory required for data: 951502000
I0925 20:26:02.878329  3547 layer_factory.hpp:77] Creating layer Convolution35
I0925 20:26:02.878336  3547 net.cpp:84] Creating Layer Convolution35
I0925 20:26:02.878338  3547 net.cpp:406] Convolution35 <- Eltwise16_PReLU33_0_split_0
I0925 20:26:02.878342  3547 net.cpp:380] Convolution35 -> Convolution35
I0925 20:26:02.879425  3547 net.cpp:122] Setting up Convolution35
I0925 20:26:02.879432  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.879436  3547 net.cpp:137] Memory required for data: 954778800
I0925 20:26:02.879439  3547 layer_factory.hpp:77] Creating layer BatchNorm35
I0925 20:26:02.879444  3547 net.cpp:84] Creating Layer BatchNorm35
I0925 20:26:02.879447  3547 net.cpp:406] BatchNorm35 <- Convolution35
I0925 20:26:02.879451  3547 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0925 20:26:02.879577  3547 net.cpp:122] Setting up BatchNorm35
I0925 20:26:02.879582  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.879585  3547 net.cpp:137] Memory required for data: 958055600
I0925 20:26:02.879588  3547 layer_factory.hpp:77] Creating layer Scale35
I0925 20:26:02.879593  3547 net.cpp:84] Creating Layer Scale35
I0925 20:26:02.879595  3547 net.cpp:406] Scale35 <- Convolution35
I0925 20:26:02.879598  3547 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0925 20:26:02.879624  3547 layer_factory.hpp:77] Creating layer Scale35
I0925 20:26:02.879698  3547 net.cpp:122] Setting up Scale35
I0925 20:26:02.879701  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.879704  3547 net.cpp:137] Memory required for data: 961332400
I0925 20:26:02.879707  3547 layer_factory.hpp:77] Creating layer PReLU34
I0925 20:26:02.879711  3547 net.cpp:84] Creating Layer PReLU34
I0925 20:26:02.879714  3547 net.cpp:406] PReLU34 <- Convolution35
I0925 20:26:02.879717  3547 net.cpp:367] PReLU34 -> Convolution35 (in-place)
I0925 20:26:02.879772  3547 net.cpp:122] Setting up PReLU34
I0925 20:26:02.879776  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.879778  3547 net.cpp:137] Memory required for data: 964609200
I0925 20:26:02.879781  3547 layer_factory.hpp:77] Creating layer Convolution36
I0925 20:26:02.879787  3547 net.cpp:84] Creating Layer Convolution36
I0925 20:26:02.879789  3547 net.cpp:406] Convolution36 <- Convolution35
I0925 20:26:02.879793  3547 net.cpp:380] Convolution36 -> Convolution36
I0925 20:26:02.880565  3547 net.cpp:122] Setting up Convolution36
I0925 20:26:02.880573  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.880575  3547 net.cpp:137] Memory required for data: 967886000
I0925 20:26:02.880579  3547 layer_factory.hpp:77] Creating layer BatchNorm36
I0925 20:26:02.880584  3547 net.cpp:84] Creating Layer BatchNorm36
I0925 20:26:02.880586  3547 net.cpp:406] BatchNorm36 <- Convolution36
I0925 20:26:02.880590  3547 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0925 20:26:02.880717  3547 net.cpp:122] Setting up BatchNorm36
I0925 20:26:02.880722  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.880724  3547 net.cpp:137] Memory required for data: 971162800
I0925 20:26:02.880735  3547 layer_factory.hpp:77] Creating layer Scale36
I0925 20:26:02.880740  3547 net.cpp:84] Creating Layer Scale36
I0925 20:26:02.880743  3547 net.cpp:406] Scale36 <- Convolution36
I0925 20:26:02.880746  3547 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0925 20:26:02.880774  3547 layer_factory.hpp:77] Creating layer Scale36
I0925 20:26:02.880847  3547 net.cpp:122] Setting up Scale36
I0925 20:26:02.880851  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.880853  3547 net.cpp:137] Memory required for data: 974439600
I0925 20:26:02.880857  3547 layer_factory.hpp:77] Creating layer Eltwise17
I0925 20:26:02.880863  3547 net.cpp:84] Creating Layer Eltwise17
I0925 20:26:02.880866  3547 net.cpp:406] Eltwise17 <- Eltwise16_PReLU33_0_split_1
I0925 20:26:02.880868  3547 net.cpp:406] Eltwise17 <- Convolution36
I0925 20:26:02.880872  3547 net.cpp:380] Eltwise17 -> Eltwise17
I0925 20:26:02.880883  3547 net.cpp:122] Setting up Eltwise17
I0925 20:26:02.880887  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.880889  3547 net.cpp:137] Memory required for data: 977716400
I0925 20:26:02.880892  3547 layer_factory.hpp:77] Creating layer PReLU35
I0925 20:26:02.880894  3547 net.cpp:84] Creating Layer PReLU35
I0925 20:26:02.880897  3547 net.cpp:406] PReLU35 <- Eltwise17
I0925 20:26:02.880900  3547 net.cpp:367] PReLU35 -> Eltwise17 (in-place)
I0925 20:26:02.880959  3547 net.cpp:122] Setting up PReLU35
I0925 20:26:02.880962  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.880964  3547 net.cpp:137] Memory required for data: 980993200
I0925 20:26:02.880967  3547 layer_factory.hpp:77] Creating layer Eltwise17_PReLU35_0_split
I0925 20:26:02.880970  3547 net.cpp:84] Creating Layer Eltwise17_PReLU35_0_split
I0925 20:26:02.880973  3547 net.cpp:406] Eltwise17_PReLU35_0_split <- Eltwise17
I0925 20:26:02.880976  3547 net.cpp:380] Eltwise17_PReLU35_0_split -> Eltwise17_PReLU35_0_split_0
I0925 20:26:02.880980  3547 net.cpp:380] Eltwise17_PReLU35_0_split -> Eltwise17_PReLU35_0_split_1
I0925 20:26:02.881003  3547 net.cpp:122] Setting up Eltwise17_PReLU35_0_split
I0925 20:26:02.881006  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.881009  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.881011  3547 net.cpp:137] Memory required for data: 987546800
I0925 20:26:02.881013  3547 layer_factory.hpp:77] Creating layer Convolution37
I0925 20:26:02.881019  3547 net.cpp:84] Creating Layer Convolution37
I0925 20:26:02.881022  3547 net.cpp:406] Convolution37 <- Eltwise17_PReLU35_0_split_0
I0925 20:26:02.881026  3547 net.cpp:380] Convolution37 -> Convolution37
I0925 20:26:02.882100  3547 net.cpp:122] Setting up Convolution37
I0925 20:26:02.882108  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.882112  3547 net.cpp:137] Memory required for data: 990823600
I0925 20:26:02.882115  3547 layer_factory.hpp:77] Creating layer BatchNorm37
I0925 20:26:02.882120  3547 net.cpp:84] Creating Layer BatchNorm37
I0925 20:26:02.882123  3547 net.cpp:406] BatchNorm37 <- Convolution37
I0925 20:26:02.882128  3547 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0925 20:26:02.882253  3547 net.cpp:122] Setting up BatchNorm37
I0925 20:26:02.882258  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.882261  3547 net.cpp:137] Memory required for data: 994100400
I0925 20:26:02.882264  3547 layer_factory.hpp:77] Creating layer Scale37
I0925 20:26:02.882268  3547 net.cpp:84] Creating Layer Scale37
I0925 20:26:02.882270  3547 net.cpp:406] Scale37 <- Convolution37
I0925 20:26:02.882273  3547 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0925 20:26:02.882300  3547 layer_factory.hpp:77] Creating layer Scale37
I0925 20:26:02.882371  3547 net.cpp:122] Setting up Scale37
I0925 20:26:02.882376  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.882378  3547 net.cpp:137] Memory required for data: 997377200
I0925 20:26:02.882382  3547 layer_factory.hpp:77] Creating layer PReLU36
I0925 20:26:02.882385  3547 net.cpp:84] Creating Layer PReLU36
I0925 20:26:02.882395  3547 net.cpp:406] PReLU36 <- Convolution37
I0925 20:26:02.882397  3547 net.cpp:367] PReLU36 -> Convolution37 (in-place)
I0925 20:26:02.882455  3547 net.cpp:122] Setting up PReLU36
I0925 20:26:02.882460  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.882462  3547 net.cpp:137] Memory required for data: 1000654000
I0925 20:26:02.882465  3547 layer_factory.hpp:77] Creating layer Convolution38
I0925 20:26:02.882470  3547 net.cpp:84] Creating Layer Convolution38
I0925 20:26:02.882473  3547 net.cpp:406] Convolution38 <- Convolution37
I0925 20:26:02.882477  3547 net.cpp:380] Convolution38 -> Convolution38
I0925 20:26:02.883869  3547 net.cpp:122] Setting up Convolution38
I0925 20:26:02.883878  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.883880  3547 net.cpp:137] Memory required for data: 1003930800
I0925 20:26:02.883885  3547 layer_factory.hpp:77] Creating layer BatchNorm38
I0925 20:26:02.883891  3547 net.cpp:84] Creating Layer BatchNorm38
I0925 20:26:02.883894  3547 net.cpp:406] BatchNorm38 <- Convolution38
I0925 20:26:02.883898  3547 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0925 20:26:02.884029  3547 net.cpp:122] Setting up BatchNorm38
I0925 20:26:02.884033  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.884035  3547 net.cpp:137] Memory required for data: 1007207600
I0925 20:26:02.904320  3547 layer_factory.hpp:77] Creating layer Scale38
I0925 20:26:02.904331  3547 net.cpp:84] Creating Layer Scale38
I0925 20:26:02.904336  3547 net.cpp:406] Scale38 <- Convolution38
I0925 20:26:02.904343  3547 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0925 20:26:02.904383  3547 layer_factory.hpp:77] Creating layer Scale38
I0925 20:26:02.904470  3547 net.cpp:122] Setting up Scale38
I0925 20:26:02.904475  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.904479  3547 net.cpp:137] Memory required for data: 1010484400
I0925 20:26:02.904482  3547 layer_factory.hpp:77] Creating layer Eltwise18
I0925 20:26:02.904487  3547 net.cpp:84] Creating Layer Eltwise18
I0925 20:26:02.904489  3547 net.cpp:406] Eltwise18 <- Eltwise17_PReLU35_0_split_1
I0925 20:26:02.904494  3547 net.cpp:406] Eltwise18 <- Convolution38
I0925 20:26:02.904505  3547 net.cpp:380] Eltwise18 -> Eltwise18
I0925 20:26:02.904520  3547 net.cpp:122] Setting up Eltwise18
I0925 20:26:02.904525  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.904526  3547 net.cpp:137] Memory required for data: 1013761200
I0925 20:26:02.904528  3547 layer_factory.hpp:77] Creating layer PReLU37
I0925 20:26:02.904532  3547 net.cpp:84] Creating Layer PReLU37
I0925 20:26:02.904534  3547 net.cpp:406] PReLU37 <- Eltwise18
I0925 20:26:02.904538  3547 net.cpp:367] PReLU37 -> Eltwise18 (in-place)
I0925 20:26:02.904605  3547 net.cpp:122] Setting up PReLU37
I0925 20:26:02.904610  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.904613  3547 net.cpp:137] Memory required for data: 1017038000
I0925 20:26:02.904616  3547 layer_factory.hpp:77] Creating layer Eltwise18_PReLU37_0_split
I0925 20:26:02.904620  3547 net.cpp:84] Creating Layer Eltwise18_PReLU37_0_split
I0925 20:26:02.904623  3547 net.cpp:406] Eltwise18_PReLU37_0_split <- Eltwise18
I0925 20:26:02.904626  3547 net.cpp:380] Eltwise18_PReLU37_0_split -> Eltwise18_PReLU37_0_split_0
I0925 20:26:02.904631  3547 net.cpp:380] Eltwise18_PReLU37_0_split -> Eltwise18_PReLU37_0_split_1
I0925 20:26:02.904656  3547 net.cpp:122] Setting up Eltwise18_PReLU37_0_split
I0925 20:26:02.904660  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.904664  3547 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0925 20:26:02.904665  3547 net.cpp:137] Memory required for data: 1023591600
I0925 20:26:02.904667  3547 layer_factory.hpp:77] Creating layer Convolution39
I0925 20:26:02.904675  3547 net.cpp:84] Creating Layer Convolution39
I0925 20:26:02.904677  3547 net.cpp:406] Convolution39 <- Eltwise18_PReLU37_0_split_0
I0925 20:26:02.904682  3547 net.cpp:380] Convolution39 -> Convolution39
I0925 20:26:02.905781  3547 net.cpp:122] Setting up Convolution39
I0925 20:26:02.905794  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.905799  3547 net.cpp:137] Memory required for data: 1025230000
I0925 20:26:02.905807  3547 layer_factory.hpp:77] Creating layer BatchNorm39
I0925 20:26:02.905813  3547 net.cpp:84] Creating Layer BatchNorm39
I0925 20:26:02.905817  3547 net.cpp:406] BatchNorm39 <- Convolution39
I0925 20:26:02.905823  3547 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0925 20:26:02.905974  3547 net.cpp:122] Setting up BatchNorm39
I0925 20:26:02.905979  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.905982  3547 net.cpp:137] Memory required for data: 1026868400
I0925 20:26:02.905987  3547 layer_factory.hpp:77] Creating layer Scale39
I0925 20:26:02.905992  3547 net.cpp:84] Creating Layer Scale39
I0925 20:26:02.905994  3547 net.cpp:406] Scale39 <- Convolution39
I0925 20:26:02.905998  3547 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0925 20:26:02.906028  3547 layer_factory.hpp:77] Creating layer Scale39
I0925 20:26:02.906118  3547 net.cpp:122] Setting up Scale39
I0925 20:26:02.906123  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.906126  3547 net.cpp:137] Memory required for data: 1028506800
I0925 20:26:02.906129  3547 layer_factory.hpp:77] Creating layer Convolution40
I0925 20:26:02.906137  3547 net.cpp:84] Creating Layer Convolution40
I0925 20:26:02.906139  3547 net.cpp:406] Convolution40 <- Eltwise18_PReLU37_0_split_1
I0925 20:26:02.906144  3547 net.cpp:380] Convolution40 -> Convolution40
I0925 20:26:02.907584  3547 net.cpp:122] Setting up Convolution40
I0925 20:26:02.907593  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.907596  3547 net.cpp:137] Memory required for data: 1030145200
I0925 20:26:02.907600  3547 layer_factory.hpp:77] Creating layer BatchNorm40
I0925 20:26:02.907605  3547 net.cpp:84] Creating Layer BatchNorm40
I0925 20:26:02.907608  3547 net.cpp:406] BatchNorm40 <- Convolution40
I0925 20:26:02.907613  3547 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0925 20:26:02.907758  3547 net.cpp:122] Setting up BatchNorm40
I0925 20:26:02.907763  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.907774  3547 net.cpp:137] Memory required for data: 1031783600
I0925 20:26:02.907779  3547 layer_factory.hpp:77] Creating layer Scale40
I0925 20:26:02.907783  3547 net.cpp:84] Creating Layer Scale40
I0925 20:26:02.907786  3547 net.cpp:406] Scale40 <- Convolution40
I0925 20:26:02.907800  3547 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0925 20:26:02.907847  3547 layer_factory.hpp:77] Creating layer Scale40
I0925 20:26:02.907954  3547 net.cpp:122] Setting up Scale40
I0925 20:26:02.907959  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.907961  3547 net.cpp:137] Memory required for data: 1033422000
I0925 20:26:02.907965  3547 layer_factory.hpp:77] Creating layer PReLU38
I0925 20:26:02.907969  3547 net.cpp:84] Creating Layer PReLU38
I0925 20:26:02.907971  3547 net.cpp:406] PReLU38 <- Convolution40
I0925 20:26:02.907974  3547 net.cpp:367] PReLU38 -> Convolution40 (in-place)
I0925 20:26:02.908041  3547 net.cpp:122] Setting up PReLU38
I0925 20:26:02.908046  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.908047  3547 net.cpp:137] Memory required for data: 1035060400
I0925 20:26:02.908051  3547 layer_factory.hpp:77] Creating layer Convolution41
I0925 20:26:02.908057  3547 net.cpp:84] Creating Layer Convolution41
I0925 20:26:02.908061  3547 net.cpp:406] Convolution41 <- Convolution40
I0925 20:26:02.908064  3547 net.cpp:380] Convolution41 -> Convolution41
I0925 20:26:02.909857  3547 net.cpp:122] Setting up Convolution41
I0925 20:26:02.909865  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.909868  3547 net.cpp:137] Memory required for data: 1036698800
I0925 20:26:02.909873  3547 layer_factory.hpp:77] Creating layer BatchNorm41
I0925 20:26:02.909878  3547 net.cpp:84] Creating Layer BatchNorm41
I0925 20:26:02.909880  3547 net.cpp:406] BatchNorm41 <- Convolution41
I0925 20:26:02.909884  3547 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0925 20:26:02.910020  3547 net.cpp:122] Setting up BatchNorm41
I0925 20:26:02.910025  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.910027  3547 net.cpp:137] Memory required for data: 1038337200
I0925 20:26:02.910032  3547 layer_factory.hpp:77] Creating layer Scale41
I0925 20:26:02.910037  3547 net.cpp:84] Creating Layer Scale41
I0925 20:26:02.910039  3547 net.cpp:406] Scale41 <- Convolution41
I0925 20:26:02.910043  3547 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0925 20:26:02.910068  3547 layer_factory.hpp:77] Creating layer Scale41
I0925 20:26:02.910141  3547 net.cpp:122] Setting up Scale41
I0925 20:26:02.910146  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.910148  3547 net.cpp:137] Memory required for data: 1039975600
I0925 20:26:02.910151  3547 layer_factory.hpp:77] Creating layer Eltwise19
I0925 20:26:02.910156  3547 net.cpp:84] Creating Layer Eltwise19
I0925 20:26:02.910159  3547 net.cpp:406] Eltwise19 <- Convolution39
I0925 20:26:02.910161  3547 net.cpp:406] Eltwise19 <- Convolution41
I0925 20:26:02.910166  3547 net.cpp:380] Eltwise19 -> Eltwise19
I0925 20:26:02.910181  3547 net.cpp:122] Setting up Eltwise19
I0925 20:26:02.910184  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.910187  3547 net.cpp:137] Memory required for data: 1041614000
I0925 20:26:02.910188  3547 layer_factory.hpp:77] Creating layer PReLU39
I0925 20:26:02.910192  3547 net.cpp:84] Creating Layer PReLU39
I0925 20:26:02.910193  3547 net.cpp:406] PReLU39 <- Eltwise19
I0925 20:26:02.910198  3547 net.cpp:367] PReLU39 -> Eltwise19 (in-place)
I0925 20:26:02.910260  3547 net.cpp:122] Setting up PReLU39
I0925 20:26:02.910265  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.910267  3547 net.cpp:137] Memory required for data: 1043252400
I0925 20:26:02.910270  3547 layer_factory.hpp:77] Creating layer Eltwise19_PReLU39_0_split
I0925 20:26:02.910274  3547 net.cpp:84] Creating Layer Eltwise19_PReLU39_0_split
I0925 20:26:02.910275  3547 net.cpp:406] Eltwise19_PReLU39_0_split <- Eltwise19
I0925 20:26:02.910279  3547 net.cpp:380] Eltwise19_PReLU39_0_split -> Eltwise19_PReLU39_0_split_0
I0925 20:26:02.910284  3547 net.cpp:380] Eltwise19_PReLU39_0_split -> Eltwise19_PReLU39_0_split_1
I0925 20:26:02.910306  3547 net.cpp:122] Setting up Eltwise19_PReLU39_0_split
I0925 20:26:02.910310  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.910312  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.910315  3547 net.cpp:137] Memory required for data: 1046529200
I0925 20:26:02.910316  3547 layer_factory.hpp:77] Creating layer Convolution42
I0925 20:26:02.910323  3547 net.cpp:84] Creating Layer Convolution42
I0925 20:26:02.910326  3547 net.cpp:406] Convolution42 <- Eltwise19_PReLU39_0_split_0
I0925 20:26:02.910331  3547 net.cpp:380] Convolution42 -> Convolution42
I0925 20:26:02.912009  3547 net.cpp:122] Setting up Convolution42
I0925 20:26:02.912016  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.912019  3547 net.cpp:137] Memory required for data: 1048167600
I0925 20:26:02.912024  3547 layer_factory.hpp:77] Creating layer BatchNorm42
I0925 20:26:02.912029  3547 net.cpp:84] Creating Layer BatchNorm42
I0925 20:26:02.912031  3547 net.cpp:406] BatchNorm42 <- Convolution42
I0925 20:26:02.912034  3547 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0925 20:26:02.912165  3547 net.cpp:122] Setting up BatchNorm42
I0925 20:26:02.912169  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.912171  3547 net.cpp:137] Memory required for data: 1049806000
I0925 20:26:02.912176  3547 layer_factory.hpp:77] Creating layer Scale42
I0925 20:26:02.912180  3547 net.cpp:84] Creating Layer Scale42
I0925 20:26:02.912184  3547 net.cpp:406] Scale42 <- Convolution42
I0925 20:26:02.912186  3547 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0925 20:26:02.912214  3547 layer_factory.hpp:77] Creating layer Scale42
I0925 20:26:02.912287  3547 net.cpp:122] Setting up Scale42
I0925 20:26:02.912292  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.912300  3547 net.cpp:137] Memory required for data: 1051444400
I0925 20:26:02.912304  3547 layer_factory.hpp:77] Creating layer PReLU40
I0925 20:26:02.912308  3547 net.cpp:84] Creating Layer PReLU40
I0925 20:26:02.912312  3547 net.cpp:406] PReLU40 <- Convolution42
I0925 20:26:02.912314  3547 net.cpp:367] PReLU40 -> Convolution42 (in-place)
I0925 20:26:02.912377  3547 net.cpp:122] Setting up PReLU40
I0925 20:26:02.912381  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.912384  3547 net.cpp:137] Memory required for data: 1053082800
I0925 20:26:02.912386  3547 layer_factory.hpp:77] Creating layer Convolution43
I0925 20:26:02.912394  3547 net.cpp:84] Creating Layer Convolution43
I0925 20:26:02.912395  3547 net.cpp:406] Convolution43 <- Convolution42
I0925 20:26:02.912400  3547 net.cpp:380] Convolution43 -> Convolution43
I0925 20:26:02.914078  3547 net.cpp:122] Setting up Convolution43
I0925 20:26:02.914086  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.914089  3547 net.cpp:137] Memory required for data: 1054721200
I0925 20:26:02.914093  3547 layer_factory.hpp:77] Creating layer BatchNorm43
I0925 20:26:02.914098  3547 net.cpp:84] Creating Layer BatchNorm43
I0925 20:26:02.914101  3547 net.cpp:406] BatchNorm43 <- Convolution43
I0925 20:26:02.914105  3547 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0925 20:26:02.914237  3547 net.cpp:122] Setting up BatchNorm43
I0925 20:26:02.914242  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.914243  3547 net.cpp:137] Memory required for data: 1056359600
I0925 20:26:02.914248  3547 layer_factory.hpp:77] Creating layer Scale43
I0925 20:26:02.914252  3547 net.cpp:84] Creating Layer Scale43
I0925 20:26:02.914255  3547 net.cpp:406] Scale43 <- Convolution43
I0925 20:26:02.914258  3547 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0925 20:26:02.914285  3547 layer_factory.hpp:77] Creating layer Scale43
I0925 20:26:02.914361  3547 net.cpp:122] Setting up Scale43
I0925 20:26:02.914366  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.914368  3547 net.cpp:137] Memory required for data: 1057998000
I0925 20:26:02.914371  3547 layer_factory.hpp:77] Creating layer Eltwise20
I0925 20:26:02.914376  3547 net.cpp:84] Creating Layer Eltwise20
I0925 20:26:02.914389  3547 net.cpp:406] Eltwise20 <- Eltwise19_PReLU39_0_split_1
I0925 20:26:02.914392  3547 net.cpp:406] Eltwise20 <- Convolution43
I0925 20:26:02.914397  3547 net.cpp:380] Eltwise20 -> Eltwise20
I0925 20:26:02.914412  3547 net.cpp:122] Setting up Eltwise20
I0925 20:26:02.914417  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.914418  3547 net.cpp:137] Memory required for data: 1059636400
I0925 20:26:02.914420  3547 layer_factory.hpp:77] Creating layer PReLU41
I0925 20:26:02.914424  3547 net.cpp:84] Creating Layer PReLU41
I0925 20:26:02.914427  3547 net.cpp:406] PReLU41 <- Eltwise20
I0925 20:26:02.914438  3547 net.cpp:367] PReLU41 -> Eltwise20 (in-place)
I0925 20:26:02.914500  3547 net.cpp:122] Setting up PReLU41
I0925 20:26:02.914505  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.914507  3547 net.cpp:137] Memory required for data: 1061274800
I0925 20:26:02.914510  3547 layer_factory.hpp:77] Creating layer Eltwise20_PReLU41_0_split
I0925 20:26:02.914513  3547 net.cpp:84] Creating Layer Eltwise20_PReLU41_0_split
I0925 20:26:02.914515  3547 net.cpp:406] Eltwise20_PReLU41_0_split <- Eltwise20
I0925 20:26:02.914518  3547 net.cpp:380] Eltwise20_PReLU41_0_split -> Eltwise20_PReLU41_0_split_0
I0925 20:26:02.914522  3547 net.cpp:380] Eltwise20_PReLU41_0_split -> Eltwise20_PReLU41_0_split_1
I0925 20:26:02.914546  3547 net.cpp:122] Setting up Eltwise20_PReLU41_0_split
I0925 20:26:02.914551  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.914553  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.914556  3547 net.cpp:137] Memory required for data: 1064551600
I0925 20:26:02.914557  3547 layer_factory.hpp:77] Creating layer Convolution44
I0925 20:26:02.914563  3547 net.cpp:84] Creating Layer Convolution44
I0925 20:26:02.914573  3547 net.cpp:406] Convolution44 <- Eltwise20_PReLU41_0_split_0
I0925 20:26:02.914578  3547 net.cpp:380] Convolution44 -> Convolution44
I0925 20:26:02.916577  3547 net.cpp:122] Setting up Convolution44
I0925 20:26:02.916586  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.916589  3547 net.cpp:137] Memory required for data: 1066190000
I0925 20:26:02.916594  3547 layer_factory.hpp:77] Creating layer BatchNorm44
I0925 20:26:02.916599  3547 net.cpp:84] Creating Layer BatchNorm44
I0925 20:26:02.916600  3547 net.cpp:406] BatchNorm44 <- Convolution44
I0925 20:26:02.916605  3547 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0925 20:26:02.916741  3547 net.cpp:122] Setting up BatchNorm44
I0925 20:26:02.916746  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.916749  3547 net.cpp:137] Memory required for data: 1067828400
I0925 20:26:02.916754  3547 layer_factory.hpp:77] Creating layer Scale44
I0925 20:26:02.916757  3547 net.cpp:84] Creating Layer Scale44
I0925 20:26:02.916759  3547 net.cpp:406] Scale44 <- Convolution44
I0925 20:26:02.916764  3547 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0925 20:26:02.916790  3547 layer_factory.hpp:77] Creating layer Scale44
I0925 20:26:02.916867  3547 net.cpp:122] Setting up Scale44
I0925 20:26:02.916872  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.916873  3547 net.cpp:137] Memory required for data: 1069466800
I0925 20:26:02.916877  3547 layer_factory.hpp:77] Creating layer PReLU42
I0925 20:26:02.916880  3547 net.cpp:84] Creating Layer PReLU42
I0925 20:26:02.916882  3547 net.cpp:406] PReLU42 <- Convolution44
I0925 20:26:02.916887  3547 net.cpp:367] PReLU42 -> Convolution44 (in-place)
I0925 20:26:02.916950  3547 net.cpp:122] Setting up PReLU42
I0925 20:26:02.916954  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.916956  3547 net.cpp:137] Memory required for data: 1071105200
I0925 20:26:02.916960  3547 layer_factory.hpp:77] Creating layer Convolution45
I0925 20:26:02.916966  3547 net.cpp:84] Creating Layer Convolution45
I0925 20:26:02.916968  3547 net.cpp:406] Convolution45 <- Convolution44
I0925 20:26:02.916972  3547 net.cpp:380] Convolution45 -> Convolution45
I0925 20:26:02.918668  3547 net.cpp:122] Setting up Convolution45
I0925 20:26:02.918676  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.918679  3547 net.cpp:137] Memory required for data: 1072743600
I0925 20:26:02.918684  3547 layer_factory.hpp:77] Creating layer BatchNorm45
I0925 20:26:02.918689  3547 net.cpp:84] Creating Layer BatchNorm45
I0925 20:26:02.918691  3547 net.cpp:406] BatchNorm45 <- Convolution45
I0925 20:26:02.918695  3547 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0925 20:26:02.918829  3547 net.cpp:122] Setting up BatchNorm45
I0925 20:26:02.918834  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.918836  3547 net.cpp:137] Memory required for data: 1074382000
I0925 20:26:02.918840  3547 layer_factory.hpp:77] Creating layer Scale45
I0925 20:26:02.918844  3547 net.cpp:84] Creating Layer Scale45
I0925 20:26:02.918848  3547 net.cpp:406] Scale45 <- Convolution45
I0925 20:26:02.918850  3547 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0925 20:26:02.918876  3547 layer_factory.hpp:77] Creating layer Scale45
I0925 20:26:02.918953  3547 net.cpp:122] Setting up Scale45
I0925 20:26:02.918957  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.918959  3547 net.cpp:137] Memory required for data: 1076020400
I0925 20:26:02.918963  3547 layer_factory.hpp:77] Creating layer Eltwise21
I0925 20:26:02.918967  3547 net.cpp:84] Creating Layer Eltwise21
I0925 20:26:02.918969  3547 net.cpp:406] Eltwise21 <- Eltwise20_PReLU41_0_split_1
I0925 20:26:02.918972  3547 net.cpp:406] Eltwise21 <- Convolution45
I0925 20:26:02.918975  3547 net.cpp:380] Eltwise21 -> Eltwise21
I0925 20:26:02.918992  3547 net.cpp:122] Setting up Eltwise21
I0925 20:26:02.918995  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.918998  3547 net.cpp:137] Memory required for data: 1077658800
I0925 20:26:02.919005  3547 layer_factory.hpp:77] Creating layer PReLU43
I0925 20:26:02.919010  3547 net.cpp:84] Creating Layer PReLU43
I0925 20:26:02.919013  3547 net.cpp:406] PReLU43 <- Eltwise21
I0925 20:26:02.919015  3547 net.cpp:367] PReLU43 -> Eltwise21 (in-place)
I0925 20:26:02.919080  3547 net.cpp:122] Setting up PReLU43
I0925 20:26:02.919085  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.919086  3547 net.cpp:137] Memory required for data: 1079297200
I0925 20:26:02.919090  3547 layer_factory.hpp:77] Creating layer Eltwise21_PReLU43_0_split
I0925 20:26:02.919093  3547 net.cpp:84] Creating Layer Eltwise21_PReLU43_0_split
I0925 20:26:02.919095  3547 net.cpp:406] Eltwise21_PReLU43_0_split <- Eltwise21
I0925 20:26:02.919100  3547 net.cpp:380] Eltwise21_PReLU43_0_split -> Eltwise21_PReLU43_0_split_0
I0925 20:26:02.919104  3547 net.cpp:380] Eltwise21_PReLU43_0_split -> Eltwise21_PReLU43_0_split_1
I0925 20:26:02.919127  3547 net.cpp:122] Setting up Eltwise21_PReLU43_0_split
I0925 20:26:02.919131  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.919134  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.934583  3547 net.cpp:137] Memory required for data: 1082574000
I0925 20:26:02.934590  3547 layer_factory.hpp:77] Creating layer Convolution46
I0925 20:26:02.934600  3547 net.cpp:84] Creating Layer Convolution46
I0925 20:26:02.934604  3547 net.cpp:406] Convolution46 <- Eltwise21_PReLU43_0_split_0
I0925 20:26:02.934609  3547 net.cpp:380] Convolution46 -> Convolution46
I0925 20:26:02.936550  3547 net.cpp:122] Setting up Convolution46
I0925 20:26:02.936559  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.936573  3547 net.cpp:137] Memory required for data: 1084212400
I0925 20:26:02.936578  3547 layer_factory.hpp:77] Creating layer BatchNorm46
I0925 20:26:02.936583  3547 net.cpp:84] Creating Layer BatchNorm46
I0925 20:26:02.936586  3547 net.cpp:406] BatchNorm46 <- Convolution46
I0925 20:26:02.936590  3547 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0925 20:26:02.936758  3547 net.cpp:122] Setting up BatchNorm46
I0925 20:26:02.936764  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.936765  3547 net.cpp:137] Memory required for data: 1085850800
I0925 20:26:02.936771  3547 layer_factory.hpp:77] Creating layer Scale46
I0925 20:26:02.936777  3547 net.cpp:84] Creating Layer Scale46
I0925 20:26:02.936780  3547 net.cpp:406] Scale46 <- Convolution46
I0925 20:26:02.936784  3547 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0925 20:26:02.936813  3547 layer_factory.hpp:77] Creating layer Scale46
I0925 20:26:02.936895  3547 net.cpp:122] Setting up Scale46
I0925 20:26:02.936900  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.936902  3547 net.cpp:137] Memory required for data: 1087489200
I0925 20:26:02.936906  3547 layer_factory.hpp:77] Creating layer PReLU44
I0925 20:26:02.936911  3547 net.cpp:84] Creating Layer PReLU44
I0925 20:26:02.936913  3547 net.cpp:406] PReLU44 <- Convolution46
I0925 20:26:02.936916  3547 net.cpp:367] PReLU44 -> Convolution46 (in-place)
I0925 20:26:02.936985  3547 net.cpp:122] Setting up PReLU44
I0925 20:26:02.936988  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.936990  3547 net.cpp:137] Memory required for data: 1089127600
I0925 20:26:02.936993  3547 layer_factory.hpp:77] Creating layer Convolution47
I0925 20:26:02.937000  3547 net.cpp:84] Creating Layer Convolution47
I0925 20:26:02.937003  3547 net.cpp:406] Convolution47 <- Convolution46
I0925 20:26:02.937006  3547 net.cpp:380] Convolution47 -> Convolution47
I0925 20:26:02.938833  3547 net.cpp:122] Setting up Convolution47
I0925 20:26:02.938841  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.938844  3547 net.cpp:137] Memory required for data: 1090766000
I0925 20:26:02.938848  3547 layer_factory.hpp:77] Creating layer BatchNorm47
I0925 20:26:02.938853  3547 net.cpp:84] Creating Layer BatchNorm47
I0925 20:26:02.938856  3547 net.cpp:406] BatchNorm47 <- Convolution47
I0925 20:26:02.938860  3547 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0925 20:26:02.939002  3547 net.cpp:122] Setting up BatchNorm47
I0925 20:26:02.939007  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.939009  3547 net.cpp:137] Memory required for data: 1092404400
I0925 20:26:02.939014  3547 layer_factory.hpp:77] Creating layer Scale47
I0925 20:26:02.939019  3547 net.cpp:84] Creating Layer Scale47
I0925 20:26:02.939021  3547 net.cpp:406] Scale47 <- Convolution47
I0925 20:26:02.939025  3547 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0925 20:26:02.939052  3547 layer_factory.hpp:77] Creating layer Scale47
I0925 20:26:02.939131  3547 net.cpp:122] Setting up Scale47
I0925 20:26:02.939136  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.939137  3547 net.cpp:137] Memory required for data: 1094042800
I0925 20:26:02.939141  3547 layer_factory.hpp:77] Creating layer Eltwise22
I0925 20:26:02.939146  3547 net.cpp:84] Creating Layer Eltwise22
I0925 20:26:02.939149  3547 net.cpp:406] Eltwise22 <- Eltwise21_PReLU43_0_split_1
I0925 20:26:02.939152  3547 net.cpp:406] Eltwise22 <- Convolution47
I0925 20:26:02.939155  3547 net.cpp:380] Eltwise22 -> Eltwise22
I0925 20:26:02.939172  3547 net.cpp:122] Setting up Eltwise22
I0925 20:26:02.939175  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.939177  3547 net.cpp:137] Memory required for data: 1095681200
I0925 20:26:02.939179  3547 layer_factory.hpp:77] Creating layer PReLU45
I0925 20:26:02.939183  3547 net.cpp:84] Creating Layer PReLU45
I0925 20:26:02.939185  3547 net.cpp:406] PReLU45 <- Eltwise22
I0925 20:26:02.939188  3547 net.cpp:367] PReLU45 -> Eltwise22 (in-place)
I0925 20:26:02.939263  3547 net.cpp:122] Setting up PReLU45
I0925 20:26:02.939268  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.939270  3547 net.cpp:137] Memory required for data: 1097319600
I0925 20:26:02.939272  3547 layer_factory.hpp:77] Creating layer Eltwise22_PReLU45_0_split
I0925 20:26:02.939276  3547 net.cpp:84] Creating Layer Eltwise22_PReLU45_0_split
I0925 20:26:02.939278  3547 net.cpp:406] Eltwise22_PReLU45_0_split <- Eltwise22
I0925 20:26:02.939282  3547 net.cpp:380] Eltwise22_PReLU45_0_split -> Eltwise22_PReLU45_0_split_0
I0925 20:26:02.939286  3547 net.cpp:380] Eltwise22_PReLU45_0_split -> Eltwise22_PReLU45_0_split_1
I0925 20:26:02.939311  3547 net.cpp:122] Setting up Eltwise22_PReLU45_0_split
I0925 20:26:02.939314  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.939317  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.939319  3547 net.cpp:137] Memory required for data: 1100596400
I0925 20:26:02.939321  3547 layer_factory.hpp:77] Creating layer Convolution48
I0925 20:26:02.939327  3547 net.cpp:84] Creating Layer Convolution48
I0925 20:26:02.939330  3547 net.cpp:406] Convolution48 <- Eltwise22_PReLU45_0_split_0
I0925 20:26:02.939335  3547 net.cpp:380] Convolution48 -> Convolution48
I0925 20:26:02.941418  3547 net.cpp:122] Setting up Convolution48
I0925 20:26:02.941427  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.941431  3547 net.cpp:137] Memory required for data: 1102234800
I0925 20:26:02.941435  3547 layer_factory.hpp:77] Creating layer BatchNorm48
I0925 20:26:02.941440  3547 net.cpp:84] Creating Layer BatchNorm48
I0925 20:26:02.941443  3547 net.cpp:406] BatchNorm48 <- Convolution48
I0925 20:26:02.941447  3547 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0925 20:26:02.941591  3547 net.cpp:122] Setting up BatchNorm48
I0925 20:26:02.941596  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.941598  3547 net.cpp:137] Memory required for data: 1103873200
I0925 20:26:02.941603  3547 layer_factory.hpp:77] Creating layer Scale48
I0925 20:26:02.941607  3547 net.cpp:84] Creating Layer Scale48
I0925 20:26:02.941610  3547 net.cpp:406] Scale48 <- Convolution48
I0925 20:26:02.941613  3547 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0925 20:26:02.941643  3547 layer_factory.hpp:77] Creating layer Scale48
I0925 20:26:02.941723  3547 net.cpp:122] Setting up Scale48
I0925 20:26:02.941727  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.941736  3547 net.cpp:137] Memory required for data: 1105511600
I0925 20:26:02.941740  3547 layer_factory.hpp:77] Creating layer PReLU46
I0925 20:26:02.941745  3547 net.cpp:84] Creating Layer PReLU46
I0925 20:26:02.941747  3547 net.cpp:406] PReLU46 <- Convolution48
I0925 20:26:02.941751  3547 net.cpp:367] PReLU46 -> Convolution48 (in-place)
I0925 20:26:02.941819  3547 net.cpp:122] Setting up PReLU46
I0925 20:26:02.941824  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.941826  3547 net.cpp:137] Memory required for data: 1107150000
I0925 20:26:02.941829  3547 layer_factory.hpp:77] Creating layer Convolution49
I0925 20:26:02.941835  3547 net.cpp:84] Creating Layer Convolution49
I0925 20:26:02.941838  3547 net.cpp:406] Convolution49 <- Convolution48
I0925 20:26:02.941843  3547 net.cpp:380] Convolution49 -> Convolution49
I0925 20:26:02.943949  3547 net.cpp:122] Setting up Convolution49
I0925 20:26:02.943959  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.943963  3547 net.cpp:137] Memory required for data: 1108788400
I0925 20:26:02.943967  3547 layer_factory.hpp:77] Creating layer BatchNorm49
I0925 20:26:02.943974  3547 net.cpp:84] Creating Layer BatchNorm49
I0925 20:26:02.943976  3547 net.cpp:406] BatchNorm49 <- Convolution49
I0925 20:26:02.943980  3547 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0925 20:26:02.944133  3547 net.cpp:122] Setting up BatchNorm49
I0925 20:26:02.944138  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.944139  3547 net.cpp:137] Memory required for data: 1110426800
I0925 20:26:02.944144  3547 layer_factory.hpp:77] Creating layer Scale49
I0925 20:26:02.944149  3547 net.cpp:84] Creating Layer Scale49
I0925 20:26:02.944152  3547 net.cpp:406] Scale49 <- Convolution49
I0925 20:26:02.944155  3547 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0925 20:26:02.944186  3547 layer_factory.hpp:77] Creating layer Scale49
I0925 20:26:02.944278  3547 net.cpp:122] Setting up Scale49
I0925 20:26:02.944283  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.944284  3547 net.cpp:137] Memory required for data: 1112065200
I0925 20:26:02.944288  3547 layer_factory.hpp:77] Creating layer Eltwise23
I0925 20:26:02.944293  3547 net.cpp:84] Creating Layer Eltwise23
I0925 20:26:02.944295  3547 net.cpp:406] Eltwise23 <- Eltwise22_PReLU45_0_split_1
I0925 20:26:02.944298  3547 net.cpp:406] Eltwise23 <- Convolution49
I0925 20:26:02.944301  3547 net.cpp:380] Eltwise23 -> Eltwise23
I0925 20:26:02.944317  3547 net.cpp:122] Setting up Eltwise23
I0925 20:26:02.944321  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.944324  3547 net.cpp:137] Memory required for data: 1113703600
I0925 20:26:02.944325  3547 layer_factory.hpp:77] Creating layer PReLU47
I0925 20:26:02.944329  3547 net.cpp:84] Creating Layer PReLU47
I0925 20:26:02.944330  3547 net.cpp:406] PReLU47 <- Eltwise23
I0925 20:26:02.944334  3547 net.cpp:367] PReLU47 -> Eltwise23 (in-place)
I0925 20:26:02.944401  3547 net.cpp:122] Setting up PReLU47
I0925 20:26:02.944404  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.944406  3547 net.cpp:137] Memory required for data: 1115342000
I0925 20:26:02.944409  3547 layer_factory.hpp:77] Creating layer Eltwise23_PReLU47_0_split
I0925 20:26:02.944412  3547 net.cpp:84] Creating Layer Eltwise23_PReLU47_0_split
I0925 20:26:02.944414  3547 net.cpp:406] Eltwise23_PReLU47_0_split <- Eltwise23
I0925 20:26:02.944418  3547 net.cpp:380] Eltwise23_PReLU47_0_split -> Eltwise23_PReLU47_0_split_0
I0925 20:26:02.944423  3547 net.cpp:380] Eltwise23_PReLU47_0_split -> Eltwise23_PReLU47_0_split_1
I0925 20:26:02.944447  3547 net.cpp:122] Setting up Eltwise23_PReLU47_0_split
I0925 20:26:02.944450  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.944453  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.944455  3547 net.cpp:137] Memory required for data: 1118618800
I0925 20:26:02.944458  3547 layer_factory.hpp:77] Creating layer Convolution50
I0925 20:26:02.944464  3547 net.cpp:84] Creating Layer Convolution50
I0925 20:26:02.944473  3547 net.cpp:406] Convolution50 <- Eltwise23_PReLU47_0_split_0
I0925 20:26:02.944478  3547 net.cpp:380] Convolution50 -> Convolution50
I0925 20:26:02.947082  3547 net.cpp:122] Setting up Convolution50
I0925 20:26:02.947091  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.947093  3547 net.cpp:137] Memory required for data: 1120257200
I0925 20:26:02.947099  3547 layer_factory.hpp:77] Creating layer BatchNorm50
I0925 20:26:02.947104  3547 net.cpp:84] Creating Layer BatchNorm50
I0925 20:26:02.947108  3547 net.cpp:406] BatchNorm50 <- Convolution50
I0925 20:26:02.947111  3547 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0925 20:26:02.947263  3547 net.cpp:122] Setting up BatchNorm50
I0925 20:26:02.947268  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.947269  3547 net.cpp:137] Memory required for data: 1121895600
I0925 20:26:02.947274  3547 layer_factory.hpp:77] Creating layer Scale50
I0925 20:26:02.947278  3547 net.cpp:84] Creating Layer Scale50
I0925 20:26:02.947281  3547 net.cpp:406] Scale50 <- Convolution50
I0925 20:26:02.947284  3547 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0925 20:26:02.947312  3547 layer_factory.hpp:77] Creating layer Scale50
I0925 20:26:02.947391  3547 net.cpp:122] Setting up Scale50
I0925 20:26:02.947396  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.947397  3547 net.cpp:137] Memory required for data: 1123534000
I0925 20:26:02.947402  3547 layer_factory.hpp:77] Creating layer PReLU48
I0925 20:26:02.947404  3547 net.cpp:84] Creating Layer PReLU48
I0925 20:26:02.947407  3547 net.cpp:406] PReLU48 <- Convolution50
I0925 20:26:02.947410  3547 net.cpp:367] PReLU48 -> Convolution50 (in-place)
I0925 20:26:02.947475  3547 net.cpp:122] Setting up PReLU48
I0925 20:26:02.947480  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.947482  3547 net.cpp:137] Memory required for data: 1125172400
I0925 20:26:02.947485  3547 layer_factory.hpp:77] Creating layer Convolution51
I0925 20:26:02.947494  3547 net.cpp:84] Creating Layer Convolution51
I0925 20:26:02.947495  3547 net.cpp:406] Convolution51 <- Convolution50
I0925 20:26:02.947499  3547 net.cpp:380] Convolution51 -> Convolution51
I0925 20:26:02.949311  3547 net.cpp:122] Setting up Convolution51
I0925 20:26:02.949321  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.949323  3547 net.cpp:137] Memory required for data: 1126810800
I0925 20:26:02.949327  3547 layer_factory.hpp:77] Creating layer BatchNorm51
I0925 20:26:02.949332  3547 net.cpp:84] Creating Layer BatchNorm51
I0925 20:26:02.949335  3547 net.cpp:406] BatchNorm51 <- Convolution51
I0925 20:26:02.949338  3547 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0925 20:26:02.949475  3547 net.cpp:122] Setting up BatchNorm51
I0925 20:26:02.949479  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.949481  3547 net.cpp:137] Memory required for data: 1128449200
I0925 20:26:02.949486  3547 layer_factory.hpp:77] Creating layer Scale51
I0925 20:26:02.949489  3547 net.cpp:84] Creating Layer Scale51
I0925 20:26:02.949492  3547 net.cpp:406] Scale51 <- Convolution51
I0925 20:26:02.949496  3547 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0925 20:26:02.949523  3547 layer_factory.hpp:77] Creating layer Scale51
I0925 20:26:02.949601  3547 net.cpp:122] Setting up Scale51
I0925 20:26:02.949605  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.949607  3547 net.cpp:137] Memory required for data: 1130087600
I0925 20:26:02.949611  3547 layer_factory.hpp:77] Creating layer Eltwise24
I0925 20:26:02.949615  3547 net.cpp:84] Creating Layer Eltwise24
I0925 20:26:02.949618  3547 net.cpp:406] Eltwise24 <- Eltwise23_PReLU47_0_split_1
I0925 20:26:02.949621  3547 net.cpp:406] Eltwise24 <- Convolution51
I0925 20:26:02.949625  3547 net.cpp:380] Eltwise24 -> Eltwise24
I0925 20:26:02.949640  3547 net.cpp:122] Setting up Eltwise24
I0925 20:26:02.949643  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.949645  3547 net.cpp:137] Memory required for data: 1131726000
I0925 20:26:02.949654  3547 layer_factory.hpp:77] Creating layer PReLU49
I0925 20:26:02.949661  3547 net.cpp:84] Creating Layer PReLU49
I0925 20:26:02.949663  3547 net.cpp:406] PReLU49 <- Eltwise24
I0925 20:26:02.949666  3547 net.cpp:367] PReLU49 -> Eltwise24 (in-place)
I0925 20:26:02.949733  3547 net.cpp:122] Setting up PReLU49
I0925 20:26:02.949738  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.949739  3547 net.cpp:137] Memory required for data: 1133364400
I0925 20:26:02.949743  3547 layer_factory.hpp:77] Creating layer Eltwise24_PReLU49_0_split
I0925 20:26:02.949746  3547 net.cpp:84] Creating Layer Eltwise24_PReLU49_0_split
I0925 20:26:02.949749  3547 net.cpp:406] Eltwise24_PReLU49_0_split <- Eltwise24
I0925 20:26:02.949753  3547 net.cpp:380] Eltwise24_PReLU49_0_split -> Eltwise24_PReLU49_0_split_0
I0925 20:26:02.949756  3547 net.cpp:380] Eltwise24_PReLU49_0_split -> Eltwise24_PReLU49_0_split_1
I0925 20:26:02.949790  3547 net.cpp:122] Setting up Eltwise24_PReLU49_0_split
I0925 20:26:02.964936  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.964946  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.964949  3547 net.cpp:137] Memory required for data: 1136641200
I0925 20:26:02.964952  3547 layer_factory.hpp:77] Creating layer Convolution52
I0925 20:26:02.964960  3547 net.cpp:84] Creating Layer Convolution52
I0925 20:26:02.964963  3547 net.cpp:406] Convolution52 <- Eltwise24_PReLU49_0_split_0
I0925 20:26:02.964968  3547 net.cpp:380] Convolution52 -> Convolution52
I0925 20:26:02.967480  3547 net.cpp:122] Setting up Convolution52
I0925 20:26:02.967490  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.967494  3547 net.cpp:137] Memory required for data: 1138279600
I0925 20:26:02.967499  3547 layer_factory.hpp:77] Creating layer BatchNorm52
I0925 20:26:02.967504  3547 net.cpp:84] Creating Layer BatchNorm52
I0925 20:26:02.967507  3547 net.cpp:406] BatchNorm52 <- Convolution52
I0925 20:26:02.967511  3547 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0925 20:26:02.967669  3547 net.cpp:122] Setting up BatchNorm52
I0925 20:26:02.967674  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.967675  3547 net.cpp:137] Memory required for data: 1139918000
I0925 20:26:02.967680  3547 layer_factory.hpp:77] Creating layer Scale52
I0925 20:26:02.967686  3547 net.cpp:84] Creating Layer Scale52
I0925 20:26:02.967689  3547 net.cpp:406] Scale52 <- Convolution52
I0925 20:26:02.967692  3547 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0925 20:26:02.967722  3547 layer_factory.hpp:77] Creating layer Scale52
I0925 20:26:02.967809  3547 net.cpp:122] Setting up Scale52
I0925 20:26:02.967814  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.967816  3547 net.cpp:137] Memory required for data: 1141556400
I0925 20:26:02.967820  3547 layer_factory.hpp:77] Creating layer PReLU50
I0925 20:26:02.967840  3547 net.cpp:84] Creating Layer PReLU50
I0925 20:26:02.967844  3547 net.cpp:406] PReLU50 <- Convolution52
I0925 20:26:02.967847  3547 net.cpp:367] PReLU50 -> Convolution52 (in-place)
I0925 20:26:02.967921  3547 net.cpp:122] Setting up PReLU50
I0925 20:26:02.967926  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.967927  3547 net.cpp:137] Memory required for data: 1143194800
I0925 20:26:02.967931  3547 layer_factory.hpp:77] Creating layer Convolution53
I0925 20:26:02.967938  3547 net.cpp:84] Creating Layer Convolution53
I0925 20:26:02.967941  3547 net.cpp:406] Convolution53 <- Convolution52
I0925 20:26:02.967945  3547 net.cpp:380] Convolution53 -> Convolution53
I0925 20:26:02.969799  3547 net.cpp:122] Setting up Convolution53
I0925 20:26:02.969810  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.969811  3547 net.cpp:137] Memory required for data: 1144833200
I0925 20:26:02.969816  3547 layer_factory.hpp:77] Creating layer BatchNorm53
I0925 20:26:02.969822  3547 net.cpp:84] Creating Layer BatchNorm53
I0925 20:26:02.969826  3547 net.cpp:406] BatchNorm53 <- Convolution53
I0925 20:26:02.969830  3547 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0925 20:26:02.969990  3547 net.cpp:122] Setting up BatchNorm53
I0925 20:26:02.969995  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.969998  3547 net.cpp:137] Memory required for data: 1146471600
I0925 20:26:02.970003  3547 layer_factory.hpp:77] Creating layer Scale53
I0925 20:26:02.970007  3547 net.cpp:84] Creating Layer Scale53
I0925 20:26:02.970010  3547 net.cpp:406] Scale53 <- Convolution53
I0925 20:26:02.970013  3547 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0925 20:26:02.970044  3547 layer_factory.hpp:77] Creating layer Scale53
I0925 20:26:02.970131  3547 net.cpp:122] Setting up Scale53
I0925 20:26:02.970136  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.970139  3547 net.cpp:137] Memory required for data: 1148110000
I0925 20:26:02.970142  3547 layer_factory.hpp:77] Creating layer Eltwise25
I0925 20:26:02.970147  3547 net.cpp:84] Creating Layer Eltwise25
I0925 20:26:02.970150  3547 net.cpp:406] Eltwise25 <- Eltwise24_PReLU49_0_split_1
I0925 20:26:02.970155  3547 net.cpp:406] Eltwise25 <- Convolution53
I0925 20:26:02.970157  3547 net.cpp:380] Eltwise25 -> Eltwise25
I0925 20:26:02.970175  3547 net.cpp:122] Setting up Eltwise25
I0925 20:26:02.970180  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.970181  3547 net.cpp:137] Memory required for data: 1149748400
I0925 20:26:02.970183  3547 layer_factory.hpp:77] Creating layer PReLU51
I0925 20:26:02.970187  3547 net.cpp:84] Creating Layer PReLU51
I0925 20:26:02.970191  3547 net.cpp:406] PReLU51 <- Eltwise25
I0925 20:26:02.970193  3547 net.cpp:367] PReLU51 -> Eltwise25 (in-place)
I0925 20:26:02.970264  3547 net.cpp:122] Setting up PReLU51
I0925 20:26:02.970269  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.970271  3547 net.cpp:137] Memory required for data: 1151386800
I0925 20:26:02.970274  3547 layer_factory.hpp:77] Creating layer Eltwise25_PReLU51_0_split
I0925 20:26:02.970279  3547 net.cpp:84] Creating Layer Eltwise25_PReLU51_0_split
I0925 20:26:02.970281  3547 net.cpp:406] Eltwise25_PReLU51_0_split <- Eltwise25
I0925 20:26:02.970284  3547 net.cpp:380] Eltwise25_PReLU51_0_split -> Eltwise25_PReLU51_0_split_0
I0925 20:26:02.970289  3547 net.cpp:380] Eltwise25_PReLU51_0_split -> Eltwise25_PReLU51_0_split_1
I0925 20:26:02.970315  3547 net.cpp:122] Setting up Eltwise25_PReLU51_0_split
I0925 20:26:02.970319  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.970322  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.970324  3547 net.cpp:137] Memory required for data: 1154663600
I0925 20:26:02.970326  3547 layer_factory.hpp:77] Creating layer Convolution54
I0925 20:26:02.970332  3547 net.cpp:84] Creating Layer Convolution54
I0925 20:26:02.970335  3547 net.cpp:406] Convolution54 <- Eltwise25_PReLU51_0_split_0
I0925 20:26:02.970340  3547 net.cpp:380] Convolution54 -> Convolution54
I0925 20:26:02.972501  3547 net.cpp:122] Setting up Convolution54
I0925 20:26:02.972509  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.972512  3547 net.cpp:137] Memory required for data: 1156302000
I0925 20:26:02.972518  3547 layer_factory.hpp:77] Creating layer BatchNorm54
I0925 20:26:02.972523  3547 net.cpp:84] Creating Layer BatchNorm54
I0925 20:26:02.972527  3547 net.cpp:406] BatchNorm54 <- Convolution54
I0925 20:26:02.972532  3547 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0925 20:26:02.972687  3547 net.cpp:122] Setting up BatchNorm54
I0925 20:26:02.972692  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.972693  3547 net.cpp:137] Memory required for data: 1157940400
I0925 20:26:02.972698  3547 layer_factory.hpp:77] Creating layer Scale54
I0925 20:26:02.972704  3547 net.cpp:84] Creating Layer Scale54
I0925 20:26:02.972707  3547 net.cpp:406] Scale54 <- Convolution54
I0925 20:26:02.972710  3547 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0925 20:26:02.972740  3547 layer_factory.hpp:77] Creating layer Scale54
I0925 20:26:02.972827  3547 net.cpp:122] Setting up Scale54
I0925 20:26:02.972832  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.972843  3547 net.cpp:137] Memory required for data: 1159578800
I0925 20:26:02.972847  3547 layer_factory.hpp:77] Creating layer PReLU52
I0925 20:26:02.972852  3547 net.cpp:84] Creating Layer PReLU52
I0925 20:26:02.972856  3547 net.cpp:406] PReLU52 <- Convolution54
I0925 20:26:02.972859  3547 net.cpp:367] PReLU52 -> Convolution54 (in-place)
I0925 20:26:02.972932  3547 net.cpp:122] Setting up PReLU52
I0925 20:26:02.972937  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.972939  3547 net.cpp:137] Memory required for data: 1161217200
I0925 20:26:02.972942  3547 layer_factory.hpp:77] Creating layer Convolution55
I0925 20:26:02.972949  3547 net.cpp:84] Creating Layer Convolution55
I0925 20:26:02.972952  3547 net.cpp:406] Convolution55 <- Convolution54
I0925 20:26:02.972956  3547 net.cpp:380] Convolution55 -> Convolution55
I0925 20:26:02.974798  3547 net.cpp:122] Setting up Convolution55
I0925 20:26:02.974807  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.974810  3547 net.cpp:137] Memory required for data: 1162855600
I0925 20:26:02.974815  3547 layer_factory.hpp:77] Creating layer BatchNorm55
I0925 20:26:02.974820  3547 net.cpp:84] Creating Layer BatchNorm55
I0925 20:26:02.974824  3547 net.cpp:406] BatchNorm55 <- Convolution55
I0925 20:26:02.974828  3547 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0925 20:26:02.974978  3547 net.cpp:122] Setting up BatchNorm55
I0925 20:26:02.974983  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.974985  3547 net.cpp:137] Memory required for data: 1164494000
I0925 20:26:02.974990  3547 layer_factory.hpp:77] Creating layer Scale55
I0925 20:26:02.974995  3547 net.cpp:84] Creating Layer Scale55
I0925 20:26:02.974998  3547 net.cpp:406] Scale55 <- Convolution55
I0925 20:26:02.975003  3547 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0925 20:26:02.975033  3547 layer_factory.hpp:77] Creating layer Scale55
I0925 20:26:02.975119  3547 net.cpp:122] Setting up Scale55
I0925 20:26:02.975123  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.975126  3547 net.cpp:137] Memory required for data: 1166132400
I0925 20:26:02.975131  3547 layer_factory.hpp:77] Creating layer Eltwise26
I0925 20:26:02.975134  3547 net.cpp:84] Creating Layer Eltwise26
I0925 20:26:02.975137  3547 net.cpp:406] Eltwise26 <- Eltwise25_PReLU51_0_split_1
I0925 20:26:02.975141  3547 net.cpp:406] Eltwise26 <- Convolution55
I0925 20:26:02.975144  3547 net.cpp:380] Eltwise26 -> Eltwise26
I0925 20:26:02.975162  3547 net.cpp:122] Setting up Eltwise26
I0925 20:26:02.975167  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.975168  3547 net.cpp:137] Memory required for data: 1167770800
I0925 20:26:02.975170  3547 layer_factory.hpp:77] Creating layer PReLU53
I0925 20:26:02.975174  3547 net.cpp:84] Creating Layer PReLU53
I0925 20:26:02.975178  3547 net.cpp:406] PReLU53 <- Eltwise26
I0925 20:26:02.975180  3547 net.cpp:367] PReLU53 -> Eltwise26 (in-place)
I0925 20:26:02.975251  3547 net.cpp:122] Setting up PReLU53
I0925 20:26:02.975256  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.975258  3547 net.cpp:137] Memory required for data: 1169409200
I0925 20:26:02.975261  3547 layer_factory.hpp:77] Creating layer Eltwise26_PReLU53_0_split
I0925 20:26:02.975265  3547 net.cpp:84] Creating Layer Eltwise26_PReLU53_0_split
I0925 20:26:02.975267  3547 net.cpp:406] Eltwise26_PReLU53_0_split <- Eltwise26
I0925 20:26:02.975271  3547 net.cpp:380] Eltwise26_PReLU53_0_split -> Eltwise26_PReLU53_0_split_0
I0925 20:26:02.975276  3547 net.cpp:380] Eltwise26_PReLU53_0_split -> Eltwise26_PReLU53_0_split_1
I0925 20:26:02.975302  3547 net.cpp:122] Setting up Eltwise26_PReLU53_0_split
I0925 20:26:02.975306  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.975309  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.975311  3547 net.cpp:137] Memory required for data: 1172686000
I0925 20:26:02.975313  3547 layer_factory.hpp:77] Creating layer Convolution56
I0925 20:26:02.975320  3547 net.cpp:84] Creating Layer Convolution56
I0925 20:26:02.975330  3547 net.cpp:406] Convolution56 <- Eltwise26_PReLU53_0_split_0
I0925 20:26:02.975335  3547 net.cpp:380] Convolution56 -> Convolution56
I0925 20:26:02.977157  3547 net.cpp:122] Setting up Convolution56
I0925 20:26:02.977167  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.977170  3547 net.cpp:137] Memory required for data: 1174324400
I0925 20:26:02.977175  3547 layer_factory.hpp:77] Creating layer BatchNorm56
I0925 20:26:02.977181  3547 net.cpp:84] Creating Layer BatchNorm56
I0925 20:26:02.977185  3547 net.cpp:406] BatchNorm56 <- Convolution56
I0925 20:26:02.977188  3547 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0925 20:26:02.977342  3547 net.cpp:122] Setting up BatchNorm56
I0925 20:26:02.977347  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.977349  3547 net.cpp:137] Memory required for data: 1175962800
I0925 20:26:02.977355  3547 layer_factory.hpp:77] Creating layer Scale56
I0925 20:26:02.977360  3547 net.cpp:84] Creating Layer Scale56
I0925 20:26:02.977361  3547 net.cpp:406] Scale56 <- Convolution56
I0925 20:26:02.977365  3547 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0925 20:26:02.977396  3547 layer_factory.hpp:77] Creating layer Scale56
I0925 20:26:02.977485  3547 net.cpp:122] Setting up Scale56
I0925 20:26:02.977490  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.977493  3547 net.cpp:137] Memory required for data: 1177601200
I0925 20:26:02.977496  3547 layer_factory.hpp:77] Creating layer PReLU54
I0925 20:26:02.977500  3547 net.cpp:84] Creating Layer PReLU54
I0925 20:26:02.977504  3547 net.cpp:406] PReLU54 <- Convolution56
I0925 20:26:02.977506  3547 net.cpp:367] PReLU54 -> Convolution56 (in-place)
I0925 20:26:02.977579  3547 net.cpp:122] Setting up PReLU54
I0925 20:26:02.977584  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.977586  3547 net.cpp:137] Memory required for data: 1179239600
I0925 20:26:02.977589  3547 layer_factory.hpp:77] Creating layer Convolution57
I0925 20:26:02.977596  3547 net.cpp:84] Creating Layer Convolution57
I0925 20:26:02.977599  3547 net.cpp:406] Convolution57 <- Convolution56
I0925 20:26:02.977603  3547 net.cpp:380] Convolution57 -> Convolution57
I0925 20:26:02.979425  3547 net.cpp:122] Setting up Convolution57
I0925 20:26:02.979434  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.979437  3547 net.cpp:137] Memory required for data: 1180878000
I0925 20:26:02.979442  3547 layer_factory.hpp:77] Creating layer BatchNorm57
I0925 20:26:02.979447  3547 net.cpp:84] Creating Layer BatchNorm57
I0925 20:26:02.979450  3547 net.cpp:406] BatchNorm57 <- Convolution57
I0925 20:26:02.979454  3547 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0925 20:26:02.979604  3547 net.cpp:122] Setting up BatchNorm57
I0925 20:26:02.979609  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.979611  3547 net.cpp:137] Memory required for data: 1182516400
I0925 20:26:02.979616  3547 layer_factory.hpp:77] Creating layer Scale57
I0925 20:26:02.979620  3547 net.cpp:84] Creating Layer Scale57
I0925 20:26:02.979624  3547 net.cpp:406] Scale57 <- Convolution57
I0925 20:26:02.979626  3547 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0925 20:26:02.979660  3547 layer_factory.hpp:77] Creating layer Scale57
I0925 20:26:02.979746  3547 net.cpp:122] Setting up Scale57
I0925 20:26:02.979751  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.979753  3547 net.cpp:137] Memory required for data: 1184154800
I0925 20:26:02.979758  3547 layer_factory.hpp:77] Creating layer Eltwise27
I0925 20:26:02.979763  3547 net.cpp:84] Creating Layer Eltwise27
I0925 20:26:02.979765  3547 net.cpp:406] Eltwise27 <- Eltwise26_PReLU53_0_split_1
I0925 20:26:02.979768  3547 net.cpp:406] Eltwise27 <- Convolution57
I0925 20:26:02.979773  3547 net.cpp:380] Eltwise27 -> Eltwise27
I0925 20:26:02.979789  3547 net.cpp:122] Setting up Eltwise27
I0925 20:26:02.979794  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.979795  3547 net.cpp:137] Memory required for data: 1185793200
I0925 20:26:02.979797  3547 layer_factory.hpp:77] Creating layer PReLU55
I0925 20:26:02.979809  3547 net.cpp:84] Creating Layer PReLU55
I0925 20:26:02.979812  3547 net.cpp:406] PReLU55 <- Eltwise27
I0925 20:26:02.979815  3547 net.cpp:367] PReLU55 -> Eltwise27 (in-place)
I0925 20:26:02.979887  3547 net.cpp:122] Setting up PReLU55
I0925 20:26:02.979892  3547 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0925 20:26:02.979894  3547 net.cpp:137] Memory required for data: 1187431600
I0925 20:26:02.979898  3547 layer_factory.hpp:77] Creating layer Pooling1
I0925 20:26:02.979903  3547 net.cpp:84] Creating Layer Pooling1
I0925 20:26:02.979907  3547 net.cpp:406] Pooling1 <- Eltwise27
I0925 20:26:02.979909  3547 net.cpp:380] Pooling1 -> Pooling1
I0925 20:26:02.980422  3547 net.cpp:122] Setting up Pooling1
I0925 20:26:02.980429  3547 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0925 20:26:02.995245  3547 net.cpp:137] Memory required for data: 1187457200
I0925 20:26:02.995254  3547 layer_factory.hpp:77] Creating layer InnerProduct1
I0925 20:26:02.995261  3547 net.cpp:84] Creating Layer InnerProduct1
I0925 20:26:02.995265  3547 net.cpp:406] InnerProduct1 <- Pooling1
I0925 20:26:02.995270  3547 net.cpp:380] InnerProduct1 -> InnerProduct1
I0925 20:26:02.995398  3547 net.cpp:122] Setting up InnerProduct1
I0925 20:26:02.995404  3547 net.cpp:129] Top shape: 100 10 (1000)
I0925 20:26:02.995405  3547 net.cpp:137] Memory required for data: 1187461200
I0925 20:26:02.995410  3547 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0925 20:26:02.995414  3547 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0925 20:26:02.995416  3547 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0925 20:26:02.995420  3547 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0925 20:26:02.995425  3547 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0925 20:26:02.995455  3547 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0925 20:26:02.995458  3547 net.cpp:129] Top shape: 100 10 (1000)
I0925 20:26:02.995461  3547 net.cpp:129] Top shape: 100 10 (1000)
I0925 20:26:02.995465  3547 net.cpp:137] Memory required for data: 1187469200
I0925 20:26:02.995466  3547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0925 20:26:02.995471  3547 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0925 20:26:02.995472  3547 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0925 20:26:02.995476  3547 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0925 20:26:02.995481  3547 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0925 20:26:02.995486  3547 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0925 20:26:02.995710  3547 net.cpp:122] Setting up SoftmaxWithLoss1
I0925 20:26:02.995718  3547 net.cpp:129] Top shape: (1)
I0925 20:26:02.995720  3547 net.cpp:132]     with loss weight 1
I0925 20:26:02.995728  3547 net.cpp:137] Memory required for data: 1187469204
I0925 20:26:02.995730  3547 layer_factory.hpp:77] Creating layer Accuracy1
I0925 20:26:02.995734  3547 net.cpp:84] Creating Layer Accuracy1
I0925 20:26:02.995738  3547 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0925 20:26:02.995741  3547 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0925 20:26:02.995745  3547 net.cpp:380] Accuracy1 -> Accuracy1
I0925 20:26:02.995753  3547 net.cpp:122] Setting up Accuracy1
I0925 20:26:02.995755  3547 net.cpp:129] Top shape: (1)
I0925 20:26:02.995757  3547 net.cpp:137] Memory required for data: 1187469208
I0925 20:26:02.995760  3547 net.cpp:200] Accuracy1 does not need backward computation.
I0925 20:26:02.995762  3547 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0925 20:26:02.995765  3547 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0925 20:26:02.995769  3547 net.cpp:198] InnerProduct1 needs backward computation.
I0925 20:26:02.995770  3547 net.cpp:198] Pooling1 needs backward computation.
I0925 20:26:02.995774  3547 net.cpp:198] PReLU55 needs backward computation.
I0925 20:26:02.995782  3547 net.cpp:198] Eltwise27 needs backward computation.
I0925 20:26:02.995786  3547 net.cpp:198] Scale57 needs backward computation.
I0925 20:26:02.995788  3547 net.cpp:198] BatchNorm57 needs backward computation.
I0925 20:26:02.995790  3547 net.cpp:198] Convolution57 needs backward computation.
I0925 20:26:02.995792  3547 net.cpp:198] PReLU54 needs backward computation.
I0925 20:26:02.995795  3547 net.cpp:198] Scale56 needs backward computation.
I0925 20:26:02.995796  3547 net.cpp:198] BatchNorm56 needs backward computation.
I0925 20:26:02.995800  3547 net.cpp:198] Convolution56 needs backward computation.
I0925 20:26:02.995801  3547 net.cpp:198] Eltwise26_PReLU53_0_split needs backward computation.
I0925 20:26:02.995805  3547 net.cpp:198] PReLU53 needs backward computation.
I0925 20:26:02.995806  3547 net.cpp:198] Eltwise26 needs backward computation.
I0925 20:26:02.995810  3547 net.cpp:198] Scale55 needs backward computation.
I0925 20:26:02.995811  3547 net.cpp:198] BatchNorm55 needs backward computation.
I0925 20:26:02.995813  3547 net.cpp:198] Convolution55 needs backward computation.
I0925 20:26:02.995815  3547 net.cpp:198] PReLU52 needs backward computation.
I0925 20:26:02.995817  3547 net.cpp:198] Scale54 needs backward computation.
I0925 20:26:02.995820  3547 net.cpp:198] BatchNorm54 needs backward computation.
I0925 20:26:02.995821  3547 net.cpp:198] Convolution54 needs backward computation.
I0925 20:26:02.995824  3547 net.cpp:198] Eltwise25_PReLU51_0_split needs backward computation.
I0925 20:26:02.995826  3547 net.cpp:198] PReLU51 needs backward computation.
I0925 20:26:02.995828  3547 net.cpp:198] Eltwise25 needs backward computation.
I0925 20:26:02.995831  3547 net.cpp:198] Scale53 needs backward computation.
I0925 20:26:02.995833  3547 net.cpp:198] BatchNorm53 needs backward computation.
I0925 20:26:02.995836  3547 net.cpp:198] Convolution53 needs backward computation.
I0925 20:26:02.995837  3547 net.cpp:198] PReLU50 needs backward computation.
I0925 20:26:02.995841  3547 net.cpp:198] Scale52 needs backward computation.
I0925 20:26:02.995842  3547 net.cpp:198] BatchNorm52 needs backward computation.
I0925 20:26:02.995844  3547 net.cpp:198] Convolution52 needs backward computation.
I0925 20:26:02.995846  3547 net.cpp:198] Eltwise24_PReLU49_0_split needs backward computation.
I0925 20:26:02.995849  3547 net.cpp:198] PReLU49 needs backward computation.
I0925 20:26:02.995851  3547 net.cpp:198] Eltwise24 needs backward computation.
I0925 20:26:02.995853  3547 net.cpp:198] Scale51 needs backward computation.
I0925 20:26:02.995857  3547 net.cpp:198] BatchNorm51 needs backward computation.
I0925 20:26:02.995858  3547 net.cpp:198] Convolution51 needs backward computation.
I0925 20:26:02.995860  3547 net.cpp:198] PReLU48 needs backward computation.
I0925 20:26:02.995863  3547 net.cpp:198] Scale50 needs backward computation.
I0925 20:26:02.995865  3547 net.cpp:198] BatchNorm50 needs backward computation.
I0925 20:26:02.995867  3547 net.cpp:198] Convolution50 needs backward computation.
I0925 20:26:02.995869  3547 net.cpp:198] Eltwise23_PReLU47_0_split needs backward computation.
I0925 20:26:02.995872  3547 net.cpp:198] PReLU47 needs backward computation.
I0925 20:26:02.995874  3547 net.cpp:198] Eltwise23 needs backward computation.
I0925 20:26:02.995877  3547 net.cpp:198] Scale49 needs backward computation.
I0925 20:26:02.995879  3547 net.cpp:198] BatchNorm49 needs backward computation.
I0925 20:26:02.995882  3547 net.cpp:198] Convolution49 needs backward computation.
I0925 20:26:02.995884  3547 net.cpp:198] PReLU46 needs backward computation.
I0925 20:26:02.995887  3547 net.cpp:198] Scale48 needs backward computation.
I0925 20:26:02.995889  3547 net.cpp:198] BatchNorm48 needs backward computation.
I0925 20:26:02.995892  3547 net.cpp:198] Convolution48 needs backward computation.
I0925 20:26:02.995893  3547 net.cpp:198] Eltwise22_PReLU45_0_split needs backward computation.
I0925 20:26:02.995896  3547 net.cpp:198] PReLU45 needs backward computation.
I0925 20:26:02.995898  3547 net.cpp:198] Eltwise22 needs backward computation.
I0925 20:26:02.995905  3547 net.cpp:198] Scale47 needs backward computation.
I0925 20:26:02.995908  3547 net.cpp:198] BatchNorm47 needs backward computation.
I0925 20:26:02.995909  3547 net.cpp:198] Convolution47 needs backward computation.
I0925 20:26:02.995913  3547 net.cpp:198] PReLU44 needs backward computation.
I0925 20:26:02.995914  3547 net.cpp:198] Scale46 needs backward computation.
I0925 20:26:02.995916  3547 net.cpp:198] BatchNorm46 needs backward computation.
I0925 20:26:02.995919  3547 net.cpp:198] Convolution46 needs backward computation.
I0925 20:26:02.995921  3547 net.cpp:198] Eltwise21_PReLU43_0_split needs backward computation.
I0925 20:26:02.995924  3547 net.cpp:198] PReLU43 needs backward computation.
I0925 20:26:03.025521  3547 net.cpp:198] Eltwise21 needs backward computation.
I0925 20:26:03.025534  3547 net.cpp:198] Scale45 needs backward computation.
I0925 20:26:03.025538  3547 net.cpp:198] BatchNorm45 needs backward computation.
I0925 20:26:03.025543  3547 net.cpp:198] Convolution45 needs backward computation.
I0925 20:26:03.025547  3547 net.cpp:198] PReLU42 needs backward computation.
I0925 20:26:03.025552  3547 net.cpp:198] Scale44 needs backward computation.
I0925 20:26:03.025557  3547 net.cpp:198] BatchNorm44 needs backward computation.
I0925 20:26:03.025560  3547 net.cpp:198] Convolution44 needs backward computation.
I0925 20:26:03.025565  3547 net.cpp:198] Eltwise20_PReLU41_0_split needs backward computation.
I0925 20:26:03.025569  3547 net.cpp:198] PReLU41 needs backward computation.
I0925 20:26:03.025574  3547 net.cpp:198] Eltwise20 needs backward computation.
I0925 20:26:03.025579  3547 net.cpp:198] Scale43 needs backward computation.
I0925 20:26:03.025583  3547 net.cpp:198] BatchNorm43 needs backward computation.
I0925 20:26:03.025586  3547 net.cpp:198] Convolution43 needs backward computation.
I0925 20:26:03.025591  3547 net.cpp:198] PReLU40 needs backward computation.
I0925 20:26:03.025594  3547 net.cpp:198] Scale42 needs backward computation.
I0925 20:26:03.025596  3547 net.cpp:198] BatchNorm42 needs backward computation.
I0925 20:26:03.025599  3547 net.cpp:198] Convolution42 needs backward computation.
I0925 20:26:03.025602  3547 net.cpp:198] Eltwise19_PReLU39_0_split needs backward computation.
I0925 20:26:03.025605  3547 net.cpp:198] PReLU39 needs backward computation.
I0925 20:26:03.025607  3547 net.cpp:198] Eltwise19 needs backward computation.
I0925 20:26:03.025610  3547 net.cpp:198] Scale41 needs backward computation.
I0925 20:26:03.025614  3547 net.cpp:198] BatchNorm41 needs backward computation.
I0925 20:26:03.025616  3547 net.cpp:198] Convolution41 needs backward computation.
I0925 20:26:03.025620  3547 net.cpp:198] PReLU38 needs backward computation.
I0925 20:26:03.025624  3547 net.cpp:198] Scale40 needs backward computation.
I0925 20:26:03.025627  3547 net.cpp:198] BatchNorm40 needs backward computation.
I0925 20:26:03.025629  3547 net.cpp:198] Convolution40 needs backward computation.
I0925 20:26:03.025632  3547 net.cpp:198] Scale39 needs backward computation.
I0925 20:26:03.025635  3547 net.cpp:198] BatchNorm39 needs backward computation.
I0925 20:26:03.025636  3547 net.cpp:198] Convolution39 needs backward computation.
I0925 20:26:03.025640  3547 net.cpp:198] Eltwise18_PReLU37_0_split needs backward computation.
I0925 20:26:03.025642  3547 net.cpp:198] PReLU37 needs backward computation.
I0925 20:26:03.025645  3547 net.cpp:198] Eltwise18 needs backward computation.
I0925 20:26:03.025648  3547 net.cpp:198] Scale38 needs backward computation.
I0925 20:26:03.025650  3547 net.cpp:198] BatchNorm38 needs backward computation.
I0925 20:26:03.025652  3547 net.cpp:198] Convolution38 needs backward computation.
I0925 20:26:03.025655  3547 net.cpp:198] PReLU36 needs backward computation.
I0925 20:26:03.025657  3547 net.cpp:198] Scale37 needs backward computation.
I0925 20:26:03.025660  3547 net.cpp:198] BatchNorm37 needs backward computation.
I0925 20:26:03.025662  3547 net.cpp:198] Convolution37 needs backward computation.
I0925 20:26:03.025665  3547 net.cpp:198] Eltwise17_PReLU35_0_split needs backward computation.
I0925 20:26:03.025676  3547 net.cpp:198] PReLU35 needs backward computation.
I0925 20:26:03.025678  3547 net.cpp:198] Eltwise17 needs backward computation.
I0925 20:26:03.025681  3547 net.cpp:198] Scale36 needs backward computation.
I0925 20:26:03.025683  3547 net.cpp:198] BatchNorm36 needs backward computation.
I0925 20:26:03.025686  3547 net.cpp:198] Convolution36 needs backward computation.
I0925 20:26:03.025688  3547 net.cpp:198] PReLU34 needs backward computation.
I0925 20:26:03.025691  3547 net.cpp:198] Scale35 needs backward computation.
I0925 20:26:03.025693  3547 net.cpp:198] BatchNorm35 needs backward computation.
I0925 20:26:03.025696  3547 net.cpp:198] Convolution35 needs backward computation.
I0925 20:26:03.025698  3547 net.cpp:198] Eltwise16_PReLU33_0_split needs backward computation.
I0925 20:26:03.025701  3547 net.cpp:198] PReLU33 needs backward computation.
I0925 20:26:03.025703  3547 net.cpp:198] Eltwise16 needs backward computation.
I0925 20:26:03.025707  3547 net.cpp:198] Scale34 needs backward computation.
I0925 20:26:03.025709  3547 net.cpp:198] BatchNorm34 needs backward computation.
I0925 20:26:03.025712  3547 net.cpp:198] Convolution34 needs backward computation.
I0925 20:26:03.025714  3547 net.cpp:198] PReLU32 needs backward computation.
I0925 20:26:03.025717  3547 net.cpp:198] Scale33 needs backward computation.
I0925 20:26:03.025718  3547 net.cpp:198] BatchNorm33 needs backward computation.
I0925 20:26:03.025722  3547 net.cpp:198] Convolution33 needs backward computation.
I0925 20:26:03.025723  3547 net.cpp:198] Eltwise15_PReLU31_0_split needs backward computation.
I0925 20:26:03.025727  3547 net.cpp:198] PReLU31 needs backward computation.
I0925 20:26:03.025729  3547 net.cpp:198] Eltwise15 needs backward computation.
I0925 20:26:03.025732  3547 net.cpp:198] Scale32 needs backward computation.
I0925 20:26:03.025734  3547 net.cpp:198] BatchNorm32 needs backward computation.
I0925 20:26:03.025737  3547 net.cpp:198] Convolution32 needs backward computation.
I0925 20:26:03.025738  3547 net.cpp:198] PReLU30 needs backward computation.
I0925 20:26:03.025741  3547 net.cpp:198] Scale31 needs backward computation.
I0925 20:26:03.025743  3547 net.cpp:198] BatchNorm31 needs backward computation.
I0925 20:26:03.025745  3547 net.cpp:198] Convolution31 needs backward computation.
I0925 20:26:03.025748  3547 net.cpp:198] Eltwise14_PReLU29_0_split needs backward computation.
I0925 20:26:03.025751  3547 net.cpp:198] PReLU29 needs backward computation.
I0925 20:26:03.025753  3547 net.cpp:198] Eltwise14 needs backward computation.
I0925 20:26:03.025756  3547 net.cpp:198] Scale30 needs backward computation.
I0925 20:26:03.025759  3547 net.cpp:198] BatchNorm30 needs backward computation.
I0925 20:26:03.025761  3547 net.cpp:198] Convolution30 needs backward computation.
I0925 20:26:03.025764  3547 net.cpp:198] PReLU28 needs backward computation.
I0925 20:26:03.025766  3547 net.cpp:198] Scale29 needs backward computation.
I0925 20:26:03.025768  3547 net.cpp:198] BatchNorm29 needs backward computation.
I0925 20:26:03.025771  3547 net.cpp:198] Convolution29 needs backward computation.
I0925 20:26:03.025774  3547 net.cpp:198] Eltwise13_PReLU27_0_split needs backward computation.
I0925 20:26:03.025776  3547 net.cpp:198] PReLU27 needs backward computation.
I0925 20:26:03.025779  3547 net.cpp:198] Eltwise13 needs backward computation.
I0925 20:26:03.025781  3547 net.cpp:198] Scale28 needs backward computation.
I0925 20:26:03.025784  3547 net.cpp:198] BatchNorm28 needs backward computation.
I0925 20:26:03.025786  3547 net.cpp:198] Convolution28 needs backward computation.
I0925 20:26:03.025789  3547 net.cpp:198] PReLU26 needs backward computation.
I0925 20:26:03.025791  3547 net.cpp:198] Scale27 needs backward computation.
I0925 20:26:03.025794  3547 net.cpp:198] BatchNorm27 needs backward computation.
I0925 20:26:03.025796  3547 net.cpp:198] Convolution27 needs backward computation.
I0925 20:26:03.025799  3547 net.cpp:198] Eltwise12_PReLU25_0_split needs backward computation.
I0925 20:26:03.025804  3547 net.cpp:198] PReLU25 needs backward computation.
I0925 20:26:03.025807  3547 net.cpp:198] Eltwise12 needs backward computation.
I0925 20:26:03.025810  3547 net.cpp:198] Scale26 needs backward computation.
I0925 20:26:03.025812  3547 net.cpp:198] BatchNorm26 needs backward computation.
I0925 20:26:03.025815  3547 net.cpp:198] Convolution26 needs backward computation.
I0925 20:26:03.025817  3547 net.cpp:198] PReLU24 needs backward computation.
I0925 20:26:03.025820  3547 net.cpp:198] Scale25 needs backward computation.
I0925 20:26:03.025822  3547 net.cpp:198] BatchNorm25 needs backward computation.
I0925 20:26:03.025825  3547 net.cpp:198] Convolution25 needs backward computation.
I0925 20:26:03.025827  3547 net.cpp:198] Eltwise11_PReLU23_0_split needs backward computation.
I0925 20:26:03.025830  3547 net.cpp:198] PReLU23 needs backward computation.
I0925 20:26:03.025832  3547 net.cpp:198] Eltwise11 needs backward computation.
I0925 20:26:03.025835  3547 net.cpp:198] Scale24 needs backward computation.
I0925 20:26:03.025837  3547 net.cpp:198] BatchNorm24 needs backward computation.
I0925 20:26:03.025840  3547 net.cpp:198] Convolution24 needs backward computation.
I0925 20:26:03.025842  3547 net.cpp:198] PReLU22 needs backward computation.
I0925 20:26:03.025846  3547 net.cpp:198] Scale23 needs backward computation.
I0925 20:26:03.025847  3547 net.cpp:198] BatchNorm23 needs backward computation.
I0925 20:26:03.025849  3547 net.cpp:198] Convolution23 needs backward computation.
I0925 20:26:03.025853  3547 net.cpp:198] Eltwise10_PReLU21_0_split needs backward computation.
I0925 20:26:03.025856  3547 net.cpp:198] PReLU21 needs backward computation.
I0925 20:26:03.025858  3547 net.cpp:198] Eltwise10 needs backward computation.
I0925 20:26:03.025861  3547 net.cpp:198] Scale22 needs backward computation.
I0925 20:26:03.025863  3547 net.cpp:198] BatchNorm22 needs backward computation.
I0925 20:26:03.025866  3547 net.cpp:198] Convolution22 needs backward computation.
I0925 20:26:03.025868  3547 net.cpp:198] PReLU20 needs backward computation.
I0925 20:26:03.025871  3547 net.cpp:198] Scale21 needs backward computation.
I0925 20:26:03.025873  3547 net.cpp:198] BatchNorm21 needs backward computation.
I0925 20:26:03.025876  3547 net.cpp:198] Convolution21 needs backward computation.
I0925 20:26:03.025878  3547 net.cpp:198] Scale20 needs backward computation.
I0925 20:26:03.025880  3547 net.cpp:198] BatchNorm20 needs backward computation.
I0925 20:26:03.025883  3547 net.cpp:198] Convolution20 needs backward computation.
I0925 20:26:03.025887  3547 net.cpp:198] Eltwise9_PReLU19_0_split needs backward computation.
I0925 20:26:03.025889  3547 net.cpp:198] PReLU19 needs backward computation.
I0925 20:26:03.025892  3547 net.cpp:198] Eltwise9 needs backward computation.
I0925 20:26:03.025894  3547 net.cpp:198] Scale19 needs backward computation.
I0925 20:26:03.025897  3547 net.cpp:198] BatchNorm19 needs backward computation.
I0925 20:26:03.025899  3547 net.cpp:198] Convolution19 needs backward computation.
I0925 20:26:03.025902  3547 net.cpp:198] PReLU18 needs backward computation.
I0925 20:26:03.025904  3547 net.cpp:198] Scale18 needs backward computation.
I0925 20:26:03.025907  3547 net.cpp:198] BatchNorm18 needs backward computation.
I0925 20:26:03.025909  3547 net.cpp:198] Convolution18 needs backward computation.
I0925 20:26:03.025912  3547 net.cpp:198] Eltwise8_PReLU17_0_split needs backward computation.
I0925 20:26:03.025914  3547 net.cpp:198] PReLU17 needs backward computation.
I0925 20:26:03.025916  3547 net.cpp:198] Eltwise8 needs backward computation.
I0925 20:26:03.025919  3547 net.cpp:198] Scale17 needs backward computation.
I0925 20:26:03.025923  3547 net.cpp:198] BatchNorm17 needs backward computation.
I0925 20:26:03.025924  3547 net.cpp:198] Convolution17 needs backward computation.
I0925 20:26:03.025928  3547 net.cpp:198] PReLU16 needs backward computation.
I0925 20:26:03.025929  3547 net.cpp:198] Scale16 needs backward computation.
I0925 20:26:03.025933  3547 net.cpp:198] BatchNorm16 needs backward computation.
I0925 20:26:03.025938  3547 net.cpp:198] Convolution16 needs backward computation.
I0925 20:26:03.025941  3547 net.cpp:198] Eltwise7_PReLU15_0_split needs backward computation.
I0925 20:26:03.025943  3547 net.cpp:198] PReLU15 needs backward computation.
I0925 20:26:03.025946  3547 net.cpp:198] Eltwise7 needs backward computation.
I0925 20:26:03.025949  3547 net.cpp:198] Scale15 needs backward computation.
I0925 20:26:03.025951  3547 net.cpp:198] BatchNorm15 needs backward computation.
I0925 20:26:03.025954  3547 net.cpp:198] Convolution15 needs backward computation.
I0925 20:26:03.025956  3547 net.cpp:198] PReLU14 needs backward computation.
I0925 20:26:03.025959  3547 net.cpp:198] Scale14 needs backward computation.
I0925 20:26:03.025961  3547 net.cpp:198] BatchNorm14 needs backward computation.
I0925 20:26:03.025964  3547 net.cpp:198] Convolution14 needs backward computation.
I0925 20:26:03.025966  3547 net.cpp:198] Eltwise6_PReLU13_0_split needs backward computation.
I0925 20:26:03.025969  3547 net.cpp:198] PReLU13 needs backward computation.
I0925 20:26:03.025971  3547 net.cpp:198] Eltwise6 needs backward computation.
I0925 20:26:03.025974  3547 net.cpp:198] Scale13 needs backward computation.
I0925 20:26:03.025976  3547 net.cpp:198] BatchNorm13 needs backward computation.
I0925 20:26:03.025979  3547 net.cpp:198] Convolution13 needs backward computation.
I0925 20:26:03.025981  3547 net.cpp:198] PReLU12 needs backward computation.
I0925 20:26:03.025985  3547 net.cpp:198] Scale12 needs backward computation.
I0925 20:26:03.025986  3547 net.cpp:198] BatchNorm12 needs backward computation.
I0925 20:26:03.025990  3547 net.cpp:198] Convolution12 needs backward computation.
I0925 20:26:03.025991  3547 net.cpp:198] Eltwise5_PReLU11_0_split needs backward computation.
I0925 20:26:03.025995  3547 net.cpp:198] PReLU11 needs backward computation.
I0925 20:26:03.025996  3547 net.cpp:198] Eltwise5 needs backward computation.
I0925 20:26:03.026000  3547 net.cpp:198] Scale11 needs backward computation.
I0925 20:26:03.026002  3547 net.cpp:198] BatchNorm11 needs backward computation.
I0925 20:26:03.026005  3547 net.cpp:198] Convolution11 needs backward computation.
I0925 20:26:03.026007  3547 net.cpp:198] PReLU10 needs backward computation.
I0925 20:26:03.026010  3547 net.cpp:198] Scale10 needs backward computation.
I0925 20:26:03.026012  3547 net.cpp:198] BatchNorm10 needs backward computation.
I0925 20:26:03.026015  3547 net.cpp:198] Convolution10 needs backward computation.
I0925 20:26:03.026017  3547 net.cpp:198] Eltwise4_PReLU9_0_split needs backward computation.
I0925 20:26:03.026020  3547 net.cpp:198] PReLU9 needs backward computation.
I0925 20:26:03.026022  3547 net.cpp:198] Eltwise4 needs backward computation.
I0925 20:26:03.026026  3547 net.cpp:198] Scale9 needs backward computation.
I0925 20:26:03.026029  3547 net.cpp:198] BatchNorm9 needs backward computation.
I0925 20:26:03.026031  3547 net.cpp:198] Convolution9 needs backward computation.
I0925 20:26:03.026034  3547 net.cpp:198] PReLU8 needs backward computation.
I0925 20:26:03.026037  3547 net.cpp:198] Scale8 needs backward computation.
I0925 20:26:03.026039  3547 net.cpp:198] BatchNorm8 needs backward computation.
I0925 20:26:03.026042  3547 net.cpp:198] Convolution8 needs backward computation.
I0925 20:26:03.026046  3547 net.cpp:198] Eltwise3_PReLU7_0_split needs backward computation.
I0925 20:26:03.026047  3547 net.cpp:198] PReLU7 needs backward computation.
I0925 20:26:03.026051  3547 net.cpp:198] Eltwise3 needs backward computation.
I0925 20:26:03.026053  3547 net.cpp:198] Scale7 needs backward computation.
I0925 20:26:03.026057  3547 net.cpp:198] BatchNorm7 needs backward computation.
I0925 20:26:03.026058  3547 net.cpp:198] Convolution7 needs backward computation.
I0925 20:26:03.026062  3547 net.cpp:198] PReLU6 needs backward computation.
I0925 20:26:03.026063  3547 net.cpp:198] Scale6 needs backward computation.
I0925 20:26:03.026065  3547 net.cpp:198] BatchNorm6 needs backward computation.
I0925 20:26:03.026067  3547 net.cpp:198] Convolution6 needs backward computation.
I0925 20:26:03.026074  3547 net.cpp:198] Eltwise2_PReLU5_0_split needs backward computation.
I0925 20:26:03.026077  3547 net.cpp:198] PReLU5 needs backward computation.
I0925 20:26:03.026079  3547 net.cpp:198] Eltwise2 needs backward computation.
I0925 20:26:03.026082  3547 net.cpp:198] Scale5 needs backward computation.
I0925 20:26:03.026085  3547 net.cpp:198] BatchNorm5 needs backward computation.
I0925 20:26:03.026087  3547 net.cpp:198] Convolution5 needs backward computation.
I0925 20:26:03.027595  3547 net.cpp:198] PReLU4 needs backward computation.
I0925 20:26:03.027602  3547 net.cpp:198] Scale4 needs backward computation.
I0925 20:26:03.027606  3547 net.cpp:198] BatchNorm4 needs backward computation.
I0925 20:26:03.027607  3547 net.cpp:198] Convolution4 needs backward computation.
I0925 20:26:03.027611  3547 net.cpp:198] Eltwise1_PReLU3_0_split needs backward computation.
I0925 20:26:03.027614  3547 net.cpp:198] PReLU3 needs backward computation.
I0925 20:26:03.027616  3547 net.cpp:198] Eltwise1 needs backward computation.
I0925 20:26:03.027619  3547 net.cpp:198] Scale3 needs backward computation.
I0925 20:26:03.027622  3547 net.cpp:198] BatchNorm3 needs backward computation.
I0925 20:26:03.027624  3547 net.cpp:198] Convolution3 needs backward computation.
I0925 20:26:03.027626  3547 net.cpp:198] PReLU2 needs backward computation.
I0925 20:26:03.027629  3547 net.cpp:198] Scale2 needs backward computation.
I0925 20:26:03.027631  3547 net.cpp:198] BatchNorm2 needs backward computation.
I0925 20:26:03.027634  3547 net.cpp:198] Convolution2 needs backward computation.
I0925 20:26:03.027637  3547 net.cpp:198] Convolution1_PReLU1_0_split needs backward computation.
I0925 20:26:03.027639  3547 net.cpp:198] PReLU1 needs backward computation.
I0925 20:26:03.027642  3547 net.cpp:198] Scale1 needs backward computation.
I0925 20:26:03.027644  3547 net.cpp:198] BatchNorm1 needs backward computation.
I0925 20:26:03.027647  3547 net.cpp:198] Convolution1 needs backward computation.
I0925 20:26:03.027650  3547 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0925 20:26:03.027653  3547 net.cpp:200] Data1 does not need backward computation.
I0925 20:26:03.027655  3547 net.cpp:242] This network produces output Accuracy1
I0925 20:26:03.027658  3547 net.cpp:242] This network produces output SoftmaxWithLoss1
I0925 20:26:03.027755  3547 net.cpp:255] Network initialization done.
I0925 20:26:03.028427  3547 solver.cpp:56] Solver scaffolding done.
I0925 20:26:03.040151  3547 caffe.cpp:248] Starting Optimization
I0925 20:26:03.040158  3547 solver.cpp:272] Solving resnet_cifar10
I0925 20:26:03.040160  3547 solver.cpp:273] Learning Rate Policy: multistep
I0925 20:26:03.045573  3547 solver.cpp:330] Iteration 0, Testing net (#0)
I0925 20:26:06.449697  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:26:06.587976  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0925 20:26:06.588013  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0925 20:26:06.782126  3547 solver.cpp:218] Iteration 0 (-3.68885e-33 iter/s, 3.74187s/100 iters), loss = 2.31775
I0925 20:26:06.782156  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.31775 (* 1 = 2.31775 loss)
I0925 20:26:06.782171  3547 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0925 20:26:20.712579  3547 solver.cpp:218] Iteration 100 (7.17859 iter/s, 13.9303s/100 iters), loss = 1.88237
I0925 20:26:20.712611  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.88237 (* 1 = 1.88237 loss)
I0925 20:26:20.712628  3547 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0925 20:26:34.620568  3547 solver.cpp:218] Iteration 200 (7.19019 iter/s, 13.9078s/100 iters), loss = 1.84725
I0925 20:26:34.620654  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.84725 (* 1 = 1.84725 loss)
I0925 20:26:34.620662  3547 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0925 20:26:48.646036  3547 solver.cpp:218] Iteration 300 (7.12999 iter/s, 14.0253s/100 iters), loss = 1.56631
I0925 20:26:48.646066  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.56631 (* 1 = 1.56631 loss)
I0925 20:26:48.646072  3547 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0925 20:27:02.685516  3547 solver.cpp:218] Iteration 400 (7.12284 iter/s, 14.0393s/100 iters), loss = 1.51302
I0925 20:27:02.685549  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.51302 (* 1 = 1.51302 loss)
I0925 20:27:02.685556  3547 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0925 20:27:16.054414  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:27:16.630128  3547 solver.cpp:330] Iteration 500, Testing net (#0)
I0925 20:27:20.006316  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:27:20.144620  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1279
I0925 20:27:20.144655  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.74946 (* 1 = 3.74946 loss)
I0925 20:27:20.283079  3547 solver.cpp:218] Iteration 500 (5.68266 iter/s, 17.5974s/100 iters), loss = 1.60778
I0925 20:27:20.283108  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.60778 (* 1 = 1.60778 loss)
I0925 20:27:20.283114  3547 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0925 20:27:34.310039  3547 solver.cpp:218] Iteration 600 (7.1292 iter/s, 14.0268s/100 iters), loss = 1.40617
I0925 20:27:34.310073  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.40617 (* 1 = 1.40617 loss)
I0925 20:27:34.310081  3547 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0925 20:27:48.316452  3547 solver.cpp:218] Iteration 700 (7.13968 iter/s, 14.0062s/100 iters), loss = 1.26312
I0925 20:27:48.316562  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.26312 (* 1 = 1.26312 loss)
I0925 20:27:48.316570  3547 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0925 20:28:02.298671  3547 solver.cpp:218] Iteration 800 (7.15205 iter/s, 13.982s/100 iters), loss = 1.10663
I0925 20:28:02.298705  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10663 (* 1 = 1.10663 loss)
I0925 20:28:02.298712  3547 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0925 20:28:16.363381  3547 solver.cpp:218] Iteration 900 (7.11006 iter/s, 14.0646s/100 iters), loss = 0.901098
I0925 20:28:16.363415  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.901098 (* 1 = 0.901098 loss)
I0925 20:28:16.363420  3547 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0925 20:28:29.820456  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:28:30.380969  3547 solver.cpp:330] Iteration 1000, Testing net (#0)
I0925 20:28:33.731662  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:28:33.869575  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1805
I0925 20:28:33.869611  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.08786 (* 1 = 5.08786 loss)
I0925 20:28:34.007977  3547 solver.cpp:218] Iteration 1000 (5.6675 iter/s, 17.6445s/100 iters), loss = 1.07185
I0925 20:28:34.008010  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.07185 (* 1 = 1.07185 loss)
I0925 20:28:34.008028  3547 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0925 20:28:48.166098  3547 solver.cpp:218] Iteration 1100 (7.06314 iter/s, 14.158s/100 iters), loss = 0.973265
I0925 20:28:48.166131  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.973265 (* 1 = 0.973265 loss)
I0925 20:28:48.166136  3547 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0925 20:29:02.294447  3547 solver.cpp:218] Iteration 1200 (7.07802 iter/s, 14.1282s/100 iters), loss = 0.93894
I0925 20:29:02.294544  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.93894 (* 1 = 0.93894 loss)
I0925 20:29:02.294562  3547 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0925 20:29:16.404032  3547 solver.cpp:218] Iteration 1300 (7.08747 iter/s, 14.1094s/100 iters), loss = 0.844549
I0925 20:29:16.404064  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.844549 (* 1 = 0.844549 loss)
I0925 20:29:16.404081  3547 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0925 20:29:30.539858  3547 solver.cpp:218] Iteration 1400 (7.07427 iter/s, 14.1357s/100 iters), loss = 0.75716
I0925 20:29:30.539890  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.75716 (* 1 = 0.75716 loss)
I0925 20:29:30.539896  3547 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0925 20:29:43.975236  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:29:44.545303  3547 solver.cpp:330] Iteration 1500, Testing net (#0)
I0925 20:29:47.893368  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:29:48.031577  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2823
I0925 20:29:48.031612  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.65948 (* 1 = 3.65948 loss)
I0925 20:29:48.169862  3547 solver.cpp:218] Iteration 1500 (5.67218 iter/s, 17.6299s/100 iters), loss = 0.903879
I0925 20:29:48.169889  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.903879 (* 1 = 0.903879 loss)
I0925 20:29:48.169896  3547 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0925 20:30:02.272264  3547 solver.cpp:218] Iteration 1600 (7.09104 iter/s, 14.1023s/100 iters), loss = 0.705435
I0925 20:30:02.272300  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.705435 (* 1 = 0.705435 loss)
I0925 20:30:02.272307  3547 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0925 20:30:16.393651  3547 solver.cpp:218] Iteration 1700 (7.08151 iter/s, 14.1213s/100 iters), loss = 0.697597
I0925 20:30:16.393795  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.697597 (* 1 = 0.697597 loss)
I0925 20:30:16.393805  3547 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0925 20:30:30.540436  3547 solver.cpp:218] Iteration 1800 (7.06885 iter/s, 14.1466s/100 iters), loss = 0.754877
I0925 20:30:30.540482  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.754877 (* 1 = 0.754877 loss)
I0925 20:30:30.540489  3547 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0925 20:30:44.689579  3547 solver.cpp:218] Iteration 1900 (7.06762 iter/s, 14.149s/100 iters), loss = 0.664395
I0925 20:30:44.689611  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.664395 (* 1 = 0.664395 loss)
I0925 20:30:44.689618  3547 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0925 20:30:58.072692  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:30:58.635888  3547 solver.cpp:330] Iteration 2000, Testing net (#0)
I0925 20:31:02.022521  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:31:02.161850  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3775
I0925 20:31:02.161888  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.34194 (* 1 = 2.34194 loss)
I0925 20:31:02.304927  3547 solver.cpp:218] Iteration 2000 (5.6769 iter/s, 17.6152s/100 iters), loss = 0.75489
I0925 20:31:02.304960  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.75489 (* 1 = 0.75489 loss)
I0925 20:31:02.304968  3547 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0925 20:31:16.444241  3547 solver.cpp:218] Iteration 2100 (7.07253 iter/s, 14.1392s/100 iters), loss = 0.577107
I0925 20:31:16.444278  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577107 (* 1 = 0.577107 loss)
I0925 20:31:16.444288  3547 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0925 20:31:30.535825  3547 solver.cpp:218] Iteration 2200 (7.09648 iter/s, 14.0915s/100 iters), loss = 0.632699
I0925 20:31:30.535941  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.632699 (* 1 = 0.632699 loss)
I0925 20:31:30.535964  3547 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0925 20:31:44.622619  3547 solver.cpp:218] Iteration 2300 (7.09893 iter/s, 14.0866s/100 iters), loss = 0.612354
I0925 20:31:44.622651  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.612354 (* 1 = 0.612354 loss)
I0925 20:31:44.622658  3547 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0925 20:31:58.802130  3547 solver.cpp:218] Iteration 2400 (7.05247 iter/s, 14.1794s/100 iters), loss = 0.576873
I0925 20:31:58.802163  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.576873 (* 1 = 0.576873 loss)
I0925 20:31:58.802170  3547 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0925 20:32:12.227943  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:32:12.793815  3547 solver.cpp:330] Iteration 2500, Testing net (#0)
I0925 20:32:16.185320  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:32:16.325800  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4772
I0925 20:32:16.325826  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.64448 (* 1 = 1.64448 loss)
I0925 20:32:16.464457  3547 solver.cpp:218] Iteration 2500 (5.6618 iter/s, 17.6622s/100 iters), loss = 0.700638
I0925 20:32:16.464483  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.700638 (* 1 = 0.700638 loss)
I0925 20:32:16.464490  3547 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0925 20:32:30.518404  3547 solver.cpp:218] Iteration 2600 (7.11548 iter/s, 14.0539s/100 iters), loss = 0.463429
I0925 20:32:30.518437  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463429 (* 1 = 0.463429 loss)
I0925 20:32:30.518445  3547 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0925 20:32:44.657384  3547 solver.cpp:218] Iteration 2700 (7.07269 iter/s, 14.1389s/100 iters), loss = 0.535669
I0925 20:32:44.657526  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535669 (* 1 = 0.535669 loss)
I0925 20:32:44.657552  3547 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0925 20:32:58.798900  3547 solver.cpp:218] Iteration 2800 (7.07147 iter/s, 14.1413s/100 iters), loss = 0.602895
I0925 20:32:58.798934  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.602895 (* 1 = 0.602895 loss)
I0925 20:32:58.798954  3547 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0925 20:33:12.939236  3547 solver.cpp:218] Iteration 2900 (7.07201 iter/s, 14.1402s/100 iters), loss = 0.496827
I0925 20:33:12.939270  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.496827 (* 1 = 0.496827 loss)
I0925 20:33:12.939277  3547 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0925 20:33:26.425560  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:33:26.993929  3547 solver.cpp:330] Iteration 3000, Testing net (#0)
I0925 20:33:30.366394  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:33:30.505036  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6895
I0925 20:33:30.505060  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.905226 (* 1 = 0.905226 loss)
I0925 20:33:30.645690  3547 solver.cpp:218] Iteration 3000 (5.64769 iter/s, 17.7064s/100 iters), loss = 0.628782
I0925 20:33:30.645725  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.628782 (* 1 = 0.628782 loss)
I0925 20:33:30.645732  3547 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0925 20:33:44.781977  3547 solver.cpp:218] Iteration 3100 (7.07404 iter/s, 14.1362s/100 iters), loss = 0.488147
I0925 20:33:44.782013  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488147 (* 1 = 0.488147 loss)
I0925 20:33:44.782021  3547 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0925 20:33:58.973893  3547 solver.cpp:218] Iteration 3200 (7.04631 iter/s, 14.1918s/100 iters), loss = 0.55277
I0925 20:33:58.973996  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.55277 (* 1 = 0.55277 loss)
I0925 20:33:58.974004  3547 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0925 20:34:13.039271  3547 solver.cpp:218] Iteration 3300 (7.10973 iter/s, 14.0652s/100 iters), loss = 0.57534
I0925 20:34:13.039301  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.57534 (* 1 = 0.57534 loss)
I0925 20:34:13.039307  3547 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0925 20:34:27.080000  3547 solver.cpp:218] Iteration 3400 (7.12218 iter/s, 14.0406s/100 iters), loss = 0.498586
I0925 20:34:27.080030  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498586 (* 1 = 0.498586 loss)
I0925 20:34:27.080036  3547 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0925 20:34:40.487951  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:34:41.046902  3547 solver.cpp:330] Iteration 3500, Testing net (#0)
I0925 20:34:44.370544  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:34:44.509111  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6455
I0925 20:34:44.509146  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03793 (* 1 = 1.03793 loss)
I0925 20:34:44.647028  3547 solver.cpp:218] Iteration 3500 (5.69251 iter/s, 17.5669s/100 iters), loss = 0.433385
I0925 20:34:44.647060  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433385 (* 1 = 0.433385 loss)
I0925 20:34:44.647068  3547 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0925 20:34:58.842607  3547 solver.cpp:218] Iteration 3600 (7.04449 iter/s, 14.1955s/100 iters), loss = 0.445079
I0925 20:34:58.842640  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445079 (* 1 = 0.445079 loss)
I0925 20:34:58.842648  3547 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0925 20:35:12.908584  3547 solver.cpp:218] Iteration 3700 (7.1094 iter/s, 14.0659s/100 iters), loss = 0.526135
I0925 20:35:12.908704  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.526135 (* 1 = 0.526135 loss)
I0925 20:35:12.908715  3547 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0925 20:35:26.942126  3547 solver.cpp:218] Iteration 3800 (7.12587 iter/s, 14.0334s/100 iters), loss = 0.575883
I0925 20:35:26.942174  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.575883 (* 1 = 0.575883 loss)
I0925 20:35:26.942183  3547 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0925 20:35:41.075315  3547 solver.cpp:218] Iteration 3900 (7.07559 iter/s, 14.1331s/100 iters), loss = 0.523915
I0925 20:35:41.075361  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.523915 (* 1 = 0.523915 loss)
I0925 20:35:41.075369  3547 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0925 20:35:54.465111  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:35:55.027087  3547 solver.cpp:330] Iteration 4000, Testing net (#0)
I0925 20:35:58.353766  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:35:58.493388  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6517
I0925 20:35:58.493427  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00673 (* 1 = 1.00673 loss)
I0925 20:35:58.632230  3547 solver.cpp:218] Iteration 4000 (5.6958 iter/s, 17.5568s/100 iters), loss = 0.458681
I0925 20:35:58.632274  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.458681 (* 1 = 0.458681 loss)
I0925 20:35:58.632282  3547 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0925 20:36:12.670424  3547 solver.cpp:218] Iteration 4100 (7.12347 iter/s, 14.0381s/100 iters), loss = 0.351411
I0925 20:36:12.670471  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351411 (* 1 = 0.351411 loss)
I0925 20:36:12.670478  3547 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0925 20:36:26.680349  3547 solver.cpp:218] Iteration 4200 (7.13785 iter/s, 14.0098s/100 iters), loss = 0.474635
I0925 20:36:26.680456  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474635 (* 1 = 0.474635 loss)
I0925 20:36:26.680464  3547 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0925 20:36:40.733242  3547 solver.cpp:218] Iteration 4300 (7.11605 iter/s, 14.0527s/100 iters), loss = 0.430699
I0925 20:36:40.733278  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430699 (* 1 = 0.430699 loss)
I0925 20:36:40.733286  3547 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0925 20:36:54.755769  3547 solver.cpp:218] Iteration 4400 (7.13143 iter/s, 14.0224s/100 iters), loss = 0.421532
I0925 20:36:54.755813  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421532 (* 1 = 0.421532 loss)
I0925 20:36:54.755821  3547 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0925 20:37:08.060609  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:37:08.476541  3547 blocking_queue.cpp:49] Waiting for data
I0925 20:37:09.406149  3547 solver.cpp:330] Iteration 4500, Testing net (#0)
I0925 20:37:12.747434  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:37:12.887032  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7033
I0925 20:37:12.887080  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.831311 (* 1 = 0.831311 loss)
I0925 20:37:13.026118  3547 solver.cpp:218] Iteration 4500 (5.47338 iter/s, 18.2702s/100 iters), loss = 0.354302
I0925 20:37:13.026150  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354302 (* 1 = 0.354302 loss)
I0925 20:37:13.026159  3547 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0925 20:37:27.063580  3547 solver.cpp:218] Iteration 4600 (7.12384 iter/s, 14.0374s/100 iters), loss = 0.35479
I0925 20:37:27.063617  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35479 (* 1 = 0.35479 loss)
I0925 20:37:27.063635  3547 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0925 20:37:41.072366  3547 solver.cpp:218] Iteration 4700 (7.13842 iter/s, 14.0087s/100 iters), loss = 0.388413
I0925 20:37:41.072471  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388413 (* 1 = 0.388413 loss)
I0925 20:37:41.072479  3547 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0925 20:37:55.106472  3547 solver.cpp:218] Iteration 4800 (7.12558 iter/s, 14.0339s/100 iters), loss = 0.489111
I0925 20:37:55.106508  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489111 (* 1 = 0.489111 loss)
I0925 20:37:55.106515  3547 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0925 20:38:09.128072  3547 solver.cpp:218] Iteration 4900 (7.1319 iter/s, 14.0215s/100 iters), loss = 0.326278
I0925 20:38:09.128108  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326278 (* 1 = 0.326278 loss)
I0925 20:38:09.128114  3547 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0925 20:38:22.436033  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:38:22.998955  3547 solver.cpp:330] Iteration 5000, Testing net (#0)
I0925 20:38:26.335763  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:38:26.475039  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7138
I0925 20:38:26.475086  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.805071 (* 1 = 0.805071 loss)
I0925 20:38:26.614728  3547 solver.cpp:218] Iteration 5000 (5.71868 iter/s, 17.4866s/100 iters), loss = 0.362211
I0925 20:38:26.614773  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362211 (* 1 = 0.362211 loss)
I0925 20:38:26.614780  3547 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0925 20:38:40.640691  3547 solver.cpp:218] Iteration 5100 (7.12968 iter/s, 14.0259s/100 iters), loss = 0.292136
I0925 20:38:40.640723  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292136 (* 1 = 0.292136 loss)
I0925 20:38:40.640730  3547 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0925 20:38:54.634387  3547 solver.cpp:218] Iteration 5200 (7.14612 iter/s, 13.9936s/100 iters), loss = 0.342232
I0925 20:38:54.634495  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342232 (* 1 = 0.342232 loss)
I0925 20:38:54.634505  3547 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0925 20:39:08.658244  3547 solver.cpp:218] Iteration 5300 (7.13079 iter/s, 14.0237s/100 iters), loss = 0.412705
I0925 20:39:08.658291  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412705 (* 1 = 0.412705 loss)
I0925 20:39:08.658299  3547 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0925 20:39:22.672097  3547 solver.cpp:218] Iteration 5400 (7.13584 iter/s, 14.0138s/100 iters), loss = 0.304785
I0925 20:39:22.672127  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304785 (* 1 = 0.304785 loss)
I0925 20:39:22.672133  3547 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0925 20:39:36.002161  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:39:36.562945  3547 solver.cpp:330] Iteration 5500, Testing net (#0)
I0925 20:39:39.899588  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:39:40.037734  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7556
I0925 20:39:40.037757  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.713342 (* 1 = 0.713342 loss)
I0925 20:39:40.176882  3547 solver.cpp:218] Iteration 5500 (5.71275 iter/s, 17.5047s/100 iters), loss = 0.276497
I0925 20:39:40.176915  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276497 (* 1 = 0.276497 loss)
I0925 20:39:40.176923  3547 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0925 20:39:54.183537  3547 solver.cpp:218] Iteration 5600 (7.13951 iter/s, 14.0066s/100 iters), loss = 0.319414
I0925 20:39:54.183583  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319414 (* 1 = 0.319414 loss)
I0925 20:39:54.183593  3547 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0925 20:40:08.204058  3547 solver.cpp:218] Iteration 5700 (7.13245 iter/s, 14.0204s/100 iters), loss = 0.360472
I0925 20:40:08.204181  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360472 (* 1 = 0.360472 loss)
I0925 20:40:08.204200  3547 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0925 20:40:22.216576  3547 solver.cpp:218] Iteration 5800 (7.13656 iter/s, 14.0123s/100 iters), loss = 0.361052
I0925 20:40:22.216606  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361052 (* 1 = 0.361052 loss)
I0925 20:40:22.216612  3547 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0925 20:40:36.226862  3547 solver.cpp:218] Iteration 5900 (7.13765 iter/s, 14.0102s/100 iters), loss = 0.286384
I0925 20:40:36.226899  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286384 (* 1 = 0.286384 loss)
I0925 20:40:36.226907  3547 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0925 20:40:49.549048  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:40:50.108865  3547 solver.cpp:330] Iteration 6000, Testing net (#0)
I0925 20:40:53.445617  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:40:53.585649  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7557
I0925 20:40:53.585678  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698411 (* 1 = 0.698411 loss)
I0925 20:40:53.724831  3547 solver.cpp:218] Iteration 6000 (5.71498 iter/s, 17.4979s/100 iters), loss = 0.312328
I0925 20:40:53.724865  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312328 (* 1 = 0.312328 loss)
I0925 20:40:53.724884  3547 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0925 20:41:07.751246  3547 solver.cpp:218] Iteration 6100 (7.12945 iter/s, 14.0263s/100 iters), loss = 0.33156
I0925 20:41:07.751281  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33156 (* 1 = 0.33156 loss)
I0925 20:41:07.751298  3547 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0925 20:41:21.766216  3547 solver.cpp:218] Iteration 6200 (7.13527 iter/s, 14.0149s/100 iters), loss = 0.352794
I0925 20:41:21.766332  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352794 (* 1 = 0.352794 loss)
I0925 20:41:21.766340  3547 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0925 20:41:35.810961  3547 solver.cpp:218] Iteration 6300 (7.12018 iter/s, 14.0446s/100 iters), loss = 0.495916
I0925 20:41:35.810997  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.495916 (* 1 = 0.495916 loss)
I0925 20:41:35.811013  3547 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0925 20:41:49.837116  3547 solver.cpp:218] Iteration 6400 (7.12958 iter/s, 14.0261s/100 iters), loss = 0.307423
I0925 20:41:49.837152  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307423 (* 1 = 0.307423 loss)
I0925 20:41:49.837159  3547 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0925 20:42:03.184310  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:42:03.744681  3547 solver.cpp:330] Iteration 6500, Testing net (#0)
I0925 20:42:07.080514  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:42:07.220827  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7352
I0925 20:42:07.220867  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.792483 (* 1 = 0.792483 loss)
I0925 20:42:07.359792  3547 solver.cpp:218] Iteration 6500 (5.70692 iter/s, 17.5226s/100 iters), loss = 0.21938
I0925 20:42:07.359848  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21938 (* 1 = 0.21938 loss)
I0925 20:42:07.359865  3547 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0925 20:42:21.411396  3547 solver.cpp:218] Iteration 6600 (7.11668 iter/s, 14.0515s/100 iters), loss = 0.372784
I0925 20:42:21.411437  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372784 (* 1 = 0.372784 loss)
I0925 20:42:21.411442  3547 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0925 20:42:35.387045  3547 solver.cpp:218] Iteration 6700 (7.15535 iter/s, 13.9756s/100 iters), loss = 0.325127
I0925 20:42:35.387151  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325127 (* 1 = 0.325127 loss)
I0925 20:42:35.387158  3547 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0925 20:42:49.352902  3547 solver.cpp:218] Iteration 6800 (7.1604 iter/s, 13.9657s/100 iters), loss = 0.38702
I0925 20:42:49.352942  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38702 (* 1 = 0.38702 loss)
I0925 20:42:49.352949  3547 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0925 20:43:03.319854  3547 solver.cpp:218] Iteration 6900 (7.1598 iter/s, 13.9669s/100 iters), loss = 0.306393
I0925 20:43:03.319892  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306393 (* 1 = 0.306393 loss)
I0925 20:43:03.319898  3547 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0925 20:43:16.588412  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:43:17.146981  3547 solver.cpp:330] Iteration 7000, Testing net (#0)
I0925 20:43:20.470460  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:43:20.609000  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7114
I0925 20:43:20.609025  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.861371 (* 1 = 0.861371 loss)
I0925 20:43:20.747515  3547 solver.cpp:218] Iteration 7000 (5.73804 iter/s, 17.4276s/100 iters), loss = 0.314441
I0925 20:43:20.747546  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314441 (* 1 = 0.314441 loss)
I0925 20:43:20.747553  3547 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0925 20:43:34.702600  3547 solver.cpp:218] Iteration 7100 (7.16589 iter/s, 13.955s/100 iters), loss = 0.270874
I0925 20:43:34.702641  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270874 (* 1 = 0.270874 loss)
I0925 20:43:34.702647  3547 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0925 20:43:48.667697  3547 solver.cpp:218] Iteration 7200 (7.16076 iter/s, 13.965s/100 iters), loss = 0.319199
I0925 20:43:48.667826  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3192 (* 1 = 0.3192 loss)
I0925 20:43:48.667834  3547 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0925 20:44:02.623585  3547 solver.cpp:218] Iteration 7300 (7.16552 iter/s, 13.9557s/100 iters), loss = 0.298342
I0925 20:44:02.623615  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298342 (* 1 = 0.298342 loss)
I0925 20:44:02.623620  3547 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0925 20:44:16.581807  3547 solver.cpp:218] Iteration 7400 (7.16428 iter/s, 13.9581s/100 iters), loss = 0.37747
I0925 20:44:16.581847  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377471 (* 1 = 0.377471 loss)
I0925 20:44:16.581853  3547 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0925 20:44:29.845888  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:44:30.404579  3547 solver.cpp:330] Iteration 7500, Testing net (#0)
I0925 20:44:33.730237  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:44:33.868290  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7505
I0925 20:44:33.868326  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.693382 (* 1 = 0.693382 loss)
I0925 20:44:34.006429  3547 solver.cpp:218] Iteration 7500 (5.73904 iter/s, 17.4245s/100 iters), loss = 0.265874
I0925 20:44:34.006458  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265874 (* 1 = 0.265874 loss)
I0925 20:44:34.006465  3547 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0925 20:44:47.940490  3547 solver.cpp:218] Iteration 7600 (7.1767 iter/s, 13.934s/100 iters), loss = 0.284763
I0925 20:44:47.940523  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284763 (* 1 = 0.284763 loss)
I0925 20:44:47.940529  3547 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0925 20:45:01.886492  3547 solver.cpp:218] Iteration 7700 (7.17055 iter/s, 13.9459s/100 iters), loss = 0.21886
I0925 20:45:01.886648  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21886 (* 1 = 0.21886 loss)
I0925 20:45:01.886670  3547 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0925 20:45:15.833029  3547 solver.cpp:218] Iteration 7800 (7.17034 iter/s, 13.9463s/100 iters), loss = 0.382904
I0925 20:45:15.833068  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382904 (* 1 = 0.382904 loss)
I0925 20:45:15.833076  3547 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0925 20:45:29.779389  3547 solver.cpp:218] Iteration 7900 (7.17037 iter/s, 13.9463s/100 iters), loss = 0.293767
I0925 20:45:29.779429  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293767 (* 1 = 0.293767 loss)
I0925 20:45:29.779435  3547 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0925 20:45:43.031318  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:45:43.588695  3547 solver.cpp:330] Iteration 8000, Testing net (#0)
I0925 20:45:46.911181  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:45:47.049998  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7026
I0925 20:45:47.050034  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.902492 (* 1 = 0.902492 loss)
I0925 20:45:47.187810  3547 solver.cpp:218] Iteration 8000 (5.74438 iter/s, 17.4083s/100 iters), loss = 0.296672
I0925 20:45:47.187839  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296672 (* 1 = 0.296672 loss)
I0925 20:45:47.187845  3547 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0925 20:46:01.131734  3547 solver.cpp:218] Iteration 8100 (7.17162 iter/s, 13.9438s/100 iters), loss = 0.183078
I0925 20:46:01.131774  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183078 (* 1 = 0.183078 loss)
I0925 20:46:01.131779  3547 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0925 20:46:15.074506  3547 solver.cpp:218] Iteration 8200 (7.17222 iter/s, 13.9427s/100 iters), loss = 0.351538
I0925 20:46:15.074625  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351539 (* 1 = 0.351539 loss)
I0925 20:46:15.074643  3547 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0925 20:46:29.024680  3547 solver.cpp:218] Iteration 8300 (7.16845 iter/s, 13.95s/100 iters), loss = 0.244641
I0925 20:46:29.024710  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244641 (* 1 = 0.244641 loss)
I0925 20:46:29.024716  3547 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0925 20:46:42.963600  3547 solver.cpp:218] Iteration 8400 (7.1742 iter/s, 13.9388s/100 iters), loss = 0.356482
I0925 20:46:42.963640  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356482 (* 1 = 0.356482 loss)
I0925 20:46:42.963647  3547 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0925 20:46:56.225200  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:46:56.781195  3547 solver.cpp:330] Iteration 8500, Testing net (#0)
I0925 20:47:00.104068  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:47:00.243604  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7093
I0925 20:47:00.243639  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.83918 (* 1 = 0.83918 loss)
I0925 20:47:00.382851  3547 solver.cpp:218] Iteration 8500 (5.74081 iter/s, 17.4192s/100 iters), loss = 0.240693
I0925 20:47:00.382881  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240693 (* 1 = 0.240693 loss)
I0925 20:47:00.382887  3547 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0925 20:47:14.329324  3547 solver.cpp:218] Iteration 8600 (7.17031 iter/s, 13.9464s/100 iters), loss = 0.263177
I0925 20:47:14.329365  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263177 (* 1 = 0.263177 loss)
I0925 20:47:14.329371  3547 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0925 20:47:28.281936  3547 solver.cpp:218] Iteration 8700 (7.16716 iter/s, 13.9525s/100 iters), loss = 0.256652
I0925 20:47:28.282094  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256653 (* 1 = 0.256653 loss)
I0925 20:47:28.282101  3547 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0925 20:47:42.231169  3547 solver.cpp:218] Iteration 8800 (7.16895 iter/s, 13.949s/100 iters), loss = 0.303683
I0925 20:47:42.231209  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303683 (* 1 = 0.303683 loss)
I0925 20:47:42.231215  3547 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0925 20:47:56.175475  3547 solver.cpp:218] Iteration 8900 (7.17143 iter/s, 13.9442s/100 iters), loss = 0.341474
I0925 20:47:56.175514  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341474 (* 1 = 0.341474 loss)
I0925 20:47:56.175521  3547 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0925 20:48:09.430189  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:48:09.988764  3547 solver.cpp:330] Iteration 9000, Testing net (#0)
I0925 20:48:13.312971  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:48:13.451448  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7108
I0925 20:48:13.451484  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.912929 (* 1 = 0.912929 loss)
I0925 20:48:13.589998  3547 solver.cpp:218] Iteration 9000 (5.74237 iter/s, 17.4144s/100 iters), loss = 0.196846
I0925 20:48:13.590026  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196846 (* 1 = 0.196846 loss)
I0925 20:48:13.590032  3547 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0925 20:48:27.534159  3547 solver.cpp:218] Iteration 9100 (7.1715 iter/s, 13.9441s/100 iters), loss = 0.309409
I0925 20:48:27.534188  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309409 (* 1 = 0.309409 loss)
I0925 20:48:27.534194  3547 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0925 20:48:41.487154  3547 solver.cpp:218] Iteration 9200 (7.16696 iter/s, 13.9529s/100 iters), loss = 0.306427
I0925 20:48:41.487239  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306427 (* 1 = 0.306427 loss)
I0925 20:48:41.487257  3547 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0925 20:48:55.443791  3547 solver.cpp:218] Iteration 9300 (7.16512 iter/s, 13.9565s/100 iters), loss = 0.258251
I0925 20:48:55.443820  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258251 (* 1 = 0.258251 loss)
I0925 20:48:55.443826  3547 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0925 20:49:09.402500  3547 solver.cpp:218] Iteration 9400 (7.16403 iter/s, 13.9586s/100 iters), loss = 0.315654
I0925 20:49:09.402530  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315655 (* 1 = 0.315655 loss)
I0925 20:49:09.402546  3547 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0925 20:49:22.659467  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:49:23.218780  3547 solver.cpp:330] Iteration 9500, Testing net (#0)
I0925 20:49:26.540122  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:49:26.678977  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6952
I0925 20:49:26.679013  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.994532 (* 1 = 0.994532 loss)
I0925 20:49:26.817963  3547 solver.cpp:218] Iteration 9500 (5.74205 iter/s, 17.4154s/100 iters), loss = 0.193539
I0925 20:49:26.817993  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193539 (* 1 = 0.193539 loss)
I0925 20:49:26.818001  3547 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0925 20:49:40.772330  3547 solver.cpp:218] Iteration 9600 (7.16626 iter/s, 13.9543s/100 iters), loss = 0.184667
I0925 20:49:40.772361  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184667 (* 1 = 0.184667 loss)
I0925 20:49:40.772367  3547 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0925 20:49:54.734874  3547 solver.cpp:218] Iteration 9700 (7.16206 iter/s, 13.9625s/100 iters), loss = 0.375063
I0925 20:49:54.735049  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375063 (* 1 = 0.375063 loss)
I0925 20:49:54.735059  3547 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0925 20:50:08.699631  3547 solver.cpp:218] Iteration 9800 (7.16099 iter/s, 13.9646s/100 iters), loss = 0.265669
I0925 20:50:08.699671  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265669 (* 1 = 0.265669 loss)
I0925 20:50:08.699677  3547 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0925 20:50:22.661424  3547 solver.cpp:218] Iteration 9900 (7.16245 iter/s, 13.9617s/100 iters), loss = 0.229946
I0925 20:50:22.661455  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229946 (* 1 = 0.229946 loss)
I0925 20:50:22.661461  3547 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0925 20:50:35.921478  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:50:36.480875  3547 solver.cpp:330] Iteration 10000, Testing net (#0)
I0925 20:50:39.805546  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:50:39.944279  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.765
I0925 20:50:39.944314  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.693392 (* 1 = 0.693392 loss)
I0925 20:50:40.082235  3547 solver.cpp:218] Iteration 10000 (5.74029 iter/s, 17.4207s/100 iters), loss = 0.250273
I0925 20:50:40.082262  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250273 (* 1 = 0.250273 loss)
I0925 20:50:40.082269  3547 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0925 20:50:54.046053  3547 solver.cpp:218] Iteration 10100 (7.1614 iter/s, 13.9637s/100 iters), loss = 0.179224
I0925 20:50:54.046093  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179224 (* 1 = 0.179224 loss)
I0925 20:50:54.046100  3547 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0925 20:51:08.013633  3547 solver.cpp:218] Iteration 10200 (7.15948 iter/s, 13.9675s/100 iters), loss = 0.273447
I0925 20:51:08.013769  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273447 (* 1 = 0.273447 loss)
I0925 20:51:08.013787  3547 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0925 20:51:21.971942  3547 solver.cpp:218] Iteration 10300 (7.16428 iter/s, 13.9581s/100 iters), loss = 0.344897
I0925 20:51:21.971982  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344897 (* 1 = 0.344897 loss)
I0925 20:51:21.971988  3547 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0925 20:51:35.941856  3547 solver.cpp:218] Iteration 10400 (7.15828 iter/s, 13.9698s/100 iters), loss = 0.227575
I0925 20:51:35.941887  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227575 (* 1 = 0.227575 loss)
I0925 20:51:35.941893  3547 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0925 20:51:49.216279  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:51:49.775554  3547 solver.cpp:330] Iteration 10500, Testing net (#0)
I0925 20:51:53.100713  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:51:53.238876  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7556
I0925 20:51:53.238903  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.740143 (* 1 = 0.740143 loss)
I0925 20:51:53.377104  3547 solver.cpp:218] Iteration 10500 (5.73554 iter/s, 17.4352s/100 iters), loss = 0.304482
I0925 20:51:53.377133  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304482 (* 1 = 0.304482 loss)
I0925 20:51:53.377140  3547 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0925 20:52:07.328096  3547 solver.cpp:218] Iteration 10600 (7.16799 iter/s, 13.9509s/100 iters), loss = 0.304926
I0925 20:52:07.328136  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304926 (* 1 = 0.304926 loss)
I0925 20:52:07.328142  3547 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0925 20:52:21.290248  3547 solver.cpp:218] Iteration 10700 (7.16226 iter/s, 13.9621s/100 iters), loss = 0.17682
I0925 20:52:21.290343  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17682 (* 1 = 0.17682 loss)
I0925 20:52:21.290351  3547 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0925 20:52:35.245318  3547 solver.cpp:218] Iteration 10800 (7.16593 iter/s, 13.9549s/100 iters), loss = 0.23299
I0925 20:52:35.245358  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23299 (* 1 = 0.23299 loss)
I0925 20:52:35.245364  3547 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0925 20:52:49.205173  3547 solver.cpp:218] Iteration 10900 (7.16344 iter/s, 13.9598s/100 iters), loss = 0.179469
I0925 20:52:49.205212  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179469 (* 1 = 0.179469 loss)
I0925 20:52:49.205217  3547 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0925 20:53:02.467043  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:53:03.025243  3547 solver.cpp:330] Iteration 11000, Testing net (#0)
I0925 20:53:06.349973  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:53:06.488276  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7131
I0925 20:53:06.488312  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.928082 (* 1 = 0.928082 loss)
I0925 20:53:06.626696  3547 solver.cpp:218] Iteration 11000 (5.74006 iter/s, 17.4214s/100 iters), loss = 0.320477
I0925 20:53:06.626725  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320477 (* 1 = 0.320477 loss)
I0925 20:53:06.626731  3547 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0925 20:53:20.597023  3547 solver.cpp:218] Iteration 11100 (7.15807 iter/s, 13.9703s/100 iters), loss = 0.258251
I0925 20:53:20.597064  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258251 (* 1 = 0.258251 loss)
I0925 20:53:20.597069  3547 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0925 20:53:34.567010  3547 solver.cpp:218] Iteration 11200 (7.15825 iter/s, 13.9699s/100 iters), loss = 0.265162
I0925 20:53:34.567112  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265162 (* 1 = 0.265162 loss)
I0925 20:53:34.567121  3547 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0925 20:53:48.534726  3547 solver.cpp:218] Iteration 11300 (7.15944 iter/s, 13.9676s/100 iters), loss = 0.399851
I0925 20:53:48.534767  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399851 (* 1 = 0.399851 loss)
I0925 20:53:48.534775  3547 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0925 20:54:02.494374  3547 solver.cpp:218] Iteration 11400 (7.16355 iter/s, 13.9596s/100 iters), loss = 0.261024
I0925 20:54:02.494415  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261024 (* 1 = 0.261024 loss)
I0925 20:54:02.494421  3547 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0925 20:54:15.772634  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:54:16.331638  3547 solver.cpp:330] Iteration 11500, Testing net (#0)
I0925 20:54:19.655807  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:54:19.794415  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7486
I0925 20:54:19.794450  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.76063 (* 1 = 0.76063 loss)
I0925 20:54:19.932888  3547 solver.cpp:218] Iteration 11500 (5.73447 iter/s, 17.4384s/100 iters), loss = 0.234491
I0925 20:54:19.932916  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234491 (* 1 = 0.234491 loss)
I0925 20:54:19.932924  3547 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0925 20:54:33.878660  3547 solver.cpp:218] Iteration 11600 (7.17067 iter/s, 13.9457s/100 iters), loss = 0.196324
I0925 20:54:33.878690  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196324 (* 1 = 0.196324 loss)
I0925 20:54:33.878697  3547 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0925 20:54:47.820519  3547 solver.cpp:218] Iteration 11700 (7.17268 iter/s, 13.9418s/100 iters), loss = 0.225926
I0925 20:54:47.820703  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225926 (* 1 = 0.225926 loss)
I0925 20:54:47.820711  3547 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0925 20:55:01.768926  3547 solver.cpp:218] Iteration 11800 (7.16939 iter/s, 13.9482s/100 iters), loss = 0.316386
I0925 20:55:01.768955  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316386 (* 1 = 0.316386 loss)
I0925 20:55:01.768961  3547 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0925 20:55:15.719023  3547 solver.cpp:218] Iteration 11900 (7.16845 iter/s, 13.95s/100 iters), loss = 0.186555
I0925 20:55:15.719054  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186555 (* 1 = 0.186555 loss)
I0925 20:55:15.719061  3547 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0925 20:55:28.972374  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:55:29.530632  3547 solver.cpp:330] Iteration 12000, Testing net (#0)
I0925 20:55:32.853700  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:55:32.992117  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.633
I0925 20:55:32.992153  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37165 (* 1 = 1.37165 loss)
I0925 20:55:33.130910  3547 solver.cpp:218] Iteration 12000 (5.74323 iter/s, 17.4118s/100 iters), loss = 0.198062
I0925 20:55:33.130942  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198062 (* 1 = 0.198062 loss)
I0925 20:55:33.130949  3547 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0925 20:55:47.074285  3547 solver.cpp:218] Iteration 12100 (7.1719 iter/s, 13.9433s/100 iters), loss = 0.281363
I0925 20:55:47.074324  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281363 (* 1 = 0.281363 loss)
I0925 20:55:47.074331  3547 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0925 20:56:01.019347  3547 solver.cpp:218] Iteration 12200 (7.17104 iter/s, 13.945s/100 iters), loss = 0.239055
I0925 20:56:01.019420  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239055 (* 1 = 0.239055 loss)
I0925 20:56:01.019428  3547 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0925 20:56:14.962316  3547 solver.cpp:218] Iteration 12300 (7.17213 iter/s, 13.9429s/100 iters), loss = 0.286253
I0925 20:56:14.962357  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286253 (* 1 = 0.286253 loss)
I0925 20:56:14.962363  3547 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0925 20:56:28.909921  3547 solver.cpp:218] Iteration 12400 (7.16973 iter/s, 13.9475s/100 iters), loss = 0.254625
I0925 20:56:28.909962  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254625 (* 1 = 0.254625 loss)
I0925 20:56:28.909968  3547 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0925 20:56:42.161739  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:56:42.719781  3547 solver.cpp:330] Iteration 12500, Testing net (#0)
I0925 20:56:46.043869  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:56:46.182150  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6078
I0925 20:56:46.182175  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.55644 (* 1 = 1.55644 loss)
I0925 20:56:46.321535  3547 solver.cpp:218] Iteration 12500 (5.74332 iter/s, 17.4115s/100 iters), loss = 0.243392
I0925 20:56:46.321564  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243392 (* 1 = 0.243392 loss)
I0925 20:56:46.321571  3547 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0925 20:57:00.273283  3547 solver.cpp:218] Iteration 12600 (7.1676 iter/s, 13.9517s/100 iters), loss = 0.239332
I0925 20:57:00.273313  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239332 (* 1 = 0.239332 loss)
I0925 20:57:00.273319  3547 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0925 20:57:14.231701  3547 solver.cpp:218] Iteration 12700 (7.16417 iter/s, 13.9583s/100 iters), loss = 0.253717
I0925 20:57:14.231819  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253717 (* 1 = 0.253717 loss)
I0925 20:57:14.231827  3547 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0925 20:57:28.179394  3547 solver.cpp:218] Iteration 12800 (7.16973 iter/s, 13.9475s/100 iters), loss = 0.252141
I0925 20:57:28.179425  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252141 (* 1 = 0.252141 loss)
I0925 20:57:28.179431  3547 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0925 20:57:42.129210  3547 solver.cpp:218] Iteration 12900 (7.16859 iter/s, 13.9497s/100 iters), loss = 0.216639
I0925 20:57:42.129251  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216639 (* 1 = 0.216639 loss)
I0925 20:57:42.129257  3547 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0925 20:57:55.385078  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:57:55.942431  3547 solver.cpp:330] Iteration 13000, Testing net (#0)
I0925 20:57:59.266865  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:57:59.405279  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.705
I0925 20:57:59.405315  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.899196 (* 1 = 0.899196 loss)
I0925 20:57:59.544210  3547 solver.cpp:218] Iteration 13000 (5.74221 iter/s, 17.4149s/100 iters), loss = 0.167347
I0925 20:57:59.544239  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167347 (* 1 = 0.167347 loss)
I0925 20:57:59.544245  3547 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0925 20:58:13.491550  3547 solver.cpp:218] Iteration 13100 (7.16987 iter/s, 13.9473s/100 iters), loss = 0.209221
I0925 20:58:13.491614  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209221 (* 1 = 0.209221 loss)
I0925 20:58:13.491626  3547 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0925 20:58:27.441676  3547 solver.cpp:218] Iteration 13200 (7.16845 iter/s, 13.95s/100 iters), loss = 0.24429
I0925 20:58:27.441763  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24429 (* 1 = 0.24429 loss)
I0925 20:58:27.441782  3547 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0925 20:58:41.384502  3547 solver.cpp:218] Iteration 13300 (7.17221 iter/s, 13.9427s/100 iters), loss = 0.302408
I0925 20:58:41.384533  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302408 (* 1 = 0.302408 loss)
I0925 20:58:41.384538  3547 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0925 20:58:55.327602  3547 solver.cpp:218] Iteration 13400 (7.17204 iter/s, 13.943s/100 iters), loss = 0.264582
I0925 20:58:55.327632  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264582 (* 1 = 0.264582 loss)
I0925 20:58:55.327638  3547 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0925 20:59:08.580145  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:59:09.139330  3547 solver.cpp:330] Iteration 13500, Testing net (#0)
I0925 20:59:12.458250  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 20:59:12.596458  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7281
I0925 20:59:12.596482  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.837463 (* 1 = 0.837463 loss)
I0925 20:59:12.734994  3547 solver.cpp:218] Iteration 13500 (5.74471 iter/s, 17.4073s/100 iters), loss = 0.235322
I0925 20:59:12.735029  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235322 (* 1 = 0.235322 loss)
I0925 20:59:12.735036  3547 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0925 20:59:26.676995  3547 solver.cpp:218] Iteration 13600 (7.17261 iter/s, 13.9419s/100 iters), loss = 0.159674
I0925 20:59:26.677026  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159674 (* 1 = 0.159674 loss)
I0925 20:59:26.677031  3547 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0925 20:59:40.621415  3547 solver.cpp:218] Iteration 13700 (7.17137 iter/s, 13.9443s/100 iters), loss = 0.24845
I0925 20:59:40.621590  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248451 (* 1 = 0.248451 loss)
I0925 20:59:40.621599  3547 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0925 20:59:54.568234  3547 solver.cpp:218] Iteration 13800 (7.1702 iter/s, 13.9466s/100 iters), loss = 0.389264
I0925 20:59:54.568275  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389264 (* 1 = 0.389264 loss)
I0925 20:59:54.568281  3547 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0925 21:00:08.518980  3547 solver.cpp:218] Iteration 13900 (7.16812 iter/s, 13.9507s/100 iters), loss = 0.152579
I0925 21:00:08.519021  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152579 (* 1 = 0.152579 loss)
I0925 21:00:08.519026  3547 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0925 21:00:21.774634  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:00:22.332958  3547 solver.cpp:330] Iteration 14000, Testing net (#0)
I0925 21:00:25.657069  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:00:25.795568  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7375
I0925 21:00:25.795604  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.823386 (* 1 = 0.823386 loss)
I0925 21:00:25.933172  3547 solver.cpp:218] Iteration 14000 (5.74247 iter/s, 17.4141s/100 iters), loss = 0.179576
I0925 21:00:25.933200  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179576 (* 1 = 0.179576 loss)
I0925 21:00:25.933207  3547 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0925 21:00:39.883541  3547 solver.cpp:218] Iteration 14100 (7.16831 iter/s, 13.9503s/100 iters), loss = 0.293237
I0925 21:00:39.883571  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293237 (* 1 = 0.293237 loss)
I0925 21:00:39.883579  3547 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0925 21:00:53.829900  3547 solver.cpp:218] Iteration 14200 (7.17037 iter/s, 13.9463s/100 iters), loss = 0.223219
I0925 21:00:53.830018  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22322 (* 1 = 0.22322 loss)
I0925 21:00:53.830025  3547 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0925 21:01:07.786612  3547 solver.cpp:218] Iteration 14300 (7.16509 iter/s, 13.9566s/100 iters), loss = 0.229314
I0925 21:01:07.786643  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229314 (* 1 = 0.229314 loss)
I0925 21:01:07.786648  3547 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0925 21:01:21.736066  3547 solver.cpp:218] Iteration 14400 (7.16878 iter/s, 13.9494s/100 iters), loss = 0.222899
I0925 21:01:21.736095  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222899 (* 1 = 0.222899 loss)
I0925 21:01:21.736101  3547 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0925 21:01:34.993713  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:01:35.550992  3547 solver.cpp:330] Iteration 14500, Testing net (#0)
I0925 21:01:38.874146  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:01:39.014605  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6812
I0925 21:01:39.014631  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11593 (* 1 = 1.11593 loss)
I0925 21:01:39.153067  3547 solver.cpp:218] Iteration 14500 (5.74154 iter/s, 17.4169s/100 iters), loss = 0.176203
I0925 21:01:39.153098  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176203 (* 1 = 0.176203 loss)
I0925 21:01:39.153105  3547 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0925 21:01:53.119303  3547 solver.cpp:218] Iteration 14600 (7.16016 iter/s, 13.9662s/100 iters), loss = 0.225325
I0925 21:01:53.119333  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225325 (* 1 = 0.225325 loss)
I0925 21:01:53.119338  3547 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0925 21:02:07.101657  3547 solver.cpp:218] Iteration 14700 (7.15191 iter/s, 13.9823s/100 iters), loss = 0.18746
I0925 21:02:07.101791  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18746 (* 1 = 0.18746 loss)
I0925 21:02:07.101799  3547 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0925 21:02:21.228641  3547 solver.cpp:218] Iteration 14800 (7.07874 iter/s, 14.1268s/100 iters), loss = 0.247044
I0925 21:02:21.228669  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247044 (* 1 = 0.247044 loss)
I0925 21:02:21.228675  3547 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0925 21:02:35.229419  3547 solver.cpp:218] Iteration 14900 (7.1425 iter/s, 14.0007s/100 iters), loss = 0.148084
I0925 21:02:35.229449  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148084 (* 1 = 0.148084 loss)
I0925 21:02:35.229455  3547 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0925 21:02:48.491317  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:02:49.048866  3547 solver.cpp:330] Iteration 15000, Testing net (#0)
I0925 21:02:52.366989  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:02:52.504894  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.516
I0925 21:02:52.504928  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.15795 (* 1 = 2.15795 loss)
I0925 21:02:52.641968  3547 solver.cpp:218] Iteration 15000 (5.74301 iter/s, 17.4125s/100 iters), loss = 0.185746
I0925 21:02:52.641999  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185746 (* 1 = 0.185746 loss)
I0925 21:02:52.642005  3547 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0925 21:03:06.593495  3547 solver.cpp:218] Iteration 15100 (7.16771 iter/s, 13.9515s/100 iters), loss = 0.189564
I0925 21:03:06.593536  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189564 (* 1 = 0.189564 loss)
I0925 21:03:06.593542  3547 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0925 21:03:20.534734  3547 solver.cpp:218] Iteration 15200 (7.17301 iter/s, 13.9412s/100 iters), loss = 0.240149
I0925 21:03:20.534870  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240149 (* 1 = 0.240149 loss)
I0925 21:03:20.534878  3547 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0925 21:03:34.479177  3547 solver.cpp:218] Iteration 15300 (7.17141 iter/s, 13.9443s/100 iters), loss = 0.248991
I0925 21:03:34.479207  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248991 (* 1 = 0.248991 loss)
I0925 21:03:34.479213  3547 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0925 21:03:48.421263  3547 solver.cpp:218] Iteration 15400 (7.17257 iter/s, 13.942s/100 iters), loss = 0.164283
I0925 21:03:48.421301  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164283 (* 1 = 0.164283 loss)
I0925 21:03:48.421308  3547 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0925 21:04:01.672513  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:04:02.228801  3547 solver.cpp:330] Iteration 15500, Testing net (#0)
I0925 21:04:05.545171  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:04:05.682952  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6626
I0925 21:04:05.682988  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.20979 (* 1 = 1.20979 loss)
I0925 21:04:05.819936  3547 solver.cpp:218] Iteration 15500 (5.74759 iter/s, 17.3986s/100 iters), loss = 0.134585
I0925 21:04:05.819963  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134586 (* 1 = 0.134586 loss)
I0925 21:04:05.819970  3547 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0925 21:04:19.749521  3547 solver.cpp:218] Iteration 15600 (7.179 iter/s, 13.9295s/100 iters), loss = 0.27322
I0925 21:04:19.749550  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273221 (* 1 = 0.273221 loss)
I0925 21:04:19.749557  3547 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0925 21:04:33.681401  3547 solver.cpp:218] Iteration 15700 (7.17782 iter/s, 13.9318s/100 iters), loss = 0.175072
I0925 21:04:33.681522  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175072 (* 1 = 0.175072 loss)
I0925 21:04:33.681529  3547 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0925 21:04:47.613055  3547 solver.cpp:218] Iteration 15800 (7.17798 iter/s, 13.9315s/100 iters), loss = 0.265791
I0925 21:04:47.613086  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265791 (* 1 = 0.265791 loss)
I0925 21:04:47.613093  3547 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0925 21:05:01.541769  3547 solver.cpp:218] Iteration 15900 (7.17945 iter/s, 13.9286s/100 iters), loss = 0.216517
I0925 21:05:01.541810  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216517 (* 1 = 0.216517 loss)
I0925 21:05:01.541815  3547 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0925 21:05:14.767154  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:05:15.323729  3547 solver.cpp:330] Iteration 16000, Testing net (#0)
I0925 21:05:18.638800  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:05:18.776156  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.685
I0925 21:05:18.776191  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08432 (* 1 = 1.08432 loss)
I0925 21:05:18.912474  3547 solver.cpp:218] Iteration 16000 (5.75685 iter/s, 17.3706s/100 iters), loss = 0.148486
I0925 21:05:18.912503  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148486 (* 1 = 0.148486 loss)
I0925 21:05:18.912508  3547 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0925 21:05:32.837796  3547 solver.cpp:218] Iteration 16100 (7.1812 iter/s, 13.9252s/100 iters), loss = 0.216819
I0925 21:05:32.837827  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216819 (* 1 = 0.216819 loss)
I0925 21:05:32.837833  3547 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0925 21:05:46.766737  3547 solver.cpp:218] Iteration 16200 (7.17934 iter/s, 13.9289s/100 iters), loss = 0.221596
I0925 21:05:46.766845  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221596 (* 1 = 0.221596 loss)
I0925 21:05:46.766852  3547 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0925 21:06:00.693439  3547 solver.cpp:218] Iteration 16300 (7.18053 iter/s, 13.9265s/100 iters), loss = 0.301206
I0925 21:06:00.693470  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301206 (* 1 = 0.301206 loss)
I0925 21:06:00.693477  3547 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0925 21:06:14.620920  3547 solver.cpp:218] Iteration 16400 (7.18009 iter/s, 13.9274s/100 iters), loss = 0.13416
I0925 21:06:14.620951  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13416 (* 1 = 0.13416 loss)
I0925 21:06:14.620957  3547 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0925 21:06:27.864869  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:06:28.421521  3547 solver.cpp:330] Iteration 16500, Testing net (#0)
I0925 21:06:31.739650  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:06:31.876806  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6637
I0925 21:06:31.876832  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04834 (* 1 = 1.04834 loss)
I0925 21:06:32.013607  3547 solver.cpp:218] Iteration 16500 (5.74957 iter/s, 17.3926s/100 iters), loss = 0.214497
I0925 21:06:32.013630  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214497 (* 1 = 0.214497 loss)
I0925 21:06:32.013638  3547 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0925 21:06:45.968696  3547 solver.cpp:218] Iteration 16600 (7.16588 iter/s, 13.955s/100 iters), loss = 0.170601
I0925 21:06:45.968726  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170601 (* 1 = 0.170601 loss)
I0925 21:06:45.968731  3547 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0925 21:06:59.916811  3547 solver.cpp:218] Iteration 16700 (7.16947 iter/s, 13.948s/100 iters), loss = 0.244238
I0925 21:06:59.916926  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244238 (* 1 = 0.244238 loss)
I0925 21:06:59.916944  3547 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0925 21:07:13.868708  3547 solver.cpp:218] Iteration 16800 (7.16756 iter/s, 13.9517s/100 iters), loss = 0.244786
I0925 21:07:13.868748  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244786 (* 1 = 0.244786 loss)
I0925 21:07:13.868754  3547 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0925 21:07:28.007238  3547 solver.cpp:218] Iteration 16900 (7.07291 iter/s, 14.1384s/100 iters), loss = 0.143954
I0925 21:07:28.007272  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143954 (* 1 = 0.143954 loss)
I0925 21:07:28.007287  3547 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0925 21:07:41.289655  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:07:41.846613  3547 solver.cpp:330] Iteration 17000, Testing net (#0)
I0925 21:07:45.167867  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:07:45.306469  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7359
I0925 21:07:45.306504  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.86926 (* 1 = 0.86926 loss)
I0925 21:07:45.445118  3547 solver.cpp:218] Iteration 17000 (5.73467 iter/s, 17.4378s/100 iters), loss = 0.140894
I0925 21:07:45.445149  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140894 (* 1 = 0.140894 loss)
I0925 21:07:45.445155  3547 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0925 21:07:59.385104  3547 solver.cpp:218] Iteration 17100 (7.17365 iter/s, 13.9399s/100 iters), loss = 0.223731
I0925 21:07:59.385145  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223731 (* 1 = 0.223731 loss)
I0925 21:07:59.385150  3547 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0925 21:08:13.323249  3547 solver.cpp:218] Iteration 17200 (7.1746 iter/s, 13.9381s/100 iters), loss = 0.309572
I0925 21:08:13.323355  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309572 (* 1 = 0.309572 loss)
I0925 21:08:13.323362  3547 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0925 21:08:27.265506  3547 solver.cpp:218] Iteration 17300 (7.17252 iter/s, 13.9421s/100 iters), loss = 0.200248
I0925 21:08:27.265545  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200248 (* 1 = 0.200248 loss)
I0925 21:08:27.265552  3547 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0925 21:08:41.210886  3547 solver.cpp:218] Iteration 17400 (7.17088 iter/s, 13.9453s/100 iters), loss = 0.256386
I0925 21:08:41.210925  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256386 (* 1 = 0.256386 loss)
I0925 21:08:41.210930  3547 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0925 21:08:54.461520  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:08:55.020920  3547 solver.cpp:330] Iteration 17500, Testing net (#0)
I0925 21:08:58.340888  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:08:58.479157  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6884
I0925 21:08:58.479193  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0816 (* 1 = 1.0816 loss)
I0925 21:08:58.617741  3547 solver.cpp:218] Iteration 17500 (5.74489 iter/s, 17.4068s/100 iters), loss = 0.258196
I0925 21:08:58.617770  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258196 (* 1 = 0.258196 loss)
I0925 21:08:58.617776  3547 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0925 21:09:12.559257  3547 solver.cpp:218] Iteration 17600 (7.17286 iter/s, 13.9414s/100 iters), loss = 0.203587
I0925 21:09:12.559286  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203587 (* 1 = 0.203587 loss)
I0925 21:09:12.559293  3547 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0925 21:09:26.508997  3547 solver.cpp:218] Iteration 17700 (7.16863 iter/s, 13.9497s/100 iters), loss = 0.15117
I0925 21:09:26.509104  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15117 (* 1 = 0.15117 loss)
I0925 21:09:26.509111  3547 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0925 21:09:40.458068  3547 solver.cpp:218] Iteration 17800 (7.16901 iter/s, 13.9489s/100 iters), loss = 0.193971
I0925 21:09:40.458109  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193971 (* 1 = 0.193971 loss)
I0925 21:09:40.458115  3547 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0925 21:09:54.399220  3547 solver.cpp:218] Iteration 17900 (7.17305 iter/s, 13.9411s/100 iters), loss = 0.146907
I0925 21:09:54.399261  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146907 (* 1 = 0.146907 loss)
I0925 21:09:54.399267  3547 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0925 21:10:07.655086  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:10:08.212653  3547 solver.cpp:330] Iteration 18000, Testing net (#0)
I0925 21:10:11.534343  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:10:11.672998  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4407
I0925 21:10:11.673033  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.25187 (* 1 = 3.25187 loss)
I0925 21:10:11.811513  3547 solver.cpp:218] Iteration 18000 (5.7431 iter/s, 17.4122s/100 iters), loss = 0.177876
I0925 21:10:11.811544  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177876 (* 1 = 0.177876 loss)
I0925 21:10:11.811552  3547 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0925 21:10:25.764415  3547 solver.cpp:218] Iteration 18100 (7.16701 iter/s, 13.9528s/100 iters), loss = 0.162655
I0925 21:10:25.764446  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162655 (* 1 = 0.162655 loss)
I0925 21:10:25.764452  3547 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0925 21:10:39.714112  3547 solver.cpp:218] Iteration 18200 (7.16865 iter/s, 13.9496s/100 iters), loss = 0.260525
I0925 21:10:39.714254  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260526 (* 1 = 0.260526 loss)
I0925 21:10:39.714262  3547 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0925 21:10:53.677006  3547 solver.cpp:218] Iteration 18300 (7.16193 iter/s, 13.9627s/100 iters), loss = 0.189075
I0925 21:10:53.677047  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189075 (* 1 = 0.189075 loss)
I0925 21:10:53.677053  3547 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0925 21:11:07.629153  3547 solver.cpp:218] Iteration 18400 (7.1674 iter/s, 13.9521s/100 iters), loss = 0.195291
I0925 21:11:07.629182  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195291 (* 1 = 0.195291 loss)
I0925 21:11:07.629187  3547 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0925 21:11:20.893854  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:11:21.452090  3547 solver.cpp:330] Iteration 18500, Testing net (#0)
I0925 21:11:24.773746  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:11:24.913631  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6367
I0925 21:11:24.913657  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.27798 (* 1 = 1.27798 loss)
I0925 21:11:25.051784  3547 solver.cpp:218] Iteration 18500 (5.73969 iter/s, 17.4225s/100 iters), loss = 0.111019
I0925 21:11:25.051811  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111019 (* 1 = 0.111019 loss)
I0925 21:11:25.051818  3547 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0925 21:11:38.984817  3547 solver.cpp:218] Iteration 18600 (7.17723 iter/s, 13.933s/100 iters), loss = 0.306461
I0925 21:11:38.984858  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306461 (* 1 = 0.306461 loss)
I0925 21:11:38.984863  3547 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0925 21:11:52.929070  3547 solver.cpp:218] Iteration 18700 (7.17146 iter/s, 13.9442s/100 iters), loss = 0.273445
I0925 21:11:52.929168  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273445 (* 1 = 0.273445 loss)
I0925 21:11:52.929185  3547 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0925 21:12:06.872759  3547 solver.cpp:218] Iteration 18800 (7.17178 iter/s, 13.9435s/100 iters), loss = 0.186179
I0925 21:12:06.872789  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186179 (* 1 = 0.186179 loss)
I0925 21:12:06.872795  3547 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0925 21:12:20.811610  3547 solver.cpp:218] Iteration 18900 (7.17423 iter/s, 13.9388s/100 iters), loss = 0.123086
I0925 21:12:20.811650  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123087 (* 1 = 0.123087 loss)
I0925 21:12:20.811655  3547 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0925 21:12:34.054543  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:12:34.613427  3547 solver.cpp:330] Iteration 19000, Testing net (#0)
I0925 21:12:37.935904  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:12:38.074940  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7354
I0925 21:12:38.074976  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833762 (* 1 = 0.833762 loss)
I0925 21:12:38.213793  3547 solver.cpp:218] Iteration 19000 (5.74644 iter/s, 17.4021s/100 iters), loss = 0.205436
I0925 21:12:38.213822  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205436 (* 1 = 0.205436 loss)
I0925 21:12:38.213829  3547 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0925 21:12:52.169883  3547 solver.cpp:218] Iteration 19100 (7.16537 iter/s, 13.956s/100 iters), loss = 0.160947
I0925 21:12:52.169912  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160947 (* 1 = 0.160947 loss)
I0925 21:12:52.169919  3547 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0925 21:13:06.129506  3547 solver.cpp:218] Iteration 19200 (7.16356 iter/s, 13.9595s/100 iters), loss = 0.241875
I0925 21:13:06.129614  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241875 (* 1 = 0.241875 loss)
I0925 21:13:06.129631  3547 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0925 21:13:20.082788  3547 solver.cpp:218] Iteration 19300 (7.16685 iter/s, 13.9531s/100 iters), loss = 0.177888
I0925 21:13:20.082832  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177888 (* 1 = 0.177888 loss)
I0925 21:13:20.082839  3547 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0925 21:13:34.047164  3547 solver.cpp:218] Iteration 19400 (7.16128 iter/s, 13.964s/100 iters), loss = 0.145848
I0925 21:13:34.047194  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145848 (* 1 = 0.145848 loss)
I0925 21:13:34.047199  3547 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0925 21:13:47.311846  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:13:47.869858  3547 solver.cpp:330] Iteration 19500, Testing net (#0)
I0925 21:13:51.193806  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:13:51.331895  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7632
I0925 21:13:51.331931  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.805456 (* 1 = 0.805456 loss)
I0925 21:13:51.470161  3547 solver.cpp:218] Iteration 19500 (5.73957 iter/s, 17.4229s/100 iters), loss = 0.16724
I0925 21:13:51.470191  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16724 (* 1 = 0.16724 loss)
I0925 21:13:51.470196  3547 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0925 21:14:05.427814  3547 solver.cpp:218] Iteration 19600 (7.16457 iter/s, 13.9576s/100 iters), loss = 0.140924
I0925 21:14:05.427855  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140924 (* 1 = 0.140924 loss)
I0925 21:14:05.427860  3547 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0925 21:14:19.377216  3547 solver.cpp:218] Iteration 19700 (7.16881 iter/s, 13.9493s/100 iters), loss = 0.222763
I0925 21:14:19.377322  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222763 (* 1 = 0.222763 loss)
I0925 21:14:19.377328  3547 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0925 21:14:33.329668  3547 solver.cpp:218] Iteration 19800 (7.16728 iter/s, 13.9523s/100 iters), loss = 0.148403
I0925 21:14:33.329696  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148403 (* 1 = 0.148403 loss)
I0925 21:14:33.329702  3547 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0925 21:14:47.282791  3547 solver.cpp:218] Iteration 19900 (7.16689 iter/s, 13.953s/100 iters), loss = 0.238932
I0925 21:14:47.282831  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238932 (* 1 = 0.238932 loss)
I0925 21:14:47.282837  3547 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0925 21:15:00.540937  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:15:01.098150  3547 solver.cpp:330] Iteration 20000, Testing net (#0)
I0925 21:15:04.419919  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:15:04.558600  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7314
I0925 21:15:04.558625  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.871423 (* 1 = 0.871423 loss)
I0925 21:15:04.696766  3547 solver.cpp:218] Iteration 20000 (5.74255 iter/s, 17.4139s/100 iters), loss = 0.162447
I0925 21:15:04.696795  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162447 (* 1 = 0.162447 loss)
I0925 21:15:04.696801  3547 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0925 21:15:18.654088  3547 solver.cpp:218] Iteration 20100 (7.16474 iter/s, 13.9572s/100 iters), loss = 0.283781
I0925 21:15:18.654129  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283781 (* 1 = 0.283781 loss)
I0925 21:15:18.654135  3547 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0925 21:15:32.607000  3547 solver.cpp:218] Iteration 20200 (7.16701 iter/s, 13.9528s/100 iters), loss = 0.278492
I0925 21:15:32.607096  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278492 (* 1 = 0.278492 loss)
I0925 21:15:32.607115  3547 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0925 21:15:46.566748  3547 solver.cpp:218] Iteration 20300 (7.16353 iter/s, 13.9596s/100 iters), loss = 0.159589
I0925 21:15:46.566788  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15959 (* 1 = 0.15959 loss)
I0925 21:15:46.566794  3547 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0925 21:16:00.526959  3547 solver.cpp:218] Iteration 20400 (7.16326 iter/s, 13.9601s/100 iters), loss = 0.171125
I0925 21:16:00.526988  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171125 (* 1 = 0.171125 loss)
I0925 21:16:00.526995  3547 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0925 21:16:13.784934  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:16:14.342665  3547 solver.cpp:330] Iteration 20500, Testing net (#0)
I0925 21:16:17.666909  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:16:17.804538  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6264
I0925 21:16:17.804582  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.29942 (* 1 = 1.29942 loss)
I0925 21:16:17.942507  3547 solver.cpp:218] Iteration 20500 (5.74202 iter/s, 17.4155s/100 iters), loss = 0.116993
I0925 21:16:17.942535  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116993 (* 1 = 0.116993 loss)
I0925 21:16:17.942543  3547 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0925 21:16:31.884362  3547 solver.cpp:218] Iteration 20600 (7.17269 iter/s, 13.9418s/100 iters), loss = 0.347732
I0925 21:16:31.884402  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347732 (* 1 = 0.347732 loss)
I0925 21:16:31.884408  3547 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0925 21:16:45.842650  3547 solver.cpp:218] Iteration 20700 (7.16425 iter/s, 13.9582s/100 iters), loss = 0.233101
I0925 21:16:45.842716  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233101 (* 1 = 0.233101 loss)
I0925 21:16:45.842723  3547 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0925 21:16:59.784185  3547 solver.cpp:218] Iteration 20800 (7.17287 iter/s, 13.9414s/100 iters), loss = 0.191012
I0925 21:16:59.784214  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191012 (* 1 = 0.191012 loss)
I0925 21:16:59.784220  3547 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0925 21:17:13.730610  3547 solver.cpp:218] Iteration 20900 (7.17033 iter/s, 13.9464s/100 iters), loss = 0.251811
I0925 21:17:13.730640  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251811 (* 1 = 0.251811 loss)
I0925 21:17:13.730646  3547 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0925 21:17:26.987181  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:17:27.545764  3547 solver.cpp:330] Iteration 21000, Testing net (#0)
I0925 21:17:30.870738  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:17:31.009732  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7753
I0925 21:17:31.009768  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.686482 (* 1 = 0.686482 loss)
I0925 21:17:31.148128  3547 solver.cpp:218] Iteration 21000 (5.74137 iter/s, 17.4174s/100 iters), loss = 0.24275
I0925 21:17:31.148155  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24275 (* 1 = 0.24275 loss)
I0925 21:17:31.148162  3547 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0925 21:17:45.101104  3547 solver.cpp:218] Iteration 21100 (7.16697 iter/s, 13.9529s/100 iters), loss = 0.184173
I0925 21:17:45.101133  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184173 (* 1 = 0.184173 loss)
I0925 21:17:45.101140  3547 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0925 21:17:59.065598  3547 solver.cpp:218] Iteration 21200 (7.16106 iter/s, 13.9644s/100 iters), loss = 0.230576
I0925 21:17:59.065721  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230576 (* 1 = 0.230576 loss)
I0925 21:17:59.065738  3547 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0925 21:18:13.021525  3547 solver.cpp:218] Iteration 21300 (7.1655 iter/s, 13.9558s/100 iters), loss = 0.199143
I0925 21:18:13.021566  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199143 (* 1 = 0.199143 loss)
I0925 21:18:13.021572  3547 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0925 21:18:26.982818  3547 solver.cpp:218] Iteration 21400 (7.1627 iter/s, 13.9612s/100 iters), loss = 0.206996
I0925 21:18:26.982847  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206996 (* 1 = 0.206996 loss)
I0925 21:18:26.982854  3547 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0925 21:18:40.248370  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:18:40.808442  3547 solver.cpp:330] Iteration 21500, Testing net (#0)
I0925 21:18:44.130540  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:18:44.269141  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7688
I0925 21:18:44.269176  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.719573 (* 1 = 0.719573 loss)
I0925 21:18:44.407328  3547 solver.cpp:218] Iteration 21500 (5.73907 iter/s, 17.4244s/100 iters), loss = 0.174451
I0925 21:18:44.407361  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174451 (* 1 = 0.174451 loss)
I0925 21:18:44.407367  3547 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0925 21:18:58.344604  3547 solver.cpp:218] Iteration 21600 (7.17504 iter/s, 13.9372s/100 iters), loss = 0.255151
I0925 21:18:58.344643  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255151 (* 1 = 0.255151 loss)
I0925 21:18:58.344650  3547 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0925 21:19:12.296699  3547 solver.cpp:218] Iteration 21700 (7.16743 iter/s, 13.952s/100 iters), loss = 0.238418
I0925 21:19:12.296838  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238418 (* 1 = 0.238418 loss)
I0925 21:19:12.296844  3547 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0925 21:19:26.249224  3547 solver.cpp:218] Iteration 21800 (7.16725 iter/s, 13.9523s/100 iters), loss = 0.19163
I0925 21:19:26.249254  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19163 (* 1 = 0.19163 loss)
I0925 21:19:26.249259  3547 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0925 21:19:40.194228  3547 solver.cpp:218] Iteration 21900 (7.17107 iter/s, 13.9449s/100 iters), loss = 0.0579713
I0925 21:19:40.194262  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579713 (* 1 = 0.0579713 loss)
I0925 21:19:40.194272  3547 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0925 21:19:53.447268  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:19:54.006075  3547 solver.cpp:330] Iteration 22000, Testing net (#0)
I0925 21:19:57.328949  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:19:57.467782  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7277
I0925 21:19:57.467816  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01506 (* 1 = 1.01506 loss)
I0925 21:19:57.605099  3547 solver.cpp:218] Iteration 22000 (5.74357 iter/s, 17.4108s/100 iters), loss = 0.149929
I0925 21:19:57.605129  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149929 (* 1 = 0.149929 loss)
I0925 21:19:57.605135  3547 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0925 21:20:11.541055  3547 solver.cpp:218] Iteration 22100 (7.17572 iter/s, 13.9359s/100 iters), loss = 0.132619
I0925 21:20:11.541086  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132619 (* 1 = 0.132619 loss)
I0925 21:20:11.541092  3547 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0925 21:20:25.472836  3547 solver.cpp:218] Iteration 22200 (7.17787 iter/s, 13.9317s/100 iters), loss = 0.192051
I0925 21:20:25.472965  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192051 (* 1 = 0.192051 loss)
I0925 21:20:25.472975  3547 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0925 21:20:39.403825  3547 solver.cpp:218] Iteration 22300 (7.17833 iter/s, 13.9308s/100 iters), loss = 0.253218
I0925 21:20:39.403856  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253218 (* 1 = 0.253218 loss)
I0925 21:20:39.403861  3547 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0925 21:20:53.347067  3547 solver.cpp:218] Iteration 22400 (7.17197 iter/s, 13.9432s/100 iters), loss = 0.0763211
I0925 21:20:53.347095  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.076321 (* 1 = 0.076321 loss)
I0925 21:20:53.347101  3547 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0925 21:21:06.600817  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:21:07.158534  3547 solver.cpp:330] Iteration 22500, Testing net (#0)
I0925 21:21:10.478497  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:21:10.616641  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3893
I0925 21:21:10.616664  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.82736 (* 1 = 3.82736 loss)
I0925 21:21:10.755043  3547 solver.cpp:218] Iteration 22500 (5.74452 iter/s, 17.4079s/100 iters), loss = 0.161017
I0925 21:21:10.755074  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161017 (* 1 = 0.161017 loss)
I0925 21:21:10.755081  3547 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0925 21:21:24.697396  3547 solver.cpp:218] Iteration 22600 (7.17243 iter/s, 13.9423s/100 iters), loss = 0.186715
I0925 21:21:24.697427  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186715 (* 1 = 0.186715 loss)
I0925 21:21:24.697432  3547 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0925 21:21:38.639889  3547 solver.cpp:218] Iteration 22700 (7.17236 iter/s, 13.9424s/100 iters), loss = 0.241088
I0925 21:21:38.639993  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241088 (* 1 = 0.241088 loss)
I0925 21:21:38.640002  3547 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0925 21:21:52.583807  3547 solver.cpp:218] Iteration 22800 (7.17166 iter/s, 13.9438s/100 iters), loss = 0.138386
I0925 21:21:52.583837  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138386 (* 1 = 0.138386 loss)
I0925 21:21:52.583843  3547 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0925 21:22:06.535161  3547 solver.cpp:218] Iteration 22900 (7.1678 iter/s, 13.9513s/100 iters), loss = 0.131269
I0925 21:22:06.535202  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131269 (* 1 = 0.131269 loss)
I0925 21:22:06.535208  3547 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0925 21:22:19.778312  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:22:20.336372  3547 solver.cpp:330] Iteration 23000, Testing net (#0)
I0925 21:22:23.661540  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:22:23.799757  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8119
I0925 21:22:23.799791  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.564228 (* 1 = 0.564228 loss)
I0925 21:22:23.938271  3547 solver.cpp:218] Iteration 23000 (5.74613 iter/s, 17.403s/100 iters), loss = 0.088178
I0925 21:22:23.938299  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0881779 (* 1 = 0.0881779 loss)
I0925 21:22:23.938307  3547 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0925 21:22:37.885319  3547 solver.cpp:218] Iteration 23100 (7.17001 iter/s, 13.947s/100 iters), loss = 0.177955
I0925 21:22:37.885349  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177955 (* 1 = 0.177955 loss)
I0925 21:22:37.885354  3547 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0925 21:22:51.844265  3547 solver.cpp:218] Iteration 23200 (7.1639 iter/s, 13.9589s/100 iters), loss = 0.227294
I0925 21:22:51.844377  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227294 (* 1 = 0.227294 loss)
I0925 21:22:51.844383  3547 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0925 21:23:05.796633  3547 solver.cpp:218] Iteration 23300 (7.16732 iter/s, 13.9522s/100 iters), loss = 0.251235
I0925 21:23:05.796674  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251235 (* 1 = 0.251235 loss)
I0925 21:23:05.796679  3547 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0925 21:23:19.749197  3547 solver.cpp:218] Iteration 23400 (7.16718 iter/s, 13.9525s/100 iters), loss = 0.133496
I0925 21:23:19.749238  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133496 (* 1 = 0.133496 loss)
I0925 21:23:19.749243  3547 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0925 21:23:33.016139  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:23:33.574935  3547 solver.cpp:330] Iteration 23500, Testing net (#0)
I0925 21:23:36.896423  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:23:37.035208  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5658
I0925 21:23:37.035243  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.71144 (* 1 = 1.71144 loss)
I0925 21:23:37.173807  3547 solver.cpp:218] Iteration 23500 (5.73904 iter/s, 17.4245s/100 iters), loss = 0.149157
I0925 21:23:37.173835  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149157 (* 1 = 0.149157 loss)
I0925 21:23:37.173841  3547 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0925 21:23:51.121317  3547 solver.cpp:218] Iteration 23600 (7.16978 iter/s, 13.9474s/100 iters), loss = 0.234519
I0925 21:23:51.121347  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234519 (* 1 = 0.234519 loss)
I0925 21:23:51.121353  3547 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0925 21:24:05.069022  3547 solver.cpp:218] Iteration 23700 (7.16968 iter/s, 13.9476s/100 iters), loss = 0.124778
I0925 21:24:05.069124  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124778 (* 1 = 0.124778 loss)
I0925 21:24:05.069131  3547 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0925 21:24:19.022670  3547 solver.cpp:218] Iteration 23800 (7.16666 iter/s, 13.9535s/100 iters), loss = 0.153533
I0925 21:24:19.022711  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153533 (* 1 = 0.153533 loss)
I0925 21:24:19.022716  3547 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0925 21:24:32.977540  3547 solver.cpp:218] Iteration 23900 (7.166 iter/s, 13.9548s/100 iters), loss = 0.132473
I0925 21:24:32.977569  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132473 (* 1 = 0.132473 loss)
I0925 21:24:32.977576  3547 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0925 21:24:46.235803  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:24:46.793973  3547 solver.cpp:330] Iteration 24000, Testing net (#0)
I0925 21:24:50.115975  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:24:50.254495  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7612
I0925 21:24:50.254530  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.832033 (* 1 = 0.832033 loss)
I0925 21:24:50.393234  3547 solver.cpp:218] Iteration 24000 (5.74198 iter/s, 17.4156s/100 iters), loss = 0.138947
I0925 21:24:50.393267  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138947 (* 1 = 0.138947 loss)
I0925 21:24:50.393275  3547 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0925 21:25:04.357731  3547 solver.cpp:218] Iteration 24100 (7.16106 iter/s, 13.9644s/100 iters), loss = 0.20529
I0925 21:25:04.357770  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20529 (* 1 = 0.20529 loss)
I0925 21:25:04.357776  3547 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0925 21:25:18.327791  3547 solver.cpp:218] Iteration 24200 (7.15821 iter/s, 13.97s/100 iters), loss = 0.184849
I0925 21:25:18.327924  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184849 (* 1 = 0.184849 loss)
I0925 21:25:18.327942  3547 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0925 21:25:32.296723  3547 solver.cpp:218] Iteration 24300 (7.15883 iter/s, 13.9688s/100 iters), loss = 0.224843
I0925 21:25:32.296753  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224843 (* 1 = 0.224843 loss)
I0925 21:25:32.296759  3547 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0925 21:25:46.264848  3547 solver.cpp:218] Iteration 24400 (7.1592 iter/s, 13.968s/100 iters), loss = 0.173332
I0925 21:25:46.264880  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173332 (* 1 = 0.173332 loss)
I0925 21:25:46.264888  3547 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0925 21:25:59.537356  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:26:00.095245  3547 solver.cpp:330] Iteration 24500, Testing net (#0)
I0925 21:26:03.418704  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:26:03.556941  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6435
I0925 21:26:03.556977  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.30452 (* 1 = 1.30452 loss)
I0925 21:26:03.695595  3547 solver.cpp:218] Iteration 24500 (5.73702 iter/s, 17.4307s/100 iters), loss = 0.116902
I0925 21:26:03.695623  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116902 (* 1 = 0.116902 loss)
I0925 21:26:03.695629  3547 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0925 21:26:17.635787  3547 solver.cpp:218] Iteration 24600 (7.17354 iter/s, 13.9401s/100 iters), loss = 0.198938
I0925 21:26:17.635815  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198938 (* 1 = 0.198938 loss)
I0925 21:26:17.635821  3547 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0925 21:26:31.586786  3547 solver.cpp:218] Iteration 24700 (7.16798 iter/s, 13.9509s/100 iters), loss = 0.1771
I0925 21:26:31.586896  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1771 (* 1 = 0.1771 loss)
I0925 21:26:31.586905  3547 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0925 21:26:45.534998  3547 solver.cpp:218] Iteration 24800 (7.16946 iter/s, 13.9481s/100 iters), loss = 0.19537
I0925 21:26:45.535038  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19537 (* 1 = 0.19537 loss)
I0925 21:26:45.535045  3547 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0925 21:26:59.492955  3547 solver.cpp:218] Iteration 24900 (7.16442 iter/s, 13.9579s/100 iters), loss = 0.173102
I0925 21:26:59.492985  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173102 (* 1 = 0.173102 loss)
I0925 21:26:59.492991  3547 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0925 21:27:12.758307  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:27:13.315527  3547 solver.cpp:330] Iteration 25000, Testing net (#0)
I0925 21:27:16.637712  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:27:16.776217  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7484
I0925 21:27:16.776252  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.837312 (* 1 = 0.837312 loss)
I0925 21:27:16.914248  3547 solver.cpp:218] Iteration 25000 (5.74013 iter/s, 17.4212s/100 iters), loss = 0.184209
I0925 21:27:16.914276  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184209 (* 1 = 0.184209 loss)
I0925 21:27:16.914283  3547 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0925 21:27:30.869633  3547 solver.cpp:218] Iteration 25100 (7.16573 iter/s, 13.9553s/100 iters), loss = 0.155151
I0925 21:27:30.869673  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155151 (* 1 = 0.155151 loss)
I0925 21:27:30.869679  3547 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0925 21:27:44.832144  3547 solver.cpp:218] Iteration 25200 (7.16208 iter/s, 13.9624s/100 iters), loss = 0.202989
I0925 21:27:44.832314  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202989 (* 1 = 0.202989 loss)
I0925 21:27:44.832337  3547 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0925 21:27:58.790181  3547 solver.cpp:218] Iteration 25300 (7.16444 iter/s, 13.9578s/100 iters), loss = 0.202735
I0925 21:27:58.790222  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202735 (* 1 = 0.202735 loss)
I0925 21:27:58.790228  3547 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0925 21:28:12.748117  3547 solver.cpp:218] Iteration 25400 (7.16443 iter/s, 13.9578s/100 iters), loss = 0.134911
I0925 21:28:12.748157  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134911 (* 1 = 0.134911 loss)
I0925 21:28:12.748164  3547 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0925 21:28:26.011215  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:28:26.571537  3547 solver.cpp:330] Iteration 25500, Testing net (#0)
I0925 21:28:29.891340  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:28:30.030081  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6861
I0925 21:28:30.030114  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14969 (* 1 = 1.14969 loss)
I0925 21:28:30.168979  3547 solver.cpp:218] Iteration 25500 (5.74028 iter/s, 17.4208s/100 iters), loss = 0.151439
I0925 21:28:30.169008  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151439 (* 1 = 0.151439 loss)
I0925 21:28:30.169015  3547 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0925 21:28:44.114800  3547 solver.cpp:218] Iteration 25600 (7.17065 iter/s, 13.9457s/100 iters), loss = 0.196541
I0925 21:28:44.114840  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196541 (* 1 = 0.196541 loss)
I0925 21:28:44.114846  3547 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0925 21:28:58.063520  3547 solver.cpp:218] Iteration 25700 (7.16916 iter/s, 13.9486s/100 iters), loss = 0.163473
I0925 21:28:58.063632  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163473 (* 1 = 0.163473 loss)
I0925 21:28:58.063640  3547 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0925 21:29:12.009502  3547 solver.cpp:218] Iteration 25800 (7.1706 iter/s, 13.9458s/100 iters), loss = 0.210125
I0925 21:29:12.009532  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210125 (* 1 = 0.210125 loss)
I0925 21:29:12.009538  3547 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0925 21:29:25.957674  3547 solver.cpp:218] Iteration 25900 (7.16944 iter/s, 13.9481s/100 iters), loss = 0.180942
I0925 21:29:25.957713  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180942 (* 1 = 0.180942 loss)
I0925 21:29:25.957720  3547 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0925 21:29:39.219611  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:29:39.777972  3547 solver.cpp:330] Iteration 26000, Testing net (#0)
I0925 21:29:43.100955  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:29:43.239212  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7458
I0925 21:29:43.239248  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.837306 (* 1 = 0.837306 loss)
I0925 21:29:43.377573  3547 solver.cpp:218] Iteration 26000 (5.74059 iter/s, 17.4198s/100 iters), loss = 0.124812
I0925 21:29:43.377600  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124812 (* 1 = 0.124812 loss)
I0925 21:29:43.377607  3547 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0925 21:29:57.324897  3547 solver.cpp:218] Iteration 26100 (7.16987 iter/s, 13.9472s/100 iters), loss = 0.0900141
I0925 21:29:57.324937  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0900141 (* 1 = 0.0900141 loss)
I0925 21:29:57.324944  3547 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0925 21:30:11.271174  3547 solver.cpp:218] Iteration 26200 (7.17042 iter/s, 13.9462s/100 iters), loss = 0.239858
I0925 21:30:11.271315  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239858 (* 1 = 0.239858 loss)
I0925 21:30:11.271337  3547 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0925 21:30:25.218277  3547 solver.cpp:218] Iteration 26300 (7.17004 iter/s, 13.9469s/100 iters), loss = 0.103393
I0925 21:30:25.218307  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103393 (* 1 = 0.103393 loss)
I0925 21:30:25.218317  3547 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0925 21:30:39.163578  3547 solver.cpp:218] Iteration 26400 (7.17091 iter/s, 13.9452s/100 iters), loss = 0.109109
I0925 21:30:39.163610  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109109 (* 1 = 0.109109 loss)
I0925 21:30:39.163630  3547 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0925 21:30:52.410841  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:30:52.970178  3547 solver.cpp:330] Iteration 26500, Testing net (#0)
I0925 21:30:56.290678  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:30:56.429518  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7542
I0925 21:30:56.429553  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780825 (* 1 = 0.780825 loss)
I0925 21:30:56.567452  3547 solver.cpp:218] Iteration 26500 (5.74588 iter/s, 17.4038s/100 iters), loss = 0.147584
I0925 21:30:56.567482  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147584 (* 1 = 0.147584 loss)
I0925 21:30:56.567488  3547 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0925 21:31:10.504981  3547 solver.cpp:218] Iteration 26600 (7.17491 iter/s, 13.9375s/100 iters), loss = 0.194481
I0925 21:31:10.505013  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194481 (* 1 = 0.194481 loss)
I0925 21:31:10.505019  3547 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0925 21:31:24.448287  3547 solver.cpp:218] Iteration 26700 (7.17194 iter/s, 13.9432s/100 iters), loss = 0.134638
I0925 21:31:24.448410  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134638 (* 1 = 0.134638 loss)
I0925 21:31:24.448427  3547 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0925 21:31:38.379323  3547 solver.cpp:218] Iteration 26800 (7.1783 iter/s, 13.9309s/100 iters), loss = 0.135094
I0925 21:31:38.379364  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135094 (* 1 = 0.135094 loss)
I0925 21:31:38.379370  3547 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0925 21:31:52.318737  3547 solver.cpp:218] Iteration 26900 (7.17395 iter/s, 13.9393s/100 iters), loss = 0.130156
I0925 21:31:52.318778  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130156 (* 1 = 0.130156 loss)
I0925 21:31:52.318784  3547 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0925 21:32:05.564745  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:32:06.121601  3547 solver.cpp:330] Iteration 27000, Testing net (#0)
I0925 21:32:09.444372  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:32:09.582705  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7082
I0925 21:32:09.582741  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06712 (* 1 = 1.06712 loss)
I0925 21:32:09.720832  3547 solver.cpp:218] Iteration 27000 (5.74647 iter/s, 17.402s/100 iters), loss = 0.120849
I0925 21:32:09.720862  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120849 (* 1 = 0.120849 loss)
I0925 21:32:09.720870  3547 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0925 21:32:23.661583  3547 solver.cpp:218] Iteration 27100 (7.17326 iter/s, 13.9407s/100 iters), loss = 0.301477
I0925 21:32:23.661614  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301477 (* 1 = 0.301477 loss)
I0925 21:32:23.661620  3547 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0925 21:32:37.606884  3547 solver.cpp:218] Iteration 27200 (7.17091 iter/s, 13.9452s/100 iters), loss = 0.212945
I0925 21:32:37.607028  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212945 (* 1 = 0.212945 loss)
I0925 21:32:37.607036  3547 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0925 21:32:51.555145  3547 solver.cpp:218] Iteration 27300 (7.16944 iter/s, 13.9481s/100 iters), loss = 0.228952
I0925 21:32:51.555176  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228952 (* 1 = 0.228952 loss)
I0925 21:32:51.555181  3547 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0925 21:33:05.504900  3547 solver.cpp:218] Iteration 27400 (7.16862 iter/s, 13.9497s/100 iters), loss = 0.12813
I0925 21:33:05.504931  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128131 (* 1 = 0.128131 loss)
I0925 21:33:05.504937  3547 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0925 21:33:18.759889  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:33:19.317644  3547 solver.cpp:330] Iteration 27500, Testing net (#0)
I0925 21:33:22.639163  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:33:22.777783  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6616
I0925 21:33:22.777818  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.27255 (* 1 = 1.27255 loss)
I0925 21:33:22.916142  3547 solver.cpp:218] Iteration 27500 (5.74344 iter/s, 17.4112s/100 iters), loss = 0.187259
I0925 21:33:22.916172  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187259 (* 1 = 0.187259 loss)
I0925 21:33:22.916177  3547 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0925 21:33:36.856789  3547 solver.cpp:218] Iteration 27600 (7.17331 iter/s, 13.9406s/100 iters), loss = 0.12185
I0925 21:33:36.856818  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12185 (* 1 = 0.12185 loss)
I0925 21:33:36.856823  3547 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0925 21:33:50.796864  3547 solver.cpp:218] Iteration 27700 (7.1736 iter/s, 13.94s/100 iters), loss = 0.211544
I0925 21:33:50.796986  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211544 (* 1 = 0.211544 loss)
I0925 21:33:50.797004  3547 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0925 21:34:04.746920  3547 solver.cpp:218] Iteration 27800 (7.16852 iter/s, 13.9499s/100 iters), loss = 0.300737
I0925 21:34:04.746961  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300737 (* 1 = 0.300737 loss)
I0925 21:34:04.746968  3547 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0925 21:34:18.692621  3547 solver.cpp:218] Iteration 27900 (7.17071 iter/s, 13.9456s/100 iters), loss = 0.194803
I0925 21:34:18.692651  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194803 (* 1 = 0.194803 loss)
I0925 21:34:18.692657  3547 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0925 21:34:31.954874  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:34:32.514261  3547 solver.cpp:330] Iteration 28000, Testing net (#0)
I0925 21:34:35.833909  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:34:35.972259  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7844
I0925 21:34:35.972295  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.656739 (* 1 = 0.656739 loss)
I0925 21:34:36.110951  3547 solver.cpp:218] Iteration 28000 (5.74111 iter/s, 17.4182s/100 iters), loss = 0.148273
I0925 21:34:36.110980  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148273 (* 1 = 0.148273 loss)
I0925 21:34:36.110986  3547 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0925 21:34:50.061744  3547 solver.cpp:218] Iteration 28100 (7.16809 iter/s, 13.9507s/100 iters), loss = 0.160621
I0925 21:34:50.061774  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160621 (* 1 = 0.160621 loss)
I0925 21:34:50.061779  3547 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0925 21:35:04.005611  3547 solver.cpp:218] Iteration 28200 (7.17165 iter/s, 13.9438s/100 iters), loss = 0.114251
I0925 21:35:04.005777  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114251 (* 1 = 0.114251 loss)
I0925 21:35:04.005786  3547 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0925 21:35:17.960597  3547 solver.cpp:218] Iteration 28300 (7.166 iter/s, 13.9548s/100 iters), loss = 0.14728
I0925 21:35:17.960625  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14728 (* 1 = 0.14728 loss)
I0925 21:35:17.960641  3547 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0925 21:35:31.915608  3547 solver.cpp:218] Iteration 28400 (7.16592 iter/s, 13.9549s/100 iters), loss = 0.141598
I0925 21:35:31.915638  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141598 (* 1 = 0.141598 loss)
I0925 21:35:31.915654  3547 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0925 21:35:45.173384  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:35:45.731364  3547 solver.cpp:330] Iteration 28500, Testing net (#0)
I0925 21:35:49.053393  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:35:49.191893  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7236
I0925 21:35:49.191929  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.893713 (* 1 = 0.893713 loss)
I0925 21:35:49.330183  3547 solver.cpp:218] Iteration 28500 (5.74235 iter/s, 17.4145s/100 iters), loss = 0.171847
I0925 21:35:49.330211  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171847 (* 1 = 0.171847 loss)
I0925 21:35:49.330219  3547 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0925 21:36:03.285888  3547 solver.cpp:218] Iteration 28600 (7.16557 iter/s, 13.9556s/100 iters), loss = 0.184815
I0925 21:36:03.285918  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184815 (* 1 = 0.184815 loss)
I0925 21:36:03.285923  3547 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0925 21:36:17.243029  3547 solver.cpp:218] Iteration 28700 (7.16483 iter/s, 13.9571s/100 iters), loss = 0.189156
I0925 21:36:17.243175  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189156 (* 1 = 0.189156 loss)
I0925 21:36:17.243185  3547 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0925 21:36:31.196339  3547 solver.cpp:218] Iteration 28800 (7.16686 iter/s, 13.9531s/100 iters), loss = 0.0870394
I0925 21:36:31.196379  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0870395 (* 1 = 0.0870395 loss)
I0925 21:36:31.196385  3547 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0925 21:36:45.158529  3547 solver.cpp:218] Iteration 28900 (7.16225 iter/s, 13.9621s/100 iters), loss = 0.221669
I0925 21:36:45.158569  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221669 (* 1 = 0.221669 loss)
I0925 21:36:45.158576  3547 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0925 21:36:58.421270  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:36:58.979869  3547 solver.cpp:330] Iteration 29000, Testing net (#0)
I0925 21:37:02.301940  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:37:02.439546  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6152
I0925 21:37:02.439581  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.53045 (* 1 = 1.53045 loss)
I0925 21:37:02.577875  3547 solver.cpp:218] Iteration 29000 (5.74077 iter/s, 17.4193s/100 iters), loss = 0.132466
I0925 21:37:02.577905  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132466 (* 1 = 0.132466 loss)
I0925 21:37:02.577913  3547 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0925 21:37:16.523620  3547 solver.cpp:218] Iteration 29100 (7.17068 iter/s, 13.9457s/100 iters), loss = 0.171991
I0925 21:37:16.523650  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171991 (* 1 = 0.171991 loss)
I0925 21:37:16.523656  3547 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0925 21:37:30.479631  3547 solver.cpp:218] Iteration 29200 (7.16541 iter/s, 13.9559s/100 iters), loss = 0.180531
I0925 21:37:30.479748  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180531 (* 1 = 0.180531 loss)
I0925 21:37:30.479766  3547 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0925 21:37:44.436960  3547 solver.cpp:218] Iteration 29300 (7.16478 iter/s, 13.9572s/100 iters), loss = 0.163772
I0925 21:37:44.437000  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163772 (* 1 = 0.163772 loss)
I0925 21:37:44.437005  3547 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0925 21:37:58.387058  3547 solver.cpp:218] Iteration 29400 (7.16845 iter/s, 13.95s/100 iters), loss = 0.0796719
I0925 21:37:58.387096  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.079672 (* 1 = 0.079672 loss)
I0925 21:37:58.387102  3547 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0925 21:38:11.645829  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:38:12.203054  3547 solver.cpp:330] Iteration 29500, Testing net (#0)
I0925 21:38:15.524384  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:38:15.662745  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.758
I0925 21:38:15.662781  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.766285 (* 1 = 0.766285 loss)
I0925 21:38:15.801508  3547 solver.cpp:218] Iteration 29500 (5.74239 iter/s, 17.4144s/100 iters), loss = 0.28124
I0925 21:38:15.801538  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28124 (* 1 = 0.28124 loss)
I0925 21:38:15.801544  3547 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0925 21:38:29.750411  3547 solver.cpp:218] Iteration 29600 (7.16906 iter/s, 13.9488s/100 iters), loss = 0.214486
I0925 21:38:29.750444  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214486 (* 1 = 0.214486 loss)
I0925 21:38:29.750450  3547 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0925 21:38:43.709986  3547 solver.cpp:218] Iteration 29700 (7.16358 iter/s, 13.9595s/100 iters), loss = 0.205644
I0925 21:38:43.710129  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205644 (* 1 = 0.205644 loss)
I0925 21:38:43.710149  3547 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0925 21:38:57.661656  3547 solver.cpp:218] Iteration 29800 (7.16769 iter/s, 13.9515s/100 iters), loss = 0.189288
I0925 21:38:57.661686  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189288 (* 1 = 0.189288 loss)
I0925 21:38:57.661692  3547 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0925 21:39:11.612591  3547 solver.cpp:218] Iteration 29900 (7.16802 iter/s, 13.9509s/100 iters), loss = 0.103785
I0925 21:39:11.612632  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103785 (* 1 = 0.103785 loss)
I0925 21:39:11.612637  3547 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0925 21:39:24.864614  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:39:25.422926  3547 solver.cpp:330] Iteration 30000, Testing net (#0)
I0925 21:39:28.745782  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:39:28.884299  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.706
I0925 21:39:28.884333  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1061 (* 1 = 1.1061 loss)
I0925 21:39:29.022596  3547 solver.cpp:218] Iteration 30000 (5.74385 iter/s, 17.4099s/100 iters), loss = 0.138312
I0925 21:39:29.022625  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138312 (* 1 = 0.138312 loss)
I0925 21:39:29.022632  3547 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0925 21:39:42.972287  3547 solver.cpp:218] Iteration 30100 (7.16866 iter/s, 13.9496s/100 iters), loss = 0.0863973
I0925 21:39:42.972328  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0863972 (* 1 = 0.0863972 loss)
I0925 21:39:42.972335  3547 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0925 21:39:56.927310  3547 solver.cpp:218] Iteration 30200 (7.16592 iter/s, 13.9549s/100 iters), loss = 0.175117
I0925 21:39:56.927465  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175117 (* 1 = 0.175117 loss)
I0925 21:39:56.927484  3547 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0925 21:40:10.881602  3547 solver.cpp:218] Iteration 30300 (7.16636 iter/s, 13.9541s/100 iters), loss = 0.152724
I0925 21:40:10.881630  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152724 (* 1 = 0.152724 loss)
I0925 21:40:10.881636  3547 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0925 21:40:24.842414  3547 solver.cpp:218] Iteration 30400 (7.16294 iter/s, 13.9607s/100 iters), loss = 0.168253
I0925 21:40:24.842444  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168253 (* 1 = 0.168253 loss)
I0925 21:40:24.842450  3547 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0925 21:40:38.103351  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:40:38.661767  3547 solver.cpp:330] Iteration 30500, Testing net (#0)
I0925 21:40:41.981544  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:40:42.120074  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6647
I0925 21:40:42.120110  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1805 (* 1 = 1.1805 loss)
I0925 21:40:42.258024  3547 solver.cpp:218] Iteration 30500 (5.742 iter/s, 17.4155s/100 iters), loss = 0.116805
I0925 21:40:42.258066  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116805 (* 1 = 0.116805 loss)
I0925 21:40:42.258074  3547 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0925 21:40:56.199138  3547 solver.cpp:218] Iteration 30600 (7.17307 iter/s, 13.941s/100 iters), loss = 0.22216
I0925 21:40:56.199178  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22216 (* 1 = 0.22216 loss)
I0925 21:40:56.199184  3547 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0925 21:41:10.150851  3547 solver.cpp:218] Iteration 30700 (7.16762 iter/s, 13.9516s/100 iters), loss = 0.187852
I0925 21:41:10.150985  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187852 (* 1 = 0.187852 loss)
I0925 21:41:10.150992  3547 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0925 21:41:24.098975  3547 solver.cpp:218] Iteration 30800 (7.16951 iter/s, 13.948s/100 iters), loss = 0.109873
I0925 21:41:24.099016  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109873 (* 1 = 0.109873 loss)
I0925 21:41:24.099022  3547 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0925 21:41:38.050417  3547 solver.cpp:218] Iteration 30900 (7.16776 iter/s, 13.9514s/100 iters), loss = 0.113886
I0925 21:41:38.050457  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113886 (* 1 = 0.113886 loss)
I0925 21:41:38.050463  3547 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0925 21:41:51.309448  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:41:51.867305  3547 solver.cpp:330] Iteration 31000, Testing net (#0)
I0925 21:41:55.187577  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:41:55.326108  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5728
I0925 21:41:55.326144  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.64384 (* 1 = 1.64384 loss)
I0925 21:41:55.464617  3547 solver.cpp:218] Iteration 31000 (5.74247 iter/s, 17.4141s/100 iters), loss = 0.0999446
I0925 21:41:55.464660  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0999445 (* 1 = 0.0999445 loss)
I0925 21:41:55.464679  3547 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0925 21:42:09.421824  3547 solver.cpp:218] Iteration 31100 (7.1648 iter/s, 13.9571s/100 iters), loss = 0.131941
I0925 21:42:09.421865  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131941 (* 1 = 0.131941 loss)
I0925 21:42:09.421871  3547 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0925 21:42:23.374941  3547 solver.cpp:218] Iteration 31200 (7.1669 iter/s, 13.953s/100 iters), loss = 0.159327
I0925 21:42:23.375067  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159327 (* 1 = 0.159327 loss)
I0925 21:42:23.375075  3547 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0925 21:42:37.333670  3547 solver.cpp:218] Iteration 31300 (7.16406 iter/s, 13.9586s/100 iters), loss = 0.23578
I0925 21:42:37.333700  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23578 (* 1 = 0.23578 loss)
I0925 21:42:37.333706  3547 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0925 21:42:51.292107  3547 solver.cpp:218] Iteration 31400 (7.16416 iter/s, 13.9584s/100 iters), loss = 0.108669
I0925 21:42:51.292147  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108669 (* 1 = 0.108669 loss)
I0925 21:42:51.292153  3547 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0925 21:43:04.557634  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:43:05.115357  3547 solver.cpp:330] Iteration 31500, Testing net (#0)
I0925 21:43:08.437932  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:43:08.576335  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.734
I0925 21:43:08.576372  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.828653 (* 1 = 0.828653 loss)
I0925 21:43:08.714900  3547 solver.cpp:218] Iteration 31500 (5.73964 iter/s, 17.4227s/100 iters), loss = 0.157281
I0925 21:43:08.714931  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157281 (* 1 = 0.157281 loss)
I0925 21:43:08.714937  3547 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0925 21:43:22.656064  3547 solver.cpp:218] Iteration 31600 (7.17304 iter/s, 13.9411s/100 iters), loss = 0.223841
I0925 21:43:22.656093  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223841 (* 1 = 0.223841 loss)
I0925 21:43:22.656098  3547 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0925 21:43:36.597043  3547 solver.cpp:218] Iteration 31700 (7.17314 iter/s, 13.9409s/100 iters), loss = 0.106201
I0925 21:43:36.597157  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106201 (* 1 = 0.106201 loss)
I0925 21:43:36.597165  3547 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0925 21:43:50.537727  3547 solver.cpp:218] Iteration 31800 (7.17333 iter/s, 13.9405s/100 iters), loss = 0.228099
I0925 21:43:50.537768  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228099 (* 1 = 0.228099 loss)
I0925 21:43:50.537775  3547 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0925 21:44:04.483481  3547 solver.cpp:218] Iteration 31900 (7.17068 iter/s, 13.9457s/100 iters), loss = 0.0706764
I0925 21:44:04.483521  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0706764 (* 1 = 0.0706764 loss)
I0925 21:44:04.483527  3547 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0925 21:44:17.736682  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:44:18.295171  3547 solver.cpp:330] Iteration 32000, Testing net (#0)
I0925 21:44:21.615751  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:44:21.754201  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7527
I0925 21:44:21.754236  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.7742 (* 1 = 0.7742 loss)
I0925 21:44:21.892513  3547 solver.cpp:218] Iteration 32000 (5.74418 iter/s, 17.4089s/100 iters), loss = 0.111052
I0925 21:44:21.892542  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111052 (* 1 = 0.111052 loss)
I0925 21:44:21.892549  3547 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0925 21:44:35.856700  3547 solver.cpp:218] Iteration 32100 (7.16122 iter/s, 13.9641s/100 iters), loss = 0.206353
I0925 21:44:35.856730  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206353 (* 1 = 0.206353 loss)
I0925 21:44:35.856736  3547 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0925 21:44:49.816565  3547 solver.cpp:218] Iteration 32200 (7.16343 iter/s, 13.9598s/100 iters), loss = 0.216831
I0925 21:44:49.816736  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216831 (* 1 = 0.216831 loss)
I0925 21:44:49.816745  3547 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0925 21:45:03.778955  3547 solver.cpp:218] Iteration 32300 (7.1622 iter/s, 13.9622s/100 iters), loss = 0.239098
I0925 21:45:03.778996  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239098 (* 1 = 0.239098 loss)
I0925 21:45:03.779001  3547 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0925 21:45:17.749970  3547 solver.cpp:218] Iteration 32400 (7.15772 iter/s, 13.9709s/100 iters), loss = 0.110711
I0925 21:45:17.750011  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110711 (* 1 = 0.110711 loss)
I0925 21:45:17.750017  3547 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0925 21:45:31.018139  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:45:31.576385  3547 solver.cpp:330] Iteration 32500, Testing net (#0)
I0925 21:45:34.897444  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:45:35.036319  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6446
I0925 21:45:35.036342  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.45553 (* 1 = 1.45553 loss)
I0925 21:45:35.174949  3547 solver.cpp:218] Iteration 32500 (5.73892 iter/s, 17.4249s/100 iters), loss = 0.113359
I0925 21:45:35.174979  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113359 (* 1 = 0.113359 loss)
I0925 21:45:35.174985  3547 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0925 21:45:49.120080  3547 solver.cpp:218] Iteration 32600 (7.171 iter/s, 13.9451s/100 iters), loss = 0.118217
I0925 21:45:49.120110  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118217 (* 1 = 0.118217 loss)
I0925 21:45:49.120115  3547 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0925 21:46:03.071660  3547 solver.cpp:218] Iteration 32700 (7.16769 iter/s, 13.9515s/100 iters), loss = 0.284042
I0925 21:46:03.071740  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284042 (* 1 = 0.284042 loss)
I0925 21:46:03.071763  3547 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0925 21:46:17.021260  3547 solver.cpp:218] Iteration 32800 (7.16873 iter/s, 13.9495s/100 iters), loss = 0.0961522
I0925 21:46:17.021301  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0961522 (* 1 = 0.0961522 loss)
I0925 21:46:17.021306  3547 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0925 21:46:30.976202  3547 solver.cpp:218] Iteration 32900 (7.16596 iter/s, 13.9549s/100 iters), loss = 0.147285
I0925 21:46:30.976241  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147285 (* 1 = 0.147285 loss)
I0925 21:46:30.976248  3547 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0925 21:46:44.234220  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:46:44.791699  3547 solver.cpp:330] Iteration 33000, Testing net (#0)
I0925 21:46:48.112026  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:46:48.250598  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7646
I0925 21:46:48.250623  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.735918 (* 1 = 0.735918 loss)
I0925 21:46:48.388686  3547 solver.cpp:218] Iteration 33000 (5.74304 iter/s, 17.4124s/100 iters), loss = 0.141868
I0925 21:46:48.388713  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141868 (* 1 = 0.141868 loss)
I0925 21:46:48.388720  3547 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0925 21:47:02.344744  3547 solver.cpp:218] Iteration 33100 (7.16539 iter/s, 13.956s/100 iters), loss = 0.162829
I0925 21:47:02.344784  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162829 (* 1 = 0.162829 loss)
I0925 21:47:02.344791  3547 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0925 21:47:16.295367  3547 solver.cpp:218] Iteration 33200 (7.16818 iter/s, 13.9505s/100 iters), loss = 0.205008
I0925 21:47:16.295485  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205008 (* 1 = 0.205008 loss)
I0925 21:47:16.295491  3547 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0925 21:47:30.261492  3547 solver.cpp:218] Iteration 33300 (7.16026 iter/s, 13.966s/100 iters), loss = 0.082831
I0925 21:47:30.261523  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.082831 (* 1 = 0.082831 loss)
I0925 21:47:30.261528  3547 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0925 21:47:44.215374  3547 solver.cpp:218] Iteration 33400 (7.1665 iter/s, 13.9538s/100 iters), loss = 0.170841
I0925 21:47:44.215415  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170841 (* 1 = 0.170841 loss)
I0925 21:47:44.215420  3547 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0925 21:47:57.479663  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:47:58.037362  3547 solver.cpp:330] Iteration 33500, Testing net (#0)
I0925 21:48:01.361007  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:48:01.499181  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6087
I0925 21:48:01.499217  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.75064 (* 1 = 1.75064 loss)
I0925 21:48:01.637994  3547 solver.cpp:218] Iteration 33500 (5.7397 iter/s, 17.4225s/100 iters), loss = 0.126791
I0925 21:48:01.638020  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126791 (* 1 = 0.126791 loss)
I0925 21:48:01.638026  3547 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0925 21:48:15.577585  3547 solver.cpp:218] Iteration 33600 (7.17385 iter/s, 13.9395s/100 iters), loss = 0.148361
I0925 21:48:15.577625  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148361 (* 1 = 0.148361 loss)
I0925 21:48:15.577630  3547 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0925 21:48:29.514408  3547 solver.cpp:218] Iteration 33700 (7.17528 iter/s, 13.9367s/100 iters), loss = 0.118653
I0925 21:48:29.514518  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118653 (* 1 = 0.118653 loss)
I0925 21:48:29.514525  3547 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0925 21:48:43.459712  3547 solver.cpp:218] Iteration 33800 (7.17095 iter/s, 13.9452s/100 iters), loss = 0.149591
I0925 21:48:43.459743  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149591 (* 1 = 0.149591 loss)
I0925 21:48:43.459749  3547 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0925 21:48:57.393946  3547 solver.cpp:218] Iteration 33900 (7.17661 iter/s, 13.9342s/100 iters), loss = 0.141561
I0925 21:48:57.393977  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141561 (* 1 = 0.141561 loss)
I0925 21:48:57.393983  3547 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0925 21:49:10.643242  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:49:11.200799  3547 solver.cpp:330] Iteration 34000, Testing net (#0)
I0925 21:49:14.524313  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:49:14.662590  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7025
I0925 21:49:14.662613  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07422 (* 1 = 1.07422 loss)
I0925 21:49:14.800459  3547 solver.cpp:218] Iteration 34000 (5.745 iter/s, 17.4064s/100 iters), loss = 0.209581
I0925 21:49:14.800488  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209581 (* 1 = 0.209581 loss)
I0925 21:49:14.800498  3547 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0925 21:49:28.745764  3547 solver.cpp:218] Iteration 34100 (7.17091 iter/s, 13.9452s/100 iters), loss = 0.120926
I0925 21:49:28.745795  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120926 (* 1 = 0.120926 loss)
I0925 21:49:28.745800  3547 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0925 21:49:42.693513  3547 solver.cpp:218] Iteration 34200 (7.16965 iter/s, 13.9477s/100 iters), loss = 0.193546
I0925 21:49:42.693639  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193546 (* 1 = 0.193546 loss)
I0925 21:49:42.693656  3547 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0925 21:49:56.645725  3547 solver.cpp:218] Iteration 34300 (7.16741 iter/s, 13.952s/100 iters), loss = 0.146955
I0925 21:49:56.645754  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146955 (* 1 = 0.146955 loss)
I0925 21:49:56.645761  3547 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0925 21:50:10.589807  3547 solver.cpp:218] Iteration 34400 (7.17154 iter/s, 13.944s/100 iters), loss = 0.162481
I0925 21:50:10.589848  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162481 (* 1 = 0.162481 loss)
I0925 21:50:10.589854  3547 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0925 21:50:23.848250  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:50:24.405463  3547 solver.cpp:330] Iteration 34500, Testing net (#0)
I0925 21:50:27.728164  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:50:27.866809  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.703
I0925 21:50:27.866837  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0834 (* 1 = 1.0834 loss)
I0925 21:50:28.005127  3547 solver.cpp:218] Iteration 34500 (5.7421 iter/s, 17.4152s/100 iters), loss = 0.151832
I0925 21:50:28.005158  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151832 (* 1 = 0.151832 loss)
I0925 21:50:28.005165  3547 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0925 21:50:41.968607  3547 solver.cpp:218] Iteration 34600 (7.16158 iter/s, 13.9634s/100 iters), loss = 0.171788
I0925 21:50:41.968636  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171788 (* 1 = 0.171788 loss)
I0925 21:50:41.968642  3547 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0925 21:50:55.937446  3547 solver.cpp:218] Iteration 34700 (7.15883 iter/s, 13.9688s/100 iters), loss = 0.170978
I0925 21:50:55.937541  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170978 (* 1 = 0.170978 loss)
I0925 21:50:55.937551  3547 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0925 21:51:09.900072  3547 solver.cpp:218] Iteration 34800 (7.16205 iter/s, 13.9625s/100 iters), loss = 0.136827
I0925 21:51:09.900102  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136826 (* 1 = 0.136826 loss)
I0925 21:51:09.900108  3547 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0925 21:51:23.860066  3547 solver.cpp:218] Iteration 34900 (7.16337 iter/s, 13.9599s/100 iters), loss = 0.190133
I0925 21:51:23.860106  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190133 (* 1 = 0.190133 loss)
I0925 21:51:23.860112  3547 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0925 21:51:37.127737  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:51:37.686914  3547 solver.cpp:330] Iteration 35000, Testing net (#0)
I0925 21:51:41.011091  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:51:41.149432  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6431
I0925 21:51:41.149457  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.61818 (* 1 = 1.61818 loss)
I0925 21:51:41.288107  3547 solver.cpp:218] Iteration 35000 (5.73791 iter/s, 17.4279s/100 iters), loss = 0.0977064
I0925 21:51:41.288134  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0977064 (* 1 = 0.0977064 loss)
I0925 21:51:41.288141  3547 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0925 21:51:55.232870  3547 solver.cpp:218] Iteration 35100 (7.17119 iter/s, 13.9447s/100 iters), loss = 0.202669
I0925 21:51:55.232899  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202669 (* 1 = 0.202669 loss)
I0925 21:51:55.232905  3547 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0925 21:52:09.179960  3547 solver.cpp:218] Iteration 35200 (7.16999 iter/s, 13.947s/100 iters), loss = 0.115525
I0925 21:52:09.180099  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115525 (* 1 = 0.115525 loss)
I0925 21:52:09.180106  3547 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0925 21:52:23.120141  3547 solver.cpp:218] Iteration 35300 (7.1736 iter/s, 13.94s/100 iters), loss = 0.207005
I0925 21:52:23.120180  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207005 (* 1 = 0.207005 loss)
I0925 21:52:23.120187  3547 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0925 21:52:37.067495  3547 solver.cpp:218] Iteration 35400 (7.16986 iter/s, 13.9473s/100 iters), loss = 0.151022
I0925 21:52:37.067535  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151022 (* 1 = 0.151022 loss)
I0925 21:52:37.067541  3547 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0925 21:52:50.323427  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:52:50.881000  3547 solver.cpp:330] Iteration 35500, Testing net (#0)
I0925 21:52:54.202700  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:52:54.341411  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7161
I0925 21:52:54.341446  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.827758 (* 1 = 0.827758 loss)
I0925 21:52:54.479986  3547 solver.cpp:218] Iteration 35500 (5.74303 iter/s, 17.4124s/100 iters), loss = 0.146266
I0925 21:52:54.480020  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146266 (* 1 = 0.146266 loss)
I0925 21:52:54.480026  3547 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0925 21:53:08.435837  3547 solver.cpp:218] Iteration 35600 (7.16549 iter/s, 13.9558s/100 iters), loss = 0.199865
I0925 21:53:08.435865  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199865 (* 1 = 0.199865 loss)
I0925 21:53:08.435871  3547 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0925 21:53:22.400485  3547 solver.cpp:218] Iteration 35700 (7.16098 iter/s, 13.9646s/100 iters), loss = 0.172326
I0925 21:53:22.400598  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172326 (* 1 = 0.172326 loss)
I0925 21:53:22.400604  3547 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0925 21:53:36.356693  3547 solver.cpp:218] Iteration 35800 (7.16535 iter/s, 13.9561s/100 iters), loss = 0.117722
I0925 21:53:36.356734  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117722 (* 1 = 0.117722 loss)
I0925 21:53:36.356741  3547 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0925 21:53:50.313904  3547 solver.cpp:218] Iteration 35900 (7.1648 iter/s, 13.9571s/100 iters), loss = 0.23853
I0925 21:53:50.313933  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238529 (* 1 = 0.238529 loss)
I0925 21:53:50.313938  3547 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0925 21:54:03.581710  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:54:04.141096  3547 solver.cpp:330] Iteration 36000, Testing net (#0)
I0925 21:54:07.462689  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:54:07.600992  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5112
I0925 21:54:07.601028  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.56209 (* 1 = 2.56209 loss)
I0925 21:54:07.738754  3547 solver.cpp:218] Iteration 36000 (5.73896 iter/s, 17.4248s/100 iters), loss = 0.201911
I0925 21:54:07.738782  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20191 (* 1 = 0.20191 loss)
I0925 21:54:07.738788  3547 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0925 21:54:21.680410  3547 solver.cpp:218] Iteration 36100 (7.17279 iter/s, 13.9416s/100 iters), loss = 0.214209
I0925 21:54:21.680440  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214209 (* 1 = 0.214209 loss)
I0925 21:54:21.680456  3547 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0925 21:54:35.620035  3547 solver.cpp:218] Iteration 36200 (7.17383 iter/s, 13.9396s/100 iters), loss = 0.12792
I0925 21:54:35.620175  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12792 (* 1 = 0.12792 loss)
I0925 21:54:35.620184  3547 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0925 21:54:49.563105  3547 solver.cpp:218] Iteration 36300 (7.17211 iter/s, 13.9429s/100 iters), loss = 0.221811
I0925 21:54:49.563146  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221811 (* 1 = 0.221811 loss)
I0925 21:54:49.563151  3547 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0925 21:55:03.509140  3547 solver.cpp:218] Iteration 36400 (7.17054 iter/s, 13.9459s/100 iters), loss = 0.13174
I0925 21:55:03.509172  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13174 (* 1 = 0.13174 loss)
I0925 21:55:03.509178  3547 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0925 21:55:16.759591  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:55:17.316941  3547 solver.cpp:330] Iteration 36500, Testing net (#0)
I0925 21:55:20.639324  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:55:20.777937  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5504
I0925 21:55:20.777973  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.9194 (* 1 = 1.9194 loss)
I0925 21:55:20.916697  3547 solver.cpp:218] Iteration 36500 (5.74466 iter/s, 17.4075s/100 iters), loss = 0.0873493
I0925 21:55:20.916738  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0873493 (* 1 = 0.0873493 loss)
I0925 21:55:20.916745  3547 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0925 21:55:34.861734  3547 solver.cpp:218] Iteration 36600 (7.17105 iter/s, 13.945s/100 iters), loss = 0.127779
I0925 21:55:34.861774  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127779 (* 1 = 0.127779 loss)
I0925 21:55:34.861780  3547 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0925 21:55:48.812889  3547 solver.cpp:218] Iteration 36700 (7.16791 iter/s, 13.9511s/100 iters), loss = 0.150111
I0925 21:55:48.812994  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150111 (* 1 = 0.150111 loss)
I0925 21:55:48.813001  3547 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0925 21:56:02.767676  3547 solver.cpp:218] Iteration 36800 (7.16608 iter/s, 13.9546s/100 iters), loss = 0.154728
I0925 21:56:02.767716  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154728 (* 1 = 0.154728 loss)
I0925 21:56:02.767722  3547 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0925 21:56:16.721026  3547 solver.cpp:218] Iteration 36900 (7.16678 iter/s, 13.9533s/100 iters), loss = 0.0956192
I0925 21:56:16.721067  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0956192 (* 1 = 0.0956192 loss)
I0925 21:56:16.721073  3547 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0925 21:56:29.978724  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:56:30.534960  3547 solver.cpp:330] Iteration 37000, Testing net (#0)
I0925 21:56:33.854130  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:56:33.994334  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6441
I0925 21:56:33.994360  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.46498 (* 1 = 1.46498 loss)
I0925 21:56:34.132179  3547 solver.cpp:218] Iteration 37000 (5.74348 iter/s, 17.4111s/100 iters), loss = 0.102234
I0925 21:56:34.132210  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102234 (* 1 = 0.102234 loss)
I0925 21:56:34.132217  3547 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0925 21:56:48.095088  3547 solver.cpp:218] Iteration 37100 (7.16187 iter/s, 13.9628s/100 iters), loss = 0.215689
I0925 21:56:48.095127  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215689 (* 1 = 0.215689 loss)
I0925 21:56:48.095134  3547 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0925 21:57:02.064260  3547 solver.cpp:218] Iteration 37200 (7.15866 iter/s, 13.9691s/100 iters), loss = 0.109016
I0925 21:57:02.064368  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109016 (* 1 = 0.109016 loss)
I0925 21:57:02.064384  3547 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0925 21:57:16.035481  3547 solver.cpp:218] Iteration 37300 (7.15765 iter/s, 13.9711s/100 iters), loss = 0.128827
I0925 21:57:16.035521  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128827 (* 1 = 0.128827 loss)
I0925 21:57:16.035527  3547 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0925 21:57:30.004073  3547 solver.cpp:218] Iteration 37400 (7.15896 iter/s, 13.9685s/100 iters), loss = 0.112118
I0925 21:57:30.004114  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112118 (* 1 = 0.112118 loss)
I0925 21:57:30.004120  3547 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0925 21:57:43.281750  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:57:43.840461  3547 solver.cpp:330] Iteration 37500, Testing net (#0)
I0925 21:57:47.161764  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:57:47.300118  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5803
I0925 21:57:47.300153  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.94033 (* 1 = 1.94033 loss)
I0925 21:57:47.439151  3547 solver.cpp:218] Iteration 37500 (5.7356 iter/s, 17.435s/100 iters), loss = 0.103815
I0925 21:57:47.439178  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103815 (* 1 = 0.103815 loss)
I0925 21:57:47.439185  3547 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0925 21:58:01.392081  3547 solver.cpp:218] Iteration 37600 (7.16699 iter/s, 13.9529s/100 iters), loss = 0.171234
I0925 21:58:01.392120  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171234 (* 1 = 0.171234 loss)
I0925 21:58:01.392127  3547 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0925 21:58:15.349069  3547 solver.cpp:218] Iteration 37700 (7.16491 iter/s, 13.9569s/100 iters), loss = 0.185444
I0925 21:58:15.349145  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185444 (* 1 = 0.185444 loss)
I0925 21:58:15.349153  3547 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0925 21:58:29.296025  3547 solver.cpp:218] Iteration 37800 (7.17009 iter/s, 13.9468s/100 iters), loss = 0.0909127
I0925 21:58:29.296066  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0909127 (* 1 = 0.0909127 loss)
I0925 21:58:29.296072  3547 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0925 21:58:43.250542  3547 solver.cpp:218] Iteration 37900 (7.16618 iter/s, 13.9544s/100 iters), loss = 0.156817
I0925 21:58:43.250583  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156817 (* 1 = 0.156817 loss)
I0925 21:58:43.250589  3547 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0925 21:58:56.510366  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:58:57.068591  3547 solver.cpp:330] Iteration 38000, Testing net (#0)
I0925 21:59:00.394383  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:59:00.532997  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7649
I0925 21:59:00.533021  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.743491 (* 1 = 0.743491 loss)
I0925 21:59:00.672147  3547 solver.cpp:218] Iteration 38000 (5.74003 iter/s, 17.4215s/100 iters), loss = 0.107007
I0925 21:59:00.672176  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107007 (* 1 = 0.107007 loss)
I0925 21:59:00.672183  3547 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0925 21:59:14.618190  3547 solver.cpp:218] Iteration 38100 (7.17053 iter/s, 13.946s/100 iters), loss = 0.120774
I0925 21:59:14.618219  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120774 (* 1 = 0.120774 loss)
I0925 21:59:14.618225  3547 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0925 21:59:28.564889  3547 solver.cpp:218] Iteration 38200 (7.17019 iter/s, 13.9466s/100 iters), loss = 0.110844
I0925 21:59:28.564999  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110844 (* 1 = 0.110844 loss)
I0925 21:59:28.565008  3547 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0925 21:59:42.511767  3547 solver.cpp:218] Iteration 38300 (7.17014 iter/s, 13.9467s/100 iters), loss = 0.19441
I0925 21:59:42.511807  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19441 (* 1 = 0.19441 loss)
I0925 21:59:42.511813  3547 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0925 21:59:56.463675  3547 solver.cpp:218] Iteration 38400 (7.16752 iter/s, 13.9518s/100 iters), loss = 0.10771
I0925 21:59:56.463706  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107709 (* 1 = 0.107709 loss)
I0925 21:59:56.463711  3547 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0925 22:00:09.716306  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:00:10.273283  3547 solver.cpp:330] Iteration 38500, Testing net (#0)
I0925 22:00:13.594588  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:00:13.732892  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6064
I0925 22:00:13.732928  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.71892 (* 1 = 1.71892 loss)
I0925 22:00:13.871433  3547 solver.cpp:218] Iteration 38500 (5.74459 iter/s, 17.4077s/100 iters), loss = 0.220869
I0925 22:00:13.871462  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220869 (* 1 = 0.220869 loss)
I0925 22:00:13.871469  3547 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0925 22:00:27.829836  3547 solver.cpp:218] Iteration 38600 (7.16418 iter/s, 13.9583s/100 iters), loss = 0.156187
I0925 22:00:27.829875  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156187 (* 1 = 0.156187 loss)
I0925 22:00:27.829881  3547 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0925 22:00:41.780973  3547 solver.cpp:218] Iteration 38700 (7.16792 iter/s, 13.9511s/100 iters), loss = 0.136465
I0925 22:00:41.781077  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136465 (* 1 = 0.136465 loss)
I0925 22:00:41.781085  3547 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0925 22:00:55.734565  3547 solver.cpp:218] Iteration 38800 (7.16669 iter/s, 13.9534s/100 iters), loss = 0.14575
I0925 22:00:55.734594  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14575 (* 1 = 0.14575 loss)
I0925 22:00:55.734601  3547 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0925 22:01:09.695670  3547 solver.cpp:218] Iteration 38900 (7.1628 iter/s, 13.961s/100 iters), loss = 0.113521
I0925 22:01:09.695700  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113521 (* 1 = 0.113521 loss)
I0925 22:01:09.695708  3547 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0925 22:01:22.957056  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:01:23.515897  3547 solver.cpp:330] Iteration 39000, Testing net (#0)
I0925 22:01:26.837543  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:01:26.976033  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6694
I0925 22:01:26.976069  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.30735 (* 1 = 1.30735 loss)
I0925 22:01:27.114329  3547 solver.cpp:218] Iteration 39000 (5.741 iter/s, 17.4186s/100 iters), loss = 0.124503
I0925 22:01:27.114358  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124503 (* 1 = 0.124503 loss)
I0925 22:01:27.114364  3547 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0925 22:01:41.064821  3547 solver.cpp:218] Iteration 39100 (7.16825 iter/s, 13.9504s/100 iters), loss = 0.123025
I0925 22:01:41.064851  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123024 (* 1 = 0.123024 loss)
I0925 22:01:41.064857  3547 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0925 22:01:55.015579  3547 solver.cpp:218] Iteration 39200 (7.16811 iter/s, 13.9507s/100 iters), loss = 0.191727
I0925 22:01:55.015691  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191727 (* 1 = 0.191727 loss)
I0925 22:01:55.015712  3547 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0925 22:02:08.966245  3547 solver.cpp:218] Iteration 39300 (7.1682 iter/s, 13.9505s/100 iters), loss = 0.0519743
I0925 22:02:08.966285  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519741 (* 1 = 0.0519741 loss)
I0925 22:02:08.966291  3547 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0925 22:02:22.921092  3547 solver.cpp:218] Iteration 39400 (7.16601 iter/s, 13.9548s/100 iters), loss = 0.161628
I0925 22:02:22.921131  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161628 (* 1 = 0.161628 loss)
I0925 22:02:22.921136  3547 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0925 22:02:36.178175  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:02:36.735996  3547 solver.cpp:330] Iteration 39500, Testing net (#0)
I0925 22:02:40.057227  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:02:40.195792  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7154
I0925 22:02:40.195828  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.956535 (* 1 = 0.956535 loss)
I0925 22:02:40.333991  3547 solver.cpp:218] Iteration 39500 (5.7429 iter/s, 17.4128s/100 iters), loss = 0.144804
I0925 22:02:40.334019  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144804 (* 1 = 0.144804 loss)
I0925 22:02:40.334026  3547 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0925 22:02:54.270437  3547 solver.cpp:218] Iteration 39600 (7.17547 iter/s, 13.9364s/100 iters), loss = 0.183323
I0925 22:02:54.270478  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183323 (* 1 = 0.183323 loss)
I0925 22:02:54.270483  3547 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0925 22:03:08.217854  3547 solver.cpp:218] Iteration 39700 (7.16983 iter/s, 13.9473s/100 iters), loss = 0.166364
I0925 22:03:08.217957  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166364 (* 1 = 0.166364 loss)
I0925 22:03:08.217973  3547 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0925 22:03:22.162830  3547 solver.cpp:218] Iteration 39800 (7.17112 iter/s, 13.9448s/100 iters), loss = 0.220066
I0925 22:03:22.162869  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220066 (* 1 = 0.220066 loss)
I0925 22:03:22.162875  3547 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0925 22:03:36.104138  3547 solver.cpp:218] Iteration 39900 (7.17297 iter/s, 13.9412s/100 iters), loss = 0.0705861
I0925 22:03:36.104168  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0705861 (* 1 = 0.0705861 loss)
I0925 22:03:36.104174  3547 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0925 22:03:49.351815  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:03:49.910691  3547 solver.cpp:330] Iteration 40000, Testing net (#0)
I0925 22:03:53.231075  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:03:53.369412  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6085
I0925 22:03:53.369447  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.53868 (* 1 = 1.53868 loss)
I0925 22:03:53.508123  3547 solver.cpp:218] Iteration 40000 (5.74584 iter/s, 17.4039s/100 iters), loss = 0.116626
I0925 22:03:53.508152  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116626 (* 1 = 0.116626 loss)
I0925 22:03:53.508157  3547 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0925 22:03:53.508160  3547 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0925 22:04:07.456815  3547 solver.cpp:218] Iteration 40100 (7.16917 iter/s, 13.9486s/100 iters), loss = 0.136373
I0925 22:04:07.456845  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136373 (* 1 = 0.136373 loss)
I0925 22:04:07.456851  3547 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0925 22:04:21.404237  3547 solver.cpp:218] Iteration 40200 (7.16982 iter/s, 13.9473s/100 iters), loss = 0.14352
I0925 22:04:21.404345  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14352 (* 1 = 0.14352 loss)
I0925 22:04:21.404351  3547 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0925 22:04:35.351856  3547 solver.cpp:218] Iteration 40300 (7.16976 iter/s, 13.9475s/100 iters), loss = 0.14475
I0925 22:04:35.351886  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14475 (* 1 = 0.14475 loss)
I0925 22:04:35.351891  3547 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0925 22:04:49.303565  3547 solver.cpp:218] Iteration 40400 (7.16762 iter/s, 13.9516s/100 iters), loss = 0.0327234
I0925 22:04:49.303606  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327234 (* 1 = 0.0327234 loss)
I0925 22:04:49.303611  3547 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0925 22:05:02.556713  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:05:03.114521  3547 solver.cpp:330] Iteration 40500, Testing net (#0)
I0925 22:05:06.435247  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:05:06.573559  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8783
I0925 22:05:06.573595  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374344 (* 1 = 0.374344 loss)
I0925 22:05:06.711786  3547 solver.cpp:218] Iteration 40500 (5.74444 iter/s, 17.4081s/100 iters), loss = 0.036378
I0925 22:05:06.711815  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036378 (* 1 = 0.036378 loss)
I0925 22:05:06.711822  3547 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0925 22:05:20.648998  3547 solver.cpp:218] Iteration 40600 (7.17508 iter/s, 13.9371s/100 iters), loss = 0.0231295
I0925 22:05:20.649039  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231295 (* 1 = 0.0231295 loss)
I0925 22:05:20.649044  3547 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0925 22:05:34.583740  3547 solver.cpp:218] Iteration 40700 (7.17635 iter/s, 13.9347s/100 iters), loss = 0.0845678
I0925 22:05:34.583847  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0845677 (* 1 = 0.0845677 loss)
I0925 22:05:34.583864  3547 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0925 22:05:48.520969  3547 solver.cpp:218] Iteration 40800 (7.1751 iter/s, 13.9371s/100 iters), loss = 0.0697992
I0925 22:05:48.521000  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0697992 (* 1 = 0.0697992 loss)
I0925 22:05:48.521006  3547 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0925 22:06:02.457213  3547 solver.cpp:218] Iteration 40900 (7.17557 iter/s, 13.9362s/100 iters), loss = 0.0143474
I0925 22:06:02.457244  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143474 (* 1 = 0.0143474 loss)
I0925 22:06:02.457252  3547 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0925 22:06:15.701185  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:06:16.258232  3547 solver.cpp:330] Iteration 41000, Testing net (#0)
I0925 22:06:19.579269  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:06:19.717618  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9081
I0925 22:06:19.717654  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.275005 (* 1 = 0.275005 loss)
I0925 22:06:19.856665  3547 solver.cpp:218] Iteration 41000 (5.74734 iter/s, 17.3994s/100 iters), loss = 0.0230468
I0925 22:06:19.856695  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230467 (* 1 = 0.0230467 loss)
I0925 22:06:19.856701  3547 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0925 22:06:33.808403  3547 solver.cpp:218] Iteration 41100 (7.16761 iter/s, 13.9517s/100 iters), loss = 0.0173482
I0925 22:06:33.808432  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173482 (* 1 = 0.0173482 loss)
I0925 22:06:33.808439  3547 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0925 22:06:47.762332  3547 solver.cpp:218] Iteration 41200 (7.16648 iter/s, 13.9539s/100 iters), loss = 0.0674316
I0925 22:06:47.762429  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0674316 (* 1 = 0.0674316 loss)
I0925 22:06:47.762446  3547 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0925 22:07:01.711433  3547 solver.cpp:218] Iteration 41300 (7.16899 iter/s, 13.949s/100 iters), loss = 0.0975453
I0925 22:07:01.711473  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0975452 (* 1 = 0.0975452 loss)
I0925 22:07:01.711479  3547 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0925 22:07:15.666146  3547 solver.cpp:218] Iteration 41400 (7.16608 iter/s, 13.9546s/100 iters), loss = 0.0186668
I0925 22:07:15.666177  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186667 (* 1 = 0.0186667 loss)
I0925 22:07:15.666193  3547 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0925 22:07:28.927949  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:07:29.485641  3547 solver.cpp:330] Iteration 41500, Testing net (#0)
I0925 22:07:32.807693  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:07:32.946163  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9092
I0925 22:07:32.946189  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279717 (* 1 = 0.279717 loss)
I0925 22:07:33.084091  3547 solver.cpp:218] Iteration 41500 (5.74123 iter/s, 17.4179s/100 iters), loss = 0.0763718
I0925 22:07:33.084120  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0763717 (* 1 = 0.0763717 loss)
I0925 22:07:33.084126  3547 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0925 22:07:47.028864  3547 solver.cpp:218] Iteration 41600 (7.17119 iter/s, 13.9447s/100 iters), loss = 0.0440336
I0925 22:07:47.028894  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440335 (* 1 = 0.0440335 loss)
I0925 22:07:47.028900  3547 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0925 22:08:00.970566  3547 solver.cpp:218] Iteration 41700 (7.17276 iter/s, 13.9416s/100 iters), loss = 0.0582329
I0925 22:08:00.970695  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0582328 (* 1 = 0.0582328 loss)
I0925 22:08:00.970703  3547 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0925 22:08:14.911620  3547 solver.cpp:218] Iteration 41800 (7.17314 iter/s, 13.9409s/100 iters), loss = 0.067845
I0925 22:08:14.911659  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.067845 (* 1 = 0.067845 loss)
I0925 22:08:14.911665  3547 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0925 22:08:28.861444  3547 solver.cpp:218] Iteration 41900 (7.16859 iter/s, 13.9497s/100 iters), loss = 0.0265064
I0925 22:08:28.861485  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265064 (* 1 = 0.0265064 loss)
I0925 22:08:28.861490  3547 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0925 22:08:42.112164  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:08:42.669461  3547 solver.cpp:330] Iteration 42000, Testing net (#0)
I0925 22:08:45.992980  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:08:46.131717  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I0925 22:08:46.131753  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264614 (* 1 = 0.264614 loss)
I0925 22:08:46.270802  3547 solver.cpp:218] Iteration 42000 (5.74407 iter/s, 17.4093s/100 iters), loss = 0.0282088
I0925 22:08:46.270829  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282088 (* 1 = 0.0282088 loss)
I0925 22:08:46.270836  3547 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0925 22:09:00.218039  3547 solver.cpp:218] Iteration 42100 (7.16992 iter/s, 13.9472s/100 iters), loss = 0.0372028
I0925 22:09:00.218072  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372027 (* 1 = 0.0372027 loss)
I0925 22:09:00.218080  3547 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0925 22:09:14.165307  3547 solver.cpp:218] Iteration 42200 (7.1699 iter/s, 13.9472s/100 iters), loss = 0.0523379
I0925 22:09:14.165411  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0523378 (* 1 = 0.0523378 loss)
I0925 22:09:14.165418  3547 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0925 22:09:28.113608  3547 solver.cpp:218] Iteration 42300 (7.16941 iter/s, 13.9482s/100 iters), loss = 0.0625113
I0925 22:09:28.113651  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0625113 (* 1 = 0.0625113 loss)
I0925 22:09:28.113656  3547 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0925 22:09:42.065440  3547 solver.cpp:218] Iteration 42400 (7.16756 iter/s, 13.9517s/100 iters), loss = 0.0155473
I0925 22:09:42.065480  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155473 (* 1 = 0.0155473 loss)
I0925 22:09:42.065486  3547 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0925 22:09:55.323477  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:09:55.881920  3547 solver.cpp:330] Iteration 42500, Testing net (#0)
I0925 22:09:59.202852  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:09:59.341298  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I0925 22:09:59.341323  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270446 (* 1 = 0.270446 loss)
I0925 22:09:59.479776  3547 solver.cpp:218] Iteration 42500 (5.74243 iter/s, 17.4142s/100 iters), loss = 0.0233134
I0925 22:09:59.479807  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233133 (* 1 = 0.0233133 loss)
I0925 22:09:59.479813  3547 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0925 22:10:13.432989  3547 solver.cpp:218] Iteration 42600 (7.16685 iter/s, 13.9531s/100 iters), loss = 0.0237312
I0925 22:10:13.433018  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237311 (* 1 = 0.0237311 loss)
I0925 22:10:13.433024  3547 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0925 22:10:27.381691  3547 solver.cpp:218] Iteration 42700 (7.16916 iter/s, 13.9486s/100 iters), loss = 0.0275008
I0925 22:10:27.381798  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275007 (* 1 = 0.0275007 loss)
I0925 22:10:27.381814  3547 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0925 22:10:41.329560  3547 solver.cpp:218] Iteration 42800 (7.16963 iter/s, 13.9477s/100 iters), loss = 0.0136371
I0925 22:10:41.329601  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136371 (* 1 = 0.0136371 loss)
I0925 22:10:41.329607  3547 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0925 22:10:55.289301  3547 solver.cpp:218] Iteration 42900 (7.1635 iter/s, 13.9597s/100 iters), loss = 0.0114175
I0925 22:10:55.289335  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114175 (* 1 = 0.0114175 loss)
I0925 22:10:55.289342  3547 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0925 22:11:08.553618  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:11:09.110728  3547 solver.cpp:330] Iteration 43000, Testing net (#0)
I0925 22:11:12.432124  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:11:12.570567  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I0925 22:11:12.570592  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282975 (* 1 = 0.282975 loss)
I0925 22:11:12.709048  3547 solver.cpp:218] Iteration 43000 (5.74064 iter/s, 17.4197s/100 iters), loss = 0.00851826
I0925 22:11:12.709086  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00851824 (* 1 = 0.00851824 loss)
I0925 22:11:12.709094  3547 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0925 22:11:26.650229  3547 solver.cpp:218] Iteration 43100 (7.17304 iter/s, 13.9411s/100 iters), loss = 0.0187401
I0925 22:11:26.650260  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187401 (* 1 = 0.0187401 loss)
I0925 22:11:26.650266  3547 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0925 22:11:40.592947  3547 solver.cpp:218] Iteration 43200 (7.17224 iter/s, 13.9426s/100 iters), loss = 0.0215887
I0925 22:11:40.593030  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215887 (* 1 = 0.0215887 loss)
I0925 22:11:40.593046  3547 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0925 22:11:54.526780  3547 solver.cpp:218] Iteration 43300 (7.17684 iter/s, 13.9337s/100 iters), loss = 0.0296313
I0925 22:11:54.526811  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296313 (* 1 = 0.0296313 loss)
I0925 22:11:54.526818  3547 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0925 22:12:08.464617  3547 solver.cpp:218] Iteration 43400 (7.17475 iter/s, 13.9378s/100 iters), loss = 0.0519084
I0925 22:12:08.464658  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519084 (* 1 = 0.0519084 loss)
I0925 22:12:08.464663  3547 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0925 22:12:21.720365  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:12:22.277704  3547 solver.cpp:330] Iteration 43500, Testing net (#0)
I0925 22:12:25.600278  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:12:25.738677  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I0925 22:12:25.738703  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295961 (* 1 = 0.295961 loss)
I0925 22:12:25.877017  3547 solver.cpp:218] Iteration 43500 (5.74306 iter/s, 17.4123s/100 iters), loss = 0.0231355
I0925 22:12:25.877046  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231355 (* 1 = 0.0231355 loss)
I0925 22:12:25.877053  3547 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0925 22:12:39.834900  3547 solver.cpp:218] Iteration 43600 (7.16445 iter/s, 13.9578s/100 iters), loss = 0.0241403
I0925 22:12:39.834933  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241402 (* 1 = 0.0241402 loss)
I0925 22:12:39.834939  3547 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0925 22:12:53.792371  3547 solver.cpp:218] Iteration 43700 (7.16466 iter/s, 13.9574s/100 iters), loss = 0.0330834
I0925 22:12:53.792484  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330833 (* 1 = 0.0330833 loss)
I0925 22:12:53.792492  3547 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0925 22:13:07.749883  3547 solver.cpp:218] Iteration 43800 (7.16468 iter/s, 13.9574s/100 iters), loss = 0.0418039
I0925 22:13:07.749915  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418039 (* 1 = 0.0418039 loss)
I0925 22:13:07.749922  3547 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0925 22:13:21.714912  3547 solver.cpp:218] Iteration 43900 (7.16078 iter/s, 13.965s/100 iters), loss = 0.0106846
I0925 22:13:21.714952  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106846 (* 1 = 0.0106846 loss)
I0925 22:13:21.714959  3547 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0925 22:13:34.974282  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:13:35.534261  3547 solver.cpp:330] Iteration 44000, Testing net (#0)
I0925 22:13:38.855031  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:13:38.993290  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0925 22:13:38.993317  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269952 (* 1 = 0.269952 loss)
I0925 22:13:39.131978  3547 solver.cpp:218] Iteration 44000 (5.74153 iter/s, 17.417s/100 iters), loss = 0.0152611
I0925 22:13:39.132006  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152611 (* 1 = 0.0152611 loss)
I0925 22:13:39.132012  3547 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0925 22:13:53.069881  3547 solver.cpp:218] Iteration 44100 (7.17472 iter/s, 13.9378s/100 iters), loss = 0.0171564
I0925 22:13:53.069921  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171564 (* 1 = 0.0171564 loss)
I0925 22:13:53.069927  3547 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0925 22:14:07.015312  3547 solver.cpp:218] Iteration 44200 (7.17085 iter/s, 13.9453s/100 iters), loss = 0.0366482
I0925 22:14:07.015452  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366482 (* 1 = 0.0366482 loss)
I0925 22:14:07.015460  3547 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0925 22:14:20.958254  3547 solver.cpp:218] Iteration 44300 (7.17218 iter/s, 13.9428s/100 iters), loss = 0.016349
I0925 22:14:20.958286  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016349 (* 1 = 0.016349 loss)
I0925 22:14:20.958292  3547 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0925 22:14:34.904749  3547 solver.cpp:218] Iteration 44400 (7.1703 iter/s, 13.9464s/100 iters), loss = 0.00515734
I0925 22:14:34.904790  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515733 (* 1 = 0.00515733 loss)
I0925 22:14:34.904796  3547 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0925 22:14:48.155895  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:14:48.713142  3547 solver.cpp:330] Iteration 44500, Testing net (#0)
I0925 22:14:52.034884  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:14:52.173065  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I0925 22:14:52.173101  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313433 (* 1 = 0.313433 loss)
I0925 22:14:52.311326  3547 solver.cpp:218] Iteration 44500 (5.74499 iter/s, 17.4065s/100 iters), loss = 0.0128982
I0925 22:14:52.311353  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128982 (* 1 = 0.0128982 loss)
I0925 22:14:52.311359  3547 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0925 22:15:06.264194  3547 solver.cpp:218] Iteration 44600 (7.16702 iter/s, 13.9528s/100 iters), loss = 0.017967
I0925 22:15:06.264235  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017967 (* 1 = 0.017967 loss)
I0925 22:15:06.264240  3547 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0925 22:15:20.215183  3547 solver.cpp:218] Iteration 44700 (7.16799 iter/s, 13.9509s/100 iters), loss = 0.0591098
I0925 22:15:20.215339  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0591098 (* 1 = 0.0591098 loss)
I0925 22:15:20.215348  3547 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0925 22:15:34.175004  3547 solver.cpp:218] Iteration 44800 (7.16352 iter/s, 13.9596s/100 iters), loss = 0.0406994
I0925 22:15:34.175032  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406993 (* 1 = 0.0406993 loss)
I0925 22:15:34.175038  3547 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0925 22:15:48.130154  3547 solver.cpp:218] Iteration 44900 (7.16585 iter/s, 13.9551s/100 iters), loss = 0.00388679
I0925 22:15:48.130195  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388674 (* 1 = 0.00388674 loss)
I0925 22:15:48.130201  3547 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0925 22:16:01.393044  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:16:01.951627  3547 solver.cpp:330] Iteration 45000, Testing net (#0)
I0925 22:16:05.271984  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:16:05.410573  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I0925 22:16:05.410609  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292646 (* 1 = 0.292646 loss)
I0925 22:16:05.548836  3547 solver.cpp:218] Iteration 45000 (5.74099 iter/s, 17.4186s/100 iters), loss = 0.0115502
I0925 22:16:05.548866  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115501 (* 1 = 0.0115501 loss)
I0925 22:16:05.548872  3547 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0925 22:16:19.488685  3547 solver.cpp:218] Iteration 45100 (7.17372 iter/s, 13.9398s/100 iters), loss = 0.0179646
I0925 22:16:19.488716  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179646 (* 1 = 0.0179646 loss)
I0925 22:16:19.488723  3547 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0925 22:16:33.435972  3547 solver.cpp:218] Iteration 45200 (7.16989 iter/s, 13.9472s/100 iters), loss = 0.0318679
I0925 22:16:33.436106  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318678 (* 1 = 0.0318678 loss)
I0925 22:16:33.436113  3547 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0925 22:16:47.383766  3547 solver.cpp:218] Iteration 45300 (7.16968 iter/s, 13.9476s/100 iters), loss = 0.0148542
I0925 22:16:47.383806  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148541 (* 1 = 0.0148541 loss)
I0925 22:16:47.383812  3547 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0925 22:17:01.320901  3547 solver.cpp:218] Iteration 45400 (7.17512 iter/s, 13.937s/100 iters), loss = 0.0148055
I0925 22:17:01.320941  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148055 (* 1 = 0.0148055 loss)
I0925 22:17:01.320947  3547 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0925 22:17:14.566159  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:17:15.122615  3547 solver.cpp:330] Iteration 45500, Testing net (#0)
I0925 22:17:18.444680  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:17:18.582962  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I0925 22:17:18.582998  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285849 (* 1 = 0.285849 loss)
I0925 22:17:18.721550  3547 solver.cpp:218] Iteration 45500 (5.74694 iter/s, 17.4006s/100 iters), loss = 0.0114223
I0925 22:17:18.721581  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114223 (* 1 = 0.0114223 loss)
I0925 22:17:18.721587  3547 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0925 22:17:32.681710  3547 solver.cpp:218] Iteration 45600 (7.16328 iter/s, 13.9601s/100 iters), loss = 0.0208191
I0925 22:17:32.681738  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208191 (* 1 = 0.0208191 loss)
I0925 22:17:32.681744  3547 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0925 22:17:46.640408  3547 solver.cpp:218] Iteration 45700 (7.16403 iter/s, 13.9586s/100 iters), loss = 0.0110579
I0925 22:17:46.640517  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110579 (* 1 = 0.0110579 loss)
I0925 22:17:46.640525  3547 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0925 22:18:00.608495  3547 solver.cpp:218] Iteration 45800 (7.15925 iter/s, 13.9679s/100 iters), loss = 0.0105816
I0925 22:18:00.608536  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105815 (* 1 = 0.0105815 loss)
I0925 22:18:00.608542  3547 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0925 22:18:14.571539  3547 solver.cpp:218] Iteration 45900 (7.16181 iter/s, 13.963s/100 iters), loss = 0.015456
I0925 22:18:14.571580  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154559 (* 1 = 0.0154559 loss)
I0925 22:18:14.571586  3547 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0925 22:18:27.842522  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:18:28.400207  3547 solver.cpp:330] Iteration 46000, Testing net (#0)
I0925 22:18:31.721712  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:18:31.860481  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I0925 22:18:31.860508  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298135 (* 1 = 0.298135 loss)
I0925 22:18:31.999011  3547 solver.cpp:218] Iteration 46000 (5.7381 iter/s, 17.4274s/100 iters), loss = 0.0230186
I0925 22:18:31.999039  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230185 (* 1 = 0.0230185 loss)
I0925 22:18:31.999045  3547 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0925 22:18:45.936252  3547 solver.cpp:218] Iteration 46100 (7.17506 iter/s, 13.9372s/100 iters), loss = 0.0153593
I0925 22:18:45.936282  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153592 (* 1 = 0.0153592 loss)
I0925 22:18:45.936290  3547 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0925 22:18:59.878274  3547 solver.cpp:218] Iteration 46200 (7.1726 iter/s, 13.9419s/100 iters), loss = 0.0280396
I0925 22:18:59.878412  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280395 (* 1 = 0.0280395 loss)
I0925 22:18:59.878419  3547 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0925 22:19:13.821419  3547 solver.cpp:218] Iteration 46300 (7.17207 iter/s, 13.943s/100 iters), loss = 0.0175703
I0925 22:19:13.821460  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175702 (* 1 = 0.0175702 loss)
I0925 22:19:13.821466  3547 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0925 22:19:27.771941  3547 solver.cpp:218] Iteration 46400 (7.16823 iter/s, 13.9504s/100 iters), loss = 0.0110041
I0925 22:19:27.771975  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011004 (* 1 = 0.011004 loss)
I0925 22:19:27.771991  3547 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0925 22:19:41.023613  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:19:41.581622  3547 solver.cpp:330] Iteration 46500, Testing net (#0)
I0925 22:19:44.902130  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:19:45.040702  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0925 22:19:45.040737  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288785 (* 1 = 0.288785 loss)
I0925 22:19:45.179186  3547 solver.cpp:218] Iteration 46500 (5.74476 iter/s, 17.4072s/100 iters), loss = 0.00339863
I0925 22:19:45.179217  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339856 (* 1 = 0.00339856 loss)
I0925 22:19:45.179224  3547 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0925 22:19:59.144532  3547 solver.cpp:218] Iteration 46600 (7.16062 iter/s, 13.9653s/100 iters), loss = 0.023504
I0925 22:19:59.144572  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235039 (* 1 = 0.0235039 loss)
I0925 22:19:59.144578  3547 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0925 22:20:13.116116  3547 solver.cpp:218] Iteration 46700 (7.15743 iter/s, 13.9715s/100 iters), loss = 0.00428693
I0925 22:20:13.116242  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428685 (* 1 = 0.00428685 loss)
I0925 22:20:13.116250  3547 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0925 22:20:27.087852  3547 solver.cpp:218] Iteration 46800 (7.15739 iter/s, 13.9716s/100 iters), loss = 0.00906138
I0925 22:20:27.087891  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00906129 (* 1 = 0.00906129 loss)
I0925 22:20:27.087898  3547 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0925 22:20:41.051769  3547 solver.cpp:218] Iteration 46900 (7.16136 iter/s, 13.9638s/100 iters), loss = 0.0103905
I0925 22:20:41.051798  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103904 (* 1 = 0.0103904 loss)
I0925 22:20:41.051805  3547 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0925 22:20:54.323501  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:20:54.882336  3547 solver.cpp:330] Iteration 47000, Testing net (#0)
I0925 22:20:58.203387  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:20:58.341562  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I0925 22:20:58.341598  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316173 (* 1 = 0.316173 loss)
I0925 22:20:58.480252  3547 solver.cpp:218] Iteration 47000 (5.73776 iter/s, 17.4284s/100 iters), loss = 0.00393808
I0925 22:20:58.480279  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393799 (* 1 = 0.00393799 loss)
I0925 22:20:58.480286  3547 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0925 22:21:12.429883  3547 solver.cpp:218] Iteration 47100 (7.16869 iter/s, 13.9496s/100 iters), loss = 0.0169013
I0925 22:21:12.429922  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169012 (* 1 = 0.0169012 loss)
I0925 22:21:12.429927  3547 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0925 22:21:26.376013  3547 solver.cpp:218] Iteration 47200 (7.17049 iter/s, 13.946s/100 iters), loss = 0.0343526
I0925 22:21:26.376121  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343526 (* 1 = 0.0343526 loss)
I0925 22:21:26.376137  3547 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0925 22:21:40.324028  3547 solver.cpp:218] Iteration 47300 (7.16956 iter/s, 13.9479s/100 iters), loss = 0.0279242
I0925 22:21:40.324067  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279241 (* 1 = 0.0279241 loss)
I0925 22:21:40.324074  3547 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0925 22:21:54.263550  3547 solver.cpp:218] Iteration 47400 (7.17389 iter/s, 13.9394s/100 iters), loss = 0.0039976
I0925 22:21:54.263579  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399752 (* 1 = 0.00399752 loss)
I0925 22:21:54.263586  3547 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0925 22:22:07.516065  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:22:08.073904  3547 solver.cpp:330] Iteration 47500, Testing net (#0)
I0925 22:22:11.394664  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:22:11.533618  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0925 22:22:11.533653  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301709 (* 1 = 0.301709 loss)
I0925 22:22:11.671900  3547 solver.cpp:218] Iteration 47500 (5.7444 iter/s, 17.4083s/100 iters), loss = 0.00669564
I0925 22:22:11.671931  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669556 (* 1 = 0.00669556 loss)
I0925 22:22:11.671937  3547 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0925 22:22:25.639380  3547 solver.cpp:218] Iteration 47600 (7.15953 iter/s, 13.9674s/100 iters), loss = 0.00943116
I0925 22:22:25.639410  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943108 (* 1 = 0.00943108 loss)
I0925 22:22:25.639416  3547 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0925 22:22:39.610129  3547 solver.cpp:218] Iteration 47700 (7.15785 iter/s, 13.9707s/100 iters), loss = 0.015031
I0925 22:22:39.610261  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015031 (* 1 = 0.015031 loss)
I0925 22:22:39.610270  3547 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0925 22:22:53.577178  3547 solver.cpp:218] Iteration 47800 (7.1598 iter/s, 13.9669s/100 iters), loss = 0.00530032
I0925 22:22:53.577208  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530025 (* 1 = 0.00530025 loss)
I0925 22:22:53.577214  3547 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0925 22:23:07.542587  3547 solver.cpp:218] Iteration 47900 (7.16059 iter/s, 13.9653s/100 iters), loss = 0.00337051
I0925 22:23:07.542626  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337045 (* 1 = 0.00337045 loss)
I0925 22:23:07.542632  3547 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0925 22:23:20.817895  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:23:21.377995  3547 solver.cpp:330] Iteration 48000, Testing net (#0)
I0925 22:23:24.699730  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:23:24.838515  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I0925 22:23:24.838548  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308516 (* 1 = 0.308516 loss)
I0925 22:23:24.977177  3547 solver.cpp:218] Iteration 48000 (5.73575 iter/s, 17.4345s/100 iters), loss = 0.00671649
I0925 22:23:24.977205  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671643 (* 1 = 0.00671643 loss)
I0925 22:23:24.977211  3547 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0925 22:23:38.925498  3547 solver.cpp:218] Iteration 48100 (7.16936 iter/s, 13.9482s/100 iters), loss = 0.0155984
I0925 22:23:38.925539  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155984 (* 1 = 0.0155984 loss)
I0925 22:23:38.925544  3547 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0925 22:23:52.876301  3547 solver.cpp:218] Iteration 48200 (7.16809 iter/s, 13.9507s/100 iters), loss = 0.0105279
I0925 22:23:52.876435  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105278 (* 1 = 0.0105278 loss)
I0925 22:23:52.876442  3547 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0925 22:24:06.833945  3547 solver.cpp:218] Iteration 48300 (7.16462 iter/s, 13.9575s/100 iters), loss = 0.0368216
I0925 22:24:06.833976  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368215 (* 1 = 0.0368215 loss)
I0925 22:24:06.833982  3547 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0925 22:24:20.790174  3547 solver.cpp:218] Iteration 48400 (7.1653 iter/s, 13.9562s/100 iters), loss = 0.00360723
I0925 22:24:20.790215  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360717 (* 1 = 0.00360717 loss)
I0925 22:24:20.790221  3547 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0925 22:24:34.043359  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:24:34.601969  3547 solver.cpp:330] Iteration 48500, Testing net (#0)
I0925 22:24:37.924734  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:24:38.062983  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I0925 22:24:38.063009  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286964 (* 1 = 0.286964 loss)
I0925 22:24:38.201750  3547 solver.cpp:218] Iteration 48500 (5.74334 iter/s, 17.4115s/100 iters), loss = 0.00132025
I0925 22:24:38.201781  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132019 (* 1 = 0.00132019 loss)
I0925 22:24:38.201787  3547 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0925 22:24:52.159684  3547 solver.cpp:218] Iteration 48600 (7.16442 iter/s, 13.9579s/100 iters), loss = 0.00685608
I0925 22:24:52.159724  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685601 (* 1 = 0.00685601 loss)
I0925 22:24:52.159730  3547 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0925 22:25:06.124187  3547 solver.cpp:218] Iteration 48700 (7.16106 iter/s, 13.9644s/100 iters), loss = 0.0107079
I0925 22:25:06.124342  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107078 (* 1 = 0.0107078 loss)
I0925 22:25:06.124351  3547 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0925 22:25:20.086836  3547 solver.cpp:218] Iteration 48800 (7.16206 iter/s, 13.9625s/100 iters), loss = 0.00357848
I0925 22:25:20.086866  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035784 (* 1 = 0.0035784 loss)
I0925 22:25:20.086871  3547 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0925 22:25:34.044095  3547 solver.cpp:218] Iteration 48900 (7.16477 iter/s, 13.9572s/100 iters), loss = 0.016185
I0925 22:25:34.044134  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161849 (* 1 = 0.0161849 loss)
I0925 22:25:34.044140  3547 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0925 22:25:47.309875  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:25:47.867856  3547 solver.cpp:330] Iteration 49000, Testing net (#0)
I0925 22:25:51.190119  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:25:51.328888  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0925 22:25:51.328915  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291459 (* 1 = 0.291459 loss)
I0925 22:25:51.468936  3547 solver.cpp:218] Iteration 49000 (5.73897 iter/s, 17.4247s/100 iters), loss = 0.00429172
I0925 22:25:51.468971  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429166 (* 1 = 0.00429166 loss)
I0925 22:25:51.468981  3547 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0925 22:26:05.419016  3547 solver.cpp:218] Iteration 49100 (7.16846 iter/s, 13.95s/100 iters), loss = 0.00874246
I0925 22:26:05.419049  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087424 (* 1 = 0.0087424 loss)
I0925 22:26:05.419066  3547 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0925 22:26:19.376741  3547 solver.cpp:218] Iteration 49200 (7.16453 iter/s, 13.9576s/100 iters), loss = 0.013182
I0925 22:26:19.376857  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131819 (* 1 = 0.0131819 loss)
I0925 22:26:19.376876  3547 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0925 22:26:33.333211  3547 solver.cpp:218] Iteration 49300 (7.16521 iter/s, 13.9563s/100 iters), loss = 0.0161421
I0925 22:26:33.333245  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161421 (* 1 = 0.0161421 loss)
I0925 22:26:33.333263  3547 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0925 22:26:47.292058  3547 solver.cpp:218] Iteration 49400 (7.16395 iter/s, 13.9588s/100 iters), loss = 0.00266054
I0925 22:26:47.292091  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266049 (* 1 = 0.00266049 loss)
I0925 22:26:47.292109  3547 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0925 22:27:00.557032  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:27:01.115440  3547 solver.cpp:330] Iteration 49500, Testing net (#0)
I0925 22:27:04.438415  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:27:04.577414  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0925 22:27:04.577440  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303245 (* 1 = 0.303245 loss)
I0925 22:27:04.715512  3547 solver.cpp:218] Iteration 49500 (5.73942 iter/s, 17.4234s/100 iters), loss = 0.00191929
I0925 22:27:04.715544  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191923 (* 1 = 0.00191923 loss)
I0925 22:27:04.715554  3547 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0925 22:27:18.647857  3547 solver.cpp:218] Iteration 49600 (7.17758 iter/s, 13.9323s/100 iters), loss = 0.00770985
I0925 22:27:18.647891  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00770979 (* 1 = 0.00770979 loss)
I0925 22:27:18.647898  3547 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0925 22:27:32.587393  3547 solver.cpp:218] Iteration 49700 (7.17388 iter/s, 13.9395s/100 iters), loss = 0.0186912
I0925 22:27:32.587522  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186911 (* 1 = 0.0186911 loss)
I0925 22:27:32.587548  3547 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0925 22:27:46.524257  3547 solver.cpp:218] Iteration 49800 (7.1753 iter/s, 13.9367s/100 iters), loss = 0.00695538
I0925 22:27:46.524292  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695533 (* 1 = 0.00695533 loss)
I0925 22:27:46.524302  3547 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0925 22:28:00.459974  3547 solver.cpp:218] Iteration 49900 (7.17585 iter/s, 13.9356s/100 iters), loss = 0.00400658
I0925 22:28:00.460006  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400652 (* 1 = 0.00400652 loss)
I0925 22:28:00.460014  3547 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0925 22:28:13.707429  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:28:14.264641  3547 solver.cpp:330] Iteration 50000, Testing net (#0)
I0925 22:28:17.588801  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:28:17.727028  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I0925 22:28:17.727056  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311079 (* 1 = 0.311079 loss)
I0925 22:28:17.865444  3547 solver.cpp:218] Iteration 50000 (5.74535 iter/s, 17.4054s/100 iters), loss = 0.0263045
I0925 22:28:17.865474  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263044 (* 1 = 0.0263044 loss)
I0925 22:28:17.865484  3547 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0925 22:28:31.813776  3547 solver.cpp:218] Iteration 50100 (7.16936 iter/s, 13.9483s/100 iters), loss = 0.00739756
I0925 22:28:31.813810  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073975 (* 1 = 0.0073975 loss)
I0925 22:28:31.813828  3547 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0925 22:28:45.769017  3547 solver.cpp:218] Iteration 50200 (7.16581 iter/s, 13.9552s/100 iters), loss = 0.0030722
I0925 22:28:45.769109  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307214 (* 1 = 0.00307214 loss)
I0925 22:28:45.769119  3547 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0925 22:28:59.728370  3547 solver.cpp:218] Iteration 50300 (7.16372 iter/s, 13.9592s/100 iters), loss = 0.00296331
I0925 22:28:59.728402  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296324 (* 1 = 0.00296324 loss)
I0925 22:28:59.728420  3547 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0925 22:29:13.684835  3547 solver.cpp:218] Iteration 50400 (7.16518 iter/s, 13.9564s/100 iters), loss = 0.00291757
I0925 22:29:13.684865  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029175 (* 1 = 0.0029175 loss)
I0925 22:29:13.684881  3547 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0925 22:29:26.945008  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:29:27.502874  3547 solver.cpp:330] Iteration 50500, Testing net (#0)
I0925 22:29:30.822139  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:29:30.960999  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0925 22:29:30.961035  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306922 (* 1 = 0.306922 loss)
I0925 22:29:31.099117  3547 solver.cpp:218] Iteration 50500 (5.74244 iter/s, 17.4142s/100 iters), loss = 0.00347246
I0925 22:29:31.099148  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347238 (* 1 = 0.00347238 loss)
I0925 22:29:31.099154  3547 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0925 22:29:45.038554  3547 solver.cpp:218] Iteration 50600 (7.17393 iter/s, 13.9394s/100 iters), loss = 0.00653679
I0925 22:29:45.038583  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653671 (* 1 = 0.00653671 loss)
I0925 22:29:45.038589  3547 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0925 22:29:58.975930  3547 solver.cpp:218] Iteration 50700 (7.17499 iter/s, 13.9373s/100 iters), loss = 0.00370638
I0925 22:29:58.976092  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370631 (* 1 = 0.00370631 loss)
I0925 22:29:58.976101  3547 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0925 22:30:12.919683  3547 solver.cpp:218] Iteration 50800 (7.17177 iter/s, 13.9436s/100 iters), loss = 0.00242455
I0925 22:30:12.919713  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242449 (* 1 = 0.00242449 loss)
I0925 22:30:12.919718  3547 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0925 22:30:26.864171  3547 solver.cpp:218] Iteration 50900 (7.17133 iter/s, 13.9444s/100 iters), loss = 0.0020161
I0925 22:30:26.864202  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201604 (* 1 = 0.00201604 loss)
I0925 22:30:26.864208  3547 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0925 22:30:40.112435  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:30:40.670975  3547 solver.cpp:330] Iteration 51000, Testing net (#0)
I0925 22:30:43.993660  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:30:44.132402  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0925 22:30:44.132438  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307632 (* 1 = 0.307632 loss)
I0925 22:30:44.270252  3547 solver.cpp:218] Iteration 51000 (5.74515 iter/s, 17.406s/100 iters), loss = 0.00816965
I0925 22:30:44.270282  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081696 (* 1 = 0.0081696 loss)
I0925 22:30:44.270287  3547 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0925 22:30:58.215463  3547 solver.cpp:218] Iteration 51100 (7.17096 iter/s, 13.9451s/100 iters), loss = 0.013444
I0925 22:30:58.215503  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013444 (* 1 = 0.013444 loss)
I0925 22:30:58.215509  3547 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0925 22:31:12.169330  3547 solver.cpp:218] Iteration 51200 (7.16652 iter/s, 13.9538s/100 iters), loss = 0.00803687
I0925 22:31:12.169443  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00803681 (* 1 = 0.00803681 loss)
I0925 22:31:12.169461  3547 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0925 22:31:26.116068  3547 solver.cpp:218] Iteration 51300 (7.17021 iter/s, 13.9466s/100 iters), loss = 0.00224175
I0925 22:31:26.116108  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224169 (* 1 = 0.00224169 loss)
I0925 22:31:26.116114  3547 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0925 22:31:40.069193  3547 solver.cpp:218] Iteration 51400 (7.1669 iter/s, 13.953s/100 iters), loss = 0.00654662
I0925 22:31:40.069223  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00654657 (* 1 = 0.00654657 loss)
I0925 22:31:40.069229  3547 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0925 22:31:53.323765  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:31:53.882082  3547 solver.cpp:330] Iteration 51500, Testing net (#0)
I0925 22:31:57.205343  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:31:57.343554  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0925 22:31:57.343588  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313285 (* 1 = 0.313285 loss)
I0925 22:31:57.482134  3547 solver.cpp:218] Iteration 51500 (5.74288 iter/s, 17.4129s/100 iters), loss = 0.00923585
I0925 22:31:57.482172  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00923579 (* 1 = 0.00923579 loss)
I0925 22:31:57.482179  3547 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0925 22:32:11.426087  3547 solver.cpp:218] Iteration 51600 (7.17161 iter/s, 13.9439s/100 iters), loss = 0.00844026
I0925 22:32:11.426117  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0084402 (* 1 = 0.0084402 loss)
I0925 22:32:11.426123  3547 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0925 22:32:25.377485  3547 solver.cpp:218] Iteration 51700 (7.16778 iter/s, 13.9513s/100 iters), loss = 0.000985078
I0925 22:32:25.377580  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000985024 (* 1 = 0.000985024 loss)
I0925 22:32:25.377588  3547 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0925 22:32:39.335032  3547 solver.cpp:218] Iteration 51800 (7.16465 iter/s, 13.9574s/100 iters), loss = 0.00861009
I0925 22:32:39.335072  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00861003 (* 1 = 0.00861003 loss)
I0925 22:32:39.335078  3547 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0925 22:32:53.286741  3547 solver.cpp:218] Iteration 51900 (7.16763 iter/s, 13.9516s/100 iters), loss = 0.00203228
I0925 22:32:53.286769  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203223 (* 1 = 0.00203223 loss)
I0925 22:32:53.286775  3547 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0925 22:33:06.547734  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:33:07.106259  3547 solver.cpp:330] Iteration 52000, Testing net (#0)
I0925 22:33:10.426148  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:33:10.563876  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0925 22:33:10.563901  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315916 (* 1 = 0.315916 loss)
I0925 22:33:10.701992  3547 solver.cpp:218] Iteration 52000 (5.74212 iter/s, 17.4152s/100 iters), loss = 0.00152586
I0925 22:33:10.702024  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015258 (* 1 = 0.0015258 loss)
I0925 22:33:10.702031  3547 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0925 22:33:24.640511  3547 solver.cpp:218] Iteration 52100 (7.1744 iter/s, 13.9384s/100 iters), loss = 0.0113339
I0925 22:33:24.640540  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113338 (* 1 = 0.0113338 loss)
I0925 22:33:24.640547  3547 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0925 22:33:38.587210  3547 solver.cpp:218] Iteration 52200 (7.17019 iter/s, 13.9466s/100 iters), loss = 0.0101653
I0925 22:33:38.587319  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101652 (* 1 = 0.0101652 loss)
I0925 22:33:38.587327  3547 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0925 22:33:52.531348  3547 solver.cpp:218] Iteration 52300 (7.17154 iter/s, 13.944s/100 iters), loss = 0.00350974
I0925 22:33:52.531378  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350968 (* 1 = 0.00350968 loss)
I0925 22:33:52.531394  3547 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0925 22:34:06.468747  3547 solver.cpp:218] Iteration 52400 (7.17498 iter/s, 13.9373s/100 iters), loss = 0.00239665
I0925 22:34:06.468777  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023966 (* 1 = 0.0023966 loss)
I0925 22:34:06.468783  3547 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0925 22:34:19.720474  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:34:20.277367  3547 solver.cpp:330] Iteration 52500, Testing net (#0)
I0925 22:34:23.601476  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:34:23.740124  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I0925 22:34:23.740160  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314206 (* 1 = 0.314206 loss)
I0925 22:34:23.878690  3547 solver.cpp:218] Iteration 52500 (5.74387 iter/s, 17.4099s/100 iters), loss = 0.00291777
I0925 22:34:23.878720  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291772 (* 1 = 0.00291772 loss)
I0925 22:34:23.878726  3547 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0925 22:34:37.846271  3547 solver.cpp:218] Iteration 52600 (7.15947 iter/s, 13.9675s/100 iters), loss = 0.00238704
I0925 22:34:37.846312  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238698 (* 1 = 0.00238698 loss)
I0925 22:34:37.846318  3547 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0925 22:34:51.821933  3547 solver.cpp:218] Iteration 52700 (7.15534 iter/s, 13.9756s/100 iters), loss = 0.013174
I0925 22:34:51.822108  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131739 (* 1 = 0.0131739 loss)
I0925 22:34:51.822116  3547 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0925 22:35:05.791152  3547 solver.cpp:218] Iteration 52800 (7.1587 iter/s, 13.969s/100 iters), loss = 0.00803943
I0925 22:35:05.791193  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00803938 (* 1 = 0.00803938 loss)
I0925 22:35:05.791199  3547 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0925 22:35:19.763659  3547 solver.cpp:218] Iteration 52900 (7.15696 iter/s, 13.9724s/100 iters), loss = 0.000823293
I0925 22:35:19.763700  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000823239 (* 1 = 0.000823239 loss)
I0925 22:35:19.763705  3547 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0925 22:35:33.045814  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:35:33.604954  3547 solver.cpp:330] Iteration 53000, Testing net (#0)
I0925 22:35:36.926264  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:35:37.064699  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.921
I0925 22:35:37.064723  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31968 (* 1 = 0.31968 loss)
I0925 22:35:37.203910  3547 solver.cpp:218] Iteration 53000 (5.73389 iter/s, 17.4402s/100 iters), loss = 0.00336646
I0925 22:35:37.203943  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00336641 (* 1 = 0.00336641 loss)
I0925 22:35:37.203949  3547 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0925 22:35:51.161828  3547 solver.cpp:218] Iteration 53100 (7.16443 iter/s, 13.9578s/100 iters), loss = 0.0104013
I0925 22:35:51.161859  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104012 (* 1 = 0.0104012 loss)
I0925 22:35:51.161865  3547 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0925 22:36:05.114107  3547 solver.cpp:218] Iteration 53200 (7.16733 iter/s, 13.9522s/100 iters), loss = 0.0202191
I0925 22:36:05.114222  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202191 (* 1 = 0.0202191 loss)
I0925 22:36:05.114238  3547 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0925 22:36:19.074846  3547 solver.cpp:218] Iteration 53300 (7.16303 iter/s, 13.9606s/100 iters), loss = 0.0052023
I0925 22:36:19.074877  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520224 (* 1 = 0.00520224 loss)
I0925 22:36:19.074893  3547 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0925 22:36:33.031116  3547 solver.cpp:218] Iteration 53400 (7.16528 iter/s, 13.9562s/100 iters), loss = 0.004289
I0925 22:36:33.031146  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428894 (* 1 = 0.00428894 loss)
I0925 22:36:33.031162  3547 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0925 22:36:46.293057  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:36:46.850033  3547 solver.cpp:330] Iteration 53500, Testing net (#0)
I0925 22:36:50.173374  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:36:50.311739  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9197
I0925 22:36:50.311774  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330847 (* 1 = 0.330847 loss)
I0925 22:36:50.450708  3547 solver.cpp:218] Iteration 53500 (5.74069 iter/s, 17.4195s/100 iters), loss = 0.000714679
I0925 22:36:50.450737  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000714616 (* 1 = 0.000714616 loss)
I0925 22:36:50.450743  3547 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0925 22:37:04.411428  3547 solver.cpp:218] Iteration 53600 (7.16299 iter/s, 13.9606s/100 iters), loss = 0.0136619
I0925 22:37:04.411460  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136619 (* 1 = 0.0136619 loss)
I0925 22:37:04.411478  3547 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0925 22:37:18.372123  3547 solver.cpp:218] Iteration 53700 (7.16301 iter/s, 13.9606s/100 iters), loss = 0.0124619
I0925 22:37:18.372226  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124618 (* 1 = 0.0124618 loss)
I0925 22:37:18.372244  3547 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0925 22:37:32.332283  3547 solver.cpp:218] Iteration 53800 (7.16331 iter/s, 13.96s/100 iters), loss = 0.00672785
I0925 22:37:32.332312  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00672779 (* 1 = 0.00672779 loss)
I0925 22:37:32.332319  3547 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0925 22:37:46.287552  3547 solver.cpp:218] Iteration 53900 (7.16579 iter/s, 13.9552s/100 iters), loss = 0.00263451
I0925 22:37:46.287583  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263445 (* 1 = 0.00263445 loss)
I0925 22:37:46.287590  3547 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0925 22:37:59.553272  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:38:00.112366  3547 solver.cpp:330] Iteration 54000, Testing net (#0)
I0925 22:38:03.434653  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:38:03.573405  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0925 22:38:03.573441  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312902 (* 1 = 0.312902 loss)
I0925 22:38:03.712595  3547 solver.cpp:218] Iteration 54000 (5.73889 iter/s, 17.425s/100 iters), loss = 0.00104385
I0925 22:38:03.712626  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104379 (* 1 = 0.00104379 loss)
I0925 22:38:03.712633  3547 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0925 22:38:17.679966  3547 solver.cpp:218] Iteration 54100 (7.15958 iter/s, 13.9673s/100 iters), loss = 0.00974159
I0925 22:38:17.679997  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00974153 (* 1 = 0.00974153 loss)
I0925 22:38:17.680014  3547 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0925 22:38:31.643661  3547 solver.cpp:218] Iteration 54200 (7.16147 iter/s, 13.9636s/100 iters), loss = 0.00210984
I0925 22:38:31.643798  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210978 (* 1 = 0.00210978 loss)
I0925 22:38:31.643807  3547 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0925 22:38:45.605306  3547 solver.cpp:218] Iteration 54300 (7.16257 iter/s, 13.9615s/100 iters), loss = 0.00408106
I0925 22:38:45.605336  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00408099 (* 1 = 0.00408099 loss)
I0925 22:38:45.605352  3547 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0925 22:38:59.573757  3547 solver.cpp:218] Iteration 54400 (7.15903 iter/s, 13.9684s/100 iters), loss = 0.00158642
I0925 22:38:59.573789  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158635 (* 1 = 0.00158635 loss)
I0925 22:38:59.573807  3547 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0925 22:39:12.845257  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:39:13.403520  3547 solver.cpp:330] Iteration 54500, Testing net (#0)
I0925 22:39:16.723163  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:39:16.862169  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9197
I0925 22:39:16.862203  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313436 (* 1 = 0.313436 loss)
I0925 22:39:17.000823  3547 solver.cpp:218] Iteration 54500 (5.73823 iter/s, 17.427s/100 iters), loss = 0.00456292
I0925 22:39:17.000852  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456286 (* 1 = 0.00456286 loss)
I0925 22:39:17.000859  3547 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0925 22:39:30.952659  3547 solver.cpp:218] Iteration 54600 (7.16755 iter/s, 13.9518s/100 iters), loss = 0.000584327
I0925 22:39:30.952690  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00058426 (* 1 = 0.00058426 loss)
I0925 22:39:30.952706  3547 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0925 22:39:44.904752  3547 solver.cpp:218] Iteration 54700 (7.16742 iter/s, 13.952s/100 iters), loss = 0.00505132
I0925 22:39:44.904861  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505125 (* 1 = 0.00505125 loss)
I0925 22:39:44.904878  3547 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0925 22:39:58.852026  3547 solver.cpp:218] Iteration 54800 (7.16993 iter/s, 13.9471s/100 iters), loss = 0.00370629
I0925 22:39:58.852056  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370622 (* 1 = 0.00370622 loss)
I0925 22:39:58.852062  3547 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0925 22:40:12.800484  3547 solver.cpp:218] Iteration 54900 (7.16929 iter/s, 13.9484s/100 iters), loss = 0.00596631
I0925 22:40:12.800516  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596623 (* 1 = 0.00596623 loss)
I0925 22:40:12.800534  3547 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0925 22:40:26.055797  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:40:26.613749  3547 solver.cpp:330] Iteration 55000, Testing net (#0)
I0925 22:40:29.934914  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:40:30.073853  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I0925 22:40:30.073887  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324871 (* 1 = 0.324871 loss)
I0925 22:40:30.212251  3547 solver.cpp:218] Iteration 55000 (5.74327 iter/s, 17.4117s/100 iters), loss = 0.00245499
I0925 22:40:30.212278  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245492 (* 1 = 0.00245492 loss)
I0925 22:40:30.212285  3547 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0925 22:40:44.175042  3547 solver.cpp:218] Iteration 55100 (7.16193 iter/s, 13.9627s/100 iters), loss = 0.00844269
I0925 22:40:44.175084  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844262 (* 1 = 0.00844262 loss)
I0925 22:40:44.175091  3547 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0925 22:40:58.137790  3547 solver.cpp:218] Iteration 55200 (7.16196 iter/s, 13.9627s/100 iters), loss = 0.0260861
I0925 22:40:58.137889  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026086 (* 1 = 0.026086 loss)
I0925 22:40:58.137897  3547 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0925 22:41:12.100780  3547 solver.cpp:218] Iteration 55300 (7.16186 iter/s, 13.9628s/100 iters), loss = 0.00419765
I0925 22:41:12.100821  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419757 (* 1 = 0.00419757 loss)
I0925 22:41:12.100826  3547 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0925 22:41:26.073124  3547 solver.cpp:218] Iteration 55400 (7.15704 iter/s, 13.9723s/100 iters), loss = 0.00257165
I0925 22:41:26.073163  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257157 (* 1 = 0.00257157 loss)
I0925 22:41:26.073169  3547 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0925 22:41:39.340427  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:41:39.898468  3547 solver.cpp:330] Iteration 55500, Testing net (#0)
I0925 22:41:43.220736  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:41:43.359032  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I0925 22:41:43.359068  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339022 (* 1 = 0.339022 loss)
I0925 22:41:43.498195  3547 solver.cpp:218] Iteration 55500 (5.73889 iter/s, 17.425s/100 iters), loss = 0.00502825
I0925 22:41:43.498224  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502816 (* 1 = 0.00502816 loss)
I0925 22:41:43.498230  3547 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0925 22:41:57.464473  3547 solver.cpp:218] Iteration 55600 (7.16014 iter/s, 13.9662s/100 iters), loss = 0.00267616
I0925 22:41:57.464516  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267608 (* 1 = 0.00267608 loss)
I0925 22:41:57.464524  3547 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0925 22:42:11.426661  3547 solver.cpp:218] Iteration 55700 (7.16225 iter/s, 13.9621s/100 iters), loss = 0.00975974
I0925 22:42:11.426785  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00975966 (* 1 = 0.00975966 loss)
I0925 22:42:11.426793  3547 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0925 22:42:25.381911  3547 solver.cpp:218] Iteration 55800 (7.16585 iter/s, 13.9551s/100 iters), loss = 0.00334315
I0925 22:42:25.381953  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334307 (* 1 = 0.00334307 loss)
I0925 22:42:25.381959  3547 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0925 22:42:39.342397  3547 solver.cpp:218] Iteration 55900 (7.16312 iter/s, 13.9604s/100 iters), loss = 0.00752092
I0925 22:42:39.342438  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752085 (* 1 = 0.00752085 loss)
I0925 22:42:39.342444  3547 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0925 22:42:52.606560  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:42:53.165740  3547 solver.cpp:330] Iteration 56000, Testing net (#0)
I0925 22:42:56.487393  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:42:56.626147  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I0925 22:42:56.626183  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337322 (* 1 = 0.337322 loss)
I0925 22:42:56.764549  3547 solver.cpp:218] Iteration 56000 (5.73985 iter/s, 17.4221s/100 iters), loss = 0.00134437
I0925 22:42:56.764575  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013443 (* 1 = 0.0013443 loss)
I0925 22:42:56.764582  3547 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0925 22:43:10.704349  3547 solver.cpp:218] Iteration 56100 (7.17374 iter/s, 13.9397s/100 iters), loss = 0.0146654
I0925 22:43:10.704388  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146653 (* 1 = 0.0146653 loss)
I0925 22:43:10.704393  3547 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0925 22:43:24.655390  3547 solver.cpp:218] Iteration 56200 (7.16797 iter/s, 13.951s/100 iters), loss = 0.00913432
I0925 22:43:24.655536  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00913425 (* 1 = 0.00913425 loss)
I0925 22:43:24.655544  3547 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0925 22:43:38.606143  3547 solver.cpp:218] Iteration 56300 (7.16817 iter/s, 13.9506s/100 iters), loss = 0.00687857
I0925 22:43:38.606185  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068785 (* 1 = 0.0068785 loss)
I0925 22:43:38.606191  3547 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0925 22:43:52.555519  3547 solver.cpp:218] Iteration 56400 (7.16882 iter/s, 13.9493s/100 iters), loss = 0.00115581
I0925 22:43:52.555559  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115573 (* 1 = 0.00115573 loss)
I0925 22:43:52.555564  3547 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0925 22:44:05.811683  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:44:06.368906  3547 solver.cpp:330] Iteration 56500, Testing net (#0)
I0925 22:44:09.691795  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:44:09.830646  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0925 22:44:09.830672  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326314 (* 1 = 0.326314 loss)
I0925 22:44:09.968708  3547 solver.cpp:218] Iteration 56500 (5.74281 iter/s, 17.4131s/100 iters), loss = 0.00153335
I0925 22:44:09.968739  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153328 (* 1 = 0.00153328 loss)
I0925 22:44:09.968744  3547 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0925 22:44:23.922621  3547 solver.cpp:218] Iteration 56600 (7.16649 iter/s, 13.9538s/100 iters), loss = 0.00328217
I0925 22:44:23.922650  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032821 (* 1 = 0.0032821 loss)
I0925 22:44:23.922657  3547 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0925 22:44:37.877918  3547 solver.cpp:218] Iteration 56700 (7.16578 iter/s, 13.9552s/100 iters), loss = 0.00431781
I0925 22:44:37.878080  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431773 (* 1 = 0.00431773 loss)
I0925 22:44:37.878101  3547 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0925 22:44:51.837465  3547 solver.cpp:218] Iteration 56800 (7.16366 iter/s, 13.9593s/100 iters), loss = 0.0188096
I0925 22:44:51.837493  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188095 (* 1 = 0.0188095 loss)
I0925 22:44:51.837499  3547 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0925 22:45:05.793854  3547 solver.cpp:218] Iteration 56900 (7.16521 iter/s, 13.9563s/100 iters), loss = 0.00112844
I0925 22:45:05.793886  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112836 (* 1 = 0.00112836 loss)
I0925 22:45:05.793893  3547 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0925 22:45:19.060613  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:45:19.619637  3547 solver.cpp:330] Iteration 57000, Testing net (#0)
I0925 22:45:22.939816  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:45:23.078620  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0925 22:45:23.078644  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317727 (* 1 = 0.317727 loss)
I0925 22:45:23.216929  3547 solver.cpp:218] Iteration 57000 (5.73954 iter/s, 17.423s/100 iters), loss = 0.00439015
I0925 22:45:23.216958  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439006 (* 1 = 0.00439006 loss)
I0925 22:45:23.216965  3547 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0925 22:45:37.159529  3547 solver.cpp:218] Iteration 57100 (7.1723 iter/s, 13.9425s/100 iters), loss = 0.00302751
I0925 22:45:37.159570  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302743 (* 1 = 0.00302743 loss)
I0925 22:45:37.159576  3547 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0925 22:45:51.097882  3547 solver.cpp:218] Iteration 57200 (7.17449 iter/s, 13.9383s/100 iters), loss = 0.00268325
I0925 22:45:51.098017  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268316 (* 1 = 0.00268316 loss)
I0925 22:45:51.098026  3547 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0925 22:46:05.046911  3547 solver.cpp:218] Iteration 57300 (7.16904 iter/s, 13.9489s/100 iters), loss = 0.00465881
I0925 22:46:05.046941  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465872 (* 1 = 0.00465872 loss)
I0925 22:46:05.046947  3547 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0925 22:46:18.996554  3547 solver.cpp:218] Iteration 57400 (7.16868 iter/s, 13.9496s/100 iters), loss = 0.00351122
I0925 22:46:18.996594  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351114 (* 1 = 0.00351114 loss)
I0925 22:46:18.996600  3547 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0925 22:46:32.255605  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:46:32.814153  3547 solver.cpp:330] Iteration 57500, Testing net (#0)
I0925 22:46:36.136183  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:46:36.274611  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0925 22:46:36.274646  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332282 (* 1 = 0.332282 loss)
I0925 22:46:36.412876  3547 solver.cpp:218] Iteration 57500 (5.74177 iter/s, 17.4162s/100 iters), loss = 0.00411607
I0925 22:46:36.412910  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411599 (* 1 = 0.00411599 loss)
I0925 22:46:36.412916  3547 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0925 22:46:50.359750  3547 solver.cpp:218] Iteration 57600 (7.17011 iter/s, 13.9468s/100 iters), loss = 0.00295957
I0925 22:46:50.359789  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029595 (* 1 = 0.0029595 loss)
I0925 22:46:50.359796  3547 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0925 22:47:04.314486  3547 solver.cpp:218] Iteration 57700 (7.16607 iter/s, 13.9547s/100 iters), loss = 0.00316112
I0925 22:47:04.314610  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316104 (* 1 = 0.00316104 loss)
I0925 22:47:04.314618  3547 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0925 22:47:18.254863  3547 solver.cpp:218] Iteration 57800 (7.17349 iter/s, 13.9402s/100 iters), loss = 0.00292339
I0925 22:47:18.254904  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292332 (* 1 = 0.00292332 loss)
I0925 22:47:18.254910  3547 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0925 22:47:32.197845  3547 solver.cpp:218] Iteration 57900 (7.17211 iter/s, 13.9429s/100 iters), loss = 0.00148201
I0925 22:47:32.197877  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148194 (* 1 = 0.00148194 loss)
I0925 22:47:32.197883  3547 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0925 22:47:45.455183  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:47:46.012619  3547 solver.cpp:330] Iteration 58000, Testing net (#0)
I0925 22:47:49.334583  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:47:49.473474  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0925 22:47:49.473510  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322602 (* 1 = 0.322602 loss)
I0925 22:47:49.612608  3547 solver.cpp:218] Iteration 58000 (5.74228 iter/s, 17.4147s/100 iters), loss = 0.00176666
I0925 22:47:49.612638  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176659 (* 1 = 0.00176659 loss)
I0925 22:47:49.612645  3547 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0925 22:48:03.568914  3547 solver.cpp:218] Iteration 58100 (7.16526 iter/s, 13.9562s/100 iters), loss = 0.00915218
I0925 22:48:03.568944  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915211 (* 1 = 0.00915211 loss)
I0925 22:48:03.568950  3547 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0925 22:48:17.532209  3547 solver.cpp:218] Iteration 58200 (7.16167 iter/s, 13.9632s/100 iters), loss = 0.00231096
I0925 22:48:17.532310  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231089 (* 1 = 0.00231089 loss)
I0925 22:48:17.532317  3547 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0925 22:48:31.498265  3547 solver.cpp:218] Iteration 58300 (7.16029 iter/s, 13.9659s/100 iters), loss = 0.0228294
I0925 22:48:31.498294  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228293 (* 1 = 0.0228293 loss)
I0925 22:48:31.498301  3547 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0925 22:48:45.464545  3547 solver.cpp:218] Iteration 58400 (7.16014 iter/s, 13.9662s/100 iters), loss = 0.00140599
I0925 22:48:45.464584  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140592 (* 1 = 0.00140592 loss)
I0925 22:48:45.464591  3547 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0925 22:48:58.736306  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:48:59.296480  3547 solver.cpp:330] Iteration 58500, Testing net (#0)
I0925 22:49:02.619127  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:49:02.757692  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0925 22:49:02.757727  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336062 (* 1 = 0.336062 loss)
I0925 22:49:02.896332  3547 solver.cpp:218] Iteration 58500 (5.73668 iter/s, 17.4317s/100 iters), loss = 0.00455892
I0925 22:49:02.896361  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455885 (* 1 = 0.00455885 loss)
I0925 22:49:02.896368  3547 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0925 22:49:16.836340  3547 solver.cpp:218] Iteration 58600 (7.17364 iter/s, 13.9399s/100 iters), loss = 0.00129779
I0925 22:49:16.836369  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129772 (* 1 = 0.00129772 loss)
I0925 22:49:16.836375  3547 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0925 22:49:30.783285  3547 solver.cpp:218] Iteration 58700 (7.17007 iter/s, 13.9469s/100 iters), loss = 0.00128352
I0925 22:49:30.783422  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128345 (* 1 = 0.00128345 loss)
I0925 22:49:30.783440  3547 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0925 22:49:44.730515  3547 solver.cpp:218] Iteration 58800 (7.16998 iter/s, 13.947s/100 iters), loss = 0.000941095
I0925 22:49:44.730556  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000941023 (* 1 = 0.000941023 loss)
I0925 22:49:44.730561  3547 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0925 22:49:58.680706  3547 solver.cpp:218] Iteration 58900 (7.1684 iter/s, 13.9501s/100 iters), loss = 0.00279543
I0925 22:49:58.680733  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279536 (* 1 = 0.00279536 loss)
I0925 22:49:58.680739  3547 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0925 22:50:11.934583  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:50:12.492892  3547 solver.cpp:330] Iteration 59000, Testing net (#0)
I0925 22:50:15.814692  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:50:15.953533  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I0925 22:50:15.953558  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338104 (* 1 = 0.338104 loss)
I0925 22:50:16.092607  3547 solver.cpp:218] Iteration 59000 (5.74323 iter/s, 17.4118s/100 iters), loss = 0.00221998
I0925 22:50:16.092636  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221991 (* 1 = 0.00221991 loss)
I0925 22:50:16.092643  3547 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0925 22:50:30.048195  3547 solver.cpp:218] Iteration 59100 (7.16563 iter/s, 13.9555s/100 iters), loss = 0.00228766
I0925 22:50:30.048224  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228759 (* 1 = 0.00228759 loss)
I0925 22:50:30.048230  3547 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0925 22:50:44.005969  3547 solver.cpp:218] Iteration 59200 (7.16451 iter/s, 13.9577s/100 iters), loss = 0.00967087
I0925 22:50:44.006078  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0096708 (* 1 = 0.0096708 loss)
I0925 22:50:44.006095  3547 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0925 22:50:57.965950  3547 solver.cpp:218] Iteration 59300 (7.16341 iter/s, 13.9598s/100 iters), loss = 0.00765719
I0925 22:50:57.965979  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765712 (* 1 = 0.00765712 loss)
I0925 22:50:57.965986  3547 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0925 22:51:11.929206  3547 solver.cpp:218] Iteration 59400 (7.16169 iter/s, 13.9632s/100 iters), loss = 0.00218924
I0925 22:51:11.929237  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218917 (* 1 = 0.00218917 loss)
I0925 22:51:11.929244  3547 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0925 22:51:25.190395  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:51:25.748893  3547 solver.cpp:330] Iteration 59500, Testing net (#0)
I0925 22:51:29.071194  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:51:29.209674  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0925 22:51:29.209708  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326237 (* 1 = 0.326237 loss)
I0925 22:51:29.348173  3547 solver.cpp:218] Iteration 59500 (5.7409 iter/s, 17.4189s/100 iters), loss = 0.0014486
I0925 22:51:29.348202  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144853 (* 1 = 0.00144853 loss)
I0925 22:51:29.348209  3547 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0925 22:51:43.282589  3547 solver.cpp:218] Iteration 59600 (7.17652 iter/s, 13.9343s/100 iters), loss = 0.00214829
I0925 22:51:43.282629  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214821 (* 1 = 0.00214821 loss)
I0925 22:51:43.282636  3547 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0925 22:51:57.229148  3547 solver.cpp:218] Iteration 59700 (7.17027 iter/s, 13.9465s/100 iters), loss = 0.0017473
I0925 22:51:57.229301  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174723 (* 1 = 0.00174723 loss)
I0925 22:51:57.229310  3547 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0925 22:52:11.172485  3547 solver.cpp:218] Iteration 59800 (7.17198 iter/s, 13.9432s/100 iters), loss = 0.00244801
I0925 22:52:11.172518  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244794 (* 1 = 0.00244794 loss)
I0925 22:52:11.172523  3547 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0925 22:52:25.127418  3547 solver.cpp:218] Iteration 59900 (7.16596 iter/s, 13.9549s/100 iters), loss = 0.00464848
I0925 22:52:25.127460  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046484 (* 1 = 0.0046484 loss)
I0925 22:52:25.127465  3547 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0925 22:52:38.381466  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:52:38.941716  3547 solver.cpp:330] Iteration 60000, Testing net (#0)
I0925 22:52:42.263619  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:52:42.401942  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I0925 22:52:42.401978  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309909 (* 1 = 0.309909 loss)
I0925 22:52:42.540005  3547 solver.cpp:218] Iteration 60000 (5.743 iter/s, 17.4125s/100 iters), loss = 0.00328003
I0925 22:52:42.540040  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327996 (* 1 = 0.00327996 loss)
I0925 22:52:42.540046  3547 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0925 22:52:56.492630  3547 solver.cpp:218] Iteration 60100 (7.16715 iter/s, 13.9525s/100 iters), loss = 0.00195625
I0925 22:52:56.492672  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195617 (* 1 = 0.00195617 loss)
I0925 22:52:56.492678  3547 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0925 22:53:10.448675  3547 solver.cpp:218] Iteration 60200 (7.1654 iter/s, 13.956s/100 iters), loss = 0.00121043
I0925 22:53:10.448762  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121035 (* 1 = 0.00121035 loss)
I0925 22:53:10.448781  3547 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0925 22:53:24.409008  3547 solver.cpp:218] Iteration 60300 (7.16322 iter/s, 13.9602s/100 iters), loss = 0.00100689
I0925 22:53:24.409049  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100681 (* 1 = 0.00100681 loss)
I0925 22:53:24.409056  3547 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0925 22:53:38.365803  3547 solver.cpp:218] Iteration 60400 (7.16501 iter/s, 13.9567s/100 iters), loss = 0.000909719
I0925 22:53:38.365844  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000909638 (* 1 = 0.000909638 loss)
I0925 22:53:38.365850  3547 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0925 22:53:51.633214  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:53:52.192718  3547 solver.cpp:330] Iteration 60500, Testing net (#0)
I0925 22:53:55.513742  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:53:55.652091  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0925 22:53:55.652127  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311147 (* 1 = 0.311147 loss)
I0925 22:53:55.790802  3547 solver.cpp:218] Iteration 60500 (5.73891 iter/s, 17.4249s/100 iters), loss = 0.000978203
I0925 22:53:55.790832  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000978124 (* 1 = 0.000978124 loss)
I0925 22:53:55.790839  3547 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0925 22:54:09.733631  3547 solver.cpp:218] Iteration 60600 (7.17219 iter/s, 13.9427s/100 iters), loss = 0.00656899
I0925 22:54:09.733672  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00656891 (* 1 = 0.00656891 loss)
I0925 22:54:09.733678  3547 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0925 22:54:23.672127  3547 solver.cpp:218] Iteration 60700 (7.17442 iter/s, 13.9384s/100 iters), loss = 0.0034556
I0925 22:54:23.672248  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345553 (* 1 = 0.00345553 loss)
I0925 22:54:23.672257  3547 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0925 22:54:37.630146  3547 solver.cpp:218] Iteration 60800 (7.16442 iter/s, 13.9579s/100 iters), loss = 0.000755851
I0925 22:54:37.630187  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000755772 (* 1 = 0.000755772 loss)
I0925 22:54:37.630194  3547 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0925 22:54:51.576967  3547 solver.cpp:218] Iteration 60900 (7.17014 iter/s, 13.9467s/100 iters), loss = 0.00146535
I0925 22:54:51.577008  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146528 (* 1 = 0.00146528 loss)
I0925 22:54:51.577013  3547 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0925 22:55:04.836962  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:55:05.395686  3547 solver.cpp:330] Iteration 61000, Testing net (#0)
I0925 22:55:08.717339  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:55:08.855479  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0925 22:55:08.855515  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324419 (* 1 = 0.324419 loss)
I0925 22:55:08.995220  3547 solver.cpp:218] Iteration 61000 (5.74114 iter/s, 17.4182s/100 iters), loss = 0.00243223
I0925 22:55:08.995251  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243215 (* 1 = 0.00243215 loss)
I0925 22:55:08.995259  3547 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0925 22:55:22.944350  3547 solver.cpp:218] Iteration 61100 (7.16895 iter/s, 13.949s/100 iters), loss = 0.0020558
I0925 22:55:22.944378  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205572 (* 1 = 0.00205572 loss)
I0925 22:55:22.944384  3547 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0925 22:55:36.902979  3547 solver.cpp:218] Iteration 61200 (7.16407 iter/s, 13.9586s/100 iters), loss = 0.00358239
I0925 22:55:36.903122  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358231 (* 1 = 0.00358231 loss)
I0925 22:55:36.903142  3547 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0925 22:55:50.858549  3547 solver.cpp:218] Iteration 61300 (7.16569 iter/s, 13.9554s/100 iters), loss = 0.00133756
I0925 22:55:50.858579  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133748 (* 1 = 0.00133748 loss)
I0925 22:55:50.858584  3547 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0925 22:56:04.811648  3547 solver.cpp:218] Iteration 61400 (7.1669 iter/s, 13.953s/100 iters), loss = 0.000778878
I0925 22:56:04.811678  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000778797 (* 1 = 0.000778797 loss)
I0925 22:56:04.811684  3547 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0925 22:56:18.069831  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:56:18.628126  3547 solver.cpp:330] Iteration 61500, Testing net (#0)
I0925 22:56:21.949784  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:56:22.087971  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0925 22:56:22.088006  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318179 (* 1 = 0.318179 loss)
I0925 22:56:22.226354  3547 solver.cpp:218] Iteration 61500 (5.7423 iter/s, 17.4146s/100 iters), loss = 0.00121217
I0925 22:56:22.226382  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121209 (* 1 = 0.00121209 loss)
I0925 22:56:22.226387  3547 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0925 22:56:36.192579  3547 solver.cpp:218] Iteration 61600 (7.16017 iter/s, 13.9661s/100 iters), loss = 0.00532841
I0925 22:56:36.192621  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532833 (* 1 = 0.00532833 loss)
I0925 22:56:36.192627  3547 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0925 22:56:50.160992  3547 solver.cpp:218] Iteration 61700 (7.15905 iter/s, 13.9683s/100 iters), loss = 0.00102547
I0925 22:56:50.161124  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102539 (* 1 = 0.00102539 loss)
I0925 22:56:50.161131  3547 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0925 22:57:04.133071  3547 solver.cpp:218] Iteration 61800 (7.15722 iter/s, 13.9719s/100 iters), loss = 0.00304683
I0925 22:57:04.133101  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304676 (* 1 = 0.00304676 loss)
I0925 22:57:04.133107  3547 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0925 22:57:18.099691  3547 solver.cpp:218] Iteration 61900 (7.15997 iter/s, 13.9665s/100 iters), loss = 0.00123792
I0925 22:57:18.099731  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123784 (* 1 = 0.00123784 loss)
I0925 22:57:18.099737  3547 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0925 22:57:31.374596  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:57:31.933910  3547 solver.cpp:330] Iteration 62000, Testing net (#0)
I0925 22:57:35.256433  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:57:35.394806  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I0925 22:57:35.394842  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327217 (* 1 = 0.327217 loss)
I0925 22:57:35.533462  3547 solver.cpp:218] Iteration 62000 (5.73603 iter/s, 17.4337s/100 iters), loss = 0.00598911
I0925 22:57:35.533493  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598904 (* 1 = 0.00598904 loss)
I0925 22:57:35.533499  3547 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0925 22:57:49.478891  3547 solver.cpp:218] Iteration 62100 (7.17085 iter/s, 13.9453s/100 iters), loss = 0.00510242
I0925 22:57:49.478931  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510234 (* 1 = 0.00510234 loss)
I0925 22:57:49.478936  3547 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0925 22:58:03.420505  3547 solver.cpp:218] Iteration 62200 (7.17281 iter/s, 13.9415s/100 iters), loss = 0.00133184
I0925 22:58:03.420646  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133177 (* 1 = 0.00133177 loss)
I0925 22:58:03.420653  3547 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0925 22:58:17.373802  3547 solver.cpp:218] Iteration 62300 (7.16685 iter/s, 13.9531s/100 iters), loss = 0.00214676
I0925 22:58:17.373843  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214669 (* 1 = 0.00214669 loss)
I0925 22:58:17.373849  3547 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0925 22:58:31.324707  3547 solver.cpp:218] Iteration 62400 (7.16804 iter/s, 13.9508s/100 iters), loss = 0.000423914
I0925 22:58:31.324748  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000423842 (* 1 = 0.000423842 loss)
I0925 22:58:31.324753  3547 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0925 22:58:44.585939  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:58:45.144168  3547 solver.cpp:330] Iteration 62500, Testing net (#0)
I0925 22:58:48.464073  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:58:48.602732  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0925 22:58:48.602767  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333205 (* 1 = 0.333205 loss)
I0925 22:58:48.740919  3547 solver.cpp:218] Iteration 62500 (5.74181 iter/s, 17.4161s/100 iters), loss = 0.001109
I0925 22:58:48.740948  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110893 (* 1 = 0.00110893 loss)
I0925 22:58:48.740955  3547 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0925 22:59:02.681268  3547 solver.cpp:218] Iteration 62600 (7.17346 iter/s, 13.9403s/100 iters), loss = 0.00526455
I0925 22:59:02.681298  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00526448 (* 1 = 0.00526448 loss)
I0925 22:59:02.681304  3547 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0925 22:59:16.628916  3547 solver.cpp:218] Iteration 62700 (7.16971 iter/s, 13.9476s/100 iters), loss = 0.000643231
I0925 22:59:16.629022  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00064316 (* 1 = 0.00064316 loss)
I0925 22:59:16.629039  3547 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0925 22:59:30.578018  3547 solver.cpp:218] Iteration 62800 (7.169 iter/s, 13.949s/100 iters), loss = 0.00141842
I0925 22:59:30.578048  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141835 (* 1 = 0.00141835 loss)
I0925 22:59:30.578054  3547 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0925 22:59:44.528000  3547 solver.cpp:218] Iteration 62900 (7.16851 iter/s, 13.9499s/100 iters), loss = 0.00175727
I0925 22:59:44.528029  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017572 (* 1 = 0.0017572 loss)
I0925 22:59:44.528035  3547 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0925 22:59:57.790267  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:59:58.347764  3547 solver.cpp:330] Iteration 63000, Testing net (#0)
I0925 23:00:01.669163  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:00:01.807456  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0925 23:00:01.807482  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320906 (* 1 = 0.320906 loss)
I0925 23:00:01.946441  3547 solver.cpp:218] Iteration 63000 (5.74107 iter/s, 17.4184s/100 iters), loss = 0.00128
I0925 23:00:01.946471  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127993 (* 1 = 0.00127993 loss)
I0925 23:00:01.946477  3547 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0925 23:00:15.896148  3547 solver.cpp:218] Iteration 63100 (7.16865 iter/s, 13.9496s/100 iters), loss = 0.0129152
I0925 23:00:15.896179  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129151 (* 1 = 0.0129151 loss)
I0925 23:00:15.896185  3547 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0925 23:00:29.846585  3547 solver.cpp:218] Iteration 63200 (7.16827 iter/s, 13.9504s/100 iters), loss = 0.000959172
I0925 23:00:29.846740  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000959103 (* 1 = 0.000959103 loss)
I0925 23:00:29.846747  3547 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0925 23:00:43.793756  3547 solver.cpp:218] Iteration 63300 (7.17001 iter/s, 13.947s/100 iters), loss = 0.00160911
I0925 23:00:43.793787  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160904 (* 1 = 0.00160904 loss)
I0925 23:00:43.793792  3547 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0925 23:00:57.745501  3547 solver.cpp:218] Iteration 63400 (7.1676 iter/s, 13.9517s/100 iters), loss = 0.000933576
I0925 23:00:57.745530  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000933505 (* 1 = 0.000933505 loss)
I0925 23:00:57.745535  3547 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0925 23:01:11.006909  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:01:11.565466  3547 solver.cpp:330] Iteration 63500, Testing net (#0)
I0925 23:01:14.887596  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:01:15.026494  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0925 23:01:15.026518  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324847 (* 1 = 0.324847 loss)
I0925 23:01:15.164922  3547 solver.cpp:218] Iteration 63500 (5.74075 iter/s, 17.4193s/100 iters), loss = 0.00101098
I0925 23:01:15.164952  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101091 (* 1 = 0.00101091 loss)
I0925 23:01:15.164958  3547 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0925 23:01:29.125599  3547 solver.cpp:218] Iteration 63600 (7.16301 iter/s, 13.9606s/100 iters), loss = 0.00359003
I0925 23:01:29.125640  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358995 (* 1 = 0.00358995 loss)
I0925 23:01:29.125648  3547 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0925 23:01:43.094228  3547 solver.cpp:218] Iteration 63700 (7.15894 iter/s, 13.9685s/100 iters), loss = 0.000751516
I0925 23:01:43.094367  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000751438 (* 1 = 0.000751438 loss)
I0925 23:01:43.094374  3547 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0925 23:01:57.058192  3547 solver.cpp:218] Iteration 63800 (7.16138 iter/s, 13.9638s/100 iters), loss = 0.00418
I0925 23:01:57.058233  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417992 (* 1 = 0.00417992 loss)
I0925 23:01:57.058238  3547 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0925 23:02:11.021883  3547 solver.cpp:218] Iteration 63900 (7.16147 iter/s, 13.9636s/100 iters), loss = 0.00058727
I0925 23:02:11.021925  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000587193 (* 1 = 0.000587193 loss)
I0925 23:02:11.021931  3547 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0925 23:02:24.290005  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:02:24.851457  3547 solver.cpp:330] Iteration 64000, Testing net (#0)
I0925 23:02:28.174254  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:02:28.313067  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0925 23:02:28.313103  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348476 (* 1 = 0.348476 loss)
I0925 23:02:28.451628  3547 solver.cpp:218] Iteration 64000 (5.73735 iter/s, 17.4296s/100 iters), loss = 0.00209725
I0925 23:02:28.451658  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209717 (* 1 = 0.00209717 loss)
I0925 23:02:28.451663  3547 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0925 23:02:42.402016  3547 solver.cpp:218] Iteration 64100 (7.1683 iter/s, 13.9503s/100 iters), loss = 0.00474025
I0925 23:02:42.402057  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474017 (* 1 = 0.00474017 loss)
I0925 23:02:42.402063  3547 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0925 23:02:56.351081  3547 solver.cpp:218] Iteration 64200 (7.16898 iter/s, 13.949s/100 iters), loss = 0.000656399
I0925 23:02:56.351189  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000656324 (* 1 = 0.000656324 loss)
I0925 23:02:56.351197  3547 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0925 23:03:10.297252  3547 solver.cpp:218] Iteration 64300 (7.17051 iter/s, 13.946s/100 iters), loss = 0.00620425
I0925 23:03:10.297293  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00620417 (* 1 = 0.00620417 loss)
I0925 23:03:10.297299  3547 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0925 23:03:24.249900  3547 solver.cpp:218] Iteration 64400 (7.16714 iter/s, 13.9526s/100 iters), loss = 0.0017639
I0925 23:03:24.249943  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176383 (* 1 = 0.00176383 loss)
I0925 23:03:24.249948  3547 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0925 23:03:37.505550  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:03:38.064141  3547 solver.cpp:330] Iteration 64500, Testing net (#0)
I0925 23:03:41.384999  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:03:41.523946  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I0925 23:03:41.523980  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350977 (* 1 = 0.350977 loss)
I0925 23:03:41.662886  3547 solver.cpp:218] Iteration 64500 (5.74287 iter/s, 17.4129s/100 iters), loss = 0.000578849
I0925 23:03:41.662915  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00057878 (* 1 = 0.00057878 loss)
I0925 23:03:41.662921  3547 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0925 23:03:55.609617  3547 solver.cpp:218] Iteration 64600 (7.17018 iter/s, 13.9467s/100 iters), loss = 0.000875826
I0925 23:03:55.609658  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000875758 (* 1 = 0.000875758 loss)
I0925 23:03:55.609664  3547 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0925 23:04:09.554729  3547 solver.cpp:218] Iteration 64700 (7.17101 iter/s, 13.945s/100 iters), loss = 0.00126497
I0925 23:04:09.554811  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012649 (* 1 = 0.0012649 loss)
I0925 23:04:09.554828  3547 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0925 23:04:23.504293  3547 solver.cpp:218] Iteration 64800 (7.16875 iter/s, 13.9494s/100 iters), loss = 0.00174302
I0925 23:04:23.504323  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174295 (* 1 = 0.00174295 loss)
I0925 23:04:23.504338  3547 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0925 23:04:37.453960  3547 solver.cpp:218] Iteration 64900 (7.16867 iter/s, 13.9496s/100 iters), loss = 0.00293894
I0925 23:04:37.453991  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293887 (* 1 = 0.00293887 loss)
I0925 23:04:37.453997  3547 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0925 23:04:50.707093  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:04:51.264087  3547 solver.cpp:330] Iteration 65000, Testing net (#0)
I0925 23:04:54.585263  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:04:54.723839  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I0925 23:04:54.723875  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322477 (* 1 = 0.322477 loss)
I0925 23:04:54.862407  3547 solver.cpp:218] Iteration 65000 (5.74437 iter/s, 17.4084s/100 iters), loss = 0.000866813
I0925 23:04:54.862435  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000866744 (* 1 = 0.000866744 loss)
I0925 23:04:54.862442  3547 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0925 23:05:08.817601  3547 solver.cpp:218] Iteration 65100 (7.16583 iter/s, 13.9551s/100 iters), loss = 0.003255
I0925 23:05:08.817631  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325493 (* 1 = 0.00325493 loss)
I0925 23:05:08.817638  3547 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0925 23:05:22.769186  3547 solver.cpp:218] Iteration 65200 (7.16768 iter/s, 13.9515s/100 iters), loss = 0.0016268
I0925 23:05:22.769301  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162673 (* 1 = 0.00162673 loss)
I0925 23:05:22.769309  3547 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0925 23:05:36.727574  3547 solver.cpp:218] Iteration 65300 (7.16423 iter/s, 13.9582s/100 iters), loss = 0.00450996
I0925 23:05:36.727605  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450989 (* 1 = 0.00450989 loss)
I0925 23:05:36.727610  3547 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0925 23:05:50.681396  3547 solver.cpp:218] Iteration 65400 (7.16653 iter/s, 13.9537s/100 iters), loss = 0.00140823
I0925 23:05:50.681426  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140816 (* 1 = 0.00140816 loss)
I0925 23:05:50.681432  3547 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0925 23:06:03.940419  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:06:04.497388  3547 solver.cpp:330] Iteration 65500, Testing net (#0)
I0925 23:06:07.820245  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:06:07.958818  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I0925 23:06:07.958853  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33242 (* 1 = 0.33242 loss)
I0925 23:06:08.097811  3547 solver.cpp:218] Iteration 65500 (5.74174 iter/s, 17.4163s/100 iters), loss = 0.00134023
I0925 23:06:08.097841  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134016 (* 1 = 0.00134016 loss)
I0925 23:06:08.097848  3547 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0925 23:06:22.049274  3547 solver.cpp:218] Iteration 65600 (7.16775 iter/s, 13.9514s/100 iters), loss = 0.00157469
I0925 23:06:22.049305  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157461 (* 1 = 0.00157461 loss)
I0925 23:06:22.049311  3547 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0925 23:06:36.005367  3547 solver.cpp:218] Iteration 65700 (7.16537 iter/s, 13.956s/100 iters), loss = 0.00574102
I0925 23:06:36.005502  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574095 (* 1 = 0.00574095 loss)
I0925 23:06:36.005511  3547 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0925 23:06:49.952477  3547 solver.cpp:218] Iteration 65800 (7.17003 iter/s, 13.9469s/100 iters), loss = 0.000932314
I0925 23:06:49.952510  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000932239 (* 1 = 0.000932239 loss)
I0925 23:06:49.952517  3547 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0925 23:07:03.899047  3547 solver.cpp:218] Iteration 65900 (7.17026 iter/s, 13.9465s/100 iters), loss = 0.000858379
I0925 23:07:03.899077  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000858304 (* 1 = 0.000858304 loss)
I0925 23:07:03.899083  3547 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0925 23:07:17.159145  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:07:17.717526  3547 solver.cpp:330] Iteration 66000, Testing net (#0)
I0925 23:07:21.039271  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:07:21.177994  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0925 23:07:21.178020  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348032 (* 1 = 0.348032 loss)
I0925 23:07:21.316498  3547 solver.cpp:218] Iteration 66000 (5.7414 iter/s, 17.4174s/100 iters), loss = 0.00113485
I0925 23:07:21.316529  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113477 (* 1 = 0.00113477 loss)
I0925 23:07:21.316535  3547 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0925 23:07:35.248833  3547 solver.cpp:218] Iteration 66100 (7.17759 iter/s, 13.9323s/100 iters), loss = 0.00392753
I0925 23:07:35.248864  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392745 (* 1 = 0.00392745 loss)
I0925 23:07:35.248869  3547 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0925 23:07:49.188266  3547 solver.cpp:218] Iteration 66200 (7.17393 iter/s, 13.9394s/100 iters), loss = 0.00145417
I0925 23:07:49.188400  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145409 (* 1 = 0.00145409 loss)
I0925 23:07:49.188406  3547 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0925 23:08:03.137135  3547 solver.cpp:218] Iteration 66300 (7.16913 iter/s, 13.9487s/100 iters), loss = 0.000941454
I0925 23:08:03.137174  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000941383 (* 1 = 0.000941383 loss)
I0925 23:08:03.137181  3547 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0925 23:08:17.069965  3547 solver.cpp:218] Iteration 66400 (7.17734 iter/s, 13.9327s/100 iters), loss = 0.00135465
I0925 23:08:17.069995  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135458 (* 1 = 0.00135458 loss)
I0925 23:08:17.070001  3547 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0925 23:08:30.317113  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:08:30.876545  3547 solver.cpp:330] Iteration 66500, Testing net (#0)
I0925 23:08:34.197501  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:08:34.336011  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0925 23:08:34.336046  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326064 (* 1 = 0.326064 loss)
I0925 23:08:34.474109  3547 solver.cpp:218] Iteration 66500 (5.74579 iter/s, 17.4041s/100 iters), loss = 0.00144995
I0925 23:08:34.474140  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144988 (* 1 = 0.00144988 loss)
I0925 23:08:34.474146  3547 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0925 23:08:48.421830  3547 solver.cpp:218] Iteration 66600 (7.16967 iter/s, 13.9476s/100 iters), loss = 0.00076445
I0925 23:08:48.421860  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000764383 (* 1 = 0.000764383 loss)
I0925 23:08:48.421867  3547 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0925 23:09:02.374876  3547 solver.cpp:218] Iteration 66700 (7.16693 iter/s, 13.953s/100 iters), loss = 0.000901619
I0925 23:09:02.374984  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000901553 (* 1 = 0.000901553 loss)
I0925 23:09:02.374991  3547 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0925 23:09:16.325058  3547 solver.cpp:218] Iteration 66800 (7.16844 iter/s, 13.95s/100 iters), loss = 0.000817547
I0925 23:09:16.325098  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00081748 (* 1 = 0.00081748 loss)
I0925 23:09:16.325104  3547 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0925 23:09:30.280608  3547 solver.cpp:218] Iteration 66900 (7.16565 iter/s, 13.9555s/100 iters), loss = 0.000720933
I0925 23:09:30.280637  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000720867 (* 1 = 0.000720867 loss)
I0925 23:09:30.280644  3547 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0925 23:09:43.540287  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:09:44.098126  3547 solver.cpp:330] Iteration 67000, Testing net (#0)
I0925 23:09:47.419821  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:09:47.558670  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I0925 23:09:47.558706  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328439 (* 1 = 0.328439 loss)
I0925 23:09:47.697155  3547 solver.cpp:218] Iteration 67000 (5.74169 iter/s, 17.4165s/100 iters), loss = 0.00210595
I0925 23:09:47.697185  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210589 (* 1 = 0.00210589 loss)
I0925 23:09:47.697191  3547 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0925 23:10:01.630584  3547 solver.cpp:218] Iteration 67100 (7.17702 iter/s, 13.9334s/100 iters), loss = 0.00729156
I0925 23:10:01.630614  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00729149 (* 1 = 0.00729149 loss)
I0925 23:10:01.630620  3547 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0925 23:10:15.567601  3547 solver.cpp:218] Iteration 67200 (7.17518 iter/s, 13.9369s/100 iters), loss = 0.00119678
I0925 23:10:15.567747  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119672 (* 1 = 0.00119672 loss)
I0925 23:10:15.567756  3547 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0925 23:10:29.496417  3547 solver.cpp:218] Iteration 67300 (7.17946 iter/s, 13.9286s/100 iters), loss = 0.00412871
I0925 23:10:29.496444  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412865 (* 1 = 0.00412865 loss)
I0925 23:10:29.496450  3547 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0925 23:10:43.434057  3547 solver.cpp:218] Iteration 67400 (7.17485 iter/s, 13.9376s/100 iters), loss = 0.00243859
I0925 23:10:43.434098  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243852 (* 1 = 0.00243852 loss)
I0925 23:10:43.434104  3547 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0925 23:10:56.678198  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:10:57.234505  3547 solver.cpp:330] Iteration 67500, Testing net (#0)
I0925 23:11:00.556653  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:11:00.695660  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0925 23:11:00.695684  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330243 (* 1 = 0.330243 loss)
I0925 23:11:00.833880  3547 solver.cpp:218] Iteration 67500 (5.74722 iter/s, 17.3997s/100 iters), loss = 0.00201866
I0925 23:11:00.833910  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201859 (* 1 = 0.00201859 loss)
I0925 23:11:00.833916  3547 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0925 23:11:14.785208  3547 solver.cpp:218] Iteration 67600 (7.16782 iter/s, 13.9513s/100 iters), loss = 0.00312511
I0925 23:11:14.785238  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312504 (* 1 = 0.00312504 loss)
I0925 23:11:14.785243  3547 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0925 23:11:28.733417  3547 solver.cpp:218] Iteration 67700 (7.16942 iter/s, 13.9481s/100 iters), loss = 0.00324756
I0925 23:11:28.733528  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324749 (* 1 = 0.00324749 loss)
I0925 23:11:28.733544  3547 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0925 23:11:42.686354  3547 solver.cpp:218] Iteration 67800 (7.16703 iter/s, 13.9528s/100 iters), loss = 0.000957948
I0925 23:11:42.686384  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000957876 (* 1 = 0.000957876 loss)
I0925 23:11:42.686390  3547 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0925 23:11:56.630601  3547 solver.cpp:218] Iteration 67900 (7.17145 iter/s, 13.9442s/100 iters), loss = 0.000712533
I0925 23:11:56.630631  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000712462 (* 1 = 0.000712462 loss)
I0925 23:11:56.630637  3547 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0925 23:12:09.884855  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:12:10.444051  3547 solver.cpp:330] Iteration 68000, Testing net (#0)
I0925 23:12:13.765395  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:12:13.903666  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0925 23:12:13.903702  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325891 (* 1 = 0.325891 loss)
I0925 23:12:14.042277  3547 solver.cpp:218] Iteration 68000 (5.7433 iter/s, 17.4116s/100 iters), loss = 0.00167506
I0925 23:12:14.042306  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167499 (* 1 = 0.00167499 loss)
I0925 23:12:14.042312  3547 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0925 23:12:27.991539  3547 solver.cpp:218] Iteration 68100 (7.16888 iter/s, 13.9492s/100 iters), loss = 0.0350191
I0925 23:12:27.991577  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035019 (* 1 = 0.035019 loss)
I0925 23:12:27.991583  3547 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0925 23:12:41.944413  3547 solver.cpp:218] Iteration 68200 (7.16702 iter/s, 13.9528s/100 iters), loss = 0.00289196
I0925 23:12:41.944555  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289188 (* 1 = 0.00289188 loss)
I0925 23:12:41.944563  3547 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0925 23:12:55.898946  3547 solver.cpp:218] Iteration 68300 (7.16622 iter/s, 13.9544s/100 iters), loss = 0.0056729
I0925 23:12:55.898973  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567283 (* 1 = 0.00567283 loss)
I0925 23:12:55.898989  3547 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0925 23:13:09.848532  3547 solver.cpp:218] Iteration 68400 (7.16871 iter/s, 13.9495s/100 iters), loss = 0.00134123
I0925 23:13:09.848562  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134116 (* 1 = 0.00134116 loss)
I0925 23:13:09.848568  3547 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0925 23:13:23.104802  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:13:23.663446  3547 solver.cpp:330] Iteration 68500, Testing net (#0)
I0925 23:13:26.984560  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:13:27.123392  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0925 23:13:27.123416  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325833 (* 1 = 0.325833 loss)
I0925 23:13:27.261802  3547 solver.cpp:218] Iteration 68500 (5.74277 iter/s, 17.4132s/100 iters), loss = 0.00402021
I0925 23:13:27.261831  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402014 (* 1 = 0.00402014 loss)
I0925 23:13:27.261837  3547 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0925 23:13:41.214043  3547 solver.cpp:218] Iteration 68600 (7.16735 iter/s, 13.9522s/100 iters), loss = 0.00278458
I0925 23:13:41.214083  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278451 (* 1 = 0.00278451 loss)
I0925 23:13:41.214088  3547 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0925 23:13:55.170691  3547 solver.cpp:218] Iteration 68700 (7.16509 iter/s, 13.9566s/100 iters), loss = 0.00127173
I0925 23:13:55.170804  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127166 (* 1 = 0.00127166 loss)
I0925 23:13:55.170811  3547 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0925 23:14:09.121384  3547 solver.cpp:218] Iteration 68800 (7.16818 iter/s, 13.9505s/100 iters), loss = 0.00312205
I0925 23:14:09.121414  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312199 (* 1 = 0.00312199 loss)
I0925 23:14:09.121420  3547 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0925 23:14:23.083825  3547 solver.cpp:218] Iteration 68900 (7.16211 iter/s, 13.9624s/100 iters), loss = 0.000678755
I0925 23:14:23.083865  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000678688 (* 1 = 0.000678688 loss)
I0925 23:14:23.083871  3547 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0925 23:14:36.348604  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:14:36.907243  3547 solver.cpp:330] Iteration 69000, Testing net (#0)
I0925 23:14:40.227818  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:14:40.366211  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0925 23:14:40.366247  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342012 (* 1 = 0.342012 loss)
I0925 23:14:40.504901  3547 solver.cpp:218] Iteration 69000 (5.7402 iter/s, 17.421s/100 iters), loss = 0.00106643
I0925 23:14:40.504930  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106636 (* 1 = 0.00106636 loss)
I0925 23:14:40.504937  3547 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0925 23:14:54.446444  3547 solver.cpp:218] Iteration 69100 (7.17284 iter/s, 13.9415s/100 iters), loss = 0.00384876
I0925 23:14:54.446483  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038487 (* 1 = 0.0038487 loss)
I0925 23:14:54.446491  3547 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0925 23:15:08.394322  3547 solver.cpp:218] Iteration 69200 (7.16959 iter/s, 13.9478s/100 iters), loss = 0.00569272
I0925 23:15:08.394429  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569266 (* 1 = 0.00569266 loss)
I0925 23:15:08.394438  3547 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0925 23:15:22.335706  3547 solver.cpp:218] Iteration 69300 (7.17297 iter/s, 13.9412s/100 iters), loss = 0.00515263
I0925 23:15:22.335747  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515257 (* 1 = 0.00515257 loss)
I0925 23:15:22.335752  3547 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0925 23:15:36.285163  3547 solver.cpp:218] Iteration 69400 (7.16878 iter/s, 13.9494s/100 iters), loss = 0.00192325
I0925 23:15:36.285203  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192318 (* 1 = 0.00192318 loss)
I0925 23:15:36.285209  3547 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0925 23:15:49.544764  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:15:50.102495  3547 solver.cpp:330] Iteration 69500, Testing net (#0)
I0925 23:15:53.425549  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:15:53.564222  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0925 23:15:53.564258  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345459 (* 1 = 0.345459 loss)
I0925 23:15:53.702561  3547 solver.cpp:218] Iteration 69500 (5.74142 iter/s, 17.4173s/100 iters), loss = 0.00384629
I0925 23:15:53.702590  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384623 (* 1 = 0.00384623 loss)
I0925 23:15:53.702597  3547 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0925 23:16:07.644841  3547 solver.cpp:218] Iteration 69600 (7.17246 iter/s, 13.9422s/100 iters), loss = 0.00567514
I0925 23:16:07.644882  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567507 (* 1 = 0.00567507 loss)
I0925 23:16:07.644888  3547 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0925 23:16:21.582798  3547 solver.cpp:218] Iteration 69700 (7.1747 iter/s, 13.9379s/100 iters), loss = 0.00241553
I0925 23:16:21.582885  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241546 (* 1 = 0.00241546 loss)
I0925 23:16:21.582903  3547 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0925 23:16:35.524518  3547 solver.cpp:218] Iteration 69800 (7.17278 iter/s, 13.9416s/100 iters), loss = 0.00115306
I0925 23:16:35.524547  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115299 (* 1 = 0.00115299 loss)
I0925 23:16:35.524552  3547 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0925 23:16:49.471127  3547 solver.cpp:218] Iteration 69900 (7.17024 iter/s, 13.9465s/100 iters), loss = 0.00850745
I0925 23:16:49.471158  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00850739 (* 1 = 0.00850739 loss)
I0925 23:16:49.471163  3547 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0925 23:17:02.728276  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:17:03.286264  3547 solver.cpp:330] Iteration 70000, Testing net (#0)
I0925 23:17:06.606292  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:17:06.745239  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0925 23:17:06.745275  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327875 (* 1 = 0.327875 loss)
I0925 23:17:06.883934  3547 solver.cpp:218] Iteration 70000 (5.74293 iter/s, 17.4127s/100 iters), loss = 0.000378088
I0925 23:17:06.883975  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00037803 (* 1 = 0.00037803 loss)
I0925 23:17:06.883982  3547 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0925 23:17:20.835618  3547 solver.cpp:218] Iteration 70100 (7.16764 iter/s, 13.9516s/100 iters), loss = 0.00270988
I0925 23:17:20.835647  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270982 (* 1 = 0.00270982 loss)
I0925 23:17:20.835654  3547 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0925 23:17:34.792444  3547 solver.cpp:218] Iteration 70200 (7.16499 iter/s, 13.9568s/100 iters), loss = 0.00139357
I0925 23:17:34.792548  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139351 (* 1 = 0.00139351 loss)
I0925 23:17:34.792556  3547 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0925 23:17:48.753010  3547 solver.cpp:218] Iteration 70300 (7.16311 iter/s, 13.9604s/100 iters), loss = 0.00707297
I0925 23:17:48.753039  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707292 (* 1 = 0.00707292 loss)
I0925 23:17:48.753044  3547 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0925 23:18:02.713024  3547 solver.cpp:218] Iteration 70400 (7.16335 iter/s, 13.9599s/100 iters), loss = 0.00040401
I0925 23:18:02.713064  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000403954 (* 1 = 0.000403954 loss)
I0925 23:18:02.713070  3547 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0925 23:18:15.975651  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:18:16.532972  3547 solver.cpp:330] Iteration 70500, Testing net (#0)
I0925 23:18:19.851864  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:18:19.990578  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0925 23:18:19.990614  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319897 (* 1 = 0.319897 loss)
I0925 23:18:20.129169  3547 solver.cpp:218] Iteration 70500 (5.74183 iter/s, 17.4161s/100 iters), loss = 0.0145043
I0925 23:18:20.129197  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145042 (* 1 = 0.0145042 loss)
I0925 23:18:20.129204  3547 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0925 23:18:34.082173  3547 solver.cpp:218] Iteration 70600 (7.16695 iter/s, 13.9529s/100 iters), loss = 0.000760674
I0925 23:18:34.082216  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000760619 (* 1 = 0.000760619 loss)
I0925 23:18:34.082221  3547 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0925 23:18:48.043849  3547 solver.cpp:218] Iteration 70700 (7.16251 iter/s, 13.9616s/100 iters), loss = 0.000954323
I0925 23:18:48.043983  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000954268 (* 1 = 0.000954268 loss)
I0925 23:18:48.043990  3547 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0925 23:19:02.001312  3547 solver.cpp:218] Iteration 70800 (7.16471 iter/s, 13.9573s/100 iters), loss = 0.000981291
I0925 23:19:02.001353  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000981233 (* 1 = 0.000981233 loss)
I0925 23:19:02.001359  3547 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0925 23:19:15.953866  3547 solver.cpp:218] Iteration 70900 (7.16719 iter/s, 13.9525s/100 iters), loss = 0.00172421
I0925 23:19:15.953908  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172415 (* 1 = 0.00172415 loss)
I0925 23:19:15.953914  3547 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0925 23:19:29.221245  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:19:29.780136  3547 solver.cpp:330] Iteration 71000, Testing net (#0)
I0925 23:19:33.100797  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:19:33.239703  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0925 23:19:33.239739  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326063 (* 1 = 0.326063 loss)
I0925 23:19:33.378010  3547 solver.cpp:218] Iteration 71000 (5.73919 iter/s, 17.4241s/100 iters), loss = 0.000848669
I0925 23:19:33.378038  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000848612 (* 1 = 0.000848612 loss)
I0925 23:19:33.378046  3547 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0925 23:19:47.335577  3547 solver.cpp:218] Iteration 71100 (7.16461 iter/s, 13.9575s/100 iters), loss = 0.00128812
I0925 23:19:47.335618  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128806 (* 1 = 0.00128806 loss)
I0925 23:19:47.335623  3547 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0925 23:20:01.294399  3547 solver.cpp:218] Iteration 71200 (7.16397 iter/s, 13.9587s/100 iters), loss = 0.000575713
I0925 23:20:01.294519  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000575661 (* 1 = 0.000575661 loss)
I0925 23:20:01.294536  3547 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0925 23:20:15.255525  3547 solver.cpp:218] Iteration 71300 (7.16282 iter/s, 13.961s/100 iters), loss = 0.000986894
I0925 23:20:15.255555  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000986841 (* 1 = 0.000986841 loss)
I0925 23:20:15.255561  3547 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0925 23:20:29.210204  3547 solver.cpp:218] Iteration 71400 (7.16609 iter/s, 13.9546s/100 iters), loss = 0.00256117
I0925 23:20:29.210235  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256112 (* 1 = 0.00256112 loss)
I0925 23:20:29.210242  3547 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0925 23:20:42.478296  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:20:43.037323  3547 solver.cpp:330] Iteration 71500, Testing net (#0)
I0925 23:20:46.357949  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:20:46.496991  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0925 23:20:46.497016  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316502 (* 1 = 0.316502 loss)
I0925 23:20:46.635207  3547 solver.cpp:218] Iteration 71500 (5.73891 iter/s, 17.4249s/100 iters), loss = 0.00144863
I0925 23:20:46.635236  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144858 (* 1 = 0.00144858 loss)
I0925 23:20:46.635243  3547 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0925 23:21:00.588517  3547 solver.cpp:218] Iteration 71600 (7.1668 iter/s, 13.9532s/100 iters), loss = 0.001457
I0925 23:21:00.588547  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145696 (* 1 = 0.00145696 loss)
I0925 23:21:00.588553  3547 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0925 23:21:14.546782  3547 solver.cpp:218] Iteration 71700 (7.16425 iter/s, 13.9582s/100 iters), loss = 0.00227499
I0925 23:21:14.546887  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227494 (* 1 = 0.00227494 loss)
I0925 23:21:14.546895  3547 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0925 23:21:28.502955  3547 solver.cpp:218] Iteration 71800 (7.16536 iter/s, 13.956s/100 iters), loss = 0.00107304
I0925 23:21:28.502985  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001073 (* 1 = 0.001073 loss)
I0925 23:21:28.502991  3547 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0925 23:21:42.455787  3547 solver.cpp:218] Iteration 71900 (7.16704 iter/s, 13.9528s/100 iters), loss = 0.00552466
I0925 23:21:42.455829  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552462 (* 1 = 0.00552462 loss)
I0925 23:21:42.455835  3547 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0925 23:21:55.713819  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:21:56.273785  3547 solver.cpp:330] Iteration 72000, Testing net (#0)
I0925 23:21:59.593626  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:21:59.731820  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0925 23:21:59.731856  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335158 (* 1 = 0.335158 loss)
I0925 23:21:59.869720  3547 solver.cpp:218] Iteration 72000 (5.74256 iter/s, 17.4138s/100 iters), loss = 0.000717905
I0925 23:21:59.869748  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000717854 (* 1 = 0.000717854 loss)
I0925 23:21:59.869755  3547 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0925 23:22:13.806957  3547 solver.cpp:218] Iteration 72100 (7.17506 iter/s, 13.9372s/100 iters), loss = 0.00203527
I0925 23:22:13.806988  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203522 (* 1 = 0.00203522 loss)
I0925 23:22:13.806994  3547 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0925 23:22:27.744402  3547 solver.cpp:218] Iteration 72200 (7.17495 iter/s, 13.9374s/100 iters), loss = 0.000763795
I0925 23:22:27.744552  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000763743 (* 1 = 0.000763743 loss)
I0925 23:22:27.744561  3547 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0925 23:22:41.682083  3547 solver.cpp:218] Iteration 72300 (7.17489 iter/s, 13.9375s/100 iters), loss = 0.00351065
I0925 23:22:41.682114  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035106 (* 1 = 0.0035106 loss)
I0925 23:22:41.682121  3547 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0925 23:22:55.622984  3547 solver.cpp:218] Iteration 72400 (7.17317 iter/s, 13.9408s/100 iters), loss = 0.000832857
I0925 23:22:55.623024  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000832805 (* 1 = 0.000832805 loss)
I0925 23:22:55.623030  3547 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0925 23:23:08.868640  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:23:09.425786  3547 solver.cpp:330] Iteration 72500, Testing net (#0)
I0925 23:23:12.746978  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:23:12.885926  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9251
I0925 23:23:12.885963  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314505 (* 1 = 0.314505 loss)
I0925 23:23:13.023689  3547 solver.cpp:218] Iteration 72500 (5.74692 iter/s, 17.4006s/100 iters), loss = 0.00628595
I0925 23:23:13.023718  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0062859 (* 1 = 0.0062859 loss)
I0925 23:23:13.023725  3547 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0925 23:23:26.960649  3547 solver.cpp:218] Iteration 72600 (7.1752 iter/s, 13.9369s/100 iters), loss = 0.000635345
I0925 23:23:26.960690  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000635295 (* 1 = 0.000635295 loss)
I0925 23:23:26.960697  3547 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0925 23:23:40.896684  3547 solver.cpp:218] Iteration 72700 (7.17568 iter/s, 13.936s/100 iters), loss = 0.00108786
I0925 23:23:40.896824  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108781 (* 1 = 0.00108781 loss)
I0925 23:23:40.896833  3547 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0925 23:23:54.845026  3547 solver.cpp:218] Iteration 72800 (7.1694 iter/s, 13.9482s/100 iters), loss = 0.00103716
I0925 23:23:54.845055  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103711 (* 1 = 0.00103711 loss)
I0925 23:23:54.845062  3547 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0925 23:24:08.798050  3547 solver.cpp:218] Iteration 72900 (7.16694 iter/s, 13.953s/100 iters), loss = 0.00207627
I0925 23:24:08.798079  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207622 (* 1 = 0.00207622 loss)
I0925 23:24:08.798084  3547 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0925 23:24:22.046850  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:24:22.604864  3547 solver.cpp:330] Iteration 73000, Testing net (#0)
I0925 23:24:25.925853  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:24:26.064132  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I0925 23:24:26.064168  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340646 (* 1 = 0.340646 loss)
I0925 23:24:26.202924  3547 solver.cpp:218] Iteration 73000 (5.74554 iter/s, 17.4048s/100 iters), loss = 0.00104288
I0925 23:24:26.202952  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104283 (* 1 = 0.00104283 loss)
I0925 23:24:26.202960  3547 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0925 23:24:40.157285  3547 solver.cpp:218] Iteration 73100 (7.16625 iter/s, 13.9543s/100 iters), loss = 0.00159608
I0925 23:24:40.157325  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159603 (* 1 = 0.00159603 loss)
I0925 23:24:40.157331  3547 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0925 23:24:54.115706  3547 solver.cpp:218] Iteration 73200 (7.16417 iter/s, 13.9583s/100 iters), loss = 0.00172905
I0925 23:24:54.115821  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001729 (* 1 = 0.001729 loss)
I0925 23:24:54.115829  3547 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0925 23:25:08.076715  3547 solver.cpp:218] Iteration 73300 (7.16288 iter/s, 13.9609s/100 iters), loss = 0.00150188
I0925 23:25:08.076746  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150182 (* 1 = 0.00150182 loss)
I0925 23:25:08.076752  3547 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0925 23:25:22.036061  3547 solver.cpp:218] Iteration 73400 (7.1637 iter/s, 13.9593s/100 iters), loss = 0.000426407
I0925 23:25:22.036092  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000426356 (* 1 = 0.000426356 loss)
I0925 23:25:22.036098  3547 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0925 23:25:35.296589  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:25:35.855603  3547 solver.cpp:330] Iteration 73500, Testing net (#0)
I0925 23:25:39.177407  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:25:39.315862  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0925 23:25:39.315897  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329294 (* 1 = 0.329294 loss)
I0925 23:25:39.454252  3547 solver.cpp:218] Iteration 73500 (5.74115 iter/s, 17.4181s/100 iters), loss = 0.00123551
I0925 23:25:39.454283  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123546 (* 1 = 0.00123546 loss)
I0925 23:25:39.454289  3547 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0925 23:25:53.399338  3547 solver.cpp:218] Iteration 73600 (7.17102 iter/s, 13.945s/100 iters), loss = 0.00415398
I0925 23:25:53.399369  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415393 (* 1 = 0.00415393 loss)
I0925 23:25:53.399375  3547 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0925 23:26:07.346585  3547 solver.cpp:218] Iteration 73700 (7.16991 iter/s, 13.9472s/100 iters), loss = 0.0156329
I0925 23:26:07.346711  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156328 (* 1 = 0.0156328 loss)
I0925 23:26:07.346727  3547 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0925 23:26:21.289134  3547 solver.cpp:218] Iteration 73800 (7.17237 iter/s, 13.9424s/100 iters), loss = 0.00197622
I0925 23:26:21.289175  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197617 (* 1 = 0.00197617 loss)
I0925 23:26:21.289181  3547 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0925 23:26:35.231676  3547 solver.cpp:218] Iteration 73900 (7.17233 iter/s, 13.9425s/100 iters), loss = 0.00193073
I0925 23:26:35.231716  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193067 (* 1 = 0.00193067 loss)
I0925 23:26:35.231722  3547 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0925 23:26:48.488606  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:26:49.045881  3547 solver.cpp:330] Iteration 74000, Testing net (#0)
I0925 23:26:52.367785  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:26:52.506005  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0925 23:26:52.506029  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329404 (* 1 = 0.329404 loss)
I0925 23:26:52.644508  3547 solver.cpp:218] Iteration 74000 (5.74292 iter/s, 17.4127s/100 iters), loss = 0.00132305
I0925 23:26:52.644538  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001323 (* 1 = 0.001323 loss)
I0925 23:26:52.644544  3547 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0925 23:27:06.596611  3547 solver.cpp:218] Iteration 74100 (7.16741 iter/s, 13.952s/100 iters), loss = 0.00275963
I0925 23:27:06.596642  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275958 (* 1 = 0.00275958 loss)
I0925 23:27:06.596659  3547 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0925 23:27:20.548123  3547 solver.cpp:218] Iteration 74200 (7.16772 iter/s, 13.9514s/100 iters), loss = 0.0021006
I0925 23:27:20.548265  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210055 (* 1 = 0.00210055 loss)
I0925 23:27:20.548274  3547 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0925 23:27:34.497663  3547 solver.cpp:218] Iteration 74300 (7.16878 iter/s, 13.9494s/100 iters), loss = 0.000448769
I0925 23:27:34.497704  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000448719 (* 1 = 0.000448719 loss)
I0925 23:27:34.497711  3547 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0925 23:27:48.443684  3547 solver.cpp:218] Iteration 74400 (7.17054 iter/s, 13.9459s/100 iters), loss = 0.000946083
I0925 23:27:48.443725  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000946035 (* 1 = 0.000946035 loss)
I0925 23:27:48.443732  3547 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0925 23:28:01.704056  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:28:02.262781  3547 solver.cpp:330] Iteration 74500, Testing net (#0)
I0925 23:28:05.583099  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:28:05.721985  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0925 23:28:05.722020  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328383 (* 1 = 0.328383 loss)
I0925 23:28:05.859752  3547 solver.cpp:218] Iteration 74500 (5.74185 iter/s, 17.416s/100 iters), loss = 0.000743992
I0925 23:28:05.859783  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000743945 (* 1 = 0.000743945 loss)
I0925 23:28:05.859789  3547 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0925 23:28:19.811727  3547 solver.cpp:218] Iteration 74600 (7.16748 iter/s, 13.9519s/100 iters), loss = 0.00102071
I0925 23:28:19.811756  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102066 (* 1 = 0.00102066 loss)
I0925 23:28:19.811763  3547 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0925 23:28:33.768098  3547 solver.cpp:218] Iteration 74700 (7.16522 iter/s, 13.9563s/100 iters), loss = 0.000590127
I0925 23:28:33.768204  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000590078 (* 1 = 0.000590078 loss)
I0925 23:28:33.768210  3547 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0925 23:28:47.725054  3547 solver.cpp:218] Iteration 74800 (7.16495 iter/s, 13.9568s/100 iters), loss = 0.00958178
I0925 23:28:47.725083  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00958173 (* 1 = 0.00958173 loss)
I0925 23:28:47.725090  3547 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0925 23:29:01.680616  3547 solver.cpp:218] Iteration 74900 (7.16564 iter/s, 13.9555s/100 iters), loss = 0.000757077
I0925 23:29:01.680645  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000757026 (* 1 = 0.000757026 loss)
I0925 23:29:01.680651  3547 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0925 23:29:14.941534  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:29:15.499596  3547 solver.cpp:330] Iteration 75000, Testing net (#0)
I0925 23:29:18.822283  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:29:18.960381  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0925 23:29:18.960417  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324312 (* 1 = 0.324312 loss)
I0925 23:29:19.098783  3547 solver.cpp:218] Iteration 75000 (5.74116 iter/s, 17.4181s/100 iters), loss = 0.000783359
I0925 23:29:19.098814  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000783306 (* 1 = 0.000783306 loss)
I0925 23:29:19.098819  3547 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0925 23:29:33.042011  3547 solver.cpp:218] Iteration 75100 (7.17198 iter/s, 13.9432s/100 iters), loss = 0.00147301
I0925 23:29:33.042052  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147296 (* 1 = 0.00147296 loss)
I0925 23:29:33.042058  3547 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0925 23:29:46.991077  3547 solver.cpp:218] Iteration 75200 (7.16898 iter/s, 13.949s/100 iters), loss = 0.00251741
I0925 23:29:46.991222  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251736 (* 1 = 0.00251736 loss)
I0925 23:29:46.991231  3547 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0925 23:30:00.942845  3547 solver.cpp:218] Iteration 75300 (7.16764 iter/s, 13.9516s/100 iters), loss = 0.000271848
I0925 23:30:00.942874  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000271796 (* 1 = 0.000271796 loss)
I0925 23:30:00.942880  3547 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0925 23:30:14.895298  3547 solver.cpp:218] Iteration 75400 (7.16723 iter/s, 13.9524s/100 iters), loss = 0.000835344
I0925 23:30:14.895337  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000835292 (* 1 = 0.000835292 loss)
I0925 23:30:14.895344  3547 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0925 23:30:28.149065  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:30:28.707177  3547 solver.cpp:330] Iteration 75500, Testing net (#0)
I0925 23:30:32.028991  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:30:32.167477  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9251
I0925 23:30:32.167501  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316677 (* 1 = 0.316677 loss)
I0925 23:30:32.305197  3547 solver.cpp:218] Iteration 75500 (5.74389 iter/s, 17.4098s/100 iters), loss = 0.000859743
I0925 23:30:32.305225  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000859692 (* 1 = 0.000859692 loss)
I0925 23:30:32.305232  3547 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0925 23:30:46.253533  3547 solver.cpp:218] Iteration 75600 (7.16935 iter/s, 13.9483s/100 iters), loss = 0.000966222
I0925 23:30:46.253562  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000966173 (* 1 = 0.000966173 loss)
I0925 23:30:46.253568  3547 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0925 23:31:00.215605  3547 solver.cpp:218] Iteration 75700 (7.1623 iter/s, 13.962s/100 iters), loss = 0.000741963
I0925 23:31:00.215714  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000741913 (* 1 = 0.000741913 loss)
I0925 23:31:00.215721  3547 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0925 23:31:14.176635  3547 solver.cpp:218] Iteration 75800 (7.16287 iter/s, 13.9609s/100 iters), loss = 0.00116378
I0925 23:31:14.176664  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116373 (* 1 = 0.00116373 loss)
I0925 23:31:14.176669  3547 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0925 23:31:28.125689  3547 solver.cpp:218] Iteration 75900 (7.16898 iter/s, 13.949s/100 iters), loss = 0.00628896
I0925 23:31:28.125718  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628891 (* 1 = 0.00628891 loss)
I0925 23:31:28.125725  3547 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0925 23:31:41.384467  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:31:41.942960  3547 solver.cpp:330] Iteration 76000, Testing net (#0)
I0925 23:31:45.265525  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:31:45.403656  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0925 23:31:45.403682  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325492 (* 1 = 0.325492 loss)
I0925 23:31:45.541697  3547 solver.cpp:218] Iteration 76000 (5.74187 iter/s, 17.4159s/100 iters), loss = 0.000809024
I0925 23:31:45.541726  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000808977 (* 1 = 0.000808977 loss)
I0925 23:31:45.541733  3547 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0925 23:31:59.511137  3547 solver.cpp:218] Iteration 76100 (7.15852 iter/s, 13.9694s/100 iters), loss = 0.00280749
I0925 23:31:59.511178  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280744 (* 1 = 0.00280744 loss)
I0925 23:31:59.511183  3547 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0925 23:32:13.468346  3547 solver.cpp:218] Iteration 76200 (7.1648 iter/s, 13.9571s/100 iters), loss = 0.00253031
I0925 23:32:13.468439  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253026 (* 1 = 0.00253026 loss)
I0925 23:32:13.468458  3547 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0925 23:32:27.431365  3547 solver.cpp:218] Iteration 76300 (7.16184 iter/s, 13.9629s/100 iters), loss = 0.000691063
I0925 23:32:27.431394  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000691014 (* 1 = 0.000691014 loss)
I0925 23:32:27.431401  3547 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0925 23:32:41.392534  3547 solver.cpp:218] Iteration 76400 (7.16276 iter/s, 13.9611s/100 iters), loss = 0.00659392
I0925 23:32:41.392575  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659387 (* 1 = 0.00659387 loss)
I0925 23:32:41.392580  3547 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0925 23:32:54.659814  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:32:55.219097  3547 solver.cpp:330] Iteration 76500, Testing net (#0)
I0925 23:32:58.541251  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:32:58.679860  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0925 23:32:58.679895  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327766 (* 1 = 0.327766 loss)
I0925 23:32:58.818174  3547 solver.cpp:218] Iteration 76500 (5.7387 iter/s, 17.4256s/100 iters), loss = 0.000791553
I0925 23:32:58.818202  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000791504 (* 1 = 0.000791504 loss)
I0925 23:32:58.818209  3547 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0925 23:33:12.761708  3547 solver.cpp:218] Iteration 76600 (7.17182 iter/s, 13.9435s/100 iters), loss = 0.00184529
I0925 23:33:12.761747  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184524 (* 1 = 0.00184524 loss)
I0925 23:33:12.761754  3547 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0925 23:33:26.705655  3547 solver.cpp:218] Iteration 76700 (7.17161 iter/s, 13.9439s/100 iters), loss = 0.000600488
I0925 23:33:26.705750  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000600439 (* 1 = 0.000600439 loss)
I0925 23:33:26.705767  3547 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0925 23:33:40.653465  3547 solver.cpp:218] Iteration 76800 (7.16965 iter/s, 13.9477s/100 iters), loss = 0.000544478
I0925 23:33:40.653506  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000544428 (* 1 = 0.000544428 loss)
I0925 23:33:40.653512  3547 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0925 23:33:54.595136  3547 solver.cpp:218] Iteration 76900 (7.17278 iter/s, 13.9416s/100 iters), loss = 0.00107846
I0925 23:33:54.595176  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107841 (* 1 = 0.00107841 loss)
I0925 23:33:54.595182  3547 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0925 23:34:07.854277  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:34:08.412372  3547 solver.cpp:330] Iteration 77000, Testing net (#0)
I0925 23:34:11.732168  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:34:11.870697  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I0925 23:34:11.870733  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329199 (* 1 = 0.329199 loss)
I0925 23:34:12.008847  3547 solver.cpp:218] Iteration 77000 (5.74263 iter/s, 17.4136s/100 iters), loss = 0.00145032
I0925 23:34:12.008877  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145027 (* 1 = 0.00145027 loss)
I0925 23:34:12.008884  3547 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0925 23:34:25.964203  3547 solver.cpp:218] Iteration 77100 (7.16574 iter/s, 13.9553s/100 iters), loss = 0.00066558
I0925 23:34:25.964243  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000665529 (* 1 = 0.000665529 loss)
I0925 23:34:25.964249  3547 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0925 23:34:39.918781  3547 solver.cpp:218] Iteration 77200 (7.16615 iter/s, 13.9545s/100 iters), loss = 0.00159282
I0925 23:34:39.918895  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159277 (* 1 = 0.00159277 loss)
I0925 23:34:39.918901  3547 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0925 23:34:53.871186  3547 solver.cpp:218] Iteration 77300 (7.1673 iter/s, 13.9523s/100 iters), loss = 0.00200806
I0925 23:34:53.871227  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200801 (* 1 = 0.00200801 loss)
I0925 23:34:53.871232  3547 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0925 23:35:07.825366  3547 solver.cpp:218] Iteration 77400 (7.16635 iter/s, 13.9541s/100 iters), loss = 0.000405428
I0925 23:35:07.825407  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000405378 (* 1 = 0.000405378 loss)
I0925 23:35:07.825412  3547 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0925 23:35:21.085407  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:35:21.644390  3547 solver.cpp:330] Iteration 77500, Testing net (#0)
I0925 23:35:24.967913  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:35:25.106595  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0925 23:35:25.106631  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339567 (* 1 = 0.339567 loss)
I0925 23:35:25.245396  3547 solver.cpp:218] Iteration 77500 (5.74055 iter/s, 17.4199s/100 iters), loss = 0.00618993
I0925 23:35:25.245424  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618988 (* 1 = 0.00618988 loss)
I0925 23:35:25.245431  3547 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0925 23:35:39.194144  3547 solver.cpp:218] Iteration 77600 (7.16914 iter/s, 13.9487s/100 iters), loss = 0.000969619
I0925 23:35:39.194183  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00096957 (* 1 = 0.00096957 loss)
I0925 23:35:39.194190  3547 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0925 23:35:53.143579  3547 solver.cpp:218] Iteration 77700 (7.16879 iter/s, 13.9494s/100 iters), loss = 0.000842236
I0925 23:35:53.143707  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000842187 (* 1 = 0.000842187 loss)
I0925 23:35:53.143713  3547 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0925 23:36:07.088570  3547 solver.cpp:218] Iteration 77800 (7.17111 iter/s, 13.9448s/100 iters), loss = 0.00223766
I0925 23:36:07.088611  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223762 (* 1 = 0.00223762 loss)
I0925 23:36:07.088616  3547 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0925 23:36:21.034672  3547 solver.cpp:218] Iteration 77900 (7.1705 iter/s, 13.946s/100 iters), loss = 0.00170715
I0925 23:36:21.034711  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170711 (* 1 = 0.00170711 loss)
I0925 23:36:21.034718  3547 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0925 23:36:34.294800  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:36:34.852344  3547 solver.cpp:330] Iteration 78000, Testing net (#0)
I0925 23:36:38.174386  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:36:38.312937  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0925 23:36:38.312961  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335715 (* 1 = 0.335715 loss)
I0925 23:36:38.451037  3547 solver.cpp:218] Iteration 78000 (5.74175 iter/s, 17.4163s/100 iters), loss = 0.0054826
I0925 23:36:38.451066  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548255 (* 1 = 0.00548255 loss)
I0925 23:36:38.451073  3547 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0925 23:36:52.399593  3547 solver.cpp:218] Iteration 78100 (7.16924 iter/s, 13.9485s/100 iters), loss = 0.00224941
I0925 23:36:52.399634  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224936 (* 1 = 0.00224936 loss)
I0925 23:36:52.399641  3547 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0925 23:37:06.348991  3547 solver.cpp:218] Iteration 78200 (7.16881 iter/s, 13.9493s/100 iters), loss = 0.000294762
I0925 23:37:06.349107  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000294714 (* 1 = 0.000294714 loss)
I0925 23:37:06.349114  3547 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0925 23:37:20.293097  3547 solver.cpp:218] Iteration 78300 (7.17156 iter/s, 13.944s/100 iters), loss = 0.000763673
I0925 23:37:20.293126  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000763626 (* 1 = 0.000763626 loss)
I0925 23:37:20.293133  3547 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0925 23:37:34.232539  3547 solver.cpp:218] Iteration 78400 (7.17392 iter/s, 13.9394s/100 iters), loss = 0.000495667
I0925 23:37:34.232570  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000495619 (* 1 = 0.000495619 loss)
I0925 23:37:34.232575  3547 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0925 23:37:47.487921  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:37:48.048054  3547 solver.cpp:330] Iteration 78500, Testing net (#0)
I0925 23:37:51.369091  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:37:51.507763  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0925 23:37:51.507788  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335821 (* 1 = 0.335821 loss)
I0925 23:37:51.646209  3547 solver.cpp:218] Iteration 78500 (5.74264 iter/s, 17.4136s/100 iters), loss = 0.000456845
I0925 23:37:51.646244  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000456797 (* 1 = 0.000456797 loss)
I0925 23:37:51.646250  3547 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0925 23:38:05.585248  3547 solver.cpp:218] Iteration 78600 (7.17413 iter/s, 13.939s/100 iters), loss = 0.000583177
I0925 23:38:05.585278  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00058313 (* 1 = 0.00058313 loss)
I0925 23:38:05.585283  3547 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0925 23:38:19.527011  3547 solver.cpp:218] Iteration 78700 (7.17273 iter/s, 13.9417s/100 iters), loss = 0.000985166
I0925 23:38:19.527119  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000985118 (* 1 = 0.000985118 loss)
I0925 23:38:19.527127  3547 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0925 23:38:33.476331  3547 solver.cpp:218] Iteration 78800 (7.16888 iter/s, 13.9492s/100 iters), loss = 0.000535982
I0925 23:38:33.476361  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000535934 (* 1 = 0.000535934 loss)
I0925 23:38:33.476367  3547 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0925 23:38:47.423346  3547 solver.cpp:218] Iteration 78900 (7.17003 iter/s, 13.9469s/100 iters), loss = 0.00283544
I0925 23:38:47.423388  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283539 (* 1 = 0.00283539 loss)
I0925 23:38:47.423394  3547 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0925 23:39:00.677645  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:39:01.233966  3547 solver.cpp:330] Iteration 79000, Testing net (#0)
I0925 23:39:04.555845  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:39:04.694144  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0925 23:39:04.694180  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336693 (* 1 = 0.336693 loss)
I0925 23:39:04.832849  3547 solver.cpp:218] Iteration 79000 (5.74402 iter/s, 17.4094s/100 iters), loss = 0.000252245
I0925 23:39:04.832880  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000252197 (* 1 = 0.000252197 loss)
I0925 23:39:04.832886  3547 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0925 23:39:18.766566  3547 solver.cpp:218] Iteration 79100 (7.17687 iter/s, 13.9336s/100 iters), loss = 0.00149648
I0925 23:39:18.766595  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149643 (* 1 = 0.00149643 loss)
I0925 23:39:18.766602  3547 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0925 23:39:32.714653  3547 solver.cpp:218] Iteration 79200 (7.16948 iter/s, 13.948s/100 iters), loss = 0.0015484
I0925 23:39:32.714797  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154835 (* 1 = 0.00154835 loss)
I0925 23:39:32.714807  3547 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0925 23:39:46.659474  3547 solver.cpp:218] Iteration 79300 (7.17121 iter/s, 13.9446s/100 iters), loss = 0.000394125
I0925 23:39:46.659514  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000394077 (* 1 = 0.000394077 loss)
I0925 23:39:46.659520  3547 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0925 23:40:00.605403  3547 solver.cpp:218] Iteration 79400 (7.17059 iter/s, 13.9459s/100 iters), loss = 0.00169946
I0925 23:40:00.605432  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169941 (* 1 = 0.00169941 loss)
I0925 23:40:00.605438  3547 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0925 23:40:13.848755  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:40:14.407663  3547 solver.cpp:330] Iteration 79500, Testing net (#0)
I0925 23:40:17.729694  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:40:17.868005  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I0925 23:40:17.868039  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324793 (* 1 = 0.324793 loss)
I0925 23:40:18.006299  3547 solver.cpp:218] Iteration 79500 (5.74685 iter/s, 17.4008s/100 iters), loss = 0.000399509
I0925 23:40:18.006330  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000399458 (* 1 = 0.000399458 loss)
I0925 23:40:18.006336  3547 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0925 23:40:31.952702  3547 solver.cpp:218] Iteration 79600 (7.17034 iter/s, 13.9463s/100 iters), loss = 0.00142446
I0925 23:40:31.952742  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142441 (* 1 = 0.00142441 loss)
I0925 23:40:31.952749  3547 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0925 23:40:45.903969  3547 solver.cpp:218] Iteration 79700 (7.16785 iter/s, 13.9512s/100 iters), loss = 0.000960567
I0925 23:40:45.904110  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000960518 (* 1 = 0.000960518 loss)
I0925 23:40:45.904119  3547 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0925 23:40:59.852871  3547 solver.cpp:218] Iteration 79800 (7.16911 iter/s, 13.9487s/100 iters), loss = 0.0075287
I0925 23:40:59.852901  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752865 (* 1 = 0.00752865 loss)
I0925 23:40:59.852907  3547 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0925 23:41:13.804427  3547 solver.cpp:218] Iteration 79900 (7.16769 iter/s, 13.9515s/100 iters), loss = 0.00162083
I0925 23:41:13.804456  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162079 (* 1 = 0.00162079 loss)
I0925 23:41:13.804462  3547 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0925 23:41:27.055430  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:41:27.611620  3547 solver.cpp:330] Iteration 80000, Testing net (#0)
I0925 23:41:30.934684  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:41:31.073426  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0925 23:41:31.073462  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332814 (* 1 = 0.332814 loss)
I0925 23:41:31.211942  3547 solver.cpp:218] Iteration 80000 (5.74467 iter/s, 17.4074s/100 iters), loss = 0.000873578
I0925 23:41:31.211972  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000873531 (* 1 = 0.000873531 loss)
I0925 23:41:31.211977  3547 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0925 23:41:31.211982  3547 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0925 23:41:45.168551  3547 solver.cpp:218] Iteration 80100 (7.1651 iter/s, 13.9565s/100 iters), loss = 0.00258602
I0925 23:41:45.168592  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258597 (* 1 = 0.00258597 loss)
I0925 23:41:45.168598  3547 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0925 23:41:59.130630  3547 solver.cpp:218] Iteration 80200 (7.1623 iter/s, 13.962s/100 iters), loss = 0.00248437
I0925 23:41:59.130771  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248432 (* 1 = 0.00248432 loss)
I0925 23:41:59.130779  3547 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0925 23:42:13.087908  3547 solver.cpp:218] Iteration 80300 (7.16481 iter/s, 13.9571s/100 iters), loss = 0.000470222
I0925 23:42:13.087937  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000470174 (* 1 = 0.000470174 loss)
I0925 23:42:13.087954  3547 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0925 23:42:27.038009  3547 solver.cpp:218] Iteration 80400 (7.16844 iter/s, 13.95s/100 iters), loss = 0.000912029
I0925 23:42:27.038040  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000911981 (* 1 = 0.000911981 loss)
I0925 23:42:27.038056  3547 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0925 23:42:40.307029  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:42:40.867020  3547 solver.cpp:330] Iteration 80500, Testing net (#0)
I0925 23:42:44.191187  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:42:44.330107  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9256
I0925 23:42:44.330142  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316937 (* 1 = 0.316937 loss)
I0925 23:42:44.468576  3547 solver.cpp:218] Iteration 80500 (5.73707 iter/s, 17.4305s/100 iters), loss = 0.000658847
I0925 23:42:44.468606  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000658798 (* 1 = 0.000658798 loss)
I0925 23:42:44.468612  3547 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0925 23:42:58.424587  3547 solver.cpp:218] Iteration 80600 (7.16541 iter/s, 13.9559s/100 iters), loss = 0.00152053
I0925 23:42:58.424628  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152048 (* 1 = 0.00152048 loss)
I0925 23:42:58.424634  3547 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0925 23:43:12.383105  3547 solver.cpp:218] Iteration 80700 (7.16412 iter/s, 13.9584s/100 iters), loss = 0.00128549
I0925 23:43:12.383203  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128544 (* 1 = 0.00128544 loss)
I0925 23:43:12.383220  3547 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0925 23:43:26.337702  3547 solver.cpp:218] Iteration 80800 (7.16616 iter/s, 13.9545s/100 iters), loss = 0.000354818
I0925 23:43:26.337743  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000354766 (* 1 = 0.000354766 loss)
I0925 23:43:26.337749  3547 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0925 23:43:40.293831  3547 solver.cpp:218] Iteration 80900 (7.16535 iter/s, 13.9561s/100 iters), loss = 0.000881944
I0925 23:43:40.293872  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000881892 (* 1 = 0.000881892 loss)
I0925 23:43:40.293879  3547 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0925 23:43:53.561115  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:43:54.118618  3547 solver.cpp:330] Iteration 81000, Testing net (#0)
I0925 23:43:57.440155  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:43:57.578953  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9269
I0925 23:43:57.578989  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311167 (* 1 = 0.311167 loss)
I0925 23:43:57.717416  3547 solver.cpp:218] Iteration 81000 (5.73938 iter/s, 17.4235s/100 iters), loss = 0.000561649
I0925 23:43:57.717444  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000561598 (* 1 = 0.000561598 loss)
I0925 23:43:57.717450  3547 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0925 23:44:11.661892  3547 solver.cpp:218] Iteration 81100 (7.17133 iter/s, 13.9444s/100 iters), loss = 0.00457378
I0925 23:44:11.661931  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457372 (* 1 = 0.00457372 loss)
I0925 23:44:11.661937  3547 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0925 23:44:25.608206  3547 solver.cpp:218] Iteration 81200 (7.17039 iter/s, 13.9462s/100 iters), loss = 0.00168332
I0925 23:44:25.608320  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168327 (* 1 = 0.00168327 loss)
I0925 23:44:25.608327  3547 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0925 23:44:39.554173  3547 solver.cpp:218] Iteration 81300 (7.1706 iter/s, 13.9458s/100 iters), loss = 0.000932427
I0925 23:44:39.554203  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000932374 (* 1 = 0.000932374 loss)
I0925 23:44:39.554209  3547 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0925 23:44:53.503772  3547 solver.cpp:218] Iteration 81400 (7.1687 iter/s, 13.9495s/100 iters), loss = 0.000963108
I0925 23:44:53.503801  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000963056 (* 1 = 0.000963056 loss)
I0925 23:44:53.503808  3547 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0925 23:45:06.761046  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:45:07.317307  3547 solver.cpp:330] Iteration 81500, Testing net (#0)
I0925 23:45:10.639850  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:45:10.778018  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9272
I0925 23:45:10.778044  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30927 (* 1 = 0.30927 loss)
I0925 23:45:10.916641  3547 solver.cpp:218] Iteration 81500 (5.7429 iter/s, 17.4128s/100 iters), loss = 0.00232402
I0925 23:45:10.916671  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232397 (* 1 = 0.00232397 loss)
I0925 23:45:10.916678  3547 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0925 23:45:24.857522  3547 solver.cpp:218] Iteration 81600 (7.17318 iter/s, 13.9408s/100 iters), loss = 0.00251686
I0925 23:45:24.857550  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025168 (* 1 = 0.0025168 loss)
I0925 23:45:24.857556  3547 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0925 23:45:38.804873  3547 solver.cpp:218] Iteration 81700 (7.16985 iter/s, 13.9473s/100 iters), loss = 0.000293934
I0925 23:45:38.805011  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000293885 (* 1 = 0.000293885 loss)
I0925 23:45:38.805019  3547 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0925 23:45:52.749373  3547 solver.cpp:218] Iteration 81800 (7.17137 iter/s, 13.9443s/100 iters), loss = 0.000284011
I0925 23:45:52.749413  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000283962 (* 1 = 0.000283962 loss)
I0925 23:45:52.749419  3547 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0925 23:46:06.696822  3547 solver.cpp:218] Iteration 81900 (7.16981 iter/s, 13.9474s/100 iters), loss = 0.000889031
I0925 23:46:06.696852  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000888984 (* 1 = 0.000888984 loss)
I0925 23:46:06.696858  3547 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0925 23:46:19.947592  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:46:20.505885  3547 solver.cpp:330] Iteration 82000, Testing net (#0)
I0925 23:46:23.828493  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:46:23.966866  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0925 23:46:23.966902  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307865 (* 1 = 0.307865 loss)
I0925 23:46:24.105381  3547 solver.cpp:218] Iteration 82000 (5.74433 iter/s, 17.4085s/100 iters), loss = 0.000266172
I0925 23:46:24.105418  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000266126 (* 1 = 0.000266126 loss)
I0925 23:46:24.105424  3547 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0925 23:46:38.047000  3547 solver.cpp:218] Iteration 82100 (7.17281 iter/s, 13.9415s/100 iters), loss = 0.00218551
I0925 23:46:38.047040  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218546 (* 1 = 0.00218546 loss)
I0925 23:46:38.047045  3547 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0925 23:46:51.990140  3547 solver.cpp:218] Iteration 82200 (7.17202 iter/s, 13.9431s/100 iters), loss = 0.000598758
I0925 23:46:51.990268  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00059871 (* 1 = 0.00059871 loss)
I0925 23:46:51.990275  3547 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0925 23:47:05.941076  3547 solver.cpp:218] Iteration 82300 (7.16806 iter/s, 13.9508s/100 iters), loss = 0.00221035
I0925 23:47:05.941115  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022103 (* 1 = 0.0022103 loss)
I0925 23:47:05.941121  3547 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0925 23:47:19.885056  3547 solver.cpp:218] Iteration 82400 (7.17159 iter/s, 13.9439s/100 iters), loss = 0.00207244
I0925 23:47:19.885097  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020724 (* 1 = 0.0020724 loss)
I0925 23:47:19.885104  3547 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0925 23:47:33.137332  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:47:33.696760  3547 solver.cpp:330] Iteration 82500, Testing net (#0)
I0925 23:47:37.017617  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:47:37.155953  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I0925 23:47:37.155988  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307158 (* 1 = 0.307158 loss)
I0925 23:47:37.294203  3547 solver.cpp:218] Iteration 82500 (5.74413 iter/s, 17.4091s/100 iters), loss = 0.000333484
I0925 23:47:37.294229  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000333436 (* 1 = 0.000333436 loss)
I0925 23:47:37.294236  3547 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0925 23:47:51.243608  3547 solver.cpp:218] Iteration 82600 (7.1688 iter/s, 13.9493s/100 iters), loss = 0.000606172
I0925 23:47:51.243638  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000606124 (* 1 = 0.000606124 loss)
I0925 23:47:51.243643  3547 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0925 23:48:05.194994  3547 solver.cpp:218] Iteration 82700 (7.16778 iter/s, 13.9513s/100 iters), loss = 0.000872811
I0925 23:48:05.195102  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000872762 (* 1 = 0.000872762 loss)
I0925 23:48:05.195109  3547 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0925 23:48:19.151752  3547 solver.cpp:218] Iteration 82800 (7.16506 iter/s, 13.9566s/100 iters), loss = 0.000694055
I0925 23:48:19.151783  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000694008 (* 1 = 0.000694008 loss)
I0925 23:48:19.151789  3547 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0925 23:48:33.101555  3547 solver.cpp:218] Iteration 82900 (7.16859 iter/s, 13.9497s/100 iters), loss = 0.000850361
I0925 23:48:33.101596  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000850314 (* 1 = 0.000850314 loss)
I0925 23:48:33.101603  3547 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0925 23:48:46.358209  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:48:46.915741  3547 solver.cpp:330] Iteration 83000, Testing net (#0)
I0925 23:48:50.236831  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:48:50.375656  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0925 23:48:50.375692  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306927 (* 1 = 0.306927 loss)
I0925 23:48:50.513375  3547 solver.cpp:218] Iteration 83000 (5.74325 iter/s, 17.4117s/100 iters), loss = 0.00102316
I0925 23:48:50.513403  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102311 (* 1 = 0.00102311 loss)
I0925 23:48:50.513409  3547 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0925 23:49:04.455831  3547 solver.cpp:218] Iteration 83100 (7.17237 iter/s, 13.9424s/100 iters), loss = 0.00396177
I0925 23:49:04.455860  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396172 (* 1 = 0.00396172 loss)
I0925 23:49:04.455866  3547 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0925 23:49:18.403292  3547 solver.cpp:218] Iteration 83200 (7.1698 iter/s, 13.9474s/100 iters), loss = 0.00132819
I0925 23:49:18.403408  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132814 (* 1 = 0.00132814 loss)
I0925 23:49:18.403425  3547 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0925 23:49:32.346892  3547 solver.cpp:218] Iteration 83300 (7.17182 iter/s, 13.9435s/100 iters), loss = 0.00130704
I0925 23:49:32.346932  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130699 (* 1 = 0.00130699 loss)
I0925 23:49:32.346938  3547 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0925 23:49:46.288902  3547 solver.cpp:218] Iteration 83400 (7.1726 iter/s, 13.9419s/100 iters), loss = 0.00144609
I0925 23:49:46.288942  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144604 (* 1 = 0.00144604 loss)
I0925 23:49:46.288949  3547 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0925 23:49:59.536548  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:50:00.095108  3547 solver.cpp:330] Iteration 83500, Testing net (#0)
I0925 23:50:03.417076  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:50:03.556200  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0925 23:50:03.556223  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306418 (* 1 = 0.306418 loss)
I0925 23:50:03.694886  3547 solver.cpp:218] Iteration 83500 (5.74518 iter/s, 17.4059s/100 iters), loss = 0.000233043
I0925 23:50:03.694917  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000232996 (* 1 = 0.000232996 loss)
I0925 23:50:03.694924  3547 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0925 23:50:17.644469  3547 solver.cpp:218] Iteration 83600 (7.16871 iter/s, 13.9495s/100 iters), loss = 0.00251373
I0925 23:50:17.644500  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251369 (* 1 = 0.00251369 loss)
I0925 23:50:17.644506  3547 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0925 23:50:31.602232  3547 solver.cpp:218] Iteration 83700 (7.16451 iter/s, 13.9577s/100 iters), loss = 0.000786508
I0925 23:50:31.602372  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000786461 (* 1 = 0.000786461 loss)
I0925 23:50:31.602381  3547 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0925 23:50:45.554555  3547 solver.cpp:218] Iteration 83800 (7.16735 iter/s, 13.9522s/100 iters), loss = 0.000836597
I0925 23:50:45.554585  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00083655 (* 1 = 0.00083655 loss)
I0925 23:50:45.554591  3547 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0925 23:50:59.506709  3547 solver.cpp:218] Iteration 83900 (7.16738 iter/s, 13.9521s/100 iters), loss = 0.00108321
I0925 23:50:59.506739  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108316 (* 1 = 0.00108316 loss)
I0925 23:50:59.506747  3547 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0925 23:51:12.770097  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:51:13.327949  3547 solver.cpp:330] Iteration 84000, Testing net (#0)
I0925 23:51:16.651801  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:51:16.790172  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9277
I0925 23:51:16.790207  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306136 (* 1 = 0.306136 loss)
I0925 23:51:16.929450  3547 solver.cpp:218] Iteration 84000 (5.73965 iter/s, 17.4227s/100 iters), loss = 0.000598581
I0925 23:51:16.929493  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000598534 (* 1 = 0.000598534 loss)
I0925 23:51:16.929500  3547 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0925 23:51:30.884714  3547 solver.cpp:218] Iteration 84100 (7.16579 iter/s, 13.9552s/100 iters), loss = 0.00458285
I0925 23:51:30.884755  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045828 (* 1 = 0.0045828 loss)
I0925 23:51:30.884762  3547 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0925 23:51:44.849828  3547 solver.cpp:218] Iteration 84200 (7.16074 iter/s, 13.965s/100 iters), loss = 0.0014209
I0925 23:51:44.849918  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142085 (* 1 = 0.00142085 loss)
I0925 23:51:44.849926  3547 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0925 23:51:58.804074  3547 solver.cpp:218] Iteration 84300 (7.16634 iter/s, 13.9541s/100 iters), loss = 0.00247271
I0925 23:51:58.804105  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247267 (* 1 = 0.00247267 loss)
I0925 23:51:58.804111  3547 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0925 23:52:12.763542  3547 solver.cpp:218] Iteration 84400 (7.16363 iter/s, 13.9594s/100 iters), loss = 0.000336897
I0925 23:52:12.763573  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000336849 (* 1 = 0.000336849 loss)
I0925 23:52:12.763589  3547 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0925 23:52:26.029152  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:52:26.587574  3547 solver.cpp:330] Iteration 84500, Testing net (#0)
I0925 23:52:29.910969  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:52:30.049470  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0925 23:52:30.049505  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306165 (* 1 = 0.306165 loss)
I0925 23:52:30.188712  3547 solver.cpp:218] Iteration 84500 (5.73885 iter/s, 17.4251s/100 iters), loss = 0.00124466
I0925 23:52:30.188742  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124461 (* 1 = 0.00124461 loss)
I0925 23:52:30.188750  3547 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0925 23:52:44.143784  3547 solver.cpp:218] Iteration 84600 (7.16589 iter/s, 13.955s/100 iters), loss = 0.00212554
I0925 23:52:44.143824  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212549 (* 1 = 0.00212549 loss)
I0925 23:52:44.143831  3547 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0925 23:52:58.101313  3547 solver.cpp:218] Iteration 84700 (7.16463 iter/s, 13.9575s/100 iters), loss = 0.00112741
I0925 23:52:58.101430  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112737 (* 1 = 0.00112737 loss)
I0925 23:52:58.101449  3547 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0925 23:53:12.052207  3547 solver.cpp:218] Iteration 84800 (7.16807 iter/s, 13.9508s/100 iters), loss = 0.00168229
I0925 23:53:12.052247  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168224 (* 1 = 0.00168224 loss)
I0925 23:53:12.052253  3547 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0925 23:53:26.016120  3547 solver.cpp:218] Iteration 84900 (7.16135 iter/s, 13.9638s/100 iters), loss = 0.000552904
I0925 23:53:26.016161  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000552858 (* 1 = 0.000552858 loss)
I0925 23:53:26.016167  3547 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0925 23:53:39.283565  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:53:39.842566  3547 solver.cpp:330] Iteration 85000, Testing net (#0)
I0925 23:53:43.163660  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:53:43.302067  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0925 23:53:43.302103  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306165 (* 1 = 0.306165 loss)
I0925 23:53:43.440127  3547 solver.cpp:218] Iteration 85000 (5.73924 iter/s, 17.4239s/100 iters), loss = 0.00129433
I0925 23:53:43.440158  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129428 (* 1 = 0.00129428 loss)
I0925 23:53:43.440165  3547 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0925 23:53:57.388214  3547 solver.cpp:218] Iteration 85100 (7.16948 iter/s, 13.948s/100 iters), loss = 0.00144069
I0925 23:53:57.388245  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144065 (* 1 = 0.00144065 loss)
I0925 23:53:57.388252  3547 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0925 23:54:11.333667  3547 solver.cpp:218] Iteration 85200 (7.17083 iter/s, 13.9454s/100 iters), loss = 0.000574383
I0925 23:54:11.333778  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000574337 (* 1 = 0.000574337 loss)
I0925 23:54:11.333786  3547 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0925 23:54:25.291553  3547 solver.cpp:218] Iteration 85300 (7.16448 iter/s, 13.9577s/100 iters), loss = 0.000755054
I0925 23:54:25.291582  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000755008 (* 1 = 0.000755008 loss)
I0925 23:54:25.291587  3547 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0925 23:54:39.245123  3547 solver.cpp:218] Iteration 85400 (7.16666 iter/s, 13.9535s/100 iters), loss = 0.00181593
I0925 23:54:39.245153  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181589 (* 1 = 0.00181589 loss)
I0925 23:54:39.245169  3547 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0925 23:54:52.502205  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:54:53.061564  3547 solver.cpp:330] Iteration 85500, Testing net (#0)
I0925 23:54:56.382477  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:54:56.521191  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0925 23:54:56.521217  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306435 (* 1 = 0.306435 loss)
I0925 23:54:56.659466  3547 solver.cpp:218] Iteration 85500 (5.74242 iter/s, 17.4143s/100 iters), loss = 0.000403111
I0925 23:54:56.659494  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000403066 (* 1 = 0.000403066 loss)
I0925 23:54:56.659502  3547 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0925 23:55:10.595850  3547 solver.cpp:218] Iteration 85600 (7.17549 iter/s, 13.9363s/100 iters), loss = 0.00132335
I0925 23:55:10.595880  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132331 (* 1 = 0.00132331 loss)
I0925 23:55:10.595885  3547 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0925 23:55:24.535022  3547 solver.cpp:218] Iteration 85700 (7.17406 iter/s, 13.9391s/100 iters), loss = 0.00130493
I0925 23:55:24.535117  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130488 (* 1 = 0.00130488 loss)
I0925 23:55:24.535125  3547 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0925 23:55:38.468207  3547 solver.cpp:218] Iteration 85800 (7.17718 iter/s, 13.9331s/100 iters), loss = 0.000874276
I0925 23:55:38.468237  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000874231 (* 1 = 0.000874231 loss)
I0925 23:55:38.468243  3547 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0925 23:55:52.403681  3547 solver.cpp:218] Iteration 85900 (7.17596 iter/s, 13.9354s/100 iters), loss = 0.00065518
I0925 23:55:52.403722  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000655134 (* 1 = 0.000655134 loss)
I0925 23:55:52.403728  3547 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0925 23:56:05.650339  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:56:06.208071  3547 solver.cpp:330] Iteration 86000, Testing net (#0)
I0925 23:56:09.529512  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:56:09.667904  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0925 23:56:09.667929  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305785 (* 1 = 0.305785 loss)
I0925 23:56:09.805785  3547 solver.cpp:218] Iteration 86000 (5.74646 iter/s, 17.402s/100 iters), loss = 0.000672758
I0925 23:56:09.805814  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000672712 (* 1 = 0.000672712 loss)
I0925 23:56:09.805821  3547 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0925 23:56:23.762523  3547 solver.cpp:218] Iteration 86100 (7.16503 iter/s, 13.9567s/100 iters), loss = 0.00138005
I0925 23:56:23.762554  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138 (* 1 = 0.00138 loss)
I0925 23:56:23.762569  3547 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0925 23:56:37.720731  3547 solver.cpp:218] Iteration 86200 (7.16428 iter/s, 13.9581s/100 iters), loss = 0.00248379
I0925 23:56:37.720818  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248374 (* 1 = 0.00248374 loss)
I0925 23:56:37.720834  3547 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0925 23:56:51.678170  3547 solver.cpp:218] Iteration 86300 (7.1647 iter/s, 13.9573s/100 iters), loss = 0.0018249
I0925 23:56:51.678212  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182485 (* 1 = 0.00182485 loss)
I0925 23:56:51.678218  3547 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0925 23:57:05.638151  3547 solver.cpp:218] Iteration 86400 (7.16337 iter/s, 13.9599s/100 iters), loss = 0.000543982
I0925 23:57:05.638180  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000543936 (* 1 = 0.000543936 loss)
I0925 23:57:05.638186  3547 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0925 23:57:18.895073  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:57:19.455404  3547 solver.cpp:330] Iteration 86500, Testing net (#0)
I0925 23:57:22.775172  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:57:22.914039  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9277
I0925 23:57:22.914074  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306152 (* 1 = 0.306152 loss)
I0925 23:57:23.052335  3547 solver.cpp:218] Iteration 86500 (5.74247 iter/s, 17.4141s/100 iters), loss = 0.000783653
I0925 23:57:23.052364  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000783606 (* 1 = 0.000783606 loss)
I0925 23:57:23.052371  3547 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0925 23:57:36.995435  3547 solver.cpp:218] Iteration 86600 (7.17204 iter/s, 13.943s/100 iters), loss = 0.000846177
I0925 23:57:36.995477  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000846131 (* 1 = 0.000846131 loss)
I0925 23:57:36.995483  3547 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0925 23:57:50.942759  3547 solver.cpp:218] Iteration 86700 (7.16987 iter/s, 13.9472s/100 iters), loss = 0.00127553
I0925 23:57:50.942903  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127548 (* 1 = 0.00127548 loss)
I0925 23:57:50.942911  3547 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0925 23:58:04.888801  3547 solver.cpp:218] Iteration 86800 (7.17058 iter/s, 13.9459s/100 iters), loss = 0.000305871
I0925 23:58:04.888833  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000305826 (* 1 = 0.000305826 loss)
I0925 23:58:04.888839  3547 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0925 23:58:18.838568  3547 solver.cpp:218] Iteration 86900 (7.16861 iter/s, 13.9497s/100 iters), loss = 0.00123651
I0925 23:58:18.838608  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123646 (* 1 = 0.00123646 loss)
I0925 23:58:18.838614  3547 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0925 23:58:32.092147  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:58:32.649222  3547 solver.cpp:330] Iteration 87000, Testing net (#0)
I0925 23:58:35.971323  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:58:36.109066  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9275
I0925 23:58:36.109100  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305492 (* 1 = 0.305492 loss)
I0925 23:58:36.247977  3547 solver.cpp:218] Iteration 87000 (5.74405 iter/s, 17.4093s/100 iters), loss = 0.000380901
I0925 23:58:36.248006  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000380857 (* 1 = 0.000380857 loss)
I0925 23:58:36.248013  3547 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0925 23:58:50.197911  3547 solver.cpp:218] Iteration 87100 (7.16853 iter/s, 13.9499s/100 iters), loss = 0.00194639
I0925 23:58:50.197942  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194635 (* 1 = 0.00194635 loss)
I0925 23:58:50.197947  3547 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0925 23:59:04.155175  3547 solver.cpp:218] Iteration 87200 (7.16476 iter/s, 13.9572s/100 iters), loss = 0.00080377
I0925 23:59:04.155293  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000803727 (* 1 = 0.000803727 loss)
I0925 23:59:04.155311  3547 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0925 23:59:18.110399  3547 solver.cpp:218] Iteration 87300 (7.16585 iter/s, 13.9551s/100 iters), loss = 0.000565933
I0925 23:59:18.110430  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000565889 (* 1 = 0.000565889 loss)
I0925 23:59:18.110435  3547 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0925 23:59:32.070199  3547 solver.cpp:218] Iteration 87400 (7.16346 iter/s, 13.9597s/100 iters), loss = 0.000499764
I0925 23:59:32.070230  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000499721 (* 1 = 0.000499721 loss)
I0925 23:59:32.070247  3547 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0925 23:59:45.334265  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:59:45.892602  3547 solver.cpp:330] Iteration 87500, Testing net (#0)
I0925 23:59:49.215441  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:59:49.354275  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0925 23:59:49.354310  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305422 (* 1 = 0.305422 loss)
I0925 23:59:49.492858  3547 solver.cpp:218] Iteration 87500 (5.73968 iter/s, 17.4226s/100 iters), loss = 0.000643323
I0925 23:59:49.492890  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000643279 (* 1 = 0.000643279 loss)
I0925 23:59:49.492897  3547 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0926 00:00:03.440534  3547 solver.cpp:218] Iteration 87600 (7.16969 iter/s, 13.9476s/100 iters), loss = 0.000991631
I0926 00:00:03.440567  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000991587 (* 1 = 0.000991587 loss)
I0926 00:00:03.440572  3547 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0926 00:00:17.396252  3547 solver.cpp:218] Iteration 87700 (7.16556 iter/s, 13.9557s/100 iters), loss = 0.000680293
I0926 00:00:17.396332  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000680249 (* 1 = 0.000680249 loss)
I0926 00:00:17.396340  3547 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0926 00:00:31.348881  3547 solver.cpp:218] Iteration 87800 (7.16717 iter/s, 13.9525s/100 iters), loss = 0.00077674
I0926 00:00:31.348920  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000776697 (* 1 = 0.000776697 loss)
I0926 00:00:31.348927  3547 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0926 00:00:45.296317  3547 solver.cpp:218] Iteration 87900 (7.16981 iter/s, 13.9474s/100 iters), loss = 0.000929793
I0926 00:00:45.296347  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000929751 (* 1 = 0.000929751 loss)
I0926 00:00:45.296353  3547 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0926 00:00:58.542409  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:00:59.101192  3547 solver.cpp:330] Iteration 88000, Testing net (#0)
I0926 00:01:02.425299  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:01:02.564000  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0926 00:01:02.564036  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306315 (* 1 = 0.306315 loss)
I0926 00:01:02.702446  3547 solver.cpp:218] Iteration 88000 (5.74513 iter/s, 17.4061s/100 iters), loss = 0.000185587
I0926 00:01:02.702476  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000185546 (* 1 = 0.000185546 loss)
I0926 00:01:02.702482  3547 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0926 00:01:16.652822  3547 solver.cpp:218] Iteration 88100 (7.1683 iter/s, 13.9503s/100 iters), loss = 0.00169814
I0926 00:01:16.652863  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016981 (* 1 = 0.0016981 loss)
I0926 00:01:16.652868  3547 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0926 00:01:30.606832  3547 solver.cpp:218] Iteration 88200 (7.16644 iter/s, 13.9539s/100 iters), loss = 0.000260561
I0926 00:01:30.606946  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000260522 (* 1 = 0.000260522 loss)
I0926 00:01:30.606963  3547 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0926 00:01:44.554695  3547 solver.cpp:218] Iteration 88300 (7.16963 iter/s, 13.9477s/100 iters), loss = 0.00182996
I0926 00:01:44.554728  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182992 (* 1 = 0.00182992 loss)
I0926 00:01:44.554735  3547 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0926 00:01:58.500720  3547 solver.cpp:218] Iteration 88400 (7.17054 iter/s, 13.946s/100 iters), loss = 0.000497247
I0926 00:01:58.500749  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000497209 (* 1 = 0.000497209 loss)
I0926 00:01:58.500756  3547 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0926 00:02:11.758669  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:02:12.315068  3547 solver.cpp:330] Iteration 88500, Testing net (#0)
I0926 00:02:15.637732  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:02:15.776026  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9275
I0926 00:02:15.776062  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306535 (* 1 = 0.306535 loss)
I0926 00:02:15.914759  3547 solver.cpp:218] Iteration 88500 (5.74252 iter/s, 17.414s/100 iters), loss = 0.000949147
I0926 00:02:15.914788  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00094911 (* 1 = 0.00094911 loss)
I0926 00:02:15.914794  3547 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0926 00:02:29.865630  3547 solver.cpp:218] Iteration 88600 (7.16805 iter/s, 13.9508s/100 iters), loss = 0.00322813
I0926 00:02:29.865660  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322809 (* 1 = 0.00322809 loss)
I0926 00:02:29.865665  3547 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0926 00:02:43.815798  3547 solver.cpp:218] Iteration 88700 (7.16841 iter/s, 13.9501s/100 iters), loss = 0.00124412
I0926 00:02:43.815924  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124408 (* 1 = 0.00124408 loss)
I0926 00:02:43.815932  3547 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0926 00:02:57.760293  3547 solver.cpp:218] Iteration 88800 (7.17137 iter/s, 13.9443s/100 iters), loss = 0.00208523
I0926 00:02:57.760321  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208519 (* 1 = 0.00208519 loss)
I0926 00:02:57.760326  3547 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0926 00:03:11.703649  3547 solver.cpp:218] Iteration 88900 (7.17191 iter/s, 13.9433s/100 iters), loss = 0.000439848
I0926 00:03:11.703678  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000439813 (* 1 = 0.000439813 loss)
I0926 00:03:11.703685  3547 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0926 00:03:24.961115  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:03:25.518410  3547 solver.cpp:330] Iteration 89000, Testing net (#0)
I0926 00:03:28.837342  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:03:28.976065  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0926 00:03:28.976109  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307021 (* 1 = 0.307021 loss)
I0926 00:03:29.114826  3547 solver.cpp:218] Iteration 89000 (5.74346 iter/s, 17.4111s/100 iters), loss = 0.00082115
I0926 00:03:29.114858  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000821115 (* 1 = 0.000821115 loss)
I0926 00:03:29.114864  3547 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0926 00:03:43.074002  3547 solver.cpp:218] Iteration 89100 (7.16378 iter/s, 13.9591s/100 iters), loss = 0.0013508
I0926 00:03:43.074040  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135077 (* 1 = 0.00135077 loss)
I0926 00:03:43.074046  3547 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0926 00:03:57.041627  3547 solver.cpp:218] Iteration 89200 (7.15945 iter/s, 13.9676s/100 iters), loss = 0.00103462
I0926 00:03:57.041749  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103459 (* 1 = 0.00103459 loss)
I0926 00:03:57.041755  3547 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0926 00:04:11.010625  3547 solver.cpp:218] Iteration 89300 (7.15879 iter/s, 13.9688s/100 iters), loss = 0.000722685
I0926 00:04:11.010653  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000722649 (* 1 = 0.000722649 loss)
I0926 00:04:11.010659  3547 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0926 00:04:24.982903  3547 solver.cpp:218] Iteration 89400 (7.15706 iter/s, 13.9722s/100 iters), loss = 0.000880215
I0926 00:04:24.982934  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00088018 (* 1 = 0.00088018 loss)
I0926 00:04:24.982950  3547 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0926 00:04:38.252655  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:04:38.809736  3547 solver.cpp:330] Iteration 89500, Testing net (#0)
I0926 00:04:42.133029  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:04:42.271493  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I0926 00:04:42.271529  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307139 (* 1 = 0.307139 loss)
I0926 00:04:42.409716  3547 solver.cpp:218] Iteration 89500 (5.73831 iter/s, 17.4267s/100 iters), loss = 0.00144369
I0926 00:04:42.409744  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144366 (* 1 = 0.00144366 loss)
I0926 00:04:42.409750  3547 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0926 00:04:56.357960  3547 solver.cpp:218] Iteration 89600 (7.16939 iter/s, 13.9482s/100 iters), loss = 0.00124219
I0926 00:04:56.358000  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124215 (* 1 = 0.00124215 loss)
I0926 00:04:56.358006  3547 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0926 00:05:10.297806  3547 solver.cpp:218] Iteration 89700 (7.17372 iter/s, 13.9398s/100 iters), loss = 0.000578689
I0926 00:05:10.297894  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000578655 (* 1 = 0.000578655 loss)
I0926 00:05:10.297911  3547 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0926 00:05:24.242924  3547 solver.cpp:218] Iteration 89800 (7.17103 iter/s, 13.945s/100 iters), loss = 0.000970291
I0926 00:05:24.242964  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000970256 (* 1 = 0.000970256 loss)
I0926 00:05:24.242970  3547 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0926 00:05:38.187556  3547 solver.cpp:218] Iteration 89900 (7.17126 iter/s, 13.9446s/100 iters), loss = 0.000173721
I0926 00:05:38.187594  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000173687 (* 1 = 0.000173687 loss)
I0926 00:05:38.187600  3547 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0926 00:05:51.434655  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:05:51.992110  3547 solver.cpp:330] Iteration 90000, Testing net (#0)
I0926 00:05:55.314103  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:05:55.452941  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9275
I0926 00:05:55.452976  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305997 (* 1 = 0.305997 loss)
I0926 00:05:55.592031  3547 solver.cpp:218] Iteration 90000 (5.74568 iter/s, 17.4044s/100 iters), loss = 0.000464652
I0926 00:05:55.592061  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000464619 (* 1 = 0.000464619 loss)
I0926 00:05:55.592067  3547 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0926 00:06:09.549048  3547 solver.cpp:218] Iteration 90100 (7.16489 iter/s, 13.957s/100 iters), loss = 0.000744077
I0926 00:06:09.549089  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000744043 (* 1 = 0.000744043 loss)
I0926 00:06:09.549094  3547 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0926 00:06:23.501317  3547 solver.cpp:218] Iteration 90200 (7.16733 iter/s, 13.9522s/100 iters), loss = 0.000866445
I0926 00:06:23.501466  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000866412 (* 1 = 0.000866412 loss)
I0926 00:06:23.501476  3547 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0926 00:06:37.445669  3547 solver.cpp:218] Iteration 90300 (7.17146 iter/s, 13.9442s/100 iters), loss = 0.00203758
I0926 00:06:37.445710  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203755 (* 1 = 0.00203755 loss)
I0926 00:06:37.445716  3547 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0926 00:06:51.401016  3547 solver.cpp:218] Iteration 90400 (7.16575 iter/s, 13.9553s/100 iters), loss = 0.000720257
I0926 00:06:51.401057  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000720223 (* 1 = 0.000720223 loss)
I0926 00:06:51.401062  3547 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0926 00:07:04.663005  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:07:05.223855  3547 solver.cpp:330] Iteration 90500, Testing net (#0)
I0926 00:07:08.544643  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:07:08.683748  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0926 00:07:08.683784  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304887 (* 1 = 0.304887 loss)
I0926 00:07:08.821211  3547 solver.cpp:218] Iteration 90500 (5.74049 iter/s, 17.4201s/100 iters), loss = 0.000284112
I0926 00:07:08.821241  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000284079 (* 1 = 0.000284079 loss)
I0926 00:07:08.821247  3547 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0926 00:07:22.747812  3547 solver.cpp:218] Iteration 90600 (7.18054 iter/s, 13.9265s/100 iters), loss = 0.00167815
I0926 00:07:22.747841  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167812 (* 1 = 0.00167812 loss)
I0926 00:07:22.747848  3547 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0926 00:07:36.694234  3547 solver.cpp:218] Iteration 90700 (7.17033 iter/s, 13.9464s/100 iters), loss = 0.00121256
I0926 00:07:36.694378  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121253 (* 1 = 0.00121253 loss)
I0926 00:07:36.694394  3547 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0926 00:07:50.638941  3547 solver.cpp:218] Iteration 90800 (7.17127 iter/s, 13.9445s/100 iters), loss = 0.00113113
I0926 00:07:50.638970  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011311 (* 1 = 0.0011311 loss)
I0926 00:07:50.638977  3547 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0926 00:08:04.580082  3547 solver.cpp:218] Iteration 90900 (7.17305 iter/s, 13.9411s/100 iters), loss = 0.00117011
I0926 00:08:04.580122  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117008 (* 1 = 0.00117008 loss)
I0926 00:08:04.580128  3547 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0926 00:08:17.834861  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:08:18.393407  3547 solver.cpp:330] Iteration 91000, Testing net (#0)
I0926 00:08:21.714368  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:08:21.853140  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0926 00:08:21.853176  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304433 (* 1 = 0.304433 loss)
I0926 00:08:21.991366  3547 solver.cpp:218] Iteration 91000 (5.74343 iter/s, 17.4112s/100 iters), loss = 0.000403761
I0926 00:08:21.991397  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00040373 (* 1 = 0.00040373 loss)
I0926 00:08:21.991405  3547 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0926 00:08:35.949832  3547 solver.cpp:218] Iteration 91100 (7.16414 iter/s, 13.9584s/100 iters), loss = 0.00161857
I0926 00:08:35.949863  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161853 (* 1 = 0.00161853 loss)
I0926 00:08:35.949869  3547 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0926 00:08:49.903589  3547 solver.cpp:218] Iteration 91200 (7.16656 iter/s, 13.9537s/100 iters), loss = 0.000760904
I0926 00:08:49.903736  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000760868 (* 1 = 0.000760868 loss)
I0926 00:08:49.903745  3547 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0926 00:09:03.865835  3547 solver.cpp:218] Iteration 91300 (7.16226 iter/s, 13.9621s/100 iters), loss = 0.00114814
I0926 00:09:03.865875  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011481 (* 1 = 0.0011481 loss)
I0926 00:09:03.865881  3547 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0926 00:09:17.826362  3547 solver.cpp:218] Iteration 91400 (7.16309 iter/s, 13.9605s/100 iters), loss = 0.000369905
I0926 00:09:17.826402  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00036987 (* 1 = 0.00036987 loss)
I0926 00:09:17.826408  3547 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0926 00:09:31.098630  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:09:31.657557  3547 solver.cpp:330] Iteration 91500, Testing net (#0)
I0926 00:09:34.980000  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:09:35.118743  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0926 00:09:35.118778  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304829 (* 1 = 0.304829 loss)
I0926 00:09:35.259433  3547 solver.cpp:218] Iteration 91500 (5.73625 iter/s, 17.433s/100 iters), loss = 0.000690079
I0926 00:09:35.259464  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000690043 (* 1 = 0.000690043 loss)
I0926 00:09:35.259471  3547 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0926 00:09:49.217985  3547 solver.cpp:218] Iteration 91600 (7.1641 iter/s, 13.9585s/100 iters), loss = 0.000922765
I0926 00:09:49.218016  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000922728 (* 1 = 0.000922728 loss)
I0926 00:09:49.218022  3547 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0926 00:10:03.180976  3547 solver.cpp:218] Iteration 91700 (7.16182 iter/s, 13.9629s/100 iters), loss = 0.000614955
I0926 00:10:03.181085  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000614917 (* 1 = 0.000614917 loss)
I0926 00:10:03.181093  3547 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0926 00:10:17.139474  3547 solver.cpp:218] Iteration 91800 (7.16417 iter/s, 13.9584s/100 iters), loss = 0.000630301
I0926 00:10:17.139508  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000630263 (* 1 = 0.000630263 loss)
I0926 00:10:17.139516  3547 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0926 00:10:31.093889  3547 solver.cpp:218] Iteration 91900 (7.16622 iter/s, 13.9544s/100 iters), loss = 0.00156824
I0926 00:10:31.093924  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015682 (* 1 = 0.0015682 loss)
I0926 00:10:31.093932  3547 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0926 00:10:44.360189  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:10:44.919697  3547 solver.cpp:330] Iteration 92000, Testing net (#0)
I0926 00:10:48.243397  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:10:48.382297  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0926 00:10:48.382324  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304631 (* 1 = 0.304631 loss)
I0926 00:10:48.520582  3547 solver.cpp:218] Iteration 92000 (5.73835 iter/s, 17.4266s/100 iters), loss = 0.000374012
I0926 00:10:48.520617  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000373975 (* 1 = 0.000373975 loss)
I0926 00:10:48.520627  3547 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0926 00:11:02.472944  3547 solver.cpp:218] Iteration 92100 (7.16728 iter/s, 13.9523s/100 iters), loss = 0.000863324
I0926 00:11:02.472976  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000863287 (* 1 = 0.000863287 loss)
I0926 00:11:02.472985  3547 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0926 00:11:16.420037  3547 solver.cpp:218] Iteration 92200 (7.16999 iter/s, 13.947s/100 iters), loss = 0.00080469
I0926 00:11:16.420153  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000804653 (* 1 = 0.000804653 loss)
I0926 00:11:16.420166  3547 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0926 00:11:30.371009  3547 solver.cpp:218] Iteration 92300 (7.16803 iter/s, 13.9508s/100 iters), loss = 0.00207759
I0926 00:11:30.371044  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207755 (* 1 = 0.00207755 loss)
I0926 00:11:30.371054  3547 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0926 00:11:44.316347  3547 solver.cpp:218] Iteration 92400 (7.17089 iter/s, 13.9453s/100 iters), loss = 0.000536355
I0926 00:11:44.316381  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000536319 (* 1 = 0.000536319 loss)
I0926 00:11:44.316390  3547 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0926 00:11:57.575140  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:11:58.133294  3547 solver.cpp:330] Iteration 92500, Testing net (#0)
I0926 00:12:01.456786  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:12:01.595295  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I0926 00:12:01.595322  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305391 (* 1 = 0.305391 loss)
I0926 00:12:01.733904  3547 solver.cpp:218] Iteration 92500 (5.74136 iter/s, 17.4175s/100 iters), loss = 0.000586665
I0926 00:12:01.733934  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000586629 (* 1 = 0.000586629 loss)
I0926 00:12:01.733943  3547 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0926 00:12:15.693164  3547 solver.cpp:218] Iteration 92600 (7.16374 iter/s, 13.9592s/100 iters), loss = 0.00172268
I0926 00:12:15.693197  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172264 (* 1 = 0.00172264 loss)
I0926 00:12:15.693207  3547 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0926 00:12:29.649845  3547 solver.cpp:218] Iteration 92700 (7.16506 iter/s, 13.9566s/100 iters), loss = 0.00067563
I0926 00:12:29.649966  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000675595 (* 1 = 0.000675595 loss)
I0926 00:12:29.649988  3547 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0926 00:12:43.610591  3547 solver.cpp:218] Iteration 92800 (7.16301 iter/s, 13.9606s/100 iters), loss = 0.000802416
I0926 00:12:43.610622  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00080238 (* 1 = 0.00080238 loss)
I0926 00:12:43.610631  3547 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0926 00:12:57.567679  3547 solver.cpp:218] Iteration 92900 (7.16485 iter/s, 13.957s/100 iters), loss = 0.000613074
I0926 00:12:57.567713  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000613039 (* 1 = 0.000613039 loss)
I0926 00:12:57.567721  3547 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0926 00:13:10.839397  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:13:11.396715  3547 solver.cpp:330] Iteration 93000, Testing net (#0)
I0926 00:13:14.718636  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:13:14.857101  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0926 00:13:14.857127  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30434 (* 1 = 0.30434 loss)
I0926 00:13:14.995411  3547 solver.cpp:218] Iteration 93000 (5.73801 iter/s, 17.4277s/100 iters), loss = 0.000427539
I0926 00:13:14.995443  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000427507 (* 1 = 0.000427507 loss)
I0926 00:13:14.995451  3547 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0926 00:13:28.945782  3547 solver.cpp:218] Iteration 93100 (7.1683 iter/s, 13.9503s/100 iters), loss = 0.00116872
I0926 00:13:28.945816  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116869 (* 1 = 0.00116869 loss)
I0926 00:13:28.945823  3547 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0926 00:13:42.904958  3547 solver.cpp:218] Iteration 93200 (7.16378 iter/s, 13.9591s/100 iters), loss = 0.00042931
I0926 00:13:42.905082  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000429277 (* 1 = 0.000429277 loss)
I0926 00:13:42.905094  3547 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0926 00:13:56.868057  3547 solver.cpp:218] Iteration 93300 (7.16181 iter/s, 13.9629s/100 iters), loss = 0.00063561
I0926 00:13:56.868091  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000635577 (* 1 = 0.000635577 loss)
I0926 00:13:56.868100  3547 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0926 00:14:10.824935  3547 solver.cpp:218] Iteration 93400 (7.16496 iter/s, 13.9568s/100 iters), loss = 0.000645054
I0926 00:14:10.824968  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00064502 (* 1 = 0.00064502 loss)
I0926 00:14:10.824977  3547 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0926 00:14:24.085356  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:14:24.642944  3547 solver.cpp:330] Iteration 93500, Testing net (#0)
I0926 00:14:27.967288  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:14:28.106287  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I0926 00:14:28.106313  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304464 (* 1 = 0.304464 loss)
I0926 00:14:28.244873  3547 solver.cpp:218] Iteration 93500 (5.74057 iter/s, 17.4199s/100 iters), loss = 0.000441061
I0926 00:14:28.244904  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000441027 (* 1 = 0.000441027 loss)
I0926 00:14:28.244915  3547 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0926 00:14:42.184414  3547 solver.cpp:218] Iteration 93600 (7.17387 iter/s, 13.9395s/100 iters), loss = 0.00105409
I0926 00:14:42.184448  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105406 (* 1 = 0.00105406 loss)
I0926 00:14:42.184466  3547 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0926 00:14:56.134228  3547 solver.cpp:218] Iteration 93700 (7.16859 iter/s, 13.9497s/100 iters), loss = 0.0015453
I0926 00:14:56.134330  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154527 (* 1 = 0.00154527 loss)
I0926 00:14:56.134354  3547 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0926 00:15:10.078140  3547 solver.cpp:218] Iteration 93800 (7.17165 iter/s, 13.9438s/100 iters), loss = 0.000385419
I0926 00:15:10.078171  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000385385 (* 1 = 0.000385385 loss)
I0926 00:15:10.078181  3547 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0926 00:15:24.015090  3547 solver.cpp:218] Iteration 93900 (7.1752 iter/s, 13.9369s/100 iters), loss = 0.00103726
I0926 00:15:24.015123  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103723 (* 1 = 0.00103723 loss)
I0926 00:15:24.015141  3547 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0926 00:15:37.268631  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:15:37.826303  3547 solver.cpp:330] Iteration 94000, Testing net (#0)
I0926 00:15:41.149284  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:15:41.287988  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9283
I0926 00:15:41.288015  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304156 (* 1 = 0.304156 loss)
I0926 00:15:41.426452  3547 solver.cpp:218] Iteration 94000 (5.7434 iter/s, 17.4113s/100 iters), loss = 0.000257204
I0926 00:15:41.426486  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00025717 (* 1 = 0.00025717 loss)
I0926 00:15:41.426494  3547 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0926 00:15:55.370599  3547 solver.cpp:218] Iteration 94100 (7.1715 iter/s, 13.9441s/100 iters), loss = 0.00185395
I0926 00:15:55.370635  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185392 (* 1 = 0.00185392 loss)
I0926 00:15:55.370653  3547 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0926 00:16:09.323861  3547 solver.cpp:218] Iteration 94200 (7.16682 iter/s, 13.9532s/100 iters), loss = 0.000342497
I0926 00:16:09.323957  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000342463 (* 1 = 0.000342463 loss)
I0926 00:16:09.323971  3547 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0926 00:16:23.270819  3547 solver.cpp:218] Iteration 94300 (7.17008 iter/s, 13.9468s/100 iters), loss = 0.0011346
I0926 00:16:23.270849  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113457 (* 1 = 0.00113457 loss)
I0926 00:16:23.270864  3547 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0926 00:16:37.214263  3547 solver.cpp:218] Iteration 94400 (7.17186 iter/s, 13.9434s/100 iters), loss = 0.000357605
I0926 00:16:37.214293  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000357571 (* 1 = 0.000357571 loss)
I0926 00:16:37.214299  3547 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0926 00:16:50.459389  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:16:51.017493  3547 solver.cpp:330] Iteration 94500, Testing net (#0)
I0926 00:16:54.339601  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:16:54.477872  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0926 00:16:54.477908  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304869 (* 1 = 0.304869 loss)
I0926 00:16:54.616624  3547 solver.cpp:218] Iteration 94500 (5.74637 iter/s, 17.4023s/100 iters), loss = 0.000930376
I0926 00:16:54.616653  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000930341 (* 1 = 0.000930341 loss)
I0926 00:16:54.616660  3547 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0926 00:17:08.584014  3547 solver.cpp:218] Iteration 94600 (7.15956 iter/s, 13.9673s/100 iters), loss = 0.00250429
I0926 00:17:08.584054  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250426 (* 1 = 0.00250426 loss)
I0926 00:17:08.584060  3547 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0926 00:17:22.552315  3547 solver.cpp:218] Iteration 94700 (7.1591 iter/s, 13.9682s/100 iters), loss = 0.000795263
I0926 00:17:22.552450  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00079523 (* 1 = 0.00079523 loss)
I0926 00:17:22.552458  3547 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0926 00:17:36.525148  3547 solver.cpp:218] Iteration 94800 (7.15683 iter/s, 13.9727s/100 iters), loss = 0.000211156
I0926 00:17:36.525178  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000211123 (* 1 = 0.000211123 loss)
I0926 00:17:36.525183  3547 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0926 00:17:50.495328  3547 solver.cpp:218] Iteration 94900 (7.15813 iter/s, 13.9701s/100 iters), loss = 0.00075782
I0926 00:17:50.495358  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000757787 (* 1 = 0.000757787 loss)
I0926 00:17:50.495364  3547 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0926 00:18:03.779784  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:18:04.338393  3547 solver.cpp:330] Iteration 95000, Testing net (#0)
I0926 00:18:07.662561  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:18:07.800801  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0926 00:18:07.800824  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305026 (* 1 = 0.305026 loss)
I0926 00:18:07.939028  3547 solver.cpp:218] Iteration 95000 (5.73275 iter/s, 17.4436s/100 iters), loss = 0.000317583
I0926 00:18:07.939057  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00031755 (* 1 = 0.00031755 loss)
I0926 00:18:07.939064  3547 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0926 00:18:21.904996  3547 solver.cpp:218] Iteration 95100 (7.1603 iter/s, 13.9659s/100 iters), loss = 0.000649036
I0926 00:18:21.905038  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000649003 (* 1 = 0.000649003 loss)
I0926 00:18:21.905045  3547 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0926 00:18:35.857883  3547 solver.cpp:218] Iteration 95200 (7.16701 iter/s, 13.9528s/100 iters), loss = 0.000655875
I0926 00:18:35.858022  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000655841 (* 1 = 0.000655841 loss)
I0926 00:18:35.858041  3547 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0926 00:18:49.823499  3547 solver.cpp:218] Iteration 95300 (7.16053 iter/s, 13.9654s/100 iters), loss = 0.00056093
I0926 00:18:49.823531  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000560897 (* 1 = 0.000560897 loss)
I0926 00:18:49.823547  3547 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0926 00:19:03.786653  3547 solver.cpp:218] Iteration 95400 (7.16174 iter/s, 13.9631s/100 iters), loss = 0.000500235
I0926 00:19:03.786684  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000500202 (* 1 = 0.000500202 loss)
I0926 00:19:03.786689  3547 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0926 00:19:17.051887  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:19:17.609953  3547 solver.cpp:330] Iteration 95500, Testing net (#0)
I0926 00:19:20.934070  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:19:21.074409  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9267
I0926 00:19:21.074434  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305109 (* 1 = 0.305109 loss)
I0926 00:19:21.211885  3547 solver.cpp:218] Iteration 95500 (5.73883 iter/s, 17.4252s/100 iters), loss = 0.000515752
I0926 00:19:21.211913  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000515719 (* 1 = 0.000515719 loss)
I0926 00:19:21.211920  3547 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0926 00:19:35.166330  3547 solver.cpp:218] Iteration 95600 (7.16621 iter/s, 13.9544s/100 iters), loss = 0.00100081
I0926 00:19:35.166360  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100078 (* 1 = 0.00100078 loss)
I0926 00:19:35.166366  3547 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0926 00:19:49.129168  3547 solver.cpp:218] Iteration 95700 (7.1619 iter/s, 13.9628s/100 iters), loss = 0.00181645
I0926 00:19:49.129289  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181642 (* 1 = 0.00181642 loss)
I0926 00:19:49.129297  3547 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0926 00:20:03.087960  3547 solver.cpp:218] Iteration 95800 (7.16402 iter/s, 13.9586s/100 iters), loss = 0.00119991
I0926 00:20:03.088001  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119987 (* 1 = 0.00119987 loss)
I0926 00:20:03.088007  3547 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0926 00:20:17.049839  3547 solver.cpp:218] Iteration 95900 (7.1624 iter/s, 13.9618s/100 iters), loss = 0.00045619
I0926 00:20:17.049868  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000456154 (* 1 = 0.000456154 loss)
I0926 00:20:17.049875  3547 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0926 00:20:30.310351  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:20:30.869254  3547 solver.cpp:330] Iteration 96000, Testing net (#0)
I0926 00:20:34.198119  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:20:34.336899  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0926 00:20:34.336935  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305646 (* 1 = 0.305646 loss)
I0926 00:20:34.474995  3547 solver.cpp:218] Iteration 96000 (5.73885 iter/s, 17.4251s/100 iters), loss = 0.000887217
I0926 00:20:34.475026  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000887181 (* 1 = 0.000887181 loss)
I0926 00:20:34.475033  3547 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0926 00:20:48.439646  3547 solver.cpp:218] Iteration 96100 (7.16097 iter/s, 13.9646s/100 iters), loss = 0.00162324
I0926 00:20:48.439677  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016232 (* 1 = 0.0016232 loss)
I0926 00:20:48.439682  3547 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0926 00:21:02.404458  3547 solver.cpp:218] Iteration 96200 (7.16089 iter/s, 13.9647s/100 iters), loss = 0.000653484
I0926 00:21:02.404628  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000653448 (* 1 = 0.000653448 loss)
I0926 00:21:02.404646  3547 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0926 00:21:16.366607  3547 solver.cpp:218] Iteration 96300 (7.16232 iter/s, 13.9619s/100 iters), loss = 0.000639883
I0926 00:21:16.366648  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000639848 (* 1 = 0.000639848 loss)
I0926 00:21:16.366654  3547 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0926 00:21:30.333778  3547 solver.cpp:218] Iteration 96400 (7.15968 iter/s, 13.9671s/100 iters), loss = 0.000617602
I0926 00:21:30.333819  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000617567 (* 1 = 0.000617567 loss)
I0926 00:21:30.333825  3547 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0926 00:21:43.602344  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:21:44.160418  3547 solver.cpp:330] Iteration 96500, Testing net (#0)
I0926 00:21:47.488801  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:21:47.627377  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I0926 00:21:47.627401  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305071 (* 1 = 0.305071 loss)
I0926 00:21:47.765763  3547 solver.cpp:218] Iteration 96500 (5.73661 iter/s, 17.4319s/100 iters), loss = 0.000843176
I0926 00:21:47.765794  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000843142 (* 1 = 0.000843142 loss)
I0926 00:21:47.765799  3547 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0926 00:22:01.742312  3547 solver.cpp:218] Iteration 96600 (7.15488 iter/s, 13.9765s/100 iters), loss = 0.000972051
I0926 00:22:01.742352  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000972015 (* 1 = 0.000972015 loss)
I0926 00:22:01.742359  3547 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0926 00:22:15.706564  3547 solver.cpp:218] Iteration 96700 (7.16118 iter/s, 13.9642s/100 iters), loss = 0.000765126
I0926 00:22:15.706723  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000765089 (* 1 = 0.000765089 loss)
I0926 00:22:15.706732  3547 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0926 00:22:29.673435  3547 solver.cpp:218] Iteration 96800 (7.1599 iter/s, 13.9667s/100 iters), loss = 0.000543
I0926 00:22:29.673476  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000542963 (* 1 = 0.000542963 loss)
I0926 00:22:29.673482  3547 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0926 00:22:43.657411  3547 solver.cpp:218] Iteration 96900 (7.15108 iter/s, 13.9839s/100 iters), loss = 0.00272403
I0926 00:22:43.657443  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272399 (* 1 = 0.00272399 loss)
I0926 00:22:43.657449  3547 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0926 00:22:56.921134  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:22:57.479609  3547 solver.cpp:330] Iteration 97000, Testing net (#0)
I0926 00:23:00.804822  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:23:00.944309  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0926 00:23:00.944345  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30408 (* 1 = 0.30408 loss)
I0926 00:23:01.083369  3547 solver.cpp:218] Iteration 97000 (5.73859 iter/s, 17.4259s/100 iters), loss = 0.00045058
I0926 00:23:01.083396  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000450543 (* 1 = 0.000450543 loss)
I0926 00:23:01.083403  3547 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0926 00:23:15.049991  3547 solver.cpp:218] Iteration 97100 (7.15996 iter/s, 13.9666s/100 iters), loss = 0.000576372
I0926 00:23:15.050021  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000576336 (* 1 = 0.000576336 loss)
I0926 00:23:15.050027  3547 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0926 00:23:29.019284  3547 solver.cpp:218] Iteration 97200 (7.15859 iter/s, 13.9692s/100 iters), loss = 0.000797738
I0926 00:23:29.019443  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000797701 (* 1 = 0.000797701 loss)
I0926 00:23:29.019460  3547 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0926 00:23:42.996079  3547 solver.cpp:218] Iteration 97300 (7.15481 iter/s, 13.9766s/100 iters), loss = 0.000466632
I0926 00:23:42.996120  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000466595 (* 1 = 0.000466595 loss)
I0926 00:23:42.996126  3547 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0926 00:23:56.972546  3547 solver.cpp:218] Iteration 97400 (7.15492 iter/s, 13.9764s/100 iters), loss = 0.000389409
I0926 00:23:56.972576  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000389372 (* 1 = 0.000389372 loss)
I0926 00:23:56.972582  3547 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0926 00:24:10.252226  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:24:10.811045  3547 solver.cpp:330] Iteration 97500, Testing net (#0)
I0926 00:24:14.139647  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:24:14.278363  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0926 00:24:14.278398  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304373 (* 1 = 0.304373 loss)
I0926 00:24:14.417436  3547 solver.cpp:218] Iteration 97500 (5.73236 iter/s, 17.4448s/100 iters), loss = 0.000235988
I0926 00:24:14.417465  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00023595 (* 1 = 0.00023595 loss)
I0926 00:24:14.417471  3547 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0926 00:24:28.379634  3547 solver.cpp:218] Iteration 97600 (7.16223 iter/s, 13.9621s/100 iters), loss = 0.00204758
I0926 00:24:28.379676  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204754 (* 1 = 0.00204754 loss)
I0926 00:24:28.379683  3547 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0926 00:24:42.341950  3547 solver.cpp:218] Iteration 97700 (7.16217 iter/s, 13.9622s/100 iters), loss = 0.000998928
I0926 00:24:42.342052  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000998891 (* 1 = 0.000998891 loss)
I0926 00:24:42.342061  3547 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0926 00:24:56.307962  3547 solver.cpp:218] Iteration 97800 (7.1603 iter/s, 13.9659s/100 iters), loss = 0.000595601
I0926 00:24:56.307992  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000595563 (* 1 = 0.000595563 loss)
I0926 00:24:56.307998  3547 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0926 00:25:10.269567  3547 solver.cpp:218] Iteration 97900 (7.16253 iter/s, 13.9615s/100 iters), loss = 0.00132087
I0926 00:25:10.269595  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132083 (* 1 = 0.00132083 loss)
I0926 00:25:10.269601  3547 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0926 00:25:23.542644  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:25:24.100916  3547 solver.cpp:330] Iteration 98000, Testing net (#0)
I0926 00:25:27.428150  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:25:27.567005  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0926 00:25:27.567031  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303966 (* 1 = 0.303966 loss)
I0926 00:25:27.706008  3547 solver.cpp:218] Iteration 98000 (5.73514 iter/s, 17.4364s/100 iters), loss = 0.00125229
I0926 00:25:27.706037  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125225 (* 1 = 0.00125225 loss)
I0926 00:25:27.706044  3547 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0926 00:25:41.676481  3547 solver.cpp:218] Iteration 98100 (7.15799 iter/s, 13.9704s/100 iters), loss = 0.00163769
I0926 00:25:41.676513  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163765 (* 1 = 0.00163765 loss)
I0926 00:25:41.676520  3547 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0926 00:25:55.646991  3547 solver.cpp:218] Iteration 98200 (7.15797 iter/s, 13.9704s/100 iters), loss = 0.000680322
I0926 00:25:55.647130  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000680284 (* 1 = 0.000680284 loss)
I0926 00:25:55.647138  3547 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0926 00:26:09.624418  3547 solver.cpp:218] Iteration 98300 (7.15448 iter/s, 13.9773s/100 iters), loss = 0.0010442
I0926 00:26:09.624449  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104416 (* 1 = 0.00104416 loss)
I0926 00:26:09.624465  3547 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0926 00:26:23.597468  3547 solver.cpp:218] Iteration 98400 (7.15667 iter/s, 13.973s/100 iters), loss = 0.00111614
I0926 00:26:23.597498  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111611 (* 1 = 0.00111611 loss)
I0926 00:26:23.597504  3547 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0926 00:26:36.880242  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:26:37.438434  3547 solver.cpp:330] Iteration 98500, Testing net (#0)
I0926 00:26:40.766495  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:26:40.904747  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I0926 00:26:40.904783  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303905 (* 1 = 0.303905 loss)
I0926 00:26:41.043329  3547 solver.cpp:218] Iteration 98500 (5.73204 iter/s, 17.4458s/100 iters), loss = 0.00124598
I0926 00:26:41.043359  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124595 (* 1 = 0.00124595 loss)
I0926 00:26:41.043365  3547 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0926 00:26:55.003499  3547 solver.cpp:218] Iteration 98600 (7.16327 iter/s, 13.9601s/100 iters), loss = 0.00073802
I0926 00:26:55.003540  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000737984 (* 1 = 0.000737984 loss)
I0926 00:26:55.003545  3547 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0926 00:27:08.973115  3547 solver.cpp:218] Iteration 98700 (7.15843 iter/s, 13.9695s/100 iters), loss = 0.000790091
I0926 00:27:08.973206  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000790055 (* 1 = 0.000790055 loss)
I0926 00:27:08.973223  3547 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0926 00:27:22.939524  3547 solver.cpp:218] Iteration 98800 (7.1601 iter/s, 13.9663s/100 iters), loss = 0.00048299
I0926 00:27:22.939554  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000482953 (* 1 = 0.000482953 loss)
I0926 00:27:22.939561  3547 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0926 00:27:36.908707  3547 solver.cpp:218] Iteration 98900 (7.15865 iter/s, 13.9691s/100 iters), loss = 0.000298544
I0926 00:27:36.908737  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000298507 (* 1 = 0.000298507 loss)
I0926 00:27:36.908743  3547 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0926 00:27:50.184841  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:27:50.743916  3547 solver.cpp:330] Iteration 99000, Testing net (#0)
I0926 00:27:54.071315  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:27:54.210223  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9281
I0926 00:27:54.210259  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303999 (* 1 = 0.303999 loss)
I0926 00:27:54.349382  3547 solver.cpp:218] Iteration 99000 (5.73375 iter/s, 17.4406s/100 iters), loss = 0.000412413
I0926 00:27:54.349412  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000412377 (* 1 = 0.000412377 loss)
I0926 00:27:54.349419  3547 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0926 00:28:08.317242  3547 solver.cpp:218] Iteration 99100 (7.15933 iter/s, 13.9678s/100 iters), loss = 0.00159104
I0926 00:28:08.317284  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159101 (* 1 = 0.00159101 loss)
I0926 00:28:08.317291  3547 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0926 00:28:22.298023  3547 solver.cpp:218] Iteration 99200 (7.15271 iter/s, 13.9807s/100 iters), loss = 0.000500421
I0926 00:28:22.298121  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000500386 (* 1 = 0.000500386 loss)
I0926 00:28:22.298140  3547 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0926 00:28:36.272619  3547 solver.cpp:218] Iteration 99300 (7.15591 iter/s, 13.9745s/100 iters), loss = 0.00138984
I0926 00:28:36.272651  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013898 (* 1 = 0.0013898 loss)
I0926 00:28:36.272657  3547 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0926 00:28:50.247402  3547 solver.cpp:218] Iteration 99400 (7.15578 iter/s, 13.9747s/100 iters), loss = 0.000683173
I0926 00:28:50.247434  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000683139 (* 1 = 0.000683139 loss)
I0926 00:28:50.247440  3547 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0926 00:29:03.511322  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:29:04.069200  3547 solver.cpp:330] Iteration 99500, Testing net (#0)
I0926 00:29:07.398516  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:29:07.537690  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9282
I0926 00:29:07.537715  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304071 (* 1 = 0.304071 loss)
I0926 00:29:07.676404  3547 solver.cpp:218] Iteration 99500 (5.73759 iter/s, 17.4289s/100 iters), loss = 0.000524967
I0926 00:29:07.676434  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000524933 (* 1 = 0.000524933 loss)
I0926 00:29:07.676441  3547 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0926 00:29:21.642536  3547 solver.cpp:218] Iteration 99600 (7.16021 iter/s, 13.9661s/100 iters), loss = 0.00166811
I0926 00:29:21.642578  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166808 (* 1 = 0.00166808 loss)
I0926 00:29:21.642585  3547 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0926 00:29:35.618307  3547 solver.cpp:218] Iteration 99700 (7.15528 iter/s, 13.9757s/100 iters), loss = 0.000512774
I0926 00:29:35.618453  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00051274 (* 1 = 0.00051274 loss)
I0926 00:29:35.618474  3547 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0926 00:29:49.584336  3547 solver.cpp:218] Iteration 99800 (7.16032 iter/s, 13.9659s/100 iters), loss = 0.000192843
I0926 00:29:49.584377  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000192809 (* 1 = 0.000192809 loss)
I0926 00:29:49.584383  3547 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0926 00:30:03.557860  3547 solver.cpp:218] Iteration 99900 (7.15643 iter/s, 13.9735s/100 iters), loss = 0.000653298
I0926 00:30:03.557900  3547 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000653265 (* 1 = 0.000653265 loss)
I0926 00:30:03.557907  3547 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0926 00:30:16.833266  3555 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:30:17.391705  3547 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_prelu_gauss_iter_100000.caffemodel
I0926 00:30:17.415144  3547 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_prelu_gauss_iter_100000.solverstate
I0926 00:30:17.455113  3547 solver.cpp:310] Iteration 100000, loss = 0.00065601
I0926 00:30:17.455137  3547 solver.cpp:330] Iteration 100000, Testing net (#0)
I0926 00:30:20.778549  3556 data_layer.cpp:73] Restarting data prefetching from start.
I0926 00:30:20.917649  3547 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9275
I0926 00:30:20.917673  3547 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304462 (* 1 = 0.304462 loss)
I0926 00:30:20.917677  3547 solver.cpp:315] Optimization Done.
I0926 00:30:20.917680  3547 caffe.cpp:259] Optimization Done.
