I0929 19:16:17.419376  2630 caffe.cpp:218] Using GPUs 0
I0929 19:16:17.438096  2630 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0929 19:16:17.649238  2630 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_relu_msra"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_relu_msra.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0929 19:16:17.649374  2630 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_relu_msra.prototxt
I0929 19:16:17.652302  2630 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_relu_msra.prototxt
I0929 19:16:17.652318  2630 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0929 19:16:17.652571  2630 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0929 19:16:17.652688  2630 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0929 19:16:17.653501  2630 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution32"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
I0929 19:16:17.654580  2630 layer_factory.hpp:77] Creating layer Data1
I0929 19:16:17.654677  2630 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0929 19:16:17.654703  2630 net.cpp:84] Creating Layer Data1
I0929 19:16:17.654709  2630 net.cpp:380] Data1 -> Data1
I0929 19:16:17.654726  2630 net.cpp:380] Data1 -> Data2
I0929 19:16:17.654736  2630 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0929 19:16:17.656172  2630 data_layer.cpp:45] output data size: 100,3,28,28
I0929 19:16:17.658493  2630 net.cpp:122] Setting up Data1
I0929 19:16:17.658506  2630 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0929 19:16:17.658510  2630 net.cpp:129] Top shape: 100 (100)
I0929 19:16:17.658514  2630 net.cpp:137] Memory required for data: 941200
I0929 19:16:17.658524  2630 layer_factory.hpp:77] Creating layer Convolution1
I0929 19:16:17.658545  2630 net.cpp:84] Creating Layer Convolution1
I0929 19:16:17.658550  2630 net.cpp:406] Convolution1 <- Data1
I0929 19:16:17.658560  2630 net.cpp:380] Convolution1 -> Convolution1
I0929 19:16:17.805140  2630 net.cpp:122] Setting up Convolution1
I0929 19:16:17.805164  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.805168  2630 net.cpp:137] Memory required for data: 5958800
I0929 19:16:17.805199  2630 layer_factory.hpp:77] Creating layer BatchNorm1
I0929 19:16:17.805214  2630 net.cpp:84] Creating Layer BatchNorm1
I0929 19:16:17.805219  2630 net.cpp:406] BatchNorm1 <- Convolution1
I0929 19:16:17.805239  2630 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0929 19:16:17.805379  2630 net.cpp:122] Setting up BatchNorm1
I0929 19:16:17.805387  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.805392  2630 net.cpp:137] Memory required for data: 10976400
I0929 19:16:17.805414  2630 layer_factory.hpp:77] Creating layer Scale1
I0929 19:16:17.805438  2630 net.cpp:84] Creating Layer Scale1
I0929 19:16:17.805443  2630 net.cpp:406] Scale1 <- Convolution1
I0929 19:16:17.805447  2630 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0929 19:16:17.805506  2630 layer_factory.hpp:77] Creating layer Scale1
I0929 19:16:17.805631  2630 net.cpp:122] Setting up Scale1
I0929 19:16:17.805639  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.805655  2630 net.cpp:137] Memory required for data: 15994000
I0929 19:16:17.805662  2630 layer_factory.hpp:77] Creating layer ReLU1
I0929 19:16:17.805681  2630 net.cpp:84] Creating Layer ReLU1
I0929 19:16:17.805686  2630 net.cpp:406] ReLU1 <- Convolution1
I0929 19:16:17.805693  2630 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0929 19:16:17.805830  2630 net.cpp:122] Setting up ReLU1
I0929 19:16:17.805837  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.805852  2630 net.cpp:137] Memory required for data: 21011600
I0929 19:16:17.805857  2630 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0929 19:16:17.805879  2630 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0929 19:16:17.805883  2630 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0929 19:16:17.805898  2630 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0929 19:16:17.805917  2630 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0929 19:16:17.805955  2630 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0929 19:16:17.805971  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.805979  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.805992  2630 net.cpp:137] Memory required for data: 31046800
I0929 19:16:17.805999  2630 layer_factory.hpp:77] Creating layer Convolution2
I0929 19:16:17.806020  2630 net.cpp:84] Creating Layer Convolution2
I0929 19:16:17.806025  2630 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0929 19:16:17.806040  2630 net.cpp:380] Convolution2 -> Convolution2
I0929 19:16:17.806938  2630 net.cpp:122] Setting up Convolution2
I0929 19:16:17.806951  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.806955  2630 net.cpp:137] Memory required for data: 36064400
I0929 19:16:17.806965  2630 layer_factory.hpp:77] Creating layer BatchNorm2
I0929 19:16:17.806973  2630 net.cpp:84] Creating Layer BatchNorm2
I0929 19:16:17.806979  2630 net.cpp:406] BatchNorm2 <- Convolution2
I0929 19:16:17.806985  2630 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0929 19:16:17.807111  2630 net.cpp:122] Setting up BatchNorm2
I0929 19:16:17.807118  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.807123  2630 net.cpp:137] Memory required for data: 41082000
I0929 19:16:17.807132  2630 layer_factory.hpp:77] Creating layer Scale2
I0929 19:16:17.807142  2630 net.cpp:84] Creating Layer Scale2
I0929 19:16:17.807145  2630 net.cpp:406] Scale2 <- Convolution2
I0929 19:16:17.807152  2630 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0929 19:16:17.807190  2630 layer_factory.hpp:77] Creating layer Scale2
I0929 19:16:17.807276  2630 net.cpp:122] Setting up Scale2
I0929 19:16:17.807283  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.807288  2630 net.cpp:137] Memory required for data: 46099600
I0929 19:16:17.807296  2630 layer_factory.hpp:77] Creating layer ReLU2
I0929 19:16:17.807303  2630 net.cpp:84] Creating Layer ReLU2
I0929 19:16:17.807309  2630 net.cpp:406] ReLU2 <- Convolution2
I0929 19:16:17.807315  2630 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0929 19:16:17.807756  2630 net.cpp:122] Setting up ReLU2
I0929 19:16:17.807767  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.807781  2630 net.cpp:137] Memory required for data: 51117200
I0929 19:16:17.807787  2630 layer_factory.hpp:77] Creating layer Convolution3
I0929 19:16:17.807797  2630 net.cpp:84] Creating Layer Convolution3
I0929 19:16:17.807802  2630 net.cpp:406] Convolution3 <- Convolution2
I0929 19:16:17.807811  2630 net.cpp:380] Convolution3 -> Convolution3
I0929 19:16:17.808334  2630 net.cpp:122] Setting up Convolution3
I0929 19:16:17.808346  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.808349  2630 net.cpp:137] Memory required for data: 56134800
I0929 19:16:17.808359  2630 layer_factory.hpp:77] Creating layer BatchNorm3
I0929 19:16:17.808367  2630 net.cpp:84] Creating Layer BatchNorm3
I0929 19:16:17.808372  2630 net.cpp:406] BatchNorm3 <- Convolution3
I0929 19:16:17.808380  2630 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0929 19:16:17.808504  2630 net.cpp:122] Setting up BatchNorm3
I0929 19:16:17.808511  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.808517  2630 net.cpp:137] Memory required for data: 61152400
I0929 19:16:17.808528  2630 layer_factory.hpp:77] Creating layer Scale3
I0929 19:16:17.808535  2630 net.cpp:84] Creating Layer Scale3
I0929 19:16:17.808542  2630 net.cpp:406] Scale3 <- Convolution3
I0929 19:16:17.808548  2630 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0929 19:16:17.808578  2630 layer_factory.hpp:77] Creating layer Scale3
I0929 19:16:17.808656  2630 net.cpp:122] Setting up Scale3
I0929 19:16:17.808665  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.808670  2630 net.cpp:137] Memory required for data: 66170000
I0929 19:16:17.808676  2630 layer_factory.hpp:77] Creating layer Eltwise1
I0929 19:16:17.808684  2630 net.cpp:84] Creating Layer Eltwise1
I0929 19:16:17.808689  2630 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0929 19:16:17.808696  2630 net.cpp:406] Eltwise1 <- Convolution3
I0929 19:16:17.808702  2630 net.cpp:380] Eltwise1 -> Eltwise1
I0929 19:16:17.808724  2630 net.cpp:122] Setting up Eltwise1
I0929 19:16:17.808732  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.808737  2630 net.cpp:137] Memory required for data: 71187600
I0929 19:16:17.808742  2630 layer_factory.hpp:77] Creating layer ReLU3
I0929 19:16:17.808748  2630 net.cpp:84] Creating Layer ReLU3
I0929 19:16:17.808753  2630 net.cpp:406] ReLU3 <- Eltwise1
I0929 19:16:17.808759  2630 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0929 19:16:17.809201  2630 net.cpp:122] Setting up ReLU3
I0929 19:16:17.809212  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.809217  2630 net.cpp:137] Memory required for data: 76205200
I0929 19:16:17.809221  2630 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0929 19:16:17.809229  2630 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0929 19:16:17.809236  2630 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0929 19:16:17.809242  2630 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0929 19:16:17.809252  2630 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0929 19:16:17.809283  2630 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0929 19:16:17.809289  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.809296  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.809301  2630 net.cpp:137] Memory required for data: 86240400
I0929 19:16:17.809305  2630 layer_factory.hpp:77] Creating layer Convolution4
I0929 19:16:17.809317  2630 net.cpp:84] Creating Layer Convolution4
I0929 19:16:17.809321  2630 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0929 19:16:17.809329  2630 net.cpp:380] Convolution4 -> Convolution4
I0929 19:16:17.810205  2630 net.cpp:122] Setting up Convolution4
I0929 19:16:17.810216  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.810221  2630 net.cpp:137] Memory required for data: 91258000
I0929 19:16:17.810230  2630 layer_factory.hpp:77] Creating layer BatchNorm4
I0929 19:16:17.810237  2630 net.cpp:84] Creating Layer BatchNorm4
I0929 19:16:17.810243  2630 net.cpp:406] BatchNorm4 <- Convolution4
I0929 19:16:17.810257  2630 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0929 19:16:17.810382  2630 net.cpp:122] Setting up BatchNorm4
I0929 19:16:17.810390  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.810395  2630 net.cpp:137] Memory required for data: 96275600
I0929 19:16:17.810405  2630 layer_factory.hpp:77] Creating layer Scale4
I0929 19:16:17.810411  2630 net.cpp:84] Creating Layer Scale4
I0929 19:16:17.810416  2630 net.cpp:406] Scale4 <- Convolution4
I0929 19:16:17.810422  2630 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0929 19:16:17.810452  2630 layer_factory.hpp:77] Creating layer Scale4
I0929 19:16:17.810551  2630 net.cpp:122] Setting up Scale4
I0929 19:16:17.810559  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.810564  2630 net.cpp:137] Memory required for data: 101293200
I0929 19:16:17.810570  2630 layer_factory.hpp:77] Creating layer ReLU4
I0929 19:16:17.810577  2630 net.cpp:84] Creating Layer ReLU4
I0929 19:16:17.810582  2630 net.cpp:406] ReLU4 <- Convolution4
I0929 19:16:17.810590  2630 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0929 19:16:17.810710  2630 net.cpp:122] Setting up ReLU4
I0929 19:16:17.810719  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.810724  2630 net.cpp:137] Memory required for data: 106310800
I0929 19:16:17.810729  2630 layer_factory.hpp:77] Creating layer Convolution5
I0929 19:16:17.810739  2630 net.cpp:84] Creating Layer Convolution5
I0929 19:16:17.810745  2630 net.cpp:406] Convolution5 <- Convolution4
I0929 19:16:17.810752  2630 net.cpp:380] Convolution5 -> Convolution5
I0929 19:16:17.811625  2630 net.cpp:122] Setting up Convolution5
I0929 19:16:17.811635  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.811640  2630 net.cpp:137] Memory required for data: 111328400
I0929 19:16:17.811647  2630 layer_factory.hpp:77] Creating layer BatchNorm5
I0929 19:16:17.811656  2630 net.cpp:84] Creating Layer BatchNorm5
I0929 19:16:17.811662  2630 net.cpp:406] BatchNorm5 <- Convolution5
I0929 19:16:17.811669  2630 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0929 19:16:17.811802  2630 net.cpp:122] Setting up BatchNorm5
I0929 19:16:17.811810  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.811813  2630 net.cpp:137] Memory required for data: 116346000
I0929 19:16:17.811826  2630 layer_factory.hpp:77] Creating layer Scale5
I0929 19:16:17.811833  2630 net.cpp:84] Creating Layer Scale5
I0929 19:16:17.811839  2630 net.cpp:406] Scale5 <- Convolution5
I0929 19:16:17.811846  2630 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0929 19:16:17.811878  2630 layer_factory.hpp:77] Creating layer Scale5
I0929 19:16:17.811960  2630 net.cpp:122] Setting up Scale5
I0929 19:16:17.811967  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.811971  2630 net.cpp:137] Memory required for data: 121363600
I0929 19:16:17.811980  2630 layer_factory.hpp:77] Creating layer Eltwise2
I0929 19:16:17.811988  2630 net.cpp:84] Creating Layer Eltwise2
I0929 19:16:17.811993  2630 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0929 19:16:17.811998  2630 net.cpp:406] Eltwise2 <- Convolution5
I0929 19:16:17.812005  2630 net.cpp:380] Eltwise2 -> Eltwise2
I0929 19:16:17.812026  2630 net.cpp:122] Setting up Eltwise2
I0929 19:16:17.812032  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.812036  2630 net.cpp:137] Memory required for data: 126381200
I0929 19:16:17.812042  2630 layer_factory.hpp:77] Creating layer ReLU5
I0929 19:16:17.812048  2630 net.cpp:84] Creating Layer ReLU5
I0929 19:16:17.812053  2630 net.cpp:406] ReLU5 <- Eltwise2
I0929 19:16:17.812059  2630 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0929 19:16:17.812175  2630 net.cpp:122] Setting up ReLU5
I0929 19:16:17.812185  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.812188  2630 net.cpp:137] Memory required for data: 131398800
I0929 19:16:17.812193  2630 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0929 19:16:17.812201  2630 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0929 19:16:17.812211  2630 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0929 19:16:17.812219  2630 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0929 19:16:17.812227  2630 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0929 19:16:17.812259  2630 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0929 19:16:17.812266  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.812273  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.812278  2630 net.cpp:137] Memory required for data: 141434000
I0929 19:16:17.812283  2630 layer_factory.hpp:77] Creating layer Convolution6
I0929 19:16:17.812294  2630 net.cpp:84] Creating Layer Convolution6
I0929 19:16:17.812299  2630 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0929 19:16:17.812305  2630 net.cpp:380] Convolution6 -> Convolution6
I0929 19:16:17.813181  2630 net.cpp:122] Setting up Convolution6
I0929 19:16:17.813194  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.813199  2630 net.cpp:137] Memory required for data: 146451600
I0929 19:16:17.813206  2630 layer_factory.hpp:77] Creating layer BatchNorm6
I0929 19:16:17.813215  2630 net.cpp:84] Creating Layer BatchNorm6
I0929 19:16:17.813220  2630 net.cpp:406] BatchNorm6 <- Convolution6
I0929 19:16:17.813238  2630 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0929 19:16:17.813382  2630 net.cpp:122] Setting up BatchNorm6
I0929 19:16:17.813390  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.813393  2630 net.cpp:137] Memory required for data: 151469200
I0929 19:16:17.813402  2630 layer_factory.hpp:77] Creating layer Scale6
I0929 19:16:17.813410  2630 net.cpp:84] Creating Layer Scale6
I0929 19:16:17.813415  2630 net.cpp:406] Scale6 <- Convolution6
I0929 19:16:17.813421  2630 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0929 19:16:17.813454  2630 layer_factory.hpp:77] Creating layer Scale6
I0929 19:16:17.813536  2630 net.cpp:122] Setting up Scale6
I0929 19:16:17.813544  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.813549  2630 net.cpp:137] Memory required for data: 156486800
I0929 19:16:17.813555  2630 layer_factory.hpp:77] Creating layer ReLU6
I0929 19:16:17.813562  2630 net.cpp:84] Creating Layer ReLU6
I0929 19:16:17.813567  2630 net.cpp:406] ReLU6 <- Convolution6
I0929 19:16:17.813573  2630 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0929 19:16:17.813693  2630 net.cpp:122] Setting up ReLU6
I0929 19:16:17.813701  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.813705  2630 net.cpp:137] Memory required for data: 161504400
I0929 19:16:17.813709  2630 layer_factory.hpp:77] Creating layer Convolution7
I0929 19:16:17.813720  2630 net.cpp:84] Creating Layer Convolution7
I0929 19:16:17.813725  2630 net.cpp:406] Convolution7 <- Convolution6
I0929 19:16:17.813735  2630 net.cpp:380] Convolution7 -> Convolution7
I0929 19:16:17.814620  2630 net.cpp:122] Setting up Convolution7
I0929 19:16:17.814631  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.814636  2630 net.cpp:137] Memory required for data: 166522000
I0929 19:16:17.814644  2630 layer_factory.hpp:77] Creating layer BatchNorm7
I0929 19:16:17.814653  2630 net.cpp:84] Creating Layer BatchNorm7
I0929 19:16:17.814659  2630 net.cpp:406] BatchNorm7 <- Convolution7
I0929 19:16:17.814667  2630 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0929 19:16:17.814800  2630 net.cpp:122] Setting up BatchNorm7
I0929 19:16:17.814807  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.814811  2630 net.cpp:137] Memory required for data: 171539600
I0929 19:16:17.814821  2630 layer_factory.hpp:77] Creating layer Scale7
I0929 19:16:17.814831  2630 net.cpp:84] Creating Layer Scale7
I0929 19:16:17.814836  2630 net.cpp:406] Scale7 <- Convolution7
I0929 19:16:17.814841  2630 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0929 19:16:17.814872  2630 layer_factory.hpp:77] Creating layer Scale7
I0929 19:16:17.814955  2630 net.cpp:122] Setting up Scale7
I0929 19:16:17.814963  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.814975  2630 net.cpp:137] Memory required for data: 176557200
I0929 19:16:17.814982  2630 layer_factory.hpp:77] Creating layer Eltwise3
I0929 19:16:17.814990  2630 net.cpp:84] Creating Layer Eltwise3
I0929 19:16:17.814996  2630 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0929 19:16:17.815001  2630 net.cpp:406] Eltwise3 <- Convolution7
I0929 19:16:17.815009  2630 net.cpp:380] Eltwise3 -> Eltwise3
I0929 19:16:17.815029  2630 net.cpp:122] Setting up Eltwise3
I0929 19:16:17.815037  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.815042  2630 net.cpp:137] Memory required for data: 181574800
I0929 19:16:17.815047  2630 layer_factory.hpp:77] Creating layer ReLU7
I0929 19:16:17.815054  2630 net.cpp:84] Creating Layer ReLU7
I0929 19:16:17.815058  2630 net.cpp:406] ReLU7 <- Eltwise3
I0929 19:16:17.815064  2630 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0929 19:16:17.815181  2630 net.cpp:122] Setting up ReLU7
I0929 19:16:17.815189  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.815193  2630 net.cpp:137] Memory required for data: 186592400
I0929 19:16:17.815197  2630 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0929 19:16:17.815206  2630 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0929 19:16:17.815210  2630 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0929 19:16:17.815217  2630 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0929 19:16:17.815224  2630 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0929 19:16:17.815254  2630 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0929 19:16:17.815261  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.815268  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.815273  2630 net.cpp:137] Memory required for data: 196627600
I0929 19:16:17.815277  2630 layer_factory.hpp:77] Creating layer Convolution8
I0929 19:16:17.815289  2630 net.cpp:84] Creating Layer Convolution8
I0929 19:16:17.815292  2630 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0929 19:16:17.815301  2630 net.cpp:380] Convolution8 -> Convolution8
I0929 19:16:17.816227  2630 net.cpp:122] Setting up Convolution8
I0929 19:16:17.816239  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.816246  2630 net.cpp:137] Memory required for data: 201645200
I0929 19:16:17.816252  2630 layer_factory.hpp:77] Creating layer BatchNorm8
I0929 19:16:17.816260  2630 net.cpp:84] Creating Layer BatchNorm8
I0929 19:16:17.816267  2630 net.cpp:406] BatchNorm8 <- Convolution8
I0929 19:16:17.816274  2630 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0929 19:16:17.816429  2630 net.cpp:122] Setting up BatchNorm8
I0929 19:16:17.816437  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.816442  2630 net.cpp:137] Memory required for data: 206662800
I0929 19:16:17.816449  2630 layer_factory.hpp:77] Creating layer Scale8
I0929 19:16:17.816457  2630 net.cpp:84] Creating Layer Scale8
I0929 19:16:17.816462  2630 net.cpp:406] Scale8 <- Convolution8
I0929 19:16:17.816468  2630 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0929 19:16:17.816499  2630 layer_factory.hpp:77] Creating layer Scale8
I0929 19:16:17.816586  2630 net.cpp:122] Setting up Scale8
I0929 19:16:17.816592  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.816596  2630 net.cpp:137] Memory required for data: 211680400
I0929 19:16:17.816604  2630 layer_factory.hpp:77] Creating layer ReLU8
I0929 19:16:17.816610  2630 net.cpp:84] Creating Layer ReLU8
I0929 19:16:17.816617  2630 net.cpp:406] ReLU8 <- Convolution8
I0929 19:16:17.816622  2630 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0929 19:16:17.817098  2630 net.cpp:122] Setting up ReLU8
I0929 19:16:17.817109  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.817114  2630 net.cpp:137] Memory required for data: 216698000
I0929 19:16:17.817118  2630 layer_factory.hpp:77] Creating layer Convolution9
I0929 19:16:17.817131  2630 net.cpp:84] Creating Layer Convolution9
I0929 19:16:17.817136  2630 net.cpp:406] Convolution9 <- Convolution8
I0929 19:16:17.817150  2630 net.cpp:380] Convolution9 -> Convolution9
I0929 19:16:17.817713  2630 net.cpp:122] Setting up Convolution9
I0929 19:16:17.817723  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.817728  2630 net.cpp:137] Memory required for data: 221715600
I0929 19:16:17.817735  2630 layer_factory.hpp:77] Creating layer BatchNorm9
I0929 19:16:17.817744  2630 net.cpp:84] Creating Layer BatchNorm9
I0929 19:16:17.817759  2630 net.cpp:406] BatchNorm9 <- Convolution9
I0929 19:16:17.817767  2630 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0929 19:16:17.817903  2630 net.cpp:122] Setting up BatchNorm9
I0929 19:16:17.817911  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.817916  2630 net.cpp:137] Memory required for data: 226733200
I0929 19:16:17.817926  2630 layer_factory.hpp:77] Creating layer Scale9
I0929 19:16:17.817934  2630 net.cpp:84] Creating Layer Scale9
I0929 19:16:17.817939  2630 net.cpp:406] Scale9 <- Convolution9
I0929 19:16:17.817946  2630 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0929 19:16:17.817978  2630 layer_factory.hpp:77] Creating layer Scale9
I0929 19:16:17.818066  2630 net.cpp:122] Setting up Scale9
I0929 19:16:17.818074  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.818078  2630 net.cpp:137] Memory required for data: 231750800
I0929 19:16:17.818086  2630 layer_factory.hpp:77] Creating layer Eltwise4
I0929 19:16:17.818094  2630 net.cpp:84] Creating Layer Eltwise4
I0929 19:16:17.818099  2630 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0929 19:16:17.818104  2630 net.cpp:406] Eltwise4 <- Convolution9
I0929 19:16:17.818112  2630 net.cpp:380] Eltwise4 -> Eltwise4
I0929 19:16:17.818132  2630 net.cpp:122] Setting up Eltwise4
I0929 19:16:17.818140  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.818145  2630 net.cpp:137] Memory required for data: 236768400
I0929 19:16:17.818150  2630 layer_factory.hpp:77] Creating layer ReLU9
I0929 19:16:17.818157  2630 net.cpp:84] Creating Layer ReLU9
I0929 19:16:17.818162  2630 net.cpp:406] ReLU9 <- Eltwise4
I0929 19:16:17.818167  2630 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0929 19:16:17.818636  2630 net.cpp:122] Setting up ReLU9
I0929 19:16:17.818647  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.818652  2630 net.cpp:137] Memory required for data: 241786000
I0929 19:16:17.818656  2630 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0929 19:16:17.818665  2630 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0929 19:16:17.818670  2630 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0929 19:16:17.818675  2630 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0929 19:16:17.818684  2630 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0929 19:16:17.818717  2630 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0929 19:16:17.818723  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.818730  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.818734  2630 net.cpp:137] Memory required for data: 251821200
I0929 19:16:17.818739  2630 layer_factory.hpp:77] Creating layer Convolution10
I0929 19:16:17.818749  2630 net.cpp:84] Creating Layer Convolution10
I0929 19:16:17.818754  2630 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0929 19:16:17.818763  2630 net.cpp:380] Convolution10 -> Convolution10
I0929 19:16:17.819644  2630 net.cpp:122] Setting up Convolution10
I0929 19:16:17.819655  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.819661  2630 net.cpp:137] Memory required for data: 256838800
I0929 19:16:17.819679  2630 layer_factory.hpp:77] Creating layer BatchNorm10
I0929 19:16:17.819687  2630 net.cpp:84] Creating Layer BatchNorm10
I0929 19:16:17.819692  2630 net.cpp:406] BatchNorm10 <- Convolution10
I0929 19:16:17.819700  2630 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0929 19:16:17.819833  2630 net.cpp:122] Setting up BatchNorm10
I0929 19:16:17.819840  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.819844  2630 net.cpp:137] Memory required for data: 261856400
I0929 19:16:17.819861  2630 layer_factory.hpp:77] Creating layer Scale10
I0929 19:16:17.819869  2630 net.cpp:84] Creating Layer Scale10
I0929 19:16:17.819874  2630 net.cpp:406] Scale10 <- Convolution10
I0929 19:16:17.819880  2630 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0929 19:16:17.819913  2630 layer_factory.hpp:77] Creating layer Scale10
I0929 19:16:17.819996  2630 net.cpp:122] Setting up Scale10
I0929 19:16:17.820004  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.820009  2630 net.cpp:137] Memory required for data: 266874000
I0929 19:16:17.820016  2630 layer_factory.hpp:77] Creating layer ReLU10
I0929 19:16:17.820024  2630 net.cpp:84] Creating Layer ReLU10
I0929 19:16:17.820027  2630 net.cpp:406] ReLU10 <- Convolution10
I0929 19:16:17.820034  2630 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I0929 19:16:17.820155  2630 net.cpp:122] Setting up ReLU10
I0929 19:16:17.820165  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.820170  2630 net.cpp:137] Memory required for data: 271891600
I0929 19:16:17.820175  2630 layer_factory.hpp:77] Creating layer Convolution11
I0929 19:16:17.820186  2630 net.cpp:84] Creating Layer Convolution11
I0929 19:16:17.820191  2630 net.cpp:406] Convolution11 <- Convolution10
I0929 19:16:17.820199  2630 net.cpp:380] Convolution11 -> Convolution11
I0929 19:16:17.821094  2630 net.cpp:122] Setting up Convolution11
I0929 19:16:17.821105  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.821108  2630 net.cpp:137] Memory required for data: 276909200
I0929 19:16:17.821116  2630 layer_factory.hpp:77] Creating layer BatchNorm11
I0929 19:16:17.821125  2630 net.cpp:84] Creating Layer BatchNorm11
I0929 19:16:17.821130  2630 net.cpp:406] BatchNorm11 <- Convolution11
I0929 19:16:17.821138  2630 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0929 19:16:17.821274  2630 net.cpp:122] Setting up BatchNorm11
I0929 19:16:17.821281  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.821286  2630 net.cpp:137] Memory required for data: 281926800
I0929 19:16:17.821305  2630 layer_factory.hpp:77] Creating layer Scale11
I0929 19:16:17.821312  2630 net.cpp:84] Creating Layer Scale11
I0929 19:16:17.821326  2630 net.cpp:406] Scale11 <- Convolution11
I0929 19:16:17.821343  2630 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0929 19:16:17.821383  2630 layer_factory.hpp:77] Creating layer Scale11
I0929 19:16:17.821485  2630 net.cpp:122] Setting up Scale11
I0929 19:16:17.821493  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.821497  2630 net.cpp:137] Memory required for data: 286944400
I0929 19:16:17.821514  2630 layer_factory.hpp:77] Creating layer Eltwise5
I0929 19:16:17.821521  2630 net.cpp:84] Creating Layer Eltwise5
I0929 19:16:17.821527  2630 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0929 19:16:17.821532  2630 net.cpp:406] Eltwise5 <- Convolution11
I0929 19:16:17.821540  2630 net.cpp:380] Eltwise5 -> Eltwise5
I0929 19:16:17.821563  2630 net.cpp:122] Setting up Eltwise5
I0929 19:16:17.821570  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.821574  2630 net.cpp:137] Memory required for data: 291962000
I0929 19:16:17.821579  2630 layer_factory.hpp:77] Creating layer ReLU11
I0929 19:16:17.821586  2630 net.cpp:84] Creating Layer ReLU11
I0929 19:16:17.821591  2630 net.cpp:406] ReLU11 <- Eltwise5
I0929 19:16:17.821596  2630 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0929 19:16:17.821719  2630 net.cpp:122] Setting up ReLU11
I0929 19:16:17.821727  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.821732  2630 net.cpp:137] Memory required for data: 296979600
I0929 19:16:17.821738  2630 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0929 19:16:17.821744  2630 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0929 19:16:17.821749  2630 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0929 19:16:17.821755  2630 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0929 19:16:17.821764  2630 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0929 19:16:17.821805  2630 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0929 19:16:17.821811  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.821818  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.821822  2630 net.cpp:137] Memory required for data: 307014800
I0929 19:16:17.821827  2630 layer_factory.hpp:77] Creating layer Convolution12
I0929 19:16:17.821840  2630 net.cpp:84] Creating Layer Convolution12
I0929 19:16:17.821843  2630 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0929 19:16:17.821851  2630 net.cpp:380] Convolution12 -> Convolution12
I0929 19:16:17.822777  2630 net.cpp:122] Setting up Convolution12
I0929 19:16:17.822788  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.822793  2630 net.cpp:137] Memory required for data: 312032400
I0929 19:16:17.822800  2630 layer_factory.hpp:77] Creating layer BatchNorm12
I0929 19:16:17.822809  2630 net.cpp:84] Creating Layer BatchNorm12
I0929 19:16:17.822815  2630 net.cpp:406] BatchNorm12 <- Convolution12
I0929 19:16:17.822824  2630 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0929 19:16:17.822960  2630 net.cpp:122] Setting up BatchNorm12
I0929 19:16:17.822968  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.822973  2630 net.cpp:137] Memory required for data: 317050000
I0929 19:16:17.822981  2630 layer_factory.hpp:77] Creating layer Scale12
I0929 19:16:17.822990  2630 net.cpp:84] Creating Layer Scale12
I0929 19:16:17.822995  2630 net.cpp:406] Scale12 <- Convolution12
I0929 19:16:17.823002  2630 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0929 19:16:17.823035  2630 layer_factory.hpp:77] Creating layer Scale12
I0929 19:16:17.823117  2630 net.cpp:122] Setting up Scale12
I0929 19:16:17.823125  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.823130  2630 net.cpp:137] Memory required for data: 322067600
I0929 19:16:17.823138  2630 layer_factory.hpp:77] Creating layer ReLU12
I0929 19:16:17.823148  2630 net.cpp:84] Creating Layer ReLU12
I0929 19:16:17.823153  2630 net.cpp:406] ReLU12 <- Convolution12
I0929 19:16:17.823158  2630 net.cpp:367] ReLU12 -> Convolution12 (in-place)
I0929 19:16:17.823277  2630 net.cpp:122] Setting up ReLU12
I0929 19:16:17.823287  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.823290  2630 net.cpp:137] Memory required for data: 327085200
I0929 19:16:17.823295  2630 layer_factory.hpp:77] Creating layer Convolution13
I0929 19:16:17.823307  2630 net.cpp:84] Creating Layer Convolution13
I0929 19:16:17.823312  2630 net.cpp:406] Convolution13 <- Convolution12
I0929 19:16:17.823319  2630 net.cpp:380] Convolution13 -> Convolution13
I0929 19:16:17.824213  2630 net.cpp:122] Setting up Convolution13
I0929 19:16:17.824224  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.824229  2630 net.cpp:137] Memory required for data: 332102800
I0929 19:16:17.824237  2630 layer_factory.hpp:77] Creating layer BatchNorm13
I0929 19:16:17.824247  2630 net.cpp:84] Creating Layer BatchNorm13
I0929 19:16:17.824252  2630 net.cpp:406] BatchNorm13 <- Convolution13
I0929 19:16:17.824260  2630 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0929 19:16:17.824398  2630 net.cpp:122] Setting up BatchNorm13
I0929 19:16:17.824406  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.824410  2630 net.cpp:137] Memory required for data: 337120400
I0929 19:16:17.824419  2630 layer_factory.hpp:77] Creating layer Scale13
I0929 19:16:17.824426  2630 net.cpp:84] Creating Layer Scale13
I0929 19:16:17.824431  2630 net.cpp:406] Scale13 <- Convolution13
I0929 19:16:17.824439  2630 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0929 19:16:17.824470  2630 layer_factory.hpp:77] Creating layer Scale13
I0929 19:16:17.824556  2630 net.cpp:122] Setting up Scale13
I0929 19:16:17.824563  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.824568  2630 net.cpp:137] Memory required for data: 342138000
I0929 19:16:17.824575  2630 layer_factory.hpp:77] Creating layer Eltwise6
I0929 19:16:17.824589  2630 net.cpp:84] Creating Layer Eltwise6
I0929 19:16:17.824595  2630 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0929 19:16:17.824601  2630 net.cpp:406] Eltwise6 <- Convolution13
I0929 19:16:17.824609  2630 net.cpp:380] Eltwise6 -> Eltwise6
I0929 19:16:17.824633  2630 net.cpp:122] Setting up Eltwise6
I0929 19:16:17.824640  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.824645  2630 net.cpp:137] Memory required for data: 347155600
I0929 19:16:17.824651  2630 layer_factory.hpp:77] Creating layer ReLU13
I0929 19:16:17.824661  2630 net.cpp:84] Creating Layer ReLU13
I0929 19:16:17.824666  2630 net.cpp:406] ReLU13 <- Eltwise6
I0929 19:16:17.824673  2630 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0929 19:16:17.824797  2630 net.cpp:122] Setting up ReLU13
I0929 19:16:17.824805  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.824810  2630 net.cpp:137] Memory required for data: 352173200
I0929 19:16:17.824816  2630 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0929 19:16:17.824822  2630 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0929 19:16:17.824827  2630 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0929 19:16:17.824836  2630 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0929 19:16:17.824842  2630 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0929 19:16:17.824873  2630 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0929 19:16:17.824880  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.824887  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.824892  2630 net.cpp:137] Memory required for data: 362208400
I0929 19:16:17.824895  2630 layer_factory.hpp:77] Creating layer Convolution14
I0929 19:16:17.824908  2630 net.cpp:84] Creating Layer Convolution14
I0929 19:16:17.824911  2630 net.cpp:406] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0929 19:16:17.824918  2630 net.cpp:380] Convolution14 -> Convolution14
I0929 19:16:17.825814  2630 net.cpp:122] Setting up Convolution14
I0929 19:16:17.825821  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.825824  2630 net.cpp:137] Memory required for data: 367226000
I0929 19:16:17.825829  2630 layer_factory.hpp:77] Creating layer BatchNorm14
I0929 19:16:17.825834  2630 net.cpp:84] Creating Layer BatchNorm14
I0929 19:16:17.825836  2630 net.cpp:406] BatchNorm14 <- Convolution14
I0929 19:16:17.825841  2630 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0929 19:16:17.825973  2630 net.cpp:122] Setting up BatchNorm14
I0929 19:16:17.825976  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.825978  2630 net.cpp:137] Memory required for data: 372243600
I0929 19:16:17.825984  2630 layer_factory.hpp:77] Creating layer Scale14
I0929 19:16:17.825989  2630 net.cpp:84] Creating Layer Scale14
I0929 19:16:17.825990  2630 net.cpp:406] Scale14 <- Convolution14
I0929 19:16:17.825994  2630 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0929 19:16:17.826020  2630 layer_factory.hpp:77] Creating layer Scale14
I0929 19:16:17.826097  2630 net.cpp:122] Setting up Scale14
I0929 19:16:17.826102  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.826103  2630 net.cpp:137] Memory required for data: 377261200
I0929 19:16:17.826107  2630 layer_factory.hpp:77] Creating layer ReLU14
I0929 19:16:17.826112  2630 net.cpp:84] Creating Layer ReLU14
I0929 19:16:17.826114  2630 net.cpp:406] ReLU14 <- Convolution14
I0929 19:16:17.826117  2630 net.cpp:367] ReLU14 -> Convolution14 (in-place)
I0929 19:16:17.826578  2630 net.cpp:122] Setting up ReLU14
I0929 19:16:17.826586  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.826588  2630 net.cpp:137] Memory required for data: 382278800
I0929 19:16:17.826591  2630 layer_factory.hpp:77] Creating layer Convolution15
I0929 19:16:17.826598  2630 net.cpp:84] Creating Layer Convolution15
I0929 19:16:17.826601  2630 net.cpp:406] Convolution15 <- Convolution14
I0929 19:16:17.826606  2630 net.cpp:380] Convolution15 -> Convolution15
I0929 19:16:17.827189  2630 net.cpp:122] Setting up Convolution15
I0929 19:16:17.827203  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.827206  2630 net.cpp:137] Memory required for data: 387296400
I0929 19:16:17.827210  2630 layer_factory.hpp:77] Creating layer BatchNorm15
I0929 19:16:17.827215  2630 net.cpp:84] Creating Layer BatchNorm15
I0929 19:16:17.827219  2630 net.cpp:406] BatchNorm15 <- Convolution15
I0929 19:16:17.827221  2630 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0929 19:16:17.827354  2630 net.cpp:122] Setting up BatchNorm15
I0929 19:16:17.827358  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.827360  2630 net.cpp:137] Memory required for data: 392314000
I0929 19:16:17.827365  2630 layer_factory.hpp:77] Creating layer Scale15
I0929 19:16:17.827369  2630 net.cpp:84] Creating Layer Scale15
I0929 19:16:17.827371  2630 net.cpp:406] Scale15 <- Convolution15
I0929 19:16:17.827374  2630 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0929 19:16:17.827400  2630 layer_factory.hpp:77] Creating layer Scale15
I0929 19:16:17.827477  2630 net.cpp:122] Setting up Scale15
I0929 19:16:17.827482  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.827484  2630 net.cpp:137] Memory required for data: 397331600
I0929 19:16:17.827487  2630 layer_factory.hpp:77] Creating layer Eltwise7
I0929 19:16:17.827492  2630 net.cpp:84] Creating Layer Eltwise7
I0929 19:16:17.827494  2630 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0929 19:16:17.827497  2630 net.cpp:406] Eltwise7 <- Convolution15
I0929 19:16:17.827500  2630 net.cpp:380] Eltwise7 -> Eltwise7
I0929 19:16:17.827517  2630 net.cpp:122] Setting up Eltwise7
I0929 19:16:17.827519  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.827522  2630 net.cpp:137] Memory required for data: 402349200
I0929 19:16:17.827523  2630 layer_factory.hpp:77] Creating layer ReLU15
I0929 19:16:17.827527  2630 net.cpp:84] Creating Layer ReLU15
I0929 19:16:17.827529  2630 net.cpp:406] ReLU15 <- Eltwise7
I0929 19:16:17.827533  2630 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0929 19:16:17.827970  2630 net.cpp:122] Setting up ReLU15
I0929 19:16:17.827978  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.827981  2630 net.cpp:137] Memory required for data: 407366800
I0929 19:16:17.827983  2630 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0929 19:16:17.827988  2630 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0929 19:16:17.827991  2630 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0929 19:16:17.827994  2630 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0929 19:16:17.827999  2630 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0929 19:16:17.828027  2630 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0929 19:16:17.828030  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.828033  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.828035  2630 net.cpp:137] Memory required for data: 417402000
I0929 19:16:17.828037  2630 layer_factory.hpp:77] Creating layer Convolution16
I0929 19:16:17.828044  2630 net.cpp:84] Creating Layer Convolution16
I0929 19:16:17.828047  2630 net.cpp:406] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0929 19:16:17.828052  2630 net.cpp:380] Convolution16 -> Convolution16
I0929 19:16:17.829249  2630 net.cpp:122] Setting up Convolution16
I0929 19:16:17.829259  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.829262  2630 net.cpp:137] Memory required for data: 422419600
I0929 19:16:17.829267  2630 layer_factory.hpp:77] Creating layer BatchNorm16
I0929 19:16:17.829270  2630 net.cpp:84] Creating Layer BatchNorm16
I0929 19:16:17.829273  2630 net.cpp:406] BatchNorm16 <- Convolution16
I0929 19:16:17.829277  2630 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0929 19:16:17.829411  2630 net.cpp:122] Setting up BatchNorm16
I0929 19:16:17.829416  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.829417  2630 net.cpp:137] Memory required for data: 427437200
I0929 19:16:17.829422  2630 layer_factory.hpp:77] Creating layer Scale16
I0929 19:16:17.829433  2630 net.cpp:84] Creating Layer Scale16
I0929 19:16:17.829437  2630 net.cpp:406] Scale16 <- Convolution16
I0929 19:16:17.829440  2630 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0929 19:16:17.829466  2630 layer_factory.hpp:77] Creating layer Scale16
I0929 19:16:17.829545  2630 net.cpp:122] Setting up Scale16
I0929 19:16:17.829548  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.829550  2630 net.cpp:137] Memory required for data: 432454800
I0929 19:16:17.829555  2630 layer_factory.hpp:77] Creating layer ReLU16
I0929 19:16:17.829558  2630 net.cpp:84] Creating Layer ReLU16
I0929 19:16:17.829560  2630 net.cpp:406] ReLU16 <- Convolution16
I0929 19:16:17.829563  2630 net.cpp:367] ReLU16 -> Convolution16 (in-place)
I0929 19:16:17.829682  2630 net.cpp:122] Setting up ReLU16
I0929 19:16:17.829689  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.829690  2630 net.cpp:137] Memory required for data: 437472400
I0929 19:16:17.829694  2630 layer_factory.hpp:77] Creating layer Convolution17
I0929 19:16:17.829700  2630 net.cpp:84] Creating Layer Convolution17
I0929 19:16:17.829704  2630 net.cpp:406] Convolution17 <- Convolution16
I0929 19:16:17.829707  2630 net.cpp:380] Convolution17 -> Convolution17
I0929 19:16:17.830639  2630 net.cpp:122] Setting up Convolution17
I0929 19:16:17.830648  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.830651  2630 net.cpp:137] Memory required for data: 442490000
I0929 19:16:17.830655  2630 layer_factory.hpp:77] Creating layer BatchNorm17
I0929 19:16:17.830660  2630 net.cpp:84] Creating Layer BatchNorm17
I0929 19:16:17.830663  2630 net.cpp:406] BatchNorm17 <- Convolution17
I0929 19:16:17.830667  2630 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0929 19:16:17.830868  2630 net.cpp:122] Setting up BatchNorm17
I0929 19:16:17.830876  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.830880  2630 net.cpp:137] Memory required for data: 447507600
I0929 19:16:17.830888  2630 layer_factory.hpp:77] Creating layer Scale17
I0929 19:16:17.830894  2630 net.cpp:84] Creating Layer Scale17
I0929 19:16:17.830899  2630 net.cpp:406] Scale17 <- Convolution17
I0929 19:16:17.830904  2630 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0929 19:16:17.830940  2630 layer_factory.hpp:77] Creating layer Scale17
I0929 19:16:17.831027  2630 net.cpp:122] Setting up Scale17
I0929 19:16:17.831032  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.831033  2630 net.cpp:137] Memory required for data: 452525200
I0929 19:16:17.831037  2630 layer_factory.hpp:77] Creating layer Eltwise8
I0929 19:16:17.831041  2630 net.cpp:84] Creating Layer Eltwise8
I0929 19:16:17.831043  2630 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0929 19:16:17.831046  2630 net.cpp:406] Eltwise8 <- Convolution17
I0929 19:16:17.831050  2630 net.cpp:380] Eltwise8 -> Eltwise8
I0929 19:16:17.831068  2630 net.cpp:122] Setting up Eltwise8
I0929 19:16:17.831071  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.831073  2630 net.cpp:137] Memory required for data: 457542800
I0929 19:16:17.831075  2630 layer_factory.hpp:77] Creating layer ReLU17
I0929 19:16:17.831079  2630 net.cpp:84] Creating Layer ReLU17
I0929 19:16:17.831081  2630 net.cpp:406] ReLU17 <- Eltwise8
I0929 19:16:17.831084  2630 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0929 19:16:17.831205  2630 net.cpp:122] Setting up ReLU17
I0929 19:16:17.831212  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.831213  2630 net.cpp:137] Memory required for data: 462560400
I0929 19:16:17.831215  2630 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0929 19:16:17.831219  2630 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0929 19:16:17.831221  2630 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0929 19:16:17.831225  2630 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0929 19:16:17.831230  2630 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0929 19:16:17.831264  2630 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0929 19:16:17.831269  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.831271  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.831274  2630 net.cpp:137] Memory required for data: 472595600
I0929 19:16:17.831275  2630 layer_factory.hpp:77] Creating layer Convolution18
I0929 19:16:17.831284  2630 net.cpp:84] Creating Layer Convolution18
I0929 19:16:17.831285  2630 net.cpp:406] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0929 19:16:17.831290  2630 net.cpp:380] Convolution18 -> Convolution18
I0929 19:16:17.832228  2630 net.cpp:122] Setting up Convolution18
I0929 19:16:17.832237  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.832239  2630 net.cpp:137] Memory required for data: 477613200
I0929 19:16:17.832244  2630 layer_factory.hpp:77] Creating layer BatchNorm18
I0929 19:16:17.832249  2630 net.cpp:84] Creating Layer BatchNorm18
I0929 19:16:17.832252  2630 net.cpp:406] BatchNorm18 <- Convolution18
I0929 19:16:17.832257  2630 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0929 19:16:17.832396  2630 net.cpp:122] Setting up BatchNorm18
I0929 19:16:17.832401  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.832403  2630 net.cpp:137] Memory required for data: 482630800
I0929 19:16:17.832408  2630 layer_factory.hpp:77] Creating layer Scale18
I0929 19:16:17.832413  2630 net.cpp:84] Creating Layer Scale18
I0929 19:16:17.832415  2630 net.cpp:406] Scale18 <- Convolution18
I0929 19:16:17.832418  2630 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0929 19:16:17.832446  2630 layer_factory.hpp:77] Creating layer Scale18
I0929 19:16:17.832559  2630 net.cpp:122] Setting up Scale18
I0929 19:16:17.832567  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.832569  2630 net.cpp:137] Memory required for data: 487648400
I0929 19:16:17.832583  2630 layer_factory.hpp:77] Creating layer ReLU18
I0929 19:16:17.832588  2630 net.cpp:84] Creating Layer ReLU18
I0929 19:16:17.832590  2630 net.cpp:406] ReLU18 <- Convolution18
I0929 19:16:17.832594  2630 net.cpp:367] ReLU18 -> Convolution18 (in-place)
I0929 19:16:17.832712  2630 net.cpp:122] Setting up ReLU18
I0929 19:16:17.832718  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.832720  2630 net.cpp:137] Memory required for data: 492666000
I0929 19:16:17.832723  2630 layer_factory.hpp:77] Creating layer Convolution19
I0929 19:16:17.832731  2630 net.cpp:84] Creating Layer Convolution19
I0929 19:16:17.832733  2630 net.cpp:406] Convolution19 <- Convolution18
I0929 19:16:17.832738  2630 net.cpp:380] Convolution19 -> Convolution19
I0929 19:16:17.833932  2630 net.cpp:122] Setting up Convolution19
I0929 19:16:17.833943  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.833948  2630 net.cpp:137] Memory required for data: 497683600
I0929 19:16:17.833956  2630 layer_factory.hpp:77] Creating layer BatchNorm19
I0929 19:16:17.833966  2630 net.cpp:84] Creating Layer BatchNorm19
I0929 19:16:17.833971  2630 net.cpp:406] BatchNorm19 <- Convolution19
I0929 19:16:17.833978  2630 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0929 19:16:17.834125  2630 net.cpp:122] Setting up BatchNorm19
I0929 19:16:17.834131  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.834136  2630 net.cpp:137] Memory required for data: 502701200
I0929 19:16:17.834156  2630 layer_factory.hpp:77] Creating layer Scale19
I0929 19:16:17.834163  2630 net.cpp:84] Creating Layer Scale19
I0929 19:16:17.834168  2630 net.cpp:406] Scale19 <- Convolution19
I0929 19:16:17.834175  2630 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0929 19:16:17.834211  2630 layer_factory.hpp:77] Creating layer Scale19
I0929 19:16:17.834311  2630 net.cpp:122] Setting up Scale19
I0929 19:16:17.834318  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.834323  2630 net.cpp:137] Memory required for data: 507718800
I0929 19:16:17.834331  2630 layer_factory.hpp:77] Creating layer Eltwise9
I0929 19:16:17.834338  2630 net.cpp:84] Creating Layer Eltwise9
I0929 19:16:17.834350  2630 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0929 19:16:17.834357  2630 net.cpp:406] Eltwise9 <- Convolution19
I0929 19:16:17.834364  2630 net.cpp:380] Eltwise9 -> Eltwise9
I0929 19:16:17.834386  2630 net.cpp:122] Setting up Eltwise9
I0929 19:16:17.834403  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.834408  2630 net.cpp:137] Memory required for data: 512736400
I0929 19:16:17.834424  2630 layer_factory.hpp:77] Creating layer ReLU19
I0929 19:16:17.834431  2630 net.cpp:84] Creating Layer ReLU19
I0929 19:16:17.834436  2630 net.cpp:406] ReLU19 <- Eltwise9
I0929 19:16:17.834442  2630 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0929 19:16:17.834578  2630 net.cpp:122] Setting up ReLU19
I0929 19:16:17.834586  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.834591  2630 net.cpp:137] Memory required for data: 517754000
I0929 19:16:17.834595  2630 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0929 19:16:17.834604  2630 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0929 19:16:17.834609  2630 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0929 19:16:17.834615  2630 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0929 19:16:17.834625  2630 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0929 19:16:17.834657  2630 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0929 19:16:17.834664  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.834669  2630 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 19:16:17.834671  2630 net.cpp:137] Memory required for data: 527789200
I0929 19:16:17.834674  2630 layer_factory.hpp:77] Creating layer Convolution20
I0929 19:16:17.834681  2630 net.cpp:84] Creating Layer Convolution20
I0929 19:16:17.834692  2630 net.cpp:406] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0929 19:16:17.834697  2630 net.cpp:380] Convolution20 -> Convolution20
I0929 19:16:17.835942  2630 net.cpp:122] Setting up Convolution20
I0929 19:16:17.835950  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.835953  2630 net.cpp:137] Memory required for data: 530298000
I0929 19:16:17.835958  2630 layer_factory.hpp:77] Creating layer BatchNorm20
I0929 19:16:17.835963  2630 net.cpp:84] Creating Layer BatchNorm20
I0929 19:16:17.835966  2630 net.cpp:406] BatchNorm20 <- Convolution20
I0929 19:16:17.835970  2630 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0929 19:16:17.836113  2630 net.cpp:122] Setting up BatchNorm20
I0929 19:16:17.836118  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.836120  2630 net.cpp:137] Memory required for data: 532806800
I0929 19:16:17.836125  2630 layer_factory.hpp:77] Creating layer Scale20
I0929 19:16:17.836129  2630 net.cpp:84] Creating Layer Scale20
I0929 19:16:17.836133  2630 net.cpp:406] Scale20 <- Convolution20
I0929 19:16:17.836135  2630 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0929 19:16:17.836161  2630 layer_factory.hpp:77] Creating layer Scale20
I0929 19:16:17.836238  2630 net.cpp:122] Setting up Scale20
I0929 19:16:17.836243  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.836246  2630 net.cpp:137] Memory required for data: 535315600
I0929 19:16:17.836249  2630 layer_factory.hpp:77] Creating layer Convolution21
I0929 19:16:17.836256  2630 net.cpp:84] Creating Layer Convolution21
I0929 19:16:17.836258  2630 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_1
I0929 19:16:17.836262  2630 net.cpp:380] Convolution21 -> Convolution21
I0929 19:16:17.838028  2630 net.cpp:122] Setting up Convolution21
I0929 19:16:17.838037  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.838040  2630 net.cpp:137] Memory required for data: 537824400
I0929 19:16:17.838045  2630 layer_factory.hpp:77] Creating layer BatchNorm21
I0929 19:16:17.838049  2630 net.cpp:84] Creating Layer BatchNorm21
I0929 19:16:17.838052  2630 net.cpp:406] BatchNorm21 <- Convolution21
I0929 19:16:17.838057  2630 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0929 19:16:17.838196  2630 net.cpp:122] Setting up BatchNorm21
I0929 19:16:17.838208  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.838210  2630 net.cpp:137] Memory required for data: 540333200
I0929 19:16:17.838215  2630 layer_factory.hpp:77] Creating layer Scale21
I0929 19:16:17.838220  2630 net.cpp:84] Creating Layer Scale21
I0929 19:16:17.838222  2630 net.cpp:406] Scale21 <- Convolution21
I0929 19:16:17.838225  2630 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0929 19:16:17.838255  2630 layer_factory.hpp:77] Creating layer Scale21
I0929 19:16:17.838335  2630 net.cpp:122] Setting up Scale21
I0929 19:16:17.838338  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.838340  2630 net.cpp:137] Memory required for data: 542842000
I0929 19:16:17.838345  2630 layer_factory.hpp:77] Creating layer ReLU20
I0929 19:16:17.838348  2630 net.cpp:84] Creating Layer ReLU20
I0929 19:16:17.838351  2630 net.cpp:406] ReLU20 <- Convolution21
I0929 19:16:17.838353  2630 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I0929 19:16:17.838482  2630 net.cpp:122] Setting up ReLU20
I0929 19:16:17.838488  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.838490  2630 net.cpp:137] Memory required for data: 545350800
I0929 19:16:17.838493  2630 layer_factory.hpp:77] Creating layer Convolution22
I0929 19:16:17.838500  2630 net.cpp:84] Creating Layer Convolution22
I0929 19:16:17.838502  2630 net.cpp:406] Convolution22 <- Convolution21
I0929 19:16:17.838507  2630 net.cpp:380] Convolution22 -> Convolution22
I0929 19:16:17.839553  2630 net.cpp:122] Setting up Convolution22
I0929 19:16:17.839561  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.839565  2630 net.cpp:137] Memory required for data: 547859600
I0929 19:16:17.839568  2630 layer_factory.hpp:77] Creating layer BatchNorm22
I0929 19:16:17.839573  2630 net.cpp:84] Creating Layer BatchNorm22
I0929 19:16:17.839576  2630 net.cpp:406] BatchNorm22 <- Convolution22
I0929 19:16:17.839581  2630 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0929 19:16:17.839712  2630 net.cpp:122] Setting up BatchNorm22
I0929 19:16:17.839716  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.839718  2630 net.cpp:137] Memory required for data: 550368400
I0929 19:16:17.839723  2630 layer_factory.hpp:77] Creating layer Scale22
I0929 19:16:17.839727  2630 net.cpp:84] Creating Layer Scale22
I0929 19:16:17.839730  2630 net.cpp:406] Scale22 <- Convolution22
I0929 19:16:17.839733  2630 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0929 19:16:17.839757  2630 layer_factory.hpp:77] Creating layer Scale22
I0929 19:16:17.839833  2630 net.cpp:122] Setting up Scale22
I0929 19:16:17.839838  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.839839  2630 net.cpp:137] Memory required for data: 552877200
I0929 19:16:17.839843  2630 layer_factory.hpp:77] Creating layer Eltwise10
I0929 19:16:17.839848  2630 net.cpp:84] Creating Layer Eltwise10
I0929 19:16:17.839849  2630 net.cpp:406] Eltwise10 <- Convolution20
I0929 19:16:17.839853  2630 net.cpp:406] Eltwise10 <- Convolution22
I0929 19:16:17.839856  2630 net.cpp:380] Eltwise10 -> Eltwise10
I0929 19:16:17.839871  2630 net.cpp:122] Setting up Eltwise10
I0929 19:16:17.839875  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.839877  2630 net.cpp:137] Memory required for data: 555386000
I0929 19:16:17.839879  2630 layer_factory.hpp:77] Creating layer ReLU21
I0929 19:16:17.839882  2630 net.cpp:84] Creating Layer ReLU21
I0929 19:16:17.839884  2630 net.cpp:406] ReLU21 <- Eltwise10
I0929 19:16:17.839887  2630 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I0929 19:16:17.840317  2630 net.cpp:122] Setting up ReLU21
I0929 19:16:17.840324  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.840327  2630 net.cpp:137] Memory required for data: 557894800
I0929 19:16:17.840329  2630 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0929 19:16:17.840333  2630 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I0929 19:16:17.840337  2630 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I0929 19:16:17.840339  2630 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0929 19:16:17.840351  2630 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0929 19:16:17.840379  2630 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I0929 19:16:17.840384  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.840386  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.840389  2630 net.cpp:137] Memory required for data: 562912400
I0929 19:16:17.840391  2630 layer_factory.hpp:77] Creating layer Convolution23
I0929 19:16:17.840397  2630 net.cpp:84] Creating Layer Convolution23
I0929 19:16:17.840400  2630 net.cpp:406] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0929 19:16:17.840404  2630 net.cpp:380] Convolution23 -> Convolution23
I0929 19:16:17.841441  2630 net.cpp:122] Setting up Convolution23
I0929 19:16:17.841449  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.841452  2630 net.cpp:137] Memory required for data: 565421200
I0929 19:16:17.841456  2630 layer_factory.hpp:77] Creating layer BatchNorm23
I0929 19:16:17.841461  2630 net.cpp:84] Creating Layer BatchNorm23
I0929 19:16:17.841464  2630 net.cpp:406] BatchNorm23 <- Convolution23
I0929 19:16:17.841467  2630 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0929 19:16:17.841603  2630 net.cpp:122] Setting up BatchNorm23
I0929 19:16:17.841609  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.841611  2630 net.cpp:137] Memory required for data: 567930000
I0929 19:16:17.841615  2630 layer_factory.hpp:77] Creating layer Scale23
I0929 19:16:17.841619  2630 net.cpp:84] Creating Layer Scale23
I0929 19:16:17.841622  2630 net.cpp:406] Scale23 <- Convolution23
I0929 19:16:17.841626  2630 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0929 19:16:17.841651  2630 layer_factory.hpp:77] Creating layer Scale23
I0929 19:16:17.841727  2630 net.cpp:122] Setting up Scale23
I0929 19:16:17.841732  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.841733  2630 net.cpp:137] Memory required for data: 570438800
I0929 19:16:17.841737  2630 layer_factory.hpp:77] Creating layer ReLU22
I0929 19:16:17.841740  2630 net.cpp:84] Creating Layer ReLU22
I0929 19:16:17.841742  2630 net.cpp:406] ReLU22 <- Convolution23
I0929 19:16:17.841747  2630 net.cpp:367] ReLU22 -> Convolution23 (in-place)
I0929 19:16:17.842170  2630 net.cpp:122] Setting up ReLU22
I0929 19:16:17.842177  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.842180  2630 net.cpp:137] Memory required for data: 572947600
I0929 19:16:17.842182  2630 layer_factory.hpp:77] Creating layer Convolution24
I0929 19:16:17.842190  2630 net.cpp:84] Creating Layer Convolution24
I0929 19:16:17.842191  2630 net.cpp:406] Convolution24 <- Convolution23
I0929 19:16:17.842196  2630 net.cpp:380] Convolution24 -> Convolution24
I0929 19:16:17.843235  2630 net.cpp:122] Setting up Convolution24
I0929 19:16:17.843243  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.843245  2630 net.cpp:137] Memory required for data: 575456400
I0929 19:16:17.843250  2630 layer_factory.hpp:77] Creating layer BatchNorm24
I0929 19:16:17.843255  2630 net.cpp:84] Creating Layer BatchNorm24
I0929 19:16:17.843258  2630 net.cpp:406] BatchNorm24 <- Convolution24
I0929 19:16:17.843261  2630 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0929 19:16:17.843396  2630 net.cpp:122] Setting up BatchNorm24
I0929 19:16:17.843400  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.843403  2630 net.cpp:137] Memory required for data: 577965200
I0929 19:16:17.843407  2630 layer_factory.hpp:77] Creating layer Scale24
I0929 19:16:17.843411  2630 net.cpp:84] Creating Layer Scale24
I0929 19:16:17.843413  2630 net.cpp:406] Scale24 <- Convolution24
I0929 19:16:17.843416  2630 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0929 19:16:17.843443  2630 layer_factory.hpp:77] Creating layer Scale24
I0929 19:16:17.843518  2630 net.cpp:122] Setting up Scale24
I0929 19:16:17.843523  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.843524  2630 net.cpp:137] Memory required for data: 580474000
I0929 19:16:17.843534  2630 layer_factory.hpp:77] Creating layer Eltwise11
I0929 19:16:17.843539  2630 net.cpp:84] Creating Layer Eltwise11
I0929 19:16:17.843541  2630 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0929 19:16:17.843544  2630 net.cpp:406] Eltwise11 <- Convolution24
I0929 19:16:17.843547  2630 net.cpp:380] Eltwise11 -> Eltwise11
I0929 19:16:17.843564  2630 net.cpp:122] Setting up Eltwise11
I0929 19:16:17.843569  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.843570  2630 net.cpp:137] Memory required for data: 582982800
I0929 19:16:17.843572  2630 layer_factory.hpp:77] Creating layer ReLU23
I0929 19:16:17.843575  2630 net.cpp:84] Creating Layer ReLU23
I0929 19:16:17.843577  2630 net.cpp:406] ReLU23 <- Eltwise11
I0929 19:16:17.843581  2630 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0929 19:16:17.843696  2630 net.cpp:122] Setting up ReLU23
I0929 19:16:17.843703  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.843704  2630 net.cpp:137] Memory required for data: 585491600
I0929 19:16:17.843706  2630 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0929 19:16:17.843710  2630 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0929 19:16:17.843713  2630 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0929 19:16:17.843716  2630 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0929 19:16:17.843720  2630 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0929 19:16:17.843747  2630 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0929 19:16:17.843751  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.843753  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.843755  2630 net.cpp:137] Memory required for data: 590509200
I0929 19:16:17.843757  2630 layer_factory.hpp:77] Creating layer Convolution25
I0929 19:16:17.843765  2630 net.cpp:84] Creating Layer Convolution25
I0929 19:16:17.843766  2630 net.cpp:406] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0929 19:16:17.843771  2630 net.cpp:380] Convolution25 -> Convolution25
I0929 19:16:17.844799  2630 net.cpp:122] Setting up Convolution25
I0929 19:16:17.844806  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.844808  2630 net.cpp:137] Memory required for data: 593018000
I0929 19:16:17.844813  2630 layer_factory.hpp:77] Creating layer BatchNorm25
I0929 19:16:17.844817  2630 net.cpp:84] Creating Layer BatchNorm25
I0929 19:16:17.844820  2630 net.cpp:406] BatchNorm25 <- Convolution25
I0929 19:16:17.844825  2630 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0929 19:16:17.844962  2630 net.cpp:122] Setting up BatchNorm25
I0929 19:16:17.844967  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.844969  2630 net.cpp:137] Memory required for data: 595526800
I0929 19:16:17.844974  2630 layer_factory.hpp:77] Creating layer Scale25
I0929 19:16:17.844979  2630 net.cpp:84] Creating Layer Scale25
I0929 19:16:17.844980  2630 net.cpp:406] Scale25 <- Convolution25
I0929 19:16:17.844985  2630 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0929 19:16:17.845010  2630 layer_factory.hpp:77] Creating layer Scale25
I0929 19:16:17.845086  2630 net.cpp:122] Setting up Scale25
I0929 19:16:17.845090  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.845093  2630 net.cpp:137] Memory required for data: 598035600
I0929 19:16:17.845096  2630 layer_factory.hpp:77] Creating layer ReLU24
I0929 19:16:17.845099  2630 net.cpp:84] Creating Layer ReLU24
I0929 19:16:17.845101  2630 net.cpp:406] ReLU24 <- Convolution25
I0929 19:16:17.845105  2630 net.cpp:367] ReLU24 -> Convolution25 (in-place)
I0929 19:16:17.845218  2630 net.cpp:122] Setting up ReLU24
I0929 19:16:17.845224  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.845227  2630 net.cpp:137] Memory required for data: 600544400
I0929 19:16:17.845229  2630 layer_factory.hpp:77] Creating layer Convolution26
I0929 19:16:17.845237  2630 net.cpp:84] Creating Layer Convolution26
I0929 19:16:17.845239  2630 net.cpp:406] Convolution26 <- Convolution25
I0929 19:16:17.845249  2630 net.cpp:380] Convolution26 -> Convolution26
I0929 19:16:17.846287  2630 net.cpp:122] Setting up Convolution26
I0929 19:16:17.846294  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.846297  2630 net.cpp:137] Memory required for data: 603053200
I0929 19:16:17.846302  2630 layer_factory.hpp:77] Creating layer BatchNorm26
I0929 19:16:17.846307  2630 net.cpp:84] Creating Layer BatchNorm26
I0929 19:16:17.846309  2630 net.cpp:406] BatchNorm26 <- Convolution26
I0929 19:16:17.846313  2630 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0929 19:16:17.846448  2630 net.cpp:122] Setting up BatchNorm26
I0929 19:16:17.846452  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.846454  2630 net.cpp:137] Memory required for data: 605562000
I0929 19:16:17.846459  2630 layer_factory.hpp:77] Creating layer Scale26
I0929 19:16:17.846463  2630 net.cpp:84] Creating Layer Scale26
I0929 19:16:17.846467  2630 net.cpp:406] Scale26 <- Convolution26
I0929 19:16:17.846469  2630 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0929 19:16:17.846495  2630 layer_factory.hpp:77] Creating layer Scale26
I0929 19:16:17.846580  2630 net.cpp:122] Setting up Scale26
I0929 19:16:17.846585  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.846587  2630 net.cpp:137] Memory required for data: 608070800
I0929 19:16:17.846591  2630 layer_factory.hpp:77] Creating layer Eltwise12
I0929 19:16:17.846596  2630 net.cpp:84] Creating Layer Eltwise12
I0929 19:16:17.846598  2630 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0929 19:16:17.846601  2630 net.cpp:406] Eltwise12 <- Convolution26
I0929 19:16:17.846604  2630 net.cpp:380] Eltwise12 -> Eltwise12
I0929 19:16:17.846621  2630 net.cpp:122] Setting up Eltwise12
I0929 19:16:17.846623  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.846626  2630 net.cpp:137] Memory required for data: 610579600
I0929 19:16:17.846627  2630 layer_factory.hpp:77] Creating layer ReLU25
I0929 19:16:17.846632  2630 net.cpp:84] Creating Layer ReLU25
I0929 19:16:17.846633  2630 net.cpp:406] ReLU25 <- Eltwise12
I0929 19:16:17.846637  2630 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I0929 19:16:17.846752  2630 net.cpp:122] Setting up ReLU25
I0929 19:16:17.846758  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.846760  2630 net.cpp:137] Memory required for data: 613088400
I0929 19:16:17.846763  2630 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0929 19:16:17.846776  2630 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I0929 19:16:17.846777  2630 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I0929 19:16:17.846781  2630 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0929 19:16:17.846791  2630 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0929 19:16:17.846818  2630 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I0929 19:16:17.846823  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.846827  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.846828  2630 net.cpp:137] Memory required for data: 618106000
I0929 19:16:17.846830  2630 layer_factory.hpp:77] Creating layer Convolution27
I0929 19:16:17.846837  2630 net.cpp:84] Creating Layer Convolution27
I0929 19:16:17.846839  2630 net.cpp:406] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0929 19:16:17.846843  2630 net.cpp:380] Convolution27 -> Convolution27
I0929 19:16:17.847867  2630 net.cpp:122] Setting up Convolution27
I0929 19:16:17.847877  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.847878  2630 net.cpp:137] Memory required for data: 620614800
I0929 19:16:17.847882  2630 layer_factory.hpp:77] Creating layer BatchNorm27
I0929 19:16:17.847887  2630 net.cpp:84] Creating Layer BatchNorm27
I0929 19:16:17.847890  2630 net.cpp:406] BatchNorm27 <- Convolution27
I0929 19:16:17.847895  2630 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0929 19:16:17.848029  2630 net.cpp:122] Setting up BatchNorm27
I0929 19:16:17.848034  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.848042  2630 net.cpp:137] Memory required for data: 623123600
I0929 19:16:17.848047  2630 layer_factory.hpp:77] Creating layer Scale27
I0929 19:16:17.848052  2630 net.cpp:84] Creating Layer Scale27
I0929 19:16:17.848053  2630 net.cpp:406] Scale27 <- Convolution27
I0929 19:16:17.848057  2630 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0929 19:16:17.848084  2630 layer_factory.hpp:77] Creating layer Scale27
I0929 19:16:17.848161  2630 net.cpp:122] Setting up Scale27
I0929 19:16:17.848165  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.848167  2630 net.cpp:137] Memory required for data: 625632400
I0929 19:16:17.848171  2630 layer_factory.hpp:77] Creating layer ReLU26
I0929 19:16:17.848176  2630 net.cpp:84] Creating Layer ReLU26
I0929 19:16:17.848177  2630 net.cpp:406] ReLU26 <- Convolution27
I0929 19:16:17.848181  2630 net.cpp:367] ReLU26 -> Convolution27 (in-place)
I0929 19:16:17.848297  2630 net.cpp:122] Setting up ReLU26
I0929 19:16:17.848304  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.848305  2630 net.cpp:137] Memory required for data: 628141200
I0929 19:16:17.848307  2630 layer_factory.hpp:77] Creating layer Convolution28
I0929 19:16:17.848315  2630 net.cpp:84] Creating Layer Convolution28
I0929 19:16:17.848316  2630 net.cpp:406] Convolution28 <- Convolution27
I0929 19:16:17.848321  2630 net.cpp:380] Convolution28 -> Convolution28
I0929 19:16:17.849352  2630 net.cpp:122] Setting up Convolution28
I0929 19:16:17.849361  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.849364  2630 net.cpp:137] Memory required for data: 630650000
I0929 19:16:17.849369  2630 layer_factory.hpp:77] Creating layer BatchNorm28
I0929 19:16:17.849372  2630 net.cpp:84] Creating Layer BatchNorm28
I0929 19:16:17.849375  2630 net.cpp:406] BatchNorm28 <- Convolution28
I0929 19:16:17.849380  2630 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0929 19:16:17.849514  2630 net.cpp:122] Setting up BatchNorm28
I0929 19:16:17.849519  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.849521  2630 net.cpp:137] Memory required for data: 633158800
I0929 19:16:17.849525  2630 layer_factory.hpp:77] Creating layer Scale28
I0929 19:16:17.849529  2630 net.cpp:84] Creating Layer Scale28
I0929 19:16:17.849531  2630 net.cpp:406] Scale28 <- Convolution28
I0929 19:16:17.849535  2630 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0929 19:16:17.849560  2630 layer_factory.hpp:77] Creating layer Scale28
I0929 19:16:17.849637  2630 net.cpp:122] Setting up Scale28
I0929 19:16:17.849640  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.849643  2630 net.cpp:137] Memory required for data: 635667600
I0929 19:16:17.849647  2630 layer_factory.hpp:77] Creating layer Eltwise13
I0929 19:16:17.849650  2630 net.cpp:84] Creating Layer Eltwise13
I0929 19:16:17.849653  2630 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0929 19:16:17.849655  2630 net.cpp:406] Eltwise13 <- Convolution28
I0929 19:16:17.849659  2630 net.cpp:380] Eltwise13 -> Eltwise13
I0929 19:16:17.849674  2630 net.cpp:122] Setting up Eltwise13
I0929 19:16:17.849678  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.849680  2630 net.cpp:137] Memory required for data: 638176400
I0929 19:16:17.849683  2630 layer_factory.hpp:77] Creating layer ReLU27
I0929 19:16:17.849685  2630 net.cpp:84] Creating Layer ReLU27
I0929 19:16:17.849687  2630 net.cpp:406] ReLU27 <- Eltwise13
I0929 19:16:17.849690  2630 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I0929 19:16:17.850117  2630 net.cpp:122] Setting up ReLU27
I0929 19:16:17.850126  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.850128  2630 net.cpp:137] Memory required for data: 640685200
I0929 19:16:17.850131  2630 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0929 19:16:17.850134  2630 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I0929 19:16:17.850137  2630 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I0929 19:16:17.850141  2630 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0929 19:16:17.850152  2630 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0929 19:16:17.850181  2630 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I0929 19:16:17.850185  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.850188  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.850190  2630 net.cpp:137] Memory required for data: 645702800
I0929 19:16:17.850193  2630 layer_factory.hpp:77] Creating layer Convolution29
I0929 19:16:17.850199  2630 net.cpp:84] Creating Layer Convolution29
I0929 19:16:17.850203  2630 net.cpp:406] Convolution29 <- Eltwise13_ReLU27_0_split_0
I0929 19:16:17.850208  2630 net.cpp:380] Convolution29 -> Convolution29
I0929 19:16:17.850929  2630 net.cpp:122] Setting up Convolution29
I0929 19:16:17.850935  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.850939  2630 net.cpp:137] Memory required for data: 648211600
I0929 19:16:17.850942  2630 layer_factory.hpp:77] Creating layer BatchNorm29
I0929 19:16:17.850947  2630 net.cpp:84] Creating Layer BatchNorm29
I0929 19:16:17.850950  2630 net.cpp:406] BatchNorm29 <- Convolution29
I0929 19:16:17.850955  2630 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0929 19:16:17.851089  2630 net.cpp:122] Setting up BatchNorm29
I0929 19:16:17.851094  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.851095  2630 net.cpp:137] Memory required for data: 650720400
I0929 19:16:17.851100  2630 layer_factory.hpp:77] Creating layer Scale29
I0929 19:16:17.851104  2630 net.cpp:84] Creating Layer Scale29
I0929 19:16:17.851107  2630 net.cpp:406] Scale29 <- Convolution29
I0929 19:16:17.851110  2630 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0929 19:16:17.851136  2630 layer_factory.hpp:77] Creating layer Scale29
I0929 19:16:17.851214  2630 net.cpp:122] Setting up Scale29
I0929 19:16:17.851218  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.851220  2630 net.cpp:137] Memory required for data: 653229200
I0929 19:16:17.851224  2630 layer_factory.hpp:77] Creating layer ReLU28
I0929 19:16:17.851228  2630 net.cpp:84] Creating Layer ReLU28
I0929 19:16:17.851230  2630 net.cpp:406] ReLU28 <- Convolution29
I0929 19:16:17.851233  2630 net.cpp:367] ReLU28 -> Convolution29 (in-place)
I0929 19:16:17.851658  2630 net.cpp:122] Setting up ReLU28
I0929 19:16:17.851666  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.851670  2630 net.cpp:137] Memory required for data: 655738000
I0929 19:16:17.851671  2630 layer_factory.hpp:77] Creating layer Convolution30
I0929 19:16:17.851678  2630 net.cpp:84] Creating Layer Convolution30
I0929 19:16:17.851681  2630 net.cpp:406] Convolution30 <- Convolution29
I0929 19:16:17.851686  2630 net.cpp:380] Convolution30 -> Convolution30
I0929 19:16:17.852748  2630 net.cpp:122] Setting up Convolution30
I0929 19:16:17.852757  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.852759  2630 net.cpp:137] Memory required for data: 658246800
I0929 19:16:17.852764  2630 layer_factory.hpp:77] Creating layer BatchNorm30
I0929 19:16:17.852768  2630 net.cpp:84] Creating Layer BatchNorm30
I0929 19:16:17.852771  2630 net.cpp:406] BatchNorm30 <- Convolution30
I0929 19:16:17.852776  2630 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0929 19:16:17.852911  2630 net.cpp:122] Setting up BatchNorm30
I0929 19:16:17.852916  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.852918  2630 net.cpp:137] Memory required for data: 660755600
I0929 19:16:17.852922  2630 layer_factory.hpp:77] Creating layer Scale30
I0929 19:16:17.852926  2630 net.cpp:84] Creating Layer Scale30
I0929 19:16:17.852928  2630 net.cpp:406] Scale30 <- Convolution30
I0929 19:16:17.852932  2630 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0929 19:16:17.852958  2630 layer_factory.hpp:77] Creating layer Scale30
I0929 19:16:17.853035  2630 net.cpp:122] Setting up Scale30
I0929 19:16:17.853039  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.853041  2630 net.cpp:137] Memory required for data: 663264400
I0929 19:16:17.853051  2630 layer_factory.hpp:77] Creating layer Eltwise14
I0929 19:16:17.853055  2630 net.cpp:84] Creating Layer Eltwise14
I0929 19:16:17.853058  2630 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0929 19:16:17.853061  2630 net.cpp:406] Eltwise14 <- Convolution30
I0929 19:16:17.853066  2630 net.cpp:380] Eltwise14 -> Eltwise14
I0929 19:16:17.853083  2630 net.cpp:122] Setting up Eltwise14
I0929 19:16:17.853088  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.853091  2630 net.cpp:137] Memory required for data: 665773200
I0929 19:16:17.853092  2630 layer_factory.hpp:77] Creating layer ReLU29
I0929 19:16:17.853096  2630 net.cpp:84] Creating Layer ReLU29
I0929 19:16:17.853097  2630 net.cpp:406] ReLU29 <- Eltwise14
I0929 19:16:17.853101  2630 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I0929 19:16:17.853219  2630 net.cpp:122] Setting up ReLU29
I0929 19:16:17.853224  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.853226  2630 net.cpp:137] Memory required for data: 668282000
I0929 19:16:17.853229  2630 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0929 19:16:17.853232  2630 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I0929 19:16:17.853235  2630 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I0929 19:16:17.853238  2630 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0929 19:16:17.853242  2630 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0929 19:16:17.853271  2630 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I0929 19:16:17.853274  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.853276  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.853278  2630 net.cpp:137] Memory required for data: 673299600
I0929 19:16:17.853281  2630 layer_factory.hpp:77] Creating layer Convolution31
I0929 19:16:17.853287  2630 net.cpp:84] Creating Layer Convolution31
I0929 19:16:17.853289  2630 net.cpp:406] Convolution31 <- Eltwise14_ReLU29_0_split_0
I0929 19:16:17.853293  2630 net.cpp:380] Convolution31 -> Convolution31
I0929 19:16:17.854333  2630 net.cpp:122] Setting up Convolution31
I0929 19:16:17.854341  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.854344  2630 net.cpp:137] Memory required for data: 675808400
I0929 19:16:17.854348  2630 layer_factory.hpp:77] Creating layer BatchNorm31
I0929 19:16:17.854353  2630 net.cpp:84] Creating Layer BatchNorm31
I0929 19:16:17.854357  2630 net.cpp:406] BatchNorm31 <- Convolution31
I0929 19:16:17.854360  2630 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0929 19:16:17.854516  2630 net.cpp:122] Setting up BatchNorm31
I0929 19:16:17.854524  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.854526  2630 net.cpp:137] Memory required for data: 678317200
I0929 19:16:17.854532  2630 layer_factory.hpp:77] Creating layer Scale31
I0929 19:16:17.854537  2630 net.cpp:84] Creating Layer Scale31
I0929 19:16:17.854538  2630 net.cpp:406] Scale31 <- Convolution31
I0929 19:16:17.854542  2630 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0929 19:16:17.854568  2630 layer_factory.hpp:77] Creating layer Scale31
I0929 19:16:17.854645  2630 net.cpp:122] Setting up Scale31
I0929 19:16:17.854650  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.854651  2630 net.cpp:137] Memory required for data: 680826000
I0929 19:16:17.854655  2630 layer_factory.hpp:77] Creating layer ReLU30
I0929 19:16:17.854660  2630 net.cpp:84] Creating Layer ReLU30
I0929 19:16:17.854661  2630 net.cpp:406] ReLU30 <- Convolution31
I0929 19:16:17.854665  2630 net.cpp:367] ReLU30 -> Convolution31 (in-place)
I0929 19:16:17.854781  2630 net.cpp:122] Setting up ReLU30
I0929 19:16:17.854786  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.854789  2630 net.cpp:137] Memory required for data: 683334800
I0929 19:16:17.854791  2630 layer_factory.hpp:77] Creating layer Convolution32
I0929 19:16:17.854799  2630 net.cpp:84] Creating Layer Convolution32
I0929 19:16:17.854802  2630 net.cpp:406] Convolution32 <- Convolution31
I0929 19:16:17.854812  2630 net.cpp:380] Convolution32 -> Convolution32
I0929 19:16:17.855860  2630 net.cpp:122] Setting up Convolution32
I0929 19:16:17.855870  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.855871  2630 net.cpp:137] Memory required for data: 685843600
I0929 19:16:17.855875  2630 layer_factory.hpp:77] Creating layer BatchNorm32
I0929 19:16:17.855881  2630 net.cpp:84] Creating Layer BatchNorm32
I0929 19:16:17.855883  2630 net.cpp:406] BatchNorm32 <- Convolution32
I0929 19:16:17.855888  2630 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0929 19:16:17.856024  2630 net.cpp:122] Setting up BatchNorm32
I0929 19:16:17.856029  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.856031  2630 net.cpp:137] Memory required for data: 688352400
I0929 19:16:17.856035  2630 layer_factory.hpp:77] Creating layer Scale32
I0929 19:16:17.856040  2630 net.cpp:84] Creating Layer Scale32
I0929 19:16:17.856043  2630 net.cpp:406] Scale32 <- Convolution32
I0929 19:16:17.856046  2630 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0929 19:16:17.856072  2630 layer_factory.hpp:77] Creating layer Scale32
I0929 19:16:17.856150  2630 net.cpp:122] Setting up Scale32
I0929 19:16:17.856154  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.856156  2630 net.cpp:137] Memory required for data: 690861200
I0929 19:16:17.856160  2630 layer_factory.hpp:77] Creating layer Eltwise15
I0929 19:16:17.856164  2630 net.cpp:84] Creating Layer Eltwise15
I0929 19:16:17.856168  2630 net.cpp:406] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0929 19:16:17.856169  2630 net.cpp:406] Eltwise15 <- Convolution32
I0929 19:16:17.856173  2630 net.cpp:380] Eltwise15 -> Eltwise15
I0929 19:16:17.856189  2630 net.cpp:122] Setting up Eltwise15
I0929 19:16:17.856191  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.856194  2630 net.cpp:137] Memory required for data: 693370000
I0929 19:16:17.856195  2630 layer_factory.hpp:77] Creating layer ReLU31
I0929 19:16:17.856199  2630 net.cpp:84] Creating Layer ReLU31
I0929 19:16:17.856202  2630 net.cpp:406] ReLU31 <- Eltwise15
I0929 19:16:17.856204  2630 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I0929 19:16:17.856628  2630 net.cpp:122] Setting up ReLU31
I0929 19:16:17.856637  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.856638  2630 net.cpp:137] Memory required for data: 695878800
I0929 19:16:17.856642  2630 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0929 19:16:17.856644  2630 net.cpp:84] Creating Layer Eltwise15_ReLU31_0_split
I0929 19:16:17.856647  2630 net.cpp:406] Eltwise15_ReLU31_0_split <- Eltwise15
I0929 19:16:17.856650  2630 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0929 19:16:17.856657  2630 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0929 19:16:17.856685  2630 net.cpp:122] Setting up Eltwise15_ReLU31_0_split
I0929 19:16:17.856689  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.856691  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.856693  2630 net.cpp:137] Memory required for data: 700896400
I0929 19:16:17.856695  2630 layer_factory.hpp:77] Creating layer Convolution33
I0929 19:16:17.856703  2630 net.cpp:84] Creating Layer Convolution33
I0929 19:16:17.856706  2630 net.cpp:406] Convolution33 <- Eltwise15_ReLU31_0_split_0
I0929 19:16:17.856710  2630 net.cpp:380] Convolution33 -> Convolution33
I0929 19:16:17.858053  2630 net.cpp:122] Setting up Convolution33
I0929 19:16:17.858062  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.858064  2630 net.cpp:137] Memory required for data: 703405200
I0929 19:16:17.858068  2630 layer_factory.hpp:77] Creating layer BatchNorm33
I0929 19:16:17.858073  2630 net.cpp:84] Creating Layer BatchNorm33
I0929 19:16:17.858077  2630 net.cpp:406] BatchNorm33 <- Convolution33
I0929 19:16:17.858080  2630 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0929 19:16:17.858222  2630 net.cpp:122] Setting up BatchNorm33
I0929 19:16:17.858227  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.858235  2630 net.cpp:137] Memory required for data: 705914000
I0929 19:16:17.858240  2630 layer_factory.hpp:77] Creating layer Scale33
I0929 19:16:17.858244  2630 net.cpp:84] Creating Layer Scale33
I0929 19:16:17.858247  2630 net.cpp:406] Scale33 <- Convolution33
I0929 19:16:17.858250  2630 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0929 19:16:17.858278  2630 layer_factory.hpp:77] Creating layer Scale33
I0929 19:16:17.858358  2630 net.cpp:122] Setting up Scale33
I0929 19:16:17.858362  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.858364  2630 net.cpp:137] Memory required for data: 708422800
I0929 19:16:17.858368  2630 layer_factory.hpp:77] Creating layer ReLU32
I0929 19:16:17.858371  2630 net.cpp:84] Creating Layer ReLU32
I0929 19:16:17.858374  2630 net.cpp:406] ReLU32 <- Convolution33
I0929 19:16:17.858376  2630 net.cpp:367] ReLU32 -> Convolution33 (in-place)
I0929 19:16:17.858495  2630 net.cpp:122] Setting up ReLU32
I0929 19:16:17.858500  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.858502  2630 net.cpp:137] Memory required for data: 710931600
I0929 19:16:17.858505  2630 layer_factory.hpp:77] Creating layer Convolution34
I0929 19:16:17.858511  2630 net.cpp:84] Creating Layer Convolution34
I0929 19:16:17.858515  2630 net.cpp:406] Convolution34 <- Convolution33
I0929 19:16:17.858520  2630 net.cpp:380] Convolution34 -> Convolution34
I0929 19:16:17.859575  2630 net.cpp:122] Setting up Convolution34
I0929 19:16:17.859582  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.859586  2630 net.cpp:137] Memory required for data: 713440400
I0929 19:16:17.859589  2630 layer_factory.hpp:77] Creating layer BatchNorm34
I0929 19:16:17.859596  2630 net.cpp:84] Creating Layer BatchNorm34
I0929 19:16:17.859597  2630 net.cpp:406] BatchNorm34 <- Convolution34
I0929 19:16:17.859601  2630 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0929 19:16:17.859740  2630 net.cpp:122] Setting up BatchNorm34
I0929 19:16:17.859745  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.859746  2630 net.cpp:137] Memory required for data: 715949200
I0929 19:16:17.859751  2630 layer_factory.hpp:77] Creating layer Scale34
I0929 19:16:17.859755  2630 net.cpp:84] Creating Layer Scale34
I0929 19:16:17.859758  2630 net.cpp:406] Scale34 <- Convolution34
I0929 19:16:17.859761  2630 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0929 19:16:17.859788  2630 layer_factory.hpp:77] Creating layer Scale34
I0929 19:16:17.859866  2630 net.cpp:122] Setting up Scale34
I0929 19:16:17.859870  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.859872  2630 net.cpp:137] Memory required for data: 718458000
I0929 19:16:17.859876  2630 layer_factory.hpp:77] Creating layer Eltwise16
I0929 19:16:17.859880  2630 net.cpp:84] Creating Layer Eltwise16
I0929 19:16:17.859884  2630 net.cpp:406] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0929 19:16:17.859886  2630 net.cpp:406] Eltwise16 <- Convolution34
I0929 19:16:17.859889  2630 net.cpp:380] Eltwise16 -> Eltwise16
I0929 19:16:17.859905  2630 net.cpp:122] Setting up Eltwise16
I0929 19:16:17.859910  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.859911  2630 net.cpp:137] Memory required for data: 720966800
I0929 19:16:17.859913  2630 layer_factory.hpp:77] Creating layer ReLU33
I0929 19:16:17.859916  2630 net.cpp:84] Creating Layer ReLU33
I0929 19:16:17.859920  2630 net.cpp:406] ReLU33 <- Eltwise16
I0929 19:16:17.859922  2630 net.cpp:367] ReLU33 -> Eltwise16 (in-place)
I0929 19:16:17.860352  2630 net.cpp:122] Setting up ReLU33
I0929 19:16:17.860360  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.860363  2630 net.cpp:137] Memory required for data: 723475600
I0929 19:16:17.860364  2630 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0929 19:16:17.860368  2630 net.cpp:84] Creating Layer Eltwise16_ReLU33_0_split
I0929 19:16:17.860371  2630 net.cpp:406] Eltwise16_ReLU33_0_split <- Eltwise16
I0929 19:16:17.860375  2630 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0929 19:16:17.860386  2630 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0929 19:16:17.860415  2630 net.cpp:122] Setting up Eltwise16_ReLU33_0_split
I0929 19:16:17.860420  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.860424  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.860425  2630 net.cpp:137] Memory required for data: 728493200
I0929 19:16:17.860427  2630 layer_factory.hpp:77] Creating layer Convolution35
I0929 19:16:17.860435  2630 net.cpp:84] Creating Layer Convolution35
I0929 19:16:17.860438  2630 net.cpp:406] Convolution35 <- Eltwise16_ReLU33_0_split_0
I0929 19:16:17.860442  2630 net.cpp:380] Convolution35 -> Convolution35
I0929 19:16:17.861165  2630 net.cpp:122] Setting up Convolution35
I0929 19:16:17.861173  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.861176  2630 net.cpp:137] Memory required for data: 731002000
I0929 19:16:17.861179  2630 layer_factory.hpp:77] Creating layer BatchNorm35
I0929 19:16:17.861184  2630 net.cpp:84] Creating Layer BatchNorm35
I0929 19:16:17.861187  2630 net.cpp:406] BatchNorm35 <- Convolution35
I0929 19:16:17.861191  2630 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0929 19:16:17.861330  2630 net.cpp:122] Setting up BatchNorm35
I0929 19:16:17.861333  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.861335  2630 net.cpp:137] Memory required for data: 733510800
I0929 19:16:17.861340  2630 layer_factory.hpp:77] Creating layer Scale35
I0929 19:16:17.861344  2630 net.cpp:84] Creating Layer Scale35
I0929 19:16:17.861346  2630 net.cpp:406] Scale35 <- Convolution35
I0929 19:16:17.861349  2630 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0929 19:16:17.861376  2630 layer_factory.hpp:77] Creating layer Scale35
I0929 19:16:17.861455  2630 net.cpp:122] Setting up Scale35
I0929 19:16:17.861459  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.861461  2630 net.cpp:137] Memory required for data: 736019600
I0929 19:16:17.861465  2630 layer_factory.hpp:77] Creating layer ReLU34
I0929 19:16:17.861469  2630 net.cpp:84] Creating Layer ReLU34
I0929 19:16:17.861471  2630 net.cpp:406] ReLU34 <- Convolution35
I0929 19:16:17.861474  2630 net.cpp:367] ReLU34 -> Convolution35 (in-place)
I0929 19:16:17.861907  2630 net.cpp:122] Setting up ReLU34
I0929 19:16:17.861915  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.861917  2630 net.cpp:137] Memory required for data: 738528400
I0929 19:16:17.861920  2630 layer_factory.hpp:77] Creating layer Convolution36
I0929 19:16:17.861927  2630 net.cpp:84] Creating Layer Convolution36
I0929 19:16:17.861929  2630 net.cpp:406] Convolution36 <- Convolution35
I0929 19:16:17.861934  2630 net.cpp:380] Convolution36 -> Convolution36
I0929 19:16:17.862985  2630 net.cpp:122] Setting up Convolution36
I0929 19:16:17.862994  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.862996  2630 net.cpp:137] Memory required for data: 741037200
I0929 19:16:17.863001  2630 layer_factory.hpp:77] Creating layer BatchNorm36
I0929 19:16:17.863006  2630 net.cpp:84] Creating Layer BatchNorm36
I0929 19:16:17.863009  2630 net.cpp:406] BatchNorm36 <- Convolution36
I0929 19:16:17.863013  2630 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0929 19:16:17.863154  2630 net.cpp:122] Setting up BatchNorm36
I0929 19:16:17.863159  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.863162  2630 net.cpp:137] Memory required for data: 743546000
I0929 19:16:17.863167  2630 layer_factory.hpp:77] Creating layer Scale36
I0929 19:16:17.863170  2630 net.cpp:84] Creating Layer Scale36
I0929 19:16:17.863173  2630 net.cpp:406] Scale36 <- Convolution36
I0929 19:16:17.863176  2630 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0929 19:16:17.863203  2630 layer_factory.hpp:77] Creating layer Scale36
I0929 19:16:17.863281  2630 net.cpp:122] Setting up Scale36
I0929 19:16:17.863286  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.863287  2630 net.cpp:137] Memory required for data: 746054800
I0929 19:16:17.863291  2630 layer_factory.hpp:77] Creating layer Eltwise17
I0929 19:16:17.863302  2630 net.cpp:84] Creating Layer Eltwise17
I0929 19:16:17.863306  2630 net.cpp:406] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0929 19:16:17.863308  2630 net.cpp:406] Eltwise17 <- Convolution36
I0929 19:16:17.863312  2630 net.cpp:380] Eltwise17 -> Eltwise17
I0929 19:16:17.863342  2630 net.cpp:122] Setting up Eltwise17
I0929 19:16:17.863348  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.863349  2630 net.cpp:137] Memory required for data: 748563600
I0929 19:16:17.863361  2630 layer_factory.hpp:77] Creating layer ReLU35
I0929 19:16:17.863365  2630 net.cpp:84] Creating Layer ReLU35
I0929 19:16:17.863368  2630 net.cpp:406] ReLU35 <- Eltwise17
I0929 19:16:17.863381  2630 net.cpp:367] ReLU35 -> Eltwise17 (in-place)
I0929 19:16:17.863567  2630 net.cpp:122] Setting up ReLU35
I0929 19:16:17.863575  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.863577  2630 net.cpp:137] Memory required for data: 751072400
I0929 19:16:17.863579  2630 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0929 19:16:17.863584  2630 net.cpp:84] Creating Layer Eltwise17_ReLU35_0_split
I0929 19:16:17.863586  2630 net.cpp:406] Eltwise17_ReLU35_0_split <- Eltwise17
I0929 19:16:17.863590  2630 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0929 19:16:17.863595  2630 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0929 19:16:17.863625  2630 net.cpp:122] Setting up Eltwise17_ReLU35_0_split
I0929 19:16:17.863628  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.863631  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.863633  2630 net.cpp:137] Memory required for data: 756090000
I0929 19:16:17.863636  2630 layer_factory.hpp:77] Creating layer Convolution37
I0929 19:16:17.863642  2630 net.cpp:84] Creating Layer Convolution37
I0929 19:16:17.863646  2630 net.cpp:406] Convolution37 <- Eltwise17_ReLU35_0_split_0
I0929 19:16:17.863651  2630 net.cpp:380] Convolution37 -> Convolution37
I0929 19:16:17.864768  2630 net.cpp:122] Setting up Convolution37
I0929 19:16:17.864778  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.864779  2630 net.cpp:137] Memory required for data: 758598800
I0929 19:16:17.864786  2630 layer_factory.hpp:77] Creating layer BatchNorm37
I0929 19:16:17.864791  2630 net.cpp:84] Creating Layer BatchNorm37
I0929 19:16:17.864794  2630 net.cpp:406] BatchNorm37 <- Convolution37
I0929 19:16:17.864799  2630 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0929 19:16:17.864946  2630 net.cpp:122] Setting up BatchNorm37
I0929 19:16:17.864951  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.864953  2630 net.cpp:137] Memory required for data: 761107600
I0929 19:16:17.864979  2630 layer_factory.hpp:77] Creating layer Scale37
I0929 19:16:17.864984  2630 net.cpp:84] Creating Layer Scale37
I0929 19:16:17.864987  2630 net.cpp:406] Scale37 <- Convolution37
I0929 19:16:17.864991  2630 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0929 19:16:17.865021  2630 layer_factory.hpp:77] Creating layer Scale37
I0929 19:16:17.865111  2630 net.cpp:122] Setting up Scale37
I0929 19:16:17.865119  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.865123  2630 net.cpp:137] Memory required for data: 763616400
I0929 19:16:17.865129  2630 layer_factory.hpp:77] Creating layer ReLU36
I0929 19:16:17.865136  2630 net.cpp:84] Creating Layer ReLU36
I0929 19:16:17.865140  2630 net.cpp:406] ReLU36 <- Convolution37
I0929 19:16:17.865147  2630 net.cpp:367] ReLU36 -> Convolution37 (in-place)
I0929 19:16:17.865289  2630 net.cpp:122] Setting up ReLU36
I0929 19:16:17.865296  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.865299  2630 net.cpp:137] Memory required for data: 766125200
I0929 19:16:17.865301  2630 layer_factory.hpp:77] Creating layer Convolution38
I0929 19:16:17.865309  2630 net.cpp:84] Creating Layer Convolution38
I0929 19:16:17.865311  2630 net.cpp:406] Convolution38 <- Convolution37
I0929 19:16:17.865316  2630 net.cpp:380] Convolution38 -> Convolution38
I0929 19:16:17.866655  2630 net.cpp:122] Setting up Convolution38
I0929 19:16:17.866664  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.866667  2630 net.cpp:137] Memory required for data: 768634000
I0929 19:16:17.866672  2630 layer_factory.hpp:77] Creating layer BatchNorm38
I0929 19:16:17.866677  2630 net.cpp:84] Creating Layer BatchNorm38
I0929 19:16:17.866680  2630 net.cpp:406] BatchNorm38 <- Convolution38
I0929 19:16:17.866683  2630 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0929 19:16:17.866828  2630 net.cpp:122] Setting up BatchNorm38
I0929 19:16:17.866833  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.866835  2630 net.cpp:137] Memory required for data: 771142800
I0929 19:16:17.866840  2630 layer_factory.hpp:77] Creating layer Scale38
I0929 19:16:17.866844  2630 net.cpp:84] Creating Layer Scale38
I0929 19:16:17.866847  2630 net.cpp:406] Scale38 <- Convolution38
I0929 19:16:17.866850  2630 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0929 19:16:17.866878  2630 layer_factory.hpp:77] Creating layer Scale38
I0929 19:16:17.866976  2630 net.cpp:122] Setting up Scale38
I0929 19:16:17.866979  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.866981  2630 net.cpp:137] Memory required for data: 773651600
I0929 19:16:17.866986  2630 layer_factory.hpp:77] Creating layer Eltwise18
I0929 19:16:17.866991  2630 net.cpp:84] Creating Layer Eltwise18
I0929 19:16:17.866993  2630 net.cpp:406] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0929 19:16:17.866997  2630 net.cpp:406] Eltwise18 <- Convolution38
I0929 19:16:17.866999  2630 net.cpp:380] Eltwise18 -> Eltwise18
I0929 19:16:17.867017  2630 net.cpp:122] Setting up Eltwise18
I0929 19:16:17.867022  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.867023  2630 net.cpp:137] Memory required for data: 776160400
I0929 19:16:17.867025  2630 layer_factory.hpp:77] Creating layer ReLU37
I0929 19:16:17.867029  2630 net.cpp:84] Creating Layer ReLU37
I0929 19:16:17.867031  2630 net.cpp:406] ReLU37 <- Eltwise18
I0929 19:16:17.867044  2630 net.cpp:367] ReLU37 -> Eltwise18 (in-place)
I0929 19:16:17.867177  2630 net.cpp:122] Setting up ReLU37
I0929 19:16:17.867182  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.867185  2630 net.cpp:137] Memory required for data: 778669200
I0929 19:16:17.867187  2630 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0929 19:16:17.867192  2630 net.cpp:84] Creating Layer Eltwise18_ReLU37_0_split
I0929 19:16:17.867193  2630 net.cpp:406] Eltwise18_ReLU37_0_split <- Eltwise18
I0929 19:16:17.867197  2630 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0929 19:16:17.867202  2630 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0929 19:16:17.867231  2630 net.cpp:122] Setting up Eltwise18_ReLU37_0_split
I0929 19:16:17.867235  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.867238  2630 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 19:16:17.867240  2630 net.cpp:137] Memory required for data: 783686800
I0929 19:16:17.867242  2630 layer_factory.hpp:77] Creating layer Convolution39
I0929 19:16:17.867250  2630 net.cpp:84] Creating Layer Convolution39
I0929 19:16:17.867254  2630 net.cpp:406] Convolution39 <- Eltwise18_ReLU37_0_split_0
I0929 19:16:17.867257  2630 net.cpp:380] Convolution39 -> Convolution39
I0929 19:16:17.868255  2630 net.cpp:122] Setting up Convolution39
I0929 19:16:17.868264  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.868268  2630 net.cpp:137] Memory required for data: 784941200
I0929 19:16:17.868271  2630 layer_factory.hpp:77] Creating layer BatchNorm39
I0929 19:16:17.868278  2630 net.cpp:84] Creating Layer BatchNorm39
I0929 19:16:17.868280  2630 net.cpp:406] BatchNorm39 <- Convolution39
I0929 19:16:17.868284  2630 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0929 19:16:17.868427  2630 net.cpp:122] Setting up BatchNorm39
I0929 19:16:17.868432  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.868434  2630 net.cpp:137] Memory required for data: 786195600
I0929 19:16:17.868446  2630 layer_factory.hpp:77] Creating layer Scale39
I0929 19:16:17.868450  2630 net.cpp:84] Creating Layer Scale39
I0929 19:16:17.868453  2630 net.cpp:406] Scale39 <- Convolution39
I0929 19:16:17.868456  2630 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0929 19:16:17.868485  2630 layer_factory.hpp:77] Creating layer Scale39
I0929 19:16:17.868568  2630 net.cpp:122] Setting up Scale39
I0929 19:16:17.868572  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.868574  2630 net.cpp:137] Memory required for data: 787450000
I0929 19:16:17.868578  2630 layer_factory.hpp:77] Creating layer Convolution40
I0929 19:16:17.868585  2630 net.cpp:84] Creating Layer Convolution40
I0929 19:16:17.868588  2630 net.cpp:406] Convolution40 <- Eltwise18_ReLU37_0_split_1
I0929 19:16:17.868592  2630 net.cpp:380] Convolution40 -> Convolution40
I0929 19:16:17.870404  2630 net.cpp:122] Setting up Convolution40
I0929 19:16:17.870412  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.870415  2630 net.cpp:137] Memory required for data: 788704400
I0929 19:16:17.870420  2630 layer_factory.hpp:77] Creating layer BatchNorm40
I0929 19:16:17.870425  2630 net.cpp:84] Creating Layer BatchNorm40
I0929 19:16:17.870429  2630 net.cpp:406] BatchNorm40 <- Convolution40
I0929 19:16:17.870432  2630 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0929 19:16:17.870611  2630 net.cpp:122] Setting up BatchNorm40
I0929 19:16:17.870616  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.870620  2630 net.cpp:137] Memory required for data: 789958800
I0929 19:16:17.870625  2630 layer_factory.hpp:77] Creating layer Scale40
I0929 19:16:17.870628  2630 net.cpp:84] Creating Layer Scale40
I0929 19:16:17.870630  2630 net.cpp:406] Scale40 <- Convolution40
I0929 19:16:17.870633  2630 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0929 19:16:17.870663  2630 layer_factory.hpp:77] Creating layer Scale40
I0929 19:16:17.870745  2630 net.cpp:122] Setting up Scale40
I0929 19:16:17.870749  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.870751  2630 net.cpp:137] Memory required for data: 791213200
I0929 19:16:17.870755  2630 layer_factory.hpp:77] Creating layer ReLU38
I0929 19:16:17.870759  2630 net.cpp:84] Creating Layer ReLU38
I0929 19:16:17.870762  2630 net.cpp:406] ReLU38 <- Convolution40
I0929 19:16:17.870764  2630 net.cpp:367] ReLU38 -> Convolution40 (in-place)
I0929 19:16:17.870887  2630 net.cpp:122] Setting up ReLU38
I0929 19:16:17.870893  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.870895  2630 net.cpp:137] Memory required for data: 792467600
I0929 19:16:17.870898  2630 layer_factory.hpp:77] Creating layer Convolution41
I0929 19:16:17.870904  2630 net.cpp:84] Creating Layer Convolution41
I0929 19:16:17.870906  2630 net.cpp:406] Convolution41 <- Convolution40
I0929 19:16:17.870911  2630 net.cpp:380] Convolution41 -> Convolution41
I0929 19:16:17.872896  2630 net.cpp:122] Setting up Convolution41
I0929 19:16:17.872905  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.872907  2630 net.cpp:137] Memory required for data: 793722000
I0929 19:16:17.872911  2630 layer_factory.hpp:77] Creating layer BatchNorm41
I0929 19:16:17.872917  2630 net.cpp:84] Creating Layer BatchNorm41
I0929 19:16:17.872920  2630 net.cpp:406] BatchNorm41 <- Convolution41
I0929 19:16:17.872923  2630 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0929 19:16:17.873070  2630 net.cpp:122] Setting up BatchNorm41
I0929 19:16:17.873073  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.873076  2630 net.cpp:137] Memory required for data: 794976400
I0929 19:16:17.873080  2630 layer_factory.hpp:77] Creating layer Scale41
I0929 19:16:17.873085  2630 net.cpp:84] Creating Layer Scale41
I0929 19:16:17.873087  2630 net.cpp:406] Scale41 <- Convolution41
I0929 19:16:17.873090  2630 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0929 19:16:17.873119  2630 layer_factory.hpp:77] Creating layer Scale41
I0929 19:16:17.873203  2630 net.cpp:122] Setting up Scale41
I0929 19:16:17.873214  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.873215  2630 net.cpp:137] Memory required for data: 796230800
I0929 19:16:17.873219  2630 layer_factory.hpp:77] Creating layer Eltwise19
I0929 19:16:17.873224  2630 net.cpp:84] Creating Layer Eltwise19
I0929 19:16:17.873227  2630 net.cpp:406] Eltwise19 <- Convolution39
I0929 19:16:17.873229  2630 net.cpp:406] Eltwise19 <- Convolution41
I0929 19:16:17.873234  2630 net.cpp:380] Eltwise19 -> Eltwise19
I0929 19:16:17.873251  2630 net.cpp:122] Setting up Eltwise19
I0929 19:16:17.873255  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.873257  2630 net.cpp:137] Memory required for data: 797485200
I0929 19:16:17.873260  2630 layer_factory.hpp:77] Creating layer ReLU39
I0929 19:16:17.873262  2630 net.cpp:84] Creating Layer ReLU39
I0929 19:16:17.873265  2630 net.cpp:406] ReLU39 <- Eltwise19
I0929 19:16:17.873268  2630 net.cpp:367] ReLU39 -> Eltwise19 (in-place)
I0929 19:16:17.873389  2630 net.cpp:122] Setting up ReLU39
I0929 19:16:17.873394  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.873396  2630 net.cpp:137] Memory required for data: 798739600
I0929 19:16:17.873399  2630 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0929 19:16:17.873404  2630 net.cpp:84] Creating Layer Eltwise19_ReLU39_0_split
I0929 19:16:17.873405  2630 net.cpp:406] Eltwise19_ReLU39_0_split <- Eltwise19
I0929 19:16:17.873409  2630 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0929 19:16:17.873414  2630 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0929 19:16:17.873441  2630 net.cpp:122] Setting up Eltwise19_ReLU39_0_split
I0929 19:16:17.873445  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.873448  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.873450  2630 net.cpp:137] Memory required for data: 801248400
I0929 19:16:17.873452  2630 layer_factory.hpp:77] Creating layer Convolution42
I0929 19:16:17.873459  2630 net.cpp:84] Creating Layer Convolution42
I0929 19:16:17.873462  2630 net.cpp:406] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0929 19:16:17.873466  2630 net.cpp:380] Convolution42 -> Convolution42
I0929 19:16:17.875129  2630 net.cpp:122] Setting up Convolution42
I0929 19:16:17.875138  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.875140  2630 net.cpp:137] Memory required for data: 802502800
I0929 19:16:17.875144  2630 layer_factory.hpp:77] Creating layer BatchNorm42
I0929 19:16:17.875149  2630 net.cpp:84] Creating Layer BatchNorm42
I0929 19:16:17.875152  2630 net.cpp:406] BatchNorm42 <- Convolution42
I0929 19:16:17.875156  2630 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0929 19:16:17.875298  2630 net.cpp:122] Setting up BatchNorm42
I0929 19:16:17.875303  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.875305  2630 net.cpp:137] Memory required for data: 803757200
I0929 19:16:17.875310  2630 layer_factory.hpp:77] Creating layer Scale42
I0929 19:16:17.875313  2630 net.cpp:84] Creating Layer Scale42
I0929 19:16:17.875316  2630 net.cpp:406] Scale42 <- Convolution42
I0929 19:16:17.875319  2630 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0929 19:16:17.875347  2630 layer_factory.hpp:77] Creating layer Scale42
I0929 19:16:17.875430  2630 net.cpp:122] Setting up Scale42
I0929 19:16:17.875435  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.875437  2630 net.cpp:137] Memory required for data: 805011600
I0929 19:16:17.875442  2630 layer_factory.hpp:77] Creating layer ReLU40
I0929 19:16:17.875445  2630 net.cpp:84] Creating Layer ReLU40
I0929 19:16:17.875448  2630 net.cpp:406] ReLU40 <- Convolution42
I0929 19:16:17.875450  2630 net.cpp:367] ReLU40 -> Convolution42 (in-place)
I0929 19:16:17.875885  2630 net.cpp:122] Setting up ReLU40
I0929 19:16:17.875895  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.875896  2630 net.cpp:137] Memory required for data: 806266000
I0929 19:16:17.875900  2630 layer_factory.hpp:77] Creating layer Convolution43
I0929 19:16:17.875906  2630 net.cpp:84] Creating Layer Convolution43
I0929 19:16:17.875916  2630 net.cpp:406] Convolution43 <- Convolution42
I0929 19:16:17.875921  2630 net.cpp:380] Convolution43 -> Convolution43
I0929 19:16:17.877883  2630 net.cpp:122] Setting up Convolution43
I0929 19:16:17.877892  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.877893  2630 net.cpp:137] Memory required for data: 807520400
I0929 19:16:17.877898  2630 layer_factory.hpp:77] Creating layer BatchNorm43
I0929 19:16:17.877903  2630 net.cpp:84] Creating Layer BatchNorm43
I0929 19:16:17.877905  2630 net.cpp:406] BatchNorm43 <- Convolution43
I0929 19:16:17.877910  2630 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0929 19:16:17.878057  2630 net.cpp:122] Setting up BatchNorm43
I0929 19:16:17.878062  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.878063  2630 net.cpp:137] Memory required for data: 808774800
I0929 19:16:17.878068  2630 layer_factory.hpp:77] Creating layer Scale43
I0929 19:16:17.878072  2630 net.cpp:84] Creating Layer Scale43
I0929 19:16:17.878074  2630 net.cpp:406] Scale43 <- Convolution43
I0929 19:16:17.878078  2630 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0929 19:16:17.878105  2630 layer_factory.hpp:77] Creating layer Scale43
I0929 19:16:17.878190  2630 net.cpp:122] Setting up Scale43
I0929 19:16:17.878196  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.878197  2630 net.cpp:137] Memory required for data: 810029200
I0929 19:16:17.878201  2630 layer_factory.hpp:77] Creating layer Eltwise20
I0929 19:16:17.878204  2630 net.cpp:84] Creating Layer Eltwise20
I0929 19:16:17.878207  2630 net.cpp:406] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0929 19:16:17.878209  2630 net.cpp:406] Eltwise20 <- Convolution43
I0929 19:16:17.878213  2630 net.cpp:380] Eltwise20 -> Eltwise20
I0929 19:16:17.878232  2630 net.cpp:122] Setting up Eltwise20
I0929 19:16:17.878234  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.878237  2630 net.cpp:137] Memory required for data: 811283600
I0929 19:16:17.878239  2630 layer_factory.hpp:77] Creating layer ReLU41
I0929 19:16:17.878242  2630 net.cpp:84] Creating Layer ReLU41
I0929 19:16:17.878244  2630 net.cpp:406] ReLU41 <- Eltwise20
I0929 19:16:17.878247  2630 net.cpp:367] ReLU41 -> Eltwise20 (in-place)
I0929 19:16:17.878376  2630 net.cpp:122] Setting up ReLU41
I0929 19:16:17.878381  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.878384  2630 net.cpp:137] Memory required for data: 812538000
I0929 19:16:17.878386  2630 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0929 19:16:17.878391  2630 net.cpp:84] Creating Layer Eltwise20_ReLU41_0_split
I0929 19:16:17.878392  2630 net.cpp:406] Eltwise20_ReLU41_0_split <- Eltwise20
I0929 19:16:17.878396  2630 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0929 19:16:17.878401  2630 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0929 19:16:17.878428  2630 net.cpp:122] Setting up Eltwise20_ReLU41_0_split
I0929 19:16:17.878432  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.878435  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.878437  2630 net.cpp:137] Memory required for data: 815046800
I0929 19:16:17.878439  2630 layer_factory.hpp:77] Creating layer Convolution44
I0929 19:16:17.878446  2630 net.cpp:84] Creating Layer Convolution44
I0929 19:16:17.878449  2630 net.cpp:406] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0929 19:16:17.878453  2630 net.cpp:380] Convolution44 -> Convolution44
I0929 19:16:17.880141  2630 net.cpp:122] Setting up Convolution44
I0929 19:16:17.880149  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.880152  2630 net.cpp:137] Memory required for data: 816301200
I0929 19:16:17.880156  2630 layer_factory.hpp:77] Creating layer BatchNorm44
I0929 19:16:17.880162  2630 net.cpp:84] Creating Layer BatchNorm44
I0929 19:16:17.880164  2630 net.cpp:406] BatchNorm44 <- Convolution44
I0929 19:16:17.880168  2630 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0929 19:16:17.880314  2630 net.cpp:122] Setting up BatchNorm44
I0929 19:16:17.880326  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.880327  2630 net.cpp:137] Memory required for data: 817555600
I0929 19:16:17.880332  2630 layer_factory.hpp:77] Creating layer Scale44
I0929 19:16:17.880337  2630 net.cpp:84] Creating Layer Scale44
I0929 19:16:17.880339  2630 net.cpp:406] Scale44 <- Convolution44
I0929 19:16:17.880343  2630 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0929 19:16:17.880373  2630 layer_factory.hpp:77] Creating layer Scale44
I0929 19:16:17.880456  2630 net.cpp:122] Setting up Scale44
I0929 19:16:17.880460  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.880462  2630 net.cpp:137] Memory required for data: 818810000
I0929 19:16:17.880466  2630 layer_factory.hpp:77] Creating layer ReLU42
I0929 19:16:17.880471  2630 net.cpp:84] Creating Layer ReLU42
I0929 19:16:17.880473  2630 net.cpp:406] ReLU42 <- Convolution44
I0929 19:16:17.880476  2630 net.cpp:367] ReLU42 -> Convolution44 (in-place)
I0929 19:16:17.880597  2630 net.cpp:122] Setting up ReLU42
I0929 19:16:17.880604  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.880605  2630 net.cpp:137] Memory required for data: 820064400
I0929 19:16:17.880607  2630 layer_factory.hpp:77] Creating layer Convolution45
I0929 19:16:17.880614  2630 net.cpp:84] Creating Layer Convolution45
I0929 19:16:17.880617  2630 net.cpp:406] Convolution45 <- Convolution44
I0929 19:16:17.880621  2630 net.cpp:380] Convolution45 -> Convolution45
I0929 19:16:17.882611  2630 net.cpp:122] Setting up Convolution45
I0929 19:16:17.882619  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.882622  2630 net.cpp:137] Memory required for data: 821318800
I0929 19:16:17.882627  2630 layer_factory.hpp:77] Creating layer BatchNorm45
I0929 19:16:17.882632  2630 net.cpp:84] Creating Layer BatchNorm45
I0929 19:16:17.882635  2630 net.cpp:406] BatchNorm45 <- Convolution45
I0929 19:16:17.882638  2630 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0929 19:16:17.882788  2630 net.cpp:122] Setting up BatchNorm45
I0929 19:16:17.882792  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.882796  2630 net.cpp:137] Memory required for data: 822573200
I0929 19:16:17.882799  2630 layer_factory.hpp:77] Creating layer Scale45
I0929 19:16:17.882804  2630 net.cpp:84] Creating Layer Scale45
I0929 19:16:17.882807  2630 net.cpp:406] Scale45 <- Convolution45
I0929 19:16:17.882809  2630 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0929 19:16:17.882838  2630 layer_factory.hpp:77] Creating layer Scale45
I0929 19:16:17.882920  2630 net.cpp:122] Setting up Scale45
I0929 19:16:17.882925  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.882927  2630 net.cpp:137] Memory required for data: 823827600
I0929 19:16:17.882930  2630 layer_factory.hpp:77] Creating layer Eltwise21
I0929 19:16:17.882936  2630 net.cpp:84] Creating Layer Eltwise21
I0929 19:16:17.882939  2630 net.cpp:406] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0929 19:16:17.882942  2630 net.cpp:406] Eltwise21 <- Convolution45
I0929 19:16:17.882946  2630 net.cpp:380] Eltwise21 -> Eltwise21
I0929 19:16:17.882962  2630 net.cpp:122] Setting up Eltwise21
I0929 19:16:17.882966  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.882968  2630 net.cpp:137] Memory required for data: 825082000
I0929 19:16:17.882971  2630 layer_factory.hpp:77] Creating layer ReLU43
I0929 19:16:17.882973  2630 net.cpp:84] Creating Layer ReLU43
I0929 19:16:17.882975  2630 net.cpp:406] ReLU43 <- Eltwise21
I0929 19:16:17.882979  2630 net.cpp:367] ReLU43 -> Eltwise21 (in-place)
I0929 19:16:17.883102  2630 net.cpp:122] Setting up ReLU43
I0929 19:16:17.883108  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.883111  2630 net.cpp:137] Memory required for data: 826336400
I0929 19:16:17.883113  2630 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0929 19:16:17.883116  2630 net.cpp:84] Creating Layer Eltwise21_ReLU43_0_split
I0929 19:16:17.883118  2630 net.cpp:406] Eltwise21_ReLU43_0_split <- Eltwise21
I0929 19:16:17.883123  2630 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0929 19:16:17.883133  2630 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0929 19:16:17.883163  2630 net.cpp:122] Setting up Eltwise21_ReLU43_0_split
I0929 19:16:17.883167  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.883170  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.883172  2630 net.cpp:137] Memory required for data: 828845200
I0929 19:16:17.883174  2630 layer_factory.hpp:77] Creating layer Convolution46
I0929 19:16:17.883182  2630 net.cpp:84] Creating Layer Convolution46
I0929 19:16:17.883184  2630 net.cpp:406] Convolution46 <- Eltwise21_ReLU43_0_split_0
I0929 19:16:17.883188  2630 net.cpp:380] Convolution46 -> Convolution46
I0929 19:16:17.884858  2630 net.cpp:122] Setting up Convolution46
I0929 19:16:17.884867  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.884871  2630 net.cpp:137] Memory required for data: 830099600
I0929 19:16:17.884874  2630 layer_factory.hpp:77] Creating layer BatchNorm46
I0929 19:16:17.884879  2630 net.cpp:84] Creating Layer BatchNorm46
I0929 19:16:17.884882  2630 net.cpp:406] BatchNorm46 <- Convolution46
I0929 19:16:17.884896  2630 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0929 19:16:17.885040  2630 net.cpp:122] Setting up BatchNorm46
I0929 19:16:17.885043  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.885046  2630 net.cpp:137] Memory required for data: 831354000
I0929 19:16:17.885051  2630 layer_factory.hpp:77] Creating layer Scale46
I0929 19:16:17.885056  2630 net.cpp:84] Creating Layer Scale46
I0929 19:16:17.885057  2630 net.cpp:406] Scale46 <- Convolution46
I0929 19:16:17.885061  2630 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0929 19:16:17.885089  2630 layer_factory.hpp:77] Creating layer Scale46
I0929 19:16:17.885172  2630 net.cpp:122] Setting up Scale46
I0929 19:16:17.885177  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.885179  2630 net.cpp:137] Memory required for data: 832608400
I0929 19:16:17.885182  2630 layer_factory.hpp:77] Creating layer ReLU44
I0929 19:16:17.885186  2630 net.cpp:84] Creating Layer ReLU44
I0929 19:16:17.885188  2630 net.cpp:406] ReLU44 <- Convolution46
I0929 19:16:17.885192  2630 net.cpp:367] ReLU44 -> Convolution46 (in-place)
I0929 19:16:17.885313  2630 net.cpp:122] Setting up ReLU44
I0929 19:16:17.885318  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.885321  2630 net.cpp:137] Memory required for data: 833862800
I0929 19:16:17.885324  2630 layer_factory.hpp:77] Creating layer Convolution47
I0929 19:16:17.885329  2630 net.cpp:84] Creating Layer Convolution47
I0929 19:16:17.885332  2630 net.cpp:406] Convolution47 <- Convolution46
I0929 19:16:17.885337  2630 net.cpp:380] Convolution47 -> Convolution47
I0929 19:16:17.887315  2630 net.cpp:122] Setting up Convolution47
I0929 19:16:17.887323  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.887326  2630 net.cpp:137] Memory required for data: 835117200
I0929 19:16:17.887331  2630 layer_factory.hpp:77] Creating layer BatchNorm47
I0929 19:16:17.887336  2630 net.cpp:84] Creating Layer BatchNorm47
I0929 19:16:17.887338  2630 net.cpp:406] BatchNorm47 <- Convolution47
I0929 19:16:17.887342  2630 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0929 19:16:17.887491  2630 net.cpp:122] Setting up BatchNorm47
I0929 19:16:17.887496  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.887498  2630 net.cpp:137] Memory required for data: 836371600
I0929 19:16:17.887503  2630 layer_factory.hpp:77] Creating layer Scale47
I0929 19:16:17.887508  2630 net.cpp:84] Creating Layer Scale47
I0929 19:16:17.887511  2630 net.cpp:406] Scale47 <- Convolution47
I0929 19:16:17.887513  2630 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0929 19:16:17.887542  2630 layer_factory.hpp:77] Creating layer Scale47
I0929 19:16:17.887648  2630 net.cpp:122] Setting up Scale47
I0929 19:16:17.887652  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.887655  2630 net.cpp:137] Memory required for data: 837626000
I0929 19:16:17.887665  2630 layer_factory.hpp:77] Creating layer Eltwise22
I0929 19:16:17.887670  2630 net.cpp:84] Creating Layer Eltwise22
I0929 19:16:17.887673  2630 net.cpp:406] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0929 19:16:17.887676  2630 net.cpp:406] Eltwise22 <- Convolution47
I0929 19:16:17.887679  2630 net.cpp:380] Eltwise22 -> Eltwise22
I0929 19:16:17.887697  2630 net.cpp:122] Setting up Eltwise22
I0929 19:16:17.887701  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.887703  2630 net.cpp:137] Memory required for data: 838880400
I0929 19:16:17.887706  2630 layer_factory.hpp:77] Creating layer ReLU45
I0929 19:16:17.887709  2630 net.cpp:84] Creating Layer ReLU45
I0929 19:16:17.887712  2630 net.cpp:406] ReLU45 <- Eltwise22
I0929 19:16:17.887717  2630 net.cpp:367] ReLU45 -> Eltwise22 (in-place)
I0929 19:16:17.887845  2630 net.cpp:122] Setting up ReLU45
I0929 19:16:17.887850  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.887853  2630 net.cpp:137] Memory required for data: 840134800
I0929 19:16:17.887856  2630 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0929 19:16:17.887858  2630 net.cpp:84] Creating Layer Eltwise22_ReLU45_0_split
I0929 19:16:17.887861  2630 net.cpp:406] Eltwise22_ReLU45_0_split <- Eltwise22
I0929 19:16:17.887866  2630 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0929 19:16:17.887869  2630 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0929 19:16:17.887898  2630 net.cpp:122] Setting up Eltwise22_ReLU45_0_split
I0929 19:16:17.887902  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.887905  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.887907  2630 net.cpp:137] Memory required for data: 842643600
I0929 19:16:17.887909  2630 layer_factory.hpp:77] Creating layer Convolution48
I0929 19:16:17.887917  2630 net.cpp:84] Creating Layer Convolution48
I0929 19:16:17.887919  2630 net.cpp:406] Convolution48 <- Eltwise22_ReLU45_0_split_0
I0929 19:16:17.887923  2630 net.cpp:380] Convolution48 -> Convolution48
I0929 19:16:17.889569  2630 net.cpp:122] Setting up Convolution48
I0929 19:16:17.889578  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.889581  2630 net.cpp:137] Memory required for data: 843898000
I0929 19:16:17.889585  2630 layer_factory.hpp:77] Creating layer BatchNorm48
I0929 19:16:17.889590  2630 net.cpp:84] Creating Layer BatchNorm48
I0929 19:16:17.889593  2630 net.cpp:406] BatchNorm48 <- Convolution48
I0929 19:16:17.889597  2630 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0929 19:16:17.889744  2630 net.cpp:122] Setting up BatchNorm48
I0929 19:16:17.889747  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.889750  2630 net.cpp:137] Memory required for data: 845152400
I0929 19:16:17.889755  2630 layer_factory.hpp:77] Creating layer Scale48
I0929 19:16:17.889758  2630 net.cpp:84] Creating Layer Scale48
I0929 19:16:17.889761  2630 net.cpp:406] Scale48 <- Convolution48
I0929 19:16:17.889765  2630 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0929 19:16:17.889792  2630 layer_factory.hpp:77] Creating layer Scale48
I0929 19:16:17.889875  2630 net.cpp:122] Setting up Scale48
I0929 19:16:17.889879  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.889881  2630 net.cpp:137] Memory required for data: 846406800
I0929 19:16:17.889885  2630 layer_factory.hpp:77] Creating layer ReLU46
I0929 19:16:17.889889  2630 net.cpp:84] Creating Layer ReLU46
I0929 19:16:17.889891  2630 net.cpp:406] ReLU46 <- Convolution48
I0929 19:16:17.889894  2630 net.cpp:367] ReLU46 -> Convolution48 (in-place)
I0929 19:16:17.890328  2630 net.cpp:122] Setting up ReLU46
I0929 19:16:17.890336  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.890338  2630 net.cpp:137] Memory required for data: 847661200
I0929 19:16:17.890341  2630 layer_factory.hpp:77] Creating layer Convolution49
I0929 19:16:17.890348  2630 net.cpp:84] Creating Layer Convolution49
I0929 19:16:17.890352  2630 net.cpp:406] Convolution49 <- Convolution48
I0929 19:16:17.890362  2630 net.cpp:380] Convolution49 -> Convolution49
I0929 19:16:17.892729  2630 net.cpp:122] Setting up Convolution49
I0929 19:16:17.892736  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.892740  2630 net.cpp:137] Memory required for data: 848915600
I0929 19:16:17.892745  2630 layer_factory.hpp:77] Creating layer BatchNorm49
I0929 19:16:17.892750  2630 net.cpp:84] Creating Layer BatchNorm49
I0929 19:16:17.892752  2630 net.cpp:406] BatchNorm49 <- Convolution49
I0929 19:16:17.892756  2630 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0929 19:16:17.892909  2630 net.cpp:122] Setting up BatchNorm49
I0929 19:16:17.892912  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.892915  2630 net.cpp:137] Memory required for data: 850170000
I0929 19:16:17.892920  2630 layer_factory.hpp:77] Creating layer Scale49
I0929 19:16:17.892925  2630 net.cpp:84] Creating Layer Scale49
I0929 19:16:17.892927  2630 net.cpp:406] Scale49 <- Convolution49
I0929 19:16:17.892930  2630 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0929 19:16:17.892959  2630 layer_factory.hpp:77] Creating layer Scale49
I0929 19:16:17.893044  2630 net.cpp:122] Setting up Scale49
I0929 19:16:17.893049  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.893050  2630 net.cpp:137] Memory required for data: 851424400
I0929 19:16:17.893054  2630 layer_factory.hpp:77] Creating layer Eltwise23
I0929 19:16:17.893059  2630 net.cpp:84] Creating Layer Eltwise23
I0929 19:16:17.893061  2630 net.cpp:406] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0929 19:16:17.893064  2630 net.cpp:406] Eltwise23 <- Convolution49
I0929 19:16:17.893067  2630 net.cpp:380] Eltwise23 -> Eltwise23
I0929 19:16:17.893085  2630 net.cpp:122] Setting up Eltwise23
I0929 19:16:17.893088  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.893090  2630 net.cpp:137] Memory required for data: 852678800
I0929 19:16:17.893092  2630 layer_factory.hpp:77] Creating layer ReLU47
I0929 19:16:17.893095  2630 net.cpp:84] Creating Layer ReLU47
I0929 19:16:17.893097  2630 net.cpp:406] ReLU47 <- Eltwise23
I0929 19:16:17.893101  2630 net.cpp:367] ReLU47 -> Eltwise23 (in-place)
I0929 19:16:17.893226  2630 net.cpp:122] Setting up ReLU47
I0929 19:16:17.893231  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.893234  2630 net.cpp:137] Memory required for data: 853933200
I0929 19:16:17.893236  2630 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0929 19:16:17.893240  2630 net.cpp:84] Creating Layer Eltwise23_ReLU47_0_split
I0929 19:16:17.893244  2630 net.cpp:406] Eltwise23_ReLU47_0_split <- Eltwise23
I0929 19:16:17.893246  2630 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0929 19:16:17.893250  2630 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0929 19:16:17.893280  2630 net.cpp:122] Setting up Eltwise23_ReLU47_0_split
I0929 19:16:17.893285  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.893286  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.893288  2630 net.cpp:137] Memory required for data: 856442000
I0929 19:16:17.893291  2630 layer_factory.hpp:77] Creating layer Convolution50
I0929 19:16:17.893297  2630 net.cpp:84] Creating Layer Convolution50
I0929 19:16:17.893299  2630 net.cpp:406] Convolution50 <- Eltwise23_ReLU47_0_split_0
I0929 19:16:17.893304  2630 net.cpp:380] Convolution50 -> Convolution50
I0929 19:16:17.895136  2630 net.cpp:122] Setting up Convolution50
I0929 19:16:17.895145  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.895148  2630 net.cpp:137] Memory required for data: 857696400
I0929 19:16:17.895153  2630 layer_factory.hpp:77] Creating layer BatchNorm50
I0929 19:16:17.895159  2630 net.cpp:84] Creating Layer BatchNorm50
I0929 19:16:17.895161  2630 net.cpp:406] BatchNorm50 <- Convolution50
I0929 19:16:17.895164  2630 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0929 19:16:17.895344  2630 net.cpp:122] Setting up BatchNorm50
I0929 19:16:17.895349  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.895350  2630 net.cpp:137] Memory required for data: 858950800
I0929 19:16:17.895362  2630 layer_factory.hpp:77] Creating layer Scale50
I0929 19:16:17.895366  2630 net.cpp:84] Creating Layer Scale50
I0929 19:16:17.895370  2630 net.cpp:406] Scale50 <- Convolution50
I0929 19:16:17.895372  2630 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0929 19:16:17.895406  2630 layer_factory.hpp:77] Creating layer Scale50
I0929 19:16:17.895495  2630 net.cpp:122] Setting up Scale50
I0929 19:16:17.895500  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.895503  2630 net.cpp:137] Memory required for data: 860205200
I0929 19:16:17.895506  2630 layer_factory.hpp:77] Creating layer ReLU48
I0929 19:16:17.895510  2630 net.cpp:84] Creating Layer ReLU48
I0929 19:16:17.895514  2630 net.cpp:406] ReLU48 <- Convolution50
I0929 19:16:17.895516  2630 net.cpp:367] ReLU48 -> Convolution50 (in-place)
I0929 19:16:17.895645  2630 net.cpp:122] Setting up ReLU48
I0929 19:16:17.895653  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.895655  2630 net.cpp:137] Memory required for data: 861459600
I0929 19:16:17.895658  2630 layer_factory.hpp:77] Creating layer Convolution51
I0929 19:16:17.895664  2630 net.cpp:84] Creating Layer Convolution51
I0929 19:16:17.895668  2630 net.cpp:406] Convolution51 <- Convolution50
I0929 19:16:17.895671  2630 net.cpp:380] Convolution51 -> Convolution51
I0929 19:16:17.897936  2630 net.cpp:122] Setting up Convolution51
I0929 19:16:17.897946  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.897948  2630 net.cpp:137] Memory required for data: 862714000
I0929 19:16:17.897963  2630 layer_factory.hpp:77] Creating layer BatchNorm51
I0929 19:16:17.897979  2630 net.cpp:84] Creating Layer BatchNorm51
I0929 19:16:17.897981  2630 net.cpp:406] BatchNorm51 <- Convolution51
I0929 19:16:17.897985  2630 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0929 19:16:17.898147  2630 net.cpp:122] Setting up BatchNorm51
I0929 19:16:17.898151  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.898154  2630 net.cpp:137] Memory required for data: 863968400
I0929 19:16:17.898159  2630 layer_factory.hpp:77] Creating layer Scale51
I0929 19:16:17.898164  2630 net.cpp:84] Creating Layer Scale51
I0929 19:16:17.898165  2630 net.cpp:406] Scale51 <- Convolution51
I0929 19:16:17.898169  2630 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0929 19:16:17.898200  2630 layer_factory.hpp:77] Creating layer Scale51
I0929 19:16:17.898290  2630 net.cpp:122] Setting up Scale51
I0929 19:16:17.898304  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.898306  2630 net.cpp:137] Memory required for data: 865222800
I0929 19:16:17.898309  2630 layer_factory.hpp:77] Creating layer Eltwise24
I0929 19:16:17.898314  2630 net.cpp:84] Creating Layer Eltwise24
I0929 19:16:17.898317  2630 net.cpp:406] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0929 19:16:17.898320  2630 net.cpp:406] Eltwise24 <- Convolution51
I0929 19:16:17.898324  2630 net.cpp:380] Eltwise24 -> Eltwise24
I0929 19:16:17.898341  2630 net.cpp:122] Setting up Eltwise24
I0929 19:16:17.898345  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.898347  2630 net.cpp:137] Memory required for data: 866477200
I0929 19:16:17.898350  2630 layer_factory.hpp:77] Creating layer ReLU49
I0929 19:16:17.898355  2630 net.cpp:84] Creating Layer ReLU49
I0929 19:16:17.898356  2630 net.cpp:406] ReLU49 <- Eltwise24
I0929 19:16:17.898360  2630 net.cpp:367] ReLU49 -> Eltwise24 (in-place)
I0929 19:16:17.898494  2630 net.cpp:122] Setting up ReLU49
I0929 19:16:17.898500  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.898502  2630 net.cpp:137] Memory required for data: 867731600
I0929 19:16:17.898504  2630 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0929 19:16:17.898509  2630 net.cpp:84] Creating Layer Eltwise24_ReLU49_0_split
I0929 19:16:17.898511  2630 net.cpp:406] Eltwise24_ReLU49_0_split <- Eltwise24
I0929 19:16:17.898516  2630 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0929 19:16:17.898540  2630 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0929 19:16:17.898591  2630 net.cpp:122] Setting up Eltwise24_ReLU49_0_split
I0929 19:16:17.898597  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.898599  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.898602  2630 net.cpp:137] Memory required for data: 870240400
I0929 19:16:17.898603  2630 layer_factory.hpp:77] Creating layer Convolution52
I0929 19:16:17.898612  2630 net.cpp:84] Creating Layer Convolution52
I0929 19:16:17.898614  2630 net.cpp:406] Convolution52 <- Eltwise24_ReLU49_0_split_0
I0929 19:16:17.898618  2630 net.cpp:380] Convolution52 -> Convolution52
I0929 19:16:17.900341  2630 net.cpp:122] Setting up Convolution52
I0929 19:16:17.900349  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.900352  2630 net.cpp:137] Memory required for data: 871494800
I0929 19:16:17.900357  2630 layer_factory.hpp:77] Creating layer BatchNorm52
I0929 19:16:17.900362  2630 net.cpp:84] Creating Layer BatchNorm52
I0929 19:16:17.900364  2630 net.cpp:406] BatchNorm52 <- Convolution52
I0929 19:16:17.900368  2630 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0929 19:16:17.900523  2630 net.cpp:122] Setting up BatchNorm52
I0929 19:16:17.900527  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.900530  2630 net.cpp:137] Memory required for data: 872749200
I0929 19:16:17.900534  2630 layer_factory.hpp:77] Creating layer Scale52
I0929 19:16:17.900538  2630 net.cpp:84] Creating Layer Scale52
I0929 19:16:17.900542  2630 net.cpp:406] Scale52 <- Convolution52
I0929 19:16:17.900544  2630 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0929 19:16:17.900575  2630 layer_factory.hpp:77] Creating layer Scale52
I0929 19:16:17.900662  2630 net.cpp:122] Setting up Scale52
I0929 19:16:17.900667  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.900669  2630 net.cpp:137] Memory required for data: 874003600
I0929 19:16:17.900672  2630 layer_factory.hpp:77] Creating layer ReLU50
I0929 19:16:17.900676  2630 net.cpp:84] Creating Layer ReLU50
I0929 19:16:17.900678  2630 net.cpp:406] ReLU50 <- Convolution52
I0929 19:16:17.900681  2630 net.cpp:367] ReLU50 -> Convolution52 (in-place)
I0929 19:16:17.900810  2630 net.cpp:122] Setting up ReLU50
I0929 19:16:17.900815  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.900817  2630 net.cpp:137] Memory required for data: 875258000
I0929 19:16:17.900820  2630 layer_factory.hpp:77] Creating layer Convolution53
I0929 19:16:17.900852  2630 net.cpp:84] Creating Layer Convolution53
I0929 19:16:17.900856  2630 net.cpp:406] Convolution53 <- Convolution52
I0929 19:16:17.900859  2630 net.cpp:380] Convolution53 -> Convolution53
I0929 19:16:17.902925  2630 net.cpp:122] Setting up Convolution53
I0929 19:16:17.902935  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.902938  2630 net.cpp:137] Memory required for data: 876512400
I0929 19:16:17.902943  2630 layer_factory.hpp:77] Creating layer BatchNorm53
I0929 19:16:17.902948  2630 net.cpp:84] Creating Layer BatchNorm53
I0929 19:16:17.902951  2630 net.cpp:406] BatchNorm53 <- Convolution53
I0929 19:16:17.902956  2630 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0929 19:16:17.903117  2630 net.cpp:122] Setting up BatchNorm53
I0929 19:16:17.903122  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.903125  2630 net.cpp:137] Memory required for data: 877766800
I0929 19:16:17.903129  2630 layer_factory.hpp:77] Creating layer Scale53
I0929 19:16:17.903133  2630 net.cpp:84] Creating Layer Scale53
I0929 19:16:17.903136  2630 net.cpp:406] Scale53 <- Convolution53
I0929 19:16:17.903139  2630 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0929 19:16:17.903170  2630 layer_factory.hpp:77] Creating layer Scale53
I0929 19:16:17.903260  2630 net.cpp:122] Setting up Scale53
I0929 19:16:17.903265  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.903267  2630 net.cpp:137] Memory required for data: 879021200
I0929 19:16:17.903271  2630 layer_factory.hpp:77] Creating layer Eltwise25
I0929 19:16:17.903281  2630 net.cpp:84] Creating Layer Eltwise25
I0929 19:16:17.903285  2630 net.cpp:406] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0929 19:16:17.903287  2630 net.cpp:406] Eltwise25 <- Convolution53
I0929 19:16:17.903291  2630 net.cpp:380] Eltwise25 -> Eltwise25
I0929 19:16:17.903311  2630 net.cpp:122] Setting up Eltwise25
I0929 19:16:17.903316  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.903318  2630 net.cpp:137] Memory required for data: 880275600
I0929 19:16:17.903321  2630 layer_factory.hpp:77] Creating layer ReLU51
I0929 19:16:17.903323  2630 net.cpp:84] Creating Layer ReLU51
I0929 19:16:17.903326  2630 net.cpp:406] ReLU51 <- Eltwise25
I0929 19:16:17.903329  2630 net.cpp:367] ReLU51 -> Eltwise25 (in-place)
I0929 19:16:17.903479  2630 net.cpp:122] Setting up ReLU51
I0929 19:16:17.903486  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.903487  2630 net.cpp:137] Memory required for data: 881530000
I0929 19:16:17.903491  2630 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0929 19:16:17.903494  2630 net.cpp:84] Creating Layer Eltwise25_ReLU51_0_split
I0929 19:16:17.903496  2630 net.cpp:406] Eltwise25_ReLU51_0_split <- Eltwise25
I0929 19:16:17.903499  2630 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0929 19:16:17.903506  2630 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0929 19:16:17.903537  2630 net.cpp:122] Setting up Eltwise25_ReLU51_0_split
I0929 19:16:17.903542  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.903544  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.903547  2630 net.cpp:137] Memory required for data: 884038800
I0929 19:16:17.903548  2630 layer_factory.hpp:77] Creating layer Convolution54
I0929 19:16:17.903556  2630 net.cpp:84] Creating Layer Convolution54
I0929 19:16:17.903558  2630 net.cpp:406] Convolution54 <- Eltwise25_ReLU51_0_split_0
I0929 19:16:17.903563  2630 net.cpp:380] Convolution54 -> Convolution54
I0929 19:16:17.905776  2630 net.cpp:122] Setting up Convolution54
I0929 19:16:17.905786  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.905788  2630 net.cpp:137] Memory required for data: 885293200
I0929 19:16:17.905793  2630 layer_factory.hpp:77] Creating layer BatchNorm54
I0929 19:16:17.905797  2630 net.cpp:84] Creating Layer BatchNorm54
I0929 19:16:17.905800  2630 net.cpp:406] BatchNorm54 <- Convolution54
I0929 19:16:17.905804  2630 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0929 19:16:17.905958  2630 net.cpp:122] Setting up BatchNorm54
I0929 19:16:17.905962  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.905964  2630 net.cpp:137] Memory required for data: 886547600
I0929 19:16:17.905969  2630 layer_factory.hpp:77] Creating layer Scale54
I0929 19:16:17.905973  2630 net.cpp:84] Creating Layer Scale54
I0929 19:16:17.905975  2630 net.cpp:406] Scale54 <- Convolution54
I0929 19:16:17.905978  2630 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0929 19:16:17.906008  2630 layer_factory.hpp:77] Creating layer Scale54
I0929 19:16:17.906097  2630 net.cpp:122] Setting up Scale54
I0929 19:16:17.906101  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.906103  2630 net.cpp:137] Memory required for data: 887802000
I0929 19:16:17.906107  2630 layer_factory.hpp:77] Creating layer ReLU52
I0929 19:16:17.906111  2630 net.cpp:84] Creating Layer ReLU52
I0929 19:16:17.906113  2630 net.cpp:406] ReLU52 <- Convolution54
I0929 19:16:17.906116  2630 net.cpp:367] ReLU52 -> Convolution54 (in-place)
I0929 19:16:17.906571  2630 net.cpp:122] Setting up ReLU52
I0929 19:16:17.906579  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.906582  2630 net.cpp:137] Memory required for data: 889056400
I0929 19:16:17.906584  2630 layer_factory.hpp:77] Creating layer Convolution55
I0929 19:16:17.906591  2630 net.cpp:84] Creating Layer Convolution55
I0929 19:16:17.906594  2630 net.cpp:406] Convolution55 <- Convolution54
I0929 19:16:17.906599  2630 net.cpp:380] Convolution55 -> Convolution55
I0929 19:16:17.908607  2630 net.cpp:122] Setting up Convolution55
I0929 19:16:17.908622  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.908625  2630 net.cpp:137] Memory required for data: 890310800
I0929 19:16:17.908630  2630 layer_factory.hpp:77] Creating layer BatchNorm55
I0929 19:16:17.908635  2630 net.cpp:84] Creating Layer BatchNorm55
I0929 19:16:17.908638  2630 net.cpp:406] BatchNorm55 <- Convolution55
I0929 19:16:17.908643  2630 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0929 19:16:17.908799  2630 net.cpp:122] Setting up BatchNorm55
I0929 19:16:17.908804  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.908807  2630 net.cpp:137] Memory required for data: 891565200
I0929 19:16:17.908810  2630 layer_factory.hpp:77] Creating layer Scale55
I0929 19:16:17.908815  2630 net.cpp:84] Creating Layer Scale55
I0929 19:16:17.908818  2630 net.cpp:406] Scale55 <- Convolution55
I0929 19:16:17.908821  2630 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0929 19:16:17.908850  2630 layer_factory.hpp:77] Creating layer Scale55
I0929 19:16:17.908938  2630 net.cpp:122] Setting up Scale55
I0929 19:16:17.908942  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.908944  2630 net.cpp:137] Memory required for data: 892819600
I0929 19:16:17.908948  2630 layer_factory.hpp:77] Creating layer Eltwise26
I0929 19:16:17.908953  2630 net.cpp:84] Creating Layer Eltwise26
I0929 19:16:17.908956  2630 net.cpp:406] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0929 19:16:17.908958  2630 net.cpp:406] Eltwise26 <- Convolution55
I0929 19:16:17.908962  2630 net.cpp:380] Eltwise26 -> Eltwise26
I0929 19:16:17.908980  2630 net.cpp:122] Setting up Eltwise26
I0929 19:16:17.908984  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.908985  2630 net.cpp:137] Memory required for data: 894074000
I0929 19:16:17.908988  2630 layer_factory.hpp:77] Creating layer ReLU53
I0929 19:16:17.908991  2630 net.cpp:84] Creating Layer ReLU53
I0929 19:16:17.908993  2630 net.cpp:406] ReLU53 <- Eltwise26
I0929 19:16:17.908998  2630 net.cpp:367] ReLU53 -> Eltwise26 (in-place)
I0929 19:16:17.909126  2630 net.cpp:122] Setting up ReLU53
I0929 19:16:17.909132  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.909133  2630 net.cpp:137] Memory required for data: 895328400
I0929 19:16:17.909137  2630 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0929 19:16:17.909139  2630 net.cpp:84] Creating Layer Eltwise26_ReLU53_0_split
I0929 19:16:17.909142  2630 net.cpp:406] Eltwise26_ReLU53_0_split <- Eltwise26
I0929 19:16:17.909145  2630 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0929 19:16:17.909149  2630 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0929 19:16:17.909181  2630 net.cpp:122] Setting up Eltwise26_ReLU53_0_split
I0929 19:16:17.909185  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.909188  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.909189  2630 net.cpp:137] Memory required for data: 897837200
I0929 19:16:17.909193  2630 layer_factory.hpp:77] Creating layer Convolution56
I0929 19:16:17.909198  2630 net.cpp:84] Creating Layer Convolution56
I0929 19:16:17.909201  2630 net.cpp:406] Convolution56 <- Eltwise26_ReLU53_0_split_0
I0929 19:16:17.909206  2630 net.cpp:380] Convolution56 -> Convolution56
I0929 19:16:17.910917  2630 net.cpp:122] Setting up Convolution56
I0929 19:16:17.910925  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.910928  2630 net.cpp:137] Memory required for data: 899091600
I0929 19:16:17.910933  2630 layer_factory.hpp:77] Creating layer BatchNorm56
I0929 19:16:17.910936  2630 net.cpp:84] Creating Layer BatchNorm56
I0929 19:16:17.910939  2630 net.cpp:406] BatchNorm56 <- Convolution56
I0929 19:16:17.910943  2630 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0929 19:16:17.911099  2630 net.cpp:122] Setting up BatchNorm56
I0929 19:16:17.911103  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.911106  2630 net.cpp:137] Memory required for data: 900346000
I0929 19:16:17.911110  2630 layer_factory.hpp:77] Creating layer Scale56
I0929 19:16:17.911121  2630 net.cpp:84] Creating Layer Scale56
I0929 19:16:17.911124  2630 net.cpp:406] Scale56 <- Convolution56
I0929 19:16:17.911128  2630 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0929 19:16:17.911159  2630 layer_factory.hpp:77] Creating layer Scale56
I0929 19:16:17.911247  2630 net.cpp:122] Setting up Scale56
I0929 19:16:17.911252  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.911253  2630 net.cpp:137] Memory required for data: 901600400
I0929 19:16:17.911257  2630 layer_factory.hpp:77] Creating layer ReLU54
I0929 19:16:17.911260  2630 net.cpp:84] Creating Layer ReLU54
I0929 19:16:17.924751  2630 net.cpp:406] ReLU54 <- Convolution56
I0929 19:16:17.924764  2630 net.cpp:367] ReLU54 -> Convolution56 (in-place)
I0929 19:16:17.924932  2630 net.cpp:122] Setting up ReLU54
I0929 19:16:17.924939  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.924942  2630 net.cpp:137] Memory required for data: 902854800
I0929 19:16:17.924944  2630 layer_factory.hpp:77] Creating layer Convolution57
I0929 19:16:17.924952  2630 net.cpp:84] Creating Layer Convolution57
I0929 19:16:17.924955  2630 net.cpp:406] Convolution57 <- Convolution56
I0929 19:16:17.924960  2630 net.cpp:380] Convolution57 -> Convolution57
I0929 19:16:17.927702  2630 net.cpp:122] Setting up Convolution57
I0929 19:16:17.927712  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.927716  2630 net.cpp:137] Memory required for data: 904109200
I0929 19:16:17.927721  2630 layer_factory.hpp:77] Creating layer BatchNorm57
I0929 19:16:17.927726  2630 net.cpp:84] Creating Layer BatchNorm57
I0929 19:16:17.927728  2630 net.cpp:406] BatchNorm57 <- Convolution57
I0929 19:16:17.927733  2630 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0929 19:16:17.927896  2630 net.cpp:122] Setting up BatchNorm57
I0929 19:16:17.927901  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.927903  2630 net.cpp:137] Memory required for data: 905363600
I0929 19:16:17.927908  2630 layer_factory.hpp:77] Creating layer Scale57
I0929 19:16:17.927913  2630 net.cpp:84] Creating Layer Scale57
I0929 19:16:17.927916  2630 net.cpp:406] Scale57 <- Convolution57
I0929 19:16:17.927918  2630 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0929 19:16:17.927950  2630 layer_factory.hpp:77] Creating layer Scale57
I0929 19:16:17.928040  2630 net.cpp:122] Setting up Scale57
I0929 19:16:17.928045  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.928046  2630 net.cpp:137] Memory required for data: 906618000
I0929 19:16:17.928050  2630 layer_factory.hpp:77] Creating layer Eltwise27
I0929 19:16:17.928056  2630 net.cpp:84] Creating Layer Eltwise27
I0929 19:16:17.928058  2630 net.cpp:406] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0929 19:16:17.928061  2630 net.cpp:406] Eltwise27 <- Convolution57
I0929 19:16:17.928066  2630 net.cpp:380] Eltwise27 -> Eltwise27
I0929 19:16:17.928082  2630 net.cpp:122] Setting up Eltwise27
I0929 19:16:17.928086  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.928088  2630 net.cpp:137] Memory required for data: 907872400
I0929 19:16:17.928091  2630 layer_factory.hpp:77] Creating layer ReLU55
I0929 19:16:17.928094  2630 net.cpp:84] Creating Layer ReLU55
I0929 19:16:17.928097  2630 net.cpp:406] ReLU55 <- Eltwise27
I0929 19:16:17.928100  2630 net.cpp:367] ReLU55 -> Eltwise27 (in-place)
I0929 19:16:17.928242  2630 net.cpp:122] Setting up ReLU55
I0929 19:16:17.928248  2630 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 19:16:17.928251  2630 net.cpp:137] Memory required for data: 909126800
I0929 19:16:17.928252  2630 layer_factory.hpp:77] Creating layer Pooling1
I0929 19:16:17.928258  2630 net.cpp:84] Creating Layer Pooling1
I0929 19:16:17.928261  2630 net.cpp:406] Pooling1 <- Eltwise27
I0929 19:16:17.928264  2630 net.cpp:380] Pooling1 -> Pooling1
I0929 19:16:17.928447  2630 net.cpp:122] Setting up Pooling1
I0929 19:16:17.928452  2630 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0929 19:16:17.928454  2630 net.cpp:137] Memory required for data: 909152400
I0929 19:16:17.928464  2630 layer_factory.hpp:77] Creating layer InnerProduct1
I0929 19:16:17.928473  2630 net.cpp:84] Creating Layer InnerProduct1
I0929 19:16:17.928475  2630 net.cpp:406] InnerProduct1 <- Pooling1
I0929 19:16:17.928480  2630 net.cpp:380] InnerProduct1 -> InnerProduct1
I0929 19:16:17.928597  2630 net.cpp:122] Setting up InnerProduct1
I0929 19:16:17.928611  2630 net.cpp:129] Top shape: 100 10 (1000)
I0929 19:16:17.928613  2630 net.cpp:137] Memory required for data: 909156400
I0929 19:16:17.928629  2630 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 19:16:17.928634  2630 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0929 19:16:17.928637  2630 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0929 19:16:17.928640  2630 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0929 19:16:17.928644  2630 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0929 19:16:17.928649  2630 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 19:16:17.929237  2630 net.cpp:122] Setting up SoftmaxWithLoss1
I0929 19:16:17.929245  2630 net.cpp:129] Top shape: (1)
I0929 19:16:17.929249  2630 net.cpp:132]     with loss weight 1
I0929 19:16:17.929260  2630 net.cpp:137] Memory required for data: 909156404
I0929 19:16:17.929263  2630 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0929 19:16:17.929266  2630 net.cpp:198] InnerProduct1 needs backward computation.
I0929 19:16:17.929268  2630 net.cpp:198] Pooling1 needs backward computation.
I0929 19:16:17.929270  2630 net.cpp:198] ReLU55 needs backward computation.
I0929 19:16:17.929272  2630 net.cpp:198] Eltwise27 needs backward computation.
I0929 19:16:17.929275  2630 net.cpp:198] Scale57 needs backward computation.
I0929 19:16:17.929277  2630 net.cpp:198] BatchNorm57 needs backward computation.
I0929 19:16:17.929280  2630 net.cpp:198] Convolution57 needs backward computation.
I0929 19:16:17.929281  2630 net.cpp:198] ReLU54 needs backward computation.
I0929 19:16:17.929283  2630 net.cpp:198] Scale56 needs backward computation.
I0929 19:16:17.929286  2630 net.cpp:198] BatchNorm56 needs backward computation.
I0929 19:16:17.929287  2630 net.cpp:198] Convolution56 needs backward computation.
I0929 19:16:17.929289  2630 net.cpp:198] Eltwise26_ReLU53_0_split needs backward computation.
I0929 19:16:17.929291  2630 net.cpp:198] ReLU53 needs backward computation.
I0929 19:16:17.929293  2630 net.cpp:198] Eltwise26 needs backward computation.
I0929 19:16:17.929296  2630 net.cpp:198] Scale55 needs backward computation.
I0929 19:16:17.929298  2630 net.cpp:198] BatchNorm55 needs backward computation.
I0929 19:16:17.929301  2630 net.cpp:198] Convolution55 needs backward computation.
I0929 19:16:17.929302  2630 net.cpp:198] ReLU52 needs backward computation.
I0929 19:16:17.929304  2630 net.cpp:198] Scale54 needs backward computation.
I0929 19:16:17.929306  2630 net.cpp:198] BatchNorm54 needs backward computation.
I0929 19:16:17.929308  2630 net.cpp:198] Convolution54 needs backward computation.
I0929 19:16:17.929311  2630 net.cpp:198] Eltwise25_ReLU51_0_split needs backward computation.
I0929 19:16:17.929314  2630 net.cpp:198] ReLU51 needs backward computation.
I0929 19:16:17.929316  2630 net.cpp:198] Eltwise25 needs backward computation.
I0929 19:16:17.929318  2630 net.cpp:198] Scale53 needs backward computation.
I0929 19:16:17.929322  2630 net.cpp:198] BatchNorm53 needs backward computation.
I0929 19:16:17.929323  2630 net.cpp:198] Convolution53 needs backward computation.
I0929 19:16:17.929325  2630 net.cpp:198] ReLU50 needs backward computation.
I0929 19:16:17.929327  2630 net.cpp:198] Scale52 needs backward computation.
I0929 19:16:17.929329  2630 net.cpp:198] BatchNorm52 needs backward computation.
I0929 19:16:17.929332  2630 net.cpp:198] Convolution52 needs backward computation.
I0929 19:16:17.929334  2630 net.cpp:198] Eltwise24_ReLU49_0_split needs backward computation.
I0929 19:16:17.929337  2630 net.cpp:198] ReLU49 needs backward computation.
I0929 19:16:17.929338  2630 net.cpp:198] Eltwise24 needs backward computation.
I0929 19:16:17.929342  2630 net.cpp:198] Scale51 needs backward computation.
I0929 19:16:17.929349  2630 net.cpp:198] BatchNorm51 needs backward computation.
I0929 19:16:17.929352  2630 net.cpp:198] Convolution51 needs backward computation.
I0929 19:16:17.929354  2630 net.cpp:198] ReLU48 needs backward computation.
I0929 19:16:17.929356  2630 net.cpp:198] Scale50 needs backward computation.
I0929 19:16:17.929358  2630 net.cpp:198] BatchNorm50 needs backward computation.
I0929 19:16:17.929361  2630 net.cpp:198] Convolution50 needs backward computation.
I0929 19:16:17.929363  2630 net.cpp:198] Eltwise23_ReLU47_0_split needs backward computation.
I0929 19:16:17.929366  2630 net.cpp:198] ReLU47 needs backward computation.
I0929 19:16:17.929368  2630 net.cpp:198] Eltwise23 needs backward computation.
I0929 19:16:17.929371  2630 net.cpp:198] Scale49 needs backward computation.
I0929 19:16:17.929373  2630 net.cpp:198] BatchNorm49 needs backward computation.
I0929 19:16:17.929375  2630 net.cpp:198] Convolution49 needs backward computation.
I0929 19:16:17.929378  2630 net.cpp:198] ReLU46 needs backward computation.
I0929 19:16:17.929380  2630 net.cpp:198] Scale48 needs backward computation.
I0929 19:16:17.929383  2630 net.cpp:198] BatchNorm48 needs backward computation.
I0929 19:16:17.929385  2630 net.cpp:198] Convolution48 needs backward computation.
I0929 19:16:17.929388  2630 net.cpp:198] Eltwise22_ReLU45_0_split needs backward computation.
I0929 19:16:17.929390  2630 net.cpp:198] ReLU45 needs backward computation.
I0929 19:16:17.929392  2630 net.cpp:198] Eltwise22 needs backward computation.
I0929 19:16:17.929395  2630 net.cpp:198] Scale47 needs backward computation.
I0929 19:16:17.929397  2630 net.cpp:198] BatchNorm47 needs backward computation.
I0929 19:16:17.929399  2630 net.cpp:198] Convolution47 needs backward computation.
I0929 19:16:17.929401  2630 net.cpp:198] ReLU44 needs backward computation.
I0929 19:16:17.929404  2630 net.cpp:198] Scale46 needs backward computation.
I0929 19:16:17.929406  2630 net.cpp:198] BatchNorm46 needs backward computation.
I0929 19:16:17.929409  2630 net.cpp:198] Convolution46 needs backward computation.
I0929 19:16:17.929411  2630 net.cpp:198] Eltwise21_ReLU43_0_split needs backward computation.
I0929 19:16:17.929414  2630 net.cpp:198] ReLU43 needs backward computation.
I0929 19:16:17.929415  2630 net.cpp:198] Eltwise21 needs backward computation.
I0929 19:16:17.929419  2630 net.cpp:198] Scale45 needs backward computation.
I0929 19:16:17.929420  2630 net.cpp:198] BatchNorm45 needs backward computation.
I0929 19:16:17.929422  2630 net.cpp:198] Convolution45 needs backward computation.
I0929 19:16:17.929425  2630 net.cpp:198] ReLU42 needs backward computation.
I0929 19:16:17.929427  2630 net.cpp:198] Scale44 needs backward computation.
I0929 19:16:17.929430  2630 net.cpp:198] BatchNorm44 needs backward computation.
I0929 19:16:17.929431  2630 net.cpp:198] Convolution44 needs backward computation.
I0929 19:16:17.929433  2630 net.cpp:198] Eltwise20_ReLU41_0_split needs backward computation.
I0929 19:16:17.929436  2630 net.cpp:198] ReLU41 needs backward computation.
I0929 19:16:17.929438  2630 net.cpp:198] Eltwise20 needs backward computation.
I0929 19:16:17.929441  2630 net.cpp:198] Scale43 needs backward computation.
I0929 19:16:17.929443  2630 net.cpp:198] BatchNorm43 needs backward computation.
I0929 19:16:17.929445  2630 net.cpp:198] Convolution43 needs backward computation.
I0929 19:16:17.929448  2630 net.cpp:198] ReLU40 needs backward computation.
I0929 19:16:17.929450  2630 net.cpp:198] Scale42 needs backward computation.
I0929 19:16:17.929452  2630 net.cpp:198] BatchNorm42 needs backward computation.
I0929 19:16:17.929455  2630 net.cpp:198] Convolution42 needs backward computation.
I0929 19:16:17.929457  2630 net.cpp:198] Eltwise19_ReLU39_0_split needs backward computation.
I0929 19:16:17.929460  2630 net.cpp:198] ReLU39 needs backward computation.
I0929 19:16:17.929462  2630 net.cpp:198] Eltwise19 needs backward computation.
I0929 19:16:17.929466  2630 net.cpp:198] Scale41 needs backward computation.
I0929 19:16:17.929467  2630 net.cpp:198] BatchNorm41 needs backward computation.
I0929 19:16:17.929472  2630 net.cpp:198] Convolution41 needs backward computation.
I0929 19:16:17.929476  2630 net.cpp:198] ReLU38 needs backward computation.
I0929 19:16:17.929477  2630 net.cpp:198] Scale40 needs backward computation.
I0929 19:16:17.929479  2630 net.cpp:198] BatchNorm40 needs backward computation.
I0929 19:16:17.929482  2630 net.cpp:198] Convolution40 needs backward computation.
I0929 19:16:17.929484  2630 net.cpp:198] Scale39 needs backward computation.
I0929 19:16:17.929487  2630 net.cpp:198] BatchNorm39 needs backward computation.
I0929 19:16:17.929489  2630 net.cpp:198] Convolution39 needs backward computation.
I0929 19:16:17.929492  2630 net.cpp:198] Eltwise18_ReLU37_0_split needs backward computation.
I0929 19:16:17.929494  2630 net.cpp:198] ReLU37 needs backward computation.
I0929 19:16:17.929497  2630 net.cpp:198] Eltwise18 needs backward computation.
I0929 19:16:17.929500  2630 net.cpp:198] Scale38 needs backward computation.
I0929 19:16:17.929502  2630 net.cpp:198] BatchNorm38 needs backward computation.
I0929 19:16:17.929504  2630 net.cpp:198] Convolution38 needs backward computation.
I0929 19:16:17.929507  2630 net.cpp:198] ReLU36 needs backward computation.
I0929 19:16:17.929509  2630 net.cpp:198] Scale37 needs backward computation.
I0929 19:16:17.929512  2630 net.cpp:198] BatchNorm37 needs backward computation.
I0929 19:16:17.929513  2630 net.cpp:198] Convolution37 needs backward computation.
I0929 19:16:17.929517  2630 net.cpp:198] Eltwise17_ReLU35_0_split needs backward computation.
I0929 19:16:17.929518  2630 net.cpp:198] ReLU35 needs backward computation.
I0929 19:16:17.929520  2630 net.cpp:198] Eltwise17 needs backward computation.
I0929 19:16:17.929523  2630 net.cpp:198] Scale36 needs backward computation.
I0929 19:16:17.929525  2630 net.cpp:198] BatchNorm36 needs backward computation.
I0929 19:16:17.929527  2630 net.cpp:198] Convolution36 needs backward computation.
I0929 19:16:17.929530  2630 net.cpp:198] ReLU34 needs backward computation.
I0929 19:16:17.929533  2630 net.cpp:198] Scale35 needs backward computation.
I0929 19:16:17.929534  2630 net.cpp:198] BatchNorm35 needs backward computation.
I0929 19:16:17.929538  2630 net.cpp:198] Convolution35 needs backward computation.
I0929 19:16:17.929539  2630 net.cpp:198] Eltwise16_ReLU33_0_split needs backward computation.
I0929 19:16:17.929541  2630 net.cpp:198] ReLU33 needs backward computation.
I0929 19:16:17.929544  2630 net.cpp:198] Eltwise16 needs backward computation.
I0929 19:16:17.929546  2630 net.cpp:198] Scale34 needs backward computation.
I0929 19:16:17.929548  2630 net.cpp:198] BatchNorm34 needs backward computation.
I0929 19:16:17.929551  2630 net.cpp:198] Convolution34 needs backward computation.
I0929 19:16:17.929553  2630 net.cpp:198] ReLU32 needs backward computation.
I0929 19:16:17.929555  2630 net.cpp:198] Scale33 needs backward computation.
I0929 19:16:17.929558  2630 net.cpp:198] BatchNorm33 needs backward computation.
I0929 19:16:17.929559  2630 net.cpp:198] Convolution33 needs backward computation.
I0929 19:16:17.929563  2630 net.cpp:198] Eltwise15_ReLU31_0_split needs backward computation.
I0929 19:16:17.929565  2630 net.cpp:198] ReLU31 needs backward computation.
I0929 19:16:17.929569  2630 net.cpp:198] Eltwise15 needs backward computation.
I0929 19:16:17.929570  2630 net.cpp:198] Scale32 needs backward computation.
I0929 19:16:17.929572  2630 net.cpp:198] BatchNorm32 needs backward computation.
I0929 19:16:17.929575  2630 net.cpp:198] Convolution32 needs backward computation.
I0929 19:16:17.929577  2630 net.cpp:198] ReLU30 needs backward computation.
I0929 19:16:17.929579  2630 net.cpp:198] Scale31 needs backward computation.
I0929 19:16:17.929581  2630 net.cpp:198] BatchNorm31 needs backward computation.
I0929 19:16:17.929584  2630 net.cpp:198] Convolution31 needs backward computation.
I0929 19:16:17.929586  2630 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I0929 19:16:17.929589  2630 net.cpp:198] ReLU29 needs backward computation.
I0929 19:16:17.929591  2630 net.cpp:198] Eltwise14 needs backward computation.
I0929 19:16:17.929599  2630 net.cpp:198] Scale30 needs backward computation.
I0929 19:16:17.929600  2630 net.cpp:198] BatchNorm30 needs backward computation.
I0929 19:16:17.929602  2630 net.cpp:198] Convolution30 needs backward computation.
I0929 19:16:17.929605  2630 net.cpp:198] ReLU28 needs backward computation.
I0929 19:16:17.929607  2630 net.cpp:198] Scale29 needs backward computation.
I0929 19:16:17.955334  2630 net.cpp:198] BatchNorm29 needs backward computation.
I0929 19:16:17.955344  2630 net.cpp:198] Convolution29 needs backward computation.
I0929 19:16:17.955350  2630 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I0929 19:16:17.955354  2630 net.cpp:198] ReLU27 needs backward computation.
I0929 19:16:17.955359  2630 net.cpp:198] Eltwise13 needs backward computation.
I0929 19:16:17.955363  2630 net.cpp:198] Scale28 needs backward computation.
I0929 19:16:17.955368  2630 net.cpp:198] BatchNorm28 needs backward computation.
I0929 19:16:17.955371  2630 net.cpp:198] Convolution28 needs backward computation.
I0929 19:16:17.955375  2630 net.cpp:198] ReLU26 needs backward computation.
I0929 19:16:17.955379  2630 net.cpp:198] Scale27 needs backward computation.
I0929 19:16:17.955384  2630 net.cpp:198] BatchNorm27 needs backward computation.
I0929 19:16:17.955387  2630 net.cpp:198] Convolution27 needs backward computation.
I0929 19:16:17.955392  2630 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I0929 19:16:17.955396  2630 net.cpp:198] ReLU25 needs backward computation.
I0929 19:16:17.955400  2630 net.cpp:198] Eltwise12 needs backward computation.
I0929 19:16:17.955404  2630 net.cpp:198] Scale26 needs backward computation.
I0929 19:16:17.955406  2630 net.cpp:198] BatchNorm26 needs backward computation.
I0929 19:16:17.955409  2630 net.cpp:198] Convolution26 needs backward computation.
I0929 19:16:17.955411  2630 net.cpp:198] ReLU24 needs backward computation.
I0929 19:16:17.955413  2630 net.cpp:198] Scale25 needs backward computation.
I0929 19:16:17.955416  2630 net.cpp:198] BatchNorm25 needs backward computation.
I0929 19:16:17.955418  2630 net.cpp:198] Convolution25 needs backward computation.
I0929 19:16:17.955421  2630 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0929 19:16:17.955423  2630 net.cpp:198] ReLU23 needs backward computation.
I0929 19:16:17.955426  2630 net.cpp:198] Eltwise11 needs backward computation.
I0929 19:16:17.955428  2630 net.cpp:198] Scale24 needs backward computation.
I0929 19:16:17.955431  2630 net.cpp:198] BatchNorm24 needs backward computation.
I0929 19:16:17.955433  2630 net.cpp:198] Convolution24 needs backward computation.
I0929 19:16:17.955436  2630 net.cpp:198] ReLU22 needs backward computation.
I0929 19:16:17.955438  2630 net.cpp:198] Scale23 needs backward computation.
I0929 19:16:17.955441  2630 net.cpp:198] BatchNorm23 needs backward computation.
I0929 19:16:17.955443  2630 net.cpp:198] Convolution23 needs backward computation.
I0929 19:16:17.955446  2630 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I0929 19:16:17.955448  2630 net.cpp:198] ReLU21 needs backward computation.
I0929 19:16:17.955451  2630 net.cpp:198] Eltwise10 needs backward computation.
I0929 19:16:17.955454  2630 net.cpp:198] Scale22 needs backward computation.
I0929 19:16:17.955456  2630 net.cpp:198] BatchNorm22 needs backward computation.
I0929 19:16:17.955458  2630 net.cpp:198] Convolution22 needs backward computation.
I0929 19:16:17.955461  2630 net.cpp:198] ReLU20 needs backward computation.
I0929 19:16:17.955463  2630 net.cpp:198] Scale21 needs backward computation.
I0929 19:16:17.955466  2630 net.cpp:198] BatchNorm21 needs backward computation.
I0929 19:16:17.955468  2630 net.cpp:198] Convolution21 needs backward computation.
I0929 19:16:17.955471  2630 net.cpp:198] Scale20 needs backward computation.
I0929 19:16:17.955473  2630 net.cpp:198] BatchNorm20 needs backward computation.
I0929 19:16:17.955476  2630 net.cpp:198] Convolution20 needs backward computation.
I0929 19:16:17.955478  2630 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0929 19:16:17.955487  2630 net.cpp:198] ReLU19 needs backward computation.
I0929 19:16:17.955490  2630 net.cpp:198] Eltwise9 needs backward computation.
I0929 19:16:17.955493  2630 net.cpp:198] Scale19 needs backward computation.
I0929 19:16:17.955497  2630 net.cpp:198] BatchNorm19 needs backward computation.
I0929 19:16:17.955500  2630 net.cpp:198] Convolution19 needs backward computation.
I0929 19:16:17.955502  2630 net.cpp:198] ReLU18 needs backward computation.
I0929 19:16:17.955505  2630 net.cpp:198] Scale18 needs backward computation.
I0929 19:16:17.955507  2630 net.cpp:198] BatchNorm18 needs backward computation.
I0929 19:16:17.955509  2630 net.cpp:198] Convolution18 needs backward computation.
I0929 19:16:17.955513  2630 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0929 19:16:17.955515  2630 net.cpp:198] ReLU17 needs backward computation.
I0929 19:16:17.955518  2630 net.cpp:198] Eltwise8 needs backward computation.
I0929 19:16:17.955520  2630 net.cpp:198] Scale17 needs backward computation.
I0929 19:16:17.955523  2630 net.cpp:198] BatchNorm17 needs backward computation.
I0929 19:16:17.955525  2630 net.cpp:198] Convolution17 needs backward computation.
I0929 19:16:17.955528  2630 net.cpp:198] ReLU16 needs backward computation.
I0929 19:16:17.955530  2630 net.cpp:198] Scale16 needs backward computation.
I0929 19:16:17.955533  2630 net.cpp:198] BatchNorm16 needs backward computation.
I0929 19:16:17.955534  2630 net.cpp:198] Convolution16 needs backward computation.
I0929 19:16:17.955538  2630 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0929 19:16:17.955539  2630 net.cpp:198] ReLU15 needs backward computation.
I0929 19:16:17.955543  2630 net.cpp:198] Eltwise7 needs backward computation.
I0929 19:16:17.955545  2630 net.cpp:198] Scale15 needs backward computation.
I0929 19:16:17.955548  2630 net.cpp:198] BatchNorm15 needs backward computation.
I0929 19:16:17.955550  2630 net.cpp:198] Convolution15 needs backward computation.
I0929 19:16:17.955552  2630 net.cpp:198] ReLU14 needs backward computation.
I0929 19:16:17.955555  2630 net.cpp:198] Scale14 needs backward computation.
I0929 19:16:17.955557  2630 net.cpp:198] BatchNorm14 needs backward computation.
I0929 19:16:17.955559  2630 net.cpp:198] Convolution14 needs backward computation.
I0929 19:16:17.955562  2630 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0929 19:16:17.955565  2630 net.cpp:198] ReLU13 needs backward computation.
I0929 19:16:17.955567  2630 net.cpp:198] Eltwise6 needs backward computation.
I0929 19:16:17.955570  2630 net.cpp:198] Scale13 needs backward computation.
I0929 19:16:17.955574  2630 net.cpp:198] BatchNorm13 needs backward computation.
I0929 19:16:17.955575  2630 net.cpp:198] Convolution13 needs backward computation.
I0929 19:16:17.955579  2630 net.cpp:198] ReLU12 needs backward computation.
I0929 19:16:17.955580  2630 net.cpp:198] Scale12 needs backward computation.
I0929 19:16:17.955582  2630 net.cpp:198] BatchNorm12 needs backward computation.
I0929 19:16:17.955585  2630 net.cpp:198] Convolution12 needs backward computation.
I0929 19:16:17.955587  2630 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0929 19:16:17.955590  2630 net.cpp:198] ReLU11 needs backward computation.
I0929 19:16:17.955592  2630 net.cpp:198] Eltwise5 needs backward computation.
I0929 19:16:17.955595  2630 net.cpp:198] Scale11 needs backward computation.
I0929 19:16:17.955597  2630 net.cpp:198] BatchNorm11 needs backward computation.
I0929 19:16:17.955600  2630 net.cpp:198] Convolution11 needs backward computation.
I0929 19:16:17.955602  2630 net.cpp:198] ReLU10 needs backward computation.
I0929 19:16:17.955605  2630 net.cpp:198] Scale10 needs backward computation.
I0929 19:16:17.955607  2630 net.cpp:198] BatchNorm10 needs backward computation.
I0929 19:16:17.955610  2630 net.cpp:198] Convolution10 needs backward computation.
I0929 19:16:17.955612  2630 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0929 19:16:17.955618  2630 net.cpp:198] ReLU9 needs backward computation.
I0929 19:16:17.955621  2630 net.cpp:198] Eltwise4 needs backward computation.
I0929 19:16:17.955626  2630 net.cpp:198] Scale9 needs backward computation.
I0929 19:16:17.955627  2630 net.cpp:198] BatchNorm9 needs backward computation.
I0929 19:16:17.957752  2630 net.cpp:198] Convolution9 needs backward computation.
I0929 19:16:17.957772  2630 net.cpp:198] ReLU8 needs backward computation.
I0929 19:16:17.957777  2630 net.cpp:198] Scale8 needs backward computation.
I0929 19:16:17.957789  2630 net.cpp:198] BatchNorm8 needs backward computation.
I0929 19:16:17.957792  2630 net.cpp:198] Convolution8 needs backward computation.
I0929 19:16:17.957798  2630 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0929 19:16:17.957801  2630 net.cpp:198] ReLU7 needs backward computation.
I0929 19:16:17.957804  2630 net.cpp:198] Eltwise3 needs backward computation.
I0929 19:16:17.957809  2630 net.cpp:198] Scale7 needs backward computation.
I0929 19:16:17.957813  2630 net.cpp:198] BatchNorm7 needs backward computation.
I0929 19:16:17.957816  2630 net.cpp:198] Convolution7 needs backward computation.
I0929 19:16:17.957820  2630 net.cpp:198] ReLU6 needs backward computation.
I0929 19:16:17.957831  2630 net.cpp:198] Scale6 needs backward computation.
I0929 19:16:17.957835  2630 net.cpp:198] BatchNorm6 needs backward computation.
I0929 19:16:17.957839  2630 net.cpp:198] Convolution6 needs backward computation.
I0929 19:16:17.957844  2630 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0929 19:16:17.957847  2630 net.cpp:198] ReLU5 needs backward computation.
I0929 19:16:17.957850  2630 net.cpp:198] Eltwise2 needs backward computation.
I0929 19:16:17.957855  2630 net.cpp:198] Scale5 needs backward computation.
I0929 19:16:17.957859  2630 net.cpp:198] BatchNorm5 needs backward computation.
I0929 19:16:17.957862  2630 net.cpp:198] Convolution5 needs backward computation.
I0929 19:16:17.957866  2630 net.cpp:198] ReLU4 needs backward computation.
I0929 19:16:17.957870  2630 net.cpp:198] Scale4 needs backward computation.
I0929 19:16:17.957871  2630 net.cpp:198] BatchNorm4 needs backward computation.
I0929 19:16:17.957873  2630 net.cpp:198] Convolution4 needs backward computation.
I0929 19:16:17.957876  2630 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0929 19:16:17.957878  2630 net.cpp:198] ReLU3 needs backward computation.
I0929 19:16:17.957881  2630 net.cpp:198] Eltwise1 needs backward computation.
I0929 19:16:17.957885  2630 net.cpp:198] Scale3 needs backward computation.
I0929 19:16:17.957886  2630 net.cpp:198] BatchNorm3 needs backward computation.
I0929 19:16:17.957888  2630 net.cpp:198] Convolution3 needs backward computation.
I0929 19:16:17.957890  2630 net.cpp:198] ReLU2 needs backward computation.
I0929 19:16:17.957893  2630 net.cpp:198] Scale2 needs backward computation.
I0929 19:16:17.957895  2630 net.cpp:198] BatchNorm2 needs backward computation.
I0929 19:16:17.957897  2630 net.cpp:198] Convolution2 needs backward computation.
I0929 19:16:17.957901  2630 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0929 19:16:17.957902  2630 net.cpp:198] ReLU1 needs backward computation.
I0929 19:16:17.957906  2630 net.cpp:198] Scale1 needs backward computation.
I0929 19:16:17.957907  2630 net.cpp:198] BatchNorm1 needs backward computation.
I0929 19:16:17.957909  2630 net.cpp:198] Convolution1 needs backward computation.
I0929 19:16:17.957912  2630 net.cpp:200] Data1 does not need backward computation.
I0929 19:16:17.957914  2630 net.cpp:242] This network produces output SoftmaxWithLoss1
I0929 19:16:17.958004  2630 net.cpp:255] Network initialization done.
I0929 19:16:17.961470  2630 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_relu_msra.prototxt
I0929 19:16:17.961483  2630 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0929 19:16:17.961486  2630 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_relu_msra.prototxt
I0929 19:16:17.961664  2630 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0929 19:16:17.962553  2630 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution32"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  botto
I0929 19:16:18.019852  2630 layer_factory.hpp:77] Creating layer Data1
I0929 19:16:18.019906  2630 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0929 19:16:18.019918  2630 net.cpp:84] Creating Layer Data1
I0929 19:16:18.019924  2630 net.cpp:380] Data1 -> Data1
I0929 19:16:18.019933  2630 net.cpp:380] Data1 -> Data2
I0929 19:16:18.019939  2630 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0929 19:16:18.020128  2630 data_layer.cpp:45] output data size: 100,3,32,32
I0929 19:16:18.024255  2630 net.cpp:122] Setting up Data1
I0929 19:16:18.024276  2630 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0929 19:16:18.024279  2630 net.cpp:129] Top shape: 100 (100)
I0929 19:16:18.024282  2630 net.cpp:137] Memory required for data: 1229200
I0929 19:16:18.024286  2630 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0929 19:16:18.024296  2630 net.cpp:84] Creating Layer Data2_Data1_1_split
I0929 19:16:18.024299  2630 net.cpp:406] Data2_Data1_1_split <- Data2
I0929 19:16:18.024305  2630 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0929 19:16:18.024312  2630 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0929 19:16:18.024408  2630 net.cpp:122] Setting up Data2_Data1_1_split
I0929 19:16:18.024418  2630 net.cpp:129] Top shape: 100 (100)
I0929 19:16:18.024421  2630 net.cpp:129] Top shape: 100 (100)
I0929 19:16:18.024423  2630 net.cpp:137] Memory required for data: 1230000
I0929 19:16:18.024426  2630 layer_factory.hpp:77] Creating layer Convolution1
I0929 19:16:18.024437  2630 net.cpp:84] Creating Layer Convolution1
I0929 19:16:18.024441  2630 net.cpp:406] Convolution1 <- Data1
I0929 19:16:18.024444  2630 net.cpp:380] Convolution1 -> Convolution1
I0929 19:16:18.025760  2630 net.cpp:122] Setting up Convolution1
I0929 19:16:18.025773  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.025775  2630 net.cpp:137] Memory required for data: 7783600
I0929 19:16:18.025784  2630 layer_factory.hpp:77] Creating layer BatchNorm1
I0929 19:16:18.025789  2630 net.cpp:84] Creating Layer BatchNorm1
I0929 19:16:18.025791  2630 net.cpp:406] BatchNorm1 <- Convolution1
I0929 19:16:18.025801  2630 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0929 19:16:18.025964  2630 net.cpp:122] Setting up BatchNorm1
I0929 19:16:18.025969  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.025974  2630 net.cpp:137] Memory required for data: 14337200
I0929 19:16:18.025980  2630 layer_factory.hpp:77] Creating layer Scale1
I0929 19:16:18.026000  2630 net.cpp:84] Creating Layer Scale1
I0929 19:16:18.026003  2630 net.cpp:406] Scale1 <- Convolution1
I0929 19:16:18.026007  2630 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0929 19:16:18.026041  2630 layer_factory.hpp:77] Creating layer Scale1
I0929 19:16:18.026131  2630 net.cpp:122] Setting up Scale1
I0929 19:16:18.026135  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.026139  2630 net.cpp:137] Memory required for data: 20890800
I0929 19:16:18.026144  2630 layer_factory.hpp:77] Creating layer ReLU1
I0929 19:16:18.026147  2630 net.cpp:84] Creating Layer ReLU1
I0929 19:16:18.026151  2630 net.cpp:406] ReLU1 <- Convolution1
I0929 19:16:18.026154  2630 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0929 19:16:18.026304  2630 net.cpp:122] Setting up ReLU1
I0929 19:16:18.026309  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.026312  2630 net.cpp:137] Memory required for data: 27444400
I0929 19:16:18.026314  2630 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0929 19:16:18.026319  2630 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0929 19:16:18.026321  2630 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0929 19:16:18.026325  2630 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0929 19:16:18.026330  2630 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0929 19:16:18.026363  2630 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0929 19:16:18.026367  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.047286  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.047296  2630 net.cpp:137] Memory required for data: 40551600
I0929 19:16:18.047300  2630 layer_factory.hpp:77] Creating layer Convolution2
I0929 19:16:18.047313  2630 net.cpp:84] Creating Layer Convolution2
I0929 19:16:18.047318  2630 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0929 19:16:18.047327  2630 net.cpp:380] Convolution2 -> Convolution2
I0929 19:16:18.048503  2630 net.cpp:122] Setting up Convolution2
I0929 19:16:18.048511  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.048514  2630 net.cpp:137] Memory required for data: 47105200
I0929 19:16:18.048521  2630 layer_factory.hpp:77] Creating layer BatchNorm2
I0929 19:16:18.048528  2630 net.cpp:84] Creating Layer BatchNorm2
I0929 19:16:18.048532  2630 net.cpp:406] BatchNorm2 <- Convolution2
I0929 19:16:18.048545  2630 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0929 19:16:18.048732  2630 net.cpp:122] Setting up BatchNorm2
I0929 19:16:18.048737  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.048738  2630 net.cpp:137] Memory required for data: 53658800
I0929 19:16:18.048743  2630 layer_factory.hpp:77] Creating layer Scale2
I0929 19:16:18.048748  2630 net.cpp:84] Creating Layer Scale2
I0929 19:16:18.048750  2630 net.cpp:406] Scale2 <- Convolution2
I0929 19:16:18.048753  2630 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0929 19:16:18.048789  2630 layer_factory.hpp:77] Creating layer Scale2
I0929 19:16:18.048879  2630 net.cpp:122] Setting up Scale2
I0929 19:16:18.048884  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.048887  2630 net.cpp:137] Memory required for data: 60212400
I0929 19:16:18.048890  2630 layer_factory.hpp:77] Creating layer ReLU2
I0929 19:16:18.048894  2630 net.cpp:84] Creating Layer ReLU2
I0929 19:16:18.048897  2630 net.cpp:406] ReLU2 <- Convolution2
I0929 19:16:18.048900  2630 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0929 19:16:18.049031  2630 net.cpp:122] Setting up ReLU2
I0929 19:16:18.049037  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.049041  2630 net.cpp:137] Memory required for data: 66766000
I0929 19:16:18.049042  2630 layer_factory.hpp:77] Creating layer Convolution3
I0929 19:16:18.049049  2630 net.cpp:84] Creating Layer Convolution3
I0929 19:16:18.049052  2630 net.cpp:406] Convolution3 <- Convolution2
I0929 19:16:18.049057  2630 net.cpp:380] Convolution3 -> Convolution3
I0929 19:16:18.050215  2630 net.cpp:122] Setting up Convolution3
I0929 19:16:18.050225  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.050227  2630 net.cpp:137] Memory required for data: 73319600
I0929 19:16:18.050231  2630 layer_factory.hpp:77] Creating layer BatchNorm3
I0929 19:16:18.050237  2630 net.cpp:84] Creating Layer BatchNorm3
I0929 19:16:18.050240  2630 net.cpp:406] BatchNorm3 <- Convolution3
I0929 19:16:18.050243  2630 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0929 19:16:18.050403  2630 net.cpp:122] Setting up BatchNorm3
I0929 19:16:18.050407  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.050410  2630 net.cpp:137] Memory required for data: 79873200
I0929 19:16:18.050417  2630 layer_factory.hpp:77] Creating layer Scale3
I0929 19:16:18.050421  2630 net.cpp:84] Creating Layer Scale3
I0929 19:16:18.050423  2630 net.cpp:406] Scale3 <- Convolution3
I0929 19:16:18.050426  2630 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0929 19:16:18.050458  2630 layer_factory.hpp:77] Creating layer Scale3
I0929 19:16:18.050578  2630 net.cpp:122] Setting up Scale3
I0929 19:16:18.050583  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.050585  2630 net.cpp:137] Memory required for data: 86426800
I0929 19:16:18.050590  2630 layer_factory.hpp:77] Creating layer Eltwise1
I0929 19:16:18.050595  2630 net.cpp:84] Creating Layer Eltwise1
I0929 19:16:18.050596  2630 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0929 19:16:18.050599  2630 net.cpp:406] Eltwise1 <- Convolution3
I0929 19:16:18.050603  2630 net.cpp:380] Eltwise1 -> Eltwise1
I0929 19:16:18.050621  2630 net.cpp:122] Setting up Eltwise1
I0929 19:16:18.050624  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.050626  2630 net.cpp:137] Memory required for data: 92980400
I0929 19:16:18.050628  2630 layer_factory.hpp:77] Creating layer ReLU3
I0929 19:16:18.050633  2630 net.cpp:84] Creating Layer ReLU3
I0929 19:16:18.050635  2630 net.cpp:406] ReLU3 <- Eltwise1
I0929 19:16:18.050638  2630 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0929 19:16:18.050765  2630 net.cpp:122] Setting up ReLU3
I0929 19:16:18.050770  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.050772  2630 net.cpp:137] Memory required for data: 99534000
I0929 19:16:18.050776  2630 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0929 19:16:18.050781  2630 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0929 19:16:18.050783  2630 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0929 19:16:18.050787  2630 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0929 19:16:18.050792  2630 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0929 19:16:18.050823  2630 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0929 19:16:18.050828  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.050832  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.050833  2630 net.cpp:137] Memory required for data: 112641200
I0929 19:16:18.050835  2630 layer_factory.hpp:77] Creating layer Convolution4
I0929 19:16:18.050842  2630 net.cpp:84] Creating Layer Convolution4
I0929 19:16:18.050844  2630 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0929 19:16:18.050848  2630 net.cpp:380] Convolution4 -> Convolution4
I0929 19:16:18.051894  2630 net.cpp:122] Setting up Convolution4
I0929 19:16:18.051903  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.051906  2630 net.cpp:137] Memory required for data: 119194800
I0929 19:16:18.051910  2630 layer_factory.hpp:77] Creating layer BatchNorm4
I0929 19:16:18.051916  2630 net.cpp:84] Creating Layer BatchNorm4
I0929 19:16:18.051918  2630 net.cpp:406] BatchNorm4 <- Convolution4
I0929 19:16:18.051923  2630 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0929 19:16:18.052084  2630 net.cpp:122] Setting up BatchNorm4
I0929 19:16:18.052089  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.052091  2630 net.cpp:137] Memory required for data: 125748400
I0929 19:16:18.052096  2630 layer_factory.hpp:77] Creating layer Scale4
I0929 19:16:18.052108  2630 net.cpp:84] Creating Layer Scale4
I0929 19:16:18.052109  2630 net.cpp:406] Scale4 <- Convolution4
I0929 19:16:18.052114  2630 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0929 19:16:18.052146  2630 layer_factory.hpp:77] Creating layer Scale4
I0929 19:16:18.052237  2630 net.cpp:122] Setting up Scale4
I0929 19:16:18.052240  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.052243  2630 net.cpp:137] Memory required for data: 132302000
I0929 19:16:18.052247  2630 layer_factory.hpp:77] Creating layer ReLU4
I0929 19:16:18.052250  2630 net.cpp:84] Creating Layer ReLU4
I0929 19:16:18.052253  2630 net.cpp:406] ReLU4 <- Convolution4
I0929 19:16:18.052258  2630 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0929 19:16:18.052386  2630 net.cpp:122] Setting up ReLU4
I0929 19:16:18.052392  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.052393  2630 net.cpp:137] Memory required for data: 138855600
I0929 19:16:18.052397  2630 layer_factory.hpp:77] Creating layer Convolution5
I0929 19:16:18.052402  2630 net.cpp:84] Creating Layer Convolution5
I0929 19:16:18.052405  2630 net.cpp:406] Convolution5 <- Convolution4
I0929 19:16:18.052410  2630 net.cpp:380] Convolution5 -> Convolution5
I0929 19:16:18.053385  2630 net.cpp:122] Setting up Convolution5
I0929 19:16:18.053393  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.053396  2630 net.cpp:137] Memory required for data: 145409200
I0929 19:16:18.053400  2630 layer_factory.hpp:77] Creating layer BatchNorm5
I0929 19:16:18.053406  2630 net.cpp:84] Creating Layer BatchNorm5
I0929 19:16:18.053408  2630 net.cpp:406] BatchNorm5 <- Convolution5
I0929 19:16:18.053413  2630 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0929 19:16:18.053570  2630 net.cpp:122] Setting up BatchNorm5
I0929 19:16:18.053575  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.053577  2630 net.cpp:137] Memory required for data: 151962800
I0929 19:16:18.053586  2630 layer_factory.hpp:77] Creating layer Scale5
I0929 19:16:18.053589  2630 net.cpp:84] Creating Layer Scale5
I0929 19:16:18.053591  2630 net.cpp:406] Scale5 <- Convolution5
I0929 19:16:18.053594  2630 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0929 19:16:18.053627  2630 layer_factory.hpp:77] Creating layer Scale5
I0929 19:16:18.053717  2630 net.cpp:122] Setting up Scale5
I0929 19:16:18.053721  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.053725  2630 net.cpp:137] Memory required for data: 158516400
I0929 19:16:18.053727  2630 layer_factory.hpp:77] Creating layer Eltwise2
I0929 19:16:18.053732  2630 net.cpp:84] Creating Layer Eltwise2
I0929 19:16:18.053735  2630 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0929 19:16:18.053737  2630 net.cpp:406] Eltwise2 <- Convolution5
I0929 19:16:18.053741  2630 net.cpp:380] Eltwise2 -> Eltwise2
I0929 19:16:18.053758  2630 net.cpp:122] Setting up Eltwise2
I0929 19:16:18.053762  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.053764  2630 net.cpp:137] Memory required for data: 165070000
I0929 19:16:18.053766  2630 layer_factory.hpp:77] Creating layer ReLU5
I0929 19:16:18.053771  2630 net.cpp:84] Creating Layer ReLU5
I0929 19:16:18.053773  2630 net.cpp:406] ReLU5 <- Eltwise2
I0929 19:16:18.053776  2630 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0929 19:16:18.054234  2630 net.cpp:122] Setting up ReLU5
I0929 19:16:18.054244  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.054246  2630 net.cpp:137] Memory required for data: 171623600
I0929 19:16:18.054249  2630 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0929 19:16:18.054253  2630 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0929 19:16:18.054255  2630 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0929 19:16:18.054260  2630 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0929 19:16:18.054263  2630 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0929 19:16:18.054299  2630 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0929 19:16:18.054309  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.054313  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.054316  2630 net.cpp:137] Memory required for data: 184730800
I0929 19:16:18.054317  2630 layer_factory.hpp:77] Creating layer Convolution6
I0929 19:16:18.054325  2630 net.cpp:84] Creating Layer Convolution6
I0929 19:16:18.054327  2630 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0929 19:16:18.054332  2630 net.cpp:380] Convolution6 -> Convolution6
I0929 19:16:18.054976  2630 net.cpp:122] Setting up Convolution6
I0929 19:16:18.054985  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.054986  2630 net.cpp:137] Memory required for data: 191284400
I0929 19:16:18.054991  2630 layer_factory.hpp:77] Creating layer BatchNorm6
I0929 19:16:18.054996  2630 net.cpp:84] Creating Layer BatchNorm6
I0929 19:16:18.054998  2630 net.cpp:406] BatchNorm6 <- Convolution6
I0929 19:16:18.055002  2630 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0929 19:16:18.055160  2630 net.cpp:122] Setting up BatchNorm6
I0929 19:16:18.055164  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.055167  2630 net.cpp:137] Memory required for data: 197838000
I0929 19:16:18.055171  2630 layer_factory.hpp:77] Creating layer Scale6
I0929 19:16:18.055176  2630 net.cpp:84] Creating Layer Scale6
I0929 19:16:18.055178  2630 net.cpp:406] Scale6 <- Convolution6
I0929 19:16:18.055181  2630 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0929 19:16:18.055212  2630 layer_factory.hpp:77] Creating layer Scale6
I0929 19:16:18.055299  2630 net.cpp:122] Setting up Scale6
I0929 19:16:18.055304  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.055305  2630 net.cpp:137] Memory required for data: 204391600
I0929 19:16:18.055310  2630 layer_factory.hpp:77] Creating layer ReLU6
I0929 19:16:18.055315  2630 net.cpp:84] Creating Layer ReLU6
I0929 19:16:18.055316  2630 net.cpp:406] ReLU6 <- Convolution6
I0929 19:16:18.055320  2630 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0929 19:16:18.055781  2630 net.cpp:122] Setting up ReLU6
I0929 19:16:18.055789  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.055793  2630 net.cpp:137] Memory required for data: 210945200
I0929 19:16:18.055794  2630 layer_factory.hpp:77] Creating layer Convolution7
I0929 19:16:18.055801  2630 net.cpp:84] Creating Layer Convolution7
I0929 19:16:18.055804  2630 net.cpp:406] Convolution7 <- Convolution6
I0929 19:16:18.055809  2630 net.cpp:380] Convolution7 -> Convolution7
I0929 19:16:18.057112  2630 net.cpp:122] Setting up Convolution7
I0929 19:16:18.057121  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.057123  2630 net.cpp:137] Memory required for data: 217498800
I0929 19:16:18.057128  2630 layer_factory.hpp:77] Creating layer BatchNorm7
I0929 19:16:18.057135  2630 net.cpp:84] Creating Layer BatchNorm7
I0929 19:16:18.057138  2630 net.cpp:406] BatchNorm7 <- Convolution7
I0929 19:16:18.057142  2630 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0929 19:16:18.057302  2630 net.cpp:122] Setting up BatchNorm7
I0929 19:16:18.057307  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.057309  2630 net.cpp:137] Memory required for data: 224052400
I0929 19:16:18.057314  2630 layer_factory.hpp:77] Creating layer Scale7
I0929 19:16:18.057318  2630 net.cpp:84] Creating Layer Scale7
I0929 19:16:18.057322  2630 net.cpp:406] Scale7 <- Convolution7
I0929 19:16:18.057324  2630 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0929 19:16:18.057355  2630 layer_factory.hpp:77] Creating layer Scale7
I0929 19:16:18.057445  2630 net.cpp:122] Setting up Scale7
I0929 19:16:18.057448  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.057451  2630 net.cpp:137] Memory required for data: 230606000
I0929 19:16:18.057454  2630 layer_factory.hpp:77] Creating layer Eltwise3
I0929 19:16:18.057458  2630 net.cpp:84] Creating Layer Eltwise3
I0929 19:16:18.057461  2630 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0929 19:16:18.057464  2630 net.cpp:406] Eltwise3 <- Convolution7
I0929 19:16:18.057473  2630 net.cpp:380] Eltwise3 -> Eltwise3
I0929 19:16:18.057494  2630 net.cpp:122] Setting up Eltwise3
I0929 19:16:18.057498  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.057500  2630 net.cpp:137] Memory required for data: 237159600
I0929 19:16:18.057502  2630 layer_factory.hpp:77] Creating layer ReLU7
I0929 19:16:18.057505  2630 net.cpp:84] Creating Layer ReLU7
I0929 19:16:18.057508  2630 net.cpp:406] ReLU7 <- Eltwise3
I0929 19:16:18.057512  2630 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0929 19:16:18.057638  2630 net.cpp:122] Setting up ReLU7
I0929 19:16:18.057644  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.057647  2630 net.cpp:137] Memory required for data: 243713200
I0929 19:16:18.057649  2630 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0929 19:16:18.057653  2630 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0929 19:16:18.057656  2630 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0929 19:16:18.057659  2630 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0929 19:16:18.057663  2630 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0929 19:16:18.057695  2630 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0929 19:16:18.057699  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.057703  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.057704  2630 net.cpp:137] Memory required for data: 256820400
I0929 19:16:18.078100  2630 layer_factory.hpp:77] Creating layer Convolution8
I0929 19:16:18.078119  2630 net.cpp:84] Creating Layer Convolution8
I0929 19:16:18.078125  2630 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0929 19:16:18.078133  2630 net.cpp:380] Convolution8 -> Convolution8
I0929 19:16:18.079232  2630 net.cpp:122] Setting up Convolution8
I0929 19:16:18.079242  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.079246  2630 net.cpp:137] Memory required for data: 263374000
I0929 19:16:18.079251  2630 layer_factory.hpp:77] Creating layer BatchNorm8
I0929 19:16:18.079257  2630 net.cpp:84] Creating Layer BatchNorm8
I0929 19:16:18.079259  2630 net.cpp:406] BatchNorm8 <- Convolution8
I0929 19:16:18.079264  2630 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0929 19:16:18.079439  2630 net.cpp:122] Setting up BatchNorm8
I0929 19:16:18.079444  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.079447  2630 net.cpp:137] Memory required for data: 269927600
I0929 19:16:18.079452  2630 layer_factory.hpp:77] Creating layer Scale8
I0929 19:16:18.079457  2630 net.cpp:84] Creating Layer Scale8
I0929 19:16:18.079460  2630 net.cpp:406] Scale8 <- Convolution8
I0929 19:16:18.079463  2630 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0929 19:16:18.079497  2630 layer_factory.hpp:77] Creating layer Scale8
I0929 19:16:18.079594  2630 net.cpp:122] Setting up Scale8
I0929 19:16:18.079599  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.079602  2630 net.cpp:137] Memory required for data: 276481200
I0929 19:16:18.079607  2630 layer_factory.hpp:77] Creating layer ReLU8
I0929 19:16:18.079610  2630 net.cpp:84] Creating Layer ReLU8
I0929 19:16:18.079613  2630 net.cpp:406] ReLU8 <- Convolution8
I0929 19:16:18.079617  2630 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0929 19:16:18.079777  2630 net.cpp:122] Setting up ReLU8
I0929 19:16:18.079789  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.079794  2630 net.cpp:137] Memory required for data: 283034800
I0929 19:16:18.079797  2630 layer_factory.hpp:77] Creating layer Convolution9
I0929 19:16:18.079805  2630 net.cpp:84] Creating Layer Convolution9
I0929 19:16:18.079808  2630 net.cpp:406] Convolution9 <- Convolution8
I0929 19:16:18.079813  2630 net.cpp:380] Convolution9 -> Convolution9
I0929 19:16:18.080893  2630 net.cpp:122] Setting up Convolution9
I0929 19:16:18.080901  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.080904  2630 net.cpp:137] Memory required for data: 289588400
I0929 19:16:18.080909  2630 layer_factory.hpp:77] Creating layer BatchNorm9
I0929 19:16:18.080919  2630 net.cpp:84] Creating Layer BatchNorm9
I0929 19:16:18.080922  2630 net.cpp:406] BatchNorm9 <- Convolution9
I0929 19:16:18.080927  2630 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0929 19:16:18.081089  2630 net.cpp:122] Setting up BatchNorm9
I0929 19:16:18.081094  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.081096  2630 net.cpp:137] Memory required for data: 296142000
I0929 19:16:18.081100  2630 layer_factory.hpp:77] Creating layer Scale9
I0929 19:16:18.081105  2630 net.cpp:84] Creating Layer Scale9
I0929 19:16:18.081107  2630 net.cpp:406] Scale9 <- Convolution9
I0929 19:16:18.081110  2630 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0929 19:16:18.081142  2630 layer_factory.hpp:77] Creating layer Scale9
I0929 19:16:18.081231  2630 net.cpp:122] Setting up Scale9
I0929 19:16:18.081235  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.081238  2630 net.cpp:137] Memory required for data: 302695600
I0929 19:16:18.081241  2630 layer_factory.hpp:77] Creating layer Eltwise4
I0929 19:16:18.081245  2630 net.cpp:84] Creating Layer Eltwise4
I0929 19:16:18.081248  2630 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0929 19:16:18.081251  2630 net.cpp:406] Eltwise4 <- Convolution9
I0929 19:16:18.081254  2630 net.cpp:380] Eltwise4 -> Eltwise4
I0929 19:16:18.081272  2630 net.cpp:122] Setting up Eltwise4
I0929 19:16:18.081276  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.081279  2630 net.cpp:137] Memory required for data: 309249200
I0929 19:16:18.081280  2630 layer_factory.hpp:77] Creating layer ReLU9
I0929 19:16:18.081285  2630 net.cpp:84] Creating Layer ReLU9
I0929 19:16:18.081287  2630 net.cpp:406] ReLU9 <- Eltwise4
I0929 19:16:18.081290  2630 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0929 19:16:18.081420  2630 net.cpp:122] Setting up ReLU9
I0929 19:16:18.081426  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.081429  2630 net.cpp:137] Memory required for data: 315802800
I0929 19:16:18.081431  2630 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0929 19:16:18.081434  2630 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0929 19:16:18.081437  2630 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0929 19:16:18.081452  2630 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0929 19:16:18.081457  2630 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0929 19:16:18.081490  2630 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0929 19:16:18.081493  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.081497  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.081499  2630 net.cpp:137] Memory required for data: 328910000
I0929 19:16:18.081501  2630 layer_factory.hpp:77] Creating layer Convolution10
I0929 19:16:18.081508  2630 net.cpp:84] Creating Layer Convolution10
I0929 19:16:18.081511  2630 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0929 19:16:18.081514  2630 net.cpp:380] Convolution10 -> Convolution10
I0929 19:16:18.082680  2630 net.cpp:122] Setting up Convolution10
I0929 19:16:18.082690  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.082692  2630 net.cpp:137] Memory required for data: 335463600
I0929 19:16:18.082705  2630 layer_factory.hpp:77] Creating layer BatchNorm10
I0929 19:16:18.082710  2630 net.cpp:84] Creating Layer BatchNorm10
I0929 19:16:18.082712  2630 net.cpp:406] BatchNorm10 <- Convolution10
I0929 19:16:18.082716  2630 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0929 19:16:18.082878  2630 net.cpp:122] Setting up BatchNorm10
I0929 19:16:18.082883  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.082885  2630 net.cpp:137] Memory required for data: 342017200
I0929 19:16:18.082890  2630 layer_factory.hpp:77] Creating layer Scale10
I0929 19:16:18.082895  2630 net.cpp:84] Creating Layer Scale10
I0929 19:16:18.082897  2630 net.cpp:406] Scale10 <- Convolution10
I0929 19:16:18.082901  2630 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0929 19:16:18.082942  2630 layer_factory.hpp:77] Creating layer Scale10
I0929 19:16:18.083032  2630 net.cpp:122] Setting up Scale10
I0929 19:16:18.083037  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.083039  2630 net.cpp:137] Memory required for data: 348570800
I0929 19:16:18.083043  2630 layer_factory.hpp:77] Creating layer ReLU10
I0929 19:16:18.083046  2630 net.cpp:84] Creating Layer ReLU10
I0929 19:16:18.083050  2630 net.cpp:406] ReLU10 <- Convolution10
I0929 19:16:18.083052  2630 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I0929 19:16:18.083180  2630 net.cpp:122] Setting up ReLU10
I0929 19:16:18.083186  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.083189  2630 net.cpp:137] Memory required for data: 355124400
I0929 19:16:18.083191  2630 layer_factory.hpp:77] Creating layer Convolution11
I0929 19:16:18.083199  2630 net.cpp:84] Creating Layer Convolution11
I0929 19:16:18.083202  2630 net.cpp:406] Convolution11 <- Convolution10
I0929 19:16:18.083206  2630 net.cpp:380] Convolution11 -> Convolution11
I0929 19:16:18.084503  2630 net.cpp:122] Setting up Convolution11
I0929 19:16:18.084512  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.084516  2630 net.cpp:137] Memory required for data: 361678000
I0929 19:16:18.084520  2630 layer_factory.hpp:77] Creating layer BatchNorm11
I0929 19:16:18.084525  2630 net.cpp:84] Creating Layer BatchNorm11
I0929 19:16:18.084528  2630 net.cpp:406] BatchNorm11 <- Convolution11
I0929 19:16:18.084532  2630 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0929 19:16:18.084702  2630 net.cpp:122] Setting up BatchNorm11
I0929 19:16:18.084707  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.084709  2630 net.cpp:137] Memory required for data: 368231600
I0929 19:16:18.084714  2630 layer_factory.hpp:77] Creating layer Scale11
I0929 19:16:18.084718  2630 net.cpp:84] Creating Layer Scale11
I0929 19:16:18.084722  2630 net.cpp:406] Scale11 <- Convolution11
I0929 19:16:18.084724  2630 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0929 19:16:18.084756  2630 layer_factory.hpp:77] Creating layer Scale11
I0929 19:16:18.084848  2630 net.cpp:122] Setting up Scale11
I0929 19:16:18.084852  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.084854  2630 net.cpp:137] Memory required for data: 374785200
I0929 19:16:18.084858  2630 layer_factory.hpp:77] Creating layer Eltwise5
I0929 19:16:18.084862  2630 net.cpp:84] Creating Layer Eltwise5
I0929 19:16:18.084866  2630 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0929 19:16:18.084868  2630 net.cpp:406] Eltwise5 <- Convolution11
I0929 19:16:18.084872  2630 net.cpp:380] Eltwise5 -> Eltwise5
I0929 19:16:18.084890  2630 net.cpp:122] Setting up Eltwise5
I0929 19:16:18.084893  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.084895  2630 net.cpp:137] Memory required for data: 381338800
I0929 19:16:18.084898  2630 layer_factory.hpp:77] Creating layer ReLU11
I0929 19:16:18.084903  2630 net.cpp:84] Creating Layer ReLU11
I0929 19:16:18.084904  2630 net.cpp:406] ReLU11 <- Eltwise5
I0929 19:16:18.084908  2630 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0929 19:16:18.085369  2630 net.cpp:122] Setting up ReLU11
I0929 19:16:18.085378  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.085381  2630 net.cpp:137] Memory required for data: 387892400
I0929 19:16:18.085383  2630 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0929 19:16:18.085387  2630 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0929 19:16:18.085389  2630 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0929 19:16:18.085393  2630 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0929 19:16:18.085397  2630 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0929 19:16:18.085433  2630 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0929 19:16:18.085436  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.085439  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.085441  2630 net.cpp:137] Memory required for data: 400999600
I0929 19:16:18.085449  2630 layer_factory.hpp:77] Creating layer Convolution12
I0929 19:16:18.085458  2630 net.cpp:84] Creating Layer Convolution12
I0929 19:16:18.085460  2630 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0929 19:16:18.085465  2630 net.cpp:380] Convolution12 -> Convolution12
I0929 19:16:18.086110  2630 net.cpp:122] Setting up Convolution12
I0929 19:16:18.086118  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.086122  2630 net.cpp:137] Memory required for data: 407553200
I0929 19:16:18.086125  2630 layer_factory.hpp:77] Creating layer BatchNorm12
I0929 19:16:18.086130  2630 net.cpp:84] Creating Layer BatchNorm12
I0929 19:16:18.086133  2630 net.cpp:406] BatchNorm12 <- Convolution12
I0929 19:16:18.086138  2630 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0929 19:16:18.086297  2630 net.cpp:122] Setting up BatchNorm12
I0929 19:16:18.086302  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.086304  2630 net.cpp:137] Memory required for data: 414106800
I0929 19:16:18.086309  2630 layer_factory.hpp:77] Creating layer Scale12
I0929 19:16:18.086313  2630 net.cpp:84] Creating Layer Scale12
I0929 19:16:18.086315  2630 net.cpp:406] Scale12 <- Convolution12
I0929 19:16:18.086319  2630 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0929 19:16:18.086350  2630 layer_factory.hpp:77] Creating layer Scale12
I0929 19:16:18.086441  2630 net.cpp:122] Setting up Scale12
I0929 19:16:18.086447  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.086448  2630 net.cpp:137] Memory required for data: 420660400
I0929 19:16:18.086452  2630 layer_factory.hpp:77] Creating layer ReLU12
I0929 19:16:18.086455  2630 net.cpp:84] Creating Layer ReLU12
I0929 19:16:18.086458  2630 net.cpp:406] ReLU12 <- Convolution12
I0929 19:16:18.086462  2630 net.cpp:367] ReLU12 -> Convolution12 (in-place)
I0929 19:16:18.086963  2630 net.cpp:122] Setting up ReLU12
I0929 19:16:18.086972  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.086974  2630 net.cpp:137] Memory required for data: 427214000
I0929 19:16:18.086977  2630 layer_factory.hpp:77] Creating layer Convolution13
I0929 19:16:18.086984  2630 net.cpp:84] Creating Layer Convolution13
I0929 19:16:18.086987  2630 net.cpp:406] Convolution13 <- Convolution12
I0929 19:16:18.086993  2630 net.cpp:380] Convolution13 -> Convolution13
I0929 19:16:18.088008  2630 net.cpp:122] Setting up Convolution13
I0929 19:16:18.088017  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.088021  2630 net.cpp:137] Memory required for data: 433767600
I0929 19:16:18.088024  2630 layer_factory.hpp:77] Creating layer BatchNorm13
I0929 19:16:18.088029  2630 net.cpp:84] Creating Layer BatchNorm13
I0929 19:16:18.088032  2630 net.cpp:406] BatchNorm13 <- Convolution13
I0929 19:16:18.088037  2630 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0929 19:16:18.088201  2630 net.cpp:122] Setting up BatchNorm13
I0929 19:16:18.088204  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.088207  2630 net.cpp:137] Memory required for data: 440321200
I0929 19:16:18.088212  2630 layer_factory.hpp:77] Creating layer Scale13
I0929 19:16:18.088215  2630 net.cpp:84] Creating Layer Scale13
I0929 19:16:18.088217  2630 net.cpp:406] Scale13 <- Convolution13
I0929 19:16:18.088220  2630 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0929 19:16:18.088253  2630 layer_factory.hpp:77] Creating layer Scale13
I0929 19:16:18.088342  2630 net.cpp:122] Setting up Scale13
I0929 19:16:18.088346  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.088348  2630 net.cpp:137] Memory required for data: 446874800
I0929 19:16:18.088352  2630 layer_factory.hpp:77] Creating layer Eltwise6
I0929 19:16:18.088361  2630 net.cpp:84] Creating Layer Eltwise6
I0929 19:16:18.088363  2630 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0929 19:16:18.088366  2630 net.cpp:406] Eltwise6 <- Convolution13
I0929 19:16:18.088369  2630 net.cpp:380] Eltwise6 -> Eltwise6
I0929 19:16:18.088388  2630 net.cpp:122] Setting up Eltwise6
I0929 19:16:18.088399  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.088402  2630 net.cpp:137] Memory required for data: 453428400
I0929 19:16:18.088404  2630 layer_factory.hpp:77] Creating layer ReLU13
I0929 19:16:18.088408  2630 net.cpp:84] Creating Layer ReLU13
I0929 19:16:18.088412  2630 net.cpp:406] ReLU13 <- Eltwise6
I0929 19:16:18.088414  2630 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0929 19:16:18.088546  2630 net.cpp:122] Setting up ReLU13
I0929 19:16:18.088553  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.088555  2630 net.cpp:137] Memory required for data: 459982000
I0929 19:16:18.088558  2630 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0929 19:16:18.088562  2630 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0929 19:16:18.088564  2630 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0929 19:16:18.088567  2630 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0929 19:16:18.088572  2630 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0929 19:16:18.088604  2630 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0929 19:16:18.088608  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.088610  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.088613  2630 net.cpp:137] Memory required for data: 473089200
I0929 19:16:18.108688  2630 layer_factory.hpp:77] Creating layer Convolution14
I0929 19:16:18.108707  2630 net.cpp:84] Creating Layer Convolution14
I0929 19:16:18.108712  2630 net.cpp:406] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0929 19:16:18.108721  2630 net.cpp:380] Convolution14 -> Convolution14
I0929 19:16:18.109897  2630 net.cpp:122] Setting up Convolution14
I0929 19:16:18.109907  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.109910  2630 net.cpp:137] Memory required for data: 479642800
I0929 19:16:18.109915  2630 layer_factory.hpp:77] Creating layer BatchNorm14
I0929 19:16:18.109921  2630 net.cpp:84] Creating Layer BatchNorm14
I0929 19:16:18.109925  2630 net.cpp:406] BatchNorm14 <- Convolution14
I0929 19:16:18.109930  2630 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0929 19:16:18.110107  2630 net.cpp:122] Setting up BatchNorm14
I0929 19:16:18.110112  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.110116  2630 net.cpp:137] Memory required for data: 486196400
I0929 19:16:18.110121  2630 layer_factory.hpp:77] Creating layer Scale14
I0929 19:16:18.110126  2630 net.cpp:84] Creating Layer Scale14
I0929 19:16:18.110127  2630 net.cpp:406] Scale14 <- Convolution14
I0929 19:16:18.110132  2630 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0929 19:16:18.110167  2630 layer_factory.hpp:77] Creating layer Scale14
I0929 19:16:18.110267  2630 net.cpp:122] Setting up Scale14
I0929 19:16:18.110272  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.110275  2630 net.cpp:137] Memory required for data: 492750000
I0929 19:16:18.110278  2630 layer_factory.hpp:77] Creating layer ReLU14
I0929 19:16:18.110283  2630 net.cpp:84] Creating Layer ReLU14
I0929 19:16:18.110286  2630 net.cpp:406] ReLU14 <- Convolution14
I0929 19:16:18.110290  2630 net.cpp:367] ReLU14 -> Convolution14 (in-place)
I0929 19:16:18.110456  2630 net.cpp:122] Setting up ReLU14
I0929 19:16:18.110468  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.110482  2630 net.cpp:137] Memory required for data: 499303600
I0929 19:16:18.110486  2630 layer_factory.hpp:77] Creating layer Convolution15
I0929 19:16:18.110507  2630 net.cpp:84] Creating Layer Convolution15
I0929 19:16:18.110510  2630 net.cpp:406] Convolution15 <- Convolution14
I0929 19:16:18.110514  2630 net.cpp:380] Convolution15 -> Convolution15
I0929 19:16:18.111651  2630 net.cpp:122] Setting up Convolution15
I0929 19:16:18.111663  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.111668  2630 net.cpp:137] Memory required for data: 505857200
I0929 19:16:18.111675  2630 layer_factory.hpp:77] Creating layer BatchNorm15
I0929 19:16:18.111682  2630 net.cpp:84] Creating Layer BatchNorm15
I0929 19:16:18.111696  2630 net.cpp:406] BatchNorm15 <- Convolution15
I0929 19:16:18.111703  2630 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0929 19:16:18.111874  2630 net.cpp:122] Setting up BatchNorm15
I0929 19:16:18.111879  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.111881  2630 net.cpp:137] Memory required for data: 512410800
I0929 19:16:18.111886  2630 layer_factory.hpp:77] Creating layer Scale15
I0929 19:16:18.111891  2630 net.cpp:84] Creating Layer Scale15
I0929 19:16:18.111893  2630 net.cpp:406] Scale15 <- Convolution15
I0929 19:16:18.111896  2630 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0929 19:16:18.111930  2630 layer_factory.hpp:77] Creating layer Scale15
I0929 19:16:18.112026  2630 net.cpp:122] Setting up Scale15
I0929 19:16:18.112030  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.112033  2630 net.cpp:137] Memory required for data: 518964400
I0929 19:16:18.112036  2630 layer_factory.hpp:77] Creating layer Eltwise7
I0929 19:16:18.112041  2630 net.cpp:84] Creating Layer Eltwise7
I0929 19:16:18.112045  2630 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0929 19:16:18.112047  2630 net.cpp:406] Eltwise7 <- Convolution15
I0929 19:16:18.112051  2630 net.cpp:380] Eltwise7 -> Eltwise7
I0929 19:16:18.112071  2630 net.cpp:122] Setting up Eltwise7
I0929 19:16:18.112073  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.112076  2630 net.cpp:137] Memory required for data: 525518000
I0929 19:16:18.112078  2630 layer_factory.hpp:77] Creating layer ReLU15
I0929 19:16:18.112082  2630 net.cpp:84] Creating Layer ReLU15
I0929 19:16:18.112085  2630 net.cpp:406] ReLU15 <- Eltwise7
I0929 19:16:18.112087  2630 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0929 19:16:18.112220  2630 net.cpp:122] Setting up ReLU15
I0929 19:16:18.112226  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.112227  2630 net.cpp:137] Memory required for data: 532071600
I0929 19:16:18.112229  2630 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0929 19:16:18.112234  2630 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0929 19:16:18.112237  2630 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0929 19:16:18.112241  2630 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0929 19:16:18.112246  2630 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0929 19:16:18.112278  2630 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0929 19:16:18.112282  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.112285  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.112287  2630 net.cpp:137] Memory required for data: 545178800
I0929 19:16:18.112289  2630 layer_factory.hpp:77] Creating layer Convolution16
I0929 19:16:18.112296  2630 net.cpp:84] Creating Layer Convolution16
I0929 19:16:18.112298  2630 net.cpp:406] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0929 19:16:18.112303  2630 net.cpp:380] Convolution16 -> Convolution16
I0929 19:16:18.113401  2630 net.cpp:122] Setting up Convolution16
I0929 19:16:18.113411  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.113415  2630 net.cpp:137] Memory required for data: 551732400
I0929 19:16:18.113420  2630 layer_factory.hpp:77] Creating layer BatchNorm16
I0929 19:16:18.113425  2630 net.cpp:84] Creating Layer BatchNorm16
I0929 19:16:18.113428  2630 net.cpp:406] BatchNorm16 <- Convolution16
I0929 19:16:18.113432  2630 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0929 19:16:18.113602  2630 net.cpp:122] Setting up BatchNorm16
I0929 19:16:18.113607  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.113610  2630 net.cpp:137] Memory required for data: 558286000
I0929 19:16:18.113615  2630 layer_factory.hpp:77] Creating layer Scale16
I0929 19:16:18.113620  2630 net.cpp:84] Creating Layer Scale16
I0929 19:16:18.113622  2630 net.cpp:406] Scale16 <- Convolution16
I0929 19:16:18.113626  2630 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0929 19:16:18.113658  2630 layer_factory.hpp:77] Creating layer Scale16
I0929 19:16:18.113762  2630 net.cpp:122] Setting up Scale16
I0929 19:16:18.113767  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.113770  2630 net.cpp:137] Memory required for data: 564839600
I0929 19:16:18.113773  2630 layer_factory.hpp:77] Creating layer ReLU16
I0929 19:16:18.113777  2630 net.cpp:84] Creating Layer ReLU16
I0929 19:16:18.113780  2630 net.cpp:406] ReLU16 <- Convolution16
I0929 19:16:18.113785  2630 net.cpp:367] ReLU16 -> Convolution16 (in-place)
I0929 19:16:18.113920  2630 net.cpp:122] Setting up ReLU16
I0929 19:16:18.113926  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.113929  2630 net.cpp:137] Memory required for data: 571393200
I0929 19:16:18.113931  2630 layer_factory.hpp:77] Creating layer Convolution17
I0929 19:16:18.113939  2630 net.cpp:84] Creating Layer Convolution17
I0929 19:16:18.113942  2630 net.cpp:406] Convolution17 <- Convolution16
I0929 19:16:18.113946  2630 net.cpp:380] Convolution17 -> Convolution17
I0929 19:16:18.114971  2630 net.cpp:122] Setting up Convolution17
I0929 19:16:18.114981  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.114984  2630 net.cpp:137] Memory required for data: 577946800
I0929 19:16:18.114989  2630 layer_factory.hpp:77] Creating layer BatchNorm17
I0929 19:16:18.114995  2630 net.cpp:84] Creating Layer BatchNorm17
I0929 19:16:18.114997  2630 net.cpp:406] BatchNorm17 <- Convolution17
I0929 19:16:18.115000  2630 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0929 19:16:18.115172  2630 net.cpp:122] Setting up BatchNorm17
I0929 19:16:18.115177  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.115180  2630 net.cpp:137] Memory required for data: 584500400
I0929 19:16:18.115185  2630 layer_factory.hpp:77] Creating layer Scale17
I0929 19:16:18.115188  2630 net.cpp:84] Creating Layer Scale17
I0929 19:16:18.115191  2630 net.cpp:406] Scale17 <- Convolution17
I0929 19:16:18.115195  2630 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0929 19:16:18.115227  2630 layer_factory.hpp:77] Creating layer Scale17
I0929 19:16:18.115321  2630 net.cpp:122] Setting up Scale17
I0929 19:16:18.115326  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.115329  2630 net.cpp:137] Memory required for data: 591054000
I0929 19:16:18.115332  2630 layer_factory.hpp:77] Creating layer Eltwise8
I0929 19:16:18.115336  2630 net.cpp:84] Creating Layer Eltwise8
I0929 19:16:18.115339  2630 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0929 19:16:18.115342  2630 net.cpp:406] Eltwise8 <- Convolution17
I0929 19:16:18.115345  2630 net.cpp:380] Eltwise8 -> Eltwise8
I0929 19:16:18.115365  2630 net.cpp:122] Setting up Eltwise8
I0929 19:16:18.115370  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.115371  2630 net.cpp:137] Memory required for data: 597607600
I0929 19:16:18.115373  2630 layer_factory.hpp:77] Creating layer ReLU17
I0929 19:16:18.115377  2630 net.cpp:84] Creating Layer ReLU17
I0929 19:16:18.115381  2630 net.cpp:406] ReLU17 <- Eltwise8
I0929 19:16:18.115383  2630 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0929 19:16:18.115859  2630 net.cpp:122] Setting up ReLU17
I0929 19:16:18.115867  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.115870  2630 net.cpp:137] Memory required for data: 604161200
I0929 19:16:18.115872  2630 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0929 19:16:18.115877  2630 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0929 19:16:18.115880  2630 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0929 19:16:18.115885  2630 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0929 19:16:18.115888  2630 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0929 19:16:18.115924  2630 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0929 19:16:18.115929  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.115932  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.115934  2630 net.cpp:137] Memory required for data: 617268400
I0929 19:16:18.115936  2630 layer_factory.hpp:77] Creating layer Convolution18
I0929 19:16:18.115950  2630 net.cpp:84] Creating Layer Convolution18
I0929 19:16:18.115953  2630 net.cpp:406] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0929 19:16:18.115958  2630 net.cpp:380] Convolution18 -> Convolution18
I0929 19:16:18.116621  2630 net.cpp:122] Setting up Convolution18
I0929 19:16:18.116629  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.116631  2630 net.cpp:137] Memory required for data: 623822000
I0929 19:16:18.116636  2630 layer_factory.hpp:77] Creating layer BatchNorm18
I0929 19:16:18.116641  2630 net.cpp:84] Creating Layer BatchNorm18
I0929 19:16:18.116643  2630 net.cpp:406] BatchNorm18 <- Convolution18
I0929 19:16:18.116648  2630 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0929 19:16:18.116818  2630 net.cpp:122] Setting up BatchNorm18
I0929 19:16:18.116823  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.116825  2630 net.cpp:137] Memory required for data: 630375600
I0929 19:16:18.116830  2630 layer_factory.hpp:77] Creating layer Scale18
I0929 19:16:18.116834  2630 net.cpp:84] Creating Layer Scale18
I0929 19:16:18.116837  2630 net.cpp:406] Scale18 <- Convolution18
I0929 19:16:18.116840  2630 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0929 19:16:18.116873  2630 layer_factory.hpp:77] Creating layer Scale18
I0929 19:16:18.116968  2630 net.cpp:122] Setting up Scale18
I0929 19:16:18.116973  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.116976  2630 net.cpp:137] Memory required for data: 636929200
I0929 19:16:18.116979  2630 layer_factory.hpp:77] Creating layer ReLU18
I0929 19:16:18.116983  2630 net.cpp:84] Creating Layer ReLU18
I0929 19:16:18.116986  2630 net.cpp:406] ReLU18 <- Convolution18
I0929 19:16:18.116989  2630 net.cpp:367] ReLU18 -> Convolution18 (in-place)
I0929 19:16:18.117463  2630 net.cpp:122] Setting up ReLU18
I0929 19:16:18.117471  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.117475  2630 net.cpp:137] Memory required for data: 643482800
I0929 19:16:18.117477  2630 layer_factory.hpp:77] Creating layer Convolution19
I0929 19:16:18.117486  2630 net.cpp:84] Creating Layer Convolution19
I0929 19:16:18.117488  2630 net.cpp:406] Convolution19 <- Convolution18
I0929 19:16:18.117493  2630 net.cpp:380] Convolution19 -> Convolution19
I0929 19:16:18.118510  2630 net.cpp:122] Setting up Convolution19
I0929 19:16:18.118518  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.118526  2630 net.cpp:137] Memory required for data: 650036400
I0929 19:16:18.118531  2630 layer_factory.hpp:77] Creating layer BatchNorm19
I0929 19:16:18.118536  2630 net.cpp:84] Creating Layer BatchNorm19
I0929 19:16:18.118540  2630 net.cpp:406] BatchNorm19 <- Convolution19
I0929 19:16:18.118543  2630 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0929 19:16:18.118715  2630 net.cpp:122] Setting up BatchNorm19
I0929 19:16:18.118719  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.118721  2630 net.cpp:137] Memory required for data: 656590000
I0929 19:16:18.118741  2630 layer_factory.hpp:77] Creating layer Scale19
I0929 19:16:18.118746  2630 net.cpp:84] Creating Layer Scale19
I0929 19:16:18.118748  2630 net.cpp:406] Scale19 <- Convolution19
I0929 19:16:18.118752  2630 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0929 19:16:18.118788  2630 layer_factory.hpp:77] Creating layer Scale19
I0929 19:16:18.118885  2630 net.cpp:122] Setting up Scale19
I0929 19:16:18.118890  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.118891  2630 net.cpp:137] Memory required for data: 663143600
I0929 19:16:18.118896  2630 layer_factory.hpp:77] Creating layer Eltwise9
I0929 19:16:18.118899  2630 net.cpp:84] Creating Layer Eltwise9
I0929 19:16:18.118902  2630 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0929 19:16:18.118906  2630 net.cpp:406] Eltwise9 <- Convolution19
I0929 19:16:18.118908  2630 net.cpp:380] Eltwise9 -> Eltwise9
I0929 19:16:18.118927  2630 net.cpp:122] Setting up Eltwise9
I0929 19:16:18.118930  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.118939  2630 net.cpp:137] Memory required for data: 669697200
I0929 19:16:18.118942  2630 layer_factory.hpp:77] Creating layer ReLU19
I0929 19:16:18.118947  2630 net.cpp:84] Creating Layer ReLU19
I0929 19:16:18.118949  2630 net.cpp:406] ReLU19 <- Eltwise9
I0929 19:16:18.118952  2630 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0929 19:16:18.119086  2630 net.cpp:122] Setting up ReLU19
I0929 19:16:18.119092  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.119094  2630 net.cpp:137] Memory required for data: 676250800
I0929 19:16:18.119097  2630 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0929 19:16:18.119102  2630 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0929 19:16:18.119104  2630 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0929 19:16:18.119107  2630 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0929 19:16:18.119112  2630 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0929 19:16:18.119146  2630 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0929 19:16:18.119150  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.119153  2630 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 19:16:18.119155  2630 net.cpp:137] Memory required for data: 689358000
I0929 19:16:18.139482  2630 layer_factory.hpp:77] Creating layer Convolution20
I0929 19:16:18.139499  2630 net.cpp:84] Creating Layer Convolution20
I0929 19:16:18.139505  2630 net.cpp:406] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0929 19:16:18.139514  2630 net.cpp:380] Convolution20 -> Convolution20
I0929 19:16:18.140642  2630 net.cpp:122] Setting up Convolution20
I0929 19:16:18.140652  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.140655  2630 net.cpp:137] Memory required for data: 692634800
I0929 19:16:18.140661  2630 layer_factory.hpp:77] Creating layer BatchNorm20
I0929 19:16:18.140666  2630 net.cpp:84] Creating Layer BatchNorm20
I0929 19:16:18.140669  2630 net.cpp:406] BatchNorm20 <- Convolution20
I0929 19:16:18.140676  2630 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0929 19:16:18.140851  2630 net.cpp:122] Setting up BatchNorm20
I0929 19:16:18.140856  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.140858  2630 net.cpp:137] Memory required for data: 695911600
I0929 19:16:18.140863  2630 layer_factory.hpp:77] Creating layer Scale20
I0929 19:16:18.140868  2630 net.cpp:84] Creating Layer Scale20
I0929 19:16:18.140871  2630 net.cpp:406] Scale20 <- Convolution20
I0929 19:16:18.140874  2630 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0929 19:16:18.140911  2630 layer_factory.hpp:77] Creating layer Scale20
I0929 19:16:18.141043  2630 net.cpp:122] Setting up Scale20
I0929 19:16:18.141053  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.141057  2630 net.cpp:137] Memory required for data: 699188400
I0929 19:16:18.141063  2630 layer_factory.hpp:77] Creating layer Convolution21
I0929 19:16:18.141072  2630 net.cpp:84] Creating Layer Convolution21
I0929 19:16:18.141074  2630 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_1
I0929 19:16:18.141082  2630 net.cpp:380] Convolution21 -> Convolution21
I0929 19:16:18.142243  2630 net.cpp:122] Setting up Convolution21
I0929 19:16:18.142252  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.142256  2630 net.cpp:137] Memory required for data: 702465200
I0929 19:16:18.142261  2630 layer_factory.hpp:77] Creating layer BatchNorm21
I0929 19:16:18.142266  2630 net.cpp:84] Creating Layer BatchNorm21
I0929 19:16:18.142269  2630 net.cpp:406] BatchNorm21 <- Convolution21
I0929 19:16:18.142272  2630 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0929 19:16:18.142439  2630 net.cpp:122] Setting up BatchNorm21
I0929 19:16:18.142443  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.142446  2630 net.cpp:137] Memory required for data: 705742000
I0929 19:16:18.142451  2630 layer_factory.hpp:77] Creating layer Scale21
I0929 19:16:18.142455  2630 net.cpp:84] Creating Layer Scale21
I0929 19:16:18.142458  2630 net.cpp:406] Scale21 <- Convolution21
I0929 19:16:18.142468  2630 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0929 19:16:18.142504  2630 layer_factory.hpp:77] Creating layer Scale21
I0929 19:16:18.142612  2630 net.cpp:122] Setting up Scale21
I0929 19:16:18.142618  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.142621  2630 net.cpp:137] Memory required for data: 709018800
I0929 19:16:18.142624  2630 layer_factory.hpp:77] Creating layer ReLU20
I0929 19:16:18.142628  2630 net.cpp:84] Creating Layer ReLU20
I0929 19:16:18.142630  2630 net.cpp:406] ReLU20 <- Convolution21
I0929 19:16:18.142635  2630 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I0929 19:16:18.142771  2630 net.cpp:122] Setting up ReLU20
I0929 19:16:18.142776  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.142778  2630 net.cpp:137] Memory required for data: 712295600
I0929 19:16:18.142781  2630 layer_factory.hpp:77] Creating layer Convolution22
I0929 19:16:18.142787  2630 net.cpp:84] Creating Layer Convolution22
I0929 19:16:18.142791  2630 net.cpp:406] Convolution22 <- Convolution21
I0929 19:16:18.142796  2630 net.cpp:380] Convolution22 -> Convolution22
I0929 19:16:18.143977  2630 net.cpp:122] Setting up Convolution22
I0929 19:16:18.143986  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.143990  2630 net.cpp:137] Memory required for data: 715572400
I0929 19:16:18.143993  2630 layer_factory.hpp:77] Creating layer BatchNorm22
I0929 19:16:18.143999  2630 net.cpp:84] Creating Layer BatchNorm22
I0929 19:16:18.144002  2630 net.cpp:406] BatchNorm22 <- Convolution22
I0929 19:16:18.144006  2630 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0929 19:16:18.144170  2630 net.cpp:122] Setting up BatchNorm22
I0929 19:16:18.144176  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.144177  2630 net.cpp:137] Memory required for data: 718849200
I0929 19:16:18.144182  2630 layer_factory.hpp:77] Creating layer Scale22
I0929 19:16:18.144186  2630 net.cpp:84] Creating Layer Scale22
I0929 19:16:18.144189  2630 net.cpp:406] Scale22 <- Convolution22
I0929 19:16:18.144194  2630 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0929 19:16:18.144227  2630 layer_factory.hpp:77] Creating layer Scale22
I0929 19:16:18.144322  2630 net.cpp:122] Setting up Scale22
I0929 19:16:18.144327  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.144330  2630 net.cpp:137] Memory required for data: 722126000
I0929 19:16:18.144333  2630 layer_factory.hpp:77] Creating layer Eltwise10
I0929 19:16:18.144337  2630 net.cpp:84] Creating Layer Eltwise10
I0929 19:16:18.144340  2630 net.cpp:406] Eltwise10 <- Convolution20
I0929 19:16:18.144343  2630 net.cpp:406] Eltwise10 <- Convolution22
I0929 19:16:18.144346  2630 net.cpp:380] Eltwise10 -> Eltwise10
I0929 19:16:18.144363  2630 net.cpp:122] Setting up Eltwise10
I0929 19:16:18.144367  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.144369  2630 net.cpp:137] Memory required for data: 725402800
I0929 19:16:18.144371  2630 layer_factory.hpp:77] Creating layer ReLU21
I0929 19:16:18.144376  2630 net.cpp:84] Creating Layer ReLU21
I0929 19:16:18.144377  2630 net.cpp:406] ReLU21 <- Eltwise10
I0929 19:16:18.144381  2630 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I0929 19:16:18.144512  2630 net.cpp:122] Setting up ReLU21
I0929 19:16:18.144518  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.144521  2630 net.cpp:137] Memory required for data: 728679600
I0929 19:16:18.144523  2630 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0929 19:16:18.144527  2630 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I0929 19:16:18.144529  2630 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I0929 19:16:18.144533  2630 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0929 19:16:18.144538  2630 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0929 19:16:18.144572  2630 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I0929 19:16:18.144577  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.144587  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.144589  2630 net.cpp:137] Memory required for data: 735233200
I0929 19:16:18.144592  2630 layer_factory.hpp:77] Creating layer Convolution23
I0929 19:16:18.144598  2630 net.cpp:84] Creating Layer Convolution23
I0929 19:16:18.144601  2630 net.cpp:406] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0929 19:16:18.144605  2630 net.cpp:380] Convolution23 -> Convolution23
I0929 19:16:18.146092  2630 net.cpp:122] Setting up Convolution23
I0929 19:16:18.146101  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.146104  2630 net.cpp:137] Memory required for data: 738510000
I0929 19:16:18.146108  2630 layer_factory.hpp:77] Creating layer BatchNorm23
I0929 19:16:18.146114  2630 net.cpp:84] Creating Layer BatchNorm23
I0929 19:16:18.146117  2630 net.cpp:406] BatchNorm23 <- Convolution23
I0929 19:16:18.146121  2630 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0929 19:16:18.146283  2630 net.cpp:122] Setting up BatchNorm23
I0929 19:16:18.146287  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.146289  2630 net.cpp:137] Memory required for data: 741786800
I0929 19:16:18.146294  2630 layer_factory.hpp:77] Creating layer Scale23
I0929 19:16:18.146299  2630 net.cpp:84] Creating Layer Scale23
I0929 19:16:18.146302  2630 net.cpp:406] Scale23 <- Convolution23
I0929 19:16:18.146306  2630 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0929 19:16:18.146338  2630 layer_factory.hpp:77] Creating layer Scale23
I0929 19:16:18.146432  2630 net.cpp:122] Setting up Scale23
I0929 19:16:18.146436  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.146438  2630 net.cpp:137] Memory required for data: 745063600
I0929 19:16:18.146442  2630 layer_factory.hpp:77] Creating layer ReLU22
I0929 19:16:18.146445  2630 net.cpp:84] Creating Layer ReLU22
I0929 19:16:18.146448  2630 net.cpp:406] ReLU22 <- Convolution23
I0929 19:16:18.146451  2630 net.cpp:367] ReLU22 -> Convolution23 (in-place)
I0929 19:16:18.146610  2630 net.cpp:122] Setting up ReLU22
I0929 19:16:18.146617  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.146620  2630 net.cpp:137] Memory required for data: 748340400
I0929 19:16:18.146622  2630 layer_factory.hpp:77] Creating layer Convolution24
I0929 19:16:18.146628  2630 net.cpp:84] Creating Layer Convolution24
I0929 19:16:18.146631  2630 net.cpp:406] Convolution24 <- Convolution23
I0929 19:16:18.146636  2630 net.cpp:380] Convolution24 -> Convolution24
I0929 19:16:18.147789  2630 net.cpp:122] Setting up Convolution24
I0929 19:16:18.147797  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.147800  2630 net.cpp:137] Memory required for data: 751617200
I0929 19:16:18.147804  2630 layer_factory.hpp:77] Creating layer BatchNorm24
I0929 19:16:18.147809  2630 net.cpp:84] Creating Layer BatchNorm24
I0929 19:16:18.147812  2630 net.cpp:406] BatchNorm24 <- Convolution24
I0929 19:16:18.147816  2630 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0929 19:16:18.147979  2630 net.cpp:122] Setting up BatchNorm24
I0929 19:16:18.147984  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.147986  2630 net.cpp:137] Memory required for data: 754894000
I0929 19:16:18.147990  2630 layer_factory.hpp:77] Creating layer Scale24
I0929 19:16:18.147994  2630 net.cpp:84] Creating Layer Scale24
I0929 19:16:18.147997  2630 net.cpp:406] Scale24 <- Convolution24
I0929 19:16:18.148000  2630 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0929 19:16:18.148033  2630 layer_factory.hpp:77] Creating layer Scale24
I0929 19:16:18.148126  2630 net.cpp:122] Setting up Scale24
I0929 19:16:18.148130  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.148133  2630 net.cpp:137] Memory required for data: 758170800
I0929 19:16:18.148136  2630 layer_factory.hpp:77] Creating layer Eltwise11
I0929 19:16:18.148141  2630 net.cpp:84] Creating Layer Eltwise11
I0929 19:16:18.148144  2630 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0929 19:16:18.148146  2630 net.cpp:406] Eltwise11 <- Convolution24
I0929 19:16:18.148156  2630 net.cpp:380] Eltwise11 -> Eltwise11
I0929 19:16:18.148174  2630 net.cpp:122] Setting up Eltwise11
I0929 19:16:18.148177  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.148180  2630 net.cpp:137] Memory required for data: 761447600
I0929 19:16:18.148181  2630 layer_factory.hpp:77] Creating layer ReLU23
I0929 19:16:18.148186  2630 net.cpp:84] Creating Layer ReLU23
I0929 19:16:18.148188  2630 net.cpp:406] ReLU23 <- Eltwise11
I0929 19:16:18.148191  2630 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0929 19:16:18.148321  2630 net.cpp:122] Setting up ReLU23
I0929 19:16:18.148327  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.148330  2630 net.cpp:137] Memory required for data: 764724400
I0929 19:16:18.148332  2630 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0929 19:16:18.148337  2630 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0929 19:16:18.148339  2630 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0929 19:16:18.148342  2630 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0929 19:16:18.148347  2630 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0929 19:16:18.148381  2630 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0929 19:16:18.148386  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.148388  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.148391  2630 net.cpp:137] Memory required for data: 771278000
I0929 19:16:18.148392  2630 layer_factory.hpp:77] Creating layer Convolution25
I0929 19:16:18.148398  2630 net.cpp:84] Creating Layer Convolution25
I0929 19:16:18.148401  2630 net.cpp:406] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0929 19:16:18.148406  2630 net.cpp:380] Convolution25 -> Convolution25
I0929 19:16:18.149544  2630 net.cpp:122] Setting up Convolution25
I0929 19:16:18.149554  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.149556  2630 net.cpp:137] Memory required for data: 774554800
I0929 19:16:18.149560  2630 layer_factory.hpp:77] Creating layer BatchNorm25
I0929 19:16:18.149565  2630 net.cpp:84] Creating Layer BatchNorm25
I0929 19:16:18.149567  2630 net.cpp:406] BatchNorm25 <- Convolution25
I0929 19:16:18.149572  2630 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0929 19:16:18.149739  2630 net.cpp:122] Setting up BatchNorm25
I0929 19:16:18.149744  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.149745  2630 net.cpp:137] Memory required for data: 777831600
I0929 19:16:18.149750  2630 layer_factory.hpp:77] Creating layer Scale25
I0929 19:16:18.149755  2630 net.cpp:84] Creating Layer Scale25
I0929 19:16:18.149756  2630 net.cpp:406] Scale25 <- Convolution25
I0929 19:16:18.149760  2630 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0929 19:16:18.149792  2630 layer_factory.hpp:77] Creating layer Scale25
I0929 19:16:18.149888  2630 net.cpp:122] Setting up Scale25
I0929 19:16:18.149891  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.149893  2630 net.cpp:137] Memory required for data: 781108400
I0929 19:16:18.149897  2630 layer_factory.hpp:77] Creating layer ReLU24
I0929 19:16:18.149901  2630 net.cpp:84] Creating Layer ReLU24
I0929 19:16:18.149904  2630 net.cpp:406] ReLU24 <- Convolution25
I0929 19:16:18.149907  2630 net.cpp:367] ReLU24 -> Convolution25 (in-place)
I0929 19:16:18.150367  2630 net.cpp:122] Setting up ReLU24
I0929 19:16:18.150374  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.150377  2630 net.cpp:137] Memory required for data: 784385200
I0929 19:16:18.150379  2630 layer_factory.hpp:77] Creating layer Convolution26
I0929 19:16:18.150387  2630 net.cpp:84] Creating Layer Convolution26
I0929 19:16:18.150389  2630 net.cpp:406] Convolution26 <- Convolution25
I0929 19:16:18.150394  2630 net.cpp:380] Convolution26 -> Convolution26
I0929 19:16:18.151602  2630 net.cpp:122] Setting up Convolution26
I0929 19:16:18.151612  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.151614  2630 net.cpp:137] Memory required for data: 787662000
I0929 19:16:18.151619  2630 layer_factory.hpp:77] Creating layer BatchNorm26
I0929 19:16:18.151633  2630 net.cpp:84] Creating Layer BatchNorm26
I0929 19:16:18.151635  2630 net.cpp:406] BatchNorm26 <- Convolution26
I0929 19:16:18.151640  2630 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0929 19:16:18.151819  2630 net.cpp:122] Setting up BatchNorm26
I0929 19:16:18.151825  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.151828  2630 net.cpp:137] Memory required for data: 790938800
I0929 19:16:18.151832  2630 layer_factory.hpp:77] Creating layer Scale26
I0929 19:16:18.151836  2630 net.cpp:84] Creating Layer Scale26
I0929 19:16:18.151839  2630 net.cpp:406] Scale26 <- Convolution26
I0929 19:16:18.151842  2630 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0929 19:16:18.151875  2630 layer_factory.hpp:77] Creating layer Scale26
I0929 19:16:18.151969  2630 net.cpp:122] Setting up Scale26
I0929 19:16:18.151973  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.151975  2630 net.cpp:137] Memory required for data: 794215600
I0929 19:16:18.151979  2630 layer_factory.hpp:77] Creating layer Eltwise12
I0929 19:16:18.170379  2630 net.cpp:84] Creating Layer Eltwise12
I0929 19:16:18.170389  2630 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0929 19:16:18.170395  2630 net.cpp:406] Eltwise12 <- Convolution26
I0929 19:16:18.170403  2630 net.cpp:380] Eltwise12 -> Eltwise12
I0929 19:16:18.170433  2630 net.cpp:122] Setting up Eltwise12
I0929 19:16:18.170439  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.170440  2630 net.cpp:137] Memory required for data: 797492400
I0929 19:16:18.170444  2630 layer_factory.hpp:77] Creating layer ReLU25
I0929 19:16:18.170459  2630 net.cpp:84] Creating Layer ReLU25
I0929 19:16:18.170461  2630 net.cpp:406] ReLU25 <- Eltwise12
I0929 19:16:18.170464  2630 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I0929 19:16:18.170619  2630 net.cpp:122] Setting up ReLU25
I0929 19:16:18.170627  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.170630  2630 net.cpp:137] Memory required for data: 800769200
I0929 19:16:18.170634  2630 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0929 19:16:18.170637  2630 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I0929 19:16:18.170639  2630 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I0929 19:16:18.170644  2630 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0929 19:16:18.170650  2630 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0929 19:16:18.170686  2630 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I0929 19:16:18.170691  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.170693  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.170696  2630 net.cpp:137] Memory required for data: 807322800
I0929 19:16:18.170698  2630 layer_factory.hpp:77] Creating layer Convolution27
I0929 19:16:18.170706  2630 net.cpp:84] Creating Layer Convolution27
I0929 19:16:18.170708  2630 net.cpp:406] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0929 19:16:18.170713  2630 net.cpp:380] Convolution27 -> Convolution27
I0929 19:16:18.171954  2630 net.cpp:122] Setting up Convolution27
I0929 19:16:18.171964  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.171967  2630 net.cpp:137] Memory required for data: 810599600
I0929 19:16:18.171972  2630 layer_factory.hpp:77] Creating layer BatchNorm27
I0929 19:16:18.171977  2630 net.cpp:84] Creating Layer BatchNorm27
I0929 19:16:18.171979  2630 net.cpp:406] BatchNorm27 <- Convolution27
I0929 19:16:18.171983  2630 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0929 19:16:18.172190  2630 net.cpp:122] Setting up BatchNorm27
I0929 19:16:18.172197  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.172200  2630 net.cpp:137] Memory required for data: 813876400
I0929 19:16:18.172205  2630 layer_factory.hpp:77] Creating layer Scale27
I0929 19:16:18.172210  2630 net.cpp:84] Creating Layer Scale27
I0929 19:16:18.172214  2630 net.cpp:406] Scale27 <- Convolution27
I0929 19:16:18.172216  2630 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0929 19:16:18.172261  2630 layer_factory.hpp:77] Creating layer Scale27
I0929 19:16:18.172395  2630 net.cpp:122] Setting up Scale27
I0929 19:16:18.172404  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.172407  2630 net.cpp:137] Memory required for data: 817153200
I0929 19:16:18.172413  2630 layer_factory.hpp:77] Creating layer ReLU26
I0929 19:16:18.172420  2630 net.cpp:84] Creating Layer ReLU26
I0929 19:16:18.172423  2630 net.cpp:406] ReLU26 <- Convolution27
I0929 19:16:18.172430  2630 net.cpp:367] ReLU26 -> Convolution27 (in-place)
I0929 19:16:18.172566  2630 net.cpp:122] Setting up ReLU26
I0929 19:16:18.172574  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.172575  2630 net.cpp:137] Memory required for data: 820430000
I0929 19:16:18.172579  2630 layer_factory.hpp:77] Creating layer Convolution28
I0929 19:16:18.172585  2630 net.cpp:84] Creating Layer Convolution28
I0929 19:16:18.172587  2630 net.cpp:406] Convolution28 <- Convolution27
I0929 19:16:18.172592  2630 net.cpp:380] Convolution28 -> Convolution28
I0929 19:16:18.174185  2630 net.cpp:122] Setting up Convolution28
I0929 19:16:18.174194  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.174197  2630 net.cpp:137] Memory required for data: 823706800
I0929 19:16:18.174202  2630 layer_factory.hpp:77] Creating layer BatchNorm28
I0929 19:16:18.174208  2630 net.cpp:84] Creating Layer BatchNorm28
I0929 19:16:18.174211  2630 net.cpp:406] BatchNorm28 <- Convolution28
I0929 19:16:18.174216  2630 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0929 19:16:18.174392  2630 net.cpp:122] Setting up BatchNorm28
I0929 19:16:18.174397  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.174399  2630 net.cpp:137] Memory required for data: 826983600
I0929 19:16:18.174404  2630 layer_factory.hpp:77] Creating layer Scale28
I0929 19:16:18.174408  2630 net.cpp:84] Creating Layer Scale28
I0929 19:16:18.174412  2630 net.cpp:406] Scale28 <- Convolution28
I0929 19:16:18.174415  2630 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0929 19:16:18.174449  2630 layer_factory.hpp:77] Creating layer Scale28
I0929 19:16:18.174557  2630 net.cpp:122] Setting up Scale28
I0929 19:16:18.174562  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.174564  2630 net.cpp:137] Memory required for data: 830260400
I0929 19:16:18.174568  2630 layer_factory.hpp:77] Creating layer Eltwise13
I0929 19:16:18.174573  2630 net.cpp:84] Creating Layer Eltwise13
I0929 19:16:18.174576  2630 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0929 19:16:18.174579  2630 net.cpp:406] Eltwise13 <- Convolution28
I0929 19:16:18.174582  2630 net.cpp:380] Eltwise13 -> Eltwise13
I0929 19:16:18.174600  2630 net.cpp:122] Setting up Eltwise13
I0929 19:16:18.174603  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.174605  2630 net.cpp:137] Memory required for data: 833537200
I0929 19:16:18.174608  2630 layer_factory.hpp:77] Creating layer ReLU27
I0929 19:16:18.174612  2630 net.cpp:84] Creating Layer ReLU27
I0929 19:16:18.174614  2630 net.cpp:406] ReLU27 <- Eltwise13
I0929 19:16:18.174618  2630 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I0929 19:16:18.174758  2630 net.cpp:122] Setting up ReLU27
I0929 19:16:18.174764  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.174767  2630 net.cpp:137] Memory required for data: 836814000
I0929 19:16:18.174769  2630 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0929 19:16:18.174773  2630 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I0929 19:16:18.174775  2630 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I0929 19:16:18.174779  2630 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0929 19:16:18.174784  2630 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0929 19:16:18.174819  2630 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I0929 19:16:18.174824  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.174826  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.174836  2630 net.cpp:137] Memory required for data: 843367600
I0929 19:16:18.174839  2630 layer_factory.hpp:77] Creating layer Convolution29
I0929 19:16:18.174846  2630 net.cpp:84] Creating Layer Convolution29
I0929 19:16:18.174849  2630 net.cpp:406] Convolution29 <- Eltwise13_ReLU27_0_split_0
I0929 19:16:18.174854  2630 net.cpp:380] Convolution29 -> Convolution29
I0929 19:16:18.176043  2630 net.cpp:122] Setting up Convolution29
I0929 19:16:18.176054  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.176055  2630 net.cpp:137] Memory required for data: 846644400
I0929 19:16:18.176060  2630 layer_factory.hpp:77] Creating layer BatchNorm29
I0929 19:16:18.176065  2630 net.cpp:84] Creating Layer BatchNorm29
I0929 19:16:18.176069  2630 net.cpp:406] BatchNorm29 <- Convolution29
I0929 19:16:18.176072  2630 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0929 19:16:18.176244  2630 net.cpp:122] Setting up BatchNorm29
I0929 19:16:18.176249  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.176251  2630 net.cpp:137] Memory required for data: 849921200
I0929 19:16:18.176256  2630 layer_factory.hpp:77] Creating layer Scale29
I0929 19:16:18.176260  2630 net.cpp:84] Creating Layer Scale29
I0929 19:16:18.176264  2630 net.cpp:406] Scale29 <- Convolution29
I0929 19:16:18.176266  2630 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0929 19:16:18.176301  2630 layer_factory.hpp:77] Creating layer Scale29
I0929 19:16:18.176396  2630 net.cpp:122] Setting up Scale29
I0929 19:16:18.176400  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.176403  2630 net.cpp:137] Memory required for data: 853198000
I0929 19:16:18.176406  2630 layer_factory.hpp:77] Creating layer ReLU28
I0929 19:16:18.176410  2630 net.cpp:84] Creating Layer ReLU28
I0929 19:16:18.176412  2630 net.cpp:406] ReLU28 <- Convolution29
I0929 19:16:18.176416  2630 net.cpp:367] ReLU28 -> Convolution29 (in-place)
I0929 19:16:18.176548  2630 net.cpp:122] Setting up ReLU28
I0929 19:16:18.176553  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.176555  2630 net.cpp:137] Memory required for data: 856474800
I0929 19:16:18.176558  2630 layer_factory.hpp:77] Creating layer Convolution30
I0929 19:16:18.176565  2630 net.cpp:84] Creating Layer Convolution30
I0929 19:16:18.176568  2630 net.cpp:406] Convolution30 <- Convolution29
I0929 19:16:18.176573  2630 net.cpp:380] Convolution30 -> Convolution30
I0929 19:16:18.177743  2630 net.cpp:122] Setting up Convolution30
I0929 19:16:18.177752  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.177755  2630 net.cpp:137] Memory required for data: 859751600
I0929 19:16:18.177759  2630 layer_factory.hpp:77] Creating layer BatchNorm30
I0929 19:16:18.177765  2630 net.cpp:84] Creating Layer BatchNorm30
I0929 19:16:18.177768  2630 net.cpp:406] BatchNorm30 <- Convolution30
I0929 19:16:18.177772  2630 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0929 19:16:18.177939  2630 net.cpp:122] Setting up BatchNorm30
I0929 19:16:18.177944  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.177947  2630 net.cpp:137] Memory required for data: 863028400
I0929 19:16:18.177951  2630 layer_factory.hpp:77] Creating layer Scale30
I0929 19:16:18.177956  2630 net.cpp:84] Creating Layer Scale30
I0929 19:16:18.177959  2630 net.cpp:406] Scale30 <- Convolution30
I0929 19:16:18.177963  2630 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0929 19:16:18.177999  2630 layer_factory.hpp:77] Creating layer Scale30
I0929 19:16:18.178097  2630 net.cpp:122] Setting up Scale30
I0929 19:16:18.178102  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.178103  2630 net.cpp:137] Memory required for data: 866305200
I0929 19:16:18.178107  2630 layer_factory.hpp:77] Creating layer Eltwise14
I0929 19:16:18.178112  2630 net.cpp:84] Creating Layer Eltwise14
I0929 19:16:18.178115  2630 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0929 19:16:18.178118  2630 net.cpp:406] Eltwise14 <- Convolution30
I0929 19:16:18.178122  2630 net.cpp:380] Eltwise14 -> Eltwise14
I0929 19:16:18.178148  2630 net.cpp:122] Setting up Eltwise14
I0929 19:16:18.178151  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.178153  2630 net.cpp:137] Memory required for data: 869582000
I0929 19:16:18.178156  2630 layer_factory.hpp:77] Creating layer ReLU29
I0929 19:16:18.178159  2630 net.cpp:84] Creating Layer ReLU29
I0929 19:16:18.178162  2630 net.cpp:406] ReLU29 <- Eltwise14
I0929 19:16:18.178165  2630 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I0929 19:16:18.178299  2630 net.cpp:122] Setting up ReLU29
I0929 19:16:18.178305  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.178308  2630 net.cpp:137] Memory required for data: 872858800
I0929 19:16:18.178310  2630 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0929 19:16:18.178314  2630 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I0929 19:16:18.178316  2630 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I0929 19:16:18.178320  2630 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0929 19:16:18.178325  2630 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0929 19:16:18.178360  2630 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I0929 19:16:18.178364  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.178366  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.178369  2630 net.cpp:137] Memory required for data: 879412400
I0929 19:16:18.178371  2630 layer_factory.hpp:77] Creating layer Convolution31
I0929 19:16:18.178378  2630 net.cpp:84] Creating Layer Convolution31
I0929 19:16:18.178381  2630 net.cpp:406] Convolution31 <- Eltwise14_ReLU29_0_split_0
I0929 19:16:18.178385  2630 net.cpp:380] Convolution31 -> Convolution31
I0929 19:16:18.179570  2630 net.cpp:122] Setting up Convolution31
I0929 19:16:18.179579  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.179581  2630 net.cpp:137] Memory required for data: 882689200
I0929 19:16:18.179586  2630 layer_factory.hpp:77] Creating layer BatchNorm31
I0929 19:16:18.179591  2630 net.cpp:84] Creating Layer BatchNorm31
I0929 19:16:18.179594  2630 net.cpp:406] BatchNorm31 <- Convolution31
I0929 19:16:18.179600  2630 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0929 19:16:18.179769  2630 net.cpp:122] Setting up BatchNorm31
I0929 19:16:18.179772  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.179775  2630 net.cpp:137] Memory required for data: 885966000
I0929 19:16:18.179780  2630 layer_factory.hpp:77] Creating layer Scale31
I0929 19:16:18.179785  2630 net.cpp:84] Creating Layer Scale31
I0929 19:16:18.179787  2630 net.cpp:406] Scale31 <- Convolution31
I0929 19:16:18.179790  2630 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0929 19:16:18.179826  2630 layer_factory.hpp:77] Creating layer Scale31
I0929 19:16:18.179924  2630 net.cpp:122] Setting up Scale31
I0929 19:16:18.179929  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.179931  2630 net.cpp:137] Memory required for data: 889242800
I0929 19:16:18.179935  2630 layer_factory.hpp:77] Creating layer ReLU30
I0929 19:16:18.179939  2630 net.cpp:84] Creating Layer ReLU30
I0929 19:16:18.179941  2630 net.cpp:406] ReLU30 <- Convolution31
I0929 19:16:18.179945  2630 net.cpp:367] ReLU30 -> Convolution31 (in-place)
I0929 19:16:18.180420  2630 net.cpp:122] Setting up ReLU30
I0929 19:16:18.180428  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.180431  2630 net.cpp:137] Memory required for data: 892519600
I0929 19:16:18.180434  2630 layer_factory.hpp:77] Creating layer Convolution32
I0929 19:16:18.180441  2630 net.cpp:84] Creating Layer Convolution32
I0929 19:16:18.180444  2630 net.cpp:406] Convolution32 <- Convolution31
I0929 19:16:18.180450  2630 net.cpp:380] Convolution32 -> Convolution32
I0929 19:16:18.181635  2630 net.cpp:122] Setting up Convolution32
I0929 19:16:18.181644  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.181648  2630 net.cpp:137] Memory required for data: 895796400
I0929 19:16:18.181651  2630 layer_factory.hpp:77] Creating layer BatchNorm32
I0929 19:16:18.181664  2630 net.cpp:84] Creating Layer BatchNorm32
I0929 19:16:18.181668  2630 net.cpp:406] BatchNorm32 <- Convolution32
I0929 19:16:18.181671  2630 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0929 19:16:18.181843  2630 net.cpp:122] Setting up BatchNorm32
I0929 19:16:18.181849  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.181850  2630 net.cpp:137] Memory required for data: 899073200
I0929 19:16:18.181855  2630 layer_factory.hpp:77] Creating layer Scale32
I0929 19:16:18.181860  2630 net.cpp:84] Creating Layer Scale32
I0929 19:16:18.181862  2630 net.cpp:406] Scale32 <- Convolution32
I0929 19:16:18.181866  2630 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0929 19:16:18.181900  2630 layer_factory.hpp:77] Creating layer Scale32
I0929 19:16:18.182000  2630 net.cpp:122] Setting up Scale32
I0929 19:16:18.182004  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.182006  2630 net.cpp:137] Memory required for data: 902350000
I0929 19:16:18.182011  2630 layer_factory.hpp:77] Creating layer Eltwise15
I0929 19:16:18.182015  2630 net.cpp:84] Creating Layer Eltwise15
I0929 19:16:18.182018  2630 net.cpp:406] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0929 19:16:18.182020  2630 net.cpp:406] Eltwise15 <- Convolution32
I0929 19:16:18.182024  2630 net.cpp:380] Eltwise15 -> Eltwise15
I0929 19:16:18.182041  2630 net.cpp:122] Setting up Eltwise15
I0929 19:16:18.182045  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.182047  2630 net.cpp:137] Memory required for data: 905626800
I0929 19:16:18.182050  2630 layer_factory.hpp:77] Creating layer ReLU31
I0929 19:16:18.182054  2630 net.cpp:84] Creating Layer ReLU31
I0929 19:16:18.182056  2630 net.cpp:406] ReLU31 <- Eltwise15
I0929 19:16:18.182060  2630 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I0929 19:16:18.182193  2630 net.cpp:122] Setting up ReLU31
I0929 19:16:18.182199  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.182201  2630 net.cpp:137] Memory required for data: 908903600
I0929 19:16:18.182204  2630 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0929 19:16:18.182207  2630 net.cpp:84] Creating Layer Eltwise15_ReLU31_0_split
I0929 19:16:18.182210  2630 net.cpp:406] Eltwise15_ReLU31_0_split <- Eltwise15
I0929 19:16:18.182214  2630 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0929 19:16:18.182219  2630 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0929 19:16:18.182252  2630 net.cpp:122] Setting up Eltwise15_ReLU31_0_split
I0929 19:16:18.182257  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.182260  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.182261  2630 net.cpp:137] Memory required for data: 915457200
I0929 19:16:18.182265  2630 layer_factory.hpp:77] Creating layer Convolution33
I0929 19:16:18.182271  2630 net.cpp:84] Creating Layer Convolution33
I0929 19:16:18.182273  2630 net.cpp:406] Convolution33 <- Eltwise15_ReLU31_0_split_0
I0929 19:16:18.182278  2630 net.cpp:380] Convolution33 -> Convolution33
I0929 19:16:18.183470  2630 net.cpp:122] Setting up Convolution33
I0929 19:16:18.183478  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.183480  2630 net.cpp:137] Memory required for data: 918734000
I0929 19:16:18.183485  2630 layer_factory.hpp:77] Creating layer BatchNorm33
I0929 19:16:18.183490  2630 net.cpp:84] Creating Layer BatchNorm33
I0929 19:16:18.183493  2630 net.cpp:406] BatchNorm33 <- Convolution33
I0929 19:16:18.183498  2630 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0929 19:16:18.183675  2630 net.cpp:122] Setting up BatchNorm33
I0929 19:16:18.183679  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.183681  2630 net.cpp:137] Memory required for data: 922010800
I0929 19:16:18.183686  2630 layer_factory.hpp:77] Creating layer Scale33
I0929 19:16:18.183691  2630 net.cpp:84] Creating Layer Scale33
I0929 19:16:18.183693  2630 net.cpp:406] Scale33 <- Convolution33
I0929 19:16:18.183697  2630 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0929 19:16:18.183739  2630 layer_factory.hpp:77] Creating layer Scale33
I0929 19:16:18.183840  2630 net.cpp:122] Setting up Scale33
I0929 19:16:18.183845  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.183847  2630 net.cpp:137] Memory required for data: 925287600
I0929 19:16:18.183851  2630 layer_factory.hpp:77] Creating layer ReLU32
I0929 19:16:18.183856  2630 net.cpp:84] Creating Layer ReLU32
I0929 19:16:18.183857  2630 net.cpp:406] ReLU32 <- Convolution33
I0929 19:16:18.183861  2630 net.cpp:367] ReLU32 -> Convolution33 (in-place)
I0929 19:16:18.183997  2630 net.cpp:122] Setting up ReLU32
I0929 19:16:18.184003  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.184005  2630 net.cpp:137] Memory required for data: 928564400
I0929 19:16:18.184008  2630 layer_factory.hpp:77] Creating layer Convolution34
I0929 19:16:18.184015  2630 net.cpp:84] Creating Layer Convolution34
I0929 19:16:18.184017  2630 net.cpp:406] Convolution34 <- Convolution33
I0929 19:16:18.200474  2630 net.cpp:380] Convolution34 -> Convolution34
I0929 19:16:18.201776  2630 net.cpp:122] Setting up Convolution34
I0929 19:16:18.201786  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.201789  2630 net.cpp:137] Memory required for data: 931841200
I0929 19:16:18.201795  2630 layer_factory.hpp:77] Creating layer BatchNorm34
I0929 19:16:18.201800  2630 net.cpp:84] Creating Layer BatchNorm34
I0929 19:16:18.201803  2630 net.cpp:406] BatchNorm34 <- Convolution34
I0929 19:16:18.201808  2630 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0929 19:16:18.201993  2630 net.cpp:122] Setting up BatchNorm34
I0929 19:16:18.201998  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.202002  2630 net.cpp:137] Memory required for data: 935118000
I0929 19:16:18.202006  2630 layer_factory.hpp:77] Creating layer Scale34
I0929 19:16:18.202010  2630 net.cpp:84] Creating Layer Scale34
I0929 19:16:18.202013  2630 net.cpp:406] Scale34 <- Convolution34
I0929 19:16:18.202018  2630 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0929 19:16:18.202055  2630 layer_factory.hpp:77] Creating layer Scale34
I0929 19:16:18.202185  2630 net.cpp:122] Setting up Scale34
I0929 19:16:18.202195  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.202199  2630 net.cpp:137] Memory required for data: 938394800
I0929 19:16:18.202206  2630 layer_factory.hpp:77] Creating layer Eltwise16
I0929 19:16:18.202214  2630 net.cpp:84] Creating Layer Eltwise16
I0929 19:16:18.202219  2630 net.cpp:406] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0929 19:16:18.202224  2630 net.cpp:406] Eltwise16 <- Convolution34
I0929 19:16:18.202229  2630 net.cpp:380] Eltwise16 -> Eltwise16
I0929 19:16:18.202251  2630 net.cpp:122] Setting up Eltwise16
I0929 19:16:18.202255  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.202257  2630 net.cpp:137] Memory required for data: 941671600
I0929 19:16:18.202260  2630 layer_factory.hpp:77] Creating layer ReLU33
I0929 19:16:18.202263  2630 net.cpp:84] Creating Layer ReLU33
I0929 19:16:18.202266  2630 net.cpp:406] ReLU33 <- Eltwise16
I0929 19:16:18.202270  2630 net.cpp:367] ReLU33 -> Eltwise16 (in-place)
I0929 19:16:18.202409  2630 net.cpp:122] Setting up ReLU33
I0929 19:16:18.202414  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.202417  2630 net.cpp:137] Memory required for data: 944948400
I0929 19:16:18.202419  2630 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0929 19:16:18.202424  2630 net.cpp:84] Creating Layer Eltwise16_ReLU33_0_split
I0929 19:16:18.202425  2630 net.cpp:406] Eltwise16_ReLU33_0_split <- Eltwise16
I0929 19:16:18.202430  2630 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0929 19:16:18.202435  2630 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0929 19:16:18.202471  2630 net.cpp:122] Setting up Eltwise16_ReLU33_0_split
I0929 19:16:18.202476  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.202478  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.202481  2630 net.cpp:137] Memory required for data: 951502000
I0929 19:16:18.202489  2630 layer_factory.hpp:77] Creating layer Convolution35
I0929 19:16:18.202497  2630 net.cpp:84] Creating Layer Convolution35
I0929 19:16:18.202499  2630 net.cpp:406] Convolution35 <- Eltwise16_ReLU33_0_split_0
I0929 19:16:18.202504  2630 net.cpp:380] Convolution35 -> Convolution35
I0929 19:16:18.203759  2630 net.cpp:122] Setting up Convolution35
I0929 19:16:18.203768  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.203771  2630 net.cpp:137] Memory required for data: 954778800
I0929 19:16:18.203776  2630 layer_factory.hpp:77] Creating layer BatchNorm35
I0929 19:16:18.203781  2630 net.cpp:84] Creating Layer BatchNorm35
I0929 19:16:18.203784  2630 net.cpp:406] BatchNorm35 <- Convolution35
I0929 19:16:18.203788  2630 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0929 19:16:18.203966  2630 net.cpp:122] Setting up BatchNorm35
I0929 19:16:18.203971  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.203974  2630 net.cpp:137] Memory required for data: 958055600
I0929 19:16:18.203979  2630 layer_factory.hpp:77] Creating layer Scale35
I0929 19:16:18.203984  2630 net.cpp:84] Creating Layer Scale35
I0929 19:16:18.203986  2630 net.cpp:406] Scale35 <- Convolution35
I0929 19:16:18.203989  2630 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0929 19:16:18.204025  2630 layer_factory.hpp:77] Creating layer Scale35
I0929 19:16:18.204125  2630 net.cpp:122] Setting up Scale35
I0929 19:16:18.204130  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.204133  2630 net.cpp:137] Memory required for data: 961332400
I0929 19:16:18.204136  2630 layer_factory.hpp:77] Creating layer ReLU34
I0929 19:16:18.204140  2630 net.cpp:84] Creating Layer ReLU34
I0929 19:16:18.204144  2630 net.cpp:406] ReLU34 <- Convolution35
I0929 19:16:18.204145  2630 net.cpp:367] ReLU34 -> Convolution35 (in-place)
I0929 19:16:18.204284  2630 net.cpp:122] Setting up ReLU34
I0929 19:16:18.204290  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.204293  2630 net.cpp:137] Memory required for data: 964609200
I0929 19:16:18.204295  2630 layer_factory.hpp:77] Creating layer Convolution36
I0929 19:16:18.204303  2630 net.cpp:84] Creating Layer Convolution36
I0929 19:16:18.204306  2630 net.cpp:406] Convolution36 <- Convolution35
I0929 19:16:18.204310  2630 net.cpp:380] Convolution36 -> Convolution36
I0929 19:16:18.205510  2630 net.cpp:122] Setting up Convolution36
I0929 19:16:18.205519  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.205523  2630 net.cpp:137] Memory required for data: 967886000
I0929 19:16:18.205528  2630 layer_factory.hpp:77] Creating layer BatchNorm36
I0929 19:16:18.205533  2630 net.cpp:84] Creating Layer BatchNorm36
I0929 19:16:18.205536  2630 net.cpp:406] BatchNorm36 <- Convolution36
I0929 19:16:18.205540  2630 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0929 19:16:18.205719  2630 net.cpp:122] Setting up BatchNorm36
I0929 19:16:18.205724  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.205726  2630 net.cpp:137] Memory required for data: 971162800
I0929 19:16:18.205731  2630 layer_factory.hpp:77] Creating layer Scale36
I0929 19:16:18.205735  2630 net.cpp:84] Creating Layer Scale36
I0929 19:16:18.205737  2630 net.cpp:406] Scale36 <- Convolution36
I0929 19:16:18.205741  2630 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0929 19:16:18.205776  2630 layer_factory.hpp:77] Creating layer Scale36
I0929 19:16:18.205878  2630 net.cpp:122] Setting up Scale36
I0929 19:16:18.205881  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.205883  2630 net.cpp:137] Memory required for data: 974439600
I0929 19:16:18.205888  2630 layer_factory.hpp:77] Creating layer Eltwise17
I0929 19:16:18.205891  2630 net.cpp:84] Creating Layer Eltwise17
I0929 19:16:18.205894  2630 net.cpp:406] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0929 19:16:18.205898  2630 net.cpp:406] Eltwise17 <- Convolution36
I0929 19:16:18.205902  2630 net.cpp:380] Eltwise17 -> Eltwise17
I0929 19:16:18.205919  2630 net.cpp:122] Setting up Eltwise17
I0929 19:16:18.205934  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.205936  2630 net.cpp:137] Memory required for data: 977716400
I0929 19:16:18.205938  2630 layer_factory.hpp:77] Creating layer ReLU35
I0929 19:16:18.205943  2630 net.cpp:84] Creating Layer ReLU35
I0929 19:16:18.205945  2630 net.cpp:406] ReLU35 <- Eltwise17
I0929 19:16:18.205948  2630 net.cpp:367] ReLU35 -> Eltwise17 (in-place)
I0929 19:16:18.206084  2630 net.cpp:122] Setting up ReLU35
I0929 19:16:18.206090  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.206092  2630 net.cpp:137] Memory required for data: 980993200
I0929 19:16:18.206094  2630 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0929 19:16:18.206100  2630 net.cpp:84] Creating Layer Eltwise17_ReLU35_0_split
I0929 19:16:18.206104  2630 net.cpp:406] Eltwise17_ReLU35_0_split <- Eltwise17
I0929 19:16:18.206106  2630 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0929 19:16:18.206111  2630 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0929 19:16:18.206147  2630 net.cpp:122] Setting up Eltwise17_ReLU35_0_split
I0929 19:16:18.206152  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.206154  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.206156  2630 net.cpp:137] Memory required for data: 987546800
I0929 19:16:18.206159  2630 layer_factory.hpp:77] Creating layer Convolution37
I0929 19:16:18.206166  2630 net.cpp:84] Creating Layer Convolution37
I0929 19:16:18.206168  2630 net.cpp:406] Convolution37 <- Eltwise17_ReLU35_0_split_0
I0929 19:16:18.206173  2630 net.cpp:380] Convolution37 -> Convolution37
I0929 19:16:18.207375  2630 net.cpp:122] Setting up Convolution37
I0929 19:16:18.207383  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.207386  2630 net.cpp:137] Memory required for data: 990823600
I0929 19:16:18.207391  2630 layer_factory.hpp:77] Creating layer BatchNorm37
I0929 19:16:18.207396  2630 net.cpp:84] Creating Layer BatchNorm37
I0929 19:16:18.207399  2630 net.cpp:406] BatchNorm37 <- Convolution37
I0929 19:16:18.207403  2630 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0929 19:16:18.208075  2630 net.cpp:122] Setting up BatchNorm37
I0929 19:16:18.208082  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.208086  2630 net.cpp:137] Memory required for data: 994100400
I0929 19:16:18.208117  2630 layer_factory.hpp:77] Creating layer Scale37
I0929 19:16:18.208122  2630 net.cpp:84] Creating Layer Scale37
I0929 19:16:18.208124  2630 net.cpp:406] Scale37 <- Convolution37
I0929 19:16:18.208128  2630 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0929 19:16:18.208161  2630 layer_factory.hpp:77] Creating layer Scale37
I0929 19:16:18.208235  2630 net.cpp:122] Setting up Scale37
I0929 19:16:18.208240  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.208242  2630 net.cpp:137] Memory required for data: 997377200
I0929 19:16:18.208246  2630 layer_factory.hpp:77] Creating layer ReLU36
I0929 19:16:18.208250  2630 net.cpp:84] Creating Layer ReLU36
I0929 19:16:18.208253  2630 net.cpp:406] ReLU36 <- Convolution37
I0929 19:16:18.208256  2630 net.cpp:367] ReLU36 -> Convolution37 (in-place)
I0929 19:16:18.208741  2630 net.cpp:122] Setting up ReLU36
I0929 19:16:18.208750  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.208752  2630 net.cpp:137] Memory required for data: 1000654000
I0929 19:16:18.208755  2630 layer_factory.hpp:77] Creating layer Convolution38
I0929 19:16:18.208762  2630 net.cpp:84] Creating Layer Convolution38
I0929 19:16:18.208766  2630 net.cpp:406] Convolution38 <- Convolution37
I0929 19:16:18.208770  2630 net.cpp:380] Convolution38 -> Convolution38
I0929 19:16:18.210247  2630 net.cpp:122] Setting up Convolution38
I0929 19:16:18.210255  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.210258  2630 net.cpp:137] Memory required for data: 1003930800
I0929 19:16:18.210264  2630 layer_factory.hpp:77] Creating layer BatchNorm38
I0929 19:16:18.210269  2630 net.cpp:84] Creating Layer BatchNorm38
I0929 19:16:18.210279  2630 net.cpp:406] BatchNorm38 <- Convolution38
I0929 19:16:18.210284  2630 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0929 19:16:18.210420  2630 net.cpp:122] Setting up BatchNorm38
I0929 19:16:18.210425  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.210427  2630 net.cpp:137] Memory required for data: 1007207600
I0929 19:16:18.210433  2630 layer_factory.hpp:77] Creating layer Scale38
I0929 19:16:18.210436  2630 net.cpp:84] Creating Layer Scale38
I0929 19:16:18.210439  2630 net.cpp:406] Scale38 <- Convolution38
I0929 19:16:18.210443  2630 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0929 19:16:18.210470  2630 layer_factory.hpp:77] Creating layer Scale38
I0929 19:16:18.210553  2630 net.cpp:122] Setting up Scale38
I0929 19:16:18.210558  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.210561  2630 net.cpp:137] Memory required for data: 1010484400
I0929 19:16:18.210564  2630 layer_factory.hpp:77] Creating layer Eltwise18
I0929 19:16:18.210569  2630 net.cpp:84] Creating Layer Eltwise18
I0929 19:16:18.210572  2630 net.cpp:406] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0929 19:16:18.210575  2630 net.cpp:406] Eltwise18 <- Convolution38
I0929 19:16:18.210579  2630 net.cpp:380] Eltwise18 -> Eltwise18
I0929 19:16:18.210592  2630 net.cpp:122] Setting up Eltwise18
I0929 19:16:18.210595  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.210597  2630 net.cpp:137] Memory required for data: 1013761200
I0929 19:16:18.210599  2630 layer_factory.hpp:77] Creating layer ReLU37
I0929 19:16:18.210603  2630 net.cpp:84] Creating Layer ReLU37
I0929 19:16:18.210606  2630 net.cpp:406] ReLU37 <- Eltwise18
I0929 19:16:18.210609  2630 net.cpp:367] ReLU37 -> Eltwise18 (in-place)
I0929 19:16:18.210747  2630 net.cpp:122] Setting up ReLU37
I0929 19:16:18.210752  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.210754  2630 net.cpp:137] Memory required for data: 1017038000
I0929 19:16:18.210757  2630 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0929 19:16:18.210762  2630 net.cpp:84] Creating Layer Eltwise18_ReLU37_0_split
I0929 19:16:18.210763  2630 net.cpp:406] Eltwise18_ReLU37_0_split <- Eltwise18
I0929 19:16:18.210768  2630 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0929 19:16:18.210772  2630 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0929 19:16:18.210799  2630 net.cpp:122] Setting up Eltwise18_ReLU37_0_split
I0929 19:16:18.210804  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.210808  2630 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 19:16:18.210809  2630 net.cpp:137] Memory required for data: 1023591600
I0929 19:16:18.210811  2630 layer_factory.hpp:77] Creating layer Convolution39
I0929 19:16:18.210819  2630 net.cpp:84] Creating Layer Convolution39
I0929 19:16:18.210821  2630 net.cpp:406] Convolution39 <- Eltwise18_ReLU37_0_split_0
I0929 19:16:18.210825  2630 net.cpp:380] Convolution39 -> Convolution39
I0929 19:16:18.212158  2630 net.cpp:122] Setting up Convolution39
I0929 19:16:18.212167  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.212170  2630 net.cpp:137] Memory required for data: 1025230000
I0929 19:16:18.212174  2630 layer_factory.hpp:77] Creating layer BatchNorm39
I0929 19:16:18.212180  2630 net.cpp:84] Creating Layer BatchNorm39
I0929 19:16:18.212183  2630 net.cpp:406] BatchNorm39 <- Convolution39
I0929 19:16:18.212188  2630 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0929 19:16:18.212321  2630 net.cpp:122] Setting up BatchNorm39
I0929 19:16:18.212327  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.212328  2630 net.cpp:137] Memory required for data: 1026868400
I0929 19:16:18.212333  2630 layer_factory.hpp:77] Creating layer Scale39
I0929 19:16:18.212339  2630 net.cpp:84] Creating Layer Scale39
I0929 19:16:18.212342  2630 net.cpp:406] Scale39 <- Convolution39
I0929 19:16:18.212344  2630 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0929 19:16:18.212371  2630 layer_factory.hpp:77] Creating layer Scale39
I0929 19:16:18.212457  2630 net.cpp:122] Setting up Scale39
I0929 19:16:18.212462  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.212465  2630 net.cpp:137] Memory required for data: 1028506800
I0929 19:16:18.212468  2630 layer_factory.hpp:77] Creating layer Convolution40
I0929 19:16:18.212476  2630 net.cpp:84] Creating Layer Convolution40
I0929 19:16:18.212478  2630 net.cpp:406] Convolution40 <- Eltwise18_ReLU37_0_split_1
I0929 19:16:18.212482  2630 net.cpp:380] Convolution40 -> Convolution40
I0929 19:16:18.213853  2630 net.cpp:122] Setting up Convolution40
I0929 19:16:18.213862  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.213865  2630 net.cpp:137] Memory required for data: 1030145200
I0929 19:16:18.213870  2630 layer_factory.hpp:77] Creating layer BatchNorm40
I0929 19:16:18.233736  2630 net.cpp:84] Creating Layer BatchNorm40
I0929 19:16:18.233747  2630 net.cpp:406] BatchNorm40 <- Convolution40
I0929 19:16:18.233754  2630 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0929 19:16:18.233940  2630 net.cpp:122] Setting up BatchNorm40
I0929 19:16:18.233947  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.233949  2630 net.cpp:137] Memory required for data: 1031783600
I0929 19:16:18.233955  2630 layer_factory.hpp:77] Creating layer Scale40
I0929 19:16:18.233960  2630 net.cpp:84] Creating Layer Scale40
I0929 19:16:18.233963  2630 net.cpp:406] Scale40 <- Convolution40
I0929 19:16:18.233966  2630 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0929 19:16:18.233995  2630 layer_factory.hpp:77] Creating layer Scale40
I0929 19:16:18.234072  2630 net.cpp:122] Setting up Scale40
I0929 19:16:18.234077  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.234079  2630 net.cpp:137] Memory required for data: 1033422000
I0929 19:16:18.234083  2630 layer_factory.hpp:77] Creating layer ReLU38
I0929 19:16:18.234087  2630 net.cpp:84] Creating Layer ReLU38
I0929 19:16:18.234091  2630 net.cpp:406] ReLU38 <- Convolution40
I0929 19:16:18.234092  2630 net.cpp:367] ReLU38 -> Convolution40 (in-place)
I0929 19:16:18.234236  2630 net.cpp:122] Setting up ReLU38
I0929 19:16:18.234242  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.234244  2630 net.cpp:137] Memory required for data: 1035060400
I0929 19:16:18.234247  2630 layer_factory.hpp:77] Creating layer Convolution41
I0929 19:16:18.234253  2630 net.cpp:84] Creating Layer Convolution41
I0929 19:16:18.234256  2630 net.cpp:406] Convolution41 <- Convolution40
I0929 19:16:18.234261  2630 net.cpp:380] Convolution41 -> Convolution41
I0929 19:16:18.236099  2630 net.cpp:122] Setting up Convolution41
I0929 19:16:18.236107  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.236110  2630 net.cpp:137] Memory required for data: 1036698800
I0929 19:16:18.236115  2630 layer_factory.hpp:77] Creating layer BatchNorm41
I0929 19:16:18.236120  2630 net.cpp:84] Creating Layer BatchNorm41
I0929 19:16:18.236124  2630 net.cpp:406] BatchNorm41 <- Convolution41
I0929 19:16:18.236127  2630 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0929 19:16:18.236261  2630 net.cpp:122] Setting up BatchNorm41
I0929 19:16:18.236266  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.236268  2630 net.cpp:137] Memory required for data: 1038337200
I0929 19:16:18.236274  2630 layer_factory.hpp:77] Creating layer Scale41
I0929 19:16:18.236277  2630 net.cpp:84] Creating Layer Scale41
I0929 19:16:18.236279  2630 net.cpp:406] Scale41 <- Convolution41
I0929 19:16:18.236282  2630 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0929 19:16:18.236310  2630 layer_factory.hpp:77] Creating layer Scale41
I0929 19:16:18.236383  2630 net.cpp:122] Setting up Scale41
I0929 19:16:18.236387  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.236389  2630 net.cpp:137] Memory required for data: 1039975600
I0929 19:16:18.236393  2630 layer_factory.hpp:77] Creating layer Eltwise19
I0929 19:16:18.236398  2630 net.cpp:84] Creating Layer Eltwise19
I0929 19:16:18.236400  2630 net.cpp:406] Eltwise19 <- Convolution39
I0929 19:16:18.236412  2630 net.cpp:406] Eltwise19 <- Convolution41
I0929 19:16:18.236415  2630 net.cpp:380] Eltwise19 -> Eltwise19
I0929 19:16:18.236433  2630 net.cpp:122] Setting up Eltwise19
I0929 19:16:18.236436  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.236438  2630 net.cpp:137] Memory required for data: 1041614000
I0929 19:16:18.236440  2630 layer_factory.hpp:77] Creating layer ReLU39
I0929 19:16:18.236443  2630 net.cpp:84] Creating Layer ReLU39
I0929 19:16:18.236446  2630 net.cpp:406] ReLU39 <- Eltwise19
I0929 19:16:18.236449  2630 net.cpp:367] ReLU39 -> Eltwise19 (in-place)
I0929 19:16:18.236582  2630 net.cpp:122] Setting up ReLU39
I0929 19:16:18.236588  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.236590  2630 net.cpp:137] Memory required for data: 1043252400
I0929 19:16:18.236593  2630 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0929 19:16:18.236596  2630 net.cpp:84] Creating Layer Eltwise19_ReLU39_0_split
I0929 19:16:18.236599  2630 net.cpp:406] Eltwise19_ReLU39_0_split <- Eltwise19
I0929 19:16:18.236603  2630 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0929 19:16:18.236608  2630 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0929 19:16:18.236634  2630 net.cpp:122] Setting up Eltwise19_ReLU39_0_split
I0929 19:16:18.236639  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.236641  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.236644  2630 net.cpp:137] Memory required for data: 1046529200
I0929 19:16:18.236645  2630 layer_factory.hpp:77] Creating layer Convolution42
I0929 19:16:18.236652  2630 net.cpp:84] Creating Layer Convolution42
I0929 19:16:18.236655  2630 net.cpp:406] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0929 19:16:18.236660  2630 net.cpp:380] Convolution42 -> Convolution42
I0929 19:16:18.238389  2630 net.cpp:122] Setting up Convolution42
I0929 19:16:18.238399  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.238400  2630 net.cpp:137] Memory required for data: 1048167600
I0929 19:16:18.238405  2630 layer_factory.hpp:77] Creating layer BatchNorm42
I0929 19:16:18.238409  2630 net.cpp:84] Creating Layer BatchNorm42
I0929 19:16:18.238412  2630 net.cpp:406] BatchNorm42 <- Convolution42
I0929 19:16:18.238417  2630 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0929 19:16:18.238554  2630 net.cpp:122] Setting up BatchNorm42
I0929 19:16:18.238559  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.238561  2630 net.cpp:137] Memory required for data: 1049806000
I0929 19:16:18.238565  2630 layer_factory.hpp:77] Creating layer Scale42
I0929 19:16:18.238570  2630 net.cpp:84] Creating Layer Scale42
I0929 19:16:18.238572  2630 net.cpp:406] Scale42 <- Convolution42
I0929 19:16:18.238575  2630 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0929 19:16:18.238603  2630 layer_factory.hpp:77] Creating layer Scale42
I0929 19:16:18.238679  2630 net.cpp:122] Setting up Scale42
I0929 19:16:18.238684  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.238687  2630 net.cpp:137] Memory required for data: 1051444400
I0929 19:16:18.238690  2630 layer_factory.hpp:77] Creating layer ReLU40
I0929 19:16:18.238693  2630 net.cpp:84] Creating Layer ReLU40
I0929 19:16:18.238696  2630 net.cpp:406] ReLU40 <- Convolution42
I0929 19:16:18.238699  2630 net.cpp:367] ReLU40 -> Convolution42 (in-place)
I0929 19:16:18.238833  2630 net.cpp:122] Setting up ReLU40
I0929 19:16:18.238839  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.238842  2630 net.cpp:137] Memory required for data: 1053082800
I0929 19:16:18.238844  2630 layer_factory.hpp:77] Creating layer Convolution43
I0929 19:16:18.238850  2630 net.cpp:84] Creating Layer Convolution43
I0929 19:16:18.238853  2630 net.cpp:406] Convolution43 <- Convolution42
I0929 19:16:18.238858  2630 net.cpp:380] Convolution43 -> Convolution43
I0929 19:16:18.240587  2630 net.cpp:122] Setting up Convolution43
I0929 19:16:18.240595  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.240604  2630 net.cpp:137] Memory required for data: 1054721200
I0929 19:16:18.240609  2630 layer_factory.hpp:77] Creating layer BatchNorm43
I0929 19:16:18.240615  2630 net.cpp:84] Creating Layer BatchNorm43
I0929 19:16:18.240618  2630 net.cpp:406] BatchNorm43 <- Convolution43
I0929 19:16:18.240622  2630 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0929 19:16:18.240754  2630 net.cpp:122] Setting up BatchNorm43
I0929 19:16:18.240758  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.240761  2630 net.cpp:137] Memory required for data: 1056359600
I0929 19:16:18.240766  2630 layer_factory.hpp:77] Creating layer Scale43
I0929 19:16:18.240770  2630 net.cpp:84] Creating Layer Scale43
I0929 19:16:18.240772  2630 net.cpp:406] Scale43 <- Convolution43
I0929 19:16:18.240775  2630 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0929 19:16:18.240803  2630 layer_factory.hpp:77] Creating layer Scale43
I0929 19:16:18.240876  2630 net.cpp:122] Setting up Scale43
I0929 19:16:18.240880  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.240882  2630 net.cpp:137] Memory required for data: 1057998000
I0929 19:16:18.240886  2630 layer_factory.hpp:77] Creating layer Eltwise20
I0929 19:16:18.240890  2630 net.cpp:84] Creating Layer Eltwise20
I0929 19:16:18.240893  2630 net.cpp:406] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0929 19:16:18.240896  2630 net.cpp:406] Eltwise20 <- Convolution43
I0929 19:16:18.240900  2630 net.cpp:380] Eltwise20 -> Eltwise20
I0929 19:16:18.240916  2630 net.cpp:122] Setting up Eltwise20
I0929 19:16:18.240919  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.240921  2630 net.cpp:137] Memory required for data: 1059636400
I0929 19:16:18.240923  2630 layer_factory.hpp:77] Creating layer ReLU41
I0929 19:16:18.240926  2630 net.cpp:84] Creating Layer ReLU41
I0929 19:16:18.240928  2630 net.cpp:406] ReLU41 <- Eltwise20
I0929 19:16:18.240932  2630 net.cpp:367] ReLU41 -> Eltwise20 (in-place)
I0929 19:16:18.241066  2630 net.cpp:122] Setting up ReLU41
I0929 19:16:18.241072  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.241075  2630 net.cpp:137] Memory required for data: 1061274800
I0929 19:16:18.241076  2630 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0929 19:16:18.241080  2630 net.cpp:84] Creating Layer Eltwise20_ReLU41_0_split
I0929 19:16:18.241082  2630 net.cpp:406] Eltwise20_ReLU41_0_split <- Eltwise20
I0929 19:16:18.241086  2630 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0929 19:16:18.241091  2630 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0929 19:16:18.241118  2630 net.cpp:122] Setting up Eltwise20_ReLU41_0_split
I0929 19:16:18.241123  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.241125  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.241127  2630 net.cpp:137] Memory required for data: 1064551600
I0929 19:16:18.241129  2630 layer_factory.hpp:77] Creating layer Convolution44
I0929 19:16:18.241137  2630 net.cpp:84] Creating Layer Convolution44
I0929 19:16:18.241139  2630 net.cpp:406] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0929 19:16:18.241143  2630 net.cpp:380] Convolution44 -> Convolution44
I0929 19:16:18.243197  2630 net.cpp:122] Setting up Convolution44
I0929 19:16:18.243206  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.243208  2630 net.cpp:137] Memory required for data: 1066190000
I0929 19:16:18.243213  2630 layer_factory.hpp:77] Creating layer BatchNorm44
I0929 19:16:18.243218  2630 net.cpp:84] Creating Layer BatchNorm44
I0929 19:16:18.243221  2630 net.cpp:406] BatchNorm44 <- Convolution44
I0929 19:16:18.243225  2630 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0929 19:16:18.243362  2630 net.cpp:122] Setting up BatchNorm44
I0929 19:16:18.243366  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.243368  2630 net.cpp:137] Memory required for data: 1067828400
I0929 19:16:18.243373  2630 layer_factory.hpp:77] Creating layer Scale44
I0929 19:16:18.243377  2630 net.cpp:84] Creating Layer Scale44
I0929 19:16:18.243386  2630 net.cpp:406] Scale44 <- Convolution44
I0929 19:16:18.243391  2630 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0929 19:16:18.243418  2630 layer_factory.hpp:77] Creating layer Scale44
I0929 19:16:18.243495  2630 net.cpp:122] Setting up Scale44
I0929 19:16:18.243499  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.243501  2630 net.cpp:137] Memory required for data: 1069466800
I0929 19:16:18.243505  2630 layer_factory.hpp:77] Creating layer ReLU42
I0929 19:16:18.243510  2630 net.cpp:84] Creating Layer ReLU42
I0929 19:16:18.243511  2630 net.cpp:406] ReLU42 <- Convolution44
I0929 19:16:18.243515  2630 net.cpp:367] ReLU42 -> Convolution44 (in-place)
I0929 19:16:18.243983  2630 net.cpp:122] Setting up ReLU42
I0929 19:16:18.243991  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.243993  2630 net.cpp:137] Memory required for data: 1071105200
I0929 19:16:18.243996  2630 layer_factory.hpp:77] Creating layer Convolution45
I0929 19:16:18.244004  2630 net.cpp:84] Creating Layer Convolution45
I0929 19:16:18.244006  2630 net.cpp:406] Convolution45 <- Convolution44
I0929 19:16:18.244011  2630 net.cpp:380] Convolution45 -> Convolution45
I0929 19:16:18.245400  2630 net.cpp:122] Setting up Convolution45
I0929 19:16:18.245409  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.245411  2630 net.cpp:137] Memory required for data: 1072743600
I0929 19:16:18.245415  2630 layer_factory.hpp:77] Creating layer BatchNorm45
I0929 19:16:18.245420  2630 net.cpp:84] Creating Layer BatchNorm45
I0929 19:16:18.245424  2630 net.cpp:406] BatchNorm45 <- Convolution45
I0929 19:16:18.245427  2630 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0929 19:16:18.245563  2630 net.cpp:122] Setting up BatchNorm45
I0929 19:16:18.245566  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.245569  2630 net.cpp:137] Memory required for data: 1074382000
I0929 19:16:18.245573  2630 layer_factory.hpp:77] Creating layer Scale45
I0929 19:16:18.245579  2630 net.cpp:84] Creating Layer Scale45
I0929 19:16:18.245581  2630 net.cpp:406] Scale45 <- Convolution45
I0929 19:16:18.245584  2630 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0929 19:16:18.245610  2630 layer_factory.hpp:77] Creating layer Scale45
I0929 19:16:18.245687  2630 net.cpp:122] Setting up Scale45
I0929 19:16:18.245690  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.245692  2630 net.cpp:137] Memory required for data: 1076020400
I0929 19:16:18.245697  2630 layer_factory.hpp:77] Creating layer Eltwise21
I0929 19:16:18.245702  2630 net.cpp:84] Creating Layer Eltwise21
I0929 19:16:18.245703  2630 net.cpp:406] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0929 19:16:18.245707  2630 net.cpp:406] Eltwise21 <- Convolution45
I0929 19:16:18.245710  2630 net.cpp:380] Eltwise21 -> Eltwise21
I0929 19:16:18.245726  2630 net.cpp:122] Setting up Eltwise21
I0929 19:16:18.245730  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.245733  2630 net.cpp:137] Memory required for data: 1077658800
I0929 19:16:18.245734  2630 layer_factory.hpp:77] Creating layer ReLU43
I0929 19:16:18.245738  2630 net.cpp:84] Creating Layer ReLU43
I0929 19:16:18.245740  2630 net.cpp:406] ReLU43 <- Eltwise21
I0929 19:16:18.245743  2630 net.cpp:367] ReLU43 -> Eltwise21 (in-place)
I0929 19:16:18.246207  2630 net.cpp:122] Setting up ReLU43
I0929 19:16:18.246215  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.246218  2630 net.cpp:137] Memory required for data: 1079297200
I0929 19:16:18.246220  2630 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0929 19:16:18.246225  2630 net.cpp:84] Creating Layer Eltwise21_ReLU43_0_split
I0929 19:16:18.246228  2630 net.cpp:406] Eltwise21_ReLU43_0_split <- Eltwise21
I0929 19:16:18.246232  2630 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0929 19:16:18.246237  2630 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0929 19:16:18.246265  2630 net.cpp:122] Setting up Eltwise21_ReLU43_0_split
I0929 19:16:18.246270  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.246279  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.246281  2630 net.cpp:137] Memory required for data: 1082574000
I0929 19:16:18.246284  2630 layer_factory.hpp:77] Creating layer Convolution46
I0929 19:16:18.246291  2630 net.cpp:84] Creating Layer Convolution46
I0929 19:16:18.246294  2630 net.cpp:406] Convolution46 <- Eltwise21_ReLU43_0_split_0
I0929 19:16:18.246299  2630 net.cpp:380] Convolution46 -> Convolution46
I0929 19:16:18.248322  2630 net.cpp:122] Setting up Convolution46
I0929 19:16:18.248330  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.248333  2630 net.cpp:137] Memory required for data: 1084212400
I0929 19:16:18.248338  2630 layer_factory.hpp:77] Creating layer BatchNorm46
I0929 19:16:18.261904  2630 net.cpp:84] Creating Layer BatchNorm46
I0929 19:16:18.261914  2630 net.cpp:406] BatchNorm46 <- Convolution46
I0929 19:16:18.261919  2630 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0929 19:16:18.262079  2630 net.cpp:122] Setting up BatchNorm46
I0929 19:16:18.262085  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.262089  2630 net.cpp:137] Memory required for data: 1085850800
I0929 19:16:18.262094  2630 layer_factory.hpp:77] Creating layer Scale46
I0929 19:16:18.262099  2630 net.cpp:84] Creating Layer Scale46
I0929 19:16:18.262101  2630 net.cpp:406] Scale46 <- Convolution46
I0929 19:16:18.262104  2630 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0929 19:16:18.262135  2630 layer_factory.hpp:77] Creating layer Scale46
I0929 19:16:18.262221  2630 net.cpp:122] Setting up Scale46
I0929 19:16:18.262228  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.262229  2630 net.cpp:137] Memory required for data: 1087489200
I0929 19:16:18.262233  2630 layer_factory.hpp:77] Creating layer ReLU44
I0929 19:16:18.262238  2630 net.cpp:84] Creating Layer ReLU44
I0929 19:16:18.262240  2630 net.cpp:406] ReLU44 <- Convolution46
I0929 19:16:18.262243  2630 net.cpp:367] ReLU44 -> Convolution46 (in-place)
I0929 19:16:18.262395  2630 net.cpp:122] Setting up ReLU44
I0929 19:16:18.262403  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.262405  2630 net.cpp:137] Memory required for data: 1089127600
I0929 19:16:18.262408  2630 layer_factory.hpp:77] Creating layer Convolution47
I0929 19:16:18.262415  2630 net.cpp:84] Creating Layer Convolution47
I0929 19:16:18.262418  2630 net.cpp:406] Convolution47 <- Convolution46
I0929 19:16:18.262423  2630 net.cpp:380] Convolution47 -> Convolution47
I0929 19:16:18.264652  2630 net.cpp:122] Setting up Convolution47
I0929 19:16:18.264662  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.264664  2630 net.cpp:137] Memory required for data: 1090766000
I0929 19:16:18.264668  2630 layer_factory.hpp:77] Creating layer BatchNorm47
I0929 19:16:18.264674  2630 net.cpp:84] Creating Layer BatchNorm47
I0929 19:16:18.264677  2630 net.cpp:406] BatchNorm47 <- Convolution47
I0929 19:16:18.264681  2630 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0929 19:16:18.264817  2630 net.cpp:122] Setting up BatchNorm47
I0929 19:16:18.264822  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.264823  2630 net.cpp:137] Memory required for data: 1092404400
I0929 19:16:18.264828  2630 layer_factory.hpp:77] Creating layer Scale47
I0929 19:16:18.264832  2630 net.cpp:84] Creating Layer Scale47
I0929 19:16:18.264835  2630 net.cpp:406] Scale47 <- Convolution47
I0929 19:16:18.264838  2630 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0929 19:16:18.264865  2630 layer_factory.hpp:77] Creating layer Scale47
I0929 19:16:18.264942  2630 net.cpp:122] Setting up Scale47
I0929 19:16:18.264946  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.264948  2630 net.cpp:137] Memory required for data: 1094042800
I0929 19:16:18.264952  2630 layer_factory.hpp:77] Creating layer Eltwise22
I0929 19:16:18.264956  2630 net.cpp:84] Creating Layer Eltwise22
I0929 19:16:18.264960  2630 net.cpp:406] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0929 19:16:18.264962  2630 net.cpp:406] Eltwise22 <- Convolution47
I0929 19:16:18.264972  2630 net.cpp:380] Eltwise22 -> Eltwise22
I0929 19:16:18.264991  2630 net.cpp:122] Setting up Eltwise22
I0929 19:16:18.264994  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.264997  2630 net.cpp:137] Memory required for data: 1095681200
I0929 19:16:18.264998  2630 layer_factory.hpp:77] Creating layer ReLU45
I0929 19:16:18.265002  2630 net.cpp:84] Creating Layer ReLU45
I0929 19:16:18.265004  2630 net.cpp:406] ReLU45 <- Eltwise22
I0929 19:16:18.265007  2630 net.cpp:367] ReLU45 -> Eltwise22 (in-place)
I0929 19:16:18.265142  2630 net.cpp:122] Setting up ReLU45
I0929 19:16:18.265148  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.265151  2630 net.cpp:137] Memory required for data: 1097319600
I0929 19:16:18.265153  2630 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0929 19:16:18.265157  2630 net.cpp:84] Creating Layer Eltwise22_ReLU45_0_split
I0929 19:16:18.265161  2630 net.cpp:406] Eltwise22_ReLU45_0_split <- Eltwise22
I0929 19:16:18.265163  2630 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0929 19:16:18.265168  2630 net.cpp:380] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0929 19:16:18.265195  2630 net.cpp:122] Setting up Eltwise22_ReLU45_0_split
I0929 19:16:18.265199  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.265202  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.265204  2630 net.cpp:137] Memory required for data: 1100596400
I0929 19:16:18.265206  2630 layer_factory.hpp:77] Creating layer Convolution48
I0929 19:16:18.265213  2630 net.cpp:84] Creating Layer Convolution48
I0929 19:16:18.265216  2630 net.cpp:406] Convolution48 <- Eltwise22_ReLU45_0_split_0
I0929 19:16:18.265220  2630 net.cpp:380] Convolution48 -> Convolution48
I0929 19:16:18.267370  2630 net.cpp:122] Setting up Convolution48
I0929 19:16:18.267379  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.267381  2630 net.cpp:137] Memory required for data: 1102234800
I0929 19:16:18.267386  2630 layer_factory.hpp:77] Creating layer BatchNorm48
I0929 19:16:18.267391  2630 net.cpp:84] Creating Layer BatchNorm48
I0929 19:16:18.267395  2630 net.cpp:406] BatchNorm48 <- Convolution48
I0929 19:16:18.267398  2630 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0929 19:16:18.267535  2630 net.cpp:122] Setting up BatchNorm48
I0929 19:16:18.267539  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.267541  2630 net.cpp:137] Memory required for data: 1103873200
I0929 19:16:18.267546  2630 layer_factory.hpp:77] Creating layer Scale48
I0929 19:16:18.267550  2630 net.cpp:84] Creating Layer Scale48
I0929 19:16:18.267552  2630 net.cpp:406] Scale48 <- Convolution48
I0929 19:16:18.267555  2630 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0929 19:16:18.267581  2630 layer_factory.hpp:77] Creating layer Scale48
I0929 19:16:18.267658  2630 net.cpp:122] Setting up Scale48
I0929 19:16:18.267663  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.267664  2630 net.cpp:137] Memory required for data: 1105511600
I0929 19:16:18.267668  2630 layer_factory.hpp:77] Creating layer ReLU46
I0929 19:16:18.267671  2630 net.cpp:84] Creating Layer ReLU46
I0929 19:16:18.267673  2630 net.cpp:406] ReLU46 <- Convolution48
I0929 19:16:18.267676  2630 net.cpp:367] ReLU46 -> Convolution48 (in-place)
I0929 19:16:18.267813  2630 net.cpp:122] Setting up ReLU46
I0929 19:16:18.267818  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.267820  2630 net.cpp:137] Memory required for data: 1107150000
I0929 19:16:18.267823  2630 layer_factory.hpp:77] Creating layer Convolution49
I0929 19:16:18.267829  2630 net.cpp:84] Creating Layer Convolution49
I0929 19:16:18.267832  2630 net.cpp:406] Convolution49 <- Convolution48
I0929 19:16:18.267838  2630 net.cpp:380] Convolution49 -> Convolution49
I0929 19:16:18.269528  2630 net.cpp:122] Setting up Convolution49
I0929 19:16:18.269537  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.269539  2630 net.cpp:137] Memory required for data: 1108788400
I0929 19:16:18.269551  2630 layer_factory.hpp:77] Creating layer BatchNorm49
I0929 19:16:18.269557  2630 net.cpp:84] Creating Layer BatchNorm49
I0929 19:16:18.269560  2630 net.cpp:406] BatchNorm49 <- Convolution49
I0929 19:16:18.269564  2630 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0929 19:16:18.269697  2630 net.cpp:122] Setting up BatchNorm49
I0929 19:16:18.269701  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.269703  2630 net.cpp:137] Memory required for data: 1110426800
I0929 19:16:18.269708  2630 layer_factory.hpp:77] Creating layer Scale49
I0929 19:16:18.269712  2630 net.cpp:84] Creating Layer Scale49
I0929 19:16:18.269716  2630 net.cpp:406] Scale49 <- Convolution49
I0929 19:16:18.269721  2630 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0929 19:16:18.269747  2630 layer_factory.hpp:77] Creating layer Scale49
I0929 19:16:18.269821  2630 net.cpp:122] Setting up Scale49
I0929 19:16:18.269825  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.269827  2630 net.cpp:137] Memory required for data: 1112065200
I0929 19:16:18.269831  2630 layer_factory.hpp:77] Creating layer Eltwise23
I0929 19:16:18.269835  2630 net.cpp:84] Creating Layer Eltwise23
I0929 19:16:18.269837  2630 net.cpp:406] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0929 19:16:18.269840  2630 net.cpp:406] Eltwise23 <- Convolution49
I0929 19:16:18.269845  2630 net.cpp:380] Eltwise23 -> Eltwise23
I0929 19:16:18.269860  2630 net.cpp:122] Setting up Eltwise23
I0929 19:16:18.269865  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.269866  2630 net.cpp:137] Memory required for data: 1113703600
I0929 19:16:18.269868  2630 layer_factory.hpp:77] Creating layer ReLU47
I0929 19:16:18.269872  2630 net.cpp:84] Creating Layer ReLU47
I0929 19:16:18.269875  2630 net.cpp:406] ReLU47 <- Eltwise23
I0929 19:16:18.269877  2630 net.cpp:367] ReLU47 -> Eltwise23 (in-place)
I0929 19:16:18.270009  2630 net.cpp:122] Setting up ReLU47
I0929 19:16:18.270015  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.270016  2630 net.cpp:137] Memory required for data: 1115342000
I0929 19:16:18.270018  2630 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0929 19:16:18.270022  2630 net.cpp:84] Creating Layer Eltwise23_ReLU47_0_split
I0929 19:16:18.270025  2630 net.cpp:406] Eltwise23_ReLU47_0_split <- Eltwise23
I0929 19:16:18.270028  2630 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0929 19:16:18.270033  2630 net.cpp:380] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0929 19:16:18.270059  2630 net.cpp:122] Setting up Eltwise23_ReLU47_0_split
I0929 19:16:18.270063  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.270066  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.270068  2630 net.cpp:137] Memory required for data: 1118618800
I0929 19:16:18.270071  2630 layer_factory.hpp:77] Creating layer Convolution50
I0929 19:16:18.270077  2630 net.cpp:84] Creating Layer Convolution50
I0929 19:16:18.270079  2630 net.cpp:406] Convolution50 <- Eltwise23_ReLU47_0_split_0
I0929 19:16:18.270083  2630 net.cpp:380] Convolution50 -> Convolution50
I0929 19:16:18.272637  2630 net.cpp:122] Setting up Convolution50
I0929 19:16:18.272646  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.272650  2630 net.cpp:137] Memory required for data: 1120257200
I0929 19:16:18.272655  2630 layer_factory.hpp:77] Creating layer BatchNorm50
I0929 19:16:18.272660  2630 net.cpp:84] Creating Layer BatchNorm50
I0929 19:16:18.272662  2630 net.cpp:406] BatchNorm50 <- Convolution50
I0929 19:16:18.272666  2630 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0929 19:16:18.272802  2630 net.cpp:122] Setting up BatchNorm50
I0929 19:16:18.272806  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.272809  2630 net.cpp:137] Memory required for data: 1121895600
I0929 19:16:18.272814  2630 layer_factory.hpp:77] Creating layer Scale50
I0929 19:16:18.272817  2630 net.cpp:84] Creating Layer Scale50
I0929 19:16:18.272820  2630 net.cpp:406] Scale50 <- Convolution50
I0929 19:16:18.272830  2630 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0929 19:16:18.272858  2630 layer_factory.hpp:77] Creating layer Scale50
I0929 19:16:18.272935  2630 net.cpp:122] Setting up Scale50
I0929 19:16:18.272939  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.272943  2630 net.cpp:137] Memory required for data: 1123534000
I0929 19:16:18.272945  2630 layer_factory.hpp:77] Creating layer ReLU48
I0929 19:16:18.272949  2630 net.cpp:84] Creating Layer ReLU48
I0929 19:16:18.272951  2630 net.cpp:406] ReLU48 <- Convolution50
I0929 19:16:18.272955  2630 net.cpp:367] ReLU48 -> Convolution50 (in-place)
I0929 19:16:18.273414  2630 net.cpp:122] Setting up ReLU48
I0929 19:16:18.273422  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.273424  2630 net.cpp:137] Memory required for data: 1125172400
I0929 19:16:18.273427  2630 layer_factory.hpp:77] Creating layer Convolution51
I0929 19:16:18.273434  2630 net.cpp:84] Creating Layer Convolution51
I0929 19:16:18.273437  2630 net.cpp:406] Convolution51 <- Convolution50
I0929 19:16:18.273442  2630 net.cpp:380] Convolution51 -> Convolution51
I0929 19:16:18.274821  2630 net.cpp:122] Setting up Convolution51
I0929 19:16:18.274828  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.274832  2630 net.cpp:137] Memory required for data: 1126810800
I0929 19:16:18.274835  2630 layer_factory.hpp:77] Creating layer BatchNorm51
I0929 19:16:18.274840  2630 net.cpp:84] Creating Layer BatchNorm51
I0929 19:16:18.274843  2630 net.cpp:406] BatchNorm51 <- Convolution51
I0929 19:16:18.274847  2630 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0929 19:16:18.274979  2630 net.cpp:122] Setting up BatchNorm51
I0929 19:16:18.274983  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.274986  2630 net.cpp:137] Memory required for data: 1128449200
I0929 19:16:18.274989  2630 layer_factory.hpp:77] Creating layer Scale51
I0929 19:16:18.274993  2630 net.cpp:84] Creating Layer Scale51
I0929 19:16:18.274996  2630 net.cpp:406] Scale51 <- Convolution51
I0929 19:16:18.274999  2630 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0929 19:16:18.275025  2630 layer_factory.hpp:77] Creating layer Scale51
I0929 19:16:18.275100  2630 net.cpp:122] Setting up Scale51
I0929 19:16:18.275104  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.275106  2630 net.cpp:137] Memory required for data: 1130087600
I0929 19:16:18.275110  2630 layer_factory.hpp:77] Creating layer Eltwise24
I0929 19:16:18.275113  2630 net.cpp:84] Creating Layer Eltwise24
I0929 19:16:18.275116  2630 net.cpp:406] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0929 19:16:18.275120  2630 net.cpp:406] Eltwise24 <- Convolution51
I0929 19:16:18.275122  2630 net.cpp:380] Eltwise24 -> Eltwise24
I0929 19:16:18.275138  2630 net.cpp:122] Setting up Eltwise24
I0929 19:16:18.275141  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.275143  2630 net.cpp:137] Memory required for data: 1131726000
I0929 19:16:18.275146  2630 layer_factory.hpp:77] Creating layer ReLU49
I0929 19:16:18.275151  2630 net.cpp:84] Creating Layer ReLU49
I0929 19:16:18.275152  2630 net.cpp:406] ReLU49 <- Eltwise24
I0929 19:16:18.275156  2630 net.cpp:367] ReLU49 -> Eltwise24 (in-place)
I0929 19:16:18.275614  2630 net.cpp:122] Setting up ReLU49
I0929 19:16:18.275621  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.275624  2630 net.cpp:137] Memory required for data: 1133364400
I0929 19:16:18.275626  2630 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0929 19:16:18.275631  2630 net.cpp:84] Creating Layer Eltwise24_ReLU49_0_split
I0929 19:16:18.275635  2630 net.cpp:406] Eltwise24_ReLU49_0_split <- Eltwise24
I0929 19:16:18.275637  2630 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0929 19:16:18.275642  2630 net.cpp:380] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0929 19:16:18.275681  2630 net.cpp:122] Setting up Eltwise24_ReLU49_0_split
I0929 19:16:18.275686  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.275689  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.275698  2630 net.cpp:137] Memory required for data: 1136641200
I0929 19:16:18.275701  2630 layer_factory.hpp:77] Creating layer Convolution52
I0929 19:16:18.275707  2630 net.cpp:84] Creating Layer Convolution52
I0929 19:16:18.275710  2630 net.cpp:406] Convolution52 <- Eltwise24_ReLU49_0_split_0
I0929 19:16:18.275714  2630 net.cpp:380] Convolution52 -> Convolution52
I0929 19:16:18.277709  2630 net.cpp:122] Setting up Convolution52
I0929 19:16:18.277717  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.277720  2630 net.cpp:137] Memory required for data: 1138279600
I0929 19:16:18.292655  2630 layer_factory.hpp:77] Creating layer BatchNorm52
I0929 19:16:18.292670  2630 net.cpp:84] Creating Layer BatchNorm52
I0929 19:16:18.292675  2630 net.cpp:406] BatchNorm52 <- Convolution52
I0929 19:16:18.292678  2630 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0929 19:16:18.292834  2630 net.cpp:122] Setting up BatchNorm52
I0929 19:16:18.292840  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.292842  2630 net.cpp:137] Memory required for data: 1139918000
I0929 19:16:18.292847  2630 layer_factory.hpp:77] Creating layer Scale52
I0929 19:16:18.292853  2630 net.cpp:84] Creating Layer Scale52
I0929 19:16:18.292856  2630 net.cpp:406] Scale52 <- Convolution52
I0929 19:16:18.292860  2630 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0929 19:16:18.292889  2630 layer_factory.hpp:77] Creating layer Scale52
I0929 19:16:18.292973  2630 net.cpp:122] Setting up Scale52
I0929 19:16:18.292979  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.292980  2630 net.cpp:137] Memory required for data: 1141556400
I0929 19:16:18.292984  2630 layer_factory.hpp:77] Creating layer ReLU50
I0929 19:16:18.293007  2630 net.cpp:84] Creating Layer ReLU50
I0929 19:16:18.293010  2630 net.cpp:406] ReLU50 <- Convolution52
I0929 19:16:18.293015  2630 net.cpp:367] ReLU50 -> Convolution52 (in-place)
I0929 19:16:18.293170  2630 net.cpp:122] Setting up ReLU50
I0929 19:16:18.293179  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.293181  2630 net.cpp:137] Memory required for data: 1143194800
I0929 19:16:18.293184  2630 layer_factory.hpp:77] Creating layer Convolution53
I0929 19:16:18.293191  2630 net.cpp:84] Creating Layer Convolution53
I0929 19:16:18.293195  2630 net.cpp:406] Convolution53 <- Convolution52
I0929 19:16:18.293200  2630 net.cpp:380] Convolution53 -> Convolution53
I0929 19:16:18.295416  2630 net.cpp:122] Setting up Convolution53
I0929 19:16:18.295426  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.295428  2630 net.cpp:137] Memory required for data: 1144833200
I0929 19:16:18.295433  2630 layer_factory.hpp:77] Creating layer BatchNorm53
I0929 19:16:18.295439  2630 net.cpp:84] Creating Layer BatchNorm53
I0929 19:16:18.295442  2630 net.cpp:406] BatchNorm53 <- Convolution53
I0929 19:16:18.295447  2630 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0929 19:16:18.295585  2630 net.cpp:122] Setting up BatchNorm53
I0929 19:16:18.295590  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.295593  2630 net.cpp:137] Memory required for data: 1146471600
I0929 19:16:18.295598  2630 layer_factory.hpp:77] Creating layer Scale53
I0929 19:16:18.295601  2630 net.cpp:84] Creating Layer Scale53
I0929 19:16:18.295604  2630 net.cpp:406] Scale53 <- Convolution53
I0929 19:16:18.295608  2630 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0929 19:16:18.295635  2630 layer_factory.hpp:77] Creating layer Scale53
I0929 19:16:18.295714  2630 net.cpp:122] Setting up Scale53
I0929 19:16:18.295719  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.295722  2630 net.cpp:137] Memory required for data: 1148110000
I0929 19:16:18.295725  2630 layer_factory.hpp:77] Creating layer Eltwise25
I0929 19:16:18.295729  2630 net.cpp:84] Creating Layer Eltwise25
I0929 19:16:18.295732  2630 net.cpp:406] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0929 19:16:18.295735  2630 net.cpp:406] Eltwise25 <- Convolution53
I0929 19:16:18.295738  2630 net.cpp:380] Eltwise25 -> Eltwise25
I0929 19:16:18.295763  2630 net.cpp:122] Setting up Eltwise25
I0929 19:16:18.295768  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.295770  2630 net.cpp:137] Memory required for data: 1149748400
I0929 19:16:18.295773  2630 layer_factory.hpp:77] Creating layer ReLU51
I0929 19:16:18.295776  2630 net.cpp:84] Creating Layer ReLU51
I0929 19:16:18.295779  2630 net.cpp:406] ReLU51 <- Eltwise25
I0929 19:16:18.295783  2630 net.cpp:367] ReLU51 -> Eltwise25 (in-place)
I0929 19:16:18.295922  2630 net.cpp:122] Setting up ReLU51
I0929 19:16:18.295928  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.295930  2630 net.cpp:137] Memory required for data: 1151386800
I0929 19:16:18.295933  2630 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0929 19:16:18.295938  2630 net.cpp:84] Creating Layer Eltwise25_ReLU51_0_split
I0929 19:16:18.295940  2630 net.cpp:406] Eltwise25_ReLU51_0_split <- Eltwise25
I0929 19:16:18.295943  2630 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0929 19:16:18.295948  2630 net.cpp:380] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0929 19:16:18.295975  2630 net.cpp:122] Setting up Eltwise25_ReLU51_0_split
I0929 19:16:18.295980  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.295982  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.295984  2630 net.cpp:137] Memory required for data: 1154663600
I0929 19:16:18.295987  2630 layer_factory.hpp:77] Creating layer Convolution54
I0929 19:16:18.295994  2630 net.cpp:84] Creating Layer Convolution54
I0929 19:16:18.295996  2630 net.cpp:406] Convolution54 <- Eltwise25_ReLU51_0_split_0
I0929 19:16:18.296001  2630 net.cpp:380] Convolution54 -> Convolution54
I0929 19:16:18.298125  2630 net.cpp:122] Setting up Convolution54
I0929 19:16:18.298133  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.298135  2630 net.cpp:137] Memory required for data: 1156302000
I0929 19:16:18.298141  2630 layer_factory.hpp:77] Creating layer BatchNorm54
I0929 19:16:18.298146  2630 net.cpp:84] Creating Layer BatchNorm54
I0929 19:16:18.298149  2630 net.cpp:406] BatchNorm54 <- Convolution54
I0929 19:16:18.298152  2630 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0929 19:16:18.298298  2630 net.cpp:122] Setting up BatchNorm54
I0929 19:16:18.298303  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.298305  2630 net.cpp:137] Memory required for data: 1157940400
I0929 19:16:18.298310  2630 layer_factory.hpp:77] Creating layer Scale54
I0929 19:16:18.298316  2630 net.cpp:84] Creating Layer Scale54
I0929 19:16:18.298317  2630 net.cpp:406] Scale54 <- Convolution54
I0929 19:16:18.298321  2630 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0929 19:16:18.298351  2630 layer_factory.hpp:77] Creating layer Scale54
I0929 19:16:18.298430  2630 net.cpp:122] Setting up Scale54
I0929 19:16:18.298435  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.298439  2630 net.cpp:137] Memory required for data: 1159578800
I0929 19:16:18.298442  2630 layer_factory.hpp:77] Creating layer ReLU52
I0929 19:16:18.298445  2630 net.cpp:84] Creating Layer ReLU52
I0929 19:16:18.298449  2630 net.cpp:406] ReLU52 <- Convolution54
I0929 19:16:18.298451  2630 net.cpp:367] ReLU52 -> Convolution54 (in-place)
I0929 19:16:18.298609  2630 net.cpp:122] Setting up ReLU52
I0929 19:16:18.298616  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.298619  2630 net.cpp:137] Memory required for data: 1161217200
I0929 19:16:18.298621  2630 layer_factory.hpp:77] Creating layer Convolution55
I0929 19:16:18.298629  2630 net.cpp:84] Creating Layer Convolution55
I0929 19:16:18.298631  2630 net.cpp:406] Convolution55 <- Convolution54
I0929 19:16:18.298636  2630 net.cpp:380] Convolution55 -> Convolution55
I0929 19:16:18.300376  2630 net.cpp:122] Setting up Convolution55
I0929 19:16:18.300385  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.300388  2630 net.cpp:137] Memory required for data: 1162855600
I0929 19:16:18.300392  2630 layer_factory.hpp:77] Creating layer BatchNorm55
I0929 19:16:18.300405  2630 net.cpp:84] Creating Layer BatchNorm55
I0929 19:16:18.300407  2630 net.cpp:406] BatchNorm55 <- Convolution55
I0929 19:16:18.300412  2630 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0929 19:16:18.300550  2630 net.cpp:122] Setting up BatchNorm55
I0929 19:16:18.300554  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.300557  2630 net.cpp:137] Memory required for data: 1164494000
I0929 19:16:18.300561  2630 layer_factory.hpp:77] Creating layer Scale55
I0929 19:16:18.300565  2630 net.cpp:84] Creating Layer Scale55
I0929 19:16:18.300568  2630 net.cpp:406] Scale55 <- Convolution55
I0929 19:16:18.300572  2630 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0929 19:16:18.300598  2630 layer_factory.hpp:77] Creating layer Scale55
I0929 19:16:18.300675  2630 net.cpp:122] Setting up Scale55
I0929 19:16:18.300679  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.300681  2630 net.cpp:137] Memory required for data: 1166132400
I0929 19:16:18.300685  2630 layer_factory.hpp:77] Creating layer Eltwise26
I0929 19:16:18.300689  2630 net.cpp:84] Creating Layer Eltwise26
I0929 19:16:18.300693  2630 net.cpp:406] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0929 19:16:18.300695  2630 net.cpp:406] Eltwise26 <- Convolution55
I0929 19:16:18.300699  2630 net.cpp:380] Eltwise26 -> Eltwise26
I0929 19:16:18.300714  2630 net.cpp:122] Setting up Eltwise26
I0929 19:16:18.300719  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.300720  2630 net.cpp:137] Memory required for data: 1167770800
I0929 19:16:18.300722  2630 layer_factory.hpp:77] Creating layer ReLU53
I0929 19:16:18.300726  2630 net.cpp:84] Creating Layer ReLU53
I0929 19:16:18.300729  2630 net.cpp:406] ReLU53 <- Eltwise26
I0929 19:16:18.300731  2630 net.cpp:367] ReLU53 -> Eltwise26 (in-place)
I0929 19:16:18.301196  2630 net.cpp:122] Setting up ReLU53
I0929 19:16:18.301204  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.301208  2630 net.cpp:137] Memory required for data: 1169409200
I0929 19:16:18.301209  2630 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0929 19:16:18.301214  2630 net.cpp:84] Creating Layer Eltwise26_ReLU53_0_split
I0929 19:16:18.301218  2630 net.cpp:406] Eltwise26_ReLU53_0_split <- Eltwise26
I0929 19:16:18.301221  2630 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0929 19:16:18.301226  2630 net.cpp:380] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0929 19:16:18.301256  2630 net.cpp:122] Setting up Eltwise26_ReLU53_0_split
I0929 19:16:18.301260  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.301264  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.301265  2630 net.cpp:137] Memory required for data: 1172686000
I0929 19:16:18.301267  2630 layer_factory.hpp:77] Creating layer Convolution56
I0929 19:16:18.301273  2630 net.cpp:84] Creating Layer Convolution56
I0929 19:16:18.301276  2630 net.cpp:406] Convolution56 <- Eltwise26_ReLU53_0_split_0
I0929 19:16:18.301281  2630 net.cpp:380] Convolution56 -> Convolution56
I0929 19:16:18.303362  2630 net.cpp:122] Setting up Convolution56
I0929 19:16:18.303370  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.303373  2630 net.cpp:137] Memory required for data: 1174324400
I0929 19:16:18.303378  2630 layer_factory.hpp:77] Creating layer BatchNorm56
I0929 19:16:18.303383  2630 net.cpp:84] Creating Layer BatchNorm56
I0929 19:16:18.303386  2630 net.cpp:406] BatchNorm56 <- Convolution56
I0929 19:16:18.303390  2630 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0929 19:16:18.303531  2630 net.cpp:122] Setting up BatchNorm56
I0929 19:16:18.303536  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.303539  2630 net.cpp:137] Memory required for data: 1175962800
I0929 19:16:18.303544  2630 layer_factory.hpp:77] Creating layer Scale56
I0929 19:16:18.303548  2630 net.cpp:84] Creating Layer Scale56
I0929 19:16:18.303551  2630 net.cpp:406] Scale56 <- Convolution56
I0929 19:16:18.303555  2630 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0929 19:16:18.303591  2630 layer_factory.hpp:77] Creating layer Scale56
I0929 19:16:18.303671  2630 net.cpp:122] Setting up Scale56
I0929 19:16:18.303675  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.303678  2630 net.cpp:137] Memory required for data: 1177601200
I0929 19:16:18.303681  2630 layer_factory.hpp:77] Creating layer ReLU54
I0929 19:16:18.303685  2630 net.cpp:84] Creating Layer ReLU54
I0929 19:16:18.303689  2630 net.cpp:406] ReLU54 <- Convolution56
I0929 19:16:18.303691  2630 net.cpp:367] ReLU54 -> Convolution56 (in-place)
I0929 19:16:18.304162  2630 net.cpp:122] Setting up ReLU54
I0929 19:16:18.304170  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.304172  2630 net.cpp:137] Memory required for data: 1179239600
I0929 19:16:18.304175  2630 layer_factory.hpp:77] Creating layer Convolution57
I0929 19:16:18.304183  2630 net.cpp:84] Creating Layer Convolution57
I0929 19:16:18.304185  2630 net.cpp:406] Convolution57 <- Convolution56
I0929 19:16:18.304191  2630 net.cpp:380] Convolution57 -> Convolution57
I0929 19:16:18.305614  2630 net.cpp:122] Setting up Convolution57
I0929 19:16:18.305622  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.305625  2630 net.cpp:137] Memory required for data: 1180878000
I0929 19:16:18.305629  2630 layer_factory.hpp:77] Creating layer BatchNorm57
I0929 19:16:18.305634  2630 net.cpp:84] Creating Layer BatchNorm57
I0929 19:16:18.305637  2630 net.cpp:406] BatchNorm57 <- Convolution57
I0929 19:16:18.305641  2630 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0929 19:16:18.305779  2630 net.cpp:122] Setting up BatchNorm57
I0929 19:16:18.305783  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.305785  2630 net.cpp:137] Memory required for data: 1182516400
I0929 19:16:18.305790  2630 layer_factory.hpp:77] Creating layer Scale57
I0929 19:16:18.305794  2630 net.cpp:84] Creating Layer Scale57
I0929 19:16:18.305797  2630 net.cpp:406] Scale57 <- Convolution57
I0929 19:16:18.305800  2630 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0929 19:16:18.305827  2630 layer_factory.hpp:77] Creating layer Scale57
I0929 19:16:18.305905  2630 net.cpp:122] Setting up Scale57
I0929 19:16:18.305909  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.305912  2630 net.cpp:137] Memory required for data: 1184154800
I0929 19:16:18.305915  2630 layer_factory.hpp:77] Creating layer Eltwise27
I0929 19:16:18.305919  2630 net.cpp:84] Creating Layer Eltwise27
I0929 19:16:18.305922  2630 net.cpp:406] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0929 19:16:18.305925  2630 net.cpp:406] Eltwise27 <- Convolution57
I0929 19:16:18.305929  2630 net.cpp:380] Eltwise27 -> Eltwise27
I0929 19:16:18.305945  2630 net.cpp:122] Setting up Eltwise27
I0929 19:16:18.305949  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.305951  2630 net.cpp:137] Memory required for data: 1185793200
I0929 19:16:18.305953  2630 layer_factory.hpp:77] Creating layer ReLU55
I0929 19:16:18.305956  2630 net.cpp:84] Creating Layer ReLU55
I0929 19:16:18.305958  2630 net.cpp:406] ReLU55 <- Eltwise27
I0929 19:16:18.305963  2630 net.cpp:367] ReLU55 -> Eltwise27 (in-place)
I0929 19:16:18.306432  2630 net.cpp:122] Setting up ReLU55
I0929 19:16:18.306440  2630 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 19:16:18.306442  2630 net.cpp:137] Memory required for data: 1187431600
I0929 19:16:18.306445  2630 layer_factory.hpp:77] Creating layer Pooling1
I0929 19:16:18.306449  2630 net.cpp:84] Creating Layer Pooling1
I0929 19:16:18.306452  2630 net.cpp:406] Pooling1 <- Eltwise27
I0929 19:16:18.306457  2630 net.cpp:380] Pooling1 -> Pooling1
I0929 19:16:18.306620  2630 net.cpp:122] Setting up Pooling1
I0929 19:16:18.306627  2630 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0929 19:16:18.306629  2630 net.cpp:137] Memory required for data: 1187457200
I0929 19:16:18.306632  2630 layer_factory.hpp:77] Creating layer InnerProduct1
I0929 19:16:18.306638  2630 net.cpp:84] Creating Layer InnerProduct1
I0929 19:16:18.306640  2630 net.cpp:406] InnerProduct1 <- Pooling1
I0929 19:16:18.306644  2630 net.cpp:380] InnerProduct1 -> InnerProduct1
I0929 19:16:18.306759  2630 net.cpp:122] Setting up InnerProduct1
I0929 19:16:18.306766  2630 net.cpp:129] Top shape: 100 10 (1000)
I0929 19:16:18.306767  2630 net.cpp:137] Memory required for data: 1187461200
I0929 19:16:18.306771  2630 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0929 19:16:18.306776  2630 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0929 19:16:18.326004  2630 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0929 19:16:18.326019  2630 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0929 19:16:18.326027  2630 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0929 19:16:18.326083  2630 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0929 19:16:18.326090  2630 net.cpp:129] Top shape: 100 10 (1000)
I0929 19:16:18.326095  2630 net.cpp:129] Top shape: 100 10 (1000)
I0929 19:16:18.326098  2630 net.cpp:137] Memory required for data: 1187469200
I0929 19:16:18.326102  2630 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 19:16:18.326109  2630 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0929 19:16:18.326114  2630 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0929 19:16:18.326120  2630 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0929 19:16:18.326125  2630 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0929 19:16:18.326133  2630 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 19:16:18.326370  2630 net.cpp:122] Setting up SoftmaxWithLoss1
I0929 19:16:18.326376  2630 net.cpp:129] Top shape: (1)
I0929 19:16:18.326380  2630 net.cpp:132]     with loss weight 1
I0929 19:16:18.326386  2630 net.cpp:137] Memory required for data: 1187469204
I0929 19:16:18.326390  2630 layer_factory.hpp:77] Creating layer Accuracy1
I0929 19:16:18.326395  2630 net.cpp:84] Creating Layer Accuracy1
I0929 19:16:18.326398  2630 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0929 19:16:18.326401  2630 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0929 19:16:18.326406  2630 net.cpp:380] Accuracy1 -> Accuracy1
I0929 19:16:18.326411  2630 net.cpp:122] Setting up Accuracy1
I0929 19:16:18.326416  2630 net.cpp:129] Top shape: (1)
I0929 19:16:18.326417  2630 net.cpp:137] Memory required for data: 1187469208
I0929 19:16:18.326421  2630 net.cpp:200] Accuracy1 does not need backward computation.
I0929 19:16:18.326422  2630 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0929 19:16:18.326426  2630 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0929 19:16:18.326428  2630 net.cpp:198] InnerProduct1 needs backward computation.
I0929 19:16:18.326431  2630 net.cpp:198] Pooling1 needs backward computation.
I0929 19:16:18.326433  2630 net.cpp:198] ReLU55 needs backward computation.
I0929 19:16:18.326436  2630 net.cpp:198] Eltwise27 needs backward computation.
I0929 19:16:18.326438  2630 net.cpp:198] Scale57 needs backward computation.
I0929 19:16:18.326441  2630 net.cpp:198] BatchNorm57 needs backward computation.
I0929 19:16:18.326442  2630 net.cpp:198] Convolution57 needs backward computation.
I0929 19:16:18.326445  2630 net.cpp:198] ReLU54 needs backward computation.
I0929 19:16:18.326447  2630 net.cpp:198] Scale56 needs backward computation.
I0929 19:16:18.326449  2630 net.cpp:198] BatchNorm56 needs backward computation.
I0929 19:16:18.326452  2630 net.cpp:198] Convolution56 needs backward computation.
I0929 19:16:18.326453  2630 net.cpp:198] Eltwise26_ReLU53_0_split needs backward computation.
I0929 19:16:18.326457  2630 net.cpp:198] ReLU53 needs backward computation.
I0929 19:16:18.326458  2630 net.cpp:198] Eltwise26 needs backward computation.
I0929 19:16:18.326462  2630 net.cpp:198] Scale55 needs backward computation.
I0929 19:16:18.326464  2630 net.cpp:198] BatchNorm55 needs backward computation.
I0929 19:16:18.326467  2630 net.cpp:198] Convolution55 needs backward computation.
I0929 19:16:18.326469  2630 net.cpp:198] ReLU52 needs backward computation.
I0929 19:16:18.326478  2630 net.cpp:198] Scale54 needs backward computation.
I0929 19:16:18.326480  2630 net.cpp:198] BatchNorm54 needs backward computation.
I0929 19:16:18.326483  2630 net.cpp:198] Convolution54 needs backward computation.
I0929 19:16:18.326485  2630 net.cpp:198] Eltwise25_ReLU51_0_split needs backward computation.
I0929 19:16:18.326488  2630 net.cpp:198] ReLU51 needs backward computation.
I0929 19:16:18.326490  2630 net.cpp:198] Eltwise25 needs backward computation.
I0929 19:16:18.326493  2630 net.cpp:198] Scale53 needs backward computation.
I0929 19:16:18.326495  2630 net.cpp:198] BatchNorm53 needs backward computation.
I0929 19:16:18.326498  2630 net.cpp:198] Convolution53 needs backward computation.
I0929 19:16:18.326500  2630 net.cpp:198] ReLU50 needs backward computation.
I0929 19:16:18.326503  2630 net.cpp:198] Scale52 needs backward computation.
I0929 19:16:18.326505  2630 net.cpp:198] BatchNorm52 needs backward computation.
I0929 19:16:18.326508  2630 net.cpp:198] Convolution52 needs backward computation.
I0929 19:16:18.326510  2630 net.cpp:198] Eltwise24_ReLU49_0_split needs backward computation.
I0929 19:16:18.326512  2630 net.cpp:198] ReLU49 needs backward computation.
I0929 19:16:18.326515  2630 net.cpp:198] Eltwise24 needs backward computation.
I0929 19:16:18.326519  2630 net.cpp:198] Scale51 needs backward computation.
I0929 19:16:18.326527  2630 net.cpp:198] BatchNorm51 needs backward computation.
I0929 19:16:18.326530  2630 net.cpp:198] Convolution51 needs backward computation.
I0929 19:16:18.326534  2630 net.cpp:198] ReLU48 needs backward computation.
I0929 19:16:18.326535  2630 net.cpp:198] Scale50 needs backward computation.
I0929 19:16:18.326537  2630 net.cpp:198] BatchNorm50 needs backward computation.
I0929 19:16:18.326539  2630 net.cpp:198] Convolution50 needs backward computation.
I0929 19:16:18.326542  2630 net.cpp:198] Eltwise23_ReLU47_0_split needs backward computation.
I0929 19:16:18.326545  2630 net.cpp:198] ReLU47 needs backward computation.
I0929 19:16:18.326547  2630 net.cpp:198] Eltwise23 needs backward computation.
I0929 19:16:18.326550  2630 net.cpp:198] Scale49 needs backward computation.
I0929 19:16:18.326553  2630 net.cpp:198] BatchNorm49 needs backward computation.
I0929 19:16:18.326555  2630 net.cpp:198] Convolution49 needs backward computation.
I0929 19:16:18.326557  2630 net.cpp:198] ReLU46 needs backward computation.
I0929 19:16:18.326560  2630 net.cpp:198] Scale48 needs backward computation.
I0929 19:16:18.326562  2630 net.cpp:198] BatchNorm48 needs backward computation.
I0929 19:16:18.326565  2630 net.cpp:198] Convolution48 needs backward computation.
I0929 19:16:18.326567  2630 net.cpp:198] Eltwise22_ReLU45_0_split needs backward computation.
I0929 19:16:18.326570  2630 net.cpp:198] ReLU45 needs backward computation.
I0929 19:16:18.326572  2630 net.cpp:198] Eltwise22 needs backward computation.
I0929 19:16:18.326575  2630 net.cpp:198] Scale47 needs backward computation.
I0929 19:16:18.326577  2630 net.cpp:198] BatchNorm47 needs backward computation.
I0929 19:16:18.326580  2630 net.cpp:198] Convolution47 needs backward computation.
I0929 19:16:18.326582  2630 net.cpp:198] ReLU44 needs backward computation.
I0929 19:16:18.326584  2630 net.cpp:198] Scale46 needs backward computation.
I0929 19:16:18.326586  2630 net.cpp:198] BatchNorm46 needs backward computation.
I0929 19:16:18.326588  2630 net.cpp:198] Convolution46 needs backward computation.
I0929 19:16:18.326591  2630 net.cpp:198] Eltwise21_ReLU43_0_split needs backward computation.
I0929 19:16:18.326594  2630 net.cpp:198] ReLU43 needs backward computation.
I0929 19:16:18.326596  2630 net.cpp:198] Eltwise21 needs backward computation.
I0929 19:16:18.326599  2630 net.cpp:198] Scale45 needs backward computation.
I0929 19:16:18.326601  2630 net.cpp:198] BatchNorm45 needs backward computation.
I0929 19:16:18.326603  2630 net.cpp:198] Convolution45 needs backward computation.
I0929 19:16:18.326606  2630 net.cpp:198] ReLU42 needs backward computation.
I0929 19:16:18.326608  2630 net.cpp:198] Scale44 needs backward computation.
I0929 19:16:18.326614  2630 net.cpp:198] BatchNorm44 needs backward computation.
I0929 19:16:18.326617  2630 net.cpp:198] Convolution44 needs backward computation.
I0929 19:16:18.326620  2630 net.cpp:198] Eltwise20_ReLU41_0_split needs backward computation.
I0929 19:16:18.326622  2630 net.cpp:198] ReLU41 needs backward computation.
I0929 19:16:18.326625  2630 net.cpp:198] Eltwise20 needs backward computation.
I0929 19:16:18.326628  2630 net.cpp:198] Scale43 needs backward computation.
I0929 19:16:18.326630  2630 net.cpp:198] BatchNorm43 needs backward computation.
I0929 19:16:18.326633  2630 net.cpp:198] Convolution43 needs backward computation.
I0929 19:16:18.326635  2630 net.cpp:198] ReLU40 needs backward computation.
I0929 19:16:18.326638  2630 net.cpp:198] Scale42 needs backward computation.
I0929 19:16:18.326640  2630 net.cpp:198] BatchNorm42 needs backward computation.
I0929 19:16:18.326642  2630 net.cpp:198] Convolution42 needs backward computation.
I0929 19:16:18.326645  2630 net.cpp:198] Eltwise19_ReLU39_0_split needs backward computation.
I0929 19:16:18.326648  2630 net.cpp:198] ReLU39 needs backward computation.
I0929 19:16:18.326650  2630 net.cpp:198] Eltwise19 needs backward computation.
I0929 19:16:18.326653  2630 net.cpp:198] Scale41 needs backward computation.
I0929 19:16:18.326655  2630 net.cpp:198] BatchNorm41 needs backward computation.
I0929 19:16:18.326658  2630 net.cpp:198] Convolution41 needs backward computation.
I0929 19:16:18.326661  2630 net.cpp:198] ReLU38 needs backward computation.
I0929 19:16:18.326663  2630 net.cpp:198] Scale40 needs backward computation.
I0929 19:16:18.326665  2630 net.cpp:198] BatchNorm40 needs backward computation.
I0929 19:16:18.326668  2630 net.cpp:198] Convolution40 needs backward computation.
I0929 19:16:18.326670  2630 net.cpp:198] Scale39 needs backward computation.
I0929 19:16:18.326673  2630 net.cpp:198] BatchNorm39 needs backward computation.
I0929 19:16:18.326675  2630 net.cpp:198] Convolution39 needs backward computation.
I0929 19:16:18.326678  2630 net.cpp:198] Eltwise18_ReLU37_0_split needs backward computation.
I0929 19:16:18.326681  2630 net.cpp:198] ReLU37 needs backward computation.
I0929 19:16:18.326683  2630 net.cpp:198] Eltwise18 needs backward computation.
I0929 19:16:18.326686  2630 net.cpp:198] Scale38 needs backward computation.
I0929 19:16:18.326689  2630 net.cpp:198] BatchNorm38 needs backward computation.
I0929 19:16:18.326691  2630 net.cpp:198] Convolution38 needs backward computation.
I0929 19:16:18.326694  2630 net.cpp:198] ReLU36 needs backward computation.
I0929 19:16:18.326695  2630 net.cpp:198] Scale37 needs backward computation.
I0929 19:16:18.326699  2630 net.cpp:198] BatchNorm37 needs backward computation.
I0929 19:16:18.326700  2630 net.cpp:198] Convolution37 needs backward computation.
I0929 19:16:18.326704  2630 net.cpp:198] Eltwise17_ReLU35_0_split needs backward computation.
I0929 19:16:18.326705  2630 net.cpp:198] ReLU35 needs backward computation.
I0929 19:16:18.326709  2630 net.cpp:198] Eltwise17 needs backward computation.
I0929 19:16:18.326711  2630 net.cpp:198] Scale36 needs backward computation.
I0929 19:16:18.326714  2630 net.cpp:198] BatchNorm36 needs backward computation.
I0929 19:16:18.326715  2630 net.cpp:198] Convolution36 needs backward computation.
I0929 19:16:18.326719  2630 net.cpp:198] ReLU34 needs backward computation.
I0929 19:16:18.326720  2630 net.cpp:198] Scale35 needs backward computation.
I0929 19:16:18.326723  2630 net.cpp:198] BatchNorm35 needs backward computation.
I0929 19:16:18.326725  2630 net.cpp:198] Convolution35 needs backward computation.
I0929 19:16:18.326728  2630 net.cpp:198] Eltwise16_ReLU33_0_split needs backward computation.
I0929 19:16:18.326730  2630 net.cpp:198] ReLU33 needs backward computation.
I0929 19:16:18.326733  2630 net.cpp:198] Eltwise16 needs backward computation.
I0929 19:16:18.326735  2630 net.cpp:198] Scale34 needs backward computation.
I0929 19:16:18.326738  2630 net.cpp:198] BatchNorm34 needs backward computation.
I0929 19:16:18.326743  2630 net.cpp:198] Convolution34 needs backward computation.
I0929 19:16:18.326746  2630 net.cpp:198] ReLU32 needs backward computation.
I0929 19:16:18.326748  2630 net.cpp:198] Scale33 needs backward computation.
I0929 19:16:18.326751  2630 net.cpp:198] BatchNorm33 needs backward computation.
I0929 19:16:18.326753  2630 net.cpp:198] Convolution33 needs backward computation.
I0929 19:16:18.326756  2630 net.cpp:198] Eltwise15_ReLU31_0_split needs backward computation.
I0929 19:16:18.326759  2630 net.cpp:198] ReLU31 needs backward computation.
I0929 19:16:18.326762  2630 net.cpp:198] Eltwise15 needs backward computation.
I0929 19:16:18.326764  2630 net.cpp:198] Scale32 needs backward computation.
I0929 19:16:18.326767  2630 net.cpp:198] BatchNorm32 needs backward computation.
I0929 19:16:18.326769  2630 net.cpp:198] Convolution32 needs backward computation.
I0929 19:16:18.326772  2630 net.cpp:198] ReLU30 needs backward computation.
I0929 19:16:18.326774  2630 net.cpp:198] Scale31 needs backward computation.
I0929 19:16:18.326776  2630 net.cpp:198] BatchNorm31 needs backward computation.
I0929 19:16:18.326779  2630 net.cpp:198] Convolution31 needs backward computation.
I0929 19:16:18.326781  2630 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I0929 19:16:18.326784  2630 net.cpp:198] ReLU29 needs backward computation.
I0929 19:16:18.326786  2630 net.cpp:198] Eltwise14 needs backward computation.
I0929 19:16:18.326789  2630 net.cpp:198] Scale30 needs backward computation.
I0929 19:16:18.326792  2630 net.cpp:198] BatchNorm30 needs backward computation.
I0929 19:16:18.326794  2630 net.cpp:198] Convolution30 needs backward computation.
I0929 19:16:18.326797  2630 net.cpp:198] ReLU28 needs backward computation.
I0929 19:16:18.326799  2630 net.cpp:198] Scale29 needs backward computation.
I0929 19:16:18.326802  2630 net.cpp:198] BatchNorm29 needs backward computation.
I0929 19:16:18.326804  2630 net.cpp:198] Convolution29 needs backward computation.
I0929 19:16:18.326807  2630 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I0929 19:16:18.326809  2630 net.cpp:198] ReLU27 needs backward computation.
I0929 19:16:18.326812  2630 net.cpp:198] Eltwise13 needs backward computation.
I0929 19:16:18.326814  2630 net.cpp:198] Scale28 needs backward computation.
I0929 19:16:18.326817  2630 net.cpp:198] BatchNorm28 needs backward computation.
I0929 19:16:18.326819  2630 net.cpp:198] Convolution28 needs backward computation.
I0929 19:16:18.326822  2630 net.cpp:198] ReLU26 needs backward computation.
I0929 19:16:18.326824  2630 net.cpp:198] Scale27 needs backward computation.
I0929 19:16:18.326827  2630 net.cpp:198] BatchNorm27 needs backward computation.
I0929 19:16:18.326828  2630 net.cpp:198] Convolution27 needs backward computation.
I0929 19:16:18.326831  2630 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I0929 19:16:18.326833  2630 net.cpp:198] ReLU25 needs backward computation.
I0929 19:16:18.326836  2630 net.cpp:198] Eltwise12 needs backward computation.
I0929 19:16:18.326839  2630 net.cpp:198] Scale26 needs backward computation.
I0929 19:16:18.326841  2630 net.cpp:198] BatchNorm26 needs backward computation.
I0929 19:16:18.326843  2630 net.cpp:198] Convolution26 needs backward computation.
I0929 19:16:18.326846  2630 net.cpp:198] ReLU24 needs backward computation.
I0929 19:16:18.326848  2630 net.cpp:198] Scale25 needs backward computation.
I0929 19:16:18.326850  2630 net.cpp:198] BatchNorm25 needs backward computation.
I0929 19:16:18.326853  2630 net.cpp:198] Convolution25 needs backward computation.
I0929 19:16:18.326855  2630 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0929 19:16:18.326858  2630 net.cpp:198] ReLU23 needs backward computation.
I0929 19:16:18.326860  2630 net.cpp:198] Eltwise11 needs backward computation.
I0929 19:16:18.326864  2630 net.cpp:198] Scale24 needs backward computation.
I0929 19:16:18.326866  2630 net.cpp:198] BatchNorm24 needs backward computation.
I0929 19:16:18.326869  2630 net.cpp:198] Convolution24 needs backward computation.
I0929 19:16:18.326874  2630 net.cpp:198] ReLU22 needs backward computation.
I0929 19:16:18.326876  2630 net.cpp:198] Scale23 needs backward computation.
I0929 19:16:18.354127  2630 net.cpp:198] BatchNorm23 needs backward computation.
I0929 19:16:18.354136  2630 net.cpp:198] Convolution23 needs backward computation.
I0929 19:16:18.354142  2630 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I0929 19:16:18.354146  2630 net.cpp:198] ReLU21 needs backward computation.
I0929 19:16:18.354148  2630 net.cpp:198] Eltwise10 needs backward computation.
I0929 19:16:18.354151  2630 net.cpp:198] Scale22 needs backward computation.
I0929 19:16:18.354154  2630 net.cpp:198] BatchNorm22 needs backward computation.
I0929 19:16:18.354157  2630 net.cpp:198] Convolution22 needs backward computation.
I0929 19:16:18.354159  2630 net.cpp:198] ReLU20 needs backward computation.
I0929 19:16:18.354162  2630 net.cpp:198] Scale21 needs backward computation.
I0929 19:16:18.354164  2630 net.cpp:198] BatchNorm21 needs backward computation.
I0929 19:16:18.354166  2630 net.cpp:198] Convolution21 needs backward computation.
I0929 19:16:18.354169  2630 net.cpp:198] Scale20 needs backward computation.
I0929 19:16:18.354171  2630 net.cpp:198] BatchNorm20 needs backward computation.
I0929 19:16:18.354174  2630 net.cpp:198] Convolution20 needs backward computation.
I0929 19:16:18.354177  2630 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0929 19:16:18.354179  2630 net.cpp:198] ReLU19 needs backward computation.
I0929 19:16:18.354182  2630 net.cpp:198] Eltwise9 needs backward computation.
I0929 19:16:18.354185  2630 net.cpp:198] Scale19 needs backward computation.
I0929 19:16:18.354190  2630 net.cpp:198] BatchNorm19 needs backward computation.
I0929 19:16:18.354192  2630 net.cpp:198] Convolution19 needs backward computation.
I0929 19:16:18.354195  2630 net.cpp:198] ReLU18 needs backward computation.
I0929 19:16:18.354197  2630 net.cpp:198] Scale18 needs backward computation.
I0929 19:16:18.354199  2630 net.cpp:198] BatchNorm18 needs backward computation.
I0929 19:16:18.354202  2630 net.cpp:198] Convolution18 needs backward computation.
I0929 19:16:18.354204  2630 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0929 19:16:18.354207  2630 net.cpp:198] ReLU17 needs backward computation.
I0929 19:16:18.354210  2630 net.cpp:198] Eltwise8 needs backward computation.
I0929 19:16:18.354212  2630 net.cpp:198] Scale17 needs backward computation.
I0929 19:16:18.354215  2630 net.cpp:198] BatchNorm17 needs backward computation.
I0929 19:16:18.354218  2630 net.cpp:198] Convolution17 needs backward computation.
I0929 19:16:18.354220  2630 net.cpp:198] ReLU16 needs backward computation.
I0929 19:16:18.354223  2630 net.cpp:198] Scale16 needs backward computation.
I0929 19:16:18.354224  2630 net.cpp:198] BatchNorm16 needs backward computation.
I0929 19:16:18.354228  2630 net.cpp:198] Convolution16 needs backward computation.
I0929 19:16:18.354230  2630 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0929 19:16:18.354233  2630 net.cpp:198] ReLU15 needs backward computation.
I0929 19:16:18.354235  2630 net.cpp:198] Eltwise7 needs backward computation.
I0929 19:16:18.354238  2630 net.cpp:198] Scale15 needs backward computation.
I0929 19:16:18.354240  2630 net.cpp:198] BatchNorm15 needs backward computation.
I0929 19:16:18.354243  2630 net.cpp:198] Convolution15 needs backward computation.
I0929 19:16:18.354245  2630 net.cpp:198] ReLU14 needs backward computation.
I0929 19:16:18.354248  2630 net.cpp:198] Scale14 needs backward computation.
I0929 19:16:18.354250  2630 net.cpp:198] BatchNorm14 needs backward computation.
I0929 19:16:18.354252  2630 net.cpp:198] Convolution14 needs backward computation.
I0929 19:16:18.354255  2630 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0929 19:16:18.354257  2630 net.cpp:198] ReLU13 needs backward computation.
I0929 19:16:18.354260  2630 net.cpp:198] Eltwise6 needs backward computation.
I0929 19:16:18.354262  2630 net.cpp:198] Scale13 needs backward computation.
I0929 19:16:18.354272  2630 net.cpp:198] BatchNorm13 needs backward computation.
I0929 19:16:18.354275  2630 net.cpp:198] Convolution13 needs backward computation.
I0929 19:16:18.354279  2630 net.cpp:198] ReLU12 needs backward computation.
I0929 19:16:18.354280  2630 net.cpp:198] Scale12 needs backward computation.
I0929 19:16:18.354284  2630 net.cpp:198] BatchNorm12 needs backward computation.
I0929 19:16:18.354285  2630 net.cpp:198] Convolution12 needs backward computation.
I0929 19:16:18.354288  2630 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0929 19:16:18.354290  2630 net.cpp:198] ReLU11 needs backward computation.
I0929 19:16:18.354293  2630 net.cpp:198] Eltwise5 needs backward computation.
I0929 19:16:18.354296  2630 net.cpp:198] Scale11 needs backward computation.
I0929 19:16:18.354298  2630 net.cpp:198] BatchNorm11 needs backward computation.
I0929 19:16:18.354300  2630 net.cpp:198] Convolution11 needs backward computation.
I0929 19:16:18.354303  2630 net.cpp:198] ReLU10 needs backward computation.
I0929 19:16:18.354305  2630 net.cpp:198] Scale10 needs backward computation.
I0929 19:16:18.354307  2630 net.cpp:198] BatchNorm10 needs backward computation.
I0929 19:16:18.354310  2630 net.cpp:198] Convolution10 needs backward computation.
I0929 19:16:18.354313  2630 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0929 19:16:18.354316  2630 net.cpp:198] ReLU9 needs backward computation.
I0929 19:16:18.354318  2630 net.cpp:198] Eltwise4 needs backward computation.
I0929 19:16:18.354321  2630 net.cpp:198] Scale9 needs backward computation.
I0929 19:16:18.354324  2630 net.cpp:198] BatchNorm9 needs backward computation.
I0929 19:16:18.354326  2630 net.cpp:198] Convolution9 needs backward computation.
I0929 19:16:18.354329  2630 net.cpp:198] ReLU8 needs backward computation.
I0929 19:16:18.354332  2630 net.cpp:198] Scale8 needs backward computation.
I0929 19:16:18.354334  2630 net.cpp:198] BatchNorm8 needs backward computation.
I0929 19:16:18.354337  2630 net.cpp:198] Convolution8 needs backward computation.
I0929 19:16:18.354339  2630 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0929 19:16:18.354342  2630 net.cpp:198] ReLU7 needs backward computation.
I0929 19:16:18.354346  2630 net.cpp:198] Eltwise3 needs backward computation.
I0929 19:16:18.354348  2630 net.cpp:198] Scale7 needs backward computation.
I0929 19:16:18.354351  2630 net.cpp:198] BatchNorm7 needs backward computation.
I0929 19:16:18.354353  2630 net.cpp:198] Convolution7 needs backward computation.
I0929 19:16:18.354356  2630 net.cpp:198] ReLU6 needs backward computation.
I0929 19:16:18.354357  2630 net.cpp:198] Scale6 needs backward computation.
I0929 19:16:18.354360  2630 net.cpp:198] BatchNorm6 needs backward computation.
I0929 19:16:18.354362  2630 net.cpp:198] Convolution6 needs backward computation.
I0929 19:16:18.354365  2630 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0929 19:16:18.354368  2630 net.cpp:198] ReLU5 needs backward computation.
I0929 19:16:18.354370  2630 net.cpp:198] Eltwise2 needs backward computation.
I0929 19:16:18.354373  2630 net.cpp:198] Scale5 needs backward computation.
I0929 19:16:18.354377  2630 net.cpp:198] BatchNorm5 needs backward computation.
I0929 19:16:18.354378  2630 net.cpp:198] Convolution5 needs backward computation.
I0929 19:16:18.354382  2630 net.cpp:198] ReLU4 needs backward computation.
I0929 19:16:18.354383  2630 net.cpp:198] Scale4 needs backward computation.
I0929 19:16:18.354387  2630 net.cpp:198] BatchNorm4 needs backward computation.
I0929 19:16:18.354388  2630 net.cpp:198] Convolution4 needs backward computation.
I0929 19:16:18.354390  2630 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0929 19:16:18.354393  2630 net.cpp:198] ReLU3 needs backward computation.
I0929 19:16:18.354396  2630 net.cpp:198] Eltwise1 needs backward computation.
I0929 19:16:18.354399  2630 net.cpp:198] Scale3 needs backward computation.
I0929 19:16:18.354401  2630 net.cpp:198] BatchNorm3 needs backward computation.
I0929 19:16:18.354408  2630 net.cpp:198] Convolution3 needs backward computation.
I0929 19:16:18.384603  2630 net.cpp:198] ReLU2 needs backward computation.
I0929 19:16:18.384613  2630 net.cpp:198] Scale2 needs backward computation.
I0929 19:16:18.384618  2630 net.cpp:198] BatchNorm2 needs backward computation.
I0929 19:16:18.384621  2630 net.cpp:198] Convolution2 needs backward computation.
I0929 19:16:18.384626  2630 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0929 19:16:18.384631  2630 net.cpp:198] ReLU1 needs backward computation.
I0929 19:16:18.384635  2630 net.cpp:198] Scale1 needs backward computation.
I0929 19:16:18.384639  2630 net.cpp:198] BatchNorm1 needs backward computation.
I0929 19:16:18.384642  2630 net.cpp:198] Convolution1 needs backward computation.
I0929 19:16:18.384649  2630 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0929 19:16:18.384652  2630 net.cpp:200] Data1 does not need backward computation.
I0929 19:16:18.384656  2630 net.cpp:242] This network produces output Accuracy1
I0929 19:16:18.384660  2630 net.cpp:242] This network produces output SoftmaxWithLoss1
I0929 19:16:18.384789  2630 net.cpp:255] Network initialization done.
I0929 19:16:18.385463  2630 solver.cpp:56] Solver scaffolding done.
I0929 19:16:18.395710  2630 caffe.cpp:248] Starting Optimization
I0929 19:16:18.395720  2630 solver.cpp:272] Solving resnet_cifar10
I0929 19:16:18.395723  2630 solver.cpp:273] Learning Rate Policy: multistep
I0929 19:16:18.400899  2630 solver.cpp:330] Iteration 0, Testing net (#0)
I0929 19:16:21.553910  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:16:21.682770  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0929 19:16:21.682797  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0929 19:16:21.856523  2630 solver.cpp:218] Iteration 0 (0.0657805 iter/s, 3.46073s/100 iters), loss = 2.30597
I0929 19:16:21.856556  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30597 (* 1 = 2.30597 loss)
I0929 19:16:21.856571  2630 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0929 19:16:35.347206  2630 solver.cpp:218] Iteration 100 (7.41256 iter/s, 13.4906s/100 iters), loss = 2.11221
I0929 19:16:35.347257  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.11221 (* 1 = 2.11221 loss)
I0929 19:16:35.347267  2630 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0929 19:16:48.811425  2630 solver.cpp:218] Iteration 200 (7.42716 iter/s, 13.4641s/100 iters), loss = 2.15434
I0929 19:16:48.811655  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.15434 (* 1 = 2.15434 loss)
I0929 19:16:48.811663  2630 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0929 19:17:02.289322  2630 solver.cpp:218] Iteration 300 (7.41971 iter/s, 13.4776s/100 iters), loss = 1.73567
I0929 19:17:02.289369  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.73567 (* 1 = 1.73567 loss)
I0929 19:17:02.289378  2630 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0929 19:17:15.766984  2630 solver.cpp:218] Iteration 400 (7.41975 iter/s, 13.4775s/100 iters), loss = 1.53749
I0929 19:17:15.767014  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.53749 (* 1 = 1.53749 loss)
I0929 19:17:15.767020  2630 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0929 19:17:28.570761  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:17:29.107900  2630 solver.cpp:330] Iteration 500, Testing net (#0)
I0929 19:17:32.201934  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:17:32.336592  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1025
I0929 19:17:32.336632  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.36573 (* 1 = 5.36573 loss)
I0929 19:17:32.473392  2630 solver.cpp:218] Iteration 500 (5.98576 iter/s, 16.7063s/100 iters), loss = 1.6918
I0929 19:17:32.473428  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.6918 (* 1 = 1.6918 loss)
I0929 19:17:32.473435  2630 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0929 19:17:45.946466  2630 solver.cpp:218] Iteration 600 (7.42225 iter/s, 13.473s/100 iters), loss = 1.57393
I0929 19:17:45.946496  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.57393 (* 1 = 1.57393 loss)
I0929 19:17:45.946512  2630 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0929 19:17:59.419174  2630 solver.cpp:218] Iteration 700 (7.42245 iter/s, 13.4726s/100 iters), loss = 1.69707
I0929 19:17:59.419322  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.69707 (* 1 = 1.69707 loss)
I0929 19:17:59.419332  2630 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0929 19:18:12.891432  2630 solver.cpp:218] Iteration 800 (7.42276 iter/s, 13.4721s/100 iters), loss = 1.30684
I0929 19:18:12.891461  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.30684 (* 1 = 1.30684 loss)
I0929 19:18:12.891469  2630 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0929 19:18:26.378123  2630 solver.cpp:218] Iteration 900 (7.41476 iter/s, 13.4866s/100 iters), loss = 1.16917
I0929 19:18:26.378161  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16917 (* 1 = 1.16917 loss)
I0929 19:18:26.378170  2630 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0929 19:18:39.179322  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:18:39.716814  2630 solver.cpp:330] Iteration 1000, Testing net (#0)
I0929 19:18:42.808145  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:18:42.936980  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2231
I0929 19:18:42.937014  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.53366 (* 1 = 3.53366 loss)
I0929 19:18:43.069866  2630 solver.cpp:218] Iteration 1000 (5.99102 iter/s, 16.6917s/100 iters), loss = 1.27339
I0929 19:18:43.069897  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27339 (* 1 = 1.27339 loss)
I0929 19:18:43.069905  2630 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0929 19:18:56.532034  2630 solver.cpp:218] Iteration 1100 (7.42827 iter/s, 13.4621s/100 iters), loss = 1.08718
I0929 19:18:56.532069  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.08718 (* 1 = 1.08718 loss)
I0929 19:18:56.532076  2630 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0929 19:19:10.001571  2630 solver.cpp:218] Iteration 1200 (7.4242 iter/s, 13.4695s/100 iters), loss = 1.27589
I0929 19:19:10.001690  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27589 (* 1 = 1.27589 loss)
I0929 19:19:10.001708  2630 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0929 19:19:23.463901  2630 solver.cpp:218] Iteration 1300 (7.42823 iter/s, 13.4622s/100 iters), loss = 1.04685
I0929 19:19:23.463948  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04685 (* 1 = 1.04685 loss)
I0929 19:19:23.463955  2630 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0929 19:19:36.912715  2630 solver.cpp:218] Iteration 1400 (7.43566 iter/s, 13.4487s/100 iters), loss = 0.955417
I0929 19:19:36.912746  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.955417 (* 1 = 0.955417 loss)
I0929 19:19:36.912752  2630 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0929 19:19:49.705515  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:19:50.245113  2630 solver.cpp:330] Iteration 1500, Testing net (#0)
I0929 19:19:53.343333  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:19:53.475236  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3069
I0929 19:19:53.475265  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.5548 (* 1 = 2.5548 loss)
I0929 19:19:53.609659  2630 solver.cpp:218] Iteration 1500 (5.98915 iter/s, 16.6969s/100 iters), loss = 1.09959
I0929 19:19:53.609694  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09959 (* 1 = 1.09959 loss)
I0929 19:19:53.609704  2630 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0929 19:20:07.065515  2630 solver.cpp:218] Iteration 1600 (7.43175 iter/s, 13.4558s/100 iters), loss = 0.762063
I0929 19:20:07.065548  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.762063 (* 1 = 0.762063 loss)
I0929 19:20:07.065557  2630 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0929 19:20:20.530778  2630 solver.cpp:218] Iteration 1700 (7.42656 iter/s, 13.4652s/100 iters), loss = 0.840269
I0929 19:20:20.530916  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.840269 (* 1 = 0.840269 loss)
I0929 19:20:20.530930  2630 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0929 19:20:33.989248  2630 solver.cpp:218] Iteration 1800 (7.43036 iter/s, 13.4583s/100 iters), loss = 0.824016
I0929 19:20:33.989282  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.824016 (* 1 = 0.824016 loss)
I0929 19:20:33.989290  2630 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0929 19:20:47.459807  2630 solver.cpp:218] Iteration 1900 (7.42364 iter/s, 13.4705s/100 iters), loss = 0.705398
I0929 19:20:47.459853  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.705398 (* 1 = 0.705398 loss)
I0929 19:20:47.459861  2630 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0929 19:21:00.257338  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:21:00.793479  2630 solver.cpp:330] Iteration 2000, Testing net (#0)
I0929 19:21:03.884346  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:21:04.012830  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3737
I0929 19:21:04.012864  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.04089 (* 1 = 2.04089 loss)
I0929 19:21:04.147469  2630 solver.cpp:218] Iteration 2000 (5.9925 iter/s, 16.6875s/100 iters), loss = 0.961541
I0929 19:21:04.147496  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.961541 (* 1 = 0.961541 loss)
I0929 19:21:04.147503  2630 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0929 19:21:17.618444  2630 solver.cpp:218] Iteration 2100 (7.42341 iter/s, 13.4709s/100 iters), loss = 0.645088
I0929 19:21:17.618481  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.645088 (* 1 = 0.645088 loss)
I0929 19:21:17.618489  2630 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0929 19:21:31.084914  2630 solver.cpp:218] Iteration 2200 (7.42589 iter/s, 13.4664s/100 iters), loss = 0.811154
I0929 19:21:31.085054  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.811154 (* 1 = 0.811154 loss)
I0929 19:21:31.085063  2630 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0929 19:21:44.564267  2630 solver.cpp:218] Iteration 2300 (7.41885 iter/s, 13.4792s/100 iters), loss = 0.772938
I0929 19:21:44.564301  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.772938 (* 1 = 0.772938 loss)
I0929 19:21:44.564307  2630 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0929 19:21:58.029186  2630 solver.cpp:218] Iteration 2400 (7.42675 iter/s, 13.4648s/100 iters), loss = 0.655367
I0929 19:21:58.029219  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.655367 (* 1 = 0.655367 loss)
I0929 19:21:58.029227  2630 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0929 19:22:10.832815  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:22:11.376420  2630 solver.cpp:330] Iteration 2500, Testing net (#0)
I0929 19:22:14.476110  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:22:14.605561  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4634
I0929 19:22:14.605597  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.65829 (* 1 = 1.65829 loss)
I0929 19:22:14.739300  2630 solver.cpp:218] Iteration 2500 (5.98443 iter/s, 16.71s/100 iters), loss = 0.703621
I0929 19:22:14.739334  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.703621 (* 1 = 0.703621 loss)
I0929 19:22:14.739341  2630 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0929 19:22:28.207279  2630 solver.cpp:218] Iteration 2600 (7.42506 iter/s, 13.4679s/100 iters), loss = 0.519445
I0929 19:22:28.207310  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519445 (* 1 = 0.519445 loss)
I0929 19:22:28.207326  2630 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0929 19:22:41.683524  2630 solver.cpp:218] Iteration 2700 (7.42051 iter/s, 13.4762s/100 iters), loss = 0.61305
I0929 19:22:41.683661  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61305 (* 1 = 0.61305 loss)
I0929 19:22:41.683681  2630 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0929 19:22:55.151486  2630 solver.cpp:218] Iteration 2800 (7.42512 iter/s, 13.4678s/100 iters), loss = 0.63261
I0929 19:22:55.151520  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.63261 (* 1 = 0.63261 loss)
I0929 19:22:55.151526  2630 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0929 19:23:08.641154  2630 solver.cpp:218] Iteration 2900 (7.41312 iter/s, 13.4896s/100 iters), loss = 0.668033
I0929 19:23:08.641186  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.668033 (* 1 = 0.668033 loss)
I0929 19:23:08.641193  2630 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0929 19:23:21.448617  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:23:21.984973  2630 solver.cpp:330] Iteration 3000, Testing net (#0)
I0929 19:23:25.076258  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:23:25.204993  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5108
I0929 19:23:25.205027  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.61234 (* 1 = 1.61234 loss)
I0929 19:23:25.339165  2630 solver.cpp:218] Iteration 3000 (5.98877 iter/s, 16.6979s/100 iters), loss = 0.601069
I0929 19:23:25.339195  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601069 (* 1 = 0.601069 loss)
I0929 19:23:25.339202  2630 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0929 19:23:38.806174  2630 solver.cpp:218] Iteration 3100 (7.42559 iter/s, 13.4669s/100 iters), loss = 0.550231
I0929 19:23:38.806207  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.550231 (* 1 = 0.550231 loss)
I0929 19:23:38.806215  2630 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0929 19:23:52.255081  2630 solver.cpp:218] Iteration 3200 (7.43559 iter/s, 13.4488s/100 iters), loss = 0.538157
I0929 19:23:52.255221  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.538157 (* 1 = 0.538157 loss)
I0929 19:23:52.255228  2630 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0929 19:24:05.728744  2630 solver.cpp:218] Iteration 3300 (7.42199 iter/s, 13.4735s/100 iters), loss = 0.601807
I0929 19:24:05.728778  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601807 (* 1 = 0.601807 loss)
I0929 19:24:05.728786  2630 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0929 19:24:19.181712  2630 solver.cpp:218] Iteration 3400 (7.43335 iter/s, 13.4529s/100 iters), loss = 0.611044
I0929 19:24:19.181741  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.611044 (* 1 = 0.611044 loss)
I0929 19:24:19.181747  2630 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0929 19:24:31.975065  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:24:32.523525  2630 solver.cpp:330] Iteration 3500, Testing net (#0)
I0929 19:24:35.617509  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:24:35.746228  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6512
I0929 19:24:35.746265  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.978267 (* 1 = 0.978267 loss)
I0929 19:24:35.880069  2630 solver.cpp:218] Iteration 3500 (5.98864 iter/s, 16.6983s/100 iters), loss = 0.524867
I0929 19:24:35.880103  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524867 (* 1 = 0.524867 loss)
I0929 19:24:35.880111  2630 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0929 19:24:49.342449  2630 solver.cpp:218] Iteration 3600 (7.42815 iter/s, 13.4623s/100 iters), loss = 0.481267
I0929 19:24:49.342490  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481267 (* 1 = 0.481267 loss)
I0929 19:24:49.342496  2630 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0929 19:25:02.810992  2630 solver.cpp:218] Iteration 3700 (7.42475 iter/s, 13.4685s/100 iters), loss = 0.560336
I0929 19:25:02.811148  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.560336 (* 1 = 0.560336 loss)
I0929 19:25:02.811172  2630 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0929 19:25:16.274669  2630 solver.cpp:218] Iteration 3800 (7.42749 iter/s, 13.4635s/100 iters), loss = 0.609085
I0929 19:25:16.274710  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.609085 (* 1 = 0.609085 loss)
I0929 19:25:16.274716  2630 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0929 19:25:29.744408  2630 solver.cpp:218] Iteration 3900 (7.42409 iter/s, 13.4697s/100 iters), loss = 0.512853
I0929 19:25:29.744441  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512853 (* 1 = 0.512853 loss)
I0929 19:25:29.744448  2630 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0929 19:25:42.543440  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:25:43.081297  2630 solver.cpp:330] Iteration 4000, Testing net (#0)
I0929 19:25:46.172673  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:25:46.301097  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6935
I0929 19:25:46.301132  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.898015 (* 1 = 0.898015 loss)
I0929 19:25:46.435209  2630 solver.cpp:218] Iteration 4000 (5.99135 iter/s, 16.6907s/100 iters), loss = 0.518747
I0929 19:25:46.435240  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518747 (* 1 = 0.518747 loss)
I0929 19:25:46.435246  2630 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0929 19:25:59.912215  2630 solver.cpp:218] Iteration 4100 (7.42009 iter/s, 13.4769s/100 iters), loss = 0.471781
I0929 19:25:59.912259  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471781 (* 1 = 0.471781 loss)
I0929 19:25:59.912267  2630 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0929 19:26:13.386991  2630 solver.cpp:218] Iteration 4200 (7.42132 iter/s, 13.4747s/100 iters), loss = 0.519964
I0929 19:26:13.387116  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519964 (* 1 = 0.519964 loss)
I0929 19:26:13.387140  2630 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0929 19:26:26.875950  2630 solver.cpp:218] Iteration 4300 (7.41356 iter/s, 13.4888s/100 iters), loss = 0.508231
I0929 19:26:26.875985  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508231 (* 1 = 0.508231 loss)
I0929 19:26:26.875993  2630 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0929 19:26:40.356519  2630 solver.cpp:218] Iteration 4400 (7.41813 iter/s, 13.4805s/100 iters), loss = 0.476728
I0929 19:26:40.356549  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476728 (* 1 = 0.476728 loss)
I0929 19:26:40.356555  2630 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0929 19:26:53.157797  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:26:53.704982  2630 solver.cpp:330] Iteration 4500, Testing net (#0)
I0929 19:26:56.795598  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:26:56.924669  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.665
I0929 19:26:56.924695  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.929367 (* 1 = 0.929367 loss)
I0929 19:26:57.057971  2630 solver.cpp:218] Iteration 4500 (5.98753 iter/s, 16.7014s/100 iters), loss = 0.338004
I0929 19:26:57.058002  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338004 (* 1 = 0.338004 loss)
I0929 19:26:57.058012  2630 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0929 19:27:10.517633  2630 solver.cpp:218] Iteration 4600 (7.42965 iter/s, 13.4596s/100 iters), loss = 0.366179
I0929 19:27:10.517673  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366179 (* 1 = 0.366179 loss)
I0929 19:27:10.517683  2630 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0929 19:27:23.995175  2630 solver.cpp:218] Iteration 4700 (7.4198 iter/s, 13.4775s/100 iters), loss = 0.501163
I0929 19:27:23.995311  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501163 (* 1 = 0.501163 loss)
I0929 19:27:23.995332  2630 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0929 19:27:37.457124  2630 solver.cpp:218] Iteration 4800 (7.42844 iter/s, 13.4618s/100 iters), loss = 0.422938
I0929 19:27:37.457154  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422938 (* 1 = 0.422938 loss)
I0929 19:27:37.457170  2630 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0929 19:27:50.937880  2630 solver.cpp:218] Iteration 4900 (7.41802 iter/s, 13.4807s/100 iters), loss = 0.553816
I0929 19:27:50.937918  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.553816 (* 1 = 0.553816 loss)
I0929 19:27:50.937927  2630 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0929 19:28:03.743114  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:28:04.281085  2630 solver.cpp:330] Iteration 5000, Testing net (#0)
I0929 19:28:07.372793  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:28:07.500959  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6218
I0929 19:28:07.500995  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0528 (* 1 = 1.0528 loss)
I0929 19:28:07.634948  2630 solver.cpp:218] Iteration 5000 (5.98911 iter/s, 16.697s/100 iters), loss = 0.446671
I0929 19:28:07.634977  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446671 (* 1 = 0.446671 loss)
I0929 19:28:07.634984  2630 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0929 19:28:21.101172  2630 solver.cpp:218] Iteration 5100 (7.42603 iter/s, 13.4661s/100 iters), loss = 0.575424
I0929 19:28:21.101203  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.575424 (* 1 = 0.575424 loss)
I0929 19:28:21.101210  2630 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0929 19:28:34.560452  2630 solver.cpp:218] Iteration 5200 (7.42986 iter/s, 13.4592s/100 iters), loss = 0.436288
I0929 19:28:34.560592  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436288 (* 1 = 0.436288 loss)
I0929 19:28:34.560601  2630 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0929 19:28:48.037364  2630 solver.cpp:218] Iteration 5300 (7.42019 iter/s, 13.4767s/100 iters), loss = 0.463539
I0929 19:28:48.037395  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463539 (* 1 = 0.463539 loss)
I0929 19:28:48.037402  2630 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0929 19:29:01.499012  2630 solver.cpp:218] Iteration 5400 (7.42855 iter/s, 13.4616s/100 iters), loss = 0.390641
I0929 19:29:01.499042  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390641 (* 1 = 0.390641 loss)
I0929 19:29:01.499048  2630 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0929 19:29:14.294507  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:29:14.838135  2630 solver.cpp:330] Iteration 5500, Testing net (#0)
I0929 19:29:17.929590  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:29:18.058235  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6672
I0929 19:29:18.058270  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.920104 (* 1 = 0.920104 loss)
I0929 19:29:18.192116  2630 solver.cpp:218] Iteration 5500 (5.99053 iter/s, 16.693s/100 iters), loss = 0.306975
I0929 19:29:18.192148  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306975 (* 1 = 0.306975 loss)
I0929 19:29:18.192155  2630 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0929 19:29:31.645637  2630 solver.cpp:218] Iteration 5600 (7.43304 iter/s, 13.4534s/100 iters), loss = 0.414835
I0929 19:29:31.645665  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414835 (* 1 = 0.414835 loss)
I0929 19:29:31.645671  2630 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0929 19:29:45.118885  2630 solver.cpp:218] Iteration 5700 (7.42215 iter/s, 13.4732s/100 iters), loss = 0.414753
I0929 19:29:45.119026  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414753 (* 1 = 0.414753 loss)
I0929 19:29:45.119035  2630 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0929 19:29:58.570241  2630 solver.cpp:218] Iteration 5800 (7.43429 iter/s, 13.4512s/100 iters), loss = 0.479271
I0929 19:29:58.570282  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479271 (* 1 = 0.479271 loss)
I0929 19:29:58.570288  2630 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0929 19:30:12.039674  2630 solver.cpp:218] Iteration 5900 (7.42426 iter/s, 13.4694s/100 iters), loss = 0.408917
I0929 19:30:12.039714  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408917 (* 1 = 0.408917 loss)
I0929 19:30:12.039721  2630 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0929 19:30:24.834113  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:30:25.370638  2630 solver.cpp:330] Iteration 6000, Testing net (#0)
I0929 19:30:28.466001  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:30:28.595031  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6724
I0929 19:30:28.595054  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.916518 (* 1 = 0.916518 loss)
I0929 19:30:28.728240  2630 solver.cpp:218] Iteration 6000 (5.99216 iter/s, 16.6885s/100 iters), loss = 0.266789
I0929 19:30:28.728271  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266789 (* 1 = 0.266789 loss)
I0929 19:30:28.728278  2630 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0929 19:30:42.186357  2630 solver.cpp:218] Iteration 6100 (7.4305 iter/s, 13.458s/100 iters), loss = 0.311645
I0929 19:30:42.186391  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311645 (* 1 = 0.311645 loss)
I0929 19:30:42.186399  2630 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0929 19:30:55.643649  2630 solver.cpp:218] Iteration 6200 (7.43096 iter/s, 13.4572s/100 iters), loss = 0.371243
I0929 19:30:55.643772  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371243 (* 1 = 0.371243 loss)
I0929 19:30:55.643780  2630 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0929 19:31:09.112416  2630 solver.cpp:218] Iteration 6300 (7.42468 iter/s, 13.4686s/100 iters), loss = 0.479024
I0929 19:31:09.112447  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479024 (* 1 = 0.479024 loss)
I0929 19:31:09.112464  2630 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0929 19:31:22.572401  2630 solver.cpp:218] Iteration 6400 (7.42947 iter/s, 13.4599s/100 iters), loss = 0.393273
I0929 19:31:22.572430  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393273 (* 1 = 0.393273 loss)
I0929 19:31:22.572437  2630 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0929 19:31:35.357693  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:31:35.899096  2630 solver.cpp:330] Iteration 6500, Testing net (#0)
I0929 19:31:38.992674  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:31:39.121711  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.718
I0929 19:31:39.121747  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.807381 (* 1 = 0.807381 loss)
I0929 19:31:39.255836  2630 solver.cpp:218] Iteration 6500 (5.994 iter/s, 16.6834s/100 iters), loss = 0.292883
I0929 19:31:39.255878  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292883 (* 1 = 0.292883 loss)
I0929 19:31:39.255887  2630 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0929 19:31:52.712478  2630 solver.cpp:218] Iteration 6600 (7.43132 iter/s, 13.4566s/100 iters), loss = 0.306289
I0929 19:31:52.712508  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306289 (* 1 = 0.306289 loss)
I0929 19:31:52.712514  2630 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0929 19:32:06.177237  2630 solver.cpp:218] Iteration 6700 (7.42684 iter/s, 13.4647s/100 iters), loss = 0.379338
I0929 19:32:06.177345  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379338 (* 1 = 0.379338 loss)
I0929 19:32:06.177353  2630 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0929 19:32:19.628841  2630 solver.cpp:218] Iteration 6800 (7.43414 iter/s, 13.4515s/100 iters), loss = 0.369089
I0929 19:32:19.628871  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369089 (* 1 = 0.369089 loss)
I0929 19:32:19.628877  2630 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0929 19:32:33.094502  2630 solver.cpp:218] Iteration 6900 (7.42634 iter/s, 13.4656s/100 iters), loss = 0.281933
I0929 19:32:33.094537  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281933 (* 1 = 0.281933 loss)
I0929 19:32:33.094543  2630 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0929 19:32:45.890955  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:32:46.427307  2630 solver.cpp:330] Iteration 7000, Testing net (#0)
I0929 19:32:49.524624  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:32:49.653847  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7753
I0929 19:32:49.653883  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.671018 (* 1 = 0.671018 loss)
I0929 19:32:49.787401  2630 solver.cpp:218] Iteration 7000 (5.9906 iter/s, 16.6928s/100 iters), loss = 0.331606
I0929 19:32:49.787433  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331606 (* 1 = 0.331606 loss)
I0929 19:32:49.787441  2630 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0929 19:33:03.255043  2630 solver.cpp:218] Iteration 7100 (7.42524 iter/s, 13.4676s/100 iters), loss = 0.342492
I0929 19:33:03.255075  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342492 (* 1 = 0.342492 loss)
I0929 19:33:03.255082  2630 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0929 19:33:16.705345  2630 solver.cpp:218] Iteration 7200 (7.43482 iter/s, 13.4502s/100 iters), loss = 0.322496
I0929 19:33:16.705469  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322496 (* 1 = 0.322496 loss)
I0929 19:33:16.705476  2630 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0929 19:33:30.178655  2630 solver.cpp:218] Iteration 7300 (7.42217 iter/s, 13.4731s/100 iters), loss = 0.382955
I0929 19:33:30.178688  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382955 (* 1 = 0.382955 loss)
I0929 19:33:30.178694  2630 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0929 19:33:43.643961  2630 solver.cpp:218] Iteration 7400 (7.42653 iter/s, 13.4652s/100 iters), loss = 0.313954
I0929 19:33:43.643992  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313954 (* 1 = 0.313954 loss)
I0929 19:33:43.643999  2630 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0929 19:33:56.432287  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:33:56.973861  2630 solver.cpp:330] Iteration 7500, Testing net (#0)
I0929 19:34:00.063447  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:34:00.191570  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7635
I0929 19:34:00.191606  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.689161 (* 1 = 0.689161 loss)
I0929 19:34:00.325912  2630 solver.cpp:218] Iteration 7500 (5.99453 iter/s, 16.6819s/100 iters), loss = 0.223373
I0929 19:34:00.325947  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223373 (* 1 = 0.223373 loss)
I0929 19:34:00.325955  2630 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0929 19:34:13.782320  2630 solver.cpp:218] Iteration 7600 (7.43145 iter/s, 13.4563s/100 iters), loss = 0.318693
I0929 19:34:13.782352  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318693 (* 1 = 0.318693 loss)
I0929 19:34:13.782359  2630 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0929 19:34:27.241022  2630 solver.cpp:218] Iteration 7700 (7.43018 iter/s, 13.4586s/100 iters), loss = 0.259266
I0929 19:34:27.241148  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259266 (* 1 = 0.259266 loss)
I0929 19:34:27.241158  2630 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0929 19:34:40.690603  2630 solver.cpp:218] Iteration 7800 (7.43527 iter/s, 13.4494s/100 iters), loss = 0.355454
I0929 19:34:40.690646  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355454 (* 1 = 0.355454 loss)
I0929 19:34:40.690654  2630 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0929 19:34:54.150460  2630 solver.cpp:218] Iteration 7900 (7.42955 iter/s, 13.4598s/100 iters), loss = 0.24831
I0929 19:34:54.150494  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24831 (* 1 = 0.24831 loss)
I0929 19:34:54.150501  2630 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0929 19:35:06.941396  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:35:07.477486  2630 solver.cpp:330] Iteration 8000, Testing net (#0)
I0929 19:35:10.572854  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:35:10.701336  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6122
I0929 19:35:10.701371  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.33269 (* 1 = 1.33269 loss)
I0929 19:35:10.834550  2630 solver.cpp:218] Iteration 8000 (5.99376 iter/s, 16.684s/100 iters), loss = 0.323848
I0929 19:35:10.834580  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323848 (* 1 = 0.323848 loss)
I0929 19:35:10.834588  2630 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0929 19:35:24.302924  2630 solver.cpp:218] Iteration 8100 (7.42484 iter/s, 13.4683s/100 iters), loss = 0.309669
I0929 19:35:24.302956  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309669 (* 1 = 0.309669 loss)
I0929 19:35:24.302963  2630 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0929 19:35:37.762337  2630 solver.cpp:218] Iteration 8200 (7.42978 iter/s, 13.4593s/100 iters), loss = 0.356919
I0929 19:35:37.762460  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356919 (* 1 = 0.356919 loss)
I0929 19:35:37.762468  2630 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0929 19:35:51.230690  2630 solver.cpp:218] Iteration 8300 (7.4249 iter/s, 13.4682s/100 iters), loss = 0.306306
I0929 19:35:51.230722  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306306 (* 1 = 0.306306 loss)
I0929 19:35:51.230728  2630 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0929 19:36:04.700253  2630 solver.cpp:218] Iteration 8400 (7.42419 iter/s, 13.4695s/100 iters), loss = 0.331256
I0929 19:36:04.700284  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331256 (* 1 = 0.331256 loss)
I0929 19:36:04.700292  2630 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0929 19:36:17.500697  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:36:18.040166  2630 solver.cpp:330] Iteration 8500, Testing net (#0)
I0929 19:36:21.132516  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:36:21.261179  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7576
I0929 19:36:21.261205  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710135 (* 1 = 0.710135 loss)
I0929 19:36:21.395040  2630 solver.cpp:218] Iteration 8500 (5.98992 iter/s, 16.6947s/100 iters), loss = 0.299841
I0929 19:36:21.395076  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299841 (* 1 = 0.299841 loss)
I0929 19:36:21.395086  2630 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0929 19:36:34.856318  2630 solver.cpp:218] Iteration 8600 (7.42876 iter/s, 13.4612s/100 iters), loss = 0.303205
I0929 19:36:34.856353  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303205 (* 1 = 0.303205 loss)
I0929 19:36:34.856360  2630 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0929 19:36:48.326280  2630 solver.cpp:218] Iteration 8700 (7.42397 iter/s, 13.4699s/100 iters), loss = 0.401898
I0929 19:36:48.326388  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401898 (* 1 = 0.401898 loss)
I0929 19:36:48.326396  2630 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0929 19:37:01.786978  2630 solver.cpp:218] Iteration 8800 (7.42911 iter/s, 13.4606s/100 iters), loss = 0.347405
I0929 19:37:01.787009  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347405 (* 1 = 0.347405 loss)
I0929 19:37:01.787014  2630 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0929 19:37:15.255162  2630 solver.cpp:218] Iteration 8900 (7.42495 iter/s, 13.4681s/100 iters), loss = 0.289494
I0929 19:37:15.255190  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289494 (* 1 = 0.289494 loss)
I0929 19:37:15.255198  2630 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0929 19:37:28.045635  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:37:28.583086  2630 solver.cpp:330] Iteration 9000, Testing net (#0)
I0929 19:37:31.675350  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:37:31.804245  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7741
I0929 19:37:31.804271  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.639336 (* 1 = 0.639336 loss)
I0929 19:37:31.938115  2630 solver.cpp:218] Iteration 9000 (5.99417 iter/s, 16.6829s/100 iters), loss = 0.348766
I0929 19:37:31.938149  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348766 (* 1 = 0.348766 loss)
I0929 19:37:31.938156  2630 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0929 19:37:45.415068  2630 solver.cpp:218] Iteration 9100 (7.42012 iter/s, 13.4769s/100 iters), loss = 0.258191
I0929 19:37:45.415099  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258191 (* 1 = 0.258191 loss)
I0929 19:37:45.415107  2630 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0929 19:37:58.882606  2630 solver.cpp:218] Iteration 9200 (7.4253 iter/s, 13.4675s/100 iters), loss = 0.496263
I0929 19:37:58.882741  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.496263 (* 1 = 0.496263 loss)
I0929 19:37:58.882748  2630 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0929 19:38:12.364626  2630 solver.cpp:218] Iteration 9300 (7.41738 iter/s, 13.4818s/100 iters), loss = 0.323285
I0929 19:38:12.364661  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323285 (* 1 = 0.323285 loss)
I0929 19:38:12.364668  2630 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0929 19:38:25.842447  2630 solver.cpp:218] Iteration 9400 (7.41964 iter/s, 13.4777s/100 iters), loss = 0.315249
I0929 19:38:25.842486  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315248 (* 1 = 0.315248 loss)
I0929 19:38:25.842494  2630 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0929 19:38:38.649678  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:38:39.187777  2630 solver.cpp:330] Iteration 9500, Testing net (#0)
I0929 19:38:42.277354  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:38:42.406549  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7449
I0929 19:38:42.406574  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.746333 (* 1 = 0.746333 loss)
I0929 19:38:42.540846  2630 solver.cpp:218] Iteration 9500 (5.98863 iter/s, 16.6983s/100 iters), loss = 0.278326
I0929 19:38:42.540879  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278325 (* 1 = 0.278325 loss)
I0929 19:38:42.540885  2630 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0929 19:38:56.005954  2630 solver.cpp:218] Iteration 9600 (7.42664 iter/s, 13.465s/100 iters), loss = 0.21788
I0929 19:38:56.005985  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21788 (* 1 = 0.21788 loss)
I0929 19:38:56.005991  2630 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0929 19:39:09.491562  2630 solver.cpp:218] Iteration 9700 (7.41535 iter/s, 13.4855s/100 iters), loss = 0.324464
I0929 19:39:09.491675  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324464 (* 1 = 0.324464 loss)
I0929 19:39:09.491683  2630 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0929 19:39:22.954635  2630 solver.cpp:218] Iteration 9800 (7.42781 iter/s, 13.4629s/100 iters), loss = 0.306449
I0929 19:39:22.954668  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306449 (* 1 = 0.306449 loss)
I0929 19:39:22.954674  2630 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0929 19:39:36.428390  2630 solver.cpp:218] Iteration 9900 (7.42188 iter/s, 13.4737s/100 iters), loss = 0.237949
I0929 19:39:36.428423  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237949 (* 1 = 0.237949 loss)
I0929 19:39:36.428431  2630 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0929 19:39:49.235460  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:39:49.772806  2630 solver.cpp:330] Iteration 10000, Testing net (#0)
I0929 19:39:52.864435  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:39:52.993675  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7877
I0929 19:39:52.993710  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.62653 (* 1 = 0.62653 loss)
I0929 19:39:53.127403  2630 solver.cpp:218] Iteration 10000 (5.98841 iter/s, 16.6989s/100 iters), loss = 0.263027
I0929 19:39:53.127434  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263027 (* 1 = 0.263027 loss)
I0929 19:39:53.127439  2630 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0929 19:40:06.614284  2630 solver.cpp:218] Iteration 10100 (7.41465 iter/s, 13.4868s/100 iters), loss = 0.422905
I0929 19:40:06.614315  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422905 (* 1 = 0.422905 loss)
I0929 19:40:06.614322  2630 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0929 19:40:20.077159  2630 solver.cpp:218] Iteration 10200 (7.42787 iter/s, 13.4628s/100 iters), loss = 0.289184
I0929 19:40:20.077260  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289184 (* 1 = 0.289184 loss)
I0929 19:40:20.077267  2630 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0929 19:40:33.552923  2630 solver.cpp:218] Iteration 10300 (7.42081 iter/s, 13.4756s/100 iters), loss = 0.342116
I0929 19:40:33.552953  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342115 (* 1 = 0.342115 loss)
I0929 19:40:33.552958  2630 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0929 19:40:47.030987  2630 solver.cpp:218] Iteration 10400 (7.4195 iter/s, 13.478s/100 iters), loss = 0.247281
I0929 19:40:47.031020  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247281 (* 1 = 0.247281 loss)
I0929 19:40:47.031028  2630 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0929 19:40:59.841784  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:41:00.380439  2630 solver.cpp:330] Iteration 10500, Testing net (#0)
I0929 19:41:03.471047  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:41:03.599814  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7864
I0929 19:41:03.599851  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.649374 (* 1 = 0.649374 loss)
I0929 19:41:03.733458  2630 solver.cpp:218] Iteration 10500 (5.98717 iter/s, 16.7024s/100 iters), loss = 0.235302
I0929 19:41:03.733487  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235301 (* 1 = 0.235301 loss)
I0929 19:41:03.733494  2630 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0929 19:41:17.190810  2630 solver.cpp:218] Iteration 10600 (7.43092 iter/s, 13.4573s/100 iters), loss = 0.307096
I0929 19:41:17.190841  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307096 (* 1 = 0.307096 loss)
I0929 19:41:17.190847  2630 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0929 19:41:30.665333  2630 solver.cpp:218] Iteration 10700 (7.42145 iter/s, 13.4745s/100 iters), loss = 0.324983
I0929 19:41:30.665431  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324982 (* 1 = 0.324982 loss)
I0929 19:41:30.665447  2630 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0929 19:41:44.124891  2630 solver.cpp:218] Iteration 10800 (7.42974 iter/s, 13.4594s/100 iters), loss = 0.353008
I0929 19:41:44.124919  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353008 (* 1 = 0.353008 loss)
I0929 19:41:44.124927  2630 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0929 19:41:57.580035  2630 solver.cpp:218] Iteration 10900 (7.43214 iter/s, 13.4551s/100 iters), loss = 0.201207
I0929 19:41:57.580065  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201206 (* 1 = 0.201206 loss)
I0929 19:41:57.580071  2630 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0929 19:42:10.379772  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:42:10.917666  2630 solver.cpp:330] Iteration 11000, Testing net (#0)
I0929 19:42:14.010551  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:42:14.139431  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7269
I0929 19:42:14.139467  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.868241 (* 1 = 0.868241 loss)
I0929 19:42:14.272377  2630 solver.cpp:218] Iteration 11000 (5.9908 iter/s, 16.6923s/100 iters), loss = 0.235597
I0929 19:42:14.272406  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235597 (* 1 = 0.235597 loss)
I0929 19:42:14.272413  2630 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0929 19:42:27.750761  2630 solver.cpp:218] Iteration 11100 (7.41933 iter/s, 13.4783s/100 iters), loss = 0.218265
I0929 19:42:27.750792  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218265 (* 1 = 0.218265 loss)
I0929 19:42:27.750797  2630 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0929 19:42:41.217155  2630 solver.cpp:218] Iteration 11200 (7.42593 iter/s, 13.4663s/100 iters), loss = 0.217568
I0929 19:42:41.217272  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217568 (* 1 = 0.217568 loss)
I0929 19:42:41.217280  2630 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0929 19:42:54.691682  2630 solver.cpp:218] Iteration 11300 (7.42149 iter/s, 13.4744s/100 iters), loss = 0.366121
I0929 19:42:54.691714  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36612 (* 1 = 0.36612 loss)
I0929 19:42:54.691720  2630 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0929 19:43:08.170905  2630 solver.cpp:218] Iteration 11400 (7.41887 iter/s, 13.4791s/100 iters), loss = 0.264011
I0929 19:43:08.170945  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264011 (* 1 = 0.264011 loss)
I0929 19:43:08.170953  2630 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0929 19:43:20.985393  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:43:21.522344  2630 solver.cpp:330] Iteration 11500, Testing net (#0)
I0929 19:43:24.615253  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:43:24.744078  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7842
I0929 19:43:24.744114  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658127 (* 1 = 0.658127 loss)
I0929 19:43:24.878080  2630 solver.cpp:218] Iteration 11500 (5.98548 iter/s, 16.7071s/100 iters), loss = 0.267648
I0929 19:43:24.878110  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267647 (* 1 = 0.267647 loss)
I0929 19:43:24.878118  2630 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0929 19:43:38.323386  2630 solver.cpp:218] Iteration 11600 (7.43758 iter/s, 13.4452s/100 iters), loss = 0.254605
I0929 19:43:38.323427  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254605 (* 1 = 0.254605 loss)
I0929 19:43:38.323433  2630 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0929 19:43:51.796715  2630 solver.cpp:218] Iteration 11700 (7.42212 iter/s, 13.4732s/100 iters), loss = 0.372785
I0929 19:43:51.796824  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372785 (* 1 = 0.372785 loss)
I0929 19:43:51.796831  2630 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0929 19:44:05.256238  2630 solver.cpp:218] Iteration 11800 (7.42976 iter/s, 13.4594s/100 iters), loss = 0.254007
I0929 19:44:05.256268  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254007 (* 1 = 0.254007 loss)
I0929 19:44:05.256284  2630 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0929 19:44:18.713999  2630 solver.cpp:218] Iteration 11900 (7.4307 iter/s, 13.4577s/100 iters), loss = 0.192821
I0929 19:44:18.714030  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192821 (* 1 = 0.192821 loss)
I0929 19:44:18.714040  2630 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0929 19:44:31.502837  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:44:32.039832  2630 solver.cpp:330] Iteration 12000, Testing net (#0)
I0929 19:44:35.133702  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:44:35.262588  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5766
I0929 19:44:35.262614  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.58935 (* 1 = 1.58935 loss)
I0929 19:44:35.397892  2630 solver.cpp:218] Iteration 12000 (5.99383 iter/s, 16.6838s/100 iters), loss = 0.29952
I0929 19:44:35.397931  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29952 (* 1 = 0.29952 loss)
I0929 19:44:35.397941  2630 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0929 19:44:48.872406  2630 solver.cpp:218] Iteration 12100 (7.42146 iter/s, 13.4744s/100 iters), loss = 0.225379
I0929 19:44:48.872439  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225379 (* 1 = 0.225379 loss)
I0929 19:44:48.872458  2630 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0929 19:45:02.333441  2630 solver.cpp:218] Iteration 12200 (7.42889 iter/s, 13.461s/100 iters), loss = 0.279435
I0929 19:45:02.333609  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279435 (* 1 = 0.279435 loss)
I0929 19:45:02.333633  2630 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0929 19:45:15.804329  2630 solver.cpp:218] Iteration 12300 (7.42353 iter/s, 13.4707s/100 iters), loss = 0.341232
I0929 19:45:15.804363  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341231 (* 1 = 0.341231 loss)
I0929 19:45:15.804370  2630 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0929 19:45:29.270014  2630 solver.cpp:218] Iteration 12400 (7.42632 iter/s, 13.4656s/100 iters), loss = 0.24275
I0929 19:45:29.270046  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24275 (* 1 = 0.24275 loss)
I0929 19:45:29.270054  2630 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0929 19:45:42.080307  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:45:42.617991  2630 solver.cpp:330] Iteration 12500, Testing net (#0)
I0929 19:45:45.710180  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:45:45.839081  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7569
I0929 19:45:45.839107  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.814231 (* 1 = 0.814231 loss)
I0929 19:45:45.972805  2630 solver.cpp:218] Iteration 12500 (5.98705 iter/s, 16.7027s/100 iters), loss = 0.226311
I0929 19:45:45.972839  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22631 (* 1 = 0.22631 loss)
I0929 19:45:45.972848  2630 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0929 19:45:59.422075  2630 solver.cpp:218] Iteration 12600 (7.43539 iter/s, 13.4492s/100 iters), loss = 0.277505
I0929 19:45:59.422116  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277505 (* 1 = 0.277505 loss)
I0929 19:45:59.422125  2630 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0929 19:46:12.894914  2630 solver.cpp:218] Iteration 12700 (7.42238 iter/s, 13.4728s/100 iters), loss = 0.163723
I0929 19:46:12.895027  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163722 (* 1 = 0.163722 loss)
I0929 19:46:12.895037  2630 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0929 19:46:26.358345  2630 solver.cpp:218] Iteration 12800 (7.42761 iter/s, 13.4633s/100 iters), loss = 0.268231
I0929 19:46:26.358382  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268231 (* 1 = 0.268231 loss)
I0929 19:46:26.358392  2630 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0929 19:46:39.821333  2630 solver.cpp:218] Iteration 12900 (7.42781 iter/s, 13.4629s/100 iters), loss = 0.228757
I0929 19:46:39.821370  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228757 (* 1 = 0.228757 loss)
I0929 19:46:39.821380  2630 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0929 19:46:52.610086  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:46:53.148596  2630 solver.cpp:330] Iteration 13000, Testing net (#0)
I0929 19:46:56.243692  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:46:56.372997  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7216
I0929 19:46:56.373047  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.846697 (* 1 = 0.846697 loss)
I0929 19:46:56.511571  2630 solver.cpp:218] Iteration 13000 (5.99156 iter/s, 16.6902s/100 iters), loss = 0.248583
I0929 19:46:56.511613  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248583 (* 1 = 0.248583 loss)
I0929 19:46:56.511623  2630 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0929 19:47:09.980005  2630 solver.cpp:218] Iteration 13100 (7.42481 iter/s, 13.4684s/100 iters), loss = 0.263891
I0929 19:47:09.980037  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263891 (* 1 = 0.263891 loss)
I0929 19:47:09.980046  2630 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0929 19:47:23.436784  2630 solver.cpp:218] Iteration 13200 (7.43124 iter/s, 13.4567s/100 iters), loss = 0.327703
I0929 19:47:23.436931  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327703 (* 1 = 0.327703 loss)
I0929 19:47:23.436965  2630 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0929 19:47:36.899318  2630 solver.cpp:218] Iteration 13300 (7.42814 iter/s, 13.4623s/100 iters), loss = 0.318794
I0929 19:47:36.899358  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318793 (* 1 = 0.318793 loss)
I0929 19:47:36.899364  2630 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0929 19:47:50.358103  2630 solver.cpp:218] Iteration 13400 (7.43014 iter/s, 13.4587s/100 iters), loss = 0.247813
I0929 19:47:50.358145  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247813 (* 1 = 0.247813 loss)
I0929 19:47:50.358151  2630 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0929 19:48:03.161149  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:48:03.699440  2630 solver.cpp:330] Iteration 13500, Testing net (#0)
I0929 19:48:06.794642  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:48:06.923017  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7624
I0929 19:48:06.923053  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.723808 (* 1 = 0.723808 loss)
I0929 19:48:07.056749  2630 solver.cpp:218] Iteration 13500 (5.98854 iter/s, 16.6986s/100 iters), loss = 0.162034
I0929 19:48:07.056780  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162034 (* 1 = 0.162034 loss)
I0929 19:48:07.056787  2630 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0929 19:48:20.512773  2630 solver.cpp:218] Iteration 13600 (7.43166 iter/s, 13.4559s/100 iters), loss = 0.323804
I0929 19:48:20.512814  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323804 (* 1 = 0.323804 loss)
I0929 19:48:20.512823  2630 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0929 19:48:33.981717  2630 solver.cpp:218] Iteration 13700 (7.42453 iter/s, 13.4689s/100 iters), loss = 0.268279
I0929 19:48:33.981829  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268279 (* 1 = 0.268279 loss)
I0929 19:48:33.981837  2630 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0929 19:48:47.446125  2630 solver.cpp:218] Iteration 13800 (7.42707 iter/s, 13.4643s/100 iters), loss = 0.270175
I0929 19:48:47.446175  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270174 (* 1 = 0.270174 loss)
I0929 19:48:47.446183  2630 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0929 19:49:00.910728  2630 solver.cpp:218] Iteration 13900 (7.42695 iter/s, 13.4645s/100 iters), loss = 0.233909
I0929 19:49:00.910758  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233909 (* 1 = 0.233909 loss)
I0929 19:49:00.910765  2630 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0929 19:49:13.697409  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:49:14.234055  2630 solver.cpp:330] Iteration 14000, Testing net (#0)
I0929 19:49:17.329877  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:49:17.462378  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7336
I0929 19:49:17.462407  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.876646 (* 1 = 0.876646 loss)
I0929 19:49:17.601409  2630 solver.cpp:218] Iteration 14000 (5.9914 iter/s, 16.6906s/100 iters), loss = 0.219321
I0929 19:49:17.601459  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219321 (* 1 = 0.219321 loss)
I0929 19:49:17.601465  2630 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0929 19:49:31.064714  2630 solver.cpp:218] Iteration 14100 (7.42765 iter/s, 13.4632s/100 iters), loss = 0.26989
I0929 19:49:31.064754  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26989 (* 1 = 0.26989 loss)
I0929 19:49:31.064761  2630 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0929 19:49:44.529501  2630 solver.cpp:218] Iteration 14200 (7.42683 iter/s, 13.4647s/100 iters), loss = 0.321494
I0929 19:49:44.529660  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321494 (* 1 = 0.321494 loss)
I0929 19:49:44.529671  2630 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0929 19:49:57.986973  2630 solver.cpp:218] Iteration 14300 (7.43092 iter/s, 13.4573s/100 iters), loss = 0.296724
I0929 19:49:57.987004  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296723 (* 1 = 0.296723 loss)
I0929 19:49:57.987011  2630 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0929 19:50:11.449453  2630 solver.cpp:218] Iteration 14400 (7.4281 iter/s, 13.4624s/100 iters), loss = 0.354981
I0929 19:50:11.449504  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354981 (* 1 = 0.354981 loss)
I0929 19:50:11.449512  2630 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0929 19:50:24.252251  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:50:24.788985  2630 solver.cpp:330] Iteration 14500, Testing net (#0)
I0929 19:50:27.879276  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:50:28.007654  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8287
I0929 19:50:28.007679  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.527536 (* 1 = 0.527536 loss)
I0929 19:50:28.140877  2630 solver.cpp:218] Iteration 14500 (5.99115 iter/s, 16.6913s/100 iters), loss = 0.198424
I0929 19:50:28.140920  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198424 (* 1 = 0.198424 loss)
I0929 19:50:28.140928  2630 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0929 19:50:41.613065  2630 solver.cpp:218] Iteration 14600 (7.42275 iter/s, 13.4721s/100 iters), loss = 0.30002
I0929 19:50:41.613104  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30002 (* 1 = 0.30002 loss)
I0929 19:50:41.613112  2630 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0929 19:50:55.082392  2630 solver.cpp:218] Iteration 14700 (7.42432 iter/s, 13.4692s/100 iters), loss = 0.27037
I0929 19:50:55.082504  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27037 (* 1 = 0.27037 loss)
I0929 19:50:55.082525  2630 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0929 19:51:08.566150  2630 solver.cpp:218] Iteration 14800 (7.41641 iter/s, 13.4836s/100 iters), loss = 0.262529
I0929 19:51:08.566201  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262529 (* 1 = 0.262529 loss)
I0929 19:51:08.566210  2630 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0929 19:51:22.038445  2630 solver.cpp:218] Iteration 14900 (7.42271 iter/s, 13.4722s/100 iters), loss = 0.238757
I0929 19:51:22.038475  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238757 (* 1 = 0.238757 loss)
I0929 19:51:22.038480  2630 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0929 19:51:34.836479  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:51:35.376438  2630 solver.cpp:330] Iteration 15000, Testing net (#0)
I0929 19:51:38.466759  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:51:38.599277  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7782
I0929 19:51:38.599313  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.666898 (* 1 = 0.666898 loss)
I0929 19:51:38.735054  2630 solver.cpp:218] Iteration 15000 (5.98927 iter/s, 16.6965s/100 iters), loss = 0.213711
I0929 19:51:38.735090  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21371 (* 1 = 0.21371 loss)
I0929 19:51:38.735097  2630 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0929 19:51:52.197623  2630 solver.cpp:218] Iteration 15100 (7.42804 iter/s, 13.4625s/100 iters), loss = 0.302042
I0929 19:51:52.197654  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302042 (* 1 = 0.302042 loss)
I0929 19:51:52.197661  2630 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0929 19:52:05.673218  2630 solver.cpp:218] Iteration 15200 (7.42087 iter/s, 13.4755s/100 iters), loss = 0.332932
I0929 19:52:05.673395  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332932 (* 1 = 0.332932 loss)
I0929 19:52:05.673404  2630 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0929 19:52:19.134335  2630 solver.cpp:218] Iteration 15300 (7.42894 iter/s, 13.4609s/100 iters), loss = 0.316278
I0929 19:52:19.134364  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316277 (* 1 = 0.316277 loss)
I0929 19:52:19.134371  2630 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0929 19:52:32.607563  2630 solver.cpp:218] Iteration 15400 (7.42217 iter/s, 13.4732s/100 iters), loss = 0.206178
I0929 19:52:32.607611  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206178 (* 1 = 0.206178 loss)
I0929 19:52:32.607620  2630 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0929 19:52:45.409019  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:52:45.946151  2630 solver.cpp:330] Iteration 15500, Testing net (#0)
I0929 19:52:49.039950  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:52:49.168701  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7984
I0929 19:52:49.168742  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.63455 (* 1 = 0.63455 loss)
I0929 19:52:49.302899  2630 solver.cpp:218] Iteration 15500 (5.98974 iter/s, 16.6952s/100 iters), loss = 0.277177
I0929 19:52:49.302927  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277177 (* 1 = 0.277177 loss)
I0929 19:52:49.302934  2630 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0929 19:53:02.770015  2630 solver.cpp:218] Iteration 15600 (7.42554 iter/s, 13.467s/100 iters), loss = 0.242236
I0929 19:53:02.770050  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242235 (* 1 = 0.242235 loss)
I0929 19:53:02.770056  2630 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0929 19:53:16.229130  2630 solver.cpp:218] Iteration 15700 (7.42995 iter/s, 13.459s/100 iters), loss = 0.319573
I0929 19:53:16.229230  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319573 (* 1 = 0.319573 loss)
I0929 19:53:16.229238  2630 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0929 19:53:29.704929  2630 solver.cpp:218] Iteration 15800 (7.42079 iter/s, 13.4757s/100 iters), loss = 0.358254
I0929 19:53:29.704965  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358253 (* 1 = 0.358253 loss)
I0929 19:53:29.704972  2630 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0929 19:53:43.169734  2630 solver.cpp:218] Iteration 15900 (7.42681 iter/s, 13.4647s/100 iters), loss = 0.237053
I0929 19:53:43.169764  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237053 (* 1 = 0.237053 loss)
I0929 19:53:43.169770  2630 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0929 19:53:55.967293  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:53:56.507151  2630 solver.cpp:330] Iteration 16000, Testing net (#0)
I0929 19:53:59.599458  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:53:59.730809  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8057
I0929 19:53:59.730835  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.610646 (* 1 = 0.610646 loss)
I0929 19:53:59.864537  2630 solver.cpp:218] Iteration 16000 (5.98992 iter/s, 16.6947s/100 iters), loss = 0.232366
I0929 19:53:59.864570  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232366 (* 1 = 0.232366 loss)
I0929 19:53:59.864578  2630 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0929 19:54:13.322458  2630 solver.cpp:218] Iteration 16100 (7.43061 iter/s, 13.4578s/100 iters), loss = 0.254798
I0929 19:54:13.322489  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254798 (* 1 = 0.254798 loss)
I0929 19:54:13.322494  2630 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0929 19:54:26.791359  2630 solver.cpp:218] Iteration 16200 (7.42455 iter/s, 13.4688s/100 iters), loss = 0.331808
I0929 19:54:26.791493  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331808 (* 1 = 0.331808 loss)
I0929 19:54:26.791512  2630 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0929 19:54:40.247894  2630 solver.cpp:218] Iteration 16300 (7.43142 iter/s, 13.4564s/100 iters), loss = 0.221929
I0929 19:54:40.247928  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221928 (* 1 = 0.221928 loss)
I0929 19:54:40.247936  2630 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0929 19:54:53.722744  2630 solver.cpp:218] Iteration 16400 (7.42128 iter/s, 13.4748s/100 iters), loss = 0.268998
I0929 19:54:53.722793  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268998 (* 1 = 0.268998 loss)
I0929 19:54:53.722800  2630 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0929 19:55:06.531215  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:55:07.068017  2630 solver.cpp:330] Iteration 16500, Testing net (#0)
I0929 19:55:10.161336  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:55:10.290015  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7402
I0929 19:55:10.290051  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.854275 (* 1 = 0.854275 loss)
I0929 19:55:10.423279  2630 solver.cpp:218] Iteration 16500 (5.98787 iter/s, 16.7004s/100 iters), loss = 0.191995
I0929 19:55:10.423306  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191995 (* 1 = 0.191995 loss)
I0929 19:55:10.423313  2630 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0929 19:55:23.887560  2630 solver.cpp:218] Iteration 16600 (7.4271 iter/s, 13.4642s/100 iters), loss = 0.327788
I0929 19:55:23.887594  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327788 (* 1 = 0.327788 loss)
I0929 19:55:23.887601  2630 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0929 19:55:37.348230  2630 solver.cpp:218] Iteration 16700 (7.42909 iter/s, 13.4606s/100 iters), loss = 0.255534
I0929 19:55:37.348373  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255534 (* 1 = 0.255534 loss)
I0929 19:55:37.348381  2630 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0929 19:55:50.818532  2630 solver.cpp:218] Iteration 16800 (7.42383 iter/s, 13.4701s/100 iters), loss = 0.231377
I0929 19:55:50.818567  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231377 (* 1 = 0.231377 loss)
I0929 19:55:50.818573  2630 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0929 19:56:04.282109  2630 solver.cpp:218] Iteration 16900 (7.42749 iter/s, 13.4635s/100 iters), loss = 0.175347
I0929 19:56:04.282137  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175347 (* 1 = 0.175347 loss)
I0929 19:56:04.282143  2630 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0929 19:56:17.070297  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:56:17.610960  2630 solver.cpp:330] Iteration 17000, Testing net (#0)
I0929 19:56:20.703168  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:56:20.832195  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8305
I0929 19:56:20.832221  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.524265 (* 1 = 0.524265 loss)
I0929 19:56:20.965554  2630 solver.cpp:218] Iteration 17000 (5.99399 iter/s, 16.6834s/100 iters), loss = 0.158855
I0929 19:56:20.965589  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158855 (* 1 = 0.158855 loss)
I0929 19:56:20.965595  2630 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0929 19:56:34.429586  2630 solver.cpp:218] Iteration 17100 (7.42724 iter/s, 13.464s/100 iters), loss = 0.254468
I0929 19:56:34.429620  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254467 (* 1 = 0.254467 loss)
I0929 19:56:34.429636  2630 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0929 19:56:47.917083  2630 solver.cpp:218] Iteration 17200 (7.41432 iter/s, 13.4874s/100 iters), loss = 0.24883
I0929 19:56:47.917217  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248829 (* 1 = 0.248829 loss)
I0929 19:56:47.917234  2630 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0929 19:57:01.396793  2630 solver.cpp:218] Iteration 17300 (7.41865 iter/s, 13.4795s/100 iters), loss = 0.260962
I0929 19:57:01.396823  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260962 (* 1 = 0.260962 loss)
I0929 19:57:01.396839  2630 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0929 19:57:14.872977  2630 solver.cpp:218] Iteration 17400 (7.42054 iter/s, 13.4761s/100 iters), loss = 0.248635
I0929 19:57:14.873010  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248635 (* 1 = 0.248635 loss)
I0929 19:57:14.873028  2630 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0929 19:57:27.687042  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:57:28.224179  2630 solver.cpp:330] Iteration 17500, Testing net (#0)
I0929 19:57:31.317015  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:57:31.445472  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7362
I0929 19:57:31.445508  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.83858 (* 1 = 0.83858 loss)
I0929 19:57:31.579437  2630 solver.cpp:218] Iteration 17500 (5.98574 iter/s, 16.7064s/100 iters), loss = 0.20214
I0929 19:57:31.579468  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20214 (* 1 = 0.20214 loss)
I0929 19:57:31.579473  2630 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0929 19:57:45.051538  2630 solver.cpp:218] Iteration 17600 (7.42279 iter/s, 13.472s/100 iters), loss = 0.172316
I0929 19:57:45.051571  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172316 (* 1 = 0.172316 loss)
I0929 19:57:45.051578  2630 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0929 19:57:58.506340  2630 solver.cpp:218] Iteration 17700 (7.43233 iter/s, 13.4547s/100 iters), loss = 0.305894
I0929 19:57:58.506451  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305894 (* 1 = 0.305894 loss)
I0929 19:57:58.506458  2630 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0929 19:58:11.977169  2630 solver.cpp:218] Iteration 17800 (7.42353 iter/s, 13.4707s/100 iters), loss = 0.196101
I0929 19:58:11.977200  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1961 (* 1 = 0.1961 loss)
I0929 19:58:11.977207  2630 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0929 19:58:25.449308  2630 solver.cpp:218] Iteration 17900 (7.42277 iter/s, 13.4721s/100 iters), loss = 0.286705
I0929 19:58:25.449338  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286704 (* 1 = 0.286704 loss)
I0929 19:58:25.449354  2630 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0929 19:58:38.242208  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:58:38.788331  2630 solver.cpp:330] Iteration 18000, Testing net (#0)
I0929 19:58:41.878612  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:58:42.007454  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7846
I0929 19:58:42.007478  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.690138 (* 1 = 0.690138 loss)
I0929 19:58:42.140955  2630 solver.cpp:218] Iteration 18000 (5.99105 iter/s, 16.6916s/100 iters), loss = 0.260955
I0929 19:58:42.140988  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260954 (* 1 = 0.260954 loss)
I0929 19:58:42.140995  2630 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0929 19:58:55.606772  2630 solver.cpp:218] Iteration 18100 (7.42625 iter/s, 13.4657s/100 iters), loss = 0.231765
I0929 19:58:55.606806  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231765 (* 1 = 0.231765 loss)
I0929 19:58:55.606827  2630 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0929 19:59:09.087393  2630 solver.cpp:218] Iteration 18200 (7.4181 iter/s, 13.4805s/100 iters), loss = 0.304572
I0929 19:59:09.087563  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304572 (* 1 = 0.304572 loss)
I0929 19:59:09.087575  2630 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0929 19:59:22.550989  2630 solver.cpp:218] Iteration 18300 (7.42755 iter/s, 13.4634s/100 iters), loss = 0.239707
I0929 19:59:22.551023  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239707 (* 1 = 0.239707 loss)
I0929 19:59:22.551033  2630 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0929 19:59:36.008815  2630 solver.cpp:218] Iteration 18400 (7.43066 iter/s, 13.4578s/100 iters), loss = 0.123765
I0929 19:59:36.008852  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123765 (* 1 = 0.123765 loss)
I0929 19:59:36.008862  2630 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0929 19:59:48.809599  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:59:49.347833  2630 solver.cpp:330] Iteration 18500, Testing net (#0)
I0929 19:59:52.441741  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:59:52.570464  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7082
I0929 19:59:52.570492  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04724 (* 1 = 1.04724 loss)
I0929 19:59:52.704541  2630 solver.cpp:218] Iteration 18500 (5.98959 iter/s, 16.6956s/100 iters), loss = 0.202108
I0929 19:59:52.704576  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202107 (* 1 = 0.202107 loss)
I0929 19:59:52.704586  2630 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0929 20:00:06.172538  2630 solver.cpp:218] Iteration 18600 (7.42505 iter/s, 13.4679s/100 iters), loss = 0.269631
I0929 20:00:06.172574  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26963 (* 1 = 0.26963 loss)
I0929 20:00:06.172583  2630 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0929 20:00:19.632309  2630 solver.cpp:218] Iteration 18700 (7.42959 iter/s, 13.4597s/100 iters), loss = 0.223321
I0929 20:00:19.632422  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223321 (* 1 = 0.223321 loss)
I0929 20:00:19.632443  2630 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0929 20:00:33.107712  2630 solver.cpp:218] Iteration 18800 (7.42101 iter/s, 13.4753s/100 iters), loss = 0.1875
I0929 20:00:33.107744  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1875 (* 1 = 0.1875 loss)
I0929 20:00:33.107762  2630 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0929 20:00:46.577111  2630 solver.cpp:218] Iteration 18900 (7.42428 iter/s, 13.4693s/100 iters), loss = 0.158959
I0929 20:00:46.577145  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158958 (* 1 = 0.158958 loss)
I0929 20:00:46.577152  2630 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0929 20:00:59.371218  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:00:59.915244  2630 solver.cpp:330] Iteration 19000, Testing net (#0)
I0929 20:01:03.008730  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:01:03.137158  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6871
I0929 20:01:03.137183  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15999 (* 1 = 1.15999 loss)
I0929 20:01:03.270845  2630 solver.cpp:218] Iteration 19000 (5.9903 iter/s, 16.6937s/100 iters), loss = 0.151658
I0929 20:01:03.270881  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151658 (* 1 = 0.151658 loss)
I0929 20:01:03.270889  2630 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0929 20:01:16.731293  2630 solver.cpp:218] Iteration 19100 (7.42922 iter/s, 13.4604s/100 iters), loss = 0.252616
I0929 20:01:16.731323  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252615 (* 1 = 0.252615 loss)
I0929 20:01:16.731339  2630 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0929 20:01:30.213384  2630 solver.cpp:218] Iteration 19200 (7.41729 iter/s, 13.482s/100 iters), loss = 0.258785
I0929 20:01:30.213526  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258784 (* 1 = 0.258784 loss)
I0929 20:01:30.213541  2630 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0929 20:01:43.676889  2630 solver.cpp:218] Iteration 19300 (7.42758 iter/s, 13.4633s/100 iters), loss = 0.2039
I0929 20:01:43.676923  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203899 (* 1 = 0.203899 loss)
I0929 20:01:43.676940  2630 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0929 20:01:57.144477  2630 solver.cpp:218] Iteration 19400 (7.42527 iter/s, 13.4675s/100 iters), loss = 0.229612
I0929 20:01:57.144510  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229612 (* 1 = 0.229612 loss)
I0929 20:01:57.144516  2630 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0929 20:02:09.954326  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:02:10.491350  2630 solver.cpp:330] Iteration 19500, Testing net (#0)
I0929 20:02:13.582103  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:02:13.710808  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7899
I0929 20:02:13.710841  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.68306 (* 1 = 0.68306 loss)
I0929 20:02:13.844558  2630 solver.cpp:218] Iteration 19500 (5.98802 iter/s, 16.7s/100 iters), loss = 0.194279
I0929 20:02:13.844586  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194278 (* 1 = 0.194278 loss)
I0929 20:02:13.844594  2630 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0929 20:02:27.309974  2630 solver.cpp:218] Iteration 19600 (7.42647 iter/s, 13.4653s/100 iters), loss = 0.197227
I0929 20:02:27.310006  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197227 (* 1 = 0.197227 loss)
I0929 20:02:27.310014  2630 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0929 20:02:40.762081  2630 solver.cpp:218] Iteration 19700 (7.43382 iter/s, 13.452s/100 iters), loss = 0.220752
I0929 20:02:40.762205  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220752 (* 1 = 0.220752 loss)
I0929 20:02:40.762212  2630 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0929 20:02:54.228947  2630 solver.cpp:218] Iteration 19800 (7.42572 iter/s, 13.4667s/100 iters), loss = 0.26571
I0929 20:02:54.228979  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265709 (* 1 = 0.265709 loss)
I0929 20:02:54.228986  2630 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0929 20:03:07.693303  2630 solver.cpp:218] Iteration 19900 (7.42706 iter/s, 13.4643s/100 iters), loss = 0.190944
I0929 20:03:07.693333  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190944 (* 1 = 0.190944 loss)
I0929 20:03:07.693341  2630 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0929 20:03:20.492534  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:03:21.037168  2630 solver.cpp:330] Iteration 20000, Testing net (#0)
I0929 20:03:24.127707  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:03:24.256916  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7913
I0929 20:03:24.256953  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.655997 (* 1 = 0.655997 loss)
I0929 20:03:24.390713  2630 solver.cpp:218] Iteration 20000 (5.98898 iter/s, 16.6973s/100 iters), loss = 0.109558
I0929 20:03:24.390746  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109558 (* 1 = 0.109558 loss)
I0929 20:03:24.390753  2630 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0929 20:03:37.845968  2630 solver.cpp:218] Iteration 20100 (7.43208 iter/s, 13.4552s/100 iters), loss = 0.238537
I0929 20:03:37.845998  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238537 (* 1 = 0.238537 loss)
I0929 20:03:37.846002  2630 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0929 20:03:51.319351  2630 solver.cpp:218] Iteration 20200 (7.42208 iter/s, 13.4733s/100 iters), loss = 0.214135
I0929 20:03:51.319530  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214135 (* 1 = 0.214135 loss)
I0929 20:03:51.319538  2630 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0929 20:04:04.782372  2630 solver.cpp:218] Iteration 20300 (7.42786 iter/s, 13.4628s/100 iters), loss = 0.193716
I0929 20:04:04.782402  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193716 (* 1 = 0.193716 loss)
I0929 20:04:04.782407  2630 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0929 20:04:18.244309  2630 solver.cpp:218] Iteration 20400 (7.42839 iter/s, 13.4619s/100 iters), loss = 0.170615
I0929 20:04:18.244351  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170614 (* 1 = 0.170614 loss)
I0929 20:04:18.244359  2630 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0929 20:04:31.028900  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:04:31.567234  2630 solver.cpp:330] Iteration 20500, Testing net (#0)
I0929 20:04:34.660076  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:04:34.788271  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8364
I0929 20:04:34.788306  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.480725 (* 1 = 0.480725 loss)
I0929 20:04:34.922044  2630 solver.cpp:218] Iteration 20500 (5.99605 iter/s, 16.6776s/100 iters), loss = 0.128941
I0929 20:04:34.922076  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128941 (* 1 = 0.128941 loss)
I0929 20:04:34.922083  2630 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0929 20:04:48.394043  2630 solver.cpp:218] Iteration 20600 (7.42285 iter/s, 13.4719s/100 iters), loss = 0.154856
I0929 20:04:48.394088  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154856 (* 1 = 0.154856 loss)
I0929 20:04:48.394094  2630 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0929 20:05:01.857095  2630 solver.cpp:218] Iteration 20700 (7.42778 iter/s, 13.463s/100 iters), loss = 0.185869
I0929 20:05:01.857216  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185869 (* 1 = 0.185869 loss)
I0929 20:05:01.857223  2630 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0929 20:05:15.323302  2630 solver.cpp:218] Iteration 20800 (7.42609 iter/s, 13.466s/100 iters), loss = 0.195594
I0929 20:05:15.323331  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195594 (* 1 = 0.195594 loss)
I0929 20:05:15.323338  2630 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0929 20:05:28.789670  2630 solver.cpp:218] Iteration 20900 (7.42595 iter/s, 13.4663s/100 iters), loss = 0.135862
I0929 20:05:28.789710  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135862 (* 1 = 0.135862 loss)
I0929 20:05:28.789716  2630 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0929 20:05:41.596429  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:05:42.139503  2630 solver.cpp:330] Iteration 21000, Testing net (#0)
I0929 20:05:45.229845  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:05:45.358675  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7942
I0929 20:05:45.358700  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.665106 (* 1 = 0.665106 loss)
I0929 20:05:45.492681  2630 solver.cpp:218] Iteration 21000 (5.98698 iter/s, 16.7029s/100 iters), loss = 0.262432
I0929 20:05:45.492713  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262432 (* 1 = 0.262432 loss)
I0929 20:05:45.492720  2630 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0929 20:05:58.946908  2630 solver.cpp:218] Iteration 21100 (7.43265 iter/s, 13.4541s/100 iters), loss = 0.211695
I0929 20:05:58.946938  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211694 (* 1 = 0.211694 loss)
I0929 20:05:58.946944  2630 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0929 20:06:12.421687  2630 solver.cpp:218] Iteration 21200 (7.42131 iter/s, 13.4747s/100 iters), loss = 0.163504
I0929 20:06:12.421866  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163504 (* 1 = 0.163504 loss)
I0929 20:06:12.421875  2630 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0929 20:06:25.885246  2630 solver.cpp:218] Iteration 21300 (7.42757 iter/s, 13.4634s/100 iters), loss = 0.215492
I0929 20:06:25.885277  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215492 (* 1 = 0.215492 loss)
I0929 20:06:25.885282  2630 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0929 20:06:39.350567  2630 solver.cpp:218] Iteration 21400 (7.42652 iter/s, 13.4653s/100 iters), loss = 0.128961
I0929 20:06:39.350599  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128961 (* 1 = 0.128961 loss)
I0929 20:06:39.350605  2630 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0929 20:06:52.135982  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:06:52.671787  2630 solver.cpp:330] Iteration 21500, Testing net (#0)
I0929 20:06:55.765480  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:06:55.894309  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7517
I0929 20:06:55.894335  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.791808 (* 1 = 0.791808 loss)
I0929 20:06:56.028803  2630 solver.cpp:218] Iteration 21500 (5.99587 iter/s, 16.6782s/100 iters), loss = 0.168075
I0929 20:06:56.028831  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168074 (* 1 = 0.168074 loss)
I0929 20:06:56.028838  2630 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0929 20:07:09.502909  2630 solver.cpp:218] Iteration 21600 (7.42168 iter/s, 13.474s/100 iters), loss = 0.12889
I0929 20:07:09.502939  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128889 (* 1 = 0.128889 loss)
I0929 20:07:09.502946  2630 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0929 20:07:22.965595  2630 solver.cpp:218] Iteration 21700 (7.42798 iter/s, 13.4626s/100 iters), loss = 0.294117
I0929 20:07:22.965708  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294117 (* 1 = 0.294117 loss)
I0929 20:07:22.965716  2630 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0929 20:07:36.428098  2630 solver.cpp:218] Iteration 21800 (7.42812 iter/s, 13.4624s/100 iters), loss = 0.234896
I0929 20:07:36.428128  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234895 (* 1 = 0.234895 loss)
I0929 20:07:36.428134  2630 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0929 20:07:49.888612  2630 solver.cpp:218] Iteration 21900 (7.42918 iter/s, 13.4604s/100 iters), loss = 0.172067
I0929 20:07:49.888641  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172067 (* 1 = 0.172067 loss)
I0929 20:07:49.888648  2630 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0929 20:08:02.692286  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:08:03.232066  2630 solver.cpp:330] Iteration 22000, Testing net (#0)
I0929 20:08:06.323426  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:08:06.452175  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8073
I0929 20:08:06.452224  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.592231 (* 1 = 0.592231 loss)
I0929 20:08:06.586619  2630 solver.cpp:218] Iteration 22000 (5.98877 iter/s, 16.6979s/100 iters), loss = 0.156473
I0929 20:08:06.586653  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156473 (* 1 = 0.156473 loss)
I0929 20:08:06.586661  2630 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0929 20:08:20.037356  2630 solver.cpp:218] Iteration 22100 (7.43458 iter/s, 13.4507s/100 iters), loss = 0.354365
I0929 20:08:20.037389  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354365 (* 1 = 0.354365 loss)
I0929 20:08:20.037395  2630 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0929 20:08:33.501549  2630 solver.cpp:218] Iteration 22200 (7.42715 iter/s, 13.4641s/100 iters), loss = 0.187257
I0929 20:08:33.501691  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187257 (* 1 = 0.187257 loss)
I0929 20:08:33.501700  2630 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0929 20:08:46.972751  2630 solver.cpp:218] Iteration 22300 (7.42334 iter/s, 13.471s/100 iters), loss = 0.126781
I0929 20:08:46.972782  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126781 (* 1 = 0.126781 loss)
I0929 20:08:46.972789  2630 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0929 20:09:00.442962  2630 solver.cpp:218] Iteration 22400 (7.42383 iter/s, 13.4701s/100 iters), loss = 0.15357
I0929 20:09:00.442992  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153569 (* 1 = 0.153569 loss)
I0929 20:09:00.442998  2630 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0929 20:09:13.232029  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:09:13.768263  2630 solver.cpp:330] Iteration 22500, Testing net (#0)
I0929 20:09:16.860318  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:09:16.988309  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7064
I0929 20:09:16.988332  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03919 (* 1 = 1.03919 loss)
I0929 20:09:17.122288  2630 solver.cpp:218] Iteration 22500 (5.99547 iter/s, 16.6792s/100 iters), loss = 0.195257
I0929 20:09:17.122347  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195257 (* 1 = 0.195257 loss)
I0929 20:09:17.122354  2630 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0929 20:09:30.601747  2630 solver.cpp:218] Iteration 22600 (7.41875 iter/s, 13.4794s/100 iters), loss = 0.304943
I0929 20:09:30.601778  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304943 (* 1 = 0.304943 loss)
I0929 20:09:30.601785  2630 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0929 20:09:44.071566  2630 solver.cpp:218] Iteration 22700 (7.42404 iter/s, 13.4697s/100 iters), loss = 0.226365
I0929 20:09:44.071691  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226365 (* 1 = 0.226365 loss)
I0929 20:09:44.071707  2630 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0929 20:09:57.540004  2630 solver.cpp:218] Iteration 22800 (7.42486 iter/s, 13.4683s/100 iters), loss = 0.136679
I0929 20:09:57.540040  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136679 (* 1 = 0.136679 loss)
I0929 20:09:57.540047  2630 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0929 20:10:11.005101  2630 solver.cpp:218] Iteration 22900 (7.42665 iter/s, 13.465s/100 iters), loss = 0.182695
I0929 20:10:11.005133  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182694 (* 1 = 0.182694 loss)
I0929 20:10:11.005141  2630 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0929 20:10:23.818555  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:10:24.356295  2630 solver.cpp:330] Iteration 23000, Testing net (#0)
I0929 20:10:27.450728  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:10:27.579248  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7952
I0929 20:10:27.579274  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.623637 (* 1 = 0.623637 loss)
I0929 20:10:27.713279  2630 solver.cpp:218] Iteration 23000 (5.98512 iter/s, 16.7081s/100 iters), loss = 0.154901
I0929 20:10:27.713310  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154901 (* 1 = 0.154901 loss)
I0929 20:10:27.713327  2630 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0929 20:10:41.218667  2630 solver.cpp:218] Iteration 23100 (7.40449 iter/s, 13.5053s/100 iters), loss = 0.22302
I0929 20:10:41.218695  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22302 (* 1 = 0.22302 loss)
I0929 20:10:41.218701  2630 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0929 20:10:54.744840  2630 solver.cpp:218] Iteration 23200 (7.39311 iter/s, 13.5261s/100 iters), loss = 0.153984
I0929 20:10:54.744994  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153983 (* 1 = 0.153983 loss)
I0929 20:10:54.745002  2630 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0929 20:11:08.325281  2630 solver.cpp:218] Iteration 23300 (7.36364 iter/s, 13.5802s/100 iters), loss = 0.236644
I0929 20:11:08.325325  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236644 (* 1 = 0.236644 loss)
I0929 20:11:08.325332  2630 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0929 20:11:21.807458  2630 solver.cpp:218] Iteration 23400 (7.41725 iter/s, 13.4821s/100 iters), loss = 0.220556
I0929 20:11:21.807488  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220556 (* 1 = 0.220556 loss)
I0929 20:11:21.807494  2630 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0929 20:11:34.601378  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:11:35.136653  2630 solver.cpp:330] Iteration 23500, Testing net (#0)
I0929 20:11:38.230979  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:11:38.359349  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7185
I0929 20:11:38.359385  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.879398 (* 1 = 0.879398 loss)
I0929 20:11:38.493173  2630 solver.cpp:218] Iteration 23500 (5.99318 iter/s, 16.6856s/100 iters), loss = 0.188121
I0929 20:11:38.493206  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18812 (* 1 = 0.18812 loss)
I0929 20:11:38.493213  2630 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0929 20:11:51.960297  2630 solver.cpp:218] Iteration 23600 (7.42553 iter/s, 13.467s/100 iters), loss = 0.250801
I0929 20:11:51.960328  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250801 (* 1 = 0.250801 loss)
I0929 20:11:51.960335  2630 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0929 20:12:05.429739  2630 solver.cpp:218] Iteration 23700 (7.42425 iter/s, 13.4694s/100 iters), loss = 0.243877
I0929 20:12:05.429860  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243877 (* 1 = 0.243877 loss)
I0929 20:12:05.429877  2630 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0929 20:12:18.902779  2630 solver.cpp:218] Iteration 23800 (7.42231 iter/s, 13.4729s/100 iters), loss = 0.169778
I0929 20:12:18.902822  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169777 (* 1 = 0.169777 loss)
I0929 20:12:18.902827  2630 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0929 20:12:32.367707  2630 solver.cpp:218] Iteration 23900 (7.42675 iter/s, 13.4648s/100 iters), loss = 0.121981
I0929 20:12:32.367736  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12198 (* 1 = 0.12198 loss)
I0929 20:12:32.367743  2630 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0929 20:12:45.180413  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:12:45.717317  2630 solver.cpp:330] Iteration 24000, Testing net (#0)
I0929 20:12:48.811334  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:12:48.940124  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8153
I0929 20:12:48.940160  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.582808 (* 1 = 0.582808 loss)
I0929 20:12:49.073927  2630 solver.cpp:218] Iteration 24000 (5.98582 iter/s, 16.7061s/100 iters), loss = 0.153037
I0929 20:12:49.073957  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153036 (* 1 = 0.153036 loss)
I0929 20:12:49.073964  2630 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0929 20:13:02.522186  2630 solver.cpp:218] Iteration 24100 (7.43595 iter/s, 13.4482s/100 iters), loss = 0.174625
I0929 20:13:02.522225  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174625 (* 1 = 0.174625 loss)
I0929 20:13:02.522231  2630 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0929 20:13:15.988590  2630 solver.cpp:218] Iteration 24200 (7.42593 iter/s, 13.4663s/100 iters), loss = 0.211331
I0929 20:13:15.988701  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211331 (* 1 = 0.211331 loss)
I0929 20:13:15.988718  2630 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0929 20:13:29.451356  2630 solver.cpp:218] Iteration 24300 (7.42797 iter/s, 13.4626s/100 iters), loss = 0.275862
I0929 20:13:29.451386  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275862 (* 1 = 0.275862 loss)
I0929 20:13:29.451392  2630 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0929 20:13:42.925758  2630 solver.cpp:218] Iteration 24400 (7.42152 iter/s, 13.4743s/100 iters), loss = 0.230134
I0929 20:13:42.925799  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230134 (* 1 = 0.230134 loss)
I0929 20:13:42.925806  2630 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0929 20:13:55.715912  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:13:56.253082  2630 solver.cpp:330] Iteration 24500, Testing net (#0)
I0929 20:13:59.345762  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:13:59.473901  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8168
I0929 20:13:59.473937  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558802 (* 1 = 0.558802 loss)
I0929 20:13:59.609319  2630 solver.cpp:218] Iteration 24500 (5.99396 iter/s, 16.6835s/100 iters), loss = 0.143548
I0929 20:13:59.609354  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143548 (* 1 = 0.143548 loss)
I0929 20:13:59.609360  2630 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0929 20:14:13.079215  2630 solver.cpp:218] Iteration 24600 (7.424 iter/s, 13.4698s/100 iters), loss = 0.210688
I0929 20:14:13.079243  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210688 (* 1 = 0.210688 loss)
I0929 20:14:13.079251  2630 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0929 20:14:26.547797  2630 solver.cpp:218] Iteration 24700 (7.42473 iter/s, 13.4685s/100 iters), loss = 0.224847
I0929 20:14:26.547945  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224846 (* 1 = 0.224846 loss)
I0929 20:14:26.547955  2630 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0929 20:14:40.004776  2630 solver.cpp:218] Iteration 24800 (7.43121 iter/s, 13.4568s/100 iters), loss = 0.145447
I0929 20:14:40.004806  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145446 (* 1 = 0.145446 loss)
I0929 20:14:40.004812  2630 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0929 20:14:53.461249  2630 solver.cpp:218] Iteration 24900 (7.43141 iter/s, 13.4564s/100 iters), loss = 0.197121
I0929 20:14:53.461278  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197121 (* 1 = 0.197121 loss)
I0929 20:14:53.461285  2630 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0929 20:15:06.270896  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:15:06.807551  2630 solver.cpp:330] Iteration 25000, Testing net (#0)
I0929 20:15:09.899816  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:15:10.028863  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7804
I0929 20:15:10.028909  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.694677 (* 1 = 0.694677 loss)
I0929 20:15:10.163255  2630 solver.cpp:218] Iteration 25000 (5.98733 iter/s, 16.7019s/100 iters), loss = 0.159384
I0929 20:15:10.163285  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159384 (* 1 = 0.159384 loss)
I0929 20:15:10.163291  2630 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0929 20:15:23.623461  2630 solver.cpp:218] Iteration 25100 (7.42935 iter/s, 13.4601s/100 iters), loss = 0.30563
I0929 20:15:23.623497  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30563 (* 1 = 0.30563 loss)
I0929 20:15:23.623504  2630 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0929 20:15:37.085240  2630 solver.cpp:218] Iteration 25200 (7.42848 iter/s, 13.4617s/100 iters), loss = 0.210708
I0929 20:15:37.085378  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210708 (* 1 = 0.210708 loss)
I0929 20:15:37.085386  2630 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0929 20:15:50.551420  2630 solver.cpp:218] Iteration 25300 (7.4261 iter/s, 13.466s/100 iters), loss = 0.203824
I0929 20:15:50.551455  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203824 (* 1 = 0.203824 loss)
I0929 20:15:50.551462  2630 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0929 20:16:04.029247  2630 solver.cpp:218] Iteration 25400 (7.41964 iter/s, 13.4778s/100 iters), loss = 0.192038
I0929 20:16:04.029278  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192038 (* 1 = 0.192038 loss)
I0929 20:16:04.029284  2630 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0929 20:16:16.822026  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:16:17.359324  2630 solver.cpp:330] Iteration 25500, Testing net (#0)
I0929 20:16:20.449610  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:16:20.579926  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7704
I0929 20:16:20.579953  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794294 (* 1 = 0.794294 loss)
I0929 20:16:20.718250  2630 solver.cpp:218] Iteration 25500 (5.992 iter/s, 16.6889s/100 iters), loss = 0.225192
I0929 20:16:20.718297  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225192 (* 1 = 0.225192 loss)
I0929 20:16:20.718303  2630 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0929 20:16:34.179013  2630 solver.cpp:218] Iteration 25600 (7.42907 iter/s, 13.4606s/100 iters), loss = 0.192943
I0929 20:16:34.179054  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192943 (* 1 = 0.192943 loss)
I0929 20:16:34.179060  2630 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0929 20:16:47.649271  2630 solver.cpp:218] Iteration 25700 (7.42381 iter/s, 13.4702s/100 iters), loss = 0.188406
I0929 20:16:47.649377  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188405 (* 1 = 0.188405 loss)
I0929 20:16:47.649395  2630 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0929 20:17:01.116281  2630 solver.cpp:218] Iteration 25800 (7.42563 iter/s, 13.4669s/100 iters), loss = 0.170866
I0929 20:17:01.116312  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170865 (* 1 = 0.170865 loss)
I0929 20:17:01.116317  2630 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0929 20:17:14.579213  2630 solver.cpp:218] Iteration 25900 (7.42784 iter/s, 13.4629s/100 iters), loss = 0.307314
I0929 20:17:14.579260  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307314 (* 1 = 0.307314 loss)
I0929 20:17:14.579268  2630 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0929 20:17:27.387243  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:17:27.925395  2630 solver.cpp:330] Iteration 26000, Testing net (#0)
I0929 20:17:31.018103  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:17:31.146551  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7839
I0929 20:17:31.146576  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.662642 (* 1 = 0.662642 loss)
I0929 20:17:31.280223  2630 solver.cpp:218] Iteration 26000 (5.98771 iter/s, 16.7009s/100 iters), loss = 0.21841
I0929 20:17:31.280253  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21841 (* 1 = 0.21841 loss)
I0929 20:17:31.280261  2630 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0929 20:17:44.746484  2630 solver.cpp:218] Iteration 26100 (7.42601 iter/s, 13.4662s/100 iters), loss = 0.172295
I0929 20:17:44.746518  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172295 (* 1 = 0.172295 loss)
I0929 20:17:44.746537  2630 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0929 20:17:58.206684  2630 solver.cpp:218] Iteration 26200 (7.42935 iter/s, 13.4601s/100 iters), loss = 0.209363
I0929 20:17:58.206796  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209363 (* 1 = 0.209363 loss)
I0929 20:17:58.206804  2630 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0929 20:18:11.672821  2630 solver.cpp:218] Iteration 26300 (7.42612 iter/s, 13.466s/100 iters), loss = 0.214569
I0929 20:18:11.672857  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214569 (* 1 = 0.214569 loss)
I0929 20:18:11.672864  2630 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0929 20:18:25.144453  2630 solver.cpp:218] Iteration 26400 (7.42307 iter/s, 13.4715s/100 iters), loss = 0.176058
I0929 20:18:25.144492  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176058 (* 1 = 0.176058 loss)
I0929 20:18:25.144500  2630 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0929 20:18:37.936676  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:18:38.473335  2630 solver.cpp:330] Iteration 26500, Testing net (#0)
I0929 20:18:41.565521  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:18:41.697326  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6781
I0929 20:18:41.697365  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09897 (* 1 = 1.09897 loss)
I0929 20:18:41.834241  2630 solver.cpp:218] Iteration 26500 (5.99172 iter/s, 16.6897s/100 iters), loss = 0.115255
I0929 20:18:41.834275  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115255 (* 1 = 0.115255 loss)
I0929 20:18:41.834283  2630 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0929 20:18:55.299835  2630 solver.cpp:218] Iteration 26600 (7.42638 iter/s, 13.4655s/100 iters), loss = 0.175501
I0929 20:18:55.299875  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175501 (* 1 = 0.175501 loss)
I0929 20:18:55.299880  2630 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0929 20:19:08.779162  2630 solver.cpp:218] Iteration 26700 (7.41881 iter/s, 13.4792s/100 iters), loss = 0.151648
I0929 20:19:08.779284  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151648 (* 1 = 0.151648 loss)
I0929 20:19:08.779292  2630 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0929 20:19:22.251305  2630 solver.cpp:218] Iteration 26800 (7.42281 iter/s, 13.472s/100 iters), loss = 0.118859
I0929 20:19:22.251335  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118859 (* 1 = 0.118859 loss)
I0929 20:19:22.251343  2630 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0929 20:19:35.722306  2630 solver.cpp:218] Iteration 26900 (7.42339 iter/s, 13.4709s/100 iters), loss = 0.215231
I0929 20:19:35.722344  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215231 (* 1 = 0.215231 loss)
I0929 20:19:35.722352  2630 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0929 20:19:48.531803  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:19:49.068899  2630 solver.cpp:330] Iteration 27000, Testing net (#0)
I0929 20:19:52.164188  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:19:52.292470  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7712
I0929 20:19:52.292511  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.737186 (* 1 = 0.737186 loss)
I0929 20:19:52.425776  2630 solver.cpp:218] Iteration 27000 (5.98681 iter/s, 16.7034s/100 iters), loss = 0.102072
I0929 20:19:52.425803  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102072 (* 1 = 0.102072 loss)
I0929 20:19:52.425810  2630 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0929 20:20:05.902060  2630 solver.cpp:218] Iteration 27100 (7.42049 iter/s, 13.4762s/100 iters), loss = 0.251371
I0929 20:20:05.902096  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251371 (* 1 = 0.251371 loss)
I0929 20:20:05.902102  2630 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0929 20:20:19.358296  2630 solver.cpp:218] Iteration 27200 (7.43154 iter/s, 13.4562s/100 iters), loss = 0.377567
I0929 20:20:19.358412  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377567 (* 1 = 0.377567 loss)
I0929 20:20:19.358429  2630 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0929 20:20:32.826493  2630 solver.cpp:218] Iteration 27300 (7.42498 iter/s, 13.468s/100 iters), loss = 0.170219
I0929 20:20:32.826530  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170219 (* 1 = 0.170219 loss)
I0929 20:20:32.826539  2630 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0929 20:20:46.296753  2630 solver.cpp:218] Iteration 27400 (7.4238 iter/s, 13.4702s/100 iters), loss = 0.168177
I0929 20:20:46.296784  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168177 (* 1 = 0.168177 loss)
I0929 20:20:46.296790  2630 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0929 20:20:59.096223  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:20:59.634976  2630 solver.cpp:330] Iteration 27500, Testing net (#0)
I0929 20:21:02.729132  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:21:02.860304  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7791
I0929 20:21:02.860359  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739168 (* 1 = 0.739168 loss)
I0929 20:21:02.995540  2630 solver.cpp:218] Iteration 27500 (5.98849 iter/s, 16.6987s/100 iters), loss = 0.142952
I0929 20:21:02.995573  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142951 (* 1 = 0.142951 loss)
I0929 20:21:02.995581  2630 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0929 20:21:16.448869  2630 solver.cpp:218] Iteration 27600 (7.43315 iter/s, 13.4533s/100 iters), loss = 0.187155
I0929 20:21:16.448909  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187154 (* 1 = 0.187154 loss)
I0929 20:21:16.448915  2630 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0929 20:21:29.918691  2630 solver.cpp:218] Iteration 27700 (7.42405 iter/s, 13.4697s/100 iters), loss = 0.145213
I0929 20:21:29.918817  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145213 (* 1 = 0.145213 loss)
I0929 20:21:29.918825  2630 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0929 20:21:43.372628  2630 solver.cpp:218] Iteration 27800 (7.43286 iter/s, 13.4538s/100 iters), loss = 0.308398
I0929 20:21:43.372658  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308398 (* 1 = 0.308398 loss)
I0929 20:21:43.372664  2630 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0929 20:21:56.831434  2630 solver.cpp:218] Iteration 27900 (7.43012 iter/s, 13.4587s/100 iters), loss = 0.183362
I0929 20:21:56.831475  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183362 (* 1 = 0.183362 loss)
I0929 20:21:56.831495  2630 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0929 20:22:09.621871  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:22:10.159857  2630 solver.cpp:330] Iteration 28000, Testing net (#0)
I0929 20:22:13.254462  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:22:13.383433  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8418
I0929 20:22:13.383463  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.489326 (* 1 = 0.489326 loss)
I0929 20:22:13.516618  2630 solver.cpp:218] Iteration 28000 (5.99345 iter/s, 16.6849s/100 iters), loss = 0.130717
I0929 20:22:13.516651  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130717 (* 1 = 0.130717 loss)
I0929 20:22:13.516659  2630 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0929 20:22:26.992698  2630 solver.cpp:218] Iteration 28100 (7.4206 iter/s, 13.476s/100 iters), loss = 0.133597
I0929 20:22:26.992732  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133597 (* 1 = 0.133597 loss)
I0929 20:22:26.992755  2630 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0929 20:22:40.454985  2630 solver.cpp:218] Iteration 28200 (7.4282 iter/s, 13.4622s/100 iters), loss = 0.208974
I0929 20:22:40.455133  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208974 (* 1 = 0.208974 loss)
I0929 20:22:40.455142  2630 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0929 20:22:53.929822  2630 solver.cpp:218] Iteration 28300 (7.42134 iter/s, 13.4747s/100 iters), loss = 0.189871
I0929 20:22:53.929858  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189871 (* 1 = 0.189871 loss)
I0929 20:22:53.929865  2630 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0929 20:23:07.391705  2630 solver.cpp:218] Iteration 28400 (7.42842 iter/s, 13.4618s/100 iters), loss = 0.110748
I0929 20:23:07.391734  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110748 (* 1 = 0.110748 loss)
I0929 20:23:07.391741  2630 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0929 20:23:20.188778  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:23:20.728925  2630 solver.cpp:330] Iteration 28500, Testing net (#0)
I0929 20:23:23.823024  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:23:23.953353  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8365
I0929 20:23:23.953389  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.48648 (* 1 = 0.48648 loss)
I0929 20:23:24.087285  2630 solver.cpp:218] Iteration 28500 (5.98964 iter/s, 16.6955s/100 iters), loss = 0.128298
I0929 20:23:24.087321  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128298 (* 1 = 0.128298 loss)
I0929 20:23:24.087327  2630 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0929 20:23:37.534837  2630 solver.cpp:218] Iteration 28600 (7.43634 iter/s, 13.4475s/100 iters), loss = 0.258131
I0929 20:23:37.534867  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258131 (* 1 = 0.258131 loss)
I0929 20:23:37.534873  2630 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0929 20:23:51.006265  2630 solver.cpp:218] Iteration 28700 (7.42316 iter/s, 13.4714s/100 iters), loss = 0.171367
I0929 20:23:51.006361  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171367 (* 1 = 0.171367 loss)
I0929 20:23:51.006381  2630 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0929 20:24:04.471750  2630 solver.cpp:218] Iteration 28800 (7.42647 iter/s, 13.4654s/100 iters), loss = 0.237884
I0929 20:24:04.471781  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237884 (* 1 = 0.237884 loss)
I0929 20:24:04.471787  2630 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0929 20:24:17.931903  2630 solver.cpp:218] Iteration 28900 (7.42938 iter/s, 13.4601s/100 iters), loss = 0.161421
I0929 20:24:17.931937  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161421 (* 1 = 0.161421 loss)
I0929 20:24:17.931944  2630 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0929 20:24:30.726562  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:24:31.262818  2630 solver.cpp:330] Iteration 29000, Testing net (#0)
I0929 20:24:34.356376  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:24:34.485018  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.802
I0929 20:24:34.485054  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.603218 (* 1 = 0.603218 loss)
I0929 20:24:34.619216  2630 solver.cpp:218] Iteration 29000 (5.99261 iter/s, 16.6872s/100 iters), loss = 0.20333
I0929 20:24:34.619246  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20333 (* 1 = 0.20333 loss)
I0929 20:24:34.619252  2630 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0929 20:24:48.086529  2630 solver.cpp:218] Iteration 29100 (7.42543 iter/s, 13.4672s/100 iters), loss = 0.219429
I0929 20:24:48.086571  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219429 (* 1 = 0.219429 loss)
I0929 20:24:48.086578  2630 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0929 20:25:01.552142  2630 solver.cpp:218] Iteration 29200 (7.42637 iter/s, 13.4655s/100 iters), loss = 0.183284
I0929 20:25:01.552279  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183284 (* 1 = 0.183284 loss)
I0929 20:25:01.552287  2630 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0929 20:25:15.019306  2630 solver.cpp:218] Iteration 29300 (7.42556 iter/s, 13.467s/100 iters), loss = 0.113951
I0929 20:25:15.019340  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11395 (* 1 = 0.11395 loss)
I0929 20:25:15.019346  2630 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0929 20:25:28.483053  2630 solver.cpp:218] Iteration 29400 (7.42739 iter/s, 13.4637s/100 iters), loss = 0.224182
I0929 20:25:28.483083  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224182 (* 1 = 0.224182 loss)
I0929 20:25:28.483089  2630 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0929 20:25:41.292922  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:25:41.837999  2630 solver.cpp:330] Iteration 29500, Testing net (#0)
I0929 20:25:44.929072  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:25:45.057533  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7886
I0929 20:25:45.057559  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691735 (* 1 = 0.691735 loss)
I0929 20:25:45.191747  2630 solver.cpp:218] Iteration 29500 (5.98494 iter/s, 16.7086s/100 iters), loss = 0.195771
I0929 20:25:45.191781  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195771 (* 1 = 0.195771 loss)
I0929 20:25:45.191787  2630 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0929 20:25:58.640422  2630 solver.cpp:218] Iteration 29600 (7.43572 iter/s, 13.4486s/100 iters), loss = 0.135275
I0929 20:25:58.640452  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135275 (* 1 = 0.135275 loss)
I0929 20:25:58.640458  2630 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0929 20:26:12.110965  2630 solver.cpp:218] Iteration 29700 (7.42365 iter/s, 13.4705s/100 iters), loss = 0.234229
I0929 20:26:12.111069  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234228 (* 1 = 0.234228 loss)
I0929 20:26:12.111086  2630 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0929 20:26:25.579620  2630 solver.cpp:218] Iteration 29800 (7.42473 iter/s, 13.4685s/100 iters), loss = 0.15348
I0929 20:26:25.579663  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15348 (* 1 = 0.15348 loss)
I0929 20:26:25.579669  2630 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0929 20:26:39.046154  2630 solver.cpp:218] Iteration 29900 (7.42586 iter/s, 13.4664s/100 iters), loss = 0.136224
I0929 20:26:39.046185  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136224 (* 1 = 0.136224 loss)
I0929 20:26:39.046191  2630 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0929 20:26:51.831239  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:26:52.366688  2630 solver.cpp:330] Iteration 30000, Testing net (#0)
I0929 20:26:55.460618  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:26:55.589038  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8227
I0929 20:26:55.589073  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.542936 (* 1 = 0.542936 loss)
I0929 20:26:55.722548  2630 solver.cpp:218] Iteration 30000 (5.99653 iter/s, 16.6763s/100 iters), loss = 0.138663
I0929 20:26:55.722580  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138663 (* 1 = 0.138663 loss)
I0929 20:26:55.722586  2630 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0929 20:27:09.208164  2630 solver.cpp:218] Iteration 30100 (7.41535 iter/s, 13.4855s/100 iters), loss = 0.202942
I0929 20:27:09.208196  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202942 (* 1 = 0.202942 loss)
I0929 20:27:09.208204  2630 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0929 20:27:22.678067  2630 solver.cpp:218] Iteration 30200 (7.424 iter/s, 13.4698s/100 iters), loss = 0.270411
I0929 20:27:22.678200  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27041 (* 1 = 0.27041 loss)
I0929 20:27:22.678207  2630 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0929 20:27:36.148552  2630 solver.cpp:218] Iteration 30300 (7.42373 iter/s, 13.4703s/100 iters), loss = 0.263783
I0929 20:27:36.148586  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263783 (* 1 = 0.263783 loss)
I0929 20:27:36.148592  2630 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0929 20:27:49.625658  2630 solver.cpp:218] Iteration 30400 (7.42003 iter/s, 13.477s/100 iters), loss = 0.212318
I0929 20:27:49.625686  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212318 (* 1 = 0.212318 loss)
I0929 20:27:49.625692  2630 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0929 20:28:02.435748  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:28:02.984369  2630 solver.cpp:330] Iteration 30500, Testing net (#0)
I0929 20:28:06.077296  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:28:06.206032  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8077
I0929 20:28:06.206068  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629159 (* 1 = 0.629159 loss)
I0929 20:28:06.339877  2630 solver.cpp:218] Iteration 30500 (5.98296 iter/s, 16.7141s/100 iters), loss = 0.190445
I0929 20:28:06.339911  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190445 (* 1 = 0.190445 loss)
I0929 20:28:06.339920  2630 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0929 20:28:19.809098  2630 solver.cpp:218] Iteration 30600 (7.42437 iter/s, 13.4691s/100 iters), loss = 0.285642
I0929 20:28:19.809128  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285642 (* 1 = 0.285642 loss)
I0929 20:28:19.809144  2630 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0929 20:28:33.287482  2630 solver.cpp:218] Iteration 30700 (7.41933 iter/s, 13.4783s/100 iters), loss = 0.216212
I0929 20:28:33.287658  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216212 (* 1 = 0.216212 loss)
I0929 20:28:33.287683  2630 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0929 20:28:46.767838  2630 solver.cpp:218] Iteration 30800 (7.41832 iter/s, 13.4801s/100 iters), loss = 0.179976
I0929 20:28:46.767870  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179976 (* 1 = 0.179976 loss)
I0929 20:28:46.767889  2630 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0929 20:29:00.246763  2630 solver.cpp:218] Iteration 30900 (7.41903 iter/s, 13.4789s/100 iters), loss = 0.158041
I0929 20:29:00.246807  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158041 (* 1 = 0.158041 loss)
I0929 20:29:00.246817  2630 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0929 20:29:13.037772  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:29:13.575101  2630 solver.cpp:330] Iteration 31000, Testing net (#0)
I0929 20:29:16.668371  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:29:16.797145  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.774
I0929 20:29:16.797173  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710128 (* 1 = 0.710128 loss)
I0929 20:29:16.931259  2630 solver.cpp:218] Iteration 31000 (5.99362 iter/s, 16.6844s/100 iters), loss = 0.158908
I0929 20:29:16.931295  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158908 (* 1 = 0.158908 loss)
I0929 20:29:16.931314  2630 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0929 20:29:30.412700  2630 solver.cpp:218] Iteration 31100 (7.41765 iter/s, 13.4814s/100 iters), loss = 0.175754
I0929 20:29:30.412731  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175754 (* 1 = 0.175754 loss)
I0929 20:29:30.412739  2630 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0929 20:29:43.887822  2630 solver.cpp:218] Iteration 31200 (7.42112 iter/s, 13.4751s/100 iters), loss = 0.10521
I0929 20:29:43.887934  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10521 (* 1 = 0.10521 loss)
I0929 20:29:43.887943  2630 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0929 20:29:57.361378  2630 solver.cpp:218] Iteration 31300 (7.42202 iter/s, 13.4734s/100 iters), loss = 0.168342
I0929 20:29:57.361414  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168342 (* 1 = 0.168342 loss)
I0929 20:29:57.361421  2630 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0929 20:30:10.832940  2630 solver.cpp:218] Iteration 31400 (7.42309 iter/s, 13.4715s/100 iters), loss = 0.14762
I0929 20:30:10.832970  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14762 (* 1 = 0.14762 loss)
I0929 20:30:10.832976  2630 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0929 20:30:23.639897  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:30:24.189442  2630 solver.cpp:330] Iteration 31500, Testing net (#0)
I0929 20:30:27.281327  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:30:27.410030  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8059
I0929 20:30:27.410056  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.633201 (* 1 = 0.633201 loss)
I0929 20:30:27.544317  2630 solver.cpp:218] Iteration 31500 (5.98398 iter/s, 16.7113s/100 iters), loss = 0.103614
I0929 20:30:27.544350  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103614 (* 1 = 0.103614 loss)
I0929 20:30:27.544358  2630 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0929 20:30:40.995882  2630 solver.cpp:218] Iteration 31600 (7.43412 iter/s, 13.4515s/100 iters), loss = 0.245997
I0929 20:30:40.995914  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245997 (* 1 = 0.245997 loss)
I0929 20:30:40.995920  2630 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0929 20:30:54.461182  2630 solver.cpp:218] Iteration 31700 (7.42654 iter/s, 13.4652s/100 iters), loss = 0.23231
I0929 20:30:54.461330  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23231 (* 1 = 0.23231 loss)
I0929 20:30:54.461354  2630 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0929 20:31:07.930052  2630 solver.cpp:218] Iteration 31800 (7.42463 iter/s, 13.4687s/100 iters), loss = 0.171581
I0929 20:31:07.930083  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171581 (* 1 = 0.171581 loss)
I0929 20:31:07.930089  2630 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0929 20:31:21.399104  2630 solver.cpp:218] Iteration 31900 (7.42447 iter/s, 13.469s/100 iters), loss = 0.124167
I0929 20:31:21.399135  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124167 (* 1 = 0.124167 loss)
I0929 20:31:21.399142  2630 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0929 20:31:34.184059  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:31:34.720588  2630 solver.cpp:330] Iteration 32000, Testing net (#0)
I0929 20:31:37.811514  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:31:37.939981  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8214
I0929 20:31:37.940018  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.586286 (* 1 = 0.586286 loss)
I0929 20:31:38.074218  2630 solver.cpp:218] Iteration 32000 (5.99699 iter/s, 16.675s/100 iters), loss = 0.121584
I0929 20:31:38.074250  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121584 (* 1 = 0.121584 loss)
I0929 20:31:38.074257  2630 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0929 20:31:51.550993  2630 solver.cpp:218] Iteration 32100 (7.42022 iter/s, 13.4767s/100 iters), loss = 0.181336
I0929 20:31:51.551028  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181336 (* 1 = 0.181336 loss)
I0929 20:31:51.551034  2630 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0929 20:32:05.016525  2630 solver.cpp:218] Iteration 32200 (7.42641 iter/s, 13.4655s/100 iters), loss = 0.279276
I0929 20:32:05.016649  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279275 (* 1 = 0.279275 loss)
I0929 20:32:05.016667  2630 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0929 20:32:18.489413  2630 solver.cpp:218] Iteration 32300 (7.4224 iter/s, 13.4727s/100 iters), loss = 0.12316
I0929 20:32:18.489444  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12316 (* 1 = 0.12316 loss)
I0929 20:32:18.489450  2630 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0929 20:32:31.951243  2630 solver.cpp:218] Iteration 32400 (7.42845 iter/s, 13.4618s/100 iters), loss = 0.0928418
I0929 20:32:31.951277  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0928417 (* 1 = 0.0928417 loss)
I0929 20:32:31.951283  2630 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0929 20:32:44.760505  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:32:45.303490  2630 solver.cpp:330] Iteration 32500, Testing net (#0)
I0929 20:32:48.398998  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:32:48.527477  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8189
I0929 20:32:48.527513  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.578333 (* 1 = 0.578333 loss)
I0929 20:32:48.660611  2630 solver.cpp:218] Iteration 32500 (5.9847 iter/s, 16.7093s/100 iters), loss = 0.188927
I0929 20:32:48.660642  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188927 (* 1 = 0.188927 loss)
I0929 20:32:48.660650  2630 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0929 20:33:02.124493  2630 solver.cpp:218] Iteration 32600 (7.42732 iter/s, 13.4638s/100 iters), loss = 0.191101
I0929 20:33:02.124522  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191101 (* 1 = 0.191101 loss)
I0929 20:33:02.124528  2630 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0929 20:33:15.593523  2630 solver.cpp:218] Iteration 32700 (7.42448 iter/s, 13.469s/100 iters), loss = 0.221779
I0929 20:33:15.593652  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221778 (* 1 = 0.221778 loss)
I0929 20:33:15.593665  2630 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0929 20:33:29.059584  2630 solver.cpp:218] Iteration 32800 (7.42616 iter/s, 13.4659s/100 iters), loss = 0.203654
I0929 20:33:29.059617  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203654 (* 1 = 0.203654 loss)
I0929 20:33:29.059626  2630 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0929 20:33:42.540261  2630 solver.cpp:218] Iteration 32900 (7.41807 iter/s, 13.4806s/100 iters), loss = 0.222554
I0929 20:33:42.540294  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222554 (* 1 = 0.222554 loss)
I0929 20:33:42.540302  2630 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0929 20:33:55.330106  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:33:55.866019  2630 solver.cpp:330] Iteration 33000, Testing net (#0)
I0929 20:33:58.956284  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:33:59.085342  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8082
I0929 20:33:59.085379  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600847 (* 1 = 0.600847 loss)
I0929 20:33:59.221459  2630 solver.cpp:218] Iteration 33000 (5.9948 iter/s, 16.6811s/100 iters), loss = 0.162154
I0929 20:33:59.221490  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162154 (* 1 = 0.162154 loss)
I0929 20:33:59.221498  2630 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0929 20:34:12.699621  2630 solver.cpp:218] Iteration 33100 (7.41945 iter/s, 13.4781s/100 iters), loss = 0.270719
I0929 20:34:12.699652  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270719 (* 1 = 0.270719 loss)
I0929 20:34:12.699659  2630 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0929 20:34:26.174363  2630 solver.cpp:218] Iteration 33200 (7.42133 iter/s, 13.4747s/100 iters), loss = 0.101999
I0929 20:34:26.174505  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101999 (* 1 = 0.101999 loss)
I0929 20:34:26.174513  2630 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0929 20:34:39.651413  2630 solver.cpp:218] Iteration 33300 (7.42012 iter/s, 13.4769s/100 iters), loss = 0.227099
I0929 20:34:39.651444  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227099 (* 1 = 0.227099 loss)
I0929 20:34:39.651450  2630 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0929 20:34:53.113628  2630 solver.cpp:218] Iteration 33400 (7.42824 iter/s, 13.4621s/100 iters), loss = 0.221852
I0929 20:34:53.113658  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221852 (* 1 = 0.221852 loss)
I0929 20:34:53.113664  2630 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0929 20:35:05.931052  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:35:06.471310  2630 solver.cpp:330] Iteration 33500, Testing net (#0)
I0929 20:35:09.564970  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:35:09.693717  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8059
I0929 20:35:09.693742  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.625216 (* 1 = 0.625216 loss)
I0929 20:35:09.827759  2630 solver.cpp:218] Iteration 33500 (5.98299 iter/s, 16.714s/100 iters), loss = 0.166626
I0929 20:35:09.827788  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166626 (* 1 = 0.166626 loss)
I0929 20:35:09.827795  2630 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0929 20:35:23.289710  2630 solver.cpp:218] Iteration 33600 (7.42838 iter/s, 13.4619s/100 iters), loss = 0.179274
I0929 20:35:23.289739  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179273 (* 1 = 0.179273 loss)
I0929 20:35:23.289746  2630 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0929 20:35:36.749438  2630 solver.cpp:218] Iteration 33700 (7.42961 iter/s, 13.4597s/100 iters), loss = 0.22361
I0929 20:35:36.749560  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22361 (* 1 = 0.22361 loss)
I0929 20:35:36.749568  2630 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0929 20:35:50.212383  2630 solver.cpp:218] Iteration 33800 (7.42788 iter/s, 13.4628s/100 iters), loss = 0.265113
I0929 20:35:50.212414  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265113 (* 1 = 0.265113 loss)
I0929 20:35:50.212420  2630 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0929 20:36:03.692546  2630 solver.cpp:218] Iteration 33900 (7.41835 iter/s, 13.4801s/100 iters), loss = 0.132284
I0929 20:36:03.692576  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132284 (* 1 = 0.132284 loss)
I0929 20:36:03.692584  2630 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0929 20:36:16.480561  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:36:17.019032  2630 solver.cpp:330] Iteration 34000, Testing net (#0)
I0929 20:36:20.110085  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:36:20.238565  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8357
I0929 20:36:20.238590  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.531951 (* 1 = 0.531951 loss)
I0929 20:36:20.372700  2630 solver.cpp:218] Iteration 34000 (5.99518 iter/s, 16.6801s/100 iters), loss = 0.131227
I0929 20:36:20.372728  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131227 (* 1 = 0.131227 loss)
I0929 20:36:20.372735  2630 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0929 20:36:33.839465  2630 solver.cpp:218] Iteration 34100 (7.42573 iter/s, 13.4667s/100 iters), loss = 0.155375
I0929 20:36:33.839499  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155375 (* 1 = 0.155375 loss)
I0929 20:36:33.839507  2630 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0929 20:36:47.310747  2630 solver.cpp:218] Iteration 34200 (7.42324 iter/s, 13.4712s/100 iters), loss = 0.325906
I0929 20:36:47.310860  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325906 (* 1 = 0.325906 loss)
I0929 20:36:47.310870  2630 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0929 20:37:00.778501  2630 solver.cpp:218] Iteration 34300 (7.42523 iter/s, 13.4676s/100 iters), loss = 0.212683
I0929 20:37:00.778533  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212683 (* 1 = 0.212683 loss)
I0929 20:37:00.778540  2630 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0929 20:37:14.237704  2630 solver.cpp:218] Iteration 34400 (7.4299 iter/s, 13.4591s/100 iters), loss = 0.137652
I0929 20:37:14.237732  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137652 (* 1 = 0.137652 loss)
I0929 20:37:14.237738  2630 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0929 20:37:27.044888  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:37:27.582994  2630 solver.cpp:330] Iteration 34500, Testing net (#0)
I0929 20:37:30.673337  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:37:30.802580  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7984
I0929 20:37:30.802606  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.68281 (* 1 = 0.68281 loss)
I0929 20:37:30.936345  2630 solver.cpp:218] Iteration 34500 (5.98854 iter/s, 16.6986s/100 iters), loss = 0.117023
I0929 20:37:30.936378  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117023 (* 1 = 0.117023 loss)
I0929 20:37:30.936385  2630 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0929 20:37:44.394314  2630 solver.cpp:218] Iteration 34600 (7.43058 iter/s, 13.4579s/100 iters), loss = 0.172492
I0929 20:37:44.394345  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172492 (* 1 = 0.172492 loss)
I0929 20:37:44.394351  2630 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0929 20:37:57.851852  2630 solver.cpp:218] Iteration 34700 (7.43082 iter/s, 13.4575s/100 iters), loss = 0.205074
I0929 20:37:57.852032  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205074 (* 1 = 0.205074 loss)
I0929 20:37:57.852041  2630 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0929 20:38:11.369248  2630 solver.cpp:218] Iteration 34800 (7.39798 iter/s, 13.5172s/100 iters), loss = 0.185402
I0929 20:38:11.369279  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185401 (* 1 = 0.185401 loss)
I0929 20:38:11.369285  2630 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0929 20:38:24.939649  2630 solver.cpp:218] Iteration 34900 (7.36902 iter/s, 13.5703s/100 iters), loss = 0.113825
I0929 20:38:24.939682  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113824 (* 1 = 0.113824 loss)
I0929 20:38:24.939692  2630 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0929 20:38:37.874161  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:38:38.410612  2630 solver.cpp:330] Iteration 35000, Testing net (#0)
I0929 20:38:41.499500  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:38:41.626606  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8194
I0929 20:38:41.626633  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.569097 (* 1 = 0.569097 loss)
I0929 20:38:41.760061  2630 solver.cpp:218] Iteration 35000 (5.94519 iter/s, 16.8203s/100 iters), loss = 0.146277
I0929 20:38:41.760102  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146277 (* 1 = 0.146277 loss)
I0929 20:38:41.760110  2630 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0929 20:38:55.302033  2630 solver.cpp:218] Iteration 35100 (7.38449 iter/s, 13.5419s/100 iters), loss = 0.205269
I0929 20:38:55.302065  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205269 (* 1 = 0.205269 loss)
I0929 20:38:55.302074  2630 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0929 20:39:08.995537  2630 solver.cpp:218] Iteration 35200 (7.30277 iter/s, 13.6934s/100 iters), loss = 0.203709
I0929 20:39:08.995642  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203709 (* 1 = 0.203709 loss)
I0929 20:39:08.995651  2630 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0929 20:39:22.741128  2630 solver.cpp:218] Iteration 35300 (7.27514 iter/s, 13.7454s/100 iters), loss = 0.210783
I0929 20:39:22.741163  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210783 (* 1 = 0.210783 loss)
I0929 20:39:22.741171  2630 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0929 20:39:36.322742  2630 solver.cpp:218] Iteration 35400 (7.36294 iter/s, 13.5815s/100 iters), loss = 0.131236
I0929 20:39:36.322774  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131235 (* 1 = 0.131235 loss)
I0929 20:39:36.322782  2630 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0929 20:39:49.232331  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:39:49.771466  2630 solver.cpp:330] Iteration 35500, Testing net (#0)
I0929 20:39:52.897549  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:39:53.025216  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8247
I0929 20:39:53.025240  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.563972 (* 1 = 0.563972 loss)
I0929 20:39:53.157428  2630 solver.cpp:218] Iteration 35500 (5.94015 iter/s, 16.8346s/100 iters), loss = 0.140456
I0929 20:39:53.157456  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140456 (* 1 = 0.140456 loss)
I0929 20:39:53.157464  2630 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0929 20:40:06.831701  2630 solver.cpp:218] Iteration 35600 (7.31304 iter/s, 13.6742s/100 iters), loss = 0.188794
I0929 20:40:06.831753  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188794 (* 1 = 0.188794 loss)
I0929 20:40:06.831761  2630 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0929 20:40:20.593183  2630 solver.cpp:218] Iteration 35700 (7.26674 iter/s, 13.7613s/100 iters), loss = 0.228678
I0929 20:40:20.593348  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228678 (* 1 = 0.228678 loss)
I0929 20:40:20.593366  2630 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0929 20:40:34.363968  2630 solver.cpp:218] Iteration 35800 (7.26186 iter/s, 13.7706s/100 iters), loss = 0.225439
I0929 20:40:34.364001  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225439 (* 1 = 0.225439 loss)
I0929 20:40:34.364007  2630 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0929 20:40:48.013957  2630 solver.cpp:218] Iteration 35900 (7.32605 iter/s, 13.6499s/100 iters), loss = 0.151206
I0929 20:40:48.013993  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151206 (* 1 = 0.151206 loss)
I0929 20:40:48.014000  2630 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0929 20:41:00.910117  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:41:01.455693  2630 solver.cpp:330] Iteration 36000, Testing net (#0)
I0929 20:41:04.561233  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:41:04.693843  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7848
I0929 20:41:04.693869  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.685419 (* 1 = 0.685419 loss)
I0929 20:41:04.828718  2630 solver.cpp:218] Iteration 36000 (5.94719 iter/s, 16.8147s/100 iters), loss = 0.109166
I0929 20:41:04.828748  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109166 (* 1 = 0.109166 loss)
I0929 20:41:04.828757  2630 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0929 20:41:18.418704  2630 solver.cpp:218] Iteration 36100 (7.35841 iter/s, 13.5899s/100 iters), loss = 0.18688
I0929 20:41:18.418759  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18688 (* 1 = 0.18688 loss)
I0929 20:41:18.418766  2630 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0929 20:41:32.099102  2630 solver.cpp:218] Iteration 36200 (7.30978 iter/s, 13.6803s/100 iters), loss = 0.267097
I0929 20:41:32.099241  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267097 (* 1 = 0.267097 loss)
I0929 20:41:32.099248  2630 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0929 20:41:45.887761  2630 solver.cpp:218] Iteration 36300 (7.25243 iter/s, 13.7885s/100 iters), loss = 0.197332
I0929 20:41:45.887792  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197332 (* 1 = 0.197332 loss)
I0929 20:41:45.887799  2630 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0929 20:41:59.613529  2630 solver.cpp:218] Iteration 36400 (7.28561 iter/s, 13.7257s/100 iters), loss = 0.216462
I0929 20:41:59.613567  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216462 (* 1 = 0.216462 loss)
I0929 20:41:59.613574  2630 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0929 20:42:12.460136  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:42:12.997058  2630 solver.cpp:330] Iteration 36500, Testing net (#0)
I0929 20:42:16.086696  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:42:16.215109  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8229
I0929 20:42:16.215134  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.538741 (* 1 = 0.538741 loss)
I0929 20:42:16.349148  2630 solver.cpp:218] Iteration 36500 (5.97531 iter/s, 16.7355s/100 iters), loss = 0.12463
I0929 20:42:16.349176  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12463 (* 1 = 0.12463 loss)
I0929 20:42:16.349184  2630 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0929 20:42:29.819988  2630 solver.cpp:218] Iteration 36600 (7.42348 iter/s, 13.4708s/100 iters), loss = 0.176672
I0929 20:42:29.820024  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176672 (* 1 = 0.176672 loss)
I0929 20:42:29.820032  2630 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0929 20:42:43.274768  2630 solver.cpp:218] Iteration 36700 (7.43234 iter/s, 13.4547s/100 iters), loss = 0.203668
I0929 20:42:43.274900  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203668 (* 1 = 0.203668 loss)
I0929 20:42:43.274919  2630 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0929 20:42:56.747614  2630 solver.cpp:218] Iteration 36800 (7.42243 iter/s, 13.4727s/100 iters), loss = 0.136843
I0929 20:42:56.747651  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136843 (* 1 = 0.136843 loss)
I0929 20:42:56.747659  2630 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0929 20:43:10.272636  2630 solver.cpp:218] Iteration 36900 (7.39375 iter/s, 13.5249s/100 iters), loss = 0.163911
I0929 20:43:10.272676  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163911 (* 1 = 0.163911 loss)
I0929 20:43:10.272683  2630 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0929 20:43:23.104195  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:43:23.641999  2630 solver.cpp:330] Iteration 37000, Testing net (#0)
I0929 20:43:26.737280  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:43:26.868911  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8278
I0929 20:43:26.868938  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.519596 (* 1 = 0.519596 loss)
I0929 20:43:27.005731  2630 solver.cpp:218] Iteration 37000 (5.97621 iter/s, 16.733s/100 iters), loss = 0.181754
I0929 20:43:27.005779  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181754 (* 1 = 0.181754 loss)
I0929 20:43:27.005786  2630 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0929 20:43:40.457726  2630 solver.cpp:218] Iteration 37100 (7.43391 iter/s, 13.4519s/100 iters), loss = 0.197556
I0929 20:43:40.457754  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197556 (* 1 = 0.197556 loss)
I0929 20:43:40.457761  2630 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0929 20:43:53.929283  2630 solver.cpp:218] Iteration 37200 (7.42309 iter/s, 13.4715s/100 iters), loss = 0.159248
I0929 20:43:53.929389  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159248 (* 1 = 0.159248 loss)
I0929 20:43:53.929399  2630 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0929 20:44:07.398267  2630 solver.cpp:218] Iteration 37300 (7.42455 iter/s, 13.4688s/100 iters), loss = 0.18367
I0929 20:44:07.398298  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18367 (* 1 = 0.18367 loss)
I0929 20:44:07.398304  2630 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0929 20:44:20.859928  2630 solver.cpp:218] Iteration 37400 (7.42854 iter/s, 13.4616s/100 iters), loss = 0.134864
I0929 20:44:20.859975  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134864 (* 1 = 0.134864 loss)
I0929 20:44:20.859983  2630 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0929 20:44:33.658814  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:44:34.195917  2630 solver.cpp:330] Iteration 37500, Testing net (#0)
I0929 20:44:37.288022  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:44:37.417095  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7409
I0929 20:44:37.417132  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.837407 (* 1 = 0.837407 loss)
I0929 20:44:37.550946  2630 solver.cpp:218] Iteration 37500 (5.99129 iter/s, 16.6909s/100 iters), loss = 0.163007
I0929 20:44:37.550978  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163007 (* 1 = 0.163007 loss)
I0929 20:44:37.550985  2630 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0929 20:44:51.020072  2630 solver.cpp:218] Iteration 37600 (7.42443 iter/s, 13.469s/100 iters), loss = 0.216073
I0929 20:44:51.020119  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216073 (* 1 = 0.216073 loss)
I0929 20:44:51.020138  2630 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0929 20:45:04.482563  2630 solver.cpp:218] Iteration 37700 (7.42811 iter/s, 13.4624s/100 iters), loss = 0.192724
I0929 20:45:04.482736  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192724 (* 1 = 0.192724 loss)
I0929 20:45:04.482744  2630 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0929 20:45:17.953691  2630 solver.cpp:218] Iteration 37800 (7.4234 iter/s, 13.4709s/100 iters), loss = 0.169793
I0929 20:45:17.953727  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169793 (* 1 = 0.169793 loss)
I0929 20:45:17.953733  2630 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0929 20:45:31.425071  2630 solver.cpp:218] Iteration 37900 (7.42319 iter/s, 13.4713s/100 iters), loss = 0.17168
I0929 20:45:31.425099  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17168 (* 1 = 0.17168 loss)
I0929 20:45:31.425104  2630 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0929 20:45:44.229212  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:45:44.768679  2630 solver.cpp:330] Iteration 38000, Testing net (#0)
I0929 20:45:47.864789  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:45:47.996295  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8053
I0929 20:45:47.996321  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.626265 (* 1 = 0.626265 loss)
I0929 20:45:48.131534  2630 solver.cpp:218] Iteration 38000 (5.98574 iter/s, 16.7064s/100 iters), loss = 0.135192
I0929 20:45:48.131569  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135192 (* 1 = 0.135192 loss)
I0929 20:45:48.131577  2630 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0929 20:46:01.593411  2630 solver.cpp:218] Iteration 38100 (7.42842 iter/s, 13.4618s/100 iters), loss = 0.149719
I0929 20:46:01.593442  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149719 (* 1 = 0.149719 loss)
I0929 20:46:01.593448  2630 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0929 20:46:15.075336  2630 solver.cpp:218] Iteration 38200 (7.41738 iter/s, 13.4819s/100 iters), loss = 0.166653
I0929 20:46:15.075456  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166653 (* 1 = 0.166653 loss)
I0929 20:46:15.075479  2630 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0929 20:46:28.556552  2630 solver.cpp:218] Iteration 38300 (7.41781 iter/s, 13.4811s/100 iters), loss = 0.215146
I0929 20:46:28.556583  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215146 (* 1 = 0.215146 loss)
I0929 20:46:28.556589  2630 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0929 20:46:42.017242  2630 solver.cpp:218] Iteration 38400 (7.42909 iter/s, 13.4606s/100 iters), loss = 0.191137
I0929 20:46:42.017298  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191137 (* 1 = 0.191137 loss)
I0929 20:46:42.017316  2630 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0929 20:46:54.807420  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:46:55.345746  2630 solver.cpp:330] Iteration 38500, Testing net (#0)
I0929 20:46:58.437444  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:46:58.566087  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8069
I0929 20:46:58.566110  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648024 (* 1 = 0.648024 loss)
I0929 20:46:58.699965  2630 solver.cpp:218] Iteration 38500 (5.99427 iter/s, 16.6826s/100 iters), loss = 0.173495
I0929 20:46:58.699993  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173496 (* 1 = 0.173496 loss)
I0929 20:46:58.700001  2630 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0929 20:47:12.181478  2630 solver.cpp:218] Iteration 38600 (7.4176 iter/s, 13.4814s/100 iters), loss = 0.153061
I0929 20:47:12.181511  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153061 (* 1 = 0.153061 loss)
I0929 20:47:12.181519  2630 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0929 20:47:25.648591  2630 solver.cpp:218] Iteration 38700 (7.42554 iter/s, 13.467s/100 iters), loss = 0.14916
I0929 20:47:25.648725  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14916 (* 1 = 0.14916 loss)
I0929 20:47:25.648732  2630 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0929 20:47:39.120357  2630 solver.cpp:218] Iteration 38800 (7.42303 iter/s, 13.4716s/100 iters), loss = 0.205346
I0929 20:47:39.120402  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205346 (* 1 = 0.205346 loss)
I0929 20:47:39.120410  2630 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0929 20:47:52.588285  2630 solver.cpp:218] Iteration 38900 (7.42509 iter/s, 13.4678s/100 iters), loss = 0.191781
I0929 20:47:52.588326  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191781 (* 1 = 0.191781 loss)
I0929 20:47:52.588332  2630 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0929 20:48:05.392115  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:48:05.936620  2630 solver.cpp:330] Iteration 39000, Testing net (#0)
I0929 20:48:09.029367  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:48:09.158596  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7518
I0929 20:48:09.158622  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.849114 (* 1 = 0.849114 loss)
I0929 20:48:09.292125  2630 solver.cpp:218] Iteration 39000 (5.98668 iter/s, 16.7037s/100 iters), loss = 0.129378
I0929 20:48:09.292165  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129378 (* 1 = 0.129378 loss)
I0929 20:48:09.292171  2630 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0929 20:48:22.754062  2630 solver.cpp:218] Iteration 39100 (7.42839 iter/s, 13.4619s/100 iters), loss = 0.200132
I0929 20:48:22.754092  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200132 (* 1 = 0.200132 loss)
I0929 20:48:22.754108  2630 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0929 20:48:36.236970  2630 solver.cpp:218] Iteration 39200 (7.41684 iter/s, 13.4828s/100 iters), loss = 0.248365
I0929 20:48:36.237110  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248365 (* 1 = 0.248365 loss)
I0929 20:48:36.237118  2630 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0929 20:48:49.708894  2630 solver.cpp:218] Iteration 39300 (7.42294 iter/s, 13.4717s/100 iters), loss = 0.165934
I0929 20:48:49.708922  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165934 (* 1 = 0.165934 loss)
I0929 20:48:49.708928  2630 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0929 20:49:03.183172  2630 solver.cpp:218] Iteration 39400 (7.42159 iter/s, 13.4742s/100 iters), loss = 0.155489
I0929 20:49:03.183203  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155489 (* 1 = 0.155489 loss)
I0929 20:49:03.183210  2630 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0929 20:49:15.981133  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:49:16.518568  2630 solver.cpp:330] Iteration 39500, Testing net (#0)
I0929 20:49:19.612695  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:49:19.741432  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8042
I0929 20:49:19.741467  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.633072 (* 1 = 0.633072 loss)
I0929 20:49:19.875881  2630 solver.cpp:218] Iteration 39500 (5.99067 iter/s, 16.6926s/100 iters), loss = 0.126157
I0929 20:49:19.875913  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126157 (* 1 = 0.126157 loss)
I0929 20:49:19.875921  2630 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0929 20:49:33.355649  2630 solver.cpp:218] Iteration 39600 (7.41857 iter/s, 13.4797s/100 iters), loss = 0.173057
I0929 20:49:33.355695  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173057 (* 1 = 0.173057 loss)
I0929 20:49:33.355702  2630 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0929 20:49:46.820077  2630 solver.cpp:218] Iteration 39700 (7.42702 iter/s, 13.4643s/100 iters), loss = 0.207936
I0929 20:49:46.820216  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207936 (* 1 = 0.207936 loss)
I0929 20:49:46.820224  2630 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0929 20:50:00.284936  2630 solver.cpp:218] Iteration 39800 (7.42684 iter/s, 13.4647s/100 iters), loss = 0.19405
I0929 20:50:00.284971  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19405 (* 1 = 0.19405 loss)
I0929 20:50:00.284979  2630 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0929 20:50:13.756005  2630 solver.cpp:218] Iteration 39900 (7.42336 iter/s, 13.471s/100 iters), loss = 0.210458
I0929 20:50:13.756036  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210458 (* 1 = 0.210458 loss)
I0929 20:50:13.756052  2630 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0929 20:50:26.553954  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:50:27.101228  2630 solver.cpp:330] Iteration 40000, Testing net (#0)
I0929 20:50:30.196122  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:50:30.324982  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8037
I0929 20:50:30.325009  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61842 (* 1 = 0.61842 loss)
I0929 20:50:30.458797  2630 solver.cpp:218] Iteration 40000 (5.98705 iter/s, 16.7027s/100 iters), loss = 0.142618
I0929 20:50:30.458848  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142618 (* 1 = 0.142618 loss)
I0929 20:50:30.458856  2630 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0929 20:50:30.458860  2630 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0929 20:50:43.904562  2630 solver.cpp:218] Iteration 40100 (7.43734 iter/s, 13.4457s/100 iters), loss = 0.191338
I0929 20:50:43.904593  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191338 (* 1 = 0.191338 loss)
I0929 20:50:43.904600  2630 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0929 20:50:57.368305  2630 solver.cpp:218] Iteration 40200 (7.4274 iter/s, 13.4637s/100 iters), loss = 0.160246
I0929 20:50:57.368425  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160246 (* 1 = 0.160246 loss)
I0929 20:50:57.368433  2630 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0929 20:51:10.833580  2630 solver.cpp:218] Iteration 40300 (7.42659 iter/s, 13.4651s/100 iters), loss = 0.0874649
I0929 20:51:10.833611  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0874649 (* 1 = 0.0874649 loss)
I0929 20:51:10.833617  2630 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0929 20:51:24.301079  2630 solver.cpp:218] Iteration 40400 (7.42532 iter/s, 13.4674s/100 iters), loss = 0.0353417
I0929 20:51:24.301112  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353417 (* 1 = 0.0353417 loss)
I0929 20:51:24.301120  2630 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0929 20:51:37.091780  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:51:37.629184  2630 solver.cpp:330] Iteration 40500, Testing net (#0)
I0929 20:51:40.721559  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:51:40.851423  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I0929 20:51:40.851447  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321389 (* 1 = 0.321389 loss)
I0929 20:51:40.984515  2630 solver.cpp:218] Iteration 40500 (5.994 iter/s, 16.6834s/100 iters), loss = 0.0568864
I0929 20:51:40.984549  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568864 (* 1 = 0.0568864 loss)
I0929 20:51:40.984555  2630 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0929 20:51:54.458536  2630 solver.cpp:218] Iteration 40600 (7.42173 iter/s, 13.4739s/100 iters), loss = 0.103331
I0929 20:51:54.458570  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103331 (* 1 = 0.103331 loss)
I0929 20:51:54.458576  2630 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0929 20:52:07.929522  2630 solver.cpp:218] Iteration 40700 (7.4234 iter/s, 13.4709s/100 iters), loss = 0.0936902
I0929 20:52:07.929621  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0936903 (* 1 = 0.0936903 loss)
I0929 20:52:07.929639  2630 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0929 20:52:21.393828  2630 solver.cpp:218] Iteration 40800 (7.42712 iter/s, 13.4642s/100 iters), loss = 0.0558671
I0929 20:52:21.393859  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558672 (* 1 = 0.0558672 loss)
I0929 20:52:21.393867  2630 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0929 20:52:34.851415  2630 solver.cpp:218] Iteration 40900 (7.43079 iter/s, 13.4575s/100 iters), loss = 0.0571148
I0929 20:52:34.851446  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0571149 (* 1 = 0.0571149 loss)
I0929 20:52:34.851452  2630 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0929 20:52:47.653035  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:52:48.199172  2630 solver.cpp:330] Iteration 41000, Testing net (#0)
I0929 20:52:51.291424  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:52:51.420229  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I0929 20:52:51.420265  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267266 (* 1 = 0.267266 loss)
I0929 20:52:51.554750  2630 solver.cpp:218] Iteration 41000 (5.98686 iter/s, 16.7033s/100 iters), loss = 0.0553187
I0929 20:52:51.554785  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553188 (* 1 = 0.0553188 loss)
I0929 20:52:51.554793  2630 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0929 20:53:05.000005  2630 solver.cpp:218] Iteration 41100 (7.43761 iter/s, 13.4452s/100 iters), loss = 0.0671168
I0929 20:53:05.000046  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0671168 (* 1 = 0.0671168 loss)
I0929 20:53:05.000051  2630 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0929 20:53:18.460028  2630 solver.cpp:218] Iteration 41200 (7.42945 iter/s, 13.4599s/100 iters), loss = 0.091628
I0929 20:53:18.460180  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0916281 (* 1 = 0.0916281 loss)
I0929 20:53:18.460189  2630 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0929 20:53:31.920166  2630 solver.cpp:218] Iteration 41300 (7.42945 iter/s, 13.4599s/100 iters), loss = 0.0425842
I0929 20:53:31.920200  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425843 (* 1 = 0.0425843 loss)
I0929 20:53:31.920207  2630 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0929 20:53:45.393798  2630 solver.cpp:218] Iteration 41400 (7.42195 iter/s, 13.4736s/100 iters), loss = 0.0339091
I0929 20:53:45.393829  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339092 (* 1 = 0.0339092 loss)
I0929 20:53:45.393836  2630 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0929 20:53:58.175303  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:53:58.712391  2630 solver.cpp:330] Iteration 41500, Testing net (#0)
I0929 20:54:01.805276  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:54:01.934325  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I0929 20:54:01.934362  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.246533 (* 1 = 0.246533 loss)
I0929 20:54:02.067988  2630 solver.cpp:218] Iteration 41500 (5.99732 iter/s, 16.6741s/100 iters), loss = 0.0438177
I0929 20:54:02.068017  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438178 (* 1 = 0.0438178 loss)
I0929 20:54:02.068023  2630 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0929 20:54:15.546607  2630 solver.cpp:218] Iteration 41600 (7.4192 iter/s, 13.4785s/100 iters), loss = 0.0442207
I0929 20:54:15.546639  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0442209 (* 1 = 0.0442209 loss)
I0929 20:54:15.546645  2630 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0929 20:54:29.009862  2630 solver.cpp:218] Iteration 41700 (7.42766 iter/s, 13.4632s/100 iters), loss = 0.103377
I0929 20:54:29.010011  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103377 (* 1 = 0.103377 loss)
I0929 20:54:29.010035  2630 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0929 20:54:42.482864  2630 solver.cpp:218] Iteration 41800 (7.42235 iter/s, 13.4728s/100 iters), loss = 0.0280086
I0929 20:54:42.482908  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280087 (* 1 = 0.0280087 loss)
I0929 20:54:42.482914  2630 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0929 20:54:55.945575  2630 solver.cpp:218] Iteration 41900 (7.42797 iter/s, 13.4626s/100 iters), loss = 0.0441317
I0929 20:54:55.945606  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441318 (* 1 = 0.0441318 loss)
I0929 20:54:55.945612  2630 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0929 20:55:08.751147  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:55:09.299453  2630 solver.cpp:330] Iteration 42000, Testing net (#0)
I0929 20:55:12.393492  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:55:12.522263  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I0929 20:55:12.522289  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264234 (* 1 = 0.264234 loss)
I0929 20:55:12.656771  2630 solver.cpp:218] Iteration 42000 (5.98404 iter/s, 16.7111s/100 iters), loss = 0.0637248
I0929 20:55:12.656805  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.063725 (* 1 = 0.063725 loss)
I0929 20:55:12.656824  2630 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0929 20:55:26.119462  2630 solver.cpp:218] Iteration 42100 (7.42798 iter/s, 13.4626s/100 iters), loss = 0.0638505
I0929 20:55:26.119496  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0638506 (* 1 = 0.0638506 loss)
I0929 20:55:26.119505  2630 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0929 20:55:39.595044  2630 solver.cpp:218] Iteration 42200 (7.42087 iter/s, 13.4755s/100 iters), loss = 0.0954569
I0929 20:55:39.595168  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.095457 (* 1 = 0.095457 loss)
I0929 20:55:39.595196  2630 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0929 20:55:53.073341  2630 solver.cpp:218] Iteration 42300 (7.41942 iter/s, 13.4781s/100 iters), loss = 0.033459
I0929 20:55:53.073375  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334591 (* 1 = 0.0334591 loss)
I0929 20:55:53.073384  2630 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0929 20:56:06.554023  2630 solver.cpp:218] Iteration 42400 (7.41806 iter/s, 13.4806s/100 iters), loss = 0.0224553
I0929 20:56:06.554055  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224554 (* 1 = 0.0224554 loss)
I0929 20:56:06.554061  2630 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0929 20:56:19.342037  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:56:19.880087  2630 solver.cpp:330] Iteration 42500, Testing net (#0)
I0929 20:56:22.972642  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:56:23.101763  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I0929 20:56:23.101797  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.252888 (* 1 = 0.252888 loss)
I0929 20:56:23.236212  2630 solver.cpp:218] Iteration 42500 (5.99445 iter/s, 16.6821s/100 iters), loss = 0.0325043
I0929 20:56:23.236240  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325044 (* 1 = 0.0325044 loss)
I0929 20:56:23.236248  2630 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0929 20:56:36.712211  2630 solver.cpp:218] Iteration 42600 (7.42064 iter/s, 13.4759s/100 iters), loss = 0.0504122
I0929 20:56:36.712244  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504123 (* 1 = 0.0504123 loss)
I0929 20:56:36.712250  2630 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0929 20:56:50.185709  2630 solver.cpp:218] Iteration 42700 (7.42202 iter/s, 13.4734s/100 iters), loss = 0.0390705
I0929 20:56:50.185823  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390706 (* 1 = 0.0390706 loss)
I0929 20:56:50.185830  2630 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0929 20:57:03.662420  2630 solver.cpp:218] Iteration 42800 (7.42029 iter/s, 13.4766s/100 iters), loss = 0.0494624
I0929 20:57:03.662451  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494625 (* 1 = 0.0494625 loss)
I0929 20:57:03.662458  2630 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0929 20:57:17.128993  2630 solver.cpp:218] Iteration 42900 (7.42583 iter/s, 13.4665s/100 iters), loss = 0.0301305
I0929 20:57:17.129022  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301306 (* 1 = 0.0301306 loss)
I0929 20:57:17.129029  2630 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0929 20:57:29.936712  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:57:30.478564  2630 solver.cpp:330] Iteration 43000, Testing net (#0)
I0929 20:57:33.572890  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:57:33.701642  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I0929 20:57:33.701678  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.248157 (* 1 = 0.248157 loss)
I0929 20:57:33.834609  2630 solver.cpp:218] Iteration 43000 (5.98604 iter/s, 16.7055s/100 iters), loss = 0.03165
I0929 20:57:33.834641  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316501 (* 1 = 0.0316501 loss)
I0929 20:57:33.834648  2630 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0929 20:57:47.306715  2630 solver.cpp:218] Iteration 43100 (7.42278 iter/s, 13.472s/100 iters), loss = 0.0582873
I0929 20:57:47.306753  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0582874 (* 1 = 0.0582874 loss)
I0929 20:57:47.306759  2630 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0929 20:58:00.777110  2630 solver.cpp:218] Iteration 43200 (7.42373 iter/s, 13.4703s/100 iters), loss = 0.0654986
I0929 20:58:00.777249  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0654986 (* 1 = 0.0654986 loss)
I0929 20:58:00.777256  2630 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0929 20:58:14.252614  2630 solver.cpp:218] Iteration 43300 (7.42096 iter/s, 13.4753s/100 iters), loss = 0.0554835
I0929 20:58:14.252645  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554835 (* 1 = 0.0554835 loss)
I0929 20:58:14.252651  2630 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0929 20:58:27.736834  2630 solver.cpp:218] Iteration 43400 (7.41612 iter/s, 13.4841s/100 iters), loss = 0.035443
I0929 20:58:27.736863  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035443 (* 1 = 0.035443 loss)
I0929 20:58:27.736871  2630 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0929 20:58:40.539077  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:58:41.075182  2630 solver.cpp:330] Iteration 43500, Testing net (#0)
I0929 20:58:44.169744  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:58:44.298017  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0929 20:58:44.298053  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.241984 (* 1 = 0.241984 loss)
I0929 20:58:44.432526  2630 solver.cpp:218] Iteration 43500 (5.9896 iter/s, 16.6956s/100 iters), loss = 0.0198358
I0929 20:58:44.432557  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198359 (* 1 = 0.0198359 loss)
I0929 20:58:44.432564  2630 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0929 20:58:57.894317  2630 solver.cpp:218] Iteration 43600 (7.42847 iter/s, 13.4617s/100 iters), loss = 0.0272045
I0929 20:58:57.894348  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272046 (* 1 = 0.0272046 loss)
I0929 20:58:57.894356  2630 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0929 20:59:11.352421  2630 solver.cpp:218] Iteration 43700 (7.43051 iter/s, 13.458s/100 iters), loss = 0.0394472
I0929 20:59:11.352517  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394472 (* 1 = 0.0394472 loss)
I0929 20:59:11.352533  2630 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0929 20:59:24.824605  2630 solver.cpp:218] Iteration 43800 (7.42278 iter/s, 13.472s/100 iters), loss = 0.016997
I0929 20:59:24.824645  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016997 (* 1 = 0.016997 loss)
I0929 20:59:24.824652  2630 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0929 20:59:38.287782  2630 solver.cpp:218] Iteration 43900 (7.42771 iter/s, 13.4631s/100 iters), loss = 0.0293367
I0929 20:59:38.287822  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293368 (* 1 = 0.0293368 loss)
I0929 20:59:38.287829  2630 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0929 20:59:51.095522  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:59:51.635133  2630 solver.cpp:330] Iteration 44000, Testing net (#0)
I0929 20:59:54.728557  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:59:54.857260  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I0929 20:59:54.857297  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.253972 (* 1 = 0.253972 loss)
I0929 20:59:54.991382  2630 solver.cpp:218] Iteration 44000 (5.98677 iter/s, 16.7035s/100 iters), loss = 0.0217939
I0929 20:59:54.991415  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021794 (* 1 = 0.021794 loss)
I0929 20:59:54.991421  2630 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0929 21:00:08.459363  2630 solver.cpp:218] Iteration 44100 (7.42506 iter/s, 13.4679s/100 iters), loss = 0.0262253
I0929 21:00:08.459394  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262254 (* 1 = 0.0262254 loss)
I0929 21:00:08.459401  2630 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0929 21:00:21.927042  2630 solver.cpp:218] Iteration 44200 (7.42522 iter/s, 13.4676s/100 iters), loss = 0.0550878
I0929 21:00:21.927157  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550879 (* 1 = 0.0550879 loss)
I0929 21:00:21.927166  2630 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0929 21:00:35.390367  2630 solver.cpp:218] Iteration 44300 (7.42766 iter/s, 13.4632s/100 iters), loss = 0.0106758
I0929 21:00:35.390395  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106759 (* 1 = 0.0106759 loss)
I0929 21:00:35.390403  2630 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0929 21:00:48.867362  2630 solver.cpp:218] Iteration 44400 (7.42009 iter/s, 13.4769s/100 iters), loss = 0.0411157
I0929 21:00:48.867403  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411157 (* 1 = 0.0411157 loss)
I0929 21:00:48.867408  2630 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0929 21:01:01.667984  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:01:02.203708  2630 solver.cpp:330] Iteration 44500, Testing net (#0)
I0929 21:01:05.291950  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:01:05.420562  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I0929 21:01:05.420598  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.254852 (* 1 = 0.254852 loss)
I0929 21:01:05.554180  2630 solver.cpp:218] Iteration 44500 (5.99279 iter/s, 16.6867s/100 iters), loss = 0.0253181
I0929 21:01:05.554211  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253182 (* 1 = 0.0253182 loss)
I0929 21:01:05.554219  2630 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0929 21:01:19.024130  2630 solver.cpp:218] Iteration 44600 (7.42397 iter/s, 13.4699s/100 iters), loss = 0.0224341
I0929 21:01:19.024161  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224342 (* 1 = 0.0224342 loss)
I0929 21:01:19.024168  2630 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0929 21:01:32.487581  2630 solver.cpp:218] Iteration 44700 (7.42756 iter/s, 13.4634s/100 iters), loss = 0.046712
I0929 21:01:32.487679  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046712 (* 1 = 0.046712 loss)
I0929 21:01:32.487686  2630 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0929 21:01:45.954649  2630 solver.cpp:218] Iteration 44800 (7.4256 iter/s, 13.4669s/100 iters), loss = 0.042963
I0929 21:01:45.954692  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429631 (* 1 = 0.0429631 loss)
I0929 21:01:45.954699  2630 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0929 21:01:59.413393  2630 solver.cpp:218] Iteration 44900 (7.43016 iter/s, 13.4587s/100 iters), loss = 0.00773118
I0929 21:01:59.413422  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00773126 (* 1 = 0.00773126 loss)
I0929 21:01:59.413429  2630 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0929 21:02:12.221499  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:02:12.758685  2630 solver.cpp:330] Iteration 45000, Testing net (#0)
I0929 21:02:15.850173  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:02:15.979105  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0929 21:02:15.979141  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.253946 (* 1 = 0.253946 loss)
I0929 21:02:16.113279  2630 solver.cpp:218] Iteration 45000 (5.98809 iter/s, 16.6998s/100 iters), loss = 0.0188136
I0929 21:02:16.113310  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188137 (* 1 = 0.0188137 loss)
I0929 21:02:16.113317  2630 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0929 21:02:29.569337  2630 solver.cpp:218] Iteration 45100 (7.43164 iter/s, 13.456s/100 iters), loss = 0.0198757
I0929 21:02:29.569366  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198758 (* 1 = 0.0198758 loss)
I0929 21:02:29.569372  2630 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0929 21:02:43.029749  2630 solver.cpp:218] Iteration 45200 (7.42923 iter/s, 13.4603s/100 iters), loss = 0.0414706
I0929 21:02:43.029896  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414707 (* 1 = 0.0414707 loss)
I0929 21:02:43.029906  2630 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0929 21:02:56.483875  2630 solver.cpp:218] Iteration 45300 (7.43277 iter/s, 13.4539s/100 iters), loss = 0.0123579
I0929 21:02:56.483906  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012358 (* 1 = 0.012358 loss)
I0929 21:02:56.483912  2630 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0929 21:03:09.964905  2630 solver.cpp:218] Iteration 45400 (7.41787 iter/s, 13.481s/100 iters), loss = 0.0222129
I0929 21:03:09.964937  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022213 (* 1 = 0.022213 loss)
I0929 21:03:09.964944  2630 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0929 21:03:22.756203  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:03:23.294153  2630 solver.cpp:330] Iteration 45500, Testing net (#0)
I0929 21:03:26.386296  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:03:26.515307  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0929 21:03:26.515333  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.252973 (* 1 = 0.252973 loss)
I0929 21:03:26.648164  2630 solver.cpp:218] Iteration 45500 (5.99406 iter/s, 16.6832s/100 iters), loss = 0.0208732
I0929 21:03:26.648195  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208733 (* 1 = 0.0208733 loss)
I0929 21:03:26.648201  2630 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0929 21:03:40.111865  2630 solver.cpp:218] Iteration 45600 (7.42742 iter/s, 13.4636s/100 iters), loss = 0.0453698
I0929 21:03:40.111897  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453699 (* 1 = 0.0453699 loss)
I0929 21:03:40.111907  2630 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0929 21:03:53.572216  2630 solver.cpp:218] Iteration 45700 (7.42927 iter/s, 13.4603s/100 iters), loss = 0.0308117
I0929 21:03:53.572324  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308118 (* 1 = 0.0308118 loss)
I0929 21:03:53.572332  2630 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0929 21:04:07.042583  2630 solver.cpp:218] Iteration 45800 (7.42379 iter/s, 13.4702s/100 iters), loss = 0.0415694
I0929 21:04:07.042628  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0415695 (* 1 = 0.0415695 loss)
I0929 21:04:07.042635  2630 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0929 21:04:20.494662  2630 solver.cpp:218] Iteration 45900 (7.43384 iter/s, 13.452s/100 iters), loss = 0.01133
I0929 21:04:20.494693  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01133 (* 1 = 0.01133 loss)
I0929 21:04:20.494702  2630 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0929 21:04:33.301250  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:04:33.839267  2630 solver.cpp:330] Iteration 46000, Testing net (#0)
I0929 21:04:36.935317  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:04:37.066211  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0929 21:04:37.066247  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.252691 (* 1 = 0.252691 loss)
I0929 21:04:37.199944  2630 solver.cpp:218] Iteration 46000 (5.98616 iter/s, 16.7052s/100 iters), loss = 0.0100358
I0929 21:04:37.199987  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100358 (* 1 = 0.0100358 loss)
I0929 21:04:37.199996  2630 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0929 21:04:50.656654  2630 solver.cpp:218] Iteration 46100 (7.43128 iter/s, 13.4566s/100 iters), loss = 0.0868634
I0929 21:04:50.656684  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0868634 (* 1 = 0.0868634 loss)
I0929 21:04:50.656690  2630 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0929 21:05:04.128762  2630 solver.cpp:218] Iteration 46200 (7.42278 iter/s, 13.472s/100 iters), loss = 0.0463363
I0929 21:05:04.128903  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463363 (* 1 = 0.0463363 loss)
I0929 21:05:04.128911  2630 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0929 21:05:17.584868  2630 solver.cpp:218] Iteration 46300 (7.43167 iter/s, 13.4559s/100 iters), loss = 0.0339523
I0929 21:05:17.584898  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339524 (* 1 = 0.0339524 loss)
I0929 21:05:17.584904  2630 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0929 21:05:31.059674  2630 solver.cpp:218] Iteration 46400 (7.4213 iter/s, 13.4747s/100 iters), loss = 0.0255212
I0929 21:05:31.059705  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255213 (* 1 = 0.0255213 loss)
I0929 21:05:31.059711  2630 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0929 21:05:43.851258  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:05:44.388228  2630 solver.cpp:330] Iteration 46500, Testing net (#0)
I0929 21:05:47.481329  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:05:47.610160  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0929 21:05:47.610185  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.272886 (* 1 = 0.272886 loss)
I0929 21:05:47.743921  2630 solver.cpp:218] Iteration 46500 (5.99371 iter/s, 16.6842s/100 iters), loss = 0.0133351
I0929 21:05:47.743955  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133351 (* 1 = 0.0133351 loss)
I0929 21:05:47.743963  2630 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0929 21:06:01.205564  2630 solver.cpp:218] Iteration 46600 (7.42856 iter/s, 13.4616s/100 iters), loss = 0.0104131
I0929 21:06:01.205600  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104131 (* 1 = 0.0104131 loss)
I0929 21:06:01.205608  2630 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0929 21:06:14.674871  2630 solver.cpp:218] Iteration 46700 (7.42433 iter/s, 13.4692s/100 iters), loss = 0.0387658
I0929 21:06:14.675004  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387658 (* 1 = 0.0387658 loss)
I0929 21:06:14.675011  2630 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0929 21:06:28.156807  2630 solver.cpp:218] Iteration 46800 (7.41742 iter/s, 13.4818s/100 iters), loss = 0.0220532
I0929 21:06:28.156838  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220532 (* 1 = 0.0220532 loss)
I0929 21:06:28.156844  2630 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0929 21:06:41.621922  2630 solver.cpp:218] Iteration 46900 (7.42664 iter/s, 13.465s/100 iters), loss = 0.0299775
I0929 21:06:41.621963  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299775 (* 1 = 0.0299775 loss)
I0929 21:06:41.621969  2630 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0929 21:06:54.424465  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:06:54.961913  2630 solver.cpp:330] Iteration 47000, Testing net (#0)
I0929 21:06:58.056651  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:06:58.185562  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I0929 21:06:58.185598  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292251 (* 1 = 0.292251 loss)
I0929 21:06:58.319501  2630 solver.cpp:218] Iteration 47000 (5.98892 iter/s, 16.6975s/100 iters), loss = 0.0124676
I0929 21:06:58.319530  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124677 (* 1 = 0.0124677 loss)
I0929 21:06:58.319537  2630 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0929 21:07:11.773782  2630 solver.cpp:218] Iteration 47100 (7.43262 iter/s, 13.4542s/100 iters), loss = 0.0239447
I0929 21:07:11.773810  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239447 (* 1 = 0.0239447 loss)
I0929 21:07:11.773815  2630 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0929 21:07:25.240821  2630 solver.cpp:218] Iteration 47200 (7.42558 iter/s, 13.467s/100 iters), loss = 0.0306491
I0929 21:07:25.240947  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306491 (* 1 = 0.0306491 loss)
I0929 21:07:25.240965  2630 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0929 21:07:38.694366  2630 solver.cpp:218] Iteration 47300 (7.43307 iter/s, 13.4534s/100 iters), loss = 0.00634405
I0929 21:07:38.694396  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063441 (* 1 = 0.0063441 loss)
I0929 21:07:38.694402  2630 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0929 21:07:52.165877  2630 solver.cpp:218] Iteration 47400 (7.42311 iter/s, 13.4714s/100 iters), loss = 0.0043682
I0929 21:07:52.165908  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436825 (* 1 = 0.00436825 loss)
I0929 21:07:52.165915  2630 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0929 21:08:04.958403  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:08:05.496096  2630 solver.cpp:330] Iteration 47500, Testing net (#0)
I0929 21:08:08.593262  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:08:08.722335  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0929 21:08:08.722370  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269355 (* 1 = 0.269355 loss)
I0929 21:08:08.855645  2630 solver.cpp:218] Iteration 47500 (5.99172 iter/s, 16.6897s/100 iters), loss = 0.00988171
I0929 21:08:08.855679  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00988176 (* 1 = 0.00988176 loss)
I0929 21:08:08.855685  2630 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0929 21:08:22.310590  2630 solver.cpp:218] Iteration 47600 (7.43225 iter/s, 13.4549s/100 iters), loss = 0.0136105
I0929 21:08:22.310629  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136105 (* 1 = 0.0136105 loss)
I0929 21:08:22.310636  2630 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0929 21:08:35.772972  2630 solver.cpp:218] Iteration 47700 (7.42815 iter/s, 13.4623s/100 iters), loss = 0.0240262
I0929 21:08:35.773123  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240262 (* 1 = 0.0240262 loss)
I0929 21:08:35.773130  2630 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0929 21:08:49.244102  2630 solver.cpp:218] Iteration 47800 (7.42339 iter/s, 13.4709s/100 iters), loss = 0.0156705
I0929 21:08:49.244132  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156705 (* 1 = 0.0156705 loss)
I0929 21:08:49.244138  2630 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0929 21:09:02.706981  2630 solver.cpp:218] Iteration 47900 (7.42787 iter/s, 13.4628s/100 iters), loss = 0.00718162
I0929 21:09:02.707011  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00718165 (* 1 = 0.00718165 loss)
I0929 21:09:02.707017  2630 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0929 21:09:15.507164  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:09:16.045049  2630 solver.cpp:330] Iteration 48000, Testing net (#0)
I0929 21:09:19.140297  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:09:19.269078  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I0929 21:09:19.269114  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281956 (* 1 = 0.281956 loss)
I0929 21:09:19.403597  2630 solver.cpp:218] Iteration 48000 (5.98927 iter/s, 16.6965s/100 iters), loss = 0.00571295
I0929 21:09:19.403630  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571298 (* 1 = 0.00571298 loss)
I0929 21:09:19.403637  2630 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0929 21:09:32.864079  2630 solver.cpp:218] Iteration 48100 (7.4292 iter/s, 13.4604s/100 iters), loss = 0.018013
I0929 21:09:32.864110  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018013 (* 1 = 0.018013 loss)
I0929 21:09:32.864116  2630 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0929 21:09:46.332608  2630 solver.cpp:218] Iteration 48200 (7.42475 iter/s, 13.4685s/100 iters), loss = 0.0419695
I0929 21:09:46.332749  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419695 (* 1 = 0.0419695 loss)
I0929 21:09:46.332758  2630 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0929 21:09:59.787649  2630 solver.cpp:218] Iteration 48300 (7.43226 iter/s, 13.4549s/100 iters), loss = 0.0299682
I0929 21:09:59.787699  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299682 (* 1 = 0.0299682 loss)
I0929 21:09:59.787705  2630 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0929 21:10:13.259394  2630 solver.cpp:218] Iteration 48400 (7.42299 iter/s, 13.4717s/100 iters), loss = 0.00536781
I0929 21:10:13.259428  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536782 (* 1 = 0.00536782 loss)
I0929 21:10:13.259436  2630 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0929 21:10:26.048329  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:10:26.586829  2630 solver.cpp:330] Iteration 48500, Testing net (#0)
I0929 21:10:29.682664  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:10:29.811010  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I0929 21:10:29.811036  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28212 (* 1 = 0.28212 loss)
I0929 21:10:29.945497  2630 solver.cpp:218] Iteration 48500 (5.99304 iter/s, 16.686s/100 iters), loss = 0.0316267
I0929 21:10:29.945535  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316268 (* 1 = 0.0316268 loss)
I0929 21:10:29.945545  2630 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0929 21:10:43.407816  2630 solver.cpp:218] Iteration 48600 (7.42818 iter/s, 13.4622s/100 iters), loss = 0.0156923
I0929 21:10:43.407850  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156923 (* 1 = 0.0156923 loss)
I0929 21:10:43.407869  2630 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0929 21:10:56.865192  2630 solver.cpp:218] Iteration 48700 (7.43091 iter/s, 13.4573s/100 iters), loss = 0.00951631
I0929 21:10:56.865300  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951634 (* 1 = 0.00951634 loss)
I0929 21:10:56.865310  2630 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0929 21:11:10.343472  2630 solver.cpp:218] Iteration 48800 (7.41942 iter/s, 13.4781s/100 iters), loss = 0.0124281
I0929 21:11:10.343505  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124282 (* 1 = 0.0124282 loss)
I0929 21:11:10.343523  2630 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0929 21:11:23.813634  2630 solver.cpp:218] Iteration 48900 (7.42386 iter/s, 13.4701s/100 iters), loss = 0.026045
I0929 21:11:23.813668  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260451 (* 1 = 0.0260451 loss)
I0929 21:11:23.813678  2630 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0929 21:11:36.609668  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:11:37.147382  2630 solver.cpp:330] Iteration 49000, Testing net (#0)
I0929 21:11:40.240335  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:11:40.368894  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0929 21:11:40.368921  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278521 (* 1 = 0.278521 loss)
I0929 21:11:40.503268  2630 solver.cpp:218] Iteration 49000 (5.99177 iter/s, 16.6896s/100 iters), loss = 0.00894622
I0929 21:11:40.503301  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00894626 (* 1 = 0.00894626 loss)
I0929 21:11:40.503311  2630 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0929 21:11:53.969797  2630 solver.cpp:218] Iteration 49100 (7.42586 iter/s, 13.4664s/100 iters), loss = 0.00970124
I0929 21:11:53.969861  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00970127 (* 1 = 0.00970127 loss)
I0929 21:11:53.969871  2630 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0929 21:12:07.445447  2630 solver.cpp:218] Iteration 49200 (7.42086 iter/s, 13.4755s/100 iters), loss = 0.00895057
I0929 21:12:07.445547  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895061 (* 1 = 0.00895061 loss)
I0929 21:12:07.445555  2630 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0929 21:12:20.905930  2630 solver.cpp:218] Iteration 49300 (7.42923 iter/s, 13.4603s/100 iters), loss = 0.0032292
I0929 21:12:20.905961  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322924 (* 1 = 0.00322924 loss)
I0929 21:12:20.905966  2630 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0929 21:12:34.383152  2630 solver.cpp:218] Iteration 49400 (7.41997 iter/s, 13.4771s/100 iters), loss = 0.0266082
I0929 21:12:34.383193  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266083 (* 1 = 0.0266083 loss)
I0929 21:12:34.383199  2630 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0929 21:12:47.184470  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:12:47.721321  2630 solver.cpp:330] Iteration 49500, Testing net (#0)
I0929 21:12:50.816866  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:12:50.946188  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0929 21:12:50.946225  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279561 (* 1 = 0.279561 loss)
I0929 21:12:51.084256  2630 solver.cpp:218] Iteration 49500 (5.98766 iter/s, 16.701s/100 iters), loss = 0.0111502
I0929 21:12:51.084306  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111503 (* 1 = 0.0111503 loss)
I0929 21:12:51.084314  2630 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0929 21:13:04.541987  2630 solver.cpp:218] Iteration 49600 (7.43074 iter/s, 13.4576s/100 iters), loss = 0.0458852
I0929 21:13:04.542019  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0458852 (* 1 = 0.0458852 loss)
I0929 21:13:04.542026  2630 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0929 21:13:18.002228  2630 solver.cpp:218] Iteration 49700 (7.42934 iter/s, 13.4602s/100 iters), loss = 0.0128775
I0929 21:13:18.002346  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128775 (* 1 = 0.0128775 loss)
I0929 21:13:18.002365  2630 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0929 21:13:31.472898  2630 solver.cpp:218] Iteration 49800 (7.42363 iter/s, 13.4705s/100 iters), loss = 0.00736661
I0929 21:13:31.472928  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00736665 (* 1 = 0.00736665 loss)
I0929 21:13:31.472934  2630 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0929 21:13:44.944429  2630 solver.cpp:218] Iteration 49900 (7.4231 iter/s, 13.4715s/100 iters), loss = 0.0020531
I0929 21:13:44.944464  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205314 (* 1 = 0.00205314 loss)
I0929 21:13:44.944481  2630 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0929 21:13:57.746667  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:13:58.286034  2630 solver.cpp:330] Iteration 50000, Testing net (#0)
I0929 21:14:01.377173  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:14:01.506788  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0929 21:14:01.506824  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280231 (* 1 = 0.280231 loss)
I0929 21:14:01.640437  2630 solver.cpp:218] Iteration 50000 (5.9895 iter/s, 16.6959s/100 iters), loss = 0.00877618
I0929 21:14:01.640467  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877621 (* 1 = 0.00877621 loss)
I0929 21:14:01.640473  2630 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0929 21:14:15.116513  2630 solver.cpp:218] Iteration 50100 (7.4206 iter/s, 13.476s/100 iters), loss = 0.014874
I0929 21:14:15.116552  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014874 (* 1 = 0.014874 loss)
I0929 21:14:15.116560  2630 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0929 21:14:28.589939  2630 solver.cpp:218] Iteration 50200 (7.42206 iter/s, 13.4733s/100 iters), loss = 0.0126221
I0929 21:14:28.590076  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126221 (* 1 = 0.0126221 loss)
I0929 21:14:28.590085  2630 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0929 21:14:42.058845  2630 solver.cpp:218] Iteration 50300 (7.42461 iter/s, 13.4687s/100 iters), loss = 0.0127883
I0929 21:14:42.058892  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127883 (* 1 = 0.0127883 loss)
I0929 21:14:42.058908  2630 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0929 21:14:55.519158  2630 solver.cpp:218] Iteration 50400 (7.42932 iter/s, 13.4602s/100 iters), loss = 0.00507
I0929 21:14:55.519188  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507003 (* 1 = 0.00507003 loss)
I0929 21:14:55.519194  2630 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0929 21:15:08.327833  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:15:08.864820  2630 solver.cpp:330] Iteration 50500, Testing net (#0)
I0929 21:15:11.961907  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:15:12.095579  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0929 21:15:12.095609  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278362 (* 1 = 0.278362 loss)
I0929 21:15:12.233032  2630 solver.cpp:218] Iteration 50500 (5.98308 iter/s, 16.7138s/100 iters), loss = 0.0095175
I0929 21:15:12.233067  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951753 (* 1 = 0.00951753 loss)
I0929 21:15:12.233075  2630 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0929 21:15:25.691344  2630 solver.cpp:218] Iteration 50600 (7.4304 iter/s, 13.4582s/100 iters), loss = 0.00552176
I0929 21:15:25.691373  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552178 (* 1 = 0.00552178 loss)
I0929 21:15:25.691380  2630 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0929 21:15:39.166330  2630 solver.cpp:218] Iteration 50700 (7.4212 iter/s, 13.4749s/100 iters), loss = 0.00586876
I0929 21:15:39.166431  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00586879 (* 1 = 0.00586879 loss)
I0929 21:15:39.166443  2630 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0929 21:15:52.644810  2630 solver.cpp:218] Iteration 50800 (7.41932 iter/s, 13.4783s/100 iters), loss = 0.00556225
I0929 21:15:52.644845  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556227 (* 1 = 0.00556227 loss)
I0929 21:15:52.644851  2630 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0929 21:16:06.127182  2630 solver.cpp:218] Iteration 50900 (7.41714 iter/s, 13.4823s/100 iters), loss = 0.00803148
I0929 21:16:06.127219  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00803149 (* 1 = 0.00803149 loss)
I0929 21:16:06.127226  2630 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0929 21:16:18.930614  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:16:19.468166  2630 solver.cpp:330] Iteration 51000, Testing net (#0)
I0929 21:16:22.558570  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:16:22.687584  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0929 21:16:22.687620  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292183 (* 1 = 0.292183 loss)
I0929 21:16:22.821869  2630 solver.cpp:218] Iteration 51000 (5.98996 iter/s, 16.6946s/100 iters), loss = 0.0022371
I0929 21:16:22.821903  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223711 (* 1 = 0.00223711 loss)
I0929 21:16:22.821910  2630 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0929 21:16:36.285203  2630 solver.cpp:218] Iteration 51100 (7.42762 iter/s, 13.4633s/100 iters), loss = 0.0663604
I0929 21:16:36.285238  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0663604 (* 1 = 0.0663604 loss)
I0929 21:16:36.285245  2630 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0929 21:16:49.752135  2630 solver.cpp:218] Iteration 51200 (7.42564 iter/s, 13.4669s/100 iters), loss = 0.00605999
I0929 21:16:49.752260  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00606 (* 1 = 0.00606 loss)
I0929 21:16:49.752267  2630 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0929 21:17:03.219223  2630 solver.cpp:218] Iteration 51300 (7.4256 iter/s, 13.4669s/100 iters), loss = 0.0159488
I0929 21:17:03.219259  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159488 (* 1 = 0.0159488 loss)
I0929 21:17:03.219267  2630 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0929 21:17:16.668318  2630 solver.cpp:218] Iteration 51400 (7.43549 iter/s, 13.449s/100 iters), loss = 0.00934465
I0929 21:17:16.668347  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00934467 (* 1 = 0.00934467 loss)
I0929 21:17:16.668354  2630 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0929 21:17:29.463762  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:17:30.003640  2630 solver.cpp:330] Iteration 51500, Testing net (#0)
I0929 21:17:33.102216  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:17:33.240394  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0929 21:17:33.240422  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291794 (* 1 = 0.291794 loss)
I0929 21:17:33.373930  2630 solver.cpp:218] Iteration 51500 (5.98604 iter/s, 16.7055s/100 iters), loss = 0.0022925
I0929 21:17:33.373966  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229253 (* 1 = 0.00229253 loss)
I0929 21:17:33.373975  2630 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0929 21:17:46.842150  2630 solver.cpp:218] Iteration 51600 (7.42493 iter/s, 13.4681s/100 iters), loss = 0.00979437
I0929 21:17:46.842181  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00979439 (* 1 = 0.00979439 loss)
I0929 21:17:46.842187  2630 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0929 21:18:00.315762  2630 solver.cpp:218] Iteration 51700 (7.42195 iter/s, 13.4735s/100 iters), loss = 0.00831435
I0929 21:18:00.315873  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831436 (* 1 = 0.00831436 loss)
I0929 21:18:00.315882  2630 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0929 21:18:13.791762  2630 solver.cpp:218] Iteration 51800 (7.42068 iter/s, 13.4759s/100 iters), loss = 0.0363157
I0929 21:18:13.791793  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363157 (* 1 = 0.0363157 loss)
I0929 21:18:13.791800  2630 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0929 21:18:27.267360  2630 solver.cpp:218] Iteration 51900 (7.42086 iter/s, 13.4755s/100 iters), loss = 0.0357967
I0929 21:18:27.267405  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357967 (* 1 = 0.0357967 loss)
I0929 21:18:27.267413  2630 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0929 21:18:40.061918  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:18:40.599119  2630 solver.cpp:330] Iteration 52000, Testing net (#0)
I0929 21:18:43.691953  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:18:43.820672  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0929 21:18:43.820708  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283896 (* 1 = 0.283896 loss)
I0929 21:18:43.954825  2630 solver.cpp:218] Iteration 52000 (5.99256 iter/s, 16.6874s/100 iters), loss = 0.00477662
I0929 21:18:43.954855  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477661 (* 1 = 0.00477661 loss)
I0929 21:18:43.954862  2630 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0929 21:18:57.420651  2630 solver.cpp:218] Iteration 52100 (7.42625 iter/s, 13.4658s/100 iters), loss = 0.00554768
I0929 21:18:57.420688  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554768 (* 1 = 0.00554768 loss)
I0929 21:18:57.420696  2630 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0929 21:19:10.893594  2630 solver.cpp:218] Iteration 52200 (7.42233 iter/s, 13.4729s/100 iters), loss = 0.0782131
I0929 21:19:10.893736  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0782131 (* 1 = 0.0782131 loss)
I0929 21:19:10.893745  2630 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0929 21:19:24.359035  2630 solver.cpp:218] Iteration 52300 (7.42651 iter/s, 13.4653s/100 iters), loss = 0.0602492
I0929 21:19:24.359078  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602492 (* 1 = 0.0602492 loss)
I0929 21:19:24.359086  2630 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0929 21:19:37.815526  2630 solver.cpp:218] Iteration 52400 (7.43141 iter/s, 13.4564s/100 iters), loss = 0.00373595
I0929 21:19:37.815567  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373594 (* 1 = 0.00373594 loss)
I0929 21:19:37.815573  2630 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0929 21:19:50.615702  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:19:51.158872  2630 solver.cpp:330] Iteration 52500, Testing net (#0)
I0929 21:19:54.257525  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:19:54.386890  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0929 21:19:54.386917  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290162 (* 1 = 0.290162 loss)
I0929 21:19:54.520532  2630 solver.cpp:218] Iteration 52500 (5.98626 iter/s, 16.7049s/100 iters), loss = 0.0253005
I0929 21:19:54.520565  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253005 (* 1 = 0.0253005 loss)
I0929 21:19:54.520572  2630 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0929 21:20:07.986239  2630 solver.cpp:218] Iteration 52600 (7.42631 iter/s, 13.4656s/100 iters), loss = 0.0134066
I0929 21:20:07.986270  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134066 (* 1 = 0.0134066 loss)
I0929 21:20:07.986276  2630 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0929 21:20:21.459834  2630 solver.cpp:218] Iteration 52700 (7.42197 iter/s, 13.4735s/100 iters), loss = 0.00959508
I0929 21:20:21.459995  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00959504 (* 1 = 0.00959504 loss)
I0929 21:20:21.460014  2630 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0929 21:20:34.925420  2630 solver.cpp:218] Iteration 52800 (7.42645 iter/s, 13.4654s/100 iters), loss = 0.00289292
I0929 21:20:34.925452  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289289 (* 1 = 0.00289289 loss)
I0929 21:20:34.925459  2630 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0929 21:20:48.402107  2630 solver.cpp:218] Iteration 52900 (7.42026 iter/s, 13.4766s/100 iters), loss = 0.00652223
I0929 21:20:48.402138  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0065222 (* 1 = 0.0065222 loss)
I0929 21:20:48.402146  2630 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0929 21:21:01.200361  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:21:01.737680  2630 solver.cpp:330] Iteration 53000, Testing net (#0)
I0929 21:21:04.828174  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:21:04.956436  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I0929 21:21:04.956472  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298982 (* 1 = 0.298982 loss)
I0929 21:21:05.090214  2630 solver.cpp:218] Iteration 53000 (5.99232 iter/s, 16.688s/100 iters), loss = 0.00349339
I0929 21:21:05.090245  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349336 (* 1 = 0.00349336 loss)
I0929 21:21:05.090252  2630 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0929 21:21:18.551798  2630 solver.cpp:218] Iteration 53100 (7.42859 iter/s, 13.4615s/100 iters), loss = 0.00831597
I0929 21:21:18.551833  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831594 (* 1 = 0.00831594 loss)
I0929 21:21:18.551841  2630 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0929 21:21:32.013573  2630 solver.cpp:218] Iteration 53200 (7.42848 iter/s, 13.4617s/100 iters), loss = 0.00945979
I0929 21:21:32.013733  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00945976 (* 1 = 0.00945976 loss)
I0929 21:21:32.013752  2630 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0929 21:21:45.482966  2630 solver.cpp:218] Iteration 53300 (7.42435 iter/s, 13.4692s/100 iters), loss = 0.00400798
I0929 21:21:45.483000  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400796 (* 1 = 0.00400796 loss)
I0929 21:21:45.483007  2630 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0929 21:21:58.944190  2630 solver.cpp:218] Iteration 53400 (7.42879 iter/s, 13.4611s/100 iters), loss = 0.00309203
I0929 21:21:58.944221  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309201 (* 1 = 0.00309201 loss)
I0929 21:21:58.944236  2630 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0929 21:22:11.737042  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:22:12.284844  2630 solver.cpp:330] Iteration 53500, Testing net (#0)
I0929 21:22:15.377142  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:22:15.506201  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0929 21:22:15.506237  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29194 (* 1 = 0.29194 loss)
I0929 21:22:15.640378  2630 solver.cpp:218] Iteration 53500 (5.98942 iter/s, 16.6961s/100 iters), loss = 0.00297915
I0929 21:22:15.640413  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297912 (* 1 = 0.00297912 loss)
I0929 21:22:15.640419  2630 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0929 21:22:29.099068  2630 solver.cpp:218] Iteration 53600 (7.43019 iter/s, 13.4586s/100 iters), loss = 0.00431544
I0929 21:22:29.099098  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431542 (* 1 = 0.00431542 loss)
I0929 21:22:29.099104  2630 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0929 21:22:42.560955  2630 solver.cpp:218] Iteration 53700 (7.42842 iter/s, 13.4618s/100 iters), loss = 0.0365722
I0929 21:22:42.561055  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365722 (* 1 = 0.0365722 loss)
I0929 21:22:42.561064  2630 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0929 21:22:56.016940  2630 solver.cpp:218] Iteration 53800 (7.43172 iter/s, 13.4558s/100 iters), loss = 0.0415224
I0929 21:22:56.016971  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0415224 (* 1 = 0.0415224 loss)
I0929 21:22:56.016978  2630 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0929 21:23:09.487222  2630 solver.cpp:218] Iteration 53900 (7.42379 iter/s, 13.4702s/100 iters), loss = 0.0081809
I0929 21:23:09.487265  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00818087 (* 1 = 0.00818087 loss)
I0929 21:23:09.487272  2630 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0929 21:23:22.278182  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:23:22.815426  2630 solver.cpp:330] Iteration 54000, Testing net (#0)
I0929 21:23:25.908867  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:23:26.037220  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I0929 21:23:26.037245  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287698 (* 1 = 0.287698 loss)
I0929 21:23:26.171049  2630 solver.cpp:218] Iteration 54000 (5.99386 iter/s, 16.6837s/100 iters), loss = 0.0036172
I0929 21:23:26.171079  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361717 (* 1 = 0.00361717 loss)
I0929 21:23:26.171087  2630 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0929 21:23:39.636898  2630 solver.cpp:218] Iteration 54100 (7.42623 iter/s, 13.4658s/100 iters), loss = 0.0125111
I0929 21:23:39.636932  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125111 (* 1 = 0.0125111 loss)
I0929 21:23:39.636940  2630 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0929 21:23:53.099220  2630 solver.cpp:218] Iteration 54200 (7.42818 iter/s, 13.4622s/100 iters), loss = 0.0144998
I0929 21:23:53.099385  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144998 (* 1 = 0.0144998 loss)
I0929 21:23:53.099396  2630 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0929 21:24:06.575013  2630 solver.cpp:218] Iteration 54300 (7.42083 iter/s, 13.4756s/100 iters), loss = 0.0127862
I0929 21:24:06.575047  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127861 (* 1 = 0.0127861 loss)
I0929 21:24:06.575053  2630 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0929 21:24:20.041332  2630 solver.cpp:218] Iteration 54400 (7.42597 iter/s, 13.4662s/100 iters), loss = 0.00433956
I0929 21:24:20.041363  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433953 (* 1 = 0.00433953 loss)
I0929 21:24:20.041369  2630 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0929 21:24:32.834487  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:24:33.382259  2630 solver.cpp:330] Iteration 54500, Testing net (#0)
I0929 21:24:36.480374  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:24:36.609161  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I0929 21:24:36.609199  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303219 (* 1 = 0.303219 loss)
I0929 21:24:36.744030  2630 solver.cpp:218] Iteration 54500 (5.98709 iter/s, 16.7026s/100 iters), loss = 0.00322235
I0929 21:24:36.744063  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322232 (* 1 = 0.00322232 loss)
I0929 21:24:36.744081  2630 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0929 21:24:50.211056  2630 solver.cpp:218] Iteration 54600 (7.42559 iter/s, 13.467s/100 iters), loss = 0.0190025
I0929 21:24:50.211086  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190025 (* 1 = 0.0190025 loss)
I0929 21:24:50.211091  2630 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0929 21:25:03.689658  2630 solver.cpp:218] Iteration 54700 (7.41921 iter/s, 13.4785s/100 iters), loss = 0.0345983
I0929 21:25:03.689787  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345982 (* 1 = 0.0345982 loss)
I0929 21:25:03.689805  2630 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0929 21:25:17.163202  2630 solver.cpp:218] Iteration 54800 (7.42205 iter/s, 13.4734s/100 iters), loss = 0.00207646
I0929 21:25:17.163233  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207642 (* 1 = 0.00207642 loss)
I0929 21:25:17.163249  2630 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0929 21:25:30.652546  2630 solver.cpp:218] Iteration 54900 (7.4133 iter/s, 13.4893s/100 iters), loss = 0.00168489
I0929 21:25:30.652580  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168485 (* 1 = 0.00168485 loss)
I0929 21:25:30.652596  2630 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0929 21:25:43.460515  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:25:43.999908  2630 solver.cpp:330] Iteration 55000, Testing net (#0)
I0929 21:25:47.091886  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:25:47.221002  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0929 21:25:47.221038  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296316 (* 1 = 0.296316 loss)
I0929 21:25:47.355430  2630 solver.cpp:218] Iteration 55000 (5.98702 iter/s, 16.7028s/100 iters), loss = 0.0060413
I0929 21:25:47.355465  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00604126 (* 1 = 0.00604126 loss)
I0929 21:25:47.355473  2630 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0929 21:26:00.821342  2630 solver.cpp:218] Iteration 55100 (7.4262 iter/s, 13.4658s/100 iters), loss = 0.00524321
I0929 21:26:00.821373  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524318 (* 1 = 0.00524318 loss)
I0929 21:26:00.821379  2630 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0929 21:26:14.291245  2630 solver.cpp:218] Iteration 55200 (7.424 iter/s, 13.4698s/100 iters), loss = 0.00354424
I0929 21:26:14.291415  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354419 (* 1 = 0.00354419 loss)
I0929 21:26:14.291424  2630 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0929 21:26:27.772179  2630 solver.cpp:218] Iteration 55300 (7.41799 iter/s, 13.4807s/100 iters), loss = 0.00249473
I0929 21:26:27.772212  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249468 (* 1 = 0.00249468 loss)
I0929 21:26:27.772217  2630 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0929 21:26:41.228863  2630 solver.cpp:218] Iteration 55400 (7.43129 iter/s, 13.4566s/100 iters), loss = 0.00638465
I0929 21:26:41.228902  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00638461 (* 1 = 0.00638461 loss)
I0929 21:26:41.228909  2630 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0929 21:26:54.015195  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:26:54.562568  2630 solver.cpp:330] Iteration 55500, Testing net (#0)
I0929 21:26:57.654947  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:26:57.783349  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0929 21:26:57.783385  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3011 (* 1 = 0.3011 loss)
I0929 21:26:57.916807  2630 solver.cpp:218] Iteration 55500 (5.99238 iter/s, 16.6879s/100 iters), loss = 0.00573293
I0929 21:26:57.916839  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573288 (* 1 = 0.00573288 loss)
I0929 21:26:57.916846  2630 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0929 21:27:11.381287  2630 solver.cpp:218] Iteration 55600 (7.42699 iter/s, 13.4644s/100 iters), loss = 0.00409616
I0929 21:27:11.381317  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409612 (* 1 = 0.00409612 loss)
I0929 21:27:11.381325  2630 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0929 21:27:24.856273  2630 solver.cpp:218] Iteration 55700 (7.4212 iter/s, 13.4749s/100 iters), loss = 0.00374334
I0929 21:27:24.856389  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037433 (* 1 = 0.0037433 loss)
I0929 21:27:24.856397  2630 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0929 21:27:38.311106  2630 solver.cpp:218] Iteration 55800 (7.43236 iter/s, 13.4547s/100 iters), loss = 0.000937626
I0929 21:27:38.311136  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000937584 (* 1 = 0.000937584 loss)
I0929 21:27:38.311143  2630 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0929 21:27:51.782310  2630 solver.cpp:218] Iteration 55900 (7.42328 iter/s, 13.4711s/100 iters), loss = 0.00266924
I0929 21:27:51.782341  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026692 (* 1 = 0.0026692 loss)
I0929 21:27:51.782346  2630 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0929 21:28:04.581790  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:28:05.118893  2630 solver.cpp:330] Iteration 56000, Testing net (#0)
I0929 21:28:08.211555  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:28:08.339982  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I0929 21:28:08.340018  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.275514 (* 1 = 0.275514 loss)
I0929 21:28:08.474131  2630 solver.cpp:218] Iteration 56000 (5.99099 iter/s, 16.6917s/100 iters), loss = 0.00315286
I0929 21:28:08.474167  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315282 (* 1 = 0.00315282 loss)
I0929 21:28:08.474174  2630 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0929 21:28:21.943421  2630 solver.cpp:218] Iteration 56100 (7.42434 iter/s, 13.4692s/100 iters), loss = 0.016871
I0929 21:28:21.943455  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016871 (* 1 = 0.016871 loss)
I0929 21:28:21.943462  2630 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0929 21:28:35.412847  2630 solver.cpp:218] Iteration 56200 (7.42426 iter/s, 13.4693s/100 iters), loss = 0.0055001
I0929 21:28:35.413004  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550006 (* 1 = 0.00550006 loss)
I0929 21:28:35.413012  2630 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0929 21:28:48.896636  2630 solver.cpp:218] Iteration 56300 (7.41642 iter/s, 13.4836s/100 iters), loss = 0.00409416
I0929 21:28:48.896667  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409412 (* 1 = 0.00409412 loss)
I0929 21:28:48.896673  2630 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0929 21:29:02.363162  2630 solver.cpp:218] Iteration 56400 (7.42586 iter/s, 13.4665s/100 iters), loss = 0.00848755
I0929 21:29:02.363193  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00848753 (* 1 = 0.00848753 loss)
I0929 21:29:02.363198  2630 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0929 21:29:15.175026  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:29:15.716024  2630 solver.cpp:330] Iteration 56500, Testing net (#0)
I0929 21:29:18.810470  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:29:18.939569  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I0929 21:29:18.939605  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286344 (* 1 = 0.286344 loss)
I0929 21:29:19.073676  2630 solver.cpp:218] Iteration 56500 (5.98428 iter/s, 16.7104s/100 iters), loss = 0.0047134
I0929 21:29:19.073706  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471337 (* 1 = 0.00471337 loss)
I0929 21:29:19.073714  2630 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0929 21:29:32.534449  2630 solver.cpp:218] Iteration 56600 (7.42904 iter/s, 13.4607s/100 iters), loss = 0.00840163
I0929 21:29:32.534482  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00840161 (* 1 = 0.00840161 loss)
I0929 21:29:32.534489  2630 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0929 21:29:46.004482  2630 solver.cpp:218] Iteration 56700 (7.42393 iter/s, 13.47s/100 iters), loss = 0.0166861
I0929 21:29:46.004595  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166861 (* 1 = 0.0166861 loss)
I0929 21:29:46.004601  2630 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0929 21:29:59.462666  2630 solver.cpp:218] Iteration 56800 (7.4305 iter/s, 13.458s/100 iters), loss = 0.00391995
I0929 21:29:59.462699  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391993 (* 1 = 0.00391993 loss)
I0929 21:29:59.462705  2630 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0929 21:30:12.934692  2630 solver.cpp:218] Iteration 56900 (7.42283 iter/s, 13.472s/100 iters), loss = 0.00749705
I0929 21:30:12.934732  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00749703 (* 1 = 0.00749703 loss)
I0929 21:30:12.934739  2630 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0929 21:30:25.746603  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:30:26.288188  2630 solver.cpp:330] Iteration 57000, Testing net (#0)
I0929 21:30:29.391861  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:30:29.519070  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0929 21:30:29.519106  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308111 (* 1 = 0.308111 loss)
I0929 21:30:29.651307  2630 solver.cpp:218] Iteration 57000 (5.9821 iter/s, 16.7165s/100 iters), loss = 0.00315004
I0929 21:30:29.651335  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315001 (* 1 = 0.00315001 loss)
I0929 21:30:29.651342  2630 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0929 21:30:43.190136  2630 solver.cpp:218] Iteration 57100 (7.3862 iter/s, 13.5388s/100 iters), loss = 0.00420997
I0929 21:30:43.190171  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420995 (* 1 = 0.00420995 loss)
I0929 21:30:43.190177  2630 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0929 21:30:56.689529  2630 solver.cpp:218] Iteration 57200 (7.40778 iter/s, 13.4993s/100 iters), loss = 0.0046091
I0929 21:30:56.689692  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460907 (* 1 = 0.00460907 loss)
I0929 21:30:56.689702  2630 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0929 21:31:10.167307  2630 solver.cpp:218] Iteration 57300 (7.41973 iter/s, 13.4776s/100 iters), loss = 0.0208186
I0929 21:31:10.167340  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208186 (* 1 = 0.0208186 loss)
I0929 21:31:10.167347  2630 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0929 21:31:23.631150  2630 solver.cpp:218] Iteration 57400 (7.42734 iter/s, 13.4638s/100 iters), loss = 0.0306898
I0929 21:31:23.631181  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306897 (* 1 = 0.0306897 loss)
I0929 21:31:23.631187  2630 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0929 21:31:36.564960  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:31:37.126143  2630 solver.cpp:330] Iteration 57500, Testing net (#0)
I0929 21:31:40.261200  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:31:40.391023  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0929 21:31:40.391047  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303873 (* 1 = 0.303873 loss)
I0929 21:31:40.524093  2630 solver.cpp:218] Iteration 57500 (5.91966 iter/s, 16.8929s/100 iters), loss = 0.015091
I0929 21:31:40.524122  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015091 (* 1 = 0.015091 loss)
I0929 21:31:40.524129  2630 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0929 21:31:54.026201  2630 solver.cpp:218] Iteration 57600 (7.40629 iter/s, 13.502s/100 iters), loss = 0.00342756
I0929 21:31:54.026232  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342754 (* 1 = 0.00342754 loss)
I0929 21:31:54.026238  2630 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0929 21:32:07.502066  2630 solver.cpp:218] Iteration 57700 (7.42071 iter/s, 13.4758s/100 iters), loss = 0.00144463
I0929 21:32:07.502215  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014446 (* 1 = 0.0014446 loss)
I0929 21:32:07.502238  2630 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0929 21:32:20.963001  2630 solver.cpp:218] Iteration 57800 (7.42901 iter/s, 13.4607s/100 iters), loss = 0.00515378
I0929 21:32:20.963050  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515376 (* 1 = 0.00515376 loss)
I0929 21:32:20.963057  2630 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0929 21:32:34.435729  2630 solver.cpp:218] Iteration 57900 (7.42245 iter/s, 13.4726s/100 iters), loss = 0.00402082
I0929 21:32:34.435757  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040208 (* 1 = 0.0040208 loss)
I0929 21:32:34.435765  2630 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0929 21:32:47.235935  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:32:47.773694  2630 solver.cpp:330] Iteration 58000, Testing net (#0)
I0929 21:32:50.869294  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:32:50.998222  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0929 21:32:50.998258  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297517 (* 1 = 0.297517 loss)
I0929 21:32:51.134941  2630 solver.cpp:218] Iteration 58000 (5.98834 iter/s, 16.6991s/100 iters), loss = 0.00211686
I0929 21:32:51.134980  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211684 (* 1 = 0.00211684 loss)
I0929 21:32:51.134989  2630 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0929 21:33:04.600556  2630 solver.cpp:218] Iteration 58100 (7.42637 iter/s, 13.4655s/100 iters), loss = 0.0200149
I0929 21:33:04.600585  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200148 (* 1 = 0.0200148 loss)
I0929 21:33:04.600591  2630 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0929 21:33:18.066354  2630 solver.cpp:218] Iteration 58200 (7.42626 iter/s, 13.4657s/100 iters), loss = 0.00562209
I0929 21:33:18.066565  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562207 (* 1 = 0.00562207 loss)
I0929 21:33:18.066576  2630 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0929 21:33:31.546350  2630 solver.cpp:218] Iteration 58300 (7.41855 iter/s, 13.4797s/100 iters), loss = 0.00179017
I0929 21:33:31.546380  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179014 (* 1 = 0.00179014 loss)
I0929 21:33:31.546396  2630 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0929 21:33:45.013559  2630 solver.cpp:218] Iteration 58400 (7.42548 iter/s, 13.4671s/100 iters), loss = 0.0099069
I0929 21:33:45.013589  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00990687 (* 1 = 0.00990687 loss)
I0929 21:33:45.013595  2630 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0929 21:33:57.814781  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:33:58.351644  2630 solver.cpp:330] Iteration 58500, Testing net (#0)
I0929 21:34:01.445039  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:34:01.573942  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0929 21:34:01.573977  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321776 (* 1 = 0.321776 loss)
I0929 21:34:01.708046  2630 solver.cpp:218] Iteration 58500 (5.99003 iter/s, 16.6944s/100 iters), loss = 0.00302456
I0929 21:34:01.708076  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302453 (* 1 = 0.00302453 loss)
I0929 21:34:01.708083  2630 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0929 21:34:15.182370  2630 solver.cpp:218] Iteration 58600 (7.42157 iter/s, 13.4742s/100 iters), loss = 0.00239842
I0929 21:34:15.182410  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239839 (* 1 = 0.00239839 loss)
I0929 21:34:15.182417  2630 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0929 21:34:28.652968  2630 solver.cpp:218] Iteration 58700 (7.42364 iter/s, 13.4705s/100 iters), loss = 0.00224334
I0929 21:34:28.653106  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224332 (* 1 = 0.00224332 loss)
I0929 21:34:28.653113  2630 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0929 21:34:42.113891  2630 solver.cpp:218] Iteration 58800 (7.429 iter/s, 13.4608s/100 iters), loss = 0.00990264
I0929 21:34:42.113929  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00990261 (* 1 = 0.00990261 loss)
I0929 21:34:42.113935  2630 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0929 21:34:55.582212  2630 solver.cpp:218] Iteration 58900 (7.42487 iter/s, 13.4682s/100 iters), loss = 0.0304776
I0929 21:34:55.582242  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304776 (* 1 = 0.0304776 loss)
I0929 21:34:55.582249  2630 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0929 21:35:08.382298  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:35:08.920209  2630 solver.cpp:330] Iteration 59000, Testing net (#0)
I0929 21:35:12.016124  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:35:12.148929  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 21:35:12.148957  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319752 (* 1 = 0.319752 loss)
I0929 21:35:12.287575  2630 solver.cpp:218] Iteration 59000 (5.98613 iter/s, 16.7053s/100 iters), loss = 0.00303111
I0929 21:35:12.287609  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303109 (* 1 = 0.00303109 loss)
I0929 21:35:12.287617  2630 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0929 21:35:25.739787  2630 solver.cpp:218] Iteration 59100 (7.43376 iter/s, 13.4521s/100 iters), loss = 0.00593027
I0929 21:35:25.739819  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00593024 (* 1 = 0.00593024 loss)
I0929 21:35:25.739825  2630 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0929 21:35:39.209867  2630 solver.cpp:218] Iteration 59200 (7.4239 iter/s, 13.47s/100 iters), loss = 0.00532294
I0929 21:35:39.210008  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532291 (* 1 = 0.00532291 loss)
I0929 21:35:39.210017  2630 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0929 21:35:52.678676  2630 solver.cpp:218] Iteration 59300 (7.42466 iter/s, 13.4686s/100 iters), loss = 0.0125552
I0929 21:35:52.678707  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125552 (* 1 = 0.0125552 loss)
I0929 21:35:52.678714  2630 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0929 21:36:06.145699  2630 solver.cpp:218] Iteration 59400 (7.42559 iter/s, 13.4669s/100 iters), loss = 0.00357144
I0929 21:36:06.145747  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357141 (* 1 = 0.00357141 loss)
I0929 21:36:06.145754  2630 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0929 21:36:18.939359  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:36:19.476287  2630 solver.cpp:330] Iteration 59500, Testing net (#0)
I0929 21:36:22.568011  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:36:22.696873  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0929 21:36:22.696908  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304132 (* 1 = 0.304132 loss)
I0929 21:36:22.830387  2630 solver.cpp:218] Iteration 59500 (5.99359 iter/s, 16.6845s/100 iters), loss = 0.0193775
I0929 21:36:22.830418  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193775 (* 1 = 0.0193775 loss)
I0929 21:36:22.830425  2630 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0929 21:36:36.292426  2630 solver.cpp:218] Iteration 59600 (7.42834 iter/s, 13.462s/100 iters), loss = 0.00458226
I0929 21:36:36.292475  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458224 (* 1 = 0.00458224 loss)
I0929 21:36:36.292484  2630 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0929 21:36:49.756312  2630 solver.cpp:218] Iteration 59700 (7.42734 iter/s, 13.4638s/100 iters), loss = 0.0017717
I0929 21:36:49.756428  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177167 (* 1 = 0.00177167 loss)
I0929 21:36:49.756436  2630 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0929 21:37:03.225102  2630 solver.cpp:218] Iteration 59800 (7.42465 iter/s, 13.4686s/100 iters), loss = 0.00143058
I0929 21:37:03.225173  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143056 (* 1 = 0.00143056 loss)
I0929 21:37:03.225189  2630 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0929 21:37:16.688998  2630 solver.cpp:218] Iteration 59900 (7.42732 iter/s, 13.4638s/100 iters), loss = 0.00190504
I0929 21:37:16.689029  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190501 (* 1 = 0.00190501 loss)
I0929 21:37:16.689035  2630 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0929 21:37:29.487768  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:37:30.024366  2630 solver.cpp:330] Iteration 60000, Testing net (#0)
I0929 21:37:33.120920  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:37:33.254652  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0929 21:37:33.254680  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309881 (* 1 = 0.309881 loss)
I0929 21:37:33.391566  2630 solver.cpp:218] Iteration 60000 (5.98713 iter/s, 16.7025s/100 iters), loss = 0.00326774
I0929 21:37:33.391599  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326772 (* 1 = 0.00326772 loss)
I0929 21:37:33.391607  2630 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0929 21:37:46.855093  2630 solver.cpp:218] Iteration 60100 (7.42752 iter/s, 13.4634s/100 iters), loss = 0.0245193
I0929 21:37:46.855123  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245193 (* 1 = 0.0245193 loss)
I0929 21:37:46.855140  2630 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0929 21:38:00.329119  2630 solver.cpp:218] Iteration 60200 (7.42173 iter/s, 13.474s/100 iters), loss = 0.0114305
I0929 21:38:00.329252  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114304 (* 1 = 0.0114304 loss)
I0929 21:38:00.329262  2630 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0929 21:38:13.809940  2630 solver.cpp:218] Iteration 60300 (7.41804 iter/s, 13.4806s/100 iters), loss = 0.00100283
I0929 21:38:13.809972  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100281 (* 1 = 0.00100281 loss)
I0929 21:38:13.809988  2630 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0929 21:38:27.290632  2630 solver.cpp:218] Iteration 60400 (7.41806 iter/s, 13.4806s/100 iters), loss = 0.00452265
I0929 21:38:27.290668  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452263 (* 1 = 0.00452263 loss)
I0929 21:38:27.290676  2630 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0929 21:38:40.091462  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:38:40.629580  2630 solver.cpp:330] Iteration 60500, Testing net (#0)
I0929 21:38:43.719902  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:38:43.848551  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I0929 21:38:43.848587  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314497 (* 1 = 0.314497 loss)
I0929 21:38:43.982272  2630 solver.cpp:218] Iteration 60500 (5.99105 iter/s, 16.6916s/100 iters), loss = 0.00230585
I0929 21:38:43.982302  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230584 (* 1 = 0.00230584 loss)
I0929 21:38:43.982309  2630 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0929 21:38:57.456650  2630 solver.cpp:218] Iteration 60600 (7.42154 iter/s, 13.4743s/100 iters), loss = 0.0106414
I0929 21:38:57.456683  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106414 (* 1 = 0.0106414 loss)
I0929 21:38:57.456691  2630 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0929 21:39:10.922233  2630 solver.cpp:218] Iteration 60700 (7.42638 iter/s, 13.4655s/100 iters), loss = 0.015259
I0929 21:39:10.922394  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015259 (* 1 = 0.015259 loss)
I0929 21:39:10.922404  2630 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0929 21:39:24.391175  2630 solver.cpp:218] Iteration 60800 (7.4246 iter/s, 13.4687s/100 iters), loss = 0.00148231
I0929 21:39:24.391224  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014823 (* 1 = 0.0014823 loss)
I0929 21:39:24.391233  2630 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0929 21:39:37.849370  2630 solver.cpp:218] Iteration 60900 (7.43047 iter/s, 13.4581s/100 iters), loss = 0.0018633
I0929 21:39:37.849400  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018633 (* 1 = 0.0018633 loss)
I0929 21:39:37.849407  2630 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0929 21:39:50.646311  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:39:51.186868  2630 solver.cpp:330] Iteration 61000, Testing net (#0)
I0929 21:39:54.285002  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:39:54.416204  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I0929 21:39:54.416230  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305949 (* 1 = 0.305949 loss)
I0929 21:39:54.550160  2630 solver.cpp:218] Iteration 61000 (5.98777 iter/s, 16.7007s/100 iters), loss = 0.00128412
I0929 21:39:54.550204  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128412 (* 1 = 0.00128412 loss)
I0929 21:39:54.550220  2630 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0929 21:40:08.015789  2630 solver.cpp:218] Iteration 61100 (7.42636 iter/s, 13.4655s/100 iters), loss = 0.00277785
I0929 21:40:08.015831  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277785 (* 1 = 0.00277785 loss)
I0929 21:40:08.015838  2630 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0929 21:40:21.498270  2630 solver.cpp:218] Iteration 61200 (7.41708 iter/s, 13.4824s/100 iters), loss = 0.0221318
I0929 21:40:21.498445  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221319 (* 1 = 0.0221319 loss)
I0929 21:40:21.498456  2630 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0929 21:40:35.066504  2630 solver.cpp:218] Iteration 61300 (7.37027 iter/s, 13.568s/100 iters), loss = 0.00245197
I0929 21:40:35.066546  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245198 (* 1 = 0.00245198 loss)
I0929 21:40:35.066553  2630 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0929 21:40:48.575918  2630 solver.cpp:218] Iteration 61400 (7.40229 iter/s, 13.5093s/100 iters), loss = 0.00970331
I0929 21:40:48.575953  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00970332 (* 1 = 0.00970332 loss)
I0929 21:40:48.575959  2630 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0929 21:41:01.504878  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:41:02.041622  2630 solver.cpp:330] Iteration 61500, Testing net (#0)
I0929 21:41:05.144454  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:41:05.273993  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0929 21:41:05.274020  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296594 (* 1 = 0.296594 loss)
I0929 21:41:05.409096  2630 solver.cpp:218] Iteration 61500 (5.94068 iter/s, 16.8331s/100 iters), loss = 0.0104881
I0929 21:41:05.409128  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104881 (* 1 = 0.0104881 loss)
I0929 21:41:05.409135  2630 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0929 21:41:18.968956  2630 solver.cpp:218] Iteration 61600 (7.37475 iter/s, 13.5598s/100 iters), loss = 0.027661
I0929 21:41:18.968998  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027661 (* 1 = 0.027661 loss)
I0929 21:41:18.969005  2630 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0929 21:41:32.449879  2630 solver.cpp:218] Iteration 61700 (7.41794 iter/s, 13.4808s/100 iters), loss = 0.00175415
I0929 21:41:32.450001  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175415 (* 1 = 0.00175415 loss)
I0929 21:41:32.450007  2630 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0929 21:41:45.930335  2630 solver.cpp:218] Iteration 61800 (7.41824 iter/s, 13.4803s/100 iters), loss = 0.0148108
I0929 21:41:45.930366  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148108 (* 1 = 0.0148108 loss)
I0929 21:41:45.930371  2630 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0929 21:41:59.394395  2630 solver.cpp:218] Iteration 61900 (7.42722 iter/s, 13.464s/100 iters), loss = 0.00193998
I0929 21:41:59.394429  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193999 (* 1 = 0.00193999 loss)
I0929 21:41:59.394435  2630 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0929 21:42:12.197449  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:42:12.742414  2630 solver.cpp:330] Iteration 62000, Testing net (#0)
I0929 21:42:15.835602  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:42:15.964630  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0929 21:42:15.964666  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301847 (* 1 = 0.301847 loss)
I0929 21:42:16.098851  2630 solver.cpp:218] Iteration 62000 (5.98646 iter/s, 16.7044s/100 iters), loss = 0.00767735
I0929 21:42:16.098883  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00767735 (* 1 = 0.00767735 loss)
I0929 21:42:16.098891  2630 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0929 21:42:29.574018  2630 solver.cpp:218] Iteration 62100 (7.4211 iter/s, 13.4751s/100 iters), loss = 0.00379321
I0929 21:42:29.574059  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379321 (* 1 = 0.00379321 loss)
I0929 21:42:29.574065  2630 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0929 21:42:43.049152  2630 solver.cpp:218] Iteration 62200 (7.42112 iter/s, 13.4751s/100 iters), loss = 0.0188203
I0929 21:42:43.049326  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188203 (* 1 = 0.0188203 loss)
I0929 21:42:43.049335  2630 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0929 21:42:56.527995  2630 solver.cpp:218] Iteration 62300 (7.41915 iter/s, 13.4786s/100 iters), loss = 0.00481905
I0929 21:42:56.528039  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481905 (* 1 = 0.00481905 loss)
I0929 21:42:56.528045  2630 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0929 21:43:10.200117  2630 solver.cpp:218] Iteration 62400 (7.3142 iter/s, 13.672s/100 iters), loss = 0.00183406
I0929 21:43:10.200148  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183405 (* 1 = 0.00183405 loss)
I0929 21:43:10.200155  2630 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0929 21:43:23.162621  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:43:23.703583  2630 solver.cpp:330] Iteration 62500, Testing net (#0)
I0929 21:43:26.804955  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:43:26.933995  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0929 21:43:26.934031  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296802 (* 1 = 0.296802 loss)
I0929 21:43:27.066504  2630 solver.cpp:218] Iteration 62500 (5.92898 iter/s, 16.8663s/100 iters), loss = 0.0129556
I0929 21:43:27.066535  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129556 (* 1 = 0.0129556 loss)
I0929 21:43:27.066542  2630 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0929 21:43:40.602094  2630 solver.cpp:218] Iteration 62600 (7.38797 iter/s, 13.5355s/100 iters), loss = 0.00122922
I0929 21:43:40.602124  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122921 (* 1 = 0.00122921 loss)
I0929 21:43:40.602130  2630 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0929 21:43:54.055122  2630 solver.cpp:218] Iteration 62700 (7.43331 iter/s, 13.453s/100 iters), loss = 0.00111144
I0929 21:43:54.055193  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111143 (* 1 = 0.00111143 loss)
I0929 21:43:54.055202  2630 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0929 21:44:07.520227  2630 solver.cpp:218] Iteration 62800 (7.42667 iter/s, 13.465s/100 iters), loss = 0.0294729
I0929 21:44:07.520258  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294729 (* 1 = 0.0294729 loss)
I0929 21:44:07.520264  2630 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0929 21:44:20.965729  2630 solver.cpp:218] Iteration 62900 (7.43747 iter/s, 13.4454s/100 iters), loss = 0.000520765
I0929 21:44:20.965770  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000520757 (* 1 = 0.000520757 loss)
I0929 21:44:20.965777  2630 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0929 21:44:33.766990  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:44:34.305027  2630 solver.cpp:330] Iteration 63000, Testing net (#0)
I0929 21:44:37.400205  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:44:37.528666  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I0929 21:44:37.528690  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299497 (* 1 = 0.299497 loss)
I0929 21:44:37.661964  2630 solver.cpp:218] Iteration 63000 (5.98941 iter/s, 16.6961s/100 iters), loss = 0.00424096
I0929 21:44:37.661998  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424095 (* 1 = 0.00424095 loss)
I0929 21:44:37.662005  2630 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0929 21:44:51.120216  2630 solver.cpp:218] Iteration 63100 (7.43043 iter/s, 13.4582s/100 iters), loss = 0.0017477
I0929 21:44:51.120249  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017477 (* 1 = 0.0017477 loss)
I0929 21:44:51.120255  2630 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0929 21:45:04.587075  2630 solver.cpp:218] Iteration 63200 (7.42568 iter/s, 13.4668s/100 iters), loss = 0.00719298
I0929 21:45:04.587211  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00719297 (* 1 = 0.00719297 loss)
I0929 21:45:04.587219  2630 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0929 21:45:18.035825  2630 solver.cpp:218] Iteration 63300 (7.43573 iter/s, 13.4486s/100 iters), loss = 0.00986537
I0929 21:45:18.035853  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00986536 (* 1 = 0.00986536 loss)
I0929 21:45:18.035859  2630 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0929 21:45:31.497560  2630 solver.cpp:218] Iteration 63400 (7.4285 iter/s, 13.4617s/100 iters), loss = 0.0108562
I0929 21:45:31.497589  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108562 (* 1 = 0.0108562 loss)
I0929 21:45:31.497596  2630 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0929 21:45:44.295100  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:45:44.832602  2630 solver.cpp:330] Iteration 63500, Testing net (#0)
I0929 21:45:47.922557  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:45:48.051061  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0929 21:45:48.051097  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308193 (* 1 = 0.308193 loss)
I0929 21:45:48.185220  2630 solver.cpp:218] Iteration 63500 (5.99248 iter/s, 16.6876s/100 iters), loss = 0.00122416
I0929 21:45:48.185253  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122415 (* 1 = 0.00122415 loss)
I0929 21:45:48.185261  2630 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0929 21:46:01.653450  2630 solver.cpp:218] Iteration 63600 (7.42492 iter/s, 13.4682s/100 iters), loss = 0.00219578
I0929 21:46:01.653491  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219577 (* 1 = 0.00219577 loss)
I0929 21:46:01.653497  2630 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0929 21:46:15.121392  2630 solver.cpp:218] Iteration 63700 (7.42509 iter/s, 13.4679s/100 iters), loss = 0.00508356
I0929 21:46:15.121534  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508355 (* 1 = 0.00508355 loss)
I0929 21:46:15.121542  2630 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0929 21:46:28.602254  2630 solver.cpp:218] Iteration 63800 (7.41802 iter/s, 13.4807s/100 iters), loss = 0.00145058
I0929 21:46:28.602284  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145057 (* 1 = 0.00145057 loss)
I0929 21:46:28.602290  2630 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0929 21:46:42.053133  2630 solver.cpp:218] Iteration 63900 (7.4345 iter/s, 13.4508s/100 iters), loss = 0.00088282
I0929 21:46:42.053164  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000882811 (* 1 = 0.000882811 loss)
I0929 21:46:42.053169  2630 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0929 21:46:54.843960  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:46:55.380954  2630 solver.cpp:330] Iteration 64000, Testing net (#0)
I0929 21:46:58.468574  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:46:58.597015  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0929 21:46:58.597049  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318646 (* 1 = 0.318646 loss)
I0929 21:46:58.730377  2630 solver.cpp:218] Iteration 64000 (5.99622 iter/s, 16.6772s/100 iters), loss = 0.0027287
I0929 21:46:58.730412  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272869 (* 1 = 0.00272869 loss)
I0929 21:46:58.730418  2630 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0929 21:47:12.189002  2630 solver.cpp:218] Iteration 64100 (7.43022 iter/s, 13.4585s/100 iters), loss = 0.00229576
I0929 21:47:12.189043  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229575 (* 1 = 0.00229575 loss)
I0929 21:47:12.189054  2630 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0929 21:47:25.642323  2630 solver.cpp:218] Iteration 64200 (7.43315 iter/s, 13.4532s/100 iters), loss = 0.00270885
I0929 21:47:25.642495  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270884 (* 1 = 0.00270884 loss)
I0929 21:47:25.642508  2630 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0929 21:47:39.091439  2630 solver.cpp:218] Iteration 64300 (7.43555 iter/s, 13.4489s/100 iters), loss = 0.00666464
I0929 21:47:39.091470  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666464 (* 1 = 0.00666464 loss)
I0929 21:47:39.091476  2630 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0929 21:47:52.554189  2630 solver.cpp:218] Iteration 64400 (7.42794 iter/s, 13.4627s/100 iters), loss = 0.0157824
I0929 21:47:52.554220  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157824 (* 1 = 0.0157824 loss)
I0929 21:47:52.554236  2630 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0929 21:48:05.332850  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:48:05.870287  2630 solver.cpp:330] Iteration 64500, Testing net (#0)
I0929 21:48:08.962433  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:48:09.091200  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I0929 21:48:09.091238  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339878 (* 1 = 0.339878 loss)
I0929 21:48:09.226425  2630 solver.cpp:218] Iteration 64500 (5.99802 iter/s, 16.6722s/100 iters), loss = 0.00598723
I0929 21:48:09.226471  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598722 (* 1 = 0.00598722 loss)
I0929 21:48:09.226478  2630 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0929 21:48:22.682658  2630 solver.cpp:218] Iteration 64600 (7.43156 iter/s, 13.4561s/100 iters), loss = 0.00178604
I0929 21:48:22.682687  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178602 (* 1 = 0.00178602 loss)
I0929 21:48:22.682693  2630 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0929 21:48:36.139631  2630 solver.cpp:218] Iteration 64700 (7.43113 iter/s, 13.4569s/100 iters), loss = 0.00595768
I0929 21:48:36.139708  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595766 (* 1 = 0.00595766 loss)
I0929 21:48:36.139727  2630 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0929 21:48:49.622568  2630 solver.cpp:218] Iteration 64800 (7.41684 iter/s, 13.4828s/100 iters), loss = 0.00141233
I0929 21:48:49.622609  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141231 (* 1 = 0.00141231 loss)
I0929 21:48:49.622615  2630 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0929 21:49:03.082792  2630 solver.cpp:218] Iteration 64900 (7.42934 iter/s, 13.4601s/100 iters), loss = 0.00103261
I0929 21:49:03.082823  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103259 (* 1 = 0.00103259 loss)
I0929 21:49:03.082829  2630 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0929 21:49:15.880147  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:49:16.417510  2630 solver.cpp:330] Iteration 65000, Testing net (#0)
I0929 21:49:19.508705  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:49:19.637872  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0929 21:49:19.637897  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305542 (* 1 = 0.305542 loss)
I0929 21:49:19.771651  2630 solver.cpp:218] Iteration 65000 (5.99205 iter/s, 16.6888s/100 iters), loss = 0.00228884
I0929 21:49:19.771684  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228882 (* 1 = 0.00228882 loss)
I0929 21:49:19.771692  2630 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0929 21:49:33.238536  2630 solver.cpp:218] Iteration 65100 (7.42567 iter/s, 13.4668s/100 iters), loss = 0.00235527
I0929 21:49:33.238584  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235525 (* 1 = 0.00235525 loss)
I0929 21:49:33.238592  2630 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0929 21:49:46.703878  2630 solver.cpp:218] Iteration 65200 (7.42654 iter/s, 13.4652s/100 iters), loss = 0.00617537
I0929 21:49:46.704011  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00617535 (* 1 = 0.00617535 loss)
I0929 21:49:46.704030  2630 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0929 21:50:00.154531  2630 solver.cpp:218] Iteration 65300 (7.43468 iter/s, 13.4505s/100 iters), loss = 0.00340078
I0929 21:50:00.154572  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340076 (* 1 = 0.00340076 loss)
I0929 21:50:00.154579  2630 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0929 21:50:13.621382  2630 solver.cpp:218] Iteration 65400 (7.42569 iter/s, 13.4668s/100 iters), loss = 0.00204021
I0929 21:50:13.621412  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204019 (* 1 = 0.00204019 loss)
I0929 21:50:13.621418  2630 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0929 21:50:26.414283  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:50:26.951817  2630 solver.cpp:330] Iteration 65500, Testing net (#0)
I0929 21:50:30.043254  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:50:30.172669  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0929 21:50:30.172698  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314675 (* 1 = 0.314675 loss)
I0929 21:50:30.309734  2630 solver.cpp:218] Iteration 65500 (5.99223 iter/s, 16.6883s/100 iters), loss = 0.0041347
I0929 21:50:30.309770  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413469 (* 1 = 0.00413469 loss)
I0929 21:50:30.309778  2630 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0929 21:50:43.755177  2630 solver.cpp:218] Iteration 65600 (7.43751 iter/s, 13.4454s/100 iters), loss = 0.0105266
I0929 21:50:43.755209  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105266 (* 1 = 0.0105266 loss)
I0929 21:50:43.755215  2630 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0929 21:50:57.204001  2630 solver.cpp:218] Iteration 65700 (7.43564 iter/s, 13.4487s/100 iters), loss = 0.0236526
I0929 21:50:57.204152  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236526 (* 1 = 0.0236526 loss)
I0929 21:50:57.204161  2630 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0929 21:51:10.661602  2630 solver.cpp:218] Iteration 65800 (7.43084 iter/s, 13.4574s/100 iters), loss = 0.00400824
I0929 21:51:10.661633  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400822 (* 1 = 0.00400822 loss)
I0929 21:51:10.661638  2630 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0929 21:51:24.121923  2630 solver.cpp:218] Iteration 65900 (7.42928 iter/s, 13.4603s/100 iters), loss = 0.0101433
I0929 21:51:24.121953  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101433 (* 1 = 0.0101433 loss)
I0929 21:51:24.121959  2630 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0929 21:51:36.916329  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:51:37.453425  2630 solver.cpp:330] Iteration 66000, Testing net (#0)
I0929 21:51:40.542055  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:51:40.670513  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9265
I0929 21:51:40.670542  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294792 (* 1 = 0.294792 loss)
I0929 21:51:40.804036  2630 solver.cpp:218] Iteration 66000 (5.99447 iter/s, 16.682s/100 iters), loss = 0.00174594
I0929 21:51:40.804069  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174591 (* 1 = 0.00174591 loss)
I0929 21:51:40.804075  2630 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0929 21:51:54.261536  2630 solver.cpp:218] Iteration 66100 (7.43084 iter/s, 13.4574s/100 iters), loss = 0.00131029
I0929 21:51:54.261595  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131026 (* 1 = 0.00131026 loss)
I0929 21:51:54.261602  2630 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0929 21:52:07.730459  2630 solver.cpp:218] Iteration 66200 (7.42456 iter/s, 13.4688s/100 iters), loss = 0.00920364
I0929 21:52:07.730614  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00920361 (* 1 = 0.00920361 loss)
I0929 21:52:07.730633  2630 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0929 21:52:21.185155  2630 solver.cpp:218] Iteration 66300 (7.43246 iter/s, 13.4545s/100 iters), loss = 0.0329724
I0929 21:52:21.185201  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329724 (* 1 = 0.0329724 loss)
I0929 21:52:21.185209  2630 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0929 21:52:34.649570  2630 solver.cpp:218] Iteration 66400 (7.42705 iter/s, 13.4643s/100 iters), loss = 0.0080991
I0929 21:52:34.649601  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00809906 (* 1 = 0.00809906 loss)
I0929 21:52:34.649607  2630 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0929 21:52:47.442057  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:52:47.979425  2630 solver.cpp:330] Iteration 66500, Testing net (#0)
I0929 21:52:51.070036  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:52:51.199944  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0929 21:52:51.199980  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316758 (* 1 = 0.316758 loss)
I0929 21:52:51.337564  2630 solver.cpp:218] Iteration 66500 (5.99236 iter/s, 16.6879s/100 iters), loss = 0.0104578
I0929 21:52:51.337615  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104578 (* 1 = 0.0104578 loss)
I0929 21:52:51.337622  2630 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0929 21:53:04.792726  2630 solver.cpp:218] Iteration 66600 (7.43216 iter/s, 13.455s/100 iters), loss = 0.0097426
I0929 21:53:04.792755  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00974257 (* 1 = 0.00974257 loss)
I0929 21:53:04.792762  2630 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0929 21:53:18.247231  2630 solver.cpp:218] Iteration 66700 (7.43249 iter/s, 13.4544s/100 iters), loss = 0.0046138
I0929 21:53:18.247357  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461376 (* 1 = 0.00461376 loss)
I0929 21:53:18.247366  2630 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0929 21:53:31.714404  2630 solver.cpp:218] Iteration 66800 (7.42556 iter/s, 13.467s/100 iters), loss = 0.00375043
I0929 21:53:31.714444  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375038 (* 1 = 0.00375038 loss)
I0929 21:53:31.714450  2630 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0929 21:53:45.184510  2630 solver.cpp:218] Iteration 66900 (7.42389 iter/s, 13.47s/100 iters), loss = 0.00140308
I0929 21:53:45.184558  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140303 (* 1 = 0.00140303 loss)
I0929 21:53:45.184566  2630 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0929 21:53:57.981262  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:53:58.518714  2630 solver.cpp:330] Iteration 67000, Testing net (#0)
I0929 21:54:01.610604  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:54:01.739203  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I0929 21:54:01.739239  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352686 (* 1 = 0.352686 loss)
I0929 21:54:01.872943  2630 solver.cpp:218] Iteration 67000 (5.99221 iter/s, 16.6883s/100 iters), loss = 0.0151824
I0929 21:54:01.872975  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151823 (* 1 = 0.0151823 loss)
I0929 21:54:01.872982  2630 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0929 21:54:15.334115  2630 solver.cpp:218] Iteration 67100 (7.42882 iter/s, 13.4611s/100 iters), loss = 0.00190584
I0929 21:54:15.334159  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190579 (* 1 = 0.00190579 loss)
I0929 21:54:15.334168  2630 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0929 21:54:28.797991  2630 solver.cpp:218] Iteration 67200 (7.42733 iter/s, 13.4638s/100 iters), loss = 0.00421696
I0929 21:54:28.798118  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421692 (* 1 = 0.00421692 loss)
I0929 21:54:28.798127  2630 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0929 21:54:42.258245  2630 solver.cpp:218] Iteration 67300 (7.42937 iter/s, 13.4601s/100 iters), loss = 0.00188452
I0929 21:54:42.258291  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188447 (* 1 = 0.00188447 loss)
I0929 21:54:42.258301  2630 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0929 21:54:55.723354  2630 solver.cpp:218] Iteration 67400 (7.42665 iter/s, 13.465s/100 iters), loss = 0.00126254
I0929 21:54:55.723397  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012625 (* 1 = 0.0012625 loss)
I0929 21:54:55.723403  2630 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0929 21:55:08.525213  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:55:09.063520  2630 solver.cpp:330] Iteration 67500, Testing net (#0)
I0929 21:55:12.155722  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:55:12.289191  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0929 21:55:12.289219  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306532 (* 1 = 0.306532 loss)
I0929 21:55:12.426930  2630 solver.cpp:218] Iteration 67500 (5.98678 iter/s, 16.7035s/100 iters), loss = 0.00213934
I0929 21:55:12.426975  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021393 (* 1 = 0.0021393 loss)
I0929 21:55:12.426983  2630 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0929 21:55:25.881755  2630 solver.cpp:218] Iteration 67600 (7.43235 iter/s, 13.4547s/100 iters), loss = 0.00679333
I0929 21:55:25.881786  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679328 (* 1 = 0.00679328 loss)
I0929 21:55:25.881793  2630 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0929 21:55:39.338312  2630 solver.cpp:218] Iteration 67700 (7.43136 iter/s, 13.4565s/100 iters), loss = 0.00187484
I0929 21:55:39.338459  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187479 (* 1 = 0.00187479 loss)
I0929 21:55:39.338467  2630 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0929 21:55:52.802629  2630 solver.cpp:218] Iteration 67800 (7.42714 iter/s, 13.4641s/100 iters), loss = 0.00323139
I0929 21:55:52.802670  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323135 (* 1 = 0.00323135 loss)
I0929 21:55:52.802677  2630 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0929 21:56:06.254492  2630 solver.cpp:218] Iteration 67900 (7.43396 iter/s, 13.4518s/100 iters), loss = 0.00116781
I0929 21:56:06.254541  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116776 (* 1 = 0.00116776 loss)
I0929 21:56:06.254550  2630 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0929 21:56:19.035864  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:56:19.574260  2630 solver.cpp:330] Iteration 68000, Testing net (#0)
I0929 21:56:22.661674  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:56:22.790765  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0929 21:56:22.790789  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336379 (* 1 = 0.336379 loss)
I0929 21:56:22.923842  2630 solver.cpp:218] Iteration 68000 (5.99908 iter/s, 16.6692s/100 iters), loss = 0.000761893
I0929 21:56:22.923876  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000761847 (* 1 = 0.000761847 loss)
I0929 21:56:22.923882  2630 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0929 21:56:36.373498  2630 solver.cpp:218] Iteration 68100 (7.43518 iter/s, 13.4496s/100 iters), loss = 0.00168082
I0929 21:56:36.373536  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168077 (* 1 = 0.00168077 loss)
I0929 21:56:36.373544  2630 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0929 21:56:49.829501  2630 solver.cpp:218] Iteration 68200 (7.43167 iter/s, 13.4559s/100 iters), loss = 0.0100296
I0929 21:56:49.829632  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100296 (* 1 = 0.0100296 loss)
I0929 21:56:49.829648  2630 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0929 21:57:03.279717  2630 solver.cpp:218] Iteration 68300 (7.43491 iter/s, 13.4501s/100 iters), loss = 0.00450779
I0929 21:57:03.279765  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450774 (* 1 = 0.00450774 loss)
I0929 21:57:03.279773  2630 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0929 21:57:16.737606  2630 solver.cpp:218] Iteration 68400 (7.43065 iter/s, 13.4578s/100 iters), loss = 0.00187785
I0929 21:57:16.737637  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018778 (* 1 = 0.0018778 loss)
I0929 21:57:16.737643  2630 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0929 21:57:29.521550  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:57:30.056989  2630 solver.cpp:330] Iteration 68500, Testing net (#0)
I0929 21:57:33.147936  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:57:33.279081  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0929 21:57:33.279129  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316496 (* 1 = 0.316496 loss)
I0929 21:57:33.416401  2630 solver.cpp:218] Iteration 68500 (5.99567 iter/s, 16.6787s/100 iters), loss = 0.000738606
I0929 21:57:33.416437  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000738552 (* 1 = 0.000738552 loss)
I0929 21:57:33.416445  2630 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0929 21:57:46.881099  2630 solver.cpp:218] Iteration 68600 (7.42687 iter/s, 13.4646s/100 iters), loss = 0.00221892
I0929 21:57:46.881129  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221887 (* 1 = 0.00221887 loss)
I0929 21:57:46.881135  2630 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0929 21:58:00.332060  2630 solver.cpp:218] Iteration 68700 (7.43445 iter/s, 13.4509s/100 iters), loss = 0.0110122
I0929 21:58:00.332180  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110122 (* 1 = 0.0110122 loss)
I0929 21:58:00.332198  2630 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0929 21:58:13.797214  2630 solver.cpp:218] Iteration 68800 (7.42668 iter/s, 13.465s/100 iters), loss = 0.00205551
I0929 21:58:13.797247  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205546 (* 1 = 0.00205546 loss)
I0929 21:58:13.797263  2630 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0929 21:58:27.252080  2630 solver.cpp:218] Iteration 68900 (7.4323 iter/s, 13.4548s/100 iters), loss = 0.0135873
I0929 21:58:27.252128  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135872 (* 1 = 0.0135872 loss)
I0929 21:58:27.252135  2630 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0929 21:58:40.039786  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:58:40.578143  2630 solver.cpp:330] Iteration 69000, Testing net (#0)
I0929 21:58:43.670270  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:58:43.799495  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 21:58:43.799531  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321944 (* 1 = 0.321944 loss)
I0929 21:58:43.933096  2630 solver.cpp:218] Iteration 69000 (5.99489 iter/s, 16.6809s/100 iters), loss = 0.000706354
I0929 21:58:43.933130  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000706295 (* 1 = 0.000706295 loss)
I0929 21:58:43.933136  2630 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0929 21:58:57.404762  2630 solver.cpp:218] Iteration 69100 (7.42303 iter/s, 13.4716s/100 iters), loss = 0.00465543
I0929 21:58:57.404808  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465537 (* 1 = 0.00465537 loss)
I0929 21:58:57.404826  2630 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0929 21:59:10.873086  2630 solver.cpp:218] Iteration 69200 (7.42489 iter/s, 13.4682s/100 iters), loss = 0.00340998
I0929 21:59:10.873258  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340992 (* 1 = 0.00340992 loss)
I0929 21:59:10.873266  2630 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0929 21:59:24.344146  2630 solver.cpp:218] Iteration 69300 (7.42344 iter/s, 13.4708s/100 iters), loss = 0.00207799
I0929 21:59:24.344192  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207793 (* 1 = 0.00207793 loss)
I0929 21:59:24.344200  2630 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0929 21:59:37.809419  2630 solver.cpp:218] Iteration 69400 (7.42658 iter/s, 13.4652s/100 iters), loss = 0.00773957
I0929 21:59:37.809450  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00773951 (* 1 = 0.00773951 loss)
I0929 21:59:37.809458  2630 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0929 21:59:50.610914  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:59:51.149745  2630 solver.cpp:330] Iteration 69500, Testing net (#0)
I0929 21:59:54.242327  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:59:54.375175  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0929 21:59:54.375214  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309498 (* 1 = 0.309498 loss)
I0929 21:59:54.512959  2630 solver.cpp:218] Iteration 69500 (5.98678 iter/s, 16.7035s/100 iters), loss = 0.00280289
I0929 21:59:54.512996  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280283 (* 1 = 0.00280283 loss)
I0929 21:59:54.513003  2630 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0929 22:00:07.975406  2630 solver.cpp:218] Iteration 69600 (7.42811 iter/s, 13.4624s/100 iters), loss = 0.00332598
I0929 22:00:07.975447  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332593 (* 1 = 0.00332593 loss)
I0929 22:00:07.975455  2630 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0929 22:00:21.432698  2630 solver.cpp:218] Iteration 69700 (7.43096 iter/s, 13.4572s/100 iters), loss = 0.000811429
I0929 22:00:21.432824  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000811376 (* 1 = 0.000811376 loss)
I0929 22:00:21.432834  2630 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0929 22:00:34.892927  2630 solver.cpp:218] Iteration 69800 (7.4294 iter/s, 13.46s/100 iters), loss = 0.00290518
I0929 22:00:34.892957  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290513 (* 1 = 0.00290513 loss)
I0929 22:00:34.892964  2630 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0929 22:00:48.358791  2630 solver.cpp:218] Iteration 69900 (7.42623 iter/s, 13.4658s/100 iters), loss = 0.00113879
I0929 22:00:48.358829  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113874 (* 1 = 0.00113874 loss)
I0929 22:00:48.358836  2630 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0929 22:01:01.151871  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:01:01.688940  2630 solver.cpp:330] Iteration 70000, Testing net (#0)
I0929 22:01:04.779644  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:01:04.907897  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I0929 22:01:04.907933  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325962 (* 1 = 0.325962 loss)
I0929 22:01:05.042091  2630 solver.cpp:218] Iteration 70000 (5.99405 iter/s, 16.6832s/100 iters), loss = 0.00492227
I0929 22:01:05.042121  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492222 (* 1 = 0.00492222 loss)
I0929 22:01:05.042129  2630 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0929 22:01:18.496114  2630 solver.cpp:218] Iteration 70100 (7.43277 iter/s, 13.4539s/100 iters), loss = 0.00167644
I0929 22:01:18.496150  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016764 (* 1 = 0.0016764 loss)
I0929 22:01:18.496157  2630 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0929 22:01:31.950239  2630 solver.cpp:218] Iteration 70200 (7.4327 iter/s, 13.4541s/100 iters), loss = 0.00232396
I0929 22:01:31.950382  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232392 (* 1 = 0.00232392 loss)
I0929 22:01:31.950390  2630 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0929 22:01:45.413528  2630 solver.cpp:218] Iteration 70300 (7.42771 iter/s, 13.4631s/100 iters), loss = 0.00673079
I0929 22:01:45.413574  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00673074 (* 1 = 0.00673074 loss)
I0929 22:01:45.413583  2630 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0929 22:01:58.864238  2630 solver.cpp:218] Iteration 70400 (7.43462 iter/s, 13.4506s/100 iters), loss = 0.00110302
I0929 22:01:58.864267  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110298 (* 1 = 0.00110298 loss)
I0929 22:01:58.864274  2630 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0929 22:02:11.650920  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:02:12.188197  2630 solver.cpp:330] Iteration 70500, Testing net (#0)
I0929 22:02:15.282786  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:02:15.416188  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0929 22:02:15.416225  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333796 (* 1 = 0.333796 loss)
I0929 22:02:15.553074  2630 solver.cpp:218] Iteration 70500 (5.99206 iter/s, 16.6888s/100 iters), loss = 0.000419153
I0929 22:02:15.553108  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000419107 (* 1 = 0.000419107 loss)
I0929 22:02:15.553117  2630 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0929 22:02:29.003309  2630 solver.cpp:218] Iteration 70600 (7.43486 iter/s, 13.4502s/100 iters), loss = 0.00321497
I0929 22:02:29.003340  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321492 (* 1 = 0.00321492 loss)
I0929 22:02:29.003346  2630 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0929 22:02:42.464102  2630 solver.cpp:218] Iteration 70700 (7.42902 iter/s, 13.4607s/100 iters), loss = 0.00228251
I0929 22:02:42.464192  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228246 (* 1 = 0.00228246 loss)
I0929 22:02:42.464211  2630 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0929 22:02:55.908679  2630 solver.cpp:218] Iteration 70800 (7.43801 iter/s, 13.4445s/100 iters), loss = 0.00100189
I0929 22:02:55.908711  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100185 (* 1 = 0.00100185 loss)
I0929 22:02:55.908717  2630 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0929 22:03:09.366528  2630 solver.cpp:218] Iteration 70900 (7.43065 iter/s, 13.4578s/100 iters), loss = 0.000564677
I0929 22:03:09.366576  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000564632 (* 1 = 0.000564632 loss)
I0929 22:03:09.366585  2630 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0929 22:03:22.148937  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:03:22.688001  2630 solver.cpp:330] Iteration 71000, Testing net (#0)
I0929 22:03:25.776785  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:03:25.905552  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I0929 22:03:25.905587  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330598 (* 1 = 0.330598 loss)
I0929 22:03:26.039767  2630 solver.cpp:218] Iteration 71000 (5.99768 iter/s, 16.6731s/100 iters), loss = 0.00552925
I0929 22:03:26.039799  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055292 (* 1 = 0.0055292 loss)
I0929 22:03:26.039806  2630 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0929 22:03:39.499248  2630 solver.cpp:218] Iteration 71100 (7.42975 iter/s, 13.4594s/100 iters), loss = 0.00544247
I0929 22:03:39.499285  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544243 (* 1 = 0.00544243 loss)
I0929 22:03:39.499294  2630 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0929 22:03:52.945125  2630 solver.cpp:218] Iteration 71200 (7.43727 iter/s, 13.4458s/100 iters), loss = 0.00166599
I0929 22:03:52.945286  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166595 (* 1 = 0.00166595 loss)
I0929 22:03:52.945298  2630 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0929 22:04:06.402362  2630 solver.cpp:218] Iteration 71300 (7.43106 iter/s, 13.457s/100 iters), loss = 0.0152685
I0929 22:04:06.402411  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152685 (* 1 = 0.0152685 loss)
I0929 22:04:06.402420  2630 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0929 22:04:19.845598  2630 solver.cpp:218] Iteration 71400 (7.43873 iter/s, 13.4431s/100 iters), loss = 0.00108518
I0929 22:04:19.845640  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108513 (* 1 = 0.00108513 loss)
I0929 22:04:19.845648  2630 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0929 22:04:32.632874  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:04:33.170491  2630 solver.cpp:330] Iteration 71500, Testing net (#0)
I0929 22:04:36.263769  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:04:36.397424  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I0929 22:04:36.397452  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325099 (* 1 = 0.325099 loss)
I0929 22:04:36.534298  2630 solver.cpp:218] Iteration 71500 (5.99211 iter/s, 16.6886s/100 iters), loss = 0.000591172
I0929 22:04:36.534345  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00059113 (* 1 = 0.00059113 loss)
I0929 22:04:36.534353  2630 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0929 22:04:49.995116  2630 solver.cpp:218] Iteration 71600 (7.42904 iter/s, 13.4607s/100 iters), loss = 0.00219228
I0929 22:04:49.995147  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219224 (* 1 = 0.00219224 loss)
I0929 22:04:49.995153  2630 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0929 22:05:03.448050  2630 solver.cpp:218] Iteration 71700 (7.43336 iter/s, 13.4529s/100 iters), loss = 0.00502776
I0929 22:05:03.448180  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502771 (* 1 = 0.00502771 loss)
I0929 22:05:03.448199  2630 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0929 22:05:16.899528  2630 solver.cpp:218] Iteration 71800 (7.43421 iter/s, 13.4513s/100 iters), loss = 0.00752259
I0929 22:05:16.899559  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752254 (* 1 = 0.00752254 loss)
I0929 22:05:16.899565  2630 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0929 22:05:30.361212  2630 solver.cpp:218] Iteration 71900 (7.42853 iter/s, 13.4616s/100 iters), loss = 0.00110324
I0929 22:05:30.361249  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110319 (* 1 = 0.00110319 loss)
I0929 22:05:30.361256  2630 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0929 22:05:43.162353  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:05:43.700979  2630 solver.cpp:330] Iteration 72000, Testing net (#0)
I0929 22:05:46.786506  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:05:46.915500  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I0929 22:05:46.915526  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327914 (* 1 = 0.327914 loss)
I0929 22:05:47.048961  2630 solver.cpp:218] Iteration 72000 (5.99245 iter/s, 16.6877s/100 iters), loss = 0.000728694
I0929 22:05:47.048990  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000728646 (* 1 = 0.000728646 loss)
I0929 22:05:47.048997  2630 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0929 22:06:00.497098  2630 solver.cpp:218] Iteration 72100 (7.43601 iter/s, 13.4481s/100 iters), loss = 0.00208273
I0929 22:06:00.497136  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208267 (* 1 = 0.00208267 loss)
I0929 22:06:00.497156  2630 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0929 22:06:13.958468  2630 solver.cpp:218] Iteration 72200 (7.42882 iter/s, 13.4611s/100 iters), loss = 0.0042293
I0929 22:06:13.958593  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422924 (* 1 = 0.00422924 loss)
I0929 22:06:13.958601  2630 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0929 22:06:27.421322  2630 solver.cpp:218] Iteration 72300 (7.42794 iter/s, 13.4627s/100 iters), loss = 0.00188272
I0929 22:06:27.421365  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188266 (* 1 = 0.00188266 loss)
I0929 22:06:27.421372  2630 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0929 22:06:40.881351  2630 solver.cpp:218] Iteration 72400 (7.42945 iter/s, 13.4599s/100 iters), loss = 0.0066955
I0929 22:06:40.881381  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669545 (* 1 = 0.00669545 loss)
I0929 22:06:40.881397  2630 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0929 22:06:53.664685  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:06:54.200497  2630 solver.cpp:330] Iteration 72500, Testing net (#0)
I0929 22:06:57.293174  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:06:57.425859  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0929 22:06:57.425889  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319588 (* 1 = 0.319588 loss)
I0929 22:06:57.563325  2630 solver.cpp:218] Iteration 72500 (5.99452 iter/s, 16.6819s/100 iters), loss = 0.000529093
I0929 22:06:57.563362  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000529035 (* 1 = 0.000529035 loss)
I0929 22:06:57.563370  2630 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0929 22:07:11.021039  2630 solver.cpp:218] Iteration 72600 (7.43073 iter/s, 13.4576s/100 iters), loss = 0.00219255
I0929 22:07:11.021070  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219249 (* 1 = 0.00219249 loss)
I0929 22:07:11.021086  2630 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0929 22:07:24.478291  2630 solver.cpp:218] Iteration 72700 (7.43098 iter/s, 13.4572s/100 iters), loss = 0.000725061
I0929 22:07:24.478438  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000725003 (* 1 = 0.000725003 loss)
I0929 22:07:24.478458  2630 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0929 22:07:37.930547  2630 solver.cpp:218] Iteration 72800 (7.43382 iter/s, 13.452s/100 iters), loss = 0.00154802
I0929 22:07:37.930582  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154796 (* 1 = 0.00154796 loss)
I0929 22:07:37.930589  2630 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0929 22:07:51.387464  2630 solver.cpp:218] Iteration 72900 (7.43117 iter/s, 13.4568s/100 iters), loss = 0.00178203
I0929 22:07:51.387508  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178197 (* 1 = 0.00178197 loss)
I0929 22:07:51.387517  2630 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0929 22:08:04.184415  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:08:04.721232  2630 solver.cpp:330] Iteration 73000, Testing net (#0)
I0929 22:08:07.812614  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:08:07.942121  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0929 22:08:07.942147  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323667 (* 1 = 0.323667 loss)
I0929 22:08:08.075635  2630 solver.cpp:218] Iteration 73000 (5.9923 iter/s, 16.6881s/100 iters), loss = 0.00225935
I0929 22:08:08.075664  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225929 (* 1 = 0.00225929 loss)
I0929 22:08:08.075672  2630 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0929 22:08:21.526028  2630 solver.cpp:218] Iteration 73100 (7.43477 iter/s, 13.4503s/100 iters), loss = 0.00222335
I0929 22:08:21.526064  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222329 (* 1 = 0.00222329 loss)
I0929 22:08:21.526072  2630 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0929 22:08:34.984362  2630 solver.cpp:218] Iteration 73200 (7.43038 iter/s, 13.4583s/100 iters), loss = 0.00110547
I0929 22:08:34.984493  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110541 (* 1 = 0.00110541 loss)
I0929 22:08:34.984500  2630 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0929 22:08:48.456182  2630 solver.cpp:218] Iteration 73300 (7.423 iter/s, 13.4717s/100 iters), loss = 0.00282939
I0929 22:08:48.456228  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282933 (* 1 = 0.00282933 loss)
I0929 22:08:48.456236  2630 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0929 22:09:01.914392  2630 solver.cpp:218] Iteration 73400 (7.43047 iter/s, 13.4581s/100 iters), loss = 0.00111022
I0929 22:09:01.914423  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111015 (* 1 = 0.00111015 loss)
I0929 22:09:01.914429  2630 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0929 22:09:14.703907  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:09:15.241785  2630 solver.cpp:330] Iteration 73500, Testing net (#0)
I0929 22:09:18.334956  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:09:18.468870  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0929 22:09:18.468897  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325504 (* 1 = 0.325504 loss)
I0929 22:09:18.605273  2630 solver.cpp:218] Iteration 73500 (5.99132 iter/s, 16.6908s/100 iters), loss = 0.00163459
I0929 22:09:18.605307  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163453 (* 1 = 0.00163453 loss)
I0929 22:09:18.605315  2630 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0929 22:09:32.052968  2630 solver.cpp:218] Iteration 73600 (7.43626 iter/s, 13.4476s/100 iters), loss = 0.00527649
I0929 22:09:32.052999  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527643 (* 1 = 0.00527643 loss)
I0929 22:09:32.053005  2630 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0929 22:09:45.512385  2630 solver.cpp:218] Iteration 73700 (7.42978 iter/s, 13.4593s/100 iters), loss = 0.00128616
I0929 22:09:45.512503  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128609 (* 1 = 0.00128609 loss)
I0929 22:09:45.512521  2630 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0929 22:09:58.953234  2630 solver.cpp:218] Iteration 73800 (7.44008 iter/s, 13.4407s/100 iters), loss = 0.0017288
I0929 22:09:58.953265  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172874 (* 1 = 0.00172874 loss)
I0929 22:09:58.953271  2630 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0929 22:10:12.407657  2630 solver.cpp:218] Iteration 73900 (7.43254 iter/s, 13.4544s/100 iters), loss = 0.0143298
I0929 22:10:12.407703  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143298 (* 1 = 0.0143298 loss)
I0929 22:10:12.407711  2630 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0929 22:10:25.200549  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:10:25.738061  2630 solver.cpp:330] Iteration 74000, Testing net (#0)
I0929 22:10:28.830003  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:10:28.959156  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9212
I0929 22:10:28.959190  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324931 (* 1 = 0.324931 loss)
I0929 22:10:29.092780  2630 solver.cpp:218] Iteration 74000 (5.99341 iter/s, 16.685s/100 iters), loss = 0.00337783
I0929 22:10:29.092808  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337776 (* 1 = 0.00337776 loss)
I0929 22:10:29.092814  2630 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0929 22:10:42.557965  2630 solver.cpp:218] Iteration 74100 (7.4266 iter/s, 13.4651s/100 iters), loss = 0.00158777
I0929 22:10:42.558002  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015877 (* 1 = 0.0015877 loss)
I0929 22:10:42.558010  2630 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0929 22:10:56.019052  2630 solver.cpp:218] Iteration 74200 (7.42886 iter/s, 13.461s/100 iters), loss = 0.00361046
I0929 22:10:56.019160  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361039 (* 1 = 0.00361039 loss)
I0929 22:10:56.019177  2630 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0929 22:11:09.493129  2630 solver.cpp:218] Iteration 74300 (7.42174 iter/s, 13.4739s/100 iters), loss = 0.00193792
I0929 22:11:09.493165  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193785 (* 1 = 0.00193785 loss)
I0929 22:11:09.493172  2630 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0929 22:11:22.957082  2630 solver.cpp:218] Iteration 74400 (7.42728 iter/s, 13.4639s/100 iters), loss = 0.00098414
I0929 22:11:22.957110  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000984075 (* 1 = 0.000984075 loss)
I0929 22:11:22.957118  2630 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0929 22:11:35.744992  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:11:36.283346  2630 solver.cpp:330] Iteration 74500, Testing net (#0)
I0929 22:11:39.377692  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:11:39.509552  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I0929 22:11:39.509577  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347304 (* 1 = 0.347304 loss)
I0929 22:11:39.645953  2630 solver.cpp:218] Iteration 74500 (5.99204 iter/s, 16.6888s/100 iters), loss = 0.0028585
I0929 22:11:39.645987  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285843 (* 1 = 0.00285843 loss)
I0929 22:11:39.645994  2630 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0929 22:11:53.108140  2630 solver.cpp:218] Iteration 74600 (7.42825 iter/s, 13.4621s/100 iters), loss = 0.00173488
I0929 22:11:53.108170  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173482 (* 1 = 0.00173482 loss)
I0929 22:11:53.108177  2630 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0929 22:12:06.573339  2630 solver.cpp:218] Iteration 74700 (7.42659 iter/s, 13.4651s/100 iters), loss = 0.00947189
I0929 22:12:06.573489  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00947182 (* 1 = 0.00947182 loss)
I0929 22:12:06.573509  2630 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0929 22:12:20.024672  2630 solver.cpp:218] Iteration 74800 (7.43432 iter/s, 13.4511s/100 iters), loss = 0.00596123
I0929 22:12:20.024700  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596116 (* 1 = 0.00596116 loss)
I0929 22:12:20.024706  2630 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0929 22:12:33.479112  2630 solver.cpp:218] Iteration 74900 (7.43253 iter/s, 13.4544s/100 iters), loss = 0.00274355
I0929 22:12:33.479159  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274349 (* 1 = 0.00274349 loss)
I0929 22:12:33.479167  2630 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0929 22:12:46.273710  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:12:46.811661  2630 solver.cpp:330] Iteration 75000, Testing net (#0)
I0929 22:12:49.901337  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:12:50.030293  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0929 22:12:50.030318  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322096 (* 1 = 0.322096 loss)
I0929 22:12:50.163918  2630 solver.cpp:218] Iteration 75000 (5.99352 iter/s, 16.6847s/100 iters), loss = 0.00311006
I0929 22:12:50.163946  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310999 (* 1 = 0.00310999 loss)
I0929 22:12:50.163952  2630 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0929 22:13:03.634341  2630 solver.cpp:218] Iteration 75100 (7.42371 iter/s, 13.4704s/100 iters), loss = 0.00587694
I0929 22:13:03.634376  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00587688 (* 1 = 0.00587688 loss)
I0929 22:13:03.634382  2630 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0929 22:13:17.085788  2630 solver.cpp:218] Iteration 75200 (7.43418 iter/s, 13.4514s/100 iters), loss = 0.00102918
I0929 22:13:17.085902  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102911 (* 1 = 0.00102911 loss)
I0929 22:13:17.085919  2630 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0929 22:13:30.555276  2630 solver.cpp:218] Iteration 75300 (7.42426 iter/s, 13.4693s/100 iters), loss = 0.000296881
I0929 22:13:30.555311  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000296807 (* 1 = 0.000296807 loss)
I0929 22:13:30.555320  2630 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0929 22:13:44.016374  2630 solver.cpp:218] Iteration 75400 (7.42885 iter/s, 13.461s/100 iters), loss = 0.00314074
I0929 22:13:44.016407  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314066 (* 1 = 0.00314066 loss)
I0929 22:13:44.016414  2630 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0929 22:13:56.792405  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:13:57.331985  2630 solver.cpp:330] Iteration 75500, Testing net (#0)
I0929 22:14:00.425076  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:14:00.558199  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0929 22:14:00.558226  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329592 (* 1 = 0.329592 loss)
I0929 22:14:00.692855  2630 solver.cpp:218] Iteration 75500 (5.9965 iter/s, 16.6764s/100 iters), loss = 0.00419424
I0929 22:14:00.692889  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419416 (* 1 = 0.00419416 loss)
I0929 22:14:00.692896  2630 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0929 22:14:14.153476  2630 solver.cpp:218] Iteration 75600 (7.42912 iter/s, 13.4605s/100 iters), loss = 0.00395939
I0929 22:14:14.153506  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395932 (* 1 = 0.00395932 loss)
I0929 22:14:14.153512  2630 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0929 22:14:27.623390  2630 solver.cpp:218] Iteration 75700 (7.42399 iter/s, 13.4698s/100 iters), loss = 0.0143987
I0929 22:14:27.623504  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143986 (* 1 = 0.0143986 loss)
I0929 22:14:27.623522  2630 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0929 22:14:41.075872  2630 solver.cpp:218] Iteration 75800 (7.43365 iter/s, 13.4523s/100 iters), loss = 0.00194532
I0929 22:14:41.075911  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194525 (* 1 = 0.00194525 loss)
I0929 22:14:41.075917  2630 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0929 22:14:54.532295  2630 solver.cpp:218] Iteration 75900 (7.43144 iter/s, 13.4563s/100 iters), loss = 0.0017902
I0929 22:14:54.532331  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179013 (* 1 = 0.00179013 loss)
I0929 22:14:54.532340  2630 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0929 22:15:07.320570  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:15:07.858425  2630 solver.cpp:330] Iteration 76000, Testing net (#0)
I0929 22:15:10.949026  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:15:11.078167  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I0929 22:15:11.078203  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340735 (* 1 = 0.340735 loss)
I0929 22:15:11.211688  2630 solver.cpp:218] Iteration 76000 (5.99545 iter/s, 16.6793s/100 iters), loss = 0.00128779
I0929 22:15:11.211716  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128772 (* 1 = 0.00128772 loss)
I0929 22:15:11.211724  2630 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0929 22:15:24.680589  2630 solver.cpp:218] Iteration 76100 (7.42455 iter/s, 13.4688s/100 iters), loss = 0.0015707
I0929 22:15:24.680624  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157062 (* 1 = 0.00157062 loss)
I0929 22:15:24.680631  2630 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0929 22:15:38.128983  2630 solver.cpp:218] Iteration 76200 (7.43587 iter/s, 13.4483s/100 iters), loss = 0.00134246
I0929 22:15:38.129091  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134238 (* 1 = 0.00134238 loss)
I0929 22:15:38.129098  2630 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0929 22:15:51.590240  2630 solver.cpp:218] Iteration 76300 (7.42881 iter/s, 13.4611s/100 iters), loss = 0.0019784
I0929 22:15:51.590291  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197832 (* 1 = 0.00197832 loss)
I0929 22:15:51.590297  2630 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0929 22:16:05.048099  2630 solver.cpp:218] Iteration 76400 (7.43067 iter/s, 13.4577s/100 iters), loss = 0.00258647
I0929 22:16:05.048130  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258639 (* 1 = 0.00258639 loss)
I0929 22:16:05.048136  2630 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0929 22:16:17.832238  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:16:18.371554  2630 solver.cpp:330] Iteration 76500, Testing net (#0)
I0929 22:16:21.463052  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:16:21.593395  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0929 22:16:21.593433  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338276 (* 1 = 0.338276 loss)
I0929 22:16:21.728955  2630 solver.cpp:218] Iteration 76500 (5.99492 iter/s, 16.6808s/100 iters), loss = 0.0022686
I0929 22:16:21.728989  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226851 (* 1 = 0.00226851 loss)
I0929 22:16:21.728996  2630 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0929 22:16:35.186533  2630 solver.cpp:218] Iteration 76600 (7.4308 iter/s, 13.4575s/100 iters), loss = 0.00140756
I0929 22:16:35.186565  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140747 (* 1 = 0.00140747 loss)
I0929 22:16:35.186574  2630 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0929 22:16:48.656394  2630 solver.cpp:218] Iteration 76700 (7.42402 iter/s, 13.4698s/100 iters), loss = 0.00169389
I0929 22:16:48.656512  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016938 (* 1 = 0.0016938 loss)
I0929 22:16:48.656533  2630 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0929 22:17:02.113497  2630 solver.cpp:218] Iteration 76800 (7.43109 iter/s, 13.457s/100 iters), loss = 0.00724829
I0929 22:17:02.113530  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0072482 (* 1 = 0.0072482 loss)
I0929 22:17:02.113539  2630 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0929 22:17:15.570170  2630 solver.cpp:218] Iteration 76900 (7.4313 iter/s, 13.4566s/100 iters), loss = 0.00106459
I0929 22:17:15.570214  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106449 (* 1 = 0.00106449 loss)
I0929 22:17:15.570225  2630 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0929 22:17:28.359535  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:17:28.897326  2630 solver.cpp:330] Iteration 77000, Testing net (#0)
I0929 22:17:31.986176  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:17:32.115228  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I0929 22:17:32.115257  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313792 (* 1 = 0.313792 loss)
I0929 22:17:32.248894  2630 solver.cpp:218] Iteration 77000 (5.99569 iter/s, 16.6786s/100 iters), loss = 0.000919961
I0929 22:17:32.248926  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000919864 (* 1 = 0.000919864 loss)
I0929 22:17:32.248936  2630 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0929 22:17:45.705663  2630 solver.cpp:218] Iteration 77100 (7.43124 iter/s, 13.4567s/100 iters), loss = 0.00350578
I0929 22:17:45.705700  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350568 (* 1 = 0.00350568 loss)
I0929 22:17:45.705710  2630 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0929 22:17:59.143674  2630 solver.cpp:218] Iteration 77200 (7.44162 iter/s, 13.4379s/100 iters), loss = 0.00208045
I0929 22:17:59.143822  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208036 (* 1 = 0.00208036 loss)
I0929 22:17:59.143847  2630 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0929 22:18:12.598251  2630 solver.cpp:218] Iteration 77300 (7.43251 iter/s, 13.4544s/100 iters), loss = 0.00188011
I0929 22:18:12.598291  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188002 (* 1 = 0.00188002 loss)
I0929 22:18:12.598301  2630 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0929 22:18:26.052274  2630 solver.cpp:218] Iteration 77400 (7.43276 iter/s, 13.4539s/100 iters), loss = 0.00533683
I0929 22:18:26.052309  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533674 (* 1 = 0.00533674 loss)
I0929 22:18:26.052317  2630 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0929 22:18:38.838907  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:18:39.376960  2630 solver.cpp:330] Iteration 77500, Testing net (#0)
I0929 22:18:42.465725  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:18:42.597594  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I0929 22:18:42.597625  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334232 (* 1 = 0.334232 loss)
I0929 22:18:42.732347  2630 solver.cpp:218] Iteration 77500 (5.9952 iter/s, 16.68s/100 iters), loss = 0.00190973
I0929 22:18:42.732383  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190964 (* 1 = 0.00190964 loss)
I0929 22:18:42.732393  2630 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0929 22:18:56.180472  2630 solver.cpp:218] Iteration 77600 (7.43602 iter/s, 13.4481s/100 iters), loss = 0.00217472
I0929 22:18:56.180505  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217462 (* 1 = 0.00217462 loss)
I0929 22:18:56.180513  2630 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0929 22:19:09.643656  2630 solver.cpp:218] Iteration 77700 (7.4277 iter/s, 13.4631s/100 iters), loss = 0.00631843
I0929 22:19:09.643774  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00631833 (* 1 = 0.00631833 loss)
I0929 22:19:09.643784  2630 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0929 22:19:23.096669  2630 solver.cpp:218] Iteration 77800 (7.43336 iter/s, 13.4529s/100 iters), loss = 0.0143502
I0929 22:19:23.096704  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143501 (* 1 = 0.0143501 loss)
I0929 22:19:23.096712  2630 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0929 22:19:36.549808  2630 solver.cpp:218] Iteration 77900 (7.43325 iter/s, 13.4531s/100 iters), loss = 0.00162777
I0929 22:19:36.549846  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162768 (* 1 = 0.00162768 loss)
I0929 22:19:36.549866  2630 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0929 22:19:49.343171  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:19:49.881170  2630 solver.cpp:330] Iteration 78000, Testing net (#0)
I0929 22:19:52.972160  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:19:53.100951  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I0929 22:19:53.100977  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351189 (* 1 = 0.351189 loss)
I0929 22:19:53.234711  2630 solver.cpp:218] Iteration 78000 (5.99347 iter/s, 16.6848s/100 iters), loss = 0.00391333
I0929 22:19:53.234743  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391324 (* 1 = 0.00391324 loss)
I0929 22:19:53.234753  2630 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0929 22:20:06.706476  2630 solver.cpp:218] Iteration 78100 (7.42297 iter/s, 13.4717s/100 iters), loss = 0.000496183
I0929 22:20:06.706513  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000496096 (* 1 = 0.000496096 loss)
I0929 22:20:06.706524  2630 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0929 22:20:20.154281  2630 solver.cpp:218] Iteration 78200 (7.4362 iter/s, 13.4477s/100 iters), loss = 0.00537249
I0929 22:20:20.154404  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00537241 (* 1 = 0.00537241 loss)
I0929 22:20:20.154412  2630 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0929 22:20:33.611161  2630 solver.cpp:218] Iteration 78300 (7.43123 iter/s, 13.4567s/100 iters), loss = 0.00154577
I0929 22:20:33.611198  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154568 (* 1 = 0.00154568 loss)
I0929 22:20:33.611207  2630 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0929 22:20:47.070677  2630 solver.cpp:218] Iteration 78400 (7.42973 iter/s, 13.4594s/100 iters), loss = 0.0178224
I0929 22:20:47.070716  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178223 (* 1 = 0.0178223 loss)
I0929 22:20:47.070724  2630 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0929 22:20:59.859545  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:21:00.399027  2630 solver.cpp:330] Iteration 78500, Testing net (#0)
I0929 22:21:03.488736  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:21:03.620282  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I0929 22:21:03.620312  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326143 (* 1 = 0.326143 loss)
I0929 22:21:03.755379  2630 solver.cpp:218] Iteration 78500 (5.99354 iter/s, 16.6846s/100 iters), loss = 0.00338875
I0929 22:21:03.755412  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338866 (* 1 = 0.00338866 loss)
I0929 22:21:03.755419  2630 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0929 22:21:17.214449  2630 solver.cpp:218] Iteration 78600 (7.42997 iter/s, 13.459s/100 iters), loss = 0.0120359
I0929 22:21:17.214478  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120358 (* 1 = 0.0120358 loss)
I0929 22:21:17.214484  2630 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0929 22:21:30.679482  2630 solver.cpp:218] Iteration 78700 (7.42668 iter/s, 13.465s/100 iters), loss = 0.00316161
I0929 22:21:30.679632  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316152 (* 1 = 0.00316152 loss)
I0929 22:21:30.679641  2630 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0929 22:21:44.144953  2630 solver.cpp:218] Iteration 78800 (7.4265 iter/s, 13.4653s/100 iters), loss = 0.00487438
I0929 22:21:44.144984  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487429 (* 1 = 0.00487429 loss)
I0929 22:21:44.144989  2630 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0929 22:21:57.599859  2630 solver.cpp:218] Iteration 78900 (7.43227 iter/s, 13.4548s/100 iters), loss = 0.00649245
I0929 22:21:57.599898  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00649236 (* 1 = 0.00649236 loss)
I0929 22:21:57.599906  2630 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0929 22:22:10.390156  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:22:10.928320  2630 solver.cpp:330] Iteration 79000, Testing net (#0)
I0929 22:22:14.019517  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:22:14.148684  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0929 22:22:14.148720  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338236 (* 1 = 0.338236 loss)
I0929 22:22:14.282392  2630 solver.cpp:218] Iteration 79000 (5.99432 iter/s, 16.6825s/100 iters), loss = 0.0183078
I0929 22:22:14.282420  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183077 (* 1 = 0.0183077 loss)
I0929 22:22:14.282428  2630 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0929 22:22:27.755163  2630 solver.cpp:218] Iteration 79100 (7.42241 iter/s, 13.4727s/100 iters), loss = 0.011445
I0929 22:22:27.755199  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114449 (* 1 = 0.0114449 loss)
I0929 22:22:27.755206  2630 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0929 22:22:41.215502  2630 solver.cpp:218] Iteration 79200 (7.42927 iter/s, 13.4603s/100 iters), loss = 0.00533181
I0929 22:22:41.215602  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533172 (* 1 = 0.00533172 loss)
I0929 22:22:41.215610  2630 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0929 22:22:54.683396  2630 solver.cpp:218] Iteration 79300 (7.42514 iter/s, 13.4678s/100 iters), loss = 0.00184975
I0929 22:22:54.683431  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184966 (* 1 = 0.00184966 loss)
I0929 22:22:54.683439  2630 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0929 22:23:08.141037  2630 solver.cpp:218] Iteration 79400 (7.43076 iter/s, 13.4576s/100 iters), loss = 0.0011105
I0929 22:23:08.141067  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011104 (* 1 = 0.0011104 loss)
I0929 22:23:08.141073  2630 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0929 22:23:20.931988  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:23:21.472563  2630 solver.cpp:330] Iteration 79500, Testing net (#0)
I0929 22:23:24.563995  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:23:24.694455  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I0929 22:23:24.694492  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311577 (* 1 = 0.311577 loss)
I0929 22:23:24.828150  2630 solver.cpp:218] Iteration 79500 (5.99268 iter/s, 16.687s/100 iters), loss = 0.00253842
I0929 22:23:24.828182  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253833 (* 1 = 0.00253833 loss)
I0929 22:23:24.828189  2630 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0929 22:23:38.280922  2630 solver.cpp:218] Iteration 79600 (7.43345 iter/s, 13.4527s/100 iters), loss = 0.00185276
I0929 22:23:38.280952  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185267 (* 1 = 0.00185267 loss)
I0929 22:23:38.280958  2630 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0929 22:23:51.750445  2630 solver.cpp:218] Iteration 79700 (7.42421 iter/s, 13.4695s/100 iters), loss = 0.00488589
I0929 22:23:51.750566  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0048858 (* 1 = 0.0048858 loss)
I0929 22:23:51.750586  2630 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0929 22:24:05.210067  2630 solver.cpp:218] Iteration 79800 (7.42971 iter/s, 13.4595s/100 iters), loss = 0.0057984
I0929 22:24:05.210108  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579831 (* 1 = 0.00579831 loss)
I0929 22:24:05.210114  2630 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0929 22:24:18.662760  2630 solver.cpp:218] Iteration 79900 (7.4335 iter/s, 13.4526s/100 iters), loss = 0.000978339
I0929 22:24:18.662796  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000978249 (* 1 = 0.000978249 loss)
I0929 22:24:18.662804  2630 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0929 22:24:31.452993  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:24:31.990638  2630 solver.cpp:330] Iteration 80000, Testing net (#0)
I0929 22:24:35.080049  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:24:35.208801  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I0929 22:24:35.208835  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335609 (* 1 = 0.335609 loss)
I0929 22:24:35.341756  2630 solver.cpp:218] Iteration 80000 (5.99559 iter/s, 16.6789s/100 iters), loss = 0.00106298
I0929 22:24:35.341789  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106289 (* 1 = 0.00106289 loss)
I0929 22:24:35.341795  2630 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0929 22:24:35.341799  2630 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0929 22:24:48.810250  2630 solver.cpp:218] Iteration 80100 (7.42477 iter/s, 13.4684s/100 iters), loss = 0.00427211
I0929 22:24:48.810292  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00427201 (* 1 = 0.00427201 loss)
I0929 22:24:48.810298  2630 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0929 22:25:02.266428  2630 solver.cpp:218] Iteration 80200 (7.43157 iter/s, 13.4561s/100 iters), loss = 0.0027351
I0929 22:25:02.266557  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002735 (* 1 = 0.002735 loss)
I0929 22:25:02.266566  2630 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0929 22:25:15.728703  2630 solver.cpp:218] Iteration 80300 (7.42825 iter/s, 13.4621s/100 iters), loss = 0.00140407
I0929 22:25:15.728749  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140397 (* 1 = 0.00140397 loss)
I0929 22:25:15.728757  2630 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0929 22:25:29.188210  2630 solver.cpp:218] Iteration 80400 (7.42974 iter/s, 13.4594s/100 iters), loss = 0.00183273
I0929 22:25:29.188241  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183264 (* 1 = 0.00183264 loss)
I0929 22:25:29.188246  2630 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0929 22:25:41.976223  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:25:42.517827  2630 solver.cpp:330] Iteration 80500, Testing net (#0)
I0929 22:25:45.609098  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:25:45.739940  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I0929 22:25:45.739977  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307799 (* 1 = 0.307799 loss)
I0929 22:25:45.873427  2630 solver.cpp:218] Iteration 80500 (5.99336 iter/s, 16.6851s/100 iters), loss = 0.00106304
I0929 22:25:45.873461  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106294 (* 1 = 0.00106294 loss)
I0929 22:25:45.873469  2630 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0929 22:25:59.321434  2630 solver.cpp:218] Iteration 80600 (7.43609 iter/s, 13.4479s/100 iters), loss = 0.00123655
I0929 22:25:59.321465  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123645 (* 1 = 0.00123645 loss)
I0929 22:25:59.321471  2630 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0929 22:26:12.783329  2630 solver.cpp:218] Iteration 80700 (7.42841 iter/s, 13.4618s/100 iters), loss = 0.00624651
I0929 22:26:12.783475  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624641 (* 1 = 0.00624641 loss)
I0929 22:26:12.783484  2630 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0929 22:26:26.235702  2630 solver.cpp:218] Iteration 80800 (7.43373 iter/s, 13.4522s/100 iters), loss = 0.00103769
I0929 22:26:26.235743  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103759 (* 1 = 0.00103759 loss)
I0929 22:26:26.235749  2630 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0929 22:26:39.692986  2630 solver.cpp:218] Iteration 80900 (7.43096 iter/s, 13.4572s/100 iters), loss = 0.0124815
I0929 22:26:39.693022  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124814 (* 1 = 0.0124814 loss)
I0929 22:26:39.693029  2630 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0929 22:26:52.468530  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:26:53.005892  2630 solver.cpp:330] Iteration 81000, Testing net (#0)
I0929 22:26:56.097748  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:26:56.226409  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9272
I0929 22:26:56.226444  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300738 (* 1 = 0.300738 loss)
I0929 22:26:56.360688  2630 solver.cpp:218] Iteration 81000 (5.99965 iter/s, 16.6676s/100 iters), loss = 0.0155395
I0929 22:26:56.360718  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155394 (* 1 = 0.0155394 loss)
I0929 22:26:56.360723  2630 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0929 22:27:09.837162  2630 solver.cpp:218] Iteration 81100 (7.42037 iter/s, 13.4764s/100 iters), loss = 0.00592658
I0929 22:27:09.837193  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00592647 (* 1 = 0.00592647 loss)
I0929 22:27:09.837200  2630 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0929 22:27:23.295549  2630 solver.cpp:218] Iteration 81200 (7.43035 iter/s, 13.4583s/100 iters), loss = 0.00214116
I0929 22:27:23.295711  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214105 (* 1 = 0.00214105 loss)
I0929 22:27:23.295719  2630 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0929 22:27:36.756515  2630 solver.cpp:218] Iteration 81300 (7.429 iter/s, 13.4608s/100 iters), loss = 0.000716051
I0929 22:27:36.756549  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000715945 (* 1 = 0.000715945 loss)
I0929 22:27:36.756556  2630 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0929 22:27:50.214787  2630 solver.cpp:218] Iteration 81400 (7.43041 iter/s, 13.4582s/100 iters), loss = 0.001137
I0929 22:27:50.214818  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011369 (* 1 = 0.0011369 loss)
I0929 22:27:50.214823  2630 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0929 22:28:03.009433  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:28:03.551935  2630 solver.cpp:330] Iteration 81500, Testing net (#0)
I0929 22:28:06.646484  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:28:06.776414  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9265
I0929 22:28:06.776442  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294909 (* 1 = 0.294909 loss)
I0929 22:28:06.910025  2630 solver.cpp:218] Iteration 81500 (5.98976 iter/s, 16.6952s/100 iters), loss = 0.000982311
I0929 22:28:06.910060  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000982207 (* 1 = 0.000982207 loss)
I0929 22:28:06.910068  2630 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0929 22:28:20.358996  2630 solver.cpp:218] Iteration 81600 (7.43555 iter/s, 13.4489s/100 iters), loss = 0.000528987
I0929 22:28:20.359026  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000528883 (* 1 = 0.000528883 loss)
I0929 22:28:20.359032  2630 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0929 22:28:33.823417  2630 solver.cpp:218] Iteration 81700 (7.42702 iter/s, 13.4644s/100 iters), loss = 0.00295298
I0929 22:28:33.823520  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295288 (* 1 = 0.00295288 loss)
I0929 22:28:33.823529  2630 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0929 22:28:47.278753  2630 solver.cpp:218] Iteration 81800 (7.43207 iter/s, 13.4552s/100 iters), loss = 0.00231912
I0929 22:28:47.278784  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231902 (* 1 = 0.00231902 loss)
I0929 22:28:47.278790  2630 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0929 22:29:00.741645  2630 solver.cpp:218] Iteration 81900 (7.42786 iter/s, 13.4628s/100 iters), loss = 0.00096502
I0929 22:29:00.741690  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000964918 (* 1 = 0.000964918 loss)
I0929 22:29:00.741698  2630 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0929 22:29:13.523627  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:29:14.061180  2630 solver.cpp:330] Iteration 82000, Testing net (#0)
I0929 22:29:17.152935  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:29:17.281805  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0929 22:29:17.281831  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293283 (* 1 = 0.293283 loss)
I0929 22:29:17.415725  2630 solver.cpp:218] Iteration 82000 (5.99736 iter/s, 16.674s/100 iters), loss = 0.00173578
I0929 22:29:17.415758  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173568 (* 1 = 0.00173568 loss)
I0929 22:29:17.415766  2630 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0929 22:29:30.875598  2630 solver.cpp:218] Iteration 82100 (7.42953 iter/s, 13.4598s/100 iters), loss = 0.000879848
I0929 22:29:30.875633  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000879746 (* 1 = 0.000879746 loss)
I0929 22:29:30.875640  2630 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0929 22:29:44.323261  2630 solver.cpp:218] Iteration 82200 (7.43627 iter/s, 13.4476s/100 iters), loss = 0.00148912
I0929 22:29:44.323365  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148902 (* 1 = 0.00148902 loss)
I0929 22:29:44.323381  2630 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0929 22:29:57.776424  2630 solver.cpp:218] Iteration 82300 (7.43327 iter/s, 13.453s/100 iters), loss = 0.00130197
I0929 22:29:57.776459  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130187 (* 1 = 0.00130187 loss)
I0929 22:29:57.776466  2630 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0929 22:30:11.229122  2630 solver.cpp:218] Iteration 82400 (7.43349 iter/s, 13.4526s/100 iters), loss = 0.0011078
I0929 22:30:11.229152  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011077 (* 1 = 0.0011077 loss)
I0929 22:30:11.229158  2630 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0929 22:30:24.014456  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:30:24.556659  2630 solver.cpp:330] Iteration 82500, Testing net (#0)
I0929 22:30:27.648939  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:30:27.778657  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0929 22:30:27.778693  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292408 (* 1 = 0.292408 loss)
I0929 22:30:27.912281  2630 solver.cpp:218] Iteration 82500 (5.99409 iter/s, 16.6831s/100 iters), loss = 0.0039191
I0929 22:30:27.912317  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391899 (* 1 = 0.00391899 loss)
I0929 22:30:27.912325  2630 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0929 22:30:41.371696  2630 solver.cpp:218] Iteration 82600 (7.42978 iter/s, 13.4593s/100 iters), loss = 0.001121
I0929 22:30:41.371728  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112089 (* 1 = 0.00112089 loss)
I0929 22:30:41.371734  2630 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0929 22:30:54.834794  2630 solver.cpp:218] Iteration 82700 (7.42775 iter/s, 13.463s/100 iters), loss = 0.00194912
I0929 22:30:54.834920  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194902 (* 1 = 0.00194902 loss)
I0929 22:30:54.834928  2630 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0929 22:31:08.295045  2630 solver.cpp:218] Iteration 82800 (7.42936 iter/s, 13.4601s/100 iters), loss = 0.00446817
I0929 22:31:08.295076  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446806 (* 1 = 0.00446806 loss)
I0929 22:31:08.295083  2630 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0929 22:31:21.759443  2630 solver.cpp:218] Iteration 82900 (7.42703 iter/s, 13.4643s/100 iters), loss = 0.00162937
I0929 22:31:21.759479  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162927 (* 1 = 0.00162927 loss)
I0929 22:31:21.759485  2630 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0929 22:31:34.542548  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:31:35.080380  2630 solver.cpp:330] Iteration 83000, Testing net (#0)
I0929 22:31:38.167510  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:31:38.296494  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.929
I0929 22:31:38.296530  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291302 (* 1 = 0.291302 loss)
I0929 22:31:38.430393  2630 solver.cpp:218] Iteration 83000 (5.99849 iter/s, 16.6709s/100 iters), loss = 0.00623452
I0929 22:31:38.430423  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623442 (* 1 = 0.00623442 loss)
I0929 22:31:38.430429  2630 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0929 22:31:51.898481  2630 solver.cpp:218] Iteration 83100 (7.425 iter/s, 13.468s/100 iters), loss = 0.00163703
I0929 22:31:51.898519  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163692 (* 1 = 0.00163692 loss)
I0929 22:31:51.898528  2630 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0929 22:32:05.359218  2630 solver.cpp:218] Iteration 83200 (7.42905 iter/s, 13.4607s/100 iters), loss = 0.00348836
I0929 22:32:05.359325  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348825 (* 1 = 0.00348825 loss)
I0929 22:32:05.359335  2630 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0929 22:32:18.813477  2630 solver.cpp:218] Iteration 83300 (7.43266 iter/s, 13.4541s/100 iters), loss = 0.000717066
I0929 22:32:18.813510  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000716962 (* 1 = 0.000716962 loss)
I0929 22:32:18.813518  2630 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0929 22:32:32.263435  2630 solver.cpp:218] Iteration 83400 (7.435 iter/s, 13.4499s/100 iters), loss = 0.00256331
I0929 22:32:32.263466  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025632 (* 1 = 0.0025632 loss)
I0929 22:32:32.263473  2630 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0929 22:32:45.055483  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:32:45.599892  2630 solver.cpp:330] Iteration 83500, Testing net (#0)
I0929 22:32:48.692250  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:32:48.821741  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0929 22:32:48.821766  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292396 (* 1 = 0.292396 loss)
I0929 22:32:48.955075  2630 solver.cpp:218] Iteration 83500 (5.99105 iter/s, 16.6916s/100 iters), loss = 0.000294286
I0929 22:32:48.955109  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000294178 (* 1 = 0.000294178 loss)
I0929 22:32:48.955117  2630 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0929 22:33:02.412346  2630 solver.cpp:218] Iteration 83600 (7.43096 iter/s, 13.4572s/100 iters), loss = 0.00345399
I0929 22:33:02.412379  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345389 (* 1 = 0.00345389 loss)
I0929 22:33:02.412387  2630 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0929 22:33:15.870385  2630 solver.cpp:218] Iteration 83700 (7.43054 iter/s, 13.458s/100 iters), loss = 0.00222009
I0929 22:33:15.870517  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221998 (* 1 = 0.00221998 loss)
I0929 22:33:15.870542  2630 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0929 22:33:29.323300  2630 solver.cpp:218] Iteration 83800 (7.43342 iter/s, 13.4528s/100 iters), loss = 0.00181987
I0929 22:33:29.323330  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181976 (* 1 = 0.00181976 loss)
I0929 22:33:29.323336  2630 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0929 22:33:42.785709  2630 solver.cpp:218] Iteration 83900 (7.42813 iter/s, 13.4623s/100 iters), loss = 0.000459632
I0929 22:33:42.785745  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000459522 (* 1 = 0.000459522 loss)
I0929 22:33:42.785753  2630 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0929 22:33:55.566942  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:33:56.102165  2630 solver.cpp:330] Iteration 84000, Testing net (#0)
I0929 22:33:59.185704  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:33:59.314543  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.928
I0929 22:33:59.314584  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292184 (* 1 = 0.292184 loss)
I0929 22:33:59.447062  2630 solver.cpp:218] Iteration 84000 (6.00194 iter/s, 16.6613s/100 iters), loss = 0.00135351
I0929 22:33:59.447099  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013534 (* 1 = 0.0013534 loss)
I0929 22:33:59.447108  2630 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0929 22:34:12.915894  2630 solver.cpp:218] Iteration 84100 (7.42459 iter/s, 13.4688s/100 iters), loss = 0.00148869
I0929 22:34:12.915928  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148858 (* 1 = 0.00148858 loss)
I0929 22:34:12.915935  2630 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0929 22:34:26.374598  2630 solver.cpp:218] Iteration 84200 (7.43017 iter/s, 13.4586s/100 iters), loss = 0.000592681
I0929 22:34:26.374706  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00059257 (* 1 = 0.00059257 loss)
I0929 22:34:26.374724  2630 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0929 22:34:39.831840  2630 solver.cpp:218] Iteration 84300 (7.43102 iter/s, 13.4571s/100 iters), loss = 0.00183877
I0929 22:34:39.831881  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183865 (* 1 = 0.00183865 loss)
I0929 22:34:39.831888  2630 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0929 22:34:53.285471  2630 solver.cpp:218] Iteration 84400 (7.43298 iter/s, 13.4536s/100 iters), loss = 0.0014116
I0929 22:34:53.285512  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141149 (* 1 = 0.00141149 loss)
I0929 22:34:53.285518  2630 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0929 22:35:06.079428  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:35:06.624601  2630 solver.cpp:330] Iteration 84500, Testing net (#0)
I0929 22:35:09.715030  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:35:09.844121  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0929 22:35:09.844156  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291163 (* 1 = 0.291163 loss)
I0929 22:35:09.977958  2630 solver.cpp:218] Iteration 84500 (5.99075 iter/s, 16.6924s/100 iters), loss = 0.000390299
I0929 22:35:09.977993  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000390184 (* 1 = 0.000390184 loss)
I0929 22:35:09.978000  2630 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0929 22:35:23.436786  2630 solver.cpp:218] Iteration 84600 (7.43011 iter/s, 13.4588s/100 iters), loss = 0.00567898
I0929 22:35:23.436827  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567887 (* 1 = 0.00567887 loss)
I0929 22:35:23.436833  2630 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0929 22:35:36.908078  2630 solver.cpp:218] Iteration 84700 (7.42323 iter/s, 13.4712s/100 iters), loss = 0.00252778
I0929 22:35:36.908201  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252767 (* 1 = 0.00252767 loss)
I0929 22:35:36.908218  2630 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0929 22:35:50.362272  2630 solver.cpp:218] Iteration 84800 (7.43271 iter/s, 13.454s/100 iters), loss = 0.0043772
I0929 22:35:50.362304  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437709 (* 1 = 0.00437709 loss)
I0929 22:35:50.362311  2630 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0929 22:36:03.827450  2630 solver.cpp:218] Iteration 84900 (7.4266 iter/s, 13.4651s/100 iters), loss = 0.00107586
I0929 22:36:03.827486  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107575 (* 1 = 0.00107575 loss)
I0929 22:36:03.827492  2630 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0929 22:36:16.606709  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:36:17.144549  2630 solver.cpp:330] Iteration 85000, Testing net (#0)
I0929 22:36:20.234834  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:36:20.363600  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0929 22:36:20.363636  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291804 (* 1 = 0.291804 loss)
I0929 22:36:20.497313  2630 solver.cpp:218] Iteration 85000 (5.99888 iter/s, 16.6698s/100 iters), loss = 0.000437819
I0929 22:36:20.497342  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000437708 (* 1 = 0.000437708 loss)
I0929 22:36:20.497349  2630 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0929 22:36:33.954560  2630 solver.cpp:218] Iteration 85100 (7.43098 iter/s, 13.4572s/100 iters), loss = 0.00228756
I0929 22:36:33.954594  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228745 (* 1 = 0.00228745 loss)
I0929 22:36:33.954602  2630 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0929 22:36:47.407264  2630 solver.cpp:218] Iteration 85200 (7.43349 iter/s, 13.4526s/100 iters), loss = 0.00100534
I0929 22:36:47.407404  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100522 (* 1 = 0.00100522 loss)
I0929 22:36:47.407413  2630 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0929 22:37:00.865772  2630 solver.cpp:218] Iteration 85300 (7.43034 iter/s, 13.4583s/100 iters), loss = 0.000470129
I0929 22:37:00.865804  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000470017 (* 1 = 0.000470017 loss)
I0929 22:37:00.865811  2630 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0929 22:37:14.309928  2630 solver.cpp:218] Iteration 85400 (7.43821 iter/s, 13.4441s/100 iters), loss = 0.000837705
I0929 22:37:14.309957  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000837595 (* 1 = 0.000837595 loss)
I0929 22:37:14.309964  2630 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0929 22:37:27.092633  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:37:27.637861  2630 solver.cpp:330] Iteration 85500, Testing net (#0)
I0929 22:37:30.730939  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:37:30.861351  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9289
I0929 22:37:30.861387  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291508 (* 1 = 0.291508 loss)
I0929 22:37:30.994369  2630 solver.cpp:218] Iteration 85500 (5.99363 iter/s, 16.6844s/100 iters), loss = 0.000643005
I0929 22:37:30.994405  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000642892 (* 1 = 0.000642892 loss)
I0929 22:37:30.994412  2630 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0929 22:37:44.462260  2630 solver.cpp:218] Iteration 85600 (7.42511 iter/s, 13.4678s/100 iters), loss = 0.00366717
I0929 22:37:44.462302  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366705 (* 1 = 0.00366705 loss)
I0929 22:37:44.462309  2630 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0929 22:37:57.932458  2630 solver.cpp:218] Iteration 85700 (7.42384 iter/s, 13.4701s/100 iters), loss = 0.00211951
I0929 22:37:57.932562  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211939 (* 1 = 0.00211939 loss)
I0929 22:37:57.932571  2630 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0929 22:38:11.397608  2630 solver.cpp:218] Iteration 85800 (7.42665 iter/s, 13.465s/100 iters), loss = 0.000499229
I0929 22:38:11.397640  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000499118 (* 1 = 0.000499118 loss)
I0929 22:38:11.397647  2630 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0929 22:38:24.865919  2630 solver.cpp:218] Iteration 85900 (7.42487 iter/s, 13.4682s/100 iters), loss = 0.000355514
I0929 22:38:24.865972  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000355404 (* 1 = 0.000355404 loss)
I0929 22:38:24.865978  2630 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0929 22:38:37.654819  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:38:38.192826  2630 solver.cpp:330] Iteration 86000, Testing net (#0)
I0929 22:38:41.283565  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:38:41.412323  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0929 22:38:41.412348  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290909 (* 1 = 0.290909 loss)
I0929 22:38:41.546480  2630 solver.cpp:218] Iteration 86000 (5.99503 iter/s, 16.6805s/100 iters), loss = 0.00102405
I0929 22:38:41.546510  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102394 (* 1 = 0.00102394 loss)
I0929 22:38:41.546517  2630 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0929 22:38:55.028663  2630 solver.cpp:218] Iteration 86100 (7.41723 iter/s, 13.4821s/100 iters), loss = 0.00571464
I0929 22:38:55.028697  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571453 (* 1 = 0.00571453 loss)
I0929 22:38:55.028702  2630 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0929 22:39:08.512378  2630 solver.cpp:218] Iteration 86200 (7.41639 iter/s, 13.4836s/100 iters), loss = 0.00296285
I0929 22:39:08.512503  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296274 (* 1 = 0.00296274 loss)
I0929 22:39:08.512511  2630 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0929 22:39:21.992970  2630 solver.cpp:218] Iteration 86300 (7.41816 iter/s, 13.4804s/100 iters), loss = 0.00163944
I0929 22:39:21.993003  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163932 (* 1 = 0.00163932 loss)
I0929 22:39:21.993021  2630 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0929 22:39:35.462044  2630 solver.cpp:218] Iteration 86400 (7.42445 iter/s, 13.469s/100 iters), loss = 0.00431051
I0929 22:39:35.462074  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431039 (* 1 = 0.00431039 loss)
I0929 22:39:35.462080  2630 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0929 22:39:48.269898  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:39:48.817989  2630 solver.cpp:330] Iteration 86500, Testing net (#0)
I0929 22:39:51.913442  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:39:52.042405  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9296
I0929 22:39:52.042443  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292146 (* 1 = 0.292146 loss)
I0929 22:39:52.176908  2630 solver.cpp:218] Iteration 86500 (5.98272 iter/s, 16.7148s/100 iters), loss = 0.000551042
I0929 22:39:52.176941  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000550928 (* 1 = 0.000550928 loss)
I0929 22:39:52.176949  2630 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0929 22:40:05.663926  2630 solver.cpp:218] Iteration 86600 (7.41458 iter/s, 13.4869s/100 iters), loss = 0.0017271
I0929 22:40:05.663957  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172698 (* 1 = 0.00172698 loss)
I0929 22:40:05.663964  2630 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0929 22:40:19.149958  2630 solver.cpp:218] Iteration 86700 (7.41512 iter/s, 13.486s/100 iters), loss = 0.00397659
I0929 22:40:19.150112  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397648 (* 1 = 0.00397648 loss)
I0929 22:40:19.150120  2630 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0929 22:40:32.631696  2630 solver.cpp:218] Iteration 86800 (7.41754 iter/s, 13.4816s/100 iters), loss = 0.000382474
I0929 22:40:32.631726  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000382361 (* 1 = 0.000382361 loss)
I0929 22:40:32.631731  2630 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0929 22:40:46.128931  2630 solver.cpp:218] Iteration 86900 (7.40896 iter/s, 13.4972s/100 iters), loss = 0.000698458
I0929 22:40:46.128962  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000698344 (* 1 = 0.000698344 loss)
I0929 22:40:46.128970  2630 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0929 22:40:58.940665  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:40:59.478533  2630 solver.cpp:330] Iteration 87000, Testing net (#0)
I0929 22:41:02.572777  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:41:02.701447  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9298
I0929 22:41:02.701481  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291024 (* 1 = 0.291024 loss)
I0929 22:41:02.835202  2630 solver.cpp:218] Iteration 87000 (5.9858 iter/s, 16.7062s/100 iters), loss = 0.000910554
I0929 22:41:02.835230  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00091044 (* 1 = 0.00091044 loss)
I0929 22:41:02.835237  2630 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0929 22:41:16.311533  2630 solver.cpp:218] Iteration 87100 (7.42045 iter/s, 13.4763s/100 iters), loss = 0.000268015
I0929 22:41:16.311564  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000267903 (* 1 = 0.000267903 loss)
I0929 22:41:16.311571  2630 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0929 22:41:29.782171  2630 solver.cpp:218] Iteration 87200 (7.42359 iter/s, 13.4706s/100 iters), loss = 0.000207513
I0929 22:41:29.782294  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000207399 (* 1 = 0.000207399 loss)
I0929 22:41:29.782315  2630 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0929 22:41:43.268041  2630 solver.cpp:218] Iteration 87300 (7.41525 iter/s, 13.4857s/100 iters), loss = 0.000989696
I0929 22:41:43.268074  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000989581 (* 1 = 0.000989581 loss)
I0929 22:41:43.268082  2630 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0929 22:41:56.728413  2630 solver.cpp:218] Iteration 87400 (7.42925 iter/s, 13.4603s/100 iters), loss = 0.00278908
I0929 22:41:56.728443  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278897 (* 1 = 0.00278897 loss)
I0929 22:41:56.728451  2630 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0929 22:42:09.526489  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:42:10.071976  2630 solver.cpp:330] Iteration 87500, Testing net (#0)
I0929 22:42:13.166826  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:42:13.295318  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9288
I0929 22:42:13.295346  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290939 (* 1 = 0.290939 loss)
I0929 22:42:13.428735  2630 solver.cpp:218] Iteration 87500 (5.98793 iter/s, 16.7003s/100 iters), loss = 0.000834259
I0929 22:42:13.428766  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000834144 (* 1 = 0.000834144 loss)
I0929 22:42:13.428772  2630 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0929 22:42:26.907974  2630 solver.cpp:218] Iteration 87600 (7.41885 iter/s, 13.4792s/100 iters), loss = 0.00116348
I0929 22:42:26.908015  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116336 (* 1 = 0.00116336 loss)
I0929 22:42:26.908021  2630 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0929 22:42:40.384909  2630 solver.cpp:218] Iteration 87700 (7.42013 iter/s, 13.4769s/100 iters), loss = 0.000909226
I0929 22:42:40.385054  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00090911 (* 1 = 0.00090911 loss)
I0929 22:42:40.385061  2630 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0929 22:42:53.847924  2630 solver.cpp:218] Iteration 87800 (7.42785 iter/s, 13.4629s/100 iters), loss = 0.000256995
I0929 22:42:53.847954  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000256881 (* 1 = 0.000256881 loss)
I0929 22:42:53.847960  2630 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0929 22:43:07.324826  2630 solver.cpp:218] Iteration 87900 (7.42014 iter/s, 13.4768s/100 iters), loss = 0.00158309
I0929 22:43:07.324859  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158298 (* 1 = 0.00158298 loss)
I0929 22:43:07.324867  2630 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0929 22:43:20.127111  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:43:20.665997  2630 solver.cpp:330] Iteration 88000, Testing net (#0)
I0929 22:43:23.757403  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:43:23.886476  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0929 22:43:23.886502  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291856 (* 1 = 0.291856 loss)
I0929 22:43:24.020155  2630 solver.cpp:218] Iteration 88000 (5.98973 iter/s, 16.6953s/100 iters), loss = 0.000901458
I0929 22:43:24.020184  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000901344 (* 1 = 0.000901344 loss)
I0929 22:43:24.020191  2630 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0929 22:43:37.495949  2630 solver.cpp:218] Iteration 88100 (7.42075 iter/s, 13.4757s/100 iters), loss = 0.00392521
I0929 22:43:37.495988  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039251 (* 1 = 0.0039251 loss)
I0929 22:43:37.495997  2630 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0929 22:43:50.975152  2630 solver.cpp:218] Iteration 88200 (7.41888 iter/s, 13.4791s/100 iters), loss = 0.000176434
I0929 22:43:50.975267  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000176319 (* 1 = 0.000176319 loss)
I0929 22:43:50.975286  2630 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0929 22:44:04.469733  2630 solver.cpp:218] Iteration 88300 (7.41046 iter/s, 13.4944s/100 iters), loss = 0.000693856
I0929 22:44:04.469774  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000693742 (* 1 = 0.000693742 loss)
I0929 22:44:04.469780  2630 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0929 22:44:17.946573  2630 solver.cpp:218] Iteration 88400 (7.42018 iter/s, 13.4768s/100 iters), loss = 0.00070691
I0929 22:44:17.946622  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000706798 (* 1 = 0.000706798 loss)
I0929 22:44:17.946630  2630 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0929 22:44:30.754650  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:44:31.293928  2630 solver.cpp:330] Iteration 88500, Testing net (#0)
I0929 22:44:34.385875  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:44:34.515308  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9286
I0929 22:44:34.515343  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291574 (* 1 = 0.291574 loss)
I0929 22:44:34.649113  2630 solver.cpp:218] Iteration 88500 (5.98714 iter/s, 16.7025s/100 iters), loss = 0.00110145
I0929 22:44:34.649147  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110134 (* 1 = 0.00110134 loss)
I0929 22:44:34.649155  2630 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0929 22:44:48.135407  2630 solver.cpp:218] Iteration 88600 (7.41497 iter/s, 13.4862s/100 iters), loss = 0.00208567
I0929 22:44:48.135438  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208555 (* 1 = 0.00208555 loss)
I0929 22:44:48.135445  2630 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0929 22:45:01.625063  2630 solver.cpp:218] Iteration 88700 (7.41312 iter/s, 13.4896s/100 iters), loss = 0.00141363
I0929 22:45:01.625165  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141351 (* 1 = 0.00141351 loss)
I0929 22:45:01.625174  2630 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0929 22:45:15.091547  2630 solver.cpp:218] Iteration 88800 (7.42592 iter/s, 13.4664s/100 iters), loss = 0.000438534
I0929 22:45:15.091578  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000438423 (* 1 = 0.000438423 loss)
I0929 22:45:15.091583  2630 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0929 22:45:28.581509  2630 solver.cpp:218] Iteration 88900 (7.41295 iter/s, 13.4899s/100 iters), loss = 0.00125444
I0929 22:45:28.581544  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125433 (* 1 = 0.00125433 loss)
I0929 22:45:28.581553  2630 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0929 22:45:41.385641  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:45:41.922683  2630 solver.cpp:330] Iteration 89000, Testing net (#0)
I0929 22:45:45.017102  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:45:45.146035  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9285
I0929 22:45:45.146064  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292652 (* 1 = 0.292652 loss)
I0929 22:45:45.280164  2630 solver.cpp:218] Iteration 89000 (5.98853 iter/s, 16.6986s/100 iters), loss = 0.00216001
I0929 22:45:45.280199  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215989 (* 1 = 0.00215989 loss)
I0929 22:45:45.280208  2630 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0929 22:45:58.760174  2630 solver.cpp:218] Iteration 89100 (7.41843 iter/s, 13.4799s/100 iters), loss = 0.00183888
I0929 22:45:58.760207  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183877 (* 1 = 0.00183877 loss)
I0929 22:45:58.760216  2630 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0929 22:46:12.238013  2630 solver.cpp:218] Iteration 89200 (7.41962 iter/s, 13.4778s/100 iters), loss = 0.000824868
I0929 22:46:12.238168  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000824755 (* 1 = 0.000824755 loss)
I0929 22:46:12.238190  2630 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0929 22:46:25.726832  2630 solver.cpp:218] Iteration 89300 (7.41365 iter/s, 13.4886s/100 iters), loss = 0.00389813
I0929 22:46:25.726866  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389801 (* 1 = 0.00389801 loss)
I0929 22:46:25.726876  2630 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0929 22:46:39.207188  2630 solver.cpp:218] Iteration 89400 (7.41824 iter/s, 13.4803s/100 iters), loss = 0.00101275
I0929 22:46:39.207221  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101264 (* 1 = 0.00101264 loss)
I0929 22:46:39.207240  2630 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0929 22:46:52.007266  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:46:52.546205  2630 solver.cpp:330] Iteration 89500, Testing net (#0)
I0929 22:46:55.644107  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:46:55.773685  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9294
I0929 22:46:55.773711  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291921 (* 1 = 0.291921 loss)
I0929 22:46:55.908951  2630 solver.cpp:218] Iteration 89500 (5.98742 iter/s, 16.7017s/100 iters), loss = 0.000381223
I0929 22:46:55.908984  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000381111 (* 1 = 0.000381111 loss)
I0929 22:46:55.908993  2630 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0929 22:47:09.381731  2630 solver.cpp:218] Iteration 89600 (7.42241 iter/s, 13.4727s/100 iters), loss = 0.00356288
I0929 22:47:09.381760  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356276 (* 1 = 0.00356276 loss)
I0929 22:47:09.381767  2630 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0929 22:47:22.864576  2630 solver.cpp:218] Iteration 89700 (7.41687 iter/s, 13.4828s/100 iters), loss = 0.000525518
I0929 22:47:22.864694  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000525405 (* 1 = 0.000525405 loss)
I0929 22:47:22.864701  2630 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0929 22:47:36.341801  2630 solver.cpp:218] Iteration 89800 (7.42 iter/s, 13.4771s/100 iters), loss = 0.00292468
I0929 22:47:36.341833  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292457 (* 1 = 0.00292457 loss)
I0929 22:47:36.341840  2630 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0929 22:47:49.827934  2630 solver.cpp:218] Iteration 89900 (7.41506 iter/s, 13.4861s/100 iters), loss = 0.00179093
I0929 22:47:49.827963  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179081 (* 1 = 0.00179081 loss)
I0929 22:47:49.827970  2630 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0929 22:48:02.641484  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:48:03.178795  2630 solver.cpp:330] Iteration 90000, Testing net (#0)
I0929 22:48:06.274669  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:48:06.403590  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9299
I0929 22:48:06.403616  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290116 (* 1 = 0.290116 loss)
I0929 22:48:06.537688  2630 solver.cpp:218] Iteration 90000 (5.98455 iter/s, 16.7097s/100 iters), loss = 0.00213761
I0929 22:48:06.537732  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021375 (* 1 = 0.0021375 loss)
I0929 22:48:06.537740  2630 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0929 22:48:20.013424  2630 solver.cpp:218] Iteration 90100 (7.42081 iter/s, 13.4756s/100 iters), loss = 0.0013088
I0929 22:48:20.013454  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130869 (* 1 = 0.00130869 loss)
I0929 22:48:20.013460  2630 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0929 22:48:33.479976  2630 solver.cpp:218] Iteration 90200 (7.42584 iter/s, 13.4665s/100 iters), loss = 0.00124309
I0929 22:48:33.480111  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124297 (* 1 = 0.00124297 loss)
I0929 22:48:33.480119  2630 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0929 22:48:46.966231  2630 solver.cpp:218] Iteration 90300 (7.41505 iter/s, 13.4861s/100 iters), loss = 0.00120067
I0929 22:48:46.966272  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120055 (* 1 = 0.00120055 loss)
I0929 22:48:46.966279  2630 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0929 22:49:00.434337  2630 solver.cpp:218] Iteration 90400 (7.42499 iter/s, 13.468s/100 iters), loss = 0.000904056
I0929 22:49:00.434367  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000903941 (* 1 = 0.000903941 loss)
I0929 22:49:00.434373  2630 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0929 22:49:13.244369  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:49:13.782802  2630 solver.cpp:330] Iteration 90500, Testing net (#0)
I0929 22:49:16.878856  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:49:17.007345  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9302
I0929 22:49:17.007380  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289826 (* 1 = 0.289826 loss)
I0929 22:49:17.141216  2630 solver.cpp:218] Iteration 90500 (5.98558 iter/s, 16.7068s/100 iters), loss = 0.000423118
I0929 22:49:17.141244  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000423005 (* 1 = 0.000423005 loss)
I0929 22:49:17.141250  2630 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0929 22:49:30.623329  2630 solver.cpp:218] Iteration 90600 (7.41727 iter/s, 13.482s/100 iters), loss = 0.000660422
I0929 22:49:30.623378  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000660309 (* 1 = 0.000660309 loss)
I0929 22:49:30.623386  2630 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0929 22:49:44.104429  2630 solver.cpp:218] Iteration 90700 (7.41785 iter/s, 13.481s/100 iters), loss = 0.00401399
I0929 22:49:44.104542  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401388 (* 1 = 0.00401388 loss)
I0929 22:49:44.104549  2630 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0929 22:49:57.581090  2630 solver.cpp:218] Iteration 90800 (7.42031 iter/s, 13.4765s/100 iters), loss = 0.00179078
I0929 22:49:57.581125  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179067 (* 1 = 0.00179067 loss)
I0929 22:49:57.581131  2630 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0929 22:50:11.065748  2630 solver.cpp:218] Iteration 90900 (7.41587 iter/s, 13.4846s/100 iters), loss = 0.000686614
I0929 22:50:11.065789  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000686497 (* 1 = 0.000686497 loss)
I0929 22:50:11.065795  2630 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0929 22:50:23.876631  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:50:24.415551  2630 solver.cpp:330] Iteration 91000, Testing net (#0)
I0929 22:50:27.510613  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:50:27.645015  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0929 22:50:27.645062  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29007 (* 1 = 0.29007 loss)
I0929 22:50:27.783183  2630 solver.cpp:218] Iteration 91000 (5.98181 iter/s, 16.7174s/100 iters), loss = 0.000487803
I0929 22:50:27.783221  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000487685 (* 1 = 0.000487685 loss)
I0929 22:50:27.783228  2630 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0929 22:50:41.246127  2630 solver.cpp:218] Iteration 91100 (7.42784 iter/s, 13.4629s/100 iters), loss = 0.000299492
I0929 22:50:41.246160  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000299375 (* 1 = 0.000299375 loss)
I0929 22:50:41.246167  2630 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0929 22:50:54.721809  2630 solver.cpp:218] Iteration 91200 (7.42081 iter/s, 13.4756s/100 iters), loss = 0.0034774
I0929 22:50:54.721971  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347728 (* 1 = 0.00347728 loss)
I0929 22:50:54.721992  2630 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0929 22:51:08.202545  2630 solver.cpp:218] Iteration 91300 (7.41811 iter/s, 13.4805s/100 iters), loss = 0.00285299
I0929 22:51:08.202576  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285287 (* 1 = 0.00285287 loss)
I0929 22:51:08.202582  2630 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0929 22:51:21.681927  2630 solver.cpp:218] Iteration 91400 (7.41877 iter/s, 13.4793s/100 iters), loss = 0.000919507
I0929 22:51:21.681965  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000919389 (* 1 = 0.000919389 loss)
I0929 22:51:21.681973  2630 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0929 22:51:34.481871  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:51:35.019588  2630 solver.cpp:330] Iteration 91500, Testing net (#0)
I0929 22:51:38.111922  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:51:38.240483  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0929 22:51:38.240517  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290372 (* 1 = 0.290372 loss)
I0929 22:51:38.374824  2630 solver.cpp:218] Iteration 91500 (5.9906 iter/s, 16.6928s/100 iters), loss = 0.000802188
I0929 22:51:38.374855  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00080207 (* 1 = 0.00080207 loss)
I0929 22:51:38.374861  2630 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0929 22:51:51.860395  2630 solver.cpp:218] Iteration 91600 (7.41537 iter/s, 13.4855s/100 iters), loss = 0.00335176
I0929 22:51:51.860442  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335164 (* 1 = 0.00335164 loss)
I0929 22:51:51.860450  2630 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0929 22:52:05.332970  2630 solver.cpp:218] Iteration 91700 (7.42253 iter/s, 13.4725s/100 iters), loss = 0.00129298
I0929 22:52:05.333062  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129286 (* 1 = 0.00129286 loss)
I0929 22:52:05.333079  2630 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0929 22:52:18.809631  2630 solver.cpp:218] Iteration 91800 (7.42031 iter/s, 13.4765s/100 iters), loss = 0.000663513
I0929 22:52:18.809667  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000663397 (* 1 = 0.000663397 loss)
I0929 22:52:18.809675  2630 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0929 22:52:32.282930  2630 solver.cpp:218] Iteration 91900 (7.42212 iter/s, 13.4732s/100 iters), loss = 0.000906944
I0929 22:52:32.282961  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000906828 (* 1 = 0.000906828 loss)
I0929 22:52:32.282968  2630 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0929 22:52:45.089061  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:52:45.628666  2630 solver.cpp:330] Iteration 92000, Testing net (#0)
I0929 22:52:48.727774  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:52:48.860524  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0929 22:52:48.860564  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291168 (* 1 = 0.291168 loss)
I0929 22:52:48.993803  2630 solver.cpp:218] Iteration 92000 (5.98415 iter/s, 16.7108s/100 iters), loss = 0.000600288
I0929 22:52:48.993844  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000600173 (* 1 = 0.000600173 loss)
I0929 22:52:48.993854  2630 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0929 22:53:02.471930  2630 solver.cpp:218] Iteration 92100 (7.41947 iter/s, 13.4781s/100 iters), loss = 0.00099847
I0929 22:53:02.471971  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000998355 (* 1 = 0.000998355 loss)
I0929 22:53:02.471976  2630 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0929 22:53:15.949156  2630 solver.cpp:218] Iteration 92200 (7.41997 iter/s, 13.4771s/100 iters), loss = 0.00111089
I0929 22:53:15.949280  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111078 (* 1 = 0.00111078 loss)
I0929 22:53:15.949298  2630 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0929 22:53:29.428503  2630 solver.cpp:218] Iteration 92300 (7.41884 iter/s, 13.4792s/100 iters), loss = 0.000683475
I0929 22:53:29.428534  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000683361 (* 1 = 0.000683361 loss)
I0929 22:53:29.428539  2630 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0929 22:53:42.919291  2630 solver.cpp:218] Iteration 92400 (7.4125 iter/s, 13.4907s/100 iters), loss = 0.000609684
I0929 22:53:42.919325  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00060957 (* 1 = 0.00060957 loss)
I0929 22:53:42.919333  2630 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0929 22:53:55.718628  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:53:56.256093  2630 solver.cpp:330] Iteration 92500, Testing net (#0)
I0929 22:53:59.348567  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:53:59.477474  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9306
I0929 22:53:59.477510  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290386 (* 1 = 0.290386 loss)
I0929 22:53:59.610745  2630 solver.cpp:218] Iteration 92500 (5.99112 iter/s, 16.6914s/100 iters), loss = 0.00185035
I0929 22:53:59.610774  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185023 (* 1 = 0.00185023 loss)
I0929 22:53:59.610781  2630 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0929 22:54:13.095885  2630 solver.cpp:218] Iteration 92600 (7.41561 iter/s, 13.4851s/100 iters), loss = 0.000525437
I0929 22:54:13.095917  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000525322 (* 1 = 0.000525322 loss)
I0929 22:54:13.095924  2630 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0929 22:54:26.566213  2630 solver.cpp:218] Iteration 92700 (7.42376 iter/s, 13.4703s/100 iters), loss = 0.0014012
I0929 22:54:26.566339  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140109 (* 1 = 0.00140109 loss)
I0929 22:54:26.566347  2630 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0929 22:54:40.042213  2630 solver.cpp:218] Iteration 92800 (7.42069 iter/s, 13.4758s/100 iters), loss = 0.000652248
I0929 22:54:40.042245  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000652132 (* 1 = 0.000652132 loss)
I0929 22:54:40.042253  2630 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0929 22:54:53.513466  2630 solver.cpp:218] Iteration 92900 (7.42325 iter/s, 13.4712s/100 iters), loss = 0.000478594
I0929 22:54:53.513495  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000478477 (* 1 = 0.000478477 loss)
I0929 22:54:53.513501  2630 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0929 22:55:06.331987  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:55:06.881609  2630 solver.cpp:330] Iteration 93000, Testing net (#0)
I0929 22:55:09.975353  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:55:10.104569  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9308
I0929 22:55:10.104595  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289518 (* 1 = 0.289518 loss)
I0929 22:55:10.238554  2630 solver.cpp:218] Iteration 93000 (5.97907 iter/s, 16.725s/100 iters), loss = 0.00285084
I0929 22:55:10.238586  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285072 (* 1 = 0.00285072 loss)
I0929 22:55:10.238593  2630 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0929 22:55:23.707669  2630 solver.cpp:218] Iteration 93100 (7.42443 iter/s, 13.469s/100 iters), loss = 0.000936344
I0929 22:55:23.707700  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000936226 (* 1 = 0.000936226 loss)
I0929 22:55:23.707705  2630 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0929 22:55:37.180076  2630 solver.cpp:218] Iteration 93200 (7.42262 iter/s, 13.4723s/100 iters), loss = 0.00530665
I0929 22:55:37.180181  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530654 (* 1 = 0.00530654 loss)
I0929 22:55:37.180199  2630 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0929 22:55:50.653810  2630 solver.cpp:218] Iteration 93300 (7.42192 iter/s, 13.4736s/100 iters), loss = 0.0100387
I0929 22:55:50.653851  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100386 (* 1 = 0.0100386 loss)
I0929 22:55:50.653858  2630 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0929 22:56:04.132362  2630 solver.cpp:218] Iteration 93400 (7.41924 iter/s, 13.4785s/100 iters), loss = 0.00037487
I0929 22:56:04.132417  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000374753 (* 1 = 0.000374753 loss)
I0929 22:56:04.132434  2630 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0929 22:56:16.932770  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:56:17.471505  2630 solver.cpp:330] Iteration 93500, Testing net (#0)
I0929 22:56:20.562127  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:56:20.690971  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9304
I0929 22:56:20.691007  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289622 (* 1 = 0.289622 loss)
I0929 22:56:20.824676  2630 solver.cpp:218] Iteration 93500 (5.99081 iter/s, 16.6922s/100 iters), loss = 0.00270738
I0929 22:56:20.824715  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270726 (* 1 = 0.00270726 loss)
I0929 22:56:20.824721  2630 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0929 22:56:34.291049  2630 solver.cpp:218] Iteration 93600 (7.42595 iter/s, 13.4663s/100 iters), loss = 0.00050919
I0929 22:56:34.291081  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000509073 (* 1 = 0.000509073 loss)
I0929 22:56:34.291088  2630 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0929 22:56:47.762181  2630 solver.cpp:218] Iteration 93700 (7.42332 iter/s, 13.4711s/100 iters), loss = 0.00110341
I0929 22:56:47.762315  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110329 (* 1 = 0.00110329 loss)
I0929 22:56:47.762322  2630 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0929 22:57:01.230440  2630 solver.cpp:218] Iteration 93800 (7.42496 iter/s, 13.4681s/100 iters), loss = 0.000749504
I0929 22:57:01.230471  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000749387 (* 1 = 0.000749387 loss)
I0929 22:57:01.230479  2630 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0929 22:57:14.690126  2630 solver.cpp:218] Iteration 93900 (7.42963 iter/s, 13.4596s/100 iters), loss = 0.000771402
I0929 22:57:14.690155  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000771286 (* 1 = 0.000771286 loss)
I0929 22:57:14.690162  2630 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0929 22:57:27.497730  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:57:28.046368  2630 solver.cpp:330] Iteration 94000, Testing net (#0)
I0929 22:57:31.141091  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:57:31.270007  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9303
I0929 22:57:31.270040  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289144 (* 1 = 0.289144 loss)
I0929 22:57:31.403457  2630 solver.cpp:218] Iteration 94000 (5.98327 iter/s, 16.7133s/100 iters), loss = 0.000532134
I0929 22:57:31.403488  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000532017 (* 1 = 0.000532017 loss)
I0929 22:57:31.403494  2630 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0929 22:57:44.876288  2630 solver.cpp:218] Iteration 94100 (7.42238 iter/s, 13.4728s/100 iters), loss = 0.00750429
I0929 22:57:44.876318  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750417 (* 1 = 0.00750417 loss)
I0929 22:57:44.876324  2630 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0929 22:57:58.352910  2630 solver.cpp:218] Iteration 94200 (7.42029 iter/s, 13.4766s/100 iters), loss = 0.00267241
I0929 22:57:58.353061  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026723 (* 1 = 0.0026723 loss)
I0929 22:57:58.353071  2630 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0929 22:58:11.826505  2630 solver.cpp:218] Iteration 94300 (7.42202 iter/s, 13.4734s/100 iters), loss = 0.00185648
I0929 22:58:11.826539  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185636 (* 1 = 0.00185636 loss)
I0929 22:58:11.826547  2630 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0929 22:58:25.310572  2630 solver.cpp:218] Iteration 94400 (7.4162 iter/s, 13.484s/100 iters), loss = 0.000767267
I0929 22:58:25.310614  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000767152 (* 1 = 0.000767152 loss)
I0929 22:58:25.310621  2630 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0929 22:58:38.113431  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:58:38.651656  2630 solver.cpp:330] Iteration 94500, Testing net (#0)
I0929 22:58:41.742415  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:58:41.871743  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9309
I0929 22:58:41.871779  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289175 (* 1 = 0.289175 loss)
I0929 22:58:42.005373  2630 solver.cpp:218] Iteration 94500 (5.98992 iter/s, 16.6947s/100 iters), loss = 0.0007846
I0929 22:58:42.005403  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000784484 (* 1 = 0.000784484 loss)
I0929 22:58:42.005410  2630 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0929 22:58:55.484911  2630 solver.cpp:218] Iteration 94600 (7.41869 iter/s, 13.4795s/100 iters), loss = 0.00186021
I0929 22:58:55.484941  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186009 (* 1 = 0.00186009 loss)
I0929 22:58:55.484947  2630 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0929 22:59:08.962522  2630 solver.cpp:218] Iteration 94700 (7.41975 iter/s, 13.4775s/100 iters), loss = 0.000714355
I0929 22:59:08.962630  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000714238 (* 1 = 0.000714238 loss)
I0929 22:59:08.962646  2630 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0929 22:59:22.442901  2630 solver.cpp:218] Iteration 94800 (7.41827 iter/s, 13.4802s/100 iters), loss = 0.00127973
I0929 22:59:22.442939  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127961 (* 1 = 0.00127961 loss)
I0929 22:59:22.442946  2630 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0929 22:59:35.910188  2630 solver.cpp:218] Iteration 94900 (7.42544 iter/s, 13.4672s/100 iters), loss = 0.000228316
I0929 22:59:35.910219  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000228202 (* 1 = 0.000228202 loss)
I0929 22:59:35.910235  2630 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0929 22:59:48.720330  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:59:49.262439  2630 solver.cpp:330] Iteration 95000, Testing net (#0)
I0929 22:59:52.360600  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:59:52.489361  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9308
I0929 22:59:52.489385  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289122 (* 1 = 0.289122 loss)
I0929 22:59:52.623896  2630 solver.cpp:218] Iteration 95000 (5.98314 iter/s, 16.7136s/100 iters), loss = 0.000339404
I0929 22:59:52.623929  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00033929 (* 1 = 0.00033929 loss)
I0929 22:59:52.623935  2630 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0929 23:00:06.103893  2630 solver.cpp:218] Iteration 95100 (7.41844 iter/s, 13.4799s/100 iters), loss = 0.000795116
I0929 23:00:06.103922  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000795003 (* 1 = 0.000795003 loss)
I0929 23:00:06.103929  2630 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0929 23:00:19.579519  2630 solver.cpp:218] Iteration 95200 (7.42084 iter/s, 13.4756s/100 iters), loss = 0.0010037
I0929 23:00:19.579615  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100358 (* 1 = 0.00100358 loss)
I0929 23:00:19.579632  2630 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0929 23:00:33.049891  2630 solver.cpp:218] Iteration 95300 (7.42377 iter/s, 13.4702s/100 iters), loss = 0.000696038
I0929 23:00:33.049926  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000695924 (* 1 = 0.000695924 loss)
I0929 23:00:33.049933  2630 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0929 23:00:46.542362  2630 solver.cpp:218] Iteration 95400 (7.41158 iter/s, 13.4924s/100 iters), loss = 0.000750083
I0929 23:00:46.542408  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00074997 (* 1 = 0.00074997 loss)
I0929 23:00:46.542415  2630 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0929 23:00:59.359032  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:00:59.897130  2630 solver.cpp:330] Iteration 95500, Testing net (#0)
I0929 23:01:02.990514  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:01:03.119565  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.93
I0929 23:01:03.119601  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.2896 (* 1 = 0.2896 loss)
I0929 23:01:03.253803  2630 solver.cpp:218] Iteration 95500 (5.98396 iter/s, 16.7114s/100 iters), loss = 0.000606395
I0929 23:01:03.253834  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000606283 (* 1 = 0.000606283 loss)
I0929 23:01:03.253841  2630 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0929 23:01:16.731942  2630 solver.cpp:218] Iteration 95600 (7.41946 iter/s, 13.4781s/100 iters), loss = 0.00279843
I0929 23:01:16.731982  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279832 (* 1 = 0.00279832 loss)
I0929 23:01:16.731988  2630 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0929 23:01:30.205699  2630 solver.cpp:218] Iteration 95700 (7.42187 iter/s, 13.4737s/100 iters), loss = 0.00161562
I0929 23:01:30.205811  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161551 (* 1 = 0.00161551 loss)
I0929 23:01:30.205818  2630 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0929 23:01:43.687358  2630 solver.cpp:218] Iteration 95800 (7.41756 iter/s, 13.4815s/100 iters), loss = 0.000520872
I0929 23:01:43.687399  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000520761 (* 1 = 0.000520761 loss)
I0929 23:01:43.687405  2630 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0929 23:01:57.155231  2630 solver.cpp:218] Iteration 95900 (7.42512 iter/s, 13.4678s/100 iters), loss = 0.000498414
I0929 23:01:57.155263  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000498303 (* 1 = 0.000498303 loss)
I0929 23:01:57.155269  2630 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0929 23:02:09.963419  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:02:10.502100  2630 solver.cpp:330] Iteration 96000, Testing net (#0)
I0929 23:02:13.598412  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:02:13.727993  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9305
I0929 23:02:13.728019  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290039 (* 1 = 0.290039 loss)
I0929 23:02:13.861881  2630 solver.cpp:218] Iteration 96000 (5.98567 iter/s, 16.7066s/100 iters), loss = 0.000662093
I0929 23:02:13.861912  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000661981 (* 1 = 0.000661981 loss)
I0929 23:02:13.861919  2630 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0929 23:02:27.349925  2630 solver.cpp:218] Iteration 96100 (7.41401 iter/s, 13.488s/100 iters), loss = 0.00190327
I0929 23:02:27.349964  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190316 (* 1 = 0.00190316 loss)
I0929 23:02:27.349972  2630 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0929 23:02:40.832396  2630 solver.cpp:218] Iteration 96200 (7.41708 iter/s, 13.4824s/100 iters), loss = 0.000394709
I0929 23:02:40.832511  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000394597 (* 1 = 0.000394597 loss)
I0929 23:02:40.832518  2630 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0929 23:02:54.308316  2630 solver.cpp:218] Iteration 96300 (7.42072 iter/s, 13.4758s/100 iters), loss = 0.000810375
I0929 23:02:54.308357  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000810265 (* 1 = 0.000810265 loss)
I0929 23:02:54.308364  2630 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0929 23:03:07.812376  2630 solver.cpp:218] Iteration 96400 (7.40522 iter/s, 13.504s/100 iters), loss = 0.00213246
I0929 23:03:07.812418  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213235 (* 1 = 0.00213235 loss)
I0929 23:03:07.812425  2630 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0929 23:03:20.631724  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:03:21.170250  2630 solver.cpp:330] Iteration 96500, Testing net (#0)
I0929 23:03:24.264171  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:03:24.393077  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.931
I0929 23:03:24.393113  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291188 (* 1 = 0.291188 loss)
I0929 23:03:24.527029  2630 solver.cpp:218] Iteration 96500 (5.9828 iter/s, 16.7146s/100 iters), loss = 0.000429667
I0929 23:03:24.527058  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000429555 (* 1 = 0.000429555 loss)
I0929 23:03:24.527065  2630 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0929 23:03:38.011059  2630 solver.cpp:218] Iteration 96600 (7.41622 iter/s, 13.484s/100 iters), loss = 0.000343388
I0929 23:03:38.011101  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000343275 (* 1 = 0.000343275 loss)
I0929 23:03:38.011107  2630 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0929 23:03:51.491921  2630 solver.cpp:218] Iteration 96700 (7.41796 iter/s, 13.4808s/100 iters), loss = 0.000288789
I0929 23:03:51.491994  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000288676 (* 1 = 0.000288676 loss)
I0929 23:03:51.492002  2630 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0929 23:04:04.992269  2630 solver.cpp:218] Iteration 96800 (7.40727 iter/s, 13.5002s/100 iters), loss = 0.00131397
I0929 23:04:04.992311  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131386 (* 1 = 0.00131386 loss)
I0929 23:04:04.992318  2630 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0929 23:04:18.472928  2630 solver.cpp:218] Iteration 96900 (7.41808 iter/s, 13.4806s/100 iters), loss = 0.000382875
I0929 23:04:18.472968  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000382762 (* 1 = 0.000382762 loss)
I0929 23:04:18.472975  2630 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0929 23:04:31.290432  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:04:31.828771  2630 solver.cpp:330] Iteration 97000, Testing net (#0)
I0929 23:04:34.925159  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:04:35.054457  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9307
I0929 23:04:35.054482  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291053 (* 1 = 0.291053 loss)
I0929 23:04:35.188294  2630 solver.cpp:218] Iteration 97000 (5.98255 iter/s, 16.7153s/100 iters), loss = 0.00191538
I0929 23:04:35.188325  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191527 (* 1 = 0.00191527 loss)
I0929 23:04:35.188331  2630 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0929 23:04:48.668643  2630 solver.cpp:218] Iteration 97100 (7.41824 iter/s, 13.4803s/100 iters), loss = 0.000828532
I0929 23:04:48.668689  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000828419 (* 1 = 0.000828419 loss)
I0929 23:04:48.668695  2630 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0929 23:05:02.151847  2630 solver.cpp:218] Iteration 97200 (7.41669 iter/s, 13.4831s/100 iters), loss = 0.00136726
I0929 23:05:02.151958  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136714 (* 1 = 0.00136714 loss)
I0929 23:05:02.151965  2630 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0929 23:05:15.625990  2630 solver.cpp:218] Iteration 97300 (7.4217 iter/s, 13.474s/100 iters), loss = 0.000417956
I0929 23:05:15.626021  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000417843 (* 1 = 0.000417843 loss)
I0929 23:05:15.626029  2630 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0929 23:05:29.115303  2630 solver.cpp:218] Iteration 97400 (7.41331 iter/s, 13.4893s/100 iters), loss = 0.00135811
I0929 23:05:29.115336  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001358 (* 1 = 0.001358 loss)
I0929 23:05:29.115342  2630 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0929 23:05:41.929994  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:05:42.469724  2630 solver.cpp:330] Iteration 97500, Testing net (#0)
I0929 23:05:45.563143  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:05:45.693317  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9299
I0929 23:05:45.693344  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291679 (* 1 = 0.291679 loss)
I0929 23:05:45.829651  2630 solver.cpp:218] Iteration 97500 (5.98291 iter/s, 16.7143s/100 iters), loss = 0.000750603
I0929 23:05:45.829720  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000750491 (* 1 = 0.000750491 loss)
I0929 23:05:45.829727  2630 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0929 23:05:59.296847  2630 solver.cpp:218] Iteration 97600 (7.42561 iter/s, 13.4669s/100 iters), loss = 0.00159765
I0929 23:05:59.296890  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159754 (* 1 = 0.00159754 loss)
I0929 23:05:59.296895  2630 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0929 23:06:12.766563  2630 solver.cpp:218] Iteration 97700 (7.4241 iter/s, 13.4696s/100 iters), loss = 0.000689144
I0929 23:06:12.766687  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000689033 (* 1 = 0.000689033 loss)
I0929 23:06:12.766706  2630 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0929 23:06:26.245414  2630 solver.cpp:218] Iteration 97800 (7.41911 iter/s, 13.4787s/100 iters), loss = 0.00242629
I0929 23:06:26.245455  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242618 (* 1 = 0.00242618 loss)
I0929 23:06:26.245461  2630 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0929 23:06:39.715770  2630 solver.cpp:218] Iteration 97900 (7.42375 iter/s, 13.4703s/100 iters), loss = 0.00032611
I0929 23:06:39.715806  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000326 (* 1 = 0.000326 loss)
I0929 23:06:39.715812  2630 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0929 23:06:52.527330  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:06:53.064980  2630 solver.cpp:330] Iteration 98000, Testing net (#0)
I0929 23:06:56.159268  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:06:56.288020  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9304
I0929 23:06:56.288046  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290886 (* 1 = 0.290886 loss)
I0929 23:06:56.421983  2630 solver.cpp:218] Iteration 98000 (5.98582 iter/s, 16.7061s/100 iters), loss = 0.000270993
I0929 23:06:56.422015  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000270883 (* 1 = 0.000270883 loss)
I0929 23:06:56.422034  2630 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0929 23:07:09.917469  2630 solver.cpp:218] Iteration 98100 (7.40992 iter/s, 13.4954s/100 iters), loss = 0.00126885
I0929 23:07:09.917505  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126874 (* 1 = 0.00126874 loss)
I0929 23:07:09.917512  2630 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0929 23:07:23.402784  2630 solver.cpp:218] Iteration 98200 (7.41551 iter/s, 13.4852s/100 iters), loss = 0.00282098
I0929 23:07:23.402886  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282087 (* 1 = 0.00282087 loss)
I0929 23:07:23.402904  2630 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0929 23:07:36.880511  2630 solver.cpp:218] Iteration 98300 (7.41972 iter/s, 13.4776s/100 iters), loss = 0.00086783
I0929 23:07:36.880548  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00086772 (* 1 = 0.00086772 loss)
I0929 23:07:36.880555  2630 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0929 23:07:50.361521  2630 solver.cpp:218] Iteration 98400 (7.41788 iter/s, 13.4809s/100 iters), loss = 0.000345609
I0929 23:07:50.361552  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000345498 (* 1 = 0.000345498 loss)
I0929 23:07:50.361557  2630 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0929 23:08:03.175444  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:08:03.716609  2630 solver.cpp:330] Iteration 98500, Testing net (#0)
I0929 23:08:06.815021  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:08:06.947895  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9305
I0929 23:08:06.947921  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291514 (* 1 = 0.291514 loss)
I0929 23:08:07.081128  2630 solver.cpp:218] Iteration 98500 (5.98103 iter/s, 16.7195s/100 iters), loss = 0.000964717
I0929 23:08:07.081161  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000964606 (* 1 = 0.000964606 loss)
I0929 23:08:07.081168  2630 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0929 23:08:20.551893  2630 solver.cpp:218] Iteration 98600 (7.42352 iter/s, 13.4707s/100 iters), loss = 0.00035293
I0929 23:08:20.551930  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000352818 (* 1 = 0.000352818 loss)
I0929 23:08:20.551939  2630 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0929 23:08:34.041427  2630 solver.cpp:218] Iteration 98700 (7.41319 iter/s, 13.4895s/100 iters), loss = 0.00171353
I0929 23:08:34.041548  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171342 (* 1 = 0.00171342 loss)
I0929 23:08:34.041558  2630 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0929 23:08:47.524405  2630 solver.cpp:218] Iteration 98800 (7.41684 iter/s, 13.4828s/100 iters), loss = 0.00128997
I0929 23:08:47.524442  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128986 (* 1 = 0.00128986 loss)
I0929 23:08:47.524449  2630 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0929 23:09:01.010957  2630 solver.cpp:218] Iteration 98900 (7.41483 iter/s, 13.4865s/100 iters), loss = 0.000419254
I0929 23:09:01.010992  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00041914 (* 1 = 0.00041914 loss)
I0929 23:09:01.010998  2630 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0929 23:09:13.816653  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:09:14.353528  2630 solver.cpp:330] Iteration 99000, Testing net (#0)
I0929 23:09:17.447435  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:09:17.578243  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9312
I0929 23:09:17.578269  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290551 (* 1 = 0.290551 loss)
I0929 23:09:17.711551  2630 solver.cpp:218] Iteration 99000 (5.98784 iter/s, 16.7005s/100 iters), loss = 0.000462247
I0929 23:09:17.711578  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000462132 (* 1 = 0.000462132 loss)
I0929 23:09:17.711585  2630 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0929 23:09:31.189520  2630 solver.cpp:218] Iteration 99100 (7.41955 iter/s, 13.4779s/100 iters), loss = 0.00188695
I0929 23:09:31.189553  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188683 (* 1 = 0.00188683 loss)
I0929 23:09:31.189560  2630 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0929 23:09:44.658440  2630 solver.cpp:218] Iteration 99200 (7.42454 iter/s, 13.4689s/100 iters), loss = 0.000668704
I0929 23:09:44.658545  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000668589 (* 1 = 0.000668589 loss)
I0929 23:09:44.658552  2630 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0929 23:09:58.129029  2630 solver.cpp:218] Iteration 99300 (7.42365 iter/s, 13.4705s/100 iters), loss = 0.000517938
I0929 23:09:58.129061  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000517823 (* 1 = 0.000517823 loss)
I0929 23:09:58.129068  2630 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0929 23:10:11.598139  2630 solver.cpp:218] Iteration 99400 (7.42443 iter/s, 13.469s/100 iters), loss = 0.00152458
I0929 23:10:11.598179  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152446 (* 1 = 0.00152446 loss)
I0929 23:10:11.598186  2630 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0929 23:10:24.394615  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:10:24.941614  2630 solver.cpp:330] Iteration 99500, Testing net (#0)
I0929 23:10:28.038841  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:10:28.167790  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9312
I0929 23:10:28.167817  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290604 (* 1 = 0.290604 loss)
I0929 23:10:28.301601  2630 solver.cpp:218] Iteration 99500 (5.98681 iter/s, 16.7034s/100 iters), loss = 0.000305039
I0929 23:10:28.301633  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000304926 (* 1 = 0.000304926 loss)
I0929 23:10:28.301641  2630 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0929 23:10:41.774462  2630 solver.cpp:218] Iteration 99600 (7.42236 iter/s, 13.4728s/100 iters), loss = 0.000516688
I0929 23:10:41.774492  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000516577 (* 1 = 0.000516577 loss)
I0929 23:10:41.774497  2630 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0929 23:10:55.259774  2630 solver.cpp:218] Iteration 99700 (7.41551 iter/s, 13.4852s/100 iters), loss = 0.000947928
I0929 23:10:55.259894  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000947816 (* 1 = 0.000947816 loss)
I0929 23:10:55.259912  2630 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0929 23:11:08.741904  2630 solver.cpp:218] Iteration 99800 (7.4173 iter/s, 13.482s/100 iters), loss = 0.00063881
I0929 23:11:08.741933  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000638698 (* 1 = 0.000638698 loss)
I0929 23:11:08.741940  2630 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0929 23:11:22.222133  2630 solver.cpp:218] Iteration 99900 (7.41831 iter/s, 13.4802s/100 iters), loss = 0.000531651
I0929 23:11:22.222177  2630 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000531538 (* 1 = 0.000531538 loss)
I0929 23:11:22.222184  2630 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0929 23:11:35.024839  2636 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:11:35.562258  2630 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_relu_msra_iter_100000.caffemodel
I0929 23:11:35.583247  2630 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_relu_msra_iter_100000.solverstate
I0929 23:11:35.620795  2630 solver.cpp:310] Iteration 100000, loss = 0.00040484
I0929 23:11:35.620816  2630 solver.cpp:330] Iteration 100000, Testing net (#0)
I0929 23:11:38.711722  2637 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:11:38.840557  2630 solver.cpp:397]     Test net output #0: Accuracy1 = 0.93
I0929 23:11:38.840592  2630 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291759 (* 1 = 0.291759 loss)
I0929 23:11:38.840598  2630 solver.cpp:315] Optimization Done.
I0929 23:11:38.840600  2630 caffe.cpp:259] Optimization Done.
