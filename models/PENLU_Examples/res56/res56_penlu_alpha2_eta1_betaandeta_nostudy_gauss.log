I0926 22:37:43.992570  2459 caffe.cpp:218] Using GPUs 0
I0926 22:37:44.198416  2459 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0926 22:37:46.371470  2459 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_betaandeta_nostudy_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0926 22:37:46.475963  2459 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 22:37:46.550164  2459 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 22:37:46.550184  2459 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0926 22:37:46.587702  2459 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0926 22:37:46.587828  2459 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0926 22:37:46.589159  2459 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std
I0926 22:37:46.590324  2459 layer_factory.hpp:77] Creating layer Data1
I0926 22:37:46.833302  2459 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0926 22:37:46.921911  2459 net.cpp:84] Creating Layer Data1
I0926 22:37:46.921932  2459 net.cpp:380] Data1 -> Data1
I0926 22:37:46.957484  2459 net.cpp:380] Data1 -> Data2
I0926 22:37:46.957505  2459 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0926 22:37:47.033345  2459 data_layer.cpp:45] output data size: 100,3,28,28
I0926 22:37:47.037163  2459 net.cpp:122] Setting up Data1
I0926 22:37:47.037191  2459 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0926 22:37:47.037204  2459 net.cpp:129] Top shape: 100 (100)
I0926 22:37:47.037212  2459 net.cpp:137] Memory required for data: 941200
I0926 22:37:47.037228  2459 layer_factory.hpp:77] Creating layer Convolution1
I0926 22:37:47.062036  2459 net.cpp:84] Creating Layer Convolution1
I0926 22:37:47.062048  2459 net.cpp:406] Convolution1 <- Data1
I0926 22:37:47.062063  2459 net.cpp:380] Convolution1 -> Convolution1
I0926 22:37:52.221974  2459 net.cpp:122] Setting up Convolution1
I0926 22:37:52.221997  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.222000  2459 net.cpp:137] Memory required for data: 5958800
I0926 22:37:52.222015  2459 layer_factory.hpp:77] Creating layer BatchNorm1
I0926 22:37:52.222025  2459 net.cpp:84] Creating Layer BatchNorm1
I0926 22:37:52.222030  2459 net.cpp:406] BatchNorm1 <- Convolution1
I0926 22:37:52.222056  2459 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0926 22:37:52.222198  2459 net.cpp:122] Setting up BatchNorm1
I0926 22:37:52.222204  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.222206  2459 net.cpp:137] Memory required for data: 10976400
I0926 22:37:52.222214  2459 layer_factory.hpp:77] Creating layer Scale1
I0926 22:37:52.222223  2459 net.cpp:84] Creating Layer Scale1
I0926 22:37:52.222225  2459 net.cpp:406] Scale1 <- Convolution1
I0926 22:37:52.222239  2459 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0926 22:37:52.222278  2459 layer_factory.hpp:77] Creating layer Scale1
I0926 22:37:52.247417  2459 net.cpp:122] Setting up Scale1
I0926 22:37:52.247431  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.247433  2459 net.cpp:137] Memory required for data: 15994000
I0926 22:37:52.247438  2459 layer_factory.hpp:77] Creating layer penlu1
I0926 22:37:52.247450  2459 net.cpp:84] Creating Layer penlu1
I0926 22:37:52.247453  2459 net.cpp:406] penlu1 <- Convolution1
I0926 22:37:52.247458  2459 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0926 22:37:52.248189  2459 net.cpp:122] Setting up penlu1
I0926 22:37:52.248201  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.248217  2459 net.cpp:137] Memory required for data: 21011600
I0926 22:37:52.248231  2459 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0926 22:37:52.284608  2459 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0926 22:37:52.284620  2459 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0926 22:37:52.284626  2459 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0926 22:37:52.284632  2459 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0926 22:37:52.284667  2459 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0926 22:37:52.284674  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.284677  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.284680  2459 net.cpp:137] Memory required for data: 31046800
I0926 22:37:52.284682  2459 layer_factory.hpp:77] Creating layer Convolution2
I0926 22:37:52.284692  2459 net.cpp:84] Creating Layer Convolution2
I0926 22:37:52.284694  2459 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0926 22:37:52.284698  2459 net.cpp:380] Convolution2 -> Convolution2
I0926 22:37:52.312840  2459 net.cpp:122] Setting up Convolution2
I0926 22:37:52.312853  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.312856  2459 net.cpp:137] Memory required for data: 36064400
I0926 22:37:52.312862  2459 layer_factory.hpp:77] Creating layer BatchNorm2
I0926 22:37:52.312870  2459 net.cpp:84] Creating Layer BatchNorm2
I0926 22:37:52.312872  2459 net.cpp:406] BatchNorm2 <- Convolution2
I0926 22:37:52.312876  2459 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0926 22:37:52.313017  2459 net.cpp:122] Setting up BatchNorm2
I0926 22:37:52.313024  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.313026  2459 net.cpp:137] Memory required for data: 41082000
I0926 22:37:52.313031  2459 layer_factory.hpp:77] Creating layer Scale2
I0926 22:37:52.313038  2459 net.cpp:84] Creating Layer Scale2
I0926 22:37:52.313040  2459 net.cpp:406] Scale2 <- Convolution2
I0926 22:37:52.313045  2459 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0926 22:37:52.313076  2459 layer_factory.hpp:77] Creating layer Scale2
I0926 22:37:52.313155  2459 net.cpp:122] Setting up Scale2
I0926 22:37:52.313161  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.313163  2459 net.cpp:137] Memory required for data: 46099600
I0926 22:37:52.313170  2459 layer_factory.hpp:77] Creating layer penlu2
I0926 22:37:52.313176  2459 net.cpp:84] Creating Layer penlu2
I0926 22:37:52.313179  2459 net.cpp:406] penlu2 <- Convolution2
I0926 22:37:52.313184  2459 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0926 22:37:52.313288  2459 net.cpp:122] Setting up penlu2
I0926 22:37:52.313294  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.313308  2459 net.cpp:137] Memory required for data: 51117200
I0926 22:37:52.313313  2459 layer_factory.hpp:77] Creating layer Convolution3
I0926 22:37:52.313320  2459 net.cpp:84] Creating Layer Convolution3
I0926 22:37:52.313324  2459 net.cpp:406] Convolution3 <- Convolution2
I0926 22:37:52.313328  2459 net.cpp:380] Convolution3 -> Convolution3
I0926 22:37:52.314282  2459 net.cpp:122] Setting up Convolution3
I0926 22:37:52.314293  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.314296  2459 net.cpp:137] Memory required for data: 56134800
I0926 22:37:52.314301  2459 layer_factory.hpp:77] Creating layer BatchNorm3
I0926 22:37:52.314306  2459 net.cpp:84] Creating Layer BatchNorm3
I0926 22:37:52.314308  2459 net.cpp:406] BatchNorm3 <- Convolution3
I0926 22:37:52.314322  2459 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0926 22:37:52.314469  2459 net.cpp:122] Setting up BatchNorm3
I0926 22:37:52.314474  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.314477  2459 net.cpp:137] Memory required for data: 61152400
I0926 22:37:52.314481  2459 layer_factory.hpp:77] Creating layer Scale3
I0926 22:37:52.314486  2459 net.cpp:84] Creating Layer Scale3
I0926 22:37:52.314488  2459 net.cpp:406] Scale3 <- Convolution3
I0926 22:37:52.314491  2459 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0926 22:37:52.314550  2459 layer_factory.hpp:77] Creating layer Scale3
I0926 22:37:52.314666  2459 net.cpp:122] Setting up Scale3
I0926 22:37:52.314671  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.314673  2459 net.cpp:137] Memory required for data: 66170000
I0926 22:37:52.314677  2459 layer_factory.hpp:77] Creating layer Eltwise1
I0926 22:37:52.314682  2459 net.cpp:84] Creating Layer Eltwise1
I0926 22:37:52.314684  2459 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0926 22:37:52.314687  2459 net.cpp:406] Eltwise1 <- Convolution3
I0926 22:37:52.314690  2459 net.cpp:380] Eltwise1 -> Eltwise1
I0926 22:37:52.314731  2459 net.cpp:122] Setting up Eltwise1
I0926 22:37:52.314744  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.314746  2459 net.cpp:137] Memory required for data: 71187600
I0926 22:37:52.314749  2459 layer_factory.hpp:77] Creating layer penlu3
I0926 22:37:52.314764  2459 net.cpp:84] Creating Layer penlu3
I0926 22:37:52.314766  2459 net.cpp:406] penlu3 <- Eltwise1
I0926 22:37:52.314770  2459 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0926 22:37:52.314901  2459 net.cpp:122] Setting up penlu3
I0926 22:37:52.314906  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.314908  2459 net.cpp:137] Memory required for data: 76205200
I0926 22:37:52.314913  2459 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0926 22:37:52.314916  2459 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0926 22:37:52.314918  2459 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0926 22:37:52.314921  2459 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0926 22:37:52.314936  2459 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0926 22:37:52.314968  2459 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0926 22:37:52.314972  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.314975  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.314977  2459 net.cpp:137] Memory required for data: 86240400
I0926 22:37:52.314980  2459 layer_factory.hpp:77] Creating layer Convolution4
I0926 22:37:52.314987  2459 net.cpp:84] Creating Layer Convolution4
I0926 22:37:52.314990  2459 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0926 22:37:52.315003  2459 net.cpp:380] Convolution4 -> Convolution4
I0926 22:37:52.315917  2459 net.cpp:122] Setting up Convolution4
I0926 22:37:52.315927  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.315929  2459 net.cpp:137] Memory required for data: 91258000
I0926 22:37:52.315934  2459 layer_factory.hpp:77] Creating layer BatchNorm4
I0926 22:37:52.315939  2459 net.cpp:84] Creating Layer BatchNorm4
I0926 22:37:52.315949  2459 net.cpp:406] BatchNorm4 <- Convolution4
I0926 22:37:52.315955  2459 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0926 22:37:52.316078  2459 net.cpp:122] Setting up BatchNorm4
I0926 22:37:52.316083  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.316087  2459 net.cpp:137] Memory required for data: 96275600
I0926 22:37:52.316094  2459 layer_factory.hpp:77] Creating layer Scale4
I0926 22:37:52.316099  2459 net.cpp:84] Creating Layer Scale4
I0926 22:37:52.316102  2459 net.cpp:406] Scale4 <- Convolution4
I0926 22:37:52.316105  2459 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0926 22:37:52.316133  2459 layer_factory.hpp:77] Creating layer Scale4
I0926 22:37:52.316212  2459 net.cpp:122] Setting up Scale4
I0926 22:37:52.316222  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.316224  2459 net.cpp:137] Memory required for data: 101293200
I0926 22:37:52.316228  2459 layer_factory.hpp:77] Creating layer penlu4
I0926 22:37:52.316234  2459 net.cpp:84] Creating Layer penlu4
I0926 22:37:52.316237  2459 net.cpp:406] penlu4 <- Convolution4
I0926 22:37:52.316241  2459 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0926 22:37:52.316347  2459 net.cpp:122] Setting up penlu4
I0926 22:37:52.316352  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.316355  2459 net.cpp:137] Memory required for data: 106310800
I0926 22:37:52.316359  2459 layer_factory.hpp:77] Creating layer Convolution5
I0926 22:37:52.316365  2459 net.cpp:84] Creating Layer Convolution5
I0926 22:37:52.316367  2459 net.cpp:406] Convolution5 <- Convolution4
I0926 22:37:52.316383  2459 net.cpp:380] Convolution5 -> Convolution5
I0926 22:37:52.317276  2459 net.cpp:122] Setting up Convolution5
I0926 22:37:52.317286  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.317289  2459 net.cpp:137] Memory required for data: 111328400
I0926 22:37:52.317293  2459 layer_factory.hpp:77] Creating layer BatchNorm5
I0926 22:37:52.317298  2459 net.cpp:84] Creating Layer BatchNorm5
I0926 22:37:52.317312  2459 net.cpp:406] BatchNorm5 <- Convolution5
I0926 22:37:52.317317  2459 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0926 22:37:52.317467  2459 net.cpp:122] Setting up BatchNorm5
I0926 22:37:52.317472  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.317474  2459 net.cpp:137] Memory required for data: 116346000
I0926 22:37:52.317479  2459 layer_factory.hpp:77] Creating layer Scale5
I0926 22:37:52.317484  2459 net.cpp:84] Creating Layer Scale5
I0926 22:37:52.317487  2459 net.cpp:406] Scale5 <- Convolution5
I0926 22:37:52.317490  2459 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0926 22:37:52.317535  2459 layer_factory.hpp:77] Creating layer Scale5
I0926 22:37:52.317627  2459 net.cpp:122] Setting up Scale5
I0926 22:37:52.317632  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.317634  2459 net.cpp:137] Memory required for data: 121363600
I0926 22:37:52.317638  2459 layer_factory.hpp:77] Creating layer Eltwise2
I0926 22:37:52.317643  2459 net.cpp:84] Creating Layer Eltwise2
I0926 22:37:52.317657  2459 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0926 22:37:52.317662  2459 net.cpp:406] Eltwise2 <- Convolution5
I0926 22:37:52.317664  2459 net.cpp:380] Eltwise2 -> Eltwise2
I0926 22:37:52.317699  2459 net.cpp:122] Setting up Eltwise2
I0926 22:37:52.317704  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.317715  2459 net.cpp:137] Memory required for data: 126381200
I0926 22:37:52.317718  2459 layer_factory.hpp:77] Creating layer penlu5
I0926 22:37:52.317723  2459 net.cpp:84] Creating Layer penlu5
I0926 22:37:52.317725  2459 net.cpp:406] penlu5 <- Eltwise2
I0926 22:37:52.317729  2459 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0926 22:37:52.317852  2459 net.cpp:122] Setting up penlu5
I0926 22:37:52.317857  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.317868  2459 net.cpp:137] Memory required for data: 131398800
I0926 22:37:52.317873  2459 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0926 22:37:52.317884  2459 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0926 22:37:52.317898  2459 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0926 22:37:52.317900  2459 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0926 22:37:52.317904  2459 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0926 22:37:52.317946  2459 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0926 22:37:52.317951  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.317953  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.317965  2459 net.cpp:137] Memory required for data: 141434000
I0926 22:37:52.317967  2459 layer_factory.hpp:77] Creating layer Convolution6
I0926 22:37:52.317975  2459 net.cpp:84] Creating Layer Convolution6
I0926 22:37:52.317977  2459 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0926 22:37:52.317981  2459 net.cpp:380] Convolution6 -> Convolution6
I0926 22:37:52.318859  2459 net.cpp:122] Setting up Convolution6
I0926 22:37:52.318869  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.318873  2459 net.cpp:137] Memory required for data: 146451600
I0926 22:37:52.318878  2459 layer_factory.hpp:77] Creating layer BatchNorm6
I0926 22:37:52.318883  2459 net.cpp:84] Creating Layer BatchNorm6
I0926 22:37:52.318886  2459 net.cpp:406] BatchNorm6 <- Convolution6
I0926 22:37:52.318892  2459 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0926 22:37:52.319020  2459 net.cpp:122] Setting up BatchNorm6
I0926 22:37:52.319025  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.319028  2459 net.cpp:137] Memory required for data: 151469200
I0926 22:37:52.319033  2459 layer_factory.hpp:77] Creating layer Scale6
I0926 22:37:52.319038  2459 net.cpp:84] Creating Layer Scale6
I0926 22:37:52.319042  2459 net.cpp:406] Scale6 <- Convolution6
I0926 22:37:52.319046  2459 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0926 22:37:52.319072  2459 layer_factory.hpp:77] Creating layer Scale6
I0926 22:37:52.319149  2459 net.cpp:122] Setting up Scale6
I0926 22:37:52.319154  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.319157  2459 net.cpp:137] Memory required for data: 156486800
I0926 22:37:52.319161  2459 layer_factory.hpp:77] Creating layer penlu6
I0926 22:37:52.319167  2459 net.cpp:84] Creating Layer penlu6
I0926 22:37:52.319170  2459 net.cpp:406] penlu6 <- Convolution6
I0926 22:37:52.319175  2459 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0926 22:37:52.319279  2459 net.cpp:122] Setting up penlu6
I0926 22:37:52.319285  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.319288  2459 net.cpp:137] Memory required for data: 161504400
I0926 22:37:52.319293  2459 layer_factory.hpp:77] Creating layer Convolution7
I0926 22:37:52.319299  2459 net.cpp:84] Creating Layer Convolution7
I0926 22:37:52.319303  2459 net.cpp:406] Convolution7 <- Convolution6
I0926 22:37:52.319308  2459 net.cpp:380] Convolution7 -> Convolution7
I0926 22:37:52.319864  2459 net.cpp:122] Setting up Convolution7
I0926 22:37:52.319874  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.319877  2459 net.cpp:137] Memory required for data: 166522000
I0926 22:37:52.319881  2459 layer_factory.hpp:77] Creating layer BatchNorm7
I0926 22:37:52.319887  2459 net.cpp:84] Creating Layer BatchNorm7
I0926 22:37:52.319890  2459 net.cpp:406] BatchNorm7 <- Convolution7
I0926 22:37:52.319895  2459 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0926 22:37:52.320020  2459 net.cpp:122] Setting up BatchNorm7
I0926 22:37:52.320025  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.320029  2459 net.cpp:137] Memory required for data: 171539600
I0926 22:37:52.320039  2459 layer_factory.hpp:77] Creating layer Scale7
I0926 22:37:52.320046  2459 net.cpp:84] Creating Layer Scale7
I0926 22:37:52.320050  2459 net.cpp:406] Scale7 <- Convolution7
I0926 22:37:52.320053  2459 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0926 22:37:52.320080  2459 layer_factory.hpp:77] Creating layer Scale7
I0926 22:37:52.320155  2459 net.cpp:122] Setting up Scale7
I0926 22:37:52.320168  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.320171  2459 net.cpp:137] Memory required for data: 176557200
I0926 22:37:52.320175  2459 layer_factory.hpp:77] Creating layer Eltwise3
I0926 22:37:52.320181  2459 net.cpp:84] Creating Layer Eltwise3
I0926 22:37:52.320184  2459 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0926 22:37:52.320188  2459 net.cpp:406] Eltwise3 <- Convolution7
I0926 22:37:52.320190  2459 net.cpp:380] Eltwise3 -> Eltwise3
I0926 22:37:52.320226  2459 net.cpp:122] Setting up Eltwise3
I0926 22:37:52.320233  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.320235  2459 net.cpp:137] Memory required for data: 181574800
I0926 22:37:52.320247  2459 layer_factory.hpp:77] Creating layer penlu7
I0926 22:37:52.320252  2459 net.cpp:84] Creating Layer penlu7
I0926 22:37:52.320255  2459 net.cpp:406] penlu7 <- Eltwise3
I0926 22:37:52.320258  2459 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0926 22:37:52.320366  2459 net.cpp:122] Setting up penlu7
I0926 22:37:52.320371  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.320374  2459 net.cpp:137] Memory required for data: 186592400
I0926 22:37:52.320379  2459 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0926 22:37:52.320384  2459 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0926 22:37:52.320386  2459 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0926 22:37:52.320391  2459 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0926 22:37:52.320395  2459 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0926 22:37:52.320417  2459 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0926 22:37:52.320422  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.320426  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.320428  2459 net.cpp:137] Memory required for data: 196627600
I0926 22:37:52.320430  2459 layer_factory.hpp:77] Creating layer Convolution8
I0926 22:37:52.320436  2459 net.cpp:84] Creating Layer Convolution8
I0926 22:37:52.320439  2459 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0926 22:37:52.320443  2459 net.cpp:380] Convolution8 -> Convolution8
I0926 22:37:52.321425  2459 net.cpp:122] Setting up Convolution8
I0926 22:37:52.321436  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.321439  2459 net.cpp:137] Memory required for data: 201645200
I0926 22:37:52.321444  2459 layer_factory.hpp:77] Creating layer BatchNorm8
I0926 22:37:52.321450  2459 net.cpp:84] Creating Layer BatchNorm8
I0926 22:37:52.321455  2459 net.cpp:406] BatchNorm8 <- Convolution8
I0926 22:37:52.321458  2459 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0926 22:37:52.321585  2459 net.cpp:122] Setting up BatchNorm8
I0926 22:37:52.321590  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.321593  2459 net.cpp:137] Memory required for data: 206662800
I0926 22:37:52.321599  2459 layer_factory.hpp:77] Creating layer Scale8
I0926 22:37:52.321604  2459 net.cpp:84] Creating Layer Scale8
I0926 22:37:52.321606  2459 net.cpp:406] Scale8 <- Convolution8
I0926 22:37:52.321610  2459 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0926 22:37:52.321637  2459 layer_factory.hpp:77] Creating layer Scale8
I0926 22:37:52.321712  2459 net.cpp:122] Setting up Scale8
I0926 22:37:52.321718  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.321722  2459 net.cpp:137] Memory required for data: 211680400
I0926 22:37:52.321725  2459 layer_factory.hpp:77] Creating layer penlu8
I0926 22:37:52.321732  2459 net.cpp:84] Creating Layer penlu8
I0926 22:37:52.321734  2459 net.cpp:406] penlu8 <- Convolution8
I0926 22:37:52.321738  2459 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0926 22:37:52.321844  2459 net.cpp:122] Setting up penlu8
I0926 22:37:52.321849  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.321852  2459 net.cpp:137] Memory required for data: 216698000
I0926 22:37:52.321856  2459 layer_factory.hpp:77] Creating layer Convolution9
I0926 22:37:52.321873  2459 net.cpp:84] Creating Layer Convolution9
I0926 22:37:52.321877  2459 net.cpp:406] Convolution9 <- Convolution8
I0926 22:37:52.321880  2459 net.cpp:380] Convolution9 -> Convolution9
I0926 22:37:52.322767  2459 net.cpp:122] Setting up Convolution9
I0926 22:37:52.322777  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.322780  2459 net.cpp:137] Memory required for data: 221715600
I0926 22:37:52.322784  2459 layer_factory.hpp:77] Creating layer BatchNorm9
I0926 22:37:52.322790  2459 net.cpp:84] Creating Layer BatchNorm9
I0926 22:37:52.322794  2459 net.cpp:406] BatchNorm9 <- Convolution9
I0926 22:37:52.322799  2459 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0926 22:37:52.322928  2459 net.cpp:122] Setting up BatchNorm9
I0926 22:37:52.322933  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.322937  2459 net.cpp:137] Memory required for data: 226733200
I0926 22:37:52.322942  2459 layer_factory.hpp:77] Creating layer Scale9
I0926 22:37:52.322947  2459 net.cpp:84] Creating Layer Scale9
I0926 22:37:52.322950  2459 net.cpp:406] Scale9 <- Convolution9
I0926 22:37:52.322954  2459 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0926 22:37:52.322981  2459 layer_factory.hpp:77] Creating layer Scale9
I0926 22:37:52.323060  2459 net.cpp:122] Setting up Scale9
I0926 22:37:52.323065  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.323068  2459 net.cpp:137] Memory required for data: 231750800
I0926 22:37:52.323072  2459 layer_factory.hpp:77] Creating layer Eltwise4
I0926 22:37:52.323078  2459 net.cpp:84] Creating Layer Eltwise4
I0926 22:37:52.323081  2459 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0926 22:37:52.323084  2459 net.cpp:406] Eltwise4 <- Convolution9
I0926 22:37:52.323088  2459 net.cpp:380] Eltwise4 -> Eltwise4
I0926 22:37:52.323104  2459 net.cpp:122] Setting up Eltwise4
I0926 22:37:52.323108  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.323112  2459 net.cpp:137] Memory required for data: 236768400
I0926 22:37:52.323113  2459 layer_factory.hpp:77] Creating layer penlu9
I0926 22:37:52.323118  2459 net.cpp:84] Creating Layer penlu9
I0926 22:37:52.323122  2459 net.cpp:406] penlu9 <- Eltwise4
I0926 22:37:52.323125  2459 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0926 22:37:52.323231  2459 net.cpp:122] Setting up penlu9
I0926 22:37:52.323236  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.323240  2459 net.cpp:137] Memory required for data: 241786000
I0926 22:37:52.323245  2459 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0926 22:37:52.323248  2459 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0926 22:37:52.323251  2459 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0926 22:37:52.323254  2459 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0926 22:37:52.323259  2459 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0926 22:37:52.323282  2459 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0926 22:37:52.323287  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.323289  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.323292  2459 net.cpp:137] Memory required for data: 251821200
I0926 22:37:52.323294  2459 layer_factory.hpp:77] Creating layer Convolution10
I0926 22:37:52.323302  2459 net.cpp:84] Creating Layer Convolution10
I0926 22:37:52.323304  2459 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0926 22:37:52.323308  2459 net.cpp:380] Convolution10 -> Convolution10
I0926 22:37:52.324187  2459 net.cpp:122] Setting up Convolution10
I0926 22:37:52.324198  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.324201  2459 net.cpp:137] Memory required for data: 256838800
I0926 22:37:52.324223  2459 layer_factory.hpp:77] Creating layer BatchNorm10
I0926 22:37:52.324230  2459 net.cpp:84] Creating Layer BatchNorm10
I0926 22:37:52.324234  2459 net.cpp:406] BatchNorm10 <- Convolution10
I0926 22:37:52.324249  2459 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0926 22:37:52.324379  2459 net.cpp:122] Setting up BatchNorm10
I0926 22:37:52.324393  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.324395  2459 net.cpp:137] Memory required for data: 261856400
I0926 22:37:52.324400  2459 layer_factory.hpp:77] Creating layer Scale10
I0926 22:37:52.324406  2459 net.cpp:84] Creating Layer Scale10
I0926 22:37:52.324409  2459 net.cpp:406] Scale10 <- Convolution10
I0926 22:37:52.324412  2459 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0926 22:37:52.324440  2459 layer_factory.hpp:77] Creating layer Scale10
I0926 22:37:52.324518  2459 net.cpp:122] Setting up Scale10
I0926 22:37:52.324523  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.324527  2459 net.cpp:137] Memory required for data: 266874000
I0926 22:37:52.324530  2459 layer_factory.hpp:77] Creating layer penlu10
I0926 22:37:52.324537  2459 net.cpp:84] Creating Layer penlu10
I0926 22:37:52.324539  2459 net.cpp:406] penlu10 <- Convolution10
I0926 22:37:52.324543  2459 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0926 22:37:52.324648  2459 net.cpp:122] Setting up penlu10
I0926 22:37:52.324653  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.324656  2459 net.cpp:137] Memory required for data: 271891600
I0926 22:37:52.324659  2459 layer_factory.hpp:77] Creating layer Convolution11
I0926 22:37:52.324666  2459 net.cpp:84] Creating Layer Convolution11
I0926 22:37:52.324668  2459 net.cpp:406] Convolution11 <- Convolution10
I0926 22:37:52.324672  2459 net.cpp:380] Convolution11 -> Convolution11
I0926 22:37:52.325577  2459 net.cpp:122] Setting up Convolution11
I0926 22:37:52.325587  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.325589  2459 net.cpp:137] Memory required for data: 276909200
I0926 22:37:52.325594  2459 layer_factory.hpp:77] Creating layer BatchNorm11
I0926 22:37:52.325599  2459 net.cpp:84] Creating Layer BatchNorm11
I0926 22:37:52.325603  2459 net.cpp:406] BatchNorm11 <- Convolution11
I0926 22:37:52.325606  2459 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0926 22:37:52.325739  2459 net.cpp:122] Setting up BatchNorm11
I0926 22:37:52.325744  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.325747  2459 net.cpp:137] Memory required for data: 281926800
I0926 22:37:52.325752  2459 layer_factory.hpp:77] Creating layer Scale11
I0926 22:37:52.325755  2459 net.cpp:84] Creating Layer Scale11
I0926 22:37:52.325758  2459 net.cpp:406] Scale11 <- Convolution11
I0926 22:37:52.325762  2459 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0926 22:37:52.325788  2459 layer_factory.hpp:77] Creating layer Scale11
I0926 22:37:52.325865  2459 net.cpp:122] Setting up Scale11
I0926 22:37:52.325868  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.325870  2459 net.cpp:137] Memory required for data: 286944400
I0926 22:37:52.325875  2459 layer_factory.hpp:77] Creating layer Eltwise5
I0926 22:37:52.325880  2459 net.cpp:84] Creating Layer Eltwise5
I0926 22:37:52.325882  2459 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0926 22:37:52.325884  2459 net.cpp:406] Eltwise5 <- Convolution11
I0926 22:37:52.325888  2459 net.cpp:380] Eltwise5 -> Eltwise5
I0926 22:37:52.325904  2459 net.cpp:122] Setting up Eltwise5
I0926 22:37:52.325907  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.325909  2459 net.cpp:137] Memory required for data: 291962000
I0926 22:37:52.325911  2459 layer_factory.hpp:77] Creating layer penlu11
I0926 22:37:52.325917  2459 net.cpp:84] Creating Layer penlu11
I0926 22:37:52.325919  2459 net.cpp:406] penlu11 <- Eltwise5
I0926 22:37:52.325923  2459 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0926 22:37:52.326032  2459 net.cpp:122] Setting up penlu11
I0926 22:37:52.326036  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.326038  2459 net.cpp:137] Memory required for data: 296979600
I0926 22:37:52.326043  2459 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0926 22:37:52.326046  2459 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0926 22:37:52.326050  2459 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0926 22:37:52.326058  2459 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0926 22:37:52.326063  2459 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0926 22:37:52.326087  2459 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0926 22:37:52.326092  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.326093  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.326095  2459 net.cpp:137] Memory required for data: 307014800
I0926 22:37:52.326098  2459 layer_factory.hpp:77] Creating layer Convolution12
I0926 22:37:52.326104  2459 net.cpp:84] Creating Layer Convolution12
I0926 22:37:52.326107  2459 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0926 22:37:52.326110  2459 net.cpp:380] Convolution12 -> Convolution12
I0926 22:37:52.327003  2459 net.cpp:122] Setting up Convolution12
I0926 22:37:52.327013  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.327015  2459 net.cpp:137] Memory required for data: 312032400
I0926 22:37:52.327019  2459 layer_factory.hpp:77] Creating layer BatchNorm12
I0926 22:37:52.327024  2459 net.cpp:84] Creating Layer BatchNorm12
I0926 22:37:52.327028  2459 net.cpp:406] BatchNorm12 <- Convolution12
I0926 22:37:52.327031  2459 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0926 22:37:52.327165  2459 net.cpp:122] Setting up BatchNorm12
I0926 22:37:52.327169  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.327172  2459 net.cpp:137] Memory required for data: 317050000
I0926 22:37:52.327177  2459 layer_factory.hpp:77] Creating layer Scale12
I0926 22:37:52.327181  2459 net.cpp:84] Creating Layer Scale12
I0926 22:37:52.327184  2459 net.cpp:406] Scale12 <- Convolution12
I0926 22:37:52.327188  2459 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0926 22:37:52.327214  2459 layer_factory.hpp:77] Creating layer Scale12
I0926 22:37:52.327291  2459 net.cpp:122] Setting up Scale12
I0926 22:37:52.327294  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.327296  2459 net.cpp:137] Memory required for data: 322067600
I0926 22:37:52.327301  2459 layer_factory.hpp:77] Creating layer penlu12
I0926 22:37:52.327306  2459 net.cpp:84] Creating Layer penlu12
I0926 22:37:52.327308  2459 net.cpp:406] penlu12 <- Convolution12
I0926 22:37:52.327312  2459 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0926 22:37:52.327419  2459 net.cpp:122] Setting up penlu12
I0926 22:37:52.327422  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.327425  2459 net.cpp:137] Memory required for data: 327085200
I0926 22:37:52.327430  2459 layer_factory.hpp:77] Creating layer Convolution13
I0926 22:37:52.327435  2459 net.cpp:84] Creating Layer Convolution13
I0926 22:37:52.327438  2459 net.cpp:406] Convolution13 <- Convolution12
I0926 22:37:52.327442  2459 net.cpp:380] Convolution13 -> Convolution13
I0926 22:37:52.328364  2459 net.cpp:122] Setting up Convolution13
I0926 22:37:52.328373  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.328377  2459 net.cpp:137] Memory required for data: 332102800
I0926 22:37:52.328380  2459 layer_factory.hpp:77] Creating layer BatchNorm13
I0926 22:37:52.328385  2459 net.cpp:84] Creating Layer BatchNorm13
I0926 22:37:52.328387  2459 net.cpp:406] BatchNorm13 <- Convolution13
I0926 22:37:52.328392  2459 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0926 22:37:52.328526  2459 net.cpp:122] Setting up BatchNorm13
I0926 22:37:52.328531  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.328532  2459 net.cpp:137] Memory required for data: 337120400
I0926 22:37:52.328537  2459 layer_factory.hpp:77] Creating layer Scale13
I0926 22:37:52.328541  2459 net.cpp:84] Creating Layer Scale13
I0926 22:37:52.328543  2459 net.cpp:406] Scale13 <- Convolution13
I0926 22:37:52.328547  2459 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0926 22:37:52.328572  2459 layer_factory.hpp:77] Creating layer Scale13
I0926 22:37:52.328652  2459 net.cpp:122] Setting up Scale13
I0926 22:37:52.328657  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.328666  2459 net.cpp:137] Memory required for data: 342138000
I0926 22:37:52.328670  2459 layer_factory.hpp:77] Creating layer Eltwise6
I0926 22:37:52.328675  2459 net.cpp:84] Creating Layer Eltwise6
I0926 22:37:52.328677  2459 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0926 22:37:52.328680  2459 net.cpp:406] Eltwise6 <- Convolution13
I0926 22:37:52.328685  2459 net.cpp:380] Eltwise6 -> Eltwise6
I0926 22:37:52.328703  2459 net.cpp:122] Setting up Eltwise6
I0926 22:37:52.328708  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.328711  2459 net.cpp:137] Memory required for data: 347155600
I0926 22:37:52.328712  2459 layer_factory.hpp:77] Creating layer penlu13
I0926 22:37:52.328721  2459 net.cpp:84] Creating Layer penlu13
I0926 22:37:52.328723  2459 net.cpp:406] penlu13 <- Eltwise6
I0926 22:37:52.328727  2459 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0926 22:37:52.328837  2459 net.cpp:122] Setting up penlu13
I0926 22:37:52.328841  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.328843  2459 net.cpp:137] Memory required for data: 352173200
I0926 22:37:52.328856  2459 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0926 22:37:52.328860  2459 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0926 22:37:52.328862  2459 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0926 22:37:52.328867  2459 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0926 22:37:52.328871  2459 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0926 22:37:52.328896  2459 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0926 22:37:52.328899  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.328902  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.328903  2459 net.cpp:137] Memory required for data: 362208400
I0926 22:37:52.328905  2459 layer_factory.hpp:77] Creating layer Convolution14
I0926 22:37:52.328913  2459 net.cpp:84] Creating Layer Convolution14
I0926 22:37:52.328915  2459 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0926 22:37:52.328919  2459 net.cpp:380] Convolution14 -> Convolution14
I0926 22:37:52.329818  2459 net.cpp:122] Setting up Convolution14
I0926 22:37:52.329826  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.329829  2459 net.cpp:137] Memory required for data: 367226000
I0926 22:37:52.329834  2459 layer_factory.hpp:77] Creating layer BatchNorm14
I0926 22:37:52.329839  2459 net.cpp:84] Creating Layer BatchNorm14
I0926 22:37:52.329843  2459 net.cpp:406] BatchNorm14 <- Convolution14
I0926 22:37:52.329847  2459 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0926 22:37:52.329979  2459 net.cpp:122] Setting up BatchNorm14
I0926 22:37:52.329984  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.329987  2459 net.cpp:137] Memory required for data: 372243600
I0926 22:37:52.329991  2459 layer_factory.hpp:77] Creating layer Scale14
I0926 22:37:52.329996  2459 net.cpp:84] Creating Layer Scale14
I0926 22:37:52.329999  2459 net.cpp:406] Scale14 <- Convolution14
I0926 22:37:52.330003  2459 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0926 22:37:52.330029  2459 layer_factory.hpp:77] Creating layer Scale14
I0926 22:37:52.330107  2459 net.cpp:122] Setting up Scale14
I0926 22:37:52.330112  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.330114  2459 net.cpp:137] Memory required for data: 377261200
I0926 22:37:52.330118  2459 layer_factory.hpp:77] Creating layer penlu14
I0926 22:37:52.330124  2459 net.cpp:84] Creating Layer penlu14
I0926 22:37:52.330127  2459 net.cpp:406] penlu14 <- Convolution14
I0926 22:37:52.330130  2459 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0926 22:37:52.330240  2459 net.cpp:122] Setting up penlu14
I0926 22:37:52.330245  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.330246  2459 net.cpp:137] Memory required for data: 382278800
I0926 22:37:52.330250  2459 layer_factory.hpp:77] Creating layer Convolution15
I0926 22:37:52.330257  2459 net.cpp:84] Creating Layer Convolution15
I0926 22:37:52.330266  2459 net.cpp:406] Convolution15 <- Convolution14
I0926 22:37:52.330271  2459 net.cpp:380] Convolution15 -> Convolution15
I0926 22:37:52.331168  2459 net.cpp:122] Setting up Convolution15
I0926 22:37:52.331176  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.331179  2459 net.cpp:137] Memory required for data: 387296400
I0926 22:37:52.331183  2459 layer_factory.hpp:77] Creating layer BatchNorm15
I0926 22:37:52.331189  2459 net.cpp:84] Creating Layer BatchNorm15
I0926 22:37:52.331192  2459 net.cpp:406] BatchNorm15 <- Convolution15
I0926 22:37:52.331195  2459 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0926 22:37:52.331327  2459 net.cpp:122] Setting up BatchNorm15
I0926 22:37:52.331332  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.331334  2459 net.cpp:137] Memory required for data: 392314000
I0926 22:37:52.331339  2459 layer_factory.hpp:77] Creating layer Scale15
I0926 22:37:52.331344  2459 net.cpp:84] Creating Layer Scale15
I0926 22:37:52.331347  2459 net.cpp:406] Scale15 <- Convolution15
I0926 22:37:52.331351  2459 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0926 22:37:52.331377  2459 layer_factory.hpp:77] Creating layer Scale15
I0926 22:37:52.331454  2459 net.cpp:122] Setting up Scale15
I0926 22:37:52.331459  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.331460  2459 net.cpp:137] Memory required for data: 397331600
I0926 22:37:52.331465  2459 layer_factory.hpp:77] Creating layer Eltwise7
I0926 22:37:52.331470  2459 net.cpp:84] Creating Layer Eltwise7
I0926 22:37:52.331472  2459 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0926 22:37:52.331475  2459 net.cpp:406] Eltwise7 <- Convolution15
I0926 22:37:52.331478  2459 net.cpp:380] Eltwise7 -> Eltwise7
I0926 22:37:52.331495  2459 net.cpp:122] Setting up Eltwise7
I0926 22:37:52.331498  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.331501  2459 net.cpp:137] Memory required for data: 402349200
I0926 22:37:52.331502  2459 layer_factory.hpp:77] Creating layer penlu15
I0926 22:37:52.331508  2459 net.cpp:84] Creating Layer penlu15
I0926 22:37:52.331511  2459 net.cpp:406] penlu15 <- Eltwise7
I0926 22:37:52.331514  2459 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0926 22:37:52.331621  2459 net.cpp:122] Setting up penlu15
I0926 22:37:52.331625  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.331627  2459 net.cpp:137] Memory required for data: 407366800
I0926 22:37:52.331631  2459 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0926 22:37:52.331635  2459 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0926 22:37:52.331637  2459 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0926 22:37:52.331641  2459 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0926 22:37:52.331645  2459 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0926 22:37:52.331667  2459 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0926 22:37:52.331671  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.331674  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.331676  2459 net.cpp:137] Memory required for data: 417402000
I0926 22:37:52.331678  2459 layer_factory.hpp:77] Creating layer Convolution16
I0926 22:37:52.331684  2459 net.cpp:84] Creating Layer Convolution16
I0926 22:37:52.331687  2459 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0926 22:37:52.331691  2459 net.cpp:380] Convolution16 -> Convolution16
I0926 22:37:52.332589  2459 net.cpp:122] Setting up Convolution16
I0926 22:37:52.332598  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.332602  2459 net.cpp:137] Memory required for data: 422419600
I0926 22:37:52.332605  2459 layer_factory.hpp:77] Creating layer BatchNorm16
I0926 22:37:52.332612  2459 net.cpp:84] Creating Layer BatchNorm16
I0926 22:37:52.332614  2459 net.cpp:406] BatchNorm16 <- Convolution16
I0926 22:37:52.332617  2459 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0926 22:37:52.332751  2459 net.cpp:122] Setting up BatchNorm16
I0926 22:37:52.332762  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.332764  2459 net.cpp:137] Memory required for data: 427437200
I0926 22:37:52.332769  2459 layer_factory.hpp:77] Creating layer Scale16
I0926 22:37:52.332774  2459 net.cpp:84] Creating Layer Scale16
I0926 22:37:52.332777  2459 net.cpp:406] Scale16 <- Convolution16
I0926 22:37:52.332780  2459 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0926 22:37:52.332808  2459 layer_factory.hpp:77] Creating layer Scale16
I0926 22:37:52.332887  2459 net.cpp:122] Setting up Scale16
I0926 22:37:52.332892  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.332895  2459 net.cpp:137] Memory required for data: 432454800
I0926 22:37:52.332898  2459 layer_factory.hpp:77] Creating layer penlu16
I0926 22:37:52.332904  2459 net.cpp:84] Creating Layer penlu16
I0926 22:37:52.332906  2459 net.cpp:406] penlu16 <- Convolution16
I0926 22:37:52.332911  2459 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0926 22:37:52.333021  2459 net.cpp:122] Setting up penlu16
I0926 22:37:52.333025  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.333027  2459 net.cpp:137] Memory required for data: 437472400
I0926 22:37:52.333032  2459 layer_factory.hpp:77] Creating layer Convolution17
I0926 22:37:52.333039  2459 net.cpp:84] Creating Layer Convolution17
I0926 22:37:52.333042  2459 net.cpp:406] Convolution17 <- Convolution16
I0926 22:37:52.333045  2459 net.cpp:380] Convolution17 -> Convolution17
I0926 22:37:52.333686  2459 net.cpp:122] Setting up Convolution17
I0926 22:37:52.333695  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.333698  2459 net.cpp:137] Memory required for data: 442490000
I0926 22:37:52.333705  2459 layer_factory.hpp:77] Creating layer BatchNorm17
I0926 22:37:52.333711  2459 net.cpp:84] Creating Layer BatchNorm17
I0926 22:37:52.333714  2459 net.cpp:406] BatchNorm17 <- Convolution17
I0926 22:37:52.333719  2459 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0926 22:37:52.333858  2459 net.cpp:122] Setting up BatchNorm17
I0926 22:37:52.333863  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.333864  2459 net.cpp:137] Memory required for data: 447507600
I0926 22:37:52.333869  2459 layer_factory.hpp:77] Creating layer Scale17
I0926 22:37:52.333874  2459 net.cpp:84] Creating Layer Scale17
I0926 22:37:52.333878  2459 net.cpp:406] Scale17 <- Convolution17
I0926 22:37:52.333883  2459 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0926 22:37:52.333910  2459 layer_factory.hpp:77] Creating layer Scale17
I0926 22:37:52.333992  2459 net.cpp:122] Setting up Scale17
I0926 22:37:52.333997  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.333998  2459 net.cpp:137] Memory required for data: 452525200
I0926 22:37:52.334003  2459 layer_factory.hpp:77] Creating layer Eltwise8
I0926 22:37:52.334009  2459 net.cpp:84] Creating Layer Eltwise8
I0926 22:37:52.334012  2459 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0926 22:37:52.334014  2459 net.cpp:406] Eltwise8 <- Convolution17
I0926 22:37:52.334019  2459 net.cpp:380] Eltwise8 -> Eltwise8
I0926 22:37:52.334035  2459 net.cpp:122] Setting up Eltwise8
I0926 22:37:52.334038  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.334040  2459 net.cpp:137] Memory required for data: 457542800
I0926 22:37:52.334043  2459 layer_factory.hpp:77] Creating layer penlu17
I0926 22:37:52.334048  2459 net.cpp:84] Creating Layer penlu17
I0926 22:37:52.334051  2459 net.cpp:406] penlu17 <- Eltwise8
I0926 22:37:52.334054  2459 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0926 22:37:52.334167  2459 net.cpp:122] Setting up penlu17
I0926 22:37:52.334172  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.334173  2459 net.cpp:137] Memory required for data: 462560400
I0926 22:37:52.334177  2459 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0926 22:37:52.334182  2459 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0926 22:37:52.334185  2459 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0926 22:37:52.334197  2459 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0926 22:37:52.334204  2459 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0926 22:37:52.334228  2459 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0926 22:37:52.334233  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.334235  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.334237  2459 net.cpp:137] Memory required for data: 472595600
I0926 22:37:52.334239  2459 layer_factory.hpp:77] Creating layer Convolution18
I0926 22:37:52.334246  2459 net.cpp:84] Creating Layer Convolution18
I0926 22:37:52.334250  2459 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0926 22:37:52.334255  2459 net.cpp:380] Convolution18 -> Convolution18
I0926 22:37:52.335175  2459 net.cpp:122] Setting up Convolution18
I0926 22:37:52.335183  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.335186  2459 net.cpp:137] Memory required for data: 477613200
I0926 22:37:52.335191  2459 layer_factory.hpp:77] Creating layer BatchNorm18
I0926 22:37:52.335196  2459 net.cpp:84] Creating Layer BatchNorm18
I0926 22:37:52.335198  2459 net.cpp:406] BatchNorm18 <- Convolution18
I0926 22:37:52.335203  2459 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0926 22:37:52.335352  2459 net.cpp:122] Setting up BatchNorm18
I0926 22:37:52.335360  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.335361  2459 net.cpp:137] Memory required for data: 482630800
I0926 22:37:52.335366  2459 layer_factory.hpp:77] Creating layer Scale18
I0926 22:37:52.335371  2459 net.cpp:84] Creating Layer Scale18
I0926 22:37:52.335374  2459 net.cpp:406] Scale18 <- Convolution18
I0926 22:37:52.335378  2459 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0926 22:37:52.335407  2459 layer_factory.hpp:77] Creating layer Scale18
I0926 22:37:52.335486  2459 net.cpp:122] Setting up Scale18
I0926 22:37:52.335490  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.335492  2459 net.cpp:137] Memory required for data: 487648400
I0926 22:37:52.335496  2459 layer_factory.hpp:77] Creating layer penlu18
I0926 22:37:52.335502  2459 net.cpp:84] Creating Layer penlu18
I0926 22:37:52.335505  2459 net.cpp:406] penlu18 <- Convolution18
I0926 22:37:52.335508  2459 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0926 22:37:52.335616  2459 net.cpp:122] Setting up penlu18
I0926 22:37:52.335620  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.335623  2459 net.cpp:137] Memory required for data: 492666000
I0926 22:37:52.335628  2459 layer_factory.hpp:77] Creating layer Convolution19
I0926 22:37:52.335633  2459 net.cpp:84] Creating Layer Convolution19
I0926 22:37:52.335636  2459 net.cpp:406] Convolution19 <- Convolution18
I0926 22:37:52.335640  2459 net.cpp:380] Convolution19 -> Convolution19
I0926 22:37:52.336554  2459 net.cpp:122] Setting up Convolution19
I0926 22:37:52.336561  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.336565  2459 net.cpp:137] Memory required for data: 497683600
I0926 22:37:52.336570  2459 layer_factory.hpp:77] Creating layer BatchNorm19
I0926 22:37:52.336575  2459 net.cpp:84] Creating Layer BatchNorm19
I0926 22:37:52.336577  2459 net.cpp:406] BatchNorm19 <- Convolution19
I0926 22:37:52.336581  2459 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0926 22:37:52.336715  2459 net.cpp:122] Setting up BatchNorm19
I0926 22:37:52.336720  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.336722  2459 net.cpp:137] Memory required for data: 502701200
I0926 22:37:52.336727  2459 layer_factory.hpp:77] Creating layer Scale19
I0926 22:37:52.336732  2459 net.cpp:84] Creating Layer Scale19
I0926 22:37:52.336735  2459 net.cpp:406] Scale19 <- Convolution19
I0926 22:37:52.336738  2459 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0926 22:37:52.336766  2459 layer_factory.hpp:77] Creating layer Scale19
I0926 22:37:52.336854  2459 net.cpp:122] Setting up Scale19
I0926 22:37:52.336863  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.336876  2459 net.cpp:137] Memory required for data: 507718800
I0926 22:37:52.336885  2459 layer_factory.hpp:77] Creating layer Eltwise9
I0926 22:37:52.336894  2459 net.cpp:84] Creating Layer Eltwise9
I0926 22:37:52.336899  2459 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0926 22:37:52.336905  2459 net.cpp:406] Eltwise9 <- Convolution19
I0926 22:37:52.336912  2459 net.cpp:380] Eltwise9 -> Eltwise9
I0926 22:37:52.336935  2459 net.cpp:122] Setting up Eltwise9
I0926 22:37:52.336940  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.336941  2459 net.cpp:137] Memory required for data: 512736400
I0926 22:37:52.336943  2459 layer_factory.hpp:77] Creating layer penlu19
I0926 22:37:52.336949  2459 net.cpp:84] Creating Layer penlu19
I0926 22:37:52.336952  2459 net.cpp:406] penlu19 <- Eltwise9
I0926 22:37:52.336956  2459 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0926 22:37:52.337066  2459 net.cpp:122] Setting up penlu19
I0926 22:37:52.337071  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.337074  2459 net.cpp:137] Memory required for data: 517754000
I0926 22:37:52.337077  2459 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0926 22:37:52.337081  2459 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0926 22:37:52.337083  2459 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0926 22:37:52.337087  2459 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0926 22:37:52.337091  2459 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0926 22:37:52.337115  2459 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0926 22:37:52.337118  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.337121  2459 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0926 22:37:52.337122  2459 net.cpp:137] Memory required for data: 527789200
I0926 22:37:52.337126  2459 layer_factory.hpp:77] Creating layer Convolution20
I0926 22:37:52.337131  2459 net.cpp:84] Creating Layer Convolution20
I0926 22:37:52.337134  2459 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0926 22:37:52.337138  2459 net.cpp:380] Convolution20 -> Convolution20
I0926 22:37:52.338318  2459 net.cpp:122] Setting up Convolution20
I0926 22:37:52.338328  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.338331  2459 net.cpp:137] Memory required for data: 530298000
I0926 22:37:52.338336  2459 layer_factory.hpp:77] Creating layer BatchNorm20
I0926 22:37:52.338340  2459 net.cpp:84] Creating Layer BatchNorm20
I0926 22:37:52.338343  2459 net.cpp:406] BatchNorm20 <- Convolution20
I0926 22:37:52.338347  2459 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0926 22:37:52.338490  2459 net.cpp:122] Setting up BatchNorm20
I0926 22:37:52.338495  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.338496  2459 net.cpp:137] Memory required for data: 532806800
I0926 22:37:52.338501  2459 layer_factory.hpp:77] Creating layer Scale20
I0926 22:37:52.338505  2459 net.cpp:84] Creating Layer Scale20
I0926 22:37:52.338508  2459 net.cpp:406] Scale20 <- Convolution20
I0926 22:37:52.338512  2459 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0926 22:37:52.338538  2459 layer_factory.hpp:77] Creating layer Scale20
I0926 22:37:52.338615  2459 net.cpp:122] Setting up Scale20
I0926 22:37:52.338619  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.338621  2459 net.cpp:137] Memory required for data: 535315600
I0926 22:37:52.338625  2459 layer_factory.hpp:77] Creating layer Convolution21
I0926 22:37:52.338632  2459 net.cpp:84] Creating Layer Convolution21
I0926 22:37:52.338635  2459 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0926 22:37:52.338639  2459 net.cpp:380] Convolution21 -> Convolution21
I0926 22:37:52.340270  2459 net.cpp:122] Setting up Convolution21
I0926 22:37:52.340278  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.340281  2459 net.cpp:137] Memory required for data: 537824400
I0926 22:37:52.340286  2459 layer_factory.hpp:77] Creating layer BatchNorm21
I0926 22:37:52.340292  2459 net.cpp:84] Creating Layer BatchNorm21
I0926 22:37:52.340302  2459 net.cpp:406] BatchNorm21 <- Convolution21
I0926 22:37:52.340306  2459 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0926 22:37:52.340451  2459 net.cpp:122] Setting up BatchNorm21
I0926 22:37:52.340456  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.340458  2459 net.cpp:137] Memory required for data: 540333200
I0926 22:37:52.340463  2459 layer_factory.hpp:77] Creating layer Scale21
I0926 22:37:52.340469  2459 net.cpp:84] Creating Layer Scale21
I0926 22:37:52.340471  2459 net.cpp:406] Scale21 <- Convolution21
I0926 22:37:52.340476  2459 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0926 22:37:52.340504  2459 layer_factory.hpp:77] Creating layer Scale21
I0926 22:37:52.340586  2459 net.cpp:122] Setting up Scale21
I0926 22:37:52.340590  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.340592  2459 net.cpp:137] Memory required for data: 542842000
I0926 22:37:52.340596  2459 layer_factory.hpp:77] Creating layer penlu20
I0926 22:37:52.340602  2459 net.cpp:84] Creating Layer penlu20
I0926 22:37:52.340605  2459 net.cpp:406] penlu20 <- Convolution21
I0926 22:37:52.340610  2459 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0926 22:37:52.340739  2459 net.cpp:122] Setting up penlu20
I0926 22:37:52.340744  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.340746  2459 net.cpp:137] Memory required for data: 545350800
I0926 22:37:52.340750  2459 layer_factory.hpp:77] Creating layer Convolution22
I0926 22:37:52.340757  2459 net.cpp:84] Creating Layer Convolution22
I0926 22:37:52.340760  2459 net.cpp:406] Convolution22 <- Convolution21
I0926 22:37:52.340764  2459 net.cpp:380] Convolution22 -> Convolution22
I0926 22:37:52.365993  2459 net.cpp:122] Setting up Convolution22
I0926 22:37:52.366005  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.366008  2459 net.cpp:137] Memory required for data: 547859600
I0926 22:37:52.366014  2459 layer_factory.hpp:77] Creating layer BatchNorm22
I0926 22:37:52.366020  2459 net.cpp:84] Creating Layer BatchNorm22
I0926 22:37:52.366024  2459 net.cpp:406] BatchNorm22 <- Convolution22
I0926 22:37:52.366029  2459 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0926 22:37:52.366184  2459 net.cpp:122] Setting up BatchNorm22
I0926 22:37:52.366189  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.366191  2459 net.cpp:137] Memory required for data: 550368400
I0926 22:37:52.366197  2459 layer_factory.hpp:77] Creating layer Scale22
I0926 22:37:52.366201  2459 net.cpp:84] Creating Layer Scale22
I0926 22:37:52.366204  2459 net.cpp:406] Scale22 <- Convolution22
I0926 22:37:52.366209  2459 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0926 22:37:52.366238  2459 layer_factory.hpp:77] Creating layer Scale22
I0926 22:37:52.366324  2459 net.cpp:122] Setting up Scale22
I0926 22:37:52.366329  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.366333  2459 net.cpp:137] Memory required for data: 552877200
I0926 22:37:52.366336  2459 layer_factory.hpp:77] Creating layer Eltwise10
I0926 22:37:52.366341  2459 net.cpp:84] Creating Layer Eltwise10
I0926 22:37:52.366343  2459 net.cpp:406] Eltwise10 <- Convolution20
I0926 22:37:52.366346  2459 net.cpp:406] Eltwise10 <- Convolution22
I0926 22:37:52.366351  2459 net.cpp:380] Eltwise10 -> Eltwise10
I0926 22:37:52.366369  2459 net.cpp:122] Setting up Eltwise10
I0926 22:37:52.366375  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.366377  2459 net.cpp:137] Memory required for data: 555386000
I0926 22:37:52.366379  2459 layer_factory.hpp:77] Creating layer penlu21
I0926 22:37:52.366385  2459 net.cpp:84] Creating Layer penlu21
I0926 22:37:52.366387  2459 net.cpp:406] penlu21 <- Eltwise10
I0926 22:37:52.366392  2459 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0926 22:37:52.366510  2459 net.cpp:122] Setting up penlu21
I0926 22:37:52.366514  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.366518  2459 net.cpp:137] Memory required for data: 557894800
I0926 22:37:52.366521  2459 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0926 22:37:52.366535  2459 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0926 22:37:52.366539  2459 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0926 22:37:52.366542  2459 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0926 22:37:52.366547  2459 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0926 22:37:52.366574  2459 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0926 22:37:52.366578  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.366581  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.366583  2459 net.cpp:137] Memory required for data: 562912400
I0926 22:37:52.366586  2459 layer_factory.hpp:77] Creating layer Convolution23
I0926 22:37:52.366592  2459 net.cpp:84] Creating Layer Convolution23
I0926 22:37:52.366595  2459 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0926 22:37:52.366600  2459 net.cpp:380] Convolution23 -> Convolution23
I0926 22:37:52.368041  2459 net.cpp:122] Setting up Convolution23
I0926 22:37:52.368050  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.368053  2459 net.cpp:137] Memory required for data: 565421200
I0926 22:37:52.368058  2459 layer_factory.hpp:77] Creating layer BatchNorm23
I0926 22:37:52.368063  2459 net.cpp:84] Creating Layer BatchNorm23
I0926 22:37:52.368067  2459 net.cpp:406] BatchNorm23 <- Convolution23
I0926 22:37:52.368070  2459 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0926 22:37:52.368217  2459 net.cpp:122] Setting up BatchNorm23
I0926 22:37:52.368222  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.368224  2459 net.cpp:137] Memory required for data: 567930000
I0926 22:37:52.368229  2459 layer_factory.hpp:77] Creating layer Scale23
I0926 22:37:52.368234  2459 net.cpp:84] Creating Layer Scale23
I0926 22:37:52.368237  2459 net.cpp:406] Scale23 <- Convolution23
I0926 22:37:52.368240  2459 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0926 22:37:52.368268  2459 layer_factory.hpp:77] Creating layer Scale23
I0926 22:37:52.368345  2459 net.cpp:122] Setting up Scale23
I0926 22:37:52.368350  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.368352  2459 net.cpp:137] Memory required for data: 570438800
I0926 22:37:52.368356  2459 layer_factory.hpp:77] Creating layer penlu22
I0926 22:37:52.368361  2459 net.cpp:84] Creating Layer penlu22
I0926 22:37:52.368365  2459 net.cpp:406] penlu22 <- Convolution23
I0926 22:37:52.368368  2459 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0926 22:37:52.368475  2459 net.cpp:122] Setting up penlu22
I0926 22:37:52.368480  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.368482  2459 net.cpp:137] Memory required for data: 572947600
I0926 22:37:52.368486  2459 layer_factory.hpp:77] Creating layer Convolution24
I0926 22:37:52.368494  2459 net.cpp:84] Creating Layer Convolution24
I0926 22:37:52.368496  2459 net.cpp:406] Convolution24 <- Convolution23
I0926 22:37:52.368500  2459 net.cpp:380] Convolution24 -> Convolution24
I0926 22:37:52.369563  2459 net.cpp:122] Setting up Convolution24
I0926 22:37:52.369571  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.369575  2459 net.cpp:137] Memory required for data: 575456400
I0926 22:37:52.369580  2459 layer_factory.hpp:77] Creating layer BatchNorm24
I0926 22:37:52.369585  2459 net.cpp:84] Creating Layer BatchNorm24
I0926 22:37:52.369587  2459 net.cpp:406] BatchNorm24 <- Convolution24
I0926 22:37:52.369593  2459 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0926 22:37:52.369730  2459 net.cpp:122] Setting up BatchNorm24
I0926 22:37:52.369735  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.369737  2459 net.cpp:137] Memory required for data: 577965200
I0926 22:37:52.369742  2459 layer_factory.hpp:77] Creating layer Scale24
I0926 22:37:52.369747  2459 net.cpp:84] Creating Layer Scale24
I0926 22:37:52.369750  2459 net.cpp:406] Scale24 <- Convolution24
I0926 22:37:52.369752  2459 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0926 22:37:52.369788  2459 layer_factory.hpp:77] Creating layer Scale24
I0926 22:37:52.369868  2459 net.cpp:122] Setting up Scale24
I0926 22:37:52.369873  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.369874  2459 net.cpp:137] Memory required for data: 580474000
I0926 22:37:52.369879  2459 layer_factory.hpp:77] Creating layer Eltwise11
I0926 22:37:52.369882  2459 net.cpp:84] Creating Layer Eltwise11
I0926 22:37:52.369884  2459 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0926 22:37:52.369887  2459 net.cpp:406] Eltwise11 <- Convolution24
I0926 22:37:52.369892  2459 net.cpp:380] Eltwise11 -> Eltwise11
I0926 22:37:52.369909  2459 net.cpp:122] Setting up Eltwise11
I0926 22:37:52.369912  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.369915  2459 net.cpp:137] Memory required for data: 582982800
I0926 22:37:52.369916  2459 layer_factory.hpp:77] Creating layer penlu23
I0926 22:37:52.369922  2459 net.cpp:84] Creating Layer penlu23
I0926 22:37:52.369925  2459 net.cpp:406] penlu23 <- Eltwise11
I0926 22:37:52.369927  2459 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0926 22:37:52.370035  2459 net.cpp:122] Setting up penlu23
I0926 22:37:52.370040  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.370043  2459 net.cpp:137] Memory required for data: 585491600
I0926 22:37:52.370046  2459 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0926 22:37:52.370050  2459 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0926 22:37:52.370052  2459 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0926 22:37:52.370056  2459 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0926 22:37:52.370060  2459 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0926 22:37:52.370082  2459 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0926 22:37:52.370086  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.370090  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.370091  2459 net.cpp:137] Memory required for data: 590509200
I0926 22:37:52.370093  2459 layer_factory.hpp:77] Creating layer Convolution25
I0926 22:37:52.370100  2459 net.cpp:84] Creating Layer Convolution25
I0926 22:37:52.370102  2459 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0926 22:37:52.370106  2459 net.cpp:380] Convolution25 -> Convolution25
I0926 22:37:52.371198  2459 net.cpp:122] Setting up Convolution25
I0926 22:37:52.371207  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.371210  2459 net.cpp:137] Memory required for data: 593018000
I0926 22:37:52.371214  2459 layer_factory.hpp:77] Creating layer BatchNorm25
I0926 22:37:52.371219  2459 net.cpp:84] Creating Layer BatchNorm25
I0926 22:37:52.371222  2459 net.cpp:406] BatchNorm25 <- Convolution25
I0926 22:37:52.371227  2459 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0926 22:37:52.371363  2459 net.cpp:122] Setting up BatchNorm25
I0926 22:37:52.371368  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.371371  2459 net.cpp:137] Memory required for data: 595526800
I0926 22:37:52.371376  2459 layer_factory.hpp:77] Creating layer Scale25
I0926 22:37:52.371381  2459 net.cpp:84] Creating Layer Scale25
I0926 22:37:52.371384  2459 net.cpp:406] Scale25 <- Convolution25
I0926 22:37:52.371387  2459 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0926 22:37:52.371414  2459 layer_factory.hpp:77] Creating layer Scale25
I0926 22:37:52.371492  2459 net.cpp:122] Setting up Scale25
I0926 22:37:52.371496  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.371498  2459 net.cpp:137] Memory required for data: 598035600
I0926 22:37:52.371502  2459 layer_factory.hpp:77] Creating layer penlu24
I0926 22:37:52.371508  2459 net.cpp:84] Creating Layer penlu24
I0926 22:37:52.371511  2459 net.cpp:406] penlu24 <- Convolution25
I0926 22:37:52.371515  2459 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0926 22:37:52.371621  2459 net.cpp:122] Setting up penlu24
I0926 22:37:52.371626  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.371634  2459 net.cpp:137] Memory required for data: 600544400
I0926 22:37:52.371639  2459 layer_factory.hpp:77] Creating layer Convolution26
I0926 22:37:52.371646  2459 net.cpp:84] Creating Layer Convolution26
I0926 22:37:52.371649  2459 net.cpp:406] Convolution26 <- Convolution25
I0926 22:37:52.371654  2459 net.cpp:380] Convolution26 -> Convolution26
I0926 22:37:52.372781  2459 net.cpp:122] Setting up Convolution26
I0926 22:37:52.372790  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.372792  2459 net.cpp:137] Memory required for data: 603053200
I0926 22:37:52.372797  2459 layer_factory.hpp:77] Creating layer BatchNorm26
I0926 22:37:52.372803  2459 net.cpp:84] Creating Layer BatchNorm26
I0926 22:37:52.372807  2459 net.cpp:406] BatchNorm26 <- Convolution26
I0926 22:37:52.372809  2459 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0926 22:37:52.372979  2459 net.cpp:122] Setting up BatchNorm26
I0926 22:37:52.372984  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.372987  2459 net.cpp:137] Memory required for data: 605562000
I0926 22:37:52.372992  2459 layer_factory.hpp:77] Creating layer Scale26
I0926 22:37:52.372997  2459 net.cpp:84] Creating Layer Scale26
I0926 22:37:52.373009  2459 net.cpp:406] Scale26 <- Convolution26
I0926 22:37:52.373013  2459 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0926 22:37:52.373040  2459 layer_factory.hpp:77] Creating layer Scale26
I0926 22:37:52.373122  2459 net.cpp:122] Setting up Scale26
I0926 22:37:52.373127  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.373129  2459 net.cpp:137] Memory required for data: 608070800
I0926 22:37:52.373133  2459 layer_factory.hpp:77] Creating layer Eltwise12
I0926 22:37:52.373138  2459 net.cpp:84] Creating Layer Eltwise12
I0926 22:37:52.373142  2459 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0926 22:37:52.373144  2459 net.cpp:406] Eltwise12 <- Convolution26
I0926 22:37:52.373147  2459 net.cpp:380] Eltwise12 -> Eltwise12
I0926 22:37:52.373164  2459 net.cpp:122] Setting up Eltwise12
I0926 22:37:52.373170  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.373173  2459 net.cpp:137] Memory required for data: 610579600
I0926 22:37:52.373178  2459 layer_factory.hpp:77] Creating layer penlu25
I0926 22:37:52.373185  2459 net.cpp:84] Creating Layer penlu25
I0926 22:37:52.373190  2459 net.cpp:406] penlu25 <- Eltwise12
I0926 22:37:52.373196  2459 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0926 22:37:52.373345  2459 net.cpp:122] Setting up penlu25
I0926 22:37:52.373353  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.373358  2459 net.cpp:137] Memory required for data: 613088400
I0926 22:37:52.373394  2459 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0926 22:37:52.373414  2459 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0926 22:37:52.373420  2459 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0926 22:37:52.373426  2459 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0926 22:37:52.373436  2459 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0926 22:37:52.373467  2459 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0926 22:37:52.373473  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.373476  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.373478  2459 net.cpp:137] Memory required for data: 618106000
I0926 22:37:52.373481  2459 layer_factory.hpp:77] Creating layer Convolution27
I0926 22:37:52.373488  2459 net.cpp:84] Creating Layer Convolution27
I0926 22:37:52.373491  2459 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0926 22:37:52.373495  2459 net.cpp:380] Convolution27 -> Convolution27
I0926 22:37:52.374382  2459 net.cpp:122] Setting up Convolution27
I0926 22:37:52.374392  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.374394  2459 net.cpp:137] Memory required for data: 620614800
I0926 22:37:52.374399  2459 layer_factory.hpp:77] Creating layer BatchNorm27
I0926 22:37:52.374405  2459 net.cpp:84] Creating Layer BatchNorm27
I0926 22:37:52.374415  2459 net.cpp:406] BatchNorm27 <- Convolution27
I0926 22:37:52.374420  2459 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0926 22:37:52.374565  2459 net.cpp:122] Setting up BatchNorm27
I0926 22:37:52.374570  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.374572  2459 net.cpp:137] Memory required for data: 623123600
I0926 22:37:52.374577  2459 layer_factory.hpp:77] Creating layer Scale27
I0926 22:37:52.374583  2459 net.cpp:84] Creating Layer Scale27
I0926 22:37:52.374585  2459 net.cpp:406] Scale27 <- Convolution27
I0926 22:37:52.374589  2459 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0926 22:37:52.374617  2459 layer_factory.hpp:77] Creating layer Scale27
I0926 22:37:52.374701  2459 net.cpp:122] Setting up Scale27
I0926 22:37:52.374706  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.374707  2459 net.cpp:137] Memory required for data: 625632400
I0926 22:37:52.374711  2459 layer_factory.hpp:77] Creating layer penlu26
I0926 22:37:52.374717  2459 net.cpp:84] Creating Layer penlu26
I0926 22:37:52.374719  2459 net.cpp:406] penlu26 <- Convolution27
I0926 22:37:52.374722  2459 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0926 22:37:52.374835  2459 net.cpp:122] Setting up penlu26
I0926 22:37:52.374840  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.374842  2459 net.cpp:137] Memory required for data: 628141200
I0926 22:37:52.374846  2459 layer_factory.hpp:77] Creating layer Convolution28
I0926 22:37:52.374855  2459 net.cpp:84] Creating Layer Convolution28
I0926 22:37:52.374856  2459 net.cpp:406] Convolution28 <- Convolution27
I0926 22:37:52.374861  2459 net.cpp:380] Convolution28 -> Convolution28
I0926 22:37:52.375947  2459 net.cpp:122] Setting up Convolution28
I0926 22:37:52.375957  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.375959  2459 net.cpp:137] Memory required for data: 630650000
I0926 22:37:52.375964  2459 layer_factory.hpp:77] Creating layer BatchNorm28
I0926 22:37:52.375972  2459 net.cpp:84] Creating Layer BatchNorm28
I0926 22:37:52.375974  2459 net.cpp:406] BatchNorm28 <- Convolution28
I0926 22:37:52.375977  2459 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0926 22:37:52.376121  2459 net.cpp:122] Setting up BatchNorm28
I0926 22:37:52.376126  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.376127  2459 net.cpp:137] Memory required for data: 633158800
I0926 22:37:52.376132  2459 layer_factory.hpp:77] Creating layer Scale28
I0926 22:37:52.376137  2459 net.cpp:84] Creating Layer Scale28
I0926 22:37:52.376140  2459 net.cpp:406] Scale28 <- Convolution28
I0926 22:37:52.376143  2459 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0926 22:37:52.376171  2459 layer_factory.hpp:77] Creating layer Scale28
I0926 22:37:52.376266  2459 net.cpp:122] Setting up Scale28
I0926 22:37:52.376271  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.376273  2459 net.cpp:137] Memory required for data: 635667600
I0926 22:37:52.376277  2459 layer_factory.hpp:77] Creating layer Eltwise13
I0926 22:37:52.376282  2459 net.cpp:84] Creating Layer Eltwise13
I0926 22:37:52.376286  2459 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0926 22:37:52.376288  2459 net.cpp:406] Eltwise13 <- Convolution28
I0926 22:37:52.376291  2459 net.cpp:380] Eltwise13 -> Eltwise13
I0926 22:37:52.376310  2459 net.cpp:122] Setting up Eltwise13
I0926 22:37:52.376314  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.376317  2459 net.cpp:137] Memory required for data: 638176400
I0926 22:37:52.376318  2459 layer_factory.hpp:77] Creating layer penlu27
I0926 22:37:52.376323  2459 net.cpp:84] Creating Layer penlu27
I0926 22:37:52.376327  2459 net.cpp:406] penlu27 <- Eltwise13
I0926 22:37:52.376329  2459 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0926 22:37:52.376442  2459 net.cpp:122] Setting up penlu27
I0926 22:37:52.376447  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.376449  2459 net.cpp:137] Memory required for data: 640685200
I0926 22:37:52.376461  2459 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0926 22:37:52.376466  2459 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0926 22:37:52.376467  2459 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0926 22:37:52.376471  2459 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0926 22:37:52.376476  2459 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0926 22:37:52.376502  2459 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0926 22:37:52.376505  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.376508  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.376510  2459 net.cpp:137] Memory required for data: 645702800
I0926 22:37:52.376513  2459 layer_factory.hpp:77] Creating layer Convolution29
I0926 22:37:52.376519  2459 net.cpp:84] Creating Layer Convolution29
I0926 22:37:52.376523  2459 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0926 22:37:52.376526  2459 net.cpp:380] Convolution29 -> Convolution29
I0926 22:37:52.377611  2459 net.cpp:122] Setting up Convolution29
I0926 22:37:52.377620  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.377622  2459 net.cpp:137] Memory required for data: 648211600
I0926 22:37:52.377627  2459 layer_factory.hpp:77] Creating layer BatchNorm29
I0926 22:37:52.377634  2459 net.cpp:84] Creating Layer BatchNorm29
I0926 22:37:52.377636  2459 net.cpp:406] BatchNorm29 <- Convolution29
I0926 22:37:52.377640  2459 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0926 22:37:52.377782  2459 net.cpp:122] Setting up BatchNorm29
I0926 22:37:52.377787  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.377789  2459 net.cpp:137] Memory required for data: 650720400
I0926 22:37:52.377794  2459 layer_factory.hpp:77] Creating layer Scale29
I0926 22:37:52.377799  2459 net.cpp:84] Creating Layer Scale29
I0926 22:37:52.377802  2459 net.cpp:406] Scale29 <- Convolution29
I0926 22:37:52.377805  2459 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0926 22:37:52.377833  2459 layer_factory.hpp:77] Creating layer Scale29
I0926 22:37:52.377916  2459 net.cpp:122] Setting up Scale29
I0926 22:37:52.377921  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.377923  2459 net.cpp:137] Memory required for data: 653229200
I0926 22:37:52.377928  2459 layer_factory.hpp:77] Creating layer penlu28
I0926 22:37:52.377933  2459 net.cpp:84] Creating Layer penlu28
I0926 22:37:52.377936  2459 net.cpp:406] penlu28 <- Convolution29
I0926 22:37:52.377940  2459 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0926 22:37:52.378053  2459 net.cpp:122] Setting up penlu28
I0926 22:37:52.378057  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.378059  2459 net.cpp:137] Memory required for data: 655738000
I0926 22:37:52.378064  2459 layer_factory.hpp:77] Creating layer Convolution30
I0926 22:37:52.378072  2459 net.cpp:84] Creating Layer Convolution30
I0926 22:37:52.378074  2459 net.cpp:406] Convolution30 <- Convolution29
I0926 22:37:52.378078  2459 net.cpp:380] Convolution30 -> Convolution30
I0926 22:37:52.379166  2459 net.cpp:122] Setting up Convolution30
I0926 22:37:52.379176  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.379179  2459 net.cpp:137] Memory required for data: 658246800
I0926 22:37:52.379184  2459 layer_factory.hpp:77] Creating layer BatchNorm30
I0926 22:37:52.379189  2459 net.cpp:84] Creating Layer BatchNorm30
I0926 22:37:52.379191  2459 net.cpp:406] BatchNorm30 <- Convolution30
I0926 22:37:52.379195  2459 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0926 22:37:52.379336  2459 net.cpp:122] Setting up BatchNorm30
I0926 22:37:52.379341  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.379343  2459 net.cpp:137] Memory required for data: 660755600
I0926 22:37:52.379348  2459 layer_factory.hpp:77] Creating layer Scale30
I0926 22:37:52.379353  2459 net.cpp:84] Creating Layer Scale30
I0926 22:37:52.379355  2459 net.cpp:406] Scale30 <- Convolution30
I0926 22:37:52.379359  2459 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0926 22:37:52.379395  2459 layer_factory.hpp:77] Creating layer Scale30
I0926 22:37:52.379477  2459 net.cpp:122] Setting up Scale30
I0926 22:37:52.379482  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.379483  2459 net.cpp:137] Memory required for data: 663264400
I0926 22:37:52.379487  2459 layer_factory.hpp:77] Creating layer Eltwise14
I0926 22:37:52.379492  2459 net.cpp:84] Creating Layer Eltwise14
I0926 22:37:52.379494  2459 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0926 22:37:52.379498  2459 net.cpp:406] Eltwise14 <- Convolution30
I0926 22:37:52.379503  2459 net.cpp:380] Eltwise14 -> Eltwise14
I0926 22:37:52.379520  2459 net.cpp:122] Setting up Eltwise14
I0926 22:37:52.379524  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.379528  2459 net.cpp:137] Memory required for data: 665773200
I0926 22:37:52.379529  2459 layer_factory.hpp:77] Creating layer penlu29
I0926 22:37:52.379534  2459 net.cpp:84] Creating Layer penlu29
I0926 22:37:52.379536  2459 net.cpp:406] penlu29 <- Eltwise14
I0926 22:37:52.379540  2459 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0926 22:37:52.379653  2459 net.cpp:122] Setting up penlu29
I0926 22:37:52.379658  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.379660  2459 net.cpp:137] Memory required for data: 668282000
I0926 22:37:52.379664  2459 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0926 22:37:52.379668  2459 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0926 22:37:52.379670  2459 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0926 22:37:52.379673  2459 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0926 22:37:52.379678  2459 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0926 22:37:52.379703  2459 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0926 22:37:52.379706  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.379709  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.379711  2459 net.cpp:137] Memory required for data: 673299600
I0926 22:37:52.379714  2459 layer_factory.hpp:77] Creating layer Convolution31
I0926 22:37:52.379720  2459 net.cpp:84] Creating Layer Convolution31
I0926 22:37:52.379722  2459 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0926 22:37:52.379726  2459 net.cpp:380] Convolution31 -> Convolution31
I0926 22:37:52.380879  2459 net.cpp:122] Setting up Convolution31
I0926 22:37:52.380887  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.380890  2459 net.cpp:137] Memory required for data: 675808400
I0926 22:37:52.380894  2459 layer_factory.hpp:77] Creating layer BatchNorm31
I0926 22:37:52.380899  2459 net.cpp:84] Creating Layer BatchNorm31
I0926 22:37:52.380901  2459 net.cpp:406] BatchNorm31 <- Convolution31
I0926 22:37:52.380906  2459 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0926 22:37:52.381044  2459 net.cpp:122] Setting up BatchNorm31
I0926 22:37:52.381048  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.381050  2459 net.cpp:137] Memory required for data: 678317200
I0926 22:37:52.381055  2459 layer_factory.hpp:77] Creating layer Scale31
I0926 22:37:52.381059  2459 net.cpp:84] Creating Layer Scale31
I0926 22:37:52.381062  2459 net.cpp:406] Scale31 <- Convolution31
I0926 22:37:52.381065  2459 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0926 22:37:52.381091  2459 layer_factory.hpp:77] Creating layer Scale31
I0926 22:37:52.381170  2459 net.cpp:122] Setting up Scale31
I0926 22:37:52.381175  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.381176  2459 net.cpp:137] Memory required for data: 680826000
I0926 22:37:52.381181  2459 layer_factory.hpp:77] Creating layer penlu30
I0926 22:37:52.381186  2459 net.cpp:84] Creating Layer penlu30
I0926 22:37:52.381188  2459 net.cpp:406] penlu30 <- Convolution31
I0926 22:37:52.381191  2459 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0926 22:37:52.381299  2459 net.cpp:122] Setting up penlu30
I0926 22:37:52.381304  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.381314  2459 net.cpp:137] Memory required for data: 683334800
I0926 22:37:52.381319  2459 layer_factory.hpp:77] Creating layer Convolution32
I0926 22:37:52.381325  2459 net.cpp:84] Creating Layer Convolution32
I0926 22:37:52.381327  2459 net.cpp:406] Convolution32 <- Convolution31
I0926 22:37:52.381332  2459 net.cpp:380] Convolution32 -> Convolution32
I0926 22:37:52.382391  2459 net.cpp:122] Setting up Convolution32
I0926 22:37:52.382400  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.382403  2459 net.cpp:137] Memory required for data: 685843600
I0926 22:37:52.382408  2459 layer_factory.hpp:77] Creating layer BatchNorm32
I0926 22:37:52.382412  2459 net.cpp:84] Creating Layer BatchNorm32
I0926 22:37:52.382416  2459 net.cpp:406] BatchNorm32 <- Convolution32
I0926 22:37:52.382419  2459 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0926 22:37:52.382556  2459 net.cpp:122] Setting up BatchNorm32
I0926 22:37:52.382560  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.382562  2459 net.cpp:137] Memory required for data: 688352400
I0926 22:37:52.382567  2459 layer_factory.hpp:77] Creating layer Scale32
I0926 22:37:52.382571  2459 net.cpp:84] Creating Layer Scale32
I0926 22:37:52.382573  2459 net.cpp:406] Scale32 <- Convolution32
I0926 22:37:52.382576  2459 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0926 22:37:52.382603  2459 layer_factory.hpp:77] Creating layer Scale32
I0926 22:37:52.382683  2459 net.cpp:122] Setting up Scale32
I0926 22:37:52.382688  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.382689  2459 net.cpp:137] Memory required for data: 690861200
I0926 22:37:52.382694  2459 layer_factory.hpp:77] Creating layer Eltwise15
I0926 22:37:52.382697  2459 net.cpp:84] Creating Layer Eltwise15
I0926 22:37:52.382699  2459 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0926 22:37:52.382702  2459 net.cpp:406] Eltwise15 <- Convolution32
I0926 22:37:52.382706  2459 net.cpp:380] Eltwise15 -> Eltwise15
I0926 22:37:52.382724  2459 net.cpp:122] Setting up Eltwise15
I0926 22:37:52.382727  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.382730  2459 net.cpp:137] Memory required for data: 693370000
I0926 22:37:52.382731  2459 layer_factory.hpp:77] Creating layer penlu31
I0926 22:37:52.382737  2459 net.cpp:84] Creating Layer penlu31
I0926 22:37:52.382740  2459 net.cpp:406] penlu31 <- Eltwise15
I0926 22:37:52.382743  2459 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0926 22:37:52.382853  2459 net.cpp:122] Setting up penlu31
I0926 22:37:52.382858  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.382870  2459 net.cpp:137] Memory required for data: 695878800
I0926 22:37:52.382874  2459 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0926 22:37:52.382879  2459 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0926 22:37:52.382880  2459 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0926 22:37:52.382884  2459 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0926 22:37:52.382889  2459 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0926 22:37:52.382920  2459 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0926 22:37:52.382925  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.382927  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.382930  2459 net.cpp:137] Memory required for data: 700896400
I0926 22:37:52.382931  2459 layer_factory.hpp:77] Creating layer Convolution33
I0926 22:37:52.382936  2459 net.cpp:84] Creating Layer Convolution33
I0926 22:37:52.382939  2459 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0926 22:37:52.382943  2459 net.cpp:380] Convolution33 -> Convolution33
I0926 22:37:52.384317  2459 net.cpp:122] Setting up Convolution33
I0926 22:37:52.384326  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.384328  2459 net.cpp:137] Memory required for data: 703405200
I0926 22:37:52.384333  2459 layer_factory.hpp:77] Creating layer BatchNorm33
I0926 22:37:52.384346  2459 net.cpp:84] Creating Layer BatchNorm33
I0926 22:37:52.384348  2459 net.cpp:406] BatchNorm33 <- Convolution33
I0926 22:37:52.384352  2459 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0926 22:37:52.384493  2459 net.cpp:122] Setting up BatchNorm33
I0926 22:37:52.384498  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.384500  2459 net.cpp:137] Memory required for data: 705914000
I0926 22:37:52.384505  2459 layer_factory.hpp:77] Creating layer Scale33
I0926 22:37:52.384510  2459 net.cpp:84] Creating Layer Scale33
I0926 22:37:52.384512  2459 net.cpp:406] Scale33 <- Convolution33
I0926 22:37:52.384516  2459 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0926 22:37:52.384543  2459 layer_factory.hpp:77] Creating layer Scale33
I0926 22:37:52.384624  2459 net.cpp:122] Setting up Scale33
I0926 22:37:52.384627  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.384629  2459 net.cpp:137] Memory required for data: 708422800
I0926 22:37:52.384634  2459 layer_factory.hpp:77] Creating layer penlu32
I0926 22:37:52.384639  2459 net.cpp:84] Creating Layer penlu32
I0926 22:37:52.384641  2459 net.cpp:406] penlu32 <- Convolution33
I0926 22:37:52.384645  2459 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0926 22:37:52.384754  2459 net.cpp:122] Setting up penlu32
I0926 22:37:52.384758  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.384760  2459 net.cpp:137] Memory required for data: 710931600
I0926 22:37:52.384764  2459 layer_factory.hpp:77] Creating layer Convolution34
I0926 22:37:52.384771  2459 net.cpp:84] Creating Layer Convolution34
I0926 22:37:52.384773  2459 net.cpp:406] Convolution34 <- Convolution33
I0926 22:37:52.384778  2459 net.cpp:380] Convolution34 -> Convolution34
I0926 22:37:52.385826  2459 net.cpp:122] Setting up Convolution34
I0926 22:37:52.385835  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.385838  2459 net.cpp:137] Memory required for data: 713440400
I0926 22:37:52.385843  2459 layer_factory.hpp:77] Creating layer BatchNorm34
I0926 22:37:52.385848  2459 net.cpp:84] Creating Layer BatchNorm34
I0926 22:37:52.385850  2459 net.cpp:406] BatchNorm34 <- Convolution34
I0926 22:37:52.385854  2459 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0926 22:37:52.386029  2459 net.cpp:122] Setting up BatchNorm34
I0926 22:37:52.386039  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.386042  2459 net.cpp:137] Memory required for data: 715949200
I0926 22:37:52.386050  2459 layer_factory.hpp:77] Creating layer Scale34
I0926 22:37:52.386057  2459 net.cpp:84] Creating Layer Scale34
I0926 22:37:52.386062  2459 net.cpp:406] Scale34 <- Convolution34
I0926 22:37:52.386067  2459 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0926 22:37:52.386112  2459 layer_factory.hpp:77] Creating layer Scale34
I0926 22:37:52.386232  2459 net.cpp:122] Setting up Scale34
I0926 22:37:52.386240  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.386242  2459 net.cpp:137] Memory required for data: 718458000
I0926 22:37:52.386246  2459 layer_factory.hpp:77] Creating layer Eltwise16
I0926 22:37:52.386251  2459 net.cpp:84] Creating Layer Eltwise16
I0926 22:37:52.386255  2459 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0926 22:37:52.386258  2459 net.cpp:406] Eltwise16 <- Convolution34
I0926 22:37:52.386261  2459 net.cpp:380] Eltwise16 -> Eltwise16
I0926 22:37:52.386279  2459 net.cpp:122] Setting up Eltwise16
I0926 22:37:52.386283  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.386286  2459 net.cpp:137] Memory required for data: 720966800
I0926 22:37:52.386287  2459 layer_factory.hpp:77] Creating layer penlu33
I0926 22:37:52.386292  2459 net.cpp:84] Creating Layer penlu33
I0926 22:37:52.386296  2459 net.cpp:406] penlu33 <- Eltwise16
I0926 22:37:52.386298  2459 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0926 22:37:52.386407  2459 net.cpp:122] Setting up penlu33
I0926 22:37:52.386412  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.386415  2459 net.cpp:137] Memory required for data: 723475600
I0926 22:37:52.386425  2459 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0926 22:37:52.386428  2459 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0926 22:37:52.386430  2459 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0926 22:37:52.386435  2459 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0926 22:37:52.386438  2459 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0926 22:37:52.386463  2459 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0926 22:37:52.386467  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.386471  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.386472  2459 net.cpp:137] Memory required for data: 728493200
I0926 22:37:52.386474  2459 layer_factory.hpp:77] Creating layer Convolution35
I0926 22:37:52.386481  2459 net.cpp:84] Creating Layer Convolution35
I0926 22:37:52.386483  2459 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0926 22:37:52.386487  2459 net.cpp:380] Convolution35 -> Convolution35
I0926 22:37:52.387536  2459 net.cpp:122] Setting up Convolution35
I0926 22:37:52.387543  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.387547  2459 net.cpp:137] Memory required for data: 731002000
I0926 22:37:52.387552  2459 layer_factory.hpp:77] Creating layer BatchNorm35
I0926 22:37:52.387557  2459 net.cpp:84] Creating Layer BatchNorm35
I0926 22:37:52.387559  2459 net.cpp:406] BatchNorm35 <- Convolution35
I0926 22:37:52.387562  2459 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0926 22:37:52.387699  2459 net.cpp:122] Setting up BatchNorm35
I0926 22:37:52.387704  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.387706  2459 net.cpp:137] Memory required for data: 733510800
I0926 22:37:52.387712  2459 layer_factory.hpp:77] Creating layer Scale35
I0926 22:37:52.387717  2459 net.cpp:84] Creating Layer Scale35
I0926 22:37:52.387719  2459 net.cpp:406] Scale35 <- Convolution35
I0926 22:37:52.387722  2459 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0926 22:37:52.387750  2459 layer_factory.hpp:77] Creating layer Scale35
I0926 22:37:52.387830  2459 net.cpp:122] Setting up Scale35
I0926 22:37:52.387833  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.387835  2459 net.cpp:137] Memory required for data: 736019600
I0926 22:37:52.387840  2459 layer_factory.hpp:77] Creating layer penlu34
I0926 22:37:52.387845  2459 net.cpp:84] Creating Layer penlu34
I0926 22:37:52.387847  2459 net.cpp:406] penlu34 <- Convolution35
I0926 22:37:52.387851  2459 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0926 22:37:52.387959  2459 net.cpp:122] Setting up penlu34
I0926 22:37:52.387964  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.387965  2459 net.cpp:137] Memory required for data: 738528400
I0926 22:37:52.387970  2459 layer_factory.hpp:77] Creating layer Convolution36
I0926 22:37:52.387976  2459 net.cpp:84] Creating Layer Convolution36
I0926 22:37:52.387979  2459 net.cpp:406] Convolution36 <- Convolution35
I0926 22:37:52.387982  2459 net.cpp:380] Convolution36 -> Convolution36
I0926 22:37:52.389096  2459 net.cpp:122] Setting up Convolution36
I0926 22:37:52.389104  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.389107  2459 net.cpp:137] Memory required for data: 741037200
I0926 22:37:52.389111  2459 layer_factory.hpp:77] Creating layer BatchNorm36
I0926 22:37:52.389116  2459 net.cpp:84] Creating Layer BatchNorm36
I0926 22:37:52.389118  2459 net.cpp:406] BatchNorm36 <- Convolution36
I0926 22:37:52.389122  2459 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0926 22:37:52.389259  2459 net.cpp:122] Setting up BatchNorm36
I0926 22:37:52.389263  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.389266  2459 net.cpp:137] Memory required for data: 743546000
I0926 22:37:52.389271  2459 layer_factory.hpp:77] Creating layer Scale36
I0926 22:37:52.389274  2459 net.cpp:84] Creating Layer Scale36
I0926 22:37:52.389276  2459 net.cpp:406] Scale36 <- Convolution36
I0926 22:37:52.389281  2459 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0926 22:37:52.389315  2459 layer_factory.hpp:77] Creating layer Scale36
I0926 22:37:52.389395  2459 net.cpp:122] Setting up Scale36
I0926 22:37:52.389400  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.389401  2459 net.cpp:137] Memory required for data: 746054800
I0926 22:37:52.389405  2459 layer_factory.hpp:77] Creating layer Eltwise17
I0926 22:37:52.389410  2459 net.cpp:84] Creating Layer Eltwise17
I0926 22:37:52.389411  2459 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0926 22:37:52.389415  2459 net.cpp:406] Eltwise17 <- Convolution36
I0926 22:37:52.389418  2459 net.cpp:380] Eltwise17 -> Eltwise17
I0926 22:37:52.389436  2459 net.cpp:122] Setting up Eltwise17
I0926 22:37:52.389439  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.389441  2459 net.cpp:137] Memory required for data: 748563600
I0926 22:37:52.389443  2459 layer_factory.hpp:77] Creating layer penlu35
I0926 22:37:52.389448  2459 net.cpp:84] Creating Layer penlu35
I0926 22:37:52.389451  2459 net.cpp:406] penlu35 <- Eltwise17
I0926 22:37:52.389454  2459 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0926 22:37:52.389565  2459 net.cpp:122] Setting up penlu35
I0926 22:37:52.389570  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.389572  2459 net.cpp:137] Memory required for data: 751072400
I0926 22:37:52.389576  2459 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0926 22:37:52.389580  2459 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0926 22:37:52.389582  2459 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0926 22:37:52.389585  2459 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0926 22:37:52.389590  2459 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0926 22:37:52.389613  2459 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0926 22:37:52.389617  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.389621  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.389622  2459 net.cpp:137] Memory required for data: 756090000
I0926 22:37:52.389624  2459 layer_factory.hpp:77] Creating layer Convolution37
I0926 22:37:52.389631  2459 net.cpp:84] Creating Layer Convolution37
I0926 22:37:52.389633  2459 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0926 22:37:52.389636  2459 net.cpp:380] Convolution37 -> Convolution37
I0926 22:37:52.390372  2459 net.cpp:122] Setting up Convolution37
I0926 22:37:52.390379  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.390383  2459 net.cpp:137] Memory required for data: 758598800
I0926 22:37:52.390386  2459 layer_factory.hpp:77] Creating layer BatchNorm37
I0926 22:37:52.390391  2459 net.cpp:84] Creating Layer BatchNorm37
I0926 22:37:52.390394  2459 net.cpp:406] BatchNorm37 <- Convolution37
I0926 22:37:52.390398  2459 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0926 22:37:52.390535  2459 net.cpp:122] Setting up BatchNorm37
I0926 22:37:52.390539  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.390542  2459 net.cpp:137] Memory required for data: 761107600
I0926 22:37:52.390547  2459 layer_factory.hpp:77] Creating layer Scale37
I0926 22:37:52.390550  2459 net.cpp:84] Creating Layer Scale37
I0926 22:37:52.390553  2459 net.cpp:406] Scale37 <- Convolution37
I0926 22:37:52.390557  2459 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0926 22:37:52.390583  2459 layer_factory.hpp:77] Creating layer Scale37
I0926 22:37:52.390661  2459 net.cpp:122] Setting up Scale37
I0926 22:37:52.390664  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.390666  2459 net.cpp:137] Memory required for data: 763616400
I0926 22:37:52.390671  2459 layer_factory.hpp:77] Creating layer penlu36
I0926 22:37:52.390676  2459 net.cpp:84] Creating Layer penlu36
I0926 22:37:52.390677  2459 net.cpp:406] penlu36 <- Convolution37
I0926 22:37:52.390681  2459 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0926 22:37:52.390799  2459 net.cpp:122] Setting up penlu36
I0926 22:37:52.390803  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.390812  2459 net.cpp:137] Memory required for data: 766125200
I0926 22:37:52.390825  2459 layer_factory.hpp:77] Creating layer Convolution38
I0926 22:37:52.390833  2459 net.cpp:84] Creating Layer Convolution38
I0926 22:37:52.390836  2459 net.cpp:406] Convolution38 <- Convolution37
I0926 22:37:52.390841  2459 net.cpp:380] Convolution38 -> Convolution38
I0926 22:37:52.391893  2459 net.cpp:122] Setting up Convolution38
I0926 22:37:52.391902  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.391904  2459 net.cpp:137] Memory required for data: 768634000
I0926 22:37:52.391909  2459 layer_factory.hpp:77] Creating layer BatchNorm38
I0926 22:37:52.391914  2459 net.cpp:84] Creating Layer BatchNorm38
I0926 22:37:52.391916  2459 net.cpp:406] BatchNorm38 <- Convolution38
I0926 22:37:52.391921  2459 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0926 22:37:52.392062  2459 net.cpp:122] Setting up BatchNorm38
I0926 22:37:52.392066  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.392068  2459 net.cpp:137] Memory required for data: 771142800
I0926 22:37:52.392073  2459 layer_factory.hpp:77] Creating layer Scale38
I0926 22:37:52.392078  2459 net.cpp:84] Creating Layer Scale38
I0926 22:37:52.392081  2459 net.cpp:406] Scale38 <- Convolution38
I0926 22:37:52.392083  2459 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0926 22:37:52.392112  2459 layer_factory.hpp:77] Creating layer Scale38
I0926 22:37:52.392191  2459 net.cpp:122] Setting up Scale38
I0926 22:37:52.392195  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.392197  2459 net.cpp:137] Memory required for data: 773651600
I0926 22:37:52.392201  2459 layer_factory.hpp:77] Creating layer Eltwise18
I0926 22:37:52.392222  2459 net.cpp:84] Creating Layer Eltwise18
I0926 22:37:52.392228  2459 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0926 22:37:52.392231  2459 net.cpp:406] Eltwise18 <- Convolution38
I0926 22:37:52.392235  2459 net.cpp:380] Eltwise18 -> Eltwise18
I0926 22:37:52.392263  2459 net.cpp:122] Setting up Eltwise18
I0926 22:37:52.392267  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.392269  2459 net.cpp:137] Memory required for data: 776160400
I0926 22:37:52.392271  2459 layer_factory.hpp:77] Creating layer penlu37
I0926 22:37:52.392277  2459 net.cpp:84] Creating Layer penlu37
I0926 22:37:52.392280  2459 net.cpp:406] penlu37 <- Eltwise18
I0926 22:37:52.392283  2459 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0926 22:37:52.392393  2459 net.cpp:122] Setting up penlu37
I0926 22:37:52.392398  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.392400  2459 net.cpp:137] Memory required for data: 778669200
I0926 22:37:52.392405  2459 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0926 22:37:52.392408  2459 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0926 22:37:52.392410  2459 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0926 22:37:52.392413  2459 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0926 22:37:52.392417  2459 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0926 22:37:52.392441  2459 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0926 22:37:52.392444  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.392447  2459 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0926 22:37:52.392449  2459 net.cpp:137] Memory required for data: 783686800
I0926 22:37:52.392452  2459 layer_factory.hpp:77] Creating layer Convolution39
I0926 22:37:52.392457  2459 net.cpp:84] Creating Layer Convolution39
I0926 22:37:52.392460  2459 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0926 22:37:52.392463  2459 net.cpp:380] Convolution39 -> Convolution39
I0926 22:37:52.393354  2459 net.cpp:122] Setting up Convolution39
I0926 22:37:52.393362  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.393365  2459 net.cpp:137] Memory required for data: 784941200
I0926 22:37:52.393369  2459 layer_factory.hpp:77] Creating layer BatchNorm39
I0926 22:37:52.393381  2459 net.cpp:84] Creating Layer BatchNorm39
I0926 22:37:52.393384  2459 net.cpp:406] BatchNorm39 <- Convolution39
I0926 22:37:52.393389  2459 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0926 22:37:52.393525  2459 net.cpp:122] Setting up BatchNorm39
I0926 22:37:52.393530  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.393532  2459 net.cpp:137] Memory required for data: 786195600
I0926 22:37:52.393537  2459 layer_factory.hpp:77] Creating layer Scale39
I0926 22:37:52.393541  2459 net.cpp:84] Creating Layer Scale39
I0926 22:37:52.393544  2459 net.cpp:406] Scale39 <- Convolution39
I0926 22:37:52.393548  2459 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0926 22:37:52.393574  2459 layer_factory.hpp:77] Creating layer Scale39
I0926 22:37:52.393652  2459 net.cpp:122] Setting up Scale39
I0926 22:37:52.393657  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.393659  2459 net.cpp:137] Memory required for data: 787450000
I0926 22:37:52.393662  2459 layer_factory.hpp:77] Creating layer Convolution40
I0926 22:37:52.393669  2459 net.cpp:84] Creating Layer Convolution40
I0926 22:37:52.393672  2459 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0926 22:37:52.393676  2459 net.cpp:380] Convolution40 -> Convolution40
I0926 22:37:52.395424  2459 net.cpp:122] Setting up Convolution40
I0926 22:37:52.395433  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.395436  2459 net.cpp:137] Memory required for data: 788704400
I0926 22:37:52.395440  2459 layer_factory.hpp:77] Creating layer BatchNorm40
I0926 22:37:52.395447  2459 net.cpp:84] Creating Layer BatchNorm40
I0926 22:37:52.395448  2459 net.cpp:406] BatchNorm40 <- Convolution40
I0926 22:37:52.395453  2459 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0926 22:37:52.395591  2459 net.cpp:122] Setting up BatchNorm40
I0926 22:37:52.395596  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.395597  2459 net.cpp:137] Memory required for data: 789958800
I0926 22:37:52.395602  2459 layer_factory.hpp:77] Creating layer Scale40
I0926 22:37:52.395607  2459 net.cpp:84] Creating Layer Scale40
I0926 22:37:52.395609  2459 net.cpp:406] Scale40 <- Convolution40
I0926 22:37:52.395613  2459 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0926 22:37:52.395642  2459 layer_factory.hpp:77] Creating layer Scale40
I0926 22:37:52.395720  2459 net.cpp:122] Setting up Scale40
I0926 22:37:52.395723  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.395725  2459 net.cpp:137] Memory required for data: 791213200
I0926 22:37:52.395730  2459 layer_factory.hpp:77] Creating layer penlu38
I0926 22:37:52.395735  2459 net.cpp:84] Creating Layer penlu38
I0926 22:37:52.395737  2459 net.cpp:406] penlu38 <- Convolution40
I0926 22:37:52.395742  2459 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0926 22:37:52.395850  2459 net.cpp:122] Setting up penlu38
I0926 22:37:52.395854  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.395856  2459 net.cpp:137] Memory required for data: 792467600
I0926 22:37:52.395861  2459 layer_factory.hpp:77] Creating layer Convolution41
I0926 22:37:52.395867  2459 net.cpp:84] Creating Layer Convolution41
I0926 22:37:52.395870  2459 net.cpp:406] Convolution41 <- Convolution40
I0926 22:37:52.395874  2459 net.cpp:380] Convolution41 -> Convolution41
I0926 22:37:52.397905  2459 net.cpp:122] Setting up Convolution41
I0926 22:37:52.397913  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.397917  2459 net.cpp:137] Memory required for data: 793722000
I0926 22:37:52.397922  2459 layer_factory.hpp:77] Creating layer BatchNorm41
I0926 22:37:52.397927  2459 net.cpp:84] Creating Layer BatchNorm41
I0926 22:37:52.397929  2459 net.cpp:406] BatchNorm41 <- Convolution41
I0926 22:37:52.397933  2459 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0926 22:37:52.398074  2459 net.cpp:122] Setting up BatchNorm41
I0926 22:37:52.398079  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.398082  2459 net.cpp:137] Memory required for data: 794976400
I0926 22:37:52.398092  2459 layer_factory.hpp:77] Creating layer Scale41
I0926 22:37:52.398097  2459 net.cpp:84] Creating Layer Scale41
I0926 22:37:52.398099  2459 net.cpp:406] Scale41 <- Convolution41
I0926 22:37:52.398103  2459 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0926 22:37:52.398133  2459 layer_factory.hpp:77] Creating layer Scale41
I0926 22:37:52.398214  2459 net.cpp:122] Setting up Scale41
I0926 22:37:52.398219  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.398221  2459 net.cpp:137] Memory required for data: 796230800
I0926 22:37:52.398226  2459 layer_factory.hpp:77] Creating layer Eltwise19
I0926 22:37:52.398229  2459 net.cpp:84] Creating Layer Eltwise19
I0926 22:37:52.398232  2459 net.cpp:406] Eltwise19 <- Convolution39
I0926 22:37:52.398236  2459 net.cpp:406] Eltwise19 <- Convolution41
I0926 22:37:52.398238  2459 net.cpp:380] Eltwise19 -> Eltwise19
I0926 22:37:52.398257  2459 net.cpp:122] Setting up Eltwise19
I0926 22:37:52.398260  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.398262  2459 net.cpp:137] Memory required for data: 797485200
I0926 22:37:52.398264  2459 layer_factory.hpp:77] Creating layer penlu39
I0926 22:37:52.398269  2459 net.cpp:84] Creating Layer penlu39
I0926 22:37:52.398272  2459 net.cpp:406] penlu39 <- Eltwise19
I0926 22:37:52.398275  2459 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0926 22:37:52.398387  2459 net.cpp:122] Setting up penlu39
I0926 22:37:52.398392  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.398394  2459 net.cpp:137] Memory required for data: 798739600
I0926 22:37:52.398398  2459 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0926 22:37:52.398403  2459 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0926 22:37:52.398406  2459 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0926 22:37:52.398408  2459 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0926 22:37:52.398413  2459 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0926 22:37:52.398437  2459 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0926 22:37:52.398440  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.398443  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.398445  2459 net.cpp:137] Memory required for data: 801248400
I0926 22:37:52.398447  2459 layer_factory.hpp:77] Creating layer Convolution42
I0926 22:37:52.398453  2459 net.cpp:84] Creating Layer Convolution42
I0926 22:37:52.398455  2459 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0926 22:37:52.398460  2459 net.cpp:380] Convolution42 -> Convolution42
I0926 22:37:52.400342  2459 net.cpp:122] Setting up Convolution42
I0926 22:37:52.400354  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.400358  2459 net.cpp:137] Memory required for data: 802502800
I0926 22:37:52.400365  2459 layer_factory.hpp:77] Creating layer BatchNorm42
I0926 22:37:52.400372  2459 net.cpp:84] Creating Layer BatchNorm42
I0926 22:37:52.400377  2459 net.cpp:406] BatchNorm42 <- Convolution42
I0926 22:37:52.400382  2459 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0926 22:37:52.400585  2459 net.cpp:122] Setting up BatchNorm42
I0926 22:37:52.400593  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.400598  2459 net.cpp:137] Memory required for data: 803757200
I0926 22:37:52.400605  2459 layer_factory.hpp:77] Creating layer Scale42
I0926 22:37:52.400611  2459 net.cpp:84] Creating Layer Scale42
I0926 22:37:52.400615  2459 net.cpp:406] Scale42 <- Convolution42
I0926 22:37:52.400620  2459 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0926 22:37:52.400662  2459 layer_factory.hpp:77] Creating layer Scale42
I0926 22:37:52.400779  2459 net.cpp:122] Setting up Scale42
I0926 22:37:52.400785  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.400789  2459 net.cpp:137] Memory required for data: 805011600
I0926 22:37:52.400795  2459 layer_factory.hpp:77] Creating layer penlu40
I0926 22:37:52.400804  2459 net.cpp:84] Creating Layer penlu40
I0926 22:37:52.400807  2459 net.cpp:406] penlu40 <- Convolution42
I0926 22:37:52.400822  2459 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0926 22:37:52.400990  2459 net.cpp:122] Setting up penlu40
I0926 22:37:52.400996  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.401000  2459 net.cpp:137] Memory required for data: 806266000
I0926 22:37:52.401008  2459 layer_factory.hpp:77] Creating layer Convolution43
I0926 22:37:52.401020  2459 net.cpp:84] Creating Layer Convolution43
I0926 22:37:52.401023  2459 net.cpp:406] Convolution43 <- Convolution42
I0926 22:37:52.401031  2459 net.cpp:380] Convolution43 -> Convolution43
I0926 22:37:52.404084  2459 net.cpp:122] Setting up Convolution43
I0926 22:37:52.404096  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.404098  2459 net.cpp:137] Memory required for data: 807520400
I0926 22:37:52.404104  2459 layer_factory.hpp:77] Creating layer BatchNorm43
I0926 22:37:52.404109  2459 net.cpp:84] Creating Layer BatchNorm43
I0926 22:37:52.404112  2459 net.cpp:406] BatchNorm43 <- Convolution43
I0926 22:37:52.404116  2459 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0926 22:37:52.404284  2459 net.cpp:122] Setting up BatchNorm43
I0926 22:37:52.404289  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.404292  2459 net.cpp:137] Memory required for data: 808774800
I0926 22:37:52.404297  2459 layer_factory.hpp:77] Creating layer Scale43
I0926 22:37:52.404301  2459 net.cpp:84] Creating Layer Scale43
I0926 22:37:52.404304  2459 net.cpp:406] Scale43 <- Convolution43
I0926 22:37:52.404307  2459 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0926 22:37:52.404337  2459 layer_factory.hpp:77] Creating layer Scale43
I0926 22:37:52.404431  2459 net.cpp:122] Setting up Scale43
I0926 22:37:52.404436  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.404438  2459 net.cpp:137] Memory required for data: 810029200
I0926 22:37:52.404443  2459 layer_factory.hpp:77] Creating layer Eltwise20
I0926 22:37:52.404446  2459 net.cpp:84] Creating Layer Eltwise20
I0926 22:37:52.404449  2459 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0926 22:37:52.404453  2459 net.cpp:406] Eltwise20 <- Convolution43
I0926 22:37:52.404455  2459 net.cpp:380] Eltwise20 -> Eltwise20
I0926 22:37:52.404474  2459 net.cpp:122] Setting up Eltwise20
I0926 22:37:52.404479  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.404480  2459 net.cpp:137] Memory required for data: 811283600
I0926 22:37:52.404482  2459 layer_factory.hpp:77] Creating layer penlu41
I0926 22:37:52.404487  2459 net.cpp:84] Creating Layer penlu41
I0926 22:37:52.404490  2459 net.cpp:406] penlu41 <- Eltwise20
I0926 22:37:52.404495  2459 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0926 22:37:52.404614  2459 net.cpp:122] Setting up penlu41
I0926 22:37:52.404619  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.404631  2459 net.cpp:137] Memory required for data: 812538000
I0926 22:37:52.404636  2459 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0926 22:37:52.404640  2459 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0926 22:37:52.404642  2459 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0926 22:37:52.404645  2459 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0926 22:37:52.404659  2459 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0926 22:37:52.404685  2459 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0926 22:37:52.404690  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.404692  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.404695  2459 net.cpp:137] Memory required for data: 815046800
I0926 22:37:52.404697  2459 layer_factory.hpp:77] Creating layer Convolution44
I0926 22:37:52.404703  2459 net.cpp:84] Creating Layer Convolution44
I0926 22:37:52.404706  2459 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0926 22:37:52.404711  2459 net.cpp:380] Convolution44 -> Convolution44
I0926 22:37:52.406560  2459 net.cpp:122] Setting up Convolution44
I0926 22:37:52.406570  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.406582  2459 net.cpp:137] Memory required for data: 816301200
I0926 22:37:52.406591  2459 layer_factory.hpp:77] Creating layer BatchNorm44
I0926 22:37:52.406599  2459 net.cpp:84] Creating Layer BatchNorm44
I0926 22:37:52.406602  2459 net.cpp:406] BatchNorm44 <- Convolution44
I0926 22:37:52.406610  2459 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0926 22:37:52.406827  2459 net.cpp:122] Setting up BatchNorm44
I0926 22:37:52.406837  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.406842  2459 net.cpp:137] Memory required for data: 817555600
I0926 22:37:52.406850  2459 layer_factory.hpp:77] Creating layer Scale44
I0926 22:37:52.406857  2459 net.cpp:84] Creating Layer Scale44
I0926 22:37:52.406862  2459 net.cpp:406] Scale44 <- Convolution44
I0926 22:37:52.406867  2459 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0926 22:37:52.406919  2459 layer_factory.hpp:77] Creating layer Scale44
I0926 22:37:52.407030  2459 net.cpp:122] Setting up Scale44
I0926 22:37:52.407039  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.407043  2459 net.cpp:137] Memory required for data: 818810000
I0926 22:37:52.407050  2459 layer_factory.hpp:77] Creating layer penlu42
I0926 22:37:52.407058  2459 net.cpp:84] Creating Layer penlu42
I0926 22:37:52.407063  2459 net.cpp:406] penlu42 <- Convolution44
I0926 22:37:52.407070  2459 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0926 22:37:52.407232  2459 net.cpp:122] Setting up penlu42
I0926 22:37:52.407240  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.407243  2459 net.cpp:137] Memory required for data: 820064400
I0926 22:37:52.407248  2459 layer_factory.hpp:77] Creating layer Convolution45
I0926 22:37:52.407254  2459 net.cpp:84] Creating Layer Convolution45
I0926 22:37:52.407258  2459 net.cpp:406] Convolution45 <- Convolution44
I0926 22:37:52.407265  2459 net.cpp:380] Convolution45 -> Convolution45
I0926 22:37:52.409780  2459 net.cpp:122] Setting up Convolution45
I0926 22:37:52.409791  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.409796  2459 net.cpp:137] Memory required for data: 821318800
I0926 22:37:52.409806  2459 layer_factory.hpp:77] Creating layer BatchNorm45
I0926 22:37:52.409814  2459 net.cpp:84] Creating Layer BatchNorm45
I0926 22:37:52.409818  2459 net.cpp:406] BatchNorm45 <- Convolution45
I0926 22:37:52.409826  2459 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0926 22:37:52.410037  2459 net.cpp:122] Setting up BatchNorm45
I0926 22:37:52.410046  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.410048  2459 net.cpp:137] Memory required for data: 822573200
I0926 22:37:52.410054  2459 layer_factory.hpp:77] Creating layer Scale45
I0926 22:37:52.410058  2459 net.cpp:84] Creating Layer Scale45
I0926 22:37:52.410061  2459 net.cpp:406] Scale45 <- Convolution45
I0926 22:37:52.410065  2459 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0926 22:37:52.410096  2459 layer_factory.hpp:77] Creating layer Scale45
I0926 22:37:52.410179  2459 net.cpp:122] Setting up Scale45
I0926 22:37:52.410184  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.410187  2459 net.cpp:137] Memory required for data: 823827600
I0926 22:37:52.410190  2459 layer_factory.hpp:77] Creating layer Eltwise21
I0926 22:37:52.410194  2459 net.cpp:84] Creating Layer Eltwise21
I0926 22:37:52.410197  2459 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0926 22:37:52.410200  2459 net.cpp:406] Eltwise21 <- Convolution45
I0926 22:37:52.410204  2459 net.cpp:380] Eltwise21 -> Eltwise21
I0926 22:37:52.410221  2459 net.cpp:122] Setting up Eltwise21
I0926 22:37:52.410225  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.410228  2459 net.cpp:137] Memory required for data: 825082000
I0926 22:37:52.410229  2459 layer_factory.hpp:77] Creating layer penlu43
I0926 22:37:52.410234  2459 net.cpp:84] Creating Layer penlu43
I0926 22:37:52.410236  2459 net.cpp:406] penlu43 <- Eltwise21
I0926 22:37:52.410239  2459 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0926 22:37:52.410388  2459 net.cpp:122] Setting up penlu43
I0926 22:37:52.410408  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.410411  2459 net.cpp:137] Memory required for data: 826336400
I0926 22:37:52.410416  2459 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0926 22:37:52.410423  2459 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0926 22:37:52.410425  2459 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0926 22:37:52.410429  2459 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0926 22:37:52.410434  2459 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0926 22:37:52.410462  2459 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0926 22:37:52.410467  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.410470  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.410471  2459 net.cpp:137] Memory required for data: 828845200
I0926 22:37:52.410473  2459 layer_factory.hpp:77] Creating layer Convolution46
I0926 22:37:52.410480  2459 net.cpp:84] Creating Layer Convolution46
I0926 22:37:52.410482  2459 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0926 22:37:52.410487  2459 net.cpp:380] Convolution46 -> Convolution46
I0926 22:37:52.412175  2459 net.cpp:122] Setting up Convolution46
I0926 22:37:52.412184  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.412187  2459 net.cpp:137] Memory required for data: 830099600
I0926 22:37:52.412191  2459 layer_factory.hpp:77] Creating layer BatchNorm46
I0926 22:37:52.412197  2459 net.cpp:84] Creating Layer BatchNorm46
I0926 22:37:52.412200  2459 net.cpp:406] BatchNorm46 <- Convolution46
I0926 22:37:52.412220  2459 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0926 22:37:52.412379  2459 net.cpp:122] Setting up BatchNorm46
I0926 22:37:52.412384  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.412386  2459 net.cpp:137] Memory required for data: 831354000
I0926 22:37:52.412391  2459 layer_factory.hpp:77] Creating layer Scale46
I0926 22:37:52.412395  2459 net.cpp:84] Creating Layer Scale46
I0926 22:37:52.412397  2459 net.cpp:406] Scale46 <- Convolution46
I0926 22:37:52.412401  2459 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0926 22:37:52.412430  2459 layer_factory.hpp:77] Creating layer Scale46
I0926 22:37:52.412513  2459 net.cpp:122] Setting up Scale46
I0926 22:37:52.412516  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.412518  2459 net.cpp:137] Memory required for data: 832608400
I0926 22:37:52.412523  2459 layer_factory.hpp:77] Creating layer penlu44
I0926 22:37:52.412528  2459 net.cpp:84] Creating Layer penlu44
I0926 22:37:52.412530  2459 net.cpp:406] penlu44 <- Convolution46
I0926 22:37:52.412534  2459 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0926 22:37:52.412668  2459 net.cpp:122] Setting up penlu44
I0926 22:37:52.412673  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.412675  2459 net.cpp:137] Memory required for data: 833862800
I0926 22:37:52.412679  2459 layer_factory.hpp:77] Creating layer Convolution47
I0926 22:37:52.412686  2459 net.cpp:84] Creating Layer Convolution47
I0926 22:37:52.412688  2459 net.cpp:406] Convolution47 <- Convolution46
I0926 22:37:52.412693  2459 net.cpp:380] Convolution47 -> Convolution47
I0926 22:37:52.414335  2459 net.cpp:122] Setting up Convolution47
I0926 22:37:52.414343  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.414346  2459 net.cpp:137] Memory required for data: 835117200
I0926 22:37:52.414350  2459 layer_factory.hpp:77] Creating layer BatchNorm47
I0926 22:37:52.414355  2459 net.cpp:84] Creating Layer BatchNorm47
I0926 22:37:52.414358  2459 net.cpp:406] BatchNorm47 <- Convolution47
I0926 22:37:52.414361  2459 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0926 22:37:52.414508  2459 net.cpp:122] Setting up BatchNorm47
I0926 22:37:52.414513  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.414515  2459 net.cpp:137] Memory required for data: 836371600
I0926 22:37:52.414520  2459 layer_factory.hpp:77] Creating layer Scale47
I0926 22:37:52.414531  2459 net.cpp:84] Creating Layer Scale47
I0926 22:37:52.414535  2459 net.cpp:406] Scale47 <- Convolution47
I0926 22:37:52.414537  2459 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0926 22:37:52.414568  2459 layer_factory.hpp:77] Creating layer Scale47
I0926 22:37:52.414650  2459 net.cpp:122] Setting up Scale47
I0926 22:37:52.414654  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.414657  2459 net.cpp:137] Memory required for data: 837626000
I0926 22:37:52.414661  2459 layer_factory.hpp:77] Creating layer Eltwise22
I0926 22:37:52.414665  2459 net.cpp:84] Creating Layer Eltwise22
I0926 22:37:52.414669  2459 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0926 22:37:52.414671  2459 net.cpp:406] Eltwise22 <- Convolution47
I0926 22:37:52.414674  2459 net.cpp:380] Eltwise22 -> Eltwise22
I0926 22:37:52.414692  2459 net.cpp:122] Setting up Eltwise22
I0926 22:37:52.414696  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.414698  2459 net.cpp:137] Memory required for data: 838880400
I0926 22:37:52.414700  2459 layer_factory.hpp:77] Creating layer penlu45
I0926 22:37:52.414705  2459 net.cpp:84] Creating Layer penlu45
I0926 22:37:52.414707  2459 net.cpp:406] penlu45 <- Eltwise22
I0926 22:37:52.414711  2459 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0926 22:37:52.414826  2459 net.cpp:122] Setting up penlu45
I0926 22:37:52.414830  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.414832  2459 net.cpp:137] Memory required for data: 840134800
I0926 22:37:52.414837  2459 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0926 22:37:52.414841  2459 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0926 22:37:52.414844  2459 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0926 22:37:52.414847  2459 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0926 22:37:52.414851  2459 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0926 22:37:52.414876  2459 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0926 22:37:52.414880  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.414882  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.414885  2459 net.cpp:137] Memory required for data: 842643600
I0926 22:37:52.414886  2459 layer_factory.hpp:77] Creating layer Convolution48
I0926 22:37:52.414892  2459 net.cpp:84] Creating Layer Convolution48
I0926 22:37:52.414894  2459 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0926 22:37:52.414899  2459 net.cpp:380] Convolution48 -> Convolution48
I0926 22:37:52.416553  2459 net.cpp:122] Setting up Convolution48
I0926 22:37:52.416563  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.416565  2459 net.cpp:137] Memory required for data: 843898000
I0926 22:37:52.416569  2459 layer_factory.hpp:77] Creating layer BatchNorm48
I0926 22:37:52.416574  2459 net.cpp:84] Creating Layer BatchNorm48
I0926 22:37:52.416577  2459 net.cpp:406] BatchNorm48 <- Convolution48
I0926 22:37:52.416581  2459 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0926 22:37:52.416726  2459 net.cpp:122] Setting up BatchNorm48
I0926 22:37:52.416731  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.416733  2459 net.cpp:137] Memory required for data: 845152400
I0926 22:37:52.416738  2459 layer_factory.hpp:77] Creating layer Scale48
I0926 22:37:52.416741  2459 net.cpp:84] Creating Layer Scale48
I0926 22:37:52.416744  2459 net.cpp:406] Scale48 <- Convolution48
I0926 22:37:52.416748  2459 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0926 22:37:52.416775  2459 layer_factory.hpp:77] Creating layer Scale48
I0926 22:37:52.416858  2459 net.cpp:122] Setting up Scale48
I0926 22:37:52.416862  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.416864  2459 net.cpp:137] Memory required for data: 846406800
I0926 22:37:52.416868  2459 layer_factory.hpp:77] Creating layer penlu46
I0926 22:37:52.416873  2459 net.cpp:84] Creating Layer penlu46
I0926 22:37:52.416877  2459 net.cpp:406] penlu46 <- Convolution48
I0926 22:37:52.416880  2459 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0926 22:37:52.417004  2459 net.cpp:122] Setting up penlu46
I0926 22:37:52.417009  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.417011  2459 net.cpp:137] Memory required for data: 847661200
I0926 22:37:52.417016  2459 layer_factory.hpp:77] Creating layer Convolution49
I0926 22:37:52.417022  2459 net.cpp:84] Creating Layer Convolution49
I0926 22:37:52.417024  2459 net.cpp:406] Convolution49 <- Convolution48
I0926 22:37:52.417029  2459 net.cpp:380] Convolution49 -> Convolution49
I0926 22:37:52.418985  2459 net.cpp:122] Setting up Convolution49
I0926 22:37:52.418994  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.418997  2459 net.cpp:137] Memory required for data: 848915600
I0926 22:37:52.419001  2459 layer_factory.hpp:77] Creating layer BatchNorm49
I0926 22:37:52.419006  2459 net.cpp:84] Creating Layer BatchNorm49
I0926 22:37:52.419009  2459 net.cpp:406] BatchNorm49 <- Convolution49
I0926 22:37:52.419013  2459 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0926 22:37:52.419160  2459 net.cpp:122] Setting up BatchNorm49
I0926 22:37:52.419165  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.419167  2459 net.cpp:137] Memory required for data: 850170000
I0926 22:37:52.419172  2459 layer_factory.hpp:77] Creating layer Scale49
I0926 22:37:52.419176  2459 net.cpp:84] Creating Layer Scale49
I0926 22:37:52.419179  2459 net.cpp:406] Scale49 <- Convolution49
I0926 22:37:52.419183  2459 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0926 22:37:52.419211  2459 layer_factory.hpp:77] Creating layer Scale49
I0926 22:37:52.419294  2459 net.cpp:122] Setting up Scale49
I0926 22:37:52.419299  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.419301  2459 net.cpp:137] Memory required for data: 851424400
I0926 22:37:52.419306  2459 layer_factory.hpp:77] Creating layer Eltwise23
I0926 22:37:52.419309  2459 net.cpp:84] Creating Layer Eltwise23
I0926 22:37:52.419312  2459 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0926 22:37:52.419315  2459 net.cpp:406] Eltwise23 <- Convolution49
I0926 22:37:52.419319  2459 net.cpp:380] Eltwise23 -> Eltwise23
I0926 22:37:52.419337  2459 net.cpp:122] Setting up Eltwise23
I0926 22:37:52.419339  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.419342  2459 net.cpp:137] Memory required for data: 852678800
I0926 22:37:52.419343  2459 layer_factory.hpp:77] Creating layer penlu47
I0926 22:37:52.419349  2459 net.cpp:84] Creating Layer penlu47
I0926 22:37:52.419351  2459 net.cpp:406] penlu47 <- Eltwise23
I0926 22:37:52.419355  2459 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0926 22:37:52.419471  2459 net.cpp:122] Setting up penlu47
I0926 22:37:52.419476  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.419477  2459 net.cpp:137] Memory required for data: 853933200
I0926 22:37:52.419481  2459 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0926 22:37:52.419486  2459 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0926 22:37:52.419487  2459 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0926 22:37:52.419492  2459 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0926 22:37:52.419497  2459 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0926 22:37:52.419520  2459 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0926 22:37:52.419524  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.419526  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.419528  2459 net.cpp:137] Memory required for data: 856442000
I0926 22:37:52.419530  2459 layer_factory.hpp:77] Creating layer Convolution50
I0926 22:37:52.419538  2459 net.cpp:84] Creating Layer Convolution50
I0926 22:37:52.419539  2459 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0926 22:37:52.419543  2459 net.cpp:380] Convolution50 -> Convolution50
I0926 22:37:52.421227  2459 net.cpp:122] Setting up Convolution50
I0926 22:37:52.421236  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.421245  2459 net.cpp:137] Memory required for data: 857696400
I0926 22:37:52.421250  2459 layer_factory.hpp:77] Creating layer BatchNorm50
I0926 22:37:52.421257  2459 net.cpp:84] Creating Layer BatchNorm50
I0926 22:37:52.421260  2459 net.cpp:406] BatchNorm50 <- Convolution50
I0926 22:37:52.421263  2459 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0926 22:37:52.421409  2459 net.cpp:122] Setting up BatchNorm50
I0926 22:37:52.421414  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.421416  2459 net.cpp:137] Memory required for data: 858950800
I0926 22:37:52.421422  2459 layer_factory.hpp:77] Creating layer Scale50
I0926 22:37:52.421425  2459 net.cpp:84] Creating Layer Scale50
I0926 22:37:52.421428  2459 net.cpp:406] Scale50 <- Convolution50
I0926 22:37:52.421432  2459 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0926 22:37:52.421463  2459 layer_factory.hpp:77] Creating layer Scale50
I0926 22:37:52.421550  2459 net.cpp:122] Setting up Scale50
I0926 22:37:52.421553  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.421555  2459 net.cpp:137] Memory required for data: 860205200
I0926 22:37:52.421560  2459 layer_factory.hpp:77] Creating layer penlu48
I0926 22:37:52.421564  2459 net.cpp:84] Creating Layer penlu48
I0926 22:37:52.421567  2459 net.cpp:406] penlu48 <- Convolution50
I0926 22:37:52.421571  2459 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0926 22:37:52.421687  2459 net.cpp:122] Setting up penlu48
I0926 22:37:52.421691  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.421694  2459 net.cpp:137] Memory required for data: 861459600
I0926 22:37:52.421697  2459 layer_factory.hpp:77] Creating layer Convolution51
I0926 22:37:52.421705  2459 net.cpp:84] Creating Layer Convolution51
I0926 22:37:52.421706  2459 net.cpp:406] Convolution51 <- Convolution50
I0926 22:37:52.421710  2459 net.cpp:380] Convolution51 -> Convolution51
I0926 22:37:52.423761  2459 net.cpp:122] Setting up Convolution51
I0926 22:37:52.423770  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.423774  2459 net.cpp:137] Memory required for data: 862714000
I0926 22:37:52.423777  2459 layer_factory.hpp:77] Creating layer BatchNorm51
I0926 22:37:52.423784  2459 net.cpp:84] Creating Layer BatchNorm51
I0926 22:37:52.423785  2459 net.cpp:406] BatchNorm51 <- Convolution51
I0926 22:37:52.423789  2459 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0926 22:37:52.423943  2459 net.cpp:122] Setting up BatchNorm51
I0926 22:37:52.423948  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.423949  2459 net.cpp:137] Memory required for data: 863968400
I0926 22:37:52.423954  2459 layer_factory.hpp:77] Creating layer Scale51
I0926 22:37:52.423959  2459 net.cpp:84] Creating Layer Scale51
I0926 22:37:52.423961  2459 net.cpp:406] Scale51 <- Convolution51
I0926 22:37:52.423965  2459 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0926 22:37:52.423995  2459 layer_factory.hpp:77] Creating layer Scale51
I0926 22:37:52.424079  2459 net.cpp:122] Setting up Scale51
I0926 22:37:52.424084  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.424087  2459 net.cpp:137] Memory required for data: 865222800
I0926 22:37:52.424089  2459 layer_factory.hpp:77] Creating layer Eltwise24
I0926 22:37:52.424093  2459 net.cpp:84] Creating Layer Eltwise24
I0926 22:37:52.424096  2459 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0926 22:37:52.424100  2459 net.cpp:406] Eltwise24 <- Convolution51
I0926 22:37:52.424103  2459 net.cpp:380] Eltwise24 -> Eltwise24
I0926 22:37:52.424121  2459 net.cpp:122] Setting up Eltwise24
I0926 22:37:52.424125  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.424127  2459 net.cpp:137] Memory required for data: 866477200
I0926 22:37:52.424129  2459 layer_factory.hpp:77] Creating layer penlu49
I0926 22:37:52.424134  2459 net.cpp:84] Creating Layer penlu49
I0926 22:37:52.424137  2459 net.cpp:406] penlu49 <- Eltwise24
I0926 22:37:52.424140  2459 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0926 22:37:52.424278  2459 net.cpp:122] Setting up penlu49
I0926 22:37:52.424291  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.424293  2459 net.cpp:137] Memory required for data: 867731600
I0926 22:37:52.424299  2459 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0926 22:37:52.424302  2459 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0926 22:37:52.424304  2459 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0926 22:37:52.424309  2459 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0926 22:37:52.424312  2459 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0926 22:37:52.424340  2459 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0926 22:37:52.424345  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.424347  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.424350  2459 net.cpp:137] Memory required for data: 870240400
I0926 22:37:52.424351  2459 layer_factory.hpp:77] Creating layer Convolution52
I0926 22:37:52.424358  2459 net.cpp:84] Creating Layer Convolution52
I0926 22:37:52.424360  2459 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0926 22:37:52.424365  2459 net.cpp:380] Convolution52 -> Convolution52
I0926 22:37:52.426105  2459 net.cpp:122] Setting up Convolution52
I0926 22:37:52.426113  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.426116  2459 net.cpp:137] Memory required for data: 871494800
I0926 22:37:52.426120  2459 layer_factory.hpp:77] Creating layer BatchNorm52
I0926 22:37:52.426126  2459 net.cpp:84] Creating Layer BatchNorm52
I0926 22:37:52.426128  2459 net.cpp:406] BatchNorm52 <- Convolution52
I0926 22:37:52.426132  2459 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0926 22:37:52.426282  2459 net.cpp:122] Setting up BatchNorm52
I0926 22:37:52.426286  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.426288  2459 net.cpp:137] Memory required for data: 872749200
I0926 22:37:52.426293  2459 layer_factory.hpp:77] Creating layer Scale52
I0926 22:37:52.426297  2459 net.cpp:84] Creating Layer Scale52
I0926 22:37:52.426301  2459 net.cpp:406] Scale52 <- Convolution52
I0926 22:37:52.426304  2459 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0926 22:37:52.426332  2459 layer_factory.hpp:77] Creating layer Scale52
I0926 22:37:52.426419  2459 net.cpp:122] Setting up Scale52
I0926 22:37:52.426424  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.426426  2459 net.cpp:137] Memory required for data: 874003600
I0926 22:37:52.426429  2459 layer_factory.hpp:77] Creating layer penlu50
I0926 22:37:52.426435  2459 net.cpp:84] Creating Layer penlu50
I0926 22:37:52.426439  2459 net.cpp:406] penlu50 <- Convolution52
I0926 22:37:52.426442  2459 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0926 22:37:52.426561  2459 net.cpp:122] Setting up penlu50
I0926 22:37:52.426565  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.426568  2459 net.cpp:137] Memory required for data: 875258000
I0926 22:37:52.426609  2459 layer_factory.hpp:77] Creating layer Convolution53
I0926 22:37:52.426631  2459 net.cpp:84] Creating Layer Convolution53
I0926 22:37:52.426635  2459 net.cpp:406] Convolution53 <- Convolution52
I0926 22:37:52.426638  2459 net.cpp:380] Convolution53 -> Convolution53
I0926 22:37:52.428643  2459 net.cpp:122] Setting up Convolution53
I0926 22:37:52.428661  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.428664  2459 net.cpp:137] Memory required for data: 876512400
I0926 22:37:52.428669  2459 layer_factory.hpp:77] Creating layer BatchNorm53
I0926 22:37:52.428675  2459 net.cpp:84] Creating Layer BatchNorm53
I0926 22:37:52.428678  2459 net.cpp:406] BatchNorm53 <- Convolution53
I0926 22:37:52.428681  2459 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0926 22:37:52.428874  2459 net.cpp:122] Setting up BatchNorm53
I0926 22:37:52.428879  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.428881  2459 net.cpp:137] Memory required for data: 877766800
I0926 22:37:52.431795  2459 layer_factory.hpp:77] Creating layer Scale53
I0926 22:37:52.431807  2459 net.cpp:84] Creating Layer Scale53
I0926 22:37:52.431818  2459 net.cpp:406] Scale53 <- Convolution53
I0926 22:37:52.431823  2459 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0926 22:37:52.431869  2459 layer_factory.hpp:77] Creating layer Scale53
I0926 22:37:52.431970  2459 net.cpp:122] Setting up Scale53
I0926 22:37:52.431975  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.431977  2459 net.cpp:137] Memory required for data: 879021200
I0926 22:37:52.431982  2459 layer_factory.hpp:77] Creating layer Eltwise25
I0926 22:37:52.431988  2459 net.cpp:84] Creating Layer Eltwise25
I0926 22:37:52.431991  2459 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0926 22:37:52.431994  2459 net.cpp:406] Eltwise25 <- Convolution53
I0926 22:37:52.431998  2459 net.cpp:380] Eltwise25 -> Eltwise25
I0926 22:37:52.432018  2459 net.cpp:122] Setting up Eltwise25
I0926 22:37:52.432024  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.432025  2459 net.cpp:137] Memory required for data: 880275600
I0926 22:37:52.432027  2459 layer_factory.hpp:77] Creating layer penlu51
I0926 22:37:52.432034  2459 net.cpp:84] Creating Layer penlu51
I0926 22:37:52.432036  2459 net.cpp:406] penlu51 <- Eltwise25
I0926 22:37:52.432039  2459 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0926 22:37:52.432170  2459 net.cpp:122] Setting up penlu51
I0926 22:37:52.432175  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.432178  2459 net.cpp:137] Memory required for data: 881530000
I0926 22:37:52.432183  2459 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0926 22:37:52.432186  2459 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0926 22:37:52.432189  2459 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0926 22:37:52.432193  2459 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0926 22:37:52.432198  2459 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0926 22:37:52.432240  2459 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0926 22:37:52.432247  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.432250  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.432252  2459 net.cpp:137] Memory required for data: 884038800
I0926 22:37:52.432255  2459 layer_factory.hpp:77] Creating layer Convolution54
I0926 22:37:52.432262  2459 net.cpp:84] Creating Layer Convolution54
I0926 22:37:52.432265  2459 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0926 22:37:52.432270  2459 net.cpp:380] Convolution54 -> Convolution54
I0926 22:37:52.434871  2459 net.cpp:122] Setting up Convolution54
I0926 22:37:52.434882  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.434885  2459 net.cpp:137] Memory required for data: 885293200
I0926 22:37:52.434890  2459 layer_factory.hpp:77] Creating layer BatchNorm54
I0926 22:37:52.434895  2459 net.cpp:84] Creating Layer BatchNorm54
I0926 22:37:52.434898  2459 net.cpp:406] BatchNorm54 <- Convolution54
I0926 22:37:52.434902  2459 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0926 22:37:52.435058  2459 net.cpp:122] Setting up BatchNorm54
I0926 22:37:52.435063  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.435065  2459 net.cpp:137] Memory required for data: 886547600
I0926 22:37:52.435070  2459 layer_factory.hpp:77] Creating layer Scale54
I0926 22:37:52.435075  2459 net.cpp:84] Creating Layer Scale54
I0926 22:37:52.435077  2459 net.cpp:406] Scale54 <- Convolution54
I0926 22:37:52.435081  2459 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0926 22:37:52.435127  2459 layer_factory.hpp:77] Creating layer Scale54
I0926 22:37:52.435227  2459 net.cpp:122] Setting up Scale54
I0926 22:37:52.435232  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.435235  2459 net.cpp:137] Memory required for data: 887802000
I0926 22:37:52.435238  2459 layer_factory.hpp:77] Creating layer penlu52
I0926 22:37:52.435243  2459 net.cpp:84] Creating Layer penlu52
I0926 22:37:52.435246  2459 net.cpp:406] penlu52 <- Convolution54
I0926 22:37:52.435251  2459 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0926 22:37:52.435384  2459 net.cpp:122] Setting up penlu52
I0926 22:37:52.435389  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.435390  2459 net.cpp:137] Memory required for data: 889056400
I0926 22:37:52.435395  2459 layer_factory.hpp:77] Creating layer Convolution55
I0926 22:37:52.435402  2459 net.cpp:84] Creating Layer Convolution55
I0926 22:37:52.435405  2459 net.cpp:406] Convolution55 <- Convolution54
I0926 22:37:52.435410  2459 net.cpp:380] Convolution55 -> Convolution55
I0926 22:37:52.437507  2459 net.cpp:122] Setting up Convolution55
I0926 22:37:52.437516  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.437520  2459 net.cpp:137] Memory required for data: 890310800
I0926 22:37:52.437525  2459 layer_factory.hpp:77] Creating layer BatchNorm55
I0926 22:37:52.437530  2459 net.cpp:84] Creating Layer BatchNorm55
I0926 22:37:52.437532  2459 net.cpp:406] BatchNorm55 <- Convolution55
I0926 22:37:52.437536  2459 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0926 22:37:52.437695  2459 net.cpp:122] Setting up BatchNorm55
I0926 22:37:52.437700  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.437701  2459 net.cpp:137] Memory required for data: 891565200
I0926 22:37:52.437706  2459 layer_factory.hpp:77] Creating layer Scale55
I0926 22:37:52.437711  2459 net.cpp:84] Creating Layer Scale55
I0926 22:37:52.437713  2459 net.cpp:406] Scale55 <- Convolution55
I0926 22:37:52.437717  2459 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0926 22:37:52.437748  2459 layer_factory.hpp:77] Creating layer Scale55
I0926 22:37:52.437837  2459 net.cpp:122] Setting up Scale55
I0926 22:37:52.437842  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.437844  2459 net.cpp:137] Memory required for data: 892819600
I0926 22:37:52.437849  2459 layer_factory.hpp:77] Creating layer Eltwise26
I0926 22:37:52.437852  2459 net.cpp:84] Creating Layer Eltwise26
I0926 22:37:52.437855  2459 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0926 22:37:52.437858  2459 net.cpp:406] Eltwise26 <- Convolution55
I0926 22:37:52.437863  2459 net.cpp:380] Eltwise26 -> Eltwise26
I0926 22:37:52.437881  2459 net.cpp:122] Setting up Eltwise26
I0926 22:37:52.437885  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.437887  2459 net.cpp:137] Memory required for data: 894074000
I0926 22:37:52.437889  2459 layer_factory.hpp:77] Creating layer penlu53
I0926 22:37:52.437896  2459 net.cpp:84] Creating Layer penlu53
I0926 22:37:52.437897  2459 net.cpp:406] penlu53 <- Eltwise26
I0926 22:37:52.437901  2459 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0926 22:37:52.438025  2459 net.cpp:122] Setting up penlu53
I0926 22:37:52.438030  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.438032  2459 net.cpp:137] Memory required for data: 895328400
I0926 22:37:52.438037  2459 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0926 22:37:52.438041  2459 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0926 22:37:52.438043  2459 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0926 22:37:52.438047  2459 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0926 22:37:52.438051  2459 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0926 22:37:52.438078  2459 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0926 22:37:52.438081  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.438084  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.438086  2459 net.cpp:137] Memory required for data: 897837200
I0926 22:37:52.438088  2459 layer_factory.hpp:77] Creating layer Convolution56
I0926 22:37:52.438096  2459 net.cpp:84] Creating Layer Convolution56
I0926 22:37:52.438097  2459 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0926 22:37:52.438102  2459 net.cpp:380] Convolution56 -> Convolution56
I0926 22:37:52.439826  2459 net.cpp:122] Setting up Convolution56
I0926 22:37:52.439836  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.439838  2459 net.cpp:137] Memory required for data: 899091600
I0926 22:37:52.439849  2459 layer_factory.hpp:77] Creating layer BatchNorm56
I0926 22:37:52.439855  2459 net.cpp:84] Creating Layer BatchNorm56
I0926 22:37:52.439858  2459 net.cpp:406] BatchNorm56 <- Convolution56
I0926 22:37:52.439862  2459 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0926 22:37:52.440018  2459 net.cpp:122] Setting up BatchNorm56
I0926 22:37:52.440023  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.440026  2459 net.cpp:137] Memory required for data: 900346000
I0926 22:37:52.440030  2459 layer_factory.hpp:77] Creating layer Scale56
I0926 22:37:52.440034  2459 net.cpp:84] Creating Layer Scale56
I0926 22:37:52.440037  2459 net.cpp:406] Scale56 <- Convolution56
I0926 22:37:52.440040  2459 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0926 22:37:52.440071  2459 layer_factory.hpp:77] Creating layer Scale56
I0926 22:37:52.440160  2459 net.cpp:122] Setting up Scale56
I0926 22:37:52.440163  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.440165  2459 net.cpp:137] Memory required for data: 901600400
I0926 22:37:52.440170  2459 layer_factory.hpp:77] Creating layer penlu54
I0926 22:37:52.440176  2459 net.cpp:84] Creating Layer penlu54
I0926 22:37:52.440177  2459 net.cpp:406] penlu54 <- Convolution56
I0926 22:37:52.440181  2459 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0926 22:37:52.440318  2459 net.cpp:122] Setting up penlu54
I0926 22:37:52.440325  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.440326  2459 net.cpp:137] Memory required for data: 902854800
I0926 22:37:52.440331  2459 layer_factory.hpp:77] Creating layer Convolution57
I0926 22:37:52.440338  2459 net.cpp:84] Creating Layer Convolution57
I0926 22:37:52.440340  2459 net.cpp:406] Convolution57 <- Convolution56
I0926 22:37:52.440345  2459 net.cpp:380] Convolution57 -> Convolution57
I0926 22:37:52.442049  2459 net.cpp:122] Setting up Convolution57
I0926 22:37:52.442059  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.442061  2459 net.cpp:137] Memory required for data: 904109200
I0926 22:37:52.442066  2459 layer_factory.hpp:77] Creating layer BatchNorm57
I0926 22:37:52.442071  2459 net.cpp:84] Creating Layer BatchNorm57
I0926 22:37:52.442075  2459 net.cpp:406] BatchNorm57 <- Convolution57
I0926 22:37:52.442077  2459 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0926 22:37:52.442237  2459 net.cpp:122] Setting up BatchNorm57
I0926 22:37:52.442242  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.442245  2459 net.cpp:137] Memory required for data: 905363600
I0926 22:37:52.442250  2459 layer_factory.hpp:77] Creating layer Scale57
I0926 22:37:52.442253  2459 net.cpp:84] Creating Layer Scale57
I0926 22:37:52.442256  2459 net.cpp:406] Scale57 <- Convolution57
I0926 22:37:52.442260  2459 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0926 22:37:52.442292  2459 layer_factory.hpp:77] Creating layer Scale57
I0926 22:37:52.442384  2459 net.cpp:122] Setting up Scale57
I0926 22:37:52.442389  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.442391  2459 net.cpp:137] Memory required for data: 906618000
I0926 22:37:52.442395  2459 layer_factory.hpp:77] Creating layer Eltwise27
I0926 22:37:52.442400  2459 net.cpp:84] Creating Layer Eltwise27
I0926 22:37:52.442404  2459 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0926 22:37:52.442406  2459 net.cpp:406] Eltwise27 <- Convolution57
I0926 22:37:52.442409  2459 net.cpp:380] Eltwise27 -> Eltwise27
I0926 22:37:52.442427  2459 net.cpp:122] Setting up Eltwise27
I0926 22:37:52.442431  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.442433  2459 net.cpp:137] Memory required for data: 907872400
I0926 22:37:52.442435  2459 layer_factory.hpp:77] Creating layer penlu55
I0926 22:37:52.442440  2459 net.cpp:84] Creating Layer penlu55
I0926 22:37:52.442443  2459 net.cpp:406] penlu55 <- Eltwise27
I0926 22:37:52.442446  2459 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0926 22:37:52.442571  2459 net.cpp:122] Setting up penlu55
I0926 22:37:52.442575  2459 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0926 22:37:52.442584  2459 net.cpp:137] Memory required for data: 909126800
I0926 22:37:52.442589  2459 layer_factory.hpp:77] Creating layer Pooling1
I0926 22:37:52.442595  2459 net.cpp:84] Creating Layer Pooling1
I0926 22:37:52.442597  2459 net.cpp:406] Pooling1 <- Eltwise27
I0926 22:37:52.442601  2459 net.cpp:380] Pooling1 -> Pooling1
I0926 22:37:52.443081  2459 net.cpp:122] Setting up Pooling1
I0926 22:37:52.443089  2459 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0926 22:37:52.443092  2459 net.cpp:137] Memory required for data: 909152400
I0926 22:37:52.443095  2459 layer_factory.hpp:77] Creating layer InnerProduct1
I0926 22:37:52.466140  2459 net.cpp:84] Creating Layer InnerProduct1
I0926 22:37:52.466151  2459 net.cpp:406] InnerProduct1 <- Pooling1
I0926 22:37:52.466157  2459 net.cpp:380] InnerProduct1 -> InnerProduct1
I0926 22:37:52.466300  2459 net.cpp:122] Setting up InnerProduct1
I0926 22:37:52.466306  2459 net.cpp:129] Top shape: 100 10 (1000)
I0926 22:37:52.466310  2459 net.cpp:137] Memory required for data: 909156400
I0926 22:37:52.466315  2459 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 22:37:52.466320  2459 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0926 22:37:52.466321  2459 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0926 22:37:52.466325  2459 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0926 22:37:52.466329  2459 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0926 22:37:52.466336  2459 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 22:37:52.466563  2459 net.cpp:122] Setting up SoftmaxWithLoss1
I0926 22:37:52.466570  2459 net.cpp:129] Top shape: (1)
I0926 22:37:52.466572  2459 net.cpp:132]     with loss weight 1
I0926 22:37:52.466585  2459 net.cpp:137] Memory required for data: 909156404
I0926 22:37:52.466588  2459 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0926 22:37:52.466591  2459 net.cpp:198] InnerProduct1 needs backward computation.
I0926 22:37:52.466593  2459 net.cpp:198] Pooling1 needs backward computation.
I0926 22:37:52.466595  2459 net.cpp:198] penlu55 needs backward computation.
I0926 22:37:52.466598  2459 net.cpp:198] Eltwise27 needs backward computation.
I0926 22:37:52.466600  2459 net.cpp:198] Scale57 needs backward computation.
I0926 22:37:52.466603  2459 net.cpp:198] BatchNorm57 needs backward computation.
I0926 22:37:52.466604  2459 net.cpp:198] Convolution57 needs backward computation.
I0926 22:37:52.466608  2459 net.cpp:198] penlu54 needs backward computation.
I0926 22:37:52.466609  2459 net.cpp:198] Scale56 needs backward computation.
I0926 22:37:52.466611  2459 net.cpp:198] BatchNorm56 needs backward computation.
I0926 22:37:52.466614  2459 net.cpp:198] Convolution56 needs backward computation.
I0926 22:37:52.466616  2459 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0926 22:37:52.466619  2459 net.cpp:198] penlu53 needs backward computation.
I0926 22:37:52.466621  2459 net.cpp:198] Eltwise26 needs backward computation.
I0926 22:37:52.466624  2459 net.cpp:198] Scale55 needs backward computation.
I0926 22:37:52.466626  2459 net.cpp:198] BatchNorm55 needs backward computation.
I0926 22:37:52.466629  2459 net.cpp:198] Convolution55 needs backward computation.
I0926 22:37:52.466630  2459 net.cpp:198] penlu52 needs backward computation.
I0926 22:37:52.466632  2459 net.cpp:198] Scale54 needs backward computation.
I0926 22:37:52.466635  2459 net.cpp:198] BatchNorm54 needs backward computation.
I0926 22:37:52.466637  2459 net.cpp:198] Convolution54 needs backward computation.
I0926 22:37:52.466639  2459 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0926 22:37:52.466642  2459 net.cpp:198] penlu51 needs backward computation.
I0926 22:37:52.466645  2459 net.cpp:198] Eltwise25 needs backward computation.
I0926 22:37:52.466647  2459 net.cpp:198] Scale53 needs backward computation.
I0926 22:37:52.466650  2459 net.cpp:198] BatchNorm53 needs backward computation.
I0926 22:37:52.466652  2459 net.cpp:198] Convolution53 needs backward computation.
I0926 22:37:52.466655  2459 net.cpp:198] penlu50 needs backward computation.
I0926 22:37:52.466665  2459 net.cpp:198] Scale52 needs backward computation.
I0926 22:37:52.466667  2459 net.cpp:198] BatchNorm52 needs backward computation.
I0926 22:37:52.466672  2459 net.cpp:198] Convolution52 needs backward computation.
I0926 22:37:52.466675  2459 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0926 22:37:52.466677  2459 net.cpp:198] penlu49 needs backward computation.
I0926 22:37:52.466680  2459 net.cpp:198] Eltwise24 needs backward computation.
I0926 22:37:52.466682  2459 net.cpp:198] Scale51 needs backward computation.
I0926 22:37:52.466686  2459 net.cpp:198] BatchNorm51 needs backward computation.
I0926 22:37:52.466687  2459 net.cpp:198] Convolution51 needs backward computation.
I0926 22:37:52.466691  2459 net.cpp:198] penlu48 needs backward computation.
I0926 22:37:52.466692  2459 net.cpp:198] Scale50 needs backward computation.
I0926 22:37:52.466694  2459 net.cpp:198] BatchNorm50 needs backward computation.
I0926 22:37:52.466697  2459 net.cpp:198] Convolution50 needs backward computation.
I0926 22:37:52.466699  2459 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0926 22:37:52.466702  2459 net.cpp:198] penlu47 needs backward computation.
I0926 22:37:52.466704  2459 net.cpp:198] Eltwise23 needs backward computation.
I0926 22:37:52.466707  2459 net.cpp:198] Scale49 needs backward computation.
I0926 22:37:52.466709  2459 net.cpp:198] BatchNorm49 needs backward computation.
I0926 22:37:52.466712  2459 net.cpp:198] Convolution49 needs backward computation.
I0926 22:37:52.466714  2459 net.cpp:198] penlu46 needs backward computation.
I0926 22:37:52.466717  2459 net.cpp:198] Scale48 needs backward computation.
I0926 22:37:52.466719  2459 net.cpp:198] BatchNorm48 needs backward computation.
I0926 22:37:52.466722  2459 net.cpp:198] Convolution48 needs backward computation.
I0926 22:37:52.466724  2459 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0926 22:37:52.466727  2459 net.cpp:198] penlu45 needs backward computation.
I0926 22:37:52.466729  2459 net.cpp:198] Eltwise22 needs backward computation.
I0926 22:37:52.466732  2459 net.cpp:198] Scale47 needs backward computation.
I0926 22:37:52.466734  2459 net.cpp:198] BatchNorm47 needs backward computation.
I0926 22:37:52.466737  2459 net.cpp:198] Convolution47 needs backward computation.
I0926 22:37:52.466739  2459 net.cpp:198] penlu44 needs backward computation.
I0926 22:37:52.466742  2459 net.cpp:198] Scale46 needs backward computation.
I0926 22:37:52.466744  2459 net.cpp:198] BatchNorm46 needs backward computation.
I0926 22:37:52.466747  2459 net.cpp:198] Convolution46 needs backward computation.
I0926 22:37:52.466749  2459 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0926 22:37:52.466751  2459 net.cpp:198] penlu43 needs backward computation.
I0926 22:37:52.466754  2459 net.cpp:198] Eltwise21 needs backward computation.
I0926 22:37:52.466756  2459 net.cpp:198] Scale45 needs backward computation.
I0926 22:37:52.466759  2459 net.cpp:198] BatchNorm45 needs backward computation.
I0926 22:37:52.466761  2459 net.cpp:198] Convolution45 needs backward computation.
I0926 22:37:52.466764  2459 net.cpp:198] penlu42 needs backward computation.
I0926 22:37:52.466766  2459 net.cpp:198] Scale44 needs backward computation.
I0926 22:37:52.466768  2459 net.cpp:198] BatchNorm44 needs backward computation.
I0926 22:37:52.466771  2459 net.cpp:198] Convolution44 needs backward computation.
I0926 22:37:52.466773  2459 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0926 22:37:52.466776  2459 net.cpp:198] penlu41 needs backward computation.
I0926 22:37:52.466778  2459 net.cpp:198] Eltwise20 needs backward computation.
I0926 22:37:52.466781  2459 net.cpp:198] Scale43 needs backward computation.
I0926 22:37:52.466784  2459 net.cpp:198] BatchNorm43 needs backward computation.
I0926 22:37:52.466786  2459 net.cpp:198] Convolution43 needs backward computation.
I0926 22:37:52.466789  2459 net.cpp:198] penlu40 needs backward computation.
I0926 22:37:52.466794  2459 net.cpp:198] Scale42 needs backward computation.
I0926 22:37:52.466797  2459 net.cpp:198] BatchNorm42 needs backward computation.
I0926 22:37:52.466799  2459 net.cpp:198] Convolution42 needs backward computation.
I0926 22:37:52.466802  2459 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0926 22:37:52.466805  2459 net.cpp:198] penlu39 needs backward computation.
I0926 22:37:52.466807  2459 net.cpp:198] Eltwise19 needs backward computation.
I0926 22:37:52.466810  2459 net.cpp:198] Scale41 needs backward computation.
I0926 22:37:52.466814  2459 net.cpp:198] BatchNorm41 needs backward computation.
I0926 22:37:52.466815  2459 net.cpp:198] Convolution41 needs backward computation.
I0926 22:37:52.466819  2459 net.cpp:198] penlu38 needs backward computation.
I0926 22:37:52.466820  2459 net.cpp:198] Scale40 needs backward computation.
I0926 22:37:52.466823  2459 net.cpp:198] BatchNorm40 needs backward computation.
I0926 22:37:52.466825  2459 net.cpp:198] Convolution40 needs backward computation.
I0926 22:37:52.466828  2459 net.cpp:198] Scale39 needs backward computation.
I0926 22:37:52.466831  2459 net.cpp:198] BatchNorm39 needs backward computation.
I0926 22:37:52.466833  2459 net.cpp:198] Convolution39 needs backward computation.
I0926 22:37:52.466836  2459 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0926 22:37:52.466838  2459 net.cpp:198] penlu37 needs backward computation.
I0926 22:37:52.466841  2459 net.cpp:198] Eltwise18 needs backward computation.
I0926 22:37:52.466843  2459 net.cpp:198] Scale38 needs backward computation.
I0926 22:37:52.466846  2459 net.cpp:198] BatchNorm38 needs backward computation.
I0926 22:37:52.466850  2459 net.cpp:198] Convolution38 needs backward computation.
I0926 22:37:52.466851  2459 net.cpp:198] penlu36 needs backward computation.
I0926 22:37:52.466855  2459 net.cpp:198] Scale37 needs backward computation.
I0926 22:37:52.466856  2459 net.cpp:198] BatchNorm37 needs backward computation.
I0926 22:37:52.466858  2459 net.cpp:198] Convolution37 needs backward computation.
I0926 22:37:52.466861  2459 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0926 22:37:52.466864  2459 net.cpp:198] penlu35 needs backward computation.
I0926 22:37:52.466866  2459 net.cpp:198] Eltwise17 needs backward computation.
I0926 22:37:52.466869  2459 net.cpp:198] Scale36 needs backward computation.
I0926 22:37:52.466871  2459 net.cpp:198] BatchNorm36 needs backward computation.
I0926 22:37:52.466874  2459 net.cpp:198] Convolution36 needs backward computation.
I0926 22:37:52.466876  2459 net.cpp:198] penlu34 needs backward computation.
I0926 22:37:52.466879  2459 net.cpp:198] Scale35 needs backward computation.
I0926 22:37:52.466881  2459 net.cpp:198] BatchNorm35 needs backward computation.
I0926 22:37:52.466883  2459 net.cpp:198] Convolution35 needs backward computation.
I0926 22:37:52.466886  2459 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0926 22:37:52.466889  2459 net.cpp:198] penlu33 needs backward computation.
I0926 22:37:52.466892  2459 net.cpp:198] Eltwise16 needs backward computation.
I0926 22:37:52.466894  2459 net.cpp:198] Scale34 needs backward computation.
I0926 22:37:52.466897  2459 net.cpp:198] BatchNorm34 needs backward computation.
I0926 22:37:52.466899  2459 net.cpp:198] Convolution34 needs backward computation.
I0926 22:37:52.466902  2459 net.cpp:198] penlu32 needs backward computation.
I0926 22:37:52.466904  2459 net.cpp:198] Scale33 needs backward computation.
I0926 22:37:52.466907  2459 net.cpp:198] BatchNorm33 needs backward computation.
I0926 22:37:52.466909  2459 net.cpp:198] Convolution33 needs backward computation.
I0926 22:37:52.466912  2459 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0926 22:37:52.466914  2459 net.cpp:198] penlu31 needs backward computation.
I0926 22:37:52.466917  2459 net.cpp:198] Eltwise15 needs backward computation.
I0926 22:37:52.466919  2459 net.cpp:198] Scale32 needs backward computation.
I0926 22:37:52.466922  2459 net.cpp:198] BatchNorm32 needs backward computation.
I0926 22:37:52.466928  2459 net.cpp:198] Convolution32 needs backward computation.
I0926 22:37:52.466930  2459 net.cpp:198] penlu30 needs backward computation.
I0926 22:37:52.466933  2459 net.cpp:198] Scale31 needs backward computation.
I0926 22:37:52.466935  2459 net.cpp:198] BatchNorm31 needs backward computation.
I0926 22:37:52.466938  2459 net.cpp:198] Convolution31 needs backward computation.
I0926 22:37:52.466944  2459 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0926 22:37:52.466948  2459 net.cpp:198] penlu29 needs backward computation.
I0926 22:37:52.466949  2459 net.cpp:198] Eltwise14 needs backward computation.
I0926 22:37:52.466953  2459 net.cpp:198] Scale30 needs backward computation.
I0926 22:37:52.466955  2459 net.cpp:198] BatchNorm30 needs backward computation.
I0926 22:37:52.466958  2459 net.cpp:198] Convolution30 needs backward computation.
I0926 22:37:52.466959  2459 net.cpp:198] penlu28 needs backward computation.
I0926 22:37:52.466962  2459 net.cpp:198] Scale29 needs backward computation.
I0926 22:37:52.466964  2459 net.cpp:198] BatchNorm29 needs backward computation.
I0926 22:37:52.466967  2459 net.cpp:198] Convolution29 needs backward computation.
I0926 22:37:52.466969  2459 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0926 22:37:52.466972  2459 net.cpp:198] penlu27 needs backward computation.
I0926 22:37:52.466974  2459 net.cpp:198] Eltwise13 needs backward computation.
I0926 22:37:52.466977  2459 net.cpp:198] Scale28 needs backward computation.
I0926 22:37:52.466980  2459 net.cpp:198] BatchNorm28 needs backward computation.
I0926 22:37:52.466982  2459 net.cpp:198] Convolution28 needs backward computation.
I0926 22:37:52.466985  2459 net.cpp:198] penlu26 needs backward computation.
I0926 22:37:52.466987  2459 net.cpp:198] Scale27 needs backward computation.
I0926 22:37:52.466989  2459 net.cpp:198] BatchNorm27 needs backward computation.
I0926 22:37:52.466992  2459 net.cpp:198] Convolution27 needs backward computation.
I0926 22:37:52.466995  2459 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0926 22:37:52.466997  2459 net.cpp:198] penlu25 needs backward computation.
I0926 22:37:52.467000  2459 net.cpp:198] Eltwise12 needs backward computation.
I0926 22:37:52.467002  2459 net.cpp:198] Scale26 needs backward computation.
I0926 22:37:52.467005  2459 net.cpp:198] BatchNorm26 needs backward computation.
I0926 22:37:52.467007  2459 net.cpp:198] Convolution26 needs backward computation.
I0926 22:37:52.467010  2459 net.cpp:198] penlu24 needs backward computation.
I0926 22:37:52.467012  2459 net.cpp:198] Scale25 needs backward computation.
I0926 22:37:52.467015  2459 net.cpp:198] BatchNorm25 needs backward computation.
I0926 22:37:52.467017  2459 net.cpp:198] Convolution25 needs backward computation.
I0926 22:37:52.467020  2459 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0926 22:37:52.467022  2459 net.cpp:198] penlu23 needs backward computation.
I0926 22:37:52.467025  2459 net.cpp:198] Eltwise11 needs backward computation.
I0926 22:37:52.467027  2459 net.cpp:198] Scale24 needs backward computation.
I0926 22:37:52.467031  2459 net.cpp:198] BatchNorm24 needs backward computation.
I0926 22:37:52.467032  2459 net.cpp:198] Convolution24 needs backward computation.
I0926 22:37:52.467036  2459 net.cpp:198] penlu22 needs backward computation.
I0926 22:37:52.467037  2459 net.cpp:198] Scale23 needs backward computation.
I0926 22:37:52.467041  2459 net.cpp:198] BatchNorm23 needs backward computation.
I0926 22:37:52.467042  2459 net.cpp:198] Convolution23 needs backward computation.
I0926 22:37:52.467046  2459 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0926 22:37:52.467049  2459 net.cpp:198] penlu21 needs backward computation.
I0926 22:37:52.467052  2459 net.cpp:198] Eltwise10 needs backward computation.
I0926 22:37:52.467054  2459 net.cpp:198] Scale22 needs backward computation.
I0926 22:37:52.467057  2459 net.cpp:198] BatchNorm22 needs backward computation.
I0926 22:37:52.467059  2459 net.cpp:198] Convolution22 needs backward computation.
I0926 22:37:52.467066  2459 net.cpp:198] penlu20 needs backward computation.
I0926 22:37:52.467068  2459 net.cpp:198] Scale21 needs backward computation.
I0926 22:37:52.467070  2459 net.cpp:198] BatchNorm21 needs backward computation.
I0926 22:37:52.467073  2459 net.cpp:198] Convolution21 needs backward computation.
I0926 22:37:52.467075  2459 net.cpp:198] Scale20 needs backward computation.
I0926 22:37:52.467078  2459 net.cpp:198] BatchNorm20 needs backward computation.
I0926 22:37:52.467080  2459 net.cpp:198] Convolution20 needs backward computation.
I0926 22:37:52.467083  2459 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0926 22:37:52.467087  2459 net.cpp:198] penlu19 needs backward computation.
I0926 22:37:52.467088  2459 net.cpp:198] Eltwise9 needs backward computation.
I0926 22:37:52.467092  2459 net.cpp:198] Scale19 needs backward computation.
I0926 22:37:52.467094  2459 net.cpp:198] BatchNorm19 needs backward computation.
I0926 22:37:52.467097  2459 net.cpp:198] Convolution19 needs backward computation.
I0926 22:37:52.467099  2459 net.cpp:198] penlu18 needs backward computation.
I0926 22:37:52.467103  2459 net.cpp:198] Scale18 needs backward computation.
I0926 22:37:52.467104  2459 net.cpp:198] BatchNorm18 needs backward computation.
I0926 22:37:52.467106  2459 net.cpp:198] Convolution18 needs backward computation.
I0926 22:37:52.467109  2459 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0926 22:37:52.467113  2459 net.cpp:198] penlu17 needs backward computation.
I0926 22:37:52.467114  2459 net.cpp:198] Eltwise8 needs backward computation.
I0926 22:37:52.467118  2459 net.cpp:198] Scale17 needs backward computation.
I0926 22:37:52.467120  2459 net.cpp:198] BatchNorm17 needs backward computation.
I0926 22:37:52.467123  2459 net.cpp:198] Convolution17 needs backward computation.
I0926 22:37:52.467125  2459 net.cpp:198] penlu16 needs backward computation.
I0926 22:37:52.467128  2459 net.cpp:198] Scale16 needs backward computation.
I0926 22:37:52.467130  2459 net.cpp:198] BatchNorm16 needs backward computation.
I0926 22:37:52.467133  2459 net.cpp:198] Convolution16 needs backward computation.
I0926 22:37:52.467135  2459 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0926 22:37:52.467139  2459 net.cpp:198] penlu15 needs backward computation.
I0926 22:37:52.467140  2459 net.cpp:198] Eltwise7 needs backward computation.
I0926 22:37:52.467144  2459 net.cpp:198] Scale15 needs backward computation.
I0926 22:37:52.467146  2459 net.cpp:198] BatchNorm15 needs backward computation.
I0926 22:37:52.467149  2459 net.cpp:198] Convolution15 needs backward computation.
I0926 22:37:52.467151  2459 net.cpp:198] penlu14 needs backward computation.
I0926 22:37:52.467154  2459 net.cpp:198] Scale14 needs backward computation.
I0926 22:37:52.467155  2459 net.cpp:198] BatchNorm14 needs backward computation.
I0926 22:37:52.467159  2459 net.cpp:198] Convolution14 needs backward computation.
I0926 22:37:52.467161  2459 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0926 22:37:52.467164  2459 net.cpp:198] penlu13 needs backward computation.
I0926 22:37:52.467166  2459 net.cpp:198] Eltwise6 needs backward computation.
I0926 22:37:52.467170  2459 net.cpp:198] Scale13 needs backward computation.
I0926 22:37:52.467171  2459 net.cpp:198] BatchNorm13 needs backward computation.
I0926 22:37:52.467173  2459 net.cpp:198] Convolution13 needs backward computation.
I0926 22:37:52.467176  2459 net.cpp:198] penlu12 needs backward computation.
I0926 22:37:52.467178  2459 net.cpp:198] Scale12 needs backward computation.
I0926 22:37:52.492858  2459 net.cpp:198] BatchNorm12 needs backward computation.
I0926 22:37:52.492866  2459 net.cpp:198] Convolution12 needs backward computation.
I0926 22:37:52.492869  2459 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0926 22:37:52.492872  2459 net.cpp:198] penlu11 needs backward computation.
I0926 22:37:52.492874  2459 net.cpp:198] Eltwise5 needs backward computation.
I0926 22:37:52.492885  2459 net.cpp:198] Scale11 needs backward computation.
I0926 22:37:52.492888  2459 net.cpp:198] BatchNorm11 needs backward computation.
I0926 22:37:52.492890  2459 net.cpp:198] Convolution11 needs backward computation.
I0926 22:37:52.492893  2459 net.cpp:198] penlu10 needs backward computation.
I0926 22:37:52.492895  2459 net.cpp:198] Scale10 needs backward computation.
I0926 22:37:52.492897  2459 net.cpp:198] BatchNorm10 needs backward computation.
I0926 22:37:52.492900  2459 net.cpp:198] Convolution10 needs backward computation.
I0926 22:37:52.492903  2459 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0926 22:37:52.492907  2459 net.cpp:198] penlu9 needs backward computation.
I0926 22:37:52.492908  2459 net.cpp:198] Eltwise4 needs backward computation.
I0926 22:37:52.492913  2459 net.cpp:198] Scale9 needs backward computation.
I0926 22:37:52.492915  2459 net.cpp:198] BatchNorm9 needs backward computation.
I0926 22:37:52.492918  2459 net.cpp:198] Convolution9 needs backward computation.
I0926 22:37:52.492920  2459 net.cpp:198] penlu8 needs backward computation.
I0926 22:37:52.492923  2459 net.cpp:198] Scale8 needs backward computation.
I0926 22:37:52.492925  2459 net.cpp:198] BatchNorm8 needs backward computation.
I0926 22:37:52.492928  2459 net.cpp:198] Convolution8 needs backward computation.
I0926 22:37:52.492930  2459 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0926 22:37:52.492933  2459 net.cpp:198] penlu7 needs backward computation.
I0926 22:37:52.492936  2459 net.cpp:198] Eltwise3 needs backward computation.
I0926 22:37:52.492939  2459 net.cpp:198] Scale7 needs backward computation.
I0926 22:37:52.492943  2459 net.cpp:198] BatchNorm7 needs backward computation.
I0926 22:37:52.492944  2459 net.cpp:198] Convolution7 needs backward computation.
I0926 22:37:52.492946  2459 net.cpp:198] penlu6 needs backward computation.
I0926 22:37:52.492949  2459 net.cpp:198] Scale6 needs backward computation.
I0926 22:37:52.492951  2459 net.cpp:198] BatchNorm6 needs backward computation.
I0926 22:37:52.492954  2459 net.cpp:198] Convolution6 needs backward computation.
I0926 22:37:52.492956  2459 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0926 22:37:52.492959  2459 net.cpp:198] penlu5 needs backward computation.
I0926 22:37:52.492961  2459 net.cpp:198] Eltwise2 needs backward computation.
I0926 22:37:52.492965  2459 net.cpp:198] Scale5 needs backward computation.
I0926 22:37:52.492967  2459 net.cpp:198] BatchNorm5 needs backward computation.
I0926 22:37:52.492970  2459 net.cpp:198] Convolution5 needs backward computation.
I0926 22:37:52.492972  2459 net.cpp:198] penlu4 needs backward computation.
I0926 22:37:52.492975  2459 net.cpp:198] Scale4 needs backward computation.
I0926 22:37:52.492977  2459 net.cpp:198] BatchNorm4 needs backward computation.
I0926 22:37:52.492980  2459 net.cpp:198] Convolution4 needs backward computation.
I0926 22:37:52.492982  2459 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0926 22:37:52.492985  2459 net.cpp:198] penlu3 needs backward computation.
I0926 22:37:52.492987  2459 net.cpp:198] Eltwise1 needs backward computation.
I0926 22:37:52.492990  2459 net.cpp:198] Scale3 needs backward computation.
I0926 22:37:52.492993  2459 net.cpp:198] BatchNorm3 needs backward computation.
I0926 22:37:52.492995  2459 net.cpp:198] Convolution3 needs backward computation.
I0926 22:37:52.492998  2459 net.cpp:198] penlu2 needs backward computation.
I0926 22:37:52.493000  2459 net.cpp:198] Scale2 needs backward computation.
I0926 22:37:52.493003  2459 net.cpp:198] BatchNorm2 needs backward computation.
I0926 22:37:52.493005  2459 net.cpp:198] Convolution2 needs backward computation.
I0926 22:37:52.493008  2459 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0926 22:37:52.493011  2459 net.cpp:198] penlu1 needs backward computation.
I0926 22:37:52.493015  2459 net.cpp:198] Scale1 needs backward computation.
I0926 22:37:52.493016  2459 net.cpp:198] BatchNorm1 needs backward computation.
I0926 22:37:52.493022  2459 net.cpp:198] Convolution1 needs backward computation.
I0926 22:37:52.493026  2459 net.cpp:200] Data1 does not need backward computation.
I0926 22:37:52.493027  2459 net.cpp:242] This network produces output SoftmaxWithLoss1
I0926 22:37:52.493124  2459 net.cpp:255] Network initialization done.
I0926 22:37:52.498008  2459 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 22:37:52.498024  2459 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0926 22:37:52.498029  2459 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0926 22:37:52.498234  2459 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0926 22:37:52.499689  2459 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      
I0926 22:37:52.554812  2459 layer_factory.hpp:77] Creating layer Data1
I0926 22:37:52.654381  2459 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0926 22:37:52.698532  2459 net.cpp:84] Creating Layer Data1
I0926 22:37:52.698554  2459 net.cpp:380] Data1 -> Data1
I0926 22:37:52.698567  2459 net.cpp:380] Data1 -> Data2
I0926 22:37:52.698576  2459 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0926 22:37:52.698863  2459 data_layer.cpp:45] output data size: 100,3,32,32
I0926 22:37:52.705102  2459 net.cpp:122] Setting up Data1
I0926 22:37:52.705124  2459 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0926 22:37:52.705130  2459 net.cpp:129] Top shape: 100 (100)
I0926 22:37:52.705134  2459 net.cpp:137] Memory required for data: 1229200
I0926 22:37:52.705139  2459 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0926 22:37:52.705149  2459 net.cpp:84] Creating Layer Data2_Data1_1_split
I0926 22:37:52.705155  2459 net.cpp:406] Data2_Data1_1_split <- Data2
I0926 22:37:52.705163  2459 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0926 22:37:52.705173  2459 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0926 22:37:52.705251  2459 net.cpp:122] Setting up Data2_Data1_1_split
I0926 22:37:52.705261  2459 net.cpp:129] Top shape: 100 (100)
I0926 22:37:52.705265  2459 net.cpp:129] Top shape: 100 (100)
I0926 22:37:52.705269  2459 net.cpp:137] Memory required for data: 1230000
I0926 22:37:52.705272  2459 layer_factory.hpp:77] Creating layer Convolution1
I0926 22:37:52.705287  2459 net.cpp:84] Creating Layer Convolution1
I0926 22:37:52.705293  2459 net.cpp:406] Convolution1 <- Data1
I0926 22:37:52.705302  2459 net.cpp:380] Convolution1 -> Convolution1
I0926 22:37:52.707176  2459 net.cpp:122] Setting up Convolution1
I0926 22:37:52.707207  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.707213  2459 net.cpp:137] Memory required for data: 7783600
I0926 22:37:52.707227  2459 layer_factory.hpp:77] Creating layer BatchNorm1
I0926 22:37:52.707237  2459 net.cpp:84] Creating Layer BatchNorm1
I0926 22:37:52.707242  2459 net.cpp:406] BatchNorm1 <- Convolution1
I0926 22:37:52.707249  2459 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0926 22:37:52.707511  2459 net.cpp:122] Setting up BatchNorm1
I0926 22:37:52.707520  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.707525  2459 net.cpp:137] Memory required for data: 14337200
I0926 22:37:52.707538  2459 layer_factory.hpp:77] Creating layer Scale1
I0926 22:37:52.707548  2459 net.cpp:84] Creating Layer Scale1
I0926 22:37:52.707551  2459 net.cpp:406] Scale1 <- Convolution1
I0926 22:37:52.707557  2459 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0926 22:37:52.707612  2459 layer_factory.hpp:77] Creating layer Scale1
I0926 22:37:52.707758  2459 net.cpp:122] Setting up Scale1
I0926 22:37:52.707767  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.707769  2459 net.cpp:137] Memory required for data: 20890800
I0926 22:37:52.707777  2459 layer_factory.hpp:77] Creating layer penlu1
I0926 22:37:52.707787  2459 net.cpp:84] Creating Layer penlu1
I0926 22:37:52.707792  2459 net.cpp:406] penlu1 <- Convolution1
I0926 22:37:52.707798  2459 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0926 22:37:52.708647  2459 net.cpp:122] Setting up penlu1
I0926 22:37:52.708657  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.708660  2459 net.cpp:137] Memory required for data: 27444400
I0926 22:37:52.708668  2459 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0926 22:37:52.708674  2459 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0926 22:37:52.708678  2459 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0926 22:37:52.708681  2459 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0926 22:37:52.708688  2459 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0926 22:37:52.708721  2459 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0926 22:37:52.708727  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.708730  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.708734  2459 net.cpp:137] Memory required for data: 40551600
I0926 22:37:52.708736  2459 layer_factory.hpp:77] Creating layer Convolution2
I0926 22:37:52.708745  2459 net.cpp:84] Creating Layer Convolution2
I0926 22:37:52.708748  2459 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0926 22:37:52.708753  2459 net.cpp:380] Convolution2 -> Convolution2
I0926 22:37:52.709884  2459 net.cpp:122] Setting up Convolution2
I0926 22:37:52.709895  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.709898  2459 net.cpp:137] Memory required for data: 47105200
I0926 22:37:52.709903  2459 layer_factory.hpp:77] Creating layer BatchNorm2
I0926 22:37:52.709908  2459 net.cpp:84] Creating Layer BatchNorm2
I0926 22:37:52.709913  2459 net.cpp:406] BatchNorm2 <- Convolution2
I0926 22:37:52.709926  2459 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0926 22:37:52.710079  2459 net.cpp:122] Setting up BatchNorm2
I0926 22:37:52.710085  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.710088  2459 net.cpp:137] Memory required for data: 53658800
I0926 22:37:52.710093  2459 layer_factory.hpp:77] Creating layer Scale2
I0926 22:37:52.710098  2459 net.cpp:84] Creating Layer Scale2
I0926 22:37:52.710100  2459 net.cpp:406] Scale2 <- Convolution2
I0926 22:37:52.710104  2459 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0926 22:37:52.710136  2459 layer_factory.hpp:77] Creating layer Scale2
I0926 22:37:52.710223  2459 net.cpp:122] Setting up Scale2
I0926 22:37:52.710228  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.710232  2459 net.cpp:137] Memory required for data: 60212400
I0926 22:37:52.710238  2459 layer_factory.hpp:77] Creating layer penlu2
I0926 22:37:52.710253  2459 net.cpp:84] Creating Layer penlu2
I0926 22:37:52.710264  2459 net.cpp:406] penlu2 <- Convolution2
I0926 22:37:52.710270  2459 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0926 22:37:52.710412  2459 net.cpp:122] Setting up penlu2
I0926 22:37:52.710420  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.710423  2459 net.cpp:137] Memory required for data: 66766000
I0926 22:37:52.710427  2459 layer_factory.hpp:77] Creating layer Convolution3
I0926 22:37:52.710436  2459 net.cpp:84] Creating Layer Convolution3
I0926 22:37:52.710439  2459 net.cpp:406] Convolution3 <- Convolution2
I0926 22:37:52.710444  2459 net.cpp:380] Convolution3 -> Convolution3
I0926 22:37:52.711441  2459 net.cpp:122] Setting up Convolution3
I0926 22:37:52.711450  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.711453  2459 net.cpp:137] Memory required for data: 73319600
I0926 22:37:52.711458  2459 layer_factory.hpp:77] Creating layer BatchNorm3
I0926 22:37:52.711465  2459 net.cpp:84] Creating Layer BatchNorm3
I0926 22:37:52.711468  2459 net.cpp:406] BatchNorm3 <- Convolution3
I0926 22:37:52.711472  2459 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0926 22:37:52.711623  2459 net.cpp:122] Setting up BatchNorm3
I0926 22:37:52.711628  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.711632  2459 net.cpp:137] Memory required for data: 79873200
I0926 22:37:52.711637  2459 layer_factory.hpp:77] Creating layer Scale3
I0926 22:37:52.711642  2459 net.cpp:84] Creating Layer Scale3
I0926 22:37:52.711645  2459 net.cpp:406] Scale3 <- Convolution3
I0926 22:37:52.711648  2459 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0926 22:37:52.711680  2459 layer_factory.hpp:77] Creating layer Scale3
I0926 22:37:52.711768  2459 net.cpp:122] Setting up Scale3
I0926 22:37:52.711773  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.711776  2459 net.cpp:137] Memory required for data: 86426800
I0926 22:37:52.711781  2459 layer_factory.hpp:77] Creating layer Eltwise1
I0926 22:37:52.711786  2459 net.cpp:84] Creating Layer Eltwise1
I0926 22:37:52.711789  2459 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0926 22:37:52.711792  2459 net.cpp:406] Eltwise1 <- Convolution3
I0926 22:37:52.711796  2459 net.cpp:380] Eltwise1 -> Eltwise1
I0926 22:37:52.711817  2459 net.cpp:122] Setting up Eltwise1
I0926 22:37:52.711820  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.711823  2459 net.cpp:137] Memory required for data: 92980400
I0926 22:37:52.711825  2459 layer_factory.hpp:77] Creating layer penlu3
I0926 22:37:52.711833  2459 net.cpp:84] Creating Layer penlu3
I0926 22:37:52.711835  2459 net.cpp:406] penlu3 <- Eltwise1
I0926 22:37:52.711838  2459 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0926 22:37:52.711969  2459 net.cpp:122] Setting up penlu3
I0926 22:37:52.711987  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.711995  2459 net.cpp:137] Memory required for data: 99534000
I0926 22:37:52.712000  2459 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0926 22:37:52.712008  2459 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0926 22:37:52.712011  2459 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0926 22:37:52.712015  2459 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0926 22:37:52.712020  2459 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0926 22:37:52.712051  2459 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0926 22:37:52.712056  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.712060  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.712064  2459 net.cpp:137] Memory required for data: 112641200
I0926 22:37:52.712066  2459 layer_factory.hpp:77] Creating layer Convolution4
I0926 22:37:52.712074  2459 net.cpp:84] Creating Layer Convolution4
I0926 22:37:52.712077  2459 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0926 22:37:52.712081  2459 net.cpp:380] Convolution4 -> Convolution4
I0926 22:37:52.713122  2459 net.cpp:122] Setting up Convolution4
I0926 22:37:52.713140  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.713143  2459 net.cpp:137] Memory required for data: 119194800
I0926 22:37:52.713147  2459 layer_factory.hpp:77] Creating layer BatchNorm4
I0926 22:37:52.713155  2459 net.cpp:84] Creating Layer BatchNorm4
I0926 22:37:52.713157  2459 net.cpp:406] BatchNorm4 <- Convolution4
I0926 22:37:52.713161  2459 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0926 22:37:52.713317  2459 net.cpp:122] Setting up BatchNorm4
I0926 22:37:52.713322  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.713325  2459 net.cpp:137] Memory required for data: 125748400
I0926 22:37:52.713333  2459 layer_factory.hpp:77] Creating layer Scale4
I0926 22:37:52.713338  2459 net.cpp:84] Creating Layer Scale4
I0926 22:37:52.713341  2459 net.cpp:406] Scale4 <- Convolution4
I0926 22:37:52.713346  2459 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0926 22:37:52.713377  2459 layer_factory.hpp:77] Creating layer Scale4
I0926 22:37:52.713464  2459 net.cpp:122] Setting up Scale4
I0926 22:37:52.713469  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.713471  2459 net.cpp:137] Memory required for data: 132302000
I0926 22:37:52.713475  2459 layer_factory.hpp:77] Creating layer penlu4
I0926 22:37:52.713482  2459 net.cpp:84] Creating Layer penlu4
I0926 22:37:52.713485  2459 net.cpp:406] penlu4 <- Convolution4
I0926 22:37:52.713490  2459 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0926 22:37:52.713620  2459 net.cpp:122] Setting up penlu4
I0926 22:37:52.713625  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.713629  2459 net.cpp:137] Memory required for data: 138855600
I0926 22:37:52.713632  2459 layer_factory.hpp:77] Creating layer Convolution5
I0926 22:37:52.713640  2459 net.cpp:84] Creating Layer Convolution5
I0926 22:37:52.713644  2459 net.cpp:406] Convolution5 <- Convolution4
I0926 22:37:52.713647  2459 net.cpp:380] Convolution5 -> Convolution5
I0926 22:37:52.714612  2459 net.cpp:122] Setting up Convolution5
I0926 22:37:52.714622  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.714625  2459 net.cpp:137] Memory required for data: 145409200
I0926 22:37:52.714630  2459 layer_factory.hpp:77] Creating layer BatchNorm5
I0926 22:37:52.714637  2459 net.cpp:84] Creating Layer BatchNorm5
I0926 22:37:52.714639  2459 net.cpp:406] BatchNorm5 <- Convolution5
I0926 22:37:52.714643  2459 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0926 22:37:52.714798  2459 net.cpp:122] Setting up BatchNorm5
I0926 22:37:52.714803  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.714807  2459 net.cpp:137] Memory required for data: 151962800
I0926 22:37:52.714812  2459 layer_factory.hpp:77] Creating layer Scale5
I0926 22:37:52.714817  2459 net.cpp:84] Creating Layer Scale5
I0926 22:37:52.714819  2459 net.cpp:406] Scale5 <- Convolution5
I0926 22:37:52.714823  2459 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0926 22:37:52.714854  2459 layer_factory.hpp:77] Creating layer Scale5
I0926 22:37:52.714941  2459 net.cpp:122] Setting up Scale5
I0926 22:37:52.714946  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.714948  2459 net.cpp:137] Memory required for data: 158516400
I0926 22:37:52.714952  2459 layer_factory.hpp:77] Creating layer Eltwise2
I0926 22:37:52.714958  2459 net.cpp:84] Creating Layer Eltwise2
I0926 22:37:52.714962  2459 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0926 22:37:52.714964  2459 net.cpp:406] Eltwise2 <- Convolution5
I0926 22:37:52.714967  2459 net.cpp:380] Eltwise2 -> Eltwise2
I0926 22:37:52.714987  2459 net.cpp:122] Setting up Eltwise2
I0926 22:37:52.714992  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.714993  2459 net.cpp:137] Memory required for data: 165070000
I0926 22:37:52.714995  2459 layer_factory.hpp:77] Creating layer penlu5
I0926 22:37:52.715001  2459 net.cpp:84] Creating Layer penlu5
I0926 22:37:52.715004  2459 net.cpp:406] penlu5 <- Eltwise2
I0926 22:37:52.715008  2459 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0926 22:37:52.715145  2459 net.cpp:122] Setting up penlu5
I0926 22:37:52.715152  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.715154  2459 net.cpp:137] Memory required for data: 171623600
I0926 22:37:52.715159  2459 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0926 22:37:52.715163  2459 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0926 22:37:52.715167  2459 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0926 22:37:52.715169  2459 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0926 22:37:52.715174  2459 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0926 22:37:52.715204  2459 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0926 22:37:52.715209  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.715212  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.715215  2459 net.cpp:137] Memory required for data: 184730800
I0926 22:37:52.715217  2459 layer_factory.hpp:77] Creating layer Convolution6
I0926 22:37:52.715224  2459 net.cpp:84] Creating Layer Convolution6
I0926 22:37:52.715227  2459 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0926 22:37:52.715231  2459 net.cpp:380] Convolution6 -> Convolution6
I0926 22:37:52.716184  2459 net.cpp:122] Setting up Convolution6
I0926 22:37:52.716194  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.716197  2459 net.cpp:137] Memory required for data: 191284400
I0926 22:37:52.716202  2459 layer_factory.hpp:77] Creating layer BatchNorm6
I0926 22:37:52.716224  2459 net.cpp:84] Creating Layer BatchNorm6
I0926 22:37:52.716228  2459 net.cpp:406] BatchNorm6 <- Convolution6
I0926 22:37:52.716233  2459 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0926 22:37:52.716404  2459 net.cpp:122] Setting up BatchNorm6
I0926 22:37:52.716410  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.716413  2459 net.cpp:137] Memory required for data: 197838000
I0926 22:37:52.716418  2459 layer_factory.hpp:77] Creating layer Scale6
I0926 22:37:52.716423  2459 net.cpp:84] Creating Layer Scale6
I0926 22:37:52.716425  2459 net.cpp:406] Scale6 <- Convolution6
I0926 22:37:52.716429  2459 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0926 22:37:52.716459  2459 layer_factory.hpp:77] Creating layer Scale6
I0926 22:37:52.716547  2459 net.cpp:122] Setting up Scale6
I0926 22:37:52.716552  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.716555  2459 net.cpp:137] Memory required for data: 204391600
I0926 22:37:52.716559  2459 layer_factory.hpp:77] Creating layer penlu6
I0926 22:37:52.716565  2459 net.cpp:84] Creating Layer penlu6
I0926 22:37:52.716568  2459 net.cpp:406] penlu6 <- Convolution6
I0926 22:37:52.716573  2459 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0926 22:37:52.716702  2459 net.cpp:122] Setting up penlu6
I0926 22:37:52.716708  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.716711  2459 net.cpp:137] Memory required for data: 210945200
I0926 22:37:52.716715  2459 layer_factory.hpp:77] Creating layer Convolution7
I0926 22:37:52.716722  2459 net.cpp:84] Creating Layer Convolution7
I0926 22:37:52.716725  2459 net.cpp:406] Convolution7 <- Convolution6
I0926 22:37:52.716730  2459 net.cpp:380] Convolution7 -> Convolution7
I0926 22:37:52.717679  2459 net.cpp:122] Setting up Convolution7
I0926 22:37:52.717689  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.717691  2459 net.cpp:137] Memory required for data: 217498800
I0926 22:37:52.717695  2459 layer_factory.hpp:77] Creating layer BatchNorm7
I0926 22:37:52.717703  2459 net.cpp:84] Creating Layer BatchNorm7
I0926 22:37:52.717706  2459 net.cpp:406] BatchNorm7 <- Convolution7
I0926 22:37:52.717710  2459 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0926 22:37:52.717861  2459 net.cpp:122] Setting up BatchNorm7
I0926 22:37:52.717867  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.717869  2459 net.cpp:137] Memory required for data: 224052400
I0926 22:37:52.717880  2459 layer_factory.hpp:77] Creating layer Scale7
I0926 22:37:52.717892  2459 net.cpp:84] Creating Layer Scale7
I0926 22:37:52.717895  2459 net.cpp:406] Scale7 <- Convolution7
I0926 22:37:52.717900  2459 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0926 22:37:52.717932  2459 layer_factory.hpp:77] Creating layer Scale7
I0926 22:37:52.718021  2459 net.cpp:122] Setting up Scale7
I0926 22:37:52.718026  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.718029  2459 net.cpp:137] Memory required for data: 230606000
I0926 22:37:52.718034  2459 layer_factory.hpp:77] Creating layer Eltwise3
I0926 22:37:52.718039  2459 net.cpp:84] Creating Layer Eltwise3
I0926 22:37:52.718042  2459 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0926 22:37:52.718045  2459 net.cpp:406] Eltwise3 <- Convolution7
I0926 22:37:52.718049  2459 net.cpp:380] Eltwise3 -> Eltwise3
I0926 22:37:52.718067  2459 net.cpp:122] Setting up Eltwise3
I0926 22:37:52.718072  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.718075  2459 net.cpp:137] Memory required for data: 237159600
I0926 22:37:52.718077  2459 layer_factory.hpp:77] Creating layer penlu7
I0926 22:37:52.718083  2459 net.cpp:84] Creating Layer penlu7
I0926 22:37:52.718086  2459 net.cpp:406] penlu7 <- Eltwise3
I0926 22:37:52.718089  2459 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0926 22:37:52.718219  2459 net.cpp:122] Setting up penlu7
I0926 22:37:52.718225  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.718226  2459 net.cpp:137] Memory required for data: 243713200
I0926 22:37:52.718231  2459 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0926 22:37:52.718235  2459 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0926 22:37:52.718238  2459 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0926 22:37:52.718241  2459 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0926 22:37:52.718246  2459 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0926 22:37:52.718273  2459 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0926 22:37:52.718278  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.718281  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.718283  2459 net.cpp:137] Memory required for data: 256820400
I0926 22:37:52.718286  2459 layer_factory.hpp:77] Creating layer Convolution8
I0926 22:37:52.718292  2459 net.cpp:84] Creating Layer Convolution8
I0926 22:37:52.718296  2459 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0926 22:37:52.718299  2459 net.cpp:380] Convolution8 -> Convolution8
I0926 22:37:52.719249  2459 net.cpp:122] Setting up Convolution8
I0926 22:37:52.719259  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.719264  2459 net.cpp:137] Memory required for data: 263374000
I0926 22:37:52.719267  2459 layer_factory.hpp:77] Creating layer BatchNorm8
I0926 22:37:52.719272  2459 net.cpp:84] Creating Layer BatchNorm8
I0926 22:37:52.719276  2459 net.cpp:406] BatchNorm8 <- Convolution8
I0926 22:37:52.719280  2459 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0926 22:37:52.719434  2459 net.cpp:122] Setting up BatchNorm8
I0926 22:37:52.719440  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.719442  2459 net.cpp:137] Memory required for data: 269927600
I0926 22:37:52.719447  2459 layer_factory.hpp:77] Creating layer Scale8
I0926 22:37:52.719452  2459 net.cpp:84] Creating Layer Scale8
I0926 22:37:52.719455  2459 net.cpp:406] Scale8 <- Convolution8
I0926 22:37:52.719460  2459 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0926 22:37:52.719491  2459 layer_factory.hpp:77] Creating layer Scale8
I0926 22:37:52.719576  2459 net.cpp:122] Setting up Scale8
I0926 22:37:52.719581  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.719584  2459 net.cpp:137] Memory required for data: 276481200
I0926 22:37:52.719588  2459 layer_factory.hpp:77] Creating layer penlu8
I0926 22:37:52.719595  2459 net.cpp:84] Creating Layer penlu8
I0926 22:37:52.719599  2459 net.cpp:406] penlu8 <- Convolution8
I0926 22:37:52.719601  2459 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0926 22:37:52.719740  2459 net.cpp:122] Setting up penlu8
I0926 22:37:52.719745  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.719748  2459 net.cpp:137] Memory required for data: 283034800
I0926 22:37:52.719753  2459 layer_factory.hpp:77] Creating layer Convolution9
I0926 22:37:52.719759  2459 net.cpp:84] Creating Layer Convolution9
I0926 22:37:52.719763  2459 net.cpp:406] Convolution9 <- Convolution8
I0926 22:37:52.719766  2459 net.cpp:380] Convolution9 -> Convolution9
I0926 22:37:52.720749  2459 net.cpp:122] Setting up Convolution9
I0926 22:37:52.720758  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.720762  2459 net.cpp:137] Memory required for data: 289588400
I0926 22:37:52.720765  2459 layer_factory.hpp:77] Creating layer BatchNorm9
I0926 22:37:52.720770  2459 net.cpp:84] Creating Layer BatchNorm9
I0926 22:37:52.720773  2459 net.cpp:406] BatchNorm9 <- Convolution9
I0926 22:37:52.720778  2459 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0926 22:37:52.720929  2459 net.cpp:122] Setting up BatchNorm9
I0926 22:37:52.720934  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.720937  2459 net.cpp:137] Memory required for data: 296142000
I0926 22:37:52.720942  2459 layer_factory.hpp:77] Creating layer Scale9
I0926 22:37:52.720947  2459 net.cpp:84] Creating Layer Scale9
I0926 22:37:52.720948  2459 net.cpp:406] Scale9 <- Convolution9
I0926 22:37:52.720952  2459 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0926 22:37:52.720983  2459 layer_factory.hpp:77] Creating layer Scale9
I0926 22:37:52.721071  2459 net.cpp:122] Setting up Scale9
I0926 22:37:52.721074  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.721076  2459 net.cpp:137] Memory required for data: 302695600
I0926 22:37:52.721081  2459 layer_factory.hpp:77] Creating layer Eltwise4
I0926 22:37:52.721084  2459 net.cpp:84] Creating Layer Eltwise4
I0926 22:37:52.721087  2459 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0926 22:37:52.721091  2459 net.cpp:406] Eltwise4 <- Convolution9
I0926 22:37:52.721093  2459 net.cpp:380] Eltwise4 -> Eltwise4
I0926 22:37:52.721112  2459 net.cpp:122] Setting up Eltwise4
I0926 22:37:52.721117  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.721118  2459 net.cpp:137] Memory required for data: 309249200
I0926 22:37:52.721120  2459 layer_factory.hpp:77] Creating layer penlu9
I0926 22:37:52.721125  2459 net.cpp:84] Creating Layer penlu9
I0926 22:37:52.721128  2459 net.cpp:406] penlu9 <- Eltwise4
I0926 22:37:52.721132  2459 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0926 22:37:52.721259  2459 net.cpp:122] Setting up penlu9
I0926 22:37:52.721264  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.721266  2459 net.cpp:137] Memory required for data: 315802800
I0926 22:37:52.721271  2459 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0926 22:37:52.721274  2459 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0926 22:37:52.721276  2459 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0926 22:37:52.721279  2459 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0926 22:37:52.721283  2459 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0926 22:37:52.721309  2459 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0926 22:37:52.721313  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.721316  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.721318  2459 net.cpp:137] Memory required for data: 328910000
I0926 22:37:52.721320  2459 layer_factory.hpp:77] Creating layer Convolution10
I0926 22:37:52.721326  2459 net.cpp:84] Creating Layer Convolution10
I0926 22:37:52.721328  2459 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0926 22:37:52.721333  2459 net.cpp:380] Convolution10 -> Convolution10
I0926 22:37:52.722281  2459 net.cpp:122] Setting up Convolution10
I0926 22:37:52.722290  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.722292  2459 net.cpp:137] Memory required for data: 335463600
I0926 22:37:52.722297  2459 layer_factory.hpp:77] Creating layer BatchNorm10
I0926 22:37:52.722309  2459 net.cpp:84] Creating Layer BatchNorm10
I0926 22:37:52.722313  2459 net.cpp:406] BatchNorm10 <- Convolution10
I0926 22:37:52.722316  2459 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0926 22:37:52.722471  2459 net.cpp:122] Setting up BatchNorm10
I0926 22:37:52.722476  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.722478  2459 net.cpp:137] Memory required for data: 342017200
I0926 22:37:52.722483  2459 layer_factory.hpp:77] Creating layer Scale10
I0926 22:37:52.722487  2459 net.cpp:84] Creating Layer Scale10
I0926 22:37:52.722491  2459 net.cpp:406] Scale10 <- Convolution10
I0926 22:37:52.722493  2459 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0926 22:37:52.722523  2459 layer_factory.hpp:77] Creating layer Scale10
I0926 22:37:52.722610  2459 net.cpp:122] Setting up Scale10
I0926 22:37:52.722615  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.722616  2459 net.cpp:137] Memory required for data: 348570800
I0926 22:37:52.722620  2459 layer_factory.hpp:77] Creating layer penlu10
I0926 22:37:52.722626  2459 net.cpp:84] Creating Layer penlu10
I0926 22:37:52.722628  2459 net.cpp:406] penlu10 <- Convolution10
I0926 22:37:52.722632  2459 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0926 22:37:52.722760  2459 net.cpp:122] Setting up penlu10
I0926 22:37:52.722764  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.722766  2459 net.cpp:137] Memory required for data: 355124400
I0926 22:37:52.722770  2459 layer_factory.hpp:77] Creating layer Convolution11
I0926 22:37:52.722777  2459 net.cpp:84] Creating Layer Convolution11
I0926 22:37:52.722779  2459 net.cpp:406] Convolution11 <- Convolution10
I0926 22:37:52.722784  2459 net.cpp:380] Convolution11 -> Convolution11
I0926 22:37:52.724045  2459 net.cpp:122] Setting up Convolution11
I0926 22:37:52.724053  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.724056  2459 net.cpp:137] Memory required for data: 361678000
I0926 22:37:52.724061  2459 layer_factory.hpp:77] Creating layer BatchNorm11
I0926 22:37:52.724067  2459 net.cpp:84] Creating Layer BatchNorm11
I0926 22:37:52.724069  2459 net.cpp:406] BatchNorm11 <- Convolution11
I0926 22:37:52.724073  2459 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0926 22:37:52.724267  2459 net.cpp:122] Setting up BatchNorm11
I0926 22:37:52.724272  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.724275  2459 net.cpp:137] Memory required for data: 368231600
I0926 22:37:52.724279  2459 layer_factory.hpp:77] Creating layer Scale11
I0926 22:37:52.724284  2459 net.cpp:84] Creating Layer Scale11
I0926 22:37:52.724287  2459 net.cpp:406] Scale11 <- Convolution11
I0926 22:37:52.724290  2459 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0926 22:37:52.724321  2459 layer_factory.hpp:77] Creating layer Scale11
I0926 22:37:52.724408  2459 net.cpp:122] Setting up Scale11
I0926 22:37:52.724413  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.724416  2459 net.cpp:137] Memory required for data: 374785200
I0926 22:37:52.724419  2459 layer_factory.hpp:77] Creating layer Eltwise5
I0926 22:37:52.724423  2459 net.cpp:84] Creating Layer Eltwise5
I0926 22:37:52.724426  2459 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0926 22:37:52.724428  2459 net.cpp:406] Eltwise5 <- Convolution11
I0926 22:37:52.724432  2459 net.cpp:380] Eltwise5 -> Eltwise5
I0926 22:37:52.724452  2459 net.cpp:122] Setting up Eltwise5
I0926 22:37:52.724455  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.724457  2459 net.cpp:137] Memory required for data: 381338800
I0926 22:37:52.724459  2459 layer_factory.hpp:77] Creating layer penlu11
I0926 22:37:52.724463  2459 net.cpp:84] Creating Layer penlu11
I0926 22:37:52.724467  2459 net.cpp:406] penlu11 <- Eltwise5
I0926 22:37:52.724470  2459 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0926 22:37:52.724601  2459 net.cpp:122] Setting up penlu11
I0926 22:37:52.724606  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.724608  2459 net.cpp:137] Memory required for data: 387892400
I0926 22:37:52.724619  2459 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0926 22:37:52.724623  2459 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0926 22:37:52.724625  2459 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0926 22:37:52.724628  2459 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0926 22:37:52.724632  2459 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0926 22:37:52.724661  2459 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0926 22:37:52.724665  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.724668  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.724670  2459 net.cpp:137] Memory required for data: 400999600
I0926 22:37:52.724673  2459 layer_factory.hpp:77] Creating layer Convolution12
I0926 22:37:52.724679  2459 net.cpp:84] Creating Layer Convolution12
I0926 22:37:52.724681  2459 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0926 22:37:52.724685  2459 net.cpp:380] Convolution12 -> Convolution12
I0926 22:37:52.725647  2459 net.cpp:122] Setting up Convolution12
I0926 22:37:52.725656  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.725659  2459 net.cpp:137] Memory required for data: 407553200
I0926 22:37:52.725663  2459 layer_factory.hpp:77] Creating layer BatchNorm12
I0926 22:37:52.725669  2459 net.cpp:84] Creating Layer BatchNorm12
I0926 22:37:52.725672  2459 net.cpp:406] BatchNorm12 <- Convolution12
I0926 22:37:52.725675  2459 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0926 22:37:52.725832  2459 net.cpp:122] Setting up BatchNorm12
I0926 22:37:52.725837  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.725839  2459 net.cpp:137] Memory required for data: 414106800
I0926 22:37:52.725843  2459 layer_factory.hpp:77] Creating layer Scale12
I0926 22:37:52.725847  2459 net.cpp:84] Creating Layer Scale12
I0926 22:37:52.725850  2459 net.cpp:406] Scale12 <- Convolution12
I0926 22:37:52.725854  2459 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0926 22:37:52.725884  2459 layer_factory.hpp:77] Creating layer Scale12
I0926 22:37:52.725972  2459 net.cpp:122] Setting up Scale12
I0926 22:37:52.725978  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.725980  2459 net.cpp:137] Memory required for data: 420660400
I0926 22:37:52.725985  2459 layer_factory.hpp:77] Creating layer penlu12
I0926 22:37:52.725989  2459 net.cpp:84] Creating Layer penlu12
I0926 22:37:52.725991  2459 net.cpp:406] penlu12 <- Convolution12
I0926 22:37:52.725996  2459 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0926 22:37:52.726125  2459 net.cpp:122] Setting up penlu12
I0926 22:37:52.726130  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.726132  2459 net.cpp:137] Memory required for data: 427214000
I0926 22:37:52.726136  2459 layer_factory.hpp:77] Creating layer Convolution13
I0926 22:37:52.726143  2459 net.cpp:84] Creating Layer Convolution13
I0926 22:37:52.726146  2459 net.cpp:406] Convolution13 <- Convolution12
I0926 22:37:52.726150  2459 net.cpp:380] Convolution13 -> Convolution13
I0926 22:37:52.727109  2459 net.cpp:122] Setting up Convolution13
I0926 22:37:52.727118  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.727120  2459 net.cpp:137] Memory required for data: 433767600
I0926 22:37:52.727125  2459 layer_factory.hpp:77] Creating layer BatchNorm13
I0926 22:37:52.727130  2459 net.cpp:84] Creating Layer BatchNorm13
I0926 22:37:52.727133  2459 net.cpp:406] BatchNorm13 <- Convolution13
I0926 22:37:52.727138  2459 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0926 22:37:52.727293  2459 net.cpp:122] Setting up BatchNorm13
I0926 22:37:52.727298  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.727299  2459 net.cpp:137] Memory required for data: 440321200
I0926 22:37:52.727304  2459 layer_factory.hpp:77] Creating layer Scale13
I0926 22:37:52.727309  2459 net.cpp:84] Creating Layer Scale13
I0926 22:37:52.727313  2459 net.cpp:406] Scale13 <- Convolution13
I0926 22:37:52.727321  2459 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0926 22:37:52.727355  2459 layer_factory.hpp:77] Creating layer Scale13
I0926 22:37:52.727442  2459 net.cpp:122] Setting up Scale13
I0926 22:37:52.727447  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.727449  2459 net.cpp:137] Memory required for data: 446874800
I0926 22:37:52.727452  2459 layer_factory.hpp:77] Creating layer Eltwise6
I0926 22:37:52.727460  2459 net.cpp:84] Creating Layer Eltwise6
I0926 22:37:52.727463  2459 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0926 22:37:52.727466  2459 net.cpp:406] Eltwise6 <- Convolution13
I0926 22:37:52.727470  2459 net.cpp:380] Eltwise6 -> Eltwise6
I0926 22:37:52.727488  2459 net.cpp:122] Setting up Eltwise6
I0926 22:37:52.727493  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.727494  2459 net.cpp:137] Memory required for data: 453428400
I0926 22:37:52.727497  2459 layer_factory.hpp:77] Creating layer penlu13
I0926 22:37:52.727502  2459 net.cpp:84] Creating Layer penlu13
I0926 22:37:52.727505  2459 net.cpp:406] penlu13 <- Eltwise6
I0926 22:37:52.727509  2459 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0926 22:37:52.727638  2459 net.cpp:122] Setting up penlu13
I0926 22:37:52.727643  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.727644  2459 net.cpp:137] Memory required for data: 459982000
I0926 22:37:52.727656  2459 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0926 22:37:52.727660  2459 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0926 22:37:52.727663  2459 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0926 22:37:52.727666  2459 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0926 22:37:52.727671  2459 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0926 22:37:52.727699  2459 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0926 22:37:52.727704  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.727706  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.727708  2459 net.cpp:137] Memory required for data: 473089200
I0926 22:37:52.727710  2459 layer_factory.hpp:77] Creating layer Convolution14
I0926 22:37:52.727717  2459 net.cpp:84] Creating Layer Convolution14
I0926 22:37:52.727720  2459 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0926 22:37:52.727725  2459 net.cpp:380] Convolution14 -> Convolution14
I0926 22:37:52.728689  2459 net.cpp:122] Setting up Convolution14
I0926 22:37:52.728698  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.728700  2459 net.cpp:137] Memory required for data: 479642800
I0926 22:37:52.728704  2459 layer_factory.hpp:77] Creating layer BatchNorm14
I0926 22:37:52.728709  2459 net.cpp:84] Creating Layer BatchNorm14
I0926 22:37:52.728711  2459 net.cpp:406] BatchNorm14 <- Convolution14
I0926 22:37:52.728716  2459 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0926 22:37:52.728871  2459 net.cpp:122] Setting up BatchNorm14
I0926 22:37:52.728876  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.728878  2459 net.cpp:137] Memory required for data: 486196400
I0926 22:37:52.728883  2459 layer_factory.hpp:77] Creating layer Scale14
I0926 22:37:52.728888  2459 net.cpp:84] Creating Layer Scale14
I0926 22:37:52.728889  2459 net.cpp:406] Scale14 <- Convolution14
I0926 22:37:52.728893  2459 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0926 22:37:52.728922  2459 layer_factory.hpp:77] Creating layer Scale14
I0926 22:37:52.729008  2459 net.cpp:122] Setting up Scale14
I0926 22:37:52.729013  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.729015  2459 net.cpp:137] Memory required for data: 492750000
I0926 22:37:52.729019  2459 layer_factory.hpp:77] Creating layer penlu14
I0926 22:37:52.729024  2459 net.cpp:84] Creating Layer penlu14
I0926 22:37:52.729027  2459 net.cpp:406] penlu14 <- Convolution14
I0926 22:37:52.729030  2459 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0926 22:37:52.729161  2459 net.cpp:122] Setting up penlu14
I0926 22:37:52.729172  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.729174  2459 net.cpp:137] Memory required for data: 499303600
I0926 22:37:52.729179  2459 layer_factory.hpp:77] Creating layer Convolution15
I0926 22:37:52.729187  2459 net.cpp:84] Creating Layer Convolution15
I0926 22:37:52.729189  2459 net.cpp:406] Convolution15 <- Convolution14
I0926 22:37:52.729193  2459 net.cpp:380] Convolution15 -> Convolution15
I0926 22:37:52.730154  2459 net.cpp:122] Setting up Convolution15
I0926 22:37:52.730163  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.730165  2459 net.cpp:137] Memory required for data: 505857200
I0926 22:37:52.730170  2459 layer_factory.hpp:77] Creating layer BatchNorm15
I0926 22:37:52.730175  2459 net.cpp:84] Creating Layer BatchNorm15
I0926 22:37:52.730178  2459 net.cpp:406] BatchNorm15 <- Convolution15
I0926 22:37:52.730182  2459 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0926 22:37:52.730336  2459 net.cpp:122] Setting up BatchNorm15
I0926 22:37:52.730340  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.730342  2459 net.cpp:137] Memory required for data: 512410800
I0926 22:37:52.730347  2459 layer_factory.hpp:77] Creating layer Scale15
I0926 22:37:52.730352  2459 net.cpp:84] Creating Layer Scale15
I0926 22:37:52.730355  2459 net.cpp:406] Scale15 <- Convolution15
I0926 22:37:52.730358  2459 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0926 22:37:52.730388  2459 layer_factory.hpp:77] Creating layer Scale15
I0926 22:37:52.730476  2459 net.cpp:122] Setting up Scale15
I0926 22:37:52.730481  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.730484  2459 net.cpp:137] Memory required for data: 518964400
I0926 22:37:52.730487  2459 layer_factory.hpp:77] Creating layer Eltwise7
I0926 22:37:52.730491  2459 net.cpp:84] Creating Layer Eltwise7
I0926 22:37:52.730494  2459 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0926 22:37:52.730496  2459 net.cpp:406] Eltwise7 <- Convolution15
I0926 22:37:52.730499  2459 net.cpp:380] Eltwise7 -> Eltwise7
I0926 22:37:52.730518  2459 net.cpp:122] Setting up Eltwise7
I0926 22:37:52.730522  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.730525  2459 net.cpp:137] Memory required for data: 525518000
I0926 22:37:52.730526  2459 layer_factory.hpp:77] Creating layer penlu15
I0926 22:37:52.730531  2459 net.cpp:84] Creating Layer penlu15
I0926 22:37:52.730535  2459 net.cpp:406] penlu15 <- Eltwise7
I0926 22:37:52.730538  2459 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0926 22:37:52.730669  2459 net.cpp:122] Setting up penlu15
I0926 22:37:52.730672  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.730674  2459 net.cpp:137] Memory required for data: 532071600
I0926 22:37:52.730679  2459 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0926 22:37:52.730682  2459 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0926 22:37:52.730684  2459 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0926 22:37:52.730689  2459 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0926 22:37:52.730691  2459 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0926 22:37:52.730718  2459 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0926 22:37:52.730722  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.730726  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.730727  2459 net.cpp:137] Memory required for data: 545178800
I0926 22:37:52.730729  2459 layer_factory.hpp:77] Creating layer Convolution16
I0926 22:37:52.730734  2459 net.cpp:84] Creating Layer Convolution16
I0926 22:37:52.730737  2459 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0926 22:37:52.730742  2459 net.cpp:380] Convolution16 -> Convolution16
I0926 22:37:52.731410  2459 net.cpp:122] Setting up Convolution16
I0926 22:37:52.731417  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.731420  2459 net.cpp:137] Memory required for data: 551732400
I0926 22:37:52.731426  2459 layer_factory.hpp:77] Creating layer BatchNorm16
I0926 22:37:52.731436  2459 net.cpp:84] Creating Layer BatchNorm16
I0926 22:37:52.731439  2459 net.cpp:406] BatchNorm16 <- Convolution16
I0926 22:37:52.731442  2459 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0926 22:37:52.731600  2459 net.cpp:122] Setting up BatchNorm16
I0926 22:37:52.731604  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.731606  2459 net.cpp:137] Memory required for data: 558286000
I0926 22:37:52.731611  2459 layer_factory.hpp:77] Creating layer Scale16
I0926 22:37:52.731614  2459 net.cpp:84] Creating Layer Scale16
I0926 22:37:52.731617  2459 net.cpp:406] Scale16 <- Convolution16
I0926 22:37:52.731621  2459 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0926 22:37:52.731650  2459 layer_factory.hpp:77] Creating layer Scale16
I0926 22:37:52.731735  2459 net.cpp:122] Setting up Scale16
I0926 22:37:52.731740  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.731742  2459 net.cpp:137] Memory required for data: 564839600
I0926 22:37:52.731745  2459 layer_factory.hpp:77] Creating layer penlu16
I0926 22:37:52.731751  2459 net.cpp:84] Creating Layer penlu16
I0926 22:37:52.731753  2459 net.cpp:406] penlu16 <- Convolution16
I0926 22:37:52.731757  2459 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0926 22:37:52.731889  2459 net.cpp:122] Setting up penlu16
I0926 22:37:52.731894  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.731896  2459 net.cpp:137] Memory required for data: 571393200
I0926 22:37:52.731900  2459 layer_factory.hpp:77] Creating layer Convolution17
I0926 22:37:52.731906  2459 net.cpp:84] Creating Layer Convolution17
I0926 22:37:52.731909  2459 net.cpp:406] Convolution17 <- Convolution16
I0926 22:37:52.731912  2459 net.cpp:380] Convolution17 -> Convolution17
I0926 22:37:52.733047  2459 net.cpp:122] Setting up Convolution17
I0926 22:37:52.733059  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.733064  2459 net.cpp:137] Memory required for data: 577946800
I0926 22:37:52.733072  2459 layer_factory.hpp:77] Creating layer BatchNorm17
I0926 22:37:52.733079  2459 net.cpp:84] Creating Layer BatchNorm17
I0926 22:37:52.733084  2459 net.cpp:406] BatchNorm17 <- Convolution17
I0926 22:37:52.733091  2459 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0926 22:37:52.733306  2459 net.cpp:122] Setting up BatchNorm17
I0926 22:37:52.733321  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.733325  2459 net.cpp:137] Memory required for data: 584500400
I0926 22:37:52.733330  2459 layer_factory.hpp:77] Creating layer Scale17
I0926 22:37:52.733335  2459 net.cpp:84] Creating Layer Scale17
I0926 22:37:52.733337  2459 net.cpp:406] Scale17 <- Convolution17
I0926 22:37:52.733341  2459 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0926 22:37:52.733376  2459 layer_factory.hpp:77] Creating layer Scale17
I0926 22:37:52.733466  2459 net.cpp:122] Setting up Scale17
I0926 22:37:52.733471  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.733474  2459 net.cpp:137] Memory required for data: 591054000
I0926 22:37:52.733477  2459 layer_factory.hpp:77] Creating layer Eltwise8
I0926 22:37:52.733481  2459 net.cpp:84] Creating Layer Eltwise8
I0926 22:37:52.733484  2459 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0926 22:37:52.733486  2459 net.cpp:406] Eltwise8 <- Convolution17
I0926 22:37:52.733490  2459 net.cpp:380] Eltwise8 -> Eltwise8
I0926 22:37:52.733510  2459 net.cpp:122] Setting up Eltwise8
I0926 22:37:52.733515  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.733516  2459 net.cpp:137] Memory required for data: 597607600
I0926 22:37:52.733518  2459 layer_factory.hpp:77] Creating layer penlu17
I0926 22:37:52.733522  2459 net.cpp:84] Creating Layer penlu17
I0926 22:37:52.733525  2459 net.cpp:406] penlu17 <- Eltwise8
I0926 22:37:52.733530  2459 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0926 22:37:52.733666  2459 net.cpp:122] Setting up penlu17
I0926 22:37:52.733671  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.733674  2459 net.cpp:137] Memory required for data: 604161200
I0926 22:37:52.733685  2459 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0926 22:37:52.733690  2459 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0926 22:37:52.733691  2459 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0926 22:37:52.733695  2459 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0926 22:37:52.733700  2459 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0926 22:37:52.733728  2459 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0926 22:37:52.733733  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.733736  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.733738  2459 net.cpp:137] Memory required for data: 617268400
I0926 22:37:52.733741  2459 layer_factory.hpp:77] Creating layer Convolution18
I0926 22:37:52.733747  2459 net.cpp:84] Creating Layer Convolution18
I0926 22:37:52.733749  2459 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0926 22:37:52.733753  2459 net.cpp:380] Convolution18 -> Convolution18
I0926 22:37:52.734778  2459 net.cpp:122] Setting up Convolution18
I0926 22:37:52.734787  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.734791  2459 net.cpp:137] Memory required for data: 623822000
I0926 22:37:52.734794  2459 layer_factory.hpp:77] Creating layer BatchNorm18
I0926 22:37:52.734799  2459 net.cpp:84] Creating Layer BatchNorm18
I0926 22:37:52.734802  2459 net.cpp:406] BatchNorm18 <- Convolution18
I0926 22:37:52.734805  2459 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0926 22:37:52.734961  2459 net.cpp:122] Setting up BatchNorm18
I0926 22:37:52.734966  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.734968  2459 net.cpp:137] Memory required for data: 630375600
I0926 22:37:52.734973  2459 layer_factory.hpp:77] Creating layer Scale18
I0926 22:37:52.734977  2459 net.cpp:84] Creating Layer Scale18
I0926 22:37:52.734980  2459 net.cpp:406] Scale18 <- Convolution18
I0926 22:37:52.734983  2459 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0926 22:37:52.735013  2459 layer_factory.hpp:77] Creating layer Scale18
I0926 22:37:52.735101  2459 net.cpp:122] Setting up Scale18
I0926 22:37:52.735105  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.735107  2459 net.cpp:137] Memory required for data: 636929200
I0926 22:37:52.735111  2459 layer_factory.hpp:77] Creating layer penlu18
I0926 22:37:52.735117  2459 net.cpp:84] Creating Layer penlu18
I0926 22:37:52.735119  2459 net.cpp:406] penlu18 <- Convolution18
I0926 22:37:52.735123  2459 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0926 22:37:52.735257  2459 net.cpp:122] Setting up penlu18
I0926 22:37:52.735262  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.735265  2459 net.cpp:137] Memory required for data: 643482800
I0926 22:37:52.735268  2459 layer_factory.hpp:77] Creating layer Convolution19
I0926 22:37:52.735275  2459 net.cpp:84] Creating Layer Convolution19
I0926 22:37:52.735278  2459 net.cpp:406] Convolution19 <- Convolution18
I0926 22:37:52.735281  2459 net.cpp:380] Convolution19 -> Convolution19
I0926 22:37:52.736307  2459 net.cpp:122] Setting up Convolution19
I0926 22:37:52.736316  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.736320  2459 net.cpp:137] Memory required for data: 650036400
I0926 22:37:52.736323  2459 layer_factory.hpp:77] Creating layer BatchNorm19
I0926 22:37:52.736330  2459 net.cpp:84] Creating Layer BatchNorm19
I0926 22:37:52.736332  2459 net.cpp:406] BatchNorm19 <- Convolution19
I0926 22:37:52.736335  2459 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0926 22:37:52.736500  2459 net.cpp:122] Setting up BatchNorm19
I0926 22:37:52.736505  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.736507  2459 net.cpp:137] Memory required for data: 656590000
I0926 22:37:52.736512  2459 layer_factory.hpp:77] Creating layer Scale19
I0926 22:37:52.736516  2459 net.cpp:84] Creating Layer Scale19
I0926 22:37:52.736519  2459 net.cpp:406] Scale19 <- Convolution19
I0926 22:37:52.736531  2459 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0926 22:37:52.736563  2459 layer_factory.hpp:77] Creating layer Scale19
I0926 22:37:52.736654  2459 net.cpp:122] Setting up Scale19
I0926 22:37:52.736660  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.736661  2459 net.cpp:137] Memory required for data: 663143600
I0926 22:37:52.736665  2459 layer_factory.hpp:77] Creating layer Eltwise9
I0926 22:37:52.736670  2459 net.cpp:84] Creating Layer Eltwise9
I0926 22:37:52.736673  2459 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0926 22:37:52.736676  2459 net.cpp:406] Eltwise9 <- Convolution19
I0926 22:37:52.736680  2459 net.cpp:380] Eltwise9 -> Eltwise9
I0926 22:37:52.736699  2459 net.cpp:122] Setting up Eltwise9
I0926 22:37:52.736703  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.736706  2459 net.cpp:137] Memory required for data: 669697200
I0926 22:37:52.736707  2459 layer_factory.hpp:77] Creating layer penlu19
I0926 22:37:52.736712  2459 net.cpp:84] Creating Layer penlu19
I0926 22:37:52.736716  2459 net.cpp:406] penlu19 <- Eltwise9
I0926 22:37:52.736718  2459 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0926 22:37:52.736857  2459 net.cpp:122] Setting up penlu19
I0926 22:37:52.736862  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.736865  2459 net.cpp:137] Memory required for data: 676250800
I0926 22:37:52.736870  2459 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0926 22:37:52.736873  2459 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0926 22:37:52.736876  2459 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0926 22:37:52.736879  2459 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0926 22:37:52.736883  2459 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0926 22:37:52.736912  2459 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0926 22:37:52.736917  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.736919  2459 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0926 22:37:52.736922  2459 net.cpp:137] Memory required for data: 689358000
I0926 22:37:52.736923  2459 layer_factory.hpp:77] Creating layer Convolution20
I0926 22:37:52.736929  2459 net.cpp:84] Creating Layer Convolution20
I0926 22:37:52.736932  2459 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0926 22:37:52.736937  2459 net.cpp:380] Convolution20 -> Convolution20
I0926 22:37:52.738483  2459 net.cpp:122] Setting up Convolution20
I0926 22:37:52.738492  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.738495  2459 net.cpp:137] Memory required for data: 692634800
I0926 22:37:52.738499  2459 layer_factory.hpp:77] Creating layer BatchNorm20
I0926 22:37:52.738505  2459 net.cpp:84] Creating Layer BatchNorm20
I0926 22:37:52.738508  2459 net.cpp:406] BatchNorm20 <- Convolution20
I0926 22:37:52.738512  2459 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0926 22:37:52.738641  2459 net.cpp:122] Setting up BatchNorm20
I0926 22:37:52.738644  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.738646  2459 net.cpp:137] Memory required for data: 695911600
I0926 22:37:52.738651  2459 layer_factory.hpp:77] Creating layer Scale20
I0926 22:37:52.738656  2459 net.cpp:84] Creating Layer Scale20
I0926 22:37:52.738657  2459 net.cpp:406] Scale20 <- Convolution20
I0926 22:37:52.738662  2459 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0926 22:37:52.738687  2459 layer_factory.hpp:77] Creating layer Scale20
I0926 22:37:52.738759  2459 net.cpp:122] Setting up Scale20
I0926 22:37:52.738764  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.738765  2459 net.cpp:137] Memory required for data: 699188400
I0926 22:37:52.738770  2459 layer_factory.hpp:77] Creating layer Convolution21
I0926 22:37:52.738776  2459 net.cpp:84] Creating Layer Convolution21
I0926 22:37:52.738780  2459 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0926 22:37:52.738783  2459 net.cpp:380] Convolution21 -> Convolution21
I0926 22:37:52.739845  2459 net.cpp:122] Setting up Convolution21
I0926 22:37:52.739861  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.739863  2459 net.cpp:137] Memory required for data: 702465200
I0926 22:37:52.739868  2459 layer_factory.hpp:77] Creating layer BatchNorm21
I0926 22:37:52.739873  2459 net.cpp:84] Creating Layer BatchNorm21
I0926 22:37:52.739876  2459 net.cpp:406] BatchNorm21 <- Convolution21
I0926 22:37:52.739881  2459 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0926 22:37:52.740010  2459 net.cpp:122] Setting up BatchNorm21
I0926 22:37:52.740015  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.740017  2459 net.cpp:137] Memory required for data: 705742000
I0926 22:37:52.740022  2459 layer_factory.hpp:77] Creating layer Scale21
I0926 22:37:52.740026  2459 net.cpp:84] Creating Layer Scale21
I0926 22:37:52.740028  2459 net.cpp:406] Scale21 <- Convolution21
I0926 22:37:52.740032  2459 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0926 22:37:52.740059  2459 layer_factory.hpp:77] Creating layer Scale21
I0926 22:37:52.740133  2459 net.cpp:122] Setting up Scale21
I0926 22:37:52.740136  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.740139  2459 net.cpp:137] Memory required for data: 709018800
I0926 22:37:52.740142  2459 layer_factory.hpp:77] Creating layer penlu20
I0926 22:37:52.740147  2459 net.cpp:84] Creating Layer penlu20
I0926 22:37:52.740150  2459 net.cpp:406] penlu20 <- Convolution21
I0926 22:37:52.740154  2459 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0926 22:37:52.740294  2459 net.cpp:122] Setting up penlu20
I0926 22:37:52.740301  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.740303  2459 net.cpp:137] Memory required for data: 712295600
I0926 22:37:52.740309  2459 layer_factory.hpp:77] Creating layer Convolution22
I0926 22:37:52.740314  2459 net.cpp:84] Creating Layer Convolution22
I0926 22:37:52.740317  2459 net.cpp:406] Convolution22 <- Convolution21
I0926 22:37:52.740321  2459 net.cpp:380] Convolution22 -> Convolution22
I0926 22:37:52.741436  2459 net.cpp:122] Setting up Convolution22
I0926 22:37:52.741444  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.741447  2459 net.cpp:137] Memory required for data: 715572400
I0926 22:37:52.741451  2459 layer_factory.hpp:77] Creating layer BatchNorm22
I0926 22:37:52.741456  2459 net.cpp:84] Creating Layer BatchNorm22
I0926 22:37:52.741459  2459 net.cpp:406] BatchNorm22 <- Convolution22
I0926 22:37:52.741463  2459 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0926 22:37:52.741590  2459 net.cpp:122] Setting up BatchNorm22
I0926 22:37:52.741593  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.741596  2459 net.cpp:137] Memory required for data: 718849200
I0926 22:37:52.741601  2459 layer_factory.hpp:77] Creating layer Scale22
I0926 22:37:52.741605  2459 net.cpp:84] Creating Layer Scale22
I0926 22:37:52.741607  2459 net.cpp:406] Scale22 <- Convolution22
I0926 22:37:52.741611  2459 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0926 22:37:52.741637  2459 layer_factory.hpp:77] Creating layer Scale22
I0926 22:37:52.741711  2459 net.cpp:122] Setting up Scale22
I0926 22:37:52.741716  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.741719  2459 net.cpp:137] Memory required for data: 722126000
I0926 22:37:52.741722  2459 layer_factory.hpp:77] Creating layer Eltwise10
I0926 22:37:52.741726  2459 net.cpp:84] Creating Layer Eltwise10
I0926 22:37:52.741729  2459 net.cpp:406] Eltwise10 <- Convolution20
I0926 22:37:52.741731  2459 net.cpp:406] Eltwise10 <- Convolution22
I0926 22:37:52.741735  2459 net.cpp:380] Eltwise10 -> Eltwise10
I0926 22:37:52.741747  2459 net.cpp:122] Setting up Eltwise10
I0926 22:37:52.741751  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.741753  2459 net.cpp:137] Memory required for data: 725402800
I0926 22:37:52.741755  2459 layer_factory.hpp:77] Creating layer penlu21
I0926 22:37:52.741760  2459 net.cpp:84] Creating Layer penlu21
I0926 22:37:52.741763  2459 net.cpp:406] penlu21 <- Eltwise10
I0926 22:37:52.741766  2459 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0926 22:37:52.741883  2459 net.cpp:122] Setting up penlu21
I0926 22:37:52.741888  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.741890  2459 net.cpp:137] Memory required for data: 728679600
I0926 22:37:52.741894  2459 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0926 22:37:52.741899  2459 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0926 22:37:52.741900  2459 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0926 22:37:52.741905  2459 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0926 22:37:52.741909  2459 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0926 22:37:52.741931  2459 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0926 22:37:52.741935  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.741938  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.741940  2459 net.cpp:137] Memory required for data: 735233200
I0926 22:37:52.741942  2459 layer_factory.hpp:77] Creating layer Convolution23
I0926 22:37:52.741950  2459 net.cpp:84] Creating Layer Convolution23
I0926 22:37:52.741951  2459 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0926 22:37:52.741955  2459 net.cpp:380] Convolution23 -> Convolution23
I0926 22:37:52.743063  2459 net.cpp:122] Setting up Convolution23
I0926 22:37:52.743072  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.743074  2459 net.cpp:137] Memory required for data: 738510000
I0926 22:37:52.743079  2459 layer_factory.hpp:77] Creating layer BatchNorm23
I0926 22:37:52.743084  2459 net.cpp:84] Creating Layer BatchNorm23
I0926 22:37:52.743088  2459 net.cpp:406] BatchNorm23 <- Convolution23
I0926 22:37:52.743090  2459 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0926 22:37:52.743213  2459 net.cpp:122] Setting up BatchNorm23
I0926 22:37:52.743218  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.743221  2459 net.cpp:137] Memory required for data: 741786800
I0926 22:37:52.743225  2459 layer_factory.hpp:77] Creating layer Scale23
I0926 22:37:52.743229  2459 net.cpp:84] Creating Layer Scale23
I0926 22:37:52.743232  2459 net.cpp:406] Scale23 <- Convolution23
I0926 22:37:52.743235  2459 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0926 22:37:52.743260  2459 layer_factory.hpp:77] Creating layer Scale23
I0926 22:37:52.743335  2459 net.cpp:122] Setting up Scale23
I0926 22:37:52.743340  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.743342  2459 net.cpp:137] Memory required for data: 745063600
I0926 22:37:52.743346  2459 layer_factory.hpp:77] Creating layer penlu22
I0926 22:37:52.743351  2459 net.cpp:84] Creating Layer penlu22
I0926 22:37:52.743355  2459 net.cpp:406] penlu22 <- Convolution23
I0926 22:37:52.743358  2459 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0926 22:37:52.743463  2459 net.cpp:122] Setting up penlu22
I0926 22:37:52.743468  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.743470  2459 net.cpp:137] Memory required for data: 748340400
I0926 22:37:52.743474  2459 layer_factory.hpp:77] Creating layer Convolution24
I0926 22:37:52.743480  2459 net.cpp:84] Creating Layer Convolution24
I0926 22:37:52.743484  2459 net.cpp:406] Convolution24 <- Convolution23
I0926 22:37:52.743489  2459 net.cpp:380] Convolution24 -> Convolution24
I0926 22:37:52.744621  2459 net.cpp:122] Setting up Convolution24
I0926 22:37:52.744629  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.744632  2459 net.cpp:137] Memory required for data: 751617200
I0926 22:37:52.744637  2459 layer_factory.hpp:77] Creating layer BatchNorm24
I0926 22:37:52.744642  2459 net.cpp:84] Creating Layer BatchNorm24
I0926 22:37:52.744644  2459 net.cpp:406] BatchNorm24 <- Convolution24
I0926 22:37:52.744648  2459 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0926 22:37:52.744777  2459 net.cpp:122] Setting up BatchNorm24
I0926 22:37:52.744781  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.744783  2459 net.cpp:137] Memory required for data: 754894000
I0926 22:37:52.744796  2459 layer_factory.hpp:77] Creating layer Scale24
I0926 22:37:52.744801  2459 net.cpp:84] Creating Layer Scale24
I0926 22:37:52.744803  2459 net.cpp:406] Scale24 <- Convolution24
I0926 22:37:52.744807  2459 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0926 22:37:52.744835  2459 layer_factory.hpp:77] Creating layer Scale24
I0926 22:37:52.744909  2459 net.cpp:122] Setting up Scale24
I0926 22:37:52.744913  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.744915  2459 net.cpp:137] Memory required for data: 758170800
I0926 22:37:52.744920  2459 layer_factory.hpp:77] Creating layer Eltwise11
I0926 22:37:52.744925  2459 net.cpp:84] Creating Layer Eltwise11
I0926 22:37:52.744926  2459 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0926 22:37:52.744930  2459 net.cpp:406] Eltwise11 <- Convolution24
I0926 22:37:52.744935  2459 net.cpp:380] Eltwise11 -> Eltwise11
I0926 22:37:52.744946  2459 net.cpp:122] Setting up Eltwise11
I0926 22:37:52.744951  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.744951  2459 net.cpp:137] Memory required for data: 761447600
I0926 22:37:52.744953  2459 layer_factory.hpp:77] Creating layer penlu23
I0926 22:37:52.744959  2459 net.cpp:84] Creating Layer penlu23
I0926 22:37:52.744962  2459 net.cpp:406] penlu23 <- Eltwise11
I0926 22:37:52.744966  2459 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0926 22:37:52.745074  2459 net.cpp:122] Setting up penlu23
I0926 22:37:52.745079  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.745080  2459 net.cpp:137] Memory required for data: 764724400
I0926 22:37:52.745085  2459 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0926 22:37:52.745088  2459 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0926 22:37:52.745090  2459 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0926 22:37:52.745095  2459 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0926 22:37:52.745098  2459 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0926 22:37:52.745121  2459 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0926 22:37:52.745124  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.745127  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.745129  2459 net.cpp:137] Memory required for data: 771278000
I0926 22:37:52.745131  2459 layer_factory.hpp:77] Creating layer Convolution25
I0926 22:37:52.745138  2459 net.cpp:84] Creating Layer Convolution25
I0926 22:37:52.745141  2459 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0926 22:37:52.745144  2459 net.cpp:380] Convolution25 -> Convolution25
I0926 22:37:52.746250  2459 net.cpp:122] Setting up Convolution25
I0926 22:37:52.746259  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.746261  2459 net.cpp:137] Memory required for data: 774554800
I0926 22:37:52.746266  2459 layer_factory.hpp:77] Creating layer BatchNorm25
I0926 22:37:52.746271  2459 net.cpp:84] Creating Layer BatchNorm25
I0926 22:37:52.746274  2459 net.cpp:406] BatchNorm25 <- Convolution25
I0926 22:37:52.746279  2459 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0926 22:37:52.746412  2459 net.cpp:122] Setting up BatchNorm25
I0926 22:37:52.746417  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.746418  2459 net.cpp:137] Memory required for data: 777831600
I0926 22:37:52.746423  2459 layer_factory.hpp:77] Creating layer Scale25
I0926 22:37:52.746426  2459 net.cpp:84] Creating Layer Scale25
I0926 22:37:52.746429  2459 net.cpp:406] Scale25 <- Convolution25
I0926 22:37:52.746433  2459 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0926 22:37:52.746460  2459 layer_factory.hpp:77] Creating layer Scale25
I0926 22:37:52.746534  2459 net.cpp:122] Setting up Scale25
I0926 22:37:52.746539  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.746541  2459 net.cpp:137] Memory required for data: 781108400
I0926 22:37:52.746546  2459 layer_factory.hpp:77] Creating layer penlu24
I0926 22:37:52.746551  2459 net.cpp:84] Creating Layer penlu24
I0926 22:37:52.746558  2459 net.cpp:406] penlu24 <- Convolution25
I0926 22:37:52.746563  2459 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0926 22:37:52.746673  2459 net.cpp:122] Setting up penlu24
I0926 22:37:52.746678  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.746680  2459 net.cpp:137] Memory required for data: 784385200
I0926 22:37:52.746685  2459 layer_factory.hpp:77] Creating layer Convolution26
I0926 22:37:52.746691  2459 net.cpp:84] Creating Layer Convolution26
I0926 22:37:52.746695  2459 net.cpp:406] Convolution26 <- Convolution25
I0926 22:37:52.746698  2459 net.cpp:380] Convolution26 -> Convolution26
I0926 22:37:52.747479  2459 net.cpp:122] Setting up Convolution26
I0926 22:37:52.747488  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.747490  2459 net.cpp:137] Memory required for data: 787662000
I0926 22:37:52.747495  2459 layer_factory.hpp:77] Creating layer BatchNorm26
I0926 22:37:52.747500  2459 net.cpp:84] Creating Layer BatchNorm26
I0926 22:37:52.747503  2459 net.cpp:406] BatchNorm26 <- Convolution26
I0926 22:37:52.747508  2459 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0926 22:37:52.747637  2459 net.cpp:122] Setting up BatchNorm26
I0926 22:37:52.747642  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.747643  2459 net.cpp:137] Memory required for data: 790938800
I0926 22:37:52.747648  2459 layer_factory.hpp:77] Creating layer Scale26
I0926 22:37:52.747653  2459 net.cpp:84] Creating Layer Scale26
I0926 22:37:52.747654  2459 net.cpp:406] Scale26 <- Convolution26
I0926 22:37:52.747658  2459 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0926 22:37:52.747684  2459 layer_factory.hpp:77] Creating layer Scale26
I0926 22:37:52.747761  2459 net.cpp:122] Setting up Scale26
I0926 22:37:52.747764  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.747766  2459 net.cpp:137] Memory required for data: 794215600
I0926 22:37:52.747771  2459 layer_factory.hpp:77] Creating layer Eltwise12
I0926 22:37:52.747774  2459 net.cpp:84] Creating Layer Eltwise12
I0926 22:37:52.747777  2459 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0926 22:37:52.747781  2459 net.cpp:406] Eltwise12 <- Convolution26
I0926 22:37:52.747784  2459 net.cpp:380] Eltwise12 -> Eltwise12
I0926 22:37:52.747797  2459 net.cpp:122] Setting up Eltwise12
I0926 22:37:52.747800  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.747802  2459 net.cpp:137] Memory required for data: 797492400
I0926 22:37:52.747804  2459 layer_factory.hpp:77] Creating layer penlu25
I0926 22:37:52.747817  2459 net.cpp:84] Creating Layer penlu25
I0926 22:37:52.747820  2459 net.cpp:406] penlu25 <- Eltwise12
I0926 22:37:52.747824  2459 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0926 22:37:52.747936  2459 net.cpp:122] Setting up penlu25
I0926 22:37:52.747941  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.747943  2459 net.cpp:137] Memory required for data: 800769200
I0926 22:37:52.747967  2459 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0926 22:37:52.747970  2459 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0926 22:37:52.747972  2459 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0926 22:37:52.747977  2459 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0926 22:37:52.747982  2459 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0926 22:37:52.748006  2459 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0926 22:37:52.748010  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.748013  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.748015  2459 net.cpp:137] Memory required for data: 807322800
I0926 22:37:52.748018  2459 layer_factory.hpp:77] Creating layer Convolution27
I0926 22:37:52.748024  2459 net.cpp:84] Creating Layer Convolution27
I0926 22:37:52.748026  2459 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0926 22:37:52.748031  2459 net.cpp:380] Convolution27 -> Convolution27
I0926 22:37:52.749485  2459 net.cpp:122] Setting up Convolution27
I0926 22:37:52.749500  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.749503  2459 net.cpp:137] Memory required for data: 810599600
I0926 22:37:52.749507  2459 layer_factory.hpp:77] Creating layer BatchNorm27
I0926 22:37:52.749513  2459 net.cpp:84] Creating Layer BatchNorm27
I0926 22:37:52.749516  2459 net.cpp:406] BatchNorm27 <- Convolution27
I0926 22:37:52.749519  2459 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0926 22:37:52.749650  2459 net.cpp:122] Setting up BatchNorm27
I0926 22:37:52.749655  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.749657  2459 net.cpp:137] Memory required for data: 813876400
I0926 22:37:52.749662  2459 layer_factory.hpp:77] Creating layer Scale27
I0926 22:37:52.749667  2459 net.cpp:84] Creating Layer Scale27
I0926 22:37:52.749670  2459 net.cpp:406] Scale27 <- Convolution27
I0926 22:37:52.749673  2459 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0926 22:37:52.749701  2459 layer_factory.hpp:77] Creating layer Scale27
I0926 22:37:52.749774  2459 net.cpp:122] Setting up Scale27
I0926 22:37:52.749779  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.749781  2459 net.cpp:137] Memory required for data: 817153200
I0926 22:37:52.749785  2459 layer_factory.hpp:77] Creating layer penlu26
I0926 22:37:52.749791  2459 net.cpp:84] Creating Layer penlu26
I0926 22:37:52.749794  2459 net.cpp:406] penlu26 <- Convolution27
I0926 22:37:52.749797  2459 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0926 22:37:52.749912  2459 net.cpp:122] Setting up penlu26
I0926 22:37:52.749917  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.749920  2459 net.cpp:137] Memory required for data: 820430000
I0926 22:37:52.749925  2459 layer_factory.hpp:77] Creating layer Convolution28
I0926 22:37:52.749932  2459 net.cpp:84] Creating Layer Convolution28
I0926 22:37:52.749934  2459 net.cpp:406] Convolution28 <- Convolution27
I0926 22:37:52.749939  2459 net.cpp:380] Convolution28 -> Convolution28
I0926 22:37:52.751523  2459 net.cpp:122] Setting up Convolution28
I0926 22:37:52.751533  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.751534  2459 net.cpp:137] Memory required for data: 823706800
I0926 22:37:52.751540  2459 layer_factory.hpp:77] Creating layer BatchNorm28
I0926 22:37:52.751545  2459 net.cpp:84] Creating Layer BatchNorm28
I0926 22:37:52.751549  2459 net.cpp:406] BatchNorm28 <- Convolution28
I0926 22:37:52.751552  2459 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0926 22:37:52.751685  2459 net.cpp:122] Setting up BatchNorm28
I0926 22:37:52.751690  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.751693  2459 net.cpp:137] Memory required for data: 826983600
I0926 22:37:52.751698  2459 layer_factory.hpp:77] Creating layer Scale28
I0926 22:37:52.751703  2459 net.cpp:84] Creating Layer Scale28
I0926 22:37:52.751705  2459 net.cpp:406] Scale28 <- Convolution28
I0926 22:37:52.751708  2459 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0926 22:37:52.751736  2459 layer_factory.hpp:77] Creating layer Scale28
I0926 22:37:52.751812  2459 net.cpp:122] Setting up Scale28
I0926 22:37:52.751817  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.751819  2459 net.cpp:137] Memory required for data: 830260400
I0926 22:37:52.751823  2459 layer_factory.hpp:77] Creating layer Eltwise13
I0926 22:37:52.751827  2459 net.cpp:84] Creating Layer Eltwise13
I0926 22:37:52.751829  2459 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0926 22:37:52.751832  2459 net.cpp:406] Eltwise13 <- Convolution28
I0926 22:37:52.751837  2459 net.cpp:380] Eltwise13 -> Eltwise13
I0926 22:37:52.751849  2459 net.cpp:122] Setting up Eltwise13
I0926 22:37:52.751853  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.751855  2459 net.cpp:137] Memory required for data: 833537200
I0926 22:37:52.751858  2459 layer_factory.hpp:77] Creating layer penlu27
I0926 22:37:52.751863  2459 net.cpp:84] Creating Layer penlu27
I0926 22:37:52.751865  2459 net.cpp:406] penlu27 <- Eltwise13
I0926 22:37:52.751875  2459 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0926 22:37:52.751991  2459 net.cpp:122] Setting up penlu27
I0926 22:37:52.751994  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.751997  2459 net.cpp:137] Memory required for data: 836814000
I0926 22:37:52.752002  2459 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0926 22:37:52.752005  2459 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0926 22:37:52.752008  2459 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0926 22:37:52.752012  2459 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0926 22:37:52.752015  2459 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0926 22:37:52.752039  2459 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0926 22:37:52.752043  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.752046  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.752048  2459 net.cpp:137] Memory required for data: 843367600
I0926 22:37:52.752050  2459 layer_factory.hpp:77] Creating layer Convolution29
I0926 22:37:52.752056  2459 net.cpp:84] Creating Layer Convolution29
I0926 22:37:52.752059  2459 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0926 22:37:52.752063  2459 net.cpp:380] Convolution29 -> Convolution29
I0926 22:37:52.753188  2459 net.cpp:122] Setting up Convolution29
I0926 22:37:52.753197  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.753201  2459 net.cpp:137] Memory required for data: 846644400
I0926 22:37:52.753204  2459 layer_factory.hpp:77] Creating layer BatchNorm29
I0926 22:37:52.753211  2459 net.cpp:84] Creating Layer BatchNorm29
I0926 22:37:52.753213  2459 net.cpp:406] BatchNorm29 <- Convolution29
I0926 22:37:52.753216  2459 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0926 22:37:52.753347  2459 net.cpp:122] Setting up BatchNorm29
I0926 22:37:52.753352  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.753355  2459 net.cpp:137] Memory required for data: 849921200
I0926 22:37:52.753360  2459 layer_factory.hpp:77] Creating layer Scale29
I0926 22:37:52.753365  2459 net.cpp:84] Creating Layer Scale29
I0926 22:37:52.753366  2459 net.cpp:406] Scale29 <- Convolution29
I0926 22:37:52.753371  2459 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0926 22:37:52.753398  2459 layer_factory.hpp:77] Creating layer Scale29
I0926 22:37:52.753473  2459 net.cpp:122] Setting up Scale29
I0926 22:37:52.753479  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.753480  2459 net.cpp:137] Memory required for data: 853198000
I0926 22:37:52.753484  2459 layer_factory.hpp:77] Creating layer penlu28
I0926 22:37:52.753490  2459 net.cpp:84] Creating Layer penlu28
I0926 22:37:52.753494  2459 net.cpp:406] penlu28 <- Convolution29
I0926 22:37:52.753497  2459 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0926 22:37:52.753605  2459 net.cpp:122] Setting up penlu28
I0926 22:37:52.753609  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.753612  2459 net.cpp:137] Memory required for data: 856474800
I0926 22:37:52.753615  2459 layer_factory.hpp:77] Creating layer Convolution30
I0926 22:37:52.753623  2459 net.cpp:84] Creating Layer Convolution30
I0926 22:37:52.753625  2459 net.cpp:406] Convolution30 <- Convolution29
I0926 22:37:52.753629  2459 net.cpp:380] Convolution30 -> Convolution30
I0926 22:37:52.754736  2459 net.cpp:122] Setting up Convolution30
I0926 22:37:52.754745  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.754747  2459 net.cpp:137] Memory required for data: 859751600
I0926 22:37:52.754752  2459 layer_factory.hpp:77] Creating layer BatchNorm30
I0926 22:37:52.754758  2459 net.cpp:84] Creating Layer BatchNorm30
I0926 22:37:52.754761  2459 net.cpp:406] BatchNorm30 <- Convolution30
I0926 22:37:52.754765  2459 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0926 22:37:52.754891  2459 net.cpp:122] Setting up BatchNorm30
I0926 22:37:52.754896  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.754899  2459 net.cpp:137] Memory required for data: 863028400
I0926 22:37:52.754910  2459 layer_factory.hpp:77] Creating layer Scale30
I0926 22:37:52.754914  2459 net.cpp:84] Creating Layer Scale30
I0926 22:37:52.754917  2459 net.cpp:406] Scale30 <- Convolution30
I0926 22:37:52.754920  2459 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0926 22:37:52.754948  2459 layer_factory.hpp:77] Creating layer Scale30
I0926 22:37:52.755022  2459 net.cpp:122] Setting up Scale30
I0926 22:37:52.755026  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.755028  2459 net.cpp:137] Memory required for data: 866305200
I0926 22:37:52.755033  2459 layer_factory.hpp:77] Creating layer Eltwise14
I0926 22:37:52.755036  2459 net.cpp:84] Creating Layer Eltwise14
I0926 22:37:52.755039  2459 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0926 22:37:52.755043  2459 net.cpp:406] Eltwise14 <- Convolution30
I0926 22:37:52.755045  2459 net.cpp:380] Eltwise14 -> Eltwise14
I0926 22:37:52.755058  2459 net.cpp:122] Setting up Eltwise14
I0926 22:37:52.755061  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.755064  2459 net.cpp:137] Memory required for data: 869582000
I0926 22:37:52.755065  2459 layer_factory.hpp:77] Creating layer penlu29
I0926 22:37:52.755071  2459 net.cpp:84] Creating Layer penlu29
I0926 22:37:52.755074  2459 net.cpp:406] penlu29 <- Eltwise14
I0926 22:37:52.755077  2459 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0926 22:37:52.755187  2459 net.cpp:122] Setting up penlu29
I0926 22:37:52.755190  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.755193  2459 net.cpp:137] Memory required for data: 872858800
I0926 22:37:52.755198  2459 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0926 22:37:52.755200  2459 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0926 22:37:52.755203  2459 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0926 22:37:52.755208  2459 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0926 22:37:52.755211  2459 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0926 22:37:52.755234  2459 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0926 22:37:52.755237  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.755240  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.755242  2459 net.cpp:137] Memory required for data: 879412400
I0926 22:37:52.755244  2459 layer_factory.hpp:77] Creating layer Convolution31
I0926 22:37:52.755254  2459 net.cpp:84] Creating Layer Convolution31
I0926 22:37:52.755255  2459 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0926 22:37:52.755260  2459 net.cpp:380] Convolution31 -> Convolution31
I0926 22:37:52.756377  2459 net.cpp:122] Setting up Convolution31
I0926 22:37:52.756386  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.756389  2459 net.cpp:137] Memory required for data: 882689200
I0926 22:37:52.756393  2459 layer_factory.hpp:77] Creating layer BatchNorm31
I0926 22:37:52.756399  2459 net.cpp:84] Creating Layer BatchNorm31
I0926 22:37:52.756402  2459 net.cpp:406] BatchNorm31 <- Convolution31
I0926 22:37:52.756405  2459 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0926 22:37:52.756532  2459 net.cpp:122] Setting up BatchNorm31
I0926 22:37:52.756537  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.756539  2459 net.cpp:137] Memory required for data: 885966000
I0926 22:37:52.756544  2459 layer_factory.hpp:77] Creating layer Scale31
I0926 22:37:52.756548  2459 net.cpp:84] Creating Layer Scale31
I0926 22:37:52.756551  2459 net.cpp:406] Scale31 <- Convolution31
I0926 22:37:52.756556  2459 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0926 22:37:52.756582  2459 layer_factory.hpp:77] Creating layer Scale31
I0926 22:37:52.756655  2459 net.cpp:122] Setting up Scale31
I0926 22:37:52.756659  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.756661  2459 net.cpp:137] Memory required for data: 889242800
I0926 22:37:52.756665  2459 layer_factory.hpp:77] Creating layer penlu30
I0926 22:37:52.756671  2459 net.cpp:84] Creating Layer penlu30
I0926 22:37:52.756680  2459 net.cpp:406] penlu30 <- Convolution31
I0926 22:37:52.756685  2459 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0926 22:37:52.756790  2459 net.cpp:122] Setting up penlu30
I0926 22:37:52.756795  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.756798  2459 net.cpp:137] Memory required for data: 892519600
I0926 22:37:52.756803  2459 layer_factory.hpp:77] Creating layer Convolution32
I0926 22:37:52.756808  2459 net.cpp:84] Creating Layer Convolution32
I0926 22:37:52.756810  2459 net.cpp:406] Convolution32 <- Convolution31
I0926 22:37:52.756814  2459 net.cpp:380] Convolution32 -> Convolution32
I0926 22:37:52.757923  2459 net.cpp:122] Setting up Convolution32
I0926 22:37:52.757931  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.757935  2459 net.cpp:137] Memory required for data: 895796400
I0926 22:37:52.757938  2459 layer_factory.hpp:77] Creating layer BatchNorm32
I0926 22:37:52.757944  2459 net.cpp:84] Creating Layer BatchNorm32
I0926 22:37:52.757947  2459 net.cpp:406] BatchNorm32 <- Convolution32
I0926 22:37:52.757951  2459 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0926 22:37:52.758080  2459 net.cpp:122] Setting up BatchNorm32
I0926 22:37:52.758085  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.758087  2459 net.cpp:137] Memory required for data: 899073200
I0926 22:37:52.758092  2459 layer_factory.hpp:77] Creating layer Scale32
I0926 22:37:52.758096  2459 net.cpp:84] Creating Layer Scale32
I0926 22:37:52.758100  2459 net.cpp:406] Scale32 <- Convolution32
I0926 22:37:52.758102  2459 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0926 22:37:52.758129  2459 layer_factory.hpp:77] Creating layer Scale32
I0926 22:37:52.758205  2459 net.cpp:122] Setting up Scale32
I0926 22:37:52.758209  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.758211  2459 net.cpp:137] Memory required for data: 902350000
I0926 22:37:52.758215  2459 layer_factory.hpp:77] Creating layer Eltwise15
I0926 22:37:52.758220  2459 net.cpp:84] Creating Layer Eltwise15
I0926 22:37:52.758224  2459 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0926 22:37:52.758226  2459 net.cpp:406] Eltwise15 <- Convolution32
I0926 22:37:52.758229  2459 net.cpp:380] Eltwise15 -> Eltwise15
I0926 22:37:52.758242  2459 net.cpp:122] Setting up Eltwise15
I0926 22:37:52.758246  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.758249  2459 net.cpp:137] Memory required for data: 905626800
I0926 22:37:52.758250  2459 layer_factory.hpp:77] Creating layer penlu31
I0926 22:37:52.758256  2459 net.cpp:84] Creating Layer penlu31
I0926 22:37:52.758258  2459 net.cpp:406] penlu31 <- Eltwise15
I0926 22:37:52.758262  2459 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0926 22:37:52.758375  2459 net.cpp:122] Setting up penlu31
I0926 22:37:52.758380  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.758383  2459 net.cpp:137] Memory required for data: 908903600
I0926 22:37:52.758386  2459 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0926 22:37:52.758390  2459 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0926 22:37:52.758393  2459 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0926 22:37:52.758395  2459 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0926 22:37:52.758399  2459 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0926 22:37:52.758424  2459 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0926 22:37:52.758427  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.758430  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.758432  2459 net.cpp:137] Memory required for data: 915457200
I0926 22:37:52.758435  2459 layer_factory.hpp:77] Creating layer Convolution33
I0926 22:37:52.758441  2459 net.cpp:84] Creating Layer Convolution33
I0926 22:37:52.758443  2459 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0926 22:37:52.758447  2459 net.cpp:380] Convolution33 -> Convolution33
I0926 22:37:52.759578  2459 net.cpp:122] Setting up Convolution33
I0926 22:37:52.759588  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.759590  2459 net.cpp:137] Memory required for data: 918734000
I0926 22:37:52.759594  2459 layer_factory.hpp:77] Creating layer BatchNorm33
I0926 22:37:52.759599  2459 net.cpp:84] Creating Layer BatchNorm33
I0926 22:37:52.759603  2459 net.cpp:406] BatchNorm33 <- Convolution33
I0926 22:37:52.759606  2459 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0926 22:37:52.759738  2459 net.cpp:122] Setting up BatchNorm33
I0926 22:37:52.759743  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.759745  2459 net.cpp:137] Memory required for data: 922010800
I0926 22:37:52.759750  2459 layer_factory.hpp:77] Creating layer Scale33
I0926 22:37:52.759754  2459 net.cpp:84] Creating Layer Scale33
I0926 22:37:52.759757  2459 net.cpp:406] Scale33 <- Convolution33
I0926 22:37:52.759760  2459 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0926 22:37:52.759788  2459 layer_factory.hpp:77] Creating layer Scale33
I0926 22:37:52.759862  2459 net.cpp:122] Setting up Scale33
I0926 22:37:52.759867  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.759869  2459 net.cpp:137] Memory required for data: 925287600
I0926 22:37:52.759873  2459 layer_factory.hpp:77] Creating layer penlu32
I0926 22:37:52.759878  2459 net.cpp:84] Creating Layer penlu32
I0926 22:37:52.759881  2459 net.cpp:406] penlu32 <- Convolution33
I0926 22:37:52.759884  2459 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0926 22:37:52.759992  2459 net.cpp:122] Setting up penlu32
I0926 22:37:52.759996  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.759999  2459 net.cpp:137] Memory required for data: 928564400
I0926 22:37:52.760004  2459 layer_factory.hpp:77] Creating layer Convolution34
I0926 22:37:52.760010  2459 net.cpp:84] Creating Layer Convolution34
I0926 22:37:52.760013  2459 net.cpp:406] Convolution34 <- Convolution33
I0926 22:37:52.760016  2459 net.cpp:380] Convolution34 -> Convolution34
I0926 22:37:52.761667  2459 net.cpp:122] Setting up Convolution34
I0926 22:37:52.761675  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.761677  2459 net.cpp:137] Memory required for data: 931841200
I0926 22:37:52.761682  2459 layer_factory.hpp:77] Creating layer BatchNorm34
I0926 22:37:52.761687  2459 net.cpp:84] Creating Layer BatchNorm34
I0926 22:37:52.761689  2459 net.cpp:406] BatchNorm34 <- Convolution34
I0926 22:37:52.761694  2459 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0926 22:37:52.761826  2459 net.cpp:122] Setting up BatchNorm34
I0926 22:37:52.761831  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.761833  2459 net.cpp:137] Memory required for data: 935118000
I0926 22:37:52.761838  2459 layer_factory.hpp:77] Creating layer Scale34
I0926 22:37:52.761842  2459 net.cpp:84] Creating Layer Scale34
I0926 22:37:52.761844  2459 net.cpp:406] Scale34 <- Convolution34
I0926 22:37:52.761848  2459 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0926 22:37:52.761875  2459 layer_factory.hpp:77] Creating layer Scale34
I0926 22:37:52.761950  2459 net.cpp:122] Setting up Scale34
I0926 22:37:52.761955  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.761957  2459 net.cpp:137] Memory required for data: 938394800
I0926 22:37:52.761961  2459 layer_factory.hpp:77] Creating layer Eltwise16
I0926 22:37:52.761965  2459 net.cpp:84] Creating Layer Eltwise16
I0926 22:37:52.761968  2459 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0926 22:37:52.761971  2459 net.cpp:406] Eltwise16 <- Convolution34
I0926 22:37:52.761976  2459 net.cpp:380] Eltwise16 -> Eltwise16
I0926 22:37:52.761987  2459 net.cpp:122] Setting up Eltwise16
I0926 22:37:52.761991  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.761992  2459 net.cpp:137] Memory required for data: 941671600
I0926 22:37:52.761994  2459 layer_factory.hpp:77] Creating layer penlu33
I0926 22:37:52.762001  2459 net.cpp:84] Creating Layer penlu33
I0926 22:37:52.762002  2459 net.cpp:406] penlu33 <- Eltwise16
I0926 22:37:52.762013  2459 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0926 22:37:52.762130  2459 net.cpp:122] Setting up penlu33
I0926 22:37:52.762135  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.762136  2459 net.cpp:137] Memory required for data: 944948400
I0926 22:37:52.762141  2459 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0926 22:37:52.762145  2459 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0926 22:37:52.762147  2459 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0926 22:37:52.762151  2459 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0926 22:37:52.762156  2459 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0926 22:37:52.762179  2459 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0926 22:37:52.762183  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.762187  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.762188  2459 net.cpp:137] Memory required for data: 951502000
I0926 22:37:52.762190  2459 layer_factory.hpp:77] Creating layer Convolution35
I0926 22:37:52.762197  2459 net.cpp:84] Creating Layer Convolution35
I0926 22:37:52.762199  2459 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0926 22:37:52.762203  2459 net.cpp:380] Convolution35 -> Convolution35
I0926 22:37:52.763319  2459 net.cpp:122] Setting up Convolution35
I0926 22:37:52.763327  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.763330  2459 net.cpp:137] Memory required for data: 954778800
I0926 22:37:52.763334  2459 layer_factory.hpp:77] Creating layer BatchNorm35
I0926 22:37:52.763340  2459 net.cpp:84] Creating Layer BatchNorm35
I0926 22:37:52.763344  2459 net.cpp:406] BatchNorm35 <- Convolution35
I0926 22:37:52.763348  2459 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0926 22:37:52.763481  2459 net.cpp:122] Setting up BatchNorm35
I0926 22:37:52.763486  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.763489  2459 net.cpp:137] Memory required for data: 958055600
I0926 22:37:52.763494  2459 layer_factory.hpp:77] Creating layer Scale35
I0926 22:37:52.763499  2459 net.cpp:84] Creating Layer Scale35
I0926 22:37:52.763501  2459 net.cpp:406] Scale35 <- Convolution35
I0926 22:37:52.763504  2459 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0926 22:37:52.763532  2459 layer_factory.hpp:77] Creating layer Scale35
I0926 22:37:52.763612  2459 net.cpp:122] Setting up Scale35
I0926 22:37:52.763615  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.763617  2459 net.cpp:137] Memory required for data: 961332400
I0926 22:37:52.763622  2459 layer_factory.hpp:77] Creating layer penlu34
I0926 22:37:52.763628  2459 net.cpp:84] Creating Layer penlu34
I0926 22:37:52.763629  2459 net.cpp:406] penlu34 <- Convolution35
I0926 22:37:52.763634  2459 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0926 22:37:52.763741  2459 net.cpp:122] Setting up penlu34
I0926 22:37:52.763746  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.763747  2459 net.cpp:137] Memory required for data: 964609200
I0926 22:37:52.763751  2459 layer_factory.hpp:77] Creating layer Convolution36
I0926 22:37:52.763758  2459 net.cpp:84] Creating Layer Convolution36
I0926 22:37:52.763761  2459 net.cpp:406] Convolution36 <- Convolution35
I0926 22:37:52.763766  2459 net.cpp:380] Convolution36 -> Convolution36
I0926 22:37:52.764550  2459 net.cpp:122] Setting up Convolution36
I0926 22:37:52.764559  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.764560  2459 net.cpp:137] Memory required for data: 967886000
I0926 22:37:52.764564  2459 layer_factory.hpp:77] Creating layer BatchNorm36
I0926 22:37:52.764569  2459 net.cpp:84] Creating Layer BatchNorm36
I0926 22:37:52.764572  2459 net.cpp:406] BatchNorm36 <- Convolution36
I0926 22:37:52.764577  2459 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0926 22:37:52.764708  2459 net.cpp:122] Setting up BatchNorm36
I0926 22:37:52.764714  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.764722  2459 net.cpp:137] Memory required for data: 971162800
I0926 22:37:52.764727  2459 layer_factory.hpp:77] Creating layer Scale36
I0926 22:37:52.764731  2459 net.cpp:84] Creating Layer Scale36
I0926 22:37:52.764734  2459 net.cpp:406] Scale36 <- Convolution36
I0926 22:37:52.764739  2459 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0926 22:37:52.764767  2459 layer_factory.hpp:77] Creating layer Scale36
I0926 22:37:52.764844  2459 net.cpp:122] Setting up Scale36
I0926 22:37:52.764848  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.764850  2459 net.cpp:137] Memory required for data: 974439600
I0926 22:37:52.764854  2459 layer_factory.hpp:77] Creating layer Eltwise17
I0926 22:37:52.764858  2459 net.cpp:84] Creating Layer Eltwise17
I0926 22:37:52.764861  2459 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0926 22:37:52.764864  2459 net.cpp:406] Eltwise17 <- Convolution36
I0926 22:37:52.764868  2459 net.cpp:380] Eltwise17 -> Eltwise17
I0926 22:37:52.764880  2459 net.cpp:122] Setting up Eltwise17
I0926 22:37:52.764884  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.764886  2459 net.cpp:137] Memory required for data: 977716400
I0926 22:37:52.764889  2459 layer_factory.hpp:77] Creating layer penlu35
I0926 22:37:52.764894  2459 net.cpp:84] Creating Layer penlu35
I0926 22:37:52.764896  2459 net.cpp:406] penlu35 <- Eltwise17
I0926 22:37:52.764899  2459 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0926 22:37:52.765012  2459 net.cpp:122] Setting up penlu35
I0926 22:37:52.765017  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.765019  2459 net.cpp:137] Memory required for data: 980993200
I0926 22:37:52.765023  2459 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0926 22:37:52.765028  2459 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0926 22:37:52.765030  2459 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0926 22:37:52.765034  2459 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0926 22:37:52.765038  2459 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0926 22:37:52.765064  2459 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0926 22:37:52.765067  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.765069  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.765071  2459 net.cpp:137] Memory required for data: 987546800
I0926 22:37:52.765074  2459 layer_factory.hpp:77] Creating layer Convolution37
I0926 22:37:52.765079  2459 net.cpp:84] Creating Layer Convolution37
I0926 22:37:52.765082  2459 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0926 22:37:52.765087  2459 net.cpp:380] Convolution37 -> Convolution37
I0926 22:37:52.766201  2459 net.cpp:122] Setting up Convolution37
I0926 22:37:52.766208  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.766211  2459 net.cpp:137] Memory required for data: 990823600
I0926 22:37:52.766216  2459 layer_factory.hpp:77] Creating layer BatchNorm37
I0926 22:37:52.766222  2459 net.cpp:84] Creating Layer BatchNorm37
I0926 22:37:52.766224  2459 net.cpp:406] BatchNorm37 <- Convolution37
I0926 22:37:52.766228  2459 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0926 22:37:52.766362  2459 net.cpp:122] Setting up BatchNorm37
I0926 22:37:52.766366  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.766369  2459 net.cpp:137] Memory required for data: 994100400
I0926 22:37:52.766374  2459 layer_factory.hpp:77] Creating layer Scale37
I0926 22:37:52.766379  2459 net.cpp:84] Creating Layer Scale37
I0926 22:37:52.766381  2459 net.cpp:406] Scale37 <- Convolution37
I0926 22:37:52.766386  2459 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0926 22:37:52.766414  2459 layer_factory.hpp:77] Creating layer Scale37
I0926 22:37:52.766494  2459 net.cpp:122] Setting up Scale37
I0926 22:37:52.766497  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.766499  2459 net.cpp:137] Memory required for data: 997377200
I0926 22:37:52.766504  2459 layer_factory.hpp:77] Creating layer penlu36
I0926 22:37:52.766515  2459 net.cpp:84] Creating Layer penlu36
I0926 22:37:52.766518  2459 net.cpp:406] penlu36 <- Convolution37
I0926 22:37:52.766523  2459 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0926 22:37:52.766633  2459 net.cpp:122] Setting up penlu36
I0926 22:37:52.766638  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.766640  2459 net.cpp:137] Memory required for data: 1000654000
I0926 22:37:52.766644  2459 layer_factory.hpp:77] Creating layer Convolution38
I0926 22:37:52.766650  2459 net.cpp:84] Creating Layer Convolution38
I0926 22:37:52.766654  2459 net.cpp:406] Convolution38 <- Convolution37
I0926 22:37:52.766657  2459 net.cpp:380] Convolution38 -> Convolution38
I0926 22:37:52.768141  2459 net.cpp:122] Setting up Convolution38
I0926 22:37:52.768159  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.768162  2459 net.cpp:137] Memory required for data: 1003930800
I0926 22:37:52.768168  2459 layer_factory.hpp:77] Creating layer BatchNorm38
I0926 22:37:52.768173  2459 net.cpp:84] Creating Layer BatchNorm38
I0926 22:37:52.768177  2459 net.cpp:406] BatchNorm38 <- Convolution38
I0926 22:37:52.768180  2459 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0926 22:37:52.768324  2459 net.cpp:122] Setting up BatchNorm38
I0926 22:37:52.768329  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.768332  2459 net.cpp:137] Memory required for data: 1007207600
I0926 22:37:52.768337  2459 layer_factory.hpp:77] Creating layer Scale38
I0926 22:37:52.768342  2459 net.cpp:84] Creating Layer Scale38
I0926 22:37:52.768344  2459 net.cpp:406] Scale38 <- Convolution38
I0926 22:37:52.768348  2459 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0926 22:37:52.768376  2459 layer_factory.hpp:77] Creating layer Scale38
I0926 22:37:52.768456  2459 net.cpp:122] Setting up Scale38
I0926 22:37:52.768460  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.768463  2459 net.cpp:137] Memory required for data: 1010484400
I0926 22:37:52.768467  2459 layer_factory.hpp:77] Creating layer Eltwise18
I0926 22:37:52.768471  2459 net.cpp:84] Creating Layer Eltwise18
I0926 22:37:52.768473  2459 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0926 22:37:52.768476  2459 net.cpp:406] Eltwise18 <- Convolution38
I0926 22:37:52.768481  2459 net.cpp:380] Eltwise18 -> Eltwise18
I0926 22:37:52.768493  2459 net.cpp:122] Setting up Eltwise18
I0926 22:37:52.768498  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.768501  2459 net.cpp:137] Memory required for data: 1013761200
I0926 22:37:52.768502  2459 layer_factory.hpp:77] Creating layer penlu37
I0926 22:37:52.768507  2459 net.cpp:84] Creating Layer penlu37
I0926 22:37:52.768509  2459 net.cpp:406] penlu37 <- Eltwise18
I0926 22:37:52.768513  2459 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0926 22:37:52.768671  2459 net.cpp:122] Setting up penlu37
I0926 22:37:52.768676  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.768677  2459 net.cpp:137] Memory required for data: 1017038000
I0926 22:37:52.768682  2459 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0926 22:37:52.768685  2459 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0926 22:37:52.768687  2459 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0926 22:37:52.768690  2459 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0926 22:37:52.768695  2459 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0926 22:37:52.768719  2459 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0926 22:37:52.768723  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.768726  2459 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0926 22:37:52.768728  2459 net.cpp:137] Memory required for data: 1023591600
I0926 22:37:52.768730  2459 layer_factory.hpp:77] Creating layer Convolution39
I0926 22:37:52.768736  2459 net.cpp:84] Creating Layer Convolution39
I0926 22:37:52.768739  2459 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0926 22:37:52.768743  2459 net.cpp:380] Convolution39 -> Convolution39
I0926 22:37:52.769964  2459 net.cpp:122] Setting up Convolution39
I0926 22:37:52.769974  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.769976  2459 net.cpp:137] Memory required for data: 1025230000
I0926 22:37:52.769981  2459 layer_factory.hpp:77] Creating layer BatchNorm39
I0926 22:37:52.769986  2459 net.cpp:84] Creating Layer BatchNorm39
I0926 22:37:52.769989  2459 net.cpp:406] BatchNorm39 <- Convolution39
I0926 22:37:52.769994  2459 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0926 22:37:52.770140  2459 net.cpp:122] Setting up BatchNorm39
I0926 22:37:52.770145  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.770148  2459 net.cpp:137] Memory required for data: 1026868400
I0926 22:37:52.770153  2459 layer_factory.hpp:77] Creating layer Scale39
I0926 22:37:52.770157  2459 net.cpp:84] Creating Layer Scale39
I0926 22:37:52.770160  2459 net.cpp:406] Scale39 <- Convolution39
I0926 22:37:52.770164  2459 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0926 22:37:52.770195  2459 layer_factory.hpp:77] Creating layer Scale39
I0926 22:37:52.770287  2459 net.cpp:122] Setting up Scale39
I0926 22:37:52.770290  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.770292  2459 net.cpp:137] Memory required for data: 1028506800
I0926 22:37:52.770297  2459 layer_factory.hpp:77] Creating layer Convolution40
I0926 22:37:52.770303  2459 net.cpp:84] Creating Layer Convolution40
I0926 22:37:52.770306  2459 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0926 22:37:52.770311  2459 net.cpp:380] Convolution40 -> Convolution40
I0926 22:37:52.771731  2459 net.cpp:122] Setting up Convolution40
I0926 22:37:52.771740  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.771744  2459 net.cpp:137] Memory required for data: 1030145200
I0926 22:37:52.771747  2459 layer_factory.hpp:77] Creating layer BatchNorm40
I0926 22:37:52.771754  2459 net.cpp:84] Creating Layer BatchNorm40
I0926 22:37:52.771756  2459 net.cpp:406] BatchNorm40 <- Convolution40
I0926 22:37:52.771759  2459 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0926 22:37:52.771899  2459 net.cpp:122] Setting up BatchNorm40
I0926 22:37:52.771904  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.771906  2459 net.cpp:137] Memory required for data: 1031783600
I0926 22:37:52.771911  2459 layer_factory.hpp:77] Creating layer Scale40
I0926 22:37:52.771916  2459 net.cpp:84] Creating Layer Scale40
I0926 22:37:52.771919  2459 net.cpp:406] Scale40 <- Convolution40
I0926 22:37:52.771922  2459 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0926 22:37:52.771950  2459 layer_factory.hpp:77] Creating layer Scale40
I0926 22:37:52.772028  2459 net.cpp:122] Setting up Scale40
I0926 22:37:52.772032  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.772034  2459 net.cpp:137] Memory required for data: 1033422000
I0926 22:37:52.772038  2459 layer_factory.hpp:77] Creating layer penlu38
I0926 22:37:52.772043  2459 net.cpp:84] Creating Layer penlu38
I0926 22:37:52.772047  2459 net.cpp:406] penlu38 <- Convolution40
I0926 22:37:52.772050  2459 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0926 22:37:52.772168  2459 net.cpp:122] Setting up penlu38
I0926 22:37:52.772173  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.772176  2459 net.cpp:137] Memory required for data: 1035060400
I0926 22:37:52.772179  2459 layer_factory.hpp:77] Creating layer Convolution41
I0926 22:37:52.772186  2459 net.cpp:84] Creating Layer Convolution41
I0926 22:37:52.772189  2459 net.cpp:406] Convolution41 <- Convolution40
I0926 22:37:52.772193  2459 net.cpp:380] Convolution41 -> Convolution41
I0926 22:37:52.773965  2459 net.cpp:122] Setting up Convolution41
I0926 22:37:52.773974  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.773977  2459 net.cpp:137] Memory required for data: 1036698800
I0926 22:37:52.773982  2459 layer_factory.hpp:77] Creating layer BatchNorm41
I0926 22:37:52.773988  2459 net.cpp:84] Creating Layer BatchNorm41
I0926 22:37:52.773990  2459 net.cpp:406] BatchNorm41 <- Convolution41
I0926 22:37:52.774000  2459 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0926 22:37:52.774139  2459 net.cpp:122] Setting up BatchNorm41
I0926 22:37:52.774143  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.774147  2459 net.cpp:137] Memory required for data: 1038337200
I0926 22:37:52.774150  2459 layer_factory.hpp:77] Creating layer Scale41
I0926 22:37:52.774155  2459 net.cpp:84] Creating Layer Scale41
I0926 22:37:52.774158  2459 net.cpp:406] Scale41 <- Convolution41
I0926 22:37:52.774161  2459 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0926 22:37:52.774189  2459 layer_factory.hpp:77] Creating layer Scale41
I0926 22:37:52.774269  2459 net.cpp:122] Setting up Scale41
I0926 22:37:52.774273  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.774276  2459 net.cpp:137] Memory required for data: 1039975600
I0926 22:37:52.774279  2459 layer_factory.hpp:77] Creating layer Eltwise19
I0926 22:37:52.774283  2459 net.cpp:84] Creating Layer Eltwise19
I0926 22:37:52.774286  2459 net.cpp:406] Eltwise19 <- Convolution39
I0926 22:37:52.774289  2459 net.cpp:406] Eltwise19 <- Convolution41
I0926 22:37:52.774292  2459 net.cpp:380] Eltwise19 -> Eltwise19
I0926 22:37:52.774309  2459 net.cpp:122] Setting up Eltwise19
I0926 22:37:52.774313  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.774315  2459 net.cpp:137] Memory required for data: 1041614000
I0926 22:37:52.774317  2459 layer_factory.hpp:77] Creating layer penlu39
I0926 22:37:52.774322  2459 net.cpp:84] Creating Layer penlu39
I0926 22:37:52.774325  2459 net.cpp:406] penlu39 <- Eltwise19
I0926 22:37:52.774328  2459 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0926 22:37:52.774446  2459 net.cpp:122] Setting up penlu39
I0926 22:37:52.774451  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.774452  2459 net.cpp:137] Memory required for data: 1043252400
I0926 22:37:52.774457  2459 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0926 22:37:52.774461  2459 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0926 22:37:52.774463  2459 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0926 22:37:52.774466  2459 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0926 22:37:52.774471  2459 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0926 22:37:52.774495  2459 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0926 22:37:52.774499  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.774502  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.774503  2459 net.cpp:137] Memory required for data: 1046529200
I0926 22:37:52.774505  2459 layer_factory.hpp:77] Creating layer Convolution42
I0926 22:37:52.774513  2459 net.cpp:84] Creating Layer Convolution42
I0926 22:37:52.774514  2459 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0926 22:37:52.774518  2459 net.cpp:380] Convolution42 -> Convolution42
I0926 22:37:52.776233  2459 net.cpp:122] Setting up Convolution42
I0926 22:37:52.776252  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.776254  2459 net.cpp:137] Memory required for data: 1048167600
I0926 22:37:52.776268  2459 layer_factory.hpp:77] Creating layer BatchNorm42
I0926 22:37:52.776275  2459 net.cpp:84] Creating Layer BatchNorm42
I0926 22:37:52.776278  2459 net.cpp:406] BatchNorm42 <- Convolution42
I0926 22:37:52.776291  2459 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0926 22:37:52.776428  2459 net.cpp:122] Setting up BatchNorm42
I0926 22:37:52.776433  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.776435  2459 net.cpp:137] Memory required for data: 1049806000
I0926 22:37:52.776439  2459 layer_factory.hpp:77] Creating layer Scale42
I0926 22:37:52.776444  2459 net.cpp:84] Creating Layer Scale42
I0926 22:37:52.776446  2459 net.cpp:406] Scale42 <- Convolution42
I0926 22:37:52.776450  2459 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0926 22:37:52.776477  2459 layer_factory.hpp:77] Creating layer Scale42
I0926 22:37:52.776556  2459 net.cpp:122] Setting up Scale42
I0926 22:37:52.776567  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.776569  2459 net.cpp:137] Memory required for data: 1051444400
I0926 22:37:52.776573  2459 layer_factory.hpp:77] Creating layer penlu40
I0926 22:37:52.776579  2459 net.cpp:84] Creating Layer penlu40
I0926 22:37:52.776582  2459 net.cpp:406] penlu40 <- Convolution42
I0926 22:37:52.776587  2459 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0926 22:37:52.776703  2459 net.cpp:122] Setting up penlu40
I0926 22:37:52.776708  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.776710  2459 net.cpp:137] Memory required for data: 1053082800
I0926 22:37:52.776715  2459 layer_factory.hpp:77] Creating layer Convolution43
I0926 22:37:52.776721  2459 net.cpp:84] Creating Layer Convolution43
I0926 22:37:52.776722  2459 net.cpp:406] Convolution43 <- Convolution42
I0926 22:37:52.776727  2459 net.cpp:380] Convolution43 -> Convolution43
I0926 22:37:52.778419  2459 net.cpp:122] Setting up Convolution43
I0926 22:37:52.778427  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.778430  2459 net.cpp:137] Memory required for data: 1054721200
I0926 22:37:52.778434  2459 layer_factory.hpp:77] Creating layer BatchNorm43
I0926 22:37:52.778439  2459 net.cpp:84] Creating Layer BatchNorm43
I0926 22:37:52.778441  2459 net.cpp:406] BatchNorm43 <- Convolution43
I0926 22:37:52.778445  2459 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0926 22:37:52.778581  2459 net.cpp:122] Setting up BatchNorm43
I0926 22:37:52.778586  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.778589  2459 net.cpp:137] Memory required for data: 1056359600
I0926 22:37:52.778594  2459 layer_factory.hpp:77] Creating layer Scale43
I0926 22:37:52.778597  2459 net.cpp:84] Creating Layer Scale43
I0926 22:37:52.778599  2459 net.cpp:406] Scale43 <- Convolution43
I0926 22:37:52.778602  2459 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0926 22:37:52.778630  2459 layer_factory.hpp:77] Creating layer Scale43
I0926 22:37:52.778709  2459 net.cpp:122] Setting up Scale43
I0926 22:37:52.778714  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.778717  2459 net.cpp:137] Memory required for data: 1057998000
I0926 22:37:52.778720  2459 layer_factory.hpp:77] Creating layer Eltwise20
I0926 22:37:52.778723  2459 net.cpp:84] Creating Layer Eltwise20
I0926 22:37:52.778726  2459 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0926 22:37:52.778729  2459 net.cpp:406] Eltwise20 <- Convolution43
I0926 22:37:52.778733  2459 net.cpp:380] Eltwise20 -> Eltwise20
I0926 22:37:52.778749  2459 net.cpp:122] Setting up Eltwise20
I0926 22:37:52.778753  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.778755  2459 net.cpp:137] Memory required for data: 1059636400
I0926 22:37:52.778758  2459 layer_factory.hpp:77] Creating layer penlu41
I0926 22:37:52.778762  2459 net.cpp:84] Creating Layer penlu41
I0926 22:37:52.778765  2459 net.cpp:406] penlu41 <- Eltwise20
I0926 22:37:52.778769  2459 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0926 22:37:52.778883  2459 net.cpp:122] Setting up penlu41
I0926 22:37:52.778888  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.778890  2459 net.cpp:137] Memory required for data: 1061274800
I0926 22:37:52.778894  2459 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0926 22:37:52.778898  2459 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0926 22:37:52.778900  2459 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0926 22:37:52.778903  2459 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0926 22:37:52.778908  2459 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0926 22:37:52.778931  2459 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0926 22:37:52.778935  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.778939  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.778940  2459 net.cpp:137] Memory required for data: 1064551600
I0926 22:37:52.778942  2459 layer_factory.hpp:77] Creating layer Convolution44
I0926 22:37:52.778955  2459 net.cpp:84] Creating Layer Convolution44
I0926 22:37:52.778959  2459 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0926 22:37:52.778962  2459 net.cpp:380] Convolution44 -> Convolution44
I0926 22:37:52.781028  2459 net.cpp:122] Setting up Convolution44
I0926 22:37:52.781038  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.781040  2459 net.cpp:137] Memory required for data: 1066190000
I0926 22:37:52.781045  2459 layer_factory.hpp:77] Creating layer BatchNorm44
I0926 22:37:52.781050  2459 net.cpp:84] Creating Layer BatchNorm44
I0926 22:37:52.781054  2459 net.cpp:406] BatchNorm44 <- Convolution44
I0926 22:37:52.781059  2459 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0926 22:37:52.781203  2459 net.cpp:122] Setting up BatchNorm44
I0926 22:37:52.781208  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.781209  2459 net.cpp:137] Memory required for data: 1067828400
I0926 22:37:52.781214  2459 layer_factory.hpp:77] Creating layer Scale44
I0926 22:37:52.781219  2459 net.cpp:84] Creating Layer Scale44
I0926 22:37:52.781222  2459 net.cpp:406] Scale44 <- Convolution44
I0926 22:37:52.781225  2459 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0926 22:37:52.781255  2459 layer_factory.hpp:77] Creating layer Scale44
I0926 22:37:52.781335  2459 net.cpp:122] Setting up Scale44
I0926 22:37:52.781339  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.781342  2459 net.cpp:137] Memory required for data: 1069466800
I0926 22:37:52.781345  2459 layer_factory.hpp:77] Creating layer penlu42
I0926 22:37:52.781350  2459 net.cpp:84] Creating Layer penlu42
I0926 22:37:52.781353  2459 net.cpp:406] penlu42 <- Convolution44
I0926 22:37:52.781357  2459 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0926 22:37:52.781481  2459 net.cpp:122] Setting up penlu42
I0926 22:37:52.781486  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.781487  2459 net.cpp:137] Memory required for data: 1071105200
I0926 22:37:52.781492  2459 layer_factory.hpp:77] Creating layer Convolution45
I0926 22:37:52.781499  2459 net.cpp:84] Creating Layer Convolution45
I0926 22:37:52.781502  2459 net.cpp:406] Convolution45 <- Convolution44
I0926 22:37:52.781505  2459 net.cpp:380] Convolution45 -> Convolution45
I0926 22:37:52.783216  2459 net.cpp:122] Setting up Convolution45
I0926 22:37:52.783224  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.783227  2459 net.cpp:137] Memory required for data: 1072743600
I0926 22:37:52.783231  2459 layer_factory.hpp:77] Creating layer BatchNorm45
I0926 22:37:52.783237  2459 net.cpp:84] Creating Layer BatchNorm45
I0926 22:37:52.783241  2459 net.cpp:406] BatchNorm45 <- Convolution45
I0926 22:37:52.783243  2459 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0926 22:37:52.783381  2459 net.cpp:122] Setting up BatchNorm45
I0926 22:37:52.783386  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.783388  2459 net.cpp:137] Memory required for data: 1074382000
I0926 22:37:52.783392  2459 layer_factory.hpp:77] Creating layer Scale45
I0926 22:37:52.783397  2459 net.cpp:84] Creating Layer Scale45
I0926 22:37:52.796816  2459 net.cpp:406] Scale45 <- Convolution45
I0926 22:37:52.796828  2459 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0926 22:37:52.796875  2459 layer_factory.hpp:77] Creating layer Scale45
I0926 22:37:52.796970  2459 net.cpp:122] Setting up Scale45
I0926 22:37:52.796975  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.796977  2459 net.cpp:137] Memory required for data: 1076020400
I0926 22:37:52.796983  2459 layer_factory.hpp:77] Creating layer Eltwise21
I0926 22:37:52.796988  2459 net.cpp:84] Creating Layer Eltwise21
I0926 22:37:52.796991  2459 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0926 22:37:52.796994  2459 net.cpp:406] Eltwise21 <- Convolution45
I0926 22:37:52.796998  2459 net.cpp:380] Eltwise21 -> Eltwise21
I0926 22:37:52.797019  2459 net.cpp:122] Setting up Eltwise21
I0926 22:37:52.797022  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.797024  2459 net.cpp:137] Memory required for data: 1077658800
I0926 22:37:52.797034  2459 layer_factory.hpp:77] Creating layer penlu43
I0926 22:37:52.797041  2459 net.cpp:84] Creating Layer penlu43
I0926 22:37:52.797044  2459 net.cpp:406] penlu43 <- Eltwise21
I0926 22:37:52.797049  2459 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0926 22:37:52.797178  2459 net.cpp:122] Setting up penlu43
I0926 22:37:52.797184  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.797186  2459 net.cpp:137] Memory required for data: 1079297200
I0926 22:37:52.797191  2459 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0926 22:37:52.797195  2459 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0926 22:37:52.797199  2459 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0926 22:37:52.797201  2459 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0926 22:37:52.797206  2459 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0926 22:37:52.797235  2459 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0926 22:37:52.797238  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.797241  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.797243  2459 net.cpp:137] Memory required for data: 1082574000
I0926 22:37:52.797246  2459 layer_factory.hpp:77] Creating layer Convolution46
I0926 22:37:52.797253  2459 net.cpp:84] Creating Layer Convolution46
I0926 22:37:52.797256  2459 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0926 22:37:52.797260  2459 net.cpp:380] Convolution46 -> Convolution46
I0926 22:37:52.799249  2459 net.cpp:122] Setting up Convolution46
I0926 22:37:52.799258  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.799270  2459 net.cpp:137] Memory required for data: 1084212400
I0926 22:37:52.799275  2459 layer_factory.hpp:77] Creating layer BatchNorm46
I0926 22:37:52.799281  2459 net.cpp:84] Creating Layer BatchNorm46
I0926 22:37:52.799284  2459 net.cpp:406] BatchNorm46 <- Convolution46
I0926 22:37:52.799288  2459 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0926 22:37:52.799434  2459 net.cpp:122] Setting up BatchNorm46
I0926 22:37:52.799439  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.799441  2459 net.cpp:137] Memory required for data: 1085850800
I0926 22:37:52.799446  2459 layer_factory.hpp:77] Creating layer Scale46
I0926 22:37:52.799451  2459 net.cpp:84] Creating Layer Scale46
I0926 22:37:52.799454  2459 net.cpp:406] Scale46 <- Convolution46
I0926 22:37:52.799458  2459 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0926 22:37:52.799489  2459 layer_factory.hpp:77] Creating layer Scale46
I0926 22:37:52.799571  2459 net.cpp:122] Setting up Scale46
I0926 22:37:52.799574  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.799576  2459 net.cpp:137] Memory required for data: 1087489200
I0926 22:37:52.799581  2459 layer_factory.hpp:77] Creating layer penlu44
I0926 22:37:52.799587  2459 net.cpp:84] Creating Layer penlu44
I0926 22:37:52.799589  2459 net.cpp:406] penlu44 <- Convolution46
I0926 22:37:52.799593  2459 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0926 22:37:52.799712  2459 net.cpp:122] Setting up penlu44
I0926 22:37:52.799716  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.799718  2459 net.cpp:137] Memory required for data: 1089127600
I0926 22:37:52.799723  2459 layer_factory.hpp:77] Creating layer Convolution47
I0926 22:37:52.799729  2459 net.cpp:84] Creating Layer Convolution47
I0926 22:37:52.799732  2459 net.cpp:406] Convolution47 <- Convolution46
I0926 22:37:52.799736  2459 net.cpp:380] Convolution47 -> Convolution47
I0926 22:37:52.801537  2459 net.cpp:122] Setting up Convolution47
I0926 22:37:52.801545  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.801548  2459 net.cpp:137] Memory required for data: 1090766000
I0926 22:37:52.801553  2459 layer_factory.hpp:77] Creating layer BatchNorm47
I0926 22:37:52.801558  2459 net.cpp:84] Creating Layer BatchNorm47
I0926 22:37:52.801561  2459 net.cpp:406] BatchNorm47 <- Convolution47
I0926 22:37:52.801565  2459 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0926 22:37:52.801714  2459 net.cpp:122] Setting up BatchNorm47
I0926 22:37:52.801720  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.801723  2459 net.cpp:137] Memory required for data: 1092404400
I0926 22:37:52.801728  2459 layer_factory.hpp:77] Creating layer Scale47
I0926 22:37:52.801731  2459 net.cpp:84] Creating Layer Scale47
I0926 22:37:52.801734  2459 net.cpp:406] Scale47 <- Convolution47
I0926 22:37:52.801738  2459 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0926 22:37:52.801766  2459 layer_factory.hpp:77] Creating layer Scale47
I0926 22:37:52.801846  2459 net.cpp:122] Setting up Scale47
I0926 22:37:52.801849  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.801852  2459 net.cpp:137] Memory required for data: 1094042800
I0926 22:37:52.801856  2459 layer_factory.hpp:77] Creating layer Eltwise22
I0926 22:37:52.801862  2459 net.cpp:84] Creating Layer Eltwise22
I0926 22:37:52.801863  2459 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0926 22:37:52.801867  2459 net.cpp:406] Eltwise22 <- Convolution47
I0926 22:37:52.801870  2459 net.cpp:380] Eltwise22 -> Eltwise22
I0926 22:37:52.801887  2459 net.cpp:122] Setting up Eltwise22
I0926 22:37:52.801892  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.801893  2459 net.cpp:137] Memory required for data: 1095681200
I0926 22:37:52.801895  2459 layer_factory.hpp:77] Creating layer penlu45
I0926 22:37:52.801901  2459 net.cpp:84] Creating Layer penlu45
I0926 22:37:52.801903  2459 net.cpp:406] penlu45 <- Eltwise22
I0926 22:37:52.801906  2459 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0926 22:37:52.802022  2459 net.cpp:122] Setting up penlu45
I0926 22:37:52.802027  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.802029  2459 net.cpp:137] Memory required for data: 1097319600
I0926 22:37:52.802033  2459 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0926 22:37:52.802037  2459 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0926 22:37:52.802039  2459 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0926 22:37:52.802043  2459 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0926 22:37:52.802047  2459 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0926 22:37:52.802073  2459 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0926 22:37:52.802078  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.802080  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.802083  2459 net.cpp:137] Memory required for data: 1100596400
I0926 22:37:52.802084  2459 layer_factory.hpp:77] Creating layer Convolution48
I0926 22:37:52.802090  2459 net.cpp:84] Creating Layer Convolution48
I0926 22:37:52.802093  2459 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0926 22:37:52.802098  2459 net.cpp:380] Convolution48 -> Convolution48
I0926 22:37:52.804168  2459 net.cpp:122] Setting up Convolution48
I0926 22:37:52.804177  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.804180  2459 net.cpp:137] Memory required for data: 1102234800
I0926 22:37:52.804185  2459 layer_factory.hpp:77] Creating layer BatchNorm48
I0926 22:37:52.804190  2459 net.cpp:84] Creating Layer BatchNorm48
I0926 22:37:52.804193  2459 net.cpp:406] BatchNorm48 <- Convolution48
I0926 22:37:52.804198  2459 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0926 22:37:52.804354  2459 net.cpp:122] Setting up BatchNorm48
I0926 22:37:52.804360  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.804363  2459 net.cpp:137] Memory required for data: 1103873200
I0926 22:37:52.804368  2459 layer_factory.hpp:77] Creating layer Scale48
I0926 22:37:52.804371  2459 net.cpp:84] Creating Layer Scale48
I0926 22:37:52.804373  2459 net.cpp:406] Scale48 <- Convolution48
I0926 22:37:52.804378  2459 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0926 22:37:52.804406  2459 layer_factory.hpp:77] Creating layer Scale48
I0926 22:37:52.804486  2459 net.cpp:122] Setting up Scale48
I0926 22:37:52.804491  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.804499  2459 net.cpp:137] Memory required for data: 1105511600
I0926 22:37:52.804504  2459 layer_factory.hpp:77] Creating layer penlu46
I0926 22:37:52.804509  2459 net.cpp:84] Creating Layer penlu46
I0926 22:37:52.804512  2459 net.cpp:406] penlu46 <- Convolution48
I0926 22:37:52.804517  2459 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0926 22:37:52.804632  2459 net.cpp:122] Setting up penlu46
I0926 22:37:52.804637  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.804639  2459 net.cpp:137] Memory required for data: 1107150000
I0926 22:37:52.804643  2459 layer_factory.hpp:77] Creating layer Convolution49
I0926 22:37:52.804651  2459 net.cpp:84] Creating Layer Convolution49
I0926 22:37:52.804653  2459 net.cpp:406] Convolution49 <- Convolution48
I0926 22:37:52.804657  2459 net.cpp:380] Convolution49 -> Convolution49
I0926 22:37:52.806684  2459 net.cpp:122] Setting up Convolution49
I0926 22:37:52.806694  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.806695  2459 net.cpp:137] Memory required for data: 1108788400
I0926 22:37:52.806700  2459 layer_factory.hpp:77] Creating layer BatchNorm49
I0926 22:37:52.806704  2459 net.cpp:84] Creating Layer BatchNorm49
I0926 22:37:52.806707  2459 net.cpp:406] BatchNorm49 <- Convolution49
I0926 22:37:52.806712  2459 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0926 22:37:52.806851  2459 net.cpp:122] Setting up BatchNorm49
I0926 22:37:52.806855  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.806857  2459 net.cpp:137] Memory required for data: 1110426800
I0926 22:37:52.806862  2459 layer_factory.hpp:77] Creating layer Scale49
I0926 22:37:52.806866  2459 net.cpp:84] Creating Layer Scale49
I0926 22:37:52.806869  2459 net.cpp:406] Scale49 <- Convolution49
I0926 22:37:52.806872  2459 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0926 22:37:52.806900  2459 layer_factory.hpp:77] Creating layer Scale49
I0926 22:37:52.806980  2459 net.cpp:122] Setting up Scale49
I0926 22:37:52.806985  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.806988  2459 net.cpp:137] Memory required for data: 1112065200
I0926 22:37:52.806991  2459 layer_factory.hpp:77] Creating layer Eltwise23
I0926 22:37:52.806995  2459 net.cpp:84] Creating Layer Eltwise23
I0926 22:37:52.806998  2459 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0926 22:37:52.807000  2459 net.cpp:406] Eltwise23 <- Convolution49
I0926 22:37:52.807004  2459 net.cpp:380] Eltwise23 -> Eltwise23
I0926 22:37:52.807023  2459 net.cpp:122] Setting up Eltwise23
I0926 22:37:52.807026  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.807029  2459 net.cpp:137] Memory required for data: 1113703600
I0926 22:37:52.807030  2459 layer_factory.hpp:77] Creating layer penlu47
I0926 22:37:52.807034  2459 net.cpp:84] Creating Layer penlu47
I0926 22:37:52.807037  2459 net.cpp:406] penlu47 <- Eltwise23
I0926 22:37:52.807041  2459 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0926 22:37:52.807158  2459 net.cpp:122] Setting up penlu47
I0926 22:37:52.807163  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.807165  2459 net.cpp:137] Memory required for data: 1115342000
I0926 22:37:52.807169  2459 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0926 22:37:52.807173  2459 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0926 22:37:52.807175  2459 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0926 22:37:52.807178  2459 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0926 22:37:52.807183  2459 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0926 22:37:52.807207  2459 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0926 22:37:52.807211  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.807214  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.807215  2459 net.cpp:137] Memory required for data: 1118618800
I0926 22:37:52.807217  2459 layer_factory.hpp:77] Creating layer Convolution50
I0926 22:37:52.807224  2459 net.cpp:84] Creating Layer Convolution50
I0926 22:37:52.807234  2459 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0926 22:37:52.807237  2459 net.cpp:380] Convolution50 -> Convolution50
I0926 22:37:52.809880  2459 net.cpp:122] Setting up Convolution50
I0926 22:37:52.809890  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.809892  2459 net.cpp:137] Memory required for data: 1120257200
I0926 22:37:52.809896  2459 layer_factory.hpp:77] Creating layer BatchNorm50
I0926 22:37:52.809902  2459 net.cpp:84] Creating Layer BatchNorm50
I0926 22:37:52.809906  2459 net.cpp:406] BatchNorm50 <- Convolution50
I0926 22:37:52.809908  2459 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0926 22:37:52.810053  2459 net.cpp:122] Setting up BatchNorm50
I0926 22:37:52.810058  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.810060  2459 net.cpp:137] Memory required for data: 1121895600
I0926 22:37:52.810065  2459 layer_factory.hpp:77] Creating layer Scale50
I0926 22:37:52.810070  2459 net.cpp:84] Creating Layer Scale50
I0926 22:37:52.810073  2459 net.cpp:406] Scale50 <- Convolution50
I0926 22:37:52.810076  2459 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0926 22:37:52.810104  2459 layer_factory.hpp:77] Creating layer Scale50
I0926 22:37:52.810185  2459 net.cpp:122] Setting up Scale50
I0926 22:37:52.810190  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.810192  2459 net.cpp:137] Memory required for data: 1123534000
I0926 22:37:52.810196  2459 layer_factory.hpp:77] Creating layer penlu48
I0926 22:37:52.810201  2459 net.cpp:84] Creating Layer penlu48
I0926 22:37:52.810204  2459 net.cpp:406] penlu48 <- Convolution50
I0926 22:37:52.810209  2459 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0926 22:37:52.810323  2459 net.cpp:122] Setting up penlu48
I0926 22:37:52.810328  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.810329  2459 net.cpp:137] Memory required for data: 1125172400
I0926 22:37:52.810333  2459 layer_factory.hpp:77] Creating layer Convolution51
I0926 22:37:52.810341  2459 net.cpp:84] Creating Layer Convolution51
I0926 22:37:52.810344  2459 net.cpp:406] Convolution51 <- Convolution50
I0926 22:37:52.810348  2459 net.cpp:380] Convolution51 -> Convolution51
I0926 22:37:52.812077  2459 net.cpp:122] Setting up Convolution51
I0926 22:37:52.812085  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.812088  2459 net.cpp:137] Memory required for data: 1126810800
I0926 22:37:52.812093  2459 layer_factory.hpp:77] Creating layer BatchNorm51
I0926 22:37:52.812096  2459 net.cpp:84] Creating Layer BatchNorm51
I0926 22:37:52.812099  2459 net.cpp:406] BatchNorm51 <- Convolution51
I0926 22:37:52.812104  2459 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0926 22:37:52.812270  2459 net.cpp:122] Setting up BatchNorm51
I0926 22:37:52.812276  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.812278  2459 net.cpp:137] Memory required for data: 1128449200
I0926 22:37:52.827312  2459 layer_factory.hpp:77] Creating layer Scale51
I0926 22:37:52.827322  2459 net.cpp:84] Creating Layer Scale51
I0926 22:37:52.827325  2459 net.cpp:406] Scale51 <- Convolution51
I0926 22:37:52.827332  2459 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0926 22:37:52.827380  2459 layer_factory.hpp:77] Creating layer Scale51
I0926 22:37:52.827466  2459 net.cpp:122] Setting up Scale51
I0926 22:37:52.827471  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.827473  2459 net.cpp:137] Memory required for data: 1130087600
I0926 22:37:52.827477  2459 layer_factory.hpp:77] Creating layer Eltwise24
I0926 22:37:52.827482  2459 net.cpp:84] Creating Layer Eltwise24
I0926 22:37:52.827484  2459 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0926 22:37:52.827487  2459 net.cpp:406] Eltwise24 <- Convolution51
I0926 22:37:52.827492  2459 net.cpp:380] Eltwise24 -> Eltwise24
I0926 22:37:52.827510  2459 net.cpp:122] Setting up Eltwise24
I0926 22:37:52.827514  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.827517  2459 net.cpp:137] Memory required for data: 1131726000
I0926 22:37:52.827525  2459 layer_factory.hpp:77] Creating layer penlu49
I0926 22:37:52.827530  2459 net.cpp:84] Creating Layer penlu49
I0926 22:37:52.827533  2459 net.cpp:406] penlu49 <- Eltwise24
I0926 22:37:52.827538  2459 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0926 22:37:52.827659  2459 net.cpp:122] Setting up penlu49
I0926 22:37:52.827664  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.827666  2459 net.cpp:137] Memory required for data: 1133364400
I0926 22:37:52.827672  2459 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0926 22:37:52.827675  2459 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0926 22:37:52.827677  2459 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0926 22:37:52.827680  2459 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0926 22:37:52.827685  2459 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0926 22:37:52.827719  2459 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0926 22:37:52.827723  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.827728  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.827729  2459 net.cpp:137] Memory required for data: 1136641200
I0926 22:37:52.827731  2459 layer_factory.hpp:77] Creating layer Convolution52
I0926 22:37:52.827738  2459 net.cpp:84] Creating Layer Convolution52
I0926 22:37:52.827740  2459 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0926 22:37:52.827744  2459 net.cpp:380] Convolution52 -> Convolution52
I0926 22:37:52.830260  2459 net.cpp:122] Setting up Convolution52
I0926 22:37:52.830271  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.830273  2459 net.cpp:137] Memory required for data: 1138279600
I0926 22:37:52.830279  2459 layer_factory.hpp:77] Creating layer BatchNorm52
I0926 22:37:52.830286  2459 net.cpp:84] Creating Layer BatchNorm52
I0926 22:37:52.830288  2459 net.cpp:406] BatchNorm52 <- Convolution52
I0926 22:37:52.830292  2459 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0926 22:37:52.830446  2459 net.cpp:122] Setting up BatchNorm52
I0926 22:37:52.830451  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.830454  2459 net.cpp:137] Memory required for data: 1139918000
I0926 22:37:52.830459  2459 layer_factory.hpp:77] Creating layer Scale52
I0926 22:37:52.830463  2459 net.cpp:84] Creating Layer Scale52
I0926 22:37:52.830466  2459 net.cpp:406] Scale52 <- Convolution52
I0926 22:37:52.830471  2459 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0926 22:37:52.830502  2459 layer_factory.hpp:77] Creating layer Scale52
I0926 22:37:52.830588  2459 net.cpp:122] Setting up Scale52
I0926 22:37:52.830593  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.830595  2459 net.cpp:137] Memory required for data: 1141556400
I0926 22:37:52.830600  2459 layer_factory.hpp:77] Creating layer penlu50
I0926 22:37:52.830622  2459 net.cpp:84] Creating Layer penlu50
I0926 22:37:52.830626  2459 net.cpp:406] penlu50 <- Convolution52
I0926 22:37:52.830629  2459 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0926 22:37:52.830756  2459 net.cpp:122] Setting up penlu50
I0926 22:37:52.830761  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.830763  2459 net.cpp:137] Memory required for data: 1143194800
I0926 22:37:52.830812  2459 layer_factory.hpp:77] Creating layer Convolution53
I0926 22:37:52.830821  2459 net.cpp:84] Creating Layer Convolution53
I0926 22:37:52.830823  2459 net.cpp:406] Convolution53 <- Convolution52
I0926 22:37:52.830827  2459 net.cpp:380] Convolution53 -> Convolution53
I0926 22:37:52.832635  2459 net.cpp:122] Setting up Convolution53
I0926 22:37:52.832644  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.832646  2459 net.cpp:137] Memory required for data: 1144833200
I0926 22:37:52.832651  2459 layer_factory.hpp:77] Creating layer BatchNorm53
I0926 22:37:52.832656  2459 net.cpp:84] Creating Layer BatchNorm53
I0926 22:37:52.832659  2459 net.cpp:406] BatchNorm53 <- Convolution53
I0926 22:37:52.832664  2459 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0926 22:37:52.832816  2459 net.cpp:122] Setting up BatchNorm53
I0926 22:37:52.832821  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.832824  2459 net.cpp:137] Memory required for data: 1146471600
I0926 22:37:52.832828  2459 layer_factory.hpp:77] Creating layer Scale53
I0926 22:37:52.832834  2459 net.cpp:84] Creating Layer Scale53
I0926 22:37:52.832835  2459 net.cpp:406] Scale53 <- Convolution53
I0926 22:37:52.832839  2459 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0926 22:37:52.832867  2459 layer_factory.hpp:77] Creating layer Scale53
I0926 22:37:52.832949  2459 net.cpp:122] Setting up Scale53
I0926 22:37:52.832954  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.832957  2459 net.cpp:137] Memory required for data: 1148110000
I0926 22:37:52.832960  2459 layer_factory.hpp:77] Creating layer Eltwise25
I0926 22:37:52.832964  2459 net.cpp:84] Creating Layer Eltwise25
I0926 22:37:52.832967  2459 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0926 22:37:52.832972  2459 net.cpp:406] Eltwise25 <- Convolution53
I0926 22:37:52.832974  2459 net.cpp:380] Eltwise25 -> Eltwise25
I0926 22:37:52.832993  2459 net.cpp:122] Setting up Eltwise25
I0926 22:37:52.832996  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.832998  2459 net.cpp:137] Memory required for data: 1149748400
I0926 22:37:52.833000  2459 layer_factory.hpp:77] Creating layer penlu51
I0926 22:37:52.833006  2459 net.cpp:84] Creating Layer penlu51
I0926 22:37:52.833009  2459 net.cpp:406] penlu51 <- Eltwise25
I0926 22:37:52.833012  2459 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0926 22:37:52.833133  2459 net.cpp:122] Setting up penlu51
I0926 22:37:52.833137  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.833139  2459 net.cpp:137] Memory required for data: 1151386800
I0926 22:37:52.833143  2459 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0926 22:37:52.833148  2459 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0926 22:37:52.833149  2459 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0926 22:37:52.833153  2459 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0926 22:37:52.833158  2459 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0926 22:37:52.833181  2459 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0926 22:37:52.833185  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.833189  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.833190  2459 net.cpp:137] Memory required for data: 1154663600
I0926 22:37:52.833192  2459 layer_factory.hpp:77] Creating layer Convolution54
I0926 22:37:52.833197  2459 net.cpp:84] Creating Layer Convolution54
I0926 22:37:52.833200  2459 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0926 22:37:52.833205  2459 net.cpp:380] Convolution54 -> Convolution54
I0926 22:37:52.835233  2459 net.cpp:122] Setting up Convolution54
I0926 22:37:52.835242  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.835244  2459 net.cpp:137] Memory required for data: 1156302000
I0926 22:37:52.835249  2459 layer_factory.hpp:77] Creating layer BatchNorm54
I0926 22:37:52.835254  2459 net.cpp:84] Creating Layer BatchNorm54
I0926 22:37:52.835258  2459 net.cpp:406] BatchNorm54 <- Convolution54
I0926 22:37:52.835261  2459 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0926 22:37:52.835407  2459 net.cpp:122] Setting up BatchNorm54
I0926 22:37:52.835412  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.835414  2459 net.cpp:137] Memory required for data: 1157940400
I0926 22:37:52.835419  2459 layer_factory.hpp:77] Creating layer Scale54
I0926 22:37:52.835425  2459 net.cpp:84] Creating Layer Scale54
I0926 22:37:52.835428  2459 net.cpp:406] Scale54 <- Convolution54
I0926 22:37:52.835431  2459 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0926 22:37:52.835460  2459 layer_factory.hpp:77] Creating layer Scale54
I0926 22:37:52.835542  2459 net.cpp:122] Setting up Scale54
I0926 22:37:52.835546  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.835554  2459 net.cpp:137] Memory required for data: 1159578800
I0926 22:37:52.835559  2459 layer_factory.hpp:77] Creating layer penlu52
I0926 22:37:52.835566  2459 net.cpp:84] Creating Layer penlu52
I0926 22:37:52.835567  2459 net.cpp:406] penlu52 <- Convolution54
I0926 22:37:52.835572  2459 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0926 22:37:52.835690  2459 net.cpp:122] Setting up penlu52
I0926 22:37:52.835695  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.835697  2459 net.cpp:137] Memory required for data: 1161217200
I0926 22:37:52.835701  2459 layer_factory.hpp:77] Creating layer Convolution55
I0926 22:37:52.835708  2459 net.cpp:84] Creating Layer Convolution55
I0926 22:37:52.835711  2459 net.cpp:406] Convolution55 <- Convolution54
I0926 22:37:52.835714  2459 net.cpp:380] Convolution55 -> Convolution55
I0926 22:37:52.837432  2459 net.cpp:122] Setting up Convolution55
I0926 22:37:52.837441  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.837445  2459 net.cpp:137] Memory required for data: 1162855600
I0926 22:37:52.837448  2459 layer_factory.hpp:77] Creating layer BatchNorm55
I0926 22:37:52.837453  2459 net.cpp:84] Creating Layer BatchNorm55
I0926 22:37:52.837456  2459 net.cpp:406] BatchNorm55 <- Convolution55
I0926 22:37:52.837461  2459 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0926 22:37:52.837602  2459 net.cpp:122] Setting up BatchNorm55
I0926 22:37:52.837607  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.837610  2459 net.cpp:137] Memory required for data: 1164494000
I0926 22:37:52.837615  2459 layer_factory.hpp:77] Creating layer Scale55
I0926 22:37:52.837620  2459 net.cpp:84] Creating Layer Scale55
I0926 22:37:52.837621  2459 net.cpp:406] Scale55 <- Convolution55
I0926 22:37:52.837625  2459 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0926 22:37:52.837653  2459 layer_factory.hpp:77] Creating layer Scale55
I0926 22:37:52.837735  2459 net.cpp:122] Setting up Scale55
I0926 22:37:52.837740  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.837743  2459 net.cpp:137] Memory required for data: 1166132400
I0926 22:37:52.837746  2459 layer_factory.hpp:77] Creating layer Eltwise26
I0926 22:37:52.837750  2459 net.cpp:84] Creating Layer Eltwise26
I0926 22:37:52.837754  2459 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0926 22:37:52.837756  2459 net.cpp:406] Eltwise26 <- Convolution55
I0926 22:37:52.837760  2459 net.cpp:380] Eltwise26 -> Eltwise26
I0926 22:37:52.837776  2459 net.cpp:122] Setting up Eltwise26
I0926 22:37:52.837780  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.837782  2459 net.cpp:137] Memory required for data: 1167770800
I0926 22:37:52.837785  2459 layer_factory.hpp:77] Creating layer penlu53
I0926 22:37:52.837790  2459 net.cpp:84] Creating Layer penlu53
I0926 22:37:52.837792  2459 net.cpp:406] penlu53 <- Eltwise26
I0926 22:37:52.837796  2459 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0926 22:37:52.837913  2459 net.cpp:122] Setting up penlu53
I0926 22:37:52.837918  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.837920  2459 net.cpp:137] Memory required for data: 1169409200
I0926 22:37:52.837924  2459 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0926 22:37:52.837929  2459 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0926 22:37:52.837930  2459 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0926 22:37:52.837934  2459 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0926 22:37:52.837939  2459 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0926 22:37:52.837962  2459 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0926 22:37:52.837966  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.837968  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.837970  2459 net.cpp:137] Memory required for data: 1172686000
I0926 22:37:52.837972  2459 layer_factory.hpp:77] Creating layer Convolution56
I0926 22:37:52.837980  2459 net.cpp:84] Creating Layer Convolution56
I0926 22:37:52.837988  2459 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0926 22:37:52.837992  2459 net.cpp:380] Convolution56 -> Convolution56
I0926 22:37:52.839682  2459 net.cpp:122] Setting up Convolution56
I0926 22:37:52.839690  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.839694  2459 net.cpp:137] Memory required for data: 1174324400
I0926 22:37:52.839697  2459 layer_factory.hpp:77] Creating layer BatchNorm56
I0926 22:37:52.839704  2459 net.cpp:84] Creating Layer BatchNorm56
I0926 22:37:52.839705  2459 net.cpp:406] BatchNorm56 <- Convolution56
I0926 22:37:52.839710  2459 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0926 22:37:52.839855  2459 net.cpp:122] Setting up BatchNorm56
I0926 22:37:52.839859  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.839862  2459 net.cpp:137] Memory required for data: 1175962800
I0926 22:37:52.839866  2459 layer_factory.hpp:77] Creating layer Scale56
I0926 22:37:52.839872  2459 net.cpp:84] Creating Layer Scale56
I0926 22:37:52.839875  2459 net.cpp:406] Scale56 <- Convolution56
I0926 22:37:52.839879  2459 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0926 22:37:52.839908  2459 layer_factory.hpp:77] Creating layer Scale56
I0926 22:37:52.839989  2459 net.cpp:122] Setting up Scale56
I0926 22:37:52.839994  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.839996  2459 net.cpp:137] Memory required for data: 1177601200
I0926 22:37:52.839999  2459 layer_factory.hpp:77] Creating layer penlu54
I0926 22:37:52.840005  2459 net.cpp:84] Creating Layer penlu54
I0926 22:37:52.840008  2459 net.cpp:406] penlu54 <- Convolution56
I0926 22:37:52.840013  2459 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0926 22:37:52.840133  2459 net.cpp:122] Setting up penlu54
I0926 22:37:52.840137  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.840139  2459 net.cpp:137] Memory required for data: 1179239600
I0926 22:37:52.840144  2459 layer_factory.hpp:77] Creating layer Convolution57
I0926 22:37:52.840150  2459 net.cpp:84] Creating Layer Convolution57
I0926 22:37:52.840153  2459 net.cpp:406] Convolution57 <- Convolution56
I0926 22:37:52.840157  2459 net.cpp:380] Convolution57 -> Convolution57
I0926 22:37:52.841856  2459 net.cpp:122] Setting up Convolution57
I0926 22:37:52.841864  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.841866  2459 net.cpp:137] Memory required for data: 1180878000
I0926 22:37:52.841871  2459 layer_factory.hpp:77] Creating layer BatchNorm57
I0926 22:37:52.841876  2459 net.cpp:84] Creating Layer BatchNorm57
I0926 22:37:52.841879  2459 net.cpp:406] BatchNorm57 <- Convolution57
I0926 22:37:52.841882  2459 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0926 22:37:52.858319  2459 net.cpp:122] Setting up BatchNorm57
I0926 22:37:52.858330  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.858331  2459 net.cpp:137] Memory required for data: 1182516400
I0926 22:37:52.858337  2459 layer_factory.hpp:77] Creating layer Scale57
I0926 22:37:52.858343  2459 net.cpp:84] Creating Layer Scale57
I0926 22:37:52.858347  2459 net.cpp:406] Scale57 <- Convolution57
I0926 22:37:52.858351  2459 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0926 22:37:52.858386  2459 layer_factory.hpp:77] Creating layer Scale57
I0926 22:37:52.858477  2459 net.cpp:122] Setting up Scale57
I0926 22:37:52.858482  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.858485  2459 net.cpp:137] Memory required for data: 1184154800
I0926 22:37:52.858489  2459 layer_factory.hpp:77] Creating layer Eltwise27
I0926 22:37:52.858494  2459 net.cpp:84] Creating Layer Eltwise27
I0926 22:37:52.858499  2459 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0926 22:37:52.858501  2459 net.cpp:406] Eltwise27 <- Convolution57
I0926 22:37:52.858505  2459 net.cpp:380] Eltwise27 -> Eltwise27
I0926 22:37:52.858525  2459 net.cpp:122] Setting up Eltwise27
I0926 22:37:52.858530  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.858531  2459 net.cpp:137] Memory required for data: 1185793200
I0926 22:37:52.858541  2459 layer_factory.hpp:77] Creating layer penlu55
I0926 22:37:52.858548  2459 net.cpp:84] Creating Layer penlu55
I0926 22:37:52.858551  2459 net.cpp:406] penlu55 <- Eltwise27
I0926 22:37:52.858556  2459 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0926 22:37:52.858691  2459 net.cpp:122] Setting up penlu55
I0926 22:37:52.858696  2459 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0926 22:37:52.858700  2459 net.cpp:137] Memory required for data: 1187431600
I0926 22:37:52.858705  2459 layer_factory.hpp:77] Creating layer Pooling1
I0926 22:37:52.858710  2459 net.cpp:84] Creating Layer Pooling1
I0926 22:37:52.858712  2459 net.cpp:406] Pooling1 <- Eltwise27
I0926 22:37:52.858716  2459 net.cpp:380] Pooling1 -> Pooling1
I0926 22:37:52.859251  2459 net.cpp:122] Setting up Pooling1
I0926 22:37:52.859261  2459 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0926 22:37:52.859263  2459 net.cpp:137] Memory required for data: 1187457200
I0926 22:37:52.859266  2459 layer_factory.hpp:77] Creating layer InnerProduct1
I0926 22:37:52.859272  2459 net.cpp:84] Creating Layer InnerProduct1
I0926 22:37:52.859275  2459 net.cpp:406] InnerProduct1 <- Pooling1
I0926 22:37:52.859280  2459 net.cpp:380] InnerProduct1 -> InnerProduct1
I0926 22:37:52.859439  2459 net.cpp:122] Setting up InnerProduct1
I0926 22:37:52.859444  2459 net.cpp:129] Top shape: 100 10 (1000)
I0926 22:37:52.859447  2459 net.cpp:137] Memory required for data: 1187461200
I0926 22:37:52.859450  2459 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0926 22:37:52.859455  2459 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0926 22:37:52.859458  2459 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0926 22:37:52.859462  2459 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0926 22:37:52.859467  2459 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0926 22:37:52.859494  2459 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0926 22:37:52.859498  2459 net.cpp:129] Top shape: 100 10 (1000)
I0926 22:37:52.859500  2459 net.cpp:129] Top shape: 100 10 (1000)
I0926 22:37:52.859503  2459 net.cpp:137] Memory required for data: 1187469200
I0926 22:37:52.859504  2459 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 22:37:52.859509  2459 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0926 22:37:52.859511  2459 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0926 22:37:52.859514  2459 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0926 22:37:52.859519  2459 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0926 22:37:52.859524  2459 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0926 22:37:52.859762  2459 net.cpp:122] Setting up SoftmaxWithLoss1
I0926 22:37:52.859769  2459 net.cpp:129] Top shape: (1)
I0926 22:37:52.859771  2459 net.cpp:132]     with loss weight 1
I0926 22:37:52.859778  2459 net.cpp:137] Memory required for data: 1187469204
I0926 22:37:52.859781  2459 layer_factory.hpp:77] Creating layer Accuracy1
I0926 22:37:52.859799  2459 net.cpp:84] Creating Layer Accuracy1
I0926 22:37:52.859802  2459 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0926 22:37:52.859807  2459 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0926 22:37:52.859812  2459 net.cpp:380] Accuracy1 -> Accuracy1
I0926 22:37:52.859817  2459 net.cpp:122] Setting up Accuracy1
I0926 22:37:52.859830  2459 net.cpp:129] Top shape: (1)
I0926 22:37:52.859833  2459 net.cpp:137] Memory required for data: 1187469208
I0926 22:37:52.859835  2459 net.cpp:200] Accuracy1 does not need backward computation.
I0926 22:37:52.859838  2459 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0926 22:37:52.859840  2459 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0926 22:37:52.859843  2459 net.cpp:198] InnerProduct1 needs backward computation.
I0926 22:37:52.859845  2459 net.cpp:198] Pooling1 needs backward computation.
I0926 22:37:52.859858  2459 net.cpp:198] penlu55 needs backward computation.
I0926 22:37:52.859879  2459 net.cpp:198] Eltwise27 needs backward computation.
I0926 22:37:52.859881  2459 net.cpp:198] Scale57 needs backward computation.
I0926 22:37:52.859884  2459 net.cpp:198] BatchNorm57 needs backward computation.
I0926 22:37:52.859885  2459 net.cpp:198] Convolution57 needs backward computation.
I0926 22:37:52.859897  2459 net.cpp:198] penlu54 needs backward computation.
I0926 22:37:52.859899  2459 net.cpp:198] Scale56 needs backward computation.
I0926 22:37:52.859901  2459 net.cpp:198] BatchNorm56 needs backward computation.
I0926 22:37:52.859904  2459 net.cpp:198] Convolution56 needs backward computation.
I0926 22:37:52.859905  2459 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0926 22:37:52.859908  2459 net.cpp:198] penlu53 needs backward computation.
I0926 22:37:52.859920  2459 net.cpp:198] Eltwise26 needs backward computation.
I0926 22:37:52.859922  2459 net.cpp:198] Scale55 needs backward computation.
I0926 22:37:52.859925  2459 net.cpp:198] BatchNorm55 needs backward computation.
I0926 22:37:52.859927  2459 net.cpp:198] Convolution55 needs backward computation.
I0926 22:37:52.859930  2459 net.cpp:198] penlu52 needs backward computation.
I0926 22:37:52.859931  2459 net.cpp:198] Scale54 needs backward computation.
I0926 22:37:52.859933  2459 net.cpp:198] BatchNorm54 needs backward computation.
I0926 22:37:52.859935  2459 net.cpp:198] Convolution54 needs backward computation.
I0926 22:37:52.859938  2459 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0926 22:37:52.859941  2459 net.cpp:198] penlu51 needs backward computation.
I0926 22:37:52.859942  2459 net.cpp:198] Eltwise25 needs backward computation.
I0926 22:37:52.859946  2459 net.cpp:198] Scale53 needs backward computation.
I0926 22:37:52.859947  2459 net.cpp:198] BatchNorm53 needs backward computation.
I0926 22:37:52.859949  2459 net.cpp:198] Convolution53 needs backward computation.
I0926 22:37:52.859951  2459 net.cpp:198] penlu50 needs backward computation.
I0926 22:37:52.859953  2459 net.cpp:198] Scale52 needs backward computation.
I0926 22:37:52.859956  2459 net.cpp:198] BatchNorm52 needs backward computation.
I0926 22:37:52.859958  2459 net.cpp:198] Convolution52 needs backward computation.
I0926 22:37:52.859961  2459 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0926 22:37:52.859963  2459 net.cpp:198] penlu49 needs backward computation.
I0926 22:37:52.859966  2459 net.cpp:198] Eltwise24 needs backward computation.
I0926 22:37:52.859968  2459 net.cpp:198] Scale51 needs backward computation.
I0926 22:37:52.860529  2459 net.cpp:198] BatchNorm51 needs backward computation.
I0926 22:37:52.860538  2459 net.cpp:198] Convolution51 needs backward computation.
I0926 22:37:52.860540  2459 net.cpp:198] penlu48 needs backward computation.
I0926 22:37:52.860543  2459 net.cpp:198] Scale50 needs backward computation.
I0926 22:37:52.860545  2459 net.cpp:198] BatchNorm50 needs backward computation.
I0926 22:37:52.860548  2459 net.cpp:198] Convolution50 needs backward computation.
I0926 22:37:52.860550  2459 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0926 22:37:52.860553  2459 net.cpp:198] penlu47 needs backward computation.
I0926 22:37:52.860556  2459 net.cpp:198] Eltwise23 needs backward computation.
I0926 22:37:52.860559  2459 net.cpp:198] Scale49 needs backward computation.
I0926 22:37:52.860561  2459 net.cpp:198] BatchNorm49 needs backward computation.
I0926 22:37:52.860564  2459 net.cpp:198] Convolution49 needs backward computation.
I0926 22:37:52.860566  2459 net.cpp:198] penlu46 needs backward computation.
I0926 22:37:52.860569  2459 net.cpp:198] Scale48 needs backward computation.
I0926 22:37:52.860571  2459 net.cpp:198] BatchNorm48 needs backward computation.
I0926 22:37:52.860574  2459 net.cpp:198] Convolution48 needs backward computation.
I0926 22:37:52.860576  2459 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0926 22:37:52.860579  2459 net.cpp:198] penlu45 needs backward computation.
I0926 22:37:52.860589  2459 net.cpp:198] Eltwise22 needs backward computation.
I0926 22:37:52.860592  2459 net.cpp:198] Scale47 needs backward computation.
I0926 22:37:52.860595  2459 net.cpp:198] BatchNorm47 needs backward computation.
I0926 22:37:52.860597  2459 net.cpp:198] Convolution47 needs backward computation.
I0926 22:37:52.860600  2459 net.cpp:198] penlu44 needs backward computation.
I0926 22:37:52.860602  2459 net.cpp:198] Scale46 needs backward computation.
I0926 22:37:52.860605  2459 net.cpp:198] BatchNorm46 needs backward computation.
I0926 22:37:52.860607  2459 net.cpp:198] Convolution46 needs backward computation.
I0926 22:37:52.860610  2459 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0926 22:37:52.860612  2459 net.cpp:198] penlu43 needs backward computation.
I0926 22:37:52.860615  2459 net.cpp:198] Eltwise21 needs backward computation.
I0926 22:37:52.860617  2459 net.cpp:198] Scale45 needs backward computation.
I0926 22:37:52.860620  2459 net.cpp:198] BatchNorm45 needs backward computation.
I0926 22:37:52.860622  2459 net.cpp:198] Convolution45 needs backward computation.
I0926 22:37:52.860625  2459 net.cpp:198] penlu42 needs backward computation.
I0926 22:37:52.860627  2459 net.cpp:198] Scale44 needs backward computation.
I0926 22:37:52.860630  2459 net.cpp:198] BatchNorm44 needs backward computation.
I0926 22:37:52.860631  2459 net.cpp:198] Convolution44 needs backward computation.
I0926 22:37:52.860635  2459 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0926 22:37:52.860637  2459 net.cpp:198] penlu41 needs backward computation.
I0926 22:37:52.860640  2459 net.cpp:198] Eltwise20 needs backward computation.
I0926 22:37:52.860643  2459 net.cpp:198] Scale43 needs backward computation.
I0926 22:37:52.860646  2459 net.cpp:198] BatchNorm43 needs backward computation.
I0926 22:37:52.860647  2459 net.cpp:198] Convolution43 needs backward computation.
I0926 22:37:52.860651  2459 net.cpp:198] penlu40 needs backward computation.
I0926 22:37:52.860652  2459 net.cpp:198] Scale42 needs backward computation.
I0926 22:37:52.860656  2459 net.cpp:198] BatchNorm42 needs backward computation.
I0926 22:37:52.860657  2459 net.cpp:198] Convolution42 needs backward computation.
I0926 22:37:52.860661  2459 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0926 22:37:52.860663  2459 net.cpp:198] penlu39 needs backward computation.
I0926 22:37:52.860666  2459 net.cpp:198] Eltwise19 needs backward computation.
I0926 22:37:52.860668  2459 net.cpp:198] Scale41 needs backward computation.
I0926 22:37:52.860671  2459 net.cpp:198] BatchNorm41 needs backward computation.
I0926 22:37:52.860674  2459 net.cpp:198] Convolution41 needs backward computation.
I0926 22:37:52.860677  2459 net.cpp:198] penlu38 needs backward computation.
I0926 22:37:52.860679  2459 net.cpp:198] Scale40 needs backward computation.
I0926 22:37:52.860682  2459 net.cpp:198] BatchNorm40 needs backward computation.
I0926 22:37:52.860684  2459 net.cpp:198] Convolution40 needs backward computation.
I0926 22:37:52.860688  2459 net.cpp:198] Scale39 needs backward computation.
I0926 22:37:52.860690  2459 net.cpp:198] BatchNorm39 needs backward computation.
I0926 22:37:52.860693  2459 net.cpp:198] Convolution39 needs backward computation.
I0926 22:37:52.860697  2459 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0926 22:37:52.860698  2459 net.cpp:198] penlu37 needs backward computation.
I0926 22:37:52.860702  2459 net.cpp:198] Eltwise18 needs backward computation.
I0926 22:37:52.860704  2459 net.cpp:198] Scale38 needs backward computation.
I0926 22:37:52.860707  2459 net.cpp:198] BatchNorm38 needs backward computation.
I0926 22:37:52.860708  2459 net.cpp:198] Convolution38 needs backward computation.
I0926 22:37:52.860711  2459 net.cpp:198] penlu36 needs backward computation.
I0926 22:37:52.860714  2459 net.cpp:198] Scale37 needs backward computation.
I0926 22:37:52.860716  2459 net.cpp:198] BatchNorm37 needs backward computation.
I0926 22:37:52.860718  2459 net.cpp:198] Convolution37 needs backward computation.
I0926 22:37:52.860725  2459 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0926 22:37:52.860728  2459 net.cpp:198] penlu35 needs backward computation.
I0926 22:37:52.860731  2459 net.cpp:198] Eltwise17 needs backward computation.
I0926 22:37:52.860734  2459 net.cpp:198] Scale36 needs backward computation.
I0926 22:37:52.860736  2459 net.cpp:198] BatchNorm36 needs backward computation.
I0926 22:37:52.860738  2459 net.cpp:198] Convolution36 needs backward computation.
I0926 22:37:52.860741  2459 net.cpp:198] penlu34 needs backward computation.
I0926 22:37:52.860743  2459 net.cpp:198] Scale35 needs backward computation.
I0926 22:37:52.860746  2459 net.cpp:198] BatchNorm35 needs backward computation.
I0926 22:37:52.860749  2459 net.cpp:198] Convolution35 needs backward computation.
I0926 22:37:52.860751  2459 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0926 22:37:52.860754  2459 net.cpp:198] penlu33 needs backward computation.
I0926 22:37:52.860755  2459 net.cpp:198] Eltwise16 needs backward computation.
I0926 22:37:52.860759  2459 net.cpp:198] Scale34 needs backward computation.
I0926 22:37:52.860761  2459 net.cpp:198] BatchNorm34 needs backward computation.
I0926 22:37:52.860764  2459 net.cpp:198] Convolution34 needs backward computation.
I0926 22:37:52.860766  2459 net.cpp:198] penlu32 needs backward computation.
I0926 22:37:52.860769  2459 net.cpp:198] Scale33 needs backward computation.
I0926 22:37:52.860771  2459 net.cpp:198] BatchNorm33 needs backward computation.
I0926 22:37:52.860774  2459 net.cpp:198] Convolution33 needs backward computation.
I0926 22:37:52.860775  2459 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0926 22:37:52.860779  2459 net.cpp:198] penlu31 needs backward computation.
I0926 22:37:52.860781  2459 net.cpp:198] Eltwise15 needs backward computation.
I0926 22:37:52.860785  2459 net.cpp:198] Scale32 needs backward computation.
I0926 22:37:52.860786  2459 net.cpp:198] BatchNorm32 needs backward computation.
I0926 22:37:52.860788  2459 net.cpp:198] Convolution32 needs backward computation.
I0926 22:37:52.860791  2459 net.cpp:198] penlu30 needs backward computation.
I0926 22:37:52.860793  2459 net.cpp:198] Scale31 needs backward computation.
I0926 22:37:52.860796  2459 net.cpp:198] BatchNorm31 needs backward computation.
I0926 22:37:52.860798  2459 net.cpp:198] Convolution31 needs backward computation.
I0926 22:37:52.860801  2459 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0926 22:37:52.889001  2459 net.cpp:198] penlu29 needs backward computation.
I0926 22:37:52.889009  2459 net.cpp:198] Eltwise14 needs backward computation.
I0926 22:37:52.889014  2459 net.cpp:198] Scale30 needs backward computation.
I0926 22:37:52.889016  2459 net.cpp:198] BatchNorm30 needs backward computation.
I0926 22:37:52.889019  2459 net.cpp:198] Convolution30 needs backward computation.
I0926 22:37:52.889021  2459 net.cpp:198] penlu28 needs backward computation.
I0926 22:37:52.889024  2459 net.cpp:198] Scale29 needs backward computation.
I0926 22:37:52.889026  2459 net.cpp:198] BatchNorm29 needs backward computation.
I0926 22:37:52.889029  2459 net.cpp:198] Convolution29 needs backward computation.
I0926 22:37:52.889032  2459 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0926 22:37:52.889034  2459 net.cpp:198] penlu27 needs backward computation.
I0926 22:37:52.889037  2459 net.cpp:198] Eltwise13 needs backward computation.
I0926 22:37:52.889040  2459 net.cpp:198] Scale28 needs backward computation.
I0926 22:37:52.889042  2459 net.cpp:198] BatchNorm28 needs backward computation.
I0926 22:37:52.889045  2459 net.cpp:198] Convolution28 needs backward computation.
I0926 22:37:52.889048  2459 net.cpp:198] penlu26 needs backward computation.
I0926 22:37:52.889050  2459 net.cpp:198] Scale27 needs backward computation.
I0926 22:37:52.889052  2459 net.cpp:198] BatchNorm27 needs backward computation.
I0926 22:37:52.889055  2459 net.cpp:198] Convolution27 needs backward computation.
I0926 22:37:52.889058  2459 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0926 22:37:52.889068  2459 net.cpp:198] penlu25 needs backward computation.
I0926 22:37:52.889071  2459 net.cpp:198] Eltwise12 needs backward computation.
I0926 22:37:52.889075  2459 net.cpp:198] Scale26 needs backward computation.
I0926 22:37:52.889080  2459 net.cpp:198] BatchNorm26 needs backward computation.
I0926 22:37:52.889082  2459 net.cpp:198] Convolution26 needs backward computation.
I0926 22:37:52.889084  2459 net.cpp:198] penlu24 needs backward computation.
I0926 22:37:52.889087  2459 net.cpp:198] Scale25 needs backward computation.
I0926 22:37:52.889089  2459 net.cpp:198] BatchNorm25 needs backward computation.
I0926 22:37:52.889092  2459 net.cpp:198] Convolution25 needs backward computation.
I0926 22:37:52.889094  2459 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0926 22:37:52.889097  2459 net.cpp:198] penlu23 needs backward computation.
I0926 22:37:52.889099  2459 net.cpp:198] Eltwise11 needs backward computation.
I0926 22:37:52.889102  2459 net.cpp:198] Scale24 needs backward computation.
I0926 22:37:52.889106  2459 net.cpp:198] BatchNorm24 needs backward computation.
I0926 22:37:52.889107  2459 net.cpp:198] Convolution24 needs backward computation.
I0926 22:37:52.889111  2459 net.cpp:198] penlu22 needs backward computation.
I0926 22:37:52.889112  2459 net.cpp:198] Scale23 needs backward computation.
I0926 22:37:52.889114  2459 net.cpp:198] BatchNorm23 needs backward computation.
I0926 22:37:52.889117  2459 net.cpp:198] Convolution23 needs backward computation.
I0926 22:37:52.889120  2459 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0926 22:37:52.889123  2459 net.cpp:198] penlu21 needs backward computation.
I0926 22:37:52.889125  2459 net.cpp:198] Eltwise10 needs backward computation.
I0926 22:37:52.889128  2459 net.cpp:198] Scale22 needs backward computation.
I0926 22:37:52.889130  2459 net.cpp:198] BatchNorm22 needs backward computation.
I0926 22:37:52.889133  2459 net.cpp:198] Convolution22 needs backward computation.
I0926 22:37:52.889135  2459 net.cpp:198] penlu20 needs backward computation.
I0926 22:37:52.889138  2459 net.cpp:198] Scale21 needs backward computation.
I0926 22:37:52.889140  2459 net.cpp:198] BatchNorm21 needs backward computation.
I0926 22:37:52.889143  2459 net.cpp:198] Convolution21 needs backward computation.
I0926 22:37:52.889147  2459 net.cpp:198] Scale20 needs backward computation.
I0926 22:37:52.889148  2459 net.cpp:198] BatchNorm20 needs backward computation.
I0926 22:37:52.889152  2459 net.cpp:198] Convolution20 needs backward computation.
I0926 22:37:52.889153  2459 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0926 22:37:52.889156  2459 net.cpp:198] penlu19 needs backward computation.
I0926 22:37:52.889159  2459 net.cpp:198] Eltwise9 needs backward computation.
I0926 22:37:52.889163  2459 net.cpp:198] Scale19 needs backward computation.
I0926 22:37:52.889164  2459 net.cpp:198] BatchNorm19 needs backward computation.
I0926 22:37:52.889168  2459 net.cpp:198] Convolution19 needs backward computation.
I0926 22:37:52.889169  2459 net.cpp:198] penlu18 needs backward computation.
I0926 22:37:52.889173  2459 net.cpp:198] Scale18 needs backward computation.
I0926 22:37:52.889174  2459 net.cpp:198] BatchNorm18 needs backward computation.
I0926 22:37:52.889176  2459 net.cpp:198] Convolution18 needs backward computation.
I0926 22:37:52.889179  2459 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0926 22:37:52.889183  2459 net.cpp:198] penlu17 needs backward computation.
I0926 22:37:52.889184  2459 net.cpp:198] Eltwise8 needs backward computation.
I0926 22:37:52.889187  2459 net.cpp:198] Scale17 needs backward computation.
I0926 22:37:52.889190  2459 net.cpp:198] BatchNorm17 needs backward computation.
I0926 22:37:52.889192  2459 net.cpp:198] Convolution17 needs backward computation.
I0926 22:37:52.889195  2459 net.cpp:198] penlu16 needs backward computation.
I0926 22:37:52.889197  2459 net.cpp:198] Scale16 needs backward computation.
I0926 22:37:52.889204  2459 net.cpp:198] BatchNorm16 needs backward computation.
I0926 22:37:52.889206  2459 net.cpp:198] Convolution16 needs backward computation.
I0926 22:37:52.889209  2459 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0926 22:37:52.889211  2459 net.cpp:198] penlu15 needs backward computation.
I0926 22:37:52.889214  2459 net.cpp:198] Eltwise7 needs backward computation.
I0926 22:37:52.889216  2459 net.cpp:198] Scale15 needs backward computation.
I0926 22:37:52.889219  2459 net.cpp:198] BatchNorm15 needs backward computation.
I0926 22:37:52.889221  2459 net.cpp:198] Convolution15 needs backward computation.
I0926 22:37:52.889225  2459 net.cpp:198] penlu14 needs backward computation.
I0926 22:37:52.889226  2459 net.cpp:198] Scale14 needs backward computation.
I0926 22:37:52.889228  2459 net.cpp:198] BatchNorm14 needs backward computation.
I0926 22:37:52.889231  2459 net.cpp:198] Convolution14 needs backward computation.
I0926 22:37:52.889233  2459 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0926 22:37:52.889236  2459 net.cpp:198] penlu13 needs backward computation.
I0926 22:37:52.889238  2459 net.cpp:198] Eltwise6 needs backward computation.
I0926 22:37:52.889241  2459 net.cpp:198] Scale13 needs backward computation.
I0926 22:37:52.889245  2459 net.cpp:198] BatchNorm13 needs backward computation.
I0926 22:37:52.889246  2459 net.cpp:198] Convolution13 needs backward computation.
I0926 22:37:52.889250  2459 net.cpp:198] penlu12 needs backward computation.
I0926 22:37:52.889251  2459 net.cpp:198] Scale12 needs backward computation.
I0926 22:37:52.889253  2459 net.cpp:198] BatchNorm12 needs backward computation.
I0926 22:37:52.889256  2459 net.cpp:198] Convolution12 needs backward computation.
I0926 22:37:52.889258  2459 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0926 22:37:52.889261  2459 net.cpp:198] penlu11 needs backward computation.
I0926 22:37:52.889264  2459 net.cpp:198] Eltwise5 needs backward computation.
I0926 22:37:52.889267  2459 net.cpp:198] Scale11 needs backward computation.
I0926 22:37:52.889269  2459 net.cpp:198] BatchNorm11 needs backward computation.
I0926 22:37:52.889271  2459 net.cpp:198] Convolution11 needs backward computation.
I0926 22:37:52.889274  2459 net.cpp:198] penlu10 needs backward computation.
I0926 22:37:52.889277  2459 net.cpp:198] Scale10 needs backward computation.
I0926 22:37:52.891301  2459 net.cpp:198] BatchNorm10 needs backward computation.
I0926 22:37:52.891309  2459 net.cpp:198] Convolution10 needs backward computation.
I0926 22:37:52.891311  2459 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0926 22:37:52.891314  2459 net.cpp:198] penlu9 needs backward computation.
I0926 22:37:52.891317  2459 net.cpp:198] Eltwise4 needs backward computation.
I0926 22:37:52.891320  2459 net.cpp:198] Scale9 needs backward computation.
I0926 22:37:52.891324  2459 net.cpp:198] BatchNorm9 needs backward computation.
I0926 22:37:52.891325  2459 net.cpp:198] Convolution9 needs backward computation.
I0926 22:37:52.891329  2459 net.cpp:198] penlu8 needs backward computation.
I0926 22:37:52.891330  2459 net.cpp:198] Scale8 needs backward computation.
I0926 22:37:52.891333  2459 net.cpp:198] BatchNorm8 needs backward computation.
I0926 22:37:52.891335  2459 net.cpp:198] Convolution8 needs backward computation.
I0926 22:37:52.891338  2459 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0926 22:37:52.891340  2459 net.cpp:198] penlu7 needs backward computation.
I0926 22:37:52.891343  2459 net.cpp:198] Eltwise3 needs backward computation.
I0926 22:37:52.891346  2459 net.cpp:198] Scale7 needs backward computation.
I0926 22:37:52.891348  2459 net.cpp:198] BatchNorm7 needs backward computation.
I0926 22:37:52.891351  2459 net.cpp:198] Convolution7 needs backward computation.
I0926 22:37:52.891353  2459 net.cpp:198] penlu6 needs backward computation.
I0926 22:37:52.891355  2459 net.cpp:198] Scale6 needs backward computation.
I0926 22:37:52.891358  2459 net.cpp:198] BatchNorm6 needs backward computation.
I0926 22:37:52.891366  2459 net.cpp:198] Convolution6 needs backward computation.
I0926 22:37:52.891379  2459 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0926 22:37:52.891382  2459 net.cpp:198] penlu5 needs backward computation.
I0926 22:37:52.891384  2459 net.cpp:198] Eltwise2 needs backward computation.
I0926 22:37:52.891388  2459 net.cpp:198] Scale5 needs backward computation.
I0926 22:37:52.891391  2459 net.cpp:198] BatchNorm5 needs backward computation.
I0926 22:37:52.891393  2459 net.cpp:198] Convolution5 needs backward computation.
I0926 22:37:52.891396  2459 net.cpp:198] penlu4 needs backward computation.
I0926 22:37:52.891398  2459 net.cpp:198] Scale4 needs backward computation.
I0926 22:37:52.891400  2459 net.cpp:198] BatchNorm4 needs backward computation.
I0926 22:37:52.891402  2459 net.cpp:198] Convolution4 needs backward computation.
I0926 22:37:52.891404  2459 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0926 22:37:52.891407  2459 net.cpp:198] penlu3 needs backward computation.
I0926 22:37:52.891409  2459 net.cpp:198] Eltwise1 needs backward computation.
I0926 22:37:52.891412  2459 net.cpp:198] Scale3 needs backward computation.
I0926 22:37:52.891414  2459 net.cpp:198] BatchNorm3 needs backward computation.
I0926 22:37:52.891417  2459 net.cpp:198] Convolution3 needs backward computation.
I0926 22:37:52.891419  2459 net.cpp:198] penlu2 needs backward computation.
I0926 22:37:52.891422  2459 net.cpp:198] Scale2 needs backward computation.
I0926 22:37:52.891423  2459 net.cpp:198] BatchNorm2 needs backward computation.
I0926 22:37:52.891425  2459 net.cpp:198] Convolution2 needs backward computation.
I0926 22:37:52.891428  2459 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0926 22:37:52.891432  2459 net.cpp:198] penlu1 needs backward computation.
I0926 22:37:52.891433  2459 net.cpp:198] Scale1 needs backward computation.
I0926 22:37:52.891435  2459 net.cpp:198] BatchNorm1 needs backward computation.
I0926 22:37:52.891438  2459 net.cpp:198] Convolution1 needs backward computation.
I0926 22:37:52.891440  2459 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0926 22:37:52.891443  2459 net.cpp:200] Data1 does not need backward computation.
I0926 22:37:52.891445  2459 net.cpp:242] This network produces output Accuracy1
I0926 22:37:52.891448  2459 net.cpp:242] This network produces output SoftmaxWithLoss1
I0926 22:37:52.891561  2459 net.cpp:255] Network initialization done.
I0926 22:37:52.892604  2459 solver.cpp:56] Solver scaffolding done.
I0926 22:37:52.906867  2459 caffe.cpp:248] Starting Optimization
I0926 22:37:52.906873  2459 solver.cpp:272] Solving resnet_cifar10
I0926 22:37:52.906875  2459 solver.cpp:273] Learning Rate Policy: multistep
I0926 22:37:52.913637  2459 solver.cpp:330] Iteration 0, Testing net (#0)
I0926 22:37:53.315409  2459 blocking_queue.cpp:49] Waiting for data
I0926 22:37:57.546519  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:37:57.685580  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0926 22:37:57.685616  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0926 22:37:57.886639  2459 solver.cpp:218] Iteration 0 (-2.03297e-36 iter/s, 4.97965s/100 iters), loss = 2.30861
I0926 22:37:57.886670  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30861 (* 1 = 2.30861 loss)
I0926 22:37:57.886687  2459 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0926 22:38:12.411684  2459 solver.cpp:218] Iteration 100 (6.88474 iter/s, 14.5249s/100 iters), loss = 1.55377
I0926 22:38:12.411722  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55377 (* 1 = 1.55377 loss)
I0926 22:38:12.411729  2459 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0926 22:38:26.920367  2459 solver.cpp:218] Iteration 200 (6.89251 iter/s, 14.5085s/100 iters), loss = 1.43799
I0926 22:38:26.920523  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.43799 (* 1 = 1.43799 loss)
I0926 22:38:26.920531  2459 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0926 22:38:41.431732  2459 solver.cpp:218] Iteration 300 (6.89129 iter/s, 14.5111s/100 iters), loss = 1.31344
I0926 22:38:41.431772  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31344 (* 1 = 1.31344 loss)
I0926 22:38:41.431778  2459 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0926 22:38:55.942103  2459 solver.cpp:218] Iteration 400 (6.89171 iter/s, 14.5102s/100 iters), loss = 1.04833
I0926 22:38:55.942143  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04833 (* 1 = 1.04833 loss)
I0926 22:38:55.942149  2459 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0926 22:39:09.751525  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:39:10.332073  2459 solver.cpp:330] Iteration 500, Testing net (#0)
I0926 22:39:13.740263  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:39:13.882391  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.404
I0926 22:39:13.882427  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.48868 (* 1 = 2.48868 loss)
I0926 22:39:14.027199  2459 solver.cpp:218] Iteration 500 (5.52948 iter/s, 18.0849s/100 iters), loss = 1.14642
I0926 22:39:14.027227  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14642 (* 1 = 1.14642 loss)
I0926 22:39:14.027233  2459 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0926 22:39:28.559783  2459 solver.cpp:218] Iteration 600 (6.88117 iter/s, 14.5324s/100 iters), loss = 1.16431
I0926 22:39:28.559823  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16431 (* 1 = 1.16431 loss)
I0926 22:39:28.559828  2459 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0926 22:39:43.097419  2459 solver.cpp:218] Iteration 700 (6.87878 iter/s, 14.5375s/100 iters), loss = 0.978211
I0926 22:39:43.097522  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.978211 (* 1 = 0.978211 loss)
I0926 22:39:43.097529  2459 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0926 22:39:57.637606  2459 solver.cpp:218] Iteration 800 (6.8776 iter/s, 14.54s/100 iters), loss = 0.998166
I0926 22:39:57.637647  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.998166 (* 1 = 0.998166 loss)
I0926 22:39:57.637653  2459 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0926 22:40:12.174473  2459 solver.cpp:218] Iteration 900 (6.87914 iter/s, 14.5367s/100 iters), loss = 0.792457
I0926 22:40:12.174513  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.792457 (* 1 = 0.792457 loss)
I0926 22:40:12.174520  2459 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0926 22:40:25.994917  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:40:26.577692  2459 solver.cpp:330] Iteration 1000, Testing net (#0)
I0926 22:40:29.987592  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:40:30.129920  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4863
I0926 22:40:30.129956  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.84327 (* 1 = 1.84327 loss)
I0926 22:40:30.274871  2459 solver.cpp:218] Iteration 1000 (5.5248 iter/s, 18.1002s/100 iters), loss = 0.956672
I0926 22:40:30.274899  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.956672 (* 1 = 0.956672 loss)
I0926 22:40:30.274906  2459 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0926 22:40:44.821017  2459 solver.cpp:218] Iteration 1100 (6.87474 iter/s, 14.546s/100 iters), loss = 0.796529
I0926 22:40:44.821058  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.796529 (* 1 = 0.796529 loss)
I0926 22:40:44.821064  2459 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0926 22:40:59.370038  2459 solver.cpp:218] Iteration 1200 (6.87339 iter/s, 14.5489s/100 iters), loss = 0.927749
I0926 22:40:59.370115  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.927749 (* 1 = 0.927749 loss)
I0926 22:40:59.370121  2459 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0926 22:41:13.923766  2459 solver.cpp:218] Iteration 1300 (6.87118 iter/s, 14.5535s/100 iters), loss = 0.982509
I0926 22:41:13.923808  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.982509 (* 1 = 0.982509 loss)
I0926 22:41:13.923815  2459 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0926 22:41:28.477409  2459 solver.cpp:218] Iteration 1400 (6.8712 iter/s, 14.5535s/100 iters), loss = 0.794795
I0926 22:41:28.477449  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.794795 (* 1 = 0.794795 loss)
I0926 22:41:28.477455  2459 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0926 22:41:42.307358  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:41:42.889187  2459 solver.cpp:330] Iteration 1500, Testing net (#0)
I0926 22:41:46.300364  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:41:46.442308  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6574
I0926 22:41:46.442345  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02911 (* 1 = 1.02911 loss)
I0926 22:41:46.586436  2459 solver.cpp:218] Iteration 1500 (5.52216 iter/s, 18.1089s/100 iters), loss = 1.01864
I0926 22:41:46.586462  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01864 (* 1 = 1.01864 loss)
I0926 22:41:46.586469  2459 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0926 22:42:01.141348  2459 solver.cpp:218] Iteration 1600 (6.87059 iter/s, 14.5548s/100 iters), loss = 0.690387
I0926 22:42:01.141389  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.690387 (* 1 = 0.690387 loss)
I0926 22:42:01.141396  2459 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0926 22:42:15.701787  2459 solver.cpp:218] Iteration 1700 (6.86798 iter/s, 14.5603s/100 iters), loss = 0.76143
I0926 22:42:15.701889  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.76143 (* 1 = 0.76143 loss)
I0926 22:42:15.701895  2459 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0926 22:42:30.256127  2459 solver.cpp:218] Iteration 1800 (6.87088 iter/s, 14.5542s/100 iters), loss = 0.905969
I0926 22:42:30.256170  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.905969 (* 1 = 0.905969 loss)
I0926 22:42:30.256175  2459 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0926 22:42:44.805754  2459 solver.cpp:218] Iteration 1900 (6.87308 iter/s, 14.5495s/100 iters), loss = 0.701784
I0926 22:42:44.805784  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.701784 (* 1 = 0.701784 loss)
I0926 22:42:44.805789  2459 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0926 22:42:58.637183  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:42:59.219318  2459 solver.cpp:330] Iteration 2000, Testing net (#0)
I0926 22:43:02.632423  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:43:02.774780  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5756
I0926 22:43:02.774816  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36066 (* 1 = 1.36066 loss)
I0926 22:43:02.918937  2459 solver.cpp:218] Iteration 2000 (5.52087 iter/s, 18.1131s/100 iters), loss = 0.782387
I0926 22:43:02.918964  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.782387 (* 1 = 0.782387 loss)
I0926 22:43:02.918972  2459 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0926 22:43:17.475983  2459 solver.cpp:218] Iteration 2100 (6.86957 iter/s, 14.557s/100 iters), loss = 0.654274
I0926 22:43:17.476025  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.654274 (* 1 = 0.654274 loss)
I0926 22:43:17.476032  2459 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0926 22:43:32.030859  2459 solver.cpp:218] Iteration 2200 (6.8706 iter/s, 14.5548s/100 iters), loss = 0.68198
I0926 22:43:32.030980  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.68198 (* 1 = 0.68198 loss)
I0926 22:43:32.030997  2459 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0926 22:43:46.591542  2459 solver.cpp:218] Iteration 2300 (6.86789 iter/s, 14.5605s/100 iters), loss = 0.792727
I0926 22:43:46.591584  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.792727 (* 1 = 0.792727 loss)
I0926 22:43:46.591590  2459 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0926 22:44:01.151680  2459 solver.cpp:218] Iteration 2400 (6.86811 iter/s, 14.56s/100 iters), loss = 0.61356
I0926 22:44:01.151722  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61356 (* 1 = 0.61356 loss)
I0926 22:44:01.151728  2459 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0926 22:44:14.989840  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:44:15.571929  2459 solver.cpp:330] Iteration 2500, Testing net (#0)
I0926 22:44:18.984889  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:44:19.127100  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6835
I0926 22:44:19.127135  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.969998 (* 1 = 0.969998 loss)
I0926 22:44:19.271487  2459 solver.cpp:218] Iteration 2500 (5.51886 iter/s, 18.1197s/100 iters), loss = 0.656301
I0926 22:44:19.271514  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.656301 (* 1 = 0.656301 loss)
I0926 22:44:19.271520  2459 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0926 22:44:33.828027  2459 solver.cpp:218] Iteration 2600 (6.86981 iter/s, 14.5565s/100 iters), loss = 0.674071
I0926 22:44:33.828058  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.674071 (* 1 = 0.674071 loss)
I0926 22:44:33.828063  2459 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0926 22:44:48.391990  2459 solver.cpp:218] Iteration 2700 (6.8663 iter/s, 14.5639s/100 iters), loss = 0.601972
I0926 22:44:48.392060  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601972 (* 1 = 0.601972 loss)
I0926 22:44:48.392066  2459 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0926 22:45:02.949579  2459 solver.cpp:218] Iteration 2800 (6.86933 iter/s, 14.5575s/100 iters), loss = 0.797187
I0926 22:45:02.949620  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.797187 (* 1 = 0.797187 loss)
I0926 22:45:02.949625  2459 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0926 22:45:17.514816  2459 solver.cpp:218] Iteration 2900 (6.86571 iter/s, 14.5651s/100 iters), loss = 0.630538
I0926 22:45:17.514855  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.630538 (* 1 = 0.630538 loss)
I0926 22:45:17.514861  2459 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0926 22:45:31.354933  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:45:31.937588  2459 solver.cpp:330] Iteration 3000, Testing net (#0)
I0926 22:45:35.351346  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:45:35.493662  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7304
I0926 22:45:35.493700  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.77941 (* 1 = 0.77941 loss)
I0926 22:45:35.638631  2459 solver.cpp:218] Iteration 3000 (5.51763 iter/s, 18.1237s/100 iters), loss = 0.688178
I0926 22:45:35.638660  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.688178 (* 1 = 0.688178 loss)
I0926 22:45:35.638666  2459 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0926 22:45:50.198091  2459 solver.cpp:218] Iteration 3100 (6.86843 iter/s, 14.5594s/100 iters), loss = 0.481969
I0926 22:45:50.198130  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481969 (* 1 = 0.481969 loss)
I0926 22:45:50.198137  2459 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0926 22:46:04.761029  2459 solver.cpp:218] Iteration 3200 (6.86679 iter/s, 14.5628s/100 iters), loss = 0.694424
I0926 22:46:04.761112  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.694424 (* 1 = 0.694424 loss)
I0926 22:46:04.761127  2459 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0926 22:46:19.325112  2459 solver.cpp:218] Iteration 3300 (6.86627 iter/s, 14.5639s/100 iters), loss = 0.721724
I0926 22:46:19.325153  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.721724 (* 1 = 0.721724 loss)
I0926 22:46:19.325160  2459 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0926 22:46:33.888236  2459 solver.cpp:218] Iteration 3400 (6.8667 iter/s, 14.563s/100 iters), loss = 0.568948
I0926 22:46:33.888278  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.568948 (* 1 = 0.568948 loss)
I0926 22:46:33.888283  2459 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0926 22:46:47.725481  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:46:48.307095  2459 solver.cpp:330] Iteration 3500, Testing net (#0)
I0926 22:46:51.720072  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:46:51.862311  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7431
I0926 22:46:51.862347  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733697 (* 1 = 0.733697 loss)
I0926 22:46:52.006498  2459 solver.cpp:218] Iteration 3500 (5.51933 iter/s, 18.1182s/100 iters), loss = 0.609267
I0926 22:46:52.006526  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.609267 (* 1 = 0.609267 loss)
I0926 22:46:52.006534  2459 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0926 22:47:06.568761  2459 solver.cpp:218] Iteration 3600 (6.8671 iter/s, 14.5622s/100 iters), loss = 0.508352
I0926 22:47:06.568804  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508352 (* 1 = 0.508352 loss)
I0926 22:47:06.568810  2459 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0926 22:47:21.128984  2459 solver.cpp:218] Iteration 3700 (6.86807 iter/s, 14.5601s/100 iters), loss = 0.562169
I0926 22:47:21.129125  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.562169 (* 1 = 0.562169 loss)
I0926 22:47:21.129133  2459 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0926 22:47:35.690204  2459 solver.cpp:218] Iteration 3800 (6.86765 iter/s, 14.561s/100 iters), loss = 0.645478
I0926 22:47:35.690235  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.645478 (* 1 = 0.645478 loss)
I0926 22:47:35.690241  2459 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0926 22:47:50.254520  2459 solver.cpp:218] Iteration 3900 (6.86614 iter/s, 14.5642s/100 iters), loss = 0.52665
I0926 22:47:50.254561  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52665 (* 1 = 0.52665 loss)
I0926 22:47:50.254567  2459 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0926 22:48:04.091872  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:48:04.675114  2459 solver.cpp:330] Iteration 4000, Testing net (#0)
I0926 22:48:08.088219  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:48:08.230352  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7479
I0926 22:48:08.230388  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.722853 (* 1 = 0.722853 loss)
I0926 22:48:08.374749  2459 solver.cpp:218] Iteration 4000 (5.51873 iter/s, 18.1201s/100 iters), loss = 0.673685
I0926 22:48:08.374778  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.673685 (* 1 = 0.673685 loss)
I0926 22:48:08.374783  2459 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0926 22:48:22.941088  2459 solver.cpp:218] Iteration 4100 (6.86518 iter/s, 14.5663s/100 iters), loss = 0.511557
I0926 22:48:22.941119  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511557 (* 1 = 0.511557 loss)
I0926 22:48:22.941124  2459 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0926 22:48:37.512099  2459 solver.cpp:218] Iteration 4200 (6.86298 iter/s, 14.5709s/100 iters), loss = 0.548644
I0926 22:48:37.512171  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.548644 (* 1 = 0.548644 loss)
I0926 22:48:37.512177  2459 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0926 22:48:52.071465  2459 solver.cpp:218] Iteration 4300 (6.86849 iter/s, 14.5592s/100 iters), loss = 0.591311
I0926 22:48:52.071507  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.591311 (* 1 = 0.591311 loss)
I0926 22:48:52.071513  2459 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0926 22:49:06.634480  2459 solver.cpp:218] Iteration 4400 (6.86675 iter/s, 14.5629s/100 iters), loss = 0.535453
I0926 22:49:06.634511  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535453 (* 1 = 0.535453 loss)
I0926 22:49:06.634517  2459 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0926 22:49:20.465677  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:49:21.048552  2459 solver.cpp:330] Iteration 4500, Testing net (#0)
I0926 22:49:24.465247  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:49:24.607540  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7249
I0926 22:49:24.607578  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.76773 (* 1 = 0.76773 loss)
I0926 22:49:24.752873  2459 solver.cpp:218] Iteration 4500 (5.51928 iter/s, 18.1183s/100 iters), loss = 0.656555
I0926 22:49:24.752900  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.656556 (* 1 = 0.656556 loss)
I0926 22:49:24.752907  2459 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0926 22:49:39.321362  2459 solver.cpp:218] Iteration 4600 (6.86417 iter/s, 14.5684s/100 iters), loss = 0.414192
I0926 22:49:39.321403  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414192 (* 1 = 0.414192 loss)
I0926 22:49:39.321408  2459 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0926 22:49:53.890046  2459 solver.cpp:218] Iteration 4700 (6.86408 iter/s, 14.5686s/100 iters), loss = 0.508529
I0926 22:49:53.890184  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508529 (* 1 = 0.508529 loss)
I0926 22:49:53.890192  2459 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0926 22:50:08.461601  2459 solver.cpp:218] Iteration 4800 (6.86277 iter/s, 14.5714s/100 iters), loss = 0.575567
I0926 22:50:08.461633  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.575567 (* 1 = 0.575567 loss)
I0926 22:50:08.461639  2459 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0926 22:50:23.040638  2459 solver.cpp:218] Iteration 4900 (6.8592 iter/s, 14.579s/100 iters), loss = 0.681188
I0926 22:50:23.040679  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.681188 (* 1 = 0.681188 loss)
I0926 22:50:23.040684  2459 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0926 22:50:36.890223  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:50:37.473160  2459 solver.cpp:330] Iteration 5000, Testing net (#0)
I0926 22:50:40.891403  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:50:41.034061  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.678
I0926 22:50:41.034097  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01943 (* 1 = 1.01943 loss)
I0926 22:50:41.179157  2459 solver.cpp:218] Iteration 5000 (5.51316 iter/s, 18.1384s/100 iters), loss = 0.550157
I0926 22:50:41.179185  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.550157 (* 1 = 0.550157 loss)
I0926 22:50:41.179193  2459 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0926 22:50:55.749017  2459 solver.cpp:218] Iteration 5100 (6.86352 iter/s, 14.5698s/100 iters), loss = 0.427395
I0926 22:50:55.749047  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427395 (* 1 = 0.427395 loss)
I0926 22:50:55.749053  2459 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0926 22:51:10.327443  2459 solver.cpp:218] Iteration 5200 (6.85949 iter/s, 14.5784s/100 iters), loss = 0.436867
I0926 22:51:10.327586  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436867 (* 1 = 0.436867 loss)
I0926 22:51:10.327592  2459 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0926 22:51:24.910293  2459 solver.cpp:218] Iteration 5300 (6.85746 iter/s, 14.5827s/100 iters), loss = 0.593502
I0926 22:51:24.910323  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.593502 (* 1 = 0.593502 loss)
I0926 22:51:24.910329  2459 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0926 22:51:39.496053  2459 solver.cpp:218] Iteration 5400 (6.85604 iter/s, 14.5857s/100 iters), loss = 0.611889
I0926 22:51:39.496095  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.611889 (* 1 = 0.611889 loss)
I0926 22:51:39.496100  2459 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0926 22:51:53.354346  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:51:53.937664  2459 solver.cpp:330] Iteration 5500, Testing net (#0)
I0926 22:51:57.357802  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:51:57.500424  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7544
I0926 22:51:57.500450  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.688237 (* 1 = 0.688237 loss)
I0926 22:51:57.645643  2459 solver.cpp:218] Iteration 5500 (5.50979 iter/s, 18.1495s/100 iters), loss = 0.552812
I0926 22:51:57.645671  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.552812 (* 1 = 0.552812 loss)
I0926 22:51:57.645678  2459 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0926 22:52:12.234350  2459 solver.cpp:218] Iteration 5600 (6.85465 iter/s, 14.5886s/100 iters), loss = 0.4629
I0926 22:52:12.234391  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4629 (* 1 = 0.4629 loss)
I0926 22:52:12.234397  2459 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0926 22:52:26.830257  2459 solver.cpp:218] Iteration 5700 (6.85127 iter/s, 14.5958s/100 iters), loss = 0.521034
I0926 22:52:26.830348  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.521034 (* 1 = 0.521034 loss)
I0926 22:52:26.830354  2459 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0926 22:52:41.424063  2459 solver.cpp:218] Iteration 5800 (6.85228 iter/s, 14.5937s/100 iters), loss = 0.55556
I0926 22:52:41.424103  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.55556 (* 1 = 0.55556 loss)
I0926 22:52:41.424108  2459 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0926 22:52:56.019851  2459 solver.cpp:218] Iteration 5900 (6.85133 iter/s, 14.5957s/100 iters), loss = 0.580461
I0926 22:52:56.019891  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.580461 (* 1 = 0.580461 loss)
I0926 22:52:56.019897  2459 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0926 22:53:09.887004  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:53:10.471133  2459 solver.cpp:330] Iteration 6000, Testing net (#0)
I0926 22:53:13.888538  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:53:14.031278  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6556
I0926 22:53:14.031316  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00279 (* 1 = 1.00279 loss)
I0926 22:53:14.176074  2459 solver.cpp:218] Iteration 6000 (5.50778 iter/s, 18.1561s/100 iters), loss = 0.528757
I0926 22:53:14.176100  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.528757 (* 1 = 0.528757 loss)
I0926 22:53:14.176106  2459 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0926 22:53:28.763125  2459 solver.cpp:218] Iteration 6100 (6.85543 iter/s, 14.587s/100 iters), loss = 0.410952
I0926 22:53:28.763166  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410952 (* 1 = 0.410952 loss)
I0926 22:53:28.763172  2459 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0926 22:53:43.354116  2459 solver.cpp:218] Iteration 6200 (6.85358 iter/s, 14.5909s/100 iters), loss = 0.492756
I0926 22:53:43.354241  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492756 (* 1 = 0.492756 loss)
I0926 22:53:43.354249  2459 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0926 22:53:57.933902  2459 solver.cpp:218] Iteration 6300 (6.85888 iter/s, 14.5796s/100 iters), loss = 0.588373
I0926 22:53:57.933943  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.588373 (* 1 = 0.588373 loss)
I0926 22:53:57.933948  2459 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0926 22:54:12.524206  2459 solver.cpp:218] Iteration 6400 (6.8539 iter/s, 14.5902s/100 iters), loss = 0.601993
I0926 22:54:12.524236  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601993 (* 1 = 0.601993 loss)
I0926 22:54:12.524242  2459 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0926 22:54:26.392139  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:54:26.976686  2459 solver.cpp:330] Iteration 6500, Testing net (#0)
I0926 22:54:30.398120  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:54:30.540751  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7279
I0926 22:54:30.540779  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.762563 (* 1 = 0.762563 loss)
I0926 22:54:30.685734  2459 solver.cpp:218] Iteration 6500 (5.50617 iter/s, 18.1615s/100 iters), loss = 0.535331
I0926 22:54:30.685762  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535331 (* 1 = 0.535331 loss)
I0926 22:54:30.685768  2459 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0926 22:54:45.261391  2459 solver.cpp:218] Iteration 6600 (6.86079 iter/s, 14.5756s/100 iters), loss = 0.394906
I0926 22:54:45.261420  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394906 (* 1 = 0.394906 loss)
I0926 22:54:45.261426  2459 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0926 22:54:59.830127  2459 solver.cpp:218] Iteration 6700 (6.86405 iter/s, 14.5687s/100 iters), loss = 0.38336
I0926 22:54:59.830229  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383361 (* 1 = 0.383361 loss)
I0926 22:54:59.830237  2459 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0926 22:55:14.407662  2459 solver.cpp:218] Iteration 6800 (6.85994 iter/s, 14.5774s/100 iters), loss = 0.60656
I0926 22:55:14.407703  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.60656 (* 1 = 0.60656 loss)
I0926 22:55:14.407708  2459 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0926 22:55:28.989681  2459 solver.cpp:218] Iteration 6900 (6.8578 iter/s, 14.5819s/100 iters), loss = 0.564831
I0926 22:55:28.989723  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.564831 (* 1 = 0.564831 loss)
I0926 22:55:28.989729  2459 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0926 22:55:42.850392  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:55:43.433869  2459 solver.cpp:330] Iteration 7000, Testing net (#0)
I0926 22:55:46.853927  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:55:46.996146  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7778
I0926 22:55:46.996183  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.662341 (* 1 = 0.662341 loss)
I0926 22:55:47.140857  2459 solver.cpp:218] Iteration 7000 (5.50931 iter/s, 18.1511s/100 iters), loss = 0.376734
I0926 22:55:47.140887  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376734 (* 1 = 0.376734 loss)
I0926 22:55:47.140893  2459 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0926 22:56:01.706337  2459 solver.cpp:218] Iteration 7100 (6.86558 iter/s, 14.5654s/100 iters), loss = 0.43329
I0926 22:56:01.706367  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43329 (* 1 = 0.43329 loss)
I0926 22:56:01.706372  2459 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0926 22:56:16.289402  2459 solver.cpp:218] Iteration 7200 (6.8573 iter/s, 14.583s/100 iters), loss = 0.620625
I0926 22:56:16.289474  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.620625 (* 1 = 0.620625 loss)
I0926 22:56:16.289480  2459 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0926 22:56:30.864655  2459 solver.cpp:218] Iteration 7300 (6.86099 iter/s, 14.5751s/100 iters), loss = 0.695107
I0926 22:56:30.864696  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.695107 (* 1 = 0.695107 loss)
I0926 22:56:30.864701  2459 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0926 22:56:45.440354  2459 solver.cpp:218] Iteration 7400 (6.86077 iter/s, 14.5756s/100 iters), loss = 0.46775
I0926 22:56:45.440385  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46775 (* 1 = 0.46775 loss)
I0926 22:56:45.440390  2459 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0926 22:56:59.291774  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:56:59.874706  2459 solver.cpp:330] Iteration 7500, Testing net (#0)
I0926 22:57:03.295980  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:57:03.438936  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7646
I0926 22:57:03.438973  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.664384 (* 1 = 0.664384 loss)
I0926 22:57:03.584254  2459 solver.cpp:218] Iteration 7500 (5.51152 iter/s, 18.1438s/100 iters), loss = 0.492748
I0926 22:57:03.584282  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492748 (* 1 = 0.492748 loss)
I0926 22:57:03.584290  2459 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0926 22:57:18.160655  2459 solver.cpp:218] Iteration 7600 (6.86043 iter/s, 14.5763s/100 iters), loss = 0.360245
I0926 22:57:18.160697  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360246 (* 1 = 0.360246 loss)
I0926 22:57:18.160703  2459 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0926 22:57:32.744050  2459 solver.cpp:218] Iteration 7700 (6.85715 iter/s, 14.5833s/100 iters), loss = 0.438185
I0926 22:57:32.744141  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438185 (* 1 = 0.438185 loss)
I0926 22:57:32.744148  2459 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0926 22:57:47.324954  2459 solver.cpp:218] Iteration 7800 (6.85834 iter/s, 14.5808s/100 iters), loss = 0.46825
I0926 22:57:47.324995  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46825 (* 1 = 0.46825 loss)
I0926 22:57:47.325001  2459 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0926 22:58:01.905956  2459 solver.cpp:218] Iteration 7900 (6.85827 iter/s, 14.5809s/100 iters), loss = 0.466871
I0926 22:58:01.905997  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466871 (* 1 = 0.466871 loss)
I0926 22:58:01.906002  2459 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0926 22:58:15.762503  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:58:16.346951  2459 solver.cpp:330] Iteration 8000, Testing net (#0)
I0926 22:58:19.766134  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:58:19.908488  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6864
I0926 22:58:19.908524  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.836818 (* 1 = 0.836818 loss)
I0926 22:58:20.053396  2459 solver.cpp:218] Iteration 8000 (5.51044 iter/s, 18.1474s/100 iters), loss = 0.436323
I0926 22:58:20.053424  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436323 (* 1 = 0.436323 loss)
I0926 22:58:20.053431  2459 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0926 22:58:34.641535  2459 solver.cpp:218] Iteration 8100 (6.85491 iter/s, 14.5881s/100 iters), loss = 0.353535
I0926 22:58:34.641566  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353535 (* 1 = 0.353535 loss)
I0926 22:58:34.641572  2459 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0926 22:58:49.230912  2459 solver.cpp:218] Iteration 8200 (6.85433 iter/s, 14.5893s/100 iters), loss = 0.396041
I0926 22:58:49.230978  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396041 (* 1 = 0.396041 loss)
I0926 22:58:49.230985  2459 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0926 22:59:03.825780  2459 solver.cpp:218] Iteration 8300 (6.85177 iter/s, 14.5948s/100 iters), loss = 0.578012
I0926 22:59:03.825822  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.578012 (* 1 = 0.578012 loss)
I0926 22:59:03.825827  2459 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0926 22:59:18.409567  2459 solver.cpp:218] Iteration 8400 (6.85697 iter/s, 14.5837s/100 iters), loss = 0.474072
I0926 22:59:18.409607  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474072 (* 1 = 0.474072 loss)
I0926 22:59:18.409613  2459 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0926 22:59:32.265678  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:59:32.849684  2459 solver.cpp:330] Iteration 8500, Testing net (#0)
I0926 22:59:36.268679  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 22:59:36.411437  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7744
I0926 22:59:36.411473  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.642289 (* 1 = 0.642289 loss)
I0926 22:59:36.556186  2459 solver.cpp:218] Iteration 8500 (5.51069 iter/s, 18.1465s/100 iters), loss = 0.447572
I0926 22:59:36.556216  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447572 (* 1 = 0.447572 loss)
I0926 22:59:36.556232  2459 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0926 22:59:51.123461  2459 solver.cpp:218] Iteration 8600 (6.86473 iter/s, 14.5672s/100 iters), loss = 0.468268
I0926 22:59:51.123492  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468268 (* 1 = 0.468268 loss)
I0926 22:59:51.123497  2459 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0926 23:00:05.693197  2459 solver.cpp:218] Iteration 8700 (6.86357 iter/s, 14.5697s/100 iters), loss = 0.394812
I0926 23:00:05.693336  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394812 (* 1 = 0.394812 loss)
I0926 23:00:05.693347  2459 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0926 23:00:20.265195  2459 solver.cpp:218] Iteration 8800 (6.86256 iter/s, 14.5718s/100 iters), loss = 0.545265
I0926 23:00:20.265238  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545266 (* 1 = 0.545266 loss)
I0926 23:00:20.265244  2459 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0926 23:00:34.837656  2459 solver.cpp:218] Iteration 8900 (6.8623 iter/s, 14.5724s/100 iters), loss = 0.510989
I0926 23:00:34.837687  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510989 (* 1 = 0.510989 loss)
I0926 23:00:34.837692  2459 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0926 23:00:48.682138  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:00:49.264683  2459 solver.cpp:330] Iteration 9000, Testing net (#0)
I0926 23:00:52.684198  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:00:52.826767  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7449
I0926 23:00:52.826804  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.758456 (* 1 = 0.758456 loss)
I0926 23:00:52.971509  2459 solver.cpp:218] Iteration 9000 (5.51457 iter/s, 18.1338s/100 iters), loss = 0.527496
I0926 23:00:52.971536  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.527496 (* 1 = 0.527496 loss)
I0926 23:00:52.971544  2459 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0926 23:01:07.555596  2459 solver.cpp:218] Iteration 9100 (6.85682 iter/s, 14.584s/100 iters), loss = 0.361245
I0926 23:01:07.555637  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361245 (* 1 = 0.361245 loss)
I0926 23:01:07.555644  2459 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0926 23:01:22.141149  2459 solver.cpp:218] Iteration 9200 (6.85613 iter/s, 14.5855s/100 iters), loss = 0.467197
I0926 23:01:22.141235  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467197 (* 1 = 0.467197 loss)
I0926 23:01:22.141242  2459 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0926 23:01:36.723727  2459 solver.cpp:218] Iteration 9300 (6.85755 iter/s, 14.5825s/100 iters), loss = 0.555863
I0926 23:01:36.723769  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555863 (* 1 = 0.555863 loss)
I0926 23:01:36.723775  2459 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0926 23:01:51.312978  2459 solver.cpp:218] Iteration 9400 (6.8544 iter/s, 14.5892s/100 iters), loss = 0.450805
I0926 23:01:51.313019  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450805 (* 1 = 0.450805 loss)
I0926 23:01:51.313024  2459 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0926 23:02:05.173938  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:02:05.758869  2459 solver.cpp:330] Iteration 9500, Testing net (#0)
I0926 23:02:09.177309  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:02:09.320092  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7623
I0926 23:02:09.320128  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658401 (* 1 = 0.658401 loss)
I0926 23:02:09.465121  2459 solver.cpp:218] Iteration 9500 (5.50902 iter/s, 18.1521s/100 iters), loss = 0.343979
I0926 23:02:09.465147  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343979 (* 1 = 0.343979 loss)
I0926 23:02:09.465154  2459 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0926 23:02:24.031719  2459 solver.cpp:218] Iteration 9600 (6.86505 iter/s, 14.5665s/100 iters), loss = 0.354009
I0926 23:02:24.031761  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35401 (* 1 = 0.35401 loss)
I0926 23:02:24.031766  2459 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0926 23:02:38.604061  2459 solver.cpp:218] Iteration 9700 (6.86235 iter/s, 14.5723s/100 iters), loss = 0.403036
I0926 23:02:38.604156  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403036 (* 1 = 0.403036 loss)
I0926 23:02:38.604167  2459 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0926 23:02:53.170637  2459 solver.cpp:218] Iteration 9800 (6.86509 iter/s, 14.5665s/100 iters), loss = 0.520347
I0926 23:02:53.170678  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520348 (* 1 = 0.520348 loss)
I0926 23:02:53.170684  2459 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0926 23:03:07.745437  2459 solver.cpp:218] Iteration 9900 (6.86119 iter/s, 14.5747s/100 iters), loss = 0.457692
I0926 23:03:07.745478  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457693 (* 1 = 0.457693 loss)
I0926 23:03:07.745484  2459 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0926 23:03:21.594686  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:03:22.177448  2459 solver.cpp:330] Iteration 10000, Testing net (#0)
I0926 23:03:25.596056  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:03:25.738988  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7428
I0926 23:03:25.739024  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739499 (* 1 = 0.739499 loss)
I0926 23:03:25.884069  2459 solver.cpp:218] Iteration 10000 (5.51312 iter/s, 18.1386s/100 iters), loss = 0.430557
I0926 23:03:25.884096  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430557 (* 1 = 0.430557 loss)
I0926 23:03:25.884104  2459 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0926 23:03:40.460696  2459 solver.cpp:218] Iteration 10100 (6.86033 iter/s, 14.5766s/100 iters), loss = 0.436341
I0926 23:03:40.460738  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436341 (* 1 = 0.436341 loss)
I0926 23:03:40.460744  2459 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0926 23:03:55.037904  2459 solver.cpp:218] Iteration 10200 (6.86006 iter/s, 14.5771s/100 iters), loss = 0.364445
I0926 23:03:55.037977  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364445 (* 1 = 0.364445 loss)
I0926 23:03:55.037986  2459 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0926 23:04:09.624862  2459 solver.cpp:218] Iteration 10300 (6.85549 iter/s, 14.5869s/100 iters), loss = 0.489605
I0926 23:04:09.624902  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489605 (* 1 = 0.489605 loss)
I0926 23:04:09.624908  2459 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0926 23:04:24.206926  2459 solver.cpp:218] Iteration 10400 (6.85777 iter/s, 14.582s/100 iters), loss = 0.431158
I0926 23:04:24.206969  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431158 (* 1 = 0.431158 loss)
I0926 23:04:24.206974  2459 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0926 23:04:38.057649  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:04:38.641270  2459 solver.cpp:330] Iteration 10500, Testing net (#0)
I0926 23:04:42.060940  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:04:42.203475  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7361
I0926 23:04:42.203510  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780516 (* 1 = 0.780516 loss)
I0926 23:04:42.348302  2459 solver.cpp:218] Iteration 10500 (5.51229 iter/s, 18.1413s/100 iters), loss = 0.54171
I0926 23:04:42.348330  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.54171 (* 1 = 0.54171 loss)
I0926 23:04:42.348335  2459 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0926 23:04:56.916106  2459 solver.cpp:218] Iteration 10600 (6.86448 iter/s, 14.5677s/100 iters), loss = 0.415078
I0926 23:04:56.916136  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415078 (* 1 = 0.415078 loss)
I0926 23:04:56.916142  2459 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0926 23:05:11.489751  2459 solver.cpp:218] Iteration 10700 (6.86173 iter/s, 14.5736s/100 iters), loss = 0.426712
I0926 23:05:11.489841  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426713 (* 1 = 0.426713 loss)
I0926 23:05:11.489850  2459 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0926 23:05:26.065572  2459 solver.cpp:218] Iteration 10800 (6.86073 iter/s, 14.5757s/100 iters), loss = 0.542546
I0926 23:05:26.065610  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.542546 (* 1 = 0.542546 loss)
I0926 23:05:26.065616  2459 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0926 23:05:40.642927  2459 solver.cpp:218] Iteration 10900 (6.85999 iter/s, 14.5773s/100 iters), loss = 0.428933
I0926 23:05:40.642958  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428933 (* 1 = 0.428933 loss)
I0926 23:05:40.642964  2459 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0926 23:05:54.495021  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:05:55.080855  2459 solver.cpp:330] Iteration 11000, Testing net (#0)
I0926 23:05:58.499399  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:05:58.642065  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7413
I0926 23:05:58.642101  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.774717 (* 1 = 0.774717 loss)
I0926 23:05:58.786267  2459 solver.cpp:218] Iteration 11000 (5.51168 iter/s, 18.1433s/100 iters), loss = 0.354793
I0926 23:05:58.786294  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354793 (* 1 = 0.354793 loss)
I0926 23:05:58.786301  2459 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0926 23:06:13.361517  2459 solver.cpp:218] Iteration 11100 (6.86097 iter/s, 14.5752s/100 iters), loss = 0.39307
I0926 23:06:13.361547  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39307 (* 1 = 0.39307 loss)
I0926 23:06:13.361553  2459 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0926 23:06:27.930609  2459 solver.cpp:218] Iteration 11200 (6.86387 iter/s, 14.569s/100 iters), loss = 0.460557
I0926 23:06:27.930729  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460557 (* 1 = 0.460557 loss)
I0926 23:06:27.930740  2459 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0926 23:06:42.508754  2459 solver.cpp:218] Iteration 11300 (6.85965 iter/s, 14.578s/100 iters), loss = 0.547478
I0926 23:06:42.508795  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.547478 (* 1 = 0.547478 loss)
I0926 23:06:42.508801  2459 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0926 23:06:57.085907  2459 solver.cpp:218] Iteration 11400 (6.86008 iter/s, 14.5771s/100 iters), loss = 0.412042
I0926 23:06:57.085948  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412042 (* 1 = 0.412042 loss)
I0926 23:06:57.085954  2459 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0926 23:07:10.937808  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:07:11.520431  2459 solver.cpp:330] Iteration 11500, Testing net (#0)
I0926 23:07:14.940032  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:07:15.082484  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7351
I0926 23:07:15.082518  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.786421 (* 1 = 0.786421 loss)
I0926 23:07:15.227459  2459 solver.cpp:218] Iteration 11500 (5.51223 iter/s, 18.1415s/100 iters), loss = 0.347459
I0926 23:07:15.227488  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34746 (* 1 = 0.34746 loss)
I0926 23:07:15.227494  2459 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0926 23:07:29.796463  2459 solver.cpp:218] Iteration 11600 (6.86392 iter/s, 14.5689s/100 iters), loss = 0.387801
I0926 23:07:29.796504  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387801 (* 1 = 0.387801 loss)
I0926 23:07:29.796510  2459 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0926 23:07:44.366863  2459 solver.cpp:218] Iteration 11700 (6.86326 iter/s, 14.5703s/100 iters), loss = 0.452881
I0926 23:07:44.366969  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452881 (* 1 = 0.452881 loss)
I0926 23:07:44.366986  2459 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0926 23:07:58.938998  2459 solver.cpp:218] Iteration 11800 (6.86248 iter/s, 14.572s/100 iters), loss = 0.569574
I0926 23:07:58.939040  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.569574 (* 1 = 0.569574 loss)
I0926 23:07:58.939046  2459 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0926 23:08:13.502317  2459 solver.cpp:218] Iteration 11900 (6.8666 iter/s, 14.5632s/100 iters), loss = 0.353642
I0926 23:08:13.502358  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353642 (* 1 = 0.353642 loss)
I0926 23:08:13.502364  2459 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0926 23:08:27.362035  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:08:27.944275  2459 solver.cpp:330] Iteration 12000, Testing net (#0)
I0926 23:08:31.363685  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:08:31.506474  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7676
I0926 23:08:31.506511  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.672967 (* 1 = 0.672967 loss)
I0926 23:08:31.651657  2459 solver.cpp:218] Iteration 12000 (5.50987 iter/s, 18.1493s/100 iters), loss = 0.43237
I0926 23:08:31.651686  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43237 (* 1 = 0.43237 loss)
I0926 23:08:31.651693  2459 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0926 23:08:46.239909  2459 solver.cpp:218] Iteration 12100 (6.85486 iter/s, 14.5882s/100 iters), loss = 0.451708
I0926 23:08:46.239938  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451708 (* 1 = 0.451708 loss)
I0926 23:08:46.239944  2459 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0926 23:09:00.827435  2459 solver.cpp:218] Iteration 12200 (6.8552 iter/s, 14.5875s/100 iters), loss = 0.438049
I0926 23:09:00.827574  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438049 (* 1 = 0.438049 loss)
I0926 23:09:00.827582  2459 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0926 23:09:15.415874  2459 solver.cpp:218] Iteration 12300 (6.85482 iter/s, 14.5883s/100 iters), loss = 0.51434
I0926 23:09:15.415915  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51434 (* 1 = 0.51434 loss)
I0926 23:09:15.415920  2459 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0926 23:09:30.003890  2459 solver.cpp:218] Iteration 12400 (6.85498 iter/s, 14.5879s/100 iters), loss = 0.365579
I0926 23:09:30.003932  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365579 (* 1 = 0.365579 loss)
I0926 23:09:30.003937  2459 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0926 23:09:43.863016  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:09:44.446411  2459 solver.cpp:330] Iteration 12500, Testing net (#0)
I0926 23:09:47.865886  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:09:48.008615  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7366
I0926 23:09:48.008651  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.760824 (* 1 = 0.760824 loss)
I0926 23:09:48.153473  2459 solver.cpp:218] Iteration 12500 (5.50979 iter/s, 18.1495s/100 iters), loss = 0.389906
I0926 23:09:48.153501  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389906 (* 1 = 0.389906 loss)
I0926 23:09:48.153508  2459 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0926 23:10:02.735365  2459 solver.cpp:218] Iteration 12600 (6.85785 iter/s, 14.5818s/100 iters), loss = 0.396151
I0926 23:10:02.735405  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396151 (* 1 = 0.396151 loss)
I0926 23:10:02.735411  2459 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0926 23:10:17.317225  2459 solver.cpp:218] Iteration 12700 (6.85787 iter/s, 14.5818s/100 iters), loss = 0.427362
I0926 23:10:17.317351  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427362 (* 1 = 0.427362 loss)
I0926 23:10:17.317359  2459 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0926 23:10:31.895481  2459 solver.cpp:218] Iteration 12800 (6.8596 iter/s, 14.5781s/100 iters), loss = 0.457934
I0926 23:10:31.895512  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457934 (* 1 = 0.457934 loss)
I0926 23:10:31.895519  2459 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0926 23:10:46.479554  2459 solver.cpp:218] Iteration 12900 (6.85682 iter/s, 14.584s/100 iters), loss = 0.374363
I0926 23:10:46.479594  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374363 (* 1 = 0.374363 loss)
I0926 23:10:46.479600  2459 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0926 23:11:00.337051  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:11:00.920883  2459 solver.cpp:330] Iteration 13000, Testing net (#0)
I0926 23:11:04.340353  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:11:04.482887  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7565
I0926 23:11:04.482923  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.692357 (* 1 = 0.692357 loss)
I0926 23:11:04.627223  2459 solver.cpp:218] Iteration 13000 (5.51037 iter/s, 18.1476s/100 iters), loss = 0.359264
I0926 23:11:04.627251  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359264 (* 1 = 0.359264 loss)
I0926 23:11:04.627259  2459 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0926 23:11:19.197031  2459 solver.cpp:218] Iteration 13100 (6.86354 iter/s, 14.5697s/100 iters), loss = 0.375035
I0926 23:11:19.197072  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375035 (* 1 = 0.375035 loss)
I0926 23:11:19.197078  2459 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0926 23:11:33.769771  2459 solver.cpp:218] Iteration 13200 (6.86216 iter/s, 14.5727s/100 iters), loss = 0.400998
I0926 23:11:33.769865  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400999 (* 1 = 0.400999 loss)
I0926 23:11:33.769872  2459 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0926 23:11:48.340428  2459 solver.cpp:218] Iteration 13300 (6.86317 iter/s, 14.5705s/100 iters), loss = 0.529874
I0926 23:11:48.340471  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.529874 (* 1 = 0.529874 loss)
I0926 23:11:48.340476  2459 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0926 23:12:02.916976  2459 solver.cpp:218] Iteration 13400 (6.86037 iter/s, 14.5765s/100 iters), loss = 0.352134
I0926 23:12:02.917018  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352134 (* 1 = 0.352134 loss)
I0926 23:12:02.917024  2459 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0926 23:12:16.762696  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:12:17.345919  2459 solver.cpp:330] Iteration 13500, Testing net (#0)
I0926 23:12:20.764015  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:12:20.906666  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7913
I0926 23:12:20.906703  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.60938 (* 1 = 0.60938 loss)
I0926 23:12:21.051064  2459 solver.cpp:218] Iteration 13500 (5.5145 iter/s, 18.134s/100 iters), loss = 0.372127
I0926 23:12:21.051091  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372128 (* 1 = 0.372128 loss)
I0926 23:12:21.051098  2459 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0926 23:12:35.621676  2459 solver.cpp:218] Iteration 13600 (6.86316 iter/s, 14.5706s/100 iters), loss = 0.374729
I0926 23:12:35.621718  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374729 (* 1 = 0.374729 loss)
I0926 23:12:35.621724  2459 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0926 23:12:50.207254  2459 solver.cpp:218] Iteration 13700 (6.85612 iter/s, 14.5855s/100 iters), loss = 0.32041
I0926 23:12:50.207403  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32041 (* 1 = 0.32041 loss)
I0926 23:12:50.207411  2459 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0926 23:13:04.791779  2459 solver.cpp:218] Iteration 13800 (6.85666 iter/s, 14.5844s/100 iters), loss = 0.472066
I0926 23:13:04.791826  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472067 (* 1 = 0.472067 loss)
I0926 23:13:04.791833  2459 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0926 23:13:19.367645  2459 solver.cpp:218] Iteration 13900 (6.86069 iter/s, 14.5758s/100 iters), loss = 0.381539
I0926 23:13:19.367686  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381539 (* 1 = 0.381539 loss)
I0926 23:13:19.367691  2459 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0926 23:13:33.224351  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:13:33.808544  2459 solver.cpp:330] Iteration 14000, Testing net (#0)
I0926 23:13:37.227777  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:13:37.370466  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8129
I0926 23:13:37.370502  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.548781 (* 1 = 0.548781 loss)
I0926 23:13:37.515792  2459 solver.cpp:218] Iteration 14000 (5.51023 iter/s, 18.1481s/100 iters), loss = 0.358019
I0926 23:13:37.515820  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358019 (* 1 = 0.358019 loss)
I0926 23:13:37.515826  2459 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0926 23:13:52.101269  2459 solver.cpp:218] Iteration 14100 (6.85616 iter/s, 14.5854s/100 iters), loss = 0.371095
I0926 23:13:52.101310  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371096 (* 1 = 0.371096 loss)
I0926 23:13:52.101316  2459 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0926 23:14:06.685528  2459 solver.cpp:218] Iteration 14200 (6.85674 iter/s, 14.5842s/100 iters), loss = 0.382123
I0926 23:14:06.685621  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382123 (* 1 = 0.382123 loss)
I0926 23:14:06.685628  2459 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0926 23:14:21.270360  2459 solver.cpp:218] Iteration 14300 (6.8565 iter/s, 14.5847s/100 iters), loss = 0.569237
I0926 23:14:21.270401  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.569237 (* 1 = 0.569237 loss)
I0926 23:14:21.270407  2459 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0926 23:14:35.852519  2459 solver.cpp:218] Iteration 14400 (6.85773 iter/s, 14.5821s/100 iters), loss = 0.363237
I0926 23:14:35.852560  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363237 (* 1 = 0.363237 loss)
I0926 23:14:35.852566  2459 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0926 23:14:49.722108  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:14:50.304163  2459 solver.cpp:330] Iteration 14500, Testing net (#0)
I0926 23:14:53.723130  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:14:53.865906  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7151
I0926 23:14:53.865942  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.870093 (* 1 = 0.870093 loss)
I0926 23:14:54.011015  2459 solver.cpp:218] Iteration 14500 (5.50709 iter/s, 18.1584s/100 iters), loss = 0.364332
I0926 23:14:54.011044  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364333 (* 1 = 0.364333 loss)
I0926 23:14:54.011050  2459 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0926 23:15:08.604300  2459 solver.cpp:218] Iteration 14600 (6.85249 iter/s, 14.5932s/100 iters), loss = 0.319601
I0926 23:15:08.604349  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319602 (* 1 = 0.319602 loss)
I0926 23:15:08.604357  2459 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0926 23:15:23.185636  2459 solver.cpp:218] Iteration 14700 (6.85812 iter/s, 14.5813s/100 iters), loss = 0.314613
I0926 23:15:23.185730  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314613 (* 1 = 0.314613 loss)
I0926 23:15:23.185737  2459 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0926 23:15:37.767812  2459 solver.cpp:218] Iteration 14800 (6.85774 iter/s, 14.5821s/100 iters), loss = 0.464389
I0926 23:15:37.767843  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464389 (* 1 = 0.464389 loss)
I0926 23:15:37.767848  2459 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0926 23:15:52.350124  2459 solver.cpp:218] Iteration 14900 (6.85765 iter/s, 14.5823s/100 iters), loss = 0.427928
I0926 23:15:52.350173  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427929 (* 1 = 0.427929 loss)
I0926 23:15:52.350181  2459 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0926 23:16:06.219516  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:16:06.803159  2459 solver.cpp:330] Iteration 15000, Testing net (#0)
I0926 23:16:10.219491  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:16:10.362308  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7342
I0926 23:16:10.362342  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.803326 (* 1 = 0.803326 loss)
I0926 23:16:10.507294  2459 solver.cpp:218] Iteration 15000 (5.50749 iter/s, 18.1571s/100 iters), loss = 0.329755
I0926 23:16:10.507321  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329756 (* 1 = 0.329756 loss)
I0926 23:16:10.507328  2459 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0926 23:16:25.090486  2459 solver.cpp:218] Iteration 15100 (6.85724 iter/s, 14.5831s/100 iters), loss = 0.312921
I0926 23:16:25.090517  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312921 (* 1 = 0.312921 loss)
I0926 23:16:25.090523  2459 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0926 23:16:39.683217  2459 solver.cpp:218] Iteration 15200 (6.85276 iter/s, 14.5927s/100 iters), loss = 0.412827
I0926 23:16:39.683312  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412827 (* 1 = 0.412827 loss)
I0926 23:16:39.683320  2459 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0926 23:16:54.277444  2459 solver.cpp:218] Iteration 15300 (6.85208 iter/s, 14.5941s/100 iters), loss = 0.422492
I0926 23:16:54.277485  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422493 (* 1 = 0.422493 loss)
I0926 23:16:54.277492  2459 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0926 23:17:08.876194  2459 solver.cpp:218] Iteration 15400 (6.84994 iter/s, 14.5987s/100 iters), loss = 0.459948
I0926 23:17:08.876252  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459949 (* 1 = 0.459949 loss)
I0926 23:17:08.876267  2459 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0926 23:17:22.743775  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:17:23.327486  2459 solver.cpp:330] Iteration 15500, Testing net (#0)
I0926 23:17:26.746191  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:17:26.888952  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7924
I0926 23:17:26.888983  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600908 (* 1 = 0.600908 loss)
I0926 23:17:27.033350  2459 solver.cpp:218] Iteration 15500 (5.5075 iter/s, 18.1571s/100 iters), loss = 0.421283
I0926 23:17:27.033383  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421283 (* 1 = 0.421283 loss)
I0926 23:17:27.033392  2459 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0926 23:17:41.626760  2459 solver.cpp:218] Iteration 15600 (6.85244 iter/s, 14.5933s/100 iters), loss = 0.393949
I0926 23:17:41.626801  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39395 (* 1 = 0.39395 loss)
I0926 23:17:41.626807  2459 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0926 23:17:56.213248  2459 solver.cpp:218] Iteration 15700 (6.85569 iter/s, 14.5864s/100 iters), loss = 0.383938
I0926 23:17:56.213335  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383938 (* 1 = 0.383938 loss)
I0926 23:17:56.213342  2459 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0926 23:18:10.796398  2459 solver.cpp:218] Iteration 15800 (6.85728 iter/s, 14.583s/100 iters), loss = 0.500372
I0926 23:18:10.796443  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.500372 (* 1 = 0.500372 loss)
I0926 23:18:10.796450  2459 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0926 23:18:25.381991  2459 solver.cpp:218] Iteration 15900 (6.85611 iter/s, 14.5855s/100 iters), loss = 0.373411
I0926 23:18:25.382033  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373411 (* 1 = 0.373411 loss)
I0926 23:18:25.382040  2459 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0926 23:18:39.251204  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:18:39.836520  2459 solver.cpp:330] Iteration 16000, Testing net (#0)
I0926 23:18:43.251461  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:18:43.393679  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7499
I0926 23:18:43.393710  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.73694 (* 1 = 0.73694 loss)
I0926 23:18:43.537633  2459 solver.cpp:218] Iteration 16000 (5.50795 iter/s, 18.1556s/100 iters), loss = 0.365545
I0926 23:18:43.537665  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365545 (* 1 = 0.365545 loss)
I0926 23:18:43.537674  2459 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0926 23:18:58.122436  2459 solver.cpp:218] Iteration 16100 (6.85648 iter/s, 14.5847s/100 iters), loss = 0.371682
I0926 23:18:58.122476  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371682 (* 1 = 0.371682 loss)
I0926 23:18:58.122483  2459 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0926 23:19:12.705809  2459 solver.cpp:218] Iteration 16200 (6.85716 iter/s, 14.5833s/100 iters), loss = 0.35566
I0926 23:19:12.705921  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355661 (* 1 = 0.355661 loss)
I0926 23:19:12.705929  2459 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0926 23:19:27.292428  2459 solver.cpp:218] Iteration 16300 (6.85566 iter/s, 14.5865s/100 iters), loss = 0.437478
I0926 23:19:27.292474  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437478 (* 1 = 0.437478 loss)
I0926 23:19:27.292481  2459 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0926 23:19:41.892149  2459 solver.cpp:218] Iteration 16400 (6.84948 iter/s, 14.5996s/100 iters), loss = 0.343257
I0926 23:19:41.892197  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343258 (* 1 = 0.343258 loss)
I0926 23:19:41.892207  2459 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0926 23:19:55.758595  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:19:56.343150  2459 solver.cpp:330] Iteration 16500, Testing net (#0)
I0926 23:19:59.758929  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:19:59.901489  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7593
I0926 23:19:59.901530  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733972 (* 1 = 0.733972 loss)
I0926 23:20:00.045375  2459 solver.cpp:218] Iteration 16500 (5.50869 iter/s, 18.1531s/100 iters), loss = 0.324803
I0926 23:20:00.045408  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324803 (* 1 = 0.324803 loss)
I0926 23:20:00.045418  2459 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0926 23:20:14.638124  2459 solver.cpp:218] Iteration 16600 (6.85275 iter/s, 14.5927s/100 iters), loss = 0.291983
I0926 23:20:14.638166  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291984 (* 1 = 0.291984 loss)
I0926 23:20:14.638173  2459 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0926 23:20:29.239650  2459 solver.cpp:218] Iteration 16700 (6.84863 iter/s, 14.6015s/100 iters), loss = 0.408492
I0926 23:20:29.239766  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408492 (* 1 = 0.408492 loss)
I0926 23:20:29.239773  2459 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0926 23:20:43.831254  2459 solver.cpp:218] Iteration 16800 (6.85332 iter/s, 14.5915s/100 iters), loss = 0.462875
I0926 23:20:43.831295  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462876 (* 1 = 0.462876 loss)
I0926 23:20:43.831301  2459 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0926 23:20:58.425320  2459 solver.cpp:218] Iteration 16900 (6.85213 iter/s, 14.594s/100 iters), loss = 0.333724
I0926 23:20:58.425362  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333724 (* 1 = 0.333724 loss)
I0926 23:20:58.425369  2459 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0926 23:21:12.286005  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:21:12.870368  2459 solver.cpp:330] Iteration 17000, Testing net (#0)
I0926 23:21:16.286873  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:21:16.429342  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7669
I0926 23:21:16.429373  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.674737 (* 1 = 0.674737 loss)
I0926 23:21:16.573516  2459 solver.cpp:218] Iteration 17000 (5.51021 iter/s, 18.1481s/100 iters), loss = 0.355378
I0926 23:21:16.573551  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355379 (* 1 = 0.355379 loss)
I0926 23:21:16.573559  2459 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0926 23:21:31.153898  2459 solver.cpp:218] Iteration 17100 (6.85856 iter/s, 14.5803s/100 iters), loss = 0.41909
I0926 23:21:31.153944  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419091 (* 1 = 0.419091 loss)
I0926 23:21:31.153950  2459 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0926 23:21:45.743429  2459 solver.cpp:218] Iteration 17200 (6.85426 iter/s, 14.5895s/100 iters), loss = 0.373009
I0926 23:21:45.743576  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373009 (* 1 = 0.373009 loss)
I0926 23:21:45.743583  2459 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0926 23:22:00.337596  2459 solver.cpp:218] Iteration 17300 (6.85213 iter/s, 14.594s/100 iters), loss = 0.446414
I0926 23:22:00.337633  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446415 (* 1 = 0.446415 loss)
I0926 23:22:00.337642  2459 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0926 23:22:14.927693  2459 solver.cpp:218] Iteration 17400 (6.85399 iter/s, 14.59s/100 iters), loss = 0.26291
I0926 23:22:14.927739  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26291 (* 1 = 0.26291 loss)
I0926 23:22:14.927747  2459 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0926 23:22:28.798064  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:22:29.380640  2459 solver.cpp:330] Iteration 17500, Testing net (#0)
I0926 23:22:32.798020  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:22:32.940824  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7507
I0926 23:22:32.940860  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.714075 (* 1 = 0.714075 loss)
I0926 23:22:33.085376  2459 solver.cpp:218] Iteration 17500 (5.50733 iter/s, 18.1576s/100 iters), loss = 0.361222
I0926 23:22:33.085402  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361222 (* 1 = 0.361222 loss)
I0926 23:22:33.085409  2459 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0926 23:22:47.657737  2459 solver.cpp:218] Iteration 17600 (6.86233 iter/s, 14.5723s/100 iters), loss = 0.351666
I0926 23:22:47.657778  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351666 (* 1 = 0.351666 loss)
I0926 23:22:47.657784  2459 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0926 23:23:02.230182  2459 solver.cpp:218] Iteration 17700 (6.8623 iter/s, 14.5724s/100 iters), loss = 0.370707
I0926 23:23:02.230273  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370708 (* 1 = 0.370708 loss)
I0926 23:23:02.230288  2459 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0926 23:23:16.800397  2459 solver.cpp:218] Iteration 17800 (6.86337 iter/s, 14.5701s/100 iters), loss = 0.372965
I0926 23:23:16.800427  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372965 (* 1 = 0.372965 loss)
I0926 23:23:16.800433  2459 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0926 23:23:31.373710  2459 solver.cpp:218] Iteration 17900 (6.86188 iter/s, 14.5733s/100 iters), loss = 0.376132
I0926 23:23:31.373749  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376132 (* 1 = 0.376132 loss)
I0926 23:23:31.373755  2459 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0926 23:23:45.217285  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:23:45.800241  2459 solver.cpp:330] Iteration 18000, Testing net (#0)
I0926 23:23:49.219211  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:23:49.361856  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7844
I0926 23:23:49.361893  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.624063 (* 1 = 0.624063 loss)
I0926 23:23:49.506482  2459 solver.cpp:218] Iteration 18000 (5.5149 iter/s, 18.1327s/100 iters), loss = 0.364691
I0926 23:23:49.506510  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364691 (* 1 = 0.364691 loss)
I0926 23:23:49.506515  2459 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0926 23:24:04.082962  2459 solver.cpp:218] Iteration 18100 (6.86039 iter/s, 14.5764s/100 iters), loss = 0.369974
I0926 23:24:04.083004  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369974 (* 1 = 0.369974 loss)
I0926 23:24:04.083009  2459 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0926 23:24:18.658797  2459 solver.cpp:218] Iteration 18200 (6.8607 iter/s, 14.5758s/100 iters), loss = 0.344733
I0926 23:24:18.658906  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344733 (* 1 = 0.344733 loss)
I0926 23:24:18.658913  2459 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0926 23:24:33.234207  2459 solver.cpp:218] Iteration 18300 (6.86093 iter/s, 14.5753s/100 iters), loss = 0.523161
I0926 23:24:33.234248  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.523162 (* 1 = 0.523162 loss)
I0926 23:24:33.234254  2459 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0926 23:24:47.806699  2459 solver.cpp:218] Iteration 18400 (6.86228 iter/s, 14.5724s/100 iters), loss = 0.358673
I0926 23:24:47.806741  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358674 (* 1 = 0.358674 loss)
I0926 23:24:47.806746  2459 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0926 23:25:01.657300  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:25:02.240396  2459 solver.cpp:330] Iteration 18500, Testing net (#0)
I0926 23:25:05.659802  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:25:05.802410  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7796
I0926 23:25:05.802448  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.66473 (* 1 = 0.66473 loss)
I0926 23:25:05.947139  2459 solver.cpp:218] Iteration 18500 (5.51257 iter/s, 18.1404s/100 iters), loss = 0.335032
I0926 23:25:05.947166  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335032 (* 1 = 0.335032 loss)
I0926 23:25:05.947173  2459 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0926 23:25:20.513744  2459 solver.cpp:218] Iteration 18600 (6.86504 iter/s, 14.5665s/100 iters), loss = 0.318156
I0926 23:25:20.513787  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318156 (* 1 = 0.318156 loss)
I0926 23:25:20.513792  2459 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0926 23:25:35.080626  2459 solver.cpp:218] Iteration 18700 (6.86492 iter/s, 14.5668s/100 iters), loss = 0.435879
I0926 23:25:35.080695  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43588 (* 1 = 0.43588 loss)
I0926 23:25:35.080703  2459 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0926 23:25:49.649813  2459 solver.cpp:218] Iteration 18800 (6.86385 iter/s, 14.5691s/100 iters), loss = 0.343559
I0926 23:25:49.649855  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343559 (* 1 = 0.343559 loss)
I0926 23:25:49.649860  2459 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0926 23:26:04.225594  2459 solver.cpp:218] Iteration 18900 (6.86073 iter/s, 14.5757s/100 iters), loss = 0.274174
I0926 23:26:04.225636  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274174 (* 1 = 0.274174 loss)
I0926 23:26:04.225641  2459 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0926 23:26:18.068972  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:26:18.652370  2459 solver.cpp:330] Iteration 19000, Testing net (#0)
I0926 23:26:22.069663  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:26:22.212076  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8059
I0926 23:26:22.212112  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.580081 (* 1 = 0.580081 loss)
I0926 23:26:22.357058  2459 solver.cpp:218] Iteration 19000 (5.5153 iter/s, 18.1314s/100 iters), loss = 0.333863
I0926 23:26:22.357086  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333863 (* 1 = 0.333863 loss)
I0926 23:26:22.357092  2459 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0926 23:26:36.932201  2459 solver.cpp:218] Iteration 19100 (6.86102 iter/s, 14.5751s/100 iters), loss = 0.271192
I0926 23:26:36.932255  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271192 (* 1 = 0.271192 loss)
I0926 23:26:36.932271  2459 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0926 23:26:51.511425  2459 solver.cpp:218] Iteration 19200 (6.85911 iter/s, 14.5791s/100 iters), loss = 0.464056
I0926 23:26:51.511540  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464057 (* 1 = 0.464057 loss)
I0926 23:26:51.511548  2459 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0926 23:27:06.094455  2459 solver.cpp:218] Iteration 19300 (6.85735 iter/s, 14.5829s/100 iters), loss = 0.555638
I0926 23:27:06.094496  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555638 (* 1 = 0.555638 loss)
I0926 23:27:06.094502  2459 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0926 23:27:20.678010  2459 solver.cpp:218] Iteration 19400 (6.85707 iter/s, 14.5835s/100 iters), loss = 0.379718
I0926 23:27:20.678051  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379718 (* 1 = 0.379718 loss)
I0926 23:27:20.678058  2459 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0926 23:27:34.534595  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:27:35.118957  2459 solver.cpp:330] Iteration 19500, Testing net (#0)
I0926 23:27:38.538071  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:27:38.680358  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7732
I0926 23:27:38.680394  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.667469 (* 1 = 0.667469 loss)
I0926 23:27:38.825825  2459 solver.cpp:218] Iteration 19500 (5.51033 iter/s, 18.1477s/100 iters), loss = 0.356061
I0926 23:27:38.825853  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356062 (* 1 = 0.356062 loss)
I0926 23:27:38.825860  2459 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0926 23:27:53.391180  2459 solver.cpp:218] Iteration 19600 (6.86563 iter/s, 14.5653s/100 iters), loss = 0.261352
I0926 23:27:53.391219  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261352 (* 1 = 0.261352 loss)
I0926 23:27:53.391227  2459 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0926 23:28:07.971261  2459 solver.cpp:218] Iteration 19700 (6.8587 iter/s, 14.58s/100 iters), loss = 0.295847
I0926 23:28:07.971380  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295848 (* 1 = 0.295848 loss)
I0926 23:28:07.971400  2459 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0926 23:28:22.543299  2459 solver.cpp:218] Iteration 19800 (6.86253 iter/s, 14.5719s/100 iters), loss = 0.398362
I0926 23:28:22.543341  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398363 (* 1 = 0.398363 loss)
I0926 23:28:22.543347  2459 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0926 23:28:37.115820  2459 solver.cpp:218] Iteration 19900 (6.86226 iter/s, 14.5725s/100 iters), loss = 0.382253
I0926 23:28:37.115860  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382254 (* 1 = 0.382254 loss)
I0926 23:28:37.115866  2459 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0926 23:28:50.965442  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:28:51.548961  2459 solver.cpp:330] Iteration 20000, Testing net (#0)
I0926 23:28:54.966369  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:28:55.109288  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.755
I0926 23:28:55.109324  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.774807 (* 1 = 0.774807 loss)
I0926 23:28:55.254462  2459 solver.cpp:218] Iteration 20000 (5.51311 iter/s, 18.1386s/100 iters), loss = 0.390289
I0926 23:28:55.254489  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390289 (* 1 = 0.390289 loss)
I0926 23:28:55.254496  2459 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0926 23:29:09.824441  2459 solver.cpp:218] Iteration 20100 (6.86345 iter/s, 14.5699s/100 iters), loss = 0.356618
I0926 23:29:09.824483  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356619 (* 1 = 0.356619 loss)
I0926 23:29:09.824489  2459 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0926 23:29:24.400764  2459 solver.cpp:218] Iteration 20200 (6.86047 iter/s, 14.5763s/100 iters), loss = 0.425616
I0926 23:29:24.400887  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425617 (* 1 = 0.425617 loss)
I0926 23:29:24.400903  2459 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0926 23:29:38.969455  2459 solver.cpp:218] Iteration 20300 (6.8641 iter/s, 14.5686s/100 iters), loss = 0.483351
I0926 23:29:38.969496  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.483351 (* 1 = 0.483351 loss)
I0926 23:29:38.969501  2459 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0926 23:29:53.542088  2459 solver.cpp:218] Iteration 20400 (6.86221 iter/s, 14.5726s/100 iters), loss = 0.419767
I0926 23:29:53.542129  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419767 (* 1 = 0.419767 loss)
I0926 23:29:53.542135  2459 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0926 23:30:07.390074  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:30:07.973533  2459 solver.cpp:330] Iteration 20500, Testing net (#0)
I0926 23:30:11.392081  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:30:11.534827  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7924
I0926 23:30:11.534864  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.646999 (* 1 = 0.646999 loss)
I0926 23:30:11.680369  2459 solver.cpp:218] Iteration 20500 (5.51322 iter/s, 18.1382s/100 iters), loss = 0.299696
I0926 23:30:11.680397  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299697 (* 1 = 0.299697 loss)
I0926 23:30:11.680404  2459 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0926 23:30:26.247081  2459 solver.cpp:218] Iteration 20600 (6.86499 iter/s, 14.5667s/100 iters), loss = 0.278684
I0926 23:30:26.247122  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278685 (* 1 = 0.278685 loss)
I0926 23:30:26.247128  2459 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0926 23:30:40.821941  2459 solver.cpp:218] Iteration 20700 (6.86116 iter/s, 14.5748s/100 iters), loss = 0.321801
I0926 23:30:40.822007  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321802 (* 1 = 0.321802 loss)
I0926 23:30:40.822013  2459 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0926 23:30:55.398875  2459 solver.cpp:218] Iteration 20800 (6.8602 iter/s, 14.5768s/100 iters), loss = 0.487278
I0926 23:30:55.398906  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.487278 (* 1 = 0.487278 loss)
I0926 23:30:55.398911  2459 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0926 23:31:09.970927  2459 solver.cpp:218] Iteration 20900 (6.86248 iter/s, 14.572s/100 iters), loss = 0.31184
I0926 23:31:09.970968  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31184 (* 1 = 0.31184 loss)
I0926 23:31:09.970974  2459 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0926 23:31:23.822504  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:31:24.406122  2459 solver.cpp:330] Iteration 21000, Testing net (#0)
I0926 23:31:27.826458  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:31:27.968691  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8108
I0926 23:31:27.968727  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.554958 (* 1 = 0.554958 loss)
I0926 23:31:28.113504  2459 solver.cpp:218] Iteration 21000 (5.51192 iter/s, 18.1425s/100 iters), loss = 0.320569
I0926 23:31:28.113533  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320569 (* 1 = 0.320569 loss)
I0926 23:31:28.113538  2459 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0926 23:31:42.683270  2459 solver.cpp:218] Iteration 21100 (6.86355 iter/s, 14.5697s/100 iters), loss = 0.302235
I0926 23:31:42.683301  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302236 (* 1 = 0.302236 loss)
I0926 23:31:42.683307  2459 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0926 23:31:57.261173  2459 solver.cpp:218] Iteration 21200 (6.85972 iter/s, 14.5778s/100 iters), loss = 0.319997
I0926 23:31:57.261303  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319997 (* 1 = 0.319997 loss)
I0926 23:31:57.261312  2459 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0926 23:32:11.840204  2459 solver.cpp:218] Iteration 21300 (6.85923 iter/s, 14.5789s/100 iters), loss = 0.343481
I0926 23:32:11.840243  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343481 (* 1 = 0.343481 loss)
I0926 23:32:11.840250  2459 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0926 23:32:26.421216  2459 solver.cpp:218] Iteration 21400 (6.85827 iter/s, 14.5809s/100 iters), loss = 0.324602
I0926 23:32:26.421257  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324602 (* 1 = 0.324602 loss)
I0926 23:32:26.421262  2459 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0926 23:32:40.273430  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:32:40.856377  2459 solver.cpp:330] Iteration 21500, Testing net (#0)
I0926 23:32:44.273838  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:32:44.416720  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8147
I0926 23:32:44.416754  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.543892 (* 1 = 0.543892 loss)
I0926 23:32:44.561789  2459 solver.cpp:218] Iteration 21500 (5.51253 iter/s, 18.1405s/100 iters), loss = 0.38688
I0926 23:32:44.561816  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38688 (* 1 = 0.38688 loss)
I0926 23:32:44.561823  2459 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0926 23:32:59.132638  2459 solver.cpp:218] Iteration 21600 (6.86304 iter/s, 14.5708s/100 iters), loss = 0.353825
I0926 23:32:59.132679  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353825 (* 1 = 0.353825 loss)
I0926 23:32:59.132685  2459 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0926 23:33:13.715595  2459 solver.cpp:218] Iteration 21700 (6.85735 iter/s, 14.5829s/100 iters), loss = 0.379542
I0926 23:33:13.715692  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379543 (* 1 = 0.379543 loss)
I0926 23:33:13.715698  2459 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0926 23:33:28.291501  2459 solver.cpp:218] Iteration 21800 (6.86069 iter/s, 14.5758s/100 iters), loss = 0.382967
I0926 23:33:28.291541  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382968 (* 1 = 0.382968 loss)
I0926 23:33:28.291548  2459 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0926 23:33:42.867059  2459 solver.cpp:218] Iteration 21900 (6.86083 iter/s, 14.5755s/100 iters), loss = 0.328089
I0926 23:33:42.867101  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328089 (* 1 = 0.328089 loss)
I0926 23:33:42.867107  2459 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0926 23:33:56.721077  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:33:57.304141  2459 solver.cpp:330] Iteration 22000, Testing net (#0)
I0926 23:34:00.723567  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:34:00.865703  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7885
I0926 23:34:00.865747  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61608 (* 1 = 0.61608 loss)
I0926 23:34:01.010525  2459 solver.cpp:218] Iteration 22000 (5.51165 iter/s, 18.1434s/100 iters), loss = 0.29056
I0926 23:34:01.010552  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29056 (* 1 = 0.29056 loss)
I0926 23:34:01.010558  2459 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0926 23:34:15.584878  2459 solver.cpp:218] Iteration 22100 (6.86139 iter/s, 14.5743s/100 iters), loss = 0.333145
I0926 23:34:15.584918  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333146 (* 1 = 0.333146 loss)
I0926 23:34:15.584924  2459 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0926 23:34:30.163322  2459 solver.cpp:218] Iteration 22200 (6.85947 iter/s, 14.5784s/100 iters), loss = 0.334275
I0926 23:34:30.163451  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334276 (* 1 = 0.334276 loss)
I0926 23:34:30.163458  2459 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0926 23:34:44.743099  2459 solver.cpp:218] Iteration 22300 (6.85888 iter/s, 14.5796s/100 iters), loss = 0.437352
I0926 23:34:44.743130  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437353 (* 1 = 0.437353 loss)
I0926 23:34:44.743135  2459 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0926 23:34:59.319272  2459 solver.cpp:218] Iteration 22400 (6.86054 iter/s, 14.5761s/100 iters), loss = 0.275443
I0926 23:34:59.319313  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275444 (* 1 = 0.275444 loss)
I0926 23:34:59.319319  2459 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0926 23:35:13.177431  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:35:13.760282  2459 solver.cpp:330] Iteration 22500, Testing net (#0)
I0926 23:35:17.176777  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:35:17.319602  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7776
I0926 23:35:17.319638  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659274 (* 1 = 0.659274 loss)
I0926 23:35:17.464479  2459 solver.cpp:218] Iteration 22500 (5.51112 iter/s, 18.1451s/100 iters), loss = 0.382708
I0926 23:35:17.464506  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382708 (* 1 = 0.382708 loss)
I0926 23:35:17.464514  2459 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0926 23:35:32.021823  2459 solver.cpp:218] Iteration 22600 (6.86941 iter/s, 14.5573s/100 iters), loss = 0.360866
I0926 23:35:32.021863  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360866 (* 1 = 0.360866 loss)
I0926 23:35:32.021869  2459 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0926 23:35:46.596308  2459 solver.cpp:218] Iteration 22700 (6.86134 iter/s, 14.5744s/100 iters), loss = 0.386785
I0926 23:35:46.596428  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386785 (* 1 = 0.386785 loss)
I0926 23:35:46.596446  2459 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0926 23:36:01.174351  2459 solver.cpp:218] Iteration 22800 (6.8597 iter/s, 14.5779s/100 iters), loss = 0.411641
I0926 23:36:01.174381  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411641 (* 1 = 0.411641 loss)
I0926 23:36:01.174386  2459 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0926 23:36:15.749675  2459 solver.cpp:218] Iteration 22900 (6.86094 iter/s, 14.5753s/100 iters), loss = 0.279413
I0926 23:36:15.749704  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279413 (* 1 = 0.279413 loss)
I0926 23:36:15.749709  2459 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0926 23:36:29.596786  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:36:30.180882  2459 solver.cpp:330] Iteration 23000, Testing net (#0)
I0926 23:36:33.599735  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:36:33.742379  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.771
I0926 23:36:33.742406  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.674868 (* 1 = 0.674868 loss)
I0926 23:36:33.887725  2459 solver.cpp:218] Iteration 23000 (5.51329 iter/s, 18.138s/100 iters), loss = 0.362705
I0926 23:36:33.887750  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362705 (* 1 = 0.362705 loss)
I0926 23:36:33.887758  2459 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0926 23:36:48.467887  2459 solver.cpp:218] Iteration 23100 (6.85866 iter/s, 14.5801s/100 iters), loss = 0.284289
I0926 23:36:48.467917  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284289 (* 1 = 0.284289 loss)
I0926 23:36:48.467923  2459 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0926 23:37:03.053781  2459 solver.cpp:218] Iteration 23200 (6.85597 iter/s, 14.5858s/100 iters), loss = 0.355476
I0926 23:37:03.053870  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355476 (* 1 = 0.355476 loss)
I0926 23:37:03.053879  2459 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0926 23:37:17.638530  2459 solver.cpp:218] Iteration 23300 (6.85653 iter/s, 14.5846s/100 iters), loss = 0.295696
I0926 23:37:17.638561  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295696 (* 1 = 0.295696 loss)
I0926 23:37:17.638566  2459 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0926 23:37:32.222877  2459 solver.cpp:218] Iteration 23400 (6.85669 iter/s, 14.5843s/100 iters), loss = 0.296871
I0926 23:37:32.222916  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296871 (* 1 = 0.296871 loss)
I0926 23:37:32.222921  2459 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0926 23:37:46.082384  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:37:46.666043  2459 solver.cpp:330] Iteration 23500, Testing net (#0)
I0926 23:37:50.083813  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:37:50.226606  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7536
I0926 23:37:50.226642  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.724491 (* 1 = 0.724491 loss)
I0926 23:37:50.371747  2459 solver.cpp:218] Iteration 23500 (5.51001 iter/s, 18.1488s/100 iters), loss = 0.247372
I0926 23:37:50.371773  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247372 (* 1 = 0.247372 loss)
I0926 23:37:50.371779  2459 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0926 23:38:04.942832  2459 solver.cpp:218] Iteration 23600 (6.86293 iter/s, 14.571s/100 iters), loss = 0.371189
I0926 23:38:04.942863  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371189 (* 1 = 0.371189 loss)
I0926 23:38:04.942869  2459 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0926 23:38:19.520673  2459 solver.cpp:218] Iteration 23700 (6.85975 iter/s, 14.5778s/100 iters), loss = 0.352956
I0926 23:38:19.520748  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352956 (* 1 = 0.352956 loss)
I0926 23:38:19.520756  2459 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0926 23:38:34.096738  2459 solver.cpp:218] Iteration 23800 (6.86061 iter/s, 14.576s/100 iters), loss = 0.374995
I0926 23:38:34.096779  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374995 (* 1 = 0.374995 loss)
I0926 23:38:34.096784  2459 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0926 23:38:48.674130  2459 solver.cpp:218] Iteration 23900 (6.85997 iter/s, 14.5773s/100 iters), loss = 0.254837
I0926 23:38:48.674161  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254837 (* 1 = 0.254837 loss)
I0926 23:38:48.674167  2459 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0926 23:39:02.528558  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:39:03.111834  2459 solver.cpp:330] Iteration 24000, Testing net (#0)
I0926 23:39:06.529294  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:39:06.671701  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8018
I0926 23:39:06.671737  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.589856 (* 1 = 0.589856 loss)
I0926 23:39:06.817057  2459 solver.cpp:218] Iteration 24000 (5.51181 iter/s, 18.1429s/100 iters), loss = 0.36354
I0926 23:39:06.817085  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36354 (* 1 = 0.36354 loss)
I0926 23:39:06.817091  2459 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0926 23:39:21.394373  2459 solver.cpp:218] Iteration 24100 (6.86 iter/s, 14.5773s/100 iters), loss = 0.324528
I0926 23:39:21.394414  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324528 (* 1 = 0.324528 loss)
I0926 23:39:21.394420  2459 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0926 23:39:35.966951  2459 solver.cpp:218] Iteration 24200 (6.86223 iter/s, 14.5725s/100 iters), loss = 0.41645
I0926 23:39:35.967046  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41645 (* 1 = 0.41645 loss)
I0926 23:39:35.967064  2459 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0926 23:39:50.545814  2459 solver.cpp:218] Iteration 24300 (6.8593 iter/s, 14.5787s/100 iters), loss = 0.410648
I0926 23:39:50.545843  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410648 (* 1 = 0.410648 loss)
I0926 23:39:50.545850  2459 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0926 23:40:05.123060  2459 solver.cpp:218] Iteration 24400 (6.86003 iter/s, 14.5772s/100 iters), loss = 0.302966
I0926 23:40:05.123101  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302966 (* 1 = 0.302966 loss)
I0926 23:40:05.123107  2459 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0926 23:40:18.981294  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:40:19.566007  2459 solver.cpp:330] Iteration 24500, Testing net (#0)
I0926 23:40:22.986343  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:40:23.129181  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7697
I0926 23:40:23.129217  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695063 (* 1 = 0.695063 loss)
I0926 23:40:23.274524  2459 solver.cpp:218] Iteration 24500 (5.50922 iter/s, 18.1514s/100 iters), loss = 0.268014
I0926 23:40:23.274552  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268015 (* 1 = 0.268015 loss)
I0926 23:40:23.274559  2459 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0926 23:40:37.847805  2459 solver.cpp:218] Iteration 24600 (6.8619 iter/s, 14.5732s/100 iters), loss = 0.303568
I0926 23:40:37.847846  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303568 (* 1 = 0.303568 loss)
I0926 23:40:37.847851  2459 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0926 23:40:52.423754  2459 solver.cpp:218] Iteration 24700 (6.86065 iter/s, 14.5759s/100 iters), loss = 0.411605
I0926 23:40:52.423825  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411605 (* 1 = 0.411605 loss)
I0926 23:40:52.423831  2459 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0926 23:41:07.008222  2459 solver.cpp:218] Iteration 24800 (6.85665 iter/s, 14.5844s/100 iters), loss = 0.352722
I0926 23:41:07.008265  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352722 (* 1 = 0.352722 loss)
I0926 23:41:07.008270  2459 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0926 23:41:21.583379  2459 solver.cpp:218] Iteration 24900 (6.86102 iter/s, 14.5751s/100 iters), loss = 0.334124
I0926 23:41:21.583421  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334124 (* 1 = 0.334124 loss)
I0926 23:41:21.583427  2459 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0926 23:41:35.431859  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:41:36.014612  2459 solver.cpp:330] Iteration 25000, Testing net (#0)
I0926 23:41:39.433527  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:41:39.576252  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8063
I0926 23:41:39.576289  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.565799 (* 1 = 0.565799 loss)
I0926 23:41:39.720988  2459 solver.cpp:218] Iteration 25000 (5.51343 iter/s, 18.1375s/100 iters), loss = 0.393061
I0926 23:41:39.721014  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393061 (* 1 = 0.393061 loss)
I0926 23:41:39.721021  2459 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0926 23:41:54.291662  2459 solver.cpp:218] Iteration 25100 (6.86313 iter/s, 14.5706s/100 iters), loss = 0.30808
I0926 23:41:54.291703  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30808 (* 1 = 0.30808 loss)
I0926 23:41:54.291709  2459 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0926 23:42:08.871332  2459 solver.cpp:218] Iteration 25200 (6.8589 iter/s, 14.5796s/100 iters), loss = 0.321966
I0926 23:42:08.871451  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321967 (* 1 = 0.321967 loss)
I0926 23:42:08.871459  2459 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0926 23:42:23.447939  2459 solver.cpp:218] Iteration 25300 (6.86037 iter/s, 14.5765s/100 iters), loss = 0.365361
I0926 23:42:23.447980  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365361 (* 1 = 0.365361 loss)
I0926 23:42:23.447986  2459 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0926 23:42:38.026553  2459 solver.cpp:218] Iteration 25400 (6.85939 iter/s, 14.5785s/100 iters), loss = 0.237967
I0926 23:42:38.026583  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237967 (* 1 = 0.237967 loss)
I0926 23:42:38.026589  2459 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0926 23:42:51.882954  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:42:52.467443  2459 solver.cpp:330] Iteration 25500, Testing net (#0)
I0926 23:42:55.884835  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:42:56.027560  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8121
I0926 23:42:56.027597  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.5535 (* 1 = 0.5535 loss)
I0926 23:42:56.172632  2459 solver.cpp:218] Iteration 25500 (5.51085 iter/s, 18.146s/100 iters), loss = 0.392487
I0926 23:42:56.172657  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392487 (* 1 = 0.392487 loss)
I0926 23:42:56.172664  2459 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0926 23:43:10.753028  2459 solver.cpp:218] Iteration 25600 (6.85855 iter/s, 14.5803s/100 iters), loss = 0.271016
I0926 23:43:10.753070  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271016 (* 1 = 0.271016 loss)
I0926 23:43:10.753077  2459 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0926 23:43:25.334625  2459 solver.cpp:218] Iteration 25700 (6.85799 iter/s, 14.5815s/100 iters), loss = 0.370492
I0926 23:43:25.334751  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370492 (* 1 = 0.370492 loss)
I0926 23:43:25.334769  2459 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0926 23:43:39.915760  2459 solver.cpp:218] Iteration 25800 (6.85825 iter/s, 14.581s/100 iters), loss = 0.33796
I0926 23:43:39.915802  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337961 (* 1 = 0.337961 loss)
I0926 23:43:39.915807  2459 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0926 23:43:54.500496  2459 solver.cpp:218] Iteration 25900 (6.85651 iter/s, 14.5847s/100 iters), loss = 0.236029
I0926 23:43:54.500538  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23603 (* 1 = 0.23603 loss)
I0926 23:43:54.500543  2459 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0926 23:44:08.358237  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:44:08.942479  2459 solver.cpp:330] Iteration 26000, Testing net (#0)
I0926 23:44:12.362175  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:44:12.505012  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7667
I0926 23:44:12.505049  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.724645 (* 1 = 0.724645 loss)
I0926 23:44:12.649981  2459 solver.cpp:218] Iteration 26000 (5.50982 iter/s, 18.1494s/100 iters), loss = 0.34973
I0926 23:44:12.650007  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34973 (* 1 = 0.34973 loss)
I0926 23:44:12.650013  2459 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0926 23:44:27.218588  2459 solver.cpp:218] Iteration 26100 (6.8641 iter/s, 14.5686s/100 iters), loss = 0.319338
I0926 23:44:27.218629  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319339 (* 1 = 0.319339 loss)
I0926 23:44:27.218636  2459 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0926 23:44:41.789633  2459 solver.cpp:218] Iteration 26200 (6.86296 iter/s, 14.571s/100 iters), loss = 0.428023
I0926 23:44:41.789746  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428023 (* 1 = 0.428023 loss)
I0926 23:44:41.789753  2459 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0926 23:44:56.360296  2459 solver.cpp:218] Iteration 26300 (6.86316 iter/s, 14.5705s/100 iters), loss = 0.437148
I0926 23:44:56.360335  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437148 (* 1 = 0.437148 loss)
I0926 23:44:56.360342  2459 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0926 23:45:10.939818  2459 solver.cpp:218] Iteration 26400 (6.85897 iter/s, 14.5795s/100 iters), loss = 0.172002
I0926 23:45:10.939859  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172002 (* 1 = 0.172002 loss)
I0926 23:45:10.939865  2459 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0926 23:45:24.790690  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:45:25.373545  2459 solver.cpp:330] Iteration 26500, Testing net (#0)
I0926 23:45:28.792852  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:45:28.935510  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.791
I0926 23:45:28.935547  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.620547 (* 1 = 0.620547 loss)
I0926 23:45:29.080571  2459 solver.cpp:218] Iteration 26500 (5.51247 iter/s, 18.1407s/100 iters), loss = 0.296062
I0926 23:45:29.080598  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296062 (* 1 = 0.296062 loss)
I0926 23:45:29.080605  2459 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0926 23:45:43.656546  2459 solver.cpp:218] Iteration 26600 (6.86063 iter/s, 14.5759s/100 iters), loss = 0.249661
I0926 23:45:43.656589  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249661 (* 1 = 0.249661 loss)
I0926 23:45:43.656594  2459 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0926 23:45:58.237021  2459 solver.cpp:218] Iteration 26700 (6.85852 iter/s, 14.5804s/100 iters), loss = 0.349947
I0926 23:45:58.237102  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349948 (* 1 = 0.349948 loss)
I0926 23:45:58.237112  2459 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0926 23:46:12.815528  2459 solver.cpp:218] Iteration 26800 (6.85946 iter/s, 14.5784s/100 iters), loss = 0.375274
I0926 23:46:12.815569  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375274 (* 1 = 0.375274 loss)
I0926 23:46:12.815574  2459 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0926 23:46:27.393481  2459 solver.cpp:218] Iteration 26900 (6.85971 iter/s, 14.5779s/100 iters), loss = 0.376249
I0926 23:46:27.393520  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376249 (* 1 = 0.376249 loss)
I0926 23:46:27.393527  2459 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0926 23:46:41.246932  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:46:41.829668  2459 solver.cpp:330] Iteration 27000, Testing net (#0)
I0926 23:46:45.246728  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:46:45.389330  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8143
I0926 23:46:45.389366  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.546789 (* 1 = 0.546789 loss)
I0926 23:46:45.534406  2459 solver.cpp:218] Iteration 27000 (5.51242 iter/s, 18.1409s/100 iters), loss = 0.279667
I0926 23:46:45.534433  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279667 (* 1 = 0.279667 loss)
I0926 23:46:45.534440  2459 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0926 23:47:00.116916  2459 solver.cpp:218] Iteration 27100 (6.85756 iter/s, 14.5825s/100 iters), loss = 0.341527
I0926 23:47:00.116945  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341528 (* 1 = 0.341528 loss)
I0926 23:47:00.116951  2459 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0926 23:47:14.703317  2459 solver.cpp:218] Iteration 27200 (6.85573 iter/s, 14.5863s/100 iters), loss = 0.295479
I0926 23:47:14.703481  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295479 (* 1 = 0.295479 loss)
I0926 23:47:14.703492  2459 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0926 23:47:29.284031  2459 solver.cpp:218] Iteration 27300 (6.85846 iter/s, 14.5805s/100 iters), loss = 0.394927
I0926 23:47:29.284073  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394927 (* 1 = 0.394927 loss)
I0926 23:47:29.284078  2459 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0926 23:47:43.872123  2459 solver.cpp:218] Iteration 27400 (6.85494 iter/s, 14.588s/100 iters), loss = 0.269678
I0926 23:47:43.872164  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269678 (* 1 = 0.269678 loss)
I0926 23:47:43.872169  2459 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0926 23:47:57.730353  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:47:58.313257  2459 solver.cpp:330] Iteration 27500, Testing net (#0)
I0926 23:48:01.731962  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:48:01.874557  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8244
I0926 23:48:01.874583  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.51557 (* 1 = 0.51557 loss)
I0926 23:48:02.019469  2459 solver.cpp:218] Iteration 27500 (5.51047 iter/s, 18.1473s/100 iters), loss = 0.277506
I0926 23:48:02.019495  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277507 (* 1 = 0.277507 loss)
I0926 23:48:02.019502  2459 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0926 23:48:16.581049  2459 solver.cpp:218] Iteration 27600 (6.86741 iter/s, 14.5615s/100 iters), loss = 0.245692
I0926 23:48:16.581089  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245692 (* 1 = 0.245692 loss)
I0926 23:48:16.581094  2459 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0926 23:48:31.153959  2459 solver.cpp:218] Iteration 27700 (6.86208 iter/s, 14.5728s/100 iters), loss = 0.251431
I0926 23:48:31.154079  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251431 (* 1 = 0.251431 loss)
I0926 23:48:31.154096  2459 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0926 23:48:45.726371  2459 solver.cpp:218] Iteration 27800 (6.86235 iter/s, 14.5723s/100 iters), loss = 0.405178
I0926 23:48:45.726402  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405178 (* 1 = 0.405178 loss)
I0926 23:48:45.726406  2459 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0926 23:49:00.298511  2459 solver.cpp:218] Iteration 27900 (6.86244 iter/s, 14.5721s/100 iters), loss = 0.272395
I0926 23:49:00.298542  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272395 (* 1 = 0.272395 loss)
I0926 23:49:00.298547  2459 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0926 23:49:14.147176  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:49:14.732036  2459 solver.cpp:330] Iteration 28000, Testing net (#0)
I0926 23:49:18.149099  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:49:18.292063  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8051
I0926 23:49:18.292099  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.57705 (* 1 = 0.57705 loss)
I0926 23:49:18.436074  2459 solver.cpp:218] Iteration 28000 (5.51344 iter/s, 18.1375s/100 iters), loss = 0.234658
I0926 23:49:18.436100  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234658 (* 1 = 0.234658 loss)
I0926 23:49:18.436107  2459 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0926 23:49:33.011857  2459 solver.cpp:218] Iteration 28100 (6.86072 iter/s, 14.5757s/100 iters), loss = 0.405147
I0926 23:49:33.011884  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405147 (* 1 = 0.405147 loss)
I0926 23:49:33.011890  2459 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0926 23:49:47.592175  2459 solver.cpp:218] Iteration 28200 (6.85859 iter/s, 14.5803s/100 iters), loss = 0.256223
I0926 23:49:47.592285  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256223 (* 1 = 0.256223 loss)
I0926 23:49:47.592293  2459 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0926 23:50:02.173615  2459 solver.cpp:218] Iteration 28300 (6.8581 iter/s, 14.5813s/100 iters), loss = 0.32968
I0926 23:50:02.173655  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32968 (* 1 = 0.32968 loss)
I0926 23:50:02.173661  2459 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0926 23:50:16.756520  2459 solver.cpp:218] Iteration 28400 (6.85738 iter/s, 14.5828s/100 iters), loss = 0.306569
I0926 23:50:16.756549  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306569 (* 1 = 0.306569 loss)
I0926 23:50:16.756556  2459 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0926 23:50:30.614560  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:50:31.197693  2459 solver.cpp:330] Iteration 28500, Testing net (#0)
I0926 23:50:34.614883  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:50:34.757585  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7836
I0926 23:50:34.757621  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663802 (* 1 = 0.663802 loss)
I0926 23:50:34.902422  2459 solver.cpp:218] Iteration 28500 (5.5109 iter/s, 18.1458s/100 iters), loss = 0.324194
I0926 23:50:34.902451  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324195 (* 1 = 0.324195 loss)
I0926 23:50:34.902457  2459 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0926 23:50:49.487341  2459 solver.cpp:218] Iteration 28600 (6.85642 iter/s, 14.5849s/100 iters), loss = 0.238729
I0926 23:50:49.487373  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238729 (* 1 = 0.238729 loss)
I0926 23:50:49.487380  2459 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0926 23:51:04.070871  2459 solver.cpp:218] Iteration 28700 (6.85708 iter/s, 14.5835s/100 iters), loss = 0.346595
I0926 23:51:04.071015  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346595 (* 1 = 0.346595 loss)
I0926 23:51:04.071024  2459 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0926 23:51:18.658126  2459 solver.cpp:218] Iteration 28800 (6.85537 iter/s, 14.5871s/100 iters), loss = 0.437905
I0926 23:51:18.658167  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437905 (* 1 = 0.437905 loss)
I0926 23:51:18.658174  2459 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0926 23:51:33.241992  2459 solver.cpp:218] Iteration 28900 (6.85692 iter/s, 14.5838s/100 iters), loss = 0.232643
I0926 23:51:33.242031  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232643 (* 1 = 0.232643 loss)
I0926 23:51:33.242038  2459 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0926 23:51:47.102807  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:51:47.686545  2459 solver.cpp:330] Iteration 29000, Testing net (#0)
I0926 23:51:51.104594  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:51:51.247014  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.775
I0926 23:51:51.247051  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684452 (* 1 = 0.684452 loss)
I0926 23:51:51.392029  2459 solver.cpp:218] Iteration 29000 (5.50965 iter/s, 18.15s/100 iters), loss = 0.247144
I0926 23:51:51.392055  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247144 (* 1 = 0.247144 loss)
I0926 23:51:51.392061  2459 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0926 23:52:05.962888  2459 solver.cpp:218] Iteration 29100 (6.86304 iter/s, 14.5708s/100 iters), loss = 0.332889
I0926 23:52:05.962929  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332889 (* 1 = 0.332889 loss)
I0926 23:52:05.962934  2459 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0926 23:52:20.535979  2459 solver.cpp:218] Iteration 29200 (6.86199 iter/s, 14.573s/100 iters), loss = 0.403929
I0926 23:52:20.536105  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403929 (* 1 = 0.403929 loss)
I0926 23:52:20.536113  2459 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0926 23:52:35.111635  2459 solver.cpp:218] Iteration 29300 (6.86083 iter/s, 14.5755s/100 iters), loss = 0.390302
I0926 23:52:35.111676  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390302 (* 1 = 0.390302 loss)
I0926 23:52:35.111682  2459 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0926 23:52:49.687180  2459 solver.cpp:218] Iteration 29400 (6.86084 iter/s, 14.5755s/100 iters), loss = 0.326419
I0926 23:52:49.687222  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326419 (* 1 = 0.326419 loss)
I0926 23:52:49.687227  2459 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0926 23:53:03.542503  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:53:04.125241  2459 solver.cpp:330] Iteration 29500, Testing net (#0)
I0926 23:53:07.543606  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:53:07.686059  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7393
I0926 23:53:07.686095  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.757362 (* 1 = 0.757362 loss)
I0926 23:53:07.830943  2459 solver.cpp:218] Iteration 29500 (5.51156 iter/s, 18.1437s/100 iters), loss = 0.36439
I0926 23:53:07.830971  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36439 (* 1 = 0.36439 loss)
I0926 23:53:07.830978  2459 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0926 23:53:22.403556  2459 solver.cpp:218] Iteration 29600 (6.86221 iter/s, 14.5726s/100 iters), loss = 0.268876
I0926 23:53:22.403599  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268876 (* 1 = 0.268876 loss)
I0926 23:53:22.403604  2459 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0926 23:53:36.975088  2459 solver.cpp:218] Iteration 29700 (6.86273 iter/s, 14.5715s/100 iters), loss = 0.392543
I0926 23:53:36.975203  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392543 (* 1 = 0.392543 loss)
I0926 23:53:36.975219  2459 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0926 23:53:51.551656  2459 solver.cpp:218] Iteration 29800 (6.86039 iter/s, 14.5764s/100 iters), loss = 0.236333
I0926 23:53:51.551699  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236333 (* 1 = 0.236333 loss)
I0926 23:53:51.551704  2459 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0926 23:54:06.121750  2459 solver.cpp:218] Iteration 29900 (6.86341 iter/s, 14.57s/100 iters), loss = 0.194468
I0926 23:54:06.121791  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194469 (* 1 = 0.194469 loss)
I0926 23:54:06.121798  2459 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0926 23:54:19.969137  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:54:20.553243  2459 solver.cpp:330] Iteration 30000, Testing net (#0)
I0926 23:54:23.968673  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:54:24.111268  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8094
I0926 23:54:24.111302  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.576812 (* 1 = 0.576812 loss)
I0926 23:54:24.256230  2459 solver.cpp:218] Iteration 30000 (5.51438 iter/s, 18.1344s/100 iters), loss = 0.253633
I0926 23:54:24.256258  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253633 (* 1 = 0.253633 loss)
I0926 23:54:24.256264  2459 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0926 23:54:38.826179  2459 solver.cpp:218] Iteration 30100 (6.86347 iter/s, 14.5699s/100 iters), loss = 0.24454
I0926 23:54:38.826220  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244541 (* 1 = 0.244541 loss)
I0926 23:54:38.826225  2459 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0926 23:54:53.401705  2459 solver.cpp:218] Iteration 30200 (6.86085 iter/s, 14.5755s/100 iters), loss = 0.278121
I0926 23:54:53.401824  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278121 (* 1 = 0.278121 loss)
I0926 23:54:53.401832  2459 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0926 23:55:07.982415  2459 solver.cpp:218] Iteration 30300 (6.85844 iter/s, 14.5806s/100 iters), loss = 0.306743
I0926 23:55:07.982457  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306744 (* 1 = 0.306744 loss)
I0926 23:55:07.982463  2459 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0926 23:55:22.561684  2459 solver.cpp:218] Iteration 30400 (6.85909 iter/s, 14.5792s/100 iters), loss = 0.226209
I0926 23:55:22.561727  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22621 (* 1 = 0.22621 loss)
I0926 23:55:22.561733  2459 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0926 23:55:36.415237  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:55:36.998141  2459 solver.cpp:330] Iteration 30500, Testing net (#0)
I0926 23:55:40.415751  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:55:40.558583  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.781
I0926 23:55:40.558619  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.69026 (* 1 = 0.69026 loss)
I0926 23:55:40.703212  2459 solver.cpp:218] Iteration 30500 (5.51224 iter/s, 18.1415s/100 iters), loss = 0.282419
I0926 23:55:40.703239  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282419 (* 1 = 0.282419 loss)
I0926 23:55:40.703245  2459 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0926 23:55:55.275902  2459 solver.cpp:218] Iteration 30600 (6.86218 iter/s, 14.5726s/100 iters), loss = 0.290503
I0926 23:55:55.275943  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290503 (* 1 = 0.290503 loss)
I0926 23:55:55.275949  2459 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0926 23:56:09.853869  2459 solver.cpp:218] Iteration 30700 (6.8597 iter/s, 14.5779s/100 iters), loss = 0.398394
I0926 23:56:09.853978  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398394 (* 1 = 0.398394 loss)
I0926 23:56:09.853986  2459 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0926 23:56:24.421927  2459 solver.cpp:218] Iteration 30800 (6.86439 iter/s, 14.5679s/100 iters), loss = 0.414786
I0926 23:56:24.421968  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414786 (* 1 = 0.414786 loss)
I0926 23:56:24.421973  2459 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0926 23:56:38.992977  2459 solver.cpp:218] Iteration 30900 (6.86296 iter/s, 14.571s/100 iters), loss = 0.30466
I0926 23:56:38.993017  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30466 (* 1 = 0.30466 loss)
I0926 23:56:38.993023  2459 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0926 23:56:52.844528  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:56:53.427227  2459 solver.cpp:330] Iteration 31000, Testing net (#0)
I0926 23:56:56.845211  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:56:56.987520  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7666
I0926 23:56:56.987555  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.720469 (* 1 = 0.720469 loss)
I0926 23:56:57.132459  2459 solver.cpp:218] Iteration 31000 (5.51286 iter/s, 18.1394s/100 iters), loss = 0.374664
I0926 23:56:57.132488  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374665 (* 1 = 0.374665 loss)
I0926 23:56:57.132494  2459 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0926 23:57:11.702956  2459 solver.cpp:218] Iteration 31100 (6.86321 iter/s, 14.5704s/100 iters), loss = 0.271318
I0926 23:57:11.702986  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271319 (* 1 = 0.271319 loss)
I0926 23:57:11.702991  2459 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0926 23:57:26.277842  2459 solver.cpp:218] Iteration 31200 (6.86114 iter/s, 14.5748s/100 iters), loss = 0.371126
I0926 23:57:26.277984  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371127 (* 1 = 0.371127 loss)
I0926 23:57:26.277992  2459 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0926 23:57:40.848863  2459 solver.cpp:218] Iteration 31300 (6.86302 iter/s, 14.5709s/100 iters), loss = 0.390701
I0926 23:57:40.848893  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390701 (* 1 = 0.390701 loss)
I0926 23:57:40.848898  2459 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0926 23:57:55.417620  2459 solver.cpp:218] Iteration 31400 (6.86403 iter/s, 14.5687s/100 iters), loss = 0.203997
I0926 23:57:55.417650  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203998 (* 1 = 0.203998 loss)
I0926 23:57:55.417656  2459 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0926 23:58:09.267282  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:58:09.851374  2459 solver.cpp:330] Iteration 31500, Testing net (#0)
I0926 23:58:13.269938  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:58:13.412705  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7481
I0926 23:58:13.412741  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.820672 (* 1 = 0.820672 loss)
I0926 23:58:13.557832  2459 solver.cpp:218] Iteration 31500 (5.51263 iter/s, 18.1402s/100 iters), loss = 0.198875
I0926 23:58:13.557857  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198875 (* 1 = 0.198875 loss)
I0926 23:58:13.557864  2459 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0926 23:58:28.137897  2459 solver.cpp:218] Iteration 31600 (6.8587 iter/s, 14.58s/100 iters), loss = 0.253732
I0926 23:58:28.137928  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253733 (* 1 = 0.253733 loss)
I0926 23:58:28.137934  2459 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0926 23:58:42.720177  2459 solver.cpp:218] Iteration 31700 (6.85766 iter/s, 14.5822s/100 iters), loss = 0.334676
I0926 23:58:42.720296  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334676 (* 1 = 0.334676 loss)
I0926 23:58:42.720304  2459 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0926 23:58:57.302042  2459 solver.cpp:218] Iteration 31800 (6.8579 iter/s, 14.5817s/100 iters), loss = 0.361838
I0926 23:58:57.302081  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361839 (* 1 = 0.361839 loss)
I0926 23:58:57.302088  2459 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0926 23:59:11.888183  2459 solver.cpp:218] Iteration 31900 (6.85585 iter/s, 14.5861s/100 iters), loss = 0.281303
I0926 23:59:11.888226  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281303 (* 1 = 0.281303 loss)
I0926 23:59:11.888231  2459 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0926 23:59:25.744166  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:59:26.327409  2459 solver.cpp:330] Iteration 32000, Testing net (#0)
I0926 23:59:29.746172  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0926 23:59:29.888141  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.74
I0926 23:59:29.888177  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.836387 (* 1 = 0.836387 loss)
I0926 23:59:30.032922  2459 solver.cpp:218] Iteration 32000 (5.51126 iter/s, 18.1447s/100 iters), loss = 0.371709
I0926 23:59:30.032949  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371709 (* 1 = 0.371709 loss)
I0926 23:59:30.032955  2459 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0926 23:59:44.603600  2459 solver.cpp:218] Iteration 32100 (6.86312 iter/s, 14.5706s/100 iters), loss = 0.347075
I0926 23:59:44.603641  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347075 (* 1 = 0.347075 loss)
I0926 23:59:44.603646  2459 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0926 23:59:59.177698  2459 solver.cpp:218] Iteration 32200 (6.86152 iter/s, 14.574s/100 iters), loss = 0.379868
I0926 23:59:59.177856  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379869 (* 1 = 0.379869 loss)
I0926 23:59:59.177875  2459 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0927 00:00:13.754349  2459 solver.cpp:218] Iteration 32300 (6.86037 iter/s, 14.5765s/100 iters), loss = 0.27792
I0927 00:00:13.754379  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277921 (* 1 = 0.277921 loss)
I0927 00:00:13.754385  2459 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0927 00:00:28.329891  2459 solver.cpp:218] Iteration 32400 (6.86083 iter/s, 14.5755s/100 iters), loss = 0.267757
I0927 00:00:28.329932  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267757 (* 1 = 0.267757 loss)
I0927 00:00:28.329938  2459 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0927 00:00:42.181694  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:00:42.764494  2459 solver.cpp:330] Iteration 32500, Testing net (#0)
I0927 00:00:46.181344  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:00:46.323822  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7323
I0927 00:00:46.323858  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.877081 (* 1 = 0.877081 loss)
I0927 00:00:46.468924  2459 solver.cpp:218] Iteration 32500 (5.51299 iter/s, 18.139s/100 iters), loss = 0.29844
I0927 00:00:46.468950  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29844 (* 1 = 0.29844 loss)
I0927 00:00:46.468957  2459 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0927 00:01:01.048997  2459 solver.cpp:218] Iteration 32600 (6.8587 iter/s, 14.58s/100 iters), loss = 0.21793
I0927 00:01:01.049039  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21793 (* 1 = 0.21793 loss)
I0927 00:01:01.049046  2459 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0927 00:01:15.628319  2459 solver.cpp:218] Iteration 32700 (6.85906 iter/s, 14.5793s/100 iters), loss = 0.319013
I0927 00:01:15.628386  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319013 (* 1 = 0.319013 loss)
I0927 00:01:15.628392  2459 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0927 00:01:30.209448  2459 solver.cpp:218] Iteration 32800 (6.85822 iter/s, 14.581s/100 iters), loss = 0.25692
I0927 00:01:30.209488  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25692 (* 1 = 0.25692 loss)
I0927 00:01:30.209494  2459 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0927 00:01:44.790403  2459 solver.cpp:218] Iteration 32900 (6.85829 iter/s, 14.5809s/100 iters), loss = 0.254365
I0927 00:01:44.790433  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254365 (* 1 = 0.254365 loss)
I0927 00:01:44.790439  2459 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0927 00:01:58.646178  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:01:59.230321  2459 solver.cpp:330] Iteration 33000, Testing net (#0)
I0927 00:02:02.650048  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:02:02.792439  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7978
I0927 00:02:02.792466  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600897 (* 1 = 0.600897 loss)
I0927 00:02:02.938356  2459 solver.cpp:218] Iteration 33000 (5.51028 iter/s, 18.1479s/100 iters), loss = 0.230988
I0927 00:02:02.938385  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230988 (* 1 = 0.230988 loss)
I0927 00:02:02.938391  2459 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0927 00:02:17.519801  2459 solver.cpp:218] Iteration 33100 (6.85806 iter/s, 14.5814s/100 iters), loss = 0.270666
I0927 00:02:17.519841  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270666 (* 1 = 0.270666 loss)
I0927 00:02:17.519846  2459 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0927 00:02:32.102366  2459 solver.cpp:218] Iteration 33200 (6.85754 iter/s, 14.5825s/100 iters), loss = 0.287296
I0927 00:02:32.102491  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287297 (* 1 = 0.287297 loss)
I0927 00:02:32.102509  2459 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0927 00:02:46.672317  2459 solver.cpp:218] Iteration 33300 (6.86351 iter/s, 14.5698s/100 iters), loss = 0.422774
I0927 00:02:46.672358  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422774 (* 1 = 0.422774 loss)
I0927 00:02:46.672363  2459 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0927 00:03:01.243355  2459 solver.cpp:218] Iteration 33400 (6.86296 iter/s, 14.571s/100 iters), loss = 0.288501
I0927 00:03:01.243396  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288501 (* 1 = 0.288501 loss)
I0927 00:03:01.243402  2459 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0927 00:03:15.086876  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:03:15.669625  2459 solver.cpp:330] Iteration 33500, Testing net (#0)
I0927 00:03:19.085819  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:03:19.228564  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7838
I0927 00:03:19.228606  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.620476 (* 1 = 0.620476 loss)
I0927 00:03:19.374050  2459 solver.cpp:218] Iteration 33500 (5.51553 iter/s, 18.1306s/100 iters), loss = 0.284119
I0927 00:03:19.374078  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28412 (* 1 = 0.28412 loss)
I0927 00:03:19.374085  2459 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0927 00:03:33.950960  2459 solver.cpp:218] Iteration 33600 (6.86019 iter/s, 14.5769s/100 iters), loss = 0.266411
I0927 00:03:33.951001  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266411 (* 1 = 0.266411 loss)
I0927 00:03:33.951007  2459 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0927 00:03:48.529567  2459 solver.cpp:218] Iteration 33700 (6.8594 iter/s, 14.5785s/100 iters), loss = 0.279349
I0927 00:03:48.529645  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27935 (* 1 = 0.27935 loss)
I0927 00:03:48.529652  2459 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0927 00:04:03.108669  2459 solver.cpp:218] Iteration 33800 (6.85918 iter/s, 14.579s/100 iters), loss = 0.384012
I0927 00:04:03.108700  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384012 (* 1 = 0.384012 loss)
I0927 00:04:03.108706  2459 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0927 00:04:17.685407  2459 solver.cpp:218] Iteration 33900 (6.86027 iter/s, 14.5767s/100 iters), loss = 0.236325
I0927 00:04:17.685446  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236325 (* 1 = 0.236325 loss)
I0927 00:04:17.685452  2459 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0927 00:04:31.542667  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:04:32.124908  2459 solver.cpp:330] Iteration 34000, Testing net (#0)
I0927 00:04:35.543856  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:04:35.686396  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7432
I0927 00:04:35.686434  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.800216 (* 1 = 0.800216 loss)
I0927 00:04:35.831480  2459 solver.cpp:218] Iteration 34000 (5.51085 iter/s, 18.146s/100 iters), loss = 0.289356
I0927 00:04:35.831507  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289356 (* 1 = 0.289356 loss)
I0927 00:04:35.831513  2459 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0927 00:04:50.406978  2459 solver.cpp:218] Iteration 34100 (6.86085 iter/s, 14.5754s/100 iters), loss = 0.213658
I0927 00:04:50.407021  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213658 (* 1 = 0.213658 loss)
I0927 00:04:50.407025  2459 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0927 00:05:04.984760  2459 solver.cpp:218] Iteration 34200 (6.85979 iter/s, 14.5777s/100 iters), loss = 0.336253
I0927 00:05:04.984858  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336253 (* 1 = 0.336253 loss)
I0927 00:05:04.984865  2459 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0927 00:05:19.569216  2459 solver.cpp:218] Iteration 34300 (6.85667 iter/s, 14.5843s/100 iters), loss = 0.30218
I0927 00:05:19.569250  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30218 (* 1 = 0.30218 loss)
I0927 00:05:19.569257  2459 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0927 00:05:34.155561  2459 solver.cpp:218] Iteration 34400 (6.85575 iter/s, 14.5863s/100 iters), loss = 0.272919
I0927 00:05:34.155602  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272919 (* 1 = 0.272919 loss)
I0927 00:05:34.155607  2459 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0927 00:05:48.022563  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:05:48.607549  2459 solver.cpp:330] Iteration 34500, Testing net (#0)
I0927 00:05:52.024641  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:05:52.167069  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.797
I0927 00:05:52.167105  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.605857 (* 1 = 0.605857 loss)
I0927 00:05:52.311694  2459 solver.cpp:218] Iteration 34500 (5.5078 iter/s, 18.1561s/100 iters), loss = 0.29763
I0927 00:05:52.311720  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29763 (* 1 = 0.29763 loss)
I0927 00:05:52.311728  2459 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0927 00:06:06.888847  2459 solver.cpp:218] Iteration 34600 (6.86007 iter/s, 14.5771s/100 iters), loss = 0.191882
I0927 00:06:06.888888  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191882 (* 1 = 0.191882 loss)
I0927 00:06:06.888893  2459 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0927 00:06:21.464661  2459 solver.cpp:218] Iteration 34700 (6.86071 iter/s, 14.5757s/100 iters), loss = 0.25189
I0927 00:06:21.464740  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25189 (* 1 = 0.25189 loss)
I0927 00:06:21.464746  2459 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0927 00:06:36.039522  2459 solver.cpp:218] Iteration 34800 (6.86118 iter/s, 14.5748s/100 iters), loss = 0.395796
I0927 00:06:36.039564  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395797 (* 1 = 0.395797 loss)
I0927 00:06:36.039571  2459 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0927 00:06:50.614228  2459 solver.cpp:218] Iteration 34900 (6.86123 iter/s, 14.5746s/100 iters), loss = 0.215113
I0927 00:06:50.614259  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215114 (* 1 = 0.215114 loss)
I0927 00:06:50.614264  2459 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0927 00:07:04.462532  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:07:05.044872  2459 solver.cpp:330] Iteration 35000, Testing net (#0)
I0927 00:07:08.463726  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:07:08.605873  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.782
I0927 00:07:08.605909  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.636158 (* 1 = 0.636158 loss)
I0927 00:07:08.751130  2459 solver.cpp:218] Iteration 35000 (5.51364 iter/s, 18.1368s/100 iters), loss = 0.353496
I0927 00:07:08.751159  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353496 (* 1 = 0.353496 loss)
I0927 00:07:08.751165  2459 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0927 00:07:23.341020  2459 solver.cpp:218] Iteration 35100 (6.85409 iter/s, 14.5898s/100 iters), loss = 0.250367
I0927 00:07:23.341060  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250367 (* 1 = 0.250367 loss)
I0927 00:07:23.341066  2459 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0927 00:07:37.934630  2459 solver.cpp:218] Iteration 35200 (6.85234 iter/s, 14.5935s/100 iters), loss = 0.235833
I0927 00:07:37.934737  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235834 (* 1 = 0.235834 loss)
I0927 00:07:37.934746  2459 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0927 00:07:52.529563  2459 solver.cpp:218] Iteration 35300 (6.85175 iter/s, 14.5948s/100 iters), loss = 0.444772
I0927 00:07:52.529604  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444772 (* 1 = 0.444772 loss)
I0927 00:07:52.529609  2459 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0927 00:08:07.126646  2459 solver.cpp:218] Iteration 35400 (6.85072 iter/s, 14.597s/100 iters), loss = 0.281237
I0927 00:08:07.126685  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281237 (* 1 = 0.281237 loss)
I0927 00:08:07.126691  2459 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0927 00:08:20.998306  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:08:21.582566  2459 solver.cpp:330] Iteration 35500, Testing net (#0)
I0927 00:08:25.000202  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:08:25.142693  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.781
I0927 00:08:25.142729  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658827 (* 1 = 0.658827 loss)
I0927 00:08:25.287904  2459 solver.cpp:218] Iteration 35500 (5.50625 iter/s, 18.1612s/100 iters), loss = 0.22172
I0927 00:08:25.287930  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221721 (* 1 = 0.221721 loss)
I0927 00:08:25.287936  2459 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0927 00:08:39.865906  2459 solver.cpp:218] Iteration 35600 (6.85968 iter/s, 14.5779s/100 iters), loss = 0.258233
I0927 00:08:39.865936  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258233 (* 1 = 0.258233 loss)
I0927 00:08:39.865942  2459 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0927 00:08:54.442942  2459 solver.cpp:218] Iteration 35700 (6.86013 iter/s, 14.577s/100 iters), loss = 0.381985
I0927 00:08:54.443053  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381986 (* 1 = 0.381986 loss)
I0927 00:08:54.443069  2459 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0927 00:09:09.026914  2459 solver.cpp:218] Iteration 35800 (6.8569 iter/s, 14.5838s/100 iters), loss = 0.384827
I0927 00:09:09.026955  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384828 (* 1 = 0.384828 loss)
I0927 00:09:09.026962  2459 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0927 00:09:23.609215  2459 solver.cpp:218] Iteration 35900 (6.85766 iter/s, 14.5822s/100 iters), loss = 0.218224
I0927 00:09:23.609246  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218225 (* 1 = 0.218225 loss)
I0927 00:09:23.609251  2459 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0927 00:09:37.469121  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:09:38.052295  2459 solver.cpp:330] Iteration 36000, Testing net (#0)
I0927 00:09:41.470350  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:09:41.613263  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7783
I0927 00:09:41.613289  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.67725 (* 1 = 0.67725 loss)
I0927 00:09:41.757967  2459 solver.cpp:218] Iteration 36000 (5.51004 iter/s, 18.1487s/100 iters), loss = 0.240973
I0927 00:09:41.757995  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240974 (* 1 = 0.240974 loss)
I0927 00:09:41.758002  2459 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0927 00:09:56.328683  2459 solver.cpp:218] Iteration 36100 (6.86311 iter/s, 14.5707s/100 iters), loss = 0.289015
I0927 00:09:56.328714  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289016 (* 1 = 0.289016 loss)
I0927 00:09:56.328721  2459 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0927 00:10:10.912456  2459 solver.cpp:218] Iteration 36200 (6.85696 iter/s, 14.5837s/100 iters), loss = 0.380995
I0927 00:10:10.912577  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380996 (* 1 = 0.380996 loss)
I0927 00:10:10.912586  2459 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0927 00:10:25.499203  2459 solver.cpp:218] Iteration 36300 (6.85561 iter/s, 14.5866s/100 iters), loss = 0.303206
I0927 00:10:25.499234  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303206 (* 1 = 0.303206 loss)
I0927 00:10:25.499250  2459 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0927 00:10:40.085572  2459 solver.cpp:218] Iteration 36400 (6.85574 iter/s, 14.5863s/100 iters), loss = 0.242509
I0927 00:10:40.085602  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242509 (* 1 = 0.242509 loss)
I0927 00:10:40.085608  2459 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0927 00:10:53.938566  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:10:54.521467  2459 solver.cpp:330] Iteration 36500, Testing net (#0)
I0927 00:10:57.938715  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:10:58.081778  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7645
I0927 00:10:58.081814  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.731218 (* 1 = 0.731218 loss)
I0927 00:10:58.227005  2459 solver.cpp:218] Iteration 36500 (5.51226 iter/s, 18.1414s/100 iters), loss = 0.273542
I0927 00:10:58.227032  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273542 (* 1 = 0.273542 loss)
I0927 00:10:58.227039  2459 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0927 00:11:12.808720  2459 solver.cpp:218] Iteration 36600 (6.85793 iter/s, 14.5817s/100 iters), loss = 0.270198
I0927 00:11:12.808778  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270198 (* 1 = 0.270198 loss)
I0927 00:11:12.808784  2459 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0927 00:11:27.390269  2459 solver.cpp:218] Iteration 36700 (6.85802 iter/s, 14.5815s/100 iters), loss = 0.291191
I0927 00:11:27.390375  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291191 (* 1 = 0.291191 loss)
I0927 00:11:27.390383  2459 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0927 00:11:41.974316  2459 solver.cpp:218] Iteration 36800 (6.85687 iter/s, 14.5839s/100 iters), loss = 0.302395
I0927 00:11:41.974356  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302395 (* 1 = 0.302395 loss)
I0927 00:11:41.974362  2459 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0927 00:11:56.560479  2459 solver.cpp:218] Iteration 36900 (6.85584 iter/s, 14.5861s/100 iters), loss = 0.234176
I0927 00:11:56.560521  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234176 (* 1 = 0.234176 loss)
I0927 00:11:56.560528  2459 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0927 00:12:10.415325  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:12:10.998850  2459 solver.cpp:330] Iteration 37000, Testing net (#0)
I0927 00:12:14.418305  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:12:14.561074  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8007
I0927 00:12:14.561100  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.614223 (* 1 = 0.614223 loss)
I0927 00:12:14.706219  2459 solver.cpp:218] Iteration 37000 (5.51096 iter/s, 18.1457s/100 iters), loss = 0.294602
I0927 00:12:14.706246  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294603 (* 1 = 0.294603 loss)
I0927 00:12:14.706254  2459 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0927 00:12:29.275717  2459 solver.cpp:218] Iteration 37100 (6.86368 iter/s, 14.5694s/100 iters), loss = 0.308105
I0927 00:12:29.275748  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308105 (* 1 = 0.308105 loss)
I0927 00:12:29.275755  2459 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0927 00:12:43.851192  2459 solver.cpp:218] Iteration 37200 (6.86087 iter/s, 14.5754s/100 iters), loss = 0.345597
I0927 00:12:43.851325  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345598 (* 1 = 0.345598 loss)
I0927 00:12:43.851331  2459 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0927 00:12:58.425441  2459 solver.cpp:218] Iteration 37300 (6.86149 iter/s, 14.5741s/100 iters), loss = 0.355995
I0927 00:12:58.425482  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355996 (* 1 = 0.355996 loss)
I0927 00:12:58.425487  2459 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0927 00:13:13.000916  2459 solver.cpp:218] Iteration 37400 (6.86087 iter/s, 14.5754s/100 iters), loss = 0.260515
I0927 00:13:13.000947  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260515 (* 1 = 0.260515 loss)
I0927 00:13:13.000953  2459 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0927 00:13:26.849509  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:13:27.432466  2459 solver.cpp:330] Iteration 37500, Testing net (#0)
I0927 00:13:30.849913  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:13:30.992655  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7914
I0927 00:13:30.992691  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.616087 (* 1 = 0.616087 loss)
I0927 00:13:31.137554  2459 solver.cpp:218] Iteration 37500 (5.51372 iter/s, 18.1366s/100 iters), loss = 0.29168
I0927 00:13:31.137580  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29168 (* 1 = 0.29168 loss)
I0927 00:13:31.137588  2459 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0927 00:13:45.711791  2459 solver.cpp:218] Iteration 37600 (6.86145 iter/s, 14.5742s/100 iters), loss = 0.312629
I0927 00:13:45.711833  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312629 (* 1 = 0.312629 loss)
I0927 00:13:45.711838  2459 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0927 00:14:00.290840  2459 solver.cpp:218] Iteration 37700 (6.85919 iter/s, 14.579s/100 iters), loss = 0.341344
I0927 00:14:00.290959  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341344 (* 1 = 0.341344 loss)
I0927 00:14:00.290967  2459 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0927 00:14:14.871569  2459 solver.cpp:218] Iteration 37800 (6.85843 iter/s, 14.5806s/100 iters), loss = 0.358901
I0927 00:14:14.871610  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358902 (* 1 = 0.358902 loss)
I0927 00:14:14.871616  2459 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0927 00:14:29.448827  2459 solver.cpp:218] Iteration 37900 (6.86003 iter/s, 14.5772s/100 iters), loss = 0.171823
I0927 00:14:29.448868  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171824 (* 1 = 0.171824 loss)
I0927 00:14:29.448873  2459 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0927 00:14:43.303170  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:14:43.885828  2459 solver.cpp:330] Iteration 38000, Testing net (#0)
I0927 00:14:47.303599  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:14:47.446454  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8014
I0927 00:14:47.446491  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.601576 (* 1 = 0.601576 loss)
I0927 00:14:47.592115  2459 solver.cpp:218] Iteration 38000 (5.5117 iter/s, 18.1432s/100 iters), loss = 0.317826
I0927 00:14:47.592141  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317826 (* 1 = 0.317826 loss)
I0927 00:14:47.592149  2459 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0927 00:15:02.170790  2459 solver.cpp:218] Iteration 38100 (6.85936 iter/s, 14.5786s/100 iters), loss = 0.234416
I0927 00:15:02.170830  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234417 (* 1 = 0.234417 loss)
I0927 00:15:02.170837  2459 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0927 00:15:16.751237  2459 solver.cpp:218] Iteration 38200 (6.85853 iter/s, 14.5804s/100 iters), loss = 0.328057
I0927 00:15:16.751338  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328057 (* 1 = 0.328057 loss)
I0927 00:15:16.751345  2459 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0927 00:15:31.320883  2459 solver.cpp:218] Iteration 38300 (6.86364 iter/s, 14.5695s/100 iters), loss = 0.404309
I0927 00:15:31.320924  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404309 (* 1 = 0.404309 loss)
I0927 00:15:31.320930  2459 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0927 00:15:45.893046  2459 solver.cpp:218] Iteration 38400 (6.86243 iter/s, 14.5721s/100 iters), loss = 0.203403
I0927 00:15:45.893077  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203404 (* 1 = 0.203404 loss)
I0927 00:15:45.893084  2459 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0927 00:15:59.741534  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:16:00.324255  2459 solver.cpp:330] Iteration 38500, Testing net (#0)
I0927 00:16:03.743192  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:16:03.885833  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7852
I0927 00:16:03.885869  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663114 (* 1 = 0.663114 loss)
I0927 00:16:04.031353  2459 solver.cpp:218] Iteration 38500 (5.51321 iter/s, 18.1382s/100 iters), loss = 0.183316
I0927 00:16:04.031378  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183316 (* 1 = 0.183316 loss)
I0927 00:16:04.031385  2459 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0927 00:16:18.606087  2459 solver.cpp:218] Iteration 38600 (6.86121 iter/s, 14.5747s/100 iters), loss = 0.221834
I0927 00:16:18.606117  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221834 (* 1 = 0.221834 loss)
I0927 00:16:18.606123  2459 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0927 00:16:33.188151  2459 solver.cpp:218] Iteration 38700 (6.85777 iter/s, 14.582s/100 iters), loss = 0.390953
I0927 00:16:33.188275  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390953 (* 1 = 0.390953 loss)
I0927 00:16:33.188282  2459 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0927 00:16:47.765885  2459 solver.cpp:218] Iteration 38800 (6.85985 iter/s, 14.5776s/100 iters), loss = 0.215556
I0927 00:16:47.765918  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215557 (* 1 = 0.215557 loss)
I0927 00:16:47.765923  2459 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0927 00:17:02.353713  2459 solver.cpp:218] Iteration 38900 (6.85506 iter/s, 14.5878s/100 iters), loss = 0.199024
I0927 00:17:02.353752  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199025 (* 1 = 0.199025 loss)
I0927 00:17:02.353759  2459 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0927 00:17:16.209642  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:17:16.791836  2459 solver.cpp:330] Iteration 39000, Testing net (#0)
I0927 00:17:20.208257  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:17:20.350600  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7689
I0927 00:17:20.350636  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684277 (* 1 = 0.684277 loss)
I0927 00:17:20.495175  2459 solver.cpp:218] Iteration 39000 (5.51226 iter/s, 18.1414s/100 iters), loss = 0.255181
I0927 00:17:20.495203  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255181 (* 1 = 0.255181 loss)
I0927 00:17:20.495209  2459 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0927 00:17:35.062686  2459 solver.cpp:218] Iteration 39100 (6.86461 iter/s, 14.5675s/100 iters), loss = 0.304051
I0927 00:17:35.062727  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304051 (* 1 = 0.304051 loss)
I0927 00:17:35.062733  2459 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0927 00:17:49.637997  2459 solver.cpp:218] Iteration 39200 (6.86095 iter/s, 14.5752s/100 iters), loss = 0.271307
I0927 00:17:49.638072  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271307 (* 1 = 0.271307 loss)
I0927 00:17:49.638079  2459 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0927 00:18:04.214618  2459 solver.cpp:218] Iteration 39300 (6.86035 iter/s, 14.5765s/100 iters), loss = 0.330444
I0927 00:18:04.214659  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330444 (* 1 = 0.330444 loss)
I0927 00:18:04.214665  2459 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0927 00:18:18.790581  2459 solver.cpp:218] Iteration 39400 (6.86064 iter/s, 14.5759s/100 iters), loss = 0.22158
I0927 00:18:18.790622  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22158 (* 1 = 0.22158 loss)
I0927 00:18:18.790628  2459 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0927 00:18:32.645627  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:18:33.229717  2459 solver.cpp:330] Iteration 39500, Testing net (#0)
I0927 00:18:36.648383  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:18:36.790593  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8106
I0927 00:18:36.790628  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.567565 (* 1 = 0.567565 loss)
I0927 00:18:36.935106  2459 solver.cpp:218] Iteration 39500 (5.51133 iter/s, 18.1445s/100 iters), loss = 0.259039
I0927 00:18:36.935130  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259039 (* 1 = 0.259039 loss)
I0927 00:18:36.935137  2459 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0927 00:18:51.506758  2459 solver.cpp:218] Iteration 39600 (6.86266 iter/s, 14.5716s/100 iters), loss = 0.281561
I0927 00:18:51.506798  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281561 (* 1 = 0.281561 loss)
I0927 00:18:51.506804  2459 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0927 00:19:06.082262  2459 solver.cpp:218] Iteration 39700 (6.86086 iter/s, 14.5754s/100 iters), loss = 0.242179
I0927 00:19:06.082367  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24218 (* 1 = 0.24218 loss)
I0927 00:19:06.082375  2459 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0927 00:19:20.651623  2459 solver.cpp:218] Iteration 39800 (6.86378 iter/s, 14.5692s/100 iters), loss = 0.198637
I0927 00:19:20.651654  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198637 (* 1 = 0.198637 loss)
I0927 00:19:20.651660  2459 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0927 00:19:35.222434  2459 solver.cpp:218] Iteration 39900 (6.86306 iter/s, 14.5708s/100 iters), loss = 0.242473
I0927 00:19:35.222465  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242473 (* 1 = 0.242473 loss)
I0927 00:19:35.222470  2459 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0927 00:19:49.074309  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:19:49.656972  2459 solver.cpp:330] Iteration 40000, Testing net (#0)
I0927 00:19:53.076064  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:19:53.218682  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8145
I0927 00:19:53.218708  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.551234 (* 1 = 0.551234 loss)
I0927 00:19:53.363297  2459 solver.cpp:218] Iteration 40000 (5.51243 iter/s, 18.1408s/100 iters), loss = 0.197068
I0927 00:19:53.363325  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197068 (* 1 = 0.197068 loss)
I0927 00:19:53.363332  2459 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0927 00:19:53.363334  2459 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0927 00:20:07.936530  2459 solver.cpp:218] Iteration 40100 (6.86192 iter/s, 14.5732s/100 iters), loss = 0.231078
I0927 00:20:07.936571  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231079 (* 1 = 0.231079 loss)
I0927 00:20:07.936578  2459 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0927 00:20:22.515219  2459 solver.cpp:218] Iteration 40200 (6.85936 iter/s, 14.5786s/100 iters), loss = 0.240852
I0927 00:20:22.515292  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240853 (* 1 = 0.240853 loss)
I0927 00:20:22.515300  2459 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0927 00:20:37.099165  2459 solver.cpp:218] Iteration 40300 (6.8569 iter/s, 14.5839s/100 iters), loss = 0.208424
I0927 00:20:37.099195  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208424 (* 1 = 0.208424 loss)
I0927 00:20:37.099201  2459 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0927 00:20:51.679612  2459 solver.cpp:218] Iteration 40400 (6.85853 iter/s, 14.5804s/100 iters), loss = 0.125539
I0927 00:20:51.679653  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12554 (* 1 = 0.12554 loss)
I0927 00:20:51.679658  2459 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0927 00:21:05.535213  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:21:06.118118  2459 solver.cpp:330] Iteration 40500, Testing net (#0)
I0927 00:21:09.535606  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:21:09.678426  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8709
I0927 00:21:09.678462  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365432 (* 1 = 0.365432 loss)
I0927 00:21:09.823051  2459 solver.cpp:218] Iteration 40500 (5.51166 iter/s, 18.1434s/100 iters), loss = 0.162025
I0927 00:21:09.823078  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162026 (* 1 = 0.162026 loss)
I0927 00:21:09.823084  2459 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0927 00:21:24.394891  2459 solver.cpp:218] Iteration 40600 (6.86258 iter/s, 14.5718s/100 iters), loss = 0.216717
I0927 00:21:24.394932  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216717 (* 1 = 0.216717 loss)
I0927 00:21:24.394938  2459 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0927 00:21:38.972376  2459 solver.cpp:218] Iteration 40700 (6.85992 iter/s, 14.5774s/100 iters), loss = 0.209804
I0927 00:21:38.972498  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209804 (* 1 = 0.209804 loss)
I0927 00:21:38.972517  2459 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0927 00:21:53.547080  2459 solver.cpp:218] Iteration 40800 (6.86127 iter/s, 14.5746s/100 iters), loss = 0.19871
I0927 00:21:53.547119  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198711 (* 1 = 0.198711 loss)
I0927 00:21:53.547125  2459 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0927 00:22:08.123009  2459 solver.cpp:218] Iteration 40900 (6.86066 iter/s, 14.5759s/100 iters), loss = 0.138892
I0927 00:22:08.123050  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138892 (* 1 = 0.138892 loss)
I0927 00:22:08.123055  2459 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0927 00:22:21.971863  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:22:22.554975  2459 solver.cpp:330] Iteration 41000, Testing net (#0)
I0927 00:22:25.972792  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:22:26.115222  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8743
I0927 00:22:26.115257  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354304 (* 1 = 0.354304 loss)
I0927 00:22:26.260262  2459 solver.cpp:218] Iteration 41000 (5.51354 iter/s, 18.1372s/100 iters), loss = 0.157191
I0927 00:22:26.260289  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157191 (* 1 = 0.157191 loss)
I0927 00:22:26.260296  2459 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0927 00:22:40.827888  2459 solver.cpp:218] Iteration 41100 (6.86456 iter/s, 14.5676s/100 iters), loss = 0.184935
I0927 00:22:40.827930  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184935 (* 1 = 0.184935 loss)
I0927 00:22:40.827936  2459 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0927 00:22:55.400548  2459 solver.cpp:218] Iteration 41200 (6.8622 iter/s, 14.5726s/100 iters), loss = 0.209963
I0927 00:22:55.400653  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209963 (* 1 = 0.209963 loss)
I0927 00:22:55.400660  2459 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0927 00:23:09.976881  2459 solver.cpp:218] Iteration 41300 (6.8605 iter/s, 14.5762s/100 iters), loss = 0.160761
I0927 00:23:09.976922  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160761 (* 1 = 0.160761 loss)
I0927 00:23:09.976928  2459 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0927 00:23:24.553905  2459 solver.cpp:218] Iteration 41400 (6.86014 iter/s, 14.577s/100 iters), loss = 0.123084
I0927 00:23:24.553944  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123084 (* 1 = 0.123084 loss)
I0927 00:23:24.553951  2459 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0927 00:23:38.409096  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:23:38.992023  2459 solver.cpp:330] Iteration 41500, Testing net (#0)
I0927 00:23:42.410472  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:23:42.553457  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8819
I0927 00:23:42.553493  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336218 (* 1 = 0.336218 loss)
I0927 00:23:42.698802  2459 solver.cpp:218] Iteration 41500 (5.51121 iter/s, 18.1448s/100 iters), loss = 0.130862
I0927 00:23:42.698832  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130862 (* 1 = 0.130862 loss)
I0927 00:23:42.698837  2459 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0927 00:23:57.268821  2459 solver.cpp:218] Iteration 41600 (6.86343 iter/s, 14.57s/100 iters), loss = 0.144811
I0927 00:23:57.268853  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144811 (* 1 = 0.144811 loss)
I0927 00:23:57.268862  2459 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0927 00:24:11.845005  2459 solver.cpp:218] Iteration 41700 (6.86053 iter/s, 14.5761s/100 iters), loss = 0.195942
I0927 00:24:11.845129  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195943 (* 1 = 0.195943 loss)
I0927 00:24:11.845146  2459 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0927 00:24:26.428731  2459 solver.cpp:218] Iteration 41800 (6.85703 iter/s, 14.5836s/100 iters), loss = 0.143693
I0927 00:24:26.428774  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143693 (* 1 = 0.143693 loss)
I0927 00:24:26.428779  2459 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0927 00:24:41.002338  2459 solver.cpp:218] Iteration 41900 (6.86176 iter/s, 14.5735s/100 iters), loss = 0.122657
I0927 00:24:41.002389  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122657 (* 1 = 0.122657 loss)
I0927 00:24:41.002395  2459 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0927 00:24:54.852618  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:24:55.436345  2459 solver.cpp:330] Iteration 42000, Testing net (#0)
I0927 00:24:58.854557  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:24:58.997256  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.879
I0927 00:24:58.997282  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347223 (* 1 = 0.347223 loss)
I0927 00:24:59.142319  2459 solver.cpp:218] Iteration 42000 (5.51271 iter/s, 18.1399s/100 iters), loss = 0.126694
I0927 00:24:59.142346  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126694 (* 1 = 0.126694 loss)
I0927 00:24:59.142352  2459 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0927 00:25:13.718505  2459 solver.cpp:218] Iteration 42100 (6.86053 iter/s, 14.5761s/100 iters), loss = 0.131873
I0927 00:25:13.718547  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131873 (* 1 = 0.131873 loss)
I0927 00:25:13.718554  2459 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0927 00:25:28.297354  2459 solver.cpp:218] Iteration 42200 (6.85928 iter/s, 14.5788s/100 iters), loss = 0.110612
I0927 00:25:28.297461  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110612 (* 1 = 0.110612 loss)
I0927 00:25:28.297469  2459 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0927 00:25:42.882195  2459 solver.cpp:218] Iteration 42300 (6.85649 iter/s, 14.5847s/100 iters), loss = 0.117144
I0927 00:25:42.882236  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117144 (* 1 = 0.117144 loss)
I0927 00:25:42.882242  2459 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0927 00:25:57.467988  2459 solver.cpp:218] Iteration 42400 (6.85602 iter/s, 14.5857s/100 iters), loss = 0.111292
I0927 00:25:57.468019  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111293 (* 1 = 0.111293 loss)
I0927 00:25:57.468024  2459 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0927 00:26:11.335842  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:26:11.920581  2459 solver.cpp:330] Iteration 42500, Testing net (#0)
I0927 00:26:15.338820  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:26:15.481552  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8809
I0927 00:26:15.481588  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339305 (* 1 = 0.339305 loss)
I0927 00:26:15.626091  2459 solver.cpp:218] Iteration 42500 (5.5072 iter/s, 18.158s/100 iters), loss = 0.111572
I0927 00:26:15.626117  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111572 (* 1 = 0.111572 loss)
I0927 00:26:15.626124  2459 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0927 00:26:30.199102  2459 solver.cpp:218] Iteration 42600 (6.86202 iter/s, 14.573s/100 iters), loss = 0.192338
I0927 00:26:30.199144  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192338 (* 1 = 0.192338 loss)
I0927 00:26:30.199151  2459 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0927 00:26:44.782919  2459 solver.cpp:218] Iteration 42700 (6.85695 iter/s, 14.5838s/100 iters), loss = 0.137612
I0927 00:26:44.783033  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137612 (* 1 = 0.137612 loss)
I0927 00:26:44.783042  2459 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0927 00:26:59.365671  2459 solver.cpp:218] Iteration 42800 (6.85748 iter/s, 14.5826s/100 iters), loss = 0.11598
I0927 00:26:59.365703  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115981 (* 1 = 0.115981 loss)
I0927 00:26:59.365710  2459 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0927 00:27:13.956050  2459 solver.cpp:218] Iteration 42900 (6.85386 iter/s, 14.5903s/100 iters), loss = 0.131739
I0927 00:27:13.956092  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131739 (* 1 = 0.131739 loss)
I0927 00:27:13.956099  2459 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0927 00:27:27.824955  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:27:28.408996  2459 solver.cpp:330] Iteration 43000, Testing net (#0)
I0927 00:27:31.827426  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:27:31.970360  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8828
I0927 00:27:31.970397  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330544 (* 1 = 0.330544 loss)
I0927 00:27:32.115586  2459 solver.cpp:218] Iteration 43000 (5.50677 iter/s, 18.1595s/100 iters), loss = 0.129581
I0927 00:27:32.115613  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129581 (* 1 = 0.129581 loss)
I0927 00:27:32.115620  2459 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0927 00:27:46.692210  2459 solver.cpp:218] Iteration 43100 (6.86032 iter/s, 14.5766s/100 iters), loss = 0.149011
I0927 00:27:46.692251  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149012 (* 1 = 0.149012 loss)
I0927 00:27:46.692257  2459 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0927 00:28:01.268210  2459 solver.cpp:218] Iteration 43200 (6.86062 iter/s, 14.5759s/100 iters), loss = 0.106618
I0927 00:28:01.268293  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106618 (* 1 = 0.106618 loss)
I0927 00:28:01.268311  2459 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0927 00:28:15.847110  2459 solver.cpp:218] Iteration 43300 (6.85928 iter/s, 14.5788s/100 iters), loss = 0.130278
I0927 00:28:15.847151  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130279 (* 1 = 0.130279 loss)
I0927 00:28:15.847157  2459 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0927 00:28:30.427331  2459 solver.cpp:218] Iteration 43400 (6.85864 iter/s, 14.5802s/100 iters), loss = 0.101045
I0927 00:28:30.427372  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101045 (* 1 = 0.101045 loss)
I0927 00:28:30.427379  2459 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0927 00:28:44.286034  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:28:44.869213  2459 solver.cpp:330] Iteration 43500, Testing net (#0)
I0927 00:28:48.286978  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:28:48.429522  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8858
I0927 00:28:48.429558  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329531 (* 1 = 0.329531 loss)
I0927 00:28:48.574300  2459 solver.cpp:218] Iteration 43500 (5.51058 iter/s, 18.1469s/100 iters), loss = 0.120656
I0927 00:28:48.574327  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120656 (* 1 = 0.120656 loss)
I0927 00:28:48.574334  2459 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0927 00:29:03.160449  2459 solver.cpp:218] Iteration 43600 (6.85584 iter/s, 14.5861s/100 iters), loss = 0.109447
I0927 00:29:03.160478  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109447 (* 1 = 0.109447 loss)
I0927 00:29:03.160485  2459 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0927 00:29:17.738813  2459 solver.cpp:218] Iteration 43700 (6.85951 iter/s, 14.5783s/100 iters), loss = 0.154787
I0927 00:29:17.738921  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154787 (* 1 = 0.154787 loss)
I0927 00:29:17.738940  2459 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0927 00:29:32.318330  2459 solver.cpp:218] Iteration 43800 (6.859 iter/s, 14.5794s/100 iters), loss = 0.122413
I0927 00:29:32.318377  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122413 (* 1 = 0.122413 loss)
I0927 00:29:32.318385  2459 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0927 00:29:46.898320  2459 solver.cpp:218] Iteration 43900 (6.85875 iter/s, 14.5799s/100 iters), loss = 0.118811
I0927 00:29:46.898361  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118811 (* 1 = 0.118811 loss)
I0927 00:29:46.898368  2459 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0927 00:30:00.754040  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:30:01.336995  2459 solver.cpp:330] Iteration 44000, Testing net (#0)
I0927 00:30:04.753052  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:30:04.895601  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8821
I0927 00:30:04.895637  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34483 (* 1 = 0.34483 loss)
I0927 00:30:05.040112  2459 solver.cpp:218] Iteration 44000 (5.51216 iter/s, 18.1417s/100 iters), loss = 0.0721652
I0927 00:30:05.040140  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721653 (* 1 = 0.0721653 loss)
I0927 00:30:05.040148  2459 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0927 00:30:19.611049  2459 solver.cpp:218] Iteration 44100 (6.863 iter/s, 14.5709s/100 iters), loss = 0.0977111
I0927 00:30:19.611090  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0977112 (* 1 = 0.0977112 loss)
I0927 00:30:19.611096  2459 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0927 00:30:34.186846  2459 solver.cpp:218] Iteration 44200 (6.86072 iter/s, 14.5757s/100 iters), loss = 0.0760796
I0927 00:30:34.186969  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0760797 (* 1 = 0.0760797 loss)
I0927 00:30:34.186985  2459 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0927 00:30:48.750509  2459 solver.cpp:218] Iteration 44300 (6.86647 iter/s, 14.5635s/100 iters), loss = 0.0874171
I0927 00:30:48.750550  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0874172 (* 1 = 0.0874172 loss)
I0927 00:30:48.750555  2459 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0927 00:31:03.322546  2459 solver.cpp:218] Iteration 44400 (6.86249 iter/s, 14.572s/100 iters), loss = 0.108135
I0927 00:31:03.322587  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108135 (* 1 = 0.108135 loss)
I0927 00:31:03.322592  2459 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0927 00:31:17.172586  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:31:17.755553  2459 solver.cpp:330] Iteration 44500, Testing net (#0)
I0927 00:31:21.174793  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:31:21.317420  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8876
I0927 00:31:21.317456  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334234 (* 1 = 0.334234 loss)
I0927 00:31:21.462203  2459 solver.cpp:218] Iteration 44500 (5.5128 iter/s, 18.1396s/100 iters), loss = 0.149153
I0927 00:31:21.462230  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149153 (* 1 = 0.149153 loss)
I0927 00:31:21.462237  2459 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0927 00:31:36.040905  2459 solver.cpp:218] Iteration 44600 (6.85934 iter/s, 14.5787s/100 iters), loss = 0.119285
I0927 00:31:36.040946  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119285 (* 1 = 0.119285 loss)
I0927 00:31:36.040952  2459 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0927 00:31:50.618630  2459 solver.cpp:218] Iteration 44700 (6.85981 iter/s, 14.5777s/100 iters), loss = 0.114837
I0927 00:31:50.618765  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114837 (* 1 = 0.114837 loss)
I0927 00:31:50.618782  2459 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0927 00:32:05.196347  2459 solver.cpp:218] Iteration 44800 (6.85985 iter/s, 14.5776s/100 iters), loss = 0.0491174
I0927 00:32:05.196388  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491175 (* 1 = 0.0491175 loss)
I0927 00:32:05.196393  2459 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0927 00:32:19.772855  2459 solver.cpp:218] Iteration 44900 (6.86038 iter/s, 14.5764s/100 iters), loss = 0.0755994
I0927 00:32:19.772897  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0755995 (* 1 = 0.0755995 loss)
I0927 00:32:19.772903  2459 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0927 00:32:33.629283  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:32:34.213049  2459 solver.cpp:330] Iteration 45000, Testing net (#0)
I0927 00:32:37.630067  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:32:37.772971  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8877
I0927 00:32:37.773007  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329385 (* 1 = 0.329385 loss)
I0927 00:32:37.917764  2459 solver.cpp:218] Iteration 45000 (5.51121 iter/s, 18.1448s/100 iters), loss = 0.0801634
I0927 00:32:37.917793  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0801635 (* 1 = 0.0801635 loss)
I0927 00:32:37.917800  2459 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0927 00:32:52.493505  2459 solver.cpp:218] Iteration 45100 (6.86074 iter/s, 14.5757s/100 iters), loss = 0.0701744
I0927 00:32:52.493552  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0701746 (* 1 = 0.0701746 loss)
I0927 00:32:52.493559  2459 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0927 00:33:07.071996  2459 solver.cpp:218] Iteration 45200 (6.85945 iter/s, 14.5784s/100 iters), loss = 0.12647
I0927 00:33:07.072118  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12647 (* 1 = 0.12647 loss)
I0927 00:33:07.072135  2459 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0927 00:33:21.648519  2459 solver.cpp:218] Iteration 45300 (6.86042 iter/s, 14.5764s/100 iters), loss = 0.120052
I0927 00:33:21.648561  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120052 (* 1 = 0.120052 loss)
I0927 00:33:21.648566  2459 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0927 00:33:36.230329  2459 solver.cpp:218] Iteration 45400 (6.85789 iter/s, 14.5817s/100 iters), loss = 0.114956
I0927 00:33:36.230370  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114956 (* 1 = 0.114956 loss)
I0927 00:33:36.230376  2459 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0927 00:33:50.086730  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:33:50.669597  2459 solver.cpp:330] Iteration 45500, Testing net (#0)
I0927 00:33:54.086964  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:33:54.229773  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8883
I0927 00:33:54.229809  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326547 (* 1 = 0.326547 loss)
I0927 00:33:54.373949  2459 solver.cpp:218] Iteration 45500 (5.5116 iter/s, 18.1436s/100 iters), loss = 0.0875628
I0927 00:33:54.373976  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0875629 (* 1 = 0.0875629 loss)
I0927 00:33:54.373983  2459 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0927 00:34:08.948807  2459 solver.cpp:218] Iteration 45600 (6.86116 iter/s, 14.5748s/100 iters), loss = 0.130414
I0927 00:34:08.948848  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130414 (* 1 = 0.130414 loss)
I0927 00:34:08.948854  2459 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0927 00:34:23.528151  2459 solver.cpp:218] Iteration 45700 (6.85905 iter/s, 14.5793s/100 iters), loss = 0.117315
I0927 00:34:23.528270  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117315 (* 1 = 0.117315 loss)
I0927 00:34:23.528278  2459 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0927 00:34:38.110944  2459 solver.cpp:218] Iteration 45800 (6.85746 iter/s, 14.5827s/100 iters), loss = 0.143969
I0927 00:34:38.110985  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143969 (* 1 = 0.143969 loss)
I0927 00:34:38.110991  2459 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0927 00:34:52.692164  2459 solver.cpp:218] Iteration 45900 (6.85817 iter/s, 14.5812s/100 iters), loss = 0.0604435
I0927 00:34:52.692209  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604437 (* 1 = 0.0604437 loss)
I0927 00:34:52.692214  2459 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0927 00:35:06.553123  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:35:07.136972  2459 solver.cpp:330] Iteration 46000, Testing net (#0)
I0927 00:35:10.554261  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:35:10.696866  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8895
I0927 00:35:10.696902  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329816 (* 1 = 0.329816 loss)
I0927 00:35:10.842068  2459 solver.cpp:218] Iteration 46000 (5.50969 iter/s, 18.1498s/100 iters), loss = 0.0765493
I0927 00:35:10.842097  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765495 (* 1 = 0.0765495 loss)
I0927 00:35:10.842104  2459 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0927 00:35:25.415410  2459 solver.cpp:218] Iteration 46100 (6.86187 iter/s, 14.5733s/100 iters), loss = 0.139539
I0927 00:35:25.415452  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13954 (* 1 = 0.13954 loss)
I0927 00:35:25.415457  2459 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0927 00:35:39.997849  2459 solver.cpp:218] Iteration 46200 (6.85759 iter/s, 14.5824s/100 iters), loss = 0.0695206
I0927 00:35:39.997994  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0695207 (* 1 = 0.0695207 loss)
I0927 00:35:39.998003  2459 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0927 00:35:54.569212  2459 solver.cpp:218] Iteration 46300 (6.86285 iter/s, 14.5712s/100 iters), loss = 0.136283
I0927 00:35:54.569242  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136283 (* 1 = 0.136283 loss)
I0927 00:35:54.569249  2459 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0927 00:36:09.145891  2459 solver.cpp:218] Iteration 46400 (6.8603 iter/s, 14.5766s/100 iters), loss = 0.0802456
I0927 00:36:09.145921  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0802458 (* 1 = 0.0802458 loss)
I0927 00:36:09.145927  2459 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0927 00:36:22.995817  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:36:23.578142  2459 solver.cpp:330] Iteration 46500, Testing net (#0)
I0927 00:36:26.995411  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:36:27.137734  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8878
I0927 00:36:27.137760  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3401 (* 1 = 0.3401 loss)
I0927 00:36:27.282265  2459 solver.cpp:218] Iteration 46500 (5.5138 iter/s, 18.1363s/100 iters), loss = 0.062341
I0927 00:36:27.282292  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0623411 (* 1 = 0.0623411 loss)
I0927 00:36:27.282299  2459 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0927 00:36:41.863561  2459 solver.cpp:218] Iteration 46600 (6.85813 iter/s, 14.5812s/100 iters), loss = 0.0865561
I0927 00:36:41.863590  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0865562 (* 1 = 0.0865562 loss)
I0927 00:36:41.863597  2459 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0927 00:36:56.449548  2459 solver.cpp:218] Iteration 46700 (6.85592 iter/s, 14.5859s/100 iters), loss = 0.125525
I0927 00:36:56.449643  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125525 (* 1 = 0.125525 loss)
I0927 00:36:56.449651  2459 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0927 00:37:11.035315  2459 solver.cpp:218] Iteration 46800 (6.85605 iter/s, 14.5857s/100 iters), loss = 0.112141
I0927 00:37:11.035347  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112141 (* 1 = 0.112141 loss)
I0927 00:37:11.035353  2459 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0927 00:37:25.618973  2459 solver.cpp:218] Iteration 46900 (6.85702 iter/s, 14.5836s/100 iters), loss = 0.035971
I0927 00:37:25.619004  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359711 (* 1 = 0.0359711 loss)
I0927 00:37:25.619010  2459 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0927 00:37:39.482023  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:37:40.065412  2459 solver.cpp:330] Iteration 47000, Testing net (#0)
I0927 00:37:43.484120  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:37:43.626952  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8859
I0927 00:37:43.626988  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34464 (* 1 = 0.34464 loss)
I0927 00:37:43.771692  2459 solver.cpp:218] Iteration 47000 (5.50883 iter/s, 18.1527s/100 iters), loss = 0.115996
I0927 00:37:43.771718  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115996 (* 1 = 0.115996 loss)
I0927 00:37:43.771724  2459 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0927 00:37:58.337425  2459 solver.cpp:218] Iteration 47100 (6.86545 iter/s, 14.5657s/100 iters), loss = 0.168601
I0927 00:37:58.337455  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168601 (* 1 = 0.168601 loss)
I0927 00:37:58.337462  2459 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0927 00:38:12.908027  2459 solver.cpp:218] Iteration 47200 (6.86316 iter/s, 14.5705s/100 iters), loss = 0.132282
I0927 00:38:12.908164  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132282 (* 1 = 0.132282 loss)
I0927 00:38:12.908172  2459 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0927 00:38:27.477962  2459 solver.cpp:218] Iteration 47300 (6.86352 iter/s, 14.5698s/100 iters), loss = 0.16472
I0927 00:38:27.477993  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16472 (* 1 = 0.16472 loss)
I0927 00:38:27.477998  2459 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0927 00:38:42.053999  2459 solver.cpp:218] Iteration 47400 (6.8606 iter/s, 14.576s/100 iters), loss = 0.0911603
I0927 00:38:42.054041  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0911604 (* 1 = 0.0911604 loss)
I0927 00:38:42.054047  2459 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0927 00:38:55.907223  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:38:56.491084  2459 solver.cpp:330] Iteration 47500, Testing net (#0)
I0927 00:38:59.910080  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:39:00.052655  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8885
I0927 00:39:00.052691  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332262 (* 1 = 0.332262 loss)
I0927 00:39:00.198524  2459 solver.cpp:218] Iteration 47500 (5.51133 iter/s, 18.1445s/100 iters), loss = 0.087531
I0927 00:39:00.198554  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0875311 (* 1 = 0.0875311 loss)
I0927 00:39:00.198561  2459 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0927 00:39:14.769966  2459 solver.cpp:218] Iteration 47600 (6.86276 iter/s, 14.5714s/100 iters), loss = 0.141485
I0927 00:39:14.770007  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141485 (* 1 = 0.141485 loss)
I0927 00:39:14.770014  2459 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0927 00:39:29.346123  2459 solver.cpp:218] Iteration 47700 (6.86055 iter/s, 14.5761s/100 iters), loss = 0.132265
I0927 00:39:29.346266  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132265 (* 1 = 0.132265 loss)
I0927 00:39:29.346272  2459 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0927 00:39:43.918190  2459 solver.cpp:218] Iteration 47800 (6.86252 iter/s, 14.5719s/100 iters), loss = 0.126735
I0927 00:39:43.918229  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126735 (* 1 = 0.126735 loss)
I0927 00:39:43.918236  2459 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0927 00:39:58.492792  2459 solver.cpp:218] Iteration 47900 (6.86128 iter/s, 14.5745s/100 iters), loss = 0.0688525
I0927 00:39:58.492833  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0688525 (* 1 = 0.0688525 loss)
I0927 00:39:58.492839  2459 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0927 00:40:12.346716  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:40:12.930853  2459 solver.cpp:330] Iteration 48000, Testing net (#0)
I0927 00:40:16.349298  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:40:16.492028  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8828
I0927 00:40:16.492064  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355087 (* 1 = 0.355087 loss)
I0927 00:40:16.637254  2459 solver.cpp:218] Iteration 48000 (5.51134 iter/s, 18.1444s/100 iters), loss = 0.10867
I0927 00:40:16.637281  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10867 (* 1 = 0.10867 loss)
I0927 00:40:16.637287  2459 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0927 00:40:31.198647  2459 solver.cpp:218] Iteration 48100 (6.8675 iter/s, 14.5613s/100 iters), loss = 0.0845992
I0927 00:40:31.198688  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0845992 (* 1 = 0.0845992 loss)
I0927 00:40:31.198693  2459 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0927 00:40:45.763931  2459 solver.cpp:218] Iteration 48200 (6.86567 iter/s, 14.5652s/100 iters), loss = 0.0804051
I0927 00:40:45.764019  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0804052 (* 1 = 0.0804052 loss)
I0927 00:40:45.764027  2459 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0927 00:41:00.331848  2459 solver.cpp:218] Iteration 48300 (6.86445 iter/s, 14.5678s/100 iters), loss = 0.118501
I0927 00:41:00.331890  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118501 (* 1 = 0.118501 loss)
I0927 00:41:00.331897  2459 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0927 00:41:14.899621  2459 solver.cpp:218] Iteration 48400 (6.8645 iter/s, 14.5677s/100 iters), loss = 0.0662196
I0927 00:41:14.899662  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0662196 (* 1 = 0.0662196 loss)
I0927 00:41:14.899668  2459 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0927 00:41:28.747568  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:41:29.330426  2459 solver.cpp:330] Iteration 48500, Testing net (#0)
I0927 00:41:32.750500  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:41:32.892791  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8883
I0927 00:41:32.892827  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342179 (* 1 = 0.342179 loss)
I0927 00:41:33.037499  2459 solver.cpp:218] Iteration 48500 (5.51335 iter/s, 18.1378s/100 iters), loss = 0.0553503
I0927 00:41:33.037526  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553503 (* 1 = 0.0553503 loss)
I0927 00:41:33.037533  2459 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0927 00:41:47.607832  2459 solver.cpp:218] Iteration 48600 (6.86329 iter/s, 14.5703s/100 iters), loss = 0.0977088
I0927 00:41:47.607873  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0977088 (* 1 = 0.0977088 loss)
I0927 00:41:47.607879  2459 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0927 00:42:02.189599  2459 solver.cpp:218] Iteration 48700 (6.85791 iter/s, 14.5817s/100 iters), loss = 0.0759457
I0927 00:42:02.189684  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0759457 (* 1 = 0.0759457 loss)
I0927 00:42:02.189692  2459 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0927 00:42:16.768213  2459 solver.cpp:218] Iteration 48800 (6.85942 iter/s, 14.5785s/100 iters), loss = 0.0888609
I0927 00:42:16.768256  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0888609 (* 1 = 0.0888609 loss)
I0927 00:42:16.768262  2459 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0927 00:42:31.349598  2459 solver.cpp:218] Iteration 48900 (6.85809 iter/s, 14.5813s/100 iters), loss = 0.0360237
I0927 00:42:31.349639  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360237 (* 1 = 0.0360237 loss)
I0927 00:42:31.349645  2459 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0927 00:42:45.205257  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:42:45.788954  2459 solver.cpp:330] Iteration 49000, Testing net (#0)
I0927 00:42:49.206357  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:42:49.349400  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8805
I0927 00:42:49.349436  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382448 (* 1 = 0.382448 loss)
I0927 00:42:49.494747  2459 solver.cpp:218] Iteration 49000 (5.51114 iter/s, 18.1451s/100 iters), loss = 0.058445
I0927 00:42:49.494776  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0584449 (* 1 = 0.0584449 loss)
I0927 00:42:49.494782  2459 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0927 00:43:04.079561  2459 solver.cpp:218] Iteration 49100 (6.85647 iter/s, 14.5848s/100 iters), loss = 0.0996896
I0927 00:43:04.079602  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0996896 (* 1 = 0.0996896 loss)
I0927 00:43:04.079608  2459 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0927 00:43:18.664111  2459 solver.cpp:218] Iteration 49200 (6.8566 iter/s, 14.5845s/100 iters), loss = 0.0748625
I0927 00:43:18.664228  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0748625 (* 1 = 0.0748625 loss)
I0927 00:43:18.664247  2459 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0927 00:43:33.251746  2459 solver.cpp:218] Iteration 49300 (6.85519 iter/s, 14.5875s/100 iters), loss = 0.0868341
I0927 00:43:33.251777  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.086834 (* 1 = 0.086834 loss)
I0927 00:43:33.251783  2459 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0927 00:43:47.830842  2459 solver.cpp:218] Iteration 49400 (6.85916 iter/s, 14.579s/100 iters), loss = 0.106578
I0927 00:43:47.830873  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106578 (* 1 = 0.106578 loss)
I0927 00:43:47.830878  2459 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0927 00:44:01.689401  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:44:02.273170  2459 solver.cpp:330] Iteration 49500, Testing net (#0)
I0927 00:44:05.693048  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:44:05.835845  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8906
I0927 00:44:05.835882  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33586 (* 1 = 0.33586 loss)
I0927 00:44:05.980597  2459 solver.cpp:218] Iteration 49500 (5.50973 iter/s, 18.1497s/100 iters), loss = 0.0991947
I0927 00:44:05.980625  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0991947 (* 1 = 0.0991947 loss)
I0927 00:44:05.980631  2459 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0927 00:44:20.554178  2459 solver.cpp:218] Iteration 49600 (6.86176 iter/s, 14.5735s/100 iters), loss = 0.0886215
I0927 00:44:20.554208  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0886214 (* 1 = 0.0886214 loss)
I0927 00:44:20.554214  2459 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0927 00:44:35.135732  2459 solver.cpp:218] Iteration 49700 (6.85801 iter/s, 14.5815s/100 iters), loss = 0.115848
I0927 00:44:35.135869  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115848 (* 1 = 0.115848 loss)
I0927 00:44:35.135875  2459 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0927 00:44:49.717193  2459 solver.cpp:218] Iteration 49800 (6.8581 iter/s, 14.5813s/100 iters), loss = 0.120198
I0927 00:44:49.717236  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120198 (* 1 = 0.120198 loss)
I0927 00:44:49.717242  2459 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0927 00:45:04.300899  2459 solver.cpp:218] Iteration 49900 (6.857 iter/s, 14.5836s/100 iters), loss = 0.0832588
I0927 00:45:04.300938  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0832587 (* 1 = 0.0832587 loss)
I0927 00:45:04.300945  2459 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0927 00:45:18.161548  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:45:18.745213  2459 solver.cpp:330] Iteration 50000, Testing net (#0)
I0927 00:45:22.163318  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:45:22.306149  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8901
I0927 00:45:22.306185  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338259 (* 1 = 0.338259 loss)
I0927 00:45:22.450439  2459 solver.cpp:218] Iteration 50000 (5.5098 iter/s, 18.1495s/100 iters), loss = 0.0633339
I0927 00:45:22.450466  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0633338 (* 1 = 0.0633338 loss)
I0927 00:45:22.450474  2459 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0927 00:45:37.017033  2459 solver.cpp:218] Iteration 50100 (6.86505 iter/s, 14.5665s/100 iters), loss = 0.0841377
I0927 00:45:37.017065  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0841376 (* 1 = 0.0841376 loss)
I0927 00:45:37.017071  2459 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0927 00:45:51.590026  2459 solver.cpp:218] Iteration 50200 (6.86203 iter/s, 14.5729s/100 iters), loss = 0.0608204
I0927 00:45:51.590111  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0608204 (* 1 = 0.0608204 loss)
I0927 00:45:51.590127  2459 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0927 00:46:06.170840  2459 solver.cpp:218] Iteration 50300 (6.85838 iter/s, 14.5807s/100 iters), loss = 0.0869838
I0927 00:46:06.170881  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0869837 (* 1 = 0.0869837 loss)
I0927 00:46:06.170888  2459 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0927 00:46:20.746960  2459 solver.cpp:218] Iteration 50400 (6.86057 iter/s, 14.5761s/100 iters), loss = 0.0563258
I0927 00:46:20.747001  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0563257 (* 1 = 0.0563257 loss)
I0927 00:46:20.747007  2459 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0927 00:46:34.603200  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:46:35.186666  2459 solver.cpp:330] Iteration 50500, Testing net (#0)
I0927 00:46:38.605348  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:46:38.747738  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8897
I0927 00:46:38.747776  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344774 (* 1 = 0.344774 loss)
I0927 00:46:38.892840  2459 solver.cpp:218] Iteration 50500 (5.51091 iter/s, 18.1458s/100 iters), loss = 0.0527156
I0927 00:46:38.892868  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0527155 (* 1 = 0.0527155 loss)
I0927 00:46:38.892874  2459 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0927 00:46:53.474872  2459 solver.cpp:218] Iteration 50600 (6.85778 iter/s, 14.582s/100 iters), loss = 0.0696142
I0927 00:46:53.474913  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0696141 (* 1 = 0.0696141 loss)
I0927 00:46:53.474920  2459 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0927 00:47:08.055601  2459 solver.cpp:218] Iteration 50700 (6.8584 iter/s, 14.5807s/100 iters), loss = 0.0805138
I0927 00:47:08.055763  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805136 (* 1 = 0.0805136 loss)
I0927 00:47:08.055783  2459 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0927 00:47:22.635009  2459 solver.cpp:218] Iteration 50800 (6.85907 iter/s, 14.5792s/100 iters), loss = 0.0855155
I0927 00:47:22.635040  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0855154 (* 1 = 0.0855154 loss)
I0927 00:47:22.635044  2459 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0927 00:47:37.220839  2459 solver.cpp:218] Iteration 50900 (6.856 iter/s, 14.5858s/100 iters), loss = 0.0668044
I0927 00:47:37.220870  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0668043 (* 1 = 0.0668043 loss)
I0927 00:47:37.220876  2459 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0927 00:47:51.081739  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:47:51.665848  2459 solver.cpp:330] Iteration 51000, Testing net (#0)
I0927 00:47:55.082988  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:47:55.225420  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8879
I0927 00:47:55.225456  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340701 (* 1 = 0.340701 loss)
I0927 00:47:55.369925  2459 solver.cpp:218] Iteration 51000 (5.50994 iter/s, 18.149s/100 iters), loss = 0.0754306
I0927 00:47:55.369952  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0754305 (* 1 = 0.0754305 loss)
I0927 00:47:55.369959  2459 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0927 00:48:09.931946  2459 solver.cpp:218] Iteration 51100 (6.8672 iter/s, 14.562s/100 iters), loss = 0.0984625
I0927 00:48:09.931977  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0984624 (* 1 = 0.0984624 loss)
I0927 00:48:09.931982  2459 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0927 00:48:24.496325  2459 solver.cpp:218] Iteration 51200 (6.86609 iter/s, 14.5643s/100 iters), loss = 0.0491887
I0927 00:48:24.496446  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491886 (* 1 = 0.0491886 loss)
I0927 00:48:24.496454  2459 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0927 00:48:39.059221  2459 solver.cpp:218] Iteration 51300 (6.86683 iter/s, 14.5628s/100 iters), loss = 0.115293
I0927 00:48:39.059262  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115293 (* 1 = 0.115293 loss)
I0927 00:48:39.059268  2459 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0927 00:48:53.624004  2459 solver.cpp:218] Iteration 51400 (6.86591 iter/s, 14.5647s/100 iters), loss = 0.0816682
I0927 00:48:53.624045  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.081668 (* 1 = 0.081668 loss)
I0927 00:48:53.624052  2459 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0927 00:49:07.467619  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:49:08.050485  2459 solver.cpp:330] Iteration 51500, Testing net (#0)
I0927 00:49:11.468659  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:49:11.611512  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.886
I0927 00:49:11.611549  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361118 (* 1 = 0.361118 loss)
I0927 00:49:11.756302  2459 solver.cpp:218] Iteration 51500 (5.51504 iter/s, 18.1322s/100 iters), loss = 0.0496942
I0927 00:49:11.756330  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496941 (* 1 = 0.0496941 loss)
I0927 00:49:11.756336  2459 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0927 00:49:26.331300  2459 solver.cpp:218] Iteration 51600 (6.86109 iter/s, 14.5749s/100 iters), loss = 0.11504
I0927 00:49:26.331331  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11504 (* 1 = 0.11504 loss)
I0927 00:49:26.331336  2459 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0927 00:49:40.908547  2459 solver.cpp:218] Iteration 51700 (6.86003 iter/s, 14.5772s/100 iters), loss = 0.0762764
I0927 00:49:40.908725  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0762762 (* 1 = 0.0762762 loss)
I0927 00:49:40.908743  2459 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0927 00:49:55.488209  2459 solver.cpp:218] Iteration 51800 (6.85896 iter/s, 14.5795s/100 iters), loss = 0.044978
I0927 00:49:55.488250  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449778 (* 1 = 0.0449778 loss)
I0927 00:49:55.488256  2459 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0927 00:50:10.071732  2459 solver.cpp:218] Iteration 51900 (6.85708 iter/s, 14.5835s/100 iters), loss = 0.0422548
I0927 00:50:10.071774  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422546 (* 1 = 0.0422546 loss)
I0927 00:50:10.071779  2459 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0927 00:50:23.929226  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:50:24.513042  2459 solver.cpp:330] Iteration 52000, Testing net (#0)
I0927 00:50:27.930696  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:50:28.073763  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8792
I0927 00:50:28.073801  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388984 (* 1 = 0.388984 loss)
I0927 00:50:28.218655  2459 solver.cpp:218] Iteration 52000 (5.5106 iter/s, 18.1469s/100 iters), loss = 0.131537
I0927 00:50:28.218683  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131537 (* 1 = 0.131537 loss)
I0927 00:50:28.218689  2459 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0927 00:50:42.779961  2459 solver.cpp:218] Iteration 52100 (6.86754 iter/s, 14.5613s/100 iters), loss = 0.0551526
I0927 00:50:42.779991  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0551524 (* 1 = 0.0551524 loss)
I0927 00:50:42.779997  2459 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0927 00:50:57.345813  2459 solver.cpp:218] Iteration 52200 (6.8654 iter/s, 14.5658s/100 iters), loss = 0.10061
I0927 00:50:57.345903  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10061 (* 1 = 0.10061 loss)
I0927 00:50:57.345911  2459 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0927 00:51:11.922771  2459 solver.cpp:218] Iteration 52300 (6.8602 iter/s, 14.5768s/100 iters), loss = 0.103439
I0927 00:51:11.922819  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103438 (* 1 = 0.103438 loss)
I0927 00:51:11.922827  2459 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0927 00:51:26.505267  2459 solver.cpp:218] Iteration 52400 (6.85757 iter/s, 14.5824s/100 iters), loss = 0.0666944
I0927 00:51:26.505309  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666943 (* 1 = 0.0666943 loss)
I0927 00:51:26.505316  2459 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0927 00:51:40.359505  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:51:40.942647  2459 solver.cpp:330] Iteration 52500, Testing net (#0)
I0927 00:51:44.361814  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:51:44.504652  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8872
I0927 00:51:44.504688  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368441 (* 1 = 0.368441 loss)
I0927 00:51:44.649351  2459 solver.cpp:218] Iteration 52500 (5.51146 iter/s, 18.144s/100 iters), loss = 0.0971842
I0927 00:51:44.649380  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.097184 (* 1 = 0.097184 loss)
I0927 00:51:44.649386  2459 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0927 00:51:59.232579  2459 solver.cpp:218] Iteration 52600 (6.85722 iter/s, 14.5832s/100 iters), loss = 0.0939226
I0927 00:51:59.232621  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0939224 (* 1 = 0.0939224 loss)
I0927 00:51:59.232627  2459 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0927 00:52:13.825698  2459 solver.cpp:218] Iteration 52700 (6.85258 iter/s, 14.5931s/100 iters), loss = 0.143595
I0927 00:52:13.825796  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143595 (* 1 = 0.143595 loss)
I0927 00:52:13.825803  2459 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0927 00:52:28.414997  2459 solver.cpp:218] Iteration 52800 (6.8544 iter/s, 14.5892s/100 iters), loss = 0.0542627
I0927 00:52:28.415045  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0542625 (* 1 = 0.0542625 loss)
I0927 00:52:28.415051  2459 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0927 00:52:43.000905  2459 solver.cpp:218] Iteration 52900 (6.85597 iter/s, 14.5858s/100 iters), loss = 0.0402831
I0927 00:52:43.000947  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402828 (* 1 = 0.0402828 loss)
I0927 00:52:43.000953  2459 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0927 00:52:56.861214  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:52:57.444650  2459 solver.cpp:330] Iteration 53000, Testing net (#0)
I0927 00:53:00.863282  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:53:01.005877  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8871
I0927 00:53:01.005913  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36445 (* 1 = 0.36445 loss)
I0927 00:53:01.150044  2459 solver.cpp:218] Iteration 53000 (5.50992 iter/s, 18.1491s/100 iters), loss = 0.094522
I0927 00:53:01.150074  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0945218 (* 1 = 0.0945218 loss)
I0927 00:53:01.150080  2459 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0927 00:53:15.731060  2459 solver.cpp:218] Iteration 53100 (6.85826 iter/s, 14.581s/100 iters), loss = 0.0622134
I0927 00:53:15.731101  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0622131 (* 1 = 0.0622131 loss)
I0927 00:53:15.731107  2459 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0927 00:53:30.316776  2459 solver.cpp:218] Iteration 53200 (6.85605 iter/s, 14.5856s/100 iters), loss = 0.0619313
I0927 00:53:30.316854  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061931 (* 1 = 0.061931 loss)
I0927 00:53:30.316860  2459 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0927 00:53:44.900647  2459 solver.cpp:218] Iteration 53300 (6.85694 iter/s, 14.5838s/100 iters), loss = 0.075615
I0927 00:53:44.900688  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756148 (* 1 = 0.0756148 loss)
I0927 00:53:44.900694  2459 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0927 00:53:59.481796  2459 solver.cpp:218] Iteration 53400 (6.8582 iter/s, 14.5811s/100 iters), loss = 0.0500804
I0927 00:53:59.481827  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0500801 (* 1 = 0.0500801 loss)
I0927 00:53:59.481832  2459 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0927 00:54:13.343076  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:54:13.926810  2459 solver.cpp:330] Iteration 53500, Testing net (#0)
I0927 00:54:17.344406  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:54:17.487356  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8872
I0927 00:54:17.487392  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364999 (* 1 = 0.364999 loss)
I0927 00:54:17.632797  2459 solver.cpp:218] Iteration 53500 (5.50936 iter/s, 18.1509s/100 iters), loss = 0.0524247
I0927 00:54:17.632824  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0524244 (* 1 = 0.0524244 loss)
I0927 00:54:17.632830  2459 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0927 00:54:32.211290  2459 solver.cpp:218] Iteration 53600 (6.85944 iter/s, 14.5784s/100 iters), loss = 0.0875134
I0927 00:54:32.211333  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0875131 (* 1 = 0.0875131 loss)
I0927 00:54:32.211339  2459 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0927 00:54:46.798522  2459 solver.cpp:218] Iteration 53700 (6.85534 iter/s, 14.5872s/100 iters), loss = 0.043818
I0927 00:54:46.798656  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438178 (* 1 = 0.0438178 loss)
I0927 00:54:46.798666  2459 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0927 00:55:01.384943  2459 solver.cpp:218] Iteration 53800 (6.85576 iter/s, 14.5863s/100 iters), loss = 0.0885336
I0927 00:55:01.384984  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0885334 (* 1 = 0.0885334 loss)
I0927 00:55:01.384990  2459 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0927 00:55:15.970901  2459 solver.cpp:218] Iteration 53900 (6.85594 iter/s, 14.5859s/100 iters), loss = 0.0655857
I0927 00:55:15.970942  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655855 (* 1 = 0.0655855 loss)
I0927 00:55:15.970948  2459 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0927 00:55:29.835696  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:55:30.420598  2459 solver.cpp:330] Iteration 54000, Testing net (#0)
I0927 00:55:33.839536  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:55:33.982851  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8811
I0927 00:55:33.982887  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393053 (* 1 = 0.393053 loss)
I0927 00:55:34.128074  2459 solver.cpp:218] Iteration 54000 (5.50749 iter/s, 18.1571s/100 iters), loss = 0.0547509
I0927 00:55:34.128100  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0547508 (* 1 = 0.0547508 loss)
I0927 00:55:34.128106  2459 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0927 00:55:48.701896  2459 solver.cpp:218] Iteration 54100 (6.86164 iter/s, 14.5738s/100 iters), loss = 0.127486
I0927 00:55:48.701936  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127485 (* 1 = 0.127485 loss)
I0927 00:55:48.701942  2459 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0927 00:56:03.269637  2459 solver.cpp:218] Iteration 54200 (6.86451 iter/s, 14.5677s/100 iters), loss = 0.0633039
I0927 00:56:03.269775  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0633037 (* 1 = 0.0633037 loss)
I0927 00:56:03.269783  2459 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0927 00:56:17.840508  2459 solver.cpp:218] Iteration 54300 (6.86308 iter/s, 14.5707s/100 iters), loss = 0.0474734
I0927 00:56:17.840549  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474732 (* 1 = 0.0474732 loss)
I0927 00:56:17.840555  2459 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0927 00:56:32.414460  2459 solver.cpp:218] Iteration 54400 (6.86159 iter/s, 14.5739s/100 iters), loss = 0.0671977
I0927 00:56:32.414502  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0671975 (* 1 = 0.0671975 loss)
I0927 00:56:32.414508  2459 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0927 00:56:46.263836  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:56:46.847147  2459 solver.cpp:330] Iteration 54500, Testing net (#0)
I0927 00:56:50.264992  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:56:50.407419  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8832
I0927 00:56:50.407456  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388929 (* 1 = 0.388929 loss)
I0927 00:56:50.552049  2459 solver.cpp:218] Iteration 54500 (5.51343 iter/s, 18.1375s/100 iters), loss = 0.114963
I0927 00:56:50.552078  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114963 (* 1 = 0.114963 loss)
I0927 00:56:50.552085  2459 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0927 00:57:05.128729  2459 solver.cpp:218] Iteration 54600 (6.8603 iter/s, 14.5766s/100 iters), loss = 0.0761211
I0927 00:57:05.128769  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0761209 (* 1 = 0.0761209 loss)
I0927 00:57:05.128777  2459 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0927 00:57:19.708006  2459 solver.cpp:218] Iteration 54700 (6.85908 iter/s, 14.5792s/100 iters), loss = 0.0816707
I0927 00:57:19.708109  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816705 (* 1 = 0.0816705 loss)
I0927 00:57:19.708117  2459 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0927 00:57:34.289425  2459 solver.cpp:218] Iteration 54800 (6.8581 iter/s, 14.5813s/100 iters), loss = 0.0607405
I0927 00:57:34.289468  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0607403 (* 1 = 0.0607403 loss)
I0927 00:57:34.289474  2459 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0927 00:57:48.872931  2459 solver.cpp:218] Iteration 54900 (6.85709 iter/s, 14.5834s/100 iters), loss = 0.0554016
I0927 00:57:48.872959  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554014 (* 1 = 0.0554014 loss)
I0927 00:57:48.872965  2459 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0927 00:58:02.730403  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:58:03.314637  2459 solver.cpp:330] Iteration 55000, Testing net (#0)
I0927 00:58:06.733712  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:58:06.876423  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8897
I0927 00:58:06.876459  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371741 (* 1 = 0.371741 loss)
I0927 00:58:07.021564  2459 solver.cpp:218] Iteration 55000 (5.51007 iter/s, 18.1486s/100 iters), loss = 0.109492
I0927 00:58:07.021590  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109492 (* 1 = 0.109492 loss)
I0927 00:58:07.021597  2459 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0927 00:58:21.592301  2459 solver.cpp:218] Iteration 55100 (6.86309 iter/s, 14.5707s/100 iters), loss = 0.0619895
I0927 00:58:21.592342  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0619893 (* 1 = 0.0619893 loss)
I0927 00:58:21.592348  2459 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0927 00:58:36.160372  2459 solver.cpp:218] Iteration 55200 (6.86436 iter/s, 14.568s/100 iters), loss = 0.0815496
I0927 00:58:36.160465  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0815493 (* 1 = 0.0815493 loss)
I0927 00:58:36.160480  2459 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0927 00:58:50.731330  2459 solver.cpp:218] Iteration 55300 (6.86302 iter/s, 14.5708s/100 iters), loss = 0.0866118
I0927 00:58:50.731371  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0866116 (* 1 = 0.0866116 loss)
I0927 00:58:50.731377  2459 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0927 00:59:05.308473  2459 solver.cpp:218] Iteration 55400 (6.86009 iter/s, 14.5771s/100 iters), loss = 0.0337219
I0927 00:59:05.308503  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337217 (* 1 = 0.0337217 loss)
I0927 00:59:05.308509  2459 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0927 00:59:19.156579  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:59:19.739699  2459 solver.cpp:330] Iteration 55500, Testing net (#0)
I0927 00:59:23.157353  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:59:23.300144  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8823
I0927 00:59:23.300179  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393686 (* 1 = 0.393686 loss)
I0927 00:59:23.444176  2459 solver.cpp:218] Iteration 55500 (5.514 iter/s, 18.1356s/100 iters), loss = 0.0365617
I0927 00:59:23.444205  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365615 (* 1 = 0.0365615 loss)
I0927 00:59:23.444228  2459 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0927 00:59:38.013553  2459 solver.cpp:218] Iteration 55600 (6.86374 iter/s, 14.5693s/100 iters), loss = 0.117401
I0927 00:59:38.013594  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117401 (* 1 = 0.117401 loss)
I0927 00:59:38.013602  2459 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0927 00:59:52.590030  2459 solver.cpp:218] Iteration 55700 (6.8604 iter/s, 14.5764s/100 iters), loss = 0.0944532
I0927 00:59:52.590137  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0944529 (* 1 = 0.0944529 loss)
I0927 00:59:52.590143  2459 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0927 01:00:07.162554  2459 solver.cpp:218] Iteration 55800 (6.86229 iter/s, 14.5724s/100 iters), loss = 0.0921036
I0927 01:00:07.162585  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0921033 (* 1 = 0.0921033 loss)
I0927 01:00:07.162590  2459 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0927 01:00:21.740185  2459 solver.cpp:218] Iteration 55900 (6.85985 iter/s, 14.5776s/100 iters), loss = 0.0521559
I0927 01:00:21.740228  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521556 (* 1 = 0.0521556 loss)
I0927 01:00:21.740234  2459 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0927 01:00:35.590126  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:00:36.173835  2459 solver.cpp:330] Iteration 56000, Testing net (#0)
I0927 01:00:39.590807  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:00:39.733661  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8859
I0927 01:00:39.733698  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389013 (* 1 = 0.389013 loss)
I0927 01:00:39.878381  2459 solver.cpp:218] Iteration 56000 (5.51325 iter/s, 18.1381s/100 iters), loss = 0.0554886
I0927 01:00:39.878407  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554883 (* 1 = 0.0554883 loss)
I0927 01:00:39.878414  2459 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0927 01:00:54.453403  2459 solver.cpp:218] Iteration 56100 (6.86108 iter/s, 14.575s/100 iters), loss = 0.0618876
I0927 01:00:54.453435  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618872 (* 1 = 0.0618872 loss)
I0927 01:00:54.453441  2459 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0927 01:01:09.030886  2459 solver.cpp:218] Iteration 56200 (6.85992 iter/s, 14.5774s/100 iters), loss = 0.0930343
I0927 01:01:09.030988  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.093034 (* 1 = 0.093034 loss)
I0927 01:01:09.030995  2459 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0927 01:01:23.604826  2459 solver.cpp:218] Iteration 56300 (6.86162 iter/s, 14.5738s/100 iters), loss = 0.0559262
I0927 01:01:23.604867  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559259 (* 1 = 0.0559259 loss)
I0927 01:01:23.604873  2459 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0927 01:01:38.176079  2459 solver.cpp:218] Iteration 56400 (6.86286 iter/s, 14.5712s/100 iters), loss = 0.0194335
I0927 01:01:38.176118  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194332 (* 1 = 0.0194332 loss)
I0927 01:01:38.176126  2459 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0927 01:01:52.028257  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:01:52.612489  2459 solver.cpp:330] Iteration 56500, Testing net (#0)
I0927 01:01:56.028806  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:01:56.171244  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.883
I0927 01:01:56.171280  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389073 (* 1 = 0.389073 loss)
I0927 01:01:56.316514  2459 solver.cpp:218] Iteration 56500 (5.51257 iter/s, 18.1404s/100 iters), loss = 0.0598953
I0927 01:01:56.316540  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0598949 (* 1 = 0.0598949 loss)
I0927 01:01:56.316546  2459 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0927 01:02:10.889055  2459 solver.cpp:218] Iteration 56600 (6.86225 iter/s, 14.5725s/100 iters), loss = 0.115001
I0927 01:02:10.889096  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115 (* 1 = 0.115 loss)
I0927 01:02:10.889101  2459 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0927 01:02:25.468116  2459 solver.cpp:218] Iteration 56700 (6.85918 iter/s, 14.579s/100 iters), loss = 0.0437599
I0927 01:02:25.468226  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437596 (* 1 = 0.0437596 loss)
I0927 01:02:25.468243  2459 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0927 01:02:40.047818  2459 solver.cpp:218] Iteration 56800 (6.85891 iter/s, 14.5796s/100 iters), loss = 0.125819
I0927 01:02:40.047859  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125819 (* 1 = 0.125819 loss)
I0927 01:02:40.047865  2459 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0927 01:02:54.626588  2459 solver.cpp:218] Iteration 56900 (6.85932 iter/s, 14.5787s/100 iters), loss = 0.0280969
I0927 01:02:54.626629  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280966 (* 1 = 0.0280966 loss)
I0927 01:02:54.626636  2459 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0927 01:03:08.480970  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:03:09.065079  2459 solver.cpp:330] Iteration 57000, Testing net (#0)
I0927 01:03:12.483286  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:03:12.625587  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8801
I0927 01:03:12.625623  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.408716 (* 1 = 0.408716 loss)
I0927 01:03:12.770251  2459 solver.cpp:218] Iteration 57000 (5.51159 iter/s, 18.1436s/100 iters), loss = 0.0367506
I0927 01:03:12.770279  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367503 (* 1 = 0.0367503 loss)
I0927 01:03:12.770287  2459 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0927 01:03:27.346614  2459 solver.cpp:218] Iteration 57100 (6.86045 iter/s, 14.5763s/100 iters), loss = 0.0439445
I0927 01:03:27.346654  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439442 (* 1 = 0.0439442 loss)
I0927 01:03:27.346660  2459 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0927 01:03:41.923661  2459 solver.cpp:218] Iteration 57200 (6.86013 iter/s, 14.577s/100 iters), loss = 0.0572803
I0927 01:03:41.923769  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.05728 (* 1 = 0.05728 loss)
I0927 01:03:41.923776  2459 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0927 01:03:56.498435  2459 solver.cpp:218] Iteration 57300 (6.86123 iter/s, 14.5746s/100 iters), loss = 0.0463252
I0927 01:03:56.498477  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463249 (* 1 = 0.0463249 loss)
I0927 01:03:56.498483  2459 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0927 01:04:11.081351  2459 solver.cpp:218] Iteration 57400 (6.85737 iter/s, 14.5829s/100 iters), loss = 0.0313734
I0927 01:04:11.081393  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313731 (* 1 = 0.0313731 loss)
I0927 01:04:11.081399  2459 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0927 01:04:24.940057  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:04:25.523582  2459 solver.cpp:330] Iteration 57500, Testing net (#0)
I0927 01:04:28.942247  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:04:29.084897  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.879
I0927 01:04:29.084933  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.418566 (* 1 = 0.418566 loss)
I0927 01:04:29.230145  2459 solver.cpp:218] Iteration 57500 (5.51003 iter/s, 18.1487s/100 iters), loss = 0.0362436
I0927 01:04:29.230173  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362433 (* 1 = 0.0362433 loss)
I0927 01:04:29.230180  2459 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0927 01:04:43.797502  2459 solver.cpp:218] Iteration 57600 (6.86469 iter/s, 14.5673s/100 iters), loss = 0.061874
I0927 01:04:43.797544  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618736 (* 1 = 0.0618736 loss)
I0927 01:04:43.797549  2459 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0927 01:04:58.368312  2459 solver.cpp:218] Iteration 57700 (6.86307 iter/s, 14.5707s/100 iters), loss = 0.0338292
I0927 01:04:58.368453  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338289 (* 1 = 0.0338289 loss)
I0927 01:04:58.368460  2459 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0927 01:05:12.942539  2459 solver.cpp:218] Iteration 57800 (6.8615 iter/s, 14.5741s/100 iters), loss = 0.0627195
I0927 01:05:12.942570  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0627192 (* 1 = 0.0627192 loss)
I0927 01:05:12.942576  2459 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0927 01:05:27.511884  2459 solver.cpp:218] Iteration 57900 (6.86375 iter/s, 14.5693s/100 iters), loss = 0.0483804
I0927 01:05:27.511925  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04838 (* 1 = 0.04838 loss)
I0927 01:05:27.511931  2459 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0927 01:05:41.360254  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:05:41.943944  2459 solver.cpp:330] Iteration 58000, Testing net (#0)
I0927 01:05:45.361986  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:05:45.504680  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8655
I0927 01:05:45.504716  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.476501 (* 1 = 0.476501 loss)
I0927 01:05:45.649232  2459 solver.cpp:218] Iteration 58000 (5.51351 iter/s, 18.1373s/100 iters), loss = 0.0657267
I0927 01:05:45.649260  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0657263 (* 1 = 0.0657263 loss)
I0927 01:05:45.649267  2459 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0927 01:06:00.216919  2459 solver.cpp:218] Iteration 58100 (6.86453 iter/s, 14.5676s/100 iters), loss = 0.0628211
I0927 01:06:00.216951  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628208 (* 1 = 0.0628208 loss)
I0927 01:06:00.216958  2459 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0927 01:06:14.793015  2459 solver.cpp:218] Iteration 58200 (6.86057 iter/s, 14.576s/100 iters), loss = 0.112412
I0927 01:06:14.793138  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112412 (* 1 = 0.112412 loss)
I0927 01:06:14.793155  2459 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0927 01:06:29.365305  2459 solver.cpp:218] Iteration 58300 (6.86241 iter/s, 14.5721s/100 iters), loss = 0.162392
I0927 01:06:29.365345  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162391 (* 1 = 0.162391 loss)
I0927 01:06:29.365350  2459 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0927 01:06:43.938263  2459 solver.cpp:218] Iteration 58400 (6.86206 iter/s, 14.5729s/100 iters), loss = 0.0323554
I0927 01:06:43.938304  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323551 (* 1 = 0.0323551 loss)
I0927 01:06:43.938310  2459 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0927 01:06:57.787523  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:06:58.370682  2459 solver.cpp:330] Iteration 58500, Testing net (#0)
I0927 01:07:01.789417  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:07:01.932319  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8845
I0927 01:07:01.932356  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385465 (* 1 = 0.385465 loss)
I0927 01:07:02.076578  2459 solver.cpp:218] Iteration 58500 (5.51321 iter/s, 18.1382s/100 iters), loss = 0.046024
I0927 01:07:02.076606  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460237 (* 1 = 0.0460237 loss)
I0927 01:07:02.076613  2459 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0927 01:07:16.648427  2459 solver.cpp:218] Iteration 58600 (6.86257 iter/s, 14.5718s/100 iters), loss = 0.0319314
I0927 01:07:16.648459  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319311 (* 1 = 0.0319311 loss)
I0927 01:07:16.648465  2459 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0927 01:07:31.228945  2459 solver.cpp:218] Iteration 58700 (6.85849 iter/s, 14.5805s/100 iters), loss = 0.0322708
I0927 01:07:31.229079  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322705 (* 1 = 0.0322705 loss)
I0927 01:07:31.229086  2459 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0927 01:07:45.801316  2459 solver.cpp:218] Iteration 58800 (6.86238 iter/s, 14.5722s/100 iters), loss = 0.0530878
I0927 01:07:45.801357  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0530875 (* 1 = 0.0530875 loss)
I0927 01:07:45.801362  2459 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0927 01:08:00.372622  2459 solver.cpp:218] Iteration 58900 (6.86283 iter/s, 14.5712s/100 iters), loss = 0.0895105
I0927 01:08:00.372663  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0895102 (* 1 = 0.0895102 loss)
I0927 01:08:00.372668  2459 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0927 01:08:14.222455  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:08:14.805493  2459 solver.cpp:330] Iteration 59000, Testing net (#0)
I0927 01:08:18.224073  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:08:18.366708  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8926
I0927 01:08:18.366742  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374462 (* 1 = 0.374462 loss)
I0927 01:08:18.511878  2459 solver.cpp:218] Iteration 59000 (5.51293 iter/s, 18.1392s/100 iters), loss = 0.0628341
I0927 01:08:18.511905  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628338 (* 1 = 0.0628338 loss)
I0927 01:08:18.511911  2459 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0927 01:08:33.086005  2459 solver.cpp:218] Iteration 59100 (6.8615 iter/s, 14.5741s/100 iters), loss = 0.0289403
I0927 01:08:33.086035  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02894 (* 1 = 0.02894 loss)
I0927 01:08:33.086041  2459 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0927 01:08:47.655411  2459 solver.cpp:218] Iteration 59200 (6.86372 iter/s, 14.5693s/100 iters), loss = 0.0702834
I0927 01:08:47.655486  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0702832 (* 1 = 0.0702832 loss)
I0927 01:08:47.655494  2459 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0927 01:09:02.224937  2459 solver.cpp:218] Iteration 59300 (6.86369 iter/s, 14.5694s/100 iters), loss = 0.0384278
I0927 01:09:02.224978  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384275 (* 1 = 0.0384275 loss)
I0927 01:09:02.224984  2459 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0927 01:09:16.795235  2459 solver.cpp:218] Iteration 59400 (6.86331 iter/s, 14.5702s/100 iters), loss = 0.0537282
I0927 01:09:16.795266  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0537279 (* 1 = 0.0537279 loss)
I0927 01:09:16.795272  2459 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0927 01:09:30.639287  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:09:31.222828  2459 solver.cpp:330] Iteration 59500, Testing net (#0)
I0927 01:09:34.639791  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:09:34.782517  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8907
I0927 01:09:34.782552  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377933 (* 1 = 0.377933 loss)
I0927 01:09:34.927290  2459 solver.cpp:218] Iteration 59500 (5.51511 iter/s, 18.132s/100 iters), loss = 0.032004
I0927 01:09:34.927319  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320037 (* 1 = 0.0320037 loss)
I0927 01:09:34.927325  2459 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0927 01:09:49.509487  2459 solver.cpp:218] Iteration 59600 (6.8577 iter/s, 14.5821s/100 iters), loss = 0.056749
I0927 01:09:49.509526  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0567487 (* 1 = 0.0567487 loss)
I0927 01:09:49.509532  2459 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0927 01:10:04.093384  2459 solver.cpp:218] Iteration 59700 (6.85691 iter/s, 14.5838s/100 iters), loss = 0.0421534
I0927 01:10:04.093518  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0421531 (* 1 = 0.0421531 loss)
I0927 01:10:04.093528  2459 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0927 01:10:18.665249  2459 solver.cpp:218] Iteration 59800 (6.86261 iter/s, 14.5717s/100 iters), loss = 0.0514806
I0927 01:10:18.665280  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514803 (* 1 = 0.0514803 loss)
I0927 01:10:18.665295  2459 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0927 01:10:33.240720  2459 solver.cpp:218] Iteration 59900 (6.86087 iter/s, 14.5754s/100 iters), loss = 0.043284
I0927 01:10:33.240749  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432837 (* 1 = 0.0432837 loss)
I0927 01:10:33.240766  2459 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0927 01:10:47.093067  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:10:47.675613  2459 solver.cpp:330] Iteration 60000, Testing net (#0)
I0927 01:10:51.093180  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:10:51.235882  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8781
I0927 01:10:51.235908  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424967 (* 1 = 0.424967 loss)
I0927 01:10:51.380436  2459 solver.cpp:218] Iteration 60000 (5.51278 iter/s, 18.1397s/100 iters), loss = 0.0338803
I0927 01:10:51.380463  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03388 (* 1 = 0.03388 loss)
I0927 01:10:51.380470  2459 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0927 01:11:05.946759  2459 solver.cpp:218] Iteration 60100 (6.86517 iter/s, 14.5663s/100 iters), loss = 0.0335984
I0927 01:11:05.946800  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335982 (* 1 = 0.0335982 loss)
I0927 01:11:05.946806  2459 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0927 01:11:20.519321  2459 solver.cpp:218] Iteration 60200 (6.86224 iter/s, 14.5725s/100 iters), loss = 0.0842161
I0927 01:11:20.519400  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0842158 (* 1 = 0.0842158 loss)
I0927 01:11:20.519407  2459 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0927 01:11:35.086724  2459 solver.cpp:218] Iteration 60300 (6.86469 iter/s, 14.5673s/100 iters), loss = 0.0682083
I0927 01:11:35.086755  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068208 (* 1 = 0.068208 loss)
I0927 01:11:35.086760  2459 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0927 01:11:49.657299  2459 solver.cpp:218] Iteration 60400 (6.86317 iter/s, 14.5705s/100 iters), loss = 0.0639914
I0927 01:11:49.657341  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0639911 (* 1 = 0.0639911 loss)
I0927 01:11:49.657346  2459 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0927 01:12:03.505342  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:12:04.088217  2459 solver.cpp:330] Iteration 60500, Testing net (#0)
I0927 01:12:07.505136  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:12:07.647675  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8743
I0927 01:12:07.647711  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.438342 (* 1 = 0.438342 loss)
I0927 01:12:07.791831  2459 solver.cpp:218] Iteration 60500 (5.51436 iter/s, 18.1345s/100 iters), loss = 0.0729966
I0927 01:12:07.791859  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729963 (* 1 = 0.0729963 loss)
I0927 01:12:07.791865  2459 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0927 01:12:22.367117  2459 solver.cpp:218] Iteration 60600 (6.86095 iter/s, 14.5752s/100 iters), loss = 0.0801474
I0927 01:12:22.367159  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0801471 (* 1 = 0.0801471 loss)
I0927 01:12:22.367166  2459 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0927 01:12:36.948464  2459 solver.cpp:218] Iteration 60700 (6.85811 iter/s, 14.5813s/100 iters), loss = 0.0752816
I0927 01:12:36.948552  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752814 (* 1 = 0.0752814 loss)
I0927 01:12:36.948568  2459 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0927 01:12:51.527745  2459 solver.cpp:218] Iteration 60800 (6.8591 iter/s, 14.5792s/100 iters), loss = 0.0891242
I0927 01:12:51.527787  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0891239 (* 1 = 0.0891239 loss)
I0927 01:12:51.527793  2459 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0927 01:13:06.111237  2459 solver.cpp:218] Iteration 60900 (6.8571 iter/s, 14.5834s/100 iters), loss = 0.0617241
I0927 01:13:06.111277  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0617238 (* 1 = 0.0617238 loss)
I0927 01:13:06.111284  2459 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0927 01:13:19.969738  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:13:20.553922  2459 solver.cpp:330] Iteration 61000, Testing net (#0)
I0927 01:13:23.971181  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:13:24.113667  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8748
I0927 01:13:24.113703  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.486692 (* 1 = 0.486692 loss)
I0927 01:13:24.258287  2459 solver.cpp:218] Iteration 61000 (5.51056 iter/s, 18.147s/100 iters), loss = 0.0568859
I0927 01:13:24.258316  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568856 (* 1 = 0.0568856 loss)
I0927 01:13:24.258322  2459 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0927 01:13:38.832301  2459 solver.cpp:218] Iteration 61100 (6.86155 iter/s, 14.574s/100 iters), loss = 0.123171
I0927 01:13:38.832332  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123171 (* 1 = 0.123171 loss)
I0927 01:13:38.832339  2459 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0927 01:13:53.412765  2459 solver.cpp:218] Iteration 61200 (6.85852 iter/s, 14.5804s/100 iters), loss = 0.131568
I0927 01:13:53.412888  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131568 (* 1 = 0.131568 loss)
I0927 01:13:53.412905  2459 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0927 01:14:07.993649  2459 solver.cpp:218] Iteration 61300 (6.85836 iter/s, 14.5807s/100 iters), loss = 0.0504426
I0927 01:14:07.993690  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504423 (* 1 = 0.0504423 loss)
I0927 01:14:07.993696  2459 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0927 01:14:22.573951  2459 solver.cpp:218] Iteration 61400 (6.8586 iter/s, 14.5802s/100 iters), loss = 0.0730811
I0927 01:14:22.573992  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0730808 (* 1 = 0.0730808 loss)
I0927 01:14:22.573998  2459 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0927 01:14:36.432613  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:14:37.015803  2459 solver.cpp:330] Iteration 61500, Testing net (#0)
I0927 01:14:40.433859  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:14:40.576194  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8781
I0927 01:14:40.576247  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406142 (* 1 = 0.406142 loss)
I0927 01:14:40.720906  2459 solver.cpp:218] Iteration 61500 (5.51059 iter/s, 18.1469s/100 iters), loss = 0.0519641
I0927 01:14:40.720933  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519638 (* 1 = 0.0519638 loss)
I0927 01:14:40.720939  2459 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0927 01:14:55.303761  2459 solver.cpp:218] Iteration 61600 (6.85739 iter/s, 14.5828s/100 iters), loss = 0.0506101
I0927 01:14:55.303802  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0506099 (* 1 = 0.0506099 loss)
I0927 01:14:55.303808  2459 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0927 01:15:09.892112  2459 solver.cpp:218] Iteration 61700 (6.85481 iter/s, 14.5883s/100 iters), loss = 0.103131
I0927 01:15:09.892199  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103131 (* 1 = 0.103131 loss)
I0927 01:15:09.892220  2459 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0927 01:15:24.479794  2459 solver.cpp:218] Iteration 61800 (6.85515 iter/s, 14.5876s/100 iters), loss = 0.0514601
I0927 01:15:24.479837  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514597 (* 1 = 0.0514597 loss)
I0927 01:15:24.479843  2459 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0927 01:15:39.067339  2459 solver.cpp:218] Iteration 61900 (6.85519 iter/s, 14.5875s/100 iters), loss = 0.0239391
I0927 01:15:39.067379  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239387 (* 1 = 0.0239387 loss)
I0927 01:15:39.067386  2459 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0927 01:15:52.934090  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:15:53.518517  2459 solver.cpp:330] Iteration 62000, Testing net (#0)
I0927 01:15:56.934795  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:15:57.076551  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8711
I0927 01:15:57.076587  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.50873 (* 1 = 0.50873 loss)
I0927 01:15:57.221079  2459 solver.cpp:218] Iteration 62000 (5.50853 iter/s, 18.1537s/100 iters), loss = 0.0339109
I0927 01:15:57.221107  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339106 (* 1 = 0.0339106 loss)
I0927 01:15:57.221114  2459 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0927 01:16:11.796999  2459 solver.cpp:218] Iteration 62100 (6.86066 iter/s, 14.5759s/100 iters), loss = 0.0796519
I0927 01:16:11.797049  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0796516 (* 1 = 0.0796516 loss)
I0927 01:16:11.797055  2459 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0927 01:16:26.372406  2459 solver.cpp:218] Iteration 62200 (6.86091 iter/s, 14.5753s/100 iters), loss = 0.0960963
I0927 01:16:26.372483  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.096096 (* 1 = 0.096096 loss)
I0927 01:16:26.372490  2459 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0927 01:16:40.945724  2459 solver.cpp:218] Iteration 62300 (6.8619 iter/s, 14.5732s/100 iters), loss = 0.112826
I0927 01:16:40.945765  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112826 (* 1 = 0.112826 loss)
I0927 01:16:40.945771  2459 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0927 01:16:55.531222  2459 solver.cpp:218] Iteration 62400 (6.85616 iter/s, 14.5854s/100 iters), loss = 0.069248
I0927 01:16:55.531263  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0692477 (* 1 = 0.0692477 loss)
I0927 01:16:55.531270  2459 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0927 01:17:09.384929  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:17:09.968844  2459 solver.cpp:330] Iteration 62500, Testing net (#0)
I0927 01:17:13.385362  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:17:13.527232  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8714
I0927 01:17:13.527269  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.459613 (* 1 = 0.459613 loss)
I0927 01:17:13.672227  2459 solver.cpp:218] Iteration 62500 (5.51239 iter/s, 18.1409s/100 iters), loss = 0.0908463
I0927 01:17:13.672255  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0908461 (* 1 = 0.0908461 loss)
I0927 01:17:13.672263  2459 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0927 01:17:28.251710  2459 solver.cpp:218] Iteration 62600 (6.85898 iter/s, 14.5794s/100 iters), loss = 0.03832
I0927 01:17:28.251751  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383197 (* 1 = 0.0383197 loss)
I0927 01:17:28.251757  2459 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0927 01:17:42.843601  2459 solver.cpp:218] Iteration 62700 (6.85315 iter/s, 14.5918s/100 iters), loss = 0.046897
I0927 01:17:42.843721  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0468967 (* 1 = 0.0468967 loss)
I0927 01:17:42.843739  2459 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0927 01:17:57.419960  2459 solver.cpp:218] Iteration 62800 (6.86049 iter/s, 14.5762s/100 iters), loss = 0.0565819
I0927 01:17:57.420002  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0565816 (* 1 = 0.0565816 loss)
I0927 01:17:57.420008  2459 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0927 01:18:11.999466  2459 solver.cpp:218] Iteration 62900 (6.85897 iter/s, 14.5794s/100 iters), loss = 0.0279614
I0927 01:18:11.999514  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279611 (* 1 = 0.0279611 loss)
I0927 01:18:11.999522  2459 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0927 01:18:25.855381  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:18:26.438233  2459 solver.cpp:330] Iteration 63000, Testing net (#0)
I0927 01:18:29.855731  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:18:29.998320  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8835
I0927 01:18:29.998356  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402578 (* 1 = 0.402578 loss)
I0927 01:18:30.143324  2459 solver.cpp:218] Iteration 63000 (5.51153 iter/s, 18.1438s/100 iters), loss = 0.0325731
I0927 01:18:30.143353  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325729 (* 1 = 0.0325729 loss)
I0927 01:18:30.143360  2459 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0927 01:18:44.733875  2459 solver.cpp:218] Iteration 63100 (6.85378 iter/s, 14.5905s/100 iters), loss = 0.0541663
I0927 01:18:44.733916  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541661 (* 1 = 0.0541661 loss)
I0927 01:18:44.733922  2459 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0927 01:18:59.327349  2459 solver.cpp:218] Iteration 63200 (6.85241 iter/s, 14.5934s/100 iters), loss = 0.0778335
I0927 01:18:59.327458  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0778333 (* 1 = 0.0778333 loss)
I0927 01:18:59.327466  2459 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0927 01:19:13.922075  2459 solver.cpp:218] Iteration 63300 (6.85185 iter/s, 14.5946s/100 iters), loss = 0.0665434
I0927 01:19:13.922116  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665431 (* 1 = 0.0665431 loss)
I0927 01:19:13.922122  2459 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0927 01:19:28.508733  2459 solver.cpp:218] Iteration 63400 (6.85561 iter/s, 14.5866s/100 iters), loss = 0.0585297
I0927 01:19:28.508774  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0585294 (* 1 = 0.0585294 loss)
I0927 01:19:28.508780  2459 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0927 01:19:42.369047  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:19:42.954435  2459 solver.cpp:330] Iteration 63500, Testing net (#0)
I0927 01:19:46.373292  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:19:46.516084  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8858
I0927 01:19:46.516120  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394815 (* 1 = 0.394815 loss)
I0927 01:19:46.660720  2459 solver.cpp:218] Iteration 63500 (5.50906 iter/s, 18.1519s/100 iters), loss = 0.0389537
I0927 01:19:46.660748  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389534 (* 1 = 0.0389534 loss)
I0927 01:19:46.660754  2459 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0927 01:20:01.240427  2459 solver.cpp:218] Iteration 63600 (6.85887 iter/s, 14.5797s/100 iters), loss = 0.0523335
I0927 01:20:01.240458  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0523333 (* 1 = 0.0523333 loss)
I0927 01:20:01.240464  2459 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0927 01:20:15.823460  2459 solver.cpp:218] Iteration 63700 (6.85731 iter/s, 14.583s/100 iters), loss = 0.0322542
I0927 01:20:15.823570  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032254 (* 1 = 0.032254 loss)
I0927 01:20:15.823587  2459 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0927 01:20:30.403645  2459 solver.cpp:218] Iteration 63800 (6.85869 iter/s, 14.5801s/100 iters), loss = 0.0588532
I0927 01:20:30.403686  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.058853 (* 1 = 0.058853 loss)
I0927 01:20:30.403692  2459 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0927 01:20:44.983222  2459 solver.cpp:218] Iteration 63900 (6.85894 iter/s, 14.5795s/100 iters), loss = 0.0389243
I0927 01:20:44.983253  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389241 (* 1 = 0.0389241 loss)
I0927 01:20:44.983258  2459 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0927 01:20:58.838524  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:20:59.422029  2459 solver.cpp:330] Iteration 64000, Testing net (#0)
I0927 01:21:02.840672  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:21:02.983413  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8818
I0927 01:21:02.983440  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411572 (* 1 = 0.411572 loss)
I0927 01:21:03.128247  2459 solver.cpp:218] Iteration 64000 (5.51117 iter/s, 18.145s/100 iters), loss = 0.0328867
I0927 01:21:03.128274  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328865 (* 1 = 0.0328865 loss)
I0927 01:21:03.128281  2459 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0927 01:21:17.697160  2459 solver.cpp:218] Iteration 64100 (6.86396 iter/s, 14.5689s/100 iters), loss = 0.0929391
I0927 01:21:17.697201  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0929389 (* 1 = 0.0929389 loss)
I0927 01:21:17.697208  2459 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0927 01:21:32.274359  2459 solver.cpp:218] Iteration 64200 (6.86006 iter/s, 14.5771s/100 iters), loss = 0.0473071
I0927 01:21:32.274437  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473069 (* 1 = 0.0473069 loss)
I0927 01:21:32.274446  2459 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0927 01:21:46.851438  2459 solver.cpp:218] Iteration 64300 (6.86013 iter/s, 14.577s/100 iters), loss = 0.0584185
I0927 01:21:46.851480  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0584183 (* 1 = 0.0584183 loss)
I0927 01:21:46.851485  2459 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0927 01:22:01.428167  2459 solver.cpp:218] Iteration 64400 (6.86028 iter/s, 14.5767s/100 iters), loss = 0.120636
I0927 01:22:01.428211  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120636 (* 1 = 0.120636 loss)
I0927 01:22:01.428217  2459 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0927 01:22:15.282958  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:22:15.867054  2459 solver.cpp:330] Iteration 64500, Testing net (#0)
I0927 01:22:19.284360  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:22:19.427045  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8875
I0927 01:22:19.427083  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388676 (* 1 = 0.388676 loss)
I0927 01:22:19.571866  2459 solver.cpp:218] Iteration 64500 (5.51158 iter/s, 18.1436s/100 iters), loss = 0.029397
I0927 01:22:19.571893  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293969 (* 1 = 0.0293969 loss)
I0927 01:22:19.571900  2459 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0927 01:22:34.143461  2459 solver.cpp:218] Iteration 64600 (6.86269 iter/s, 14.5715s/100 iters), loss = 0.0184191
I0927 01:22:34.143489  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184189 (* 1 = 0.0184189 loss)
I0927 01:22:34.143506  2459 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0927 01:22:48.737277  2459 solver.cpp:218] Iteration 64700 (6.85224 iter/s, 14.5938s/100 iters), loss = 0.0995247
I0927 01:22:48.737370  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0995245 (* 1 = 0.0995245 loss)
I0927 01:22:48.737388  2459 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0927 01:23:03.325610  2459 solver.cpp:218] Iteration 64800 (6.85485 iter/s, 14.5882s/100 iters), loss = 0.0560994
I0927 01:23:03.325641  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560992 (* 1 = 0.0560992 loss)
I0927 01:23:03.325657  2459 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0927 01:23:17.911823  2459 solver.cpp:218] Iteration 64900 (6.85582 iter/s, 14.5862s/100 iters), loss = 0.0402989
I0927 01:23:17.911854  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402987 (* 1 = 0.0402987 loss)
I0927 01:23:17.911870  2459 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0927 01:23:31.776741  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:23:32.361084  2459 solver.cpp:330] Iteration 65000, Testing net (#0)
I0927 01:23:35.779999  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:23:35.922389  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8749
I0927 01:23:35.922425  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.453352 (* 1 = 0.453352 loss)
I0927 01:23:36.067095  2459 solver.cpp:218] Iteration 65000 (5.50806 iter/s, 18.1552s/100 iters), loss = 0.0904725
I0927 01:23:36.067121  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0904723 (* 1 = 0.0904723 loss)
I0927 01:23:36.067128  2459 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0927 01:23:50.642428  2459 solver.cpp:218] Iteration 65100 (6.86093 iter/s, 14.5753s/100 iters), loss = 0.0749796
I0927 01:23:50.642460  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0749794 (* 1 = 0.0749794 loss)
I0927 01:23:50.642477  2459 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0927 01:24:05.219458  2459 solver.cpp:218] Iteration 65200 (6.86013 iter/s, 14.577s/100 iters), loss = 0.0755863
I0927 01:24:05.219521  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0755862 (* 1 = 0.0755862 loss)
I0927 01:24:05.219542  2459 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0927 01:24:19.797267  2459 solver.cpp:218] Iteration 65300 (6.85978 iter/s, 14.5777s/100 iters), loss = 0.0525727
I0927 01:24:19.797299  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0525725 (* 1 = 0.0525725 loss)
I0927 01:24:19.797307  2459 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0927 01:24:34.373787  2459 solver.cpp:218] Iteration 65400 (6.86037 iter/s, 14.5765s/100 iters), loss = 0.0777265
I0927 01:24:34.373817  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0777263 (* 1 = 0.0777263 loss)
I0927 01:24:34.373826  2459 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0927 01:24:48.229485  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:24:48.814738  2459 solver.cpp:330] Iteration 65500, Testing net (#0)
I0927 01:24:52.232913  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:24:52.375610  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8891
I0927 01:24:52.375648  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.407131 (* 1 = 0.407131 loss)
I0927 01:24:52.520375  2459 solver.cpp:218] Iteration 65500 (5.51069 iter/s, 18.1465s/100 iters), loss = 0.0614282
I0927 01:24:52.520403  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061428 (* 1 = 0.061428 loss)
I0927 01:24:52.520411  2459 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0927 01:25:07.095223  2459 solver.cpp:218] Iteration 65600 (6.86116 iter/s, 14.5748s/100 iters), loss = 0.0598002
I0927 01:25:07.095257  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0598001 (* 1 = 0.0598001 loss)
I0927 01:25:07.095264  2459 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0927 01:25:21.671928  2459 solver.cpp:218] Iteration 65700 (6.86029 iter/s, 14.5766s/100 iters), loss = 0.0993292
I0927 01:25:21.672035  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.099329 (* 1 = 0.099329 loss)
I0927 01:25:21.672044  2459 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0927 01:25:36.250499  2459 solver.cpp:218] Iteration 65800 (6.85944 iter/s, 14.5784s/100 iters), loss = 0.0850138
I0927 01:25:36.250531  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0850137 (* 1 = 0.0850137 loss)
I0927 01:25:36.250540  2459 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0927 01:25:50.827541  2459 solver.cpp:218] Iteration 65900 (6.86013 iter/s, 14.577s/100 iters), loss = 0.0278828
I0927 01:25:50.827572  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278827 (* 1 = 0.0278827 loss)
I0927 01:25:50.827580  2459 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0927 01:26:04.682765  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:26:05.267215  2459 solver.cpp:330] Iteration 66000, Testing net (#0)
I0927 01:26:08.685626  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:26:08.828035  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8741
I0927 01:26:08.828073  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.456899 (* 1 = 0.456899 loss)
I0927 01:26:08.973094  2459 solver.cpp:218] Iteration 66000 (5.51101 iter/s, 18.1455s/100 iters), loss = 0.0380386
I0927 01:26:08.973120  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380384 (* 1 = 0.0380384 loss)
I0927 01:26:08.973127  2459 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0927 01:26:23.547130  2459 solver.cpp:218] Iteration 66100 (6.86154 iter/s, 14.574s/100 iters), loss = 0.0257045
I0927 01:26:23.547161  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257043 (* 1 = 0.0257043 loss)
I0927 01:26:23.547169  2459 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0927 01:26:38.124224  2459 solver.cpp:218] Iteration 66200 (6.8601 iter/s, 14.577s/100 iters), loss = 0.0580976
I0927 01:26:38.124356  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580974 (* 1 = 0.0580974 loss)
I0927 01:26:38.124377  2459 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0927 01:26:52.705726  2459 solver.cpp:218] Iteration 66300 (6.85808 iter/s, 14.5814s/100 iters), loss = 0.0398988
I0927 01:26:52.705760  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398986 (* 1 = 0.0398986 loss)
I0927 01:26:52.705767  2459 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0927 01:27:07.287199  2459 solver.cpp:218] Iteration 66400 (6.85804 iter/s, 14.5814s/100 iters), loss = 0.0304979
I0927 01:27:07.287230  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304977 (* 1 = 0.0304977 loss)
I0927 01:27:07.287238  2459 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0927 01:27:21.141372  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:27:21.724660  2459 solver.cpp:330] Iteration 66500, Testing net (#0)
I0927 01:27:25.142717  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:27:25.285348  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8818
I0927 01:27:25.285385  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.429096 (* 1 = 0.429096 loss)
I0927 01:27:25.429534  2459 solver.cpp:218] Iteration 66500 (5.51199 iter/s, 18.1423s/100 iters), loss = 0.0505146
I0927 01:27:25.429560  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505144 (* 1 = 0.0505144 loss)
I0927 01:27:25.429567  2459 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0927 01:27:40.005867  2459 solver.cpp:218] Iteration 66600 (6.86046 iter/s, 14.5763s/100 iters), loss = 0.0993252
I0927 01:27:40.005898  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.099325 (* 1 = 0.099325 loss)
I0927 01:27:40.005906  2459 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0927 01:27:54.580965  2459 solver.cpp:218] Iteration 66700 (6.86104 iter/s, 14.575s/100 iters), loss = 0.13467
I0927 01:27:54.581063  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13467 (* 1 = 0.13467 loss)
I0927 01:27:54.581089  2459 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0927 01:28:09.164368  2459 solver.cpp:218] Iteration 66800 (6.85717 iter/s, 14.5833s/100 iters), loss = 0.0574377
I0927 01:28:09.164400  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574375 (* 1 = 0.0574375 loss)
I0927 01:28:09.164408  2459 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0927 01:28:23.748409  2459 solver.cpp:218] Iteration 66900 (6.85684 iter/s, 14.584s/100 iters), loss = 0.0624472
I0927 01:28:23.748441  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0624471 (* 1 = 0.0624471 loss)
I0927 01:28:23.748450  2459 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0927 01:28:37.602195  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:28:38.186311  2459 solver.cpp:330] Iteration 67000, Testing net (#0)
I0927 01:28:41.604138  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:28:41.746801  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8774
I0927 01:28:41.746837  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.455747 (* 1 = 0.455747 loss)
I0927 01:28:41.891957  2459 solver.cpp:218] Iteration 67000 (5.51162 iter/s, 18.1435s/100 iters), loss = 0.0566383
I0927 01:28:41.891983  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0566382 (* 1 = 0.0566382 loss)
I0927 01:28:41.891989  2459 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0927 01:28:56.476372  2459 solver.cpp:218] Iteration 67100 (6.85666 iter/s, 14.5844s/100 iters), loss = 0.0720466
I0927 01:28:56.476404  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0720464 (* 1 = 0.0720464 loss)
I0927 01:28:56.476410  2459 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0927 01:29:11.064888  2459 solver.cpp:218] Iteration 67200 (6.85473 iter/s, 14.5885s/100 iters), loss = 0.0230492
I0927 01:29:11.064996  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230491 (* 1 = 0.0230491 loss)
I0927 01:29:11.065016  2459 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0927 01:29:25.658951  2459 solver.cpp:218] Iteration 67300 (6.85216 iter/s, 14.5939s/100 iters), loss = 0.0354831
I0927 01:29:25.658993  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354829 (* 1 = 0.0354829 loss)
I0927 01:29:25.658998  2459 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0927 01:29:40.251231  2459 solver.cpp:218] Iteration 67400 (6.85297 iter/s, 14.5922s/100 iters), loss = 0.0750657
I0927 01:29:40.251272  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0750655 (* 1 = 0.0750655 loss)
I0927 01:29:40.251278  2459 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0927 01:29:54.117204  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:29:54.701442  2459 solver.cpp:330] Iteration 67500, Testing net (#0)
I0927 01:29:58.119045  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:29:58.261919  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8788
I0927 01:29:58.261955  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.446394 (* 1 = 0.446394 loss)
I0927 01:29:58.407320  2459 solver.cpp:218] Iteration 67500 (5.50781 iter/s, 18.156s/100 iters), loss = 0.0523773
I0927 01:29:58.407347  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0523771 (* 1 = 0.0523771 loss)
I0927 01:29:58.407354  2459 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0927 01:30:12.982177  2459 solver.cpp:218] Iteration 67600 (6.86116 iter/s, 14.5748s/100 iters), loss = 0.0455308
I0927 01:30:12.982208  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455307 (* 1 = 0.0455307 loss)
I0927 01:30:12.982213  2459 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0927 01:30:27.564111  2459 solver.cpp:218] Iteration 67700 (6.85783 iter/s, 14.5819s/100 iters), loss = 0.0379071
I0927 01:30:27.564187  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037907 (* 1 = 0.037907 loss)
I0927 01:30:27.564193  2459 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0927 01:30:42.151258  2459 solver.cpp:218] Iteration 67800 (6.8554 iter/s, 14.587s/100 iters), loss = 0.082937
I0927 01:30:42.151300  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0829369 (* 1 = 0.0829369 loss)
I0927 01:30:42.151306  2459 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0927 01:30:56.734598  2459 solver.cpp:218] Iteration 67900 (6.85717 iter/s, 14.5833s/100 iters), loss = 0.0819468
I0927 01:30:56.734629  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0819466 (* 1 = 0.0819466 loss)
I0927 01:30:56.734634  2459 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0927 01:31:10.594751  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:31:11.178750  2459 solver.cpp:330] Iteration 68000, Testing net (#0)
I0927 01:31:14.597363  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:31:14.740414  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8833
I0927 01:31:14.740450  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426097 (* 1 = 0.426097 loss)
I0927 01:31:14.885481  2459 solver.cpp:218] Iteration 68000 (5.50939 iter/s, 18.1508s/100 iters), loss = 0.056348
I0927 01:31:14.885509  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0563479 (* 1 = 0.0563479 loss)
I0927 01:31:14.885515  2459 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0927 01:31:29.458942  2459 solver.cpp:218] Iteration 68100 (6.86181 iter/s, 14.5734s/100 iters), loss = 0.0713774
I0927 01:31:29.458973  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0713772 (* 1 = 0.0713772 loss)
I0927 01:31:29.458978  2459 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0927 01:31:44.037361  2459 solver.cpp:218] Iteration 68200 (6.85948 iter/s, 14.5784s/100 iters), loss = 0.07365
I0927 01:31:44.037482  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0736498 (* 1 = 0.0736498 loss)
I0927 01:31:44.037490  2459 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0927 01:31:58.620025  2459 solver.cpp:218] Iteration 68300 (6.85752 iter/s, 14.5825s/100 iters), loss = 0.0620662
I0927 01:31:58.620067  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620661 (* 1 = 0.0620661 loss)
I0927 01:31:58.620074  2459 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0927 01:32:13.201670  2459 solver.cpp:218] Iteration 68400 (6.85797 iter/s, 14.5816s/100 iters), loss = 0.0579141
I0927 01:32:13.201711  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579139 (* 1 = 0.0579139 loss)
I0927 01:32:13.201717  2459 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0927 01:32:27.059394  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:32:27.641484  2459 solver.cpp:330] Iteration 68500, Testing net (#0)
I0927 01:32:31.060329  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:32:31.202872  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8852
I0927 01:32:31.202898  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422675 (* 1 = 0.422675 loss)
I0927 01:32:31.347600  2459 solver.cpp:218] Iteration 68500 (5.5109 iter/s, 18.1459s/100 iters), loss = 0.0528028
I0927 01:32:31.347627  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0528026 (* 1 = 0.0528026 loss)
I0927 01:32:31.347633  2459 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0927 01:32:45.921047  2459 solver.cpp:218] Iteration 68600 (6.86182 iter/s, 14.5734s/100 iters), loss = 0.0547714
I0927 01:32:45.921088  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0547712 (* 1 = 0.0547712 loss)
I0927 01:32:45.921094  2459 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0927 01:33:00.501003  2459 solver.cpp:218] Iteration 68700 (6.85876 iter/s, 14.5799s/100 iters), loss = 0.0864956
I0927 01:33:00.501103  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0864954 (* 1 = 0.0864954 loss)
I0927 01:33:00.501111  2459 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0927 01:33:15.078632  2459 solver.cpp:218] Iteration 68800 (6.85988 iter/s, 14.5775s/100 iters), loss = 0.0348057
I0927 01:33:15.078661  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348055 (* 1 = 0.0348055 loss)
I0927 01:33:15.078667  2459 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0927 01:33:29.661495  2459 solver.cpp:218] Iteration 68900 (6.85739 iter/s, 14.5828s/100 iters), loss = 0.0414983
I0927 01:33:29.661537  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414981 (* 1 = 0.0414981 loss)
I0927 01:33:29.661543  2459 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0927 01:33:43.520493  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:33:44.104071  2459 solver.cpp:330] Iteration 69000, Testing net (#0)
I0927 01:33:47.523414  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:33:47.666234  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8801
I0927 01:33:47.666270  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.430248 (* 1 = 0.430248 loss)
I0927 01:33:47.811318  2459 solver.cpp:218] Iteration 69000 (5.50972 iter/s, 18.1498s/100 iters), loss = 0.0499063
I0927 01:33:47.811345  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499061 (* 1 = 0.0499061 loss)
I0927 01:33:47.811352  2459 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0927 01:34:02.395051  2459 solver.cpp:218] Iteration 69100 (6.85698 iter/s, 14.5837s/100 iters), loss = 0.0761111
I0927 01:34:02.395082  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0761108 (* 1 = 0.0761108 loss)
I0927 01:34:02.395088  2459 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0927 01:34:16.979643  2459 solver.cpp:218] Iteration 69200 (6.85658 iter/s, 14.5845s/100 iters), loss = 0.0298282
I0927 01:34:16.979799  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298279 (* 1 = 0.0298279 loss)
I0927 01:34:16.979809  2459 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0927 01:34:31.566332  2459 solver.cpp:218] Iteration 69300 (6.85565 iter/s, 14.5865s/100 iters), loss = 0.0881545
I0927 01:34:31.566373  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0881542 (* 1 = 0.0881542 loss)
I0927 01:34:31.566380  2459 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0927 01:34:46.149464  2459 solver.cpp:218] Iteration 69400 (6.85727 iter/s, 14.5831s/100 iters), loss = 0.0450476
I0927 01:34:46.149495  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450473 (* 1 = 0.0450473 loss)
I0927 01:34:46.149502  2459 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0927 01:35:00.007450  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:35:00.592792  2459 solver.cpp:330] Iteration 69500, Testing net (#0)
I0927 01:35:04.012385  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:35:04.154134  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8752
I0927 01:35:04.154170  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.467945 (* 1 = 0.467945 loss)
I0927 01:35:04.299564  2459 solver.cpp:218] Iteration 69500 (5.50963 iter/s, 18.15s/100 iters), loss = 0.0247327
I0927 01:35:04.299589  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247324 (* 1 = 0.0247324 loss)
I0927 01:35:04.299595  2459 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0927 01:35:18.886173  2459 solver.cpp:218] Iteration 69600 (6.85563 iter/s, 14.5866s/100 iters), loss = 0.0222616
I0927 01:35:18.886204  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222613 (* 1 = 0.0222613 loss)
I0927 01:35:18.886209  2459 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0927 01:35:33.475524  2459 solver.cpp:218] Iteration 69700 (6.85434 iter/s, 14.5893s/100 iters), loss = 0.0230373
I0927 01:35:33.475594  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230371 (* 1 = 0.0230371 loss)
I0927 01:35:33.475601  2459 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0927 01:35:48.064980  2459 solver.cpp:218] Iteration 69800 (6.85431 iter/s, 14.5894s/100 iters), loss = 0.0650088
I0927 01:35:48.065012  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650085 (* 1 = 0.0650085 loss)
I0927 01:35:48.065019  2459 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0927 01:36:02.651466  2459 solver.cpp:218] Iteration 69900 (6.85569 iter/s, 14.5864s/100 iters), loss = 0.0170449
I0927 01:36:02.651507  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170445 (* 1 = 0.0170445 loss)
I0927 01:36:02.651513  2459 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0927 01:36:16.514334  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:36:17.097796  2459 solver.cpp:330] Iteration 70000, Testing net (#0)
I0927 01:36:20.516108  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:36:20.658304  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8736
I0927 01:36:20.658341  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.480522 (* 1 = 0.480522 loss)
I0927 01:36:20.803768  2459 solver.cpp:218] Iteration 70000 (5.50896 iter/s, 18.1522s/100 iters), loss = 0.036901
I0927 01:36:20.803793  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369007 (* 1 = 0.0369007 loss)
I0927 01:36:20.803799  2459 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0927 01:36:35.375658  2459 solver.cpp:218] Iteration 70100 (6.86255 iter/s, 14.5718s/100 iters), loss = 0.0404552
I0927 01:36:35.375699  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404549 (* 1 = 0.0404549 loss)
I0927 01:36:35.375705  2459 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0927 01:36:49.953317  2459 solver.cpp:218] Iteration 70200 (6.85984 iter/s, 14.5776s/100 iters), loss = 0.0622932
I0927 01:36:49.953474  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0622929 (* 1 = 0.0622929 loss)
I0927 01:36:49.953485  2459 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0927 01:37:04.530808  2459 solver.cpp:218] Iteration 70300 (6.85997 iter/s, 14.5773s/100 iters), loss = 0.117996
I0927 01:37:04.530850  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117996 (* 1 = 0.117996 loss)
I0927 01:37:04.530855  2459 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0927 01:37:19.106065  2459 solver.cpp:218] Iteration 70400 (6.86097 iter/s, 14.5752s/100 iters), loss = 0.0323284
I0927 01:37:19.106096  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323281 (* 1 = 0.0323281 loss)
I0927 01:37:19.106101  2459 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0927 01:37:32.959035  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:37:33.542795  2459 solver.cpp:330] Iteration 70500, Testing net (#0)
I0927 01:37:36.960899  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:37:37.103493  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8887
I0927 01:37:37.103518  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.4084 (* 1 = 0.4084 loss)
I0927 01:37:37.249012  2459 solver.cpp:218] Iteration 70500 (5.5118 iter/s, 18.1429s/100 iters), loss = 0.0577533
I0927 01:37:37.249038  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057753 (* 1 = 0.057753 loss)
I0927 01:37:37.249044  2459 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0927 01:37:51.819787  2459 solver.cpp:218] Iteration 70600 (6.86308 iter/s, 14.5707s/100 iters), loss = 0.0619004
I0927 01:37:51.819828  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0619001 (* 1 = 0.0619001 loss)
I0927 01:37:51.819833  2459 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0927 01:38:06.396129  2459 solver.cpp:218] Iteration 70700 (6.86046 iter/s, 14.5763s/100 iters), loss = 0.0588995
I0927 01:38:06.396209  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0588992 (* 1 = 0.0588992 loss)
I0927 01:38:06.396216  2459 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0927 01:38:20.965775  2459 solver.cpp:218] Iteration 70800 (6.86363 iter/s, 14.5695s/100 iters), loss = 0.0631182
I0927 01:38:20.965816  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0631179 (* 1 = 0.0631179 loss)
I0927 01:38:20.965821  2459 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0927 01:38:35.542531  2459 solver.cpp:218] Iteration 70900 (6.86027 iter/s, 14.5767s/100 iters), loss = 0.0189795
I0927 01:38:35.542572  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189792 (* 1 = 0.0189792 loss)
I0927 01:38:35.542577  2459 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0927 01:38:49.389241  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:38:49.972513  2459 solver.cpp:330] Iteration 71000, Testing net (#0)
I0927 01:38:53.390377  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:38:53.533171  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8854
I0927 01:38:53.533207  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411875 (* 1 = 0.411875 loss)
I0927 01:38:53.678210  2459 solver.cpp:218] Iteration 71000 (5.51401 iter/s, 18.1356s/100 iters), loss = 0.0134857
I0927 01:38:53.678236  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134853 (* 1 = 0.0134853 loss)
I0927 01:38:53.678241  2459 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0927 01:39:08.251009  2459 solver.cpp:218] Iteration 71100 (6.86212 iter/s, 14.5728s/100 iters), loss = 0.0477698
I0927 01:39:08.251050  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477695 (* 1 = 0.0477695 loss)
I0927 01:39:08.251056  2459 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0927 01:39:22.831252  2459 solver.cpp:218] Iteration 71200 (6.85863 iter/s, 14.5802s/100 iters), loss = 0.125317
I0927 01:39:22.831375  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125316 (* 1 = 0.125316 loss)
I0927 01:39:22.831383  2459 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0927 01:39:37.408599  2459 solver.cpp:218] Iteration 71300 (6.86003 iter/s, 14.5772s/100 iters), loss = 0.0411068
I0927 01:39:37.408640  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411064 (* 1 = 0.0411064 loss)
I0927 01:39:37.408646  2459 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0927 01:39:51.986480  2459 solver.cpp:218] Iteration 71400 (6.85974 iter/s, 14.5778s/100 iters), loss = 0.0319724
I0927 01:39:51.986510  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319721 (* 1 = 0.0319721 loss)
I0927 01:39:51.986526  2459 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0927 01:40:05.837599  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:40:06.420956  2459 solver.cpp:330] Iteration 71500, Testing net (#0)
I0927 01:40:09.838973  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:40:09.981794  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8713
I0927 01:40:09.981830  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.474035 (* 1 = 0.474035 loss)
I0927 01:40:10.126494  2459 solver.cpp:218] Iteration 71500 (5.51269 iter/s, 18.14s/100 iters), loss = 0.0209325
I0927 01:40:10.126521  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209322 (* 1 = 0.0209322 loss)
I0927 01:40:10.126528  2459 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0927 01:40:24.704023  2459 solver.cpp:218] Iteration 71600 (6.8599 iter/s, 14.5775s/100 iters), loss = 0.0542145
I0927 01:40:24.704056  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0542142 (* 1 = 0.0542142 loss)
I0927 01:40:24.704061  2459 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0927 01:40:39.280521  2459 solver.cpp:218] Iteration 71700 (6.86038 iter/s, 14.5764s/100 iters), loss = 0.0203729
I0927 01:40:39.280616  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203726 (* 1 = 0.0203726 loss)
I0927 01:40:39.280623  2459 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0927 01:40:53.862118  2459 solver.cpp:218] Iteration 71800 (6.85802 iter/s, 14.5815s/100 iters), loss = 0.0452759
I0927 01:40:53.862159  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452756 (* 1 = 0.0452756 loss)
I0927 01:40:53.862164  2459 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0927 01:41:08.443251  2459 solver.cpp:218] Iteration 71900 (6.85821 iter/s, 14.5811s/100 iters), loss = 0.0279449
I0927 01:41:08.443292  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279446 (* 1 = 0.0279446 loss)
I0927 01:41:08.443298  2459 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0927 01:41:22.303539  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:41:22.887212  2459 solver.cpp:330] Iteration 72000, Testing net (#0)
I0927 01:41:26.304066  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:41:26.446897  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.881
I0927 01:41:26.446933  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.449993 (* 1 = 0.449993 loss)
I0927 01:41:26.591470  2459 solver.cpp:218] Iteration 72000 (5.5102 iter/s, 18.1482s/100 iters), loss = 0.038693
I0927 01:41:26.591497  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386927 (* 1 = 0.0386927 loss)
I0927 01:41:26.591503  2459 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0927 01:41:41.179293  2459 solver.cpp:218] Iteration 72100 (6.85506 iter/s, 14.5878s/100 iters), loss = 0.0377005
I0927 01:41:41.179335  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377002 (* 1 = 0.0377002 loss)
I0927 01:41:41.179342  2459 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0927 01:41:55.768254  2459 solver.cpp:218] Iteration 72200 (6.85453 iter/s, 14.5889s/100 iters), loss = 0.0837759
I0927 01:41:55.768362  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0837756 (* 1 = 0.0837756 loss)
I0927 01:41:55.768369  2459 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0927 01:42:10.362607  2459 solver.cpp:218] Iteration 72300 (6.85202 iter/s, 14.5942s/100 iters), loss = 0.0530427
I0927 01:42:10.362638  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0530424 (* 1 = 0.0530424 loss)
I0927 01:42:10.362644  2459 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0927 01:42:24.951920  2459 solver.cpp:218] Iteration 72400 (6.85436 iter/s, 14.5893s/100 iters), loss = 0.0736185
I0927 01:42:24.951964  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0736182 (* 1 = 0.0736182 loss)
I0927 01:42:24.951979  2459 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0927 01:42:38.810837  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:42:39.395083  2459 solver.cpp:330] Iteration 72500, Testing net (#0)
I0927 01:42:42.812813  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:42:42.955353  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8672
I0927 01:42:42.955389  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.52313 (* 1 = 0.52313 loss)
I0927 01:42:43.100687  2459 solver.cpp:218] Iteration 72500 (5.51004 iter/s, 18.1487s/100 iters), loss = 0.0410975
I0927 01:42:43.100713  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410972 (* 1 = 0.0410972 loss)
I0927 01:42:43.100719  2459 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0927 01:42:57.675211  2459 solver.cpp:218] Iteration 72600 (6.86131 iter/s, 14.5745s/100 iters), loss = 0.0327286
I0927 01:42:57.675253  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327283 (* 1 = 0.0327283 loss)
I0927 01:42:57.675259  2459 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0927 01:43:12.261343  2459 solver.cpp:218] Iteration 72700 (6.85586 iter/s, 14.5861s/100 iters), loss = 0.0496012
I0927 01:43:12.261447  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496009 (* 1 = 0.0496009 loss)
I0927 01:43:12.261454  2459 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0927 01:43:26.836140  2459 solver.cpp:218] Iteration 72800 (6.86122 iter/s, 14.5747s/100 iters), loss = 0.039003
I0927 01:43:26.836170  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390028 (* 1 = 0.0390028 loss)
I0927 01:43:26.836176  2459 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0927 01:43:41.410210  2459 solver.cpp:218] Iteration 72900 (6.86153 iter/s, 14.574s/100 iters), loss = 0.0569736
I0927 01:43:41.410240  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0569734 (* 1 = 0.0569734 loss)
I0927 01:43:41.410246  2459 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0927 01:43:55.262393  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:43:55.845381  2459 solver.cpp:330] Iteration 73000, Testing net (#0)
I0927 01:43:59.262837  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:43:59.405594  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8781
I0927 01:43:59.405620  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.46039 (* 1 = 0.46039 loss)
I0927 01:43:59.550062  2459 solver.cpp:218] Iteration 73000 (5.51274 iter/s, 18.1398s/100 iters), loss = 0.0270614
I0927 01:43:59.550088  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270612 (* 1 = 0.0270612 loss)
I0927 01:43:59.550094  2459 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0927 01:44:14.122053  2459 solver.cpp:218] Iteration 73100 (6.8625 iter/s, 14.5719s/100 iters), loss = 0.0229498
I0927 01:44:14.122095  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229496 (* 1 = 0.0229496 loss)
I0927 01:44:14.122102  2459 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0927 01:44:28.695557  2459 solver.cpp:218] Iteration 73200 (6.8618 iter/s, 14.5734s/100 iters), loss = 0.0412019
I0927 01:44:28.695715  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412016 (* 1 = 0.0412016 loss)
I0927 01:44:28.695734  2459 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0927 01:44:43.262243  2459 solver.cpp:218] Iteration 73300 (6.86506 iter/s, 14.5665s/100 iters), loss = 0.105787
I0927 01:44:43.262274  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105786 (* 1 = 0.105786 loss)
I0927 01:44:43.262279  2459 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0927 01:44:57.837695  2459 solver.cpp:218] Iteration 73400 (6.86088 iter/s, 14.5754s/100 iters), loss = 0.021269
I0927 01:44:57.837738  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212688 (* 1 = 0.0212688 loss)
I0927 01:44:57.837743  2459 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0927 01:45:11.686265  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:45:12.269556  2459 solver.cpp:330] Iteration 73500, Testing net (#0)
I0927 01:45:15.687953  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:45:15.830216  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8824
I0927 01:45:15.830255  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.414233 (* 1 = 0.414233 loss)
I0927 01:45:15.974961  2459 solver.cpp:218] Iteration 73500 (5.51353 iter/s, 18.1372s/100 iters), loss = 0.0556202
I0927 01:45:15.974989  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556199 (* 1 = 0.0556199 loss)
I0927 01:45:15.974997  2459 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0927 01:45:30.545833  2459 solver.cpp:218] Iteration 73600 (6.86303 iter/s, 14.5708s/100 iters), loss = 0.0213839
I0927 01:45:30.545874  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213837 (* 1 = 0.0213837 loss)
I0927 01:45:30.545881  2459 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0927 01:45:45.124939  2459 solver.cpp:218] Iteration 73700 (6.85916 iter/s, 14.579s/100 iters), loss = 0.0650029
I0927 01:45:45.125042  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650027 (* 1 = 0.0650027 loss)
I0927 01:45:45.125049  2459 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0927 01:45:59.702867  2459 solver.cpp:218] Iteration 73800 (6.85974 iter/s, 14.5778s/100 iters), loss = 0.0660883
I0927 01:45:59.702908  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660881 (* 1 = 0.0660881 loss)
I0927 01:45:59.702913  2459 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0927 01:46:14.284518  2459 solver.cpp:218] Iteration 73900 (6.85796 iter/s, 14.5816s/100 iters), loss = 0.0425087
I0927 01:46:14.284559  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425085 (* 1 = 0.0425085 loss)
I0927 01:46:14.284564  2459 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0927 01:46:28.140803  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:46:28.724232  2459 solver.cpp:330] Iteration 74000, Testing net (#0)
I0927 01:46:32.141646  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:46:32.284315  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8803
I0927 01:46:32.284351  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.445778 (* 1 = 0.445778 loss)
I0927 01:46:32.429092  2459 solver.cpp:218] Iteration 74000 (5.51131 iter/s, 18.1445s/100 iters), loss = 0.0559993
I0927 01:46:32.429121  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559991 (* 1 = 0.0559991 loss)
I0927 01:46:32.429127  2459 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0927 01:46:47.003901  2459 solver.cpp:218] Iteration 74100 (6.86118 iter/s, 14.5748s/100 iters), loss = 0.0690168
I0927 01:46:47.003931  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0690165 (* 1 = 0.0690165 loss)
I0927 01:46:47.003937  2459 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0927 01:47:01.579818  2459 solver.cpp:218] Iteration 74200 (6.86066 iter/s, 14.5759s/100 iters), loss = 0.0368909
I0927 01:47:01.579893  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368907 (* 1 = 0.0368907 loss)
I0927 01:47:01.579910  2459 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0927 01:47:16.160578  2459 solver.cpp:218] Iteration 74300 (6.8584 iter/s, 14.5807s/100 iters), loss = 0.074047
I0927 01:47:16.160609  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0740468 (* 1 = 0.0740468 loss)
I0927 01:47:16.160614  2459 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0927 01:47:30.741818  2459 solver.cpp:218] Iteration 74400 (6.85815 iter/s, 14.5812s/100 iters), loss = 0.0826238
I0927 01:47:30.741849  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0826236 (* 1 = 0.0826236 loss)
I0927 01:47:30.741855  2459 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0927 01:47:44.596009  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:47:45.179132  2459 solver.cpp:330] Iteration 74500, Testing net (#0)
I0927 01:47:48.597600  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:47:48.739965  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8725
I0927 01:47:48.739991  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500686 (* 1 = 0.500686 loss)
I0927 01:47:48.884833  2459 solver.cpp:218] Iteration 74500 (5.51178 iter/s, 18.143s/100 iters), loss = 0.0359369
I0927 01:47:48.884860  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359367 (* 1 = 0.0359367 loss)
I0927 01:47:48.884866  2459 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0927 01:48:03.464923  2459 solver.cpp:218] Iteration 74600 (6.85869 iter/s, 14.58s/100 iters), loss = 0.0712277
I0927 01:48:03.464964  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712275 (* 1 = 0.0712275 loss)
I0927 01:48:03.464970  2459 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0927 01:48:18.048445  2459 solver.cpp:218] Iteration 74700 (6.85708 iter/s, 14.5835s/100 iters), loss = 0.0403124
I0927 01:48:18.048586  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403122 (* 1 = 0.0403122 loss)
I0927 01:48:18.048594  2459 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0927 01:48:32.626636  2459 solver.cpp:218] Iteration 74800 (6.85964 iter/s, 14.578s/100 iters), loss = 0.012764
I0927 01:48:32.626677  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127638 (* 1 = 0.0127638 loss)
I0927 01:48:32.626683  2459 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0927 01:48:47.211572  2459 solver.cpp:218] Iteration 74900 (6.85642 iter/s, 14.5849s/100 iters), loss = 0.0362303
I0927 01:48:47.211613  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362301 (* 1 = 0.0362301 loss)
I0927 01:48:47.211619  2459 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0927 01:49:01.065063  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:49:01.649617  2459 solver.cpp:330] Iteration 75000, Testing net (#0)
I0927 01:49:05.066329  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:49:05.209065  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8719
I0927 01:49:05.209101  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.526803 (* 1 = 0.526803 loss)
I0927 01:49:05.354338  2459 solver.cpp:218] Iteration 75000 (5.51186 iter/s, 18.1427s/100 iters), loss = 0.0238253
I0927 01:49:05.354367  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238251 (* 1 = 0.0238251 loss)
I0927 01:49:05.354373  2459 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0927 01:49:19.924165  2459 solver.cpp:218] Iteration 75100 (6.86352 iter/s, 14.5698s/100 iters), loss = 0.0397056
I0927 01:49:19.924194  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397054 (* 1 = 0.0397054 loss)
I0927 01:49:19.924201  2459 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0927 01:49:34.494576  2459 solver.cpp:218] Iteration 75200 (6.86325 iter/s, 14.5704s/100 iters), loss = 0.0585288
I0927 01:49:34.494709  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0585286 (* 1 = 0.0585286 loss)
I0927 01:49:34.494715  2459 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0927 01:49:49.065748  2459 solver.cpp:218] Iteration 75300 (6.86293 iter/s, 14.571s/100 iters), loss = 0.0486683
I0927 01:49:49.065788  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486681 (* 1 = 0.0486681 loss)
I0927 01:49:49.065794  2459 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0927 01:50:03.639034  2459 solver.cpp:218] Iteration 75400 (6.8619 iter/s, 14.5732s/100 iters), loss = 0.0215321
I0927 01:50:03.639075  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215319 (* 1 = 0.0215319 loss)
I0927 01:50:03.639081  2459 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0927 01:50:17.493011  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:50:18.076665  2459 solver.cpp:330] Iteration 75500, Testing net (#0)
I0927 01:50:21.494729  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:50:21.637701  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8762
I0927 01:50:21.637727  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477375 (* 1 = 0.477375 loss)
I0927 01:50:21.782649  2459 solver.cpp:218] Iteration 75500 (5.5116 iter/s, 18.1435s/100 iters), loss = 0.0959053
I0927 01:50:21.782676  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.095905 (* 1 = 0.095905 loss)
I0927 01:50:21.782683  2459 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0927 01:50:36.348930  2459 solver.cpp:218] Iteration 75600 (6.86519 iter/s, 14.5662s/100 iters), loss = 0.0262231
I0927 01:50:36.348970  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262229 (* 1 = 0.0262229 loss)
I0927 01:50:36.348976  2459 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0927 01:50:50.920272  2459 solver.cpp:218] Iteration 75700 (6.86282 iter/s, 14.5713s/100 iters), loss = 0.0387005
I0927 01:50:50.920384  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387002 (* 1 = 0.0387002 loss)
I0927 01:50:50.920392  2459 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0927 01:51:05.497941  2459 solver.cpp:218] Iteration 75800 (6.85987 iter/s, 14.5775s/100 iters), loss = 0.032471
I0927 01:51:05.497982  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324708 (* 1 = 0.0324708 loss)
I0927 01:51:05.497987  2459 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0927 01:51:20.065857  2459 solver.cpp:218] Iteration 75900 (6.86443 iter/s, 14.5679s/100 iters), loss = 0.0312929
I0927 01:51:20.065886  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312927 (* 1 = 0.0312927 loss)
I0927 01:51:20.065892  2459 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0927 01:51:33.914526  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:51:34.497287  2459 solver.cpp:330] Iteration 76000, Testing net (#0)
I0927 01:51:37.915446  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:51:38.058202  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8737
I0927 01:51:38.058238  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.502628 (* 1 = 0.502628 loss)
I0927 01:51:38.203647  2459 solver.cpp:218] Iteration 76000 (5.51337 iter/s, 18.1377s/100 iters), loss = 0.0247938
I0927 01:51:38.203673  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247936 (* 1 = 0.0247936 loss)
I0927 01:51:38.203680  2459 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0927 01:51:52.770843  2459 solver.cpp:218] Iteration 76100 (6.86476 iter/s, 14.5671s/100 iters), loss = 0.027401
I0927 01:51:52.770884  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274008 (* 1 = 0.0274008 loss)
I0927 01:51:52.770889  2459 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0927 01:52:07.339447  2459 solver.cpp:218] Iteration 76200 (6.86411 iter/s, 14.5685s/100 iters), loss = 0.0181476
I0927 01:52:07.339545  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181474 (* 1 = 0.0181474 loss)
I0927 01:52:07.339552  2459 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0927 01:52:21.907891  2459 solver.cpp:218] Iteration 76300 (6.86421 iter/s, 14.5683s/100 iters), loss = 0.0640059
I0927 01:52:21.907932  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640057 (* 1 = 0.0640057 loss)
I0927 01:52:21.907938  2459 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0927 01:52:36.475150  2459 solver.cpp:218] Iteration 76400 (6.86474 iter/s, 14.5672s/100 iters), loss = 0.0332373
I0927 01:52:36.475180  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332371 (* 1 = 0.0332371 loss)
I0927 01:52:36.475186  2459 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0927 01:52:50.318410  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:52:50.901248  2459 solver.cpp:330] Iteration 76500, Testing net (#0)
I0927 01:52:54.319104  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:52:54.461966  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8824
I0927 01:52:54.462002  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.433185 (* 1 = 0.433185 loss)
I0927 01:52:54.606621  2459 solver.cpp:218] Iteration 76500 (5.51529 iter/s, 18.1314s/100 iters), loss = 0.0871727
I0927 01:52:54.606648  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0871725 (* 1 = 0.0871725 loss)
I0927 01:52:54.606654  2459 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0927 01:53:09.182230  2459 solver.cpp:218] Iteration 76600 (6.8608 iter/s, 14.5756s/100 iters), loss = 0.153554
I0927 01:53:09.182271  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153554 (* 1 = 0.153554 loss)
I0927 01:53:09.182277  2459 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0927 01:53:23.749192  2459 solver.cpp:218] Iteration 76700 (6.86488 iter/s, 14.5669s/100 iters), loss = 0.040938
I0927 01:53:23.749266  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409378 (* 1 = 0.0409378 loss)
I0927 01:53:23.749274  2459 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0927 01:53:38.323233  2459 solver.cpp:218] Iteration 76800 (6.86156 iter/s, 14.5739s/100 iters), loss = 0.104388
I0927 01:53:38.323274  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104387 (* 1 = 0.104387 loss)
I0927 01:53:38.323281  2459 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0927 01:53:52.901284  2459 solver.cpp:218] Iteration 76900 (6.85966 iter/s, 14.578s/100 iters), loss = 0.0752345
I0927 01:53:52.901326  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752343 (* 1 = 0.0752343 loss)
I0927 01:53:52.901332  2459 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0927 01:54:06.756969  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:54:07.340278  2459 solver.cpp:330] Iteration 77000, Testing net (#0)
I0927 01:54:10.759366  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:54:10.901545  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8561
I0927 01:54:10.901581  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.562077 (* 1 = 0.562077 loss)
I0927 01:54:11.046583  2459 solver.cpp:218] Iteration 77000 (5.51109 iter/s, 18.1452s/100 iters), loss = 0.0483313
I0927 01:54:11.046612  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048331 (* 1 = 0.048331 loss)
I0927 01:54:11.046617  2459 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0927 01:54:25.632752  2459 solver.cpp:218] Iteration 77100 (6.85583 iter/s, 14.5861s/100 iters), loss = 0.0143883
I0927 01:54:25.632793  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143881 (* 1 = 0.0143881 loss)
I0927 01:54:25.632799  2459 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0927 01:54:40.220855  2459 solver.cpp:218] Iteration 77200 (6.85493 iter/s, 14.588s/100 iters), loss = 0.0788388
I0927 01:54:40.221005  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0788385 (* 1 = 0.0788385 loss)
I0927 01:54:40.221024  2459 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0927 01:54:54.800912  2459 solver.cpp:218] Iteration 77300 (6.85876 iter/s, 14.5799s/100 iters), loss = 0.0826837
I0927 01:54:54.800954  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0826835 (* 1 = 0.0826835 loss)
I0927 01:54:54.800961  2459 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0927 01:55:09.387215  2459 solver.cpp:218] Iteration 77400 (6.85578 iter/s, 14.5862s/100 iters), loss = 0.0226325
I0927 01:55:09.387256  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226323 (* 1 = 0.0226323 loss)
I0927 01:55:09.387262  2459 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0927 01:55:23.250486  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:55:23.834520  2459 solver.cpp:330] Iteration 77500, Testing net (#0)
I0927 01:55:27.251437  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:55:27.393880  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.865
I0927 01:55:27.393915  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.531138 (* 1 = 0.531138 loss)
I0927 01:55:27.539252  2459 solver.cpp:218] Iteration 77500 (5.50904 iter/s, 18.152s/100 iters), loss = 0.0178367
I0927 01:55:27.539280  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178365 (* 1 = 0.0178365 loss)
I0927 01:55:27.539288  2459 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0927 01:55:42.116309  2459 solver.cpp:218] Iteration 77600 (6.86012 iter/s, 14.577s/100 iters), loss = 0.10152
I0927 01:55:42.116350  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10152 (* 1 = 0.10152 loss)
I0927 01:55:42.116358  2459 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0927 01:55:56.691892  2459 solver.cpp:218] Iteration 77700 (6.86082 iter/s, 14.5755s/100 iters), loss = 0.0797483
I0927 01:55:56.692026  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0797481 (* 1 = 0.0797481 loss)
I0927 01:55:56.692034  2459 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0927 01:56:11.273406  2459 solver.cpp:218] Iteration 77800 (6.85807 iter/s, 14.5814s/100 iters), loss = 0.0374865
I0927 01:56:11.273447  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374862 (* 1 = 0.0374862 loss)
I0927 01:56:11.273452  2459 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0927 01:56:25.852922  2459 solver.cpp:218] Iteration 77900 (6.85897 iter/s, 14.5795s/100 iters), loss = 0.0976102
I0927 01:56:25.852964  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.09761 (* 1 = 0.09761 loss)
I0927 01:56:25.852970  2459 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0927 01:56:39.709312  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:56:40.292317  2459 solver.cpp:330] Iteration 78000, Testing net (#0)
I0927 01:56:43.710134  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:56:43.852953  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8703
I0927 01:56:43.852989  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.489829 (* 1 = 0.489829 loss)
I0927 01:56:43.997606  2459 solver.cpp:218] Iteration 78000 (5.51128 iter/s, 18.1446s/100 iters), loss = 0.0242812
I0927 01:56:43.997637  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024281 (* 1 = 0.024281 loss)
I0927 01:56:43.997643  2459 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0927 01:56:58.570066  2459 solver.cpp:218] Iteration 78100 (6.86229 iter/s, 14.5724s/100 iters), loss = 0.0440966
I0927 01:56:58.570109  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440964 (* 1 = 0.0440964 loss)
I0927 01:56:58.570116  2459 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0927 01:57:13.149188  2459 solver.cpp:218] Iteration 78200 (6.85915 iter/s, 14.5791s/100 iters), loss = 0.0816599
I0927 01:57:13.149343  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816597 (* 1 = 0.0816597 loss)
I0927 01:57:13.149360  2459 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0927 01:57:27.726305  2459 solver.cpp:218] Iteration 78300 (6.86015 iter/s, 14.577s/100 iters), loss = 0.046342
I0927 01:57:27.726348  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463418 (* 1 = 0.0463418 loss)
I0927 01:57:27.726354  2459 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0927 01:57:42.294952  2459 solver.cpp:218] Iteration 78400 (6.86409 iter/s, 14.5686s/100 iters), loss = 0.0615005
I0927 01:57:42.294993  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615003 (* 1 = 0.0615003 loss)
I0927 01:57:42.294999  2459 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0927 01:57:56.143980  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:57:56.726627  2459 solver.cpp:330] Iteration 78500, Testing net (#0)
I0927 01:58:00.146185  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:58:00.289191  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8831
I0927 01:58:00.289224  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.435084 (* 1 = 0.435084 loss)
I0927 01:58:00.433995  2459 solver.cpp:218] Iteration 78500 (5.51299 iter/s, 18.139s/100 iters), loss = 0.0322546
I0927 01:58:00.434025  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322544 (* 1 = 0.0322544 loss)
I0927 01:58:00.434031  2459 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0927 01:58:15.006881  2459 solver.cpp:218] Iteration 78600 (6.86208 iter/s, 14.5728s/100 iters), loss = 0.0656371
I0927 01:58:15.006918  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0656368 (* 1 = 0.0656368 loss)
I0927 01:58:15.006925  2459 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0927 01:58:29.583379  2459 solver.cpp:218] Iteration 78700 (6.86039 iter/s, 14.5764s/100 iters), loss = 0.0429051
I0927 01:58:29.583494  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429049 (* 1 = 0.0429049 loss)
I0927 01:58:29.583500  2459 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0927 01:58:44.164746  2459 solver.cpp:218] Iteration 78800 (6.85813 iter/s, 14.5812s/100 iters), loss = 0.067927
I0927 01:58:44.164778  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0679268 (* 1 = 0.0679268 loss)
I0927 01:58:44.164794  2459 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0927 01:58:58.744494  2459 solver.cpp:218] Iteration 78900 (6.85886 iter/s, 14.5797s/100 iters), loss = 0.0459183
I0927 01:58:58.744525  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045918 (* 1 = 0.045918 loss)
I0927 01:58:58.744541  2459 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0927 01:59:12.606902  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:59:13.189880  2459 solver.cpp:330] Iteration 79000, Testing net (#0)
I0927 01:59:16.609521  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:59:16.752132  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8722
I0927 01:59:16.752168  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.504853 (* 1 = 0.504853 loss)
I0927 01:59:16.897334  2459 solver.cpp:218] Iteration 79000 (5.5088 iter/s, 18.1528s/100 iters), loss = 0.0399169
I0927 01:59:16.897361  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399166 (* 1 = 0.0399166 loss)
I0927 01:59:16.897368  2459 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0927 01:59:31.466142  2459 solver.cpp:218] Iteration 79100 (6.864 iter/s, 14.5688s/100 iters), loss = 0.0445122
I0927 01:59:31.466183  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445119 (* 1 = 0.0445119 loss)
I0927 01:59:31.466189  2459 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0927 01:59:46.046398  2459 solver.cpp:218] Iteration 79200 (6.85862 iter/s, 14.5802s/100 iters), loss = 0.0318645
I0927 01:59:46.046531  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318643 (* 1 = 0.0318643 loss)
I0927 01:59:46.046540  2459 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0927 02:00:00.631686  2459 solver.cpp:218] Iteration 79300 (6.85629 iter/s, 14.5851s/100 iters), loss = 0.0861057
I0927 02:00:00.631726  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0861054 (* 1 = 0.0861054 loss)
I0927 02:00:00.631731  2459 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0927 02:00:15.215945  2459 solver.cpp:218] Iteration 79400 (6.85674 iter/s, 14.5842s/100 iters), loss = 0.0579154
I0927 02:00:15.215977  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579151 (* 1 = 0.0579151 loss)
I0927 02:00:15.215993  2459 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0927 02:00:29.075727  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:00:29.660233  2459 solver.cpp:330] Iteration 79500, Testing net (#0)
I0927 02:00:33.077966  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:00:33.220463  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8733
I0927 02:00:33.220499  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.498147 (* 1 = 0.498147 loss)
I0927 02:00:33.365592  2459 solver.cpp:218] Iteration 79500 (5.50977 iter/s, 18.1496s/100 iters), loss = 0.033695
I0927 02:00:33.365620  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336948 (* 1 = 0.0336948 loss)
I0927 02:00:33.365628  2459 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0927 02:00:47.939739  2459 solver.cpp:218] Iteration 79600 (6.86149 iter/s, 14.5741s/100 iters), loss = 0.0914009
I0927 02:00:47.939770  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914007 (* 1 = 0.0914007 loss)
I0927 02:00:47.939776  2459 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0927 02:01:02.522995  2459 solver.cpp:218] Iteration 79700 (6.8572 iter/s, 14.5832s/100 iters), loss = 0.0220155
I0927 02:01:02.523052  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220153 (* 1 = 0.0220153 loss)
I0927 02:01:02.523059  2459 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0927 02:01:17.104876  2459 solver.cpp:218] Iteration 79800 (6.85786 iter/s, 14.5818s/100 iters), loss = 0.0696051
I0927 02:01:17.104918  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0696049 (* 1 = 0.0696049 loss)
I0927 02:01:17.104923  2459 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0927 02:01:31.683501  2459 solver.cpp:218] Iteration 79900 (6.85939 iter/s, 14.5786s/100 iters), loss = 0.0365205
I0927 02:01:31.683542  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365203 (* 1 = 0.0365203 loss)
I0927 02:01:31.683548  2459 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0927 02:01:45.535580  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:01:46.118293  2459 solver.cpp:330] Iteration 80000, Testing net (#0)
I0927 02:01:49.535246  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:01:49.678005  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8795
I0927 02:01:49.678043  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.417887 (* 1 = 0.417887 loss)
I0927 02:01:49.822481  2459 solver.cpp:218] Iteration 80000 (5.51301 iter/s, 18.1389s/100 iters), loss = 0.0339149
I0927 02:01:49.822509  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339146 (* 1 = 0.0339146 loss)
I0927 02:01:49.822515  2459 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0927 02:01:49.822517  2459 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0927 02:02:04.392877  2459 solver.cpp:218] Iteration 80100 (6.86326 iter/s, 14.5703s/100 iters), loss = 0.0244664
I0927 02:02:04.392909  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244662 (* 1 = 0.0244662 loss)
I0927 02:02:04.392915  2459 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0927 02:02:18.963603  2459 solver.cpp:218] Iteration 80200 (6.8631 iter/s, 14.5707s/100 iters), loss = 0.0242448
I0927 02:02:18.963701  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242446 (* 1 = 0.0242446 loss)
I0927 02:02:18.963709  2459 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0927 02:02:33.541834  2459 solver.cpp:218] Iteration 80300 (6.8596 iter/s, 14.5781s/100 iters), loss = 0.0210633
I0927 02:02:33.541865  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210631 (* 1 = 0.0210631 loss)
I0927 02:02:33.541872  2459 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0927 02:02:48.115105  2459 solver.cpp:218] Iteration 80400 (6.8619 iter/s, 14.5732s/100 iters), loss = 0.0109721
I0927 02:02:48.115146  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109719 (* 1 = 0.0109719 loss)
I0927 02:02:48.115152  2459 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0927 02:03:01.964526  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:03:02.547560  2459 solver.cpp:330] Iteration 80500, Testing net (#0)
I0927 02:03:05.966339  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:03:06.108539  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8962
I0927 02:03:06.108575  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370214 (* 1 = 0.370214 loss)
I0927 02:03:06.253192  2459 solver.cpp:218] Iteration 80500 (5.51328 iter/s, 18.138s/100 iters), loss = 0.0538773
I0927 02:03:06.253218  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538771 (* 1 = 0.0538771 loss)
I0927 02:03:06.253226  2459 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0927 02:03:20.824589  2459 solver.cpp:218] Iteration 80600 (6.86278 iter/s, 14.5713s/100 iters), loss = 0.0156478
I0927 02:03:20.824617  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156475 (* 1 = 0.0156475 loss)
I0927 02:03:20.824623  2459 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0927 02:03:35.405936  2459 solver.cpp:218] Iteration 80700 (6.8581 iter/s, 14.5813s/100 iters), loss = 0.0156931
I0927 02:03:35.406040  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156929 (* 1 = 0.0156929 loss)
I0927 02:03:35.406047  2459 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0927 02:03:49.982247  2459 solver.cpp:218] Iteration 80800 (6.86051 iter/s, 14.5762s/100 iters), loss = 0.0675547
I0927 02:03:49.982288  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0675545 (* 1 = 0.0675545 loss)
I0927 02:03:49.982295  2459 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0927 02:04:04.562938  2459 solver.cpp:218] Iteration 80900 (6.85842 iter/s, 14.5806s/100 iters), loss = 0.026152
I0927 02:04:04.562969  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261518 (* 1 = 0.0261518 loss)
I0927 02:04:04.562975  2459 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0927 02:04:18.413754  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:04:18.997473  2459 solver.cpp:330] Iteration 81000, Testing net (#0)
I0927 02:04:22.415908  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:04:22.558732  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8993
I0927 02:04:22.558768  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36762 (* 1 = 0.36762 loss)
I0927 02:04:22.703455  2459 solver.cpp:218] Iteration 81000 (5.51254 iter/s, 18.1405s/100 iters), loss = 0.026755
I0927 02:04:22.703483  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267548 (* 1 = 0.0267548 loss)
I0927 02:04:22.703490  2459 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0927 02:04:37.282735  2459 solver.cpp:218] Iteration 81100 (6.85907 iter/s, 14.5792s/100 iters), loss = 0.0255938
I0927 02:04:37.282775  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255936 (* 1 = 0.0255936 loss)
I0927 02:04:37.282781  2459 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0927 02:04:51.856211  2459 solver.cpp:218] Iteration 81200 (6.86181 iter/s, 14.5734s/100 iters), loss = 0.0496641
I0927 02:04:51.856333  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496638 (* 1 = 0.0496638 loss)
I0927 02:04:51.856341  2459 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0927 02:05:06.444785  2459 solver.cpp:218] Iteration 81300 (6.85475 iter/s, 14.5884s/100 iters), loss = 0.0386491
I0927 02:05:06.444818  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386488 (* 1 = 0.0386488 loss)
I0927 02:05:06.444823  2459 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0927 02:05:21.030899  2459 solver.cpp:218] Iteration 81400 (6.85586 iter/s, 14.5861s/100 iters), loss = 0.0115848
I0927 02:05:21.030930  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115846 (* 1 = 0.0115846 loss)
I0927 02:05:21.030936  2459 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0927 02:05:34.892784  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:05:35.477372  2459 solver.cpp:330] Iteration 81500, Testing net (#0)
I0927 02:05:38.897258  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:05:39.040035  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I0927 02:05:39.040071  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37111 (* 1 = 0.37111 loss)
I0927 02:05:39.184582  2459 solver.cpp:218] Iteration 81500 (5.50854 iter/s, 18.1536s/100 iters), loss = 0.0440186
I0927 02:05:39.184609  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440184 (* 1 = 0.0440184 loss)
I0927 02:05:39.184617  2459 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0927 02:05:53.755523  2459 solver.cpp:218] Iteration 81600 (6.863 iter/s, 14.5709s/100 iters), loss = 0.0156092
I0927 02:05:53.755553  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015609 (* 1 = 0.015609 loss)
I0927 02:05:53.755559  2459 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0927 02:06:08.330538  2459 solver.cpp:218] Iteration 81700 (6.86108 iter/s, 14.575s/100 iters), loss = 0.0514988
I0927 02:06:08.330667  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514986 (* 1 = 0.0514986 loss)
I0927 02:06:08.330684  2459 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0927 02:06:22.903457  2459 solver.cpp:218] Iteration 81800 (6.86211 iter/s, 14.5728s/100 iters), loss = 0.0120993
I0927 02:06:22.903488  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120991 (* 1 = 0.0120991 loss)
I0927 02:06:22.903503  2459 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0927 02:06:37.477780  2459 solver.cpp:218] Iteration 81900 (6.86141 iter/s, 14.5743s/100 iters), loss = 0.0148447
I0927 02:06:37.477809  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148445 (* 1 = 0.0148445 loss)
I0927 02:06:37.477825  2459 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0927 02:06:51.323483  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:06:51.906708  2459 solver.cpp:330] Iteration 82000, Testing net (#0)
I0927 02:06:55.326783  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:06:55.468819  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9014
I0927 02:06:55.468857  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370621 (* 1 = 0.370621 loss)
I0927 02:06:55.613720  2459 solver.cpp:218] Iteration 82000 (5.51393 iter/s, 18.1359s/100 iters), loss = 0.0312351
I0927 02:06:55.613749  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312349 (* 1 = 0.0312349 loss)
I0927 02:06:55.613755  2459 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0927 02:07:10.187857  2459 solver.cpp:218] Iteration 82100 (6.86149 iter/s, 14.5741s/100 iters), loss = 0.0243971
I0927 02:07:10.187888  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243968 (* 1 = 0.0243968 loss)
I0927 02:07:10.187894  2459 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0927 02:07:24.772596  2459 solver.cpp:218] Iteration 82200 (6.85651 iter/s, 14.5847s/100 iters), loss = 0.00908341
I0927 02:07:24.772706  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090832 (* 1 = 0.0090832 loss)
I0927 02:07:24.772713  2459 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0927 02:07:39.351766  2459 solver.cpp:218] Iteration 82300 (6.85916 iter/s, 14.579s/100 iters), loss = 0.00932388
I0927 02:07:39.351799  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00932368 (* 1 = 0.00932368 loss)
I0927 02:07:39.351805  2459 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0927 02:07:53.929113  2459 solver.cpp:218] Iteration 82400 (6.85998 iter/s, 14.5773s/100 iters), loss = 0.00331499
I0927 02:07:53.929144  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331479 (* 1 = 0.00331479 loss)
I0927 02:07:53.929160  2459 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0927 02:08:07.785935  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:08:08.368765  2459 solver.cpp:330] Iteration 82500, Testing net (#0)
I0927 02:08:11.785611  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:08:11.928669  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9013
I0927 02:08:11.928695  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369742 (* 1 = 0.369742 loss)
I0927 02:08:12.073709  2459 solver.cpp:218] Iteration 82500 (5.5113 iter/s, 18.1445s/100 iters), loss = 0.0193802
I0927 02:08:12.073734  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01938 (* 1 = 0.01938 loss)
I0927 02:08:12.073741  2459 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0927 02:08:26.657799  2459 solver.cpp:218] Iteration 82600 (6.85681 iter/s, 14.584s/100 iters), loss = 0.012451
I0927 02:08:26.657829  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124508 (* 1 = 0.0124508 loss)
I0927 02:08:26.657835  2459 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0927 02:08:41.241379  2459 solver.cpp:218] Iteration 82700 (6.85705 iter/s, 14.5835s/100 iters), loss = 0.0171301
I0927 02:08:41.241454  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171299 (* 1 = 0.0171299 loss)
I0927 02:08:41.241462  2459 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0927 02:08:55.829665  2459 solver.cpp:218] Iteration 82800 (6.85486 iter/s, 14.5882s/100 iters), loss = 0.0201511
I0927 02:08:55.829697  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201509 (* 1 = 0.0201509 loss)
I0927 02:08:55.829705  2459 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0927 02:09:10.421778  2459 solver.cpp:218] Iteration 82900 (6.85304 iter/s, 14.5921s/100 iters), loss = 0.0400059
I0927 02:09:10.421809  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400057 (* 1 = 0.0400057 loss)
I0927 02:09:10.421818  2459 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0927 02:09:24.284073  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:09:24.868449  2459 solver.cpp:330] Iteration 83000, Testing net (#0)
I0927 02:09:28.287586  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:09:28.430564  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I0927 02:09:28.430590  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3708 (* 1 = 0.3708 loss)
I0927 02:09:28.576231  2459 solver.cpp:218] Iteration 83000 (5.50831 iter/s, 18.1544s/100 iters), loss = 0.0141609
I0927 02:09:28.576257  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141607 (* 1 = 0.0141607 loss)
I0927 02:09:28.576264  2459 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0927 02:09:43.161070  2459 solver.cpp:218] Iteration 83100 (6.85646 iter/s, 14.5848s/100 iters), loss = 0.00728584
I0927 02:09:43.161110  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728566 (* 1 = 0.00728566 loss)
I0927 02:09:43.161116  2459 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0927 02:09:57.755785  2459 solver.cpp:218] Iteration 83200 (6.85182 iter/s, 14.5947s/100 iters), loss = 0.0250391
I0927 02:09:57.755895  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250389 (* 1 = 0.0250389 loss)
I0927 02:09:57.755903  2459 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0927 02:10:12.344859  2459 solver.cpp:218] Iteration 83300 (6.85451 iter/s, 14.5889s/100 iters), loss = 0.0126973
I0927 02:10:12.344902  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126971 (* 1 = 0.0126971 loss)
I0927 02:10:12.344907  2459 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0927 02:10:26.936655  2459 solver.cpp:218] Iteration 83400 (6.8532 iter/s, 14.5917s/100 iters), loss = 0.00961303
I0927 02:10:26.936697  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00961284 (* 1 = 0.00961284 loss)
I0927 02:10:26.936702  2459 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0927 02:10:40.800871  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:10:41.384907  2459 solver.cpp:330] Iteration 83500, Testing net (#0)
I0927 02:10:44.805181  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:10:44.947896  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I0927 02:10:44.947932  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371903 (* 1 = 0.371903 loss)
I0927 02:10:45.092684  2459 solver.cpp:218] Iteration 83500 (5.50783 iter/s, 18.156s/100 iters), loss = 0.0198132
I0927 02:10:45.092710  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019813 (* 1 = 0.019813 loss)
I0927 02:10:45.092717  2459 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0927 02:10:59.670181  2459 solver.cpp:218] Iteration 83600 (6.85991 iter/s, 14.5774s/100 iters), loss = 0.00832368
I0927 02:10:59.670213  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00832349 (* 1 = 0.00832349 loss)
I0927 02:10:59.670219  2459 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0927 02:11:14.251065  2459 solver.cpp:218] Iteration 83700 (6.85832 iter/s, 14.5808s/100 iters), loss = 0.0273106
I0927 02:11:14.251144  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273104 (* 1 = 0.0273104 loss)
I0927 02:11:14.251154  2459 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0927 02:11:28.828514  2459 solver.cpp:218] Iteration 83800 (6.85996 iter/s, 14.5773s/100 iters), loss = 0.0149694
I0927 02:11:28.828557  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149692 (* 1 = 0.0149692 loss)
I0927 02:11:28.828562  2459 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0927 02:11:43.405901  2459 solver.cpp:218] Iteration 83900 (6.85997 iter/s, 14.5773s/100 iters), loss = 0.00766672
I0927 02:11:43.405942  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00766652 (* 1 = 0.00766652 loss)
I0927 02:11:43.405948  2459 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0927 02:11:57.256119  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:11:57.840065  2459 solver.cpp:330] Iteration 84000, Testing net (#0)
I0927 02:12:01.259166  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:12:01.401895  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9022
I0927 02:12:01.401932  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374717 (* 1 = 0.374717 loss)
I0927 02:12:01.546970  2459 solver.cpp:218] Iteration 84000 (5.51237 iter/s, 18.141s/100 iters), loss = 0.0190502
I0927 02:12:01.546998  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01905 (* 1 = 0.01905 loss)
I0927 02:12:01.547004  2459 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0927 02:12:16.114452  2459 solver.cpp:218] Iteration 84100 (6.86463 iter/s, 14.5674s/100 iters), loss = 0.0116301
I0927 02:12:16.114495  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116299 (* 1 = 0.0116299 loss)
I0927 02:12:16.114500  2459 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0927 02:12:30.692322  2459 solver.cpp:218] Iteration 84200 (6.85974 iter/s, 14.5778s/100 iters), loss = 0.00252808
I0927 02:12:30.692442  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025279 (* 1 = 0.0025279 loss)
I0927 02:12:30.692461  2459 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0927 02:12:45.263581  2459 solver.cpp:218] Iteration 84300 (6.86289 iter/s, 14.5711s/100 iters), loss = 0.0158784
I0927 02:12:45.263622  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158782 (* 1 = 0.0158782 loss)
I0927 02:12:45.263628  2459 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0927 02:12:59.843273  2459 solver.cpp:218] Iteration 84400 (6.85889 iter/s, 14.5796s/100 iters), loss = 0.00745421
I0927 02:12:59.843315  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745403 (* 1 = 0.00745403 loss)
I0927 02:12:59.843322  2459 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0927 02:13:13.693192  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:13:14.276218  2459 solver.cpp:330] Iteration 84500, Testing net (#0)
I0927 02:13:17.696233  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:13:17.838933  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I0927 02:13:17.838969  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373026 (* 1 = 0.373026 loss)
I0927 02:13:17.983439  2459 solver.cpp:218] Iteration 84500 (5.51265 iter/s, 18.1401s/100 iters), loss = 0.0303149
I0927 02:13:17.983466  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303148 (* 1 = 0.0303148 loss)
I0927 02:13:17.983472  2459 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0927 02:13:32.553925  2459 solver.cpp:218] Iteration 84600 (6.86321 iter/s, 14.5704s/100 iters), loss = 0.00860991
I0927 02:13:32.553966  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00860974 (* 1 = 0.00860974 loss)
I0927 02:13:32.553972  2459 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0927 02:13:47.128212  2459 solver.cpp:218] Iteration 84700 (6.86143 iter/s, 14.5742s/100 iters), loss = 0.0209188
I0927 02:13:47.128316  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209186 (* 1 = 0.0209186 loss)
I0927 02:13:47.128324  2459 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0927 02:14:01.703372  2459 solver.cpp:218] Iteration 84800 (6.86104 iter/s, 14.575s/100 iters), loss = 0.03205
I0927 02:14:01.703402  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320498 (* 1 = 0.0320498 loss)
I0927 02:14:01.703408  2459 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0927 02:14:16.280575  2459 solver.cpp:218] Iteration 84900 (6.86005 iter/s, 14.5771s/100 iters), loss = 0.0217097
I0927 02:14:16.280616  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217095 (* 1 = 0.0217095 loss)
I0927 02:14:16.280622  2459 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0927 02:14:30.124402  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:14:30.709228  2459 solver.cpp:330] Iteration 85000, Testing net (#0)
I0927 02:14:34.128404  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:14:34.271118  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I0927 02:14:34.271144  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374308 (* 1 = 0.374308 loss)
I0927 02:14:34.416541  2459 solver.cpp:218] Iteration 85000 (5.51393 iter/s, 18.1359s/100 iters), loss = 0.0243638
I0927 02:14:34.416568  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243636 (* 1 = 0.0243636 loss)
I0927 02:14:34.416575  2459 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0927 02:14:48.998932  2459 solver.cpp:218] Iteration 85100 (6.85761 iter/s, 14.5823s/100 iters), loss = 0.00996732
I0927 02:14:48.998973  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00996715 (* 1 = 0.00996715 loss)
I0927 02:14:48.998980  2459 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0927 02:15:03.588502  2459 solver.cpp:218] Iteration 85200 (6.85424 iter/s, 14.5895s/100 iters), loss = 0.0440432
I0927 02:15:03.588613  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044043 (* 1 = 0.044043 loss)
I0927 02:15:03.588629  2459 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0927 02:15:18.172920  2459 solver.cpp:218] Iteration 85300 (6.85669 iter/s, 14.5843s/100 iters), loss = 0.0181898
I0927 02:15:18.172950  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181896 (* 1 = 0.0181896 loss)
I0927 02:15:18.172957  2459 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0927 02:15:32.754544  2459 solver.cpp:218] Iteration 85400 (6.85797 iter/s, 14.5816s/100 iters), loss = 0.0223104
I0927 02:15:32.754575  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223102 (* 1 = 0.0223102 loss)
I0927 02:15:32.754581  2459 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0927 02:15:46.615898  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:15:47.200146  2459 solver.cpp:330] Iteration 85500, Testing net (#0)
I0927 02:15:50.620543  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:15:50.763252  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I0927 02:15:50.763288  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373334 (* 1 = 0.373334 loss)
I0927 02:15:50.908339  2459 solver.cpp:218] Iteration 85500 (5.50851 iter/s, 18.1537s/100 iters), loss = 0.0256895
I0927 02:15:50.908367  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256894 (* 1 = 0.0256894 loss)
I0927 02:15:50.908373  2459 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0927 02:16:05.488963  2459 solver.cpp:218] Iteration 85600 (6.85844 iter/s, 14.5806s/100 iters), loss = 0.00591776
I0927 02:16:05.488993  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00591758 (* 1 = 0.00591758 loss)
I0927 02:16:05.489001  2459 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0927 02:16:20.073837  2459 solver.cpp:218] Iteration 85700 (6.85644 iter/s, 14.5848s/100 iters), loss = 0.0108455
I0927 02:16:20.073945  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108453 (* 1 = 0.0108453 loss)
I0927 02:16:20.073952  2459 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0927 02:16:34.658270  2459 solver.cpp:218] Iteration 85800 (6.85669 iter/s, 14.5843s/100 iters), loss = 0.00799396
I0927 02:16:34.658313  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00799377 (* 1 = 0.00799377 loss)
I0927 02:16:34.658318  2459 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0927 02:16:49.238461  2459 solver.cpp:218] Iteration 85900 (6.85865 iter/s, 14.5801s/100 iters), loss = 0.0165778
I0927 02:16:49.238502  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165776 (* 1 = 0.0165776 loss)
I0927 02:16:49.238507  2459 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0927 02:17:03.095952  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:17:03.680344  2459 solver.cpp:330] Iteration 86000, Testing net (#0)
I0927 02:17:07.101073  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:17:07.243649  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9017
I0927 02:17:07.243685  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377269 (* 1 = 0.377269 loss)
I0927 02:17:07.388192  2459 solver.cpp:218] Iteration 86000 (5.50974 iter/s, 18.1497s/100 iters), loss = 0.0348125
I0927 02:17:07.388221  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348123 (* 1 = 0.0348123 loss)
I0927 02:17:07.388227  2459 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0927 02:17:21.951580  2459 solver.cpp:218] Iteration 86100 (6.86656 iter/s, 14.5633s/100 iters), loss = 0.0113644
I0927 02:17:21.951622  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113642 (* 1 = 0.0113642 loss)
I0927 02:17:21.951627  2459 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0927 02:17:36.519670  2459 solver.cpp:218] Iteration 86200 (6.86435 iter/s, 14.568s/100 iters), loss = 0.00551597
I0927 02:17:36.519771  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551578 (* 1 = 0.00551578 loss)
I0927 02:17:36.519790  2459 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0927 02:17:51.079023  2459 solver.cpp:218] Iteration 86300 (6.86849 iter/s, 14.5592s/100 iters), loss = 0.0222531
I0927 02:17:51.079054  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222529 (* 1 = 0.0222529 loss)
I0927 02:17:51.079061  2459 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0927 02:18:05.649507  2459 solver.cpp:218] Iteration 86400 (6.86321 iter/s, 14.5704s/100 iters), loss = 0.00678694
I0927 02:18:05.649536  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678676 (* 1 = 0.00678676 loss)
I0927 02:18:05.649543  2459 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0927 02:18:19.490900  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:18:20.073987  2459 solver.cpp:330] Iteration 86500, Testing net (#0)
I0927 02:18:23.491791  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:18:23.634431  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I0927 02:18:23.634469  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373995 (* 1 = 0.373995 loss)
I0927 02:18:23.779820  2459 solver.cpp:218] Iteration 86500 (5.51564 iter/s, 18.1303s/100 iters), loss = 0.0199519
I0927 02:18:23.779846  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199517 (* 1 = 0.0199517 loss)
I0927 02:18:23.779853  2459 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0927 02:18:38.357893  2459 solver.cpp:218] Iteration 86600 (6.85964 iter/s, 14.578s/100 iters), loss = 0.0254803
I0927 02:18:38.357923  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254801 (* 1 = 0.0254801 loss)
I0927 02:18:38.357928  2459 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0927 02:18:52.938197  2459 solver.cpp:218] Iteration 86700 (6.85859 iter/s, 14.5803s/100 iters), loss = 0.0124719
I0927 02:18:52.938302  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124717 (* 1 = 0.0124717 loss)
I0927 02:18:52.938321  2459 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0927 02:19:07.520073  2459 solver.cpp:218] Iteration 86800 (6.85789 iter/s, 14.5818s/100 iters), loss = 0.0197614
I0927 02:19:07.520114  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197612 (* 1 = 0.0197612 loss)
I0927 02:19:07.520120  2459 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0927 02:19:22.111066  2459 solver.cpp:218] Iteration 86900 (6.85357 iter/s, 14.5909s/100 iters), loss = 0.0173741
I0927 02:19:22.111107  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173739 (* 1 = 0.0173739 loss)
I0927 02:19:22.111114  2459 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0927 02:19:35.968485  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:19:36.551739  2459 solver.cpp:330] Iteration 87000, Testing net (#0)
I0927 02:19:39.969313  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:19:40.112124  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I0927 02:19:40.112159  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377778 (* 1 = 0.377778 loss)
I0927 02:19:40.256655  2459 solver.cpp:218] Iteration 87000 (5.511 iter/s, 18.1455s/100 iters), loss = 0.0245428
I0927 02:19:40.256681  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245426 (* 1 = 0.0245426 loss)
I0927 02:19:40.256688  2459 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0927 02:19:54.826045  2459 solver.cpp:218] Iteration 87100 (6.86373 iter/s, 14.5693s/100 iters), loss = 0.0068285
I0927 02:19:54.826076  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068283 (* 1 = 0.0068283 loss)
I0927 02:19:54.826082  2459 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0927 02:20:09.407958  2459 solver.cpp:218] Iteration 87200 (6.85784 iter/s, 14.5819s/100 iters), loss = 0.00871273
I0927 02:20:09.408082  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00871253 (* 1 = 0.00871253 loss)
I0927 02:20:09.408103  2459 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0927 02:20:23.995054  2459 solver.cpp:218] Iteration 87300 (6.85544 iter/s, 14.587s/100 iters), loss = 0.0198839
I0927 02:20:23.995085  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198837 (* 1 = 0.0198837 loss)
I0927 02:20:23.995090  2459 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0927 02:20:38.579728  2459 solver.cpp:218] Iteration 87400 (6.85654 iter/s, 14.5846s/100 iters), loss = 0.0101939
I0927 02:20:38.579759  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101937 (* 1 = 0.0101937 loss)
I0927 02:20:38.579767  2459 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0927 02:20:52.440088  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:20:53.024046  2459 solver.cpp:330] Iteration 87500, Testing net (#0)
I0927 02:20:56.443394  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:20:56.586199  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I0927 02:20:56.586236  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377108 (* 1 = 0.377108 loss)
I0927 02:20:56.731721  2459 solver.cpp:218] Iteration 87500 (5.50905 iter/s, 18.1519s/100 iters), loss = 0.012531
I0927 02:20:56.731748  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125308 (* 1 = 0.0125308 loss)
I0927 02:20:56.731755  2459 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0927 02:21:11.313308  2459 solver.cpp:218] Iteration 87600 (6.85799 iter/s, 14.5815s/100 iters), loss = 0.0243067
I0927 02:21:11.313339  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243065 (* 1 = 0.0243065 loss)
I0927 02:21:11.313345  2459 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0927 02:21:25.893445  2459 solver.cpp:218] Iteration 87700 (6.85867 iter/s, 14.5801s/100 iters), loss = 0.00919394
I0927 02:21:25.893555  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00919372 (* 1 = 0.00919372 loss)
I0927 02:21:25.893565  2459 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0927 02:21:40.479089  2459 solver.cpp:218] Iteration 87800 (6.85612 iter/s, 14.5855s/100 iters), loss = 0.0037755
I0927 02:21:40.479131  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377527 (* 1 = 0.00377527 loss)
I0927 02:21:40.479137  2459 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0927 02:21:55.058454  2459 solver.cpp:218] Iteration 87900 (6.85904 iter/s, 14.5793s/100 iters), loss = 0.00994025
I0927 02:21:55.058496  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00994001 (* 1 = 0.00994001 loss)
I0927 02:21:55.058502  2459 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0927 02:22:08.918294  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:22:09.502378  2459 solver.cpp:330] Iteration 88000, Testing net (#0)
I0927 02:22:12.920724  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:22:13.063755  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I0927 02:22:13.063789  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376841 (* 1 = 0.376841 loss)
I0927 02:22:13.208467  2459 solver.cpp:218] Iteration 88000 (5.50966 iter/s, 18.1499s/100 iters), loss = 0.0217858
I0927 02:22:13.208492  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217856 (* 1 = 0.0217856 loss)
I0927 02:22:13.208499  2459 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0927 02:22:27.782444  2459 solver.cpp:218] Iteration 88100 (6.86157 iter/s, 14.5739s/100 iters), loss = 0.0113885
I0927 02:22:27.782486  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113883 (* 1 = 0.0113883 loss)
I0927 02:22:27.782492  2459 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0927 02:22:42.363790  2459 solver.cpp:218] Iteration 88200 (6.85811 iter/s, 14.5813s/100 iters), loss = 0.00847737
I0927 02:22:42.363875  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847715 (* 1 = 0.00847715 loss)
I0927 02:22:42.363891  2459 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0927 02:22:56.936461  2459 solver.cpp:218] Iteration 88300 (6.86221 iter/s, 14.5726s/100 iters), loss = 0.00280164
I0927 02:22:56.936492  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028014 (* 1 = 0.0028014 loss)
I0927 02:22:56.936499  2459 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0927 02:23:11.510795  2459 solver.cpp:218] Iteration 88400 (6.8614 iter/s, 14.5743s/100 iters), loss = 0.0243413
I0927 02:23:11.510825  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243411 (* 1 = 0.0243411 loss)
I0927 02:23:11.510831  2459 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0927 02:23:25.356501  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:23:25.940286  2459 solver.cpp:330] Iteration 88500, Testing net (#0)
I0927 02:23:29.359215  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:23:29.502125  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I0927 02:23:29.502161  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377202 (* 1 = 0.377202 loss)
I0927 02:23:29.647671  2459 solver.cpp:218] Iteration 88500 (5.51365 iter/s, 18.1368s/100 iters), loss = 0.0152971
I0927 02:23:29.647698  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152969 (* 1 = 0.0152969 loss)
I0927 02:23:29.647704  2459 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0927 02:23:44.228643  2459 solver.cpp:218] Iteration 88600 (6.85828 iter/s, 14.5809s/100 iters), loss = 0.00706462
I0927 02:23:44.228684  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706438 (* 1 = 0.00706438 loss)
I0927 02:23:44.228690  2459 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0927 02:23:58.811779  2459 solver.cpp:218] Iteration 88700 (6.85727 iter/s, 14.5831s/100 iters), loss = 0.00680097
I0927 02:23:58.811890  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680074 (* 1 = 0.00680074 loss)
I0927 02:23:58.811908  2459 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0927 02:24:13.394372  2459 solver.cpp:218] Iteration 88800 (6.85755 iter/s, 14.5825s/100 iters), loss = 0.00888051
I0927 02:24:13.394405  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00888028 (* 1 = 0.00888028 loss)
I0927 02:24:13.394412  2459 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0927 02:24:27.975131  2459 solver.cpp:218] Iteration 88900 (6.85838 iter/s, 14.5807s/100 iters), loss = 0.0145174
I0927 02:24:27.975173  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145171 (* 1 = 0.0145171 loss)
I0927 02:24:27.975179  2459 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0927 02:24:41.833709  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:24:42.416791  2459 solver.cpp:330] Iteration 89000, Testing net (#0)
I0927 02:24:45.836161  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:24:45.979007  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9009
I0927 02:24:45.979041  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37957 (* 1 = 0.37957 loss)
I0927 02:24:46.123844  2459 solver.cpp:218] Iteration 89000 (5.51005 iter/s, 18.1486s/100 iters), loss = 0.0293412
I0927 02:24:46.123872  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029341 (* 1 = 0.029341 loss)
I0927 02:24:46.123878  2459 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0927 02:25:00.706651  2459 solver.cpp:218] Iteration 89100 (6.85741 iter/s, 14.5828s/100 iters), loss = 0.0115604
I0927 02:25:00.706693  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115602 (* 1 = 0.0115602 loss)
I0927 02:25:00.706699  2459 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0927 02:25:15.299808  2459 solver.cpp:218] Iteration 89200 (6.85256 iter/s, 14.5931s/100 iters), loss = 0.0205047
I0927 02:25:15.299904  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205045 (* 1 = 0.0205045 loss)
I0927 02:25:15.299911  2459 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0927 02:25:29.893604  2459 solver.cpp:218] Iteration 89300 (6.85228 iter/s, 14.5937s/100 iters), loss = 0.00382702
I0927 02:25:29.893647  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382679 (* 1 = 0.00382679 loss)
I0927 02:25:29.893653  2459 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0927 02:25:44.474825  2459 solver.cpp:218] Iteration 89400 (6.85817 iter/s, 14.5812s/100 iters), loss = 0.013142
I0927 02:25:44.474856  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131418 (* 1 = 0.0131418 loss)
I0927 02:25:44.474862  2459 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0927 02:25:58.333319  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:25:58.916353  2459 solver.cpp:330] Iteration 89500, Testing net (#0)
I0927 02:26:02.334496  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:26:02.477354  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9017
I0927 02:26:02.477391  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384053 (* 1 = 0.384053 loss)
I0927 02:26:02.622233  2459 solver.cpp:218] Iteration 89500 (5.51045 iter/s, 18.1474s/100 iters), loss = 0.0158477
I0927 02:26:02.622263  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158475 (* 1 = 0.0158475 loss)
I0927 02:26:02.622269  2459 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0927 02:26:17.210160  2459 solver.cpp:218] Iteration 89600 (6.85501 iter/s, 14.5879s/100 iters), loss = 0.0211849
I0927 02:26:17.210201  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211846 (* 1 = 0.0211846 loss)
I0927 02:26:17.210207  2459 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0927 02:26:31.803369  2459 solver.cpp:218] Iteration 89700 (6.85253 iter/s, 14.5931s/100 iters), loss = 0.0161994
I0927 02:26:31.803508  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161992 (* 1 = 0.0161992 loss)
I0927 02:26:31.803516  2459 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0927 02:26:46.389032  2459 solver.cpp:218] Iteration 89800 (6.85612 iter/s, 14.5855s/100 iters), loss = 0.0154313
I0927 02:26:46.389061  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015431 (* 1 = 0.015431 loss)
I0927 02:26:46.389067  2459 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0927 02:27:00.972625  2459 solver.cpp:218] Iteration 89900 (6.85705 iter/s, 14.5835s/100 iters), loss = 0.0077994
I0927 02:27:00.972656  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00779916 (* 1 = 0.00779916 loss)
I0927 02:27:00.972662  2459 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0927 02:27:14.835835  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:27:15.418069  2459 solver.cpp:330] Iteration 90000, Testing net (#0)
I0927 02:27:18.837405  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:27:18.980144  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9014
I0927 02:27:18.980180  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384893 (* 1 = 0.384893 loss)
I0927 02:27:19.125243  2459 solver.cpp:218] Iteration 90000 (5.50886 iter/s, 18.1526s/100 iters), loss = 0.0173977
I0927 02:27:19.125272  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173974 (* 1 = 0.0173974 loss)
I0927 02:27:19.125279  2459 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0927 02:27:33.697664  2459 solver.cpp:218] Iteration 90100 (6.8623 iter/s, 14.5724s/100 iters), loss = 0.00745074
I0927 02:27:33.697705  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745048 (* 1 = 0.00745048 loss)
I0927 02:27:33.697711  2459 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0927 02:27:48.277024  2459 solver.cpp:218] Iteration 90200 (6.85904 iter/s, 14.5793s/100 iters), loss = 0.0145385
I0927 02:27:48.277143  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145382 (* 1 = 0.0145382 loss)
I0927 02:27:48.277159  2459 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0927 02:28:02.858305  2459 solver.cpp:218] Iteration 90300 (6.85817 iter/s, 14.5811s/100 iters), loss = 0.00256048
I0927 02:28:02.858336  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256022 (* 1 = 0.00256022 loss)
I0927 02:28:02.858342  2459 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0927 02:28:17.439527  2459 solver.cpp:218] Iteration 90400 (6.85816 iter/s, 14.5812s/100 iters), loss = 0.00764051
I0927 02:28:17.439568  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00764025 (* 1 = 0.00764025 loss)
I0927 02:28:17.439574  2459 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0927 02:28:31.296432  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:28:31.879287  2459 solver.cpp:330] Iteration 90500, Testing net (#0)
I0927 02:28:35.297726  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:28:35.440424  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9025
I0927 02:28:35.440460  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383293 (* 1 = 0.383293 loss)
I0927 02:28:35.584714  2459 solver.cpp:218] Iteration 90500 (5.51112 iter/s, 18.1451s/100 iters), loss = 0.00616634
I0927 02:28:35.584740  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616608 (* 1 = 0.00616608 loss)
I0927 02:28:35.584748  2459 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0927 02:28:50.155299  2459 solver.cpp:218] Iteration 90600 (6.86317 iter/s, 14.5705s/100 iters), loss = 0.0177969
I0927 02:28:50.155329  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177966 (* 1 = 0.0177966 loss)
I0927 02:28:50.155335  2459 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0927 02:29:04.737764  2459 solver.cpp:218] Iteration 90700 (6.85758 iter/s, 14.5824s/100 iters), loss = 0.0132252
I0927 02:29:04.737869  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132249 (* 1 = 0.0132249 loss)
I0927 02:29:04.737877  2459 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0927 02:29:19.318787  2459 solver.cpp:218] Iteration 90800 (6.85829 iter/s, 14.5809s/100 iters), loss = 0.0032722
I0927 02:29:19.318817  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327194 (* 1 = 0.00327194 loss)
I0927 02:29:19.318823  2459 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0927 02:29:33.902031  2459 solver.cpp:218] Iteration 90900 (6.85721 iter/s, 14.5832s/100 iters), loss = 0.00840774
I0927 02:29:33.902072  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00840748 (* 1 = 0.00840748 loss)
I0927 02:29:33.902079  2459 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0927 02:29:47.758985  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:29:48.342495  2459 solver.cpp:330] Iteration 91000, Testing net (#0)
I0927 02:29:51.761396  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:29:51.904348  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I0927 02:29:51.904386  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383974 (* 1 = 0.383974 loss)
I0927 02:29:52.048950  2459 solver.cpp:218] Iteration 91000 (5.5106 iter/s, 18.1469s/100 iters), loss = 0.0190919
I0927 02:29:52.048977  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190916 (* 1 = 0.0190916 loss)
I0927 02:29:52.048985  2459 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0927 02:30:06.629340  2459 solver.cpp:218] Iteration 91100 (6.85855 iter/s, 14.5803s/100 iters), loss = 0.00503253
I0927 02:30:06.629370  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503226 (* 1 = 0.00503226 loss)
I0927 02:30:06.629376  2459 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0927 02:30:21.212875  2459 solver.cpp:218] Iteration 91200 (6.85707 iter/s, 14.5835s/100 iters), loss = 0.0022477
I0927 02:30:21.213001  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224744 (* 1 = 0.00224744 loss)
I0927 02:30:21.213021  2459 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0927 02:30:35.801726  2459 solver.cpp:218] Iteration 91300 (6.85462 iter/s, 14.5887s/100 iters), loss = 0.0189256
I0927 02:30:35.801758  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189254 (* 1 = 0.0189254 loss)
I0927 02:30:35.801765  2459 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0927 02:30:50.390208  2459 solver.cpp:218] Iteration 91400 (6.85475 iter/s, 14.5884s/100 iters), loss = 0.0284159
I0927 02:30:50.390238  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284156 (* 1 = 0.0284156 loss)
I0927 02:30:50.390245  2459 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0927 02:31:04.255393  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:31:04.839263  2459 solver.cpp:330] Iteration 91500, Testing net (#0)
I0927 02:31:08.257764  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:31:08.400535  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.902
I0927 02:31:08.400571  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385241 (* 1 = 0.385241 loss)
I0927 02:31:08.545117  2459 solver.cpp:218] Iteration 91500 (5.50817 iter/s, 18.1549s/100 iters), loss = 0.0232075
I0927 02:31:08.545143  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232073 (* 1 = 0.0232073 loss)
I0927 02:31:08.545150  2459 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0927 02:31:23.117527  2459 solver.cpp:218] Iteration 91600 (6.86231 iter/s, 14.5724s/100 iters), loss = 0.0109867
I0927 02:31:23.117557  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109864 (* 1 = 0.0109864 loss)
I0927 02:31:23.117561  2459 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0927 02:31:37.692909  2459 solver.cpp:218] Iteration 91700 (6.86091 iter/s, 14.5753s/100 iters), loss = 0.00179106
I0927 02:31:37.692988  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179079 (* 1 = 0.00179079 loss)
I0927 02:31:37.693006  2459 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0927 02:31:52.264999  2459 solver.cpp:218] Iteration 91800 (6.86248 iter/s, 14.572s/100 iters), loss = 0.00763055
I0927 02:31:52.265041  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00763028 (* 1 = 0.00763028 loss)
I0927 02:31:52.265048  2459 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0927 02:32:06.844511  2459 solver.cpp:218] Iteration 91900 (6.85897 iter/s, 14.5794s/100 iters), loss = 0.0163111
I0927 02:32:06.844539  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163108 (* 1 = 0.0163108 loss)
I0927 02:32:06.844545  2459 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0927 02:32:20.697412  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:32:21.280849  2459 solver.cpp:330] Iteration 92000, Testing net (#0)
I0927 02:32:24.701333  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:32:24.843972  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I0927 02:32:24.843998  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385608 (* 1 = 0.385608 loss)
I0927 02:32:24.989538  2459 solver.cpp:218] Iteration 92000 (5.51117 iter/s, 18.145s/100 iters), loss = 0.00861066
I0927 02:32:24.989565  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0086104 (* 1 = 0.0086104 loss)
I0927 02:32:24.989572  2459 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0927 02:32:39.566359  2459 solver.cpp:218] Iteration 92100 (6.86023 iter/s, 14.5768s/100 iters), loss = 0.0185868
I0927 02:32:39.566401  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185866 (* 1 = 0.0185866 loss)
I0927 02:32:39.566406  2459 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0927 02:32:54.144826  2459 solver.cpp:218] Iteration 92200 (6.85946 iter/s, 14.5784s/100 iters), loss = 0.0137462
I0927 02:32:54.144953  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137459 (* 1 = 0.0137459 loss)
I0927 02:32:54.144960  2459 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0927 02:33:08.726069  2459 solver.cpp:218] Iteration 92300 (6.8582 iter/s, 14.5811s/100 iters), loss = 0.0168003
I0927 02:33:08.726111  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168 (* 1 = 0.0168 loss)
I0927 02:33:08.726117  2459 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0927 02:33:23.300447  2459 solver.cpp:218] Iteration 92400 (6.86139 iter/s, 14.5743s/100 iters), loss = 0.00869547
I0927 02:33:23.300477  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869522 (* 1 = 0.00869522 loss)
I0927 02:33:23.300493  2459 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0927 02:33:37.157892  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:33:37.740183  2459 solver.cpp:330] Iteration 92500, Testing net (#0)
I0927 02:33:41.160068  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:33:41.302762  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I0927 02:33:41.302798  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383488 (* 1 = 0.383488 loss)
I0927 02:33:41.448017  2459 solver.cpp:218] Iteration 92500 (5.5104 iter/s, 18.1475s/100 iters), loss = 0.0142236
I0927 02:33:41.448045  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142234 (* 1 = 0.0142234 loss)
I0927 02:33:41.448051  2459 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0927 02:33:56.026607  2459 solver.cpp:218] Iteration 92600 (6.8594 iter/s, 14.5785s/100 iters), loss = 0.0178889
I0927 02:33:56.026649  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178886 (* 1 = 0.0178886 loss)
I0927 02:33:56.026655  2459 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0927 02:34:10.611871  2459 solver.cpp:218] Iteration 92700 (6.85627 iter/s, 14.5852s/100 iters), loss = 0.00695668
I0927 02:34:10.611940  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695642 (* 1 = 0.00695642 loss)
I0927 02:34:10.611948  2459 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0927 02:34:25.199090  2459 solver.cpp:218] Iteration 92800 (6.85536 iter/s, 14.5871s/100 iters), loss = 0.00556268
I0927 02:34:25.199132  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556241 (* 1 = 0.00556241 loss)
I0927 02:34:25.199138  2459 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0927 02:34:39.784574  2459 solver.cpp:218] Iteration 92900 (6.85616 iter/s, 14.5854s/100 iters), loss = 0.0160267
I0927 02:34:39.784615  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160264 (* 1 = 0.0160264 loss)
I0927 02:34:39.784621  2459 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0927 02:34:53.641543  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:34:54.225177  2459 solver.cpp:330] Iteration 93000, Testing net (#0)
I0927 02:34:57.645046  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:34:57.788064  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I0927 02:34:57.788092  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38439 (* 1 = 0.38439 loss)
I0927 02:34:57.933001  2459 solver.cpp:218] Iteration 93000 (5.51014 iter/s, 18.1484s/100 iters), loss = 0.00310462
I0927 02:34:57.933027  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310434 (* 1 = 0.00310434 loss)
I0927 02:34:57.933032  2459 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0927 02:35:12.507375  2459 solver.cpp:218] Iteration 93100 (6.86138 iter/s, 14.5743s/100 iters), loss = 0.0136821
I0927 02:35:12.507414  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136818 (* 1 = 0.0136818 loss)
I0927 02:35:12.507421  2459 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0927 02:35:27.082370  2459 solver.cpp:218] Iteration 93200 (6.8611 iter/s, 14.5749s/100 iters), loss = 0.016044
I0927 02:35:27.082489  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160437 (* 1 = 0.0160437 loss)
I0927 02:35:27.082506  2459 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0927 02:35:41.659924  2459 solver.cpp:218] Iteration 93300 (6.85993 iter/s, 14.5774s/100 iters), loss = 0.00370413
I0927 02:35:41.659965  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370384 (* 1 = 0.00370384 loss)
I0927 02:35:41.659971  2459 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0927 02:35:56.236394  2459 solver.cpp:218] Iteration 93400 (6.8604 iter/s, 14.5764s/100 iters), loss = 0.00515088
I0927 02:35:56.236425  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051506 (* 1 = 0.0051506 loss)
I0927 02:35:56.236431  2459 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0927 02:36:10.087923  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:36:10.671095  2459 solver.cpp:330] Iteration 93500, Testing net (#0)
I0927 02:36:14.089498  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:36:14.232287  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9022
I0927 02:36:14.232323  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38472 (* 1 = 0.38472 loss)
I0927 02:36:14.377032  2459 solver.cpp:218] Iteration 93500 (5.5125 iter/s, 18.1406s/100 iters), loss = 0.00731309
I0927 02:36:14.377058  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731281 (* 1 = 0.00731281 loss)
I0927 02:36:14.377065  2459 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0927 02:36:28.949667  2459 solver.cpp:218] Iteration 93600 (6.8622 iter/s, 14.5726s/100 iters), loss = 0.022563
I0927 02:36:28.949708  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225627 (* 1 = 0.0225627 loss)
I0927 02:36:28.949714  2459 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0927 02:36:43.526988  2459 solver.cpp:218] Iteration 93700 (6.86 iter/s, 14.5773s/100 iters), loss = 0.00350747
I0927 02:36:43.527050  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350719 (* 1 = 0.00350719 loss)
I0927 02:36:43.527055  2459 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0927 02:36:58.096613  2459 solver.cpp:218] Iteration 93800 (6.86363 iter/s, 14.5695s/100 iters), loss = 0.0165157
I0927 02:36:58.096654  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165154 (* 1 = 0.0165154 loss)
I0927 02:36:58.096660  2459 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0927 02:37:12.669809  2459 solver.cpp:218] Iteration 93900 (6.86194 iter/s, 14.5731s/100 iters), loss = 0.00332116
I0927 02:37:12.669839  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332089 (* 1 = 0.00332089 loss)
I0927 02:37:12.669847  2459 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0927 02:37:26.511827  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:37:27.095805  2459 solver.cpp:330] Iteration 94000, Testing net (#0)
I0927 02:37:30.514852  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:37:30.657248  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9022
I0927 02:37:30.657284  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385322 (* 1 = 0.385322 loss)
I0927 02:37:30.802289  2459 solver.cpp:218] Iteration 94000 (5.51498 iter/s, 18.1324s/100 iters), loss = 0.0343397
I0927 02:37:30.802315  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343394 (* 1 = 0.0343394 loss)
I0927 02:37:30.802322  2459 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0927 02:37:45.371183  2459 solver.cpp:218] Iteration 94100 (6.86396 iter/s, 14.5688s/100 iters), loss = 0.00986707
I0927 02:37:45.371214  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0098668 (* 1 = 0.0098668 loss)
I0927 02:37:45.371220  2459 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0927 02:37:59.944109  2459 solver.cpp:218] Iteration 94200 (6.86207 iter/s, 14.5729s/100 iters), loss = 0.0097829
I0927 02:37:59.944224  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978262 (* 1 = 0.00978262 loss)
I0927 02:37:59.944234  2459 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0927 02:38:14.519963  2459 solver.cpp:218] Iteration 94300 (6.86073 iter/s, 14.5757s/100 iters), loss = 0.00757166
I0927 02:38:14.520004  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00757139 (* 1 = 0.00757139 loss)
I0927 02:38:14.520009  2459 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0927 02:38:29.091619  2459 solver.cpp:218] Iteration 94400 (6.86267 iter/s, 14.5716s/100 iters), loss = 0.00789946
I0927 02:38:29.091660  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00789918 (* 1 = 0.00789918 loss)
I0927 02:38:29.091665  2459 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0927 02:38:42.944572  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:38:43.528806  2459 solver.cpp:330] Iteration 94500, Testing net (#0)
I0927 02:38:46.947041  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:38:47.089845  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I0927 02:38:47.089881  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389731 (* 1 = 0.389731 loss)
I0927 02:38:47.234663  2459 solver.cpp:218] Iteration 94500 (5.51177 iter/s, 18.143s/100 iters), loss = 0.00692832
I0927 02:38:47.234689  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692804 (* 1 = 0.00692804 loss)
I0927 02:38:47.234696  2459 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0927 02:39:01.820613  2459 solver.cpp:218] Iteration 94600 (6.85594 iter/s, 14.5859s/100 iters), loss = 0.00454344
I0927 02:39:01.820657  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454315 (* 1 = 0.00454315 loss)
I0927 02:39:01.820663  2459 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0927 02:39:16.407727  2459 solver.cpp:218] Iteration 94700 (6.8554 iter/s, 14.587s/100 iters), loss = 0.00388566
I0927 02:39:16.407805  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388537 (* 1 = 0.00388537 loss)
I0927 02:39:16.407815  2459 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0927 02:39:30.991037  2459 solver.cpp:218] Iteration 94800 (6.8572 iter/s, 14.5832s/100 iters), loss = 0.004313
I0927 02:39:30.991070  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043127 (* 1 = 0.0043127 loss)
I0927 02:39:30.991077  2459 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0927 02:39:45.577719  2459 solver.cpp:218] Iteration 94900 (6.85559 iter/s, 14.5866s/100 iters), loss = 0.00762717
I0927 02:39:45.577751  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00762688 (* 1 = 0.00762688 loss)
I0927 02:39:45.577760  2459 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0927 02:39:59.447284  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:40:00.031523  2459 solver.cpp:330] Iteration 95000, Testing net (#0)
I0927 02:40:03.451299  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:40:03.594513  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I0927 02:40:03.594550  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389104 (* 1 = 0.389104 loss)
I0927 02:40:03.738895  2459 solver.cpp:218] Iteration 95000 (5.50627 iter/s, 18.1611s/100 iters), loss = 0.00909909
I0927 02:40:03.738921  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090988 (* 1 = 0.0090988 loss)
I0927 02:40:03.738929  2459 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0927 02:40:18.315831  2459 solver.cpp:218] Iteration 95100 (6.86018 iter/s, 14.5769s/100 iters), loss = 0.0136238
I0927 02:40:18.315862  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136235 (* 1 = 0.0136235 loss)
I0927 02:40:18.315868  2459 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0927 02:40:32.887718  2459 solver.cpp:218] Iteration 95200 (6.86256 iter/s, 14.5718s/100 iters), loss = 0.0371132
I0927 02:40:32.887856  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371129 (* 1 = 0.0371129 loss)
I0927 02:40:32.887866  2459 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0927 02:40:47.465839  2459 solver.cpp:218] Iteration 95300 (6.85967 iter/s, 14.578s/100 iters), loss = 0.0119933
I0927 02:40:47.465870  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011993 (* 1 = 0.011993 loss)
I0927 02:40:47.465876  2459 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0927 02:41:02.040976  2459 solver.cpp:218] Iteration 95400 (6.86103 iter/s, 14.5751s/100 iters), loss = 0.0237806
I0927 02:41:02.041007  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237803 (* 1 = 0.0237803 loss)
I0927 02:41:02.041014  2459 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0927 02:41:15.897256  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:41:16.480182  2459 solver.cpp:330] Iteration 95500, Testing net (#0)
I0927 02:41:19.897353  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:41:20.040191  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9025
I0927 02:41:20.040230  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.386389 (* 1 = 0.386389 loss)
I0927 02:41:20.185305  2459 solver.cpp:218] Iteration 95500 (5.51138 iter/s, 18.1443s/100 iters), loss = 0.0117235
I0927 02:41:20.185331  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117232 (* 1 = 0.0117232 loss)
I0927 02:41:20.185338  2459 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0927 02:41:34.762825  2459 solver.cpp:218] Iteration 95600 (6.8599 iter/s, 14.5775s/100 iters), loss = 0.0150778
I0927 02:41:34.762868  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150775 (* 1 = 0.0150775 loss)
I0927 02:41:34.762873  2459 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0927 02:41:49.348906  2459 solver.cpp:218] Iteration 95700 (6.85588 iter/s, 14.586s/100 iters), loss = 0.0152467
I0927 02:41:49.348992  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152464 (* 1 = 0.0152464 loss)
I0927 02:41:49.349000  2459 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0927 02:42:03.929324  2459 solver.cpp:218] Iteration 95800 (6.85856 iter/s, 14.5803s/100 iters), loss = 0.00448096
I0927 02:42:03.929365  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448065 (* 1 = 0.00448065 loss)
I0927 02:42:03.929371  2459 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0927 02:42:18.510044  2459 solver.cpp:218] Iteration 95900 (6.8584 iter/s, 14.5807s/100 iters), loss = 0.00425331
I0927 02:42:18.510087  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425299 (* 1 = 0.00425299 loss)
I0927 02:42:18.510092  2459 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0927 02:42:32.365018  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:42:32.948633  2459 solver.cpp:330] Iteration 96000, Testing net (#0)
I0927 02:42:36.367434  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:42:36.509971  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I0927 02:42:36.510009  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389827 (* 1 = 0.389827 loss)
I0927 02:42:36.654593  2459 solver.cpp:218] Iteration 96000 (5.51132 iter/s, 18.1445s/100 iters), loss = 0.0073697
I0927 02:42:36.654619  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00736938 (* 1 = 0.00736938 loss)
I0927 02:42:36.654626  2459 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0927 02:42:51.228199  2459 solver.cpp:218] Iteration 96100 (6.86174 iter/s, 14.5736s/100 iters), loss = 0.0115541
I0927 02:42:51.228240  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115538 (* 1 = 0.0115538 loss)
I0927 02:42:51.228245  2459 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0927 02:43:05.809013  2459 solver.cpp:218] Iteration 96200 (6.85836 iter/s, 14.5808s/100 iters), loss = 0.00590455
I0927 02:43:05.809114  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00590424 (* 1 = 0.00590424 loss)
I0927 02:43:05.809134  2459 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0927 02:43:20.393147  2459 solver.cpp:218] Iteration 96300 (6.85682 iter/s, 14.584s/100 iters), loss = 0.00359314
I0927 02:43:20.393189  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359283 (* 1 = 0.00359283 loss)
I0927 02:43:20.393195  2459 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0927 02:43:34.973012  2459 solver.cpp:218] Iteration 96400 (6.8588 iter/s, 14.5798s/100 iters), loss = 0.0225508
I0927 02:43:34.973054  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225505 (* 1 = 0.0225505 loss)
I0927 02:43:34.973059  2459 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0927 02:43:48.831908  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:43:49.415808  2459 solver.cpp:330] Iteration 96500, Testing net (#0)
I0927 02:43:52.834491  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:43:52.976917  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9005
I0927 02:43:52.976953  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393917 (* 1 = 0.393917 loss)
I0927 02:43:53.121470  2459 solver.cpp:218] Iteration 96500 (5.51013 iter/s, 18.1484s/100 iters), loss = 0.0118117
I0927 02:43:53.121497  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118113 (* 1 = 0.0118113 loss)
I0927 02:43:53.121503  2459 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0927 02:44:07.704207  2459 solver.cpp:218] Iteration 96600 (6.85745 iter/s, 14.5827s/100 iters), loss = 0.00392255
I0927 02:44:07.704237  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392223 (* 1 = 0.00392223 loss)
I0927 02:44:07.704243  2459 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0927 02:44:22.289371  2459 solver.cpp:218] Iteration 96700 (6.85631 iter/s, 14.5851s/100 iters), loss = 0.0135841
I0927 02:44:22.289463  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135838 (* 1 = 0.0135838 loss)
I0927 02:44:22.289472  2459 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0927 02:44:36.871162  2459 solver.cpp:218] Iteration 96800 (6.85792 iter/s, 14.5817s/100 iters), loss = 0.00568009
I0927 02:44:36.871203  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567977 (* 1 = 0.00567977 loss)
I0927 02:44:36.871210  2459 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0927 02:44:51.444221  2459 solver.cpp:218] Iteration 96900 (6.86201 iter/s, 14.573s/100 iters), loss = 0.0153864
I0927 02:44:51.444252  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153861 (* 1 = 0.0153861 loss)
I0927 02:44:51.444267  2459 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0927 02:45:05.292907  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:45:05.876560  2459 solver.cpp:330] Iteration 97000, Testing net (#0)
I0927 02:45:09.295435  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:45:09.438480  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I0927 02:45:09.438516  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391693 (* 1 = 0.391693 loss)
I0927 02:45:09.583549  2459 solver.cpp:218] Iteration 97000 (5.5129 iter/s, 18.1393s/100 iters), loss = 0.0110829
I0927 02:45:09.583576  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110826 (* 1 = 0.0110826 loss)
I0927 02:45:09.583583  2459 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0927 02:45:24.159883  2459 solver.cpp:218] Iteration 97100 (6.86046 iter/s, 14.5763s/100 iters), loss = 0.0153659
I0927 02:45:24.159914  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153656 (* 1 = 0.0153656 loss)
I0927 02:45:24.159920  2459 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0927 02:45:38.736178  2459 solver.cpp:218] Iteration 97200 (6.86048 iter/s, 14.5762s/100 iters), loss = 0.0131382
I0927 02:45:38.736260  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131379 (* 1 = 0.0131379 loss)
I0927 02:45:38.736268  2459 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0927 02:45:53.316581  2459 solver.cpp:218] Iteration 97300 (6.85857 iter/s, 14.5803s/100 iters), loss = 0.00806455
I0927 02:45:53.316622  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00806423 (* 1 = 0.00806423 loss)
I0927 02:45:53.316628  2459 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0927 02:46:07.897948  2459 solver.cpp:218] Iteration 97400 (6.8581 iter/s, 14.5813s/100 iters), loss = 0.00829189
I0927 02:46:07.897979  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829156 (* 1 = 0.00829156 loss)
I0927 02:46:07.897985  2459 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0927 02:46:21.753782  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:46:22.336319  2459 solver.cpp:330] Iteration 97500, Testing net (#0)
I0927 02:46:25.753118  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:46:25.896206  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9038
I0927 02:46:25.896250  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389412 (* 1 = 0.389412 loss)
I0927 02:46:26.040746  2459 solver.cpp:218] Iteration 97500 (5.51185 iter/s, 18.1427s/100 iters), loss = 0.0115538
I0927 02:46:26.040774  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115534 (* 1 = 0.0115534 loss)
I0927 02:46:26.040781  2459 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0927 02:46:40.609969  2459 solver.cpp:218] Iteration 97600 (6.86381 iter/s, 14.5692s/100 iters), loss = 0.00511386
I0927 02:46:40.609999  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511353 (* 1 = 0.00511353 loss)
I0927 02:46:40.610005  2459 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0927 02:46:55.181434  2459 solver.cpp:218] Iteration 97700 (6.86275 iter/s, 14.5714s/100 iters), loss = 0.00360861
I0927 02:46:55.181529  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360828 (* 1 = 0.00360828 loss)
I0927 02:46:55.181535  2459 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0927 02:47:09.759297  2459 solver.cpp:218] Iteration 97800 (6.85977 iter/s, 14.5777s/100 iters), loss = 0.00911693
I0927 02:47:09.759340  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091166 (* 1 = 0.0091166 loss)
I0927 02:47:09.759346  2459 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0927 02:47:24.337319  2459 solver.cpp:218] Iteration 97900 (6.85967 iter/s, 14.578s/100 iters), loss = 0.00606185
I0927 02:47:24.337362  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00606151 (* 1 = 0.00606151 loss)
I0927 02:47:24.337366  2459 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0927 02:47:38.188854  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:47:38.772243  2459 solver.cpp:330] Iteration 98000, Testing net (#0)
I0927 02:47:42.191761  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:47:42.334807  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I0927 02:47:42.334844  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391639 (* 1 = 0.391639 loss)
I0927 02:47:42.480173  2459 solver.cpp:218] Iteration 98000 (5.51183 iter/s, 18.1428s/100 iters), loss = 0.00336007
I0927 02:47:42.480204  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335973 (* 1 = 0.00335973 loss)
I0927 02:47:42.480211  2459 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0927 02:47:57.059072  2459 solver.cpp:218] Iteration 98100 (6.85925 iter/s, 14.5788s/100 iters), loss = 0.00970259
I0927 02:47:57.059114  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00970226 (* 1 = 0.00970226 loss)
I0927 02:47:57.059120  2459 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0927 02:48:11.640769  2459 solver.cpp:218] Iteration 98200 (6.85794 iter/s, 14.5816s/100 iters), loss = 0.00460996
I0927 02:48:11.640888  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460963 (* 1 = 0.00460963 loss)
I0927 02:48:11.640905  2459 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0927 02:48:26.223635  2459 solver.cpp:218] Iteration 98300 (6.85743 iter/s, 14.5827s/100 iters), loss = 0.0132993
I0927 02:48:26.223677  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132989 (* 1 = 0.0132989 loss)
I0927 02:48:26.223683  2459 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0927 02:48:40.810410  2459 solver.cpp:218] Iteration 98400 (6.85556 iter/s, 14.5867s/100 iters), loss = 0.00521357
I0927 02:48:40.810442  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521322 (* 1 = 0.00521322 loss)
I0927 02:48:40.810458  2459 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0927 02:48:54.671952  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:48:55.255386  2459 solver.cpp:330] Iteration 98500, Testing net (#0)
I0927 02:48:58.673483  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:48:58.816242  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9026
I0927 02:48:58.816279  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391623 (* 1 = 0.391623 loss)
I0927 02:48:58.960705  2459 solver.cpp:218] Iteration 98500 (5.50957 iter/s, 18.1502s/100 iters), loss = 0.0164851
I0927 02:48:58.960731  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164847 (* 1 = 0.0164847 loss)
I0927 02:48:58.960737  2459 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0927 02:49:13.531251  2459 solver.cpp:218] Iteration 98600 (6.86318 iter/s, 14.5705s/100 iters), loss = 0.00400677
I0927 02:49:13.531292  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400642 (* 1 = 0.00400642 loss)
I0927 02:49:13.531298  2459 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0927 02:49:28.102718  2459 solver.cpp:218] Iteration 98700 (6.86276 iter/s, 14.5714s/100 iters), loss = 0.0127937
I0927 02:49:28.102869  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127933 (* 1 = 0.0127933 loss)
I0927 02:49:28.102888  2459 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0927 02:49:42.676045  2459 solver.cpp:218] Iteration 98800 (6.86193 iter/s, 14.5732s/100 iters), loss = 0.00669334
I0927 02:49:42.676087  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006693 (* 1 = 0.006693 loss)
I0927 02:49:42.676093  2459 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0927 02:49:57.245582  2459 solver.cpp:218] Iteration 98900 (6.86367 iter/s, 14.5695s/100 iters), loss = 0.00700685
I0927 02:49:57.245623  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0070065 (* 1 = 0.0070065 loss)
I0927 02:49:57.245630  2459 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0927 02:50:11.093209  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:50:11.677251  2459 solver.cpp:330] Iteration 99000, Testing net (#0)
I0927 02:50:15.095479  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:50:15.238391  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I0927 02:50:15.238427  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388627 (* 1 = 0.388627 loss)
I0927 02:50:15.383882  2459 solver.cpp:218] Iteration 99000 (5.51322 iter/s, 18.1382s/100 iters), loss = 0.00527413
I0927 02:50:15.383910  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527379 (* 1 = 0.00527379 loss)
I0927 02:50:15.383918  2459 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0927 02:50:29.953773  2459 solver.cpp:218] Iteration 99100 (6.86349 iter/s, 14.5698s/100 iters), loss = 0.00411745
I0927 02:50:29.953814  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041171 (* 1 = 0.0041171 loss)
I0927 02:50:29.953820  2459 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0927 02:50:44.524945  2459 solver.cpp:218] Iteration 99200 (6.86289 iter/s, 14.5711s/100 iters), loss = 0.0105409
I0927 02:50:44.525013  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105406 (* 1 = 0.0105406 loss)
I0927 02:50:44.525019  2459 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0927 02:50:59.095549  2459 solver.cpp:218] Iteration 99300 (6.86318 iter/s, 14.5705s/100 iters), loss = 0.00225287
I0927 02:50:59.095590  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225253 (* 1 = 0.00225253 loss)
I0927 02:50:59.095597  2459 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0927 02:51:13.668296  2459 solver.cpp:218] Iteration 99400 (6.86215 iter/s, 14.5727s/100 iters), loss = 0.00847885
I0927 02:51:13.668339  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847851 (* 1 = 0.00847851 loss)
I0927 02:51:13.668344  2459 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0927 02:51:27.514258  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:51:28.097734  2459 solver.cpp:330] Iteration 99500, Testing net (#0)
I0927 02:51:31.516161  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:51:31.658720  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I0927 02:51:31.658756  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.39347 (* 1 = 0.39347 loss)
I0927 02:51:31.803457  2459 solver.cpp:218] Iteration 99500 (5.51417 iter/s, 18.1351s/100 iters), loss = 0.0100929
I0927 02:51:31.803484  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100926 (* 1 = 0.0100926 loss)
I0927 02:51:31.803491  2459 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0927 02:51:46.384007  2459 solver.cpp:218] Iteration 99600 (6.85848 iter/s, 14.5805s/100 iters), loss = 0.00671685
I0927 02:51:46.384049  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067165 (* 1 = 0.0067165 loss)
I0927 02:51:46.384055  2459 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0927 02:52:00.971587  2459 solver.cpp:218] Iteration 99700 (6.85518 iter/s, 14.5875s/100 iters), loss = 0.0406758
I0927 02:52:00.971684  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406755 (* 1 = 0.0406755 loss)
I0927 02:52:00.971701  2459 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0927 02:52:15.560492  2459 solver.cpp:218] Iteration 99800 (6.85458 iter/s, 14.5888s/100 iters), loss = 0.0117613
I0927 02:52:15.560533  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117609 (* 1 = 0.0117609 loss)
I0927 02:52:15.560539  2459 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0927 02:52:30.150033  2459 solver.cpp:218] Iteration 99900 (6.85426 iter/s, 14.5895s/100 iters), loss = 0.00470769
I0927 02:52:30.150074  2459 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00470735 (* 1 = 0.00470735 loss)
I0927 02:52:30.150080  2459 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0927 02:52:44.014750  2499 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:52:44.597908  2459 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_betaandeta_nostudy_gauss_iter_100000.caffemodel
I0927 02:52:44.625277  2459 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_betaandeta_nostudy_gauss_iter_100000.solverstate
I0927 02:52:44.665977  2459 solver.cpp:310] Iteration 100000, loss = 0.00808618
I0927 02:52:44.665998  2459 solver.cpp:330] Iteration 100000, Testing net (#0)
I0927 02:52:48.083117  2502 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:52:48.225917  2459 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I0927 02:52:48.225955  2459 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393085 (* 1 = 0.393085 loss)
I0927 02:52:48.225960  2459 solver.cpp:315] Optimization Done.
I0927 02:52:48.225961  2459 caffe.cpp:259] Optimization Done.
