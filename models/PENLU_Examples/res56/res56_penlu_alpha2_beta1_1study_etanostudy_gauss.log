I0927 10:14:38.507045  3315 caffe.cpp:218] Using GPUs 0
I0927 10:14:38.541792  3315 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0927 10:14:38.767794  3315 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_eta_nostudy_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0927 10:14:38.767943  3315 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0927 10:14:38.771911  3315 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0927 10:14:38.771924  3315 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0927 10:14:38.772213  3315 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0927 10:14:38.772351  3315 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0927 10:14:38.773550  3315 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std
I0927 10:14:38.774325  3315 layer_factory.hpp:77] Creating layer Data1
I0927 10:14:38.774412  3315 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0927 10:14:38.774432  3315 net.cpp:84] Creating Layer Data1
I0927 10:14:38.774437  3315 net.cpp:380] Data1 -> Data1
I0927 10:14:38.774454  3315 net.cpp:380] Data1 -> Data2
I0927 10:14:38.774463  3315 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0927 10:14:38.775861  3315 data_layer.cpp:45] output data size: 100,3,28,28
I0927 10:14:38.778107  3315 net.cpp:122] Setting up Data1
I0927 10:14:38.778120  3315 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0927 10:14:38.778123  3315 net.cpp:129] Top shape: 100 (100)
I0927 10:14:38.778126  3315 net.cpp:137] Memory required for data: 941200
I0927 10:14:38.778132  3315 layer_factory.hpp:77] Creating layer Convolution1
I0927 10:14:38.778151  3315 net.cpp:84] Creating Layer Convolution1
I0927 10:14:38.778154  3315 net.cpp:406] Convolution1 <- Data1
I0927 10:14:38.778163  3315 net.cpp:380] Convolution1 -> Convolution1
I0927 10:14:38.923311  3315 net.cpp:122] Setting up Convolution1
I0927 10:14:38.923336  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.923339  3315 net.cpp:137] Memory required for data: 5958800
I0927 10:14:38.923353  3315 layer_factory.hpp:77] Creating layer BatchNorm1
I0927 10:14:38.923373  3315 net.cpp:84] Creating Layer BatchNorm1
I0927 10:14:38.923377  3315 net.cpp:406] BatchNorm1 <- Convolution1
I0927 10:14:38.923393  3315 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0927 10:14:38.923526  3315 net.cpp:122] Setting up BatchNorm1
I0927 10:14:38.923532  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.923533  3315 net.cpp:137] Memory required for data: 10976400
I0927 10:14:38.923540  3315 layer_factory.hpp:77] Creating layer Scale1
I0927 10:14:38.923550  3315 net.cpp:84] Creating Layer Scale1
I0927 10:14:38.923563  3315 net.cpp:406] Scale1 <- Convolution1
I0927 10:14:38.923566  3315 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0927 10:14:38.923596  3315 layer_factory.hpp:77] Creating layer Scale1
I0927 10:14:38.923702  3315 net.cpp:122] Setting up Scale1
I0927 10:14:38.923708  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.923710  3315 net.cpp:137] Memory required for data: 15994000
I0927 10:14:38.923725  3315 layer_factory.hpp:77] Creating layer penlu1
I0927 10:14:38.923732  3315 net.cpp:84] Creating Layer penlu1
I0927 10:14:38.923735  3315 net.cpp:406] penlu1 <- Convolution1
I0927 10:14:38.923739  3315 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0927 10:14:38.924355  3315 net.cpp:122] Setting up penlu1
I0927 10:14:38.924365  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.924367  3315 net.cpp:137] Memory required for data: 21011600
I0927 10:14:38.924386  3315 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0927 10:14:38.924407  3315 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0927 10:14:38.924412  3315 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0927 10:14:38.924424  3315 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0927 10:14:38.924443  3315 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0927 10:14:38.924485  3315 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0927 10:14:38.924499  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.924504  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.924516  3315 net.cpp:137] Memory required for data: 31046800
I0927 10:14:38.924520  3315 layer_factory.hpp:77] Creating layer Convolution2
I0927 10:14:38.924537  3315 net.cpp:84] Creating Layer Convolution2
I0927 10:14:38.924540  3315 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0927 10:14:38.924545  3315 net.cpp:380] Convolution2 -> Convolution2
I0927 10:14:38.925397  3315 net.cpp:122] Setting up Convolution2
I0927 10:14:38.925407  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.925421  3315 net.cpp:137] Memory required for data: 36064400
I0927 10:14:38.925427  3315 layer_factory.hpp:77] Creating layer BatchNorm2
I0927 10:14:38.925447  3315 net.cpp:84] Creating Layer BatchNorm2
I0927 10:14:38.925451  3315 net.cpp:406] BatchNorm2 <- Convolution2
I0927 10:14:38.925464  3315 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0927 10:14:38.925628  3315 net.cpp:122] Setting up BatchNorm2
I0927 10:14:38.925633  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.925637  3315 net.cpp:137] Memory required for data: 41082000
I0927 10:14:38.925652  3315 layer_factory.hpp:77] Creating layer Scale2
I0927 10:14:38.925657  3315 net.cpp:84] Creating Layer Scale2
I0927 10:14:38.925670  3315 net.cpp:406] Scale2 <- Convolution2
I0927 10:14:38.925674  3315 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0927 10:14:38.925709  3315 layer_factory.hpp:77] Creating layer Scale2
I0927 10:14:38.925827  3315 net.cpp:122] Setting up Scale2
I0927 10:14:38.925832  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.925834  3315 net.cpp:137] Memory required for data: 46099600
I0927 10:14:38.925850  3315 layer_factory.hpp:77] Creating layer penlu2
I0927 10:14:38.925866  3315 net.cpp:84] Creating Layer penlu2
I0927 10:14:38.925869  3315 net.cpp:406] penlu2 <- Convolution2
I0927 10:14:38.925873  3315 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0927 10:14:38.925981  3315 net.cpp:122] Setting up penlu2
I0927 10:14:38.925987  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.925997  3315 net.cpp:137] Memory required for data: 51117200
I0927 10:14:38.926002  3315 layer_factory.hpp:77] Creating layer Convolution3
I0927 10:14:38.926008  3315 net.cpp:84] Creating Layer Convolution3
I0927 10:14:38.926012  3315 net.cpp:406] Convolution3 <- Convolution2
I0927 10:14:38.926015  3315 net.cpp:380] Convolution3 -> Convolution3
I0927 10:14:38.926821  3315 net.cpp:122] Setting up Convolution3
I0927 10:14:38.926831  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.926836  3315 net.cpp:137] Memory required for data: 56134800
I0927 10:14:38.926839  3315 layer_factory.hpp:77] Creating layer BatchNorm3
I0927 10:14:38.926846  3315 net.cpp:84] Creating Layer BatchNorm3
I0927 10:14:38.926848  3315 net.cpp:406] BatchNorm3 <- Convolution3
I0927 10:14:38.926852  3315 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0927 10:14:38.926961  3315 net.cpp:122] Setting up BatchNorm3
I0927 10:14:38.926966  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.926970  3315 net.cpp:137] Memory required for data: 61152400
I0927 10:14:38.926975  3315 layer_factory.hpp:77] Creating layer Scale3
I0927 10:14:38.926978  3315 net.cpp:84] Creating Layer Scale3
I0927 10:14:38.926982  3315 net.cpp:406] Scale3 <- Convolution3
I0927 10:14:38.926985  3315 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0927 10:14:38.927008  3315 layer_factory.hpp:77] Creating layer Scale3
I0927 10:14:38.927073  3315 net.cpp:122] Setting up Scale3
I0927 10:14:38.927078  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.927080  3315 net.cpp:137] Memory required for data: 66170000
I0927 10:14:38.927084  3315 layer_factory.hpp:77] Creating layer Eltwise1
I0927 10:14:38.927089  3315 net.cpp:84] Creating Layer Eltwise1
I0927 10:14:38.927093  3315 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0927 10:14:38.927095  3315 net.cpp:406] Eltwise1 <- Convolution3
I0927 10:14:38.927099  3315 net.cpp:380] Eltwise1 -> Eltwise1
I0927 10:14:38.927115  3315 net.cpp:122] Setting up Eltwise1
I0927 10:14:38.927120  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.927124  3315 net.cpp:137] Memory required for data: 71187600
I0927 10:14:38.927125  3315 layer_factory.hpp:77] Creating layer penlu3
I0927 10:14:38.927130  3315 net.cpp:84] Creating Layer penlu3
I0927 10:14:38.927134  3315 net.cpp:406] penlu3 <- Eltwise1
I0927 10:14:38.927136  3315 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0927 10:14:38.927227  3315 net.cpp:122] Setting up penlu3
I0927 10:14:38.927232  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.927234  3315 net.cpp:137] Memory required for data: 76205200
I0927 10:14:38.927239  3315 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0927 10:14:38.927243  3315 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0927 10:14:38.927247  3315 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0927 10:14:38.927249  3315 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0927 10:14:38.927255  3315 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0927 10:14:38.927275  3315 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0927 10:14:38.927280  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.927284  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.927286  3315 net.cpp:137] Memory required for data: 86240400
I0927 10:14:38.927289  3315 layer_factory.hpp:77] Creating layer Convolution4
I0927 10:14:38.927295  3315 net.cpp:84] Creating Layer Convolution4
I0927 10:14:38.927299  3315 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0927 10:14:38.927301  3315 net.cpp:380] Convolution4 -> Convolution4
I0927 10:14:38.928094  3315 net.cpp:122] Setting up Convolution4
I0927 10:14:38.928104  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.928108  3315 net.cpp:137] Memory required for data: 91258000
I0927 10:14:38.928112  3315 layer_factory.hpp:77] Creating layer BatchNorm4
I0927 10:14:38.928118  3315 net.cpp:84] Creating Layer BatchNorm4
I0927 10:14:38.928128  3315 net.cpp:406] BatchNorm4 <- Convolution4
I0927 10:14:38.928133  3315 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0927 10:14:38.928242  3315 net.cpp:122] Setting up BatchNorm4
I0927 10:14:38.928247  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.928251  3315 net.cpp:137] Memory required for data: 96275600
I0927 10:14:38.928258  3315 layer_factory.hpp:77] Creating layer Scale4
I0927 10:14:38.928262  3315 net.cpp:84] Creating Layer Scale4
I0927 10:14:38.928267  3315 net.cpp:406] Scale4 <- Convolution4
I0927 10:14:38.928269  3315 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0927 10:14:38.928292  3315 layer_factory.hpp:77] Creating layer Scale4
I0927 10:14:38.928356  3315 net.cpp:122] Setting up Scale4
I0927 10:14:38.928361  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.928364  3315 net.cpp:137] Memory required for data: 101293200
I0927 10:14:38.928369  3315 layer_factory.hpp:77] Creating layer penlu4
I0927 10:14:38.928375  3315 net.cpp:84] Creating Layer penlu4
I0927 10:14:38.928377  3315 net.cpp:406] penlu4 <- Convolution4
I0927 10:14:38.928381  3315 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0927 10:14:38.928473  3315 net.cpp:122] Setting up penlu4
I0927 10:14:38.928479  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.928483  3315 net.cpp:137] Memory required for data: 106310800
I0927 10:14:38.928488  3315 layer_factory.hpp:77] Creating layer Convolution5
I0927 10:14:38.928494  3315 net.cpp:84] Creating Layer Convolution5
I0927 10:14:38.928498  3315 net.cpp:406] Convolution5 <- Convolution4
I0927 10:14:38.928501  3315 net.cpp:380] Convolution5 -> Convolution5
I0927 10:14:38.929329  3315 net.cpp:122] Setting up Convolution5
I0927 10:14:38.929339  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.929342  3315 net.cpp:137] Memory required for data: 111328400
I0927 10:14:38.929347  3315 layer_factory.hpp:77] Creating layer BatchNorm5
I0927 10:14:38.929352  3315 net.cpp:84] Creating Layer BatchNorm5
I0927 10:14:38.929356  3315 net.cpp:406] BatchNorm5 <- Convolution5
I0927 10:14:38.929360  3315 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0927 10:14:38.929479  3315 net.cpp:122] Setting up BatchNorm5
I0927 10:14:38.929484  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.929487  3315 net.cpp:137] Memory required for data: 116346000
I0927 10:14:38.929492  3315 layer_factory.hpp:77] Creating layer Scale5
I0927 10:14:38.929497  3315 net.cpp:84] Creating Layer Scale5
I0927 10:14:38.929499  3315 net.cpp:406] Scale5 <- Convolution5
I0927 10:14:38.929503  3315 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0927 10:14:38.929529  3315 layer_factory.hpp:77] Creating layer Scale5
I0927 10:14:38.929600  3315 net.cpp:122] Setting up Scale5
I0927 10:14:38.929605  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.929606  3315 net.cpp:137] Memory required for data: 121363600
I0927 10:14:38.929610  3315 layer_factory.hpp:77] Creating layer Eltwise2
I0927 10:14:38.929616  3315 net.cpp:84] Creating Layer Eltwise2
I0927 10:14:38.929620  3315 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0927 10:14:38.929622  3315 net.cpp:406] Eltwise2 <- Convolution5
I0927 10:14:38.929625  3315 net.cpp:380] Eltwise2 -> Eltwise2
I0927 10:14:38.929641  3315 net.cpp:122] Setting up Eltwise2
I0927 10:14:38.929644  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.929646  3315 net.cpp:137] Memory required for data: 126381200
I0927 10:14:38.929648  3315 layer_factory.hpp:77] Creating layer penlu5
I0927 10:14:38.929654  3315 net.cpp:84] Creating Layer penlu5
I0927 10:14:38.929657  3315 net.cpp:406] penlu5 <- Eltwise2
I0927 10:14:38.929661  3315 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0927 10:14:38.929759  3315 net.cpp:122] Setting up penlu5
I0927 10:14:38.929764  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.929766  3315 net.cpp:137] Memory required for data: 131398800
I0927 10:14:38.929770  3315 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0927 10:14:38.929783  3315 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0927 10:14:38.929785  3315 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0927 10:14:38.929790  3315 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0927 10:14:38.929795  3315 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0927 10:14:38.929816  3315 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0927 10:14:38.929821  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.929823  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.929826  3315 net.cpp:137] Memory required for data: 141434000
I0927 10:14:38.929828  3315 layer_factory.hpp:77] Creating layer Convolution6
I0927 10:14:38.929834  3315 net.cpp:84] Creating Layer Convolution6
I0927 10:14:38.929837  3315 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0927 10:14:38.929842  3315 net.cpp:380] Convolution6 -> Convolution6
I0927 10:14:38.930678  3315 net.cpp:122] Setting up Convolution6
I0927 10:14:38.930688  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.930692  3315 net.cpp:137] Memory required for data: 146451600
I0927 10:14:38.930696  3315 layer_factory.hpp:77] Creating layer BatchNorm6
I0927 10:14:38.930702  3315 net.cpp:84] Creating Layer BatchNorm6
I0927 10:14:38.930706  3315 net.cpp:406] BatchNorm6 <- Convolution6
I0927 10:14:38.930711  3315 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0927 10:14:38.930832  3315 net.cpp:122] Setting up BatchNorm6
I0927 10:14:38.930837  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.930840  3315 net.cpp:137] Memory required for data: 151469200
I0927 10:14:38.930845  3315 layer_factory.hpp:77] Creating layer Scale6
I0927 10:14:38.930850  3315 net.cpp:84] Creating Layer Scale6
I0927 10:14:38.930853  3315 net.cpp:406] Scale6 <- Convolution6
I0927 10:14:38.930856  3315 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0927 10:14:38.930882  3315 layer_factory.hpp:77] Creating layer Scale6
I0927 10:14:38.930954  3315 net.cpp:122] Setting up Scale6
I0927 10:14:38.930959  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.930963  3315 net.cpp:137] Memory required for data: 156486800
I0927 10:14:38.930966  3315 layer_factory.hpp:77] Creating layer penlu6
I0927 10:14:38.930972  3315 net.cpp:84] Creating Layer penlu6
I0927 10:14:38.930975  3315 net.cpp:406] penlu6 <- Convolution6
I0927 10:14:38.930979  3315 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0927 10:14:38.931076  3315 net.cpp:122] Setting up penlu6
I0927 10:14:38.931080  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.931083  3315 net.cpp:137] Memory required for data: 161504400
I0927 10:14:38.931088  3315 layer_factory.hpp:77] Creating layer Convolution7
I0927 10:14:38.931097  3315 net.cpp:84] Creating Layer Convolution7
I0927 10:14:38.931099  3315 net.cpp:406] Convolution7 <- Convolution6
I0927 10:14:38.931103  3315 net.cpp:380] Convolution7 -> Convolution7
I0927 10:14:38.931622  3315 net.cpp:122] Setting up Convolution7
I0927 10:14:38.931630  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.931634  3315 net.cpp:137] Memory required for data: 166522000
I0927 10:14:38.931638  3315 layer_factory.hpp:77] Creating layer BatchNorm7
I0927 10:14:38.931643  3315 net.cpp:84] Creating Layer BatchNorm7
I0927 10:14:38.931645  3315 net.cpp:406] BatchNorm7 <- Convolution7
I0927 10:14:38.931650  3315 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0927 10:14:38.931771  3315 net.cpp:122] Setting up BatchNorm7
I0927 10:14:38.931777  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.931780  3315 net.cpp:137] Memory required for data: 171539600
I0927 10:14:38.931789  3315 layer_factory.hpp:77] Creating layer Scale7
I0927 10:14:38.931797  3315 net.cpp:84] Creating Layer Scale7
I0927 10:14:38.931799  3315 net.cpp:406] Scale7 <- Convolution7
I0927 10:14:38.931803  3315 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0927 10:14:38.931828  3315 layer_factory.hpp:77] Creating layer Scale7
I0927 10:14:38.931900  3315 net.cpp:122] Setting up Scale7
I0927 10:14:38.931910  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.931913  3315 net.cpp:137] Memory required for data: 176557200
I0927 10:14:38.931917  3315 layer_factory.hpp:77] Creating layer Eltwise3
I0927 10:14:38.931922  3315 net.cpp:84] Creating Layer Eltwise3
I0927 10:14:38.931926  3315 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0927 10:14:38.931929  3315 net.cpp:406] Eltwise3 <- Convolution7
I0927 10:14:38.931933  3315 net.cpp:380] Eltwise3 -> Eltwise3
I0927 10:14:38.931949  3315 net.cpp:122] Setting up Eltwise3
I0927 10:14:38.931953  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.931955  3315 net.cpp:137] Memory required for data: 181574800
I0927 10:14:38.931957  3315 layer_factory.hpp:77] Creating layer penlu7
I0927 10:14:38.931963  3315 net.cpp:84] Creating Layer penlu7
I0927 10:14:38.931967  3315 net.cpp:406] penlu7 <- Eltwise3
I0927 10:14:38.931969  3315 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0927 10:14:38.932070  3315 net.cpp:122] Setting up penlu7
I0927 10:14:38.932076  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.932078  3315 net.cpp:137] Memory required for data: 186592400
I0927 10:14:38.932083  3315 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0927 10:14:38.932087  3315 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0927 10:14:38.932090  3315 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0927 10:14:38.932093  3315 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0927 10:14:38.932098  3315 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0927 10:14:38.932121  3315 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0927 10:14:38.932124  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.932127  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.932130  3315 net.cpp:137] Memory required for data: 196627600
I0927 10:14:38.932132  3315 layer_factory.hpp:77] Creating layer Convolution8
I0927 10:14:38.932138  3315 net.cpp:84] Creating Layer Convolution8
I0927 10:14:38.932142  3315 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0927 10:14:38.932145  3315 net.cpp:380] Convolution8 -> Convolution8
I0927 10:14:38.932976  3315 net.cpp:122] Setting up Convolution8
I0927 10:14:38.932986  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.932989  3315 net.cpp:137] Memory required for data: 201645200
I0927 10:14:38.932993  3315 layer_factory.hpp:77] Creating layer BatchNorm8
I0927 10:14:38.932999  3315 net.cpp:84] Creating Layer BatchNorm8
I0927 10:14:38.933003  3315 net.cpp:406] BatchNorm8 <- Convolution8
I0927 10:14:38.933007  3315 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0927 10:14:38.933130  3315 net.cpp:122] Setting up BatchNorm8
I0927 10:14:38.933135  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.933137  3315 net.cpp:137] Memory required for data: 206662800
I0927 10:14:38.933142  3315 layer_factory.hpp:77] Creating layer Scale8
I0927 10:14:38.933146  3315 net.cpp:84] Creating Layer Scale8
I0927 10:14:38.933149  3315 net.cpp:406] Scale8 <- Convolution8
I0927 10:14:38.933154  3315 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0927 10:14:38.933179  3315 layer_factory.hpp:77] Creating layer Scale8
I0927 10:14:38.933251  3315 net.cpp:122] Setting up Scale8
I0927 10:14:38.933256  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.933259  3315 net.cpp:137] Memory required for data: 211680400
I0927 10:14:38.933262  3315 layer_factory.hpp:77] Creating layer penlu8
I0927 10:14:38.933269  3315 net.cpp:84] Creating Layer penlu8
I0927 10:14:38.933271  3315 net.cpp:406] penlu8 <- Convolution8
I0927 10:14:38.933276  3315 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0927 10:14:38.933374  3315 net.cpp:122] Setting up penlu8
I0927 10:14:38.933379  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.933382  3315 net.cpp:137] Memory required for data: 216698000
I0927 10:14:38.933387  3315 layer_factory.hpp:77] Creating layer Convolution9
I0927 10:14:38.933394  3315 net.cpp:84] Creating Layer Convolution9
I0927 10:14:38.933403  3315 net.cpp:406] Convolution9 <- Convolution8
I0927 10:14:38.933408  3315 net.cpp:380] Convolution9 -> Convolution9
I0927 10:14:38.934269  3315 net.cpp:122] Setting up Convolution9
I0927 10:14:38.934280  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.934284  3315 net.cpp:137] Memory required for data: 221715600
I0927 10:14:38.934288  3315 layer_factory.hpp:77] Creating layer BatchNorm9
I0927 10:14:38.934293  3315 net.cpp:84] Creating Layer BatchNorm9
I0927 10:14:38.934296  3315 net.cpp:406] BatchNorm9 <- Convolution9
I0927 10:14:38.934301  3315 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0927 10:14:38.934429  3315 net.cpp:122] Setting up BatchNorm9
I0927 10:14:38.934434  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.934438  3315 net.cpp:137] Memory required for data: 226733200
I0927 10:14:38.934443  3315 layer_factory.hpp:77] Creating layer Scale9
I0927 10:14:38.934448  3315 net.cpp:84] Creating Layer Scale9
I0927 10:14:38.934451  3315 net.cpp:406] Scale9 <- Convolution9
I0927 10:14:38.934454  3315 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0927 10:14:38.934481  3315 layer_factory.hpp:77] Creating layer Scale9
I0927 10:14:38.934564  3315 net.cpp:122] Setting up Scale9
I0927 10:14:38.934571  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.934573  3315 net.cpp:137] Memory required for data: 231750800
I0927 10:14:38.934577  3315 layer_factory.hpp:77] Creating layer Eltwise4
I0927 10:14:38.934582  3315 net.cpp:84] Creating Layer Eltwise4
I0927 10:14:38.934586  3315 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0927 10:14:38.934588  3315 net.cpp:406] Eltwise4 <- Convolution9
I0927 10:14:38.934593  3315 net.cpp:380] Eltwise4 -> Eltwise4
I0927 10:14:38.934609  3315 net.cpp:122] Setting up Eltwise4
I0927 10:14:38.934614  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.934617  3315 net.cpp:137] Memory required for data: 236768400
I0927 10:14:38.934618  3315 layer_factory.hpp:77] Creating layer penlu9
I0927 10:14:38.934623  3315 net.cpp:84] Creating Layer penlu9
I0927 10:14:38.934628  3315 net.cpp:406] penlu9 <- Eltwise4
I0927 10:14:38.934631  3315 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0927 10:14:38.934736  3315 net.cpp:122] Setting up penlu9
I0927 10:14:38.934741  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.934744  3315 net.cpp:137] Memory required for data: 241786000
I0927 10:14:38.934749  3315 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0927 10:14:38.934753  3315 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0927 10:14:38.934756  3315 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0927 10:14:38.934761  3315 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0927 10:14:38.934764  3315 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0927 10:14:38.934787  3315 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0927 10:14:38.934790  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.934793  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.934797  3315 net.cpp:137] Memory required for data: 251821200
I0927 10:14:38.934798  3315 layer_factory.hpp:77] Creating layer Convolution10
I0927 10:14:38.934804  3315 net.cpp:84] Creating Layer Convolution10
I0927 10:14:38.934808  3315 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0927 10:14:38.934813  3315 net.cpp:380] Convolution10 -> Convolution10
I0927 10:14:38.935781  3315 net.cpp:122] Setting up Convolution10
I0927 10:14:38.935791  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.935794  3315 net.cpp:137] Memory required for data: 256838800
I0927 10:14:38.935798  3315 layer_factory.hpp:77] Creating layer BatchNorm10
I0927 10:14:38.935803  3315 net.cpp:84] Creating Layer BatchNorm10
I0927 10:14:38.935806  3315 net.cpp:406] BatchNorm10 <- Convolution10
I0927 10:14:38.935811  3315 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0927 10:14:38.935935  3315 net.cpp:122] Setting up BatchNorm10
I0927 10:14:38.935947  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.935950  3315 net.cpp:137] Memory required for data: 261856400
I0927 10:14:38.935956  3315 layer_factory.hpp:77] Creating layer Scale10
I0927 10:14:38.935961  3315 net.cpp:84] Creating Layer Scale10
I0927 10:14:38.935963  3315 net.cpp:406] Scale10 <- Convolution10
I0927 10:14:38.935966  3315 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0927 10:14:38.935993  3315 layer_factory.hpp:77] Creating layer Scale10
I0927 10:14:38.936067  3315 net.cpp:122] Setting up Scale10
I0927 10:14:38.936074  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.936076  3315 net.cpp:137] Memory required for data: 266874000
I0927 10:14:38.936080  3315 layer_factory.hpp:77] Creating layer penlu10
I0927 10:14:38.936085  3315 net.cpp:84] Creating Layer penlu10
I0927 10:14:38.936089  3315 net.cpp:406] penlu10 <- Convolution10
I0927 10:14:38.936094  3315 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0927 10:14:38.936194  3315 net.cpp:122] Setting up penlu10
I0927 10:14:38.936200  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.936203  3315 net.cpp:137] Memory required for data: 271891600
I0927 10:14:38.936208  3315 layer_factory.hpp:77] Creating layer Convolution11
I0927 10:14:38.936214  3315 net.cpp:84] Creating Layer Convolution11
I0927 10:14:38.936218  3315 net.cpp:406] Convolution11 <- Convolution10
I0927 10:14:38.936223  3315 net.cpp:380] Convolution11 -> Convolution11
I0927 10:14:38.937117  3315 net.cpp:122] Setting up Convolution11
I0927 10:14:38.937127  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.937130  3315 net.cpp:137] Memory required for data: 276909200
I0927 10:14:38.937134  3315 layer_factory.hpp:77] Creating layer BatchNorm11
I0927 10:14:38.937140  3315 net.cpp:84] Creating Layer BatchNorm11
I0927 10:14:38.937144  3315 net.cpp:406] BatchNorm11 <- Convolution11
I0927 10:14:38.937147  3315 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0927 10:14:38.937275  3315 net.cpp:122] Setting up BatchNorm11
I0927 10:14:38.937281  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.937283  3315 net.cpp:137] Memory required for data: 281926800
I0927 10:14:38.937288  3315 layer_factory.hpp:77] Creating layer Scale11
I0927 10:14:38.937292  3315 net.cpp:84] Creating Layer Scale11
I0927 10:14:38.937295  3315 net.cpp:406] Scale11 <- Convolution11
I0927 10:14:38.937300  3315 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0927 10:14:38.937326  3315 layer_factory.hpp:77] Creating layer Scale11
I0927 10:14:38.937402  3315 net.cpp:122] Setting up Scale11
I0927 10:14:38.937407  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.937410  3315 net.cpp:137] Memory required for data: 286944400
I0927 10:14:38.937414  3315 layer_factory.hpp:77] Creating layer Eltwise5
I0927 10:14:38.937419  3315 net.cpp:84] Creating Layer Eltwise5
I0927 10:14:38.937423  3315 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0927 10:14:38.937427  3315 net.cpp:406] Eltwise5 <- Convolution11
I0927 10:14:38.937430  3315 net.cpp:380] Eltwise5 -> Eltwise5
I0927 10:14:38.937448  3315 net.cpp:122] Setting up Eltwise5
I0927 10:14:38.937453  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.937454  3315 net.cpp:137] Memory required for data: 291962000
I0927 10:14:38.937456  3315 layer_factory.hpp:77] Creating layer penlu11
I0927 10:14:38.937461  3315 net.cpp:84] Creating Layer penlu11
I0927 10:14:38.937465  3315 net.cpp:406] penlu11 <- Eltwise5
I0927 10:14:38.937469  3315 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0927 10:14:38.937577  3315 net.cpp:122] Setting up penlu11
I0927 10:14:38.937583  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.937587  3315 net.cpp:137] Memory required for data: 296979600
I0927 10:14:38.937590  3315 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0927 10:14:38.937597  3315 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0927 10:14:38.937599  3315 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0927 10:14:38.937609  3315 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0927 10:14:38.937614  3315 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0927 10:14:38.937638  3315 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0927 10:14:38.937644  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.937646  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.937649  3315 net.cpp:137] Memory required for data: 307014800
I0927 10:14:38.937651  3315 layer_factory.hpp:77] Creating layer Convolution12
I0927 10:14:38.937657  3315 net.cpp:84] Creating Layer Convolution12
I0927 10:14:38.937660  3315 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0927 10:14:38.937665  3315 net.cpp:380] Convolution12 -> Convolution12
I0927 10:14:38.938549  3315 net.cpp:122] Setting up Convolution12
I0927 10:14:38.938560  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.938563  3315 net.cpp:137] Memory required for data: 312032400
I0927 10:14:38.938568  3315 layer_factory.hpp:77] Creating layer BatchNorm12
I0927 10:14:38.938575  3315 net.cpp:84] Creating Layer BatchNorm12
I0927 10:14:38.938578  3315 net.cpp:406] BatchNorm12 <- Convolution12
I0927 10:14:38.938582  3315 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0927 10:14:38.938710  3315 net.cpp:122] Setting up BatchNorm12
I0927 10:14:38.938716  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.938719  3315 net.cpp:137] Memory required for data: 317050000
I0927 10:14:38.938724  3315 layer_factory.hpp:77] Creating layer Scale12
I0927 10:14:38.938730  3315 net.cpp:84] Creating Layer Scale12
I0927 10:14:38.938732  3315 net.cpp:406] Scale12 <- Convolution12
I0927 10:14:38.938735  3315 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0927 10:14:38.938765  3315 layer_factory.hpp:77] Creating layer Scale12
I0927 10:14:38.938840  3315 net.cpp:122] Setting up Scale12
I0927 10:14:38.938846  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.938849  3315 net.cpp:137] Memory required for data: 322067600
I0927 10:14:38.938853  3315 layer_factory.hpp:77] Creating layer penlu12
I0927 10:14:38.938859  3315 net.cpp:84] Creating Layer penlu12
I0927 10:14:38.938863  3315 net.cpp:406] penlu12 <- Convolution12
I0927 10:14:38.938868  3315 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0927 10:14:38.938973  3315 net.cpp:122] Setting up penlu12
I0927 10:14:38.938978  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.938982  3315 net.cpp:137] Memory required for data: 327085200
I0927 10:14:38.938987  3315 layer_factory.hpp:77] Creating layer Convolution13
I0927 10:14:38.938995  3315 net.cpp:84] Creating Layer Convolution13
I0927 10:14:38.938998  3315 net.cpp:406] Convolution13 <- Convolution12
I0927 10:14:38.939002  3315 net.cpp:380] Convolution13 -> Convolution13
I0927 10:14:38.939879  3315 net.cpp:122] Setting up Convolution13
I0927 10:14:38.939889  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.939893  3315 net.cpp:137] Memory required for data: 332102800
I0927 10:14:38.939898  3315 layer_factory.hpp:77] Creating layer BatchNorm13
I0927 10:14:38.939904  3315 net.cpp:84] Creating Layer BatchNorm13
I0927 10:14:38.939908  3315 net.cpp:406] BatchNorm13 <- Convolution13
I0927 10:14:38.939911  3315 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0927 10:14:38.940039  3315 net.cpp:122] Setting up BatchNorm13
I0927 10:14:38.940044  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.940047  3315 net.cpp:137] Memory required for data: 337120400
I0927 10:14:38.940052  3315 layer_factory.hpp:77] Creating layer Scale13
I0927 10:14:38.940057  3315 net.cpp:84] Creating Layer Scale13
I0927 10:14:38.940060  3315 net.cpp:406] Scale13 <- Convolution13
I0927 10:14:38.940063  3315 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0927 10:14:38.940091  3315 layer_factory.hpp:77] Creating layer Scale13
I0927 10:14:38.940167  3315 net.cpp:122] Setting up Scale13
I0927 10:14:38.940173  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.940182  3315 net.cpp:137] Memory required for data: 342138000
I0927 10:14:38.940186  3315 layer_factory.hpp:77] Creating layer Eltwise6
I0927 10:14:38.940191  3315 net.cpp:84] Creating Layer Eltwise6
I0927 10:14:38.940196  3315 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0927 10:14:38.940198  3315 net.cpp:406] Eltwise6 <- Convolution13
I0927 10:14:38.940201  3315 net.cpp:380] Eltwise6 -> Eltwise6
I0927 10:14:38.940220  3315 net.cpp:122] Setting up Eltwise6
I0927 10:14:38.940227  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.940229  3315 net.cpp:137] Memory required for data: 347155600
I0927 10:14:38.940232  3315 layer_factory.hpp:77] Creating layer penlu13
I0927 10:14:38.940239  3315 net.cpp:84] Creating Layer penlu13
I0927 10:14:38.940243  3315 net.cpp:406] penlu13 <- Eltwise6
I0927 10:14:38.940248  3315 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0927 10:14:38.940356  3315 net.cpp:122] Setting up penlu13
I0927 10:14:38.940362  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.940366  3315 net.cpp:137] Memory required for data: 352173200
I0927 10:14:38.940378  3315 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0927 10:14:38.940383  3315 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0927 10:14:38.940387  3315 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0927 10:14:38.940390  3315 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0927 10:14:38.940397  3315 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0927 10:14:38.940420  3315 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0927 10:14:38.940425  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.940429  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.940433  3315 net.cpp:137] Memory required for data: 362208400
I0927 10:14:38.940434  3315 layer_factory.hpp:77] Creating layer Convolution14
I0927 10:14:38.940440  3315 net.cpp:84] Creating Layer Convolution14
I0927 10:14:38.940443  3315 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0927 10:14:38.940448  3315 net.cpp:380] Convolution14 -> Convolution14
I0927 10:14:38.941328  3315 net.cpp:122] Setting up Convolution14
I0927 10:14:38.941335  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.941339  3315 net.cpp:137] Memory required for data: 367226000
I0927 10:14:38.941342  3315 layer_factory.hpp:77] Creating layer BatchNorm14
I0927 10:14:38.941347  3315 net.cpp:84] Creating Layer BatchNorm14
I0927 10:14:38.941350  3315 net.cpp:406] BatchNorm14 <- Convolution14
I0927 10:14:38.941354  3315 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0927 10:14:38.941484  3315 net.cpp:122] Setting up BatchNorm14
I0927 10:14:38.941489  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.941491  3315 net.cpp:137] Memory required for data: 372243600
I0927 10:14:38.941496  3315 layer_factory.hpp:77] Creating layer Scale14
I0927 10:14:38.941500  3315 net.cpp:84] Creating Layer Scale14
I0927 10:14:38.941503  3315 net.cpp:406] Scale14 <- Convolution14
I0927 10:14:38.941505  3315 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0927 10:14:38.941531  3315 layer_factory.hpp:77] Creating layer Scale14
I0927 10:14:38.941606  3315 net.cpp:122] Setting up Scale14
I0927 10:14:38.941612  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.941613  3315 net.cpp:137] Memory required for data: 377261200
I0927 10:14:38.941617  3315 layer_factory.hpp:77] Creating layer penlu14
I0927 10:14:38.941622  3315 net.cpp:84] Creating Layer penlu14
I0927 10:14:38.941624  3315 net.cpp:406] penlu14 <- Convolution14
I0927 10:14:38.941629  3315 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0927 10:14:38.941736  3315 net.cpp:122] Setting up penlu14
I0927 10:14:38.941741  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.941743  3315 net.cpp:137] Memory required for data: 382278800
I0927 10:14:38.941747  3315 layer_factory.hpp:77] Creating layer Convolution15
I0927 10:14:38.941753  3315 net.cpp:84] Creating Layer Convolution15
I0927 10:14:38.941762  3315 net.cpp:406] Convolution15 <- Convolution14
I0927 10:14:38.941767  3315 net.cpp:380] Convolution15 -> Convolution15
I0927 10:14:38.942651  3315 net.cpp:122] Setting up Convolution15
I0927 10:14:38.942659  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.942662  3315 net.cpp:137] Memory required for data: 387296400
I0927 10:14:38.942667  3315 layer_factory.hpp:77] Creating layer BatchNorm15
I0927 10:14:38.942672  3315 net.cpp:84] Creating Layer BatchNorm15
I0927 10:14:38.942674  3315 net.cpp:406] BatchNorm15 <- Convolution15
I0927 10:14:38.942678  3315 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0927 10:14:38.942806  3315 net.cpp:122] Setting up BatchNorm15
I0927 10:14:38.942811  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.942812  3315 net.cpp:137] Memory required for data: 392314000
I0927 10:14:38.942817  3315 layer_factory.hpp:77] Creating layer Scale15
I0927 10:14:38.942821  3315 net.cpp:84] Creating Layer Scale15
I0927 10:14:38.942823  3315 net.cpp:406] Scale15 <- Convolution15
I0927 10:14:38.942826  3315 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0927 10:14:38.942852  3315 layer_factory.hpp:77] Creating layer Scale15
I0927 10:14:38.942924  3315 net.cpp:122] Setting up Scale15
I0927 10:14:38.942929  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.942930  3315 net.cpp:137] Memory required for data: 397331600
I0927 10:14:38.942934  3315 layer_factory.hpp:77] Creating layer Eltwise7
I0927 10:14:38.942939  3315 net.cpp:84] Creating Layer Eltwise7
I0927 10:14:38.942940  3315 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0927 10:14:38.942944  3315 net.cpp:406] Eltwise7 <- Convolution15
I0927 10:14:38.942946  3315 net.cpp:380] Eltwise7 -> Eltwise7
I0927 10:14:38.942961  3315 net.cpp:122] Setting up Eltwise7
I0927 10:14:38.942965  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.942967  3315 net.cpp:137] Memory required for data: 402349200
I0927 10:14:38.942970  3315 layer_factory.hpp:77] Creating layer penlu15
I0927 10:14:38.942975  3315 net.cpp:84] Creating Layer penlu15
I0927 10:14:38.942976  3315 net.cpp:406] penlu15 <- Eltwise7
I0927 10:14:38.942981  3315 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0927 10:14:38.943084  3315 net.cpp:122] Setting up penlu15
I0927 10:14:38.943089  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.943090  3315 net.cpp:137] Memory required for data: 407366800
I0927 10:14:38.943094  3315 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0927 10:14:38.943099  3315 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0927 10:14:38.943101  3315 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0927 10:14:38.943104  3315 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0927 10:14:38.943109  3315 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0927 10:14:38.943128  3315 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0927 10:14:38.943132  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.943135  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.943137  3315 net.cpp:137] Memory required for data: 417402000
I0927 10:14:38.943140  3315 layer_factory.hpp:77] Creating layer Convolution16
I0927 10:14:38.943145  3315 net.cpp:84] Creating Layer Convolution16
I0927 10:14:38.943146  3315 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0927 10:14:38.943151  3315 net.cpp:380] Convolution16 -> Convolution16
I0927 10:14:38.944001  3315 net.cpp:122] Setting up Convolution16
I0927 10:14:38.944010  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.944012  3315 net.cpp:137] Memory required for data: 422419600
I0927 10:14:38.944016  3315 layer_factory.hpp:77] Creating layer BatchNorm16
I0927 10:14:38.944021  3315 net.cpp:84] Creating Layer BatchNorm16
I0927 10:14:38.944025  3315 net.cpp:406] BatchNorm16 <- Convolution16
I0927 10:14:38.944027  3315 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0927 10:14:38.944154  3315 net.cpp:122] Setting up BatchNorm16
I0927 10:14:38.944165  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.944167  3315 net.cpp:137] Memory required for data: 427437200
I0927 10:14:38.944172  3315 layer_factory.hpp:77] Creating layer Scale16
I0927 10:14:38.944176  3315 net.cpp:84] Creating Layer Scale16
I0927 10:14:38.944178  3315 net.cpp:406] Scale16 <- Convolution16
I0927 10:14:38.944182  3315 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0927 10:14:38.944209  3315 layer_factory.hpp:77] Creating layer Scale16
I0927 10:14:38.944283  3315 net.cpp:122] Setting up Scale16
I0927 10:14:38.944286  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.944288  3315 net.cpp:137] Memory required for data: 432454800
I0927 10:14:38.944293  3315 layer_factory.hpp:77] Creating layer penlu16
I0927 10:14:38.944298  3315 net.cpp:84] Creating Layer penlu16
I0927 10:14:38.944299  3315 net.cpp:406] penlu16 <- Convolution16
I0927 10:14:38.944303  3315 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0927 10:14:38.944411  3315 net.cpp:122] Setting up penlu16
I0927 10:14:38.944416  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.944417  3315 net.cpp:137] Memory required for data: 437472400
I0927 10:14:38.944422  3315 layer_factory.hpp:77] Creating layer Convolution17
I0927 10:14:38.944428  3315 net.cpp:84] Creating Layer Convolution17
I0927 10:14:38.944432  3315 net.cpp:406] Convolution17 <- Convolution16
I0927 10:14:38.944434  3315 net.cpp:380] Convolution17 -> Convolution17
I0927 10:14:38.944978  3315 net.cpp:122] Setting up Convolution17
I0927 10:14:38.944986  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.944988  3315 net.cpp:137] Memory required for data: 442490000
I0927 10:14:38.944993  3315 layer_factory.hpp:77] Creating layer BatchNorm17
I0927 10:14:38.944998  3315 net.cpp:84] Creating Layer BatchNorm17
I0927 10:14:38.944999  3315 net.cpp:406] BatchNorm17 <- Convolution17
I0927 10:14:38.945003  3315 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0927 10:14:38.945130  3315 net.cpp:122] Setting up BatchNorm17
I0927 10:14:38.945134  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.945137  3315 net.cpp:137] Memory required for data: 447507600
I0927 10:14:38.945142  3315 layer_factory.hpp:77] Creating layer Scale17
I0927 10:14:38.945144  3315 net.cpp:84] Creating Layer Scale17
I0927 10:14:38.945147  3315 net.cpp:406] Scale17 <- Convolution17
I0927 10:14:38.945150  3315 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0927 10:14:38.945175  3315 layer_factory.hpp:77] Creating layer Scale17
I0927 10:14:38.945269  3315 net.cpp:122] Setting up Scale17
I0927 10:14:38.945273  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.945276  3315 net.cpp:137] Memory required for data: 452525200
I0927 10:14:38.945279  3315 layer_factory.hpp:77] Creating layer Eltwise8
I0927 10:14:38.945282  3315 net.cpp:84] Creating Layer Eltwise8
I0927 10:14:38.945286  3315 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0927 10:14:38.945287  3315 net.cpp:406] Eltwise8 <- Convolution17
I0927 10:14:38.945291  3315 net.cpp:380] Eltwise8 -> Eltwise8
I0927 10:14:38.945305  3315 net.cpp:122] Setting up Eltwise8
I0927 10:14:38.945309  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.945312  3315 net.cpp:137] Memory required for data: 457542800
I0927 10:14:38.945313  3315 layer_factory.hpp:77] Creating layer penlu17
I0927 10:14:38.945318  3315 net.cpp:84] Creating Layer penlu17
I0927 10:14:38.945320  3315 net.cpp:406] penlu17 <- Eltwise8
I0927 10:14:38.945324  3315 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0927 10:14:38.945428  3315 net.cpp:122] Setting up penlu17
I0927 10:14:38.945432  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.945435  3315 net.cpp:137] Memory required for data: 462560400
I0927 10:14:38.945439  3315 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0927 10:14:38.945442  3315 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0927 10:14:38.945444  3315 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0927 10:14:38.945453  3315 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0927 10:14:38.945457  3315 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0927 10:14:38.945480  3315 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0927 10:14:38.945484  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.945487  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.945488  3315 net.cpp:137] Memory required for data: 472595600
I0927 10:14:38.945490  3315 layer_factory.hpp:77] Creating layer Convolution18
I0927 10:14:38.945497  3315 net.cpp:84] Creating Layer Convolution18
I0927 10:14:38.945498  3315 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0927 10:14:38.945503  3315 net.cpp:380] Convolution18 -> Convolution18
I0927 10:14:38.946358  3315 net.cpp:122] Setting up Convolution18
I0927 10:14:38.946368  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.946370  3315 net.cpp:137] Memory required for data: 477613200
I0927 10:14:38.946374  3315 layer_factory.hpp:77] Creating layer BatchNorm18
I0927 10:14:38.946379  3315 net.cpp:84] Creating Layer BatchNorm18
I0927 10:14:38.946382  3315 net.cpp:406] BatchNorm18 <- Convolution18
I0927 10:14:38.946386  3315 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0927 10:14:38.946512  3315 net.cpp:122] Setting up BatchNorm18
I0927 10:14:38.946517  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.946519  3315 net.cpp:137] Memory required for data: 482630800
I0927 10:14:38.946539  3315 layer_factory.hpp:77] Creating layer Scale18
I0927 10:14:38.946543  3315 net.cpp:84] Creating Layer Scale18
I0927 10:14:38.946547  3315 net.cpp:406] Scale18 <- Convolution18
I0927 10:14:38.946550  3315 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0927 10:14:38.946584  3315 layer_factory.hpp:77] Creating layer Scale18
I0927 10:14:38.946662  3315 net.cpp:122] Setting up Scale18
I0927 10:14:38.946667  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.946669  3315 net.cpp:137] Memory required for data: 487648400
I0927 10:14:38.946672  3315 layer_factory.hpp:77] Creating layer penlu18
I0927 10:14:38.946678  3315 net.cpp:84] Creating Layer penlu18
I0927 10:14:38.946681  3315 net.cpp:406] penlu18 <- Convolution18
I0927 10:14:38.946684  3315 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0927 10:14:38.946787  3315 net.cpp:122] Setting up penlu18
I0927 10:14:38.946792  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.946794  3315 net.cpp:137] Memory required for data: 492666000
I0927 10:14:38.946799  3315 layer_factory.hpp:77] Creating layer Convolution19
I0927 10:14:38.946805  3315 net.cpp:84] Creating Layer Convolution19
I0927 10:14:38.946807  3315 net.cpp:406] Convolution19 <- Convolution18
I0927 10:14:38.946811  3315 net.cpp:380] Convolution19 -> Convolution19
I0927 10:14:38.947676  3315 net.cpp:122] Setting up Convolution19
I0927 10:14:38.947685  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.947687  3315 net.cpp:137] Memory required for data: 497683600
I0927 10:14:38.947692  3315 layer_factory.hpp:77] Creating layer BatchNorm19
I0927 10:14:38.947697  3315 net.cpp:84] Creating Layer BatchNorm19
I0927 10:14:38.947700  3315 net.cpp:406] BatchNorm19 <- Convolution19
I0927 10:14:38.947705  3315 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0927 10:14:38.947831  3315 net.cpp:122] Setting up BatchNorm19
I0927 10:14:38.947835  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.947839  3315 net.cpp:137] Memory required for data: 502701200
I0927 10:14:38.947842  3315 layer_factory.hpp:77] Creating layer Scale19
I0927 10:14:38.947846  3315 net.cpp:84] Creating Layer Scale19
I0927 10:14:38.947849  3315 net.cpp:406] Scale19 <- Convolution19
I0927 10:14:38.947851  3315 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0927 10:14:38.947877  3315 layer_factory.hpp:77] Creating layer Scale19
I0927 10:14:38.947952  3315 net.cpp:122] Setting up Scale19
I0927 10:14:38.947955  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.947963  3315 net.cpp:137] Memory required for data: 507718800
I0927 10:14:38.947968  3315 layer_factory.hpp:77] Creating layer Eltwise9
I0927 10:14:38.947971  3315 net.cpp:84] Creating Layer Eltwise9
I0927 10:14:38.947974  3315 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0927 10:14:38.947978  3315 net.cpp:406] Eltwise9 <- Convolution19
I0927 10:14:38.947980  3315 net.cpp:380] Eltwise9 -> Eltwise9
I0927 10:14:38.947998  3315 net.cpp:122] Setting up Eltwise9
I0927 10:14:38.948001  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.948004  3315 net.cpp:137] Memory required for data: 512736400
I0927 10:14:38.948005  3315 layer_factory.hpp:77] Creating layer penlu19
I0927 10:14:38.948010  3315 net.cpp:84] Creating Layer penlu19
I0927 10:14:38.948012  3315 net.cpp:406] penlu19 <- Eltwise9
I0927 10:14:38.948016  3315 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0927 10:14:38.948122  3315 net.cpp:122] Setting up penlu19
I0927 10:14:38.948127  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.948129  3315 net.cpp:137] Memory required for data: 517754000
I0927 10:14:38.948133  3315 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0927 10:14:38.948137  3315 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0927 10:14:38.948139  3315 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0927 10:14:38.948143  3315 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0927 10:14:38.948146  3315 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0927 10:14:38.948168  3315 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0927 10:14:38.948173  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.948174  3315 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0927 10:14:38.948176  3315 net.cpp:137] Memory required for data: 527789200
I0927 10:14:38.948179  3315 layer_factory.hpp:77] Creating layer Convolution20
I0927 10:14:38.948184  3315 net.cpp:84] Creating Layer Convolution20
I0927 10:14:38.948186  3315 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0927 10:14:38.948191  3315 net.cpp:380] Convolution20 -> Convolution20
I0927 10:14:38.949355  3315 net.cpp:122] Setting up Convolution20
I0927 10:14:38.949364  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.949368  3315 net.cpp:137] Memory required for data: 530298000
I0927 10:14:38.949371  3315 layer_factory.hpp:77] Creating layer BatchNorm20
I0927 10:14:38.949378  3315 net.cpp:84] Creating Layer BatchNorm20
I0927 10:14:38.949379  3315 net.cpp:406] BatchNorm20 <- Convolution20
I0927 10:14:38.949383  3315 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0927 10:14:38.949519  3315 net.cpp:122] Setting up BatchNorm20
I0927 10:14:38.949524  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.949527  3315 net.cpp:137] Memory required for data: 532806800
I0927 10:14:38.949532  3315 layer_factory.hpp:77] Creating layer Scale20
I0927 10:14:38.949537  3315 net.cpp:84] Creating Layer Scale20
I0927 10:14:38.949538  3315 net.cpp:406] Scale20 <- Convolution20
I0927 10:14:38.949542  3315 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0927 10:14:38.949568  3315 layer_factory.hpp:77] Creating layer Scale20
I0927 10:14:38.949642  3315 net.cpp:122] Setting up Scale20
I0927 10:14:38.949646  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.949648  3315 net.cpp:137] Memory required for data: 535315600
I0927 10:14:38.949652  3315 layer_factory.hpp:77] Creating layer Convolution21
I0927 10:14:38.949659  3315 net.cpp:84] Creating Layer Convolution21
I0927 10:14:38.949661  3315 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0927 10:14:38.949666  3315 net.cpp:380] Convolution21 -> Convolution21
I0927 10:14:38.951334  3315 net.cpp:122] Setting up Convolution21
I0927 10:14:38.951344  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.951346  3315 net.cpp:137] Memory required for data: 537824400
I0927 10:14:38.951351  3315 layer_factory.hpp:77] Creating layer BatchNorm21
I0927 10:14:38.951356  3315 net.cpp:84] Creating Layer BatchNorm21
I0927 10:14:38.951366  3315 net.cpp:406] BatchNorm21 <- Convolution21
I0927 10:14:38.951370  3315 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0927 10:14:38.951508  3315 net.cpp:122] Setting up BatchNorm21
I0927 10:14:38.951511  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.951514  3315 net.cpp:137] Memory required for data: 540333200
I0927 10:14:38.951519  3315 layer_factory.hpp:77] Creating layer Scale21
I0927 10:14:38.951524  3315 net.cpp:84] Creating Layer Scale21
I0927 10:14:38.951525  3315 net.cpp:406] Scale21 <- Convolution21
I0927 10:14:38.951529  3315 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0927 10:14:38.951556  3315 layer_factory.hpp:77] Creating layer Scale21
I0927 10:14:38.951673  3315 net.cpp:122] Setting up Scale21
I0927 10:14:38.951678  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.951680  3315 net.cpp:137] Memory required for data: 542842000
I0927 10:14:38.951684  3315 layer_factory.hpp:77] Creating layer penlu20
I0927 10:14:38.951689  3315 net.cpp:84] Creating Layer penlu20
I0927 10:14:38.951691  3315 net.cpp:406] penlu20 <- Convolution21
I0927 10:14:38.951696  3315 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0927 10:14:38.951812  3315 net.cpp:122] Setting up penlu20
I0927 10:14:38.951817  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.951818  3315 net.cpp:137] Memory required for data: 545350800
I0927 10:14:38.951823  3315 layer_factory.hpp:77] Creating layer Convolution22
I0927 10:14:38.951829  3315 net.cpp:84] Creating Layer Convolution22
I0927 10:14:38.951833  3315 net.cpp:406] Convolution22 <- Convolution21
I0927 10:14:38.951835  3315 net.cpp:380] Convolution22 -> Convolution22
I0927 10:14:38.952886  3315 net.cpp:122] Setting up Convolution22
I0927 10:14:38.952895  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.952898  3315 net.cpp:137] Memory required for data: 547859600
I0927 10:14:38.952903  3315 layer_factory.hpp:77] Creating layer BatchNorm22
I0927 10:14:38.952908  3315 net.cpp:84] Creating Layer BatchNorm22
I0927 10:14:38.952910  3315 net.cpp:406] BatchNorm22 <- Convolution22
I0927 10:14:38.952914  3315 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0927 10:14:38.953044  3315 net.cpp:122] Setting up BatchNorm22
I0927 10:14:38.953048  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.953050  3315 net.cpp:137] Memory required for data: 550368400
I0927 10:14:38.953055  3315 layer_factory.hpp:77] Creating layer Scale22
I0927 10:14:38.953060  3315 net.cpp:84] Creating Layer Scale22
I0927 10:14:38.953063  3315 net.cpp:406] Scale22 <- Convolution22
I0927 10:14:38.953065  3315 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0927 10:14:38.953091  3315 layer_factory.hpp:77] Creating layer Scale22
I0927 10:14:38.953164  3315 net.cpp:122] Setting up Scale22
I0927 10:14:38.953168  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.953171  3315 net.cpp:137] Memory required for data: 552877200
I0927 10:14:38.953174  3315 layer_factory.hpp:77] Creating layer Eltwise10
I0927 10:14:38.953177  3315 net.cpp:84] Creating Layer Eltwise10
I0927 10:14:38.953181  3315 net.cpp:406] Eltwise10 <- Convolution20
I0927 10:14:38.953182  3315 net.cpp:406] Eltwise10 <- Convolution22
I0927 10:14:38.953186  3315 net.cpp:380] Eltwise10 -> Eltwise10
I0927 10:14:38.953202  3315 net.cpp:122] Setting up Eltwise10
I0927 10:14:38.953205  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.953207  3315 net.cpp:137] Memory required for data: 555386000
I0927 10:14:38.953209  3315 layer_factory.hpp:77] Creating layer penlu21
I0927 10:14:38.953214  3315 net.cpp:84] Creating Layer penlu21
I0927 10:14:38.953217  3315 net.cpp:406] penlu21 <- Eltwise10
I0927 10:14:38.953220  3315 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0927 10:14:38.953342  3315 net.cpp:122] Setting up penlu21
I0927 10:14:38.953346  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.953348  3315 net.cpp:137] Memory required for data: 557894800
I0927 10:14:38.953353  3315 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0927 10:14:38.953363  3315 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0927 10:14:38.953366  3315 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0927 10:14:38.953369  3315 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0927 10:14:38.953374  3315 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0927 10:14:38.953397  3315 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0927 10:14:38.953402  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.953403  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.953405  3315 net.cpp:137] Memory required for data: 562912400
I0927 10:14:38.953408  3315 layer_factory.hpp:77] Creating layer Convolution23
I0927 10:14:38.953414  3315 net.cpp:84] Creating Layer Convolution23
I0927 10:14:38.953416  3315 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0927 10:14:38.953420  3315 net.cpp:380] Convolution23 -> Convolution23
I0927 10:14:38.954762  3315 net.cpp:122] Setting up Convolution23
I0927 10:14:38.954771  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.954773  3315 net.cpp:137] Memory required for data: 565421200
I0927 10:14:38.954778  3315 layer_factory.hpp:77] Creating layer BatchNorm23
I0927 10:14:38.954782  3315 net.cpp:84] Creating Layer BatchNorm23
I0927 10:14:38.954784  3315 net.cpp:406] BatchNorm23 <- Convolution23
I0927 10:14:38.954789  3315 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0927 10:14:38.954923  3315 net.cpp:122] Setting up BatchNorm23
I0927 10:14:38.954927  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.954931  3315 net.cpp:137] Memory required for data: 567930000
I0927 10:14:38.954936  3315 layer_factory.hpp:77] Creating layer Scale23
I0927 10:14:38.954939  3315 net.cpp:84] Creating Layer Scale23
I0927 10:14:38.954941  3315 net.cpp:406] Scale23 <- Convolution23
I0927 10:14:38.954946  3315 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0927 10:14:38.954972  3315 layer_factory.hpp:77] Creating layer Scale23
I0927 10:14:38.955046  3315 net.cpp:122] Setting up Scale23
I0927 10:14:38.955050  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.955052  3315 net.cpp:137] Memory required for data: 570438800
I0927 10:14:38.955056  3315 layer_factory.hpp:77] Creating layer penlu22
I0927 10:14:38.955061  3315 net.cpp:84] Creating Layer penlu22
I0927 10:14:38.955065  3315 net.cpp:406] penlu22 <- Convolution23
I0927 10:14:38.955068  3315 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0927 10:14:38.955170  3315 net.cpp:122] Setting up penlu22
I0927 10:14:38.955175  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.955178  3315 net.cpp:137] Memory required for data: 572947600
I0927 10:14:38.955183  3315 layer_factory.hpp:77] Creating layer Convolution24
I0927 10:14:38.955188  3315 net.cpp:84] Creating Layer Convolution24
I0927 10:14:38.955191  3315 net.cpp:406] Convolution24 <- Convolution23
I0927 10:14:38.955194  3315 net.cpp:380] Convolution24 -> Convolution24
I0927 10:14:38.956218  3315 net.cpp:122] Setting up Convolution24
I0927 10:14:38.956226  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.956229  3315 net.cpp:137] Memory required for data: 575456400
I0927 10:14:38.956233  3315 layer_factory.hpp:77] Creating layer BatchNorm24
I0927 10:14:38.956238  3315 net.cpp:84] Creating Layer BatchNorm24
I0927 10:14:38.956239  3315 net.cpp:406] BatchNorm24 <- Convolution24
I0927 10:14:38.956244  3315 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0927 10:14:38.956377  3315 net.cpp:122] Setting up BatchNorm24
I0927 10:14:38.956382  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.956383  3315 net.cpp:137] Memory required for data: 577965200
I0927 10:14:38.956387  3315 layer_factory.hpp:77] Creating layer Scale24
I0927 10:14:38.956392  3315 net.cpp:84] Creating Layer Scale24
I0927 10:14:38.956394  3315 net.cpp:406] Scale24 <- Convolution24
I0927 10:14:38.956398  3315 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0927 10:14:38.956430  3315 layer_factory.hpp:77] Creating layer Scale24
I0927 10:14:38.956506  3315 net.cpp:122] Setting up Scale24
I0927 10:14:38.956511  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.956512  3315 net.cpp:137] Memory required for data: 580474000
I0927 10:14:38.956516  3315 layer_factory.hpp:77] Creating layer Eltwise11
I0927 10:14:38.956519  3315 net.cpp:84] Creating Layer Eltwise11
I0927 10:14:38.956522  3315 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0927 10:14:38.956524  3315 net.cpp:406] Eltwise11 <- Convolution24
I0927 10:14:38.956529  3315 net.cpp:380] Eltwise11 -> Eltwise11
I0927 10:14:38.956544  3315 net.cpp:122] Setting up Eltwise11
I0927 10:14:38.956548  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.956550  3315 net.cpp:137] Memory required for data: 582982800
I0927 10:14:38.956552  3315 layer_factory.hpp:77] Creating layer penlu23
I0927 10:14:38.956557  3315 net.cpp:84] Creating Layer penlu23
I0927 10:14:38.956559  3315 net.cpp:406] penlu23 <- Eltwise11
I0927 10:14:38.956563  3315 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0927 10:14:38.956668  3315 net.cpp:122] Setting up penlu23
I0927 10:14:38.956673  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.956676  3315 net.cpp:137] Memory required for data: 585491600
I0927 10:14:38.956679  3315 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0927 10:14:38.956683  3315 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0927 10:14:38.956686  3315 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0927 10:14:38.956688  3315 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0927 10:14:38.956692  3315 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0927 10:14:38.956715  3315 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0927 10:14:38.956719  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.956722  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.956724  3315 net.cpp:137] Memory required for data: 590509200
I0927 10:14:38.956727  3315 layer_factory.hpp:77] Creating layer Convolution25
I0927 10:14:38.956732  3315 net.cpp:84] Creating Layer Convolution25
I0927 10:14:38.956735  3315 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0927 10:14:38.956739  3315 net.cpp:380] Convolution25 -> Convolution25
I0927 10:14:38.957759  3315 net.cpp:122] Setting up Convolution25
I0927 10:14:38.957768  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.957770  3315 net.cpp:137] Memory required for data: 593018000
I0927 10:14:38.957774  3315 layer_factory.hpp:77] Creating layer BatchNorm25
I0927 10:14:38.957779  3315 net.cpp:84] Creating Layer BatchNorm25
I0927 10:14:38.957782  3315 net.cpp:406] BatchNorm25 <- Convolution25
I0927 10:14:38.957787  3315 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0927 10:14:38.957918  3315 net.cpp:122] Setting up BatchNorm25
I0927 10:14:38.957922  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.957924  3315 net.cpp:137] Memory required for data: 595526800
I0927 10:14:38.957929  3315 layer_factory.hpp:77] Creating layer Scale25
I0927 10:14:38.957933  3315 net.cpp:84] Creating Layer Scale25
I0927 10:14:38.957936  3315 net.cpp:406] Scale25 <- Convolution25
I0927 10:14:38.957938  3315 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0927 10:14:38.957965  3315 layer_factory.hpp:77] Creating layer Scale25
I0927 10:14:38.958039  3315 net.cpp:122] Setting up Scale25
I0927 10:14:38.958045  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.958046  3315 net.cpp:137] Memory required for data: 598035600
I0927 10:14:38.958050  3315 layer_factory.hpp:77] Creating layer penlu24
I0927 10:14:38.958055  3315 net.cpp:84] Creating Layer penlu24
I0927 10:14:38.958056  3315 net.cpp:406] penlu24 <- Convolution25
I0927 10:14:38.958060  3315 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0927 10:14:38.958165  3315 net.cpp:122] Setting up penlu24
I0927 10:14:38.958170  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.958178  3315 net.cpp:137] Memory required for data: 600544400
I0927 10:14:38.958184  3315 layer_factory.hpp:77] Creating layer Convolution26
I0927 10:14:38.958190  3315 net.cpp:84] Creating Layer Convolution26
I0927 10:14:38.958192  3315 net.cpp:406] Convolution26 <- Convolution25
I0927 10:14:38.958196  3315 net.cpp:380] Convolution26 -> Convolution26
I0927 10:14:38.959244  3315 net.cpp:122] Setting up Convolution26
I0927 10:14:38.959254  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.959255  3315 net.cpp:137] Memory required for data: 603053200
I0927 10:14:38.959260  3315 layer_factory.hpp:77] Creating layer BatchNorm26
I0927 10:14:38.959265  3315 net.cpp:84] Creating Layer BatchNorm26
I0927 10:14:38.959267  3315 net.cpp:406] BatchNorm26 <- Convolution26
I0927 10:14:38.959271  3315 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0927 10:14:38.959404  3315 net.cpp:122] Setting up BatchNorm26
I0927 10:14:38.959409  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.959411  3315 net.cpp:137] Memory required for data: 605562000
I0927 10:14:38.959415  3315 layer_factory.hpp:77] Creating layer Scale26
I0927 10:14:38.959419  3315 net.cpp:84] Creating Layer Scale26
I0927 10:14:38.959422  3315 net.cpp:406] Scale26 <- Convolution26
I0927 10:14:38.959425  3315 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0927 10:14:38.959451  3315 layer_factory.hpp:77] Creating layer Scale26
I0927 10:14:38.959527  3315 net.cpp:122] Setting up Scale26
I0927 10:14:38.959532  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.959534  3315 net.cpp:137] Memory required for data: 608070800
I0927 10:14:38.959538  3315 layer_factory.hpp:77] Creating layer Eltwise12
I0927 10:14:38.959542  3315 net.cpp:84] Creating Layer Eltwise12
I0927 10:14:38.959545  3315 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0927 10:14:38.959547  3315 net.cpp:406] Eltwise12 <- Convolution26
I0927 10:14:38.959550  3315 net.cpp:380] Eltwise12 -> Eltwise12
I0927 10:14:38.959568  3315 net.cpp:122] Setting up Eltwise12
I0927 10:14:38.959570  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.959573  3315 net.cpp:137] Memory required for data: 610579600
I0927 10:14:38.959574  3315 layer_factory.hpp:77] Creating layer penlu25
I0927 10:14:38.959580  3315 net.cpp:84] Creating Layer penlu25
I0927 10:14:38.959583  3315 net.cpp:406] penlu25 <- Eltwise12
I0927 10:14:38.959585  3315 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0927 10:14:38.959692  3315 net.cpp:122] Setting up penlu25
I0927 10:14:38.959697  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.959699  3315 net.cpp:137] Memory required for data: 613088400
I0927 10:14:38.959722  3315 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0927 10:14:38.959733  3315 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0927 10:14:38.959735  3315 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0927 10:14:38.959739  3315 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0927 10:14:38.959748  3315 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0927 10:14:38.959772  3315 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0927 10:14:38.959776  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.959779  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.959780  3315 net.cpp:137] Memory required for data: 618106000
I0927 10:14:38.959784  3315 layer_factory.hpp:77] Creating layer Convolution27
I0927 10:14:38.959789  3315 net.cpp:84] Creating Layer Convolution27
I0927 10:14:38.959792  3315 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0927 10:14:38.959796  3315 net.cpp:380] Convolution27 -> Convolution27
I0927 10:14:38.960499  3315 net.cpp:122] Setting up Convolution27
I0927 10:14:38.960507  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.960510  3315 net.cpp:137] Memory required for data: 620614800
I0927 10:14:38.960513  3315 layer_factory.hpp:77] Creating layer BatchNorm27
I0927 10:14:38.960517  3315 net.cpp:84] Creating Layer BatchNorm27
I0927 10:14:38.960526  3315 net.cpp:406] BatchNorm27 <- Convolution27
I0927 10:14:38.960531  3315 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0927 10:14:38.960664  3315 net.cpp:122] Setting up BatchNorm27
I0927 10:14:38.960669  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.960671  3315 net.cpp:137] Memory required for data: 623123600
I0927 10:14:38.960675  3315 layer_factory.hpp:77] Creating layer Scale27
I0927 10:14:38.960680  3315 net.cpp:84] Creating Layer Scale27
I0927 10:14:38.960681  3315 net.cpp:406] Scale27 <- Convolution27
I0927 10:14:38.960685  3315 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0927 10:14:38.960711  3315 layer_factory.hpp:77] Creating layer Scale27
I0927 10:14:38.960786  3315 net.cpp:122] Setting up Scale27
I0927 10:14:38.960790  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.960793  3315 net.cpp:137] Memory required for data: 625632400
I0927 10:14:38.960796  3315 layer_factory.hpp:77] Creating layer penlu26
I0927 10:14:38.960801  3315 net.cpp:84] Creating Layer penlu26
I0927 10:14:38.960803  3315 net.cpp:406] penlu26 <- Convolution27
I0927 10:14:38.960806  3315 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0927 10:14:38.960913  3315 net.cpp:122] Setting up penlu26
I0927 10:14:38.960918  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.960921  3315 net.cpp:137] Memory required for data: 628141200
I0927 10:14:38.960924  3315 layer_factory.hpp:77] Creating layer Convolution28
I0927 10:14:38.960932  3315 net.cpp:84] Creating Layer Convolution28
I0927 10:14:38.960933  3315 net.cpp:406] Convolution28 <- Convolution27
I0927 10:14:38.960938  3315 net.cpp:380] Convolution28 -> Convolution28
I0927 10:14:38.961951  3315 net.cpp:122] Setting up Convolution28
I0927 10:14:38.961958  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.961961  3315 net.cpp:137] Memory required for data: 630650000
I0927 10:14:38.961966  3315 layer_factory.hpp:77] Creating layer BatchNorm28
I0927 10:14:38.961971  3315 net.cpp:84] Creating Layer BatchNorm28
I0927 10:14:38.961972  3315 net.cpp:406] BatchNorm28 <- Convolution28
I0927 10:14:38.961977  3315 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0927 10:14:38.962108  3315 net.cpp:122] Setting up BatchNorm28
I0927 10:14:38.962112  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.962115  3315 net.cpp:137] Memory required for data: 633158800
I0927 10:14:38.962119  3315 layer_factory.hpp:77] Creating layer Scale28
I0927 10:14:38.962123  3315 net.cpp:84] Creating Layer Scale28
I0927 10:14:38.962126  3315 net.cpp:406] Scale28 <- Convolution28
I0927 10:14:38.962128  3315 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0927 10:14:38.962155  3315 layer_factory.hpp:77] Creating layer Scale28
I0927 10:14:38.962231  3315 net.cpp:122] Setting up Scale28
I0927 10:14:38.962235  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.962237  3315 net.cpp:137] Memory required for data: 635667600
I0927 10:14:38.962241  3315 layer_factory.hpp:77] Creating layer Eltwise13
I0927 10:14:38.962245  3315 net.cpp:84] Creating Layer Eltwise13
I0927 10:14:38.962247  3315 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0927 10:14:38.962250  3315 net.cpp:406] Eltwise13 <- Convolution28
I0927 10:14:38.962254  3315 net.cpp:380] Eltwise13 -> Eltwise13
I0927 10:14:38.962270  3315 net.cpp:122] Setting up Eltwise13
I0927 10:14:38.962273  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.962275  3315 net.cpp:137] Memory required for data: 638176400
I0927 10:14:38.962277  3315 layer_factory.hpp:77] Creating layer penlu27
I0927 10:14:38.962282  3315 net.cpp:84] Creating Layer penlu27
I0927 10:14:38.962285  3315 net.cpp:406] penlu27 <- Eltwise13
I0927 10:14:38.962288  3315 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0927 10:14:38.962394  3315 net.cpp:122] Setting up penlu27
I0927 10:14:38.962399  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.962400  3315 net.cpp:137] Memory required for data: 640685200
I0927 10:14:38.962404  3315 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0927 10:14:38.962414  3315 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0927 10:14:38.962417  3315 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0927 10:14:38.962420  3315 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0927 10:14:38.962425  3315 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0927 10:14:38.962448  3315 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0927 10:14:38.962452  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.962455  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.962457  3315 net.cpp:137] Memory required for data: 645702800
I0927 10:14:38.962460  3315 layer_factory.hpp:77] Creating layer Convolution29
I0927 10:14:38.962465  3315 net.cpp:84] Creating Layer Convolution29
I0927 10:14:38.962467  3315 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0927 10:14:38.962471  3315 net.cpp:380] Convolution29 -> Convolution29
I0927 10:14:38.963521  3315 net.cpp:122] Setting up Convolution29
I0927 10:14:38.963528  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.963531  3315 net.cpp:137] Memory required for data: 648211600
I0927 10:14:38.963536  3315 layer_factory.hpp:77] Creating layer BatchNorm29
I0927 10:14:38.963541  3315 net.cpp:84] Creating Layer BatchNorm29
I0927 10:14:38.963543  3315 net.cpp:406] BatchNorm29 <- Convolution29
I0927 10:14:38.963547  3315 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0927 10:14:38.963680  3315 net.cpp:122] Setting up BatchNorm29
I0927 10:14:38.963685  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.963686  3315 net.cpp:137] Memory required for data: 650720400
I0927 10:14:38.963690  3315 layer_factory.hpp:77] Creating layer Scale29
I0927 10:14:38.963695  3315 net.cpp:84] Creating Layer Scale29
I0927 10:14:38.963696  3315 net.cpp:406] Scale29 <- Convolution29
I0927 10:14:38.963701  3315 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0927 10:14:38.963726  3315 layer_factory.hpp:77] Creating layer Scale29
I0927 10:14:38.963802  3315 net.cpp:122] Setting up Scale29
I0927 10:14:38.963807  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.963809  3315 net.cpp:137] Memory required for data: 653229200
I0927 10:14:38.963812  3315 layer_factory.hpp:77] Creating layer penlu28
I0927 10:14:38.963819  3315 net.cpp:84] Creating Layer penlu28
I0927 10:14:38.963820  3315 net.cpp:406] penlu28 <- Convolution29
I0927 10:14:38.963824  3315 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0927 10:14:38.963932  3315 net.cpp:122] Setting up penlu28
I0927 10:14:38.963935  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.963937  3315 net.cpp:137] Memory required for data: 655738000
I0927 10:14:38.963943  3315 layer_factory.hpp:77] Creating layer Convolution30
I0927 10:14:38.963948  3315 net.cpp:84] Creating Layer Convolution30
I0927 10:14:38.963950  3315 net.cpp:406] Convolution30 <- Convolution29
I0927 10:14:38.963954  3315 net.cpp:380] Convolution30 -> Convolution30
I0927 10:14:38.964975  3315 net.cpp:122] Setting up Convolution30
I0927 10:14:38.964983  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.964987  3315 net.cpp:137] Memory required for data: 658246800
I0927 10:14:38.964990  3315 layer_factory.hpp:77] Creating layer BatchNorm30
I0927 10:14:38.964996  3315 net.cpp:84] Creating Layer BatchNorm30
I0927 10:14:38.964999  3315 net.cpp:406] BatchNorm30 <- Convolution30
I0927 10:14:38.965003  3315 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0927 10:14:38.965134  3315 net.cpp:122] Setting up BatchNorm30
I0927 10:14:38.965138  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.965142  3315 net.cpp:137] Memory required for data: 660755600
I0927 10:14:38.965145  3315 layer_factory.hpp:77] Creating layer Scale30
I0927 10:14:38.965150  3315 net.cpp:84] Creating Layer Scale30
I0927 10:14:38.965152  3315 net.cpp:406] Scale30 <- Convolution30
I0927 10:14:38.965155  3315 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0927 10:14:38.965190  3315 layer_factory.hpp:77] Creating layer Scale30
I0927 10:14:38.965267  3315 net.cpp:122] Setting up Scale30
I0927 10:14:38.965271  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.965273  3315 net.cpp:137] Memory required for data: 663264400
I0927 10:14:38.965277  3315 layer_factory.hpp:77] Creating layer Eltwise14
I0927 10:14:38.965281  3315 net.cpp:84] Creating Layer Eltwise14
I0927 10:14:38.965283  3315 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0927 10:14:38.965286  3315 net.cpp:406] Eltwise14 <- Convolution30
I0927 10:14:38.965291  3315 net.cpp:380] Eltwise14 -> Eltwise14
I0927 10:14:38.965306  3315 net.cpp:122] Setting up Eltwise14
I0927 10:14:38.965309  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.965312  3315 net.cpp:137] Memory required for data: 665773200
I0927 10:14:38.965313  3315 layer_factory.hpp:77] Creating layer penlu29
I0927 10:14:38.965318  3315 net.cpp:84] Creating Layer penlu29
I0927 10:14:38.965322  3315 net.cpp:406] penlu29 <- Eltwise14
I0927 10:14:38.965324  3315 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0927 10:14:38.965428  3315 net.cpp:122] Setting up penlu29
I0927 10:14:38.965432  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.965435  3315 net.cpp:137] Memory required for data: 668282000
I0927 10:14:38.965438  3315 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0927 10:14:38.965442  3315 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0927 10:14:38.965445  3315 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0927 10:14:38.965448  3315 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0927 10:14:38.965453  3315 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0927 10:14:38.965476  3315 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0927 10:14:38.965478  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.965481  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.965483  3315 net.cpp:137] Memory required for data: 673299600
I0927 10:14:38.965486  3315 layer_factory.hpp:77] Creating layer Convolution31
I0927 10:14:38.965492  3315 net.cpp:84] Creating Layer Convolution31
I0927 10:14:38.965494  3315 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0927 10:14:38.965497  3315 net.cpp:380] Convolution31 -> Convolution31
I0927 10:14:38.966540  3315 net.cpp:122] Setting up Convolution31
I0927 10:14:38.966549  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.966552  3315 net.cpp:137] Memory required for data: 675808400
I0927 10:14:38.966565  3315 layer_factory.hpp:77] Creating layer BatchNorm31
I0927 10:14:38.966570  3315 net.cpp:84] Creating Layer BatchNorm31
I0927 10:14:38.966573  3315 net.cpp:406] BatchNorm31 <- Convolution31
I0927 10:14:38.966578  3315 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0927 10:14:38.966712  3315 net.cpp:122] Setting up BatchNorm31
I0927 10:14:38.966717  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.966718  3315 net.cpp:137] Memory required for data: 678317200
I0927 10:14:38.966723  3315 layer_factory.hpp:77] Creating layer Scale31
I0927 10:14:38.966728  3315 net.cpp:84] Creating Layer Scale31
I0927 10:14:38.966730  3315 net.cpp:406] Scale31 <- Convolution31
I0927 10:14:38.966733  3315 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0927 10:14:38.966759  3315 layer_factory.hpp:77] Creating layer Scale31
I0927 10:14:38.966836  3315 net.cpp:122] Setting up Scale31
I0927 10:14:38.966841  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.966843  3315 net.cpp:137] Memory required for data: 680826000
I0927 10:14:38.966846  3315 layer_factory.hpp:77] Creating layer penlu30
I0927 10:14:38.966852  3315 net.cpp:84] Creating Layer penlu30
I0927 10:14:38.966855  3315 net.cpp:406] penlu30 <- Convolution31
I0927 10:14:38.966857  3315 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0927 10:14:38.966964  3315 net.cpp:122] Setting up penlu30
I0927 10:14:38.966969  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.966976  3315 net.cpp:137] Memory required for data: 683334800
I0927 10:14:38.966980  3315 layer_factory.hpp:77] Creating layer Convolution32
I0927 10:14:38.966987  3315 net.cpp:84] Creating Layer Convolution32
I0927 10:14:38.966989  3315 net.cpp:406] Convolution32 <- Convolution31
I0927 10:14:38.966994  3315 net.cpp:380] Convolution32 -> Convolution32
I0927 10:14:38.968024  3315 net.cpp:122] Setting up Convolution32
I0927 10:14:38.968032  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.968034  3315 net.cpp:137] Memory required for data: 685843600
I0927 10:14:38.968039  3315 layer_factory.hpp:77] Creating layer BatchNorm32
I0927 10:14:38.968044  3315 net.cpp:84] Creating Layer BatchNorm32
I0927 10:14:38.968047  3315 net.cpp:406] BatchNorm32 <- Convolution32
I0927 10:14:38.968051  3315 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0927 10:14:38.968183  3315 net.cpp:122] Setting up BatchNorm32
I0927 10:14:38.968189  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.968190  3315 net.cpp:137] Memory required for data: 688352400
I0927 10:14:38.968194  3315 layer_factory.hpp:77] Creating layer Scale32
I0927 10:14:38.968200  3315 net.cpp:84] Creating Layer Scale32
I0927 10:14:38.968202  3315 net.cpp:406] Scale32 <- Convolution32
I0927 10:14:38.968205  3315 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0927 10:14:38.968231  3315 layer_factory.hpp:77] Creating layer Scale32
I0927 10:14:38.968312  3315 net.cpp:122] Setting up Scale32
I0927 10:14:38.968315  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.968317  3315 net.cpp:137] Memory required for data: 690861200
I0927 10:14:38.968322  3315 layer_factory.hpp:77] Creating layer Eltwise15
I0927 10:14:38.968325  3315 net.cpp:84] Creating Layer Eltwise15
I0927 10:14:38.968328  3315 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0927 10:14:38.968331  3315 net.cpp:406] Eltwise15 <- Convolution32
I0927 10:14:38.968334  3315 net.cpp:380] Eltwise15 -> Eltwise15
I0927 10:14:38.968350  3315 net.cpp:122] Setting up Eltwise15
I0927 10:14:38.968354  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.968356  3315 net.cpp:137] Memory required for data: 693370000
I0927 10:14:38.968358  3315 layer_factory.hpp:77] Creating layer penlu31
I0927 10:14:38.968364  3315 net.cpp:84] Creating Layer penlu31
I0927 10:14:38.968365  3315 net.cpp:406] penlu31 <- Eltwise15
I0927 10:14:38.968369  3315 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0927 10:14:38.968475  3315 net.cpp:122] Setting up penlu31
I0927 10:14:38.968479  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.968482  3315 net.cpp:137] Memory required for data: 695878800
I0927 10:14:38.968485  3315 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0927 10:14:38.968489  3315 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0927 10:14:38.968492  3315 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0927 10:14:38.968494  3315 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0927 10:14:38.968498  3315 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0927 10:14:38.968521  3315 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0927 10:14:38.968525  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.968528  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.968529  3315 net.cpp:137] Memory required for data: 700896400
I0927 10:14:38.968531  3315 layer_factory.hpp:77] Creating layer Convolution33
I0927 10:14:38.968538  3315 net.cpp:84] Creating Layer Convolution33
I0927 10:14:38.968540  3315 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0927 10:14:38.968544  3315 net.cpp:380] Convolution33 -> Convolution33
I0927 10:14:38.969884  3315 net.cpp:122] Setting up Convolution33
I0927 10:14:38.969892  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.969894  3315 net.cpp:137] Memory required for data: 703405200
I0927 10:14:38.969900  3315 layer_factory.hpp:77] Creating layer BatchNorm33
I0927 10:14:38.969904  3315 net.cpp:84] Creating Layer BatchNorm33
I0927 10:14:38.969913  3315 net.cpp:406] BatchNorm33 <- Convolution33
I0927 10:14:38.969918  3315 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0927 10:14:38.970057  3315 net.cpp:122] Setting up BatchNorm33
I0927 10:14:38.970060  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.970062  3315 net.cpp:137] Memory required for data: 705914000
I0927 10:14:38.970067  3315 layer_factory.hpp:77] Creating layer Scale33
I0927 10:14:38.970072  3315 net.cpp:84] Creating Layer Scale33
I0927 10:14:38.970073  3315 net.cpp:406] Scale33 <- Convolution33
I0927 10:14:38.970077  3315 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0927 10:14:38.970103  3315 layer_factory.hpp:77] Creating layer Scale33
I0927 10:14:38.970181  3315 net.cpp:122] Setting up Scale33
I0927 10:14:38.970186  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.970188  3315 net.cpp:137] Memory required for data: 708422800
I0927 10:14:38.970192  3315 layer_factory.hpp:77] Creating layer penlu32
I0927 10:14:38.970196  3315 net.cpp:84] Creating Layer penlu32
I0927 10:14:38.970198  3315 net.cpp:406] penlu32 <- Convolution33
I0927 10:14:38.970203  3315 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0927 10:14:38.970312  3315 net.cpp:122] Setting up penlu32
I0927 10:14:38.970316  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.970319  3315 net.cpp:137] Memory required for data: 710931600
I0927 10:14:38.970322  3315 layer_factory.hpp:77] Creating layer Convolution34
I0927 10:14:38.970329  3315 net.cpp:84] Creating Layer Convolution34
I0927 10:14:38.970332  3315 net.cpp:406] Convolution34 <- Convolution33
I0927 10:14:38.970337  3315 net.cpp:380] Convolution34 -> Convolution34
I0927 10:14:38.971405  3315 net.cpp:122] Setting up Convolution34
I0927 10:14:38.971412  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.971415  3315 net.cpp:137] Memory required for data: 713440400
I0927 10:14:38.971420  3315 layer_factory.hpp:77] Creating layer BatchNorm34
I0927 10:14:38.971424  3315 net.cpp:84] Creating Layer BatchNorm34
I0927 10:14:38.971427  3315 net.cpp:406] BatchNorm34 <- Convolution34
I0927 10:14:38.971431  3315 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0927 10:14:38.971566  3315 net.cpp:122] Setting up BatchNorm34
I0927 10:14:38.971571  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.971573  3315 net.cpp:137] Memory required for data: 715949200
I0927 10:14:38.971577  3315 layer_factory.hpp:77] Creating layer Scale34
I0927 10:14:38.971581  3315 net.cpp:84] Creating Layer Scale34
I0927 10:14:38.971585  3315 net.cpp:406] Scale34 <- Convolution34
I0927 10:14:38.971587  3315 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0927 10:14:38.971614  3315 layer_factory.hpp:77] Creating layer Scale34
I0927 10:14:38.971688  3315 net.cpp:122] Setting up Scale34
I0927 10:14:38.971693  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.971695  3315 net.cpp:137] Memory required for data: 718458000
I0927 10:14:38.971699  3315 layer_factory.hpp:77] Creating layer Eltwise16
I0927 10:14:38.971704  3315 net.cpp:84] Creating Layer Eltwise16
I0927 10:14:38.971705  3315 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0927 10:14:38.971709  3315 net.cpp:406] Eltwise16 <- Convolution34
I0927 10:14:38.971711  3315 net.cpp:380] Eltwise16 -> Eltwise16
I0927 10:14:38.971729  3315 net.cpp:122] Setting up Eltwise16
I0927 10:14:38.971732  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.971735  3315 net.cpp:137] Memory required for data: 720966800
I0927 10:14:38.971736  3315 layer_factory.hpp:77] Creating layer penlu33
I0927 10:14:38.971741  3315 net.cpp:84] Creating Layer penlu33
I0927 10:14:38.971743  3315 net.cpp:406] penlu33 <- Eltwise16
I0927 10:14:38.971746  3315 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0927 10:14:38.971853  3315 net.cpp:122] Setting up penlu33
I0927 10:14:38.971858  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.971859  3315 net.cpp:137] Memory required for data: 723475600
I0927 10:14:38.971871  3315 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0927 10:14:38.971877  3315 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0927 10:14:38.971879  3315 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0927 10:14:38.971882  3315 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0927 10:14:38.971886  3315 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0927 10:14:38.971910  3315 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0927 10:14:38.971915  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.971917  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.971918  3315 net.cpp:137] Memory required for data: 728493200
I0927 10:14:38.971921  3315 layer_factory.hpp:77] Creating layer Convolution35
I0927 10:14:38.971926  3315 net.cpp:84] Creating Layer Convolution35
I0927 10:14:38.971928  3315 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0927 10:14:38.971933  3315 net.cpp:380] Convolution35 -> Convolution35
I0927 10:14:38.972966  3315 net.cpp:122] Setting up Convolution35
I0927 10:14:38.972975  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.972977  3315 net.cpp:137] Memory required for data: 731002000
I0927 10:14:38.972981  3315 layer_factory.hpp:77] Creating layer BatchNorm35
I0927 10:14:38.972986  3315 net.cpp:84] Creating Layer BatchNorm35
I0927 10:14:38.972990  3315 net.cpp:406] BatchNorm35 <- Convolution35
I0927 10:14:38.972993  3315 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0927 10:14:38.973129  3315 net.cpp:122] Setting up BatchNorm35
I0927 10:14:38.973134  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.973135  3315 net.cpp:137] Memory required for data: 733510800
I0927 10:14:38.973140  3315 layer_factory.hpp:77] Creating layer Scale35
I0927 10:14:38.973143  3315 net.cpp:84] Creating Layer Scale35
I0927 10:14:38.973145  3315 net.cpp:406] Scale35 <- Convolution35
I0927 10:14:38.973148  3315 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0927 10:14:38.973176  3315 layer_factory.hpp:77] Creating layer Scale35
I0927 10:14:38.973253  3315 net.cpp:122] Setting up Scale35
I0927 10:14:38.973258  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.973259  3315 net.cpp:137] Memory required for data: 736019600
I0927 10:14:38.973263  3315 layer_factory.hpp:77] Creating layer penlu34
I0927 10:14:38.973268  3315 net.cpp:84] Creating Layer penlu34
I0927 10:14:38.973270  3315 net.cpp:406] penlu34 <- Convolution35
I0927 10:14:38.973274  3315 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0927 10:14:38.973381  3315 net.cpp:122] Setting up penlu34
I0927 10:14:38.973387  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.973388  3315 net.cpp:137] Memory required for data: 738528400
I0927 10:14:38.973392  3315 layer_factory.hpp:77] Creating layer Convolution36
I0927 10:14:38.973399  3315 net.cpp:84] Creating Layer Convolution36
I0927 10:14:38.973402  3315 net.cpp:406] Convolution36 <- Convolution35
I0927 10:14:38.973405  3315 net.cpp:380] Convolution36 -> Convolution36
I0927 10:14:38.974440  3315 net.cpp:122] Setting up Convolution36
I0927 10:14:38.974448  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.974452  3315 net.cpp:137] Memory required for data: 741037200
I0927 10:14:38.974455  3315 layer_factory.hpp:77] Creating layer BatchNorm36
I0927 10:14:38.974460  3315 net.cpp:84] Creating Layer BatchNorm36
I0927 10:14:38.974464  3315 net.cpp:406] BatchNorm36 <- Convolution36
I0927 10:14:38.974467  3315 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0927 10:14:38.974627  3315 net.cpp:122] Setting up BatchNorm36
I0927 10:14:38.974632  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.974633  3315 net.cpp:137] Memory required for data: 743546000
I0927 10:14:38.974638  3315 layer_factory.hpp:77] Creating layer Scale36
I0927 10:14:38.974643  3315 net.cpp:84] Creating Layer Scale36
I0927 10:14:38.974645  3315 net.cpp:406] Scale36 <- Convolution36
I0927 10:14:38.974648  3315 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0927 10:14:38.974684  3315 layer_factory.hpp:77] Creating layer Scale36
I0927 10:14:38.974761  3315 net.cpp:122] Setting up Scale36
I0927 10:14:38.974766  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.974767  3315 net.cpp:137] Memory required for data: 746054800
I0927 10:14:38.974771  3315 layer_factory.hpp:77] Creating layer Eltwise17
I0927 10:14:38.974774  3315 net.cpp:84] Creating Layer Eltwise17
I0927 10:14:38.974777  3315 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0927 10:14:38.974781  3315 net.cpp:406] Eltwise17 <- Convolution36
I0927 10:14:38.974784  3315 net.cpp:380] Eltwise17 -> Eltwise17
I0927 10:14:38.974799  3315 net.cpp:122] Setting up Eltwise17
I0927 10:14:38.974802  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.974804  3315 net.cpp:137] Memory required for data: 748563600
I0927 10:14:38.974807  3315 layer_factory.hpp:77] Creating layer penlu35
I0927 10:14:38.974812  3315 net.cpp:84] Creating Layer penlu35
I0927 10:14:38.974814  3315 net.cpp:406] penlu35 <- Eltwise17
I0927 10:14:38.974817  3315 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0927 10:14:38.974921  3315 net.cpp:122] Setting up penlu35
I0927 10:14:38.974926  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.974928  3315 net.cpp:137] Memory required for data: 751072400
I0927 10:14:38.974932  3315 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0927 10:14:38.974936  3315 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0927 10:14:38.974938  3315 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0927 10:14:38.974942  3315 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0927 10:14:38.974946  3315 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0927 10:14:38.974968  3315 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0927 10:14:38.974972  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.974974  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.974977  3315 net.cpp:137] Memory required for data: 756090000
I0927 10:14:38.974978  3315 layer_factory.hpp:77] Creating layer Convolution37
I0927 10:14:38.974984  3315 net.cpp:84] Creating Layer Convolution37
I0927 10:14:38.974987  3315 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0927 10:14:38.974990  3315 net.cpp:380] Convolution37 -> Convolution37
I0927 10:14:38.975703  3315 net.cpp:122] Setting up Convolution37
I0927 10:14:38.975709  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.975713  3315 net.cpp:137] Memory required for data: 758598800
I0927 10:14:38.975716  3315 layer_factory.hpp:77] Creating layer BatchNorm37
I0927 10:14:38.975720  3315 net.cpp:84] Creating Layer BatchNorm37
I0927 10:14:38.975723  3315 net.cpp:406] BatchNorm37 <- Convolution37
I0927 10:14:38.975728  3315 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0927 10:14:38.975862  3315 net.cpp:122] Setting up BatchNorm37
I0927 10:14:38.975867  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.975868  3315 net.cpp:137] Memory required for data: 761107600
I0927 10:14:38.975873  3315 layer_factory.hpp:77] Creating layer Scale37
I0927 10:14:38.975877  3315 net.cpp:84] Creating Layer Scale37
I0927 10:14:38.975879  3315 net.cpp:406] Scale37 <- Convolution37
I0927 10:14:38.975883  3315 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0927 10:14:38.975908  3315 layer_factory.hpp:77] Creating layer Scale37
I0927 10:14:38.975983  3315 net.cpp:122] Setting up Scale37
I0927 10:14:38.975987  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.975989  3315 net.cpp:137] Memory required for data: 763616400
I0927 10:14:38.975993  3315 layer_factory.hpp:77] Creating layer penlu36
I0927 10:14:38.975998  3315 net.cpp:84] Creating Layer penlu36
I0927 10:14:38.976001  3315 net.cpp:406] penlu36 <- Convolution37
I0927 10:14:38.976004  3315 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0927 10:14:38.976110  3315 net.cpp:122] Setting up penlu36
I0927 10:14:38.976115  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.976122  3315 net.cpp:137] Memory required for data: 766125200
I0927 10:14:38.976127  3315 layer_factory.hpp:77] Creating layer Convolution38
I0927 10:14:38.976133  3315 net.cpp:84] Creating Layer Convolution38
I0927 10:14:38.976135  3315 net.cpp:406] Convolution38 <- Convolution37
I0927 10:14:38.976140  3315 net.cpp:380] Convolution38 -> Convolution38
I0927 10:14:38.977181  3315 net.cpp:122] Setting up Convolution38
I0927 10:14:38.977190  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.977192  3315 net.cpp:137] Memory required for data: 768634000
I0927 10:14:38.977196  3315 layer_factory.hpp:77] Creating layer BatchNorm38
I0927 10:14:38.977202  3315 net.cpp:84] Creating Layer BatchNorm38
I0927 10:14:38.977205  3315 net.cpp:406] BatchNorm38 <- Convolution38
I0927 10:14:38.977208  3315 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0927 10:14:38.977346  3315 net.cpp:122] Setting up BatchNorm38
I0927 10:14:38.977351  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.977354  3315 net.cpp:137] Memory required for data: 771142800
I0927 10:14:38.977357  3315 layer_factory.hpp:77] Creating layer Scale38
I0927 10:14:38.977361  3315 net.cpp:84] Creating Layer Scale38
I0927 10:14:38.977365  3315 net.cpp:406] Scale38 <- Convolution38
I0927 10:14:38.977367  3315 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0927 10:14:38.977396  3315 layer_factory.hpp:77] Creating layer Scale38
I0927 10:14:38.977470  3315 net.cpp:122] Setting up Scale38
I0927 10:14:38.977475  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.977478  3315 net.cpp:137] Memory required for data: 773651600
I0927 10:14:38.977481  3315 layer_factory.hpp:77] Creating layer Eltwise18
I0927 10:14:38.977485  3315 net.cpp:84] Creating Layer Eltwise18
I0927 10:14:38.977488  3315 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0927 10:14:38.977490  3315 net.cpp:406] Eltwise18 <- Convolution38
I0927 10:14:38.977494  3315 net.cpp:380] Eltwise18 -> Eltwise18
I0927 10:14:38.977509  3315 net.cpp:122] Setting up Eltwise18
I0927 10:14:38.977514  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.977515  3315 net.cpp:137] Memory required for data: 776160400
I0927 10:14:38.977517  3315 layer_factory.hpp:77] Creating layer penlu37
I0927 10:14:38.977522  3315 net.cpp:84] Creating Layer penlu37
I0927 10:14:38.977525  3315 net.cpp:406] penlu37 <- Eltwise18
I0927 10:14:38.977530  3315 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0927 10:14:38.977638  3315 net.cpp:122] Setting up penlu37
I0927 10:14:38.977641  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.977643  3315 net.cpp:137] Memory required for data: 778669200
I0927 10:14:38.977648  3315 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0927 10:14:38.977653  3315 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0927 10:14:38.977654  3315 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0927 10:14:38.977658  3315 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0927 10:14:38.977661  3315 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0927 10:14:38.977684  3315 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0927 10:14:38.977689  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.977691  3315 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0927 10:14:38.977694  3315 net.cpp:137] Memory required for data: 783686800
I0927 10:14:38.977695  3315 layer_factory.hpp:77] Creating layer Convolution39
I0927 10:14:38.977700  3315 net.cpp:84] Creating Layer Convolution39
I0927 10:14:38.977704  3315 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0927 10:14:38.977707  3315 net.cpp:380] Convolution39 -> Convolution39
I0927 10:14:38.978611  3315 net.cpp:122] Setting up Convolution39
I0927 10:14:38.978619  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.978622  3315 net.cpp:137] Memory required for data: 784941200
I0927 10:14:38.978626  3315 layer_factory.hpp:77] Creating layer BatchNorm39
I0927 10:14:38.978637  3315 net.cpp:84] Creating Layer BatchNorm39
I0927 10:14:38.978641  3315 net.cpp:406] BatchNorm39 <- Convolution39
I0927 10:14:38.978644  3315 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0927 10:14:38.978778  3315 net.cpp:122] Setting up BatchNorm39
I0927 10:14:38.978782  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.978785  3315 net.cpp:137] Memory required for data: 786195600
I0927 10:14:38.978790  3315 layer_factory.hpp:77] Creating layer Scale39
I0927 10:14:38.978793  3315 net.cpp:84] Creating Layer Scale39
I0927 10:14:38.978796  3315 net.cpp:406] Scale39 <- Convolution39
I0927 10:14:38.978798  3315 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0927 10:14:38.978826  3315 layer_factory.hpp:77] Creating layer Scale39
I0927 10:14:38.978902  3315 net.cpp:122] Setting up Scale39
I0927 10:14:38.978907  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.978909  3315 net.cpp:137] Memory required for data: 787450000
I0927 10:14:38.978914  3315 layer_factory.hpp:77] Creating layer Convolution40
I0927 10:14:38.978919  3315 net.cpp:84] Creating Layer Convolution40
I0927 10:14:38.978922  3315 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0927 10:14:38.978926  3315 net.cpp:380] Convolution40 -> Convolution40
I0927 10:14:38.980659  3315 net.cpp:122] Setting up Convolution40
I0927 10:14:38.980667  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.980669  3315 net.cpp:137] Memory required for data: 788704400
I0927 10:14:38.980674  3315 layer_factory.hpp:77] Creating layer BatchNorm40
I0927 10:14:38.980679  3315 net.cpp:84] Creating Layer BatchNorm40
I0927 10:14:38.980681  3315 net.cpp:406] BatchNorm40 <- Convolution40
I0927 10:14:38.980686  3315 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0927 10:14:38.980824  3315 net.cpp:122] Setting up BatchNorm40
I0927 10:14:38.980829  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.980830  3315 net.cpp:137] Memory required for data: 789958800
I0927 10:14:38.980835  3315 layer_factory.hpp:77] Creating layer Scale40
I0927 10:14:38.980839  3315 net.cpp:84] Creating Layer Scale40
I0927 10:14:38.980841  3315 net.cpp:406] Scale40 <- Convolution40
I0927 10:14:38.980844  3315 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0927 10:14:38.980871  3315 layer_factory.hpp:77] Creating layer Scale40
I0927 10:14:38.980948  3315 net.cpp:122] Setting up Scale40
I0927 10:14:38.980952  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.980954  3315 net.cpp:137] Memory required for data: 791213200
I0927 10:14:38.980958  3315 layer_factory.hpp:77] Creating layer penlu38
I0927 10:14:38.980962  3315 net.cpp:84] Creating Layer penlu38
I0927 10:14:38.980965  3315 net.cpp:406] penlu38 <- Convolution40
I0927 10:14:38.980969  3315 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0927 10:14:38.981076  3315 net.cpp:122] Setting up penlu38
I0927 10:14:38.981081  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.981082  3315 net.cpp:137] Memory required for data: 792467600
I0927 10:14:38.981086  3315 layer_factory.hpp:77] Creating layer Convolution41
I0927 10:14:38.981092  3315 net.cpp:84] Creating Layer Convolution41
I0927 10:14:38.981096  3315 net.cpp:406] Convolution41 <- Convolution40
I0927 10:14:38.981099  3315 net.cpp:380] Convolution41 -> Convolution41
I0927 10:14:38.983196  3315 net.cpp:122] Setting up Convolution41
I0927 10:14:38.983206  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.983208  3315 net.cpp:137] Memory required for data: 793722000
I0927 10:14:38.983213  3315 layer_factory.hpp:77] Creating layer BatchNorm41
I0927 10:14:38.983219  3315 net.cpp:84] Creating Layer BatchNorm41
I0927 10:14:38.983222  3315 net.cpp:406] BatchNorm41 <- Convolution41
I0927 10:14:38.983225  3315 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0927 10:14:38.983383  3315 net.cpp:122] Setting up BatchNorm41
I0927 10:14:38.983392  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.983397  3315 net.cpp:137] Memory required for data: 794976400
I0927 10:14:38.983415  3315 layer_factory.hpp:77] Creating layer Scale41
I0927 10:14:38.983425  3315 net.cpp:84] Creating Layer Scale41
I0927 10:14:38.983428  3315 net.cpp:406] Scale41 <- Convolution41
I0927 10:14:38.983433  3315 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0927 10:14:38.983465  3315 layer_factory.hpp:77] Creating layer Scale41
I0927 10:14:38.983566  3315 net.cpp:122] Setting up Scale41
I0927 10:14:38.983575  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.983579  3315 net.cpp:137] Memory required for data: 796230800
I0927 10:14:38.983587  3315 layer_factory.hpp:77] Creating layer Eltwise19
I0927 10:14:38.983594  3315 net.cpp:84] Creating Layer Eltwise19
I0927 10:14:38.983599  3315 net.cpp:406] Eltwise19 <- Convolution39
I0927 10:14:38.983603  3315 net.cpp:406] Eltwise19 <- Convolution41
I0927 10:14:38.983608  3315 net.cpp:380] Eltwise19 -> Eltwise19
I0927 10:14:38.983628  3315 net.cpp:122] Setting up Eltwise19
I0927 10:14:38.983633  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.983634  3315 net.cpp:137] Memory required for data: 797485200
I0927 10:14:38.983636  3315 layer_factory.hpp:77] Creating layer penlu39
I0927 10:14:38.983642  3315 net.cpp:84] Creating Layer penlu39
I0927 10:14:38.983645  3315 net.cpp:406] penlu39 <- Eltwise19
I0927 10:14:38.983649  3315 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0927 10:14:38.983773  3315 net.cpp:122] Setting up penlu39
I0927 10:14:38.983777  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.983779  3315 net.cpp:137] Memory required for data: 798739600
I0927 10:14:38.983784  3315 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0927 10:14:38.983788  3315 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0927 10:14:38.983790  3315 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0927 10:14:38.983793  3315 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0927 10:14:38.983798  3315 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0927 10:14:38.983821  3315 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0927 10:14:38.983825  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.983827  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.983829  3315 net.cpp:137] Memory required for data: 801248400
I0927 10:14:38.983832  3315 layer_factory.hpp:77] Creating layer Convolution42
I0927 10:14:38.983839  3315 net.cpp:84] Creating Layer Convolution42
I0927 10:14:38.983841  3315 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0927 10:14:38.983845  3315 net.cpp:380] Convolution42 -> Convolution42
I0927 10:14:38.985611  3315 net.cpp:122] Setting up Convolution42
I0927 10:14:38.985620  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.985623  3315 net.cpp:137] Memory required for data: 802502800
I0927 10:14:38.985627  3315 layer_factory.hpp:77] Creating layer BatchNorm42
I0927 10:14:38.985632  3315 net.cpp:84] Creating Layer BatchNorm42
I0927 10:14:38.985635  3315 net.cpp:406] BatchNorm42 <- Convolution42
I0927 10:14:38.985640  3315 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0927 10:14:38.985780  3315 net.cpp:122] Setting up BatchNorm42
I0927 10:14:38.985785  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.985787  3315 net.cpp:137] Memory required for data: 803757200
I0927 10:14:38.985791  3315 layer_factory.hpp:77] Creating layer Scale42
I0927 10:14:38.985796  3315 net.cpp:84] Creating Layer Scale42
I0927 10:14:38.985800  3315 net.cpp:406] Scale42 <- Convolution42
I0927 10:14:38.985802  3315 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0927 10:14:38.985831  3315 layer_factory.hpp:77] Creating layer Scale42
I0927 10:14:38.985911  3315 net.cpp:122] Setting up Scale42
I0927 10:14:38.985916  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.985918  3315 net.cpp:137] Memory required for data: 805011600
I0927 10:14:38.985922  3315 layer_factory.hpp:77] Creating layer penlu40
I0927 10:14:38.985927  3315 net.cpp:84] Creating Layer penlu40
I0927 10:14:38.985930  3315 net.cpp:406] penlu40 <- Convolution42
I0927 10:14:38.985940  3315 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0927 10:14:38.986055  3315 net.cpp:122] Setting up penlu40
I0927 10:14:38.986059  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.986062  3315 net.cpp:137] Memory required for data: 806266000
I0927 10:14:38.986066  3315 layer_factory.hpp:77] Creating layer Convolution43
I0927 10:14:38.986073  3315 net.cpp:84] Creating Layer Convolution43
I0927 10:14:38.986075  3315 net.cpp:406] Convolution43 <- Convolution42
I0927 10:14:38.986079  3315 net.cpp:380] Convolution43 -> Convolution43
I0927 10:14:38.988389  3315 net.cpp:122] Setting up Convolution43
I0927 10:14:38.988399  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.988400  3315 net.cpp:137] Memory required for data: 807520400
I0927 10:14:38.988405  3315 layer_factory.hpp:77] Creating layer BatchNorm43
I0927 10:14:38.988410  3315 net.cpp:84] Creating Layer BatchNorm43
I0927 10:14:38.988414  3315 net.cpp:406] BatchNorm43 <- Convolution43
I0927 10:14:38.988417  3315 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0927 10:14:38.988560  3315 net.cpp:122] Setting up BatchNorm43
I0927 10:14:38.988564  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.988566  3315 net.cpp:137] Memory required for data: 808774800
I0927 10:14:38.988571  3315 layer_factory.hpp:77] Creating layer Scale43
I0927 10:14:38.988575  3315 net.cpp:84] Creating Layer Scale43
I0927 10:14:38.988579  3315 net.cpp:406] Scale43 <- Convolution43
I0927 10:14:38.988581  3315 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0927 10:14:38.988610  3315 layer_factory.hpp:77] Creating layer Scale43
I0927 10:14:38.988690  3315 net.cpp:122] Setting up Scale43
I0927 10:14:38.988694  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.988696  3315 net.cpp:137] Memory required for data: 810029200
I0927 10:14:38.988700  3315 layer_factory.hpp:77] Creating layer Eltwise20
I0927 10:14:38.988704  3315 net.cpp:84] Creating Layer Eltwise20
I0927 10:14:38.988706  3315 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0927 10:14:38.988709  3315 net.cpp:406] Eltwise20 <- Convolution43
I0927 10:14:38.988713  3315 net.cpp:380] Eltwise20 -> Eltwise20
I0927 10:14:38.988729  3315 net.cpp:122] Setting up Eltwise20
I0927 10:14:38.988734  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.988735  3315 net.cpp:137] Memory required for data: 811283600
I0927 10:14:38.988737  3315 layer_factory.hpp:77] Creating layer penlu41
I0927 10:14:38.988744  3315 net.cpp:84] Creating Layer penlu41
I0927 10:14:38.988745  3315 net.cpp:406] penlu41 <- Eltwise20
I0927 10:14:38.988749  3315 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0927 10:14:38.988862  3315 net.cpp:122] Setting up penlu41
I0927 10:14:38.988865  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.988867  3315 net.cpp:137] Memory required for data: 812538000
I0927 10:14:38.988871  3315 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0927 10:14:38.988874  3315 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0927 10:14:38.988878  3315 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0927 10:14:38.988881  3315 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0927 10:14:38.988885  3315 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0927 10:14:38.988909  3315 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0927 10:14:38.988911  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.988914  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.988916  3315 net.cpp:137] Memory required for data: 815046800
I0927 10:14:38.988919  3315 layer_factory.hpp:77] Creating layer Convolution44
I0927 10:14:38.988924  3315 net.cpp:84] Creating Layer Convolution44
I0927 10:14:38.988927  3315 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0927 10:14:38.988931  3315 net.cpp:380] Convolution44 -> Convolution44
I0927 10:14:38.990605  3315 net.cpp:122] Setting up Convolution44
I0927 10:14:38.990613  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.990624  3315 net.cpp:137] Memory required for data: 816301200
I0927 10:14:38.990629  3315 layer_factory.hpp:77] Creating layer BatchNorm44
I0927 10:14:38.990635  3315 net.cpp:84] Creating Layer BatchNorm44
I0927 10:14:38.990638  3315 net.cpp:406] BatchNorm44 <- Convolution44
I0927 10:14:38.990643  3315 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0927 10:14:38.990780  3315 net.cpp:122] Setting up BatchNorm44
I0927 10:14:38.990785  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.990787  3315 net.cpp:137] Memory required for data: 817555600
I0927 10:14:38.990792  3315 layer_factory.hpp:77] Creating layer Scale44
I0927 10:14:38.990798  3315 net.cpp:84] Creating Layer Scale44
I0927 10:14:38.990800  3315 net.cpp:406] Scale44 <- Convolution44
I0927 10:14:38.990803  3315 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0927 10:14:38.990833  3315 layer_factory.hpp:77] Creating layer Scale44
I0927 10:14:38.990912  3315 net.cpp:122] Setting up Scale44
I0927 10:14:38.990916  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.990918  3315 net.cpp:137] Memory required for data: 818810000
I0927 10:14:38.990922  3315 layer_factory.hpp:77] Creating layer penlu42
I0927 10:14:38.990928  3315 net.cpp:84] Creating Layer penlu42
I0927 10:14:38.990931  3315 net.cpp:406] penlu42 <- Convolution44
I0927 10:14:38.990933  3315 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0927 10:14:38.991044  3315 net.cpp:122] Setting up penlu42
I0927 10:14:38.991048  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.991050  3315 net.cpp:137] Memory required for data: 820064400
I0927 10:14:38.991055  3315 layer_factory.hpp:77] Creating layer Convolution45
I0927 10:14:38.991061  3315 net.cpp:84] Creating Layer Convolution45
I0927 10:14:38.991065  3315 net.cpp:406] Convolution45 <- Convolution44
I0927 10:14:38.991067  3315 net.cpp:380] Convolution45 -> Convolution45
I0927 10:14:38.993010  3315 net.cpp:122] Setting up Convolution45
I0927 10:14:38.993019  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.993021  3315 net.cpp:137] Memory required for data: 821318800
I0927 10:14:38.993026  3315 layer_factory.hpp:77] Creating layer BatchNorm45
I0927 10:14:38.993031  3315 net.cpp:84] Creating Layer BatchNorm45
I0927 10:14:38.993032  3315 net.cpp:406] BatchNorm45 <- Convolution45
I0927 10:14:38.993037  3315 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0927 10:14:38.993180  3315 net.cpp:122] Setting up BatchNorm45
I0927 10:14:38.993185  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.993186  3315 net.cpp:137] Memory required for data: 822573200
I0927 10:14:38.993191  3315 layer_factory.hpp:77] Creating layer Scale45
I0927 10:14:38.993196  3315 net.cpp:84] Creating Layer Scale45
I0927 10:14:38.993197  3315 net.cpp:406] Scale45 <- Convolution45
I0927 10:14:38.993201  3315 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0927 10:14:38.993228  3315 layer_factory.hpp:77] Creating layer Scale45
I0927 10:14:38.993309  3315 net.cpp:122] Setting up Scale45
I0927 10:14:38.993314  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.993315  3315 net.cpp:137] Memory required for data: 823827600
I0927 10:14:38.993319  3315 layer_factory.hpp:77] Creating layer Eltwise21
I0927 10:14:38.993324  3315 net.cpp:84] Creating Layer Eltwise21
I0927 10:14:38.993325  3315 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0927 10:14:38.993329  3315 net.cpp:406] Eltwise21 <- Convolution45
I0927 10:14:38.993332  3315 net.cpp:380] Eltwise21 -> Eltwise21
I0927 10:14:38.993350  3315 net.cpp:122] Setting up Eltwise21
I0927 10:14:38.993353  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.993355  3315 net.cpp:137] Memory required for data: 825082000
I0927 10:14:38.993358  3315 layer_factory.hpp:77] Creating layer penlu43
I0927 10:14:38.993362  3315 net.cpp:84] Creating Layer penlu43
I0927 10:14:38.993365  3315 net.cpp:406] penlu43 <- Eltwise21
I0927 10:14:38.993368  3315 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0927 10:14:38.993482  3315 net.cpp:122] Setting up penlu43
I0927 10:14:38.993492  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.993495  3315 net.cpp:137] Memory required for data: 826336400
I0927 10:14:38.993499  3315 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0927 10:14:38.993504  3315 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0927 10:14:38.993505  3315 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0927 10:14:38.993508  3315 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0927 10:14:38.993513  3315 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0927 10:14:38.993538  3315 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0927 10:14:38.993542  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.993546  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.993547  3315 net.cpp:137] Memory required for data: 828845200
I0927 10:14:38.993549  3315 layer_factory.hpp:77] Creating layer Convolution46
I0927 10:14:38.993556  3315 net.cpp:84] Creating Layer Convolution46
I0927 10:14:38.993557  3315 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0927 10:14:38.993562  3315 net.cpp:380] Convolution46 -> Convolution46
I0927 10:14:38.995267  3315 net.cpp:122] Setting up Convolution46
I0927 10:14:38.995276  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.995278  3315 net.cpp:137] Memory required for data: 830099600
I0927 10:14:38.995283  3315 layer_factory.hpp:77] Creating layer BatchNorm46
I0927 10:14:38.995287  3315 net.cpp:84] Creating Layer BatchNorm46
I0927 10:14:38.995290  3315 net.cpp:406] BatchNorm46 <- Convolution46
I0927 10:14:38.995293  3315 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0927 10:14:38.995436  3315 net.cpp:122] Setting up BatchNorm46
I0927 10:14:38.995440  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.995442  3315 net.cpp:137] Memory required for data: 831354000
I0927 10:14:38.995447  3315 layer_factory.hpp:77] Creating layer Scale46
I0927 10:14:38.995451  3315 net.cpp:84] Creating Layer Scale46
I0927 10:14:38.995453  3315 net.cpp:406] Scale46 <- Convolution46
I0927 10:14:38.995457  3315 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0927 10:14:38.995484  3315 layer_factory.hpp:77] Creating layer Scale46
I0927 10:14:38.995565  3315 net.cpp:122] Setting up Scale46
I0927 10:14:38.995569  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.995571  3315 net.cpp:137] Memory required for data: 832608400
I0927 10:14:38.995574  3315 layer_factory.hpp:77] Creating layer penlu44
I0927 10:14:38.995580  3315 net.cpp:84] Creating Layer penlu44
I0927 10:14:38.995582  3315 net.cpp:406] penlu44 <- Convolution46
I0927 10:14:38.995586  3315 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0927 10:14:38.995700  3315 net.cpp:122] Setting up penlu44
I0927 10:14:38.995705  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.995707  3315 net.cpp:137] Memory required for data: 833862800
I0927 10:14:38.995712  3315 layer_factory.hpp:77] Creating layer Convolution47
I0927 10:14:38.995718  3315 net.cpp:84] Creating Layer Convolution47
I0927 10:14:38.995720  3315 net.cpp:406] Convolution47 <- Convolution46
I0927 10:14:38.995723  3315 net.cpp:380] Convolution47 -> Convolution47
I0927 10:14:38.997354  3315 net.cpp:122] Setting up Convolution47
I0927 10:14:38.997362  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.997365  3315 net.cpp:137] Memory required for data: 835117200
I0927 10:14:38.997370  3315 layer_factory.hpp:77] Creating layer BatchNorm47
I0927 10:14:38.997375  3315 net.cpp:84] Creating Layer BatchNorm47
I0927 10:14:38.997377  3315 net.cpp:406] BatchNorm47 <- Convolution47
I0927 10:14:38.997381  3315 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0927 10:14:38.997524  3315 net.cpp:122] Setting up BatchNorm47
I0927 10:14:38.997529  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.997531  3315 net.cpp:137] Memory required for data: 836371600
I0927 10:14:38.997536  3315 layer_factory.hpp:77] Creating layer Scale47
I0927 10:14:38.997547  3315 net.cpp:84] Creating Layer Scale47
I0927 10:14:38.997550  3315 net.cpp:406] Scale47 <- Convolution47
I0927 10:14:38.997553  3315 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0927 10:14:38.997582  3315 layer_factory.hpp:77] Creating layer Scale47
I0927 10:14:38.997665  3315 net.cpp:122] Setting up Scale47
I0927 10:14:38.997669  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.997671  3315 net.cpp:137] Memory required for data: 837626000
I0927 10:14:38.997675  3315 layer_factory.hpp:77] Creating layer Eltwise22
I0927 10:14:38.997680  3315 net.cpp:84] Creating Layer Eltwise22
I0927 10:14:38.997683  3315 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0927 10:14:38.997685  3315 net.cpp:406] Eltwise22 <- Convolution47
I0927 10:14:38.997689  3315 net.cpp:380] Eltwise22 -> Eltwise22
I0927 10:14:38.997706  3315 net.cpp:122] Setting up Eltwise22
I0927 10:14:38.997710  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.997711  3315 net.cpp:137] Memory required for data: 838880400
I0927 10:14:38.997714  3315 layer_factory.hpp:77] Creating layer penlu45
I0927 10:14:38.997720  3315 net.cpp:84] Creating Layer penlu45
I0927 10:14:38.997721  3315 net.cpp:406] penlu45 <- Eltwise22
I0927 10:14:38.997725  3315 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0927 10:14:38.997835  3315 net.cpp:122] Setting up penlu45
I0927 10:14:38.997840  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.997843  3315 net.cpp:137] Memory required for data: 840134800
I0927 10:14:38.997846  3315 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0927 10:14:38.997849  3315 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0927 10:14:38.997853  3315 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0927 10:14:38.997855  3315 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0927 10:14:38.997859  3315 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0927 10:14:38.997884  3315 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0927 10:14:38.997887  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.997890  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.997892  3315 net.cpp:137] Memory required for data: 842643600
I0927 10:14:38.997895  3315 layer_factory.hpp:77] Creating layer Convolution48
I0927 10:14:38.997900  3315 net.cpp:84] Creating Layer Convolution48
I0927 10:14:38.997902  3315 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0927 10:14:38.997906  3315 net.cpp:380] Convolution48 -> Convolution48
I0927 10:14:38.999546  3315 net.cpp:122] Setting up Convolution48
I0927 10:14:38.999554  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.999557  3315 net.cpp:137] Memory required for data: 843898000
I0927 10:14:38.999562  3315 layer_factory.hpp:77] Creating layer BatchNorm48
I0927 10:14:38.999567  3315 net.cpp:84] Creating Layer BatchNorm48
I0927 10:14:38.999568  3315 net.cpp:406] BatchNorm48 <- Convolution48
I0927 10:14:38.999572  3315 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0927 10:14:38.999713  3315 net.cpp:122] Setting up BatchNorm48
I0927 10:14:38.999717  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.999719  3315 net.cpp:137] Memory required for data: 845152400
I0927 10:14:38.999724  3315 layer_factory.hpp:77] Creating layer Scale48
I0927 10:14:38.999728  3315 net.cpp:84] Creating Layer Scale48
I0927 10:14:38.999732  3315 net.cpp:406] Scale48 <- Convolution48
I0927 10:14:38.999734  3315 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0927 10:14:38.999763  3315 layer_factory.hpp:77] Creating layer Scale48
I0927 10:14:38.999843  3315 net.cpp:122] Setting up Scale48
I0927 10:14:38.999847  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.999850  3315 net.cpp:137] Memory required for data: 846406800
I0927 10:14:38.999853  3315 layer_factory.hpp:77] Creating layer penlu46
I0927 10:14:38.999858  3315 net.cpp:84] Creating Layer penlu46
I0927 10:14:38.999861  3315 net.cpp:406] penlu46 <- Convolution48
I0927 10:14:38.999864  3315 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0927 10:14:38.999984  3315 net.cpp:122] Setting up penlu46
I0927 10:14:38.999989  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:38.999991  3315 net.cpp:137] Memory required for data: 847661200
I0927 10:14:38.999995  3315 layer_factory.hpp:77] Creating layer Convolution49
I0927 10:14:39.000001  3315 net.cpp:84] Creating Layer Convolution49
I0927 10:14:39.000005  3315 net.cpp:406] Convolution49 <- Convolution48
I0927 10:14:39.000008  3315 net.cpp:380] Convolution49 -> Convolution49
I0927 10:14:39.001955  3315 net.cpp:122] Setting up Convolution49
I0927 10:14:39.001962  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.001965  3315 net.cpp:137] Memory required for data: 848915600
I0927 10:14:39.001971  3315 layer_factory.hpp:77] Creating layer BatchNorm49
I0927 10:14:39.001976  3315 net.cpp:84] Creating Layer BatchNorm49
I0927 10:14:39.001978  3315 net.cpp:406] BatchNorm49 <- Convolution49
I0927 10:14:39.001982  3315 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0927 10:14:39.002127  3315 net.cpp:122] Setting up BatchNorm49
I0927 10:14:39.002132  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.002135  3315 net.cpp:137] Memory required for data: 850170000
I0927 10:14:39.002138  3315 layer_factory.hpp:77] Creating layer Scale49
I0927 10:14:39.002142  3315 net.cpp:84] Creating Layer Scale49
I0927 10:14:39.002144  3315 net.cpp:406] Scale49 <- Convolution49
I0927 10:14:39.002147  3315 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0927 10:14:39.002177  3315 layer_factory.hpp:77] Creating layer Scale49
I0927 10:14:39.002259  3315 net.cpp:122] Setting up Scale49
I0927 10:14:39.002262  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.002265  3315 net.cpp:137] Memory required for data: 851424400
I0927 10:14:39.002269  3315 layer_factory.hpp:77] Creating layer Eltwise23
I0927 10:14:39.002272  3315 net.cpp:84] Creating Layer Eltwise23
I0927 10:14:39.002275  3315 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0927 10:14:39.002277  3315 net.cpp:406] Eltwise23 <- Convolution49
I0927 10:14:39.002281  3315 net.cpp:380] Eltwise23 -> Eltwise23
I0927 10:14:39.002298  3315 net.cpp:122] Setting up Eltwise23
I0927 10:14:39.002301  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.002303  3315 net.cpp:137] Memory required for data: 852678800
I0927 10:14:39.002305  3315 layer_factory.hpp:77] Creating layer penlu47
I0927 10:14:39.002311  3315 net.cpp:84] Creating Layer penlu47
I0927 10:14:39.002313  3315 net.cpp:406] penlu47 <- Eltwise23
I0927 10:14:39.002317  3315 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0927 10:14:39.002432  3315 net.cpp:122] Setting up penlu47
I0927 10:14:39.002436  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.002439  3315 net.cpp:137] Memory required for data: 853933200
I0927 10:14:39.002442  3315 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0927 10:14:39.002445  3315 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0927 10:14:39.002447  3315 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0927 10:14:39.002451  3315 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0927 10:14:39.002455  3315 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0927 10:14:39.002480  3315 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0927 10:14:39.002483  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.002485  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.002487  3315 net.cpp:137] Memory required for data: 856442000
I0927 10:14:39.002490  3315 layer_factory.hpp:77] Creating layer Convolution50
I0927 10:14:39.002496  3315 net.cpp:84] Creating Layer Convolution50
I0927 10:14:39.002498  3315 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0927 10:14:39.002502  3315 net.cpp:380] Convolution50 -> Convolution50
I0927 10:14:39.004154  3315 net.cpp:122] Setting up Convolution50
I0927 10:14:39.004163  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.004165  3315 net.cpp:137] Memory required for data: 857696400
I0927 10:14:39.004176  3315 layer_factory.hpp:77] Creating layer BatchNorm50
I0927 10:14:39.004181  3315 net.cpp:84] Creating Layer BatchNorm50
I0927 10:14:39.004184  3315 net.cpp:406] BatchNorm50 <- Convolution50
I0927 10:14:39.004189  3315 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0927 10:14:39.004330  3315 net.cpp:122] Setting up BatchNorm50
I0927 10:14:39.004334  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.004336  3315 net.cpp:137] Memory required for data: 858950800
I0927 10:14:39.004341  3315 layer_factory.hpp:77] Creating layer Scale50
I0927 10:14:39.004345  3315 net.cpp:84] Creating Layer Scale50
I0927 10:14:39.004348  3315 net.cpp:406] Scale50 <- Convolution50
I0927 10:14:39.004351  3315 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0927 10:14:39.004379  3315 layer_factory.hpp:77] Creating layer Scale50
I0927 10:14:39.004462  3315 net.cpp:122] Setting up Scale50
I0927 10:14:39.004467  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.012598  3315 net.cpp:137] Memory required for data: 860205200
I0927 10:14:39.012604  3315 layer_factory.hpp:77] Creating layer penlu48
I0927 10:14:39.012610  3315 net.cpp:84] Creating Layer penlu48
I0927 10:14:39.012614  3315 net.cpp:406] penlu48 <- Convolution50
I0927 10:14:39.012619  3315 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0927 10:14:39.012749  3315 net.cpp:122] Setting up penlu48
I0927 10:14:39.012754  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.012756  3315 net.cpp:137] Memory required for data: 861459600
I0927 10:14:39.012761  3315 layer_factory.hpp:77] Creating layer Convolution51
I0927 10:14:39.012768  3315 net.cpp:84] Creating Layer Convolution51
I0927 10:14:39.012771  3315 net.cpp:406] Convolution51 <- Convolution50
I0927 10:14:39.012775  3315 net.cpp:380] Convolution51 -> Convolution51
I0927 10:14:39.015069  3315 net.cpp:122] Setting up Convolution51
I0927 10:14:39.015079  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.015081  3315 net.cpp:137] Memory required for data: 862714000
I0927 10:14:39.015086  3315 layer_factory.hpp:77] Creating layer BatchNorm51
I0927 10:14:39.015091  3315 net.cpp:84] Creating Layer BatchNorm51
I0927 10:14:39.015094  3315 net.cpp:406] BatchNorm51 <- Convolution51
I0927 10:14:39.015099  3315 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0927 10:14:39.015290  3315 net.cpp:122] Setting up BatchNorm51
I0927 10:14:39.015295  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.015296  3315 net.cpp:137] Memory required for data: 863968400
I0927 10:14:39.015301  3315 layer_factory.hpp:77] Creating layer Scale51
I0927 10:14:39.015305  3315 net.cpp:84] Creating Layer Scale51
I0927 10:14:39.015308  3315 net.cpp:406] Scale51 <- Convolution51
I0927 10:14:39.015311  3315 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0927 10:14:39.015341  3315 layer_factory.hpp:77] Creating layer Scale51
I0927 10:14:39.015426  3315 net.cpp:122] Setting up Scale51
I0927 10:14:39.015431  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.015434  3315 net.cpp:137] Memory required for data: 865222800
I0927 10:14:39.015437  3315 layer_factory.hpp:77] Creating layer Eltwise24
I0927 10:14:39.015441  3315 net.cpp:84] Creating Layer Eltwise24
I0927 10:14:39.015444  3315 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0927 10:14:39.015447  3315 net.cpp:406] Eltwise24 <- Convolution51
I0927 10:14:39.015450  3315 net.cpp:380] Eltwise24 -> Eltwise24
I0927 10:14:39.015468  3315 net.cpp:122] Setting up Eltwise24
I0927 10:14:39.015472  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.015475  3315 net.cpp:137] Memory required for data: 866477200
I0927 10:14:39.015476  3315 layer_factory.hpp:77] Creating layer penlu49
I0927 10:14:39.015482  3315 net.cpp:84] Creating Layer penlu49
I0927 10:14:39.015485  3315 net.cpp:406] penlu49 <- Eltwise24
I0927 10:14:39.015487  3315 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0927 10:14:39.015606  3315 net.cpp:122] Setting up penlu49
I0927 10:14:39.015617  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.015620  3315 net.cpp:137] Memory required for data: 867731600
I0927 10:14:39.015625  3315 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0927 10:14:39.015630  3315 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0927 10:14:39.015631  3315 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0927 10:14:39.015635  3315 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0927 10:14:39.015640  3315 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0927 10:14:39.015666  3315 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0927 10:14:39.015669  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.015672  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.015674  3315 net.cpp:137] Memory required for data: 870240400
I0927 10:14:39.015676  3315 layer_factory.hpp:77] Creating layer Convolution52
I0927 10:14:39.015682  3315 net.cpp:84] Creating Layer Convolution52
I0927 10:14:39.015686  3315 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0927 10:14:39.015691  3315 net.cpp:380] Convolution52 -> Convolution52
I0927 10:14:39.017556  3315 net.cpp:122] Setting up Convolution52
I0927 10:14:39.017566  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.017568  3315 net.cpp:137] Memory required for data: 871494800
I0927 10:14:39.017573  3315 layer_factory.hpp:77] Creating layer BatchNorm52
I0927 10:14:39.017578  3315 net.cpp:84] Creating Layer BatchNorm52
I0927 10:14:39.017581  3315 net.cpp:406] BatchNorm52 <- Convolution52
I0927 10:14:39.017585  3315 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0927 10:14:39.017730  3315 net.cpp:122] Setting up BatchNorm52
I0927 10:14:39.017735  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.017736  3315 net.cpp:137] Memory required for data: 872749200
I0927 10:14:39.017741  3315 layer_factory.hpp:77] Creating layer Scale52
I0927 10:14:39.017745  3315 net.cpp:84] Creating Layer Scale52
I0927 10:14:39.017747  3315 net.cpp:406] Scale52 <- Convolution52
I0927 10:14:39.017751  3315 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0927 10:14:39.017781  3315 layer_factory.hpp:77] Creating layer Scale52
I0927 10:14:39.017863  3315 net.cpp:122] Setting up Scale52
I0927 10:14:39.017868  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.017869  3315 net.cpp:137] Memory required for data: 874003600
I0927 10:14:39.017874  3315 layer_factory.hpp:77] Creating layer penlu50
I0927 10:14:39.017879  3315 net.cpp:84] Creating Layer penlu50
I0927 10:14:39.017880  3315 net.cpp:406] penlu50 <- Convolution52
I0927 10:14:39.017884  3315 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0927 10:14:39.018002  3315 net.cpp:122] Setting up penlu50
I0927 10:14:39.018005  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.018007  3315 net.cpp:137] Memory required for data: 875258000
I0927 10:14:39.018050  3315 layer_factory.hpp:77] Creating layer Convolution53
I0927 10:14:39.018074  3315 net.cpp:84] Creating Layer Convolution53
I0927 10:14:39.018076  3315 net.cpp:406] Convolution53 <- Convolution52
I0927 10:14:39.018080  3315 net.cpp:380] Convolution53 -> Convolution53
I0927 10:14:39.020093  3315 net.cpp:122] Setting up Convolution53
I0927 10:14:39.020104  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.020107  3315 net.cpp:137] Memory required for data: 876512400
I0927 10:14:39.020112  3315 layer_factory.hpp:77] Creating layer BatchNorm53
I0927 10:14:39.020117  3315 net.cpp:84] Creating Layer BatchNorm53
I0927 10:14:39.020120  3315 net.cpp:406] BatchNorm53 <- Convolution53
I0927 10:14:39.020124  3315 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0927 10:14:39.020270  3315 net.cpp:122] Setting up BatchNorm53
I0927 10:14:39.020275  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.020277  3315 net.cpp:137] Memory required for data: 877766800
I0927 10:14:39.020282  3315 layer_factory.hpp:77] Creating layer Scale53
I0927 10:14:39.020287  3315 net.cpp:84] Creating Layer Scale53
I0927 10:14:39.020297  3315 net.cpp:406] Scale53 <- Convolution53
I0927 10:14:39.020299  3315 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0927 10:14:39.020331  3315 layer_factory.hpp:77] Creating layer Scale53
I0927 10:14:39.020413  3315 net.cpp:122] Setting up Scale53
I0927 10:14:39.020417  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.020419  3315 net.cpp:137] Memory required for data: 879021200
I0927 10:14:39.020423  3315 layer_factory.hpp:77] Creating layer Eltwise25
I0927 10:14:39.020428  3315 net.cpp:84] Creating Layer Eltwise25
I0927 10:14:39.020431  3315 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0927 10:14:39.020433  3315 net.cpp:406] Eltwise25 <- Convolution53
I0927 10:14:39.020437  3315 net.cpp:380] Eltwise25 -> Eltwise25
I0927 10:14:39.020454  3315 net.cpp:122] Setting up Eltwise25
I0927 10:14:39.020458  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.020459  3315 net.cpp:137] Memory required for data: 880275600
I0927 10:14:39.020462  3315 layer_factory.hpp:77] Creating layer penlu51
I0927 10:14:39.020467  3315 net.cpp:84] Creating Layer penlu51
I0927 10:14:39.020469  3315 net.cpp:406] penlu51 <- Eltwise25
I0927 10:14:39.020473  3315 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0927 10:14:39.020587  3315 net.cpp:122] Setting up penlu51
I0927 10:14:39.020591  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.020593  3315 net.cpp:137] Memory required for data: 881530000
I0927 10:14:39.020597  3315 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0927 10:14:39.020602  3315 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0927 10:14:39.020604  3315 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0927 10:14:39.020607  3315 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0927 10:14:39.020612  3315 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0927 10:14:39.020637  3315 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0927 10:14:39.020639  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.020642  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.020644  3315 net.cpp:137] Memory required for data: 884038800
I0927 10:14:39.020647  3315 layer_factory.hpp:77] Creating layer Convolution54
I0927 10:14:39.020653  3315 net.cpp:84] Creating Layer Convolution54
I0927 10:14:39.020654  3315 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0927 10:14:39.020659  3315 net.cpp:380] Convolution54 -> Convolution54
I0927 10:14:39.022857  3315 net.cpp:122] Setting up Convolution54
I0927 10:14:39.022866  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.022869  3315 net.cpp:137] Memory required for data: 885293200
I0927 10:14:39.022873  3315 layer_factory.hpp:77] Creating layer BatchNorm54
I0927 10:14:39.022879  3315 net.cpp:84] Creating Layer BatchNorm54
I0927 10:14:39.022882  3315 net.cpp:406] BatchNorm54 <- Convolution54
I0927 10:14:39.022887  3315 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0927 10:14:39.023036  3315 net.cpp:122] Setting up BatchNorm54
I0927 10:14:39.023041  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.023043  3315 net.cpp:137] Memory required for data: 886547600
I0927 10:14:39.023048  3315 layer_factory.hpp:77] Creating layer Scale54
I0927 10:14:39.023054  3315 net.cpp:84] Creating Layer Scale54
I0927 10:14:39.023057  3315 net.cpp:406] Scale54 <- Convolution54
I0927 10:14:39.023061  3315 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0927 10:14:39.023090  3315 layer_factory.hpp:77] Creating layer Scale54
I0927 10:14:39.023175  3315 net.cpp:122] Setting up Scale54
I0927 10:14:39.023180  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.023182  3315 net.cpp:137] Memory required for data: 887802000
I0927 10:14:39.023186  3315 layer_factory.hpp:77] Creating layer penlu52
I0927 10:14:39.023191  3315 net.cpp:84] Creating Layer penlu52
I0927 10:14:39.023195  3315 net.cpp:406] penlu52 <- Convolution54
I0927 10:14:39.023198  3315 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0927 10:14:39.023324  3315 net.cpp:122] Setting up penlu52
I0927 10:14:39.023329  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.023331  3315 net.cpp:137] Memory required for data: 889056400
I0927 10:14:39.023336  3315 layer_factory.hpp:77] Creating layer Convolution55
I0927 10:14:39.023344  3315 net.cpp:84] Creating Layer Convolution55
I0927 10:14:39.023345  3315 net.cpp:406] Convolution55 <- Convolution54
I0927 10:14:39.023350  3315 net.cpp:380] Convolution55 -> Convolution55
I0927 10:14:39.025372  3315 net.cpp:122] Setting up Convolution55
I0927 10:14:39.025380  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.025383  3315 net.cpp:137] Memory required for data: 890310800
I0927 10:14:39.025388  3315 layer_factory.hpp:77] Creating layer BatchNorm55
I0927 10:14:39.025393  3315 net.cpp:84] Creating Layer BatchNorm55
I0927 10:14:39.025394  3315 net.cpp:406] BatchNorm55 <- Convolution55
I0927 10:14:39.025399  3315 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0927 10:14:39.025553  3315 net.cpp:122] Setting up BatchNorm55
I0927 10:14:39.025558  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.025560  3315 net.cpp:137] Memory required for data: 891565200
I0927 10:14:39.025564  3315 layer_factory.hpp:77] Creating layer Scale55
I0927 10:14:39.025568  3315 net.cpp:84] Creating Layer Scale55
I0927 10:14:39.025571  3315 net.cpp:406] Scale55 <- Convolution55
I0927 10:14:39.025575  3315 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0927 10:14:39.025604  3315 layer_factory.hpp:77] Creating layer Scale55
I0927 10:14:39.025689  3315 net.cpp:122] Setting up Scale55
I0927 10:14:39.025693  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.025696  3315 net.cpp:137] Memory required for data: 892819600
I0927 10:14:39.025699  3315 layer_factory.hpp:77] Creating layer Eltwise26
I0927 10:14:39.025703  3315 net.cpp:84] Creating Layer Eltwise26
I0927 10:14:39.025705  3315 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0927 10:14:39.025708  3315 net.cpp:406] Eltwise26 <- Convolution55
I0927 10:14:39.025713  3315 net.cpp:380] Eltwise26 -> Eltwise26
I0927 10:14:39.025730  3315 net.cpp:122] Setting up Eltwise26
I0927 10:14:39.025734  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.025737  3315 net.cpp:137] Memory required for data: 894074000
I0927 10:14:39.025738  3315 layer_factory.hpp:77] Creating layer penlu53
I0927 10:14:39.025743  3315 net.cpp:84] Creating Layer penlu53
I0927 10:14:39.025745  3315 net.cpp:406] penlu53 <- Eltwise26
I0927 10:14:39.025750  3315 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0927 10:14:39.025872  3315 net.cpp:122] Setting up penlu53
I0927 10:14:39.025877  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.025879  3315 net.cpp:137] Memory required for data: 895328400
I0927 10:14:39.025884  3315 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0927 10:14:39.025887  3315 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0927 10:14:39.025890  3315 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0927 10:14:39.025893  3315 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0927 10:14:39.025897  3315 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0927 10:14:39.025923  3315 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0927 10:14:39.025926  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.025929  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.025931  3315 net.cpp:137] Memory required for data: 897837200
I0927 10:14:39.025933  3315 layer_factory.hpp:77] Creating layer Convolution56
I0927 10:14:39.025940  3315 net.cpp:84] Creating Layer Convolution56
I0927 10:14:39.025943  3315 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0927 10:14:39.025946  3315 net.cpp:380] Convolution56 -> Convolution56
I0927 10:14:39.027662  3315 net.cpp:122] Setting up Convolution56
I0927 10:14:39.027669  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.027673  3315 net.cpp:137] Memory required for data: 899091600
I0927 10:14:39.027683  3315 layer_factory.hpp:77] Creating layer BatchNorm56
I0927 10:14:39.027688  3315 net.cpp:84] Creating Layer BatchNorm56
I0927 10:14:39.027689  3315 net.cpp:406] BatchNorm56 <- Convolution56
I0927 10:14:39.027694  3315 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0927 10:14:39.027842  3315 net.cpp:122] Setting up BatchNorm56
I0927 10:14:39.027846  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.027848  3315 net.cpp:137] Memory required for data: 900346000
I0927 10:14:39.027853  3315 layer_factory.hpp:77] Creating layer Scale56
I0927 10:14:39.027858  3315 net.cpp:84] Creating Layer Scale56
I0927 10:14:39.027859  3315 net.cpp:406] Scale56 <- Convolution56
I0927 10:14:39.027863  3315 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0927 10:14:39.027891  3315 layer_factory.hpp:77] Creating layer Scale56
I0927 10:14:39.043534  3315 net.cpp:122] Setting up Scale56
I0927 10:14:39.043542  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.043545  3315 net.cpp:137] Memory required for data: 901600400
I0927 10:14:39.043550  3315 layer_factory.hpp:77] Creating layer penlu54
I0927 10:14:39.043556  3315 net.cpp:84] Creating Layer penlu54
I0927 10:14:39.043560  3315 net.cpp:406] penlu54 <- Convolution56
I0927 10:14:39.043565  3315 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0927 10:14:39.043699  3315 net.cpp:122] Setting up penlu54
I0927 10:14:39.043704  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.043707  3315 net.cpp:137] Memory required for data: 902854800
I0927 10:14:39.043712  3315 layer_factory.hpp:77] Creating layer Convolution57
I0927 10:14:39.043720  3315 net.cpp:84] Creating Layer Convolution57
I0927 10:14:39.043723  3315 net.cpp:406] Convolution57 <- Convolution56
I0927 10:14:39.043727  3315 net.cpp:380] Convolution57 -> Convolution57
I0927 10:14:39.045635  3315 net.cpp:122] Setting up Convolution57
I0927 10:14:39.045644  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.045646  3315 net.cpp:137] Memory required for data: 904109200
I0927 10:14:39.045651  3315 layer_factory.hpp:77] Creating layer BatchNorm57
I0927 10:14:39.045656  3315 net.cpp:84] Creating Layer BatchNorm57
I0927 10:14:39.045658  3315 net.cpp:406] BatchNorm57 <- Convolution57
I0927 10:14:39.045663  3315 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0927 10:14:39.045816  3315 net.cpp:122] Setting up BatchNorm57
I0927 10:14:39.045821  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.045824  3315 net.cpp:137] Memory required for data: 905363600
I0927 10:14:39.045828  3315 layer_factory.hpp:77] Creating layer Scale57
I0927 10:14:39.045842  3315 net.cpp:84] Creating Layer Scale57
I0927 10:14:39.045845  3315 net.cpp:406] Scale57 <- Convolution57
I0927 10:14:39.045850  3315 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0927 10:14:39.045908  3315 layer_factory.hpp:77] Creating layer Scale57
I0927 10:14:39.046007  3315 net.cpp:122] Setting up Scale57
I0927 10:14:39.046012  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.046015  3315 net.cpp:137] Memory required for data: 906618000
I0927 10:14:39.046018  3315 layer_factory.hpp:77] Creating layer Eltwise27
I0927 10:14:39.046022  3315 net.cpp:84] Creating Layer Eltwise27
I0927 10:14:39.046025  3315 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0927 10:14:39.046027  3315 net.cpp:406] Eltwise27 <- Convolution57
I0927 10:14:39.046042  3315 net.cpp:380] Eltwise27 -> Eltwise27
I0927 10:14:39.046072  3315 net.cpp:122] Setting up Eltwise27
I0927 10:14:39.046075  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.046077  3315 net.cpp:137] Memory required for data: 907872400
I0927 10:14:39.046079  3315 layer_factory.hpp:77] Creating layer penlu55
I0927 10:14:39.046083  3315 net.cpp:84] Creating Layer penlu55
I0927 10:14:39.046087  3315 net.cpp:406] penlu55 <- Eltwise27
I0927 10:14:39.046090  3315 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0927 10:14:39.046217  3315 net.cpp:122] Setting up penlu55
I0927 10:14:39.046222  3315 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0927 10:14:39.046231  3315 net.cpp:137] Memory required for data: 909126800
I0927 10:14:39.046236  3315 layer_factory.hpp:77] Creating layer Pooling1
I0927 10:14:39.046241  3315 net.cpp:84] Creating Layer Pooling1
I0927 10:14:39.046243  3315 net.cpp:406] Pooling1 <- Eltwise27
I0927 10:14:39.046247  3315 net.cpp:380] Pooling1 -> Pooling1
I0927 10:14:39.046728  3315 net.cpp:122] Setting up Pooling1
I0927 10:14:39.046736  3315 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0927 10:14:39.046739  3315 net.cpp:137] Memory required for data: 909152400
I0927 10:14:39.046741  3315 layer_factory.hpp:77] Creating layer InnerProduct1
I0927 10:14:39.046751  3315 net.cpp:84] Creating Layer InnerProduct1
I0927 10:14:39.046754  3315 net.cpp:406] InnerProduct1 <- Pooling1
I0927 10:14:39.046759  3315 net.cpp:380] InnerProduct1 -> InnerProduct1
I0927 10:14:39.046864  3315 net.cpp:122] Setting up InnerProduct1
I0927 10:14:39.046869  3315 net.cpp:129] Top shape: 100 10 (1000)
I0927 10:14:39.046870  3315 net.cpp:137] Memory required for data: 909156400
I0927 10:14:39.046875  3315 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 10:14:39.046880  3315 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0927 10:14:39.046881  3315 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0927 10:14:39.046885  3315 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0927 10:14:39.046888  3315 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0927 10:14:39.046895  3315 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 10:14:39.047116  3315 net.cpp:122] Setting up SoftmaxWithLoss1
I0927 10:14:39.047133  3315 net.cpp:129] Top shape: (1)
I0927 10:14:39.047135  3315 net.cpp:132]     with loss weight 1
I0927 10:14:39.047168  3315 net.cpp:137] Memory required for data: 909156404
I0927 10:14:39.047169  3315 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0927 10:14:39.047173  3315 net.cpp:198] InnerProduct1 needs backward computation.
I0927 10:14:39.047174  3315 net.cpp:198] Pooling1 needs backward computation.
I0927 10:14:39.047176  3315 net.cpp:198] penlu55 needs backward computation.
I0927 10:14:39.047178  3315 net.cpp:198] Eltwise27 needs backward computation.
I0927 10:14:39.047181  3315 net.cpp:198] Scale57 needs backward computation.
I0927 10:14:39.047193  3315 net.cpp:198] BatchNorm57 needs backward computation.
I0927 10:14:39.047194  3315 net.cpp:198] Convolution57 needs backward computation.
I0927 10:14:39.047196  3315 net.cpp:198] penlu54 needs backward computation.
I0927 10:14:39.047199  3315 net.cpp:198] Scale56 needs backward computation.
I0927 10:14:39.047215  3315 net.cpp:198] BatchNorm56 needs backward computation.
I0927 10:14:39.047217  3315 net.cpp:198] Convolution56 needs backward computation.
I0927 10:14:39.047219  3315 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0927 10:14:39.047221  3315 net.cpp:198] penlu53 needs backward computation.
I0927 10:14:39.047232  3315 net.cpp:198] Eltwise26 needs backward computation.
I0927 10:14:39.047235  3315 net.cpp:198] Scale55 needs backward computation.
I0927 10:14:39.047237  3315 net.cpp:198] BatchNorm55 needs backward computation.
I0927 10:14:39.047240  3315 net.cpp:198] Convolution55 needs backward computation.
I0927 10:14:39.047241  3315 net.cpp:198] penlu52 needs backward computation.
I0927 10:14:39.047243  3315 net.cpp:198] Scale54 needs backward computation.
I0927 10:14:39.047245  3315 net.cpp:198] BatchNorm54 needs backward computation.
I0927 10:14:39.047246  3315 net.cpp:198] Convolution54 needs backward computation.
I0927 10:14:39.047248  3315 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0927 10:14:39.047251  3315 net.cpp:198] penlu51 needs backward computation.
I0927 10:14:39.047253  3315 net.cpp:198] Eltwise25 needs backward computation.
I0927 10:14:39.047255  3315 net.cpp:198] Scale53 needs backward computation.
I0927 10:14:39.047257  3315 net.cpp:198] BatchNorm53 needs backward computation.
I0927 10:14:39.047260  3315 net.cpp:198] Convolution53 needs backward computation.
I0927 10:14:39.047271  3315 net.cpp:198] penlu50 needs backward computation.
I0927 10:14:39.047279  3315 net.cpp:198] Scale52 needs backward computation.
I0927 10:14:39.047282  3315 net.cpp:198] BatchNorm52 needs backward computation.
I0927 10:14:39.047284  3315 net.cpp:198] Convolution52 needs backward computation.
I0927 10:14:39.047286  3315 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0927 10:14:39.047288  3315 net.cpp:198] penlu49 needs backward computation.
I0927 10:14:39.047291  3315 net.cpp:198] Eltwise24 needs backward computation.
I0927 10:14:39.047293  3315 net.cpp:198] Scale51 needs backward computation.
I0927 10:14:39.047296  3315 net.cpp:198] BatchNorm51 needs backward computation.
I0927 10:14:39.047297  3315 net.cpp:198] Convolution51 needs backward computation.
I0927 10:14:39.047299  3315 net.cpp:198] penlu48 needs backward computation.
I0927 10:14:39.047302  3315 net.cpp:198] Scale50 needs backward computation.
I0927 10:14:39.047304  3315 net.cpp:198] BatchNorm50 needs backward computation.
I0927 10:14:39.047307  3315 net.cpp:198] Convolution50 needs backward computation.
I0927 10:14:39.047308  3315 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0927 10:14:39.047310  3315 net.cpp:198] penlu47 needs backward computation.
I0927 10:14:39.047312  3315 net.cpp:198] Eltwise23 needs backward computation.
I0927 10:14:39.047317  3315 net.cpp:198] Scale49 needs backward computation.
I0927 10:14:39.047320  3315 net.cpp:198] BatchNorm49 needs backward computation.
I0927 10:14:39.047322  3315 net.cpp:198] Convolution49 needs backward computation.
I0927 10:14:39.047324  3315 net.cpp:198] penlu46 needs backward computation.
I0927 10:14:39.047327  3315 net.cpp:198] Scale48 needs backward computation.
I0927 10:14:39.047328  3315 net.cpp:198] BatchNorm48 needs backward computation.
I0927 10:14:39.047330  3315 net.cpp:198] Convolution48 needs backward computation.
I0927 10:14:39.047333  3315 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0927 10:14:39.047335  3315 net.cpp:198] penlu45 needs backward computation.
I0927 10:14:39.047338  3315 net.cpp:198] Eltwise22 needs backward computation.
I0927 10:14:39.047340  3315 net.cpp:198] Scale47 needs backward computation.
I0927 10:14:39.047343  3315 net.cpp:198] BatchNorm47 needs backward computation.
I0927 10:14:39.047344  3315 net.cpp:198] Convolution47 needs backward computation.
I0927 10:14:39.047348  3315 net.cpp:198] penlu44 needs backward computation.
I0927 10:14:39.047349  3315 net.cpp:198] Scale46 needs backward computation.
I0927 10:14:39.047351  3315 net.cpp:198] BatchNorm46 needs backward computation.
I0927 10:14:39.047353  3315 net.cpp:198] Convolution46 needs backward computation.
I0927 10:14:39.047355  3315 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0927 10:14:39.047358  3315 net.cpp:198] penlu43 needs backward computation.
I0927 10:14:39.047360  3315 net.cpp:198] Eltwise21 needs backward computation.
I0927 10:14:39.047363  3315 net.cpp:198] Scale45 needs backward computation.
I0927 10:14:39.047364  3315 net.cpp:198] BatchNorm45 needs backward computation.
I0927 10:14:39.047368  3315 net.cpp:198] Convolution45 needs backward computation.
I0927 10:14:39.047369  3315 net.cpp:198] penlu42 needs backward computation.
I0927 10:14:39.047371  3315 net.cpp:198] Scale44 needs backward computation.
I0927 10:14:39.047374  3315 net.cpp:198] BatchNorm44 needs backward computation.
I0927 10:14:39.047376  3315 net.cpp:198] Convolution44 needs backward computation.
I0927 10:14:39.047379  3315 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0927 10:14:39.047380  3315 net.cpp:198] penlu41 needs backward computation.
I0927 10:14:39.047384  3315 net.cpp:198] Eltwise20 needs backward computation.
I0927 10:14:39.047385  3315 net.cpp:198] Scale43 needs backward computation.
I0927 10:14:39.047389  3315 net.cpp:198] BatchNorm43 needs backward computation.
I0927 10:14:39.047400  3315 net.cpp:198] Convolution43 needs backward computation.
I0927 10:14:39.047402  3315 net.cpp:198] penlu40 needs backward computation.
I0927 10:14:39.047405  3315 net.cpp:198] Scale42 needs backward computation.
I0927 10:14:39.047418  3315 net.cpp:198] BatchNorm42 needs backward computation.
I0927 10:14:39.047421  3315 net.cpp:198] Convolution42 needs backward computation.
I0927 10:14:39.047423  3315 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0927 10:14:39.047426  3315 net.cpp:198] penlu39 needs backward computation.
I0927 10:14:39.047428  3315 net.cpp:198] Eltwise19 needs backward computation.
I0927 10:14:39.047431  3315 net.cpp:198] Scale41 needs backward computation.
I0927 10:14:39.047433  3315 net.cpp:198] BatchNorm41 needs backward computation.
I0927 10:14:39.047446  3315 net.cpp:198] Convolution41 needs backward computation.
I0927 10:14:39.047448  3315 net.cpp:198] penlu38 needs backward computation.
I0927 10:14:39.047451  3315 net.cpp:198] Scale40 needs backward computation.
I0927 10:14:39.047452  3315 net.cpp:198] BatchNorm40 needs backward computation.
I0927 10:14:39.047454  3315 net.cpp:198] Convolution40 needs backward computation.
I0927 10:14:39.047457  3315 net.cpp:198] Scale39 needs backward computation.
I0927 10:14:39.047459  3315 net.cpp:198] BatchNorm39 needs backward computation.
I0927 10:14:39.047472  3315 net.cpp:198] Convolution39 needs backward computation.
I0927 10:14:39.047473  3315 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0927 10:14:39.047475  3315 net.cpp:198] penlu37 needs backward computation.
I0927 10:14:39.047478  3315 net.cpp:198] Eltwise18 needs backward computation.
I0927 10:14:39.047490  3315 net.cpp:198] Scale38 needs backward computation.
I0927 10:14:39.047492  3315 net.cpp:198] BatchNorm38 needs backward computation.
I0927 10:14:39.047495  3315 net.cpp:198] Convolution38 needs backward computation.
I0927 10:14:39.047497  3315 net.cpp:198] penlu36 needs backward computation.
I0927 10:14:39.047499  3315 net.cpp:198] Scale37 needs backward computation.
I0927 10:14:39.047502  3315 net.cpp:198] BatchNorm37 needs backward computation.
I0927 10:14:39.047503  3315 net.cpp:198] Convolution37 needs backward computation.
I0927 10:14:39.047505  3315 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0927 10:14:39.047508  3315 net.cpp:198] penlu35 needs backward computation.
I0927 10:14:39.047510  3315 net.cpp:198] Eltwise17 needs backward computation.
I0927 10:14:39.047513  3315 net.cpp:198] Scale36 needs backward computation.
I0927 10:14:39.047515  3315 net.cpp:198] BatchNorm36 needs backward computation.
I0927 10:14:39.047518  3315 net.cpp:198] Convolution36 needs backward computation.
I0927 10:14:39.047519  3315 net.cpp:198] penlu34 needs backward computation.
I0927 10:14:39.047521  3315 net.cpp:198] Scale35 needs backward computation.
I0927 10:14:39.047524  3315 net.cpp:198] BatchNorm35 needs backward computation.
I0927 10:14:39.047526  3315 net.cpp:198] Convolution35 needs backward computation.
I0927 10:14:39.047528  3315 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0927 10:14:39.047531  3315 net.cpp:198] penlu33 needs backward computation.
I0927 10:14:39.047533  3315 net.cpp:198] Eltwise16 needs backward computation.
I0927 10:14:39.047536  3315 net.cpp:198] Scale34 needs backward computation.
I0927 10:14:39.047538  3315 net.cpp:198] BatchNorm34 needs backward computation.
I0927 10:14:39.047540  3315 net.cpp:198] Convolution34 needs backward computation.
I0927 10:14:39.047544  3315 net.cpp:198] penlu32 needs backward computation.
I0927 10:14:39.047545  3315 net.cpp:198] Scale33 needs backward computation.
I0927 10:14:39.047547  3315 net.cpp:198] BatchNorm33 needs backward computation.
I0927 10:14:39.047549  3315 net.cpp:198] Convolution33 needs backward computation.
I0927 10:14:39.047551  3315 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0927 10:14:39.047554  3315 net.cpp:198] penlu31 needs backward computation.
I0927 10:14:39.047556  3315 net.cpp:198] Eltwise15 needs backward computation.
I0927 10:14:39.047559  3315 net.cpp:198] Scale32 needs backward computation.
I0927 10:14:39.047561  3315 net.cpp:198] BatchNorm32 needs backward computation.
I0927 10:14:39.047566  3315 net.cpp:198] Convolution32 needs backward computation.
I0927 10:14:39.047569  3315 net.cpp:198] penlu30 needs backward computation.
I0927 10:14:39.047571  3315 net.cpp:198] Scale31 needs backward computation.
I0927 10:14:39.047574  3315 net.cpp:198] BatchNorm31 needs backward computation.
I0927 10:14:39.047575  3315 net.cpp:198] Convolution31 needs backward computation.
I0927 10:14:39.047577  3315 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0927 10:14:39.047580  3315 net.cpp:198] penlu29 needs backward computation.
I0927 10:14:39.047582  3315 net.cpp:198] Eltwise14 needs backward computation.
I0927 10:14:39.047585  3315 net.cpp:198] Scale30 needs backward computation.
I0927 10:14:39.074337  3315 net.cpp:198] BatchNorm30 needs backward computation.
I0927 10:14:39.074345  3315 net.cpp:198] Convolution30 needs backward computation.
I0927 10:14:39.074348  3315 net.cpp:198] penlu28 needs backward computation.
I0927 10:14:39.074350  3315 net.cpp:198] Scale29 needs backward computation.
I0927 10:14:39.074353  3315 net.cpp:198] BatchNorm29 needs backward computation.
I0927 10:14:39.074355  3315 net.cpp:198] Convolution29 needs backward computation.
I0927 10:14:39.074359  3315 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0927 10:14:39.074362  3315 net.cpp:198] penlu27 needs backward computation.
I0927 10:14:39.074364  3315 net.cpp:198] Eltwise13 needs backward computation.
I0927 10:14:39.074368  3315 net.cpp:198] Scale28 needs backward computation.
I0927 10:14:39.074370  3315 net.cpp:198] BatchNorm28 needs backward computation.
I0927 10:14:39.074373  3315 net.cpp:198] Convolution28 needs backward computation.
I0927 10:14:39.074375  3315 net.cpp:198] penlu26 needs backward computation.
I0927 10:14:39.074378  3315 net.cpp:198] Scale27 needs backward computation.
I0927 10:14:39.074380  3315 net.cpp:198] BatchNorm27 needs backward computation.
I0927 10:14:39.074383  3315 net.cpp:198] Convolution27 needs backward computation.
I0927 10:14:39.074385  3315 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0927 10:14:39.074388  3315 net.cpp:198] penlu25 needs backward computation.
I0927 10:14:39.074390  3315 net.cpp:198] Eltwise12 needs backward computation.
I0927 10:14:39.074393  3315 net.cpp:198] Scale26 needs backward computation.
I0927 10:14:39.074396  3315 net.cpp:198] BatchNorm26 needs backward computation.
I0927 10:14:39.074398  3315 net.cpp:198] Convolution26 needs backward computation.
I0927 10:14:39.074401  3315 net.cpp:198] penlu24 needs backward computation.
I0927 10:14:39.074404  3315 net.cpp:198] Scale25 needs backward computation.
I0927 10:14:39.074405  3315 net.cpp:198] BatchNorm25 needs backward computation.
I0927 10:14:39.074409  3315 net.cpp:198] Convolution25 needs backward computation.
I0927 10:14:39.074410  3315 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0927 10:14:39.074414  3315 net.cpp:198] penlu23 needs backward computation.
I0927 10:14:39.074415  3315 net.cpp:198] Eltwise11 needs backward computation.
I0927 10:14:39.074419  3315 net.cpp:198] Scale24 needs backward computation.
I0927 10:14:39.074421  3315 net.cpp:198] BatchNorm24 needs backward computation.
I0927 10:14:39.074424  3315 net.cpp:198] Convolution24 needs backward computation.
I0927 10:14:39.074425  3315 net.cpp:198] penlu22 needs backward computation.
I0927 10:14:39.074429  3315 net.cpp:198] Scale23 needs backward computation.
I0927 10:14:39.074430  3315 net.cpp:198] BatchNorm23 needs backward computation.
I0927 10:14:39.074432  3315 net.cpp:198] Convolution23 needs backward computation.
I0927 10:14:39.074435  3315 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0927 10:14:39.074439  3315 net.cpp:198] penlu21 needs backward computation.
I0927 10:14:39.074440  3315 net.cpp:198] Eltwise10 needs backward computation.
I0927 10:14:39.074443  3315 net.cpp:198] Scale22 needs backward computation.
I0927 10:14:39.074446  3315 net.cpp:198] BatchNorm22 needs backward computation.
I0927 10:14:39.074448  3315 net.cpp:198] Convolution22 needs backward computation.
I0927 10:14:39.074460  3315 net.cpp:198] penlu20 needs backward computation.
I0927 10:14:39.074462  3315 net.cpp:198] Scale21 needs backward computation.
I0927 10:14:39.074465  3315 net.cpp:198] BatchNorm21 needs backward computation.
I0927 10:14:39.074467  3315 net.cpp:198] Convolution21 needs backward computation.
I0927 10:14:39.074470  3315 net.cpp:198] Scale20 needs backward computation.
I0927 10:14:39.074472  3315 net.cpp:198] BatchNorm20 needs backward computation.
I0927 10:14:39.074475  3315 net.cpp:198] Convolution20 needs backward computation.
I0927 10:14:39.074477  3315 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0927 10:14:39.074481  3315 net.cpp:198] penlu19 needs backward computation.
I0927 10:14:39.074483  3315 net.cpp:198] Eltwise9 needs backward computation.
I0927 10:14:39.074486  3315 net.cpp:198] Scale19 needs backward computation.
I0927 10:14:39.074488  3315 net.cpp:198] BatchNorm19 needs backward computation.
I0927 10:14:39.074491  3315 net.cpp:198] Convolution19 needs backward computation.
I0927 10:14:39.074493  3315 net.cpp:198] penlu18 needs backward computation.
I0927 10:14:39.074496  3315 net.cpp:198] Scale18 needs backward computation.
I0927 10:14:39.074498  3315 net.cpp:198] BatchNorm18 needs backward computation.
I0927 10:14:39.074501  3315 net.cpp:198] Convolution18 needs backward computation.
I0927 10:14:39.074503  3315 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0927 10:14:39.074506  3315 net.cpp:198] penlu17 needs backward computation.
I0927 10:14:39.074508  3315 net.cpp:198] Eltwise8 needs backward computation.
I0927 10:14:39.074512  3315 net.cpp:198] Scale17 needs backward computation.
I0927 10:14:39.074514  3315 net.cpp:198] BatchNorm17 needs backward computation.
I0927 10:14:39.074517  3315 net.cpp:198] Convolution17 needs backward computation.
I0927 10:14:39.074519  3315 net.cpp:198] penlu16 needs backward computation.
I0927 10:14:39.074527  3315 net.cpp:198] Scale16 needs backward computation.
I0927 10:14:39.074530  3315 net.cpp:198] BatchNorm16 needs backward computation.
I0927 10:14:39.074532  3315 net.cpp:198] Convolution16 needs backward computation.
I0927 10:14:39.074535  3315 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0927 10:14:39.074538  3315 net.cpp:198] penlu15 needs backward computation.
I0927 10:14:39.074540  3315 net.cpp:198] Eltwise7 needs backward computation.
I0927 10:14:39.074543  3315 net.cpp:198] Scale15 needs backward computation.
I0927 10:14:39.074545  3315 net.cpp:198] BatchNorm15 needs backward computation.
I0927 10:14:39.074548  3315 net.cpp:198] Convolution15 needs backward computation.
I0927 10:14:39.074550  3315 net.cpp:198] penlu14 needs backward computation.
I0927 10:14:39.074553  3315 net.cpp:198] Scale14 needs backward computation.
I0927 10:14:39.074555  3315 net.cpp:198] BatchNorm14 needs backward computation.
I0927 10:14:39.074558  3315 net.cpp:198] Convolution14 needs backward computation.
I0927 10:14:39.074563  3315 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0927 10:14:39.074564  3315 net.cpp:198] penlu13 needs backward computation.
I0927 10:14:39.074568  3315 net.cpp:198] Eltwise6 needs backward computation.
I0927 10:14:39.074569  3315 net.cpp:198] Scale13 needs backward computation.
I0927 10:14:39.074573  3315 net.cpp:198] BatchNorm13 needs backward computation.
I0927 10:14:39.074574  3315 net.cpp:198] Convolution13 needs backward computation.
I0927 10:14:39.074578  3315 net.cpp:198] penlu12 needs backward computation.
I0927 10:14:39.074579  3315 net.cpp:198] Scale12 needs backward computation.
I0927 10:14:39.074581  3315 net.cpp:198] BatchNorm12 needs backward computation.
I0927 10:14:39.074584  3315 net.cpp:198] Convolution12 needs backward computation.
I0927 10:14:39.074586  3315 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0927 10:14:39.074589  3315 net.cpp:198] penlu11 needs backward computation.
I0927 10:14:39.074591  3315 net.cpp:198] Eltwise5 needs backward computation.
I0927 10:14:39.074599  3315 net.cpp:198] Scale11 needs backward computation.
I0927 10:14:39.074601  3315 net.cpp:198] BatchNorm11 needs backward computation.
I0927 10:14:39.074604  3315 net.cpp:198] Convolution11 needs backward computation.
I0927 10:14:39.074606  3315 net.cpp:198] penlu10 needs backward computation.
I0927 10:14:39.074609  3315 net.cpp:198] Scale10 needs backward computation.
I0927 10:14:39.074610  3315 net.cpp:198] BatchNorm10 needs backward computation.
I0927 10:14:39.074614  3315 net.cpp:198] Convolution10 needs backward computation.
I0927 10:14:39.074615  3315 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0927 10:14:39.076906  3315 net.cpp:198] penlu9 needs backward computation.
I0927 10:14:39.076915  3315 net.cpp:198] Eltwise4 needs backward computation.
I0927 10:14:39.076917  3315 net.cpp:198] Scale9 needs backward computation.
I0927 10:14:39.076920  3315 net.cpp:198] BatchNorm9 needs backward computation.
I0927 10:14:39.076923  3315 net.cpp:198] Convolution9 needs backward computation.
I0927 10:14:39.076925  3315 net.cpp:198] penlu8 needs backward computation.
I0927 10:14:39.076927  3315 net.cpp:198] Scale8 needs backward computation.
I0927 10:14:39.076930  3315 net.cpp:198] BatchNorm8 needs backward computation.
I0927 10:14:39.076932  3315 net.cpp:198] Convolution8 needs backward computation.
I0927 10:14:39.076936  3315 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0927 10:14:39.076937  3315 net.cpp:198] penlu7 needs backward computation.
I0927 10:14:39.076941  3315 net.cpp:198] Eltwise3 needs backward computation.
I0927 10:14:39.076943  3315 net.cpp:198] Scale7 needs backward computation.
I0927 10:14:39.076946  3315 net.cpp:198] BatchNorm7 needs backward computation.
I0927 10:14:39.076947  3315 net.cpp:198] Convolution7 needs backward computation.
I0927 10:14:39.076951  3315 net.cpp:198] penlu6 needs backward computation.
I0927 10:14:39.076952  3315 net.cpp:198] Scale6 needs backward computation.
I0927 10:14:39.076956  3315 net.cpp:198] BatchNorm6 needs backward computation.
I0927 10:14:39.076957  3315 net.cpp:198] Convolution6 needs backward computation.
I0927 10:14:39.076959  3315 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0927 10:14:39.076962  3315 net.cpp:198] penlu5 needs backward computation.
I0927 10:14:39.076964  3315 net.cpp:198] Eltwise2 needs backward computation.
I0927 10:14:39.076967  3315 net.cpp:198] Scale5 needs backward computation.
I0927 10:14:39.076970  3315 net.cpp:198] BatchNorm5 needs backward computation.
I0927 10:14:39.076972  3315 net.cpp:198] Convolution5 needs backward computation.
I0927 10:14:39.076975  3315 net.cpp:198] penlu4 needs backward computation.
I0927 10:14:39.076977  3315 net.cpp:198] Scale4 needs backward computation.
I0927 10:14:39.076979  3315 net.cpp:198] BatchNorm4 needs backward computation.
I0927 10:14:39.076982  3315 net.cpp:198] Convolution4 needs backward computation.
I0927 10:14:39.076984  3315 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0927 10:14:39.076987  3315 net.cpp:198] penlu3 needs backward computation.
I0927 10:14:39.076989  3315 net.cpp:198] Eltwise1 needs backward computation.
I0927 10:14:39.076992  3315 net.cpp:198] Scale3 needs backward computation.
I0927 10:14:39.076994  3315 net.cpp:198] BatchNorm3 needs backward computation.
I0927 10:14:39.076997  3315 net.cpp:198] Convolution3 needs backward computation.
I0927 10:14:39.076999  3315 net.cpp:198] penlu2 needs backward computation.
I0927 10:14:39.077002  3315 net.cpp:198] Scale2 needs backward computation.
I0927 10:14:39.077004  3315 net.cpp:198] BatchNorm2 needs backward computation.
I0927 10:14:39.077006  3315 net.cpp:198] Convolution2 needs backward computation.
I0927 10:14:39.077009  3315 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0927 10:14:39.077011  3315 net.cpp:198] penlu1 needs backward computation.
I0927 10:14:39.077014  3315 net.cpp:198] Scale1 needs backward computation.
I0927 10:14:39.077016  3315 net.cpp:198] BatchNorm1 needs backward computation.
I0927 10:14:39.077018  3315 net.cpp:198] Convolution1 needs backward computation.
I0927 10:14:39.077028  3315 net.cpp:200] Data1 does not need backward computation.
I0927 10:14:39.077030  3315 net.cpp:242] This network produces output SoftmaxWithLoss1
I0927 10:14:39.077126  3315 net.cpp:255] Network initialization done.
I0927 10:14:39.081779  3315 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0927 10:14:39.081791  3315 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0927 10:14:39.081796  3315 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56_penlu_train_test.prototxt
I0927 10:14:39.081989  3315 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0927 10:14:39.083283  3315 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      
I0927 10:14:39.138942  3315 layer_factory.hpp:77] Creating layer Data1
I0927 10:14:39.138993  3315 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0927 10:14:39.139005  3315 net.cpp:84] Creating Layer Data1
I0927 10:14:39.139009  3315 net.cpp:380] Data1 -> Data1
I0927 10:14:39.139019  3315 net.cpp:380] Data1 -> Data2
I0927 10:14:39.139024  3315 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0927 10:14:39.139202  3315 data_layer.cpp:45] output data size: 100,3,32,32
I0927 10:14:39.143257  3315 net.cpp:122] Setting up Data1
I0927 10:14:39.143280  3315 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0927 10:14:39.143283  3315 net.cpp:129] Top shape: 100 (100)
I0927 10:14:39.143286  3315 net.cpp:137] Memory required for data: 1229200
I0927 10:14:39.143290  3315 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0927 10:14:39.143301  3315 net.cpp:84] Creating Layer Data2_Data1_1_split
I0927 10:14:39.143304  3315 net.cpp:406] Data2_Data1_1_split <- Data2
I0927 10:14:39.143308  3315 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0927 10:14:39.143316  3315 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0927 10:14:39.143362  3315 net.cpp:122] Setting up Data2_Data1_1_split
I0927 10:14:39.143368  3315 net.cpp:129] Top shape: 100 (100)
I0927 10:14:39.143370  3315 net.cpp:129] Top shape: 100 (100)
I0927 10:14:39.143373  3315 net.cpp:137] Memory required for data: 1230000
I0927 10:14:39.143374  3315 layer_factory.hpp:77] Creating layer Convolution1
I0927 10:14:39.143384  3315 net.cpp:84] Creating Layer Convolution1
I0927 10:14:39.143386  3315 net.cpp:406] Convolution1 <- Data1
I0927 10:14:39.143391  3315 net.cpp:380] Convolution1 -> Convolution1
I0927 10:14:39.144641  3315 net.cpp:122] Setting up Convolution1
I0927 10:14:39.144654  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.144670  3315 net.cpp:137] Memory required for data: 7783600
I0927 10:14:39.144681  3315 layer_factory.hpp:77] Creating layer BatchNorm1
I0927 10:14:39.144686  3315 net.cpp:84] Creating Layer BatchNorm1
I0927 10:14:39.144690  3315 net.cpp:406] BatchNorm1 <- Convolution1
I0927 10:14:39.144695  3315 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0927 10:14:39.144852  3315 net.cpp:122] Setting up BatchNorm1
I0927 10:14:39.144857  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.144860  3315 net.cpp:137] Memory required for data: 14337200
I0927 10:14:39.144868  3315 layer_factory.hpp:77] Creating layer Scale1
I0927 10:14:39.144873  3315 net.cpp:84] Creating Layer Scale1
I0927 10:14:39.144877  3315 net.cpp:406] Scale1 <- Convolution1
I0927 10:14:39.144883  3315 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0927 10:14:39.144917  3315 layer_factory.hpp:77] Creating layer Scale1
I0927 10:14:39.145004  3315 net.cpp:122] Setting up Scale1
I0927 10:14:39.145009  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.145012  3315 net.cpp:137] Memory required for data: 20890800
I0927 10:14:39.145017  3315 layer_factory.hpp:77] Creating layer penlu1
I0927 10:14:39.145025  3315 net.cpp:84] Creating Layer penlu1
I0927 10:14:39.145026  3315 net.cpp:406] penlu1 <- Convolution1
I0927 10:14:39.145035  3315 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0927 10:14:39.145690  3315 net.cpp:122] Setting up penlu1
I0927 10:14:39.145699  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.145702  3315 net.cpp:137] Memory required for data: 27444400
I0927 10:14:39.145709  3315 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0927 10:14:39.145717  3315 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0927 10:14:39.145720  3315 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0927 10:14:39.145725  3315 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0927 10:14:39.145730  3315 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0927 10:14:39.145759  3315 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0927 10:14:39.145763  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.166393  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.166400  3315 net.cpp:137] Memory required for data: 40551600
I0927 10:14:39.166404  3315 layer_factory.hpp:77] Creating layer Convolution2
I0927 10:14:39.166412  3315 net.cpp:84] Creating Layer Convolution2
I0927 10:14:39.166415  3315 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0927 10:14:39.166424  3315 net.cpp:380] Convolution2 -> Convolution2
I0927 10:14:39.167590  3315 net.cpp:122] Setting up Convolution2
I0927 10:14:39.167600  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.167603  3315 net.cpp:137] Memory required for data: 47105200
I0927 10:14:39.167608  3315 layer_factory.hpp:77] Creating layer BatchNorm2
I0927 10:14:39.167616  3315 net.cpp:84] Creating Layer BatchNorm2
I0927 10:14:39.167618  3315 net.cpp:406] BatchNorm2 <- Convolution2
I0927 10:14:39.167624  3315 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0927 10:14:39.167812  3315 net.cpp:122] Setting up BatchNorm2
I0927 10:14:39.167819  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.167821  3315 net.cpp:137] Memory required for data: 53658800
I0927 10:14:39.167826  3315 layer_factory.hpp:77] Creating layer Scale2
I0927 10:14:39.167832  3315 net.cpp:84] Creating Layer Scale2
I0927 10:14:39.167834  3315 net.cpp:406] Scale2 <- Convolution2
I0927 10:14:39.167848  3315 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0927 10:14:39.167883  3315 layer_factory.hpp:77] Creating layer Scale2
I0927 10:14:39.168000  3315 net.cpp:122] Setting up Scale2
I0927 10:14:39.168020  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.168023  3315 net.cpp:137] Memory required for data: 60212400
I0927 10:14:39.168033  3315 layer_factory.hpp:77] Creating layer penlu2
I0927 10:14:39.168058  3315 net.cpp:84] Creating Layer penlu2
I0927 10:14:39.168061  3315 net.cpp:406] penlu2 <- Convolution2
I0927 10:14:39.168066  3315 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0927 10:14:39.168272  3315 net.cpp:122] Setting up penlu2
I0927 10:14:39.168290  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.168292  3315 net.cpp:137] Memory required for data: 66766000
I0927 10:14:39.168298  3315 layer_factory.hpp:77] Creating layer Convolution3
I0927 10:14:39.168305  3315 net.cpp:84] Creating Layer Convolution3
I0927 10:14:39.168308  3315 net.cpp:406] Convolution3 <- Convolution2
I0927 10:14:39.168313  3315 net.cpp:380] Convolution3 -> Convolution3
I0927 10:14:39.169648  3315 net.cpp:122] Setting up Convolution3
I0927 10:14:39.169657  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.169661  3315 net.cpp:137] Memory required for data: 73319600
I0927 10:14:39.169664  3315 layer_factory.hpp:77] Creating layer BatchNorm3
I0927 10:14:39.169669  3315 net.cpp:84] Creating Layer BatchNorm3
I0927 10:14:39.169672  3315 net.cpp:406] BatchNorm3 <- Convolution3
I0927 10:14:39.169677  3315 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0927 10:14:39.169828  3315 net.cpp:122] Setting up BatchNorm3
I0927 10:14:39.169833  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.169836  3315 net.cpp:137] Memory required for data: 79873200
I0927 10:14:39.169840  3315 layer_factory.hpp:77] Creating layer Scale3
I0927 10:14:39.169844  3315 net.cpp:84] Creating Layer Scale3
I0927 10:14:39.169847  3315 net.cpp:406] Scale3 <- Convolution3
I0927 10:14:39.169849  3315 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0927 10:14:39.169879  3315 layer_factory.hpp:77] Creating layer Scale3
I0927 10:14:39.169965  3315 net.cpp:122] Setting up Scale3
I0927 10:14:39.169968  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.169970  3315 net.cpp:137] Memory required for data: 86426800
I0927 10:14:39.169975  3315 layer_factory.hpp:77] Creating layer Eltwise1
I0927 10:14:39.169981  3315 net.cpp:84] Creating Layer Eltwise1
I0927 10:14:39.169982  3315 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0927 10:14:39.169986  3315 net.cpp:406] Eltwise1 <- Convolution3
I0927 10:14:39.169989  3315 net.cpp:380] Eltwise1 -> Eltwise1
I0927 10:14:39.170007  3315 net.cpp:122] Setting up Eltwise1
I0927 10:14:39.170011  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.170013  3315 net.cpp:137] Memory required for data: 92980400
I0927 10:14:39.170016  3315 layer_factory.hpp:77] Creating layer penlu3
I0927 10:14:39.170022  3315 net.cpp:84] Creating Layer penlu3
I0927 10:14:39.170024  3315 net.cpp:406] penlu3 <- Eltwise1
I0927 10:14:39.170027  3315 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0927 10:14:39.170156  3315 net.cpp:122] Setting up penlu3
I0927 10:14:39.170161  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.170162  3315 net.cpp:137] Memory required for data: 99534000
I0927 10:14:39.170167  3315 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0927 10:14:39.170172  3315 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0927 10:14:39.170176  3315 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0927 10:14:39.170178  3315 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0927 10:14:39.170183  3315 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0927 10:14:39.170217  3315 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0927 10:14:39.170231  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.170234  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.170236  3315 net.cpp:137] Memory required for data: 112641200
I0927 10:14:39.170238  3315 layer_factory.hpp:77] Creating layer Convolution4
I0927 10:14:39.170254  3315 net.cpp:84] Creating Layer Convolution4
I0927 10:14:39.170256  3315 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0927 10:14:39.170261  3315 net.cpp:380] Convolution4 -> Convolution4
I0927 10:14:39.171360  3315 net.cpp:122] Setting up Convolution4
I0927 10:14:39.171376  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.171380  3315 net.cpp:137] Memory required for data: 119194800
I0927 10:14:39.171385  3315 layer_factory.hpp:77] Creating layer BatchNorm4
I0927 10:14:39.171391  3315 net.cpp:84] Creating Layer BatchNorm4
I0927 10:14:39.171393  3315 net.cpp:406] BatchNorm4 <- Convolution4
I0927 10:14:39.171397  3315 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0927 10:14:39.171551  3315 net.cpp:122] Setting up BatchNorm4
I0927 10:14:39.171556  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.171558  3315 net.cpp:137] Memory required for data: 125748400
I0927 10:14:39.171567  3315 layer_factory.hpp:77] Creating layer Scale4
I0927 10:14:39.171571  3315 net.cpp:84] Creating Layer Scale4
I0927 10:14:39.171574  3315 net.cpp:406] Scale4 <- Convolution4
I0927 10:14:39.171577  3315 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0927 10:14:39.171609  3315 layer_factory.hpp:77] Creating layer Scale4
I0927 10:14:39.171696  3315 net.cpp:122] Setting up Scale4
I0927 10:14:39.171701  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.171703  3315 net.cpp:137] Memory required for data: 132302000
I0927 10:14:39.171707  3315 layer_factory.hpp:77] Creating layer penlu4
I0927 10:14:39.171712  3315 net.cpp:84] Creating Layer penlu4
I0927 10:14:39.171715  3315 net.cpp:406] penlu4 <- Convolution4
I0927 10:14:39.171720  3315 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0927 10:14:39.171849  3315 net.cpp:122] Setting up penlu4
I0927 10:14:39.171854  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.171856  3315 net.cpp:137] Memory required for data: 138855600
I0927 10:14:39.171860  3315 layer_factory.hpp:77] Creating layer Convolution5
I0927 10:14:39.171869  3315 net.cpp:84] Creating Layer Convolution5
I0927 10:14:39.171870  3315 net.cpp:406] Convolution5 <- Convolution4
I0927 10:14:39.171875  3315 net.cpp:380] Convolution5 -> Convolution5
I0927 10:14:39.172830  3315 net.cpp:122] Setting up Convolution5
I0927 10:14:39.172838  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.172842  3315 net.cpp:137] Memory required for data: 145409200
I0927 10:14:39.172847  3315 layer_factory.hpp:77] Creating layer BatchNorm5
I0927 10:14:39.172852  3315 net.cpp:84] Creating Layer BatchNorm5
I0927 10:14:39.172854  3315 net.cpp:406] BatchNorm5 <- Convolution5
I0927 10:14:39.172857  3315 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0927 10:14:39.173012  3315 net.cpp:122] Setting up BatchNorm5
I0927 10:14:39.173017  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.173018  3315 net.cpp:137] Memory required for data: 151962800
I0927 10:14:39.173023  3315 layer_factory.hpp:77] Creating layer Scale5
I0927 10:14:39.173027  3315 net.cpp:84] Creating Layer Scale5
I0927 10:14:39.173029  3315 net.cpp:406] Scale5 <- Convolution5
I0927 10:14:39.173033  3315 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0927 10:14:39.173063  3315 layer_factory.hpp:77] Creating layer Scale5
I0927 10:14:39.173146  3315 net.cpp:122] Setting up Scale5
I0927 10:14:39.173151  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.173153  3315 net.cpp:137] Memory required for data: 158516400
I0927 10:14:39.173157  3315 layer_factory.hpp:77] Creating layer Eltwise2
I0927 10:14:39.173161  3315 net.cpp:84] Creating Layer Eltwise2
I0927 10:14:39.173164  3315 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0927 10:14:39.173167  3315 net.cpp:406] Eltwise2 <- Convolution5
I0927 10:14:39.173171  3315 net.cpp:380] Eltwise2 -> Eltwise2
I0927 10:14:39.173188  3315 net.cpp:122] Setting up Eltwise2
I0927 10:14:39.173192  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.173194  3315 net.cpp:137] Memory required for data: 165070000
I0927 10:14:39.173197  3315 layer_factory.hpp:77] Creating layer penlu5
I0927 10:14:39.173202  3315 net.cpp:84] Creating Layer penlu5
I0927 10:14:39.173204  3315 net.cpp:406] penlu5 <- Eltwise2
I0927 10:14:39.173208  3315 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0927 10:14:39.173346  3315 net.cpp:122] Setting up penlu5
I0927 10:14:39.173351  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.173352  3315 net.cpp:137] Memory required for data: 171623600
I0927 10:14:39.173357  3315 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0927 10:14:39.173362  3315 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0927 10:14:39.173363  3315 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0927 10:14:39.173367  3315 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0927 10:14:39.173372  3315 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0927 10:14:39.173398  3315 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0927 10:14:39.173403  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.173405  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.173408  3315 net.cpp:137] Memory required for data: 184730800
I0927 10:14:39.173409  3315 layer_factory.hpp:77] Creating layer Convolution6
I0927 10:14:39.173415  3315 net.cpp:84] Creating Layer Convolution6
I0927 10:14:39.173418  3315 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0927 10:14:39.173422  3315 net.cpp:380] Convolution6 -> Convolution6
I0927 10:14:39.174372  3315 net.cpp:122] Setting up Convolution6
I0927 10:14:39.174381  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.174383  3315 net.cpp:137] Memory required for data: 191284400
I0927 10:14:39.174387  3315 layer_factory.hpp:77] Creating layer BatchNorm6
I0927 10:14:39.174393  3315 net.cpp:84] Creating Layer BatchNorm6
I0927 10:14:39.174396  3315 net.cpp:406] BatchNorm6 <- Convolution6
I0927 10:14:39.174401  3315 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0927 10:14:39.174562  3315 net.cpp:122] Setting up BatchNorm6
I0927 10:14:39.174568  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.174571  3315 net.cpp:137] Memory required for data: 197838000
I0927 10:14:39.174576  3315 layer_factory.hpp:77] Creating layer Scale6
I0927 10:14:39.174579  3315 net.cpp:84] Creating Layer Scale6
I0927 10:14:39.174582  3315 net.cpp:406] Scale6 <- Convolution6
I0927 10:14:39.174585  3315 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0927 10:14:39.174616  3315 layer_factory.hpp:77] Creating layer Scale6
I0927 10:14:39.174701  3315 net.cpp:122] Setting up Scale6
I0927 10:14:39.174705  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.174707  3315 net.cpp:137] Memory required for data: 204391600
I0927 10:14:39.174711  3315 layer_factory.hpp:77] Creating layer penlu6
I0927 10:14:39.174716  3315 net.cpp:84] Creating Layer penlu6
I0927 10:14:39.174720  3315 net.cpp:406] penlu6 <- Convolution6
I0927 10:14:39.174724  3315 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0927 10:14:39.174850  3315 net.cpp:122] Setting up penlu6
I0927 10:14:39.174855  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.174857  3315 net.cpp:137] Memory required for data: 210945200
I0927 10:14:39.174861  3315 layer_factory.hpp:77] Creating layer Convolution7
I0927 10:14:39.174868  3315 net.cpp:84] Creating Layer Convolution7
I0927 10:14:39.174870  3315 net.cpp:406] Convolution7 <- Convolution6
I0927 10:14:39.174875  3315 net.cpp:380] Convolution7 -> Convolution7
I0927 10:14:39.175824  3315 net.cpp:122] Setting up Convolution7
I0927 10:14:39.175833  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.175837  3315 net.cpp:137] Memory required for data: 217498800
I0927 10:14:39.175840  3315 layer_factory.hpp:77] Creating layer BatchNorm7
I0927 10:14:39.175848  3315 net.cpp:84] Creating Layer BatchNorm7
I0927 10:14:39.175850  3315 net.cpp:406] BatchNorm7 <- Convolution7
I0927 10:14:39.175854  3315 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0927 10:14:39.176005  3315 net.cpp:122] Setting up BatchNorm7
I0927 10:14:39.176010  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.176012  3315 net.cpp:137] Memory required for data: 224052400
I0927 10:14:39.176023  3315 layer_factory.hpp:77] Creating layer Scale7
I0927 10:14:39.176026  3315 net.cpp:84] Creating Layer Scale7
I0927 10:14:39.176035  3315 net.cpp:406] Scale7 <- Convolution7
I0927 10:14:39.176040  3315 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0927 10:14:39.176072  3315 layer_factory.hpp:77] Creating layer Scale7
I0927 10:14:39.176159  3315 net.cpp:122] Setting up Scale7
I0927 10:14:39.176165  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.176167  3315 net.cpp:137] Memory required for data: 230606000
I0927 10:14:39.176172  3315 layer_factory.hpp:77] Creating layer Eltwise3
I0927 10:14:39.176175  3315 net.cpp:84] Creating Layer Eltwise3
I0927 10:14:39.176178  3315 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0927 10:14:39.176182  3315 net.cpp:406] Eltwise3 <- Convolution7
I0927 10:14:39.176184  3315 net.cpp:380] Eltwise3 -> Eltwise3
I0927 10:14:39.176203  3315 net.cpp:122] Setting up Eltwise3
I0927 10:14:39.176206  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.176208  3315 net.cpp:137] Memory required for data: 237159600
I0927 10:14:39.176211  3315 layer_factory.hpp:77] Creating layer penlu7
I0927 10:14:39.176215  3315 net.cpp:84] Creating Layer penlu7
I0927 10:14:39.176218  3315 net.cpp:406] penlu7 <- Eltwise3
I0927 10:14:39.176221  3315 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0927 10:14:39.176348  3315 net.cpp:122] Setting up penlu7
I0927 10:14:39.176352  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.176355  3315 net.cpp:137] Memory required for data: 243713200
I0927 10:14:39.176359  3315 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0927 10:14:39.176363  3315 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0927 10:14:39.176367  3315 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0927 10:14:39.176369  3315 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0927 10:14:39.176373  3315 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0927 10:14:39.176399  3315 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0927 10:14:39.176403  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.176405  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.197310  3315 net.cpp:137] Memory required for data: 256820400
I0927 10:14:39.197317  3315 layer_factory.hpp:77] Creating layer Convolution8
I0927 10:14:39.197325  3315 net.cpp:84] Creating Layer Convolution8
I0927 10:14:39.197329  3315 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0927 10:14:39.197335  3315 net.cpp:380] Convolution8 -> Convolution8
I0927 10:14:39.198381  3315 net.cpp:122] Setting up Convolution8
I0927 10:14:39.198390  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.198393  3315 net.cpp:137] Memory required for data: 263374000
I0927 10:14:39.198398  3315 layer_factory.hpp:77] Creating layer BatchNorm8
I0927 10:14:39.198403  3315 net.cpp:84] Creating Layer BatchNorm8
I0927 10:14:39.198406  3315 net.cpp:406] BatchNorm8 <- Convolution8
I0927 10:14:39.198411  3315 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0927 10:14:39.198596  3315 net.cpp:122] Setting up BatchNorm8
I0927 10:14:39.198602  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.198606  3315 net.cpp:137] Memory required for data: 269927600
I0927 10:14:39.198611  3315 layer_factory.hpp:77] Creating layer Scale8
I0927 10:14:39.198616  3315 net.cpp:84] Creating Layer Scale8
I0927 10:14:39.198618  3315 net.cpp:406] Scale8 <- Convolution8
I0927 10:14:39.198622  3315 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0927 10:14:39.198655  3315 layer_factory.hpp:77] Creating layer Scale8
I0927 10:14:39.198768  3315 net.cpp:122] Setting up Scale8
I0927 10:14:39.198776  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.198779  3315 net.cpp:137] Memory required for data: 276481200
I0927 10:14:39.198783  3315 layer_factory.hpp:77] Creating layer penlu8
I0927 10:14:39.198789  3315 net.cpp:84] Creating Layer penlu8
I0927 10:14:39.198792  3315 net.cpp:406] penlu8 <- Convolution8
I0927 10:14:39.198796  3315 net.cpp:367] penlu8 -> Convolution8 (in-place)
I0927 10:14:39.198971  3315 net.cpp:122] Setting up penlu8
I0927 10:14:39.198981  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.198982  3315 net.cpp:137] Memory required for data: 283034800
I0927 10:14:39.198987  3315 layer_factory.hpp:77] Creating layer Convolution9
I0927 10:14:39.198993  3315 net.cpp:84] Creating Layer Convolution9
I0927 10:14:39.198997  3315 net.cpp:406] Convolution9 <- Convolution8
I0927 10:14:39.199002  3315 net.cpp:380] Convolution9 -> Convolution9
I0927 10:14:39.200034  3315 net.cpp:122] Setting up Convolution9
I0927 10:14:39.200043  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.200047  3315 net.cpp:137] Memory required for data: 289588400
I0927 10:14:39.200050  3315 layer_factory.hpp:77] Creating layer BatchNorm9
I0927 10:14:39.200057  3315 net.cpp:84] Creating Layer BatchNorm9
I0927 10:14:39.200059  3315 net.cpp:406] BatchNorm9 <- Convolution9
I0927 10:14:39.200063  3315 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0927 10:14:39.200222  3315 net.cpp:122] Setting up BatchNorm9
I0927 10:14:39.200227  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.200228  3315 net.cpp:137] Memory required for data: 296142000
I0927 10:14:39.200233  3315 layer_factory.hpp:77] Creating layer Scale9
I0927 10:14:39.200237  3315 net.cpp:84] Creating Layer Scale9
I0927 10:14:39.200239  3315 net.cpp:406] Scale9 <- Convolution9
I0927 10:14:39.200243  3315 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0927 10:14:39.200274  3315 layer_factory.hpp:77] Creating layer Scale9
I0927 10:14:39.200361  3315 net.cpp:122] Setting up Scale9
I0927 10:14:39.200366  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.200368  3315 net.cpp:137] Memory required for data: 302695600
I0927 10:14:39.200372  3315 layer_factory.hpp:77] Creating layer Eltwise4
I0927 10:14:39.200377  3315 net.cpp:84] Creating Layer Eltwise4
I0927 10:14:39.200381  3315 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I0927 10:14:39.200383  3315 net.cpp:406] Eltwise4 <- Convolution9
I0927 10:14:39.200387  3315 net.cpp:380] Eltwise4 -> Eltwise4
I0927 10:14:39.200405  3315 net.cpp:122] Setting up Eltwise4
I0927 10:14:39.200409  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.200412  3315 net.cpp:137] Memory required for data: 309249200
I0927 10:14:39.200414  3315 layer_factory.hpp:77] Creating layer penlu9
I0927 10:14:39.200419  3315 net.cpp:84] Creating Layer penlu9
I0927 10:14:39.200423  3315 net.cpp:406] penlu9 <- Eltwise4
I0927 10:14:39.200426  3315 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0927 10:14:39.200557  3315 net.cpp:122] Setting up penlu9
I0927 10:14:39.200562  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.200564  3315 net.cpp:137] Memory required for data: 315802800
I0927 10:14:39.200568  3315 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0927 10:14:39.200572  3315 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0927 10:14:39.200574  3315 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0927 10:14:39.200578  3315 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0927 10:14:39.200582  3315 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0927 10:14:39.200609  3315 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0927 10:14:39.200613  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.200615  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.200618  3315 net.cpp:137] Memory required for data: 328910000
I0927 10:14:39.200620  3315 layer_factory.hpp:77] Creating layer Convolution10
I0927 10:14:39.200626  3315 net.cpp:84] Creating Layer Convolution10
I0927 10:14:39.200629  3315 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I0927 10:14:39.200634  3315 net.cpp:380] Convolution10 -> Convolution10
I0927 10:14:39.201726  3315 net.cpp:122] Setting up Convolution10
I0927 10:14:39.201736  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.201738  3315 net.cpp:137] Memory required for data: 335463600
I0927 10:14:39.201743  3315 layer_factory.hpp:77] Creating layer BatchNorm10
I0927 10:14:39.201756  3315 net.cpp:84] Creating Layer BatchNorm10
I0927 10:14:39.201759  3315 net.cpp:406] BatchNorm10 <- Convolution10
I0927 10:14:39.201763  3315 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0927 10:14:39.201918  3315 net.cpp:122] Setting up BatchNorm10
I0927 10:14:39.201923  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.201926  3315 net.cpp:137] Memory required for data: 342017200
I0927 10:14:39.201930  3315 layer_factory.hpp:77] Creating layer Scale10
I0927 10:14:39.201936  3315 net.cpp:84] Creating Layer Scale10
I0927 10:14:39.201937  3315 net.cpp:406] Scale10 <- Convolution10
I0927 10:14:39.201941  3315 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0927 10:14:39.201972  3315 layer_factory.hpp:77] Creating layer Scale10
I0927 10:14:39.202057  3315 net.cpp:122] Setting up Scale10
I0927 10:14:39.202061  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.202064  3315 net.cpp:137] Memory required for data: 348570800
I0927 10:14:39.202069  3315 layer_factory.hpp:77] Creating layer penlu10
I0927 10:14:39.202074  3315 net.cpp:84] Creating Layer penlu10
I0927 10:14:39.202076  3315 net.cpp:406] penlu10 <- Convolution10
I0927 10:14:39.202080  3315 net.cpp:367] penlu10 -> Convolution10 (in-place)
I0927 10:14:39.202210  3315 net.cpp:122] Setting up penlu10
I0927 10:14:39.202215  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.202217  3315 net.cpp:137] Memory required for data: 355124400
I0927 10:14:39.202221  3315 layer_factory.hpp:77] Creating layer Convolution11
I0927 10:14:39.202229  3315 net.cpp:84] Creating Layer Convolution11
I0927 10:14:39.202231  3315 net.cpp:406] Convolution11 <- Convolution10
I0927 10:14:39.202235  3315 net.cpp:380] Convolution11 -> Convolution11
I0927 10:14:39.203524  3315 net.cpp:122] Setting up Convolution11
I0927 10:14:39.203533  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.203536  3315 net.cpp:137] Memory required for data: 361678000
I0927 10:14:39.203541  3315 layer_factory.hpp:77] Creating layer BatchNorm11
I0927 10:14:39.203547  3315 net.cpp:84] Creating Layer BatchNorm11
I0927 10:14:39.203549  3315 net.cpp:406] BatchNorm11 <- Convolution11
I0927 10:14:39.203554  3315 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0927 10:14:39.203713  3315 net.cpp:122] Setting up BatchNorm11
I0927 10:14:39.203718  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.203721  3315 net.cpp:137] Memory required for data: 368231600
I0927 10:14:39.203725  3315 layer_factory.hpp:77] Creating layer Scale11
I0927 10:14:39.203729  3315 net.cpp:84] Creating Layer Scale11
I0927 10:14:39.203732  3315 net.cpp:406] Scale11 <- Convolution11
I0927 10:14:39.203735  3315 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0927 10:14:39.203764  3315 layer_factory.hpp:77] Creating layer Scale11
I0927 10:14:39.203850  3315 net.cpp:122] Setting up Scale11
I0927 10:14:39.203855  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.203857  3315 net.cpp:137] Memory required for data: 374785200
I0927 10:14:39.203861  3315 layer_factory.hpp:77] Creating layer Eltwise5
I0927 10:14:39.203866  3315 net.cpp:84] Creating Layer Eltwise5
I0927 10:14:39.203868  3315 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0927 10:14:39.203871  3315 net.cpp:406] Eltwise5 <- Convolution11
I0927 10:14:39.203874  3315 net.cpp:380] Eltwise5 -> Eltwise5
I0927 10:14:39.203893  3315 net.cpp:122] Setting up Eltwise5
I0927 10:14:39.203896  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.203898  3315 net.cpp:137] Memory required for data: 381338800
I0927 10:14:39.203900  3315 layer_factory.hpp:77] Creating layer penlu11
I0927 10:14:39.203907  3315 net.cpp:84] Creating Layer penlu11
I0927 10:14:39.203909  3315 net.cpp:406] penlu11 <- Eltwise5
I0927 10:14:39.203912  3315 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0927 10:14:39.204044  3315 net.cpp:122] Setting up penlu11
I0927 10:14:39.204048  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.204051  3315 net.cpp:137] Memory required for data: 387892400
I0927 10:14:39.204061  3315 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0927 10:14:39.204066  3315 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0927 10:14:39.204068  3315 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0927 10:14:39.204072  3315 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0927 10:14:39.204077  3315 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0927 10:14:39.204103  3315 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0927 10:14:39.204107  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.204110  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.204113  3315 net.cpp:137] Memory required for data: 400999600
I0927 10:14:39.204114  3315 layer_factory.hpp:77] Creating layer Convolution12
I0927 10:14:39.204120  3315 net.cpp:84] Creating Layer Convolution12
I0927 10:14:39.204123  3315 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I0927 10:14:39.204128  3315 net.cpp:380] Convolution12 -> Convolution12
I0927 10:14:39.205094  3315 net.cpp:122] Setting up Convolution12
I0927 10:14:39.205103  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.205106  3315 net.cpp:137] Memory required for data: 407553200
I0927 10:14:39.205111  3315 layer_factory.hpp:77] Creating layer BatchNorm12
I0927 10:14:39.205116  3315 net.cpp:84] Creating Layer BatchNorm12
I0927 10:14:39.205118  3315 net.cpp:406] BatchNorm12 <- Convolution12
I0927 10:14:39.205121  3315 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0927 10:14:39.205277  3315 net.cpp:122] Setting up BatchNorm12
I0927 10:14:39.205282  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.205284  3315 net.cpp:137] Memory required for data: 414106800
I0927 10:14:39.205289  3315 layer_factory.hpp:77] Creating layer Scale12
I0927 10:14:39.205293  3315 net.cpp:84] Creating Layer Scale12
I0927 10:14:39.205296  3315 net.cpp:406] Scale12 <- Convolution12
I0927 10:14:39.205299  3315 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0927 10:14:39.205330  3315 layer_factory.hpp:77] Creating layer Scale12
I0927 10:14:39.205417  3315 net.cpp:122] Setting up Scale12
I0927 10:14:39.205422  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.205425  3315 net.cpp:137] Memory required for data: 420660400
I0927 10:14:39.205428  3315 layer_factory.hpp:77] Creating layer penlu12
I0927 10:14:39.205435  3315 net.cpp:84] Creating Layer penlu12
I0927 10:14:39.205436  3315 net.cpp:406] penlu12 <- Convolution12
I0927 10:14:39.205440  3315 net.cpp:367] penlu12 -> Convolution12 (in-place)
I0927 10:14:39.205569  3315 net.cpp:122] Setting up penlu12
I0927 10:14:39.205574  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.205576  3315 net.cpp:137] Memory required for data: 427214000
I0927 10:14:39.205580  3315 layer_factory.hpp:77] Creating layer Convolution13
I0927 10:14:39.205586  3315 net.cpp:84] Creating Layer Convolution13
I0927 10:14:39.205590  3315 net.cpp:406] Convolution13 <- Convolution12
I0927 10:14:39.205593  3315 net.cpp:380] Convolution13 -> Convolution13
I0927 10:14:39.206567  3315 net.cpp:122] Setting up Convolution13
I0927 10:14:39.206576  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.206578  3315 net.cpp:137] Memory required for data: 433767600
I0927 10:14:39.206583  3315 layer_factory.hpp:77] Creating layer BatchNorm13
I0927 10:14:39.206588  3315 net.cpp:84] Creating Layer BatchNorm13
I0927 10:14:39.206590  3315 net.cpp:406] BatchNorm13 <- Convolution13
I0927 10:14:39.206594  3315 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0927 10:14:39.206750  3315 net.cpp:122] Setting up BatchNorm13
I0927 10:14:39.206755  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.206758  3315 net.cpp:137] Memory required for data: 440321200
I0927 10:14:39.206763  3315 layer_factory.hpp:77] Creating layer Scale13
I0927 10:14:39.206766  3315 net.cpp:84] Creating Layer Scale13
I0927 10:14:39.206768  3315 net.cpp:406] Scale13 <- Convolution13
I0927 10:14:39.206779  3315 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0927 10:14:39.206811  3315 layer_factory.hpp:77] Creating layer Scale13
I0927 10:14:39.206899  3315 net.cpp:122] Setting up Scale13
I0927 10:14:39.206904  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.206907  3315 net.cpp:137] Memory required for data: 446874800
I0927 10:14:39.206910  3315 layer_factory.hpp:77] Creating layer Eltwise6
I0927 10:14:39.206918  3315 net.cpp:84] Creating Layer Eltwise6
I0927 10:14:39.206921  3315 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0927 10:14:39.206924  3315 net.cpp:406] Eltwise6 <- Convolution13
I0927 10:14:39.206928  3315 net.cpp:380] Eltwise6 -> Eltwise6
I0927 10:14:39.206948  3315 net.cpp:122] Setting up Eltwise6
I0927 10:14:39.206953  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.206954  3315 net.cpp:137] Memory required for data: 453428400
I0927 10:14:39.206957  3315 layer_factory.hpp:77] Creating layer penlu13
I0927 10:14:39.206962  3315 net.cpp:84] Creating Layer penlu13
I0927 10:14:39.206965  3315 net.cpp:406] penlu13 <- Eltwise6
I0927 10:14:39.206969  3315 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0927 10:14:39.207099  3315 net.cpp:122] Setting up penlu13
I0927 10:14:39.207104  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.207106  3315 net.cpp:137] Memory required for data: 459982000
I0927 10:14:39.207119  3315 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0927 10:14:39.207124  3315 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0927 10:14:39.207126  3315 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0927 10:14:39.207129  3315 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0927 10:14:39.207134  3315 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0927 10:14:39.207161  3315 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0927 10:14:39.207165  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.207167  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.228005  3315 net.cpp:137] Memory required for data: 473089200
I0927 10:14:39.228013  3315 layer_factory.hpp:77] Creating layer Convolution14
I0927 10:14:39.228024  3315 net.cpp:84] Creating Layer Convolution14
I0927 10:14:39.228026  3315 net.cpp:406] Convolution14 <- Eltwise6_penlu13_0_split_0
I0927 10:14:39.228031  3315 net.cpp:380] Convolution14 -> Convolution14
I0927 10:14:39.229089  3315 net.cpp:122] Setting up Convolution14
I0927 10:14:39.229099  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.229101  3315 net.cpp:137] Memory required for data: 479642800
I0927 10:14:39.229106  3315 layer_factory.hpp:77] Creating layer BatchNorm14
I0927 10:14:39.229111  3315 net.cpp:84] Creating Layer BatchNorm14
I0927 10:14:39.229115  3315 net.cpp:406] BatchNorm14 <- Convolution14
I0927 10:14:39.229120  3315 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0927 10:14:39.229297  3315 net.cpp:122] Setting up BatchNorm14
I0927 10:14:39.229302  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.229305  3315 net.cpp:137] Memory required for data: 486196400
I0927 10:14:39.229313  3315 layer_factory.hpp:77] Creating layer Scale14
I0927 10:14:39.229321  3315 net.cpp:84] Creating Layer Scale14
I0927 10:14:39.229326  3315 net.cpp:406] Scale14 <- Convolution14
I0927 10:14:39.229331  3315 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0927 10:14:39.229369  3315 layer_factory.hpp:77] Creating layer Scale14
I0927 10:14:39.229460  3315 net.cpp:122] Setting up Scale14
I0927 10:14:39.229465  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.229467  3315 net.cpp:137] Memory required for data: 492750000
I0927 10:14:39.229471  3315 layer_factory.hpp:77] Creating layer penlu14
I0927 10:14:39.229476  3315 net.cpp:84] Creating Layer penlu14
I0927 10:14:39.229480  3315 net.cpp:406] penlu14 <- Convolution14
I0927 10:14:39.229485  3315 net.cpp:367] penlu14 -> Convolution14 (in-place)
I0927 10:14:39.229656  3315 net.cpp:122] Setting up penlu14
I0927 10:14:39.229679  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.229684  3315 net.cpp:137] Memory required for data: 499303600
I0927 10:14:39.229692  3315 layer_factory.hpp:77] Creating layer Convolution15
I0927 10:14:39.229702  3315 net.cpp:84] Creating Layer Convolution15
I0927 10:14:39.229707  3315 net.cpp:406] Convolution15 <- Convolution14
I0927 10:14:39.229713  3315 net.cpp:380] Convolution15 -> Convolution15
I0927 10:14:39.231226  3315 net.cpp:122] Setting up Convolution15
I0927 10:14:39.231235  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.231237  3315 net.cpp:137] Memory required for data: 505857200
I0927 10:14:39.231242  3315 layer_factory.hpp:77] Creating layer BatchNorm15
I0927 10:14:39.231247  3315 net.cpp:84] Creating Layer BatchNorm15
I0927 10:14:39.231251  3315 net.cpp:406] BatchNorm15 <- Convolution15
I0927 10:14:39.231254  3315 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0927 10:14:39.231410  3315 net.cpp:122] Setting up BatchNorm15
I0927 10:14:39.231415  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.231417  3315 net.cpp:137] Memory required for data: 512410800
I0927 10:14:39.231421  3315 layer_factory.hpp:77] Creating layer Scale15
I0927 10:14:39.231426  3315 net.cpp:84] Creating Layer Scale15
I0927 10:14:39.231428  3315 net.cpp:406] Scale15 <- Convolution15
I0927 10:14:39.231431  3315 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0927 10:14:39.231463  3315 layer_factory.hpp:77] Creating layer Scale15
I0927 10:14:39.231549  3315 net.cpp:122] Setting up Scale15
I0927 10:14:39.231554  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.231556  3315 net.cpp:137] Memory required for data: 518964400
I0927 10:14:39.231559  3315 layer_factory.hpp:77] Creating layer Eltwise7
I0927 10:14:39.231564  3315 net.cpp:84] Creating Layer Eltwise7
I0927 10:14:39.231567  3315 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I0927 10:14:39.231570  3315 net.cpp:406] Eltwise7 <- Convolution15
I0927 10:14:39.231575  3315 net.cpp:380] Eltwise7 -> Eltwise7
I0927 10:14:39.231591  3315 net.cpp:122] Setting up Eltwise7
I0927 10:14:39.231595  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.231597  3315 net.cpp:137] Memory required for data: 525518000
I0927 10:14:39.231600  3315 layer_factory.hpp:77] Creating layer penlu15
I0927 10:14:39.231606  3315 net.cpp:84] Creating Layer penlu15
I0927 10:14:39.231607  3315 net.cpp:406] penlu15 <- Eltwise7
I0927 10:14:39.231611  3315 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0927 10:14:39.231765  3315 net.cpp:122] Setting up penlu15
I0927 10:14:39.231770  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.231771  3315 net.cpp:137] Memory required for data: 532071600
I0927 10:14:39.231776  3315 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0927 10:14:39.231779  3315 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0927 10:14:39.231782  3315 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0927 10:14:39.231786  3315 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0927 10:14:39.231789  3315 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0927 10:14:39.231817  3315 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0927 10:14:39.231819  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.231822  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.231824  3315 net.cpp:137] Memory required for data: 545178800
I0927 10:14:39.231827  3315 layer_factory.hpp:77] Creating layer Convolution16
I0927 10:14:39.231833  3315 net.cpp:84] Creating Layer Convolution16
I0927 10:14:39.231835  3315 net.cpp:406] Convolution16 <- Eltwise7_penlu15_0_split_0
I0927 10:14:39.231839  3315 net.cpp:380] Convolution16 -> Convolution16
I0927 10:14:39.232470  3315 net.cpp:122] Setting up Convolution16
I0927 10:14:39.232476  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.232480  3315 net.cpp:137] Memory required for data: 551732400
I0927 10:14:39.232483  3315 layer_factory.hpp:77] Creating layer BatchNorm16
I0927 10:14:39.232496  3315 net.cpp:84] Creating Layer BatchNorm16
I0927 10:14:39.232498  3315 net.cpp:406] BatchNorm16 <- Convolution16
I0927 10:14:39.232502  3315 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0927 10:14:39.232657  3315 net.cpp:122] Setting up BatchNorm16
I0927 10:14:39.232662  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.232664  3315 net.cpp:137] Memory required for data: 558286000
I0927 10:14:39.232669  3315 layer_factory.hpp:77] Creating layer Scale16
I0927 10:14:39.232674  3315 net.cpp:84] Creating Layer Scale16
I0927 10:14:39.232676  3315 net.cpp:406] Scale16 <- Convolution16
I0927 10:14:39.232679  3315 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0927 10:14:39.232710  3315 layer_factory.hpp:77] Creating layer Scale16
I0927 10:14:39.232798  3315 net.cpp:122] Setting up Scale16
I0927 10:14:39.232802  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.232805  3315 net.cpp:137] Memory required for data: 564839600
I0927 10:14:39.232808  3315 layer_factory.hpp:77] Creating layer penlu16
I0927 10:14:39.232813  3315 net.cpp:84] Creating Layer penlu16
I0927 10:14:39.232816  3315 net.cpp:406] penlu16 <- Convolution16
I0927 10:14:39.232820  3315 net.cpp:367] penlu16 -> Convolution16 (in-place)
I0927 10:14:39.232952  3315 net.cpp:122] Setting up penlu16
I0927 10:14:39.232957  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.232959  3315 net.cpp:137] Memory required for data: 571393200
I0927 10:14:39.232964  3315 layer_factory.hpp:77] Creating layer Convolution17
I0927 10:14:39.232970  3315 net.cpp:84] Creating Layer Convolution17
I0927 10:14:39.232972  3315 net.cpp:406] Convolution17 <- Convolution16
I0927 10:14:39.232976  3315 net.cpp:380] Convolution17 -> Convolution17
I0927 10:14:39.233943  3315 net.cpp:122] Setting up Convolution17
I0927 10:14:39.233953  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.233955  3315 net.cpp:137] Memory required for data: 577946800
I0927 10:14:39.233960  3315 layer_factory.hpp:77] Creating layer BatchNorm17
I0927 10:14:39.233964  3315 net.cpp:84] Creating Layer BatchNorm17
I0927 10:14:39.233968  3315 net.cpp:406] BatchNorm17 <- Convolution17
I0927 10:14:39.233973  3315 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0927 10:14:39.234130  3315 net.cpp:122] Setting up BatchNorm17
I0927 10:14:39.234134  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.234136  3315 net.cpp:137] Memory required for data: 584500400
I0927 10:14:39.234141  3315 layer_factory.hpp:77] Creating layer Scale17
I0927 10:14:39.234145  3315 net.cpp:84] Creating Layer Scale17
I0927 10:14:39.234148  3315 net.cpp:406] Scale17 <- Convolution17
I0927 10:14:39.234151  3315 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0927 10:14:39.234182  3315 layer_factory.hpp:77] Creating layer Scale17
I0927 10:14:39.234269  3315 net.cpp:122] Setting up Scale17
I0927 10:14:39.234273  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.234275  3315 net.cpp:137] Memory required for data: 591054000
I0927 10:14:39.234279  3315 layer_factory.hpp:77] Creating layer Eltwise8
I0927 10:14:39.234283  3315 net.cpp:84] Creating Layer Eltwise8
I0927 10:14:39.234287  3315 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0927 10:14:39.234288  3315 net.cpp:406] Eltwise8 <- Convolution17
I0927 10:14:39.234292  3315 net.cpp:380] Eltwise8 -> Eltwise8
I0927 10:14:39.234310  3315 net.cpp:122] Setting up Eltwise8
I0927 10:14:39.234314  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.234316  3315 net.cpp:137] Memory required for data: 597607600
I0927 10:14:39.234318  3315 layer_factory.hpp:77] Creating layer penlu17
I0927 10:14:39.234324  3315 net.cpp:84] Creating Layer penlu17
I0927 10:14:39.234326  3315 net.cpp:406] penlu17 <- Eltwise8
I0927 10:14:39.234330  3315 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0927 10:14:39.234465  3315 net.cpp:122] Setting up penlu17
I0927 10:14:39.234469  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.234472  3315 net.cpp:137] Memory required for data: 604161200
I0927 10:14:39.234483  3315 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0927 10:14:39.234486  3315 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0927 10:14:39.234489  3315 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0927 10:14:39.234493  3315 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0927 10:14:39.234498  3315 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0927 10:14:39.234529  3315 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0927 10:14:39.234534  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.234536  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.234539  3315 net.cpp:137] Memory required for data: 617268400
I0927 10:14:39.234540  3315 layer_factory.hpp:77] Creating layer Convolution18
I0927 10:14:39.234547  3315 net.cpp:84] Creating Layer Convolution18
I0927 10:14:39.234550  3315 net.cpp:406] Convolution18 <- Eltwise8_penlu17_0_split_0
I0927 10:14:39.234555  3315 net.cpp:380] Convolution18 -> Convolution18
I0927 10:14:39.235558  3315 net.cpp:122] Setting up Convolution18
I0927 10:14:39.235566  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.235569  3315 net.cpp:137] Memory required for data: 623822000
I0927 10:14:39.235574  3315 layer_factory.hpp:77] Creating layer BatchNorm18
I0927 10:14:39.235579  3315 net.cpp:84] Creating Layer BatchNorm18
I0927 10:14:39.235580  3315 net.cpp:406] BatchNorm18 <- Convolution18
I0927 10:14:39.235584  3315 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0927 10:14:39.235738  3315 net.cpp:122] Setting up BatchNorm18
I0927 10:14:39.235743  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.235745  3315 net.cpp:137] Memory required for data: 630375600
I0927 10:14:39.235749  3315 layer_factory.hpp:77] Creating layer Scale18
I0927 10:14:39.235754  3315 net.cpp:84] Creating Layer Scale18
I0927 10:14:39.235756  3315 net.cpp:406] Scale18 <- Convolution18
I0927 10:14:39.235759  3315 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0927 10:14:39.235790  3315 layer_factory.hpp:77] Creating layer Scale18
I0927 10:14:39.235875  3315 net.cpp:122] Setting up Scale18
I0927 10:14:39.235880  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.235882  3315 net.cpp:137] Memory required for data: 636929200
I0927 10:14:39.235887  3315 layer_factory.hpp:77] Creating layer penlu18
I0927 10:14:39.235891  3315 net.cpp:84] Creating Layer penlu18
I0927 10:14:39.235893  3315 net.cpp:406] penlu18 <- Convolution18
I0927 10:14:39.235898  3315 net.cpp:367] penlu18 -> Convolution18 (in-place)
I0927 10:14:39.236032  3315 net.cpp:122] Setting up penlu18
I0927 10:14:39.236037  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.236038  3315 net.cpp:137] Memory required for data: 643482800
I0927 10:14:39.236043  3315 layer_factory.hpp:77] Creating layer Convolution19
I0927 10:14:39.236049  3315 net.cpp:84] Creating Layer Convolution19
I0927 10:14:39.236052  3315 net.cpp:406] Convolution19 <- Convolution18
I0927 10:14:39.236057  3315 net.cpp:380] Convolution19 -> Convolution19
I0927 10:14:39.237015  3315 net.cpp:122] Setting up Convolution19
I0927 10:14:39.237025  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.237027  3315 net.cpp:137] Memory required for data: 650036400
I0927 10:14:39.237031  3315 layer_factory.hpp:77] Creating layer BatchNorm19
I0927 10:14:39.237037  3315 net.cpp:84] Creating Layer BatchNorm19
I0927 10:14:39.237040  3315 net.cpp:406] BatchNorm19 <- Convolution19
I0927 10:14:39.237043  3315 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0927 10:14:39.237201  3315 net.cpp:122] Setting up BatchNorm19
I0927 10:14:39.237206  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.237208  3315 net.cpp:137] Memory required for data: 656590000
I0927 10:14:39.237213  3315 layer_factory.hpp:77] Creating layer Scale19
I0927 10:14:39.237218  3315 net.cpp:84] Creating Layer Scale19
I0927 10:14:39.237221  3315 net.cpp:406] Scale19 <- Convolution19
I0927 10:14:39.237231  3315 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0927 10:14:39.237263  3315 layer_factory.hpp:77] Creating layer Scale19
I0927 10:14:39.237352  3315 net.cpp:122] Setting up Scale19
I0927 10:14:39.237357  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.237360  3315 net.cpp:137] Memory required for data: 663143600
I0927 10:14:39.237362  3315 layer_factory.hpp:77] Creating layer Eltwise9
I0927 10:14:39.237367  3315 net.cpp:84] Creating Layer Eltwise9
I0927 10:14:39.237370  3315 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0927 10:14:39.237373  3315 net.cpp:406] Eltwise9 <- Convolution19
I0927 10:14:39.237376  3315 net.cpp:380] Eltwise9 -> Eltwise9
I0927 10:14:39.237396  3315 net.cpp:122] Setting up Eltwise9
I0927 10:14:39.237399  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.237401  3315 net.cpp:137] Memory required for data: 669697200
I0927 10:14:39.237403  3315 layer_factory.hpp:77] Creating layer penlu19
I0927 10:14:39.237408  3315 net.cpp:84] Creating Layer penlu19
I0927 10:14:39.237411  3315 net.cpp:406] penlu19 <- Eltwise9
I0927 10:14:39.237414  3315 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0927 10:14:39.237550  3315 net.cpp:122] Setting up penlu19
I0927 10:14:39.237555  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.237556  3315 net.cpp:137] Memory required for data: 676250800
I0927 10:14:39.237560  3315 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I0927 10:14:39.237565  3315 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I0927 10:14:39.237566  3315 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I0927 10:14:39.237571  3315 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I0927 10:14:39.237574  3315 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I0927 10:14:39.237601  3315 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I0927 10:14:39.258893  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.258900  3315 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0927 10:14:39.258903  3315 net.cpp:137] Memory required for data: 689358000
I0927 10:14:39.258906  3315 layer_factory.hpp:77] Creating layer Convolution20
I0927 10:14:39.258915  3315 net.cpp:84] Creating Layer Convolution20
I0927 10:14:39.258919  3315 net.cpp:406] Convolution20 <- Eltwise9_penlu19_0_split_0
I0927 10:14:39.258924  3315 net.cpp:380] Convolution20 -> Convolution20
I0927 10:14:39.260551  3315 net.cpp:122] Setting up Convolution20
I0927 10:14:39.260565  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.260568  3315 net.cpp:137] Memory required for data: 692634800
I0927 10:14:39.260576  3315 layer_factory.hpp:77] Creating layer BatchNorm20
I0927 10:14:39.260584  3315 net.cpp:84] Creating Layer BatchNorm20
I0927 10:14:39.260589  3315 net.cpp:406] BatchNorm20 <- Convolution20
I0927 10:14:39.260596  3315 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0927 10:14:39.260761  3315 net.cpp:122] Setting up BatchNorm20
I0927 10:14:39.260766  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.260769  3315 net.cpp:137] Memory required for data: 695911600
I0927 10:14:39.260774  3315 layer_factory.hpp:77] Creating layer Scale20
I0927 10:14:39.260779  3315 net.cpp:84] Creating Layer Scale20
I0927 10:14:39.260782  3315 net.cpp:406] Scale20 <- Convolution20
I0927 10:14:39.260787  3315 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0927 10:14:39.260814  3315 layer_factory.hpp:77] Creating layer Scale20
I0927 10:14:39.260888  3315 net.cpp:122] Setting up Scale20
I0927 10:14:39.260892  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.260895  3315 net.cpp:137] Memory required for data: 699188400
I0927 10:14:39.260900  3315 layer_factory.hpp:77] Creating layer Convolution21
I0927 10:14:39.260906  3315 net.cpp:84] Creating Layer Convolution21
I0927 10:14:39.260910  3315 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_1
I0927 10:14:39.260913  3315 net.cpp:380] Convolution21 -> Convolution21
I0927 10:14:39.261939  3315 net.cpp:122] Setting up Convolution21
I0927 10:14:39.261956  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.261960  3315 net.cpp:137] Memory required for data: 702465200
I0927 10:14:39.261965  3315 layer_factory.hpp:77] Creating layer BatchNorm21
I0927 10:14:39.261970  3315 net.cpp:84] Creating Layer BatchNorm21
I0927 10:14:39.261972  3315 net.cpp:406] BatchNorm21 <- Convolution21
I0927 10:14:39.261978  3315 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0927 10:14:39.262104  3315 net.cpp:122] Setting up BatchNorm21
I0927 10:14:39.262109  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.262111  3315 net.cpp:137] Memory required for data: 705742000
I0927 10:14:39.262116  3315 layer_factory.hpp:77] Creating layer Scale21
I0927 10:14:39.262121  3315 net.cpp:84] Creating Layer Scale21
I0927 10:14:39.262123  3315 net.cpp:406] Scale21 <- Convolution21
I0927 10:14:39.262127  3315 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0927 10:14:39.262153  3315 layer_factory.hpp:77] Creating layer Scale21
I0927 10:14:39.262225  3315 net.cpp:122] Setting up Scale21
I0927 10:14:39.262229  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.262231  3315 net.cpp:137] Memory required for data: 709018800
I0927 10:14:39.262235  3315 layer_factory.hpp:77] Creating layer penlu20
I0927 10:14:39.262240  3315 net.cpp:84] Creating Layer penlu20
I0927 10:14:39.262243  3315 net.cpp:406] penlu20 <- Convolution21
I0927 10:14:39.262248  3315 net.cpp:367] penlu20 -> Convolution21 (in-place)
I0927 10:14:39.262364  3315 net.cpp:122] Setting up penlu20
I0927 10:14:39.262368  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.262370  3315 net.cpp:137] Memory required for data: 712295600
I0927 10:14:39.262375  3315 layer_factory.hpp:77] Creating layer Convolution22
I0927 10:14:39.262382  3315 net.cpp:84] Creating Layer Convolution22
I0927 10:14:39.262384  3315 net.cpp:406] Convolution22 <- Convolution21
I0927 10:14:39.262389  3315 net.cpp:380] Convolution22 -> Convolution22
I0927 10:14:39.263499  3315 net.cpp:122] Setting up Convolution22
I0927 10:14:39.263509  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.263511  3315 net.cpp:137] Memory required for data: 715572400
I0927 10:14:39.263515  3315 layer_factory.hpp:77] Creating layer BatchNorm22
I0927 10:14:39.263520  3315 net.cpp:84] Creating Layer BatchNorm22
I0927 10:14:39.263523  3315 net.cpp:406] BatchNorm22 <- Convolution22
I0927 10:14:39.263527  3315 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0927 10:14:39.263649  3315 net.cpp:122] Setting up BatchNorm22
I0927 10:14:39.263653  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.263655  3315 net.cpp:137] Memory required for data: 718849200
I0927 10:14:39.263660  3315 layer_factory.hpp:77] Creating layer Scale22
I0927 10:14:39.263665  3315 net.cpp:84] Creating Layer Scale22
I0927 10:14:39.263667  3315 net.cpp:406] Scale22 <- Convolution22
I0927 10:14:39.263671  3315 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0927 10:14:39.263696  3315 layer_factory.hpp:77] Creating layer Scale22
I0927 10:14:39.263768  3315 net.cpp:122] Setting up Scale22
I0927 10:14:39.263772  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.263774  3315 net.cpp:137] Memory required for data: 722126000
I0927 10:14:39.263778  3315 layer_factory.hpp:77] Creating layer Eltwise10
I0927 10:14:39.263783  3315 net.cpp:84] Creating Layer Eltwise10
I0927 10:14:39.263785  3315 net.cpp:406] Eltwise10 <- Convolution20
I0927 10:14:39.263788  3315 net.cpp:406] Eltwise10 <- Convolution22
I0927 10:14:39.263792  3315 net.cpp:380] Eltwise10 -> Eltwise10
I0927 10:14:39.263803  3315 net.cpp:122] Setting up Eltwise10
I0927 10:14:39.263808  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.263809  3315 net.cpp:137] Memory required for data: 725402800
I0927 10:14:39.263811  3315 layer_factory.hpp:77] Creating layer penlu21
I0927 10:14:39.263816  3315 net.cpp:84] Creating Layer penlu21
I0927 10:14:39.263818  3315 net.cpp:406] penlu21 <- Eltwise10
I0927 10:14:39.263823  3315 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I0927 10:14:39.263936  3315 net.cpp:122] Setting up penlu21
I0927 10:14:39.263941  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.263942  3315 net.cpp:137] Memory required for data: 728679600
I0927 10:14:39.263947  3315 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I0927 10:14:39.263950  3315 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I0927 10:14:39.263952  3315 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I0927 10:14:39.263957  3315 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I0927 10:14:39.263960  3315 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I0927 10:14:39.263983  3315 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I0927 10:14:39.263985  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.263988  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.263990  3315 net.cpp:137] Memory required for data: 735233200
I0927 10:14:39.263993  3315 layer_factory.hpp:77] Creating layer Convolution23
I0927 10:14:39.263999  3315 net.cpp:84] Creating Layer Convolution23
I0927 10:14:39.264001  3315 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I0927 10:14:39.264005  3315 net.cpp:380] Convolution23 -> Convolution23
I0927 10:14:39.265091  3315 net.cpp:122] Setting up Convolution23
I0927 10:14:39.265100  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.265102  3315 net.cpp:137] Memory required for data: 738510000
I0927 10:14:39.265107  3315 layer_factory.hpp:77] Creating layer BatchNorm23
I0927 10:14:39.265112  3315 net.cpp:84] Creating Layer BatchNorm23
I0927 10:14:39.265115  3315 net.cpp:406] BatchNorm23 <- Convolution23
I0927 10:14:39.265118  3315 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0927 10:14:39.265240  3315 net.cpp:122] Setting up BatchNorm23
I0927 10:14:39.265244  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.265246  3315 net.cpp:137] Memory required for data: 741786800
I0927 10:14:39.265251  3315 layer_factory.hpp:77] Creating layer Scale23
I0927 10:14:39.265255  3315 net.cpp:84] Creating Layer Scale23
I0927 10:14:39.265257  3315 net.cpp:406] Scale23 <- Convolution23
I0927 10:14:39.265261  3315 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0927 10:14:39.265285  3315 layer_factory.hpp:77] Creating layer Scale23
I0927 10:14:39.265357  3315 net.cpp:122] Setting up Scale23
I0927 10:14:39.265362  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.265363  3315 net.cpp:137] Memory required for data: 745063600
I0927 10:14:39.265367  3315 layer_factory.hpp:77] Creating layer penlu22
I0927 10:14:39.265373  3315 net.cpp:84] Creating Layer penlu22
I0927 10:14:39.265375  3315 net.cpp:406] penlu22 <- Convolution23
I0927 10:14:39.265379  3315 net.cpp:367] penlu22 -> Convolution23 (in-place)
I0927 10:14:39.265485  3315 net.cpp:122] Setting up penlu22
I0927 10:14:39.265488  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.265491  3315 net.cpp:137] Memory required for data: 748340400
I0927 10:14:39.265494  3315 layer_factory.hpp:77] Creating layer Convolution24
I0927 10:14:39.265502  3315 net.cpp:84] Creating Layer Convolution24
I0927 10:14:39.265504  3315 net.cpp:406] Convolution24 <- Convolution23
I0927 10:14:39.265508  3315 net.cpp:380] Convolution24 -> Convolution24
I0927 10:14:39.266607  3315 net.cpp:122] Setting up Convolution24
I0927 10:14:39.266616  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.266619  3315 net.cpp:137] Memory required for data: 751617200
I0927 10:14:39.266623  3315 layer_factory.hpp:77] Creating layer BatchNorm24
I0927 10:14:39.266629  3315 net.cpp:84] Creating Layer BatchNorm24
I0927 10:14:39.266631  3315 net.cpp:406] BatchNorm24 <- Convolution24
I0927 10:14:39.266636  3315 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0927 10:14:39.266762  3315 net.cpp:122] Setting up BatchNorm24
I0927 10:14:39.266767  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.266768  3315 net.cpp:137] Memory required for data: 754894000
I0927 10:14:39.266779  3315 layer_factory.hpp:77] Creating layer Scale24
I0927 10:14:39.266784  3315 net.cpp:84] Creating Layer Scale24
I0927 10:14:39.266786  3315 net.cpp:406] Scale24 <- Convolution24
I0927 10:14:39.266790  3315 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0927 10:14:39.266816  3315 layer_factory.hpp:77] Creating layer Scale24
I0927 10:14:39.266888  3315 net.cpp:122] Setting up Scale24
I0927 10:14:39.266892  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.266894  3315 net.cpp:137] Memory required for data: 758170800
I0927 10:14:39.266898  3315 layer_factory.hpp:77] Creating layer Eltwise11
I0927 10:14:39.266902  3315 net.cpp:84] Creating Layer Eltwise11
I0927 10:14:39.266904  3315 net.cpp:406] Eltwise11 <- Eltwise10_penlu21_0_split_1
I0927 10:14:39.266907  3315 net.cpp:406] Eltwise11 <- Convolution24
I0927 10:14:39.266911  3315 net.cpp:380] Eltwise11 -> Eltwise11
I0927 10:14:39.266922  3315 net.cpp:122] Setting up Eltwise11
I0927 10:14:39.266927  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.266928  3315 net.cpp:137] Memory required for data: 761447600
I0927 10:14:39.266930  3315 layer_factory.hpp:77] Creating layer penlu23
I0927 10:14:39.266935  3315 net.cpp:84] Creating Layer penlu23
I0927 10:14:39.266938  3315 net.cpp:406] penlu23 <- Eltwise11
I0927 10:14:39.266942  3315 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I0927 10:14:39.267048  3315 net.cpp:122] Setting up penlu23
I0927 10:14:39.267053  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.267055  3315 net.cpp:137] Memory required for data: 764724400
I0927 10:14:39.267060  3315 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I0927 10:14:39.267063  3315 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I0927 10:14:39.267066  3315 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I0927 10:14:39.267069  3315 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I0927 10:14:39.267074  3315 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I0927 10:14:39.267096  3315 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I0927 10:14:39.267099  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.267102  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.267104  3315 net.cpp:137] Memory required for data: 771278000
I0927 10:14:39.267107  3315 layer_factory.hpp:77] Creating layer Convolution25
I0927 10:14:39.267112  3315 net.cpp:84] Creating Layer Convolution25
I0927 10:14:39.267114  3315 net.cpp:406] Convolution25 <- Eltwise11_penlu23_0_split_0
I0927 10:14:39.267119  3315 net.cpp:380] Convolution25 -> Convolution25
I0927 10:14:39.268208  3315 net.cpp:122] Setting up Convolution25
I0927 10:14:39.268216  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.268219  3315 net.cpp:137] Memory required for data: 774554800
I0927 10:14:39.268224  3315 layer_factory.hpp:77] Creating layer BatchNorm25
I0927 10:14:39.268229  3315 net.cpp:84] Creating Layer BatchNorm25
I0927 10:14:39.268231  3315 net.cpp:406] BatchNorm25 <- Convolution25
I0927 10:14:39.268235  3315 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0927 10:14:39.268364  3315 net.cpp:122] Setting up BatchNorm25
I0927 10:14:39.268369  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.268371  3315 net.cpp:137] Memory required for data: 777831600
I0927 10:14:39.268376  3315 layer_factory.hpp:77] Creating layer Scale25
I0927 10:14:39.268380  3315 net.cpp:84] Creating Layer Scale25
I0927 10:14:39.268383  3315 net.cpp:406] Scale25 <- Convolution25
I0927 10:14:39.268386  3315 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0927 10:14:39.268412  3315 layer_factory.hpp:77] Creating layer Scale25
I0927 10:14:39.268484  3315 net.cpp:122] Setting up Scale25
I0927 10:14:39.268488  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.268491  3315 net.cpp:137] Memory required for data: 781108400
I0927 10:14:39.268494  3315 layer_factory.hpp:77] Creating layer penlu24
I0927 10:14:39.268501  3315 net.cpp:84] Creating Layer penlu24
I0927 10:14:39.268509  3315 net.cpp:406] penlu24 <- Convolution25
I0927 10:14:39.268514  3315 net.cpp:367] penlu24 -> Convolution25 (in-place)
I0927 10:14:39.268620  3315 net.cpp:122] Setting up penlu24
I0927 10:14:39.268625  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.268627  3315 net.cpp:137] Memory required for data: 784385200
I0927 10:14:39.268631  3315 layer_factory.hpp:77] Creating layer Convolution26
I0927 10:14:39.268638  3315 net.cpp:84] Creating Layer Convolution26
I0927 10:14:39.268640  3315 net.cpp:406] Convolution26 <- Convolution25
I0927 10:14:39.268645  3315 net.cpp:380] Convolution26 -> Convolution26
I0927 10:14:39.269397  3315 net.cpp:122] Setting up Convolution26
I0927 10:14:39.269407  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.269408  3315 net.cpp:137] Memory required for data: 787662000
I0927 10:14:39.269412  3315 layer_factory.hpp:77] Creating layer BatchNorm26
I0927 10:14:39.269418  3315 net.cpp:84] Creating Layer BatchNorm26
I0927 10:14:39.269419  3315 net.cpp:406] BatchNorm26 <- Convolution26
I0927 10:14:39.269424  3315 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0927 10:14:39.269549  3315 net.cpp:122] Setting up BatchNorm26
I0927 10:14:39.269553  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.269556  3315 net.cpp:137] Memory required for data: 790938800
I0927 10:14:39.269560  3315 layer_factory.hpp:77] Creating layer Scale26
I0927 10:14:39.269564  3315 net.cpp:84] Creating Layer Scale26
I0927 10:14:39.269567  3315 net.cpp:406] Scale26 <- Convolution26
I0927 10:14:39.269569  3315 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0927 10:14:39.269594  3315 layer_factory.hpp:77] Creating layer Scale26
I0927 10:14:39.289098  3315 net.cpp:122] Setting up Scale26
I0927 10:14:39.289106  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.289108  3315 net.cpp:137] Memory required for data: 794215600
I0927 10:14:39.289113  3315 layer_factory.hpp:77] Creating layer Eltwise12
I0927 10:14:39.289119  3315 net.cpp:84] Creating Layer Eltwise12
I0927 10:14:39.289121  3315 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I0927 10:14:39.289124  3315 net.cpp:406] Eltwise12 <- Convolution26
I0927 10:14:39.289129  3315 net.cpp:380] Eltwise12 -> Eltwise12
I0927 10:14:39.289144  3315 net.cpp:122] Setting up Eltwise12
I0927 10:14:39.289147  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.289149  3315 net.cpp:137] Memory required for data: 797492400
I0927 10:14:39.289152  3315 layer_factory.hpp:77] Creating layer penlu25
I0927 10:14:39.289165  3315 net.cpp:84] Creating Layer penlu25
I0927 10:14:39.289168  3315 net.cpp:406] penlu25 <- Eltwise12
I0927 10:14:39.289172  3315 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I0927 10:14:39.289293  3315 net.cpp:122] Setting up penlu25
I0927 10:14:39.289299  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.289300  3315 net.cpp:137] Memory required for data: 800769200
I0927 10:14:39.289324  3315 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I0927 10:14:39.289328  3315 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I0927 10:14:39.289331  3315 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I0927 10:14:39.289335  3315 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I0927 10:14:39.289340  3315 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I0927 10:14:39.289366  3315 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I0927 10:14:39.289371  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.289374  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.289376  3315 net.cpp:137] Memory required for data: 807322800
I0927 10:14:39.289378  3315 layer_factory.hpp:77] Creating layer Convolution27
I0927 10:14:39.289386  3315 net.cpp:84] Creating Layer Convolution27
I0927 10:14:39.289388  3315 net.cpp:406] Convolution27 <- Eltwise12_penlu25_0_split_0
I0927 10:14:39.289393  3315 net.cpp:380] Convolution27 -> Convolution27
I0927 10:14:39.290988  3315 net.cpp:122] Setting up Convolution27
I0927 10:14:39.291005  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.291008  3315 net.cpp:137] Memory required for data: 810599600
I0927 10:14:39.291013  3315 layer_factory.hpp:77] Creating layer BatchNorm27
I0927 10:14:39.291018  3315 net.cpp:84] Creating Layer BatchNorm27
I0927 10:14:39.291020  3315 net.cpp:406] BatchNorm27 <- Convolution27
I0927 10:14:39.291025  3315 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0927 10:14:39.291157  3315 net.cpp:122] Setting up BatchNorm27
I0927 10:14:39.291162  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.291164  3315 net.cpp:137] Memory required for data: 813876400
I0927 10:14:39.291169  3315 layer_factory.hpp:77] Creating layer Scale27
I0927 10:14:39.291173  3315 net.cpp:84] Creating Layer Scale27
I0927 10:14:39.291177  3315 net.cpp:406] Scale27 <- Convolution27
I0927 10:14:39.291179  3315 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0927 10:14:39.291208  3315 layer_factory.hpp:77] Creating layer Scale27
I0927 10:14:39.291281  3315 net.cpp:122] Setting up Scale27
I0927 10:14:39.291286  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.291288  3315 net.cpp:137] Memory required for data: 817153200
I0927 10:14:39.291292  3315 layer_factory.hpp:77] Creating layer penlu26
I0927 10:14:39.291297  3315 net.cpp:84] Creating Layer penlu26
I0927 10:14:39.291301  3315 net.cpp:406] penlu26 <- Convolution27
I0927 10:14:39.291304  3315 net.cpp:367] penlu26 -> Convolution27 (in-place)
I0927 10:14:39.291414  3315 net.cpp:122] Setting up penlu26
I0927 10:14:39.291419  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.291420  3315 net.cpp:137] Memory required for data: 820430000
I0927 10:14:39.291425  3315 layer_factory.hpp:77] Creating layer Convolution28
I0927 10:14:39.291432  3315 net.cpp:84] Creating Layer Convolution28
I0927 10:14:39.291435  3315 net.cpp:406] Convolution28 <- Convolution27
I0927 10:14:39.291440  3315 net.cpp:380] Convolution28 -> Convolution28
I0927 10:14:39.292938  3315 net.cpp:122] Setting up Convolution28
I0927 10:14:39.292948  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.292950  3315 net.cpp:137] Memory required for data: 823706800
I0927 10:14:39.292954  3315 layer_factory.hpp:77] Creating layer BatchNorm28
I0927 10:14:39.292959  3315 net.cpp:84] Creating Layer BatchNorm28
I0927 10:14:39.292963  3315 net.cpp:406] BatchNorm28 <- Convolution28
I0927 10:14:39.292966  3315 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0927 10:14:39.293098  3315 net.cpp:122] Setting up BatchNorm28
I0927 10:14:39.293103  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.293105  3315 net.cpp:137] Memory required for data: 826983600
I0927 10:14:39.293110  3315 layer_factory.hpp:77] Creating layer Scale28
I0927 10:14:39.293114  3315 net.cpp:84] Creating Layer Scale28
I0927 10:14:39.293117  3315 net.cpp:406] Scale28 <- Convolution28
I0927 10:14:39.293120  3315 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0927 10:14:39.293148  3315 layer_factory.hpp:77] Creating layer Scale28
I0927 10:14:39.293222  3315 net.cpp:122] Setting up Scale28
I0927 10:14:39.293226  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.293228  3315 net.cpp:137] Memory required for data: 830260400
I0927 10:14:39.293232  3315 layer_factory.hpp:77] Creating layer Eltwise13
I0927 10:14:39.293237  3315 net.cpp:84] Creating Layer Eltwise13
I0927 10:14:39.293241  3315 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I0927 10:14:39.293243  3315 net.cpp:406] Eltwise13 <- Convolution28
I0927 10:14:39.293246  3315 net.cpp:380] Eltwise13 -> Eltwise13
I0927 10:14:39.293258  3315 net.cpp:122] Setting up Eltwise13
I0927 10:14:39.293262  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.293263  3315 net.cpp:137] Memory required for data: 833537200
I0927 10:14:39.293265  3315 layer_factory.hpp:77] Creating layer penlu27
I0927 10:14:39.293272  3315 net.cpp:84] Creating Layer penlu27
I0927 10:14:39.293273  3315 net.cpp:406] penlu27 <- Eltwise13
I0927 10:14:39.293285  3315 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I0927 10:14:39.293400  3315 net.cpp:122] Setting up penlu27
I0927 10:14:39.293403  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.293406  3315 net.cpp:137] Memory required for data: 836814000
I0927 10:14:39.293411  3315 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I0927 10:14:39.293414  3315 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I0927 10:14:39.293416  3315 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I0927 10:14:39.293419  3315 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I0927 10:14:39.293426  3315 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I0927 10:14:39.293447  3315 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I0927 10:14:39.293452  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.293453  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.293455  3315 net.cpp:137] Memory required for data: 843367600
I0927 10:14:39.293458  3315 layer_factory.hpp:77] Creating layer Convolution29
I0927 10:14:39.293464  3315 net.cpp:84] Creating Layer Convolution29
I0927 10:14:39.293467  3315 net.cpp:406] Convolution29 <- Eltwise13_penlu27_0_split_0
I0927 10:14:39.293471  3315 net.cpp:380] Convolution29 -> Convolution29
I0927 10:14:39.294569  3315 net.cpp:122] Setting up Convolution29
I0927 10:14:39.294579  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.294580  3315 net.cpp:137] Memory required for data: 846644400
I0927 10:14:39.294585  3315 layer_factory.hpp:77] Creating layer BatchNorm29
I0927 10:14:39.294591  3315 net.cpp:84] Creating Layer BatchNorm29
I0927 10:14:39.294595  3315 net.cpp:406] BatchNorm29 <- Convolution29
I0927 10:14:39.294600  3315 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0927 10:14:39.294728  3315 net.cpp:122] Setting up BatchNorm29
I0927 10:14:39.294733  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.294734  3315 net.cpp:137] Memory required for data: 849921200
I0927 10:14:39.294739  3315 layer_factory.hpp:77] Creating layer Scale29
I0927 10:14:39.294744  3315 net.cpp:84] Creating Layer Scale29
I0927 10:14:39.294745  3315 net.cpp:406] Scale29 <- Convolution29
I0927 10:14:39.294749  3315 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0927 10:14:39.294775  3315 layer_factory.hpp:77] Creating layer Scale29
I0927 10:14:39.294849  3315 net.cpp:122] Setting up Scale29
I0927 10:14:39.294854  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.294857  3315 net.cpp:137] Memory required for data: 853198000
I0927 10:14:39.294860  3315 layer_factory.hpp:77] Creating layer penlu28
I0927 10:14:39.294864  3315 net.cpp:84] Creating Layer penlu28
I0927 10:14:39.294867  3315 net.cpp:406] penlu28 <- Convolution29
I0927 10:14:39.294872  3315 net.cpp:367] penlu28 -> Convolution29 (in-place)
I0927 10:14:39.294981  3315 net.cpp:122] Setting up penlu28
I0927 10:14:39.294986  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.294987  3315 net.cpp:137] Memory required for data: 856474800
I0927 10:14:39.294991  3315 layer_factory.hpp:77] Creating layer Convolution30
I0927 10:14:39.294998  3315 net.cpp:84] Creating Layer Convolution30
I0927 10:14:39.295001  3315 net.cpp:406] Convolution30 <- Convolution29
I0927 10:14:39.295004  3315 net.cpp:380] Convolution30 -> Convolution30
I0927 10:14:39.296095  3315 net.cpp:122] Setting up Convolution30
I0927 10:14:39.296104  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.296108  3315 net.cpp:137] Memory required for data: 859751600
I0927 10:14:39.296111  3315 layer_factory.hpp:77] Creating layer BatchNorm30
I0927 10:14:39.296118  3315 net.cpp:84] Creating Layer BatchNorm30
I0927 10:14:39.296120  3315 net.cpp:406] BatchNorm30 <- Convolution30
I0927 10:14:39.296123  3315 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0927 10:14:39.296248  3315 net.cpp:122] Setting up BatchNorm30
I0927 10:14:39.296253  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.296255  3315 net.cpp:137] Memory required for data: 863028400
I0927 10:14:39.296267  3315 layer_factory.hpp:77] Creating layer Scale30
I0927 10:14:39.296272  3315 net.cpp:84] Creating Layer Scale30
I0927 10:14:39.296274  3315 net.cpp:406] Scale30 <- Convolution30
I0927 10:14:39.296278  3315 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0927 10:14:39.296304  3315 layer_factory.hpp:77] Creating layer Scale30
I0927 10:14:39.296377  3315 net.cpp:122] Setting up Scale30
I0927 10:14:39.296382  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.296385  3315 net.cpp:137] Memory required for data: 866305200
I0927 10:14:39.296388  3315 layer_factory.hpp:77] Creating layer Eltwise14
I0927 10:14:39.296392  3315 net.cpp:84] Creating Layer Eltwise14
I0927 10:14:39.296396  3315 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I0927 10:14:39.296398  3315 net.cpp:406] Eltwise14 <- Convolution30
I0927 10:14:39.296401  3315 net.cpp:380] Eltwise14 -> Eltwise14
I0927 10:14:39.296414  3315 net.cpp:122] Setting up Eltwise14
I0927 10:14:39.296418  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.296421  3315 net.cpp:137] Memory required for data: 869582000
I0927 10:14:39.296422  3315 layer_factory.hpp:77] Creating layer penlu29
I0927 10:14:39.296427  3315 net.cpp:84] Creating Layer penlu29
I0927 10:14:39.296429  3315 net.cpp:406] penlu29 <- Eltwise14
I0927 10:14:39.296433  3315 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I0927 10:14:39.296540  3315 net.cpp:122] Setting up penlu29
I0927 10:14:39.296545  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.296546  3315 net.cpp:137] Memory required for data: 872858800
I0927 10:14:39.296551  3315 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I0927 10:14:39.296555  3315 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I0927 10:14:39.296556  3315 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I0927 10:14:39.296561  3315 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I0927 10:14:39.296564  3315 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I0927 10:14:39.296587  3315 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I0927 10:14:39.296591  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.296593  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.296596  3315 net.cpp:137] Memory required for data: 879412400
I0927 10:14:39.296597  3315 layer_factory.hpp:77] Creating layer Convolution31
I0927 10:14:39.296603  3315 net.cpp:84] Creating Layer Convolution31
I0927 10:14:39.296607  3315 net.cpp:406] Convolution31 <- Eltwise14_penlu29_0_split_0
I0927 10:14:39.296610  3315 net.cpp:380] Convolution31 -> Convolution31
I0927 10:14:39.297700  3315 net.cpp:122] Setting up Convolution31
I0927 10:14:39.297709  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.297711  3315 net.cpp:137] Memory required for data: 882689200
I0927 10:14:39.297716  3315 layer_factory.hpp:77] Creating layer BatchNorm31
I0927 10:14:39.297720  3315 net.cpp:84] Creating Layer BatchNorm31
I0927 10:14:39.297724  3315 net.cpp:406] BatchNorm31 <- Convolution31
I0927 10:14:39.297729  3315 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0927 10:14:39.297853  3315 net.cpp:122] Setting up BatchNorm31
I0927 10:14:39.297858  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.297860  3315 net.cpp:137] Memory required for data: 885966000
I0927 10:14:39.297865  3315 layer_factory.hpp:77] Creating layer Scale31
I0927 10:14:39.297869  3315 net.cpp:84] Creating Layer Scale31
I0927 10:14:39.297871  3315 net.cpp:406] Scale31 <- Convolution31
I0927 10:14:39.297874  3315 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0927 10:14:39.297901  3315 layer_factory.hpp:77] Creating layer Scale31
I0927 10:14:39.297972  3315 net.cpp:122] Setting up Scale31
I0927 10:14:39.297976  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.297978  3315 net.cpp:137] Memory required for data: 889242800
I0927 10:14:39.297982  3315 layer_factory.hpp:77] Creating layer penlu30
I0927 10:14:39.297988  3315 net.cpp:84] Creating Layer penlu30
I0927 10:14:39.297997  3315 net.cpp:406] penlu30 <- Convolution31
I0927 10:14:39.298002  3315 net.cpp:367] penlu30 -> Convolution31 (in-place)
I0927 10:14:39.298106  3315 net.cpp:122] Setting up penlu30
I0927 10:14:39.298110  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.298112  3315 net.cpp:137] Memory required for data: 892519600
I0927 10:14:39.298117  3315 layer_factory.hpp:77] Creating layer Convolution32
I0927 10:14:39.298125  3315 net.cpp:84] Creating Layer Convolution32
I0927 10:14:39.298126  3315 net.cpp:406] Convolution32 <- Convolution31
I0927 10:14:39.298130  3315 net.cpp:380] Convolution32 -> Convolution32
I0927 10:14:39.299233  3315 net.cpp:122] Setting up Convolution32
I0927 10:14:39.299242  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.299245  3315 net.cpp:137] Memory required for data: 895796400
I0927 10:14:39.299249  3315 layer_factory.hpp:77] Creating layer BatchNorm32
I0927 10:14:39.299255  3315 net.cpp:84] Creating Layer BatchNorm32
I0927 10:14:39.299258  3315 net.cpp:406] BatchNorm32 <- Convolution32
I0927 10:14:39.299263  3315 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0927 10:14:39.299387  3315 net.cpp:122] Setting up BatchNorm32
I0927 10:14:39.299391  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.299394  3315 net.cpp:137] Memory required for data: 899073200
I0927 10:14:39.299398  3315 layer_factory.hpp:77] Creating layer Scale32
I0927 10:14:39.299402  3315 net.cpp:84] Creating Layer Scale32
I0927 10:14:39.299405  3315 net.cpp:406] Scale32 <- Convolution32
I0927 10:14:39.320034  3315 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0927 10:14:39.320077  3315 layer_factory.hpp:77] Creating layer Scale32
I0927 10:14:39.320164  3315 net.cpp:122] Setting up Scale32
I0927 10:14:39.320169  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.320173  3315 net.cpp:137] Memory required for data: 902350000
I0927 10:14:39.320178  3315 layer_factory.hpp:77] Creating layer Eltwise15
I0927 10:14:39.320181  3315 net.cpp:84] Creating Layer Eltwise15
I0927 10:14:39.320184  3315 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I0927 10:14:39.320188  3315 net.cpp:406] Eltwise15 <- Convolution32
I0927 10:14:39.320191  3315 net.cpp:380] Eltwise15 -> Eltwise15
I0927 10:14:39.320205  3315 net.cpp:122] Setting up Eltwise15
I0927 10:14:39.320209  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.320211  3315 net.cpp:137] Memory required for data: 905626800
I0927 10:14:39.320214  3315 layer_factory.hpp:77] Creating layer penlu31
I0927 10:14:39.320219  3315 net.cpp:84] Creating Layer penlu31
I0927 10:14:39.320222  3315 net.cpp:406] penlu31 <- Eltwise15
I0927 10:14:39.320226  3315 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I0927 10:14:39.320348  3315 net.cpp:122] Setting up penlu31
I0927 10:14:39.320353  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.320354  3315 net.cpp:137] Memory required for data: 908903600
I0927 10:14:39.320359  3315 layer_factory.hpp:77] Creating layer Eltwise15_penlu31_0_split
I0927 10:14:39.320364  3315 net.cpp:84] Creating Layer Eltwise15_penlu31_0_split
I0927 10:14:39.320367  3315 net.cpp:406] Eltwise15_penlu31_0_split <- Eltwise15
I0927 10:14:39.320370  3315 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_0
I0927 10:14:39.320375  3315 net.cpp:380] Eltwise15_penlu31_0_split -> Eltwise15_penlu31_0_split_1
I0927 10:14:39.320400  3315 net.cpp:122] Setting up Eltwise15_penlu31_0_split
I0927 10:14:39.320405  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.320407  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.320410  3315 net.cpp:137] Memory required for data: 915457200
I0927 10:14:39.320412  3315 layer_factory.hpp:77] Creating layer Convolution33
I0927 10:14:39.320418  3315 net.cpp:84] Creating Layer Convolution33
I0927 10:14:39.320420  3315 net.cpp:406] Convolution33 <- Eltwise15_penlu31_0_split_0
I0927 10:14:39.320425  3315 net.cpp:380] Convolution33 -> Convolution33
I0927 10:14:39.321676  3315 net.cpp:122] Setting up Convolution33
I0927 10:14:39.321697  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.321703  3315 net.cpp:137] Memory required for data: 918734000
I0927 10:14:39.321710  3315 layer_factory.hpp:77] Creating layer BatchNorm33
I0927 10:14:39.321717  3315 net.cpp:84] Creating Layer BatchNorm33
I0927 10:14:39.321720  3315 net.cpp:406] BatchNorm33 <- Convolution33
I0927 10:14:39.321724  3315 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0927 10:14:39.321871  3315 net.cpp:122] Setting up BatchNorm33
I0927 10:14:39.321876  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.321877  3315 net.cpp:137] Memory required for data: 922010800
I0927 10:14:39.321882  3315 layer_factory.hpp:77] Creating layer Scale33
I0927 10:14:39.321887  3315 net.cpp:84] Creating Layer Scale33
I0927 10:14:39.321889  3315 net.cpp:406] Scale33 <- Convolution33
I0927 10:14:39.321893  3315 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0927 10:14:39.321920  3315 layer_factory.hpp:77] Creating layer Scale33
I0927 10:14:39.321996  3315 net.cpp:122] Setting up Scale33
I0927 10:14:39.322001  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.322003  3315 net.cpp:137] Memory required for data: 925287600
I0927 10:14:39.322007  3315 layer_factory.hpp:77] Creating layer penlu32
I0927 10:14:39.322012  3315 net.cpp:84] Creating Layer penlu32
I0927 10:14:39.322016  3315 net.cpp:406] penlu32 <- Convolution33
I0927 10:14:39.322019  3315 net.cpp:367] penlu32 -> Convolution33 (in-place)
I0927 10:14:39.322125  3315 net.cpp:122] Setting up penlu32
I0927 10:14:39.322129  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.322132  3315 net.cpp:137] Memory required for data: 928564400
I0927 10:14:39.322136  3315 layer_factory.hpp:77] Creating layer Convolution34
I0927 10:14:39.322144  3315 net.cpp:84] Creating Layer Convolution34
I0927 10:14:39.322145  3315 net.cpp:406] Convolution34 <- Convolution33
I0927 10:14:39.322149  3315 net.cpp:380] Convolution34 -> Convolution34
I0927 10:14:39.323945  3315 net.cpp:122] Setting up Convolution34
I0927 10:14:39.323956  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.323958  3315 net.cpp:137] Memory required for data: 931841200
I0927 10:14:39.323963  3315 layer_factory.hpp:77] Creating layer BatchNorm34
I0927 10:14:39.323971  3315 net.cpp:84] Creating Layer BatchNorm34
I0927 10:14:39.323973  3315 net.cpp:406] BatchNorm34 <- Convolution34
I0927 10:14:39.323977  3315 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0927 10:14:39.324122  3315 net.cpp:122] Setting up BatchNorm34
I0927 10:14:39.324127  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.324129  3315 net.cpp:137] Memory required for data: 935118000
I0927 10:14:39.324134  3315 layer_factory.hpp:77] Creating layer Scale34
I0927 10:14:39.324139  3315 net.cpp:84] Creating Layer Scale34
I0927 10:14:39.324141  3315 net.cpp:406] Scale34 <- Convolution34
I0927 10:14:39.324146  3315 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0927 10:14:39.324173  3315 layer_factory.hpp:77] Creating layer Scale34
I0927 10:14:39.324249  3315 net.cpp:122] Setting up Scale34
I0927 10:14:39.324254  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.324255  3315 net.cpp:137] Memory required for data: 938394800
I0927 10:14:39.324259  3315 layer_factory.hpp:77] Creating layer Eltwise16
I0927 10:14:39.324264  3315 net.cpp:84] Creating Layer Eltwise16
I0927 10:14:39.324267  3315 net.cpp:406] Eltwise16 <- Eltwise15_penlu31_0_split_1
I0927 10:14:39.324270  3315 net.cpp:406] Eltwise16 <- Convolution34
I0927 10:14:39.324275  3315 net.cpp:380] Eltwise16 -> Eltwise16
I0927 10:14:39.324287  3315 net.cpp:122] Setting up Eltwise16
I0927 10:14:39.324292  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.324295  3315 net.cpp:137] Memory required for data: 941671600
I0927 10:14:39.324296  3315 layer_factory.hpp:77] Creating layer penlu33
I0927 10:14:39.324301  3315 net.cpp:84] Creating Layer penlu33
I0927 10:14:39.324303  3315 net.cpp:406] penlu33 <- Eltwise16
I0927 10:14:39.324317  3315 net.cpp:367] penlu33 -> Eltwise16 (in-place)
I0927 10:14:39.324431  3315 net.cpp:122] Setting up penlu33
I0927 10:14:39.324435  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.324437  3315 net.cpp:137] Memory required for data: 944948400
I0927 10:14:39.324442  3315 layer_factory.hpp:77] Creating layer Eltwise16_penlu33_0_split
I0927 10:14:39.324446  3315 net.cpp:84] Creating Layer Eltwise16_penlu33_0_split
I0927 10:14:39.324448  3315 net.cpp:406] Eltwise16_penlu33_0_split <- Eltwise16
I0927 10:14:39.324452  3315 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_0
I0927 10:14:39.324456  3315 net.cpp:380] Eltwise16_penlu33_0_split -> Eltwise16_penlu33_0_split_1
I0927 10:14:39.324481  3315 net.cpp:122] Setting up Eltwise16_penlu33_0_split
I0927 10:14:39.324484  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.324487  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.324489  3315 net.cpp:137] Memory required for data: 951502000
I0927 10:14:39.324491  3315 layer_factory.hpp:77] Creating layer Convolution35
I0927 10:14:39.324497  3315 net.cpp:84] Creating Layer Convolution35
I0927 10:14:39.324499  3315 net.cpp:406] Convolution35 <- Eltwise16_penlu33_0_split_0
I0927 10:14:39.324504  3315 net.cpp:380] Convolution35 -> Convolution35
I0927 10:14:39.325615  3315 net.cpp:122] Setting up Convolution35
I0927 10:14:39.325624  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.325628  3315 net.cpp:137] Memory required for data: 954778800
I0927 10:14:39.325633  3315 layer_factory.hpp:77] Creating layer BatchNorm35
I0927 10:14:39.325636  3315 net.cpp:84] Creating Layer BatchNorm35
I0927 10:14:39.325639  3315 net.cpp:406] BatchNorm35 <- Convolution35
I0927 10:14:39.325644  3315 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0927 10:14:39.325775  3315 net.cpp:122] Setting up BatchNorm35
I0927 10:14:39.325780  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.325783  3315 net.cpp:137] Memory required for data: 958055600
I0927 10:14:39.325788  3315 layer_factory.hpp:77] Creating layer Scale35
I0927 10:14:39.325791  3315 net.cpp:84] Creating Layer Scale35
I0927 10:14:39.325794  3315 net.cpp:406] Scale35 <- Convolution35
I0927 10:14:39.325798  3315 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0927 10:14:39.325824  3315 layer_factory.hpp:77] Creating layer Scale35
I0927 10:14:39.325901  3315 net.cpp:122] Setting up Scale35
I0927 10:14:39.325906  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.325907  3315 net.cpp:137] Memory required for data: 961332400
I0927 10:14:39.325911  3315 layer_factory.hpp:77] Creating layer penlu34
I0927 10:14:39.325917  3315 net.cpp:84] Creating Layer penlu34
I0927 10:14:39.325920  3315 net.cpp:406] penlu34 <- Convolution35
I0927 10:14:39.325923  3315 net.cpp:367] penlu34 -> Convolution35 (in-place)
I0927 10:14:39.326030  3315 net.cpp:122] Setting up penlu34
I0927 10:14:39.326035  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.326036  3315 net.cpp:137] Memory required for data: 964609200
I0927 10:14:39.326040  3315 layer_factory.hpp:77] Creating layer Convolution36
I0927 10:14:39.326047  3315 net.cpp:84] Creating Layer Convolution36
I0927 10:14:39.326050  3315 net.cpp:406] Convolution36 <- Convolution35
I0927 10:14:39.326056  3315 net.cpp:380] Convolution36 -> Convolution36
I0927 10:14:39.326843  3315 net.cpp:122] Setting up Convolution36
I0927 10:14:39.326851  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.326854  3315 net.cpp:137] Memory required for data: 967886000
I0927 10:14:39.326858  3315 layer_factory.hpp:77] Creating layer BatchNorm36
I0927 10:14:39.326864  3315 net.cpp:84] Creating Layer BatchNorm36
I0927 10:14:39.326866  3315 net.cpp:406] BatchNorm36 <- Convolution36
I0927 10:14:39.326870  3315 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0927 10:14:39.327000  3315 net.cpp:122] Setting up BatchNorm36
I0927 10:14:39.327004  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.327006  3315 net.cpp:137] Memory required for data: 971162800
I0927 10:14:39.327019  3315 layer_factory.hpp:77] Creating layer Scale36
I0927 10:14:39.327024  3315 net.cpp:84] Creating Layer Scale36
I0927 10:14:39.327026  3315 net.cpp:406] Scale36 <- Convolution36
I0927 10:14:39.327029  3315 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0927 10:14:39.327057  3315 layer_factory.hpp:77] Creating layer Scale36
I0927 10:14:39.327133  3315 net.cpp:122] Setting up Scale36
I0927 10:14:39.327137  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.327141  3315 net.cpp:137] Memory required for data: 974439600
I0927 10:14:39.327143  3315 layer_factory.hpp:77] Creating layer Eltwise17
I0927 10:14:39.327148  3315 net.cpp:84] Creating Layer Eltwise17
I0927 10:14:39.327150  3315 net.cpp:406] Eltwise17 <- Eltwise16_penlu33_0_split_1
I0927 10:14:39.327153  3315 net.cpp:406] Eltwise17 <- Convolution36
I0927 10:14:39.327157  3315 net.cpp:380] Eltwise17 -> Eltwise17
I0927 10:14:39.327169  3315 net.cpp:122] Setting up Eltwise17
I0927 10:14:39.327173  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.327175  3315 net.cpp:137] Memory required for data: 977716400
I0927 10:14:39.327178  3315 layer_factory.hpp:77] Creating layer penlu35
I0927 10:14:39.327183  3315 net.cpp:84] Creating Layer penlu35
I0927 10:14:39.327185  3315 net.cpp:406] penlu35 <- Eltwise17
I0927 10:14:39.327188  3315 net.cpp:367] penlu35 -> Eltwise17 (in-place)
I0927 10:14:39.327298  3315 net.cpp:122] Setting up penlu35
I0927 10:14:39.327303  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.327306  3315 net.cpp:137] Memory required for data: 980993200
I0927 10:14:39.327309  3315 layer_factory.hpp:77] Creating layer Eltwise17_penlu35_0_split
I0927 10:14:39.327312  3315 net.cpp:84] Creating Layer Eltwise17_penlu35_0_split
I0927 10:14:39.327316  3315 net.cpp:406] Eltwise17_penlu35_0_split <- Eltwise17
I0927 10:14:39.327318  3315 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_0
I0927 10:14:39.327322  3315 net.cpp:380] Eltwise17_penlu35_0_split -> Eltwise17_penlu35_0_split_1
I0927 10:14:39.327347  3315 net.cpp:122] Setting up Eltwise17_penlu35_0_split
I0927 10:14:39.327350  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.327353  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.327355  3315 net.cpp:137] Memory required for data: 987546800
I0927 10:14:39.327358  3315 layer_factory.hpp:77] Creating layer Convolution37
I0927 10:14:39.327363  3315 net.cpp:84] Creating Layer Convolution37
I0927 10:14:39.327366  3315 net.cpp:406] Convolution37 <- Eltwise17_penlu35_0_split_0
I0927 10:14:39.327370  3315 net.cpp:380] Convolution37 -> Convolution37
I0927 10:14:39.328467  3315 net.cpp:122] Setting up Convolution37
I0927 10:14:39.328475  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.328478  3315 net.cpp:137] Memory required for data: 990823600
I0927 10:14:39.328482  3315 layer_factory.hpp:77] Creating layer BatchNorm37
I0927 10:14:39.328488  3315 net.cpp:84] Creating Layer BatchNorm37
I0927 10:14:39.328491  3315 net.cpp:406] BatchNorm37 <- Convolution37
I0927 10:14:39.328495  3315 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0927 10:14:39.328629  3315 net.cpp:122] Setting up BatchNorm37
I0927 10:14:39.328634  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.328635  3315 net.cpp:137] Memory required for data: 994100400
I0927 10:14:39.328640  3315 layer_factory.hpp:77] Creating layer Scale37
I0927 10:14:39.328644  3315 net.cpp:84] Creating Layer Scale37
I0927 10:14:39.328646  3315 net.cpp:406] Scale37 <- Convolution37
I0927 10:14:39.328650  3315 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0927 10:14:39.328677  3315 layer_factory.hpp:77] Creating layer Scale37
I0927 10:14:39.328753  3315 net.cpp:122] Setting up Scale37
I0927 10:14:39.328758  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.328759  3315 net.cpp:137] Memory required for data: 997377200
I0927 10:14:39.328763  3315 layer_factory.hpp:77] Creating layer penlu36
I0927 10:14:39.328775  3315 net.cpp:84] Creating Layer penlu36
I0927 10:14:39.328778  3315 net.cpp:406] penlu36 <- Convolution37
I0927 10:14:39.328783  3315 net.cpp:367] penlu36 -> Convolution37 (in-place)
I0927 10:14:39.328891  3315 net.cpp:122] Setting up penlu36
I0927 10:14:39.328896  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.328898  3315 net.cpp:137] Memory required for data: 1000654000
I0927 10:14:39.328902  3315 layer_factory.hpp:77] Creating layer Convolution38
I0927 10:14:39.328909  3315 net.cpp:84] Creating Layer Convolution38
I0927 10:14:39.328912  3315 net.cpp:406] Convolution38 <- Convolution37
I0927 10:14:39.328917  3315 net.cpp:380] Convolution38 -> Convolution38
I0927 10:14:39.330338  3315 net.cpp:122] Setting up Convolution38
I0927 10:14:39.330348  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.330350  3315 net.cpp:137] Memory required for data: 1003930800
I0927 10:14:39.330354  3315 layer_factory.hpp:77] Creating layer BatchNorm38
I0927 10:14:39.330359  3315 net.cpp:84] Creating Layer BatchNorm38
I0927 10:14:39.330363  3315 net.cpp:406] BatchNorm38 <- Convolution38
I0927 10:14:39.330366  3315 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0927 10:14:39.330504  3315 net.cpp:122] Setting up BatchNorm38
I0927 10:14:39.330508  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.330512  3315 net.cpp:137] Memory required for data: 1007207600
I0927 10:14:39.350684  3315 layer_factory.hpp:77] Creating layer Scale38
I0927 10:14:39.350694  3315 net.cpp:84] Creating Layer Scale38
I0927 10:14:39.350698  3315 net.cpp:406] Scale38 <- Convolution38
I0927 10:14:39.350703  3315 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0927 10:14:39.350744  3315 layer_factory.hpp:77] Creating layer Scale38
I0927 10:14:39.350836  3315 net.cpp:122] Setting up Scale38
I0927 10:14:39.350841  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.350844  3315 net.cpp:137] Memory required for data: 1010484400
I0927 10:14:39.350848  3315 layer_factory.hpp:77] Creating layer Eltwise18
I0927 10:14:39.350853  3315 net.cpp:84] Creating Layer Eltwise18
I0927 10:14:39.350857  3315 net.cpp:406] Eltwise18 <- Eltwise17_penlu35_0_split_1
I0927 10:14:39.350860  3315 net.cpp:406] Eltwise18 <- Convolution38
I0927 10:14:39.350863  3315 net.cpp:380] Eltwise18 -> Eltwise18
I0927 10:14:39.350878  3315 net.cpp:122] Setting up Eltwise18
I0927 10:14:39.350881  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.350883  3315 net.cpp:137] Memory required for data: 1013761200
I0927 10:14:39.350886  3315 layer_factory.hpp:77] Creating layer penlu37
I0927 10:14:39.350893  3315 net.cpp:84] Creating Layer penlu37
I0927 10:14:39.350894  3315 net.cpp:406] penlu37 <- Eltwise18
I0927 10:14:39.350899  3315 net.cpp:367] penlu37 -> Eltwise18 (in-place)
I0927 10:14:39.351022  3315 net.cpp:122] Setting up penlu37
I0927 10:14:39.351027  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.351029  3315 net.cpp:137] Memory required for data: 1017038000
I0927 10:14:39.351034  3315 layer_factory.hpp:77] Creating layer Eltwise18_penlu37_0_split
I0927 10:14:39.351038  3315 net.cpp:84] Creating Layer Eltwise18_penlu37_0_split
I0927 10:14:39.351040  3315 net.cpp:406] Eltwise18_penlu37_0_split <- Eltwise18
I0927 10:14:39.351044  3315 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_0
I0927 10:14:39.351049  3315 net.cpp:380] Eltwise18_penlu37_0_split -> Eltwise18_penlu37_0_split_1
I0927 10:14:39.351075  3315 net.cpp:122] Setting up Eltwise18_penlu37_0_split
I0927 10:14:39.351079  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.351083  3315 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0927 10:14:39.351084  3315 net.cpp:137] Memory required for data: 1023591600
I0927 10:14:39.351086  3315 layer_factory.hpp:77] Creating layer Convolution39
I0927 10:14:39.351094  3315 net.cpp:84] Creating Layer Convolution39
I0927 10:14:39.351096  3315 net.cpp:406] Convolution39 <- Eltwise18_penlu37_0_split_0
I0927 10:14:39.351101  3315 net.cpp:380] Convolution39 -> Convolution39
I0927 10:14:39.352216  3315 net.cpp:122] Setting up Convolution39
I0927 10:14:39.352226  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.352229  3315 net.cpp:137] Memory required for data: 1025230000
I0927 10:14:39.352233  3315 layer_factory.hpp:77] Creating layer BatchNorm39
I0927 10:14:39.352241  3315 net.cpp:84] Creating Layer BatchNorm39
I0927 10:14:39.352244  3315 net.cpp:406] BatchNorm39 <- Convolution39
I0927 10:14:39.352249  3315 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0927 10:14:39.352450  3315 net.cpp:122] Setting up BatchNorm39
I0927 10:14:39.352466  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.352469  3315 net.cpp:137] Memory required for data: 1026868400
I0927 10:14:39.352474  3315 layer_factory.hpp:77] Creating layer Scale39
I0927 10:14:39.352478  3315 net.cpp:84] Creating Layer Scale39
I0927 10:14:39.352481  3315 net.cpp:406] Scale39 <- Convolution39
I0927 10:14:39.352485  3315 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0927 10:14:39.352515  3315 layer_factory.hpp:77] Creating layer Scale39
I0927 10:14:39.352594  3315 net.cpp:122] Setting up Scale39
I0927 10:14:39.352598  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.352600  3315 net.cpp:137] Memory required for data: 1028506800
I0927 10:14:39.352604  3315 layer_factory.hpp:77] Creating layer Convolution40
I0927 10:14:39.352612  3315 net.cpp:84] Creating Layer Convolution40
I0927 10:14:39.352615  3315 net.cpp:406] Convolution40 <- Eltwise18_penlu37_0_split_1
I0927 10:14:39.352620  3315 net.cpp:380] Convolution40 -> Convolution40
I0927 10:14:39.353991  3315 net.cpp:122] Setting up Convolution40
I0927 10:14:39.354001  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.354003  3315 net.cpp:137] Memory required for data: 1030145200
I0927 10:14:39.354007  3315 layer_factory.hpp:77] Creating layer BatchNorm40
I0927 10:14:39.354013  3315 net.cpp:84] Creating Layer BatchNorm40
I0927 10:14:39.354017  3315 net.cpp:406] BatchNorm40 <- Convolution40
I0927 10:14:39.354020  3315 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0927 10:14:39.354161  3315 net.cpp:122] Setting up BatchNorm40
I0927 10:14:39.354166  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.354168  3315 net.cpp:137] Memory required for data: 1031783600
I0927 10:14:39.354173  3315 layer_factory.hpp:77] Creating layer Scale40
I0927 10:14:39.354177  3315 net.cpp:84] Creating Layer Scale40
I0927 10:14:39.354180  3315 net.cpp:406] Scale40 <- Convolution40
I0927 10:14:39.354183  3315 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0927 10:14:39.354212  3315 layer_factory.hpp:77] Creating layer Scale40
I0927 10:14:39.354316  3315 net.cpp:122] Setting up Scale40
I0927 10:14:39.354322  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.354324  3315 net.cpp:137] Memory required for data: 1033422000
I0927 10:14:39.354329  3315 layer_factory.hpp:77] Creating layer penlu38
I0927 10:14:39.354334  3315 net.cpp:84] Creating Layer penlu38
I0927 10:14:39.354336  3315 net.cpp:406] penlu38 <- Convolution40
I0927 10:14:39.354341  3315 net.cpp:367] penlu38 -> Convolution40 (in-place)
I0927 10:14:39.354461  3315 net.cpp:122] Setting up penlu38
I0927 10:14:39.354466  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.354468  3315 net.cpp:137] Memory required for data: 1035060400
I0927 10:14:39.354472  3315 layer_factory.hpp:77] Creating layer Convolution41
I0927 10:14:39.354480  3315 net.cpp:84] Creating Layer Convolution41
I0927 10:14:39.354482  3315 net.cpp:406] Convolution41 <- Convolution40
I0927 10:14:39.354486  3315 net.cpp:380] Convolution41 -> Convolution41
I0927 10:14:39.356250  3315 net.cpp:122] Setting up Convolution41
I0927 10:14:39.356259  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.356261  3315 net.cpp:137] Memory required for data: 1036698800
I0927 10:14:39.356266  3315 layer_factory.hpp:77] Creating layer BatchNorm41
I0927 10:14:39.356271  3315 net.cpp:84] Creating Layer BatchNorm41
I0927 10:14:39.356274  3315 net.cpp:406] BatchNorm41 <- Convolution41
I0927 10:14:39.356286  3315 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0927 10:14:39.356422  3315 net.cpp:122] Setting up BatchNorm41
I0927 10:14:39.356427  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.356429  3315 net.cpp:137] Memory required for data: 1038337200
I0927 10:14:39.356434  3315 layer_factory.hpp:77] Creating layer Scale41
I0927 10:14:39.356438  3315 net.cpp:84] Creating Layer Scale41
I0927 10:14:39.356441  3315 net.cpp:406] Scale41 <- Convolution41
I0927 10:14:39.356444  3315 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0927 10:14:39.356473  3315 layer_factory.hpp:77] Creating layer Scale41
I0927 10:14:39.356552  3315 net.cpp:122] Setting up Scale41
I0927 10:14:39.356557  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.356559  3315 net.cpp:137] Memory required for data: 1039975600
I0927 10:14:39.356564  3315 layer_factory.hpp:77] Creating layer Eltwise19
I0927 10:14:39.356567  3315 net.cpp:84] Creating Layer Eltwise19
I0927 10:14:39.356570  3315 net.cpp:406] Eltwise19 <- Convolution39
I0927 10:14:39.356573  3315 net.cpp:406] Eltwise19 <- Convolution41
I0927 10:14:39.356576  3315 net.cpp:380] Eltwise19 -> Eltwise19
I0927 10:14:39.356593  3315 net.cpp:122] Setting up Eltwise19
I0927 10:14:39.356597  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.356600  3315 net.cpp:137] Memory required for data: 1041614000
I0927 10:14:39.356601  3315 layer_factory.hpp:77] Creating layer penlu39
I0927 10:14:39.356606  3315 net.cpp:84] Creating Layer penlu39
I0927 10:14:39.356609  3315 net.cpp:406] penlu39 <- Eltwise19
I0927 10:14:39.356612  3315 net.cpp:367] penlu39 -> Eltwise19 (in-place)
I0927 10:14:39.356729  3315 net.cpp:122] Setting up penlu39
I0927 10:14:39.356734  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.356735  3315 net.cpp:137] Memory required for data: 1043252400
I0927 10:14:39.356740  3315 layer_factory.hpp:77] Creating layer Eltwise19_penlu39_0_split
I0927 10:14:39.356745  3315 net.cpp:84] Creating Layer Eltwise19_penlu39_0_split
I0927 10:14:39.356746  3315 net.cpp:406] Eltwise19_penlu39_0_split <- Eltwise19
I0927 10:14:39.356750  3315 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_0
I0927 10:14:39.356755  3315 net.cpp:380] Eltwise19_penlu39_0_split -> Eltwise19_penlu39_0_split_1
I0927 10:14:39.356778  3315 net.cpp:122] Setting up Eltwise19_penlu39_0_split
I0927 10:14:39.356783  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.356786  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.356788  3315 net.cpp:137] Memory required for data: 1046529200
I0927 10:14:39.356791  3315 layer_factory.hpp:77] Creating layer Convolution42
I0927 10:14:39.356796  3315 net.cpp:84] Creating Layer Convolution42
I0927 10:14:39.356798  3315 net.cpp:406] Convolution42 <- Eltwise19_penlu39_0_split_0
I0927 10:14:39.356802  3315 net.cpp:380] Convolution42 -> Convolution42
I0927 10:14:39.358542  3315 net.cpp:122] Setting up Convolution42
I0927 10:14:39.358551  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.358554  3315 net.cpp:137] Memory required for data: 1048167600
I0927 10:14:39.358568  3315 layer_factory.hpp:77] Creating layer BatchNorm42
I0927 10:14:39.358574  3315 net.cpp:84] Creating Layer BatchNorm42
I0927 10:14:39.358577  3315 net.cpp:406] BatchNorm42 <- Convolution42
I0927 10:14:39.358580  3315 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0927 10:14:39.358718  3315 net.cpp:122] Setting up BatchNorm42
I0927 10:14:39.358722  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.358726  3315 net.cpp:137] Memory required for data: 1049806000
I0927 10:14:39.358729  3315 layer_factory.hpp:77] Creating layer Scale42
I0927 10:14:39.358734  3315 net.cpp:84] Creating Layer Scale42
I0927 10:14:39.358736  3315 net.cpp:406] Scale42 <- Convolution42
I0927 10:14:39.358741  3315 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0927 10:14:39.358767  3315 layer_factory.hpp:77] Creating layer Scale42
I0927 10:14:39.358847  3315 net.cpp:122] Setting up Scale42
I0927 10:14:39.358858  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.358860  3315 net.cpp:137] Memory required for data: 1051444400
I0927 10:14:39.358865  3315 layer_factory.hpp:77] Creating layer penlu40
I0927 10:14:39.358870  3315 net.cpp:84] Creating Layer penlu40
I0927 10:14:39.358872  3315 net.cpp:406] penlu40 <- Convolution42
I0927 10:14:39.358876  3315 net.cpp:367] penlu40 -> Convolution42 (in-place)
I0927 10:14:39.358994  3315 net.cpp:122] Setting up penlu40
I0927 10:14:39.358997  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.358999  3315 net.cpp:137] Memory required for data: 1053082800
I0927 10:14:39.359004  3315 layer_factory.hpp:77] Creating layer Convolution43
I0927 10:14:39.359011  3315 net.cpp:84] Creating Layer Convolution43
I0927 10:14:39.359014  3315 net.cpp:406] Convolution43 <- Convolution42
I0927 10:14:39.359019  3315 net.cpp:380] Convolution43 -> Convolution43
I0927 10:14:39.360779  3315 net.cpp:122] Setting up Convolution43
I0927 10:14:39.360787  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.360790  3315 net.cpp:137] Memory required for data: 1054721200
I0927 10:14:39.360795  3315 layer_factory.hpp:77] Creating layer BatchNorm43
I0927 10:14:39.360800  3315 net.cpp:84] Creating Layer BatchNorm43
I0927 10:14:39.360802  3315 net.cpp:406] BatchNorm43 <- Convolution43
I0927 10:14:39.360807  3315 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0927 10:14:39.360944  3315 net.cpp:122] Setting up BatchNorm43
I0927 10:14:39.360949  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.360951  3315 net.cpp:137] Memory required for data: 1056359600
I0927 10:14:39.360956  3315 layer_factory.hpp:77] Creating layer Scale43
I0927 10:14:39.360961  3315 net.cpp:84] Creating Layer Scale43
I0927 10:14:39.360963  3315 net.cpp:406] Scale43 <- Convolution43
I0927 10:14:39.360967  3315 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0927 10:14:39.360994  3315 layer_factory.hpp:77] Creating layer Scale43
I0927 10:14:39.361074  3315 net.cpp:122] Setting up Scale43
I0927 10:14:39.361079  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.361081  3315 net.cpp:137] Memory required for data: 1057998000
I0927 10:14:39.361084  3315 layer_factory.hpp:77] Creating layer Eltwise20
I0927 10:14:39.361090  3315 net.cpp:84] Creating Layer Eltwise20
I0927 10:14:39.361093  3315 net.cpp:406] Eltwise20 <- Eltwise19_penlu39_0_split_1
I0927 10:14:39.361096  3315 net.cpp:406] Eltwise20 <- Convolution43
I0927 10:14:39.361100  3315 net.cpp:380] Eltwise20 -> Eltwise20
I0927 10:14:39.361116  3315 net.cpp:122] Setting up Eltwise20
I0927 10:14:39.361120  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.361122  3315 net.cpp:137] Memory required for data: 1059636400
I0927 10:14:39.361124  3315 layer_factory.hpp:77] Creating layer penlu41
I0927 10:14:39.361129  3315 net.cpp:84] Creating Layer penlu41
I0927 10:14:39.361132  3315 net.cpp:406] penlu41 <- Eltwise20
I0927 10:14:39.361135  3315 net.cpp:367] penlu41 -> Eltwise20 (in-place)
I0927 10:14:39.361250  3315 net.cpp:122] Setting up penlu41
I0927 10:14:39.361255  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.361258  3315 net.cpp:137] Memory required for data: 1061274800
I0927 10:14:39.361261  3315 layer_factory.hpp:77] Creating layer Eltwise20_penlu41_0_split
I0927 10:14:39.361265  3315 net.cpp:84] Creating Layer Eltwise20_penlu41_0_split
I0927 10:14:39.361268  3315 net.cpp:406] Eltwise20_penlu41_0_split <- Eltwise20
I0927 10:14:39.361271  3315 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_0
I0927 10:14:39.361276  3315 net.cpp:380] Eltwise20_penlu41_0_split -> Eltwise20_penlu41_0_split_1
I0927 10:14:39.361299  3315 net.cpp:122] Setting up Eltwise20_penlu41_0_split
I0927 10:14:39.361304  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.361306  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.361308  3315 net.cpp:137] Memory required for data: 1064551600
I0927 10:14:39.361310  3315 layer_factory.hpp:77] Creating layer Convolution44
I0927 10:14:39.361323  3315 net.cpp:84] Creating Layer Convolution44
I0927 10:14:39.361326  3315 net.cpp:406] Convolution44 <- Eltwise20_penlu41_0_split_0
I0927 10:14:39.361330  3315 net.cpp:380] Convolution44 -> Convolution44
I0927 10:14:39.363405  3315 net.cpp:122] Setting up Convolution44
I0927 10:14:39.363415  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.363416  3315 net.cpp:137] Memory required for data: 1066190000
I0927 10:14:39.363430  3315 layer_factory.hpp:77] Creating layer BatchNorm44
I0927 10:14:39.363435  3315 net.cpp:84] Creating Layer BatchNorm44
I0927 10:14:39.363437  3315 net.cpp:406] BatchNorm44 <- Convolution44
I0927 10:14:39.363441  3315 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0927 10:14:39.363590  3315 net.cpp:122] Setting up BatchNorm44
I0927 10:14:39.363595  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.363597  3315 net.cpp:137] Memory required for data: 1067828400
I0927 10:14:39.363602  3315 layer_factory.hpp:77] Creating layer Scale44
I0927 10:14:39.363606  3315 net.cpp:84] Creating Layer Scale44
I0927 10:14:39.363608  3315 net.cpp:406] Scale44 <- Convolution44
I0927 10:14:39.363613  3315 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0927 10:14:39.363641  3315 layer_factory.hpp:77] Creating layer Scale44
I0927 10:14:39.363723  3315 net.cpp:122] Setting up Scale44
I0927 10:14:39.363729  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.363730  3315 net.cpp:137] Memory required for data: 1069466800
I0927 10:14:39.363734  3315 layer_factory.hpp:77] Creating layer penlu42
I0927 10:14:39.363740  3315 net.cpp:84] Creating Layer penlu42
I0927 10:14:39.363742  3315 net.cpp:406] penlu42 <- Convolution44
I0927 10:14:39.363747  3315 net.cpp:367] penlu42 -> Convolution44 (in-place)
I0927 10:14:39.363864  3315 net.cpp:122] Setting up penlu42
I0927 10:14:39.363870  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.363873  3315 net.cpp:137] Memory required for data: 1071105200
I0927 10:14:39.363876  3315 layer_factory.hpp:77] Creating layer Convolution45
I0927 10:14:39.363883  3315 net.cpp:84] Creating Layer Convolution45
I0927 10:14:39.363885  3315 net.cpp:406] Convolution45 <- Convolution44
I0927 10:14:39.363890  3315 net.cpp:380] Convolution45 -> Convolution45
I0927 10:14:39.365653  3315 net.cpp:122] Setting up Convolution45
I0927 10:14:39.365662  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.365664  3315 net.cpp:137] Memory required for data: 1072743600
I0927 10:14:39.365669  3315 layer_factory.hpp:77] Creating layer BatchNorm45
I0927 10:14:39.365674  3315 net.cpp:84] Creating Layer BatchNorm45
I0927 10:14:39.365677  3315 net.cpp:406] BatchNorm45 <- Convolution45
I0927 10:14:39.365681  3315 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0927 10:14:39.365820  3315 net.cpp:122] Setting up BatchNorm45
I0927 10:14:39.365825  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.365828  3315 net.cpp:137] Memory required for data: 1074382000
I0927 10:14:39.365833  3315 layer_factory.hpp:77] Creating layer Scale45
I0927 10:14:39.365836  3315 net.cpp:84] Creating Layer Scale45
I0927 10:14:39.365839  3315 net.cpp:406] Scale45 <- Convolution45
I0927 10:14:39.365841  3315 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0927 10:14:39.365870  3315 layer_factory.hpp:77] Creating layer Scale45
I0927 10:14:39.365949  3315 net.cpp:122] Setting up Scale45
I0927 10:14:39.365954  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.365957  3315 net.cpp:137] Memory required for data: 1076020400
I0927 10:14:39.365960  3315 layer_factory.hpp:77] Creating layer Eltwise21
I0927 10:14:39.365964  3315 net.cpp:84] Creating Layer Eltwise21
I0927 10:14:39.365967  3315 net.cpp:406] Eltwise21 <- Eltwise20_penlu41_0_split_1
I0927 10:14:39.365969  3315 net.cpp:406] Eltwise21 <- Convolution45
I0927 10:14:39.365973  3315 net.cpp:380] Eltwise21 -> Eltwise21
I0927 10:14:39.365990  3315 net.cpp:122] Setting up Eltwise21
I0927 10:14:39.365994  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.365996  3315 net.cpp:137] Memory required for data: 1077658800
I0927 10:14:39.366004  3315 layer_factory.hpp:77] Creating layer penlu43
I0927 10:14:39.366010  3315 net.cpp:84] Creating Layer penlu43
I0927 10:14:39.366014  3315 net.cpp:406] penlu43 <- Eltwise21
I0927 10:14:39.366017  3315 net.cpp:367] penlu43 -> Eltwise21 (in-place)
I0927 10:14:39.366135  3315 net.cpp:122] Setting up penlu43
I0927 10:14:39.366140  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.366142  3315 net.cpp:137] Memory required for data: 1079297200
I0927 10:14:39.366147  3315 layer_factory.hpp:77] Creating layer Eltwise21_penlu43_0_split
I0927 10:14:39.366152  3315 net.cpp:84] Creating Layer Eltwise21_penlu43_0_split
I0927 10:14:39.366153  3315 net.cpp:406] Eltwise21_penlu43_0_split <- Eltwise21
I0927 10:14:39.366158  3315 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_0
I0927 10:14:39.366161  3315 net.cpp:380] Eltwise21_penlu43_0_split -> Eltwise21_penlu43_0_split_1
I0927 10:14:39.366186  3315 net.cpp:122] Setting up Eltwise21_penlu43_0_split
I0927 10:14:39.366189  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.366192  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.381393  3315 net.cpp:137] Memory required for data: 1082574000
I0927 10:14:39.381400  3315 layer_factory.hpp:77] Creating layer Convolution46
I0927 10:14:39.381408  3315 net.cpp:84] Creating Layer Convolution46
I0927 10:14:39.381412  3315 net.cpp:406] Convolution46 <- Eltwise21_penlu43_0_split_0
I0927 10:14:39.381419  3315 net.cpp:380] Convolution46 -> Convolution46
I0927 10:14:39.383359  3315 net.cpp:122] Setting up Convolution46
I0927 10:14:39.383368  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.383371  3315 net.cpp:137] Memory required for data: 1084212400
I0927 10:14:39.383378  3315 layer_factory.hpp:77] Creating layer BatchNorm46
I0927 10:14:39.383383  3315 net.cpp:84] Creating Layer BatchNorm46
I0927 10:14:39.383385  3315 net.cpp:406] BatchNorm46 <- Convolution46
I0927 10:14:39.383389  3315 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0927 10:14:39.383535  3315 net.cpp:122] Setting up BatchNorm46
I0927 10:14:39.383540  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.383543  3315 net.cpp:137] Memory required for data: 1085850800
I0927 10:14:39.383548  3315 layer_factory.hpp:77] Creating layer Scale46
I0927 10:14:39.383551  3315 net.cpp:84] Creating Layer Scale46
I0927 10:14:39.383554  3315 net.cpp:406] Scale46 <- Convolution46
I0927 10:14:39.383558  3315 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0927 10:14:39.383585  3315 layer_factory.hpp:77] Creating layer Scale46
I0927 10:14:39.383697  3315 net.cpp:122] Setting up Scale46
I0927 10:14:39.383713  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.383714  3315 net.cpp:137] Memory required for data: 1087489200
I0927 10:14:39.383718  3315 layer_factory.hpp:77] Creating layer penlu44
I0927 10:14:39.383723  3315 net.cpp:84] Creating Layer penlu44
I0927 10:14:39.383725  3315 net.cpp:406] penlu44 <- Convolution46
I0927 10:14:39.383729  3315 net.cpp:367] penlu44 -> Convolution46 (in-place)
I0927 10:14:39.383849  3315 net.cpp:122] Setting up penlu44
I0927 10:14:39.383853  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.383855  3315 net.cpp:137] Memory required for data: 1089127600
I0927 10:14:39.383860  3315 layer_factory.hpp:77] Creating layer Convolution47
I0927 10:14:39.383867  3315 net.cpp:84] Creating Layer Convolution47
I0927 10:14:39.383869  3315 net.cpp:406] Convolution47 <- Convolution46
I0927 10:14:39.383874  3315 net.cpp:380] Convolution47 -> Convolution47
I0927 10:14:39.385668  3315 net.cpp:122] Setting up Convolution47
I0927 10:14:39.385677  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.385679  3315 net.cpp:137] Memory required for data: 1090766000
I0927 10:14:39.385684  3315 layer_factory.hpp:77] Creating layer BatchNorm47
I0927 10:14:39.385689  3315 net.cpp:84] Creating Layer BatchNorm47
I0927 10:14:39.385692  3315 net.cpp:406] BatchNorm47 <- Convolution47
I0927 10:14:39.385696  3315 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0927 10:14:39.385846  3315 net.cpp:122] Setting up BatchNorm47
I0927 10:14:39.385851  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.385854  3315 net.cpp:137] Memory required for data: 1092404400
I0927 10:14:39.385859  3315 layer_factory.hpp:77] Creating layer Scale47
I0927 10:14:39.385862  3315 net.cpp:84] Creating Layer Scale47
I0927 10:14:39.385865  3315 net.cpp:406] Scale47 <- Convolution47
I0927 10:14:39.385869  3315 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0927 10:14:39.385897  3315 layer_factory.hpp:77] Creating layer Scale47
I0927 10:14:39.385977  3315 net.cpp:122] Setting up Scale47
I0927 10:14:39.385982  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.385984  3315 net.cpp:137] Memory required for data: 1094042800
I0927 10:14:39.385988  3315 layer_factory.hpp:77] Creating layer Eltwise22
I0927 10:14:39.385993  3315 net.cpp:84] Creating Layer Eltwise22
I0927 10:14:39.385995  3315 net.cpp:406] Eltwise22 <- Eltwise21_penlu43_0_split_1
I0927 10:14:39.385998  3315 net.cpp:406] Eltwise22 <- Convolution47
I0927 10:14:39.386001  3315 net.cpp:380] Eltwise22 -> Eltwise22
I0927 10:14:39.386019  3315 net.cpp:122] Setting up Eltwise22
I0927 10:14:39.386023  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.386025  3315 net.cpp:137] Memory required for data: 1095681200
I0927 10:14:39.386027  3315 layer_factory.hpp:77] Creating layer penlu45
I0927 10:14:39.386032  3315 net.cpp:84] Creating Layer penlu45
I0927 10:14:39.386035  3315 net.cpp:406] penlu45 <- Eltwise22
I0927 10:14:39.386039  3315 net.cpp:367] penlu45 -> Eltwise22 (in-place)
I0927 10:14:39.386157  3315 net.cpp:122] Setting up penlu45
I0927 10:14:39.386162  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.386163  3315 net.cpp:137] Memory required for data: 1097319600
I0927 10:14:39.386168  3315 layer_factory.hpp:77] Creating layer Eltwise22_penlu45_0_split
I0927 10:14:39.386173  3315 net.cpp:84] Creating Layer Eltwise22_penlu45_0_split
I0927 10:14:39.386175  3315 net.cpp:406] Eltwise22_penlu45_0_split <- Eltwise22
I0927 10:14:39.386178  3315 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_0
I0927 10:14:39.386183  3315 net.cpp:380] Eltwise22_penlu45_0_split -> Eltwise22_penlu45_0_split_1
I0927 10:14:39.386207  3315 net.cpp:122] Setting up Eltwise22_penlu45_0_split
I0927 10:14:39.386211  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.386214  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.386216  3315 net.cpp:137] Memory required for data: 1100596400
I0927 10:14:39.386219  3315 layer_factory.hpp:77] Creating layer Convolution48
I0927 10:14:39.386224  3315 net.cpp:84] Creating Layer Convolution48
I0927 10:14:39.386226  3315 net.cpp:406] Convolution48 <- Eltwise22_penlu45_0_split_0
I0927 10:14:39.386231  3315 net.cpp:380] Convolution48 -> Convolution48
I0927 10:14:39.388319  3315 net.cpp:122] Setting up Convolution48
I0927 10:14:39.388329  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.388330  3315 net.cpp:137] Memory required for data: 1102234800
I0927 10:14:39.388335  3315 layer_factory.hpp:77] Creating layer BatchNorm48
I0927 10:14:39.388340  3315 net.cpp:84] Creating Layer BatchNorm48
I0927 10:14:39.388344  3315 net.cpp:406] BatchNorm48 <- Convolution48
I0927 10:14:39.388348  3315 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0927 10:14:39.388495  3315 net.cpp:122] Setting up BatchNorm48
I0927 10:14:39.388499  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.388501  3315 net.cpp:137] Memory required for data: 1103873200
I0927 10:14:39.388506  3315 layer_factory.hpp:77] Creating layer Scale48
I0927 10:14:39.388510  3315 net.cpp:84] Creating Layer Scale48
I0927 10:14:39.388512  3315 net.cpp:406] Scale48 <- Convolution48
I0927 10:14:39.388516  3315 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0927 10:14:39.388545  3315 layer_factory.hpp:77] Creating layer Scale48
I0927 10:14:39.388629  3315 net.cpp:122] Setting up Scale48
I0927 10:14:39.388633  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.388643  3315 net.cpp:137] Memory required for data: 1105511600
I0927 10:14:39.388646  3315 layer_factory.hpp:77] Creating layer penlu46
I0927 10:14:39.388653  3315 net.cpp:84] Creating Layer penlu46
I0927 10:14:39.388655  3315 net.cpp:406] penlu46 <- Convolution48
I0927 10:14:39.388659  3315 net.cpp:367] penlu46 -> Convolution48 (in-place)
I0927 10:14:39.388779  3315 net.cpp:122] Setting up penlu46
I0927 10:14:39.388783  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.388785  3315 net.cpp:137] Memory required for data: 1107150000
I0927 10:14:39.388790  3315 layer_factory.hpp:77] Creating layer Convolution49
I0927 10:14:39.388797  3315 net.cpp:84] Creating Layer Convolution49
I0927 10:14:39.388799  3315 net.cpp:406] Convolution49 <- Convolution48
I0927 10:14:39.388803  3315 net.cpp:380] Convolution49 -> Convolution49
I0927 10:14:39.390890  3315 net.cpp:122] Setting up Convolution49
I0927 10:14:39.390899  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.390902  3315 net.cpp:137] Memory required for data: 1108788400
I0927 10:14:39.390907  3315 layer_factory.hpp:77] Creating layer BatchNorm49
I0927 10:14:39.390913  3315 net.cpp:84] Creating Layer BatchNorm49
I0927 10:14:39.390915  3315 net.cpp:406] BatchNorm49 <- Convolution49
I0927 10:14:39.390919  3315 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0927 10:14:39.391062  3315 net.cpp:122] Setting up BatchNorm49
I0927 10:14:39.391067  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.391069  3315 net.cpp:137] Memory required for data: 1110426800
I0927 10:14:39.391074  3315 layer_factory.hpp:77] Creating layer Scale49
I0927 10:14:39.391078  3315 net.cpp:84] Creating Layer Scale49
I0927 10:14:39.391080  3315 net.cpp:406] Scale49 <- Convolution49
I0927 10:14:39.391083  3315 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0927 10:14:39.391113  3315 layer_factory.hpp:77] Creating layer Scale49
I0927 10:14:39.391196  3315 net.cpp:122] Setting up Scale49
I0927 10:14:39.391199  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.391201  3315 net.cpp:137] Memory required for data: 1112065200
I0927 10:14:39.391206  3315 layer_factory.hpp:77] Creating layer Eltwise23
I0927 10:14:39.391211  3315 net.cpp:84] Creating Layer Eltwise23
I0927 10:14:39.391213  3315 net.cpp:406] Eltwise23 <- Eltwise22_penlu45_0_split_1
I0927 10:14:39.391216  3315 net.cpp:406] Eltwise23 <- Convolution49
I0927 10:14:39.391219  3315 net.cpp:380] Eltwise23 -> Eltwise23
I0927 10:14:39.391235  3315 net.cpp:122] Setting up Eltwise23
I0927 10:14:39.391239  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.391242  3315 net.cpp:137] Memory required for data: 1113703600
I0927 10:14:39.391243  3315 layer_factory.hpp:77] Creating layer penlu47
I0927 10:14:39.391249  3315 net.cpp:84] Creating Layer penlu47
I0927 10:14:39.391252  3315 net.cpp:406] penlu47 <- Eltwise23
I0927 10:14:39.391255  3315 net.cpp:367] penlu47 -> Eltwise23 (in-place)
I0927 10:14:39.391374  3315 net.cpp:122] Setting up penlu47
I0927 10:14:39.391379  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.391381  3315 net.cpp:137] Memory required for data: 1115342000
I0927 10:14:39.391386  3315 layer_factory.hpp:77] Creating layer Eltwise23_penlu47_0_split
I0927 10:14:39.391389  3315 net.cpp:84] Creating Layer Eltwise23_penlu47_0_split
I0927 10:14:39.391391  3315 net.cpp:406] Eltwise23_penlu47_0_split <- Eltwise23
I0927 10:14:39.391396  3315 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_0
I0927 10:14:39.391400  3315 net.cpp:380] Eltwise23_penlu47_0_split -> Eltwise23_penlu47_0_split_1
I0927 10:14:39.391425  3315 net.cpp:122] Setting up Eltwise23_penlu47_0_split
I0927 10:14:39.391428  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.391432  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.391433  3315 net.cpp:137] Memory required for data: 1118618800
I0927 10:14:39.391435  3315 layer_factory.hpp:77] Creating layer Convolution50
I0927 10:14:39.391443  3315 net.cpp:84] Creating Layer Convolution50
I0927 10:14:39.391451  3315 net.cpp:406] Convolution50 <- Eltwise23_penlu47_0_split_0
I0927 10:14:39.391456  3315 net.cpp:380] Convolution50 -> Convolution50
I0927 10:14:39.394032  3315 net.cpp:122] Setting up Convolution50
I0927 10:14:39.394039  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.394042  3315 net.cpp:137] Memory required for data: 1120257200
I0927 10:14:39.394047  3315 layer_factory.hpp:77] Creating layer BatchNorm50
I0927 10:14:39.394052  3315 net.cpp:84] Creating Layer BatchNorm50
I0927 10:14:39.394055  3315 net.cpp:406] BatchNorm50 <- Convolution50
I0927 10:14:39.394058  3315 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0927 10:14:39.394207  3315 net.cpp:122] Setting up BatchNorm50
I0927 10:14:39.394210  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.394213  3315 net.cpp:137] Memory required for data: 1121895600
I0927 10:14:39.394217  3315 layer_factory.hpp:77] Creating layer Scale50
I0927 10:14:39.394222  3315 net.cpp:84] Creating Layer Scale50
I0927 10:14:39.394224  3315 net.cpp:406] Scale50 <- Convolution50
I0927 10:14:39.394227  3315 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0927 10:14:39.394258  3315 layer_factory.hpp:77] Creating layer Scale50
I0927 10:14:39.394340  3315 net.cpp:122] Setting up Scale50
I0927 10:14:39.394345  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.394346  3315 net.cpp:137] Memory required for data: 1123534000
I0927 10:14:39.394351  3315 layer_factory.hpp:77] Creating layer penlu48
I0927 10:14:39.394356  3315 net.cpp:84] Creating Layer penlu48
I0927 10:14:39.394358  3315 net.cpp:406] penlu48 <- Convolution50
I0927 10:14:39.394362  3315 net.cpp:367] penlu48 -> Convolution50 (in-place)
I0927 10:14:39.394481  3315 net.cpp:122] Setting up penlu48
I0927 10:14:39.394486  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.394489  3315 net.cpp:137] Memory required for data: 1125172400
I0927 10:14:39.394492  3315 layer_factory.hpp:77] Creating layer Convolution51
I0927 10:14:39.394500  3315 net.cpp:84] Creating Layer Convolution51
I0927 10:14:39.394502  3315 net.cpp:406] Convolution51 <- Convolution50
I0927 10:14:39.394506  3315 net.cpp:380] Convolution51 -> Convolution51
I0927 10:14:39.396266  3315 net.cpp:122] Setting up Convolution51
I0927 10:14:39.396275  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.396278  3315 net.cpp:137] Memory required for data: 1126810800
I0927 10:14:39.396283  3315 layer_factory.hpp:77] Creating layer BatchNorm51
I0927 10:14:39.396288  3315 net.cpp:84] Creating Layer BatchNorm51
I0927 10:14:39.396291  3315 net.cpp:406] BatchNorm51 <- Convolution51
I0927 10:14:39.396294  3315 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0927 10:14:39.396437  3315 net.cpp:122] Setting up BatchNorm51
I0927 10:14:39.396441  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.396443  3315 net.cpp:137] Memory required for data: 1128449200
I0927 10:14:39.396448  3315 layer_factory.hpp:77] Creating layer Scale51
I0927 10:14:39.396452  3315 net.cpp:84] Creating Layer Scale51
I0927 10:14:39.396456  3315 net.cpp:406] Scale51 <- Convolution51
I0927 10:14:39.396458  3315 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0927 10:14:39.396488  3315 layer_factory.hpp:77] Creating layer Scale51
I0927 10:14:39.396569  3315 net.cpp:122] Setting up Scale51
I0927 10:14:39.396572  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.396574  3315 net.cpp:137] Memory required for data: 1130087600
I0927 10:14:39.396579  3315 layer_factory.hpp:77] Creating layer Eltwise24
I0927 10:14:39.396582  3315 net.cpp:84] Creating Layer Eltwise24
I0927 10:14:39.396586  3315 net.cpp:406] Eltwise24 <- Eltwise23_penlu47_0_split_1
I0927 10:14:39.396589  3315 net.cpp:406] Eltwise24 <- Convolution51
I0927 10:14:39.396592  3315 net.cpp:380] Eltwise24 -> Eltwise24
I0927 10:14:39.396610  3315 net.cpp:122] Setting up Eltwise24
I0927 10:14:39.396612  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.396615  3315 net.cpp:137] Memory required for data: 1131726000
I0927 10:14:39.396623  3315 layer_factory.hpp:77] Creating layer penlu49
I0927 10:14:39.396630  3315 net.cpp:84] Creating Layer penlu49
I0927 10:14:39.396632  3315 net.cpp:406] penlu49 <- Eltwise24
I0927 10:14:39.396636  3315 net.cpp:367] penlu49 -> Eltwise24 (in-place)
I0927 10:14:39.396754  3315 net.cpp:122] Setting up penlu49
I0927 10:14:39.396759  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.396760  3315 net.cpp:137] Memory required for data: 1133364400
I0927 10:14:39.396765  3315 layer_factory.hpp:77] Creating layer Eltwise24_penlu49_0_split
I0927 10:14:39.396770  3315 net.cpp:84] Creating Layer Eltwise24_penlu49_0_split
I0927 10:14:39.396771  3315 net.cpp:406] Eltwise24_penlu49_0_split <- Eltwise24
I0927 10:14:39.396775  3315 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_0
I0927 10:14:39.396780  3315 net.cpp:380] Eltwise24_penlu49_0_split -> Eltwise24_penlu49_0_split_1
I0927 10:14:39.396816  3315 net.cpp:122] Setting up Eltwise24_penlu49_0_split
I0927 10:14:39.412001  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.412009  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.412012  3315 net.cpp:137] Memory required for data: 1136641200
I0927 10:14:39.412015  3315 layer_factory.hpp:77] Creating layer Convolution52
I0927 10:14:39.412025  3315 net.cpp:84] Creating Layer Convolution52
I0927 10:14:39.412029  3315 net.cpp:406] Convolution52 <- Eltwise24_penlu49_0_split_0
I0927 10:14:39.412034  3315 net.cpp:380] Convolution52 -> Convolution52
I0927 10:14:39.414355  3315 net.cpp:122] Setting up Convolution52
I0927 10:14:39.414363  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.414366  3315 net.cpp:137] Memory required for data: 1138279600
I0927 10:14:39.414371  3315 layer_factory.hpp:77] Creating layer BatchNorm52
I0927 10:14:39.414376  3315 net.cpp:84] Creating Layer BatchNorm52
I0927 10:14:39.414378  3315 net.cpp:406] BatchNorm52 <- Convolution52
I0927 10:14:39.414383  3315 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0927 10:14:39.414593  3315 net.cpp:122] Setting up BatchNorm52
I0927 10:14:39.414599  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.414611  3315 net.cpp:137] Memory required for data: 1139918000
I0927 10:14:39.414616  3315 layer_factory.hpp:77] Creating layer Scale52
I0927 10:14:39.414621  3315 net.cpp:84] Creating Layer Scale52
I0927 10:14:39.414635  3315 net.cpp:406] Scale52 <- Convolution52
I0927 10:14:39.414639  3315 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0927 10:14:39.414680  3315 layer_factory.hpp:77] Creating layer Scale52
I0927 10:14:39.414762  3315 net.cpp:122] Setting up Scale52
I0927 10:14:39.414765  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.414767  3315 net.cpp:137] Memory required for data: 1141556400
I0927 10:14:39.414780  3315 layer_factory.hpp:77] Creating layer penlu50
I0927 10:14:39.414801  3315 net.cpp:84] Creating Layer penlu50
I0927 10:14:39.414804  3315 net.cpp:406] penlu50 <- Convolution52
I0927 10:14:39.414808  3315 net.cpp:367] penlu50 -> Convolution52 (in-place)
I0927 10:14:39.414927  3315 net.cpp:122] Setting up penlu50
I0927 10:14:39.414932  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.414934  3315 net.cpp:137] Memory required for data: 1143194800
I0927 10:14:39.414975  3315 layer_factory.hpp:77] Creating layer Convolution53
I0927 10:14:39.414983  3315 net.cpp:84] Creating Layer Convolution53
I0927 10:14:39.414985  3315 net.cpp:406] Convolution53 <- Convolution52
I0927 10:14:39.414989  3315 net.cpp:380] Convolution53 -> Convolution53
I0927 10:14:39.416787  3315 net.cpp:122] Setting up Convolution53
I0927 10:14:39.416796  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.416798  3315 net.cpp:137] Memory required for data: 1144833200
I0927 10:14:39.416803  3315 layer_factory.hpp:77] Creating layer BatchNorm53
I0927 10:14:39.416810  3315 net.cpp:84] Creating Layer BatchNorm53
I0927 10:14:39.416812  3315 net.cpp:406] BatchNorm53 <- Convolution53
I0927 10:14:39.416817  3315 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0927 10:14:39.416965  3315 net.cpp:122] Setting up BatchNorm53
I0927 10:14:39.416970  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.416971  3315 net.cpp:137] Memory required for data: 1146471600
I0927 10:14:39.416976  3315 layer_factory.hpp:77] Creating layer Scale53
I0927 10:14:39.416981  3315 net.cpp:84] Creating Layer Scale53
I0927 10:14:39.416985  3315 net.cpp:406] Scale53 <- Convolution53
I0927 10:14:39.416987  3315 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0927 10:14:39.417016  3315 layer_factory.hpp:77] Creating layer Scale53
I0927 10:14:39.417098  3315 net.cpp:122] Setting up Scale53
I0927 10:14:39.417101  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.417104  3315 net.cpp:137] Memory required for data: 1148110000
I0927 10:14:39.417107  3315 layer_factory.hpp:77] Creating layer Eltwise25
I0927 10:14:39.417112  3315 net.cpp:84] Creating Layer Eltwise25
I0927 10:14:39.417115  3315 net.cpp:406] Eltwise25 <- Eltwise24_penlu49_0_split_1
I0927 10:14:39.417119  3315 net.cpp:406] Eltwise25 <- Convolution53
I0927 10:14:39.417121  3315 net.cpp:380] Eltwise25 -> Eltwise25
I0927 10:14:39.417138  3315 net.cpp:122] Setting up Eltwise25
I0927 10:14:39.417142  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.417145  3315 net.cpp:137] Memory required for data: 1149748400
I0927 10:14:39.417146  3315 layer_factory.hpp:77] Creating layer penlu51
I0927 10:14:39.417151  3315 net.cpp:84] Creating Layer penlu51
I0927 10:14:39.417155  3315 net.cpp:406] penlu51 <- Eltwise25
I0927 10:14:39.417157  3315 net.cpp:367] penlu51 -> Eltwise25 (in-place)
I0927 10:14:39.417273  3315 net.cpp:122] Setting up penlu51
I0927 10:14:39.417277  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.417279  3315 net.cpp:137] Memory required for data: 1151386800
I0927 10:14:39.417284  3315 layer_factory.hpp:77] Creating layer Eltwise25_penlu51_0_split
I0927 10:14:39.417287  3315 net.cpp:84] Creating Layer Eltwise25_penlu51_0_split
I0927 10:14:39.417289  3315 net.cpp:406] Eltwise25_penlu51_0_split <- Eltwise25
I0927 10:14:39.417292  3315 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_0
I0927 10:14:39.417296  3315 net.cpp:380] Eltwise25_penlu51_0_split -> Eltwise25_penlu51_0_split_1
I0927 10:14:39.417321  3315 net.cpp:122] Setting up Eltwise25_penlu51_0_split
I0927 10:14:39.417325  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.417327  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.417330  3315 net.cpp:137] Memory required for data: 1154663600
I0927 10:14:39.417331  3315 layer_factory.hpp:77] Creating layer Convolution54
I0927 10:14:39.417337  3315 net.cpp:84] Creating Layer Convolution54
I0927 10:14:39.417340  3315 net.cpp:406] Convolution54 <- Eltwise25_penlu51_0_split_0
I0927 10:14:39.417345  3315 net.cpp:380] Convolution54 -> Convolution54
I0927 10:14:39.419390  3315 net.cpp:122] Setting up Convolution54
I0927 10:14:39.419399  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.419402  3315 net.cpp:137] Memory required for data: 1156302000
I0927 10:14:39.419407  3315 layer_factory.hpp:77] Creating layer BatchNorm54
I0927 10:14:39.419411  3315 net.cpp:84] Creating Layer BatchNorm54
I0927 10:14:39.419414  3315 net.cpp:406] BatchNorm54 <- Convolution54
I0927 10:14:39.419420  3315 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0927 10:14:39.419579  3315 net.cpp:122] Setting up BatchNorm54
I0927 10:14:39.419582  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.419584  3315 net.cpp:137] Memory required for data: 1157940400
I0927 10:14:39.419589  3315 layer_factory.hpp:77] Creating layer Scale54
I0927 10:14:39.419594  3315 net.cpp:84] Creating Layer Scale54
I0927 10:14:39.419596  3315 net.cpp:406] Scale54 <- Convolution54
I0927 10:14:39.419600  3315 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0927 10:14:39.419627  3315 layer_factory.hpp:77] Creating layer Scale54
I0927 10:14:39.419708  3315 net.cpp:122] Setting up Scale54
I0927 10:14:39.419713  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.419720  3315 net.cpp:137] Memory required for data: 1159578800
I0927 10:14:39.419725  3315 layer_factory.hpp:77] Creating layer penlu52
I0927 10:14:39.419729  3315 net.cpp:84] Creating Layer penlu52
I0927 10:14:39.419733  3315 net.cpp:406] penlu52 <- Convolution54
I0927 10:14:39.419736  3315 net.cpp:367] penlu52 -> Convolution54 (in-place)
I0927 10:14:39.419857  3315 net.cpp:122] Setting up penlu52
I0927 10:14:39.419862  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.419863  3315 net.cpp:137] Memory required for data: 1161217200
I0927 10:14:39.419867  3315 layer_factory.hpp:77] Creating layer Convolution55
I0927 10:14:39.419874  3315 net.cpp:84] Creating Layer Convolution55
I0927 10:14:39.419878  3315 net.cpp:406] Convolution55 <- Convolution54
I0927 10:14:39.419881  3315 net.cpp:380] Convolution55 -> Convolution55
I0927 10:14:39.421578  3315 net.cpp:122] Setting up Convolution55
I0927 10:14:39.421587  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.421591  3315 net.cpp:137] Memory required for data: 1162855600
I0927 10:14:39.421594  3315 layer_factory.hpp:77] Creating layer BatchNorm55
I0927 10:14:39.421599  3315 net.cpp:84] Creating Layer BatchNorm55
I0927 10:14:39.421602  3315 net.cpp:406] BatchNorm55 <- Convolution55
I0927 10:14:39.421607  3315 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0927 10:14:39.421746  3315 net.cpp:122] Setting up BatchNorm55
I0927 10:14:39.421751  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.421752  3315 net.cpp:137] Memory required for data: 1164494000
I0927 10:14:39.421757  3315 layer_factory.hpp:77] Creating layer Scale55
I0927 10:14:39.421761  3315 net.cpp:84] Creating Layer Scale55
I0927 10:14:39.421763  3315 net.cpp:406] Scale55 <- Convolution55
I0927 10:14:39.421766  3315 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0927 10:14:39.421794  3315 layer_factory.hpp:77] Creating layer Scale55
I0927 10:14:39.421875  3315 net.cpp:122] Setting up Scale55
I0927 10:14:39.421880  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.421882  3315 net.cpp:137] Memory required for data: 1166132400
I0927 10:14:39.421885  3315 layer_factory.hpp:77] Creating layer Eltwise26
I0927 10:14:39.421890  3315 net.cpp:84] Creating Layer Eltwise26
I0927 10:14:39.421892  3315 net.cpp:406] Eltwise26 <- Eltwise25_penlu51_0_split_1
I0927 10:14:39.421895  3315 net.cpp:406] Eltwise26 <- Convolution55
I0927 10:14:39.421898  3315 net.cpp:380] Eltwise26 -> Eltwise26
I0927 10:14:39.421916  3315 net.cpp:122] Setting up Eltwise26
I0927 10:14:39.421919  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.421921  3315 net.cpp:137] Memory required for data: 1167770800
I0927 10:14:39.421922  3315 layer_factory.hpp:77] Creating layer penlu53
I0927 10:14:39.421928  3315 net.cpp:84] Creating Layer penlu53
I0927 10:14:39.421931  3315 net.cpp:406] penlu53 <- Eltwise26
I0927 10:14:39.421934  3315 net.cpp:367] penlu53 -> Eltwise26 (in-place)
I0927 10:14:39.422052  3315 net.cpp:122] Setting up penlu53
I0927 10:14:39.422056  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.422058  3315 net.cpp:137] Memory required for data: 1169409200
I0927 10:14:39.422062  3315 layer_factory.hpp:77] Creating layer Eltwise26_penlu53_0_split
I0927 10:14:39.422066  3315 net.cpp:84] Creating Layer Eltwise26_penlu53_0_split
I0927 10:14:39.422068  3315 net.cpp:406] Eltwise26_penlu53_0_split <- Eltwise26
I0927 10:14:39.422071  3315 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_0
I0927 10:14:39.422076  3315 net.cpp:380] Eltwise26_penlu53_0_split -> Eltwise26_penlu53_0_split_1
I0927 10:14:39.422099  3315 net.cpp:122] Setting up Eltwise26_penlu53_0_split
I0927 10:14:39.422103  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.422106  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.422108  3315 net.cpp:137] Memory required for data: 1172686000
I0927 10:14:39.422111  3315 layer_factory.hpp:77] Creating layer Convolution56
I0927 10:14:39.422116  3315 net.cpp:84] Creating Layer Convolution56
I0927 10:14:39.422124  3315 net.cpp:406] Convolution56 <- Eltwise26_penlu53_0_split_0
I0927 10:14:39.422129  3315 net.cpp:380] Convolution56 -> Convolution56
I0927 10:14:39.423848  3315 net.cpp:122] Setting up Convolution56
I0927 10:14:39.423857  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.423861  3315 net.cpp:137] Memory required for data: 1174324400
I0927 10:14:39.423866  3315 layer_factory.hpp:77] Creating layer BatchNorm56
I0927 10:14:39.423871  3315 net.cpp:84] Creating Layer BatchNorm56
I0927 10:14:39.423873  3315 net.cpp:406] BatchNorm56 <- Convolution56
I0927 10:14:39.423877  3315 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0927 10:14:39.424026  3315 net.cpp:122] Setting up BatchNorm56
I0927 10:14:39.424031  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.424033  3315 net.cpp:137] Memory required for data: 1175962800
I0927 10:14:39.424038  3315 layer_factory.hpp:77] Creating layer Scale56
I0927 10:14:39.424042  3315 net.cpp:84] Creating Layer Scale56
I0927 10:14:39.424044  3315 net.cpp:406] Scale56 <- Convolution56
I0927 10:14:39.424048  3315 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0927 10:14:39.424079  3315 layer_factory.hpp:77] Creating layer Scale56
I0927 10:14:39.424162  3315 net.cpp:122] Setting up Scale56
I0927 10:14:39.424168  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.424170  3315 net.cpp:137] Memory required for data: 1177601200
I0927 10:14:39.424175  3315 layer_factory.hpp:77] Creating layer penlu54
I0927 10:14:39.424178  3315 net.cpp:84] Creating Layer penlu54
I0927 10:14:39.424181  3315 net.cpp:406] penlu54 <- Convolution56
I0927 10:14:39.424185  3315 net.cpp:367] penlu54 -> Convolution56 (in-place)
I0927 10:14:39.424309  3315 net.cpp:122] Setting up penlu54
I0927 10:14:39.424314  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.424315  3315 net.cpp:137] Memory required for data: 1179239600
I0927 10:14:39.424319  3315 layer_factory.hpp:77] Creating layer Convolution57
I0927 10:14:39.424326  3315 net.cpp:84] Creating Layer Convolution57
I0927 10:14:39.424329  3315 net.cpp:406] Convolution57 <- Convolution56
I0927 10:14:39.424334  3315 net.cpp:380] Convolution57 -> Convolution57
I0927 10:14:39.426030  3315 net.cpp:122] Setting up Convolution57
I0927 10:14:39.426039  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.426041  3315 net.cpp:137] Memory required for data: 1180878000
I0927 10:14:39.426045  3315 layer_factory.hpp:77] Creating layer BatchNorm57
I0927 10:14:39.426051  3315 net.cpp:84] Creating Layer BatchNorm57
I0927 10:14:39.426054  3315 net.cpp:406] BatchNorm57 <- Convolution57
I0927 10:14:39.426057  3315 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0927 10:14:39.426199  3315 net.cpp:122] Setting up BatchNorm57
I0927 10:14:39.426204  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.426206  3315 net.cpp:137] Memory required for data: 1182516400
I0927 10:14:39.426210  3315 layer_factory.hpp:77] Creating layer Scale57
I0927 10:14:39.426214  3315 net.cpp:84] Creating Layer Scale57
I0927 10:14:39.426216  3315 net.cpp:406] Scale57 <- Convolution57
I0927 10:14:39.426220  3315 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0927 10:14:39.426249  3315 layer_factory.hpp:77] Creating layer Scale57
I0927 10:14:39.426331  3315 net.cpp:122] Setting up Scale57
I0927 10:14:39.426334  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.426337  3315 net.cpp:137] Memory required for data: 1184154800
I0927 10:14:39.426340  3315 layer_factory.hpp:77] Creating layer Eltwise27
I0927 10:14:39.426344  3315 net.cpp:84] Creating Layer Eltwise27
I0927 10:14:39.426347  3315 net.cpp:406] Eltwise27 <- Eltwise26_penlu53_0_split_1
I0927 10:14:39.426350  3315 net.cpp:406] Eltwise27 <- Convolution57
I0927 10:14:39.426353  3315 net.cpp:380] Eltwise27 -> Eltwise27
I0927 10:14:39.426370  3315 net.cpp:122] Setting up Eltwise27
I0927 10:14:39.426374  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.426376  3315 net.cpp:137] Memory required for data: 1185793200
I0927 10:14:39.426385  3315 layer_factory.hpp:77] Creating layer penlu55
I0927 10:14:39.426390  3315 net.cpp:84] Creating Layer penlu55
I0927 10:14:39.426393  3315 net.cpp:406] penlu55 <- Eltwise27
I0927 10:14:39.426396  3315 net.cpp:367] penlu55 -> Eltwise27 (in-place)
I0927 10:14:39.426517  3315 net.cpp:122] Setting up penlu55
I0927 10:14:39.426525  3315 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0927 10:14:39.426527  3315 net.cpp:137] Memory required for data: 1187431600
I0927 10:14:39.426532  3315 layer_factory.hpp:77] Creating layer Pooling1
I0927 10:14:39.426539  3315 net.cpp:84] Creating Layer Pooling1
I0927 10:14:39.426542  3315 net.cpp:406] Pooling1 <- Eltwise27
I0927 10:14:39.426545  3315 net.cpp:380] Pooling1 -> Pooling1
I0927 10:14:39.427021  3315 net.cpp:122] Setting up Pooling1
I0927 10:14:39.427029  3315 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0927 10:14:39.442881  3315 net.cpp:137] Memory required for data: 1187457200
I0927 10:14:39.442888  3315 layer_factory.hpp:77] Creating layer InnerProduct1
I0927 10:14:39.442898  3315 net.cpp:84] Creating Layer InnerProduct1
I0927 10:14:39.442900  3315 net.cpp:406] InnerProduct1 <- Pooling1
I0927 10:14:39.442906  3315 net.cpp:380] InnerProduct1 -> InnerProduct1
I0927 10:14:39.443033  3315 net.cpp:122] Setting up InnerProduct1
I0927 10:14:39.443039  3315 net.cpp:129] Top shape: 100 10 (1000)
I0927 10:14:39.443042  3315 net.cpp:137] Memory required for data: 1187461200
I0927 10:14:39.443047  3315 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0927 10:14:39.443051  3315 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0927 10:14:39.443053  3315 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0927 10:14:39.443058  3315 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0927 10:14:39.443063  3315 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0927 10:14:39.443091  3315 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0927 10:14:39.443096  3315 net.cpp:129] Top shape: 100 10 (1000)
I0927 10:14:39.443099  3315 net.cpp:129] Top shape: 100 10 (1000)
I0927 10:14:39.443101  3315 net.cpp:137] Memory required for data: 1187469200
I0927 10:14:39.443104  3315 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 10:14:39.443109  3315 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0927 10:14:39.443110  3315 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0927 10:14:39.443114  3315 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0927 10:14:39.443119  3315 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0927 10:14:39.443123  3315 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0927 10:14:39.443344  3315 net.cpp:122] Setting up SoftmaxWithLoss1
I0927 10:14:39.443351  3315 net.cpp:129] Top shape: (1)
I0927 10:14:39.443353  3315 net.cpp:132]     with loss weight 1
I0927 10:14:39.443361  3315 net.cpp:137] Memory required for data: 1187469204
I0927 10:14:39.443363  3315 layer_factory.hpp:77] Creating layer Accuracy1
I0927 10:14:39.443368  3315 net.cpp:84] Creating Layer Accuracy1
I0927 10:14:39.443372  3315 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0927 10:14:39.443375  3315 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0927 10:14:39.443379  3315 net.cpp:380] Accuracy1 -> Accuracy1
I0927 10:14:39.443387  3315 net.cpp:122] Setting up Accuracy1
I0927 10:14:39.443389  3315 net.cpp:129] Top shape: (1)
I0927 10:14:39.443392  3315 net.cpp:137] Memory required for data: 1187469208
I0927 10:14:39.443394  3315 net.cpp:200] Accuracy1 does not need backward computation.
I0927 10:14:39.443397  3315 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0927 10:14:39.443399  3315 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0927 10:14:39.443403  3315 net.cpp:198] InnerProduct1 needs backward computation.
I0927 10:14:39.443404  3315 net.cpp:198] Pooling1 needs backward computation.
I0927 10:14:39.443406  3315 net.cpp:198] penlu55 needs backward computation.
I0927 10:14:39.443416  3315 net.cpp:198] Eltwise27 needs backward computation.
I0927 10:14:39.443420  3315 net.cpp:198] Scale57 needs backward computation.
I0927 10:14:39.443423  3315 net.cpp:198] BatchNorm57 needs backward computation.
I0927 10:14:39.443424  3315 net.cpp:198] Convolution57 needs backward computation.
I0927 10:14:39.443426  3315 net.cpp:198] penlu54 needs backward computation.
I0927 10:14:39.443428  3315 net.cpp:198] Scale56 needs backward computation.
I0927 10:14:39.443430  3315 net.cpp:198] BatchNorm56 needs backward computation.
I0927 10:14:39.443433  3315 net.cpp:198] Convolution56 needs backward computation.
I0927 10:14:39.443435  3315 net.cpp:198] Eltwise26_penlu53_0_split needs backward computation.
I0927 10:14:39.443437  3315 net.cpp:198] penlu53 needs backward computation.
I0927 10:14:39.443440  3315 net.cpp:198] Eltwise26 needs backward computation.
I0927 10:14:39.443442  3315 net.cpp:198] Scale55 needs backward computation.
I0927 10:14:39.443445  3315 net.cpp:198] BatchNorm55 needs backward computation.
I0927 10:14:39.443447  3315 net.cpp:198] Convolution55 needs backward computation.
I0927 10:14:39.443449  3315 net.cpp:198] penlu52 needs backward computation.
I0927 10:14:39.443451  3315 net.cpp:198] Scale54 needs backward computation.
I0927 10:14:39.443454  3315 net.cpp:198] BatchNorm54 needs backward computation.
I0927 10:14:39.443455  3315 net.cpp:198] Convolution54 needs backward computation.
I0927 10:14:39.443457  3315 net.cpp:198] Eltwise25_penlu51_0_split needs backward computation.
I0927 10:14:39.443460  3315 net.cpp:198] penlu51 needs backward computation.
I0927 10:14:39.443462  3315 net.cpp:198] Eltwise25 needs backward computation.
I0927 10:14:39.443464  3315 net.cpp:198] Scale53 needs backward computation.
I0927 10:14:39.443467  3315 net.cpp:198] BatchNorm53 needs backward computation.
I0927 10:14:39.443470  3315 net.cpp:198] Convolution53 needs backward computation.
I0927 10:14:39.443471  3315 net.cpp:198] penlu50 needs backward computation.
I0927 10:14:39.443473  3315 net.cpp:198] Scale52 needs backward computation.
I0927 10:14:39.443475  3315 net.cpp:198] BatchNorm52 needs backward computation.
I0927 10:14:39.443477  3315 net.cpp:198] Convolution52 needs backward computation.
I0927 10:14:39.443480  3315 net.cpp:198] Eltwise24_penlu49_0_split needs backward computation.
I0927 10:14:39.443482  3315 net.cpp:198] penlu49 needs backward computation.
I0927 10:14:39.443485  3315 net.cpp:198] Eltwise24 needs backward computation.
I0927 10:14:39.443487  3315 net.cpp:198] Scale51 needs backward computation.
I0927 10:14:39.443490  3315 net.cpp:198] BatchNorm51 needs backward computation.
I0927 10:14:39.443492  3315 net.cpp:198] Convolution51 needs backward computation.
I0927 10:14:39.443495  3315 net.cpp:198] penlu48 needs backward computation.
I0927 10:14:39.443496  3315 net.cpp:198] Scale50 needs backward computation.
I0927 10:14:39.443500  3315 net.cpp:198] BatchNorm50 needs backward computation.
I0927 10:14:39.443501  3315 net.cpp:198] Convolution50 needs backward computation.
I0927 10:14:39.443503  3315 net.cpp:198] Eltwise23_penlu47_0_split needs backward computation.
I0927 10:14:39.443506  3315 net.cpp:198] penlu47 needs backward computation.
I0927 10:14:39.443508  3315 net.cpp:198] Eltwise23 needs backward computation.
I0927 10:14:39.443511  3315 net.cpp:198] Scale49 needs backward computation.
I0927 10:14:39.443513  3315 net.cpp:198] BatchNorm49 needs backward computation.
I0927 10:14:39.443516  3315 net.cpp:198] Convolution49 needs backward computation.
I0927 10:14:39.443518  3315 net.cpp:198] penlu46 needs backward computation.
I0927 10:14:39.443521  3315 net.cpp:198] Scale48 needs backward computation.
I0927 10:14:39.443523  3315 net.cpp:198] BatchNorm48 needs backward computation.
I0927 10:14:39.443526  3315 net.cpp:198] Convolution48 needs backward computation.
I0927 10:14:39.443528  3315 net.cpp:198] Eltwise22_penlu45_0_split needs backward computation.
I0927 10:14:39.443531  3315 net.cpp:198] penlu45 needs backward computation.
I0927 10:14:39.443532  3315 net.cpp:198] Eltwise22 needs backward computation.
I0927 10:14:39.443539  3315 net.cpp:198] Scale47 needs backward computation.
I0927 10:14:39.443542  3315 net.cpp:198] BatchNorm47 needs backward computation.
I0927 10:14:39.443544  3315 net.cpp:198] Convolution47 needs backward computation.
I0927 10:14:39.443547  3315 net.cpp:198] penlu44 needs backward computation.
I0927 10:14:39.443548  3315 net.cpp:198] Scale46 needs backward computation.
I0927 10:14:39.443552  3315 net.cpp:198] BatchNorm46 needs backward computation.
I0927 10:14:39.443553  3315 net.cpp:198] Convolution46 needs backward computation.
I0927 10:14:39.443555  3315 net.cpp:198] Eltwise21_penlu43_0_split needs backward computation.
I0927 10:14:39.443558  3315 net.cpp:198] penlu43 needs backward computation.
I0927 10:14:39.445523  3315 net.cpp:198] Eltwise21 needs backward computation.
I0927 10:14:39.445530  3315 net.cpp:198] Scale45 needs backward computation.
I0927 10:14:39.445541  3315 net.cpp:198] BatchNorm45 needs backward computation.
I0927 10:14:39.445544  3315 net.cpp:198] Convolution45 needs backward computation.
I0927 10:14:39.445546  3315 net.cpp:198] penlu42 needs backward computation.
I0927 10:14:39.445549  3315 net.cpp:198] Scale44 needs backward computation.
I0927 10:14:39.445550  3315 net.cpp:198] BatchNorm44 needs backward computation.
I0927 10:14:39.445552  3315 net.cpp:198] Convolution44 needs backward computation.
I0927 10:14:39.445555  3315 net.cpp:198] Eltwise20_penlu41_0_split needs backward computation.
I0927 10:14:39.445557  3315 net.cpp:198] penlu41 needs backward computation.
I0927 10:14:39.445560  3315 net.cpp:198] Eltwise20 needs backward computation.
I0927 10:14:39.445564  3315 net.cpp:198] Scale43 needs backward computation.
I0927 10:14:39.445566  3315 net.cpp:198] BatchNorm43 needs backward computation.
I0927 10:14:39.445569  3315 net.cpp:198] Convolution43 needs backward computation.
I0927 10:14:39.445571  3315 net.cpp:198] penlu40 needs backward computation.
I0927 10:14:39.445574  3315 net.cpp:198] Scale42 needs backward computation.
I0927 10:14:39.445575  3315 net.cpp:198] BatchNorm42 needs backward computation.
I0927 10:14:39.445577  3315 net.cpp:198] Convolution42 needs backward computation.
I0927 10:14:39.445580  3315 net.cpp:198] Eltwise19_penlu39_0_split needs backward computation.
I0927 10:14:39.445582  3315 net.cpp:198] penlu39 needs backward computation.
I0927 10:14:39.445585  3315 net.cpp:198] Eltwise19 needs backward computation.
I0927 10:14:39.445587  3315 net.cpp:198] Scale41 needs backward computation.
I0927 10:14:39.445590  3315 net.cpp:198] BatchNorm41 needs backward computation.
I0927 10:14:39.445591  3315 net.cpp:198] Convolution41 needs backward computation.
I0927 10:14:39.445595  3315 net.cpp:198] penlu38 needs backward computation.
I0927 10:14:39.445596  3315 net.cpp:198] Scale40 needs backward computation.
I0927 10:14:39.445598  3315 net.cpp:198] BatchNorm40 needs backward computation.
I0927 10:14:39.445600  3315 net.cpp:198] Convolution40 needs backward computation.
I0927 10:14:39.445603  3315 net.cpp:198] Scale39 needs backward computation.
I0927 10:14:39.445605  3315 net.cpp:198] BatchNorm39 needs backward computation.
I0927 10:14:39.445607  3315 net.cpp:198] Convolution39 needs backward computation.
I0927 10:14:39.445610  3315 net.cpp:198] Eltwise18_penlu37_0_split needs backward computation.
I0927 10:14:39.445612  3315 net.cpp:198] penlu37 needs backward computation.
I0927 10:14:39.445614  3315 net.cpp:198] Eltwise18 needs backward computation.
I0927 10:14:39.445617  3315 net.cpp:198] Scale38 needs backward computation.
I0927 10:14:39.445619  3315 net.cpp:198] BatchNorm38 needs backward computation.
I0927 10:14:39.445621  3315 net.cpp:198] Convolution38 needs backward computation.
I0927 10:14:39.445623  3315 net.cpp:198] penlu36 needs backward computation.
I0927 10:14:39.445626  3315 net.cpp:198] Scale37 needs backward computation.
I0927 10:14:39.445627  3315 net.cpp:198] BatchNorm37 needs backward computation.
I0927 10:14:39.445629  3315 net.cpp:198] Convolution37 needs backward computation.
I0927 10:14:39.445639  3315 net.cpp:198] Eltwise17_penlu35_0_split needs backward computation.
I0927 10:14:39.445642  3315 net.cpp:198] penlu35 needs backward computation.
I0927 10:14:39.445644  3315 net.cpp:198] Eltwise17 needs backward computation.
I0927 10:14:39.445647  3315 net.cpp:198] Scale36 needs backward computation.
I0927 10:14:39.445649  3315 net.cpp:198] BatchNorm36 needs backward computation.
I0927 10:14:39.445652  3315 net.cpp:198] Convolution36 needs backward computation.
I0927 10:14:39.445653  3315 net.cpp:198] penlu34 needs backward computation.
I0927 10:14:39.445657  3315 net.cpp:198] Scale35 needs backward computation.
I0927 10:14:39.445658  3315 net.cpp:198] BatchNorm35 needs backward computation.
I0927 10:14:39.445660  3315 net.cpp:198] Convolution35 needs backward computation.
I0927 10:14:39.445662  3315 net.cpp:198] Eltwise16_penlu33_0_split needs backward computation.
I0927 10:14:39.445665  3315 net.cpp:198] penlu33 needs backward computation.
I0927 10:14:39.445667  3315 net.cpp:198] Eltwise16 needs backward computation.
I0927 10:14:39.445669  3315 net.cpp:198] Scale34 needs backward computation.
I0927 10:14:39.445672  3315 net.cpp:198] BatchNorm34 needs backward computation.
I0927 10:14:39.445673  3315 net.cpp:198] Convolution34 needs backward computation.
I0927 10:14:39.445677  3315 net.cpp:198] penlu32 needs backward computation.
I0927 10:14:39.445678  3315 net.cpp:198] Scale33 needs backward computation.
I0927 10:14:39.445680  3315 net.cpp:198] BatchNorm33 needs backward computation.
I0927 10:14:39.445683  3315 net.cpp:198] Convolution33 needs backward computation.
I0927 10:14:39.445684  3315 net.cpp:198] Eltwise15_penlu31_0_split needs backward computation.
I0927 10:14:39.445686  3315 net.cpp:198] penlu31 needs backward computation.
I0927 10:14:39.445689  3315 net.cpp:198] Eltwise15 needs backward computation.
I0927 10:14:39.445691  3315 net.cpp:198] Scale32 needs backward computation.
I0927 10:14:39.445693  3315 net.cpp:198] BatchNorm32 needs backward computation.
I0927 10:14:39.445695  3315 net.cpp:198] Convolution32 needs backward computation.
I0927 10:14:39.445698  3315 net.cpp:198] penlu30 needs backward computation.
I0927 10:14:39.445699  3315 net.cpp:198] Scale31 needs backward computation.
I0927 10:14:39.445703  3315 net.cpp:198] BatchNorm31 needs backward computation.
I0927 10:14:39.445704  3315 net.cpp:198] Convolution31 needs backward computation.
I0927 10:14:39.445714  3315 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I0927 10:14:39.445718  3315 net.cpp:198] penlu29 needs backward computation.
I0927 10:14:39.445719  3315 net.cpp:198] Eltwise14 needs backward computation.
I0927 10:14:39.445722  3315 net.cpp:198] Scale30 needs backward computation.
I0927 10:14:39.445724  3315 net.cpp:198] BatchNorm30 needs backward computation.
I0927 10:14:39.445726  3315 net.cpp:198] Convolution30 needs backward computation.
I0927 10:14:39.445729  3315 net.cpp:198] penlu28 needs backward computation.
I0927 10:14:39.445731  3315 net.cpp:198] Scale29 needs backward computation.
I0927 10:14:39.445734  3315 net.cpp:198] BatchNorm29 needs backward computation.
I0927 10:14:39.445736  3315 net.cpp:198] Convolution29 needs backward computation.
I0927 10:14:39.445739  3315 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I0927 10:14:39.445741  3315 net.cpp:198] penlu27 needs backward computation.
I0927 10:14:39.445744  3315 net.cpp:198] Eltwise13 needs backward computation.
I0927 10:14:39.445746  3315 net.cpp:198] Scale28 needs backward computation.
I0927 10:14:39.445749  3315 net.cpp:198] BatchNorm28 needs backward computation.
I0927 10:14:39.445751  3315 net.cpp:198] Convolution28 needs backward computation.
I0927 10:14:39.445753  3315 net.cpp:198] penlu26 needs backward computation.
I0927 10:14:39.445755  3315 net.cpp:198] Scale27 needs backward computation.
I0927 10:14:39.445758  3315 net.cpp:198] BatchNorm27 needs backward computation.
I0927 10:14:39.445760  3315 net.cpp:198] Convolution27 needs backward computation.
I0927 10:14:39.445762  3315 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I0927 10:14:39.445768  3315 net.cpp:198] penlu25 needs backward computation.
I0927 10:14:39.445771  3315 net.cpp:198] Eltwise12 needs backward computation.
I0927 10:14:39.445775  3315 net.cpp:198] Scale26 needs backward computation.
I0927 10:14:39.445776  3315 net.cpp:198] BatchNorm26 needs backward computation.
I0927 10:14:39.445778  3315 net.cpp:198] Convolution26 needs backward computation.
I0927 10:14:39.445780  3315 net.cpp:198] penlu24 needs backward computation.
I0927 10:14:39.445783  3315 net.cpp:198] Scale25 needs backward computation.
I0927 10:14:39.445785  3315 net.cpp:198] BatchNorm25 needs backward computation.
I0927 10:14:39.473678  3315 net.cpp:198] Convolution25 needs backward computation.
I0927 10:14:39.473687  3315 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I0927 10:14:39.473690  3315 net.cpp:198] penlu23 needs backward computation.
I0927 10:14:39.473693  3315 net.cpp:198] Eltwise11 needs backward computation.
I0927 10:14:39.473696  3315 net.cpp:198] Scale24 needs backward computation.
I0927 10:14:39.473700  3315 net.cpp:198] BatchNorm24 needs backward computation.
I0927 10:14:39.473701  3315 net.cpp:198] Convolution24 needs backward computation.
I0927 10:14:39.473704  3315 net.cpp:198] penlu22 needs backward computation.
I0927 10:14:39.473706  3315 net.cpp:198] Scale23 needs backward computation.
I0927 10:14:39.473709  3315 net.cpp:198] BatchNorm23 needs backward computation.
I0927 10:14:39.473711  3315 net.cpp:198] Convolution23 needs backward computation.
I0927 10:14:39.473714  3315 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I0927 10:14:39.473717  3315 net.cpp:198] penlu21 needs backward computation.
I0927 10:14:39.473721  3315 net.cpp:198] Eltwise10 needs backward computation.
I0927 10:14:39.473726  3315 net.cpp:198] Scale22 needs backward computation.
I0927 10:14:39.473728  3315 net.cpp:198] BatchNorm22 needs backward computation.
I0927 10:14:39.473731  3315 net.cpp:198] Convolution22 needs backward computation.
I0927 10:14:39.473733  3315 net.cpp:198] penlu20 needs backward computation.
I0927 10:14:39.473737  3315 net.cpp:198] Scale21 needs backward computation.
I0927 10:14:39.473738  3315 net.cpp:198] BatchNorm21 needs backward computation.
I0927 10:14:39.473742  3315 net.cpp:198] Convolution21 needs backward computation.
I0927 10:14:39.473743  3315 net.cpp:198] Scale20 needs backward computation.
I0927 10:14:39.473745  3315 net.cpp:198] BatchNorm20 needs backward computation.
I0927 10:14:39.473748  3315 net.cpp:198] Convolution20 needs backward computation.
I0927 10:14:39.473750  3315 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I0927 10:14:39.473753  3315 net.cpp:198] penlu19 needs backward computation.
I0927 10:14:39.473757  3315 net.cpp:198] Eltwise9 needs backward computation.
I0927 10:14:39.473759  3315 net.cpp:198] Scale19 needs backward computation.
I0927 10:14:39.473762  3315 net.cpp:198] BatchNorm19 needs backward computation.
I0927 10:14:39.473764  3315 net.cpp:198] Convolution19 needs backward computation.
I0927 10:14:39.473767  3315 net.cpp:198] penlu18 needs backward computation.
I0927 10:14:39.473769  3315 net.cpp:198] Scale18 needs backward computation.
I0927 10:14:39.473772  3315 net.cpp:198] BatchNorm18 needs backward computation.
I0927 10:14:39.473773  3315 net.cpp:198] Convolution18 needs backward computation.
I0927 10:14:39.473776  3315 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0927 10:14:39.473779  3315 net.cpp:198] penlu17 needs backward computation.
I0927 10:14:39.473781  3315 net.cpp:198] Eltwise8 needs backward computation.
I0927 10:14:39.473784  3315 net.cpp:198] Scale17 needs backward computation.
I0927 10:14:39.473786  3315 net.cpp:198] BatchNorm17 needs backward computation.
I0927 10:14:39.473789  3315 net.cpp:198] Convolution17 needs backward computation.
I0927 10:14:39.473791  3315 net.cpp:198] penlu16 needs backward computation.
I0927 10:14:39.473793  3315 net.cpp:198] Scale16 needs backward computation.
I0927 10:14:39.473803  3315 net.cpp:198] BatchNorm16 needs backward computation.
I0927 10:14:39.473806  3315 net.cpp:198] Convolution16 needs backward computation.
I0927 10:14:39.473809  3315 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0927 10:14:39.473811  3315 net.cpp:198] penlu15 needs backward computation.
I0927 10:14:39.473814  3315 net.cpp:198] Eltwise7 needs backward computation.
I0927 10:14:39.473816  3315 net.cpp:198] Scale15 needs backward computation.
I0927 10:14:39.473819  3315 net.cpp:198] BatchNorm15 needs backward computation.
I0927 10:14:39.473821  3315 net.cpp:198] Convolution15 needs backward computation.
I0927 10:14:39.473824  3315 net.cpp:198] penlu14 needs backward computation.
I0927 10:14:39.473826  3315 net.cpp:198] Scale14 needs backward computation.
I0927 10:14:39.473829  3315 net.cpp:198] BatchNorm14 needs backward computation.
I0927 10:14:39.473831  3315 net.cpp:198] Convolution14 needs backward computation.
I0927 10:14:39.473834  3315 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0927 10:14:39.473836  3315 net.cpp:198] penlu13 needs backward computation.
I0927 10:14:39.473839  3315 net.cpp:198] Eltwise6 needs backward computation.
I0927 10:14:39.473842  3315 net.cpp:198] Scale13 needs backward computation.
I0927 10:14:39.473845  3315 net.cpp:198] BatchNorm13 needs backward computation.
I0927 10:14:39.473846  3315 net.cpp:198] Convolution13 needs backward computation.
I0927 10:14:39.473850  3315 net.cpp:198] penlu12 needs backward computation.
I0927 10:14:39.473851  3315 net.cpp:198] Scale12 needs backward computation.
I0927 10:14:39.473853  3315 net.cpp:198] BatchNorm12 needs backward computation.
I0927 10:14:39.473856  3315 net.cpp:198] Convolution12 needs backward computation.
I0927 10:14:39.473858  3315 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0927 10:14:39.473861  3315 net.cpp:198] penlu11 needs backward computation.
I0927 10:14:39.473863  3315 net.cpp:198] Eltwise5 needs backward computation.
I0927 10:14:39.473866  3315 net.cpp:198] Scale11 needs backward computation.
I0927 10:14:39.473868  3315 net.cpp:198] BatchNorm11 needs backward computation.
I0927 10:14:39.473871  3315 net.cpp:198] Convolution11 needs backward computation.
I0927 10:14:39.473873  3315 net.cpp:198] penlu10 needs backward computation.
I0927 10:14:39.473876  3315 net.cpp:198] Scale10 needs backward computation.
I0927 10:14:39.473878  3315 net.cpp:198] BatchNorm10 needs backward computation.
I0927 10:14:39.473881  3315 net.cpp:198] Convolution10 needs backward computation.
I0927 10:14:39.473883  3315 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0927 10:14:39.473886  3315 net.cpp:198] penlu9 needs backward computation.
I0927 10:14:39.473888  3315 net.cpp:198] Eltwise4 needs backward computation.
I0927 10:14:39.473892  3315 net.cpp:198] Scale9 needs backward computation.
I0927 10:14:39.473894  3315 net.cpp:198] BatchNorm9 needs backward computation.
I0927 10:14:39.473897  3315 net.cpp:198] Convolution9 needs backward computation.
I0927 10:14:39.473901  3315 net.cpp:198] penlu8 needs backward computation.
I0927 10:14:39.473902  3315 net.cpp:198] Scale8 needs backward computation.
I0927 10:14:39.473904  3315 net.cpp:198] BatchNorm8 needs backward computation.
I0927 10:14:39.473907  3315 net.cpp:198] Convolution8 needs backward computation.
I0927 10:14:39.473911  3315 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0927 10:14:39.473913  3315 net.cpp:198] penlu7 needs backward computation.
I0927 10:14:39.473917  3315 net.cpp:198] Eltwise3 needs backward computation.
I0927 10:14:39.473919  3315 net.cpp:198] Scale7 needs backward computation.
I0927 10:14:39.473922  3315 net.cpp:198] BatchNorm7 needs backward computation.
I0927 10:14:39.473924  3315 net.cpp:198] Convolution7 needs backward computation.
I0927 10:14:39.473927  3315 net.cpp:198] penlu6 needs backward computation.
I0927 10:14:39.473928  3315 net.cpp:198] Scale6 needs backward computation.
I0927 10:14:39.473932  3315 net.cpp:198] BatchNorm6 needs backward computation.
I0927 10:14:39.473937  3315 net.cpp:198] Convolution6 needs backward computation.
I0927 10:14:39.473940  3315 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0927 10:14:39.473943  3315 net.cpp:198] penlu5 needs backward computation.
I0927 10:14:39.473945  3315 net.cpp:198] Eltwise2 needs backward computation.
I0927 10:14:39.473948  3315 net.cpp:198] Scale5 needs backward computation.
I0927 10:14:39.473951  3315 net.cpp:198] BatchNorm5 needs backward computation.
I0927 10:14:39.473953  3315 net.cpp:198] Convolution5 needs backward computation.
I0927 10:14:39.476166  3315 net.cpp:198] penlu4 needs backward computation.
I0927 10:14:39.476172  3315 net.cpp:198] Scale4 needs backward computation.
I0927 10:14:39.476176  3315 net.cpp:198] BatchNorm4 needs backward computation.
I0927 10:14:39.476177  3315 net.cpp:198] Convolution4 needs backward computation.
I0927 10:14:39.476181  3315 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0927 10:14:39.476183  3315 net.cpp:198] penlu3 needs backward computation.
I0927 10:14:39.476186  3315 net.cpp:198] Eltwise1 needs backward computation.
I0927 10:14:39.476188  3315 net.cpp:198] Scale3 needs backward computation.
I0927 10:14:39.476191  3315 net.cpp:198] BatchNorm3 needs backward computation.
I0927 10:14:39.476193  3315 net.cpp:198] Convolution3 needs backward computation.
I0927 10:14:39.476196  3315 net.cpp:198] penlu2 needs backward computation.
I0927 10:14:39.476197  3315 net.cpp:198] Scale2 needs backward computation.
I0927 10:14:39.476200  3315 net.cpp:198] BatchNorm2 needs backward computation.
I0927 10:14:39.476202  3315 net.cpp:198] Convolution2 needs backward computation.
I0927 10:14:39.476204  3315 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0927 10:14:39.476207  3315 net.cpp:198] penlu1 needs backward computation.
I0927 10:14:39.476209  3315 net.cpp:198] Scale1 needs backward computation.
I0927 10:14:39.476212  3315 net.cpp:198] BatchNorm1 needs backward computation.
I0927 10:14:39.476214  3315 net.cpp:198] Convolution1 needs backward computation.
I0927 10:14:39.476217  3315 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0927 10:14:39.476220  3315 net.cpp:200] Data1 does not need backward computation.
I0927 10:14:39.476222  3315 net.cpp:242] This network produces output Accuracy1
I0927 10:14:39.476225  3315 net.cpp:242] This network produces output SoftmaxWithLoss1
I0927 10:14:39.476328  3315 net.cpp:255] Network initialization done.
I0927 10:14:39.477186  3315 solver.cpp:56] Solver scaffolding done.
I0927 10:14:39.495533  3315 caffe.cpp:248] Starting Optimization
I0927 10:14:39.495542  3315 solver.cpp:272] Solving resnet_cifar10
I0927 10:14:39.495544  3315 solver.cpp:273] Learning Rate Policy: multistep
I0927 10:14:39.503623  3315 solver.cpp:330] Iteration 0, Testing net (#0)
I0927 10:14:42.947038  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:14:43.086650  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0927 10:14:43.086688  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0927 10:14:43.293699  3315 solver.cpp:218] Iteration 0 (0 iter/s, 3.79805s/100 iters), loss = 2.30205
I0927 10:14:43.293728  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30205 (* 1 = 2.30205 loss)
I0927 10:14:43.293751  3315 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0927 10:14:57.797754  3315 solver.cpp:218] Iteration 100 (6.8947 iter/s, 14.5039s/100 iters), loss = 1.72628
I0927 10:14:57.797793  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.72628 (* 1 = 1.72628 loss)
I0927 10:14:57.797799  3315 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0927 10:15:12.291441  3315 solver.cpp:218] Iteration 200 (6.89964 iter/s, 14.4935s/100 iters), loss = 1.63399
I0927 10:15:12.291535  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.63399 (* 1 = 1.63399 loss)
I0927 10:15:12.291543  3315 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0927 10:15:26.794090  3315 solver.cpp:218] Iteration 300 (6.8954 iter/s, 14.5024s/100 iters), loss = 1.42586
I0927 10:15:26.794128  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.42586 (* 1 = 1.42586 loss)
I0927 10:15:26.794133  3315 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0927 10:15:41.298604  3315 solver.cpp:218] Iteration 400 (6.89449 iter/s, 14.5043s/100 iters), loss = 1.16733
I0927 10:15:41.298645  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16733 (* 1 = 1.16733 loss)
I0927 10:15:41.298651  3315 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0927 10:15:55.090960  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:15:55.671597  3315 solver.cpp:330] Iteration 500, Testing net (#0)
I0927 10:15:59.074389  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:15:59.216420  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4085
I0927 10:15:59.216456  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.90321 (* 1 = 1.90321 loss)
I0927 10:15:59.361266  3315 solver.cpp:218] Iteration 500 (5.53635 iter/s, 18.0625s/100 iters), loss = 1.21827
I0927 10:15:59.361295  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.21827 (* 1 = 1.21827 loss)
I0927 10:15:59.361302  3315 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0927 10:16:13.892606  3315 solver.cpp:218] Iteration 600 (6.88176 iter/s, 14.5312s/100 iters), loss = 1.07125
I0927 10:16:13.892647  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.07125 (* 1 = 1.07125 loss)
I0927 10:16:13.892652  3315 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0927 10:16:28.434068  3315 solver.cpp:218] Iteration 700 (6.87697 iter/s, 14.5413s/100 iters), loss = 1.26642
I0927 10:16:28.434203  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.26642 (* 1 = 1.26642 loss)
I0927 10:16:28.434211  3315 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0927 10:16:42.966182  3315 solver.cpp:218] Iteration 800 (6.88144 iter/s, 14.5319s/100 iters), loss = 1.01617
I0927 10:16:42.966223  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01617 (* 1 = 1.01617 loss)
I0927 10:16:42.966228  3315 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0927 10:16:57.505012  3315 solver.cpp:218] Iteration 900 (6.87821 iter/s, 14.5387s/100 iters), loss = 0.775133
I0927 10:16:57.505053  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.775133 (* 1 = 0.775133 loss)
I0927 10:16:57.505059  3315 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0927 10:17:11.323251  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:17:11.905572  3315 solver.cpp:330] Iteration 1000, Testing net (#0)
I0927 10:17:15.312927  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:17:15.455341  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5227
I0927 10:17:15.455368  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.51882 (* 1 = 1.51882 loss)
I0927 10:17:15.600368  3315 solver.cpp:218] Iteration 1000 (5.52634 iter/s, 18.0952s/100 iters), loss = 0.949892
I0927 10:17:15.600396  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.949892 (* 1 = 0.949892 loss)
I0927 10:17:15.600404  3315 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0927 10:17:30.143182  3315 solver.cpp:218] Iteration 1100 (6.87632 iter/s, 14.5427s/100 iters), loss = 0.988829
I0927 10:17:30.143223  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.988829 (* 1 = 0.988829 loss)
I0927 10:17:30.143229  3315 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0927 10:17:44.688246  3315 solver.cpp:218] Iteration 1200 (6.87526 iter/s, 14.5449s/100 iters), loss = 0.941414
I0927 10:17:44.688380  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.941414 (* 1 = 0.941414 loss)
I0927 10:17:44.688387  3315 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0927 10:17:59.235147  3315 solver.cpp:218] Iteration 1300 (6.87443 iter/s, 14.5467s/100 iters), loss = 0.95773
I0927 10:17:59.235188  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.95773 (* 1 = 0.95773 loss)
I0927 10:17:59.235193  3315 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0927 10:18:13.783648  3315 solver.cpp:218] Iteration 1400 (6.87363 iter/s, 14.5484s/100 iters), loss = 0.754288
I0927 10:18:13.783689  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.754288 (* 1 = 0.754288 loss)
I0927 10:18:13.783695  3315 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0927 10:18:27.606695  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:18:28.189373  3315 solver.cpp:330] Iteration 1500, Testing net (#0)
I0927 10:18:31.597602  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:18:31.740578  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6374
I0927 10:18:31.740604  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08802 (* 1 = 1.08802 loss)
I0927 10:18:31.885294  3315 solver.cpp:218] Iteration 1500 (5.52441 iter/s, 18.1015s/100 iters), loss = 0.864743
I0927 10:18:31.885323  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.864743 (* 1 = 0.864743 loss)
I0927 10:18:31.885329  3315 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0927 10:18:46.417726  3315 solver.cpp:218] Iteration 1600 (6.88122 iter/s, 14.5323s/100 iters), loss = 0.741435
I0927 10:18:46.417767  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.741435 (* 1 = 0.741435 loss)
I0927 10:18:46.417773  3315 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0927 10:19:00.959460  3315 solver.cpp:218] Iteration 1700 (6.87682 iter/s, 14.5416s/100 iters), loss = 0.834536
I0927 10:19:00.959534  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.834536 (* 1 = 0.834536 loss)
I0927 10:19:00.959542  3315 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0927 10:19:15.505255  3315 solver.cpp:218] Iteration 1800 (6.87491 iter/s, 14.5456s/100 iters), loss = 0.918723
I0927 10:19:15.505295  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.918723 (* 1 = 0.918723 loss)
I0927 10:19:15.505301  3315 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0927 10:19:30.047112  3315 solver.cpp:218] Iteration 1900 (6.87676 iter/s, 14.5417s/100 iters), loss = 0.655398
I0927 10:19:30.047152  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.655398 (* 1 = 0.655398 loss)
I0927 10:19:30.047158  3315 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0927 10:19:43.866605  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:19:44.448833  3315 solver.cpp:330] Iteration 2000, Testing net (#0)
I0927 10:19:47.857637  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:19:48.000624  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6877
I0927 10:19:48.000661  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.931241 (* 1 = 0.931241 loss)
I0927 10:19:48.144796  3315 solver.cpp:218] Iteration 2000 (5.52561 iter/s, 18.0976s/100 iters), loss = 0.788784
I0927 10:19:48.144825  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.788784 (* 1 = 0.788784 loss)
I0927 10:19:48.144832  3315 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0927 10:20:02.680042  3315 solver.cpp:218] Iteration 2100 (6.87987 iter/s, 14.5351s/100 iters), loss = 0.695174
I0927 10:20:02.680081  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.695174 (* 1 = 0.695174 loss)
I0927 10:20:02.680088  3315 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0927 10:20:17.215358  3315 solver.cpp:218] Iteration 2200 (6.87984 iter/s, 14.5352s/100 iters), loss = 0.690697
I0927 10:20:17.215492  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.690697 (* 1 = 0.690697 loss)
I0927 10:20:17.215500  3315 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0927 10:20:31.756242  3315 solver.cpp:218] Iteration 2300 (6.87725 iter/s, 14.5407s/100 iters), loss = 0.788591
I0927 10:20:31.756284  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.788591 (* 1 = 0.788591 loss)
I0927 10:20:31.756289  3315 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0927 10:20:46.295202  3315 solver.cpp:218] Iteration 2400 (6.87812 iter/s, 14.5389s/100 iters), loss = 0.574388
I0927 10:20:46.295243  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.574388 (* 1 = 0.574388 loss)
I0927 10:20:46.295248  3315 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0927 10:21:00.106597  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:21:00.689649  3315 solver.cpp:330] Iteration 2500, Testing net (#0)
I0927 10:21:04.100602  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:21:04.243438  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6948
I0927 10:21:04.243474  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.921717 (* 1 = 0.921717 loss)
I0927 10:21:04.388476  3315 solver.cpp:218] Iteration 2500 (5.52695 iter/s, 18.0932s/100 iters), loss = 0.822317
I0927 10:21:04.388504  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.822317 (* 1 = 0.822317 loss)
I0927 10:21:04.388511  3315 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0927 10:21:18.930384  3315 solver.cpp:218] Iteration 2600 (6.87672 iter/s, 14.5418s/100 iters), loss = 0.548753
I0927 10:21:18.930426  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.548753 (* 1 = 0.548753 loss)
I0927 10:21:18.930431  3315 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0927 10:21:33.475581  3315 solver.cpp:218] Iteration 2700 (6.87517 iter/s, 14.5451s/100 iters), loss = 0.619993
I0927 10:21:33.475661  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.619993 (* 1 = 0.619993 loss)
I0927 10:21:33.475667  3315 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0927 10:21:48.019282  3315 solver.cpp:218] Iteration 2800 (6.87589 iter/s, 14.5436s/100 iters), loss = 0.763498
I0927 10:21:48.019325  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.763498 (* 1 = 0.763498 loss)
I0927 10:21:48.019330  3315 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0927 10:22:02.572752  3315 solver.cpp:218] Iteration 2900 (6.87126 iter/s, 14.5534s/100 iters), loss = 0.625055
I0927 10:22:02.572793  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.625055 (* 1 = 0.625055 loss)
I0927 10:22:02.572799  3315 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0927 10:22:16.400017  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:22:16.982137  3315 solver.cpp:330] Iteration 3000, Testing net (#0)
I0927 10:22:20.392729  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:22:20.535480  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6192
I0927 10:22:20.535516  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.19082 (* 1 = 1.19082 loss)
I0927 10:22:20.680313  3315 solver.cpp:218] Iteration 3000 (5.52259 iter/s, 18.1074s/100 iters), loss = 0.69749
I0927 10:22:20.680342  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.69749 (* 1 = 0.69749 loss)
I0927 10:22:20.680349  3315 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0927 10:22:35.243479  3315 solver.cpp:218] Iteration 3100 (6.86668 iter/s, 14.5631s/100 iters), loss = 0.540285
I0927 10:22:35.243520  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.540285 (* 1 = 0.540285 loss)
I0927 10:22:35.243525  3315 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0927 10:22:49.814260  3315 solver.cpp:218] Iteration 3200 (6.8631 iter/s, 14.5707s/100 iters), loss = 0.509462
I0927 10:22:49.814362  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509462 (* 1 = 0.509462 loss)
I0927 10:22:49.814368  3315 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0927 10:23:04.379953  3315 solver.cpp:218] Iteration 3300 (6.86552 iter/s, 14.5655s/100 iters), loss = 0.680472
I0927 10:23:04.379986  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.680472 (* 1 = 0.680472 loss)
I0927 10:23:04.379992  3315 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0927 10:23:18.947921  3315 solver.cpp:218] Iteration 3400 (6.86442 iter/s, 14.5679s/100 iters), loss = 0.644057
I0927 10:23:18.947962  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.644057 (* 1 = 0.644057 loss)
I0927 10:23:18.947968  3315 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0927 10:23:32.787962  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:23:33.371543  3315 solver.cpp:330] Iteration 3500, Testing net (#0)
I0927 10:23:36.782970  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:23:36.925957  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7241
I0927 10:23:36.925994  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.805627 (* 1 = 0.805627 loss)
I0927 10:23:37.071069  3315 solver.cpp:218] Iteration 3500 (5.51784 iter/s, 18.123s/100 iters), loss = 0.606032
I0927 10:23:37.071097  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.606032 (* 1 = 0.606032 loss)
I0927 10:23:37.071104  3315 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0927 10:23:51.616219  3315 solver.cpp:218] Iteration 3600 (6.87518 iter/s, 14.5451s/100 iters), loss = 0.583467
I0927 10:23:51.616259  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583467 (* 1 = 0.583467 loss)
I0927 10:23:51.616266  3315 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0927 10:24:06.166399  3315 solver.cpp:218] Iteration 3700 (6.87281 iter/s, 14.5501s/100 iters), loss = 0.614759
I0927 10:24:06.166501  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.614759 (* 1 = 0.614759 loss)
I0927 10:24:06.166508  3315 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0927 10:24:20.716150  3315 solver.cpp:218] Iteration 3800 (6.87304 iter/s, 14.5496s/100 iters), loss = 0.701563
I0927 10:24:20.716192  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.701563 (* 1 = 0.701563 loss)
I0927 10:24:20.716198  3315 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0927 10:24:35.267505  3315 solver.cpp:218] Iteration 3900 (6.87226 iter/s, 14.5513s/100 iters), loss = 0.518289
I0927 10:24:35.267544  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518289 (* 1 = 0.518289 loss)
I0927 10:24:35.267550  3315 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0927 10:24:49.093153  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:24:49.675669  3315 solver.cpp:330] Iteration 4000, Testing net (#0)
I0927 10:24:53.086598  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:24:53.229223  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7389
I0927 10:24:53.229259  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.730096 (* 1 = 0.730096 loss)
I0927 10:24:53.374198  3315 solver.cpp:218] Iteration 4000 (5.52285 iter/s, 18.1066s/100 iters), loss = 0.699373
I0927 10:24:53.374227  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.699373 (* 1 = 0.699373 loss)
I0927 10:24:53.374233  3315 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0927 10:25:07.926115  3315 solver.cpp:218] Iteration 4100 (6.87199 iter/s, 14.5518s/100 iters), loss = 0.562386
I0927 10:25:07.926157  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.562386 (* 1 = 0.562386 loss)
I0927 10:25:07.926162  3315 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0927 10:25:22.489224  3315 solver.cpp:218] Iteration 4200 (6.86671 iter/s, 14.563s/100 iters), loss = 0.510506
I0927 10:25:22.489328  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510506 (* 1 = 0.510506 loss)
I0927 10:25:22.489346  3315 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0927 10:25:37.048384  3315 solver.cpp:218] Iteration 4300 (6.8686 iter/s, 14.559s/100 iters), loss = 0.61875
I0927 10:25:37.048425  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61875 (* 1 = 0.61875 loss)
I0927 10:25:37.048431  3315 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0927 10:25:51.608466  3315 solver.cpp:218] Iteration 4400 (6.86814 iter/s, 14.56s/100 iters), loss = 0.637545
I0927 10:25:51.608507  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.637545 (* 1 = 0.637545 loss)
I0927 10:25:51.608513  3315 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0927 10:26:05.439683  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:26:06.022096  3315 solver.cpp:330] Iteration 4500, Testing net (#0)
I0927 10:26:09.430310  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:26:09.572954  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7324
I0927 10:26:09.572990  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.791521 (* 1 = 0.791521 loss)
I0927 10:26:09.717872  3315 solver.cpp:218] Iteration 4500 (5.52203 iter/s, 18.1093s/100 iters), loss = 0.613894
I0927 10:26:09.717903  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.613894 (* 1 = 0.613894 loss)
I0927 10:26:09.717911  3315 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0927 10:26:24.273847  3315 solver.cpp:218] Iteration 4600 (6.87007 iter/s, 14.5559s/100 iters), loss = 0.517278
I0927 10:26:24.273888  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.517278 (* 1 = 0.517278 loss)
I0927 10:26:24.273895  3315 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0927 10:26:38.832655  3315 solver.cpp:218] Iteration 4700 (6.86874 iter/s, 14.5587s/100 iters), loss = 0.439317
I0927 10:26:38.832772  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439317 (* 1 = 0.439317 loss)
I0927 10:26:38.832788  3315 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0927 10:26:53.390964  3315 solver.cpp:218] Iteration 4800 (6.869 iter/s, 14.5581s/100 iters), loss = 0.613276
I0927 10:26:53.391006  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.613276 (* 1 = 0.613276 loss)
I0927 10:26:53.391012  3315 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0927 10:27:07.949086  3315 solver.cpp:218] Iteration 4900 (6.86906 iter/s, 14.558s/100 iters), loss = 0.490293
I0927 10:27:07.949129  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490293 (* 1 = 0.490293 loss)
I0927 10:27:07.949136  3315 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0927 10:27:21.782665  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:27:22.364491  3315 solver.cpp:330] Iteration 5000, Testing net (#0)
I0927 10:27:25.776146  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:27:25.919276  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6972
I0927 10:27:25.919312  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.890931 (* 1 = 0.890931 loss)
I0927 10:27:26.064515  3315 solver.cpp:218] Iteration 5000 (5.52019 iter/s, 18.1153s/100 iters), loss = 0.6287
I0927 10:27:26.064545  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.6287 (* 1 = 0.6287 loss)
I0927 10:27:26.064551  3315 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0927 10:27:40.617663  3315 solver.cpp:218] Iteration 5100 (6.8714 iter/s, 14.5531s/100 iters), loss = 0.531207
I0927 10:27:40.617705  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.531207 (* 1 = 0.531207 loss)
I0927 10:27:40.617712  3315 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0927 10:27:55.168519  3315 solver.cpp:218] Iteration 5200 (6.87249 iter/s, 14.5508s/100 iters), loss = 0.563211
I0927 10:27:55.168624  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.563211 (* 1 = 0.563211 loss)
I0927 10:27:55.168642  3315 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0927 10:28:09.728870  3315 solver.cpp:218] Iteration 5300 (6.86804 iter/s, 14.5602s/100 iters), loss = 0.583682
I0927 10:28:09.728912  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583682 (* 1 = 0.583682 loss)
I0927 10:28:09.728919  3315 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0927 10:28:24.288007  3315 solver.cpp:218] Iteration 5400 (6.86858 iter/s, 14.559s/100 iters), loss = 0.600089
I0927 10:28:24.288048  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.600089 (* 1 = 0.600089 loss)
I0927 10:28:24.288054  3315 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0927 10:28:38.123167  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:28:38.705166  3315 solver.cpp:330] Iteration 5500, Testing net (#0)
I0927 10:28:42.113299  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:28:42.255554  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7459
I0927 10:28:42.255591  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.759991 (* 1 = 0.759991 loss)
I0927 10:28:42.400732  3315 solver.cpp:218] Iteration 5500 (5.52101 iter/s, 18.1126s/100 iters), loss = 0.625444
I0927 10:28:42.400761  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.625444 (* 1 = 0.625444 loss)
I0927 10:28:42.400768  3315 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0927 10:28:56.960081  3315 solver.cpp:218] Iteration 5600 (6.86848 iter/s, 14.5593s/100 iters), loss = 0.563612
I0927 10:28:56.960122  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.563612 (* 1 = 0.563612 loss)
I0927 10:28:56.960129  3315 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0927 10:29:11.522552  3315 solver.cpp:218] Iteration 5700 (6.86701 iter/s, 14.5624s/100 iters), loss = 0.393168
I0927 10:29:11.522660  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393168 (* 1 = 0.393168 loss)
I0927 10:29:11.522667  3315 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0927 10:29:26.086094  3315 solver.cpp:218] Iteration 5800 (6.86654 iter/s, 14.5634s/100 iters), loss = 0.602456
I0927 10:29:26.086135  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.602456 (* 1 = 0.602456 loss)
I0927 10:29:26.086141  3315 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0927 10:29:40.645561  3315 solver.cpp:218] Iteration 5900 (6.86843 iter/s, 14.5594s/100 iters), loss = 0.448592
I0927 10:29:40.645602  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448592 (* 1 = 0.448592 loss)
I0927 10:29:40.645608  3315 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0927 10:29:54.483825  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:29:55.066300  3315 solver.cpp:330] Iteration 6000, Testing net (#0)
I0927 10:29:58.476163  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:29:58.619071  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7431
I0927 10:29:58.619108  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.736432 (* 1 = 0.736432 loss)
I0927 10:29:58.763494  3315 solver.cpp:218] Iteration 6000 (5.51942 iter/s, 18.1178s/100 iters), loss = 0.47211
I0927 10:29:58.763522  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47211 (* 1 = 0.47211 loss)
I0927 10:29:58.763528  3315 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0927 10:30:13.313923  3315 solver.cpp:218] Iteration 6100 (6.87269 iter/s, 14.5504s/100 iters), loss = 0.471948
I0927 10:30:13.313964  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471948 (* 1 = 0.471948 loss)
I0927 10:30:13.313971  3315 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0927 10:30:27.871992  3315 solver.cpp:218] Iteration 6200 (6.86908 iter/s, 14.558s/100 iters), loss = 0.528616
I0927 10:30:27.872066  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.528616 (* 1 = 0.528616 loss)
I0927 10:30:27.872072  3315 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0927 10:30:42.427776  3315 solver.cpp:218] Iteration 6300 (6.87018 iter/s, 14.5557s/100 iters), loss = 0.593347
I0927 10:30:42.427817  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.593347 (* 1 = 0.593347 loss)
I0927 10:30:42.427824  3315 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0927 10:30:56.985684  3315 solver.cpp:218] Iteration 6400 (6.86916 iter/s, 14.5578s/100 iters), loss = 0.462574
I0927 10:30:56.985725  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462574 (* 1 = 0.462574 loss)
I0927 10:30:56.985730  3315 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0927 10:31:10.823920  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:31:11.406337  3315 solver.cpp:330] Iteration 6500, Testing net (#0)
I0927 10:31:14.817265  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:31:14.960530  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.757
I0927 10:31:14.960567  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.719417 (* 1 = 0.719417 loss)
I0927 10:31:15.105619  3315 solver.cpp:218] Iteration 6500 (5.51881 iter/s, 18.1198s/100 iters), loss = 0.534036
I0927 10:31:15.105648  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534036 (* 1 = 0.534036 loss)
I0927 10:31:15.105655  3315 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0927 10:31:29.683817  3315 solver.cpp:218] Iteration 6600 (6.85959 iter/s, 14.5781s/100 iters), loss = 0.489158
I0927 10:31:29.683857  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489158 (* 1 = 0.489158 loss)
I0927 10:31:29.683862  3315 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0927 10:31:44.262773  3315 solver.cpp:218] Iteration 6700 (6.85924 iter/s, 14.5789s/100 iters), loss = 0.481198
I0927 10:31:44.262909  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481198 (* 1 = 0.481198 loss)
I0927 10:31:44.262926  3315 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0927 10:31:58.844089  3315 solver.cpp:218] Iteration 6800 (6.85817 iter/s, 14.5811s/100 iters), loss = 0.546539
I0927 10:31:58.844117  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.546539 (* 1 = 0.546539 loss)
I0927 10:31:58.844123  3315 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0927 10:32:13.424230  3315 solver.cpp:218] Iteration 6900 (6.85868 iter/s, 14.5801s/100 iters), loss = 0.493579
I0927 10:32:13.424262  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.493579 (* 1 = 0.493579 loss)
I0927 10:32:13.424278  3315 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0927 10:32:27.277329  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:32:27.860370  3315 solver.cpp:330] Iteration 7000, Testing net (#0)
I0927 10:32:31.276721  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:32:31.419740  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7732
I0927 10:32:31.419777  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.67265 (* 1 = 0.67265 loss)
I0927 10:32:31.564676  3315 solver.cpp:218] Iteration 7000 (5.51257 iter/s, 18.1404s/100 iters), loss = 0.548363
I0927 10:32:31.564704  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.548363 (* 1 = 0.548363 loss)
I0927 10:32:31.564712  3315 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0927 10:32:46.130477  3315 solver.cpp:218] Iteration 7100 (6.86543 iter/s, 14.5657s/100 iters), loss = 0.498163
I0927 10:32:46.130507  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498163 (* 1 = 0.498163 loss)
I0927 10:32:46.130525  3315 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0927 10:33:00.708042  3315 solver.cpp:218] Iteration 7200 (6.85989 iter/s, 14.5775s/100 iters), loss = 0.520473
I0927 10:33:00.708111  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520473 (* 1 = 0.520473 loss)
I0927 10:33:00.708117  3315 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0927 10:33:15.283067  3315 solver.cpp:218] Iteration 7300 (6.86111 iter/s, 14.5749s/100 iters), loss = 0.518659
I0927 10:33:15.283098  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518659 (* 1 = 0.518659 loss)
I0927 10:33:15.283103  3315 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0927 10:33:29.858232  3315 solver.cpp:218] Iteration 7400 (6.86102 iter/s, 14.5751s/100 iters), loss = 0.512417
I0927 10:33:29.858263  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512417 (* 1 = 0.512417 loss)
I0927 10:33:29.858268  3315 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0927 10:33:43.711298  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:33:44.295195  3315 solver.cpp:330] Iteration 7500, Testing net (#0)
I0927 10:33:47.711510  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:33:47.854907  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.709
I0927 10:33:47.854944  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.839889 (* 1 = 0.839889 loss)
I0927 10:33:48.000411  3315 solver.cpp:218] Iteration 7500 (5.51204 iter/s, 18.1421s/100 iters), loss = 0.590972
I0927 10:33:48.000440  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.590972 (* 1 = 0.590972 loss)
I0927 10:33:48.000447  3315 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0927 10:34:02.579471  3315 solver.cpp:218] Iteration 7600 (6.85919 iter/s, 14.579s/100 iters), loss = 0.439118
I0927 10:34:02.579501  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439118 (* 1 = 0.439118 loss)
I0927 10:34:02.579507  3315 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0927 10:34:17.156774  3315 solver.cpp:218] Iteration 7700 (6.86002 iter/s, 14.5772s/100 iters), loss = 0.420113
I0927 10:34:17.156936  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420113 (* 1 = 0.420113 loss)
I0927 10:34:17.156958  3315 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0927 10:34:31.732522  3315 solver.cpp:218] Iteration 7800 (6.86081 iter/s, 14.5755s/100 iters), loss = 0.569897
I0927 10:34:31.732553  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.569897 (* 1 = 0.569897 loss)
I0927 10:34:31.732559  3315 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0927 10:34:46.311312  3315 solver.cpp:218] Iteration 7900 (6.85932 iter/s, 14.5787s/100 iters), loss = 0.52182
I0927 10:34:46.311342  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52182 (* 1 = 0.52182 loss)
I0927 10:34:46.311347  3315 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0927 10:35:00.167946  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:35:00.752414  3315 solver.cpp:330] Iteration 8000, Testing net (#0)
I0927 10:35:04.168443  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:35:04.311420  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7471
I0927 10:35:04.311457  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.71172 (* 1 = 0.71172 loss)
I0927 10:35:04.457056  3315 solver.cpp:218] Iteration 8000 (5.51096 iter/s, 18.1457s/100 iters), loss = 0.520416
I0927 10:35:04.457084  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520416 (* 1 = 0.520416 loss)
I0927 10:35:04.457092  3315 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0927 10:35:19.020375  3315 solver.cpp:218] Iteration 8100 (6.8666 iter/s, 14.5632s/100 iters), loss = 0.524419
I0927 10:35:19.020406  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524419 (* 1 = 0.524419 loss)
I0927 10:35:19.020421  3315 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0927 10:35:33.595100  3315 solver.cpp:218] Iteration 8200 (6.86123 iter/s, 14.5746s/100 iters), loss = 0.43804
I0927 10:35:33.595186  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43804 (* 1 = 0.43804 loss)
I0927 10:35:33.595203  3315 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0927 10:35:48.173903  3315 solver.cpp:218] Iteration 8300 (6.85933 iter/s, 14.5787s/100 iters), loss = 0.559618
I0927 10:35:48.173933  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.559618 (* 1 = 0.559618 loss)
I0927 10:35:48.173938  3315 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0927 10:36:02.752077  3315 solver.cpp:218] Iteration 8400 (6.85961 iter/s, 14.5781s/100 iters), loss = 0.445132
I0927 10:36:02.752109  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445132 (* 1 = 0.445132 loss)
I0927 10:36:02.752115  3315 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0927 10:36:16.604962  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:36:17.187928  3315 solver.cpp:330] Iteration 8500, Testing net (#0)
I0927 10:36:20.604667  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:36:20.747591  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7946
I0927 10:36:20.747627  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597777 (* 1 = 0.597777 loss)
I0927 10:36:20.892735  3315 solver.cpp:218] Iteration 8500 (5.51251 iter/s, 18.1406s/100 iters), loss = 0.445762
I0927 10:36:20.892763  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445762 (* 1 = 0.445762 loss)
I0927 10:36:20.892769  3315 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0927 10:36:35.467450  3315 solver.cpp:218] Iteration 8600 (6.86123 iter/s, 14.5746s/100 iters), loss = 0.414883
I0927 10:36:35.467481  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414883 (* 1 = 0.414883 loss)
I0927 10:36:35.467497  3315 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0927 10:36:50.047878  3315 solver.cpp:218] Iteration 8700 (6.85855 iter/s, 14.5804s/100 iters), loss = 0.517145
I0927 10:36:50.047973  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.517145 (* 1 = 0.517145 loss)
I0927 10:36:50.047982  3315 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0927 10:37:04.620373  3315 solver.cpp:218] Iteration 8800 (6.86231 iter/s, 14.5724s/100 iters), loss = 0.630893
I0927 10:37:04.620401  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.630893 (* 1 = 0.630893 loss)
I0927 10:37:04.620407  3315 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0927 10:37:19.197971  3315 solver.cpp:218] Iteration 8900 (6.85988 iter/s, 14.5775s/100 iters), loss = 0.47991
I0927 10:37:19.198002  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47991 (* 1 = 0.47991 loss)
I0927 10:37:19.198009  3315 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0927 10:37:33.050227  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:37:33.635792  3315 solver.cpp:330] Iteration 9000, Testing net (#0)
I0927 10:37:37.053043  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:37:37.195533  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7547
I0927 10:37:37.195570  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.728088 (* 1 = 0.728088 loss)
I0927 10:37:37.340595  3315 solver.cpp:218] Iteration 9000 (5.51191 iter/s, 18.1425s/100 iters), loss = 0.366575
I0927 10:37:37.340625  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366575 (* 1 = 0.366575 loss)
I0927 10:37:37.340631  3315 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0927 10:37:51.915765  3315 solver.cpp:218] Iteration 9100 (6.86102 iter/s, 14.5751s/100 iters), loss = 0.425007
I0927 10:37:51.915796  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425007 (* 1 = 0.425007 loss)
I0927 10:37:51.915802  3315 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0927 10:38:06.496714  3315 solver.cpp:218] Iteration 9200 (6.8583 iter/s, 14.5809s/100 iters), loss = 0.40201
I0927 10:38:06.496772  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40201 (* 1 = 0.40201 loss)
I0927 10:38:06.496788  3315 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0927 10:38:21.079394  3315 solver.cpp:218] Iteration 9300 (6.8575 iter/s, 14.5826s/100 iters), loss = 0.540347
I0927 10:38:21.079426  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.540347 (* 1 = 0.540347 loss)
I0927 10:38:21.079432  3315 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0927 10:38:35.662534  3315 solver.cpp:218] Iteration 9400 (6.85727 iter/s, 14.5831s/100 iters), loss = 0.462967
I0927 10:38:35.662575  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462967 (* 1 = 0.462967 loss)
I0927 10:38:35.662590  3315 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0927 10:38:49.525858  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:38:50.110018  3315 solver.cpp:330] Iteration 9500, Testing net (#0)
I0927 10:38:53.527101  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:38:53.670290  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7826
I0927 10:38:53.670327  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.641572 (* 1 = 0.641572 loss)
I0927 10:38:53.815466  3315 solver.cpp:218] Iteration 9500 (5.50878 iter/s, 18.1528s/100 iters), loss = 0.494733
I0927 10:38:53.815495  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494733 (* 1 = 0.494733 loss)
I0927 10:38:53.815501  3315 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0927 10:39:08.385174  3315 solver.cpp:218] Iteration 9600 (6.86359 iter/s, 14.5696s/100 iters), loss = 0.402548
I0927 10:39:08.385203  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402548 (* 1 = 0.402548 loss)
I0927 10:39:08.385208  3315 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0927 10:39:22.961879  3315 solver.cpp:218] Iteration 9700 (6.8603 iter/s, 14.5766s/100 iters), loss = 0.445122
I0927 10:39:22.961959  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445122 (* 1 = 0.445122 loss)
I0927 10:39:22.961977  3315 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0927 10:39:37.538018  3315 solver.cpp:218] Iteration 9800 (6.86059 iter/s, 14.576s/100 iters), loss = 0.438134
I0927 10:39:37.538048  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438134 (* 1 = 0.438134 loss)
I0927 10:39:37.538054  3315 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0927 10:39:52.111562  3315 solver.cpp:218] Iteration 9900 (6.86178 iter/s, 14.5735s/100 iters), loss = 0.424292
I0927 10:39:52.111590  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424292 (* 1 = 0.424292 loss)
I0927 10:39:52.111595  3315 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0927 10:40:05.967813  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:40:06.551045  3315 solver.cpp:330] Iteration 10000, Testing net (#0)
I0927 10:40:09.967072  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:40:10.109542  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7395
I0927 10:40:10.109580  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.761048 (* 1 = 0.761048 loss)
I0927 10:40:10.254715  3315 solver.cpp:218] Iteration 10000 (5.51175 iter/s, 18.1431s/100 iters), loss = 0.386684
I0927 10:40:10.254750  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386684 (* 1 = 0.386684 loss)
I0927 10:40:10.254757  3315 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0927 10:40:24.821620  3315 solver.cpp:218] Iteration 10100 (6.86491 iter/s, 14.5668s/100 iters), loss = 0.367794
I0927 10:40:24.821650  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367794 (* 1 = 0.367794 loss)
I0927 10:40:24.821655  3315 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0927 10:40:39.395709  3315 solver.cpp:218] Iteration 10200 (6.86153 iter/s, 14.574s/100 iters), loss = 0.511934
I0927 10:40:39.395786  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511934 (* 1 = 0.511934 loss)
I0927 10:40:39.395792  3315 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0927 10:40:53.971853  3315 solver.cpp:218] Iteration 10300 (6.86058 iter/s, 14.576s/100 iters), loss = 0.559889
I0927 10:40:53.971894  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.559889 (* 1 = 0.559889 loss)
I0927 10:40:53.971899  3315 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0927 10:41:08.547560  3315 solver.cpp:218] Iteration 10400 (6.86077 iter/s, 14.5756s/100 iters), loss = 0.403097
I0927 10:41:08.547590  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403097 (* 1 = 0.403097 loss)
I0927 10:41:08.547596  3315 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0927 10:41:22.393978  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:41:22.977917  3315 solver.cpp:330] Iteration 10500, Testing net (#0)
I0927 10:41:26.395756  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:41:26.538688  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6675
I0927 10:41:26.538724  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07717 (* 1 = 1.07717 loss)
I0927 10:41:26.683429  3315 solver.cpp:218] Iteration 10500 (5.51396 iter/s, 18.1358s/100 iters), loss = 0.432545
I0927 10:41:26.683459  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432545 (* 1 = 0.432545 loss)
I0927 10:41:26.683465  3315 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0927 10:41:41.253535  3315 solver.cpp:218] Iteration 10600 (6.8634 iter/s, 14.57s/100 iters), loss = 0.427843
I0927 10:41:41.253566  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427843 (* 1 = 0.427843 loss)
I0927 10:41:41.253571  3315 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0927 10:41:55.830193  3315 solver.cpp:218] Iteration 10700 (6.86032 iter/s, 14.5766s/100 iters), loss = 0.427319
I0927 10:41:55.830314  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427319 (* 1 = 0.427319 loss)
I0927 10:41:55.830322  3315 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0927 10:42:10.406863  3315 solver.cpp:218] Iteration 10800 (6.86035 iter/s, 14.5765s/100 iters), loss = 0.505165
I0927 10:42:10.406904  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505165 (* 1 = 0.505165 loss)
I0927 10:42:10.406910  3315 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0927 10:42:24.981676  3315 solver.cpp:218] Iteration 10900 (6.86119 iter/s, 14.5747s/100 iters), loss = 0.474654
I0927 10:42:24.981717  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474654 (* 1 = 0.474654 loss)
I0927 10:42:24.981722  3315 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0927 10:42:38.831028  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:42:39.413656  3315 solver.cpp:330] Iteration 11000, Testing net (#0)
I0927 10:42:42.829702  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:42:42.972548  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7961
I0927 10:42:42.972584  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.608513 (* 1 = 0.608513 loss)
I0927 10:42:43.117612  3315 solver.cpp:218] Iteration 11000 (5.51394 iter/s, 18.1358s/100 iters), loss = 0.362114
I0927 10:42:43.117640  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362114 (* 1 = 0.362114 loss)
I0927 10:42:43.117647  3315 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0927 10:42:57.687086  3315 solver.cpp:218] Iteration 11100 (6.8637 iter/s, 14.5694s/100 iters), loss = 0.391397
I0927 10:42:57.687129  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391397 (* 1 = 0.391397 loss)
I0927 10:42:57.687134  3315 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0927 10:43:12.258682  3315 solver.cpp:218] Iteration 11200 (6.86271 iter/s, 14.5715s/100 iters), loss = 0.381747
I0927 10:43:12.258802  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381747 (* 1 = 0.381747 loss)
I0927 10:43:12.258810  3315 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0927 10:43:26.846618  3315 solver.cpp:218] Iteration 11300 (6.85506 iter/s, 14.5878s/100 iters), loss = 0.47245
I0927 10:43:26.846649  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47245 (* 1 = 0.47245 loss)
I0927 10:43:26.846655  3315 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0927 10:43:41.529911  3315 solver.cpp:218] Iteration 11400 (6.8105 iter/s, 14.6832s/100 iters), loss = 0.457463
I0927 10:43:41.529942  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457463 (* 1 = 0.457463 loss)
I0927 10:43:41.529958  3315 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0927 10:43:55.484514  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:43:56.069667  3315 solver.cpp:330] Iteration 11500, Testing net (#0)
I0927 10:43:59.533823  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:43:59.678416  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7926
I0927 10:43:59.678453  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.590094 (* 1 = 0.590094 loss)
I0927 10:43:59.821215  3315 solver.cpp:218] Iteration 11500 (5.4671 iter/s, 18.2912s/100 iters), loss = 0.382677
I0927 10:43:59.821244  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382677 (* 1 = 0.382677 loss)
I0927 10:43:59.821250  3315 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0927 10:44:14.486865  3315 solver.cpp:218] Iteration 11600 (6.81869 iter/s, 14.6656s/100 iters), loss = 0.467232
I0927 10:44:14.486907  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467232 (* 1 = 0.467232 loss)
I0927 10:44:14.486913  3315 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0927 10:44:29.068681  3315 solver.cpp:218] Iteration 11700 (6.85789 iter/s, 14.5817s/100 iters), loss = 0.336083
I0927 10:44:29.068825  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336082 (* 1 = 0.336082 loss)
I0927 10:44:29.068842  3315 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0927 10:44:43.715852  3315 solver.cpp:218] Iteration 11800 (6.82735 iter/s, 14.647s/100 iters), loss = 0.524872
I0927 10:44:43.715900  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524872 (* 1 = 0.524872 loss)
I0927 10:44:43.715910  3315 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0927 10:44:58.318794  3315 solver.cpp:218] Iteration 11900 (6.84798 iter/s, 14.6029s/100 iters), loss = 0.373558
I0927 10:44:58.318835  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373558 (* 1 = 0.373558 loss)
I0927 10:44:58.318840  3315 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0927 10:45:12.176172  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:45:12.760236  3315 solver.cpp:330] Iteration 12000, Testing net (#0)
I0927 10:45:16.177276  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:45:16.319994  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.754
I0927 10:45:16.320031  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.72272 (* 1 = 0.72272 loss)
I0927 10:45:16.464705  3315 solver.cpp:218] Iteration 12000 (5.51091 iter/s, 18.1458s/100 iters), loss = 0.461257
I0927 10:45:16.464733  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461256 (* 1 = 0.461256 loss)
I0927 10:45:16.464740  3315 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0927 10:45:31.030046  3315 solver.cpp:218] Iteration 12100 (6.86565 iter/s, 14.5653s/100 iters), loss = 0.37197
I0927 10:45:31.030076  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37197 (* 1 = 0.37197 loss)
I0927 10:45:31.030081  3315 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0927 10:45:45.604308  3315 solver.cpp:218] Iteration 12200 (6.86144 iter/s, 14.5742s/100 iters), loss = 0.461351
I0927 10:45:45.604429  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461351 (* 1 = 0.461351 loss)
I0927 10:45:45.604445  3315 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0927 10:46:00.177666  3315 solver.cpp:218] Iteration 12300 (6.86191 iter/s, 14.5732s/100 iters), loss = 0.402956
I0927 10:46:00.177706  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402956 (* 1 = 0.402956 loss)
I0927 10:46:00.177711  3315 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0927 10:46:14.756234  3315 solver.cpp:218] Iteration 12400 (6.85942 iter/s, 14.5785s/100 iters), loss = 0.414152
I0927 10:46:14.756275  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414152 (* 1 = 0.414152 loss)
I0927 10:46:14.756281  3315 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0927 10:46:28.606073  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:46:29.189079  3315 solver.cpp:330] Iteration 12500, Testing net (#0)
I0927 10:46:32.607472  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:46:32.750321  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7503
I0927 10:46:32.750357  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.772686 (* 1 = 0.772686 loss)
I0927 10:46:32.895121  3315 solver.cpp:218] Iteration 12500 (5.51305 iter/s, 18.1388s/100 iters), loss = 0.455039
I0927 10:46:32.895150  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.455039 (* 1 = 0.455039 loss)
I0927 10:46:32.895157  3315 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0927 10:46:47.470369  3315 solver.cpp:218] Iteration 12600 (6.86098 iter/s, 14.5752s/100 iters), loss = 0.419874
I0927 10:46:47.470412  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419874 (* 1 = 0.419874 loss)
I0927 10:46:47.470417  3315 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0927 10:47:02.047724  3315 solver.cpp:218] Iteration 12700 (6.86 iter/s, 14.5773s/100 iters), loss = 0.465878
I0927 10:47:02.047849  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465878 (* 1 = 0.465878 loss)
I0927 10:47:02.047868  3315 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0927 10:47:16.623682  3315 solver.cpp:218] Iteration 12800 (6.86069 iter/s, 14.5758s/100 iters), loss = 0.50896
I0927 10:47:16.623710  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50896 (* 1 = 0.50896 loss)
I0927 10:47:16.623716  3315 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0927 10:47:31.197767  3315 solver.cpp:218] Iteration 12900 (6.86153 iter/s, 14.574s/100 iters), loss = 0.386389
I0927 10:47:31.197808  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386389 (* 1 = 0.386389 loss)
I0927 10:47:31.197814  3315 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0927 10:47:45.049818  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:47:45.633823  3315 solver.cpp:330] Iteration 13000, Testing net (#0)
I0927 10:47:49.050912  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:47:49.193773  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.807
I0927 10:47:49.193809  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.564487 (* 1 = 0.564487 loss)
I0927 10:47:49.339064  3315 solver.cpp:218] Iteration 13000 (5.51231 iter/s, 18.1412s/100 iters), loss = 0.425024
I0927 10:47:49.339094  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425024 (* 1 = 0.425024 loss)
I0927 10:47:49.339100  3315 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0927 10:48:03.911382  3315 solver.cpp:218] Iteration 13100 (6.86236 iter/s, 14.5722s/100 iters), loss = 0.311008
I0927 10:48:03.911424  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311008 (* 1 = 0.311008 loss)
I0927 10:48:03.911429  3315 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0927 10:48:18.487277  3315 solver.cpp:218] Iteration 13200 (6.86068 iter/s, 14.5758s/100 iters), loss = 0.398856
I0927 10:48:18.487395  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398856 (* 1 = 0.398856 loss)
I0927 10:48:18.487411  3315 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0927 10:48:33.063105  3315 solver.cpp:218] Iteration 13300 (6.86075 iter/s, 14.5757s/100 iters), loss = 0.50232
I0927 10:48:33.063136  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50232 (* 1 = 0.50232 loss)
I0927 10:48:33.063143  3315 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0927 10:48:47.630843  3315 solver.cpp:218] Iteration 13400 (6.86452 iter/s, 14.5677s/100 iters), loss = 0.439256
I0927 10:48:47.630872  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439256 (* 1 = 0.439256 loss)
I0927 10:48:47.630878  3315 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0927 10:49:01.480650  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:49:02.064633  3315 solver.cpp:330] Iteration 13500, Testing net (#0)
I0927 10:49:05.481376  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:49:05.624202  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7793
I0927 10:49:05.624239  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658635 (* 1 = 0.658635 loss)
I0927 10:49:05.769356  3315 solver.cpp:218] Iteration 13500 (5.51316 iter/s, 18.1384s/100 iters), loss = 0.295125
I0927 10:49:05.769384  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295125 (* 1 = 0.295125 loss)
I0927 10:49:05.769392  3315 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0927 10:49:20.348299  3315 solver.cpp:218] Iteration 13600 (6.85924 iter/s, 14.5789s/100 iters), loss = 0.412633
I0927 10:49:20.348328  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412633 (* 1 = 0.412633 loss)
I0927 10:49:20.348335  3315 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0927 10:49:34.927861  3315 solver.cpp:218] Iteration 13700 (6.85895 iter/s, 14.5795s/100 iters), loss = 0.401992
I0927 10:49:34.927979  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401992 (* 1 = 0.401992 loss)
I0927 10:49:34.927996  3315 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0927 10:49:49.514014  3315 solver.cpp:218] Iteration 13800 (6.85589 iter/s, 14.586s/100 iters), loss = 0.467019
I0927 10:49:49.514053  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467019 (* 1 = 0.467019 loss)
I0927 10:49:49.514060  3315 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0927 10:50:04.101629  3315 solver.cpp:218] Iteration 13900 (6.85517 iter/s, 14.5875s/100 iters), loss = 0.398208
I0927 10:50:04.101670  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398208 (* 1 = 0.398208 loss)
I0927 10:50:04.101675  3315 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0927 10:50:17.964071  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:50:18.549089  3315 solver.cpp:330] Iteration 14000, Testing net (#0)
I0927 10:50:21.966714  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:50:22.109699  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I0927 10:50:22.109735  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.627412 (* 1 = 0.627412 loss)
I0927 10:50:22.254798  3315 solver.cpp:218] Iteration 14000 (5.50871 iter/s, 18.1531s/100 iters), loss = 0.330162
I0927 10:50:22.254827  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330162 (* 1 = 0.330162 loss)
I0927 10:50:22.254834  3315 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0927 10:50:36.820248  3315 solver.cpp:218] Iteration 14100 (6.8656 iter/s, 14.5654s/100 iters), loss = 0.349294
I0927 10:50:36.820276  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349294 (* 1 = 0.349294 loss)
I0927 10:50:36.820281  3315 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0927 10:50:51.394911  3315 solver.cpp:218] Iteration 14200 (6.86126 iter/s, 14.5746s/100 iters), loss = 0.433221
I0927 10:50:51.394960  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433221 (* 1 = 0.433221 loss)
I0927 10:50:51.394968  3315 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0927 10:51:05.973871  3315 solver.cpp:218] Iteration 14300 (6.85924 iter/s, 14.5789s/100 iters), loss = 0.381714
I0927 10:51:05.973913  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381714 (* 1 = 0.381714 loss)
I0927 10:51:05.973919  3315 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0927 10:51:20.554214  3315 solver.cpp:218] Iteration 14400 (6.85859 iter/s, 14.5803s/100 iters), loss = 0.422479
I0927 10:51:20.554255  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422479 (* 1 = 0.422479 loss)
I0927 10:51:20.554261  3315 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0927 10:51:34.411763  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:51:34.996364  3315 solver.cpp:330] Iteration 14500, Testing net (#0)
I0927 10:51:38.414325  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:51:38.557246  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7608
I0927 10:51:38.557271  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691173 (* 1 = 0.691173 loss)
I0927 10:51:38.702687  3315 solver.cpp:218] Iteration 14500 (5.51013 iter/s, 18.1484s/100 iters), loss = 0.356606
I0927 10:51:38.702715  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356606 (* 1 = 0.356606 loss)
I0927 10:51:38.702721  3315 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0927 10:51:53.270823  3315 solver.cpp:218] Iteration 14600 (6.86433 iter/s, 14.5681s/100 iters), loss = 0.343352
I0927 10:51:53.270862  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343352 (* 1 = 0.343352 loss)
I0927 10:51:53.270869  3315 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0927 10:52:07.853461  3315 solver.cpp:218] Iteration 14700 (6.85751 iter/s, 14.5826s/100 iters), loss = 0.356795
I0927 10:52:07.853600  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356795 (* 1 = 0.356795 loss)
I0927 10:52:07.853617  3315 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0927 10:52:22.434015  3315 solver.cpp:218] Iteration 14800 (6.85853 iter/s, 14.5804s/100 iters), loss = 0.403489
I0927 10:52:22.434056  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403489 (* 1 = 0.403489 loss)
I0927 10:52:22.434062  3315 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0927 10:52:37.011899  3315 solver.cpp:218] Iteration 14900 (6.85974 iter/s, 14.5778s/100 iters), loss = 0.424551
I0927 10:52:37.011929  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424551 (* 1 = 0.424551 loss)
I0927 10:52:37.011934  3315 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0927 10:52:50.871106  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:52:51.454560  3315 solver.cpp:330] Iteration 15000, Testing net (#0)
I0927 10:52:54.872782  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:52:55.015375  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7861
I0927 10:52:55.015413  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.624474 (* 1 = 0.624474 loss)
I0927 10:52:55.160553  3315 solver.cpp:218] Iteration 15000 (5.51007 iter/s, 18.1486s/100 iters), loss = 0.319878
I0927 10:52:55.160583  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319878 (* 1 = 0.319878 loss)
I0927 10:52:55.160589  3315 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0927 10:53:09.730504  3315 solver.cpp:218] Iteration 15100 (6.86348 iter/s, 14.5699s/100 iters), loss = 0.431867
I0927 10:53:09.730545  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431867 (* 1 = 0.431867 loss)
I0927 10:53:09.730551  3315 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0927 10:53:24.305260  3315 solver.cpp:218] Iteration 15200 (6.86122 iter/s, 14.5747s/100 iters), loss = 0.366157
I0927 10:53:24.305397  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366157 (* 1 = 0.366157 loss)
I0927 10:53:24.305403  3315 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0927 10:53:38.878672  3315 solver.cpp:218] Iteration 15300 (6.86189 iter/s, 14.5732s/100 iters), loss = 0.56577
I0927 10:53:38.878713  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.56577 (* 1 = 0.56577 loss)
I0927 10:53:38.878720  3315 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0927 10:53:53.453943  3315 solver.cpp:218] Iteration 15400 (6.86097 iter/s, 14.5752s/100 iters), loss = 0.488161
I0927 10:53:53.453984  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488161 (* 1 = 0.488161 loss)
I0927 10:53:53.453989  3315 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0927 10:54:07.304903  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:54:07.888720  3315 solver.cpp:330] Iteration 15500, Testing net (#0)
I0927 10:54:11.303076  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:54:11.446050  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8115
I0927 10:54:11.446086  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55012 (* 1 = 0.55012 loss)
I0927 10:54:11.590739  3315 solver.cpp:218] Iteration 15500 (5.51368 iter/s, 18.1367s/100 iters), loss = 0.328968
I0927 10:54:11.590768  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328968 (* 1 = 0.328968 loss)
I0927 10:54:11.590775  3315 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0927 10:54:26.160738  3315 solver.cpp:218] Iteration 15600 (6.86345 iter/s, 14.5699s/100 iters), loss = 0.367688
I0927 10:54:26.160778  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367688 (* 1 = 0.367688 loss)
I0927 10:54:26.160784  3315 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0927 10:54:40.730532  3315 solver.cpp:218] Iteration 15700 (6.86355 iter/s, 14.5697s/100 iters), loss = 0.442864
I0927 10:54:40.730639  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442864 (* 1 = 0.442864 loss)
I0927 10:54:40.730655  3315 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0927 10:54:55.304550  3315 solver.cpp:218] Iteration 15800 (6.86159 iter/s, 14.5739s/100 iters), loss = 0.456414
I0927 10:54:55.304580  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456414 (* 1 = 0.456414 loss)
I0927 10:54:55.304586  3315 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0927 10:55:09.877260  3315 solver.cpp:218] Iteration 15900 (6.86218 iter/s, 14.5726s/100 iters), loss = 0.343296
I0927 10:55:09.877301  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343296 (* 1 = 0.343296 loss)
I0927 10:55:09.877306  3315 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0927 10:55:23.728346  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:55:24.311609  3315 solver.cpp:330] Iteration 16000, Testing net (#0)
I0927 10:55:27.728320  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:55:27.870774  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6476
I0927 10:55:27.870811  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07427 (* 1 = 1.07427 loss)
I0927 10:55:28.015419  3315 solver.cpp:218] Iteration 16000 (5.51327 iter/s, 18.1381s/100 iters), loss = 0.288321
I0927 10:55:28.015446  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28832 (* 1 = 0.28832 loss)
I0927 10:55:28.015452  3315 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0927 10:55:42.587340  3315 solver.cpp:218] Iteration 16100 (6.86255 iter/s, 14.5719s/100 iters), loss = 0.351669
I0927 10:55:42.587370  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351669 (* 1 = 0.351669 loss)
I0927 10:55:42.587376  3315 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0927 10:55:57.161365  3315 solver.cpp:218] Iteration 16200 (6.86156 iter/s, 14.574s/100 iters), loss = 0.349904
I0927 10:55:57.161506  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349904 (* 1 = 0.349904 loss)
I0927 10:55:57.161514  3315 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0927 10:56:11.742908  3315 solver.cpp:218] Iteration 16300 (6.85807 iter/s, 14.5814s/100 iters), loss = 0.476299
I0927 10:56:11.742938  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476299 (* 1 = 0.476299 loss)
I0927 10:56:11.742944  3315 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0927 10:56:26.357254  3315 solver.cpp:218] Iteration 16400 (6.84262 iter/s, 14.6143s/100 iters), loss = 0.46056
I0927 10:56:26.357295  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46056 (* 1 = 0.46056 loss)
I0927 10:56:26.357301  3315 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0927 10:56:40.287134  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:56:40.873919  3315 solver.cpp:330] Iteration 16500, Testing net (#0)
I0927 10:56:44.314450  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:56:44.457276  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8136
I0927 10:56:44.457314  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.550534 (* 1 = 0.550534 loss)
I0927 10:56:44.599745  3315 solver.cpp:218] Iteration 16500 (5.48173 iter/s, 18.2424s/100 iters), loss = 0.332174
I0927 10:56:44.599772  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332174 (* 1 = 0.332174 loss)
I0927 10:56:44.599778  3315 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0927 10:56:59.312582  3315 solver.cpp:218] Iteration 16600 (6.79682 iter/s, 14.7128s/100 iters), loss = 0.346497
I0927 10:56:59.312613  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346497 (* 1 = 0.346497 loss)
I0927 10:56:59.312620  3315 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0927 10:57:13.935225  3315 solver.cpp:218] Iteration 16700 (6.83874 iter/s, 14.6226s/100 iters), loss = 0.431681
I0927 10:57:13.935359  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431681 (* 1 = 0.431681 loss)
I0927 10:57:13.935365  3315 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0927 10:57:28.594229  3315 solver.cpp:218] Iteration 16800 (6.82182 iter/s, 14.6588s/100 iters), loss = 0.453884
I0927 10:57:28.594260  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453884 (* 1 = 0.453884 loss)
I0927 10:57:28.594266  3315 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0927 10:57:43.167174  3315 solver.cpp:218] Iteration 16900 (6.86207 iter/s, 14.5729s/100 iters), loss = 0.439539
I0927 10:57:43.167215  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439539 (* 1 = 0.439539 loss)
I0927 10:57:43.167222  3315 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0927 10:57:57.033812  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:57:57.617513  3315 solver.cpp:330] Iteration 17000, Testing net (#0)
I0927 10:58:01.034976  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:58:01.177552  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7573
I0927 10:58:01.177589  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.738207 (* 1 = 0.738207 loss)
I0927 10:58:01.323097  3315 solver.cpp:218] Iteration 17000 (5.50787 iter/s, 18.1558s/100 iters), loss = 0.280679
I0927 10:58:01.323127  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280679 (* 1 = 0.280679 loss)
I0927 10:58:01.323134  3315 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0927 10:58:15.896289  3315 solver.cpp:218] Iteration 17100 (6.86195 iter/s, 14.5731s/100 iters), loss = 0.392861
I0927 10:58:15.896332  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392861 (* 1 = 0.392861 loss)
I0927 10:58:15.896338  3315 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0927 10:58:30.469327  3315 solver.cpp:218] Iteration 17200 (6.86203 iter/s, 14.573s/100 iters), loss = 0.340558
I0927 10:58:30.469452  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340558 (* 1 = 0.340558 loss)
I0927 10:58:30.469470  3315 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0927 10:58:45.044945  3315 solver.cpp:218] Iteration 17300 (6.86085 iter/s, 14.5755s/100 iters), loss = 0.450252
I0927 10:58:45.044986  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450251 (* 1 = 0.450251 loss)
I0927 10:58:45.044992  3315 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0927 10:58:59.619668  3315 solver.cpp:218] Iteration 17400 (6.86123 iter/s, 14.5746s/100 iters), loss = 0.313983
I0927 10:58:59.619709  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313983 (* 1 = 0.313983 loss)
I0927 10:58:59.619715  3315 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0927 10:59:13.466641  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:59:14.049932  3315 solver.cpp:330] Iteration 17500, Testing net (#0)
I0927 10:59:17.465579  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 10:59:17.608454  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7602
I0927 10:59:17.608490  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.73472 (* 1 = 0.73472 loss)
I0927 10:59:17.753690  3315 solver.cpp:218] Iteration 17500 (5.51452 iter/s, 18.1339s/100 iters), loss = 0.354162
I0927 10:59:17.753720  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354162 (* 1 = 0.354162 loss)
I0927 10:59:17.753726  3315 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0927 10:59:32.326822  3315 solver.cpp:218] Iteration 17600 (6.86198 iter/s, 14.5731s/100 iters), loss = 0.396536
I0927 10:59:32.326863  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396536 (* 1 = 0.396536 loss)
I0927 10:59:32.326869  3315 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0927 10:59:46.897629  3315 solver.cpp:218] Iteration 17700 (6.86308 iter/s, 14.5707s/100 iters), loss = 0.412567
I0927 10:59:46.897703  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412567 (* 1 = 0.412567 loss)
I0927 10:59:46.897711  3315 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0927 11:00:01.468798  3315 solver.cpp:218] Iteration 17800 (6.86292 iter/s, 14.5711s/100 iters), loss = 0.470663
I0927 11:00:01.468839  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.470663 (* 1 = 0.470663 loss)
I0927 11:00:01.468845  3315 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0927 11:00:16.046516  3315 solver.cpp:218] Iteration 17900 (6.85982 iter/s, 14.5776s/100 iters), loss = 0.388887
I0927 11:00:16.046571  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388887 (* 1 = 0.388887 loss)
I0927 11:00:16.046586  3315 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0927 11:00:29.899034  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:00:30.482164  3315 solver.cpp:330] Iteration 18000, Testing net (#0)
I0927 11:00:33.897318  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:00:34.040118  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6794
I0927 11:00:34.040145  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04062 (* 1 = 1.04062 loss)
I0927 11:00:34.185402  3315 solver.cpp:218] Iteration 18000 (5.51305 iter/s, 18.1388s/100 iters), loss = 0.342624
I0927 11:00:34.185432  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342624 (* 1 = 0.342624 loss)
I0927 11:00:34.185439  3315 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0927 11:00:48.754432  3315 solver.cpp:218] Iteration 18100 (6.86391 iter/s, 14.569s/100 iters), loss = 0.392633
I0927 11:00:48.754472  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392632 (* 1 = 0.392632 loss)
I0927 11:00:48.754478  3315 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0927 11:01:03.323096  3315 solver.cpp:218] Iteration 18200 (6.86409 iter/s, 14.5686s/100 iters), loss = 0.349784
I0927 11:01:03.323235  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349784 (* 1 = 0.349784 loss)
I0927 11:01:03.323241  3315 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0927 11:01:17.895395  3315 solver.cpp:218] Iteration 18300 (6.86241 iter/s, 14.5721s/100 iters), loss = 0.483872
I0927 11:01:17.895434  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.483872 (* 1 = 0.483872 loss)
I0927 11:01:17.895439  3315 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0927 11:01:32.468160  3315 solver.cpp:218] Iteration 18400 (6.86215 iter/s, 14.5727s/100 iters), loss = 0.30897
I0927 11:01:32.468200  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30897 (* 1 = 0.30897 loss)
I0927 11:01:32.468206  3315 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0927 11:01:46.320374  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:01:46.903193  3315 solver.cpp:330] Iteration 18500, Testing net (#0)
I0927 11:01:50.321631  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:01:50.464781  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7917
I0927 11:01:50.464818  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.615499 (* 1 = 0.615499 loss)
I0927 11:01:50.609390  3315 solver.cpp:218] Iteration 18500 (5.51233 iter/s, 18.1411s/100 iters), loss = 0.373368
I0927 11:01:50.609419  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373368 (* 1 = 0.373368 loss)
I0927 11:01:50.609426  3315 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0927 11:02:05.178320  3315 solver.cpp:218] Iteration 18600 (6.86396 iter/s, 14.5689s/100 iters), loss = 0.341509
I0927 11:02:05.178349  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341508 (* 1 = 0.341508 loss)
I0927 11:02:05.178355  3315 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0927 11:02:19.760864  3315 solver.cpp:218] Iteration 18700 (6.85755 iter/s, 14.5825s/100 iters), loss = 0.336966
I0927 11:02:19.760983  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336966 (* 1 = 0.336966 loss)
I0927 11:02:19.760990  3315 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0927 11:02:34.338104  3315 solver.cpp:218] Iteration 18800 (6.86009 iter/s, 14.5771s/100 iters), loss = 0.43654
I0927 11:02:34.338145  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43654 (* 1 = 0.43654 loss)
I0927 11:02:34.338150  3315 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0927 11:02:48.921834  3315 solver.cpp:218] Iteration 18900 (6.85699 iter/s, 14.5837s/100 iters), loss = 0.346384
I0927 11:02:48.921876  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346384 (* 1 = 0.346384 loss)
I0927 11:02:48.921881  3315 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0927 11:03:02.780858  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:03:03.365103  3315 solver.cpp:330] Iteration 19000, Testing net (#0)
I0927 11:03:06.781687  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:03:06.924571  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7587
I0927 11:03:06.924608  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.722031 (* 1 = 0.722031 loss)
I0927 11:03:07.070246  3315 solver.cpp:218] Iteration 19000 (5.51015 iter/s, 18.1483s/100 iters), loss = 0.244087
I0927 11:03:07.070276  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244087 (* 1 = 0.244087 loss)
I0927 11:03:07.070282  3315 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0927 11:03:21.643465  3315 solver.cpp:218] Iteration 19100 (6.86193 iter/s, 14.5732s/100 iters), loss = 0.309627
I0927 11:03:21.643506  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309627 (* 1 = 0.309627 loss)
I0927 11:03:21.643512  3315 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0927 11:03:36.220556  3315 solver.cpp:218] Iteration 19200 (6.86012 iter/s, 14.577s/100 iters), loss = 0.506964
I0927 11:03:36.220624  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.506963 (* 1 = 0.506963 loss)
I0927 11:03:36.220633  3315 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0927 11:03:50.794281  3315 solver.cpp:218] Iteration 19300 (6.86171 iter/s, 14.5736s/100 iters), loss = 0.502428
I0927 11:03:50.794312  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502428 (* 1 = 0.502428 loss)
I0927 11:03:50.794317  3315 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0927 11:04:05.372928  3315 solver.cpp:218] Iteration 19400 (6.85938 iter/s, 14.5786s/100 iters), loss = 0.343641
I0927 11:04:05.372958  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343641 (* 1 = 0.343641 loss)
I0927 11:04:05.372964  3315 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0927 11:04:19.220840  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:04:19.805094  3315 solver.cpp:330] Iteration 19500, Testing net (#0)
I0927 11:04:23.223548  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:04:23.366866  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8112
I0927 11:04:23.366904  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555045 (* 1 = 0.555045 loss)
I0927 11:04:23.512181  3315 solver.cpp:218] Iteration 19500 (5.51293 iter/s, 18.1392s/100 iters), loss = 0.317834
I0927 11:04:23.512210  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317834 (* 1 = 0.317834 loss)
I0927 11:04:23.512217  3315 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0927 11:04:38.088551  3315 solver.cpp:218] Iteration 19600 (6.86045 iter/s, 14.5763s/100 iters), loss = 0.344109
I0927 11:04:38.088593  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344109 (* 1 = 0.344109 loss)
I0927 11:04:38.088598  3315 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0927 11:04:52.666505  3315 solver.cpp:218] Iteration 19700 (6.85971 iter/s, 14.5779s/100 iters), loss = 0.376714
I0927 11:04:52.666626  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376714 (* 1 = 0.376714 loss)
I0927 11:04:52.666643  3315 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0927 11:05:07.239994  3315 solver.cpp:218] Iteration 19800 (6.86185 iter/s, 14.5733s/100 iters), loss = 0.462408
I0927 11:05:07.240025  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462407 (* 1 = 0.462407 loss)
I0927 11:05:07.240030  3315 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0927 11:05:21.816711  3315 solver.cpp:218] Iteration 19900 (6.86029 iter/s, 14.5766s/100 iters), loss = 0.416232
I0927 11:05:21.816751  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416232 (* 1 = 0.416232 loss)
I0927 11:05:21.816757  3315 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0927 11:05:35.669178  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:05:36.252815  3315 solver.cpp:330] Iteration 20000, Testing net (#0)
I0927 11:05:39.669630  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:05:39.812333  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8079
I0927 11:05:39.812371  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.568212 (* 1 = 0.568212 loss)
I0927 11:05:39.957275  3315 solver.cpp:218] Iteration 20000 (5.51254 iter/s, 18.1405s/100 iters), loss = 0.331358
I0927 11:05:39.957304  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331358 (* 1 = 0.331358 loss)
I0927 11:05:39.957311  3315 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0927 11:05:54.529422  3315 solver.cpp:218] Iteration 20100 (6.86244 iter/s, 14.5721s/100 iters), loss = 0.348654
I0927 11:05:54.529464  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348654 (* 1 = 0.348654 loss)
I0927 11:05:54.529469  3315 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0927 11:06:09.103575  3315 solver.cpp:218] Iteration 20200 (6.8615 iter/s, 14.5741s/100 iters), loss = 0.305632
I0927 11:06:09.103700  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305632 (* 1 = 0.305632 loss)
I0927 11:06:09.103708  3315 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0927 11:06:23.680851  3315 solver.cpp:218] Iteration 20300 (6.86007 iter/s, 14.5771s/100 iters), loss = 0.363441
I0927 11:06:23.680892  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363441 (* 1 = 0.363441 loss)
I0927 11:06:23.680898  3315 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0927 11:06:38.255493  3315 solver.cpp:218] Iteration 20400 (6.86127 iter/s, 14.5746s/100 iters), loss = 0.281509
I0927 11:06:38.255522  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281509 (* 1 = 0.281509 loss)
I0927 11:06:38.255528  3315 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0927 11:06:52.111655  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:06:52.694659  3315 solver.cpp:330] Iteration 20500, Testing net (#0)
I0927 11:06:56.114439  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:06:56.257457  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.781
I0927 11:06:56.257494  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658188 (* 1 = 0.658188 loss)
I0927 11:06:56.402734  3315 solver.cpp:218] Iteration 20500 (5.5105 iter/s, 18.1472s/100 iters), loss = 0.312973
I0927 11:06:56.402762  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312973 (* 1 = 0.312973 loss)
I0927 11:06:56.402770  3315 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0927 11:07:10.975389  3315 solver.cpp:218] Iteration 20600 (6.8622 iter/s, 14.5726s/100 iters), loss = 0.427666
I0927 11:07:10.975431  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427665 (* 1 = 0.427665 loss)
I0927 11:07:10.975437  3315 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0927 11:07:25.549229  3315 solver.cpp:218] Iteration 20700 (6.86165 iter/s, 14.5738s/100 iters), loss = 0.363139
I0927 11:07:25.549373  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363139 (* 1 = 0.363139 loss)
I0927 11:07:25.549381  3315 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0927 11:07:40.126727  3315 solver.cpp:218] Iteration 20800 (6.85997 iter/s, 14.5773s/100 iters), loss = 0.383462
I0927 11:07:40.126768  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383462 (* 1 = 0.383462 loss)
I0927 11:07:40.126775  3315 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0927 11:07:54.702476  3315 solver.cpp:218] Iteration 20900 (6.86075 iter/s, 14.5757s/100 iters), loss = 0.348572
I0927 11:07:54.702517  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348572 (* 1 = 0.348572 loss)
I0927 11:07:54.702535  3315 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0927 11:08:08.556372  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:08:09.139984  3315 solver.cpp:330] Iteration 21000, Testing net (#0)
I0927 11:08:12.557399  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:08:12.700263  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.793
I0927 11:08:12.700299  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.617637 (* 1 = 0.617637 loss)
I0927 11:08:12.844825  3315 solver.cpp:218] Iteration 21000 (5.51199 iter/s, 18.1423s/100 iters), loss = 0.296418
I0927 11:08:12.844854  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296418 (* 1 = 0.296418 loss)
I0927 11:08:12.844861  3315 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0927 11:08:27.416173  3315 solver.cpp:218] Iteration 21100 (6.86282 iter/s, 14.5713s/100 iters), loss = 0.315645
I0927 11:08:27.416215  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315645 (* 1 = 0.315645 loss)
I0927 11:08:27.416221  3315 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0927 11:08:41.996315  3315 solver.cpp:218] Iteration 21200 (6.85868 iter/s, 14.5801s/100 iters), loss = 0.313733
I0927 11:08:41.996407  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313733 (* 1 = 0.313733 loss)
I0927 11:08:41.996414  3315 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0927 11:08:56.577292  3315 solver.cpp:218] Iteration 21300 (6.85831 iter/s, 14.5808s/100 iters), loss = 0.447518
I0927 11:08:56.577333  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447518 (* 1 = 0.447518 loss)
I0927 11:08:56.577339  3315 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0927 11:09:11.158363  3315 solver.cpp:218] Iteration 21400 (6.85824 iter/s, 14.581s/100 iters), loss = 0.32047
I0927 11:09:11.158404  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32047 (* 1 = 0.32047 loss)
I0927 11:09:11.158411  3315 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0927 11:09:25.013319  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:09:25.597290  3315 solver.cpp:330] Iteration 21500, Testing net (#0)
I0927 11:09:29.014164  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:09:29.156849  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8032
I0927 11:09:29.156877  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.59362 (* 1 = 0.59362 loss)
I0927 11:09:29.302219  3315 solver.cpp:218] Iteration 21500 (5.51153 iter/s, 18.1438s/100 iters), loss = 0.265648
I0927 11:09:29.302248  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265648 (* 1 = 0.265648 loss)
I0927 11:09:29.302254  3315 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0927 11:09:43.881508  3315 solver.cpp:218] Iteration 21600 (6.85908 iter/s, 14.5792s/100 iters), loss = 0.388406
I0927 11:09:43.881551  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388406 (* 1 = 0.388406 loss)
I0927 11:09:43.881556  3315 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0927 11:09:58.460947  3315 solver.cpp:218] Iteration 21700 (6.85901 iter/s, 14.5794s/100 iters), loss = 0.388241
I0927 11:09:58.461043  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388241 (* 1 = 0.388241 loss)
I0927 11:09:58.461061  3315 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0927 11:10:13.042901  3315 solver.cpp:218] Iteration 21800 (6.85785 iter/s, 14.5818s/100 iters), loss = 0.463558
I0927 11:10:13.042932  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463558 (* 1 = 0.463558 loss)
I0927 11:10:13.042937  3315 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0927 11:10:27.618372  3315 solver.cpp:218] Iteration 21900 (6.86088 iter/s, 14.5754s/100 iters), loss = 0.353601
I0927 11:10:27.618414  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353601 (* 1 = 0.353601 loss)
I0927 11:10:27.618419  3315 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0927 11:10:41.469657  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:10:42.053822  3315 solver.cpp:330] Iteration 22000, Testing net (#0)
I0927 11:10:45.469977  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:10:45.612962  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7775
I0927 11:10:45.612998  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.651804 (* 1 = 0.651804 loss)
I0927 11:10:45.758184  3315 solver.cpp:218] Iteration 22000 (5.51276 iter/s, 18.1397s/100 iters), loss = 0.31998
I0927 11:10:45.758214  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31998 (* 1 = 0.31998 loss)
I0927 11:10:45.758221  3315 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0927 11:11:00.332703  3315 solver.cpp:218] Iteration 22100 (6.86132 iter/s, 14.5744s/100 iters), loss = 0.356776
I0927 11:11:00.332736  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356776 (* 1 = 0.356776 loss)
I0927 11:11:00.332741  3315 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0927 11:11:14.905045  3315 solver.cpp:218] Iteration 22200 (6.86235 iter/s, 14.5723s/100 iters), loss = 0.283676
I0927 11:11:14.905181  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283676 (* 1 = 0.283676 loss)
I0927 11:11:14.905189  3315 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0927 11:11:29.480195  3315 solver.cpp:218] Iteration 22300 (6.86107 iter/s, 14.575s/100 iters), loss = 0.414959
I0927 11:11:29.480235  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414959 (* 1 = 0.414959 loss)
I0927 11:11:29.480242  3315 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0927 11:11:44.059945  3315 solver.cpp:218] Iteration 22400 (6.85887 iter/s, 14.5797s/100 iters), loss = 0.345619
I0927 11:11:44.059975  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345619 (* 1 = 0.345619 loss)
I0927 11:11:44.059981  3315 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0927 11:11:57.912577  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:11:58.495793  3315 solver.cpp:330] Iteration 22500, Testing net (#0)
I0927 11:12:01.912999  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:12:02.055760  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7734
I0927 11:12:02.055795  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.682847 (* 1 = 0.682847 loss)
I0927 11:12:02.200899  3315 solver.cpp:218] Iteration 22500 (5.51241 iter/s, 18.1409s/100 iters), loss = 0.302734
I0927 11:12:02.200929  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302734 (* 1 = 0.302734 loss)
I0927 11:12:02.200937  3315 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0927 11:12:16.770668  3315 solver.cpp:218] Iteration 22600 (6.86356 iter/s, 14.5697s/100 iters), loss = 0.361756
I0927 11:12:16.770709  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361755 (* 1 = 0.361755 loss)
I0927 11:12:16.770714  3315 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0927 11:12:31.345552  3315 solver.cpp:218] Iteration 22700 (6.86116 iter/s, 14.5748s/100 iters), loss = 0.323232
I0927 11:12:31.345695  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323231 (* 1 = 0.323231 loss)
I0927 11:12:31.345702  3315 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0927 11:12:45.916534  3315 solver.cpp:218] Iteration 22800 (6.86304 iter/s, 14.5708s/100 iters), loss = 0.352431
I0927 11:12:45.916565  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352431 (* 1 = 0.352431 loss)
I0927 11:12:45.916571  3315 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0927 11:13:00.493180  3315 solver.cpp:218] Iteration 22900 (6.86032 iter/s, 14.5766s/100 iters), loss = 0.422291
I0927 11:13:00.493221  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422291 (* 1 = 0.422291 loss)
I0927 11:13:00.493228  3315 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0927 11:13:14.343353  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:13:14.927109  3315 solver.cpp:330] Iteration 23000, Testing net (#0)
I0927 11:13:18.344900  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:13:18.487764  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7362
I0927 11:13:18.487802  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.854864 (* 1 = 0.854864 loss)
I0927 11:13:18.632684  3315 solver.cpp:218] Iteration 23000 (5.51286 iter/s, 18.1394s/100 iters), loss = 0.343187
I0927 11:13:18.632714  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343187 (* 1 = 0.343187 loss)
I0927 11:13:18.632720  3315 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0927 11:13:33.207038  3315 solver.cpp:218] Iteration 23100 (6.8614 iter/s, 14.5743s/100 iters), loss = 0.337953
I0927 11:13:33.207079  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337953 (* 1 = 0.337953 loss)
I0927 11:13:33.207085  3315 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0927 11:13:47.789038  3315 solver.cpp:218] Iteration 23200 (6.85781 iter/s, 14.5819s/100 iters), loss = 0.428063
I0927 11:13:47.789152  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428063 (* 1 = 0.428063 loss)
I0927 11:13:47.789170  3315 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0927 11:14:02.361701  3315 solver.cpp:218] Iteration 23300 (6.86224 iter/s, 14.5725s/100 iters), loss = 0.449368
I0927 11:14:02.361729  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.449368 (* 1 = 0.449368 loss)
I0927 11:14:02.361735  3315 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0927 11:14:16.935417  3315 solver.cpp:218] Iteration 23400 (6.8617 iter/s, 14.5736s/100 iters), loss = 0.338193
I0927 11:14:16.935458  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338193 (* 1 = 0.338193 loss)
I0927 11:14:16.935464  3315 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0927 11:14:30.794909  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:14:31.378024  3315 solver.cpp:330] Iteration 23500, Testing net (#0)
I0927 11:14:34.794872  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:14:34.937767  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7653
I0927 11:14:34.937803  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687534 (* 1 = 0.687534 loss)
I0927 11:14:35.083246  3315 solver.cpp:218] Iteration 23500 (5.51033 iter/s, 18.1477s/100 iters), loss = 0.288893
I0927 11:14:35.083276  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288893 (* 1 = 0.288893 loss)
I0927 11:14:35.083281  3315 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0927 11:14:49.654945  3315 solver.cpp:218] Iteration 23600 (6.86265 iter/s, 14.5716s/100 iters), loss = 0.460827
I0927 11:14:49.654985  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460826 (* 1 = 0.460826 loss)
I0927 11:14:49.654990  3315 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0927 11:15:04.232441  3315 solver.cpp:218] Iteration 23700 (6.85993 iter/s, 14.5774s/100 iters), loss = 0.342879
I0927 11:15:04.232537  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342879 (* 1 = 0.342879 loss)
I0927 11:15:04.232544  3315 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0927 11:15:18.807121  3315 solver.cpp:218] Iteration 23800 (6.86127 iter/s, 14.5746s/100 iters), loss = 0.508562
I0927 11:15:18.807152  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508562 (* 1 = 0.508562 loss)
I0927 11:15:18.807168  3315 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0927 11:15:33.383390  3315 solver.cpp:218] Iteration 23900 (6.8605 iter/s, 14.5762s/100 iters), loss = 0.377571
I0927 11:15:33.383420  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377571 (* 1 = 0.377571 loss)
I0927 11:15:33.383425  3315 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0927 11:15:47.235569  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:15:47.818696  3315 solver.cpp:330] Iteration 24000, Testing net (#0)
I0927 11:15:51.234495  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:15:51.377749  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8182
I0927 11:15:51.377786  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.531169 (* 1 = 0.531169 loss)
I0927 11:15:51.522765  3315 solver.cpp:218] Iteration 24000 (5.51289 iter/s, 18.1393s/100 iters), loss = 0.274427
I0927 11:15:51.522794  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274427 (* 1 = 0.274427 loss)
I0927 11:15:51.522801  3315 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0927 11:16:06.099220  3315 solver.cpp:218] Iteration 24100 (6.86041 iter/s, 14.5764s/100 iters), loss = 0.320158
I0927 11:16:06.099261  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320158 (* 1 = 0.320158 loss)
I0927 11:16:06.099265  3315 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0927 11:16:20.677147  3315 solver.cpp:218] Iteration 24200 (6.85972 iter/s, 14.5778s/100 iters), loss = 0.408137
I0927 11:16:20.677244  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408137 (* 1 = 0.408137 loss)
I0927 11:16:20.677251  3315 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0927 11:16:35.257146  3315 solver.cpp:218] Iteration 24300 (6.85877 iter/s, 14.5799s/100 iters), loss = 0.397543
I0927 11:16:35.257177  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397543 (* 1 = 0.397543 loss)
I0927 11:16:35.257184  3315 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0927 11:16:49.842571  3315 solver.cpp:218] Iteration 24400 (6.85619 iter/s, 14.5854s/100 iters), loss = 0.259325
I0927 11:16:49.842612  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259325 (* 1 = 0.259325 loss)
I0927 11:16:49.842617  3315 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0927 11:17:03.697657  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:17:04.281409  3315 solver.cpp:330] Iteration 24500, Testing net (#0)
I0927 11:17:07.697254  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:17:07.840204  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7919
I0927 11:17:07.840242  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.62232 (* 1 = 0.62232 loss)
I0927 11:17:07.985081  3315 solver.cpp:218] Iteration 24500 (5.51194 iter/s, 18.1424s/100 iters), loss = 0.248125
I0927 11:17:07.985111  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248125 (* 1 = 0.248125 loss)
I0927 11:17:07.985117  3315 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0927 11:17:22.555727  3315 solver.cpp:218] Iteration 24600 (6.86315 iter/s, 14.5706s/100 iters), loss = 0.463856
I0927 11:17:22.555755  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463856 (* 1 = 0.463856 loss)
I0927 11:17:22.555761  3315 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0927 11:17:37.124617  3315 solver.cpp:218] Iteration 24700 (6.86397 iter/s, 14.5688s/100 iters), loss = 0.39185
I0927 11:17:37.124770  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39185 (* 1 = 0.39185 loss)
I0927 11:17:37.124778  3315 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0927 11:17:51.699267  3315 solver.cpp:218] Iteration 24800 (6.86132 iter/s, 14.5745s/100 iters), loss = 0.451324
I0927 11:17:51.699307  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451323 (* 1 = 0.451323 loss)
I0927 11:17:51.699313  3315 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0927 11:18:06.284819  3315 solver.cpp:218] Iteration 24900 (6.85614 iter/s, 14.5855s/100 iters), loss = 0.325457
I0927 11:18:06.284860  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325457 (* 1 = 0.325457 loss)
I0927 11:18:06.284865  3315 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0927 11:18:20.138555  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:18:20.721401  3315 solver.cpp:330] Iteration 25000, Testing net (#0)
I0927 11:18:24.137531  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:18:24.280078  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8044
I0927 11:18:24.280104  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.581499 (* 1 = 0.581499 loss)
I0927 11:18:24.425102  3315 solver.cpp:218] Iteration 25000 (5.51262 iter/s, 18.1402s/100 iters), loss = 0.361052
I0927 11:18:24.425129  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361052 (* 1 = 0.361052 loss)
I0927 11:18:24.425137  3315 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0927 11:18:39.001147  3315 solver.cpp:218] Iteration 25100 (6.8606 iter/s, 14.576s/100 iters), loss = 0.284335
I0927 11:18:39.001186  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284334 (* 1 = 0.284334 loss)
I0927 11:18:39.001193  3315 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0927 11:18:53.581347  3315 solver.cpp:218] Iteration 25200 (6.85865 iter/s, 14.5801s/100 iters), loss = 0.285439
I0927 11:18:53.581503  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285439 (* 1 = 0.285439 loss)
I0927 11:18:53.581511  3315 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0927 11:19:08.160853  3315 solver.cpp:218] Iteration 25300 (6.85903 iter/s, 14.5793s/100 iters), loss = 0.390039
I0927 11:19:08.160894  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390039 (* 1 = 0.390039 loss)
I0927 11:19:08.160900  3315 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0927 11:19:22.743634  3315 solver.cpp:218] Iteration 25400 (6.85744 iter/s, 14.5827s/100 iters), loss = 0.288743
I0927 11:19:22.743664  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288742 (* 1 = 0.288742 loss)
I0927 11:19:22.743669  3315 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0927 11:19:36.602632  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:19:37.186496  3315 solver.cpp:330] Iteration 25500, Testing net (#0)
I0927 11:19:40.602392  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:19:40.745369  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7256
I0927 11:19:40.745405  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.894807 (* 1 = 0.894807 loss)
I0927 11:19:40.890381  3315 solver.cpp:218] Iteration 25500 (5.51065 iter/s, 18.1467s/100 iters), loss = 0.306876
I0927 11:19:40.890410  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306876 (* 1 = 0.306876 loss)
I0927 11:19:40.890416  3315 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0927 11:19:55.453127  3315 solver.cpp:218] Iteration 25600 (6.86687 iter/s, 14.5627s/100 iters), loss = 0.291691
I0927 11:19:55.453167  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291691 (* 1 = 0.291691 loss)
I0927 11:19:55.453173  3315 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0927 11:20:10.027561  3315 solver.cpp:218] Iteration 25700 (6.86137 iter/s, 14.5744s/100 iters), loss = 0.363397
I0927 11:20:10.027647  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363396 (* 1 = 0.363396 loss)
I0927 11:20:10.027662  3315 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0927 11:20:24.601930  3315 solver.cpp:218] Iteration 25800 (6.86142 iter/s, 14.5742s/100 iters), loss = 0.420322
I0927 11:20:24.601959  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420321 (* 1 = 0.420321 loss)
I0927 11:20:24.601965  3315 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0927 11:20:39.169630  3315 solver.cpp:218] Iteration 25900 (6.86453 iter/s, 14.5676s/100 iters), loss = 0.39102
I0927 11:20:39.169659  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391019 (* 1 = 0.391019 loss)
I0927 11:20:39.169665  3315 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0927 11:20:53.013653  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:20:53.597118  3315 solver.cpp:330] Iteration 26000, Testing net (#0)
I0927 11:20:57.013890  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:20:57.156908  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8182
I0927 11:20:57.156945  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.535373 (* 1 = 0.535373 loss)
I0927 11:20:57.302096  3315 solver.cpp:218] Iteration 26000 (5.51499 iter/s, 18.1324s/100 iters), loss = 0.334586
I0927 11:20:57.302126  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334586 (* 1 = 0.334586 loss)
I0927 11:20:57.302134  3315 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0927 11:21:11.872681  3315 solver.cpp:218] Iteration 26100 (6.86317 iter/s, 14.5705s/100 iters), loss = 0.296437
I0927 11:21:11.872712  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296437 (* 1 = 0.296437 loss)
I0927 11:21:11.872719  3315 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0927 11:21:26.446144  3315 solver.cpp:218] Iteration 26200 (6.86182 iter/s, 14.5734s/100 iters), loss = 0.45686
I0927 11:21:26.446274  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45686 (* 1 = 0.45686 loss)
I0927 11:21:26.446281  3315 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0927 11:21:41.019423  3315 solver.cpp:218] Iteration 26300 (6.86195 iter/s, 14.5731s/100 iters), loss = 0.404104
I0927 11:21:41.019464  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404104 (* 1 = 0.404104 loss)
I0927 11:21:41.019469  3315 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0927 11:21:55.596838  3315 solver.cpp:218] Iteration 26400 (6.85996 iter/s, 14.5773s/100 iters), loss = 0.377911
I0927 11:21:55.596868  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377911 (* 1 = 0.377911 loss)
I0927 11:21:55.596874  3315 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0927 11:22:09.445452  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:22:10.027895  3315 solver.cpp:330] Iteration 26500, Testing net (#0)
I0927 11:22:13.444524  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:22:13.587363  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.701
I0927 11:22:13.587399  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.909568 (* 1 = 0.909568 loss)
I0927 11:22:13.732550  3315 solver.cpp:218] Iteration 26500 (5.51401 iter/s, 18.1356s/100 iters), loss = 0.267016
I0927 11:22:13.732580  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267016 (* 1 = 0.267016 loss)
I0927 11:22:13.732586  3315 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0927 11:22:28.305688  3315 solver.cpp:218] Iteration 26600 (6.86197 iter/s, 14.5731s/100 iters), loss = 0.304308
I0927 11:22:28.305729  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304307 (* 1 = 0.304307 loss)
I0927 11:22:28.305734  3315 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0927 11:22:42.878895  3315 solver.cpp:218] Iteration 26700 (6.86194 iter/s, 14.5731s/100 iters), loss = 0.357474
I0927 11:22:42.879004  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357473 (* 1 = 0.357473 loss)
I0927 11:22:42.879010  3315 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0927 11:22:57.455380  3315 solver.cpp:218] Iteration 26800 (6.86043 iter/s, 14.5763s/100 iters), loss = 0.351821
I0927 11:22:57.455421  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351821 (* 1 = 0.351821 loss)
I0927 11:22:57.455427  3315 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0927 11:23:12.028648  3315 solver.cpp:218] Iteration 26900 (6.86192 iter/s, 14.5732s/100 iters), loss = 0.297532
I0927 11:23:12.028677  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297531 (* 1 = 0.297531 loss)
I0927 11:23:12.028682  3315 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0927 11:23:25.875977  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:23:26.458004  3315 solver.cpp:330] Iteration 27000, Testing net (#0)
I0927 11:23:29.876399  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:23:30.019269  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7808
I0927 11:23:30.019306  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.651473 (* 1 = 0.651473 loss)
I0927 11:23:30.164132  3315 solver.cpp:218] Iteration 27000 (5.51407 iter/s, 18.1354s/100 iters), loss = 0.356241
I0927 11:23:30.164161  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35624 (* 1 = 0.35624 loss)
I0927 11:23:30.164168  3315 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0927 11:23:44.747583  3315 solver.cpp:218] Iteration 27100 (6.85712 iter/s, 14.5834s/100 iters), loss = 0.311026
I0927 11:23:44.747625  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311026 (* 1 = 0.311026 loss)
I0927 11:23:44.747630  3315 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0927 11:23:59.328626  3315 solver.cpp:218] Iteration 27200 (6.85826 iter/s, 14.581s/100 iters), loss = 0.308635
I0927 11:23:59.328775  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308634 (* 1 = 0.308634 loss)
I0927 11:23:59.328783  3315 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0927 11:24:13.907425  3315 solver.cpp:218] Iteration 27300 (6.85936 iter/s, 14.5786s/100 iters), loss = 0.33948
I0927 11:24:13.907466  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33948 (* 1 = 0.33948 loss)
I0927 11:24:13.907472  3315 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0927 11:24:28.490923  3315 solver.cpp:218] Iteration 27400 (6.8571 iter/s, 14.5834s/100 iters), loss = 0.255961
I0927 11:24:28.490965  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255961 (* 1 = 0.255961 loss)
I0927 11:24:28.490970  3315 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0927 11:24:42.346608  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:24:42.931097  3315 solver.cpp:330] Iteration 27500, Testing net (#0)
I0927 11:24:46.348297  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:24:46.491246  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7904
I0927 11:24:46.491283  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.649583 (* 1 = 0.649583 loss)
I0927 11:24:46.636211  3315 solver.cpp:218] Iteration 27500 (5.5111 iter/s, 18.1452s/100 iters), loss = 0.281315
I0927 11:24:46.636240  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281314 (* 1 = 0.281314 loss)
I0927 11:24:46.636247  3315 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0927 11:25:01.224678  3315 solver.cpp:218] Iteration 27600 (6.85476 iter/s, 14.5884s/100 iters), loss = 0.322578
I0927 11:25:01.224719  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322578 (* 1 = 0.322578 loss)
I0927 11:25:01.224725  3315 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0927 11:25:15.813242  3315 solver.cpp:218] Iteration 27700 (6.85472 iter/s, 14.5885s/100 iters), loss = 0.335821
I0927 11:25:15.813325  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33582 (* 1 = 0.33582 loss)
I0927 11:25:15.813341  3315 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0927 11:25:30.394901  3315 solver.cpp:218] Iteration 27800 (6.85799 iter/s, 14.5815s/100 iters), loss = 0.454121
I0927 11:25:30.394942  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45412 (* 1 = 0.45412 loss)
I0927 11:25:30.394946  3315 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0927 11:25:44.979892  3315 solver.cpp:218] Iteration 27900 (6.8564 iter/s, 14.5849s/100 iters), loss = 0.354682
I0927 11:25:44.979933  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354682 (* 1 = 0.354682 loss)
I0927 11:25:44.979938  3315 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0927 11:25:58.839090  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:25:59.422804  3315 solver.cpp:330] Iteration 28000, Testing net (#0)
I0927 11:26:02.839808  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:26:02.982606  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7755
I0927 11:26:02.982641  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.728259 (* 1 = 0.728259 loss)
I0927 11:26:03.127822  3315 solver.cpp:218] Iteration 28000 (5.5103 iter/s, 18.1478s/100 iters), loss = 0.206769
I0927 11:26:03.127851  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206769 (* 1 = 0.206769 loss)
I0927 11:26:03.127858  3315 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0927 11:26:17.690834  3315 solver.cpp:218] Iteration 28100 (6.86674 iter/s, 14.5629s/100 iters), loss = 0.299493
I0927 11:26:17.690865  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299493 (* 1 = 0.299493 loss)
I0927 11:26:17.690871  3315 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0927 11:26:32.257925  3315 solver.cpp:218] Iteration 28200 (6.86482 iter/s, 14.567s/100 iters), loss = 0.315723
I0927 11:26:32.258046  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315723 (* 1 = 0.315723 loss)
I0927 11:26:32.258054  3315 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0927 11:26:46.830715  3315 solver.cpp:218] Iteration 28300 (6.86218 iter/s, 14.5726s/100 iters), loss = 0.39349
I0927 11:26:46.830746  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39349 (* 1 = 0.39349 loss)
I0927 11:26:46.830751  3315 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0927 11:27:01.399005  3315 solver.cpp:218] Iteration 28400 (6.86426 iter/s, 14.5682s/100 iters), loss = 0.367204
I0927 11:27:01.399046  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367204 (* 1 = 0.367204 loss)
I0927 11:27:01.399052  3315 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0927 11:27:15.247439  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:27:15.830734  3315 solver.cpp:330] Iteration 28500, Testing net (#0)
I0927 11:27:19.247004  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:27:19.390394  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.774
I0927 11:27:19.390431  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.694205 (* 1 = 0.694205 loss)
I0927 11:27:19.535255  3315 solver.cpp:218] Iteration 28500 (5.51385 iter/s, 18.1362s/100 iters), loss = 0.275495
I0927 11:27:19.535285  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275494 (* 1 = 0.275494 loss)
I0927 11:27:19.535292  3315 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0927 11:27:34.108167  3315 solver.cpp:218] Iteration 28600 (6.86208 iter/s, 14.5728s/100 iters), loss = 0.433431
I0927 11:27:34.108198  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433431 (* 1 = 0.433431 loss)
I0927 11:27:34.108206  3315 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0927 11:27:48.674221  3315 solver.cpp:218] Iteration 28700 (6.86531 iter/s, 14.566s/100 iters), loss = 0.27402
I0927 11:27:48.674298  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27402 (* 1 = 0.27402 loss)
I0927 11:27:48.674314  3315 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0927 11:28:03.249984  3315 solver.cpp:218] Iteration 28800 (6.86076 iter/s, 14.5756s/100 iters), loss = 0.488003
I0927 11:28:03.250023  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488002 (* 1 = 0.488002 loss)
I0927 11:28:03.250030  3315 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0927 11:28:17.824694  3315 solver.cpp:218] Iteration 28900 (6.86124 iter/s, 14.5746s/100 iters), loss = 0.305507
I0927 11:28:17.824736  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305507 (* 1 = 0.305507 loss)
I0927 11:28:17.824743  3315 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0927 11:28:31.670653  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:28:32.252907  3315 solver.cpp:330] Iteration 29000, Testing net (#0)
I0927 11:28:35.670112  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:28:35.813230  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.729
I0927 11:28:35.813267  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.842895 (* 1 = 0.842895 loss)
I0927 11:28:35.958299  3315 solver.cpp:218] Iteration 29000 (5.51465 iter/s, 18.1335s/100 iters), loss = 0.295265
I0927 11:28:35.958328  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295264 (* 1 = 0.295264 loss)
I0927 11:28:35.958335  3315 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0927 11:28:50.528141  3315 solver.cpp:218] Iteration 29100 (6.86352 iter/s, 14.5698s/100 iters), loss = 0.364336
I0927 11:28:50.528172  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364335 (* 1 = 0.364335 loss)
I0927 11:28:50.528177  3315 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0927 11:29:05.107622  3315 solver.cpp:218] Iteration 29200 (6.85899 iter/s, 14.5794s/100 iters), loss = 0.335976
I0927 11:29:05.107709  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335976 (* 1 = 0.335976 loss)
I0927 11:29:05.107727  3315 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0927 11:29:19.685240  3315 solver.cpp:218] Iteration 29300 (6.85989 iter/s, 14.5775s/100 iters), loss = 0.354871
I0927 11:29:19.685281  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354871 (* 1 = 0.354871 loss)
I0927 11:29:19.685287  3315 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0927 11:29:34.269748  3315 solver.cpp:218] Iteration 29400 (6.85663 iter/s, 14.5844s/100 iters), loss = 0.336959
I0927 11:29:34.269790  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336959 (* 1 = 0.336959 loss)
I0927 11:29:34.269795  3315 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0927 11:29:48.124279  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:29:48.708304  3315 solver.cpp:330] Iteration 29500, Testing net (#0)
I0927 11:29:52.124006  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:29:52.266604  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8231
I0927 11:29:52.266643  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.522651 (* 1 = 0.522651 loss)
I0927 11:29:52.411808  3315 solver.cpp:218] Iteration 29500 (5.51208 iter/s, 18.142s/100 iters), loss = 0.261458
I0927 11:29:52.411837  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261458 (* 1 = 0.261458 loss)
I0927 11:29:52.411844  3315 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0927 11:30:06.991962  3315 solver.cpp:218] Iteration 29600 (6.85867 iter/s, 14.5801s/100 iters), loss = 0.279571
I0927 11:30:06.991991  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279571 (* 1 = 0.279571 loss)
I0927 11:30:06.991997  3315 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0927 11:30:21.567207  3315 solver.cpp:218] Iteration 29700 (6.86098 iter/s, 14.5752s/100 iters), loss = 0.309298
I0927 11:30:21.567281  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309298 (* 1 = 0.309298 loss)
I0927 11:30:21.567289  3315 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0927 11:30:36.149385  3315 solver.cpp:218] Iteration 29800 (6.85774 iter/s, 14.5821s/100 iters), loss = 0.356328
I0927 11:30:36.149435  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356328 (* 1 = 0.356328 loss)
I0927 11:30:36.149441  3315 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0927 11:30:50.810153  3315 solver.cpp:218] Iteration 29900 (6.82097 iter/s, 14.6607s/100 iters), loss = 0.331039
I0927 11:30:50.810194  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331039 (* 1 = 0.331039 loss)
I0927 11:30:50.810201  3315 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0927 11:31:04.659549  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:31:05.242660  3315 solver.cpp:330] Iteration 30000, Testing net (#0)
I0927 11:31:08.661038  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:31:08.803813  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7823
I0927 11:31:08.803849  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.671344 (* 1 = 0.671344 loss)
I0927 11:31:08.949023  3315 solver.cpp:218] Iteration 30000 (5.51305 iter/s, 18.1388s/100 iters), loss = 0.24004
I0927 11:31:08.949053  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24004 (* 1 = 0.24004 loss)
I0927 11:31:08.949059  3315 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0927 11:31:23.529666  3315 solver.cpp:218] Iteration 30100 (6.85844 iter/s, 14.5806s/100 iters), loss = 0.303409
I0927 11:31:23.529696  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303409 (* 1 = 0.303409 loss)
I0927 11:31:23.529702  3315 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0927 11:31:38.119894  3315 solver.cpp:218] Iteration 30200 (6.85394 iter/s, 14.5902s/100 iters), loss = 0.347691
I0927 11:31:38.120016  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34769 (* 1 = 0.34769 loss)
I0927 11:31:38.120024  3315 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0927 11:31:52.712787  3315 solver.cpp:218] Iteration 30300 (6.85272 iter/s, 14.5927s/100 iters), loss = 0.323794
I0927 11:31:52.712828  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323794 (* 1 = 0.323794 loss)
I0927 11:31:52.712834  3315 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0927 11:32:07.292337  3315 solver.cpp:218] Iteration 30400 (6.85896 iter/s, 14.5795s/100 iters), loss = 0.350827
I0927 11:32:07.292376  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350827 (* 1 = 0.350827 loss)
I0927 11:32:07.292382  3315 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0927 11:32:21.149075  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:32:21.732717  3315 solver.cpp:330] Iteration 30500, Testing net (#0)
I0927 11:32:25.149457  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:32:25.292421  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7535
I0927 11:32:25.292459  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.799614 (* 1 = 0.799614 loss)
I0927 11:32:25.437572  3315 solver.cpp:218] Iteration 30500 (5.51111 iter/s, 18.1452s/100 iters), loss = 0.248117
I0927 11:32:25.437602  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248117 (* 1 = 0.248117 loss)
I0927 11:32:25.437608  3315 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0927 11:32:40.007397  3315 solver.cpp:218] Iteration 30600 (6.86353 iter/s, 14.5698s/100 iters), loss = 0.398002
I0927 11:32:40.007438  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398001 (* 1 = 0.398001 loss)
I0927 11:32:40.007443  3315 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0927 11:32:54.578141  3315 solver.cpp:218] Iteration 30700 (6.8631 iter/s, 14.5707s/100 iters), loss = 0.315578
I0927 11:32:54.578265  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315577 (* 1 = 0.315577 loss)
I0927 11:32:54.578272  3315 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0927 11:33:09.153617  3315 solver.cpp:218] Iteration 30800 (6.86092 iter/s, 14.5753s/100 iters), loss = 0.46045
I0927 11:33:09.153659  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460449 (* 1 = 0.460449 loss)
I0927 11:33:09.153664  3315 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0927 11:33:23.724550  3315 solver.cpp:218] Iteration 30900 (6.86302 iter/s, 14.5709s/100 iters), loss = 0.368535
I0927 11:33:23.724580  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368534 (* 1 = 0.368534 loss)
I0927 11:33:23.724584  3315 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0927 11:33:37.570835  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:33:38.154215  3315 solver.cpp:330] Iteration 31000, Testing net (#0)
I0927 11:33:41.571128  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:33:41.714033  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7411
I0927 11:33:41.714076  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.792809 (* 1 = 0.792809 loss)
I0927 11:33:41.859472  3315 solver.cpp:218] Iteration 31000 (5.51425 iter/s, 18.1348s/100 iters), loss = 0.362726
I0927 11:33:41.859503  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362725 (* 1 = 0.362725 loss)
I0927 11:33:41.859509  3315 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0927 11:33:56.425590  3315 solver.cpp:218] Iteration 31100 (6.86528 iter/s, 14.566s/100 iters), loss = 0.321092
I0927 11:33:56.425621  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321092 (* 1 = 0.321092 loss)
I0927 11:33:56.425626  3315 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0927 11:34:10.999187  3315 solver.cpp:218] Iteration 31200 (6.86176 iter/s, 14.5735s/100 iters), loss = 0.362786
I0927 11:34:10.999279  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362786 (* 1 = 0.362786 loss)
I0927 11:34:10.999286  3315 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0927 11:34:25.572608  3315 solver.cpp:218] Iteration 31300 (6.86187 iter/s, 14.5733s/100 iters), loss = 0.447562
I0927 11:34:25.572649  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447562 (* 1 = 0.447562 loss)
I0927 11:34:25.572655  3315 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0927 11:34:40.152185  3315 solver.cpp:218] Iteration 31400 (6.85895 iter/s, 14.5795s/100 iters), loss = 0.356789
I0927 11:34:40.152226  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356789 (* 1 = 0.356789 loss)
I0927 11:34:40.152232  3315 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0927 11:34:54.001667  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:34:54.585299  3315 solver.cpp:330] Iteration 31500, Testing net (#0)
I0927 11:34:57.999704  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:34:58.142689  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6227
I0927 11:34:58.142727  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.43826 (* 1 = 1.43826 loss)
I0927 11:34:58.288230  3315 solver.cpp:218] Iteration 31500 (5.51391 iter/s, 18.136s/100 iters), loss = 0.301039
I0927 11:34:58.288260  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301038 (* 1 = 0.301038 loss)
I0927 11:34:58.288266  3315 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0927 11:35:12.854359  3315 solver.cpp:218] Iteration 31600 (6.86527 iter/s, 14.5661s/100 iters), loss = 0.285188
I0927 11:35:12.854389  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285188 (* 1 = 0.285188 loss)
I0927 11:35:12.854394  3315 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0927 11:35:27.441390  3315 solver.cpp:218] Iteration 31700 (6.85544 iter/s, 14.587s/100 iters), loss = 0.286397
I0927 11:35:27.441480  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286397 (* 1 = 0.286397 loss)
I0927 11:35:27.441499  3315 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0927 11:35:42.020977  3315 solver.cpp:218] Iteration 31800 (6.85897 iter/s, 14.5795s/100 iters), loss = 0.43354
I0927 11:35:42.021005  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433539 (* 1 = 0.433539 loss)
I0927 11:35:42.021011  3315 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0927 11:35:56.604645  3315 solver.cpp:218] Iteration 31900 (6.85702 iter/s, 14.5836s/100 iters), loss = 0.439729
I0927 11:35:56.604674  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439728 (* 1 = 0.439728 loss)
I0927 11:35:56.604681  3315 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0927 11:36:10.465014  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:36:11.048442  3315 solver.cpp:330] Iteration 32000, Testing net (#0)
I0927 11:36:14.463091  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:36:14.605864  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7552
I0927 11:36:14.605901  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.769974 (* 1 = 0.769974 loss)
I0927 11:36:14.750798  3315 solver.cpp:218] Iteration 32000 (5.51083 iter/s, 18.1461s/100 iters), loss = 0.29312
I0927 11:36:14.750828  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29312 (* 1 = 0.29312 loss)
I0927 11:36:14.750835  3315 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0927 11:36:29.327277  3315 solver.cpp:218] Iteration 32100 (6.8604 iter/s, 14.5764s/100 iters), loss = 0.413494
I0927 11:36:29.327307  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413494 (* 1 = 0.413494 loss)
I0927 11:36:29.327313  3315 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0927 11:36:43.901027  3315 solver.cpp:218] Iteration 32200 (6.86168 iter/s, 14.5737s/100 iters), loss = 0.314302
I0927 11:36:43.901135  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314302 (* 1 = 0.314302 loss)
I0927 11:36:43.901151  3315 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0927 11:36:58.475116  3315 solver.cpp:218] Iteration 32300 (6.86156 iter/s, 14.5739s/100 iters), loss = 0.330094
I0927 11:36:58.475157  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330094 (* 1 = 0.330094 loss)
I0927 11:36:58.475163  3315 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0927 11:37:13.052716  3315 solver.cpp:218] Iteration 32400 (6.85988 iter/s, 14.5775s/100 iters), loss = 0.293529
I0927 11:37:13.052755  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293529 (* 1 = 0.293529 loss)
I0927 11:37:13.052762  3315 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0927 11:37:26.907251  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:37:27.491250  3315 solver.cpp:330] Iteration 32500, Testing net (#0)
I0927 11:37:30.909312  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:37:31.052111  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7902
I0927 11:37:31.052139  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.630363 (* 1 = 0.630363 loss)
I0927 11:37:31.197342  3315 solver.cpp:218] Iteration 32500 (5.5113 iter/s, 18.1445s/100 iters), loss = 0.234237
I0927 11:37:31.197372  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234237 (* 1 = 0.234237 loss)
I0927 11:37:31.197378  3315 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0927 11:37:45.773725  3315 solver.cpp:218] Iteration 32600 (6.86044 iter/s, 14.5763s/100 iters), loss = 0.291265
I0927 11:37:45.773767  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291264 (* 1 = 0.291264 loss)
I0927 11:37:45.773773  3315 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0927 11:38:00.357507  3315 solver.cpp:218] Iteration 32700 (6.85697 iter/s, 14.5837s/100 iters), loss = 0.333346
I0927 11:38:00.357620  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333345 (* 1 = 0.333345 loss)
I0927 11:38:00.357626  3315 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0927 11:38:14.932862  3315 solver.cpp:218] Iteration 32800 (6.86096 iter/s, 14.5752s/100 iters), loss = 0.450928
I0927 11:38:14.932902  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450927 (* 1 = 0.450927 loss)
I0927 11:38:14.932909  3315 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0927 11:38:29.505558  3315 solver.cpp:218] Iteration 32900 (6.86219 iter/s, 14.5726s/100 iters), loss = 0.319047
I0927 11:38:29.505600  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319047 (* 1 = 0.319047 loss)
I0927 11:38:29.505606  3315 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0927 11:38:43.358017  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:38:43.941364  3315 solver.cpp:330] Iteration 33000, Testing net (#0)
I0927 11:38:47.358467  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:38:47.501376  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7734
I0927 11:38:47.501415  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.682175 (* 1 = 0.682175 loss)
I0927 11:38:47.646850  3315 solver.cpp:218] Iteration 33000 (5.51231 iter/s, 18.1412s/100 iters), loss = 0.337579
I0927 11:38:47.646879  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337578 (* 1 = 0.337578 loss)
I0927 11:38:47.646886  3315 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0927 11:39:02.229207  3315 solver.cpp:218] Iteration 33100 (6.85763 iter/s, 14.5823s/100 iters), loss = 0.203756
I0927 11:39:02.229235  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203755 (* 1 = 0.203755 loss)
I0927 11:39:02.229241  3315 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0927 11:39:16.814604  3315 solver.cpp:218] Iteration 33200 (6.8562 iter/s, 14.5853s/100 iters), loss = 0.31082
I0927 11:39:16.814710  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31082 (* 1 = 0.31082 loss)
I0927 11:39:16.814728  3315 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0927 11:39:31.407480  3315 solver.cpp:218] Iteration 33300 (6.85272 iter/s, 14.5927s/100 iters), loss = 0.391028
I0927 11:39:31.407510  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391028 (* 1 = 0.391028 loss)
I0927 11:39:31.407517  3315 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0927 11:39:45.995481  3315 solver.cpp:218] Iteration 33400 (6.85498 iter/s, 14.5879s/100 iters), loss = 0.298564
I0927 11:39:45.995523  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298563 (* 1 = 0.298563 loss)
I0927 11:39:45.995529  3315 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0927 11:39:59.857621  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:40:00.443498  3315 solver.cpp:330] Iteration 33500, Testing net (#0)
I0927 11:40:03.860659  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:40:04.003679  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8265
I0927 11:40:04.003715  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.507699 (* 1 = 0.507699 loss)
I0927 11:40:04.148205  3315 solver.cpp:218] Iteration 33500 (5.50884 iter/s, 18.1526s/100 iters), loss = 0.278668
I0927 11:40:04.148236  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278668 (* 1 = 0.278668 loss)
I0927 11:40:04.148241  3315 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0927 11:40:18.718824  3315 solver.cpp:218] Iteration 33600 (6.86316 iter/s, 14.5705s/100 iters), loss = 0.352125
I0927 11:40:18.718855  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352125 (* 1 = 0.352125 loss)
I0927 11:40:18.718861  3315 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0927 11:40:33.292872  3315 solver.cpp:218] Iteration 33700 (6.86154 iter/s, 14.574s/100 iters), loss = 0.323698
I0927 11:40:33.292994  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323698 (* 1 = 0.323698 loss)
I0927 11:40:33.293002  3315 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0927 11:40:47.868146  3315 solver.cpp:218] Iteration 33800 (6.86101 iter/s, 14.5751s/100 iters), loss = 0.411112
I0927 11:40:47.868175  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411111 (* 1 = 0.411111 loss)
I0927 11:40:47.868181  3315 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0927 11:41:02.445755  3315 solver.cpp:218] Iteration 33900 (6.85987 iter/s, 14.5775s/100 iters), loss = 0.319778
I0927 11:41:02.445796  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319778 (* 1 = 0.319778 loss)
I0927 11:41:02.445802  3315 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0927 11:41:16.295912  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:41:16.878640  3315 solver.cpp:330] Iteration 34000, Testing net (#0)
I0927 11:41:20.295397  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:41:20.437901  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8164
I0927 11:41:20.437938  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.549718 (* 1 = 0.549718 loss)
I0927 11:41:20.582710  3315 solver.cpp:218] Iteration 34000 (5.51363 iter/s, 18.1369s/100 iters), loss = 0.331177
I0927 11:41:20.582738  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331176 (* 1 = 0.331176 loss)
I0927 11:41:20.582746  3315 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0927 11:41:35.158004  3315 solver.cpp:218] Iteration 34100 (6.86096 iter/s, 14.5752s/100 iters), loss = 0.213646
I0927 11:41:35.158044  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213646 (* 1 = 0.213646 loss)
I0927 11:41:35.158051  3315 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0927 11:41:49.746367  3315 solver.cpp:218] Iteration 34200 (6.85482 iter/s, 14.5883s/100 iters), loss = 0.299463
I0927 11:41:49.746440  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299462 (* 1 = 0.299462 loss)
I0927 11:41:49.746448  3315 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0927 11:42:04.325628  3315 solver.cpp:218] Iteration 34300 (6.85911 iter/s, 14.5792s/100 iters), loss = 0.460208
I0927 11:42:04.325659  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460207 (* 1 = 0.460207 loss)
I0927 11:42:04.325664  3315 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0927 11:42:18.903515  3315 solver.cpp:218] Iteration 34400 (6.85974 iter/s, 14.5778s/100 iters), loss = 0.322959
I0927 11:42:18.903555  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322959 (* 1 = 0.322959 loss)
I0927 11:42:18.903561  3315 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0927 11:42:32.763311  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:42:33.346760  3315 solver.cpp:330] Iteration 34500, Testing net (#0)
I0927 11:42:36.764176  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:42:36.907246  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8102
I0927 11:42:36.907272  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.556838 (* 1 = 0.556838 loss)
I0927 11:42:37.052453  3315 solver.cpp:218] Iteration 34500 (5.50999 iter/s, 18.1489s/100 iters), loss = 0.229322
I0927 11:42:37.052484  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229322 (* 1 = 0.229322 loss)
I0927 11:42:37.052490  3315 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0927 11:42:51.619591  3315 solver.cpp:218] Iteration 34600 (6.8648 iter/s, 14.5671s/100 iters), loss = 0.27217
I0927 11:42:51.619632  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272169 (* 1 = 0.272169 loss)
I0927 11:42:51.619637  3315 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0927 11:43:06.193451  3315 solver.cpp:218] Iteration 34700 (6.86164 iter/s, 14.5738s/100 iters), loss = 0.282845
I0927 11:43:06.193554  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282844 (* 1 = 0.282844 loss)
I0927 11:43:06.193562  3315 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0927 11:43:20.766870  3315 solver.cpp:218] Iteration 34800 (6.86187 iter/s, 14.5733s/100 iters), loss = 0.307886
I0927 11:43:20.766911  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307886 (* 1 = 0.307886 loss)
I0927 11:43:20.766916  3315 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0927 11:43:35.339393  3315 solver.cpp:218] Iteration 34900 (6.86227 iter/s, 14.5724s/100 iters), loss = 0.262973
I0927 11:43:35.339435  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262973 (* 1 = 0.262973 loss)
I0927 11:43:35.339442  3315 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0927 11:43:49.190651  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:43:49.774412  3315 solver.cpp:330] Iteration 35000, Testing net (#0)
I0927 11:43:53.191624  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:43:53.334897  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7732
I0927 11:43:53.334933  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.645061 (* 1 = 0.645061 loss)
I0927 11:43:53.479629  3315 solver.cpp:218] Iteration 35000 (5.51263 iter/s, 18.1401s/100 iters), loss = 0.233263
I0927 11:43:53.479657  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233263 (* 1 = 0.233263 loss)
I0927 11:43:53.479665  3315 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0927 11:44:08.057036  3315 solver.cpp:218] Iteration 35100 (6.85996 iter/s, 14.5773s/100 iters), loss = 0.29624
I0927 11:44:08.057066  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29624 (* 1 = 0.29624 loss)
I0927 11:44:08.057072  3315 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0927 11:44:22.628662  3315 solver.cpp:218] Iteration 35200 (6.86268 iter/s, 14.5716s/100 iters), loss = 0.254311
I0927 11:44:22.628782  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25431 (* 1 = 0.25431 loss)
I0927 11:44:22.628788  3315 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0927 11:44:37.198375  3315 solver.cpp:218] Iteration 35300 (6.86363 iter/s, 14.5696s/100 iters), loss = 0.337007
I0927 11:44:37.198406  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337006 (* 1 = 0.337006 loss)
I0927 11:44:37.198411  3315 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0927 11:44:51.764667  3315 solver.cpp:218] Iteration 35400 (6.8652 iter/s, 14.5662s/100 iters), loss = 0.292362
I0927 11:44:51.764698  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292361 (* 1 = 0.292361 loss)
I0927 11:44:51.764703  3315 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0927 11:45:05.611232  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:45:06.194386  3315 solver.cpp:330] Iteration 35500, Testing net (#0)
I0927 11:45:09.612767  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:45:09.755803  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8002
I0927 11:45:09.755839  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596267 (* 1 = 0.596267 loss)
I0927 11:45:09.900529  3315 solver.cpp:218] Iteration 35500 (5.51396 iter/s, 18.1358s/100 iters), loss = 0.305604
I0927 11:45:09.900558  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305604 (* 1 = 0.305604 loss)
I0927 11:45:09.900565  3315 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0927 11:45:24.472741  3315 solver.cpp:218] Iteration 35600 (6.86241 iter/s, 14.5721s/100 iters), loss = 0.231457
I0927 11:45:24.472781  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231457 (* 1 = 0.231457 loss)
I0927 11:45:24.472786  3315 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0927 11:45:39.050235  3315 solver.cpp:218] Iteration 35700 (6.85993 iter/s, 14.5774s/100 iters), loss = 0.305077
I0927 11:45:39.050328  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305077 (* 1 = 0.305077 loss)
I0927 11:45:39.050335  3315 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0927 11:45:53.634480  3315 solver.cpp:218] Iteration 35800 (6.85678 iter/s, 14.5841s/100 iters), loss = 0.290458
I0927 11:45:53.634523  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290457 (* 1 = 0.290457 loss)
I0927 11:45:53.634531  3315 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0927 11:46:08.213677  3315 solver.cpp:218] Iteration 35900 (6.85913 iter/s, 14.5791s/100 iters), loss = 0.390756
I0927 11:46:08.213716  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390756 (* 1 = 0.390756 loss)
I0927 11:46:08.213722  3315 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0927 11:46:22.069583  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:46:22.653267  3315 solver.cpp:330] Iteration 36000, Testing net (#0)
I0927 11:46:26.071471  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:46:26.213906  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7553
I0927 11:46:26.213943  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.775056 (* 1 = 0.775056 loss)
I0927 11:46:26.358721  3315 solver.cpp:218] Iteration 36000 (5.51117 iter/s, 18.145s/100 iters), loss = 0.297407
I0927 11:46:26.358749  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297407 (* 1 = 0.297407 loss)
I0927 11:46:26.358755  3315 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0927 11:46:40.927304  3315 solver.cpp:218] Iteration 36100 (6.86412 iter/s, 14.5685s/100 iters), loss = 0.283173
I0927 11:46:40.927345  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283172 (* 1 = 0.283172 loss)
I0927 11:46:40.927350  3315 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0927 11:46:55.498070  3315 solver.cpp:218] Iteration 36200 (6.86309 iter/s, 14.5707s/100 iters), loss = 0.338113
I0927 11:46:55.498195  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338113 (* 1 = 0.338113 loss)
I0927 11:46:55.498214  3315 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0927 11:47:10.071678  3315 solver.cpp:218] Iteration 36300 (6.86179 iter/s, 14.5734s/100 iters), loss = 0.308399
I0927 11:47:10.071719  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308399 (* 1 = 0.308399 loss)
I0927 11:47:10.071725  3315 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0927 11:47:24.647706  3315 solver.cpp:218] Iteration 36400 (6.86062 iter/s, 14.5759s/100 iters), loss = 0.31443
I0927 11:47:24.647747  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31443 (* 1 = 0.31443 loss)
I0927 11:47:24.647753  3315 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0927 11:47:38.497862  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:47:39.080832  3315 solver.cpp:330] Iteration 36500, Testing net (#0)
I0927 11:47:42.497503  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:47:42.639729  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7897
I0927 11:47:42.639755  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663375 (* 1 = 0.663375 loss)
I0927 11:47:42.785125  3315 solver.cpp:218] Iteration 36500 (5.51349 iter/s, 18.1373s/100 iters), loss = 0.228535
I0927 11:47:42.785156  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228535 (* 1 = 0.228535 loss)
I0927 11:47:42.785161  3315 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0927 11:47:57.362433  3315 solver.cpp:218] Iteration 36600 (6.86001 iter/s, 14.5772s/100 iters), loss = 0.312957
I0927 11:47:57.362474  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312956 (* 1 = 0.312956 loss)
I0927 11:47:57.362480  3315 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0927 11:48:11.939852  3315 solver.cpp:218] Iteration 36700 (6.85996 iter/s, 14.5773s/100 iters), loss = 0.337972
I0927 11:48:11.939930  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337972 (* 1 = 0.337972 loss)
I0927 11:48:11.939937  3315 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0927 11:48:26.518467  3315 solver.cpp:218] Iteration 36800 (6.85942 iter/s, 14.5785s/100 iters), loss = 0.262911
I0927 11:48:26.518509  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262911 (* 1 = 0.262911 loss)
I0927 11:48:26.518515  3315 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0927 11:48:41.094331  3315 solver.cpp:218] Iteration 36900 (6.86069 iter/s, 14.5758s/100 iters), loss = 0.244954
I0927 11:48:41.094373  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244953 (* 1 = 0.244953 loss)
I0927 11:48:41.094379  3315 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0927 11:48:54.943907  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:48:55.526793  3315 solver.cpp:330] Iteration 37000, Testing net (#0)
I0927 11:48:58.944373  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:48:59.087465  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7861
I0927 11:48:59.087502  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.652355 (* 1 = 0.652355 loss)
I0927 11:48:59.232245  3315 solver.cpp:218] Iteration 37000 (5.51334 iter/s, 18.1378s/100 iters), loss = 0.283224
I0927 11:48:59.232275  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283224 (* 1 = 0.283224 loss)
I0927 11:48:59.232282  3315 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0927 11:49:13.817508  3315 solver.cpp:218] Iteration 37100 (6.85627 iter/s, 14.5852s/100 iters), loss = 0.315354
I0927 11:49:13.817549  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315353 (* 1 = 0.315353 loss)
I0927 11:49:13.817554  3315 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0927 11:49:28.405694  3315 solver.cpp:218] Iteration 37200 (6.8549 iter/s, 14.5881s/100 iters), loss = 0.319083
I0927 11:49:28.405804  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319083 (* 1 = 0.319083 loss)
I0927 11:49:28.405812  3315 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0927 11:49:42.990610  3315 solver.cpp:218] Iteration 37300 (6.85647 iter/s, 14.5848s/100 iters), loss = 0.365058
I0927 11:49:42.990653  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365058 (* 1 = 0.365058 loss)
I0927 11:49:42.990658  3315 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0927 11:49:57.573496  3315 solver.cpp:218] Iteration 37400 (6.85739 iter/s, 14.5828s/100 iters), loss = 0.299749
I0927 11:49:57.573537  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299749 (* 1 = 0.299749 loss)
I0927 11:49:57.573542  3315 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0927 11:50:11.428850  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:50:12.012511  3315 solver.cpp:330] Iteration 37500, Testing net (#0)
I0927 11:50:15.427327  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:50:15.570111  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7843
I0927 11:50:15.570137  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640722 (* 1 = 0.640722 loss)
I0927 11:50:15.714915  3315 solver.cpp:218] Iteration 37500 (5.51227 iter/s, 18.1413s/100 iters), loss = 0.247222
I0927 11:50:15.714944  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247222 (* 1 = 0.247222 loss)
I0927 11:50:15.714951  3315 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0927 11:50:30.298984  3315 solver.cpp:218] Iteration 37600 (6.85683 iter/s, 14.584s/100 iters), loss = 0.289154
I0927 11:50:30.299023  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289154 (* 1 = 0.289154 loss)
I0927 11:50:30.299029  3315 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0927 11:50:44.882905  3315 solver.cpp:218] Iteration 37700 (6.8569 iter/s, 14.5838s/100 iters), loss = 0.343812
I0927 11:50:44.883007  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343812 (* 1 = 0.343812 loss)
I0927 11:50:44.883014  3315 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0927 11:50:59.472664  3315 solver.cpp:218] Iteration 37800 (6.85419 iter/s, 14.5896s/100 iters), loss = 0.358156
I0927 11:50:59.472704  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358156 (* 1 = 0.358156 loss)
I0927 11:50:59.472710  3315 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0927 11:51:14.065505  3315 solver.cpp:218] Iteration 37900 (6.85271 iter/s, 14.5928s/100 iters), loss = 0.261641
I0927 11:51:14.065546  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26164 (* 1 = 0.26164 loss)
I0927 11:51:14.065552  3315 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0927 11:51:27.926059  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:51:28.510921  3315 solver.cpp:330] Iteration 38000, Testing net (#0)
I0927 11:51:31.930091  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:51:32.073096  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6826
I0927 11:51:32.073133  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09777 (* 1 = 1.09777 loss)
I0927 11:51:32.218093  3315 solver.cpp:218] Iteration 38000 (5.50888 iter/s, 18.1525s/100 iters), loss = 0.265787
I0927 11:51:32.218122  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265786 (* 1 = 0.265786 loss)
I0927 11:51:32.218129  3315 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0927 11:51:46.785801  3315 solver.cpp:218] Iteration 38100 (6.86453 iter/s, 14.5676s/100 iters), loss = 0.343239
I0927 11:51:46.785843  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343238 (* 1 = 0.343238 loss)
I0927 11:51:46.785850  3315 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0927 11:52:01.366246  3315 solver.cpp:218] Iteration 38200 (6.85854 iter/s, 14.5804s/100 iters), loss = 0.338035
I0927 11:52:01.366346  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338034 (* 1 = 0.338034 loss)
I0927 11:52:01.366353  3315 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0927 11:52:15.939399  3315 solver.cpp:218] Iteration 38300 (6.86199 iter/s, 14.573s/100 iters), loss = 0.334302
I0927 11:52:15.939440  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334302 (* 1 = 0.334302 loss)
I0927 11:52:15.939445  3315 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0927 11:52:30.514226  3315 solver.cpp:218] Iteration 38400 (6.86118 iter/s, 14.5747s/100 iters), loss = 0.304369
I0927 11:52:30.514267  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304369 (* 1 = 0.304369 loss)
I0927 11:52:30.514273  3315 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0927 11:52:44.366902  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:52:44.949836  3315 solver.cpp:330] Iteration 38500, Testing net (#0)
I0927 11:52:48.368927  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:52:48.511391  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7755
I0927 11:52:48.511427  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.700189 (* 1 = 0.700189 loss)
I0927 11:52:48.656649  3315 solver.cpp:218] Iteration 38500 (5.51197 iter/s, 18.1423s/100 iters), loss = 0.247513
I0927 11:52:48.656679  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247513 (* 1 = 0.247513 loss)
I0927 11:52:48.656687  3315 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0927 11:53:03.236552  3315 solver.cpp:218] Iteration 38600 (6.85879 iter/s, 14.5798s/100 iters), loss = 0.31745
I0927 11:53:03.236593  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317449 (* 1 = 0.317449 loss)
I0927 11:53:03.236599  3315 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0927 11:53:17.814419  3315 solver.cpp:218] Iteration 38700 (6.85975 iter/s, 14.5778s/100 iters), loss = 0.299501
I0927 11:53:17.814497  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2995 (* 1 = 0.2995 loss)
I0927 11:53:17.814504  3315 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0927 11:53:32.396451  3315 solver.cpp:218] Iteration 38800 (6.85781 iter/s, 14.5819s/100 iters), loss = 0.407626
I0927 11:53:32.396481  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407625 (* 1 = 0.407625 loss)
I0927 11:53:32.396487  3315 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0927 11:53:46.978094  3315 solver.cpp:218] Iteration 38900 (6.85797 iter/s, 14.5816s/100 iters), loss = 0.24713
I0927 11:53:46.978137  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24713 (* 1 = 0.24713 loss)
I0927 11:53:46.978142  3315 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0927 11:54:00.835314  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:54:01.418634  3315 solver.cpp:330] Iteration 39000, Testing net (#0)
I0927 11:54:04.835743  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:54:04.978720  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7881
I0927 11:54:04.978757  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658086 (* 1 = 0.658086 loss)
I0927 11:54:05.123324  3315 solver.cpp:218] Iteration 39000 (5.51112 iter/s, 18.1451s/100 iters), loss = 0.283342
I0927 11:54:05.123354  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283341 (* 1 = 0.283341 loss)
I0927 11:54:05.123361  3315 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0927 11:54:19.700423  3315 solver.cpp:218] Iteration 39100 (6.86011 iter/s, 14.577s/100 iters), loss = 0.321585
I0927 11:54:19.700453  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321584 (* 1 = 0.321584 loss)
I0927 11:54:19.700459  3315 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0927 11:54:34.284677  3315 solver.cpp:218] Iteration 39200 (6.85674 iter/s, 14.5842s/100 iters), loss = 0.252575
I0927 11:54:34.284776  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252574 (* 1 = 0.252574 loss)
I0927 11:54:34.284783  3315 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0927 11:54:48.865169  3315 solver.cpp:218] Iteration 39300 (6.85854 iter/s, 14.5804s/100 iters), loss = 0.366212
I0927 11:54:48.865198  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366212 (* 1 = 0.366212 loss)
I0927 11:54:48.865203  3315 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0927 11:55:03.446725  3315 solver.cpp:218] Iteration 39400 (6.85801 iter/s, 14.5815s/100 iters), loss = 0.244635
I0927 11:55:03.446766  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244634 (* 1 = 0.244634 loss)
I0927 11:55:03.446772  3315 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0927 11:55:17.304513  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:55:17.887555  3315 solver.cpp:330] Iteration 39500, Testing net (#0)
I0927 11:55:21.304581  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:55:21.447731  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7808
I0927 11:55:21.447759  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.674867 (* 1 = 0.674867 loss)
I0927 11:55:21.592581  3315 solver.cpp:218] Iteration 39500 (5.51093 iter/s, 18.1458s/100 iters), loss = 0.255029
I0927 11:55:21.592610  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255029 (* 1 = 0.255029 loss)
I0927 11:55:21.592617  3315 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0927 11:55:36.169965  3315 solver.cpp:218] Iteration 39600 (6.85997 iter/s, 14.5773s/100 iters), loss = 0.382222
I0927 11:55:36.170004  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382222 (* 1 = 0.382222 loss)
I0927 11:55:36.170011  3315 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0927 11:55:50.750748  3315 solver.cpp:218] Iteration 39700 (6.85838 iter/s, 14.5807s/100 iters), loss = 0.265637
I0927 11:55:50.750852  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265637 (* 1 = 0.265637 loss)
I0927 11:55:50.750860  3315 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0927 11:56:05.335909  3315 solver.cpp:218] Iteration 39800 (6.85635 iter/s, 14.585s/100 iters), loss = 0.350156
I0927 11:56:05.335952  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350155 (* 1 = 0.350155 loss)
I0927 11:56:05.335958  3315 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0927 11:56:19.920773  3315 solver.cpp:218] Iteration 39900 (6.85646 iter/s, 14.5848s/100 iters), loss = 0.300584
I0927 11:56:19.920815  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300583 (* 1 = 0.300583 loss)
I0927 11:56:19.920822  3315 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0927 11:56:33.785034  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:56:34.369004  3315 solver.cpp:330] Iteration 40000, Testing net (#0)
I0927 11:56:37.787060  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:56:37.930250  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8242
I0927 11:56:37.930277  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.518955 (* 1 = 0.518955 loss)
I0927 11:56:38.074874  3315 solver.cpp:218] Iteration 40000 (5.50842 iter/s, 18.154s/100 iters), loss = 0.25993
I0927 11:56:38.074904  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25993 (* 1 = 0.25993 loss)
I0927 11:56:38.074909  3315 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0927 11:56:38.074913  3315 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0927 11:56:52.656855  3315 solver.cpp:218] Iteration 40100 (6.85781 iter/s, 14.5819s/100 iters), loss = 0.234066
I0927 11:56:52.656896  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234066 (* 1 = 0.234066 loss)
I0927 11:56:52.656903  3315 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0927 11:57:07.246912  3315 solver.cpp:218] Iteration 40200 (6.85402 iter/s, 14.59s/100 iters), loss = 0.282295
I0927 11:57:07.247037  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282294 (* 1 = 0.282294 loss)
I0927 11:57:07.247054  3315 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0927 11:57:21.830425  3315 solver.cpp:218] Iteration 40300 (6.85713 iter/s, 14.5834s/100 iters), loss = 0.235041
I0927 11:57:21.830466  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23504 (* 1 = 0.23504 loss)
I0927 11:57:21.830472  3315 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0927 11:57:36.411567  3315 solver.cpp:218] Iteration 40400 (6.85821 iter/s, 14.5811s/100 iters), loss = 0.142497
I0927 11:57:36.411608  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142496 (* 1 = 0.142496 loss)
I0927 11:57:36.411614  3315 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0927 11:57:50.267140  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:57:50.851155  3315 solver.cpp:330] Iteration 40500, Testing net (#0)
I0927 11:57:54.267082  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:57:54.409674  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.855
I0927 11:57:54.409711  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426421 (* 1 = 0.426421 loss)
I0927 11:57:54.554867  3315 solver.cpp:218] Iteration 40500 (5.5117 iter/s, 18.1432s/100 iters), loss = 0.107519
I0927 11:57:54.554898  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107519 (* 1 = 0.107519 loss)
I0927 11:57:54.554903  3315 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0927 11:58:09.141275  3315 solver.cpp:218] Iteration 40600 (6.85573 iter/s, 14.5863s/100 iters), loss = 0.192494
I0927 11:58:09.141315  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192494 (* 1 = 0.192494 loss)
I0927 11:58:09.141320  3315 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0927 11:58:23.720638  3315 solver.cpp:218] Iteration 40700 (6.85905 iter/s, 14.5793s/100 iters), loss = 0.189606
I0927 11:58:23.720736  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189605 (* 1 = 0.189605 loss)
I0927 11:58:23.720743  3315 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0927 11:58:38.298867  3315 solver.cpp:218] Iteration 40800 (6.85961 iter/s, 14.5781s/100 iters), loss = 0.252823
I0927 11:58:38.298909  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252823 (* 1 = 0.252823 loss)
I0927 11:58:38.298915  3315 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0927 11:58:52.876163  3315 solver.cpp:218] Iteration 40900 (6.86002 iter/s, 14.5772s/100 iters), loss = 0.162042
I0927 11:58:52.876204  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162041 (* 1 = 0.162041 loss)
I0927 11:58:52.876209  3315 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0927 11:59:06.728518  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:59:07.311925  3315 solver.cpp:330] Iteration 41000, Testing net (#0)
I0927 11:59:10.730168  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 11:59:10.873137  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8826
I0927 11:59:10.873174  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353565 (* 1 = 0.353565 loss)
I0927 11:59:11.017984  3315 solver.cpp:218] Iteration 41000 (5.51215 iter/s, 18.1417s/100 iters), loss = 0.142618
I0927 11:59:11.018015  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142618 (* 1 = 0.142618 loss)
I0927 11:59:11.018023  3315 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0927 11:59:25.598342  3315 solver.cpp:218] Iteration 41100 (6.85857 iter/s, 14.5803s/100 iters), loss = 0.248723
I0927 11:59:25.598384  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248723 (* 1 = 0.248723 loss)
I0927 11:59:25.598390  3315 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0927 11:59:40.186853  3315 solver.cpp:218] Iteration 41200 (6.85475 iter/s, 14.5884s/100 iters), loss = 0.232954
I0927 11:59:40.186990  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232953 (* 1 = 0.232953 loss)
I0927 11:59:40.186997  3315 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0927 11:59:54.769450  3315 solver.cpp:218] Iteration 41300 (6.85757 iter/s, 14.5824s/100 iters), loss = 0.237355
I0927 11:59:54.769482  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237354 (* 1 = 0.237354 loss)
I0927 11:59:54.769487  3315 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0927 12:00:09.347317  3315 solver.cpp:218] Iteration 41400 (6.85975 iter/s, 14.5778s/100 iters), loss = 0.165667
I0927 12:00:09.347357  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165667 (* 1 = 0.165667 loss)
I0927 12:00:09.347363  3315 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0927 12:00:23.202472  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:00:23.786669  3315 solver.cpp:330] Iteration 41500, Testing net (#0)
I0927 12:00:27.202623  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:00:27.345502  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8845
I0927 12:00:27.345541  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338942 (* 1 = 0.338942 loss)
I0927 12:00:27.490218  3315 solver.cpp:218] Iteration 41500 (5.51182 iter/s, 18.1428s/100 iters), loss = 0.113778
I0927 12:00:27.490248  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113778 (* 1 = 0.113778 loss)
I0927 12:00:27.490255  3315 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0927 12:00:42.069011  3315 solver.cpp:218] Iteration 41600 (6.85931 iter/s, 14.5787s/100 iters), loss = 0.186645
I0927 12:00:42.069051  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186645 (* 1 = 0.186645 loss)
I0927 12:00:42.069057  3315 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0927 12:00:56.652163  3315 solver.cpp:218] Iteration 41700 (6.85726 iter/s, 14.5831s/100 iters), loss = 0.148604
I0927 12:00:56.652307  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148604 (* 1 = 0.148604 loss)
I0927 12:00:56.652325  3315 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0927 12:01:11.232230  3315 solver.cpp:218] Iteration 41800 (6.85876 iter/s, 14.5799s/100 iters), loss = 0.209284
I0927 12:01:11.232272  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209283 (* 1 = 0.209283 loss)
I0927 12:01:11.232278  3315 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0927 12:01:25.812244  3315 solver.cpp:218] Iteration 41900 (6.85874 iter/s, 14.5799s/100 iters), loss = 0.157316
I0927 12:01:25.812286  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157316 (* 1 = 0.157316 loss)
I0927 12:01:25.812291  3315 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0927 12:01:39.661211  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:01:40.244657  3315 solver.cpp:330] Iteration 42000, Testing net (#0)
I0927 12:01:43.662145  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:01:43.805312  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8856
I0927 12:01:43.805348  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339421 (* 1 = 0.339421 loss)
I0927 12:01:43.950634  3315 solver.cpp:218] Iteration 42000 (5.5132 iter/s, 18.1383s/100 iters), loss = 0.112928
I0927 12:01:43.950664  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112927 (* 1 = 0.112927 loss)
I0927 12:01:43.950670  3315 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0927 12:01:58.525301  3315 solver.cpp:218] Iteration 42100 (6.86125 iter/s, 14.5746s/100 iters), loss = 0.179817
I0927 12:01:58.525342  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179817 (* 1 = 0.179817 loss)
I0927 12:01:58.525348  3315 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0927 12:02:13.100749  3315 solver.cpp:218] Iteration 42200 (6.86089 iter/s, 14.5754s/100 iters), loss = 0.127307
I0927 12:02:13.100857  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127307 (* 1 = 0.127307 loss)
I0927 12:02:13.100863  3315 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0927 12:02:27.677657  3315 solver.cpp:218] Iteration 42300 (6.86023 iter/s, 14.5768s/100 iters), loss = 0.147486
I0927 12:02:27.677698  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147486 (* 1 = 0.147486 loss)
I0927 12:02:27.677705  3315 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0927 12:02:42.255465  3315 solver.cpp:218] Iteration 42400 (6.85978 iter/s, 14.5777s/100 iters), loss = 0.169222
I0927 12:02:42.255506  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169221 (* 1 = 0.169221 loss)
I0927 12:02:42.255511  3315 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0927 12:02:56.103333  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:02:56.686447  3315 solver.cpp:330] Iteration 42500, Testing net (#0)
I0927 12:03:00.105303  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:03:00.248643  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8807
I0927 12:03:00.248678  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35388 (* 1 = 0.35388 loss)
I0927 12:03:00.393843  3315 solver.cpp:218] Iteration 42500 (5.5132 iter/s, 18.1383s/100 iters), loss = 0.104857
I0927 12:03:00.393873  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104856 (* 1 = 0.104856 loss)
I0927 12:03:00.393880  3315 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0927 12:03:14.961432  3315 solver.cpp:218] Iteration 42600 (6.86459 iter/s, 14.5675s/100 iters), loss = 0.183964
I0927 12:03:14.961462  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183964 (* 1 = 0.183964 loss)
I0927 12:03:14.961468  3315 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0927 12:03:29.546473  3315 solver.cpp:218] Iteration 42700 (6.85637 iter/s, 14.585s/100 iters), loss = 0.150996
I0927 12:03:29.546592  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150996 (* 1 = 0.150996 loss)
I0927 12:03:29.546599  3315 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0927 12:03:44.123430  3315 solver.cpp:218] Iteration 42800 (6.86021 iter/s, 14.5768s/100 iters), loss = 0.126615
I0927 12:03:44.123459  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126614 (* 1 = 0.126614 loss)
I0927 12:03:44.123464  3315 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0927 12:03:58.701648  3315 solver.cpp:218] Iteration 42900 (6.85958 iter/s, 14.5782s/100 iters), loss = 0.116275
I0927 12:03:58.701679  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116275 (* 1 = 0.116275 loss)
I0927 12:03:58.701684  3315 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0927 12:04:12.556841  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:04:13.141592  3315 solver.cpp:330] Iteration 43000, Testing net (#0)
I0927 12:04:16.559695  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:04:16.702617  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8807
I0927 12:04:16.702653  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354647 (* 1 = 0.354647 loss)
I0927 12:04:16.847615  3315 solver.cpp:218] Iteration 43000 (5.51089 iter/s, 18.1459s/100 iters), loss = 0.0995379
I0927 12:04:16.847645  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0995375 (* 1 = 0.0995375 loss)
I0927 12:04:16.847651  3315 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0927 12:04:31.419109  3315 solver.cpp:218] Iteration 43100 (6.86275 iter/s, 14.5714s/100 iters), loss = 0.120572
I0927 12:04:31.419150  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120572 (* 1 = 0.120572 loss)
I0927 12:04:31.419157  3315 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0927 12:04:45.997669  3315 solver.cpp:218] Iteration 43200 (6.85943 iter/s, 14.5785s/100 iters), loss = 0.160851
I0927 12:04:45.997812  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160851 (* 1 = 0.160851 loss)
I0927 12:04:45.997820  3315 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0927 12:05:00.579538  3315 solver.cpp:218] Iteration 43300 (6.85791 iter/s, 14.5817s/100 iters), loss = 0.14093
I0927 12:05:00.579578  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140929 (* 1 = 0.140929 loss)
I0927 12:05:00.579584  3315 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0927 12:05:15.150815  3315 solver.cpp:218] Iteration 43400 (6.86285 iter/s, 14.5712s/100 iters), loss = 0.12117
I0927 12:05:15.150846  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12117 (* 1 = 0.12117 loss)
I0927 12:05:15.150851  3315 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0927 12:05:28.998085  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:05:29.581455  3315 solver.cpp:330] Iteration 43500, Testing net (#0)
I0927 12:05:32.998419  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:05:33.141224  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8855
I0927 12:05:33.141260  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339565 (* 1 = 0.339565 loss)
I0927 12:05:33.286269  3315 solver.cpp:218] Iteration 43500 (5.51408 iter/s, 18.1354s/100 iters), loss = 0.0743365
I0927 12:05:33.286298  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0743362 (* 1 = 0.0743362 loss)
I0927 12:05:33.286304  3315 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0927 12:05:47.856807  3315 solver.cpp:218] Iteration 43600 (6.8632 iter/s, 14.5705s/100 iters), loss = 0.205319
I0927 12:05:47.856837  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205319 (* 1 = 0.205319 loss)
I0927 12:05:47.856843  3315 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0927 12:06:02.435550  3315 solver.cpp:218] Iteration 43700 (6.85933 iter/s, 14.5787s/100 iters), loss = 0.127576
I0927 12:06:02.435631  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127576 (* 1 = 0.127576 loss)
I0927 12:06:02.435639  3315 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0927 12:06:17.011656  3315 solver.cpp:218] Iteration 43800 (6.8606 iter/s, 14.576s/100 iters), loss = 0.175533
I0927 12:06:17.011687  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175533 (* 1 = 0.175533 loss)
I0927 12:06:17.011693  3315 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0927 12:06:31.588541  3315 solver.cpp:218] Iteration 43900 (6.86021 iter/s, 14.5768s/100 iters), loss = 0.105846
I0927 12:06:31.588582  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105846 (* 1 = 0.105846 loss)
I0927 12:06:31.588588  3315 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0927 12:06:45.437877  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:06:46.021975  3315 solver.cpp:330] Iteration 44000, Testing net (#0)
I0927 12:06:49.437837  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:06:49.580324  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8856
I0927 12:06:49.580360  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327042 (* 1 = 0.327042 loss)
I0927 12:06:49.725823  3315 solver.cpp:218] Iteration 44000 (5.51353 iter/s, 18.1372s/100 iters), loss = 0.0684011
I0927 12:06:49.725852  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0684008 (* 1 = 0.0684008 loss)
I0927 12:06:49.725859  3315 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0927 12:07:04.306404  3315 solver.cpp:218] Iteration 44100 (6.85847 iter/s, 14.5805s/100 iters), loss = 0.233077
I0927 12:07:04.306435  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233077 (* 1 = 0.233077 loss)
I0927 12:07:04.306442  3315 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0927 12:07:18.890180  3315 solver.cpp:218] Iteration 44200 (6.85697 iter/s, 14.5837s/100 iters), loss = 0.127018
I0927 12:07:18.890285  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127018 (* 1 = 0.127018 loss)
I0927 12:07:18.890291  3315 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0927 12:07:33.474330  3315 solver.cpp:218] Iteration 44300 (6.85682 iter/s, 14.584s/100 iters), loss = 0.157258
I0927 12:07:33.474359  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157258 (* 1 = 0.157258 loss)
I0927 12:07:33.474365  3315 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0927 12:07:48.062016  3315 solver.cpp:218] Iteration 44400 (6.85513 iter/s, 14.5876s/100 iters), loss = 0.11133
I0927 12:07:48.062057  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11133 (* 1 = 0.11133 loss)
I0927 12:07:48.062063  3315 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0927 12:08:01.921324  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:08:02.504925  3315 solver.cpp:330] Iteration 44500, Testing net (#0)
I0927 12:08:05.922827  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:08:06.066004  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8786
I0927 12:08:06.066040  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352338 (* 1 = 0.352338 loss)
I0927 12:08:06.210701  3315 solver.cpp:218] Iteration 44500 (5.51007 iter/s, 18.1486s/100 iters), loss = 0.051442
I0927 12:08:06.210731  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514417 (* 1 = 0.0514417 loss)
I0927 12:08:06.210737  3315 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0927 12:08:20.786211  3315 solver.cpp:218] Iteration 44600 (6.86086 iter/s, 14.5754s/100 iters), loss = 0.176617
I0927 12:08:20.786242  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176616 (* 1 = 0.176616 loss)
I0927 12:08:20.786247  3315 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0927 12:08:35.362205  3315 solver.cpp:218] Iteration 44700 (6.86063 iter/s, 14.5759s/100 iters), loss = 0.212158
I0927 12:08:35.362356  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212158 (* 1 = 0.212158 loss)
I0927 12:08:35.362365  3315 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0927 12:08:49.940460  3315 solver.cpp:218] Iteration 44800 (6.85961 iter/s, 14.5781s/100 iters), loss = 0.167539
I0927 12:08:49.940500  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167539 (* 1 = 0.167539 loss)
I0927 12:08:49.940505  3315 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0927 12:09:04.519330  3315 solver.cpp:218] Iteration 44900 (6.85928 iter/s, 14.5788s/100 iters), loss = 0.0838793
I0927 12:09:04.519371  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0838789 (* 1 = 0.0838789 loss)
I0927 12:09:04.519377  3315 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0927 12:09:18.370138  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:09:18.953845  3315 solver.cpp:330] Iteration 45000, Testing net (#0)
I0927 12:09:22.372059  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:09:22.515017  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8863
I0927 12:09:22.515053  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331142 (* 1 = 0.331142 loss)
I0927 12:09:22.659679  3315 solver.cpp:218] Iteration 45000 (5.5126 iter/s, 18.1403s/100 iters), loss = 0.161846
I0927 12:09:22.659708  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161846 (* 1 = 0.161846 loss)
I0927 12:09:22.659715  3315 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0927 12:09:37.429898  3315 solver.cpp:218] Iteration 45100 (6.77041 iter/s, 14.7702s/100 iters), loss = 0.148948
I0927 12:09:37.429929  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148948 (* 1 = 0.148948 loss)
I0927 12:09:37.429935  3315 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0927 12:09:52.072422  3315 solver.cpp:218] Iteration 45200 (6.82946 iter/s, 14.6425s/100 iters), loss = 0.102842
I0927 12:09:52.072559  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102841 (* 1 = 0.102841 loss)
I0927 12:09:52.072567  3315 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0927 12:10:07.056012  3315 solver.cpp:218] Iteration 45300 (6.67405 iter/s, 14.9834s/100 iters), loss = 0.15813
I0927 12:10:07.056053  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15813 (* 1 = 0.15813 loss)
I0927 12:10:07.056058  3315 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0927 12:10:21.679752  3315 solver.cpp:218] Iteration 45400 (6.83823 iter/s, 14.6237s/100 iters), loss = 0.146588
I0927 12:10:21.679782  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146588 (* 1 = 0.146588 loss)
I0927 12:10:21.679788  3315 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0927 12:10:35.564520  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:10:36.146355  3315 solver.cpp:330] Iteration 45500, Testing net (#0)
I0927 12:10:39.593751  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:10:39.735235  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8878
I0927 12:10:39.735271  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330158 (* 1 = 0.330158 loss)
I0927 12:10:39.878295  3315 solver.cpp:218] Iteration 45500 (5.49497 iter/s, 18.1985s/100 iters), loss = 0.0704693
I0927 12:10:39.878320  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0704689 (* 1 = 0.0704689 loss)
I0927 12:10:39.878327  3315 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0927 12:10:54.604362  3315 solver.cpp:218] Iteration 45600 (6.79071 iter/s, 14.726s/100 iters), loss = 0.18985
I0927 12:10:54.604398  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18985 (* 1 = 0.18985 loss)
I0927 12:10:54.604405  3315 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0927 12:11:09.333760  3315 solver.cpp:218] Iteration 45700 (6.78918 iter/s, 14.7293s/100 iters), loss = 0.113428
I0927 12:11:09.333943  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113427 (* 1 = 0.113427 loss)
I0927 12:11:09.333952  3315 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0927 12:11:24.004865  3315 solver.cpp:218] Iteration 45800 (6.81621 iter/s, 14.6709s/100 iters), loss = 0.105592
I0927 12:11:24.004895  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105591 (* 1 = 0.105591 loss)
I0927 12:11:24.004901  3315 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0927 12:11:38.688482  3315 solver.cpp:218] Iteration 45900 (6.81034 iter/s, 14.6835s/100 iters), loss = 0.0983587
I0927 12:11:38.688513  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0983583 (* 1 = 0.0983583 loss)
I0927 12:11:38.688519  3315 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0927 12:11:52.610972  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:11:53.195325  3315 solver.cpp:330] Iteration 46000, Testing net (#0)
I0927 12:11:56.609999  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:11:56.753171  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8869
I0927 12:11:56.753206  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330435 (* 1 = 0.330435 loss)
I0927 12:11:56.898530  3315 solver.cpp:218] Iteration 46000 (5.4915 iter/s, 18.21s/100 iters), loss = 0.113292
I0927 12:11:56.898558  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113291 (* 1 = 0.113291 loss)
I0927 12:11:56.898566  3315 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0927 12:12:11.472862  3315 solver.cpp:218] Iteration 46100 (6.86141 iter/s, 14.5743s/100 iters), loss = 0.172842
I0927 12:12:11.472903  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172842 (* 1 = 0.172842 loss)
I0927 12:12:11.472908  3315 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0927 12:12:26.049196  3315 solver.cpp:218] Iteration 46200 (6.86047 iter/s, 14.5763s/100 iters), loss = 0.127987
I0927 12:12:26.049316  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127987 (* 1 = 0.127987 loss)
I0927 12:12:26.049334  3315 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0927 12:12:40.628444  3315 solver.cpp:218] Iteration 46300 (6.85914 iter/s, 14.5791s/100 iters), loss = 0.0993509
I0927 12:12:40.628486  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0993506 (* 1 = 0.0993506 loss)
I0927 12:12:40.628492  3315 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0927 12:12:55.203327  3315 solver.cpp:218] Iteration 46400 (6.86116 iter/s, 14.5748s/100 iters), loss = 0.0928873
I0927 12:12:55.203368  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.092887 (* 1 = 0.092887 loss)
I0927 12:12:55.203374  3315 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0927 12:13:09.052844  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:13:09.636168  3315 solver.cpp:330] Iteration 46500, Testing net (#0)
I0927 12:13:13.053766  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:13:13.196012  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8854
I0927 12:13:13.196048  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338925 (* 1 = 0.338925 loss)
I0927 12:13:13.340668  3315 solver.cpp:218] Iteration 46500 (5.51351 iter/s, 18.1373s/100 iters), loss = 0.0681884
I0927 12:13:13.340698  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0681881 (* 1 = 0.0681881 loss)
I0927 12:13:13.340703  3315 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0927 12:13:27.919307  3315 solver.cpp:218] Iteration 46600 (6.85938 iter/s, 14.5786s/100 iters), loss = 0.182326
I0927 12:13:27.919337  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182325 (* 1 = 0.182325 loss)
I0927 12:13:27.919343  3315 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0927 12:13:42.500931  3315 solver.cpp:218] Iteration 46700 (6.85798 iter/s, 14.5816s/100 iters), loss = 0.12645
I0927 12:13:42.501056  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12645 (* 1 = 0.12645 loss)
I0927 12:13:42.501063  3315 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0927 12:13:57.088632  3315 solver.cpp:218] Iteration 46800 (6.85516 iter/s, 14.5876s/100 iters), loss = 0.146745
I0927 12:13:57.088673  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146745 (* 1 = 0.146745 loss)
I0927 12:13:57.088678  3315 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0927 12:14:11.676967  3315 solver.cpp:218] Iteration 46900 (6.85483 iter/s, 14.5883s/100 iters), loss = 0.0701594
I0927 12:14:11.677009  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0701591 (* 1 = 0.0701591 loss)
I0927 12:14:11.677016  3315 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0927 12:14:25.539979  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:14:26.124539  3315 solver.cpp:330] Iteration 47000, Testing net (#0)
I0927 12:14:29.542852  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:14:29.685917  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8943
I0927 12:14:29.685955  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31733 (* 1 = 0.31733 loss)
I0927 12:14:29.831259  3315 solver.cpp:218] Iteration 47000 (5.50837 iter/s, 18.1542s/100 iters), loss = 0.0592912
I0927 12:14:29.831288  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0592908 (* 1 = 0.0592908 loss)
I0927 12:14:29.831295  3315 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0927 12:14:44.408597  3315 solver.cpp:218] Iteration 47100 (6.85999 iter/s, 14.5773s/100 iters), loss = 0.157338
I0927 12:14:44.408638  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157337 (* 1 = 0.157337 loss)
I0927 12:14:44.408645  3315 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0927 12:14:58.988189  3315 solver.cpp:218] Iteration 47200 (6.85894 iter/s, 14.5795s/100 iters), loss = 0.16059
I0927 12:14:58.988301  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16059 (* 1 = 0.16059 loss)
I0927 12:14:58.988308  3315 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0927 12:15:13.573273  3315 solver.cpp:218] Iteration 47300 (6.85639 iter/s, 14.5849s/100 iters), loss = 0.122818
I0927 12:15:13.573303  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122818 (* 1 = 0.122818 loss)
I0927 12:15:13.573309  3315 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0927 12:15:28.151615  3315 solver.cpp:218] Iteration 47400 (6.85952 iter/s, 14.5783s/100 iters), loss = 0.115154
I0927 12:15:28.151645  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115154 (* 1 = 0.115154 loss)
I0927 12:15:28.151651  3315 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0927 12:15:42.008144  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:15:42.591584  3315 solver.cpp:330] Iteration 47500, Testing net (#0)
I0927 12:15:46.007630  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:15:46.150612  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8887
I0927 12:15:46.150638  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325963 (* 1 = 0.325963 loss)
I0927 12:15:46.295773  3315 solver.cpp:218] Iteration 47500 (5.51144 iter/s, 18.1441s/100 iters), loss = 0.0843395
I0927 12:15:46.295802  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0843392 (* 1 = 0.0843392 loss)
I0927 12:15:46.295809  3315 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0927 12:16:00.873353  3315 solver.cpp:218] Iteration 47600 (6.85988 iter/s, 14.5775s/100 iters), loss = 0.17058
I0927 12:16:00.873394  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17058 (* 1 = 0.17058 loss)
I0927 12:16:00.873399  3315 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0927 12:16:15.461087  3315 solver.cpp:218] Iteration 47700 (6.85511 iter/s, 14.5877s/100 iters), loss = 0.115213
I0927 12:16:15.461192  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115213 (* 1 = 0.115213 loss)
I0927 12:16:15.461210  3315 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0927 12:16:30.046838  3315 solver.cpp:218] Iteration 47800 (6.85607 iter/s, 14.5856s/100 iters), loss = 0.122523
I0927 12:16:30.046866  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122523 (* 1 = 0.122523 loss)
I0927 12:16:30.046872  3315 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0927 12:16:44.633097  3315 solver.cpp:218] Iteration 47900 (6.8558 iter/s, 14.5862s/100 iters), loss = 0.0321252
I0927 12:16:44.633127  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321248 (* 1 = 0.0321248 loss)
I0927 12:16:44.633133  3315 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0927 12:16:58.488260  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:16:59.071696  3315 solver.cpp:330] Iteration 48000, Testing net (#0)
I0927 12:17:02.490586  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:17:02.633741  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8857
I0927 12:17:02.633780  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350249 (* 1 = 0.350249 loss)
I0927 12:17:02.778520  3315 solver.cpp:218] Iteration 48000 (5.51105 iter/s, 18.1453s/100 iters), loss = 0.058849
I0927 12:17:02.778550  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0588486 (* 1 = 0.0588486 loss)
I0927 12:17:02.778558  3315 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0927 12:17:17.360292  3315 solver.cpp:218] Iteration 48100 (6.85791 iter/s, 14.5817s/100 iters), loss = 0.128368
I0927 12:17:17.360332  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128367 (* 1 = 0.128367 loss)
I0927 12:17:17.360338  3315 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0927 12:17:31.953217  3315 solver.cpp:218] Iteration 48200 (6.85267 iter/s, 14.5928s/100 iters), loss = 0.1386
I0927 12:17:31.953331  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1386 (* 1 = 0.1386 loss)
I0927 12:17:31.953346  3315 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0927 12:17:46.542752  3315 solver.cpp:218] Iteration 48300 (6.85429 iter/s, 14.5894s/100 iters), loss = 0.0995856
I0927 12:17:46.542791  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0995853 (* 1 = 0.0995853 loss)
I0927 12:17:46.542798  3315 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0927 12:18:01.128554  3315 solver.cpp:218] Iteration 48400 (6.85602 iter/s, 14.5857s/100 iters), loss = 0.106474
I0927 12:18:01.128595  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106474 (* 1 = 0.106474 loss)
I0927 12:18:01.128602  3315 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0927 12:18:14.992838  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:18:15.576918  3315 solver.cpp:330] Iteration 48500, Testing net (#0)
I0927 12:18:18.995805  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:18:19.138654  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8803
I0927 12:18:19.138690  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359306 (* 1 = 0.359306 loss)
I0927 12:18:19.283855  3315 solver.cpp:218] Iteration 48500 (5.50806 iter/s, 18.1552s/100 iters), loss = 0.0915549
I0927 12:18:19.283885  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0915545 (* 1 = 0.0915545 loss)
I0927 12:18:19.283892  3315 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0927 12:18:33.854630  3315 solver.cpp:218] Iteration 48600 (6.86308 iter/s, 14.5707s/100 iters), loss = 0.149481
I0927 12:18:33.854667  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149481 (* 1 = 0.149481 loss)
I0927 12:18:33.854674  3315 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0927 12:18:48.441185  3315 solver.cpp:218] Iteration 48700 (6.85566 iter/s, 14.5865s/100 iters), loss = 0.140786
I0927 12:18:48.441326  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140785 (* 1 = 0.140785 loss)
I0927 12:18:48.441345  3315 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0927 12:19:03.018239  3315 solver.cpp:218] Iteration 48800 (6.86018 iter/s, 14.5769s/100 iters), loss = 0.123404
I0927 12:19:03.018270  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123403 (* 1 = 0.123403 loss)
I0927 12:19:03.018275  3315 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0927 12:19:17.598542  3315 solver.cpp:218] Iteration 48900 (6.8586 iter/s, 14.5802s/100 iters), loss = 0.053261
I0927 12:19:17.598584  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532606 (* 1 = 0.0532606 loss)
I0927 12:19:17.598590  3315 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0927 12:19:31.453362  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:19:32.036965  3315 solver.cpp:330] Iteration 49000, Testing net (#0)
I0927 12:19:35.453935  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:19:35.597182  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8797
I0927 12:19:35.597218  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376999 (* 1 = 0.376999 loss)
I0927 12:19:35.742472  3315 solver.cpp:218] Iteration 49000 (5.51151 iter/s, 18.1438s/100 iters), loss = 0.0755645
I0927 12:19:35.742502  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.075564 (* 1 = 0.075564 loss)
I0927 12:19:35.742509  3315 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0927 12:19:50.315562  3315 solver.cpp:218] Iteration 49100 (6.86199 iter/s, 14.573s/100 iters), loss = 0.122285
I0927 12:19:50.315593  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122285 (* 1 = 0.122285 loss)
I0927 12:19:50.315598  3315 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0927 12:20:04.892909  3315 solver.cpp:218] Iteration 49200 (6.85999 iter/s, 14.5773s/100 iters), loss = 0.103902
I0927 12:20:04.893002  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103902 (* 1 = 0.103902 loss)
I0927 12:20:04.893009  3315 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0927 12:20:19.470489  3315 solver.cpp:218] Iteration 49300 (6.85991 iter/s, 14.5775s/100 iters), loss = 0.175127
I0927 12:20:19.470521  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175126 (* 1 = 0.175126 loss)
I0927 12:20:19.470528  3315 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0927 12:20:34.048200  3315 solver.cpp:218] Iteration 49400 (6.85982 iter/s, 14.5776s/100 iters), loss = 0.0720495
I0927 12:20:34.048243  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0720491 (* 1 = 0.0720491 loss)
I0927 12:20:34.048249  3315 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0927 12:20:47.902169  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:20:48.485641  3315 solver.cpp:330] Iteration 49500, Testing net (#0)
I0927 12:20:51.903215  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:20:52.046226  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8827
I0927 12:20:52.046252  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358748 (* 1 = 0.358748 loss)
I0927 12:20:52.191764  3315 solver.cpp:218] Iteration 49500 (5.51162 iter/s, 18.1435s/100 iters), loss = 0.0666924
I0927 12:20:52.191792  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666921 (* 1 = 0.0666921 loss)
I0927 12:20:52.191799  3315 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0927 12:21:06.771951  3315 solver.cpp:218] Iteration 49600 (6.85865 iter/s, 14.5801s/100 iters), loss = 0.216127
I0927 12:21:06.771981  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216127 (* 1 = 0.216127 loss)
I0927 12:21:06.771987  3315 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0927 12:21:21.353881  3315 solver.cpp:218] Iteration 49700 (6.85783 iter/s, 14.5819s/100 iters), loss = 0.12434
I0927 12:21:21.354030  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124339 (* 1 = 0.124339 loss)
I0927 12:21:21.354038  3315 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0927 12:21:35.939824  3315 solver.cpp:218] Iteration 49800 (6.856 iter/s, 14.5858s/100 iters), loss = 0.15916
I0927 12:21:35.939865  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159159 (* 1 = 0.159159 loss)
I0927 12:21:35.939872  3315 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0927 12:21:50.524314  3315 solver.cpp:218] Iteration 49900 (6.85663 iter/s, 14.5844s/100 iters), loss = 0.0549019
I0927 12:21:50.524354  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549015 (* 1 = 0.0549015 loss)
I0927 12:21:50.524360  3315 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0927 12:22:04.375771  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:22:04.959025  3315 solver.cpp:330] Iteration 50000, Testing net (#0)
I0927 12:22:08.376713  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:22:08.519785  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8829
I0927 12:22:08.519821  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358017 (* 1 = 0.358017 loss)
I0927 12:22:08.665375  3315 solver.cpp:218] Iteration 50000 (5.51238 iter/s, 18.141s/100 iters), loss = 0.0539709
I0927 12:22:08.665405  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0539705 (* 1 = 0.0539705 loss)
I0927 12:22:08.665410  3315 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0927 12:22:23.238098  3315 solver.cpp:218] Iteration 50100 (6.86217 iter/s, 14.5727s/100 iters), loss = 0.0619632
I0927 12:22:23.238128  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0619628 (* 1 = 0.0619628 loss)
I0927 12:22:23.238134  3315 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0927 12:22:37.810014  3315 solver.cpp:218] Iteration 50200 (6.86255 iter/s, 14.5718s/100 iters), loss = 0.135593
I0927 12:22:37.810101  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135593 (* 1 = 0.135593 loss)
I0927 12:22:37.810108  3315 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0927 12:22:52.382625  3315 solver.cpp:218] Iteration 50300 (6.86225 iter/s, 14.5725s/100 iters), loss = 0.106172
I0927 12:22:52.382656  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106172 (* 1 = 0.106172 loss)
I0927 12:22:52.382663  3315 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0927 12:23:06.965221  3315 solver.cpp:218] Iteration 50400 (6.85752 iter/s, 14.5825s/100 iters), loss = 0.101043
I0927 12:23:06.965261  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101042 (* 1 = 0.101042 loss)
I0927 12:23:06.965267  3315 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0927 12:23:20.823351  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:23:21.407481  3315 solver.cpp:330] Iteration 50500, Testing net (#0)
I0927 12:23:24.825985  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:23:24.969097  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.879
I0927 12:23:24.969135  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363954 (* 1 = 0.363954 loss)
I0927 12:23:25.114430  3315 solver.cpp:218] Iteration 50500 (5.50991 iter/s, 18.1491s/100 iters), loss = 0.0452841
I0927 12:23:25.114460  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452837 (* 1 = 0.0452837 loss)
I0927 12:23:25.114466  3315 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0927 12:23:39.693190  3315 solver.cpp:218] Iteration 50600 (6.85932 iter/s, 14.5787s/100 iters), loss = 0.157397
I0927 12:23:39.693222  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157396 (* 1 = 0.157396 loss)
I0927 12:23:39.693226  3315 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0927 12:23:54.282472  3315 solver.cpp:218] Iteration 50700 (6.85438 iter/s, 14.5892s/100 iters), loss = 0.121881
I0927 12:23:54.282634  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121881 (* 1 = 0.121881 loss)
I0927 12:23:54.282644  3315 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0927 12:24:08.867727  3315 solver.cpp:218] Iteration 50800 (6.85633 iter/s, 14.5851s/100 iters), loss = 0.0829258
I0927 12:24:08.867769  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0829255 (* 1 = 0.0829255 loss)
I0927 12:24:08.867774  3315 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0927 12:24:23.450331  3315 solver.cpp:218] Iteration 50900 (6.85752 iter/s, 14.5825s/100 iters), loss = 0.0860339
I0927 12:24:23.450372  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0860336 (* 1 = 0.0860336 loss)
I0927 12:24:23.450378  3315 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0927 12:24:37.309303  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:24:37.892765  3315 solver.cpp:330] Iteration 51000, Testing net (#0)
I0927 12:24:41.309767  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:24:41.452675  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8857
I0927 12:24:41.452713  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351159 (* 1 = 0.351159 loss)
I0927 12:24:41.598930  3315 solver.cpp:218] Iteration 51000 (5.51009 iter/s, 18.1485s/100 iters), loss = 0.118183
I0927 12:24:41.598959  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118183 (* 1 = 0.118183 loss)
I0927 12:24:41.598966  3315 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0927 12:24:56.169796  3315 solver.cpp:218] Iteration 51100 (6.86304 iter/s, 14.5708s/100 iters), loss = 0.139175
I0927 12:24:56.169837  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139175 (* 1 = 0.139175 loss)
I0927 12:24:56.169842  3315 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0927 12:25:10.743046  3315 solver.cpp:218] Iteration 51200 (6.86192 iter/s, 14.5732s/100 iters), loss = 0.101011
I0927 12:25:10.743185  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10101 (* 1 = 0.10101 loss)
I0927 12:25:10.743191  3315 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0927 12:25:25.322652  3315 solver.cpp:218] Iteration 51300 (6.85898 iter/s, 14.5794s/100 iters), loss = 0.0964253
I0927 12:25:25.322692  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0964249 (* 1 = 0.0964249 loss)
I0927 12:25:25.322700  3315 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0927 12:25:39.895458  3315 solver.cpp:218] Iteration 51400 (6.86213 iter/s, 14.5727s/100 iters), loss = 0.0948433
I0927 12:25:39.895499  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.094843 (* 1 = 0.094843 loss)
I0927 12:25:39.895505  3315 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0927 12:25:53.740725  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:25:54.324654  3315 solver.cpp:330] Iteration 51500, Testing net (#0)
I0927 12:25:57.741734  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:25:57.884721  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8806
I0927 12:25:57.884758  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370518 (* 1 = 0.370518 loss)
I0927 12:25:58.029783  3315 solver.cpp:218] Iteration 51500 (5.51443 iter/s, 18.1342s/100 iters), loss = 0.0860317
I0927 12:25:58.029814  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0860313 (* 1 = 0.0860313 loss)
I0927 12:25:58.029819  3315 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0927 12:26:12.613246  3315 solver.cpp:218] Iteration 51600 (6.85711 iter/s, 14.5834s/100 iters), loss = 0.109691
I0927 12:26:12.613276  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109691 (* 1 = 0.109691 loss)
I0927 12:26:12.613282  3315 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0927 12:26:27.202062  3315 solver.cpp:218] Iteration 51700 (6.8546 iter/s, 14.5887s/100 iters), loss = 0.135592
I0927 12:26:27.202241  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135592 (* 1 = 0.135592 loss)
I0927 12:26:27.202260  3315 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0927 12:26:41.775213  3315 solver.cpp:218] Iteration 51800 (6.86203 iter/s, 14.573s/100 iters), loss = 0.0616656
I0927 12:26:41.775241  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0616652 (* 1 = 0.0616652 loss)
I0927 12:26:41.775248  3315 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0927 12:26:56.350942  3315 solver.cpp:218] Iteration 51900 (6.86075 iter/s, 14.5757s/100 iters), loss = 0.0450566
I0927 12:26:56.350972  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450562 (* 1 = 0.0450562 loss)
I0927 12:26:56.350978  3315 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0927 12:27:10.200846  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:27:10.783527  3315 solver.cpp:330] Iteration 52000, Testing net (#0)
I0927 12:27:14.200001  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:27:14.343178  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8756
I0927 12:27:14.343205  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392825 (* 1 = 0.392825 loss)
I0927 12:27:14.488207  3315 solver.cpp:218] Iteration 52000 (5.51353 iter/s, 18.1372s/100 iters), loss = 0.0763131
I0927 12:27:14.488237  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0763127 (* 1 = 0.0763127 loss)
I0927 12:27:14.488245  3315 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0927 12:27:29.072425  3315 solver.cpp:218] Iteration 52100 (6.85676 iter/s, 14.5841s/100 iters), loss = 0.116037
I0927 12:27:29.072468  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116036 (* 1 = 0.116036 loss)
I0927 12:27:29.072474  3315 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0927 12:27:43.664368  3315 solver.cpp:218] Iteration 52200 (6.85313 iter/s, 14.5919s/100 iters), loss = 0.102068
I0927 12:27:43.664507  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102068 (* 1 = 0.102068 loss)
I0927 12:27:43.664515  3315 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0927 12:27:58.244778  3315 solver.cpp:218] Iteration 52300 (6.8586 iter/s, 14.5802s/100 iters), loss = 0.122186
I0927 12:27:58.244819  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122185 (* 1 = 0.122185 loss)
I0927 12:27:58.244824  3315 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0927 12:28:12.830349  3315 solver.cpp:218] Iteration 52400 (6.85613 iter/s, 14.5855s/100 iters), loss = 0.127658
I0927 12:28:12.830389  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127657 (* 1 = 0.127657 loss)
I0927 12:28:12.830395  3315 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0927 12:28:26.689122  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:28:27.271878  3315 solver.cpp:330] Iteration 52500, Testing net (#0)
I0927 12:28:30.689755  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:28:30.832490  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8782
I0927 12:28:30.832526  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381938 (* 1 = 0.381938 loss)
I0927 12:28:30.977886  3315 solver.cpp:218] Iteration 52500 (5.51042 iter/s, 18.1475s/100 iters), loss = 0.073277
I0927 12:28:30.977916  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732766 (* 1 = 0.0732766 loss)
I0927 12:28:30.977922  3315 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0927 12:28:45.556401  3315 solver.cpp:218] Iteration 52600 (6.85944 iter/s, 14.5784s/100 iters), loss = 0.103502
I0927 12:28:45.556438  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103502 (* 1 = 0.103502 loss)
I0927 12:28:45.556445  3315 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0927 12:29:00.133677  3315 solver.cpp:218] Iteration 52700 (6.86003 iter/s, 14.5772s/100 iters), loss = 0.119984
I0927 12:29:00.133744  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119984 (* 1 = 0.119984 loss)
I0927 12:29:00.133751  3315 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0927 12:29:14.715188  3315 solver.cpp:218] Iteration 52800 (6.85805 iter/s, 14.5814s/100 iters), loss = 0.128729
I0927 12:29:14.715227  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128729 (* 1 = 0.128729 loss)
I0927 12:29:14.715232  3315 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0927 12:29:29.299665  3315 solver.cpp:218] Iteration 52900 (6.85664 iter/s, 14.5844s/100 iters), loss = 0.07297
I0927 12:29:29.299712  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729696 (* 1 = 0.0729696 loss)
I0927 12:29:29.299721  3315 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0927 12:29:43.158677  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:29:43.744335  3315 solver.cpp:330] Iteration 53000, Testing net (#0)
I0927 12:29:47.161408  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:29:47.304105  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8849
I0927 12:29:47.304141  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356737 (* 1 = 0.356737 loss)
I0927 12:29:47.449056  3315 solver.cpp:218] Iteration 53000 (5.50985 iter/s, 18.1493s/100 iters), loss = 0.054465
I0927 12:29:47.449085  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0544646 (* 1 = 0.0544646 loss)
I0927 12:29:47.449091  3315 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0927 12:30:02.030704  3315 solver.cpp:218] Iteration 53100 (6.85797 iter/s, 14.5816s/100 iters), loss = 0.106141
I0927 12:30:02.030733  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106141 (* 1 = 0.106141 loss)
I0927 12:30:02.030740  3315 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0927 12:30:16.614009  3315 solver.cpp:218] Iteration 53200 (6.85719 iter/s, 14.5832s/100 iters), loss = 0.134803
I0927 12:30:16.614133  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134802 (* 1 = 0.134802 loss)
I0927 12:30:16.614141  3315 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0927 12:30:31.198004  3315 solver.cpp:218] Iteration 53300 (6.8569 iter/s, 14.5838s/100 iters), loss = 0.125605
I0927 12:30:31.198043  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125605 (* 1 = 0.125605 loss)
I0927 12:30:31.198050  3315 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0927 12:30:45.776815  3315 solver.cpp:218] Iteration 53400 (6.85931 iter/s, 14.5787s/100 iters), loss = 0.106851
I0927 12:30:45.776857  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106851 (* 1 = 0.106851 loss)
I0927 12:30:45.776863  3315 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0927 12:30:59.639066  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:31:00.224484  3315 solver.cpp:330] Iteration 53500, Testing net (#0)
I0927 12:31:03.639756  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:31:03.782685  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.874
I0927 12:31:03.782711  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.421068 (* 1 = 0.421068 loss)
I0927 12:31:03.927844  3315 solver.cpp:218] Iteration 53500 (5.50936 iter/s, 18.1509s/100 iters), loss = 0.112281
I0927 12:31:03.927872  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11228 (* 1 = 0.11228 loss)
I0927 12:31:03.927880  3315 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0927 12:31:18.509999  3315 solver.cpp:218] Iteration 53600 (6.85773 iter/s, 14.5821s/100 iters), loss = 0.117833
I0927 12:31:18.510040  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117833 (* 1 = 0.117833 loss)
I0927 12:31:18.510046  3315 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0927 12:31:33.094485  3315 solver.cpp:218] Iteration 53700 (6.85664 iter/s, 14.5844s/100 iters), loss = 0.0996705
I0927 12:31:33.094575  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0996701 (* 1 = 0.0996701 loss)
I0927 12:31:33.094591  3315 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0927 12:31:47.678855  3315 solver.cpp:218] Iteration 53800 (6.85671 iter/s, 14.5842s/100 iters), loss = 0.103005
I0927 12:31:47.678895  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103004 (* 1 = 0.103004 loss)
I0927 12:31:47.678901  3315 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0927 12:32:02.265322  3315 solver.cpp:218] Iteration 53900 (6.85571 iter/s, 14.5864s/100 iters), loss = 0.0234284
I0927 12:32:02.265369  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234279 (* 1 = 0.0234279 loss)
I0927 12:32:02.265377  3315 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0927 12:32:16.125015  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:32:16.709188  3315 solver.cpp:330] Iteration 54000, Testing net (#0)
I0927 12:32:20.126668  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:32:20.269618  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8846
I0927 12:32:20.269655  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370149 (* 1 = 0.370149 loss)
I0927 12:32:20.414712  3315 solver.cpp:218] Iteration 54000 (5.50985 iter/s, 18.1493s/100 iters), loss = 0.0615672
I0927 12:32:20.414742  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615667 (* 1 = 0.0615667 loss)
I0927 12:32:20.414749  3315 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0927 12:32:34.993765  3315 solver.cpp:218] Iteration 54100 (6.85919 iter/s, 14.579s/100 iters), loss = 0.0602082
I0927 12:32:34.993795  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602078 (* 1 = 0.0602078 loss)
I0927 12:32:34.993801  3315 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0927 12:32:49.578758  3315 solver.cpp:218] Iteration 54200 (6.8564 iter/s, 14.5849s/100 iters), loss = 0.0704205
I0927 12:32:49.578893  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.07042 (* 1 = 0.07042 loss)
I0927 12:32:49.578902  3315 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0927 12:33:04.158933  3315 solver.cpp:218] Iteration 54300 (6.8587 iter/s, 14.58s/100 iters), loss = 0.107148
I0927 12:33:04.158974  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107148 (* 1 = 0.107148 loss)
I0927 12:33:04.158982  3315 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0927 12:33:18.729405  3315 solver.cpp:218] Iteration 54400 (6.86323 iter/s, 14.5704s/100 iters), loss = 0.0369109
I0927 12:33:18.729436  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369104 (* 1 = 0.0369104 loss)
I0927 12:33:18.729444  3315 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0927 12:33:32.583336  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:33:33.167027  3315 solver.cpp:330] Iteration 54500, Testing net (#0)
I0927 12:33:36.584529  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:33:36.727695  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8722
I0927 12:33:36.727732  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424144 (* 1 = 0.424144 loss)
I0927 12:33:36.872035  3315 solver.cpp:218] Iteration 54500 (5.5119 iter/s, 18.1426s/100 iters), loss = 0.0544009
I0927 12:33:36.872066  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0544004 (* 1 = 0.0544004 loss)
I0927 12:33:36.872071  3315 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0927 12:33:51.447007  3315 solver.cpp:218] Iteration 54600 (6.86111 iter/s, 14.5749s/100 iters), loss = 0.166834
I0927 12:33:51.447048  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166833 (* 1 = 0.166833 loss)
I0927 12:33:51.447054  3315 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0927 12:34:06.021742  3315 solver.cpp:218] Iteration 54700 (6.86122 iter/s, 14.5747s/100 iters), loss = 0.0847445
I0927 12:34:06.021828  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.084744 (* 1 = 0.084744 loss)
I0927 12:34:06.021844  3315 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0927 12:34:20.597878  3315 solver.cpp:218] Iteration 54800 (6.86059 iter/s, 14.576s/100 iters), loss = 0.0627506
I0927 12:34:20.597919  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0627501 (* 1 = 0.0627501 loss)
I0927 12:34:20.597925  3315 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0927 12:34:35.177534  3315 solver.cpp:218] Iteration 54900 (6.85891 iter/s, 14.5796s/100 iters), loss = 0.0809911
I0927 12:34:35.177574  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0809906 (* 1 = 0.0809906 loss)
I0927 12:34:35.177580  3315 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0927 12:34:49.033303  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:34:49.617478  3315 solver.cpp:330] Iteration 55000, Testing net (#0)
I0927 12:34:53.034849  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:34:53.177732  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8771
I0927 12:34:53.177759  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398084 (* 1 = 0.398084 loss)
I0927 12:34:53.323386  3315 solver.cpp:218] Iteration 55000 (5.51093 iter/s, 18.1458s/100 iters), loss = 0.0560311
I0927 12:34:53.323416  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560306 (* 1 = 0.0560306 loss)
I0927 12:34:53.323423  3315 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0927 12:35:07.897277  3315 solver.cpp:218] Iteration 55100 (6.86162 iter/s, 14.5738s/100 iters), loss = 0.124775
I0927 12:35:07.897318  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124774 (* 1 = 0.124774 loss)
I0927 12:35:07.897325  3315 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0927 12:35:22.477509  3315 solver.cpp:218] Iteration 55200 (6.85864 iter/s, 14.5802s/100 iters), loss = 0.116283
I0927 12:35:22.477619  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116283 (* 1 = 0.116283 loss)
I0927 12:35:22.477627  3315 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0927 12:35:37.060784  3315 solver.cpp:218] Iteration 55300 (6.85724 iter/s, 14.5831s/100 iters), loss = 0.0660973
I0927 12:35:37.060824  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660968 (* 1 = 0.0660968 loss)
I0927 12:35:37.060830  3315 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0927 12:35:51.640172  3315 solver.cpp:218] Iteration 55400 (6.85904 iter/s, 14.5793s/100 iters), loss = 0.0393297
I0927 12:35:51.640211  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393292 (* 1 = 0.0393292 loss)
I0927 12:35:51.640218  3315 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0927 12:36:05.498558  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:36:06.082334  3315 solver.cpp:330] Iteration 55500, Testing net (#0)
I0927 12:36:09.500663  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:36:09.643581  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.874
I0927 12:36:09.643618  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412635 (* 1 = 0.412635 loss)
I0927 12:36:09.788779  3315 solver.cpp:218] Iteration 55500 (5.51009 iter/s, 18.1485s/100 iters), loss = 0.0366258
I0927 12:36:09.788808  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366253 (* 1 = 0.0366253 loss)
I0927 12:36:09.788815  3315 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0927 12:36:24.372850  3315 solver.cpp:218] Iteration 55600 (6.85683 iter/s, 14.584s/100 iters), loss = 0.0903228
I0927 12:36:24.372891  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0903223 (* 1 = 0.0903223 loss)
I0927 12:36:24.372897  3315 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0927 12:36:38.952803  3315 solver.cpp:218] Iteration 55700 (6.85877 iter/s, 14.5799s/100 iters), loss = 0.054135
I0927 12:36:38.952908  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541345 (* 1 = 0.0541345 loss)
I0927 12:36:38.952915  3315 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0927 12:36:53.542120  3315 solver.cpp:218] Iteration 55800 (6.8544 iter/s, 14.5892s/100 iters), loss = 0.134039
I0927 12:36:53.542161  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134038 (* 1 = 0.134038 loss)
I0927 12:36:53.542166  3315 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0927 12:37:08.130370  3315 solver.cpp:218] Iteration 55900 (6.85487 iter/s, 14.5882s/100 iters), loss = 0.171986
I0927 12:37:08.130420  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171985 (* 1 = 0.171985 loss)
I0927 12:37:08.130426  3315 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0927 12:37:21.988324  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:37:22.572263  3315 solver.cpp:330] Iteration 56000, Testing net (#0)
I0927 12:37:25.988761  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:37:26.131860  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8893
I0927 12:37:26.131897  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370537 (* 1 = 0.370537 loss)
I0927 12:37:26.277230  3315 solver.cpp:218] Iteration 56000 (5.51062 iter/s, 18.1468s/100 iters), loss = 0.0257531
I0927 12:37:26.277261  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257526 (* 1 = 0.0257526 loss)
I0927 12:37:26.277267  3315 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0927 12:37:40.861650  3315 solver.cpp:218] Iteration 56100 (6.85666 iter/s, 14.5844s/100 iters), loss = 0.0546835
I0927 12:37:40.861681  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054683 (* 1 = 0.054683 loss)
I0927 12:37:40.861696  3315 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0927 12:37:55.448285  3315 solver.cpp:218] Iteration 56200 (6.85562 iter/s, 14.5866s/100 iters), loss = 0.134215
I0927 12:37:55.448421  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134215 (* 1 = 0.134215 loss)
I0927 12:37:55.448428  3315 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0927 12:38:10.026664  3315 solver.cpp:218] Iteration 56300 (6.85955 iter/s, 14.5782s/100 iters), loss = 0.115708
I0927 12:38:10.026703  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115708 (* 1 = 0.115708 loss)
I0927 12:38:10.026710  3315 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0927 12:38:24.603907  3315 solver.cpp:218] Iteration 56400 (6.86004 iter/s, 14.5772s/100 iters), loss = 0.0786301
I0927 12:38:24.603950  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0786296 (* 1 = 0.0786296 loss)
I0927 12:38:24.603955  3315 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0927 12:38:38.452877  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:38:39.036267  3315 solver.cpp:330] Iteration 56500, Testing net (#0)
I0927 12:38:42.452726  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:38:42.596014  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8837
I0927 12:38:42.596050  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381239 (* 1 = 0.381239 loss)
I0927 12:38:42.741791  3315 solver.cpp:218] Iteration 56500 (5.51335 iter/s, 18.1378s/100 iters), loss = 0.0477021
I0927 12:38:42.741821  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477016 (* 1 = 0.0477016 loss)
I0927 12:38:42.741827  3315 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0927 12:38:57.312816  3315 solver.cpp:218] Iteration 56600 (6.86297 iter/s, 14.571s/100 iters), loss = 0.094696
I0927 12:38:57.312857  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0946955 (* 1 = 0.0946955 loss)
I0927 12:38:57.312863  3315 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0927 12:39:11.889888  3315 solver.cpp:218] Iteration 56700 (6.86013 iter/s, 14.577s/100 iters), loss = 0.132942
I0927 12:39:11.890007  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132941 (* 1 = 0.132941 loss)
I0927 12:39:11.890024  3315 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0927 12:39:26.469059  3315 solver.cpp:218] Iteration 56800 (6.85917 iter/s, 14.579s/100 iters), loss = 0.0952633
I0927 12:39:26.469100  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0952628 (* 1 = 0.0952628 loss)
I0927 12:39:26.469106  3315 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0927 12:39:41.043341  3315 solver.cpp:218] Iteration 56900 (6.86144 iter/s, 14.5742s/100 iters), loss = 0.0346093
I0927 12:39:41.043382  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346089 (* 1 = 0.0346089 loss)
I0927 12:39:41.043388  3315 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0927 12:39:54.898547  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:39:55.482527  3315 solver.cpp:330] Iteration 57000, Testing net (#0)
I0927 12:39:58.899922  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:39:59.042775  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8835
I0927 12:39:59.042803  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384516 (* 1 = 0.384516 loss)
I0927 12:39:59.187913  3315 solver.cpp:218] Iteration 57000 (5.51132 iter/s, 18.1445s/100 iters), loss = 0.0739517
I0927 12:39:59.187943  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0739512 (* 1 = 0.0739512 loss)
I0927 12:39:59.187950  3315 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0927 12:40:13.760548  3315 solver.cpp:218] Iteration 57100 (6.86221 iter/s, 14.5726s/100 iters), loss = 0.0538912
I0927 12:40:13.760589  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538907 (* 1 = 0.0538907 loss)
I0927 12:40:13.760596  3315 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0927 12:40:28.335793  3315 solver.cpp:218] Iteration 57200 (6.86099 iter/s, 14.5752s/100 iters), loss = 0.100645
I0927 12:40:28.335873  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100645 (* 1 = 0.100645 loss)
I0927 12:40:28.335889  3315 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0927 12:40:42.913477  3315 solver.cpp:218] Iteration 57300 (6.85986 iter/s, 14.5776s/100 iters), loss = 0.0758752
I0927 12:40:42.913518  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0758747 (* 1 = 0.0758747 loss)
I0927 12:40:42.913524  3315 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0927 12:40:57.490458  3315 solver.cpp:218] Iteration 57400 (6.86017 iter/s, 14.5769s/100 iters), loss = 0.0269088
I0927 12:40:57.490499  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269082 (* 1 = 0.0269082 loss)
I0927 12:40:57.490505  3315 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0927 12:41:11.337049  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:41:11.919944  3315 solver.cpp:330] Iteration 57500, Testing net (#0)
I0927 12:41:15.336774  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:41:15.479445  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8786
I0927 12:41:15.479480  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402579 (* 1 = 0.402579 loss)
I0927 12:41:15.625450  3315 solver.cpp:218] Iteration 57500 (5.51423 iter/s, 18.1349s/100 iters), loss = 0.084866
I0927 12:41:15.625480  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848654 (* 1 = 0.0848654 loss)
I0927 12:41:15.625488  3315 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0927 12:41:30.202453  3315 solver.cpp:218] Iteration 57600 (6.86015 iter/s, 14.5769s/100 iters), loss = 0.176325
I0927 12:41:30.202484  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176325 (* 1 = 0.176325 loss)
I0927 12:41:30.202500  3315 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0927 12:41:44.775944  3315 solver.cpp:218] Iteration 57700 (6.86181 iter/s, 14.5734s/100 iters), loss = 0.100049
I0927 12:41:44.776020  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100048 (* 1 = 0.100048 loss)
I0927 12:41:44.776026  3315 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0927 12:41:59.346702  3315 solver.cpp:218] Iteration 57800 (6.86311 iter/s, 14.5706s/100 iters), loss = 0.0932122
I0927 12:41:59.346732  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0932116 (* 1 = 0.0932116 loss)
I0927 12:41:59.346738  3315 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0927 12:42:13.928601  3315 solver.cpp:218] Iteration 57900 (6.85785 iter/s, 14.5818s/100 iters), loss = 0.0587312
I0927 12:42:13.928632  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0587307 (* 1 = 0.0587307 loss)
I0927 12:42:13.928647  3315 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0927 12:42:27.788528  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:42:28.372859  3315 solver.cpp:330] Iteration 58000, Testing net (#0)
I0927 12:42:31.789512  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:42:31.932523  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8851
I0927 12:42:31.932559  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372323 (* 1 = 0.372323 loss)
I0927 12:42:32.077739  3315 solver.cpp:218] Iteration 58000 (5.50993 iter/s, 18.1491s/100 iters), loss = 0.0614987
I0927 12:42:32.077767  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0614981 (* 1 = 0.0614981 loss)
I0927 12:42:32.077775  3315 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0927 12:42:46.655930  3315 solver.cpp:218] Iteration 58100 (6.85959 iter/s, 14.5781s/100 iters), loss = 0.0931034
I0927 12:42:46.655961  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0931029 (* 1 = 0.0931029 loss)
I0927 12:42:46.655977  3315 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0927 12:43:01.232837  3315 solver.cpp:218] Iteration 58200 (6.8602 iter/s, 14.5768s/100 iters), loss = 0.0556658
I0927 12:43:01.232925  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556652 (* 1 = 0.0556652 loss)
I0927 12:43:01.232942  3315 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0927 12:43:15.814028  3315 solver.cpp:218] Iteration 58300 (6.85821 iter/s, 14.5811s/100 iters), loss = 0.052083
I0927 12:43:15.814056  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0520824 (* 1 = 0.0520824 loss)
I0927 12:43:15.814072  3315 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0927 12:43:30.396252  3315 solver.cpp:218] Iteration 58400 (6.8577 iter/s, 14.5822s/100 iters), loss = 0.0756097
I0927 12:43:30.396283  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756091 (* 1 = 0.0756091 loss)
I0927 12:43:30.396299  3315 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0927 12:43:44.252701  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:43:44.835896  3315 solver.cpp:330] Iteration 58500, Testing net (#0)
I0927 12:43:48.252818  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:43:48.396001  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.885
I0927 12:43:48.396039  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.39216 (* 1 = 0.39216 loss)
I0927 12:43:48.540702  3315 solver.cpp:218] Iteration 58500 (5.51135 iter/s, 18.1444s/100 iters), loss = 0.0550486
I0927 12:43:48.540732  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055048 (* 1 = 0.055048 loss)
I0927 12:43:48.540738  3315 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0927 12:44:03.125628  3315 solver.cpp:218] Iteration 58600 (6.85643 iter/s, 14.5849s/100 iters), loss = 0.0807141
I0927 12:44:03.125658  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0807135 (* 1 = 0.0807135 loss)
I0927 12:44:03.125674  3315 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0927 12:44:17.712299  3315 solver.cpp:218] Iteration 58700 (6.85561 iter/s, 14.5866s/100 iters), loss = 0.0536695
I0927 12:44:17.712415  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536689 (* 1 = 0.0536689 loss)
I0927 12:44:17.712433  3315 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0927 12:44:32.298651  3315 solver.cpp:218] Iteration 58800 (6.8558 iter/s, 14.5862s/100 iters), loss = 0.0999671
I0927 12:44:32.298683  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0999665 (* 1 = 0.0999665 loss)
I0927 12:44:32.298698  3315 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0927 12:44:46.884878  3315 solver.cpp:218] Iteration 58900 (6.85582 iter/s, 14.5862s/100 iters), loss = 0.0733762
I0927 12:44:46.884909  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0733756 (* 1 = 0.0733756 loss)
I0927 12:44:46.884925  3315 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0927 12:45:00.747207  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:45:01.329982  3315 solver.cpp:330] Iteration 59000, Testing net (#0)
I0927 12:45:04.748330  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:45:04.891460  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8775
I0927 12:45:04.891487  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413916 (* 1 = 0.413916 loss)
I0927 12:45:05.036685  3315 solver.cpp:218] Iteration 59000 (5.50912 iter/s, 18.1517s/100 iters), loss = 0.0596546
I0927 12:45:05.036716  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0596541 (* 1 = 0.0596541 loss)
I0927 12:45:05.036722  3315 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0927 12:45:19.606137  3315 solver.cpp:218] Iteration 59100 (6.86371 iter/s, 14.5694s/100 iters), loss = 0.0613627
I0927 12:45:19.606178  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0613621 (* 1 = 0.0613621 loss)
I0927 12:45:19.606184  3315 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0927 12:45:34.177415  3315 solver.cpp:218] Iteration 59200 (6.86285 iter/s, 14.5712s/100 iters), loss = 0.0800661
I0927 12:45:34.177489  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0800656 (* 1 = 0.0800656 loss)
I0927 12:45:34.177496  3315 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0927 12:45:48.753254  3315 solver.cpp:218] Iteration 59300 (6.86072 iter/s, 14.5757s/100 iters), loss = 0.0707922
I0927 12:45:48.753296  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0707917 (* 1 = 0.0707917 loss)
I0927 12:45:48.753301  3315 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0927 12:46:03.333355  3315 solver.cpp:218] Iteration 59400 (6.8587 iter/s, 14.58s/100 iters), loss = 0.101697
I0927 12:46:03.333397  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101696 (* 1 = 0.101696 loss)
I0927 12:46:03.333403  3315 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0927 12:46:17.187343  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:46:17.771224  3315 solver.cpp:330] Iteration 59500, Testing net (#0)
I0927 12:46:21.189640  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:46:21.332839  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8798
I0927 12:46:21.332876  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404825 (* 1 = 0.404825 loss)
I0927 12:46:21.477507  3315 solver.cpp:218] Iteration 59500 (5.51144 iter/s, 18.1441s/100 iters), loss = 0.0647798
I0927 12:46:21.477537  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647793 (* 1 = 0.0647793 loss)
I0927 12:46:21.477543  3315 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0927 12:46:36.052551  3315 solver.cpp:218] Iteration 59600 (6.86107 iter/s, 14.575s/100 iters), loss = 0.0990195
I0927 12:46:36.052579  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0990189 (* 1 = 0.0990189 loss)
I0927 12:46:36.052585  3315 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0927 12:46:50.631024  3315 solver.cpp:218] Iteration 59700 (6.85946 iter/s, 14.5784s/100 iters), loss = 0.0784815
I0927 12:46:50.631104  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0784809 (* 1 = 0.0784809 loss)
I0927 12:46:50.631111  3315 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0927 12:47:05.211243  3315 solver.cpp:218] Iteration 59800 (6.85866 iter/s, 14.5801s/100 iters), loss = 0.0832395
I0927 12:47:05.211284  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.083239 (* 1 = 0.083239 loss)
I0927 12:47:05.211290  3315 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0927 12:47:19.788187  3315 solver.cpp:218] Iteration 59900 (6.86019 iter/s, 14.5769s/100 iters), loss = 0.0575099
I0927 12:47:19.788228  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575093 (* 1 = 0.0575093 loss)
I0927 12:47:19.788233  3315 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0927 12:47:33.638895  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:47:34.222383  3315 solver.cpp:330] Iteration 60000, Testing net (#0)
I0927 12:47:37.639842  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:47:37.782690  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8779
I0927 12:47:37.782727  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42601 (* 1 = 0.42601 loss)
I0927 12:47:37.927901  3315 solver.cpp:218] Iteration 60000 (5.51279 iter/s, 18.1396s/100 iters), loss = 0.0319878
I0927 12:47:37.927930  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319872 (* 1 = 0.0319872 loss)
I0927 12:47:37.927937  3315 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0927 12:47:52.511139  3315 solver.cpp:218] Iteration 60100 (6.85722 iter/s, 14.5832s/100 iters), loss = 0.094417
I0927 12:47:52.511180  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0944165 (* 1 = 0.0944165 loss)
I0927 12:47:52.511186  3315 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0927 12:48:07.097470  3315 solver.cpp:218] Iteration 60200 (6.85577 iter/s, 14.5863s/100 iters), loss = 0.0535039
I0927 12:48:07.097611  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535034 (* 1 = 0.0535034 loss)
I0927 12:48:07.097618  3315 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0927 12:48:21.683429  3315 solver.cpp:218] Iteration 60300 (6.85599 iter/s, 14.5858s/100 iters), loss = 0.0933792
I0927 12:48:21.683470  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0933786 (* 1 = 0.0933786 loss)
I0927 12:48:21.683476  3315 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0927 12:48:36.269620  3315 solver.cpp:218] Iteration 60400 (6.85584 iter/s, 14.5861s/100 iters), loss = 0.0914892
I0927 12:48:36.269661  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914886 (* 1 = 0.0914886 loss)
I0927 12:48:36.269666  3315 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0927 12:48:50.127406  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:48:50.711771  3315 solver.cpp:330] Iteration 60500, Testing net (#0)
I0927 12:48:54.127960  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:48:54.270983  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8757
I0927 12:48:54.271020  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.439046 (* 1 = 0.439046 loss)
I0927 12:48:54.416893  3315 solver.cpp:218] Iteration 60500 (5.5105 iter/s, 18.1472s/100 iters), loss = 0.0344259
I0927 12:48:54.416923  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344254 (* 1 = 0.0344254 loss)
I0927 12:48:54.416929  3315 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0927 12:49:08.995966  3315 solver.cpp:218] Iteration 60600 (6.85918 iter/s, 14.579s/100 iters), loss = 0.0347787
I0927 12:49:08.996007  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347782 (* 1 = 0.0347782 loss)
I0927 12:49:08.996013  3315 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0927 12:49:23.578265  3315 solver.cpp:218] Iteration 60700 (6.85767 iter/s, 14.5822s/100 iters), loss = 0.0912394
I0927 12:49:23.578339  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0912388 (* 1 = 0.0912388 loss)
I0927 12:49:23.578346  3315 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0927 12:49:38.155858  3315 solver.cpp:218] Iteration 60800 (6.8599 iter/s, 14.5775s/100 iters), loss = 0.0976443
I0927 12:49:38.155900  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0976438 (* 1 = 0.0976438 loss)
I0927 12:49:38.155905  3315 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0927 12:49:52.735698  3315 solver.cpp:218] Iteration 60900 (6.85882 iter/s, 14.5798s/100 iters), loss = 0.0338386
I0927 12:49:52.735739  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033838 (* 1 = 0.033838 loss)
I0927 12:49:52.735745  3315 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0927 12:50:06.597553  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:50:07.182453  3315 solver.cpp:330] Iteration 61000, Testing net (#0)
I0927 12:50:10.599021  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:50:10.741801  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8818
I0927 12:50:10.741837  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403018 (* 1 = 0.403018 loss)
I0927 12:50:10.887045  3315 solver.cpp:218] Iteration 61000 (5.50926 iter/s, 18.1513s/100 iters), loss = 0.0501214
I0927 12:50:10.887076  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0501209 (* 1 = 0.0501209 loss)
I0927 12:50:10.887084  3315 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0927 12:50:25.458319  3315 solver.cpp:218] Iteration 61100 (6.86285 iter/s, 14.5712s/100 iters), loss = 0.0921876
I0927 12:50:25.458349  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0921871 (* 1 = 0.0921871 loss)
I0927 12:50:25.458365  3315 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0927 12:50:40.034198  3315 solver.cpp:218] Iteration 61200 (6.86068 iter/s, 14.5758s/100 iters), loss = 0.0451854
I0927 12:50:40.034291  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451849 (* 1 = 0.0451849 loss)
I0927 12:50:40.034307  3315 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0927 12:50:54.612929  3315 solver.cpp:218] Iteration 61300 (6.85936 iter/s, 14.5786s/100 iters), loss = 0.0443688
I0927 12:50:54.612962  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443683 (* 1 = 0.0443683 loss)
I0927 12:50:54.612977  3315 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0927 12:51:09.187127  3315 solver.cpp:218] Iteration 61400 (6.86147 iter/s, 14.5741s/100 iters), loss = 0.102607
I0927 12:51:09.187158  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102606 (* 1 = 0.102606 loss)
I0927 12:51:09.187165  3315 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0927 12:51:23.040992  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:51:23.623281  3315 solver.cpp:330] Iteration 61500, Testing net (#0)
I0927 12:51:27.040689  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:51:27.183529  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8884
I0927 12:51:27.183568  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38413 (* 1 = 0.38413 loss)
I0927 12:51:27.328244  3315 solver.cpp:218] Iteration 61500 (5.51236 iter/s, 18.141s/100 iters), loss = 0.0808792
I0927 12:51:27.328274  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0808787 (* 1 = 0.0808787 loss)
I0927 12:51:27.328281  3315 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0927 12:51:41.894870  3315 solver.cpp:218] Iteration 61600 (6.86504 iter/s, 14.5666s/100 iters), loss = 0.0759299
I0927 12:51:41.894901  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0759294 (* 1 = 0.0759294 loss)
I0927 12:51:41.894907  3315 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0927 12:51:56.468173  3315 solver.cpp:218] Iteration 61700 (6.86189 iter/s, 14.5732s/100 iters), loss = 0.0682101
I0927 12:51:56.468317  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682097 (* 1 = 0.0682097 loss)
I0927 12:51:56.468325  3315 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0927 12:52:11.041103  3315 solver.cpp:218] Iteration 61800 (6.86212 iter/s, 14.5728s/100 iters), loss = 0.0890506
I0927 12:52:11.041133  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0890502 (* 1 = 0.0890502 loss)
I0927 12:52:11.041138  3315 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0927 12:52:25.611337  3315 solver.cpp:218] Iteration 61900 (6.86334 iter/s, 14.5702s/100 iters), loss = 0.0416068
I0927 12:52:25.611368  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416064 (* 1 = 0.0416064 loss)
I0927 12:52:25.611374  3315 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0927 12:52:39.458277  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:52:40.041224  3315 solver.cpp:330] Iteration 62000, Testing net (#0)
I0927 12:52:43.458433  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:52:43.601351  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8822
I0927 12:52:43.601387  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.400321 (* 1 = 0.400321 loss)
I0927 12:52:43.746933  3315 solver.cpp:218] Iteration 62000 (5.51404 iter/s, 18.1355s/100 iters), loss = 0.0576965
I0927 12:52:43.746961  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057696 (* 1 = 0.057696 loss)
I0927 12:52:43.746968  3315 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0927 12:52:58.311640  3315 solver.cpp:218] Iteration 62100 (6.86594 iter/s, 14.5646s/100 iters), loss = 0.153803
I0927 12:52:58.311681  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153802 (* 1 = 0.153802 loss)
I0927 12:52:58.311686  3315 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0927 12:53:12.880539  3315 solver.cpp:218] Iteration 62200 (6.86397 iter/s, 14.5688s/100 iters), loss = 0.0667128
I0927 12:53:12.880677  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0667123 (* 1 = 0.0667123 loss)
I0927 12:53:12.880684  3315 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0927 12:53:27.453258  3315 solver.cpp:218] Iteration 62300 (6.86222 iter/s, 14.5725s/100 iters), loss = 0.0284181
I0927 12:53:27.453289  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284176 (* 1 = 0.0284176 loss)
I0927 12:53:27.453296  3315 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0927 12:53:42.025753  3315 solver.cpp:218] Iteration 62400 (6.86228 iter/s, 14.5724s/100 iters), loss = 0.0848293
I0927 12:53:42.025782  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848288 (* 1 = 0.0848288 loss)
I0927 12:53:42.025789  3315 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0927 12:53:55.873929  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:53:56.458014  3315 solver.cpp:330] Iteration 62500, Testing net (#0)
I0927 12:53:59.873180  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:54:00.016026  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8751
I0927 12:54:00.016063  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.441183 (* 1 = 0.441183 loss)
I0927 12:54:00.161396  3315 solver.cpp:218] Iteration 62500 (5.51403 iter/s, 18.1356s/100 iters), loss = 0.0498115
I0927 12:54:00.161425  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049811 (* 1 = 0.049811 loss)
I0927 12:54:00.161432  3315 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0927 12:54:14.742200  3315 solver.cpp:218] Iteration 62600 (6.85836 iter/s, 14.5807s/100 iters), loss = 0.102517
I0927 12:54:14.742231  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102517 (* 1 = 0.102517 loss)
I0927 12:54:14.742238  3315 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0927 12:54:29.328680  3315 solver.cpp:218] Iteration 62700 (6.8557 iter/s, 14.5864s/100 iters), loss = 0.0815289
I0927 12:54:29.328806  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0815283 (* 1 = 0.0815283 loss)
I0927 12:54:29.328824  3315 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0927 12:54:43.915088  3315 solver.cpp:218] Iteration 62800 (6.85577 iter/s, 14.5862s/100 iters), loss = 0.0587879
I0927 12:54:43.915129  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0587874 (* 1 = 0.0587874 loss)
I0927 12:54:43.915135  3315 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0927 12:54:58.499122  3315 solver.cpp:218] Iteration 62900 (6.85685 iter/s, 14.584s/100 iters), loss = 0.0604978
I0927 12:54:58.499162  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604973 (* 1 = 0.0604973 loss)
I0927 12:54:58.499168  3315 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0927 12:55:12.364002  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:55:12.947721  3315 solver.cpp:330] Iteration 63000, Testing net (#0)
I0927 12:55:16.364630  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:55:16.507889  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8872
I0927 12:55:16.507928  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384511 (* 1 = 0.384511 loss)
I0927 12:55:16.653475  3315 solver.cpp:218] Iteration 63000 (5.50835 iter/s, 18.1543s/100 iters), loss = 0.0273158
I0927 12:55:16.653506  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273154 (* 1 = 0.0273154 loss)
I0927 12:55:16.653513  3315 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0927 12:55:31.229192  3315 solver.cpp:218] Iteration 63100 (6.86076 iter/s, 14.5756s/100 iters), loss = 0.0316571
I0927 12:55:31.229223  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316566 (* 1 = 0.0316566 loss)
I0927 12:55:31.229228  3315 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0927 12:55:45.806897  3315 solver.cpp:218] Iteration 63200 (6.85982 iter/s, 14.5776s/100 iters), loss = 0.0457959
I0927 12:55:45.807026  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457954 (* 1 = 0.0457954 loss)
I0927 12:55:45.807034  3315 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0927 12:56:00.388231  3315 solver.cpp:218] Iteration 63300 (6.85816 iter/s, 14.5812s/100 iters), loss = 0.0711555
I0927 12:56:00.388259  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.071155 (* 1 = 0.071155 loss)
I0927 12:56:00.388265  3315 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0927 12:56:14.973197  3315 solver.cpp:218] Iteration 63400 (6.85641 iter/s, 14.5849s/100 iters), loss = 0.0475607
I0927 12:56:14.973227  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0475602 (* 1 = 0.0475602 loss)
I0927 12:56:14.973233  3315 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0927 12:56:28.835528  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:56:29.419376  3315 solver.cpp:330] Iteration 63500, Testing net (#0)
I0927 12:56:32.836212  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:56:32.979233  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.874
I0927 12:56:32.979269  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.450312 (* 1 = 0.450312 loss)
I0927 12:56:33.124459  3315 solver.cpp:218] Iteration 63500 (5.50928 iter/s, 18.1512s/100 iters), loss = 0.0711676
I0927 12:56:33.124487  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0711671 (* 1 = 0.0711671 loss)
I0927 12:56:33.124495  3315 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0927 12:56:47.709095  3315 solver.cpp:218] Iteration 63600 (6.85656 iter/s, 14.5846s/100 iters), loss = 0.063626
I0927 12:56:47.709136  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0636255 (* 1 = 0.0636255 loss)
I0927 12:56:47.709142  3315 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0927 12:57:02.298254  3315 solver.cpp:218] Iteration 63700 (6.85444 iter/s, 14.5891s/100 iters), loss = 0.049243
I0927 12:57:02.298318  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0492425 (* 1 = 0.0492425 loss)
I0927 12:57:02.298326  3315 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0927 12:57:16.889118  3315 solver.cpp:218] Iteration 63800 (6.85365 iter/s, 14.5908s/100 iters), loss = 0.0499332
I0927 12:57:16.889147  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499326 (* 1 = 0.0499326 loss)
I0927 12:57:16.889153  3315 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0927 12:57:31.480309  3315 solver.cpp:218] Iteration 63900 (6.85348 iter/s, 14.5911s/100 iters), loss = 0.0309877
I0927 12:57:31.480350  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309872 (* 1 = 0.0309872 loss)
I0927 12:57:31.480355  3315 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0927 12:57:45.341965  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:57:45.925506  3315 solver.cpp:330] Iteration 64000, Testing net (#0)
I0927 12:57:49.342530  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:57:49.485550  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8813
I0927 12:57:49.485587  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409037 (* 1 = 0.409037 loss)
I0927 12:57:49.630249  3315 solver.cpp:218] Iteration 64000 (5.50969 iter/s, 18.1499s/100 iters), loss = 0.0618458
I0927 12:57:49.630277  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618453 (* 1 = 0.0618453 loss)
I0927 12:57:49.630285  3315 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0927 12:58:04.204794  3315 solver.cpp:218] Iteration 64100 (6.86131 iter/s, 14.5745s/100 iters), loss = 0.116108
I0927 12:58:04.204836  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116108 (* 1 = 0.116108 loss)
I0927 12:58:04.204841  3315 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0927 12:58:18.776809  3315 solver.cpp:218] Iteration 64200 (6.86251 iter/s, 14.5719s/100 iters), loss = 0.0560072
I0927 12:58:18.776926  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560068 (* 1 = 0.0560068 loss)
I0927 12:58:18.776932  3315 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0927 12:58:33.348801  3315 solver.cpp:218] Iteration 64300 (6.86255 iter/s, 14.5718s/100 iters), loss = 0.0451601
I0927 12:58:33.348842  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451596 (* 1 = 0.0451596 loss)
I0927 12:58:33.348848  3315 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0927 12:58:47.913055  3315 solver.cpp:218] Iteration 64400 (6.86616 iter/s, 14.5642s/100 iters), loss = 0.0860362
I0927 12:58:47.913085  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0860358 (* 1 = 0.0860358 loss)
I0927 12:58:47.913091  3315 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0927 12:59:01.763167  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:59:02.346714  3315 solver.cpp:330] Iteration 64500, Testing net (#0)
I0927 12:59:05.761824  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 12:59:05.905081  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8886
I0927 12:59:05.905107  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368848 (* 1 = 0.368848 loss)
I0927 12:59:06.049612  3315 solver.cpp:218] Iteration 64500 (5.51375 iter/s, 18.1365s/100 iters), loss = 0.0392444
I0927 12:59:06.049641  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039244 (* 1 = 0.039244 loss)
I0927 12:59:06.049649  3315 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0927 12:59:20.616753  3315 solver.cpp:218] Iteration 64600 (6.8648 iter/s, 14.5671s/100 iters), loss = 0.0949196
I0927 12:59:20.616793  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0949192 (* 1 = 0.0949192 loss)
I0927 12:59:20.616799  3315 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0927 12:59:35.188804  3315 solver.cpp:218] Iteration 64700 (6.86249 iter/s, 14.572s/100 iters), loss = 0.0270442
I0927 12:59:35.188935  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270438 (* 1 = 0.0270438 loss)
I0927 12:59:35.188943  3315 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0927 12:59:49.761327  3315 solver.cpp:218] Iteration 64800 (6.8623 iter/s, 14.5724s/100 iters), loss = 0.0616895
I0927 12:59:49.761368  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0616891 (* 1 = 0.0616891 loss)
I0927 12:59:49.761374  3315 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0927 13:00:04.336168  3315 solver.cpp:218] Iteration 64900 (6.86118 iter/s, 14.5748s/100 iters), loss = 0.0245303
I0927 13:00:04.336197  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245298 (* 1 = 0.0245298 loss)
I0927 13:00:04.336203  3315 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0927 13:00:18.191692  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:00:18.775233  3315 solver.cpp:330] Iteration 65000, Testing net (#0)
I0927 13:00:22.191956  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:00:22.334759  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8777
I0927 13:00:22.334796  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42968 (* 1 = 0.42968 loss)
I0927 13:00:22.480459  3315 solver.cpp:218] Iteration 65000 (5.5114 iter/s, 18.1442s/100 iters), loss = 0.0604843
I0927 13:00:22.480489  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604839 (* 1 = 0.0604839 loss)
I0927 13:00:22.480494  3315 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0927 13:00:37.049990  3315 solver.cpp:218] Iteration 65100 (6.86367 iter/s, 14.5695s/100 iters), loss = 0.0328122
I0927 13:00:37.050020  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328118 (* 1 = 0.0328118 loss)
I0927 13:00:37.050026  3315 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0927 13:00:51.623142  3315 solver.cpp:218] Iteration 65200 (6.86197 iter/s, 14.5731s/100 iters), loss = 0.0813581
I0927 13:00:51.623301  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0813577 (* 1 = 0.0813577 loss)
I0927 13:00:51.623308  3315 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0927 13:01:06.196637  3315 solver.cpp:218] Iteration 65300 (6.86186 iter/s, 14.5733s/100 iters), loss = 0.10584
I0927 13:01:06.196666  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105839 (* 1 = 0.105839 loss)
I0927 13:01:06.196682  3315 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0927 13:01:20.774860  3315 solver.cpp:218] Iteration 65400 (6.85958 iter/s, 14.5782s/100 iters), loss = 0.0250231
I0927 13:01:20.774890  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250227 (* 1 = 0.0250227 loss)
I0927 13:01:20.774896  3315 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0927 13:01:34.627476  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:01:35.209767  3315 solver.cpp:330] Iteration 65500, Testing net (#0)
I0927 13:01:38.627593  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:01:38.770570  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8737
I0927 13:01:38.770607  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.440104 (* 1 = 0.440104 loss)
I0927 13:01:38.915762  3315 solver.cpp:218] Iteration 65500 (5.51243 iter/s, 18.1408s/100 iters), loss = 0.0441585
I0927 13:01:38.915791  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044158 (* 1 = 0.044158 loss)
I0927 13:01:38.915798  3315 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0927 13:01:53.493448  3315 solver.cpp:218] Iteration 65600 (6.85983 iter/s, 14.5776s/100 iters), loss = 0.0889453
I0927 13:01:53.493479  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0889449 (* 1 = 0.0889449 loss)
I0927 13:01:53.493485  3315 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0927 13:02:08.076318  3315 solver.cpp:218] Iteration 65700 (6.85739 iter/s, 14.5828s/100 iters), loss = 0.0516601
I0927 13:02:08.076416  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516597 (* 1 = 0.0516597 loss)
I0927 13:02:08.076432  3315 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0927 13:02:22.661751  3315 solver.cpp:218] Iteration 65800 (6.85621 iter/s, 14.5853s/100 iters), loss = 0.0411599
I0927 13:02:22.661782  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411595 (* 1 = 0.0411595 loss)
I0927 13:02:22.661788  3315 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0927 13:02:37.240023  3315 solver.cpp:218] Iteration 65900 (6.85956 iter/s, 14.5782s/100 iters), loss = 0.0365634
I0927 13:02:37.240063  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036563 (* 1 = 0.036563 loss)
I0927 13:02:37.240069  3315 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0927 13:02:51.102694  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:02:51.685825  3315 solver.cpp:330] Iteration 66000, Testing net (#0)
I0927 13:02:55.101760  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:02:55.244624  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8795
I0927 13:02:55.244659  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424059 (* 1 = 0.424059 loss)
I0927 13:02:55.389814  3315 solver.cpp:218] Iteration 66000 (5.50973 iter/s, 18.1497s/100 iters), loss = 0.0425899
I0927 13:02:55.389844  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425895 (* 1 = 0.0425895 loss)
I0927 13:02:55.389852  3315 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0927 13:03:09.957885  3315 solver.cpp:218] Iteration 66100 (6.86436 iter/s, 14.568s/100 iters), loss = 0.108635
I0927 13:03:09.957926  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108635 (* 1 = 0.108635 loss)
I0927 13:03:09.957932  3315 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0927 13:03:24.535158  3315 solver.cpp:218] Iteration 66200 (6.86003 iter/s, 14.5772s/100 iters), loss = 0.0661764
I0927 13:03:24.535336  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.066176 (* 1 = 0.066176 loss)
I0927 13:03:24.535344  3315 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0927 13:03:39.116444  3315 solver.cpp:218] Iteration 66300 (6.8582 iter/s, 14.5811s/100 iters), loss = 0.0666848
I0927 13:03:39.116475  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666843 (* 1 = 0.0666843 loss)
I0927 13:03:39.116482  3315 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0927 13:03:53.696075  3315 solver.cpp:218] Iteration 66400 (6.85892 iter/s, 14.5796s/100 iters), loss = 0.0233994
I0927 13:03:53.696116  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023399 (* 1 = 0.023399 loss)
I0927 13:03:53.696122  3315 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0927 13:04:07.551259  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:04:08.134941  3315 solver.cpp:330] Iteration 66500, Testing net (#0)
I0927 13:04:11.549749  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:04:11.692600  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8866
I0927 13:04:11.692636  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.390136 (* 1 = 0.390136 loss)
I0927 13:04:11.837251  3315 solver.cpp:218] Iteration 66500 (5.51235 iter/s, 18.1411s/100 iters), loss = 0.0496007
I0927 13:04:11.837281  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496002 (* 1 = 0.0496002 loss)
I0927 13:04:11.837287  3315 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0927 13:04:26.412135  3315 solver.cpp:218] Iteration 66600 (6.86115 iter/s, 14.5748s/100 iters), loss = 0.038576
I0927 13:04:26.412176  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385755 (* 1 = 0.0385755 loss)
I0927 13:04:26.412183  3315 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0927 13:04:40.993949  3315 solver.cpp:218] Iteration 66700 (6.85789 iter/s, 14.5817s/100 iters), loss = 0.0493376
I0927 13:04:40.994050  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493371 (* 1 = 0.0493371 loss)
I0927 13:04:40.994057  3315 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0927 13:04:55.577587  3315 solver.cpp:218] Iteration 66800 (6.85706 iter/s, 14.5835s/100 iters), loss = 0.119538
I0927 13:04:55.577628  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119537 (* 1 = 0.119537 loss)
I0927 13:04:55.577635  3315 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0927 13:05:10.154047  3315 solver.cpp:218] Iteration 66900 (6.86041 iter/s, 14.5764s/100 iters), loss = 0.0363619
I0927 13:05:10.154088  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363614 (* 1 = 0.0363614 loss)
I0927 13:05:10.154094  3315 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0927 13:05:24.005939  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:05:24.589356  3315 solver.cpp:330] Iteration 67000, Testing net (#0)
I0927 13:05:28.005254  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:05:28.148077  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8685
I0927 13:05:28.148113  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.482709 (* 1 = 0.482709 loss)
I0927 13:05:28.293009  3315 solver.cpp:218] Iteration 67000 (5.51302 iter/s, 18.1389s/100 iters), loss = 0.0831206
I0927 13:05:28.293038  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0831201 (* 1 = 0.0831201 loss)
I0927 13:05:28.293045  3315 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0927 13:05:42.862946  3315 solver.cpp:218] Iteration 67100 (6.86348 iter/s, 14.5699s/100 iters), loss = 0.0965686
I0927 13:05:42.862987  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0965681 (* 1 = 0.0965681 loss)
I0927 13:05:42.862993  3315 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0927 13:05:57.442298  3315 solver.cpp:218] Iteration 67200 (6.85905 iter/s, 14.5793s/100 iters), loss = 0.126256
I0927 13:05:57.442404  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126256 (* 1 = 0.126256 loss)
I0927 13:05:57.442420  3315 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0927 13:06:12.015385  3315 solver.cpp:218] Iteration 67300 (6.86203 iter/s, 14.5729s/100 iters), loss = 0.0385128
I0927 13:06:12.015425  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385122 (* 1 = 0.0385122 loss)
I0927 13:06:12.015431  3315 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0927 13:06:26.593327  3315 solver.cpp:218] Iteration 67400 (6.85972 iter/s, 14.5779s/100 iters), loss = 0.081683
I0927 13:06:26.593367  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816825 (* 1 = 0.0816825 loss)
I0927 13:06:26.593374  3315 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0927 13:06:40.446357  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:06:41.029227  3315 solver.cpp:330] Iteration 67500, Testing net (#0)
I0927 13:06:44.446647  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:06:44.589478  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8644
I0927 13:06:44.589515  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.487366 (* 1 = 0.487366 loss)
I0927 13:06:44.735011  3315 solver.cpp:218] Iteration 67500 (5.51219 iter/s, 18.1416s/100 iters), loss = 0.0898611
I0927 13:06:44.735040  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0898605 (* 1 = 0.0898605 loss)
I0927 13:06:44.735047  3315 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0927 13:06:59.301928  3315 solver.cpp:218] Iteration 67600 (6.8649 iter/s, 14.5668s/100 iters), loss = 0.0454166
I0927 13:06:59.301968  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454161 (* 1 = 0.0454161 loss)
I0927 13:06:59.301975  3315 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0927 13:07:13.939538  3315 solver.cpp:218] Iteration 67700 (6.83175 iter/s, 14.6375s/100 iters), loss = 0.085744
I0927 13:07:13.939680  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0857435 (* 1 = 0.0857435 loss)
I0927 13:07:13.939689  3315 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0927 13:07:28.759178  3315 solver.cpp:218] Iteration 67800 (6.74788 iter/s, 14.8195s/100 iters), loss = 0.0560153
I0927 13:07:28.759219  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560148 (* 1 = 0.0560148 loss)
I0927 13:07:28.759225  3315 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0927 13:07:43.350088  3315 solver.cpp:218] Iteration 67900 (6.85362 iter/s, 14.5908s/100 iters), loss = 0.0329503
I0927 13:07:43.350128  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329498 (* 1 = 0.0329498 loss)
I0927 13:07:43.350134  3315 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0927 13:07:57.207152  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:07:57.790201  3315 solver.cpp:330] Iteration 68000, Testing net (#0)
I0927 13:08:01.206830  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:08:01.349890  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8809
I0927 13:08:01.349917  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422047 (* 1 = 0.422047 loss)
I0927 13:08:01.494843  3315 solver.cpp:218] Iteration 68000 (5.51126 iter/s, 18.1447s/100 iters), loss = 0.0598467
I0927 13:08:01.494871  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0598462 (* 1 = 0.0598462 loss)
I0927 13:08:01.494877  3315 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0927 13:08:16.085599  3315 solver.cpp:218] Iteration 68100 (6.85369 iter/s, 14.5907s/100 iters), loss = 0.147717
I0927 13:08:16.085641  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147716 (* 1 = 0.147716 loss)
I0927 13:08:16.085647  3315 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0927 13:08:30.678083  3315 solver.cpp:218] Iteration 68200 (6.85288 iter/s, 14.5924s/100 iters), loss = 0.116539
I0927 13:08:30.678206  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116538 (* 1 = 0.116538 loss)
I0927 13:08:30.678213  3315 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0927 13:08:45.268198  3315 solver.cpp:218] Iteration 68300 (6.85403 iter/s, 14.59s/100 iters), loss = 0.0591431
I0927 13:08:45.268239  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0591426 (* 1 = 0.0591426 loss)
I0927 13:08:45.268244  3315 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0927 13:08:59.860061  3315 solver.cpp:218] Iteration 68400 (6.85317 iter/s, 14.5918s/100 iters), loss = 0.0691572
I0927 13:08:59.860101  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0691567 (* 1 = 0.0691567 loss)
I0927 13:08:59.860107  3315 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0927 13:09:13.723229  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:09:14.307406  3315 solver.cpp:330] Iteration 68500, Testing net (#0)
I0927 13:09:17.722805  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:09:17.866205  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8608
I0927 13:09:17.866242  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.493854 (* 1 = 0.493854 loss)
I0927 13:09:18.010952  3315 solver.cpp:218] Iteration 68500 (5.5094 iter/s, 18.1508s/100 iters), loss = 0.0375249
I0927 13:09:18.010982  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375244 (* 1 = 0.0375244 loss)
I0927 13:09:18.010989  3315 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0927 13:09:32.579725  3315 solver.cpp:218] Iteration 68600 (6.86403 iter/s, 14.5687s/100 iters), loss = 0.0930601
I0927 13:09:32.579766  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0930597 (* 1 = 0.0930597 loss)
I0927 13:09:32.579771  3315 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0927 13:09:47.151257  3315 solver.cpp:218] Iteration 68700 (6.86273 iter/s, 14.5715s/100 iters), loss = 0.0632091
I0927 13:09:47.151374  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0632086 (* 1 = 0.0632086 loss)
I0927 13:09:47.151381  3315 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0927 13:10:01.721549  3315 solver.cpp:218] Iteration 68800 (6.86335 iter/s, 14.5701s/100 iters), loss = 0.100629
I0927 13:10:01.721590  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100629 (* 1 = 0.100629 loss)
I0927 13:10:01.721596  3315 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0927 13:10:16.289366  3315 solver.cpp:218] Iteration 68900 (6.86448 iter/s, 14.5677s/100 iters), loss = 0.079696
I0927 13:10:16.289407  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0796956 (* 1 = 0.0796956 loss)
I0927 13:10:16.289413  3315 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0927 13:10:30.140341  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:10:30.723776  3315 solver.cpp:330] Iteration 69000, Testing net (#0)
I0927 13:10:34.140367  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:10:34.283154  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.875
I0927 13:10:34.283190  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.438674 (* 1 = 0.438674 loss)
I0927 13:10:34.428174  3315 solver.cpp:218] Iteration 69000 (5.51307 iter/s, 18.1387s/100 iters), loss = 0.0202032
I0927 13:10:34.428205  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202028 (* 1 = 0.0202028 loss)
I0927 13:10:34.428211  3315 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0927 13:10:49.025097  3315 solver.cpp:218] Iteration 69100 (6.85079 iter/s, 14.5969s/100 iters), loss = 0.0492567
I0927 13:10:49.025128  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0492563 (* 1 = 0.0492563 loss)
I0927 13:10:49.025135  3315 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0927 13:11:03.624980  3315 solver.cpp:218] Iteration 69200 (6.8494 iter/s, 14.5998s/100 iters), loss = 0.0625731
I0927 13:11:03.625077  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0625727 (* 1 = 0.0625727 loss)
I0927 13:11:03.625085  3315 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0927 13:11:18.219938  3315 solver.cpp:218] Iteration 69300 (6.85174 iter/s, 14.5948s/100 iters), loss = 0.0332861
I0927 13:11:18.219980  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332857 (* 1 = 0.0332857 loss)
I0927 13:11:18.219986  3315 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0927 13:11:32.816277  3315 solver.cpp:218] Iteration 69400 (6.85107 iter/s, 14.5963s/100 iters), loss = 0.0107367
I0927 13:11:32.816319  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107364 (* 1 = 0.0107364 loss)
I0927 13:11:32.816325  3315 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0927 13:11:46.686285  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:11:47.270483  3315 solver.cpp:330] Iteration 69500, Testing net (#0)
I0927 13:11:50.686614  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:11:50.829865  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8727
I0927 13:11:50.829892  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454225 (* 1 = 0.454225 loss)
I0927 13:11:50.975154  3315 solver.cpp:218] Iteration 69500 (5.50698 iter/s, 18.1588s/100 iters), loss = 0.0250656
I0927 13:11:50.975183  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250652 (* 1 = 0.0250652 loss)
I0927 13:11:50.975190  3315 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0927 13:12:05.554376  3315 solver.cpp:218] Iteration 69600 (6.85911 iter/s, 14.5792s/100 iters), loss = 0.0604873
I0927 13:12:05.554417  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604869 (* 1 = 0.0604869 loss)
I0927 13:12:05.554424  3315 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0927 13:12:20.135730  3315 solver.cpp:218] Iteration 69700 (6.85811 iter/s, 14.5813s/100 iters), loss = 0.0515498
I0927 13:12:20.135867  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515494 (* 1 = 0.0515494 loss)
I0927 13:12:20.135874  3315 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0927 13:12:34.713377  3315 solver.cpp:218] Iteration 69800 (6.85989 iter/s, 14.5775s/100 iters), loss = 0.0655991
I0927 13:12:34.713407  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655987 (* 1 = 0.0655987 loss)
I0927 13:12:34.713413  3315 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0927 13:12:49.294508  3315 solver.cpp:218] Iteration 69900 (6.85821 iter/s, 14.5811s/100 iters), loss = 0.0700425
I0927 13:12:49.294541  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0700421 (* 1 = 0.0700421 loss)
I0927 13:12:49.294548  3315 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0927 13:13:03.149526  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:13:03.732650  3315 solver.cpp:330] Iteration 70000, Testing net (#0)
I0927 13:13:07.150264  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:13:07.293591  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8878
I0927 13:13:07.293627  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393828 (* 1 = 0.393828 loss)
I0927 13:13:07.438243  3315 solver.cpp:218] Iteration 70000 (5.51157 iter/s, 18.1437s/100 iters), loss = 0.0670447
I0927 13:13:07.438273  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0670443 (* 1 = 0.0670443 loss)
I0927 13:13:07.438279  3315 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0927 13:13:22.011741  3315 solver.cpp:218] Iteration 70100 (6.8618 iter/s, 14.5734s/100 iters), loss = 0.0361835
I0927 13:13:22.011781  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361831 (* 1 = 0.0361831 loss)
I0927 13:13:22.011786  3315 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0927 13:13:36.591547  3315 solver.cpp:218] Iteration 70200 (6.85884 iter/s, 14.5797s/100 iters), loss = 0.0437208
I0927 13:13:36.591646  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437205 (* 1 = 0.0437205 loss)
I0927 13:13:36.591655  3315 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0927 13:13:51.163594  3315 solver.cpp:218] Iteration 70300 (6.86252 iter/s, 14.5719s/100 iters), loss = 0.0538049
I0927 13:13:51.163635  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538046 (* 1 = 0.0538046 loss)
I0927 13:13:51.163640  3315 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0927 13:14:05.739269  3315 solver.cpp:218] Iteration 70400 (6.86078 iter/s, 14.5756s/100 iters), loss = 0.0515607
I0927 13:14:05.739308  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515603 (* 1 = 0.0515603 loss)
I0927 13:14:05.739315  3315 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0927 13:14:19.587524  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:14:20.171130  3315 solver.cpp:330] Iteration 70500, Testing net (#0)
I0927 13:14:23.586958  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:14:23.729755  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8765
I0927 13:14:23.729791  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.44755 (* 1 = 0.44755 loss)
I0927 13:14:23.874354  3315 solver.cpp:218] Iteration 70500 (5.5142 iter/s, 18.135s/100 iters), loss = 0.030775
I0927 13:14:23.874384  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307746 (* 1 = 0.0307746 loss)
I0927 13:14:23.874390  3315 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0927 13:14:38.462954  3315 solver.cpp:218] Iteration 70600 (6.8547 iter/s, 14.5885s/100 iters), loss = 0.0787674
I0927 13:14:38.462994  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0787671 (* 1 = 0.0787671 loss)
I0927 13:14:38.463001  3315 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0927 13:14:53.052678  3315 solver.cpp:218] Iteration 70700 (6.85418 iter/s, 14.5896s/100 iters), loss = 0.106616
I0927 13:14:53.052779  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106616 (* 1 = 0.106616 loss)
I0927 13:14:53.052788  3315 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0927 13:15:07.639518  3315 solver.cpp:218] Iteration 70800 (6.85555 iter/s, 14.5867s/100 iters), loss = 0.0655141
I0927 13:15:07.639559  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655137 (* 1 = 0.0655137 loss)
I0927 13:15:07.639565  3315 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0927 13:15:22.224953  3315 solver.cpp:218] Iteration 70900 (6.85619 iter/s, 14.5854s/100 iters), loss = 0.0198561
I0927 13:15:22.224992  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198557 (* 1 = 0.0198557 loss)
I0927 13:15:22.224998  3315 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0927 13:15:36.077985  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:15:36.662818  3315 solver.cpp:330] Iteration 71000, Testing net (#0)
I0927 13:15:40.078824  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:15:40.222048  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8744
I0927 13:15:40.222085  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.467302 (* 1 = 0.467302 loss)
I0927 13:15:40.367326  3315 solver.cpp:218] Iteration 71000 (5.51198 iter/s, 18.1423s/100 iters), loss = 0.0618703
I0927 13:15:40.367355  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.06187 (* 1 = 0.06187 loss)
I0927 13:15:40.367362  3315 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0927 13:15:54.949326  3315 solver.cpp:218] Iteration 71100 (6.8578 iter/s, 14.5819s/100 iters), loss = 0.0887772
I0927 13:15:54.949367  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0887769 (* 1 = 0.0887769 loss)
I0927 13:15:54.949373  3315 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0927 13:16:09.535185  3315 solver.cpp:218] Iteration 71200 (6.85599 iter/s, 14.5858s/100 iters), loss = 0.0629549
I0927 13:16:09.535290  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0629545 (* 1 = 0.0629545 loss)
I0927 13:16:09.535306  3315 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0927 13:16:24.117516  3315 solver.cpp:218] Iteration 71300 (6.85768 iter/s, 14.5822s/100 iters), loss = 0.0283758
I0927 13:16:24.117558  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283754 (* 1 = 0.0283754 loss)
I0927 13:16:24.117563  3315 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0927 13:16:38.701716  3315 solver.cpp:218] Iteration 71400 (6.85677 iter/s, 14.5841s/100 iters), loss = 0.0993457
I0927 13:16:38.701757  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0993453 (* 1 = 0.0993453 loss)
I0927 13:16:38.701763  3315 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0927 13:16:52.560812  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:16:53.143332  3315 solver.cpp:330] Iteration 71500, Testing net (#0)
I0927 13:16:56.559559  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:16:56.702525  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8708
I0927 13:16:56.702563  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490073 (* 1 = 0.490073 loss)
I0927 13:16:56.847311  3315 solver.cpp:218] Iteration 71500 (5.51101 iter/s, 18.1455s/100 iters), loss = 0.0274018
I0927 13:16:56.847339  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274014 (* 1 = 0.0274014 loss)
I0927 13:16:56.847347  3315 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0927 13:17:11.422363  3315 solver.cpp:218] Iteration 71600 (6.86107 iter/s, 14.575s/100 iters), loss = 0.0738798
I0927 13:17:11.422405  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0738794 (* 1 = 0.0738794 loss)
I0927 13:17:11.422410  3315 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0927 13:17:25.999339  3315 solver.cpp:218] Iteration 71700 (6.86017 iter/s, 14.5769s/100 iters), loss = 0.0247793
I0927 13:17:25.999428  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024779 (* 1 = 0.024779 loss)
I0927 13:17:25.999444  3315 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0927 13:17:40.577594  3315 solver.cpp:218] Iteration 71800 (6.85959 iter/s, 14.5781s/100 iters), loss = 0.0545401
I0927 13:17:40.577635  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0545398 (* 1 = 0.0545398 loss)
I0927 13:17:40.577641  3315 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0927 13:17:55.155901  3315 solver.cpp:218] Iteration 71900 (6.85954 iter/s, 14.5782s/100 iters), loss = 0.0235811
I0927 13:17:55.155942  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235808 (* 1 = 0.0235808 loss)
I0927 13:17:55.155948  3315 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0927 13:18:09.008378  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:18:09.592612  3315 solver.cpp:330] Iteration 72000, Testing net (#0)
I0927 13:18:13.010095  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:18:13.153204  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8662
I0927 13:18:13.153241  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.521449 (* 1 = 0.521449 loss)
I0927 13:18:13.297560  3315 solver.cpp:218] Iteration 72000 (5.5122 iter/s, 18.1416s/100 iters), loss = 0.055002
I0927 13:18:13.297596  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550017 (* 1 = 0.0550017 loss)
I0927 13:18:13.297605  3315 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0927 13:18:27.881465  3315 solver.cpp:218] Iteration 72100 (6.85691 iter/s, 14.5838s/100 iters), loss = 0.114125
I0927 13:18:27.881506  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114125 (* 1 = 0.114125 loss)
I0927 13:18:27.881512  3315 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0927 13:18:42.461789  3315 solver.cpp:218] Iteration 72200 (6.8586 iter/s, 14.5802s/100 iters), loss = 0.0785475
I0927 13:18:42.461932  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0785472 (* 1 = 0.0785472 loss)
I0927 13:18:42.461951  3315 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0927 13:18:57.038826  3315 solver.cpp:218] Iteration 72300 (6.86019 iter/s, 14.5769s/100 iters), loss = 0.0669095
I0927 13:18:57.038856  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0669092 (* 1 = 0.0669092 loss)
I0927 13:18:57.038861  3315 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0927 13:19:11.627451  3315 solver.cpp:218] Iteration 72400 (6.85469 iter/s, 14.5886s/100 iters), loss = 0.114267
I0927 13:19:11.627492  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114266 (* 1 = 0.114266 loss)
I0927 13:19:11.627498  3315 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0927 13:19:25.487416  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:19:26.070812  3315 solver.cpp:330] Iteration 72500, Testing net (#0)
I0927 13:19:29.487541  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:19:29.630583  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8634
I0927 13:19:29.630620  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.524674 (* 1 = 0.524674 loss)
I0927 13:19:29.775262  3315 solver.cpp:218] Iteration 72500 (5.51033 iter/s, 18.1477s/100 iters), loss = 0.0968552
I0927 13:19:29.775291  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0968548 (* 1 = 0.0968548 loss)
I0927 13:19:29.775298  3315 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0927 13:19:44.353034  3315 solver.cpp:218] Iteration 72600 (6.85979 iter/s, 14.5777s/100 iters), loss = 0.0285267
I0927 13:19:44.353073  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285263 (* 1 = 0.0285263 loss)
I0927 13:19:44.353080  3315 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0927 13:19:58.933930  3315 solver.cpp:218] Iteration 72700 (6.85833 iter/s, 14.5808s/100 iters), loss = 0.0272884
I0927 13:19:58.934017  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272881 (* 1 = 0.0272881 loss)
I0927 13:19:58.934025  3315 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0927 13:20:13.517441  3315 solver.cpp:218] Iteration 72800 (6.85712 iter/s, 14.5834s/100 iters), loss = 0.0595293
I0927 13:20:13.517482  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.059529 (* 1 = 0.059529 loss)
I0927 13:20:13.517488  3315 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0927 13:20:28.100941  3315 solver.cpp:218] Iteration 72900 (6.8571 iter/s, 14.5834s/100 iters), loss = 0.0620477
I0927 13:20:28.100981  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620474 (* 1 = 0.0620474 loss)
I0927 13:20:28.100987  3315 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0927 13:20:41.956607  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:20:42.540448  3315 solver.cpp:330] Iteration 73000, Testing net (#0)
I0927 13:20:45.956697  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:20:46.099690  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.875
I0927 13:20:46.099716  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.449755 (* 1 = 0.449755 loss)
I0927 13:20:46.244740  3315 solver.cpp:218] Iteration 73000 (5.51155 iter/s, 18.1437s/100 iters), loss = 0.048756
I0927 13:20:46.244776  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0487556 (* 1 = 0.0487556 loss)
I0927 13:20:46.244784  3315 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0927 13:21:00.821415  3315 solver.cpp:218] Iteration 73100 (6.86031 iter/s, 14.5766s/100 iters), loss = 0.0353819
I0927 13:21:00.821457  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353815 (* 1 = 0.0353815 loss)
I0927 13:21:00.821463  3315 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0927 13:21:15.400197  3315 solver.cpp:218] Iteration 73200 (6.85932 iter/s, 14.5787s/100 iters), loss = 0.0484569
I0927 13:21:15.400319  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0484565 (* 1 = 0.0484565 loss)
I0927 13:21:15.400326  3315 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0927 13:21:29.979673  3315 solver.cpp:218] Iteration 73300 (6.85903 iter/s, 14.5793s/100 iters), loss = 0.0339881
I0927 13:21:29.979713  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339877 (* 1 = 0.0339877 loss)
I0927 13:21:29.979719  3315 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0927 13:21:44.553750  3315 solver.cpp:218] Iteration 73400 (6.86154 iter/s, 14.574s/100 iters), loss = 0.0852207
I0927 13:21:44.553791  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0852203 (* 1 = 0.0852203 loss)
I0927 13:21:44.553797  3315 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0927 13:21:58.406359  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:21:58.989841  3315 solver.cpp:330] Iteration 73500, Testing net (#0)
I0927 13:22:02.406800  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:22:02.549638  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8645
I0927 13:22:02.549676  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500561 (* 1 = 0.500561 loss)
I0927 13:22:02.694519  3315 solver.cpp:218] Iteration 73500 (5.51247 iter/s, 18.1407s/100 iters), loss = 0.0589054
I0927 13:22:02.694550  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589051 (* 1 = 0.0589051 loss)
I0927 13:22:02.694556  3315 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0927 13:22:17.268630  3315 solver.cpp:218] Iteration 73600 (6.86151 iter/s, 14.574s/100 iters), loss = 0.135602
I0927 13:22:17.268672  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135602 (* 1 = 0.135602 loss)
I0927 13:22:17.268678  3315 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0927 13:22:31.845813  3315 solver.cpp:218] Iteration 73700 (6.86007 iter/s, 14.5771s/100 iters), loss = 0.0540299
I0927 13:22:31.845911  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0540296 (* 1 = 0.0540296 loss)
I0927 13:22:31.845919  3315 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0927 13:22:46.421260  3315 solver.cpp:218] Iteration 73800 (6.86092 iter/s, 14.5753s/100 iters), loss = 0.0347109
I0927 13:22:46.421291  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347105 (* 1 = 0.0347105 loss)
I0927 13:22:46.421298  3315 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0927 13:23:00.996161  3315 solver.cpp:218] Iteration 73900 (6.86114 iter/s, 14.5748s/100 iters), loss = 0.0347543
I0927 13:23:00.996203  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034754 (* 1 = 0.034754 loss)
I0927 13:23:00.996209  3315 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0927 13:23:14.844086  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:23:15.427611  3315 solver.cpp:330] Iteration 74000, Testing net (#0)
I0927 13:23:18.845355  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:23:18.987993  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8774
I0927 13:23:18.988029  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.423066 (* 1 = 0.423066 loss)
I0927 13:23:19.133198  3315 solver.cpp:218] Iteration 74000 (5.51361 iter/s, 18.1369s/100 iters), loss = 0.0446509
I0927 13:23:19.133227  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446505 (* 1 = 0.0446505 loss)
I0927 13:23:19.133234  3315 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0927 13:23:33.701891  3315 solver.cpp:218] Iteration 74100 (6.86407 iter/s, 14.5686s/100 iters), loss = 0.157025
I0927 13:23:33.701922  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157025 (* 1 = 0.157025 loss)
I0927 13:23:33.701927  3315 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0927 13:23:48.271826  3315 solver.cpp:218] Iteration 74200 (6.86348 iter/s, 14.5699s/100 iters), loss = 0.0624959
I0927 13:23:48.271919  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0624955 (* 1 = 0.0624955 loss)
I0927 13:23:48.271935  3315 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0927 13:24:02.847730  3315 solver.cpp:218] Iteration 74300 (6.8607 iter/s, 14.5758s/100 iters), loss = 0.122347
I0927 13:24:02.847771  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122346 (* 1 = 0.122346 loss)
I0927 13:24:02.847777  3315 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0927 13:24:17.428875  3315 solver.cpp:218] Iteration 74400 (6.85821 iter/s, 14.5811s/100 iters), loss = 0.0470539
I0927 13:24:17.428916  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0470534 (* 1 = 0.0470534 loss)
I0927 13:24:17.428921  3315 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0927 13:24:31.279402  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:24:31.864392  3315 solver.cpp:330] Iteration 74500, Testing net (#0)
I0927 13:24:35.282158  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:24:35.425582  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8742
I0927 13:24:35.425619  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.473029 (* 1 = 0.473029 loss)
I0927 13:24:35.570536  3315 solver.cpp:218] Iteration 74500 (5.5122 iter/s, 18.1416s/100 iters), loss = 0.0478212
I0927 13:24:35.570565  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0478208 (* 1 = 0.0478208 loss)
I0927 13:24:35.570571  3315 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0927 13:24:50.146340  3315 solver.cpp:218] Iteration 74600 (6.86072 iter/s, 14.5757s/100 iters), loss = 0.0493506
I0927 13:24:50.146380  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493502 (* 1 = 0.0493502 loss)
I0927 13:24:50.146386  3315 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0927 13:25:04.722276  3315 solver.cpp:218] Iteration 74700 (6.86066 iter/s, 14.5759s/100 iters), loss = 0.0634055
I0927 13:25:04.722389  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0634051 (* 1 = 0.0634051 loss)
I0927 13:25:04.722396  3315 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0927 13:25:19.302984  3315 solver.cpp:218] Iteration 74800 (6.85845 iter/s, 14.5806s/100 iters), loss = 0.0809489
I0927 13:25:19.303025  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0809485 (* 1 = 0.0809485 loss)
I0927 13:25:19.303031  3315 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0927 13:25:33.882076  3315 solver.cpp:218] Iteration 74900 (6.85917 iter/s, 14.579s/100 iters), loss = 0.0377894
I0927 13:25:33.882118  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037789 (* 1 = 0.037789 loss)
I0927 13:25:33.882124  3315 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0927 13:25:47.736217  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:25:48.320741  3315 solver.cpp:330] Iteration 75000, Testing net (#0)
I0927 13:25:51.737735  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:25:51.881083  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.872
I0927 13:25:51.881119  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.488299 (* 1 = 0.488299 loss)
I0927 13:25:52.025780  3315 solver.cpp:218] Iteration 75000 (5.51158 iter/s, 18.1436s/100 iters), loss = 0.0770523
I0927 13:25:52.025807  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0770519 (* 1 = 0.0770519 loss)
I0927 13:25:52.025815  3315 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0927 13:26:06.595213  3315 solver.cpp:218] Iteration 75100 (6.86372 iter/s, 14.5694s/100 iters), loss = 0.0600917
I0927 13:26:06.595254  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0600913 (* 1 = 0.0600913 loss)
I0927 13:26:06.595260  3315 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0927 13:26:21.168308  3315 solver.cpp:218] Iteration 75200 (6.862 iter/s, 14.573s/100 iters), loss = 0.109107
I0927 13:26:21.168475  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109106 (* 1 = 0.109106 loss)
I0927 13:26:21.168494  3315 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0927 13:26:35.742005  3315 solver.cpp:218] Iteration 75300 (6.86177 iter/s, 14.5735s/100 iters), loss = 0.099472
I0927 13:26:35.742035  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0994716 (* 1 = 0.0994716 loss)
I0927 13:26:35.742041  3315 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0927 13:26:50.312016  3315 solver.cpp:218] Iteration 75400 (6.86344 iter/s, 14.5699s/100 iters), loss = 0.0701962
I0927 13:26:50.312044  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0701958 (* 1 = 0.0701958 loss)
I0927 13:26:50.312049  3315 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0927 13:27:04.170326  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:27:04.752851  3315 solver.cpp:330] Iteration 75500, Testing net (#0)
I0927 13:27:08.170116  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:27:08.313271  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8574
I0927 13:27:08.313308  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.536398 (* 1 = 0.536398 loss)
I0927 13:27:08.457952  3315 solver.cpp:218] Iteration 75500 (5.5109 iter/s, 18.1459s/100 iters), loss = 0.0294988
I0927 13:27:08.457981  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294983 (* 1 = 0.0294983 loss)
I0927 13:27:08.457988  3315 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0927 13:27:23.030117  3315 solver.cpp:218] Iteration 75600 (6.86243 iter/s, 14.5721s/100 iters), loss = 0.02356
I0927 13:27:23.030158  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235596 (* 1 = 0.0235596 loss)
I0927 13:27:23.030164  3315 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0927 13:27:37.611415  3315 solver.cpp:218] Iteration 75700 (6.85814 iter/s, 14.5812s/100 iters), loss = 0.093692
I0927 13:27:37.611521  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0936916 (* 1 = 0.0936916 loss)
I0927 13:27:37.611527  3315 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0927 13:27:52.188295  3315 solver.cpp:218] Iteration 75800 (6.86024 iter/s, 14.5767s/100 iters), loss = 0.0568067
I0927 13:27:52.188336  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568063 (* 1 = 0.0568063 loss)
I0927 13:27:52.188343  3315 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0927 13:28:06.761833  3315 solver.cpp:218] Iteration 75900 (6.86179 iter/s, 14.5735s/100 iters), loss = 0.0782408
I0927 13:28:06.761873  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0782404 (* 1 = 0.0782404 loss)
I0927 13:28:06.761879  3315 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0927 13:28:20.613385  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:28:21.196872  3315 solver.cpp:330] Iteration 76000, Testing net (#0)
I0927 13:28:24.613507  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:28:24.756624  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8704
I0927 13:28:24.756661  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47364 (* 1 = 0.47364 loss)
I0927 13:28:24.901430  3315 solver.cpp:218] Iteration 76000 (5.51283 iter/s, 18.1395s/100 iters), loss = 0.0651042
I0927 13:28:24.901459  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0651038 (* 1 = 0.0651038 loss)
I0927 13:28:24.901466  3315 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0927 13:28:39.474949  3315 solver.cpp:218] Iteration 76100 (6.86179 iter/s, 14.5735s/100 iters), loss = 0.0640077
I0927 13:28:39.474990  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640073 (* 1 = 0.0640073 loss)
I0927 13:28:39.474997  3315 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0927 13:28:54.050573  3315 solver.cpp:218] Iteration 76200 (6.86081 iter/s, 14.5755s/100 iters), loss = 0.0403515
I0927 13:28:54.050715  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403511 (* 1 = 0.0403511 loss)
I0927 13:28:54.050722  3315 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0927 13:29:08.627710  3315 solver.cpp:218] Iteration 76300 (6.86014 iter/s, 14.577s/100 iters), loss = 0.0686045
I0927 13:29:08.627751  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686041 (* 1 = 0.0686041 loss)
I0927 13:29:08.627756  3315 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0927 13:29:23.204288  3315 solver.cpp:218] Iteration 76400 (6.86036 iter/s, 14.5765s/100 iters), loss = 0.0589789
I0927 13:29:23.204329  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589785 (* 1 = 0.0589785 loss)
I0927 13:29:23.204334  3315 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0927 13:29:37.056660  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:29:37.640180  3315 solver.cpp:330] Iteration 76500, Testing net (#0)
I0927 13:29:41.056363  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:29:41.199347  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8638
I0927 13:29:41.199383  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.514545 (* 1 = 0.514545 loss)
I0927 13:29:41.344444  3315 solver.cpp:218] Iteration 76500 (5.51266 iter/s, 18.1401s/100 iters), loss = 0.0403449
I0927 13:29:41.344473  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403445 (* 1 = 0.0403445 loss)
I0927 13:29:41.344480  3315 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0927 13:29:55.912314  3315 solver.cpp:218] Iteration 76600 (6.86445 iter/s, 14.5678s/100 iters), loss = 0.0398623
I0927 13:29:55.912345  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398619 (* 1 = 0.0398619 loss)
I0927 13:29:55.912361  3315 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0927 13:30:10.486207  3315 solver.cpp:218] Iteration 76700 (6.86162 iter/s, 14.5738s/100 iters), loss = 0.0412843
I0927 13:30:10.486310  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412839 (* 1 = 0.0412839 loss)
I0927 13:30:10.486317  3315 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0927 13:30:25.057338  3315 solver.cpp:218] Iteration 76800 (6.86295 iter/s, 14.571s/100 iters), loss = 0.07463
I0927 13:30:25.057369  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0746296 (* 1 = 0.0746296 loss)
I0927 13:30:25.057385  3315 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0927 13:30:39.629664  3315 solver.cpp:218] Iteration 76900 (6.86235 iter/s, 14.5723s/100 iters), loss = 0.0269937
I0927 13:30:39.629694  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269932 (* 1 = 0.0269932 loss)
I0927 13:30:39.629711  3315 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0927 13:30:53.477483  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:30:54.061025  3315 solver.cpp:330] Iteration 77000, Testing net (#0)
I0927 13:30:57.477320  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:30:57.620230  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8779
I0927 13:30:57.620266  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.465175 (* 1 = 0.465175 loss)
I0927 13:30:57.764302  3315 solver.cpp:218] Iteration 77000 (5.51433 iter/s, 18.1346s/100 iters), loss = 0.0716887
I0927 13:30:57.764330  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716883 (* 1 = 0.0716883 loss)
I0927 13:30:57.764338  3315 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0927 13:31:12.336642  3315 solver.cpp:218] Iteration 77100 (6.86235 iter/s, 14.5723s/100 iters), loss = 0.106548
I0927 13:31:12.336673  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106548 (* 1 = 0.106548 loss)
I0927 13:31:12.336679  3315 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0927 13:31:26.915351  3315 solver.cpp:218] Iteration 77200 (6.85935 iter/s, 14.5786s/100 iters), loss = 0.143116
I0927 13:31:26.915474  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143116 (* 1 = 0.143116 loss)
I0927 13:31:26.915491  3315 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0927 13:31:41.488142  3315 solver.cpp:218] Iteration 77300 (6.86218 iter/s, 14.5726s/100 iters), loss = 0.0301922
I0927 13:31:41.488183  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301918 (* 1 = 0.0301918 loss)
I0927 13:31:41.488189  3315 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0927 13:31:56.063352  3315 solver.cpp:218] Iteration 77400 (6.861 iter/s, 14.5751s/100 iters), loss = 0.0176878
I0927 13:31:56.063382  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176874 (* 1 = 0.0176874 loss)
I0927 13:31:56.063388  3315 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0927 13:32:09.917757  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:32:10.500522  3315 solver.cpp:330] Iteration 77500, Testing net (#0)
I0927 13:32:13.918426  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:32:14.061337  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8686
I0927 13:32:14.061373  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500812 (* 1 = 0.500812 loss)
I0927 13:32:14.206913  3315 solver.cpp:218] Iteration 77500 (5.51162 iter/s, 18.1435s/100 iters), loss = 0.0402189
I0927 13:32:14.206943  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402184 (* 1 = 0.0402184 loss)
I0927 13:32:14.206948  3315 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0927 13:32:28.781363  3315 solver.cpp:218] Iteration 77600 (6.86135 iter/s, 14.5744s/100 iters), loss = 0.056742
I0927 13:32:28.781404  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0567416 (* 1 = 0.0567416 loss)
I0927 13:32:28.781409  3315 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0927 13:32:43.348472  3315 solver.cpp:218] Iteration 77700 (6.86482 iter/s, 14.567s/100 iters), loss = 0.0424615
I0927 13:32:43.348546  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0424611 (* 1 = 0.0424611 loss)
I0927 13:32:43.348553  3315 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0927 13:32:57.917938  3315 solver.cpp:218] Iteration 77800 (6.86372 iter/s, 14.5694s/100 iters), loss = 0.0420493
I0927 13:32:57.917968  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420489 (* 1 = 0.0420489 loss)
I0927 13:32:57.917974  3315 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0927 13:33:12.494112  3315 solver.cpp:218] Iteration 77900 (6.86054 iter/s, 14.5761s/100 iters), loss = 0.0429102
I0927 13:33:12.494154  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429098 (* 1 = 0.0429098 loss)
I0927 13:33:12.494160  3315 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0927 13:33:26.345113  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:33:26.929507  3315 solver.cpp:330] Iteration 78000, Testing net (#0)
I0927 13:33:30.347530  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:33:30.490463  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8677
I0927 13:33:30.490500  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.484493 (* 1 = 0.484493 loss)
I0927 13:33:30.635915  3315 solver.cpp:218] Iteration 78000 (5.51216 iter/s, 18.1417s/100 iters), loss = 0.0329143
I0927 13:33:30.635942  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329139 (* 1 = 0.0329139 loss)
I0927 13:33:30.635949  3315 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0927 13:33:45.218999  3315 solver.cpp:218] Iteration 78100 (6.85729 iter/s, 14.583s/100 iters), loss = 0.0462645
I0927 13:33:45.219040  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0462641 (* 1 = 0.0462641 loss)
I0927 13:33:45.219046  3315 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0927 13:33:59.797031  3315 solver.cpp:218] Iteration 78200 (6.85967 iter/s, 14.578s/100 iters), loss = 0.0949211
I0927 13:33:59.797152  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0949207 (* 1 = 0.0949207 loss)
I0927 13:33:59.797160  3315 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0927 13:34:14.375898  3315 solver.cpp:218] Iteration 78300 (6.85932 iter/s, 14.5787s/100 iters), loss = 0.076361
I0927 13:34:14.375941  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0763606 (* 1 = 0.0763606 loss)
I0927 13:34:14.375946  3315 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0927 13:34:28.953481  3315 solver.cpp:218] Iteration 78400 (6.85988 iter/s, 14.5775s/100 iters), loss = 0.0624068
I0927 13:34:28.953514  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0624064 (* 1 = 0.0624064 loss)
I0927 13:34:28.953521  3315 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0927 13:34:42.799319  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:34:43.382519  3315 solver.cpp:330] Iteration 78500, Testing net (#0)
I0927 13:34:46.800578  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:34:46.943913  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8749
I0927 13:34:46.943939  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47026 (* 1 = 0.47026 loss)
I0927 13:34:47.088809  3315 solver.cpp:218] Iteration 78500 (5.51412 iter/s, 18.1353s/100 iters), loss = 0.0429573
I0927 13:34:47.088840  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429569 (* 1 = 0.0429569 loss)
I0927 13:34:47.088845  3315 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0927 13:35:01.664866  3315 solver.cpp:218] Iteration 78600 (6.8606 iter/s, 14.576s/100 iters), loss = 0.0700991
I0927 13:35:01.664896  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0700987 (* 1 = 0.0700987 loss)
I0927 13:35:01.664902  3315 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0927 13:35:16.239241  3315 solver.cpp:218] Iteration 78700 (6.86139 iter/s, 14.5743s/100 iters), loss = 0.0433032
I0927 13:35:16.239379  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433028 (* 1 = 0.0433028 loss)
I0927 13:35:16.239387  3315 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0927 13:35:30.818639  3315 solver.cpp:218] Iteration 78800 (6.85907 iter/s, 14.5792s/100 iters), loss = 0.0792721
I0927 13:35:30.818666  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0792717 (* 1 = 0.0792717 loss)
I0927 13:35:30.818672  3315 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0927 13:35:45.390023  3315 solver.cpp:218] Iteration 78900 (6.8628 iter/s, 14.5713s/100 iters), loss = 0.0793543
I0927 13:35:45.390064  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0793539 (* 1 = 0.0793539 loss)
I0927 13:35:45.390070  3315 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0927 13:35:59.238271  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:35:59.820853  3315 solver.cpp:330] Iteration 79000, Testing net (#0)
I0927 13:36:03.240658  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:36:03.383792  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8708
I0927 13:36:03.383819  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.486912 (* 1 = 0.486912 loss)
I0927 13:36:03.528905  3315 solver.cpp:218] Iteration 79000 (5.51304 iter/s, 18.1388s/100 iters), loss = 0.0154584
I0927 13:36:03.528934  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015458 (* 1 = 0.015458 loss)
I0927 13:36:03.528940  3315 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0927 13:36:18.102272  3315 solver.cpp:218] Iteration 79100 (6.86186 iter/s, 14.5733s/100 iters), loss = 0.048677
I0927 13:36:18.102303  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486766 (* 1 = 0.0486766 loss)
I0927 13:36:18.102309  3315 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0927 13:36:32.672155  3315 solver.cpp:218] Iteration 79200 (6.8635 iter/s, 14.5698s/100 iters), loss = 0.0684918
I0927 13:36:32.672247  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0684914 (* 1 = 0.0684914 loss)
I0927 13:36:32.672266  3315 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0927 13:36:47.247179  3315 solver.cpp:218] Iteration 79300 (6.86111 iter/s, 14.5749s/100 iters), loss = 0.0508376
I0927 13:36:47.247208  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508372 (* 1 = 0.0508372 loss)
I0927 13:36:47.247215  3315 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0927 13:37:01.823140  3315 solver.cpp:218] Iteration 79400 (6.86064 iter/s, 14.5759s/100 iters), loss = 0.0208028
I0927 13:37:01.823171  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208024 (* 1 = 0.0208024 loss)
I0927 13:37:01.823177  3315 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0927 13:37:15.672183  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:37:16.255115  3315 solver.cpp:330] Iteration 79500, Testing net (#0)
I0927 13:37:19.672735  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:37:19.815971  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8682
I0927 13:37:19.816009  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.469683 (* 1 = 0.469683 loss)
I0927 13:37:19.960651  3315 solver.cpp:218] Iteration 79500 (5.51346 iter/s, 18.1374s/100 iters), loss = 0.0196838
I0927 13:37:19.960681  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196834 (* 1 = 0.0196834 loss)
I0927 13:37:19.960688  3315 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0927 13:37:34.532208  3315 solver.cpp:218] Iteration 79600 (6.86272 iter/s, 14.5715s/100 iters), loss = 0.0530158
I0927 13:37:34.532238  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0530154 (* 1 = 0.0530154 loss)
I0927 13:37:34.532244  3315 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0927 13:37:49.114645  3315 solver.cpp:218] Iteration 79700 (6.8576 iter/s, 14.5824s/100 iters), loss = 0.110161
I0927 13:37:49.114787  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110161 (* 1 = 0.110161 loss)
I0927 13:37:49.114795  3315 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0927 13:38:03.691224  3315 solver.cpp:218] Iteration 79800 (6.8604 iter/s, 14.5764s/100 iters), loss = 0.0457509
I0927 13:38:03.691256  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457506 (* 1 = 0.0457506 loss)
I0927 13:38:03.691272  3315 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0927 13:38:18.267709  3315 solver.cpp:218] Iteration 79900 (6.8604 iter/s, 14.5764s/100 iters), loss = 0.0197293
I0927 13:38:18.267741  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019729 (* 1 = 0.019729 loss)
I0927 13:38:18.267757  3315 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0927 13:38:32.119205  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:38:32.703655  3315 solver.cpp:330] Iteration 80000, Testing net (#0)
I0927 13:38:36.122460  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:38:36.265568  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8696
I0927 13:38:36.265606  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.48804 (* 1 = 0.48804 loss)
I0927 13:38:36.410908  3315 solver.cpp:218] Iteration 80000 (5.51173 iter/s, 18.1431s/100 iters), loss = 0.0754378
I0927 13:38:36.410938  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0754375 (* 1 = 0.0754375 loss)
I0927 13:38:36.410943  3315 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0927 13:38:36.410946  3315 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0927 13:38:50.978895  3315 solver.cpp:218] Iteration 80100 (6.8644 iter/s, 14.5679s/100 iters), loss = 0.0462944
I0927 13:38:50.978935  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046294 (* 1 = 0.046294 loss)
I0927 13:38:50.978940  3315 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0927 13:39:05.554244  3315 solver.cpp:218] Iteration 80200 (6.86094 iter/s, 14.5753s/100 iters), loss = 0.0458165
I0927 13:39:05.554347  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0458162 (* 1 = 0.0458162 loss)
I0927 13:39:05.554354  3315 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0927 13:39:20.125051  3315 solver.cpp:218] Iteration 80300 (6.8631 iter/s, 14.5707s/100 iters), loss = 0.0440754
I0927 13:39:20.125092  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440751 (* 1 = 0.0440751 loss)
I0927 13:39:20.125097  3315 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0927 13:39:34.698966  3315 solver.cpp:218] Iteration 80400 (6.86161 iter/s, 14.5738s/100 iters), loss = 0.0258057
I0927 13:39:34.699007  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258054 (* 1 = 0.0258054 loss)
I0927 13:39:34.699013  3315 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0927 13:39:48.546617  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:39:49.130636  3315 solver.cpp:330] Iteration 80500, Testing net (#0)
I0927 13:39:52.548292  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:39:52.691059  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8988
I0927 13:39:52.691097  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373145 (* 1 = 0.373145 loss)
I0927 13:39:52.836024  3315 solver.cpp:218] Iteration 80500 (5.5136 iter/s, 18.137s/100 iters), loss = 0.0385252
I0927 13:39:52.836055  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385248 (* 1 = 0.0385248 loss)
I0927 13:39:52.836061  3315 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0927 13:40:07.404157  3315 solver.cpp:218] Iteration 80600 (6.86433 iter/s, 14.5681s/100 iters), loss = 0.0319728
I0927 13:40:07.404196  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319724 (* 1 = 0.0319724 loss)
I0927 13:40:07.404202  3315 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0927 13:40:21.980165  3315 solver.cpp:218] Iteration 80700 (6.86062 iter/s, 14.5759s/100 iters), loss = 0.0556023
I0927 13:40:21.980265  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556019 (* 1 = 0.0556019 loss)
I0927 13:40:21.980271  3315 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0927 13:40:36.546550  3315 solver.cpp:218] Iteration 80800 (6.86519 iter/s, 14.5662s/100 iters), loss = 0.0554438
I0927 13:40:36.546578  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554435 (* 1 = 0.0554435 loss)
I0927 13:40:36.546584  3315 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0927 13:40:51.118521  3315 solver.cpp:218] Iteration 80900 (6.86252 iter/s, 14.5719s/100 iters), loss = 0.00822249
I0927 13:40:51.118551  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00822212 (* 1 = 0.00822212 loss)
I0927 13:40:51.118557  3315 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0927 13:41:04.963390  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:41:05.546727  3315 solver.cpp:330] Iteration 81000, Testing net (#0)
I0927 13:41:08.964287  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:41:09.107815  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9026
I0927 13:41:09.107852  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361745 (* 1 = 0.361745 loss)
I0927 13:41:09.252583  3315 solver.cpp:218] Iteration 81000 (5.51451 iter/s, 18.134s/100 iters), loss = 0.017011
I0927 13:41:09.252612  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170107 (* 1 = 0.0170107 loss)
I0927 13:41:09.252619  3315 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0927 13:41:23.823312  3315 solver.cpp:218] Iteration 81100 (6.86311 iter/s, 14.5707s/100 iters), loss = 0.03161
I0927 13:41:23.823351  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316097 (* 1 = 0.0316097 loss)
I0927 13:41:23.823357  3315 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0927 13:41:38.393066  3315 solver.cpp:218] Iteration 81200 (6.86357 iter/s, 14.5697s/100 iters), loss = 0.0343255
I0927 13:41:38.393208  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343251 (* 1 = 0.0343251 loss)
I0927 13:41:38.393215  3315 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0927 13:41:52.966168  3315 solver.cpp:218] Iteration 81300 (6.86204 iter/s, 14.5729s/100 iters), loss = 0.0309422
I0927 13:41:52.966210  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309419 (* 1 = 0.0309419 loss)
I0927 13:41:52.966217  3315 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0927 13:42:07.539862  3315 solver.cpp:218] Iteration 81400 (6.86171 iter/s, 14.5736s/100 iters), loss = 0.0110465
I0927 13:42:07.539903  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110461 (* 1 = 0.0110461 loss)
I0927 13:42:07.539909  3315 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0927 13:42:21.387382  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:42:21.970960  3315 solver.cpp:330] Iteration 81500, Testing net (#0)
I0927 13:42:25.387161  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:42:25.530390  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I0927 13:42:25.530426  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357641 (* 1 = 0.357641 loss)
I0927 13:42:25.674656  3315 solver.cpp:218] Iteration 81500 (5.51429 iter/s, 18.1347s/100 iters), loss = 0.0361782
I0927 13:42:25.674685  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361778 (* 1 = 0.0361778 loss)
I0927 13:42:25.674692  3315 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0927 13:42:40.238899  3315 solver.cpp:218] Iteration 81600 (6.86616 iter/s, 14.5642s/100 iters), loss = 0.0412131
I0927 13:42:40.238930  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412128 (* 1 = 0.0412128 loss)
I0927 13:42:40.238937  3315 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0927 13:42:54.816262  3315 solver.cpp:218] Iteration 81700 (6.85998 iter/s, 14.5773s/100 iters), loss = 0.0242628
I0927 13:42:54.816349  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242625 (* 1 = 0.0242625 loss)
I0927 13:42:54.816367  3315 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0927 13:43:09.393811  3315 solver.cpp:218] Iteration 81800 (6.85992 iter/s, 14.5774s/100 iters), loss = 0.025865
I0927 13:43:09.393852  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258647 (* 1 = 0.0258647 loss)
I0927 13:43:09.393858  3315 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0927 13:43:23.967248  3315 solver.cpp:218] Iteration 81900 (6.86184 iter/s, 14.5734s/100 iters), loss = 0.0219627
I0927 13:43:23.967288  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219624 (* 1 = 0.0219624 loss)
I0927 13:43:23.967294  3315 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0927 13:43:37.816004  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:43:38.399641  3315 solver.cpp:330] Iteration 82000, Testing net (#0)
I0927 13:43:41.816398  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:43:41.958987  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I0927 13:43:41.959024  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356455 (* 1 = 0.356455 loss)
I0927 13:43:42.104347  3315 solver.cpp:218] Iteration 82000 (5.51359 iter/s, 18.137s/100 iters), loss = 0.0167518
I0927 13:43:42.104377  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167515 (* 1 = 0.0167515 loss)
I0927 13:43:42.104383  3315 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0927 13:43:56.677124  3315 solver.cpp:218] Iteration 82100 (6.86214 iter/s, 14.5727s/100 iters), loss = 0.0148439
I0927 13:43:56.677153  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148436 (* 1 = 0.0148436 loss)
I0927 13:43:56.677160  3315 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0927 13:44:11.254549  3315 solver.cpp:218] Iteration 82200 (6.85995 iter/s, 14.5774s/100 iters), loss = 0.0637187
I0927 13:44:11.254634  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0637184 (* 1 = 0.0637184 loss)
I0927 13:44:11.254643  3315 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0927 13:44:25.834391  3315 solver.cpp:218] Iteration 82300 (6.85884 iter/s, 14.5797s/100 iters), loss = 0.0224106
I0927 13:44:25.834434  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224102 (* 1 = 0.0224102 loss)
I0927 13:44:25.834439  3315 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0927 13:44:40.413607  3315 solver.cpp:218] Iteration 82400 (6.85912 iter/s, 14.5791s/100 iters), loss = 0.0142939
I0927 13:44:40.413637  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142936 (* 1 = 0.0142936 loss)
I0927 13:44:40.413653  3315 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0927 13:44:54.263010  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:44:54.846737  3315 solver.cpp:330] Iteration 82500, Testing net (#0)
I0927 13:44:58.266202  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:44:58.409001  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9038
I0927 13:44:58.409039  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356157 (* 1 = 0.356157 loss)
I0927 13:44:58.554641  3315 solver.cpp:218] Iteration 82500 (5.51239 iter/s, 18.141s/100 iters), loss = 0.0187452
I0927 13:44:58.554671  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187449 (* 1 = 0.0187449 loss)
I0927 13:44:58.554677  3315 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0927 13:45:13.122196  3315 solver.cpp:218] Iteration 82600 (6.8646 iter/s, 14.5675s/100 iters), loss = 0.0114445
I0927 13:45:13.122226  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114442 (* 1 = 0.0114442 loss)
I0927 13:45:13.122232  3315 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0927 13:45:27.688267  3315 solver.cpp:218] Iteration 82700 (6.8653 iter/s, 14.566s/100 iters), loss = 0.0110926
I0927 13:45:27.688387  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110923 (* 1 = 0.0110923 loss)
I0927 13:45:27.688405  3315 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0927 13:45:42.259291  3315 solver.cpp:218] Iteration 82800 (6.86301 iter/s, 14.5709s/100 iters), loss = 0.0128337
I0927 13:45:42.259331  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128333 (* 1 = 0.0128333 loss)
I0927 13:45:42.259336  3315 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0927 13:45:56.825673  3315 solver.cpp:218] Iteration 82900 (6.86516 iter/s, 14.5663s/100 iters), loss = 0.0111492
I0927 13:45:56.825714  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111489 (* 1 = 0.0111489 loss)
I0927 13:45:56.825721  3315 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0927 13:46:10.672803  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:46:11.255587  3315 solver.cpp:330] Iteration 83000, Testing net (#0)
I0927 13:46:14.673197  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:46:14.816454  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9036
I0927 13:46:14.816493  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359627 (* 1 = 0.359627 loss)
I0927 13:46:14.961297  3315 solver.cpp:218] Iteration 83000 (5.51403 iter/s, 18.1355s/100 iters), loss = 0.0143903
I0927 13:46:14.961326  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143899 (* 1 = 0.0143899 loss)
I0927 13:46:14.961333  3315 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0927 13:46:29.530509  3315 solver.cpp:218] Iteration 83100 (6.86382 iter/s, 14.5691s/100 iters), loss = 0.0196267
I0927 13:46:29.530551  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196263 (* 1 = 0.0196263 loss)
I0927 13:46:29.530557  3315 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0927 13:46:44.102989  3315 solver.cpp:218] Iteration 83200 (6.86229 iter/s, 14.5724s/100 iters), loss = 0.025804
I0927 13:46:44.103058  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258037 (* 1 = 0.0258037 loss)
I0927 13:46:44.103065  3315 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0927 13:46:58.681172  3315 solver.cpp:218] Iteration 83300 (6.85961 iter/s, 14.5781s/100 iters), loss = 0.0193879
I0927 13:46:58.681205  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193875 (* 1 = 0.0193875 loss)
I0927 13:46:58.681221  3315 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0927 13:47:13.265841  3315 solver.cpp:218] Iteration 83400 (6.85655 iter/s, 14.5846s/100 iters), loss = 0.022573
I0927 13:47:13.265872  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225726 (* 1 = 0.0225726 loss)
I0927 13:47:13.265888  3315 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0927 13:47:27.118443  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:47:27.701622  3315 solver.cpp:330] Iteration 83500, Testing net (#0)
I0927 13:47:31.119400  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:47:31.262476  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I0927 13:47:31.262513  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358354 (* 1 = 0.358354 loss)
I0927 13:47:31.407763  3315 solver.cpp:218] Iteration 83500 (5.51212 iter/s, 18.1418s/100 iters), loss = 0.0157005
I0927 13:47:31.407793  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157001 (* 1 = 0.0157001 loss)
I0927 13:47:31.407799  3315 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0927 13:47:45.979974  3315 solver.cpp:218] Iteration 83600 (6.86241 iter/s, 14.5721s/100 iters), loss = 0.0226373
I0927 13:47:45.980005  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022637 (* 1 = 0.022637 loss)
I0927 13:47:45.980010  3315 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0927 13:48:00.556656  3315 solver.cpp:218] Iteration 83700 (6.8603 iter/s, 14.5766s/100 iters), loss = 0.0176109
I0927 13:48:00.556783  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176106 (* 1 = 0.0176106 loss)
I0927 13:48:00.556802  3315 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0927 13:48:15.132042  3315 solver.cpp:218] Iteration 83800 (6.86096 iter/s, 14.5752s/100 iters), loss = 0.0191662
I0927 13:48:15.132072  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191659 (* 1 = 0.0191659 loss)
I0927 13:48:15.132078  3315 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0927 13:48:29.700429  3315 solver.cpp:218] Iteration 83900 (6.86421 iter/s, 14.5683s/100 iters), loss = 0.00571836
I0927 13:48:29.700461  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005718 (* 1 = 0.005718 loss)
I0927 13:48:29.700467  3315 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0927 13:48:43.556875  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:48:44.139695  3315 solver.cpp:330] Iteration 84000, Testing net (#0)
I0927 13:48:47.556409  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:48:47.698989  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9043
I0927 13:48:47.699017  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355206 (* 1 = 0.355206 loss)
I0927 13:48:47.844293  3315 solver.cpp:218] Iteration 84000 (5.51153 iter/s, 18.1438s/100 iters), loss = 0.0357435
I0927 13:48:47.844321  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357432 (* 1 = 0.0357432 loss)
I0927 13:48:47.844328  3315 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0927 13:49:02.406086  3315 solver.cpp:218] Iteration 84100 (6.86732 iter/s, 14.5617s/100 iters), loss = 0.0283628
I0927 13:49:02.406127  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283625 (* 1 = 0.0283625 loss)
I0927 13:49:02.406133  3315 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0927 13:49:16.979233  3315 solver.cpp:218] Iteration 84200 (6.86197 iter/s, 14.5731s/100 iters), loss = 0.0205163
I0927 13:49:16.979341  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205159 (* 1 = 0.0205159 loss)
I0927 13:49:16.979348  3315 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0927 13:49:31.554030  3315 solver.cpp:218] Iteration 84300 (6.86123 iter/s, 14.5747s/100 iters), loss = 0.0238196
I0927 13:49:31.554071  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238192 (* 1 = 0.0238192 loss)
I0927 13:49:31.554076  3315 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0927 13:49:46.130837  3315 solver.cpp:218] Iteration 84400 (6.86025 iter/s, 14.5767s/100 iters), loss = 0.00540128
I0927 13:49:46.130877  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540093 (* 1 = 0.00540093 loss)
I0927 13:49:46.130883  3315 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0927 13:49:59.982422  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:50:00.566797  3315 solver.cpp:330] Iteration 84500, Testing net (#0)
I0927 13:50:03.985388  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:50:04.128921  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I0927 13:50:04.128958  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35983 (* 1 = 0.35983 loss)
I0927 13:50:04.273385  3315 solver.cpp:218] Iteration 84500 (5.51193 iter/s, 18.1425s/100 iters), loss = 0.0102321
I0927 13:50:04.273412  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102317 (* 1 = 0.0102317 loss)
I0927 13:50:04.273419  3315 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0927 13:50:18.842965  3315 solver.cpp:218] Iteration 84600 (6.86365 iter/s, 14.5695s/100 iters), loss = 0.0157915
I0927 13:50:18.842996  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157912 (* 1 = 0.0157912 loss)
I0927 13:50:18.843003  3315 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0927 13:50:33.421371  3315 solver.cpp:218] Iteration 84700 (6.85949 iter/s, 14.5783s/100 iters), loss = 0.0192177
I0927 13:50:33.421531  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192174 (* 1 = 0.0192174 loss)
I0927 13:50:33.421540  3315 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0927 13:50:47.998788  3315 solver.cpp:218] Iteration 84800 (6.86002 iter/s, 14.5772s/100 iters), loss = 0.0131988
I0927 13:50:47.998829  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131985 (* 1 = 0.0131985 loss)
I0927 13:50:47.998836  3315 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0927 13:51:02.576337  3315 solver.cpp:218] Iteration 84900 (6.8599 iter/s, 14.5775s/100 iters), loss = 0.00369028
I0927 13:51:02.576369  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00368993 (* 1 = 0.00368993 loss)
I0927 13:51:02.576375  3315 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0927 13:51:16.433069  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:51:17.017773  3315 solver.cpp:330] Iteration 85000, Testing net (#0)
I0927 13:51:20.434975  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:51:20.577924  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I0927 13:51:20.577960  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358861 (* 1 = 0.358861 loss)
I0927 13:51:20.722825  3315 solver.cpp:218] Iteration 85000 (5.51073 iter/s, 18.1464s/100 iters), loss = 0.028149
I0927 13:51:20.722859  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281487 (* 1 = 0.0281487 loss)
I0927 13:51:20.722867  3315 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0927 13:51:35.292307  3315 solver.cpp:218] Iteration 85100 (6.86369 iter/s, 14.5694s/100 iters), loss = 0.010412
I0927 13:51:35.292348  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104117 (* 1 = 0.0104117 loss)
I0927 13:51:35.292354  3315 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0927 13:51:49.859730  3315 solver.cpp:218] Iteration 85200 (6.86467 iter/s, 14.5673s/100 iters), loss = 0.00998487
I0927 13:51:49.859856  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00998454 (* 1 = 0.00998454 loss)
I0927 13:51:49.859863  3315 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0927 13:52:04.430955  3315 solver.cpp:218] Iteration 85300 (6.86292 iter/s, 14.5711s/100 iters), loss = 0.0376179
I0927 13:52:04.430996  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376176 (* 1 = 0.0376176 loss)
I0927 13:52:04.431002  3315 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0927 13:52:19.002070  3315 solver.cpp:218] Iteration 85400 (6.86293 iter/s, 14.571s/100 iters), loss = 0.00935952
I0927 13:52:19.002112  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00935918 (* 1 = 0.00935918 loss)
I0927 13:52:19.002118  3315 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0927 13:52:32.853154  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:52:33.436460  3315 solver.cpp:330] Iteration 85500, Testing net (#0)
I0927 13:52:36.856184  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:52:36.999016  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I0927 13:52:36.999053  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358524 (* 1 = 0.358524 loss)
I0927 13:52:37.144462  3315 solver.cpp:218] Iteration 85500 (5.51198 iter/s, 18.1423s/100 iters), loss = 0.0313317
I0927 13:52:37.144492  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313313 (* 1 = 0.0313313 loss)
I0927 13:52:37.144500  3315 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0927 13:52:51.721441  3315 solver.cpp:218] Iteration 85600 (6.86016 iter/s, 14.5769s/100 iters), loss = 0.0171505
I0927 13:52:51.721482  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171501 (* 1 = 0.0171501 loss)
I0927 13:52:51.721487  3315 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0927 13:53:06.302153  3315 solver.cpp:218] Iteration 85700 (6.85841 iter/s, 14.5806s/100 iters), loss = 0.0325448
I0927 13:53:06.302283  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325445 (* 1 = 0.0325445 loss)
I0927 13:53:06.302290  3315 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0927 13:53:20.882894  3315 solver.cpp:218] Iteration 85800 (6.85844 iter/s, 14.5806s/100 iters), loss = 0.0266277
I0927 13:53:20.882936  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266274 (* 1 = 0.0266274 loss)
I0927 13:53:20.882941  3315 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0927 13:53:35.457769  3315 solver.cpp:218] Iteration 85900 (6.86116 iter/s, 14.5748s/100 iters), loss = 0.0164908
I0927 13:53:35.457810  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164904 (* 1 = 0.0164904 loss)
I0927 13:53:35.457816  3315 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0927 13:53:49.306385  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:53:49.889991  3315 solver.cpp:330] Iteration 86000, Testing net (#0)
I0927 13:53:53.308387  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:53:53.451244  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9039
I0927 13:53:53.451282  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362304 (* 1 = 0.362304 loss)
I0927 13:53:53.596160  3315 solver.cpp:218] Iteration 86000 (5.51319 iter/s, 18.1383s/100 iters), loss = 0.0114789
I0927 13:53:53.596190  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114786 (* 1 = 0.0114786 loss)
I0927 13:53:53.596197  3315 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0927 13:54:08.172124  3315 solver.cpp:218] Iteration 86100 (6.86064 iter/s, 14.5759s/100 iters), loss = 0.0138719
I0927 13:54:08.172164  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138716 (* 1 = 0.0138716 loss)
I0927 13:54:08.172170  3315 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0927 13:54:22.742020  3315 solver.cpp:218] Iteration 86200 (6.8635 iter/s, 14.5698s/100 iters), loss = 0.0233357
I0927 13:54:22.742141  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233354 (* 1 = 0.0233354 loss)
I0927 13:54:22.742148  3315 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0927 13:54:37.317919  3315 solver.cpp:218] Iteration 86300 (6.86071 iter/s, 14.5757s/100 iters), loss = 0.00827759
I0927 13:54:37.317961  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827725 (* 1 = 0.00827725 loss)
I0927 13:54:37.317966  3315 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0927 13:54:51.892407  3315 solver.cpp:218] Iteration 86400 (6.86134 iter/s, 14.5744s/100 iters), loss = 0.013416
I0927 13:54:51.892447  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134156 (* 1 = 0.0134156 loss)
I0927 13:54:51.892453  3315 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0927 13:55:05.742511  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:55:06.326370  3315 solver.cpp:330] Iteration 86500, Testing net (#0)
I0927 13:55:09.742621  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:55:09.885745  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9012
I0927 13:55:09.885782  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364819 (* 1 = 0.364819 loss)
I0927 13:55:10.030586  3315 solver.cpp:218] Iteration 86500 (5.51326 iter/s, 18.1381s/100 iters), loss = 0.00391518
I0927 13:55:10.030616  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391483 (* 1 = 0.00391483 loss)
I0927 13:55:10.030622  3315 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0927 13:55:24.602365  3315 solver.cpp:218] Iteration 86600 (6.86261 iter/s, 14.5717s/100 iters), loss = 0.0240106
I0927 13:55:24.602404  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240102 (* 1 = 0.0240102 loss)
I0927 13:55:24.602411  3315 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0927 13:55:39.176692  3315 solver.cpp:218] Iteration 86700 (6.86142 iter/s, 14.5743s/100 iters), loss = 0.0389489
I0927 13:55:39.176810  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389485 (* 1 = 0.0389485 loss)
I0927 13:55:39.176820  3315 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0927 13:55:53.750437  3315 solver.cpp:218] Iteration 86800 (6.86173 iter/s, 14.5736s/100 iters), loss = 0.0197222
I0927 13:55:53.750468  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197219 (* 1 = 0.0197219 loss)
I0927 13:55:53.750473  3315 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0927 13:56:08.325517  3315 solver.cpp:218] Iteration 86900 (6.86106 iter/s, 14.575s/100 iters), loss = 0.0524854
I0927 13:56:08.325547  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.052485 (* 1 = 0.052485 loss)
I0927 13:56:08.325553  3315 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0927 13:56:22.179915  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:56:22.763913  3315 solver.cpp:330] Iteration 87000, Testing net (#0)
I0927 13:56:26.180855  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:56:26.323757  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I0927 13:56:26.323793  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367031 (* 1 = 0.367031 loss)
I0927 13:56:26.468539  3315 solver.cpp:218] Iteration 87000 (5.51178 iter/s, 18.143s/100 iters), loss = 0.0333068
I0927 13:56:26.468569  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333065 (* 1 = 0.0333065 loss)
I0927 13:56:26.468576  3315 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0927 13:56:41.049021  3315 solver.cpp:218] Iteration 87100 (6.85852 iter/s, 14.5804s/100 iters), loss = 0.0177047
I0927 13:56:41.049051  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177044 (* 1 = 0.0177044 loss)
I0927 13:56:41.049057  3315 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0927 13:56:55.629118  3315 solver.cpp:218] Iteration 87200 (6.8587 iter/s, 14.58s/100 iters), loss = 0.0143373
I0927 13:56:55.629233  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143369 (* 1 = 0.0143369 loss)
I0927 13:56:55.629241  3315 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0927 13:57:10.205317  3315 solver.cpp:218] Iteration 87300 (6.86057 iter/s, 14.576s/100 iters), loss = 0.0297509
I0927 13:57:10.205358  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297505 (* 1 = 0.0297505 loss)
I0927 13:57:10.205364  3315 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0927 13:57:24.782510  3315 solver.cpp:218] Iteration 87400 (6.86007 iter/s, 14.5771s/100 iters), loss = 0.00872557
I0927 13:57:24.782551  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00872521 (* 1 = 0.00872521 loss)
I0927 13:57:24.782557  3315 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0927 13:57:38.634017  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:57:39.217775  3315 solver.cpp:330] Iteration 87500, Testing net (#0)
I0927 13:57:42.636945  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:57:42.779834  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I0927 13:57:42.779871  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366946 (* 1 = 0.366946 loss)
I0927 13:57:42.924968  3315 solver.cpp:218] Iteration 87500 (5.51196 iter/s, 18.1424s/100 iters), loss = 0.0354456
I0927 13:57:42.924998  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354452 (* 1 = 0.0354452 loss)
I0927 13:57:42.925004  3315 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0927 13:57:57.514663  3315 solver.cpp:218] Iteration 87600 (6.85418 iter/s, 14.5896s/100 iters), loss = 0.0310076
I0927 13:57:57.514704  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310073 (* 1 = 0.0310073 loss)
I0927 13:57:57.514710  3315 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0927 13:58:12.108427  3315 solver.cpp:218] Iteration 87700 (6.85228 iter/s, 14.5937s/100 iters), loss = 0.00907991
I0927 13:58:12.108534  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00907956 (* 1 = 0.00907956 loss)
I0927 13:58:12.108541  3315 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0927 13:58:26.702239  3315 solver.cpp:218] Iteration 87800 (6.85228 iter/s, 14.5937s/100 iters), loss = 0.0310678
I0927 13:58:26.702280  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310675 (* 1 = 0.0310675 loss)
I0927 13:58:26.702286  3315 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0927 13:58:41.289769  3315 solver.cpp:218] Iteration 87900 (6.85521 iter/s, 14.5875s/100 iters), loss = 0.0109253
I0927 13:58:41.289810  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010925 (* 1 = 0.010925 loss)
I0927 13:58:41.289816  3315 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0927 13:58:55.153373  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:58:55.737632  3315 solver.cpp:330] Iteration 88000, Testing net (#0)
I0927 13:58:59.155022  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 13:58:59.298004  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9021
I0927 13:58:59.298041  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367672 (* 1 = 0.367672 loss)
I0927 13:58:59.443106  3315 solver.cpp:218] Iteration 88000 (5.50866 iter/s, 18.1533s/100 iters), loss = 0.0235619
I0927 13:58:59.443136  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235615 (* 1 = 0.0235615 loss)
I0927 13:58:59.443142  3315 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0927 13:59:14.026710  3315 solver.cpp:218] Iteration 88100 (6.85705 iter/s, 14.5835s/100 iters), loss = 0.0225311
I0927 13:59:14.026751  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225307 (* 1 = 0.0225307 loss)
I0927 13:59:14.026757  3315 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0927 13:59:28.611052  3315 solver.cpp:218] Iteration 88200 (6.85671 iter/s, 14.5843s/100 iters), loss = 0.00763034
I0927 13:59:28.611157  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00762997 (* 1 = 0.00762997 loss)
I0927 13:59:28.611166  3315 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0927 13:59:43.197340  3315 solver.cpp:218] Iteration 88300 (6.85582 iter/s, 14.5861s/100 iters), loss = 0.0101091
I0927 13:59:43.197381  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101087 (* 1 = 0.0101087 loss)
I0927 13:59:43.197387  3315 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0927 13:59:57.785357  3315 solver.cpp:218] Iteration 88400 (6.85498 iter/s, 14.5879s/100 iters), loss = 0.00879306
I0927 13:59:57.785399  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00879267 (* 1 = 0.00879267 loss)
I0927 13:59:57.785404  3315 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0927 14:00:11.644400  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:00:12.227866  3315 solver.cpp:330] Iteration 88500, Testing net (#0)
I0927 14:00:15.645579  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:00:15.788729  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9044
I0927 14:00:15.788765  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368045 (* 1 = 0.368045 loss)
I0927 14:00:15.934001  3315 solver.cpp:218] Iteration 88500 (5.51008 iter/s, 18.1486s/100 iters), loss = 0.00920985
I0927 14:00:15.934031  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00920946 (* 1 = 0.00920946 loss)
I0927 14:00:15.934037  3315 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0927 14:00:30.515357  3315 solver.cpp:218] Iteration 88600 (6.8581 iter/s, 14.5813s/100 iters), loss = 0.00861074
I0927 14:00:30.515398  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00861036 (* 1 = 0.00861036 loss)
I0927 14:00:30.515404  3315 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0927 14:00:45.101222  3315 solver.cpp:218] Iteration 88700 (6.85599 iter/s, 14.5858s/100 iters), loss = 0.0095261
I0927 14:00:45.101305  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0095257 (* 1 = 0.0095257 loss)
I0927 14:00:45.101311  3315 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0927 14:00:59.682869  3315 solver.cpp:218] Iteration 88800 (6.85799 iter/s, 14.5815s/100 iters), loss = 0.00880421
I0927 14:00:59.682911  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00880382 (* 1 = 0.00880382 loss)
I0927 14:00:59.682917  3315 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0927 14:01:14.267320  3315 solver.cpp:218] Iteration 88900 (6.85665 iter/s, 14.5844s/100 iters), loss = 0.0107272
I0927 14:01:14.267361  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107268 (* 1 = 0.0107268 loss)
I0927 14:01:14.267367  3315 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0927 14:01:28.127434  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:01:28.711438  3315 solver.cpp:330] Iteration 89000, Testing net (#0)
I0927 14:01:32.130367  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:01:32.273685  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I0927 14:01:32.273721  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366357 (* 1 = 0.366357 loss)
I0927 14:01:32.418635  3315 solver.cpp:218] Iteration 89000 (5.50927 iter/s, 18.1512s/100 iters), loss = 0.0142249
I0927 14:01:32.418664  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142245 (* 1 = 0.0142245 loss)
I0927 14:01:32.418670  3315 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0927 14:01:46.999281  3315 solver.cpp:218] Iteration 89100 (6.85844 iter/s, 14.5806s/100 iters), loss = 0.0194044
I0927 14:01:46.999323  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019404 (* 1 = 0.019404 loss)
I0927 14:01:46.999330  3315 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0927 14:02:01.581713  3315 solver.cpp:218] Iteration 89200 (6.8576 iter/s, 14.5824s/100 iters), loss = 0.0339513
I0927 14:02:01.581781  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339509 (* 1 = 0.0339509 loss)
I0927 14:02:01.581797  3315 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0927 14:02:16.166858  3315 solver.cpp:218] Iteration 89300 (6.85634 iter/s, 14.585s/100 iters), loss = 0.0283406
I0927 14:02:16.166890  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283402 (* 1 = 0.0283402 loss)
I0927 14:02:16.166896  3315 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0927 14:02:30.760610  3315 solver.cpp:218] Iteration 89400 (6.85228 iter/s, 14.5937s/100 iters), loss = 0.0196538
I0927 14:02:30.760641  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196534 (* 1 = 0.0196534 loss)
I0927 14:02:30.760648  3315 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0927 14:02:44.623706  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:02:45.207401  3315 solver.cpp:330] Iteration 89500, Testing net (#0)
I0927 14:02:48.624166  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:02:48.767313  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9062
I0927 14:02:48.767351  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367345 (* 1 = 0.367345 loss)
I0927 14:02:48.912072  3315 solver.cpp:218] Iteration 89500 (5.50922 iter/s, 18.1514s/100 iters), loss = 0.0155659
I0927 14:02:48.912101  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155655 (* 1 = 0.0155655 loss)
I0927 14:02:48.912108  3315 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0927 14:03:03.488885  3315 solver.cpp:218] Iteration 89600 (6.86024 iter/s, 14.5767s/100 iters), loss = 0.0149157
I0927 14:03:03.488916  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149153 (* 1 = 0.0149153 loss)
I0927 14:03:03.488922  3315 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0927 14:03:18.075976  3315 solver.cpp:218] Iteration 89700 (6.85541 iter/s, 14.587s/100 iters), loss = 0.0102325
I0927 14:03:18.076110  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102321 (* 1 = 0.0102321 loss)
I0927 14:03:18.076117  3315 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0927 14:03:32.658897  3315 solver.cpp:218] Iteration 89800 (6.85741 iter/s, 14.5828s/100 iters), loss = 0.0183325
I0927 14:03:32.658938  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183321 (* 1 = 0.0183321 loss)
I0927 14:03:32.658944  3315 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0927 14:03:47.239362  3315 solver.cpp:218] Iteration 89900 (6.85853 iter/s, 14.5804s/100 iters), loss = 0.00984083
I0927 14:03:47.239403  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00984044 (* 1 = 0.00984044 loss)
I0927 14:03:47.239408  3315 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0927 14:04:01.097012  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:04:01.681372  3315 solver.cpp:330] Iteration 90000, Testing net (#0)
I0927 14:04:05.098551  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:04:05.241255  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9054
I0927 14:04:05.241292  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366887 (* 1 = 0.366887 loss)
I0927 14:04:05.386652  3315 solver.cpp:218] Iteration 90000 (5.51049 iter/s, 18.1472s/100 iters), loss = 0.0193505
I0927 14:04:05.386680  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193501 (* 1 = 0.0193501 loss)
I0927 14:04:05.386687  3315 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0927 14:04:19.972991  3315 solver.cpp:218] Iteration 90100 (6.85576 iter/s, 14.5863s/100 iters), loss = 0.00756789
I0927 14:04:19.973031  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00756749 (* 1 = 0.00756749 loss)
I0927 14:04:19.973037  3315 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0927 14:04:34.558404  3315 solver.cpp:218] Iteration 90200 (6.8562 iter/s, 14.5853s/100 iters), loss = 0.00473907
I0927 14:04:34.558481  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473867 (* 1 = 0.00473867 loss)
I0927 14:04:34.558488  3315 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0927 14:04:49.146231  3315 solver.cpp:218] Iteration 90300 (6.85508 iter/s, 14.5877s/100 iters), loss = 0.00807302
I0927 14:04:49.146272  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00807262 (* 1 = 0.00807262 loss)
I0927 14:04:49.146278  3315 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0927 14:05:03.731994  3315 solver.cpp:218] Iteration 90400 (6.85604 iter/s, 14.5857s/100 iters), loss = 0.0147032
I0927 14:05:03.732035  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147028 (* 1 = 0.0147028 loss)
I0927 14:05:03.732041  3315 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0927 14:05:17.594528  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:05:18.178902  3315 solver.cpp:330] Iteration 90500, Testing net (#0)
I0927 14:05:21.594223  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:05:21.737228  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I0927 14:05:21.737265  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368985 (* 1 = 0.368985 loss)
I0927 14:05:21.882345  3315 solver.cpp:218] Iteration 90500 (5.50956 iter/s, 18.1503s/100 iters), loss = 0.0244592
I0927 14:05:21.882375  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244588 (* 1 = 0.0244588 loss)
I0927 14:05:21.882382  3315 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0927 14:05:36.465137  3315 solver.cpp:218] Iteration 90600 (6.85743 iter/s, 14.5827s/100 iters), loss = 0.0146557
I0927 14:05:36.465179  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146553 (* 1 = 0.0146553 loss)
I0927 14:05:36.465184  3315 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0927 14:05:51.049784  3315 solver.cpp:218] Iteration 90700 (6.85656 iter/s, 14.5846s/100 iters), loss = 0.0256819
I0927 14:05:51.049865  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256815 (* 1 = 0.0256815 loss)
I0927 14:05:51.049881  3315 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0927 14:06:05.629129  3315 solver.cpp:218] Iteration 90800 (6.85907 iter/s, 14.5792s/100 iters), loss = 0.0245212
I0927 14:06:05.629170  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245208 (* 1 = 0.0245208 loss)
I0927 14:06:05.629176  3315 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0927 14:06:20.211199  3315 solver.cpp:218] Iteration 90900 (6.85777 iter/s, 14.582s/100 iters), loss = 0.0136725
I0927 14:06:20.211228  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136721 (* 1 = 0.0136721 loss)
I0927 14:06:20.211233  3315 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0927 14:06:34.071588  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:06:34.655756  3315 solver.cpp:330] Iteration 91000, Testing net (#0)
I0927 14:06:38.073802  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:06:38.216795  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I0927 14:06:38.216832  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368883 (* 1 = 0.368883 loss)
I0927 14:06:38.361872  3315 solver.cpp:218] Iteration 91000 (5.50946 iter/s, 18.1506s/100 iters), loss = 0.0182563
I0927 14:06:38.361902  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182558 (* 1 = 0.0182558 loss)
I0927 14:06:38.361909  3315 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0927 14:06:52.932595  3315 solver.cpp:218] Iteration 91100 (6.86311 iter/s, 14.5707s/100 iters), loss = 0.011672
I0927 14:06:52.932634  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116716 (* 1 = 0.0116716 loss)
I0927 14:06:52.932641  3315 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0927 14:07:07.510342  3315 solver.cpp:218] Iteration 91200 (6.85981 iter/s, 14.5777s/100 iters), loss = 0.00759331
I0927 14:07:07.510453  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00759289 (* 1 = 0.00759289 loss)
I0927 14:07:07.510471  3315 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0927 14:07:22.088909  3315 solver.cpp:218] Iteration 91300 (6.85945 iter/s, 14.5784s/100 iters), loss = 0.0160788
I0927 14:07:22.088949  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160783 (* 1 = 0.0160783 loss)
I0927 14:07:22.088955  3315 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0927 14:07:36.663117  3315 solver.cpp:218] Iteration 91400 (6.86147 iter/s, 14.5741s/100 iters), loss = 0.00732119
I0927 14:07:36.663157  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00732078 (* 1 = 0.00732078 loss)
I0927 14:07:36.663164  3315 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0927 14:07:50.518781  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:07:51.101871  3315 solver.cpp:330] Iteration 91500, Testing net (#0)
I0927 14:07:54.520157  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:07:54.663456  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I0927 14:07:54.663493  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37163 (* 1 = 0.37163 loss)
I0927 14:07:54.808183  3315 solver.cpp:218] Iteration 91500 (5.51117 iter/s, 18.145s/100 iters), loss = 0.011769
I0927 14:07:54.808213  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117686 (* 1 = 0.0117686 loss)
I0927 14:07:54.808220  3315 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0927 14:08:09.386325  3315 solver.cpp:218] Iteration 91600 (6.85962 iter/s, 14.5781s/100 iters), loss = 0.0100492
I0927 14:08:09.386366  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100487 (* 1 = 0.0100487 loss)
I0927 14:08:09.386373  3315 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0927 14:08:23.966029  3315 solver.cpp:218] Iteration 91700 (6.85889 iter/s, 14.5796s/100 iters), loss = 0.00542228
I0927 14:08:23.966120  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542185 (* 1 = 0.00542185 loss)
I0927 14:08:23.966135  3315 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0927 14:08:38.549609  3315 solver.cpp:218] Iteration 91800 (6.85709 iter/s, 14.5835s/100 iters), loss = 0.0205359
I0927 14:08:38.549650  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205354 (* 1 = 0.0205354 loss)
I0927 14:08:38.549657  3315 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0927 14:08:53.124902  3315 solver.cpp:218] Iteration 91900 (6.86096 iter/s, 14.5752s/100 iters), loss = 0.011529
I0927 14:08:53.124941  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115285 (* 1 = 0.0115285 loss)
I0927 14:08:53.124948  3315 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0927 14:09:06.986174  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:09:07.570116  3315 solver.cpp:330] Iteration 92000, Testing net (#0)
I0927 14:09:10.987522  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:09:11.130887  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904
I0927 14:09:11.130925  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37034 (* 1 = 0.37034 loss)
I0927 14:09:11.275588  3315 solver.cpp:218] Iteration 92000 (5.50946 iter/s, 18.1506s/100 iters), loss = 0.0164398
I0927 14:09:11.275617  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164394 (* 1 = 0.0164394 loss)
I0927 14:09:11.275624  3315 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0927 14:09:25.854957  3315 solver.cpp:218] Iteration 92100 (6.85904 iter/s, 14.5793s/100 iters), loss = 0.0102987
I0927 14:09:25.855005  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102983 (* 1 = 0.0102983 loss)
I0927 14:09:25.855012  3315 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0927 14:09:40.442170  3315 solver.cpp:218] Iteration 92200 (6.85536 iter/s, 14.5871s/100 iters), loss = 0.0227621
I0927 14:09:40.442260  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227616 (* 1 = 0.0227616 loss)
I0927 14:09:40.442268  3315 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0927 14:09:55.023187  3315 solver.cpp:218] Iteration 92300 (6.85829 iter/s, 14.5809s/100 iters), loss = 0.013376
I0927 14:09:55.023228  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133755 (* 1 = 0.0133755 loss)
I0927 14:09:55.023234  3315 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0927 14:10:09.603821  3315 solver.cpp:218] Iteration 92400 (6.85845 iter/s, 14.5806s/100 iters), loss = 0.00403494
I0927 14:10:09.603863  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403451 (* 1 = 0.00403451 loss)
I0927 14:10:09.603868  3315 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0927 14:10:23.459483  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:10:24.043581  3315 solver.cpp:330] Iteration 92500, Testing net (#0)
I0927 14:10:27.462613  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:10:27.605748  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I0927 14:10:27.605785  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373378 (* 1 = 0.373378 loss)
I0927 14:10:27.750957  3315 solver.cpp:218] Iteration 92500 (5.51054 iter/s, 18.1471s/100 iters), loss = 0.00754888
I0927 14:10:27.750984  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00754845 (* 1 = 0.00754845 loss)
I0927 14:10:27.750991  3315 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0927 14:10:42.323194  3315 solver.cpp:218] Iteration 92600 (6.86239 iter/s, 14.5722s/100 iters), loss = 0.0222533
I0927 14:10:42.323233  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222529 (* 1 = 0.0222529 loss)
I0927 14:10:42.323240  3315 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0927 14:10:56.898653  3315 solver.cpp:218] Iteration 92700 (6.86088 iter/s, 14.5754s/100 iters), loss = 0.00501131
I0927 14:10:56.898783  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00501088 (* 1 = 0.00501088 loss)
I0927 14:10:56.898790  3315 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0927 14:11:11.475638  3315 solver.cpp:218] Iteration 92800 (6.8602 iter/s, 14.5768s/100 iters), loss = 0.0054887
I0927 14:11:11.475679  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548827 (* 1 = 0.00548827 loss)
I0927 14:11:11.475685  3315 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0927 14:11:26.052711  3315 solver.cpp:218] Iteration 92900 (6.86013 iter/s, 14.577s/100 iters), loss = 0.00410338
I0927 14:11:26.052752  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410295 (* 1 = 0.00410295 loss)
I0927 14:11:26.052757  3315 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0927 14:11:39.907590  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:11:40.492112  3315 solver.cpp:330] Iteration 93000, Testing net (#0)
I0927 14:11:43.909639  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:11:44.052765  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I0927 14:11:44.052803  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373796 (* 1 = 0.373796 loss)
I0927 14:11:44.197492  3315 solver.cpp:218] Iteration 93000 (5.51125 iter/s, 18.1447s/100 iters), loss = 0.00700243
I0927 14:11:44.197523  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.007002 (* 1 = 0.007002 loss)
I0927 14:11:44.197530  3315 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0927 14:11:58.779705  3315 solver.cpp:218] Iteration 93100 (6.8577 iter/s, 14.5821s/100 iters), loss = 0.0119525
I0927 14:11:58.779745  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011952 (* 1 = 0.011952 loss)
I0927 14:11:58.779752  3315 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0927 14:12:13.376003  3315 solver.cpp:218] Iteration 93200 (6.85109 iter/s, 14.5962s/100 iters), loss = 0.0105595
I0927 14:12:13.376121  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105591 (* 1 = 0.0105591 loss)
I0927 14:12:13.376139  3315 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0927 14:12:27.966315  3315 solver.cpp:218] Iteration 93300 (6.85394 iter/s, 14.5902s/100 iters), loss = 0.0165928
I0927 14:12:27.966356  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165924 (* 1 = 0.0165924 loss)
I0927 14:12:27.966362  3315 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0927 14:12:42.552875  3315 solver.cpp:218] Iteration 93400 (6.85566 iter/s, 14.5865s/100 iters), loss = 0.00723739
I0927 14:12:42.552906  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00723696 (* 1 = 0.00723696 loss)
I0927 14:12:42.552911  3315 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0927 14:12:56.415992  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:12:57.000238  3315 solver.cpp:330] Iteration 93500, Testing net (#0)
I0927 14:13:00.419062  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:13:00.561884  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I0927 14:13:00.561923  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37446 (* 1 = 0.37446 loss)
I0927 14:13:00.707103  3315 solver.cpp:218] Iteration 93500 (5.50838 iter/s, 18.1542s/100 iters), loss = 0.0180398
I0927 14:13:00.707134  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180394 (* 1 = 0.0180394 loss)
I0927 14:13:00.707140  3315 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0927 14:13:15.299335  3315 solver.cpp:218] Iteration 93600 (6.85299 iter/s, 14.5922s/100 iters), loss = 0.0142271
I0927 14:13:15.299377  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142266 (* 1 = 0.0142266 loss)
I0927 14:13:15.299383  3315 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0927 14:13:29.900040  3315 solver.cpp:218] Iteration 93700 (6.84902 iter/s, 14.6006s/100 iters), loss = 0.00918798
I0927 14:13:29.900169  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00918754 (* 1 = 0.00918754 loss)
I0927 14:13:29.900177  3315 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0927 14:13:44.496685  3315 solver.cpp:218] Iteration 93800 (6.85097 iter/s, 14.5965s/100 iters), loss = 0.00674159
I0927 14:13:44.496716  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00674116 (* 1 = 0.00674116 loss)
I0927 14:13:44.496721  3315 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0927 14:13:59.101215  3315 solver.cpp:218] Iteration 93900 (6.84722 iter/s, 14.6045s/100 iters), loss = 0.00487203
I0927 14:13:59.101256  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0048716 (* 1 = 0.0048716 loss)
I0927 14:13:59.101263  3315 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0927 14:14:12.976519  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:14:13.561005  3315 solver.cpp:330] Iteration 94000, Testing net (#0)
I0927 14:14:16.978206  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:14:17.121286  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I0927 14:14:17.121322  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374111 (* 1 = 0.374111 loss)
I0927 14:14:17.265841  3315 solver.cpp:218] Iteration 94000 (5.50523 iter/s, 18.1645s/100 iters), loss = 0.00777042
I0927 14:14:17.265871  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776998 (* 1 = 0.00776998 loss)
I0927 14:14:17.265877  3315 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0927 14:14:31.834404  3315 solver.cpp:218] Iteration 94100 (6.86413 iter/s, 14.5685s/100 iters), loss = 0.00727375
I0927 14:14:31.834445  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727331 (* 1 = 0.00727331 loss)
I0927 14:14:31.834451  3315 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0927 14:14:46.412906  3315 solver.cpp:218] Iteration 94200 (6.85945 iter/s, 14.5784s/100 iters), loss = 0.00481286
I0927 14:14:46.413012  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481243 (* 1 = 0.00481243 loss)
I0927 14:14:46.413018  3315 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0927 14:15:00.990528  3315 solver.cpp:218] Iteration 94300 (6.8599 iter/s, 14.5775s/100 iters), loss = 0.0156896
I0927 14:15:00.990569  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156892 (* 1 = 0.0156892 loss)
I0927 14:15:00.990576  3315 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0927 14:15:15.565389  3315 solver.cpp:218] Iteration 94400 (6.86117 iter/s, 14.5748s/100 iters), loss = 0.00993166
I0927 14:15:15.565420  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00993124 (* 1 = 0.00993124 loss)
I0927 14:15:15.565441  3315 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0927 14:15:29.418144  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:15:30.002449  3315 solver.cpp:330] Iteration 94500, Testing net (#0)
I0927 14:15:33.421195  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:15:33.564146  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I0927 14:15:33.564183  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376661 (* 1 = 0.376661 loss)
I0927 14:15:33.709028  3315 solver.cpp:218] Iteration 94500 (5.5116 iter/s, 18.1436s/100 iters), loss = 0.0344523
I0927 14:15:33.709056  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344519 (* 1 = 0.0344519 loss)
I0927 14:15:33.709064  3315 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0927 14:15:48.291072  3315 solver.cpp:218] Iteration 94600 (6.85778 iter/s, 14.582s/100 iters), loss = 0.0254369
I0927 14:15:48.291103  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254365 (* 1 = 0.0254365 loss)
I0927 14:15:48.291110  3315 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0927 14:16:02.878724  3315 solver.cpp:218] Iteration 94700 (6.85514 iter/s, 14.5876s/100 iters), loss = 0.0146972
I0927 14:16:02.878888  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146968 (* 1 = 0.0146968 loss)
I0927 14:16:02.878906  3315 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0927 14:16:17.468987  3315 solver.cpp:218] Iteration 94800 (6.85398 iter/s, 14.5901s/100 iters), loss = 0.00840538
I0927 14:16:17.469027  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00840496 (* 1 = 0.00840496 loss)
I0927 14:16:17.469033  3315 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0927 14:16:32.055266  3315 solver.cpp:218] Iteration 94900 (6.85579 iter/s, 14.5862s/100 iters), loss = 0.00908562
I0927 14:16:32.055299  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00908521 (* 1 = 0.00908521 loss)
I0927 14:16:32.055305  3315 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0927 14:16:45.915688  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:16:46.498515  3315 solver.cpp:330] Iteration 95000, Testing net (#0)
I0927 14:16:49.914803  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:16:50.057891  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I0927 14:16:50.057917  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376318 (* 1 = 0.376318 loss)
I0927 14:16:50.202633  3315 solver.cpp:218] Iteration 95000 (5.51046 iter/s, 18.1473s/100 iters), loss = 0.00776303
I0927 14:16:50.202662  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776261 (* 1 = 0.00776261 loss)
I0927 14:16:50.202668  3315 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0927 14:17:04.779932  3315 solver.cpp:218] Iteration 95100 (6.86001 iter/s, 14.5772s/100 iters), loss = 0.00490238
I0927 14:17:04.779973  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490196 (* 1 = 0.00490196 loss)
I0927 14:17:04.779979  3315 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0927 14:17:19.350697  3315 solver.cpp:218] Iteration 95200 (6.86309 iter/s, 14.5707s/100 iters), loss = 0.0342011
I0927 14:17:19.350817  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342007 (* 1 = 0.0342007 loss)
I0927 14:17:19.350834  3315 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0927 14:17:33.927942  3315 solver.cpp:218] Iteration 95300 (6.86008 iter/s, 14.5771s/100 iters), loss = 0.0128112
I0927 14:17:33.927983  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128108 (* 1 = 0.0128108 loss)
I0927 14:17:33.927989  3315 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0927 14:17:48.501071  3315 solver.cpp:218] Iteration 95400 (6.86198 iter/s, 14.5731s/100 iters), loss = 0.00919829
I0927 14:17:48.501112  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00919788 (* 1 = 0.00919788 loss)
I0927 14:17:48.501118  3315 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0927 14:18:02.355022  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:18:02.938725  3315 solver.cpp:330] Iteration 95500, Testing net (#0)
I0927 14:18:06.354845  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:18:06.497767  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I0927 14:18:06.497794  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381596 (* 1 = 0.381596 loss)
I0927 14:18:06.642000  3315 solver.cpp:218] Iteration 95500 (5.51242 iter/s, 18.1408s/100 iters), loss = 0.00382228
I0927 14:18:06.642030  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382186 (* 1 = 0.00382186 loss)
I0927 14:18:06.642037  3315 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0927 14:18:21.219643  3315 solver.cpp:218] Iteration 95600 (6.85985 iter/s, 14.5776s/100 iters), loss = 0.0242416
I0927 14:18:21.219674  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242412 (* 1 = 0.0242412 loss)
I0927 14:18:21.219681  3315 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0927 14:18:35.798135  3315 solver.cpp:218] Iteration 95700 (6.85945 iter/s, 14.5784s/100 iters), loss = 0.0284315
I0927 14:18:35.798280  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284311 (* 1 = 0.0284311 loss)
I0927 14:18:35.798296  3315 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0927 14:18:50.378011  3315 solver.cpp:218] Iteration 95800 (6.85885 iter/s, 14.5797s/100 iters), loss = 0.0139875
I0927 14:18:50.378042  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139871 (* 1 = 0.0139871 loss)
I0927 14:18:50.378048  3315 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0927 14:19:04.949481  3315 solver.cpp:218] Iteration 95900 (6.86276 iter/s, 14.5714s/100 iters), loss = 0.00539647
I0927 14:19:04.949523  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539606 (* 1 = 0.00539606 loss)
I0927 14:19:04.949529  3315 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0927 14:19:18.802455  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:19:19.386739  3315 solver.cpp:330] Iteration 96000, Testing net (#0)
I0927 14:19:22.804018  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:19:22.946560  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I0927 14:19:22.946597  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379868 (* 1 = 0.379868 loss)
I0927 14:19:23.091785  3315 solver.cpp:218] Iteration 96000 (5.51201 iter/s, 18.1422s/100 iters), loss = 0.0168662
I0927 14:19:23.091815  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168658 (* 1 = 0.0168658 loss)
I0927 14:19:23.091822  3315 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0927 14:19:37.689290  3315 solver.cpp:218] Iteration 96100 (6.85052 iter/s, 14.5974s/100 iters), loss = 0.0096146
I0927 14:19:37.689330  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00961421 (* 1 = 0.00961421 loss)
I0927 14:19:37.689337  3315 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0927 14:19:52.293665  3315 solver.cpp:218] Iteration 96200 (6.8473 iter/s, 14.6043s/100 iters), loss = 0.0201799
I0927 14:19:52.293774  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201795 (* 1 = 0.0201795 loss)
I0927 14:19:52.293781  3315 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0927 14:20:06.897240  3315 solver.cpp:218] Iteration 96300 (6.8477 iter/s, 14.6034s/100 iters), loss = 0.0103411
I0927 14:20:06.897270  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103407 (* 1 = 0.0103407 loss)
I0927 14:20:06.897276  3315 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0927 14:20:21.497076  3315 solver.cpp:218] Iteration 96400 (6.84942 iter/s, 14.5998s/100 iters), loss = 0.00910597
I0927 14:20:21.497103  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910556 (* 1 = 0.00910556 loss)
I0927 14:20:21.497109  3315 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0927 14:20:35.375325  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:20:35.959908  3315 solver.cpp:330] Iteration 96500, Testing net (#0)
I0927 14:20:39.376585  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:20:39.519961  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9042
I0927 14:20:39.519999  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380027 (* 1 = 0.380027 loss)
I0927 14:20:39.665222  3315 solver.cpp:218] Iteration 96500 (5.50416 iter/s, 18.1681s/100 iters), loss = 0.00896856
I0927 14:20:39.665252  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00896815 (* 1 = 0.00896815 loss)
I0927 14:20:39.665258  3315 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0927 14:20:54.238402  3315 solver.cpp:218] Iteration 96600 (6.86195 iter/s, 14.5731s/100 iters), loss = 0.0192014
I0927 14:20:54.238445  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019201 (* 1 = 0.019201 loss)
I0927 14:20:54.238451  3315 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0927 14:21:08.820906  3315 solver.cpp:218] Iteration 96700 (6.85757 iter/s, 14.5824s/100 iters), loss = 0.00751176
I0927 14:21:08.821033  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00751136 (* 1 = 0.00751136 loss)
I0927 14:21:08.821041  3315 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0927 14:21:23.405563  3315 solver.cpp:218] Iteration 96800 (6.8566 iter/s, 14.5845s/100 iters), loss = 0.0335941
I0927 14:21:23.405604  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335937 (* 1 = 0.0335937 loss)
I0927 14:21:23.405611  3315 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0927 14:21:37.990633  3315 solver.cpp:218] Iteration 96900 (6.85636 iter/s, 14.585s/100 iters), loss = 0.00661318
I0927 14:21:37.990674  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00661277 (* 1 = 0.00661277 loss)
I0927 14:21:37.990679  3315 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0927 14:21:51.851910  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:21:52.435099  3315 solver.cpp:330] Iteration 97000, Testing net (#0)
I0927 14:21:55.850674  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:21:55.992976  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9043
I0927 14:21:55.993015  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383353 (* 1 = 0.383353 loss)
I0927 14:21:56.138420  3315 solver.cpp:218] Iteration 97000 (5.51034 iter/s, 18.1477s/100 iters), loss = 0.0101316
I0927 14:21:56.138449  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101312 (* 1 = 0.0101312 loss)
I0927 14:21:56.138456  3315 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0927 14:22:10.720656  3315 solver.cpp:218] Iteration 97100 (6.85769 iter/s, 14.5822s/100 iters), loss = 0.00338838
I0927 14:22:10.720700  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338797 (* 1 = 0.00338797 loss)
I0927 14:22:10.720705  3315 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0927 14:22:25.305375  3315 solver.cpp:218] Iteration 97200 (6.85653 iter/s, 14.5846s/100 iters), loss = 0.00707494
I0927 14:22:25.305477  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707452 (* 1 = 0.00707452 loss)
I0927 14:22:25.305485  3315 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0927 14:22:39.887193  3315 solver.cpp:218] Iteration 97300 (6.85792 iter/s, 14.5817s/100 iters), loss = 0.00790108
I0927 14:22:39.887226  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790066 (* 1 = 0.00790066 loss)
I0927 14:22:39.887231  3315 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0927 14:22:54.468448  3315 solver.cpp:218] Iteration 97400 (6.85815 iter/s, 14.5812s/100 iters), loss = 0.00497934
I0927 14:22:54.468490  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497893 (* 1 = 0.00497893 loss)
I0927 14:22:54.468497  3315 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0927 14:23:08.327092  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:23:08.910717  3315 solver.cpp:330] Iteration 97500, Testing net (#0)
I0927 14:23:12.327582  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:23:12.470964  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I0927 14:23:12.471001  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378706 (* 1 = 0.378706 loss)
I0927 14:23:12.615643  3315 solver.cpp:218] Iteration 97500 (5.51052 iter/s, 18.1471s/100 iters), loss = 0.00700397
I0927 14:23:12.615674  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700357 (* 1 = 0.00700357 loss)
I0927 14:23:12.615679  3315 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0927 14:23:27.190254  3315 solver.cpp:218] Iteration 97600 (6.86128 iter/s, 14.5745s/100 iters), loss = 0.0159873
I0927 14:23:27.190295  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159869 (* 1 = 0.0159869 loss)
I0927 14:23:27.190300  3315 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0927 14:23:41.768695  3315 solver.cpp:218] Iteration 97700 (6.85948 iter/s, 14.5784s/100 iters), loss = 0.0195311
I0927 14:23:41.768784  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195307 (* 1 = 0.0195307 loss)
I0927 14:23:41.768790  3315 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0927 14:23:56.349635  3315 solver.cpp:218] Iteration 97800 (6.85833 iter/s, 14.5808s/100 iters), loss = 0.0167868
I0927 14:23:56.349676  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167864 (* 1 = 0.0167864 loss)
I0927 14:23:56.349683  3315 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0927 14:24:10.923287  3315 solver.cpp:218] Iteration 97900 (6.86173 iter/s, 14.5736s/100 iters), loss = 0.00426701
I0927 14:24:10.923329  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426661 (* 1 = 0.00426661 loss)
I0927 14:24:10.923334  3315 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0927 14:24:24.769492  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:24:25.352332  3315 solver.cpp:330] Iteration 98000, Testing net (#0)
I0927 14:24:28.769788  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:24:28.912240  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I0927 14:24:28.912277  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380272 (* 1 = 0.380272 loss)
I0927 14:24:29.057366  3315 solver.cpp:218] Iteration 98000 (5.5145 iter/s, 18.134s/100 iters), loss = 0.02369
I0927 14:24:29.057396  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236896 (* 1 = 0.0236896 loss)
I0927 14:24:29.057404  3315 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0927 14:24:43.642832  3315 solver.cpp:218] Iteration 98100 (6.85617 iter/s, 14.5854s/100 iters), loss = 0.0225545
I0927 14:24:43.642875  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225541 (* 1 = 0.0225541 loss)
I0927 14:24:43.642881  3315 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0927 14:24:58.232288  3315 solver.cpp:218] Iteration 98200 (6.8543 iter/s, 14.5894s/100 iters), loss = 0.0241051
I0927 14:24:58.232362  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241047 (* 1 = 0.0241047 loss)
I0927 14:24:58.232368  3315 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0927 14:25:12.817818  3315 solver.cpp:218] Iteration 98300 (6.85616 iter/s, 14.5854s/100 iters), loss = 0.0093942
I0927 14:25:12.817860  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00939381 (* 1 = 0.00939381 loss)
I0927 14:25:12.817867  3315 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0927 14:25:27.408154  3315 solver.cpp:218] Iteration 98400 (6.85389 iter/s, 14.5903s/100 iters), loss = 0.0126293
I0927 14:25:27.408195  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126289 (* 1 = 0.0126289 loss)
I0927 14:25:27.408200  3315 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0927 14:25:41.267230  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:25:41.851191  3315 solver.cpp:330] Iteration 98500, Testing net (#0)
I0927 14:25:45.267047  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:25:45.409806  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I0927 14:25:45.409832  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379969 (* 1 = 0.379969 loss)
I0927 14:25:45.555616  3315 solver.cpp:218] Iteration 98500 (5.51044 iter/s, 18.1474s/100 iters), loss = 0.0132284
I0927 14:25:45.555646  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013228 (* 1 = 0.013228 loss)
I0927 14:25:45.555654  3315 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0927 14:26:00.152415  3315 solver.cpp:218] Iteration 98600 (6.85085 iter/s, 14.5967s/100 iters), loss = 0.0053106
I0927 14:26:00.152446  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00531021 (* 1 = 0.00531021 loss)
I0927 14:26:00.152451  3315 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0927 14:26:14.741721  3315 solver.cpp:218] Iteration 98700 (6.85437 iter/s, 14.5892s/100 iters), loss = 0.0268117
I0927 14:26:14.741844  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268113 (* 1 = 0.0268113 loss)
I0927 14:26:14.741852  3315 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0927 14:26:29.338140  3315 solver.cpp:218] Iteration 98800 (6.85107 iter/s, 14.5963s/100 iters), loss = 0.0109341
I0927 14:26:29.338181  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109337 (* 1 = 0.0109337 loss)
I0927 14:26:29.338186  3315 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0927 14:26:43.928807  3315 solver.cpp:218] Iteration 98900 (6.85373 iter/s, 14.5906s/100 iters), loss = 0.00471057
I0927 14:26:43.928848  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471018 (* 1 = 0.00471018 loss)
I0927 14:26:43.928854  3315 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0927 14:26:57.795191  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:26:58.379386  3315 solver.cpp:330] Iteration 99000, Testing net (#0)
I0927 14:27:01.797046  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:27:01.939882  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I0927 14:27:01.939919  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380597 (* 1 = 0.380597 loss)
I0927 14:27:02.085094  3315 solver.cpp:218] Iteration 99000 (5.50776 iter/s, 18.1562s/100 iters), loss = 0.0234809
I0927 14:27:02.085124  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234805 (* 1 = 0.0234805 loss)
I0927 14:27:02.085132  3315 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0927 14:27:16.652462  3315 solver.cpp:218] Iteration 99100 (6.86469 iter/s, 14.5673s/100 iters), loss = 0.0312934
I0927 14:27:16.652503  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031293 (* 1 = 0.031293 loss)
I0927 14:27:16.652509  3315 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0927 14:27:31.221438  3315 solver.cpp:218] Iteration 99200 (6.86394 iter/s, 14.5689s/100 iters), loss = 0.00601481
I0927 14:27:31.221575  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601443 (* 1 = 0.00601443 loss)
I0927 14:27:31.221582  3315 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0927 14:27:45.791005  3315 solver.cpp:218] Iteration 99300 (6.8637 iter/s, 14.5694s/100 iters), loss = 0.0213462
I0927 14:27:45.791046  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213458 (* 1 = 0.0213458 loss)
I0927 14:27:45.791051  3315 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0927 14:28:00.367380  3315 solver.cpp:218] Iteration 99400 (6.86045 iter/s, 14.5763s/100 iters), loss = 0.0182555
I0927 14:28:00.367410  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182551 (* 1 = 0.0182551 loss)
I0927 14:28:00.367416  3315 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0927 14:28:14.220531  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:28:14.803743  3315 solver.cpp:330] Iteration 99500, Testing net (#0)
I0927 14:28:18.220186  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:28:18.363220  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9039
I0927 14:28:18.363257  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379313 (* 1 = 0.379313 loss)
I0927 14:28:18.508586  3315 solver.cpp:218] Iteration 99500 (5.51234 iter/s, 18.1411s/100 iters), loss = 0.00719689
I0927 14:28:18.508616  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0071965 (* 1 = 0.0071965 loss)
I0927 14:28:18.508622  3315 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0927 14:28:33.083807  3315 solver.cpp:218] Iteration 99600 (6.86099 iter/s, 14.5752s/100 iters), loss = 0.00574625
I0927 14:28:33.083849  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574585 (* 1 = 0.00574585 loss)
I0927 14:28:33.083855  3315 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0927 14:28:47.667384  3315 solver.cpp:218] Iteration 99700 (6.85707 iter/s, 14.5835s/100 iters), loss = 0.00825624
I0927 14:28:47.667541  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825585 (* 1 = 0.00825585 loss)
I0927 14:28:47.667557  3315 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0927 14:29:02.247099  3315 solver.cpp:218] Iteration 99800 (6.85893 iter/s, 14.5795s/100 iters), loss = 0.00810791
I0927 14:29:02.247129  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810752 (* 1 = 0.00810752 loss)
I0927 14:29:02.247135  3315 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0927 14:29:16.825631  3315 solver.cpp:218] Iteration 99900 (6.85943 iter/s, 14.5785s/100 iters), loss = 0.0148584
I0927 14:29:16.825672  3315 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014858 (* 1 = 0.014858 loss)
I0927 14:29:16.825678  3315 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0927 14:29:30.683449  3324 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:29:31.267065  3315 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_eta_nostudy_gauss_iter_100000.caffemodel
I0927 14:29:31.294203  3315 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_penlu_alpha2_eta1_eta_nostudy_gauss_iter_100000.solverstate
I0927 14:29:31.335535  3315 solver.cpp:310] Iteration 100000, loss = 0.00404942
I0927 14:29:31.335556  3315 solver.cpp:330] Iteration 100000, Testing net (#0)
I0927 14:29:34.750658  3325 data_layer.cpp:73] Restarting data prefetching from start.
I0927 14:29:34.893527  3315 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I0927 14:29:34.893564  3315 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38472 (* 1 = 0.38472 loss)
I0927 14:29:34.893568  3315 solver.cpp:315] Optimization Done.
I0927 14:29:34.893571  3315 caffe.cpp:259] Optimization Done.
