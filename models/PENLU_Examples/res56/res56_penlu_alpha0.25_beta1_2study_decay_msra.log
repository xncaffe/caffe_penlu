I0929 14:31:53.890995  2305 caffe.cpp:218] Using GPUs 0
I0929 14:31:53.928310  2305 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0929 14:31:54.158658  2305 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_2study_decay_msra"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_msra.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0929 14:31:54.158794  2305 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_msra.prototxt
I0929 14:31:54.162551  2305 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_msra.prototxt
I0929 14:31:54.162564  2305 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0929 14:31:54.162791  2305 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0929 14:31:54.162909  2305 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0929 14:31:54.163946  2305 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolutio
I0929 14:31:54.164665  2305 layer_factory.hpp:77] Creating layer Data1
I0929 14:31:54.164742  2305 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0929 14:31:54.164762  2305 net.cpp:84] Creating Layer Data1
I0929 14:31:54.164777  2305 net.cpp:380] Data1 -> Data1
I0929 14:31:54.164794  2305 net.cpp:380] Data1 -> Data2
I0929 14:31:54.164803  2305 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0929 14:31:54.166210  2305 data_layer.cpp:45] output data size: 100,3,28,28
I0929 14:31:54.168493  2305 net.cpp:122] Setting up Data1
I0929 14:31:54.168516  2305 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0929 14:31:54.168521  2305 net.cpp:129] Top shape: 100 (100)
I0929 14:31:54.168524  2305 net.cpp:137] Memory required for data: 941200
I0929 14:31:54.168530  2305 layer_factory.hpp:77] Creating layer Convolution1
I0929 14:31:54.168548  2305 net.cpp:84] Creating Layer Convolution1
I0929 14:31:54.168552  2305 net.cpp:406] Convolution1 <- Data1
I0929 14:31:54.168561  2305 net.cpp:380] Convolution1 -> Convolution1
I0929 14:31:54.315480  2305 net.cpp:122] Setting up Convolution1
I0929 14:31:54.315506  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.315510  2305 net.cpp:137] Memory required for data: 5958800
I0929 14:31:54.315524  2305 layer_factory.hpp:77] Creating layer BatchNorm1
I0929 14:31:54.315549  2305 net.cpp:84] Creating Layer BatchNorm1
I0929 14:31:54.315577  2305 net.cpp:406] BatchNorm1 <- Convolution1
I0929 14:31:54.315592  2305 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0929 14:31:54.315721  2305 net.cpp:122] Setting up BatchNorm1
I0929 14:31:54.315726  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.315728  2305 net.cpp:137] Memory required for data: 10976400
I0929 14:31:54.315737  2305 layer_factory.hpp:77] Creating layer Scale1
I0929 14:31:54.315755  2305 net.cpp:84] Creating Layer Scale1
I0929 14:31:54.315759  2305 net.cpp:406] Scale1 <- Convolution1
I0929 14:31:54.315762  2305 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0929 14:31:54.315824  2305 layer_factory.hpp:77] Creating layer Scale1
I0929 14:31:54.315932  2305 net.cpp:122] Setting up Scale1
I0929 14:31:54.315937  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.315939  2305 net.cpp:137] Memory required for data: 15994000
I0929 14:31:54.315944  2305 layer_factory.hpp:77] Creating layer M2PELU1
I0929 14:31:54.315953  2305 net.cpp:84] Creating Layer M2PELU1
I0929 14:31:54.315955  2305 net.cpp:406] M2PELU1 <- Convolution1
I0929 14:31:54.315968  2305 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0929 14:31:54.316570  2305 net.cpp:122] Setting up M2PELU1
I0929 14:31:54.316579  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.316582  2305 net.cpp:137] Memory required for data: 21011600
I0929 14:31:54.316588  2305 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0929 14:31:54.316593  2305 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0929 14:31:54.316596  2305 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0929 14:31:54.316610  2305 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0929 14:31:54.316617  2305 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0929 14:31:54.316664  2305 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0929 14:31:54.316669  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.316681  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.316684  2305 net.cpp:137] Memory required for data: 31046800
I0929 14:31:54.316686  2305 layer_factory.hpp:77] Creating layer Convolution2
I0929 14:31:54.316694  2305 net.cpp:84] Creating Layer Convolution2
I0929 14:31:54.316696  2305 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0929 14:31:54.316700  2305 net.cpp:380] Convolution2 -> Convolution2
I0929 14:31:54.317560  2305 net.cpp:122] Setting up Convolution2
I0929 14:31:54.317570  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.317574  2305 net.cpp:137] Memory required for data: 36064400
I0929 14:31:54.317579  2305 layer_factory.hpp:77] Creating layer BatchNorm2
I0929 14:31:54.317582  2305 net.cpp:84] Creating Layer BatchNorm2
I0929 14:31:54.317585  2305 net.cpp:406] BatchNorm2 <- Convolution2
I0929 14:31:54.317600  2305 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0929 14:31:54.317737  2305 net.cpp:122] Setting up BatchNorm2
I0929 14:31:54.317742  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.317745  2305 net.cpp:137] Memory required for data: 41082000
I0929 14:31:54.317750  2305 layer_factory.hpp:77] Creating layer Scale2
I0929 14:31:54.317755  2305 net.cpp:84] Creating Layer Scale2
I0929 14:31:54.317757  2305 net.cpp:406] Scale2 <- Convolution2
I0929 14:31:54.317760  2305 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0929 14:31:54.317802  2305 layer_factory.hpp:77] Creating layer Scale2
I0929 14:31:54.317910  2305 net.cpp:122] Setting up Scale2
I0929 14:31:54.317915  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.317917  2305 net.cpp:137] Memory required for data: 46099600
I0929 14:31:54.317921  2305 layer_factory.hpp:77] Creating layer M2PELU2
I0929 14:31:54.317926  2305 net.cpp:84] Creating Layer M2PELU2
I0929 14:31:54.317929  2305 net.cpp:406] M2PELU2 <- Convolution2
I0929 14:31:54.317932  2305 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0929 14:31:54.318023  2305 net.cpp:122] Setting up M2PELU2
I0929 14:31:54.318035  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.318038  2305 net.cpp:137] Memory required for data: 51117200
I0929 14:31:54.318044  2305 layer_factory.hpp:77] Creating layer Convolution3
I0929 14:31:54.318051  2305 net.cpp:84] Creating Layer Convolution3
I0929 14:31:54.318053  2305 net.cpp:406] Convolution3 <- Convolution2
I0929 14:31:54.318068  2305 net.cpp:380] Convolution3 -> Convolution3
I0929 14:31:54.318904  2305 net.cpp:122] Setting up Convolution3
I0929 14:31:54.318914  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.318917  2305 net.cpp:137] Memory required for data: 56134800
I0929 14:31:54.318922  2305 layer_factory.hpp:77] Creating layer BatchNorm3
I0929 14:31:54.318927  2305 net.cpp:84] Creating Layer BatchNorm3
I0929 14:31:54.318929  2305 net.cpp:406] BatchNorm3 <- Convolution3
I0929 14:31:54.318943  2305 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0929 14:31:54.319068  2305 net.cpp:122] Setting up BatchNorm3
I0929 14:31:54.319073  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.319077  2305 net.cpp:137] Memory required for data: 61152400
I0929 14:31:54.319082  2305 layer_factory.hpp:77] Creating layer Scale3
I0929 14:31:54.319085  2305 net.cpp:84] Creating Layer Scale3
I0929 14:31:54.319087  2305 net.cpp:406] Scale3 <- Convolution3
I0929 14:31:54.319090  2305 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0929 14:31:54.319133  2305 layer_factory.hpp:77] Creating layer Scale3
I0929 14:31:54.319222  2305 net.cpp:122] Setting up Scale3
I0929 14:31:54.319227  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.319229  2305 net.cpp:137] Memory required for data: 66170000
I0929 14:31:54.319233  2305 layer_factory.hpp:77] Creating layer Eltwise1
I0929 14:31:54.319238  2305 net.cpp:84] Creating Layer Eltwise1
I0929 14:31:54.319241  2305 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0929 14:31:54.319243  2305 net.cpp:406] Eltwise1 <- Convolution3
I0929 14:31:54.319257  2305 net.cpp:380] Eltwise1 -> Eltwise1
I0929 14:31:54.319283  2305 net.cpp:122] Setting up Eltwise1
I0929 14:31:54.319286  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.319289  2305 net.cpp:137] Memory required for data: 71187600
I0929 14:31:54.319291  2305 layer_factory.hpp:77] Creating layer M2PELU3
I0929 14:31:54.319295  2305 net.cpp:84] Creating Layer M2PELU3
I0929 14:31:54.319298  2305 net.cpp:406] M2PELU3 <- Eltwise1
I0929 14:31:54.319301  2305 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0929 14:31:54.319394  2305 net.cpp:122] Setting up M2PELU3
I0929 14:31:54.319399  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.319402  2305 net.cpp:137] Memory required for data: 76205200
I0929 14:31:54.319406  2305 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0929 14:31:54.319411  2305 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0929 14:31:54.319412  2305 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0929 14:31:54.319416  2305 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0929 14:31:54.319430  2305 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0929 14:31:54.319478  2305 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0929 14:31:54.319483  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.319485  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.319488  2305 net.cpp:137] Memory required for data: 86240400
I0929 14:31:54.319489  2305 layer_factory.hpp:77] Creating layer Convolution4
I0929 14:31:54.319496  2305 net.cpp:84] Creating Layer Convolution4
I0929 14:31:54.319499  2305 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0929 14:31:54.319512  2305 net.cpp:380] Convolution4 -> Convolution4
I0929 14:31:54.320336  2305 net.cpp:122] Setting up Convolution4
I0929 14:31:54.320346  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.320349  2305 net.cpp:137] Memory required for data: 91258000
I0929 14:31:54.320353  2305 layer_factory.hpp:77] Creating layer BatchNorm4
I0929 14:31:54.320380  2305 net.cpp:84] Creating Layer BatchNorm4
I0929 14:31:54.320397  2305 net.cpp:406] BatchNorm4 <- Convolution4
I0929 14:31:54.320400  2305 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0929 14:31:54.320538  2305 net.cpp:122] Setting up BatchNorm4
I0929 14:31:54.320543  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.320545  2305 net.cpp:137] Memory required for data: 96275600
I0929 14:31:54.320550  2305 layer_factory.hpp:77] Creating layer Scale4
I0929 14:31:54.320554  2305 net.cpp:84] Creating Layer Scale4
I0929 14:31:54.320567  2305 net.cpp:406] Scale4 <- Convolution4
I0929 14:31:54.320571  2305 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0929 14:31:54.320605  2305 layer_factory.hpp:77] Creating layer Scale4
I0929 14:31:54.320701  2305 net.cpp:122] Setting up Scale4
I0929 14:31:54.320706  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.320708  2305 net.cpp:137] Memory required for data: 101293200
I0929 14:31:54.320715  2305 layer_factory.hpp:77] Creating layer M2PELU4
I0929 14:31:54.320732  2305 net.cpp:84] Creating Layer M2PELU4
I0929 14:31:54.320735  2305 net.cpp:406] M2PELU4 <- Convolution4
I0929 14:31:54.320739  2305 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0929 14:31:54.320824  2305 net.cpp:122] Setting up M2PELU4
I0929 14:31:54.320829  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.320832  2305 net.cpp:137] Memory required for data: 106310800
I0929 14:31:54.320835  2305 layer_factory.hpp:77] Creating layer Convolution5
I0929 14:31:54.320842  2305 net.cpp:84] Creating Layer Convolution5
I0929 14:31:54.320859  2305 net.cpp:406] Convolution5 <- Convolution4
I0929 14:31:54.320863  2305 net.cpp:380] Convolution5 -> Convolution5
I0929 14:31:54.321744  2305 net.cpp:122] Setting up Convolution5
I0929 14:31:54.321754  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.321771  2305 net.cpp:137] Memory required for data: 111328400
I0929 14:31:54.321776  2305 layer_factory.hpp:77] Creating layer BatchNorm5
I0929 14:31:54.321782  2305 net.cpp:84] Creating Layer BatchNorm5
I0929 14:31:54.321797  2305 net.cpp:406] BatchNorm5 <- Convolution5
I0929 14:31:54.321802  2305 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0929 14:31:54.321950  2305 net.cpp:122] Setting up BatchNorm5
I0929 14:31:54.321955  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.321959  2305 net.cpp:137] Memory required for data: 116346000
I0929 14:31:54.321974  2305 layer_factory.hpp:77] Creating layer Scale5
I0929 14:31:54.321977  2305 net.cpp:84] Creating Layer Scale5
I0929 14:31:54.321991  2305 net.cpp:406] Scale5 <- Convolution5
I0929 14:31:54.321995  2305 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0929 14:31:54.322051  2305 layer_factory.hpp:77] Creating layer Scale5
I0929 14:31:54.322152  2305 net.cpp:122] Setting up Scale5
I0929 14:31:54.322157  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.322160  2305 net.cpp:137] Memory required for data: 121363600
I0929 14:31:54.322173  2305 layer_factory.hpp:77] Creating layer Eltwise2
I0929 14:31:54.322180  2305 net.cpp:84] Creating Layer Eltwise2
I0929 14:31:54.322182  2305 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0929 14:31:54.322185  2305 net.cpp:406] Eltwise2 <- Convolution5
I0929 14:31:54.322188  2305 net.cpp:380] Eltwise2 -> Eltwise2
I0929 14:31:54.322202  2305 net.cpp:122] Setting up Eltwise2
I0929 14:31:54.322207  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.322209  2305 net.cpp:137] Memory required for data: 126381200
I0929 14:31:54.322212  2305 layer_factory.hpp:77] Creating layer M2PELU5
I0929 14:31:54.322217  2305 net.cpp:84] Creating Layer M2PELU5
I0929 14:31:54.322221  2305 net.cpp:406] M2PELU5 <- Eltwise2
I0929 14:31:54.322223  2305 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0929 14:31:54.322301  2305 net.cpp:122] Setting up M2PELU5
I0929 14:31:54.322307  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.322310  2305 net.cpp:137] Memory required for data: 131398800
I0929 14:31:54.322314  2305 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0929 14:31:54.322325  2305 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0929 14:31:54.322329  2305 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0929 14:31:54.322332  2305 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0929 14:31:54.322337  2305 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0929 14:31:54.322360  2305 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0929 14:31:54.322365  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.322368  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.322371  2305 net.cpp:137] Memory required for data: 141434000
I0929 14:31:54.322373  2305 layer_factory.hpp:77] Creating layer Convolution6
I0929 14:31:54.322379  2305 net.cpp:84] Creating Layer Convolution6
I0929 14:31:54.322382  2305 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0929 14:31:54.322386  2305 net.cpp:380] Convolution6 -> Convolution6
I0929 14:31:54.323261  2305 net.cpp:122] Setting up Convolution6
I0929 14:31:54.323271  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.323273  2305 net.cpp:137] Memory required for data: 146451600
I0929 14:31:54.323278  2305 layer_factory.hpp:77] Creating layer BatchNorm6
I0929 14:31:54.323283  2305 net.cpp:84] Creating Layer BatchNorm6
I0929 14:31:54.323287  2305 net.cpp:406] BatchNorm6 <- Convolution6
I0929 14:31:54.323292  2305 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0929 14:31:54.323417  2305 net.cpp:122] Setting up BatchNorm6
I0929 14:31:54.323422  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.323426  2305 net.cpp:137] Memory required for data: 151469200
I0929 14:31:54.323431  2305 layer_factory.hpp:77] Creating layer Scale6
I0929 14:31:54.323434  2305 net.cpp:84] Creating Layer Scale6
I0929 14:31:54.323437  2305 net.cpp:406] Scale6 <- Convolution6
I0929 14:31:54.323441  2305 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0929 14:31:54.323467  2305 layer_factory.hpp:77] Creating layer Scale6
I0929 14:31:54.323541  2305 net.cpp:122] Setting up Scale6
I0929 14:31:54.323547  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.323550  2305 net.cpp:137] Memory required for data: 156486800
I0929 14:31:54.323554  2305 layer_factory.hpp:77] Creating layer M2PELU6
I0929 14:31:54.323560  2305 net.cpp:84] Creating Layer M2PELU6
I0929 14:31:54.323563  2305 net.cpp:406] M2PELU6 <- Convolution6
I0929 14:31:54.323566  2305 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0929 14:31:54.323649  2305 net.cpp:122] Setting up M2PELU6
I0929 14:31:54.323654  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.323657  2305 net.cpp:137] Memory required for data: 161504400
I0929 14:31:54.323662  2305 layer_factory.hpp:77] Creating layer Convolution7
I0929 14:31:54.323669  2305 net.cpp:84] Creating Layer Convolution7
I0929 14:31:54.323673  2305 net.cpp:406] Convolution7 <- Convolution6
I0929 14:31:54.323676  2305 net.cpp:380] Convolution7 -> Convolution7
I0929 14:31:54.324223  2305 net.cpp:122] Setting up Convolution7
I0929 14:31:54.324231  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.324234  2305 net.cpp:137] Memory required for data: 166522000
I0929 14:31:54.324239  2305 layer_factory.hpp:77] Creating layer BatchNorm7
I0929 14:31:54.324244  2305 net.cpp:84] Creating Layer BatchNorm7
I0929 14:31:54.324247  2305 net.cpp:406] BatchNorm7 <- Convolution7
I0929 14:31:54.324251  2305 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0929 14:31:54.324376  2305 net.cpp:122] Setting up BatchNorm7
I0929 14:31:54.324381  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.324384  2305 net.cpp:137] Memory required for data: 171539600
I0929 14:31:54.324388  2305 layer_factory.hpp:77] Creating layer Scale7
I0929 14:31:54.324395  2305 net.cpp:84] Creating Layer Scale7
I0929 14:31:54.324398  2305 net.cpp:406] Scale7 <- Convolution7
I0929 14:31:54.324401  2305 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0929 14:31:54.324427  2305 layer_factory.hpp:77] Creating layer Scale7
I0929 14:31:54.324512  2305 net.cpp:122] Setting up Scale7
I0929 14:31:54.324517  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.324520  2305 net.cpp:137] Memory required for data: 176557200
I0929 14:31:54.324524  2305 layer_factory.hpp:77] Creating layer Eltwise3
I0929 14:31:54.324529  2305 net.cpp:84] Creating Layer Eltwise3
I0929 14:31:54.324532  2305 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0929 14:31:54.324535  2305 net.cpp:406] Eltwise3 <- Convolution7
I0929 14:31:54.324540  2305 net.cpp:380] Eltwise3 -> Eltwise3
I0929 14:31:54.324555  2305 net.cpp:122] Setting up Eltwise3
I0929 14:31:54.324559  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.324563  2305 net.cpp:137] Memory required for data: 181574800
I0929 14:31:54.324564  2305 layer_factory.hpp:77] Creating layer M2PELU7
I0929 14:31:54.324569  2305 net.cpp:84] Creating Layer M2PELU7
I0929 14:31:54.324573  2305 net.cpp:406] M2PELU7 <- Eltwise3
I0929 14:31:54.324576  2305 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0929 14:31:54.324656  2305 net.cpp:122] Setting up M2PELU7
I0929 14:31:54.324661  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.324664  2305 net.cpp:137] Memory required for data: 186592400
I0929 14:31:54.324668  2305 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0929 14:31:54.324672  2305 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0929 14:31:54.324676  2305 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0929 14:31:54.324679  2305 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0929 14:31:54.324684  2305 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0929 14:31:54.324707  2305 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0929 14:31:54.324712  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.324714  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.324726  2305 net.cpp:137] Memory required for data: 196627600
I0929 14:31:54.324728  2305 layer_factory.hpp:77] Creating layer Convolution8
I0929 14:31:54.324735  2305 net.cpp:84] Creating Layer Convolution8
I0929 14:31:54.324738  2305 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0929 14:31:54.324743  2305 net.cpp:380] Convolution8 -> Convolution8
I0929 14:31:54.325613  2305 net.cpp:122] Setting up Convolution8
I0929 14:31:54.325623  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.325625  2305 net.cpp:137] Memory required for data: 201645200
I0929 14:31:54.325636  2305 layer_factory.hpp:77] Creating layer BatchNorm8
I0929 14:31:54.325641  2305 net.cpp:84] Creating Layer BatchNorm8
I0929 14:31:54.325644  2305 net.cpp:406] BatchNorm8 <- Convolution8
I0929 14:31:54.325650  2305 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0929 14:31:54.325775  2305 net.cpp:122] Setting up BatchNorm8
I0929 14:31:54.325781  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.325783  2305 net.cpp:137] Memory required for data: 206662800
I0929 14:31:54.325789  2305 layer_factory.hpp:77] Creating layer Scale8
I0929 14:31:54.325793  2305 net.cpp:84] Creating Layer Scale8
I0929 14:31:54.325796  2305 net.cpp:406] Scale8 <- Convolution8
I0929 14:31:54.325799  2305 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0929 14:31:54.325826  2305 layer_factory.hpp:77] Creating layer Scale8
I0929 14:31:54.325901  2305 net.cpp:122] Setting up Scale8
I0929 14:31:54.325906  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.325909  2305 net.cpp:137] Memory required for data: 211680400
I0929 14:31:54.325913  2305 layer_factory.hpp:77] Creating layer M2PELU8
I0929 14:31:54.325919  2305 net.cpp:84] Creating Layer M2PELU8
I0929 14:31:54.325922  2305 net.cpp:406] M2PELU8 <- Convolution8
I0929 14:31:54.325925  2305 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0929 14:31:54.326006  2305 net.cpp:122] Setting up M2PELU8
I0929 14:31:54.326011  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.326014  2305 net.cpp:137] Memory required for data: 216698000
I0929 14:31:54.326025  2305 layer_factory.hpp:77] Creating layer Convolution9
I0929 14:31:54.326033  2305 net.cpp:84] Creating Layer Convolution9
I0929 14:31:54.326047  2305 net.cpp:406] Convolution9 <- Convolution8
I0929 14:31:54.326051  2305 net.cpp:380] Convolution9 -> Convolution9
I0929 14:31:54.326969  2305 net.cpp:122] Setting up Convolution9
I0929 14:31:54.326982  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.326984  2305 net.cpp:137] Memory required for data: 221715600
I0929 14:31:54.326989  2305 layer_factory.hpp:77] Creating layer BatchNorm9
I0929 14:31:54.326995  2305 net.cpp:84] Creating Layer BatchNorm9
I0929 14:31:54.326999  2305 net.cpp:406] BatchNorm9 <- Convolution9
I0929 14:31:54.327004  2305 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0929 14:31:54.327136  2305 net.cpp:122] Setting up BatchNorm9
I0929 14:31:54.327142  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.327144  2305 net.cpp:137] Memory required for data: 226733200
I0929 14:31:54.327149  2305 layer_factory.hpp:77] Creating layer Scale9
I0929 14:31:54.327153  2305 net.cpp:84] Creating Layer Scale9
I0929 14:31:54.327157  2305 net.cpp:406] Scale9 <- Convolution9
I0929 14:31:54.327159  2305 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0929 14:31:54.327185  2305 layer_factory.hpp:77] Creating layer Scale9
I0929 14:31:54.327273  2305 net.cpp:122] Setting up Scale9
I0929 14:31:54.327282  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.327287  2305 net.cpp:137] Memory required for data: 231750800
I0929 14:31:54.327294  2305 layer_factory.hpp:77] Creating layer Eltwise4
I0929 14:31:54.327306  2305 net.cpp:84] Creating Layer Eltwise4
I0929 14:31:54.327311  2305 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0929 14:31:54.327316  2305 net.cpp:406] Eltwise4 <- Convolution9
I0929 14:31:54.327322  2305 net.cpp:380] Eltwise4 -> Eltwise4
I0929 14:31:54.327358  2305 net.cpp:122] Setting up Eltwise4
I0929 14:31:54.327378  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.327383  2305 net.cpp:137] Memory required for data: 236768400
I0929 14:31:54.327388  2305 layer_factory.hpp:77] Creating layer M2PELU9
I0929 14:31:54.327394  2305 net.cpp:84] Creating Layer M2PELU9
I0929 14:31:54.327397  2305 net.cpp:406] M2PELU9 <- Eltwise4
I0929 14:31:54.327401  2305 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0929 14:31:54.327508  2305 net.cpp:122] Setting up M2PELU9
I0929 14:31:54.327515  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.327518  2305 net.cpp:137] Memory required for data: 241786000
I0929 14:31:54.327522  2305 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0929 14:31:54.327527  2305 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0929 14:31:54.327530  2305 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0929 14:31:54.327533  2305 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0929 14:31:54.327539  2305 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0929 14:31:54.327564  2305 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0929 14:31:54.327567  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.327571  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.327574  2305 net.cpp:137] Memory required for data: 251821200
I0929 14:31:54.327576  2305 layer_factory.hpp:77] Creating layer Convolution10
I0929 14:31:54.327581  2305 net.cpp:84] Creating Layer Convolution10
I0929 14:31:54.327584  2305 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0929 14:31:54.327589  2305 net.cpp:380] Convolution10 -> Convolution10
I0929 14:31:54.328488  2305 net.cpp:122] Setting up Convolution10
I0929 14:31:54.328498  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.328502  2305 net.cpp:137] Memory required for data: 256838800
I0929 14:31:54.328517  2305 layer_factory.hpp:77] Creating layer BatchNorm10
I0929 14:31:54.328523  2305 net.cpp:84] Creating Layer BatchNorm10
I0929 14:31:54.328526  2305 net.cpp:406] BatchNorm10 <- Convolution10
I0929 14:31:54.328539  2305 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0929 14:31:54.328680  2305 net.cpp:122] Setting up BatchNorm10
I0929 14:31:54.328685  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.328687  2305 net.cpp:137] Memory required for data: 261856400
I0929 14:31:54.328692  2305 layer_factory.hpp:77] Creating layer Scale10
I0929 14:31:54.328697  2305 net.cpp:84] Creating Layer Scale10
I0929 14:31:54.328701  2305 net.cpp:406] Scale10 <- Convolution10
I0929 14:31:54.328704  2305 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0929 14:31:54.328730  2305 layer_factory.hpp:77] Creating layer Scale10
I0929 14:31:54.328807  2305 net.cpp:122] Setting up Scale10
I0929 14:31:54.328812  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.328815  2305 net.cpp:137] Memory required for data: 266874000
I0929 14:31:54.328819  2305 layer_factory.hpp:77] Creating layer M2PELU10
I0929 14:31:54.328824  2305 net.cpp:84] Creating Layer M2PELU10
I0929 14:31:54.328827  2305 net.cpp:406] M2PELU10 <- Convolution10
I0929 14:31:54.328831  2305 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0929 14:31:54.328918  2305 net.cpp:122] Setting up M2PELU10
I0929 14:31:54.328923  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.328925  2305 net.cpp:137] Memory required for data: 271891600
I0929 14:31:54.328929  2305 layer_factory.hpp:77] Creating layer Convolution11
I0929 14:31:54.328936  2305 net.cpp:84] Creating Layer Convolution11
I0929 14:31:54.328939  2305 net.cpp:406] Convolution11 <- Convolution10
I0929 14:31:54.328943  2305 net.cpp:380] Convolution11 -> Convolution11
I0929 14:31:54.329851  2305 net.cpp:122] Setting up Convolution11
I0929 14:31:54.329861  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.329864  2305 net.cpp:137] Memory required for data: 276909200
I0929 14:31:54.329869  2305 layer_factory.hpp:77] Creating layer BatchNorm11
I0929 14:31:54.329875  2305 net.cpp:84] Creating Layer BatchNorm11
I0929 14:31:54.329879  2305 net.cpp:406] BatchNorm11 <- Convolution11
I0929 14:31:54.329883  2305 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0929 14:31:54.330011  2305 net.cpp:122] Setting up BatchNorm11
I0929 14:31:54.330016  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.330019  2305 net.cpp:137] Memory required for data: 281926800
I0929 14:31:54.330024  2305 layer_factory.hpp:77] Creating layer Scale11
I0929 14:31:54.330029  2305 net.cpp:84] Creating Layer Scale11
I0929 14:31:54.330032  2305 net.cpp:406] Scale11 <- Convolution11
I0929 14:31:54.330035  2305 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0929 14:31:54.330062  2305 layer_factory.hpp:77] Creating layer Scale11
I0929 14:31:54.330140  2305 net.cpp:122] Setting up Scale11
I0929 14:31:54.330145  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.330148  2305 net.cpp:137] Memory required for data: 286944400
I0929 14:31:54.330152  2305 layer_factory.hpp:77] Creating layer Eltwise5
I0929 14:31:54.330157  2305 net.cpp:84] Creating Layer Eltwise5
I0929 14:31:54.330160  2305 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0929 14:31:54.330163  2305 net.cpp:406] Eltwise5 <- Convolution11
I0929 14:31:54.330169  2305 net.cpp:380] Eltwise5 -> Eltwise5
I0929 14:31:54.330184  2305 net.cpp:122] Setting up Eltwise5
I0929 14:31:54.330188  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.330191  2305 net.cpp:137] Memory required for data: 291962000
I0929 14:31:54.330193  2305 layer_factory.hpp:77] Creating layer M2PELU11
I0929 14:31:54.330199  2305 net.cpp:84] Creating Layer M2PELU11
I0929 14:31:54.330201  2305 net.cpp:406] M2PELU11 <- Eltwise5
I0929 14:31:54.330205  2305 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0929 14:31:54.330291  2305 net.cpp:122] Setting up M2PELU11
I0929 14:31:54.330296  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.330298  2305 net.cpp:137] Memory required for data: 296979600
I0929 14:31:54.330302  2305 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0929 14:31:54.330307  2305 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0929 14:31:54.330317  2305 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0929 14:31:54.330322  2305 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0929 14:31:54.330327  2305 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0929 14:31:54.330350  2305 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0929 14:31:54.330355  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.330358  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.330361  2305 net.cpp:137] Memory required for data: 307014800
I0929 14:31:54.330363  2305 layer_factory.hpp:77] Creating layer Convolution12
I0929 14:31:54.330370  2305 net.cpp:84] Creating Layer Convolution12
I0929 14:31:54.330374  2305 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0929 14:31:54.330377  2305 net.cpp:380] Convolution12 -> Convolution12
I0929 14:31:54.331292  2305 net.cpp:122] Setting up Convolution12
I0929 14:31:54.331302  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.331305  2305 net.cpp:137] Memory required for data: 312032400
I0929 14:31:54.331310  2305 layer_factory.hpp:77] Creating layer BatchNorm12
I0929 14:31:54.331316  2305 net.cpp:84] Creating Layer BatchNorm12
I0929 14:31:54.331320  2305 net.cpp:406] BatchNorm12 <- Convolution12
I0929 14:31:54.331324  2305 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0929 14:31:54.331456  2305 net.cpp:122] Setting up BatchNorm12
I0929 14:31:54.331461  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.331463  2305 net.cpp:137] Memory required for data: 317050000
I0929 14:31:54.331470  2305 layer_factory.hpp:77] Creating layer Scale12
I0929 14:31:54.331475  2305 net.cpp:84] Creating Layer Scale12
I0929 14:31:54.331477  2305 net.cpp:406] Scale12 <- Convolution12
I0929 14:31:54.331480  2305 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0929 14:31:54.331506  2305 layer_factory.hpp:77] Creating layer Scale12
I0929 14:31:54.331586  2305 net.cpp:122] Setting up Scale12
I0929 14:31:54.331593  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.331595  2305 net.cpp:137] Memory required for data: 322067600
I0929 14:31:54.331599  2305 layer_factory.hpp:77] Creating layer M2PELU12
I0929 14:31:54.331604  2305 net.cpp:84] Creating Layer M2PELU12
I0929 14:31:54.331607  2305 net.cpp:406] M2PELU12 <- Convolution12
I0929 14:31:54.331611  2305 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0929 14:31:54.331698  2305 net.cpp:122] Setting up M2PELU12
I0929 14:31:54.331703  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.331707  2305 net.cpp:137] Memory required for data: 327085200
I0929 14:31:54.331710  2305 layer_factory.hpp:77] Creating layer Convolution13
I0929 14:31:54.331717  2305 net.cpp:84] Creating Layer Convolution13
I0929 14:31:54.331722  2305 net.cpp:406] Convolution13 <- Convolution12
I0929 14:31:54.331725  2305 net.cpp:380] Convolution13 -> Convolution13
I0929 14:31:54.332617  2305 net.cpp:122] Setting up Convolution13
I0929 14:31:54.332626  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.332629  2305 net.cpp:137] Memory required for data: 332102800
I0929 14:31:54.332634  2305 layer_factory.hpp:77] Creating layer BatchNorm13
I0929 14:31:54.332639  2305 net.cpp:84] Creating Layer BatchNorm13
I0929 14:31:54.332643  2305 net.cpp:406] BatchNorm13 <- Convolution13
I0929 14:31:54.332648  2305 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0929 14:31:54.332779  2305 net.cpp:122] Setting up BatchNorm13
I0929 14:31:54.332784  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.332787  2305 net.cpp:137] Memory required for data: 337120400
I0929 14:31:54.332792  2305 layer_factory.hpp:77] Creating layer Scale13
I0929 14:31:54.332798  2305 net.cpp:84] Creating Layer Scale13
I0929 14:31:54.332801  2305 net.cpp:406] Scale13 <- Convolution13
I0929 14:31:54.332804  2305 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0929 14:31:54.332830  2305 layer_factory.hpp:77] Creating layer Scale13
I0929 14:31:54.332918  2305 net.cpp:122] Setting up Scale13
I0929 14:31:54.332924  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.332927  2305 net.cpp:137] Memory required for data: 342138000
I0929 14:31:54.332931  2305 layer_factory.hpp:77] Creating layer Eltwise6
I0929 14:31:54.332937  2305 net.cpp:84] Creating Layer Eltwise6
I0929 14:31:54.332939  2305 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0929 14:31:54.332942  2305 net.cpp:406] Eltwise6 <- Convolution13
I0929 14:31:54.332947  2305 net.cpp:380] Eltwise6 -> Eltwise6
I0929 14:31:54.332964  2305 net.cpp:122] Setting up Eltwise6
I0929 14:31:54.332970  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.332973  2305 net.cpp:137] Memory required for data: 347155600
I0929 14:31:54.332975  2305 layer_factory.hpp:77] Creating layer M2PELU13
I0929 14:31:54.332983  2305 net.cpp:84] Creating Layer M2PELU13
I0929 14:31:54.332986  2305 net.cpp:406] M2PELU13 <- Eltwise6
I0929 14:31:54.332990  2305 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0929 14:31:54.333077  2305 net.cpp:122] Setting up M2PELU13
I0929 14:31:54.333082  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.333086  2305 net.cpp:137] Memory required for data: 352173200
I0929 14:31:54.333089  2305 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0929 14:31:54.333093  2305 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0929 14:31:54.333096  2305 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0929 14:31:54.333101  2305 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0929 14:31:54.333106  2305 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0929 14:31:54.333127  2305 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0929 14:31:54.333132  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.333135  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.333137  2305 net.cpp:137] Memory required for data: 362208400
I0929 14:31:54.333139  2305 layer_factory.hpp:77] Creating layer Convolution14
I0929 14:31:54.333147  2305 net.cpp:84] Creating Layer Convolution14
I0929 14:31:54.333149  2305 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0929 14:31:54.333153  2305 net.cpp:380] Convolution14 -> Convolution14
I0929 14:31:54.334040  2305 net.cpp:122] Setting up Convolution14
I0929 14:31:54.334049  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.334053  2305 net.cpp:137] Memory required for data: 367226000
I0929 14:31:54.334056  2305 layer_factory.hpp:77] Creating layer BatchNorm14
I0929 14:31:54.334062  2305 net.cpp:84] Creating Layer BatchNorm14
I0929 14:31:54.334065  2305 net.cpp:406] BatchNorm14 <- Convolution14
I0929 14:31:54.334070  2305 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0929 14:31:54.334204  2305 net.cpp:122] Setting up BatchNorm14
I0929 14:31:54.334208  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.334210  2305 net.cpp:137] Memory required for data: 372243600
I0929 14:31:54.334215  2305 layer_factory.hpp:77] Creating layer Scale14
I0929 14:31:54.334220  2305 net.cpp:84] Creating Layer Scale14
I0929 14:31:54.334223  2305 net.cpp:406] Scale14 <- Convolution14
I0929 14:31:54.334226  2305 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0929 14:31:54.334251  2305 layer_factory.hpp:77] Creating layer Scale14
I0929 14:31:54.334331  2305 net.cpp:122] Setting up Scale14
I0929 14:31:54.334336  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.334337  2305 net.cpp:137] Memory required for data: 377261200
I0929 14:31:54.334342  2305 layer_factory.hpp:77] Creating layer M2PELU14
I0929 14:31:54.334347  2305 net.cpp:84] Creating Layer M2PELU14
I0929 14:31:54.334349  2305 net.cpp:406] M2PELU14 <- Convolution14
I0929 14:31:54.334352  2305 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0929 14:31:54.334435  2305 net.cpp:122] Setting up M2PELU14
I0929 14:31:54.334441  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.334444  2305 net.cpp:137] Memory required for data: 382278800
I0929 14:31:54.334453  2305 layer_factory.hpp:77] Creating layer Convolution15
I0929 14:31:54.334460  2305 net.cpp:84] Creating Layer Convolution15
I0929 14:31:54.334462  2305 net.cpp:406] Convolution15 <- Convolution14
I0929 14:31:54.334467  2305 net.cpp:380] Convolution15 -> Convolution15
I0929 14:31:54.335381  2305 net.cpp:122] Setting up Convolution15
I0929 14:31:54.335389  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.335392  2305 net.cpp:137] Memory required for data: 387296400
I0929 14:31:54.335397  2305 layer_factory.hpp:77] Creating layer BatchNorm15
I0929 14:31:54.335402  2305 net.cpp:84] Creating Layer BatchNorm15
I0929 14:31:54.335403  2305 net.cpp:406] BatchNorm15 <- Convolution15
I0929 14:31:54.335408  2305 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0929 14:31:54.335541  2305 net.cpp:122] Setting up BatchNorm15
I0929 14:31:54.335544  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.335546  2305 net.cpp:137] Memory required for data: 392314000
I0929 14:31:54.335562  2305 layer_factory.hpp:77] Creating layer Scale15
I0929 14:31:54.335567  2305 net.cpp:84] Creating Layer Scale15
I0929 14:31:54.335569  2305 net.cpp:406] Scale15 <- Convolution15
I0929 14:31:54.335573  2305 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0929 14:31:54.335600  2305 layer_factory.hpp:77] Creating layer Scale15
I0929 14:31:54.335680  2305 net.cpp:122] Setting up Scale15
I0929 14:31:54.335683  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.335686  2305 net.cpp:137] Memory required for data: 397331600
I0929 14:31:54.335690  2305 layer_factory.hpp:77] Creating layer Eltwise7
I0929 14:31:54.335695  2305 net.cpp:84] Creating Layer Eltwise7
I0929 14:31:54.335696  2305 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0929 14:31:54.335700  2305 net.cpp:406] Eltwise7 <- Convolution15
I0929 14:31:54.335703  2305 net.cpp:380] Eltwise7 -> Eltwise7
I0929 14:31:54.335719  2305 net.cpp:122] Setting up Eltwise7
I0929 14:31:54.335723  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.335726  2305 net.cpp:137] Memory required for data: 402349200
I0929 14:31:54.335727  2305 layer_factory.hpp:77] Creating layer M2PELU15
I0929 14:31:54.335733  2305 net.cpp:84] Creating Layer M2PELU15
I0929 14:31:54.335736  2305 net.cpp:406] M2PELU15 <- Eltwise7
I0929 14:31:54.335738  2305 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0929 14:31:54.335824  2305 net.cpp:122] Setting up M2PELU15
I0929 14:31:54.335829  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.335831  2305 net.cpp:137] Memory required for data: 407366800
I0929 14:31:54.335834  2305 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0929 14:31:54.335839  2305 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0929 14:31:54.335840  2305 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0929 14:31:54.335844  2305 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0929 14:31:54.335847  2305 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0929 14:31:54.335870  2305 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0929 14:31:54.335875  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.335876  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.335880  2305 net.cpp:137] Memory required for data: 417402000
I0929 14:31:54.335881  2305 layer_factory.hpp:77] Creating layer Convolution16
I0929 14:31:54.335887  2305 net.cpp:84] Creating Layer Convolution16
I0929 14:31:54.335889  2305 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0929 14:31:54.335893  2305 net.cpp:380] Convolution16 -> Convolution16
I0929 14:31:54.336773  2305 net.cpp:122] Setting up Convolution16
I0929 14:31:54.336781  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.336784  2305 net.cpp:137] Memory required for data: 422419600
I0929 14:31:54.336788  2305 layer_factory.hpp:77] Creating layer BatchNorm16
I0929 14:31:54.336794  2305 net.cpp:84] Creating Layer BatchNorm16
I0929 14:31:54.336796  2305 net.cpp:406] BatchNorm16 <- Convolution16
I0929 14:31:54.336808  2305 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0929 14:31:54.336941  2305 net.cpp:122] Setting up BatchNorm16
I0929 14:31:54.336946  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.336947  2305 net.cpp:137] Memory required for data: 427437200
I0929 14:31:54.336952  2305 layer_factory.hpp:77] Creating layer Scale16
I0929 14:31:54.336957  2305 net.cpp:84] Creating Layer Scale16
I0929 14:31:54.336959  2305 net.cpp:406] Scale16 <- Convolution16
I0929 14:31:54.336962  2305 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0929 14:31:54.336988  2305 layer_factory.hpp:77] Creating layer Scale16
I0929 14:31:54.337066  2305 net.cpp:122] Setting up Scale16
I0929 14:31:54.337070  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.337074  2305 net.cpp:137] Memory required for data: 432454800
I0929 14:31:54.337076  2305 layer_factory.hpp:77] Creating layer M2PELU16
I0929 14:31:54.337082  2305 net.cpp:84] Creating Layer M2PELU16
I0929 14:31:54.337085  2305 net.cpp:406] M2PELU16 <- Convolution16
I0929 14:31:54.337088  2305 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0929 14:31:54.337174  2305 net.cpp:122] Setting up M2PELU16
I0929 14:31:54.337178  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.337180  2305 net.cpp:137] Memory required for data: 437472400
I0929 14:31:54.337184  2305 layer_factory.hpp:77] Creating layer Convolution17
I0929 14:31:54.337191  2305 net.cpp:84] Creating Layer Convolution17
I0929 14:31:54.337194  2305 net.cpp:406] Convolution17 <- Convolution16
I0929 14:31:54.337198  2305 net.cpp:380] Convolution17 -> Convolution17
I0929 14:31:54.337759  2305 net.cpp:122] Setting up Convolution17
I0929 14:31:54.337766  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.337769  2305 net.cpp:137] Memory required for data: 442490000
I0929 14:31:54.337774  2305 layer_factory.hpp:77] Creating layer BatchNorm17
I0929 14:31:54.337779  2305 net.cpp:84] Creating Layer BatchNorm17
I0929 14:31:54.337780  2305 net.cpp:406] BatchNorm17 <- Convolution17
I0929 14:31:54.337785  2305 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0929 14:31:54.337915  2305 net.cpp:122] Setting up BatchNorm17
I0929 14:31:54.337920  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.337923  2305 net.cpp:137] Memory required for data: 447507600
I0929 14:31:54.337926  2305 layer_factory.hpp:77] Creating layer Scale17
I0929 14:31:54.337932  2305 net.cpp:84] Creating Layer Scale17
I0929 14:31:54.337934  2305 net.cpp:406] Scale17 <- Convolution17
I0929 14:31:54.337937  2305 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0929 14:31:54.337963  2305 layer_factory.hpp:77] Creating layer Scale17
I0929 14:31:54.338039  2305 net.cpp:122] Setting up Scale17
I0929 14:31:54.338043  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.338047  2305 net.cpp:137] Memory required for data: 452525200
I0929 14:31:54.338049  2305 layer_factory.hpp:77] Creating layer Eltwise8
I0929 14:31:54.338054  2305 net.cpp:84] Creating Layer Eltwise8
I0929 14:31:54.338057  2305 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0929 14:31:54.338059  2305 net.cpp:406] Eltwise8 <- Convolution17
I0929 14:31:54.338063  2305 net.cpp:380] Eltwise8 -> Eltwise8
I0929 14:31:54.338078  2305 net.cpp:122] Setting up Eltwise8
I0929 14:31:54.338081  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.338083  2305 net.cpp:137] Memory required for data: 457542800
I0929 14:31:54.338085  2305 layer_factory.hpp:77] Creating layer M2PELU17
I0929 14:31:54.338090  2305 net.cpp:84] Creating Layer M2PELU17
I0929 14:31:54.338093  2305 net.cpp:406] M2PELU17 <- Eltwise8
I0929 14:31:54.338096  2305 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0929 14:31:54.338181  2305 net.cpp:122] Setting up M2PELU17
I0929 14:31:54.338186  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.338187  2305 net.cpp:137] Memory required for data: 462560400
I0929 14:31:54.338191  2305 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0929 14:31:54.338203  2305 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0929 14:31:54.338207  2305 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0929 14:31:54.338209  2305 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0929 14:31:54.338214  2305 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0929 14:31:54.338238  2305 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0929 14:31:54.338243  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.338245  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.338248  2305 net.cpp:137] Memory required for data: 472595600
I0929 14:31:54.338249  2305 layer_factory.hpp:77] Creating layer Convolution18
I0929 14:31:54.338254  2305 net.cpp:84] Creating Layer Convolution18
I0929 14:31:54.338258  2305 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0929 14:31:54.338261  2305 net.cpp:380] Convolution18 -> Convolution18
I0929 14:31:54.339164  2305 net.cpp:122] Setting up Convolution18
I0929 14:31:54.339172  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.339175  2305 net.cpp:137] Memory required for data: 477613200
I0929 14:31:54.339179  2305 layer_factory.hpp:77] Creating layer BatchNorm18
I0929 14:31:54.339185  2305 net.cpp:84] Creating Layer BatchNorm18
I0929 14:31:54.339187  2305 net.cpp:406] BatchNorm18 <- Convolution18
I0929 14:31:54.339191  2305 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0929 14:31:54.339323  2305 net.cpp:122] Setting up BatchNorm18
I0929 14:31:54.339328  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.339330  2305 net.cpp:137] Memory required for data: 482630800
I0929 14:31:54.339334  2305 layer_factory.hpp:77] Creating layer Scale18
I0929 14:31:54.339339  2305 net.cpp:84] Creating Layer Scale18
I0929 14:31:54.339341  2305 net.cpp:406] Scale18 <- Convolution18
I0929 14:31:54.339344  2305 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0929 14:31:54.339371  2305 layer_factory.hpp:77] Creating layer Scale18
I0929 14:31:54.339449  2305 net.cpp:122] Setting up Scale18
I0929 14:31:54.339453  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.339457  2305 net.cpp:137] Memory required for data: 487648400
I0929 14:31:54.339459  2305 layer_factory.hpp:77] Creating layer M2PELU18
I0929 14:31:54.339464  2305 net.cpp:84] Creating Layer M2PELU18
I0929 14:31:54.339467  2305 net.cpp:406] M2PELU18 <- Convolution18
I0929 14:31:54.339470  2305 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0929 14:31:54.339556  2305 net.cpp:122] Setting up M2PELU18
I0929 14:31:54.339560  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.339562  2305 net.cpp:137] Memory required for data: 492666000
I0929 14:31:54.339566  2305 layer_factory.hpp:77] Creating layer Convolution19
I0929 14:31:54.339574  2305 net.cpp:84] Creating Layer Convolution19
I0929 14:31:54.339576  2305 net.cpp:406] Convolution19 <- Convolution18
I0929 14:31:54.339581  2305 net.cpp:380] Convolution19 -> Convolution19
I0929 14:31:54.340476  2305 net.cpp:122] Setting up Convolution19
I0929 14:31:54.340484  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.340487  2305 net.cpp:137] Memory required for data: 497683600
I0929 14:31:54.340492  2305 layer_factory.hpp:77] Creating layer BatchNorm19
I0929 14:31:54.340497  2305 net.cpp:84] Creating Layer BatchNorm19
I0929 14:31:54.340500  2305 net.cpp:406] BatchNorm19 <- Convolution19
I0929 14:31:54.340504  2305 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0929 14:31:54.340636  2305 net.cpp:122] Setting up BatchNorm19
I0929 14:31:54.340641  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.340642  2305 net.cpp:137] Memory required for data: 502701200
I0929 14:31:54.340647  2305 layer_factory.hpp:77] Creating layer Scale19
I0929 14:31:54.340652  2305 net.cpp:84] Creating Layer Scale19
I0929 14:31:54.340654  2305 net.cpp:406] Scale19 <- Convolution19
I0929 14:31:54.340657  2305 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0929 14:31:54.340692  2305 layer_factory.hpp:77] Creating layer Scale19
I0929 14:31:54.340771  2305 net.cpp:122] Setting up Scale19
I0929 14:31:54.340775  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.340777  2305 net.cpp:137] Memory required for data: 507718800
I0929 14:31:54.340781  2305 layer_factory.hpp:77] Creating layer Eltwise9
I0929 14:31:54.340786  2305 net.cpp:84] Creating Layer Eltwise9
I0929 14:31:54.340788  2305 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0929 14:31:54.340791  2305 net.cpp:406] Eltwise9 <- Convolution19
I0929 14:31:54.340795  2305 net.cpp:380] Eltwise9 -> Eltwise9
I0929 14:31:54.340821  2305 net.cpp:122] Setting up Eltwise9
I0929 14:31:54.340824  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.340826  2305 net.cpp:137] Memory required for data: 512736400
I0929 14:31:54.340829  2305 layer_factory.hpp:77] Creating layer M2PELU19
I0929 14:31:54.340843  2305 net.cpp:84] Creating Layer M2PELU19
I0929 14:31:54.340847  2305 net.cpp:406] M2PELU19 <- Eltwise9
I0929 14:31:54.340849  2305 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0929 14:31:54.340934  2305 net.cpp:122] Setting up M2PELU19
I0929 14:31:54.340939  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.340941  2305 net.cpp:137] Memory required for data: 517754000
I0929 14:31:54.340945  2305 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0929 14:31:54.340948  2305 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0929 14:31:54.340950  2305 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0929 14:31:54.340955  2305 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0929 14:31:54.340958  2305 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0929 14:31:54.340982  2305 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0929 14:31:54.340986  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.340988  2305 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0929 14:31:54.340991  2305 net.cpp:137] Memory required for data: 527789200
I0929 14:31:54.340992  2305 layer_factory.hpp:77] Creating layer Convolution20
I0929 14:31:54.341001  2305 net.cpp:84] Creating Layer Convolution20
I0929 14:31:54.341002  2305 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0929 14:31:54.341006  2305 net.cpp:380] Convolution20 -> Convolution20
I0929 14:31:54.342205  2305 net.cpp:122] Setting up Convolution20
I0929 14:31:54.342213  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.342216  2305 net.cpp:137] Memory required for data: 530298000
I0929 14:31:54.342222  2305 layer_factory.hpp:77] Creating layer BatchNorm20
I0929 14:31:54.342227  2305 net.cpp:84] Creating Layer BatchNorm20
I0929 14:31:54.342231  2305 net.cpp:406] BatchNorm20 <- Convolution20
I0929 14:31:54.342234  2305 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0929 14:31:54.342381  2305 net.cpp:122] Setting up BatchNorm20
I0929 14:31:54.342386  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.342387  2305 net.cpp:137] Memory required for data: 532806800
I0929 14:31:54.342392  2305 layer_factory.hpp:77] Creating layer Scale20
I0929 14:31:54.342397  2305 net.cpp:84] Creating Layer Scale20
I0929 14:31:54.342399  2305 net.cpp:406] Scale20 <- Convolution20
I0929 14:31:54.342403  2305 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0929 14:31:54.342430  2305 layer_factory.hpp:77] Creating layer Scale20
I0929 14:31:54.342511  2305 net.cpp:122] Setting up Scale20
I0929 14:31:54.342516  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.342519  2305 net.cpp:137] Memory required for data: 535315600
I0929 14:31:54.342526  2305 layer_factory.hpp:77] Creating layer Convolution21
I0929 14:31:54.342533  2305 net.cpp:84] Creating Layer Convolution21
I0929 14:31:54.342536  2305 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0929 14:31:54.342541  2305 net.cpp:380] Convolution21 -> Convolution21
I0929 14:31:54.344668  2305 net.cpp:122] Setting up Convolution21
I0929 14:31:54.344678  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.344689  2305 net.cpp:137] Memory required for data: 537824400
I0929 14:31:54.344696  2305 layer_factory.hpp:77] Creating layer BatchNorm21
I0929 14:31:54.344702  2305 net.cpp:84] Creating Layer BatchNorm21
I0929 14:31:54.344704  2305 net.cpp:406] BatchNorm21 <- Convolution21
I0929 14:31:54.344708  2305 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0929 14:31:54.344848  2305 net.cpp:122] Setting up BatchNorm21
I0929 14:31:54.344853  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.344856  2305 net.cpp:137] Memory required for data: 540333200
I0929 14:31:54.344861  2305 layer_factory.hpp:77] Creating layer Scale21
I0929 14:31:54.344866  2305 net.cpp:84] Creating Layer Scale21
I0929 14:31:54.344867  2305 net.cpp:406] Scale21 <- Convolution21
I0929 14:31:54.344871  2305 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0929 14:31:54.344899  2305 layer_factory.hpp:77] Creating layer Scale21
I0929 14:31:54.344976  2305 net.cpp:122] Setting up Scale21
I0929 14:31:54.344981  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.344983  2305 net.cpp:137] Memory required for data: 542842000
I0929 14:31:54.344987  2305 layer_factory.hpp:77] Creating layer M2PELU20
I0929 14:31:54.344992  2305 net.cpp:84] Creating Layer M2PELU20
I0929 14:31:54.344995  2305 net.cpp:406] M2PELU20 <- Convolution21
I0929 14:31:54.345000  2305 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0929 14:31:54.345105  2305 net.cpp:122] Setting up M2PELU20
I0929 14:31:54.345109  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.345111  2305 net.cpp:137] Memory required for data: 545350800
I0929 14:31:54.345115  2305 layer_factory.hpp:77] Creating layer Convolution22
I0929 14:31:54.345124  2305 net.cpp:84] Creating Layer Convolution22
I0929 14:31:54.345125  2305 net.cpp:406] Convolution22 <- Convolution21
I0929 14:31:54.345130  2305 net.cpp:380] Convolution22 -> Convolution22
I0929 14:31:54.346221  2305 net.cpp:122] Setting up Convolution22
I0929 14:31:54.346230  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.346232  2305 net.cpp:137] Memory required for data: 547859600
I0929 14:31:54.346237  2305 layer_factory.hpp:77] Creating layer BatchNorm22
I0929 14:31:54.346245  2305 net.cpp:84] Creating Layer BatchNorm22
I0929 14:31:54.346247  2305 net.cpp:406] BatchNorm22 <- Convolution22
I0929 14:31:54.346251  2305 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0929 14:31:54.346385  2305 net.cpp:122] Setting up BatchNorm22
I0929 14:31:54.346390  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.346392  2305 net.cpp:137] Memory required for data: 550368400
I0929 14:31:54.346397  2305 layer_factory.hpp:77] Creating layer Scale22
I0929 14:31:54.346402  2305 net.cpp:84] Creating Layer Scale22
I0929 14:31:54.346405  2305 net.cpp:406] Scale22 <- Convolution22
I0929 14:31:54.346408  2305 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0929 14:31:54.346434  2305 layer_factory.hpp:77] Creating layer Scale22
I0929 14:31:54.346511  2305 net.cpp:122] Setting up Scale22
I0929 14:31:54.346515  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.346518  2305 net.cpp:137] Memory required for data: 552877200
I0929 14:31:54.346537  2305 layer_factory.hpp:77] Creating layer Eltwise10
I0929 14:31:54.346544  2305 net.cpp:84] Creating Layer Eltwise10
I0929 14:31:54.346546  2305 net.cpp:406] Eltwise10 <- Convolution20
I0929 14:31:54.346549  2305 net.cpp:406] Eltwise10 <- Convolution22
I0929 14:31:54.346552  2305 net.cpp:380] Eltwise10 -> Eltwise10
I0929 14:31:54.346580  2305 net.cpp:122] Setting up Eltwise10
I0929 14:31:54.346583  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.346585  2305 net.cpp:137] Memory required for data: 555386000
I0929 14:31:54.346587  2305 layer_factory.hpp:77] Creating layer M2PELU21
I0929 14:31:54.346592  2305 net.cpp:84] Creating Layer M2PELU21
I0929 14:31:54.346595  2305 net.cpp:406] M2PELU21 <- Eltwise10
I0929 14:31:54.346598  2305 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0929 14:31:54.346681  2305 net.cpp:122] Setting up M2PELU21
I0929 14:31:54.346693  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.346696  2305 net.cpp:137] Memory required for data: 557894800
I0929 14:31:54.346700  2305 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0929 14:31:54.346705  2305 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0929 14:31:54.346709  2305 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0929 14:31:54.346711  2305 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0929 14:31:54.346715  2305 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0929 14:31:54.346741  2305 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0929 14:31:54.346745  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.346747  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.346750  2305 net.cpp:137] Memory required for data: 562912400
I0929 14:31:54.346752  2305 layer_factory.hpp:77] Creating layer Convolution23
I0929 14:31:54.346757  2305 net.cpp:84] Creating Layer Convolution23
I0929 14:31:54.346760  2305 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0929 14:31:54.346765  2305 net.cpp:380] Convolution23 -> Convolution23
I0929 14:31:54.348121  2305 net.cpp:122] Setting up Convolution23
I0929 14:31:54.348130  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.348132  2305 net.cpp:137] Memory required for data: 565421200
I0929 14:31:54.348137  2305 layer_factory.hpp:77] Creating layer BatchNorm23
I0929 14:31:54.348142  2305 net.cpp:84] Creating Layer BatchNorm23
I0929 14:31:54.348145  2305 net.cpp:406] BatchNorm23 <- Convolution23
I0929 14:31:54.348150  2305 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0929 14:31:54.348289  2305 net.cpp:122] Setting up BatchNorm23
I0929 14:31:54.348294  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.348295  2305 net.cpp:137] Memory required for data: 567930000
I0929 14:31:54.348300  2305 layer_factory.hpp:77] Creating layer Scale23
I0929 14:31:54.348305  2305 net.cpp:84] Creating Layer Scale23
I0929 14:31:54.348309  2305 net.cpp:406] Scale23 <- Convolution23
I0929 14:31:54.348311  2305 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0929 14:31:54.348338  2305 layer_factory.hpp:77] Creating layer Scale23
I0929 14:31:54.348417  2305 net.cpp:122] Setting up Scale23
I0929 14:31:54.348422  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.348424  2305 net.cpp:137] Memory required for data: 570438800
I0929 14:31:54.348428  2305 layer_factory.hpp:77] Creating layer M2PELU22
I0929 14:31:54.348433  2305 net.cpp:84] Creating Layer M2PELU22
I0929 14:31:54.348435  2305 net.cpp:406] M2PELU22 <- Convolution23
I0929 14:31:54.348439  2305 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0929 14:31:54.348521  2305 net.cpp:122] Setting up M2PELU22
I0929 14:31:54.348526  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.348528  2305 net.cpp:137] Memory required for data: 572947600
I0929 14:31:54.348532  2305 layer_factory.hpp:77] Creating layer Convolution24
I0929 14:31:54.348538  2305 net.cpp:84] Creating Layer Convolution24
I0929 14:31:54.348541  2305 net.cpp:406] Convolution24 <- Convolution23
I0929 14:31:54.348546  2305 net.cpp:380] Convolution24 -> Convolution24
I0929 14:31:54.349596  2305 net.cpp:122] Setting up Convolution24
I0929 14:31:54.349604  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.349607  2305 net.cpp:137] Memory required for data: 575456400
I0929 14:31:54.349611  2305 layer_factory.hpp:77] Creating layer BatchNorm24
I0929 14:31:54.349617  2305 net.cpp:84] Creating Layer BatchNorm24
I0929 14:31:54.349619  2305 net.cpp:406] BatchNorm24 <- Convolution24
I0929 14:31:54.349624  2305 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0929 14:31:54.349759  2305 net.cpp:122] Setting up BatchNorm24
I0929 14:31:54.349764  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.349766  2305 net.cpp:137] Memory required for data: 577965200
I0929 14:31:54.349771  2305 layer_factory.hpp:77] Creating layer Scale24
I0929 14:31:54.349781  2305 net.cpp:84] Creating Layer Scale24
I0929 14:31:54.349784  2305 net.cpp:406] Scale24 <- Convolution24
I0929 14:31:54.349788  2305 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0929 14:31:54.349817  2305 layer_factory.hpp:77] Creating layer Scale24
I0929 14:31:54.349895  2305 net.cpp:122] Setting up Scale24
I0929 14:31:54.349900  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.349902  2305 net.cpp:137] Memory required for data: 580474000
I0929 14:31:54.349906  2305 layer_factory.hpp:77] Creating layer Eltwise11
I0929 14:31:54.349910  2305 net.cpp:84] Creating Layer Eltwise11
I0929 14:31:54.349912  2305 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0929 14:31:54.349915  2305 net.cpp:406] Eltwise11 <- Convolution24
I0929 14:31:54.349918  2305 net.cpp:380] Eltwise11 -> Eltwise11
I0929 14:31:54.349936  2305 net.cpp:122] Setting up Eltwise11
I0929 14:31:54.349938  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.349941  2305 net.cpp:137] Memory required for data: 582982800
I0929 14:31:54.349942  2305 layer_factory.hpp:77] Creating layer M2PELU23
I0929 14:31:54.349948  2305 net.cpp:84] Creating Layer M2PELU23
I0929 14:31:54.349951  2305 net.cpp:406] M2PELU23 <- Eltwise11
I0929 14:31:54.349954  2305 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0929 14:31:54.350039  2305 net.cpp:122] Setting up M2PELU23
I0929 14:31:54.350042  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.350044  2305 net.cpp:137] Memory required for data: 585491600
I0929 14:31:54.350049  2305 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0929 14:31:54.350052  2305 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0929 14:31:54.350054  2305 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0929 14:31:54.350059  2305 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0929 14:31:54.350062  2305 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0929 14:31:54.350086  2305 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0929 14:31:54.350090  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.350092  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.350095  2305 net.cpp:137] Memory required for data: 590509200
I0929 14:31:54.350096  2305 layer_factory.hpp:77] Creating layer Convolution25
I0929 14:31:54.350102  2305 net.cpp:84] Creating Layer Convolution25
I0929 14:31:54.350106  2305 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0929 14:31:54.350109  2305 net.cpp:380] Convolution25 -> Convolution25
I0929 14:31:54.351189  2305 net.cpp:122] Setting up Convolution25
I0929 14:31:54.351198  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.351200  2305 net.cpp:137] Memory required for data: 593018000
I0929 14:31:54.351205  2305 layer_factory.hpp:77] Creating layer BatchNorm25
I0929 14:31:54.351212  2305 net.cpp:84] Creating Layer BatchNorm25
I0929 14:31:54.351214  2305 net.cpp:406] BatchNorm25 <- Convolution25
I0929 14:31:54.351218  2305 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0929 14:31:54.351351  2305 net.cpp:122] Setting up BatchNorm25
I0929 14:31:54.351354  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.351356  2305 net.cpp:137] Memory required for data: 595526800
I0929 14:31:54.351361  2305 layer_factory.hpp:77] Creating layer Scale25
I0929 14:31:54.351366  2305 net.cpp:84] Creating Layer Scale25
I0929 14:31:54.351368  2305 net.cpp:406] Scale25 <- Convolution25
I0929 14:31:54.351372  2305 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0929 14:31:54.351397  2305 layer_factory.hpp:77] Creating layer Scale25
I0929 14:31:54.351472  2305 net.cpp:122] Setting up Scale25
I0929 14:31:54.351476  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.351478  2305 net.cpp:137] Memory required for data: 598035600
I0929 14:31:54.351482  2305 layer_factory.hpp:77] Creating layer M2PELU24
I0929 14:31:54.351487  2305 net.cpp:84] Creating Layer M2PELU24
I0929 14:31:54.351490  2305 net.cpp:406] M2PELU24 <- Convolution25
I0929 14:31:54.351502  2305 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0929 14:31:54.351585  2305 net.cpp:122] Setting up M2PELU24
I0929 14:31:54.351590  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.351593  2305 net.cpp:137] Memory required for data: 600544400
I0929 14:31:54.351596  2305 layer_factory.hpp:77] Creating layer Convolution26
I0929 14:31:54.351603  2305 net.cpp:84] Creating Layer Convolution26
I0929 14:31:54.351605  2305 net.cpp:406] Convolution26 <- Convolution25
I0929 14:31:54.351609  2305 net.cpp:380] Convolution26 -> Convolution26
I0929 14:31:54.352634  2305 net.cpp:122] Setting up Convolution26
I0929 14:31:54.352643  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.352646  2305 net.cpp:137] Memory required for data: 603053200
I0929 14:31:54.352650  2305 layer_factory.hpp:77] Creating layer BatchNorm26
I0929 14:31:54.352654  2305 net.cpp:84] Creating Layer BatchNorm26
I0929 14:31:54.352658  2305 net.cpp:406] BatchNorm26 <- Convolution26
I0929 14:31:54.352661  2305 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0929 14:31:54.352794  2305 net.cpp:122] Setting up BatchNorm26
I0929 14:31:54.352798  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.352800  2305 net.cpp:137] Memory required for data: 605562000
I0929 14:31:54.352804  2305 layer_factory.hpp:77] Creating layer Scale26
I0929 14:31:54.352808  2305 net.cpp:84] Creating Layer Scale26
I0929 14:31:54.352811  2305 net.cpp:406] Scale26 <- Convolution26
I0929 14:31:54.352814  2305 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0929 14:31:54.352840  2305 layer_factory.hpp:77] Creating layer Scale26
I0929 14:31:54.352917  2305 net.cpp:122] Setting up Scale26
I0929 14:31:54.352921  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.352923  2305 net.cpp:137] Memory required for data: 608070800
I0929 14:31:54.352927  2305 layer_factory.hpp:77] Creating layer Eltwise12
I0929 14:31:54.352931  2305 net.cpp:84] Creating Layer Eltwise12
I0929 14:31:54.352933  2305 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0929 14:31:54.352936  2305 net.cpp:406] Eltwise12 <- Convolution26
I0929 14:31:54.352939  2305 net.cpp:380] Eltwise12 -> Eltwise12
I0929 14:31:54.352957  2305 net.cpp:122] Setting up Eltwise12
I0929 14:31:54.352960  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.352962  2305 net.cpp:137] Memory required for data: 610579600
I0929 14:31:54.352964  2305 layer_factory.hpp:77] Creating layer M2PELU25
I0929 14:31:54.352969  2305 net.cpp:84] Creating Layer M2PELU25
I0929 14:31:54.352972  2305 net.cpp:406] M2PELU25 <- Eltwise12
I0929 14:31:54.352975  2305 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0929 14:31:54.353058  2305 net.cpp:122] Setting up M2PELU25
I0929 14:31:54.353063  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.353065  2305 net.cpp:137] Memory required for data: 613088400
I0929 14:31:54.353068  2305 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0929 14:31:54.353080  2305 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0929 14:31:54.353083  2305 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0929 14:31:54.353086  2305 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0929 14:31:54.353096  2305 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0929 14:31:54.353119  2305 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0929 14:31:54.353123  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.353127  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.353128  2305 net.cpp:137] Memory required for data: 618106000
I0929 14:31:54.353132  2305 layer_factory.hpp:77] Creating layer Convolution27
I0929 14:31:54.353137  2305 net.cpp:84] Creating Layer Convolution27
I0929 14:31:54.353139  2305 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0929 14:31:54.353145  2305 net.cpp:380] Convolution27 -> Convolution27
I0929 14:31:54.353847  2305 net.cpp:122] Setting up Convolution27
I0929 14:31:54.353860  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.353863  2305 net.cpp:137] Memory required for data: 620614800
I0929 14:31:54.353868  2305 layer_factory.hpp:77] Creating layer BatchNorm27
I0929 14:31:54.353873  2305 net.cpp:84] Creating Layer BatchNorm27
I0929 14:31:54.353874  2305 net.cpp:406] BatchNorm27 <- Convolution27
I0929 14:31:54.353878  2305 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0929 14:31:54.354012  2305 net.cpp:122] Setting up BatchNorm27
I0929 14:31:54.354017  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.354018  2305 net.cpp:137] Memory required for data: 623123600
I0929 14:31:54.354022  2305 layer_factory.hpp:77] Creating layer Scale27
I0929 14:31:54.354027  2305 net.cpp:84] Creating Layer Scale27
I0929 14:31:54.354029  2305 net.cpp:406] Scale27 <- Convolution27
I0929 14:31:54.354032  2305 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0929 14:31:54.354058  2305 layer_factory.hpp:77] Creating layer Scale27
I0929 14:31:54.354133  2305 net.cpp:122] Setting up Scale27
I0929 14:31:54.354137  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.354140  2305 net.cpp:137] Memory required for data: 625632400
I0929 14:31:54.354143  2305 layer_factory.hpp:77] Creating layer M2PELU26
I0929 14:31:54.354148  2305 net.cpp:84] Creating Layer M2PELU26
I0929 14:31:54.354151  2305 net.cpp:406] M2PELU26 <- Convolution27
I0929 14:31:54.354154  2305 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0929 14:31:54.354259  2305 net.cpp:122] Setting up M2PELU26
I0929 14:31:54.354264  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.354265  2305 net.cpp:137] Memory required for data: 628141200
I0929 14:31:54.354269  2305 layer_factory.hpp:77] Creating layer Convolution28
I0929 14:31:54.354275  2305 net.cpp:84] Creating Layer Convolution28
I0929 14:31:54.354279  2305 net.cpp:406] Convolution28 <- Convolution27
I0929 14:31:54.354282  2305 net.cpp:380] Convolution28 -> Convolution28
I0929 14:31:54.355309  2305 net.cpp:122] Setting up Convolution28
I0929 14:31:54.355319  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.355320  2305 net.cpp:137] Memory required for data: 630650000
I0929 14:31:54.355325  2305 layer_factory.hpp:77] Creating layer BatchNorm28
I0929 14:31:54.355330  2305 net.cpp:84] Creating Layer BatchNorm28
I0929 14:31:54.355332  2305 net.cpp:406] BatchNorm28 <- Convolution28
I0929 14:31:54.355336  2305 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0929 14:31:54.355473  2305 net.cpp:122] Setting up BatchNorm28
I0929 14:31:54.355478  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.355479  2305 net.cpp:137] Memory required for data: 633158800
I0929 14:31:54.355484  2305 layer_factory.hpp:77] Creating layer Scale28
I0929 14:31:54.355487  2305 net.cpp:84] Creating Layer Scale28
I0929 14:31:54.355490  2305 net.cpp:406] Scale28 <- Convolution28
I0929 14:31:54.355494  2305 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0929 14:31:54.355520  2305 layer_factory.hpp:77] Creating layer Scale28
I0929 14:31:54.355595  2305 net.cpp:122] Setting up Scale28
I0929 14:31:54.355599  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.355602  2305 net.cpp:137] Memory required for data: 635667600
I0929 14:31:54.355605  2305 layer_factory.hpp:77] Creating layer Eltwise13
I0929 14:31:54.355609  2305 net.cpp:84] Creating Layer Eltwise13
I0929 14:31:54.355612  2305 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0929 14:31:54.355615  2305 net.cpp:406] Eltwise13 <- Convolution28
I0929 14:31:54.355618  2305 net.cpp:380] Eltwise13 -> Eltwise13
I0929 14:31:54.355633  2305 net.cpp:122] Setting up Eltwise13
I0929 14:31:54.355636  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.355638  2305 net.cpp:137] Memory required for data: 638176400
I0929 14:31:54.355640  2305 layer_factory.hpp:77] Creating layer M2PELU27
I0929 14:31:54.355645  2305 net.cpp:84] Creating Layer M2PELU27
I0929 14:31:54.355648  2305 net.cpp:406] M2PELU27 <- Eltwise13
I0929 14:31:54.355651  2305 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0929 14:31:54.355742  2305 net.cpp:122] Setting up M2PELU27
I0929 14:31:54.355748  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.355751  2305 net.cpp:137] Memory required for data: 640685200
I0929 14:31:54.355754  2305 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0929 14:31:54.355757  2305 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0929 14:31:54.355760  2305 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0929 14:31:54.355763  2305 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0929 14:31:54.355767  2305 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0929 14:31:54.355792  2305 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0929 14:31:54.355795  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.355798  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.355800  2305 net.cpp:137] Memory required for data: 645702800
I0929 14:31:54.355803  2305 layer_factory.hpp:77] Creating layer Convolution29
I0929 14:31:54.355808  2305 net.cpp:84] Creating Layer Convolution29
I0929 14:31:54.355810  2305 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0929 14:31:54.355814  2305 net.cpp:380] Convolution29 -> Convolution29
I0929 14:31:54.356839  2305 net.cpp:122] Setting up Convolution29
I0929 14:31:54.356848  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.356850  2305 net.cpp:137] Memory required for data: 648211600
I0929 14:31:54.356855  2305 layer_factory.hpp:77] Creating layer BatchNorm29
I0929 14:31:54.356860  2305 net.cpp:84] Creating Layer BatchNorm29
I0929 14:31:54.356863  2305 net.cpp:406] BatchNorm29 <- Convolution29
I0929 14:31:54.356866  2305 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0929 14:31:54.357002  2305 net.cpp:122] Setting up BatchNorm29
I0929 14:31:54.357005  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.357007  2305 net.cpp:137] Memory required for data: 650720400
I0929 14:31:54.357012  2305 layer_factory.hpp:77] Creating layer Scale29
I0929 14:31:54.357017  2305 net.cpp:84] Creating Layer Scale29
I0929 14:31:54.357019  2305 net.cpp:406] Scale29 <- Convolution29
I0929 14:31:54.357023  2305 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0929 14:31:54.357048  2305 layer_factory.hpp:77] Creating layer Scale29
I0929 14:31:54.357127  2305 net.cpp:122] Setting up Scale29
I0929 14:31:54.357131  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.357133  2305 net.cpp:137] Memory required for data: 653229200
I0929 14:31:54.357154  2305 layer_factory.hpp:77] Creating layer M2PELU28
I0929 14:31:54.357161  2305 net.cpp:84] Creating Layer M2PELU28
I0929 14:31:54.357164  2305 net.cpp:406] M2PELU28 <- Convolution29
I0929 14:31:54.357167  2305 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0929 14:31:54.357254  2305 net.cpp:122] Setting up M2PELU28
I0929 14:31:54.357259  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.357261  2305 net.cpp:137] Memory required for data: 655738000
I0929 14:31:54.357264  2305 layer_factory.hpp:77] Creating layer Convolution30
I0929 14:31:54.357271  2305 net.cpp:84] Creating Layer Convolution30
I0929 14:31:54.357273  2305 net.cpp:406] Convolution30 <- Convolution29
I0929 14:31:54.357277  2305 net.cpp:380] Convolution30 -> Convolution30
I0929 14:31:54.358342  2305 net.cpp:122] Setting up Convolution30
I0929 14:31:54.358351  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.358355  2305 net.cpp:137] Memory required for data: 658246800
I0929 14:31:54.358358  2305 layer_factory.hpp:77] Creating layer BatchNorm30
I0929 14:31:54.358363  2305 net.cpp:84] Creating Layer BatchNorm30
I0929 14:31:54.358366  2305 net.cpp:406] BatchNorm30 <- Convolution30
I0929 14:31:54.358371  2305 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0929 14:31:54.358543  2305 net.cpp:122] Setting up BatchNorm30
I0929 14:31:54.358548  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.358551  2305 net.cpp:137] Memory required for data: 660755600
I0929 14:31:54.358562  2305 layer_factory.hpp:77] Creating layer Scale30
I0929 14:31:54.358567  2305 net.cpp:84] Creating Layer Scale30
I0929 14:31:54.358570  2305 net.cpp:406] Scale30 <- Convolution30
I0929 14:31:54.358574  2305 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0929 14:31:54.358602  2305 layer_factory.hpp:77] Creating layer Scale30
I0929 14:31:54.358680  2305 net.cpp:122] Setting up Scale30
I0929 14:31:54.358685  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.358686  2305 net.cpp:137] Memory required for data: 663264400
I0929 14:31:54.358690  2305 layer_factory.hpp:77] Creating layer Eltwise14
I0929 14:31:54.358695  2305 net.cpp:84] Creating Layer Eltwise14
I0929 14:31:54.358696  2305 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0929 14:31:54.358700  2305 net.cpp:406] Eltwise14 <- Convolution30
I0929 14:31:54.358705  2305 net.cpp:380] Eltwise14 -> Eltwise14
I0929 14:31:54.358721  2305 net.cpp:122] Setting up Eltwise14
I0929 14:31:54.358724  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.358726  2305 net.cpp:137] Memory required for data: 665773200
I0929 14:31:54.358729  2305 layer_factory.hpp:77] Creating layer M2PELU29
I0929 14:31:54.358733  2305 net.cpp:84] Creating Layer M2PELU29
I0929 14:31:54.358736  2305 net.cpp:406] M2PELU29 <- Eltwise14
I0929 14:31:54.358739  2305 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0929 14:31:54.358824  2305 net.cpp:122] Setting up M2PELU29
I0929 14:31:54.358829  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.358831  2305 net.cpp:137] Memory required for data: 668282000
I0929 14:31:54.358834  2305 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0929 14:31:54.358839  2305 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0929 14:31:54.358841  2305 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0929 14:31:54.358844  2305 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0929 14:31:54.358849  2305 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0929 14:31:54.358872  2305 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0929 14:31:54.358875  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.358878  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.358880  2305 net.cpp:137] Memory required for data: 673299600
I0929 14:31:54.358882  2305 layer_factory.hpp:77] Creating layer Convolution31
I0929 14:31:54.358888  2305 net.cpp:84] Creating Layer Convolution31
I0929 14:31:54.358891  2305 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0929 14:31:54.358896  2305 net.cpp:380] Convolution31 -> Convolution31
I0929 14:31:54.359933  2305 net.cpp:122] Setting up Convolution31
I0929 14:31:54.359942  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.359946  2305 net.cpp:137] Memory required for data: 675808400
I0929 14:31:54.359949  2305 layer_factory.hpp:77] Creating layer BatchNorm31
I0929 14:31:54.359956  2305 net.cpp:84] Creating Layer BatchNorm31
I0929 14:31:54.359958  2305 net.cpp:406] BatchNorm31 <- Convolution31
I0929 14:31:54.359961  2305 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0929 14:31:54.360098  2305 net.cpp:122] Setting up BatchNorm31
I0929 14:31:54.360102  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.360105  2305 net.cpp:137] Memory required for data: 678317200
I0929 14:31:54.360110  2305 layer_factory.hpp:77] Creating layer Scale31
I0929 14:31:54.360113  2305 net.cpp:84] Creating Layer Scale31
I0929 14:31:54.360116  2305 net.cpp:406] Scale31 <- Convolution31
I0929 14:31:54.360118  2305 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0929 14:31:54.360147  2305 layer_factory.hpp:77] Creating layer Scale31
I0929 14:31:54.360224  2305 net.cpp:122] Setting up Scale31
I0929 14:31:54.360227  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.360229  2305 net.cpp:137] Memory required for data: 680826000
I0929 14:31:54.360234  2305 layer_factory.hpp:77] Creating layer M2PELU30
I0929 14:31:54.360246  2305 net.cpp:84] Creating Layer M2PELU30
I0929 14:31:54.360249  2305 net.cpp:406] M2PELU30 <- Convolution31
I0929 14:31:54.360254  2305 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0929 14:31:54.360371  2305 net.cpp:122] Setting up M2PELU30
I0929 14:31:54.360385  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.360388  2305 net.cpp:137] Memory required for data: 683334800
I0929 14:31:54.360390  2305 layer_factory.hpp:77] Creating layer Convolution32
I0929 14:31:54.360397  2305 net.cpp:84] Creating Layer Convolution32
I0929 14:31:54.360400  2305 net.cpp:406] Convolution32 <- Convolution31
I0929 14:31:54.360405  2305 net.cpp:380] Convolution32 -> Convolution32
I0929 14:31:54.361440  2305 net.cpp:122] Setting up Convolution32
I0929 14:31:54.361449  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.361451  2305 net.cpp:137] Memory required for data: 685843600
I0929 14:31:54.361455  2305 layer_factory.hpp:77] Creating layer BatchNorm32
I0929 14:31:54.361460  2305 net.cpp:84] Creating Layer BatchNorm32
I0929 14:31:54.361464  2305 net.cpp:406] BatchNorm32 <- Convolution32
I0929 14:31:54.361466  2305 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0929 14:31:54.361637  2305 net.cpp:122] Setting up BatchNorm32
I0929 14:31:54.361642  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.361644  2305 net.cpp:137] Memory required for data: 688352400
I0929 14:31:54.361649  2305 layer_factory.hpp:77] Creating layer Scale32
I0929 14:31:54.361665  2305 net.cpp:84] Creating Layer Scale32
I0929 14:31:54.361667  2305 net.cpp:406] Scale32 <- Convolution32
I0929 14:31:54.361670  2305 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0929 14:31:54.361708  2305 layer_factory.hpp:77] Creating layer Scale32
I0929 14:31:54.361795  2305 net.cpp:122] Setting up Scale32
I0929 14:31:54.361799  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.361801  2305 net.cpp:137] Memory required for data: 690861200
I0929 14:31:54.361805  2305 layer_factory.hpp:77] Creating layer Eltwise15
I0929 14:31:54.361810  2305 net.cpp:84] Creating Layer Eltwise15
I0929 14:31:54.361814  2305 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0929 14:31:54.361816  2305 net.cpp:406] Eltwise15 <- Convolution32
I0929 14:31:54.361819  2305 net.cpp:380] Eltwise15 -> Eltwise15
I0929 14:31:54.361835  2305 net.cpp:122] Setting up Eltwise15
I0929 14:31:54.361840  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.361841  2305 net.cpp:137] Memory required for data: 693370000
I0929 14:31:54.361843  2305 layer_factory.hpp:77] Creating layer M2PELU31
I0929 14:31:54.361848  2305 net.cpp:84] Creating Layer M2PELU31
I0929 14:31:54.361850  2305 net.cpp:406] M2PELU31 <- Eltwise15
I0929 14:31:54.361853  2305 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0929 14:31:54.361937  2305 net.cpp:122] Setting up M2PELU31
I0929 14:31:54.361940  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.361943  2305 net.cpp:137] Memory required for data: 695878800
I0929 14:31:54.361946  2305 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0929 14:31:54.361950  2305 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0929 14:31:54.361953  2305 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0929 14:31:54.361956  2305 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0929 14:31:54.361961  2305 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0929 14:31:54.361984  2305 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0929 14:31:54.361989  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.361991  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.361994  2305 net.cpp:137] Memory required for data: 700896400
I0929 14:31:54.361995  2305 layer_factory.hpp:77] Creating layer Convolution33
I0929 14:31:54.362000  2305 net.cpp:84] Creating Layer Convolution33
I0929 14:31:54.362004  2305 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0929 14:31:54.362010  2305 net.cpp:380] Convolution33 -> Convolution33
I0929 14:31:54.363451  2305 net.cpp:122] Setting up Convolution33
I0929 14:31:54.363461  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.363463  2305 net.cpp:137] Memory required for data: 703405200
I0929 14:31:54.363467  2305 layer_factory.hpp:77] Creating layer BatchNorm33
I0929 14:31:54.363472  2305 net.cpp:84] Creating Layer BatchNorm33
I0929 14:31:54.363476  2305 net.cpp:406] BatchNorm33 <- Convolution33
I0929 14:31:54.363481  2305 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0929 14:31:54.363620  2305 net.cpp:122] Setting up BatchNorm33
I0929 14:31:54.363625  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.363626  2305 net.cpp:137] Memory required for data: 705914000
I0929 14:31:54.363631  2305 layer_factory.hpp:77] Creating layer Scale33
I0929 14:31:54.363636  2305 net.cpp:84] Creating Layer Scale33
I0929 14:31:54.363638  2305 net.cpp:406] Scale33 <- Convolution33
I0929 14:31:54.363641  2305 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0929 14:31:54.363668  2305 layer_factory.hpp:77] Creating layer Scale33
I0929 14:31:54.363746  2305 net.cpp:122] Setting up Scale33
I0929 14:31:54.363750  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.363752  2305 net.cpp:137] Memory required for data: 708422800
I0929 14:31:54.363756  2305 layer_factory.hpp:77] Creating layer M2PELU32
I0929 14:31:54.363761  2305 net.cpp:84] Creating Layer M2PELU32
I0929 14:31:54.363765  2305 net.cpp:406] M2PELU32 <- Convolution33
I0929 14:31:54.363768  2305 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0929 14:31:54.363852  2305 net.cpp:122] Setting up M2PELU32
I0929 14:31:54.363857  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.363858  2305 net.cpp:137] Memory required for data: 710931600
I0929 14:31:54.363862  2305 layer_factory.hpp:77] Creating layer Convolution34
I0929 14:31:54.363867  2305 net.cpp:84] Creating Layer Convolution34
I0929 14:31:54.363870  2305 net.cpp:406] Convolution34 <- Convolution33
I0929 14:31:54.363874  2305 net.cpp:380] Convolution34 -> Convolution34
I0929 14:31:54.364912  2305 net.cpp:122] Setting up Convolution34
I0929 14:31:54.364922  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.364923  2305 net.cpp:137] Memory required for data: 713440400
I0929 14:31:54.364928  2305 layer_factory.hpp:77] Creating layer BatchNorm34
I0929 14:31:54.364933  2305 net.cpp:84] Creating Layer BatchNorm34
I0929 14:31:54.364936  2305 net.cpp:406] BatchNorm34 <- Convolution34
I0929 14:31:54.364939  2305 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0929 14:31:54.365077  2305 net.cpp:122] Setting up BatchNorm34
I0929 14:31:54.365082  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.365083  2305 net.cpp:137] Memory required for data: 715949200
I0929 14:31:54.365087  2305 layer_factory.hpp:77] Creating layer Scale34
I0929 14:31:54.365092  2305 net.cpp:84] Creating Layer Scale34
I0929 14:31:54.365094  2305 net.cpp:406] Scale34 <- Convolution34
I0929 14:31:54.365097  2305 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0929 14:31:54.365124  2305 layer_factory.hpp:77] Creating layer Scale34
I0929 14:31:54.365203  2305 net.cpp:122] Setting up Scale34
I0929 14:31:54.365208  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.365211  2305 net.cpp:137] Memory required for data: 718458000
I0929 14:31:54.365214  2305 layer_factory.hpp:77] Creating layer Eltwise16
I0929 14:31:54.365218  2305 net.cpp:84] Creating Layer Eltwise16
I0929 14:31:54.365221  2305 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0929 14:31:54.365223  2305 net.cpp:406] Eltwise16 <- Convolution34
I0929 14:31:54.365226  2305 net.cpp:380] Eltwise16 -> Eltwise16
I0929 14:31:54.365243  2305 net.cpp:122] Setting up Eltwise16
I0929 14:31:54.365247  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.365249  2305 net.cpp:137] Memory required for data: 720966800
I0929 14:31:54.365252  2305 layer_factory.hpp:77] Creating layer M2PELU33
I0929 14:31:54.365257  2305 net.cpp:84] Creating Layer M2PELU33
I0929 14:31:54.365265  2305 net.cpp:406] M2PELU33 <- Eltwise16
I0929 14:31:54.365269  2305 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0929 14:31:54.365355  2305 net.cpp:122] Setting up M2PELU33
I0929 14:31:54.365360  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.365361  2305 net.cpp:137] Memory required for data: 723475600
I0929 14:31:54.365365  2305 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0929 14:31:54.365368  2305 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0929 14:31:54.365370  2305 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0929 14:31:54.365373  2305 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0929 14:31:54.365378  2305 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0929 14:31:54.365401  2305 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0929 14:31:54.365406  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.365408  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.365411  2305 net.cpp:137] Memory required for data: 728493200
I0929 14:31:54.365412  2305 layer_factory.hpp:77] Creating layer Convolution35
I0929 14:31:54.365418  2305 net.cpp:84] Creating Layer Convolution35
I0929 14:31:54.365420  2305 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0929 14:31:54.365424  2305 net.cpp:380] Convolution35 -> Convolution35
I0929 14:31:54.366459  2305 net.cpp:122] Setting up Convolution35
I0929 14:31:54.366468  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.366470  2305 net.cpp:137] Memory required for data: 731002000
I0929 14:31:54.366475  2305 layer_factory.hpp:77] Creating layer BatchNorm35
I0929 14:31:54.366480  2305 net.cpp:84] Creating Layer BatchNorm35
I0929 14:31:54.366483  2305 net.cpp:406] BatchNorm35 <- Convolution35
I0929 14:31:54.366487  2305 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0929 14:31:54.366647  2305 net.cpp:122] Setting up BatchNorm35
I0929 14:31:54.366652  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.366653  2305 net.cpp:137] Memory required for data: 733510800
I0929 14:31:54.366658  2305 layer_factory.hpp:77] Creating layer Scale35
I0929 14:31:54.366663  2305 net.cpp:84] Creating Layer Scale35
I0929 14:31:54.366665  2305 net.cpp:406] Scale35 <- Convolution35
I0929 14:31:54.366668  2305 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0929 14:31:54.366695  2305 layer_factory.hpp:77] Creating layer Scale35
I0929 14:31:54.366775  2305 net.cpp:122] Setting up Scale35
I0929 14:31:54.366778  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.366780  2305 net.cpp:137] Memory required for data: 736019600
I0929 14:31:54.366785  2305 layer_factory.hpp:77] Creating layer M2PELU34
I0929 14:31:54.366788  2305 net.cpp:84] Creating Layer M2PELU34
I0929 14:31:54.366792  2305 net.cpp:406] M2PELU34 <- Convolution35
I0929 14:31:54.366796  2305 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0929 14:31:54.366878  2305 net.cpp:122] Setting up M2PELU34
I0929 14:31:54.366883  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.366885  2305 net.cpp:137] Memory required for data: 738528400
I0929 14:31:54.366889  2305 layer_factory.hpp:77] Creating layer Convolution36
I0929 14:31:54.366894  2305 net.cpp:84] Creating Layer Convolution36
I0929 14:31:54.366897  2305 net.cpp:406] Convolution36 <- Convolution35
I0929 14:31:54.366901  2305 net.cpp:380] Convolution36 -> Convolution36
I0929 14:31:54.367933  2305 net.cpp:122] Setting up Convolution36
I0929 14:31:54.367941  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.367944  2305 net.cpp:137] Memory required for data: 741037200
I0929 14:31:54.367949  2305 layer_factory.hpp:77] Creating layer BatchNorm36
I0929 14:31:54.367954  2305 net.cpp:84] Creating Layer BatchNorm36
I0929 14:31:54.367956  2305 net.cpp:406] BatchNorm36 <- Convolution36
I0929 14:31:54.367959  2305 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0929 14:31:54.368094  2305 net.cpp:122] Setting up BatchNorm36
I0929 14:31:54.368099  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.368108  2305 net.cpp:137] Memory required for data: 743546000
I0929 14:31:54.368113  2305 layer_factory.hpp:77] Creating layer Scale36
I0929 14:31:54.368118  2305 net.cpp:84] Creating Layer Scale36
I0929 14:31:54.368120  2305 net.cpp:406] Scale36 <- Convolution36
I0929 14:31:54.368124  2305 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0929 14:31:54.368152  2305 layer_factory.hpp:77] Creating layer Scale36
I0929 14:31:54.368229  2305 net.cpp:122] Setting up Scale36
I0929 14:31:54.368234  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.368237  2305 net.cpp:137] Memory required for data: 746054800
I0929 14:31:54.368242  2305 layer_factory.hpp:77] Creating layer Eltwise17
I0929 14:31:54.368244  2305 net.cpp:84] Creating Layer Eltwise17
I0929 14:31:54.368247  2305 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0929 14:31:54.368250  2305 net.cpp:406] Eltwise17 <- Convolution36
I0929 14:31:54.368253  2305 net.cpp:380] Eltwise17 -> Eltwise17
I0929 14:31:54.368270  2305 net.cpp:122] Setting up Eltwise17
I0929 14:31:54.368273  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.368275  2305 net.cpp:137] Memory required for data: 748563600
I0929 14:31:54.368278  2305 layer_factory.hpp:77] Creating layer M2PELU35
I0929 14:31:54.368283  2305 net.cpp:84] Creating Layer M2PELU35
I0929 14:31:54.368285  2305 net.cpp:406] M2PELU35 <- Eltwise17
I0929 14:31:54.368288  2305 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0929 14:31:54.368374  2305 net.cpp:122] Setting up M2PELU35
I0929 14:31:54.368379  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.368381  2305 net.cpp:137] Memory required for data: 751072400
I0929 14:31:54.368384  2305 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0929 14:31:54.368388  2305 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0929 14:31:54.368391  2305 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0929 14:31:54.368393  2305 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0929 14:31:54.368398  2305 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0929 14:31:54.368422  2305 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0929 14:31:54.368425  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.368428  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.368430  2305 net.cpp:137] Memory required for data: 756090000
I0929 14:31:54.368432  2305 layer_factory.hpp:77] Creating layer Convolution37
I0929 14:31:54.368439  2305 net.cpp:84] Creating Layer Convolution37
I0929 14:31:54.368443  2305 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0929 14:31:54.368445  2305 net.cpp:380] Convolution37 -> Convolution37
I0929 14:31:54.369156  2305 net.cpp:122] Setting up Convolution37
I0929 14:31:54.369164  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.369166  2305 net.cpp:137] Memory required for data: 758598800
I0929 14:31:54.369170  2305 layer_factory.hpp:77] Creating layer BatchNorm37
I0929 14:31:54.369174  2305 net.cpp:84] Creating Layer BatchNorm37
I0929 14:31:54.369177  2305 net.cpp:406] BatchNorm37 <- Convolution37
I0929 14:31:54.369181  2305 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0929 14:31:54.369316  2305 net.cpp:122] Setting up BatchNorm37
I0929 14:31:54.369320  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.369323  2305 net.cpp:137] Memory required for data: 761107600
I0929 14:31:54.369328  2305 layer_factory.hpp:77] Creating layer Scale37
I0929 14:31:54.369330  2305 net.cpp:84] Creating Layer Scale37
I0929 14:31:54.369333  2305 net.cpp:406] Scale37 <- Convolution37
I0929 14:31:54.369336  2305 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0929 14:31:54.369362  2305 layer_factory.hpp:77] Creating layer Scale37
I0929 14:31:54.369439  2305 net.cpp:122] Setting up Scale37
I0929 14:31:54.369443  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.369446  2305 net.cpp:137] Memory required for data: 763616400
I0929 14:31:54.369455  2305 layer_factory.hpp:77] Creating layer M2PELU36
I0929 14:31:54.369460  2305 net.cpp:84] Creating Layer M2PELU36
I0929 14:31:54.369462  2305 net.cpp:406] M2PELU36 <- Convolution37
I0929 14:31:54.369467  2305 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0929 14:31:54.369552  2305 net.cpp:122] Setting up M2PELU36
I0929 14:31:54.369557  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.369560  2305 net.cpp:137] Memory required for data: 766125200
I0929 14:31:54.369562  2305 layer_factory.hpp:77] Creating layer Convolution38
I0929 14:31:54.369570  2305 net.cpp:84] Creating Layer Convolution38
I0929 14:31:54.369572  2305 net.cpp:406] Convolution38 <- Convolution37
I0929 14:31:54.369575  2305 net.cpp:380] Convolution38 -> Convolution38
I0929 14:31:54.370652  2305 net.cpp:122] Setting up Convolution38
I0929 14:31:54.370661  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.370663  2305 net.cpp:137] Memory required for data: 768634000
I0929 14:31:54.370668  2305 layer_factory.hpp:77] Creating layer BatchNorm38
I0929 14:31:54.370673  2305 net.cpp:84] Creating Layer BatchNorm38
I0929 14:31:54.370676  2305 net.cpp:406] BatchNorm38 <- Convolution38
I0929 14:31:54.370681  2305 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0929 14:31:54.370815  2305 net.cpp:122] Setting up BatchNorm38
I0929 14:31:54.370820  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.370822  2305 net.cpp:137] Memory required for data: 771142800
I0929 14:31:54.370827  2305 layer_factory.hpp:77] Creating layer Scale38
I0929 14:31:54.370832  2305 net.cpp:84] Creating Layer Scale38
I0929 14:31:54.370834  2305 net.cpp:406] Scale38 <- Convolution38
I0929 14:31:54.370837  2305 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0929 14:31:54.370864  2305 layer_factory.hpp:77] Creating layer Scale38
I0929 14:31:54.370941  2305 net.cpp:122] Setting up Scale38
I0929 14:31:54.370945  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.370947  2305 net.cpp:137] Memory required for data: 773651600
I0929 14:31:54.370951  2305 layer_factory.hpp:77] Creating layer Eltwise18
I0929 14:31:54.370955  2305 net.cpp:84] Creating Layer Eltwise18
I0929 14:31:54.370959  2305 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0929 14:31:54.370961  2305 net.cpp:406] Eltwise18 <- Convolution38
I0929 14:31:54.370965  2305 net.cpp:380] Eltwise18 -> Eltwise18
I0929 14:31:54.370980  2305 net.cpp:122] Setting up Eltwise18
I0929 14:31:54.370985  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.370986  2305 net.cpp:137] Memory required for data: 776160400
I0929 14:31:54.370988  2305 layer_factory.hpp:77] Creating layer M2PELU37
I0929 14:31:54.370995  2305 net.cpp:84] Creating Layer M2PELU37
I0929 14:31:54.370996  2305 net.cpp:406] M2PELU37 <- Eltwise18
I0929 14:31:54.370999  2305 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0929 14:31:54.371084  2305 net.cpp:122] Setting up M2PELU37
I0929 14:31:54.371088  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.371090  2305 net.cpp:137] Memory required for data: 778669200
I0929 14:31:54.371094  2305 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0929 14:31:54.371098  2305 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0929 14:31:54.371099  2305 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0929 14:31:54.371104  2305 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0929 14:31:54.371107  2305 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0929 14:31:54.371130  2305 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0929 14:31:54.371134  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.371137  2305 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0929 14:31:54.371140  2305 net.cpp:137] Memory required for data: 783686800
I0929 14:31:54.371141  2305 layer_factory.hpp:77] Creating layer Convolution39
I0929 14:31:54.371146  2305 net.cpp:84] Creating Layer Convolution39
I0929 14:31:54.371150  2305 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0929 14:31:54.371160  2305 net.cpp:380] Convolution39 -> Convolution39
I0929 14:31:54.372046  2305 net.cpp:122] Setting up Convolution39
I0929 14:31:54.372056  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.372058  2305 net.cpp:137] Memory required for data: 784941200
I0929 14:31:54.372063  2305 layer_factory.hpp:77] Creating layer BatchNorm39
I0929 14:31:54.372067  2305 net.cpp:84] Creating Layer BatchNorm39
I0929 14:31:54.372071  2305 net.cpp:406] BatchNorm39 <- Convolution39
I0929 14:31:54.372074  2305 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0929 14:31:54.372210  2305 net.cpp:122] Setting up BatchNorm39
I0929 14:31:54.372215  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.372216  2305 net.cpp:137] Memory required for data: 786195600
I0929 14:31:54.372220  2305 layer_factory.hpp:77] Creating layer Scale39
I0929 14:31:54.372225  2305 net.cpp:84] Creating Layer Scale39
I0929 14:31:54.372227  2305 net.cpp:406] Scale39 <- Convolution39
I0929 14:31:54.372231  2305 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0929 14:31:54.372256  2305 layer_factory.hpp:77] Creating layer Scale39
I0929 14:31:54.372334  2305 net.cpp:122] Setting up Scale39
I0929 14:31:54.372337  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.372340  2305 net.cpp:137] Memory required for data: 787450000
I0929 14:31:54.372344  2305 layer_factory.hpp:77] Creating layer Convolution40
I0929 14:31:54.372350  2305 net.cpp:84] Creating Layer Convolution40
I0929 14:31:54.372354  2305 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0929 14:31:54.372359  2305 net.cpp:380] Convolution40 -> Convolution40
I0929 14:31:54.374140  2305 net.cpp:122] Setting up Convolution40
I0929 14:31:54.374150  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.374152  2305 net.cpp:137] Memory required for data: 788704400
I0929 14:31:54.374157  2305 layer_factory.hpp:77] Creating layer BatchNorm40
I0929 14:31:54.374162  2305 net.cpp:84] Creating Layer BatchNorm40
I0929 14:31:54.374166  2305 net.cpp:406] BatchNorm40 <- Convolution40
I0929 14:31:54.374171  2305 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0929 14:31:54.374339  2305 net.cpp:122] Setting up BatchNorm40
I0929 14:31:54.374344  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.374346  2305 net.cpp:137] Memory required for data: 789958800
I0929 14:31:54.374351  2305 layer_factory.hpp:77] Creating layer Scale40
I0929 14:31:54.374356  2305 net.cpp:84] Creating Layer Scale40
I0929 14:31:54.374358  2305 net.cpp:406] Scale40 <- Convolution40
I0929 14:31:54.374362  2305 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0929 14:31:54.374389  2305 layer_factory.hpp:77] Creating layer Scale40
I0929 14:31:54.374469  2305 net.cpp:122] Setting up Scale40
I0929 14:31:54.374475  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.374476  2305 net.cpp:137] Memory required for data: 791213200
I0929 14:31:54.374480  2305 layer_factory.hpp:77] Creating layer M2PELU38
I0929 14:31:54.374485  2305 net.cpp:84] Creating Layer M2PELU38
I0929 14:31:54.374487  2305 net.cpp:406] M2PELU38 <- Convolution40
I0929 14:31:54.374491  2305 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0929 14:31:54.374590  2305 net.cpp:122] Setting up M2PELU38
I0929 14:31:54.374595  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.374598  2305 net.cpp:137] Memory required for data: 792467600
I0929 14:31:54.374601  2305 layer_factory.hpp:77] Creating layer Convolution41
I0929 14:31:54.374609  2305 net.cpp:84] Creating Layer Convolution41
I0929 14:31:54.374611  2305 net.cpp:406] Convolution41 <- Convolution40
I0929 14:31:54.374615  2305 net.cpp:380] Convolution41 -> Convolution41
I0929 14:31:54.377133  2305 net.cpp:122] Setting up Convolution41
I0929 14:31:54.377146  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.377148  2305 net.cpp:137] Memory required for data: 793722000
I0929 14:31:54.377153  2305 layer_factory.hpp:77] Creating layer BatchNorm41
I0929 14:31:54.377159  2305 net.cpp:84] Creating Layer BatchNorm41
I0929 14:31:54.377171  2305 net.cpp:406] BatchNorm41 <- Convolution41
I0929 14:31:54.377177  2305 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0929 14:31:54.377322  2305 net.cpp:122] Setting up BatchNorm41
I0929 14:31:54.377328  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.377331  2305 net.cpp:137] Memory required for data: 794976400
I0929 14:31:54.377336  2305 layer_factory.hpp:77] Creating layer Scale41
I0929 14:31:54.377339  2305 net.cpp:84] Creating Layer Scale41
I0929 14:31:54.377342  2305 net.cpp:406] Scale41 <- Convolution41
I0929 14:31:54.377346  2305 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0929 14:31:54.377375  2305 layer_factory.hpp:77] Creating layer Scale41
I0929 14:31:54.377457  2305 net.cpp:122] Setting up Scale41
I0929 14:31:54.377462  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.377465  2305 net.cpp:137] Memory required for data: 796230800
I0929 14:31:54.377468  2305 layer_factory.hpp:77] Creating layer Eltwise19
I0929 14:31:54.377473  2305 net.cpp:84] Creating Layer Eltwise19
I0929 14:31:54.377476  2305 net.cpp:406] Eltwise19 <- Convolution39
I0929 14:31:54.377478  2305 net.cpp:406] Eltwise19 <- Convolution41
I0929 14:31:54.377483  2305 net.cpp:380] Eltwise19 -> Eltwise19
I0929 14:31:54.377501  2305 net.cpp:122] Setting up Eltwise19
I0929 14:31:54.377504  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.377506  2305 net.cpp:137] Memory required for data: 797485200
I0929 14:31:54.377508  2305 layer_factory.hpp:77] Creating layer M2PELU39
I0929 14:31:54.377513  2305 net.cpp:84] Creating Layer M2PELU39
I0929 14:31:54.377516  2305 net.cpp:406] M2PELU39 <- Eltwise19
I0929 14:31:54.377521  2305 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0929 14:31:54.377609  2305 net.cpp:122] Setting up M2PELU39
I0929 14:31:54.377614  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.377616  2305 net.cpp:137] Memory required for data: 798739600
I0929 14:31:54.377619  2305 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0929 14:31:54.377624  2305 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0929 14:31:54.377625  2305 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0929 14:31:54.377629  2305 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0929 14:31:54.377635  2305 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0929 14:31:54.377660  2305 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0929 14:31:54.377662  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.377665  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.377667  2305 net.cpp:137] Memory required for data: 801248400
I0929 14:31:54.377671  2305 layer_factory.hpp:77] Creating layer Convolution42
I0929 14:31:54.377676  2305 net.cpp:84] Creating Layer Convolution42
I0929 14:31:54.377678  2305 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0929 14:31:54.377683  2305 net.cpp:380] Convolution42 -> Convolution42
I0929 14:31:54.379506  2305 net.cpp:122] Setting up Convolution42
I0929 14:31:54.379515  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.379518  2305 net.cpp:137] Memory required for data: 802502800
I0929 14:31:54.379523  2305 layer_factory.hpp:77] Creating layer BatchNorm42
I0929 14:31:54.379529  2305 net.cpp:84] Creating Layer BatchNorm42
I0929 14:31:54.379531  2305 net.cpp:406] BatchNorm42 <- Convolution42
I0929 14:31:54.379535  2305 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0929 14:31:54.379683  2305 net.cpp:122] Setting up BatchNorm42
I0929 14:31:54.379686  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.379689  2305 net.cpp:137] Memory required for data: 803757200
I0929 14:31:54.379693  2305 layer_factory.hpp:77] Creating layer Scale42
I0929 14:31:54.379698  2305 net.cpp:84] Creating Layer Scale42
I0929 14:31:54.379700  2305 net.cpp:406] Scale42 <- Convolution42
I0929 14:31:54.379703  2305 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0929 14:31:54.379730  2305 layer_factory.hpp:77] Creating layer Scale42
I0929 14:31:54.379822  2305 net.cpp:122] Setting up Scale42
I0929 14:31:54.379827  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.379829  2305 net.cpp:137] Memory required for data: 805011600
I0929 14:31:54.379833  2305 layer_factory.hpp:77] Creating layer M2PELU40
I0929 14:31:54.379839  2305 net.cpp:84] Creating Layer M2PELU40
I0929 14:31:54.379842  2305 net.cpp:406] M2PELU40 <- Convolution42
I0929 14:31:54.379844  2305 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0929 14:31:54.379932  2305 net.cpp:122] Setting up M2PELU40
I0929 14:31:54.379936  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.379938  2305 net.cpp:137] Memory required for data: 806266000
I0929 14:31:54.379942  2305 layer_factory.hpp:77] Creating layer Convolution43
I0929 14:31:54.379948  2305 net.cpp:84] Creating Layer Convolution43
I0929 14:31:54.379951  2305 net.cpp:406] Convolution43 <- Convolution42
I0929 14:31:54.379956  2305 net.cpp:380] Convolution43 -> Convolution43
I0929 14:31:54.382230  2305 net.cpp:122] Setting up Convolution43
I0929 14:31:54.382238  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.382241  2305 net.cpp:137] Memory required for data: 807520400
I0929 14:31:54.382246  2305 layer_factory.hpp:77] Creating layer BatchNorm43
I0929 14:31:54.382251  2305 net.cpp:84] Creating Layer BatchNorm43
I0929 14:31:54.382254  2305 net.cpp:406] BatchNorm43 <- Convolution43
I0929 14:31:54.382258  2305 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0929 14:31:54.382398  2305 net.cpp:122] Setting up BatchNorm43
I0929 14:31:54.382402  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.382405  2305 net.cpp:137] Memory required for data: 808774800
I0929 14:31:54.382410  2305 layer_factory.hpp:77] Creating layer Scale43
I0929 14:31:54.382414  2305 net.cpp:84] Creating Layer Scale43
I0929 14:31:54.382417  2305 net.cpp:406] Scale43 <- Convolution43
I0929 14:31:54.382421  2305 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0929 14:31:54.382448  2305 layer_factory.hpp:77] Creating layer Scale43
I0929 14:31:54.382544  2305 net.cpp:122] Setting up Scale43
I0929 14:31:54.382550  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.382551  2305 net.cpp:137] Memory required for data: 810029200
I0929 14:31:54.382555  2305 layer_factory.hpp:77] Creating layer Eltwise20
I0929 14:31:54.382560  2305 net.cpp:84] Creating Layer Eltwise20
I0929 14:31:54.382571  2305 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0929 14:31:54.382575  2305 net.cpp:406] Eltwise20 <- Convolution43
I0929 14:31:54.382580  2305 net.cpp:380] Eltwise20 -> Eltwise20
I0929 14:31:54.382596  2305 net.cpp:122] Setting up Eltwise20
I0929 14:31:54.382601  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.382602  2305 net.cpp:137] Memory required for data: 811283600
I0929 14:31:54.382604  2305 layer_factory.hpp:77] Creating layer M2PELU41
I0929 14:31:54.382609  2305 net.cpp:84] Creating Layer M2PELU41
I0929 14:31:54.382612  2305 net.cpp:406] M2PELU41 <- Eltwise20
I0929 14:31:54.382616  2305 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0929 14:31:54.382701  2305 net.cpp:122] Setting up M2PELU41
I0929 14:31:54.382705  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.382707  2305 net.cpp:137] Memory required for data: 812538000
I0929 14:31:54.382711  2305 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0929 14:31:54.382715  2305 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0929 14:31:54.382719  2305 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0929 14:31:54.382721  2305 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0929 14:31:54.382725  2305 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0929 14:31:54.382748  2305 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0929 14:31:54.382752  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.382755  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.382757  2305 net.cpp:137] Memory required for data: 815046800
I0929 14:31:54.382766  2305 layer_factory.hpp:77] Creating layer Convolution44
I0929 14:31:54.382772  2305 net.cpp:84] Creating Layer Convolution44
I0929 14:31:54.382776  2305 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0929 14:31:54.382779  2305 net.cpp:380] Convolution44 -> Convolution44
I0929 14:31:54.384428  2305 net.cpp:122] Setting up Convolution44
I0929 14:31:54.384435  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.384438  2305 net.cpp:137] Memory required for data: 816301200
I0929 14:31:54.384443  2305 layer_factory.hpp:77] Creating layer BatchNorm44
I0929 14:31:54.384446  2305 net.cpp:84] Creating Layer BatchNorm44
I0929 14:31:54.384449  2305 net.cpp:406] BatchNorm44 <- Convolution44
I0929 14:31:54.384454  2305 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0929 14:31:54.384594  2305 net.cpp:122] Setting up BatchNorm44
I0929 14:31:54.384598  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.384600  2305 net.cpp:137] Memory required for data: 817555600
I0929 14:31:54.384605  2305 layer_factory.hpp:77] Creating layer Scale44
I0929 14:31:54.384609  2305 net.cpp:84] Creating Layer Scale44
I0929 14:31:54.384613  2305 net.cpp:406] Scale44 <- Convolution44
I0929 14:31:54.384616  2305 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0929 14:31:54.384644  2305 layer_factory.hpp:77] Creating layer Scale44
I0929 14:31:54.384723  2305 net.cpp:122] Setting up Scale44
I0929 14:31:54.384727  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.384729  2305 net.cpp:137] Memory required for data: 818810000
I0929 14:31:54.384733  2305 layer_factory.hpp:77] Creating layer M2PELU42
I0929 14:31:54.384737  2305 net.cpp:84] Creating Layer M2PELU42
I0929 14:31:54.384740  2305 net.cpp:406] M2PELU42 <- Convolution44
I0929 14:31:54.384744  2305 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0929 14:31:54.384833  2305 net.cpp:122] Setting up M2PELU42
I0929 14:31:54.384837  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.384840  2305 net.cpp:137] Memory required for data: 820064400
I0929 14:31:54.384843  2305 layer_factory.hpp:77] Creating layer Convolution45
I0929 14:31:54.384850  2305 net.cpp:84] Creating Layer Convolution45
I0929 14:31:54.384852  2305 net.cpp:406] Convolution45 <- Convolution44
I0929 14:31:54.384856  2305 net.cpp:380] Convolution45 -> Convolution45
I0929 14:31:54.386823  2305 net.cpp:122] Setting up Convolution45
I0929 14:31:54.386832  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.386834  2305 net.cpp:137] Memory required for data: 821318800
I0929 14:31:54.386839  2305 layer_factory.hpp:77] Creating layer BatchNorm45
I0929 14:31:54.386844  2305 net.cpp:84] Creating Layer BatchNorm45
I0929 14:31:54.386847  2305 net.cpp:406] BatchNorm45 <- Convolution45
I0929 14:31:54.386852  2305 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0929 14:31:54.387004  2305 net.cpp:122] Setting up BatchNorm45
I0929 14:31:54.387009  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.387012  2305 net.cpp:137] Memory required for data: 822573200
I0929 14:31:54.387017  2305 layer_factory.hpp:77] Creating layer Scale45
I0929 14:31:54.387022  2305 net.cpp:84] Creating Layer Scale45
I0929 14:31:54.387023  2305 net.cpp:406] Scale45 <- Convolution45
I0929 14:31:54.387027  2305 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0929 14:31:54.387064  2305 layer_factory.hpp:77] Creating layer Scale45
I0929 14:31:54.387146  2305 net.cpp:122] Setting up Scale45
I0929 14:31:54.387151  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.387153  2305 net.cpp:137] Memory required for data: 823827600
I0929 14:31:54.387157  2305 layer_factory.hpp:77] Creating layer Eltwise21
I0929 14:31:54.387161  2305 net.cpp:84] Creating Layer Eltwise21
I0929 14:31:54.387164  2305 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0929 14:31:54.387167  2305 net.cpp:406] Eltwise21 <- Convolution45
I0929 14:31:54.387171  2305 net.cpp:380] Eltwise21 -> Eltwise21
I0929 14:31:54.387188  2305 net.cpp:122] Setting up Eltwise21
I0929 14:31:54.387198  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.387202  2305 net.cpp:137] Memory required for data: 825082000
I0929 14:31:54.387203  2305 layer_factory.hpp:77] Creating layer M2PELU43
I0929 14:31:54.387208  2305 net.cpp:84] Creating Layer M2PELU43
I0929 14:31:54.387212  2305 net.cpp:406] M2PELU43 <- Eltwise21
I0929 14:31:54.387214  2305 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0929 14:31:54.387305  2305 net.cpp:122] Setting up M2PELU43
I0929 14:31:54.387308  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.387310  2305 net.cpp:137] Memory required for data: 826336400
I0929 14:31:54.387315  2305 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0929 14:31:54.387317  2305 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0929 14:31:54.387320  2305 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0929 14:31:54.387323  2305 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0929 14:31:54.387328  2305 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0929 14:31:54.387352  2305 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0929 14:31:54.387356  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.387359  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.387362  2305 net.cpp:137] Memory required for data: 828845200
I0929 14:31:54.387363  2305 layer_factory.hpp:77] Creating layer Convolution46
I0929 14:31:54.387369  2305 net.cpp:84] Creating Layer Convolution46
I0929 14:31:54.387372  2305 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0929 14:31:54.387375  2305 net.cpp:380] Convolution46 -> Convolution46
I0929 14:31:54.389022  2305 net.cpp:122] Setting up Convolution46
I0929 14:31:54.389031  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.389034  2305 net.cpp:137] Memory required for data: 830099600
I0929 14:31:54.389039  2305 layer_factory.hpp:77] Creating layer BatchNorm46
I0929 14:31:54.389044  2305 net.cpp:84] Creating Layer BatchNorm46
I0929 14:31:54.389046  2305 net.cpp:406] BatchNorm46 <- Convolution46
I0929 14:31:54.389050  2305 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0929 14:31:54.389192  2305 net.cpp:122] Setting up BatchNorm46
I0929 14:31:54.389196  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.389199  2305 net.cpp:137] Memory required for data: 831354000
I0929 14:31:54.389204  2305 layer_factory.hpp:77] Creating layer Scale46
I0929 14:31:54.389207  2305 net.cpp:84] Creating Layer Scale46
I0929 14:31:54.389209  2305 net.cpp:406] Scale46 <- Convolution46
I0929 14:31:54.389212  2305 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0929 14:31:54.389240  2305 layer_factory.hpp:77] Creating layer Scale46
I0929 14:31:54.389322  2305 net.cpp:122] Setting up Scale46
I0929 14:31:54.389325  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.389328  2305 net.cpp:137] Memory required for data: 832608400
I0929 14:31:54.389331  2305 layer_factory.hpp:77] Creating layer M2PELU44
I0929 14:31:54.389335  2305 net.cpp:84] Creating Layer M2PELU44
I0929 14:31:54.389338  2305 net.cpp:406] M2PELU44 <- Convolution46
I0929 14:31:54.389343  2305 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0929 14:31:54.389431  2305 net.cpp:122] Setting up M2PELU44
I0929 14:31:54.389436  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.389437  2305 net.cpp:137] Memory required for data: 833862800
I0929 14:31:54.389441  2305 layer_factory.hpp:77] Creating layer Convolution47
I0929 14:31:54.389449  2305 net.cpp:84] Creating Layer Convolution47
I0929 14:31:54.389451  2305 net.cpp:406] Convolution47 <- Convolution46
I0929 14:31:54.389456  2305 net.cpp:380] Convolution47 -> Convolution47
I0929 14:31:54.391134  2305 net.cpp:122] Setting up Convolution47
I0929 14:31:54.391142  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.391145  2305 net.cpp:137] Memory required for data: 835117200
I0929 14:31:54.391150  2305 layer_factory.hpp:77] Creating layer BatchNorm47
I0929 14:31:54.391155  2305 net.cpp:84] Creating Layer BatchNorm47
I0929 14:31:54.391165  2305 net.cpp:406] BatchNorm47 <- Convolution47
I0929 14:31:54.391170  2305 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0929 14:31:54.391324  2305 net.cpp:122] Setting up BatchNorm47
I0929 14:31:54.391330  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.391331  2305 net.cpp:137] Memory required for data: 836371600
I0929 14:31:54.391336  2305 layer_factory.hpp:77] Creating layer Scale47
I0929 14:31:54.391340  2305 net.cpp:84] Creating Layer Scale47
I0929 14:31:54.391343  2305 net.cpp:406] Scale47 <- Convolution47
I0929 14:31:54.391346  2305 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0929 14:31:54.391376  2305 layer_factory.hpp:77] Creating layer Scale47
I0929 14:31:54.391458  2305 net.cpp:122] Setting up Scale47
I0929 14:31:54.391463  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.391464  2305 net.cpp:137] Memory required for data: 837626000
I0929 14:31:54.391469  2305 layer_factory.hpp:77] Creating layer Eltwise22
I0929 14:31:54.391474  2305 net.cpp:84] Creating Layer Eltwise22
I0929 14:31:54.391477  2305 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0929 14:31:54.391479  2305 net.cpp:406] Eltwise22 <- Convolution47
I0929 14:31:54.391484  2305 net.cpp:380] Eltwise22 -> Eltwise22
I0929 14:31:54.391500  2305 net.cpp:122] Setting up Eltwise22
I0929 14:31:54.391505  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.391506  2305 net.cpp:137] Memory required for data: 838880400
I0929 14:31:54.391508  2305 layer_factory.hpp:77] Creating layer M2PELU45
I0929 14:31:54.391513  2305 net.cpp:84] Creating Layer M2PELU45
I0929 14:31:54.391516  2305 net.cpp:406] M2PELU45 <- Eltwise22
I0929 14:31:54.391520  2305 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0929 14:31:54.391609  2305 net.cpp:122] Setting up M2PELU45
I0929 14:31:54.391613  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.391615  2305 net.cpp:137] Memory required for data: 840134800
I0929 14:31:54.391619  2305 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0929 14:31:54.391623  2305 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0929 14:31:54.391625  2305 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0929 14:31:54.391628  2305 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0929 14:31:54.391633  2305 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0929 14:31:54.391657  2305 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0929 14:31:54.391661  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.391664  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.391666  2305 net.cpp:137] Memory required for data: 842643600
I0929 14:31:54.391669  2305 layer_factory.hpp:77] Creating layer Convolution48
I0929 14:31:54.391675  2305 net.cpp:84] Creating Layer Convolution48
I0929 14:31:54.391677  2305 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0929 14:31:54.391681  2305 net.cpp:380] Convolution48 -> Convolution48
I0929 14:31:54.393375  2305 net.cpp:122] Setting up Convolution48
I0929 14:31:54.393384  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.393388  2305 net.cpp:137] Memory required for data: 843898000
I0929 14:31:54.393391  2305 layer_factory.hpp:77] Creating layer BatchNorm48
I0929 14:31:54.393398  2305 net.cpp:84] Creating Layer BatchNorm48
I0929 14:31:54.393400  2305 net.cpp:406] BatchNorm48 <- Convolution48
I0929 14:31:54.393405  2305 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0929 14:31:54.393549  2305 net.cpp:122] Setting up BatchNorm48
I0929 14:31:54.393553  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.393556  2305 net.cpp:137] Memory required for data: 845152400
I0929 14:31:54.393560  2305 layer_factory.hpp:77] Creating layer Scale48
I0929 14:31:54.393565  2305 net.cpp:84] Creating Layer Scale48
I0929 14:31:54.393568  2305 net.cpp:406] Scale48 <- Convolution48
I0929 14:31:54.393571  2305 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0929 14:31:54.393600  2305 layer_factory.hpp:77] Creating layer Scale48
I0929 14:31:54.393728  2305 net.cpp:122] Setting up Scale48
I0929 14:31:54.393733  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.393735  2305 net.cpp:137] Memory required for data: 846406800
I0929 14:31:54.393748  2305 layer_factory.hpp:77] Creating layer M2PELU46
I0929 14:31:54.393754  2305 net.cpp:84] Creating Layer M2PELU46
I0929 14:31:54.393757  2305 net.cpp:406] M2PELU46 <- Convolution48
I0929 14:31:54.393761  2305 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0929 14:31:54.393852  2305 net.cpp:122] Setting up M2PELU46
I0929 14:31:54.393857  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.393859  2305 net.cpp:137] Memory required for data: 847661200
I0929 14:31:54.393863  2305 layer_factory.hpp:77] Creating layer Convolution49
I0929 14:31:54.393870  2305 net.cpp:84] Creating Layer Convolution49
I0929 14:31:54.393872  2305 net.cpp:406] Convolution49 <- Convolution48
I0929 14:31:54.393877  2305 net.cpp:380] Convolution49 -> Convolution49
I0929 14:31:54.396004  2305 net.cpp:122] Setting up Convolution49
I0929 14:31:54.396013  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.396015  2305 net.cpp:137] Memory required for data: 848915600
I0929 14:31:54.396020  2305 layer_factory.hpp:77] Creating layer BatchNorm49
I0929 14:31:54.396026  2305 net.cpp:84] Creating Layer BatchNorm49
I0929 14:31:54.396028  2305 net.cpp:406] BatchNorm49 <- Convolution49
I0929 14:31:54.396033  2305 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0929 14:31:54.396240  2305 net.cpp:122] Setting up BatchNorm49
I0929 14:31:54.396245  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.396247  2305 net.cpp:137] Memory required for data: 850170000
I0929 14:31:54.396252  2305 layer_factory.hpp:77] Creating layer Scale49
I0929 14:31:54.396257  2305 net.cpp:84] Creating Layer Scale49
I0929 14:31:54.396260  2305 net.cpp:406] Scale49 <- Convolution49
I0929 14:31:54.396263  2305 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0929 14:31:54.396292  2305 layer_factory.hpp:77] Creating layer Scale49
I0929 14:31:54.396374  2305 net.cpp:122] Setting up Scale49
I0929 14:31:54.396378  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.396381  2305 net.cpp:137] Memory required for data: 851424400
I0929 14:31:54.396385  2305 layer_factory.hpp:77] Creating layer Eltwise23
I0929 14:31:54.396389  2305 net.cpp:84] Creating Layer Eltwise23
I0929 14:31:54.396392  2305 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0929 14:31:54.396395  2305 net.cpp:406] Eltwise23 <- Convolution49
I0929 14:31:54.396399  2305 net.cpp:380] Eltwise23 -> Eltwise23
I0929 14:31:54.396415  2305 net.cpp:122] Setting up Eltwise23
I0929 14:31:54.396420  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.396421  2305 net.cpp:137] Memory required for data: 852678800
I0929 14:31:54.396423  2305 layer_factory.hpp:77] Creating layer M2PELU47
I0929 14:31:54.396428  2305 net.cpp:84] Creating Layer M2PELU47
I0929 14:31:54.396431  2305 net.cpp:406] M2PELU47 <- Eltwise23
I0929 14:31:54.396435  2305 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0929 14:31:54.396522  2305 net.cpp:122] Setting up M2PELU47
I0929 14:31:54.396528  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.396529  2305 net.cpp:137] Memory required for data: 853933200
I0929 14:31:54.396533  2305 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0929 14:31:54.396538  2305 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0929 14:31:54.396539  2305 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0929 14:31:54.396543  2305 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0929 14:31:54.396546  2305 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0929 14:31:54.396572  2305 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0929 14:31:54.396576  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.396579  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.396581  2305 net.cpp:137] Memory required for data: 856442000
I0929 14:31:54.396590  2305 layer_factory.hpp:77] Creating layer Convolution50
I0929 14:31:54.396597  2305 net.cpp:84] Creating Layer Convolution50
I0929 14:31:54.396600  2305 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0929 14:31:54.396605  2305 net.cpp:380] Convolution50 -> Convolution50
I0929 14:31:54.398255  2305 net.cpp:122] Setting up Convolution50
I0929 14:31:54.398264  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.398267  2305 net.cpp:137] Memory required for data: 857696400
I0929 14:31:54.398272  2305 layer_factory.hpp:77] Creating layer BatchNorm50
I0929 14:31:54.398277  2305 net.cpp:84] Creating Layer BatchNorm50
I0929 14:31:54.398279  2305 net.cpp:406] BatchNorm50 <- Convolution50
I0929 14:31:54.398283  2305 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0929 14:31:54.398425  2305 net.cpp:122] Setting up BatchNorm50
I0929 14:31:54.398430  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.404947  2305 net.cpp:137] Memory required for data: 858950800
I0929 14:31:54.404958  2305 layer_factory.hpp:77] Creating layer Scale50
I0929 14:31:54.404966  2305 net.cpp:84] Creating Layer Scale50
I0929 14:31:54.404969  2305 net.cpp:406] Scale50 <- Convolution50
I0929 14:31:54.404973  2305 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0929 14:31:54.405017  2305 layer_factory.hpp:77] Creating layer Scale50
I0929 14:31:54.405114  2305 net.cpp:122] Setting up Scale50
I0929 14:31:54.405119  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.405122  2305 net.cpp:137] Memory required for data: 860205200
I0929 14:31:54.405127  2305 layer_factory.hpp:77] Creating layer M2PELU48
I0929 14:31:54.405133  2305 net.cpp:84] Creating Layer M2PELU48
I0929 14:31:54.405135  2305 net.cpp:406] M2PELU48 <- Convolution50
I0929 14:31:54.405139  2305 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0929 14:31:54.405239  2305 net.cpp:122] Setting up M2PELU48
I0929 14:31:54.405243  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.405246  2305 net.cpp:137] Memory required for data: 861459600
I0929 14:31:54.405251  2305 layer_factory.hpp:77] Creating layer Convolution51
I0929 14:31:54.405257  2305 net.cpp:84] Creating Layer Convolution51
I0929 14:31:54.405261  2305 net.cpp:406] Convolution51 <- Convolution50
I0929 14:31:54.405266  2305 net.cpp:380] Convolution51 -> Convolution51
I0929 14:31:54.408041  2305 net.cpp:122] Setting up Convolution51
I0929 14:31:54.408051  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.408052  2305 net.cpp:137] Memory required for data: 862714000
I0929 14:31:54.408057  2305 layer_factory.hpp:77] Creating layer BatchNorm51
I0929 14:31:54.408063  2305 net.cpp:84] Creating Layer BatchNorm51
I0929 14:31:54.408066  2305 net.cpp:406] BatchNorm51 <- Convolution51
I0929 14:31:54.408071  2305 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0929 14:31:54.408253  2305 net.cpp:122] Setting up BatchNorm51
I0929 14:31:54.408258  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.408262  2305 net.cpp:137] Memory required for data: 863968400
I0929 14:31:54.408267  2305 layer_factory.hpp:77] Creating layer Scale51
I0929 14:31:54.408272  2305 net.cpp:84] Creating Layer Scale51
I0929 14:31:54.408274  2305 net.cpp:406] Scale51 <- Convolution51
I0929 14:31:54.408278  2305 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0929 14:31:54.408309  2305 layer_factory.hpp:77] Creating layer Scale51
I0929 14:31:54.408418  2305 net.cpp:122] Setting up Scale51
I0929 14:31:54.408423  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.408426  2305 net.cpp:137] Memory required for data: 865222800
I0929 14:31:54.408429  2305 layer_factory.hpp:77] Creating layer Eltwise24
I0929 14:31:54.408434  2305 net.cpp:84] Creating Layer Eltwise24
I0929 14:31:54.408437  2305 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0929 14:31:54.408440  2305 net.cpp:406] Eltwise24 <- Convolution51
I0929 14:31:54.408444  2305 net.cpp:380] Eltwise24 -> Eltwise24
I0929 14:31:54.408462  2305 net.cpp:122] Setting up Eltwise24
I0929 14:31:54.408474  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.408478  2305 net.cpp:137] Memory required for data: 866477200
I0929 14:31:54.408489  2305 layer_factory.hpp:77] Creating layer M2PELU49
I0929 14:31:54.408495  2305 net.cpp:84] Creating Layer M2PELU49
I0929 14:31:54.408499  2305 net.cpp:406] M2PELU49 <- Eltwise24
I0929 14:31:54.408501  2305 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0929 14:31:54.408614  2305 net.cpp:122] Setting up M2PELU49
I0929 14:31:54.408619  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.408622  2305 net.cpp:137] Memory required for data: 867731600
I0929 14:31:54.408625  2305 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0929 14:31:54.408629  2305 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0929 14:31:54.408632  2305 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0929 14:31:54.408634  2305 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0929 14:31:54.408639  2305 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0929 14:31:54.408664  2305 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0929 14:31:54.408668  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.408670  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.408673  2305 net.cpp:137] Memory required for data: 870240400
I0929 14:31:54.408674  2305 layer_factory.hpp:77] Creating layer Convolution52
I0929 14:31:54.408681  2305 net.cpp:84] Creating Layer Convolution52
I0929 14:31:54.408684  2305 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0929 14:31:54.408687  2305 net.cpp:380] Convolution52 -> Convolution52
I0929 14:31:54.410378  2305 net.cpp:122] Setting up Convolution52
I0929 14:31:54.410387  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.410389  2305 net.cpp:137] Memory required for data: 871494800
I0929 14:31:54.410394  2305 layer_factory.hpp:77] Creating layer BatchNorm52
I0929 14:31:54.410399  2305 net.cpp:84] Creating Layer BatchNorm52
I0929 14:31:54.410403  2305 net.cpp:406] BatchNorm52 <- Convolution52
I0929 14:31:54.410406  2305 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0929 14:31:54.410579  2305 net.cpp:122] Setting up BatchNorm52
I0929 14:31:54.410585  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.410588  2305 net.cpp:137] Memory required for data: 872749200
I0929 14:31:54.410591  2305 layer_factory.hpp:77] Creating layer Scale52
I0929 14:31:54.410595  2305 net.cpp:84] Creating Layer Scale52
I0929 14:31:54.410598  2305 net.cpp:406] Scale52 <- Convolution52
I0929 14:31:54.410603  2305 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0929 14:31:54.410630  2305 layer_factory.hpp:77] Creating layer Scale52
I0929 14:31:54.410714  2305 net.cpp:122] Setting up Scale52
I0929 14:31:54.410718  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.410720  2305 net.cpp:137] Memory required for data: 874003600
I0929 14:31:54.410724  2305 layer_factory.hpp:77] Creating layer M2PELU50
I0929 14:31:54.410729  2305 net.cpp:84] Creating Layer M2PELU50
I0929 14:31:54.410732  2305 net.cpp:406] M2PELU50 <- Convolution52
I0929 14:31:54.410735  2305 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0929 14:31:54.410826  2305 net.cpp:122] Setting up M2PELU50
I0929 14:31:54.410831  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.410833  2305 net.cpp:137] Memory required for data: 875258000
I0929 14:31:54.410836  2305 layer_factory.hpp:77] Creating layer Convolution53
I0929 14:31:54.410867  2305 net.cpp:84] Creating Layer Convolution53
I0929 14:31:54.410871  2305 net.cpp:406] Convolution53 <- Convolution52
I0929 14:31:54.410874  2305 net.cpp:380] Convolution53 -> Convolution53
I0929 14:31:54.412986  2305 net.cpp:122] Setting up Convolution53
I0929 14:31:54.412994  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.412997  2305 net.cpp:137] Memory required for data: 876512400
I0929 14:31:54.413002  2305 layer_factory.hpp:77] Creating layer BatchNorm53
I0929 14:31:54.413007  2305 net.cpp:84] Creating Layer BatchNorm53
I0929 14:31:54.413017  2305 net.cpp:406] BatchNorm53 <- Convolution53
I0929 14:31:54.413022  2305 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0929 14:31:54.413168  2305 net.cpp:122] Setting up BatchNorm53
I0929 14:31:54.413173  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.413177  2305 net.cpp:137] Memory required for data: 877766800
I0929 14:31:54.413182  2305 layer_factory.hpp:77] Creating layer Scale53
I0929 14:31:54.413185  2305 net.cpp:84] Creating Layer Scale53
I0929 14:31:54.413187  2305 net.cpp:406] Scale53 <- Convolution53
I0929 14:31:54.413190  2305 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0929 14:31:54.413220  2305 layer_factory.hpp:77] Creating layer Scale53
I0929 14:31:54.413305  2305 net.cpp:122] Setting up Scale53
I0929 14:31:54.413308  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.413311  2305 net.cpp:137] Memory required for data: 879021200
I0929 14:31:54.413314  2305 layer_factory.hpp:77] Creating layer Eltwise25
I0929 14:31:54.413319  2305 net.cpp:84] Creating Layer Eltwise25
I0929 14:31:54.413322  2305 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0929 14:31:54.413326  2305 net.cpp:406] Eltwise25 <- Convolution53
I0929 14:31:54.413328  2305 net.cpp:380] Eltwise25 -> Eltwise25
I0929 14:31:54.413347  2305 net.cpp:122] Setting up Eltwise25
I0929 14:31:54.413349  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.413352  2305 net.cpp:137] Memory required for data: 880275600
I0929 14:31:54.413353  2305 layer_factory.hpp:77] Creating layer M2PELU51
I0929 14:31:54.413358  2305 net.cpp:84] Creating Layer M2PELU51
I0929 14:31:54.413362  2305 net.cpp:406] M2PELU51 <- Eltwise25
I0929 14:31:54.413364  2305 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0929 14:31:54.413455  2305 net.cpp:122] Setting up M2PELU51
I0929 14:31:54.413458  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.413460  2305 net.cpp:137] Memory required for data: 881530000
I0929 14:31:54.413465  2305 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0929 14:31:54.413468  2305 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0929 14:31:54.413470  2305 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0929 14:31:54.413475  2305 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0929 14:31:54.413478  2305 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0929 14:31:54.413503  2305 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0929 14:31:54.413506  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.413509  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.413511  2305 net.cpp:137] Memory required for data: 884038800
I0929 14:31:54.413513  2305 layer_factory.hpp:77] Creating layer Convolution54
I0929 14:31:54.413519  2305 net.cpp:84] Creating Layer Convolution54
I0929 14:31:54.413522  2305 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0929 14:31:54.413527  2305 net.cpp:380] Convolution54 -> Convolution54
I0929 14:31:54.415720  2305 net.cpp:122] Setting up Convolution54
I0929 14:31:54.415730  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.415733  2305 net.cpp:137] Memory required for data: 885293200
I0929 14:31:54.415738  2305 layer_factory.hpp:77] Creating layer BatchNorm54
I0929 14:31:54.415742  2305 net.cpp:84] Creating Layer BatchNorm54
I0929 14:31:54.415745  2305 net.cpp:406] BatchNorm54 <- Convolution54
I0929 14:31:54.415751  2305 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0929 14:31:54.415895  2305 net.cpp:122] Setting up BatchNorm54
I0929 14:31:54.415900  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.415902  2305 net.cpp:137] Memory required for data: 886547600
I0929 14:31:54.415907  2305 layer_factory.hpp:77] Creating layer Scale54
I0929 14:31:54.415911  2305 net.cpp:84] Creating Layer Scale54
I0929 14:31:54.415913  2305 net.cpp:406] Scale54 <- Convolution54
I0929 14:31:54.415918  2305 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0929 14:31:54.415948  2305 layer_factory.hpp:77] Creating layer Scale54
I0929 14:31:54.416041  2305 net.cpp:122] Setting up Scale54
I0929 14:31:54.416046  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.416049  2305 net.cpp:137] Memory required for data: 887802000
I0929 14:31:54.416052  2305 layer_factory.hpp:77] Creating layer M2PELU52
I0929 14:31:54.416057  2305 net.cpp:84] Creating Layer M2PELU52
I0929 14:31:54.416059  2305 net.cpp:406] M2PELU52 <- Convolution54
I0929 14:31:54.416064  2305 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0929 14:31:54.416157  2305 net.cpp:122] Setting up M2PELU52
I0929 14:31:54.416162  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.416163  2305 net.cpp:137] Memory required for data: 889056400
I0929 14:31:54.416167  2305 layer_factory.hpp:77] Creating layer Convolution55
I0929 14:31:54.416173  2305 net.cpp:84] Creating Layer Convolution55
I0929 14:31:54.416177  2305 net.cpp:406] Convolution55 <- Convolution54
I0929 14:31:54.416180  2305 net.cpp:380] Convolution55 -> Convolution55
I0929 14:31:54.418143  2305 net.cpp:122] Setting up Convolution55
I0929 14:31:54.418153  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.418154  2305 net.cpp:137] Memory required for data: 890310800
I0929 14:31:54.418159  2305 layer_factory.hpp:77] Creating layer BatchNorm55
I0929 14:31:54.418164  2305 net.cpp:84] Creating Layer BatchNorm55
I0929 14:31:54.418167  2305 net.cpp:406] BatchNorm55 <- Convolution55
I0929 14:31:54.418171  2305 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0929 14:31:54.418323  2305 net.cpp:122] Setting up BatchNorm55
I0929 14:31:54.418328  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.418329  2305 net.cpp:137] Memory required for data: 891565200
I0929 14:31:54.418334  2305 layer_factory.hpp:77] Creating layer Scale55
I0929 14:31:54.418339  2305 net.cpp:84] Creating Layer Scale55
I0929 14:31:54.418341  2305 net.cpp:406] Scale55 <- Convolution55
I0929 14:31:54.418344  2305 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0929 14:31:54.418375  2305 layer_factory.hpp:77] Creating layer Scale55
I0929 14:31:54.418459  2305 net.cpp:122] Setting up Scale55
I0929 14:31:54.418464  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.418467  2305 net.cpp:137] Memory required for data: 892819600
I0929 14:31:54.418470  2305 layer_factory.hpp:77] Creating layer Eltwise26
I0929 14:31:54.418474  2305 net.cpp:84] Creating Layer Eltwise26
I0929 14:31:54.418478  2305 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0929 14:31:54.418480  2305 net.cpp:406] Eltwise26 <- Convolution55
I0929 14:31:54.418483  2305 net.cpp:380] Eltwise26 -> Eltwise26
I0929 14:31:54.418501  2305 net.cpp:122] Setting up Eltwise26
I0929 14:31:54.418505  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.418507  2305 net.cpp:137] Memory required for data: 894074000
I0929 14:31:54.418509  2305 layer_factory.hpp:77] Creating layer M2PELU53
I0929 14:31:54.418514  2305 net.cpp:84] Creating Layer M2PELU53
I0929 14:31:54.418516  2305 net.cpp:406] M2PELU53 <- Eltwise26
I0929 14:31:54.418535  2305 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0929 14:31:54.418639  2305 net.cpp:122] Setting up M2PELU53
I0929 14:31:54.418644  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.418647  2305 net.cpp:137] Memory required for data: 895328400
I0929 14:31:54.418650  2305 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0929 14:31:54.418653  2305 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0929 14:31:54.418656  2305 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0929 14:31:54.418660  2305 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0929 14:31:54.418664  2305 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0929 14:31:54.418689  2305 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0929 14:31:54.418694  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.418696  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.418699  2305 net.cpp:137] Memory required for data: 897837200
I0929 14:31:54.418706  2305 layer_factory.hpp:77] Creating layer Convolution56
I0929 14:31:54.418715  2305 net.cpp:84] Creating Layer Convolution56
I0929 14:31:54.418717  2305 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0929 14:31:54.418722  2305 net.cpp:380] Convolution56 -> Convolution56
I0929 14:31:54.420397  2305 net.cpp:122] Setting up Convolution56
I0929 14:31:54.420404  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.420408  2305 net.cpp:137] Memory required for data: 899091600
I0929 14:31:54.420411  2305 layer_factory.hpp:77] Creating layer BatchNorm56
I0929 14:31:54.420416  2305 net.cpp:84] Creating Layer BatchNorm56
I0929 14:31:54.420418  2305 net.cpp:406] BatchNorm56 <- Convolution56
I0929 14:31:54.420423  2305 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0929 14:31:54.436048  2305 net.cpp:122] Setting up BatchNorm56
I0929 14:31:54.436059  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.436062  2305 net.cpp:137] Memory required for data: 900346000
I0929 14:31:54.436069  2305 layer_factory.hpp:77] Creating layer Scale56
I0929 14:31:54.436074  2305 net.cpp:84] Creating Layer Scale56
I0929 14:31:54.436077  2305 net.cpp:406] Scale56 <- Convolution56
I0929 14:31:54.436082  2305 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0929 14:31:54.436116  2305 layer_factory.hpp:77] Creating layer Scale56
I0929 14:31:54.436211  2305 net.cpp:122] Setting up Scale56
I0929 14:31:54.436218  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.436219  2305 net.cpp:137] Memory required for data: 901600400
I0929 14:31:54.436223  2305 layer_factory.hpp:77] Creating layer M2PELU54
I0929 14:31:54.436228  2305 net.cpp:84] Creating Layer M2PELU54
I0929 14:31:54.436231  2305 net.cpp:406] M2PELU54 <- Convolution56
I0929 14:31:54.436235  2305 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0929 14:31:54.436342  2305 net.cpp:122] Setting up M2PELU54
I0929 14:31:54.436345  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.436348  2305 net.cpp:137] Memory required for data: 902854800
I0929 14:31:54.436352  2305 layer_factory.hpp:77] Creating layer Convolution57
I0929 14:31:54.436360  2305 net.cpp:84] Creating Layer Convolution57
I0929 14:31:54.436363  2305 net.cpp:406] Convolution57 <- Convolution56
I0929 14:31:54.436367  2305 net.cpp:380] Convolution57 -> Convolution57
I0929 14:31:54.438863  2305 net.cpp:122] Setting up Convolution57
I0929 14:31:54.438871  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.438874  2305 net.cpp:137] Memory required for data: 904109200
I0929 14:31:54.438879  2305 layer_factory.hpp:77] Creating layer BatchNorm57
I0929 14:31:54.438884  2305 net.cpp:84] Creating Layer BatchNorm57
I0929 14:31:54.438887  2305 net.cpp:406] BatchNorm57 <- Convolution57
I0929 14:31:54.438891  2305 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0929 14:31:54.439044  2305 net.cpp:122] Setting up BatchNorm57
I0929 14:31:54.439049  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.439051  2305 net.cpp:137] Memory required for data: 905363600
I0929 14:31:54.439056  2305 layer_factory.hpp:77] Creating layer Scale57
I0929 14:31:54.439060  2305 net.cpp:84] Creating Layer Scale57
I0929 14:31:54.439064  2305 net.cpp:406] Scale57 <- Convolution57
I0929 14:31:54.439066  2305 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0929 14:31:54.439096  2305 layer_factory.hpp:77] Creating layer Scale57
I0929 14:31:54.439183  2305 net.cpp:122] Setting up Scale57
I0929 14:31:54.439188  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.439190  2305 net.cpp:137] Memory required for data: 906618000
I0929 14:31:54.439194  2305 layer_factory.hpp:77] Creating layer Eltwise27
I0929 14:31:54.439199  2305 net.cpp:84] Creating Layer Eltwise27
I0929 14:31:54.439203  2305 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0929 14:31:54.439205  2305 net.cpp:406] Eltwise27 <- Convolution57
I0929 14:31:54.439208  2305 net.cpp:380] Eltwise27 -> Eltwise27
I0929 14:31:54.439229  2305 net.cpp:122] Setting up Eltwise27
I0929 14:31:54.439241  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.439244  2305 net.cpp:137] Memory required for data: 907872400
I0929 14:31:54.439245  2305 layer_factory.hpp:77] Creating layer M2PELU55
I0929 14:31:54.439250  2305 net.cpp:84] Creating Layer M2PELU55
I0929 14:31:54.439252  2305 net.cpp:406] M2PELU55 <- Eltwise27
I0929 14:31:54.439255  2305 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0929 14:31:54.439364  2305 net.cpp:122] Setting up M2PELU55
I0929 14:31:54.439369  2305 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0929 14:31:54.439371  2305 net.cpp:137] Memory required for data: 909126800
I0929 14:31:54.439375  2305 layer_factory.hpp:77] Creating layer Pooling1
I0929 14:31:54.439379  2305 net.cpp:84] Creating Layer Pooling1
I0929 14:31:54.439383  2305 net.cpp:406] Pooling1 <- Eltwise27
I0929 14:31:54.439385  2305 net.cpp:380] Pooling1 -> Pooling1
I0929 14:31:54.440016  2305 net.cpp:122] Setting up Pooling1
I0929 14:31:54.440026  2305 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0929 14:31:54.440027  2305 net.cpp:137] Memory required for data: 909152400
I0929 14:31:54.440030  2305 layer_factory.hpp:77] Creating layer InnerProduct1
I0929 14:31:54.440039  2305 net.cpp:84] Creating Layer InnerProduct1
I0929 14:31:54.440042  2305 net.cpp:406] InnerProduct1 <- Pooling1
I0929 14:31:54.440047  2305 net.cpp:380] InnerProduct1 -> InnerProduct1
I0929 14:31:54.440160  2305 net.cpp:122] Setting up InnerProduct1
I0929 14:31:54.440165  2305 net.cpp:129] Top shape: 100 10 (1000)
I0929 14:31:54.440166  2305 net.cpp:137] Memory required for data: 909156400
I0929 14:31:54.440171  2305 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 14:31:54.440176  2305 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0929 14:31:54.440177  2305 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0929 14:31:54.440181  2305 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0929 14:31:54.440196  2305 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0929 14:31:54.440202  2305 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 14:31:54.440419  2305 net.cpp:122] Setting up SoftmaxWithLoss1
I0929 14:31:54.440425  2305 net.cpp:129] Top shape: (1)
I0929 14:31:54.440428  2305 net.cpp:132]     with loss weight 1
I0929 14:31:54.440440  2305 net.cpp:137] Memory required for data: 909156404
I0929 14:31:54.440443  2305 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0929 14:31:54.440445  2305 net.cpp:198] InnerProduct1 needs backward computation.
I0929 14:31:54.440448  2305 net.cpp:198] Pooling1 needs backward computation.
I0929 14:31:54.440449  2305 net.cpp:198] M2PELU55 needs backward computation.
I0929 14:31:54.440451  2305 net.cpp:198] Eltwise27 needs backward computation.
I0929 14:31:54.440454  2305 net.cpp:198] Scale57 needs backward computation.
I0929 14:31:54.440455  2305 net.cpp:198] BatchNorm57 needs backward computation.
I0929 14:31:54.440457  2305 net.cpp:198] Convolution57 needs backward computation.
I0929 14:31:54.440459  2305 net.cpp:198] M2PELU54 needs backward computation.
I0929 14:31:54.440461  2305 net.cpp:198] Scale56 needs backward computation.
I0929 14:31:54.440464  2305 net.cpp:198] BatchNorm56 needs backward computation.
I0929 14:31:54.440465  2305 net.cpp:198] Convolution56 needs backward computation.
I0929 14:31:54.440469  2305 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0929 14:31:54.440470  2305 net.cpp:198] M2PELU53 needs backward computation.
I0929 14:31:54.440472  2305 net.cpp:198] Eltwise26 needs backward computation.
I0929 14:31:54.440475  2305 net.cpp:198] Scale55 needs backward computation.
I0929 14:31:54.440477  2305 net.cpp:198] BatchNorm55 needs backward computation.
I0929 14:31:54.440479  2305 net.cpp:198] Convolution55 needs backward computation.
I0929 14:31:54.440481  2305 net.cpp:198] M2PELU52 needs backward computation.
I0929 14:31:54.440484  2305 net.cpp:198] Scale54 needs backward computation.
I0929 14:31:54.440486  2305 net.cpp:198] BatchNorm54 needs backward computation.
I0929 14:31:54.440488  2305 net.cpp:198] Convolution54 needs backward computation.
I0929 14:31:54.440497  2305 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0929 14:31:54.440500  2305 net.cpp:198] M2PELU51 needs backward computation.
I0929 14:31:54.440502  2305 net.cpp:198] Eltwise25 needs backward computation.
I0929 14:31:54.440505  2305 net.cpp:198] Scale53 needs backward computation.
I0929 14:31:54.440507  2305 net.cpp:198] BatchNorm53 needs backward computation.
I0929 14:31:54.440510  2305 net.cpp:198] Convolution53 needs backward computation.
I0929 14:31:54.440512  2305 net.cpp:198] M2PELU50 needs backward computation.
I0929 14:31:54.440515  2305 net.cpp:198] Scale52 needs backward computation.
I0929 14:31:54.440516  2305 net.cpp:198] BatchNorm52 needs backward computation.
I0929 14:31:54.440520  2305 net.cpp:198] Convolution52 needs backward computation.
I0929 14:31:54.440521  2305 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0929 14:31:54.440524  2305 net.cpp:198] M2PELU49 needs backward computation.
I0929 14:31:54.440526  2305 net.cpp:198] Eltwise24 needs backward computation.
I0929 14:31:54.440528  2305 net.cpp:198] Scale51 needs backward computation.
I0929 14:31:54.440531  2305 net.cpp:198] BatchNorm51 needs backward computation.
I0929 14:31:54.440533  2305 net.cpp:198] Convolution51 needs backward computation.
I0929 14:31:54.440536  2305 net.cpp:198] M2PELU48 needs backward computation.
I0929 14:31:54.440537  2305 net.cpp:198] Scale50 needs backward computation.
I0929 14:31:54.440539  2305 net.cpp:198] BatchNorm50 needs backward computation.
I0929 14:31:54.440541  2305 net.cpp:198] Convolution50 needs backward computation.
I0929 14:31:54.440544  2305 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0929 14:31:54.440546  2305 net.cpp:198] M2PELU47 needs backward computation.
I0929 14:31:54.440548  2305 net.cpp:198] Eltwise23 needs backward computation.
I0929 14:31:54.440551  2305 net.cpp:198] Scale49 needs backward computation.
I0929 14:31:54.440553  2305 net.cpp:198] BatchNorm49 needs backward computation.
I0929 14:31:54.440556  2305 net.cpp:198] Convolution49 needs backward computation.
I0929 14:31:54.440558  2305 net.cpp:198] M2PELU46 needs backward computation.
I0929 14:31:54.440560  2305 net.cpp:198] Scale48 needs backward computation.
I0929 14:31:54.440562  2305 net.cpp:198] BatchNorm48 needs backward computation.
I0929 14:31:54.440564  2305 net.cpp:198] Convolution48 needs backward computation.
I0929 14:31:54.440567  2305 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0929 14:31:54.440569  2305 net.cpp:198] M2PELU45 needs backward computation.
I0929 14:31:54.440572  2305 net.cpp:198] Eltwise22 needs backward computation.
I0929 14:31:54.440573  2305 net.cpp:198] Scale47 needs backward computation.
I0929 14:31:54.440575  2305 net.cpp:198] BatchNorm47 needs backward computation.
I0929 14:31:54.440578  2305 net.cpp:198] Convolution47 needs backward computation.
I0929 14:31:54.440580  2305 net.cpp:198] M2PELU44 needs backward computation.
I0929 14:31:54.440582  2305 net.cpp:198] Scale46 needs backward computation.
I0929 14:31:54.440584  2305 net.cpp:198] BatchNorm46 needs backward computation.
I0929 14:31:54.440587  2305 net.cpp:198] Convolution46 needs backward computation.
I0929 14:31:54.440589  2305 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0929 14:31:54.440592  2305 net.cpp:198] M2PELU43 needs backward computation.
I0929 14:31:54.440593  2305 net.cpp:198] Eltwise21 needs backward computation.
I0929 14:31:54.440596  2305 net.cpp:198] Scale45 needs backward computation.
I0929 14:31:54.440598  2305 net.cpp:198] BatchNorm45 needs backward computation.
I0929 14:31:54.440600  2305 net.cpp:198] Convolution45 needs backward computation.
I0929 14:31:54.440603  2305 net.cpp:198] M2PELU42 needs backward computation.
I0929 14:31:54.440605  2305 net.cpp:198] Scale44 needs backward computation.
I0929 14:31:54.440608  2305 net.cpp:198] BatchNorm44 needs backward computation.
I0929 14:31:54.440609  2305 net.cpp:198] Convolution44 needs backward computation.
I0929 14:31:54.440618  2305 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0929 14:31:54.440620  2305 net.cpp:198] M2PELU41 needs backward computation.
I0929 14:31:54.440623  2305 net.cpp:198] Eltwise20 needs backward computation.
I0929 14:31:54.440625  2305 net.cpp:198] Scale43 needs backward computation.
I0929 14:31:54.440627  2305 net.cpp:198] BatchNorm43 needs backward computation.
I0929 14:31:54.440629  2305 net.cpp:198] Convolution43 needs backward computation.
I0929 14:31:54.440631  2305 net.cpp:198] M2PELU40 needs backward computation.
I0929 14:31:54.440634  2305 net.cpp:198] Scale42 needs backward computation.
I0929 14:31:54.440636  2305 net.cpp:198] BatchNorm42 needs backward computation.
I0929 14:31:54.440639  2305 net.cpp:198] Convolution42 needs backward computation.
I0929 14:31:54.440641  2305 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0929 14:31:54.440644  2305 net.cpp:198] M2PELU39 needs backward computation.
I0929 14:31:54.440646  2305 net.cpp:198] Eltwise19 needs backward computation.
I0929 14:31:54.440649  2305 net.cpp:198] Scale41 needs backward computation.
I0929 14:31:54.440651  2305 net.cpp:198] BatchNorm41 needs backward computation.
I0929 14:31:54.440654  2305 net.cpp:198] Convolution41 needs backward computation.
I0929 14:31:54.440655  2305 net.cpp:198] M2PELU38 needs backward computation.
I0929 14:31:54.440657  2305 net.cpp:198] Scale40 needs backward computation.
I0929 14:31:54.440659  2305 net.cpp:198] BatchNorm40 needs backward computation.
I0929 14:31:54.440662  2305 net.cpp:198] Convolution40 needs backward computation.
I0929 14:31:54.440665  2305 net.cpp:198] Scale39 needs backward computation.
I0929 14:31:54.440666  2305 net.cpp:198] BatchNorm39 needs backward computation.
I0929 14:31:54.440670  2305 net.cpp:198] Convolution39 needs backward computation.
I0929 14:31:54.440671  2305 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0929 14:31:54.440676  2305 net.cpp:198] M2PELU37 needs backward computation.
I0929 14:31:54.440678  2305 net.cpp:198] Eltwise18 needs backward computation.
I0929 14:31:54.440680  2305 net.cpp:198] Scale38 needs backward computation.
I0929 14:31:54.440683  2305 net.cpp:198] BatchNorm38 needs backward computation.
I0929 14:31:54.440685  2305 net.cpp:198] Convolution38 needs backward computation.
I0929 14:31:54.440687  2305 net.cpp:198] M2PELU36 needs backward computation.
I0929 14:31:54.440690  2305 net.cpp:198] Scale37 needs backward computation.
I0929 14:31:54.440692  2305 net.cpp:198] BatchNorm37 needs backward computation.
I0929 14:31:54.440695  2305 net.cpp:198] Convolution37 needs backward computation.
I0929 14:31:54.440696  2305 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0929 14:31:54.440699  2305 net.cpp:198] M2PELU35 needs backward computation.
I0929 14:31:54.440701  2305 net.cpp:198] Eltwise17 needs backward computation.
I0929 14:31:54.440704  2305 net.cpp:198] Scale36 needs backward computation.
I0929 14:31:54.440706  2305 net.cpp:198] BatchNorm36 needs backward computation.
I0929 14:31:54.440708  2305 net.cpp:198] Convolution36 needs backward computation.
I0929 14:31:54.440711  2305 net.cpp:198] M2PELU34 needs backward computation.
I0929 14:31:54.440712  2305 net.cpp:198] Scale35 needs backward computation.
I0929 14:31:54.440714  2305 net.cpp:198] BatchNorm35 needs backward computation.
I0929 14:31:54.440717  2305 net.cpp:198] Convolution35 needs backward computation.
I0929 14:31:54.440719  2305 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0929 14:31:54.440721  2305 net.cpp:198] M2PELU33 needs backward computation.
I0929 14:31:54.440723  2305 net.cpp:198] Eltwise16 needs backward computation.
I0929 14:31:54.440726  2305 net.cpp:198] Scale34 needs backward computation.
I0929 14:31:54.440728  2305 net.cpp:198] BatchNorm34 needs backward computation.
I0929 14:31:54.440731  2305 net.cpp:198] Convolution34 needs backward computation.
I0929 14:31:54.440733  2305 net.cpp:198] M2PELU32 needs backward computation.
I0929 14:31:54.440735  2305 net.cpp:198] Scale33 needs backward computation.
I0929 14:31:54.440740  2305 net.cpp:198] BatchNorm33 needs backward computation.
I0929 14:31:54.440742  2305 net.cpp:198] Convolution33 needs backward computation.
I0929 14:31:54.440745  2305 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0929 14:31:54.440747  2305 net.cpp:198] M2PELU31 needs backward computation.
I0929 14:31:54.440749  2305 net.cpp:198] Eltwise15 needs backward computation.
I0929 14:31:54.440752  2305 net.cpp:198] Scale32 needs backward computation.
I0929 14:31:54.440754  2305 net.cpp:198] BatchNorm32 needs backward computation.
I0929 14:31:54.440757  2305 net.cpp:198] Convolution32 needs backward computation.
I0929 14:31:54.466708  2305 net.cpp:198] M2PELU30 needs backward computation.
I0929 14:31:54.466722  2305 net.cpp:198] Scale31 needs backward computation.
I0929 14:31:54.466725  2305 net.cpp:198] BatchNorm31 needs backward computation.
I0929 14:31:54.466727  2305 net.cpp:198] Convolution31 needs backward computation.
I0929 14:31:54.466732  2305 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0929 14:31:54.466735  2305 net.cpp:198] M2PELU29 needs backward computation.
I0929 14:31:54.466737  2305 net.cpp:198] Eltwise14 needs backward computation.
I0929 14:31:54.466740  2305 net.cpp:198] Scale30 needs backward computation.
I0929 14:31:54.466743  2305 net.cpp:198] BatchNorm30 needs backward computation.
I0929 14:31:54.466745  2305 net.cpp:198] Convolution30 needs backward computation.
I0929 14:31:54.466748  2305 net.cpp:198] M2PELU28 needs backward computation.
I0929 14:31:54.466750  2305 net.cpp:198] Scale29 needs backward computation.
I0929 14:31:54.466753  2305 net.cpp:198] BatchNorm29 needs backward computation.
I0929 14:31:54.466755  2305 net.cpp:198] Convolution29 needs backward computation.
I0929 14:31:54.466758  2305 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0929 14:31:54.466761  2305 net.cpp:198] M2PELU27 needs backward computation.
I0929 14:31:54.466763  2305 net.cpp:198] Eltwise13 needs backward computation.
I0929 14:31:54.466766  2305 net.cpp:198] Scale28 needs backward computation.
I0929 14:31:54.466769  2305 net.cpp:198] BatchNorm28 needs backward computation.
I0929 14:31:54.466771  2305 net.cpp:198] Convolution28 needs backward computation.
I0929 14:31:54.466774  2305 net.cpp:198] M2PELU26 needs backward computation.
I0929 14:31:54.466776  2305 net.cpp:198] Scale27 needs backward computation.
I0929 14:31:54.466779  2305 net.cpp:198] BatchNorm27 needs backward computation.
I0929 14:31:54.466781  2305 net.cpp:198] Convolution27 needs backward computation.
I0929 14:31:54.466784  2305 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0929 14:31:54.466787  2305 net.cpp:198] M2PELU25 needs backward computation.
I0929 14:31:54.466789  2305 net.cpp:198] Eltwise12 needs backward computation.
I0929 14:31:54.466792  2305 net.cpp:198] Scale26 needs backward computation.
I0929 14:31:54.466795  2305 net.cpp:198] BatchNorm26 needs backward computation.
I0929 14:31:54.466797  2305 net.cpp:198] Convolution26 needs backward computation.
I0929 14:31:54.466800  2305 net.cpp:198] M2PELU24 needs backward computation.
I0929 14:31:54.466802  2305 net.cpp:198] Scale25 needs backward computation.
I0929 14:31:54.466804  2305 net.cpp:198] BatchNorm25 needs backward computation.
I0929 14:31:54.466807  2305 net.cpp:198] Convolution25 needs backward computation.
I0929 14:31:54.466810  2305 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0929 14:31:54.466812  2305 net.cpp:198] M2PELU23 needs backward computation.
I0929 14:31:54.466815  2305 net.cpp:198] Eltwise11 needs backward computation.
I0929 14:31:54.466817  2305 net.cpp:198] Scale24 needs backward computation.
I0929 14:31:54.466820  2305 net.cpp:198] BatchNorm24 needs backward computation.
I0929 14:31:54.466822  2305 net.cpp:198] Convolution24 needs backward computation.
I0929 14:31:54.466825  2305 net.cpp:198] M2PELU22 needs backward computation.
I0929 14:31:54.466827  2305 net.cpp:198] Scale23 needs backward computation.
I0929 14:31:54.466841  2305 net.cpp:198] BatchNorm23 needs backward computation.
I0929 14:31:54.466845  2305 net.cpp:198] Convolution23 needs backward computation.
I0929 14:31:54.466847  2305 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0929 14:31:54.466850  2305 net.cpp:198] M2PELU21 needs backward computation.
I0929 14:31:54.466852  2305 net.cpp:198] Eltwise10 needs backward computation.
I0929 14:31:54.466856  2305 net.cpp:198] Scale22 needs backward computation.
I0929 14:31:54.466858  2305 net.cpp:198] BatchNorm22 needs backward computation.
I0929 14:31:54.466861  2305 net.cpp:198] Convolution22 needs backward computation.
I0929 14:31:54.466864  2305 net.cpp:198] M2PELU20 needs backward computation.
I0929 14:31:54.466866  2305 net.cpp:198] Scale21 needs backward computation.
I0929 14:31:54.466869  2305 net.cpp:198] BatchNorm21 needs backward computation.
I0929 14:31:54.466871  2305 net.cpp:198] Convolution21 needs backward computation.
I0929 14:31:54.466874  2305 net.cpp:198] Scale20 needs backward computation.
I0929 14:31:54.466877  2305 net.cpp:198] BatchNorm20 needs backward computation.
I0929 14:31:54.466879  2305 net.cpp:198] Convolution20 needs backward computation.
I0929 14:31:54.466882  2305 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0929 14:31:54.466886  2305 net.cpp:198] M2PELU19 needs backward computation.
I0929 14:31:54.466887  2305 net.cpp:198] Eltwise9 needs backward computation.
I0929 14:31:54.466892  2305 net.cpp:198] Scale19 needs backward computation.
I0929 14:31:54.466893  2305 net.cpp:198] BatchNorm19 needs backward computation.
I0929 14:31:54.466897  2305 net.cpp:198] Convolution19 needs backward computation.
I0929 14:31:54.466898  2305 net.cpp:198] M2PELU18 needs backward computation.
I0929 14:31:54.466902  2305 net.cpp:198] Scale18 needs backward computation.
I0929 14:31:54.466903  2305 net.cpp:198] BatchNorm18 needs backward computation.
I0929 14:31:54.466907  2305 net.cpp:198] Convolution18 needs backward computation.
I0929 14:31:54.466912  2305 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0929 14:31:54.466914  2305 net.cpp:198] M2PELU17 needs backward computation.
I0929 14:31:54.466917  2305 net.cpp:198] Eltwise8 needs backward computation.
I0929 14:31:54.466920  2305 net.cpp:198] Scale17 needs backward computation.
I0929 14:31:54.466922  2305 net.cpp:198] BatchNorm17 needs backward computation.
I0929 14:31:54.466924  2305 net.cpp:198] Convolution17 needs backward computation.
I0929 14:31:54.466928  2305 net.cpp:198] M2PELU16 needs backward computation.
I0929 14:31:54.466929  2305 net.cpp:198] Scale16 needs backward computation.
I0929 14:31:54.466933  2305 net.cpp:198] BatchNorm16 needs backward computation.
I0929 14:31:54.466934  2305 net.cpp:198] Convolution16 needs backward computation.
I0929 14:31:54.466938  2305 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0929 14:31:54.466940  2305 net.cpp:198] M2PELU15 needs backward computation.
I0929 14:31:54.466943  2305 net.cpp:198] Eltwise7 needs backward computation.
I0929 14:31:54.466945  2305 net.cpp:198] Scale15 needs backward computation.
I0929 14:31:54.466948  2305 net.cpp:198] BatchNorm15 needs backward computation.
I0929 14:31:54.466950  2305 net.cpp:198] Convolution15 needs backward computation.
I0929 14:31:54.466953  2305 net.cpp:198] M2PELU14 needs backward computation.
I0929 14:31:54.466955  2305 net.cpp:198] Scale14 needs backward computation.
I0929 14:31:54.466958  2305 net.cpp:198] BatchNorm14 needs backward computation.
I0929 14:31:54.466960  2305 net.cpp:198] Convolution14 needs backward computation.
I0929 14:31:54.466962  2305 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0929 14:31:54.466965  2305 net.cpp:198] M2PELU13 needs backward computation.
I0929 14:31:54.466967  2305 net.cpp:198] Eltwise6 needs backward computation.
I0929 14:31:54.466970  2305 net.cpp:198] Scale13 needs backward computation.
I0929 14:31:54.466974  2305 net.cpp:198] BatchNorm13 needs backward computation.
I0929 14:31:54.466975  2305 net.cpp:198] Convolution13 needs backward computation.
I0929 14:31:54.466981  2305 net.cpp:198] M2PELU12 needs backward computation.
I0929 14:31:54.466984  2305 net.cpp:198] Scale12 needs backward computation.
I0929 14:31:54.466986  2305 net.cpp:198] BatchNorm12 needs backward computation.
I0929 14:31:54.466989  2305 net.cpp:198] Convolution12 needs backward computation.
I0929 14:31:54.466992  2305 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0929 14:31:54.466995  2305 net.cpp:198] M2PELU11 needs backward computation.
I0929 14:31:54.466997  2305 net.cpp:198] Eltwise5 needs backward computation.
I0929 14:31:54.469291  2305 net.cpp:198] Scale11 needs backward computation.
I0929 14:31:54.469298  2305 net.cpp:198] BatchNorm11 needs backward computation.
I0929 14:31:54.469301  2305 net.cpp:198] Convolution11 needs backward computation.
I0929 14:31:54.469305  2305 net.cpp:198] M2PELU10 needs backward computation.
I0929 14:31:54.469306  2305 net.cpp:198] Scale10 needs backward computation.
I0929 14:31:54.469308  2305 net.cpp:198] BatchNorm10 needs backward computation.
I0929 14:31:54.469311  2305 net.cpp:198] Convolution10 needs backward computation.
I0929 14:31:54.469314  2305 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0929 14:31:54.469316  2305 net.cpp:198] M2PELU9 needs backward computation.
I0929 14:31:54.469319  2305 net.cpp:198] Eltwise4 needs backward computation.
I0929 14:31:54.469322  2305 net.cpp:198] Scale9 needs backward computation.
I0929 14:31:54.469324  2305 net.cpp:198] BatchNorm9 needs backward computation.
I0929 14:31:54.469327  2305 net.cpp:198] Convolution9 needs backward computation.
I0929 14:31:54.469329  2305 net.cpp:198] M2PELU8 needs backward computation.
I0929 14:31:54.469332  2305 net.cpp:198] Scale8 needs backward computation.
I0929 14:31:54.469334  2305 net.cpp:198] BatchNorm8 needs backward computation.
I0929 14:31:54.469337  2305 net.cpp:198] Convolution8 needs backward computation.
I0929 14:31:54.469341  2305 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0929 14:31:54.469342  2305 net.cpp:198] M2PELU7 needs backward computation.
I0929 14:31:54.469346  2305 net.cpp:198] Eltwise3 needs backward computation.
I0929 14:31:54.469348  2305 net.cpp:198] Scale7 needs backward computation.
I0929 14:31:54.469350  2305 net.cpp:198] BatchNorm7 needs backward computation.
I0929 14:31:54.469352  2305 net.cpp:198] Convolution7 needs backward computation.
I0929 14:31:54.469355  2305 net.cpp:198] M2PELU6 needs backward computation.
I0929 14:31:54.469357  2305 net.cpp:198] Scale6 needs backward computation.
I0929 14:31:54.469360  2305 net.cpp:198] BatchNorm6 needs backward computation.
I0929 14:31:54.469362  2305 net.cpp:198] Convolution6 needs backward computation.
I0929 14:31:54.469364  2305 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0929 14:31:54.469367  2305 net.cpp:198] M2PELU5 needs backward computation.
I0929 14:31:54.469369  2305 net.cpp:198] Eltwise2 needs backward computation.
I0929 14:31:54.469373  2305 net.cpp:198] Scale5 needs backward computation.
I0929 14:31:54.469375  2305 net.cpp:198] BatchNorm5 needs backward computation.
I0929 14:31:54.469377  2305 net.cpp:198] Convolution5 needs backward computation.
I0929 14:31:54.469380  2305 net.cpp:198] M2PELU4 needs backward computation.
I0929 14:31:54.469384  2305 net.cpp:198] Scale4 needs backward computation.
I0929 14:31:54.469388  2305 net.cpp:198] BatchNorm4 needs backward computation.
I0929 14:31:54.469389  2305 net.cpp:198] Convolution4 needs backward computation.
I0929 14:31:54.469391  2305 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0929 14:31:54.469394  2305 net.cpp:198] M2PELU3 needs backward computation.
I0929 14:31:54.469398  2305 net.cpp:198] Eltwise1 needs backward computation.
I0929 14:31:54.469400  2305 net.cpp:198] Scale3 needs backward computation.
I0929 14:31:54.469403  2305 net.cpp:198] BatchNorm3 needs backward computation.
I0929 14:31:54.469404  2305 net.cpp:198] Convolution3 needs backward computation.
I0929 14:31:54.469413  2305 net.cpp:198] M2PELU2 needs backward computation.
I0929 14:31:54.469416  2305 net.cpp:198] Scale2 needs backward computation.
I0929 14:31:54.469419  2305 net.cpp:198] BatchNorm2 needs backward computation.
I0929 14:31:54.469420  2305 net.cpp:198] Convolution2 needs backward computation.
I0929 14:31:54.469424  2305 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0929 14:31:54.469426  2305 net.cpp:198] M2PELU1 needs backward computation.
I0929 14:31:54.469429  2305 net.cpp:198] Scale1 needs backward computation.
I0929 14:31:54.469430  2305 net.cpp:198] BatchNorm1 needs backward computation.
I0929 14:31:54.469434  2305 net.cpp:198] Convolution1 needs backward computation.
I0929 14:31:54.469436  2305 net.cpp:200] Data1 does not need backward computation.
I0929 14:31:54.469439  2305 net.cpp:242] This network produces output SoftmaxWithLoss1
I0929 14:31:54.469545  2305 net.cpp:255] Network initialization done.
I0929 14:31:54.473747  2305 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_msra.prototxt
I0929 14:31:54.473759  2305 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0929 14:31:54.473764  2305 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res56/res56_mpelu_decay_msra.prototxt
I0929 14:31:54.473950  2305 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0929 14:31:54.475136  2305 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU24"
  type: "M2PELU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: tr
I0929 14:31:54.531688  2305 layer_factory.hpp:77] Creating layer Data1
I0929 14:31:54.531749  2305 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0929 14:31:54.531761  2305 net.cpp:84] Creating Layer Data1
I0929 14:31:54.531766  2305 net.cpp:380] Data1 -> Data1
I0929 14:31:54.531775  2305 net.cpp:380] Data1 -> Data2
I0929 14:31:54.531782  2305 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0929 14:31:54.531988  2305 data_layer.cpp:45] output data size: 100,3,32,32
I0929 14:31:54.536002  2305 net.cpp:122] Setting up Data1
I0929 14:31:54.536021  2305 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0929 14:31:54.536026  2305 net.cpp:129] Top shape: 100 (100)
I0929 14:31:54.536028  2305 net.cpp:137] Memory required for data: 1229200
I0929 14:31:54.536033  2305 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0929 14:31:54.536042  2305 net.cpp:84] Creating Layer Data2_Data1_1_split
I0929 14:31:54.536046  2305 net.cpp:406] Data2_Data1_1_split <- Data2
I0929 14:31:54.536051  2305 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0929 14:31:54.536058  2305 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0929 14:31:54.536164  2305 net.cpp:122] Setting up Data2_Data1_1_split
I0929 14:31:54.536175  2305 net.cpp:129] Top shape: 100 (100)
I0929 14:31:54.536178  2305 net.cpp:129] Top shape: 100 (100)
I0929 14:31:54.536180  2305 net.cpp:137] Memory required for data: 1230000
I0929 14:31:54.536183  2305 layer_factory.hpp:77] Creating layer Convolution1
I0929 14:31:54.536195  2305 net.cpp:84] Creating Layer Convolution1
I0929 14:31:54.536197  2305 net.cpp:406] Convolution1 <- Data1
I0929 14:31:54.536201  2305 net.cpp:380] Convolution1 -> Convolution1
I0929 14:31:54.537449  2305 net.cpp:122] Setting up Convolution1
I0929 14:31:54.537461  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.537463  2305 net.cpp:137] Memory required for data: 7783600
I0929 14:31:54.537472  2305 layer_factory.hpp:77] Creating layer BatchNorm1
I0929 14:31:54.537478  2305 net.cpp:84] Creating Layer BatchNorm1
I0929 14:31:54.537480  2305 net.cpp:406] BatchNorm1 <- Convolution1
I0929 14:31:54.537484  2305 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0929 14:31:54.537643  2305 net.cpp:122] Setting up BatchNorm1
I0929 14:31:54.537648  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.537650  2305 net.cpp:137] Memory required for data: 14337200
I0929 14:31:54.537657  2305 layer_factory.hpp:77] Creating layer Scale1
I0929 14:31:54.537663  2305 net.cpp:84] Creating Layer Scale1
I0929 14:31:54.537667  2305 net.cpp:406] Scale1 <- Convolution1
I0929 14:31:54.537669  2305 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0929 14:31:54.537703  2305 layer_factory.hpp:77] Creating layer Scale1
I0929 14:31:54.537796  2305 net.cpp:122] Setting up Scale1
I0929 14:31:54.537801  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.537803  2305 net.cpp:137] Memory required for data: 20890800
I0929 14:31:54.537807  2305 layer_factory.hpp:77] Creating layer M2PELU1
I0929 14:31:54.537813  2305 net.cpp:84] Creating Layer M2PELU1
I0929 14:31:54.537817  2305 net.cpp:406] M2PELU1 <- Convolution1
I0929 14:31:54.537819  2305 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I0929 14:31:54.538455  2305 net.cpp:122] Setting up M2PELU1
I0929 14:31:54.538462  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.538465  2305 net.cpp:137] Memory required for data: 27444400
I0929 14:31:54.538472  2305 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I0929 14:31:54.538478  2305 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I0929 14:31:54.538480  2305 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I0929 14:31:54.538486  2305 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I0929 14:31:54.538491  2305 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I0929 14:31:54.538532  2305 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I0929 14:31:54.559036  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.559046  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.559049  2305 net.cpp:137] Memory required for data: 40551600
I0929 14:31:54.559052  2305 layer_factory.hpp:77] Creating layer Convolution2
I0929 14:31:54.559068  2305 net.cpp:84] Creating Layer Convolution2
I0929 14:31:54.559073  2305 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I0929 14:31:54.559079  2305 net.cpp:380] Convolution2 -> Convolution2
I0929 14:31:54.560362  2305 net.cpp:122] Setting up Convolution2
I0929 14:31:54.560374  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.560376  2305 net.cpp:137] Memory required for data: 47105200
I0929 14:31:54.560382  2305 layer_factory.hpp:77] Creating layer BatchNorm2
I0929 14:31:54.560391  2305 net.cpp:84] Creating Layer BatchNorm2
I0929 14:31:54.560395  2305 net.cpp:406] BatchNorm2 <- Convolution2
I0929 14:31:54.560400  2305 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0929 14:31:54.560562  2305 net.cpp:122] Setting up BatchNorm2
I0929 14:31:54.560567  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.560570  2305 net.cpp:137] Memory required for data: 53658800
I0929 14:31:54.560585  2305 layer_factory.hpp:77] Creating layer Scale2
I0929 14:31:54.560591  2305 net.cpp:84] Creating Layer Scale2
I0929 14:31:54.560593  2305 net.cpp:406] Scale2 <- Convolution2
I0929 14:31:54.560597  2305 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0929 14:31:54.560641  2305 layer_factory.hpp:77] Creating layer Scale2
I0929 14:31:54.560771  2305 net.cpp:122] Setting up Scale2
I0929 14:31:54.560780  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.560781  2305 net.cpp:137] Memory required for data: 60212400
I0929 14:31:54.560787  2305 layer_factory.hpp:77] Creating layer M2PELU2
I0929 14:31:54.560798  2305 net.cpp:84] Creating Layer M2PELU2
I0929 14:31:54.560802  2305 net.cpp:406] M2PELU2 <- Convolution2
I0929 14:31:54.560809  2305 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I0929 14:31:54.560919  2305 net.cpp:122] Setting up M2PELU2
I0929 14:31:54.560923  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.560925  2305 net.cpp:137] Memory required for data: 66766000
I0929 14:31:54.560933  2305 layer_factory.hpp:77] Creating layer Convolution3
I0929 14:31:54.560941  2305 net.cpp:84] Creating Layer Convolution3
I0929 14:31:54.560943  2305 net.cpp:406] Convolution3 <- Convolution2
I0929 14:31:54.560948  2305 net.cpp:380] Convolution3 -> Convolution3
I0929 14:31:54.562067  2305 net.cpp:122] Setting up Convolution3
I0929 14:31:54.562077  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.562079  2305 net.cpp:137] Memory required for data: 73319600
I0929 14:31:54.562083  2305 layer_factory.hpp:77] Creating layer BatchNorm3
I0929 14:31:54.562088  2305 net.cpp:84] Creating Layer BatchNorm3
I0929 14:31:54.562091  2305 net.cpp:406] BatchNorm3 <- Convolution3
I0929 14:31:54.562095  2305 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0929 14:31:54.562255  2305 net.cpp:122] Setting up BatchNorm3
I0929 14:31:54.562260  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.562263  2305 net.cpp:137] Memory required for data: 79873200
I0929 14:31:54.562268  2305 layer_factory.hpp:77] Creating layer Scale3
I0929 14:31:54.562271  2305 net.cpp:84] Creating Layer Scale3
I0929 14:31:54.562274  2305 net.cpp:406] Scale3 <- Convolution3
I0929 14:31:54.562278  2305 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0929 14:31:54.562309  2305 layer_factory.hpp:77] Creating layer Scale3
I0929 14:31:54.562397  2305 net.cpp:122] Setting up Scale3
I0929 14:31:54.562402  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.562404  2305 net.cpp:137] Memory required for data: 86426800
I0929 14:31:54.562408  2305 layer_factory.hpp:77] Creating layer Eltwise1
I0929 14:31:54.562413  2305 net.cpp:84] Creating Layer Eltwise1
I0929 14:31:54.562417  2305 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I0929 14:31:54.562419  2305 net.cpp:406] Eltwise1 <- Convolution3
I0929 14:31:54.562422  2305 net.cpp:380] Eltwise1 -> Eltwise1
I0929 14:31:54.562441  2305 net.cpp:122] Setting up Eltwise1
I0929 14:31:54.562445  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.562448  2305 net.cpp:137] Memory required for data: 92980400
I0929 14:31:54.562449  2305 layer_factory.hpp:77] Creating layer M2PELU3
I0929 14:31:54.562458  2305 net.cpp:84] Creating Layer M2PELU3
I0929 14:31:54.562460  2305 net.cpp:406] M2PELU3 <- Eltwise1
I0929 14:31:54.562464  2305 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I0929 14:31:54.562582  2305 net.cpp:122] Setting up M2PELU3
I0929 14:31:54.562589  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.562592  2305 net.cpp:137] Memory required for data: 99534000
I0929 14:31:54.562595  2305 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I0929 14:31:54.562602  2305 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I0929 14:31:54.562603  2305 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I0929 14:31:54.562608  2305 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I0929 14:31:54.562611  2305 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I0929 14:31:54.562649  2305 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I0929 14:31:54.562654  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.562657  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.562659  2305 net.cpp:137] Memory required for data: 112641200
I0929 14:31:54.562661  2305 layer_factory.hpp:77] Creating layer Convolution4
I0929 14:31:54.562669  2305 net.cpp:84] Creating Layer Convolution4
I0929 14:31:54.562671  2305 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I0929 14:31:54.562675  2305 net.cpp:380] Convolution4 -> Convolution4
I0929 14:31:54.563668  2305 net.cpp:122] Setting up Convolution4
I0929 14:31:54.563676  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.563679  2305 net.cpp:137] Memory required for data: 119194800
I0929 14:31:54.563683  2305 layer_factory.hpp:77] Creating layer BatchNorm4
I0929 14:31:54.563689  2305 net.cpp:84] Creating Layer BatchNorm4
I0929 14:31:54.563693  2305 net.cpp:406] BatchNorm4 <- Convolution4
I0929 14:31:54.563696  2305 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0929 14:31:54.563856  2305 net.cpp:122] Setting up BatchNorm4
I0929 14:31:54.563861  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.563863  2305 net.cpp:137] Memory required for data: 125748400
I0929 14:31:54.563868  2305 layer_factory.hpp:77] Creating layer Scale4
I0929 14:31:54.563872  2305 net.cpp:84] Creating Layer Scale4
I0929 14:31:54.563875  2305 net.cpp:406] Scale4 <- Convolution4
I0929 14:31:54.563879  2305 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0929 14:31:54.563910  2305 layer_factory.hpp:77] Creating layer Scale4
I0929 14:31:54.563997  2305 net.cpp:122] Setting up Scale4
I0929 14:31:54.564002  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.564004  2305 net.cpp:137] Memory required for data: 132302000
I0929 14:31:54.564013  2305 layer_factory.hpp:77] Creating layer M2PELU4
I0929 14:31:54.564018  2305 net.cpp:84] Creating Layer M2PELU4
I0929 14:31:54.564020  2305 net.cpp:406] M2PELU4 <- Convolution4
I0929 14:31:54.564025  2305 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I0929 14:31:54.564131  2305 net.cpp:122] Setting up M2PELU4
I0929 14:31:54.564134  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.564137  2305 net.cpp:137] Memory required for data: 138855600
I0929 14:31:54.564141  2305 layer_factory.hpp:77] Creating layer Convolution5
I0929 14:31:54.564148  2305 net.cpp:84] Creating Layer Convolution5
I0929 14:31:54.564151  2305 net.cpp:406] Convolution5 <- Convolution4
I0929 14:31:54.564155  2305 net.cpp:380] Convolution5 -> Convolution5
I0929 14:31:54.565141  2305 net.cpp:122] Setting up Convolution5
I0929 14:31:54.565150  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.565155  2305 net.cpp:137] Memory required for data: 145409200
I0929 14:31:54.565158  2305 layer_factory.hpp:77] Creating layer BatchNorm5
I0929 14:31:54.565165  2305 net.cpp:84] Creating Layer BatchNorm5
I0929 14:31:54.565167  2305 net.cpp:406] BatchNorm5 <- Convolution5
I0929 14:31:54.565171  2305 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0929 14:31:54.565333  2305 net.cpp:122] Setting up BatchNorm5
I0929 14:31:54.565338  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.565340  2305 net.cpp:137] Memory required for data: 151962800
I0929 14:31:54.565346  2305 layer_factory.hpp:77] Creating layer Scale5
I0929 14:31:54.565351  2305 net.cpp:84] Creating Layer Scale5
I0929 14:31:54.565353  2305 net.cpp:406] Scale5 <- Convolution5
I0929 14:31:54.565356  2305 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0929 14:31:54.565389  2305 layer_factory.hpp:77] Creating layer Scale5
I0929 14:31:54.565477  2305 net.cpp:122] Setting up Scale5
I0929 14:31:54.565482  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.565485  2305 net.cpp:137] Memory required for data: 158516400
I0929 14:31:54.565488  2305 layer_factory.hpp:77] Creating layer Eltwise2
I0929 14:31:54.565492  2305 net.cpp:84] Creating Layer Eltwise2
I0929 14:31:54.565501  2305 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I0929 14:31:54.565505  2305 net.cpp:406] Eltwise2 <- Convolution5
I0929 14:31:54.565510  2305 net.cpp:380] Eltwise2 -> Eltwise2
I0929 14:31:54.565528  2305 net.cpp:122] Setting up Eltwise2
I0929 14:31:54.565534  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.565536  2305 net.cpp:137] Memory required for data: 165070000
I0929 14:31:54.565538  2305 layer_factory.hpp:77] Creating layer M2PELU5
I0929 14:31:54.565543  2305 net.cpp:84] Creating Layer M2PELU5
I0929 14:31:54.565546  2305 net.cpp:406] M2PELU5 <- Eltwise2
I0929 14:31:54.565549  2305 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I0929 14:31:54.565655  2305 net.cpp:122] Setting up M2PELU5
I0929 14:31:54.565660  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.565662  2305 net.cpp:137] Memory required for data: 171623600
I0929 14:31:54.565666  2305 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I0929 14:31:54.565670  2305 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I0929 14:31:54.565672  2305 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I0929 14:31:54.565676  2305 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I0929 14:31:54.565680  2305 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I0929 14:31:54.565711  2305 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I0929 14:31:54.565714  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.565717  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.565719  2305 net.cpp:137] Memory required for data: 184730800
I0929 14:31:54.565721  2305 layer_factory.hpp:77] Creating layer Convolution6
I0929 14:31:54.565727  2305 net.cpp:84] Creating Layer Convolution6
I0929 14:31:54.565731  2305 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I0929 14:31:54.565734  2305 net.cpp:380] Convolution6 -> Convolution6
I0929 14:31:54.566721  2305 net.cpp:122] Setting up Convolution6
I0929 14:31:54.566730  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.566733  2305 net.cpp:137] Memory required for data: 191284400
I0929 14:31:54.566738  2305 layer_factory.hpp:77] Creating layer BatchNorm6
I0929 14:31:54.566745  2305 net.cpp:84] Creating Layer BatchNorm6
I0929 14:31:54.566747  2305 net.cpp:406] BatchNorm6 <- Convolution6
I0929 14:31:54.566751  2305 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0929 14:31:54.566910  2305 net.cpp:122] Setting up BatchNorm6
I0929 14:31:54.566915  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.566917  2305 net.cpp:137] Memory required for data: 197838000
I0929 14:31:54.566921  2305 layer_factory.hpp:77] Creating layer Scale6
I0929 14:31:54.566926  2305 net.cpp:84] Creating Layer Scale6
I0929 14:31:54.566929  2305 net.cpp:406] Scale6 <- Convolution6
I0929 14:31:54.566933  2305 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0929 14:31:54.566964  2305 layer_factory.hpp:77] Creating layer Scale6
I0929 14:31:54.567054  2305 net.cpp:122] Setting up Scale6
I0929 14:31:54.567059  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.567060  2305 net.cpp:137] Memory required for data: 204391600
I0929 14:31:54.567065  2305 layer_factory.hpp:77] Creating layer M2PELU6
I0929 14:31:54.567070  2305 net.cpp:84] Creating Layer M2PELU6
I0929 14:31:54.567072  2305 net.cpp:406] M2PELU6 <- Convolution6
I0929 14:31:54.567075  2305 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I0929 14:31:54.567179  2305 net.cpp:122] Setting up M2PELU6
I0929 14:31:54.567184  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.567186  2305 net.cpp:137] Memory required for data: 210945200
I0929 14:31:54.567190  2305 layer_factory.hpp:77] Creating layer Convolution7
I0929 14:31:54.567198  2305 net.cpp:84] Creating Layer Convolution7
I0929 14:31:54.567199  2305 net.cpp:406] Convolution7 <- Convolution6
I0929 14:31:54.567203  2305 net.cpp:380] Convolution7 -> Convolution7
I0929 14:31:54.568184  2305 net.cpp:122] Setting up Convolution7
I0929 14:31:54.568193  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.568202  2305 net.cpp:137] Memory required for data: 217498800
I0929 14:31:54.568208  2305 layer_factory.hpp:77] Creating layer BatchNorm7
I0929 14:31:54.568215  2305 net.cpp:84] Creating Layer BatchNorm7
I0929 14:31:54.568218  2305 net.cpp:406] BatchNorm7 <- Convolution7
I0929 14:31:54.568222  2305 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0929 14:31:54.568380  2305 net.cpp:122] Setting up BatchNorm7
I0929 14:31:54.568385  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.568388  2305 net.cpp:137] Memory required for data: 224052400
I0929 14:31:54.568393  2305 layer_factory.hpp:77] Creating layer Scale7
I0929 14:31:54.568397  2305 net.cpp:84] Creating Layer Scale7
I0929 14:31:54.568400  2305 net.cpp:406] Scale7 <- Convolution7
I0929 14:31:54.568403  2305 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0929 14:31:54.568434  2305 layer_factory.hpp:77] Creating layer Scale7
I0929 14:31:54.568526  2305 net.cpp:122] Setting up Scale7
I0929 14:31:54.568531  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.568532  2305 net.cpp:137] Memory required for data: 230606000
I0929 14:31:54.568536  2305 layer_factory.hpp:77] Creating layer Eltwise3
I0929 14:31:54.568542  2305 net.cpp:84] Creating Layer Eltwise3
I0929 14:31:54.568543  2305 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I0929 14:31:54.568547  2305 net.cpp:406] Eltwise3 <- Convolution7
I0929 14:31:54.568549  2305 net.cpp:380] Eltwise3 -> Eltwise3
I0929 14:31:54.568568  2305 net.cpp:122] Setting up Eltwise3
I0929 14:31:54.568572  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.568574  2305 net.cpp:137] Memory required for data: 237159600
I0929 14:31:54.568578  2305 layer_factory.hpp:77] Creating layer M2PELU7
I0929 14:31:54.568583  2305 net.cpp:84] Creating Layer M2PELU7
I0929 14:31:54.568584  2305 net.cpp:406] M2PELU7 <- Eltwise3
I0929 14:31:54.568588  2305 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I0929 14:31:54.568694  2305 net.cpp:122] Setting up M2PELU7
I0929 14:31:54.568698  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.568701  2305 net.cpp:137] Memory required for data: 243713200
I0929 14:31:54.568704  2305 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I0929 14:31:54.568708  2305 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I0929 14:31:54.568711  2305 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I0929 14:31:54.568713  2305 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I0929 14:31:54.568719  2305 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I0929 14:31:54.568747  2305 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I0929 14:31:54.568750  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.589615  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.589623  2305 net.cpp:137] Memory required for data: 256820400
I0929 14:31:54.589627  2305 layer_factory.hpp:77] Creating layer Convolution8
I0929 14:31:54.589635  2305 net.cpp:84] Creating Layer Convolution8
I0929 14:31:54.589638  2305 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I0929 14:31:54.589646  2305 net.cpp:380] Convolution8 -> Convolution8
I0929 14:31:54.590788  2305 net.cpp:122] Setting up Convolution8
I0929 14:31:54.590798  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.590801  2305 net.cpp:137] Memory required for data: 263374000
I0929 14:31:54.590816  2305 layer_factory.hpp:77] Creating layer BatchNorm8
I0929 14:31:54.590821  2305 net.cpp:84] Creating Layer BatchNorm8
I0929 14:31:54.590824  2305 net.cpp:406] BatchNorm8 <- Convolution8
I0929 14:31:54.590828  2305 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0929 14:31:54.590997  2305 net.cpp:122] Setting up BatchNorm8
I0929 14:31:54.591002  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.591004  2305 net.cpp:137] Memory required for data: 269927600
I0929 14:31:54.591009  2305 layer_factory.hpp:77] Creating layer Scale8
I0929 14:31:54.591015  2305 net.cpp:84] Creating Layer Scale8
I0929 14:31:54.591027  2305 net.cpp:406] Scale8 <- Convolution8
I0929 14:31:54.591032  2305 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0929 14:31:54.591070  2305 layer_factory.hpp:77] Creating layer Scale8
I0929 14:31:54.591168  2305 net.cpp:122] Setting up Scale8
I0929 14:31:54.591174  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.591178  2305 net.cpp:137] Memory required for data: 276481200
I0929 14:31:54.591186  2305 layer_factory.hpp:77] Creating layer M2PELU8
I0929 14:31:54.591197  2305 net.cpp:84] Creating Layer M2PELU8
I0929 14:31:54.591202  2305 net.cpp:406] M2PELU8 <- Convolution8
I0929 14:31:54.591207  2305 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I0929 14:31:54.591387  2305 net.cpp:122] Setting up M2PELU8
I0929 14:31:54.591395  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.591398  2305 net.cpp:137] Memory required for data: 283034800
I0929 14:31:54.591403  2305 layer_factory.hpp:77] Creating layer Convolution9
I0929 14:31:54.591411  2305 net.cpp:84] Creating Layer Convolution9
I0929 14:31:54.591414  2305 net.cpp:406] Convolution9 <- Convolution8
I0929 14:31:54.591418  2305 net.cpp:380] Convolution9 -> Convolution9
I0929 14:31:54.592452  2305 net.cpp:122] Setting up Convolution9
I0929 14:31:54.592460  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.592463  2305 net.cpp:137] Memory required for data: 289588400
I0929 14:31:54.592468  2305 layer_factory.hpp:77] Creating layer BatchNorm9
I0929 14:31:54.592474  2305 net.cpp:84] Creating Layer BatchNorm9
I0929 14:31:54.592478  2305 net.cpp:406] BatchNorm9 <- Convolution9
I0929 14:31:54.592483  2305 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0929 14:31:54.592641  2305 net.cpp:122] Setting up BatchNorm9
I0929 14:31:54.592646  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.592648  2305 net.cpp:137] Memory required for data: 296142000
I0929 14:31:54.592653  2305 layer_factory.hpp:77] Creating layer Scale9
I0929 14:31:54.592658  2305 net.cpp:84] Creating Layer Scale9
I0929 14:31:54.592661  2305 net.cpp:406] Scale9 <- Convolution9
I0929 14:31:54.592664  2305 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0929 14:31:54.592696  2305 layer_factory.hpp:77] Creating layer Scale9
I0929 14:31:54.592787  2305 net.cpp:122] Setting up Scale9
I0929 14:31:54.592790  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.592792  2305 net.cpp:137] Memory required for data: 302695600
I0929 14:31:54.592797  2305 layer_factory.hpp:77] Creating layer Eltwise4
I0929 14:31:54.592802  2305 net.cpp:84] Creating Layer Eltwise4
I0929 14:31:54.592804  2305 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I0929 14:31:54.592808  2305 net.cpp:406] Eltwise4 <- Convolution9
I0929 14:31:54.592813  2305 net.cpp:380] Eltwise4 -> Eltwise4
I0929 14:31:54.592831  2305 net.cpp:122] Setting up Eltwise4
I0929 14:31:54.592836  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.592839  2305 net.cpp:137] Memory required for data: 309249200
I0929 14:31:54.592840  2305 layer_factory.hpp:77] Creating layer M2PELU9
I0929 14:31:54.592845  2305 net.cpp:84] Creating Layer M2PELU9
I0929 14:31:54.592847  2305 net.cpp:406] M2PELU9 <- Eltwise4
I0929 14:31:54.592851  2305 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I0929 14:31:54.592957  2305 net.cpp:122] Setting up M2PELU9
I0929 14:31:54.592962  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.592964  2305 net.cpp:137] Memory required for data: 315802800
I0929 14:31:54.592968  2305 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I0929 14:31:54.592972  2305 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I0929 14:31:54.592974  2305 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I0929 14:31:54.592979  2305 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I0929 14:31:54.592983  2305 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I0929 14:31:54.593011  2305 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I0929 14:31:54.593015  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.593026  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.593029  2305 net.cpp:137] Memory required for data: 328910000
I0929 14:31:54.593031  2305 layer_factory.hpp:77] Creating layer Convolution10
I0929 14:31:54.593039  2305 net.cpp:84] Creating Layer Convolution10
I0929 14:31:54.593041  2305 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I0929 14:31:54.593045  2305 net.cpp:380] Convolution10 -> Convolution10
I0929 14:31:54.594099  2305 net.cpp:122] Setting up Convolution10
I0929 14:31:54.594107  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.594110  2305 net.cpp:137] Memory required for data: 335463600
I0929 14:31:54.594115  2305 layer_factory.hpp:77] Creating layer BatchNorm10
I0929 14:31:54.594121  2305 net.cpp:84] Creating Layer BatchNorm10
I0929 14:31:54.594125  2305 net.cpp:406] BatchNorm10 <- Convolution10
I0929 14:31:54.594128  2305 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0929 14:31:54.594288  2305 net.cpp:122] Setting up BatchNorm10
I0929 14:31:54.594293  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.594295  2305 net.cpp:137] Memory required for data: 342017200
I0929 14:31:54.594300  2305 layer_factory.hpp:77] Creating layer Scale10
I0929 14:31:54.594305  2305 net.cpp:84] Creating Layer Scale10
I0929 14:31:54.594308  2305 net.cpp:406] Scale10 <- Convolution10
I0929 14:31:54.594311  2305 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0929 14:31:54.594346  2305 layer_factory.hpp:77] Creating layer Scale10
I0929 14:31:54.594435  2305 net.cpp:122] Setting up Scale10
I0929 14:31:54.594440  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.594442  2305 net.cpp:137] Memory required for data: 348570800
I0929 14:31:54.594446  2305 layer_factory.hpp:77] Creating layer M2PELU10
I0929 14:31:54.594450  2305 net.cpp:84] Creating Layer M2PELU10
I0929 14:31:54.594454  2305 net.cpp:406] M2PELU10 <- Convolution10
I0929 14:31:54.594457  2305 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I0929 14:31:54.594569  2305 net.cpp:122] Setting up M2PELU10
I0929 14:31:54.594575  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.594578  2305 net.cpp:137] Memory required for data: 355124400
I0929 14:31:54.594581  2305 layer_factory.hpp:77] Creating layer Convolution11
I0929 14:31:54.594588  2305 net.cpp:84] Creating Layer Convolution11
I0929 14:31:54.594591  2305 net.cpp:406] Convolution11 <- Convolution10
I0929 14:31:54.594595  2305 net.cpp:380] Convolution11 -> Convolution11
I0929 14:31:54.595918  2305 net.cpp:122] Setting up Convolution11
I0929 14:31:54.595927  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.595929  2305 net.cpp:137] Memory required for data: 361678000
I0929 14:31:54.595935  2305 layer_factory.hpp:77] Creating layer BatchNorm11
I0929 14:31:54.595940  2305 net.cpp:84] Creating Layer BatchNorm11
I0929 14:31:54.595943  2305 net.cpp:406] BatchNorm11 <- Convolution11
I0929 14:31:54.595948  2305 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0929 14:31:54.596113  2305 net.cpp:122] Setting up BatchNorm11
I0929 14:31:54.596118  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.596120  2305 net.cpp:137] Memory required for data: 368231600
I0929 14:31:54.596125  2305 layer_factory.hpp:77] Creating layer Scale11
I0929 14:31:54.596130  2305 net.cpp:84] Creating Layer Scale11
I0929 14:31:54.596132  2305 net.cpp:406] Scale11 <- Convolution11
I0929 14:31:54.596135  2305 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0929 14:31:54.596168  2305 layer_factory.hpp:77] Creating layer Scale11
I0929 14:31:54.596259  2305 net.cpp:122] Setting up Scale11
I0929 14:31:54.596264  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.596266  2305 net.cpp:137] Memory required for data: 374785200
I0929 14:31:54.596271  2305 layer_factory.hpp:77] Creating layer Eltwise5
I0929 14:31:54.596274  2305 net.cpp:84] Creating Layer Eltwise5
I0929 14:31:54.596277  2305 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I0929 14:31:54.596289  2305 net.cpp:406] Eltwise5 <- Convolution11
I0929 14:31:54.596294  2305 net.cpp:380] Eltwise5 -> Eltwise5
I0929 14:31:54.596314  2305 net.cpp:122] Setting up Eltwise5
I0929 14:31:54.596318  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.596320  2305 net.cpp:137] Memory required for data: 381338800
I0929 14:31:54.596323  2305 layer_factory.hpp:77] Creating layer M2PELU11
I0929 14:31:54.596328  2305 net.cpp:84] Creating Layer M2PELU11
I0929 14:31:54.596331  2305 net.cpp:406] M2PELU11 <- Eltwise5
I0929 14:31:54.596335  2305 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I0929 14:31:54.596441  2305 net.cpp:122] Setting up M2PELU11
I0929 14:31:54.596446  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.596447  2305 net.cpp:137] Memory required for data: 387892400
I0929 14:31:54.596451  2305 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I0929 14:31:54.596456  2305 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I0929 14:31:54.596457  2305 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I0929 14:31:54.596462  2305 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I0929 14:31:54.596465  2305 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I0929 14:31:54.596493  2305 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I0929 14:31:54.596498  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.596500  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.596503  2305 net.cpp:137] Memory required for data: 400999600
I0929 14:31:54.596504  2305 layer_factory.hpp:77] Creating layer Convolution12
I0929 14:31:54.596510  2305 net.cpp:84] Creating Layer Convolution12
I0929 14:31:54.596513  2305 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I0929 14:31:54.596518  2305 net.cpp:380] Convolution12 -> Convolution12
I0929 14:31:54.597518  2305 net.cpp:122] Setting up Convolution12
I0929 14:31:54.597527  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.597530  2305 net.cpp:137] Memory required for data: 407553200
I0929 14:31:54.597534  2305 layer_factory.hpp:77] Creating layer BatchNorm12
I0929 14:31:54.597540  2305 net.cpp:84] Creating Layer BatchNorm12
I0929 14:31:54.597543  2305 net.cpp:406] BatchNorm12 <- Convolution12
I0929 14:31:54.597546  2305 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0929 14:31:54.597705  2305 net.cpp:122] Setting up BatchNorm12
I0929 14:31:54.597710  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.597712  2305 net.cpp:137] Memory required for data: 414106800
I0929 14:31:54.597718  2305 layer_factory.hpp:77] Creating layer Scale12
I0929 14:31:54.597721  2305 net.cpp:84] Creating Layer Scale12
I0929 14:31:54.597724  2305 net.cpp:406] Scale12 <- Convolution12
I0929 14:31:54.597729  2305 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0929 14:31:54.597759  2305 layer_factory.hpp:77] Creating layer Scale12
I0929 14:31:54.597849  2305 net.cpp:122] Setting up Scale12
I0929 14:31:54.597854  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.597856  2305 net.cpp:137] Memory required for data: 420660400
I0929 14:31:54.597860  2305 layer_factory.hpp:77] Creating layer M2PELU12
I0929 14:31:54.597867  2305 net.cpp:84] Creating Layer M2PELU12
I0929 14:31:54.597868  2305 net.cpp:406] M2PELU12 <- Convolution12
I0929 14:31:54.597872  2305 net.cpp:367] M2PELU12 -> Convolution12 (in-place)
I0929 14:31:54.597978  2305 net.cpp:122] Setting up M2PELU12
I0929 14:31:54.597983  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.597985  2305 net.cpp:137] Memory required for data: 427214000
I0929 14:31:54.597990  2305 layer_factory.hpp:77] Creating layer Convolution13
I0929 14:31:54.597995  2305 net.cpp:84] Creating Layer Convolution13
I0929 14:31:54.597998  2305 net.cpp:406] Convolution13 <- Convolution12
I0929 14:31:54.598003  2305 net.cpp:380] Convolution13 -> Convolution13
I0929 14:31:54.598999  2305 net.cpp:122] Setting up Convolution13
I0929 14:31:54.599009  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.599020  2305 net.cpp:137] Memory required for data: 433767600
I0929 14:31:54.599025  2305 layer_factory.hpp:77] Creating layer BatchNorm13
I0929 14:31:54.599028  2305 net.cpp:84] Creating Layer BatchNorm13
I0929 14:31:54.599031  2305 net.cpp:406] BatchNorm13 <- Convolution13
I0929 14:31:54.599037  2305 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0929 14:31:54.599200  2305 net.cpp:122] Setting up BatchNorm13
I0929 14:31:54.599205  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.599206  2305 net.cpp:137] Memory required for data: 440321200
I0929 14:31:54.599211  2305 layer_factory.hpp:77] Creating layer Scale13
I0929 14:31:54.599215  2305 net.cpp:84] Creating Layer Scale13
I0929 14:31:54.599218  2305 net.cpp:406] Scale13 <- Convolution13
I0929 14:31:54.599221  2305 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0929 14:31:54.599253  2305 layer_factory.hpp:77] Creating layer Scale13
I0929 14:31:54.599344  2305 net.cpp:122] Setting up Scale13
I0929 14:31:54.599349  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.599350  2305 net.cpp:137] Memory required for data: 446874800
I0929 14:31:54.599354  2305 layer_factory.hpp:77] Creating layer Eltwise6
I0929 14:31:54.599364  2305 net.cpp:84] Creating Layer Eltwise6
I0929 14:31:54.599366  2305 net.cpp:406] Eltwise6 <- Eltwise5_M2PELU11_0_split_1
I0929 14:31:54.599370  2305 net.cpp:406] Eltwise6 <- Convolution13
I0929 14:31:54.599372  2305 net.cpp:380] Eltwise6 -> Eltwise6
I0929 14:31:54.599392  2305 net.cpp:122] Setting up Eltwise6
I0929 14:31:54.599396  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.599400  2305 net.cpp:137] Memory required for data: 453428400
I0929 14:31:54.599401  2305 layer_factory.hpp:77] Creating layer M2PELU13
I0929 14:31:54.599406  2305 net.cpp:84] Creating Layer M2PELU13
I0929 14:31:54.599409  2305 net.cpp:406] M2PELU13 <- Eltwise6
I0929 14:31:54.599413  2305 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I0929 14:31:54.599521  2305 net.cpp:122] Setting up M2PELU13
I0929 14:31:54.599525  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.599529  2305 net.cpp:137] Memory required for data: 459982000
I0929 14:31:54.599531  2305 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I0929 14:31:54.599535  2305 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I0929 14:31:54.599539  2305 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I0929 14:31:54.599542  2305 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I0929 14:31:54.599546  2305 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I0929 14:31:54.599575  2305 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I0929 14:31:54.620353  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.620363  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.620367  2305 net.cpp:137] Memory required for data: 473089200
I0929 14:31:54.620369  2305 layer_factory.hpp:77] Creating layer Convolution14
I0929 14:31:54.620381  2305 net.cpp:84] Creating Layer Convolution14
I0929 14:31:54.620385  2305 net.cpp:406] Convolution14 <- Eltwise6_M2PELU13_0_split_0
I0929 14:31:54.620391  2305 net.cpp:380] Convolution14 -> Convolution14
I0929 14:31:54.621570  2305 net.cpp:122] Setting up Convolution14
I0929 14:31:54.621580  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.621583  2305 net.cpp:137] Memory required for data: 479642800
I0929 14:31:54.621588  2305 layer_factory.hpp:77] Creating layer BatchNorm14
I0929 14:31:54.621595  2305 net.cpp:84] Creating Layer BatchNorm14
I0929 14:31:54.621598  2305 net.cpp:406] BatchNorm14 <- Convolution14
I0929 14:31:54.621603  2305 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0929 14:31:54.621776  2305 net.cpp:122] Setting up BatchNorm14
I0929 14:31:54.621783  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.621784  2305 net.cpp:137] Memory required for data: 486196400
I0929 14:31:54.621789  2305 layer_factory.hpp:77] Creating layer Scale14
I0929 14:31:54.621795  2305 net.cpp:84] Creating Layer Scale14
I0929 14:31:54.621807  2305 net.cpp:406] Scale14 <- Convolution14
I0929 14:31:54.621812  2305 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0929 14:31:54.621850  2305 layer_factory.hpp:77] Creating layer Scale14
I0929 14:31:54.621953  2305 net.cpp:122] Setting up Scale14
I0929 14:31:54.621958  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.621959  2305 net.cpp:137] Memory required for data: 492750000
I0929 14:31:54.621963  2305 layer_factory.hpp:77] Creating layer M2PELU14
I0929 14:31:54.621969  2305 net.cpp:84] Creating Layer M2PELU14
I0929 14:31:54.621971  2305 net.cpp:406] M2PELU14 <- Convolution14
I0929 14:31:54.621976  2305 net.cpp:367] M2PELU14 -> Convolution14 (in-place)
I0929 14:31:54.622095  2305 net.cpp:122] Setting up M2PELU14
I0929 14:31:54.622104  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.622108  2305 net.cpp:137] Memory required for data: 499303600
I0929 14:31:54.622115  2305 layer_factory.hpp:77] Creating layer Convolution15
I0929 14:31:54.622128  2305 net.cpp:84] Creating Layer Convolution15
I0929 14:31:54.622133  2305 net.cpp:406] Convolution15 <- Convolution14
I0929 14:31:54.622139  2305 net.cpp:380] Convolution15 -> Convolution15
I0929 14:31:54.623548  2305 net.cpp:122] Setting up Convolution15
I0929 14:31:54.623558  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.623560  2305 net.cpp:137] Memory required for data: 505857200
I0929 14:31:54.623565  2305 layer_factory.hpp:77] Creating layer BatchNorm15
I0929 14:31:54.623570  2305 net.cpp:84] Creating Layer BatchNorm15
I0929 14:31:54.623574  2305 net.cpp:406] BatchNorm15 <- Convolution15
I0929 14:31:54.623579  2305 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0929 14:31:54.623739  2305 net.cpp:122] Setting up BatchNorm15
I0929 14:31:54.623744  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.623746  2305 net.cpp:137] Memory required for data: 512410800
I0929 14:31:54.623764  2305 layer_factory.hpp:77] Creating layer Scale15
I0929 14:31:54.623769  2305 net.cpp:84] Creating Layer Scale15
I0929 14:31:54.623771  2305 net.cpp:406] Scale15 <- Convolution15
I0929 14:31:54.623775  2305 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0929 14:31:54.623808  2305 layer_factory.hpp:77] Creating layer Scale15
I0929 14:31:54.623898  2305 net.cpp:122] Setting up Scale15
I0929 14:31:54.623903  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.623904  2305 net.cpp:137] Memory required for data: 518964400
I0929 14:31:54.623908  2305 layer_factory.hpp:77] Creating layer Eltwise7
I0929 14:31:54.623914  2305 net.cpp:84] Creating Layer Eltwise7
I0929 14:31:54.623915  2305 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I0929 14:31:54.623919  2305 net.cpp:406] Eltwise7 <- Convolution15
I0929 14:31:54.623922  2305 net.cpp:380] Eltwise7 -> Eltwise7
I0929 14:31:54.623941  2305 net.cpp:122] Setting up Eltwise7
I0929 14:31:54.623945  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.623947  2305 net.cpp:137] Memory required for data: 525518000
I0929 14:31:54.623950  2305 layer_factory.hpp:77] Creating layer M2PELU15
I0929 14:31:54.623955  2305 net.cpp:84] Creating Layer M2PELU15
I0929 14:31:54.623957  2305 net.cpp:406] M2PELU15 <- Eltwise7
I0929 14:31:54.623960  2305 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I0929 14:31:54.624065  2305 net.cpp:122] Setting up M2PELU15
I0929 14:31:54.624071  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.624074  2305 net.cpp:137] Memory required for data: 532071600
I0929 14:31:54.624078  2305 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I0929 14:31:54.624083  2305 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I0929 14:31:54.624084  2305 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I0929 14:31:54.624089  2305 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I0929 14:31:54.624092  2305 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I0929 14:31:54.624120  2305 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I0929 14:31:54.624132  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.624135  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.624138  2305 net.cpp:137] Memory required for data: 545178800
I0929 14:31:54.624140  2305 layer_factory.hpp:77] Creating layer Convolution16
I0929 14:31:54.624147  2305 net.cpp:84] Creating Layer Convolution16
I0929 14:31:54.624150  2305 net.cpp:406] Convolution16 <- Eltwise7_M2PELU15_0_split_0
I0929 14:31:54.624155  2305 net.cpp:380] Convolution16 -> Convolution16
I0929 14:31:54.624812  2305 net.cpp:122] Setting up Convolution16
I0929 14:31:54.624820  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.624822  2305 net.cpp:137] Memory required for data: 551732400
I0929 14:31:54.624827  2305 layer_factory.hpp:77] Creating layer BatchNorm16
I0929 14:31:54.624832  2305 net.cpp:84] Creating Layer BatchNorm16
I0929 14:31:54.624836  2305 net.cpp:406] BatchNorm16 <- Convolution16
I0929 14:31:54.624840  2305 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0929 14:31:54.625001  2305 net.cpp:122] Setting up BatchNorm16
I0929 14:31:54.625006  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.625008  2305 net.cpp:137] Memory required for data: 558286000
I0929 14:31:54.625013  2305 layer_factory.hpp:77] Creating layer Scale16
I0929 14:31:54.625018  2305 net.cpp:84] Creating Layer Scale16
I0929 14:31:54.625021  2305 net.cpp:406] Scale16 <- Convolution16
I0929 14:31:54.625025  2305 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0929 14:31:54.625057  2305 layer_factory.hpp:77] Creating layer Scale16
I0929 14:31:54.625149  2305 net.cpp:122] Setting up Scale16
I0929 14:31:54.625154  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.625155  2305 net.cpp:137] Memory required for data: 564839600
I0929 14:31:54.625159  2305 layer_factory.hpp:77] Creating layer M2PELU16
I0929 14:31:54.625164  2305 net.cpp:84] Creating Layer M2PELU16
I0929 14:31:54.625167  2305 net.cpp:406] M2PELU16 <- Convolution16
I0929 14:31:54.625170  2305 net.cpp:367] M2PELU16 -> Convolution16 (in-place)
I0929 14:31:54.625277  2305 net.cpp:122] Setting up M2PELU16
I0929 14:31:54.625282  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.625283  2305 net.cpp:137] Memory required for data: 571393200
I0929 14:31:54.625288  2305 layer_factory.hpp:77] Creating layer Convolution17
I0929 14:31:54.625294  2305 net.cpp:84] Creating Layer Convolution17
I0929 14:31:54.625298  2305 net.cpp:406] Convolution17 <- Convolution16
I0929 14:31:54.625300  2305 net.cpp:380] Convolution17 -> Convolution17
I0929 14:31:54.626308  2305 net.cpp:122] Setting up Convolution17
I0929 14:31:54.626318  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.626320  2305 net.cpp:137] Memory required for data: 577946800
I0929 14:31:54.626325  2305 layer_factory.hpp:77] Creating layer BatchNorm17
I0929 14:31:54.626330  2305 net.cpp:84] Creating Layer BatchNorm17
I0929 14:31:54.626333  2305 net.cpp:406] BatchNorm17 <- Convolution17
I0929 14:31:54.626338  2305 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0929 14:31:54.626498  2305 net.cpp:122] Setting up BatchNorm17
I0929 14:31:54.626503  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.626505  2305 net.cpp:137] Memory required for data: 584500400
I0929 14:31:54.626510  2305 layer_factory.hpp:77] Creating layer Scale17
I0929 14:31:54.626515  2305 net.cpp:84] Creating Layer Scale17
I0929 14:31:54.626518  2305 net.cpp:406] Scale17 <- Convolution17
I0929 14:31:54.626528  2305 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0929 14:31:54.626562  2305 layer_factory.hpp:77] Creating layer Scale17
I0929 14:31:54.626654  2305 net.cpp:122] Setting up Scale17
I0929 14:31:54.626659  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.626662  2305 net.cpp:137] Memory required for data: 591054000
I0929 14:31:54.626665  2305 layer_factory.hpp:77] Creating layer Eltwise8
I0929 14:31:54.626669  2305 net.cpp:84] Creating Layer Eltwise8
I0929 14:31:54.626672  2305 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I0929 14:31:54.626685  2305 net.cpp:406] Eltwise8 <- Convolution17
I0929 14:31:54.626691  2305 net.cpp:380] Eltwise8 -> Eltwise8
I0929 14:31:54.626713  2305 net.cpp:122] Setting up Eltwise8
I0929 14:31:54.626718  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.626719  2305 net.cpp:137] Memory required for data: 597607600
I0929 14:31:54.626722  2305 layer_factory.hpp:77] Creating layer M2PELU17
I0929 14:31:54.626726  2305 net.cpp:84] Creating Layer M2PELU17
I0929 14:31:54.626729  2305 net.cpp:406] M2PELU17 <- Eltwise8
I0929 14:31:54.626734  2305 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I0929 14:31:54.626840  2305 net.cpp:122] Setting up M2PELU17
I0929 14:31:54.626845  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.626847  2305 net.cpp:137] Memory required for data: 604161200
I0929 14:31:54.626852  2305 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I0929 14:31:54.626855  2305 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I0929 14:31:54.626857  2305 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I0929 14:31:54.626862  2305 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I0929 14:31:54.626865  2305 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I0929 14:31:54.626894  2305 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I0929 14:31:54.626899  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.626901  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.626904  2305 net.cpp:137] Memory required for data: 617268400
I0929 14:31:54.626906  2305 layer_factory.hpp:77] Creating layer Convolution18
I0929 14:31:54.626912  2305 net.cpp:84] Creating Layer Convolution18
I0929 14:31:54.626915  2305 net.cpp:406] Convolution18 <- Eltwise8_M2PELU17_0_split_0
I0929 14:31:54.626919  2305 net.cpp:380] Convolution18 -> Convolution18
I0929 14:31:54.627962  2305 net.cpp:122] Setting up Convolution18
I0929 14:31:54.627971  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.627974  2305 net.cpp:137] Memory required for data: 623822000
I0929 14:31:54.627979  2305 layer_factory.hpp:77] Creating layer BatchNorm18
I0929 14:31:54.627985  2305 net.cpp:84] Creating Layer BatchNorm18
I0929 14:31:54.627987  2305 net.cpp:406] BatchNorm18 <- Convolution18
I0929 14:31:54.627991  2305 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0929 14:31:54.628149  2305 net.cpp:122] Setting up BatchNorm18
I0929 14:31:54.628154  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.628155  2305 net.cpp:137] Memory required for data: 630375600
I0929 14:31:54.628160  2305 layer_factory.hpp:77] Creating layer Scale18
I0929 14:31:54.628165  2305 net.cpp:84] Creating Layer Scale18
I0929 14:31:54.628167  2305 net.cpp:406] Scale18 <- Convolution18
I0929 14:31:54.628170  2305 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0929 14:31:54.628202  2305 layer_factory.hpp:77] Creating layer Scale18
I0929 14:31:54.628293  2305 net.cpp:122] Setting up Scale18
I0929 14:31:54.628298  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.628300  2305 net.cpp:137] Memory required for data: 636929200
I0929 14:31:54.628304  2305 layer_factory.hpp:77] Creating layer M2PELU18
I0929 14:31:54.628309  2305 net.cpp:84] Creating Layer M2PELU18
I0929 14:31:54.628311  2305 net.cpp:406] M2PELU18 <- Convolution18
I0929 14:31:54.628315  2305 net.cpp:367] M2PELU18 -> Convolution18 (in-place)
I0929 14:31:54.628424  2305 net.cpp:122] Setting up M2PELU18
I0929 14:31:54.628429  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.628432  2305 net.cpp:137] Memory required for data: 643482800
I0929 14:31:54.628435  2305 layer_factory.hpp:77] Creating layer Convolution19
I0929 14:31:54.628443  2305 net.cpp:84] Creating Layer Convolution19
I0929 14:31:54.628444  2305 net.cpp:406] Convolution19 <- Convolution18
I0929 14:31:54.628448  2305 net.cpp:380] Convolution19 -> Convolution19
I0929 14:31:54.629438  2305 net.cpp:122] Setting up Convolution19
I0929 14:31:54.629447  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.629457  2305 net.cpp:137] Memory required for data: 650036400
I0929 14:31:54.629462  2305 layer_factory.hpp:77] Creating layer BatchNorm19
I0929 14:31:54.629468  2305 net.cpp:84] Creating Layer BatchNorm19
I0929 14:31:54.629472  2305 net.cpp:406] BatchNorm19 <- Convolution19
I0929 14:31:54.629477  2305 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0929 14:31:54.629639  2305 net.cpp:122] Setting up BatchNorm19
I0929 14:31:54.629644  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.629647  2305 net.cpp:137] Memory required for data: 656590000
I0929 14:31:54.629652  2305 layer_factory.hpp:77] Creating layer Scale19
I0929 14:31:54.629655  2305 net.cpp:84] Creating Layer Scale19
I0929 14:31:54.629657  2305 net.cpp:406] Scale19 <- Convolution19
I0929 14:31:54.629662  2305 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0929 14:31:54.629693  2305 layer_factory.hpp:77] Creating layer Scale19
I0929 14:31:54.629787  2305 net.cpp:122] Setting up Scale19
I0929 14:31:54.629791  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.629793  2305 net.cpp:137] Memory required for data: 663143600
I0929 14:31:54.629798  2305 layer_factory.hpp:77] Creating layer Eltwise9
I0929 14:31:54.629802  2305 net.cpp:84] Creating Layer Eltwise9
I0929 14:31:54.629804  2305 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I0929 14:31:54.629807  2305 net.cpp:406] Eltwise9 <- Convolution19
I0929 14:31:54.629812  2305 net.cpp:380] Eltwise9 -> Eltwise9
I0929 14:31:54.629830  2305 net.cpp:122] Setting up Eltwise9
I0929 14:31:54.629834  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.629837  2305 net.cpp:137] Memory required for data: 669697200
I0929 14:31:54.629838  2305 layer_factory.hpp:77] Creating layer M2PELU19
I0929 14:31:54.629844  2305 net.cpp:84] Creating Layer M2PELU19
I0929 14:31:54.629847  2305 net.cpp:406] M2PELU19 <- Eltwise9
I0929 14:31:54.629850  2305 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I0929 14:31:54.629958  2305 net.cpp:122] Setting up M2PELU19
I0929 14:31:54.629963  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.629966  2305 net.cpp:137] Memory required for data: 676250800
I0929 14:31:54.629969  2305 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I0929 14:31:54.629973  2305 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I0929 14:31:54.629976  2305 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I0929 14:31:54.629981  2305 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I0929 14:31:54.651298  2305 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I0929 14:31:54.651348  2305 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I0929 14:31:54.651355  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.651357  2305 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0929 14:31:54.651360  2305 net.cpp:137] Memory required for data: 689358000
I0929 14:31:54.651362  2305 layer_factory.hpp:77] Creating layer Convolution20
I0929 14:31:54.651371  2305 net.cpp:84] Creating Layer Convolution20
I0929 14:31:54.651374  2305 net.cpp:406] Convolution20 <- Eltwise9_M2PELU19_0_split_0
I0929 14:31:54.651378  2305 net.cpp:380] Convolution20 -> Convolution20
I0929 14:31:54.652446  2305 net.cpp:122] Setting up Convolution20
I0929 14:31:54.652454  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.652457  2305 net.cpp:137] Memory required for data: 692634800
I0929 14:31:54.652462  2305 layer_factory.hpp:77] Creating layer BatchNorm20
I0929 14:31:54.652468  2305 net.cpp:84] Creating Layer BatchNorm20
I0929 14:31:54.652470  2305 net.cpp:406] BatchNorm20 <- Convolution20
I0929 14:31:54.652474  2305 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0929 14:31:54.652634  2305 net.cpp:122] Setting up BatchNorm20
I0929 14:31:54.652639  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.652642  2305 net.cpp:137] Memory required for data: 695911600
I0929 14:31:54.652647  2305 layer_factory.hpp:77] Creating layer Scale20
I0929 14:31:54.652659  2305 net.cpp:84] Creating Layer Scale20
I0929 14:31:54.652663  2305 net.cpp:406] Scale20 <- Convolution20
I0929 14:31:54.652667  2305 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0929 14:31:54.652703  2305 layer_factory.hpp:77] Creating layer Scale20
I0929 14:31:54.652794  2305 net.cpp:122] Setting up Scale20
I0929 14:31:54.652798  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.652801  2305 net.cpp:137] Memory required for data: 699188400
I0929 14:31:54.652806  2305 layer_factory.hpp:77] Creating layer Convolution21
I0929 14:31:54.652812  2305 net.cpp:84] Creating Layer Convolution21
I0929 14:31:54.652815  2305 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_1
I0929 14:31:54.652819  2305 net.cpp:380] Convolution21 -> Convolution21
I0929 14:31:54.653919  2305 net.cpp:122] Setting up Convolution21
I0929 14:31:54.653928  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.653931  2305 net.cpp:137] Memory required for data: 702465200
I0929 14:31:54.653936  2305 layer_factory.hpp:77] Creating layer BatchNorm21
I0929 14:31:54.653941  2305 net.cpp:84] Creating Layer BatchNorm21
I0929 14:31:54.653944  2305 net.cpp:406] BatchNorm21 <- Convolution21
I0929 14:31:54.653947  2305 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0929 14:31:54.654124  2305 net.cpp:122] Setting up BatchNorm21
I0929 14:31:54.654129  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.654131  2305 net.cpp:137] Memory required for data: 705742000
I0929 14:31:54.654136  2305 layer_factory.hpp:77] Creating layer Scale21
I0929 14:31:54.654140  2305 net.cpp:84] Creating Layer Scale21
I0929 14:31:54.654142  2305 net.cpp:406] Scale21 <- Convolution21
I0929 14:31:54.654145  2305 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0929 14:31:54.654188  2305 layer_factory.hpp:77] Creating layer Scale21
I0929 14:31:54.654309  2305 net.cpp:122] Setting up Scale21
I0929 14:31:54.654315  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.654317  2305 net.cpp:137] Memory required for data: 709018800
I0929 14:31:54.654321  2305 layer_factory.hpp:77] Creating layer M2PELU20
I0929 14:31:54.654326  2305 net.cpp:84] Creating Layer M2PELU20
I0929 14:31:54.654328  2305 net.cpp:406] M2PELU20 <- Convolution21
I0929 14:31:54.654332  2305 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I0929 14:31:54.654433  2305 net.cpp:122] Setting up M2PELU20
I0929 14:31:54.654438  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.654440  2305 net.cpp:137] Memory required for data: 712295600
I0929 14:31:54.654443  2305 layer_factory.hpp:77] Creating layer Convolution22
I0929 14:31:54.654450  2305 net.cpp:84] Creating Layer Convolution22
I0929 14:31:54.654453  2305 net.cpp:406] Convolution22 <- Convolution21
I0929 14:31:54.654458  2305 net.cpp:380] Convolution22 -> Convolution22
I0929 14:31:54.655655  2305 net.cpp:122] Setting up Convolution22
I0929 14:31:54.655664  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.655668  2305 net.cpp:137] Memory required for data: 715572400
I0929 14:31:54.655671  2305 layer_factory.hpp:77] Creating layer BatchNorm22
I0929 14:31:54.655678  2305 net.cpp:84] Creating Layer BatchNorm22
I0929 14:31:54.655679  2305 net.cpp:406] BatchNorm22 <- Convolution22
I0929 14:31:54.655683  2305 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0929 14:31:54.655840  2305 net.cpp:122] Setting up BatchNorm22
I0929 14:31:54.655845  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.655848  2305 net.cpp:137] Memory required for data: 718849200
I0929 14:31:54.655853  2305 layer_factory.hpp:77] Creating layer Scale22
I0929 14:31:54.655856  2305 net.cpp:84] Creating Layer Scale22
I0929 14:31:54.655858  2305 net.cpp:406] Scale22 <- Convolution22
I0929 14:31:54.655861  2305 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0929 14:31:54.655894  2305 layer_factory.hpp:77] Creating layer Scale22
I0929 14:31:54.655984  2305 net.cpp:122] Setting up Scale22
I0929 14:31:54.655988  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.655998  2305 net.cpp:137] Memory required for data: 722126000
I0929 14:31:54.656002  2305 layer_factory.hpp:77] Creating layer Eltwise10
I0929 14:31:54.656008  2305 net.cpp:84] Creating Layer Eltwise10
I0929 14:31:54.656010  2305 net.cpp:406] Eltwise10 <- Convolution20
I0929 14:31:54.656014  2305 net.cpp:406] Eltwise10 <- Convolution22
I0929 14:31:54.656018  2305 net.cpp:380] Eltwise10 -> Eltwise10
I0929 14:31:54.656034  2305 net.cpp:122] Setting up Eltwise10
I0929 14:31:54.656038  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.656040  2305 net.cpp:137] Memory required for data: 725402800
I0929 14:31:54.656042  2305 layer_factory.hpp:77] Creating layer M2PELU21
I0929 14:31:54.656049  2305 net.cpp:84] Creating Layer M2PELU21
I0929 14:31:54.656050  2305 net.cpp:406] M2PELU21 <- Eltwise10
I0929 14:31:54.656054  2305 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I0929 14:31:54.656157  2305 net.cpp:122] Setting up M2PELU21
I0929 14:31:54.656162  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.656163  2305 net.cpp:137] Memory required for data: 728679600
I0929 14:31:54.656167  2305 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I0929 14:31:54.656172  2305 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I0929 14:31:54.656173  2305 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I0929 14:31:54.656177  2305 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I0929 14:31:54.656182  2305 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I0929 14:31:54.656210  2305 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I0929 14:31:54.656214  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.656217  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.656219  2305 net.cpp:137] Memory required for data: 735233200
I0929 14:31:54.656221  2305 layer_factory.hpp:77] Creating layer Convolution23
I0929 14:31:54.656229  2305 net.cpp:84] Creating Layer Convolution23
I0929 14:31:54.656231  2305 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I0929 14:31:54.656235  2305 net.cpp:380] Convolution23 -> Convolution23
I0929 14:31:54.657366  2305 net.cpp:122] Setting up Convolution23
I0929 14:31:54.657374  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.657377  2305 net.cpp:137] Memory required for data: 738510000
I0929 14:31:54.657382  2305 layer_factory.hpp:77] Creating layer BatchNorm23
I0929 14:31:54.657387  2305 net.cpp:84] Creating Layer BatchNorm23
I0929 14:31:54.657390  2305 net.cpp:406] BatchNorm23 <- Convolution23
I0929 14:31:54.657393  2305 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0929 14:31:54.657552  2305 net.cpp:122] Setting up BatchNorm23
I0929 14:31:54.657557  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.657559  2305 net.cpp:137] Memory required for data: 741786800
I0929 14:31:54.657563  2305 layer_factory.hpp:77] Creating layer Scale23
I0929 14:31:54.657568  2305 net.cpp:84] Creating Layer Scale23
I0929 14:31:54.657570  2305 net.cpp:406] Scale23 <- Convolution23
I0929 14:31:54.657573  2305 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0929 14:31:54.657605  2305 layer_factory.hpp:77] Creating layer Scale23
I0929 14:31:54.657696  2305 net.cpp:122] Setting up Scale23
I0929 14:31:54.657702  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.657704  2305 net.cpp:137] Memory required for data: 745063600
I0929 14:31:54.657708  2305 layer_factory.hpp:77] Creating layer M2PELU22
I0929 14:31:54.657712  2305 net.cpp:84] Creating Layer M2PELU22
I0929 14:31:54.657716  2305 net.cpp:406] M2PELU22 <- Convolution23
I0929 14:31:54.657719  2305 net.cpp:367] M2PELU22 -> Convolution23 (in-place)
I0929 14:31:54.657819  2305 net.cpp:122] Setting up M2PELU22
I0929 14:31:54.657822  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.657825  2305 net.cpp:137] Memory required for data: 748340400
I0929 14:31:54.657829  2305 layer_factory.hpp:77] Creating layer Convolution24
I0929 14:31:54.657835  2305 net.cpp:84] Creating Layer Convolution24
I0929 14:31:54.657845  2305 net.cpp:406] Convolution24 <- Convolution23
I0929 14:31:54.657850  2305 net.cpp:380] Convolution24 -> Convolution24
I0929 14:31:54.659016  2305 net.cpp:122] Setting up Convolution24
I0929 14:31:54.659025  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.659029  2305 net.cpp:137] Memory required for data: 751617200
I0929 14:31:54.659034  2305 layer_factory.hpp:77] Creating layer BatchNorm24
I0929 14:31:54.659037  2305 net.cpp:84] Creating Layer BatchNorm24
I0929 14:31:54.659040  2305 net.cpp:406] BatchNorm24 <- Convolution24
I0929 14:31:54.659045  2305 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0929 14:31:54.659698  2305 net.cpp:122] Setting up BatchNorm24
I0929 14:31:54.659706  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.659709  2305 net.cpp:137] Memory required for data: 754894000
I0929 14:31:54.659715  2305 layer_factory.hpp:77] Creating layer Scale24
I0929 14:31:54.659720  2305 net.cpp:84] Creating Layer Scale24
I0929 14:31:54.659723  2305 net.cpp:406] Scale24 <- Convolution24
I0929 14:31:54.659728  2305 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0929 14:31:54.659756  2305 layer_factory.hpp:77] Creating layer Scale24
I0929 14:31:54.659829  2305 net.cpp:122] Setting up Scale24
I0929 14:31:54.659834  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.659837  2305 net.cpp:137] Memory required for data: 758170800
I0929 14:31:54.659840  2305 layer_factory.hpp:77] Creating layer Eltwise11
I0929 14:31:54.659844  2305 net.cpp:84] Creating Layer Eltwise11
I0929 14:31:54.659847  2305 net.cpp:406] Eltwise11 <- Eltwise10_M2PELU21_0_split_1
I0929 14:31:54.659850  2305 net.cpp:406] Eltwise11 <- Convolution24
I0929 14:31:54.659854  2305 net.cpp:380] Eltwise11 -> Eltwise11
I0929 14:31:54.659865  2305 net.cpp:122] Setting up Eltwise11
I0929 14:31:54.659869  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.659871  2305 net.cpp:137] Memory required for data: 761447600
I0929 14:31:54.659873  2305 layer_factory.hpp:77] Creating layer M2PELU23
I0929 14:31:54.659878  2305 net.cpp:84] Creating Layer M2PELU23
I0929 14:31:54.659881  2305 net.cpp:406] M2PELU23 <- Eltwise11
I0929 14:31:54.659886  2305 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I0929 14:31:54.659970  2305 net.cpp:122] Setting up M2PELU23
I0929 14:31:54.659973  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.659976  2305 net.cpp:137] Memory required for data: 764724400
I0929 14:31:54.659979  2305 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I0929 14:31:54.659983  2305 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I0929 14:31:54.659986  2305 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I0929 14:31:54.659991  2305 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I0929 14:31:54.659994  2305 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I0929 14:31:54.660017  2305 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I0929 14:31:54.660022  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.660024  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.660027  2305 net.cpp:137] Memory required for data: 771278000
I0929 14:31:54.660028  2305 layer_factory.hpp:77] Creating layer Convolution25
I0929 14:31:54.660034  2305 net.cpp:84] Creating Layer Convolution25
I0929 14:31:54.660037  2305 net.cpp:406] Convolution25 <- Eltwise11_M2PELU23_0_split_0
I0929 14:31:54.660042  2305 net.cpp:380] Convolution25 -> Convolution25
I0929 14:31:54.661185  2305 net.cpp:122] Setting up Convolution25
I0929 14:31:54.661195  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.661197  2305 net.cpp:137] Memory required for data: 774554800
I0929 14:31:54.661201  2305 layer_factory.hpp:77] Creating layer BatchNorm25
I0929 14:31:54.661207  2305 net.cpp:84] Creating Layer BatchNorm25
I0929 14:31:54.661211  2305 net.cpp:406] BatchNorm25 <- Convolution25
I0929 14:31:54.661214  2305 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0929 14:31:54.661350  2305 net.cpp:122] Setting up BatchNorm25
I0929 14:31:54.661356  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.661358  2305 net.cpp:137] Memory required for data: 777831600
I0929 14:31:54.661363  2305 layer_factory.hpp:77] Creating layer Scale25
I0929 14:31:54.661368  2305 net.cpp:84] Creating Layer Scale25
I0929 14:31:54.661370  2305 net.cpp:406] Scale25 <- Convolution25
I0929 14:31:54.661375  2305 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0929 14:31:54.661401  2305 layer_factory.hpp:77] Creating layer Scale25
I0929 14:31:54.661474  2305 net.cpp:122] Setting up Scale25
I0929 14:31:54.661478  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.661480  2305 net.cpp:137] Memory required for data: 781108400
I0929 14:31:54.661484  2305 layer_factory.hpp:77] Creating layer M2PELU24
I0929 14:31:54.661489  2305 net.cpp:84] Creating Layer M2PELU24
I0929 14:31:54.661492  2305 net.cpp:406] M2PELU24 <- Convolution25
I0929 14:31:54.661496  2305 net.cpp:367] M2PELU24 -> Convolution25 (in-place)
I0929 14:31:54.661577  2305 net.cpp:122] Setting up M2PELU24
I0929 14:31:54.661582  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.661584  2305 net.cpp:137] Memory required for data: 784385200
I0929 14:31:54.661587  2305 layer_factory.hpp:77] Creating layer Convolution26
I0929 14:31:54.661597  2305 net.cpp:84] Creating Layer Convolution26
I0929 14:31:54.661598  2305 net.cpp:406] Convolution26 <- Convolution25
I0929 14:31:54.661602  2305 net.cpp:380] Convolution26 -> Convolution26
I0929 14:31:54.662367  2305 net.cpp:122] Setting up Convolution26
I0929 14:31:54.662375  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.662379  2305 net.cpp:137] Memory required for data: 787662000
I0929 14:31:54.662382  2305 layer_factory.hpp:77] Creating layer BatchNorm26
I0929 14:31:54.662389  2305 net.cpp:84] Creating Layer BatchNorm26
I0929 14:31:54.662391  2305 net.cpp:406] BatchNorm26 <- Convolution26
I0929 14:31:54.662395  2305 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0929 14:31:54.662525  2305 net.cpp:122] Setting up BatchNorm26
I0929 14:31:54.662531  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.662533  2305 net.cpp:137] Memory required for data: 790938800
I0929 14:31:54.662539  2305 layer_factory.hpp:77] Creating layer Scale26
I0929 14:31:54.662542  2305 net.cpp:84] Creating Layer Scale26
I0929 14:31:54.681409  2305 net.cpp:406] Scale26 <- Convolution26
I0929 14:31:54.681421  2305 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0929 14:31:54.681462  2305 layer_factory.hpp:77] Creating layer Scale26
I0929 14:31:54.681547  2305 net.cpp:122] Setting up Scale26
I0929 14:31:54.681553  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.681555  2305 net.cpp:137] Memory required for data: 794215600
I0929 14:31:54.681560  2305 layer_factory.hpp:77] Creating layer Eltwise12
I0929 14:31:54.681565  2305 net.cpp:84] Creating Layer Eltwise12
I0929 14:31:54.681567  2305 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I0929 14:31:54.681571  2305 net.cpp:406] Eltwise12 <- Convolution26
I0929 14:31:54.681574  2305 net.cpp:380] Eltwise12 -> Eltwise12
I0929 14:31:54.681587  2305 net.cpp:122] Setting up Eltwise12
I0929 14:31:54.681592  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.681594  2305 net.cpp:137] Memory required for data: 797492400
I0929 14:31:54.681597  2305 layer_factory.hpp:77] Creating layer M2PELU25
I0929 14:31:54.681613  2305 net.cpp:84] Creating Layer M2PELU25
I0929 14:31:54.681617  2305 net.cpp:406] M2PELU25 <- Eltwise12
I0929 14:31:54.681620  2305 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I0929 14:31:54.681713  2305 net.cpp:122] Setting up M2PELU25
I0929 14:31:54.681718  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.681721  2305 net.cpp:137] Memory required for data: 800769200
I0929 14:31:54.681725  2305 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I0929 14:31:54.681730  2305 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I0929 14:31:54.681741  2305 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I0929 14:31:54.681746  2305 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I0929 14:31:54.681751  2305 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I0929 14:31:54.681778  2305 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I0929 14:31:54.681783  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.681787  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.681788  2305 net.cpp:137] Memory required for data: 807322800
I0929 14:31:54.681792  2305 layer_factory.hpp:77] Creating layer Convolution27
I0929 14:31:54.681798  2305 net.cpp:84] Creating Layer Convolution27
I0929 14:31:54.681802  2305 net.cpp:406] Convolution27 <- Eltwise12_M2PELU25_0_split_0
I0929 14:31:54.681805  2305 net.cpp:380] Convolution27 -> Convolution27
I0929 14:31:54.683449  2305 net.cpp:122] Setting up Convolution27
I0929 14:31:54.683459  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.683461  2305 net.cpp:137] Memory required for data: 810599600
I0929 14:31:54.683466  2305 layer_factory.hpp:77] Creating layer BatchNorm27
I0929 14:31:54.683472  2305 net.cpp:84] Creating Layer BatchNorm27
I0929 14:31:54.683475  2305 net.cpp:406] BatchNorm27 <- Convolution27
I0929 14:31:54.683480  2305 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0929 14:31:54.683615  2305 net.cpp:122] Setting up BatchNorm27
I0929 14:31:54.683619  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.683622  2305 net.cpp:137] Memory required for data: 813876400
I0929 14:31:54.683626  2305 layer_factory.hpp:77] Creating layer Scale27
I0929 14:31:54.683631  2305 net.cpp:84] Creating Layer Scale27
I0929 14:31:54.683634  2305 net.cpp:406] Scale27 <- Convolution27
I0929 14:31:54.683637  2305 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0929 14:31:54.683665  2305 layer_factory.hpp:77] Creating layer Scale27
I0929 14:31:54.683737  2305 net.cpp:122] Setting up Scale27
I0929 14:31:54.683742  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.683743  2305 net.cpp:137] Memory required for data: 817153200
I0929 14:31:54.683748  2305 layer_factory.hpp:77] Creating layer M2PELU26
I0929 14:31:54.683753  2305 net.cpp:84] Creating Layer M2PELU26
I0929 14:31:54.683755  2305 net.cpp:406] M2PELU26 <- Convolution27
I0929 14:31:54.683761  2305 net.cpp:367] M2PELU26 -> Convolution27 (in-place)
I0929 14:31:54.683841  2305 net.cpp:122] Setting up M2PELU26
I0929 14:31:54.683846  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.683848  2305 net.cpp:137] Memory required for data: 820430000
I0929 14:31:54.683851  2305 layer_factory.hpp:77] Creating layer Convolution28
I0929 14:31:54.683859  2305 net.cpp:84] Creating Layer Convolution28
I0929 14:31:54.683861  2305 net.cpp:406] Convolution28 <- Convolution27
I0929 14:31:54.683866  2305 net.cpp:380] Convolution28 -> Convolution28
I0929 14:31:54.685534  2305 net.cpp:122] Setting up Convolution28
I0929 14:31:54.685545  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.685549  2305 net.cpp:137] Memory required for data: 823706800
I0929 14:31:54.685554  2305 layer_factory.hpp:77] Creating layer BatchNorm28
I0929 14:31:54.685559  2305 net.cpp:84] Creating Layer BatchNorm28
I0929 14:31:54.685562  2305 net.cpp:406] BatchNorm28 <- Convolution28
I0929 14:31:54.685567  2305 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I0929 14:31:54.685708  2305 net.cpp:122] Setting up BatchNorm28
I0929 14:31:54.685714  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.685716  2305 net.cpp:137] Memory required for data: 826983600
I0929 14:31:54.685721  2305 layer_factory.hpp:77] Creating layer Scale28
I0929 14:31:54.685725  2305 net.cpp:84] Creating Layer Scale28
I0929 14:31:54.685729  2305 net.cpp:406] Scale28 <- Convolution28
I0929 14:31:54.685732  2305 net.cpp:367] Scale28 -> Convolution28 (in-place)
I0929 14:31:54.685761  2305 layer_factory.hpp:77] Creating layer Scale28
I0929 14:31:54.685843  2305 net.cpp:122] Setting up Scale28
I0929 14:31:54.685858  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.685861  2305 net.cpp:137] Memory required for data: 830260400
I0929 14:31:54.685866  2305 layer_factory.hpp:77] Creating layer Eltwise13
I0929 14:31:54.685871  2305 net.cpp:84] Creating Layer Eltwise13
I0929 14:31:54.685874  2305 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I0929 14:31:54.685878  2305 net.cpp:406] Eltwise13 <- Convolution28
I0929 14:31:54.685881  2305 net.cpp:380] Eltwise13 -> Eltwise13
I0929 14:31:54.685895  2305 net.cpp:122] Setting up Eltwise13
I0929 14:31:54.685900  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.685902  2305 net.cpp:137] Memory required for data: 833537200
I0929 14:31:54.685904  2305 layer_factory.hpp:77] Creating layer M2PELU27
I0929 14:31:54.685910  2305 net.cpp:84] Creating Layer M2PELU27
I0929 14:31:54.685914  2305 net.cpp:406] M2PELU27 <- Eltwise13
I0929 14:31:54.685917  2305 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I0929 14:31:54.686014  2305 net.cpp:122] Setting up M2PELU27
I0929 14:31:54.686019  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.686022  2305 net.cpp:137] Memory required for data: 836814000
I0929 14:31:54.686025  2305 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I0929 14:31:54.686029  2305 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I0929 14:31:54.686033  2305 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I0929 14:31:54.686035  2305 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I0929 14:31:54.686039  2305 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I0929 14:31:54.686064  2305 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I0929 14:31:54.686069  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.686071  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.686074  2305 net.cpp:137] Memory required for data: 843367600
I0929 14:31:54.686075  2305 layer_factory.hpp:77] Creating layer Convolution29
I0929 14:31:54.686081  2305 net.cpp:84] Creating Layer Convolution29
I0929 14:31:54.686084  2305 net.cpp:406] Convolution29 <- Eltwise13_M2PELU27_0_split_0
I0929 14:31:54.686089  2305 net.cpp:380] Convolution29 -> Convolution29
I0929 14:31:54.687237  2305 net.cpp:122] Setting up Convolution29
I0929 14:31:54.687247  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.687250  2305 net.cpp:137] Memory required for data: 846644400
I0929 14:31:54.687254  2305 layer_factory.hpp:77] Creating layer BatchNorm29
I0929 14:31:54.687259  2305 net.cpp:84] Creating Layer BatchNorm29
I0929 14:31:54.687263  2305 net.cpp:406] BatchNorm29 <- Convolution29
I0929 14:31:54.687268  2305 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I0929 14:31:54.687398  2305 net.cpp:122] Setting up BatchNorm29
I0929 14:31:54.687402  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.687405  2305 net.cpp:137] Memory required for data: 849921200
I0929 14:31:54.687410  2305 layer_factory.hpp:77] Creating layer Scale29
I0929 14:31:54.687417  2305 net.cpp:84] Creating Layer Scale29
I0929 14:31:54.687419  2305 net.cpp:406] Scale29 <- Convolution29
I0929 14:31:54.687423  2305 net.cpp:367] Scale29 -> Convolution29 (in-place)
I0929 14:31:54.687463  2305 layer_factory.hpp:77] Creating layer Scale29
I0929 14:31:54.687561  2305 net.cpp:122] Setting up Scale29
I0929 14:31:54.687567  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.687569  2305 net.cpp:137] Memory required for data: 853198000
I0929 14:31:54.687597  2305 layer_factory.hpp:77] Creating layer M2PELU28
I0929 14:31:54.687602  2305 net.cpp:84] Creating Layer M2PELU28
I0929 14:31:54.687605  2305 net.cpp:406] M2PELU28 <- Convolution29
I0929 14:31:54.687609  2305 net.cpp:367] M2PELU28 -> Convolution29 (in-place)
I0929 14:31:54.687696  2305 net.cpp:122] Setting up M2PELU28
I0929 14:31:54.687700  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.687703  2305 net.cpp:137] Memory required for data: 856474800
I0929 14:31:54.687707  2305 layer_factory.hpp:77] Creating layer Convolution30
I0929 14:31:54.687722  2305 net.cpp:84] Creating Layer Convolution30
I0929 14:31:54.687726  2305 net.cpp:406] Convolution30 <- Convolution29
I0929 14:31:54.687729  2305 net.cpp:380] Convolution30 -> Convolution30
I0929 14:31:54.688845  2305 net.cpp:122] Setting up Convolution30
I0929 14:31:54.688854  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.688856  2305 net.cpp:137] Memory required for data: 859751600
I0929 14:31:54.688861  2305 layer_factory.hpp:77] Creating layer BatchNorm30
I0929 14:31:54.688866  2305 net.cpp:84] Creating Layer BatchNorm30
I0929 14:31:54.688869  2305 net.cpp:406] BatchNorm30 <- Convolution30
I0929 14:31:54.688874  2305 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I0929 14:31:54.688999  2305 net.cpp:122] Setting up BatchNorm30
I0929 14:31:54.689004  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.689007  2305 net.cpp:137] Memory required for data: 863028400
I0929 14:31:54.689012  2305 layer_factory.hpp:77] Creating layer Scale30
I0929 14:31:54.689015  2305 net.cpp:84] Creating Layer Scale30
I0929 14:31:54.689018  2305 net.cpp:406] Scale30 <- Convolution30
I0929 14:31:54.689021  2305 net.cpp:367] Scale30 -> Convolution30 (in-place)
I0929 14:31:54.689049  2305 layer_factory.hpp:77] Creating layer Scale30
I0929 14:31:54.689121  2305 net.cpp:122] Setting up Scale30
I0929 14:31:54.689126  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.689127  2305 net.cpp:137] Memory required for data: 866305200
I0929 14:31:54.689131  2305 layer_factory.hpp:77] Creating layer Eltwise14
I0929 14:31:54.689136  2305 net.cpp:84] Creating Layer Eltwise14
I0929 14:31:54.689137  2305 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I0929 14:31:54.689141  2305 net.cpp:406] Eltwise14 <- Convolution30
I0929 14:31:54.689144  2305 net.cpp:380] Eltwise14 -> Eltwise14
I0929 14:31:54.689157  2305 net.cpp:122] Setting up Eltwise14
I0929 14:31:54.689159  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.689162  2305 net.cpp:137] Memory required for data: 869582000
I0929 14:31:54.689163  2305 layer_factory.hpp:77] Creating layer M2PELU29
I0929 14:31:54.689169  2305 net.cpp:84] Creating Layer M2PELU29
I0929 14:31:54.689172  2305 net.cpp:406] M2PELU29 <- Eltwise14
I0929 14:31:54.689175  2305 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I0929 14:31:54.689260  2305 net.cpp:122] Setting up M2PELU29
I0929 14:31:54.689265  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.689267  2305 net.cpp:137] Memory required for data: 872858800
I0929 14:31:54.689270  2305 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I0929 14:31:54.689275  2305 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I0929 14:31:54.689276  2305 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I0929 14:31:54.689281  2305 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I0929 14:31:54.689285  2305 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I0929 14:31:54.689307  2305 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I0929 14:31:54.689311  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.689314  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.689316  2305 net.cpp:137] Memory required for data: 879412400
I0929 14:31:54.689318  2305 layer_factory.hpp:77] Creating layer Convolution31
I0929 14:31:54.689324  2305 net.cpp:84] Creating Layer Convolution31
I0929 14:31:54.689327  2305 net.cpp:406] Convolution31 <- Eltwise14_M2PELU29_0_split_0
I0929 14:31:54.689332  2305 net.cpp:380] Convolution31 -> Convolution31
I0929 14:31:54.690419  2305 net.cpp:122] Setting up Convolution31
I0929 14:31:54.690428  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.690431  2305 net.cpp:137] Memory required for data: 882689200
I0929 14:31:54.690435  2305 layer_factory.hpp:77] Creating layer BatchNorm31
I0929 14:31:54.690441  2305 net.cpp:84] Creating Layer BatchNorm31
I0929 14:31:54.690444  2305 net.cpp:406] BatchNorm31 <- Convolution31
I0929 14:31:54.690454  2305 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I0929 14:31:54.690608  2305 net.cpp:122] Setting up BatchNorm31
I0929 14:31:54.690613  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.690615  2305 net.cpp:137] Memory required for data: 885966000
I0929 14:31:54.690620  2305 layer_factory.hpp:77] Creating layer Scale31
I0929 14:31:54.690626  2305 net.cpp:84] Creating Layer Scale31
I0929 14:31:54.690629  2305 net.cpp:406] Scale31 <- Convolution31
I0929 14:31:54.690632  2305 net.cpp:367] Scale31 -> Convolution31 (in-place)
I0929 14:31:54.690659  2305 layer_factory.hpp:77] Creating layer Scale31
I0929 14:31:54.690732  2305 net.cpp:122] Setting up Scale31
I0929 14:31:54.690737  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.690738  2305 net.cpp:137] Memory required for data: 889242800
I0929 14:31:54.690742  2305 layer_factory.hpp:77] Creating layer M2PELU30
I0929 14:31:54.690747  2305 net.cpp:84] Creating Layer M2PELU30
I0929 14:31:54.690750  2305 net.cpp:406] M2PELU30 <- Convolution31
I0929 14:31:54.690754  2305 net.cpp:367] M2PELU30 -> Convolution31 (in-place)
I0929 14:31:54.690834  2305 net.cpp:122] Setting up M2PELU30
I0929 14:31:54.690837  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.690840  2305 net.cpp:137] Memory required for data: 892519600
I0929 14:31:54.690843  2305 layer_factory.hpp:77] Creating layer Convolution32
I0929 14:31:54.690850  2305 net.cpp:84] Creating Layer Convolution32
I0929 14:31:54.690853  2305 net.cpp:406] Convolution32 <- Convolution31
I0929 14:31:54.690857  2305 net.cpp:380] Convolution32 -> Convolution32
I0929 14:31:54.691967  2305 net.cpp:122] Setting up Convolution32
I0929 14:31:54.691977  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.691979  2305 net.cpp:137] Memory required for data: 895796400
I0929 14:31:54.691983  2305 layer_factory.hpp:77] Creating layer BatchNorm32
I0929 14:31:54.691989  2305 net.cpp:84] Creating Layer BatchNorm32
I0929 14:31:54.691992  2305 net.cpp:406] BatchNorm32 <- Convolution32
I0929 14:31:54.691996  2305 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I0929 14:31:54.692123  2305 net.cpp:122] Setting up BatchNorm32
I0929 14:31:54.692127  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.711678  2305 net.cpp:137] Memory required for data: 899073200
I0929 14:31:54.711693  2305 layer_factory.hpp:77] Creating layer Scale32
I0929 14:31:54.711699  2305 net.cpp:84] Creating Layer Scale32
I0929 14:31:54.711701  2305 net.cpp:406] Scale32 <- Convolution32
I0929 14:31:54.711709  2305 net.cpp:367] Scale32 -> Convolution32 (in-place)
I0929 14:31:54.711752  2305 layer_factory.hpp:77] Creating layer Scale32
I0929 14:31:54.711839  2305 net.cpp:122] Setting up Scale32
I0929 14:31:54.711844  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.711848  2305 net.cpp:137] Memory required for data: 902350000
I0929 14:31:54.711851  2305 layer_factory.hpp:77] Creating layer Eltwise15
I0929 14:31:54.711856  2305 net.cpp:84] Creating Layer Eltwise15
I0929 14:31:54.711859  2305 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I0929 14:31:54.711863  2305 net.cpp:406] Eltwise15 <- Convolution32
I0929 14:31:54.711866  2305 net.cpp:380] Eltwise15 -> Eltwise15
I0929 14:31:54.711880  2305 net.cpp:122] Setting up Eltwise15
I0929 14:31:54.711884  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.711886  2305 net.cpp:137] Memory required for data: 905626800
I0929 14:31:54.711889  2305 layer_factory.hpp:77] Creating layer M2PELU31
I0929 14:31:54.711894  2305 net.cpp:84] Creating Layer M2PELU31
I0929 14:31:54.711897  2305 net.cpp:406] M2PELU31 <- Eltwise15
I0929 14:31:54.711900  2305 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I0929 14:31:54.711998  2305 net.cpp:122] Setting up M2PELU31
I0929 14:31:54.712003  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.712005  2305 net.cpp:137] Memory required for data: 908903600
I0929 14:31:54.712009  2305 layer_factory.hpp:77] Creating layer Eltwise15_M2PELU31_0_split
I0929 14:31:54.712013  2305 net.cpp:84] Creating Layer Eltwise15_M2PELU31_0_split
I0929 14:31:54.712028  2305 net.cpp:406] Eltwise15_M2PELU31_0_split <- Eltwise15
I0929 14:31:54.712033  2305 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_0
I0929 14:31:54.712038  2305 net.cpp:380] Eltwise15_M2PELU31_0_split -> Eltwise15_M2PELU31_0_split_1
I0929 14:31:54.712064  2305 net.cpp:122] Setting up Eltwise15_M2PELU31_0_split
I0929 14:31:54.712069  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.712072  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.712074  2305 net.cpp:137] Memory required for data: 915457200
I0929 14:31:54.712077  2305 layer_factory.hpp:77] Creating layer Convolution33
I0929 14:31:54.712085  2305 net.cpp:84] Creating Layer Convolution33
I0929 14:31:54.712087  2305 net.cpp:406] Convolution33 <- Eltwise15_M2PELU31_0_split_0
I0929 14:31:54.712092  2305 net.cpp:380] Convolution33 -> Convolution33
I0929 14:31:54.713440  2305 net.cpp:122] Setting up Convolution33
I0929 14:31:54.713454  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.713457  2305 net.cpp:137] Memory required for data: 918734000
I0929 14:31:54.713462  2305 layer_factory.hpp:77] Creating layer BatchNorm33
I0929 14:31:54.713469  2305 net.cpp:84] Creating Layer BatchNorm33
I0929 14:31:54.713472  2305 net.cpp:406] BatchNorm33 <- Convolution33
I0929 14:31:54.713477  2305 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I0929 14:31:54.713629  2305 net.cpp:122] Setting up BatchNorm33
I0929 14:31:54.713635  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.713639  2305 net.cpp:137] Memory required for data: 922010800
I0929 14:31:54.713644  2305 layer_factory.hpp:77] Creating layer Scale33
I0929 14:31:54.713647  2305 net.cpp:84] Creating Layer Scale33
I0929 14:31:54.713650  2305 net.cpp:406] Scale33 <- Convolution33
I0929 14:31:54.713654  2305 net.cpp:367] Scale33 -> Convolution33 (in-place)
I0929 14:31:54.713682  2305 layer_factory.hpp:77] Creating layer Scale33
I0929 14:31:54.713757  2305 net.cpp:122] Setting up Scale33
I0929 14:31:54.713762  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.713763  2305 net.cpp:137] Memory required for data: 925287600
I0929 14:31:54.713768  2305 layer_factory.hpp:77] Creating layer M2PELU32
I0929 14:31:54.713773  2305 net.cpp:84] Creating Layer M2PELU32
I0929 14:31:54.713775  2305 net.cpp:406] M2PELU32 <- Convolution33
I0929 14:31:54.713779  2305 net.cpp:367] M2PELU32 -> Convolution33 (in-place)
I0929 14:31:54.713865  2305 net.cpp:122] Setting up M2PELU32
I0929 14:31:54.713870  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.713871  2305 net.cpp:137] Memory required for data: 928564400
I0929 14:31:54.713876  2305 layer_factory.hpp:77] Creating layer Convolution34
I0929 14:31:54.713882  2305 net.cpp:84] Creating Layer Convolution34
I0929 14:31:54.713884  2305 net.cpp:406] Convolution34 <- Convolution33
I0929 14:31:54.713889  2305 net.cpp:380] Convolution34 -> Convolution34
I0929 14:31:54.715837  2305 net.cpp:122] Setting up Convolution34
I0929 14:31:54.715847  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.715849  2305 net.cpp:137] Memory required for data: 931841200
I0929 14:31:54.715854  2305 layer_factory.hpp:77] Creating layer BatchNorm34
I0929 14:31:54.715859  2305 net.cpp:84] Creating Layer BatchNorm34
I0929 14:31:54.715863  2305 net.cpp:406] BatchNorm34 <- Convolution34
I0929 14:31:54.715867  2305 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I0929 14:31:54.715998  2305 net.cpp:122] Setting up BatchNorm34
I0929 14:31:54.716002  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.716006  2305 net.cpp:137] Memory required for data: 935118000
I0929 14:31:54.716009  2305 layer_factory.hpp:77] Creating layer Scale34
I0929 14:31:54.716014  2305 net.cpp:84] Creating Layer Scale34
I0929 14:31:54.716017  2305 net.cpp:406] Scale34 <- Convolution34
I0929 14:31:54.716019  2305 net.cpp:367] Scale34 -> Convolution34 (in-place)
I0929 14:31:54.716048  2305 layer_factory.hpp:77] Creating layer Scale34
I0929 14:31:54.716133  2305 net.cpp:122] Setting up Scale34
I0929 14:31:54.716140  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.716141  2305 net.cpp:137] Memory required for data: 938394800
I0929 14:31:54.716145  2305 layer_factory.hpp:77] Creating layer Eltwise16
I0929 14:31:54.716150  2305 net.cpp:84] Creating Layer Eltwise16
I0929 14:31:54.716154  2305 net.cpp:406] Eltwise16 <- Eltwise15_M2PELU31_0_split_1
I0929 14:31:54.716157  2305 net.cpp:406] Eltwise16 <- Convolution34
I0929 14:31:54.716162  2305 net.cpp:380] Eltwise16 -> Eltwise16
I0929 14:31:54.716174  2305 net.cpp:122] Setting up Eltwise16
I0929 14:31:54.716178  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.716181  2305 net.cpp:137] Memory required for data: 941671600
I0929 14:31:54.716182  2305 layer_factory.hpp:77] Creating layer M2PELU33
I0929 14:31:54.716188  2305 net.cpp:84] Creating Layer M2PELU33
I0929 14:31:54.716192  2305 net.cpp:406] M2PELU33 <- Eltwise16
I0929 14:31:54.716194  2305 net.cpp:367] M2PELU33 -> Eltwise16 (in-place)
I0929 14:31:54.716279  2305 net.cpp:122] Setting up M2PELU33
I0929 14:31:54.716284  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.716285  2305 net.cpp:137] Memory required for data: 944948400
I0929 14:31:54.716289  2305 layer_factory.hpp:77] Creating layer Eltwise16_M2PELU33_0_split
I0929 14:31:54.716294  2305 net.cpp:84] Creating Layer Eltwise16_M2PELU33_0_split
I0929 14:31:54.716295  2305 net.cpp:406] Eltwise16_M2PELU33_0_split <- Eltwise16
I0929 14:31:54.716300  2305 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_0
I0929 14:31:54.716305  2305 net.cpp:380] Eltwise16_M2PELU33_0_split -> Eltwise16_M2PELU33_0_split_1
I0929 14:31:54.716328  2305 net.cpp:122] Setting up Eltwise16_M2PELU33_0_split
I0929 14:31:54.716333  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.716336  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.716338  2305 net.cpp:137] Memory required for data: 951502000
I0929 14:31:54.716341  2305 layer_factory.hpp:77] Creating layer Convolution35
I0929 14:31:54.716346  2305 net.cpp:84] Creating Layer Convolution35
I0929 14:31:54.716348  2305 net.cpp:406] Convolution35 <- Eltwise16_M2PELU33_0_split_0
I0929 14:31:54.716353  2305 net.cpp:380] Convolution35 -> Convolution35
I0929 14:31:54.717456  2305 net.cpp:122] Setting up Convolution35
I0929 14:31:54.717466  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.717469  2305 net.cpp:137] Memory required for data: 954778800
I0929 14:31:54.717473  2305 layer_factory.hpp:77] Creating layer BatchNorm35
I0929 14:31:54.717478  2305 net.cpp:84] Creating Layer BatchNorm35
I0929 14:31:54.717480  2305 net.cpp:406] BatchNorm35 <- Convolution35
I0929 14:31:54.717485  2305 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I0929 14:31:54.717617  2305 net.cpp:122] Setting up BatchNorm35
I0929 14:31:54.717620  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.717623  2305 net.cpp:137] Memory required for data: 958055600
I0929 14:31:54.717628  2305 layer_factory.hpp:77] Creating layer Scale35
I0929 14:31:54.717631  2305 net.cpp:84] Creating Layer Scale35
I0929 14:31:54.717634  2305 net.cpp:406] Scale35 <- Convolution35
I0929 14:31:54.717638  2305 net.cpp:367] Scale35 -> Convolution35 (in-place)
I0929 14:31:54.717664  2305 layer_factory.hpp:77] Creating layer Scale35
I0929 14:31:54.717741  2305 net.cpp:122] Setting up Scale35
I0929 14:31:54.717746  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.717748  2305 net.cpp:137] Memory required for data: 961332400
I0929 14:31:54.717752  2305 layer_factory.hpp:77] Creating layer M2PELU34
I0929 14:31:54.717757  2305 net.cpp:84] Creating Layer M2PELU34
I0929 14:31:54.717759  2305 net.cpp:406] M2PELU34 <- Convolution35
I0929 14:31:54.717763  2305 net.cpp:367] M2PELU34 -> Convolution35 (in-place)
I0929 14:31:54.717844  2305 net.cpp:122] Setting up M2PELU34
I0929 14:31:54.717849  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.717850  2305 net.cpp:137] Memory required for data: 964609200
I0929 14:31:54.717860  2305 layer_factory.hpp:77] Creating layer Convolution36
I0929 14:31:54.717869  2305 net.cpp:84] Creating Layer Convolution36
I0929 14:31:54.717870  2305 net.cpp:406] Convolution36 <- Convolution35
I0929 14:31:54.717875  2305 net.cpp:380] Convolution36 -> Convolution36
I0929 14:31:54.718647  2305 net.cpp:122] Setting up Convolution36
I0929 14:31:54.718657  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.718658  2305 net.cpp:137] Memory required for data: 967886000
I0929 14:31:54.718662  2305 layer_factory.hpp:77] Creating layer BatchNorm36
I0929 14:31:54.718667  2305 net.cpp:84] Creating Layer BatchNorm36
I0929 14:31:54.718670  2305 net.cpp:406] BatchNorm36 <- Convolution36
I0929 14:31:54.718675  2305 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I0929 14:31:54.718806  2305 net.cpp:122] Setting up BatchNorm36
I0929 14:31:54.718809  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.718812  2305 net.cpp:137] Memory required for data: 971162800
I0929 14:31:54.718816  2305 layer_factory.hpp:77] Creating layer Scale36
I0929 14:31:54.718821  2305 net.cpp:84] Creating Layer Scale36
I0929 14:31:54.718823  2305 net.cpp:406] Scale36 <- Convolution36
I0929 14:31:54.718827  2305 net.cpp:367] Scale36 -> Convolution36 (in-place)
I0929 14:31:54.718853  2305 layer_factory.hpp:77] Creating layer Scale36
I0929 14:31:54.718930  2305 net.cpp:122] Setting up Scale36
I0929 14:31:54.718935  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.718936  2305 net.cpp:137] Memory required for data: 974439600
I0929 14:31:54.718940  2305 layer_factory.hpp:77] Creating layer Eltwise17
I0929 14:31:54.718945  2305 net.cpp:84] Creating Layer Eltwise17
I0929 14:31:54.718947  2305 net.cpp:406] Eltwise17 <- Eltwise16_M2PELU33_0_split_1
I0929 14:31:54.718950  2305 net.cpp:406] Eltwise17 <- Convolution36
I0929 14:31:54.718955  2305 net.cpp:380] Eltwise17 -> Eltwise17
I0929 14:31:54.718966  2305 net.cpp:122] Setting up Eltwise17
I0929 14:31:54.718969  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.718971  2305 net.cpp:137] Memory required for data: 977716400
I0929 14:31:54.718974  2305 layer_factory.hpp:77] Creating layer M2PELU35
I0929 14:31:54.718979  2305 net.cpp:84] Creating Layer M2PELU35
I0929 14:31:54.718981  2305 net.cpp:406] M2PELU35 <- Eltwise17
I0929 14:31:54.718984  2305 net.cpp:367] M2PELU35 -> Eltwise17 (in-place)
I0929 14:31:54.719074  2305 net.cpp:122] Setting up M2PELU35
I0929 14:31:54.719079  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.719080  2305 net.cpp:137] Memory required for data: 980993200
I0929 14:31:54.719084  2305 layer_factory.hpp:77] Creating layer Eltwise17_M2PELU35_0_split
I0929 14:31:54.719087  2305 net.cpp:84] Creating Layer Eltwise17_M2PELU35_0_split
I0929 14:31:54.719089  2305 net.cpp:406] Eltwise17_M2PELU35_0_split <- Eltwise17
I0929 14:31:54.719094  2305 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_0
I0929 14:31:54.719099  2305 net.cpp:380] Eltwise17_M2PELU35_0_split -> Eltwise17_M2PELU35_0_split_1
I0929 14:31:54.719125  2305 net.cpp:122] Setting up Eltwise17_M2PELU35_0_split
I0929 14:31:54.719127  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.719130  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.719132  2305 net.cpp:137] Memory required for data: 987546800
I0929 14:31:54.719135  2305 layer_factory.hpp:77] Creating layer Convolution37
I0929 14:31:54.719141  2305 net.cpp:84] Creating Layer Convolution37
I0929 14:31:54.719143  2305 net.cpp:406] Convolution37 <- Eltwise17_M2PELU35_0_split_0
I0929 14:31:54.719147  2305 net.cpp:380] Convolution37 -> Convolution37
I0929 14:31:54.720247  2305 net.cpp:122] Setting up Convolution37
I0929 14:31:54.720255  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.720258  2305 net.cpp:137] Memory required for data: 990823600
I0929 14:31:54.720263  2305 layer_factory.hpp:77] Creating layer BatchNorm37
I0929 14:31:54.720268  2305 net.cpp:84] Creating Layer BatchNorm37
I0929 14:31:54.720278  2305 net.cpp:406] BatchNorm37 <- Convolution37
I0929 14:31:54.720283  2305 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I0929 14:31:54.720414  2305 net.cpp:122] Setting up BatchNorm37
I0929 14:31:54.720419  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.720422  2305 net.cpp:137] Memory required for data: 994100400
I0929 14:31:54.720427  2305 layer_factory.hpp:77] Creating layer Scale37
I0929 14:31:54.720430  2305 net.cpp:84] Creating Layer Scale37
I0929 14:31:54.720433  2305 net.cpp:406] Scale37 <- Convolution37
I0929 14:31:54.720438  2305 net.cpp:367] Scale37 -> Convolution37 (in-place)
I0929 14:31:54.720463  2305 layer_factory.hpp:77] Creating layer Scale37
I0929 14:31:54.720540  2305 net.cpp:122] Setting up Scale37
I0929 14:31:54.720544  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.720546  2305 net.cpp:137] Memory required for data: 997377200
I0929 14:31:54.720551  2305 layer_factory.hpp:77] Creating layer M2PELU36
I0929 14:31:54.720554  2305 net.cpp:84] Creating Layer M2PELU36
I0929 14:31:54.720557  2305 net.cpp:406] M2PELU36 <- Convolution37
I0929 14:31:54.720561  2305 net.cpp:367] M2PELU36 -> Convolution37 (in-place)
I0929 14:31:54.720644  2305 net.cpp:122] Setting up M2PELU36
I0929 14:31:54.720649  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.720651  2305 net.cpp:137] Memory required for data: 1000654000
I0929 14:31:54.720655  2305 layer_factory.hpp:77] Creating layer Convolution38
I0929 14:31:54.720661  2305 net.cpp:84] Creating Layer Convolution38
I0929 14:31:54.720664  2305 net.cpp:406] Convolution38 <- Convolution37
I0929 14:31:54.720669  2305 net.cpp:380] Convolution38 -> Convolution38
I0929 14:31:54.722091  2305 net.cpp:122] Setting up Convolution38
I0929 14:31:54.722100  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.722103  2305 net.cpp:137] Memory required for data: 1003930800
I0929 14:31:54.722108  2305 layer_factory.hpp:77] Creating layer BatchNorm38
I0929 14:31:54.722113  2305 net.cpp:84] Creating Layer BatchNorm38
I0929 14:31:54.722116  2305 net.cpp:406] BatchNorm38 <- Convolution38
I0929 14:31:54.742614  2305 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I0929 14:31:54.742795  2305 net.cpp:122] Setting up BatchNorm38
I0929 14:31:54.742802  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.742805  2305 net.cpp:137] Memory required for data: 1007207600
I0929 14:31:54.742811  2305 layer_factory.hpp:77] Creating layer Scale38
I0929 14:31:54.742815  2305 net.cpp:84] Creating Layer Scale38
I0929 14:31:54.742818  2305 net.cpp:406] Scale38 <- Convolution38
I0929 14:31:54.742821  2305 net.cpp:367] Scale38 -> Convolution38 (in-place)
I0929 14:31:54.742859  2305 layer_factory.hpp:77] Creating layer Scale38
I0929 14:31:54.742944  2305 net.cpp:122] Setting up Scale38
I0929 14:31:54.742949  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.742952  2305 net.cpp:137] Memory required for data: 1010484400
I0929 14:31:54.742956  2305 layer_factory.hpp:77] Creating layer Eltwise18
I0929 14:31:54.742964  2305 net.cpp:84] Creating Layer Eltwise18
I0929 14:31:54.742967  2305 net.cpp:406] Eltwise18 <- Eltwise17_M2PELU35_0_split_1
I0929 14:31:54.742971  2305 net.cpp:406] Eltwise18 <- Convolution38
I0929 14:31:54.742975  2305 net.cpp:380] Eltwise18 -> Eltwise18
I0929 14:31:54.742990  2305 net.cpp:122] Setting up Eltwise18
I0929 14:31:54.742993  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.742996  2305 net.cpp:137] Memory required for data: 1013761200
I0929 14:31:54.742998  2305 layer_factory.hpp:77] Creating layer M2PELU37
I0929 14:31:54.743005  2305 net.cpp:84] Creating Layer M2PELU37
I0929 14:31:54.743006  2305 net.cpp:406] M2PELU37 <- Eltwise18
I0929 14:31:54.743010  2305 net.cpp:367] M2PELU37 -> Eltwise18 (in-place)
I0929 14:31:54.743108  2305 net.cpp:122] Setting up M2PELU37
I0929 14:31:54.743113  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.743114  2305 net.cpp:137] Memory required for data: 1017038000
I0929 14:31:54.743119  2305 layer_factory.hpp:77] Creating layer Eltwise18_M2PELU37_0_split
I0929 14:31:54.743132  2305 net.cpp:84] Creating Layer Eltwise18_M2PELU37_0_split
I0929 14:31:54.743135  2305 net.cpp:406] Eltwise18_M2PELU37_0_split <- Eltwise18
I0929 14:31:54.743139  2305 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_0
I0929 14:31:54.743145  2305 net.cpp:380] Eltwise18_M2PELU37_0_split -> Eltwise18_M2PELU37_0_split_1
I0929 14:31:54.743172  2305 net.cpp:122] Setting up Eltwise18_M2PELU37_0_split
I0929 14:31:54.743176  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.743180  2305 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0929 14:31:54.743182  2305 net.cpp:137] Memory required for data: 1023591600
I0929 14:31:54.743185  2305 layer_factory.hpp:77] Creating layer Convolution39
I0929 14:31:54.743191  2305 net.cpp:84] Creating Layer Convolution39
I0929 14:31:54.743193  2305 net.cpp:406] Convolution39 <- Eltwise18_M2PELU37_0_split_0
I0929 14:31:54.743199  2305 net.cpp:380] Convolution39 -> Convolution39
I0929 14:31:54.744475  2305 net.cpp:122] Setting up Convolution39
I0929 14:31:54.744487  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.744489  2305 net.cpp:137] Memory required for data: 1025230000
I0929 14:31:54.744494  2305 layer_factory.hpp:77] Creating layer BatchNorm39
I0929 14:31:54.744499  2305 net.cpp:84] Creating Layer BatchNorm39
I0929 14:31:54.744501  2305 net.cpp:406] BatchNorm39 <- Convolution39
I0929 14:31:54.744508  2305 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I0929 14:31:54.744640  2305 net.cpp:122] Setting up BatchNorm39
I0929 14:31:54.744645  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.744647  2305 net.cpp:137] Memory required for data: 1026868400
I0929 14:31:54.744652  2305 layer_factory.hpp:77] Creating layer Scale39
I0929 14:31:54.744657  2305 net.cpp:84] Creating Layer Scale39
I0929 14:31:54.744659  2305 net.cpp:406] Scale39 <- Convolution39
I0929 14:31:54.744664  2305 net.cpp:367] Scale39 -> Convolution39 (in-place)
I0929 14:31:54.744691  2305 layer_factory.hpp:77] Creating layer Scale39
I0929 14:31:54.744770  2305 net.cpp:122] Setting up Scale39
I0929 14:31:54.744774  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.744776  2305 net.cpp:137] Memory required for data: 1028506800
I0929 14:31:54.744781  2305 layer_factory.hpp:77] Creating layer Convolution40
I0929 14:31:54.744787  2305 net.cpp:84] Creating Layer Convolution40
I0929 14:31:54.744791  2305 net.cpp:406] Convolution40 <- Eltwise18_M2PELU37_0_split_1
I0929 14:31:54.744796  2305 net.cpp:380] Convolution40 -> Convolution40
I0929 14:31:54.746305  2305 net.cpp:122] Setting up Convolution40
I0929 14:31:54.746315  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.746317  2305 net.cpp:137] Memory required for data: 1030145200
I0929 14:31:54.746321  2305 layer_factory.hpp:77] Creating layer BatchNorm40
I0929 14:31:54.746327  2305 net.cpp:84] Creating Layer BatchNorm40
I0929 14:31:54.746330  2305 net.cpp:406] BatchNorm40 <- Convolution40
I0929 14:31:54.746333  2305 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I0929 14:31:54.746469  2305 net.cpp:122] Setting up BatchNorm40
I0929 14:31:54.746474  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.746476  2305 net.cpp:137] Memory required for data: 1031783600
I0929 14:31:54.746481  2305 layer_factory.hpp:77] Creating layer Scale40
I0929 14:31:54.746485  2305 net.cpp:84] Creating Layer Scale40
I0929 14:31:54.746487  2305 net.cpp:406] Scale40 <- Convolution40
I0929 14:31:54.746491  2305 net.cpp:367] Scale40 -> Convolution40 (in-place)
I0929 14:31:54.746518  2305 layer_factory.hpp:77] Creating layer Scale40
I0929 14:31:54.746649  2305 net.cpp:122] Setting up Scale40
I0929 14:31:54.746654  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.746656  2305 net.cpp:137] Memory required for data: 1033422000
I0929 14:31:54.746660  2305 layer_factory.hpp:77] Creating layer M2PELU38
I0929 14:31:54.746665  2305 net.cpp:84] Creating Layer M2PELU38
I0929 14:31:54.746668  2305 net.cpp:406] M2PELU38 <- Convolution40
I0929 14:31:54.746681  2305 net.cpp:367] M2PELU38 -> Convolution40 (in-place)
I0929 14:31:54.746779  2305 net.cpp:122] Setting up M2PELU38
I0929 14:31:54.746784  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.746786  2305 net.cpp:137] Memory required for data: 1035060400
I0929 14:31:54.746790  2305 layer_factory.hpp:77] Creating layer Convolution41
I0929 14:31:54.746799  2305 net.cpp:84] Creating Layer Convolution41
I0929 14:31:54.746801  2305 net.cpp:406] Convolution41 <- Convolution40
I0929 14:31:54.746805  2305 net.cpp:380] Convolution41 -> Convolution41
I0929 14:31:54.748510  2305 net.cpp:122] Setting up Convolution41
I0929 14:31:54.748519  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.748522  2305 net.cpp:137] Memory required for data: 1036698800
I0929 14:31:54.748527  2305 layer_factory.hpp:77] Creating layer BatchNorm41
I0929 14:31:54.748531  2305 net.cpp:84] Creating Layer BatchNorm41
I0929 14:31:54.748534  2305 net.cpp:406] BatchNorm41 <- Convolution41
I0929 14:31:54.748538  2305 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I0929 14:31:54.748668  2305 net.cpp:122] Setting up BatchNorm41
I0929 14:31:54.748672  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.748674  2305 net.cpp:137] Memory required for data: 1038337200
I0929 14:31:54.748679  2305 layer_factory.hpp:77] Creating layer Scale41
I0929 14:31:54.748682  2305 net.cpp:84] Creating Layer Scale41
I0929 14:31:54.748685  2305 net.cpp:406] Scale41 <- Convolution41
I0929 14:31:54.748688  2305 net.cpp:367] Scale41 -> Convolution41 (in-place)
I0929 14:31:54.748716  2305 layer_factory.hpp:77] Creating layer Scale41
I0929 14:31:54.748791  2305 net.cpp:122] Setting up Scale41
I0929 14:31:54.748796  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.748798  2305 net.cpp:137] Memory required for data: 1039975600
I0929 14:31:54.748801  2305 layer_factory.hpp:77] Creating layer Eltwise19
I0929 14:31:54.748806  2305 net.cpp:84] Creating Layer Eltwise19
I0929 14:31:54.748809  2305 net.cpp:406] Eltwise19 <- Convolution39
I0929 14:31:54.748812  2305 net.cpp:406] Eltwise19 <- Convolution41
I0929 14:31:54.748816  2305 net.cpp:380] Eltwise19 -> Eltwise19
I0929 14:31:54.748832  2305 net.cpp:122] Setting up Eltwise19
I0929 14:31:54.748836  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.748837  2305 net.cpp:137] Memory required for data: 1041614000
I0929 14:31:54.748841  2305 layer_factory.hpp:77] Creating layer M2PELU39
I0929 14:31:54.748844  2305 net.cpp:84] Creating Layer M2PELU39
I0929 14:31:54.748847  2305 net.cpp:406] M2PELU39 <- Eltwise19
I0929 14:31:54.748850  2305 net.cpp:367] M2PELU39 -> Eltwise19 (in-place)
I0929 14:31:54.748936  2305 net.cpp:122] Setting up M2PELU39
I0929 14:31:54.748941  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.748944  2305 net.cpp:137] Memory required for data: 1043252400
I0929 14:31:54.748947  2305 layer_factory.hpp:77] Creating layer Eltwise19_M2PELU39_0_split
I0929 14:31:54.748951  2305 net.cpp:84] Creating Layer Eltwise19_M2PELU39_0_split
I0929 14:31:54.748953  2305 net.cpp:406] Eltwise19_M2PELU39_0_split <- Eltwise19
I0929 14:31:54.748957  2305 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_0
I0929 14:31:54.748961  2305 net.cpp:380] Eltwise19_M2PELU39_0_split -> Eltwise19_M2PELU39_0_split_1
I0929 14:31:54.748984  2305 net.cpp:122] Setting up Eltwise19_M2PELU39_0_split
I0929 14:31:54.748988  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.748991  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.748993  2305 net.cpp:137] Memory required for data: 1046529200
I0929 14:31:54.748996  2305 layer_factory.hpp:77] Creating layer Convolution42
I0929 14:31:54.749002  2305 net.cpp:84] Creating Layer Convolution42
I0929 14:31:54.749006  2305 net.cpp:406] Convolution42 <- Eltwise19_M2PELU39_0_split_0
I0929 14:31:54.749009  2305 net.cpp:380] Convolution42 -> Convolution42
I0929 14:31:54.750701  2305 net.cpp:122] Setting up Convolution42
I0929 14:31:54.750710  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.750720  2305 net.cpp:137] Memory required for data: 1048167600
I0929 14:31:54.750725  2305 layer_factory.hpp:77] Creating layer BatchNorm42
I0929 14:31:54.750730  2305 net.cpp:84] Creating Layer BatchNorm42
I0929 14:31:54.750732  2305 net.cpp:406] BatchNorm42 <- Convolution42
I0929 14:31:54.750736  2305 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I0929 14:31:54.750869  2305 net.cpp:122] Setting up BatchNorm42
I0929 14:31:54.750874  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.750876  2305 net.cpp:137] Memory required for data: 1049806000
I0929 14:31:54.750881  2305 layer_factory.hpp:77] Creating layer Scale42
I0929 14:31:54.750885  2305 net.cpp:84] Creating Layer Scale42
I0929 14:31:54.750887  2305 net.cpp:406] Scale42 <- Convolution42
I0929 14:31:54.750892  2305 net.cpp:367] Scale42 -> Convolution42 (in-place)
I0929 14:31:54.750918  2305 layer_factory.hpp:77] Creating layer Scale42
I0929 14:31:54.750995  2305 net.cpp:122] Setting up Scale42
I0929 14:31:54.750999  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.751001  2305 net.cpp:137] Memory required for data: 1051444400
I0929 14:31:54.751005  2305 layer_factory.hpp:77] Creating layer M2PELU40
I0929 14:31:54.751010  2305 net.cpp:84] Creating Layer M2PELU40
I0929 14:31:54.751013  2305 net.cpp:406] M2PELU40 <- Convolution42
I0929 14:31:54.751016  2305 net.cpp:367] M2PELU40 -> Convolution42 (in-place)
I0929 14:31:54.751106  2305 net.cpp:122] Setting up M2PELU40
I0929 14:31:54.751109  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.751111  2305 net.cpp:137] Memory required for data: 1053082800
I0929 14:31:54.751116  2305 layer_factory.hpp:77] Creating layer Convolution43
I0929 14:31:54.751122  2305 net.cpp:84] Creating Layer Convolution43
I0929 14:31:54.751124  2305 net.cpp:406] Convolution43 <- Convolution42
I0929 14:31:54.751128  2305 net.cpp:380] Convolution43 -> Convolution43
I0929 14:31:54.752813  2305 net.cpp:122] Setting up Convolution43
I0929 14:31:54.752822  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.752825  2305 net.cpp:137] Memory required for data: 1054721200
I0929 14:31:54.752830  2305 layer_factory.hpp:77] Creating layer BatchNorm43
I0929 14:31:54.752835  2305 net.cpp:84] Creating Layer BatchNorm43
I0929 14:31:54.752838  2305 net.cpp:406] BatchNorm43 <- Convolution43
I0929 14:31:54.752841  2305 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I0929 14:31:54.752974  2305 net.cpp:122] Setting up BatchNorm43
I0929 14:31:54.752979  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.752980  2305 net.cpp:137] Memory required for data: 1056359600
I0929 14:31:54.752985  2305 layer_factory.hpp:77] Creating layer Scale43
I0929 14:31:54.752988  2305 net.cpp:84] Creating Layer Scale43
I0929 14:31:54.752991  2305 net.cpp:406] Scale43 <- Convolution43
I0929 14:31:54.752995  2305 net.cpp:367] Scale43 -> Convolution43 (in-place)
I0929 14:31:54.753021  2305 layer_factory.hpp:77] Creating layer Scale43
I0929 14:31:54.753099  2305 net.cpp:122] Setting up Scale43
I0929 14:31:54.753104  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.753106  2305 net.cpp:137] Memory required for data: 1057998000
I0929 14:31:54.753110  2305 layer_factory.hpp:77] Creating layer Eltwise20
I0929 14:31:54.753114  2305 net.cpp:84] Creating Layer Eltwise20
I0929 14:31:54.753118  2305 net.cpp:406] Eltwise20 <- Eltwise19_M2PELU39_0_split_1
I0929 14:31:54.753120  2305 net.cpp:406] Eltwise20 <- Convolution43
I0929 14:31:54.753123  2305 net.cpp:380] Eltwise20 -> Eltwise20
I0929 14:31:54.753140  2305 net.cpp:122] Setting up Eltwise20
I0929 14:31:54.753144  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.753146  2305 net.cpp:137] Memory required for data: 1059636400
I0929 14:31:54.753149  2305 layer_factory.hpp:77] Creating layer M2PELU41
I0929 14:31:54.753154  2305 net.cpp:84] Creating Layer M2PELU41
I0929 14:31:54.753155  2305 net.cpp:406] M2PELU41 <- Eltwise20
I0929 14:31:54.753159  2305 net.cpp:367] M2PELU41 -> Eltwise20 (in-place)
I0929 14:31:54.753255  2305 net.cpp:122] Setting up M2PELU41
I0929 14:31:54.753262  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.753263  2305 net.cpp:137] Memory required for data: 1061274800
I0929 14:31:54.753268  2305 layer_factory.hpp:77] Creating layer Eltwise20_M2PELU41_0_split
I0929 14:31:54.753270  2305 net.cpp:84] Creating Layer Eltwise20_M2PELU41_0_split
I0929 14:31:54.753273  2305 net.cpp:406] Eltwise20_M2PELU41_0_split <- Eltwise20
I0929 14:31:54.753276  2305 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_0
I0929 14:31:54.753280  2305 net.cpp:380] Eltwise20_M2PELU41_0_split -> Eltwise20_M2PELU41_0_split_1
I0929 14:31:54.753305  2305 net.cpp:122] Setting up Eltwise20_M2PELU41_0_split
I0929 14:31:54.753309  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.753311  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.753314  2305 net.cpp:137] Memory required for data: 1064551600
I0929 14:31:54.753316  2305 layer_factory.hpp:77] Creating layer Convolution44
I0929 14:31:54.753322  2305 net.cpp:84] Creating Layer Convolution44
I0929 14:31:54.753324  2305 net.cpp:406] Convolution44 <- Eltwise20_M2PELU41_0_split_0
I0929 14:31:54.753329  2305 net.cpp:380] Convolution44 -> Convolution44
I0929 14:31:54.755329  2305 net.cpp:122] Setting up Convolution44
I0929 14:31:54.755338  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.755340  2305 net.cpp:137] Memory required for data: 1066190000
I0929 14:31:54.755347  2305 layer_factory.hpp:77] Creating layer BatchNorm44
I0929 14:31:54.755350  2305 net.cpp:84] Creating Layer BatchNorm44
I0929 14:31:54.755353  2305 net.cpp:406] BatchNorm44 <- Convolution44
I0929 14:31:54.755357  2305 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I0929 14:31:54.755496  2305 net.cpp:122] Setting up BatchNorm44
I0929 14:31:54.755501  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.755503  2305 net.cpp:137] Memory required for data: 1067828400
I0929 14:31:54.773381  2305 layer_factory.hpp:77] Creating layer Scale44
I0929 14:31:54.773389  2305 net.cpp:84] Creating Layer Scale44
I0929 14:31:54.773393  2305 net.cpp:406] Scale44 <- Convolution44
I0929 14:31:54.773396  2305 net.cpp:367] Scale44 -> Convolution44 (in-place)
I0929 14:31:54.773435  2305 layer_factory.hpp:77] Creating layer Scale44
I0929 14:31:54.773524  2305 net.cpp:122] Setting up Scale44
I0929 14:31:54.773528  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.773530  2305 net.cpp:137] Memory required for data: 1069466800
I0929 14:31:54.773535  2305 layer_factory.hpp:77] Creating layer M2PELU42
I0929 14:31:54.773540  2305 net.cpp:84] Creating Layer M2PELU42
I0929 14:31:54.773542  2305 net.cpp:406] M2PELU42 <- Convolution44
I0929 14:31:54.773548  2305 net.cpp:367] M2PELU42 -> Convolution44 (in-place)
I0929 14:31:54.773649  2305 net.cpp:122] Setting up M2PELU42
I0929 14:31:54.773654  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.773656  2305 net.cpp:137] Memory required for data: 1071105200
I0929 14:31:54.773660  2305 layer_factory.hpp:77] Creating layer Convolution45
I0929 14:31:54.773669  2305 net.cpp:84] Creating Layer Convolution45
I0929 14:31:54.773671  2305 net.cpp:406] Convolution45 <- Convolution44
I0929 14:31:54.773676  2305 net.cpp:380] Convolution45 -> Convolution45
I0929 14:31:54.775750  2305 net.cpp:122] Setting up Convolution45
I0929 14:31:54.775761  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.775763  2305 net.cpp:137] Memory required for data: 1072743600
I0929 14:31:54.775768  2305 layer_factory.hpp:77] Creating layer BatchNorm45
I0929 14:31:54.775777  2305 net.cpp:84] Creating Layer BatchNorm45
I0929 14:31:54.775780  2305 net.cpp:406] BatchNorm45 <- Convolution45
I0929 14:31:54.775784  2305 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I0929 14:31:54.776006  2305 net.cpp:122] Setting up BatchNorm45
I0929 14:31:54.776011  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.776013  2305 net.cpp:137] Memory required for data: 1074382000
I0929 14:31:54.776027  2305 layer_factory.hpp:77] Creating layer Scale45
I0929 14:31:54.776033  2305 net.cpp:84] Creating Layer Scale45
I0929 14:31:54.776036  2305 net.cpp:406] Scale45 <- Convolution45
I0929 14:31:54.776039  2305 net.cpp:367] Scale45 -> Convolution45 (in-place)
I0929 14:31:54.776070  2305 layer_factory.hpp:77] Creating layer Scale45
I0929 14:31:54.776150  2305 net.cpp:122] Setting up Scale45
I0929 14:31:54.776155  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.776157  2305 net.cpp:137] Memory required for data: 1076020400
I0929 14:31:54.776161  2305 layer_factory.hpp:77] Creating layer Eltwise21
I0929 14:31:54.776166  2305 net.cpp:84] Creating Layer Eltwise21
I0929 14:31:54.776170  2305 net.cpp:406] Eltwise21 <- Eltwise20_M2PELU41_0_split_1
I0929 14:31:54.776173  2305 net.cpp:406] Eltwise21 <- Convolution45
I0929 14:31:54.776176  2305 net.cpp:380] Eltwise21 -> Eltwise21
I0929 14:31:54.776193  2305 net.cpp:122] Setting up Eltwise21
I0929 14:31:54.776197  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.776199  2305 net.cpp:137] Memory required for data: 1077658800
I0929 14:31:54.776201  2305 layer_factory.hpp:77] Creating layer M2PELU43
I0929 14:31:54.776207  2305 net.cpp:84] Creating Layer M2PELU43
I0929 14:31:54.776209  2305 net.cpp:406] M2PELU43 <- Eltwise21
I0929 14:31:54.776212  2305 net.cpp:367] M2PELU43 -> Eltwise21 (in-place)
I0929 14:31:54.776307  2305 net.cpp:122] Setting up M2PELU43
I0929 14:31:54.776311  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.776314  2305 net.cpp:137] Memory required for data: 1079297200
I0929 14:31:54.776317  2305 layer_factory.hpp:77] Creating layer Eltwise21_M2PELU43_0_split
I0929 14:31:54.776322  2305 net.cpp:84] Creating Layer Eltwise21_M2PELU43_0_split
I0929 14:31:54.776324  2305 net.cpp:406] Eltwise21_M2PELU43_0_split <- Eltwise21
I0929 14:31:54.776329  2305 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_0
I0929 14:31:54.776335  2305 net.cpp:380] Eltwise21_M2PELU43_0_split -> Eltwise21_M2PELU43_0_split_1
I0929 14:31:54.776360  2305 net.cpp:122] Setting up Eltwise21_M2PELU43_0_split
I0929 14:31:54.776362  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.776365  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.776367  2305 net.cpp:137] Memory required for data: 1082574000
I0929 14:31:54.776370  2305 layer_factory.hpp:77] Creating layer Convolution46
I0929 14:31:54.776376  2305 net.cpp:84] Creating Layer Convolution46
I0929 14:31:54.776378  2305 net.cpp:406] Convolution46 <- Eltwise21_M2PELU43_0_split_0
I0929 14:31:54.776383  2305 net.cpp:380] Convolution46 -> Convolution46
I0929 14:31:54.778167  2305 net.cpp:122] Setting up Convolution46
I0929 14:31:54.778177  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.778179  2305 net.cpp:137] Memory required for data: 1084212400
I0929 14:31:54.778183  2305 layer_factory.hpp:77] Creating layer BatchNorm46
I0929 14:31:54.778188  2305 net.cpp:84] Creating Layer BatchNorm46
I0929 14:31:54.778192  2305 net.cpp:406] BatchNorm46 <- Convolution46
I0929 14:31:54.778195  2305 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I0929 14:31:54.778338  2305 net.cpp:122] Setting up BatchNorm46
I0929 14:31:54.778343  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.778345  2305 net.cpp:137] Memory required for data: 1085850800
I0929 14:31:54.778350  2305 layer_factory.hpp:77] Creating layer Scale46
I0929 14:31:54.778354  2305 net.cpp:84] Creating Layer Scale46
I0929 14:31:54.778357  2305 net.cpp:406] Scale46 <- Convolution46
I0929 14:31:54.778360  2305 net.cpp:367] Scale46 -> Convolution46 (in-place)
I0929 14:31:54.778388  2305 layer_factory.hpp:77] Creating layer Scale46
I0929 14:31:54.778470  2305 net.cpp:122] Setting up Scale46
I0929 14:31:54.778475  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.778476  2305 net.cpp:137] Memory required for data: 1087489200
I0929 14:31:54.778481  2305 layer_factory.hpp:77] Creating layer M2PELU44
I0929 14:31:54.778486  2305 net.cpp:84] Creating Layer M2PELU44
I0929 14:31:54.778494  2305 net.cpp:406] M2PELU44 <- Convolution46
I0929 14:31:54.778499  2305 net.cpp:367] M2PELU44 -> Convolution46 (in-place)
I0929 14:31:54.778604  2305 net.cpp:122] Setting up M2PELU44
I0929 14:31:54.778609  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.778612  2305 net.cpp:137] Memory required for data: 1089127600
I0929 14:31:54.778616  2305 layer_factory.hpp:77] Creating layer Convolution47
I0929 14:31:54.778623  2305 net.cpp:84] Creating Layer Convolution47
I0929 14:31:54.778626  2305 net.cpp:406] Convolution47 <- Convolution46
I0929 14:31:54.778630  2305 net.cpp:380] Convolution47 -> Convolution47
I0929 14:31:54.780365  2305 net.cpp:122] Setting up Convolution47
I0929 14:31:54.780375  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.780377  2305 net.cpp:137] Memory required for data: 1090766000
I0929 14:31:54.780381  2305 layer_factory.hpp:77] Creating layer BatchNorm47
I0929 14:31:54.780387  2305 net.cpp:84] Creating Layer BatchNorm47
I0929 14:31:54.780390  2305 net.cpp:406] BatchNorm47 <- Convolution47
I0929 14:31:54.780395  2305 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I0929 14:31:54.780531  2305 net.cpp:122] Setting up BatchNorm47
I0929 14:31:54.780536  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.780539  2305 net.cpp:137] Memory required for data: 1092404400
I0929 14:31:54.780544  2305 layer_factory.hpp:77] Creating layer Scale47
I0929 14:31:54.780547  2305 net.cpp:84] Creating Layer Scale47
I0929 14:31:54.780550  2305 net.cpp:406] Scale47 <- Convolution47
I0929 14:31:54.780553  2305 net.cpp:367] Scale47 -> Convolution47 (in-place)
I0929 14:31:54.780581  2305 layer_factory.hpp:77] Creating layer Scale47
I0929 14:31:54.780660  2305 net.cpp:122] Setting up Scale47
I0929 14:31:54.780665  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.780668  2305 net.cpp:137] Memory required for data: 1094042800
I0929 14:31:54.780671  2305 layer_factory.hpp:77] Creating layer Eltwise22
I0929 14:31:54.780675  2305 net.cpp:84] Creating Layer Eltwise22
I0929 14:31:54.780678  2305 net.cpp:406] Eltwise22 <- Eltwise21_M2PELU43_0_split_1
I0929 14:31:54.780681  2305 net.cpp:406] Eltwise22 <- Convolution47
I0929 14:31:54.780685  2305 net.cpp:380] Eltwise22 -> Eltwise22
I0929 14:31:54.780701  2305 net.cpp:122] Setting up Eltwise22
I0929 14:31:54.780705  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.780707  2305 net.cpp:137] Memory required for data: 1095681200
I0929 14:31:54.780710  2305 layer_factory.hpp:77] Creating layer M2PELU45
I0929 14:31:54.780715  2305 net.cpp:84] Creating Layer M2PELU45
I0929 14:31:54.780717  2305 net.cpp:406] M2PELU45 <- Eltwise22
I0929 14:31:54.780720  2305 net.cpp:367] M2PELU45 -> Eltwise22 (in-place)
I0929 14:31:54.780812  2305 net.cpp:122] Setting up M2PELU45
I0929 14:31:54.780817  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.780819  2305 net.cpp:137] Memory required for data: 1097319600
I0929 14:31:54.780823  2305 layer_factory.hpp:77] Creating layer Eltwise22_M2PELU45_0_split
I0929 14:31:54.780827  2305 net.cpp:84] Creating Layer Eltwise22_M2PELU45_0_split
I0929 14:31:54.780830  2305 net.cpp:406] Eltwise22_M2PELU45_0_split <- Eltwise22
I0929 14:31:54.780833  2305 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_0
I0929 14:31:54.780838  2305 net.cpp:380] Eltwise22_M2PELU45_0_split -> Eltwise22_M2PELU45_0_split_1
I0929 14:31:54.780861  2305 net.cpp:122] Setting up Eltwise22_M2PELU45_0_split
I0929 14:31:54.780865  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.780869  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.780870  2305 net.cpp:137] Memory required for data: 1100596400
I0929 14:31:54.780872  2305 layer_factory.hpp:77] Creating layer Convolution48
I0929 14:31:54.780879  2305 net.cpp:84] Creating Layer Convolution48
I0929 14:31:54.780881  2305 net.cpp:406] Convolution48 <- Eltwise22_M2PELU45_0_split_0
I0929 14:31:54.780885  2305 net.cpp:380] Convolution48 -> Convolution48
I0929 14:31:54.782941  2305 net.cpp:122] Setting up Convolution48
I0929 14:31:54.782956  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.782959  2305 net.cpp:137] Memory required for data: 1102234800
I0929 14:31:54.782964  2305 layer_factory.hpp:77] Creating layer BatchNorm48
I0929 14:31:54.782971  2305 net.cpp:84] Creating Layer BatchNorm48
I0929 14:31:54.782974  2305 net.cpp:406] BatchNorm48 <- Convolution48
I0929 14:31:54.782979  2305 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I0929 14:31:54.783123  2305 net.cpp:122] Setting up BatchNorm48
I0929 14:31:54.783128  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.783130  2305 net.cpp:137] Memory required for data: 1103873200
I0929 14:31:54.783134  2305 layer_factory.hpp:77] Creating layer Scale48
I0929 14:31:54.783140  2305 net.cpp:84] Creating Layer Scale48
I0929 14:31:54.783143  2305 net.cpp:406] Scale48 <- Convolution48
I0929 14:31:54.783146  2305 net.cpp:367] Scale48 -> Convolution48 (in-place)
I0929 14:31:54.783175  2305 layer_factory.hpp:77] Creating layer Scale48
I0929 14:31:54.783257  2305 net.cpp:122] Setting up Scale48
I0929 14:31:54.783262  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.783263  2305 net.cpp:137] Memory required for data: 1105511600
I0929 14:31:54.783267  2305 layer_factory.hpp:77] Creating layer M2PELU46
I0929 14:31:54.783273  2305 net.cpp:84] Creating Layer M2PELU46
I0929 14:31:54.783277  2305 net.cpp:406] M2PELU46 <- Convolution48
I0929 14:31:54.783279  2305 net.cpp:367] M2PELU46 -> Convolution48 (in-place)
I0929 14:31:54.783370  2305 net.cpp:122] Setting up M2PELU46
I0929 14:31:54.783375  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.783377  2305 net.cpp:137] Memory required for data: 1107150000
I0929 14:31:54.783381  2305 layer_factory.hpp:77] Creating layer Convolution49
I0929 14:31:54.783387  2305 net.cpp:84] Creating Layer Convolution49
I0929 14:31:54.783390  2305 net.cpp:406] Convolution49 <- Convolution48
I0929 14:31:54.783396  2305 net.cpp:380] Convolution49 -> Convolution49
I0929 14:31:54.785465  2305 net.cpp:122] Setting up Convolution49
I0929 14:31:54.785473  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.785476  2305 net.cpp:137] Memory required for data: 1108788400
I0929 14:31:54.785481  2305 layer_factory.hpp:77] Creating layer BatchNorm49
I0929 14:31:54.785486  2305 net.cpp:84] Creating Layer BatchNorm49
I0929 14:31:54.785490  2305 net.cpp:406] BatchNorm49 <- Convolution49
I0929 14:31:54.785493  2305 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I0929 14:31:54.785632  2305 net.cpp:122] Setting up BatchNorm49
I0929 14:31:54.785636  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.785639  2305 net.cpp:137] Memory required for data: 1110426800
I0929 14:31:54.785643  2305 layer_factory.hpp:77] Creating layer Scale49
I0929 14:31:54.785648  2305 net.cpp:84] Creating Layer Scale49
I0929 14:31:54.785651  2305 net.cpp:406] Scale49 <- Convolution49
I0929 14:31:54.785655  2305 net.cpp:367] Scale49 -> Convolution49 (in-place)
I0929 14:31:54.785682  2305 layer_factory.hpp:77] Creating layer Scale49
I0929 14:31:54.785766  2305 net.cpp:122] Setting up Scale49
I0929 14:31:54.785771  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.785773  2305 net.cpp:137] Memory required for data: 1112065200
I0929 14:31:54.785778  2305 layer_factory.hpp:77] Creating layer Eltwise23
I0929 14:31:54.785781  2305 net.cpp:84] Creating Layer Eltwise23
I0929 14:31:54.785784  2305 net.cpp:406] Eltwise23 <- Eltwise22_M2PELU45_0_split_1
I0929 14:31:54.785787  2305 net.cpp:406] Eltwise23 <- Convolution49
I0929 14:31:54.785792  2305 net.cpp:380] Eltwise23 -> Eltwise23
I0929 14:31:54.785809  2305 net.cpp:122] Setting up Eltwise23
I0929 14:31:54.785812  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.785815  2305 net.cpp:137] Memory required for data: 1113703600
I0929 14:31:54.785816  2305 layer_factory.hpp:77] Creating layer M2PELU47
I0929 14:31:54.785822  2305 net.cpp:84] Creating Layer M2PELU47
I0929 14:31:54.785825  2305 net.cpp:406] M2PELU47 <- Eltwise23
I0929 14:31:54.785827  2305 net.cpp:367] M2PELU47 -> Eltwise23 (in-place)
I0929 14:31:54.785930  2305 net.cpp:122] Setting up M2PELU47
I0929 14:31:54.785935  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.785938  2305 net.cpp:137] Memory required for data: 1115342000
I0929 14:31:54.785941  2305 layer_factory.hpp:77] Creating layer Eltwise23_M2PELU47_0_split
I0929 14:31:54.785946  2305 net.cpp:84] Creating Layer Eltwise23_M2PELU47_0_split
I0929 14:31:54.785948  2305 net.cpp:406] Eltwise23_M2PELU47_0_split <- Eltwise23
I0929 14:31:54.785953  2305 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_0
I0929 14:31:54.785956  2305 net.cpp:380] Eltwise23_M2PELU47_0_split -> Eltwise23_M2PELU47_0_split_1
I0929 14:31:54.785981  2305 net.cpp:122] Setting up Eltwise23_M2PELU47_0_split
I0929 14:31:54.785985  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.785989  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.785990  2305 net.cpp:137] Memory required for data: 1118618800
I0929 14:31:54.785992  2305 layer_factory.hpp:77] Creating layer Convolution50
I0929 14:31:54.786000  2305 net.cpp:84] Creating Layer Convolution50
I0929 14:31:54.786001  2305 net.cpp:406] Convolution50 <- Eltwise23_M2PELU47_0_split_0
I0929 14:31:54.786005  2305 net.cpp:380] Convolution50 -> Convolution50
I0929 14:31:54.788601  2305 net.cpp:122] Setting up Convolution50
I0929 14:31:54.788610  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.788614  2305 net.cpp:137] Memory required for data: 1120257200
I0929 14:31:54.788617  2305 layer_factory.hpp:77] Creating layer BatchNorm50
I0929 14:31:54.788624  2305 net.cpp:84] Creating Layer BatchNorm50
I0929 14:31:54.788626  2305 net.cpp:406] BatchNorm50 <- Convolution50
I0929 14:31:54.788630  2305 net.cpp:367] BatchNorm50 -> Convolution50 (in-place)
I0929 14:31:54.804328  2305 net.cpp:122] Setting up BatchNorm50
I0929 14:31:54.804337  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.804340  2305 net.cpp:137] Memory required for data: 1121895600
I0929 14:31:54.804347  2305 layer_factory.hpp:77] Creating layer Scale50
I0929 14:31:54.804353  2305 net.cpp:84] Creating Layer Scale50
I0929 14:31:54.804356  2305 net.cpp:406] Scale50 <- Convolution50
I0929 14:31:54.804360  2305 net.cpp:367] Scale50 -> Convolution50 (in-place)
I0929 14:31:54.804394  2305 layer_factory.hpp:77] Creating layer Scale50
I0929 14:31:54.804482  2305 net.cpp:122] Setting up Scale50
I0929 14:31:54.804488  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.804491  2305 net.cpp:137] Memory required for data: 1123534000
I0929 14:31:54.804494  2305 layer_factory.hpp:77] Creating layer M2PELU48
I0929 14:31:54.804500  2305 net.cpp:84] Creating Layer M2PELU48
I0929 14:31:54.804503  2305 net.cpp:406] M2PELU48 <- Convolution50
I0929 14:31:54.804507  2305 net.cpp:367] M2PELU48 -> Convolution50 (in-place)
I0929 14:31:54.804610  2305 net.cpp:122] Setting up M2PELU48
I0929 14:31:54.804615  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.804616  2305 net.cpp:137] Memory required for data: 1125172400
I0929 14:31:54.804620  2305 layer_factory.hpp:77] Creating layer Convolution51
I0929 14:31:54.804628  2305 net.cpp:84] Creating Layer Convolution51
I0929 14:31:54.804631  2305 net.cpp:406] Convolution51 <- Convolution50
I0929 14:31:54.804636  2305 net.cpp:380] Convolution51 -> Convolution51
I0929 14:31:54.806777  2305 net.cpp:122] Setting up Convolution51
I0929 14:31:54.806787  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.806789  2305 net.cpp:137] Memory required for data: 1126810800
I0929 14:31:54.806794  2305 layer_factory.hpp:77] Creating layer BatchNorm51
I0929 14:31:54.806800  2305 net.cpp:84] Creating Layer BatchNorm51
I0929 14:31:54.806803  2305 net.cpp:406] BatchNorm51 <- Convolution51
I0929 14:31:54.806807  2305 net.cpp:367] BatchNorm51 -> Convolution51 (in-place)
I0929 14:31:54.806951  2305 net.cpp:122] Setting up BatchNorm51
I0929 14:31:54.806954  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.806957  2305 net.cpp:137] Memory required for data: 1128449200
I0929 14:31:54.806970  2305 layer_factory.hpp:77] Creating layer Scale51
I0929 14:31:54.806975  2305 net.cpp:84] Creating Layer Scale51
I0929 14:31:54.806978  2305 net.cpp:406] Scale51 <- Convolution51
I0929 14:31:54.806982  2305 net.cpp:367] Scale51 -> Convolution51 (in-place)
I0929 14:31:54.807013  2305 layer_factory.hpp:77] Creating layer Scale51
I0929 14:31:54.807097  2305 net.cpp:122] Setting up Scale51
I0929 14:31:54.807101  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.807104  2305 net.cpp:137] Memory required for data: 1130087600
I0929 14:31:54.807107  2305 layer_factory.hpp:77] Creating layer Eltwise24
I0929 14:31:54.807113  2305 net.cpp:84] Creating Layer Eltwise24
I0929 14:31:54.807117  2305 net.cpp:406] Eltwise24 <- Eltwise23_M2PELU47_0_split_1
I0929 14:31:54.807121  2305 net.cpp:406] Eltwise24 <- Convolution51
I0929 14:31:54.807123  2305 net.cpp:380] Eltwise24 -> Eltwise24
I0929 14:31:54.807142  2305 net.cpp:122] Setting up Eltwise24
I0929 14:31:54.807145  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.807147  2305 net.cpp:137] Memory required for data: 1131726000
I0929 14:31:54.807149  2305 layer_factory.hpp:77] Creating layer M2PELU49
I0929 14:31:54.807155  2305 net.cpp:84] Creating Layer M2PELU49
I0929 14:31:54.807157  2305 net.cpp:406] M2PELU49 <- Eltwise24
I0929 14:31:54.807160  2305 net.cpp:367] M2PELU49 -> Eltwise24 (in-place)
I0929 14:31:54.807260  2305 net.cpp:122] Setting up M2PELU49
I0929 14:31:54.807265  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.807266  2305 net.cpp:137] Memory required for data: 1133364400
I0929 14:31:54.807271  2305 layer_factory.hpp:77] Creating layer Eltwise24_M2PELU49_0_split
I0929 14:31:54.807274  2305 net.cpp:84] Creating Layer Eltwise24_M2PELU49_0_split
I0929 14:31:54.807276  2305 net.cpp:406] Eltwise24_M2PELU49_0_split <- Eltwise24
I0929 14:31:54.807281  2305 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_0
I0929 14:31:54.807284  2305 net.cpp:380] Eltwise24_M2PELU49_0_split -> Eltwise24_M2PELU49_0_split_1
I0929 14:31:54.807322  2305 net.cpp:122] Setting up Eltwise24_M2PELU49_0_split
I0929 14:31:54.807327  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.807330  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.807332  2305 net.cpp:137] Memory required for data: 1136641200
I0929 14:31:54.807334  2305 layer_factory.hpp:77] Creating layer Convolution52
I0929 14:31:54.807341  2305 net.cpp:84] Creating Layer Convolution52
I0929 14:31:54.807344  2305 net.cpp:406] Convolution52 <- Eltwise24_M2PELU49_0_split_0
I0929 14:31:54.807348  2305 net.cpp:380] Convolution52 -> Convolution52
I0929 14:31:54.809482  2305 net.cpp:122] Setting up Convolution52
I0929 14:31:54.809491  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.809494  2305 net.cpp:137] Memory required for data: 1138279600
I0929 14:31:54.809500  2305 layer_factory.hpp:77] Creating layer BatchNorm52
I0929 14:31:54.809506  2305 net.cpp:84] Creating Layer BatchNorm52
I0929 14:31:54.809509  2305 net.cpp:406] BatchNorm52 <- Convolution52
I0929 14:31:54.809514  2305 net.cpp:367] BatchNorm52 -> Convolution52 (in-place)
I0929 14:31:54.809664  2305 net.cpp:122] Setting up BatchNorm52
I0929 14:31:54.809669  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.809671  2305 net.cpp:137] Memory required for data: 1139918000
I0929 14:31:54.809676  2305 layer_factory.hpp:77] Creating layer Scale52
I0929 14:31:54.809681  2305 net.cpp:84] Creating Layer Scale52
I0929 14:31:54.809684  2305 net.cpp:406] Scale52 <- Convolution52
I0929 14:31:54.809686  2305 net.cpp:367] Scale52 -> Convolution52 (in-place)
I0929 14:31:54.809718  2305 layer_factory.hpp:77] Creating layer Scale52
I0929 14:31:54.809803  2305 net.cpp:122] Setting up Scale52
I0929 14:31:54.809809  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.809811  2305 net.cpp:137] Memory required for data: 1141556400
I0929 14:31:54.809815  2305 layer_factory.hpp:77] Creating layer M2PELU50
I0929 14:31:54.809847  2305 net.cpp:84] Creating Layer M2PELU50
I0929 14:31:54.809870  2305 net.cpp:406] M2PELU50 <- Convolution52
I0929 14:31:54.809875  2305 net.cpp:367] M2PELU50 -> Convolution52 (in-place)
I0929 14:31:54.809989  2305 net.cpp:122] Setting up M2PELU50
I0929 14:31:54.809994  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.809996  2305 net.cpp:137] Memory required for data: 1143194800
I0929 14:31:54.810001  2305 layer_factory.hpp:77] Creating layer Convolution53
I0929 14:31:54.810009  2305 net.cpp:84] Creating Layer Convolution53
I0929 14:31:54.810011  2305 net.cpp:406] Convolution53 <- Convolution52
I0929 14:31:54.810015  2305 net.cpp:380] Convolution53 -> Convolution53
I0929 14:31:54.811785  2305 net.cpp:122] Setting up Convolution53
I0929 14:31:54.811794  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.811797  2305 net.cpp:137] Memory required for data: 1144833200
I0929 14:31:54.811801  2305 layer_factory.hpp:77] Creating layer BatchNorm53
I0929 14:31:54.811807  2305 net.cpp:84] Creating Layer BatchNorm53
I0929 14:31:54.811810  2305 net.cpp:406] BatchNorm53 <- Convolution53
I0929 14:31:54.811813  2305 net.cpp:367] BatchNorm53 -> Convolution53 (in-place)
I0929 14:31:54.811959  2305 net.cpp:122] Setting up BatchNorm53
I0929 14:31:54.811962  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.811964  2305 net.cpp:137] Memory required for data: 1146471600
I0929 14:31:54.811969  2305 layer_factory.hpp:77] Creating layer Scale53
I0929 14:31:54.811974  2305 net.cpp:84] Creating Layer Scale53
I0929 14:31:54.811976  2305 net.cpp:406] Scale53 <- Convolution53
I0929 14:31:54.811980  2305 net.cpp:367] Scale53 -> Convolution53 (in-place)
I0929 14:31:54.812008  2305 layer_factory.hpp:77] Creating layer Scale53
I0929 14:31:54.812091  2305 net.cpp:122] Setting up Scale53
I0929 14:31:54.812095  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.812098  2305 net.cpp:137] Memory required for data: 1148110000
I0929 14:31:54.812101  2305 layer_factory.hpp:77] Creating layer Eltwise25
I0929 14:31:54.812106  2305 net.cpp:84] Creating Layer Eltwise25
I0929 14:31:54.812110  2305 net.cpp:406] Eltwise25 <- Eltwise24_M2PELU49_0_split_1
I0929 14:31:54.812114  2305 net.cpp:406] Eltwise25 <- Convolution53
I0929 14:31:54.812116  2305 net.cpp:380] Eltwise25 -> Eltwise25
I0929 14:31:54.812135  2305 net.cpp:122] Setting up Eltwise25
I0929 14:31:54.812139  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.812141  2305 net.cpp:137] Memory required for data: 1149748400
I0929 14:31:54.812144  2305 layer_factory.hpp:77] Creating layer M2PELU51
I0929 14:31:54.812149  2305 net.cpp:84] Creating Layer M2PELU51
I0929 14:31:54.812151  2305 net.cpp:406] M2PELU51 <- Eltwise25
I0929 14:31:54.812155  2305 net.cpp:367] M2PELU51 -> Eltwise25 (in-place)
I0929 14:31:54.812249  2305 net.cpp:122] Setting up M2PELU51
I0929 14:31:54.812254  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.812256  2305 net.cpp:137] Memory required for data: 1151386800
I0929 14:31:54.812260  2305 layer_factory.hpp:77] Creating layer Eltwise25_M2PELU51_0_split
I0929 14:31:54.812264  2305 net.cpp:84] Creating Layer Eltwise25_M2PELU51_0_split
I0929 14:31:54.812266  2305 net.cpp:406] Eltwise25_M2PELU51_0_split <- Eltwise25
I0929 14:31:54.812269  2305 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_0
I0929 14:31:54.812273  2305 net.cpp:380] Eltwise25_M2PELU51_0_split -> Eltwise25_M2PELU51_0_split_1
I0929 14:31:54.812300  2305 net.cpp:122] Setting up Eltwise25_M2PELU51_0_split
I0929 14:31:54.812304  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.812306  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.812309  2305 net.cpp:137] Memory required for data: 1154663600
I0929 14:31:54.812311  2305 layer_factory.hpp:77] Creating layer Convolution54
I0929 14:31:54.812317  2305 net.cpp:84] Creating Layer Convolution54
I0929 14:31:54.812319  2305 net.cpp:406] Convolution54 <- Eltwise25_M2PELU51_0_split_0
I0929 14:31:54.812324  2305 net.cpp:380] Convolution54 -> Convolution54
I0929 14:31:54.814398  2305 net.cpp:122] Setting up Convolution54
I0929 14:31:54.814405  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.814409  2305 net.cpp:137] Memory required for data: 1156302000
I0929 14:31:54.814414  2305 layer_factory.hpp:77] Creating layer BatchNorm54
I0929 14:31:54.814419  2305 net.cpp:84] Creating Layer BatchNorm54
I0929 14:31:54.814421  2305 net.cpp:406] BatchNorm54 <- Convolution54
I0929 14:31:54.814426  2305 net.cpp:367] BatchNorm54 -> Convolution54 (in-place)
I0929 14:31:54.814584  2305 net.cpp:122] Setting up BatchNorm54
I0929 14:31:54.814589  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.814592  2305 net.cpp:137] Memory required for data: 1157940400
I0929 14:31:54.814597  2305 layer_factory.hpp:77] Creating layer Scale54
I0929 14:31:54.814601  2305 net.cpp:84] Creating Layer Scale54
I0929 14:31:54.814604  2305 net.cpp:406] Scale54 <- Convolution54
I0929 14:31:54.814606  2305 net.cpp:367] Scale54 -> Convolution54 (in-place)
I0929 14:31:54.814636  2305 layer_factory.hpp:77] Creating layer Scale54
I0929 14:31:54.814721  2305 net.cpp:122] Setting up Scale54
I0929 14:31:54.814725  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.814728  2305 net.cpp:137] Memory required for data: 1159578800
I0929 14:31:54.814731  2305 layer_factory.hpp:77] Creating layer M2PELU52
I0929 14:31:54.814736  2305 net.cpp:84] Creating Layer M2PELU52
I0929 14:31:54.814738  2305 net.cpp:406] M2PELU52 <- Convolution54
I0929 14:31:54.814743  2305 net.cpp:367] M2PELU52 -> Convolution54 (in-place)
I0929 14:31:54.814838  2305 net.cpp:122] Setting up M2PELU52
I0929 14:31:54.814843  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.814846  2305 net.cpp:137] Memory required for data: 1161217200
I0929 14:31:54.814849  2305 layer_factory.hpp:77] Creating layer Convolution55
I0929 14:31:54.814857  2305 net.cpp:84] Creating Layer Convolution55
I0929 14:31:54.814859  2305 net.cpp:406] Convolution55 <- Convolution54
I0929 14:31:54.814862  2305 net.cpp:380] Convolution55 -> Convolution55
I0929 14:31:54.816615  2305 net.cpp:122] Setting up Convolution55
I0929 14:31:54.816624  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.816627  2305 net.cpp:137] Memory required for data: 1162855600
I0929 14:31:54.816632  2305 layer_factory.hpp:77] Creating layer BatchNorm55
I0929 14:31:54.816637  2305 net.cpp:84] Creating Layer BatchNorm55
I0929 14:31:54.816640  2305 net.cpp:406] BatchNorm55 <- Convolution55
I0929 14:31:54.816644  2305 net.cpp:367] BatchNorm55 -> Convolution55 (in-place)
I0929 14:31:54.816789  2305 net.cpp:122] Setting up BatchNorm55
I0929 14:31:54.816794  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.816797  2305 net.cpp:137] Memory required for data: 1164494000
I0929 14:31:54.816802  2305 layer_factory.hpp:77] Creating layer Scale55
I0929 14:31:54.816805  2305 net.cpp:84] Creating Layer Scale55
I0929 14:31:54.816808  2305 net.cpp:406] Scale55 <- Convolution55
I0929 14:31:54.816812  2305 net.cpp:367] Scale55 -> Convolution55 (in-place)
I0929 14:31:54.816841  2305 layer_factory.hpp:77] Creating layer Scale55
I0929 14:31:54.816925  2305 net.cpp:122] Setting up Scale55
I0929 14:31:54.816929  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.816931  2305 net.cpp:137] Memory required for data: 1166132400
I0929 14:31:54.816936  2305 layer_factory.hpp:77] Creating layer Eltwise26
I0929 14:31:54.816941  2305 net.cpp:84] Creating Layer Eltwise26
I0929 14:31:54.816943  2305 net.cpp:406] Eltwise26 <- Eltwise25_M2PELU51_0_split_1
I0929 14:31:54.816947  2305 net.cpp:406] Eltwise26 <- Convolution55
I0929 14:31:54.816951  2305 net.cpp:380] Eltwise26 -> Eltwise26
I0929 14:31:54.816967  2305 net.cpp:122] Setting up Eltwise26
I0929 14:31:54.816972  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.816973  2305 net.cpp:137] Memory required for data: 1167770800
I0929 14:31:54.816975  2305 layer_factory.hpp:77] Creating layer M2PELU53
I0929 14:31:54.816980  2305 net.cpp:84] Creating Layer M2PELU53
I0929 14:31:54.816983  2305 net.cpp:406] M2PELU53 <- Eltwise26
I0929 14:31:54.816993  2305 net.cpp:367] M2PELU53 -> Eltwise26 (in-place)
I0929 14:31:54.817092  2305 net.cpp:122] Setting up M2PELU53
I0929 14:31:54.817097  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.817100  2305 net.cpp:137] Memory required for data: 1169409200
I0929 14:31:54.817103  2305 layer_factory.hpp:77] Creating layer Eltwise26_M2PELU53_0_split
I0929 14:31:54.817107  2305 net.cpp:84] Creating Layer Eltwise26_M2PELU53_0_split
I0929 14:31:54.817109  2305 net.cpp:406] Eltwise26_M2PELU53_0_split <- Eltwise26
I0929 14:31:54.817113  2305 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_0
I0929 14:31:54.817117  2305 net.cpp:380] Eltwise26_M2PELU53_0_split -> Eltwise26_M2PELU53_0_split_1
I0929 14:31:54.817143  2305 net.cpp:122] Setting up Eltwise26_M2PELU53_0_split
I0929 14:31:54.817147  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.817149  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.817152  2305 net.cpp:137] Memory required for data: 1172686000
I0929 14:31:54.817154  2305 layer_factory.hpp:77] Creating layer Convolution56
I0929 14:31:54.817160  2305 net.cpp:84] Creating Layer Convolution56
I0929 14:31:54.817162  2305 net.cpp:406] Convolution56 <- Eltwise26_M2PELU53_0_split_0
I0929 14:31:54.817167  2305 net.cpp:380] Convolution56 -> Convolution56
I0929 14:31:54.818902  2305 net.cpp:122] Setting up Convolution56
I0929 14:31:54.818910  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.818913  2305 net.cpp:137] Memory required for data: 1174324400
I0929 14:31:54.818918  2305 layer_factory.hpp:77] Creating layer BatchNorm56
I0929 14:31:54.834954  2305 net.cpp:84] Creating Layer BatchNorm56
I0929 14:31:54.834962  2305 net.cpp:406] BatchNorm56 <- Convolution56
I0929 14:31:54.834969  2305 net.cpp:367] BatchNorm56 -> Convolution56 (in-place)
I0929 14:31:54.835144  2305 net.cpp:122] Setting up BatchNorm56
I0929 14:31:54.835150  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.835152  2305 net.cpp:137] Memory required for data: 1175962800
I0929 14:31:54.835158  2305 layer_factory.hpp:77] Creating layer Scale56
I0929 14:31:54.835162  2305 net.cpp:84] Creating Layer Scale56
I0929 14:31:54.835165  2305 net.cpp:406] Scale56 <- Convolution56
I0929 14:31:54.835170  2305 net.cpp:367] Scale56 -> Convolution56 (in-place)
I0929 14:31:54.835201  2305 layer_factory.hpp:77] Creating layer Scale56
I0929 14:31:54.835292  2305 net.cpp:122] Setting up Scale56
I0929 14:31:54.835297  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.835299  2305 net.cpp:137] Memory required for data: 1177601200
I0929 14:31:54.835304  2305 layer_factory.hpp:77] Creating layer M2PELU54
I0929 14:31:54.835309  2305 net.cpp:84] Creating Layer M2PELU54
I0929 14:31:54.835311  2305 net.cpp:406] M2PELU54 <- Convolution56
I0929 14:31:54.835315  2305 net.cpp:367] M2PELU54 -> Convolution56 (in-place)
I0929 14:31:54.835420  2305 net.cpp:122] Setting up M2PELU54
I0929 14:31:54.835425  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.835427  2305 net.cpp:137] Memory required for data: 1179239600
I0929 14:31:54.835431  2305 layer_factory.hpp:77] Creating layer Convolution57
I0929 14:31:54.835439  2305 net.cpp:84] Creating Layer Convolution57
I0929 14:31:54.835443  2305 net.cpp:406] Convolution57 <- Convolution56
I0929 14:31:54.835446  2305 net.cpp:380] Convolution57 -> Convolution57
I0929 14:31:54.837726  2305 net.cpp:122] Setting up Convolution57
I0929 14:31:54.837736  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.837739  2305 net.cpp:137] Memory required for data: 1180878000
I0929 14:31:54.837743  2305 layer_factory.hpp:77] Creating layer BatchNorm57
I0929 14:31:54.837749  2305 net.cpp:84] Creating Layer BatchNorm57
I0929 14:31:54.837754  2305 net.cpp:406] BatchNorm57 <- Convolution57
I0929 14:31:54.837756  2305 net.cpp:367] BatchNorm57 -> Convolution57 (in-place)
I0929 14:31:54.837900  2305 net.cpp:122] Setting up BatchNorm57
I0929 14:31:54.837905  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.837915  2305 net.cpp:137] Memory required for data: 1182516400
I0929 14:31:54.837921  2305 layer_factory.hpp:77] Creating layer Scale57
I0929 14:31:54.837926  2305 net.cpp:84] Creating Layer Scale57
I0929 14:31:54.837929  2305 net.cpp:406] Scale57 <- Convolution57
I0929 14:31:54.837932  2305 net.cpp:367] Scale57 -> Convolution57 (in-place)
I0929 14:31:54.837963  2305 layer_factory.hpp:77] Creating layer Scale57
I0929 14:31:54.838047  2305 net.cpp:122] Setting up Scale57
I0929 14:31:54.838052  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.838054  2305 net.cpp:137] Memory required for data: 1184154800
I0929 14:31:54.838057  2305 layer_factory.hpp:77] Creating layer Eltwise27
I0929 14:31:54.838063  2305 net.cpp:84] Creating Layer Eltwise27
I0929 14:31:54.838065  2305 net.cpp:406] Eltwise27 <- Eltwise26_M2PELU53_0_split_1
I0929 14:31:54.838068  2305 net.cpp:406] Eltwise27 <- Convolution57
I0929 14:31:54.838073  2305 net.cpp:380] Eltwise27 -> Eltwise27
I0929 14:31:54.838089  2305 net.cpp:122] Setting up Eltwise27
I0929 14:31:54.838093  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.838094  2305 net.cpp:137] Memory required for data: 1185793200
I0929 14:31:54.838098  2305 layer_factory.hpp:77] Creating layer M2PELU55
I0929 14:31:54.838102  2305 net.cpp:84] Creating Layer M2PELU55
I0929 14:31:54.838104  2305 net.cpp:406] M2PELU55 <- Eltwise27
I0929 14:31:54.838107  2305 net.cpp:367] M2PELU55 -> Eltwise27 (in-place)
I0929 14:31:54.838204  2305 net.cpp:122] Setting up M2PELU55
I0929 14:31:54.838208  2305 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0929 14:31:54.838210  2305 net.cpp:137] Memory required for data: 1187431600
I0929 14:31:54.838214  2305 layer_factory.hpp:77] Creating layer Pooling1
I0929 14:31:54.838219  2305 net.cpp:84] Creating Layer Pooling1
I0929 14:31:54.838222  2305 net.cpp:406] Pooling1 <- Eltwise27
I0929 14:31:54.838225  2305 net.cpp:380] Pooling1 -> Pooling1
I0929 14:31:54.839071  2305 net.cpp:122] Setting up Pooling1
I0929 14:31:54.839081  2305 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0929 14:31:54.839084  2305 net.cpp:137] Memory required for data: 1187457200
I0929 14:31:54.839087  2305 layer_factory.hpp:77] Creating layer InnerProduct1
I0929 14:31:54.839092  2305 net.cpp:84] Creating Layer InnerProduct1
I0929 14:31:54.839095  2305 net.cpp:406] InnerProduct1 <- Pooling1
I0929 14:31:54.839100  2305 net.cpp:380] InnerProduct1 -> InnerProduct1
I0929 14:31:54.839215  2305 net.cpp:122] Setting up InnerProduct1
I0929 14:31:54.839220  2305 net.cpp:129] Top shape: 100 10 (1000)
I0929 14:31:54.839221  2305 net.cpp:137] Memory required for data: 1187461200
I0929 14:31:54.839226  2305 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0929 14:31:54.839229  2305 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0929 14:31:54.839232  2305 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0929 14:31:54.839236  2305 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0929 14:31:54.839241  2305 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0929 14:31:54.839277  2305 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0929 14:31:54.839282  2305 net.cpp:129] Top shape: 100 10 (1000)
I0929 14:31:54.839284  2305 net.cpp:129] Top shape: 100 10 (1000)
I0929 14:31:54.839295  2305 net.cpp:137] Memory required for data: 1187469200
I0929 14:31:54.839298  2305 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 14:31:54.839303  2305 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0929 14:31:54.839305  2305 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0929 14:31:54.839308  2305 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0929 14:31:54.839313  2305 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0929 14:31:54.839318  2305 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0929 14:31:54.839545  2305 net.cpp:122] Setting up SoftmaxWithLoss1
I0929 14:31:54.839552  2305 net.cpp:129] Top shape: (1)
I0929 14:31:54.839563  2305 net.cpp:132]     with loss weight 1
I0929 14:31:54.839570  2305 net.cpp:137] Memory required for data: 1187469204
I0929 14:31:54.839573  2305 layer_factory.hpp:77] Creating layer Accuracy1
I0929 14:31:54.839579  2305 net.cpp:84] Creating Layer Accuracy1
I0929 14:31:54.839582  2305 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0929 14:31:54.839586  2305 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0929 14:31:54.839591  2305 net.cpp:380] Accuracy1 -> Accuracy1
I0929 14:31:54.839598  2305 net.cpp:122] Setting up Accuracy1
I0929 14:31:54.839602  2305 net.cpp:129] Top shape: (1)
I0929 14:31:54.839604  2305 net.cpp:137] Memory required for data: 1187469208
I0929 14:31:54.839607  2305 net.cpp:200] Accuracy1 does not need backward computation.
I0929 14:31:54.839609  2305 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0929 14:31:54.839612  2305 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0929 14:31:54.839615  2305 net.cpp:198] InnerProduct1 needs backward computation.
I0929 14:31:54.839617  2305 net.cpp:198] Pooling1 needs backward computation.
I0929 14:31:54.839620  2305 net.cpp:198] M2PELU55 needs backward computation.
I0929 14:31:54.839622  2305 net.cpp:198] Eltwise27 needs backward computation.
I0929 14:31:54.839625  2305 net.cpp:198] Scale57 needs backward computation.
I0929 14:31:54.839627  2305 net.cpp:198] BatchNorm57 needs backward computation.
I0929 14:31:54.839629  2305 net.cpp:198] Convolution57 needs backward computation.
I0929 14:31:54.839632  2305 net.cpp:198] M2PELU54 needs backward computation.
I0929 14:31:54.839634  2305 net.cpp:198] Scale56 needs backward computation.
I0929 14:31:54.839637  2305 net.cpp:198] BatchNorm56 needs backward computation.
I0929 14:31:54.839639  2305 net.cpp:198] Convolution56 needs backward computation.
I0929 14:31:54.839642  2305 net.cpp:198] Eltwise26_M2PELU53_0_split needs backward computation.
I0929 14:31:54.839644  2305 net.cpp:198] M2PELU53 needs backward computation.
I0929 14:31:54.839648  2305 net.cpp:198] Eltwise26 needs backward computation.
I0929 14:31:54.839649  2305 net.cpp:198] Scale55 needs backward computation.
I0929 14:31:54.839653  2305 net.cpp:198] BatchNorm55 needs backward computation.
I0929 14:31:54.839654  2305 net.cpp:198] Convolution55 needs backward computation.
I0929 14:31:54.839658  2305 net.cpp:198] M2PELU52 needs backward computation.
I0929 14:31:54.839659  2305 net.cpp:198] Scale54 needs backward computation.
I0929 14:31:54.839661  2305 net.cpp:198] BatchNorm54 needs backward computation.
I0929 14:31:54.839663  2305 net.cpp:198] Convolution54 needs backward computation.
I0929 14:31:54.839666  2305 net.cpp:198] Eltwise25_M2PELU51_0_split needs backward computation.
I0929 14:31:54.839669  2305 net.cpp:198] M2PELU51 needs backward computation.
I0929 14:31:54.839671  2305 net.cpp:198] Eltwise25 needs backward computation.
I0929 14:31:54.839674  2305 net.cpp:198] Scale53 needs backward computation.
I0929 14:31:54.839676  2305 net.cpp:198] BatchNorm53 needs backward computation.
I0929 14:31:54.839679  2305 net.cpp:198] Convolution53 needs backward computation.
I0929 14:31:54.839681  2305 net.cpp:198] M2PELU50 needs backward computation.
I0929 14:31:54.839684  2305 net.cpp:198] Scale52 needs backward computation.
I0929 14:31:54.839686  2305 net.cpp:198] BatchNorm52 needs backward computation.
I0929 14:31:54.839689  2305 net.cpp:198] Convolution52 needs backward computation.
I0929 14:31:54.839691  2305 net.cpp:198] Eltwise24_M2PELU49_0_split needs backward computation.
I0929 14:31:54.839694  2305 net.cpp:198] M2PELU49 needs backward computation.
I0929 14:31:54.839696  2305 net.cpp:198] Eltwise24 needs backward computation.
I0929 14:31:54.839699  2305 net.cpp:198] Scale51 needs backward computation.
I0929 14:31:54.839702  2305 net.cpp:198] BatchNorm51 needs backward computation.
I0929 14:31:54.839704  2305 net.cpp:198] Convolution51 needs backward computation.
I0929 14:31:54.839707  2305 net.cpp:198] M2PELU48 needs backward computation.
I0929 14:31:54.839709  2305 net.cpp:198] Scale50 needs backward computation.
I0929 14:31:54.839716  2305 net.cpp:198] BatchNorm50 needs backward computation.
I0929 14:31:54.839720  2305 net.cpp:198] Convolution50 needs backward computation.
I0929 14:31:54.839722  2305 net.cpp:198] Eltwise23_M2PELU47_0_split needs backward computation.
I0929 14:31:54.839725  2305 net.cpp:198] M2PELU47 needs backward computation.
I0929 14:31:54.839727  2305 net.cpp:198] Eltwise23 needs backward computation.
I0929 14:31:54.839730  2305 net.cpp:198] Scale49 needs backward computation.
I0929 14:31:54.839733  2305 net.cpp:198] BatchNorm49 needs backward computation.
I0929 14:31:54.839735  2305 net.cpp:198] Convolution49 needs backward computation.
I0929 14:31:54.839738  2305 net.cpp:198] M2PELU46 needs backward computation.
I0929 14:31:54.839740  2305 net.cpp:198] Scale48 needs backward computation.
I0929 14:31:54.839743  2305 net.cpp:198] BatchNorm48 needs backward computation.
I0929 14:31:54.839745  2305 net.cpp:198] Convolution48 needs backward computation.
I0929 14:31:54.839748  2305 net.cpp:198] Eltwise22_M2PELU45_0_split needs backward computation.
I0929 14:31:54.839751  2305 net.cpp:198] M2PELU45 needs backward computation.
I0929 14:31:54.839753  2305 net.cpp:198] Eltwise22 needs backward computation.
I0929 14:31:54.839756  2305 net.cpp:198] Scale47 needs backward computation.
I0929 14:31:54.839758  2305 net.cpp:198] BatchNorm47 needs backward computation.
I0929 14:31:54.839761  2305 net.cpp:198] Convolution47 needs backward computation.
I0929 14:31:54.839764  2305 net.cpp:198] M2PELU44 needs backward computation.
I0929 14:31:54.839766  2305 net.cpp:198] Scale46 needs backward computation.
I0929 14:31:54.839768  2305 net.cpp:198] BatchNorm46 needs backward computation.
I0929 14:31:54.839771  2305 net.cpp:198] Convolution46 needs backward computation.
I0929 14:31:54.839774  2305 net.cpp:198] Eltwise21_M2PELU43_0_split needs backward computation.
I0929 14:31:54.839776  2305 net.cpp:198] M2PELU43 needs backward computation.
I0929 14:31:54.839779  2305 net.cpp:198] Eltwise21 needs backward computation.
I0929 14:31:54.839782  2305 net.cpp:198] Scale45 needs backward computation.
I0929 14:31:54.839784  2305 net.cpp:198] BatchNorm45 needs backward computation.
I0929 14:31:54.839787  2305 net.cpp:198] Convolution45 needs backward computation.
I0929 14:31:54.839789  2305 net.cpp:198] M2PELU42 needs backward computation.
I0929 14:31:54.839792  2305 net.cpp:198] Scale44 needs backward computation.
I0929 14:31:54.839794  2305 net.cpp:198] BatchNorm44 needs backward computation.
I0929 14:31:54.839797  2305 net.cpp:198] Convolution44 needs backward computation.
I0929 14:31:54.839799  2305 net.cpp:198] Eltwise20_M2PELU41_0_split needs backward computation.
I0929 14:31:54.839802  2305 net.cpp:198] M2PELU41 needs backward computation.
I0929 14:31:54.839804  2305 net.cpp:198] Eltwise20 needs backward computation.
I0929 14:31:54.839807  2305 net.cpp:198] Scale43 needs backward computation.
I0929 14:31:54.839810  2305 net.cpp:198] BatchNorm43 needs backward computation.
I0929 14:31:54.839812  2305 net.cpp:198] Convolution43 needs backward computation.
I0929 14:31:54.839815  2305 net.cpp:198] M2PELU40 needs backward computation.
I0929 14:31:54.839818  2305 net.cpp:198] Scale42 needs backward computation.
I0929 14:31:54.839819  2305 net.cpp:198] BatchNorm42 needs backward computation.
I0929 14:31:54.839823  2305 net.cpp:198] Convolution42 needs backward computation.
I0929 14:31:54.839825  2305 net.cpp:198] Eltwise19_M2PELU39_0_split needs backward computation.
I0929 14:31:54.839828  2305 net.cpp:198] M2PELU39 needs backward computation.
I0929 14:31:54.839830  2305 net.cpp:198] Eltwise19 needs backward computation.
I0929 14:31:54.839833  2305 net.cpp:198] Scale41 needs backward computation.
I0929 14:31:54.839836  2305 net.cpp:198] BatchNorm41 needs backward computation.
I0929 14:31:54.839838  2305 net.cpp:198] Convolution41 needs backward computation.
I0929 14:31:54.839841  2305 net.cpp:198] M2PELU38 needs backward computation.
I0929 14:31:54.839844  2305 net.cpp:198] Scale40 needs backward computation.
I0929 14:31:54.839849  2305 net.cpp:198] BatchNorm40 needs backward computation.
I0929 14:31:54.839853  2305 net.cpp:198] Convolution40 needs backward computation.
I0929 14:31:54.839855  2305 net.cpp:198] Scale39 needs backward computation.
I0929 14:31:54.839859  2305 net.cpp:198] BatchNorm39 needs backward computation.
I0929 14:31:54.839860  2305 net.cpp:198] Convolution39 needs backward computation.
I0929 14:31:54.839864  2305 net.cpp:198] Eltwise18_M2PELU37_0_split needs backward computation.
I0929 14:31:54.839866  2305 net.cpp:198] M2PELU37 needs backward computation.
I0929 14:31:54.839869  2305 net.cpp:198] Eltwise18 needs backward computation.
I0929 14:31:54.839872  2305 net.cpp:198] Scale38 needs backward computation.
I0929 14:31:54.839874  2305 net.cpp:198] BatchNorm38 needs backward computation.
I0929 14:31:54.839877  2305 net.cpp:198] Convolution38 needs backward computation.
I0929 14:31:54.839879  2305 net.cpp:198] M2PELU36 needs backward computation.
I0929 14:31:54.839882  2305 net.cpp:198] Scale37 needs backward computation.
I0929 14:31:54.839884  2305 net.cpp:198] BatchNorm37 needs backward computation.
I0929 14:31:54.839887  2305 net.cpp:198] Convolution37 needs backward computation.
I0929 14:31:54.839890  2305 net.cpp:198] Eltwise17_M2PELU35_0_split needs backward computation.
I0929 14:31:54.839892  2305 net.cpp:198] M2PELU35 needs backward computation.
I0929 14:31:54.839895  2305 net.cpp:198] Eltwise17 needs backward computation.
I0929 14:31:54.865772  2305 net.cpp:198] Scale36 needs backward computation.
I0929 14:31:54.865780  2305 net.cpp:198] BatchNorm36 needs backward computation.
I0929 14:31:54.865783  2305 net.cpp:198] Convolution36 needs backward computation.
I0929 14:31:54.865787  2305 net.cpp:198] M2PELU34 needs backward computation.
I0929 14:31:54.865788  2305 net.cpp:198] Scale35 needs backward computation.
I0929 14:31:54.865792  2305 net.cpp:198] BatchNorm35 needs backward computation.
I0929 14:31:54.865794  2305 net.cpp:198] Convolution35 needs backward computation.
I0929 14:31:54.865797  2305 net.cpp:198] Eltwise16_M2PELU33_0_split needs backward computation.
I0929 14:31:54.865800  2305 net.cpp:198] M2PELU33 needs backward computation.
I0929 14:31:54.865803  2305 net.cpp:198] Eltwise16 needs backward computation.
I0929 14:31:54.865805  2305 net.cpp:198] Scale34 needs backward computation.
I0929 14:31:54.865808  2305 net.cpp:198] BatchNorm34 needs backward computation.
I0929 14:31:54.865810  2305 net.cpp:198] Convolution34 needs backward computation.
I0929 14:31:54.865813  2305 net.cpp:198] M2PELU32 needs backward computation.
I0929 14:31:54.865815  2305 net.cpp:198] Scale33 needs backward computation.
I0929 14:31:54.865818  2305 net.cpp:198] BatchNorm33 needs backward computation.
I0929 14:31:54.865820  2305 net.cpp:198] Convolution33 needs backward computation.
I0929 14:31:54.865823  2305 net.cpp:198] Eltwise15_M2PELU31_0_split needs backward computation.
I0929 14:31:54.865826  2305 net.cpp:198] M2PELU31 needs backward computation.
I0929 14:31:54.865828  2305 net.cpp:198] Eltwise15 needs backward computation.
I0929 14:31:54.865831  2305 net.cpp:198] Scale32 needs backward computation.
I0929 14:31:54.865834  2305 net.cpp:198] BatchNorm32 needs backward computation.
I0929 14:31:54.865836  2305 net.cpp:198] Convolution32 needs backward computation.
I0929 14:31:54.865839  2305 net.cpp:198] M2PELU30 needs backward computation.
I0929 14:31:54.865841  2305 net.cpp:198] Scale31 needs backward computation.
I0929 14:31:54.865844  2305 net.cpp:198] BatchNorm31 needs backward computation.
I0929 14:31:54.865846  2305 net.cpp:198] Convolution31 needs backward computation.
I0929 14:31:54.865849  2305 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I0929 14:31:54.865852  2305 net.cpp:198] M2PELU29 needs backward computation.
I0929 14:31:54.865854  2305 net.cpp:198] Eltwise14 needs backward computation.
I0929 14:31:54.865857  2305 net.cpp:198] Scale30 needs backward computation.
I0929 14:31:54.865859  2305 net.cpp:198] BatchNorm30 needs backward computation.
I0929 14:31:54.865869  2305 net.cpp:198] Convolution30 needs backward computation.
I0929 14:31:54.865873  2305 net.cpp:198] M2PELU28 needs backward computation.
I0929 14:31:54.865875  2305 net.cpp:198] Scale29 needs backward computation.
I0929 14:31:54.865877  2305 net.cpp:198] BatchNorm29 needs backward computation.
I0929 14:31:54.865880  2305 net.cpp:198] Convolution29 needs backward computation.
I0929 14:31:54.865883  2305 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I0929 14:31:54.865885  2305 net.cpp:198] M2PELU27 needs backward computation.
I0929 14:31:54.865888  2305 net.cpp:198] Eltwise13 needs backward computation.
I0929 14:31:54.865891  2305 net.cpp:198] Scale28 needs backward computation.
I0929 14:31:54.865893  2305 net.cpp:198] BatchNorm28 needs backward computation.
I0929 14:31:54.865896  2305 net.cpp:198] Convolution28 needs backward computation.
I0929 14:31:54.865898  2305 net.cpp:198] M2PELU26 needs backward computation.
I0929 14:31:54.865901  2305 net.cpp:198] Scale27 needs backward computation.
I0929 14:31:54.865903  2305 net.cpp:198] BatchNorm27 needs backward computation.
I0929 14:31:54.865906  2305 net.cpp:198] Convolution27 needs backward computation.
I0929 14:31:54.865908  2305 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I0929 14:31:54.865911  2305 net.cpp:198] M2PELU25 needs backward computation.
I0929 14:31:54.865913  2305 net.cpp:198] Eltwise12 needs backward computation.
I0929 14:31:54.865917  2305 net.cpp:198] Scale26 needs backward computation.
I0929 14:31:54.865919  2305 net.cpp:198] BatchNorm26 needs backward computation.
I0929 14:31:54.865922  2305 net.cpp:198] Convolution26 needs backward computation.
I0929 14:31:54.865924  2305 net.cpp:198] M2PELU24 needs backward computation.
I0929 14:31:54.865927  2305 net.cpp:198] Scale25 needs backward computation.
I0929 14:31:54.865929  2305 net.cpp:198] BatchNorm25 needs backward computation.
I0929 14:31:54.865932  2305 net.cpp:198] Convolution25 needs backward computation.
I0929 14:31:54.865934  2305 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I0929 14:31:54.865937  2305 net.cpp:198] M2PELU23 needs backward computation.
I0929 14:31:54.865939  2305 net.cpp:198] Eltwise11 needs backward computation.
I0929 14:31:54.865942  2305 net.cpp:198] Scale24 needs backward computation.
I0929 14:31:54.865945  2305 net.cpp:198] BatchNorm24 needs backward computation.
I0929 14:31:54.865947  2305 net.cpp:198] Convolution24 needs backward computation.
I0929 14:31:54.865950  2305 net.cpp:198] M2PELU22 needs backward computation.
I0929 14:31:54.865952  2305 net.cpp:198] Scale23 needs backward computation.
I0929 14:31:54.865955  2305 net.cpp:198] BatchNorm23 needs backward computation.
I0929 14:31:54.865957  2305 net.cpp:198] Convolution23 needs backward computation.
I0929 14:31:54.865960  2305 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I0929 14:31:54.865963  2305 net.cpp:198] M2PELU21 needs backward computation.
I0929 14:31:54.865965  2305 net.cpp:198] Eltwise10 needs backward computation.
I0929 14:31:54.865968  2305 net.cpp:198] Scale22 needs backward computation.
I0929 14:31:54.865972  2305 net.cpp:198] BatchNorm22 needs backward computation.
I0929 14:31:54.865974  2305 net.cpp:198] Convolution22 needs backward computation.
I0929 14:31:54.865978  2305 net.cpp:198] M2PELU20 needs backward computation.
I0929 14:31:54.865980  2305 net.cpp:198] Scale21 needs backward computation.
I0929 14:31:54.865983  2305 net.cpp:198] BatchNorm21 needs backward computation.
I0929 14:31:54.865985  2305 net.cpp:198] Convolution21 needs backward computation.
I0929 14:31:54.865988  2305 net.cpp:198] Scale20 needs backward computation.
I0929 14:31:54.865990  2305 net.cpp:198] BatchNorm20 needs backward computation.
I0929 14:31:54.865993  2305 net.cpp:198] Convolution20 needs backward computation.
I0929 14:31:54.865995  2305 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I0929 14:31:54.865998  2305 net.cpp:198] M2PELU19 needs backward computation.
I0929 14:31:54.866000  2305 net.cpp:198] Eltwise9 needs backward computation.
I0929 14:31:54.866008  2305 net.cpp:198] Scale19 needs backward computation.
I0929 14:31:54.866010  2305 net.cpp:198] BatchNorm19 needs backward computation.
I0929 14:31:54.866014  2305 net.cpp:198] Convolution19 needs backward computation.
I0929 14:31:54.866016  2305 net.cpp:198] M2PELU18 needs backward computation.
I0929 14:31:54.866019  2305 net.cpp:198] Scale18 needs backward computation.
I0929 14:31:54.866021  2305 net.cpp:198] BatchNorm18 needs backward computation.
I0929 14:31:54.866024  2305 net.cpp:198] Convolution18 needs backward computation.
I0929 14:31:54.866026  2305 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I0929 14:31:54.866029  2305 net.cpp:198] M2PELU17 needs backward computation.
I0929 14:31:54.866031  2305 net.cpp:198] Eltwise8 needs backward computation.
I0929 14:31:54.866034  2305 net.cpp:198] Scale17 needs backward computation.
I0929 14:31:54.866036  2305 net.cpp:198] BatchNorm17 needs backward computation.
I0929 14:31:54.866039  2305 net.cpp:198] Convolution17 needs backward computation.
I0929 14:31:54.866042  2305 net.cpp:198] M2PELU16 needs backward computation.
I0929 14:31:54.866044  2305 net.cpp:198] Scale16 needs backward computation.
I0929 14:31:54.866046  2305 net.cpp:198] BatchNorm16 needs backward computation.
I0929 14:31:54.866050  2305 net.cpp:198] Convolution16 needs backward computation.
I0929 14:31:54.868340  2305 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I0929 14:31:54.868360  2305 net.cpp:198] M2PELU15 needs backward computation.
I0929 14:31:54.868361  2305 net.cpp:198] Eltwise7 needs backward computation.
I0929 14:31:54.868366  2305 net.cpp:198] Scale15 needs backward computation.
I0929 14:31:54.868367  2305 net.cpp:198] BatchNorm15 needs backward computation.
I0929 14:31:54.868371  2305 net.cpp:198] Convolution15 needs backward computation.
I0929 14:31:54.868372  2305 net.cpp:198] M2PELU14 needs backward computation.
I0929 14:31:54.868376  2305 net.cpp:198] Scale14 needs backward computation.
I0929 14:31:54.868377  2305 net.cpp:198] BatchNorm14 needs backward computation.
I0929 14:31:54.868379  2305 net.cpp:198] Convolution14 needs backward computation.
I0929 14:31:54.868382  2305 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I0929 14:31:54.868386  2305 net.cpp:198] M2PELU13 needs backward computation.
I0929 14:31:54.868387  2305 net.cpp:198] Eltwise6 needs backward computation.
I0929 14:31:54.868391  2305 net.cpp:198] Scale13 needs backward computation.
I0929 14:31:54.868392  2305 net.cpp:198] BatchNorm13 needs backward computation.
I0929 14:31:54.868396  2305 net.cpp:198] Convolution13 needs backward computation.
I0929 14:31:54.868397  2305 net.cpp:198] M2PELU12 needs backward computation.
I0929 14:31:54.868399  2305 net.cpp:198] Scale12 needs backward computation.
I0929 14:31:54.868402  2305 net.cpp:198] BatchNorm12 needs backward computation.
I0929 14:31:54.868404  2305 net.cpp:198] Convolution12 needs backward computation.
I0929 14:31:54.868407  2305 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I0929 14:31:54.868409  2305 net.cpp:198] M2PELU11 needs backward computation.
I0929 14:31:54.868412  2305 net.cpp:198] Eltwise5 needs backward computation.
I0929 14:31:54.868415  2305 net.cpp:198] Scale11 needs backward computation.
I0929 14:31:54.868417  2305 net.cpp:198] BatchNorm11 needs backward computation.
I0929 14:31:54.868420  2305 net.cpp:198] Convolution11 needs backward computation.
I0929 14:31:54.868422  2305 net.cpp:198] M2PELU10 needs backward computation.
I0929 14:31:54.868425  2305 net.cpp:198] Scale10 needs backward computation.
I0929 14:31:54.868427  2305 net.cpp:198] BatchNorm10 needs backward computation.
I0929 14:31:54.868429  2305 net.cpp:198] Convolution10 needs backward computation.
I0929 14:31:54.868432  2305 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I0929 14:31:54.868435  2305 net.cpp:198] M2PELU9 needs backward computation.
I0929 14:31:54.868438  2305 net.cpp:198] Eltwise4 needs backward computation.
I0929 14:31:54.868448  2305 net.cpp:198] Scale9 needs backward computation.
I0929 14:31:54.868451  2305 net.cpp:198] BatchNorm9 needs backward computation.
I0929 14:31:54.868454  2305 net.cpp:198] Convolution9 needs backward computation.
I0929 14:31:54.868456  2305 net.cpp:198] M2PELU8 needs backward computation.
I0929 14:31:54.868459  2305 net.cpp:198] Scale8 needs backward computation.
I0929 14:31:54.868461  2305 net.cpp:198] BatchNorm8 needs backward computation.
I0929 14:31:54.868464  2305 net.cpp:198] Convolution8 needs backward computation.
I0929 14:31:54.868468  2305 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I0929 14:31:54.868470  2305 net.cpp:198] M2PELU7 needs backward computation.
I0929 14:31:54.868472  2305 net.cpp:198] Eltwise3 needs backward computation.
I0929 14:31:54.868475  2305 net.cpp:198] Scale7 needs backward computation.
I0929 14:31:54.868477  2305 net.cpp:198] BatchNorm7 needs backward computation.
I0929 14:31:54.868479  2305 net.cpp:198] Convolution7 needs backward computation.
I0929 14:31:54.868482  2305 net.cpp:198] M2PELU6 needs backward computation.
I0929 14:31:54.868484  2305 net.cpp:198] Scale6 needs backward computation.
I0929 14:31:54.868486  2305 net.cpp:198] BatchNorm6 needs backward computation.
I0929 14:31:54.868489  2305 net.cpp:198] Convolution6 needs backward computation.
I0929 14:31:54.868492  2305 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I0929 14:31:54.868494  2305 net.cpp:198] M2PELU5 needs backward computation.
I0929 14:31:54.868497  2305 net.cpp:198] Eltwise2 needs backward computation.
I0929 14:31:54.868500  2305 net.cpp:198] Scale5 needs backward computation.
I0929 14:31:54.868502  2305 net.cpp:198] BatchNorm5 needs backward computation.
I0929 14:31:54.868505  2305 net.cpp:198] Convolution5 needs backward computation.
I0929 14:31:54.868507  2305 net.cpp:198] M2PELU4 needs backward computation.
I0929 14:31:54.868510  2305 net.cpp:198] Scale4 needs backward computation.
I0929 14:31:54.868512  2305 net.cpp:198] BatchNorm4 needs backward computation.
I0929 14:31:54.868515  2305 net.cpp:198] Convolution4 needs backward computation.
I0929 14:31:54.868517  2305 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I0929 14:31:54.868520  2305 net.cpp:198] M2PELU3 needs backward computation.
I0929 14:31:54.868522  2305 net.cpp:198] Eltwise1 needs backward computation.
I0929 14:31:54.868525  2305 net.cpp:198] Scale3 needs backward computation.
I0929 14:31:54.868527  2305 net.cpp:198] BatchNorm3 needs backward computation.
I0929 14:31:54.868530  2305 net.cpp:198] Convolution3 needs backward computation.
I0929 14:31:54.868532  2305 net.cpp:198] M2PELU2 needs backward computation.
I0929 14:31:54.868535  2305 net.cpp:198] Scale2 needs backward computation.
I0929 14:31:54.868537  2305 net.cpp:198] BatchNorm2 needs backward computation.
I0929 14:31:54.868541  2305 net.cpp:198] Convolution2 needs backward computation.
I0929 14:31:54.868543  2305 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I0929 14:31:54.868546  2305 net.cpp:198] M2PELU1 needs backward computation.
I0929 14:31:54.868548  2305 net.cpp:198] Scale1 needs backward computation.
I0929 14:31:54.868551  2305 net.cpp:198] BatchNorm1 needs backward computation.
I0929 14:31:54.868552  2305 net.cpp:198] Convolution1 needs backward computation.
I0929 14:31:54.868557  2305 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0929 14:31:54.868561  2305 net.cpp:200] Data1 does not need backward computation.
I0929 14:31:54.868563  2305 net.cpp:242] This network produces output Accuracy1
I0929 14:31:54.868566  2305 net.cpp:242] This network produces output SoftmaxWithLoss1
I0929 14:31:54.868665  2305 net.cpp:255] Network initialization done.
I0929 14:31:54.869490  2305 solver.cpp:56] Solver scaffolding done.
I0929 14:31:54.882274  2305 caffe.cpp:248] Starting Optimization
I0929 14:31:54.882282  2305 solver.cpp:272] Solving resnet_cifar10
I0929 14:31:54.882284  2305 solver.cpp:273] Learning Rate Policy: multistep
I0929 14:31:54.888298  2305 solver.cpp:330] Iteration 0, Testing net (#0)
I0929 14:31:58.337167  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:31:58.476706  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0929 14:31:58.476742  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0929 14:31:58.675261  2305 solver.cpp:218] Iteration 0 (0 iter/s, 3.79288s/100 iters), loss = 2.291
I0929 14:31:58.675289  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.291 (* 1 = 2.291 loss)
I0929 14:31:58.675305  2305 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0929 14:32:12.899268  2305 solver.cpp:218] Iteration 100 (7.03045 iter/s, 14.2238s/100 iters), loss = 2.0703
I0929 14:32:12.899300  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.0703 (* 1 = 2.0703 loss)
I0929 14:32:12.899307  2305 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0929 14:32:27.099105  2305 solver.cpp:218] Iteration 200 (7.04242 iter/s, 14.1997s/100 iters), loss = 2.05128
I0929 14:32:27.099310  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.05128 (* 1 = 2.05128 loss)
I0929 14:32:27.099318  2305 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0929 14:32:41.303480  2305 solver.cpp:218] Iteration 300 (7.04025 iter/s, 14.204s/100 iters), loss = 1.7569
I0929 14:32:41.303508  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.7569 (* 1 = 1.7569 loss)
I0929 14:32:41.303514  2305 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0929 14:32:55.507113  2305 solver.cpp:218] Iteration 400 (7.04053 iter/s, 14.2035s/100 iters), loss = 1.58356
I0929 14:32:55.507143  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.58356 (* 1 = 1.58356 loss)
I0929 14:32:55.507148  2305 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0929 14:33:09.005313  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:33:09.576789  2305 solver.cpp:330] Iteration 500, Testing net (#0)
I0929 14:33:12.925999  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:33:13.065937  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3017
I0929 14:33:13.065973  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.91884 (* 1 = 1.91884 loss)
I0929 14:33:13.209282  2305 solver.cpp:218] Iteration 500 (5.64909 iter/s, 17.702s/100 iters), loss = 1.77655
I0929 14:33:13.209316  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.77655 (* 1 = 1.77655 loss)
I0929 14:33:13.209322  2305 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0929 14:33:27.433153  2305 solver.cpp:218] Iteration 600 (7.03052 iter/s, 14.2237s/100 iters), loss = 1.53664
I0929 14:33:27.433202  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.53664 (* 1 = 1.53664 loss)
I0929 14:33:27.433209  2305 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0929 14:33:41.677752  2305 solver.cpp:218] Iteration 700 (7.02031 iter/s, 14.2444s/100 iters), loss = 1.51245
I0929 14:33:41.677892  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.51245 (* 1 = 1.51245 loss)
I0929 14:33:41.677901  2305 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0929 14:33:55.913319  2305 solver.cpp:218] Iteration 800 (7.02479 iter/s, 14.2353s/100 iters), loss = 1.34336
I0929 14:33:55.913349  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.34336 (* 1 = 1.34336 loss)
I0929 14:33:55.913355  2305 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0929 14:34:10.154484  2305 solver.cpp:218] Iteration 900 (7.02198 iter/s, 14.241s/100 iters), loss = 1.18767
I0929 14:34:10.154513  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.18767 (* 1 = 1.18767 loss)
I0929 14:34:10.154522  2305 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0929 14:34:23.692348  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:34:24.259500  2305 solver.cpp:330] Iteration 1000, Testing net (#0)
I0929 14:34:27.671586  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:34:27.814388  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2555
I0929 14:34:27.814417  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.51696 (* 1 = 2.51696 loss)
I0929 14:34:27.959584  2305 solver.cpp:218] Iteration 1000 (5.61642 iter/s, 17.8049s/100 iters), loss = 1.12519
I0929 14:34:27.959616  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12519 (* 1 = 1.12519 loss)
I0929 14:34:27.959623  2305 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0929 14:34:42.257885  2305 solver.cpp:218] Iteration 1100 (6.99391 iter/s, 14.2981s/100 iters), loss = 1.10602
I0929 14:34:42.257918  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10602 (* 1 = 1.10602 loss)
I0929 14:34:42.257925  2305 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0929 14:34:56.663998  2305 solver.cpp:218] Iteration 1200 (6.94157 iter/s, 14.406s/100 iters), loss = 0.903254
I0929 14:34:56.664161  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.903254 (* 1 = 0.903254 loss)
I0929 14:34:56.664180  2305 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0929 14:35:10.932654  2305 solver.cpp:218] Iteration 1300 (7.0085 iter/s, 14.2684s/100 iters), loss = 0.924335
I0929 14:35:10.932684  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.924335 (* 1 = 0.924335 loss)
I0929 14:35:10.932690  2305 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0929 14:35:25.346629  2305 solver.cpp:218] Iteration 1400 (6.93778 iter/s, 14.4138s/100 iters), loss = 0.819188
I0929 14:35:25.346669  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.819188 (* 1 = 0.819188 loss)
I0929 14:35:25.346676  2305 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0929 14:35:38.896114  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:35:39.468016  2305 solver.cpp:330] Iteration 1500, Testing net (#0)
I0929 14:35:42.853549  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:35:42.994186  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4595
I0929 14:35:42.994212  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.66731 (* 1 = 1.66731 loss)
I0929 14:35:43.135143  2305 solver.cpp:218] Iteration 1500 (5.62166 iter/s, 17.7883s/100 iters), loss = 0.951333
I0929 14:35:43.135174  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.951333 (* 1 = 0.951333 loss)
I0929 14:35:43.135181  2305 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0929 14:35:57.386806  2305 solver.cpp:218] Iteration 1600 (7.01679 iter/s, 14.2515s/100 iters), loss = 0.634909
I0929 14:35:57.386850  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.634909 (* 1 = 0.634909 loss)
I0929 14:35:57.386857  2305 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0929 14:36:11.630223  2305 solver.cpp:218] Iteration 1700 (7.02087 iter/s, 14.2433s/100 iters), loss = 0.814281
I0929 14:36:11.630331  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.814281 (* 1 = 0.814281 loss)
I0929 14:36:11.630339  2305 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0929 14:36:25.873859  2305 solver.cpp:218] Iteration 1800 (7.02077 iter/s, 14.2434s/100 iters), loss = 0.729703
I0929 14:36:25.873891  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.729703 (* 1 = 0.729703 loss)
I0929 14:36:25.873898  2305 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0929 14:36:40.120220  2305 solver.cpp:218] Iteration 1900 (7.01939 iter/s, 14.2463s/100 iters), loss = 0.66709
I0929 14:36:40.120252  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.66709 (* 1 = 0.66709 loss)
I0929 14:36:40.120259  2305 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0929 14:36:53.651051  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:36:54.218380  2305 solver.cpp:330] Iteration 2000, Testing net (#0)
I0929 14:36:57.577486  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:36:57.720361  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.482
I0929 14:36:57.720391  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.43223 (* 1 = 1.43223 loss)
I0929 14:36:57.861559  2305 solver.cpp:218] Iteration 2000 (5.63659 iter/s, 17.7412s/100 iters), loss = 0.865931
I0929 14:36:57.861603  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.865931 (* 1 = 0.865931 loss)
I0929 14:36:57.861610  2305 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0929 14:37:12.093538  2305 solver.cpp:218] Iteration 2100 (7.02648 iter/s, 14.2319s/100 iters), loss = 0.535484
I0929 14:37:12.093569  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535484 (* 1 = 0.535484 loss)
I0929 14:37:12.093575  2305 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0929 14:37:26.337932  2305 solver.cpp:218] Iteration 2200 (7.02035 iter/s, 14.2443s/100 iters), loss = 0.574338
I0929 14:37:26.338050  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.574338 (* 1 = 0.574338 loss)
I0929 14:37:26.338059  2305 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0929 14:37:40.584470  2305 solver.cpp:218] Iteration 2300 (7.01934 iter/s, 14.2464s/100 iters), loss = 0.611507
I0929 14:37:40.584499  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.611507 (* 1 = 0.611507 loss)
I0929 14:37:40.584506  2305 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0929 14:37:54.820045  2305 solver.cpp:218] Iteration 2400 (7.0247 iter/s, 14.2355s/100 iters), loss = 0.641832
I0929 14:37:54.820078  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.641832 (* 1 = 0.641832 loss)
I0929 14:37:54.820086  2305 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0929 14:38:08.350476  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:38:08.919361  2305 solver.cpp:330] Iteration 2500, Testing net (#0)
I0929 14:38:12.275133  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:38:12.416426  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4194
I0929 14:38:12.416456  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.9091 (* 1 = 1.9091 loss)
I0929 14:38:12.562265  2305 solver.cpp:218] Iteration 2500 (5.63631 iter/s, 17.7421s/100 iters), loss = 0.73137
I0929 14:38:12.562309  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.73137 (* 1 = 0.73137 loss)
I0929 14:38:12.562316  2305 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0929 14:38:26.800297  2305 solver.cpp:218] Iteration 2600 (7.02357 iter/s, 14.2378s/100 iters), loss = 0.486527
I0929 14:38:26.800338  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486527 (* 1 = 0.486527 loss)
I0929 14:38:26.800344  2305 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0929 14:38:41.035725  2305 solver.cpp:218] Iteration 2700 (7.02477 iter/s, 14.2353s/100 iters), loss = 0.626779
I0929 14:38:41.035872  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.626779 (* 1 = 0.626779 loss)
I0929 14:38:41.035881  2305 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0929 14:38:55.281101  2305 solver.cpp:218] Iteration 2800 (7.01992 iter/s, 14.2452s/100 iters), loss = 0.573103
I0929 14:38:55.281134  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.573103 (* 1 = 0.573103 loss)
I0929 14:38:55.281141  2305 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0929 14:39:09.522593  2305 solver.cpp:218] Iteration 2900 (7.02178 iter/s, 14.2414s/100 iters), loss = 0.544624
I0929 14:39:09.522629  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.544624 (* 1 = 0.544624 loss)
I0929 14:39:09.522636  2305 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0929 14:39:23.056641  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:39:23.624044  2305 solver.cpp:330] Iteration 3000, Testing net (#0)
I0929 14:39:26.978293  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:39:27.117871  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.436
I0929 14:39:27.117897  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.79488 (* 1 = 1.79488 loss)
I0929 14:39:27.258635  2305 solver.cpp:218] Iteration 3000 (5.63827 iter/s, 17.7359s/100 iters), loss = 0.615369
I0929 14:39:27.258669  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.615369 (* 1 = 0.615369 loss)
I0929 14:39:27.258677  2305 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0929 14:39:41.494827  2305 solver.cpp:218] Iteration 3100 (7.0244 iter/s, 14.2361s/100 iters), loss = 0.405423
I0929 14:39:41.494869  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405423 (* 1 = 0.405423 loss)
I0929 14:39:41.494875  2305 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0929 14:39:55.735589  2305 solver.cpp:218] Iteration 3200 (7.02214 iter/s, 14.2407s/100 iters), loss = 0.591171
I0929 14:39:55.735711  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.591171 (* 1 = 0.591171 loss)
I0929 14:39:55.735719  2305 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0929 14:40:09.967277  2305 solver.cpp:218] Iteration 3300 (7.02666 iter/s, 14.2315s/100 iters), loss = 0.580616
I0929 14:40:09.967319  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.580616 (* 1 = 0.580616 loss)
I0929 14:40:09.967327  2305 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0929 14:40:24.191766  2305 solver.cpp:218] Iteration 3400 (7.03018 iter/s, 14.2244s/100 iters), loss = 0.506675
I0929 14:40:24.191803  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.506675 (* 1 = 0.506675 loss)
I0929 14:40:24.191812  2305 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0929 14:40:37.724529  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:40:38.292865  2305 solver.cpp:330] Iteration 3500, Testing net (#0)
I0929 14:40:41.652740  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:40:41.792531  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5166
I0929 14:40:41.792567  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36753 (* 1 = 1.36753 loss)
I0929 14:40:41.933904  2305 solver.cpp:218] Iteration 3500 (5.63633 iter/s, 17.742s/100 iters), loss = 0.597549
I0929 14:40:41.933938  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.597549 (* 1 = 0.597549 loss)
I0929 14:40:41.933945  2305 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0929 14:40:56.196146  2305 solver.cpp:218] Iteration 3600 (7.01156 iter/s, 14.2622s/100 iters), loss = 0.441558
I0929 14:40:56.196177  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441558 (* 1 = 0.441558 loss)
I0929 14:40:56.196183  2305 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0929 14:41:10.447202  2305 solver.cpp:218] Iteration 3700 (7.01706 iter/s, 14.251s/100 iters), loss = 0.509076
I0929 14:41:10.447321  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509076 (* 1 = 0.509076 loss)
I0929 14:41:10.447329  2305 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0929 14:41:24.711832  2305 solver.cpp:218] Iteration 3800 (7.01043 iter/s, 14.2645s/100 iters), loss = 0.544958
I0929 14:41:24.711868  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.544958 (* 1 = 0.544958 loss)
I0929 14:41:24.711874  2305 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0929 14:41:38.962702  2305 solver.cpp:218] Iteration 3900 (7.01716 iter/s, 14.2508s/100 iters), loss = 0.453621
I0929 14:41:38.962733  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453621 (* 1 = 0.453621 loss)
I0929 14:41:38.962739  2305 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0929 14:41:52.512737  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:41:53.082842  2305 solver.cpp:330] Iteration 4000, Testing net (#0)
I0929 14:41:56.441179  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:41:56.581243  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5235
I0929 14:41:56.581279  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.42742 (* 1 = 1.42742 loss)
I0929 14:41:56.721585  2305 solver.cpp:218] Iteration 4000 (5.63101 iter/s, 17.7588s/100 iters), loss = 0.49843
I0929 14:41:56.721616  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.49843 (* 1 = 0.49843 loss)
I0929 14:41:56.721623  2305 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0929 14:42:10.984179  2305 solver.cpp:218] Iteration 4100 (7.01139 iter/s, 14.2625s/100 iters), loss = 0.417498
I0929 14:42:10.984210  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417498 (* 1 = 0.417498 loss)
I0929 14:42:10.984215  2305 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0929 14:42:25.244850  2305 solver.cpp:218] Iteration 4200 (7.01233 iter/s, 14.2606s/100 iters), loss = 0.409993
I0929 14:42:25.245028  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409993 (* 1 = 0.409993 loss)
I0929 14:42:25.245038  2305 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0929 14:42:39.494319  2305 solver.cpp:218] Iteration 4300 (7.01791 iter/s, 14.2493s/100 iters), loss = 0.556354
I0929 14:42:39.494366  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.556354 (* 1 = 0.556354 loss)
I0929 14:42:39.494374  2305 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0929 14:42:53.752620  2305 solver.cpp:218] Iteration 4400 (7.01353 iter/s, 14.2582s/100 iters), loss = 0.429593
I0929 14:42:53.752650  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429593 (* 1 = 0.429593 loss)
I0929 14:42:53.752656  2305 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0929 14:43:07.313652  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:43:07.882160  2305 solver.cpp:330] Iteration 4500, Testing net (#0)
I0929 14:43:11.240514  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:43:11.380278  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5948
I0929 14:43:11.380313  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.27775 (* 1 = 1.27775 loss)
I0929 14:43:11.520954  2305 solver.cpp:218] Iteration 4500 (5.62802 iter/s, 17.7682s/100 iters), loss = 0.387072
I0929 14:43:11.520988  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387072 (* 1 = 0.387072 loss)
I0929 14:43:11.520995  2305 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0929 14:43:25.772176  2305 solver.cpp:218] Iteration 4600 (7.01699 iter/s, 14.2511s/100 iters), loss = 0.371571
I0929 14:43:25.772207  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371571 (* 1 = 0.371571 loss)
I0929 14:43:25.772212  2305 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0929 14:43:40.025858  2305 solver.cpp:218] Iteration 4700 (7.01577 iter/s, 14.2536s/100 iters), loss = 0.363885
I0929 14:43:40.025998  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363885 (* 1 = 0.363885 loss)
I0929 14:43:40.026006  2305 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0929 14:43:54.274179  2305 solver.cpp:218] Iteration 4800 (7.01846 iter/s, 14.2481s/100 iters), loss = 0.421099
I0929 14:43:54.274211  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421099 (* 1 = 0.421099 loss)
I0929 14:43:54.274219  2305 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0929 14:44:08.527420  2305 solver.cpp:218] Iteration 4900 (7.01599 iter/s, 14.2532s/100 iters), loss = 0.402364
I0929 14:44:08.527451  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402364 (* 1 = 0.402364 loss)
I0929 14:44:08.527457  2305 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0929 14:44:22.070812  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:44:22.640543  2305 solver.cpp:330] Iteration 5000, Testing net (#0)
I0929 14:44:25.999181  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:44:26.138983  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5924
I0929 14:44:26.139017  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26594 (* 1 = 1.26594 loss)
I0929 14:44:26.279219  2305 solver.cpp:218] Iteration 5000 (5.63326 iter/s, 17.7517s/100 iters), loss = 0.433031
I0929 14:44:26.279270  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433031 (* 1 = 0.433031 loss)
I0929 14:44:26.279278  2305 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0929 14:44:40.539501  2305 solver.cpp:218] Iteration 5100 (7.01254 iter/s, 14.2602s/100 iters), loss = 0.39095
I0929 14:44:40.539535  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39095 (* 1 = 0.39095 loss)
I0929 14:44:40.539542  2305 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0929 14:44:54.801153  2305 solver.cpp:218] Iteration 5200 (7.01185 iter/s, 14.2616s/100 iters), loss = 0.437136
I0929 14:44:54.801321  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437136 (* 1 = 0.437136 loss)
I0929 14:44:54.801339  2305 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0929 14:45:09.043095  2305 solver.cpp:218] Iteration 5300 (7.02161 iter/s, 14.2417s/100 iters), loss = 0.499211
I0929 14:45:09.043125  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.499211 (* 1 = 0.499211 loss)
I0929 14:45:09.043133  2305 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0929 14:45:23.304682  2305 solver.cpp:218] Iteration 5400 (7.01188 iter/s, 14.2615s/100 iters), loss = 0.424885
I0929 14:45:23.304713  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424885 (* 1 = 0.424885 loss)
I0929 14:45:23.304718  2305 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0929 14:45:36.858129  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:45:37.426570  2305 solver.cpp:330] Iteration 5500, Testing net (#0)
I0929 14:45:40.786072  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:45:40.926120  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7091
I0929 14:45:40.926154  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.821012 (* 1 = 0.821012 loss)
I0929 14:45:41.066766  2305 solver.cpp:218] Iteration 5500 (5.63 iter/s, 17.762s/100 iters), loss = 0.394641
I0929 14:45:41.066800  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394641 (* 1 = 0.394641 loss)
I0929 14:45:41.066807  2305 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0929 14:45:55.316211  2305 solver.cpp:218] Iteration 5600 (7.01786 iter/s, 14.2494s/100 iters), loss = 0.43378
I0929 14:45:55.316242  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43378 (* 1 = 0.43378 loss)
I0929 14:45:55.316248  2305 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0929 14:46:09.563467  2305 solver.cpp:218] Iteration 5700 (7.01894 iter/s, 14.2472s/100 iters), loss = 0.421648
I0929 14:46:09.563613  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421648 (* 1 = 0.421648 loss)
I0929 14:46:09.563632  2305 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0929 14:46:23.817935  2305 solver.cpp:218] Iteration 5800 (7.01544 iter/s, 14.2543s/100 iters), loss = 0.35034
I0929 14:46:23.817965  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35034 (* 1 = 0.35034 loss)
I0929 14:46:23.817971  2305 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0929 14:46:38.073384  2305 solver.cpp:218] Iteration 5900 (7.0149 iter/s, 14.2554s/100 iters), loss = 0.441098
I0929 14:46:38.073415  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441098 (* 1 = 0.441098 loss)
I0929 14:46:38.073422  2305 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0929 14:46:51.607206  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:46:52.179663  2305 solver.cpp:330] Iteration 6000, Testing net (#0)
I0929 14:46:55.535933  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:46:55.676079  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6092
I0929 14:46:55.676115  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.16487 (* 1 = 1.16487 loss)
I0929 14:46:55.816371  2305 solver.cpp:218] Iteration 6000 (5.63606 iter/s, 17.7429s/100 iters), loss = 0.411046
I0929 14:46:55.816401  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411046 (* 1 = 0.411046 loss)
I0929 14:46:55.816408  2305 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0929 14:47:10.078203  2305 solver.cpp:218] Iteration 6100 (7.01176 iter/s, 14.2618s/100 iters), loss = 0.259315
I0929 14:47:10.078238  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259315 (* 1 = 0.259315 loss)
I0929 14:47:10.078244  2305 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0929 14:47:24.329464  2305 solver.cpp:218] Iteration 6200 (7.01696 iter/s, 14.2512s/100 iters), loss = 0.371072
I0929 14:47:24.329630  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371072 (* 1 = 0.371072 loss)
I0929 14:47:24.329641  2305 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0929 14:47:38.585932  2305 solver.cpp:218] Iteration 6300 (7.01446 iter/s, 14.2563s/100 iters), loss = 0.456468
I0929 14:47:38.585963  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456468 (* 1 = 0.456468 loss)
I0929 14:47:38.585970  2305 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0929 14:47:52.847265  2305 solver.cpp:218] Iteration 6400 (7.01201 iter/s, 14.2613s/100 iters), loss = 0.342783
I0929 14:47:52.847293  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342783 (* 1 = 0.342783 loss)
I0929 14:47:52.847301  2305 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0929 14:48:06.399590  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:48:06.976835  2305 solver.cpp:330] Iteration 6500, Testing net (#0)
I0929 14:48:10.334859  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:48:10.475044  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6734
I0929 14:48:10.475069  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01748 (* 1 = 1.01748 loss)
I0929 14:48:10.615950  2305 solver.cpp:218] Iteration 6500 (5.62791 iter/s, 17.7686s/100 iters), loss = 0.409453
I0929 14:48:10.615983  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409453 (* 1 = 0.409453 loss)
I0929 14:48:10.615990  2305 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0929 14:48:24.862241  2305 solver.cpp:218] Iteration 6600 (7.01941 iter/s, 14.2462s/100 iters), loss = 0.324464
I0929 14:48:24.862275  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324463 (* 1 = 0.324463 loss)
I0929 14:48:24.862283  2305 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0929 14:48:39.109311  2305 solver.cpp:218] Iteration 6700 (7.01903 iter/s, 14.247s/100 iters), loss = 0.44156
I0929 14:48:39.109426  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.44156 (* 1 = 0.44156 loss)
I0929 14:48:39.109443  2305 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0929 14:48:53.361521  2305 solver.cpp:218] Iteration 6800 (7.01653 iter/s, 14.2521s/100 iters), loss = 0.462801
I0929 14:48:53.361551  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462801 (* 1 = 0.462801 loss)
I0929 14:48:53.361557  2305 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0929 14:49:07.612018  2305 solver.cpp:218] Iteration 6900 (7.01734 iter/s, 14.2504s/100 iters), loss = 0.367823
I0929 14:49:07.612051  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367823 (* 1 = 0.367823 loss)
I0929 14:49:07.612057  2305 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0929 14:49:21.151437  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:49:21.729244  2305 solver.cpp:330] Iteration 7000, Testing net (#0)
I0929 14:49:25.087278  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:49:25.226907  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7292
I0929 14:49:25.226943  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.747273 (* 1 = 0.747273 loss)
I0929 14:49:25.368183  2305 solver.cpp:218] Iteration 7000 (5.63188 iter/s, 17.7561s/100 iters), loss = 0.349287
I0929 14:49:25.368216  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349287 (* 1 = 0.349287 loss)
I0929 14:49:25.368223  2305 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0929 14:49:39.624404  2305 solver.cpp:218] Iteration 7100 (7.01452 iter/s, 14.2561s/100 iters), loss = 0.403233
I0929 14:49:39.624452  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403233 (* 1 = 0.403233 loss)
I0929 14:49:39.624460  2305 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0929 14:49:53.870362  2305 solver.cpp:218] Iteration 7200 (7.0196 iter/s, 14.2458s/100 iters), loss = 0.344459
I0929 14:49:53.870468  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344459 (* 1 = 0.344459 loss)
I0929 14:49:53.870476  2305 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0929 14:50:08.126612  2305 solver.cpp:218] Iteration 7300 (7.01454 iter/s, 14.2561s/100 iters), loss = 0.483997
I0929 14:50:08.126642  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.483997 (* 1 = 0.483997 loss)
I0929 14:50:08.126648  2305 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0929 14:50:22.389027  2305 solver.cpp:218] Iteration 7400 (7.01147 iter/s, 14.2623s/100 iters), loss = 0.336558
I0929 14:50:22.389060  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336558 (* 1 = 0.336558 loss)
I0929 14:50:22.389067  2305 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0929 14:50:35.932662  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:50:36.502190  2305 solver.cpp:330] Iteration 7500, Testing net (#0)
I0929 14:50:39.865947  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:50:40.005620  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6863
I0929 14:50:40.005656  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.866263 (* 1 = 0.866263 loss)
I0929 14:50:40.146746  2305 solver.cpp:218] Iteration 7500 (5.63138 iter/s, 17.7576s/100 iters), loss = 0.486912
I0929 14:50:40.146780  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486912 (* 1 = 0.486912 loss)
I0929 14:50:40.146786  2305 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0929 14:50:54.396257  2305 solver.cpp:218] Iteration 7600 (7.01782 iter/s, 14.2494s/100 iters), loss = 0.255817
I0929 14:50:54.396298  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255817 (* 1 = 0.255817 loss)
I0929 14:50:54.396306  2305 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0929 14:51:08.663332  2305 solver.cpp:218] Iteration 7700 (7.00919 iter/s, 14.267s/100 iters), loss = 0.501213
I0929 14:51:08.663475  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501213 (* 1 = 0.501213 loss)
I0929 14:51:08.663482  2305 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0929 14:51:22.923614  2305 solver.cpp:218] Iteration 7800 (7.01257 iter/s, 14.2601s/100 iters), loss = 0.401701
I0929 14:51:22.923645  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401701 (* 1 = 0.401701 loss)
I0929 14:51:22.923650  2305 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0929 14:51:37.178529  2305 solver.cpp:218] Iteration 7900 (7.01516 iter/s, 14.2548s/100 iters), loss = 0.270305
I0929 14:51:37.178563  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270305 (* 1 = 0.270305 loss)
I0929 14:51:37.178571  2305 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0929 14:51:50.729204  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:51:51.297004  2305 solver.cpp:330] Iteration 8000, Testing net (#0)
I0929 14:51:54.664610  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:51:54.807070  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6261
I0929 14:51:54.807106  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.17229 (* 1 = 1.17229 loss)
I0929 14:51:54.947943  2305 solver.cpp:218] Iteration 8000 (5.62768 iter/s, 17.7693s/100 iters), loss = 0.380119
I0929 14:51:54.947978  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380119 (* 1 = 0.380119 loss)
I0929 14:51:54.947985  2305 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0929 14:52:09.191161  2305 solver.cpp:218] Iteration 8100 (7.02092 iter/s, 14.2431s/100 iters), loss = 0.27042
I0929 14:52:09.191191  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27042 (* 1 = 0.27042 loss)
I0929 14:52:09.191197  2305 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0929 14:52:23.436318  2305 solver.cpp:218] Iteration 8200 (7.01997 iter/s, 14.2451s/100 iters), loss = 0.282261
I0929 14:52:23.436429  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282261 (* 1 = 0.282261 loss)
I0929 14:52:23.436446  2305 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0929 14:52:37.687482  2305 solver.cpp:218] Iteration 8300 (7.01704 iter/s, 14.251s/100 iters), loss = 0.301138
I0929 14:52:37.687522  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301137 (* 1 = 0.301137 loss)
I0929 14:52:37.687528  2305 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0929 14:52:51.942744  2305 solver.cpp:218] Iteration 8400 (7.01499 iter/s, 14.2552s/100 iters), loss = 0.317929
I0929 14:52:51.942777  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317928 (* 1 = 0.317928 loss)
I0929 14:52:51.942785  2305 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0929 14:53:05.474220  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:53:06.042284  2305 solver.cpp:330] Iteration 8500, Testing net (#0)
I0929 14:53:09.396862  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:53:09.538286  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7078
I0929 14:53:09.538316  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.897738 (* 1 = 0.897738 loss)
I0929 14:53:09.682867  2305 solver.cpp:218] Iteration 8500 (5.63697 iter/s, 17.74s/100 iters), loss = 0.339137
I0929 14:53:09.682902  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339137 (* 1 = 0.339137 loss)
I0929 14:53:09.682910  2305 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0929 14:53:23.936589  2305 solver.cpp:218] Iteration 8600 (7.01575 iter/s, 14.2536s/100 iters), loss = 0.280204
I0929 14:53:23.936630  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280204 (* 1 = 0.280204 loss)
I0929 14:53:23.936636  2305 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0929 14:53:38.202457  2305 solver.cpp:218] Iteration 8700 (7.00978 iter/s, 14.2658s/100 iters), loss = 0.30833
I0929 14:53:38.202602  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30833 (* 1 = 0.30833 loss)
I0929 14:53:38.202610  2305 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0929 14:53:52.453280  2305 solver.cpp:218] Iteration 8800 (7.01723 iter/s, 14.2506s/100 iters), loss = 0.26619
I0929 14:53:52.453315  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26619 (* 1 = 0.26619 loss)
I0929 14:53:52.453323  2305 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0929 14:54:06.703421  2305 solver.cpp:218] Iteration 8900 (7.01751 iter/s, 14.2501s/100 iters), loss = 0.318239
I0929 14:54:06.703467  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318239 (* 1 = 0.318239 loss)
I0929 14:54:06.703474  2305 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0929 14:54:20.245929  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:54:20.814693  2305 solver.cpp:330] Iteration 9000, Testing net (#0)
I0929 14:54:24.173774  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:54:24.313760  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6997
I0929 14:54:24.313796  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.89383 (* 1 = 0.89383 loss)
I0929 14:54:24.454782  2305 solver.cpp:218] Iteration 9000 (5.63341 iter/s, 17.7512s/100 iters), loss = 0.358349
I0929 14:54:24.454813  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358349 (* 1 = 0.358349 loss)
I0929 14:54:24.454820  2305 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0929 14:54:38.716061  2305 solver.cpp:218] Iteration 9100 (7.01203 iter/s, 14.2612s/100 iters), loss = 0.290414
I0929 14:54:38.716102  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290414 (* 1 = 0.290414 loss)
I0929 14:54:38.716109  2305 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0929 14:54:52.970249  2305 solver.cpp:218] Iteration 9200 (7.01552 iter/s, 14.2541s/100 iters), loss = 0.307204
I0929 14:54:52.970368  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307204 (* 1 = 0.307204 loss)
I0929 14:54:52.970386  2305 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0929 14:55:07.234551  2305 solver.cpp:218] Iteration 9300 (7.01058 iter/s, 14.2641s/100 iters), loss = 0.34185
I0929 14:55:07.234586  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34185 (* 1 = 0.34185 loss)
I0929 14:55:07.234593  2305 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0929 14:55:21.486999  2305 solver.cpp:218] Iteration 9400 (7.01638 iter/s, 14.2524s/100 iters), loss = 0.272665
I0929 14:55:21.487030  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272665 (* 1 = 0.272665 loss)
I0929 14:55:21.487035  2305 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0929 14:55:35.034443  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:55:35.602412  2305 solver.cpp:330] Iteration 9500, Testing net (#0)
I0929 14:55:38.956771  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:55:39.096750  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7387
I0929 14:55:39.096786  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.805673 (* 1 = 0.805673 loss)
I0929 14:55:39.237831  2305 solver.cpp:218] Iteration 9500 (5.63357 iter/s, 17.7507s/100 iters), loss = 0.202118
I0929 14:55:39.237864  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202118 (* 1 = 0.202118 loss)
I0929 14:55:39.237870  2305 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0929 14:55:53.495088  2305 solver.cpp:218] Iteration 9600 (7.01401 iter/s, 14.2572s/100 iters), loss = 0.225475
I0929 14:55:53.495118  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225475 (* 1 = 0.225475 loss)
I0929 14:55:53.495124  2305 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0929 14:56:07.750382  2305 solver.cpp:218] Iteration 9700 (7.01497 iter/s, 14.2552s/100 iters), loss = 0.311941
I0929 14:56:07.750530  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31194 (* 1 = 0.31194 loss)
I0929 14:56:07.750547  2305 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0929 14:56:21.995615  2305 solver.cpp:218] Iteration 9800 (7.01998 iter/s, 14.2451s/100 iters), loss = 0.388702
I0929 14:56:21.995677  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388702 (* 1 = 0.388702 loss)
I0929 14:56:21.995684  2305 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0929 14:56:36.243182  2305 solver.cpp:218] Iteration 9900 (7.01879 iter/s, 14.2475s/100 iters), loss = 0.284179
I0929 14:56:36.243219  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284179 (* 1 = 0.284179 loss)
I0929 14:56:36.243227  2305 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0929 14:56:49.794754  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:56:50.364446  2305 solver.cpp:330] Iteration 10000, Testing net (#0)
I0929 14:56:53.723083  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:56:53.862416  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7541
I0929 14:56:53.862452  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.752083 (* 1 = 0.752083 loss)
I0929 14:56:54.003034  2305 solver.cpp:218] Iteration 10000 (5.63071 iter/s, 17.7598s/100 iters), loss = 0.221796
I0929 14:56:54.003062  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221796 (* 1 = 0.221796 loss)
I0929 14:56:54.003069  2305 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0929 14:57:08.255226  2305 solver.cpp:218] Iteration 10100 (7.0165 iter/s, 14.2521s/100 iters), loss = 0.22011
I0929 14:57:08.255257  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22011 (* 1 = 0.22011 loss)
I0929 14:57:08.255264  2305 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0929 14:57:22.511081  2305 solver.cpp:218] Iteration 10200 (7.0147 iter/s, 14.2558s/100 iters), loss = 0.314448
I0929 14:57:22.511230  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314447 (* 1 = 0.314447 loss)
I0929 14:57:22.511240  2305 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0929 14:57:36.766093  2305 solver.cpp:218] Iteration 10300 (7.01517 iter/s, 14.2548s/100 iters), loss = 0.278845
I0929 14:57:36.766129  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278845 (* 1 = 0.278845 loss)
I0929 14:57:36.766135  2305 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0929 14:57:51.010136  2305 solver.cpp:218] Iteration 10400 (7.02052 iter/s, 14.244s/100 iters), loss = 0.24655
I0929 14:57:51.010177  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24655 (* 1 = 0.24655 loss)
I0929 14:57:51.010184  2305 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0929 14:58:04.554606  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:58:05.124382  2305 solver.cpp:330] Iteration 10500, Testing net (#0)
I0929 14:58:08.484232  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:58:08.624428  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8092
I0929 14:58:08.624462  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.563299 (* 1 = 0.563299 loss)
I0929 14:58:08.765619  2305 solver.cpp:218] Iteration 10500 (5.63209 iter/s, 17.7554s/100 iters), loss = 0.239093
I0929 14:58:08.765648  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239093 (* 1 = 0.239093 loss)
I0929 14:58:08.765655  2305 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0929 14:58:23.017145  2305 solver.cpp:218] Iteration 10600 (7.01683 iter/s, 14.2515s/100 iters), loss = 0.226711
I0929 14:58:23.017174  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226711 (* 1 = 0.226711 loss)
I0929 14:58:23.017180  2305 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0929 14:58:37.257570  2305 solver.cpp:218] Iteration 10700 (7.0223 iter/s, 14.2404s/100 iters), loss = 0.324893
I0929 14:58:37.257717  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324893 (* 1 = 0.324893 loss)
I0929 14:58:37.257735  2305 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0929 14:58:51.489754  2305 solver.cpp:218] Iteration 10800 (7.02642 iter/s, 14.232s/100 iters), loss = 0.24158
I0929 14:58:51.489784  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24158 (* 1 = 0.24158 loss)
I0929 14:58:51.489790  2305 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0929 14:59:05.745594  2305 solver.cpp:218] Iteration 10900 (7.01471 iter/s, 14.2558s/100 iters), loss = 0.361398
I0929 14:59:05.745625  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361398 (* 1 = 0.361398 loss)
I0929 14:59:05.745632  2305 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0929 14:59:19.290925  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:59:19.859175  2305 solver.cpp:330] Iteration 11000, Testing net (#0)
I0929 14:59:23.218073  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:59:23.358049  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8061
I0929 14:59:23.358085  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.594851 (* 1 = 0.594851 loss)
I0929 14:59:23.498636  2305 solver.cpp:218] Iteration 11000 (5.63287 iter/s, 17.753s/100 iters), loss = 0.233432
I0929 14:59:23.498668  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233432 (* 1 = 0.233432 loss)
I0929 14:59:23.498675  2305 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0929 14:59:37.750927  2305 solver.cpp:218] Iteration 11100 (7.01645 iter/s, 14.2522s/100 iters), loss = 0.250094
I0929 14:59:37.750957  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250094 (* 1 = 0.250094 loss)
I0929 14:59:37.750963  2305 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0929 14:59:52.008409  2305 solver.cpp:218] Iteration 11200 (7.0139 iter/s, 14.2574s/100 iters), loss = 0.409237
I0929 14:59:52.008496  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409237 (* 1 = 0.409237 loss)
I0929 14:59:52.008515  2305 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0929 15:00:06.259737  2305 solver.cpp:218] Iteration 11300 (7.01695 iter/s, 14.2512s/100 iters), loss = 0.405007
I0929 15:00:06.259769  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405007 (* 1 = 0.405007 loss)
I0929 15:00:06.259775  2305 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0929 15:00:20.509002  2305 solver.cpp:218] Iteration 11400 (7.01794 iter/s, 14.2492s/100 iters), loss = 0.220724
I0929 15:00:20.509045  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220724 (* 1 = 0.220724 loss)
I0929 15:00:20.509052  2305 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0929 15:00:34.051537  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:00:34.621188  2305 solver.cpp:330] Iteration 11500, Testing net (#0)
I0929 15:00:37.981478  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:00:38.121378  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7698
I0929 15:00:38.121415  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.685765 (* 1 = 0.685765 loss)
I0929 15:00:38.262116  2305 solver.cpp:218] Iteration 11500 (5.63284 iter/s, 17.753s/100 iters), loss = 0.281057
I0929 15:00:38.262159  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281057 (* 1 = 0.281057 loss)
I0929 15:00:38.262176  2305 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0929 15:00:52.516913  2305 solver.cpp:218] Iteration 11600 (7.01522 iter/s, 14.2547s/100 iters), loss = 0.285997
I0929 15:00:52.516945  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285997 (* 1 = 0.285997 loss)
I0929 15:00:52.516952  2305 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0929 15:01:06.764366  2305 solver.cpp:218] Iteration 11700 (7.01884 iter/s, 14.2474s/100 iters), loss = 0.285015
I0929 15:01:06.764472  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285015 (* 1 = 0.285015 loss)
I0929 15:01:06.764480  2305 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0929 15:01:21.010170  2305 solver.cpp:218] Iteration 11800 (7.0197 iter/s, 14.2456s/100 iters), loss = 0.309655
I0929 15:01:21.010201  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309655 (* 1 = 0.309655 loss)
I0929 15:01:21.010208  2305 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0929 15:01:35.267921  2305 solver.cpp:218] Iteration 11900 (7.01377 iter/s, 14.2577s/100 iters), loss = 0.216823
I0929 15:01:35.267951  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216823 (* 1 = 0.216823 loss)
I0929 15:01:35.267958  2305 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0929 15:01:48.812896  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:01:49.381343  2305 solver.cpp:330] Iteration 12000, Testing net (#0)
I0929 15:01:52.737560  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:01:52.876991  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7752
I0929 15:01:52.877027  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695164 (* 1 = 0.695164 loss)
I0929 15:01:53.017802  2305 solver.cpp:218] Iteration 12000 (5.63387 iter/s, 17.7498s/100 iters), loss = 0.228145
I0929 15:01:53.017834  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228144 (* 1 = 0.228144 loss)
I0929 15:01:53.017841  2305 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0929 15:02:07.274291  2305 solver.cpp:218] Iteration 12100 (7.01439 iter/s, 14.2564s/100 iters), loss = 0.269005
I0929 15:02:07.274335  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269005 (* 1 = 0.269005 loss)
I0929 15:02:07.274343  2305 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0929 15:02:21.521622  2305 solver.cpp:218] Iteration 12200 (7.0189 iter/s, 14.2472s/100 iters), loss = 0.223983
I0929 15:02:21.521765  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223982 (* 1 = 0.223982 loss)
I0929 15:02:21.521775  2305 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0929 15:02:35.776095  2305 solver.cpp:218] Iteration 12300 (7.01543 iter/s, 14.2543s/100 iters), loss = 0.308223
I0929 15:02:35.776124  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308223 (* 1 = 0.308223 loss)
I0929 15:02:35.776139  2305 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0929 15:02:50.023376  2305 solver.cpp:218] Iteration 12400 (7.01892 iter/s, 14.2472s/100 iters), loss = 0.191923
I0929 15:02:50.023406  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191922 (* 1 = 0.191922 loss)
I0929 15:02:50.023412  2305 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0929 15:03:03.573907  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:03:04.150949  2305 solver.cpp:330] Iteration 12500, Testing net (#0)
I0929 15:03:07.512892  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:03:07.652977  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7334
I0929 15:03:07.653012  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.82617 (* 1 = 0.82617 loss)
I0929 15:03:07.794339  2305 solver.cpp:218] Iteration 12500 (5.62718 iter/s, 17.7709s/100 iters), loss = 0.317969
I0929 15:03:07.794369  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317969 (* 1 = 0.317969 loss)
I0929 15:03:07.794375  2305 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0929 15:03:22.051736  2305 solver.cpp:218] Iteration 12600 (7.01394 iter/s, 14.2573s/100 iters), loss = 0.267389
I0929 15:03:22.051769  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267389 (* 1 = 0.267389 loss)
I0929 15:03:22.051785  2305 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0929 15:03:36.296540  2305 solver.cpp:218] Iteration 12700 (7.02014 iter/s, 14.2447s/100 iters), loss = 0.411306
I0929 15:03:36.296658  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411306 (* 1 = 0.411306 loss)
I0929 15:03:36.296675  2305 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0929 15:03:50.556028  2305 solver.cpp:218] Iteration 12800 (7.01295 iter/s, 14.2593s/100 iters), loss = 0.253728
I0929 15:03:50.556061  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253728 (* 1 = 0.253728 loss)
I0929 15:03:50.556067  2305 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0929 15:04:04.819195  2305 solver.cpp:218] Iteration 12900 (7.0111 iter/s, 14.2631s/100 iters), loss = 0.27067
I0929 15:04:04.819226  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27067 (* 1 = 0.27067 loss)
I0929 15:04:04.819232  2305 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0929 15:04:18.357663  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:04:18.934840  2305 solver.cpp:330] Iteration 13000, Testing net (#0)
I0929 15:04:22.292762  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:04:22.432713  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7647
I0929 15:04:22.432749  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.740981 (* 1 = 0.740981 loss)
I0929 15:04:22.573424  2305 solver.cpp:218] Iteration 13000 (5.63249 iter/s, 17.7541s/100 iters), loss = 0.226743
I0929 15:04:22.573457  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226743 (* 1 = 0.226743 loss)
I0929 15:04:22.573465  2305 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0929 15:04:36.823101  2305 solver.cpp:218] Iteration 13100 (7.01774 iter/s, 14.2496s/100 iters), loss = 0.173578
I0929 15:04:36.823137  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173577 (* 1 = 0.173577 loss)
I0929 15:04:36.823148  2305 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0929 15:04:51.067723  2305 solver.cpp:218] Iteration 13200 (7.02023 iter/s, 14.2445s/100 iters), loss = 0.349712
I0929 15:04:51.067832  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349712 (* 1 = 0.349712 loss)
I0929 15:04:51.067840  2305 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0929 15:05:05.310726  2305 solver.cpp:218] Iteration 13300 (7.02106 iter/s, 14.2429s/100 iters), loss = 0.290211
I0929 15:05:05.310756  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290211 (* 1 = 0.290211 loss)
I0929 15:05:05.310762  2305 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0929 15:05:19.553964  2305 solver.cpp:218] Iteration 13400 (7.02091 iter/s, 14.2432s/100 iters), loss = 0.262276
I0929 15:05:19.553995  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262275 (* 1 = 0.262275 loss)
I0929 15:05:19.554013  2305 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0929 15:05:33.093003  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:05:33.666193  2305 solver.cpp:330] Iteration 13500, Testing net (#0)
I0929 15:05:37.033432  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:05:37.172967  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7903
I0929 15:05:37.173003  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.622977 (* 1 = 0.622977 loss)
I0929 15:05:37.314329  2305 solver.cpp:218] Iteration 13500 (5.63054 iter/s, 17.7603s/100 iters), loss = 0.254245
I0929 15:05:37.314362  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254245 (* 1 = 0.254245 loss)
I0929 15:05:37.314368  2305 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0929 15:05:51.559041  2305 solver.cpp:218] Iteration 13600 (7.02019 iter/s, 14.2446s/100 iters), loss = 0.244321
I0929 15:05:51.559083  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244321 (* 1 = 0.244321 loss)
I0929 15:05:51.559090  2305 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0929 15:06:05.804738  2305 solver.cpp:218] Iteration 13700 (7.01971 iter/s, 14.2456s/100 iters), loss = 0.208971
I0929 15:06:05.804842  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208971 (* 1 = 0.208971 loss)
I0929 15:06:05.804850  2305 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0929 15:06:20.058606  2305 solver.cpp:218] Iteration 13800 (7.01571 iter/s, 14.2537s/100 iters), loss = 0.372341
I0929 15:06:20.058636  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372341 (* 1 = 0.372341 loss)
I0929 15:06:20.058643  2305 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0929 15:06:34.308542  2305 solver.cpp:218] Iteration 13900 (7.01761 iter/s, 14.2499s/100 iters), loss = 0.362548
I0929 15:06:34.308584  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362548 (* 1 = 0.362548 loss)
I0929 15:06:34.308591  2305 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0929 15:06:47.836520  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:06:48.404902  2305 solver.cpp:330] Iteration 14000, Testing net (#0)
I0929 15:06:51.769495  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:06:51.911559  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7805
I0929 15:06:51.911586  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.67498 (* 1 = 0.67498 loss)
I0929 15:06:52.052975  2305 solver.cpp:218] Iteration 14000 (5.6356 iter/s, 17.7443s/100 iters), loss = 0.197163
I0929 15:06:52.053006  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197163 (* 1 = 0.197163 loss)
I0929 15:06:52.053014  2305 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0929 15:07:06.301296  2305 solver.cpp:218] Iteration 14100 (7.01841 iter/s, 14.2483s/100 iters), loss = 0.199177
I0929 15:07:06.301327  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199176 (* 1 = 0.199176 loss)
I0929 15:07:06.301333  2305 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0929 15:07:20.556980  2305 solver.cpp:218] Iteration 14200 (7.01478 iter/s, 14.2556s/100 iters), loss = 0.32411
I0929 15:07:20.557122  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32411 (* 1 = 0.32411 loss)
I0929 15:07:20.557130  2305 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0929 15:07:34.798173  2305 solver.cpp:218] Iteration 14300 (7.02197 iter/s, 14.241s/100 iters), loss = 0.290245
I0929 15:07:34.798205  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290245 (* 1 = 0.290245 loss)
I0929 15:07:34.798211  2305 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0929 15:07:49.058964  2305 solver.cpp:218] Iteration 14400 (7.01227 iter/s, 14.2607s/100 iters), loss = 0.235398
I0929 15:07:49.058997  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235398 (* 1 = 0.235398 loss)
I0929 15:07:49.059005  2305 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0929 15:08:02.606650  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:08:03.175052  2305 solver.cpp:330] Iteration 14500, Testing net (#0)
I0929 15:08:06.531654  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:08:06.674631  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7935
I0929 15:08:06.674669  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619081 (* 1 = 0.619081 loss)
I0929 15:08:06.818924  2305 solver.cpp:218] Iteration 14500 (5.63067 iter/s, 17.7599s/100 iters), loss = 0.146319
I0929 15:08:06.818959  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146319 (* 1 = 0.146319 loss)
I0929 15:08:06.818966  2305 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0929 15:08:21.054502  2305 solver.cpp:218] Iteration 14600 (7.02469 iter/s, 14.2355s/100 iters), loss = 0.252772
I0929 15:08:21.054551  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252772 (* 1 = 0.252772 loss)
I0929 15:08:21.054558  2305 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0929 15:08:35.301033  2305 solver.cpp:218] Iteration 14700 (7.01929 iter/s, 14.2465s/100 iters), loss = 0.284882
I0929 15:08:35.301149  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284882 (* 1 = 0.284882 loss)
I0929 15:08:35.301157  2305 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0929 15:08:49.544636  2305 solver.cpp:218] Iteration 14800 (7.02077 iter/s, 14.2435s/100 iters), loss = 0.235449
I0929 15:08:49.544667  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235449 (* 1 = 0.235449 loss)
I0929 15:08:49.544673  2305 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0929 15:09:03.788455  2305 solver.cpp:218] Iteration 14900 (7.02063 iter/s, 14.2437s/100 iters), loss = 0.215341
I0929 15:09:03.788493  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215341 (* 1 = 0.215341 loss)
I0929 15:09:03.788501  2305 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0929 15:09:17.322116  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:09:17.890846  2305 solver.cpp:330] Iteration 15000, Testing net (#0)
I0929 15:09:21.252063  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:09:21.391825  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8222
I0929 15:09:21.391860  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.539927 (* 1 = 0.539927 loss)
I0929 15:09:21.533067  2305 solver.cpp:218] Iteration 15000 (5.63554 iter/s, 17.7445s/100 iters), loss = 0.304774
I0929 15:09:21.533100  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304774 (* 1 = 0.304774 loss)
I0929 15:09:21.533107  2305 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0929 15:09:35.801478  2305 solver.cpp:218] Iteration 15100 (7.00853 iter/s, 14.2683s/100 iters), loss = 0.182636
I0929 15:09:35.801509  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182636 (* 1 = 0.182636 loss)
I0929 15:09:35.801527  2305 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0929 15:09:50.063536  2305 solver.cpp:218] Iteration 15200 (7.01165 iter/s, 14.262s/100 iters), loss = 0.219315
I0929 15:09:50.063675  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219315 (* 1 = 0.219315 loss)
I0929 15:09:50.063684  2305 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0929 15:10:04.322075  2305 solver.cpp:218] Iteration 15300 (7.01343 iter/s, 14.2584s/100 iters), loss = 0.235774
I0929 15:10:04.322108  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235774 (* 1 = 0.235774 loss)
I0929 15:10:04.322114  2305 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0929 15:10:18.580246  2305 solver.cpp:218] Iteration 15400 (7.01356 iter/s, 14.2581s/100 iters), loss = 0.244346
I0929 15:10:18.580277  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244346 (* 1 = 0.244346 loss)
I0929 15:10:18.580284  2305 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0929 15:10:32.130914  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:10:32.698207  2305 solver.cpp:330] Iteration 15500, Testing net (#0)
I0929 15:10:36.055271  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:10:36.197604  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7885
I0929 15:10:36.197630  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.651371 (* 1 = 0.651371 loss)
I0929 15:10:36.338255  2305 solver.cpp:218] Iteration 15500 (5.63129 iter/s, 17.7579s/100 iters), loss = 0.223463
I0929 15:10:36.338285  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223462 (* 1 = 0.223462 loss)
I0929 15:10:36.338292  2305 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0929 15:10:50.580134  2305 solver.cpp:218] Iteration 15600 (7.02158 iter/s, 14.2418s/100 iters), loss = 0.249432
I0929 15:10:50.580170  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249432 (* 1 = 0.249432 loss)
I0929 15:10:50.580178  2305 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0929 15:11:04.831595  2305 solver.cpp:218] Iteration 15700 (7.01686 iter/s, 14.2514s/100 iters), loss = 0.256083
I0929 15:11:04.831698  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256083 (* 1 = 0.256083 loss)
I0929 15:11:04.831717  2305 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0929 15:11:19.082309  2305 solver.cpp:218] Iteration 15800 (7.01726 iter/s, 14.2506s/100 iters), loss = 0.336905
I0929 15:11:19.082343  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336905 (* 1 = 0.336905 loss)
I0929 15:11:19.082350  2305 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0929 15:11:33.316676  2305 solver.cpp:218] Iteration 15900 (7.02529 iter/s, 14.2343s/100 iters), loss = 0.17744
I0929 15:11:33.316712  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17744 (* 1 = 0.17744 loss)
I0929 15:11:33.316720  2305 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0929 15:11:46.856165  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:11:47.425285  2305 solver.cpp:330] Iteration 16000, Testing net (#0)
I0929 15:11:50.782024  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:11:50.921972  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7939
I0929 15:11:50.921998  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.642199 (* 1 = 0.642199 loss)
I0929 15:11:51.062463  2305 solver.cpp:218] Iteration 16000 (5.63517 iter/s, 17.7457s/100 iters), loss = 0.317641
I0929 15:11:51.062491  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317641 (* 1 = 0.317641 loss)
I0929 15:11:51.062499  2305 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0929 15:12:05.313510  2305 solver.cpp:218] Iteration 16100 (7.01707 iter/s, 14.251s/100 iters), loss = 0.237542
I0929 15:12:05.313540  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237542 (* 1 = 0.237542 loss)
I0929 15:12:05.313546  2305 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0929 15:12:19.546319  2305 solver.cpp:218] Iteration 16200 (7.02606 iter/s, 14.2327s/100 iters), loss = 0.356895
I0929 15:12:19.546432  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356895 (* 1 = 0.356895 loss)
I0929 15:12:19.546447  2305 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0929 15:12:33.792296  2305 solver.cpp:218] Iteration 16300 (7.0196 iter/s, 14.2458s/100 iters), loss = 0.25152
I0929 15:12:33.792346  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251519 (* 1 = 0.251519 loss)
I0929 15:12:33.792353  2305 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0929 15:12:48.041268  2305 solver.cpp:218] Iteration 16400 (7.01811 iter/s, 14.2489s/100 iters), loss = 0.155584
I0929 15:12:48.041297  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155584 (* 1 = 0.155584 loss)
I0929 15:12:48.041313  2305 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0929 15:13:01.581758  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:13:02.149886  2305 solver.cpp:330] Iteration 16500, Testing net (#0)
I0929 15:13:05.506443  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:13:05.646353  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5081
I0929 15:13:05.646389  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.72816 (* 1 = 1.72816 loss)
I0929 15:13:05.787447  2305 solver.cpp:218] Iteration 16500 (5.63504 iter/s, 17.7461s/100 iters), loss = 0.219606
I0929 15:13:05.787475  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219605 (* 1 = 0.219605 loss)
I0929 15:13:05.787482  2305 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0929 15:13:20.042631  2305 solver.cpp:218] Iteration 16600 (7.01503 iter/s, 14.2551s/100 iters), loss = 0.220332
I0929 15:13:20.042672  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220332 (* 1 = 0.220332 loss)
I0929 15:13:20.042678  2305 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0929 15:13:34.304086  2305 solver.cpp:218] Iteration 16700 (7.01195 iter/s, 14.2614s/100 iters), loss = 0.348899
I0929 15:13:34.304246  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348898 (* 1 = 0.348898 loss)
I0929 15:13:34.304255  2305 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0929 15:13:48.553354  2305 solver.cpp:218] Iteration 16800 (7.018 iter/s, 14.2491s/100 iters), loss = 0.174822
I0929 15:13:48.553395  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174822 (* 1 = 0.174822 loss)
I0929 15:13:48.553402  2305 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0929 15:14:02.805994  2305 solver.cpp:218] Iteration 16900 (7.01628 iter/s, 14.2526s/100 iters), loss = 0.208506
I0929 15:14:02.806036  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208506 (* 1 = 0.208506 loss)
I0929 15:14:02.806043  2305 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0929 15:14:16.371353  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:14:16.940726  2305 solver.cpp:330] Iteration 17000, Testing net (#0)
I0929 15:14:20.299437  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:14:20.439684  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8208
I0929 15:14:20.439719  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.537624 (* 1 = 0.537624 loss)
I0929 15:14:20.580356  2305 solver.cpp:218] Iteration 17000 (5.62611 iter/s, 17.7743s/100 iters), loss = 0.268119
I0929 15:14:20.580390  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268118 (* 1 = 0.268118 loss)
I0929 15:14:20.580397  2305 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0929 15:14:34.835484  2305 solver.cpp:218] Iteration 17100 (7.01506 iter/s, 14.255s/100 iters), loss = 0.235592
I0929 15:14:34.835517  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235591 (* 1 = 0.235591 loss)
I0929 15:14:34.835523  2305 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0929 15:14:49.082798  2305 solver.cpp:218] Iteration 17200 (7.0189 iter/s, 14.2472s/100 iters), loss = 0.286502
I0929 15:14:49.082932  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286501 (* 1 = 0.286501 loss)
I0929 15:14:49.082950  2305 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0929 15:15:03.328975  2305 solver.cpp:218] Iteration 17300 (7.01951 iter/s, 14.246s/100 iters), loss = 0.230576
I0929 15:15:03.329010  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230576 (* 1 = 0.230576 loss)
I0929 15:15:03.329017  2305 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0929 15:15:17.586091  2305 solver.cpp:218] Iteration 17400 (7.01408 iter/s, 14.257s/100 iters), loss = 0.176984
I0929 15:15:17.586125  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176984 (* 1 = 0.176984 loss)
I0929 15:15:17.586133  2305 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0929 15:15:31.128039  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:15:31.698585  2305 solver.cpp:330] Iteration 17500, Testing net (#0)
I0929 15:15:35.053618  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:15:35.193092  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.758
I0929 15:15:35.193128  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.817965 (* 1 = 0.817965 loss)
I0929 15:15:35.333549  2305 solver.cpp:218] Iteration 17500 (5.63464 iter/s, 17.7474s/100 iters), loss = 0.202771
I0929 15:15:35.333577  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202771 (* 1 = 0.202771 loss)
I0929 15:15:35.333583  2305 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0929 15:15:49.599561  2305 solver.cpp:218] Iteration 17600 (7.00971 iter/s, 14.2659s/100 iters), loss = 0.221764
I0929 15:15:49.599591  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221764 (* 1 = 0.221764 loss)
I0929 15:15:49.599598  2305 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0929 15:16:03.861094  2305 solver.cpp:218] Iteration 17700 (7.0119 iter/s, 14.2615s/100 iters), loss = 0.283033
I0929 15:16:03.861238  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283032 (* 1 = 0.283032 loss)
I0929 15:16:03.861258  2305 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0929 15:16:18.110898  2305 solver.cpp:218] Iteration 17800 (7.01774 iter/s, 14.2496s/100 iters), loss = 0.245161
I0929 15:16:18.110930  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24516 (* 1 = 0.24516 loss)
I0929 15:16:18.110936  2305 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0929 15:16:32.373739  2305 solver.cpp:218] Iteration 17900 (7.01126 iter/s, 14.2628s/100 iters), loss = 0.164041
I0929 15:16:32.373769  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164041 (* 1 = 0.164041 loss)
I0929 15:16:32.373773  2305 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0929 15:16:45.933012  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:16:46.500543  2305 solver.cpp:330] Iteration 18000, Testing net (#0)
I0929 15:16:49.860829  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:16:50.000687  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7262
I0929 15:16:50.000712  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.947113 (* 1 = 0.947113 loss)
I0929 15:16:50.142212  2305 solver.cpp:218] Iteration 18000 (5.62797 iter/s, 17.7684s/100 iters), loss = 0.298711
I0929 15:16:50.142242  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298711 (* 1 = 0.298711 loss)
I0929 15:16:50.142248  2305 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0929 15:17:04.388129  2305 solver.cpp:218] Iteration 18100 (7.01959 iter/s, 14.2458s/100 iters), loss = 0.208045
I0929 15:17:04.388162  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208045 (* 1 = 0.208045 loss)
I0929 15:17:04.388169  2305 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0929 15:17:18.633520  2305 solver.cpp:218] Iteration 18200 (7.01985 iter/s, 14.2453s/100 iters), loss = 0.25277
I0929 15:17:18.633641  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25277 (* 1 = 0.25277 loss)
I0929 15:17:18.633651  2305 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0929 15:17:32.888451  2305 solver.cpp:218] Iteration 18300 (7.0152 iter/s, 14.2548s/100 iters), loss = 0.25916
I0929 15:17:32.888484  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25916 (* 1 = 0.25916 loss)
I0929 15:17:32.888491  2305 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0929 15:17:47.143314  2305 solver.cpp:218] Iteration 18400 (7.01519 iter/s, 14.2548s/100 iters), loss = 0.335404
I0929 15:17:47.143344  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335404 (* 1 = 0.335404 loss)
I0929 15:17:47.143350  2305 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0929 15:18:00.680804  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:18:01.257585  2305 solver.cpp:330] Iteration 18500, Testing net (#0)
I0929 15:18:04.614228  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:18:04.754252  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8239
I0929 15:18:04.754289  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.560183 (* 1 = 0.560183 loss)
I0929 15:18:04.894879  2305 solver.cpp:218] Iteration 18500 (5.63333 iter/s, 17.7515s/100 iters), loss = 0.222354
I0929 15:18:04.894913  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222354 (* 1 = 0.222354 loss)
I0929 15:18:04.894920  2305 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0929 15:18:19.149108  2305 solver.cpp:218] Iteration 18600 (7.0155 iter/s, 14.2542s/100 iters), loss = 0.228982
I0929 15:18:19.149140  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228981 (* 1 = 0.228981 loss)
I0929 15:18:19.149147  2305 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0929 15:18:33.389534  2305 solver.cpp:218] Iteration 18700 (7.0223 iter/s, 14.2403s/100 iters), loss = 0.192839
I0929 15:18:33.389681  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192838 (* 1 = 0.192838 loss)
I0929 15:18:33.389693  2305 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0929 15:18:47.634958  2305 solver.cpp:218] Iteration 18800 (7.01989 iter/s, 14.2452s/100 iters), loss = 0.223841
I0929 15:18:47.634991  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223841 (* 1 = 0.223841 loss)
I0929 15:18:47.634999  2305 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0929 15:19:01.887346  2305 solver.cpp:218] Iteration 18900 (7.0164 iter/s, 14.2523s/100 iters), loss = 0.211002
I0929 15:19:01.887377  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211002 (* 1 = 0.211002 loss)
I0929 15:19:01.887383  2305 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0929 15:19:15.420267  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:19:15.999002  2305 solver.cpp:330] Iteration 19000, Testing net (#0)
I0929 15:19:19.356487  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:19:19.496429  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7527
I0929 15:19:19.496456  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833935 (* 1 = 0.833935 loss)
I0929 15:19:19.636961  2305 solver.cpp:218] Iteration 19000 (5.63395 iter/s, 17.7495s/100 iters), loss = 0.289655
I0929 15:19:19.636996  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289655 (* 1 = 0.289655 loss)
I0929 15:19:19.637001  2305 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0929 15:19:33.872150  2305 solver.cpp:218] Iteration 19100 (7.02488 iter/s, 14.2351s/100 iters), loss = 0.234813
I0929 15:19:33.872185  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234813 (* 1 = 0.234813 loss)
I0929 15:19:33.872192  2305 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0929 15:19:48.124744  2305 solver.cpp:218] Iteration 19200 (7.0163 iter/s, 14.2525s/100 iters), loss = 0.261189
I0929 15:19:48.124868  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261189 (* 1 = 0.261189 loss)
I0929 15:19:48.124876  2305 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0929 15:20:02.380249  2305 solver.cpp:218] Iteration 19300 (7.01491 iter/s, 14.2553s/100 iters), loss = 0.215342
I0929 15:20:02.380290  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215342 (* 1 = 0.215342 loss)
I0929 15:20:02.380296  2305 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0929 15:20:16.621939  2305 solver.cpp:218] Iteration 19400 (7.02168 iter/s, 14.2416s/100 iters), loss = 0.291924
I0929 15:20:16.621969  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291924 (* 1 = 0.291924 loss)
I0929 15:20:16.621975  2305 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0929 15:20:30.158740  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:20:30.729279  2305 solver.cpp:330] Iteration 19500, Testing net (#0)
I0929 15:20:34.095302  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:20:34.235165  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7885
I0929 15:20:34.235193  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658422 (* 1 = 0.658422 loss)
I0929 15:20:34.375978  2305 solver.cpp:218] Iteration 19500 (5.63255 iter/s, 17.754s/100 iters), loss = 0.236839
I0929 15:20:34.376013  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236839 (* 1 = 0.236839 loss)
I0929 15:20:34.376019  2305 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0929 15:20:48.613698  2305 solver.cpp:218] Iteration 19600 (7.02363 iter/s, 14.2376s/100 iters), loss = 0.206302
I0929 15:20:48.613729  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206301 (* 1 = 0.206301 loss)
I0929 15:20:48.613735  2305 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0929 15:21:02.863692  2305 solver.cpp:218] Iteration 19700 (7.01758 iter/s, 14.2499s/100 iters), loss = 0.266391
I0929 15:21:02.863828  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26639 (* 1 = 0.26639 loss)
I0929 15:21:02.863837  2305 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0929 15:21:17.109982  2305 solver.cpp:218] Iteration 19800 (7.01945 iter/s, 14.2461s/100 iters), loss = 0.173569
I0929 15:21:17.110013  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173569 (* 1 = 0.173569 loss)
I0929 15:21:17.110018  2305 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0929 15:21:31.365856  2305 solver.cpp:218] Iteration 19900 (7.01469 iter/s, 14.2558s/100 iters), loss = 0.229586
I0929 15:21:31.365887  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229586 (* 1 = 0.229586 loss)
I0929 15:21:31.365895  2305 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0929 15:21:44.899912  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:21:45.468821  2305 solver.cpp:330] Iteration 20000, Testing net (#0)
I0929 15:21:48.828963  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:21:48.972440  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8069
I0929 15:21:48.972470  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600872 (* 1 = 0.600872 loss)
I0929 15:21:49.113260  2305 solver.cpp:218] Iteration 20000 (5.63465 iter/s, 17.7473s/100 iters), loss = 0.201136
I0929 15:21:49.113296  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201136 (* 1 = 0.201136 loss)
I0929 15:21:49.113302  2305 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0929 15:22:03.353657  2305 solver.cpp:218] Iteration 20100 (7.02232 iter/s, 14.2403s/100 iters), loss = 0.13915
I0929 15:22:03.353688  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13915 (* 1 = 0.13915 loss)
I0929 15:22:03.353693  2305 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0929 15:22:17.612058  2305 solver.cpp:218] Iteration 20200 (7.01344 iter/s, 14.2583s/100 iters), loss = 0.278557
I0929 15:22:17.612198  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278557 (* 1 = 0.278557 loss)
I0929 15:22:17.612206  2305 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0929 15:22:31.864449  2305 solver.cpp:218] Iteration 20300 (7.01645 iter/s, 14.2522s/100 iters), loss = 0.182342
I0929 15:22:31.864478  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182342 (* 1 = 0.182342 loss)
I0929 15:22:31.864485  2305 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0929 15:22:46.108170  2305 solver.cpp:218] Iteration 20400 (7.02067 iter/s, 14.2437s/100 iters), loss = 0.21303
I0929 15:22:46.108203  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213029 (* 1 = 0.213029 loss)
I0929 15:22:46.108211  2305 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0929 15:22:59.647997  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:23:00.216140  2305 solver.cpp:330] Iteration 20500, Testing net (#0)
I0929 15:23:03.574781  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:23:03.716392  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7551
I0929 15:23:03.716420  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.899365 (* 1 = 0.899365 loss)
I0929 15:23:03.861209  2305 solver.cpp:218] Iteration 20500 (5.63287 iter/s, 17.753s/100 iters), loss = 0.171946
I0929 15:23:03.861256  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171946 (* 1 = 0.171946 loss)
I0929 15:23:03.861264  2305 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0929 15:23:18.094702  2305 solver.cpp:218] Iteration 20600 (7.02574 iter/s, 14.2334s/100 iters), loss = 0.239187
I0929 15:23:18.094733  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239186 (* 1 = 0.239186 loss)
I0929 15:23:18.094739  2305 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0929 15:23:32.329210  2305 solver.cpp:218] Iteration 20700 (7.02522 iter/s, 14.2344s/100 iters), loss = 0.288076
I0929 15:23:32.329383  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288075 (* 1 = 0.288075 loss)
I0929 15:23:32.329392  2305 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0929 15:23:46.565502  2305 solver.cpp:218] Iteration 20800 (7.0244 iter/s, 14.2361s/100 iters), loss = 0.167473
I0929 15:23:46.565534  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167472 (* 1 = 0.167472 loss)
I0929 15:23:46.565541  2305 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0929 15:24:00.810806  2305 solver.cpp:218] Iteration 20900 (7.01989 iter/s, 14.2452s/100 iters), loss = 0.212616
I0929 15:24:00.810854  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212615 (* 1 = 0.212615 loss)
I0929 15:24:00.810863  2305 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0929 15:24:14.342252  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:24:14.910133  2305 solver.cpp:330] Iteration 21000, Testing net (#0)
I0929 15:24:18.266819  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:24:18.406538  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7214
I0929 15:24:18.406574  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.952309 (* 1 = 0.952309 loss)
I0929 15:24:18.546865  2305 solver.cpp:218] Iteration 21000 (5.63827 iter/s, 17.7359s/100 iters), loss = 0.206066
I0929 15:24:18.546900  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206065 (* 1 = 0.206065 loss)
I0929 15:24:18.546907  2305 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0929 15:24:32.790254  2305 solver.cpp:218] Iteration 21100 (7.02084 iter/s, 14.2433s/100 iters), loss = 0.301768
I0929 15:24:32.790288  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301768 (* 1 = 0.301768 loss)
I0929 15:24:32.790294  2305 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0929 15:24:47.044301  2305 solver.cpp:218] Iteration 21200 (7.01559 iter/s, 14.254s/100 iters), loss = 0.197802
I0929 15:24:47.044407  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197802 (* 1 = 0.197802 loss)
I0929 15:24:47.044415  2305 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0929 15:25:01.293133  2305 solver.cpp:218] Iteration 21300 (7.01819 iter/s, 14.2487s/100 iters), loss = 0.269615
I0929 15:25:01.293175  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269615 (* 1 = 0.269615 loss)
I0929 15:25:01.293181  2305 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0929 15:25:15.525349  2305 solver.cpp:218] Iteration 21400 (7.02635 iter/s, 14.2321s/100 iters), loss = 0.145656
I0929 15:25:15.525391  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145655 (* 1 = 0.145655 loss)
I0929 15:25:15.525398  2305 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0929 15:25:29.071868  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:25:29.640895  2305 solver.cpp:330] Iteration 21500, Testing net (#0)
I0929 15:25:33.000725  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:25:33.140825  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8189
I0929 15:25:33.140849  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.557772 (* 1 = 0.557772 loss)
I0929 15:25:33.281472  2305 solver.cpp:218] Iteration 21500 (5.63189 iter/s, 17.756s/100 iters), loss = 0.196129
I0929 15:25:33.281500  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196128 (* 1 = 0.196128 loss)
I0929 15:25:33.281507  2305 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0929 15:25:47.532361  2305 solver.cpp:218] Iteration 21600 (7.01714 iter/s, 14.2508s/100 iters), loss = 0.229882
I0929 15:25:47.532392  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229881 (* 1 = 0.229881 loss)
I0929 15:25:47.532398  2305 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0929 15:26:01.777706  2305 solver.cpp:218] Iteration 21700 (7.01987 iter/s, 14.2453s/100 iters), loss = 0.215396
I0929 15:26:01.777846  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215395 (* 1 = 0.215395 loss)
I0929 15:26:01.777864  2305 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0929 15:26:16.037811  2305 solver.cpp:218] Iteration 21800 (7.01266 iter/s, 14.2599s/100 iters), loss = 0.247499
I0929 15:26:16.037844  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247499 (* 1 = 0.247499 loss)
I0929 15:26:16.037852  2305 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0929 15:26:30.288127  2305 solver.cpp:218] Iteration 21900 (7.01743 iter/s, 14.2502s/100 iters), loss = 0.200032
I0929 15:26:30.288159  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200032 (* 1 = 0.200032 loss)
I0929 15:26:30.288166  2305 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0929 15:26:43.827144  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:26:44.397056  2305 solver.cpp:330] Iteration 22000, Testing net (#0)
I0929 15:26:47.752466  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:26:47.892351  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7267
I0929 15:26:47.892387  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.923863 (* 1 = 0.923863 loss)
I0929 15:26:48.033244  2305 solver.cpp:218] Iteration 22000 (5.63538 iter/s, 17.745s/100 iters), loss = 0.24343
I0929 15:26:48.033273  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24343 (* 1 = 0.24343 loss)
I0929 15:26:48.033280  2305 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0929 15:27:02.292575  2305 solver.cpp:218] Iteration 22100 (7.01299 iter/s, 14.2593s/100 iters), loss = 0.248354
I0929 15:27:02.292606  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248353 (* 1 = 0.248353 loss)
I0929 15:27:02.292613  2305 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0929 15:27:16.544618  2305 solver.cpp:218] Iteration 22200 (7.01657 iter/s, 14.252s/100 iters), loss = 0.24247
I0929 15:27:16.544736  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24247 (* 1 = 0.24247 loss)
I0929 15:27:16.544754  2305 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0929 15:27:30.780879  2305 solver.cpp:218] Iteration 22300 (7.0244 iter/s, 14.2361s/100 iters), loss = 0.199911
I0929 15:27:30.780915  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199911 (* 1 = 0.199911 loss)
I0929 15:27:30.780922  2305 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0929 15:27:45.030781  2305 solver.cpp:218] Iteration 22400 (7.01763 iter/s, 14.2498s/100 iters), loss = 0.232688
I0929 15:27:45.030810  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232688 (* 1 = 0.232688 loss)
I0929 15:27:45.030817  2305 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0929 15:27:58.578291  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:27:59.146136  2305 solver.cpp:330] Iteration 22500, Testing net (#0)
I0929 15:28:02.505677  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:28:02.645386  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7799
I0929 15:28:02.645422  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663432 (* 1 = 0.663432 loss)
I0929 15:28:02.786618  2305 solver.cpp:218] Iteration 22500 (5.63198 iter/s, 17.7558s/100 iters), loss = 0.144671
I0929 15:28:02.786651  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144671 (* 1 = 0.144671 loss)
I0929 15:28:02.786659  2305 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0929 15:28:17.031622  2305 solver.cpp:218] Iteration 22600 (7.02004 iter/s, 14.2449s/100 iters), loss = 0.237968
I0929 15:28:17.031652  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237968 (* 1 = 0.237968 loss)
I0929 15:28:17.031658  2305 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0929 15:28:31.276746  2305 solver.cpp:218] Iteration 22700 (7.01998 iter/s, 14.2451s/100 iters), loss = 0.169843
I0929 15:28:31.276890  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169842 (* 1 = 0.169842 loss)
I0929 15:28:31.276908  2305 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0929 15:28:45.523763  2305 solver.cpp:218] Iteration 22800 (7.0191 iter/s, 14.2468s/100 iters), loss = 0.208177
I0929 15:28:45.523795  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208177 (* 1 = 0.208177 loss)
I0929 15:28:45.523802  2305 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0929 15:28:59.765542  2305 solver.cpp:218] Iteration 22900 (7.02163 iter/s, 14.2417s/100 iters), loss = 0.163063
I0929 15:28:59.765570  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163062 (* 1 = 0.163062 loss)
I0929 15:28:59.765576  2305 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0929 15:29:13.305565  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:29:13.875072  2305 solver.cpp:330] Iteration 23000, Testing net (#0)
I0929 15:29:17.230448  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:29:17.369992  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7946
I0929 15:29:17.370016  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.622192 (* 1 = 0.622192 loss)
I0929 15:29:17.512127  2305 solver.cpp:218] Iteration 23000 (5.63491 iter/s, 17.7465s/100 iters), loss = 0.20182
I0929 15:29:17.512161  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201819 (* 1 = 0.201819 loss)
I0929 15:29:17.512168  2305 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0929 15:29:31.761721  2305 solver.cpp:218] Iteration 23100 (7.01778 iter/s, 14.2495s/100 iters), loss = 0.169167
I0929 15:29:31.761752  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169166 (* 1 = 0.169166 loss)
I0929 15:29:31.761759  2305 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0929 15:29:46.010951  2305 solver.cpp:218] Iteration 23200 (7.01796 iter/s, 14.2492s/100 iters), loss = 0.188549
I0929 15:29:46.011087  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188549 (* 1 = 0.188549 loss)
I0929 15:29:46.011097  2305 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0929 15:30:00.246310  2305 solver.cpp:218] Iteration 23300 (7.02486 iter/s, 14.2352s/100 iters), loss = 0.258014
I0929 15:30:00.246345  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258014 (* 1 = 0.258014 loss)
I0929 15:30:00.246351  2305 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0929 15:30:14.505869  2305 solver.cpp:218] Iteration 23400 (7.01288 iter/s, 14.2595s/100 iters), loss = 0.281915
I0929 15:30:14.505901  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281914 (* 1 = 0.281914 loss)
I0929 15:30:14.505908  2305 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0929 15:30:28.053812  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:30:28.622719  2305 solver.cpp:330] Iteration 23500, Testing net (#0)
I0929 15:30:31.976428  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:30:32.116780  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7536
I0929 15:30:32.116804  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.828291 (* 1 = 0.828291 loss)
I0929 15:30:32.257928  2305 solver.cpp:218] Iteration 23500 (5.63317 iter/s, 17.752s/100 iters), loss = 0.23621
I0929 15:30:32.257962  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23621 (* 1 = 0.23621 loss)
I0929 15:30:32.257969  2305 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0929 15:30:46.507653  2305 solver.cpp:218] Iteration 23600 (7.01772 iter/s, 14.2496s/100 iters), loss = 0.165893
I0929 15:30:46.507684  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165892 (* 1 = 0.165892 loss)
I0929 15:30:46.507691  2305 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0929 15:31:00.751142  2305 solver.cpp:218] Iteration 23700 (7.02079 iter/s, 14.2434s/100 iters), loss = 0.249437
I0929 15:31:00.751251  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249437 (* 1 = 0.249437 loss)
I0929 15:31:00.751260  2305 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0929 15:31:15.014143  2305 solver.cpp:218] Iteration 23800 (7.01123 iter/s, 14.2628s/100 iters), loss = 0.206466
I0929 15:31:15.014186  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206466 (* 1 = 0.206466 loss)
I0929 15:31:15.014192  2305 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0929 15:31:29.265336  2305 solver.cpp:218] Iteration 23900 (7.017 iter/s, 14.2511s/100 iters), loss = 0.149826
I0929 15:31:29.265375  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149826 (* 1 = 0.149826 loss)
I0929 15:31:29.265383  2305 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0929 15:31:42.808796  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:31:43.383374  2305 solver.cpp:330] Iteration 24000, Testing net (#0)
I0929 15:31:46.740669  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:31:46.880416  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7971
I0929 15:31:46.880442  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659338 (* 1 = 0.659338 loss)
I0929 15:31:47.021256  2305 solver.cpp:218] Iteration 24000 (5.63195 iter/s, 17.7558s/100 iters), loss = 0.194142
I0929 15:31:47.021286  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194142 (* 1 = 0.194142 loss)
I0929 15:31:47.021292  2305 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0929 15:32:01.274402  2305 solver.cpp:218] Iteration 24100 (7.01603 iter/s, 14.2531s/100 iters), loss = 0.25846
I0929 15:32:01.274435  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25846 (* 1 = 0.25846 loss)
I0929 15:32:01.274441  2305 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0929 15:32:15.512946  2305 solver.cpp:218] Iteration 24200 (7.02323 iter/s, 14.2385s/100 iters), loss = 0.338732
I0929 15:32:15.513056  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338732 (* 1 = 0.338732 loss)
I0929 15:32:15.513073  2305 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0929 15:32:29.761708  2305 solver.cpp:218] Iteration 24300 (7.01822 iter/s, 14.2486s/100 iters), loss = 0.149683
I0929 15:32:29.761739  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149683 (* 1 = 0.149683 loss)
I0929 15:32:29.761744  2305 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0929 15:32:44.014948  2305 solver.cpp:218] Iteration 24400 (7.01598 iter/s, 14.2532s/100 iters), loss = 0.228158
I0929 15:32:44.014977  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228158 (* 1 = 0.228158 loss)
I0929 15:32:44.014983  2305 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0929 15:32:57.552695  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:32:58.130733  2305 solver.cpp:330] Iteration 24500, Testing net (#0)
I0929 15:33:01.486368  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:33:01.625715  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8023
I0929 15:33:01.625751  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.599088 (* 1 = 0.599088 loss)
I0929 15:33:01.766266  2305 solver.cpp:218] Iteration 24500 (5.63341 iter/s, 17.7512s/100 iters), loss = 0.182877
I0929 15:33:01.766299  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182877 (* 1 = 0.182877 loss)
I0929 15:33:01.766305  2305 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0929 15:33:16.010057  2305 solver.cpp:218] Iteration 24600 (7.02064 iter/s, 14.2437s/100 iters), loss = 0.195806
I0929 15:33:16.010095  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195806 (* 1 = 0.195806 loss)
I0929 15:33:16.010102  2305 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0929 15:33:30.254310  2305 solver.cpp:218] Iteration 24700 (7.02041 iter/s, 14.2442s/100 iters), loss = 0.273679
I0929 15:33:30.254496  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273678 (* 1 = 0.273678 loss)
I0929 15:33:30.254515  2305 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0929 15:33:44.507957  2305 solver.cpp:218] Iteration 24800 (7.01585 iter/s, 14.2534s/100 iters), loss = 0.188511
I0929 15:33:44.507990  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188511 (* 1 = 0.188511 loss)
I0929 15:33:44.508008  2305 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0929 15:33:58.751497  2305 solver.cpp:218] Iteration 24900 (7.02076 iter/s, 14.2435s/100 iters), loss = 0.239865
I0929 15:33:58.751530  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239865 (* 1 = 0.239865 loss)
I0929 15:33:58.751538  2305 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0929 15:34:12.289121  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:34:12.860060  2305 solver.cpp:330] Iteration 25000, Testing net (#0)
I0929 15:34:16.221541  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:34:16.361537  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7417
I0929 15:34:16.361562  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.845533 (* 1 = 0.845533 loss)
I0929 15:34:16.501948  2305 solver.cpp:218] Iteration 25000 (5.63368 iter/s, 17.7504s/100 iters), loss = 0.185775
I0929 15:34:16.501981  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185775 (* 1 = 0.185775 loss)
I0929 15:34:16.501986  2305 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0929 15:34:30.738391  2305 solver.cpp:218] Iteration 25100 (7.02426 iter/s, 14.2364s/100 iters), loss = 0.170157
I0929 15:34:30.738421  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170157 (* 1 = 0.170157 loss)
I0929 15:34:30.738427  2305 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0929 15:34:44.977984  2305 solver.cpp:218] Iteration 25200 (7.02271 iter/s, 14.2395s/100 iters), loss = 0.13493
I0929 15:34:44.978097  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13493 (* 1 = 0.13493 loss)
I0929 15:34:44.978106  2305 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0929 15:34:59.223503  2305 solver.cpp:218] Iteration 25300 (7.01982 iter/s, 14.2454s/100 iters), loss = 0.225395
I0929 15:34:59.223534  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225395 (* 1 = 0.225395 loss)
I0929 15:34:59.223541  2305 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0929 15:35:13.477568  2305 solver.cpp:218] Iteration 25400 (7.01558 iter/s, 14.254s/100 iters), loss = 0.220295
I0929 15:35:13.477600  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220295 (* 1 = 0.220295 loss)
I0929 15:35:13.477607  2305 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0929 15:35:27.009958  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:35:27.578886  2305 solver.cpp:330] Iteration 25500, Testing net (#0)
I0929 15:35:30.942675  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:35:31.085870  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8345
I0929 15:35:31.085896  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.514269 (* 1 = 0.514269 loss)
I0929 15:35:31.225653  2305 solver.cpp:218] Iteration 25500 (5.63444 iter/s, 17.748s/100 iters), loss = 0.204627
I0929 15:35:31.225689  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204627 (* 1 = 0.204627 loss)
I0929 15:35:31.225697  2305 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0929 15:35:45.458518  2305 solver.cpp:218] Iteration 25600 (7.02603 iter/s, 14.2328s/100 iters), loss = 0.175267
I0929 15:35:45.458561  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175267 (* 1 = 0.175267 loss)
I0929 15:35:45.458567  2305 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0929 15:35:59.708045  2305 solver.cpp:218] Iteration 25700 (7.01782 iter/s, 14.2494s/100 iters), loss = 0.24591
I0929 15:35:59.708181  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24591 (* 1 = 0.24591 loss)
I0929 15:35:59.708189  2305 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0929 15:36:13.956967  2305 solver.cpp:218] Iteration 25800 (7.01816 iter/s, 14.2487s/100 iters), loss = 0.171748
I0929 15:36:13.957000  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171748 (* 1 = 0.171748 loss)
I0929 15:36:13.957005  2305 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0929 15:36:28.195601  2305 solver.cpp:218] Iteration 25900 (7.02318 iter/s, 14.2386s/100 iters), loss = 0.175585
I0929 15:36:28.195636  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175584 (* 1 = 0.175584 loss)
I0929 15:36:28.195642  2305 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0929 15:36:41.729199  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:36:42.298277  2305 solver.cpp:330] Iteration 26000, Testing net (#0)
I0929 15:36:45.657999  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:36:45.799924  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8347
I0929 15:36:45.799962  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.49358 (* 1 = 0.49358 loss)
I0929 15:36:45.945180  2305 solver.cpp:218] Iteration 26000 (5.63396 iter/s, 17.7495s/100 iters), loss = 0.145211
I0929 15:36:45.945228  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14521 (* 1 = 0.14521 loss)
I0929 15:36:45.945235  2305 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0929 15:37:00.174590  2305 solver.cpp:218] Iteration 26100 (7.02776 iter/s, 14.2293s/100 iters), loss = 0.166903
I0929 15:37:00.174619  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166902 (* 1 = 0.166902 loss)
I0929 15:37:00.174625  2305 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0929 15:37:14.408303  2305 solver.cpp:218] Iteration 26200 (7.02561 iter/s, 14.2336s/100 iters), loss = 0.238631
I0929 15:37:14.408427  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238631 (* 1 = 0.238631 loss)
I0929 15:37:14.408445  2305 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0929 15:37:28.662930  2305 solver.cpp:218] Iteration 26300 (7.01535 iter/s, 14.2545s/100 iters), loss = 0.190364
I0929 15:37:28.662961  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190364 (* 1 = 0.190364 loss)
I0929 15:37:28.662967  2305 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0929 15:37:42.899193  2305 solver.cpp:218] Iteration 26400 (7.02435 iter/s, 14.2362s/100 iters), loss = 0.147829
I0929 15:37:42.899230  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147829 (* 1 = 0.147829 loss)
I0929 15:37:42.899236  2305 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0929 15:37:56.424561  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:37:56.991256  2305 solver.cpp:330] Iteration 26500, Testing net (#0)
I0929 15:38:00.347900  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:38:00.487390  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7802
I0929 15:38:00.487416  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706364 (* 1 = 0.706364 loss)
I0929 15:38:00.628049  2305 solver.cpp:218] Iteration 26500 (5.64055 iter/s, 17.7288s/100 iters), loss = 0.173705
I0929 15:38:00.628079  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173705 (* 1 = 0.173705 loss)
I0929 15:38:00.628087  2305 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0929 15:38:14.891575  2305 solver.cpp:218] Iteration 26600 (7.01092 iter/s, 14.2635s/100 iters), loss = 0.201625
I0929 15:38:14.891623  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201624 (* 1 = 0.201624 loss)
I0929 15:38:14.891629  2305 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0929 15:38:29.158903  2305 solver.cpp:218] Iteration 26700 (7.00906 iter/s, 14.2672s/100 iters), loss = 0.282872
I0929 15:38:29.159021  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282872 (* 1 = 0.282872 loss)
I0929 15:38:29.159029  2305 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0929 15:38:43.411419  2305 solver.cpp:218] Iteration 26800 (7.01639 iter/s, 14.2524s/100 iters), loss = 0.129245
I0929 15:38:43.411453  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129245 (* 1 = 0.129245 loss)
I0929 15:38:43.411458  2305 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0929 15:38:57.662377  2305 solver.cpp:218] Iteration 26900 (7.01711 iter/s, 14.2509s/100 iters), loss = 0.170706
I0929 15:38:57.662417  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170705 (* 1 = 0.170705 loss)
I0929 15:38:57.662425  2305 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0929 15:39:11.222664  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:39:11.791466  2305 solver.cpp:330] Iteration 27000, Testing net (#0)
I0929 15:39:15.149689  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:39:15.289381  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8329
I0929 15:39:15.289417  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.483177 (* 1 = 0.483177 loss)
I0929 15:39:15.430491  2305 solver.cpp:218] Iteration 27000 (5.62809 iter/s, 17.768s/100 iters), loss = 0.219972
I0929 15:39:15.430524  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219972 (* 1 = 0.219972 loss)
I0929 15:39:15.430531  2305 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0929 15:39:29.674311  2305 solver.cpp:218] Iteration 27100 (7.02062 iter/s, 14.2438s/100 iters), loss = 0.15183
I0929 15:39:29.674341  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15183 (* 1 = 0.15183 loss)
I0929 15:39:29.674348  2305 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0929 15:39:43.922293  2305 solver.cpp:218] Iteration 27200 (7.01857 iter/s, 14.2479s/100 iters), loss = 0.272328
I0929 15:39:43.922397  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272328 (* 1 = 0.272328 loss)
I0929 15:39:43.922416  2305 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0929 15:39:58.174355  2305 solver.cpp:218] Iteration 27300 (7.0166 iter/s, 14.2519s/100 iters), loss = 0.184263
I0929 15:39:58.174391  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184263 (* 1 = 0.184263 loss)
I0929 15:39:58.174399  2305 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0929 15:40:12.419175  2305 solver.cpp:218] Iteration 27400 (7.02013 iter/s, 14.2447s/100 iters), loss = 0.175774
I0929 15:40:12.419209  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175774 (* 1 = 0.175774 loss)
I0929 15:40:12.419215  2305 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0929 15:40:25.960676  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:40:26.527856  2305 solver.cpp:330] Iteration 27500, Testing net (#0)
I0929 15:40:29.884634  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:40:30.024332  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7666
I0929 15:40:30.024355  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.767954 (* 1 = 0.767954 loss)
I0929 15:40:30.165246  2305 solver.cpp:218] Iteration 27500 (5.63508 iter/s, 17.746s/100 iters), loss = 0.13499
I0929 15:40:30.165276  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13499 (* 1 = 0.13499 loss)
I0929 15:40:30.165282  2305 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0929 15:40:44.425931  2305 solver.cpp:218] Iteration 27600 (7.01232 iter/s, 14.2606s/100 iters), loss = 0.244458
I0929 15:40:44.425962  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244458 (* 1 = 0.244458 loss)
I0929 15:40:44.425978  2305 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0929 15:40:58.679666  2305 solver.cpp:218] Iteration 27700 (7.01574 iter/s, 14.2537s/100 iters), loss = 0.200926
I0929 15:40:58.679790  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200926 (* 1 = 0.200926 loss)
I0929 15:40:58.679800  2305 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0929 15:41:12.914862  2305 solver.cpp:218] Iteration 27800 (7.02493 iter/s, 14.235s/100 iters), loss = 0.249135
I0929 15:41:12.914901  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249135 (* 1 = 0.249135 loss)
I0929 15:41:12.914909  2305 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0929 15:41:27.175921  2305 solver.cpp:218] Iteration 27900 (7.01214 iter/s, 14.261s/100 iters), loss = 0.143358
I0929 15:41:27.175952  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143358 (* 1 = 0.143358 loss)
I0929 15:41:27.175959  2305 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0929 15:41:40.722195  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:41:41.291465  2305 solver.cpp:330] Iteration 28000, Testing net (#0)
I0929 15:41:44.646456  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:41:44.786437  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8119
I0929 15:41:44.786473  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.575401 (* 1 = 0.575401 loss)
I0929 15:41:44.927144  2305 solver.cpp:218] Iteration 28000 (5.63344 iter/s, 17.7511s/100 iters), loss = 0.225829
I0929 15:41:44.927172  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225829 (* 1 = 0.225829 loss)
I0929 15:41:44.927178  2305 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0929 15:41:59.164230  2305 solver.cpp:218] Iteration 28100 (7.02394 iter/s, 14.237s/100 iters), loss = 0.210213
I0929 15:41:59.164261  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210212 (* 1 = 0.210212 loss)
I0929 15:41:59.164268  2305 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0929 15:42:13.425505  2305 solver.cpp:218] Iteration 28200 (7.01203 iter/s, 14.2612s/100 iters), loss = 0.138634
I0929 15:42:13.425652  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138634 (* 1 = 0.138634 loss)
I0929 15:42:13.425662  2305 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0929 15:42:27.674207  2305 solver.cpp:218] Iteration 28300 (7.01827 iter/s, 14.2485s/100 iters), loss = 0.226121
I0929 15:42:27.674247  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226121 (* 1 = 0.226121 loss)
I0929 15:42:27.674253  2305 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0929 15:42:41.920797  2305 solver.cpp:218] Iteration 28400 (7.01927 iter/s, 14.2465s/100 iters), loss = 0.224372
I0929 15:42:41.920830  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224371 (* 1 = 0.224371 loss)
I0929 15:42:41.920846  2305 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0929 15:42:55.464313  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:42:56.032708  2305 solver.cpp:330] Iteration 28500, Testing net (#0)
I0929 15:42:59.391968  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:42:59.532003  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7566
I0929 15:42:59.532039  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.835328 (* 1 = 0.835328 loss)
I0929 15:42:59.673233  2305 solver.cpp:218] Iteration 28500 (5.63306 iter/s, 17.7524s/100 iters), loss = 0.276864
I0929 15:42:59.673262  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276864 (* 1 = 0.276864 loss)
I0929 15:42:59.673269  2305 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0929 15:43:13.932457  2305 solver.cpp:218] Iteration 28600 (7.01304 iter/s, 14.2592s/100 iters), loss = 0.216712
I0929 15:43:13.932494  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216712 (* 1 = 0.216712 loss)
I0929 15:43:13.932502  2305 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0929 15:43:28.173904  2305 solver.cpp:218] Iteration 28700 (7.0218 iter/s, 14.2414s/100 iters), loss = 0.173644
I0929 15:43:28.174018  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173643 (* 1 = 0.173643 loss)
I0929 15:43:28.174037  2305 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0929 15:43:42.411453  2305 solver.cpp:218] Iteration 28800 (7.02375 iter/s, 14.2374s/100 iters), loss = 0.196744
I0929 15:43:42.411484  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196743 (* 1 = 0.196743 loss)
I0929 15:43:42.411489  2305 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0929 15:43:56.665148  2305 solver.cpp:218] Iteration 28900 (7.01576 iter/s, 14.2536s/100 iters), loss = 0.177465
I0929 15:43:56.665179  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177465 (* 1 = 0.177465 loss)
I0929 15:43:56.665184  2305 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0929 15:44:10.212900  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:44:10.780930  2305 solver.cpp:330] Iteration 29000, Testing net (#0)
I0929 15:44:14.137188  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:44:14.276736  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8247
I0929 15:44:14.276772  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.53404 (* 1 = 0.53404 loss)
I0929 15:44:14.417567  2305 solver.cpp:218] Iteration 29000 (5.63306 iter/s, 17.7523s/100 iters), loss = 0.199107
I0929 15:44:14.417599  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199107 (* 1 = 0.199107 loss)
I0929 15:44:14.417606  2305 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0929 15:44:28.659999  2305 solver.cpp:218] Iteration 29100 (7.02131 iter/s, 14.2424s/100 iters), loss = 0.189686
I0929 15:44:28.660032  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189686 (* 1 = 0.189686 loss)
I0929 15:44:28.660040  2305 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0929 15:44:42.909811  2305 solver.cpp:218] Iteration 29200 (7.01768 iter/s, 14.2497s/100 iters), loss = 0.244767
I0929 15:44:42.909904  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244767 (* 1 = 0.244767 loss)
I0929 15:44:42.909912  2305 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0929 15:44:57.152948  2305 solver.cpp:218] Iteration 29300 (7.02101 iter/s, 14.243s/100 iters), loss = 0.150361
I0929 15:44:57.152981  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150361 (* 1 = 0.150361 loss)
I0929 15:44:57.152988  2305 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0929 15:45:11.394711  2305 solver.cpp:218] Iteration 29400 (7.02164 iter/s, 14.2417s/100 iters), loss = 0.16133
I0929 15:45:11.394740  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16133 (* 1 = 0.16133 loss)
I0929 15:45:11.394747  2305 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0929 15:45:24.937711  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:45:25.512292  2305 solver.cpp:330] Iteration 29500, Testing net (#0)
I0929 15:45:28.870386  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:45:29.010365  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8117
I0929 15:45:29.010399  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.592523 (* 1 = 0.592523 loss)
I0929 15:45:29.150182  2305 solver.cpp:218] Iteration 29500 (5.63209 iter/s, 17.7554s/100 iters), loss = 0.159945
I0929 15:45:29.150210  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159944 (* 1 = 0.159944 loss)
I0929 15:45:29.150218  2305 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0929 15:45:43.398167  2305 solver.cpp:218] Iteration 29600 (7.01857 iter/s, 14.2479s/100 iters), loss = 0.25753
I0929 15:45:43.398210  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257529 (* 1 = 0.257529 loss)
I0929 15:45:43.398216  2305 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0929 15:45:57.631382  2305 solver.cpp:218] Iteration 29700 (7.02586 iter/s, 14.2331s/100 iters), loss = 0.244802
I0929 15:45:57.631490  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244802 (* 1 = 0.244802 loss)
I0929 15:45:57.631497  2305 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0929 15:46:11.885598  2305 solver.cpp:218] Iteration 29800 (7.01554 iter/s, 14.2541s/100 iters), loss = 0.194125
I0929 15:46:11.885628  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194124 (* 1 = 0.194124 loss)
I0929 15:46:11.885645  2305 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0929 15:46:26.142277  2305 solver.cpp:218] Iteration 29900 (7.01429 iter/s, 14.2566s/100 iters), loss = 0.232059
I0929 15:46:26.142307  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232059 (* 1 = 0.232059 loss)
I0929 15:46:26.142313  2305 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0929 15:46:39.666216  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:46:40.242971  2305 solver.cpp:330] Iteration 30000, Testing net (#0)
I0929 15:46:43.597249  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:46:43.737114  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6928
I0929 15:46:43.737149  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01964 (* 1 = 1.01964 loss)
I0929 15:46:43.879079  2305 solver.cpp:218] Iteration 30000 (5.63802 iter/s, 17.7367s/100 iters), loss = 0.205267
I0929 15:46:43.879112  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205267 (* 1 = 0.205267 loss)
I0929 15:46:43.879119  2305 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0929 15:46:58.128978  2305 solver.cpp:218] Iteration 30100 (7.01763 iter/s, 14.2498s/100 iters), loss = 0.223201
I0929 15:46:58.129014  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223201 (* 1 = 0.223201 loss)
I0929 15:46:58.129021  2305 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0929 15:47:12.371103  2305 solver.cpp:218] Iteration 30200 (7.02146 iter/s, 14.2421s/100 iters), loss = 0.284039
I0929 15:47:12.371238  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284039 (* 1 = 0.284039 loss)
I0929 15:47:12.371246  2305 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0929 15:47:26.618640  2305 solver.cpp:218] Iteration 30300 (7.01884 iter/s, 14.2474s/100 iters), loss = 0.229485
I0929 15:47:26.618670  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229484 (* 1 = 0.229484 loss)
I0929 15:47:26.618677  2305 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0929 15:47:40.868993  2305 solver.cpp:218] Iteration 30400 (7.0174 iter/s, 14.2503s/100 iters), loss = 0.210804
I0929 15:47:40.869024  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210803 (* 1 = 0.210803 loss)
I0929 15:47:40.869031  2305 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0929 15:47:54.408967  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:47:54.981276  2305 solver.cpp:330] Iteration 30500, Testing net (#0)
I0929 15:47:58.339673  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:47:58.479660  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7929
I0929 15:47:58.479686  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.643448 (* 1 = 0.643448 loss)
I0929 15:47:58.619828  2305 solver.cpp:218] Iteration 30500 (5.63356 iter/s, 17.7508s/100 iters), loss = 0.182815
I0929 15:47:58.619863  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182815 (* 1 = 0.182815 loss)
I0929 15:47:58.619869  2305 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0929 15:48:12.848981  2305 solver.cpp:218] Iteration 30600 (7.02786 iter/s, 14.2291s/100 iters), loss = 0.115951
I0929 15:48:12.849026  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11595 (* 1 = 0.11595 loss)
I0929 15:48:12.849033  2305 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0929 15:48:27.084025  2305 solver.cpp:218] Iteration 30700 (7.02496 iter/s, 14.235s/100 iters), loss = 0.211268
I0929 15:48:27.084167  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211267 (* 1 = 0.211267 loss)
I0929 15:48:27.084175  2305 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0929 15:48:41.323748  2305 solver.cpp:218] Iteration 30800 (7.02269 iter/s, 14.2396s/100 iters), loss = 0.143414
I0929 15:48:41.323779  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143414 (* 1 = 0.143414 loss)
I0929 15:48:41.323786  2305 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0929 15:48:55.566422  2305 solver.cpp:218] Iteration 30900 (7.02119 iter/s, 14.2426s/100 iters), loss = 0.172154
I0929 15:48:55.566454  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172154 (* 1 = 0.172154 loss)
I0929 15:48:55.566462  2305 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0929 15:49:09.092417  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:49:09.660894  2305 solver.cpp:330] Iteration 31000, Testing net (#0)
I0929 15:49:13.022122  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:49:13.164868  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.705
I0929 15:49:13.164894  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.926414 (* 1 = 0.926414 loss)
I0929 15:49:13.306587  2305 solver.cpp:218] Iteration 31000 (5.63695 iter/s, 17.7401s/100 iters), loss = 0.13182
I0929 15:49:13.306622  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131819 (* 1 = 0.131819 loss)
I0929 15:49:13.306628  2305 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0929 15:49:27.546929  2305 solver.cpp:218] Iteration 31100 (7.02234 iter/s, 14.2403s/100 iters), loss = 0.183475
I0929 15:49:27.546962  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183474 (* 1 = 0.183474 loss)
I0929 15:49:27.546967  2305 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0929 15:49:41.794500  2305 solver.cpp:218] Iteration 31200 (7.01877 iter/s, 14.2475s/100 iters), loss = 0.237865
I0929 15:49:41.794649  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237865 (* 1 = 0.237865 loss)
I0929 15:49:41.794657  2305 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0929 15:49:56.033681  2305 solver.cpp:218] Iteration 31300 (7.02297 iter/s, 14.239s/100 iters), loss = 0.0904542
I0929 15:49:56.033711  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0904537 (* 1 = 0.0904537 loss)
I0929 15:49:56.033718  2305 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0929 15:50:10.278542  2305 solver.cpp:218] Iteration 31400 (7.02011 iter/s, 14.2448s/100 iters), loss = 0.124313
I0929 15:50:10.278574  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124312 (* 1 = 0.124312 loss)
I0929 15:50:10.278581  2305 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0929 15:50:23.808877  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:50:24.378461  2305 solver.cpp:330] Iteration 31500, Testing net (#0)
I0929 15:50:27.733330  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:50:27.874001  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8087
I0929 15:50:27.874042  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.633385 (* 1 = 0.633385 loss)
I0929 15:50:28.018442  2305 solver.cpp:218] Iteration 31500 (5.63704 iter/s, 17.7398s/100 iters), loss = 0.133691
I0929 15:50:28.018481  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133691 (* 1 = 0.133691 loss)
I0929 15:50:28.018488  2305 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0929 15:50:42.268839  2305 solver.cpp:218] Iteration 31600 (7.01739 iter/s, 14.2503s/100 iters), loss = 0.260241
I0929 15:50:42.268877  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260241 (* 1 = 0.260241 loss)
I0929 15:50:42.268887  2305 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0929 15:50:56.521267  2305 solver.cpp:218] Iteration 31700 (7.01639 iter/s, 14.2523s/100 iters), loss = 0.217496
I0929 15:50:56.521412  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217495 (* 1 = 0.217495 loss)
I0929 15:50:56.521421  2305 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0929 15:51:10.782757  2305 solver.cpp:218] Iteration 31800 (7.01198 iter/s, 14.2613s/100 iters), loss = 0.199877
I0929 15:51:10.782788  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199877 (* 1 = 0.199877 loss)
I0929 15:51:10.782805  2305 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0929 15:51:25.024641  2305 solver.cpp:218] Iteration 31900 (7.02158 iter/s, 14.2418s/100 iters), loss = 0.122662
I0929 15:51:25.024678  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122662 (* 1 = 0.122662 loss)
I0929 15:51:25.024686  2305 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0929 15:51:38.559103  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:51:39.128589  2305 solver.cpp:330] Iteration 32000, Testing net (#0)
I0929 15:51:42.486352  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:51:42.626288  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8303
I0929 15:51:42.626322  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.521627 (* 1 = 0.521627 loss)
I0929 15:51:42.766732  2305 solver.cpp:218] Iteration 32000 (5.63634 iter/s, 17.742s/100 iters), loss = 0.195413
I0929 15:51:42.766762  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195412 (* 1 = 0.195412 loss)
I0929 15:51:42.766768  2305 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0929 15:51:57.016878  2305 solver.cpp:218] Iteration 32100 (7.0175 iter/s, 14.2501s/100 iters), loss = 0.195971
I0929 15:51:57.016907  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195971 (* 1 = 0.195971 loss)
I0929 15:51:57.016913  2305 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0929 15:52:11.264695  2305 solver.cpp:218] Iteration 32200 (7.01865 iter/s, 14.2477s/100 iters), loss = 0.144122
I0929 15:52:11.264842  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144122 (* 1 = 0.144122 loss)
I0929 15:52:11.264852  2305 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0929 15:52:25.504477  2305 solver.cpp:218] Iteration 32300 (7.02267 iter/s, 14.2396s/100 iters), loss = 0.188225
I0929 15:52:25.504509  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188224 (* 1 = 0.188224 loss)
I0929 15:52:25.504516  2305 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0929 15:52:39.742571  2305 solver.cpp:218] Iteration 32400 (7.02345 iter/s, 14.238s/100 iters), loss = 0.205768
I0929 15:52:39.742601  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205768 (* 1 = 0.205768 loss)
I0929 15:52:39.742617  2305 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0929 15:52:53.286362  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:52:53.854795  2305 solver.cpp:330] Iteration 32500, Testing net (#0)
I0929 15:52:57.207275  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:52:57.346879  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6489
I0929 15:52:57.346904  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26276 (* 1 = 1.26276 loss)
I0929 15:52:57.488222  2305 solver.cpp:218] Iteration 32500 (5.63521 iter/s, 17.7456s/100 iters), loss = 0.147512
I0929 15:52:57.488255  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147512 (* 1 = 0.147512 loss)
I0929 15:52:57.488260  2305 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0929 15:53:11.734694  2305 solver.cpp:218] Iteration 32600 (7.01932 iter/s, 14.2464s/100 iters), loss = 0.15679
I0929 15:53:11.734722  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156789 (* 1 = 0.156789 loss)
I0929 15:53:11.734728  2305 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0929 15:53:25.985117  2305 solver.cpp:218] Iteration 32700 (7.01737 iter/s, 14.2503s/100 iters), loss = 0.219871
I0929 15:53:25.985224  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21987 (* 1 = 0.21987 loss)
I0929 15:53:25.985230  2305 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0929 15:53:40.240527  2305 solver.cpp:218] Iteration 32800 (7.01495 iter/s, 14.2553s/100 iters), loss = 0.214616
I0929 15:53:40.240574  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214615 (* 1 = 0.214615 loss)
I0929 15:53:40.240581  2305 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0929 15:53:54.475939  2305 solver.cpp:218] Iteration 32900 (7.02478 iter/s, 14.2353s/100 iters), loss = 0.145176
I0929 15:53:54.475972  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145175 (* 1 = 0.145175 loss)
I0929 15:53:54.475980  2305 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0929 15:54:08.022550  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:54:08.591033  2305 solver.cpp:330] Iteration 33000, Testing net (#0)
I0929 15:54:11.949584  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:54:12.089771  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7911
I0929 15:54:12.089807  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.665388 (* 1 = 0.665388 loss)
I0929 15:54:12.230717  2305 solver.cpp:218] Iteration 33000 (5.63231 iter/s, 17.7547s/100 iters), loss = 0.153775
I0929 15:54:12.230751  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153775 (* 1 = 0.153775 loss)
I0929 15:54:12.230757  2305 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0929 15:54:26.487012  2305 solver.cpp:218] Iteration 33100 (7.01448 iter/s, 14.2562s/100 iters), loss = 0.245038
I0929 15:54:26.487053  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245037 (* 1 = 0.245037 loss)
I0929 15:54:26.487061  2305 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0929 15:54:40.738494  2305 solver.cpp:218] Iteration 33200 (7.01685 iter/s, 14.2514s/100 iters), loss = 0.195548
I0929 15:54:40.738639  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195548 (* 1 = 0.195548 loss)
I0929 15:54:40.738647  2305 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0929 15:54:54.979385  2305 solver.cpp:218] Iteration 33300 (7.02212 iter/s, 14.2407s/100 iters), loss = 0.23125
I0929 15:54:54.979421  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23125 (* 1 = 0.23125 loss)
I0929 15:54:54.979429  2305 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0929 15:55:09.233062  2305 solver.cpp:218] Iteration 33400 (7.01579 iter/s, 14.2536s/100 iters), loss = 0.122394
I0929 15:55:09.233103  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122394 (* 1 = 0.122394 loss)
I0929 15:55:09.233110  2305 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0929 15:55:22.777112  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:55:23.346160  2305 solver.cpp:330] Iteration 33500, Testing net (#0)
I0929 15:55:26.702733  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:55:26.842615  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.797
I0929 15:55:26.842649  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687299 (* 1 = 0.687299 loss)
I0929 15:55:26.983417  2305 solver.cpp:218] Iteration 33500 (5.63372 iter/s, 17.7503s/100 iters), loss = 0.20045
I0929 15:55:26.983448  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20045 (* 1 = 0.20045 loss)
I0929 15:55:26.983454  2305 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0929 15:55:41.237520  2305 solver.cpp:218] Iteration 33600 (7.01556 iter/s, 14.254s/100 iters), loss = 0.14173
I0929 15:55:41.237551  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141729 (* 1 = 0.141729 loss)
I0929 15:55:41.237568  2305 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0929 15:55:55.494010  2305 solver.cpp:218] Iteration 33700 (7.01439 iter/s, 14.2564s/100 iters), loss = 0.25097
I0929 15:55:55.494129  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250969 (* 1 = 0.250969 loss)
I0929 15:55:55.494148  2305 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0929 15:56:09.742599  2305 solver.cpp:218] Iteration 33800 (7.01831 iter/s, 14.2484s/100 iters), loss = 0.196221
I0929 15:56:09.742630  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196221 (* 1 = 0.196221 loss)
I0929 15:56:09.742646  2305 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0929 15:56:23.986018  2305 solver.cpp:218] Iteration 33900 (7.02082 iter/s, 14.2433s/100 iters), loss = 0.191557
I0929 15:56:23.986048  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191557 (* 1 = 0.191557 loss)
I0929 15:56:23.986054  2305 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0929 15:56:37.536903  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:56:38.104341  2305 solver.cpp:330] Iteration 34000, Testing net (#0)
I0929 15:56:41.460892  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:56:41.600667  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6339
I0929 15:56:41.600692  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.44914 (* 1 = 1.44914 loss)
I0929 15:56:41.741436  2305 solver.cpp:218] Iteration 34000 (5.63211 iter/s, 17.7553s/100 iters), loss = 0.243713
I0929 15:56:41.741494  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243712 (* 1 = 0.243712 loss)
I0929 15:56:41.741500  2305 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0929 15:56:55.992774  2305 solver.cpp:218] Iteration 34100 (7.01694 iter/s, 14.2512s/100 iters), loss = 0.140914
I0929 15:56:55.992805  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140913 (* 1 = 0.140913 loss)
I0929 15:56:55.992812  2305 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0929 15:57:10.235230  2305 solver.cpp:218] Iteration 34200 (7.0213 iter/s, 14.2424s/100 iters), loss = 0.236556
I0929 15:57:10.235357  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236556 (* 1 = 0.236556 loss)
I0929 15:57:10.235365  2305 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0929 15:57:24.478430  2305 solver.cpp:218] Iteration 34300 (7.02098 iter/s, 14.243s/100 iters), loss = 0.14795
I0929 15:57:24.478461  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14795 (* 1 = 0.14795 loss)
I0929 15:57:24.478467  2305 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0929 15:57:38.732208  2305 solver.cpp:218] Iteration 34400 (7.01572 iter/s, 14.2537s/100 iters), loss = 0.103388
I0929 15:57:38.732237  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103388 (* 1 = 0.103388 loss)
I0929 15:57:38.732244  2305 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0929 15:57:52.279300  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:57:52.847750  2305 solver.cpp:330] Iteration 34500, Testing net (#0)
I0929 15:57:56.202675  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:57:56.342494  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7425
I0929 15:57:56.342521  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.832667 (* 1 = 0.832667 loss)
I0929 15:57:56.482955  2305 solver.cpp:218] Iteration 34500 (5.63359 iter/s, 17.7507s/100 iters), loss = 0.139798
I0929 15:57:56.482985  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139798 (* 1 = 0.139798 loss)
I0929 15:57:56.482992  2305 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0929 15:58:10.738165  2305 solver.cpp:218] Iteration 34600 (7.01501 iter/s, 14.2551s/100 iters), loss = 0.116094
I0929 15:58:10.738198  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116093 (* 1 = 0.116093 loss)
I0929 15:58:10.738204  2305 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0929 15:58:24.993713  2305 solver.cpp:218] Iteration 34700 (7.01485 iter/s, 14.2555s/100 iters), loss = 0.195403
I0929 15:58:24.993861  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195403 (* 1 = 0.195403 loss)
I0929 15:58:24.993883  2305 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0929 15:58:39.230720  2305 solver.cpp:218] Iteration 34800 (7.02405 iter/s, 14.2368s/100 iters), loss = 0.0895382
I0929 15:58:39.230756  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0895379 (* 1 = 0.0895379 loss)
I0929 15:58:39.230762  2305 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0929 15:58:53.477105  2305 solver.cpp:218] Iteration 34900 (7.01936 iter/s, 14.2463s/100 iters), loss = 0.157516
I0929 15:58:53.477138  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157515 (* 1 = 0.157515 loss)
I0929 15:58:53.477144  2305 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0929 15:59:07.021912  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:59:07.597586  2305 solver.cpp:330] Iteration 35000, Testing net (#0)
I0929 15:59:10.954627  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:59:11.094368  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7379
I0929 15:59:11.094403  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03448 (* 1 = 1.03448 loss)
I0929 15:59:11.235214  2305 solver.cpp:218] Iteration 35000 (5.63126 iter/s, 17.758s/100 iters), loss = 0.13184
I0929 15:59:11.235244  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13184 (* 1 = 0.13184 loss)
I0929 15:59:11.235251  2305 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0929 15:59:25.483188  2305 solver.cpp:218] Iteration 35100 (7.01858 iter/s, 14.2479s/100 iters), loss = 0.15247
I0929 15:59:25.483232  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15247 (* 1 = 0.15247 loss)
I0929 15:59:25.483238  2305 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0929 15:59:39.716984  2305 solver.cpp:218] Iteration 35200 (7.02557 iter/s, 14.2337s/100 iters), loss = 0.178365
I0929 15:59:39.717134  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178364 (* 1 = 0.178364 loss)
I0929 15:59:39.717150  2305 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0929 15:59:53.968642  2305 solver.cpp:218] Iteration 35300 (7.01682 iter/s, 14.2515s/100 iters), loss = 0.118533
I0929 15:59:53.968674  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118533 (* 1 = 0.118533 loss)
I0929 15:59:53.968680  2305 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0929 16:00:08.226315  2305 solver.cpp:218] Iteration 35400 (7.0138 iter/s, 14.2576s/100 iters), loss = 0.162092
I0929 16:00:08.226346  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162091 (* 1 = 0.162091 loss)
I0929 16:00:08.226351  2305 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0929 16:00:21.755177  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:00:22.331121  2305 solver.cpp:330] Iteration 35500, Testing net (#0)
I0929 16:00:25.687338  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:00:25.827415  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7042
I0929 16:00:25.827450  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04518 (* 1 = 1.04518 loss)
I0929 16:00:25.968327  2305 solver.cpp:218] Iteration 35500 (5.63636 iter/s, 17.7419s/100 iters), loss = 0.142814
I0929 16:00:25.968358  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142814 (* 1 = 0.142814 loss)
I0929 16:00:25.968364  2305 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0929 16:00:40.221916  2305 solver.cpp:218] Iteration 35600 (7.01582 iter/s, 14.2535s/100 iters), loss = 0.314835
I0929 16:00:40.221952  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314835 (* 1 = 0.314835 loss)
I0929 16:00:40.221961  2305 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0929 16:00:54.456730  2305 solver.cpp:218] Iteration 35700 (7.02509 iter/s, 14.2347s/100 iters), loss = 0.154125
I0929 16:00:54.456845  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154124 (* 1 = 0.154124 loss)
I0929 16:00:54.456852  2305 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0929 16:01:08.697510  2305 solver.cpp:218] Iteration 35800 (7.02216 iter/s, 14.2406s/100 iters), loss = 0.168536
I0929 16:01:08.697540  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168536 (* 1 = 0.168536 loss)
I0929 16:01:08.697546  2305 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0929 16:01:22.941766  2305 solver.cpp:218] Iteration 35900 (7.02041 iter/s, 14.2442s/100 iters), loss = 0.156505
I0929 16:01:22.941795  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156505 (* 1 = 0.156505 loss)
I0929 16:01:22.941802  2305 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0929 16:01:36.472421  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:01:37.043797  2305 solver.cpp:330] Iteration 36000, Testing net (#0)
I0929 16:01:40.405203  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:01:40.544937  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5624
I0929 16:01:40.544963  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.89976 (* 1 = 1.89976 loss)
I0929 16:01:40.686383  2305 solver.cpp:218] Iteration 36000 (5.63554 iter/s, 17.7445s/100 iters), loss = 0.161866
I0929 16:01:40.686414  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161866 (* 1 = 0.161866 loss)
I0929 16:01:40.686421  2305 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0929 16:01:54.916617  2305 solver.cpp:218] Iteration 36100 (7.02733 iter/s, 14.2302s/100 iters), loss = 0.156913
I0929 16:01:54.916647  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156913 (* 1 = 0.156913 loss)
I0929 16:01:54.916653  2305 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0929 16:02:09.163820  2305 solver.cpp:218] Iteration 36200 (7.01895 iter/s, 14.2471s/100 iters), loss = 0.109149
I0929 16:02:09.163965  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109149 (* 1 = 0.109149 loss)
I0929 16:02:09.163983  2305 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0929 16:02:23.407769  2305 solver.cpp:218] Iteration 36300 (7.02062 iter/s, 14.2438s/100 iters), loss = 0.118253
I0929 16:02:23.407807  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118252 (* 1 = 0.118252 loss)
I0929 16:02:23.407815  2305 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0929 16:02:37.641860  2305 solver.cpp:218] Iteration 36400 (7.02542 iter/s, 14.234s/100 iters), loss = 0.191918
I0929 16:02:37.641890  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191918 (* 1 = 0.191918 loss)
I0929 16:02:37.641906  2305 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0929 16:02:51.167191  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:02:51.735671  2305 solver.cpp:330] Iteration 36500, Testing net (#0)
I0929 16:02:55.099540  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:02:55.243665  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8376
I0929 16:02:55.243702  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.518046 (* 1 = 0.518046 loss)
I0929 16:02:55.384057  2305 solver.cpp:218] Iteration 36500 (5.6363 iter/s, 17.7421s/100 iters), loss = 0.144711
I0929 16:02:55.384091  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144711 (* 1 = 0.144711 loss)
I0929 16:02:55.384099  2305 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0929 16:03:09.637346  2305 solver.cpp:218] Iteration 36600 (7.01596 iter/s, 14.2532s/100 iters), loss = 0.196407
I0929 16:03:09.637387  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196407 (* 1 = 0.196407 loss)
I0929 16:03:09.637393  2305 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0929 16:03:23.890370  2305 solver.cpp:218] Iteration 36700 (7.0161 iter/s, 14.2529s/100 iters), loss = 0.223905
I0929 16:03:23.890449  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223904 (* 1 = 0.223904 loss)
I0929 16:03:23.890465  2305 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0929 16:03:38.141741  2305 solver.cpp:218] Iteration 36800 (7.01693 iter/s, 14.2513s/100 iters), loss = 0.121837
I0929 16:03:38.141782  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121836 (* 1 = 0.121836 loss)
I0929 16:03:38.141788  2305 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0929 16:03:52.395512  2305 solver.cpp:218] Iteration 36900 (7.01573 iter/s, 14.2537s/100 iters), loss = 0.203562
I0929 16:03:52.395551  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203562 (* 1 = 0.203562 loss)
I0929 16:03:52.395558  2305 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0929 16:04:05.933338  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:04:06.502434  2305 solver.cpp:330] Iteration 37000, Testing net (#0)
I0929 16:04:09.857398  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:04:09.998600  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8141
I0929 16:04:09.998628  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.565604 (* 1 = 0.565604 loss)
I0929 16:04:10.142772  2305 solver.cpp:218] Iteration 37000 (5.6347 iter/s, 17.7472s/100 iters), loss = 0.185901
I0929 16:04:10.142812  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185901 (* 1 = 0.185901 loss)
I0929 16:04:10.142819  2305 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0929 16:04:24.378378  2305 solver.cpp:218] Iteration 37100 (7.02468 iter/s, 14.2355s/100 iters), loss = 0.223425
I0929 16:04:24.378419  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223425 (* 1 = 0.223425 loss)
I0929 16:04:24.378425  2305 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0929 16:04:38.624482  2305 solver.cpp:218] Iteration 37200 (7.0195 iter/s, 14.246s/100 iters), loss = 0.100332
I0929 16:04:38.624644  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100332 (* 1 = 0.100332 loss)
I0929 16:04:38.624653  2305 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0929 16:04:52.875465  2305 solver.cpp:218] Iteration 37300 (7.01716 iter/s, 14.2508s/100 iters), loss = 0.196294
I0929 16:04:52.875497  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196294 (* 1 = 0.196294 loss)
I0929 16:04:52.875504  2305 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0929 16:05:07.112201  2305 solver.cpp:218] Iteration 37400 (7.02412 iter/s, 14.2367s/100 iters), loss = 0.122101
I0929 16:05:07.112239  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1221 (* 1 = 0.1221 loss)
I0929 16:05:07.112247  2305 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0929 16:05:20.650065  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:05:21.217900  2305 solver.cpp:330] Iteration 37500, Testing net (#0)
I0929 16:05:24.573807  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:05:24.713184  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7786
I0929 16:05:24.713210  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.730138 (* 1 = 0.730138 loss)
I0929 16:05:24.854313  2305 solver.cpp:218] Iteration 37500 (5.63634 iter/s, 17.742s/100 iters), loss = 0.158863
I0929 16:05:24.854346  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158863 (* 1 = 0.158863 loss)
I0929 16:05:24.854352  2305 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0929 16:05:39.110190  2305 solver.cpp:218] Iteration 37600 (7.01468 iter/s, 14.2558s/100 iters), loss = 0.142351
I0929 16:05:39.110231  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14235 (* 1 = 0.14235 loss)
I0929 16:05:39.110236  2305 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0929 16:05:53.359194  2305 solver.cpp:218] Iteration 37700 (7.01807 iter/s, 14.2489s/100 iters), loss = 0.249048
I0929 16:05:53.359339  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249047 (* 1 = 0.249047 loss)
I0929 16:05:53.359349  2305 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0929 16:06:07.607554  2305 solver.cpp:218] Iteration 37800 (7.01844 iter/s, 14.2482s/100 iters), loss = 0.159424
I0929 16:06:07.607586  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159423 (* 1 = 0.159423 loss)
I0929 16:06:07.607594  2305 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0929 16:06:21.850556  2305 solver.cpp:218] Iteration 37900 (7.02103 iter/s, 14.2429s/100 iters), loss = 0.109907
I0929 16:06:21.850586  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109907 (* 1 = 0.109907 loss)
I0929 16:06:21.850594  2305 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0929 16:06:35.397339  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:06:35.965421  2305 solver.cpp:330] Iteration 38000, Testing net (#0)
I0929 16:06:39.320245  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:06:39.460294  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.755
I0929 16:06:39.460319  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.887221 (* 1 = 0.887221 loss)
I0929 16:06:39.600498  2305 solver.cpp:218] Iteration 38000 (5.63385 iter/s, 17.7499s/100 iters), loss = 0.192379
I0929 16:06:39.600530  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192379 (* 1 = 0.192379 loss)
I0929 16:06:39.600536  2305 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0929 16:06:53.845233  2305 solver.cpp:218] Iteration 38100 (7.02017 iter/s, 14.2447s/100 iters), loss = 0.159726
I0929 16:06:53.845263  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159726 (* 1 = 0.159726 loss)
I0929 16:06:53.845268  2305 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0929 16:07:08.105334  2305 solver.cpp:218] Iteration 38200 (7.01261 iter/s, 14.26s/100 iters), loss = 0.171239
I0929 16:07:08.105490  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171239 (* 1 = 0.171239 loss)
I0929 16:07:08.105512  2305 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0929 16:07:22.349522  2305 solver.cpp:218] Iteration 38300 (7.0205 iter/s, 14.244s/100 iters), loss = 0.167576
I0929 16:07:22.349558  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167576 (* 1 = 0.167576 loss)
I0929 16:07:22.349565  2305 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0929 16:07:36.584740  2305 solver.cpp:218] Iteration 38400 (7.02487 iter/s, 14.2351s/100 iters), loss = 0.222718
I0929 16:07:36.584770  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222718 (* 1 = 0.222718 loss)
I0929 16:07:36.584786  2305 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0929 16:07:50.126935  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:07:50.697083  2305 solver.cpp:330] Iteration 38500, Testing net (#0)
I0929 16:07:54.053145  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:07:54.192967  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8208
I0929 16:07:54.193002  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.540188 (* 1 = 0.540188 loss)
I0929 16:07:54.334082  2305 solver.cpp:218] Iteration 38500 (5.63404 iter/s, 17.7493s/100 iters), loss = 0.140546
I0929 16:07:54.334116  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140546 (* 1 = 0.140546 loss)
I0929 16:07:54.334123  2305 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0929 16:08:08.585922  2305 solver.cpp:218] Iteration 38600 (7.01668 iter/s, 14.2518s/100 iters), loss = 0.188817
I0929 16:08:08.585954  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188816 (* 1 = 0.188816 loss)
I0929 16:08:08.585960  2305 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0929 16:08:22.826071  2305 solver.cpp:218] Iteration 38700 (7.02243 iter/s, 14.2401s/100 iters), loss = 0.297382
I0929 16:08:22.826207  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297382 (* 1 = 0.297382 loss)
I0929 16:08:22.826215  2305 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0929 16:08:37.067992  2305 solver.cpp:218] Iteration 38800 (7.02161 iter/s, 14.2417s/100 iters), loss = 0.1324
I0929 16:08:37.068040  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1324 (* 1 = 0.1324 loss)
I0929 16:08:37.068048  2305 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0929 16:08:51.314365  2305 solver.cpp:218] Iteration 38900 (7.01939 iter/s, 14.2462s/100 iters), loss = 0.159986
I0929 16:08:51.314405  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159985 (* 1 = 0.159985 loss)
I0929 16:08:51.314412  2305 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0929 16:09:04.851265  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:09:05.419584  2305 solver.cpp:330] Iteration 39000, Testing net (#0)
I0929 16:09:08.773922  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:09:08.913800  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7711
I0929 16:09:08.913836  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.75483 (* 1 = 0.75483 loss)
I0929 16:09:09.054654  2305 solver.cpp:218] Iteration 39000 (5.63691 iter/s, 17.7402s/100 iters), loss = 0.172165
I0929 16:09:09.054684  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172165 (* 1 = 0.172165 loss)
I0929 16:09:09.054692  2305 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0929 16:09:23.306500  2305 solver.cpp:218] Iteration 39100 (7.01667 iter/s, 14.2518s/100 iters), loss = 0.153049
I0929 16:09:23.306532  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153048 (* 1 = 0.153048 loss)
I0929 16:09:23.306538  2305 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0929 16:09:37.562355  2305 solver.cpp:218] Iteration 39200 (7.0147 iter/s, 14.2558s/100 iters), loss = 0.106695
I0929 16:09:37.562536  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106695 (* 1 = 0.106695 loss)
I0929 16:09:37.562546  2305 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0929 16:09:51.806229  2305 solver.cpp:218] Iteration 39300 (7.02066 iter/s, 14.2437s/100 iters), loss = 0.107776
I0929 16:09:51.806269  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107776 (* 1 = 0.107776 loss)
I0929 16:09:51.806277  2305 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0929 16:10:06.058239  2305 solver.cpp:218] Iteration 39400 (7.01659 iter/s, 14.2519s/100 iters), loss = 0.14638
I0929 16:10:06.058269  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14638 (* 1 = 0.14638 loss)
I0929 16:10:06.058275  2305 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0929 16:10:19.610311  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:10:20.179332  2305 solver.cpp:330] Iteration 39500, Testing net (#0)
I0929 16:10:23.536470  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:10:23.676291  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7662
I0929 16:10:23.676327  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.727412 (* 1 = 0.727412 loss)
I0929 16:10:23.816699  2305 solver.cpp:218] Iteration 39500 (5.63114 iter/s, 17.7584s/100 iters), loss = 0.210103
I0929 16:10:23.816730  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210102 (* 1 = 0.210102 loss)
I0929 16:10:23.816735  2305 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0929 16:10:38.057082  2305 solver.cpp:218] Iteration 39600 (7.02232 iter/s, 14.2403s/100 iters), loss = 0.174298
I0929 16:10:38.057116  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174298 (* 1 = 0.174298 loss)
I0929 16:10:38.057121  2305 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0929 16:10:52.306376  2305 solver.cpp:218] Iteration 39700 (7.01793 iter/s, 14.2492s/100 iters), loss = 0.192521
I0929 16:10:52.306494  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19252 (* 1 = 0.19252 loss)
I0929 16:10:52.306504  2305 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0929 16:11:06.553061  2305 solver.cpp:218] Iteration 39800 (7.01925 iter/s, 14.2465s/100 iters), loss = 0.212481
I0929 16:11:06.553092  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21248 (* 1 = 0.21248 loss)
I0929 16:11:06.553099  2305 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0929 16:11:20.794709  2305 solver.cpp:218] Iteration 39900 (7.02169 iter/s, 14.2416s/100 iters), loss = 0.13227
I0929 16:11:20.794739  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132269 (* 1 = 0.132269 loss)
I0929 16:11:20.794745  2305 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0929 16:11:34.324793  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:11:34.895376  2305 solver.cpp:330] Iteration 40000, Testing net (#0)
I0929 16:11:38.250926  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:11:38.390965  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8066
I0929 16:11:38.391000  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648783 (* 1 = 0.648783 loss)
I0929 16:11:38.532549  2305 solver.cpp:218] Iteration 40000 (5.63769 iter/s, 17.7378s/100 iters), loss = 0.162002
I0929 16:11:38.532585  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162001 (* 1 = 0.162001 loss)
I0929 16:11:38.532600  2305 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0929 16:11:38.532604  2305 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0929 16:11:52.806110  2305 solver.cpp:218] Iteration 40100 (7.006 iter/s, 14.2735s/100 iters), loss = 0.164444
I0929 16:11:52.806141  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164444 (* 1 = 0.164444 loss)
I0929 16:11:52.806149  2305 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0929 16:12:07.064910  2305 solver.cpp:218] Iteration 40200 (7.01325 iter/s, 14.2587s/100 iters), loss = 0.0954543
I0929 16:12:07.065135  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0954537 (* 1 = 0.0954537 loss)
I0929 16:12:07.065145  2305 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0929 16:12:21.321594  2305 solver.cpp:218] Iteration 40300 (7.01438 iter/s, 14.2564s/100 iters), loss = 0.0569505
I0929 16:12:21.321635  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0569499 (* 1 = 0.0569499 loss)
I0929 16:12:21.321642  2305 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0929 16:12:35.581928  2305 solver.cpp:218] Iteration 40400 (7.0125 iter/s, 14.2603s/100 iters), loss = 0.120056
I0929 16:12:35.581961  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120055 (* 1 = 0.120055 loss)
I0929 16:12:35.581967  2305 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0929 16:12:49.140404  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:12:49.713376  2305 solver.cpp:330] Iteration 40500, Testing net (#0)
I0929 16:12:53.071178  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:12:53.210925  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I0929 16:12:53.210961  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286269 (* 1 = 0.286269 loss)
I0929 16:12:53.352411  2305 solver.cpp:218] Iteration 40500 (5.62733 iter/s, 17.7704s/100 iters), loss = 0.106034
I0929 16:12:53.352442  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106033 (* 1 = 0.106033 loss)
I0929 16:12:53.352448  2305 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0929 16:13:07.590042  2305 solver.cpp:218] Iteration 40600 (7.02368 iter/s, 14.2376s/100 iters), loss = 0.1035
I0929 16:13:07.590078  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1035 (* 1 = 0.1035 loss)
I0929 16:13:07.590085  2305 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0929 16:13:21.831491  2305 solver.cpp:218] Iteration 40700 (7.02179 iter/s, 14.2414s/100 iters), loss = 0.0556522
I0929 16:13:21.831614  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556517 (* 1 = 0.0556517 loss)
I0929 16:13:21.831632  2305 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0929 16:13:36.079056  2305 solver.cpp:218] Iteration 40800 (7.01882 iter/s, 14.2474s/100 iters), loss = 0.076597
I0929 16:13:36.079088  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765964 (* 1 = 0.0765964 loss)
I0929 16:13:36.079095  2305 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0929 16:13:50.320415  2305 solver.cpp:218] Iteration 40900 (7.02184 iter/s, 14.2413s/100 iters), loss = 0.0340244
I0929 16:13:50.320444  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340238 (* 1 = 0.0340238 loss)
I0929 16:13:50.320451  2305 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0929 16:14:03.848726  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:14:04.426964  2305 solver.cpp:330] Iteration 41000, Testing net (#0)
I0929 16:14:07.783506  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:14:07.923202  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I0929 16:14:07.923228  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255732 (* 1 = 0.255732 loss)
I0929 16:14:08.063884  2305 solver.cpp:218] Iteration 41000 (5.6359 iter/s, 17.7434s/100 iters), loss = 0.0451293
I0929 16:14:08.063916  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451287 (* 1 = 0.0451287 loss)
I0929 16:14:08.063923  2305 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0929 16:14:22.316473  2305 solver.cpp:218] Iteration 41100 (7.01631 iter/s, 14.2525s/100 iters), loss = 0.129077
I0929 16:14:22.316511  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129076 (* 1 = 0.129076 loss)
I0929 16:14:22.316521  2305 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0929 16:14:36.556730  2305 solver.cpp:218] Iteration 41200 (7.02238 iter/s, 14.2402s/100 iters), loss = 0.0553295
I0929 16:14:36.556869  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055329 (* 1 = 0.055329 loss)
I0929 16:14:36.556892  2305 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0929 16:14:50.799628  2305 solver.cpp:218] Iteration 41300 (7.02112 iter/s, 14.2427s/100 iters), loss = 0.0709828
I0929 16:14:50.799661  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0709823 (* 1 = 0.0709823 loss)
I0929 16:14:50.799670  2305 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0929 16:15:05.054014  2305 solver.cpp:218] Iteration 41400 (7.01542 iter/s, 14.2543s/100 iters), loss = 0.0556952
I0929 16:15:05.054051  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556947 (* 1 = 0.0556947 loss)
I0929 16:15:05.054070  2305 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0929 16:15:18.593036  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:15:19.167037  2305 solver.cpp:330] Iteration 41500, Testing net (#0)
I0929 16:15:22.525301  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:15:22.665421  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I0929 16:15:22.665448  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.236277 (* 1 = 0.236277 loss)
I0929 16:15:22.806164  2305 solver.cpp:218] Iteration 41500 (5.63315 iter/s, 17.7521s/100 iters), loss = 0.099861
I0929 16:15:22.806198  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0998605 (* 1 = 0.0998605 loss)
I0929 16:15:22.806208  2305 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0929 16:15:37.049770  2305 solver.cpp:218] Iteration 41600 (7.02073 iter/s, 14.2435s/100 iters), loss = 0.0594541
I0929 16:15:37.049813  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0594537 (* 1 = 0.0594537 loss)
I0929 16:15:37.049834  2305 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0929 16:15:51.307808  2305 solver.cpp:218] Iteration 41700 (7.01364 iter/s, 14.2579s/100 iters), loss = 0.0984272
I0929 16:15:51.307960  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0984267 (* 1 = 0.0984267 loss)
I0929 16:15:51.307986  2305 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0929 16:16:05.562139  2305 solver.cpp:218] Iteration 41800 (7.0155 iter/s, 14.2541s/100 iters), loss = 0.0336598
I0929 16:16:05.562170  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336593 (* 1 = 0.0336593 loss)
I0929 16:16:05.562177  2305 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0929 16:16:19.808423  2305 solver.cpp:218] Iteration 41900 (7.01941 iter/s, 14.2462s/100 iters), loss = 0.0553724
I0929 16:16:19.808465  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553719 (* 1 = 0.0553719 loss)
I0929 16:16:19.808471  2305 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0929 16:16:33.346704  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:16:33.915001  2305 solver.cpp:330] Iteration 42000, Testing net (#0)
I0929 16:16:37.282984  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:16:37.424607  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I0929 16:16:37.424634  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.244913 (* 1 = 0.244913 loss)
I0929 16:16:37.565385  2305 solver.cpp:218] Iteration 42000 (5.63162 iter/s, 17.7569s/100 iters), loss = 0.0466784
I0929 16:16:37.565419  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466778 (* 1 = 0.0466778 loss)
I0929 16:16:37.565425  2305 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0929 16:16:51.804728  2305 solver.cpp:218] Iteration 42100 (7.02283 iter/s, 14.2393s/100 iters), loss = 0.0358849
I0929 16:16:51.804757  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358844 (* 1 = 0.0358844 loss)
I0929 16:16:51.804764  2305 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0929 16:17:06.046020  2305 solver.cpp:218] Iteration 42200 (7.02187 iter/s, 14.2412s/100 iters), loss = 0.0385415
I0929 16:17:06.046185  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.038541 (* 1 = 0.038541 loss)
I0929 16:17:06.046214  2305 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0929 16:17:20.295366  2305 solver.cpp:218] Iteration 42300 (7.01797 iter/s, 14.2491s/100 iters), loss = 0.029191
I0929 16:17:20.295403  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291905 (* 1 = 0.0291905 loss)
I0929 16:17:20.295409  2305 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0929 16:17:34.553458  2305 solver.cpp:218] Iteration 42400 (7.0136 iter/s, 14.258s/100 iters), loss = 0.0240604
I0929 16:17:34.553495  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240598 (* 1 = 0.0240598 loss)
I0929 16:17:34.553503  2305 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0929 16:17:48.087889  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:17:48.655887  2305 solver.cpp:330] Iteration 42500, Testing net (#0)
I0929 16:17:52.011632  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:17:52.154883  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I0929 16:17:52.154942  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.247609 (* 1 = 0.247609 loss)
I0929 16:17:52.298794  2305 solver.cpp:218] Iteration 42500 (5.63531 iter/s, 17.7452s/100 iters), loss = 0.0364529
I0929 16:17:52.298830  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364523 (* 1 = 0.0364523 loss)
I0929 16:17:52.298837  2305 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0929 16:18:06.545161  2305 solver.cpp:218] Iteration 42600 (7.01937 iter/s, 14.2463s/100 iters), loss = 0.0361206
I0929 16:18:06.545197  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03612 (* 1 = 0.03612 loss)
I0929 16:18:06.545203  2305 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0929 16:18:20.805568  2305 solver.cpp:218] Iteration 42700 (7.01246 iter/s, 14.2603s/100 iters), loss = 0.0394384
I0929 16:18:20.805685  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394378 (* 1 = 0.0394378 loss)
I0929 16:18:20.805691  2305 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0929 16:18:35.058284  2305 solver.cpp:218] Iteration 42800 (7.01628 iter/s, 14.2526s/100 iters), loss = 0.0365808
I0929 16:18:35.058317  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365802 (* 1 = 0.0365802 loss)
I0929 16:18:35.058323  2305 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0929 16:18:49.309787  2305 solver.cpp:218] Iteration 42900 (7.01684 iter/s, 14.2514s/100 iters), loss = 0.0206529
I0929 16:18:49.309823  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206523 (* 1 = 0.0206523 loss)
I0929 16:18:49.309831  2305 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0929 16:19:02.859659  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:19:03.427418  2305 solver.cpp:330] Iteration 43000, Testing net (#0)
I0929 16:19:06.786782  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:19:06.925983  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I0929 16:19:06.926008  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.24523 (* 1 = 0.24523 loss)
I0929 16:19:07.067760  2305 solver.cpp:218] Iteration 43000 (5.6313 iter/s, 17.7579s/100 iters), loss = 0.0215025
I0929 16:19:07.067807  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215019 (* 1 = 0.0215019 loss)
I0929 16:19:07.067816  2305 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0929 16:19:21.311506  2305 solver.cpp:218] Iteration 43100 (7.02069 iter/s, 14.2436s/100 iters), loss = 0.0406192
I0929 16:19:21.311545  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406186 (* 1 = 0.0406186 loss)
I0929 16:19:21.311554  2305 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0929 16:19:35.545989  2305 solver.cpp:218] Iteration 43200 (7.02523 iter/s, 14.2344s/100 iters), loss = 0.0412543
I0929 16:19:35.546131  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412537 (* 1 = 0.0412537 loss)
I0929 16:19:35.546150  2305 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0929 16:19:49.800846  2305 solver.cpp:218] Iteration 43300 (7.01524 iter/s, 14.2547s/100 iters), loss = 0.0482345
I0929 16:19:49.800878  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482339 (* 1 = 0.0482339 loss)
I0929 16:19:49.800884  2305 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0929 16:20:04.044800  2305 solver.cpp:218] Iteration 43400 (7.02056 iter/s, 14.2439s/100 iters), loss = 0.0265805
I0929 16:20:04.044829  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265799 (* 1 = 0.0265799 loss)
I0929 16:20:04.044836  2305 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0929 16:20:17.583120  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:20:18.151496  2305 solver.cpp:330] Iteration 43500, Testing net (#0)
I0929 16:20:21.505314  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:20:21.645768  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 16:20:21.645812  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.250745 (* 1 = 0.250745 loss)
I0929 16:20:21.787338  2305 solver.cpp:218] Iteration 43500 (5.6362 iter/s, 17.7425s/100 iters), loss = 0.0363261
I0929 16:20:21.787370  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363255 (* 1 = 0.0363255 loss)
I0929 16:20:21.787376  2305 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0929 16:20:36.039314  2305 solver.cpp:218] Iteration 43600 (7.01661 iter/s, 14.2519s/100 iters), loss = 0.0783497
I0929 16:20:36.039345  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0783491 (* 1 = 0.0783491 loss)
I0929 16:20:36.039351  2305 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0929 16:20:50.293413  2305 solver.cpp:218] Iteration 43700 (7.01556 iter/s, 14.254s/100 iters), loss = 0.0571716
I0929 16:20:50.293524  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057171 (* 1 = 0.057171 loss)
I0929 16:20:50.293531  2305 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0929 16:21:04.537680  2305 solver.cpp:218] Iteration 43800 (7.02044 iter/s, 14.2441s/100 iters), loss = 0.0238588
I0929 16:21:04.537717  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238582 (* 1 = 0.0238582 loss)
I0929 16:21:04.537724  2305 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0929 16:21:18.779995  2305 solver.cpp:218] Iteration 43900 (7.02137 iter/s, 14.2422s/100 iters), loss = 0.0384088
I0929 16:21:18.780025  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384081 (* 1 = 0.0384081 loss)
I0929 16:21:18.780031  2305 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0929 16:21:32.324468  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:21:32.893963  2305 solver.cpp:330] Iteration 44000, Testing net (#0)
I0929 16:21:36.249702  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:21:36.389816  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I0929 16:21:36.389850  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.250641 (* 1 = 0.250641 loss)
I0929 16:21:36.531024  2305 solver.cpp:218] Iteration 44000 (5.6335 iter/s, 17.751s/100 iters), loss = 0.0396353
I0929 16:21:36.531056  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396347 (* 1 = 0.0396347 loss)
I0929 16:21:36.531064  2305 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0929 16:21:50.779716  2305 solver.cpp:218] Iteration 44100 (7.01823 iter/s, 14.2486s/100 iters), loss = 0.028619
I0929 16:21:50.779744  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286184 (* 1 = 0.0286184 loss)
I0929 16:21:50.779750  2305 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0929 16:22:05.027963  2305 solver.cpp:218] Iteration 44200 (7.01844 iter/s, 14.2482s/100 iters), loss = 0.0444741
I0929 16:22:05.028090  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444736 (* 1 = 0.0444736 loss)
I0929 16:22:05.028098  2305 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0929 16:22:19.284126  2305 solver.cpp:218] Iteration 44300 (7.01459 iter/s, 14.256s/100 iters), loss = 0.00682012
I0929 16:22:19.284163  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00681953 (* 1 = 0.00681953 loss)
I0929 16:22:19.284171  2305 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0929 16:22:33.524790  2305 solver.cpp:218] Iteration 44400 (7.02218 iter/s, 14.2406s/100 iters), loss = 0.0314803
I0929 16:22:33.524818  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314797 (* 1 = 0.0314797 loss)
I0929 16:22:33.524824  2305 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0929 16:22:47.062424  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:22:47.631824  2305 solver.cpp:330] Iteration 44500, Testing net (#0)
I0929 16:22:50.986980  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:22:51.127058  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0929 16:22:51.127084  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.251199 (* 1 = 0.251199 loss)
I0929 16:22:51.267094  2305 solver.cpp:218] Iteration 44500 (5.63627 iter/s, 17.7422s/100 iters), loss = 0.0267281
I0929 16:22:51.267125  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267276 (* 1 = 0.0267276 loss)
I0929 16:22:51.267132  2305 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0929 16:23:05.524854  2305 solver.cpp:218] Iteration 44600 (7.01376 iter/s, 14.2577s/100 iters), loss = 0.0209655
I0929 16:23:05.524886  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209649 (* 1 = 0.0209649 loss)
I0929 16:23:05.524893  2305 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0929 16:23:19.775316  2305 solver.cpp:218] Iteration 44700 (7.01735 iter/s, 14.2504s/100 iters), loss = 0.012098
I0929 16:23:19.775434  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120974 (* 1 = 0.0120974 loss)
I0929 16:23:19.775452  2305 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0929 16:23:34.009106  2305 solver.cpp:218] Iteration 44800 (7.02561 iter/s, 14.2336s/100 iters), loss = 0.0113272
I0929 16:23:34.009148  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113266 (* 1 = 0.0113266 loss)
I0929 16:23:34.009155  2305 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0929 16:23:48.256474  2305 solver.cpp:218] Iteration 44900 (7.01888 iter/s, 14.2473s/100 iters), loss = 0.0215146
I0929 16:23:48.256503  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215141 (* 1 = 0.0215141 loss)
I0929 16:23:48.256510  2305 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0929 16:24:01.795861  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:24:02.365742  2305 solver.cpp:330] Iteration 45000, Testing net (#0)
I0929 16:24:05.722486  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:24:05.862342  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 16:24:05.862378  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262203 (* 1 = 0.262203 loss)
I0929 16:24:06.003304  2305 solver.cpp:218] Iteration 45000 (5.63483 iter/s, 17.7467s/100 iters), loss = 0.025315
I0929 16:24:06.003334  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253144 (* 1 = 0.0253144 loss)
I0929 16:24:06.003340  2305 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0929 16:24:20.253298  2305 solver.cpp:218] Iteration 45100 (7.01758 iter/s, 14.2499s/100 iters), loss = 0.0580374
I0929 16:24:20.253329  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580369 (* 1 = 0.0580369 loss)
I0929 16:24:20.253334  2305 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0929 16:24:34.516186  2305 solver.cpp:218] Iteration 45200 (7.01124 iter/s, 14.2628s/100 iters), loss = 0.0459519
I0929 16:24:34.516340  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459513 (* 1 = 0.0459513 loss)
I0929 16:24:34.516347  2305 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0929 16:24:48.776098  2305 solver.cpp:218] Iteration 45300 (7.01276 iter/s, 14.2597s/100 iters), loss = 0.0725027
I0929 16:24:48.776137  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0725021 (* 1 = 0.0725021 loss)
I0929 16:24:48.776144  2305 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0929 16:25:03.032788  2305 solver.cpp:218] Iteration 45400 (7.01429 iter/s, 14.2566s/100 iters), loss = 0.0179813
I0929 16:25:03.032819  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179807 (* 1 = 0.0179807 loss)
I0929 16:25:03.032824  2305 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0929 16:25:16.584018  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:25:17.154779  2305 solver.cpp:330] Iteration 45500, Testing net (#0)
I0929 16:25:20.512552  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:25:20.652199  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I0929 16:25:20.652235  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.254901 (* 1 = 0.254901 loss)
I0929 16:25:20.793401  2305 solver.cpp:218] Iteration 45500 (5.63046 iter/s, 17.7605s/100 iters), loss = 0.00794358
I0929 16:25:20.793431  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794298 (* 1 = 0.00794298 loss)
I0929 16:25:20.793438  2305 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0929 16:25:35.042400  2305 solver.cpp:218] Iteration 45600 (7.01807 iter/s, 14.2489s/100 iters), loss = 0.0297913
I0929 16:25:35.042435  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297907 (* 1 = 0.0297907 loss)
I0929 16:25:35.042441  2305 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0929 16:25:49.278600  2305 solver.cpp:218] Iteration 45700 (7.02438 iter/s, 14.2361s/100 iters), loss = 0.0281996
I0929 16:25:49.278710  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028199 (* 1 = 0.028199 loss)
I0929 16:25:49.278729  2305 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0929 16:26:03.514068  2305 solver.cpp:218] Iteration 45800 (7.02479 iter/s, 14.2353s/100 iters), loss = 0.00636898
I0929 16:26:03.514109  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636838 (* 1 = 0.00636838 loss)
I0929 16:26:03.514117  2305 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0929 16:26:17.766983  2305 solver.cpp:218] Iteration 45900 (7.01615 iter/s, 14.2528s/100 iters), loss = 0.0354488
I0929 16:26:17.767014  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354481 (* 1 = 0.0354481 loss)
I0929 16:26:17.767020  2305 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0929 16:26:31.303797  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:26:31.874037  2305 solver.cpp:330] Iteration 46000, Testing net (#0)
I0929 16:26:35.232026  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:26:35.371913  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0929 16:26:35.371949  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.254919 (* 1 = 0.254919 loss)
I0929 16:26:35.512665  2305 solver.cpp:218] Iteration 46000 (5.6352 iter/s, 17.7456s/100 iters), loss = 0.0185575
I0929 16:26:35.512698  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185569 (* 1 = 0.0185569 loss)
I0929 16:26:35.512706  2305 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0929 16:26:49.748544  2305 solver.cpp:218] Iteration 46100 (7.02454 iter/s, 14.2358s/100 iters), loss = 0.0122183
I0929 16:26:49.748584  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122177 (* 1 = 0.0122177 loss)
I0929 16:26:49.748592  2305 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0929 16:27:03.993752  2305 solver.cpp:218] Iteration 46200 (7.01994 iter/s, 14.2451s/100 iters), loss = 0.0266054
I0929 16:27:03.993827  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266048 (* 1 = 0.0266048 loss)
I0929 16:27:03.993845  2305 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0929 16:27:18.246074  2305 solver.cpp:218] Iteration 46300 (7.01646 iter/s, 14.2522s/100 iters), loss = 0.0122337
I0929 16:27:18.246104  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122331 (* 1 = 0.0122331 loss)
I0929 16:27:18.246110  2305 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0929 16:27:32.491629  2305 solver.cpp:218] Iteration 46400 (7.01977 iter/s, 14.2455s/100 iters), loss = 0.00964191
I0929 16:27:32.491662  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0096413 (* 1 = 0.0096413 loss)
I0929 16:27:32.491668  2305 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0929 16:27:46.026499  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:27:46.605967  2305 solver.cpp:330] Iteration 46500, Testing net (#0)
I0929 16:27:49.963201  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:27:50.103165  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I0929 16:27:50.103190  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.259199 (* 1 = 0.259199 loss)
I0929 16:27:50.243952  2305 solver.cpp:218] Iteration 46500 (5.63309 iter/s, 17.7522s/100 iters), loss = 0.0149859
I0929 16:27:50.243983  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149853 (* 1 = 0.0149853 loss)
I0929 16:27:50.243990  2305 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0929 16:28:04.497970  2305 solver.cpp:218] Iteration 46600 (7.01561 iter/s, 14.2539s/100 iters), loss = 0.0247082
I0929 16:28:04.498006  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247076 (* 1 = 0.0247076 loss)
I0929 16:28:04.498013  2305 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0929 16:28:18.734180  2305 solver.cpp:218] Iteration 46700 (7.02438 iter/s, 14.2361s/100 iters), loss = 0.0431419
I0929 16:28:18.734321  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0431413 (* 1 = 0.0431413 loss)
I0929 16:28:18.734329  2305 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0929 16:28:32.986078  2305 solver.cpp:218] Iteration 46800 (7.01669 iter/s, 14.2517s/100 iters), loss = 0.0140693
I0929 16:28:32.986109  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140687 (* 1 = 0.0140687 loss)
I0929 16:28:32.986114  2305 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0929 16:28:47.239372  2305 solver.cpp:218] Iteration 46900 (7.01596 iter/s, 14.2532s/100 iters), loss = 0.0169291
I0929 16:28:47.239400  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169285 (* 1 = 0.0169285 loss)
I0929 16:28:47.239406  2305 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0929 16:29:00.775432  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:29:01.350754  2305 solver.cpp:330] Iteration 47000, Testing net (#0)
I0929 16:29:04.704928  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:29:04.845113  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I0929 16:29:04.845139  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.266657 (* 1 = 0.266657 loss)
I0929 16:29:04.985484  2305 solver.cpp:218] Iteration 47000 (5.63506 iter/s, 17.746s/100 iters), loss = 0.00799099
I0929 16:29:04.985518  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00799038 (* 1 = 0.00799038 loss)
I0929 16:29:04.985525  2305 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0929 16:29:19.279042  2305 solver.cpp:218] Iteration 47100 (6.9962 iter/s, 14.2935s/100 iters), loss = 0.0296202
I0929 16:29:19.279083  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296196 (* 1 = 0.0296196 loss)
I0929 16:29:19.279091  2305 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0929 16:29:33.626906  2305 solver.cpp:218] Iteration 47200 (6.96982 iter/s, 14.3476s/100 iters), loss = 0.0324507
I0929 16:29:33.627048  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03245 (* 1 = 0.03245 loss)
I0929 16:29:33.627055  2305 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0929 16:29:47.884336  2305 solver.cpp:218] Iteration 47300 (7.01398 iter/s, 14.2572s/100 iters), loss = 0.0418773
I0929 16:29:47.884367  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418768 (* 1 = 0.0418768 loss)
I0929 16:29:47.884373  2305 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0929 16:30:02.137472  2305 solver.cpp:218] Iteration 47400 (7.01603 iter/s, 14.2531s/100 iters), loss = 0.00184335
I0929 16:30:02.137503  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184276 (* 1 = 0.00184276 loss)
I0929 16:30:02.137509  2305 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0929 16:30:15.679877  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:30:16.252486  2305 solver.cpp:330] Iteration 47500, Testing net (#0)
I0929 16:30:19.617758  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:30:19.757977  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I0929 16:30:19.758013  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.271921 (* 1 = 0.271921 loss)
I0929 16:30:19.900485  2305 solver.cpp:218] Iteration 47500 (5.6297 iter/s, 17.7629s/100 iters), loss = 0.0652981
I0929 16:30:19.900521  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0652975 (* 1 = 0.0652975 loss)
I0929 16:30:19.900527  2305 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0929 16:30:34.162084  2305 solver.cpp:218] Iteration 47600 (7.01187 iter/s, 14.2615s/100 iters), loss = 0.0155891
I0929 16:30:34.162142  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155886 (* 1 = 0.0155886 loss)
I0929 16:30:34.162151  2305 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0929 16:30:48.429033  2305 solver.cpp:218] Iteration 47700 (7.00925 iter/s, 14.2669s/100 iters), loss = 0.00836286
I0929 16:30:48.429177  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00836228 (* 1 = 0.00836228 loss)
I0929 16:30:48.429185  2305 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0929 16:31:02.706667  2305 solver.cpp:218] Iteration 47800 (7.00405 iter/s, 14.2775s/100 iters), loss = 0.00465831
I0929 16:31:02.706698  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465773 (* 1 = 0.00465773 loss)
I0929 16:31:02.706706  2305 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0929 16:31:16.978451  2305 solver.cpp:218] Iteration 47900 (7.00687 iter/s, 14.2717s/100 iters), loss = 0.0281921
I0929 16:31:16.978482  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281915 (* 1 = 0.0281915 loss)
I0929 16:31:16.978489  2305 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0929 16:31:30.530853  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:31:31.099802  2305 solver.cpp:330] Iteration 48000, Testing net (#0)
I0929 16:31:34.466837  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:31:34.607120  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0929 16:31:34.607156  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269507 (* 1 = 0.269507 loss)
I0929 16:31:34.749174  2305 solver.cpp:218] Iteration 48000 (5.62726 iter/s, 17.7706s/100 iters), loss = 0.00616026
I0929 16:31:34.749223  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615968 (* 1 = 0.00615968 loss)
I0929 16:31:34.749243  2305 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0929 16:31:49.002952  2305 solver.cpp:218] Iteration 48100 (7.01577 iter/s, 14.2536s/100 iters), loss = 0.0139186
I0929 16:31:49.002993  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013918 (* 1 = 0.013918 loss)
I0929 16:31:49.003000  2305 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0929 16:32:03.265501  2305 solver.cpp:218] Iteration 48200 (7.01141 iter/s, 14.2625s/100 iters), loss = 0.0586052
I0929 16:32:03.265633  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0586046 (* 1 = 0.0586046 loss)
I0929 16:32:03.265641  2305 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0929 16:32:17.515121  2305 solver.cpp:218] Iteration 48300 (7.01781 iter/s, 14.2495s/100 iters), loss = 0.0214058
I0929 16:32:17.515163  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214052 (* 1 = 0.0214052 loss)
I0929 16:32:17.515169  2305 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0929 16:32:31.775825  2305 solver.cpp:218] Iteration 48400 (7.01232 iter/s, 14.2606s/100 iters), loss = 0.0189774
I0929 16:32:31.775866  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189768 (* 1 = 0.0189768 loss)
I0929 16:32:31.775873  2305 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0929 16:32:45.325997  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:32:45.893963  2305 solver.cpp:330] Iteration 48500, Testing net (#0)
I0929 16:32:49.259933  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:32:49.404146  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0929 16:32:49.404175  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.266973 (* 1 = 0.266973 loss)
I0929 16:32:49.545349  2305 solver.cpp:218] Iteration 48500 (5.62764 iter/s, 17.7694s/100 iters), loss = 0.039956
I0929 16:32:49.545399  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399553 (* 1 = 0.0399553 loss)
I0929 16:32:49.545419  2305 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0929 16:33:03.778180  2305 solver.cpp:218] Iteration 48600 (7.02617 iter/s, 14.2325s/100 iters), loss = 0.0333937
I0929 16:33:03.778223  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333931 (* 1 = 0.0333931 loss)
I0929 16:33:03.778228  2305 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0929 16:33:18.033030  2305 solver.cpp:218] Iteration 48700 (7.0152 iter/s, 14.2548s/100 iters), loss = 0.0254391
I0929 16:33:18.033170  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254384 (* 1 = 0.0254384 loss)
I0929 16:33:18.033179  2305 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0929 16:33:32.287031  2305 solver.cpp:218] Iteration 48800 (7.01566 iter/s, 14.2538s/100 iters), loss = 0.0106495
I0929 16:33:32.287063  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106488 (* 1 = 0.0106488 loss)
I0929 16:33:32.287070  2305 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0929 16:33:46.534252  2305 solver.cpp:218] Iteration 48900 (7.01895 iter/s, 14.2471s/100 iters), loss = 0.00250765
I0929 16:33:46.534298  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250699 (* 1 = 0.00250699 loss)
I0929 16:33:46.534304  2305 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0929 16:34:00.065804  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:34:00.636116  2305 solver.cpp:330] Iteration 49000, Testing net (#0)
I0929 16:34:03.995297  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:34:04.135274  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0929 16:34:04.135310  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.277146 (* 1 = 0.277146 loss)
I0929 16:34:04.279911  2305 solver.cpp:218] Iteration 49000 (5.63521 iter/s, 17.7456s/100 iters), loss = 0.021627
I0929 16:34:04.279959  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216264 (* 1 = 0.0216264 loss)
I0929 16:34:04.279968  2305 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0929 16:34:18.538998  2305 solver.cpp:218] Iteration 49100 (7.01313 iter/s, 14.259s/100 iters), loss = 0.0292956
I0929 16:34:18.539029  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029295 (* 1 = 0.029295 loss)
I0929 16:34:18.539036  2305 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0929 16:34:32.801187  2305 solver.cpp:218] Iteration 49200 (7.01158 iter/s, 14.2621s/100 iters), loss = 0.01052
I0929 16:34:32.801302  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105193 (* 1 = 0.0105193 loss)
I0929 16:34:32.801309  2305 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0929 16:34:47.053140  2305 solver.cpp:218] Iteration 49300 (7.01665 iter/s, 14.2518s/100 iters), loss = 0.00649555
I0929 16:34:47.053182  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064949 (* 1 = 0.0064949 loss)
I0929 16:34:47.053189  2305 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0929 16:35:01.315109  2305 solver.cpp:218] Iteration 49400 (7.0117 iter/s, 14.2619s/100 iters), loss = 0.0130766
I0929 16:35:01.315145  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013076 (* 1 = 0.013076 loss)
I0929 16:35:01.315163  2305 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0929 16:35:14.861331  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:35:15.430050  2305 solver.cpp:330] Iteration 49500, Testing net (#0)
I0929 16:35:18.790647  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:35:18.930575  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I0929 16:35:18.930600  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268828 (* 1 = 0.268828 loss)
I0929 16:35:19.071163  2305 solver.cpp:218] Iteration 49500 (5.63192 iter/s, 17.7559s/100 iters), loss = 0.00554171
I0929 16:35:19.071197  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554104 (* 1 = 0.00554104 loss)
I0929 16:35:19.071203  2305 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0929 16:35:33.314956  2305 solver.cpp:218] Iteration 49600 (7.02064 iter/s, 14.2437s/100 iters), loss = 0.00761482
I0929 16:35:33.314999  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00761416 (* 1 = 0.00761416 loss)
I0929 16:35:33.315006  2305 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0929 16:35:47.574859  2305 solver.cpp:218] Iteration 49700 (7.01271 iter/s, 14.2598s/100 iters), loss = 0.0279656
I0929 16:35:47.574972  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027965 (* 1 = 0.027965 loss)
I0929 16:35:47.574980  2305 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0929 16:36:01.833410  2305 solver.cpp:218] Iteration 49800 (7.0134 iter/s, 14.2584s/100 iters), loss = 0.016919
I0929 16:36:01.833451  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169183 (* 1 = 0.0169183 loss)
I0929 16:36:01.833457  2305 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0929 16:36:16.077129  2305 solver.cpp:218] Iteration 49900 (7.02068 iter/s, 14.2436s/100 iters), loss = 0.00394642
I0929 16:36:16.077162  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394576 (* 1 = 0.00394576 loss)
I0929 16:36:16.077167  2305 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0929 16:36:29.630169  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:36:30.199077  2305 solver.cpp:330] Iteration 50000, Testing net (#0)
I0929 16:36:33.559484  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:36:33.699242  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I0929 16:36:33.699267  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270049 (* 1 = 0.270049 loss)
I0929 16:36:33.840778  2305 solver.cpp:218] Iteration 50000 (5.6295 iter/s, 17.7636s/100 iters), loss = 0.00839982
I0929 16:36:33.840813  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00839918 (* 1 = 0.00839918 loss)
I0929 16:36:33.840821  2305 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0929 16:36:48.112924  2305 solver.cpp:218] Iteration 50100 (7.00669 iter/s, 14.2721s/100 iters), loss = 0.00763552
I0929 16:36:48.112965  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00763487 (* 1 = 0.00763487 loss)
I0929 16:36:48.112972  2305 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0929 16:37:02.379813  2305 solver.cpp:218] Iteration 50200 (7.00928 iter/s, 14.2668s/100 iters), loss = 0.00549444
I0929 16:37:02.379954  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00549378 (* 1 = 0.00549378 loss)
I0929 16:37:02.379962  2305 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0929 16:37:16.646821  2305 solver.cpp:218] Iteration 50300 (7.00927 iter/s, 14.2668s/100 iters), loss = 0.00270403
I0929 16:37:16.646852  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270337 (* 1 = 0.00270337 loss)
I0929 16:37:16.646859  2305 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0929 16:37:30.911898  2305 solver.cpp:218] Iteration 50400 (7.01016 iter/s, 14.265s/100 iters), loss = 0.0294579
I0929 16:37:30.911929  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294573 (* 1 = 0.0294573 loss)
I0929 16:37:30.911936  2305 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0929 16:37:44.468502  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:37:45.038027  2305 solver.cpp:330] Iteration 50500, Testing net (#0)
I0929 16:37:48.396754  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:37:48.537106  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0929 16:37:48.537140  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278552 (* 1 = 0.278552 loss)
I0929 16:37:48.678663  2305 solver.cpp:218] Iteration 50500 (5.62851 iter/s, 17.7667s/100 iters), loss = 0.00602787
I0929 16:37:48.678696  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00602721 (* 1 = 0.00602721 loss)
I0929 16:37:48.678704  2305 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0929 16:38:02.923828  2305 solver.cpp:218] Iteration 50600 (7.01996 iter/s, 14.2451s/100 iters), loss = 0.00979354
I0929 16:38:02.923871  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00979288 (* 1 = 0.00979288 loss)
I0929 16:38:02.923877  2305 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0929 16:38:17.177361  2305 solver.cpp:218] Iteration 50700 (7.01584 iter/s, 14.2535s/100 iters), loss = 0.0148073
I0929 16:38:17.177475  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148066 (* 1 = 0.0148066 loss)
I0929 16:38:17.177484  2305 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0929 16:38:31.439923  2305 solver.cpp:218] Iteration 50800 (7.01143 iter/s, 14.2624s/100 iters), loss = 0.0150543
I0929 16:38:31.439960  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150536 (* 1 = 0.0150536 loss)
I0929 16:38:31.439966  2305 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0929 16:38:45.683804  2305 solver.cpp:218] Iteration 50900 (7.02059 iter/s, 14.2438s/100 iters), loss = 0.00233882
I0929 16:38:45.683835  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233816 (* 1 = 0.00233816 loss)
I0929 16:38:45.683841  2305 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0929 16:38:59.240203  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:38:59.808272  2305 solver.cpp:330] Iteration 51000, Testing net (#0)
I0929 16:39:03.168033  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:39:03.308120  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0929 16:39:03.308156  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281755 (* 1 = 0.281755 loss)
I0929 16:39:03.451151  2305 solver.cpp:218] Iteration 51000 (5.62833 iter/s, 17.7673s/100 iters), loss = 0.00432025
I0929 16:39:03.451182  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431958 (* 1 = 0.00431958 loss)
I0929 16:39:03.451189  2305 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0929 16:39:17.708498  2305 solver.cpp:218] Iteration 51100 (7.01396 iter/s, 14.2573s/100 iters), loss = 0.0182667
I0929 16:39:17.708539  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182661 (* 1 = 0.0182661 loss)
I0929 16:39:17.708545  2305 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0929 16:39:31.958406  2305 solver.cpp:218] Iteration 51200 (7.01763 iter/s, 14.2498s/100 iters), loss = 0.0165486
I0929 16:39:31.958554  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165479 (* 1 = 0.0165479 loss)
I0929 16:39:31.958564  2305 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0929 16:39:46.207856  2305 solver.cpp:218] Iteration 51300 (7.01791 iter/s, 14.2493s/100 iters), loss = 0.00691705
I0929 16:39:46.207904  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691638 (* 1 = 0.00691638 loss)
I0929 16:39:46.207912  2305 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0929 16:40:00.463752  2305 solver.cpp:218] Iteration 51400 (7.0147 iter/s, 14.2558s/100 iters), loss = 0.0149944
I0929 16:40:00.463783  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149937 (* 1 = 0.0149937 loss)
I0929 16:40:00.463788  2305 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0929 16:40:14.011790  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:40:14.580189  2305 solver.cpp:330] Iteration 51500, Testing net (#0)
I0929 16:40:17.939738  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:40:18.079766  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0929 16:40:18.079802  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270153 (* 1 = 0.270153 loss)
I0929 16:40:18.220398  2305 solver.cpp:218] Iteration 51500 (5.63172 iter/s, 17.7566s/100 iters), loss = 0.0157762
I0929 16:40:18.220428  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157755 (* 1 = 0.0157755 loss)
I0929 16:40:18.220434  2305 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0929 16:40:32.474864  2305 solver.cpp:218] Iteration 51600 (7.01538 iter/s, 14.2544s/100 iters), loss = 0.00628528
I0929 16:40:32.474895  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628461 (* 1 = 0.00628461 loss)
I0929 16:40:32.474900  2305 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0929 16:40:46.739756  2305 solver.cpp:218] Iteration 51700 (7.01025 iter/s, 14.2648s/100 iters), loss = 0.0392316
I0929 16:40:46.739884  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392309 (* 1 = 0.0392309 loss)
I0929 16:40:46.739903  2305 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0929 16:41:00.988628  2305 solver.cpp:218] Iteration 51800 (7.01818 iter/s, 14.2487s/100 iters), loss = 0.00402599
I0929 16:41:00.988661  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402532 (* 1 = 0.00402532 loss)
I0929 16:41:00.988677  2305 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0929 16:41:15.249385  2305 solver.cpp:218] Iteration 51900 (7.01228 iter/s, 14.2607s/100 iters), loss = 0.0216171
I0929 16:41:15.249424  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216164 (* 1 = 0.0216164 loss)
I0929 16:41:15.249431  2305 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0929 16:41:28.811126  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:41:29.380283  2305 solver.cpp:330] Iteration 52000, Testing net (#0)
I0929 16:41:32.740697  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:41:32.880710  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I0929 16:41:32.880746  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29531 (* 1 = 0.29531 loss)
I0929 16:41:33.021477  2305 solver.cpp:218] Iteration 52000 (5.62683 iter/s, 17.772s/100 iters), loss = 0.0437388
I0929 16:41:33.021508  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437381 (* 1 = 0.0437381 loss)
I0929 16:41:33.021515  2305 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0929 16:41:47.276288  2305 solver.cpp:218] Iteration 52100 (7.01521 iter/s, 14.2547s/100 iters), loss = 0.0444857
I0929 16:41:47.276319  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044485 (* 1 = 0.044485 loss)
I0929 16:41:47.276324  2305 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0929 16:42:01.526320  2305 solver.cpp:218] Iteration 52200 (7.01756 iter/s, 14.25s/100 iters), loss = 0.0572481
I0929 16:42:01.526437  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0572474 (* 1 = 0.0572474 loss)
I0929 16:42:01.526455  2305 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0929 16:42:15.777729  2305 solver.cpp:218] Iteration 52300 (7.01692 iter/s, 14.2513s/100 iters), loss = 0.00300961
I0929 16:42:15.777770  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300894 (* 1 = 0.00300894 loss)
I0929 16:42:15.777776  2305 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0929 16:42:30.042111  2305 solver.cpp:218] Iteration 52400 (7.01051 iter/s, 14.2643s/100 iters), loss = 0.0238518
I0929 16:42:30.042142  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238511 (* 1 = 0.0238511 loss)
I0929 16:42:30.042148  2305 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0929 16:42:43.586638  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:42:44.155419  2305 solver.cpp:330] Iteration 52500, Testing net (#0)
I0929 16:42:47.512986  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:42:47.653115  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I0929 16:42:47.653139  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30504 (* 1 = 0.30504 loss)
I0929 16:42:47.793841  2305 solver.cpp:218] Iteration 52500 (5.63328 iter/s, 17.7516s/100 iters), loss = 0.00356399
I0929 16:42:47.793872  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356332 (* 1 = 0.00356332 loss)
I0929 16:42:47.793879  2305 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0929 16:43:02.066330  2305 solver.cpp:218] Iteration 52600 (7.00652 iter/s, 14.2724s/100 iters), loss = 0.012868
I0929 16:43:02.066364  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128673 (* 1 = 0.0128673 loss)
I0929 16:43:02.066370  2305 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0929 16:43:16.340783  2305 solver.cpp:218] Iteration 52700 (7.00556 iter/s, 14.2744s/100 iters), loss = 0.0256369
I0929 16:43:16.340930  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256362 (* 1 = 0.0256362 loss)
I0929 16:43:16.340940  2305 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0929 16:43:30.596730  2305 solver.cpp:218] Iteration 52800 (7.01471 iter/s, 14.2558s/100 iters), loss = 0.00467542
I0929 16:43:30.596760  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467475 (* 1 = 0.00467475 loss)
I0929 16:43:30.596766  2305 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0929 16:43:44.864660  2305 solver.cpp:218] Iteration 52900 (7.00876 iter/s, 14.2679s/100 iters), loss = 0.0181889
I0929 16:43:44.864699  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181882 (* 1 = 0.0181882 loss)
I0929 16:43:44.864717  2305 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0929 16:43:58.424729  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:43:58.998628  2305 solver.cpp:330] Iteration 53000, Testing net (#0)
I0929 16:44:02.358461  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:44:02.498661  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I0929 16:44:02.498695  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298003 (* 1 = 0.298003 loss)
I0929 16:44:02.639336  2305 solver.cpp:218] Iteration 53000 (5.62601 iter/s, 17.7746s/100 iters), loss = 0.00784979
I0929 16:44:02.639366  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784912 (* 1 = 0.00784912 loss)
I0929 16:44:02.639374  2305 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0929 16:44:16.890857  2305 solver.cpp:218] Iteration 53100 (7.01683 iter/s, 14.2514s/100 iters), loss = 0.00690396
I0929 16:44:16.890898  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069033 (* 1 = 0.0069033 loss)
I0929 16:44:16.890905  2305 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0929 16:44:31.141399  2305 solver.cpp:218] Iteration 53200 (7.01732 iter/s, 14.2505s/100 iters), loss = 0.00783744
I0929 16:44:31.141513  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783678 (* 1 = 0.00783678 loss)
I0929 16:44:31.141521  2305 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0929 16:44:45.406913  2305 solver.cpp:218] Iteration 53300 (7.00999 iter/s, 14.2654s/100 iters), loss = 0.00514894
I0929 16:44:45.406952  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514828 (* 1 = 0.00514828 loss)
I0929 16:44:45.406960  2305 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0929 16:44:59.662065  2305 solver.cpp:218] Iteration 53400 (7.01505 iter/s, 14.2551s/100 iters), loss = 0.00297093
I0929 16:44:59.662094  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297028 (* 1 = 0.00297028 loss)
I0929 16:44:59.662101  2305 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0929 16:45:13.204980  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:45:13.782578  2305 solver.cpp:330] Iteration 53500, Testing net (#0)
I0929 16:45:17.140954  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:45:17.281177  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0929 16:45:17.281213  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283882 (* 1 = 0.283882 loss)
I0929 16:45:17.421803  2305 solver.cpp:218] Iteration 53500 (5.63074 iter/s, 17.7597s/100 iters), loss = 0.00358479
I0929 16:45:17.421901  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358415 (* 1 = 0.00358415 loss)
I0929 16:45:17.421912  2305 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0929 16:45:31.671850  2305 solver.cpp:218] Iteration 53600 (7.01761 iter/s, 14.2499s/100 iters), loss = 0.00188445
I0929 16:45:31.671886  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018838 (* 1 = 0.0018838 loss)
I0929 16:45:31.671895  2305 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0929 16:45:45.911808  2305 solver.cpp:218] Iteration 53700 (7.02253 iter/s, 14.2399s/100 iters), loss = 0.00846862
I0929 16:45:45.911954  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00846797 (* 1 = 0.00846797 loss)
I0929 16:45:45.911988  2305 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0929 16:46:00.164530  2305 solver.cpp:218] Iteration 53800 (7.01629 iter/s, 14.2525s/100 iters), loss = 0.0184221
I0929 16:46:00.164568  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184215 (* 1 = 0.0184215 loss)
I0929 16:46:00.164577  2305 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0929 16:46:14.426558  2305 solver.cpp:218] Iteration 53900 (7.01166 iter/s, 14.262s/100 iters), loss = 0.00633783
I0929 16:46:14.426590  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00633718 (* 1 = 0.00633718 loss)
I0929 16:46:14.426597  2305 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0929 16:46:27.970839  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:46:28.548071  2305 solver.cpp:330] Iteration 54000, Testing net (#0)
I0929 16:46:31.904204  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:46:32.044270  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I0929 16:46:32.044296  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29013 (* 1 = 0.29013 loss)
I0929 16:46:32.185081  2305 solver.cpp:218] Iteration 54000 (5.63112 iter/s, 17.7584s/100 iters), loss = 0.0079494
I0929 16:46:32.185122  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794875 (* 1 = 0.00794875 loss)
I0929 16:46:32.185132  2305 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0929 16:46:46.433645  2305 solver.cpp:218] Iteration 54100 (7.01829 iter/s, 14.2485s/100 iters), loss = 0.0090209
I0929 16:46:46.433684  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902025 (* 1 = 0.00902025 loss)
I0929 16:46:46.433692  2305 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0929 16:47:00.695667  2305 solver.cpp:218] Iteration 54200 (7.01167 iter/s, 14.2619s/100 iters), loss = 0.0151418
I0929 16:47:00.695780  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151412 (* 1 = 0.0151412 loss)
I0929 16:47:00.695787  2305 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0929 16:47:14.958395  2305 solver.cpp:218] Iteration 54300 (7.01135 iter/s, 14.2626s/100 iters), loss = 0.0148796
I0929 16:47:14.958427  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148789 (* 1 = 0.0148789 loss)
I0929 16:47:14.958434  2305 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0929 16:47:29.212916  2305 solver.cpp:218] Iteration 54400 (7.01536 iter/s, 14.2544s/100 iters), loss = 0.0114215
I0929 16:47:29.212949  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114208 (* 1 = 0.0114208 loss)
I0929 16:47:29.212956  2305 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0929 16:47:42.753782  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:47:43.326068  2305 solver.cpp:330] Iteration 54500, Testing net (#0)
I0929 16:47:46.690866  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:47:46.830811  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I0929 16:47:46.830849  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28317 (* 1 = 0.28317 loss)
I0929 16:47:46.972926  2305 solver.cpp:218] Iteration 54500 (5.63065 iter/s, 17.7599s/100 iters), loss = 0.0102008
I0929 16:47:46.972964  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102001 (* 1 = 0.0102001 loss)
I0929 16:47:46.972971  2305 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0929 16:48:01.213374  2305 solver.cpp:218] Iteration 54600 (7.02229 iter/s, 14.2404s/100 iters), loss = 0.0023354
I0929 16:48:01.213410  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233476 (* 1 = 0.00233476 loss)
I0929 16:48:01.213418  2305 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0929 16:48:15.480052  2305 solver.cpp:218] Iteration 54700 (7.00938 iter/s, 14.2666s/100 iters), loss = 0.00349681
I0929 16:48:15.480170  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349617 (* 1 = 0.00349617 loss)
I0929 16:48:15.480188  2305 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0929 16:48:29.826288  2305 solver.cpp:218] Iteration 54800 (6.97054 iter/s, 14.3461s/100 iters), loss = 0.00513948
I0929 16:48:29.826316  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513885 (* 1 = 0.00513885 loss)
I0929 16:48:29.826323  2305 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0929 16:48:44.230999  2305 solver.cpp:218] Iteration 54900 (6.9422 iter/s, 14.4046s/100 iters), loss = 0.00548666
I0929 16:48:44.231029  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548604 (* 1 = 0.00548604 loss)
I0929 16:48:44.231037  2305 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0929 16:48:57.999300  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:48:58.591847  2305 solver.cpp:330] Iteration 55000, Testing net (#0)
I0929 16:49:01.999934  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:49:02.138587  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I0929 16:49:02.138623  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.27845 (* 1 = 0.27845 loss)
I0929 16:49:02.278019  2305 solver.cpp:218] Iteration 55000 (5.5411 iter/s, 18.0469s/100 iters), loss = 0.00384273
I0929 16:49:02.278054  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038421 (* 1 = 0.0038421 loss)
I0929 16:49:02.278061  2305 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0929 16:49:16.597352  2305 solver.cpp:218] Iteration 55100 (6.9836 iter/s, 14.3193s/100 iters), loss = 0.0137432
I0929 16:49:16.597388  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137425 (* 1 = 0.0137425 loss)
I0929 16:49:16.597394  2305 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0929 16:49:30.839720  2305 solver.cpp:218] Iteration 55200 (7.02134 iter/s, 14.2423s/100 iters), loss = 0.0153662
I0929 16:49:30.839828  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153655 (* 1 = 0.0153655 loss)
I0929 16:49:30.839836  2305 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0929 16:49:45.085505  2305 solver.cpp:218] Iteration 55300 (7.01969 iter/s, 14.2456s/100 iters), loss = 0.00988177
I0929 16:49:45.085537  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00988114 (* 1 = 0.00988114 loss)
I0929 16:49:45.085544  2305 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0929 16:49:59.325214  2305 solver.cpp:218] Iteration 55400 (7.02265 iter/s, 14.2396s/100 iters), loss = 0.00931868
I0929 16:49:59.325247  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00931805 (* 1 = 0.00931805 loss)
I0929 16:49:59.325253  2305 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0929 16:50:12.864446  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:50:13.440282  2305 solver.cpp:330] Iteration 55500, Testing net (#0)
I0929 16:50:16.798429  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:50:16.937131  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I0929 16:50:16.937167  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279307 (* 1 = 0.279307 loss)
I0929 16:50:17.077105  2305 solver.cpp:218] Iteration 55500 (5.63323 iter/s, 17.7518s/100 iters), loss = 0.00424667
I0929 16:50:17.077142  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424605 (* 1 = 0.00424605 loss)
I0929 16:50:17.077148  2305 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0929 16:50:31.310681  2305 solver.cpp:218] Iteration 55600 (7.02568 iter/s, 14.2335s/100 iters), loss = 0.00945231
I0929 16:50:31.310729  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00945168 (* 1 = 0.00945168 loss)
I0929 16:50:31.310737  2305 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0929 16:50:45.549026  2305 solver.cpp:218] Iteration 55700 (7.02333 iter/s, 14.2383s/100 iters), loss = 0.00341203
I0929 16:50:45.549165  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341139 (* 1 = 0.00341139 loss)
I0929 16:50:45.549173  2305 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0929 16:50:59.792449  2305 solver.cpp:218] Iteration 55800 (7.02087 iter/s, 14.2432s/100 iters), loss = 0.00831328
I0929 16:50:59.792479  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831265 (* 1 = 0.00831265 loss)
I0929 16:50:59.792484  2305 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0929 16:51:14.038175  2305 solver.cpp:218] Iteration 55900 (7.01968 iter/s, 14.2457s/100 iters), loss = 0.000698757
I0929 16:51:14.038205  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00069813 (* 1 = 0.00069813 loss)
I0929 16:51:14.038211  2305 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0929 16:51:27.560230  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:51:28.126425  2305 solver.cpp:330] Iteration 56000, Testing net (#0)
I0929 16:51:31.487346  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:51:31.627893  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I0929 16:51:31.627921  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289886 (* 1 = 0.289886 loss)
I0929 16:51:31.767642  2305 solver.cpp:218] Iteration 56000 (5.64035 iter/s, 17.7294s/100 iters), loss = 0.00363904
I0929 16:51:31.767675  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363842 (* 1 = 0.00363842 loss)
I0929 16:51:31.767683  2305 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0929 16:51:46.008683  2305 solver.cpp:218] Iteration 56100 (7.02199 iter/s, 14.241s/100 iters), loss = 0.00570126
I0929 16:51:46.008713  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570063 (* 1 = 0.00570063 loss)
I0929 16:51:46.008718  2305 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0929 16:52:00.256170  2305 solver.cpp:218] Iteration 56200 (7.01882 iter/s, 14.2474s/100 iters), loss = 0.0219112
I0929 16:52:00.256280  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219106 (* 1 = 0.0219106 loss)
I0929 16:52:00.256299  2305 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0929 16:52:14.497310  2305 solver.cpp:218] Iteration 56300 (7.02198 iter/s, 14.241s/100 iters), loss = 0.00466567
I0929 16:52:14.497341  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466504 (* 1 = 0.00466504 loss)
I0929 16:52:14.497347  2305 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0929 16:52:28.744055  2305 solver.cpp:218] Iteration 56400 (7.01918 iter/s, 14.2467s/100 iters), loss = 0.00290465
I0929 16:52:28.744099  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290403 (* 1 = 0.00290403 loss)
I0929 16:52:28.744107  2305 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0929 16:52:42.276306  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:52:42.843704  2305 solver.cpp:330] Iteration 56500, Testing net (#0)
I0929 16:52:46.197008  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:52:46.338207  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I0929 16:52:46.338237  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295202 (* 1 = 0.295202 loss)
I0929 16:52:46.483297  2305 solver.cpp:218] Iteration 56500 (5.63725 iter/s, 17.7391s/100 iters), loss = 0.0204832
I0929 16:52:46.483345  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204826 (* 1 = 0.0204826 loss)
I0929 16:52:46.483352  2305 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0929 16:53:00.727803  2305 solver.cpp:218] Iteration 56600 (7.02031 iter/s, 14.2444s/100 iters), loss = 0.00869567
I0929 16:53:00.727833  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869503 (* 1 = 0.00869503 loss)
I0929 16:53:00.727839  2305 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0929 16:53:14.977813  2305 solver.cpp:218] Iteration 56700 (7.01757 iter/s, 14.2499s/100 iters), loss = 0.0127796
I0929 16:53:14.977882  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012779 (* 1 = 0.012779 loss)
I0929 16:53:14.977890  2305 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0929 16:53:29.234360  2305 solver.cpp:218] Iteration 56800 (7.01437 iter/s, 14.2564s/100 iters), loss = 0.0209154
I0929 16:53:29.234396  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209147 (* 1 = 0.0209147 loss)
I0929 16:53:29.234403  2305 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0929 16:53:43.492499  2305 solver.cpp:218] Iteration 56900 (7.01358 iter/s, 14.2581s/100 iters), loss = 0.00510289
I0929 16:53:43.492535  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510225 (* 1 = 0.00510225 loss)
I0929 16:53:43.492542  2305 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0929 16:53:57.033783  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:53:57.602176  2305 solver.cpp:330] Iteration 57000, Testing net (#0)
I0929 16:54:00.957294  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:54:01.095297  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9266
I0929 16:54:01.095332  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282585 (* 1 = 0.282585 loss)
I0929 16:54:01.235203  2305 solver.cpp:218] Iteration 57000 (5.63615 iter/s, 17.7426s/100 iters), loss = 0.00783077
I0929 16:54:01.235235  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783013 (* 1 = 0.00783013 loss)
I0929 16:54:01.235242  2305 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0929 16:54:15.487417  2305 solver.cpp:218] Iteration 57100 (7.01649 iter/s, 14.2521s/100 iters), loss = 0.0104619
I0929 16:54:15.487449  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104613 (* 1 = 0.0104613 loss)
I0929 16:54:15.487457  2305 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0929 16:54:29.740352  2305 solver.cpp:218] Iteration 57200 (7.01614 iter/s, 14.2529s/100 iters), loss = 0.00495824
I0929 16:54:29.740479  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495759 (* 1 = 0.00495759 loss)
I0929 16:54:29.740487  2305 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0929 16:54:43.984184  2305 solver.cpp:218] Iteration 57300 (7.02067 iter/s, 14.2437s/100 iters), loss = 0.0129551
I0929 16:54:43.984215  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129544 (* 1 = 0.0129544 loss)
I0929 16:54:43.984221  2305 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0929 16:54:58.219949  2305 solver.cpp:218] Iteration 57400 (7.0246 iter/s, 14.2357s/100 iters), loss = 0.0167313
I0929 16:54:58.219979  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167306 (* 1 = 0.0167306 loss)
I0929 16:54:58.219985  2305 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0929 16:55:11.766543  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:55:12.333546  2305 solver.cpp:330] Iteration 57500, Testing net (#0)
I0929 16:55:15.690145  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:55:15.828388  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0929 16:55:15.828414  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304825 (* 1 = 0.304825 loss)
I0929 16:55:15.968080  2305 solver.cpp:218] Iteration 57500 (5.63442 iter/s, 17.7481s/100 iters), loss = 0.00538707
I0929 16:55:15.968113  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538641 (* 1 = 0.00538641 loss)
I0929 16:55:15.968120  2305 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0929 16:55:30.206640  2305 solver.cpp:218] Iteration 57600 (7.02322 iter/s, 14.2385s/100 iters), loss = 0.0043479
I0929 16:55:30.206670  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434725 (* 1 = 0.00434725 loss)
I0929 16:55:30.206676  2305 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0929 16:55:44.453887  2305 solver.cpp:218] Iteration 57700 (7.01893 iter/s, 14.2472s/100 iters), loss = 0.0104055
I0929 16:55:44.454027  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104049 (* 1 = 0.0104049 loss)
I0929 16:55:44.454035  2305 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0929 16:55:58.705610  2305 solver.cpp:218] Iteration 57800 (7.01678 iter/s, 14.2515s/100 iters), loss = 0.00641994
I0929 16:55:58.705653  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641928 (* 1 = 0.00641928 loss)
I0929 16:55:58.705662  2305 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0929 16:56:12.943136  2305 solver.cpp:218] Iteration 57900 (7.02373 iter/s, 14.2374s/100 iters), loss = 0.0170314
I0929 16:56:12.943168  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170308 (* 1 = 0.0170308 loss)
I0929 16:56:12.943174  2305 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0929 16:56:26.478932  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:56:27.045295  2305 solver.cpp:330] Iteration 58000, Testing net (#0)
I0929 16:56:30.400612  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:56:30.538712  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I0929 16:56:30.538736  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291359 (* 1 = 0.291359 loss)
I0929 16:56:30.678272  2305 solver.cpp:218] Iteration 58000 (5.63855 iter/s, 17.7351s/100 iters), loss = 0.0124274
I0929 16:56:30.678297  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124267 (* 1 = 0.0124267 loss)
I0929 16:56:30.678303  2305 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0929 16:56:44.935652  2305 solver.cpp:218] Iteration 58100 (7.01395 iter/s, 14.2573s/100 iters), loss = 0.0185363
I0929 16:56:44.935680  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185356 (* 1 = 0.0185356 loss)
I0929 16:56:44.935688  2305 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0929 16:56:59.190536  2305 solver.cpp:218] Iteration 58200 (7.01517 iter/s, 14.2548s/100 iters), loss = 0.00495891
I0929 16:56:59.190629  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495825 (* 1 = 0.00495825 loss)
I0929 16:56:59.190650  2305 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0929 16:57:13.426756  2305 solver.cpp:218] Iteration 58300 (7.0244 iter/s, 14.2361s/100 iters), loss = 0.00285882
I0929 16:57:13.426795  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285815 (* 1 = 0.00285815 loss)
I0929 16:57:13.426801  2305 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0929 16:57:27.672520  2305 solver.cpp:218] Iteration 58400 (7.01967 iter/s, 14.2457s/100 iters), loss = 0.00433401
I0929 16:57:27.672549  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433335 (* 1 = 0.00433335 loss)
I0929 16:57:27.672555  2305 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0929 16:57:41.211494  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:57:41.779626  2305 solver.cpp:330] Iteration 58500, Testing net (#0)
I0929 16:57:45.133239  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:57:45.271550  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9263
I0929 16:57:45.271586  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294539 (* 1 = 0.294539 loss)
I0929 16:57:45.411223  2305 solver.cpp:218] Iteration 58500 (5.63742 iter/s, 17.7386s/100 iters), loss = 0.00187473
I0929 16:57:45.411257  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187406 (* 1 = 0.00187406 loss)
I0929 16:57:45.411263  2305 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0929 16:57:59.654665  2305 solver.cpp:218] Iteration 58600 (7.02082 iter/s, 14.2434s/100 iters), loss = 0.0045773
I0929 16:57:59.654707  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457663 (* 1 = 0.00457663 loss)
I0929 16:57:59.654714  2305 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0929 16:58:13.912379  2305 solver.cpp:218] Iteration 58700 (7.01379 iter/s, 14.2576s/100 iters), loss = 0.00794079
I0929 16:58:13.912528  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794014 (* 1 = 0.00794014 loss)
I0929 16:58:13.912536  2305 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0929 16:58:28.161068  2305 solver.cpp:218] Iteration 58800 (7.01828 iter/s, 14.2485s/100 iters), loss = 0.00339385
I0929 16:58:28.161109  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339319 (* 1 = 0.00339319 loss)
I0929 16:58:28.161115  2305 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0929 16:58:42.408082  2305 solver.cpp:218] Iteration 58900 (7.01905 iter/s, 14.2469s/100 iters), loss = 0.0145535
I0929 16:58:42.408115  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145528 (* 1 = 0.0145528 loss)
I0929 16:58:42.408121  2305 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0929 16:58:55.956683  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:58:56.523947  2305 solver.cpp:330] Iteration 59000, Testing net (#0)
I0929 16:58:59.878340  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:59:00.017050  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I0929 16:59:00.017084  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296738 (* 1 = 0.296738 loss)
I0929 16:59:00.156262  2305 solver.cpp:218] Iteration 59000 (5.63441 iter/s, 17.7481s/100 iters), loss = 0.00262841
I0929 16:59:00.156294  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262776 (* 1 = 0.00262776 loss)
I0929 16:59:00.156301  2305 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0929 16:59:14.411275  2305 solver.cpp:218] Iteration 59100 (7.01511 iter/s, 14.2549s/100 iters), loss = 0.013655
I0929 16:59:14.411304  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136544 (* 1 = 0.0136544 loss)
I0929 16:59:14.411310  2305 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0929 16:59:28.658356  2305 solver.cpp:218] Iteration 59200 (7.01902 iter/s, 14.247s/100 iters), loss = 0.0021195
I0929 16:59:28.658486  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211885 (* 1 = 0.00211885 loss)
I0929 16:59:28.658495  2305 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0929 16:59:42.896484  2305 solver.cpp:218] Iteration 59300 (7.02348 iter/s, 14.238s/100 iters), loss = 0.00665658
I0929 16:59:42.896517  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665593 (* 1 = 0.00665593 loss)
I0929 16:59:42.896533  2305 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0929 16:59:57.151337  2305 solver.cpp:218] Iteration 59400 (7.01519 iter/s, 14.2548s/100 iters), loss = 0.00223503
I0929 16:59:57.151368  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223439 (* 1 = 0.00223439 loss)
I0929 16:59:57.151374  2305 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0929 17:00:10.698894  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:00:11.267083  2305 solver.cpp:330] Iteration 59500, Testing net (#0)
I0929 17:00:14.619971  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:00:14.757877  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0929 17:00:14.757913  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298452 (* 1 = 0.298452 loss)
I0929 17:00:14.897208  2305 solver.cpp:218] Iteration 59500 (5.63514 iter/s, 17.7458s/100 iters), loss = 0.00639238
I0929 17:00:14.897238  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00639174 (* 1 = 0.00639174 loss)
I0929 17:00:14.897254  2305 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0929 17:00:29.141364  2305 solver.cpp:218] Iteration 59600 (7.02046 iter/s, 14.2441s/100 iters), loss = 0.00224983
I0929 17:00:29.141396  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224919 (* 1 = 0.00224919 loss)
I0929 17:00:29.141413  2305 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0929 17:00:43.386524  2305 solver.cpp:218] Iteration 59700 (7.01997 iter/s, 14.2451s/100 iters), loss = 0.00798993
I0929 17:00:43.386636  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00798929 (* 1 = 0.00798929 loss)
I0929 17:00:43.386659  2305 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0929 17:00:57.636168  2305 solver.cpp:218] Iteration 59800 (7.01779 iter/s, 14.2495s/100 iters), loss = 0.00383909
I0929 17:00:57.636204  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383845 (* 1 = 0.00383845 loss)
I0929 17:00:57.636212  2305 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0929 17:01:11.881649  2305 solver.cpp:218] Iteration 59900 (7.01981 iter/s, 14.2454s/100 iters), loss = 0.00121406
I0929 17:01:11.881682  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121341 (* 1 = 0.00121341 loss)
I0929 17:01:11.881691  2305 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0929 17:01:25.419601  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:01:25.993221  2305 solver.cpp:330] Iteration 60000, Testing net (#0)
I0929 17:01:29.347993  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:01:29.486738  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I0929 17:01:29.486765  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304581 (* 1 = 0.304581 loss)
I0929 17:01:29.625720  2305 solver.cpp:218] Iteration 60000 (5.63571 iter/s, 17.744s/100 iters), loss = 0.00277497
I0929 17:01:29.625749  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277432 (* 1 = 0.00277432 loss)
I0929 17:01:29.625768  2305 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0929 17:01:43.874372  2305 solver.cpp:218] Iteration 60100 (7.01824 iter/s, 14.2486s/100 iters), loss = 0.00440833
I0929 17:01:43.874409  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440768 (* 1 = 0.00440768 loss)
I0929 17:01:43.874419  2305 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0929 17:01:58.112534  2305 solver.cpp:218] Iteration 60200 (7.02342 iter/s, 14.2381s/100 iters), loss = 0.00610073
I0929 17:01:58.112679  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00610008 (* 1 = 0.00610008 loss)
I0929 17:01:58.112704  2305 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0929 17:02:12.364060  2305 solver.cpp:218] Iteration 60300 (7.01688 iter/s, 14.2513s/100 iters), loss = 0.0121066
I0929 17:02:12.364133  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121059 (* 1 = 0.0121059 loss)
I0929 17:02:12.364151  2305 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0929 17:02:26.621405  2305 solver.cpp:218] Iteration 60400 (7.01398 iter/s, 14.2572s/100 iters), loss = 0.00075779
I0929 17:02:26.621433  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000757143 (* 1 = 0.000757143 loss)
I0929 17:02:26.621439  2305 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0929 17:02:40.151082  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:02:40.727982  2305 solver.cpp:330] Iteration 60500, Testing net (#0)
I0929 17:02:44.079785  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:02:44.218118  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.927
I0929 17:02:44.218143  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291482 (* 1 = 0.291482 loss)
I0929 17:02:44.357774  2305 solver.cpp:218] Iteration 60500 (5.63816 iter/s, 17.7363s/100 iters), loss = 0.00177679
I0929 17:02:44.357805  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177615 (* 1 = 0.00177615 loss)
I0929 17:02:44.357811  2305 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0929 17:02:58.612527  2305 solver.cpp:218] Iteration 60600 (7.01524 iter/s, 14.2547s/100 iters), loss = 0.0122699
I0929 17:02:58.612563  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122692 (* 1 = 0.0122692 loss)
I0929 17:02:58.612581  2305 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0929 17:03:12.859432  2305 solver.cpp:218] Iteration 60700 (7.01912 iter/s, 14.2468s/100 iters), loss = 0.00643771
I0929 17:03:12.859577  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643707 (* 1 = 0.00643707 loss)
I0929 17:03:12.859586  2305 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0929 17:03:27.104506  2305 solver.cpp:218] Iteration 60800 (7.02006 iter/s, 14.2449s/100 iters), loss = 0.00109691
I0929 17:03:27.104537  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109626 (* 1 = 0.00109626 loss)
I0929 17:03:27.104542  2305 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0929 17:03:41.349826  2305 solver.cpp:218] Iteration 60900 (7.01988 iter/s, 14.2453s/100 iters), loss = 0.00305564
I0929 17:03:41.349858  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003055 (* 1 = 0.003055 loss)
I0929 17:03:41.349865  2305 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0929 17:03:54.885378  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:03:55.458590  2305 solver.cpp:330] Iteration 61000, Testing net (#0)
I0929 17:03:58.820286  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:03:58.959455  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0929 17:03:58.959481  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303135 (* 1 = 0.303135 loss)
I0929 17:03:59.099483  2305 solver.cpp:218] Iteration 61000 (5.63394 iter/s, 17.7496s/100 iters), loss = 0.00253723
I0929 17:03:59.099515  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253659 (* 1 = 0.00253659 loss)
I0929 17:03:59.099522  2305 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0929 17:04:13.351181  2305 solver.cpp:218] Iteration 61100 (7.01674 iter/s, 14.2516s/100 iters), loss = 0.00325323
I0929 17:04:13.351215  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325258 (* 1 = 0.00325258 loss)
I0929 17:04:13.351222  2305 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0929 17:04:27.606408  2305 solver.cpp:218] Iteration 61200 (7.01501 iter/s, 14.2552s/100 iters), loss = 0.00522732
I0929 17:04:27.606555  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522668 (* 1 = 0.00522668 loss)
I0929 17:04:27.606564  2305 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0929 17:04:41.865725  2305 solver.cpp:218] Iteration 61300 (7.01305 iter/s, 14.2591s/100 iters), loss = 0.0103063
I0929 17:04:41.865756  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103057 (* 1 = 0.0103057 loss)
I0929 17:04:41.865761  2305 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0929 17:04:56.116448  2305 solver.cpp:218] Iteration 61400 (7.01722 iter/s, 14.2507s/100 iters), loss = 0.00169292
I0929 17:04:56.116480  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169227 (* 1 = 0.00169227 loss)
I0929 17:04:56.116487  2305 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0929 17:05:09.654487  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:05:10.221737  2305 solver.cpp:330] Iteration 61500, Testing net (#0)
I0929 17:05:13.585885  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:05:13.725111  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I0929 17:05:13.725137  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311974 (* 1 = 0.311974 loss)
I0929 17:05:13.864276  2305 solver.cpp:218] Iteration 61500 (5.63452 iter/s, 17.7477s/100 iters), loss = 0.0077393
I0929 17:05:13.864311  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00773865 (* 1 = 0.00773865 loss)
I0929 17:05:13.864321  2305 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0929 17:05:28.100064  2305 solver.cpp:218] Iteration 61600 (7.02459 iter/s, 14.2357s/100 iters), loss = 0.00296835
I0929 17:05:28.100096  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029677 (* 1 = 0.0029677 loss)
I0929 17:05:28.100106  2305 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0929 17:05:42.346633  2305 solver.cpp:218] Iteration 61700 (7.01927 iter/s, 14.2465s/100 iters), loss = 0.00816499
I0929 17:05:42.346827  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00816435 (* 1 = 0.00816435 loss)
I0929 17:05:42.346848  2305 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0929 17:05:56.584141  2305 solver.cpp:218] Iteration 61800 (7.02381 iter/s, 14.2373s/100 iters), loss = 0.00720909
I0929 17:05:56.584174  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00720845 (* 1 = 0.00720845 loss)
I0929 17:05:56.584182  2305 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0929 17:06:10.831526  2305 solver.cpp:218] Iteration 61900 (7.01887 iter/s, 14.2473s/100 iters), loss = 0.00162547
I0929 17:06:10.831560  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162483 (* 1 = 0.00162483 loss)
I0929 17:06:10.831569  2305 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0929 17:06:24.363335  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:06:24.930538  2305 solver.cpp:330] Iteration 62000, Testing net (#0)
I0929 17:06:28.287466  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:06:28.428565  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0929 17:06:28.428617  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304273 (* 1 = 0.304273 loss)
I0929 17:06:28.571650  2305 solver.cpp:218] Iteration 62000 (5.63696 iter/s, 17.74s/100 iters), loss = 0.00195895
I0929 17:06:28.571686  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195831 (* 1 = 0.00195831 loss)
I0929 17:06:28.571694  2305 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0929 17:06:42.813457  2305 solver.cpp:218] Iteration 62100 (7.02162 iter/s, 14.2417s/100 iters), loss = 0.00279328
I0929 17:06:42.813486  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279263 (* 1 = 0.00279263 loss)
I0929 17:06:42.813493  2305 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0929 17:06:57.056037  2305 solver.cpp:218] Iteration 62200 (7.02123 iter/s, 14.2425s/100 iters), loss = 0.00536775
I0929 17:06:57.056135  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536711 (* 1 = 0.00536711 loss)
I0929 17:06:57.056154  2305 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0929 17:07:11.309325  2305 solver.cpp:218] Iteration 62300 (7.01599 iter/s, 14.2531s/100 iters), loss = 0.0025982
I0929 17:07:11.309358  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259756 (* 1 = 0.00259756 loss)
I0929 17:07:11.309365  2305 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0929 17:07:25.551095  2305 solver.cpp:218] Iteration 62400 (7.02164 iter/s, 14.2417s/100 iters), loss = 0.00222001
I0929 17:07:25.551133  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221937 (* 1 = 0.00221937 loss)
I0929 17:07:25.551141  2305 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0929 17:07:39.082288  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:07:39.650216  2305 solver.cpp:330] Iteration 62500, Testing net (#0)
I0929 17:07:43.006691  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:07:43.145026  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0929 17:07:43.145061  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310457 (* 1 = 0.310457 loss)
I0929 17:07:43.284224  2305 solver.cpp:218] Iteration 62500 (5.63919 iter/s, 17.733s/100 iters), loss = 0.00307488
I0929 17:07:43.284250  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307423 (* 1 = 0.00307423 loss)
I0929 17:07:43.284257  2305 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0929 17:07:57.533228  2305 solver.cpp:218] Iteration 62600 (7.01807 iter/s, 14.2489s/100 iters), loss = 0.00197055
I0929 17:07:57.533260  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196989 (* 1 = 0.00196989 loss)
I0929 17:07:57.533267  2305 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0929 17:08:11.774617  2305 solver.cpp:218] Iteration 62700 (7.02182 iter/s, 14.2413s/100 iters), loss = 0.00236651
I0929 17:08:11.774749  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236586 (* 1 = 0.00236586 loss)
I0929 17:08:11.774767  2305 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0929 17:08:26.009836  2305 solver.cpp:218] Iteration 62800 (7.02491 iter/s, 14.2351s/100 iters), loss = 0.00571552
I0929 17:08:26.009867  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571487 (* 1 = 0.00571487 loss)
I0929 17:08:26.009874  2305 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0929 17:08:40.249393  2305 solver.cpp:218] Iteration 62900 (7.02272 iter/s, 14.2395s/100 iters), loss = 0.00169299
I0929 17:08:40.249423  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169235 (* 1 = 0.00169235 loss)
I0929 17:08:40.249428  2305 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0929 17:08:53.793792  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:08:54.360414  2305 solver.cpp:330] Iteration 63000, Testing net (#0)
I0929 17:08:57.715873  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:08:57.854285  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0929 17:08:57.854321  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298868 (* 1 = 0.298868 loss)
I0929 17:08:57.994176  2305 solver.cpp:218] Iteration 63000 (5.63548 iter/s, 17.7447s/100 iters), loss = 0.0261467
I0929 17:08:57.994204  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261461 (* 1 = 0.0261461 loss)
I0929 17:08:57.994210  2305 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0929 17:09:12.236657  2305 solver.cpp:218] Iteration 63100 (7.02128 iter/s, 14.2424s/100 iters), loss = 0.00232223
I0929 17:09:12.236692  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232158 (* 1 = 0.00232158 loss)
I0929 17:09:12.236701  2305 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0929 17:09:26.486001  2305 solver.cpp:218] Iteration 63200 (7.01791 iter/s, 14.2493s/100 iters), loss = 0.00965084
I0929 17:09:26.486138  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0096502 (* 1 = 0.0096502 loss)
I0929 17:09:26.486146  2305 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0929 17:09:40.742455  2305 solver.cpp:218] Iteration 63300 (7.01446 iter/s, 14.2563s/100 iters), loss = 0.00496415
I0929 17:09:40.742489  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496351 (* 1 = 0.00496351 loss)
I0929 17:09:40.742497  2305 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0929 17:09:54.978202  2305 solver.cpp:218] Iteration 63400 (7.0246 iter/s, 14.2357s/100 iters), loss = 0.00233518
I0929 17:09:54.978231  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233454 (* 1 = 0.00233454 loss)
I0929 17:09:54.978237  2305 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0929 17:10:08.516327  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:10:09.083323  2305 solver.cpp:330] Iteration 63500, Testing net (#0)
I0929 17:10:12.439652  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:10:12.578109  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I0929 17:10:12.578145  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298595 (* 1 = 0.298595 loss)
I0929 17:10:12.717901  2305 solver.cpp:218] Iteration 63500 (5.6371 iter/s, 17.7396s/100 iters), loss = 0.00502864
I0929 17:10:12.717927  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005028 (* 1 = 0.005028 loss)
I0929 17:10:12.717934  2305 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0929 17:10:26.989711  2305 solver.cpp:218] Iteration 63600 (7.00685 iter/s, 14.2717s/100 iters), loss = 0.00362996
I0929 17:10:26.989738  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362932 (* 1 = 0.00362932 loss)
I0929 17:10:26.989744  2305 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0929 17:10:41.245136  2305 solver.cpp:218] Iteration 63700 (7.01491 iter/s, 14.2554s/100 iters), loss = 0.00563446
I0929 17:10:41.245297  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563382 (* 1 = 0.00563382 loss)
I0929 17:10:41.245306  2305 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0929 17:10:55.507978  2305 solver.cpp:218] Iteration 63800 (7.01133 iter/s, 14.2626s/100 iters), loss = 0.00859001
I0929 17:10:55.508039  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858936 (* 1 = 0.00858936 loss)
I0929 17:10:55.508047  2305 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0929 17:11:09.778566  2305 solver.cpp:218] Iteration 63900 (7.00749 iter/s, 14.2704s/100 iters), loss = 0.00174951
I0929 17:11:09.778597  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174886 (* 1 = 0.00174886 loss)
I0929 17:11:09.778604  2305 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0929 17:11:23.339529  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:11:23.908182  2305 solver.cpp:330] Iteration 64000, Testing net (#0)
I0929 17:11:27.260680  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:11:27.399369  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I0929 17:11:27.399405  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30507 (* 1 = 0.30507 loss)
I0929 17:11:27.539211  2305 solver.cpp:218] Iteration 64000 (5.63045 iter/s, 17.7606s/100 iters), loss = 0.00309351
I0929 17:11:27.539242  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309286 (* 1 = 0.00309286 loss)
I0929 17:11:27.539248  2305 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0929 17:11:41.772203  2305 solver.cpp:218] Iteration 64100 (7.02596 iter/s, 14.2329s/100 iters), loss = 0.00138497
I0929 17:11:41.772233  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138432 (* 1 = 0.00138432 loss)
I0929 17:11:41.772238  2305 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0929 17:11:56.011612  2305 solver.cpp:218] Iteration 64200 (7.0228 iter/s, 14.2393s/100 iters), loss = 0.0166609
I0929 17:11:56.011729  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166602 (* 1 = 0.0166602 loss)
I0929 17:11:56.011746  2305 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0929 17:12:10.238168  2305 solver.cpp:218] Iteration 64300 (7.02918 iter/s, 14.2264s/100 iters), loss = 0.0027575
I0929 17:12:10.238199  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275685 (* 1 = 0.00275685 loss)
I0929 17:12:10.238205  2305 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0929 17:12:24.464969  2305 solver.cpp:218] Iteration 64400 (7.02902 iter/s, 14.2267s/100 iters), loss = 0.0185677
I0929 17:12:24.465019  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185671 (* 1 = 0.0185671 loss)
I0929 17:12:24.465025  2305 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0929 17:12:38.012333  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:12:38.579547  2305 solver.cpp:330] Iteration 64500, Testing net (#0)
I0929 17:12:41.933812  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:12:42.071774  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0929 17:12:42.071808  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311995 (* 1 = 0.311995 loss)
I0929 17:12:42.210590  2305 solver.cpp:218] Iteration 64500 (5.63522 iter/s, 17.7455s/100 iters), loss = 0.000575084
I0929 17:12:42.210621  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000574435 (* 1 = 0.000574435 loss)
I0929 17:12:42.210628  2305 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0929 17:12:56.457744  2305 solver.cpp:218] Iteration 64600 (7.01898 iter/s, 14.2471s/100 iters), loss = 0.0139411
I0929 17:12:56.457777  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139404 (* 1 = 0.0139404 loss)
I0929 17:12:56.457784  2305 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0929 17:13:10.700944  2305 solver.cpp:218] Iteration 64700 (7.02093 iter/s, 14.2431s/100 iters), loss = 0.00135953
I0929 17:13:10.701081  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135888 (* 1 = 0.00135888 loss)
I0929 17:13:10.701100  2305 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0929 17:13:24.944856  2305 solver.cpp:218] Iteration 64800 (7.02062 iter/s, 14.2437s/100 iters), loss = 0.00412567
I0929 17:13:24.944886  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412502 (* 1 = 0.00412502 loss)
I0929 17:13:24.944892  2305 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0929 17:13:39.192817  2305 solver.cpp:218] Iteration 64900 (7.01858 iter/s, 14.2479s/100 iters), loss = 0.00156152
I0929 17:13:39.192849  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156087 (* 1 = 0.00156087 loss)
I0929 17:13:39.192857  2305 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0929 17:13:52.731432  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:13:53.298893  2305 solver.cpp:330] Iteration 65000, Testing net (#0)
I0929 17:13:56.652367  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:13:56.790650  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I0929 17:13:56.790686  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319111 (* 1 = 0.319111 loss)
I0929 17:13:56.929612  2305 solver.cpp:218] Iteration 65000 (5.63802 iter/s, 17.7367s/100 iters), loss = 0.00120947
I0929 17:13:56.929641  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120882 (* 1 = 0.00120882 loss)
I0929 17:13:56.929647  2305 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0929 17:14:11.182654  2305 solver.cpp:218] Iteration 65100 (7.01608 iter/s, 14.253s/100 iters), loss = 0.00214206
I0929 17:14:11.182698  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021414 (* 1 = 0.0021414 loss)
I0929 17:14:11.182703  2305 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0929 17:14:25.433382  2305 solver.cpp:218] Iteration 65200 (7.01723 iter/s, 14.2506s/100 iters), loss = 0.00227329
I0929 17:14:25.433524  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227263 (* 1 = 0.00227263 loss)
I0929 17:14:25.433534  2305 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0929 17:14:39.687400  2305 solver.cpp:218] Iteration 65300 (7.01567 iter/s, 14.2538s/100 iters), loss = 0.00217306
I0929 17:14:39.687443  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217241 (* 1 = 0.00217241 loss)
I0929 17:14:39.687448  2305 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0929 17:14:53.932915  2305 solver.cpp:218] Iteration 65400 (7.01979 iter/s, 14.2454s/100 iters), loss = 0.00454896
I0929 17:14:53.932946  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454831 (* 1 = 0.00454831 loss)
I0929 17:14:53.932963  2305 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0929 17:15:07.472748  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:15:08.047142  2305 solver.cpp:330] Iteration 65500, Testing net (#0)
I0929 17:15:11.401509  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:15:11.540156  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I0929 17:15:11.540182  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308649 (* 1 = 0.308649 loss)
I0929 17:15:11.679507  2305 solver.cpp:218] Iteration 65500 (5.63491 iter/s, 17.7465s/100 iters), loss = 0.00284477
I0929 17:15:11.679535  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284412 (* 1 = 0.00284412 loss)
I0929 17:15:11.679543  2305 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0929 17:15:25.928045  2305 solver.cpp:218] Iteration 65600 (7.0183 iter/s, 14.2485s/100 iters), loss = 0.00292566
I0929 17:15:25.928078  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292501 (* 1 = 0.00292501 loss)
I0929 17:15:25.928086  2305 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0929 17:15:40.164814  2305 solver.cpp:218] Iteration 65700 (7.0241 iter/s, 14.2367s/100 iters), loss = 0.00572974
I0929 17:15:40.164923  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572909 (* 1 = 0.00572909 loss)
I0929 17:15:40.164942  2305 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0929 17:15:54.423260  2305 solver.cpp:218] Iteration 65800 (7.01346 iter/s, 14.2583s/100 iters), loss = 0.00252916
I0929 17:15:54.423291  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252851 (* 1 = 0.00252851 loss)
I0929 17:15:54.423297  2305 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0929 17:16:08.680794  2305 solver.cpp:218] Iteration 65900 (7.01387 iter/s, 14.2575s/100 iters), loss = 0.000620068
I0929 17:16:08.680824  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000619417 (* 1 = 0.000619417 loss)
I0929 17:16:08.680830  2305 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0929 17:16:22.209751  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:16:22.783339  2305 solver.cpp:330] Iteration 66000, Testing net (#0)
I0929 17:16:26.137243  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:16:26.275574  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I0929 17:16:26.275599  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316837 (* 1 = 0.316837 loss)
I0929 17:16:26.415094  2305 solver.cpp:218] Iteration 66000 (5.63882 iter/s, 17.7342s/100 iters), loss = 0.001081
I0929 17:16:26.415128  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108036 (* 1 = 0.00108036 loss)
I0929 17:16:26.415135  2305 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0929 17:16:40.678653  2305 solver.cpp:218] Iteration 66100 (7.01091 iter/s, 14.2635s/100 iters), loss = 0.0158686
I0929 17:16:40.678689  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158679 (* 1 = 0.0158679 loss)
I0929 17:16:40.678695  2305 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0929 17:16:54.941210  2305 solver.cpp:218] Iteration 66200 (7.0114 iter/s, 14.2625s/100 iters), loss = 0.00300312
I0929 17:16:54.941323  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300248 (* 1 = 0.00300248 loss)
I0929 17:16:54.941331  2305 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0929 17:17:09.200245  2305 solver.cpp:218] Iteration 66300 (7.01317 iter/s, 14.2589s/100 iters), loss = 0.00282662
I0929 17:17:09.200278  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282598 (* 1 = 0.00282598 loss)
I0929 17:17:09.200284  2305 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0929 17:17:23.470125  2305 solver.cpp:218] Iteration 66400 (7.00781 iter/s, 14.2698s/100 iters), loss = 0.00534664
I0929 17:17:23.470167  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005346 (* 1 = 0.005346 loss)
I0929 17:17:23.470175  2305 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0929 17:17:37.018311  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:17:37.592603  2305 solver.cpp:330] Iteration 66500, Testing net (#0)
I0929 17:17:40.947842  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:17:41.086428  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0929 17:17:41.086464  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308321 (* 1 = 0.308321 loss)
I0929 17:17:41.226166  2305 solver.cpp:218] Iteration 66500 (5.63192 iter/s, 17.7559s/100 iters), loss = 0.0220199
I0929 17:17:41.226198  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220192 (* 1 = 0.0220192 loss)
I0929 17:17:41.226205  2305 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0929 17:17:55.454576  2305 solver.cpp:218] Iteration 66600 (7.02823 iter/s, 14.2283s/100 iters), loss = 0.000949579
I0929 17:17:55.454612  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000948938 (* 1 = 0.000948938 loss)
I0929 17:17:55.454618  2305 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0929 17:18:09.698909  2305 solver.cpp:218] Iteration 66700 (7.02037 iter/s, 14.2443s/100 iters), loss = 0.00532361
I0929 17:18:09.699026  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532297 (* 1 = 0.00532297 loss)
I0929 17:18:09.699034  2305 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0929 17:18:23.943997  2305 solver.cpp:218] Iteration 66800 (7.02004 iter/s, 14.2449s/100 iters), loss = 0.010381
I0929 17:18:23.944027  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103803 (* 1 = 0.0103803 loss)
I0929 17:18:23.944034  2305 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0929 17:18:38.177669  2305 solver.cpp:218] Iteration 66900 (7.02563 iter/s, 14.2336s/100 iters), loss = 0.00514679
I0929 17:18:38.177709  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514616 (* 1 = 0.00514616 loss)
I0929 17:18:38.177716  2305 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0929 17:18:51.703567  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:18:52.272349  2305 solver.cpp:330] Iteration 67000, Testing net (#0)
I0929 17:18:55.636813  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:18:55.778179  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9259
I0929 17:18:55.778205  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302382 (* 1 = 0.302382 loss)
I0929 17:18:55.917629  2305 solver.cpp:218] Iteration 67000 (5.63702 iter/s, 17.7399s/100 iters), loss = 0.0031092
I0929 17:18:55.917663  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310856 (* 1 = 0.00310856 loss)
I0929 17:18:55.917670  2305 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0929 17:19:10.158340  2305 solver.cpp:218] Iteration 67100 (7.02216 iter/s, 14.2406s/100 iters), loss = 0.00321794
I0929 17:19:10.158370  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321731 (* 1 = 0.00321731 loss)
I0929 17:19:10.158375  2305 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0929 17:19:24.404577  2305 solver.cpp:218] Iteration 67200 (7.01943 iter/s, 14.2462s/100 iters), loss = 0.0167063
I0929 17:19:24.404666  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167056 (* 1 = 0.0167056 loss)
I0929 17:19:24.404690  2305 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0929 17:19:38.642590  2305 solver.cpp:218] Iteration 67300 (7.02351 iter/s, 14.2379s/100 iters), loss = 0.00173382
I0929 17:19:38.642621  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173319 (* 1 = 0.00173319 loss)
I0929 17:19:38.642627  2305 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0929 17:19:52.900027  2305 solver.cpp:218] Iteration 67400 (7.01392 iter/s, 14.2574s/100 iters), loss = 0.00087579
I0929 17:19:52.900060  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00087516 (* 1 = 0.00087516 loss)
I0929 17:19:52.900068  2305 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0929 17:20:06.437324  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:20:07.004676  2305 solver.cpp:330] Iteration 67500, Testing net (#0)
I0929 17:20:10.357723  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:20:10.497694  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0929 17:20:10.497723  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305666 (* 1 = 0.305666 loss)
I0929 17:20:10.640601  2305 solver.cpp:218] Iteration 67500 (5.63682 iter/s, 17.7405s/100 iters), loss = 0.00168584
I0929 17:20:10.640646  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168521 (* 1 = 0.00168521 loss)
I0929 17:20:10.640655  2305 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0929 17:20:24.874348  2305 solver.cpp:218] Iteration 67600 (7.0256 iter/s, 14.2337s/100 iters), loss = 0.00677332
I0929 17:20:24.874380  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00677269 (* 1 = 0.00677269 loss)
I0929 17:20:24.874387  2305 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0929 17:20:39.118650  2305 solver.cpp:218] Iteration 67700 (7.02039 iter/s, 14.2442s/100 iters), loss = 0.00823088
I0929 17:20:39.118824  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823025 (* 1 = 0.00823025 loss)
I0929 17:20:39.118844  2305 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0929 17:20:53.365335  2305 solver.cpp:218] Iteration 67800 (7.01928 iter/s, 14.2465s/100 iters), loss = 0.034594
I0929 17:20:53.365366  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345933 (* 1 = 0.0345933 loss)
I0929 17:20:53.365373  2305 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0929 17:21:07.600853  2305 solver.cpp:218] Iteration 67900 (7.02472 iter/s, 14.2354s/100 iters), loss = 0.000826997
I0929 17:21:07.600889  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000826361 (* 1 = 0.000826361 loss)
I0929 17:21:07.600896  2305 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0929 17:21:21.130481  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:21:21.697620  2305 solver.cpp:330] Iteration 68000, Testing net (#0)
I0929 17:21:25.053599  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:21:25.191777  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I0929 17:21:25.191803  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313822 (* 1 = 0.313822 loss)
I0929 17:21:25.331226  2305 solver.cpp:218] Iteration 68000 (5.64007 iter/s, 17.7303s/100 iters), loss = 0.00403061
I0929 17:21:25.331267  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402997 (* 1 = 0.00402997 loss)
I0929 17:21:25.331274  2305 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0929 17:21:39.589282  2305 solver.cpp:218] Iteration 68100 (7.01362 iter/s, 14.258s/100 iters), loss = 0.00929241
I0929 17:21:39.589313  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00929177 (* 1 = 0.00929177 loss)
I0929 17:21:39.589319  2305 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0929 17:21:53.835837  2305 solver.cpp:218] Iteration 68200 (7.01928 iter/s, 14.2465s/100 iters), loss = 0.0111322
I0929 17:21:53.835978  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111315 (* 1 = 0.0111315 loss)
I0929 17:21:53.835986  2305 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0929 17:22:08.082187  2305 solver.cpp:218] Iteration 68300 (7.01943 iter/s, 14.2462s/100 iters), loss = 0.00243652
I0929 17:22:08.082231  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243589 (* 1 = 0.00243589 loss)
I0929 17:22:08.082238  2305 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0929 17:22:22.320850  2305 solver.cpp:218] Iteration 68400 (7.02317 iter/s, 14.2386s/100 iters), loss = 0.001293
I0929 17:22:22.320891  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129237 (* 1 = 0.00129237 loss)
I0929 17:22:22.320899  2305 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0929 17:22:35.856923  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:22:36.422682  2305 solver.cpp:330] Iteration 68500, Testing net (#0)
I0929 17:22:39.776727  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:22:39.915009  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9256
I0929 17:22:39.915035  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310894 (* 1 = 0.310894 loss)
I0929 17:22:40.054636  2305 solver.cpp:218] Iteration 68500 (5.63898 iter/s, 17.7337s/100 iters), loss = 0.00639304
I0929 17:22:40.054662  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00639241 (* 1 = 0.00639241 loss)
I0929 17:22:40.054669  2305 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0929 17:22:54.319875  2305 solver.cpp:218] Iteration 68600 (7.01008 iter/s, 14.2652s/100 iters), loss = 0.00162133
I0929 17:22:54.319910  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016207 (* 1 = 0.0016207 loss)
I0929 17:22:54.319916  2305 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0929 17:23:08.589756  2305 solver.cpp:218] Iteration 68700 (7.0078 iter/s, 14.2698s/100 iters), loss = 0.00139868
I0929 17:23:08.589890  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139805 (* 1 = 0.00139805 loss)
I0929 17:23:08.589897  2305 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0929 17:23:22.855661  2305 solver.cpp:218] Iteration 68800 (7.00981 iter/s, 14.2657s/100 iters), loss = 0.00278082
I0929 17:23:22.855695  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278019 (* 1 = 0.00278019 loss)
I0929 17:23:22.855702  2305 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0929 17:23:37.107899  2305 solver.cpp:218] Iteration 68900 (7.01648 iter/s, 14.2522s/100 iters), loss = 0.00538954
I0929 17:23:37.107940  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538891 (* 1 = 0.00538891 loss)
I0929 17:23:37.107947  2305 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0929 17:23:50.667215  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:23:51.234248  2305 solver.cpp:330] Iteration 69000, Testing net (#0)
I0929 17:23:54.591673  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:23:54.729885  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I0929 17:23:54.729912  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314887 (* 1 = 0.314887 loss)
I0929 17:23:54.869771  2305 solver.cpp:218] Iteration 69000 (5.63006 iter/s, 17.7618s/100 iters), loss = 0.000616527
I0929 17:23:54.869799  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000615894 (* 1 = 0.000615894 loss)
I0929 17:23:54.869807  2305 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0929 17:24:09.108867  2305 solver.cpp:218] Iteration 69100 (7.02295 iter/s, 14.239s/100 iters), loss = 0.0195023
I0929 17:24:09.108897  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195016 (* 1 = 0.0195016 loss)
I0929 17:24:09.108902  2305 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0929 17:24:23.342336  2305 solver.cpp:218] Iteration 69200 (7.02573 iter/s, 14.2334s/100 iters), loss = 0.012771
I0929 17:24:23.342437  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127704 (* 1 = 0.0127704 loss)
I0929 17:24:23.342445  2305 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0929 17:24:37.577682  2305 solver.cpp:218] Iteration 69300 (7.02484 iter/s, 14.2352s/100 iters), loss = 0.00965991
I0929 17:24:37.577730  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00965927 (* 1 = 0.00965927 loss)
I0929 17:24:37.577739  2305 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0929 17:24:51.820261  2305 solver.cpp:218] Iteration 69400 (7.02124 iter/s, 14.2425s/100 iters), loss = 0.000842866
I0929 17:24:51.820296  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000842227 (* 1 = 0.000842227 loss)
I0929 17:24:51.820302  2305 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0929 17:25:05.355648  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:25:05.922503  2305 solver.cpp:330] Iteration 69500, Testing net (#0)
I0929 17:25:09.276337  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:25:09.414474  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I0929 17:25:09.414510  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298579 (* 1 = 0.298579 loss)
I0929 17:25:09.553848  2305 solver.cpp:218] Iteration 69500 (5.63904 iter/s, 17.7335s/100 iters), loss = 0.00328736
I0929 17:25:09.553879  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328672 (* 1 = 0.00328672 loss)
I0929 17:25:09.553885  2305 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0929 17:25:23.802904  2305 solver.cpp:218] Iteration 69600 (7.01804 iter/s, 14.249s/100 iters), loss = 0.00499517
I0929 17:25:23.802937  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499453 (* 1 = 0.00499453 loss)
I0929 17:25:23.802942  2305 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0929 17:25:38.050559  2305 solver.cpp:218] Iteration 69700 (7.01873 iter/s, 14.2476s/100 iters), loss = 0.00701643
I0929 17:25:38.050642  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00701578 (* 1 = 0.00701578 loss)
I0929 17:25:38.050649  2305 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0929 17:25:52.286733  2305 solver.cpp:218] Iteration 69800 (7.02442 iter/s, 14.2361s/100 iters), loss = 0.00270074
I0929 17:25:52.286777  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027001 (* 1 = 0.0027001 loss)
I0929 17:25:52.286782  2305 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0929 17:26:06.532435  2305 solver.cpp:218] Iteration 69900 (7.0197 iter/s, 14.2456s/100 iters), loss = 0.00207596
I0929 17:26:06.532464  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207531 (* 1 = 0.00207531 loss)
I0929 17:26:06.532470  2305 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0929 17:26:20.079973  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:26:20.647223  2305 solver.cpp:330] Iteration 70000, Testing net (#0)
I0929 17:26:24.005899  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:26:24.144364  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0929 17:26:24.144399  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313508 (* 1 = 0.313508 loss)
I0929 17:26:24.283749  2305 solver.cpp:218] Iteration 70000 (5.63341 iter/s, 17.7512s/100 iters), loss = 0.0104597
I0929 17:26:24.283782  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010459 (* 1 = 0.010459 loss)
I0929 17:26:24.283789  2305 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0929 17:26:38.532649  2305 solver.cpp:218] Iteration 70100 (7.01812 iter/s, 14.2488s/100 iters), loss = 0.00353405
I0929 17:26:38.532680  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035334 (* 1 = 0.0035334 loss)
I0929 17:26:38.532687  2305 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0929 17:26:52.775521  2305 solver.cpp:218] Iteration 70200 (7.02109 iter/s, 14.2428s/100 iters), loss = 0.00116483
I0929 17:26:52.775642  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116418 (* 1 = 0.00116418 loss)
I0929 17:26:52.775661  2305 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0929 17:27:07.024281  2305 solver.cpp:218] Iteration 70300 (7.01823 iter/s, 14.2486s/100 iters), loss = 0.00335547
I0929 17:27:07.024314  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335482 (* 1 = 0.00335482 loss)
I0929 17:27:07.024330  2305 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0929 17:27:21.271046  2305 solver.cpp:218] Iteration 70400 (7.01917 iter/s, 14.2467s/100 iters), loss = 0.00156877
I0929 17:27:21.271076  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156812 (* 1 = 0.00156812 loss)
I0929 17:27:21.271082  2305 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0929 17:27:34.805999  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:27:35.374389  2305 solver.cpp:330] Iteration 70500, Testing net (#0)
I0929 17:27:38.730017  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:27:38.868181  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I0929 17:27:38.868217  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309801 (* 1 = 0.309801 loss)
I0929 17:27:39.007752  2305 solver.cpp:218] Iteration 70500 (5.63805 iter/s, 17.7366s/100 iters), loss = 0.00289209
I0929 17:27:39.007781  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289144 (* 1 = 0.00289144 loss)
I0929 17:27:39.007787  2305 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0929 17:27:53.270594  2305 solver.cpp:218] Iteration 70600 (7.01126 iter/s, 14.2628s/100 iters), loss = 0.0017526
I0929 17:27:53.270627  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175195 (* 1 = 0.00175195 loss)
I0929 17:27:53.270633  2305 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0929 17:28:07.518671  2305 solver.cpp:218] Iteration 70700 (7.01853 iter/s, 14.248s/100 iters), loss = 0.00133751
I0929 17:28:07.518836  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133686 (* 1 = 0.00133686 loss)
I0929 17:28:07.518846  2305 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0929 17:28:21.759047  2305 solver.cpp:218] Iteration 70800 (7.02243 iter/s, 14.2401s/100 iters), loss = 0.0019757
I0929 17:28:21.759080  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197506 (* 1 = 0.00197506 loss)
I0929 17:28:21.759089  2305 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0929 17:28:36.010846  2305 solver.cpp:218] Iteration 70900 (7.0167 iter/s, 14.2517s/100 iters), loss = 0.0004995
I0929 17:28:36.010877  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000498846 (* 1 = 0.000498846 loss)
I0929 17:28:36.010885  2305 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0929 17:28:49.547435  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:28:50.122948  2305 solver.cpp:330] Iteration 71000, Testing net (#0)
I0929 17:28:53.479329  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:28:53.617754  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0929 17:28:53.617790  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322365 (* 1 = 0.322365 loss)
I0929 17:28:53.757452  2305 solver.cpp:218] Iteration 71000 (5.63491 iter/s, 17.7465s/100 iters), loss = 0.00210068
I0929 17:28:53.757483  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210003 (* 1 = 0.00210003 loss)
I0929 17:28:53.757490  2305 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0929 17:29:08.013619  2305 solver.cpp:218] Iteration 71100 (7.01454 iter/s, 14.2561s/100 iters), loss = 0.00139946
I0929 17:29:08.013655  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139881 (* 1 = 0.00139881 loss)
I0929 17:29:08.013662  2305 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0929 17:29:22.262382  2305 solver.cpp:218] Iteration 71200 (7.01819 iter/s, 14.2487s/100 iters), loss = 0.00403294
I0929 17:29:22.262493  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403229 (* 1 = 0.00403229 loss)
I0929 17:29:22.262513  2305 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0929 17:29:36.528275  2305 solver.cpp:218] Iteration 71300 (7.0098 iter/s, 14.2658s/100 iters), loss = 0.00139266
I0929 17:29:36.528304  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001392 (* 1 = 0.001392 loss)
I0929 17:29:36.528311  2305 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0929 17:29:50.786643  2305 solver.cpp:218] Iteration 71400 (7.01346 iter/s, 14.2583s/100 iters), loss = 0.000721139
I0929 17:29:50.786684  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000720486 (* 1 = 0.000720486 loss)
I0929 17:29:50.786691  2305 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0929 17:30:04.325048  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:30:04.903255  2305 solver.cpp:330] Iteration 71500, Testing net (#0)
I0929 17:30:08.259769  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:30:08.398447  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I0929 17:30:08.398473  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326557 (* 1 = 0.326557 loss)
I0929 17:30:08.538286  2305 solver.cpp:218] Iteration 71500 (5.63331 iter/s, 17.7516s/100 iters), loss = 0.00147064
I0929 17:30:08.538319  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146999 (* 1 = 0.00146999 loss)
I0929 17:30:08.538326  2305 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0929 17:30:22.785862  2305 solver.cpp:218] Iteration 71600 (7.01877 iter/s, 14.2475s/100 iters), loss = 0.00442987
I0929 17:30:22.785912  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442921 (* 1 = 0.00442921 loss)
I0929 17:30:22.785919  2305 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0929 17:30:37.019057  2305 solver.cpp:218] Iteration 71700 (7.02589 iter/s, 14.2331s/100 iters), loss = 0.00320597
I0929 17:30:37.019191  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320532 (* 1 = 0.00320532 loss)
I0929 17:30:37.019198  2305 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0929 17:30:51.252393  2305 solver.cpp:218] Iteration 71800 (7.02584 iter/s, 14.2332s/100 iters), loss = 0.00140516
I0929 17:30:51.252435  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140451 (* 1 = 0.00140451 loss)
I0929 17:30:51.252442  2305 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0929 17:31:05.499650  2305 solver.cpp:218] Iteration 71900 (7.01894 iter/s, 14.2472s/100 iters), loss = 0.00910117
I0929 17:31:05.499682  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910052 (* 1 = 0.00910052 loss)
I0929 17:31:05.499689  2305 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0929 17:31:19.087627  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:31:19.666434  2305 solver.cpp:330] Iteration 72000, Testing net (#0)
I0929 17:31:23.065034  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:31:23.208632  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I0929 17:31:23.208662  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313992 (* 1 = 0.313992 loss)
I0929 17:31:23.348295  2305 solver.cpp:218] Iteration 72000 (5.60269 iter/s, 17.8486s/100 iters), loss = 0.00155003
I0929 17:31:23.348330  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154938 (* 1 = 0.00154938 loss)
I0929 17:31:23.348336  2305 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0929 17:31:37.718427  2305 solver.cpp:218] Iteration 72100 (6.95891 iter/s, 14.3701s/100 iters), loss = 0.00720573
I0929 17:31:37.718466  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00720508 (* 1 = 0.00720508 loss)
I0929 17:31:37.718474  2305 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0929 17:31:52.128777  2305 solver.cpp:218] Iteration 72200 (6.9395 iter/s, 14.4103s/100 iters), loss = 0.00204777
I0929 17:31:52.128871  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204712 (* 1 = 0.00204712 loss)
I0929 17:31:52.128880  2305 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0929 17:32:06.603864  2305 solver.cpp:218] Iteration 72300 (6.90849 iter/s, 14.475s/100 iters), loss = 0.0060759
I0929 17:32:06.603900  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00607524 (* 1 = 0.00607524 loss)
I0929 17:32:06.603909  2305 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0929 17:32:21.035269  2305 solver.cpp:218] Iteration 72400 (6.92937 iter/s, 14.4313s/100 iters), loss = 0.000921076
I0929 17:32:21.035300  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00092042 (* 1 = 0.00092042 loss)
I0929 17:32:21.035306  2305 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0929 17:32:34.709005  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:32:35.286047  2305 solver.cpp:330] Iteration 72500, Testing net (#0)
I0929 17:32:38.680302  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:32:38.819491  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0929 17:32:38.819515  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318009 (* 1 = 0.318009 loss)
I0929 17:32:38.958727  2305 solver.cpp:218] Iteration 72500 (5.5793 iter/s, 17.9234s/100 iters), loss = 0.00108664
I0929 17:32:38.958756  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108598 (* 1 = 0.00108598 loss)
I0929 17:32:38.958763  2305 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0929 17:32:53.262684  2305 solver.cpp:218] Iteration 72600 (6.99111 iter/s, 14.3039s/100 iters), loss = 0.00487017
I0929 17:32:53.262719  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486951 (* 1 = 0.00486951 loss)
I0929 17:32:53.262727  2305 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0929 17:33:07.523104  2305 solver.cpp:218] Iteration 72700 (7.01245 iter/s, 14.2603s/100 iters), loss = 0.00232028
I0929 17:33:07.523268  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231962 (* 1 = 0.00231962 loss)
I0929 17:33:07.523288  2305 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0929 17:33:21.765010  2305 solver.cpp:218] Iteration 72800 (7.02163 iter/s, 14.2417s/100 iters), loss = 0.00225284
I0929 17:33:21.765043  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225219 (* 1 = 0.00225219 loss)
I0929 17:33:21.765049  2305 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0929 17:33:36.013695  2305 solver.cpp:218] Iteration 72900 (7.01823 iter/s, 14.2486s/100 iters), loss = 0.00350592
I0929 17:33:36.013736  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350526 (* 1 = 0.00350526 loss)
I0929 17:33:36.013743  2305 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0929 17:33:49.545300  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:33:50.120296  2305 solver.cpp:330] Iteration 73000, Testing net (#0)
I0929 17:33:53.473662  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:33:53.612545  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0929 17:33:53.612570  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321306 (* 1 = 0.321306 loss)
I0929 17:33:53.752014  2305 solver.cpp:218] Iteration 73000 (5.63754 iter/s, 17.7382s/100 iters), loss = 0.00367331
I0929 17:33:53.752048  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367265 (* 1 = 0.00367265 loss)
I0929 17:33:53.752054  2305 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0929 17:34:08.002228  2305 solver.cpp:218] Iteration 73100 (7.01747 iter/s, 14.2501s/100 iters), loss = 0.00651749
I0929 17:34:08.002259  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651683 (* 1 = 0.00651683 loss)
I0929 17:34:08.002265  2305 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0929 17:34:22.246423  2305 solver.cpp:218] Iteration 73200 (7.02044 iter/s, 14.2441s/100 iters), loss = 0.00511897
I0929 17:34:22.246568  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511831 (* 1 = 0.00511831 loss)
I0929 17:34:22.246577  2305 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0929 17:34:36.489784  2305 solver.cpp:218] Iteration 73300 (7.0209 iter/s, 14.2432s/100 iters), loss = 0.00183774
I0929 17:34:36.489812  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183708 (* 1 = 0.00183708 loss)
I0929 17:34:36.489819  2305 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0929 17:34:50.731775  2305 solver.cpp:218] Iteration 73400 (7.02153 iter/s, 14.2419s/100 iters), loss = 0.00705777
I0929 17:34:50.731819  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705712 (* 1 = 0.00705712 loss)
I0929 17:34:50.731827  2305 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0929 17:35:04.270043  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:35:04.846233  2305 solver.cpp:330] Iteration 73500, Testing net (#0)
I0929 17:35:08.202811  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:35:08.341123  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I0929 17:35:08.341148  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319063 (* 1 = 0.319063 loss)
I0929 17:35:08.482421  2305 solver.cpp:218] Iteration 73500 (5.63363 iter/s, 17.7506s/100 iters), loss = 0.00123034
I0929 17:35:08.482455  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122969 (* 1 = 0.00122969 loss)
I0929 17:35:08.482461  2305 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0929 17:35:22.747985  2305 solver.cpp:218] Iteration 73600 (7.00993 iter/s, 14.2655s/100 iters), loss = 0.010303
I0929 17:35:22.748023  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103023 (* 1 = 0.0103023 loss)
I0929 17:35:22.748031  2305 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0929 17:35:37.000926  2305 solver.cpp:218] Iteration 73700 (7.01613 iter/s, 14.2529s/100 iters), loss = 0.00481253
I0929 17:35:37.001086  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481188 (* 1 = 0.00481188 loss)
I0929 17:35:37.001104  2305 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0929 17:35:51.273388  2305 solver.cpp:218] Iteration 73800 (7.00659 iter/s, 14.2723s/100 iters), loss = 0.00204481
I0929 17:35:51.273419  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204415 (* 1 = 0.00204415 loss)
I0929 17:35:51.273425  2305 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0929 17:36:05.541486  2305 solver.cpp:218] Iteration 73900 (7.00868 iter/s, 14.268s/100 iters), loss = 0.00298824
I0929 17:36:05.541529  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298758 (* 1 = 0.00298758 loss)
I0929 17:36:05.541537  2305 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0929 17:36:19.081681  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:36:19.651418  2305 solver.cpp:330] Iteration 74000, Testing net (#0)
I0929 17:36:23.008496  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:36:23.146770  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I0929 17:36:23.146806  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32125 (* 1 = 0.32125 loss)
I0929 17:36:23.286814  2305 solver.cpp:218] Iteration 74000 (5.63532 iter/s, 17.7452s/100 iters), loss = 0.00544994
I0929 17:36:23.286849  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544929 (* 1 = 0.00544929 loss)
I0929 17:36:23.286856  2305 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0929 17:36:37.519613  2305 solver.cpp:218] Iteration 74100 (7.02606 iter/s, 14.2327s/100 iters), loss = 0.00132603
I0929 17:36:37.519642  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132538 (* 1 = 0.00132538 loss)
I0929 17:36:37.519649  2305 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0929 17:36:51.765566  2305 solver.cpp:218] Iteration 74200 (7.01957 iter/s, 14.2459s/100 iters), loss = 0.00423929
I0929 17:36:51.765682  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423864 (* 1 = 0.00423864 loss)
I0929 17:36:51.765691  2305 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0929 17:37:06.001281  2305 solver.cpp:218] Iteration 74300 (7.02466 iter/s, 14.2356s/100 iters), loss = 0.00332636
I0929 17:37:06.001312  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332571 (* 1 = 0.00332571 loss)
I0929 17:37:06.001317  2305 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0929 17:37:20.245879  2305 solver.cpp:218] Iteration 74400 (7.02024 iter/s, 14.2445s/100 iters), loss = 0.00871877
I0929 17:37:20.245910  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00871812 (* 1 = 0.00871812 loss)
I0929 17:37:20.245918  2305 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0929 17:37:33.777166  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:37:34.343015  2305 solver.cpp:330] Iteration 74500, Testing net (#0)
I0929 17:37:37.704320  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:37:37.847110  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I0929 17:37:37.847139  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328611 (* 1 = 0.328611 loss)
I0929 17:37:37.987078  2305 solver.cpp:218] Iteration 74500 (5.63662 iter/s, 17.7411s/100 iters), loss = 0.00048524
I0929 17:37:37.987114  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000484588 (* 1 = 0.000484588 loss)
I0929 17:37:37.987123  2305 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0929 17:37:52.224761  2305 solver.cpp:218] Iteration 74600 (7.02365 iter/s, 14.2376s/100 iters), loss = 0.00224164
I0929 17:37:52.224798  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224099 (* 1 = 0.00224099 loss)
I0929 17:37:52.224808  2305 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0929 17:38:06.466290  2305 solver.cpp:218] Iteration 74700 (7.02175 iter/s, 14.2415s/100 iters), loss = 0.00423614
I0929 17:38:06.466410  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042355 (* 1 = 0.0042355 loss)
I0929 17:38:06.466419  2305 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0929 17:38:20.715242  2305 solver.cpp:218] Iteration 74800 (7.01814 iter/s, 14.2488s/100 iters), loss = 0.00207904
I0929 17:38:20.715273  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020784 (* 1 = 0.0020784 loss)
I0929 17:38:20.715279  2305 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0929 17:38:34.962471  2305 solver.cpp:218] Iteration 74900 (7.01895 iter/s, 14.2471s/100 iters), loss = 0.000947557
I0929 17:38:34.962517  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000946907 (* 1 = 0.000946907 loss)
I0929 17:38:34.962527  2305 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0929 17:38:48.489594  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:38:49.057983  2305 solver.cpp:330] Iteration 75000, Testing net (#0)
I0929 17:38:52.411420  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:38:52.549796  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I0929 17:38:52.549834  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320417 (* 1 = 0.320417 loss)
I0929 17:38:52.693748  2305 solver.cpp:218] Iteration 75000 (5.63978 iter/s, 17.7312s/100 iters), loss = 0.000804378
I0929 17:38:52.693797  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00080373 (* 1 = 0.00080373 loss)
I0929 17:38:52.693805  2305 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0929 17:39:06.943827  2305 solver.cpp:218] Iteration 75100 (7.01757 iter/s, 14.2499s/100 iters), loss = 0.00353036
I0929 17:39:06.943858  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352972 (* 1 = 0.00352972 loss)
I0929 17:39:06.943874  2305 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0929 17:39:21.192694  2305 solver.cpp:218] Iteration 75200 (7.01814 iter/s, 14.2488s/100 iters), loss = 0.00783933
I0929 17:39:21.192828  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783867 (* 1 = 0.00783867 loss)
I0929 17:39:21.192847  2305 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0929 17:39:35.433032  2305 solver.cpp:218] Iteration 75300 (7.02239 iter/s, 14.2402s/100 iters), loss = 0.00111475
I0929 17:39:35.433075  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011141 (* 1 = 0.0011141 loss)
I0929 17:39:35.433082  2305 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0929 17:39:49.672953  2305 solver.cpp:218] Iteration 75400 (7.02256 iter/s, 14.2398s/100 iters), loss = 0.00760688
I0929 17:39:49.672991  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760623 (* 1 = 0.00760623 loss)
I0929 17:39:49.672998  2305 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0929 17:40:03.214239  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:40:03.780175  2305 solver.cpp:330] Iteration 75500, Testing net (#0)
I0929 17:40:07.138092  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:40:07.276690  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I0929 17:40:07.276726  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312892 (* 1 = 0.312892 loss)
I0929 17:40:07.415868  2305 solver.cpp:218] Iteration 75500 (5.63608 iter/s, 17.7428s/100 iters), loss = 0.00214774
I0929 17:40:07.415895  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214709 (* 1 = 0.00214709 loss)
I0929 17:40:07.415902  2305 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0929 17:40:21.663628  2305 solver.cpp:218] Iteration 75600 (7.01868 iter/s, 14.2477s/100 iters), loss = 0.00115546
I0929 17:40:21.663658  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115481 (* 1 = 0.00115481 loss)
I0929 17:40:21.663666  2305 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0929 17:40:35.919145  2305 solver.cpp:218] Iteration 75700 (7.01486 iter/s, 14.2554s/100 iters), loss = 0.00341508
I0929 17:40:35.919281  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341443 (* 1 = 0.00341443 loss)
I0929 17:40:35.919298  2305 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0929 17:40:50.179023  2305 solver.cpp:218] Iteration 75800 (7.01276 iter/s, 14.2597s/100 iters), loss = 0.00227469
I0929 17:40:50.179066  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227404 (* 1 = 0.00227404 loss)
I0929 17:40:50.179074  2305 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0929 17:41:04.418920  2305 solver.cpp:218] Iteration 75900 (7.02256 iter/s, 14.2398s/100 iters), loss = 0.00191497
I0929 17:41:04.418951  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191432 (* 1 = 0.00191432 loss)
I0929 17:41:04.418956  2305 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0929 17:41:17.963359  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:41:18.531036  2305 solver.cpp:330] Iteration 76000, Testing net (#0)
I0929 17:41:21.887068  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:41:22.025538  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I0929 17:41:22.025563  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315733 (* 1 = 0.315733 loss)
I0929 17:41:22.164829  2305 solver.cpp:218] Iteration 76000 (5.63513 iter/s, 17.7458s/100 iters), loss = 0.00818697
I0929 17:41:22.164870  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00818632 (* 1 = 0.00818632 loss)
I0929 17:41:22.164880  2305 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0929 17:41:36.432838  2305 solver.cpp:218] Iteration 76100 (7.00873 iter/s, 14.2679s/100 iters), loss = 0.00180988
I0929 17:41:36.432869  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180923 (* 1 = 0.00180923 loss)
I0929 17:41:36.432875  2305 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0929 17:41:50.692783  2305 solver.cpp:218] Iteration 76200 (7.01269 iter/s, 14.2599s/100 iters), loss = 0.00328247
I0929 17:41:50.692885  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328182 (* 1 = 0.00328182 loss)
I0929 17:41:50.692893  2305 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0929 17:42:04.947806  2305 solver.cpp:218] Iteration 76300 (7.01514 iter/s, 14.2549s/100 iters), loss = 0.0016873
I0929 17:42:04.947841  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168665 (* 1 = 0.00168665 loss)
I0929 17:42:04.947849  2305 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0929 17:42:19.203075  2305 solver.cpp:218] Iteration 76400 (7.01499 iter/s, 14.2552s/100 iters), loss = 0.0061179
I0929 17:42:19.203106  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00611725 (* 1 = 0.00611725 loss)
I0929 17:42:19.203124  2305 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0929 17:42:32.763991  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:42:33.331326  2305 solver.cpp:330] Iteration 76500, Testing net (#0)
I0929 17:42:36.686002  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:42:36.824781  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I0929 17:42:36.824806  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323841 (* 1 = 0.323841 loss)
I0929 17:42:36.964264  2305 solver.cpp:218] Iteration 76500 (5.63028 iter/s, 17.7611s/100 iters), loss = 0.00100669
I0929 17:42:36.964292  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100604 (* 1 = 0.00100604 loss)
I0929 17:42:36.964298  2305 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0929 17:42:51.203523  2305 solver.cpp:218] Iteration 76600 (7.02287 iter/s, 14.2392s/100 iters), loss = 0.00172667
I0929 17:42:51.203565  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172602 (* 1 = 0.00172602 loss)
I0929 17:42:51.203573  2305 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0929 17:43:05.458247  2305 solver.cpp:218] Iteration 76700 (7.01526 iter/s, 14.2546s/100 iters), loss = 0.00254771
I0929 17:43:05.458410  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254706 (* 1 = 0.00254706 loss)
I0929 17:43:05.458420  2305 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0929 17:43:19.699986  2305 solver.cpp:218] Iteration 76800 (7.02171 iter/s, 14.2415s/100 iters), loss = 0.000668559
I0929 17:43:19.700021  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000667907 (* 1 = 0.000667907 loss)
I0929 17:43:19.700027  2305 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0929 17:43:33.933020  2305 solver.cpp:218] Iteration 76900 (7.02595 iter/s, 14.233s/100 iters), loss = 0.000964262
I0929 17:43:33.933061  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000963611 (* 1 = 0.000963611 loss)
I0929 17:43:33.933068  2305 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0929 17:43:47.477859  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:43:48.044744  2305 solver.cpp:330] Iteration 77000, Testing net (#0)
I0929 17:43:51.403050  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:43:51.541424  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I0929 17:43:51.541458  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319346 (* 1 = 0.319346 loss)
I0929 17:43:51.680641  2305 solver.cpp:218] Iteration 77000 (5.63459 iter/s, 17.7475s/100 iters), loss = 0.000569092
I0929 17:43:51.680667  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000568442 (* 1 = 0.000568442 loss)
I0929 17:43:51.680675  2305 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0929 17:44:05.938130  2305 solver.cpp:218] Iteration 77100 (7.01389 iter/s, 14.2574s/100 iters), loss = 0.0712605
I0929 17:44:05.938164  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712598 (* 1 = 0.0712598 loss)
I0929 17:44:05.938172  2305 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0929 17:44:20.178205  2305 solver.cpp:218] Iteration 77200 (7.02247 iter/s, 14.24s/100 iters), loss = 0.00126653
I0929 17:44:20.178346  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126588 (* 1 = 0.00126588 loss)
I0929 17:44:20.178354  2305 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0929 17:44:34.419103  2305 solver.cpp:218] Iteration 77300 (7.02212 iter/s, 14.2407s/100 iters), loss = 0.00384685
I0929 17:44:34.419134  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038462 (* 1 = 0.0038462 loss)
I0929 17:44:34.419140  2305 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0929 17:44:48.667882  2305 solver.cpp:218] Iteration 77400 (7.01818 iter/s, 14.2487s/100 iters), loss = 0.00281955
I0929 17:44:48.667913  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281889 (* 1 = 0.00281889 loss)
I0929 17:44:48.667920  2305 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0929 17:45:02.203863  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:45:02.771132  2305 solver.cpp:330] Iteration 77500, Testing net (#0)
I0929 17:45:06.127322  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:45:06.265333  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I0929 17:45:06.265367  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331179 (* 1 = 0.331179 loss)
I0929 17:45:06.404430  2305 solver.cpp:218] Iteration 77500 (5.6381 iter/s, 17.7365s/100 iters), loss = 0.00129669
I0929 17:45:06.404459  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129604 (* 1 = 0.00129604 loss)
I0929 17:45:06.404465  2305 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0929 17:45:20.642208  2305 solver.cpp:218] Iteration 77600 (7.02361 iter/s, 14.2377s/100 iters), loss = 0.00170982
I0929 17:45:20.642240  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170917 (* 1 = 0.00170917 loss)
I0929 17:45:20.642246  2305 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0929 17:45:34.887321  2305 solver.cpp:218] Iteration 77700 (7.01999 iter/s, 14.245s/100 iters), loss = 0.00875607
I0929 17:45:34.887450  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00875541 (* 1 = 0.00875541 loss)
I0929 17:45:34.887459  2305 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0929 17:45:49.122027  2305 solver.cpp:218] Iteration 77800 (7.02518 iter/s, 14.2345s/100 iters), loss = 0.00325587
I0929 17:45:49.122056  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325521 (* 1 = 0.00325521 loss)
I0929 17:45:49.122061  2305 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0929 17:46:03.357174  2305 solver.cpp:218] Iteration 77900 (7.0249 iter/s, 14.2351s/100 iters), loss = 0.00108046
I0929 17:46:03.357208  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010798 (* 1 = 0.0010798 loss)
I0929 17:46:03.357215  2305 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0929 17:46:16.897363  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:46:17.465559  2305 solver.cpp:330] Iteration 78000, Testing net (#0)
I0929 17:46:20.823421  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:46:20.961853  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I0929 17:46:20.961890  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323558 (* 1 = 0.323558 loss)
I0929 17:46:21.101410  2305 solver.cpp:218] Iteration 78000 (5.63566 iter/s, 17.7442s/100 iters), loss = 0.004071
I0929 17:46:21.101438  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407035 (* 1 = 0.00407035 loss)
I0929 17:46:21.101444  2305 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0929 17:46:35.355479  2305 solver.cpp:218] Iteration 78100 (7.01557 iter/s, 14.254s/100 iters), loss = 0.00325113
I0929 17:46:35.355511  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325048 (* 1 = 0.00325048 loss)
I0929 17:46:35.355518  2305 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0929 17:46:49.593237  2305 solver.cpp:218] Iteration 78200 (7.02362 iter/s, 14.2377s/100 iters), loss = 0.0274411
I0929 17:46:49.593366  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274404 (* 1 = 0.0274404 loss)
I0929 17:46:49.593375  2305 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0929 17:47:03.850801  2305 solver.cpp:218] Iteration 78300 (7.0139 iter/s, 14.2574s/100 iters), loss = 0.00273605
I0929 17:47:03.850833  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273539 (* 1 = 0.00273539 loss)
I0929 17:47:03.850842  2305 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0929 17:47:18.109114  2305 solver.cpp:218] Iteration 78400 (7.01349 iter/s, 14.2582s/100 iters), loss = 0.00576698
I0929 17:47:18.109145  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576632 (* 1 = 0.00576632 loss)
I0929 17:47:18.109153  2305 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0929 17:47:31.642022  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:47:32.217352  2305 solver.cpp:330] Iteration 78500, Testing net (#0)
I0929 17:47:35.572084  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:47:35.710845  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I0929 17:47:35.710872  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326846 (* 1 = 0.326846 loss)
I0929 17:47:35.850756  2305 solver.cpp:218] Iteration 78500 (5.63648 iter/s, 17.7416s/100 iters), loss = 0.000994866
I0929 17:47:35.850787  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000994204 (* 1 = 0.000994204 loss)
I0929 17:47:35.850795  2305 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0929 17:47:50.121246  2305 solver.cpp:218] Iteration 78600 (7.0075 iter/s, 14.2704s/100 iters), loss = 0.00202046
I0929 17:47:50.121280  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020198 (* 1 = 0.0020198 loss)
I0929 17:47:50.121287  2305 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0929 17:48:04.380275  2305 solver.cpp:218] Iteration 78700 (7.01314 iter/s, 14.2589s/100 iters), loss = 0.00496951
I0929 17:48:04.380437  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496884 (* 1 = 0.00496884 loss)
I0929 17:48:04.380456  2305 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0929 17:48:18.636989  2305 solver.cpp:218] Iteration 78800 (7.01433 iter/s, 14.2565s/100 iters), loss = 0.0139406
I0929 17:48:18.637029  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01394 (* 1 = 0.01394 loss)
I0929 17:48:18.637035  2305 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0929 17:48:32.899171  2305 solver.cpp:218] Iteration 78900 (7.01159 iter/s, 14.2621s/100 iters), loss = 0.0219732
I0929 17:48:32.899210  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219725 (* 1 = 0.0219725 loss)
I0929 17:48:32.899217  2305 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0929 17:48:46.448385  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:48:47.026536  2305 solver.cpp:330] Iteration 79000, Testing net (#0)
I0929 17:48:50.383594  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:48:50.521950  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I0929 17:48:50.521981  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364509 (* 1 = 0.364509 loss)
I0929 17:48:50.660883  2305 solver.cpp:218] Iteration 79000 (5.63012 iter/s, 17.7616s/100 iters), loss = 0.00277154
I0929 17:48:50.660922  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277088 (* 1 = 0.00277088 loss)
I0929 17:48:50.660929  2305 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0929 17:49:04.907341  2305 solver.cpp:218] Iteration 79100 (7.01933 iter/s, 14.2464s/100 iters), loss = 0.00234765
I0929 17:49:04.907390  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234698 (* 1 = 0.00234698 loss)
I0929 17:49:04.907398  2305 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0929 17:49:19.141513  2305 solver.cpp:218] Iteration 79200 (7.02541 iter/s, 14.2341s/100 iters), loss = 0.00149997
I0929 17:49:19.141633  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149931 (* 1 = 0.00149931 loss)
I0929 17:49:19.141650  2305 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0929 17:49:33.385947  2305 solver.cpp:218] Iteration 79300 (7.02036 iter/s, 14.2443s/100 iters), loss = 0.000877965
I0929 17:49:33.385979  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000877302 (* 1 = 0.000877302 loss)
I0929 17:49:33.386001  2305 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0929 17:49:47.628644  2305 solver.cpp:218] Iteration 79400 (7.02118 iter/s, 14.2426s/100 iters), loss = 0.0059352
I0929 17:49:47.628679  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00593454 (* 1 = 0.00593454 loss)
I0929 17:49:47.628689  2305 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0929 17:50:01.153036  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:50:01.723496  2305 solver.cpp:330] Iteration 79500, Testing net (#0)
I0929 17:50:05.084455  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:50:05.222640  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I0929 17:50:05.222668  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310414 (* 1 = 0.310414 loss)
I0929 17:50:05.362650  2305 solver.cpp:218] Iteration 79500 (5.63891 iter/s, 17.7339s/100 iters), loss = 0.000769688
I0929 17:50:05.362689  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000769025 (* 1 = 0.000769025 loss)
I0929 17:50:05.362699  2305 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0929 17:50:19.608821  2305 solver.cpp:218] Iteration 79600 (7.01947 iter/s, 14.2461s/100 iters), loss = 0.00404557
I0929 17:50:19.608855  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404491 (* 1 = 0.00404491 loss)
I0929 17:50:19.608862  2305 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0929 17:50:33.857604  2305 solver.cpp:218] Iteration 79700 (7.01818 iter/s, 14.2487s/100 iters), loss = 0.00445848
I0929 17:50:33.857785  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445782 (* 1 = 0.00445782 loss)
I0929 17:50:33.857810  2305 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0929 17:50:48.096460  2305 solver.cpp:218] Iteration 79800 (7.02314 iter/s, 14.2387s/100 iters), loss = 0.00432902
I0929 17:50:48.096493  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432836 (* 1 = 0.00432836 loss)
I0929 17:50:48.096500  2305 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0929 17:51:02.351884  2305 solver.cpp:218] Iteration 79900 (7.01491 iter/s, 14.2554s/100 iters), loss = 0.000423466
I0929 17:51:02.351919  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000422811 (* 1 = 0.000422811 loss)
I0929 17:51:02.351928  2305 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0929 17:51:15.887634  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:51:16.456003  2305 solver.cpp:330] Iteration 80000, Testing net (#0)
I0929 17:51:19.814299  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:51:19.956907  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I0929 17:51:19.956935  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347401 (* 1 = 0.347401 loss)
I0929 17:51:20.095495  2305 solver.cpp:218] Iteration 80000 (5.63586 iter/s, 17.7435s/100 iters), loss = 0.001436
I0929 17:51:20.095531  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143535 (* 1 = 0.00143535 loss)
I0929 17:51:20.095540  2305 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0929 17:51:20.095546  2305 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0929 17:51:34.324883  2305 solver.cpp:218] Iteration 80100 (7.02775 iter/s, 14.2293s/100 iters), loss = 0.00457471
I0929 17:51:34.324918  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457406 (* 1 = 0.00457406 loss)
I0929 17:51:34.324935  2305 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0929 17:51:48.580512  2305 solver.cpp:218] Iteration 80200 (7.01481 iter/s, 14.2556s/100 iters), loss = 0.00520887
I0929 17:51:48.580629  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520821 (* 1 = 0.00520821 loss)
I0929 17:51:48.580641  2305 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0929 17:52:02.828644  2305 solver.cpp:218] Iteration 80300 (7.01854 iter/s, 14.248s/100 iters), loss = 0.00153102
I0929 17:52:02.828676  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153036 (* 1 = 0.00153036 loss)
I0929 17:52:02.828685  2305 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0929 17:52:17.071146  2305 solver.cpp:218] Iteration 80400 (7.02127 iter/s, 14.2424s/100 iters), loss = 0.000281358
I0929 17:52:17.071178  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000280696 (* 1 = 0.000280696 loss)
I0929 17:52:17.071185  2305 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0929 17:52:30.602880  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:52:31.170730  2305 solver.cpp:330] Iteration 80500, Testing net (#0)
I0929 17:52:34.525290  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:52:34.665042  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9291
I0929 17:52:34.665092  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300893 (* 1 = 0.300893 loss)
I0929 17:52:34.808696  2305 solver.cpp:218] Iteration 80500 (5.63778 iter/s, 17.7375s/100 iters), loss = 0.00161503
I0929 17:52:34.808732  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161437 (* 1 = 0.00161437 loss)
I0929 17:52:34.808739  2305 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0929 17:52:49.061209  2305 solver.cpp:218] Iteration 80600 (7.01634 iter/s, 14.2524s/100 iters), loss = 0.00105072
I0929 17:52:49.061240  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105006 (* 1 = 0.00105006 loss)
I0929 17:52:49.061256  2305 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0929 17:53:03.316581  2305 solver.cpp:218] Iteration 80700 (7.01494 iter/s, 14.2553s/100 iters), loss = 0.00259132
I0929 17:53:03.316737  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259066 (* 1 = 0.00259066 loss)
I0929 17:53:03.316746  2305 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0929 17:53:17.564844  2305 solver.cpp:218] Iteration 80800 (7.01849 iter/s, 14.2481s/100 iters), loss = 0.000860167
I0929 17:53:17.564874  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0008595 (* 1 = 0.0008595 loss)
I0929 17:53:17.564890  2305 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0929 17:53:31.824566  2305 solver.cpp:218] Iteration 80900 (7.0128 iter/s, 14.2596s/100 iters), loss = 0.00127019
I0929 17:53:31.824618  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126952 (* 1 = 0.00126952 loss)
I0929 17:53:31.824636  2305 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0929 17:53:45.370877  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:53:45.938657  2305 solver.cpp:330] Iteration 81000, Testing net (#0)
I0929 17:53:49.291723  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:53:49.430405  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9304
I0929 17:53:49.430441  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290231 (* 1 = 0.290231 loss)
I0929 17:53:49.570580  2305 solver.cpp:218] Iteration 81000 (5.63511 iter/s, 17.7459s/100 iters), loss = 0.00123709
I0929 17:53:49.570606  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123642 (* 1 = 0.00123642 loss)
I0929 17:53:49.570613  2305 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0929 17:54:03.832135  2305 solver.cpp:218] Iteration 81100 (7.01189 iter/s, 14.2615s/100 iters), loss = 0.00505214
I0929 17:54:03.832170  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505147 (* 1 = 0.00505147 loss)
I0929 17:54:03.832188  2305 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0929 17:54:18.095655  2305 solver.cpp:218] Iteration 81200 (7.01093 iter/s, 14.2634s/100 iters), loss = 0.00129253
I0929 17:54:18.095798  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129186 (* 1 = 0.00129186 loss)
I0929 17:54:18.095823  2305 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0929 17:54:32.358309  2305 solver.cpp:218] Iteration 81300 (7.01141 iter/s, 14.2625s/100 iters), loss = 0.00224073
I0929 17:54:32.358348  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224007 (* 1 = 0.00224007 loss)
I0929 17:54:32.358358  2305 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0929 17:54:46.607609  2305 solver.cpp:218] Iteration 81400 (7.01793 iter/s, 14.2492s/100 iters), loss = 0.00110953
I0929 17:54:46.607645  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110887 (* 1 = 0.00110887 loss)
I0929 17:54:46.607653  2305 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0929 17:55:00.200227  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:55:00.808342  2305 solver.cpp:330] Iteration 81500, Testing net (#0)
I0929 17:55:04.244974  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:55:04.383596  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9323
I0929 17:55:04.383622  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285898 (* 1 = 0.285898 loss)
I0929 17:55:04.525970  2305 solver.cpp:218] Iteration 81500 (5.58089 iter/s, 17.9183s/100 iters), loss = 0.00124244
I0929 17:55:04.526006  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124177 (* 1 = 0.00124177 loss)
I0929 17:55:04.526013  2305 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0929 17:55:18.805783  2305 solver.cpp:218] Iteration 81600 (7.00293 iter/s, 14.2797s/100 iters), loss = 0.00437887
I0929 17:55:18.805814  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043782 (* 1 = 0.0043782 loss)
I0929 17:55:18.805819  2305 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0929 17:55:33.046355  2305 solver.cpp:218] Iteration 81700 (7.02222 iter/s, 14.2405s/100 iters), loss = 0.00205812
I0929 17:55:33.046484  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205745 (* 1 = 0.00205745 loss)
I0929 17:55:33.046492  2305 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0929 17:55:47.294936  2305 solver.cpp:218] Iteration 81800 (7.01832 iter/s, 14.2484s/100 iters), loss = 0.00216674
I0929 17:55:47.294970  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216607 (* 1 = 0.00216607 loss)
I0929 17:55:47.294978  2305 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0929 17:56:01.532888  2305 solver.cpp:218] Iteration 81900 (7.02352 iter/s, 14.2379s/100 iters), loss = 0.00224473
I0929 17:56:01.532925  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224406 (* 1 = 0.00224406 loss)
I0929 17:56:01.532933  2305 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0929 17:56:15.074491  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:56:15.642611  2305 solver.cpp:330] Iteration 82000, Testing net (#0)
I0929 17:56:18.996039  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:56:19.134568  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9316
I0929 17:56:19.134604  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283938 (* 1 = 0.283938 loss)
I0929 17:56:19.273726  2305 solver.cpp:218] Iteration 82000 (5.63674 iter/s, 17.7408s/100 iters), loss = 0.000446916
I0929 17:56:19.273753  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000446248 (* 1 = 0.000446248 loss)
I0929 17:56:19.273761  2305 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0929 17:56:33.526332  2305 solver.cpp:218] Iteration 82100 (7.0163 iter/s, 14.2525s/100 iters), loss = 0.00230324
I0929 17:56:33.526374  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230257 (* 1 = 0.00230257 loss)
I0929 17:56:33.526381  2305 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0929 17:56:47.783581  2305 solver.cpp:218] Iteration 82200 (7.01402 iter/s, 14.2572s/100 iters), loss = 0.00469218
I0929 17:56:47.783707  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469151 (* 1 = 0.00469151 loss)
I0929 17:56:47.783725  2305 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0929 17:57:02.035554  2305 solver.cpp:218] Iteration 82300 (7.01666 iter/s, 14.2518s/100 iters), loss = 0.00158326
I0929 17:57:02.035598  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158259 (* 1 = 0.00158259 loss)
I0929 17:57:02.035614  2305 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0929 17:57:16.266189  2305 solver.cpp:218] Iteration 82400 (7.02713 iter/s, 14.2306s/100 iters), loss = 0.000999572
I0929 17:57:16.266230  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000998906 (* 1 = 0.000998906 loss)
I0929 17:57:16.266237  2305 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0929 17:57:29.811655  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:57:30.378527  2305 solver.cpp:330] Iteration 82500, Testing net (#0)
I0929 17:57:33.734544  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:57:33.873049  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9313
I0929 17:57:33.873085  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284556 (* 1 = 0.284556 loss)
I0929 17:57:34.012655  2305 solver.cpp:218] Iteration 82500 (5.63495 iter/s, 17.7464s/100 iters), loss = 0.000504435
I0929 17:57:34.012681  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000503769 (* 1 = 0.000503769 loss)
I0929 17:57:34.012688  2305 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0929 17:57:48.258574  2305 solver.cpp:218] Iteration 82600 (7.01959 iter/s, 14.2459s/100 iters), loss = 0.00112744
I0929 17:57:48.258606  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112677 (* 1 = 0.00112677 loss)
I0929 17:57:48.258612  2305 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0929 17:58:02.498898  2305 solver.cpp:218] Iteration 82700 (7.02235 iter/s, 14.2402s/100 iters), loss = 0.00182411
I0929 17:58:02.499090  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182345 (* 1 = 0.00182345 loss)
I0929 17:58:02.499100  2305 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0929 17:58:16.739555  2305 solver.cpp:218] Iteration 82800 (7.02226 iter/s, 14.2404s/100 iters), loss = 0.00117621
I0929 17:58:16.739598  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117555 (* 1 = 0.00117555 loss)
I0929 17:58:16.739615  2305 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0929 17:58:30.985079  2305 solver.cpp:218] Iteration 82900 (7.0198 iter/s, 14.2454s/100 iters), loss = 0.000448027
I0929 17:58:30.985108  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000447362 (* 1 = 0.000447362 loss)
I0929 17:58:30.985113  2305 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0929 17:58:44.509922  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:58:45.077978  2305 solver.cpp:330] Iteration 83000, Testing net (#0)
I0929 17:58:48.432065  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:58:48.570660  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9316
I0929 17:58:48.570695  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283796 (* 1 = 0.283796 loss)
I0929 17:58:48.709971  2305 solver.cpp:218] Iteration 83000 (5.64181 iter/s, 17.7248s/100 iters), loss = 0.000776984
I0929 17:58:48.710003  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000776319 (* 1 = 0.000776319 loss)
I0929 17:58:48.710011  2305 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0929 17:59:02.957473  2305 solver.cpp:218] Iteration 83100 (7.01881 iter/s, 14.2474s/100 iters), loss = 0.00532041
I0929 17:59:02.957504  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00531974 (* 1 = 0.00531974 loss)
I0929 17:59:02.957509  2305 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0929 17:59:17.207404  2305 solver.cpp:218] Iteration 83200 (7.01761 iter/s, 14.2499s/100 iters), loss = 0.00254994
I0929 17:59:17.207520  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254927 (* 1 = 0.00254927 loss)
I0929 17:59:17.207528  2305 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0929 17:59:31.442540  2305 solver.cpp:218] Iteration 83300 (7.02494 iter/s, 14.235s/100 iters), loss = 0.00106131
I0929 17:59:31.442570  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106064 (* 1 = 0.00106064 loss)
I0929 17:59:31.442576  2305 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0929 17:59:45.687569  2305 solver.cpp:218] Iteration 83400 (7.02003 iter/s, 14.245s/100 iters), loss = 0.000223062
I0929 17:59:45.687602  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000222398 (* 1 = 0.000222398 loss)
I0929 17:59:45.687609  2305 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0929 17:59:59.231314  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:59:59.798447  2305 solver.cpp:330] Iteration 83500, Testing net (#0)
I0929 18:00:03.153782  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:00:03.292362  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9322
I0929 18:00:03.292397  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283994 (* 1 = 0.283994 loss)
I0929 18:00:03.431849  2305 solver.cpp:218] Iteration 83500 (5.63564 iter/s, 17.7442s/100 iters), loss = 0.000769445
I0929 18:00:03.431880  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000768781 (* 1 = 0.000768781 loss)
I0929 18:00:03.431887  2305 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0929 18:00:17.696424  2305 solver.cpp:218] Iteration 83600 (7.01041 iter/s, 14.2645s/100 iters), loss = 0.000676498
I0929 18:00:17.696455  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000675835 (* 1 = 0.000675835 loss)
I0929 18:00:17.696462  2305 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0929 18:00:31.959969  2305 solver.cpp:218] Iteration 83700 (7.01092 iter/s, 14.2635s/100 iters), loss = 0.00218243
I0929 18:00:31.960115  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218177 (* 1 = 0.00218177 loss)
I0929 18:00:31.960139  2305 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0929 18:00:46.217156  2305 solver.cpp:218] Iteration 83800 (7.0141 iter/s, 14.257s/100 iters), loss = 0.0015165
I0929 18:00:46.217195  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151583 (* 1 = 0.00151583 loss)
I0929 18:00:46.217213  2305 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0929 18:01:00.475419  2305 solver.cpp:218] Iteration 83900 (7.01351 iter/s, 14.2582s/100 iters), loss = 7.58674e-05
I0929 18:01:00.475452  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 7.52065e-05 (* 1 = 7.52065e-05 loss)
I0929 18:01:00.475461  2305 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0929 18:01:14.029247  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:01:14.597167  2305 solver.cpp:330] Iteration 84000, Testing net (#0)
I0929 18:01:17.953519  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:01:18.092272  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9312
I0929 18:01:18.092299  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283545 (* 1 = 0.283545 loss)
I0929 18:01:18.232162  2305 solver.cpp:218] Iteration 84000 (5.63169 iter/s, 17.7567s/100 iters), loss = 0.000680576
I0929 18:01:18.232197  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000679916 (* 1 = 0.000679916 loss)
I0929 18:01:18.232205  2305 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0929 18:01:32.493453  2305 solver.cpp:218] Iteration 84100 (7.01202 iter/s, 14.2612s/100 iters), loss = 0.00126809
I0929 18:01:32.493492  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126743 (* 1 = 0.00126743 loss)
I0929 18:01:32.493501  2305 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0929 18:01:46.741984  2305 solver.cpp:218] Iteration 84200 (7.01831 iter/s, 14.2485s/100 iters), loss = 0.000834635
I0929 18:01:46.742136  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000833974 (* 1 = 0.000833974 loss)
I0929 18:01:46.742159  2305 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0929 18:02:00.985296  2305 solver.cpp:218] Iteration 84300 (7.02093 iter/s, 14.2431s/100 iters), loss = 0.00650447
I0929 18:02:00.985329  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650381 (* 1 = 0.00650381 loss)
I0929 18:02:00.985338  2305 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0929 18:02:15.237709  2305 solver.cpp:218] Iteration 84400 (7.01639 iter/s, 14.2523s/100 iters), loss = 0.000944042
I0929 18:02:15.237746  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000943377 (* 1 = 0.000943377 loss)
I0929 18:02:15.237754  2305 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0929 18:02:28.784323  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:02:29.357226  2305 solver.cpp:330] Iteration 84500, Testing net (#0)
I0929 18:02:32.712123  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:02:32.850486  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9322
I0929 18:02:32.850510  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283728 (* 1 = 0.283728 loss)
I0929 18:02:32.990195  2305 solver.cpp:218] Iteration 84500 (5.63304 iter/s, 17.7524s/100 iters), loss = 0.00104331
I0929 18:02:32.990221  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104264 (* 1 = 0.00104264 loss)
I0929 18:02:32.990227  2305 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0929 18:02:47.230878  2305 solver.cpp:218] Iteration 84600 (7.02217 iter/s, 14.2406s/100 iters), loss = 0.00201614
I0929 18:02:47.230909  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201547 (* 1 = 0.00201547 loss)
I0929 18:02:47.230916  2305 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0929 18:03:01.481045  2305 solver.cpp:218] Iteration 84700 (7.0175 iter/s, 14.2501s/100 iters), loss = 0.000937872
I0929 18:03:01.481164  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000937203 (* 1 = 0.000937203 loss)
I0929 18:03:01.481173  2305 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0929 18:03:15.733928  2305 solver.cpp:218] Iteration 84800 (7.0162 iter/s, 14.2527s/100 iters), loss = 0.00675575
I0929 18:03:15.733958  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675508 (* 1 = 0.00675508 loss)
I0929 18:03:15.733965  2305 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0929 18:03:29.984516  2305 solver.cpp:218] Iteration 84900 (7.01729 iter/s, 14.2505s/100 iters), loss = 0.00260527
I0929 18:03:29.984568  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026046 (* 1 = 0.0026046 loss)
I0929 18:03:29.984575  2305 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0929 18:03:43.518782  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:03:44.095057  2305 solver.cpp:330] Iteration 85000, Testing net (#0)
I0929 18:03:47.452610  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:03:47.590683  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9327
I0929 18:03:47.590709  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282349 (* 1 = 0.282349 loss)
I0929 18:03:47.730350  2305 solver.cpp:218] Iteration 85000 (5.63516 iter/s, 17.7457s/100 iters), loss = 0.000441163
I0929 18:03:47.730382  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000440495 (* 1 = 0.000440495 loss)
I0929 18:03:47.730389  2305 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0929 18:04:01.984446  2305 solver.cpp:218] Iteration 85100 (7.01556 iter/s, 14.254s/100 iters), loss = 0.00129663
I0929 18:04:01.984484  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129597 (* 1 = 0.00129597 loss)
I0929 18:04:01.984501  2305 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0929 18:04:16.225060  2305 solver.cpp:218] Iteration 85200 (7.02222 iter/s, 14.2405s/100 iters), loss = 0.00111637
I0929 18:04:16.225172  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011157 (* 1 = 0.0011157 loss)
I0929 18:04:16.225190  2305 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0929 18:04:30.474267  2305 solver.cpp:218] Iteration 85300 (7.018 iter/s, 14.2491s/100 iters), loss = 0.00150704
I0929 18:04:30.474297  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150638 (* 1 = 0.00150638 loss)
I0929 18:04:30.474303  2305 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0929 18:04:44.732775  2305 solver.cpp:218] Iteration 85400 (7.01339 iter/s, 14.2584s/100 iters), loss = 0.000782421
I0929 18:04:44.732810  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000781753 (* 1 = 0.000781753 loss)
I0929 18:04:44.732820  2305 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0929 18:04:58.276036  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:04:58.847002  2305 solver.cpp:330] Iteration 85500, Testing net (#0)
I0929 18:05:02.206960  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:05:02.345450  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9323
I0929 18:05:02.345476  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282377 (* 1 = 0.282377 loss)
I0929 18:05:02.484890  2305 solver.cpp:218] Iteration 85500 (5.63316 iter/s, 17.752s/100 iters), loss = 0.000699625
I0929 18:05:02.484925  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000698957 (* 1 = 0.000698957 loss)
I0929 18:05:02.484932  2305 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0929 18:05:16.717993  2305 solver.cpp:218] Iteration 85600 (7.02591 iter/s, 14.233s/100 iters), loss = 0.00119245
I0929 18:05:16.718025  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119178 (* 1 = 0.00119178 loss)
I0929 18:05:16.718031  2305 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0929 18:05:30.966148  2305 solver.cpp:218] Iteration 85700 (7.01849 iter/s, 14.2481s/100 iters), loss = 0.000638627
I0929 18:05:30.966279  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000637959 (* 1 = 0.000637959 loss)
I0929 18:05:30.966286  2305 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0929 18:05:45.212802  2305 solver.cpp:218] Iteration 85800 (7.01928 iter/s, 14.2465s/100 iters), loss = 0.00516448
I0929 18:05:45.212832  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00516381 (* 1 = 0.00516381 loss)
I0929 18:05:45.212838  2305 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0929 18:05:59.452853  2305 solver.cpp:218] Iteration 85900 (7.02248 iter/s, 14.24s/100 iters), loss = 0.00597858
I0929 18:05:59.452885  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597791 (* 1 = 0.00597791 loss)
I0929 18:05:59.452891  2305 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0929 18:06:12.997478  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:06:13.564297  2305 solver.cpp:330] Iteration 86000, Testing net (#0)
I0929 18:06:16.929545  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:06:17.070698  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9315
I0929 18:06:17.070724  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283481 (* 1 = 0.283481 loss)
I0929 18:06:17.211253  2305 solver.cpp:218] Iteration 86000 (5.63116 iter/s, 17.7583s/100 iters), loss = 0.000370313
I0929 18:06:17.211287  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000369639 (* 1 = 0.000369639 loss)
I0929 18:06:17.211293  2305 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0929 18:06:31.463434  2305 solver.cpp:218] Iteration 86100 (7.0165 iter/s, 14.2521s/100 iters), loss = 0.00129042
I0929 18:06:31.463464  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128974 (* 1 = 0.00128974 loss)
I0929 18:06:31.463470  2305 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0929 18:06:45.718049  2305 solver.cpp:218] Iteration 86200 (7.01531 iter/s, 14.2545s/100 iters), loss = 0.000326775
I0929 18:06:45.718159  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000326102 (* 1 = 0.000326102 loss)
I0929 18:06:45.718168  2305 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0929 18:06:59.974109  2305 solver.cpp:218] Iteration 86300 (7.01463 iter/s, 14.2559s/100 iters), loss = 0.000829773
I0929 18:06:59.974140  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000829099 (* 1 = 0.000829099 loss)
I0929 18:06:59.974146  2305 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0929 18:07:14.243389  2305 solver.cpp:218] Iteration 86400 (7.0081 iter/s, 14.2692s/100 iters), loss = 0.00209888
I0929 18:07:14.243420  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209821 (* 1 = 0.00209821 loss)
I0929 18:07:14.243427  2305 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0929 18:07:27.785908  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:07:28.352485  2305 solver.cpp:330] Iteration 86500, Testing net (#0)
I0929 18:07:31.705698  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:07:31.847635  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9327
I0929 18:07:31.847672  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281959 (* 1 = 0.281959 loss)
I0929 18:07:31.991063  2305 solver.cpp:218] Iteration 86500 (5.63457 iter/s, 17.7476s/100 iters), loss = 0.00282617
I0929 18:07:31.991101  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028255 (* 1 = 0.0028255 loss)
I0929 18:07:31.991119  2305 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0929 18:07:46.227471  2305 solver.cpp:218] Iteration 86600 (7.0243 iter/s, 14.2363s/100 iters), loss = 0.0034806
I0929 18:07:46.227501  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347993 (* 1 = 0.00347993 loss)
I0929 18:07:46.227509  2305 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0929 18:08:00.483438  2305 solver.cpp:218] Iteration 86700 (7.01464 iter/s, 14.2559s/100 iters), loss = 0.0088163
I0929 18:08:00.483598  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00881563 (* 1 = 0.00881563 loss)
I0929 18:08:00.483608  2305 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0929 18:08:14.730836  2305 solver.cpp:218] Iteration 86800 (7.01892 iter/s, 14.2472s/100 iters), loss = 0.00160905
I0929 18:08:14.730880  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160838 (* 1 = 0.00160838 loss)
I0929 18:08:14.730885  2305 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0929 18:08:28.978075  2305 solver.cpp:218] Iteration 86900 (7.01895 iter/s, 14.2472s/100 iters), loss = 0.00195301
I0929 18:08:28.978113  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195234 (* 1 = 0.00195234 loss)
I0929 18:08:28.978121  2305 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0929 18:08:42.520412  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:08:43.087949  2305 solver.cpp:330] Iteration 87000, Testing net (#0)
I0929 18:08:46.442173  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:08:46.580601  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9332
I0929 18:08:46.580636  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283132 (* 1 = 0.283132 loss)
I0929 18:08:46.720541  2305 solver.cpp:218] Iteration 87000 (5.63622 iter/s, 17.7424s/100 iters), loss = 0.00166703
I0929 18:08:46.720582  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166635 (* 1 = 0.00166635 loss)
I0929 18:08:46.720590  2305 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0929 18:09:00.966054  2305 solver.cpp:218] Iteration 87100 (7.01979 iter/s, 14.2454s/100 iters), loss = 0.000451096
I0929 18:09:00.966084  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000450424 (* 1 = 0.000450424 loss)
I0929 18:09:00.966090  2305 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0929 18:09:15.213003  2305 solver.cpp:218] Iteration 87200 (7.01908 iter/s, 14.2469s/100 iters), loss = 0.00222473
I0929 18:09:15.213119  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222406 (* 1 = 0.00222406 loss)
I0929 18:09:15.213126  2305 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0929 18:09:29.462074  2305 solver.cpp:218] Iteration 87300 (7.01807 iter/s, 14.2489s/100 iters), loss = 0.00415607
I0929 18:09:29.462106  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415539 (* 1 = 0.00415539 loss)
I0929 18:09:29.462112  2305 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0929 18:09:43.700067  2305 solver.cpp:218] Iteration 87400 (7.0235 iter/s, 14.2379s/100 iters), loss = 0.000416363
I0929 18:09:43.700098  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000415689 (* 1 = 0.000415689 loss)
I0929 18:09:43.700104  2305 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0929 18:09:57.230093  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:09:57.796149  2305 solver.cpp:330] Iteration 87500, Testing net (#0)
I0929 18:10:01.150970  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:10:01.289306  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9327
I0929 18:10:01.289341  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283497 (* 1 = 0.283497 loss)
I0929 18:10:01.429672  2305 solver.cpp:218] Iteration 87500 (5.64031 iter/s, 17.7295s/100 iters), loss = 0.000354521
I0929 18:10:01.429705  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000353846 (* 1 = 0.000353846 loss)
I0929 18:10:01.429713  2305 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0929 18:10:15.683897  2305 solver.cpp:218] Iteration 87600 (7.0155 iter/s, 14.2542s/100 iters), loss = 0.0022087
I0929 18:10:15.683940  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220803 (* 1 = 0.00220803 loss)
I0929 18:10:15.683948  2305 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0929 18:10:29.935740  2305 solver.cpp:218] Iteration 87700 (7.01668 iter/s, 14.2518s/100 iters), loss = 0.000662871
I0929 18:10:29.935860  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000662194 (* 1 = 0.000662194 loss)
I0929 18:10:29.935878  2305 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0929 18:10:44.179072  2305 solver.cpp:218] Iteration 87800 (7.02091 iter/s, 14.2432s/100 iters), loss = 0.00107747
I0929 18:10:44.179106  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107679 (* 1 = 0.00107679 loss)
I0929 18:10:44.179113  2305 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0929 18:10:58.425134  2305 solver.cpp:218] Iteration 87900 (7.01952 iter/s, 14.246s/100 iters), loss = 0.00203424
I0929 18:10:58.425174  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203356 (* 1 = 0.00203356 loss)
I0929 18:10:58.425180  2305 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0929 18:11:11.974166  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:11:12.540948  2305 solver.cpp:330] Iteration 88000, Testing net (#0)
I0929 18:11:15.899189  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:11:16.037999  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9333
I0929 18:11:16.038024  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283633 (* 1 = 0.283633 loss)
I0929 18:11:16.177484  2305 solver.cpp:218] Iteration 88000 (5.63309 iter/s, 17.7523s/100 iters), loss = 0.000349425
I0929 18:11:16.177520  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000348746 (* 1 = 0.000348746 loss)
I0929 18:11:16.177526  2305 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0929 18:11:30.418524  2305 solver.cpp:218] Iteration 88100 (7.022 iter/s, 14.241s/100 iters), loss = 0.00119857
I0929 18:11:30.418553  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119789 (* 1 = 0.00119789 loss)
I0929 18:11:30.418560  2305 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0929 18:11:44.663420  2305 solver.cpp:218] Iteration 88200 (7.02009 iter/s, 14.2448s/100 iters), loss = 0.000881735
I0929 18:11:44.663537  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000881057 (* 1 = 0.000881057 loss)
I0929 18:11:44.663545  2305 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0929 18:11:58.912827  2305 solver.cpp:218] Iteration 88300 (7.01791 iter/s, 14.2493s/100 iters), loss = 0.000581195
I0929 18:11:58.912879  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000580517 (* 1 = 0.000580517 loss)
I0929 18:11:58.912888  2305 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0929 18:12:13.156904  2305 solver.cpp:218] Iteration 88400 (7.02052 iter/s, 14.244s/100 iters), loss = 0.000468101
I0929 18:12:13.156935  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000467423 (* 1 = 0.000467423 loss)
I0929 18:12:13.156941  2305 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0929 18:12:26.693302  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:12:27.260481  2305 solver.cpp:330] Iteration 88500, Testing net (#0)
I0929 18:12:30.617343  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:12:30.756125  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9332
I0929 18:12:30.756150  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283018 (* 1 = 0.283018 loss)
I0929 18:12:30.895387  2305 solver.cpp:218] Iteration 88500 (5.63749 iter/s, 17.7384s/100 iters), loss = 0.00142468
I0929 18:12:30.895416  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001424 (* 1 = 0.001424 loss)
I0929 18:12:30.895422  2305 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0929 18:12:45.145824  2305 solver.cpp:218] Iteration 88600 (7.01736 iter/s, 14.2504s/100 iters), loss = 0.000925237
I0929 18:12:45.145858  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000924558 (* 1 = 0.000924558 loss)
I0929 18:12:45.145864  2305 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0929 18:12:59.386904  2305 solver.cpp:218] Iteration 88700 (7.02197 iter/s, 14.241s/100 iters), loss = 0.0016975
I0929 18:12:59.387030  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169683 (* 1 = 0.00169683 loss)
I0929 18:12:59.387038  2305 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0929 18:13:13.624356  2305 solver.cpp:218] Iteration 88800 (7.02381 iter/s, 14.2373s/100 iters), loss = 0.00194984
I0929 18:13:13.624398  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194917 (* 1 = 0.00194917 loss)
I0929 18:13:13.624404  2305 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0929 18:13:27.888921  2305 solver.cpp:218] Iteration 88900 (7.01042 iter/s, 14.2645s/100 iters), loss = 0.00159685
I0929 18:13:27.888955  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159617 (* 1 = 0.00159617 loss)
I0929 18:13:27.888962  2305 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0929 18:13:41.534624  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:13:42.103901  2305 solver.cpp:330] Iteration 89000, Testing net (#0)
I0929 18:13:45.468040  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:13:45.605988  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9327
I0929 18:13:45.606014  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284058 (* 1 = 0.284058 loss)
I0929 18:13:45.745414  2305 solver.cpp:218] Iteration 89000 (5.60024 iter/s, 17.8564s/100 iters), loss = 0.000620274
I0929 18:13:45.745443  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000619596 (* 1 = 0.000619596 loss)
I0929 18:13:45.745463  2305 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0929 18:14:00.025940  2305 solver.cpp:218] Iteration 89100 (7.00258 iter/s, 14.2805s/100 iters), loss = 0.00116843
I0929 18:14:00.025971  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116775 (* 1 = 0.00116775 loss)
I0929 18:14:00.025977  2305 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0929 18:14:14.277259  2305 solver.cpp:218] Iteration 89200 (7.01693 iter/s, 14.2512s/100 iters), loss = 0.000954103
I0929 18:14:14.277420  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000953426 (* 1 = 0.000953426 loss)
I0929 18:14:14.277428  2305 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0929 18:14:28.526815  2305 solver.cpp:218] Iteration 89300 (7.01786 iter/s, 14.2494s/100 iters), loss = 0.00131614
I0929 18:14:28.526850  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131547 (* 1 = 0.00131547 loss)
I0929 18:14:28.526867  2305 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0929 18:14:42.777668  2305 solver.cpp:218] Iteration 89400 (7.01716 iter/s, 14.2508s/100 iters), loss = 0.00110193
I0929 18:14:42.777698  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110125 (* 1 = 0.00110125 loss)
I0929 18:14:42.777704  2305 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0929 18:14:56.332983  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:14:56.902402  2305 solver.cpp:330] Iteration 89500, Testing net (#0)
I0929 18:15:00.265381  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:15:00.405411  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9329
I0929 18:15:00.405447  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284682 (* 1 = 0.284682 loss)
I0929 18:15:00.546368  2305 solver.cpp:218] Iteration 89500 (5.6279 iter/s, 17.7686s/100 iters), loss = 0.000664196
I0929 18:15:00.546404  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00066352 (* 1 = 0.00066352 loss)
I0929 18:15:00.546412  2305 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0929 18:15:14.809775  2305 solver.cpp:218] Iteration 89600 (7.01099 iter/s, 14.2633s/100 iters), loss = 0.00266152
I0929 18:15:14.809818  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266084 (* 1 = 0.00266084 loss)
I0929 18:15:14.809825  2305 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0929 18:15:29.063230  2305 solver.cpp:218] Iteration 89700 (7.01588 iter/s, 14.2534s/100 iters), loss = 0.00121515
I0929 18:15:29.063370  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121448 (* 1 = 0.00121448 loss)
I0929 18:15:29.063390  2305 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0929 18:15:43.311590  2305 solver.cpp:218] Iteration 89800 (7.01845 iter/s, 14.2482s/100 iters), loss = 0.0010452
I0929 18:15:43.311620  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104452 (* 1 = 0.00104452 loss)
I0929 18:15:43.311626  2305 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0929 18:15:57.579280  2305 solver.cpp:218] Iteration 89900 (7.00888 iter/s, 14.2676s/100 iters), loss = 0.00181931
I0929 18:15:57.579311  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181863 (* 1 = 0.00181863 loss)
I0929 18:15:57.579318  2305 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0929 18:16:11.129494  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:16:11.700295  2305 solver.cpp:330] Iteration 90000, Testing net (#0)
I0929 18:16:15.059307  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:16:15.198930  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9328
I0929 18:16:15.198957  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284162 (* 1 = 0.284162 loss)
I0929 18:16:15.340625  2305 solver.cpp:218] Iteration 90000 (5.63023 iter/s, 17.7613s/100 iters), loss = 0.00127698
I0929 18:16:15.340658  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127631 (* 1 = 0.00127631 loss)
I0929 18:16:15.340668  2305 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0929 18:16:29.595155  2305 solver.cpp:218] Iteration 90100 (7.01535 iter/s, 14.2545s/100 iters), loss = 0.00227234
I0929 18:16:29.595186  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227167 (* 1 = 0.00227167 loss)
I0929 18:16:29.595192  2305 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0929 18:16:43.853138  2305 solver.cpp:218] Iteration 90200 (7.01365 iter/s, 14.2579s/100 iters), loss = 0.000964529
I0929 18:16:43.853265  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000963855 (* 1 = 0.000963855 loss)
I0929 18:16:43.853284  2305 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0929 18:16:58.113301  2305 solver.cpp:218] Iteration 90300 (7.01264 iter/s, 14.26s/100 iters), loss = 0.00189182
I0929 18:16:58.113330  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189115 (* 1 = 0.00189115 loss)
I0929 18:16:58.113337  2305 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0929 18:17:12.367897  2305 solver.cpp:218] Iteration 90400 (7.01532 iter/s, 14.2545s/100 iters), loss = 0.00057433
I0929 18:17:12.367928  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000573657 (* 1 = 0.000573657 loss)
I0929 18:17:12.367934  2305 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0929 18:17:25.915681  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:17:26.487588  2305 solver.cpp:330] Iteration 90500, Testing net (#0)
I0929 18:17:29.846935  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:17:29.986778  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9336
I0929 18:17:29.986814  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283329 (* 1 = 0.283329 loss)
I0929 18:17:30.127949  2305 solver.cpp:218] Iteration 90500 (5.63064 iter/s, 17.76s/100 iters), loss = 0.00121063
I0929 18:17:30.127982  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120996 (* 1 = 0.00120996 loss)
I0929 18:17:30.127990  2305 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0929 18:17:44.377722  2305 solver.cpp:218] Iteration 90600 (7.01769 iter/s, 14.2497s/100 iters), loss = 0.00116731
I0929 18:17:44.377755  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116663 (* 1 = 0.00116663 loss)
I0929 18:17:44.377761  2305 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0929 18:17:58.621394  2305 solver.cpp:218] Iteration 90700 (7.0207 iter/s, 14.2436s/100 iters), loss = 0.00132852
I0929 18:17:58.621508  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132785 (* 1 = 0.00132785 loss)
I0929 18:17:58.621515  2305 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0929 18:18:12.879601  2305 solver.cpp:218] Iteration 90800 (7.01357 iter/s, 14.2581s/100 iters), loss = 0.0133545
I0929 18:18:12.879631  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133539 (* 1 = 0.0133539 loss)
I0929 18:18:12.879637  2305 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0929 18:18:27.135918  2305 solver.cpp:218] Iteration 90900 (7.01447 iter/s, 14.2562s/100 iters), loss = 0.00017547
I0929 18:18:27.135951  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000174795 (* 1 = 0.000174795 loss)
I0929 18:18:27.135958  2305 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0929 18:18:40.667786  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:18:41.244133  2305 solver.cpp:330] Iteration 91000, Testing net (#0)
I0929 18:18:44.602749  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:18:44.742879  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I0929 18:18:44.742913  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284547 (* 1 = 0.284547 loss)
I0929 18:18:44.884181  2305 solver.cpp:218] Iteration 91000 (5.63438 iter/s, 17.7482s/100 iters), loss = 0.000907188
I0929 18:18:44.884214  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000906513 (* 1 = 0.000906513 loss)
I0929 18:18:44.884222  2305 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0929 18:18:59.140209  2305 solver.cpp:218] Iteration 91100 (7.01461 iter/s, 14.256s/100 iters), loss = 0.000879499
I0929 18:18:59.140245  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000878825 (* 1 = 0.000878825 loss)
I0929 18:18:59.140252  2305 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0929 18:19:13.405138  2305 solver.cpp:218] Iteration 91200 (7.01024 iter/s, 14.2648s/100 iters), loss = 0.00212096
I0929 18:19:13.405252  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212029 (* 1 = 0.00212029 loss)
I0929 18:19:13.405259  2305 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0929 18:19:27.663811  2305 solver.cpp:218] Iteration 91300 (7.01335 iter/s, 14.2585s/100 iters), loss = 0.00373671
I0929 18:19:27.663842  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373603 (* 1 = 0.00373603 loss)
I0929 18:19:27.663848  2305 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0929 18:19:41.921514  2305 solver.cpp:218] Iteration 91400 (7.01379 iter/s, 14.2576s/100 iters), loss = 0.000815904
I0929 18:19:41.921553  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000815231 (* 1 = 0.000815231 loss)
I0929 18:19:41.921561  2305 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0929 18:19:55.469666  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:19:56.045811  2305 solver.cpp:330] Iteration 91500, Testing net (#0)
I0929 18:19:59.409588  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:19:59.549480  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9318
I0929 18:19:59.549516  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283841 (* 1 = 0.283841 loss)
I0929 18:19:59.691233  2305 solver.cpp:218] Iteration 91500 (5.62758 iter/s, 17.7696s/100 iters), loss = 0.00122806
I0929 18:19:59.691268  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122738 (* 1 = 0.00122738 loss)
I0929 18:19:59.691275  2305 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0929 18:20:13.926187  2305 solver.cpp:218] Iteration 91600 (7.025 iter/s, 14.2349s/100 iters), loss = 0.000594773
I0929 18:20:13.926232  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0005941 (* 1 = 0.0005941 loss)
I0929 18:20:13.926240  2305 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0929 18:20:28.175948  2305 solver.cpp:218] Iteration 91700 (7.01772 iter/s, 14.2496s/100 iters), loss = 0.00108288
I0929 18:20:28.176084  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108221 (* 1 = 0.00108221 loss)
I0929 18:20:28.176092  2305 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0929 18:20:42.433085  2305 solver.cpp:218] Iteration 91800 (7.01412 iter/s, 14.257s/100 iters), loss = 0.0044147
I0929 18:20:42.433117  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00441403 (* 1 = 0.00441403 loss)
I0929 18:20:42.433123  2305 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0929 18:20:56.685091  2305 solver.cpp:218] Iteration 91900 (7.01659 iter/s, 14.2519s/100 iters), loss = 0.000909168
I0929 18:20:56.685122  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000908492 (* 1 = 0.000908492 loss)
I0929 18:20:56.685128  2305 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0929 18:21:10.223706  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:21:10.791851  2305 solver.cpp:330] Iteration 92000, Testing net (#0)
I0929 18:21:14.159379  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:21:14.299392  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9323
I0929 18:21:14.299429  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283396 (* 1 = 0.283396 loss)
I0929 18:21:14.440119  2305 solver.cpp:218] Iteration 92000 (5.63223 iter/s, 17.755s/100 iters), loss = 0.000831301
I0929 18:21:14.440155  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000830625 (* 1 = 0.000830625 loss)
I0929 18:21:14.440161  2305 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0929 18:21:28.685976  2305 solver.cpp:218] Iteration 92100 (7.01962 iter/s, 14.2458s/100 iters), loss = 0.000765367
I0929 18:21:28.686007  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000764691 (* 1 = 0.000764691 loss)
I0929 18:21:28.686013  2305 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0929 18:21:42.950371  2305 solver.cpp:218] Iteration 92200 (7.0105 iter/s, 14.2643s/100 iters), loss = 0.00168664
I0929 18:21:42.950471  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168596 (* 1 = 0.00168596 loss)
I0929 18:21:42.950479  2305 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0929 18:21:57.197690  2305 solver.cpp:218] Iteration 92300 (7.01893 iter/s, 14.2472s/100 iters), loss = 0.00145562
I0929 18:21:57.197721  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145494 (* 1 = 0.00145494 loss)
I0929 18:21:57.197726  2305 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0929 18:22:11.457563  2305 solver.cpp:218] Iteration 92400 (7.01272 iter/s, 14.2598s/100 iters), loss = 0.000722355
I0929 18:22:11.457597  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000721678 (* 1 = 0.000721678 loss)
I0929 18:22:11.457612  2305 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0929 18:22:25.013002  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:22:25.582017  2305 solver.cpp:330] Iteration 92500, Testing net (#0)
I0929 18:22:28.948046  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:22:29.091897  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9326
I0929 18:22:29.091928  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284851 (* 1 = 0.284851 loss)
I0929 18:22:29.234514  2305 solver.cpp:218] Iteration 92500 (5.62529 iter/s, 17.7769s/100 iters), loss = 0.0010324
I0929 18:22:29.234555  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103172 (* 1 = 0.00103172 loss)
I0929 18:22:29.234565  2305 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0929 18:22:43.474023  2305 solver.cpp:218] Iteration 92600 (7.02275 iter/s, 14.2394s/100 iters), loss = 0.00126927
I0929 18:22:43.474056  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012686 (* 1 = 0.0012686 loss)
I0929 18:22:43.474066  2305 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0929 18:22:57.731021  2305 solver.cpp:218] Iteration 92700 (7.01414 iter/s, 14.2569s/100 iters), loss = 0.000817989
I0929 18:22:57.731163  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000817313 (* 1 = 0.000817313 loss)
I0929 18:22:57.731174  2305 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0929 18:23:11.998054  2305 solver.cpp:218] Iteration 92800 (7.00925 iter/s, 14.2669s/100 iters), loss = 0.000412691
I0929 18:23:11.998086  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000412016 (* 1 = 0.000412016 loss)
I0929 18:23:11.998095  2305 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0929 18:23:26.251457  2305 solver.cpp:218] Iteration 92900 (7.0159 iter/s, 14.2533s/100 iters), loss = 0.00123139
I0929 18:23:26.251495  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123071 (* 1 = 0.00123071 loss)
I0929 18:23:26.251505  2305 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0929 18:23:39.793524  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:23:40.362803  2305 solver.cpp:330] Iteration 93000, Testing net (#0)
I0929 18:23:43.723867  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:23:43.864974  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9324
I0929 18:23:43.865005  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285541 (* 1 = 0.285541 loss)
I0929 18:23:44.010277  2305 solver.cpp:218] Iteration 93000 (5.63103 iter/s, 17.7587s/100 iters), loss = 0.000753397
I0929 18:23:44.010329  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000752721 (* 1 = 0.000752721 loss)
I0929 18:23:44.010349  2305 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0929 18:23:58.260608  2305 solver.cpp:218] Iteration 93100 (7.01744 iter/s, 14.2502s/100 iters), loss = 0.000524951
I0929 18:23:58.260641  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000524275 (* 1 = 0.000524275 loss)
I0929 18:23:58.260649  2305 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0929 18:24:12.522727  2305 solver.cpp:218] Iteration 93200 (7.01162 iter/s, 14.262s/100 iters), loss = 0.00121847
I0929 18:24:12.522855  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012178 (* 1 = 0.0012178 loss)
I0929 18:24:12.522877  2305 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0929 18:24:26.775686  2305 solver.cpp:218] Iteration 93300 (7.01617 iter/s, 14.2528s/100 iters), loss = 0.00135077
I0929 18:24:26.775722  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013501 (* 1 = 0.0013501 loss)
I0929 18:24:26.775732  2305 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0929 18:24:41.038298  2305 solver.cpp:218] Iteration 93400 (7.01138 iter/s, 14.2625s/100 iters), loss = 0.00058385
I0929 18:24:41.038338  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000583177 (* 1 = 0.000583177 loss)
I0929 18:24:41.038348  2305 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0929 18:24:54.584591  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:24:55.153507  2305 solver.cpp:330] Iteration 93500, Testing net (#0)
I0929 18:24:58.512954  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:24:58.652899  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9324
I0929 18:24:58.652926  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284531 (* 1 = 0.284531 loss)
I0929 18:24:58.794072  2305 solver.cpp:218] Iteration 93500 (5.632 iter/s, 17.7557s/100 iters), loss = 0.000574366
I0929 18:24:58.794109  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000573692 (* 1 = 0.000573692 loss)
I0929 18:24:58.794119  2305 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0929 18:25:13.036933  2305 solver.cpp:218] Iteration 93600 (7.0211 iter/s, 14.2428s/100 iters), loss = 0.00108267
I0929 18:25:13.036967  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108199 (* 1 = 0.00108199 loss)
I0929 18:25:13.036976  2305 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0929 18:25:27.291767  2305 solver.cpp:218] Iteration 93700 (7.0152 iter/s, 14.2548s/100 iters), loss = 0.00083392
I0929 18:25:27.291885  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000833245 (* 1 = 0.000833245 loss)
I0929 18:25:27.291906  2305 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0929 18:25:41.543177  2305 solver.cpp:218] Iteration 93800 (7.01693 iter/s, 14.2513s/100 iters), loss = 0.0047656
I0929 18:25:41.543213  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476492 (* 1 = 0.00476492 loss)
I0929 18:25:41.543220  2305 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0929 18:25:55.779548  2305 solver.cpp:218] Iteration 93900 (7.0243 iter/s, 14.2363s/100 iters), loss = 0.00103993
I0929 18:25:55.779580  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103926 (* 1 = 0.00103926 loss)
I0929 18:25:55.779587  2305 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0929 18:26:09.321900  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:26:09.889992  2305 solver.cpp:330] Iteration 94000, Testing net (#0)
I0929 18:26:13.251742  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:26:13.391616  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9324
I0929 18:26:13.391651  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.2838 (* 1 = 0.2838 loss)
I0929 18:26:13.532658  2305 solver.cpp:218] Iteration 94000 (5.63284 iter/s, 17.753s/100 iters), loss = 0.00045547
I0929 18:26:13.532691  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000454794 (* 1 = 0.000454794 loss)
I0929 18:26:13.532697  2305 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0929 18:26:27.783969  2305 solver.cpp:218] Iteration 94100 (7.01693 iter/s, 14.2512s/100 iters), loss = 0.00132289
I0929 18:26:27.784001  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132222 (* 1 = 0.00132222 loss)
I0929 18:26:27.784008  2305 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0929 18:26:42.029527  2305 solver.cpp:218] Iteration 94200 (7.01977 iter/s, 14.2455s/100 iters), loss = 0.00393297
I0929 18:26:42.029623  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039323 (* 1 = 0.0039323 loss)
I0929 18:26:42.029641  2305 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0929 18:26:56.287753  2305 solver.cpp:218] Iteration 94300 (7.01356 iter/s, 14.2581s/100 iters), loss = 0.000877779
I0929 18:26:56.287797  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000877106 (* 1 = 0.000877106 loss)
I0929 18:26:56.287804  2305 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0929 18:27:10.546962  2305 solver.cpp:218] Iteration 94400 (7.01305 iter/s, 14.2591s/100 iters), loss = 0.000491391
I0929 18:27:10.547003  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000490717 (* 1 = 0.000490717 loss)
I0929 18:27:10.547008  2305 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0929 18:27:24.104513  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:27:24.673507  2305 solver.cpp:330] Iteration 94500, Testing net (#0)
I0929 18:27:28.034080  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:27:28.174463  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9319
I0929 18:27:28.174499  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284277 (* 1 = 0.284277 loss)
I0929 18:27:28.315660  2305 solver.cpp:218] Iteration 94500 (5.6279 iter/s, 17.7686s/100 iters), loss = 0.000841928
I0929 18:27:28.315695  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000841255 (* 1 = 0.000841255 loss)
I0929 18:27:28.315701  2305 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0929 18:27:42.573570  2305 solver.cpp:218] Iteration 94600 (7.01369 iter/s, 14.2578s/100 iters), loss = 0.00132767
I0929 18:27:42.573601  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001327 (* 1 = 0.001327 loss)
I0929 18:27:42.573607  2305 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0929 18:27:56.833137  2305 solver.cpp:218] Iteration 94700 (7.01287 iter/s, 14.2595s/100 iters), loss = 0.00073484
I0929 18:27:56.833228  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000734166 (* 1 = 0.000734166 loss)
I0929 18:27:56.833252  2305 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0929 18:28:11.100586  2305 solver.cpp:218] Iteration 94800 (7.00903 iter/s, 14.2673s/100 iters), loss = 0.00364883
I0929 18:28:11.100623  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364816 (* 1 = 0.00364816 loss)
I0929 18:28:11.100631  2305 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0929 18:28:25.344302  2305 solver.cpp:218] Iteration 94900 (7.02068 iter/s, 14.2436s/100 iters), loss = 0.00110859
I0929 18:28:25.344332  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110792 (* 1 = 0.00110792 loss)
I0929 18:28:25.344338  2305 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0929 18:28:38.901399  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:28:39.469730  2305 solver.cpp:330] Iteration 95000, Testing net (#0)
I0929 18:28:42.829386  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:28:42.969125  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9323
I0929 18:28:42.969161  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284057 (* 1 = 0.284057 loss)
I0929 18:28:43.114930  2305 solver.cpp:218] Iteration 95000 (5.62729 iter/s, 17.7705s/100 iters), loss = 0.000946735
I0929 18:28:43.114962  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000946062 (* 1 = 0.000946062 loss)
I0929 18:28:43.114969  2305 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0929 18:28:57.370039  2305 solver.cpp:218] Iteration 95100 (7.01507 iter/s, 14.255s/100 iters), loss = 0.00038226
I0929 18:28:57.370079  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000381587 (* 1 = 0.000381587 loss)
I0929 18:28:57.370086  2305 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0929 18:29:11.620961  2305 solver.cpp:218] Iteration 95200 (7.01713 iter/s, 14.2508s/100 iters), loss = 0.00344109
I0929 18:29:11.621047  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344042 (* 1 = 0.00344042 loss)
I0929 18:29:11.621064  2305 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0929 18:29:25.865062  2305 solver.cpp:218] Iteration 95300 (7.02051 iter/s, 14.244s/100 iters), loss = 0.000468524
I0929 18:29:25.865097  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000467851 (* 1 = 0.000467851 loss)
I0929 18:29:25.865103  2305 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0929 18:29:40.124574  2305 solver.cpp:218] Iteration 95400 (7.0129 iter/s, 14.2594s/100 iters), loss = 0.00024003
I0929 18:29:40.124604  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000239358 (* 1 = 0.000239358 loss)
I0929 18:29:40.124610  2305 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0929 18:29:53.660675  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:29:54.229068  2305 solver.cpp:330] Iteration 95500, Testing net (#0)
I0929 18:29:57.586997  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:29:57.726861  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9323
I0929 18:29:57.726897  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284748 (* 1 = 0.284748 loss)
I0929 18:29:57.868113  2305 solver.cpp:218] Iteration 95500 (5.63588 iter/s, 17.7435s/100 iters), loss = 0.000671468
I0929 18:29:57.868144  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000670797 (* 1 = 0.000670797 loss)
I0929 18:29:57.868150  2305 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0929 18:30:12.126293  2305 solver.cpp:218] Iteration 95600 (7.01356 iter/s, 14.2581s/100 iters), loss = 0.000387824
I0929 18:30:12.126327  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000387153 (* 1 = 0.000387153 loss)
I0929 18:30:12.126333  2305 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0929 18:30:26.390198  2305 solver.cpp:218] Iteration 95700 (7.01074 iter/s, 14.2638s/100 iters), loss = 0.000484437
I0929 18:30:26.390316  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000483765 (* 1 = 0.000483765 loss)
I0929 18:30:26.390324  2305 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0929 18:30:40.642401  2305 solver.cpp:218] Iteration 95800 (7.01653 iter/s, 14.252s/100 iters), loss = 0.00127886
I0929 18:30:40.642432  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127819 (* 1 = 0.00127819 loss)
I0929 18:30:40.642438  2305 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0929 18:30:54.902681  2305 solver.cpp:218] Iteration 95900 (7.01252 iter/s, 14.2602s/100 iters), loss = 0.0010795
I0929 18:30:54.902714  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107882 (* 1 = 0.00107882 loss)
I0929 18:30:54.902734  2305 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0929 18:31:08.467279  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:31:09.036236  2305 solver.cpp:330] Iteration 96000, Testing net (#0)
I0929 18:31:12.399091  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:31:12.539454  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I0929 18:31:12.539481  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284862 (* 1 = 0.284862 loss)
I0929 18:31:12.680608  2305 solver.cpp:218] Iteration 96000 (5.62498 iter/s, 17.7778s/100 iters), loss = 0.000701404
I0929 18:31:12.680645  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000700733 (* 1 = 0.000700733 loss)
I0929 18:31:12.680655  2305 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0929 18:31:26.929890  2305 solver.cpp:218] Iteration 96100 (7.01794 iter/s, 14.2492s/100 iters), loss = 0.00308087
I0929 18:31:26.929924  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308019 (* 1 = 0.00308019 loss)
I0929 18:31:26.929931  2305 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0929 18:31:41.178683  2305 solver.cpp:218] Iteration 96200 (7.01817 iter/s, 14.2487s/100 iters), loss = 0.00124689
I0929 18:31:41.178802  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124622 (* 1 = 0.00124622 loss)
I0929 18:31:41.178822  2305 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0929 18:31:55.424182  2305 solver.cpp:218] Iteration 96300 (7.01983 iter/s, 14.2453s/100 iters), loss = 0.000322957
I0929 18:31:55.424212  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000322283 (* 1 = 0.000322283 loss)
I0929 18:31:55.424219  2305 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0929 18:32:09.678894  2305 solver.cpp:218] Iteration 96400 (7.01526 iter/s, 14.2546s/100 iters), loss = 0.000236241
I0929 18:32:09.678925  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000235569 (* 1 = 0.000235569 loss)
I0929 18:32:09.678931  2305 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0929 18:32:23.224370  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:32:23.794580  2305 solver.cpp:330] Iteration 96500, Testing net (#0)
I0929 18:32:27.156224  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:32:27.296286  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9327
I0929 18:32:27.296320  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284116 (* 1 = 0.284116 loss)
I0929 18:32:27.436394  2305 solver.cpp:218] Iteration 96500 (5.63145 iter/s, 17.7574s/100 iters), loss = 0.00136775
I0929 18:32:27.436427  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136708 (* 1 = 0.00136708 loss)
I0929 18:32:27.436434  2305 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0929 18:32:41.695848  2305 solver.cpp:218] Iteration 96600 (7.01293 iter/s, 14.2594s/100 iters), loss = 0.00122659
I0929 18:32:41.695884  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122592 (* 1 = 0.00122592 loss)
I0929 18:32:41.695904  2305 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0929 18:32:55.949965  2305 solver.cpp:218] Iteration 96700 (7.01555 iter/s, 14.254s/100 iters), loss = 0.00171591
I0929 18:32:55.950127  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171524 (* 1 = 0.00171524 loss)
I0929 18:32:55.950147  2305 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0929 18:33:10.199144  2305 solver.cpp:218] Iteration 96800 (7.01805 iter/s, 14.249s/100 iters), loss = 0.00387415
I0929 18:33:10.199177  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387348 (* 1 = 0.00387348 loss)
I0929 18:33:10.199184  2305 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0929 18:33:24.462507  2305 solver.cpp:218] Iteration 96900 (7.011 iter/s, 14.2633s/100 iters), loss = 0.00178579
I0929 18:33:24.462539  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178512 (* 1 = 0.00178512 loss)
I0929 18:33:24.462546  2305 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0929 18:33:38.015241  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:33:38.589304  2305 solver.cpp:330] Iteration 97000, Testing net (#0)
I0929 18:33:41.949427  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:33:42.090000  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9325
I0929 18:33:42.090026  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28382 (* 1 = 0.28382 loss)
I0929 18:33:42.230649  2305 solver.cpp:218] Iteration 97000 (5.62808 iter/s, 17.7681s/100 iters), loss = 0.000810411
I0929 18:33:42.230684  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00080974 (* 1 = 0.00080974 loss)
I0929 18:33:42.230690  2305 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0929 18:33:56.485213  2305 solver.cpp:218] Iteration 97100 (7.01533 iter/s, 14.2545s/100 iters), loss = 0.0016898
I0929 18:33:56.485246  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168913 (* 1 = 0.00168913 loss)
I0929 18:33:56.485254  2305 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0929 18:34:10.740869  2305 solver.cpp:218] Iteration 97200 (7.0148 iter/s, 14.2556s/100 iters), loss = 0.00294994
I0929 18:34:10.740991  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294927 (* 1 = 0.00294927 loss)
I0929 18:34:10.741010  2305 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0929 18:34:25.008716  2305 solver.cpp:218] Iteration 97300 (7.00884 iter/s, 14.2677s/100 iters), loss = 0.0012981
I0929 18:34:25.008747  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129743 (* 1 = 0.00129743 loss)
I0929 18:34:25.008754  2305 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0929 18:34:39.268584  2305 solver.cpp:218] Iteration 97400 (7.01272 iter/s, 14.2598s/100 iters), loss = 0.000415189
I0929 18:34:39.268625  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000414519 (* 1 = 0.000414519 loss)
I0929 18:34:39.268630  2305 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0929 18:34:52.813199  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:34:53.393292  2305 solver.cpp:330] Iteration 97500, Testing net (#0)
I0929 18:34:56.755239  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:34:56.894592  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9318
I0929 18:34:56.894628  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283884 (* 1 = 0.283884 loss)
I0929 18:34:57.035938  2305 solver.cpp:218] Iteration 97500 (5.62833 iter/s, 17.7673s/100 iters), loss = 0.00109685
I0929 18:34:57.035974  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109618 (* 1 = 0.00109618 loss)
I0929 18:34:57.035979  2305 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0929 18:35:11.295914  2305 solver.cpp:218] Iteration 97600 (7.01267 iter/s, 14.2599s/100 iters), loss = 0.000365834
I0929 18:35:11.295949  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000365163 (* 1 = 0.000365163 loss)
I0929 18:35:11.295956  2305 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0929 18:35:25.538516  2305 solver.cpp:218] Iteration 97700 (7.02123 iter/s, 14.2425s/100 iters), loss = 0.000860571
I0929 18:35:25.538663  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000859899 (* 1 = 0.000859899 loss)
I0929 18:35:25.538672  2305 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0929 18:35:39.792685  2305 solver.cpp:218] Iteration 97800 (7.01558 iter/s, 14.254s/100 iters), loss = 0.000429574
I0929 18:35:39.792713  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000428902 (* 1 = 0.000428902 loss)
I0929 18:35:39.792719  2305 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0929 18:35:54.055809  2305 solver.cpp:218] Iteration 97900 (7.01112 iter/s, 14.2631s/100 iters), loss = 0.000478462
I0929 18:35:54.055843  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000477788 (* 1 = 0.000477788 loss)
I0929 18:35:54.055850  2305 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0929 18:36:07.604185  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:36:08.177888  2305 solver.cpp:330] Iteration 98000, Testing net (#0)
I0929 18:36:11.538843  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:36:11.678592  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.932
I0929 18:36:11.678627  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28358 (* 1 = 0.28358 loss)
I0929 18:36:11.819397  2305 solver.cpp:218] Iteration 98000 (5.62952 iter/s, 17.7635s/100 iters), loss = 0.000473164
I0929 18:36:11.819433  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000472491 (* 1 = 0.000472491 loss)
I0929 18:36:11.819440  2305 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0929 18:36:26.073091  2305 solver.cpp:218] Iteration 98100 (7.01577 iter/s, 14.2536s/100 iters), loss = 0.000314664
I0929 18:36:26.073137  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000313992 (* 1 = 0.000313992 loss)
I0929 18:36:26.073145  2305 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0929 18:36:40.334825  2305 solver.cpp:218] Iteration 98200 (7.01181 iter/s, 14.2617s/100 iters), loss = 0.000902742
I0929 18:36:40.334959  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000902071 (* 1 = 0.000902071 loss)
I0929 18:36:40.334967  2305 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0929 18:36:54.630941  2305 solver.cpp:218] Iteration 98300 (6.99499 iter/s, 14.2959s/100 iters), loss = 0.0011953
I0929 18:36:54.630977  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119463 (* 1 = 0.00119463 loss)
I0929 18:36:54.630983  2305 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0929 18:37:08.975533  2305 solver.cpp:218] Iteration 98400 (6.97131 iter/s, 14.3445s/100 iters), loss = 0.00157895
I0929 18:37:08.975566  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157828 (* 1 = 0.00157828 loss)
I0929 18:37:08.975584  2305 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0929 18:37:22.581684  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:37:23.170027  2305 solver.cpp:330] Iteration 98500, Testing net (#0)
I0929 18:37:26.618618  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:37:26.758306  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9324
I0929 18:37:26.758332  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283292 (* 1 = 0.283292 loss)
I0929 18:37:26.899569  2305 solver.cpp:218] Iteration 98500 (5.57913 iter/s, 17.924s/100 iters), loss = 0.00144399
I0929 18:37:26.899605  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144332 (* 1 = 0.00144332 loss)
I0929 18:37:26.899612  2305 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0929 18:37:41.252249  2305 solver.cpp:218] Iteration 98600 (6.96738 iter/s, 14.3526s/100 iters), loss = 0.000688764
I0929 18:37:41.252285  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000688091 (* 1 = 0.000688091 loss)
I0929 18:37:41.252292  2305 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0929 18:37:55.607372  2305 solver.cpp:218] Iteration 98700 (6.96619 iter/s, 14.355s/100 iters), loss = 0.00124364
I0929 18:37:55.607457  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124297 (* 1 = 0.00124297 loss)
I0929 18:37:55.607475  2305 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0929 18:38:10.007817  2305 solver.cpp:218] Iteration 98800 (6.94429 iter/s, 14.4003s/100 iters), loss = 0.00234177
I0929 18:38:10.007849  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234109 (* 1 = 0.00234109 loss)
I0929 18:38:10.007856  2305 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0929 18:38:24.397871  2305 solver.cpp:218] Iteration 98900 (6.94928 iter/s, 14.39s/100 iters), loss = 0.000416452
I0929 18:38:24.397907  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000415778 (* 1 = 0.000415778 loss)
I0929 18:38:24.397923  2305 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0929 18:38:38.076083  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:38:38.657994  2305 solver.cpp:330] Iteration 99000, Testing net (#0)
I0929 18:38:42.046111  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:38:42.185950  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9321
I0929 18:38:42.185981  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283206 (* 1 = 0.283206 loss)
I0929 18:38:42.327538  2305 solver.cpp:218] Iteration 99000 (5.57738 iter/s, 17.9296s/100 iters), loss = 0.000564109
I0929 18:38:42.327571  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000563435 (* 1 = 0.000563435 loss)
I0929 18:38:42.327577  2305 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0929 18:38:56.738122  2305 solver.cpp:218] Iteration 99100 (6.93938 iter/s, 14.4105s/100 iters), loss = 0.00091613
I0929 18:38:56.738162  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000915457 (* 1 = 0.000915457 loss)
I0929 18:38:56.738169  2305 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0929 18:39:11.144186  2305 solver.cpp:218] Iteration 99200 (6.94157 iter/s, 14.406s/100 iters), loss = 0.00170354
I0929 18:39:11.144315  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170287 (* 1 = 0.00170287 loss)
I0929 18:39:11.144325  2305 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0929 18:39:25.531674  2305 solver.cpp:218] Iteration 99300 (6.95057 iter/s, 14.3873s/100 iters), loss = 0.00190816
I0929 18:39:25.531718  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190748 (* 1 = 0.00190748 loss)
I0929 18:39:25.531723  2305 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0929 18:39:39.939162  2305 solver.cpp:218] Iteration 99400 (6.94088 iter/s, 14.4074s/100 iters), loss = 0.000784148
I0929 18:39:39.939203  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000783474 (* 1 = 0.000783474 loss)
I0929 18:39:39.939221  2305 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0929 18:39:53.634886  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:39:54.212939  2305 solver.cpp:330] Iteration 99500, Testing net (#0)
I0929 18:39:57.619206  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:39:57.759306  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9326
I0929 18:39:57.759341  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284458 (* 1 = 0.284458 loss)
I0929 18:39:57.899569  2305 solver.cpp:218] Iteration 99500 (5.56783 iter/s, 17.9603s/100 iters), loss = 0.000262537
I0929 18:39:57.899600  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000261862 (* 1 = 0.000261862 loss)
I0929 18:39:57.899606  2305 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0929 18:40:12.323918  2305 solver.cpp:218] Iteration 99600 (6.93276 iter/s, 14.4243s/100 iters), loss = 0.00165162
I0929 18:40:12.323961  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165095 (* 1 = 0.00165095 loss)
I0929 18:40:12.323966  2305 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0929 18:40:26.742411  2305 solver.cpp:218] Iteration 99700 (6.93558 iter/s, 14.4184s/100 iters), loss = 0.000864724
I0929 18:40:26.742517  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000864047 (* 1 = 0.000864047 loss)
I0929 18:40:26.742533  2305 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0929 18:40:41.132326  2305 solver.cpp:218] Iteration 99800 (6.94938 iter/s, 14.3898s/100 iters), loss = 0.0005041
I0929 18:40:41.132367  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000503424 (* 1 = 0.000503424 loss)
I0929 18:40:41.132375  2305 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0929 18:40:55.662919  2305 solver.cpp:218] Iteration 99900 (6.88207 iter/s, 14.5305s/100 iters), loss = 0.00125401
I0929 18:40:55.662964  2305 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125334 (* 1 = 0.00125334 loss)
I0929 18:40:55.662971  2305 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0929 18:41:09.483372  2316 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:41:10.070586  2305 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_2study_decay_msra_iter_100000.caffemodel
I0929 18:41:10.096621  2305 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res56_mpelu_alpha0.25_beta1_2study_decay_msra_iter_100000.solverstate
I0929 18:41:10.137491  2305 solver.cpp:310] Iteration 100000, loss = 0.00208917
I0929 18:41:10.137516  2305 solver.cpp:330] Iteration 100000, Testing net (#0)
I0929 18:41:13.559442  2317 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:41:13.704546  2305 solver.cpp:397]     Test net output #0: Accuracy1 = 0.933
I0929 18:41:13.704572  2305 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284153 (* 1 = 0.284153 loss)
I0929 18:41:13.704577  2305 solver.cpp:315] Optimization Done.
I0929 18:41:13.704579  2305 caffe.cpp:259] Optimization Done.
