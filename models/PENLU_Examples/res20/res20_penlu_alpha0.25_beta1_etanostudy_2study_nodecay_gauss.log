I1001 17:18:19.403425  5416 caffe.cpp:218] Using GPUs 0
I1001 17:18:19.429334  5416 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1001 17:18:19.663028  5416 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1001 17:18:19.663169  5416 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1001 17:18:19.664685  5416 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1001 17:18:19.664695  5416 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1001 17:18:19.664808  5416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1001 17:18:19.664855  5416 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1001 17:18:19.665313  5416 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1001 17:18:19.665609  5416 layer_factory.hpp:77] Creating layer Data1
I1001 17:18:19.665690  5416 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1001 17:18:19.665709  5416 net.cpp:84] Creating Layer Data1
I1001 17:18:19.665715  5416 net.cpp:380] Data1 -> Data1
I1001 17:18:19.665733  5416 net.cpp:380] Data1 -> Data2
I1001 17:18:19.665742  5416 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1001 17:18:19.667198  5416 data_layer.cpp:45] output data size: 100,3,28,28
I1001 17:18:19.669514  5416 net.cpp:122] Setting up Data1
I1001 17:18:19.669529  5416 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1001 17:18:19.669533  5416 net.cpp:129] Top shape: 100 (100)
I1001 17:18:19.669536  5416 net.cpp:137] Memory required for data: 941200
I1001 17:18:19.669553  5416 layer_factory.hpp:77] Creating layer Convolution1
I1001 17:18:19.669580  5416 net.cpp:84] Creating Layer Convolution1
I1001 17:18:19.669595  5416 net.cpp:406] Convolution1 <- Data1
I1001 17:18:19.669615  5416 net.cpp:380] Convolution1 -> Convolution1
I1001 17:18:19.820904  5416 net.cpp:122] Setting up Convolution1
I1001 17:18:19.820930  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.820933  5416 net.cpp:137] Memory required for data: 5958800
I1001 17:18:19.820948  5416 layer_factory.hpp:77] Creating layer BatchNorm1
I1001 17:18:19.820969  5416 net.cpp:84] Creating Layer BatchNorm1
I1001 17:18:19.820973  5416 net.cpp:406] BatchNorm1 <- Convolution1
I1001 17:18:19.820977  5416 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1001 17:18:19.821141  5416 net.cpp:122] Setting up BatchNorm1
I1001 17:18:19.821146  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.821148  5416 net.cpp:137] Memory required for data: 10976400
I1001 17:18:19.821156  5416 layer_factory.hpp:77] Creating layer Scale1
I1001 17:18:19.821166  5416 net.cpp:84] Creating Layer Scale1
I1001 17:18:19.821178  5416 net.cpp:406] Scale1 <- Convolution1
I1001 17:18:19.821182  5416 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1001 17:18:19.821249  5416 layer_factory.hpp:77] Creating layer Scale1
I1001 17:18:19.821350  5416 net.cpp:122] Setting up Scale1
I1001 17:18:19.821355  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.821358  5416 net.cpp:137] Memory required for data: 15994000
I1001 17:18:19.821362  5416 layer_factory.hpp:77] Creating layer penlu1
I1001 17:18:19.821372  5416 net.cpp:84] Creating Layer penlu1
I1001 17:18:19.821374  5416 net.cpp:406] penlu1 <- Convolution1
I1001 17:18:19.821388  5416 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1001 17:18:19.822008  5416 net.cpp:122] Setting up penlu1
I1001 17:18:19.822017  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.822021  5416 net.cpp:137] Memory required for data: 21011600
I1001 17:18:19.822027  5416 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1001 17:18:19.822036  5416 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1001 17:18:19.822047  5416 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1001 17:18:19.822052  5416 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1001 17:18:19.822068  5416 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1001 17:18:19.822103  5416 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1001 17:18:19.822109  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.822121  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.822124  5416 net.cpp:137] Memory required for data: 31046800
I1001 17:18:19.822125  5416 layer_factory.hpp:77] Creating layer Convolution2
I1001 17:18:19.822142  5416 net.cpp:84] Creating Layer Convolution2
I1001 17:18:19.822145  5416 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1001 17:18:19.822150  5416 net.cpp:380] Convolution2 -> Convolution2
I1001 17:18:19.823038  5416 net.cpp:122] Setting up Convolution2
I1001 17:18:19.823050  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.823062  5416 net.cpp:137] Memory required for data: 36064400
I1001 17:18:19.823088  5416 layer_factory.hpp:77] Creating layer BatchNorm2
I1001 17:18:19.823096  5416 net.cpp:84] Creating Layer BatchNorm2
I1001 17:18:19.823101  5416 net.cpp:406] BatchNorm2 <- Convolution2
I1001 17:18:19.823118  5416 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1001 17:18:19.823248  5416 net.cpp:122] Setting up BatchNorm2
I1001 17:18:19.823253  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.823266  5416 net.cpp:137] Memory required for data: 41082000
I1001 17:18:19.823271  5416 layer_factory.hpp:77] Creating layer Scale2
I1001 17:18:19.823276  5416 net.cpp:84] Creating Layer Scale2
I1001 17:18:19.823278  5416 net.cpp:406] Scale2 <- Convolution2
I1001 17:18:19.823293  5416 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1001 17:18:19.823351  5416 layer_factory.hpp:77] Creating layer Scale2
I1001 17:18:19.823451  5416 net.cpp:122] Setting up Scale2
I1001 17:18:19.823457  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.823459  5416 net.cpp:137] Memory required for data: 46099600
I1001 17:18:19.823465  5416 layer_factory.hpp:77] Creating layer penlu2
I1001 17:18:19.823470  5416 net.cpp:84] Creating Layer penlu2
I1001 17:18:19.823473  5416 net.cpp:406] penlu2 <- Convolution2
I1001 17:18:19.823487  5416 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1001 17:18:19.823592  5416 net.cpp:122] Setting up penlu2
I1001 17:18:19.823597  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.823601  5416 net.cpp:137] Memory required for data: 51117200
I1001 17:18:19.823604  5416 layer_factory.hpp:77] Creating layer Convolution3
I1001 17:18:19.823611  5416 net.cpp:84] Creating Layer Convolution3
I1001 17:18:19.823614  5416 net.cpp:406] Convolution3 <- Convolution2
I1001 17:18:19.823628  5416 net.cpp:380] Convolution3 -> Convolution3
I1001 17:18:19.824486  5416 net.cpp:122] Setting up Convolution3
I1001 17:18:19.824496  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.824499  5416 net.cpp:137] Memory required for data: 56134800
I1001 17:18:19.824503  5416 layer_factory.hpp:77] Creating layer BatchNorm3
I1001 17:18:19.824509  5416 net.cpp:84] Creating Layer BatchNorm3
I1001 17:18:19.824512  5416 net.cpp:406] BatchNorm3 <- Convolution3
I1001 17:18:19.824527  5416 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1001 17:18:19.824657  5416 net.cpp:122] Setting up BatchNorm3
I1001 17:18:19.824663  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.824666  5416 net.cpp:137] Memory required for data: 61152400
I1001 17:18:19.824671  5416 layer_factory.hpp:77] Creating layer Scale3
I1001 17:18:19.824674  5416 net.cpp:84] Creating Layer Scale3
I1001 17:18:19.824677  5416 net.cpp:406] Scale3 <- Convolution3
I1001 17:18:19.824681  5416 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1001 17:18:19.824739  5416 layer_factory.hpp:77] Creating layer Scale3
I1001 17:18:19.824832  5416 net.cpp:122] Setting up Scale3
I1001 17:18:19.824837  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.824839  5416 net.cpp:137] Memory required for data: 66170000
I1001 17:18:19.824843  5416 layer_factory.hpp:77] Creating layer Eltwise1
I1001 17:18:19.824848  5416 net.cpp:84] Creating Layer Eltwise1
I1001 17:18:19.824851  5416 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1001 17:18:19.824854  5416 net.cpp:406] Eltwise1 <- Convolution3
I1001 17:18:19.824867  5416 net.cpp:380] Eltwise1 -> Eltwise1
I1001 17:18:19.824897  5416 net.cpp:122] Setting up Eltwise1
I1001 17:18:19.824909  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.824913  5416 net.cpp:137] Memory required for data: 71187600
I1001 17:18:19.824914  5416 layer_factory.hpp:77] Creating layer penlu3
I1001 17:18:19.824919  5416 net.cpp:84] Creating Layer penlu3
I1001 17:18:19.824923  5416 net.cpp:406] penlu3 <- Eltwise1
I1001 17:18:19.824925  5416 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1001 17:18:19.825040  5416 net.cpp:122] Setting up penlu3
I1001 17:18:19.825045  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.825054  5416 net.cpp:137] Memory required for data: 76205200
I1001 17:18:19.825058  5416 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1001 17:18:19.825062  5416 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1001 17:18:19.825074  5416 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1001 17:18:19.825078  5416 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1001 17:18:19.825083  5416 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1001 17:18:19.825114  5416 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1001 17:18:19.825119  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.825122  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.825124  5416 net.cpp:137] Memory required for data: 86240400
I1001 17:18:19.825126  5416 layer_factory.hpp:77] Creating layer Convolution4
I1001 17:18:19.825134  5416 net.cpp:84] Creating Layer Convolution4
I1001 17:18:19.825136  5416 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1001 17:18:19.825150  5416 net.cpp:380] Convolution4 -> Convolution4
I1001 17:18:19.826001  5416 net.cpp:122] Setting up Convolution4
I1001 17:18:19.826011  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.826025  5416 net.cpp:137] Memory required for data: 91258000
I1001 17:18:19.826030  5416 layer_factory.hpp:77] Creating layer BatchNorm4
I1001 17:18:19.826035  5416 net.cpp:84] Creating Layer BatchNorm4
I1001 17:18:19.826037  5416 net.cpp:406] BatchNorm4 <- Convolution4
I1001 17:18:19.826042  5416 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1001 17:18:19.826170  5416 net.cpp:122] Setting up BatchNorm4
I1001 17:18:19.826175  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.826187  5416 net.cpp:137] Memory required for data: 96275600
I1001 17:18:19.826195  5416 layer_factory.hpp:77] Creating layer Scale4
I1001 17:18:19.826200  5416 net.cpp:84] Creating Layer Scale4
I1001 17:18:19.826202  5416 net.cpp:406] Scale4 <- Convolution4
I1001 17:18:19.826206  5416 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1001 17:18:19.826241  5416 layer_factory.hpp:77] Creating layer Scale4
I1001 17:18:19.826354  5416 net.cpp:122] Setting up Scale4
I1001 17:18:19.826359  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.826370  5416 net.cpp:137] Memory required for data: 101293200
I1001 17:18:19.826375  5416 layer_factory.hpp:77] Creating layer penlu4
I1001 17:18:19.826378  5416 net.cpp:84] Creating Layer penlu4
I1001 17:18:19.826382  5416 net.cpp:406] penlu4 <- Convolution4
I1001 17:18:19.826386  5416 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1001 17:18:19.826489  5416 net.cpp:122] Setting up penlu4
I1001 17:18:19.826494  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.826506  5416 net.cpp:137] Memory required for data: 106310800
I1001 17:18:19.826510  5416 layer_factory.hpp:77] Creating layer Convolution5
I1001 17:18:19.826517  5416 net.cpp:84] Creating Layer Convolution5
I1001 17:18:19.826524  5416 net.cpp:406] Convolution5 <- Convolution4
I1001 17:18:19.826530  5416 net.cpp:380] Convolution5 -> Convolution5
I1001 17:18:19.827401  5416 net.cpp:122] Setting up Convolution5
I1001 17:18:19.827410  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.827424  5416 net.cpp:137] Memory required for data: 111328400
I1001 17:18:19.827428  5416 layer_factory.hpp:77] Creating layer BatchNorm5
I1001 17:18:19.827445  5416 net.cpp:84] Creating Layer BatchNorm5
I1001 17:18:19.827447  5416 net.cpp:406] BatchNorm5 <- Convolution5
I1001 17:18:19.827451  5416 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1001 17:18:19.827616  5416 net.cpp:122] Setting up BatchNorm5
I1001 17:18:19.827621  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.827633  5416 net.cpp:137] Memory required for data: 116346000
I1001 17:18:19.827638  5416 layer_factory.hpp:77] Creating layer Scale5
I1001 17:18:19.827652  5416 net.cpp:84] Creating Layer Scale5
I1001 17:18:19.827656  5416 net.cpp:406] Scale5 <- Convolution5
I1001 17:18:19.827659  5416 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1001 17:18:19.827713  5416 layer_factory.hpp:77] Creating layer Scale5
I1001 17:18:19.827833  5416 net.cpp:122] Setting up Scale5
I1001 17:18:19.827838  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.827850  5416 net.cpp:137] Memory required for data: 121363600
I1001 17:18:19.827854  5416 layer_factory.hpp:77] Creating layer Eltwise2
I1001 17:18:19.827869  5416 net.cpp:84] Creating Layer Eltwise2
I1001 17:18:19.827872  5416 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1001 17:18:19.827875  5416 net.cpp:406] Eltwise2 <- Convolution5
I1001 17:18:19.827878  5416 net.cpp:380] Eltwise2 -> Eltwise2
I1001 17:18:19.827893  5416 net.cpp:122] Setting up Eltwise2
I1001 17:18:19.827908  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.827909  5416 net.cpp:137] Memory required for data: 126381200
I1001 17:18:19.827913  5416 layer_factory.hpp:77] Creating layer penlu5
I1001 17:18:19.827926  5416 net.cpp:84] Creating Layer penlu5
I1001 17:18:19.827929  5416 net.cpp:406] penlu5 <- Eltwise2
I1001 17:18:19.827941  5416 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1001 17:18:19.828070  5416 net.cpp:122] Setting up penlu5
I1001 17:18:19.828075  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.828088  5416 net.cpp:137] Memory required for data: 131398800
I1001 17:18:19.828091  5416 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1001 17:18:19.828105  5416 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1001 17:18:19.828109  5416 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1001 17:18:19.828112  5416 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1001 17:18:19.828116  5416 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1001 17:18:19.828167  5416 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1001 17:18:19.828172  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.828184  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.828186  5416 net.cpp:137] Memory required for data: 141434000
I1001 17:18:19.828189  5416 layer_factory.hpp:77] Creating layer Convolution6
I1001 17:18:19.828204  5416 net.cpp:84] Creating Layer Convolution6
I1001 17:18:19.828207  5416 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1001 17:18:19.828220  5416 net.cpp:380] Convolution6 -> Convolution6
I1001 17:18:19.829125  5416 net.cpp:122] Setting up Convolution6
I1001 17:18:19.829136  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.829140  5416 net.cpp:137] Memory required for data: 146451600
I1001 17:18:19.829144  5416 layer_factory.hpp:77] Creating layer BatchNorm6
I1001 17:18:19.829150  5416 net.cpp:84] Creating Layer BatchNorm6
I1001 17:18:19.829154  5416 net.cpp:406] BatchNorm6 <- Convolution6
I1001 17:18:19.829159  5416 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1001 17:18:19.829288  5416 net.cpp:122] Setting up BatchNorm6
I1001 17:18:19.829294  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.829298  5416 net.cpp:137] Memory required for data: 151469200
I1001 17:18:19.829303  5416 layer_factory.hpp:77] Creating layer Scale6
I1001 17:18:19.829308  5416 net.cpp:84] Creating Layer Scale6
I1001 17:18:19.829310  5416 net.cpp:406] Scale6 <- Convolution6
I1001 17:18:19.829314  5416 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1001 17:18:19.829342  5416 layer_factory.hpp:77] Creating layer Scale6
I1001 17:18:19.829418  5416 net.cpp:122] Setting up Scale6
I1001 17:18:19.829424  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.829427  5416 net.cpp:137] Memory required for data: 156486800
I1001 17:18:19.829432  5416 layer_factory.hpp:77] Creating layer penlu6
I1001 17:18:19.829439  5416 net.cpp:84] Creating Layer penlu6
I1001 17:18:19.829442  5416 net.cpp:406] penlu6 <- Convolution6
I1001 17:18:19.829447  5416 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1001 17:18:19.829551  5416 net.cpp:122] Setting up penlu6
I1001 17:18:19.829557  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.829566  5416 net.cpp:137] Memory required for data: 161504400
I1001 17:18:19.829571  5416 layer_factory.hpp:77] Creating layer Convolution7
I1001 17:18:19.829581  5416 net.cpp:84] Creating Layer Convolution7
I1001 17:18:19.829584  5416 net.cpp:406] Convolution7 <- Convolution6
I1001 17:18:19.829588  5416 net.cpp:380] Convolution7 -> Convolution7
I1001 17:18:19.830148  5416 net.cpp:122] Setting up Convolution7
I1001 17:18:19.830158  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.830162  5416 net.cpp:137] Memory required for data: 166522000
I1001 17:18:19.830166  5416 layer_factory.hpp:77] Creating layer BatchNorm7
I1001 17:18:19.830173  5416 net.cpp:84] Creating Layer BatchNorm7
I1001 17:18:19.830175  5416 net.cpp:406] BatchNorm7 <- Convolution7
I1001 17:18:19.830179  5416 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1001 17:18:19.830308  5416 net.cpp:122] Setting up BatchNorm7
I1001 17:18:19.830314  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.830317  5416 net.cpp:137] Memory required for data: 171539600
I1001 17:18:19.830327  5416 layer_factory.hpp:77] Creating layer Scale7
I1001 17:18:19.830334  5416 net.cpp:84] Creating Layer Scale7
I1001 17:18:19.830338  5416 net.cpp:406] Scale7 <- Convolution7
I1001 17:18:19.830341  5416 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1001 17:18:19.830369  5416 layer_factory.hpp:77] Creating layer Scale7
I1001 17:18:19.830444  5416 net.cpp:122] Setting up Scale7
I1001 17:18:19.830449  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.830452  5416 net.cpp:137] Memory required for data: 176557200
I1001 17:18:19.830456  5416 layer_factory.hpp:77] Creating layer Eltwise3
I1001 17:18:19.830462  5416 net.cpp:84] Creating Layer Eltwise3
I1001 17:18:19.830466  5416 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1001 17:18:19.830468  5416 net.cpp:406] Eltwise3 <- Convolution7
I1001 17:18:19.830472  5416 net.cpp:380] Eltwise3 -> Eltwise3
I1001 17:18:19.830487  5416 net.cpp:122] Setting up Eltwise3
I1001 17:18:19.830492  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.830494  5416 net.cpp:137] Memory required for data: 181574800
I1001 17:18:19.830497  5416 layer_factory.hpp:77] Creating layer penlu7
I1001 17:18:19.830503  5416 net.cpp:84] Creating Layer penlu7
I1001 17:18:19.830507  5416 net.cpp:406] penlu7 <- Eltwise3
I1001 17:18:19.830510  5416 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1001 17:18:19.830631  5416 net.cpp:122] Setting up penlu7
I1001 17:18:19.830637  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.830641  5416 net.cpp:137] Memory required for data: 186592400
I1001 17:18:19.830644  5416 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1001 17:18:19.830649  5416 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1001 17:18:19.830652  5416 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1001 17:18:19.830655  5416 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1001 17:18:19.830660  5416 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1001 17:18:19.830683  5416 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1001 17:18:19.830687  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.830691  5416 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 17:18:19.830693  5416 net.cpp:137] Memory required for data: 196627600
I1001 17:18:19.830696  5416 layer_factory.hpp:77] Creating layer Convolution8
I1001 17:18:19.830703  5416 net.cpp:84] Creating Layer Convolution8
I1001 17:18:19.830706  5416 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1001 17:18:19.830710  5416 net.cpp:380] Convolution8 -> Convolution8
I1001 17:18:19.831851  5416 net.cpp:122] Setting up Convolution8
I1001 17:18:19.831862  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.831866  5416 net.cpp:137] Memory required for data: 199136400
I1001 17:18:19.831871  5416 layer_factory.hpp:77] Creating layer BatchNorm8
I1001 17:18:19.831885  5416 net.cpp:84] Creating Layer BatchNorm8
I1001 17:18:19.831889  5416 net.cpp:406] BatchNorm8 <- Convolution8
I1001 17:18:19.831902  5416 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1001 17:18:19.832048  5416 net.cpp:122] Setting up BatchNorm8
I1001 17:18:19.832054  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.832056  5416 net.cpp:137] Memory required for data: 201645200
I1001 17:18:19.832062  5416 layer_factory.hpp:77] Creating layer Scale8
I1001 17:18:19.832067  5416 net.cpp:84] Creating Layer Scale8
I1001 17:18:19.832069  5416 net.cpp:406] Scale8 <- Convolution8
I1001 17:18:19.832073  5416 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1001 17:18:19.832099  5416 layer_factory.hpp:77] Creating layer Scale8
I1001 17:18:19.832172  5416 net.cpp:122] Setting up Scale8
I1001 17:18:19.832177  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.832180  5416 net.cpp:137] Memory required for data: 204154000
I1001 17:18:19.832183  5416 layer_factory.hpp:77] Creating layer Convolution9
I1001 17:18:19.832190  5416 net.cpp:84] Creating Layer Convolution9
I1001 17:18:19.832195  5416 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1001 17:18:19.832198  5416 net.cpp:380] Convolution9 -> Convolution9
I1001 17:18:19.833529  5416 net.cpp:122] Setting up Convolution9
I1001 17:18:19.833539  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.833554  5416 net.cpp:137] Memory required for data: 206662800
I1001 17:18:19.833559  5416 layer_factory.hpp:77] Creating layer BatchNorm9
I1001 17:18:19.833564  5416 net.cpp:84] Creating Layer BatchNorm9
I1001 17:18:19.833567  5416 net.cpp:406] BatchNorm9 <- Convolution9
I1001 17:18:19.833571  5416 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1001 17:18:19.833709  5416 net.cpp:122] Setting up BatchNorm9
I1001 17:18:19.833715  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.833717  5416 net.cpp:137] Memory required for data: 209171600
I1001 17:18:19.833722  5416 layer_factory.hpp:77] Creating layer Scale9
I1001 17:18:19.833727  5416 net.cpp:84] Creating Layer Scale9
I1001 17:18:19.833730  5416 net.cpp:406] Scale9 <- Convolution9
I1001 17:18:19.833734  5416 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1001 17:18:19.833761  5416 layer_factory.hpp:77] Creating layer Scale9
I1001 17:18:19.833837  5416 net.cpp:122] Setting up Scale9
I1001 17:18:19.833843  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.833845  5416 net.cpp:137] Memory required for data: 211680400
I1001 17:18:19.833849  5416 layer_factory.hpp:77] Creating layer penlu8
I1001 17:18:19.833855  5416 net.cpp:84] Creating Layer penlu8
I1001 17:18:19.833858  5416 net.cpp:406] penlu8 <- Convolution9
I1001 17:18:19.833863  5416 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1001 17:18:19.833971  5416 net.cpp:122] Setting up penlu8
I1001 17:18:19.833976  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.833978  5416 net.cpp:137] Memory required for data: 214189200
I1001 17:18:19.833983  5416 layer_factory.hpp:77] Creating layer Convolution10
I1001 17:18:19.833992  5416 net.cpp:84] Creating Layer Convolution10
I1001 17:18:19.833994  5416 net.cpp:406] Convolution10 <- Convolution9
I1001 17:18:19.833998  5416 net.cpp:380] Convolution10 -> Convolution10
I1001 17:18:19.835214  5416 net.cpp:122] Setting up Convolution10
I1001 17:18:19.835225  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.835228  5416 net.cpp:137] Memory required for data: 216698000
I1001 17:18:19.835232  5416 layer_factory.hpp:77] Creating layer BatchNorm10
I1001 17:18:19.835239  5416 net.cpp:84] Creating Layer BatchNorm10
I1001 17:18:19.835243  5416 net.cpp:406] BatchNorm10 <- Convolution10
I1001 17:18:19.835247  5416 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1001 17:18:19.835382  5416 net.cpp:122] Setting up BatchNorm10
I1001 17:18:19.835388  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.835391  5416 net.cpp:137] Memory required for data: 219206800
I1001 17:18:19.835407  5416 layer_factory.hpp:77] Creating layer Scale10
I1001 17:18:19.835412  5416 net.cpp:84] Creating Layer Scale10
I1001 17:18:19.835433  5416 net.cpp:406] Scale10 <- Convolution10
I1001 17:18:19.835446  5416 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1001 17:18:19.835484  5416 layer_factory.hpp:77] Creating layer Scale10
I1001 17:18:19.835575  5416 net.cpp:122] Setting up Scale10
I1001 17:18:19.835580  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.835582  5416 net.cpp:137] Memory required for data: 221715600
I1001 17:18:19.835597  5416 layer_factory.hpp:77] Creating layer Eltwise4
I1001 17:18:19.835602  5416 net.cpp:84] Creating Layer Eltwise4
I1001 17:18:19.835605  5416 net.cpp:406] Eltwise4 <- Convolution8
I1001 17:18:19.835608  5416 net.cpp:406] Eltwise4 <- Convolution10
I1001 17:18:19.835613  5416 net.cpp:380] Eltwise4 -> Eltwise4
I1001 17:18:19.835628  5416 net.cpp:122] Setting up Eltwise4
I1001 17:18:19.835633  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.835636  5416 net.cpp:137] Memory required for data: 224224400
I1001 17:18:19.835638  5416 layer_factory.hpp:77] Creating layer penlu9
I1001 17:18:19.835644  5416 net.cpp:84] Creating Layer penlu9
I1001 17:18:19.835647  5416 net.cpp:406] penlu9 <- Eltwise4
I1001 17:18:19.835651  5416 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1001 17:18:19.835753  5416 net.cpp:122] Setting up penlu9
I1001 17:18:19.835758  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.835762  5416 net.cpp:137] Memory required for data: 226733200
I1001 17:18:19.835767  5416 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1001 17:18:19.835770  5416 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1001 17:18:19.835773  5416 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1001 17:18:19.835777  5416 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1001 17:18:19.835783  5416 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1001 17:18:19.835804  5416 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1001 17:18:19.835808  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.835813  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.835815  5416 net.cpp:137] Memory required for data: 231750800
I1001 17:18:19.835817  5416 layer_factory.hpp:77] Creating layer Convolution11
I1001 17:18:19.835824  5416 net.cpp:84] Creating Layer Convolution11
I1001 17:18:19.835827  5416 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1001 17:18:19.835831  5416 net.cpp:380] Convolution11 -> Convolution11
I1001 17:18:19.836868  5416 net.cpp:122] Setting up Convolution11
I1001 17:18:19.836877  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.836881  5416 net.cpp:137] Memory required for data: 234259600
I1001 17:18:19.836885  5416 layer_factory.hpp:77] Creating layer BatchNorm11
I1001 17:18:19.836892  5416 net.cpp:84] Creating Layer BatchNorm11
I1001 17:18:19.836896  5416 net.cpp:406] BatchNorm11 <- Convolution11
I1001 17:18:19.836899  5416 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1001 17:18:19.837031  5416 net.cpp:122] Setting up BatchNorm11
I1001 17:18:19.837036  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.837039  5416 net.cpp:137] Memory required for data: 236768400
I1001 17:18:19.837045  5416 layer_factory.hpp:77] Creating layer Scale11
I1001 17:18:19.837050  5416 net.cpp:84] Creating Layer Scale11
I1001 17:18:19.837054  5416 net.cpp:406] Scale11 <- Convolution11
I1001 17:18:19.837057  5416 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1001 17:18:19.837085  5416 layer_factory.hpp:77] Creating layer Scale11
I1001 17:18:19.837162  5416 net.cpp:122] Setting up Scale11
I1001 17:18:19.837167  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.837170  5416 net.cpp:137] Memory required for data: 239277200
I1001 17:18:19.837174  5416 layer_factory.hpp:77] Creating layer penlu10
I1001 17:18:19.837180  5416 net.cpp:84] Creating Layer penlu10
I1001 17:18:19.837184  5416 net.cpp:406] penlu10 <- Convolution11
I1001 17:18:19.837188  5416 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1001 17:18:19.837291  5416 net.cpp:122] Setting up penlu10
I1001 17:18:19.837303  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.837306  5416 net.cpp:137] Memory required for data: 241786000
I1001 17:18:19.837311  5416 layer_factory.hpp:77] Creating layer Convolution12
I1001 17:18:19.837319  5416 net.cpp:84] Creating Layer Convolution12
I1001 17:18:19.837323  5416 net.cpp:406] Convolution12 <- Convolution11
I1001 17:18:19.837327  5416 net.cpp:380] Convolution12 -> Convolution12
I1001 17:18:19.838366  5416 net.cpp:122] Setting up Convolution12
I1001 17:18:19.838376  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.838380  5416 net.cpp:137] Memory required for data: 244294800
I1001 17:18:19.838385  5416 layer_factory.hpp:77] Creating layer BatchNorm12
I1001 17:18:19.838392  5416 net.cpp:84] Creating Layer BatchNorm12
I1001 17:18:19.838394  5416 net.cpp:406] BatchNorm12 <- Convolution12
I1001 17:18:19.838399  5416 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1001 17:18:19.838532  5416 net.cpp:122] Setting up BatchNorm12
I1001 17:18:19.838538  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.838542  5416 net.cpp:137] Memory required for data: 246803600
I1001 17:18:19.838547  5416 layer_factory.hpp:77] Creating layer Scale12
I1001 17:18:19.838552  5416 net.cpp:84] Creating Layer Scale12
I1001 17:18:19.838557  5416 net.cpp:406] Scale12 <- Convolution12
I1001 17:18:19.838559  5416 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1001 17:18:19.838587  5416 layer_factory.hpp:77] Creating layer Scale12
I1001 17:18:19.838661  5416 net.cpp:122] Setting up Scale12
I1001 17:18:19.838666  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.838670  5416 net.cpp:137] Memory required for data: 249312400
I1001 17:18:19.838673  5416 layer_factory.hpp:77] Creating layer Eltwise5
I1001 17:18:19.838680  5416 net.cpp:84] Creating Layer Eltwise5
I1001 17:18:19.838682  5416 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1001 17:18:19.838685  5416 net.cpp:406] Eltwise5 <- Convolution12
I1001 17:18:19.838688  5416 net.cpp:380] Eltwise5 -> Eltwise5
I1001 17:18:19.838706  5416 net.cpp:122] Setting up Eltwise5
I1001 17:18:19.838711  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.838713  5416 net.cpp:137] Memory required for data: 251821200
I1001 17:18:19.838716  5416 layer_factory.hpp:77] Creating layer penlu11
I1001 17:18:19.838721  5416 net.cpp:84] Creating Layer penlu11
I1001 17:18:19.838724  5416 net.cpp:406] penlu11 <- Eltwise5
I1001 17:18:19.838727  5416 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1001 17:18:19.838835  5416 net.cpp:122] Setting up penlu11
I1001 17:18:19.838840  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.838842  5416 net.cpp:137] Memory required for data: 254330000
I1001 17:18:19.838847  5416 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1001 17:18:19.838851  5416 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1001 17:18:19.838855  5416 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1001 17:18:19.838858  5416 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1001 17:18:19.838863  5416 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1001 17:18:19.838886  5416 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1001 17:18:19.838891  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.838896  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.838898  5416 net.cpp:137] Memory required for data: 259347600
I1001 17:18:19.838901  5416 layer_factory.hpp:77] Creating layer Convolution13
I1001 17:18:19.838907  5416 net.cpp:84] Creating Layer Convolution13
I1001 17:18:19.838910  5416 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1001 17:18:19.838914  5416 net.cpp:380] Convolution13 -> Convolution13
I1001 17:18:19.839951  5416 net.cpp:122] Setting up Convolution13
I1001 17:18:19.839962  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.839965  5416 net.cpp:137] Memory required for data: 261856400
I1001 17:18:19.839969  5416 layer_factory.hpp:77] Creating layer BatchNorm13
I1001 17:18:19.839982  5416 net.cpp:84] Creating Layer BatchNorm13
I1001 17:18:19.839987  5416 net.cpp:406] BatchNorm13 <- Convolution13
I1001 17:18:19.839992  5416 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1001 17:18:19.840121  5416 net.cpp:122] Setting up BatchNorm13
I1001 17:18:19.840127  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.840131  5416 net.cpp:137] Memory required for data: 264365200
I1001 17:18:19.840135  5416 layer_factory.hpp:77] Creating layer Scale13
I1001 17:18:19.840142  5416 net.cpp:84] Creating Layer Scale13
I1001 17:18:19.840144  5416 net.cpp:406] Scale13 <- Convolution13
I1001 17:18:19.840147  5416 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1001 17:18:19.840175  5416 layer_factory.hpp:77] Creating layer Scale13
I1001 17:18:19.840250  5416 net.cpp:122] Setting up Scale13
I1001 17:18:19.840255  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.840258  5416 net.cpp:137] Memory required for data: 266874000
I1001 17:18:19.840262  5416 layer_factory.hpp:77] Creating layer penlu12
I1001 17:18:19.840268  5416 net.cpp:84] Creating Layer penlu12
I1001 17:18:19.840271  5416 net.cpp:406] penlu12 <- Convolution13
I1001 17:18:19.840276  5416 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1001 17:18:19.840380  5416 net.cpp:122] Setting up penlu12
I1001 17:18:19.840386  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.840389  5416 net.cpp:137] Memory required for data: 269382800
I1001 17:18:19.840394  5416 layer_factory.hpp:77] Creating layer Convolution14
I1001 17:18:19.840401  5416 net.cpp:84] Creating Layer Convolution14
I1001 17:18:19.840404  5416 net.cpp:406] Convolution14 <- Convolution13
I1001 17:18:19.840409  5416 net.cpp:380] Convolution14 -> Convolution14
I1001 17:18:19.841451  5416 net.cpp:122] Setting up Convolution14
I1001 17:18:19.841461  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.841465  5416 net.cpp:137] Memory required for data: 271891600
I1001 17:18:19.841480  5416 layer_factory.hpp:77] Creating layer BatchNorm14
I1001 17:18:19.841490  5416 net.cpp:84] Creating Layer BatchNorm14
I1001 17:18:19.841493  5416 net.cpp:406] BatchNorm14 <- Convolution14
I1001 17:18:19.841497  5416 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1001 17:18:19.841627  5416 net.cpp:122] Setting up BatchNorm14
I1001 17:18:19.841632  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.841635  5416 net.cpp:137] Memory required for data: 274400400
I1001 17:18:19.841641  5416 layer_factory.hpp:77] Creating layer Scale14
I1001 17:18:19.841647  5416 net.cpp:84] Creating Layer Scale14
I1001 17:18:19.841651  5416 net.cpp:406] Scale14 <- Convolution14
I1001 17:18:19.841655  5416 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1001 17:18:19.841681  5416 layer_factory.hpp:77] Creating layer Scale14
I1001 17:18:19.841758  5416 net.cpp:122] Setting up Scale14
I1001 17:18:19.841763  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.841764  5416 net.cpp:137] Memory required for data: 276909200
I1001 17:18:19.841768  5416 layer_factory.hpp:77] Creating layer Eltwise6
I1001 17:18:19.841773  5416 net.cpp:84] Creating Layer Eltwise6
I1001 17:18:19.841775  5416 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1001 17:18:19.841778  5416 net.cpp:406] Eltwise6 <- Convolution14
I1001 17:18:19.841783  5416 net.cpp:380] Eltwise6 -> Eltwise6
I1001 17:18:19.841797  5416 net.cpp:122] Setting up Eltwise6
I1001 17:18:19.841800  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.841804  5416 net.cpp:137] Memory required for data: 279418000
I1001 17:18:19.841805  5416 layer_factory.hpp:77] Creating layer penlu13
I1001 17:18:19.841810  5416 net.cpp:84] Creating Layer penlu13
I1001 17:18:19.841814  5416 net.cpp:406] penlu13 <- Eltwise6
I1001 17:18:19.841816  5416 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1001 17:18:19.841919  5416 net.cpp:122] Setting up penlu13
I1001 17:18:19.841923  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.841926  5416 net.cpp:137] Memory required for data: 281926800
I1001 17:18:19.841936  5416 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1001 17:18:19.841940  5416 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1001 17:18:19.841943  5416 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1001 17:18:19.841955  5416 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1001 17:18:19.841960  5416 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1001 17:18:19.841984  5416 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1001 17:18:19.841989  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.841991  5416 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 17:18:19.841994  5416 net.cpp:137] Memory required for data: 286944400
I1001 17:18:19.842005  5416 layer_factory.hpp:77] Creating layer Convolution15
I1001 17:18:19.842011  5416 net.cpp:84] Creating Layer Convolution15
I1001 17:18:19.842015  5416 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1001 17:18:19.842018  5416 net.cpp:380] Convolution15 -> Convolution15
I1001 17:18:19.842912  5416 net.cpp:122] Setting up Convolution15
I1001 17:18:19.842921  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.842924  5416 net.cpp:137] Memory required for data: 288198800
I1001 17:18:19.842928  5416 layer_factory.hpp:77] Creating layer BatchNorm15
I1001 17:18:19.842934  5416 net.cpp:84] Creating Layer BatchNorm15
I1001 17:18:19.842937  5416 net.cpp:406] BatchNorm15 <- Convolution15
I1001 17:18:19.842941  5416 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1001 17:18:19.843070  5416 net.cpp:122] Setting up BatchNorm15
I1001 17:18:19.843075  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.843077  5416 net.cpp:137] Memory required for data: 289453200
I1001 17:18:19.843082  5416 layer_factory.hpp:77] Creating layer Scale15
I1001 17:18:19.843086  5416 net.cpp:84] Creating Layer Scale15
I1001 17:18:19.843089  5416 net.cpp:406] Scale15 <- Convolution15
I1001 17:18:19.843092  5416 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1001 17:18:19.843118  5416 layer_factory.hpp:77] Creating layer Scale15
I1001 17:18:19.843194  5416 net.cpp:122] Setting up Scale15
I1001 17:18:19.843197  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.843199  5416 net.cpp:137] Memory required for data: 290707600
I1001 17:18:19.843204  5416 layer_factory.hpp:77] Creating layer Convolution16
I1001 17:18:19.843211  5416 net.cpp:84] Creating Layer Convolution16
I1001 17:18:19.843214  5416 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1001 17:18:19.843219  5416 net.cpp:380] Convolution16 -> Convolution16
I1001 17:18:19.844970  5416 net.cpp:122] Setting up Convolution16
I1001 17:18:19.844980  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.844982  5416 net.cpp:137] Memory required for data: 291962000
I1001 17:18:19.844986  5416 layer_factory.hpp:77] Creating layer BatchNorm16
I1001 17:18:19.844992  5416 net.cpp:84] Creating Layer BatchNorm16
I1001 17:18:19.844995  5416 net.cpp:406] BatchNorm16 <- Convolution16
I1001 17:18:19.845000  5416 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1001 17:18:19.845127  5416 net.cpp:122] Setting up BatchNorm16
I1001 17:18:19.845132  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.845134  5416 net.cpp:137] Memory required for data: 293216400
I1001 17:18:19.845139  5416 layer_factory.hpp:77] Creating layer Scale16
I1001 17:18:19.845144  5416 net.cpp:84] Creating Layer Scale16
I1001 17:18:19.845146  5416 net.cpp:406] Scale16 <- Convolution16
I1001 17:18:19.845149  5416 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1001 17:18:19.845175  5416 layer_factory.hpp:77] Creating layer Scale16
I1001 17:18:19.845248  5416 net.cpp:122] Setting up Scale16
I1001 17:18:19.845252  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.845254  5416 net.cpp:137] Memory required for data: 294470800
I1001 17:18:19.845258  5416 layer_factory.hpp:77] Creating layer penlu14
I1001 17:18:19.845264  5416 net.cpp:84] Creating Layer penlu14
I1001 17:18:19.845273  5416 net.cpp:406] penlu14 <- Convolution16
I1001 17:18:19.845278  5416 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1001 17:18:19.845382  5416 net.cpp:122] Setting up penlu14
I1001 17:18:19.845386  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.845388  5416 net.cpp:137] Memory required for data: 295725200
I1001 17:18:19.845393  5416 layer_factory.hpp:77] Creating layer Convolution17
I1001 17:18:19.845399  5416 net.cpp:84] Creating Layer Convolution17
I1001 17:18:19.845402  5416 net.cpp:406] Convolution17 <- Convolution16
I1001 17:18:19.845407  5416 net.cpp:380] Convolution17 -> Convolution17
I1001 17:18:19.847086  5416 net.cpp:122] Setting up Convolution17
I1001 17:18:19.847097  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.847100  5416 net.cpp:137] Memory required for data: 296979600
I1001 17:18:19.847105  5416 layer_factory.hpp:77] Creating layer BatchNorm17
I1001 17:18:19.847113  5416 net.cpp:84] Creating Layer BatchNorm17
I1001 17:18:19.847117  5416 net.cpp:406] BatchNorm17 <- Convolution17
I1001 17:18:19.847121  5416 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1001 17:18:19.847259  5416 net.cpp:122] Setting up BatchNorm17
I1001 17:18:19.847265  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.847267  5416 net.cpp:137] Memory required for data: 298234000
I1001 17:18:19.847271  5416 layer_factory.hpp:77] Creating layer Scale17
I1001 17:18:19.847277  5416 net.cpp:84] Creating Layer Scale17
I1001 17:18:19.847281  5416 net.cpp:406] Scale17 <- Convolution17
I1001 17:18:19.847285  5416 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1001 17:18:19.847312  5416 layer_factory.hpp:77] Creating layer Scale17
I1001 17:18:19.847391  5416 net.cpp:122] Setting up Scale17
I1001 17:18:19.847398  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.847400  5416 net.cpp:137] Memory required for data: 299488400
I1001 17:18:19.847404  5416 layer_factory.hpp:77] Creating layer Eltwise7
I1001 17:18:19.847409  5416 net.cpp:84] Creating Layer Eltwise7
I1001 17:18:19.847414  5416 net.cpp:406] Eltwise7 <- Convolution15
I1001 17:18:19.847416  5416 net.cpp:406] Eltwise7 <- Convolution17
I1001 17:18:19.847420  5416 net.cpp:380] Eltwise7 -> Eltwise7
I1001 17:18:19.847437  5416 net.cpp:122] Setting up Eltwise7
I1001 17:18:19.847442  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.847445  5416 net.cpp:137] Memory required for data: 300742800
I1001 17:18:19.847447  5416 layer_factory.hpp:77] Creating layer penlu15
I1001 17:18:19.847453  5416 net.cpp:84] Creating Layer penlu15
I1001 17:18:19.847456  5416 net.cpp:406] penlu15 <- Eltwise7
I1001 17:18:19.847460  5416 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1001 17:18:19.847568  5416 net.cpp:122] Setting up penlu15
I1001 17:18:19.847573  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.847575  5416 net.cpp:137] Memory required for data: 301997200
I1001 17:18:19.847580  5416 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1001 17:18:19.847584  5416 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1001 17:18:19.847586  5416 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1001 17:18:19.847589  5416 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1001 17:18:19.847594  5416 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1001 17:18:19.847615  5416 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1001 17:18:19.847620  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.847622  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.847625  5416 net.cpp:137] Memory required for data: 304506000
I1001 17:18:19.847626  5416 layer_factory.hpp:77] Creating layer Convolution18
I1001 17:18:19.847632  5416 net.cpp:84] Creating Layer Convolution18
I1001 17:18:19.847635  5416 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1001 17:18:19.847640  5416 net.cpp:380] Convolution18 -> Convolution18
I1001 17:18:19.849691  5416 net.cpp:122] Setting up Convolution18
I1001 17:18:19.849702  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.849725  5416 net.cpp:137] Memory required for data: 305760400
I1001 17:18:19.849730  5416 layer_factory.hpp:77] Creating layer BatchNorm18
I1001 17:18:19.849735  5416 net.cpp:84] Creating Layer BatchNorm18
I1001 17:18:19.849740  5416 net.cpp:406] BatchNorm18 <- Convolution18
I1001 17:18:19.849743  5416 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1001 17:18:19.849884  5416 net.cpp:122] Setting up BatchNorm18
I1001 17:18:19.849889  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.849901  5416 net.cpp:137] Memory required for data: 307014800
I1001 17:18:19.849907  5416 layer_factory.hpp:77] Creating layer Scale18
I1001 17:18:19.849911  5416 net.cpp:84] Creating Layer Scale18
I1001 17:18:19.849915  5416 net.cpp:406] Scale18 <- Convolution18
I1001 17:18:19.849918  5416 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1001 17:18:19.849956  5416 layer_factory.hpp:77] Creating layer Scale18
I1001 17:18:19.850051  5416 net.cpp:122] Setting up Scale18
I1001 17:18:19.850056  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.850069  5416 net.cpp:137] Memory required for data: 308269200
I1001 17:18:19.850072  5416 layer_factory.hpp:77] Creating layer penlu16
I1001 17:18:19.850078  5416 net.cpp:84] Creating Layer penlu16
I1001 17:18:19.850080  5416 net.cpp:406] penlu16 <- Convolution18
I1001 17:18:19.850085  5416 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1001 17:18:19.850198  5416 net.cpp:122] Setting up penlu16
I1001 17:18:19.850203  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.850215  5416 net.cpp:137] Memory required for data: 309523600
I1001 17:18:19.850219  5416 layer_factory.hpp:77] Creating layer Convolution19
I1001 17:18:19.850226  5416 net.cpp:84] Creating Layer Convolution19
I1001 17:18:19.850229  5416 net.cpp:406] Convolution19 <- Convolution18
I1001 17:18:19.850234  5416 net.cpp:380] Convolution19 -> Convolution19
I1001 17:18:19.852274  5416 net.cpp:122] Setting up Convolution19
I1001 17:18:19.852284  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.852298  5416 net.cpp:137] Memory required for data: 310778000
I1001 17:18:19.852303  5416 layer_factory.hpp:77] Creating layer BatchNorm19
I1001 17:18:19.852308  5416 net.cpp:84] Creating Layer BatchNorm19
I1001 17:18:19.852310  5416 net.cpp:406] BatchNorm19 <- Convolution19
I1001 17:18:19.852315  5416 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1001 17:18:19.852460  5416 net.cpp:122] Setting up BatchNorm19
I1001 17:18:19.852465  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.852478  5416 net.cpp:137] Memory required for data: 312032400
I1001 17:18:19.852483  5416 layer_factory.hpp:77] Creating layer Scale19
I1001 17:18:19.852488  5416 net.cpp:84] Creating Layer Scale19
I1001 17:18:19.852490  5416 net.cpp:406] Scale19 <- Convolution19
I1001 17:18:19.852494  5416 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1001 17:18:19.852530  5416 layer_factory.hpp:77] Creating layer Scale19
I1001 17:18:19.852627  5416 net.cpp:122] Setting up Scale19
I1001 17:18:19.852632  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.852643  5416 net.cpp:137] Memory required for data: 313286800
I1001 17:18:19.852648  5416 layer_factory.hpp:77] Creating layer Eltwise8
I1001 17:18:19.852651  5416 net.cpp:84] Creating Layer Eltwise8
I1001 17:18:19.852654  5416 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1001 17:18:19.852658  5416 net.cpp:406] Eltwise8 <- Convolution19
I1001 17:18:19.852661  5416 net.cpp:380] Eltwise8 -> Eltwise8
I1001 17:18:19.852679  5416 net.cpp:122] Setting up Eltwise8
I1001 17:18:19.852691  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.852694  5416 net.cpp:137] Memory required for data: 314541200
I1001 17:18:19.852696  5416 layer_factory.hpp:77] Creating layer penlu17
I1001 17:18:19.852711  5416 net.cpp:84] Creating Layer penlu17
I1001 17:18:19.852713  5416 net.cpp:406] penlu17 <- Eltwise8
I1001 17:18:19.852717  5416 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1001 17:18:19.852833  5416 net.cpp:122] Setting up penlu17
I1001 17:18:19.852844  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.852856  5416 net.cpp:137] Memory required for data: 315795600
I1001 17:18:19.852861  5416 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1001 17:18:19.852865  5416 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1001 17:18:19.852867  5416 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1001 17:18:19.852871  5416 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1001 17:18:19.852875  5416 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1001 17:18:19.852908  5416 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1001 17:18:19.852913  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.852926  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.852928  5416 net.cpp:137] Memory required for data: 318304400
I1001 17:18:19.852931  5416 layer_factory.hpp:77] Creating layer Convolution20
I1001 17:18:19.852937  5416 net.cpp:84] Creating Layer Convolution20
I1001 17:18:19.852939  5416 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1001 17:18:19.852944  5416 net.cpp:380] Convolution20 -> Convolution20
I1001 17:18:19.854641  5416 net.cpp:122] Setting up Convolution20
I1001 17:18:19.854651  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.854655  5416 net.cpp:137] Memory required for data: 319558800
I1001 17:18:19.854660  5416 layer_factory.hpp:77] Creating layer BatchNorm20
I1001 17:18:19.854665  5416 net.cpp:84] Creating Layer BatchNorm20
I1001 17:18:19.854668  5416 net.cpp:406] BatchNorm20 <- Convolution20
I1001 17:18:19.854672  5416 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1001 17:18:19.854806  5416 net.cpp:122] Setting up BatchNorm20
I1001 17:18:19.854811  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.854815  5416 net.cpp:137] Memory required for data: 320813200
I1001 17:18:19.854818  5416 layer_factory.hpp:77] Creating layer Scale20
I1001 17:18:19.854823  5416 net.cpp:84] Creating Layer Scale20
I1001 17:18:19.854826  5416 net.cpp:406] Scale20 <- Convolution20
I1001 17:18:19.854832  5416 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1001 17:18:19.854859  5416 layer_factory.hpp:77] Creating layer Scale20
I1001 17:18:19.854938  5416 net.cpp:122] Setting up Scale20
I1001 17:18:19.854944  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.854946  5416 net.cpp:137] Memory required for data: 322067600
I1001 17:18:19.854950  5416 layer_factory.hpp:77] Creating layer penlu18
I1001 17:18:19.854956  5416 net.cpp:84] Creating Layer penlu18
I1001 17:18:19.854959  5416 net.cpp:406] penlu18 <- Convolution20
I1001 17:18:19.854964  5416 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1001 17:18:19.855072  5416 net.cpp:122] Setting up penlu18
I1001 17:18:19.855077  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.855079  5416 net.cpp:137] Memory required for data: 323322000
I1001 17:18:19.855083  5416 layer_factory.hpp:77] Creating layer Convolution21
I1001 17:18:19.855090  5416 net.cpp:84] Creating Layer Convolution21
I1001 17:18:19.855093  5416 net.cpp:406] Convolution21 <- Convolution20
I1001 17:18:19.855096  5416 net.cpp:380] Convolution21 -> Convolution21
I1001 17:18:19.857396  5416 net.cpp:122] Setting up Convolution21
I1001 17:18:19.857405  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.857408  5416 net.cpp:137] Memory required for data: 324576400
I1001 17:18:19.857412  5416 layer_factory.hpp:77] Creating layer BatchNorm21
I1001 17:18:19.857419  5416 net.cpp:84] Creating Layer BatchNorm21
I1001 17:18:19.857421  5416 net.cpp:406] BatchNorm21 <- Convolution21
I1001 17:18:19.857424  5416 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1001 17:18:19.857563  5416 net.cpp:122] Setting up BatchNorm21
I1001 17:18:19.857568  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.857569  5416 net.cpp:137] Memory required for data: 325830800
I1001 17:18:19.857574  5416 layer_factory.hpp:77] Creating layer Scale21
I1001 17:18:19.857578  5416 net.cpp:84] Creating Layer Scale21
I1001 17:18:19.857589  5416 net.cpp:406] Scale21 <- Convolution21
I1001 17:18:19.857591  5416 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1001 17:18:19.857620  5416 layer_factory.hpp:77] Creating layer Scale21
I1001 17:18:19.857698  5416 net.cpp:122] Setting up Scale21
I1001 17:18:19.857703  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.857705  5416 net.cpp:137] Memory required for data: 327085200
I1001 17:18:19.857709  5416 layer_factory.hpp:77] Creating layer Eltwise9
I1001 17:18:19.857714  5416 net.cpp:84] Creating Layer Eltwise9
I1001 17:18:19.857717  5416 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1001 17:18:19.857719  5416 net.cpp:406] Eltwise9 <- Convolution21
I1001 17:18:19.857722  5416 net.cpp:380] Eltwise9 -> Eltwise9
I1001 17:18:19.857739  5416 net.cpp:122] Setting up Eltwise9
I1001 17:18:19.857743  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.857744  5416 net.cpp:137] Memory required for data: 328339600
I1001 17:18:19.857748  5416 layer_factory.hpp:77] Creating layer penlu19
I1001 17:18:19.857753  5416 net.cpp:84] Creating Layer penlu19
I1001 17:18:19.857755  5416 net.cpp:406] penlu19 <- Eltwise9
I1001 17:18:19.857758  5416 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1001 17:18:19.857867  5416 net.cpp:122] Setting up penlu19
I1001 17:18:19.857872  5416 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 17:18:19.857874  5416 net.cpp:137] Memory required for data: 329594000
I1001 17:18:19.857878  5416 layer_factory.hpp:77] Creating layer Pooling1
I1001 17:18:19.857883  5416 net.cpp:84] Creating Layer Pooling1
I1001 17:18:19.857887  5416 net.cpp:406] Pooling1 <- Eltwise9
I1001 17:18:19.857889  5416 net.cpp:380] Pooling1 -> Pooling1
I1001 17:18:19.858038  5416 net.cpp:122] Setting up Pooling1
I1001 17:18:19.858044  5416 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1001 17:18:19.858047  5416 net.cpp:137] Memory required for data: 329619600
I1001 17:18:19.858049  5416 layer_factory.hpp:77] Creating layer InnerProduct1
I1001 17:18:19.858058  5416 net.cpp:84] Creating Layer InnerProduct1
I1001 17:18:19.858062  5416 net.cpp:406] InnerProduct1 <- Pooling1
I1001 17:18:19.858065  5416 net.cpp:380] InnerProduct1 -> InnerProduct1
I1001 17:18:19.858160  5416 net.cpp:122] Setting up InnerProduct1
I1001 17:18:19.858165  5416 net.cpp:129] Top shape: 100 10 (1000)
I1001 17:18:19.858166  5416 net.cpp:137] Memory required for data: 329623600
I1001 17:18:19.858170  5416 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 17:18:19.858175  5416 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1001 17:18:19.858176  5416 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1001 17:18:19.858180  5416 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1001 17:18:19.858183  5416 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1001 17:18:19.858189  5416 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 17:18:19.858721  5416 net.cpp:122] Setting up SoftmaxWithLoss1
I1001 17:18:19.858729  5416 net.cpp:129] Top shape: (1)
I1001 17:18:19.858731  5416 net.cpp:132]     with loss weight 1
I1001 17:18:19.858743  5416 net.cpp:137] Memory required for data: 329623604
I1001 17:18:19.858747  5416 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1001 17:18:19.858749  5416 net.cpp:198] InnerProduct1 needs backward computation.
I1001 17:18:19.858752  5416 net.cpp:198] Pooling1 needs backward computation.
I1001 17:18:19.858753  5416 net.cpp:198] penlu19 needs backward computation.
I1001 17:18:19.858755  5416 net.cpp:198] Eltwise9 needs backward computation.
I1001 17:18:19.858758  5416 net.cpp:198] Scale21 needs backward computation.
I1001 17:18:19.858760  5416 net.cpp:198] BatchNorm21 needs backward computation.
I1001 17:18:19.858762  5416 net.cpp:198] Convolution21 needs backward computation.
I1001 17:18:19.858764  5416 net.cpp:198] penlu18 needs backward computation.
I1001 17:18:19.858767  5416 net.cpp:198] Scale20 needs backward computation.
I1001 17:18:19.858768  5416 net.cpp:198] BatchNorm20 needs backward computation.
I1001 17:18:19.858770  5416 net.cpp:198] Convolution20 needs backward computation.
I1001 17:18:19.858779  5416 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1001 17:18:19.858783  5416 net.cpp:198] penlu17 needs backward computation.
I1001 17:18:19.858784  5416 net.cpp:198] Eltwise8 needs backward computation.
I1001 17:18:19.858786  5416 net.cpp:198] Scale19 needs backward computation.
I1001 17:18:19.858788  5416 net.cpp:198] BatchNorm19 needs backward computation.
I1001 17:18:19.858790  5416 net.cpp:198] Convolution19 needs backward computation.
I1001 17:18:19.858793  5416 net.cpp:198] penlu16 needs backward computation.
I1001 17:18:19.858795  5416 net.cpp:198] Scale18 needs backward computation.
I1001 17:18:19.858798  5416 net.cpp:198] BatchNorm18 needs backward computation.
I1001 17:18:19.858799  5416 net.cpp:198] Convolution18 needs backward computation.
I1001 17:18:19.858801  5416 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1001 17:18:19.858803  5416 net.cpp:198] penlu15 needs backward computation.
I1001 17:18:19.858805  5416 net.cpp:198] Eltwise7 needs backward computation.
I1001 17:18:19.858810  5416 net.cpp:198] Scale17 needs backward computation.
I1001 17:18:19.858814  5416 net.cpp:198] BatchNorm17 needs backward computation.
I1001 17:18:19.858815  5416 net.cpp:198] Convolution17 needs backward computation.
I1001 17:18:19.858817  5416 net.cpp:198] penlu14 needs backward computation.
I1001 17:18:19.858819  5416 net.cpp:198] Scale16 needs backward computation.
I1001 17:18:19.858821  5416 net.cpp:198] BatchNorm16 needs backward computation.
I1001 17:18:19.858824  5416 net.cpp:198] Convolution16 needs backward computation.
I1001 17:18:19.858826  5416 net.cpp:198] Scale15 needs backward computation.
I1001 17:18:19.858829  5416 net.cpp:198] BatchNorm15 needs backward computation.
I1001 17:18:19.858830  5416 net.cpp:198] Convolution15 needs backward computation.
I1001 17:18:19.858834  5416 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1001 17:18:19.858835  5416 net.cpp:198] penlu13 needs backward computation.
I1001 17:18:19.858837  5416 net.cpp:198] Eltwise6 needs backward computation.
I1001 17:18:19.858840  5416 net.cpp:198] Scale14 needs backward computation.
I1001 17:18:19.858842  5416 net.cpp:198] BatchNorm14 needs backward computation.
I1001 17:18:19.858845  5416 net.cpp:198] Convolution14 needs backward computation.
I1001 17:18:19.858847  5416 net.cpp:198] penlu12 needs backward computation.
I1001 17:18:19.858850  5416 net.cpp:198] Scale13 needs backward computation.
I1001 17:18:19.858851  5416 net.cpp:198] BatchNorm13 needs backward computation.
I1001 17:18:19.858853  5416 net.cpp:198] Convolution13 needs backward computation.
I1001 17:18:19.858856  5416 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1001 17:18:19.858858  5416 net.cpp:198] penlu11 needs backward computation.
I1001 17:18:19.858861  5416 net.cpp:198] Eltwise5 needs backward computation.
I1001 17:18:19.858863  5416 net.cpp:198] Scale12 needs backward computation.
I1001 17:18:19.858866  5416 net.cpp:198] BatchNorm12 needs backward computation.
I1001 17:18:19.858868  5416 net.cpp:198] Convolution12 needs backward computation.
I1001 17:18:19.858870  5416 net.cpp:198] penlu10 needs backward computation.
I1001 17:18:19.858872  5416 net.cpp:198] Scale11 needs backward computation.
I1001 17:18:19.858875  5416 net.cpp:198] BatchNorm11 needs backward computation.
I1001 17:18:19.858877  5416 net.cpp:198] Convolution11 needs backward computation.
I1001 17:18:19.858880  5416 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1001 17:18:19.858881  5416 net.cpp:198] penlu9 needs backward computation.
I1001 17:18:19.858885  5416 net.cpp:198] Eltwise4 needs backward computation.
I1001 17:18:19.858886  5416 net.cpp:198] Scale10 needs backward computation.
I1001 17:18:19.858888  5416 net.cpp:198] BatchNorm10 needs backward computation.
I1001 17:18:19.858891  5416 net.cpp:198] Convolution10 needs backward computation.
I1001 17:18:19.858893  5416 net.cpp:198] penlu8 needs backward computation.
I1001 17:18:19.858899  5416 net.cpp:198] Scale9 needs backward computation.
I1001 17:18:19.858901  5416 net.cpp:198] BatchNorm9 needs backward computation.
I1001 17:18:19.858903  5416 net.cpp:198] Convolution9 needs backward computation.
I1001 17:18:19.858906  5416 net.cpp:198] Scale8 needs backward computation.
I1001 17:18:19.858908  5416 net.cpp:198] BatchNorm8 needs backward computation.
I1001 17:18:19.858911  5416 net.cpp:198] Convolution8 needs backward computation.
I1001 17:18:19.858913  5416 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1001 17:18:19.858916  5416 net.cpp:198] penlu7 needs backward computation.
I1001 17:18:19.858918  5416 net.cpp:198] Eltwise3 needs backward computation.
I1001 17:18:19.858920  5416 net.cpp:198] Scale7 needs backward computation.
I1001 17:18:19.858923  5416 net.cpp:198] BatchNorm7 needs backward computation.
I1001 17:18:19.858925  5416 net.cpp:198] Convolution7 needs backward computation.
I1001 17:18:19.858927  5416 net.cpp:198] penlu6 needs backward computation.
I1001 17:18:19.858929  5416 net.cpp:198] Scale6 needs backward computation.
I1001 17:18:19.858932  5416 net.cpp:198] BatchNorm6 needs backward computation.
I1001 17:18:19.858934  5416 net.cpp:198] Convolution6 needs backward computation.
I1001 17:18:19.858937  5416 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1001 17:18:19.858939  5416 net.cpp:198] penlu5 needs backward computation.
I1001 17:18:19.858942  5416 net.cpp:198] Eltwise2 needs backward computation.
I1001 17:18:19.858944  5416 net.cpp:198] Scale5 needs backward computation.
I1001 17:18:19.858947  5416 net.cpp:198] BatchNorm5 needs backward computation.
I1001 17:18:19.858949  5416 net.cpp:198] Convolution5 needs backward computation.
I1001 17:18:19.858952  5416 net.cpp:198] penlu4 needs backward computation.
I1001 17:18:19.858953  5416 net.cpp:198] Scale4 needs backward computation.
I1001 17:18:19.858955  5416 net.cpp:198] BatchNorm4 needs backward computation.
I1001 17:18:19.858958  5416 net.cpp:198] Convolution4 needs backward computation.
I1001 17:18:19.858960  5416 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1001 17:18:19.858963  5416 net.cpp:198] penlu3 needs backward computation.
I1001 17:18:19.858965  5416 net.cpp:198] Eltwise1 needs backward computation.
I1001 17:18:19.858968  5416 net.cpp:198] Scale3 needs backward computation.
I1001 17:18:19.858970  5416 net.cpp:198] BatchNorm3 needs backward computation.
I1001 17:18:19.858973  5416 net.cpp:198] Convolution3 needs backward computation.
I1001 17:18:19.858975  5416 net.cpp:198] penlu2 needs backward computation.
I1001 17:18:19.858978  5416 net.cpp:198] Scale2 needs backward computation.
I1001 17:18:19.858979  5416 net.cpp:198] BatchNorm2 needs backward computation.
I1001 17:18:19.858983  5416 net.cpp:198] Convolution2 needs backward computation.
I1001 17:18:19.858984  5416 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1001 17:18:19.858989  5416 net.cpp:198] penlu1 needs backward computation.
I1001 17:18:19.858990  5416 net.cpp:198] Scale1 needs backward computation.
I1001 17:18:19.858992  5416 net.cpp:198] BatchNorm1 needs backward computation.
I1001 17:18:19.858994  5416 net.cpp:198] Convolution1 needs backward computation.
I1001 17:18:19.858997  5416 net.cpp:200] Data1 does not need backward computation.
I1001 17:18:19.858999  5416 net.cpp:242] This network produces output SoftmaxWithLoss1
I1001 17:18:19.859032  5416 net.cpp:255] Network initialization done.
I1001 17:18:19.860805  5416 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1001 17:18:19.860813  5416 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1001 17:18:19.860817  5416 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1001 17:18:19.860893  5416 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1001 17:18:19.861439  5416 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1001 17:18:19.861691  5416 layer_factory.hpp:77] Creating layer Data1
I1001 17:18:19.861729  5416 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1001 17:18:19.861739  5416 net.cpp:84] Creating Layer Data1
I1001 17:18:19.861744  5416 net.cpp:380] Data1 -> Data1
I1001 17:18:19.861750  5416 net.cpp:380] Data1 -> Data2
I1001 17:18:19.861755  5416 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1001 17:18:19.861870  5416 data_layer.cpp:45] output data size: 100,3,32,32
I1001 17:18:19.865725  5416 net.cpp:122] Setting up Data1
I1001 17:18:19.865743  5416 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1001 17:18:19.865749  5416 net.cpp:129] Top shape: 100 (100)
I1001 17:18:19.865751  5416 net.cpp:137] Memory required for data: 1229200
I1001 17:18:19.865756  5416 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1001 17:18:19.865766  5416 net.cpp:84] Creating Layer Data2_Data1_1_split
I1001 17:18:19.865768  5416 net.cpp:406] Data2_Data1_1_split <- Data2
I1001 17:18:19.865772  5416 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1001 17:18:19.865779  5416 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1001 17:18:19.865828  5416 net.cpp:122] Setting up Data2_Data1_1_split
I1001 17:18:19.865833  5416 net.cpp:129] Top shape: 100 (100)
I1001 17:18:19.865836  5416 net.cpp:129] Top shape: 100 (100)
I1001 17:18:19.865839  5416 net.cpp:137] Memory required for data: 1230000
I1001 17:18:19.865840  5416 layer_factory.hpp:77] Creating layer Convolution1
I1001 17:18:19.865850  5416 net.cpp:84] Creating Layer Convolution1
I1001 17:18:19.865852  5416 net.cpp:406] Convolution1 <- Data1
I1001 17:18:19.865857  5416 net.cpp:380] Convolution1 -> Convolution1
I1001 17:18:19.867002  5416 net.cpp:122] Setting up Convolution1
I1001 17:18:19.867012  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.867014  5416 net.cpp:137] Memory required for data: 7783600
I1001 17:18:19.867022  5416 layer_factory.hpp:77] Creating layer BatchNorm1
I1001 17:18:19.867028  5416 net.cpp:84] Creating Layer BatchNorm1
I1001 17:18:19.867031  5416 net.cpp:406] BatchNorm1 <- Convolution1
I1001 17:18:19.867036  5416 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1001 17:18:19.867173  5416 net.cpp:122] Setting up BatchNorm1
I1001 17:18:19.867179  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.867182  5416 net.cpp:137] Memory required for data: 14337200
I1001 17:18:19.867189  5416 layer_factory.hpp:77] Creating layer Scale1
I1001 17:18:19.867195  5416 net.cpp:84] Creating Layer Scale1
I1001 17:18:19.867197  5416 net.cpp:406] Scale1 <- Convolution1
I1001 17:18:19.867200  5416 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1001 17:18:19.867229  5416 layer_factory.hpp:77] Creating layer Scale1
I1001 17:18:19.867305  5416 net.cpp:122] Setting up Scale1
I1001 17:18:19.867311  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.867313  5416 net.cpp:137] Memory required for data: 20890800
I1001 17:18:19.867318  5416 layer_factory.hpp:77] Creating layer penlu1
I1001 17:18:19.867324  5416 net.cpp:84] Creating Layer penlu1
I1001 17:18:19.867327  5416 net.cpp:406] penlu1 <- Convolution1
I1001 17:18:19.867331  5416 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1001 17:18:19.867450  5416 net.cpp:122] Setting up penlu1
I1001 17:18:19.867455  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.867456  5416 net.cpp:137] Memory required for data: 27444400
I1001 17:18:19.867462  5416 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1001 17:18:19.867466  5416 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1001 17:18:19.867468  5416 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1001 17:18:19.867473  5416 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1001 17:18:19.867477  5416 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1001 17:18:19.867501  5416 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1001 17:18:19.867506  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.867508  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.867511  5416 net.cpp:137] Memory required for data: 40551600
I1001 17:18:19.867512  5416 layer_factory.hpp:77] Creating layer Convolution2
I1001 17:18:19.867521  5416 net.cpp:84] Creating Layer Convolution2
I1001 17:18:19.867523  5416 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1001 17:18:19.867527  5416 net.cpp:380] Convolution2 -> Convolution2
I1001 17:18:19.868136  5416 net.cpp:122] Setting up Convolution2
I1001 17:18:19.868145  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.868147  5416 net.cpp:137] Memory required for data: 47105200
I1001 17:18:19.868152  5416 layer_factory.hpp:77] Creating layer BatchNorm2
I1001 17:18:19.868157  5416 net.cpp:84] Creating Layer BatchNorm2
I1001 17:18:19.868160  5416 net.cpp:406] BatchNorm2 <- Convolution2
I1001 17:18:19.868165  5416 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1001 17:18:19.868394  5416 net.cpp:122] Setting up BatchNorm2
I1001 17:18:19.868399  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.868402  5416 net.cpp:137] Memory required for data: 53658800
I1001 17:18:19.868414  5416 layer_factory.hpp:77] Creating layer Scale2
I1001 17:18:19.868418  5416 net.cpp:84] Creating Layer Scale2
I1001 17:18:19.868422  5416 net.cpp:406] Scale2 <- Convolution2
I1001 17:18:19.868427  5416 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1001 17:18:19.868455  5416 layer_factory.hpp:77] Creating layer Scale2
I1001 17:18:19.868531  5416 net.cpp:122] Setting up Scale2
I1001 17:18:19.868535  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.868540  5416 net.cpp:137] Memory required for data: 60212400
I1001 17:18:19.868546  5416 layer_factory.hpp:77] Creating layer penlu2
I1001 17:18:19.868551  5416 net.cpp:84] Creating Layer penlu2
I1001 17:18:19.868553  5416 net.cpp:406] penlu2 <- Convolution2
I1001 17:18:19.868557  5416 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1001 17:18:19.868675  5416 net.cpp:122] Setting up penlu2
I1001 17:18:19.868680  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.868682  5416 net.cpp:137] Memory required for data: 66766000
I1001 17:18:19.868687  5416 layer_factory.hpp:77] Creating layer Convolution3
I1001 17:18:19.868695  5416 net.cpp:84] Creating Layer Convolution3
I1001 17:18:19.868697  5416 net.cpp:406] Convolution3 <- Convolution2
I1001 17:18:19.868701  5416 net.cpp:380] Convolution3 -> Convolution3
I1001 17:18:19.869757  5416 net.cpp:122] Setting up Convolution3
I1001 17:18:19.869767  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.869770  5416 net.cpp:137] Memory required for data: 73319600
I1001 17:18:19.869774  5416 layer_factory.hpp:77] Creating layer BatchNorm3
I1001 17:18:19.869781  5416 net.cpp:84] Creating Layer BatchNorm3
I1001 17:18:19.869783  5416 net.cpp:406] BatchNorm3 <- Convolution3
I1001 17:18:19.869787  5416 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1001 17:18:19.869928  5416 net.cpp:122] Setting up BatchNorm3
I1001 17:18:19.869933  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.869935  5416 net.cpp:137] Memory required for data: 79873200
I1001 17:18:19.869941  5416 layer_factory.hpp:77] Creating layer Scale3
I1001 17:18:19.869946  5416 net.cpp:84] Creating Layer Scale3
I1001 17:18:19.869952  5416 net.cpp:406] Scale3 <- Convolution3
I1001 17:18:19.869956  5416 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1001 17:18:19.869983  5416 layer_factory.hpp:77] Creating layer Scale3
I1001 17:18:19.870061  5416 net.cpp:122] Setting up Scale3
I1001 17:18:19.870066  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.870069  5416 net.cpp:137] Memory required for data: 86426800
I1001 17:18:19.870074  5416 layer_factory.hpp:77] Creating layer Eltwise1
I1001 17:18:19.870077  5416 net.cpp:84] Creating Layer Eltwise1
I1001 17:18:19.870084  5416 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1001 17:18:19.870087  5416 net.cpp:406] Eltwise1 <- Convolution3
I1001 17:18:19.870090  5416 net.cpp:380] Eltwise1 -> Eltwise1
I1001 17:18:19.870108  5416 net.cpp:122] Setting up Eltwise1
I1001 17:18:19.870112  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.870115  5416 net.cpp:137] Memory required for data: 92980400
I1001 17:18:19.870116  5416 layer_factory.hpp:77] Creating layer penlu3
I1001 17:18:19.870122  5416 net.cpp:84] Creating Layer penlu3
I1001 17:18:19.870124  5416 net.cpp:406] penlu3 <- Eltwise1
I1001 17:18:19.870131  5416 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1001 17:18:19.870249  5416 net.cpp:122] Setting up penlu3
I1001 17:18:19.870254  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.870255  5416 net.cpp:137] Memory required for data: 99534000
I1001 17:18:19.870260  5416 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1001 17:18:19.870265  5416 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1001 17:18:19.870267  5416 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1001 17:18:19.870270  5416 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1001 17:18:19.870275  5416 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1001 17:18:19.870298  5416 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1001 17:18:19.870308  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.870311  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.870313  5416 net.cpp:137] Memory required for data: 112641200
I1001 17:18:19.870316  5416 layer_factory.hpp:77] Creating layer Convolution4
I1001 17:18:19.870324  5416 net.cpp:84] Creating Layer Convolution4
I1001 17:18:19.870326  5416 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1001 17:18:19.870331  5416 net.cpp:380] Convolution4 -> Convolution4
I1001 17:18:19.871398  5416 net.cpp:122] Setting up Convolution4
I1001 17:18:19.871409  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.871412  5416 net.cpp:137] Memory required for data: 119194800
I1001 17:18:19.871417  5416 layer_factory.hpp:77] Creating layer BatchNorm4
I1001 17:18:19.871421  5416 net.cpp:84] Creating Layer BatchNorm4
I1001 17:18:19.871423  5416 net.cpp:406] BatchNorm4 <- Convolution4
I1001 17:18:19.871429  5416 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1001 17:18:19.871567  5416 net.cpp:122] Setting up BatchNorm4
I1001 17:18:19.871572  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.871573  5416 net.cpp:137] Memory required for data: 125748400
I1001 17:18:19.871580  5416 layer_factory.hpp:77] Creating layer Scale4
I1001 17:18:19.871587  5416 net.cpp:84] Creating Layer Scale4
I1001 17:18:19.871589  5416 net.cpp:406] Scale4 <- Convolution4
I1001 17:18:19.871594  5416 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1001 17:18:19.871623  5416 layer_factory.hpp:77] Creating layer Scale4
I1001 17:18:19.871700  5416 net.cpp:122] Setting up Scale4
I1001 17:18:19.871704  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.871706  5416 net.cpp:137] Memory required for data: 132302000
I1001 17:18:19.871711  5416 layer_factory.hpp:77] Creating layer penlu4
I1001 17:18:19.871716  5416 net.cpp:84] Creating Layer penlu4
I1001 17:18:19.871719  5416 net.cpp:406] penlu4 <- Convolution4
I1001 17:18:19.871723  5416 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1001 17:18:19.871840  5416 net.cpp:122] Setting up penlu4
I1001 17:18:19.871845  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.871846  5416 net.cpp:137] Memory required for data: 138855600
I1001 17:18:19.871850  5416 layer_factory.hpp:77] Creating layer Convolution5
I1001 17:18:19.871857  5416 net.cpp:84] Creating Layer Convolution5
I1001 17:18:19.871860  5416 net.cpp:406] Convolution5 <- Convolution4
I1001 17:18:19.871865  5416 net.cpp:380] Convolution5 -> Convolution5
I1001 17:18:19.873123  5416 net.cpp:122] Setting up Convolution5
I1001 17:18:19.873132  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.873136  5416 net.cpp:137] Memory required for data: 145409200
I1001 17:18:19.873141  5416 layer_factory.hpp:77] Creating layer BatchNorm5
I1001 17:18:19.873147  5416 net.cpp:84] Creating Layer BatchNorm5
I1001 17:18:19.873148  5416 net.cpp:406] BatchNorm5 <- Convolution5
I1001 17:18:19.873153  5416 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1001 17:18:19.873293  5416 net.cpp:122] Setting up BatchNorm5
I1001 17:18:19.873298  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.873301  5416 net.cpp:137] Memory required for data: 151962800
I1001 17:18:19.873306  5416 layer_factory.hpp:77] Creating layer Scale5
I1001 17:18:19.873311  5416 net.cpp:84] Creating Layer Scale5
I1001 17:18:19.873312  5416 net.cpp:406] Scale5 <- Convolution5
I1001 17:18:19.873317  5416 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1001 17:18:19.873343  5416 layer_factory.hpp:77] Creating layer Scale5
I1001 17:18:19.873425  5416 net.cpp:122] Setting up Scale5
I1001 17:18:19.873428  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.873430  5416 net.cpp:137] Memory required for data: 158516400
I1001 17:18:19.873435  5416 layer_factory.hpp:77] Creating layer Eltwise2
I1001 17:18:19.873438  5416 net.cpp:84] Creating Layer Eltwise2
I1001 17:18:19.873441  5416 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1001 17:18:19.873450  5416 net.cpp:406] Eltwise2 <- Convolution5
I1001 17:18:19.873455  5416 net.cpp:380] Eltwise2 -> Eltwise2
I1001 17:18:19.873472  5416 net.cpp:122] Setting up Eltwise2
I1001 17:18:19.873476  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.873479  5416 net.cpp:137] Memory required for data: 165070000
I1001 17:18:19.873481  5416 layer_factory.hpp:77] Creating layer penlu5
I1001 17:18:19.873486  5416 net.cpp:84] Creating Layer penlu5
I1001 17:18:19.873489  5416 net.cpp:406] penlu5 <- Eltwise2
I1001 17:18:19.873493  5416 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1001 17:18:19.873613  5416 net.cpp:122] Setting up penlu5
I1001 17:18:19.873618  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.873620  5416 net.cpp:137] Memory required for data: 171623600
I1001 17:18:19.873625  5416 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1001 17:18:19.873628  5416 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1001 17:18:19.873631  5416 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1001 17:18:19.873633  5416 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1001 17:18:19.873637  5416 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1001 17:18:19.873663  5416 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1001 17:18:19.873667  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.873670  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.873672  5416 net.cpp:137] Memory required for data: 184730800
I1001 17:18:19.873674  5416 layer_factory.hpp:77] Creating layer Convolution6
I1001 17:18:19.873682  5416 net.cpp:84] Creating Layer Convolution6
I1001 17:18:19.873684  5416 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1001 17:18:19.873688  5416 net.cpp:380] Convolution6 -> Convolution6
I1001 17:18:19.874629  5416 net.cpp:122] Setting up Convolution6
I1001 17:18:19.874637  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.874640  5416 net.cpp:137] Memory required for data: 191284400
I1001 17:18:19.874644  5416 layer_factory.hpp:77] Creating layer BatchNorm6
I1001 17:18:19.874650  5416 net.cpp:84] Creating Layer BatchNorm6
I1001 17:18:19.874652  5416 net.cpp:406] BatchNorm6 <- Convolution6
I1001 17:18:19.874656  5416 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1001 17:18:19.874796  5416 net.cpp:122] Setting up BatchNorm6
I1001 17:18:19.874801  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.874804  5416 net.cpp:137] Memory required for data: 197838000
I1001 17:18:19.874809  5416 layer_factory.hpp:77] Creating layer Scale6
I1001 17:18:19.874812  5416 net.cpp:84] Creating Layer Scale6
I1001 17:18:19.874815  5416 net.cpp:406] Scale6 <- Convolution6
I1001 17:18:19.874819  5416 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1001 17:18:19.874846  5416 layer_factory.hpp:77] Creating layer Scale6
I1001 17:18:19.874922  5416 net.cpp:122] Setting up Scale6
I1001 17:18:19.874927  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.874929  5416 net.cpp:137] Memory required for data: 204391600
I1001 17:18:19.874933  5416 layer_factory.hpp:77] Creating layer penlu6
I1001 17:18:19.874938  5416 net.cpp:84] Creating Layer penlu6
I1001 17:18:19.874941  5416 net.cpp:406] penlu6 <- Convolution6
I1001 17:18:19.874945  5416 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1001 17:18:19.875064  5416 net.cpp:122] Setting up penlu6
I1001 17:18:19.875068  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.875072  5416 net.cpp:137] Memory required for data: 210945200
I1001 17:18:19.875075  5416 layer_factory.hpp:77] Creating layer Convolution7
I1001 17:18:19.875082  5416 net.cpp:84] Creating Layer Convolution7
I1001 17:18:19.875085  5416 net.cpp:406] Convolution7 <- Convolution6
I1001 17:18:19.875089  5416 net.cpp:380] Convolution7 -> Convolution7
I1001 17:18:19.876013  5416 net.cpp:122] Setting up Convolution7
I1001 17:18:19.876020  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.876024  5416 net.cpp:137] Memory required for data: 217498800
I1001 17:18:19.876034  5416 layer_factory.hpp:77] Creating layer BatchNorm7
I1001 17:18:19.876041  5416 net.cpp:84] Creating Layer BatchNorm7
I1001 17:18:19.876044  5416 net.cpp:406] BatchNorm7 <- Convolution7
I1001 17:18:19.876049  5416 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1001 17:18:19.876188  5416 net.cpp:122] Setting up BatchNorm7
I1001 17:18:19.876194  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.876195  5416 net.cpp:137] Memory required for data: 224052400
I1001 17:18:19.876205  5416 layer_factory.hpp:77] Creating layer Scale7
I1001 17:18:19.876210  5416 net.cpp:84] Creating Layer Scale7
I1001 17:18:19.876212  5416 net.cpp:406] Scale7 <- Convolution7
I1001 17:18:19.876216  5416 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1001 17:18:19.876245  5416 layer_factory.hpp:77] Creating layer Scale7
I1001 17:18:19.876322  5416 net.cpp:122] Setting up Scale7
I1001 17:18:19.876327  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.876329  5416 net.cpp:137] Memory required for data: 230606000
I1001 17:18:19.876333  5416 layer_factory.hpp:77] Creating layer Eltwise3
I1001 17:18:19.876338  5416 net.cpp:84] Creating Layer Eltwise3
I1001 17:18:19.876340  5416 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1001 17:18:19.876343  5416 net.cpp:406] Eltwise3 <- Convolution7
I1001 17:18:19.876346  5416 net.cpp:380] Eltwise3 -> Eltwise3
I1001 17:18:19.876363  5416 net.cpp:122] Setting up Eltwise3
I1001 17:18:19.876366  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.876369  5416 net.cpp:137] Memory required for data: 237159600
I1001 17:18:19.876371  5416 layer_factory.hpp:77] Creating layer penlu7
I1001 17:18:19.876375  5416 net.cpp:84] Creating Layer penlu7
I1001 17:18:19.876379  5416 net.cpp:406] penlu7 <- Eltwise3
I1001 17:18:19.876381  5416 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1001 17:18:19.876544  5416 net.cpp:122] Setting up penlu7
I1001 17:18:19.876554  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.876559  5416 net.cpp:137] Memory required for data: 243713200
I1001 17:18:19.876566  5416 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1001 17:18:19.876574  5416 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1001 17:18:19.876587  5416 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1001 17:18:19.876592  5416 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1001 17:18:19.876598  5416 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1001 17:18:19.876633  5416 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1001 17:18:19.876638  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.876641  5416 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 17:18:19.876643  5416 net.cpp:137] Memory required for data: 256820400
I1001 17:18:19.876646  5416 layer_factory.hpp:77] Creating layer Convolution8
I1001 17:18:19.876652  5416 net.cpp:84] Creating Layer Convolution8
I1001 17:18:19.876654  5416 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1001 17:18:19.876660  5416 net.cpp:380] Convolution8 -> Convolution8
I1001 17:18:19.877578  5416 net.cpp:122] Setting up Convolution8
I1001 17:18:19.877588  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.877590  5416 net.cpp:137] Memory required for data: 260097200
I1001 17:18:19.877594  5416 layer_factory.hpp:77] Creating layer BatchNorm8
I1001 17:18:19.877599  5416 net.cpp:84] Creating Layer BatchNorm8
I1001 17:18:19.877602  5416 net.cpp:406] BatchNorm8 <- Convolution8
I1001 17:18:19.877606  5416 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1001 17:18:19.877743  5416 net.cpp:122] Setting up BatchNorm8
I1001 17:18:19.877746  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.877749  5416 net.cpp:137] Memory required for data: 263374000
I1001 17:18:19.877753  5416 layer_factory.hpp:77] Creating layer Scale8
I1001 17:18:19.879618  5416 net.cpp:84] Creating Layer Scale8
I1001 17:18:19.879629  5416 net.cpp:406] Scale8 <- Convolution8
I1001 17:18:19.879648  5416 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1001 17:18:19.879711  5416 layer_factory.hpp:77] Creating layer Scale8
I1001 17:18:19.879806  5416 net.cpp:122] Setting up Scale8
I1001 17:18:19.879812  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.879815  5416 net.cpp:137] Memory required for data: 266650800
I1001 17:18:19.879820  5416 layer_factory.hpp:77] Creating layer Convolution9
I1001 17:18:19.879828  5416 net.cpp:84] Creating Layer Convolution9
I1001 17:18:19.879832  5416 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1001 17:18:19.879837  5416 net.cpp:380] Convolution9 -> Convolution9
I1001 17:18:19.880916  5416 net.cpp:122] Setting up Convolution9
I1001 17:18:19.880935  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.880939  5416 net.cpp:137] Memory required for data: 269927600
I1001 17:18:19.880944  5416 layer_factory.hpp:77] Creating layer BatchNorm9
I1001 17:18:19.880959  5416 net.cpp:84] Creating Layer BatchNorm9
I1001 17:18:19.880962  5416 net.cpp:406] BatchNorm9 <- Convolution9
I1001 17:18:19.880967  5416 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1001 17:18:19.881127  5416 net.cpp:122] Setting up BatchNorm9
I1001 17:18:19.881132  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.881134  5416 net.cpp:137] Memory required for data: 273204400
I1001 17:18:19.881139  5416 layer_factory.hpp:77] Creating layer Scale9
I1001 17:18:19.881145  5416 net.cpp:84] Creating Layer Scale9
I1001 17:18:19.881147  5416 net.cpp:406] Scale9 <- Convolution9
I1001 17:18:19.881150  5416 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1001 17:18:19.881180  5416 layer_factory.hpp:77] Creating layer Scale9
I1001 17:18:19.881268  5416 net.cpp:122] Setting up Scale9
I1001 17:18:19.881273  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.881274  5416 net.cpp:137] Memory required for data: 276481200
I1001 17:18:19.881278  5416 layer_factory.hpp:77] Creating layer penlu8
I1001 17:18:19.881285  5416 net.cpp:84] Creating Layer penlu8
I1001 17:18:19.881287  5416 net.cpp:406] penlu8 <- Convolution9
I1001 17:18:19.881292  5416 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1001 17:18:19.881424  5416 net.cpp:122] Setting up penlu8
I1001 17:18:19.881428  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.881431  5416 net.cpp:137] Memory required for data: 279758000
I1001 17:18:19.881435  5416 layer_factory.hpp:77] Creating layer Convolution10
I1001 17:18:19.881443  5416 net.cpp:84] Creating Layer Convolution10
I1001 17:18:19.881444  5416 net.cpp:406] Convolution10 <- Convolution9
I1001 17:18:19.881449  5416 net.cpp:380] Convolution10 -> Convolution10
I1001 17:18:19.882830  5416 net.cpp:122] Setting up Convolution10
I1001 17:18:19.882839  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.882843  5416 net.cpp:137] Memory required for data: 283034800
I1001 17:18:19.882846  5416 layer_factory.hpp:77] Creating layer BatchNorm10
I1001 17:18:19.882851  5416 net.cpp:84] Creating Layer BatchNorm10
I1001 17:18:19.882854  5416 net.cpp:406] BatchNorm10 <- Convolution10
I1001 17:18:19.882858  5416 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1001 17:18:19.882992  5416 net.cpp:122] Setting up BatchNorm10
I1001 17:18:19.882997  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.882998  5416 net.cpp:137] Memory required for data: 286311600
I1001 17:18:19.883003  5416 layer_factory.hpp:77] Creating layer Scale10
I1001 17:18:19.883008  5416 net.cpp:84] Creating Layer Scale10
I1001 17:18:19.883010  5416 net.cpp:406] Scale10 <- Convolution10
I1001 17:18:19.883013  5416 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1001 17:18:19.883041  5416 layer_factory.hpp:77] Creating layer Scale10
I1001 17:18:19.883117  5416 net.cpp:122] Setting up Scale10
I1001 17:18:19.883121  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.883123  5416 net.cpp:137] Memory required for data: 289588400
I1001 17:18:19.883127  5416 layer_factory.hpp:77] Creating layer Eltwise4
I1001 17:18:19.883132  5416 net.cpp:84] Creating Layer Eltwise4
I1001 17:18:19.883142  5416 net.cpp:406] Eltwise4 <- Convolution8
I1001 17:18:19.883147  5416 net.cpp:406] Eltwise4 <- Convolution10
I1001 17:18:19.883150  5416 net.cpp:380] Eltwise4 -> Eltwise4
I1001 17:18:19.883164  5416 net.cpp:122] Setting up Eltwise4
I1001 17:18:19.883168  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.883170  5416 net.cpp:137] Memory required for data: 292865200
I1001 17:18:19.883172  5416 layer_factory.hpp:77] Creating layer penlu9
I1001 17:18:19.883178  5416 net.cpp:84] Creating Layer penlu9
I1001 17:18:19.883180  5416 net.cpp:406] penlu9 <- Eltwise4
I1001 17:18:19.883183  5416 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1001 17:18:19.883373  5416 net.cpp:122] Setting up penlu9
I1001 17:18:19.883389  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.883393  5416 net.cpp:137] Memory required for data: 296142000
I1001 17:18:19.883399  5416 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1001 17:18:19.883404  5416 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1001 17:18:19.883409  5416 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1001 17:18:19.883422  5416 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1001 17:18:19.883427  5416 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1001 17:18:19.883461  5416 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1001 17:18:19.883467  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.883471  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.883474  5416 net.cpp:137] Memory required for data: 302695600
I1001 17:18:19.883478  5416 layer_factory.hpp:77] Creating layer Convolution11
I1001 17:18:19.883486  5416 net.cpp:84] Creating Layer Convolution11
I1001 17:18:19.883491  5416 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1001 17:18:19.883496  5416 net.cpp:380] Convolution11 -> Convolution11
I1001 17:18:19.884860  5416 net.cpp:122] Setting up Convolution11
I1001 17:18:19.884868  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.884871  5416 net.cpp:137] Memory required for data: 305972400
I1001 17:18:19.884876  5416 layer_factory.hpp:77] Creating layer BatchNorm11
I1001 17:18:19.884881  5416 net.cpp:84] Creating Layer BatchNorm11
I1001 17:18:19.884883  5416 net.cpp:406] BatchNorm11 <- Convolution11
I1001 17:18:19.884887  5416 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1001 17:18:19.885025  5416 net.cpp:122] Setting up BatchNorm11
I1001 17:18:19.885030  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.885032  5416 net.cpp:137] Memory required for data: 309249200
I1001 17:18:19.885037  5416 layer_factory.hpp:77] Creating layer Scale11
I1001 17:18:19.885041  5416 net.cpp:84] Creating Layer Scale11
I1001 17:18:19.885043  5416 net.cpp:406] Scale11 <- Convolution11
I1001 17:18:19.885047  5416 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1001 17:18:19.885074  5416 layer_factory.hpp:77] Creating layer Scale11
I1001 17:18:19.885150  5416 net.cpp:122] Setting up Scale11
I1001 17:18:19.885155  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.885157  5416 net.cpp:137] Memory required for data: 312526000
I1001 17:18:19.885161  5416 layer_factory.hpp:77] Creating layer penlu10
I1001 17:18:19.885166  5416 net.cpp:84] Creating Layer penlu10
I1001 17:18:19.885169  5416 net.cpp:406] penlu10 <- Convolution11
I1001 17:18:19.885172  5416 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1001 17:18:19.885282  5416 net.cpp:122] Setting up penlu10
I1001 17:18:19.885288  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.885289  5416 net.cpp:137] Memory required for data: 315802800
I1001 17:18:19.885293  5416 layer_factory.hpp:77] Creating layer Convolution12
I1001 17:18:19.885300  5416 net.cpp:84] Creating Layer Convolution12
I1001 17:18:19.885303  5416 net.cpp:406] Convolution12 <- Convolution11
I1001 17:18:19.885308  5416 net.cpp:380] Convolution12 -> Convolution12
I1001 17:18:19.886034  5416 net.cpp:122] Setting up Convolution12
I1001 17:18:19.886049  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.886051  5416 net.cpp:137] Memory required for data: 319079600
I1001 17:18:19.886055  5416 layer_factory.hpp:77] Creating layer BatchNorm12
I1001 17:18:19.886060  5416 net.cpp:84] Creating Layer BatchNorm12
I1001 17:18:19.886062  5416 net.cpp:406] BatchNorm12 <- Convolution12
I1001 17:18:19.886066  5416 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1001 17:18:19.886204  5416 net.cpp:122] Setting up BatchNorm12
I1001 17:18:19.886209  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.886210  5416 net.cpp:137] Memory required for data: 322356400
I1001 17:18:19.886214  5416 layer_factory.hpp:77] Creating layer Scale12
I1001 17:18:19.886219  5416 net.cpp:84] Creating Layer Scale12
I1001 17:18:19.886221  5416 net.cpp:406] Scale12 <- Convolution12
I1001 17:18:19.886224  5416 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1001 17:18:19.886251  5416 layer_factory.hpp:77] Creating layer Scale12
I1001 17:18:19.886328  5416 net.cpp:122] Setting up Scale12
I1001 17:18:19.886333  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.886335  5416 net.cpp:137] Memory required for data: 325633200
I1001 17:18:19.886339  5416 layer_factory.hpp:77] Creating layer Eltwise5
I1001 17:18:19.886343  5416 net.cpp:84] Creating Layer Eltwise5
I1001 17:18:19.886345  5416 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1001 17:18:19.886348  5416 net.cpp:406] Eltwise5 <- Convolution12
I1001 17:18:19.886351  5416 net.cpp:380] Eltwise5 -> Eltwise5
I1001 17:18:19.886364  5416 net.cpp:122] Setting up Eltwise5
I1001 17:18:19.886368  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.886370  5416 net.cpp:137] Memory required for data: 328910000
I1001 17:18:19.886373  5416 layer_factory.hpp:77] Creating layer penlu11
I1001 17:18:19.886378  5416 net.cpp:84] Creating Layer penlu11
I1001 17:18:19.886379  5416 net.cpp:406] penlu11 <- Eltwise5
I1001 17:18:19.886384  5416 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1001 17:18:19.886497  5416 net.cpp:122] Setting up penlu11
I1001 17:18:19.886502  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.886503  5416 net.cpp:137] Memory required for data: 332186800
I1001 17:18:19.886507  5416 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1001 17:18:19.886512  5416 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1001 17:18:19.886513  5416 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1001 17:18:19.886517  5416 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1001 17:18:19.886534  5416 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1001 17:18:19.886584  5416 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1001 17:18:19.886589  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.886592  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.886595  5416 net.cpp:137] Memory required for data: 338740400
I1001 17:18:19.886596  5416 layer_factory.hpp:77] Creating layer Convolution13
I1001 17:18:19.886602  5416 net.cpp:84] Creating Layer Convolution13
I1001 17:18:19.886605  5416 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1001 17:18:19.886608  5416 net.cpp:380] Convolution13 -> Convolution13
I1001 17:18:19.887665  5416 net.cpp:122] Setting up Convolution13
I1001 17:18:19.887675  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.887677  5416 net.cpp:137] Memory required for data: 342017200
I1001 17:18:19.887681  5416 layer_factory.hpp:77] Creating layer BatchNorm13
I1001 17:18:19.887686  5416 net.cpp:84] Creating Layer BatchNorm13
I1001 17:18:19.887689  5416 net.cpp:406] BatchNorm13 <- Convolution13
I1001 17:18:19.887693  5416 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1001 17:18:19.887825  5416 net.cpp:122] Setting up BatchNorm13
I1001 17:18:19.887830  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.887832  5416 net.cpp:137] Memory required for data: 345294000
I1001 17:18:19.887837  5416 layer_factory.hpp:77] Creating layer Scale13
I1001 17:18:19.887850  5416 net.cpp:84] Creating Layer Scale13
I1001 17:18:19.887852  5416 net.cpp:406] Scale13 <- Convolution13
I1001 17:18:19.887856  5416 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1001 17:18:19.887884  5416 layer_factory.hpp:77] Creating layer Scale13
I1001 17:18:19.887964  5416 net.cpp:122] Setting up Scale13
I1001 17:18:19.887967  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.887969  5416 net.cpp:137] Memory required for data: 348570800
I1001 17:18:19.887974  5416 layer_factory.hpp:77] Creating layer penlu12
I1001 17:18:19.887979  5416 net.cpp:84] Creating Layer penlu12
I1001 17:18:19.887981  5416 net.cpp:406] penlu12 <- Convolution13
I1001 17:18:19.887985  5416 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1001 17:18:19.888092  5416 net.cpp:122] Setting up penlu12
I1001 17:18:19.888098  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.888100  5416 net.cpp:137] Memory required for data: 351847600
I1001 17:18:19.888104  5416 layer_factory.hpp:77] Creating layer Convolution14
I1001 17:18:19.888114  5416 net.cpp:84] Creating Layer Convolution14
I1001 17:18:19.888118  5416 net.cpp:406] Convolution14 <- Convolution13
I1001 17:18:19.888121  5416 net.cpp:380] Convolution14 -> Convolution14
I1001 17:18:19.889178  5416 net.cpp:122] Setting up Convolution14
I1001 17:18:19.889186  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.889189  5416 net.cpp:137] Memory required for data: 355124400
I1001 17:18:19.889204  5416 layer_factory.hpp:77] Creating layer BatchNorm14
I1001 17:18:19.889209  5416 net.cpp:84] Creating Layer BatchNorm14
I1001 17:18:19.889212  5416 net.cpp:406] BatchNorm14 <- Convolution14
I1001 17:18:19.889216  5416 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1001 17:18:19.889350  5416 net.cpp:122] Setting up BatchNorm14
I1001 17:18:19.889355  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.889358  5416 net.cpp:137] Memory required for data: 358401200
I1001 17:18:19.889363  5416 layer_factory.hpp:77] Creating layer Scale14
I1001 17:18:19.889366  5416 net.cpp:84] Creating Layer Scale14
I1001 17:18:19.889369  5416 net.cpp:406] Scale14 <- Convolution14
I1001 17:18:19.889371  5416 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1001 17:18:19.889400  5416 layer_factory.hpp:77] Creating layer Scale14
I1001 17:18:19.889477  5416 net.cpp:122] Setting up Scale14
I1001 17:18:19.889480  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.889482  5416 net.cpp:137] Memory required for data: 361678000
I1001 17:18:19.889487  5416 layer_factory.hpp:77] Creating layer Eltwise6
I1001 17:18:19.889490  5416 net.cpp:84] Creating Layer Eltwise6
I1001 17:18:19.889492  5416 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1001 17:18:19.889495  5416 net.cpp:406] Eltwise6 <- Convolution14
I1001 17:18:19.889499  5416 net.cpp:380] Eltwise6 -> Eltwise6
I1001 17:18:19.889511  5416 net.cpp:122] Setting up Eltwise6
I1001 17:18:19.889515  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.889518  5416 net.cpp:137] Memory required for data: 364954800
I1001 17:18:19.889519  5416 layer_factory.hpp:77] Creating layer penlu13
I1001 17:18:19.889525  5416 net.cpp:84] Creating Layer penlu13
I1001 17:18:19.889528  5416 net.cpp:406] penlu13 <- Eltwise6
I1001 17:18:19.889531  5416 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1001 17:18:19.889644  5416 net.cpp:122] Setting up penlu13
I1001 17:18:19.889648  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.889652  5416 net.cpp:137] Memory required for data: 368231600
I1001 17:18:19.889655  5416 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1001 17:18:19.889658  5416 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1001 17:18:19.910302  5416 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1001 17:18:19.910311  5416 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1001 17:18:19.910320  5416 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1001 17:18:19.910363  5416 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1001 17:18:19.910380  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.910387  5416 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 17:18:19.910390  5416 net.cpp:137] Memory required for data: 374785200
I1001 17:18:19.910395  5416 layer_factory.hpp:77] Creating layer Convolution15
I1001 17:18:19.910405  5416 net.cpp:84] Creating Layer Convolution15
I1001 17:18:19.910410  5416 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1001 17:18:19.910418  5416 net.cpp:380] Convolution15 -> Convolution15
I1001 17:18:19.911505  5416 net.cpp:122] Setting up Convolution15
I1001 17:18:19.911515  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.911519  5416 net.cpp:137] Memory required for data: 376423600
I1001 17:18:19.911523  5416 layer_factory.hpp:77] Creating layer BatchNorm15
I1001 17:18:19.911530  5416 net.cpp:84] Creating Layer BatchNorm15
I1001 17:18:19.911532  5416 net.cpp:406] BatchNorm15 <- Convolution15
I1001 17:18:19.911537  5416 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1001 17:18:19.911689  5416 net.cpp:122] Setting up BatchNorm15
I1001 17:18:19.911694  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.911696  5416 net.cpp:137] Memory required for data: 378062000
I1001 17:18:19.911701  5416 layer_factory.hpp:77] Creating layer Scale15
I1001 17:18:19.911707  5416 net.cpp:84] Creating Layer Scale15
I1001 17:18:19.911710  5416 net.cpp:406] Scale15 <- Convolution15
I1001 17:18:19.911715  5416 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1001 17:18:19.911744  5416 layer_factory.hpp:77] Creating layer Scale15
I1001 17:18:19.911834  5416 net.cpp:122] Setting up Scale15
I1001 17:18:19.911839  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.911840  5416 net.cpp:137] Memory required for data: 379700400
I1001 17:18:19.911845  5416 layer_factory.hpp:77] Creating layer Convolution16
I1001 17:18:19.911852  5416 net.cpp:84] Creating Layer Convolution16
I1001 17:18:19.911855  5416 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1001 17:18:19.911860  5416 net.cpp:380] Convolution16 -> Convolution16
I1001 17:18:19.913293  5416 net.cpp:122] Setting up Convolution16
I1001 17:18:19.913302  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.913305  5416 net.cpp:137] Memory required for data: 381338800
I1001 17:18:19.913311  5416 layer_factory.hpp:77] Creating layer BatchNorm16
I1001 17:18:19.913316  5416 net.cpp:84] Creating Layer BatchNorm16
I1001 17:18:19.913318  5416 net.cpp:406] BatchNorm16 <- Convolution16
I1001 17:18:19.913322  5416 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1001 17:18:19.913467  5416 net.cpp:122] Setting up BatchNorm16
I1001 17:18:19.913472  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.913475  5416 net.cpp:137] Memory required for data: 382977200
I1001 17:18:19.913480  5416 layer_factory.hpp:77] Creating layer Scale16
I1001 17:18:19.913485  5416 net.cpp:84] Creating Layer Scale16
I1001 17:18:19.913486  5416 net.cpp:406] Scale16 <- Convolution16
I1001 17:18:19.913491  5416 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1001 17:18:19.913519  5416 layer_factory.hpp:77] Creating layer Scale16
I1001 17:18:19.913601  5416 net.cpp:122] Setting up Scale16
I1001 17:18:19.913606  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.913609  5416 net.cpp:137] Memory required for data: 384615600
I1001 17:18:19.913612  5416 layer_factory.hpp:77] Creating layer penlu14
I1001 17:18:19.913617  5416 net.cpp:84] Creating Layer penlu14
I1001 17:18:19.913620  5416 net.cpp:406] penlu14 <- Convolution16
I1001 17:18:19.913625  5416 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1001 17:18:19.913739  5416 net.cpp:122] Setting up penlu14
I1001 17:18:19.913744  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.913746  5416 net.cpp:137] Memory required for data: 386254000
I1001 17:18:19.913750  5416 layer_factory.hpp:77] Creating layer Convolution17
I1001 17:18:19.913758  5416 net.cpp:84] Creating Layer Convolution17
I1001 17:18:19.913760  5416 net.cpp:406] Convolution17 <- Convolution16
I1001 17:18:19.913774  5416 net.cpp:380] Convolution17 -> Convolution17
I1001 17:18:19.915760  5416 net.cpp:122] Setting up Convolution17
I1001 17:18:19.915771  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.915772  5416 net.cpp:137] Memory required for data: 387892400
I1001 17:18:19.915779  5416 layer_factory.hpp:77] Creating layer BatchNorm17
I1001 17:18:19.915786  5416 net.cpp:84] Creating Layer BatchNorm17
I1001 17:18:19.915788  5416 net.cpp:406] BatchNorm17 <- Convolution17
I1001 17:18:19.915791  5416 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1001 17:18:19.915932  5416 net.cpp:122] Setting up BatchNorm17
I1001 17:18:19.915936  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.915938  5416 net.cpp:137] Memory required for data: 389530800
I1001 17:18:19.915943  5416 layer_factory.hpp:77] Creating layer Scale17
I1001 17:18:19.915948  5416 net.cpp:84] Creating Layer Scale17
I1001 17:18:19.915951  5416 net.cpp:406] Scale17 <- Convolution17
I1001 17:18:19.915953  5416 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1001 17:18:19.915982  5416 layer_factory.hpp:77] Creating layer Scale17
I1001 17:18:19.916062  5416 net.cpp:122] Setting up Scale17
I1001 17:18:19.916066  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.916069  5416 net.cpp:137] Memory required for data: 391169200
I1001 17:18:19.916072  5416 layer_factory.hpp:77] Creating layer Eltwise7
I1001 17:18:19.916076  5416 net.cpp:84] Creating Layer Eltwise7
I1001 17:18:19.916079  5416 net.cpp:406] Eltwise7 <- Convolution15
I1001 17:18:19.916082  5416 net.cpp:406] Eltwise7 <- Convolution17
I1001 17:18:19.916085  5416 net.cpp:380] Eltwise7 -> Eltwise7
I1001 17:18:19.916102  5416 net.cpp:122] Setting up Eltwise7
I1001 17:18:19.916105  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.916107  5416 net.cpp:137] Memory required for data: 392807600
I1001 17:18:19.916110  5416 layer_factory.hpp:77] Creating layer penlu15
I1001 17:18:19.916115  5416 net.cpp:84] Creating Layer penlu15
I1001 17:18:19.916118  5416 net.cpp:406] penlu15 <- Eltwise7
I1001 17:18:19.916121  5416 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1001 17:18:19.916231  5416 net.cpp:122] Setting up penlu15
I1001 17:18:19.916236  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.916239  5416 net.cpp:137] Memory required for data: 394446000
I1001 17:18:19.916242  5416 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1001 17:18:19.916246  5416 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1001 17:18:19.916249  5416 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1001 17:18:19.916252  5416 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1001 17:18:19.916256  5416 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1001 17:18:19.916280  5416 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1001 17:18:19.916282  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.916285  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.916287  5416 net.cpp:137] Memory required for data: 397722800
I1001 17:18:19.916290  5416 layer_factory.hpp:77] Creating layer Convolution18
I1001 17:18:19.916297  5416 net.cpp:84] Creating Layer Convolution18
I1001 17:18:19.916299  5416 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1001 17:18:19.916303  5416 net.cpp:380] Convolution18 -> Convolution18
I1001 17:18:19.917961  5416 net.cpp:122] Setting up Convolution18
I1001 17:18:19.917971  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.917974  5416 net.cpp:137] Memory required for data: 399361200
I1001 17:18:19.917979  5416 layer_factory.hpp:77] Creating layer BatchNorm18
I1001 17:18:19.917984  5416 net.cpp:84] Creating Layer BatchNorm18
I1001 17:18:19.917986  5416 net.cpp:406] BatchNorm18 <- Convolution18
I1001 17:18:19.917990  5416 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1001 17:18:19.918129  5416 net.cpp:122] Setting up BatchNorm18
I1001 17:18:19.918133  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.918143  5416 net.cpp:137] Memory required for data: 400999600
I1001 17:18:19.918148  5416 layer_factory.hpp:77] Creating layer Scale18
I1001 17:18:19.918153  5416 net.cpp:84] Creating Layer Scale18
I1001 17:18:19.918154  5416 net.cpp:406] Scale18 <- Convolution18
I1001 17:18:19.918157  5416 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1001 17:18:19.918189  5416 layer_factory.hpp:77] Creating layer Scale18
I1001 17:18:19.918267  5416 net.cpp:122] Setting up Scale18
I1001 17:18:19.918272  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.918273  5416 net.cpp:137] Memory required for data: 402638000
I1001 17:18:19.918277  5416 layer_factory.hpp:77] Creating layer penlu16
I1001 17:18:19.918282  5416 net.cpp:84] Creating Layer penlu16
I1001 17:18:19.918285  5416 net.cpp:406] penlu16 <- Convolution18
I1001 17:18:19.918288  5416 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1001 17:18:19.918400  5416 net.cpp:122] Setting up penlu16
I1001 17:18:19.918404  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.918406  5416 net.cpp:137] Memory required for data: 404276400
I1001 17:18:19.918411  5416 layer_factory.hpp:77] Creating layer Convolution19
I1001 17:18:19.918417  5416 net.cpp:84] Creating Layer Convolution19
I1001 17:18:19.918421  5416 net.cpp:406] Convolution19 <- Convolution18
I1001 17:18:19.918424  5416 net.cpp:380] Convolution19 -> Convolution19
I1001 17:18:19.920102  5416 net.cpp:122] Setting up Convolution19
I1001 17:18:19.920111  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.920114  5416 net.cpp:137] Memory required for data: 405914800
I1001 17:18:19.920119  5416 layer_factory.hpp:77] Creating layer BatchNorm19
I1001 17:18:19.920123  5416 net.cpp:84] Creating Layer BatchNorm19
I1001 17:18:19.920126  5416 net.cpp:406] BatchNorm19 <- Convolution19
I1001 17:18:19.920130  5416 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1001 17:18:19.920269  5416 net.cpp:122] Setting up BatchNorm19
I1001 17:18:19.920272  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.920274  5416 net.cpp:137] Memory required for data: 407553200
I1001 17:18:19.920279  5416 layer_factory.hpp:77] Creating layer Scale19
I1001 17:18:19.920284  5416 net.cpp:84] Creating Layer Scale19
I1001 17:18:19.920286  5416 net.cpp:406] Scale19 <- Convolution19
I1001 17:18:19.920290  5416 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1001 17:18:19.920317  5416 layer_factory.hpp:77] Creating layer Scale19
I1001 17:18:19.920408  5416 net.cpp:122] Setting up Scale19
I1001 17:18:19.920413  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.920414  5416 net.cpp:137] Memory required for data: 409191600
I1001 17:18:19.920426  5416 layer_factory.hpp:77] Creating layer Eltwise8
I1001 17:18:19.920430  5416 net.cpp:84] Creating Layer Eltwise8
I1001 17:18:19.920433  5416 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1001 17:18:19.920436  5416 net.cpp:406] Eltwise8 <- Convolution19
I1001 17:18:19.920440  5416 net.cpp:380] Eltwise8 -> Eltwise8
I1001 17:18:19.920456  5416 net.cpp:122] Setting up Eltwise8
I1001 17:18:19.920460  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.920462  5416 net.cpp:137] Memory required for data: 410830000
I1001 17:18:19.920464  5416 layer_factory.hpp:77] Creating layer penlu17
I1001 17:18:19.920469  5416 net.cpp:84] Creating Layer penlu17
I1001 17:18:19.920472  5416 net.cpp:406] penlu17 <- Eltwise8
I1001 17:18:19.920475  5416 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1001 17:18:19.920586  5416 net.cpp:122] Setting up penlu17
I1001 17:18:19.920590  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.920593  5416 net.cpp:137] Memory required for data: 412468400
I1001 17:18:19.920598  5416 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1001 17:18:19.920600  5416 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1001 17:18:19.920603  5416 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1001 17:18:19.920606  5416 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1001 17:18:19.920617  5416 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1001 17:18:19.920642  5416 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1001 17:18:19.920646  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.920650  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.920651  5416 net.cpp:137] Memory required for data: 415745200
I1001 17:18:19.920655  5416 layer_factory.hpp:77] Creating layer Convolution20
I1001 17:18:19.920660  5416 net.cpp:84] Creating Layer Convolution20
I1001 17:18:19.920663  5416 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1001 17:18:19.920667  5416 net.cpp:380] Convolution20 -> Convolution20
I1001 17:18:19.922670  5416 net.cpp:122] Setting up Convolution20
I1001 17:18:19.922679  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.922682  5416 net.cpp:137] Memory required for data: 417383600
I1001 17:18:19.922688  5416 layer_factory.hpp:77] Creating layer BatchNorm20
I1001 17:18:19.922691  5416 net.cpp:84] Creating Layer BatchNorm20
I1001 17:18:19.922694  5416 net.cpp:406] BatchNorm20 <- Convolution20
I1001 17:18:19.922698  5416 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1001 17:18:19.922842  5416 net.cpp:122] Setting up BatchNorm20
I1001 17:18:19.922847  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.922849  5416 net.cpp:137] Memory required for data: 419022000
I1001 17:18:19.922854  5416 layer_factory.hpp:77] Creating layer Scale20
I1001 17:18:19.922858  5416 net.cpp:84] Creating Layer Scale20
I1001 17:18:19.922861  5416 net.cpp:406] Scale20 <- Convolution20
I1001 17:18:19.922864  5416 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1001 17:18:19.922894  5416 layer_factory.hpp:77] Creating layer Scale20
I1001 17:18:19.922973  5416 net.cpp:122] Setting up Scale20
I1001 17:18:19.922981  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.922982  5416 net.cpp:137] Memory required for data: 420660400
I1001 17:18:19.922986  5416 layer_factory.hpp:77] Creating layer penlu18
I1001 17:18:19.922991  5416 net.cpp:84] Creating Layer penlu18
I1001 17:18:19.922993  5416 net.cpp:406] penlu18 <- Convolution20
I1001 17:18:19.922997  5416 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1001 17:18:19.923110  5416 net.cpp:122] Setting up penlu18
I1001 17:18:19.923115  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.923117  5416 net.cpp:137] Memory required for data: 422298800
I1001 17:18:19.923121  5416 layer_factory.hpp:77] Creating layer Convolution21
I1001 17:18:19.923128  5416 net.cpp:84] Creating Layer Convolution21
I1001 17:18:19.923130  5416 net.cpp:406] Convolution21 <- Convolution20
I1001 17:18:19.923135  5416 net.cpp:380] Convolution21 -> Convolution21
I1001 17:18:19.925127  5416 net.cpp:122] Setting up Convolution21
I1001 17:18:19.925135  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.925138  5416 net.cpp:137] Memory required for data: 423937200
I1001 17:18:19.925143  5416 layer_factory.hpp:77] Creating layer BatchNorm21
I1001 17:18:19.925148  5416 net.cpp:84] Creating Layer BatchNorm21
I1001 17:18:19.925151  5416 net.cpp:406] BatchNorm21 <- Convolution21
I1001 17:18:19.925155  5416 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1001 17:18:19.925294  5416 net.cpp:122] Setting up BatchNorm21
I1001 17:18:19.925298  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.925300  5416 net.cpp:137] Memory required for data: 425575600
I1001 17:18:19.925305  5416 layer_factory.hpp:77] Creating layer Scale21
I1001 17:18:19.925309  5416 net.cpp:84] Creating Layer Scale21
I1001 17:18:19.940939  5416 net.cpp:406] Scale21 <- Convolution21
I1001 17:18:19.940945  5416 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1001 17:18:19.940984  5416 layer_factory.hpp:77] Creating layer Scale21
I1001 17:18:19.941076  5416 net.cpp:122] Setting up Scale21
I1001 17:18:19.941081  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.941083  5416 net.cpp:137] Memory required for data: 427214000
I1001 17:18:19.941087  5416 layer_factory.hpp:77] Creating layer Eltwise9
I1001 17:18:19.941100  5416 net.cpp:84] Creating Layer Eltwise9
I1001 17:18:19.941103  5416 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1001 17:18:19.941107  5416 net.cpp:406] Eltwise9 <- Convolution21
I1001 17:18:19.941110  5416 net.cpp:380] Eltwise9 -> Eltwise9
I1001 17:18:19.941131  5416 net.cpp:122] Setting up Eltwise9
I1001 17:18:19.941135  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.941138  5416 net.cpp:137] Memory required for data: 428852400
I1001 17:18:19.941140  5416 layer_factory.hpp:77] Creating layer penlu19
I1001 17:18:19.941146  5416 net.cpp:84] Creating Layer penlu19
I1001 17:18:19.941149  5416 net.cpp:406] penlu19 <- Eltwise9
I1001 17:18:19.941153  5416 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1001 17:18:19.941282  5416 net.cpp:122] Setting up penlu19
I1001 17:18:19.941287  5416 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 17:18:19.941289  5416 net.cpp:137] Memory required for data: 430490800
I1001 17:18:19.941294  5416 layer_factory.hpp:77] Creating layer Pooling1
I1001 17:18:19.941299  5416 net.cpp:84] Creating Layer Pooling1
I1001 17:18:19.941303  5416 net.cpp:406] Pooling1 <- Eltwise9
I1001 17:18:19.941306  5416 net.cpp:380] Pooling1 -> Pooling1
I1001 17:18:19.941458  5416 net.cpp:122] Setting up Pooling1
I1001 17:18:19.941464  5416 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1001 17:18:19.941468  5416 net.cpp:137] Memory required for data: 430516400
I1001 17:18:19.941470  5416 layer_factory.hpp:77] Creating layer InnerProduct1
I1001 17:18:19.941476  5416 net.cpp:84] Creating Layer InnerProduct1
I1001 17:18:19.941479  5416 net.cpp:406] InnerProduct1 <- Pooling1
I1001 17:18:19.941483  5416 net.cpp:380] InnerProduct1 -> InnerProduct1
I1001 17:18:19.941591  5416 net.cpp:122] Setting up InnerProduct1
I1001 17:18:19.941596  5416 net.cpp:129] Top shape: 100 10 (1000)
I1001 17:18:19.941599  5416 net.cpp:137] Memory required for data: 430520400
I1001 17:18:19.941603  5416 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1001 17:18:19.941607  5416 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1001 17:18:19.941610  5416 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1001 17:18:19.941613  5416 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1001 17:18:19.941618  5416 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1001 17:18:19.941650  5416 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1001 17:18:19.941655  5416 net.cpp:129] Top shape: 100 10 (1000)
I1001 17:18:19.941658  5416 net.cpp:129] Top shape: 100 10 (1000)
I1001 17:18:19.941660  5416 net.cpp:137] Memory required for data: 430528400
I1001 17:18:19.941663  5416 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 17:18:19.941668  5416 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1001 17:18:19.941669  5416 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1001 17:18:19.941673  5416 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1001 17:18:19.941678  5416 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1001 17:18:19.941682  5416 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 17:18:19.941884  5416 net.cpp:122] Setting up SoftmaxWithLoss1
I1001 17:18:19.941890  5416 net.cpp:129] Top shape: (1)
I1001 17:18:19.941892  5416 net.cpp:132]     with loss weight 1
I1001 17:18:19.941900  5416 net.cpp:137] Memory required for data: 430528404
I1001 17:18:19.941902  5416 layer_factory.hpp:77] Creating layer Accuracy1
I1001 17:18:19.941913  5416 net.cpp:84] Creating Layer Accuracy1
I1001 17:18:19.941916  5416 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1001 17:18:19.941920  5416 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1001 17:18:19.941925  5416 net.cpp:380] Accuracy1 -> Accuracy1
I1001 17:18:19.941931  5416 net.cpp:122] Setting up Accuracy1
I1001 17:18:19.941933  5416 net.cpp:129] Top shape: (1)
I1001 17:18:19.941936  5416 net.cpp:137] Memory required for data: 430528408
I1001 17:18:19.941946  5416 net.cpp:200] Accuracy1 does not need backward computation.
I1001 17:18:19.941949  5416 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1001 17:18:19.941952  5416 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1001 17:18:19.941954  5416 net.cpp:198] InnerProduct1 needs backward computation.
I1001 17:18:19.941957  5416 net.cpp:198] Pooling1 needs backward computation.
I1001 17:18:19.941959  5416 net.cpp:198] penlu19 needs backward computation.
I1001 17:18:19.941962  5416 net.cpp:198] Eltwise9 needs backward computation.
I1001 17:18:19.941964  5416 net.cpp:198] Scale21 needs backward computation.
I1001 17:18:19.941967  5416 net.cpp:198] BatchNorm21 needs backward computation.
I1001 17:18:19.941969  5416 net.cpp:198] Convolution21 needs backward computation.
I1001 17:18:19.941972  5416 net.cpp:198] penlu18 needs backward computation.
I1001 17:18:19.941974  5416 net.cpp:198] Scale20 needs backward computation.
I1001 17:18:19.941977  5416 net.cpp:198] BatchNorm20 needs backward computation.
I1001 17:18:19.941978  5416 net.cpp:198] Convolution20 needs backward computation.
I1001 17:18:19.941980  5416 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1001 17:18:19.941983  5416 net.cpp:198] penlu17 needs backward computation.
I1001 17:18:19.941985  5416 net.cpp:198] Eltwise8 needs backward computation.
I1001 17:18:19.941988  5416 net.cpp:198] Scale19 needs backward computation.
I1001 17:18:19.941990  5416 net.cpp:198] BatchNorm19 needs backward computation.
I1001 17:18:19.941992  5416 net.cpp:198] Convolution19 needs backward computation.
I1001 17:18:19.941995  5416 net.cpp:198] penlu16 needs backward computation.
I1001 17:18:19.941998  5416 net.cpp:198] Scale18 needs backward computation.
I1001 17:18:19.941999  5416 net.cpp:198] BatchNorm18 needs backward computation.
I1001 17:18:19.942001  5416 net.cpp:198] Convolution18 needs backward computation.
I1001 17:18:19.942004  5416 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1001 17:18:19.942006  5416 net.cpp:198] penlu15 needs backward computation.
I1001 17:18:19.942009  5416 net.cpp:198] Eltwise7 needs backward computation.
I1001 17:18:19.942011  5416 net.cpp:198] Scale17 needs backward computation.
I1001 17:18:19.942014  5416 net.cpp:198] BatchNorm17 needs backward computation.
I1001 17:18:19.942016  5416 net.cpp:198] Convolution17 needs backward computation.
I1001 17:18:19.942018  5416 net.cpp:198] penlu14 needs backward computation.
I1001 17:18:19.942021  5416 net.cpp:198] Scale16 needs backward computation.
I1001 17:18:19.942023  5416 net.cpp:198] BatchNorm16 needs backward computation.
I1001 17:18:19.942025  5416 net.cpp:198] Convolution16 needs backward computation.
I1001 17:18:19.942028  5416 net.cpp:198] Scale15 needs backward computation.
I1001 17:18:19.942030  5416 net.cpp:198] BatchNorm15 needs backward computation.
I1001 17:18:19.942032  5416 net.cpp:198] Convolution15 needs backward computation.
I1001 17:18:19.942035  5416 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1001 17:18:19.942037  5416 net.cpp:198] penlu13 needs backward computation.
I1001 17:18:19.942040  5416 net.cpp:198] Eltwise6 needs backward computation.
I1001 17:18:19.942042  5416 net.cpp:198] Scale14 needs backward computation.
I1001 17:18:19.942045  5416 net.cpp:198] BatchNorm14 needs backward computation.
I1001 17:18:19.942047  5416 net.cpp:198] Convolution14 needs backward computation.
I1001 17:18:19.942049  5416 net.cpp:198] penlu12 needs backward computation.
I1001 17:18:19.942832  5416 net.cpp:198] Scale13 needs backward computation.
I1001 17:18:19.942839  5416 net.cpp:198] BatchNorm13 needs backward computation.
I1001 17:18:19.942842  5416 net.cpp:198] Convolution13 needs backward computation.
I1001 17:18:19.942845  5416 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1001 17:18:19.942857  5416 net.cpp:198] penlu11 needs backward computation.
I1001 17:18:19.942860  5416 net.cpp:198] Eltwise5 needs backward computation.
I1001 17:18:19.942863  5416 net.cpp:198] Scale12 needs backward computation.
I1001 17:18:19.942894  5416 net.cpp:198] BatchNorm12 needs backward computation.
I1001 17:18:19.942898  5416 net.cpp:198] Convolution12 needs backward computation.
I1001 17:18:19.942899  5416 net.cpp:198] penlu10 needs backward computation.
I1001 17:18:19.942901  5416 net.cpp:198] Scale11 needs backward computation.
I1001 17:18:19.942903  5416 net.cpp:198] BatchNorm11 needs backward computation.
I1001 17:18:19.942906  5416 net.cpp:198] Convolution11 needs backward computation.
I1001 17:18:19.942909  5416 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1001 17:18:19.942911  5416 net.cpp:198] penlu9 needs backward computation.
I1001 17:18:19.942914  5416 net.cpp:198] Eltwise4 needs backward computation.
I1001 17:18:19.942916  5416 net.cpp:198] Scale10 needs backward computation.
I1001 17:18:19.942919  5416 net.cpp:198] BatchNorm10 needs backward computation.
I1001 17:18:19.942921  5416 net.cpp:198] Convolution10 needs backward computation.
I1001 17:18:19.942924  5416 net.cpp:198] penlu8 needs backward computation.
I1001 17:18:19.942929  5416 net.cpp:198] Scale9 needs backward computation.
I1001 17:18:19.942930  5416 net.cpp:198] BatchNorm9 needs backward computation.
I1001 17:18:19.942932  5416 net.cpp:198] Convolution9 needs backward computation.
I1001 17:18:19.942935  5416 net.cpp:198] Scale8 needs backward computation.
I1001 17:18:19.942937  5416 net.cpp:198] BatchNorm8 needs backward computation.
I1001 17:18:19.942940  5416 net.cpp:198] Convolution8 needs backward computation.
I1001 17:18:19.942942  5416 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1001 17:18:19.942945  5416 net.cpp:198] penlu7 needs backward computation.
I1001 17:18:19.942947  5416 net.cpp:198] Eltwise3 needs backward computation.
I1001 17:18:19.942950  5416 net.cpp:198] Scale7 needs backward computation.
I1001 17:18:19.942952  5416 net.cpp:198] BatchNorm7 needs backward computation.
I1001 17:18:19.942955  5416 net.cpp:198] Convolution7 needs backward computation.
I1001 17:18:19.942957  5416 net.cpp:198] penlu6 needs backward computation.
I1001 17:18:19.942960  5416 net.cpp:198] Scale6 needs backward computation.
I1001 17:18:19.942961  5416 net.cpp:198] BatchNorm6 needs backward computation.
I1001 17:18:19.942965  5416 net.cpp:198] Convolution6 needs backward computation.
I1001 17:18:19.942966  5416 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1001 17:18:19.942970  5416 net.cpp:198] penlu5 needs backward computation.
I1001 17:18:19.942971  5416 net.cpp:198] Eltwise2 needs backward computation.
I1001 17:18:19.942975  5416 net.cpp:198] Scale5 needs backward computation.
I1001 17:18:19.942976  5416 net.cpp:198] BatchNorm5 needs backward computation.
I1001 17:18:19.942979  5416 net.cpp:198] Convolution5 needs backward computation.
I1001 17:18:19.942981  5416 net.cpp:198] penlu4 needs backward computation.
I1001 17:18:19.942983  5416 net.cpp:198] Scale4 needs backward computation.
I1001 17:18:19.942986  5416 net.cpp:198] BatchNorm4 needs backward computation.
I1001 17:18:19.942988  5416 net.cpp:198] Convolution4 needs backward computation.
I1001 17:18:19.942991  5416 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1001 17:18:19.942993  5416 net.cpp:198] penlu3 needs backward computation.
I1001 17:18:19.942996  5416 net.cpp:198] Eltwise1 needs backward computation.
I1001 17:18:19.942998  5416 net.cpp:198] Scale3 needs backward computation.
I1001 17:18:19.943001  5416 net.cpp:198] BatchNorm3 needs backward computation.
I1001 17:18:19.943003  5416 net.cpp:198] Convolution3 needs backward computation.
I1001 17:18:19.943006  5416 net.cpp:198] penlu2 needs backward computation.
I1001 17:18:19.943007  5416 net.cpp:198] Scale2 needs backward computation.
I1001 17:18:19.943011  5416 net.cpp:198] BatchNorm2 needs backward computation.
I1001 17:18:19.943012  5416 net.cpp:198] Convolution2 needs backward computation.
I1001 17:18:19.943015  5416 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1001 17:18:19.943017  5416 net.cpp:198] penlu1 needs backward computation.
I1001 17:18:19.943023  5416 net.cpp:198] Scale1 needs backward computation.
I1001 17:18:19.943025  5416 net.cpp:198] BatchNorm1 needs backward computation.
I1001 17:18:19.943027  5416 net.cpp:198] Convolution1 needs backward computation.
I1001 17:18:19.943030  5416 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1001 17:18:19.943033  5416 net.cpp:200] Data1 does not need backward computation.
I1001 17:18:19.943035  5416 net.cpp:242] This network produces output Accuracy1
I1001 17:18:19.943038  5416 net.cpp:242] This network produces output SoftmaxWithLoss1
I1001 17:18:19.943073  5416 net.cpp:255] Network initialization done.
I1001 17:18:19.943368  5416 solver.cpp:56] Solver scaffolding done.
I1001 17:18:19.948827  5416 caffe.cpp:248] Starting Optimization
I1001 17:18:19.948833  5416 solver.cpp:272] Solving resnet_cifar10
I1001 17:18:19.948835  5416 solver.cpp:273] Learning Rate Policy: multistep
I1001 17:18:19.950801  5416 solver.cpp:330] Iteration 0, Testing net (#0)
I1001 17:18:21.178437  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:18:21.227644  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1001 17:18:21.227679  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1001 17:18:21.299887  5416 solver.cpp:218] Iteration 0 (0 iter/s, 1.35098s/100 iters), loss = 2.31456
I1001 17:18:21.299914  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.31456 (* 1 = 2.31456 loss)
I1001 17:18:21.299931  5416 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1001 17:18:26.518304  5416 solver.cpp:218] Iteration 100 (19.1632 iter/s, 5.21833s/100 iters), loss = 1.6796
I1001 17:18:26.518352  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.6796 (* 1 = 1.6796 loss)
I1001 17:18:26.518360  5416 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1001 17:18:31.733695  5416 solver.cpp:218] Iteration 200 (19.1745 iter/s, 5.21526s/100 iters), loss = 1.80804
I1001 17:18:31.733723  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.80804 (* 1 = 1.80804 loss)
I1001 17:18:31.733739  5416 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1001 17:18:36.945545  5416 solver.cpp:218] Iteration 300 (19.1873 iter/s, 5.21177s/100 iters), loss = 1.25838
I1001 17:18:36.945574  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25838 (* 1 = 1.25838 loss)
I1001 17:18:36.945580  5416 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1001 17:18:42.161836  5416 solver.cpp:218] Iteration 400 (19.171 iter/s, 5.2162s/100 iters), loss = 0.993644
I1001 17:18:42.161866  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.993644 (* 1 = 0.993644 loss)
I1001 17:18:42.161882  5416 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1001 17:18:47.107215  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:18:47.315518  5416 solver.cpp:330] Iteration 500, Testing net (#0)
I1001 17:18:48.506969  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:18:48.556689  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2646
I1001 17:18:48.556713  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.11728 (* 1 = 4.11728 loss)
I1001 17:18:48.608573  5416 solver.cpp:218] Iteration 500 (15.5119 iter/s, 6.44665s/100 iters), loss = 1.18544
I1001 17:18:48.608597  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.18544 (* 1 = 1.18544 loss)
I1001 17:18:48.608604  5416 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1001 17:18:53.828403  5416 solver.cpp:218] Iteration 600 (19.158 iter/s, 5.21975s/100 iters), loss = 0.924225
I1001 17:18:53.828478  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.924225 (* 1 = 0.924225 loss)
I1001 17:18:53.828485  5416 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1001 17:18:59.040105  5416 solver.cpp:218] Iteration 700 (19.1881 iter/s, 5.21157s/100 iters), loss = 1.05515
I1001 17:18:59.040135  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05515 (* 1 = 1.05515 loss)
I1001 17:18:59.040151  5416 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1001 17:19:04.264364  5416 solver.cpp:218] Iteration 800 (19.1418 iter/s, 5.22417s/100 iters), loss = 0.974921
I1001 17:19:04.264395  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.974921 (* 1 = 0.974921 loss)
I1001 17:19:04.264412  5416 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1001 17:19:09.489909  5416 solver.cpp:218] Iteration 900 (19.1371 iter/s, 5.22546s/100 iters), loss = 0.748631
I1001 17:19:09.489950  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.748631 (* 1 = 0.748631 loss)
I1001 17:19:09.489956  5416 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1001 17:19:14.444249  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:19:14.657791  5416 solver.cpp:330] Iteration 1000, Testing net (#0)
I1001 17:19:15.841574  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:19:15.891571  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2646
I1001 17:19:15.891597  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.04461 (* 1 = 4.04461 loss)
I1001 17:19:15.944044  5416 solver.cpp:218] Iteration 1000 (15.4942 iter/s, 6.45403s/100 iters), loss = 0.947633
I1001 17:19:15.944070  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.947633 (* 1 = 0.947633 loss)
I1001 17:19:15.944077  5416 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1001 17:19:21.168942  5416 solver.cpp:218] Iteration 1100 (19.1394 iter/s, 5.22482s/100 iters), loss = 0.741791
I1001 17:19:21.168972  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.741791 (* 1 = 0.741791 loss)
I1001 17:19:21.168989  5416 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1001 17:19:26.386179  5416 solver.cpp:218] Iteration 1200 (19.1676 iter/s, 5.21714s/100 iters), loss = 0.804668
I1001 17:19:26.386503  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.804668 (* 1 = 0.804668 loss)
I1001 17:19:26.386513  5416 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1001 17:19:31.606433  5416 solver.cpp:218] Iteration 1300 (19.1576 iter/s, 5.21986s/100 iters), loss = 0.726207
I1001 17:19:31.606462  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.726207 (* 1 = 0.726207 loss)
I1001 17:19:31.606468  5416 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1001 17:19:36.839047  5416 solver.cpp:218] Iteration 1400 (19.1112 iter/s, 5.23253s/100 iters), loss = 0.693618
I1001 17:19:36.839077  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.693618 (* 1 = 0.693618 loss)
I1001 17:19:36.839084  5416 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1001 17:19:41.806215  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:19:42.015465  5416 solver.cpp:330] Iteration 1500, Testing net (#0)
I1001 17:19:43.200904  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:19:43.251080  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5102
I1001 17:19:43.251106  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.71466 (* 1 = 1.71466 loss)
I1001 17:19:43.303241  5416 solver.cpp:218] Iteration 1500 (15.47 iter/s, 6.4641s/100 iters), loss = 0.792154
I1001 17:19:43.303269  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.792154 (* 1 = 0.792154 loss)
I1001 17:19:43.303277  5416 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1001 17:19:48.534543  5416 solver.cpp:218] Iteration 1600 (19.116 iter/s, 5.23121s/100 iters), loss = 0.545815
I1001 17:19:48.534582  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545815 (* 1 = 0.545815 loss)
I1001 17:19:48.534588  5416 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1001 17:19:53.762941  5416 solver.cpp:218] Iteration 1700 (19.1267 iter/s, 5.22831s/100 iters), loss = 0.653483
I1001 17:19:53.762972  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.653483 (* 1 = 0.653483 loss)
I1001 17:19:53.762979  5416 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1001 17:19:58.984560  5416 solver.cpp:218] Iteration 1800 (19.1515 iter/s, 5.22153s/100 iters), loss = 0.693496
I1001 17:19:58.984704  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.693496 (* 1 = 0.693496 loss)
I1001 17:19:58.984712  5416 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1001 17:20:04.217772  5416 solver.cpp:218] Iteration 1900 (19.1094 iter/s, 5.23302s/100 iters), loss = 0.567259
I1001 17:20:04.217813  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.567259 (* 1 = 0.567259 loss)
I1001 17:20:04.217818  5416 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1001 17:20:09.189337  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:20:09.398859  5416 solver.cpp:330] Iteration 2000, Testing net (#0)
I1001 17:20:10.585146  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:20:10.635049  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5214
I1001 17:20:10.635084  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32892 (* 1 = 1.32892 loss)
I1001 17:20:10.687108  5416 solver.cpp:218] Iteration 2000 (15.4578 iter/s, 6.46924s/100 iters), loss = 0.704954
I1001 17:20:10.687137  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.704954 (* 1 = 0.704954 loss)
I1001 17:20:10.687145  5416 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1001 17:20:15.917182  5416 solver.cpp:218] Iteration 2100 (19.1205 iter/s, 5.22999s/100 iters), loss = 0.521678
I1001 17:20:15.917212  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.521678 (* 1 = 0.521678 loss)
I1001 17:20:15.917218  5416 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1001 17:20:21.150318  5416 solver.cpp:218] Iteration 2200 (19.1093 iter/s, 5.23305s/100 iters), loss = 0.61511
I1001 17:20:21.150351  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61511 (* 1 = 0.61511 loss)
I1001 17:20:21.150367  5416 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1001 17:20:26.374320  5416 solver.cpp:218] Iteration 2300 (19.1427 iter/s, 5.22392s/100 iters), loss = 0.520161
I1001 17:20:26.374353  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520161 (* 1 = 0.520161 loss)
I1001 17:20:26.374362  5416 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1001 17:20:31.602491  5416 solver.cpp:218] Iteration 2400 (19.1275 iter/s, 5.22809s/100 iters), loss = 0.591874
I1001 17:20:31.602620  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.591874 (* 1 = 0.591874 loss)
I1001 17:20:31.602627  5416 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1001 17:20:36.566622  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:20:36.775295  5416 solver.cpp:330] Iteration 2500, Testing net (#0)
I1001 17:20:37.959111  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:20:38.008872  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6523
I1001 17:20:38.008905  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01021 (* 1 = 1.01021 loss)
I1001 17:20:38.061084  5416 solver.cpp:218] Iteration 2500 (15.4836 iter/s, 6.45844s/100 iters), loss = 0.583542
I1001 17:20:38.061108  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583542 (* 1 = 0.583542 loss)
I1001 17:20:38.061115  5416 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1001 17:20:43.289944  5416 solver.cpp:218] Iteration 2600 (19.1249 iter/s, 5.22878s/100 iters), loss = 0.424762
I1001 17:20:43.289985  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424762 (* 1 = 0.424762 loss)
I1001 17:20:43.290001  5416 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1001 17:20:48.515919  5416 solver.cpp:218] Iteration 2700 (19.1355 iter/s, 5.22588s/100 iters), loss = 0.53248
I1001 17:20:48.515949  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.53248 (* 1 = 0.53248 loss)
I1001 17:20:48.515954  5416 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1001 17:20:53.747144  5416 solver.cpp:218] Iteration 2800 (19.1163 iter/s, 5.23114s/100 iters), loss = 0.626858
I1001 17:20:53.747174  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.626858 (* 1 = 0.626858 loss)
I1001 17:20:53.747180  5416 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1001 17:20:58.969558  5416 solver.cpp:218] Iteration 2900 (19.1485 iter/s, 5.22234s/100 iters), loss = 0.510891
I1001 17:20:58.969599  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510891 (* 1 = 0.510891 loss)
I1001 17:20:58.969604  5416 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1001 17:21:03.940778  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:21:04.149929  5416 solver.cpp:330] Iteration 3000, Testing net (#0)
I1001 17:21:05.337442  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:21:05.388329  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5779
I1001 17:21:05.388366  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32534 (* 1 = 1.32534 loss)
I1001 17:21:05.442061  5416 solver.cpp:218] Iteration 3000 (15.4502 iter/s, 6.4724s/100 iters), loss = 0.553193
I1001 17:21:05.442096  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.553193 (* 1 = 0.553193 loss)
I1001 17:21:05.442103  5416 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1001 17:21:10.676563  5416 solver.cpp:218] Iteration 3100 (19.1043 iter/s, 5.23442s/100 iters), loss = 0.417146
I1001 17:21:10.676604  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417146 (* 1 = 0.417146 loss)
I1001 17:21:10.676609  5416 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1001 17:21:15.908355  5416 solver.cpp:218] Iteration 3200 (19.1142 iter/s, 5.2317s/100 iters), loss = 0.479047
I1001 17:21:15.908385  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479047 (* 1 = 0.479047 loss)
I1001 17:21:15.908390  5416 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1001 17:21:21.138965  5416 solver.cpp:218] Iteration 3300 (19.1185 iter/s, 5.23053s/100 iters), loss = 0.564764
I1001 17:21:21.138996  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.564764 (* 1 = 0.564764 loss)
I1001 17:21:21.139003  5416 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1001 17:21:26.367703  5416 solver.cpp:218] Iteration 3400 (19.1254 iter/s, 5.22866s/100 iters), loss = 0.545949
I1001 17:21:26.367735  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545949 (* 1 = 0.545949 loss)
I1001 17:21:26.367743  5416 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1001 17:21:31.343809  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:21:31.553575  5416 solver.cpp:330] Iteration 3500, Testing net (#0)
I1001 17:21:32.746611  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:21:32.796744  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6381
I1001 17:21:32.796779  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0807 (* 1 = 1.0807 loss)
I1001 17:21:32.849006  5416 solver.cpp:218] Iteration 3500 (15.4292 iter/s, 6.48122s/100 iters), loss = 0.531902
I1001 17:21:32.849043  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.531902 (* 1 = 0.531902 loss)
I1001 17:21:32.849050  5416 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1001 17:21:38.079486  5416 solver.cpp:218] Iteration 3600 (19.119 iter/s, 5.23039s/100 iters), loss = 0.413389
I1001 17:21:38.079622  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413389 (* 1 = 0.413389 loss)
I1001 17:21:38.079628  5416 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1001 17:21:43.320230  5416 solver.cpp:218] Iteration 3700 (19.0819 iter/s, 5.24058s/100 iters), loss = 0.384703
I1001 17:21:43.320272  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384703 (* 1 = 0.384703 loss)
I1001 17:21:43.320278  5416 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1001 17:21:48.563238  5416 solver.cpp:218] Iteration 3800 (19.0733 iter/s, 5.24292s/100 iters), loss = 0.497041
I1001 17:21:48.563294  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.497041 (* 1 = 0.497041 loss)
I1001 17:21:48.563310  5416 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1001 17:21:53.803468  5416 solver.cpp:218] Iteration 3900 (19.0835 iter/s, 5.24013s/100 iters), loss = 0.414135
I1001 17:21:53.803509  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414135 (* 1 = 0.414135 loss)
I1001 17:21:53.803516  5416 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1001 17:21:58.772938  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:21:58.982419  5416 solver.cpp:330] Iteration 4000, Testing net (#0)
I1001 17:22:00.178426  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:22:00.228853  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6692
I1001 17:22:00.228889  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.971881 (* 1 = 0.971881 loss)
I1001 17:22:00.280587  5416 solver.cpp:218] Iteration 4000 (15.4392 iter/s, 6.47703s/100 iters), loss = 0.333336
I1001 17:22:00.280612  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333336 (* 1 = 0.333336 loss)
I1001 17:22:00.280619  5416 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1001 17:22:05.515154  5416 solver.cpp:218] Iteration 4100 (19.104 iter/s, 5.2345s/100 iters), loss = 0.378574
I1001 17:22:05.515203  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378574 (* 1 = 0.378574 loss)
I1001 17:22:05.515223  5416 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1001 17:22:10.747298  5416 solver.cpp:218] Iteration 4200 (19.1131 iter/s, 5.23203s/100 iters), loss = 0.38907
I1001 17:22:10.747458  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38907 (* 1 = 0.38907 loss)
I1001 17:22:10.747478  5416 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1001 17:22:15.983574  5416 solver.cpp:218] Iteration 4300 (19.0983 iter/s, 5.23608s/100 iters), loss = 0.421244
I1001 17:22:15.983605  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421244 (* 1 = 0.421244 loss)
I1001 17:22:15.983611  5416 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1001 17:22:21.214923  5416 solver.cpp:218] Iteration 4400 (19.1158 iter/s, 5.23128s/100 iters), loss = 0.378328
I1001 17:22:21.214953  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378328 (* 1 = 0.378328 loss)
I1001 17:22:21.214959  5416 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1001 17:22:26.181185  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:22:26.392118  5416 solver.cpp:330] Iteration 4500, Testing net (#0)
I1001 17:22:27.586244  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:22:27.636292  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7192
I1001 17:22:27.636317  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.825002 (* 1 = 0.825002 loss)
I1001 17:22:27.688488  5416 solver.cpp:218] Iteration 4500 (15.4476 iter/s, 6.47349s/100 iters), loss = 0.398761
I1001 17:22:27.688514  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398761 (* 1 = 0.398761 loss)
I1001 17:22:27.688520  5416 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1001 17:22:32.929440  5416 solver.cpp:218] Iteration 4600 (19.0807 iter/s, 5.24089s/100 iters), loss = 0.307163
I1001 17:22:32.929471  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307163 (* 1 = 0.307163 loss)
I1001 17:22:32.929476  5416 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1001 17:22:38.159610  5416 solver.cpp:218] Iteration 4700 (19.1201 iter/s, 5.2301s/100 iters), loss = 0.40093
I1001 17:22:38.159641  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40093 (* 1 = 0.40093 loss)
I1001 17:22:38.159648  5416 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1001 17:22:43.401793  5416 solver.cpp:218] Iteration 4800 (19.0763 iter/s, 5.24211s/100 iters), loss = 0.397031
I1001 17:22:43.401944  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397032 (* 1 = 0.397032 loss)
I1001 17:22:43.401963  5416 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1001 17:22:48.644191  5416 solver.cpp:218] Iteration 4900 (19.0759 iter/s, 5.24222s/100 iters), loss = 0.342012
I1001 17:22:48.644222  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342012 (* 1 = 0.342012 loss)
I1001 17:22:48.644227  5416 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1001 17:22:53.618677  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:22:53.828763  5416 solver.cpp:330] Iteration 5000, Testing net (#0)
I1001 17:22:55.016449  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:22:55.066131  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7122
I1001 17:22:55.066159  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.861202 (* 1 = 0.861202 loss)
I1001 17:22:55.118976  5416 solver.cpp:218] Iteration 5000 (15.4447 iter/s, 6.47472s/100 iters), loss = 0.342591
I1001 17:22:55.119005  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342591 (* 1 = 0.342591 loss)
I1001 17:22:55.119015  5416 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1001 17:23:00.348976  5416 solver.cpp:218] Iteration 5100 (19.1207 iter/s, 5.22994s/100 iters), loss = 0.304439
I1001 17:23:00.349017  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304439 (* 1 = 0.304439 loss)
I1001 17:23:00.349023  5416 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1001 17:23:05.577298  5416 solver.cpp:218] Iteration 5200 (19.1269 iter/s, 5.22824s/100 iters), loss = 0.44767
I1001 17:23:05.577333  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.44767 (* 1 = 0.44767 loss)
I1001 17:23:05.577342  5416 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1001 17:23:10.806622  5416 solver.cpp:218] Iteration 5300 (19.1232 iter/s, 5.22926s/100 iters), loss = 0.41105
I1001 17:23:10.806663  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41105 (* 1 = 0.41105 loss)
I1001 17:23:10.806669  5416 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1001 17:23:16.044045  5416 solver.cpp:218] Iteration 5400 (19.0936 iter/s, 5.23735s/100 iters), loss = 0.349223
I1001 17:23:16.044194  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349223 (* 1 = 0.349223 loss)
I1001 17:23:16.044203  5416 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1001 17:23:21.016350  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:23:21.224848  5416 solver.cpp:330] Iteration 5500, Testing net (#0)
I1001 17:23:22.412720  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:23:22.463119  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6556
I1001 17:23:22.463155  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14674 (* 1 = 1.14674 loss)
I1001 17:23:22.515528  5416 solver.cpp:218] Iteration 5500 (15.4528 iter/s, 6.47131s/100 iters), loss = 0.31784
I1001 17:23:22.515553  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31784 (* 1 = 0.31784 loss)
I1001 17:23:22.515560  5416 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1001 17:23:27.745025  5416 solver.cpp:218] Iteration 5600 (19.1225 iter/s, 5.22943s/100 iters), loss = 0.342309
I1001 17:23:27.745052  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342309 (* 1 = 0.342309 loss)
I1001 17:23:27.745059  5416 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1001 17:23:32.980397  5416 solver.cpp:218] Iteration 5700 (19.1011 iter/s, 5.23531s/100 iters), loss = 0.455167
I1001 17:23:32.980427  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.455168 (* 1 = 0.455168 loss)
I1001 17:23:32.980432  5416 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1001 17:23:38.207521  5416 solver.cpp:218] Iteration 5800 (19.1312 iter/s, 5.22707s/100 iters), loss = 0.470467
I1001 17:23:38.207552  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.470467 (* 1 = 0.470467 loss)
I1001 17:23:38.207557  5416 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1001 17:23:43.440596  5416 solver.cpp:218] Iteration 5900 (19.1094 iter/s, 5.23301s/100 iters), loss = 0.454313
I1001 17:23:43.440626  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454313 (* 1 = 0.454313 loss)
I1001 17:23:43.440632  5416 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1001 17:23:48.411617  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:23:48.620874  5416 solver.cpp:330] Iteration 6000, Testing net (#0)
I1001 17:23:49.806699  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:23:49.856701  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5436
I1001 17:23:49.856727  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.69506 (* 1 = 1.69506 loss)
I1001 17:23:49.909442  5416 solver.cpp:218] Iteration 6000 (15.4589 iter/s, 6.46879s/100 iters), loss = 0.285457
I1001 17:23:49.909471  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285457 (* 1 = 0.285457 loss)
I1001 17:23:49.909478  5416 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1001 17:23:55.144623  5416 solver.cpp:218] Iteration 6100 (19.1017 iter/s, 5.23512s/100 iters), loss = 0.336534
I1001 17:23:55.144655  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336534 (* 1 = 0.336534 loss)
I1001 17:23:55.144664  5416 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1001 17:24:00.380748  5416 solver.cpp:218] Iteration 6200 (19.0983 iter/s, 5.23607s/100 iters), loss = 0.358881
I1001 17:24:00.380789  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358881 (* 1 = 0.358881 loss)
I1001 17:24:00.380795  5416 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1001 17:24:05.617628  5416 solver.cpp:218] Iteration 6300 (19.0956 iter/s, 5.23681s/100 iters), loss = 0.385117
I1001 17:24:05.617664  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385117 (* 1 = 0.385117 loss)
I1001 17:24:05.617672  5416 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1001 17:24:10.848717  5416 solver.cpp:218] Iteration 6400 (19.1167 iter/s, 5.23103s/100 iters), loss = 0.387927
I1001 17:24:10.848748  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387927 (* 1 = 0.387927 loss)
I1001 17:24:10.848754  5416 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1001 17:24:15.830209  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:24:16.039443  5416 solver.cpp:330] Iteration 6500, Testing net (#0)
I1001 17:24:17.226445  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:24:17.276634  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6079
I1001 17:24:17.276670  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.56101 (* 1 = 1.56101 loss)
I1001 17:24:17.329248  5416 solver.cpp:218] Iteration 6500 (15.431 iter/s, 6.48047s/100 iters), loss = 0.351287
I1001 17:24:17.329273  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351287 (* 1 = 0.351287 loss)
I1001 17:24:17.329280  5416 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1001 17:24:22.565496  5416 solver.cpp:218] Iteration 6600 (19.0978 iter/s, 5.23619s/100 iters), loss = 0.327733
I1001 17:24:22.565629  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327733 (* 1 = 0.327733 loss)
I1001 17:24:22.565635  5416 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1001 17:24:27.801949  5416 solver.cpp:218] Iteration 6700 (19.0975 iter/s, 5.23629s/100 iters), loss = 0.359067
I1001 17:24:27.801980  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359067 (* 1 = 0.359067 loss)
I1001 17:24:27.801985  5416 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1001 17:24:33.030891  5416 solver.cpp:218] Iteration 6800 (19.1245 iter/s, 5.22888s/100 iters), loss = 0.472535
I1001 17:24:33.030920  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472536 (* 1 = 0.472536 loss)
I1001 17:24:33.030926  5416 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1001 17:24:38.258069  5416 solver.cpp:218] Iteration 6900 (19.131 iter/s, 5.22712s/100 iters), loss = 0.37388
I1001 17:24:38.258100  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37388 (* 1 = 0.37388 loss)
I1001 17:24:38.258105  5416 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1001 17:24:43.230383  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:24:43.438954  5416 solver.cpp:330] Iteration 7000, Testing net (#0)
I1001 17:24:44.628434  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:24:44.678668  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5798
I1001 17:24:44.678704  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.62902 (* 1 = 1.62902 loss)
I1001 17:24:44.730527  5416 solver.cpp:218] Iteration 7000 (15.4502 iter/s, 6.47239s/100 iters), loss = 0.27052
I1001 17:24:44.730561  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27052 (* 1 = 0.27052 loss)
I1001 17:24:44.730568  5416 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1001 17:24:49.964134  5416 solver.cpp:218] Iteration 7100 (19.1075 iter/s, 5.23354s/100 iters), loss = 0.327309
I1001 17:24:49.964164  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327309 (* 1 = 0.327309 loss)
I1001 17:24:49.964170  5416 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1001 17:24:55.207764  5416 solver.cpp:218] Iteration 7200 (19.071 iter/s, 5.24357s/100 iters), loss = 0.320643
I1001 17:24:55.207885  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320643 (* 1 = 0.320643 loss)
I1001 17:24:55.207893  5416 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1001 17:25:00.451700  5416 solver.cpp:218] Iteration 7300 (19.0702 iter/s, 5.24379s/100 iters), loss = 0.42649
I1001 17:25:00.451732  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42649 (* 1 = 0.42649 loss)
I1001 17:25:00.451738  5416 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1001 17:25:05.692059  5416 solver.cpp:218] Iteration 7400 (19.0829 iter/s, 5.2403s/100 iters), loss = 0.382037
I1001 17:25:05.692090  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382037 (* 1 = 0.382037 loss)
I1001 17:25:05.692107  5416 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1001 17:25:10.660243  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:25:10.869647  5416 solver.cpp:330] Iteration 7500, Testing net (#0)
I1001 17:25:12.064708  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:25:12.114655  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6646
I1001 17:25:12.114691  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08738 (* 1 = 1.08738 loss)
I1001 17:25:12.167371  5416 solver.cpp:218] Iteration 7500 (15.4434 iter/s, 6.47525s/100 iters), loss = 0.24983
I1001 17:25:12.167404  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24983 (* 1 = 0.24983 loss)
I1001 17:25:12.167412  5416 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1001 17:25:17.395215  5416 solver.cpp:218] Iteration 7600 (19.1286 iter/s, 5.22778s/100 iters), loss = 0.326495
I1001 17:25:17.395246  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326495 (* 1 = 0.326495 loss)
I1001 17:25:17.395253  5416 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1001 17:25:22.631402  5416 solver.cpp:218] Iteration 7700 (19.0981 iter/s, 5.23613s/100 iters), loss = 0.295948
I1001 17:25:22.631441  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295948 (* 1 = 0.295948 loss)
I1001 17:25:22.631448  5416 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1001 17:25:27.871465  5416 solver.cpp:218] Iteration 7800 (19.084 iter/s, 5.24s/100 iters), loss = 0.304323
I1001 17:25:27.871594  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304323 (* 1 = 0.304323 loss)
I1001 17:25:27.871605  5416 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1001 17:25:33.112886  5416 solver.cpp:218] Iteration 7900 (19.0793 iter/s, 5.24128s/100 iters), loss = 0.372
I1001 17:25:33.112926  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372 (* 1 = 0.372 loss)
I1001 17:25:33.112933  5416 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1001 17:25:38.080683  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:25:38.290843  5416 solver.cpp:330] Iteration 8000, Testing net (#0)
I1001 17:25:39.488391  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:25:39.538496  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.703
I1001 17:25:39.538535  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00552 (* 1 = 1.00552 loss)
I1001 17:25:39.590627  5416 solver.cpp:218] Iteration 8000 (15.4376 iter/s, 6.47767s/100 iters), loss = 0.250313
I1001 17:25:39.590653  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250313 (* 1 = 0.250313 loss)
I1001 17:25:39.590661  5416 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1001 17:25:44.835806  5416 solver.cpp:218] Iteration 8100 (19.0653 iter/s, 5.24513s/100 iters), loss = 0.335389
I1001 17:25:44.835847  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335389 (* 1 = 0.335389 loss)
I1001 17:25:44.835855  5416 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1001 17:25:50.069360  5416 solver.cpp:218] Iteration 8200 (19.1077 iter/s, 5.23349s/100 iters), loss = 0.465862
I1001 17:25:50.069391  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465862 (* 1 = 0.465862 loss)
I1001 17:25:50.069398  5416 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1001 17:25:55.318040  5416 solver.cpp:218] Iteration 8300 (19.0526 iter/s, 5.24862s/100 iters), loss = 0.278581
I1001 17:25:55.318073  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278581 (* 1 = 0.278581 loss)
I1001 17:25:55.318079  5416 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1001 17:26:00.565243  5416 solver.cpp:218] Iteration 8400 (19.058 iter/s, 5.24715s/100 iters), loss = 0.406987
I1001 17:26:00.565421  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406987 (* 1 = 0.406987 loss)
I1001 17:26:00.565429  5416 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1001 17:26:05.544463  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:26:05.756819  5416 solver.cpp:330] Iteration 8500, Testing net (#0)
I1001 17:26:06.942247  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:26:06.992127  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7841
I1001 17:26:06.992162  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.660881 (* 1 = 0.660881 loss)
I1001 17:26:07.044564  5416 solver.cpp:218] Iteration 8500 (15.4342 iter/s, 6.47913s/100 iters), loss = 0.230941
I1001 17:26:07.044595  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230941 (* 1 = 0.230941 loss)
I1001 17:26:07.044602  5416 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1001 17:26:12.286554  5416 solver.cpp:218] Iteration 8600 (19.0769 iter/s, 5.24194s/100 iters), loss = 0.265724
I1001 17:26:12.286586  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265724 (* 1 = 0.265724 loss)
I1001 17:26:12.286592  5416 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1001 17:26:17.519919  5416 solver.cpp:218] Iteration 8700 (19.1084 iter/s, 5.2333s/100 iters), loss = 0.360019
I1001 17:26:17.519953  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360019 (* 1 = 0.360019 loss)
I1001 17:26:17.519959  5416 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1001 17:26:22.749296  5416 solver.cpp:218] Iteration 8800 (19.123 iter/s, 5.22931s/100 iters), loss = 0.378541
I1001 17:26:22.749352  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378541 (* 1 = 0.378541 loss)
I1001 17:26:22.749372  5416 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1001 17:26:27.993002  5416 solver.cpp:218] Iteration 8900 (19.0707 iter/s, 5.24363s/100 iters), loss = 0.29715
I1001 17:26:27.993042  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29715 (* 1 = 0.29715 loss)
I1001 17:26:27.993048  5416 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1001 17:26:32.975256  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:26:33.184559  5416 solver.cpp:330] Iteration 9000, Testing net (#0)
I1001 17:26:34.371067  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:26:34.421149  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7261
I1001 17:26:34.421174  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.841783 (* 1 = 0.841783 loss)
I1001 17:26:34.473392  5416 solver.cpp:218] Iteration 9000 (15.4313 iter/s, 6.48032s/100 iters), loss = 0.24502
I1001 17:26:34.473417  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24502 (* 1 = 0.24502 loss)
I1001 17:26:34.473423  5416 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1001 17:26:39.712716  5416 solver.cpp:218] Iteration 9100 (19.0866 iter/s, 5.23927s/100 iters), loss = 0.309962
I1001 17:26:39.712744  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309962 (* 1 = 0.309962 loss)
I1001 17:26:39.712750  5416 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1001 17:26:44.954094  5416 solver.cpp:218] Iteration 9200 (19.0792 iter/s, 5.24132s/100 iters), loss = 0.272893
I1001 17:26:44.954138  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272893 (* 1 = 0.272893 loss)
I1001 17:26:44.954145  5416 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1001 17:26:50.189519  5416 solver.cpp:218] Iteration 9300 (19.1009 iter/s, 5.23536s/100 iters), loss = 0.343141
I1001 17:26:50.189561  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343141 (* 1 = 0.343141 loss)
I1001 17:26:50.189568  5416 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1001 17:26:55.426697  5416 solver.cpp:218] Iteration 9400 (19.0945 iter/s, 5.23711s/100 iters), loss = 0.340662
I1001 17:26:55.426733  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340662 (* 1 = 0.340662 loss)
I1001 17:26:55.426758  5416 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1001 17:27:00.402626  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:27:00.611642  5416 solver.cpp:330] Iteration 9500, Testing net (#0)
I1001 17:27:01.797894  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:27:01.848183  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6693
I1001 17:27:01.848208  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07809 (* 1 = 1.07809 loss)
I1001 17:27:01.900331  5416 solver.cpp:218] Iteration 9500 (15.4474 iter/s, 6.47358s/100 iters), loss = 0.224334
I1001 17:27:01.900357  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224334 (* 1 = 0.224334 loss)
I1001 17:27:01.900364  5416 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1001 17:27:07.138350  5416 solver.cpp:218] Iteration 9600 (19.0914 iter/s, 5.23796s/100 iters), loss = 0.288887
I1001 17:27:07.138460  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288887 (* 1 = 0.288887 loss)
I1001 17:27:07.138468  5416 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1001 17:27:12.380383  5416 solver.cpp:218] Iteration 9700 (19.0771 iter/s, 5.2419s/100 iters), loss = 0.317336
I1001 17:27:12.380411  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317336 (* 1 = 0.317336 loss)
I1001 17:27:12.380417  5416 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1001 17:27:17.624743  5416 solver.cpp:218] Iteration 9800 (19.0683 iter/s, 5.2443s/100 iters), loss = 0.383145
I1001 17:27:17.624778  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383145 (* 1 = 0.383145 loss)
I1001 17:27:17.624786  5416 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1001 17:27:22.861209  5416 solver.cpp:218] Iteration 9900 (19.0971 iter/s, 5.23641s/100 iters), loss = 0.367456
I1001 17:27:22.861250  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367456 (* 1 = 0.367456 loss)
I1001 17:27:22.861255  5416 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1001 17:27:27.848143  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:27:28.058066  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_10000.caffemodel
I1001 17:27:28.066380  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_10000.solverstate
I1001 17:27:28.067742  5416 solver.cpp:330] Iteration 10000, Testing net (#0)
I1001 17:27:29.253563  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:27:29.303714  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.622
I1001 17:27:29.303738  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.44251 (* 1 = 1.44251 loss)
I1001 17:27:29.356372  5416 solver.cpp:218] Iteration 10000 (15.3962 iter/s, 6.49509s/100 iters), loss = 0.295671
I1001 17:27:29.356415  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295672 (* 1 = 0.295672 loss)
I1001 17:27:29.356423  5416 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1001 17:27:34.602159  5416 solver.cpp:218] Iteration 10100 (19.0632 iter/s, 5.24572s/100 iters), loss = 0.261117
I1001 17:27:34.602200  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261117 (* 1 = 0.261117 loss)
I1001 17:27:34.602207  5416 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1001 17:27:39.846951  5416 solver.cpp:218] Iteration 10200 (19.0668 iter/s, 5.24473s/100 iters), loss = 0.275569
I1001 17:27:39.847101  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27557 (* 1 = 0.27557 loss)
I1001 17:27:39.847121  5416 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1001 17:27:45.089141  5416 solver.cpp:218] Iteration 10300 (19.0766 iter/s, 5.24203s/100 iters), loss = 0.361821
I1001 17:27:45.089170  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361821 (* 1 = 0.361821 loss)
I1001 17:27:45.089176  5416 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1001 17:27:50.323580  5416 solver.cpp:218] Iteration 10400 (19.1044 iter/s, 5.23438s/100 iters), loss = 0.361671
I1001 17:27:50.323621  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361671 (* 1 = 0.361671 loss)
I1001 17:27:50.323626  5416 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1001 17:27:55.300053  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:27:55.511382  5416 solver.cpp:330] Iteration 10500, Testing net (#0)
I1001 17:27:56.702793  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:27:56.752918  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5677
I1001 17:27:56.752954  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.45816 (* 1 = 1.45816 loss)
I1001 17:27:56.805058  5416 solver.cpp:218] Iteration 10500 (15.4287 iter/s, 6.48141s/100 iters), loss = 0.330585
I1001 17:27:56.805089  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330585 (* 1 = 0.330585 loss)
I1001 17:27:56.805096  5416 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1001 17:28:02.036417  5416 solver.cpp:218] Iteration 10600 (19.1157 iter/s, 5.2313s/100 iters), loss = 0.335983
I1001 17:28:02.036444  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335984 (* 1 = 0.335984 loss)
I1001 17:28:02.036450  5416 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1001 17:28:07.279024  5416 solver.cpp:218] Iteration 10700 (19.0747 iter/s, 5.24256s/100 iters), loss = 0.340386
I1001 17:28:07.279054  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340386 (* 1 = 0.340386 loss)
I1001 17:28:07.279060  5416 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1001 17:28:12.524592  5416 solver.cpp:218] Iteration 10800 (19.0639 iter/s, 5.24551s/100 iters), loss = 0.300574
I1001 17:28:12.524734  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300574 (* 1 = 0.300574 loss)
I1001 17:28:12.524741  5416 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1001 17:28:17.763382  5416 solver.cpp:218] Iteration 10900 (19.089 iter/s, 5.23863s/100 iters), loss = 0.280939
I1001 17:28:17.763413  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280939 (* 1 = 0.280939 loss)
I1001 17:28:17.763420  5416 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1001 17:28:22.732170  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:28:22.941939  5416 solver.cpp:330] Iteration 11000, Testing net (#0)
I1001 17:28:24.140422  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:28:24.190587  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6801
I1001 17:28:24.190619  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1678 (* 1 = 1.1678 loss)
I1001 17:28:24.242756  5416 solver.cpp:218] Iteration 11000 (15.4337 iter/s, 6.47932s/100 iters), loss = 0.291362
I1001 17:28:24.242785  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291362 (* 1 = 0.291362 loss)
I1001 17:28:24.242792  5416 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1001 17:28:29.476852  5416 solver.cpp:218] Iteration 11100 (19.1057 iter/s, 5.23404s/100 iters), loss = 0.354455
I1001 17:28:29.476898  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354455 (* 1 = 0.354455 loss)
I1001 17:28:29.476905  5416 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1001 17:28:34.709522  5416 solver.cpp:218] Iteration 11200 (19.111 iter/s, 5.2326s/100 iters), loss = 0.283184
I1001 17:28:34.709563  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283184 (* 1 = 0.283184 loss)
I1001 17:28:34.709568  5416 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1001 17:28:39.947772  5416 solver.cpp:218] Iteration 11300 (19.0906 iter/s, 5.23818s/100 iters), loss = 0.400377
I1001 17:28:39.947803  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400377 (* 1 = 0.400377 loss)
I1001 17:28:39.947819  5416 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1001 17:28:45.183369  5416 solver.cpp:218] Iteration 11400 (19.1002 iter/s, 5.23554s/100 iters), loss = 0.371562
I1001 17:28:45.183545  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371562 (* 1 = 0.371562 loss)
I1001 17:28:45.183564  5416 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1001 17:28:50.157631  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:28:50.366936  5416 solver.cpp:330] Iteration 11500, Testing net (#0)
I1001 17:28:51.564123  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:28:51.614310  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6644
I1001 17:28:51.614344  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2576 (* 1 = 1.2576 loss)
I1001 17:28:51.666702  5416 solver.cpp:218] Iteration 11500 (15.4246 iter/s, 6.48315s/100 iters), loss = 0.220763
I1001 17:28:51.666728  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220763 (* 1 = 0.220763 loss)
I1001 17:28:51.666735  5416 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1001 17:28:56.908999  5416 solver.cpp:218] Iteration 11600 (19.0758 iter/s, 5.24224s/100 iters), loss = 0.283088
I1001 17:28:56.909030  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283088 (* 1 = 0.283088 loss)
I1001 17:28:56.909036  5416 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1001 17:29:02.142776  5416 solver.cpp:218] Iteration 11700 (19.1069 iter/s, 5.23372s/100 iters), loss = 0.296843
I1001 17:29:02.142817  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296843 (* 1 = 0.296843 loss)
I1001 17:29:02.142823  5416 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1001 17:29:07.384573  5416 solver.cpp:218] Iteration 11800 (19.0777 iter/s, 5.24173s/100 iters), loss = 0.405053
I1001 17:29:07.384613  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405053 (* 1 = 0.405053 loss)
I1001 17:29:07.384619  5416 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1001 17:29:12.627975  5416 solver.cpp:218] Iteration 11900 (19.0718 iter/s, 5.24334s/100 iters), loss = 0.279983
I1001 17:29:12.628005  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279983 (* 1 = 0.279983 loss)
I1001 17:29:12.628010  5416 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1001 17:29:17.605090  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:29:17.815924  5416 solver.cpp:330] Iteration 12000, Testing net (#0)
I1001 17:29:19.000849  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:29:19.050598  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7194
I1001 17:29:19.050632  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.932255 (* 1 = 0.932255 loss)
I1001 17:29:19.103160  5416 solver.cpp:218] Iteration 12000 (15.4437 iter/s, 6.47513s/100 iters), loss = 0.267081
I1001 17:29:19.103186  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267081 (* 1 = 0.267081 loss)
I1001 17:29:19.103193  5416 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1001 17:29:24.343936  5416 solver.cpp:218] Iteration 12100 (19.0813 iter/s, 5.24072s/100 iters), loss = 0.273325
I1001 17:29:24.343976  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273325 (* 1 = 0.273325 loss)
I1001 17:29:24.343982  5416 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1001 17:29:29.582232  5416 solver.cpp:218] Iteration 12200 (19.0904 iter/s, 5.23822s/100 iters), loss = 0.336917
I1001 17:29:29.582278  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336917 (* 1 = 0.336917 loss)
I1001 17:29:29.582284  5416 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1001 17:29:34.812304  5416 solver.cpp:218] Iteration 12300 (19.1204 iter/s, 5.23s/100 iters), loss = 0.358491
I1001 17:29:34.812338  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358491 (* 1 = 0.358491 loss)
I1001 17:29:34.812345  5416 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1001 17:29:40.051443  5416 solver.cpp:218] Iteration 12400 (19.0873 iter/s, 5.23908s/100 iters), loss = 0.273707
I1001 17:29:40.051470  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273707 (* 1 = 0.273707 loss)
I1001 17:29:40.051476  5416 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1001 17:29:45.033848  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:29:45.243032  5416 solver.cpp:330] Iteration 12500, Testing net (#0)
I1001 17:29:46.431684  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:29:46.482015  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5647
I1001 17:29:46.482049  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.86773 (* 1 = 1.86773 loss)
I1001 17:29:46.534375  5416 solver.cpp:218] Iteration 12500 (15.4252 iter/s, 6.48288s/100 iters), loss = 0.227062
I1001 17:29:46.534401  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227063 (* 1 = 0.227063 loss)
I1001 17:29:46.534409  5416 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1001 17:29:51.775229  5416 solver.cpp:218] Iteration 12600 (19.081 iter/s, 5.2408s/100 iters), loss = 0.219808
I1001 17:29:51.775393  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219808 (* 1 = 0.219808 loss)
I1001 17:29:51.775410  5416 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1001 17:29:57.014993  5416 solver.cpp:218] Iteration 12700 (19.0855 iter/s, 5.23958s/100 iters), loss = 0.259932
I1001 17:29:57.015034  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259932 (* 1 = 0.259932 loss)
I1001 17:29:57.015041  5416 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1001 17:30:02.250460  5416 solver.cpp:218] Iteration 12800 (19.1007 iter/s, 5.2354s/100 iters), loss = 0.30061
I1001 17:30:02.250490  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30061 (* 1 = 0.30061 loss)
I1001 17:30:02.250496  5416 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1001 17:30:07.489661  5416 solver.cpp:218] Iteration 12900 (19.0871 iter/s, 5.23915s/100 iters), loss = 0.240462
I1001 17:30:07.489701  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240462 (* 1 = 0.240462 loss)
I1001 17:30:07.489706  5416 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1001 17:30:12.467506  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:30:12.676148  5416 solver.cpp:330] Iteration 13000, Testing net (#0)
I1001 17:30:13.864248  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:30:13.914748  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7869
I1001 17:30:13.914783  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.635658 (* 1 = 0.635658 loss)
I1001 17:30:13.967594  5416 solver.cpp:218] Iteration 13000 (15.4372 iter/s, 6.47787s/100 iters), loss = 0.219806
I1001 17:30:13.967625  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219806 (* 1 = 0.219806 loss)
I1001 17:30:13.967633  5416 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1001 17:30:19.206351  5416 solver.cpp:218] Iteration 13100 (19.0887 iter/s, 5.2387s/100 iters), loss = 0.283386
I1001 17:30:19.206380  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283386 (* 1 = 0.283386 loss)
I1001 17:30:19.206395  5416 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1001 17:30:24.449355  5416 solver.cpp:218] Iteration 13200 (19.0732 iter/s, 5.24295s/100 iters), loss = 0.33463
I1001 17:30:24.449466  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33463 (* 1 = 0.33463 loss)
I1001 17:30:24.449476  5416 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1001 17:30:29.694918  5416 solver.cpp:218] Iteration 13300 (19.0642 iter/s, 5.24543s/100 iters), loss = 0.245884
I1001 17:30:29.694949  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245884 (* 1 = 0.245884 loss)
I1001 17:30:29.694957  5416 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1001 17:30:34.930958  5416 solver.cpp:218] Iteration 13400 (19.0986 iter/s, 5.23598s/100 iters), loss = 0.254249
I1001 17:30:34.930999  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254249 (* 1 = 0.254249 loss)
I1001 17:30:34.931005  5416 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1001 17:30:39.913739  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:30:40.122438  5416 solver.cpp:330] Iteration 13500, Testing net (#0)
I1001 17:30:41.309260  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:30:41.359594  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7205
I1001 17:30:41.359628  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.878476 (* 1 = 0.878476 loss)
I1001 17:30:41.413179  5416 solver.cpp:218] Iteration 13500 (15.427 iter/s, 6.48215s/100 iters), loss = 0.199305
I1001 17:30:41.413214  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199305 (* 1 = 0.199305 loss)
I1001 17:30:41.413223  5416 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1001 17:30:46.648495  5416 solver.cpp:218] Iteration 13600 (19.1013 iter/s, 5.23526s/100 iters), loss = 0.253307
I1001 17:30:46.648526  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253307 (* 1 = 0.253307 loss)
I1001 17:30:46.648542  5416 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1001 17:30:51.888743  5416 solver.cpp:218] Iteration 13700 (19.0833 iter/s, 5.24019s/100 iters), loss = 0.28951
I1001 17:30:51.888772  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28951 (* 1 = 0.28951 loss)
I1001 17:30:51.888778  5416 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1001 17:30:57.126736  5416 solver.cpp:218] Iteration 13800 (19.0915 iter/s, 5.23794s/100 iters), loss = 0.326616
I1001 17:30:57.126855  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326616 (* 1 = 0.326616 loss)
I1001 17:30:57.126863  5416 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1001 17:31:02.351965  5416 solver.cpp:218] Iteration 13900 (19.1384 iter/s, 5.22509s/100 iters), loss = 0.298199
I1001 17:31:02.352006  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298199 (* 1 = 0.298199 loss)
I1001 17:31:02.352012  5416 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1001 17:31:07.325160  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:31:07.533815  5416 solver.cpp:330] Iteration 14000, Testing net (#0)
I1001 17:31:08.727260  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:31:08.777330  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6197
I1001 17:31:08.777365  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32387 (* 1 = 1.32387 loss)
I1001 17:31:08.829840  5416 solver.cpp:218] Iteration 14000 (15.4373 iter/s, 6.47781s/100 iters), loss = 0.224178
I1001 17:31:08.829870  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224178 (* 1 = 0.224178 loss)
I1001 17:31:08.829877  5416 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1001 17:31:14.062055  5416 solver.cpp:218] Iteration 14100 (19.1126 iter/s, 5.23216s/100 iters), loss = 0.271989
I1001 17:31:14.062083  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271989 (* 1 = 0.271989 loss)
I1001 17:31:14.062089  5416 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1001 17:31:19.306668  5416 solver.cpp:218] Iteration 14200 (19.0674 iter/s, 5.24456s/100 iters), loss = 0.25637
I1001 17:31:19.306708  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25637 (* 1 = 0.25637 loss)
I1001 17:31:19.306713  5416 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1001 17:31:24.546000  5416 solver.cpp:218] Iteration 14300 (19.0866 iter/s, 5.23927s/100 iters), loss = 0.333549
I1001 17:31:24.546030  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333549 (* 1 = 0.333549 loss)
I1001 17:31:24.546046  5416 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1001 17:31:29.789813  5416 solver.cpp:218] Iteration 14400 (19.0703 iter/s, 5.24376s/100 iters), loss = 0.254747
I1001 17:31:29.789960  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254747 (* 1 = 0.254747 loss)
I1001 17:31:29.789983  5416 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1001 17:31:34.764000  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:31:34.973690  5416 solver.cpp:330] Iteration 14500, Testing net (#0)
I1001 17:31:36.169644  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:31:36.219918  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6809
I1001 17:31:36.219952  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.18631 (* 1 = 1.18631 loss)
I1001 17:31:36.272372  5416 solver.cpp:218] Iteration 14500 (15.4264 iter/s, 6.48239s/100 iters), loss = 0.186832
I1001 17:31:36.272398  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186832 (* 1 = 0.186832 loss)
I1001 17:31:36.272405  5416 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1001 17:31:41.605360  5416 solver.cpp:218] Iteration 14600 (18.7514 iter/s, 5.33293s/100 iters), loss = 0.311721
I1001 17:31:41.605403  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311721 (* 1 = 0.311721 loss)
I1001 17:31:41.605412  5416 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1001 17:31:46.866842  5416 solver.cpp:218] Iteration 14700 (19.0063 iter/s, 5.26142s/100 iters), loss = 0.178509
I1001 17:31:46.866871  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178509 (* 1 = 0.178509 loss)
I1001 17:31:46.866878  5416 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1001 17:31:52.126997  5416 solver.cpp:218] Iteration 14800 (19.011 iter/s, 5.2601s/100 iters), loss = 0.322496
I1001 17:31:52.127037  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322496 (* 1 = 0.322496 loss)
I1001 17:31:52.127043  5416 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1001 17:31:57.362360  5416 solver.cpp:218] Iteration 14900 (19.1011 iter/s, 5.23529s/100 iters), loss = 0.226361
I1001 17:31:57.362402  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226361 (* 1 = 0.226361 loss)
I1001 17:31:57.362408  5416 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1001 17:32:02.336024  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:32:02.549702  5416 solver.cpp:330] Iteration 15000, Testing net (#0)
I1001 17:32:03.738875  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:32:03.788609  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.727
I1001 17:32:03.788633  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.966688 (* 1 = 0.966688 loss)
I1001 17:32:03.840636  5416 solver.cpp:218] Iteration 15000 (15.4364 iter/s, 6.47821s/100 iters), loss = 0.217888
I1001 17:32:03.840662  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217888 (* 1 = 0.217888 loss)
I1001 17:32:03.840670  5416 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1001 17:32:09.079696  5416 solver.cpp:218] Iteration 15100 (19.0876 iter/s, 5.23901s/100 iters), loss = 0.287508
I1001 17:32:09.079727  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287508 (* 1 = 0.287508 loss)
I1001 17:32:09.079733  5416 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1001 17:32:14.305953  5416 solver.cpp:218] Iteration 15200 (19.1344 iter/s, 5.2262s/100 iters), loss = 0.39856
I1001 17:32:14.305994  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39856 (* 1 = 0.39856 loss)
I1001 17:32:14.306000  5416 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1001 17:32:19.543865  5416 solver.cpp:218] Iteration 15300 (19.0918 iter/s, 5.23784s/100 iters), loss = 0.244296
I1001 17:32:19.543895  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244296 (* 1 = 0.244296 loss)
I1001 17:32:19.543900  5416 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1001 17:32:24.783447  5416 solver.cpp:218] Iteration 15400 (19.0857 iter/s, 5.23953s/100 iters), loss = 0.291536
I1001 17:32:24.783488  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291536 (* 1 = 0.291536 loss)
I1001 17:32:24.783493  5416 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1001 17:32:29.759552  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:32:29.969385  5416 solver.cpp:330] Iteration 15500, Testing net (#0)
I1001 17:32:31.155722  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:32:31.205823  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6436
I1001 17:32:31.205857  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.42973 (* 1 = 1.42973 loss)
I1001 17:32:31.258155  5416 solver.cpp:218] Iteration 15500 (15.4449 iter/s, 6.47465s/100 iters), loss = 0.215046
I1001 17:32:31.258179  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215046 (* 1 = 0.215046 loss)
I1001 17:32:31.258186  5416 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1001 17:32:36.492288  5416 solver.cpp:218] Iteration 15600 (19.1055 iter/s, 5.23408s/100 iters), loss = 0.281662
I1001 17:32:36.492451  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281661 (* 1 = 0.281661 loss)
I1001 17:32:36.492460  5416 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1001 17:32:41.727697  5416 solver.cpp:218] Iteration 15700 (19.1014 iter/s, 5.23522s/100 iters), loss = 0.405385
I1001 17:32:41.727732  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405385 (* 1 = 0.405385 loss)
I1001 17:32:41.727741  5416 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1001 17:32:46.958112  5416 solver.cpp:218] Iteration 15800 (19.1191 iter/s, 5.23036s/100 iters), loss = 0.310844
I1001 17:32:46.958153  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310844 (* 1 = 0.310844 loss)
I1001 17:32:46.958158  5416 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1001 17:32:52.195019  5416 solver.cpp:218] Iteration 15900 (19.0955 iter/s, 5.23684s/100 iters), loss = 0.275188
I1001 17:32:52.195049  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275188 (* 1 = 0.275188 loss)
I1001 17:32:52.195053  5416 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1001 17:32:57.173941  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:32:57.384351  5416 solver.cpp:330] Iteration 16000, Testing net (#0)
I1001 17:32:58.570078  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:32:58.619658  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7144
I1001 17:32:58.619683  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08038 (* 1 = 1.08038 loss)
I1001 17:32:58.672022  5416 solver.cpp:218] Iteration 16000 (15.4394 iter/s, 6.47695s/100 iters), loss = 0.231933
I1001 17:32:58.672045  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231933 (* 1 = 0.231933 loss)
I1001 17:32:58.672052  5416 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1001 17:33:03.912513  5416 solver.cpp:218] Iteration 16100 (19.0824 iter/s, 5.24044s/100 iters), loss = 0.256853
I1001 17:33:03.912554  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256853 (* 1 = 0.256853 loss)
I1001 17:33:03.912559  5416 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1001 17:33:09.182241  5416 solver.cpp:218] Iteration 16200 (18.9765 iter/s, 5.26966s/100 iters), loss = 0.318516
I1001 17:33:09.182417  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318516 (* 1 = 0.318516 loss)
I1001 17:33:09.182426  5416 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1001 17:33:14.457139  5416 solver.cpp:218] Iteration 16300 (18.9584 iter/s, 5.27469s/100 iters), loss = 0.292574
I1001 17:33:14.457204  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292574 (* 1 = 0.292574 loss)
I1001 17:33:14.457224  5416 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1001 17:33:19.706434  5416 solver.cpp:218] Iteration 16400 (19.0504 iter/s, 5.24923s/100 iters), loss = 0.296336
I1001 17:33:19.706466  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296336 (* 1 = 0.296336 loss)
I1001 17:33:19.706475  5416 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1001 17:33:24.680883  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:33:24.890705  5416 solver.cpp:330] Iteration 16500, Testing net (#0)
I1001 17:33:26.082182  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:33:26.132498  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7225
I1001 17:33:26.132532  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.934939 (* 1 = 0.934939 loss)
I1001 17:33:26.185014  5416 solver.cpp:218] Iteration 16500 (15.4356 iter/s, 6.47852s/100 iters), loss = 0.245691
I1001 17:33:26.185039  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245691 (* 1 = 0.245691 loss)
I1001 17:33:26.185045  5416 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1001 17:33:31.421592  5416 solver.cpp:218] Iteration 16600 (19.0966 iter/s, 5.23653s/100 iters), loss = 0.352694
I1001 17:33:31.421622  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352694 (* 1 = 0.352694 loss)
I1001 17:33:31.421629  5416 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1001 17:33:36.651970  5416 solver.cpp:218] Iteration 16700 (19.1193 iter/s, 5.23032s/100 iters), loss = 0.342533
I1001 17:33:36.651999  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342533 (* 1 = 0.342533 loss)
I1001 17:33:36.652005  5416 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1001 17:33:41.891053  5416 solver.cpp:218] Iteration 16800 (19.0875 iter/s, 5.23903s/100 iters), loss = 0.346398
I1001 17:33:41.891145  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346398 (* 1 = 0.346398 loss)
I1001 17:33:41.891162  5416 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1001 17:33:47.292413  5416 solver.cpp:218] Iteration 16900 (18.5142 iter/s, 5.40125s/100 iters), loss = 0.25328
I1001 17:33:47.292443  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25328 (* 1 = 0.25328 loss)
I1001 17:33:47.292448  5416 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1001 17:33:52.422387  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:33:52.637397  5416 solver.cpp:330] Iteration 17000, Testing net (#0)
I1001 17:33:53.863605  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:33:53.914459  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7564
I1001 17:33:53.914499  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.770948 (* 1 = 0.770948 loss)
I1001 17:33:53.971930  5416 solver.cpp:218] Iteration 17000 (14.9713 iter/s, 6.67946s/100 iters), loss = 0.206275
I1001 17:33:53.971968  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206275 (* 1 = 0.206275 loss)
I1001 17:33:53.971976  5416 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1001 17:33:59.350455  5416 solver.cpp:218] Iteration 17100 (18.5927 iter/s, 5.37846s/100 iters), loss = 0.222292
I1001 17:33:59.350484  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222292 (* 1 = 0.222292 loss)
I1001 17:33:59.350489  5416 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1001 17:34:04.665206  5416 solver.cpp:218] Iteration 17200 (18.8157 iter/s, 5.3147s/100 iters), loss = 0.210101
I1001 17:34:04.665246  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210101 (* 1 = 0.210101 loss)
I1001 17:34:04.665252  5416 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1001 17:34:09.902689  5416 solver.cpp:218] Iteration 17300 (19.0934 iter/s, 5.23742s/100 iters), loss = 0.2662
I1001 17:34:09.902719  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2662 (* 1 = 0.2662 loss)
I1001 17:34:09.902734  5416 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1001 17:34:15.166159  5416 solver.cpp:218] Iteration 17400 (18.9991 iter/s, 5.26342s/100 iters), loss = 0.336324
I1001 17:34:15.166334  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336324 (* 1 = 0.336324 loss)
I1001 17:34:15.166347  5416 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1001 17:34:20.170963  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:34:20.379776  5416 solver.cpp:330] Iteration 17500, Testing net (#0)
I1001 17:34:21.571390  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:34:21.621306  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7321
I1001 17:34:21.621332  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.91716 (* 1 = 0.91716 loss)
I1001 17:34:21.673410  5416 solver.cpp:218] Iteration 17500 (15.3679 iter/s, 6.50707s/100 iters), loss = 0.188263
I1001 17:34:21.673434  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188263 (* 1 = 0.188263 loss)
I1001 17:34:21.673441  5416 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1001 17:34:26.938189  5416 solver.cpp:218] Iteration 17600 (18.9943 iter/s, 5.26473s/100 iters), loss = 0.238182
I1001 17:34:26.938237  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238182 (* 1 = 0.238182 loss)
I1001 17:34:26.938256  5416 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1001 17:34:32.343961  5416 solver.cpp:218] Iteration 17700 (18.499 iter/s, 5.4057s/100 iters), loss = 0.273103
I1001 17:34:32.343991  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273103 (* 1 = 0.273103 loss)
I1001 17:34:32.343997  5416 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1001 17:34:37.597412  5416 solver.cpp:218] Iteration 17800 (19.0353 iter/s, 5.2534s/100 iters), loss = 0.220969
I1001 17:34:37.597442  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220969 (* 1 = 0.220969 loss)
I1001 17:34:37.597460  5416 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1001 17:34:42.842433  5416 solver.cpp:218] Iteration 17900 (19.0659 iter/s, 5.24497s/100 iters), loss = 0.208938
I1001 17:34:42.842464  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208938 (* 1 = 0.208938 loss)
I1001 17:34:42.842471  5416 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1001 17:34:47.900790  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:34:48.116322  5416 solver.cpp:330] Iteration 18000, Testing net (#0)
I1001 17:34:49.309164  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:34:49.359731  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7535
I1001 17:34:49.359756  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.900202 (* 1 = 0.900202 loss)
I1001 17:34:49.412739  5416 solver.cpp:218] Iteration 18000 (15.2201 iter/s, 6.57025s/100 iters), loss = 0.138139
I1001 17:34:49.412781  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138139 (* 1 = 0.138139 loss)
I1001 17:34:49.412788  5416 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1001 17:34:54.664968  5416 solver.cpp:218] Iteration 18100 (19.0398 iter/s, 5.25217s/100 iters), loss = 0.28833
I1001 17:34:54.664996  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28833 (* 1 = 0.28833 loss)
I1001 17:34:54.665002  5416 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1001 17:34:59.904652  5416 solver.cpp:218] Iteration 18200 (19.0853 iter/s, 5.23963s/100 iters), loss = 0.360657
I1001 17:34:59.904685  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360657 (* 1 = 0.360657 loss)
I1001 17:34:59.904690  5416 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1001 17:35:05.134344  5416 solver.cpp:218] Iteration 18300 (19.1218 iter/s, 5.22964s/100 iters), loss = 0.216995
I1001 17:35:05.134374  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216995 (* 1 = 0.216995 loss)
I1001 17:35:05.134379  5416 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1001 17:35:10.370643  5416 solver.cpp:218] Iteration 18400 (19.0976 iter/s, 5.23625s/100 iters), loss = 0.301
I1001 17:35:10.370683  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301 (* 1 = 0.301 loss)
I1001 17:35:10.370689  5416 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1001 17:35:15.348572  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:35:15.557864  5416 solver.cpp:330] Iteration 18500, Testing net (#0)
I1001 17:35:16.743878  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:35:16.793565  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7319
I1001 17:35:16.793601  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.95521 (* 1 = 0.95521 loss)
I1001 17:35:16.845667  5416 solver.cpp:218] Iteration 18500 (15.4441 iter/s, 6.47496s/100 iters), loss = 0.165418
I1001 17:35:16.845692  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165418 (* 1 = 0.165418 loss)
I1001 17:35:16.845698  5416 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1001 17:35:22.084764  5416 solver.cpp:218] Iteration 18600 (19.0874 iter/s, 5.23905s/100 iters), loss = 0.2114
I1001 17:35:22.084918  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2114 (* 1 = 0.2114 loss)
I1001 17:35:22.084926  5416 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1001 17:35:27.320320  5416 solver.cpp:218] Iteration 18700 (19.1008 iter/s, 5.23538s/100 iters), loss = 0.381496
I1001 17:35:27.320361  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381496 (* 1 = 0.381496 loss)
I1001 17:35:27.320369  5416 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1001 17:35:32.552618  5416 solver.cpp:218] Iteration 18800 (19.1123 iter/s, 5.23222s/100 iters), loss = 0.264758
I1001 17:35:32.552680  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264757 (* 1 = 0.264757 loss)
I1001 17:35:32.552690  5416 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1001 17:35:37.780059  5416 solver.cpp:218] Iteration 18900 (19.1302 iter/s, 5.22734s/100 iters), loss = 0.264559
I1001 17:35:37.780098  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264558 (* 1 = 0.264558 loss)
I1001 17:35:37.780103  5416 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1001 17:35:42.755280  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:35:42.964130  5416 solver.cpp:330] Iteration 19000, Testing net (#0)
I1001 17:35:44.149838  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:35:44.199506  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6671
I1001 17:35:44.199540  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14642 (* 1 = 1.14642 loss)
I1001 17:35:44.251715  5416 solver.cpp:218] Iteration 19000 (15.4521 iter/s, 6.4716s/100 iters), loss = 0.126126
I1001 17:35:44.251749  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126126 (* 1 = 0.126126 loss)
I1001 17:35:44.251756  5416 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1001 17:35:49.483206  5416 solver.cpp:218] Iteration 19100 (19.1152 iter/s, 5.23143s/100 iters), loss = 0.280245
I1001 17:35:49.483247  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280245 (* 1 = 0.280245 loss)
I1001 17:35:49.483253  5416 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1001 17:35:54.745628  5416 solver.cpp:218] Iteration 19200 (19.0029 iter/s, 5.26236s/100 iters), loss = 0.213404
I1001 17:35:54.745769  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213404 (* 1 = 0.213404 loss)
I1001 17:35:54.745776  5416 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1001 17:35:59.997826  5416 solver.cpp:218] Iteration 19300 (19.0402 iter/s, 5.25203s/100 iters), loss = 0.240375
I1001 17:35:59.997858  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240375 (* 1 = 0.240375 loss)
I1001 17:35:59.997864  5416 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1001 17:36:05.285557  5416 solver.cpp:218] Iteration 19400 (18.9119 iter/s, 5.28768s/100 iters), loss = 0.185502
I1001 17:36:05.285586  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185502 (* 1 = 0.185502 loss)
I1001 17:36:05.285603  5416 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1001 17:36:10.322624  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:36:10.542582  5416 solver.cpp:330] Iteration 19500, Testing net (#0)
I1001 17:36:11.740381  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:36:11.790277  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7327
I1001 17:36:11.790302  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.849913 (* 1 = 0.849913 loss)
I1001 17:36:11.842638  5416 solver.cpp:218] Iteration 19500 (15.2508 iter/s, 6.55703s/100 iters), loss = 0.180321
I1001 17:36:11.842669  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180321 (* 1 = 0.180321 loss)
I1001 17:36:11.842675  5416 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1001 17:36:17.110097  5416 solver.cpp:218] Iteration 19600 (18.9847 iter/s, 5.26741s/100 iters), loss = 0.28873
I1001 17:36:17.110143  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28873 (* 1 = 0.28873 loss)
I1001 17:36:17.110160  5416 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1001 17:36:22.361371  5416 solver.cpp:218] Iteration 19700 (19.0432 iter/s, 5.25121s/100 iters), loss = 0.32865
I1001 17:36:22.361404  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32865 (* 1 = 0.32865 loss)
I1001 17:36:22.361421  5416 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1001 17:36:27.614466  5416 solver.cpp:218] Iteration 19800 (19.0366 iter/s, 5.25304s/100 iters), loss = 0.34167
I1001 17:36:27.614575  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341669 (* 1 = 0.341669 loss)
I1001 17:36:27.614593  5416 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1001 17:36:32.865514  5416 solver.cpp:218] Iteration 19900 (19.0443 iter/s, 5.25092s/100 iters), loss = 0.174944
I1001 17:36:32.865556  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174944 (* 1 = 0.174944 loss)
I1001 17:36:32.865563  5416 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1001 17:36:37.837610  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:36:38.047256  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_20000.caffemodel
I1001 17:36:38.052089  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_20000.solverstate
I1001 17:36:38.053428  5416 solver.cpp:330] Iteration 20000, Testing net (#0)
I1001 17:36:39.246202  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:36:39.296329  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7577
I1001 17:36:39.296365  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.828713 (* 1 = 0.828713 loss)
I1001 17:36:39.348811  5416 solver.cpp:218] Iteration 20000 (15.4244 iter/s, 6.48323s/100 iters), loss = 0.261192
I1001 17:36:39.348836  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261192 (* 1 = 0.261192 loss)
I1001 17:36:39.348843  5416 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1001 17:36:44.646288  5416 solver.cpp:218] Iteration 20100 (18.8771 iter/s, 5.29743s/100 iters), loss = 0.282527
I1001 17:36:44.646335  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282527 (* 1 = 0.282527 loss)
I1001 17:36:44.646343  5416 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1001 17:36:49.934166  5416 solver.cpp:218] Iteration 20200 (18.9115 iter/s, 5.28778s/100 iters), loss = 0.308003
I1001 17:36:49.934211  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308003 (* 1 = 0.308003 loss)
I1001 17:36:49.934218  5416 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1001 17:36:55.218180  5416 solver.cpp:218] Iteration 20300 (18.9252 iter/s, 5.28395s/100 iters), loss = 0.239661
I1001 17:36:55.218214  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239661 (* 1 = 0.239661 loss)
I1001 17:36:55.218220  5416 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1001 17:37:00.506984  5416 solver.cpp:218] Iteration 20400 (18.9084 iter/s, 5.28864s/100 iters), loss = 0.255634
I1001 17:37:00.507122  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255634 (* 1 = 0.255634 loss)
I1001 17:37:00.507133  5416 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1001 17:37:05.532166  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:37:05.746713  5416 solver.cpp:330] Iteration 20500, Testing net (#0)
I1001 17:37:06.944285  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:37:06.994709  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6768
I1001 17:37:06.994752  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.20425 (* 1 = 1.20425 loss)
I1001 17:37:07.047230  5416 solver.cpp:218] Iteration 20500 (15.2903 iter/s, 6.54009s/100 iters), loss = 0.194199
I1001 17:37:07.047256  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194198 (* 1 = 0.194198 loss)
I1001 17:37:07.047262  5416 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1001 17:37:12.352856  5416 solver.cpp:218] Iteration 20600 (18.8481 iter/s, 5.30558s/100 iters), loss = 0.255348
I1001 17:37:12.352900  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255347 (* 1 = 0.255347 loss)
I1001 17:37:12.352907  5416 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1001 17:37:17.651445  5416 solver.cpp:218] Iteration 20700 (18.8732 iter/s, 5.29852s/100 iters), loss = 0.258593
I1001 17:37:17.651481  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258592 (* 1 = 0.258592 loss)
I1001 17:37:17.651489  5416 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1001 17:37:22.914458  5416 solver.cpp:218] Iteration 20800 (19.0007 iter/s, 5.26295s/100 iters), loss = 0.34123
I1001 17:37:22.914499  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34123 (* 1 = 0.34123 loss)
I1001 17:37:22.914505  5416 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1001 17:37:28.228256  5416 solver.cpp:218] Iteration 20900 (18.8191 iter/s, 5.31375s/100 iters), loss = 0.255164
I1001 17:37:28.228286  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255164 (* 1 = 0.255164 loss)
I1001 17:37:28.228292  5416 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1001 17:37:33.256813  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:37:33.467169  5416 solver.cpp:330] Iteration 21000, Testing net (#0)
I1001 17:37:34.671430  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:37:34.721876  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7246
I1001 17:37:34.721912  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.963771 (* 1 = 0.963771 loss)
I1001 17:37:34.774173  5416 solver.cpp:218] Iteration 21000 (15.2768 iter/s, 6.54586s/100 iters), loss = 0.190048
I1001 17:37:34.774195  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190047 (* 1 = 0.190047 loss)
I1001 17:37:34.774202  5416 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1001 17:37:40.092026  5416 solver.cpp:218] Iteration 21100 (18.8047 iter/s, 5.31781s/100 iters), loss = 0.263634
I1001 17:37:40.092056  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263634 (* 1 = 0.263634 loss)
I1001 17:37:40.092072  5416 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1001 17:37:45.397521  5416 solver.cpp:218] Iteration 21200 (18.8486 iter/s, 5.30544s/100 iters), loss = 0.252433
I1001 17:37:45.397557  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252433 (* 1 = 0.252433 loss)
I1001 17:37:45.397564  5416 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1001 17:37:50.699762  5416 solver.cpp:218] Iteration 21300 (18.8602 iter/s, 5.30218s/100 iters), loss = 0.226468
I1001 17:37:50.699798  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226467 (* 1 = 0.226467 loss)
I1001 17:37:50.699805  5416 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1001 17:37:55.995218  5416 solver.cpp:218] Iteration 21400 (18.8843 iter/s, 5.2954s/100 iters), loss = 0.241251
I1001 17:37:55.995247  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24125 (* 1 = 0.24125 loss)
I1001 17:37:55.995254  5416 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1001 17:38:01.042639  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:38:01.253815  5416 solver.cpp:330] Iteration 21500, Testing net (#0)
I1001 17:38:02.457105  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:38:02.508371  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.746
I1001 17:38:02.508424  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.957101 (* 1 = 0.957101 loss)
I1001 17:38:02.562523  5416 solver.cpp:218] Iteration 21500 (15.2271 iter/s, 6.56725s/100 iters), loss = 0.187469
I1001 17:38:02.562563  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187469 (* 1 = 0.187469 loss)
I1001 17:38:02.562583  5416 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1001 17:38:07.863859  5416 solver.cpp:218] Iteration 21600 (18.8635 iter/s, 5.30124s/100 iters), loss = 0.265778
I1001 17:38:07.863997  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265777 (* 1 = 0.265777 loss)
I1001 17:38:07.864006  5416 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1001 17:38:13.168700  5416 solver.cpp:218] Iteration 21700 (18.8513 iter/s, 5.30467s/100 iters), loss = 0.378055
I1001 17:38:13.168740  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378055 (* 1 = 0.378055 loss)
I1001 17:38:13.168747  5416 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1001 17:38:18.460358  5416 solver.cpp:218] Iteration 21800 (18.8979 iter/s, 5.29159s/100 iters), loss = 0.280872
I1001 17:38:18.460388  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280871 (* 1 = 0.280871 loss)
I1001 17:38:18.460404  5416 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1001 17:38:23.763681  5416 solver.cpp:218] Iteration 21900 (18.8563 iter/s, 5.30326s/100 iters), loss = 0.232956
I1001 17:38:23.763732  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232955 (* 1 = 0.232955 loss)
I1001 17:38:23.763739  5416 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1001 17:38:28.812398  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:38:29.021260  5416 solver.cpp:330] Iteration 22000, Testing net (#0)
I1001 17:38:30.229681  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:38:30.280644  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7379
I1001 17:38:30.280669  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.871353 (* 1 = 0.871353 loss)
I1001 17:38:30.335621  5416 solver.cpp:218] Iteration 22000 (15.2164 iter/s, 6.57186s/100 iters), loss = 0.180629
I1001 17:38:30.335656  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180628 (* 1 = 0.180628 loss)
I1001 17:38:30.335664  5416 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1001 17:38:35.648224  5416 solver.cpp:218] Iteration 22100 (18.8234 iter/s, 5.31253s/100 iters), loss = 0.293559
I1001 17:38:35.648288  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293558 (* 1 = 0.293558 loss)
I1001 17:38:35.648299  5416 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1001 17:38:40.943337  5416 solver.cpp:218] Iteration 22200 (18.8857 iter/s, 5.29501s/100 iters), loss = 0.326236
I1001 17:38:40.943493  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326235 (* 1 = 0.326235 loss)
I1001 17:38:40.943502  5416 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1001 17:38:46.239004  5416 solver.cpp:218] Iteration 22300 (18.884 iter/s, 5.29549s/100 iters), loss = 0.211192
I1001 17:38:46.239037  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211191 (* 1 = 0.211191 loss)
I1001 17:38:46.239045  5416 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1001 17:38:51.542414  5416 solver.cpp:218] Iteration 22400 (18.856 iter/s, 5.30335s/100 iters), loss = 0.182812
I1001 17:38:51.542449  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182811 (* 1 = 0.182811 loss)
I1001 17:38:51.542456  5416 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1001 17:38:56.581349  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:38:56.794724  5416 solver.cpp:330] Iteration 22500, Testing net (#0)
I1001 17:38:58.004377  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:38:58.054463  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7405
I1001 17:38:58.054487  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.887459 (* 1 = 0.887459 loss)
I1001 17:38:58.106850  5416 solver.cpp:218] Iteration 22500 (15.2337 iter/s, 6.56438s/100 iters), loss = 0.246535
I1001 17:38:58.106883  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246534 (* 1 = 0.246534 loss)
I1001 17:38:58.106890  5416 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1001 17:39:03.412698  5416 solver.cpp:218] Iteration 22600 (18.8473 iter/s, 5.3058s/100 iters), loss = 0.25894
I1001 17:39:03.412726  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258939 (* 1 = 0.258939 loss)
I1001 17:39:03.412732  5416 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1001 17:39:08.707034  5416 solver.cpp:218] Iteration 22700 (18.8883 iter/s, 5.29428s/100 iters), loss = 0.311683
I1001 17:39:08.707068  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311683 (* 1 = 0.311683 loss)
I1001 17:39:08.707075  5416 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1001 17:39:14.005429  5416 solver.cpp:218] Iteration 22800 (18.8738 iter/s, 5.29834s/100 iters), loss = 0.320466
I1001 17:39:14.005595  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320466 (* 1 = 0.320466 loss)
I1001 17:39:14.005604  5416 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1001 17:39:19.314700  5416 solver.cpp:218] Iteration 22900 (18.8356 iter/s, 5.30908s/100 iters), loss = 0.172522
I1001 17:39:19.314734  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172522 (* 1 = 0.172522 loss)
I1001 17:39:19.314741  5416 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1001 17:39:24.345944  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:39:24.555490  5416 solver.cpp:330] Iteration 23000, Testing net (#0)
I1001 17:39:25.774626  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:39:25.825250  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7339
I1001 17:39:25.825275  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.871272 (* 1 = 0.871272 loss)
I1001 17:39:25.876961  5416 solver.cpp:218] Iteration 23000 (15.2388 iter/s, 6.56221s/100 iters), loss = 0.149631
I1001 17:39:25.876991  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14963 (* 1 = 0.14963 loss)
I1001 17:39:25.876997  5416 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1001 17:39:31.148892  5416 solver.cpp:218] Iteration 23100 (18.9686 iter/s, 5.27188s/100 iters), loss = 0.287655
I1001 17:39:31.148923  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287654 (* 1 = 0.287654 loss)
I1001 17:39:31.148929  5416 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1001 17:39:36.434976  5416 solver.cpp:218] Iteration 23200 (18.9178 iter/s, 5.28603s/100 iters), loss = 0.230191
I1001 17:39:36.435008  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23019 (* 1 = 0.23019 loss)
I1001 17:39:36.435014  5416 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1001 17:39:41.746740  5416 solver.cpp:218] Iteration 23300 (18.8264 iter/s, 5.3117s/100 iters), loss = 0.265487
I1001 17:39:41.746780  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265487 (* 1 = 0.265487 loss)
I1001 17:39:41.746790  5416 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1001 17:39:47.037348  5416 solver.cpp:218] Iteration 23400 (18.9016 iter/s, 5.29054s/100 iters), loss = 0.214676
I1001 17:39:47.037503  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214676 (* 1 = 0.214676 loss)
I1001 17:39:47.037530  5416 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1001 17:39:52.052291  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:39:52.263123  5416 solver.cpp:330] Iteration 23500, Testing net (#0)
I1001 17:39:53.453598  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:39:53.504386  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6925
I1001 17:39:53.504416  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10413 (* 1 = 1.10413 loss)
I1001 17:39:53.557759  5416 solver.cpp:218] Iteration 23500 (15.3369 iter/s, 6.52024s/100 iters), loss = 0.142402
I1001 17:39:53.557797  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142401 (* 1 = 0.142401 loss)
I1001 17:39:53.557806  5416 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1001 17:39:58.880385  5416 solver.cpp:218] Iteration 23600 (18.788 iter/s, 5.32256s/100 iters), loss = 0.222237
I1001 17:39:58.880425  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222236 (* 1 = 0.222236 loss)
I1001 17:39:58.880450  5416 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1001 17:40:04.151753  5416 solver.cpp:218] Iteration 23700 (18.9712 iter/s, 5.27116s/100 iters), loss = 0.275799
I1001 17:40:04.151783  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275798 (* 1 = 0.275798 loss)
I1001 17:40:04.151789  5416 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1001 17:40:09.448192  5416 solver.cpp:218] Iteration 23800 (18.8808 iter/s, 5.29639s/100 iters), loss = 0.271965
I1001 17:40:09.448228  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271964 (* 1 = 0.271964 loss)
I1001 17:40:09.448235  5416 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1001 17:40:14.711477  5416 solver.cpp:218] Iteration 23900 (18.9998 iter/s, 5.26322s/100 iters), loss = 0.173434
I1001 17:40:14.711510  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173434 (* 1 = 0.173434 loss)
I1001 17:40:14.711519  5416 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1001 17:40:19.753211  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:40:19.963599  5416 solver.cpp:330] Iteration 24000, Testing net (#0)
I1001 17:40:21.172300  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:40:21.222467  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6884
I1001 17:40:21.222502  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31606 (* 1 = 1.31606 loss)
I1001 17:40:21.274529  5416 solver.cpp:218] Iteration 24000 (15.2369 iter/s, 6.563s/100 iters), loss = 0.169837
I1001 17:40:21.274559  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169837 (* 1 = 0.169837 loss)
I1001 17:40:21.274565  5416 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1001 17:40:26.573299  5416 solver.cpp:218] Iteration 24100 (18.8725 iter/s, 5.29871s/100 iters), loss = 0.228601
I1001 17:40:26.573345  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228601 (* 1 = 0.228601 loss)
I1001 17:40:26.573352  5416 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1001 17:40:31.844450  5416 solver.cpp:218] Iteration 24200 (18.9715 iter/s, 5.27105s/100 iters), loss = 0.284038
I1001 17:40:31.844480  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284037 (* 1 = 0.284037 loss)
I1001 17:40:31.844486  5416 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1001 17:40:37.107511  5416 solver.cpp:218] Iteration 24300 (19.0005 iter/s, 5.26301s/100 iters), loss = 0.310742
I1001 17:40:37.107553  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310741 (* 1 = 0.310741 loss)
I1001 17:40:37.107560  5416 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1001 17:40:42.414760  5416 solver.cpp:218] Iteration 24400 (18.8428 iter/s, 5.30707s/100 iters), loss = 0.200364
I1001 17:40:42.414803  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200363 (* 1 = 0.200363 loss)
I1001 17:40:42.414809  5416 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1001 17:40:47.437224  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:40:47.655336  5416 solver.cpp:330] Iteration 24500, Testing net (#0)
I1001 17:40:48.850766  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:40:48.900187  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7308
I1001 17:40:48.900220  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.932657 (* 1 = 0.932657 loss)
I1001 17:40:48.952538  5416 solver.cpp:218] Iteration 24500 (15.2959 iter/s, 6.53771s/100 iters), loss = 0.216517
I1001 17:40:48.952565  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216517 (* 1 = 0.216517 loss)
I1001 17:40:48.952572  5416 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1001 17:40:54.248184  5416 solver.cpp:218] Iteration 24600 (18.8836 iter/s, 5.29559s/100 iters), loss = 0.180534
I1001 17:40:54.248363  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180534 (* 1 = 0.180534 loss)
I1001 17:40:54.248371  5416 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1001 17:40:59.537879  5416 solver.cpp:218] Iteration 24700 (18.9054 iter/s, 5.28949s/100 iters), loss = 0.285473
I1001 17:40:59.537926  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285472 (* 1 = 0.285472 loss)
I1001 17:40:59.537945  5416 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1001 17:41:04.834192  5416 solver.cpp:218] Iteration 24800 (18.8814 iter/s, 5.29621s/100 iters), loss = 0.23804
I1001 17:41:04.834231  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23804 (* 1 = 0.23804 loss)
I1001 17:41:04.834237  5416 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1001 17:41:10.116122  5416 solver.cpp:218] Iteration 24900 (18.9327 iter/s, 5.28186s/100 iters), loss = 0.149383
I1001 17:41:10.116156  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149383 (* 1 = 0.149383 loss)
I1001 17:41:10.116163  5416 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1001 17:41:15.128813  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:41:15.337299  5416 solver.cpp:330] Iteration 25000, Testing net (#0)
I1001 17:41:16.543759  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:41:16.594770  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6539
I1001 17:41:16.594806  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.30431 (* 1 = 1.30431 loss)
I1001 17:41:16.648519  5416 solver.cpp:218] Iteration 25000 (15.3086 iter/s, 6.53229s/100 iters), loss = 0.144065
I1001 17:41:16.648561  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144065 (* 1 = 0.144065 loss)
I1001 17:41:16.648567  5416 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1001 17:41:21.936731  5416 solver.cpp:218] Iteration 25100 (18.9102 iter/s, 5.28815s/100 iters), loss = 0.223984
I1001 17:41:21.936774  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223984 (* 1 = 0.223984 loss)
I1001 17:41:21.936780  5416 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1001 17:41:27.229948  5416 solver.cpp:218] Iteration 25200 (18.8923 iter/s, 5.29315s/100 iters), loss = 0.245281
I1001 17:41:27.230060  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24528 (* 1 = 0.24528 loss)
I1001 17:41:27.230078  5416 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1001 17:41:32.457934  5416 solver.cpp:218] Iteration 25300 (19.1283 iter/s, 5.22786s/100 iters), loss = 0.401493
I1001 17:41:32.457983  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401493 (* 1 = 0.401493 loss)
I1001 17:41:32.457990  5416 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1001 17:41:37.712594  5416 solver.cpp:218] Iteration 25400 (19.0311 iter/s, 5.25455s/100 iters), loss = 0.179749
I1001 17:41:37.712623  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179748 (* 1 = 0.179748 loss)
I1001 17:41:37.712630  5416 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1001 17:41:42.756789  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:41:42.966109  5416 solver.cpp:330] Iteration 25500, Testing net (#0)
I1001 17:41:44.160271  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:41:44.210136  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7531
I1001 17:41:44.210172  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.783931 (* 1 = 0.783931 loss)
I1001 17:41:44.264380  5416 solver.cpp:218] Iteration 25500 (15.2631 iter/s, 6.55173s/100 iters), loss = 0.124121
I1001 17:41:44.264425  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124121 (* 1 = 0.124121 loss)
I1001 17:41:44.264432  5416 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1001 17:41:49.580966  5416 solver.cpp:218] Iteration 25600 (18.8093 iter/s, 5.31652s/100 iters), loss = 0.245142
I1001 17:41:49.581006  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245141 (* 1 = 0.245141 loss)
I1001 17:41:49.581012  5416 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1001 17:41:54.865697  5416 solver.cpp:218] Iteration 25700 (18.9227 iter/s, 5.28467s/100 iters), loss = 0.299016
I1001 17:41:54.865737  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299015 (* 1 = 0.299015 loss)
I1001 17:41:54.865743  5416 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1001 17:42:00.191241  5416 solver.cpp:218] Iteration 25800 (18.7777 iter/s, 5.32548s/100 iters), loss = 0.298742
I1001 17:42:00.191365  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298742 (* 1 = 0.298742 loss)
I1001 17:42:00.191372  5416 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1001 17:42:05.490406  5416 solver.cpp:218] Iteration 25900 (18.8714 iter/s, 5.29902s/100 iters), loss = 0.206083
I1001 17:42:05.490442  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206083 (* 1 = 0.206083 loss)
I1001 17:42:05.490448  5416 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1001 17:42:10.496945  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:42:10.706101  5416 solver.cpp:330] Iteration 26000, Testing net (#0)
I1001 17:42:11.913034  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:42:11.964612  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6733
I1001 17:42:11.964639  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11379 (* 1 = 1.11379 loss)
I1001 17:42:12.018869  5416 solver.cpp:218] Iteration 26000 (15.3177 iter/s, 6.5284s/100 iters), loss = 0.174829
I1001 17:42:12.018916  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174828 (* 1 = 0.174828 loss)
I1001 17:42:12.018923  5416 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1001 17:42:17.315665  5416 solver.cpp:218] Iteration 26100 (18.8796 iter/s, 5.29672s/100 iters), loss = 0.176106
I1001 17:42:17.315704  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176106 (* 1 = 0.176106 loss)
I1001 17:42:17.315711  5416 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1001 17:42:22.578955  5416 solver.cpp:218] Iteration 26200 (18.9997 iter/s, 5.26323s/100 iters), loss = 0.227809
I1001 17:42:22.578994  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227809 (* 1 = 0.227809 loss)
I1001 17:42:22.579001  5416 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1001 17:42:27.883153  5416 solver.cpp:218] Iteration 26300 (18.8532 iter/s, 5.30414s/100 iters), loss = 0.215371
I1001 17:42:27.883196  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21537 (* 1 = 0.21537 loss)
I1001 17:42:27.883203  5416 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1001 17:42:33.181952  5416 solver.cpp:218] Iteration 26400 (18.8725 iter/s, 5.2987s/100 iters), loss = 0.244609
I1001 17:42:33.182116  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244608 (* 1 = 0.244608 loss)
I1001 17:42:33.182123  5416 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1001 17:42:38.175678  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:42:38.384786  5416 solver.cpp:330] Iteration 26500, Testing net (#0)
I1001 17:42:39.581035  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:42:39.630931  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8124
I1001 17:42:39.630965  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.574183 (* 1 = 0.574183 loss)
I1001 17:42:39.683198  5416 solver.cpp:218] Iteration 26500 (15.3821 iter/s, 6.50107s/100 iters), loss = 0.173911
I1001 17:42:39.683223  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17391 (* 1 = 0.17391 loss)
I1001 17:42:39.683228  5416 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1001 17:42:44.922507  5416 solver.cpp:218] Iteration 26600 (19.0867 iter/s, 5.23926s/100 iters), loss = 0.182713
I1001 17:42:44.922549  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182713 (* 1 = 0.182713 loss)
I1001 17:42:44.922556  5416 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1001 17:42:50.150248  5416 solver.cpp:218] Iteration 26700 (19.129 iter/s, 5.22768s/100 iters), loss = 0.22985
I1001 17:42:50.150287  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22985 (* 1 = 0.22985 loss)
I1001 17:42:50.150293  5416 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1001 17:42:55.384124  5416 solver.cpp:218] Iteration 26800 (19.1065 iter/s, 5.23381s/100 iters), loss = 0.324838
I1001 17:42:55.384165  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324838 (* 1 = 0.324838 loss)
I1001 17:42:55.384171  5416 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1001 17:43:00.620144  5416 solver.cpp:218] Iteration 26900 (19.0987 iter/s, 5.23596s/100 iters), loss = 0.23344
I1001 17:43:00.620184  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233439 (* 1 = 0.233439 loss)
I1001 17:43:00.620190  5416 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1001 17:43:05.632551  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:43:05.851752  5416 solver.cpp:330] Iteration 27000, Testing net (#0)
I1001 17:43:07.055027  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:43:07.105161  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.708
I1001 17:43:07.105197  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01669 (* 1 = 1.01669 loss)
I1001 17:43:07.158252  5416 solver.cpp:218] Iteration 27000 (15.2951 iter/s, 6.53804s/100 iters), loss = 0.192755
I1001 17:43:07.158285  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192754 (* 1 = 0.192754 loss)
I1001 17:43:07.158291  5416 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1001 17:43:12.445016  5416 solver.cpp:218] Iteration 27100 (18.9154 iter/s, 5.28671s/100 iters), loss = 0.23343
I1001 17:43:12.445046  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233429 (* 1 = 0.233429 loss)
I1001 17:43:12.445053  5416 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1001 17:43:17.739326  5416 solver.cpp:218] Iteration 27200 (18.8884 iter/s, 5.29425s/100 iters), loss = 0.267362
I1001 17:43:17.739370  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267362 (* 1 = 0.267362 loss)
I1001 17:43:17.739378  5416 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1001 17:43:23.030169  5416 solver.cpp:218] Iteration 27300 (18.9009 iter/s, 5.29074s/100 iters), loss = 0.213231
I1001 17:43:23.030210  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21323 (* 1 = 0.21323 loss)
I1001 17:43:23.030216  5416 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1001 17:43:28.320742  5416 solver.cpp:218] Iteration 27400 (18.9018 iter/s, 5.29051s/100 iters), loss = 0.123587
I1001 17:43:28.320776  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123586 (* 1 = 0.123586 loss)
I1001 17:43:28.320783  5416 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1001 17:43:33.365838  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:43:33.578802  5416 solver.cpp:330] Iteration 27500, Testing net (#0)
I1001 17:43:34.783521  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:43:34.833488  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7212
I1001 17:43:34.833513  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.976717 (* 1 = 0.976717 loss)
I1001 17:43:34.886121  5416 solver.cpp:218] Iteration 27500 (15.2315 iter/s, 6.56532s/100 iters), loss = 0.152372
I1001 17:43:34.886150  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152371 (* 1 = 0.152371 loss)
I1001 17:43:34.886157  5416 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1001 17:43:40.175546  5416 solver.cpp:218] Iteration 27600 (18.9058 iter/s, 5.28937s/100 iters), loss = 0.230385
I1001 17:43:40.175731  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230384 (* 1 = 0.230384 loss)
I1001 17:43:40.175740  5416 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1001 17:43:45.468526  5416 solver.cpp:218] Iteration 27700 (18.8937 iter/s, 5.29278s/100 iters), loss = 0.269427
I1001 17:43:45.468556  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269427 (* 1 = 0.269427 loss)
I1001 17:43:45.468562  5416 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1001 17:43:50.736085  5416 solver.cpp:218] Iteration 27800 (18.9843 iter/s, 5.2675s/100 iters), loss = 0.28974
I1001 17:43:50.736129  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289739 (* 1 = 0.289739 loss)
I1001 17:43:50.736136  5416 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1001 17:43:56.011278  5416 solver.cpp:218] Iteration 27900 (18.957 iter/s, 5.27509s/100 iters), loss = 0.244218
I1001 17:43:56.011312  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244218 (* 1 = 0.244218 loss)
I1001 17:43:56.011317  5416 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1001 17:44:01.042803  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:44:01.251935  5416 solver.cpp:330] Iteration 28000, Testing net (#0)
I1001 17:44:02.459710  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:44:02.511368  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7688
I1001 17:44:02.511397  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739023 (* 1 = 0.739023 loss)
I1001 17:44:02.566123  5416 solver.cpp:218] Iteration 28000 (15.256 iter/s, 6.55478s/100 iters), loss = 0.162879
I1001 17:44:02.566164  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162878 (* 1 = 0.162878 loss)
I1001 17:44:02.566171  5416 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1001 17:44:07.857472  5416 solver.cpp:218] Iteration 28100 (18.8996 iter/s, 5.29111s/100 iters), loss = 0.183674
I1001 17:44:07.857507  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183673 (* 1 = 0.183673 loss)
I1001 17:44:07.857514  5416 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1001 17:44:13.124476  5416 solver.cpp:218] Iteration 28200 (18.9863 iter/s, 5.26695s/100 iters), loss = 0.260616
I1001 17:44:13.124609  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260615 (* 1 = 0.260615 loss)
I1001 17:44:13.124616  5416 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1001 17:44:18.384351  5416 solver.cpp:218] Iteration 28300 (19.0124 iter/s, 5.25973s/100 iters), loss = 0.237549
I1001 17:44:18.384390  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237549 (* 1 = 0.237549 loss)
I1001 17:44:18.384397  5416 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1001 17:44:23.637838  5416 solver.cpp:218] Iteration 28400 (19.0352 iter/s, 5.25342s/100 iters), loss = 0.169462
I1001 17:44:23.637892  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169462 (* 1 = 0.169462 loss)
I1001 17:44:23.637900  5416 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1001 17:44:28.629716  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:44:28.841601  5416 solver.cpp:330] Iteration 28500, Testing net (#0)
I1001 17:44:30.051064  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:44:30.101167  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6834
I1001 17:44:30.101193  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04184 (* 1 = 1.04184 loss)
I1001 17:44:30.153475  5416 solver.cpp:218] Iteration 28500 (15.3479 iter/s, 6.51553s/100 iters), loss = 0.14121
I1001 17:44:30.153501  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141209 (* 1 = 0.141209 loss)
I1001 17:44:30.153507  5416 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1001 17:44:35.430984  5416 solver.cpp:218] Iteration 28600 (18.9485 iter/s, 5.27746s/100 iters), loss = 0.202419
I1001 17:44:35.431015  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202418 (* 1 = 0.202418 loss)
I1001 17:44:35.431022  5416 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1001 17:44:40.706866  5416 solver.cpp:218] Iteration 28700 (18.9544 iter/s, 5.27583s/100 iters), loss = 0.208115
I1001 17:44:40.706907  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208115 (* 1 = 0.208115 loss)
I1001 17:44:40.706912  5416 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1001 17:44:45.954612  5416 solver.cpp:218] Iteration 28800 (19.056 iter/s, 5.24768s/100 iters), loss = 0.200492
I1001 17:44:45.954751  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200492 (* 1 = 0.200492 loss)
I1001 17:44:45.954768  5416 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1001 17:44:51.241964  5416 solver.cpp:218] Iteration 28900 (18.9136 iter/s, 5.2872s/100 iters), loss = 0.198423
I1001 17:44:51.241996  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198422 (* 1 = 0.198422 loss)
I1001 17:44:51.242002  5416 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1001 17:44:56.214213  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:44:56.424000  5416 solver.cpp:330] Iteration 29000, Testing net (#0)
I1001 17:44:57.622956  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:44:57.672566  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8124
I1001 17:44:57.672601  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.627748 (* 1 = 0.627748 loss)
I1001 17:44:57.725301  5416 solver.cpp:218] Iteration 29000 (15.4243 iter/s, 6.48328s/100 iters), loss = 0.174041
I1001 17:44:57.725335  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17404 (* 1 = 0.17404 loss)
I1001 17:44:57.725342  5416 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1001 17:45:03.008828  5416 solver.cpp:218] Iteration 29100 (18.927 iter/s, 5.28347s/100 iters), loss = 0.197726
I1001 17:45:03.008862  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197726 (* 1 = 0.197726 loss)
I1001 17:45:03.008879  5416 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1001 17:45:08.320101  5416 solver.cpp:218] Iteration 29200 (18.8281 iter/s, 5.31122s/100 iters), loss = 0.231663
I1001 17:45:08.320134  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231663 (* 1 = 0.231663 loss)
I1001 17:45:08.320142  5416 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1001 17:45:13.604195  5416 solver.cpp:218] Iteration 29300 (18.9249 iter/s, 5.28404s/100 iters), loss = 0.226507
I1001 17:45:13.604225  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226507 (* 1 = 0.226507 loss)
I1001 17:45:13.604231  5416 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1001 17:45:18.862901  5416 solver.cpp:218] Iteration 29400 (19.0163 iter/s, 5.25865s/100 iters), loss = 0.197186
I1001 17:45:18.862989  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197186 (* 1 = 0.197186 loss)
I1001 17:45:18.862996  5416 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1001 17:45:23.848801  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:45:24.059454  5416 solver.cpp:330] Iteration 29500, Testing net (#0)
I1001 17:45:25.248585  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:45:25.298847  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6284
I1001 17:45:25.298871  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48099 (* 1 = 1.48099 loss)
I1001 17:45:25.351006  5416 solver.cpp:218] Iteration 29500 (15.4131 iter/s, 6.488s/100 iters), loss = 0.234521
I1001 17:45:25.351030  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234521 (* 1 = 0.234521 loss)
I1001 17:45:25.351037  5416 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1001 17:45:30.602676  5416 solver.cpp:218] Iteration 29600 (19.0417 iter/s, 5.25163s/100 iters), loss = 0.22218
I1001 17:45:30.602706  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22218 (* 1 = 0.22218 loss)
I1001 17:45:30.602722  5416 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1001 17:45:35.850960  5416 solver.cpp:218] Iteration 29700 (19.0541 iter/s, 5.24823s/100 iters), loss = 0.269546
I1001 17:45:35.850991  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269546 (* 1 = 0.269546 loss)
I1001 17:45:35.851008  5416 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1001 17:45:41.096007  5416 solver.cpp:218] Iteration 29800 (19.0658 iter/s, 5.245s/100 iters), loss = 0.187501
I1001 17:45:41.096038  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1875 (* 1 = 0.1875 loss)
I1001 17:45:41.096055  5416 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1001 17:45:46.349573  5416 solver.cpp:218] Iteration 29900 (19.0349 iter/s, 5.25352s/100 iters), loss = 0.298634
I1001 17:45:46.349603  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298633 (* 1 = 0.298633 loss)
I1001 17:45:46.349618  5416 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1001 17:45:51.339851  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:45:51.548923  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_30000.caffemodel
I1001 17:45:51.553872  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_30000.solverstate
I1001 17:45:51.555269  5416 solver.cpp:330] Iteration 30000, Testing net (#0)
I1001 17:45:52.744531  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:45:52.794787  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5663
I1001 17:45:52.794823  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.68895 (* 1 = 1.68895 loss)
I1001 17:45:52.847352  5416 solver.cpp:218] Iteration 30000 (15.39 iter/s, 6.49773s/100 iters), loss = 0.200512
I1001 17:45:52.847378  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200512 (* 1 = 0.200512 loss)
I1001 17:45:52.847385  5416 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1001 17:45:58.102542  5416 solver.cpp:218] Iteration 30100 (19.029 iter/s, 5.25514s/100 iters), loss = 0.26386
I1001 17:45:58.102572  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263859 (* 1 = 0.263859 loss)
I1001 17:45:58.102589  5416 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1001 17:46:03.354328  5416 solver.cpp:218] Iteration 30200 (19.0413 iter/s, 5.25174s/100 iters), loss = 0.192263
I1001 17:46:03.354359  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192262 (* 1 = 0.192262 loss)
I1001 17:46:03.354365  5416 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1001 17:46:08.602797  5416 solver.cpp:218] Iteration 30300 (19.0534 iter/s, 5.24842s/100 iters), loss = 0.207653
I1001 17:46:08.602840  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207653 (* 1 = 0.207653 loss)
I1001 17:46:08.602847  5416 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1001 17:46:13.851558  5416 solver.cpp:218] Iteration 30400 (19.0524 iter/s, 5.24867s/100 iters), loss = 0.207364
I1001 17:46:13.851588  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207364 (* 1 = 0.207364 loss)
I1001 17:46:13.851595  5416 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1001 17:46:18.836423  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:46:19.046350  5416 solver.cpp:330] Iteration 30500, Testing net (#0)
I1001 17:46:20.236160  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:46:20.286286  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7917
I1001 17:46:20.286321  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648586 (* 1 = 0.648586 loss)
I1001 17:46:20.338904  5416 solver.cpp:218] Iteration 30500 (15.4147 iter/s, 6.4873s/100 iters), loss = 0.239709
I1001 17:46:20.338929  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239709 (* 1 = 0.239709 loss)
I1001 17:46:20.338937  5416 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1001 17:46:25.588075  5416 solver.cpp:218] Iteration 30600 (19.0508 iter/s, 5.24913s/100 iters), loss = 0.237946
I1001 17:46:25.588215  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237946 (* 1 = 0.237946 loss)
I1001 17:46:25.588233  5416 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1001 17:46:30.841783  5416 solver.cpp:218] Iteration 30700 (19.0347 iter/s, 5.25356s/100 iters), loss = 0.381977
I1001 17:46:30.841812  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381976 (* 1 = 0.381976 loss)
I1001 17:46:30.841828  5416 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1001 17:46:36.095796  5416 solver.cpp:218] Iteration 30800 (19.0333 iter/s, 5.25396s/100 iters), loss = 0.28782
I1001 17:46:36.095827  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28782 (* 1 = 0.28782 loss)
I1001 17:46:36.095844  5416 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1001 17:46:41.338426  5416 solver.cpp:218] Iteration 30900 (19.0746 iter/s, 5.24258s/100 iters), loss = 0.215071
I1001 17:46:41.338455  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215071 (* 1 = 0.215071 loss)
I1001 17:46:41.338471  5416 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1001 17:46:46.329253  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:46:46.538719  5416 solver.cpp:330] Iteration 31000, Testing net (#0)
I1001 17:46:47.738320  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:46:47.789288  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6027
I1001 17:46:47.789315  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.77277 (* 1 = 1.77277 loss)
I1001 17:46:47.841919  5416 solver.cpp:218] Iteration 31000 (15.3765 iter/s, 6.50344s/100 iters), loss = 0.122154
I1001 17:46:47.841949  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122153 (* 1 = 0.122153 loss)
I1001 17:46:47.841958  5416 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1001 17:46:53.085960  5416 solver.cpp:218] Iteration 31100 (19.0695 iter/s, 5.24399s/100 iters), loss = 0.170574
I1001 17:46:53.085990  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170574 (* 1 = 0.170574 loss)
I1001 17:46:53.086007  5416 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1001 17:46:58.332406  5416 solver.cpp:218] Iteration 31200 (19.0607 iter/s, 5.2464s/100 iters), loss = 0.277509
I1001 17:46:58.332535  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277508 (* 1 = 0.277508 loss)
I1001 17:46:58.332556  5416 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1001 17:47:03.580869  5416 solver.cpp:218] Iteration 31300 (19.0537 iter/s, 5.24832s/100 iters), loss = 0.223513
I1001 17:47:03.580899  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223513 (* 1 = 0.223513 loss)
I1001 17:47:03.580906  5416 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1001 17:47:08.829869  5416 solver.cpp:218] Iteration 31400 (19.0514 iter/s, 5.24895s/100 iters), loss = 0.135833
I1001 17:47:08.829900  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135832 (* 1 = 0.135832 loss)
I1001 17:47:08.829908  5416 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1001 17:47:13.807971  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:47:14.017868  5416 solver.cpp:330] Iteration 31500, Testing net (#0)
I1001 17:47:15.217245  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:47:15.267402  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7811
I1001 17:47:15.267427  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.759922 (* 1 = 0.759922 loss)
I1001 17:47:15.320154  5416 solver.cpp:218] Iteration 31500 (15.4078 iter/s, 6.49023s/100 iters), loss = 0.164162
I1001 17:47:15.320190  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164162 (* 1 = 0.164162 loss)
I1001 17:47:15.320197  5416 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1001 17:47:20.566458  5416 solver.cpp:218] Iteration 31600 (19.0613 iter/s, 5.24624s/100 iters), loss = 0.237232
I1001 17:47:20.566504  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237232 (* 1 = 0.237232 loss)
I1001 17:47:20.566511  5416 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1001 17:47:25.814776  5416 solver.cpp:218] Iteration 31700 (19.0541 iter/s, 5.24821s/100 iters), loss = 0.331755
I1001 17:47:25.814807  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331755 (* 1 = 0.331755 loss)
I1001 17:47:25.814822  5416 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1001 17:47:31.067844  5416 solver.cpp:218] Iteration 31800 (19.0367 iter/s, 5.25301s/100 iters), loss = 0.421547
I1001 17:47:31.068001  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421546 (* 1 = 0.421546 loss)
I1001 17:47:31.068020  5416 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1001 17:47:36.322695  5416 solver.cpp:218] Iteration 31900 (19.0307 iter/s, 5.25468s/100 iters), loss = 0.217377
I1001 17:47:36.322726  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217377 (* 1 = 0.217377 loss)
I1001 17:47:36.322741  5416 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1001 17:47:41.300860  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:47:41.512285  5416 solver.cpp:330] Iteration 32000, Testing net (#0)
I1001 17:47:42.708494  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:47:42.759081  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6678
I1001 17:47:42.759119  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.19078 (* 1 = 1.19078 loss)
I1001 17:47:42.811617  5416 solver.cpp:218] Iteration 32000 (15.411 iter/s, 6.48887s/100 iters), loss = 0.136176
I1001 17:47:42.811643  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136176 (* 1 = 0.136176 loss)
I1001 17:47:42.811650  5416 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1001 17:47:48.067288  5416 solver.cpp:218] Iteration 32100 (19.0272 iter/s, 5.25562s/100 iters), loss = 0.173835
I1001 17:47:48.067319  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173834 (* 1 = 0.173834 loss)
I1001 17:47:48.067327  5416 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1001 17:47:53.302146  5416 solver.cpp:218] Iteration 32200 (19.1029 iter/s, 5.23481s/100 iters), loss = 0.298035
I1001 17:47:53.302186  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298034 (* 1 = 0.298034 loss)
I1001 17:47:53.302191  5416 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1001 17:47:58.548810  5416 solver.cpp:218] Iteration 32300 (19.0599 iter/s, 5.2466s/100 iters), loss = 0.177004
I1001 17:47:58.548851  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177004 (* 1 = 0.177004 loss)
I1001 17:47:58.548856  5416 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1001 17:48:03.801499  5416 solver.cpp:218] Iteration 32400 (19.0381 iter/s, 5.25263s/100 iters), loss = 0.237299
I1001 17:48:03.801637  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237298 (* 1 = 0.237298 loss)
I1001 17:48:03.801645  5416 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1001 17:48:08.794885  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:48:09.004403  5416 solver.cpp:330] Iteration 32500, Testing net (#0)
I1001 17:48:10.194764  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:48:10.244614  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.656
I1001 17:48:10.244649  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.25674 (* 1 = 1.25674 loss)
I1001 17:48:10.297235  5416 solver.cpp:218] Iteration 32500 (15.3951 iter/s, 6.49559s/100 iters), loss = 0.223198
I1001 17:48:10.297264  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223198 (* 1 = 0.223198 loss)
I1001 17:48:10.297271  5416 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1001 17:48:15.549703  5416 solver.cpp:218] Iteration 32600 (19.0388 iter/s, 5.25242s/100 iters), loss = 0.313166
I1001 17:48:15.549743  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313166 (* 1 = 0.313166 loss)
I1001 17:48:15.549749  5416 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1001 17:48:20.796022  5416 solver.cpp:218] Iteration 32700 (19.0612 iter/s, 5.24625s/100 iters), loss = 0.27015
I1001 17:48:20.796066  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27015 (* 1 = 0.27015 loss)
I1001 17:48:20.796082  5416 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1001 17:48:26.037806  5416 solver.cpp:218] Iteration 32800 (19.0777 iter/s, 5.24172s/100 iters), loss = 0.238675
I1001 17:48:26.037837  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238675 (* 1 = 0.238675 loss)
I1001 17:48:26.037842  5416 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1001 17:48:31.286739  5416 solver.cpp:218] Iteration 32900 (19.0517 iter/s, 5.24888s/100 iters), loss = 0.282171
I1001 17:48:31.286769  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28217 (* 1 = 0.28217 loss)
I1001 17:48:31.286775  5416 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1001 17:48:36.270113  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:48:36.479415  5416 solver.cpp:330] Iteration 33000, Testing net (#0)
I1001 17:48:37.670465  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:48:37.720371  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6796
I1001 17:48:37.720396  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.20011 (* 1 = 1.20011 loss)
I1001 17:48:37.773279  5416 solver.cpp:218] Iteration 33000 (15.4167 iter/s, 6.48649s/100 iters), loss = 0.161031
I1001 17:48:37.773305  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161031 (* 1 = 0.161031 loss)
I1001 17:48:37.773313  5416 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1001 17:48:43.022624  5416 solver.cpp:218] Iteration 33100 (19.0502 iter/s, 5.24929s/100 iters), loss = 0.184111
I1001 17:48:43.022665  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184111 (* 1 = 0.184111 loss)
I1001 17:48:43.022671  5416 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1001 17:48:48.273630  5416 solver.cpp:218] Iteration 33200 (19.0442 iter/s, 5.25094s/100 iters), loss = 0.212266
I1001 17:48:48.273660  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212266 (* 1 = 0.212266 loss)
I1001 17:48:48.273666  5416 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1001 17:48:53.520496  5416 solver.cpp:218] Iteration 33300 (19.0592 iter/s, 5.24681s/100 iters), loss = 0.285652
I1001 17:48:53.520532  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285651 (* 1 = 0.285651 loss)
I1001 17:48:53.520539  5416 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1001 17:48:58.772567  5416 solver.cpp:218] Iteration 33400 (19.0403 iter/s, 5.25201s/100 iters), loss = 0.203373
I1001 17:48:58.772595  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203372 (* 1 = 0.203372 loss)
I1001 17:48:58.772601  5416 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1001 17:49:03.764292  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:49:03.973137  5416 solver.cpp:330] Iteration 33500, Testing net (#0)
I1001 17:49:05.160641  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:49:05.210783  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5926
I1001 17:49:05.210817  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.67075 (* 1 = 1.67075 loss)
I1001 17:49:05.263283  5416 solver.cpp:218] Iteration 33500 (15.4067 iter/s, 6.49067s/100 iters), loss = 0.236901
I1001 17:49:05.263308  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236901 (* 1 = 0.236901 loss)
I1001 17:49:05.263314  5416 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1001 17:49:10.516984  5416 solver.cpp:218] Iteration 33600 (19.0344 iter/s, 5.25365s/100 iters), loss = 0.196138
I1001 17:49:10.517151  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196138 (* 1 = 0.196138 loss)
I1001 17:49:10.517161  5416 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1001 17:49:15.768805  5416 solver.cpp:218] Iteration 33700 (19.0417 iter/s, 5.25163s/100 iters), loss = 0.296685
I1001 17:49:15.768844  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296684 (* 1 = 0.296684 loss)
I1001 17:49:15.768851  5416 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1001 17:49:21.008476  5416 solver.cpp:218] Iteration 33800 (19.0854 iter/s, 5.23961s/100 iters), loss = 0.295321
I1001 17:49:21.008517  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295321 (* 1 = 0.295321 loss)
I1001 17:49:21.008524  5416 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1001 17:49:26.246681  5416 solver.cpp:218] Iteration 33900 (19.0907 iter/s, 5.23814s/100 iters), loss = 0.214716
I1001 17:49:26.246723  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214715 (* 1 = 0.214715 loss)
I1001 17:49:26.246729  5416 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1001 17:49:31.227797  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:49:31.437870  5416 solver.cpp:330] Iteration 34000, Testing net (#0)
I1001 17:49:32.631697  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:49:32.682909  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7101
I1001 17:49:32.682935  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.17665 (* 1 = 1.17665 loss)
I1001 17:49:32.736331  5416 solver.cpp:218] Iteration 34000 (15.4093 iter/s, 6.48958s/100 iters), loss = 0.170918
I1001 17:49:32.736382  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170917 (* 1 = 0.170917 loss)
I1001 17:49:32.736390  5416 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1001 17:49:37.982841  5416 solver.cpp:218] Iteration 34100 (19.0607 iter/s, 5.2464s/100 iters), loss = 0.237876
I1001 17:49:37.982868  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237876 (* 1 = 0.237876 loss)
I1001 17:49:37.982874  5416 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1001 17:49:43.239276  5416 solver.cpp:218] Iteration 34200 (19.0245 iter/s, 5.25639s/100 iters), loss = 0.236704
I1001 17:49:43.239398  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236703 (* 1 = 0.236703 loss)
I1001 17:49:43.239415  5416 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1001 17:49:48.495944  5416 solver.cpp:218] Iteration 34300 (19.024 iter/s, 5.25653s/100 iters), loss = 0.229796
I1001 17:49:48.495975  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229796 (* 1 = 0.229796 loss)
I1001 17:49:48.495992  5416 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1001 17:49:53.754709  5416 solver.cpp:218] Iteration 34400 (19.0161 iter/s, 5.25871s/100 iters), loss = 0.18805
I1001 17:49:53.754741  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188049 (* 1 = 0.188049 loss)
I1001 17:49:53.754748  5416 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1001 17:49:58.740605  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:49:58.950187  5416 solver.cpp:330] Iteration 34500, Testing net (#0)
I1001 17:50:00.149756  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:50:00.200109  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7326
I1001 17:50:00.200134  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.907544 (* 1 = 0.907544 loss)
I1001 17:50:00.252185  5416 solver.cpp:218] Iteration 34500 (15.3907 iter/s, 6.49742s/100 iters), loss = 0.198502
I1001 17:50:00.252212  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198501 (* 1 = 0.198501 loss)
I1001 17:50:00.252218  5416 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1001 17:50:05.490857  5416 solver.cpp:218] Iteration 34600 (19.089 iter/s, 5.23863s/100 iters), loss = 0.234686
I1001 17:50:05.490885  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234686 (* 1 = 0.234686 loss)
I1001 17:50:05.490891  5416 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1001 17:50:10.764602  5416 solver.cpp:218] Iteration 34700 (18.962 iter/s, 5.27369s/100 iters), loss = 0.246948
I1001 17:50:10.764631  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246947 (* 1 = 0.246947 loss)
I1001 17:50:10.764636  5416 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1001 17:50:16.019294  5416 solver.cpp:218] Iteration 34800 (19.0308 iter/s, 5.25464s/100 iters), loss = 0.251762
I1001 17:50:16.019431  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251762 (* 1 = 0.251762 loss)
I1001 17:50:16.019439  5416 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1001 17:50:21.313434  5416 solver.cpp:218] Iteration 34900 (18.8894 iter/s, 5.29398s/100 iters), loss = 0.281013
I1001 17:50:21.313498  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281012 (* 1 = 0.281012 loss)
I1001 17:50:21.313504  5416 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1001 17:50:26.296437  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:50:26.506492  5416 solver.cpp:330] Iteration 35000, Testing net (#0)
I1001 17:50:27.708068  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:50:27.758673  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7298
I1001 17:50:27.758708  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.916895 (* 1 = 0.916895 loss)
I1001 17:50:27.810989  5416 solver.cpp:218] Iteration 35000 (15.3906 iter/s, 6.49747s/100 iters), loss = 0.132435
I1001 17:50:27.811017  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132435 (* 1 = 0.132435 loss)
I1001 17:50:27.811023  5416 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1001 17:50:33.072803  5416 solver.cpp:218] Iteration 35100 (19.005 iter/s, 5.26176s/100 iters), loss = 0.224869
I1001 17:50:33.072844  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224868 (* 1 = 0.224868 loss)
I1001 17:50:33.072850  5416 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1001 17:50:38.319742  5416 solver.cpp:218] Iteration 35200 (19.059 iter/s, 5.24688s/100 iters), loss = 0.223604
I1001 17:50:38.319772  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223604 (* 1 = 0.223604 loss)
I1001 17:50:38.319777  5416 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1001 17:50:43.578147  5416 solver.cpp:218] Iteration 35300 (19.0174 iter/s, 5.25835s/100 iters), loss = 0.306606
I1001 17:50:43.578176  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306605 (* 1 = 0.306605 loss)
I1001 17:50:43.578182  5416 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1001 17:50:48.834400  5416 solver.cpp:218] Iteration 35400 (19.0251 iter/s, 5.2562s/100 iters), loss = 0.155552
I1001 17:50:48.834511  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155551 (* 1 = 0.155551 loss)
I1001 17:50:48.834518  5416 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1001 17:50:53.823737  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:50:54.034194  5416 solver.cpp:330] Iteration 35500, Testing net (#0)
I1001 17:50:55.224520  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:50:55.274862  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6606
I1001 17:50:55.274896  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.52632 (* 1 = 1.52632 loss)
I1001 17:50:55.327294  5416 solver.cpp:218] Iteration 35500 (15.4018 iter/s, 6.49277s/100 iters), loss = 0.19478
I1001 17:50:55.327319  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19478 (* 1 = 0.19478 loss)
I1001 17:50:55.327325  5416 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1001 17:51:00.575569  5416 solver.cpp:218] Iteration 35600 (19.0541 iter/s, 5.24822s/100 iters), loss = 0.21007
I1001 17:51:00.575599  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21007 (* 1 = 0.21007 loss)
I1001 17:51:00.575605  5416 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1001 17:51:05.822755  5416 solver.cpp:218] Iteration 35700 (19.058 iter/s, 5.24713s/100 iters), loss = 0.236624
I1001 17:51:05.822788  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236624 (* 1 = 0.236624 loss)
I1001 17:51:05.822793  5416 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1001 17:51:11.062238  5416 solver.cpp:218] Iteration 35800 (19.086 iter/s, 5.23943s/100 iters), loss = 0.244431
I1001 17:51:11.062268  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24443 (* 1 = 0.24443 loss)
I1001 17:51:11.062273  5416 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1001 17:51:16.314219  5416 solver.cpp:218] Iteration 35900 (19.0406 iter/s, 5.25193s/100 iters), loss = 0.194531
I1001 17:51:16.314260  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19453 (* 1 = 0.19453 loss)
I1001 17:51:16.314265  5416 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1001 17:51:21.305976  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:51:21.516297  5416 solver.cpp:330] Iteration 36000, Testing net (#0)
I1001 17:51:22.706449  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:51:22.756572  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.623
I1001 17:51:22.756608  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.61417 (* 1 = 1.61417 loss)
I1001 17:51:22.808814  5416 solver.cpp:218] Iteration 36000 (15.3976 iter/s, 6.49453s/100 iters), loss = 0.176071
I1001 17:51:22.808840  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176071 (* 1 = 0.176071 loss)
I1001 17:51:22.808847  5416 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1001 17:51:28.060891  5416 solver.cpp:218] Iteration 36100 (19.0403 iter/s, 5.25202s/100 iters), loss = 0.284963
I1001 17:51:28.060921  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284962 (* 1 = 0.284962 loss)
I1001 17:51:28.060927  5416 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1001 17:51:33.306530  5416 solver.cpp:218] Iteration 36200 (19.0636 iter/s, 5.24559s/100 iters), loss = 0.230689
I1001 17:51:33.306560  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230689 (* 1 = 0.230689 loss)
I1001 17:51:33.306576  5416 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1001 17:51:38.544847  5416 solver.cpp:218] Iteration 36300 (19.0903 iter/s, 5.23826s/100 iters), loss = 0.294684
I1001 17:51:38.544881  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294683 (* 1 = 0.294683 loss)
I1001 17:51:38.544888  5416 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1001 17:51:43.797017  5416 solver.cpp:218] Iteration 36400 (19.0399 iter/s, 5.25211s/100 iters), loss = 0.100732
I1001 17:51:43.797046  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100732 (* 1 = 0.100732 loss)
I1001 17:51:43.797052  5416 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1001 17:51:48.784765  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:51:48.994283  5416 solver.cpp:330] Iteration 36500, Testing net (#0)
I1001 17:51:50.181318  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:51:50.231366  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6194
I1001 17:51:50.231391  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.38051 (* 1 = 1.38051 loss)
I1001 17:51:50.283800  5416 solver.cpp:218] Iteration 36500 (15.4161 iter/s, 6.48673s/100 iters), loss = 0.164407
I1001 17:51:50.283828  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164407 (* 1 = 0.164407 loss)
I1001 17:51:50.283835  5416 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1001 17:51:55.533133  5416 solver.cpp:218] Iteration 36600 (19.0502 iter/s, 5.24928s/100 iters), loss = 0.17703
I1001 17:51:55.533303  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17703 (* 1 = 0.17703 loss)
I1001 17:51:55.533323  5416 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1001 17:52:00.783757  5416 solver.cpp:218] Iteration 36700 (19.046 iter/s, 5.25044s/100 iters), loss = 0.23953
I1001 17:52:00.783798  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23953 (* 1 = 0.23953 loss)
I1001 17:52:00.783814  5416 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1001 17:52:06.032621  5416 solver.cpp:218] Iteration 36800 (19.052 iter/s, 5.2488s/100 iters), loss = 0.233503
I1001 17:52:06.032652  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233502 (* 1 = 0.233502 loss)
I1001 17:52:06.032658  5416 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1001 17:52:11.276406  5416 solver.cpp:218] Iteration 36900 (19.0704 iter/s, 5.24373s/100 iters), loss = 0.192894
I1001 17:52:11.276435  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192893 (* 1 = 0.192893 loss)
I1001 17:52:11.276442  5416 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1001 17:52:16.270371  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:52:16.480224  5416 solver.cpp:330] Iteration 37000, Testing net (#0)
I1001 17:52:17.674603  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:52:17.725353  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5605
I1001 17:52:17.725389  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.95183 (* 1 = 1.95183 loss)
I1001 17:52:17.779573  5416 solver.cpp:218] Iteration 37000 (15.3773 iter/s, 6.50311s/100 iters), loss = 0.120993
I1001 17:52:17.779608  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120993 (* 1 = 0.120993 loss)
I1001 17:52:17.779615  5416 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1001 17:52:23.025485  5416 solver.cpp:218] Iteration 37100 (19.0627 iter/s, 5.24586s/100 iters), loss = 0.182879
I1001 17:52:23.025516  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182878 (* 1 = 0.182878 loss)
I1001 17:52:23.025522  5416 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1001 17:52:28.279222  5416 solver.cpp:218] Iteration 37200 (19.0343 iter/s, 5.25368s/100 iters), loss = 0.152929
I1001 17:52:28.279338  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152928 (* 1 = 0.152928 loss)
I1001 17:52:28.279355  5416 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1001 17:52:33.528146  5416 solver.cpp:218] Iteration 37300 (19.052 iter/s, 5.2488s/100 iters), loss = 0.321203
I1001 17:52:33.528177  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321202 (* 1 = 0.321202 loss)
I1001 17:52:33.528183  5416 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1001 17:52:38.775216  5416 solver.cpp:218] Iteration 37400 (19.0585 iter/s, 5.24702s/100 iters), loss = 0.143557
I1001 17:52:38.775250  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143557 (* 1 = 0.143557 loss)
I1001 17:52:38.775257  5416 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1001 17:52:43.756175  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:52:43.966029  5416 solver.cpp:330] Iteration 37500, Testing net (#0)
I1001 17:52:45.161594  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:52:45.211722  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6942
I1001 17:52:45.211758  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03614 (* 1 = 1.03614 loss)
I1001 17:52:45.264081  5416 solver.cpp:218] Iteration 37500 (15.4111 iter/s, 6.48881s/100 iters), loss = 0.155286
I1001 17:52:45.264114  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155286 (* 1 = 0.155286 loss)
I1001 17:52:45.264122  5416 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1001 17:52:50.508008  5416 solver.cpp:218] Iteration 37600 (19.0699 iter/s, 5.24388s/100 iters), loss = 0.256792
I1001 17:52:50.508049  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256791 (* 1 = 0.256791 loss)
I1001 17:52:50.508054  5416 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1001 17:52:55.760730  5416 solver.cpp:218] Iteration 37700 (19.038 iter/s, 5.25265s/100 iters), loss = 0.233272
I1001 17:52:55.760769  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233272 (* 1 = 0.233272 loss)
I1001 17:52:55.760776  5416 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1001 17:53:01.015507  5416 solver.cpp:218] Iteration 37800 (19.0305 iter/s, 5.25472s/100 iters), loss = 0.183667
I1001 17:53:01.015635  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183667 (* 1 = 0.183667 loss)
I1001 17:53:01.015642  5416 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1001 17:53:06.271152  5416 solver.cpp:218] Iteration 37900 (19.0277 iter/s, 5.25549s/100 iters), loss = 0.217159
I1001 17:53:06.271181  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217159 (* 1 = 0.217159 loss)
I1001 17:53:06.271198  5416 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1001 17:53:11.252151  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:53:11.462273  5416 solver.cpp:330] Iteration 38000, Testing net (#0)
I1001 17:53:12.660879  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:53:12.710976  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7265
I1001 17:53:12.711001  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05788 (* 1 = 1.05788 loss)
I1001 17:53:12.763350  5416 solver.cpp:218] Iteration 38000 (15.4032 iter/s, 6.49215s/100 iters), loss = 0.214461
I1001 17:53:12.763375  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214461 (* 1 = 0.214461 loss)
I1001 17:53:12.763381  5416 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1001 17:53:18.016832  5416 solver.cpp:218] Iteration 38100 (19.0352 iter/s, 5.25342s/100 iters), loss = 0.306382
I1001 17:53:18.016903  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306381 (* 1 = 0.306381 loss)
I1001 17:53:18.016914  5416 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1001 17:53:23.257243  5416 solver.cpp:218] Iteration 38200 (19.0828 iter/s, 5.24032s/100 iters), loss = 0.305552
I1001 17:53:23.257292  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305552 (* 1 = 0.305552 loss)
I1001 17:53:23.257299  5416 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1001 17:53:28.504947  5416 solver.cpp:218] Iteration 38300 (19.0562 iter/s, 5.24764s/100 iters), loss = 0.176713
I1001 17:53:28.504976  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176712 (* 1 = 0.176712 loss)
I1001 17:53:28.504982  5416 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1001 17:53:33.755475  5416 solver.cpp:218] Iteration 38400 (19.0459 iter/s, 5.25048s/100 iters), loss = 0.234491
I1001 17:53:33.755620  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234491 (* 1 = 0.234491 loss)
I1001 17:53:33.755627  5416 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1001 17:53:38.745259  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:53:38.957917  5416 solver.cpp:330] Iteration 38500, Testing net (#0)
I1001 17:53:40.147904  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:53:40.198310  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7719
I1001 17:53:40.198336  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.693472 (* 1 = 0.693472 loss)
I1001 17:53:40.250790  5416 solver.cpp:218] Iteration 38500 (15.3961 iter/s, 6.49516s/100 iters), loss = 0.144289
I1001 17:53:40.250815  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144289 (* 1 = 0.144289 loss)
I1001 17:53:40.250823  5416 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1001 17:53:45.507383  5416 solver.cpp:218] Iteration 38600 (19.0239 iter/s, 5.25655s/100 iters), loss = 0.275389
I1001 17:53:45.507413  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275389 (* 1 = 0.275389 loss)
I1001 17:53:45.507419  5416 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1001 17:53:50.761308  5416 solver.cpp:218] Iteration 38700 (19.0336 iter/s, 5.25387s/100 iters), loss = 0.280628
I1001 17:53:50.761344  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280628 (* 1 = 0.280628 loss)
I1001 17:53:50.761363  5416 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1001 17:53:56.004220  5416 solver.cpp:218] Iteration 38800 (19.0737 iter/s, 5.24282s/100 iters), loss = 0.192392
I1001 17:53:56.004250  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192391 (* 1 = 0.192391 loss)
I1001 17:53:56.004266  5416 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1001 17:54:01.255766  5416 solver.cpp:218] Iteration 38900 (19.0422 iter/s, 5.2515s/100 iters), loss = 0.175624
I1001 17:54:01.255796  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175624 (* 1 = 0.175624 loss)
I1001 17:54:01.255812  5416 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1001 17:54:06.241767  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:54:06.451833  5416 solver.cpp:330] Iteration 39000, Testing net (#0)
I1001 17:54:07.642583  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:54:07.692544  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7246
I1001 17:54:07.692579  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.954817 (* 1 = 0.954817 loss)
I1001 17:54:07.745252  5416 solver.cpp:218] Iteration 39000 (15.4097 iter/s, 6.48943s/100 iters), loss = 0.204574
I1001 17:54:07.745278  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204574 (* 1 = 0.204574 loss)
I1001 17:54:07.745285  5416 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1001 17:54:12.992580  5416 solver.cpp:218] Iteration 39100 (19.0575 iter/s, 5.24728s/100 iters), loss = 0.249776
I1001 17:54:12.992612  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249775 (* 1 = 0.249775 loss)
I1001 17:54:12.992619  5416 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1001 17:54:18.240860  5416 solver.cpp:218] Iteration 39200 (19.0541 iter/s, 5.24822s/100 iters), loss = 0.261968
I1001 17:54:18.240901  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261968 (* 1 = 0.261968 loss)
I1001 17:54:18.240907  5416 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1001 17:54:23.476964  5416 solver.cpp:218] Iteration 39300 (19.0984 iter/s, 5.23604s/100 iters), loss = 0.23008
I1001 17:54:23.477005  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23008 (* 1 = 0.23008 loss)
I1001 17:54:23.477010  5416 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1001 17:54:28.729902  5416 solver.cpp:218] Iteration 39400 (19.0372 iter/s, 5.25288s/100 iters), loss = 0.15336
I1001 17:54:28.729943  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15336 (* 1 = 0.15336 loss)
I1001 17:54:28.729948  5416 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1001 17:54:33.725062  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:54:33.935087  5416 solver.cpp:330] Iteration 39500, Testing net (#0)
I1001 17:54:35.125488  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:54:35.175854  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7132
I1001 17:54:35.175890  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.964229 (* 1 = 0.964229 loss)
I1001 17:54:35.228529  5416 solver.cpp:218] Iteration 39500 (15.388 iter/s, 6.49856s/100 iters), loss = 0.175456
I1001 17:54:35.228555  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175455 (* 1 = 0.175455 loss)
I1001 17:54:35.228562  5416 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1001 17:54:40.481544  5416 solver.cpp:218] Iteration 39600 (19.0369 iter/s, 5.25297s/100 iters), loss = 0.220201
I1001 17:54:40.481689  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2202 (* 1 = 0.2202 loss)
I1001 17:54:40.481708  5416 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1001 17:54:45.733247  5416 solver.cpp:218] Iteration 39700 (19.0421 iter/s, 5.25153s/100 iters), loss = 0.226215
I1001 17:54:45.733276  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226215 (* 1 = 0.226215 loss)
I1001 17:54:45.733292  5416 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1001 17:54:50.984684  5416 solver.cpp:218] Iteration 39800 (19.0426 iter/s, 5.25139s/100 iters), loss = 0.156696
I1001 17:54:50.984715  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156696 (* 1 = 0.156696 loss)
I1001 17:54:50.984731  5416 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1001 17:54:56.226445  5416 solver.cpp:218] Iteration 39900 (19.0777 iter/s, 5.24171s/100 iters), loss = 0.165715
I1001 17:54:56.226475  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165714 (* 1 = 0.165714 loss)
I1001 17:54:56.226491  5416 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1001 17:55:01.214931  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:55:01.424176  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_40000.caffemodel
I1001 17:55:01.429103  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_40000.solverstate
I1001 17:55:01.430440  5416 solver.cpp:330] Iteration 40000, Testing net (#0)
I1001 17:55:02.622650  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:55:02.674044  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6134
I1001 17:55:02.674079  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.43124 (* 1 = 1.43124 loss)
I1001 17:55:02.728346  5416 solver.cpp:218] Iteration 40000 (15.3802 iter/s, 6.50185s/100 iters), loss = 0.140328
I1001 17:55:02.728381  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140328 (* 1 = 0.140328 loss)
I1001 17:55:02.728387  5416 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1001 17:55:02.728391  5416 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1001 17:55:07.968394  5416 solver.cpp:218] Iteration 40100 (19.084 iter/s, 5.24s/100 iters), loss = 0.179157
I1001 17:55:07.968435  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179156 (* 1 = 0.179156 loss)
I1001 17:55:07.968441  5416 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1001 17:55:13.214658  5416 solver.cpp:218] Iteration 40200 (19.0614 iter/s, 5.2462s/100 iters), loss = 0.164611
I1001 17:55:13.214802  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164611 (* 1 = 0.164611 loss)
I1001 17:55:13.214809  5416 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1001 17:55:18.468541  5416 solver.cpp:218] Iteration 40300 (19.0341 iter/s, 5.25372s/100 iters), loss = 0.157176
I1001 17:55:18.468570  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157176 (* 1 = 0.157176 loss)
I1001 17:55:18.468576  5416 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1001 17:55:23.719310  5416 solver.cpp:218] Iteration 40400 (19.045 iter/s, 5.25072s/100 iters), loss = 0.128484
I1001 17:55:23.719357  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128484 (* 1 = 0.128484 loss)
I1001 17:55:23.719364  5416 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1001 17:55:28.707389  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:55:28.917755  5416 solver.cpp:330] Iteration 40500, Testing net (#0)
I1001 17:55:30.115813  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:55:30.165812  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8866
I1001 17:55:30.165838  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324214 (* 1 = 0.324214 loss)
I1001 17:55:30.218659  5416 solver.cpp:218] Iteration 40500 (15.3864 iter/s, 6.49925s/100 iters), loss = 0.106396
I1001 17:55:30.218689  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106396 (* 1 = 0.106396 loss)
I1001 17:55:30.218696  5416 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1001 17:55:35.463871  5416 solver.cpp:218] Iteration 40600 (19.0652 iter/s, 5.24516s/100 iters), loss = 0.109082
I1001 17:55:35.463904  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109081 (* 1 = 0.109081 loss)
I1001 17:55:35.463912  5416 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1001 17:55:40.717963  5416 solver.cpp:218] Iteration 40700 (19.033 iter/s, 5.25404s/100 iters), loss = 0.116622
I1001 17:55:40.717995  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116622 (* 1 = 0.116622 loss)
I1001 17:55:40.718003  5416 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1001 17:55:45.966681  5416 solver.cpp:218] Iteration 40800 (19.0525 iter/s, 5.24867s/100 iters), loss = 0.110982
I1001 17:55:45.966814  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110982 (* 1 = 0.110982 loss)
I1001 17:55:45.966831  5416 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1001 17:55:51.217949  5416 solver.cpp:218] Iteration 40900 (19.0435 iter/s, 5.25113s/100 iters), loss = 0.0794609
I1001 17:55:51.217990  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0794604 (* 1 = 0.0794604 loss)
I1001 17:55:51.217996  5416 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1001 17:55:56.197788  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:55:56.408231  5416 solver.cpp:330] Iteration 41000, Testing net (#0)
I1001 17:55:57.604254  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:55:57.654511  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I1001 17:55:57.654539  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289218 (* 1 = 0.289218 loss)
I1001 17:55:57.706959  5416 solver.cpp:218] Iteration 41000 (15.4108 iter/s, 6.48895s/100 iters), loss = 0.0718874
I1001 17:55:57.706995  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.071887 (* 1 = 0.071887 loss)
I1001 17:55:57.707001  5416 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1001 17:56:02.960645  5416 solver.cpp:218] Iteration 41100 (19.0345 iter/s, 5.25363s/100 iters), loss = 0.144549
I1001 17:56:02.960675  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144548 (* 1 = 0.144548 loss)
I1001 17:56:02.960681  5416 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1001 17:56:08.204541  5416 solver.cpp:218] Iteration 41200 (19.07 iter/s, 5.24385s/100 iters), loss = 0.124911
I1001 17:56:08.204571  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124911 (* 1 = 0.124911 loss)
I1001 17:56:08.204577  5416 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1001 17:56:13.455080  5416 solver.cpp:218] Iteration 41300 (19.0458 iter/s, 5.25049s/100 iters), loss = 0.105417
I1001 17:56:13.455111  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105417 (* 1 = 0.105417 loss)
I1001 17:56:13.455127  5416 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1001 17:56:18.706938  5416 solver.cpp:218] Iteration 41400 (19.0411 iter/s, 5.2518s/100 iters), loss = 0.0570791
I1001 17:56:18.707041  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0570787 (* 1 = 0.0570787 loss)
I1001 17:56:18.707046  5416 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1001 17:56:23.691105  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:56:23.904363  5416 solver.cpp:330] Iteration 41500, Testing net (#0)
I1001 17:56:25.094074  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:56:25.144378  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8999
I1001 17:56:25.144402  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302547 (* 1 = 0.302547 loss)
I1001 17:56:25.197063  5416 solver.cpp:218] Iteration 41500 (15.4083 iter/s, 6.49s/100 iters), loss = 0.0729839
I1001 17:56:25.197088  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729834 (* 1 = 0.0729834 loss)
I1001 17:56:25.197095  5416 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1001 17:56:30.450034  5416 solver.cpp:218] Iteration 41600 (19.037 iter/s, 5.25292s/100 iters), loss = 0.127044
I1001 17:56:30.450064  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127044 (* 1 = 0.127044 loss)
I1001 17:56:30.450070  5416 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1001 17:56:35.695132  5416 solver.cpp:218] Iteration 41700 (19.0656 iter/s, 5.24504s/100 iters), loss = 0.0669555
I1001 17:56:35.695165  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0669551 (* 1 = 0.0669551 loss)
I1001 17:56:35.695173  5416 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1001 17:56:40.940277  5416 solver.cpp:218] Iteration 41800 (19.0655 iter/s, 5.24509s/100 iters), loss = 0.0556051
I1001 17:56:40.940318  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556047 (* 1 = 0.0556047 loss)
I1001 17:56:40.940325  5416 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1001 17:56:46.187700  5416 solver.cpp:218] Iteration 41900 (19.0572 iter/s, 5.24736s/100 iters), loss = 0.0779305
I1001 17:56:46.187728  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0779301 (* 1 = 0.0779301 loss)
I1001 17:56:46.187734  5416 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1001 17:56:51.174886  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:56:51.384881  5416 solver.cpp:330] Iteration 42000, Testing net (#0)
I1001 17:56:52.573021  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:56:52.623216  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1001 17:56:52.623251  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291436 (* 1 = 0.291436 loss)
I1001 17:56:52.676080  5416 solver.cpp:218] Iteration 42000 (15.4123 iter/s, 6.48833s/100 iters), loss = 0.0716497
I1001 17:56:52.676108  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716493 (* 1 = 0.0716493 loss)
I1001 17:56:52.676115  5416 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1001 17:56:57.930310  5416 solver.cpp:218] Iteration 42100 (19.0325 iter/s, 5.25418s/100 iters), loss = 0.11484
I1001 17:56:57.930351  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11484 (* 1 = 0.11484 loss)
I1001 17:56:57.930358  5416 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1001 17:57:03.188506  5416 solver.cpp:218] Iteration 42200 (19.0182 iter/s, 5.25813s/100 iters), loss = 0.095715
I1001 17:57:03.188542  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0957146 (* 1 = 0.0957146 loss)
I1001 17:57:03.188550  5416 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1001 17:57:08.432461  5416 solver.cpp:218] Iteration 42300 (19.0698 iter/s, 5.2439s/100 iters), loss = 0.0844392
I1001 17:57:08.432500  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0844388 (* 1 = 0.0844388 loss)
I1001 17:57:08.432507  5416 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1001 17:57:13.690745  5416 solver.cpp:218] Iteration 42400 (19.0178 iter/s, 5.25822s/100 iters), loss = 0.0846208
I1001 17:57:13.690785  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0846203 (* 1 = 0.0846203 loss)
I1001 17:57:13.690793  5416 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1001 17:57:18.681679  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:57:18.892040  5416 solver.cpp:330] Iteration 42500, Testing net (#0)
I1001 17:57:20.080421  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:57:20.130695  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8973
I1001 17:57:20.130729  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309466 (* 1 = 0.309466 loss)
I1001 17:57:20.183490  5416 solver.cpp:218] Iteration 42500 (15.402 iter/s, 6.49268s/100 iters), loss = 0.039232
I1001 17:57:20.183513  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392316 (* 1 = 0.0392316 loss)
I1001 17:57:20.183521  5416 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1001 17:57:25.432405  5416 solver.cpp:218] Iteration 42600 (19.0517 iter/s, 5.24887s/100 iters), loss = 0.117241
I1001 17:57:25.432540  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117241 (* 1 = 0.117241 loss)
I1001 17:57:25.432556  5416 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1001 17:57:30.681674  5416 solver.cpp:218] Iteration 42700 (19.0508 iter/s, 5.24912s/100 iters), loss = 0.120382
I1001 17:57:30.681704  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120381 (* 1 = 0.120381 loss)
I1001 17:57:30.681710  5416 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1001 17:57:35.929821  5416 solver.cpp:218] Iteration 42800 (19.0545 iter/s, 5.24809s/100 iters), loss = 0.160149
I1001 17:57:35.929852  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160148 (* 1 = 0.160148 loss)
I1001 17:57:35.929859  5416 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1001 17:57:41.174639  5416 solver.cpp:218] Iteration 42900 (19.0666 iter/s, 5.24477s/100 iters), loss = 0.075613
I1001 17:57:41.174669  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756126 (* 1 = 0.0756126 loss)
I1001 17:57:41.174674  5416 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1001 17:57:46.168210  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:57:46.377481  5416 solver.cpp:330] Iteration 43000, Testing net (#0)
I1001 17:57:47.567368  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:57:47.618394  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I1001 17:57:47.618432  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292493 (* 1 = 0.292493 loss)
I1001 17:57:47.672803  5416 solver.cpp:218] Iteration 43000 (15.3891 iter/s, 6.49811s/100 iters), loss = 0.0646771
I1001 17:57:47.672847  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0646767 (* 1 = 0.0646767 loss)
I1001 17:57:47.672854  5416 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1001 17:57:52.917614  5416 solver.cpp:218] Iteration 43100 (19.0668 iter/s, 5.24472s/100 iters), loss = 0.139852
I1001 17:57:52.917656  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139852 (* 1 = 0.139852 loss)
I1001 17:57:52.917662  5416 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1001 17:57:58.172932  5416 solver.cpp:218] Iteration 43200 (19.0286 iter/s, 5.25526s/100 iters), loss = 0.0763507
I1001 17:57:58.173040  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0763503 (* 1 = 0.0763503 loss)
I1001 17:57:58.173048  5416 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1001 17:58:03.426661  5416 solver.cpp:218] Iteration 43300 (19.0345 iter/s, 5.25361s/100 iters), loss = 0.116781
I1001 17:58:03.426702  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116781 (* 1 = 0.116781 loss)
I1001 17:58:03.426707  5416 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1001 17:58:08.669719  5416 solver.cpp:218] Iteration 43400 (19.0731 iter/s, 5.243s/100 iters), loss = 0.0392449
I1001 17:58:08.669762  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392445 (* 1 = 0.0392445 loss)
I1001 17:58:08.669770  5416 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1001 17:58:13.653996  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:58:13.863423  5416 solver.cpp:330] Iteration 43500, Testing net (#0)
I1001 17:58:15.058992  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:58:15.109201  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904
I1001 17:58:15.109236  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29484 (* 1 = 0.29484 loss)
I1001 17:58:15.161689  5416 solver.cpp:218] Iteration 43500 (15.4038 iter/s, 6.4919s/100 iters), loss = 0.0393165
I1001 17:58:15.161723  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393161 (* 1 = 0.0393161 loss)
I1001 17:58:15.161731  5416 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1001 17:58:20.400862  5416 solver.cpp:218] Iteration 43600 (19.0872 iter/s, 5.23912s/100 iters), loss = 0.0929981
I1001 17:58:20.400902  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0929977 (* 1 = 0.0929977 loss)
I1001 17:58:20.400908  5416 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1001 17:58:25.644160  5416 solver.cpp:218] Iteration 43700 (19.0722 iter/s, 5.24324s/100 iters), loss = 0.0874869
I1001 17:58:25.644194  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0874865 (* 1 = 0.0874865 loss)
I1001 17:58:25.644203  5416 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1001 17:58:30.897294  5416 solver.cpp:218] Iteration 43800 (19.0365 iter/s, 5.25308s/100 iters), loss = 0.0352551
I1001 17:58:30.897452  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352546 (* 1 = 0.0352546 loss)
I1001 17:58:30.897459  5416 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1001 17:58:36.150527  5416 solver.cpp:218] Iteration 43900 (19.0366 iter/s, 5.25305s/100 iters), loss = 0.0532768
I1001 17:58:36.150584  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532763 (* 1 = 0.0532763 loss)
I1001 17:58:36.150590  5416 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1001 17:58:41.129964  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:58:41.340289  5416 solver.cpp:330] Iteration 44000, Testing net (#0)
I1001 17:58:42.538794  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:58:42.589066  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1001 17:58:42.589100  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312256 (* 1 = 0.312256 loss)
I1001 17:58:42.641664  5416 solver.cpp:218] Iteration 44000 (15.4058 iter/s, 6.49106s/100 iters), loss = 0.0531838
I1001 17:58:42.641690  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0531834 (* 1 = 0.0531834 loss)
I1001 17:58:42.641696  5416 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1001 17:58:47.894299  5416 solver.cpp:218] Iteration 44100 (19.0382 iter/s, 5.25259s/100 iters), loss = 0.141184
I1001 17:58:47.894330  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141184 (* 1 = 0.141184 loss)
I1001 17:58:47.894336  5416 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1001 17:58:53.131829  5416 solver.cpp:218] Iteration 44200 (19.0932 iter/s, 5.23748s/100 iters), loss = 0.0797739
I1001 17:58:53.131870  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0797735 (* 1 = 0.0797735 loss)
I1001 17:58:53.131875  5416 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1001 17:58:58.370321  5416 solver.cpp:218] Iteration 44300 (19.0897 iter/s, 5.23843s/100 iters), loss = 0.0945736
I1001 17:58:58.370352  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0945731 (* 1 = 0.0945731 loss)
I1001 17:58:58.370359  5416 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1001 17:59:03.620483  5416 solver.cpp:218] Iteration 44400 (19.0472 iter/s, 5.25011s/100 iters), loss = 0.0572073
I1001 17:59:03.620589  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0572069 (* 1 = 0.0572069 loss)
I1001 17:59:03.620595  5416 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1001 17:59:08.597308  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:59:08.812544  5416 solver.cpp:330] Iteration 44500, Testing net (#0)
I1001 17:59:10.003360  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:59:10.052822  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I1001 17:59:10.052857  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308064 (* 1 = 0.308064 loss)
I1001 17:59:10.105514  5416 solver.cpp:218] Iteration 44500 (15.4204 iter/s, 6.48492s/100 iters), loss = 0.0244604
I1001 17:59:10.105545  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02446 (* 1 = 0.02446 loss)
I1001 17:59:10.105551  5416 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1001 17:59:15.360316  5416 solver.cpp:218] Iteration 44600 (19.0304 iter/s, 5.25475s/100 iters), loss = 0.0689537
I1001 17:59:15.360357  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0689532 (* 1 = 0.0689532 loss)
I1001 17:59:15.360363  5416 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1001 17:59:20.607295  5416 solver.cpp:218] Iteration 44700 (19.0588 iter/s, 5.24691s/100 iters), loss = 0.112375
I1001 17:59:20.607362  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112374 (* 1 = 0.112374 loss)
I1001 17:59:20.607391  5416 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1001 17:59:25.859625  5416 solver.cpp:218] Iteration 44800 (19.0401 iter/s, 5.25208s/100 iters), loss = 0.0698495
I1001 17:59:25.859665  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.069849 (* 1 = 0.069849 loss)
I1001 17:59:25.859673  5416 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1001 17:59:31.116247  5416 solver.cpp:218] Iteration 44900 (19.0238 iter/s, 5.25656s/100 iters), loss = 0.0329442
I1001 17:59:31.116277  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329437 (* 1 = 0.0329437 loss)
I1001 17:59:31.116283  5416 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1001 17:59:36.104929  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:59:36.313616  5416 solver.cpp:330] Iteration 45000, Testing net (#0)
I1001 17:59:37.502506  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 17:59:37.552861  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9046
I1001 17:59:37.552896  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309766 (* 1 = 0.309766 loss)
I1001 17:59:37.605373  5416 solver.cpp:218] Iteration 45000 (15.4105 iter/s, 6.48907s/100 iters), loss = 0.0157407
I1001 17:59:37.605399  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157403 (* 1 = 0.0157403 loss)
I1001 17:59:37.605406  5416 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1001 17:59:42.856793  5416 solver.cpp:218] Iteration 45100 (19.0426 iter/s, 5.25137s/100 iters), loss = 0.069659
I1001 17:59:42.856833  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0696585 (* 1 = 0.0696585 loss)
I1001 17:59:42.856839  5416 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1001 17:59:48.102048  5416 solver.cpp:218] Iteration 45200 (19.0651 iter/s, 5.24519s/100 iters), loss = 0.0907312
I1001 17:59:48.102089  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0907307 (* 1 = 0.0907307 loss)
I1001 17:59:48.102097  5416 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1001 17:59:53.342669  5416 solver.cpp:218] Iteration 45300 (19.0819 iter/s, 5.24056s/100 iters), loss = 0.0695446
I1001 17:59:53.342708  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0695442 (* 1 = 0.0695442 loss)
I1001 17:59:53.342715  5416 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1001 17:59:58.592037  5416 solver.cpp:218] Iteration 45400 (19.0501 iter/s, 5.2493s/100 iters), loss = 0.0798674
I1001 17:59:58.592067  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0798669 (* 1 = 0.0798669 loss)
I1001 17:59:58.592073  5416 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1001 18:00:03.585525  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:00:03.795809  5416 solver.cpp:330] Iteration 45500, Testing net (#0)
I1001 18:00:04.983387  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:00:05.033869  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.902
I1001 18:00:05.033907  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31879 (* 1 = 0.31879 loss)
I1001 18:00:05.086484  5416 solver.cpp:218] Iteration 45500 (15.3979 iter/s, 6.4944s/100 iters), loss = 0.0365493
I1001 18:00:05.086515  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365488 (* 1 = 0.0365488 loss)
I1001 18:00:05.086524  5416 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1001 18:00:10.341485  5416 solver.cpp:218] Iteration 45600 (19.0297 iter/s, 5.25495s/100 iters), loss = 0.148407
I1001 18:00:10.341580  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148406 (* 1 = 0.148406 loss)
I1001 18:00:10.341589  5416 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1001 18:00:15.598912  5416 solver.cpp:218] Iteration 45700 (19.0211 iter/s, 5.25731s/100 iters), loss = 0.0949913
I1001 18:00:15.598954  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0949909 (* 1 = 0.0949909 loss)
I1001 18:00:15.598961  5416 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1001 18:00:20.855557  5416 solver.cpp:218] Iteration 45800 (19.0238 iter/s, 5.25658s/100 iters), loss = 0.0548702
I1001 18:00:20.855602  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0548698 (* 1 = 0.0548698 loss)
I1001 18:00:20.855610  5416 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1001 18:00:26.104461  5416 solver.cpp:218] Iteration 45900 (19.052 iter/s, 5.24881s/100 iters), loss = 0.0631157
I1001 18:00:26.104501  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0631152 (* 1 = 0.0631152 loss)
I1001 18:00:26.104507  5416 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1001 18:00:31.096298  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:00:31.305130  5416 solver.cpp:330] Iteration 46000, Testing net (#0)
I1001 18:00:32.494699  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:00:32.545027  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I1001 18:00:32.545063  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316165 (* 1 = 0.316165 loss)
I1001 18:00:32.598666  5416 solver.cpp:218] Iteration 46000 (15.3985 iter/s, 6.49414s/100 iters), loss = 0.0643716
I1001 18:00:32.598701  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0643711 (* 1 = 0.0643711 loss)
I1001 18:00:32.598708  5416 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1001 18:00:37.846604  5416 solver.cpp:218] Iteration 46100 (19.0553 iter/s, 5.24788s/100 iters), loss = 0.112521
I1001 18:00:37.846644  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112521 (* 1 = 0.112521 loss)
I1001 18:00:37.846650  5416 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1001 18:00:43.092880  5416 solver.cpp:218] Iteration 46200 (19.0614 iter/s, 5.24621s/100 iters), loss = 0.0444653
I1001 18:00:43.092993  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444649 (* 1 = 0.0444649 loss)
I1001 18:00:43.093008  5416 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1001 18:00:48.340761  5416 solver.cpp:218] Iteration 46300 (19.0558 iter/s, 5.24776s/100 iters), loss = 0.0589301
I1001 18:00:48.340791  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589296 (* 1 = 0.0589296 loss)
I1001 18:00:48.340798  5416 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1001 18:00:53.580955  5416 solver.cpp:218] Iteration 46400 (19.0835 iter/s, 5.24014s/100 iters), loss = 0.0421993
I1001 18:00:53.581001  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0421989 (* 1 = 0.0421989 loss)
I1001 18:00:53.581009  5416 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1001 18:00:58.568346  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:00:58.777817  5416 solver.cpp:330] Iteration 46500, Testing net (#0)
I1001 18:00:59.973526  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:01:00.023489  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I1001 18:01:00.023524  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329273 (* 1 = 0.329273 loss)
I1001 18:01:00.076272  5416 solver.cpp:218] Iteration 46500 (15.396 iter/s, 6.49521s/100 iters), loss = 0.0465998
I1001 18:01:00.076303  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465993 (* 1 = 0.0465993 loss)
I1001 18:01:00.076309  5416 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1001 18:01:05.323019  5416 solver.cpp:218] Iteration 46600 (19.0596 iter/s, 5.24669s/100 iters), loss = 0.0471037
I1001 18:01:05.323060  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0471032 (* 1 = 0.0471032 loss)
I1001 18:01:05.323065  5416 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1001 18:01:10.579730  5416 solver.cpp:218] Iteration 46700 (19.0235 iter/s, 5.25665s/100 iters), loss = 0.0314217
I1001 18:01:10.579771  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314213 (* 1 = 0.0314213 loss)
I1001 18:01:10.579777  5416 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1001 18:01:15.833851  5416 solver.cpp:218] Iteration 46800 (19.0329 iter/s, 5.25406s/100 iters), loss = 0.0497843
I1001 18:01:15.834007  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497838 (* 1 = 0.0497838 loss)
I1001 18:01:15.834024  5416 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1001 18:01:21.081010  5416 solver.cpp:218] Iteration 46900 (19.0585 iter/s, 5.24699s/100 iters), loss = 0.0237792
I1001 18:01:21.081053  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237788 (* 1 = 0.0237788 loss)
I1001 18:01:21.081059  5416 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1001 18:01:26.058992  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:01:26.269160  5416 solver.cpp:330] Iteration 47000, Testing net (#0)
I1001 18:01:27.467522  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:01:27.517802  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8986
I1001 18:01:27.517827  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340156 (* 1 = 0.340156 loss)
I1001 18:01:27.570184  5416 solver.cpp:218] Iteration 47000 (15.4104 iter/s, 6.48911s/100 iters), loss = 0.087468
I1001 18:01:27.570215  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0874676 (* 1 = 0.0874676 loss)
I1001 18:01:27.570222  5416 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1001 18:01:32.817597  5416 solver.cpp:218] Iteration 47100 (19.0572 iter/s, 5.24736s/100 iters), loss = 0.0587264
I1001 18:01:32.817632  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.058726 (* 1 = 0.058726 loss)
I1001 18:01:32.817641  5416 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1001 18:01:38.060569  5416 solver.cpp:218] Iteration 47200 (19.0734 iter/s, 5.24291s/100 iters), loss = 0.0732987
I1001 18:01:38.060598  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732983 (* 1 = 0.0732983 loss)
I1001 18:01:38.060614  5416 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1001 18:01:43.314028  5416 solver.cpp:218] Iteration 47300 (19.0353 iter/s, 5.25341s/100 iters), loss = 0.111238
I1001 18:01:43.314059  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111237 (* 1 = 0.111237 loss)
I1001 18:01:43.314074  5416 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1001 18:01:48.567889  5416 solver.cpp:218] Iteration 47400 (19.0338 iter/s, 5.25381s/100 iters), loss = 0.0344835
I1001 18:01:48.567965  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344831 (* 1 = 0.0344831 loss)
I1001 18:01:48.567971  5416 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1001 18:01:53.548879  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:01:53.766858  5416 solver.cpp:330] Iteration 47500, Testing net (#0)
I1001 18:01:54.958706  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:01:55.008918  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8997
I1001 18:01:55.008944  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346113 (* 1 = 0.346113 loss)
I1001 18:01:55.061447  5416 solver.cpp:218] Iteration 47500 (15.4001 iter/s, 6.49346s/100 iters), loss = 0.0393629
I1001 18:01:55.061491  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393625 (* 1 = 0.0393625 loss)
I1001 18:01:55.061497  5416 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1001 18:02:00.317718  5416 solver.cpp:218] Iteration 47600 (19.0251 iter/s, 5.25621s/100 iters), loss = 0.0244123
I1001 18:02:00.317749  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244119 (* 1 = 0.0244119 loss)
I1001 18:02:00.317754  5416 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1001 18:02:05.557512  5416 solver.cpp:218] Iteration 47700 (19.0849 iter/s, 5.23974s/100 iters), loss = 0.0723529
I1001 18:02:05.557552  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0723525 (* 1 = 0.0723525 loss)
I1001 18:02:05.557559  5416 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1001 18:02:10.805090  5416 solver.cpp:218] Iteration 47800 (19.0566 iter/s, 5.24751s/100 iters), loss = 0.0482952
I1001 18:02:10.805131  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482948 (* 1 = 0.0482948 loss)
I1001 18:02:10.805137  5416 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1001 18:02:16.050886  5416 solver.cpp:218] Iteration 47900 (19.0631 iter/s, 5.24573s/100 iters), loss = 0.0432991
I1001 18:02:16.050926  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432987 (* 1 = 0.0432987 loss)
I1001 18:02:16.050932  5416 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1001 18:02:21.037111  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:02:21.247018  5416 solver.cpp:330] Iteration 48000, Testing net (#0)
I1001 18:02:22.436414  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:02:22.486659  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8986
I1001 18:02:22.486685  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347432 (* 1 = 0.347432 loss)
I1001 18:02:22.539356  5416 solver.cpp:218] Iteration 48000 (15.4121 iter/s, 6.48842s/100 iters), loss = 0.0320801
I1001 18:02:22.539386  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320796 (* 1 = 0.0320796 loss)
I1001 18:02:22.539394  5416 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1001 18:02:27.792982  5416 solver.cpp:218] Iteration 48100 (19.0347 iter/s, 5.25357s/100 iters), loss = 0.0910789
I1001 18:02:27.793018  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0910785 (* 1 = 0.0910785 loss)
I1001 18:02:27.793038  5416 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1001 18:02:33.044116  5416 solver.cpp:218] Iteration 48200 (19.0437 iter/s, 5.25107s/100 iters), loss = 0.0553828
I1001 18:02:33.044145  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553824 (* 1 = 0.0553824 loss)
I1001 18:02:33.044152  5416 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1001 18:02:38.288856  5416 solver.cpp:218] Iteration 48300 (19.0669 iter/s, 5.24469s/100 iters), loss = 0.0210729
I1001 18:02:38.288887  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210724 (* 1 = 0.0210724 loss)
I1001 18:02:38.288903  5416 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1001 18:02:43.546237  5416 solver.cpp:218] Iteration 48400 (19.0211 iter/s, 5.25733s/100 iters), loss = 0.0557935
I1001 18:02:43.546267  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0557931 (* 1 = 0.0557931 loss)
I1001 18:02:43.546273  5416 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1001 18:02:48.538511  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:02:48.749951  5416 solver.cpp:330] Iteration 48500, Testing net (#0)
I1001 18:02:49.936120  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:02:49.986410  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9038
I1001 18:02:49.986434  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33768 (* 1 = 0.33768 loss)
I1001 18:02:50.039259  5416 solver.cpp:218] Iteration 48500 (15.4013 iter/s, 6.49297s/100 iters), loss = 0.0488057
I1001 18:02:50.039289  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488054 (* 1 = 0.0488054 loss)
I1001 18:02:50.039296  5416 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1001 18:02:55.294361  5416 solver.cpp:218] Iteration 48600 (19.0293 iter/s, 5.25505s/100 iters), loss = 0.0694244
I1001 18:02:55.294508  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.069424 (* 1 = 0.069424 loss)
I1001 18:02:55.294518  5416 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1001 18:03:00.546913  5416 solver.cpp:218] Iteration 48700 (19.039 iter/s, 5.25239s/100 iters), loss = 0.054167
I1001 18:03:00.546942  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541666 (* 1 = 0.0541666 loss)
I1001 18:03:00.546949  5416 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1001 18:03:05.795866  5416 solver.cpp:218] Iteration 48800 (19.0516 iter/s, 5.2489s/100 iters), loss = 0.0485476
I1001 18:03:05.795900  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485473 (* 1 = 0.0485473 loss)
I1001 18:03:05.795907  5416 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1001 18:03:11.051004  5416 solver.cpp:218] Iteration 48900 (19.0292 iter/s, 5.25508s/100 iters), loss = 0.0191231
I1001 18:03:11.051036  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191227 (* 1 = 0.0191227 loss)
I1001 18:03:11.051053  5416 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1001 18:03:16.044924  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:03:16.256019  5416 solver.cpp:330] Iteration 49000, Testing net (#0)
I1001 18:03:17.443953  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:03:17.494089  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8976
I1001 18:03:17.494117  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36457 (* 1 = 0.36457 loss)
I1001 18:03:17.547085  5416 solver.cpp:218] Iteration 49000 (15.394 iter/s, 6.49603s/100 iters), loss = 0.0277088
I1001 18:03:17.547116  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277084 (* 1 = 0.0277084 loss)
I1001 18:03:17.547124  5416 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1001 18:03:22.798957  5416 solver.cpp:218] Iteration 49100 (19.041 iter/s, 5.25182s/100 iters), loss = 0.0621515
I1001 18:03:22.798991  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0621511 (* 1 = 0.0621511 loss)
I1001 18:03:22.799010  5416 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1001 18:03:28.046686  5416 solver.cpp:218] Iteration 49200 (19.0561 iter/s, 5.24768s/100 iters), loss = 0.0385408
I1001 18:03:28.046811  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385404 (* 1 = 0.0385404 loss)
I1001 18:03:28.046828  5416 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1001 18:03:33.301156  5416 solver.cpp:218] Iteration 49300 (19.0319 iter/s, 5.25433s/100 iters), loss = 0.0733373
I1001 18:03:33.301196  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0733369 (* 1 = 0.0733369 loss)
I1001 18:03:33.301203  5416 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1001 18:03:38.548975  5416 solver.cpp:218] Iteration 49400 (19.0558 iter/s, 5.24776s/100 iters), loss = 0.0649059
I1001 18:03:38.549005  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0649055 (* 1 = 0.0649055 loss)
I1001 18:03:38.549010  5416 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1001 18:03:43.537271  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:03:43.746594  5416 solver.cpp:330] Iteration 49500, Testing net (#0)
I1001 18:03:44.941130  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:03:44.991472  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1001 18:03:44.991506  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353704 (* 1 = 0.353704 loss)
I1001 18:03:45.044665  5416 solver.cpp:218] Iteration 49500 (15.3949 iter/s, 6.49564s/100 iters), loss = 0.0161667
I1001 18:03:45.044698  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161663 (* 1 = 0.0161663 loss)
I1001 18:03:45.044706  5416 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1001 18:03:50.287187  5416 solver.cpp:218] Iteration 49600 (19.075 iter/s, 5.24247s/100 iters), loss = 0.0483074
I1001 18:03:50.287217  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048307 (* 1 = 0.048307 loss)
I1001 18:03:50.287223  5416 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1001 18:03:55.534595  5416 solver.cpp:218] Iteration 49700 (19.0572 iter/s, 5.24735s/100 iters), loss = 0.0324407
I1001 18:03:55.534644  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324403 (* 1 = 0.0324403 loss)
I1001 18:03:55.534660  5416 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1001 18:04:00.787688  5416 solver.cpp:218] Iteration 49800 (19.0367 iter/s, 5.25302s/100 iters), loss = 0.144086
I1001 18:04:00.787825  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144086 (* 1 = 0.144086 loss)
I1001 18:04:00.787842  5416 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1001 18:04:06.040136  5416 solver.cpp:218] Iteration 49900 (19.0393 iter/s, 5.2523s/100 iters), loss = 0.0756192
I1001 18:04:06.040171  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756188 (* 1 = 0.0756188 loss)
I1001 18:04:06.040180  5416 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1001 18:04:11.024309  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:04:11.233923  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_50000.caffemodel
I1001 18:04:11.238721  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_50000.solverstate
I1001 18:04:11.240059  5416 solver.cpp:330] Iteration 50000, Testing net (#0)
I1001 18:04:12.437870  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:04:12.488070  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9009
I1001 18:04:12.488098  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34129 (* 1 = 0.34129 loss)
I1001 18:04:12.540859  5416 solver.cpp:218] Iteration 50000 (15.383 iter/s, 6.50067s/100 iters), loss = 0.0240378
I1001 18:04:12.540889  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240375 (* 1 = 0.0240375 loss)
I1001 18:04:12.540899  5416 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1001 18:04:17.789585  5416 solver.cpp:218] Iteration 50100 (19.0524 iter/s, 5.24867s/100 iters), loss = 0.0407399
I1001 18:04:17.789625  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407396 (* 1 = 0.0407396 loss)
I1001 18:04:17.789634  5416 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1001 18:04:23.036829  5416 solver.cpp:218] Iteration 50200 (19.0578 iter/s, 5.24719s/100 iters), loss = 0.0840038
I1001 18:04:23.036862  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0840035 (* 1 = 0.0840035 loss)
I1001 18:04:23.036880  5416 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1001 18:04:28.287832  5416 solver.cpp:218] Iteration 50300 (19.0442 iter/s, 5.25095s/100 iters), loss = 0.0442858
I1001 18:04:28.287864  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0442854 (* 1 = 0.0442854 loss)
I1001 18:04:28.287871  5416 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1001 18:04:33.535758  5416 solver.cpp:218] Iteration 50400 (19.0553 iter/s, 5.24788s/100 iters), loss = 0.014199
I1001 18:04:33.535881  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141987 (* 1 = 0.0141987 loss)
I1001 18:04:33.535903  5416 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1001 18:04:38.513725  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:04:38.726303  5416 solver.cpp:330] Iteration 50500, Testing net (#0)
I1001 18:04:39.922754  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:04:39.972865  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8964
I1001 18:04:39.972892  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361061 (* 1 = 0.361061 loss)
I1001 18:04:40.025882  5416 solver.cpp:218] Iteration 50500 (15.4084 iter/s, 6.48998s/100 iters), loss = 0.0384186
I1001 18:04:40.025908  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384183 (* 1 = 0.0384183 loss)
I1001 18:04:40.025918  5416 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1001 18:04:45.277515  5416 solver.cpp:218] Iteration 50600 (19.0419 iter/s, 5.25159s/100 iters), loss = 0.0351075
I1001 18:04:45.277547  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351072 (* 1 = 0.0351072 loss)
I1001 18:04:45.277556  5416 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1001 18:04:50.522874  5416 solver.cpp:218] Iteration 50700 (19.0647 iter/s, 5.24531s/100 iters), loss = 0.0665279
I1001 18:04:50.522905  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665276 (* 1 = 0.0665276 loss)
I1001 18:04:50.522923  5416 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1001 18:04:55.782172  5416 solver.cpp:218] Iteration 50800 (19.0141 iter/s, 5.25925s/100 iters), loss = 0.0416196
I1001 18:04:55.782212  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416193 (* 1 = 0.0416193 loss)
I1001 18:04:55.782218  5416 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1001 18:05:01.043059  5416 solver.cpp:218] Iteration 50900 (19.0084 iter/s, 5.26083s/100 iters), loss = 0.0397915
I1001 18:05:01.043100  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397912 (* 1 = 0.0397912 loss)
I1001 18:05:01.043107  5416 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1001 18:05:06.038296  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:05:06.247383  5416 solver.cpp:330] Iteration 51000, Testing net (#0)
I1001 18:05:07.437127  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:05:07.487843  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8991
I1001 18:05:07.487866  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360222 (* 1 = 0.360222 loss)
I1001 18:05:07.540443  5416 solver.cpp:218] Iteration 51000 (15.391 iter/s, 6.49732s/100 iters), loss = 0.020007
I1001 18:05:07.540470  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200067 (* 1 = 0.0200067 loss)
I1001 18:05:07.540477  5416 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1001 18:05:12.796486  5416 solver.cpp:218] Iteration 51100 (19.0259 iter/s, 5.25599s/100 iters), loss = 0.0604129
I1001 18:05:12.796526  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604126 (* 1 = 0.0604126 loss)
I1001 18:05:12.796532  5416 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1001 18:05:18.045372  5416 solver.cpp:218] Iteration 51200 (19.0519 iter/s, 5.24883s/100 iters), loss = 0.0840484
I1001 18:05:18.045410  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0840481 (* 1 = 0.0840481 loss)
I1001 18:05:18.045418  5416 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1001 18:05:23.288692  5416 solver.cpp:218] Iteration 51300 (19.0721 iter/s, 5.24326s/100 iters), loss = 0.0416174
I1001 18:05:23.288724  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416172 (* 1 = 0.0416172 loss)
I1001 18:05:23.288743  5416 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1001 18:05:28.537989  5416 solver.cpp:218] Iteration 51400 (19.0504 iter/s, 5.24924s/100 iters), loss = 0.0194595
I1001 18:05:28.538018  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194592 (* 1 = 0.0194592 loss)
I1001 18:05:28.538024  5416 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1001 18:05:33.527144  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:05:33.737246  5416 solver.cpp:330] Iteration 51500, Testing net (#0)
I1001 18:05:34.928589  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:05:34.978852  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I1001 18:05:34.978878  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358098 (* 1 = 0.358098 loss)
I1001 18:05:35.031992  5416 solver.cpp:218] Iteration 51500 (15.3989 iter/s, 6.49395s/100 iters), loss = 0.0352167
I1001 18:05:35.032022  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352165 (* 1 = 0.0352165 loss)
I1001 18:05:35.032029  5416 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1001 18:05:40.283782  5416 solver.cpp:218] Iteration 51600 (19.0413 iter/s, 5.25174s/100 iters), loss = 0.0556651
I1001 18:05:40.283918  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556648 (* 1 = 0.0556648 loss)
I1001 18:05:40.283934  5416 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1001 18:05:45.537971  5416 solver.cpp:218] Iteration 51700 (19.033 iter/s, 5.25404s/100 iters), loss = 0.0477594
I1001 18:05:45.538003  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477592 (* 1 = 0.0477592 loss)
I1001 18:05:45.538022  5416 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1001 18:05:50.790467  5416 solver.cpp:218] Iteration 51800 (19.0388 iter/s, 5.25244s/100 iters), loss = 0.017469
I1001 18:05:50.790513  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174687 (* 1 = 0.0174687 loss)
I1001 18:05:50.790524  5416 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1001 18:05:56.042389  5416 solver.cpp:218] Iteration 51900 (19.041 iter/s, 5.25182s/100 iters), loss = 0.0195359
I1001 18:05:56.042428  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195356 (* 1 = 0.0195356 loss)
I1001 18:05:56.042434  5416 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1001 18:06:01.032665  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:06:01.243302  5416 solver.cpp:330] Iteration 52000, Testing net (#0)
I1001 18:06:02.434437  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:06:02.484881  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I1001 18:06:02.484917  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365049 (* 1 = 0.365049 loss)
I1001 18:06:02.537420  5416 solver.cpp:218] Iteration 52000 (15.3965 iter/s, 6.49497s/100 iters), loss = 0.033296
I1001 18:06:02.537447  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332957 (* 1 = 0.0332957 loss)
I1001 18:06:02.537453  5416 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1001 18:06:07.791890  5416 solver.cpp:218] Iteration 52100 (19.0316 iter/s, 5.25442s/100 iters), loss = 0.0699424
I1001 18:06:07.791931  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0699421 (* 1 = 0.0699421 loss)
I1001 18:06:07.791939  5416 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1001 18:06:13.043556  5416 solver.cpp:218] Iteration 52200 (19.0418 iter/s, 5.2516s/100 iters), loss = 0.0294108
I1001 18:06:13.043696  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294104 (* 1 = 0.0294104 loss)
I1001 18:06:13.043705  5416 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1001 18:06:18.291013  5416 solver.cpp:218] Iteration 52300 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.0414261
I1001 18:06:18.291054  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414258 (* 1 = 0.0414258 loss)
I1001 18:06:18.291061  5416 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1001 18:06:23.533283  5416 solver.cpp:218] Iteration 52400 (19.0759 iter/s, 5.24221s/100 iters), loss = 0.00562067
I1001 18:06:23.533324  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562035 (* 1 = 0.00562035 loss)
I1001 18:06:23.533329  5416 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1001 18:06:28.529554  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:06:28.739718  5416 solver.cpp:330] Iteration 52500, Testing net (#0)
I1001 18:06:29.939231  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:06:29.989336  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9045
I1001 18:06:29.989364  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349381 (* 1 = 0.349381 loss)
I1001 18:06:30.042138  5416 solver.cpp:218] Iteration 52500 (15.3638 iter/s, 6.50879s/100 iters), loss = 0.0392722
I1001 18:06:30.042171  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392719 (* 1 = 0.0392719 loss)
I1001 18:06:30.042177  5416 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1001 18:06:35.287308  5416 solver.cpp:218] Iteration 52600 (19.0654 iter/s, 5.24512s/100 iters), loss = 0.0682246
I1001 18:06:35.287338  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682243 (* 1 = 0.0682243 loss)
I1001 18:06:35.287343  5416 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1001 18:06:40.538000  5416 solver.cpp:218] Iteration 52700 (19.0453 iter/s, 5.25064s/100 iters), loss = 0.0758611
I1001 18:06:40.538029  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0758608 (* 1 = 0.0758608 loss)
I1001 18:06:40.538044  5416 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1001 18:06:45.787060  5416 solver.cpp:218] Iteration 52800 (19.0512 iter/s, 5.24901s/100 iters), loss = 0.0360409
I1001 18:06:45.787169  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360405 (* 1 = 0.0360405 loss)
I1001 18:06:45.787180  5416 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1001 18:06:51.040063  5416 solver.cpp:218] Iteration 52900 (19.0372 iter/s, 5.25288s/100 iters), loss = 0.0155486
I1001 18:06:51.040094  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155483 (* 1 = 0.0155483 loss)
I1001 18:06:51.040102  5416 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1001 18:06:56.013712  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:06:56.223754  5416 solver.cpp:330] Iteration 53000, Testing net (#0)
I1001 18:06:57.420572  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:06:57.470571  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9029
I1001 18:06:57.470607  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362571 (* 1 = 0.362571 loss)
I1001 18:06:57.522976  5416 solver.cpp:218] Iteration 53000 (15.4253 iter/s, 6.48286s/100 iters), loss = 0.0229546
I1001 18:06:57.523007  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229542 (* 1 = 0.0229542 loss)
I1001 18:06:57.523015  5416 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1001 18:07:02.765058  5416 solver.cpp:218] Iteration 53100 (19.0766 iter/s, 5.24202s/100 iters), loss = 0.0277562
I1001 18:07:02.765094  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277559 (* 1 = 0.0277559 loss)
I1001 18:07:02.765100  5416 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1001 18:07:08.011433  5416 solver.cpp:218] Iteration 53200 (19.061 iter/s, 5.24632s/100 iters), loss = 0.0112106
I1001 18:07:08.011466  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112103 (* 1 = 0.0112103 loss)
I1001 18:07:08.011471  5416 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1001 18:07:13.266216  5416 solver.cpp:218] Iteration 53300 (19.0305 iter/s, 5.25473s/100 iters), loss = 0.117587
I1001 18:07:13.266257  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117587 (* 1 = 0.117587 loss)
I1001 18:07:13.266261  5416 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1001 18:07:18.522675  5416 solver.cpp:218] Iteration 53400 (19.0244 iter/s, 5.2564s/100 iters), loss = 0.0105339
I1001 18:07:18.522799  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105336 (* 1 = 0.0105336 loss)
I1001 18:07:18.522817  5416 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1001 18:07:23.501500  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:07:23.714777  5416 solver.cpp:330] Iteration 53500, Testing net (#0)
I1001 18:07:24.912328  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:07:24.962823  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9062
I1001 18:07:24.962847  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34055 (* 1 = 0.34055 loss)
I1001 18:07:25.015501  5416 solver.cpp:218] Iteration 53500 (15.4019 iter/s, 6.49269s/100 iters), loss = 0.0173254
I1001 18:07:25.015530  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173251 (* 1 = 0.0173251 loss)
I1001 18:07:25.015537  5416 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1001 18:07:30.272534  5416 solver.cpp:218] Iteration 53600 (19.0223 iter/s, 5.25698s/100 iters), loss = 0.0970704
I1001 18:07:30.272575  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0970701 (* 1 = 0.0970701 loss)
I1001 18:07:30.272583  5416 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1001 18:07:35.516433  5416 solver.cpp:218] Iteration 53700 (19.07 iter/s, 5.24383s/100 iters), loss = 0.0240185
I1001 18:07:35.516463  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240182 (* 1 = 0.0240182 loss)
I1001 18:07:35.516469  5416 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1001 18:07:40.773301  5416 solver.cpp:218] Iteration 53800 (19.0229 iter/s, 5.25682s/100 iters), loss = 0.0479354
I1001 18:07:40.773332  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479351 (* 1 = 0.0479351 loss)
I1001 18:07:40.773339  5416 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1001 18:07:46.025979  5416 solver.cpp:218] Iteration 53900 (19.0381 iter/s, 5.25262s/100 iters), loss = 0.0176995
I1001 18:07:46.026021  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176992 (* 1 = 0.0176992 loss)
I1001 18:07:46.026026  5416 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1001 18:07:51.015647  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:07:51.226574  5416 solver.cpp:330] Iteration 54000, Testing net (#0)
I1001 18:07:52.416890  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:07:52.467351  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8915
I1001 18:07:52.467376  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.401028 (* 1 = 0.401028 loss)
I1001 18:07:52.520261  5416 solver.cpp:218] Iteration 54000 (15.3983 iter/s, 6.49422s/100 iters), loss = 0.0194202
I1001 18:07:52.520292  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194199 (* 1 = 0.0194199 loss)
I1001 18:07:52.520299  5416 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1001 18:07:57.770970  5416 solver.cpp:218] Iteration 54100 (19.0452 iter/s, 5.25066s/100 iters), loss = 0.0789569
I1001 18:07:57.771001  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0789566 (* 1 = 0.0789566 loss)
I1001 18:07:57.771008  5416 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1001 18:08:03.024927  5416 solver.cpp:218] Iteration 54200 (19.0335 iter/s, 5.2539s/100 iters), loss = 0.0405411
I1001 18:08:03.024958  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0405408 (* 1 = 0.0405408 loss)
I1001 18:08:03.024965  5416 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1001 18:08:08.268040  5416 solver.cpp:218] Iteration 54300 (19.0728 iter/s, 5.24306s/100 iters), loss = 0.0217892
I1001 18:08:08.268081  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217889 (* 1 = 0.0217889 loss)
I1001 18:08:08.268088  5416 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1001 18:08:13.522941  5416 solver.cpp:218] Iteration 54400 (19.0301 iter/s, 5.25484s/100 iters), loss = 0.0396596
I1001 18:08:13.522981  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396594 (* 1 = 0.0396594 loss)
I1001 18:08:13.522987  5416 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1001 18:08:18.514048  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:08:18.723177  5416 solver.cpp:330] Iteration 54500, Testing net (#0)
I1001 18:08:19.914491  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:08:19.964697  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8901
I1001 18:08:19.964721  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411335 (* 1 = 0.411335 loss)
I1001 18:08:20.016988  5416 solver.cpp:218] Iteration 54500 (15.3989 iter/s, 6.49399s/100 iters), loss = 0.0306558
I1001 18:08:20.017015  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306555 (* 1 = 0.0306555 loss)
I1001 18:08:20.017022  5416 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1001 18:08:25.270035  5416 solver.cpp:218] Iteration 54600 (19.0367 iter/s, 5.253s/100 iters), loss = 0.0382224
I1001 18:08:25.270150  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382221 (* 1 = 0.0382221 loss)
I1001 18:08:25.270167  5416 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1001 18:08:30.521486  5416 solver.cpp:218] Iteration 54700 (19.0428 iter/s, 5.25132s/100 iters), loss = 0.102469
I1001 18:08:30.521526  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102469 (* 1 = 0.102469 loss)
I1001 18:08:30.521533  5416 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1001 18:08:35.768460  5416 solver.cpp:218] Iteration 54800 (19.0588 iter/s, 5.24691s/100 iters), loss = 0.0315793
I1001 18:08:35.768493  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315791 (* 1 = 0.0315791 loss)
I1001 18:08:35.768501  5416 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1001 18:08:41.009354  5416 solver.cpp:218] Iteration 54900 (19.0809 iter/s, 5.24084s/100 iters), loss = 0.0243818
I1001 18:08:41.009384  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243815 (* 1 = 0.0243815 loss)
I1001 18:08:41.009392  5416 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1001 18:08:45.993393  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:08:46.203378  5416 solver.cpp:330] Iteration 55000, Testing net (#0)
I1001 18:08:47.393229  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:08:47.443637  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8882
I1001 18:08:47.443671  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.438371 (* 1 = 0.438371 loss)
I1001 18:08:47.495981  5416 solver.cpp:218] Iteration 55000 (15.4165 iter/s, 6.48658s/100 iters), loss = 0.0294035
I1001 18:08:47.496007  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294033 (* 1 = 0.0294033 loss)
I1001 18:08:47.496014  5416 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1001 18:08:52.749089  5416 solver.cpp:218] Iteration 55100 (19.0365 iter/s, 5.25306s/100 iters), loss = 0.0231781
I1001 18:08:52.749119  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231779 (* 1 = 0.0231779 loss)
I1001 18:08:52.749127  5416 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1001 18:08:58.001734  5416 solver.cpp:218] Iteration 55200 (19.0382 iter/s, 5.25259s/100 iters), loss = 0.0269793
I1001 18:08:58.001849  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026979 (* 1 = 0.026979 loss)
I1001 18:08:58.001880  5416 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1001 18:09:03.254276  5416 solver.cpp:218] Iteration 55300 (19.0389 iter/s, 5.25241s/100 iters), loss = 0.0325886
I1001 18:09:03.254320  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325884 (* 1 = 0.0325884 loss)
I1001 18:09:03.254328  5416 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1001 18:09:08.501055  5416 solver.cpp:218] Iteration 55400 (19.0595 iter/s, 5.24672s/100 iters), loss = 0.0409451
I1001 18:09:08.501085  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409448 (* 1 = 0.0409448 loss)
I1001 18:09:08.501091  5416 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1001 18:09:13.485247  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:09:13.695070  5416 solver.cpp:330] Iteration 55500, Testing net (#0)
I1001 18:09:14.892115  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:09:14.942723  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8949
I1001 18:09:14.942759  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394591 (* 1 = 0.394591 loss)
I1001 18:09:14.995430  5416 solver.cpp:218] Iteration 55500 (15.3981 iter/s, 6.49432s/100 iters), loss = 0.0286457
I1001 18:09:14.995463  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286454 (* 1 = 0.0286454 loss)
I1001 18:09:14.995471  5416 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1001 18:09:20.243379  5416 solver.cpp:218] Iteration 55600 (19.0552 iter/s, 5.2479s/100 iters), loss = 0.0102706
I1001 18:09:20.243420  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102704 (* 1 = 0.0102704 loss)
I1001 18:09:20.243427  5416 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1001 18:09:25.502326  5416 solver.cpp:218] Iteration 55700 (19.0154 iter/s, 5.25888s/100 iters), loss = 0.0267837
I1001 18:09:25.502367  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267835 (* 1 = 0.0267835 loss)
I1001 18:09:25.502372  5416 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1001 18:09:30.760123  5416 solver.cpp:218] Iteration 55800 (19.0196 iter/s, 5.25773s/100 iters), loss = 0.0300256
I1001 18:09:30.760288  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300254 (* 1 = 0.0300254 loss)
I1001 18:09:30.760308  5416 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1001 18:09:36.017354  5416 solver.cpp:218] Iteration 55900 (19.0221 iter/s, 5.25704s/100 iters), loss = 0.0309369
I1001 18:09:36.017385  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309367 (* 1 = 0.0309367 loss)
I1001 18:09:36.017391  5416 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1001 18:09:41.001639  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:09:41.211376  5416 solver.cpp:330] Iteration 56000, Testing net (#0)
I1001 18:09:42.411239  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:09:42.461890  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.901
I1001 18:09:42.461915  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38076 (* 1 = 0.38076 loss)
I1001 18:09:42.514578  5416 solver.cpp:218] Iteration 56000 (15.3913 iter/s, 6.49717s/100 iters), loss = 0.0624015
I1001 18:09:42.514603  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0624012 (* 1 = 0.0624012 loss)
I1001 18:09:42.514609  5416 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1001 18:09:47.761071  5416 solver.cpp:218] Iteration 56100 (19.0605 iter/s, 5.24644s/100 iters), loss = 0.094297
I1001 18:09:47.761108  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0942968 (* 1 = 0.0942968 loss)
I1001 18:09:47.761116  5416 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1001 18:09:53.009546  5416 solver.cpp:218] Iteration 56200 (19.0534 iter/s, 5.24842s/100 iters), loss = 0.0311934
I1001 18:09:53.009577  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311932 (* 1 = 0.0311932 loss)
I1001 18:09:53.009593  5416 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1001 18:09:58.264756  5416 solver.cpp:218] Iteration 56300 (19.0289 iter/s, 5.25516s/100 iters), loss = 0.0337401
I1001 18:09:58.264783  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337399 (* 1 = 0.0337399 loss)
I1001 18:09:58.264789  5416 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1001 18:10:03.519187  5416 solver.cpp:218] Iteration 56400 (19.0317 iter/s, 5.25438s/100 iters), loss = 0.0188259
I1001 18:10:03.519320  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188257 (* 1 = 0.0188257 loss)
I1001 18:10:03.519335  5416 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1001 18:10:08.501129  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:10:08.712908  5416 solver.cpp:330] Iteration 56500, Testing net (#0)
I1001 18:10:09.907759  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:10:09.958047  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8795
I1001 18:10:09.958070  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.488873 (* 1 = 0.488873 loss)
I1001 18:10:10.010735  5416 solver.cpp:218] Iteration 56500 (15.405 iter/s, 6.49139s/100 iters), loss = 0.0163966
I1001 18:10:10.010764  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163964 (* 1 = 0.0163964 loss)
I1001 18:10:10.010771  5416 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1001 18:10:15.262179  5416 solver.cpp:218] Iteration 56600 (19.0426 iter/s, 5.25139s/100 iters), loss = 0.0275367
I1001 18:10:15.262223  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275364 (* 1 = 0.0275364 loss)
I1001 18:10:15.262229  5416 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1001 18:10:20.505182  5416 solver.cpp:218] Iteration 56700 (19.0733 iter/s, 5.24294s/100 iters), loss = 0.0241869
I1001 18:10:20.505223  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241867 (* 1 = 0.0241867 loss)
I1001 18:10:20.505228  5416 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1001 18:10:25.756983  5416 solver.cpp:218] Iteration 56800 (19.0413 iter/s, 5.25174s/100 iters), loss = 0.0608196
I1001 18:10:25.757012  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0608194 (* 1 = 0.0608194 loss)
I1001 18:10:25.757019  5416 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1001 18:10:31.018811  5416 solver.cpp:218] Iteration 56900 (19.005 iter/s, 5.26178s/100 iters), loss = 0.0538062
I1001 18:10:31.018841  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.053806 (* 1 = 0.053806 loss)
I1001 18:10:31.018847  5416 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1001 18:10:36.015272  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:10:36.225482  5416 solver.cpp:330] Iteration 57000, Testing net (#0)
I1001 18:10:37.415665  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:10:37.465778  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I1001 18:10:37.465802  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371456 (* 1 = 0.371456 loss)
I1001 18:10:37.518257  5416 solver.cpp:218] Iteration 57000 (15.386 iter/s, 6.4994s/100 iters), loss = 0.014248
I1001 18:10:37.518285  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142478 (* 1 = 0.0142478 loss)
I1001 18:10:37.518292  5416 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1001 18:10:42.774283  5416 solver.cpp:218] Iteration 57100 (19.026 iter/s, 5.25598s/100 iters), loss = 0.00745273
I1001 18:10:42.774323  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745248 (* 1 = 0.00745248 loss)
I1001 18:10:42.774329  5416 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1001 18:10:48.031414  5416 solver.cpp:218] Iteration 57200 (19.022 iter/s, 5.25707s/100 iters), loss = 0.0711849
I1001 18:10:48.031448  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0711846 (* 1 = 0.0711846 loss)
I1001 18:10:48.031455  5416 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1001 18:10:53.280875  5416 solver.cpp:218] Iteration 57300 (19.0498 iter/s, 5.2494s/100 iters), loss = 0.0215443
I1001 18:10:53.280915  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215441 (* 1 = 0.0215441 loss)
I1001 18:10:53.280921  5416 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1001 18:10:58.534884  5416 solver.cpp:218] Iteration 57400 (19.0333 iter/s, 5.25395s/100 iters), loss = 0.020838
I1001 18:10:58.534925  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208378 (* 1 = 0.0208378 loss)
I1001 18:10:58.534931  5416 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1001 18:11:03.529577  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:11:03.740207  5416 solver.cpp:330] Iteration 57500, Testing net (#0)
I1001 18:11:04.932579  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:11:04.983031  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8959
I1001 18:11:04.983067  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385204 (* 1 = 0.385204 loss)
I1001 18:11:05.035646  5416 solver.cpp:218] Iteration 57500 (15.3829 iter/s, 6.5007s/100 iters), loss = 0.0164448
I1001 18:11:05.035671  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164446 (* 1 = 0.0164446 loss)
I1001 18:11:05.035678  5416 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1001 18:11:10.285395  5416 solver.cpp:218] Iteration 57600 (19.0487 iter/s, 5.2497s/100 iters), loss = 0.0667195
I1001 18:11:10.285545  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0667193 (* 1 = 0.0667193 loss)
I1001 18:11:10.285554  5416 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1001 18:11:15.536340  5416 solver.cpp:218] Iteration 57700 (19.0448 iter/s, 5.25077s/100 iters), loss = 0.0629964
I1001 18:11:15.536381  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0629961 (* 1 = 0.0629961 loss)
I1001 18:11:15.536387  5416 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1001 18:11:20.783706  5416 solver.cpp:218] Iteration 57800 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.00542995
I1001 18:11:20.783756  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542973 (* 1 = 0.00542973 loss)
I1001 18:11:20.783764  5416 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1001 18:11:26.029976  5416 solver.cpp:218] Iteration 57900 (19.0614 iter/s, 5.2462s/100 iters), loss = 0.0225025
I1001 18:11:26.030017  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225023 (* 1 = 0.0225023 loss)
I1001 18:11:26.030023  5416 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1001 18:11:31.021126  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:11:31.231703  5416 solver.cpp:330] Iteration 58000, Testing net (#0)
I1001 18:11:32.420629  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:11:32.471160  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8965
I1001 18:11:32.471196  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393661 (* 1 = 0.393661 loss)
I1001 18:11:32.523594  5416 solver.cpp:218] Iteration 58000 (15.3999 iter/s, 6.49356s/100 iters), loss = 0.0271698
I1001 18:11:32.523620  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271696 (* 1 = 0.0271696 loss)
I1001 18:11:32.523627  5416 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1001 18:11:37.774685  5416 solver.cpp:218] Iteration 58100 (19.0438 iter/s, 5.25104s/100 iters), loss = 0.0437719
I1001 18:11:37.774718  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437717 (* 1 = 0.0437717 loss)
I1001 18:11:37.774736  5416 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1001 18:11:43.024741  5416 solver.cpp:218] Iteration 58200 (19.0476 iter/s, 5.25s/100 iters), loss = 0.0283219
I1001 18:11:43.024870  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283217 (* 1 = 0.0283217 loss)
I1001 18:11:43.024878  5416 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1001 18:11:48.275933  5416 solver.cpp:218] Iteration 58300 (19.0438 iter/s, 5.25105s/100 iters), loss = 0.0722994
I1001 18:11:48.275962  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0722992 (* 1 = 0.0722992 loss)
I1001 18:11:48.275969  5416 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1001 18:11:53.518818  5416 solver.cpp:218] Iteration 58400 (19.0737 iter/s, 5.24283s/100 iters), loss = 0.0297006
I1001 18:11:53.518860  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297004 (* 1 = 0.0297004 loss)
I1001 18:11:53.518867  5416 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1001 18:11:58.508581  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:11:58.718611  5416 solver.cpp:330] Iteration 58500, Testing net (#0)
I1001 18:11:59.914381  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:11:59.964926  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8836
I1001 18:11:59.964960  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.487421 (* 1 = 0.487421 loss)
I1001 18:12:00.017573  5416 solver.cpp:218] Iteration 58500 (15.3877 iter/s, 6.49869s/100 iters), loss = 0.0159151
I1001 18:12:00.017603  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159149 (* 1 = 0.0159149 loss)
I1001 18:12:00.017609  5416 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1001 18:12:05.264587  5416 solver.cpp:218] Iteration 58600 (19.0586 iter/s, 5.24696s/100 iters), loss = 0.010392
I1001 18:12:05.264629  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103918 (* 1 = 0.0103918 loss)
I1001 18:12:05.264636  5416 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1001 18:12:10.515185  5416 solver.cpp:218] Iteration 58700 (19.0457 iter/s, 5.25054s/100 iters), loss = 0.0339345
I1001 18:12:10.515224  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339343 (* 1 = 0.0339343 loss)
I1001 18:12:10.515229  5416 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1001 18:12:15.771131  5416 solver.cpp:218] Iteration 58800 (19.0263 iter/s, 5.25588s/100 iters), loss = 0.0420895
I1001 18:12:15.771276  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420893 (* 1 = 0.0420893 loss)
I1001 18:12:15.771293  5416 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1001 18:12:21.025717  5416 solver.cpp:218] Iteration 58900 (19.0316 iter/s, 5.25441s/100 iters), loss = 0.0422045
I1001 18:12:21.025748  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422042 (* 1 = 0.0422042 loss)
I1001 18:12:21.025756  5416 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1001 18:12:26.007707  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:12:26.218678  5416 solver.cpp:330] Iteration 59000, Testing net (#0)
I1001 18:12:27.417847  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:12:27.468298  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8945
I1001 18:12:27.468323  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.421795 (* 1 = 0.421795 loss)
I1001 18:12:27.520761  5416 solver.cpp:218] Iteration 59000 (15.3965 iter/s, 6.49499s/100 iters), loss = 0.0173477
I1001 18:12:27.520790  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173475 (* 1 = 0.0173475 loss)
I1001 18:12:27.520797  5416 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1001 18:12:32.764046  5416 solver.cpp:218] Iteration 59100 (19.0722 iter/s, 5.24323s/100 iters), loss = 0.0674077
I1001 18:12:32.764083  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0674075 (* 1 = 0.0674075 loss)
I1001 18:12:32.764093  5416 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1001 18:12:38.010751  5416 solver.cpp:218] Iteration 59200 (19.0599 iter/s, 5.24661s/100 iters), loss = 0.0414923
I1001 18:12:38.010785  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041492 (* 1 = 0.041492 loss)
I1001 18:12:38.010803  5416 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1001 18:12:43.261764  5416 solver.cpp:218] Iteration 59300 (19.0442 iter/s, 5.25096s/100 iters), loss = 0.0267213
I1001 18:12:43.261803  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026721 (* 1 = 0.026721 loss)
I1001 18:12:43.261811  5416 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1001 18:12:48.517699  5416 solver.cpp:218] Iteration 59400 (19.0263 iter/s, 5.25587s/100 iters), loss = 0.0269492
I1001 18:12:48.517827  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269489 (* 1 = 0.0269489 loss)
I1001 18:12:48.517848  5416 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1001 18:12:53.500547  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:12:53.713039  5416 solver.cpp:330] Iteration 59500, Testing net (#0)
I1001 18:12:54.910051  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:12:54.960203  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8946
I1001 18:12:54.960228  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.435162 (* 1 = 0.435162 loss)
I1001 18:12:55.013176  5416 solver.cpp:218] Iteration 59500 (15.3957 iter/s, 6.49533s/100 iters), loss = 0.0191055
I1001 18:12:55.013202  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191053 (* 1 = 0.0191053 loss)
I1001 18:12:55.013209  5416 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1001 18:13:00.266098  5416 solver.cpp:218] Iteration 59600 (19.0372 iter/s, 5.25287s/100 iters), loss = 0.0380488
I1001 18:13:00.266129  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380486 (* 1 = 0.0380486 loss)
I1001 18:13:00.266136  5416 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1001 18:13:05.504786  5416 solver.cpp:218] Iteration 59700 (19.089 iter/s, 5.23863s/100 iters), loss = 0.0465492
I1001 18:13:05.504814  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046549 (* 1 = 0.046549 loss)
I1001 18:13:05.504820  5416 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1001 18:13:10.753239  5416 solver.cpp:218] Iteration 59800 (19.0534 iter/s, 5.2484s/100 iters), loss = 0.0119113
I1001 18:13:10.753268  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011911 (* 1 = 0.011911 loss)
I1001 18:13:10.753274  5416 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1001 18:13:16.005198  5416 solver.cpp:218] Iteration 59900 (19.0407 iter/s, 5.25191s/100 iters), loss = 0.0157689
I1001 18:13:16.005228  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157687 (* 1 = 0.0157687 loss)
I1001 18:13:16.005236  5416 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1001 18:13:20.994901  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:13:21.203908  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_60000.caffemodel
I1001 18:13:21.208781  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_60000.solverstate
I1001 18:13:21.210101  5416 solver.cpp:330] Iteration 60000, Testing net (#0)
I1001 18:13:22.400123  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:13:22.450496  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8949
I1001 18:13:22.450534  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42072 (* 1 = 0.42072 loss)
I1001 18:13:22.503100  5416 solver.cpp:218] Iteration 60000 (15.3897 iter/s, 6.49785s/100 iters), loss = 0.0154302
I1001 18:13:22.503126  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01543 (* 1 = 0.01543 loss)
I1001 18:13:22.503134  5416 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1001 18:13:27.757393  5416 solver.cpp:218] Iteration 60100 (19.0322 iter/s, 5.25425s/100 iters), loss = 0.0903876
I1001 18:13:27.757423  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0903873 (* 1 = 0.0903873 loss)
I1001 18:13:27.757429  5416 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1001 18:13:33.004668  5416 solver.cpp:218] Iteration 60200 (19.0577 iter/s, 5.24722s/100 iters), loss = 0.010178
I1001 18:13:33.004710  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101777 (* 1 = 0.0101777 loss)
I1001 18:13:33.004717  5416 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1001 18:13:38.247661  5416 solver.cpp:218] Iteration 60300 (19.0733 iter/s, 5.24293s/100 iters), loss = 0.0461065
I1001 18:13:38.247701  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461062 (* 1 = 0.0461062 loss)
I1001 18:13:38.247707  5416 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1001 18:13:43.502432  5416 solver.cpp:218] Iteration 60400 (19.0305 iter/s, 5.25471s/100 iters), loss = 0.0746842
I1001 18:13:43.502471  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0746839 (* 1 = 0.0746839 loss)
I1001 18:13:43.502477  5416 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1001 18:13:48.494123  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:13:48.704109  5416 solver.cpp:330] Iteration 60500, Testing net (#0)
I1001 18:13:49.897069  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:13:49.947463  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1001 18:13:49.947499  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385759 (* 1 = 0.385759 loss)
I1001 18:13:49.999879  5416 solver.cpp:218] Iteration 60500 (15.3908 iter/s, 6.49739s/100 iters), loss = 0.0153533
I1001 18:13:49.999907  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015353 (* 1 = 0.015353 loss)
I1001 18:13:49.999913  5416 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1001 18:13:55.256551  5416 solver.cpp:218] Iteration 60600 (19.0236 iter/s, 5.25662s/100 iters), loss = 0.0144264
I1001 18:13:55.256675  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144261 (* 1 = 0.0144261 loss)
I1001 18:13:55.256685  5416 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1001 18:14:00.513532  5416 solver.cpp:218] Iteration 60700 (19.0228 iter/s, 5.25684s/100 iters), loss = 0.0281413
I1001 18:14:00.513562  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028141 (* 1 = 0.028141 loss)
I1001 18:14:00.513568  5416 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1001 18:14:05.758797  5416 solver.cpp:218] Iteration 60800 (19.065 iter/s, 5.24521s/100 iters), loss = 0.0427971
I1001 18:14:05.758832  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427968 (* 1 = 0.0427968 loss)
I1001 18:14:05.758839  5416 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1001 18:14:11.005503  5416 solver.cpp:218] Iteration 60900 (19.0598 iter/s, 5.24665s/100 iters), loss = 0.0140481
I1001 18:14:11.005533  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140478 (* 1 = 0.0140478 loss)
I1001 18:14:11.005540  5416 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1001 18:14:15.993937  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:14:16.204663  5416 solver.cpp:330] Iteration 61000, Testing net (#0)
I1001 18:14:17.394955  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:14:17.445418  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8939
I1001 18:14:17.445453  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.446448 (* 1 = 0.446448 loss)
I1001 18:14:17.498147  5416 solver.cpp:218] Iteration 61000 (15.4022 iter/s, 6.49259s/100 iters), loss = 0.0174703
I1001 18:14:17.498172  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174701 (* 1 = 0.0174701 loss)
I1001 18:14:17.498178  5416 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1001 18:14:22.749749  5416 solver.cpp:218] Iteration 61100 (19.042 iter/s, 5.25156s/100 iters), loss = 0.0320667
I1001 18:14:22.749779  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320665 (* 1 = 0.0320665 loss)
I1001 18:14:22.749784  5416 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1001 18:14:28.001641  5416 solver.cpp:218] Iteration 61200 (19.0409 iter/s, 5.25184s/100 iters), loss = 0.0274694
I1001 18:14:28.001773  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274691 (* 1 = 0.0274691 loss)
I1001 18:14:28.001792  5416 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1001 18:14:33.256070  5416 solver.cpp:218] Iteration 61300 (19.0321 iter/s, 5.25429s/100 iters), loss = 0.0430752
I1001 18:14:33.256112  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430749 (* 1 = 0.0430749 loss)
I1001 18:14:33.256119  5416 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1001 18:14:38.499874  5416 solver.cpp:218] Iteration 61400 (19.0703 iter/s, 5.24374s/100 iters), loss = 0.0222657
I1001 18:14:38.499902  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222654 (* 1 = 0.0222654 loss)
I1001 18:14:38.499907  5416 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1001 18:14:43.491055  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:14:43.699462  5416 solver.cpp:330] Iteration 61500, Testing net (#0)
I1001 18:14:44.897070  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:14:44.947892  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8909
I1001 18:14:44.947919  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.437758 (* 1 = 0.437758 loss)
I1001 18:14:45.000610  5416 solver.cpp:218] Iteration 61500 (15.383 iter/s, 6.50069s/100 iters), loss = 0.022816
I1001 18:14:45.000646  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228157 (* 1 = 0.0228157 loss)
I1001 18:14:45.000653  5416 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1001 18:14:50.246448  5416 solver.cpp:218] Iteration 61600 (19.0629 iter/s, 5.24578s/100 iters), loss = 0.0182524
I1001 18:14:50.246487  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182522 (* 1 = 0.0182522 loss)
I1001 18:14:50.246493  5416 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1001 18:14:55.497926  5416 solver.cpp:218] Iteration 61700 (19.0425 iter/s, 5.25141s/100 iters), loss = 0.0434564
I1001 18:14:55.497967  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434561 (* 1 = 0.0434561 loss)
I1001 18:14:55.497973  5416 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1001 18:15:00.748469  5416 solver.cpp:218] Iteration 61800 (19.0459 iter/s, 5.25048s/100 iters), loss = 0.013463
I1001 18:15:00.748608  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134628 (* 1 = 0.0134628 loss)
I1001 18:15:00.748616  5416 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1001 18:15:05.996459  5416 solver.cpp:218] Iteration 61900 (19.0555 iter/s, 5.24783s/100 iters), loss = 0.0395154
I1001 18:15:05.996490  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395152 (* 1 = 0.0395152 loss)
I1001 18:15:05.996496  5416 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1001 18:15:10.974766  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:15:11.184212  5416 solver.cpp:330] Iteration 62000, Testing net (#0)
I1001 18:15:12.380755  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:15:12.431324  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.892
I1001 18:15:12.431358  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.441479 (* 1 = 0.441479 loss)
I1001 18:15:12.484359  5416 solver.cpp:218] Iteration 62000 (15.4134 iter/s, 6.48785s/100 iters), loss = 0.0119011
I1001 18:15:12.484395  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119008 (* 1 = 0.0119008 loss)
I1001 18:15:12.484402  5416 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1001 18:15:17.730684  5416 solver.cpp:218] Iteration 62100 (19.0612 iter/s, 5.24627s/100 iters), loss = 0.0252214
I1001 18:15:17.730720  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252211 (* 1 = 0.0252211 loss)
I1001 18:15:17.730727  5416 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1001 18:15:22.985321  5416 solver.cpp:218] Iteration 62200 (19.031 iter/s, 5.25458s/100 iters), loss = 0.0256327
I1001 18:15:22.985361  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256325 (* 1 = 0.0256325 loss)
I1001 18:15:22.985368  5416 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1001 18:15:28.246186  5416 solver.cpp:218] Iteration 62300 (19.0085 iter/s, 5.2608s/100 iters), loss = 0.0419759
I1001 18:15:28.246227  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419756 (* 1 = 0.0419756 loss)
I1001 18:15:28.246233  5416 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1001 18:15:33.500964  5416 solver.cpp:218] Iteration 62400 (19.0305 iter/s, 5.25471s/100 iters), loss = 0.0126121
I1001 18:15:33.501075  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126119 (* 1 = 0.0126119 loss)
I1001 18:15:33.501081  5416 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1001 18:15:38.483822  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:15:38.694984  5416 solver.cpp:330] Iteration 62500, Testing net (#0)
I1001 18:15:39.888763  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:15:39.940479  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I1001 18:15:39.940505  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.430023 (* 1 = 0.430023 loss)
I1001 18:15:39.993458  5416 solver.cpp:218] Iteration 62500 (15.4027 iter/s, 6.49237s/100 iters), loss = 0.0702634
I1001 18:15:39.993484  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0702632 (* 1 = 0.0702632 loss)
I1001 18:15:39.993490  5416 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1001 18:15:45.245961  5416 solver.cpp:218] Iteration 62600 (19.0387 iter/s, 5.25246s/100 iters), loss = 0.0573376
I1001 18:15:45.245992  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0573373 (* 1 = 0.0573373 loss)
I1001 18:15:45.245998  5416 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1001 18:15:50.493729  5416 solver.cpp:218] Iteration 62700 (19.0559 iter/s, 5.24772s/100 iters), loss = 0.0130631
I1001 18:15:50.493760  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130629 (* 1 = 0.0130629 loss)
I1001 18:15:50.493767  5416 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1001 18:15:55.749481  5416 solver.cpp:218] Iteration 62800 (19.027 iter/s, 5.2557s/100 iters), loss = 0.0731181
I1001 18:15:55.749521  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0731178 (* 1 = 0.0731178 loss)
I1001 18:15:55.749526  5416 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1001 18:16:01.007266  5416 solver.cpp:218] Iteration 62900 (19.0196 iter/s, 5.25772s/100 iters), loss = 0.036932
I1001 18:16:01.007297  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369318 (* 1 = 0.0369318 loss)
I1001 18:16:01.007302  5416 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1001 18:16:06.004357  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:16:06.214773  5416 solver.cpp:330] Iteration 63000, Testing net (#0)
I1001 18:16:07.404394  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:16:07.454668  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I1001 18:16:07.454704  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398602 (* 1 = 0.398602 loss)
I1001 18:16:07.507155  5416 solver.cpp:218] Iteration 63000 (15.385 iter/s, 6.49984s/100 iters), loss = 0.0134517
I1001 18:16:07.507180  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134514 (* 1 = 0.0134514 loss)
I1001 18:16:07.507186  5416 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1001 18:16:12.757278  5416 solver.cpp:218] Iteration 63100 (19.0473 iter/s, 5.25008s/100 iters), loss = 0.0317576
I1001 18:16:12.757309  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317574 (* 1 = 0.0317574 loss)
I1001 18:16:12.757315  5416 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1001 18:16:18.007943  5416 solver.cpp:218] Iteration 63200 (19.0454 iter/s, 5.25061s/100 iters), loss = 0.0219091
I1001 18:16:18.007974  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219088 (* 1 = 0.0219088 loss)
I1001 18:16:18.007980  5416 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1001 18:16:23.250829  5416 solver.cpp:218] Iteration 63300 (19.0737 iter/s, 5.24283s/100 iters), loss = 0.094689
I1001 18:16:23.250859  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0946888 (* 1 = 0.0946888 loss)
I1001 18:16:23.250875  5416 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1001 18:16:28.504317  5416 solver.cpp:218] Iteration 63400 (19.0352 iter/s, 5.25344s/100 iters), loss = 0.0452032
I1001 18:16:28.504348  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045203 (* 1 = 0.045203 loss)
I1001 18:16:28.504364  5416 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1001 18:16:33.492914  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:16:33.703352  5416 solver.cpp:330] Iteration 63500, Testing net (#0)
I1001 18:16:34.891937  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:16:34.942286  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8981
I1001 18:16:34.942320  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412113 (* 1 = 0.412113 loss)
I1001 18:16:34.995455  5416 solver.cpp:218] Iteration 63500 (15.4057 iter/s, 6.49109s/100 iters), loss = 0.0158493
I1001 18:16:34.995484  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015849 (* 1 = 0.015849 loss)
I1001 18:16:34.995492  5416 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1001 18:16:40.245136  5416 solver.cpp:218] Iteration 63600 (19.049 iter/s, 5.24963s/100 iters), loss = 0.102025
I1001 18:16:40.245239  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102024 (* 1 = 0.102024 loss)
I1001 18:16:40.245246  5416 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1001 18:16:45.490491  5416 solver.cpp:218] Iteration 63700 (19.0649 iter/s, 5.24523s/100 iters), loss = 0.0153884
I1001 18:16:45.490523  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153882 (* 1 = 0.0153882 loss)
I1001 18:16:45.490530  5416 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1001 18:16:50.735765  5416 solver.cpp:218] Iteration 63800 (19.065 iter/s, 5.24522s/100 iters), loss = 0.0355098
I1001 18:16:50.735801  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355095 (* 1 = 0.0355095 loss)
I1001 18:16:50.735808  5416 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1001 18:16:55.985520  5416 solver.cpp:218] Iteration 63900 (19.0487 iter/s, 5.2497s/100 iters), loss = 0.0412643
I1001 18:16:55.985561  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412641 (* 1 = 0.0412641 loss)
I1001 18:16:55.985568  5416 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1001 18:17:00.978323  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:17:01.187985  5416 solver.cpp:330] Iteration 64000, Testing net (#0)
I1001 18:17:02.376870  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:17:02.427098  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8987
I1001 18:17:02.427134  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398475 (* 1 = 0.398475 loss)
I1001 18:17:02.479996  5416 solver.cpp:218] Iteration 64000 (15.3978 iter/s, 6.49442s/100 iters), loss = 0.0212126
I1001 18:17:02.480022  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212124 (* 1 = 0.0212124 loss)
I1001 18:17:02.480031  5416 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1001 18:17:07.729573  5416 solver.cpp:218] Iteration 64100 (19.0494 iter/s, 5.24952s/100 iters), loss = 0.0155568
I1001 18:17:07.729612  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155566 (* 1 = 0.0155566 loss)
I1001 18:17:07.729619  5416 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1001 18:17:12.981366  5416 solver.cpp:218] Iteration 64200 (19.0413 iter/s, 5.25173s/100 iters), loss = 0.00947945
I1001 18:17:12.981489  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00947923 (* 1 = 0.00947923 loss)
I1001 18:17:12.981505  5416 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1001 18:17:18.229740  5416 solver.cpp:218] Iteration 64300 (19.0541 iter/s, 5.24822s/100 iters), loss = 0.0119199
I1001 18:17:18.229789  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119197 (* 1 = 0.0119197 loss)
I1001 18:17:18.229799  5416 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1001 18:17:23.475025  5416 solver.cpp:218] Iteration 64400 (19.065 iter/s, 5.24523s/100 iters), loss = 0.0566872
I1001 18:17:23.475056  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056687 (* 1 = 0.056687 loss)
I1001 18:17:23.475072  5416 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1001 18:17:28.461941  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:17:28.669828  5416 solver.cpp:330] Iteration 64500, Testing net (#0)
I1001 18:17:29.863677  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:17:29.914908  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8949
I1001 18:17:29.914933  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42985 (* 1 = 0.42985 loss)
I1001 18:17:29.968768  5416 solver.cpp:218] Iteration 64500 (15.3996 iter/s, 6.49369s/100 iters), loss = 0.00851146
I1001 18:17:29.968802  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00851125 (* 1 = 0.00851125 loss)
I1001 18:17:29.968809  5416 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1001 18:17:35.216899  5416 solver.cpp:218] Iteration 64600 (19.0546 iter/s, 5.24807s/100 iters), loss = 0.00807546
I1001 18:17:35.216928  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00807525 (* 1 = 0.00807525 loss)
I1001 18:17:35.216935  5416 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1001 18:17:40.468112  5416 solver.cpp:218] Iteration 64700 (19.0434 iter/s, 5.25116s/100 iters), loss = 0.0149923
I1001 18:17:40.468156  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014992 (* 1 = 0.014992 loss)
I1001 18:17:40.468163  5416 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1001 18:17:45.720896  5416 solver.cpp:218] Iteration 64800 (19.0377 iter/s, 5.25272s/100 iters), loss = 0.0266516
I1001 18:17:45.721035  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266513 (* 1 = 0.0266513 loss)
I1001 18:17:45.721052  5416 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1001 18:17:50.977691  5416 solver.cpp:218] Iteration 64900 (19.0236 iter/s, 5.25664s/100 iters), loss = 0.010768
I1001 18:17:50.977726  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107678 (* 1 = 0.0107678 loss)
I1001 18:17:50.977735  5416 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1001 18:17:55.962554  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:17:56.173018  5416 solver.cpp:330] Iteration 65000, Testing net (#0)
I1001 18:17:57.371323  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:17:57.421919  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8948
I1001 18:17:57.421955  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.432518 (* 1 = 0.432518 loss)
I1001 18:17:57.474617  5416 solver.cpp:218] Iteration 65000 (15.392 iter/s, 6.49687s/100 iters), loss = 0.0338405
I1001 18:17:57.474653  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338403 (* 1 = 0.0338403 loss)
I1001 18:17:57.474659  5416 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1001 18:18:02.716869  5416 solver.cpp:218] Iteration 65100 (19.076 iter/s, 5.24219s/100 iters), loss = 0.0252738
I1001 18:18:02.716902  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252736 (* 1 = 0.0252736 loss)
I1001 18:18:02.716908  5416 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1001 18:18:07.961091  5416 solver.cpp:218] Iteration 65200 (19.0688 iter/s, 5.24417s/100 iters), loss = 0.024436
I1001 18:18:07.961132  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244358 (* 1 = 0.0244358 loss)
I1001 18:18:07.961138  5416 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1001 18:18:13.206845  5416 solver.cpp:218] Iteration 65300 (19.0633 iter/s, 5.24569s/100 iters), loss = 0.0132112
I1001 18:18:13.206884  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013211 (* 1 = 0.013211 loss)
I1001 18:18:13.206890  5416 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1001 18:18:18.453485  5416 solver.cpp:218] Iteration 65400 (19.0601 iter/s, 5.24657s/100 iters), loss = 0.00843487
I1001 18:18:18.453606  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00843466 (* 1 = 0.00843466 loss)
I1001 18:18:18.453615  5416 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1001 18:18:23.421830  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:18:23.631872  5416 solver.cpp:330] Iteration 65500, Testing net (#0)
I1001 18:18:24.827666  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:18:24.877864  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8955
I1001 18:18:24.877899  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413947 (* 1 = 0.413947 loss)
I1001 18:18:24.930057  5416 solver.cpp:218] Iteration 65500 (15.4406 iter/s, 6.47643s/100 iters), loss = 0.0142751
I1001 18:18:24.930079  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142749 (* 1 = 0.0142749 loss)
I1001 18:18:24.930085  5416 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1001 18:18:30.187945  5416 solver.cpp:218] Iteration 65600 (19.0192 iter/s, 5.25784s/100 iters), loss = 0.020473
I1001 18:18:30.187979  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204728 (* 1 = 0.0204728 loss)
I1001 18:18:30.187986  5416 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1001 18:18:35.432837  5416 solver.cpp:218] Iteration 65700 (19.0665 iter/s, 5.2448s/100 iters), loss = 0.0295876
I1001 18:18:35.432878  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295874 (* 1 = 0.0295874 loss)
I1001 18:18:35.432883  5416 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1001 18:18:40.687296  5416 solver.cpp:218] Iteration 65800 (19.0317 iter/s, 5.2544s/100 iters), loss = 0.0149601
I1001 18:18:40.687336  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149599 (* 1 = 0.0149599 loss)
I1001 18:18:40.687342  5416 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1001 18:18:45.943971  5416 solver.cpp:218] Iteration 65900 (19.0237 iter/s, 5.25661s/100 iters), loss = 0.0327999
I1001 18:18:45.944011  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327997 (* 1 = 0.0327997 loss)
I1001 18:18:45.944017  5416 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1001 18:18:50.932613  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:18:51.143909  5416 solver.cpp:330] Iteration 66000, Testing net (#0)
I1001 18:18:52.334414  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:18:52.384604  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9043
I1001 18:18:52.384639  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372916 (* 1 = 0.372916 loss)
I1001 18:18:52.436955  5416 solver.cpp:218] Iteration 66000 (15.4014 iter/s, 6.49292s/100 iters), loss = 0.0268563
I1001 18:18:52.436981  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268561 (* 1 = 0.0268561 loss)
I1001 18:18:52.436988  5416 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1001 18:18:57.678335  5416 solver.cpp:218] Iteration 66100 (19.0791 iter/s, 5.24133s/100 iters), loss = 0.0301584
I1001 18:18:57.678372  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301581 (* 1 = 0.0301581 loss)
I1001 18:18:57.678380  5416 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1001 18:19:02.922001  5416 solver.cpp:218] Iteration 66200 (19.0708 iter/s, 5.24361s/100 iters), loss = 0.0912054
I1001 18:19:02.922036  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0912052 (* 1 = 0.0912052 loss)
I1001 18:19:02.922044  5416 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1001 18:19:08.165135  5416 solver.cpp:218] Iteration 66300 (19.0728 iter/s, 5.24308s/100 iters), loss = 0.0478382
I1001 18:19:08.165166  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0478379 (* 1 = 0.0478379 loss)
I1001 18:19:08.165172  5416 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1001 18:19:13.417863  5416 solver.cpp:218] Iteration 66400 (19.0379 iter/s, 5.25268s/100 iters), loss = 0.0366371
I1001 18:19:13.417903  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366368 (* 1 = 0.0366368 loss)
I1001 18:19:13.417909  5416 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1001 18:19:18.410759  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:19:18.621630  5416 solver.cpp:330] Iteration 66500, Testing net (#0)
I1001 18:19:19.810211  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:19:19.860393  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8936
I1001 18:19:19.860427  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.432286 (* 1 = 0.432286 loss)
I1001 18:19:19.913030  5416 solver.cpp:218] Iteration 66500 (15.3962 iter/s, 6.49511s/100 iters), loss = 0.0101447
I1001 18:19:19.913054  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101445 (* 1 = 0.0101445 loss)
I1001 18:19:19.913061  5416 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1001 18:19:25.166219  5416 solver.cpp:218] Iteration 66600 (19.0362 iter/s, 5.25314s/100 iters), loss = 0.00517545
I1001 18:19:25.166337  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517518 (* 1 = 0.00517518 loss)
I1001 18:19:25.166353  5416 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1001 18:19:30.420727  5416 solver.cpp:218] Iteration 66700 (19.0317 iter/s, 5.25438s/100 iters), loss = 0.0129686
I1001 18:19:30.420758  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129684 (* 1 = 0.0129684 loss)
I1001 18:19:30.420764  5416 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1001 18:19:35.666165  5416 solver.cpp:218] Iteration 66800 (19.0644 iter/s, 5.24539s/100 iters), loss = 0.063577
I1001 18:19:35.666205  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0635767 (* 1 = 0.0635767 loss)
I1001 18:19:35.666211  5416 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1001 18:19:40.919087  5416 solver.cpp:218] Iteration 66900 (19.0372 iter/s, 5.25286s/100 iters), loss = 0.0102105
I1001 18:19:40.919117  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102102 (* 1 = 0.0102102 loss)
I1001 18:19:40.919133  5416 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1001 18:19:45.903497  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:19:46.113680  5416 solver.cpp:330] Iteration 67000, Testing net (#0)
I1001 18:19:47.302965  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:19:47.353408  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8931
I1001 18:19:47.353443  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42759 (* 1 = 0.42759 loss)
I1001 18:19:47.406040  5416 solver.cpp:218] Iteration 67000 (15.4157 iter/s, 6.4869s/100 iters), loss = 0.00684511
I1001 18:19:47.406064  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684484 (* 1 = 0.00684484 loss)
I1001 18:19:47.406071  5416 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1001 18:19:52.655172  5416 solver.cpp:218] Iteration 67100 (19.0509 iter/s, 5.24909s/100 iters), loss = 0.0262643
I1001 18:19:52.655202  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026264 (* 1 = 0.026264 loss)
I1001 18:19:52.655207  5416 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1001 18:19:57.904268  5416 solver.cpp:218] Iteration 67200 (19.0511 iter/s, 5.24904s/100 iters), loss = 0.0350116
I1001 18:19:57.904373  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350113 (* 1 = 0.0350113 loss)
I1001 18:19:57.904391  5416 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1001 18:20:03.160679  5416 solver.cpp:218] Iteration 67300 (19.0248 iter/s, 5.2563s/100 iters), loss = 0.0250176
I1001 18:20:03.160711  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250174 (* 1 = 0.0250174 loss)
I1001 18:20:03.160717  5416 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1001 18:20:08.404125  5416 solver.cpp:218] Iteration 67400 (19.0716 iter/s, 5.24339s/100 iters), loss = 0.035839
I1001 18:20:08.404155  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358387 (* 1 = 0.0358387 loss)
I1001 18:20:08.404160  5416 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1001 18:20:13.393961  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:20:13.602850  5416 solver.cpp:330] Iteration 67500, Testing net (#0)
I1001 18:20:14.795542  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:20:14.846968  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8805
I1001 18:20:14.846995  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.523349 (* 1 = 0.523349 loss)
I1001 18:20:14.901013  5416 solver.cpp:218] Iteration 67500 (15.3921 iter/s, 6.49682s/100 iters), loss = 0.00477766
I1001 18:20:14.901082  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477739 (* 1 = 0.00477739 loss)
I1001 18:20:14.901103  5416 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1001 18:20:20.150316  5416 solver.cpp:218] Iteration 67600 (19.0504 iter/s, 5.24922s/100 iters), loss = 0.0438699
I1001 18:20:20.150351  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438696 (* 1 = 0.0438696 loss)
I1001 18:20:20.150368  5416 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1001 18:20:25.404492  5416 solver.cpp:218] Iteration 67700 (19.0327 iter/s, 5.25412s/100 iters), loss = 0.0115685
I1001 18:20:25.404526  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115683 (* 1 = 0.0115683 loss)
I1001 18:20:25.404533  5416 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1001 18:20:30.652848  5416 solver.cpp:218] Iteration 67800 (19.0538 iter/s, 5.2483s/100 iters), loss = 0.0117468
I1001 18:20:30.652948  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117465 (* 1 = 0.0117465 loss)
I1001 18:20:30.652968  5416 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1001 18:20:35.902204  5416 solver.cpp:218] Iteration 67900 (19.0504 iter/s, 5.24923s/100 iters), loss = 0.0066027
I1001 18:20:35.902242  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660245 (* 1 = 0.00660245 loss)
I1001 18:20:35.902251  5416 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1001 18:20:40.879607  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:20:41.089740  5416 solver.cpp:330] Iteration 68000, Testing net (#0)
I1001 18:20:42.286679  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:20:42.337105  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.886
I1001 18:20:42.337141  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.50854 (* 1 = 0.50854 loss)
I1001 18:20:42.389997  5416 solver.cpp:218] Iteration 68000 (15.4137 iter/s, 6.48774s/100 iters), loss = 0.0145762
I1001 18:20:42.390027  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014576 (* 1 = 0.014576 loss)
I1001 18:20:42.390033  5416 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1001 18:20:47.635040  5416 solver.cpp:218] Iteration 68100 (19.0658 iter/s, 5.24499s/100 iters), loss = 0.0105816
I1001 18:20:47.635069  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105813 (* 1 = 0.0105813 loss)
I1001 18:20:47.635076  5416 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1001 18:20:52.890311  5416 solver.cpp:218] Iteration 68200 (19.0287 iter/s, 5.25522s/100 iters), loss = 0.0281472
I1001 18:20:52.890341  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028147 (* 1 = 0.028147 loss)
I1001 18:20:52.890347  5416 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1001 18:20:58.143988  5416 solver.cpp:218] Iteration 68300 (19.0345 iter/s, 5.25362s/100 iters), loss = 0.0481007
I1001 18:20:58.144018  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0481005 (* 1 = 0.0481005 loss)
I1001 18:20:58.144026  5416 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1001 18:21:03.400841  5416 solver.cpp:218] Iteration 68400 (19.023 iter/s, 5.2568s/100 iters), loss = 0.0225492
I1001 18:21:03.400976  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225489 (* 1 = 0.0225489 loss)
I1001 18:21:03.400985  5416 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1001 18:21:08.384440  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:21:08.595515  5416 solver.cpp:330] Iteration 68500, Testing net (#0)
I1001 18:21:09.792793  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:21:09.842949  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8851
I1001 18:21:09.842985  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490827 (* 1 = 0.490827 loss)
I1001 18:21:09.895635  5416 solver.cpp:218] Iteration 68500 (15.3973 iter/s, 6.49464s/100 iters), loss = 0.0290801
I1001 18:21:09.895663  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290798 (* 1 = 0.0290798 loss)
I1001 18:21:09.895668  5416 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1001 18:21:15.149281  5416 solver.cpp:218] Iteration 68600 (19.0346 iter/s, 5.2536s/100 iters), loss = 0.0139981
I1001 18:21:15.149312  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139979 (* 1 = 0.0139979 loss)
I1001 18:21:15.149318  5416 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1001 18:21:20.386637  5416 solver.cpp:218] Iteration 68700 (19.0938 iter/s, 5.2373s/100 iters), loss = 0.0281058
I1001 18:21:20.386669  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281056 (* 1 = 0.0281056 loss)
I1001 18:21:20.386677  5416 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1001 18:21:25.634856  5416 solver.cpp:218] Iteration 68800 (19.0543 iter/s, 5.24817s/100 iters), loss = 0.0191184
I1001 18:21:25.634896  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191181 (* 1 = 0.0191181 loss)
I1001 18:21:25.634902  5416 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1001 18:21:30.879490  5416 solver.cpp:218] Iteration 68900 (19.0673 iter/s, 5.24457s/100 iters), loss = 0.0305421
I1001 18:21:30.879520  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305418 (* 1 = 0.0305418 loss)
I1001 18:21:30.879528  5416 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1001 18:21:35.866034  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:21:36.078867  5416 solver.cpp:330] Iteration 69000, Testing net (#0)
I1001 18:21:37.269565  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:21:37.319888  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8985
I1001 18:21:37.319923  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.410965 (* 1 = 0.410965 loss)
I1001 18:21:37.372400  5416 solver.cpp:218] Iteration 69000 (15.4015 iter/s, 6.49286s/100 iters), loss = 0.0392675
I1001 18:21:37.372426  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392673 (* 1 = 0.0392673 loss)
I1001 18:21:37.372433  5416 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1001 18:21:42.624342  5416 solver.cpp:218] Iteration 69100 (19.0408 iter/s, 5.25189s/100 iters), loss = 0.0362026
I1001 18:21:42.624372  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362024 (* 1 = 0.0362024 loss)
I1001 18:21:42.624388  5416 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1001 18:21:47.871548  5416 solver.cpp:218] Iteration 69200 (19.058 iter/s, 5.24715s/100 iters), loss = 0.00667576
I1001 18:21:47.871587  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667551 (* 1 = 0.00667551 loss)
I1001 18:21:47.871594  5416 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1001 18:21:53.117594  5416 solver.cpp:218] Iteration 69300 (19.0623 iter/s, 5.24595s/100 iters), loss = 0.0221469
I1001 18:21:53.117624  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221466 (* 1 = 0.0221466 loss)
I1001 18:21:53.117632  5416 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1001 18:21:58.371788  5416 solver.cpp:218] Iteration 69400 (19.0326 iter/s, 5.25414s/100 iters), loss = 0.0163568
I1001 18:21:58.371819  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163565 (* 1 = 0.0163565 loss)
I1001 18:21:58.371834  5416 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1001 18:22:03.363786  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:22:03.572908  5416 solver.cpp:330] Iteration 69500, Testing net (#0)
I1001 18:22:04.763803  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:22:04.813896  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8894
I1001 18:22:04.813941  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454241 (* 1 = 0.454241 loss)
I1001 18:22:04.866250  5416 solver.cpp:218] Iteration 69500 (15.3979 iter/s, 6.49441s/100 iters), loss = 0.00375695
I1001 18:22:04.866276  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375671 (* 1 = 0.00375671 loss)
I1001 18:22:04.866283  5416 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1001 18:22:10.112208  5416 solver.cpp:218] Iteration 69600 (19.0625 iter/s, 5.24591s/100 iters), loss = 0.0602281
I1001 18:22:10.112356  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602278 (* 1 = 0.0602278 loss)
I1001 18:22:10.112363  5416 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1001 18:22:15.360177  5416 solver.cpp:218] Iteration 69700 (19.0556 iter/s, 5.2478s/100 iters), loss = 0.0412563
I1001 18:22:15.360208  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041256 (* 1 = 0.041256 loss)
I1001 18:22:15.360224  5416 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1001 18:22:20.595515  5416 solver.cpp:218] Iteration 69800 (19.1012 iter/s, 5.23529s/100 iters), loss = 0.00523601
I1001 18:22:20.595546  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523578 (* 1 = 0.00523578 loss)
I1001 18:22:20.595552  5416 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1001 18:22:25.844492  5416 solver.cpp:218] Iteration 69900 (19.0515 iter/s, 5.24893s/100 iters), loss = 0.0231556
I1001 18:22:25.844521  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231553 (* 1 = 0.0231553 loss)
I1001 18:22:25.844527  5416 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1001 18:22:30.831537  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:22:31.040544  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_70000.caffemodel
I1001 18:22:31.045491  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_70000.solverstate
I1001 18:22:31.046912  5416 solver.cpp:330] Iteration 70000, Testing net (#0)
I1001 18:22:32.236644  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:22:32.287133  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8818
I1001 18:22:32.287159  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.556074 (* 1 = 0.556074 loss)
I1001 18:22:32.339721  5416 solver.cpp:218] Iteration 70000 (15.396 iter/s, 6.49518s/100 iters), loss = 0.0426898
I1001 18:22:32.339747  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426896 (* 1 = 0.0426896 loss)
I1001 18:22:32.339753  5416 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1001 18:22:37.596845  5416 solver.cpp:218] Iteration 70100 (19.022 iter/s, 5.25708s/100 iters), loss = 0.00753961
I1001 18:22:37.596885  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00753938 (* 1 = 0.00753938 loss)
I1001 18:22:37.596891  5416 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1001 18:22:42.856009  5416 solver.cpp:218] Iteration 70200 (19.0146 iter/s, 5.25911s/100 iters), loss = 0.0867666
I1001 18:22:42.856155  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0867664 (* 1 = 0.0867664 loss)
I1001 18:22:42.856173  5416 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1001 18:22:48.111071  5416 solver.cpp:218] Iteration 70300 (19.0299 iter/s, 5.2549s/100 iters), loss = 0.003849
I1001 18:22:48.111112  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384878 (* 1 = 0.00384878 loss)
I1001 18:22:48.111119  5416 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1001 18:22:53.357645  5416 solver.cpp:218] Iteration 70400 (19.0603 iter/s, 5.24651s/100 iters), loss = 0.0486602
I1001 18:22:53.357676  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486599 (* 1 = 0.0486599 loss)
I1001 18:22:53.357692  5416 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1001 18:22:58.341912  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:22:58.551995  5416 solver.cpp:330] Iteration 70500, Testing net (#0)
I1001 18:22:59.744315  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:22:59.795260  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8981
I1001 18:22:59.795295  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.401031 (* 1 = 0.401031 loss)
I1001 18:22:59.849069  5416 solver.cpp:218] Iteration 70500 (15.4051 iter/s, 6.49137s/100 iters), loss = 0.022247
I1001 18:22:59.849104  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222467 (* 1 = 0.0222467 loss)
I1001 18:22:59.849112  5416 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1001 18:23:05.094597  5416 solver.cpp:218] Iteration 70600 (19.0642 iter/s, 5.24545s/100 iters), loss = 0.0642917
I1001 18:23:05.094637  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0642914 (* 1 = 0.0642914 loss)
I1001 18:23:05.094643  5416 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1001 18:23:10.340657  5416 solver.cpp:218] Iteration 70700 (19.0621 iter/s, 5.246s/100 iters), loss = 0.015487
I1001 18:23:10.340694  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154867 (* 1 = 0.0154867 loss)
I1001 18:23:10.340711  5416 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1001 18:23:15.586577  5416 solver.cpp:218] Iteration 70800 (19.0626 iter/s, 5.24586s/100 iters), loss = 0.0502655
I1001 18:23:15.586740  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0502652 (* 1 = 0.0502652 loss)
I1001 18:23:15.586748  5416 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1001 18:23:20.830648  5416 solver.cpp:218] Iteration 70900 (19.0698 iter/s, 5.24389s/100 iters), loss = 0.0108063
I1001 18:23:20.830684  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010806 (* 1 = 0.010806 loss)
I1001 18:23:20.830693  5416 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1001 18:23:25.807364  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:23:26.018141  5416 solver.cpp:330] Iteration 71000, Testing net (#0)
I1001 18:23:27.214733  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:23:27.265043  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8882
I1001 18:23:27.265079  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.468417 (* 1 = 0.468417 loss)
I1001 18:23:27.317914  5416 solver.cpp:218] Iteration 71000 (15.415 iter/s, 6.48721s/100 iters), loss = 0.00448512
I1001 18:23:27.317947  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448484 (* 1 = 0.00448484 loss)
I1001 18:23:27.317955  5416 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1001 18:23:32.564913  5416 solver.cpp:218] Iteration 71100 (19.0587 iter/s, 5.24695s/100 iters), loss = 0.0350302
I1001 18:23:32.564954  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03503 (* 1 = 0.03503 loss)
I1001 18:23:32.564960  5416 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1001 18:23:37.819990  5416 solver.cpp:218] Iteration 71200 (19.0294 iter/s, 5.25502s/100 iters), loss = 0.029679
I1001 18:23:37.820019  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296788 (* 1 = 0.0296788 loss)
I1001 18:23:37.820025  5416 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1001 18:23:43.071414  5416 solver.cpp:218] Iteration 71300 (19.0426 iter/s, 5.25137s/100 iters), loss = 0.00755333
I1001 18:23:43.071442  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755308 (* 1 = 0.00755308 loss)
I1001 18:23:43.071449  5416 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1001 18:23:48.324115  5416 solver.cpp:218] Iteration 71400 (19.038 iter/s, 5.25265s/100 iters), loss = 0.0200385
I1001 18:23:48.324252  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200382 (* 1 = 0.0200382 loss)
I1001 18:23:48.324261  5416 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1001 18:23:53.304739  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:23:53.514286  5416 solver.cpp:330] Iteration 71500, Testing net (#0)
I1001 18:23:54.710935  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:23:54.761076  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8889
I1001 18:23:54.761111  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.46119 (* 1 = 0.46119 loss)
I1001 18:23:54.813741  5416 solver.cpp:218] Iteration 71500 (15.4096 iter/s, 6.48947s/100 iters), loss = 0.0149827
I1001 18:23:54.813766  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149824 (* 1 = 0.0149824 loss)
I1001 18:23:54.813772  5416 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1001 18:24:00.065425  5416 solver.cpp:218] Iteration 71600 (19.0417 iter/s, 5.25163s/100 iters), loss = 0.0539426
I1001 18:24:00.065455  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0539424 (* 1 = 0.0539424 loss)
I1001 18:24:00.065464  5416 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1001 18:24:05.310402  5416 solver.cpp:218] Iteration 71700 (19.066 iter/s, 5.24493s/100 iters), loss = 0.0204671
I1001 18:24:05.310442  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204669 (* 1 = 0.0204669 loss)
I1001 18:24:05.310449  5416 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1001 18:24:10.564755  5416 solver.cpp:218] Iteration 71800 (19.0321 iter/s, 5.25429s/100 iters), loss = 0.0194233
I1001 18:24:10.564784  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194231 (* 1 = 0.0194231 loss)
I1001 18:24:10.564790  5416 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1001 18:24:15.816941  5416 solver.cpp:218] Iteration 71900 (19.0399 iter/s, 5.25213s/100 iters), loss = 0.0222593
I1001 18:24:15.816970  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222591 (* 1 = 0.0222591 loss)
I1001 18:24:15.816977  5416 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1001 18:24:20.799926  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:24:21.017184  5416 solver.cpp:330] Iteration 72000, Testing net (#0)
I1001 18:24:22.208770  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:24:22.258867  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I1001 18:24:22.258893  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.460644 (* 1 = 0.460644 loss)
I1001 18:24:22.311589  5416 solver.cpp:218] Iteration 72000 (15.3974 iter/s, 6.4946s/100 iters), loss = 0.0297722
I1001 18:24:22.311619  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029772 (* 1 = 0.029772 loss)
I1001 18:24:22.311626  5416 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1001 18:24:27.565140  5416 solver.cpp:218] Iteration 72100 (19.0349 iter/s, 5.2535s/100 iters), loss = 0.0583222
I1001 18:24:27.565171  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.058322 (* 1 = 0.058322 loss)
I1001 18:24:27.565177  5416 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1001 18:24:32.805449  5416 solver.cpp:218] Iteration 72200 (19.083 iter/s, 5.24025s/100 iters), loss = 0.00934214
I1001 18:24:32.805482  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00934193 (* 1 = 0.00934193 loss)
I1001 18:24:32.805488  5416 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1001 18:24:38.047394  5416 solver.cpp:218] Iteration 72300 (19.0772 iter/s, 5.24186s/100 iters), loss = 0.0100541
I1001 18:24:38.047426  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100539 (* 1 = 0.0100539 loss)
I1001 18:24:38.047443  5416 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1001 18:24:43.293411  5416 solver.cpp:218] Iteration 72400 (19.0623 iter/s, 5.24596s/100 iters), loss = 0.0107328
I1001 18:24:43.293440  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107326 (* 1 = 0.0107326 loss)
I1001 18:24:43.293447  5416 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1001 18:24:48.282028  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:24:48.490669  5416 solver.cpp:330] Iteration 72500, Testing net (#0)
I1001 18:24:49.680753  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:24:49.731029  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8832
I1001 18:24:49.731052  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.499979 (* 1 = 0.499979 loss)
I1001 18:24:49.783712  5416 solver.cpp:218] Iteration 72500 (15.4077 iter/s, 6.49025s/100 iters), loss = 0.00445716
I1001 18:24:49.783740  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445695 (* 1 = 0.00445695 loss)
I1001 18:24:49.783746  5416 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1001 18:24:55.038426  5416 solver.cpp:218] Iteration 72600 (19.0307 iter/s, 5.25466s/100 iters), loss = 0.0138756
I1001 18:24:55.038548  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138754 (* 1 = 0.0138754 loss)
I1001 18:24:55.038556  5416 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1001 18:25:00.293654  5416 solver.cpp:218] Iteration 72700 (19.0292 iter/s, 5.25509s/100 iters), loss = 0.0319137
I1001 18:25:00.293686  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319135 (* 1 = 0.0319135 loss)
I1001 18:25:00.293694  5416 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1001 18:25:05.538543  5416 solver.cpp:218] Iteration 72800 (19.0664 iter/s, 5.24484s/100 iters), loss = 0.0105579
I1001 18:25:05.538573  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105578 (* 1 = 0.0105578 loss)
I1001 18:25:05.538579  5416 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1001 18:25:10.786947  5416 solver.cpp:218] Iteration 72900 (19.0536 iter/s, 5.24835s/100 iters), loss = 0.0281326
I1001 18:25:10.786976  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281324 (* 1 = 0.0281324 loss)
I1001 18:25:10.786983  5416 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1001 18:25:15.777711  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:25:15.988240  5416 solver.cpp:330] Iteration 73000, Testing net (#0)
I1001 18:25:17.178859  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:25:17.228734  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8849
I1001 18:25:17.228760  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.512094 (* 1 = 0.512094 loss)
I1001 18:25:17.281215  5416 solver.cpp:218] Iteration 73000 (15.3983 iter/s, 6.49422s/100 iters), loss = 0.0095195
I1001 18:25:17.281241  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951931 (* 1 = 0.00951931 loss)
I1001 18:25:17.281249  5416 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1001 18:25:22.528800  5416 solver.cpp:218] Iteration 73100 (19.0566 iter/s, 5.24754s/100 iters), loss = 0.0145955
I1001 18:25:22.528839  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145953 (* 1 = 0.0145953 loss)
I1001 18:25:22.528846  5416 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1001 18:25:27.775929  5416 solver.cpp:218] Iteration 73200 (19.0583 iter/s, 5.24706s/100 iters), loss = 0.0243198
I1001 18:25:27.776072  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243196 (* 1 = 0.0243196 loss)
I1001 18:25:27.776089  5416 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1001 18:25:33.020352  5416 solver.cpp:218] Iteration 73300 (19.0685 iter/s, 5.24426s/100 iters), loss = 0.0650573
I1001 18:25:33.020395  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650572 (* 1 = 0.0650572 loss)
I1001 18:25:33.020403  5416 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1001 18:25:38.261832  5416 solver.cpp:218] Iteration 73400 (19.0788 iter/s, 5.24141s/100 iters), loss = 0.00956473
I1001 18:25:38.261873  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00956458 (* 1 = 0.00956458 loss)
I1001 18:25:38.261880  5416 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1001 18:25:43.252954  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:25:43.462944  5416 solver.cpp:330] Iteration 73500, Testing net (#0)
I1001 18:25:44.651688  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:25:44.701972  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8887
I1001 18:25:44.702006  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.464773 (* 1 = 0.464773 loss)
I1001 18:25:44.755448  5416 solver.cpp:218] Iteration 73500 (15.3999 iter/s, 6.49354s/100 iters), loss = 0.0362233
I1001 18:25:44.755506  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362231 (* 1 = 0.0362231 loss)
I1001 18:25:44.755523  5416 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1001 18:25:50.001926  5416 solver.cpp:218] Iteration 73600 (19.0608 iter/s, 5.24637s/100 iters), loss = 0.00556354
I1001 18:25:50.001955  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556339 (* 1 = 0.00556339 loss)
I1001 18:25:50.001960  5416 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1001 18:25:55.251519  5416 solver.cpp:218] Iteration 73700 (19.0493 iter/s, 5.24954s/100 iters), loss = 0.00735622
I1001 18:25:55.251552  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00735606 (* 1 = 0.00735606 loss)
I1001 18:25:55.251560  5416 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1001 18:26:00.506883  5416 solver.cpp:218] Iteration 73800 (19.0284 iter/s, 5.25531s/100 iters), loss = 0.0210951
I1001 18:26:00.506988  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021095 (* 1 = 0.021095 loss)
I1001 18:26:00.507006  5416 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1001 18:26:05.745915  5416 solver.cpp:218] Iteration 73900 (19.0879 iter/s, 5.23892s/100 iters), loss = 0.0213337
I1001 18:26:05.745959  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213336 (* 1 = 0.0213336 loss)
I1001 18:26:05.745966  5416 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1001 18:26:10.725673  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:26:10.936465  5416 solver.cpp:330] Iteration 74000, Testing net (#0)
I1001 18:26:12.132012  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:26:12.182353  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.889
I1001 18:26:12.182389  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.471143 (* 1 = 0.471143 loss)
I1001 18:26:12.235060  5416 solver.cpp:218] Iteration 74000 (15.4106 iter/s, 6.48905s/100 iters), loss = 0.00638827
I1001 18:26:12.235091  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063881 (* 1 = 0.0063881 loss)
I1001 18:26:12.235098  5416 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1001 18:26:17.476297  5416 solver.cpp:218] Iteration 74100 (19.0797 iter/s, 5.24119s/100 iters), loss = 0.0159607
I1001 18:26:17.476328  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159606 (* 1 = 0.0159606 loss)
I1001 18:26:17.476335  5416 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1001 18:26:22.726764  5416 solver.cpp:218] Iteration 74200 (19.0461 iter/s, 5.25042s/100 iters), loss = 0.0329459
I1001 18:26:22.726804  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329458 (* 1 = 0.0329458 loss)
I1001 18:26:22.726809  5416 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1001 18:26:27.981863  5416 solver.cpp:218] Iteration 74300 (19.0294 iter/s, 5.25504s/100 iters), loss = 0.00355927
I1001 18:26:27.981894  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355911 (* 1 = 0.00355911 loss)
I1001 18:26:27.981899  5416 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1001 18:26:33.240555  5416 solver.cpp:218] Iteration 74400 (19.0163 iter/s, 5.25864s/100 iters), loss = 0.0142918
I1001 18:26:33.240653  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142916 (* 1 = 0.0142916 loss)
I1001 18:26:33.240661  5416 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1001 18:26:38.221604  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:26:38.431553  5416 solver.cpp:330] Iteration 74500, Testing net (#0)
I1001 18:26:39.628095  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:26:39.678125  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8988
I1001 18:26:39.678149  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.43446 (* 1 = 0.43446 loss)
I1001 18:26:39.730574  5416 solver.cpp:218] Iteration 74500 (15.4086 iter/s, 6.4899s/100 iters), loss = 0.0221443
I1001 18:26:39.730602  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221441 (* 1 = 0.0221441 loss)
I1001 18:26:39.730608  5416 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1001 18:26:44.981446  5416 solver.cpp:218] Iteration 74600 (19.0446 iter/s, 5.25082s/100 iters), loss = 0.0186374
I1001 18:26:44.981482  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186372 (* 1 = 0.0186372 loss)
I1001 18:26:44.981488  5416 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1001 18:26:50.217219  5416 solver.cpp:218] Iteration 74700 (19.0996 iter/s, 5.23572s/100 iters), loss = 0.0341103
I1001 18:26:50.217248  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341102 (* 1 = 0.0341102 loss)
I1001 18:26:50.217254  5416 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1001 18:26:55.462396  5416 solver.cpp:218] Iteration 74800 (19.0653 iter/s, 5.24512s/100 iters), loss = 0.0176636
I1001 18:26:55.462432  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176635 (* 1 = 0.0176635 loss)
I1001 18:26:55.462440  5416 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1001 18:27:00.708015  5416 solver.cpp:218] Iteration 74900 (19.0637 iter/s, 5.24556s/100 iters), loss = 0.0263724
I1001 18:27:00.708048  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263723 (* 1 = 0.0263723 loss)
I1001 18:27:00.708056  5416 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1001 18:27:05.682101  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:27:05.895826  5416 solver.cpp:330] Iteration 75000, Testing net (#0)
I1001 18:27:07.091310  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:27:07.141564  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8935
I1001 18:27:07.141592  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.441218 (* 1 = 0.441218 loss)
I1001 18:27:07.194473  5416 solver.cpp:218] Iteration 75000 (15.4169 iter/s, 6.4864s/100 iters), loss = 0.0292539
I1001 18:27:07.194510  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292537 (* 1 = 0.0292537 loss)
I1001 18:27:07.194524  5416 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1001 18:27:12.443143  5416 solver.cpp:218] Iteration 75100 (19.0526 iter/s, 5.24861s/100 iters), loss = 0.0127327
I1001 18:27:12.443174  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127325 (* 1 = 0.0127325 loss)
I1001 18:27:12.443183  5416 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1001 18:27:17.684820  5416 solver.cpp:218] Iteration 75200 (19.0781 iter/s, 5.24162s/100 iters), loss = 0.0168305
I1001 18:27:17.684854  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168304 (* 1 = 0.0168304 loss)
I1001 18:27:17.684870  5416 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1001 18:27:22.939260  5416 solver.cpp:218] Iteration 75300 (19.0317 iter/s, 5.25439s/100 iters), loss = 0.0162362
I1001 18:27:22.939292  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162361 (* 1 = 0.0162361 loss)
I1001 18:27:22.939311  5416 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1001 18:27:28.192009  5416 solver.cpp:218] Iteration 75400 (19.0379 iter/s, 5.25269s/100 iters), loss = 0.0141627
I1001 18:27:28.192041  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141626 (* 1 = 0.0141626 loss)
I1001 18:27:28.192059  5416 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1001 18:27:33.184094  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:27:33.393865  5416 solver.cpp:330] Iteration 75500, Testing net (#0)
I1001 18:27:34.583467  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:27:34.633889  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8895
I1001 18:27:34.633915  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.501662 (* 1 = 0.501662 loss)
I1001 18:27:34.686851  5416 solver.cpp:218] Iteration 75500 (15.397 iter/s, 6.49479s/100 iters), loss = 0.0847907
I1001 18:27:34.686882  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0847906 (* 1 = 0.0847906 loss)
I1001 18:27:34.686893  5416 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1001 18:27:39.932919  5416 solver.cpp:218] Iteration 75600 (19.0621 iter/s, 5.24601s/100 iters), loss = 0.0126835
I1001 18:27:39.933079  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126834 (* 1 = 0.0126834 loss)
I1001 18:27:39.933107  5416 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1001 18:27:45.178596  5416 solver.cpp:218] Iteration 75700 (19.0639 iter/s, 5.24551s/100 iters), loss = 0.0449725
I1001 18:27:45.178630  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449724 (* 1 = 0.0449724 loss)
I1001 18:27:45.178649  5416 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1001 18:27:50.416062  5416 solver.cpp:218] Iteration 75800 (19.0934 iter/s, 5.23741s/100 iters), loss = 0.0132684
I1001 18:27:50.416095  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132683 (* 1 = 0.0132683 loss)
I1001 18:27:50.416113  5416 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1001 18:27:55.659709  5416 solver.cpp:218] Iteration 75900 (19.0709 iter/s, 5.24359s/100 iters), loss = 0.0221659
I1001 18:27:55.659742  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221658 (* 1 = 0.0221658 loss)
I1001 18:27:55.659750  5416 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1001 18:28:00.648777  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:28:00.858871  5416 solver.cpp:330] Iteration 76000, Testing net (#0)
I1001 18:28:02.049895  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:28:02.100050  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I1001 18:28:02.100078  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426751 (* 1 = 0.426751 loss)
I1001 18:28:02.152671  5416 solver.cpp:218] Iteration 76000 (15.4014 iter/s, 6.49291s/100 iters), loss = 0.0198296
I1001 18:28:02.152705  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198295 (* 1 = 0.0198295 loss)
I1001 18:28:02.152717  5416 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1001 18:28:07.402827  5416 solver.cpp:218] Iteration 76100 (19.0473 iter/s, 5.2501s/100 iters), loss = 0.0296907
I1001 18:28:07.402864  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296906 (* 1 = 0.0296906 loss)
I1001 18:28:07.402882  5416 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1001 18:28:12.656915  5416 solver.cpp:218] Iteration 76200 (19.033 iter/s, 5.25403s/100 iters), loss = 0.00840119
I1001 18:28:12.657047  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0084011 (* 1 = 0.0084011 loss)
I1001 18:28:12.657073  5416 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1001 18:28:17.902887  5416 solver.cpp:218] Iteration 76300 (19.0628 iter/s, 5.24583s/100 iters), loss = 0.0347306
I1001 18:28:17.902932  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347305 (* 1 = 0.0347305 loss)
I1001 18:28:17.902940  5416 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1001 18:28:23.149806  5416 solver.cpp:218] Iteration 76400 (19.0592 iter/s, 5.24682s/100 iters), loss = 0.0089181
I1001 18:28:23.149845  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00891798 (* 1 = 0.00891798 loss)
I1001 18:28:23.149852  5416 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1001 18:28:28.133777  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:28:28.343816  5416 solver.cpp:330] Iteration 76500, Testing net (#0)
I1001 18:28:29.532130  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:28:29.582144  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8941
I1001 18:28:29.582180  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.457558 (* 1 = 0.457558 loss)
I1001 18:28:29.635319  5416 solver.cpp:218] Iteration 76500 (15.4191 iter/s, 6.48545s/100 iters), loss = 0.00551438
I1001 18:28:29.635344  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551427 (* 1 = 0.00551427 loss)
I1001 18:28:29.635350  5416 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1001 18:28:34.881642  5416 solver.cpp:218] Iteration 76600 (19.0611 iter/s, 5.24628s/100 iters), loss = 0.0474758
I1001 18:28:34.881672  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474757 (* 1 = 0.0474757 loss)
I1001 18:28:34.881680  5416 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1001 18:28:40.121439  5416 solver.cpp:218] Iteration 76700 (19.0849 iter/s, 5.23975s/100 iters), loss = 0.0426007
I1001 18:28:40.121480  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426006 (* 1 = 0.0426006 loss)
I1001 18:28:40.121487  5416 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1001 18:28:45.370918  5416 solver.cpp:218] Iteration 76800 (19.0497 iter/s, 5.24941s/100 iters), loss = 0.00909191
I1001 18:28:45.371042  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090918 (* 1 = 0.0090918 loss)
I1001 18:28:45.371059  5416 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1001 18:28:50.612761  5416 solver.cpp:218] Iteration 76900 (19.0778 iter/s, 5.2417s/100 iters), loss = 0.0383801
I1001 18:28:50.612800  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03838 (* 1 = 0.03838 loss)
I1001 18:28:50.612807  5416 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1001 18:28:55.593819  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:28:55.803503  5416 solver.cpp:330] Iteration 77000, Testing net (#0)
I1001 18:28:57.000309  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:28:57.051125  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8972
I1001 18:28:57.051159  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.419105 (* 1 = 0.419105 loss)
I1001 18:28:57.103879  5416 solver.cpp:218] Iteration 77000 (15.4058 iter/s, 6.49106s/100 iters), loss = 0.0236095
I1001 18:28:57.103914  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236094 (* 1 = 0.0236094 loss)
I1001 18:28:57.103921  5416 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1001 18:29:02.349372  5416 solver.cpp:218] Iteration 77100 (19.0642 iter/s, 5.24544s/100 iters), loss = 0.0372107
I1001 18:29:02.349402  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372106 (* 1 = 0.0372106 loss)
I1001 18:29:02.349408  5416 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1001 18:29:07.598266  5416 solver.cpp:218] Iteration 77200 (19.0518 iter/s, 5.24884s/100 iters), loss = 0.0384774
I1001 18:29:07.598295  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384773 (* 1 = 0.0384773 loss)
I1001 18:29:07.598300  5416 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1001 18:29:12.851148  5416 solver.cpp:218] Iteration 77300 (19.0373 iter/s, 5.25283s/100 iters), loss = 0.0613485
I1001 18:29:12.851179  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0613484 (* 1 = 0.0613484 loss)
I1001 18:29:12.851196  5416 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1001 18:29:18.104045  5416 solver.cpp:218] Iteration 77400 (19.0373 iter/s, 5.25284s/100 iters), loss = 0.0439147
I1001 18:29:18.104185  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439146 (* 1 = 0.0439146 loss)
I1001 18:29:18.104203  5416 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1001 18:29:23.083135  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:29:23.293179  5416 solver.cpp:330] Iteration 77500, Testing net (#0)
I1001 18:29:24.489967  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:29:24.539934  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8718
I1001 18:29:24.539969  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.543478 (* 1 = 0.543478 loss)
I1001 18:29:24.592398  5416 solver.cpp:218] Iteration 77500 (15.4126 iter/s, 6.4882s/100 iters), loss = 0.0107009
I1001 18:29:24.592428  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107008 (* 1 = 0.0107008 loss)
I1001 18:29:24.592434  5416 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1001 18:29:29.836997  5416 solver.cpp:218] Iteration 77600 (19.0674 iter/s, 5.24454s/100 iters), loss = 0.0687594
I1001 18:29:29.837040  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0687593 (* 1 = 0.0687593 loss)
I1001 18:29:29.837047  5416 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1001 18:29:35.084010  5416 solver.cpp:218] Iteration 77700 (19.0588 iter/s, 5.24692s/100 iters), loss = 0.0266858
I1001 18:29:35.084050  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266857 (* 1 = 0.0266857 loss)
I1001 18:29:35.084056  5416 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1001 18:29:40.334862  5416 solver.cpp:218] Iteration 77800 (19.0447 iter/s, 5.25079s/100 iters), loss = 0.0448452
I1001 18:29:40.334903  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0448451 (* 1 = 0.0448451 loss)
I1001 18:29:40.334909  5416 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1001 18:29:45.586179  5416 solver.cpp:218] Iteration 77900 (19.0431 iter/s, 5.25125s/100 iters), loss = 0.0175042
I1001 18:29:45.586221  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175041 (* 1 = 0.0175041 loss)
I1001 18:29:45.586228  5416 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1001 18:29:50.566488  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:29:50.777403  5416 solver.cpp:330] Iteration 78000, Testing net (#0)
I1001 18:29:51.979061  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:29:52.029135  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9
I1001 18:29:52.029170  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.408441 (* 1 = 0.408441 loss)
I1001 18:29:52.082020  5416 solver.cpp:218] Iteration 78000 (15.3946 iter/s, 6.49577s/100 iters), loss = 0.0104537
I1001 18:29:52.082048  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104536 (* 1 = 0.0104536 loss)
I1001 18:29:52.082056  5416 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1001 18:29:57.339188  5416 solver.cpp:218] Iteration 78100 (19.0218 iter/s, 5.25712s/100 iters), loss = 0.0332399
I1001 18:29:57.339228  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332398 (* 1 = 0.0332398 loss)
I1001 18:29:57.339236  5416 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1001 18:30:02.587136  5416 solver.cpp:218] Iteration 78200 (19.0553 iter/s, 5.24788s/100 iters), loss = 0.00902528
I1001 18:30:02.587182  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902519 (* 1 = 0.00902519 loss)
I1001 18:30:02.587190  5416 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1001 18:30:07.840087  5416 solver.cpp:218] Iteration 78300 (19.0372 iter/s, 5.25288s/100 iters), loss = 0.0887387
I1001 18:30:07.840126  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0887386 (* 1 = 0.0887386 loss)
I1001 18:30:07.840132  5416 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1001 18:30:13.087332  5416 solver.cpp:218] Iteration 78400 (19.0579 iter/s, 5.24718s/100 iters), loss = 0.0141321
I1001 18:30:13.087371  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014132 (* 1 = 0.014132 loss)
I1001 18:30:13.087378  5416 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1001 18:30:18.071902  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:30:18.281399  5416 solver.cpp:330] Iteration 78500, Testing net (#0)
I1001 18:30:19.472579  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:30:19.522816  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8825
I1001 18:30:19.522841  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.508537 (* 1 = 0.508537 loss)
I1001 18:30:19.575371  5416 solver.cpp:218] Iteration 78500 (15.4131 iter/s, 6.48798s/100 iters), loss = 0.0102707
I1001 18:30:19.575397  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102706 (* 1 = 0.0102706 loss)
I1001 18:30:19.575404  5416 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1001 18:30:24.828156  5416 solver.cpp:218] Iteration 78600 (19.0377 iter/s, 5.25274s/100 iters), loss = 0.00933268
I1001 18:30:24.828266  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00933259 (* 1 = 0.00933259 loss)
I1001 18:30:24.828274  5416 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1001 18:30:30.085985  5416 solver.cpp:218] Iteration 78700 (19.0197 iter/s, 5.2577s/100 iters), loss = 0.0250413
I1001 18:30:30.086017  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250412 (* 1 = 0.0250412 loss)
I1001 18:30:30.086024  5416 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1001 18:30:35.332751  5416 solver.cpp:218] Iteration 78800 (19.0596 iter/s, 5.24671s/100 iters), loss = 0.0126008
I1001 18:30:35.332792  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126007 (* 1 = 0.0126007 loss)
I1001 18:30:35.332798  5416 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1001 18:30:40.586730  5416 solver.cpp:218] Iteration 78900 (19.0334 iter/s, 5.25392s/100 iters), loss = 0.00982799
I1001 18:30:40.586760  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00982791 (* 1 = 0.00982791 loss)
I1001 18:30:40.586777  5416 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1001 18:30:45.578181  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:30:45.788260  5416 solver.cpp:330] Iteration 79000, Testing net (#0)
I1001 18:30:46.978250  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:30:47.028728  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8825
I1001 18:30:47.028753  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.508964 (* 1 = 0.508964 loss)
I1001 18:30:47.081324  5416 solver.cpp:218] Iteration 79000 (15.3975 iter/s, 6.49454s/100 iters), loss = 0.0111994
I1001 18:30:47.081360  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111993 (* 1 = 0.0111993 loss)
I1001 18:30:47.081367  5416 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1001 18:30:52.333415  5416 solver.cpp:218] Iteration 79100 (19.0403 iter/s, 5.25203s/100 iters), loss = 0.0131145
I1001 18:30:52.333446  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131144 (* 1 = 0.0131144 loss)
I1001 18:30:52.333452  5416 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1001 18:30:57.583035  5416 solver.cpp:218] Iteration 79200 (19.0492 iter/s, 5.24957s/100 iters), loss = 0.00765018
I1001 18:30:57.583160  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765012 (* 1 = 0.00765012 loss)
I1001 18:30:57.583169  5416 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1001 18:31:02.827934  5416 solver.cpp:218] Iteration 79300 (19.0666 iter/s, 5.24477s/100 iters), loss = 0.00385846
I1001 18:31:02.827968  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038584 (* 1 = 0.0038584 loss)
I1001 18:31:02.827986  5416 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1001 18:31:08.075922  5416 solver.cpp:218] Iteration 79400 (19.0551 iter/s, 5.24793s/100 iters), loss = 0.00394798
I1001 18:31:08.075953  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394791 (* 1 = 0.00394791 loss)
I1001 18:31:08.075969  5416 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1001 18:31:13.064558  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:31:13.275490  5416 solver.cpp:330] Iteration 79500, Testing net (#0)
I1001 18:31:14.465438  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:31:14.515615  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8726
I1001 18:31:14.515650  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56819 (* 1 = 0.56819 loss)
I1001 18:31:14.568461  5416 solver.cpp:218] Iteration 79500 (15.4024 iter/s, 6.49249s/100 iters), loss = 0.0217226
I1001 18:31:14.568498  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217225 (* 1 = 0.0217225 loss)
I1001 18:31:14.568506  5416 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1001 18:31:19.821867  5416 solver.cpp:218] Iteration 79600 (19.0355 iter/s, 5.25335s/100 iters), loss = 0.00437533
I1001 18:31:19.821897  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437526 (* 1 = 0.00437526 loss)
I1001 18:31:19.821903  5416 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1001 18:31:25.074848  5416 solver.cpp:218] Iteration 79700 (19.037 iter/s, 5.25293s/100 iters), loss = 0.047608
I1001 18:31:25.074879  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476079 (* 1 = 0.0476079 loss)
I1001 18:31:25.074895  5416 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1001 18:31:30.328917  5416 solver.cpp:218] Iteration 79800 (19.0331 iter/s, 5.25401s/100 iters), loss = 0.0287617
I1001 18:31:30.329020  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287617 (* 1 = 0.0287617 loss)
I1001 18:31:30.329027  5416 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1001 18:31:35.572291  5416 solver.cpp:218] Iteration 79900 (19.0721 iter/s, 5.24325s/100 iters), loss = 0.0105347
I1001 18:31:35.572321  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105347 (* 1 = 0.0105347 loss)
I1001 18:31:35.572338  5416 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1001 18:31:40.556290  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:31:40.766751  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_80000.caffemodel
I1001 18:31:40.772066  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_80000.solverstate
I1001 18:31:40.773449  5416 solver.cpp:330] Iteration 80000, Testing net (#0)
I1001 18:31:41.967382  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:31:42.018455  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8868
I1001 18:31:42.018491  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.496584 (* 1 = 0.496584 loss)
I1001 18:31:42.072643  5416 solver.cpp:218] Iteration 80000 (15.3839 iter/s, 6.5003s/100 iters), loss = 0.00929875
I1001 18:31:42.072679  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00929869 (* 1 = 0.00929869 loss)
I1001 18:31:42.072695  5416 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1001 18:31:42.072700  5416 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1001 18:31:47.320049  5416 solver.cpp:218] Iteration 80100 (19.0572 iter/s, 5.24735s/100 iters), loss = 0.0105127
I1001 18:31:47.320080  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105127 (* 1 = 0.0105127 loss)
I1001 18:31:47.320087  5416 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1001 18:31:52.574223  5416 solver.cpp:218] Iteration 80200 (19.0327 iter/s, 5.25412s/100 iters), loss = 0.0671661
I1001 18:31:52.574262  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0671661 (* 1 = 0.0671661 loss)
I1001 18:31:52.574268  5416 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1001 18:31:57.826725  5416 solver.cpp:218] Iteration 80300 (19.0388 iter/s, 5.25244s/100 iters), loss = 0.0173273
I1001 18:31:57.826766  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173273 (* 1 = 0.0173273 loss)
I1001 18:31:57.826772  5416 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1001 18:32:03.083160  5416 solver.cpp:218] Iteration 80400 (19.0246 iter/s, 5.25637s/100 iters), loss = 0.00265956
I1001 18:32:03.083295  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265952 (* 1 = 0.00265952 loss)
I1001 18:32:03.083313  5416 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1001 18:32:08.066030  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:32:08.276700  5416 solver.cpp:330] Iteration 80500, Testing net (#0)
I1001 18:32:09.477694  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:32:09.527758  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I1001 18:32:09.527793  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375982 (* 1 = 0.375982 loss)
I1001 18:32:09.580669  5416 solver.cpp:218] Iteration 80500 (15.3909 iter/s, 6.49736s/100 iters), loss = 0.00319983
I1001 18:32:09.580695  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319979 (* 1 = 0.00319979 loss)
I1001 18:32:09.580703  5416 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1001 18:32:14.825426  5416 solver.cpp:218] Iteration 80600 (19.0668 iter/s, 5.24471s/100 iters), loss = 0.0306454
I1001 18:32:14.825464  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306454 (* 1 = 0.0306454 loss)
I1001 18:32:14.825470  5416 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1001 18:32:20.076733  5416 solver.cpp:218] Iteration 80700 (19.0431 iter/s, 5.25125s/100 iters), loss = 0.0482246
I1001 18:32:20.076764  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482246 (* 1 = 0.0482246 loss)
I1001 18:32:20.076771  5416 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1001 18:32:25.328900  5416 solver.cpp:218] Iteration 80800 (19.0399 iter/s, 5.25212s/100 iters), loss = 0.00414017
I1001 18:32:25.328940  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414013 (* 1 = 0.00414013 loss)
I1001 18:32:25.328946  5416 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1001 18:32:30.578912  5416 solver.cpp:218] Iteration 80900 (19.0478 iter/s, 5.24995s/100 iters), loss = 0.0107604
I1001 18:32:30.578944  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107604 (* 1 = 0.0107604 loss)
I1001 18:32:30.578950  5416 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1001 18:32:35.556602  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:32:35.766674  5416 solver.cpp:330] Iteration 81000, Testing net (#0)
I1001 18:32:36.963603  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:32:37.013947  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1001 18:32:37.013983  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36518 (* 1 = 0.36518 loss)
I1001 18:32:37.066490  5416 solver.cpp:218] Iteration 81000 (15.4142 iter/s, 6.48753s/100 iters), loss = 0.00715017
I1001 18:32:37.066517  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715013 (* 1 = 0.00715013 loss)
I1001 18:32:37.066527  5416 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1001 18:32:42.321122  5416 solver.cpp:218] Iteration 81100 (19.031 iter/s, 5.25459s/100 iters), loss = 0.0122481
I1001 18:32:42.321156  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012248 (* 1 = 0.012248 loss)
I1001 18:32:42.321162  5416 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1001 18:32:47.568209  5416 solver.cpp:218] Iteration 81200 (19.0584 iter/s, 5.24704s/100 iters), loss = 0.00615234
I1001 18:32:47.568249  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615231 (* 1 = 0.00615231 loss)
I1001 18:32:47.568256  5416 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1001 18:32:52.823292  5416 solver.cpp:218] Iteration 81300 (19.0294 iter/s, 5.25502s/100 iters), loss = 0.00231723
I1001 18:32:52.823331  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023172 (* 1 = 0.0023172 loss)
I1001 18:32:52.823338  5416 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1001 18:32:58.078909  5416 solver.cpp:218] Iteration 81400 (19.0275 iter/s, 5.25556s/100 iters), loss = 0.00221167
I1001 18:32:58.078950  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221165 (* 1 = 0.00221165 loss)
I1001 18:32:58.078956  5416 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1001 18:33:03.066730  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:33:03.277001  5416 solver.cpp:330] Iteration 81500, Testing net (#0)
I1001 18:33:04.461678  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:33:04.511189  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1001 18:33:04.511214  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359557 (* 1 = 0.359557 loss)
I1001 18:33:04.563673  5416 solver.cpp:218] Iteration 81500 (15.4209 iter/s, 6.4847s/100 iters), loss = 0.00438667
I1001 18:33:04.563699  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438665 (* 1 = 0.00438665 loss)
I1001 18:33:04.563706  5416 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1001 18:33:09.818702  5416 solver.cpp:218] Iteration 81600 (19.0296 iter/s, 5.25498s/100 iters), loss = 0.0212786
I1001 18:33:09.818791  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212786 (* 1 = 0.0212786 loss)
I1001 18:33:09.818809  5416 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1001 18:33:15.075198  5416 solver.cpp:218] Iteration 81700 (19.0245 iter/s, 5.25639s/100 iters), loss = 0.0175928
I1001 18:33:15.075233  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175928 (* 1 = 0.0175928 loss)
I1001 18:33:15.075240  5416 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1001 18:33:20.317114  5416 solver.cpp:218] Iteration 81800 (19.0772 iter/s, 5.24186s/100 iters), loss = 0.0169362
I1001 18:33:20.317145  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169362 (* 1 = 0.0169362 loss)
I1001 18:33:20.317152  5416 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1001 18:33:25.563666  5416 solver.cpp:218] Iteration 81900 (19.0603 iter/s, 5.2465s/100 iters), loss = 0.00233071
I1001 18:33:25.563707  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023307 (* 1 = 0.0023307 loss)
I1001 18:33:25.563714  5416 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1001 18:33:30.552166  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:33:30.762722  5416 solver.cpp:330] Iteration 82000, Testing net (#0)
I1001 18:33:31.953696  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:33:32.004081  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1001 18:33:32.004117  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363141 (* 1 = 0.363141 loss)
I1001 18:33:32.056732  5416 solver.cpp:218] Iteration 82000 (15.4012 iter/s, 6.49301s/100 iters), loss = 0.0062626
I1001 18:33:32.056757  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0062626 (* 1 = 0.0062626 loss)
I1001 18:33:32.056763  5416 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1001 18:33:37.304579  5416 solver.cpp:218] Iteration 82100 (19.0556 iter/s, 5.2478s/100 iters), loss = 0.0109838
I1001 18:33:37.304612  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109838 (* 1 = 0.0109838 loss)
I1001 18:33:37.304620  5416 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1001 18:33:42.555263  5416 solver.cpp:218] Iteration 82200 (19.0453 iter/s, 5.25063s/100 iters), loss = 0.013931
I1001 18:33:42.555392  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013931 (* 1 = 0.013931 loss)
I1001 18:33:42.555398  5416 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1001 18:33:47.799986  5416 solver.cpp:218] Iteration 82300 (19.0673 iter/s, 5.24457s/100 iters), loss = 0.00960409
I1001 18:33:47.800020  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00960409 (* 1 = 0.00960409 loss)
I1001 18:33:47.800029  5416 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1001 18:33:53.053731  5416 solver.cpp:218] Iteration 82400 (19.0344 iter/s, 5.25366s/100 iters), loss = 0.00140987
I1001 18:33:53.053761  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140988 (* 1 = 0.00140988 loss)
I1001 18:33:53.053767  5416 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1001 18:33:58.045857  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:33:58.256438  5416 solver.cpp:330] Iteration 82500, Testing net (#0)
I1001 18:33:59.445173  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:33:59.495311  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1001 18:33:59.495345  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360314 (* 1 = 0.360314 loss)
I1001 18:33:59.548048  5416 solver.cpp:218] Iteration 82500 (15.3982 iter/s, 6.49426s/100 iters), loss = 0.00432508
I1001 18:33:59.548082  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432509 (* 1 = 0.00432509 loss)
I1001 18:33:59.548089  5416 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1001 18:34:04.803776  5416 solver.cpp:218] Iteration 82600 (19.027 iter/s, 5.25568s/100 iters), loss = 0.0144734
I1001 18:34:04.803814  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144735 (* 1 = 0.0144735 loss)
I1001 18:34:04.803820  5416 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1001 18:34:10.052279  5416 solver.cpp:218] Iteration 82700 (19.0533 iter/s, 5.24844s/100 iters), loss = 0.0217659
I1001 18:34:10.052320  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217659 (* 1 = 0.0217659 loss)
I1001 18:34:10.052325  5416 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1001 18:34:15.303835  5416 solver.cpp:218] Iteration 82800 (19.0422 iter/s, 5.25149s/100 iters), loss = 0.00590804
I1001 18:34:15.303937  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00590806 (* 1 = 0.00590806 loss)
I1001 18:34:15.303946  5416 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1001 18:34:20.545217  5416 solver.cpp:218] Iteration 82900 (19.0794 iter/s, 5.24126s/100 iters), loss = 0.00743438
I1001 18:34:20.545246  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00743441 (* 1 = 0.00743441 loss)
I1001 18:34:20.545253  5416 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1001 18:34:25.533223  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:34:25.744410  5416 solver.cpp:330] Iteration 83000, Testing net (#0)
I1001 18:34:26.941633  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:34:26.992871  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1001 18:34:26.992898  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362206 (* 1 = 0.362206 loss)
I1001 18:34:27.046339  5416 solver.cpp:218] Iteration 83000 (15.3821 iter/s, 6.50106s/100 iters), loss = 0.00708744
I1001 18:34:27.046373  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00708747 (* 1 = 0.00708747 loss)
I1001 18:34:27.046381  5416 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1001 18:34:32.295032  5416 solver.cpp:218] Iteration 83100 (19.0526 iter/s, 5.24864s/100 iters), loss = 0.0041551
I1001 18:34:32.295063  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415514 (* 1 = 0.00415514 loss)
I1001 18:34:32.295068  5416 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1001 18:34:37.546583  5416 solver.cpp:218] Iteration 83200 (19.0422 iter/s, 5.2515s/100 iters), loss = 0.00302407
I1001 18:34:37.546623  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030241 (* 1 = 0.0030241 loss)
I1001 18:34:37.546629  5416 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1001 18:34:42.803419  5416 solver.cpp:218] Iteration 83300 (19.0231 iter/s, 5.25677s/100 iters), loss = 0.00326101
I1001 18:34:42.803450  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326106 (* 1 = 0.00326106 loss)
I1001 18:34:42.803457  5416 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1001 18:34:48.062059  5416 solver.cpp:218] Iteration 83400 (19.0165 iter/s, 5.25858s/100 iters), loss = 0.000411997
I1001 18:34:48.062224  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000412042 (* 1 = 0.000412042 loss)
I1001 18:34:48.062234  5416 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1001 18:34:53.042464  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:34:53.252847  5416 solver.cpp:330] Iteration 83500, Testing net (#0)
I1001 18:34:54.447103  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:34:54.497324  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1001 18:34:54.497350  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365255 (* 1 = 0.365255 loss)
I1001 18:34:54.550040  5416 solver.cpp:218] Iteration 83500 (15.4136 iter/s, 6.48778s/100 iters), loss = 0.00408521
I1001 18:34:54.550071  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00408526 (* 1 = 0.00408526 loss)
I1001 18:34:54.550078  5416 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1001 18:34:59.793628  5416 solver.cpp:218] Iteration 83600 (19.0711 iter/s, 5.24353s/100 iters), loss = 0.00798663
I1001 18:34:59.793673  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00798668 (* 1 = 0.00798668 loss)
I1001 18:34:59.793678  5416 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1001 18:35:05.044231  5416 solver.cpp:218] Iteration 83700 (19.0458 iter/s, 5.2505s/100 iters), loss = 0.0164887
I1001 18:35:05.044262  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164888 (* 1 = 0.0164888 loss)
I1001 18:35:05.044278  5416 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1001 18:35:10.293017  5416 solver.cpp:218] Iteration 83800 (19.0522 iter/s, 5.24873s/100 iters), loss = 0.0452086
I1001 18:35:10.293058  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452087 (* 1 = 0.0452087 loss)
I1001 18:35:10.293064  5416 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1001 18:35:15.546736  5416 solver.cpp:218] Iteration 83900 (19.0344 iter/s, 5.25366s/100 iters), loss = 0.00339895
I1001 18:35:15.546779  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339898 (* 1 = 0.00339898 loss)
I1001 18:35:15.546795  5416 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1001 18:35:20.527554  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:35:20.737777  5416 solver.cpp:330] Iteration 84000, Testing net (#0)
I1001 18:35:21.935554  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:35:21.985790  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1001 18:35:21.985824  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361019 (* 1 = 0.361019 loss)
I1001 18:35:22.038537  5416 solver.cpp:218] Iteration 84000 (15.4042 iter/s, 6.49174s/100 iters), loss = 0.00244072
I1001 18:35:22.038561  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244076 (* 1 = 0.00244076 loss)
I1001 18:35:22.038568  5416 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1001 18:35:27.299659  5416 solver.cpp:218] Iteration 84100 (19.0075 iter/s, 5.26107s/100 iters), loss = 0.0186794
I1001 18:35:27.299690  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186794 (* 1 = 0.0186794 loss)
I1001 18:35:27.299697  5416 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1001 18:35:32.545009  5416 solver.cpp:218] Iteration 84200 (19.0647 iter/s, 5.2453s/100 iters), loss = 0.00826315
I1001 18:35:32.545039  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00826319 (* 1 = 0.00826319 loss)
I1001 18:35:32.545045  5416 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1001 18:35:37.805212  5416 solver.cpp:218] Iteration 84300 (19.0109 iter/s, 5.26015s/100 iters), loss = 0.00349908
I1001 18:35:37.805243  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349912 (* 1 = 0.00349912 loss)
I1001 18:35:37.805248  5416 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1001 18:35:43.058773  5416 solver.cpp:218] Iteration 84400 (19.0349 iter/s, 5.25351s/100 iters), loss = 0.00337539
I1001 18:35:43.058809  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337544 (* 1 = 0.00337544 loss)
I1001 18:35:43.058815  5416 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1001 18:35:48.044893  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:35:48.255492  5416 solver.cpp:330] Iteration 84500, Testing net (#0)
I1001 18:35:49.443403  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:35:49.493260  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1001 18:35:49.493295  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363345 (* 1 = 0.363345 loss)
I1001 18:35:49.545830  5416 solver.cpp:218] Iteration 84500 (15.4154 iter/s, 6.48701s/100 iters), loss = 0.00448882
I1001 18:35:49.545853  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448887 (* 1 = 0.00448887 loss)
I1001 18:35:49.545861  5416 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1001 18:35:54.796006  5416 solver.cpp:218] Iteration 84600 (19.0471 iter/s, 5.25013s/100 iters), loss = 0.0033369
I1001 18:35:54.796149  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333695 (* 1 = 0.00333695 loss)
I1001 18:35:54.796156  5416 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1001 18:36:00.040240  5416 solver.cpp:218] Iteration 84700 (19.0692 iter/s, 5.24407s/100 iters), loss = 0.0133066
I1001 18:36:00.040272  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133067 (* 1 = 0.0133067 loss)
I1001 18:36:00.040280  5416 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1001 18:36:05.285926  5416 solver.cpp:218] Iteration 84800 (19.0635 iter/s, 5.24563s/100 iters), loss = 0.00831079
I1001 18:36:05.285966  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831084 (* 1 = 0.00831084 loss)
I1001 18:36:05.285972  5416 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1001 18:36:10.540995  5416 solver.cpp:218] Iteration 84900 (19.0295 iter/s, 5.25501s/100 iters), loss = 0.0113941
I1001 18:36:10.541024  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113942 (* 1 = 0.0113942 loss)
I1001 18:36:10.541030  5416 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1001 18:36:15.548205  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:36:15.758548  5416 solver.cpp:330] Iteration 85000, Testing net (#0)
I1001 18:36:16.955660  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:36:17.005964  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1001 18:36:17.005998  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364155 (* 1 = 0.364155 loss)
I1001 18:36:17.058367  5416 solver.cpp:218] Iteration 85000 (15.3437 iter/s, 6.51732s/100 iters), loss = 0.00189568
I1001 18:36:17.058395  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189573 (* 1 = 0.00189573 loss)
I1001 18:36:17.058403  5416 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1001 18:36:22.311024  5416 solver.cpp:218] Iteration 85100 (19.0382 iter/s, 5.25261s/100 iters), loss = 0.0091262
I1001 18:36:22.311054  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00912626 (* 1 = 0.00912626 loss)
I1001 18:36:22.311060  5416 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1001 18:36:27.561105  5416 solver.cpp:218] Iteration 85200 (19.0475 iter/s, 5.25002s/100 iters), loss = 0.00968359
I1001 18:36:27.561224  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968365 (* 1 = 0.00968365 loss)
I1001 18:36:27.561233  5416 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1001 18:36:32.809953  5416 solver.cpp:218] Iteration 85300 (19.0523 iter/s, 5.24871s/100 iters), loss = 0.00588997
I1001 18:36:32.810008  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589003 (* 1 = 0.00589003 loss)
I1001 18:36:32.810017  5416 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1001 18:36:38.057898  5416 solver.cpp:218] Iteration 85400 (19.0555 iter/s, 5.24784s/100 iters), loss = 0.0137661
I1001 18:36:38.057938  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137661 (* 1 = 0.0137661 loss)
I1001 18:36:38.057945  5416 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1001 18:36:43.040560  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:36:43.248802  5416 solver.cpp:330] Iteration 85500, Testing net (#0)
I1001 18:36:44.438182  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:36:44.488281  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1001 18:36:44.488315  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364026 (* 1 = 0.364026 loss)
I1001 18:36:44.540498  5416 solver.cpp:218] Iteration 85500 (15.4261 iter/s, 6.48254s/100 iters), loss = 0.00381286
I1001 18:36:44.540525  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381291 (* 1 = 0.00381291 loss)
I1001 18:36:44.540532  5416 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1001 18:36:49.785157  5416 solver.cpp:218] Iteration 85600 (19.0672 iter/s, 5.24461s/100 iters), loss = 0.0365674
I1001 18:36:49.785198  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365675 (* 1 = 0.0365675 loss)
I1001 18:36:49.785204  5416 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1001 18:36:55.034360  5416 solver.cpp:218] Iteration 85700 (19.0507 iter/s, 5.24914s/100 iters), loss = 0.0124092
I1001 18:36:55.034390  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124092 (* 1 = 0.0124092 loss)
I1001 18:36:55.034396  5416 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1001 18:37:00.284839  5416 solver.cpp:218] Iteration 85800 (19.0461 iter/s, 5.25042s/100 iters), loss = 0.00741272
I1001 18:37:00.284982  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00741277 (* 1 = 0.00741277 loss)
I1001 18:37:00.284991  5416 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1001 18:37:05.528952  5416 solver.cpp:218] Iteration 85900 (19.0696 iter/s, 5.24395s/100 iters), loss = 0.00184253
I1001 18:37:05.528985  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184259 (* 1 = 0.00184259 loss)
I1001 18:37:05.528991  5416 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1001 18:37:10.517983  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:37:10.727136  5416 solver.cpp:330] Iteration 86000, Testing net (#0)
I1001 18:37:11.924914  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:37:11.976594  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1001 18:37:11.976634  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363533 (* 1 = 0.363533 loss)
I1001 18:37:12.031033  5416 solver.cpp:218] Iteration 86000 (15.3798 iter/s, 6.50202s/100 iters), loss = 0.0128857
I1001 18:37:12.031086  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128857 (* 1 = 0.0128857 loss)
I1001 18:37:12.031105  5416 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1001 18:37:17.381618  5416 solver.cpp:218] Iteration 86100 (18.6899 iter/s, 5.35048s/100 iters), loss = 0.0272968
I1001 18:37:17.381659  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272969 (* 1 = 0.0272969 loss)
I1001 18:37:17.381666  5416 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1001 18:37:22.630146  5416 solver.cpp:218] Iteration 86200 (19.0532 iter/s, 5.24847s/100 iters), loss = 0.0137475
I1001 18:37:22.630175  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137475 (* 1 = 0.0137475 loss)
I1001 18:37:22.630182  5416 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1001 18:37:27.885537  5416 solver.cpp:218] Iteration 86300 (19.0283 iter/s, 5.25534s/100 iters), loss = 0.0134021
I1001 18:37:27.885567  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134021 (* 1 = 0.0134021 loss)
I1001 18:37:27.885573  5416 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1001 18:37:33.137158  5416 solver.cpp:218] Iteration 86400 (19.0419 iter/s, 5.25157s/100 iters), loss = 0.000821991
I1001 18:37:33.137286  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000822051 (* 1 = 0.000822051 loss)
I1001 18:37:33.137295  5416 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1001 18:37:38.125980  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:37:38.336186  5416 solver.cpp:330] Iteration 86500, Testing net (#0)
I1001 18:37:39.536465  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:37:39.586642  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1001 18:37:39.586675  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367505 (* 1 = 0.367505 loss)
I1001 18:37:39.639288  5416 solver.cpp:218] Iteration 86500 (15.3799 iter/s, 6.50198s/100 iters), loss = 0.00246186
I1001 18:37:39.639319  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246192 (* 1 = 0.00246192 loss)
I1001 18:37:39.639327  5416 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1001 18:37:44.931691  5416 solver.cpp:218] Iteration 86600 (18.8952 iter/s, 5.29235s/100 iters), loss = 0.00745861
I1001 18:37:44.931740  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745866 (* 1 = 0.00745866 loss)
I1001 18:37:44.931748  5416 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1001 18:37:50.199102  5416 solver.cpp:218] Iteration 86700 (18.985 iter/s, 5.26731s/100 iters), loss = 0.011957
I1001 18:37:50.199131  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011957 (* 1 = 0.011957 loss)
I1001 18:37:50.199146  5416 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1001 18:37:55.456218  5416 solver.cpp:218] Iteration 86800 (19.022 iter/s, 5.25707s/100 iters), loss = 0.023838
I1001 18:37:55.456248  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238381 (* 1 = 0.0238381 loss)
I1001 18:37:55.456254  5416 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1001 18:38:00.751919  5416 solver.cpp:218] Iteration 86900 (18.8834 iter/s, 5.29565s/100 iters), loss = 0.00200245
I1001 18:38:00.751947  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020025 (* 1 = 0.0020025 loss)
I1001 18:38:00.751953  5416 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1001 18:38:05.797166  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:38:06.012646  5416 solver.cpp:330] Iteration 87000, Testing net (#0)
I1001 18:38:07.204937  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:38:07.257035  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1001 18:38:07.257067  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364462 (* 1 = 0.364462 loss)
I1001 18:38:07.311904  5416 solver.cpp:218] Iteration 87000 (15.2441 iter/s, 6.55993s/100 iters), loss = 0.00106784
I1001 18:38:07.311950  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106789 (* 1 = 0.00106789 loss)
I1001 18:38:07.311957  5416 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1001 18:38:12.599712  5416 solver.cpp:218] Iteration 87100 (18.9122 iter/s, 5.28758s/100 iters), loss = 0.0126788
I1001 18:38:12.599753  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126788 (* 1 = 0.0126788 loss)
I1001 18:38:12.599761  5416 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1001 18:38:17.849537  5416 solver.cpp:218] Iteration 87200 (19.0485 iter/s, 5.24976s/100 iters), loss = 0.00567245
I1001 18:38:17.849572  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0056725 (* 1 = 0.0056725 loss)
I1001 18:38:17.849580  5416 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1001 18:38:23.100992  5416 solver.cpp:218] Iteration 87300 (19.0425 iter/s, 5.2514s/100 iters), loss = 0.0299128
I1001 18:38:23.101034  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299128 (* 1 = 0.0299128 loss)
I1001 18:38:23.101040  5416 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1001 18:38:28.390108  5416 solver.cpp:218] Iteration 87400 (18.907 iter/s, 5.28905s/100 iters), loss = 0.0021245
I1001 18:38:28.390141  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212455 (* 1 = 0.00212455 loss)
I1001 18:38:28.390147  5416 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1001 18:38:33.462518  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:38:33.676579  5416 solver.cpp:330] Iteration 87500, Testing net (#0)
I1001 18:38:34.885679  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:38:34.935973  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1001 18:38:34.936009  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365054 (* 1 = 0.365054 loss)
I1001 18:38:34.989224  5416 solver.cpp:218] Iteration 87500 (15.1537 iter/s, 6.59906s/100 iters), loss = 0.0113102
I1001 18:38:34.989253  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113103 (* 1 = 0.0113103 loss)
I1001 18:38:34.989259  5416 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1001 18:38:40.255379  5416 solver.cpp:218] Iteration 87600 (18.9894 iter/s, 5.2661s/100 iters), loss = 0.00663942
I1001 18:38:40.255499  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663947 (* 1 = 0.00663947 loss)
I1001 18:38:40.255517  5416 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1001 18:38:45.514976  5416 solver.cpp:218] Iteration 87700 (19.0134 iter/s, 5.25946s/100 iters), loss = 0.00802806
I1001 18:38:45.515020  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0080281 (* 1 = 0.0080281 loss)
I1001 18:38:45.515027  5416 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1001 18:38:50.778810  5416 solver.cpp:218] Iteration 87800 (18.9978 iter/s, 5.26377s/100 iters), loss = 0.00307964
I1001 18:38:50.778851  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307969 (* 1 = 0.00307969 loss)
I1001 18:38:50.778856  5416 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1001 18:38:56.038157  5416 solver.cpp:218] Iteration 87900 (19.014 iter/s, 5.25929s/100 iters), loss = 0.00169962
I1001 18:38:56.038197  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169967 (* 1 = 0.00169967 loss)
I1001 18:38:56.038203  5416 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1001 18:39:01.029458  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:39:01.242058  5416 solver.cpp:330] Iteration 88000, Testing net (#0)
I1001 18:39:02.430518  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:39:02.481024  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1001 18:39:02.481048  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366035 (* 1 = 0.366035 loss)
I1001 18:39:02.533749  5416 solver.cpp:218] Iteration 88000 (15.3952 iter/s, 6.49553s/100 iters), loss = 0.00546026
I1001 18:39:02.533776  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546029 (* 1 = 0.00546029 loss)
I1001 18:39:02.533783  5416 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1001 18:39:07.789600  5416 solver.cpp:218] Iteration 88100 (19.0266 iter/s, 5.2558s/100 iters), loss = 0.00482483
I1001 18:39:07.789640  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482486 (* 1 = 0.00482486 loss)
I1001 18:39:07.789646  5416 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1001 18:39:13.044616  5416 solver.cpp:218] Iteration 88200 (19.0297 iter/s, 5.25495s/100 iters), loss = 0.0114166
I1001 18:39:13.044729  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114166 (* 1 = 0.0114166 loss)
I1001 18:39:13.044737  5416 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1001 18:39:18.297477  5416 solver.cpp:218] Iteration 88300 (19.0377 iter/s, 5.25274s/100 iters), loss = 0.0039263
I1001 18:39:18.297518  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392634 (* 1 = 0.00392634 loss)
I1001 18:39:18.297524  5416 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1001 18:39:23.546083  5416 solver.cpp:218] Iteration 88400 (19.0529 iter/s, 5.24855s/100 iters), loss = 0.00092789
I1001 18:39:23.546113  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000927924 (* 1 = 0.000927924 loss)
I1001 18:39:23.546119  5416 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1001 18:39:28.535712  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:39:28.745777  5416 solver.cpp:330] Iteration 88500, Testing net (#0)
I1001 18:39:29.939805  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:39:29.991530  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1001 18:39:29.991559  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366562 (* 1 = 0.366562 loss)
I1001 18:39:30.045357  5416 solver.cpp:218] Iteration 88500 (15.3865 iter/s, 6.49922s/100 iters), loss = 0.00429476
I1001 18:39:30.045392  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429479 (* 1 = 0.00429479 loss)
I1001 18:39:30.045398  5416 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1001 18:39:35.294369  5416 solver.cpp:218] Iteration 88600 (19.0514 iter/s, 5.24896s/100 iters), loss = 0.00708726
I1001 18:39:35.294399  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00708729 (* 1 = 0.00708729 loss)
I1001 18:39:35.294404  5416 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1001 18:39:40.547684  5416 solver.cpp:218] Iteration 88700 (19.0358 iter/s, 5.25327s/100 iters), loss = 0.0317144
I1001 18:39:40.547713  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317144 (* 1 = 0.0317144 loss)
I1001 18:39:40.547719  5416 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1001 18:39:45.799060  5416 solver.cpp:218] Iteration 88800 (19.0428 iter/s, 5.25132s/100 iters), loss = 0.0125745
I1001 18:39:45.799183  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125746 (* 1 = 0.0125746 loss)
I1001 18:39:45.799201  5416 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1001 18:39:51.051350  5416 solver.cpp:218] Iteration 88900 (19.0398 iter/s, 5.25214s/100 iters), loss = 0.0013165
I1001 18:39:51.051385  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131652 (* 1 = 0.00131652 loss)
I1001 18:39:51.051393  5416 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1001 18:39:56.074600  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:39:56.284473  5416 solver.cpp:330] Iteration 89000, Testing net (#0)
I1001 18:39:57.480751  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:39:57.531102  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1001 18:39:57.531138  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36275 (* 1 = 0.36275 loss)
I1001 18:39:57.583523  5416 solver.cpp:218] Iteration 89000 (15.309 iter/s, 6.53212s/100 iters), loss = 0.00821813
I1001 18:39:57.583555  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00821816 (* 1 = 0.00821816 loss)
I1001 18:39:57.583562  5416 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1001 18:40:02.855619  5416 solver.cpp:218] Iteration 89100 (18.968 iter/s, 5.27204s/100 iters), loss = 0.00785399
I1001 18:40:02.855657  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785401 (* 1 = 0.00785401 loss)
I1001 18:40:02.855664  5416 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1001 18:40:08.111549  5416 solver.cpp:218] Iteration 89200 (19.0264 iter/s, 5.25587s/100 iters), loss = 0.0102643
I1001 18:40:08.111588  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102643 (* 1 = 0.0102643 loss)
I1001 18:40:08.111594  5416 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1001 18:40:13.427454  5416 solver.cpp:218] Iteration 89300 (18.8117 iter/s, 5.31584s/100 iters), loss = 0.00252496
I1001 18:40:13.427497  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252499 (* 1 = 0.00252499 loss)
I1001 18:40:13.427505  5416 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1001 18:40:18.713539  5416 solver.cpp:218] Iteration 89400 (18.9178 iter/s, 5.28602s/100 iters), loss = 0.00236503
I1001 18:40:18.713687  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236506 (* 1 = 0.00236506 loss)
I1001 18:40:18.713698  5416 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1001 18:40:23.717061  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:40:23.933130  5416 solver.cpp:330] Iteration 89500, Testing net (#0)
I1001 18:40:25.137266  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:40:25.187696  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1001 18:40:25.187721  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36372 (* 1 = 0.36372 loss)
I1001 18:40:25.240803  5416 solver.cpp:218] Iteration 89500 (15.3207 iter/s, 6.5271s/100 iters), loss = 0.00317575
I1001 18:40:25.240836  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317578 (* 1 = 0.00317578 loss)
I1001 18:40:25.240844  5416 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1001 18:40:30.494338  5416 solver.cpp:218] Iteration 89600 (19.035 iter/s, 5.25348s/100 iters), loss = 0.0100035
I1001 18:40:30.494369  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100035 (* 1 = 0.0100035 loss)
I1001 18:40:30.494375  5416 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1001 18:40:35.764287  5416 solver.cpp:218] Iteration 89700 (18.9757 iter/s, 5.26989s/100 iters), loss = 0.00282296
I1001 18:40:35.764339  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282299 (* 1 = 0.00282299 loss)
I1001 18:40:35.764346  5416 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1001 18:40:41.046273  5416 solver.cpp:218] Iteration 89800 (18.9326 iter/s, 5.28188s/100 iters), loss = 0.00664563
I1001 18:40:41.046314  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664566 (* 1 = 0.00664566 loss)
I1001 18:40:41.046319  5416 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1001 18:40:46.296862  5416 solver.cpp:218] Iteration 89900 (19.0457 iter/s, 5.25052s/100 iters), loss = 0.00120194
I1001 18:40:46.296902  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120197 (* 1 = 0.00120197 loss)
I1001 18:40:46.296908  5416 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1001 18:40:51.322001  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:40:51.532698  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_90000.caffemodel
I1001 18:40:51.537629  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_90000.solverstate
I1001 18:40:51.538991  5416 solver.cpp:330] Iteration 90000, Testing net (#0)
I1001 18:40:52.735733  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:40:52.786201  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1001 18:40:52.786226  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360149 (* 1 = 0.360149 loss)
I1001 18:40:52.838670  5416 solver.cpp:218] Iteration 90000 (15.2864 iter/s, 6.54174s/100 iters), loss = 0.00167139
I1001 18:40:52.838704  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167142 (* 1 = 0.00167142 loss)
I1001 18:40:52.838711  5416 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1001 18:40:58.146123  5416 solver.cpp:218] Iteration 90100 (18.8416 iter/s, 5.3074s/100 iters), loss = 0.0116421
I1001 18:40:58.146154  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116421 (* 1 = 0.0116421 loss)
I1001 18:40:58.146160  5416 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1001 18:41:03.453605  5416 solver.cpp:218] Iteration 90200 (18.8415 iter/s, 5.30743s/100 iters), loss = 0.00625246
I1001 18:41:03.453640  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625249 (* 1 = 0.00625249 loss)
I1001 18:41:03.453647  5416 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1001 18:41:08.792204  5416 solver.cpp:218] Iteration 90300 (18.7317 iter/s, 5.33854s/100 iters), loss = 0.0047321
I1001 18:41:08.792235  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473213 (* 1 = 0.00473213 loss)
I1001 18:41:08.792243  5416 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1001 18:41:14.137626  5416 solver.cpp:218] Iteration 90400 (18.7078 iter/s, 5.34537s/100 iters), loss = 0.00105856
I1001 18:41:14.137667  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010586 (* 1 = 0.0010586 loss)
I1001 18:41:14.137673  5416 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1001 18:41:19.128178  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:41:19.337579  5416 solver.cpp:330] Iteration 90500, Testing net (#0)
I1001 18:41:20.526278  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:41:20.576683  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1001 18:41:20.576709  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364174 (* 1 = 0.364174 loss)
I1001 18:41:20.629431  5416 solver.cpp:218] Iteration 90500 (15.4042 iter/s, 6.49174s/100 iters), loss = 0.00538266
I1001 18:41:20.629457  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538269 (* 1 = 0.00538269 loss)
I1001 18:41:20.629464  5416 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1001 18:41:25.880702  5416 solver.cpp:218] Iteration 90600 (19.0432 iter/s, 5.25123s/100 iters), loss = 0.0109559
I1001 18:41:25.880842  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109559 (* 1 = 0.0109559 loss)
I1001 18:41:25.880861  5416 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1001 18:41:31.162569  5416 solver.cpp:218] Iteration 90700 (18.9333 iter/s, 5.28171s/100 iters), loss = 0.00331239
I1001 18:41:31.162600  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331242 (* 1 = 0.00331242 loss)
I1001 18:41:31.162606  5416 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1001 18:41:36.451539  5416 solver.cpp:218] Iteration 90800 (18.9074 iter/s, 5.28892s/100 iters), loss = 0.00227012
I1001 18:41:36.451570  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227015 (* 1 = 0.00227015 loss)
I1001 18:41:36.451575  5416 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1001 18:41:43.064646  5416 solver.cpp:218] Iteration 90900 (15.1216 iter/s, 6.61305s/100 iters), loss = 0.00192256
I1001 18:41:43.064689  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019226 (* 1 = 0.0019226 loss)
I1001 18:41:43.064697  5416 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1001 18:41:53.880606  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:41:54.255544  5416 solver.cpp:330] Iteration 91000, Testing net (#0)
I1001 18:41:56.744613  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:41:56.892324  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1001 18:41:56.892365  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365662 (* 1 = 0.365662 loss)
I1001 18:41:56.984246  5416 solver.cpp:218] Iteration 91000 (7.18528 iter/s, 13.9173s/100 iters), loss = 0.0264521
I1001 18:41:56.984309  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264521 (* 1 = 0.0264521 loss)
I1001 18:41:56.984319  5416 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1001 18:42:08.385779  5416 solver.cpp:218] Iteration 91100 (8.77085 iter/s, 11.4014s/100 iters), loss = 0.0485886
I1001 18:42:08.385817  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485887 (* 1 = 0.0485887 loss)
I1001 18:42:08.385834  5416 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1001 18:42:19.725077  5416 solver.cpp:218] Iteration 91200 (8.82063 iter/s, 11.3371s/100 iters), loss = 0.0135956
I1001 18:42:19.725108  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135956 (* 1 = 0.0135956 loss)
I1001 18:42:19.725124  5416 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1001 18:42:31.148150  5416 solver.cpp:218] Iteration 91300 (8.75429 iter/s, 11.423s/100 iters), loss = 0.0178929
I1001 18:42:31.148247  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178929 (* 1 = 0.0178929 loss)
I1001 18:42:31.148265  5416 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1001 18:42:37.291122  5416 solver.cpp:218] Iteration 91400 (16.2846 iter/s, 6.14078s/100 iters), loss = 0.00226371
I1001 18:42:37.291152  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226375 (* 1 = 0.00226375 loss)
I1001 18:42:37.291168  5416 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1001 18:42:42.327657  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:42:42.550745  5416 solver.cpp:330] Iteration 91500, Testing net (#0)
I1001 18:42:43.775413  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:42:43.826799  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1001 18:42:43.826834  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364046 (* 1 = 0.364046 loss)
I1001 18:42:43.881299  5416 solver.cpp:218] Iteration 91500 (15.1742 iter/s, 6.59013s/100 iters), loss = 0.00309995
I1001 18:42:43.881345  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309999 (* 1 = 0.00309999 loss)
I1001 18:42:43.881353  5416 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1001 18:42:49.161157  5416 solver.cpp:218] Iteration 91600 (18.9403 iter/s, 5.27974s/100 iters), loss = 0.0119193
I1001 18:42:49.161197  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119193 (* 1 = 0.0119193 loss)
I1001 18:42:49.161203  5416 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1001 18:42:54.464846  5416 solver.cpp:218] Iteration 91700 (18.855 iter/s, 5.30362s/100 iters), loss = 0.00975563
I1001 18:42:54.464877  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00975568 (* 1 = 0.00975568 loss)
I1001 18:42:54.464884  5416 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1001 18:42:59.729614  5416 solver.cpp:218] Iteration 91800 (18.9944 iter/s, 5.26472s/100 iters), loss = 0.0183301
I1001 18:42:59.729645  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183302 (* 1 = 0.0183302 loss)
I1001 18:42:59.729651  5416 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1001 18:43:05.084604  5416 solver.cpp:218] Iteration 91900 (18.6744 iter/s, 5.35494s/100 iters), loss = 0.00467664
I1001 18:43:05.084703  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046767 (* 1 = 0.0046767 loss)
I1001 18:43:05.084712  5416 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1001 18:43:10.095376  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:43:10.305464  5416 solver.cpp:330] Iteration 92000, Testing net (#0)
I1001 18:43:11.494170  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:43:11.544302  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1001 18:43:11.544337  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36279 (* 1 = 0.36279 loss)
I1001 18:43:11.596995  5416 solver.cpp:218] Iteration 92000 (15.3556 iter/s, 6.51227s/100 iters), loss = 0.00212486
I1001 18:43:11.597020  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212491 (* 1 = 0.00212491 loss)
I1001 18:43:11.597028  5416 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1001 18:43:16.853443  5416 solver.cpp:218] Iteration 92100 (19.0244 iter/s, 5.2564s/100 iters), loss = 0.010756
I1001 18:43:16.853483  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107561 (* 1 = 0.0107561 loss)
I1001 18:43:16.853489  5416 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1001 18:43:22.100242  5416 solver.cpp:218] Iteration 92200 (19.0595 iter/s, 5.24674s/100 iters), loss = 0.00487907
I1001 18:43:22.100282  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487912 (* 1 = 0.00487912 loss)
I1001 18:43:22.100288  5416 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1001 18:43:27.349886  5416 solver.cpp:218] Iteration 92300 (19.0491 iter/s, 5.24958s/100 iters), loss = 0.00272091
I1001 18:43:27.349927  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272096 (* 1 = 0.00272096 loss)
I1001 18:43:27.349934  5416 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1001 18:43:32.590471  5416 solver.cpp:218] Iteration 92400 (19.0821 iter/s, 5.24052s/100 iters), loss = 0.000902019
I1001 18:43:32.590502  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000902073 (* 1 = 0.000902073 loss)
I1001 18:43:32.590517  5416 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1001 18:43:37.582834  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:43:37.792752  5416 solver.cpp:330] Iteration 92500, Testing net (#0)
I1001 18:43:38.986030  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:43:39.037488  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1001 18:43:39.037513  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365825 (* 1 = 0.365825 loss)
I1001 18:43:39.091349  5416 solver.cpp:218] Iteration 92500 (15.3827 iter/s, 6.50082s/100 iters), loss = 0.00119774
I1001 18:43:39.091385  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119779 (* 1 = 0.00119779 loss)
I1001 18:43:39.091393  5416 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1001 18:43:44.330008  5416 solver.cpp:218] Iteration 92600 (19.0892 iter/s, 5.23857s/100 iters), loss = 0.00958723
I1001 18:43:44.330039  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00958728 (* 1 = 0.00958728 loss)
I1001 18:43:44.330044  5416 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1001 18:43:49.574502  5416 solver.cpp:218] Iteration 92700 (19.0678 iter/s, 5.24444s/100 iters), loss = 0.00462263
I1001 18:43:49.574534  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462268 (* 1 = 0.00462268 loss)
I1001 18:43:49.574540  5416 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1001 18:43:54.818768  5416 solver.cpp:218] Iteration 92800 (19.0686 iter/s, 5.24421s/100 iters), loss = 0.00135514
I1001 18:43:54.818799  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135519 (* 1 = 0.00135519 loss)
I1001 18:43:54.818804  5416 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1001 18:44:00.063357  5416 solver.cpp:218] Iteration 92900 (19.0675 iter/s, 5.24454s/100 iters), loss = 0.00294628
I1001 18:44:00.063397  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294633 (* 1 = 0.00294633 loss)
I1001 18:44:00.063405  5416 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1001 18:44:05.047232  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:44:05.257400  5416 solver.cpp:330] Iteration 93000, Testing net (#0)
I1001 18:44:06.457624  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:44:06.508044  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1001 18:44:06.508078  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366085 (* 1 = 0.366085 loss)
I1001 18:44:06.560410  5416 solver.cpp:218] Iteration 93000 (15.3917 iter/s, 6.497s/100 iters), loss = 0.00329849
I1001 18:44:06.560436  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00329855 (* 1 = 0.00329855 loss)
I1001 18:44:06.560442  5416 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1001 18:44:11.802208  5416 solver.cpp:218] Iteration 93100 (19.0776 iter/s, 5.24175s/100 iters), loss = 0.0093296
I1001 18:44:11.802347  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00932966 (* 1 = 0.00932966 loss)
I1001 18:44:11.802364  5416 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1001 18:44:17.054916  5416 solver.cpp:218] Iteration 93200 (19.0383 iter/s, 5.25256s/100 iters), loss = 0.00275964
I1001 18:44:17.054947  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027597 (* 1 = 0.0027597 loss)
I1001 18:44:17.054953  5416 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1001 18:44:22.306154  5416 solver.cpp:218] Iteration 93300 (19.0433 iter/s, 5.25118s/100 iters), loss = 0.0324168
I1001 18:44:22.306182  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324169 (* 1 = 0.0324169 loss)
I1001 18:44:22.306188  5416 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1001 18:44:27.553416  5416 solver.cpp:218] Iteration 93400 (19.0577 iter/s, 5.24721s/100 iters), loss = 0.00508846
I1001 18:44:27.553462  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508852 (* 1 = 0.00508852 loss)
I1001 18:44:27.553468  5416 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1001 18:44:32.530247  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:44:32.739943  5416 solver.cpp:330] Iteration 93500, Testing net (#0)
I1001 18:44:33.934018  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:44:33.984031  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1001 18:44:33.984066  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367116 (* 1 = 0.367116 loss)
I1001 18:44:34.036414  5416 solver.cpp:218] Iteration 93500 (15.4251 iter/s, 6.48293s/100 iters), loss = 0.0300455
I1001 18:44:34.036437  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300456 (* 1 = 0.0300456 loss)
I1001 18:44:34.036444  5416 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1001 18:44:39.280253  5416 solver.cpp:218] Iteration 93600 (19.0702 iter/s, 5.24379s/100 iters), loss = 0.00669636
I1001 18:44:39.280285  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669642 (* 1 = 0.00669642 loss)
I1001 18:44:39.280292  5416 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1001 18:44:44.516762  5416 solver.cpp:218] Iteration 93700 (19.0969 iter/s, 5.23645s/100 iters), loss = 0.00298794
I1001 18:44:44.516887  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002988 (* 1 = 0.002988 loss)
I1001 18:44:44.516904  5416 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1001 18:44:49.761528  5416 solver.cpp:218] Iteration 93800 (19.0672 iter/s, 5.24462s/100 iters), loss = 0.00317795
I1001 18:44:49.761569  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003178 (* 1 = 0.003178 loss)
I1001 18:44:49.761574  5416 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1001 18:44:55.007674  5416 solver.cpp:218] Iteration 93900 (19.0618 iter/s, 5.24609s/100 iters), loss = 0.00732411
I1001 18:44:55.007705  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00732417 (* 1 = 0.00732417 loss)
I1001 18:44:55.007711  5416 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1001 18:44:59.991719  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:45:00.207327  5416 solver.cpp:330] Iteration 94000, Testing net (#0)
I1001 18:45:01.396179  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:45:01.446526  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1001 18:45:01.446560  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372466 (* 1 = 0.372466 loss)
I1001 18:45:01.499122  5416 solver.cpp:218] Iteration 94000 (15.405 iter/s, 6.4914s/100 iters), loss = 0.00230503
I1001 18:45:01.499147  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230508 (* 1 = 0.00230508 loss)
I1001 18:45:01.499155  5416 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1001 18:45:06.746873  5416 solver.cpp:218] Iteration 94100 (19.056 iter/s, 5.2477s/100 iters), loss = 0.0158113
I1001 18:45:06.746903  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158113 (* 1 = 0.0158113 loss)
I1001 18:45:06.746909  5416 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1001 18:45:11.989552  5416 solver.cpp:218] Iteration 94200 (19.0744 iter/s, 5.24263s/100 iters), loss = 0.00204458
I1001 18:45:11.989598  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204463 (* 1 = 0.00204463 loss)
I1001 18:45:11.989605  5416 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1001 18:45:17.231801  5416 solver.cpp:218] Iteration 94300 (19.0761 iter/s, 5.24215s/100 iters), loss = 0.00317394
I1001 18:45:17.231921  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317399 (* 1 = 0.00317399 loss)
I1001 18:45:17.231930  5416 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1001 18:45:22.478004  5416 solver.cpp:218] Iteration 94400 (19.0619 iter/s, 5.24606s/100 iters), loss = 0.00382159
I1001 18:45:22.478045  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382164 (* 1 = 0.00382164 loss)
I1001 18:45:22.478052  5416 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1001 18:45:27.462968  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:45:27.672673  5416 solver.cpp:330] Iteration 94500, Testing net (#0)
I1001 18:45:28.862794  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:45:28.913236  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1001 18:45:28.913264  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369787 (* 1 = 0.369787 loss)
I1001 18:45:28.965950  5416 solver.cpp:218] Iteration 94500 (15.4134 iter/s, 6.48787s/100 iters), loss = 0.00107067
I1001 18:45:28.965979  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107073 (* 1 = 0.00107073 loss)
I1001 18:45:28.965999  5416 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1001 18:45:34.208667  5416 solver.cpp:218] Iteration 94600 (19.0743 iter/s, 5.24267s/100 iters), loss = 0.0143028
I1001 18:45:34.208703  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143029 (* 1 = 0.0143029 loss)
I1001 18:45:34.208711  5416 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1001 18:45:39.459538  5416 solver.cpp:218] Iteration 94700 (19.0447 iter/s, 5.25082s/100 iters), loss = 0.0333498
I1001 18:45:39.459573  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333499 (* 1 = 0.0333499 loss)
I1001 18:45:39.459583  5416 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1001 18:45:44.704095  5416 solver.cpp:218] Iteration 94800 (19.0676 iter/s, 5.2445s/100 iters), loss = 0.00741581
I1001 18:45:44.704129  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00741587 (* 1 = 0.00741587 loss)
I1001 18:45:44.704149  5416 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1001 18:45:49.953135  5416 solver.cpp:218] Iteration 94900 (19.0513 iter/s, 5.24899s/100 iters), loss = 0.00203976
I1001 18:45:49.953213  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203983 (* 1 = 0.00203983 loss)
I1001 18:45:49.953223  5416 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1001 18:45:54.948598  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:45:55.159399  5416 solver.cpp:330] Iteration 95000, Testing net (#0)
I1001 18:45:56.346371  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:45:56.396628  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1001 18:45:56.396656  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374713 (* 1 = 0.374713 loss)
I1001 18:45:56.449287  5416 solver.cpp:218] Iteration 95000 (15.394 iter/s, 6.49606s/100 iters), loss = 0.000888025
I1001 18:45:56.449317  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000888096 (* 1 = 0.000888096 loss)
I1001 18:45:56.449327  5416 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1001 18:46:01.699326  5416 solver.cpp:218] Iteration 95100 (19.0477 iter/s, 5.24999s/100 iters), loss = 0.035169
I1001 18:46:01.699362  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351691 (* 1 = 0.0351691 loss)
I1001 18:46:01.699379  5416 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1001 18:46:06.943356  5416 solver.cpp:218] Iteration 95200 (19.0695 iter/s, 5.24398s/100 iters), loss = 0.0139981
I1001 18:46:06.943387  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139982 (* 1 = 0.0139982 loss)
I1001 18:46:06.943395  5416 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1001 18:46:12.187768  5416 solver.cpp:218] Iteration 95300 (19.0681 iter/s, 5.24435s/100 iters), loss = 0.0320409
I1001 18:46:12.187804  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032041 (* 1 = 0.032041 loss)
I1001 18:46:12.187814  5416 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1001 18:46:17.424080  5416 solver.cpp:218] Iteration 95400 (19.0976 iter/s, 5.23626s/100 iters), loss = 0.00122652
I1001 18:46:17.424114  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122659 (* 1 = 0.00122659 loss)
I1001 18:46:17.424124  5416 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1001 18:46:22.415563  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:46:22.626250  5416 solver.cpp:330] Iteration 95500, Testing net (#0)
I1001 18:46:23.814687  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:46:23.864737  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1001 18:46:23.864766  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373194 (* 1 = 0.373194 loss)
I1001 18:46:23.919085  5416 solver.cpp:218] Iteration 95500 (15.3966 iter/s, 6.49495s/100 iters), loss = 0.00101995
I1001 18:46:23.919124  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102002 (* 1 = 0.00102002 loss)
I1001 18:46:23.919134  5416 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1001 18:46:29.160809  5416 solver.cpp:218] Iteration 95600 (19.0779 iter/s, 5.24167s/100 iters), loss = 0.0235838
I1001 18:46:29.160841  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235839 (* 1 = 0.0235839 loss)
I1001 18:46:29.160848  5416 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1001 18:46:34.408145  5416 solver.cpp:218] Iteration 95700 (19.0575 iter/s, 5.24728s/100 iters), loss = 0.00788627
I1001 18:46:34.408186  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00788634 (* 1 = 0.00788634 loss)
I1001 18:46:34.408192  5416 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1001 18:46:39.649953  5416 solver.cpp:218] Iteration 95800 (19.0776 iter/s, 5.24175s/100 iters), loss = 0.00274045
I1001 18:46:39.649983  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274052 (* 1 = 0.00274052 loss)
I1001 18:46:39.649989  5416 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1001 18:46:44.883700  5416 solver.cpp:218] Iteration 95900 (19.107 iter/s, 5.2337s/100 iters), loss = 0.005163
I1001 18:46:44.883744  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00516307 (* 1 = 0.00516307 loss)
I1001 18:46:44.883750  5416 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1001 18:46:49.869074  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:46:50.079216  5416 solver.cpp:330] Iteration 96000, Testing net (#0)
I1001 18:46:51.275375  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:46:51.325736  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1001 18:46:51.325760  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370781 (* 1 = 0.370781 loss)
I1001 18:46:51.378403  5416 solver.cpp:218] Iteration 96000 (15.3974 iter/s, 6.49461s/100 iters), loss = 0.00371377
I1001 18:46:51.378442  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371385 (* 1 = 0.00371385 loss)
I1001 18:46:51.378448  5416 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1001 18:46:56.615440  5416 solver.cpp:218] Iteration 96100 (19.095 iter/s, 5.23698s/100 iters), loss = 0.00444435
I1001 18:46:56.615597  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444442 (* 1 = 0.00444442 loss)
I1001 18:46:56.615607  5416 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1001 18:47:01.857285  5416 solver.cpp:218] Iteration 96200 (19.0778 iter/s, 5.24168s/100 iters), loss = 0.00550765
I1001 18:47:01.857326  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550772 (* 1 = 0.00550772 loss)
I1001 18:47:01.857331  5416 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1001 18:47:07.097364  5416 solver.cpp:218] Iteration 96300 (19.0839 iter/s, 5.24002s/100 iters), loss = 0.0104051
I1001 18:47:07.097393  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104052 (* 1 = 0.0104052 loss)
I1001 18:47:07.097399  5416 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1001 18:47:12.334348  5416 solver.cpp:218] Iteration 96400 (19.0951 iter/s, 5.23693s/100 iters), loss = 0.00220905
I1001 18:47:12.334378  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220913 (* 1 = 0.00220913 loss)
I1001 18:47:12.334384  5416 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1001 18:47:17.315066  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:47:17.525260  5416 solver.cpp:330] Iteration 96500, Testing net (#0)
I1001 18:47:18.722991  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:47:18.772955  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1001 18:47:18.772981  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369669 (* 1 = 0.369669 loss)
I1001 18:47:18.826035  5416 solver.cpp:218] Iteration 96500 (15.4044 iter/s, 6.49164s/100 iters), loss = 0.00196642
I1001 18:47:18.826066  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196649 (* 1 = 0.00196649 loss)
I1001 18:47:18.826071  5416 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1001 18:47:24.076180  5416 solver.cpp:218] Iteration 96600 (19.0473 iter/s, 5.25009s/100 iters), loss = 0.00487786
I1001 18:47:24.076225  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487793 (* 1 = 0.00487793 loss)
I1001 18:47:24.076233  5416 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1001 18:47:29.317160  5416 solver.cpp:218] Iteration 96700 (19.0806 iter/s, 5.24092s/100 iters), loss = 0.0100265
I1001 18:47:29.317260  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100266 (* 1 = 0.0100266 loss)
I1001 18:47:29.317268  5416 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1001 18:47:34.565461  5416 solver.cpp:218] Iteration 96800 (19.0542 iter/s, 5.24818s/100 iters), loss = 0.00489266
I1001 18:47:34.565502  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489273 (* 1 = 0.00489273 loss)
I1001 18:47:34.565507  5416 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1001 18:47:39.814020  5416 solver.cpp:218] Iteration 96900 (19.0531 iter/s, 5.24849s/100 iters), loss = 0.00311954
I1001 18:47:39.814050  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311962 (* 1 = 0.00311962 loss)
I1001 18:47:39.814056  5416 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1001 18:47:44.790349  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:47:45.004092  5416 solver.cpp:330] Iteration 97000, Testing net (#0)
I1001 18:47:46.197018  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:47:46.247366  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1001 18:47:46.247392  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369061 (* 1 = 0.369061 loss)
I1001 18:47:46.299942  5416 solver.cpp:218] Iteration 97000 (15.4181 iter/s, 6.48587s/100 iters), loss = 0.00661243
I1001 18:47:46.299964  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066125 (* 1 = 0.0066125 loss)
I1001 18:47:46.299971  5416 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1001 18:47:51.545051  5416 solver.cpp:218] Iteration 97100 (19.0655 iter/s, 5.24506s/100 iters), loss = 0.00959761
I1001 18:47:51.545081  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00959768 (* 1 = 0.00959768 loss)
I1001 18:47:51.545089  5416 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1001 18:47:56.780634  5416 solver.cpp:218] Iteration 97200 (19.1003 iter/s, 5.23553s/100 iters), loss = 0.00400583
I1001 18:47:56.780674  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040059 (* 1 = 0.0040059 loss)
I1001 18:47:56.780681  5416 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1001 18:48:02.025578  5416 solver.cpp:218] Iteration 97300 (19.0662 iter/s, 5.24488s/100 iters), loss = 0.00599416
I1001 18:48:02.025717  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599422 (* 1 = 0.00599422 loss)
I1001 18:48:02.025724  5416 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1001 18:48:07.272642  5416 solver.cpp:218] Iteration 97400 (19.0588 iter/s, 5.24691s/100 iters), loss = 0.00126364
I1001 18:48:07.272672  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126371 (* 1 = 0.00126371 loss)
I1001 18:48:07.272680  5416 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1001 18:48:12.252346  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:48:12.461554  5416 solver.cpp:330] Iteration 97500, Testing net (#0)
I1001 18:48:13.650013  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:48:13.700201  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1001 18:48:13.700227  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371025 (* 1 = 0.371025 loss)
I1001 18:48:13.752737  5416 solver.cpp:218] Iteration 97500 (15.432 iter/s, 6.48005s/100 iters), loss = 0.0011323
I1001 18:48:13.752760  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113237 (* 1 = 0.00113237 loss)
I1001 18:48:13.752766  5416 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1001 18:48:18.999946  5416 solver.cpp:218] Iteration 97600 (19.0579 iter/s, 5.24716s/100 iters), loss = 0.0040472
I1001 18:48:18.999986  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404727 (* 1 = 0.00404727 loss)
I1001 18:48:18.999992  5416 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1001 18:48:24.250516  5416 solver.cpp:218] Iteration 97700 (19.0458 iter/s, 5.2505s/100 iters), loss = 0.00370208
I1001 18:48:24.250550  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370215 (* 1 = 0.00370215 loss)
I1001 18:48:24.250557  5416 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1001 18:48:29.490947  5416 solver.cpp:218] Iteration 97800 (19.0826 iter/s, 5.24038s/100 iters), loss = 0.00220349
I1001 18:48:29.490978  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220356 (* 1 = 0.00220356 loss)
I1001 18:48:29.490983  5416 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1001 18:48:34.734982  5416 solver.cpp:218] Iteration 97900 (19.0695 iter/s, 5.24398s/100 iters), loss = 0.00172629
I1001 18:48:34.735098  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172637 (* 1 = 0.00172637 loss)
I1001 18:48:34.735105  5416 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1001 18:48:39.716617  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:48:39.925705  5416 solver.cpp:330] Iteration 98000, Testing net (#0)
I1001 18:48:41.112407  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:48:41.163126  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1001 18:48:41.163161  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372762 (* 1 = 0.372762 loss)
I1001 18:48:41.215713  5416 solver.cpp:218] Iteration 98000 (15.4307 iter/s, 6.4806s/100 iters), loss = 0.00306145
I1001 18:48:41.215739  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306153 (* 1 = 0.00306153 loss)
I1001 18:48:41.215754  5416 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1001 18:48:46.461127  5416 solver.cpp:218] Iteration 98100 (19.0645 iter/s, 5.24536s/100 iters), loss = 0.0223755
I1001 18:48:46.461159  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223756 (* 1 = 0.0223756 loss)
I1001 18:48:46.461179  5416 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1001 18:48:51.704108  5416 solver.cpp:218] Iteration 98200 (19.0733 iter/s, 5.24293s/100 iters), loss = 0.0154006
I1001 18:48:51.704141  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154007 (* 1 = 0.0154007 loss)
I1001 18:48:51.704149  5416 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1001 18:48:56.943225  5416 solver.cpp:218] Iteration 98300 (19.0874 iter/s, 5.23906s/100 iters), loss = 0.0117781
I1001 18:48:56.943264  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117782 (* 1 = 0.0117782 loss)
I1001 18:48:56.943284  5416 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1001 18:49:02.188982  5416 solver.cpp:218] Iteration 98400 (19.0632 iter/s, 5.2457s/100 iters), loss = 0.0012662
I1001 18:49:02.189016  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126628 (* 1 = 0.00126628 loss)
I1001 18:49:02.189034  5416 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1001 18:49:07.176409  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:49:07.386835  5416 solver.cpp:330] Iteration 98500, Testing net (#0)
I1001 18:49:08.574972  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:49:08.625010  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1001 18:49:08.625036  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371296 (* 1 = 0.371296 loss)
I1001 18:49:08.677156  5416 solver.cpp:218] Iteration 98500 (15.4128 iter/s, 6.48812s/100 iters), loss = 0.00260502
I1001 18:49:08.677192  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026051 (* 1 = 0.0026051 loss)
I1001 18:49:08.677217  5416 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1001 18:49:13.927556  5416 solver.cpp:218] Iteration 98600 (19.0464 iter/s, 5.25035s/100 iters), loss = 0.00153002
I1001 18:49:13.927589  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153011 (* 1 = 0.00153011 loss)
I1001 18:49:13.927608  5416 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1001 18:49:19.171950  5416 solver.cpp:218] Iteration 98700 (19.0682 iter/s, 5.24434s/100 iters), loss = 0.00385411
I1001 18:49:19.171983  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385419 (* 1 = 0.00385419 loss)
I1001 18:49:19.172000  5416 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1001 18:49:24.413070  5416 solver.cpp:218] Iteration 98800 (19.0801 iter/s, 5.24107s/100 iters), loss = 0.00643844
I1001 18:49:24.413105  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643853 (* 1 = 0.00643853 loss)
I1001 18:49:24.413122  5416 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1001 18:49:29.653950  5416 solver.cpp:218] Iteration 98900 (19.081 iter/s, 5.24083s/100 iters), loss = 0.000957373
I1001 18:49:29.653981  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000957465 (* 1 = 0.000957465 loss)
I1001 18:49:29.653990  5416 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1001 18:49:34.636307  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:49:34.845752  5416 solver.cpp:330] Iteration 99000, Testing net (#0)
I1001 18:49:36.041067  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:49:36.092777  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1001 18:49:36.092825  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37562 (* 1 = 0.37562 loss)
I1001 18:49:36.146215  5416 solver.cpp:218] Iteration 99000 (15.4031 iter/s, 6.49221s/100 iters), loss = 0.00645376
I1001 18:49:36.146256  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645385 (* 1 = 0.00645385 loss)
I1001 18:49:36.146267  5416 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1001 18:49:41.387718  5416 solver.cpp:218] Iteration 99100 (19.0787 iter/s, 5.24145s/100 iters), loss = 0.00619149
I1001 18:49:41.387886  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00619158 (* 1 = 0.00619158 loss)
I1001 18:49:41.387912  5416 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1001 18:49:46.628700  5416 solver.cpp:218] Iteration 99200 (19.081 iter/s, 5.24081s/100 iters), loss = 0.0108472
I1001 18:49:46.628731  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108473 (* 1 = 0.0108473 loss)
I1001 18:49:46.628739  5416 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1001 18:49:51.873456  5416 solver.cpp:218] Iteration 99300 (19.0669 iter/s, 5.2447s/100 iters), loss = 0.00272531
I1001 18:49:51.873491  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272541 (* 1 = 0.00272541 loss)
I1001 18:49:51.873507  5416 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1001 18:49:57.119683  5416 solver.cpp:218] Iteration 99400 (19.0615 iter/s, 5.24617s/100 iters), loss = 0.0033
I1001 18:49:57.119721  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330009 (* 1 = 0.00330009 loss)
I1001 18:49:57.119741  5416 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1001 18:50:02.101902  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:50:02.312382  5416 solver.cpp:330] Iteration 99500, Testing net (#0)
I1001 18:50:03.507872  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:50:03.558234  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1001 18:50:03.558261  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37219 (* 1 = 0.37219 loss)
I1001 18:50:03.610746  5416 solver.cpp:218] Iteration 99500 (15.406 iter/s, 6.49096s/100 iters), loss = 0.0344442
I1001 18:50:03.610792  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344443 (* 1 = 0.0344443 loss)
I1001 18:50:03.610806  5416 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1001 18:50:08.846349  5416 solver.cpp:218] Iteration 99600 (19.1002 iter/s, 5.23555s/100 iters), loss = 0.0029145
I1001 18:50:08.846388  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029146 (* 1 = 0.0029146 loss)
I1001 18:50:08.846395  5416 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1001 18:50:14.086896  5416 solver.cpp:218] Iteration 99700 (19.0822 iter/s, 5.24048s/100 iters), loss = 0.00601145
I1001 18:50:14.087015  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601154 (* 1 = 0.00601154 loss)
I1001 18:50:14.087023  5416 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1001 18:50:19.330274  5416 solver.cpp:218] Iteration 99800 (19.0722 iter/s, 5.24324s/100 iters), loss = 0.0318586
I1001 18:50:19.330303  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318587 (* 1 = 0.0318587 loss)
I1001 18:50:19.330309  5416 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1001 18:50:24.573194  5416 solver.cpp:218] Iteration 99900 (19.0735 iter/s, 5.24287s/100 iters), loss = 0.00660891
I1001 18:50:24.573223  5416 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006609 (* 1 = 0.006609 loss)
I1001 18:50:24.573230  5416 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1001 18:50:29.551254  5425 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:50:29.760655  5416 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_100000.caffemodel
I1001 18:50:29.765578  5416 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha0.25_beta1_etanostudy_2study_nodecay_gauss_iter_100000.solverstate
I1001 18:50:29.779577  5416 solver.cpp:310] Iteration 100000, loss = 0.00237426
I1001 18:50:29.779597  5416 solver.cpp:330] Iteration 100000, Testing net (#0)
I1001 18:50:30.977356  5426 data_layer.cpp:73] Restarting data prefetching from start.
I1001 18:50:31.027671  5416 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1001 18:50:31.027696  5416 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369155 (* 1 = 0.369155 loss)
I1001 18:50:31.027701  5416 solver.cpp:315] Optimization Done.
I1001 18:50:31.027714  5416 caffe.cpp:259] Optimization Done.
