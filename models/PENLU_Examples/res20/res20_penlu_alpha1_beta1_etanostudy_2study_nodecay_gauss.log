I1005 10:19:46.607342  9385 caffe.cpp:218] Using GPUs 0
I1005 10:19:46.630367  9385 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1005 10:19:46.863512  9385 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha1_beta1_etanostudy_2study_nodecay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1005 10:19:46.863628  9385 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 10:19:46.865142  9385 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 10:19:46.865154  9385 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 10:19:46.865288  9385 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1005 10:19:46.865355  9385 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1005 10:19:46.865845  9385 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1005 10:19:46.866267  9385 layer_factory.hpp:77] Creating layer Data1
I1005 10:19:46.866361  9385 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1005 10:19:46.866390  9385 net.cpp:84] Creating Layer Data1
I1005 10:19:46.866399  9385 net.cpp:380] Data1 -> Data1
I1005 10:19:46.866421  9385 net.cpp:380] Data1 -> Data2
I1005 10:19:46.866433  9385 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 10:19:46.867925  9385 data_layer.cpp:45] output data size: 100,3,28,28
I1005 10:19:46.870183  9385 net.cpp:122] Setting up Data1
I1005 10:19:46.870196  9385 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1005 10:19:46.870201  9385 net.cpp:129] Top shape: 100 (100)
I1005 10:19:46.870203  9385 net.cpp:137] Memory required for data: 941200
I1005 10:19:46.870209  9385 layer_factory.hpp:77] Creating layer Convolution1
I1005 10:19:46.870225  9385 net.cpp:84] Creating Layer Convolution1
I1005 10:19:46.870229  9385 net.cpp:406] Convolution1 <- Data1
I1005 10:19:46.870240  9385 net.cpp:380] Convolution1 -> Convolution1
I1005 10:19:47.018599  9385 net.cpp:122] Setting up Convolution1
I1005 10:19:47.018623  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.018627  9385 net.cpp:137] Memory required for data: 5958800
I1005 10:19:47.018641  9385 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 10:19:47.018666  9385 net.cpp:84] Creating Layer BatchNorm1
I1005 10:19:47.018681  9385 net.cpp:406] BatchNorm1 <- Convolution1
I1005 10:19:47.018684  9385 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 10:19:47.018832  9385 net.cpp:122] Setting up BatchNorm1
I1005 10:19:47.018838  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.018841  9385 net.cpp:137] Memory required for data: 10976400
I1005 10:19:47.018848  9385 layer_factory.hpp:77] Creating layer Scale1
I1005 10:19:47.018857  9385 net.cpp:84] Creating Layer Scale1
I1005 10:19:47.018858  9385 net.cpp:406] Scale1 <- Convolution1
I1005 10:19:47.018872  9385 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 10:19:47.018932  9385 layer_factory.hpp:77] Creating layer Scale1
I1005 10:19:47.019073  9385 net.cpp:122] Setting up Scale1
I1005 10:19:47.019078  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.019079  9385 net.cpp:137] Memory required for data: 15994000
I1005 10:19:47.019083  9385 layer_factory.hpp:77] Creating layer penlu1
I1005 10:19:47.019093  9385 net.cpp:84] Creating Layer penlu1
I1005 10:19:47.019094  9385 net.cpp:406] penlu1 <- Convolution1
I1005 10:19:47.019109  9385 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1005 10:19:47.019733  9385 net.cpp:122] Setting up penlu1
I1005 10:19:47.019743  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.019747  9385 net.cpp:137] Memory required for data: 21011600
I1005 10:19:47.019753  9385 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1005 10:19:47.019758  9385 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1005 10:19:47.019760  9385 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1005 10:19:47.019774  9385 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1005 10:19:47.019781  9385 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1005 10:19:47.019824  9385 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1005 10:19:47.019829  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.019845  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.019846  9385 net.cpp:137] Memory required for data: 31046800
I1005 10:19:47.019848  9385 layer_factory.hpp:77] Creating layer Convolution2
I1005 10:19:47.019855  9385 net.cpp:84] Creating Layer Convolution2
I1005 10:19:47.019858  9385 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1005 10:19:47.019862  9385 net.cpp:380] Convolution2 -> Convolution2
I1005 10:19:47.020741  9385 net.cpp:122] Setting up Convolution2
I1005 10:19:47.020750  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.020753  9385 net.cpp:137] Memory required for data: 36064400
I1005 10:19:47.020758  9385 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 10:19:47.020784  9385 net.cpp:84] Creating Layer BatchNorm2
I1005 10:19:47.020788  9385 net.cpp:406] BatchNorm2 <- Convolution2
I1005 10:19:47.020803  9385 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 10:19:47.020941  9385 net.cpp:122] Setting up BatchNorm2
I1005 10:19:47.020946  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.020948  9385 net.cpp:137] Memory required for data: 41082000
I1005 10:19:47.020953  9385 layer_factory.hpp:77] Creating layer Scale2
I1005 10:19:47.020959  9385 net.cpp:84] Creating Layer Scale2
I1005 10:19:47.020961  9385 net.cpp:406] Scale2 <- Convolution2
I1005 10:19:47.020975  9385 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 10:19:47.021000  9385 layer_factory.hpp:77] Creating layer Scale2
I1005 10:19:47.021121  9385 net.cpp:122] Setting up Scale2
I1005 10:19:47.021126  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.021128  9385 net.cpp:137] Memory required for data: 46099600
I1005 10:19:47.021144  9385 layer_factory.hpp:77] Creating layer penlu2
I1005 10:19:47.021152  9385 net.cpp:84] Creating Layer penlu2
I1005 10:19:47.021154  9385 net.cpp:406] penlu2 <- Convolution2
I1005 10:19:47.021157  9385 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1005 10:19:47.021262  9385 net.cpp:122] Setting up penlu2
I1005 10:19:47.021268  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.021270  9385 net.cpp:137] Memory required for data: 51117200
I1005 10:19:47.021275  9385 layer_factory.hpp:77] Creating layer Convolution3
I1005 10:19:47.021282  9385 net.cpp:84] Creating Layer Convolution3
I1005 10:19:47.021286  9385 net.cpp:406] Convolution3 <- Convolution2
I1005 10:19:47.021289  9385 net.cpp:380] Convolution3 -> Convolution3
I1005 10:19:47.022130  9385 net.cpp:122] Setting up Convolution3
I1005 10:19:47.022140  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.022143  9385 net.cpp:137] Memory required for data: 56134800
I1005 10:19:47.022148  9385 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 10:19:47.022155  9385 net.cpp:84] Creating Layer BatchNorm3
I1005 10:19:47.022157  9385 net.cpp:406] BatchNorm3 <- Convolution3
I1005 10:19:47.022161  9385 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 10:19:47.022281  9385 net.cpp:122] Setting up BatchNorm3
I1005 10:19:47.022286  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.022289  9385 net.cpp:137] Memory required for data: 61152400
I1005 10:19:47.022294  9385 layer_factory.hpp:77] Creating layer Scale3
I1005 10:19:47.022298  9385 net.cpp:84] Creating Layer Scale3
I1005 10:19:47.022301  9385 net.cpp:406] Scale3 <- Convolution3
I1005 10:19:47.022305  9385 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 10:19:47.022328  9385 layer_factory.hpp:77] Creating layer Scale3
I1005 10:19:47.022398  9385 net.cpp:122] Setting up Scale3
I1005 10:19:47.022404  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.022406  9385 net.cpp:137] Memory required for data: 66170000
I1005 10:19:47.022410  9385 layer_factory.hpp:77] Creating layer Eltwise1
I1005 10:19:47.022414  9385 net.cpp:84] Creating Layer Eltwise1
I1005 10:19:47.022418  9385 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1005 10:19:47.022420  9385 net.cpp:406] Eltwise1 <- Convolution3
I1005 10:19:47.022423  9385 net.cpp:380] Eltwise1 -> Eltwise1
I1005 10:19:47.022439  9385 net.cpp:122] Setting up Eltwise1
I1005 10:19:47.022444  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.022446  9385 net.cpp:137] Memory required for data: 71187600
I1005 10:19:47.022449  9385 layer_factory.hpp:77] Creating layer penlu3
I1005 10:19:47.022454  9385 net.cpp:84] Creating Layer penlu3
I1005 10:19:47.022456  9385 net.cpp:406] penlu3 <- Eltwise1
I1005 10:19:47.022460  9385 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1005 10:19:47.022598  9385 net.cpp:122] Setting up penlu3
I1005 10:19:47.022605  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.022608  9385 net.cpp:137] Memory required for data: 76205200
I1005 10:19:47.022619  9385 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1005 10:19:47.022625  9385 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1005 10:19:47.022629  9385 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1005 10:19:47.022631  9385 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1005 10:19:47.022636  9385 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1005 10:19:47.022658  9385 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1005 10:19:47.022663  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.022666  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.022670  9385 net.cpp:137] Memory required for data: 86240400
I1005 10:19:47.022672  9385 layer_factory.hpp:77] Creating layer Convolution4
I1005 10:19:47.022680  9385 net.cpp:84] Creating Layer Convolution4
I1005 10:19:47.022682  9385 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1005 10:19:47.022686  9385 net.cpp:380] Convolution4 -> Convolution4
I1005 10:19:47.023541  9385 net.cpp:122] Setting up Convolution4
I1005 10:19:47.023551  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.023555  9385 net.cpp:137] Memory required for data: 91258000
I1005 10:19:47.023560  9385 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 10:19:47.023566  9385 net.cpp:84] Creating Layer BatchNorm4
I1005 10:19:47.023569  9385 net.cpp:406] BatchNorm4 <- Convolution4
I1005 10:19:47.023572  9385 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 10:19:47.023692  9385 net.cpp:122] Setting up BatchNorm4
I1005 10:19:47.023697  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.023699  9385 net.cpp:137] Memory required for data: 96275600
I1005 10:19:47.023707  9385 layer_factory.hpp:77] Creating layer Scale4
I1005 10:19:47.023715  9385 net.cpp:84] Creating Layer Scale4
I1005 10:19:47.023717  9385 net.cpp:406] Scale4 <- Convolution4
I1005 10:19:47.023720  9385 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 10:19:47.023746  9385 layer_factory.hpp:77] Creating layer Scale4
I1005 10:19:47.023816  9385 net.cpp:122] Setting up Scale4
I1005 10:19:47.023821  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.023823  9385 net.cpp:137] Memory required for data: 101293200
I1005 10:19:47.023828  9385 layer_factory.hpp:77] Creating layer penlu4
I1005 10:19:47.023834  9385 net.cpp:84] Creating Layer penlu4
I1005 10:19:47.023838  9385 net.cpp:406] penlu4 <- Convolution4
I1005 10:19:47.023841  9385 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1005 10:19:47.023936  9385 net.cpp:122] Setting up penlu4
I1005 10:19:47.023941  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.023942  9385 net.cpp:137] Memory required for data: 106310800
I1005 10:19:47.023947  9385 layer_factory.hpp:77] Creating layer Convolution5
I1005 10:19:47.023954  9385 net.cpp:84] Creating Layer Convolution5
I1005 10:19:47.023957  9385 net.cpp:406] Convolution5 <- Convolution4
I1005 10:19:47.023962  9385 net.cpp:380] Convolution5 -> Convolution5
I1005 10:19:47.024822  9385 net.cpp:122] Setting up Convolution5
I1005 10:19:47.024832  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.024835  9385 net.cpp:137] Memory required for data: 111328400
I1005 10:19:47.024840  9385 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 10:19:47.024845  9385 net.cpp:84] Creating Layer BatchNorm5
I1005 10:19:47.024848  9385 net.cpp:406] BatchNorm5 <- Convolution5
I1005 10:19:47.024852  9385 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 10:19:47.024972  9385 net.cpp:122] Setting up BatchNorm5
I1005 10:19:47.024977  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.024979  9385 net.cpp:137] Memory required for data: 116346000
I1005 10:19:47.024984  9385 layer_factory.hpp:77] Creating layer Scale5
I1005 10:19:47.024989  9385 net.cpp:84] Creating Layer Scale5
I1005 10:19:47.024992  9385 net.cpp:406] Scale5 <- Convolution5
I1005 10:19:47.024996  9385 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 10:19:47.025028  9385 layer_factory.hpp:77] Creating layer Scale5
I1005 10:19:47.025102  9385 net.cpp:122] Setting up Scale5
I1005 10:19:47.025107  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.025110  9385 net.cpp:137] Memory required for data: 121363600
I1005 10:19:47.025113  9385 layer_factory.hpp:77] Creating layer Eltwise2
I1005 10:19:47.025118  9385 net.cpp:84] Creating Layer Eltwise2
I1005 10:19:47.025121  9385 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1005 10:19:47.025125  9385 net.cpp:406] Eltwise2 <- Convolution5
I1005 10:19:47.025127  9385 net.cpp:380] Eltwise2 -> Eltwise2
I1005 10:19:47.025142  9385 net.cpp:122] Setting up Eltwise2
I1005 10:19:47.025146  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.025148  9385 net.cpp:137] Memory required for data: 126381200
I1005 10:19:47.025151  9385 layer_factory.hpp:77] Creating layer penlu5
I1005 10:19:47.025156  9385 net.cpp:84] Creating Layer penlu5
I1005 10:19:47.025158  9385 net.cpp:406] penlu5 <- Eltwise2
I1005 10:19:47.025162  9385 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1005 10:19:47.025260  9385 net.cpp:122] Setting up penlu5
I1005 10:19:47.025265  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.025267  9385 net.cpp:137] Memory required for data: 131398800
I1005 10:19:47.025272  9385 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1005 10:19:47.025276  9385 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1005 10:19:47.025279  9385 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1005 10:19:47.025282  9385 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1005 10:19:47.025286  9385 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1005 10:19:47.025308  9385 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1005 10:19:47.025312  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.025315  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.025317  9385 net.cpp:137] Memory required for data: 141434000
I1005 10:19:47.025319  9385 layer_factory.hpp:77] Creating layer Convolution6
I1005 10:19:47.025326  9385 net.cpp:84] Creating Layer Convolution6
I1005 10:19:47.025329  9385 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1005 10:19:47.025333  9385 net.cpp:380] Convolution6 -> Convolution6
I1005 10:19:47.026180  9385 net.cpp:122] Setting up Convolution6
I1005 10:19:47.026190  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.026192  9385 net.cpp:137] Memory required for data: 146451600
I1005 10:19:47.026197  9385 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 10:19:47.026201  9385 net.cpp:84] Creating Layer BatchNorm6
I1005 10:19:47.026204  9385 net.cpp:406] BatchNorm6 <- Convolution6
I1005 10:19:47.026209  9385 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 10:19:47.026332  9385 net.cpp:122] Setting up BatchNorm6
I1005 10:19:47.026337  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.026340  9385 net.cpp:137] Memory required for data: 151469200
I1005 10:19:47.026345  9385 layer_factory.hpp:77] Creating layer Scale6
I1005 10:19:47.026348  9385 net.cpp:84] Creating Layer Scale6
I1005 10:19:47.026351  9385 net.cpp:406] Scale6 <- Convolution6
I1005 10:19:47.026355  9385 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 10:19:47.026378  9385 layer_factory.hpp:77] Creating layer Scale6
I1005 10:19:47.026449  9385 net.cpp:122] Setting up Scale6
I1005 10:19:47.026454  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.026456  9385 net.cpp:137] Memory required for data: 156486800
I1005 10:19:47.026460  9385 layer_factory.hpp:77] Creating layer penlu6
I1005 10:19:47.026468  9385 net.cpp:84] Creating Layer penlu6
I1005 10:19:47.026471  9385 net.cpp:406] penlu6 <- Convolution6
I1005 10:19:47.026475  9385 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1005 10:19:47.026598  9385 net.cpp:122] Setting up penlu6
I1005 10:19:47.026605  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.026607  9385 net.cpp:137] Memory required for data: 161504400
I1005 10:19:47.026619  9385 layer_factory.hpp:77] Creating layer Convolution7
I1005 10:19:47.026626  9385 net.cpp:84] Creating Layer Convolution7
I1005 10:19:47.026629  9385 net.cpp:406] Convolution7 <- Convolution6
I1005 10:19:47.026634  9385 net.cpp:380] Convolution7 -> Convolution7
I1005 10:19:47.027163  9385 net.cpp:122] Setting up Convolution7
I1005 10:19:47.027173  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.027176  9385 net.cpp:137] Memory required for data: 166522000
I1005 10:19:47.027180  9385 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 10:19:47.027185  9385 net.cpp:84] Creating Layer BatchNorm7
I1005 10:19:47.027189  9385 net.cpp:406] BatchNorm7 <- Convolution7
I1005 10:19:47.027192  9385 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 10:19:47.027313  9385 net.cpp:122] Setting up BatchNorm7
I1005 10:19:47.027318  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.027320  9385 net.cpp:137] Memory required for data: 171539600
I1005 10:19:47.027329  9385 layer_factory.hpp:77] Creating layer Scale7
I1005 10:19:47.027336  9385 net.cpp:84] Creating Layer Scale7
I1005 10:19:47.027339  9385 net.cpp:406] Scale7 <- Convolution7
I1005 10:19:47.027343  9385 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 10:19:47.027367  9385 layer_factory.hpp:77] Creating layer Scale7
I1005 10:19:47.027439  9385 net.cpp:122] Setting up Scale7
I1005 10:19:47.027444  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.027447  9385 net.cpp:137] Memory required for data: 176557200
I1005 10:19:47.027451  9385 layer_factory.hpp:77] Creating layer Eltwise3
I1005 10:19:47.027456  9385 net.cpp:84] Creating Layer Eltwise3
I1005 10:19:47.027457  9385 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1005 10:19:47.027460  9385 net.cpp:406] Eltwise3 <- Convolution7
I1005 10:19:47.027463  9385 net.cpp:380] Eltwise3 -> Eltwise3
I1005 10:19:47.027478  9385 net.cpp:122] Setting up Eltwise3
I1005 10:19:47.027482  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.027484  9385 net.cpp:137] Memory required for data: 181574800
I1005 10:19:47.027487  9385 layer_factory.hpp:77] Creating layer penlu7
I1005 10:19:47.027492  9385 net.cpp:84] Creating Layer penlu7
I1005 10:19:47.027494  9385 net.cpp:406] penlu7 <- Eltwise3
I1005 10:19:47.027498  9385 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1005 10:19:47.027597  9385 net.cpp:122] Setting up penlu7
I1005 10:19:47.027602  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.027604  9385 net.cpp:137] Memory required for data: 186592400
I1005 10:19:47.027608  9385 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1005 10:19:47.027612  9385 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1005 10:19:47.027614  9385 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1005 10:19:47.027618  9385 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1005 10:19:47.027623  9385 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1005 10:19:47.027643  9385 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1005 10:19:47.027647  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.027650  9385 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 10:19:47.027652  9385 net.cpp:137] Memory required for data: 196627600
I1005 10:19:47.027654  9385 layer_factory.hpp:77] Creating layer Convolution8
I1005 10:19:47.027662  9385 net.cpp:84] Creating Layer Convolution8
I1005 10:19:47.027664  9385 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1005 10:19:47.027667  9385 net.cpp:380] Convolution8 -> Convolution8
I1005 10:19:47.028790  9385 net.cpp:122] Setting up Convolution8
I1005 10:19:47.028801  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.028805  9385 net.cpp:137] Memory required for data: 199136400
I1005 10:19:47.028810  9385 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 10:19:47.028815  9385 net.cpp:84] Creating Layer BatchNorm8
I1005 10:19:47.028818  9385 net.cpp:406] BatchNorm8 <- Convolution8
I1005 10:19:47.028832  9385 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 10:19:47.028966  9385 net.cpp:122] Setting up BatchNorm8
I1005 10:19:47.028972  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.028975  9385 net.cpp:137] Memory required for data: 201645200
I1005 10:19:47.028980  9385 layer_factory.hpp:77] Creating layer Scale8
I1005 10:19:47.028985  9385 net.cpp:84] Creating Layer Scale8
I1005 10:19:47.028987  9385 net.cpp:406] Scale8 <- Convolution8
I1005 10:19:47.028991  9385 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 10:19:47.029016  9385 layer_factory.hpp:77] Creating layer Scale8
I1005 10:19:47.029086  9385 net.cpp:122] Setting up Scale8
I1005 10:19:47.029091  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.029093  9385 net.cpp:137] Memory required for data: 204154000
I1005 10:19:47.029098  9385 layer_factory.hpp:77] Creating layer Convolution9
I1005 10:19:47.029104  9385 net.cpp:84] Creating Layer Convolution9
I1005 10:19:47.029108  9385 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1005 10:19:47.029111  9385 net.cpp:380] Convolution9 -> Convolution9
I1005 10:19:47.030539  9385 net.cpp:122] Setting up Convolution9
I1005 10:19:47.030550  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.030552  9385 net.cpp:137] Memory required for data: 206662800
I1005 10:19:47.030557  9385 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 10:19:47.030562  9385 net.cpp:84] Creating Layer BatchNorm9
I1005 10:19:47.030565  9385 net.cpp:406] BatchNorm9 <- Convolution9
I1005 10:19:47.030570  9385 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 10:19:47.030833  9385 net.cpp:122] Setting up BatchNorm9
I1005 10:19:47.030841  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.030843  9385 net.cpp:137] Memory required for data: 209171600
I1005 10:19:47.030859  9385 layer_factory.hpp:77] Creating layer Scale9
I1005 10:19:47.030865  9385 net.cpp:84] Creating Layer Scale9
I1005 10:19:47.030869  9385 net.cpp:406] Scale9 <- Convolution9
I1005 10:19:47.030874  9385 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 10:19:47.030901  9385 layer_factory.hpp:77] Creating layer Scale9
I1005 10:19:47.030975  9385 net.cpp:122] Setting up Scale9
I1005 10:19:47.030982  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.030983  9385 net.cpp:137] Memory required for data: 211680400
I1005 10:19:47.030988  9385 layer_factory.hpp:77] Creating layer penlu8
I1005 10:19:47.030994  9385 net.cpp:84] Creating Layer penlu8
I1005 10:19:47.030997  9385 net.cpp:406] penlu8 <- Convolution9
I1005 10:19:47.031002  9385 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1005 10:19:47.031103  9385 net.cpp:122] Setting up penlu8
I1005 10:19:47.031108  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.031111  9385 net.cpp:137] Memory required for data: 214189200
I1005 10:19:47.031116  9385 layer_factory.hpp:77] Creating layer Convolution10
I1005 10:19:47.031122  9385 net.cpp:84] Creating Layer Convolution10
I1005 10:19:47.031126  9385 net.cpp:406] Convolution10 <- Convolution9
I1005 10:19:47.031131  9385 net.cpp:380] Convolution10 -> Convolution10
I1005 10:19:47.032207  9385 net.cpp:122] Setting up Convolution10
I1005 10:19:47.032236  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.032239  9385 net.cpp:137] Memory required for data: 216698000
I1005 10:19:47.032244  9385 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 10:19:47.032249  9385 net.cpp:84] Creating Layer BatchNorm10
I1005 10:19:47.032253  9385 net.cpp:406] BatchNorm10 <- Convolution10
I1005 10:19:47.032258  9385 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 10:19:47.032397  9385 net.cpp:122] Setting up BatchNorm10
I1005 10:19:47.032402  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.032403  9385 net.cpp:137] Memory required for data: 219206800
I1005 10:19:47.032408  9385 layer_factory.hpp:77] Creating layer Scale10
I1005 10:19:47.032413  9385 net.cpp:84] Creating Layer Scale10
I1005 10:19:47.032415  9385 net.cpp:406] Scale10 <- Convolution10
I1005 10:19:47.032428  9385 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 10:19:47.032455  9385 layer_factory.hpp:77] Creating layer Scale10
I1005 10:19:47.032529  9385 net.cpp:122] Setting up Scale10
I1005 10:19:47.032534  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.032536  9385 net.cpp:137] Memory required for data: 221715600
I1005 10:19:47.032541  9385 layer_factory.hpp:77] Creating layer Eltwise4
I1005 10:19:47.032544  9385 net.cpp:84] Creating Layer Eltwise4
I1005 10:19:47.032547  9385 net.cpp:406] Eltwise4 <- Convolution8
I1005 10:19:47.032551  9385 net.cpp:406] Eltwise4 <- Convolution10
I1005 10:19:47.032554  9385 net.cpp:380] Eltwise4 -> Eltwise4
I1005 10:19:47.032570  9385 net.cpp:122] Setting up Eltwise4
I1005 10:19:47.032585  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.032588  9385 net.cpp:137] Memory required for data: 224224400
I1005 10:19:47.032590  9385 layer_factory.hpp:77] Creating layer penlu9
I1005 10:19:47.032595  9385 net.cpp:84] Creating Layer penlu9
I1005 10:19:47.032598  9385 net.cpp:406] penlu9 <- Eltwise4
I1005 10:19:47.032603  9385 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1005 10:19:47.032723  9385 net.cpp:122] Setting up penlu9
I1005 10:19:47.032728  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.032740  9385 net.cpp:137] Memory required for data: 226733200
I1005 10:19:47.032745  9385 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1005 10:19:47.032748  9385 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1005 10:19:47.032752  9385 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1005 10:19:47.032754  9385 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1005 10:19:47.032759  9385 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1005 10:19:47.032791  9385 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1005 10:19:47.032795  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.032809  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.032810  9385 net.cpp:137] Memory required for data: 231750800
I1005 10:19:47.032812  9385 layer_factory.hpp:77] Creating layer Convolution11
I1005 10:19:47.032819  9385 net.cpp:84] Creating Layer Convolution11
I1005 10:19:47.032821  9385 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1005 10:19:47.032826  9385 net.cpp:380] Convolution11 -> Convolution11
I1005 10:19:47.033860  9385 net.cpp:122] Setting up Convolution11
I1005 10:19:47.033871  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.033875  9385 net.cpp:137] Memory required for data: 234259600
I1005 10:19:47.033879  9385 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 10:19:47.033885  9385 net.cpp:84] Creating Layer BatchNorm11
I1005 10:19:47.033887  9385 net.cpp:406] BatchNorm11 <- Convolution11
I1005 10:19:47.033892  9385 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 10:19:47.034024  9385 net.cpp:122] Setting up BatchNorm11
I1005 10:19:47.034029  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.034031  9385 net.cpp:137] Memory required for data: 236768400
I1005 10:19:47.034036  9385 layer_factory.hpp:77] Creating layer Scale11
I1005 10:19:47.034040  9385 net.cpp:84] Creating Layer Scale11
I1005 10:19:47.034044  9385 net.cpp:406] Scale11 <- Convolution11
I1005 10:19:47.034047  9385 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 10:19:47.034073  9385 layer_factory.hpp:77] Creating layer Scale11
I1005 10:19:47.034149  9385 net.cpp:122] Setting up Scale11
I1005 10:19:47.034154  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.034157  9385 net.cpp:137] Memory required for data: 239277200
I1005 10:19:47.034160  9385 layer_factory.hpp:77] Creating layer penlu10
I1005 10:19:47.034165  9385 net.cpp:84] Creating Layer penlu10
I1005 10:19:47.034168  9385 net.cpp:406] penlu10 <- Convolution11
I1005 10:19:47.034173  9385 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1005 10:19:47.034286  9385 net.cpp:122] Setting up penlu10
I1005 10:19:47.034291  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.034301  9385 net.cpp:137] Memory required for data: 241786000
I1005 10:19:47.034307  9385 layer_factory.hpp:77] Creating layer Convolution12
I1005 10:19:47.034323  9385 net.cpp:84] Creating Layer Convolution12
I1005 10:19:47.034327  9385 net.cpp:406] Convolution12 <- Convolution11
I1005 10:19:47.034332  9385 net.cpp:380] Convolution12 -> Convolution12
I1005 10:19:47.035400  9385 net.cpp:122] Setting up Convolution12
I1005 10:19:47.035410  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.035414  9385 net.cpp:137] Memory required for data: 244294800
I1005 10:19:47.035418  9385 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 10:19:47.035424  9385 net.cpp:84] Creating Layer BatchNorm12
I1005 10:19:47.035428  9385 net.cpp:406] BatchNorm12 <- Convolution12
I1005 10:19:47.035431  9385 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 10:19:47.035567  9385 net.cpp:122] Setting up BatchNorm12
I1005 10:19:47.035571  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.035574  9385 net.cpp:137] Memory required for data: 246803600
I1005 10:19:47.035588  9385 layer_factory.hpp:77] Creating layer Scale12
I1005 10:19:47.035593  9385 net.cpp:84] Creating Layer Scale12
I1005 10:19:47.035596  9385 net.cpp:406] Scale12 <- Convolution12
I1005 10:19:47.035599  9385 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 10:19:47.035626  9385 layer_factory.hpp:77] Creating layer Scale12
I1005 10:19:47.035701  9385 net.cpp:122] Setting up Scale12
I1005 10:19:47.035706  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.035708  9385 net.cpp:137] Memory required for data: 249312400
I1005 10:19:47.035712  9385 layer_factory.hpp:77] Creating layer Eltwise5
I1005 10:19:47.035717  9385 net.cpp:84] Creating Layer Eltwise5
I1005 10:19:47.035720  9385 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1005 10:19:47.035723  9385 net.cpp:406] Eltwise5 <- Convolution12
I1005 10:19:47.035727  9385 net.cpp:380] Eltwise5 -> Eltwise5
I1005 10:19:47.035742  9385 net.cpp:122] Setting up Eltwise5
I1005 10:19:47.035748  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.035749  9385 net.cpp:137] Memory required for data: 251821200
I1005 10:19:47.035751  9385 layer_factory.hpp:77] Creating layer penlu11
I1005 10:19:47.035756  9385 net.cpp:84] Creating Layer penlu11
I1005 10:19:47.035759  9385 net.cpp:406] penlu11 <- Eltwise5
I1005 10:19:47.035763  9385 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1005 10:19:47.035868  9385 net.cpp:122] Setting up penlu11
I1005 10:19:47.035872  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.035876  9385 net.cpp:137] Memory required for data: 254330000
I1005 10:19:47.035881  9385 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1005 10:19:47.035886  9385 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1005 10:19:47.035888  9385 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1005 10:19:47.035892  9385 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1005 10:19:47.035897  9385 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1005 10:19:47.035918  9385 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1005 10:19:47.035923  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.035926  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.035928  9385 net.cpp:137] Memory required for data: 259347600
I1005 10:19:47.035931  9385 layer_factory.hpp:77] Creating layer Convolution13
I1005 10:19:47.035936  9385 net.cpp:84] Creating Layer Convolution13
I1005 10:19:47.035940  9385 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1005 10:19:47.035944  9385 net.cpp:380] Convolution13 -> Convolution13
I1005 10:19:47.036976  9385 net.cpp:122] Setting up Convolution13
I1005 10:19:47.036986  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.036989  9385 net.cpp:137] Memory required for data: 261856400
I1005 10:19:47.036993  9385 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 10:19:47.036999  9385 net.cpp:84] Creating Layer BatchNorm13
I1005 10:19:47.037009  9385 net.cpp:406] BatchNorm13 <- Convolution13
I1005 10:19:47.037014  9385 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 10:19:47.037145  9385 net.cpp:122] Setting up BatchNorm13
I1005 10:19:47.037151  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.037153  9385 net.cpp:137] Memory required for data: 264365200
I1005 10:19:47.037158  9385 layer_factory.hpp:77] Creating layer Scale13
I1005 10:19:47.037163  9385 net.cpp:84] Creating Layer Scale13
I1005 10:19:47.037166  9385 net.cpp:406] Scale13 <- Convolution13
I1005 10:19:47.037169  9385 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 10:19:47.037196  9385 layer_factory.hpp:77] Creating layer Scale13
I1005 10:19:47.037271  9385 net.cpp:122] Setting up Scale13
I1005 10:19:47.037276  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.037278  9385 net.cpp:137] Memory required for data: 266874000
I1005 10:19:47.037282  9385 layer_factory.hpp:77] Creating layer penlu12
I1005 10:19:47.037288  9385 net.cpp:84] Creating Layer penlu12
I1005 10:19:47.037292  9385 net.cpp:406] penlu12 <- Convolution13
I1005 10:19:47.037295  9385 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1005 10:19:47.037400  9385 net.cpp:122] Setting up penlu12
I1005 10:19:47.037405  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.037406  9385 net.cpp:137] Memory required for data: 269382800
I1005 10:19:47.037411  9385 layer_factory.hpp:77] Creating layer Convolution14
I1005 10:19:47.037418  9385 net.cpp:84] Creating Layer Convolution14
I1005 10:19:47.037421  9385 net.cpp:406] Convolution14 <- Convolution13
I1005 10:19:47.037425  9385 net.cpp:380] Convolution14 -> Convolution14
I1005 10:19:47.038485  9385 net.cpp:122] Setting up Convolution14
I1005 10:19:47.038494  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.038497  9385 net.cpp:137] Memory required for data: 271891600
I1005 10:19:47.038513  9385 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 10:19:47.038525  9385 net.cpp:84] Creating Layer BatchNorm14
I1005 10:19:47.038529  9385 net.cpp:406] BatchNorm14 <- Convolution14
I1005 10:19:47.038533  9385 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 10:19:47.038663  9385 net.cpp:122] Setting up BatchNorm14
I1005 10:19:47.038669  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.038672  9385 net.cpp:137] Memory required for data: 274400400
I1005 10:19:47.038677  9385 layer_factory.hpp:77] Creating layer Scale14
I1005 10:19:47.038682  9385 net.cpp:84] Creating Layer Scale14
I1005 10:19:47.038686  9385 net.cpp:406] Scale14 <- Convolution14
I1005 10:19:47.038688  9385 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 10:19:47.038714  9385 layer_factory.hpp:77] Creating layer Scale14
I1005 10:19:47.038790  9385 net.cpp:122] Setting up Scale14
I1005 10:19:47.038796  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.038799  9385 net.cpp:137] Memory required for data: 276909200
I1005 10:19:47.038802  9385 layer_factory.hpp:77] Creating layer Eltwise6
I1005 10:19:47.038806  9385 net.cpp:84] Creating Layer Eltwise6
I1005 10:19:47.038808  9385 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1005 10:19:47.038811  9385 net.cpp:406] Eltwise6 <- Convolution14
I1005 10:19:47.038815  9385 net.cpp:380] Eltwise6 -> Eltwise6
I1005 10:19:47.038830  9385 net.cpp:122] Setting up Eltwise6
I1005 10:19:47.038833  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.038836  9385 net.cpp:137] Memory required for data: 279418000
I1005 10:19:47.038837  9385 layer_factory.hpp:77] Creating layer penlu13
I1005 10:19:47.038842  9385 net.cpp:84] Creating Layer penlu13
I1005 10:19:47.038844  9385 net.cpp:406] penlu13 <- Eltwise6
I1005 10:19:47.038848  9385 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1005 10:19:47.038972  9385 net.cpp:122] Setting up penlu13
I1005 10:19:47.038976  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.038978  9385 net.cpp:137] Memory required for data: 281926800
I1005 10:19:47.038982  9385 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1005 10:19:47.038995  9385 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1005 10:19:47.038997  9385 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1005 10:19:47.039000  9385 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1005 10:19:47.039005  9385 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1005 10:19:47.039027  9385 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1005 10:19:47.039031  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.039034  9385 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 10:19:47.039036  9385 net.cpp:137] Memory required for data: 286944400
I1005 10:19:47.039038  9385 layer_factory.hpp:77] Creating layer Convolution15
I1005 10:19:47.039043  9385 net.cpp:84] Creating Layer Convolution15
I1005 10:19:47.039047  9385 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1005 10:19:47.039050  9385 net.cpp:380] Convolution15 -> Convolution15
I1005 10:19:47.039933  9385 net.cpp:122] Setting up Convolution15
I1005 10:19:47.039942  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.039944  9385 net.cpp:137] Memory required for data: 288198800
I1005 10:19:47.039948  9385 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 10:19:47.039954  9385 net.cpp:84] Creating Layer BatchNorm15
I1005 10:19:47.039957  9385 net.cpp:406] BatchNorm15 <- Convolution15
I1005 10:19:47.039960  9385 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 10:19:47.040091  9385 net.cpp:122] Setting up BatchNorm15
I1005 10:19:47.040094  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.040097  9385 net.cpp:137] Memory required for data: 289453200
I1005 10:19:47.040102  9385 layer_factory.hpp:77] Creating layer Scale15
I1005 10:19:47.040105  9385 net.cpp:84] Creating Layer Scale15
I1005 10:19:47.040108  9385 net.cpp:406] Scale15 <- Convolution15
I1005 10:19:47.040112  9385 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 10:19:47.040138  9385 layer_factory.hpp:77] Creating layer Scale15
I1005 10:19:47.040210  9385 net.cpp:122] Setting up Scale15
I1005 10:19:47.040215  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.040217  9385 net.cpp:137] Memory required for data: 290707600
I1005 10:19:47.040220  9385 layer_factory.hpp:77] Creating layer Convolution16
I1005 10:19:47.040227  9385 net.cpp:84] Creating Layer Convolution16
I1005 10:19:47.040230  9385 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1005 10:19:47.040233  9385 net.cpp:380] Convolution16 -> Convolution16
I1005 10:19:47.041993  9385 net.cpp:122] Setting up Convolution16
I1005 10:19:47.042002  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.042006  9385 net.cpp:137] Memory required for data: 291962000
I1005 10:19:47.042011  9385 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 10:19:47.042016  9385 net.cpp:84] Creating Layer BatchNorm16
I1005 10:19:47.042018  9385 net.cpp:406] BatchNorm16 <- Convolution16
I1005 10:19:47.042022  9385 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 10:19:47.042153  9385 net.cpp:122] Setting up BatchNorm16
I1005 10:19:47.042157  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.042160  9385 net.cpp:137] Memory required for data: 293216400
I1005 10:19:47.042165  9385 layer_factory.hpp:77] Creating layer Scale16
I1005 10:19:47.042168  9385 net.cpp:84] Creating Layer Scale16
I1005 10:19:47.042171  9385 net.cpp:406] Scale16 <- Convolution16
I1005 10:19:47.042173  9385 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 10:19:47.042201  9385 layer_factory.hpp:77] Creating layer Scale16
I1005 10:19:47.042273  9385 net.cpp:122] Setting up Scale16
I1005 10:19:47.042277  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.042280  9385 net.cpp:137] Memory required for data: 294470800
I1005 10:19:47.042284  9385 layer_factory.hpp:77] Creating layer penlu14
I1005 10:19:47.042289  9385 net.cpp:84] Creating Layer penlu14
I1005 10:19:47.042290  9385 net.cpp:406] penlu14 <- Convolution16
I1005 10:19:47.042301  9385 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1005 10:19:47.042407  9385 net.cpp:122] Setting up penlu14
I1005 10:19:47.042412  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.042413  9385 net.cpp:137] Memory required for data: 295725200
I1005 10:19:47.042418  9385 layer_factory.hpp:77] Creating layer Convolution17
I1005 10:19:47.042424  9385 net.cpp:84] Creating Layer Convolution17
I1005 10:19:47.042428  9385 net.cpp:406] Convolution17 <- Convolution16
I1005 10:19:47.042431  9385 net.cpp:380] Convolution17 -> Convolution17
I1005 10:19:47.044087  9385 net.cpp:122] Setting up Convolution17
I1005 10:19:47.044095  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.044098  9385 net.cpp:137] Memory required for data: 296979600
I1005 10:19:47.044103  9385 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 10:19:47.044109  9385 net.cpp:84] Creating Layer BatchNorm17
I1005 10:19:47.044112  9385 net.cpp:406] BatchNorm17 <- Convolution17
I1005 10:19:47.044116  9385 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 10:19:47.044248  9385 net.cpp:122] Setting up BatchNorm17
I1005 10:19:47.044252  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.044255  9385 net.cpp:137] Memory required for data: 298234000
I1005 10:19:47.044260  9385 layer_factory.hpp:77] Creating layer Scale17
I1005 10:19:47.044263  9385 net.cpp:84] Creating Layer Scale17
I1005 10:19:47.044266  9385 net.cpp:406] Scale17 <- Convolution17
I1005 10:19:47.044270  9385 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 10:19:47.044296  9385 layer_factory.hpp:77] Creating layer Scale17
I1005 10:19:47.044370  9385 net.cpp:122] Setting up Scale17
I1005 10:19:47.044374  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.044376  9385 net.cpp:137] Memory required for data: 299488400
I1005 10:19:47.044380  9385 layer_factory.hpp:77] Creating layer Eltwise7
I1005 10:19:47.044385  9385 net.cpp:84] Creating Layer Eltwise7
I1005 10:19:47.044387  9385 net.cpp:406] Eltwise7 <- Convolution15
I1005 10:19:47.044390  9385 net.cpp:406] Eltwise7 <- Convolution17
I1005 10:19:47.044394  9385 net.cpp:380] Eltwise7 -> Eltwise7
I1005 10:19:47.044409  9385 net.cpp:122] Setting up Eltwise7
I1005 10:19:47.044412  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.044414  9385 net.cpp:137] Memory required for data: 300742800
I1005 10:19:47.044416  9385 layer_factory.hpp:77] Creating layer penlu15
I1005 10:19:47.044422  9385 net.cpp:84] Creating Layer penlu15
I1005 10:19:47.044425  9385 net.cpp:406] penlu15 <- Eltwise7
I1005 10:19:47.044427  9385 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1005 10:19:47.044533  9385 net.cpp:122] Setting up penlu15
I1005 10:19:47.044538  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.044539  9385 net.cpp:137] Memory required for data: 301997200
I1005 10:19:47.044543  9385 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1005 10:19:47.044548  9385 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1005 10:19:47.044549  9385 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1005 10:19:47.044553  9385 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1005 10:19:47.044556  9385 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1005 10:19:47.044579  9385 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1005 10:19:47.044581  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.044584  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.044586  9385 net.cpp:137] Memory required for data: 304506000
I1005 10:19:47.044589  9385 layer_factory.hpp:77] Creating layer Convolution18
I1005 10:19:47.044611  9385 net.cpp:84] Creating Layer Convolution18
I1005 10:19:47.044613  9385 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1005 10:19:47.044630  9385 net.cpp:380] Convolution18 -> Convolution18
I1005 10:19:47.046504  9385 net.cpp:122] Setting up Convolution18
I1005 10:19:47.046515  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.046519  9385 net.cpp:137] Memory required for data: 305760400
I1005 10:19:47.046537  9385 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 10:19:47.046543  9385 net.cpp:84] Creating Layer BatchNorm18
I1005 10:19:47.046546  9385 net.cpp:406] BatchNorm18 <- Convolution18
I1005 10:19:47.046550  9385 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 10:19:47.046687  9385 net.cpp:122] Setting up BatchNorm18
I1005 10:19:47.046692  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.046694  9385 net.cpp:137] Memory required for data: 307014800
I1005 10:19:47.046700  9385 layer_factory.hpp:77] Creating layer Scale18
I1005 10:19:47.046705  9385 net.cpp:84] Creating Layer Scale18
I1005 10:19:47.046706  9385 net.cpp:406] Scale18 <- Convolution18
I1005 10:19:47.046710  9385 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 10:19:47.046737  9385 layer_factory.hpp:77] Creating layer Scale18
I1005 10:19:47.046834  9385 net.cpp:122] Setting up Scale18
I1005 10:19:47.046840  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.046852  9385 net.cpp:137] Memory required for data: 308269200
I1005 10:19:47.046856  9385 layer_factory.hpp:77] Creating layer penlu16
I1005 10:19:47.046861  9385 net.cpp:84] Creating Layer penlu16
I1005 10:19:47.046864  9385 net.cpp:406] penlu16 <- Convolution18
I1005 10:19:47.046869  9385 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1005 10:19:47.046983  9385 net.cpp:122] Setting up penlu16
I1005 10:19:47.046989  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.047000  9385 net.cpp:137] Memory required for data: 309523600
I1005 10:19:47.047005  9385 layer_factory.hpp:77] Creating layer Convolution19
I1005 10:19:47.047011  9385 net.cpp:84] Creating Layer Convolution19
I1005 10:19:47.047014  9385 net.cpp:406] Convolution19 <- Convolution18
I1005 10:19:47.047019  9385 net.cpp:380] Convolution19 -> Convolution19
I1005 10:19:47.049161  9385 net.cpp:122] Setting up Convolution19
I1005 10:19:47.049171  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.049175  9385 net.cpp:137] Memory required for data: 310778000
I1005 10:19:47.049180  9385 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 10:19:47.049185  9385 net.cpp:84] Creating Layer BatchNorm19
I1005 10:19:47.049190  9385 net.cpp:406] BatchNorm19 <- Convolution19
I1005 10:19:47.049193  9385 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 10:19:47.049347  9385 net.cpp:122] Setting up BatchNorm19
I1005 10:19:47.049352  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.049355  9385 net.cpp:137] Memory required for data: 312032400
I1005 10:19:47.049360  9385 layer_factory.hpp:77] Creating layer Scale19
I1005 10:19:47.049365  9385 net.cpp:84] Creating Layer Scale19
I1005 10:19:47.049367  9385 net.cpp:406] Scale19 <- Convolution19
I1005 10:19:47.049371  9385 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 10:19:47.049397  9385 layer_factory.hpp:77] Creating layer Scale19
I1005 10:19:47.049475  9385 net.cpp:122] Setting up Scale19
I1005 10:19:47.049479  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.049482  9385 net.cpp:137] Memory required for data: 313286800
I1005 10:19:47.049486  9385 layer_factory.hpp:77] Creating layer Eltwise8
I1005 10:19:47.049490  9385 net.cpp:84] Creating Layer Eltwise8
I1005 10:19:47.049494  9385 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1005 10:19:47.049496  9385 net.cpp:406] Eltwise8 <- Convolution19
I1005 10:19:47.049501  9385 net.cpp:380] Eltwise8 -> Eltwise8
I1005 10:19:47.049517  9385 net.cpp:122] Setting up Eltwise8
I1005 10:19:47.049521  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.049523  9385 net.cpp:137] Memory required for data: 314541200
I1005 10:19:47.049525  9385 layer_factory.hpp:77] Creating layer penlu17
I1005 10:19:47.049531  9385 net.cpp:84] Creating Layer penlu17
I1005 10:19:47.049535  9385 net.cpp:406] penlu17 <- Eltwise8
I1005 10:19:47.049538  9385 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1005 10:19:47.049656  9385 net.cpp:122] Setting up penlu17
I1005 10:19:47.049661  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.049671  9385 net.cpp:137] Memory required for data: 315795600
I1005 10:19:47.049687  9385 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1005 10:19:47.049692  9385 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1005 10:19:47.049695  9385 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1005 10:19:47.049698  9385 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1005 10:19:47.049703  9385 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1005 10:19:47.049727  9385 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1005 10:19:47.049732  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.049736  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.049737  9385 net.cpp:137] Memory required for data: 318304400
I1005 10:19:47.049739  9385 layer_factory.hpp:77] Creating layer Convolution20
I1005 10:19:47.049746  9385 net.cpp:84] Creating Layer Convolution20
I1005 10:19:47.049748  9385 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1005 10:19:47.049753  9385 net.cpp:380] Convolution20 -> Convolution20
I1005 10:19:47.051445  9385 net.cpp:122] Setting up Convolution20
I1005 10:19:47.051456  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.051460  9385 net.cpp:137] Memory required for data: 319558800
I1005 10:19:47.051465  9385 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 10:19:47.051471  9385 net.cpp:84] Creating Layer BatchNorm20
I1005 10:19:47.051475  9385 net.cpp:406] BatchNorm20 <- Convolution20
I1005 10:19:47.051478  9385 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 10:19:47.051610  9385 net.cpp:122] Setting up BatchNorm20
I1005 10:19:47.051615  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.051618  9385 net.cpp:137] Memory required for data: 320813200
I1005 10:19:47.051623  9385 layer_factory.hpp:77] Creating layer Scale20
I1005 10:19:47.051628  9385 net.cpp:84] Creating Layer Scale20
I1005 10:19:47.051631  9385 net.cpp:406] Scale20 <- Convolution20
I1005 10:19:47.051635  9385 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 10:19:47.051663  9385 layer_factory.hpp:77] Creating layer Scale20
I1005 10:19:47.051740  9385 net.cpp:122] Setting up Scale20
I1005 10:19:47.051745  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.051748  9385 net.cpp:137] Memory required for data: 322067600
I1005 10:19:47.051753  9385 layer_factory.hpp:77] Creating layer penlu18
I1005 10:19:47.051759  9385 net.cpp:84] Creating Layer penlu18
I1005 10:19:47.051762  9385 net.cpp:406] penlu18 <- Convolution20
I1005 10:19:47.051765  9385 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1005 10:19:47.051872  9385 net.cpp:122] Setting up penlu18
I1005 10:19:47.051875  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.051877  9385 net.cpp:137] Memory required for data: 323322000
I1005 10:19:47.051882  9385 layer_factory.hpp:77] Creating layer Convolution21
I1005 10:19:47.051889  9385 net.cpp:84] Creating Layer Convolution21
I1005 10:19:47.051892  9385 net.cpp:406] Convolution21 <- Convolution20
I1005 10:19:47.051895  9385 net.cpp:380] Convolution21 -> Convolution21
I1005 10:19:47.054177  9385 net.cpp:122] Setting up Convolution21
I1005 10:19:47.054185  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.054188  9385 net.cpp:137] Memory required for data: 324576400
I1005 10:19:47.054193  9385 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 10:19:47.054198  9385 net.cpp:84] Creating Layer BatchNorm21
I1005 10:19:47.054200  9385 net.cpp:406] BatchNorm21 <- Convolution21
I1005 10:19:47.054204  9385 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 10:19:47.054353  9385 net.cpp:122] Setting up BatchNorm21
I1005 10:19:47.054358  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.054360  9385 net.cpp:137] Memory required for data: 325830800
I1005 10:19:47.054365  9385 layer_factory.hpp:77] Creating layer Scale21
I1005 10:19:47.054369  9385 net.cpp:84] Creating Layer Scale21
I1005 10:19:47.054378  9385 net.cpp:406] Scale21 <- Convolution21
I1005 10:19:47.054383  9385 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 10:19:47.054414  9385 layer_factory.hpp:77] Creating layer Scale21
I1005 10:19:47.054496  9385 net.cpp:122] Setting up Scale21
I1005 10:19:47.054500  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.054502  9385 net.cpp:137] Memory required for data: 327085200
I1005 10:19:47.054507  9385 layer_factory.hpp:77] Creating layer Eltwise9
I1005 10:19:47.054512  9385 net.cpp:84] Creating Layer Eltwise9
I1005 10:19:47.054513  9385 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1005 10:19:47.054517  9385 net.cpp:406] Eltwise9 <- Convolution21
I1005 10:19:47.054523  9385 net.cpp:380] Eltwise9 -> Eltwise9
I1005 10:19:47.054543  9385 net.cpp:122] Setting up Eltwise9
I1005 10:19:47.054555  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.054558  9385 net.cpp:137] Memory required for data: 328339600
I1005 10:19:47.054559  9385 layer_factory.hpp:77] Creating layer penlu19
I1005 10:19:47.054564  9385 net.cpp:84] Creating Layer penlu19
I1005 10:19:47.054566  9385 net.cpp:406] penlu19 <- Eltwise9
I1005 10:19:47.054570  9385 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1005 10:19:47.054678  9385 net.cpp:122] Setting up penlu19
I1005 10:19:47.054682  9385 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 10:19:47.054684  9385 net.cpp:137] Memory required for data: 329594000
I1005 10:19:47.054688  9385 layer_factory.hpp:77] Creating layer Pooling1
I1005 10:19:47.054693  9385 net.cpp:84] Creating Layer Pooling1
I1005 10:19:47.054697  9385 net.cpp:406] Pooling1 <- Eltwise9
I1005 10:19:47.054699  9385 net.cpp:380] Pooling1 -> Pooling1
I1005 10:19:47.054853  9385 net.cpp:122] Setting up Pooling1
I1005 10:19:47.054859  9385 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 10:19:47.054862  9385 net.cpp:137] Memory required for data: 329619600
I1005 10:19:47.054864  9385 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 10:19:47.054872  9385 net.cpp:84] Creating Layer InnerProduct1
I1005 10:19:47.054875  9385 net.cpp:406] InnerProduct1 <- Pooling1
I1005 10:19:47.054879  9385 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 10:19:47.054971  9385 net.cpp:122] Setting up InnerProduct1
I1005 10:19:47.054976  9385 net.cpp:129] Top shape: 100 10 (1000)
I1005 10:19:47.054978  9385 net.cpp:137] Memory required for data: 329623600
I1005 10:19:47.054981  9385 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 10:19:47.054986  9385 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 10:19:47.054989  9385 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1005 10:19:47.054991  9385 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1005 10:19:47.054996  9385 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 10:19:47.055001  9385 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 10:19:47.055492  9385 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 10:19:47.055500  9385 net.cpp:129] Top shape: (1)
I1005 10:19:47.055503  9385 net.cpp:132]     with loss weight 1
I1005 10:19:47.055516  9385 net.cpp:137] Memory required for data: 329623604
I1005 10:19:47.055518  9385 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 10:19:47.055521  9385 net.cpp:198] InnerProduct1 needs backward computation.
I1005 10:19:47.055523  9385 net.cpp:198] Pooling1 needs backward computation.
I1005 10:19:47.055526  9385 net.cpp:198] penlu19 needs backward computation.
I1005 10:19:47.055527  9385 net.cpp:198] Eltwise9 needs backward computation.
I1005 10:19:47.055529  9385 net.cpp:198] Scale21 needs backward computation.
I1005 10:19:47.055531  9385 net.cpp:198] BatchNorm21 needs backward computation.
I1005 10:19:47.055533  9385 net.cpp:198] Convolution21 needs backward computation.
I1005 10:19:47.055536  9385 net.cpp:198] penlu18 needs backward computation.
I1005 10:19:47.055537  9385 net.cpp:198] Scale20 needs backward computation.
I1005 10:19:47.055539  9385 net.cpp:198] BatchNorm20 needs backward computation.
I1005 10:19:47.055541  9385 net.cpp:198] Convolution20 needs backward computation.
I1005 10:19:47.055549  9385 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1005 10:19:47.055552  9385 net.cpp:198] penlu17 needs backward computation.
I1005 10:19:47.055554  9385 net.cpp:198] Eltwise8 needs backward computation.
I1005 10:19:47.055557  9385 net.cpp:198] Scale19 needs backward computation.
I1005 10:19:47.055558  9385 net.cpp:198] BatchNorm19 needs backward computation.
I1005 10:19:47.055560  9385 net.cpp:198] Convolution19 needs backward computation.
I1005 10:19:47.055562  9385 net.cpp:198] penlu16 needs backward computation.
I1005 10:19:47.055564  9385 net.cpp:198] Scale18 needs backward computation.
I1005 10:19:47.055567  9385 net.cpp:198] BatchNorm18 needs backward computation.
I1005 10:19:47.055568  9385 net.cpp:198] Convolution18 needs backward computation.
I1005 10:19:47.055570  9385 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1005 10:19:47.055573  9385 net.cpp:198] penlu15 needs backward computation.
I1005 10:19:47.055575  9385 net.cpp:198] Eltwise7 needs backward computation.
I1005 10:19:47.055577  9385 net.cpp:198] Scale17 needs backward computation.
I1005 10:19:47.055583  9385 net.cpp:198] BatchNorm17 needs backward computation.
I1005 10:19:47.055584  9385 net.cpp:198] Convolution17 needs backward computation.
I1005 10:19:47.055586  9385 net.cpp:198] penlu14 needs backward computation.
I1005 10:19:47.055588  9385 net.cpp:198] Scale16 needs backward computation.
I1005 10:19:47.055590  9385 net.cpp:198] BatchNorm16 needs backward computation.
I1005 10:19:47.055593  9385 net.cpp:198] Convolution16 needs backward computation.
I1005 10:19:47.055595  9385 net.cpp:198] Scale15 needs backward computation.
I1005 10:19:47.055598  9385 net.cpp:198] BatchNorm15 needs backward computation.
I1005 10:19:47.055599  9385 net.cpp:198] Convolution15 needs backward computation.
I1005 10:19:47.055601  9385 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1005 10:19:47.055604  9385 net.cpp:198] penlu13 needs backward computation.
I1005 10:19:47.055606  9385 net.cpp:198] Eltwise6 needs backward computation.
I1005 10:19:47.055608  9385 net.cpp:198] Scale14 needs backward computation.
I1005 10:19:47.055611  9385 net.cpp:198] BatchNorm14 needs backward computation.
I1005 10:19:47.055613  9385 net.cpp:198] Convolution14 needs backward computation.
I1005 10:19:47.055615  9385 net.cpp:198] penlu12 needs backward computation.
I1005 10:19:47.055618  9385 net.cpp:198] Scale13 needs backward computation.
I1005 10:19:47.055619  9385 net.cpp:198] BatchNorm13 needs backward computation.
I1005 10:19:47.055621  9385 net.cpp:198] Convolution13 needs backward computation.
I1005 10:19:47.055625  9385 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1005 10:19:47.055627  9385 net.cpp:198] penlu11 needs backward computation.
I1005 10:19:47.055629  9385 net.cpp:198] Eltwise5 needs backward computation.
I1005 10:19:47.055632  9385 net.cpp:198] Scale12 needs backward computation.
I1005 10:19:47.055634  9385 net.cpp:198] BatchNorm12 needs backward computation.
I1005 10:19:47.055636  9385 net.cpp:198] Convolution12 needs backward computation.
I1005 10:19:47.055639  9385 net.cpp:198] penlu10 needs backward computation.
I1005 10:19:47.055640  9385 net.cpp:198] Scale11 needs backward computation.
I1005 10:19:47.055642  9385 net.cpp:198] BatchNorm11 needs backward computation.
I1005 10:19:47.055644  9385 net.cpp:198] Convolution11 needs backward computation.
I1005 10:19:47.055647  9385 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1005 10:19:47.055649  9385 net.cpp:198] penlu9 needs backward computation.
I1005 10:19:47.055651  9385 net.cpp:198] Eltwise4 needs backward computation.
I1005 10:19:47.055655  9385 net.cpp:198] Scale10 needs backward computation.
I1005 10:19:47.055656  9385 net.cpp:198] BatchNorm10 needs backward computation.
I1005 10:19:47.055658  9385 net.cpp:198] Convolution10 needs backward computation.
I1005 10:19:47.055661  9385 net.cpp:198] penlu8 needs backward computation.
I1005 10:19:47.055663  9385 net.cpp:198] Scale9 needs backward computation.
I1005 10:19:47.055668  9385 net.cpp:198] BatchNorm9 needs backward computation.
I1005 10:19:47.055671  9385 net.cpp:198] Convolution9 needs backward computation.
I1005 10:19:47.055673  9385 net.cpp:198] Scale8 needs backward computation.
I1005 10:19:47.055676  9385 net.cpp:198] BatchNorm8 needs backward computation.
I1005 10:19:47.055678  9385 net.cpp:198] Convolution8 needs backward computation.
I1005 10:19:47.055680  9385 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1005 10:19:47.055683  9385 net.cpp:198] penlu7 needs backward computation.
I1005 10:19:47.055685  9385 net.cpp:198] Eltwise3 needs backward computation.
I1005 10:19:47.055688  9385 net.cpp:198] Scale7 needs backward computation.
I1005 10:19:47.055691  9385 net.cpp:198] BatchNorm7 needs backward computation.
I1005 10:19:47.055692  9385 net.cpp:198] Convolution7 needs backward computation.
I1005 10:19:47.055694  9385 net.cpp:198] penlu6 needs backward computation.
I1005 10:19:47.055696  9385 net.cpp:198] Scale6 needs backward computation.
I1005 10:19:47.055698  9385 net.cpp:198] BatchNorm6 needs backward computation.
I1005 10:19:47.055701  9385 net.cpp:198] Convolution6 needs backward computation.
I1005 10:19:47.055703  9385 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1005 10:19:47.055706  9385 net.cpp:198] penlu5 needs backward computation.
I1005 10:19:47.055707  9385 net.cpp:198] Eltwise2 needs backward computation.
I1005 10:19:47.055711  9385 net.cpp:198] Scale5 needs backward computation.
I1005 10:19:47.055712  9385 net.cpp:198] BatchNorm5 needs backward computation.
I1005 10:19:47.055714  9385 net.cpp:198] Convolution5 needs backward computation.
I1005 10:19:47.055716  9385 net.cpp:198] penlu4 needs backward computation.
I1005 10:19:47.055719  9385 net.cpp:198] Scale4 needs backward computation.
I1005 10:19:47.055721  9385 net.cpp:198] BatchNorm4 needs backward computation.
I1005 10:19:47.055723  9385 net.cpp:198] Convolution4 needs backward computation.
I1005 10:19:47.055725  9385 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1005 10:19:47.055728  9385 net.cpp:198] penlu3 needs backward computation.
I1005 10:19:47.055730  9385 net.cpp:198] Eltwise1 needs backward computation.
I1005 10:19:47.055732  9385 net.cpp:198] Scale3 needs backward computation.
I1005 10:19:47.055734  9385 net.cpp:198] BatchNorm3 needs backward computation.
I1005 10:19:47.055737  9385 net.cpp:198] Convolution3 needs backward computation.
I1005 10:19:47.055739  9385 net.cpp:198] penlu2 needs backward computation.
I1005 10:19:47.055742  9385 net.cpp:198] Scale2 needs backward computation.
I1005 10:19:47.055743  9385 net.cpp:198] BatchNorm2 needs backward computation.
I1005 10:19:47.055747  9385 net.cpp:198] Convolution2 needs backward computation.
I1005 10:19:47.055748  9385 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1005 10:19:47.055752  9385 net.cpp:198] penlu1 needs backward computation.
I1005 10:19:47.055753  9385 net.cpp:198] Scale1 needs backward computation.
I1005 10:19:47.055755  9385 net.cpp:198] BatchNorm1 needs backward computation.
I1005 10:19:47.055757  9385 net.cpp:198] Convolution1 needs backward computation.
I1005 10:19:47.055760  9385 net.cpp:200] Data1 does not need backward computation.
I1005 10:19:47.055763  9385 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 10:19:47.055795  9385 net.cpp:255] Network initialization done.
I1005 10:19:47.057466  9385 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 10:19:47.057473  9385 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 10:19:47.057478  9385 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 10:19:47.057551  9385 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1005 10:19:47.058019  9385 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1005 10:19:47.058270  9385 layer_factory.hpp:77] Creating layer Data1
I1005 10:19:47.058310  9385 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1005 10:19:47.058320  9385 net.cpp:84] Creating Layer Data1
I1005 10:19:47.058323  9385 net.cpp:380] Data1 -> Data1
I1005 10:19:47.058329  9385 net.cpp:380] Data1 -> Data2
I1005 10:19:47.058334  9385 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 10:19:47.058444  9385 data_layer.cpp:45] output data size: 100,3,32,32
I1005 10:19:47.062279  9385 net.cpp:122] Setting up Data1
I1005 10:19:47.062299  9385 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 10:19:47.062304  9385 net.cpp:129] Top shape: 100 (100)
I1005 10:19:47.062305  9385 net.cpp:137] Memory required for data: 1229200
I1005 10:19:47.062310  9385 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1005 10:19:47.062319  9385 net.cpp:84] Creating Layer Data2_Data1_1_split
I1005 10:19:47.062321  9385 net.cpp:406] Data2_Data1_1_split <- Data2
I1005 10:19:47.062327  9385 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1005 10:19:47.062333  9385 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1005 10:19:47.062391  9385 net.cpp:122] Setting up Data2_Data1_1_split
I1005 10:19:47.062397  9385 net.cpp:129] Top shape: 100 (100)
I1005 10:19:47.062413  9385 net.cpp:129] Top shape: 100 (100)
I1005 10:19:47.062417  9385 net.cpp:137] Memory required for data: 1230000
I1005 10:19:47.062418  9385 layer_factory.hpp:77] Creating layer Convolution1
I1005 10:19:47.062428  9385 net.cpp:84] Creating Layer Convolution1
I1005 10:19:47.062430  9385 net.cpp:406] Convolution1 <- Data1
I1005 10:19:47.062435  9385 net.cpp:380] Convolution1 -> Convolution1
I1005 10:19:47.063573  9385 net.cpp:122] Setting up Convolution1
I1005 10:19:47.063583  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.063586  9385 net.cpp:137] Memory required for data: 7783600
I1005 10:19:47.063593  9385 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 10:19:47.063599  9385 net.cpp:84] Creating Layer BatchNorm1
I1005 10:19:47.063607  9385 net.cpp:406] BatchNorm1 <- Convolution1
I1005 10:19:47.063611  9385 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 10:19:47.063748  9385 net.cpp:122] Setting up BatchNorm1
I1005 10:19:47.063753  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.063755  9385 net.cpp:137] Memory required for data: 14337200
I1005 10:19:47.063762  9385 layer_factory.hpp:77] Creating layer Scale1
I1005 10:19:47.063768  9385 net.cpp:84] Creating Layer Scale1
I1005 10:19:47.063772  9385 net.cpp:406] Scale1 <- Convolution1
I1005 10:19:47.063776  9385 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 10:19:47.063804  9385 layer_factory.hpp:77] Creating layer Scale1
I1005 10:19:47.063884  9385 net.cpp:122] Setting up Scale1
I1005 10:19:47.063889  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.063890  9385 net.cpp:137] Memory required for data: 20890800
I1005 10:19:47.063894  9385 layer_factory.hpp:77] Creating layer penlu1
I1005 10:19:47.063900  9385 net.cpp:84] Creating Layer penlu1
I1005 10:19:47.063904  9385 net.cpp:406] penlu1 <- Convolution1
I1005 10:19:47.063906  9385 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1005 10:19:47.064024  9385 net.cpp:122] Setting up penlu1
I1005 10:19:47.064028  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.064030  9385 net.cpp:137] Memory required for data: 27444400
I1005 10:19:47.064038  9385 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1005 10:19:47.064044  9385 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1005 10:19:47.064049  9385 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1005 10:19:47.064051  9385 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1005 10:19:47.064055  9385 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1005 10:19:47.064079  9385 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1005 10:19:47.064083  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.064086  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.064088  9385 net.cpp:137] Memory required for data: 40551600
I1005 10:19:47.064090  9385 layer_factory.hpp:77] Creating layer Convolution2
I1005 10:19:47.064096  9385 net.cpp:84] Creating Layer Convolution2
I1005 10:19:47.064098  9385 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1005 10:19:47.064103  9385 net.cpp:380] Convolution2 -> Convolution2
I1005 10:19:47.064693  9385 net.cpp:122] Setting up Convolution2
I1005 10:19:47.064700  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.064703  9385 net.cpp:137] Memory required for data: 47105200
I1005 10:19:47.064707  9385 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 10:19:47.064714  9385 net.cpp:84] Creating Layer BatchNorm2
I1005 10:19:47.064716  9385 net.cpp:406] BatchNorm2 <- Convolution2
I1005 10:19:47.064720  9385 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 10:19:47.064865  9385 net.cpp:122] Setting up BatchNorm2
I1005 10:19:47.064872  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.064873  9385 net.cpp:137] Memory required for data: 53658800
I1005 10:19:47.064878  9385 layer_factory.hpp:77] Creating layer Scale2
I1005 10:19:47.064883  9385 net.cpp:84] Creating Layer Scale2
I1005 10:19:47.064893  9385 net.cpp:406] Scale2 <- Convolution2
I1005 10:19:47.064898  9385 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 10:19:47.065006  9385 layer_factory.hpp:77] Creating layer Scale2
I1005 10:19:47.065083  9385 net.cpp:122] Setting up Scale2
I1005 10:19:47.065089  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.065091  9385 net.cpp:137] Memory required for data: 60212400
I1005 10:19:47.065098  9385 layer_factory.hpp:77] Creating layer penlu2
I1005 10:19:47.065104  9385 net.cpp:84] Creating Layer penlu2
I1005 10:19:47.065105  9385 net.cpp:406] penlu2 <- Convolution2
I1005 10:19:47.065110  9385 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1005 10:19:47.065224  9385 net.cpp:122] Setting up penlu2
I1005 10:19:47.065230  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.065232  9385 net.cpp:137] Memory required for data: 66766000
I1005 10:19:47.065237  9385 layer_factory.hpp:77] Creating layer Convolution3
I1005 10:19:47.065243  9385 net.cpp:84] Creating Layer Convolution3
I1005 10:19:47.065245  9385 net.cpp:406] Convolution3 <- Convolution2
I1005 10:19:47.065250  9385 net.cpp:380] Convolution3 -> Convolution3
I1005 10:19:47.066175  9385 net.cpp:122] Setting up Convolution3
I1005 10:19:47.066184  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.066187  9385 net.cpp:137] Memory required for data: 73319600
I1005 10:19:47.066191  9385 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 10:19:47.066198  9385 net.cpp:84] Creating Layer BatchNorm3
I1005 10:19:47.066200  9385 net.cpp:406] BatchNorm3 <- Convolution3
I1005 10:19:47.066205  9385 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 10:19:47.066468  9385 net.cpp:122] Setting up BatchNorm3
I1005 10:19:47.066474  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.066476  9385 net.cpp:137] Memory required for data: 79873200
I1005 10:19:47.066481  9385 layer_factory.hpp:77] Creating layer Scale3
I1005 10:19:47.066485  9385 net.cpp:84] Creating Layer Scale3
I1005 10:19:47.066493  9385 net.cpp:406] Scale3 <- Convolution3
I1005 10:19:47.066498  9385 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 10:19:47.066537  9385 layer_factory.hpp:77] Creating layer Scale3
I1005 10:19:47.066614  9385 net.cpp:122] Setting up Scale3
I1005 10:19:47.066619  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.066622  9385 net.cpp:137] Memory required for data: 86426800
I1005 10:19:47.066625  9385 layer_factory.hpp:77] Creating layer Eltwise1
I1005 10:19:47.066630  9385 net.cpp:84] Creating Layer Eltwise1
I1005 10:19:47.066632  9385 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1005 10:19:47.066637  9385 net.cpp:406] Eltwise1 <- Convolution3
I1005 10:19:47.066642  9385 net.cpp:380] Eltwise1 -> Eltwise1
I1005 10:19:47.066658  9385 net.cpp:122] Setting up Eltwise1
I1005 10:19:47.066661  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.066663  9385 net.cpp:137] Memory required for data: 92980400
I1005 10:19:47.066665  9385 layer_factory.hpp:77] Creating layer penlu3
I1005 10:19:47.066671  9385 net.cpp:84] Creating Layer penlu3
I1005 10:19:47.066673  9385 net.cpp:406] penlu3 <- Eltwise1
I1005 10:19:47.066678  9385 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1005 10:19:47.066792  9385 net.cpp:122] Setting up penlu3
I1005 10:19:47.066797  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.066799  9385 net.cpp:137] Memory required for data: 99534000
I1005 10:19:47.066803  9385 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1005 10:19:47.066808  9385 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1005 10:19:47.066810  9385 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1005 10:19:47.066814  9385 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1005 10:19:47.066818  9385 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1005 10:19:47.066840  9385 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1005 10:19:47.066844  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.066856  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.066859  9385 net.cpp:137] Memory required for data: 112641200
I1005 10:19:47.066861  9385 layer_factory.hpp:77] Creating layer Convolution4
I1005 10:19:47.066872  9385 net.cpp:84] Creating Layer Convolution4
I1005 10:19:47.066875  9385 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1005 10:19:47.066879  9385 net.cpp:380] Convolution4 -> Convolution4
I1005 10:19:47.067934  9385 net.cpp:122] Setting up Convolution4
I1005 10:19:47.067942  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.067945  9385 net.cpp:137] Memory required for data: 119194800
I1005 10:19:47.067950  9385 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 10:19:47.067957  9385 net.cpp:84] Creating Layer BatchNorm4
I1005 10:19:47.067960  9385 net.cpp:406] BatchNorm4 <- Convolution4
I1005 10:19:47.067963  9385 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 10:19:47.068100  9385 net.cpp:122] Setting up BatchNorm4
I1005 10:19:47.068105  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.068107  9385 net.cpp:137] Memory required for data: 125748400
I1005 10:19:47.068115  9385 layer_factory.hpp:77] Creating layer Scale4
I1005 10:19:47.068120  9385 net.cpp:84] Creating Layer Scale4
I1005 10:19:47.068122  9385 net.cpp:406] Scale4 <- Convolution4
I1005 10:19:47.068126  9385 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 10:19:47.068153  9385 layer_factory.hpp:77] Creating layer Scale4
I1005 10:19:47.068235  9385 net.cpp:122] Setting up Scale4
I1005 10:19:47.068239  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.068241  9385 net.cpp:137] Memory required for data: 132302000
I1005 10:19:47.068245  9385 layer_factory.hpp:77] Creating layer penlu4
I1005 10:19:47.068251  9385 net.cpp:84] Creating Layer penlu4
I1005 10:19:47.068253  9385 net.cpp:406] penlu4 <- Convolution4
I1005 10:19:47.068262  9385 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1005 10:19:47.068378  9385 net.cpp:122] Setting up penlu4
I1005 10:19:47.068382  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.068385  9385 net.cpp:137] Memory required for data: 138855600
I1005 10:19:47.068389  9385 layer_factory.hpp:77] Creating layer Convolution5
I1005 10:19:47.068397  9385 net.cpp:84] Creating Layer Convolution5
I1005 10:19:47.068398  9385 net.cpp:406] Convolution5 <- Convolution4
I1005 10:19:47.068403  9385 net.cpp:380] Convolution5 -> Convolution5
I1005 10:19:47.069654  9385 net.cpp:122] Setting up Convolution5
I1005 10:19:47.069664  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.069667  9385 net.cpp:137] Memory required for data: 145409200
I1005 10:19:47.069671  9385 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 10:19:47.069677  9385 net.cpp:84] Creating Layer BatchNorm5
I1005 10:19:47.069679  9385 net.cpp:406] BatchNorm5 <- Convolution5
I1005 10:19:47.069684  9385 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 10:19:47.069823  9385 net.cpp:122] Setting up BatchNorm5
I1005 10:19:47.069828  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.069830  9385 net.cpp:137] Memory required for data: 151962800
I1005 10:19:47.069834  9385 layer_factory.hpp:77] Creating layer Scale5
I1005 10:19:47.069839  9385 net.cpp:84] Creating Layer Scale5
I1005 10:19:47.069842  9385 net.cpp:406] Scale5 <- Convolution5
I1005 10:19:47.069845  9385 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 10:19:47.069872  9385 layer_factory.hpp:77] Creating layer Scale5
I1005 10:19:47.069952  9385 net.cpp:122] Setting up Scale5
I1005 10:19:47.069957  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.069959  9385 net.cpp:137] Memory required for data: 158516400
I1005 10:19:47.069963  9385 layer_factory.hpp:77] Creating layer Eltwise2
I1005 10:19:47.069967  9385 net.cpp:84] Creating Layer Eltwise2
I1005 10:19:47.069970  9385 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1005 10:19:47.069973  9385 net.cpp:406] Eltwise2 <- Convolution5
I1005 10:19:47.069977  9385 net.cpp:380] Eltwise2 -> Eltwise2
I1005 10:19:47.070000  9385 net.cpp:122] Setting up Eltwise2
I1005 10:19:47.070005  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.070008  9385 net.cpp:137] Memory required for data: 165070000
I1005 10:19:47.070009  9385 layer_factory.hpp:77] Creating layer penlu5
I1005 10:19:47.070015  9385 net.cpp:84] Creating Layer penlu5
I1005 10:19:47.070017  9385 net.cpp:406] penlu5 <- Eltwise2
I1005 10:19:47.070021  9385 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1005 10:19:47.070137  9385 net.cpp:122] Setting up penlu5
I1005 10:19:47.070142  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.070143  9385 net.cpp:137] Memory required for data: 171623600
I1005 10:19:47.070147  9385 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1005 10:19:47.070152  9385 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1005 10:19:47.070153  9385 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1005 10:19:47.070156  9385 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1005 10:19:47.070160  9385 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1005 10:19:47.070184  9385 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1005 10:19:47.070188  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.070191  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.070194  9385 net.cpp:137] Memory required for data: 184730800
I1005 10:19:47.070196  9385 layer_factory.hpp:77] Creating layer Convolution6
I1005 10:19:47.070202  9385 net.cpp:84] Creating Layer Convolution6
I1005 10:19:47.070204  9385 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1005 10:19:47.070209  9385 net.cpp:380] Convolution6 -> Convolution6
I1005 10:19:47.071142  9385 net.cpp:122] Setting up Convolution6
I1005 10:19:47.071151  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.071154  9385 net.cpp:137] Memory required for data: 191284400
I1005 10:19:47.071158  9385 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 10:19:47.071163  9385 net.cpp:84] Creating Layer BatchNorm6
I1005 10:19:47.071166  9385 net.cpp:406] BatchNorm6 <- Convolution6
I1005 10:19:47.071171  9385 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 10:19:47.071317  9385 net.cpp:122] Setting up BatchNorm6
I1005 10:19:47.071322  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.071324  9385 net.cpp:137] Memory required for data: 197838000
I1005 10:19:47.071329  9385 layer_factory.hpp:77] Creating layer Scale6
I1005 10:19:47.071342  9385 net.cpp:84] Creating Layer Scale6
I1005 10:19:47.071346  9385 net.cpp:406] Scale6 <- Convolution6
I1005 10:19:47.071348  9385 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 10:19:47.071375  9385 layer_factory.hpp:77] Creating layer Scale6
I1005 10:19:47.071450  9385 net.cpp:122] Setting up Scale6
I1005 10:19:47.071455  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.071456  9385 net.cpp:137] Memory required for data: 204391600
I1005 10:19:47.071460  9385 layer_factory.hpp:77] Creating layer penlu6
I1005 10:19:47.071465  9385 net.cpp:84] Creating Layer penlu6
I1005 10:19:47.071468  9385 net.cpp:406] penlu6 <- Convolution6
I1005 10:19:47.071471  9385 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1005 10:19:47.071589  9385 net.cpp:122] Setting up penlu6
I1005 10:19:47.071593  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.071595  9385 net.cpp:137] Memory required for data: 210945200
I1005 10:19:47.071600  9385 layer_factory.hpp:77] Creating layer Convolution7
I1005 10:19:47.071607  9385 net.cpp:84] Creating Layer Convolution7
I1005 10:19:47.071609  9385 net.cpp:406] Convolution7 <- Convolution6
I1005 10:19:47.071614  9385 net.cpp:380] Convolution7 -> Convolution7
I1005 10:19:47.072535  9385 net.cpp:122] Setting up Convolution7
I1005 10:19:47.072544  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.072546  9385 net.cpp:137] Memory required for data: 217498800
I1005 10:19:47.072552  9385 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 10:19:47.072566  9385 net.cpp:84] Creating Layer BatchNorm7
I1005 10:19:47.072569  9385 net.cpp:406] BatchNorm7 <- Convolution7
I1005 10:19:47.072573  9385 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 10:19:47.072712  9385 net.cpp:122] Setting up BatchNorm7
I1005 10:19:47.072717  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.072720  9385 net.cpp:137] Memory required for data: 224052400
I1005 10:19:47.072729  9385 layer_factory.hpp:77] Creating layer Scale7
I1005 10:19:47.072734  9385 net.cpp:84] Creating Layer Scale7
I1005 10:19:47.072736  9385 net.cpp:406] Scale7 <- Convolution7
I1005 10:19:47.072741  9385 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 10:19:47.072769  9385 layer_factory.hpp:77] Creating layer Scale7
I1005 10:19:47.072845  9385 net.cpp:122] Setting up Scale7
I1005 10:19:47.072850  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.072852  9385 net.cpp:137] Memory required for data: 230606000
I1005 10:19:47.072856  9385 layer_factory.hpp:77] Creating layer Eltwise3
I1005 10:19:47.072860  9385 net.cpp:84] Creating Layer Eltwise3
I1005 10:19:47.072862  9385 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1005 10:19:47.072865  9385 net.cpp:406] Eltwise3 <- Convolution7
I1005 10:19:47.072870  9385 net.cpp:380] Eltwise3 -> Eltwise3
I1005 10:19:47.072885  9385 net.cpp:122] Setting up Eltwise3
I1005 10:19:47.072888  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.072890  9385 net.cpp:137] Memory required for data: 237159600
I1005 10:19:47.072892  9385 layer_factory.hpp:77] Creating layer penlu7
I1005 10:19:47.072896  9385 net.cpp:84] Creating Layer penlu7
I1005 10:19:47.072898  9385 net.cpp:406] penlu7 <- Eltwise3
I1005 10:19:47.072902  9385 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1005 10:19:47.073019  9385 net.cpp:122] Setting up penlu7
I1005 10:19:47.073024  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.073025  9385 net.cpp:137] Memory required for data: 243713200
I1005 10:19:47.073030  9385 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1005 10:19:47.073034  9385 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1005 10:19:47.073036  9385 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1005 10:19:47.073040  9385 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1005 10:19:47.073043  9385 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1005 10:19:47.073067  9385 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1005 10:19:47.073071  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.073073  9385 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 10:19:47.073076  9385 net.cpp:137] Memory required for data: 256820400
I1005 10:19:47.073078  9385 layer_factory.hpp:77] Creating layer Convolution8
I1005 10:19:47.073084  9385 net.cpp:84] Creating Layer Convolution8
I1005 10:19:47.073087  9385 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1005 10:19:47.073091  9385 net.cpp:380] Convolution8 -> Convolution8
I1005 10:19:47.073985  9385 net.cpp:122] Setting up Convolution8
I1005 10:19:47.073994  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.073997  9385 net.cpp:137] Memory required for data: 260097200
I1005 10:19:47.074002  9385 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 10:19:47.074007  9385 net.cpp:84] Creating Layer BatchNorm8
I1005 10:19:47.074009  9385 net.cpp:406] BatchNorm8 <- Convolution8
I1005 10:19:47.074013  9385 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 10:19:47.074147  9385 net.cpp:122] Setting up BatchNorm8
I1005 10:19:47.074151  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.074154  9385 net.cpp:137] Memory required for data: 263374000
I1005 10:19:47.074158  9385 layer_factory.hpp:77] Creating layer Scale8
I1005 10:19:47.074162  9385 net.cpp:84] Creating Layer Scale8
I1005 10:19:47.076923  9385 net.cpp:406] Scale8 <- Convolution8
I1005 10:19:47.076930  9385 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 10:19:47.076972  9385 layer_factory.hpp:77] Creating layer Scale8
I1005 10:19:47.077069  9385 net.cpp:122] Setting up Scale8
I1005 10:19:47.077075  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.077076  9385 net.cpp:137] Memory required for data: 266650800
I1005 10:19:47.077081  9385 layer_factory.hpp:77] Creating layer Convolution9
I1005 10:19:47.077088  9385 net.cpp:84] Creating Layer Convolution9
I1005 10:19:47.077091  9385 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1005 10:19:47.077096  9385 net.cpp:380] Convolution9 -> Convolution9
I1005 10:19:47.078146  9385 net.cpp:122] Setting up Convolution9
I1005 10:19:47.078156  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.078160  9385 net.cpp:137] Memory required for data: 269927600
I1005 10:19:47.078163  9385 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 10:19:47.078169  9385 net.cpp:84] Creating Layer BatchNorm9
I1005 10:19:47.078172  9385 net.cpp:406] BatchNorm9 <- Convolution9
I1005 10:19:47.078176  9385 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 10:19:47.078362  9385 net.cpp:122] Setting up BatchNorm9
I1005 10:19:47.078372  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.078377  9385 net.cpp:137] Memory required for data: 273204400
I1005 10:19:47.078384  9385 layer_factory.hpp:77] Creating layer Scale9
I1005 10:19:47.078392  9385 net.cpp:84] Creating Layer Scale9
I1005 10:19:47.078397  9385 net.cpp:406] Scale9 <- Convolution9
I1005 10:19:47.078402  9385 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 10:19:47.078444  9385 layer_factory.hpp:77] Creating layer Scale9
I1005 10:19:47.078613  9385 net.cpp:122] Setting up Scale9
I1005 10:19:47.078621  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.078624  9385 net.cpp:137] Memory required for data: 276481200
I1005 10:19:47.078629  9385 layer_factory.hpp:77] Creating layer penlu8
I1005 10:19:47.078635  9385 net.cpp:84] Creating Layer penlu8
I1005 10:19:47.078639  9385 net.cpp:406] penlu8 <- Convolution9
I1005 10:19:47.078642  9385 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1005 10:19:47.078838  9385 net.cpp:122] Setting up penlu8
I1005 10:19:47.078856  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.078860  9385 net.cpp:137] Memory required for data: 279758000
I1005 10:19:47.078863  9385 layer_factory.hpp:77] Creating layer Convolution10
I1005 10:19:47.078871  9385 net.cpp:84] Creating Layer Convolution10
I1005 10:19:47.078874  9385 net.cpp:406] Convolution10 <- Convolution9
I1005 10:19:47.078878  9385 net.cpp:380] Convolution10 -> Convolution10
I1005 10:19:47.080019  9385 net.cpp:122] Setting up Convolution10
I1005 10:19:47.080029  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.080030  9385 net.cpp:137] Memory required for data: 283034800
I1005 10:19:47.080035  9385 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 10:19:47.080039  9385 net.cpp:84] Creating Layer BatchNorm10
I1005 10:19:47.080042  9385 net.cpp:406] BatchNorm10 <- Convolution10
I1005 10:19:47.080046  9385 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 10:19:47.080180  9385 net.cpp:122] Setting up BatchNorm10
I1005 10:19:47.080185  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.080188  9385 net.cpp:137] Memory required for data: 286311600
I1005 10:19:47.080193  9385 layer_factory.hpp:77] Creating layer Scale10
I1005 10:19:47.080205  9385 net.cpp:84] Creating Layer Scale10
I1005 10:19:47.080209  9385 net.cpp:406] Scale10 <- Convolution10
I1005 10:19:47.080211  9385 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 10:19:47.080250  9385 layer_factory.hpp:77] Creating layer Scale10
I1005 10:19:47.080368  9385 net.cpp:122] Setting up Scale10
I1005 10:19:47.080374  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.080375  9385 net.cpp:137] Memory required for data: 289588400
I1005 10:19:47.080379  9385 layer_factory.hpp:77] Creating layer Eltwise4
I1005 10:19:47.080384  9385 net.cpp:84] Creating Layer Eltwise4
I1005 10:19:47.080395  9385 net.cpp:406] Eltwise4 <- Convolution8
I1005 10:19:47.080399  9385 net.cpp:406] Eltwise4 <- Convolution10
I1005 10:19:47.080410  9385 net.cpp:380] Eltwise4 -> Eltwise4
I1005 10:19:47.080425  9385 net.cpp:122] Setting up Eltwise4
I1005 10:19:47.080428  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.080430  9385 net.cpp:137] Memory required for data: 292865200
I1005 10:19:47.080433  9385 layer_factory.hpp:77] Creating layer penlu9
I1005 10:19:47.080438  9385 net.cpp:84] Creating Layer penlu9
I1005 10:19:47.080441  9385 net.cpp:406] penlu9 <- Eltwise4
I1005 10:19:47.080446  9385 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1005 10:19:47.080561  9385 net.cpp:122] Setting up penlu9
I1005 10:19:47.080566  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.080569  9385 net.cpp:137] Memory required for data: 296142000
I1005 10:19:47.080572  9385 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1005 10:19:47.080576  9385 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1005 10:19:47.080579  9385 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1005 10:19:47.080582  9385 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1005 10:19:47.080586  9385 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1005 10:19:47.080610  9385 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1005 10:19:47.080612  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.080615  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.080617  9385 net.cpp:137] Memory required for data: 302695600
I1005 10:19:47.080620  9385 layer_factory.hpp:77] Creating layer Convolution11
I1005 10:19:47.080626  9385 net.cpp:84] Creating Layer Convolution11
I1005 10:19:47.080628  9385 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1005 10:19:47.080632  9385 net.cpp:380] Convolution11 -> Convolution11
I1005 10:19:47.081749  9385 net.cpp:122] Setting up Convolution11
I1005 10:19:47.081758  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.081761  9385 net.cpp:137] Memory required for data: 305972400
I1005 10:19:47.081765  9385 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 10:19:47.081770  9385 net.cpp:84] Creating Layer BatchNorm11
I1005 10:19:47.081773  9385 net.cpp:406] BatchNorm11 <- Convolution11
I1005 10:19:47.081778  9385 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 10:19:47.081909  9385 net.cpp:122] Setting up BatchNorm11
I1005 10:19:47.081914  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.081917  9385 net.cpp:137] Memory required for data: 309249200
I1005 10:19:47.081921  9385 layer_factory.hpp:77] Creating layer Scale11
I1005 10:19:47.081925  9385 net.cpp:84] Creating Layer Scale11
I1005 10:19:47.081928  9385 net.cpp:406] Scale11 <- Convolution11
I1005 10:19:47.081931  9385 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 10:19:47.081959  9385 layer_factory.hpp:77] Creating layer Scale11
I1005 10:19:47.082033  9385 net.cpp:122] Setting up Scale11
I1005 10:19:47.082037  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.082039  9385 net.cpp:137] Memory required for data: 312526000
I1005 10:19:47.082043  9385 layer_factory.hpp:77] Creating layer penlu10
I1005 10:19:47.082048  9385 net.cpp:84] Creating Layer penlu10
I1005 10:19:47.082051  9385 net.cpp:406] penlu10 <- Convolution11
I1005 10:19:47.082054  9385 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1005 10:19:47.082162  9385 net.cpp:122] Setting up penlu10
I1005 10:19:47.082166  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.082168  9385 net.cpp:137] Memory required for data: 315802800
I1005 10:19:47.082173  9385 layer_factory.hpp:77] Creating layer Convolution12
I1005 10:19:47.082180  9385 net.cpp:84] Creating Layer Convolution12
I1005 10:19:47.082183  9385 net.cpp:406] Convolution12 <- Convolution11
I1005 10:19:47.082188  9385 net.cpp:380] Convolution12 -> Convolution12
I1005 10:19:47.082943  9385 net.cpp:122] Setting up Convolution12
I1005 10:19:47.082950  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.082953  9385 net.cpp:137] Memory required for data: 319079600
I1005 10:19:47.082964  9385 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 10:19:47.082969  9385 net.cpp:84] Creating Layer BatchNorm12
I1005 10:19:47.082973  9385 net.cpp:406] BatchNorm12 <- Convolution12
I1005 10:19:47.082975  9385 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 10:19:47.083111  9385 net.cpp:122] Setting up BatchNorm12
I1005 10:19:47.083114  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.083117  9385 net.cpp:137] Memory required for data: 322356400
I1005 10:19:47.083122  9385 layer_factory.hpp:77] Creating layer Scale12
I1005 10:19:47.083124  9385 net.cpp:84] Creating Layer Scale12
I1005 10:19:47.083127  9385 net.cpp:406] Scale12 <- Convolution12
I1005 10:19:47.083130  9385 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 10:19:47.083156  9385 layer_factory.hpp:77] Creating layer Scale12
I1005 10:19:47.083232  9385 net.cpp:122] Setting up Scale12
I1005 10:19:47.083236  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.083238  9385 net.cpp:137] Memory required for data: 325633200
I1005 10:19:47.083242  9385 layer_factory.hpp:77] Creating layer Eltwise5
I1005 10:19:47.083246  9385 net.cpp:84] Creating Layer Eltwise5
I1005 10:19:47.083248  9385 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1005 10:19:47.083251  9385 net.cpp:406] Eltwise5 <- Convolution12
I1005 10:19:47.083254  9385 net.cpp:380] Eltwise5 -> Eltwise5
I1005 10:19:47.083267  9385 net.cpp:122] Setting up Eltwise5
I1005 10:19:47.083271  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.083272  9385 net.cpp:137] Memory required for data: 328910000
I1005 10:19:47.083274  9385 layer_factory.hpp:77] Creating layer penlu11
I1005 10:19:47.083281  9385 net.cpp:84] Creating Layer penlu11
I1005 10:19:47.083282  9385 net.cpp:406] penlu11 <- Eltwise5
I1005 10:19:47.083286  9385 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1005 10:19:47.083397  9385 net.cpp:122] Setting up penlu11
I1005 10:19:47.083402  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.083405  9385 net.cpp:137] Memory required for data: 332186800
I1005 10:19:47.083408  9385 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1005 10:19:47.083411  9385 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1005 10:19:47.083415  9385 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1005 10:19:47.083418  9385 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1005 10:19:47.083422  9385 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1005 10:19:47.083448  9385 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1005 10:19:47.083452  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.083456  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.083457  9385 net.cpp:137] Memory required for data: 338740400
I1005 10:19:47.083459  9385 layer_factory.hpp:77] Creating layer Convolution13
I1005 10:19:47.083464  9385 net.cpp:84] Creating Layer Convolution13
I1005 10:19:47.083467  9385 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1005 10:19:47.083472  9385 net.cpp:380] Convolution13 -> Convolution13
I1005 10:19:47.084517  9385 net.cpp:122] Setting up Convolution13
I1005 10:19:47.084524  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.084527  9385 net.cpp:137] Memory required for data: 342017200
I1005 10:19:47.084532  9385 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 10:19:47.084537  9385 net.cpp:84] Creating Layer BatchNorm13
I1005 10:19:47.084540  9385 net.cpp:406] BatchNorm13 <- Convolution13
I1005 10:19:47.084544  9385 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 10:19:47.084677  9385 net.cpp:122] Setting up BatchNorm13
I1005 10:19:47.084681  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.084684  9385 net.cpp:137] Memory required for data: 345294000
I1005 10:19:47.084688  9385 layer_factory.hpp:77] Creating layer Scale13
I1005 10:19:47.084692  9385 net.cpp:84] Creating Layer Scale13
I1005 10:19:47.084694  9385 net.cpp:406] Scale13 <- Convolution13
I1005 10:19:47.084704  9385 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 10:19:47.084733  9385 layer_factory.hpp:77] Creating layer Scale13
I1005 10:19:47.084811  9385 net.cpp:122] Setting up Scale13
I1005 10:19:47.084816  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.084818  9385 net.cpp:137] Memory required for data: 348570800
I1005 10:19:47.084821  9385 layer_factory.hpp:77] Creating layer penlu12
I1005 10:19:47.084827  9385 net.cpp:84] Creating Layer penlu12
I1005 10:19:47.084830  9385 net.cpp:406] penlu12 <- Convolution13
I1005 10:19:47.084833  9385 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1005 10:19:47.084941  9385 net.cpp:122] Setting up penlu12
I1005 10:19:47.084945  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.084947  9385 net.cpp:137] Memory required for data: 351847600
I1005 10:19:47.084951  9385 layer_factory.hpp:77] Creating layer Convolution14
I1005 10:19:47.084961  9385 net.cpp:84] Creating Layer Convolution14
I1005 10:19:47.084964  9385 net.cpp:406] Convolution14 <- Convolution13
I1005 10:19:47.084969  9385 net.cpp:380] Convolution14 -> Convolution14
I1005 10:19:47.086019  9385 net.cpp:122] Setting up Convolution14
I1005 10:19:47.086026  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.086030  9385 net.cpp:137] Memory required for data: 355124400
I1005 10:19:47.086045  9385 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 10:19:47.086050  9385 net.cpp:84] Creating Layer BatchNorm14
I1005 10:19:47.086052  9385 net.cpp:406] BatchNorm14 <- Convolution14
I1005 10:19:47.086056  9385 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 10:19:47.086189  9385 net.cpp:122] Setting up BatchNorm14
I1005 10:19:47.086195  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.086197  9385 net.cpp:137] Memory required for data: 358401200
I1005 10:19:47.086202  9385 layer_factory.hpp:77] Creating layer Scale14
I1005 10:19:47.086205  9385 net.cpp:84] Creating Layer Scale14
I1005 10:19:47.086208  9385 net.cpp:406] Scale14 <- Convolution14
I1005 10:19:47.086211  9385 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 10:19:47.086238  9385 layer_factory.hpp:77] Creating layer Scale14
I1005 10:19:47.086313  9385 net.cpp:122] Setting up Scale14
I1005 10:19:47.086318  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.086320  9385 net.cpp:137] Memory required for data: 361678000
I1005 10:19:47.086324  9385 layer_factory.hpp:77] Creating layer Eltwise6
I1005 10:19:47.086328  9385 net.cpp:84] Creating Layer Eltwise6
I1005 10:19:47.086330  9385 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1005 10:19:47.086333  9385 net.cpp:406] Eltwise6 <- Convolution14
I1005 10:19:47.086336  9385 net.cpp:380] Eltwise6 -> Eltwise6
I1005 10:19:47.086349  9385 net.cpp:122] Setting up Eltwise6
I1005 10:19:47.086352  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.086354  9385 net.cpp:137] Memory required for data: 364954800
I1005 10:19:47.086356  9385 layer_factory.hpp:77] Creating layer penlu13
I1005 10:19:47.086361  9385 net.cpp:84] Creating Layer penlu13
I1005 10:19:47.086364  9385 net.cpp:406] penlu13 <- Eltwise6
I1005 10:19:47.086367  9385 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1005 10:19:47.086480  9385 net.cpp:122] Setting up penlu13
I1005 10:19:47.086484  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.086486  9385 net.cpp:137] Memory required for data: 368231600
I1005 10:19:47.086490  9385 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1005 10:19:47.086494  9385 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1005 10:19:47.086496  9385 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1005 10:19:47.086500  9385 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1005 10:19:47.107406  9385 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1005 10:19:47.107450  9385 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1005 10:19:47.107455  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.107467  9385 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 10:19:47.107470  9385 net.cpp:137] Memory required for data: 374785200
I1005 10:19:47.107472  9385 layer_factory.hpp:77] Creating layer Convolution15
I1005 10:19:47.107483  9385 net.cpp:84] Creating Layer Convolution15
I1005 10:19:47.107486  9385 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1005 10:19:47.107491  9385 net.cpp:380] Convolution15 -> Convolution15
I1005 10:19:47.108521  9385 net.cpp:122] Setting up Convolution15
I1005 10:19:47.108530  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.108533  9385 net.cpp:137] Memory required for data: 376423600
I1005 10:19:47.108538  9385 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 10:19:47.108544  9385 net.cpp:84] Creating Layer BatchNorm15
I1005 10:19:47.108547  9385 net.cpp:406] BatchNorm15 <- Convolution15
I1005 10:19:47.108551  9385 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 10:19:47.108754  9385 net.cpp:122] Setting up BatchNorm15
I1005 10:19:47.108767  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.108772  9385 net.cpp:137] Memory required for data: 378062000
I1005 10:19:47.108788  9385 layer_factory.hpp:77] Creating layer Scale15
I1005 10:19:47.108795  9385 net.cpp:84] Creating Layer Scale15
I1005 10:19:47.108799  9385 net.cpp:406] Scale15 <- Convolution15
I1005 10:19:47.108805  9385 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 10:19:47.108875  9385 layer_factory.hpp:77] Creating layer Scale15
I1005 10:19:47.108979  9385 net.cpp:122] Setting up Scale15
I1005 10:19:47.108988  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.108991  9385 net.cpp:137] Memory required for data: 379700400
I1005 10:19:47.108999  9385 layer_factory.hpp:77] Creating layer Convolution16
I1005 10:19:47.109019  9385 net.cpp:84] Creating Layer Convolution16
I1005 10:19:47.109024  9385 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1005 10:19:47.109032  9385 net.cpp:380] Convolution16 -> Convolution16
I1005 10:19:47.110447  9385 net.cpp:122] Setting up Convolution16
I1005 10:19:47.110456  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.110460  9385 net.cpp:137] Memory required for data: 381338800
I1005 10:19:47.110463  9385 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 10:19:47.110468  9385 net.cpp:84] Creating Layer BatchNorm16
I1005 10:19:47.110471  9385 net.cpp:406] BatchNorm16 <- Convolution16
I1005 10:19:47.110476  9385 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 10:19:47.110677  9385 net.cpp:122] Setting up BatchNorm16
I1005 10:19:47.110682  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.110684  9385 net.cpp:137] Memory required for data: 382977200
I1005 10:19:47.110690  9385 layer_factory.hpp:77] Creating layer Scale16
I1005 10:19:47.110704  9385 net.cpp:84] Creating Layer Scale16
I1005 10:19:47.110707  9385 net.cpp:406] Scale16 <- Convolution16
I1005 10:19:47.110711  9385 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 10:19:47.110749  9385 layer_factory.hpp:77] Creating layer Scale16
I1005 10:19:47.110828  9385 net.cpp:122] Setting up Scale16
I1005 10:19:47.110833  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.110836  9385 net.cpp:137] Memory required for data: 384615600
I1005 10:19:47.110839  9385 layer_factory.hpp:77] Creating layer penlu14
I1005 10:19:47.110844  9385 net.cpp:84] Creating Layer penlu14
I1005 10:19:47.110847  9385 net.cpp:406] penlu14 <- Convolution16
I1005 10:19:47.110852  9385 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1005 10:19:47.111016  9385 net.cpp:122] Setting up penlu14
I1005 10:19:47.111022  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.111024  9385 net.cpp:137] Memory required for data: 386254000
I1005 10:19:47.111029  9385 layer_factory.hpp:77] Creating layer Convolution17
I1005 10:19:47.111035  9385 net.cpp:84] Creating Layer Convolution17
I1005 10:19:47.111038  9385 net.cpp:406] Convolution17 <- Convolution16
I1005 10:19:47.111053  9385 net.cpp:380] Convolution17 -> Convolution17
I1005 10:19:47.112818  9385 net.cpp:122] Setting up Convolution17
I1005 10:19:47.112828  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.112830  9385 net.cpp:137] Memory required for data: 387892400
I1005 10:19:47.112834  9385 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 10:19:47.112840  9385 net.cpp:84] Creating Layer BatchNorm17
I1005 10:19:47.112843  9385 net.cpp:406] BatchNorm17 <- Convolution17
I1005 10:19:47.112846  9385 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 10:19:47.112985  9385 net.cpp:122] Setting up BatchNorm17
I1005 10:19:47.112990  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.112993  9385 net.cpp:137] Memory required for data: 389530800
I1005 10:19:47.112996  9385 layer_factory.hpp:77] Creating layer Scale17
I1005 10:19:47.113000  9385 net.cpp:84] Creating Layer Scale17
I1005 10:19:47.113003  9385 net.cpp:406] Scale17 <- Convolution17
I1005 10:19:47.113006  9385 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 10:19:47.113034  9385 layer_factory.hpp:77] Creating layer Scale17
I1005 10:19:47.113116  9385 net.cpp:122] Setting up Scale17
I1005 10:19:47.113121  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.113122  9385 net.cpp:137] Memory required for data: 391169200
I1005 10:19:47.113126  9385 layer_factory.hpp:77] Creating layer Eltwise7
I1005 10:19:47.113131  9385 net.cpp:84] Creating Layer Eltwise7
I1005 10:19:47.113132  9385 net.cpp:406] Eltwise7 <- Convolution15
I1005 10:19:47.113135  9385 net.cpp:406] Eltwise7 <- Convolution17
I1005 10:19:47.113138  9385 net.cpp:380] Eltwise7 -> Eltwise7
I1005 10:19:47.113154  9385 net.cpp:122] Setting up Eltwise7
I1005 10:19:47.113158  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.113160  9385 net.cpp:137] Memory required for data: 392807600
I1005 10:19:47.113162  9385 layer_factory.hpp:77] Creating layer penlu15
I1005 10:19:47.113168  9385 net.cpp:84] Creating Layer penlu15
I1005 10:19:47.113170  9385 net.cpp:406] penlu15 <- Eltwise7
I1005 10:19:47.113174  9385 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1005 10:19:47.113284  9385 net.cpp:122] Setting up penlu15
I1005 10:19:47.113288  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.113291  9385 net.cpp:137] Memory required for data: 394446000
I1005 10:19:47.113296  9385 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1005 10:19:47.113299  9385 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1005 10:19:47.113302  9385 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1005 10:19:47.113306  9385 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1005 10:19:47.113308  9385 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1005 10:19:47.113333  9385 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1005 10:19:47.113337  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.113340  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.113343  9385 net.cpp:137] Memory required for data: 397722800
I1005 10:19:47.113344  9385 layer_factory.hpp:77] Creating layer Convolution18
I1005 10:19:47.113350  9385 net.cpp:84] Creating Layer Convolution18
I1005 10:19:47.113353  9385 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1005 10:19:47.113358  9385 net.cpp:380] Convolution18 -> Convolution18
I1005 10:19:47.115074  9385 net.cpp:122] Setting up Convolution18
I1005 10:19:47.115083  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.115087  9385 net.cpp:137] Memory required for data: 399361200
I1005 10:19:47.115090  9385 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 10:19:47.115095  9385 net.cpp:84] Creating Layer BatchNorm18
I1005 10:19:47.115098  9385 net.cpp:406] BatchNorm18 <- Convolution18
I1005 10:19:47.115103  9385 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 10:19:47.115242  9385 net.cpp:122] Setting up BatchNorm18
I1005 10:19:47.115247  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.115248  9385 net.cpp:137] Memory required for data: 400999600
I1005 10:19:47.115252  9385 layer_factory.hpp:77] Creating layer Scale18
I1005 10:19:47.115263  9385 net.cpp:84] Creating Layer Scale18
I1005 10:19:47.115267  9385 net.cpp:406] Scale18 <- Convolution18
I1005 10:19:47.115269  9385 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 10:19:47.115300  9385 layer_factory.hpp:77] Creating layer Scale18
I1005 10:19:47.115378  9385 net.cpp:122] Setting up Scale18
I1005 10:19:47.115383  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.115386  9385 net.cpp:137] Memory required for data: 402638000
I1005 10:19:47.115389  9385 layer_factory.hpp:77] Creating layer penlu16
I1005 10:19:47.115393  9385 net.cpp:84] Creating Layer penlu16
I1005 10:19:47.115396  9385 net.cpp:406] penlu16 <- Convolution18
I1005 10:19:47.115401  9385 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1005 10:19:47.115509  9385 net.cpp:122] Setting up penlu16
I1005 10:19:47.115514  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.115515  9385 net.cpp:137] Memory required for data: 404276400
I1005 10:19:47.115520  9385 layer_factory.hpp:77] Creating layer Convolution19
I1005 10:19:47.115525  9385 net.cpp:84] Creating Layer Convolution19
I1005 10:19:47.115528  9385 net.cpp:406] Convolution19 <- Convolution18
I1005 10:19:47.115532  9385 net.cpp:380] Convolution19 -> Convolution19
I1005 10:19:47.117223  9385 net.cpp:122] Setting up Convolution19
I1005 10:19:47.117230  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.117233  9385 net.cpp:137] Memory required for data: 405914800
I1005 10:19:47.117238  9385 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 10:19:47.117242  9385 net.cpp:84] Creating Layer BatchNorm19
I1005 10:19:47.117245  9385 net.cpp:406] BatchNorm19 <- Convolution19
I1005 10:19:47.117249  9385 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 10:19:47.117388  9385 net.cpp:122] Setting up BatchNorm19
I1005 10:19:47.117393  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.117394  9385 net.cpp:137] Memory required for data: 407553200
I1005 10:19:47.117399  9385 layer_factory.hpp:77] Creating layer Scale19
I1005 10:19:47.117403  9385 net.cpp:84] Creating Layer Scale19
I1005 10:19:47.117405  9385 net.cpp:406] Scale19 <- Convolution19
I1005 10:19:47.117408  9385 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 10:19:47.117436  9385 layer_factory.hpp:77] Creating layer Scale19
I1005 10:19:47.117533  9385 net.cpp:122] Setting up Scale19
I1005 10:19:47.117539  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.117542  9385 net.cpp:137] Memory required for data: 409191600
I1005 10:19:47.117545  9385 layer_factory.hpp:77] Creating layer Eltwise8
I1005 10:19:47.117550  9385 net.cpp:84] Creating Layer Eltwise8
I1005 10:19:47.117553  9385 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1005 10:19:47.117557  9385 net.cpp:406] Eltwise8 <- Convolution19
I1005 10:19:47.117559  9385 net.cpp:380] Eltwise8 -> Eltwise8
I1005 10:19:47.117578  9385 net.cpp:122] Setting up Eltwise8
I1005 10:19:47.117580  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.117583  9385 net.cpp:137] Memory required for data: 410830000
I1005 10:19:47.117584  9385 layer_factory.hpp:77] Creating layer penlu17
I1005 10:19:47.117590  9385 net.cpp:84] Creating Layer penlu17
I1005 10:19:47.117594  9385 net.cpp:406] penlu17 <- Eltwise8
I1005 10:19:47.117596  9385 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1005 10:19:47.117707  9385 net.cpp:122] Setting up penlu17
I1005 10:19:47.117712  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.117713  9385 net.cpp:137] Memory required for data: 412468400
I1005 10:19:47.117717  9385 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1005 10:19:47.117722  9385 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1005 10:19:47.117724  9385 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1005 10:19:47.117727  9385 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1005 10:19:47.117732  9385 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1005 10:19:47.117754  9385 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1005 10:19:47.117764  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.117769  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.117770  9385 net.cpp:137] Memory required for data: 415745200
I1005 10:19:47.117772  9385 layer_factory.hpp:77] Creating layer Convolution20
I1005 10:19:47.117777  9385 net.cpp:84] Creating Layer Convolution20
I1005 10:19:47.117780  9385 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1005 10:19:47.117785  9385 net.cpp:380] Convolution20 -> Convolution20
I1005 10:19:47.119817  9385 net.cpp:122] Setting up Convolution20
I1005 10:19:47.119827  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.119829  9385 net.cpp:137] Memory required for data: 417383600
I1005 10:19:47.119833  9385 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 10:19:47.119838  9385 net.cpp:84] Creating Layer BatchNorm20
I1005 10:19:47.119840  9385 net.cpp:406] BatchNorm20 <- Convolution20
I1005 10:19:47.119846  9385 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 10:19:47.119988  9385 net.cpp:122] Setting up BatchNorm20
I1005 10:19:47.119992  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.119995  9385 net.cpp:137] Memory required for data: 419022000
I1005 10:19:47.119999  9385 layer_factory.hpp:77] Creating layer Scale20
I1005 10:19:47.120003  9385 net.cpp:84] Creating Layer Scale20
I1005 10:19:47.120005  9385 net.cpp:406] Scale20 <- Convolution20
I1005 10:19:47.120009  9385 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 10:19:47.120036  9385 layer_factory.hpp:77] Creating layer Scale20
I1005 10:19:47.120117  9385 net.cpp:122] Setting up Scale20
I1005 10:19:47.120121  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.120123  9385 net.cpp:137] Memory required for data: 420660400
I1005 10:19:47.120127  9385 layer_factory.hpp:77] Creating layer penlu18
I1005 10:19:47.120132  9385 net.cpp:84] Creating Layer penlu18
I1005 10:19:47.120134  9385 net.cpp:406] penlu18 <- Convolution20
I1005 10:19:47.120138  9385 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1005 10:19:47.120249  9385 net.cpp:122] Setting up penlu18
I1005 10:19:47.120254  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.120255  9385 net.cpp:137] Memory required for data: 422298800
I1005 10:19:47.120260  9385 layer_factory.hpp:77] Creating layer Convolution21
I1005 10:19:47.120265  9385 net.cpp:84] Creating Layer Convolution21
I1005 10:19:47.120267  9385 net.cpp:406] Convolution21 <- Convolution20
I1005 10:19:47.120272  9385 net.cpp:380] Convolution21 -> Convolution21
I1005 10:19:47.122301  9385 net.cpp:122] Setting up Convolution21
I1005 10:19:47.122310  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.122313  9385 net.cpp:137] Memory required for data: 423937200
I1005 10:19:47.122318  9385 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 10:19:47.122323  9385 net.cpp:84] Creating Layer BatchNorm21
I1005 10:19:47.122325  9385 net.cpp:406] BatchNorm21 <- Convolution21
I1005 10:19:47.122329  9385 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 10:19:47.122469  9385 net.cpp:122] Setting up BatchNorm21
I1005 10:19:47.122474  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.122476  9385 net.cpp:137] Memory required for data: 425575600
I1005 10:19:47.122480  9385 layer_factory.hpp:77] Creating layer Scale21
I1005 10:19:47.122485  9385 net.cpp:84] Creating Layer Scale21
I1005 10:19:47.122488  9385 net.cpp:406] Scale21 <- Convolution21
I1005 10:19:47.122491  9385 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 10:19:47.137761  9385 layer_factory.hpp:77] Creating layer Scale21
I1005 10:19:47.137861  9385 net.cpp:122] Setting up Scale21
I1005 10:19:47.137867  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.137871  9385 net.cpp:137] Memory required for data: 427214000
I1005 10:19:47.137874  9385 layer_factory.hpp:77] Creating layer Eltwise9
I1005 10:19:47.137879  9385 net.cpp:84] Creating Layer Eltwise9
I1005 10:19:47.137882  9385 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1005 10:19:47.137893  9385 net.cpp:406] Eltwise9 <- Convolution21
I1005 10:19:47.137899  9385 net.cpp:380] Eltwise9 -> Eltwise9
I1005 10:19:47.137919  9385 net.cpp:122] Setting up Eltwise9
I1005 10:19:47.137923  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.137926  9385 net.cpp:137] Memory required for data: 428852400
I1005 10:19:47.137928  9385 layer_factory.hpp:77] Creating layer penlu19
I1005 10:19:47.137934  9385 net.cpp:84] Creating Layer penlu19
I1005 10:19:47.137938  9385 net.cpp:406] penlu19 <- Eltwise9
I1005 10:19:47.137940  9385 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1005 10:19:47.138067  9385 net.cpp:122] Setting up penlu19
I1005 10:19:47.138072  9385 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 10:19:47.138073  9385 net.cpp:137] Memory required for data: 430490800
I1005 10:19:47.138078  9385 layer_factory.hpp:77] Creating layer Pooling1
I1005 10:19:47.138083  9385 net.cpp:84] Creating Layer Pooling1
I1005 10:19:47.138087  9385 net.cpp:406] Pooling1 <- Eltwise9
I1005 10:19:47.138090  9385 net.cpp:380] Pooling1 -> Pooling1
I1005 10:19:47.138240  9385 net.cpp:122] Setting up Pooling1
I1005 10:19:47.138247  9385 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 10:19:47.138250  9385 net.cpp:137] Memory required for data: 430516400
I1005 10:19:47.138252  9385 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 10:19:47.138258  9385 net.cpp:84] Creating Layer InnerProduct1
I1005 10:19:47.138262  9385 net.cpp:406] InnerProduct1 <- Pooling1
I1005 10:19:47.138265  9385 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 10:19:47.138375  9385 net.cpp:122] Setting up InnerProduct1
I1005 10:19:47.138380  9385 net.cpp:129] Top shape: 100 10 (1000)
I1005 10:19:47.138381  9385 net.cpp:137] Memory required for data: 430520400
I1005 10:19:47.138386  9385 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1005 10:19:47.138389  9385 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1005 10:19:47.138392  9385 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1005 10:19:47.138399  9385 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1005 10:19:47.138404  9385 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1005 10:19:47.138433  9385 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1005 10:19:47.138437  9385 net.cpp:129] Top shape: 100 10 (1000)
I1005 10:19:47.138440  9385 net.cpp:129] Top shape: 100 10 (1000)
I1005 10:19:47.138442  9385 net.cpp:137] Memory required for data: 430528400
I1005 10:19:47.138444  9385 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 10:19:47.138449  9385 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 10:19:47.138453  9385 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1005 10:19:47.138455  9385 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1005 10:19:47.138458  9385 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 10:19:47.138463  9385 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 10:19:47.138672  9385 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 10:19:47.138679  9385 net.cpp:129] Top shape: (1)
I1005 10:19:47.138681  9385 net.cpp:132]     with loss weight 1
I1005 10:19:47.138689  9385 net.cpp:137] Memory required for data: 430528404
I1005 10:19:47.138691  9385 layer_factory.hpp:77] Creating layer Accuracy1
I1005 10:19:47.138697  9385 net.cpp:84] Creating Layer Accuracy1
I1005 10:19:47.138700  9385 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1005 10:19:47.138705  9385 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1005 10:19:47.138708  9385 net.cpp:380] Accuracy1 -> Accuracy1
I1005 10:19:47.138715  9385 net.cpp:122] Setting up Accuracy1
I1005 10:19:47.138717  9385 net.cpp:129] Top shape: (1)
I1005 10:19:47.138720  9385 net.cpp:137] Memory required for data: 430528408
I1005 10:19:47.138721  9385 net.cpp:200] Accuracy1 does not need backward computation.
I1005 10:19:47.138725  9385 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 10:19:47.138733  9385 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1005 10:19:47.138736  9385 net.cpp:198] InnerProduct1 needs backward computation.
I1005 10:19:47.138739  9385 net.cpp:198] Pooling1 needs backward computation.
I1005 10:19:47.138741  9385 net.cpp:198] penlu19 needs backward computation.
I1005 10:19:47.138743  9385 net.cpp:198] Eltwise9 needs backward computation.
I1005 10:19:47.138746  9385 net.cpp:198] Scale21 needs backward computation.
I1005 10:19:47.138748  9385 net.cpp:198] BatchNorm21 needs backward computation.
I1005 10:19:47.138751  9385 net.cpp:198] Convolution21 needs backward computation.
I1005 10:19:47.138753  9385 net.cpp:198] penlu18 needs backward computation.
I1005 10:19:47.138756  9385 net.cpp:198] Scale20 needs backward computation.
I1005 10:19:47.138757  9385 net.cpp:198] BatchNorm20 needs backward computation.
I1005 10:19:47.138759  9385 net.cpp:198] Convolution20 needs backward computation.
I1005 10:19:47.138761  9385 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1005 10:19:47.138764  9385 net.cpp:198] penlu17 needs backward computation.
I1005 10:19:47.138767  9385 net.cpp:198] Eltwise8 needs backward computation.
I1005 10:19:47.138769  9385 net.cpp:198] Scale19 needs backward computation.
I1005 10:19:47.138773  9385 net.cpp:198] BatchNorm19 needs backward computation.
I1005 10:19:47.138775  9385 net.cpp:198] Convolution19 needs backward computation.
I1005 10:19:47.138777  9385 net.cpp:198] penlu16 needs backward computation.
I1005 10:19:47.138779  9385 net.cpp:198] Scale18 needs backward computation.
I1005 10:19:47.138782  9385 net.cpp:198] BatchNorm18 needs backward computation.
I1005 10:19:47.138783  9385 net.cpp:198] Convolution18 needs backward computation.
I1005 10:19:47.138787  9385 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1005 10:19:47.138788  9385 net.cpp:198] penlu15 needs backward computation.
I1005 10:19:47.138790  9385 net.cpp:198] Eltwise7 needs backward computation.
I1005 10:19:47.138793  9385 net.cpp:198] Scale17 needs backward computation.
I1005 10:19:47.138795  9385 net.cpp:198] BatchNorm17 needs backward computation.
I1005 10:19:47.138797  9385 net.cpp:198] Convolution17 needs backward computation.
I1005 10:19:47.138799  9385 net.cpp:198] penlu14 needs backward computation.
I1005 10:19:47.138803  9385 net.cpp:198] Scale16 needs backward computation.
I1005 10:19:47.138804  9385 net.cpp:198] BatchNorm16 needs backward computation.
I1005 10:19:47.138806  9385 net.cpp:198] Convolution16 needs backward computation.
I1005 10:19:47.138809  9385 net.cpp:198] Scale15 needs backward computation.
I1005 10:19:47.138811  9385 net.cpp:198] BatchNorm15 needs backward computation.
I1005 10:19:47.138813  9385 net.cpp:198] Convolution15 needs backward computation.
I1005 10:19:47.138816  9385 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1005 10:19:47.138818  9385 net.cpp:198] penlu13 needs backward computation.
I1005 10:19:47.138821  9385 net.cpp:198] Eltwise6 needs backward computation.
I1005 10:19:47.138823  9385 net.cpp:198] Scale14 needs backward computation.
I1005 10:19:47.138826  9385 net.cpp:198] BatchNorm14 needs backward computation.
I1005 10:19:47.138828  9385 net.cpp:198] Convolution14 needs backward computation.
I1005 10:19:47.138831  9385 net.cpp:198] penlu12 needs backward computation.
I1005 10:19:47.138833  9385 net.cpp:198] Scale13 needs backward computation.
I1005 10:19:47.138835  9385 net.cpp:198] BatchNorm13 needs backward computation.
I1005 10:19:47.139534  9385 net.cpp:198] Convolution13 needs backward computation.
I1005 10:19:47.139544  9385 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1005 10:19:47.139549  9385 net.cpp:198] penlu11 needs backward computation.
I1005 10:19:47.139554  9385 net.cpp:198] Eltwise5 needs backward computation.
I1005 10:19:47.139557  9385 net.cpp:198] Scale12 needs backward computation.
I1005 10:19:47.139561  9385 net.cpp:198] BatchNorm12 needs backward computation.
I1005 10:19:47.139572  9385 net.cpp:198] Convolution12 needs backward computation.
I1005 10:19:47.139585  9385 net.cpp:198] penlu10 needs backward computation.
I1005 10:19:47.139587  9385 net.cpp:198] Scale11 needs backward computation.
I1005 10:19:47.139590  9385 net.cpp:198] BatchNorm11 needs backward computation.
I1005 10:19:47.139591  9385 net.cpp:198] Convolution11 needs backward computation.
I1005 10:19:47.139595  9385 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1005 10:19:47.139596  9385 net.cpp:198] penlu9 needs backward computation.
I1005 10:19:47.139600  9385 net.cpp:198] Eltwise4 needs backward computation.
I1005 10:19:47.139601  9385 net.cpp:198] Scale10 needs backward computation.
I1005 10:19:47.139603  9385 net.cpp:198] BatchNorm10 needs backward computation.
I1005 10:19:47.139605  9385 net.cpp:198] Convolution10 needs backward computation.
I1005 10:19:47.139608  9385 net.cpp:198] penlu8 needs backward computation.
I1005 10:19:47.139611  9385 net.cpp:198] Scale9 needs backward computation.
I1005 10:19:47.139613  9385 net.cpp:198] BatchNorm9 needs backward computation.
I1005 10:19:47.139616  9385 net.cpp:198] Convolution9 needs backward computation.
I1005 10:19:47.139617  9385 net.cpp:198] Scale8 needs backward computation.
I1005 10:19:47.139619  9385 net.cpp:198] BatchNorm8 needs backward computation.
I1005 10:19:47.139622  9385 net.cpp:198] Convolution8 needs backward computation.
I1005 10:19:47.139624  9385 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1005 10:19:47.139627  9385 net.cpp:198] penlu7 needs backward computation.
I1005 10:19:47.139629  9385 net.cpp:198] Eltwise3 needs backward computation.
I1005 10:19:47.139632  9385 net.cpp:198] Scale7 needs backward computation.
I1005 10:19:47.139634  9385 net.cpp:198] BatchNorm7 needs backward computation.
I1005 10:19:47.139636  9385 net.cpp:198] Convolution7 needs backward computation.
I1005 10:19:47.139638  9385 net.cpp:198] penlu6 needs backward computation.
I1005 10:19:47.139642  9385 net.cpp:198] Scale6 needs backward computation.
I1005 10:19:47.139643  9385 net.cpp:198] BatchNorm6 needs backward computation.
I1005 10:19:47.139645  9385 net.cpp:198] Convolution6 needs backward computation.
I1005 10:19:47.139647  9385 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1005 10:19:47.139650  9385 net.cpp:198] penlu5 needs backward computation.
I1005 10:19:47.139652  9385 net.cpp:198] Eltwise2 needs backward computation.
I1005 10:19:47.139655  9385 net.cpp:198] Scale5 needs backward computation.
I1005 10:19:47.139657  9385 net.cpp:198] BatchNorm5 needs backward computation.
I1005 10:19:47.139659  9385 net.cpp:198] Convolution5 needs backward computation.
I1005 10:19:47.139662  9385 net.cpp:198] penlu4 needs backward computation.
I1005 10:19:47.139663  9385 net.cpp:198] Scale4 needs backward computation.
I1005 10:19:47.139667  9385 net.cpp:198] BatchNorm4 needs backward computation.
I1005 10:19:47.139668  9385 net.cpp:198] Convolution4 needs backward computation.
I1005 10:19:47.139670  9385 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1005 10:19:47.139673  9385 net.cpp:198] penlu3 needs backward computation.
I1005 10:19:47.139675  9385 net.cpp:198] Eltwise1 needs backward computation.
I1005 10:19:47.139678  9385 net.cpp:198] Scale3 needs backward computation.
I1005 10:19:47.139680  9385 net.cpp:198] BatchNorm3 needs backward computation.
I1005 10:19:47.139683  9385 net.cpp:198] Convolution3 needs backward computation.
I1005 10:19:47.139684  9385 net.cpp:198] penlu2 needs backward computation.
I1005 10:19:47.139688  9385 net.cpp:198] Scale2 needs backward computation.
I1005 10:19:47.139689  9385 net.cpp:198] BatchNorm2 needs backward computation.
I1005 10:19:47.139691  9385 net.cpp:198] Convolution2 needs backward computation.
I1005 10:19:47.139694  9385 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1005 10:19:47.139696  9385 net.cpp:198] penlu1 needs backward computation.
I1005 10:19:47.139698  9385 net.cpp:198] Scale1 needs backward computation.
I1005 10:19:47.139703  9385 net.cpp:198] BatchNorm1 needs backward computation.
I1005 10:19:47.139706  9385 net.cpp:198] Convolution1 needs backward computation.
I1005 10:19:47.139709  9385 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1005 10:19:47.139713  9385 net.cpp:200] Data1 does not need backward computation.
I1005 10:19:47.139714  9385 net.cpp:242] This network produces output Accuracy1
I1005 10:19:47.139716  9385 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 10:19:47.139752  9385 net.cpp:255] Network initialization done.
I1005 10:19:47.140012  9385 solver.cpp:56] Solver scaffolding done.
I1005 10:19:47.145447  9385 caffe.cpp:248] Starting Optimization
I1005 10:19:47.145455  9385 solver.cpp:272] Solving resnet_cifar10
I1005 10:19:47.145457  9385 solver.cpp:273] Learning Rate Policy: multistep
I1005 10:19:47.147414  9385 solver.cpp:330] Iteration 0, Testing net (#0)
I1005 10:19:48.370594  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:19:48.419723  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1005 10:19:48.419759  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1005 10:19:48.492597  9385 solver.cpp:218] Iteration 0 (0.168996 iter/s, 1.34706s/100 iters), loss = 2.31674
I1005 10:19:48.492624  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.31674 (* 1 = 2.31674 loss)
I1005 10:19:48.492640  9385 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1005 10:19:53.742807  9385 solver.cpp:218] Iteration 100 (19.0472 iter/s, 5.25013s/100 iters), loss = 1.65219
I1005 10:19:53.742846  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.65219 (* 1 = 1.65219 loss)
I1005 10:19:53.742852  9385 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1005 10:19:58.958395  9385 solver.cpp:218] Iteration 200 (19.1737 iter/s, 5.21549s/100 iters), loss = 1.65212
I1005 10:19:58.958423  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.65212 (* 1 = 1.65212 loss)
I1005 10:19:58.958428  9385 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1005 10:20:04.175395  9385 solver.cpp:218] Iteration 300 (19.1684 iter/s, 5.21692s/100 iters), loss = 1.20302
I1005 10:20:04.175431  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.20302 (* 1 = 1.20302 loss)
I1005 10:20:04.175438  9385 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1005 10:20:09.390367  9385 solver.cpp:218] Iteration 400 (19.1759 iter/s, 5.21488s/100 iters), loss = 1.12197
I1005 10:20:09.390408  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12197 (* 1 = 1.12197 loss)
I1005 10:20:09.390413  9385 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1005 10:20:14.358176  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:20:14.566289  9385 solver.cpp:330] Iteration 500, Testing net (#0)
I1005 10:20:15.747095  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:20:15.796360  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3247
I1005 10:20:15.796396  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.62164 (* 1 = 3.62164 loss)
I1005 10:20:15.848026  9385 solver.cpp:218] Iteration 500 (15.4857 iter/s, 6.45756s/100 iters), loss = 1.2485
I1005 10:20:15.848052  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.2485 (* 1 = 1.2485 loss)
I1005 10:20:15.848059  9385 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1005 10:20:21.073946  9385 solver.cpp:218] Iteration 600 (19.1357 iter/s, 5.22583s/100 iters), loss = 1.0149
I1005 10:20:21.074029  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.0149 (* 1 = 1.0149 loss)
I1005 10:20:21.074035  9385 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1005 10:20:26.293220  9385 solver.cpp:218] Iteration 700 (19.1603 iter/s, 5.21914s/100 iters), loss = 1.10995
I1005 10:20:26.293257  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10995 (* 1 = 1.10995 loss)
I1005 10:20:26.293263  9385 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1005 10:20:31.515856  9385 solver.cpp:218] Iteration 800 (19.1478 iter/s, 5.22254s/100 iters), loss = 0.933318
I1005 10:20:31.515894  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.933318 (* 1 = 0.933318 loss)
I1005 10:20:31.515900  9385 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1005 10:20:36.727691  9385 solver.cpp:218] Iteration 900 (19.1874 iter/s, 5.21174s/100 iters), loss = 0.921425
I1005 10:20:36.727721  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.921425 (* 1 = 0.921425 loss)
I1005 10:20:36.727727  9385 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1005 10:20:41.697329  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:20:41.904752  9385 solver.cpp:330] Iteration 1000, Testing net (#0)
I1005 10:20:43.089977  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:20:43.140332  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4672
I1005 10:20:43.140358  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.15929 (* 1 = 2.15929 loss)
I1005 10:20:43.194351  9385 solver.cpp:218] Iteration 1000 (15.4642 iter/s, 6.46657s/100 iters), loss = 0.995654
I1005 10:20:43.194397  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.995654 (* 1 = 0.995654 loss)
I1005 10:20:43.194406  9385 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1005 10:20:48.420603  9385 solver.cpp:218] Iteration 1100 (19.1346 iter/s, 5.22612s/100 iters), loss = 0.719579
I1005 10:20:48.420632  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.719579 (* 1 = 0.719579 loss)
I1005 10:20:48.420637  9385 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1005 10:20:53.651705  9385 solver.cpp:218] Iteration 1200 (19.1167 iter/s, 5.23102s/100 iters), loss = 0.855894
I1005 10:20:53.651844  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.855894 (* 1 = 0.855894 loss)
I1005 10:20:53.651861  9385 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1005 10:20:58.883438  9385 solver.cpp:218] Iteration 1300 (19.1148 iter/s, 5.23155s/100 iters), loss = 0.804644
I1005 10:20:58.883478  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.804644 (* 1 = 0.804644 loss)
I1005 10:20:58.883484  9385 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1005 10:21:04.105257  9385 solver.cpp:218] Iteration 1400 (19.1508 iter/s, 5.22172s/100 iters), loss = 0.808609
I1005 10:21:04.105304  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.808609 (* 1 = 0.808609 loss)
I1005 10:21:04.105312  9385 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1005 10:21:09.079027  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:21:09.287771  9385 solver.cpp:330] Iteration 1500, Testing net (#0)
I1005 10:21:10.480731  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:21:10.530170  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.607
I1005 10:21:10.530196  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.25811 (* 1 = 1.25811 loss)
I1005 10:21:10.582823  9385 solver.cpp:218] Iteration 1500 (15.4382 iter/s, 6.47743s/100 iters), loss = 0.961448
I1005 10:21:10.582859  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.961448 (* 1 = 0.961448 loss)
I1005 10:21:10.582865  9385 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1005 10:21:15.803625  9385 solver.cpp:218] Iteration 1600 (19.1544 iter/s, 5.22072s/100 iters), loss = 0.595448
I1005 10:21:15.803668  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.595448 (* 1 = 0.595448 loss)
I1005 10:21:15.803673  9385 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1005 10:21:21.034899  9385 solver.cpp:218] Iteration 1700 (19.1161 iter/s, 5.23118s/100 iters), loss = 0.763
I1005 10:21:21.034941  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.763 (* 1 = 0.763 loss)
I1005 10:21:21.034947  9385 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1005 10:21:26.260773  9385 solver.cpp:218] Iteration 1800 (19.1359 iter/s, 5.22578s/100 iters), loss = 0.729656
I1005 10:21:26.260921  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.729656 (* 1 = 0.729656 loss)
I1005 10:21:26.260929  9385 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1005 10:21:31.486531  9385 solver.cpp:218] Iteration 1900 (19.1367 iter/s, 5.22556s/100 iters), loss = 0.603484
I1005 10:21:31.486562  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603484 (* 1 = 0.603484 loss)
I1005 10:21:31.486568  9385 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1005 10:21:36.451463  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:21:36.660567  9385 solver.cpp:330] Iteration 2000, Testing net (#0)
I1005 10:21:37.857669  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:21:37.906822  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6161
I1005 10:21:37.906857  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.16922 (* 1 = 1.16922 loss)
I1005 10:21:37.959245  9385 solver.cpp:218] Iteration 2000 (15.4497 iter/s, 6.47263s/100 iters), loss = 0.859248
I1005 10:21:37.959275  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.859248 (* 1 = 0.859248 loss)
I1005 10:21:37.959282  9385 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1005 10:21:43.189416  9385 solver.cpp:218] Iteration 2100 (19.1201 iter/s, 5.23009s/100 iters), loss = 0.536118
I1005 10:21:43.189467  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.536118 (* 1 = 0.536118 loss)
I1005 10:21:43.189476  9385 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1005 10:21:48.425074  9385 solver.cpp:218] Iteration 2200 (19.1003 iter/s, 5.23553s/100 iters), loss = 0.579392
I1005 10:21:48.425110  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.579392 (* 1 = 0.579392 loss)
I1005 10:21:48.425117  9385 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1005 10:21:53.663717  9385 solver.cpp:218] Iteration 2300 (19.0892 iter/s, 5.23857s/100 iters), loss = 0.666205
I1005 10:21:53.663745  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.666205 (* 1 = 0.666205 loss)
I1005 10:21:53.663751  9385 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1005 10:21:58.896828  9385 solver.cpp:218] Iteration 2400 (19.1094 iter/s, 5.23304s/100 iters), loss = 0.642387
I1005 10:21:58.896932  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.642387 (* 1 = 0.642387 loss)
I1005 10:21:58.896948  9385 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1005 10:22:03.864259  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:22:04.073344  9385 solver.cpp:330] Iteration 2500, Testing net (#0)
I1005 10:22:05.264621  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:22:05.314158  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6503
I1005 10:22:05.314193  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01112 (* 1 = 1.01112 loss)
I1005 10:22:05.366663  9385 solver.cpp:218] Iteration 2500 (15.4567 iter/s, 6.46968s/100 iters), loss = 0.554688
I1005 10:22:05.366686  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.554688 (* 1 = 0.554688 loss)
I1005 10:22:05.366693  9385 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1005 10:22:10.601711  9385 solver.cpp:218] Iteration 2600 (19.1023 iter/s, 5.23497s/100 iters), loss = 0.49973
I1005 10:22:10.601752  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.49973 (* 1 = 0.49973 loss)
I1005 10:22:10.601758  9385 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1005 10:22:15.824863  9385 solver.cpp:218] Iteration 2700 (19.1458 iter/s, 5.22307s/100 iters), loss = 0.566263
I1005 10:22:15.824892  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.566263 (* 1 = 0.566263 loss)
I1005 10:22:15.824898  9385 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1005 10:22:21.059803  9385 solver.cpp:218] Iteration 2800 (19.1027 iter/s, 5.23487s/100 iters), loss = 0.597844
I1005 10:22:21.059831  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.597844 (* 1 = 0.597844 loss)
I1005 10:22:21.059837  9385 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1005 10:22:26.291569  9385 solver.cpp:218] Iteration 2900 (19.1143 iter/s, 5.2317s/100 iters), loss = 0.514025
I1005 10:22:26.291610  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.514025 (* 1 = 0.514025 loss)
I1005 10:22:26.291615  9385 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1005 10:22:31.270651  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:22:31.482245  9385 solver.cpp:330] Iteration 3000, Testing net (#0)
I1005 10:22:32.665968  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:22:32.715533  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6981
I1005 10:22:32.715566  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.823276 (* 1 = 0.823276 loss)
I1005 10:22:32.767621  9385 solver.cpp:218] Iteration 3000 (15.4417 iter/s, 6.47597s/100 iters), loss = 0.559022
I1005 10:22:32.767644  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.559022 (* 1 = 0.559022 loss)
I1005 10:22:32.767652  9385 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1005 10:22:38.001502  9385 solver.cpp:218] Iteration 3100 (19.1065 iter/s, 5.23382s/100 iters), loss = 0.474362
I1005 10:22:38.001530  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474362 (* 1 = 0.474362 loss)
I1005 10:22:38.001536  9385 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1005 10:22:43.232512  9385 solver.cpp:218] Iteration 3200 (19.117 iter/s, 5.23094s/100 iters), loss = 0.575031
I1005 10:22:43.232561  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.575031 (* 1 = 0.575031 loss)
I1005 10:22:43.232570  9385 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1005 10:22:48.461360  9385 solver.cpp:218] Iteration 3300 (19.125 iter/s, 5.22876s/100 iters), loss = 0.589348
I1005 10:22:48.461401  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.589348 (* 1 = 0.589348 loss)
I1005 10:22:48.461407  9385 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1005 10:22:53.688774  9385 solver.cpp:218] Iteration 3400 (19.1302 iter/s, 5.22734s/100 iters), loss = 0.518622
I1005 10:22:53.688804  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518622 (* 1 = 0.518622 loss)
I1005 10:22:53.688810  9385 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1005 10:22:58.663141  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:22:58.871456  9385 solver.cpp:330] Iteration 3500, Testing net (#0)
I1005 10:23:00.053709  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:23:00.102530  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7134
I1005 10:23:00.102550  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.818456 (* 1 = 0.818456 loss)
I1005 10:23:00.155459  9385 solver.cpp:218] Iteration 3500 (15.464 iter/s, 6.46662s/100 iters), loss = 0.450907
I1005 10:23:00.155486  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450907 (* 1 = 0.450907 loss)
I1005 10:23:00.155493  9385 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1005 10:23:05.388123  9385 solver.cpp:218] Iteration 3600 (19.1109 iter/s, 5.2326s/100 iters), loss = 0.501507
I1005 10:23:05.388239  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501507 (* 1 = 0.501507 loss)
I1005 10:23:05.388259  9385 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1005 10:23:10.627526  9385 solver.cpp:218] Iteration 3700 (19.0867 iter/s, 5.23926s/100 iters), loss = 0.457934
I1005 10:23:10.627555  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457934 (* 1 = 0.457934 loss)
I1005 10:23:10.627562  9385 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1005 10:23:15.853840  9385 solver.cpp:218] Iteration 3800 (19.1342 iter/s, 5.22625s/100 iters), loss = 0.591145
I1005 10:23:15.853870  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.591145 (* 1 = 0.591145 loss)
I1005 10:23:15.853876  9385 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1005 10:23:21.088937  9385 solver.cpp:218] Iteration 3900 (19.1021 iter/s, 5.23503s/100 iters), loss = 0.487136
I1005 10:23:21.088968  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.487136 (* 1 = 0.487136 loss)
I1005 10:23:21.088974  9385 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1005 10:23:26.067425  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:23:26.276417  9385 solver.cpp:330] Iteration 4000, Testing net (#0)
I1005 10:23:27.460080  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:23:27.509297  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7076
I1005 10:23:27.509322  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.84231 (* 1 = 0.84231 loss)
I1005 10:23:27.561604  9385 solver.cpp:218] Iteration 4000 (15.4497 iter/s, 6.4726s/100 iters), loss = 0.435785
I1005 10:23:27.561636  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435785 (* 1 = 0.435785 loss)
I1005 10:23:27.561643  9385 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1005 10:23:32.798233  9385 solver.cpp:218] Iteration 4100 (19.0965 iter/s, 5.23657s/100 iters), loss = 0.384994
I1005 10:23:32.798274  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384994 (* 1 = 0.384994 loss)
I1005 10:23:32.798280  9385 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1005 10:23:38.034792  9385 solver.cpp:218] Iteration 4200 (19.0968 iter/s, 5.23648s/100 iters), loss = 0.42958
I1005 10:23:38.034934  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42958 (* 1 = 0.42958 loss)
I1005 10:23:38.034952  9385 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1005 10:23:43.269807  9385 solver.cpp:218] Iteration 4300 (19.1028 iter/s, 5.23484s/100 iters), loss = 0.473072
I1005 10:23:43.269842  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.473072 (* 1 = 0.473072 loss)
I1005 10:23:43.269850  9385 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1005 10:23:48.491919  9385 solver.cpp:218] Iteration 4400 (19.1497 iter/s, 5.22201s/100 iters), loss = 0.483041
I1005 10:23:48.491950  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.483041 (* 1 = 0.483041 loss)
I1005 10:23:48.491955  9385 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1005 10:23:53.465036  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:23:53.674116  9385 solver.cpp:330] Iteration 4500, Testing net (#0)
I1005 10:23:54.858605  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:23:54.907333  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7537
I1005 10:23:54.907368  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.721409 (* 1 = 0.721409 loss)
I1005 10:23:54.959761  9385 solver.cpp:218] Iteration 4500 (15.4613 iter/s, 6.46778s/100 iters), loss = 0.494008
I1005 10:23:54.959789  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494008 (* 1 = 0.494008 loss)
I1005 10:23:54.959796  9385 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1005 10:24:00.203138  9385 solver.cpp:218] Iteration 4600 (19.0719 iter/s, 5.24331s/100 iters), loss = 0.442597
I1005 10:24:00.203168  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442597 (* 1 = 0.442597 loss)
I1005 10:24:00.203174  9385 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1005 10:24:05.436607  9385 solver.cpp:218] Iteration 4700 (19.108 iter/s, 5.23341s/100 iters), loss = 0.441972
I1005 10:24:05.436637  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441972 (* 1 = 0.441972 loss)
I1005 10:24:05.436643  9385 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1005 10:24:10.672909  9385 solver.cpp:218] Iteration 4800 (19.0977 iter/s, 5.23624s/100 iters), loss = 0.598502
I1005 10:24:10.673032  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.598502 (* 1 = 0.598502 loss)
I1005 10:24:10.673039  9385 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1005 10:24:15.900002  9385 solver.cpp:218] Iteration 4900 (19.1316 iter/s, 5.22695s/100 iters), loss = 0.471568
I1005 10:24:15.900032  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471568 (* 1 = 0.471568 loss)
I1005 10:24:15.900040  9385 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1005 10:24:20.884748  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:24:21.093346  9385 solver.cpp:330] Iteration 5000, Testing net (#0)
I1005 10:24:22.285984  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:24:22.335888  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7044
I1005 10:24:22.335914  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.881876 (* 1 = 0.881876 loss)
I1005 10:24:22.389031  9385 solver.cpp:218] Iteration 5000 (15.4108 iter/s, 6.48896s/100 iters), loss = 0.379929
I1005 10:24:22.389066  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379929 (* 1 = 0.379929 loss)
I1005 10:24:22.389073  9385 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1005 10:24:27.618655  9385 solver.cpp:218] Iteration 5100 (19.1221 iter/s, 5.22956s/100 iters), loss = 0.416656
I1005 10:24:27.618685  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416656 (* 1 = 0.416656 loss)
I1005 10:24:27.618690  9385 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1005 10:24:32.855901  9385 solver.cpp:218] Iteration 5200 (19.0942 iter/s, 5.23719s/100 iters), loss = 0.457449
I1005 10:24:32.855929  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457449 (* 1 = 0.457449 loss)
I1005 10:24:32.855944  9385 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1005 10:24:38.096396  9385 solver.cpp:218] Iteration 5300 (19.0824 iter/s, 5.24044s/100 iters), loss = 0.462527
I1005 10:24:38.096426  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.462527 (* 1 = 0.462527 loss)
I1005 10:24:38.096431  9385 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1005 10:24:43.335310  9385 solver.cpp:218] Iteration 5400 (19.0882 iter/s, 5.23885s/100 iters), loss = 0.418036
I1005 10:24:43.335456  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418036 (* 1 = 0.418036 loss)
I1005 10:24:43.335465  9385 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1005 10:24:48.313711  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:24:48.523052  9385 solver.cpp:330] Iteration 5500, Testing net (#0)
I1005 10:24:49.720233  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:24:49.769731  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.656
I1005 10:24:49.769764  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00749 (* 1 = 1.00749 loss)
I1005 10:24:49.821771  9385 solver.cpp:218] Iteration 5500 (15.4171 iter/s, 6.4863s/100 iters), loss = 0.356118
I1005 10:24:49.821799  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356118 (* 1 = 0.356118 loss)
I1005 10:24:49.821805  9385 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1005 10:24:55.055991  9385 solver.cpp:218] Iteration 5600 (19.1052 iter/s, 5.23417s/100 iters), loss = 0.41658
I1005 10:24:55.056020  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41658 (* 1 = 0.41658 loss)
I1005 10:24:55.056026  9385 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1005 10:25:00.298678  9385 solver.cpp:218] Iteration 5700 (19.0744 iter/s, 5.24263s/100 iters), loss = 0.4837
I1005 10:25:00.298718  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4837 (* 1 = 0.4837 loss)
I1005 10:25:00.298724  9385 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1005 10:25:05.543332  9385 solver.cpp:218] Iteration 5800 (19.0673 iter/s, 5.24458s/100 iters), loss = 0.515257
I1005 10:25:05.543371  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.515257 (* 1 = 0.515257 loss)
I1005 10:25:05.543377  9385 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1005 10:25:10.780131  9385 solver.cpp:218] Iteration 5900 (19.0959 iter/s, 5.23673s/100 iters), loss = 0.399848
I1005 10:25:10.780174  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399848 (* 1 = 0.399848 loss)
I1005 10:25:10.780179  9385 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1005 10:25:15.749163  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:25:15.957304  9385 solver.cpp:330] Iteration 6000, Testing net (#0)
I1005 10:25:17.148412  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:25:17.197863  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7154
I1005 10:25:17.197896  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.824313 (* 1 = 0.824313 loss)
I1005 10:25:17.250198  9385 solver.cpp:218] Iteration 6000 (15.456 iter/s, 6.47s/100 iters), loss = 0.308815
I1005 10:25:17.250232  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308815 (* 1 = 0.308815 loss)
I1005 10:25:17.250241  9385 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1005 10:25:22.487871  9385 solver.cpp:218] Iteration 6100 (19.0927 iter/s, 5.23761s/100 iters), loss = 0.391598
I1005 10:25:22.487902  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391598 (* 1 = 0.391598 loss)
I1005 10:25:22.487910  9385 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1005 10:25:27.720787  9385 solver.cpp:218] Iteration 6200 (19.11 iter/s, 5.23285s/100 iters), loss = 0.398621
I1005 10:25:27.720827  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398621 (* 1 = 0.398621 loss)
I1005 10:25:27.720834  9385 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1005 10:25:32.959394  9385 solver.cpp:218] Iteration 6300 (19.0893 iter/s, 5.23854s/100 iters), loss = 0.409093
I1005 10:25:32.959424  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409093 (* 1 = 0.409093 loss)
I1005 10:25:32.959430  9385 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1005 10:25:38.194303  9385 solver.cpp:218] Iteration 6400 (19.1027 iter/s, 5.23485s/100 iters), loss = 0.376207
I1005 10:25:38.194332  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376207 (* 1 = 0.376207 loss)
I1005 10:25:38.194339  9385 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1005 10:25:43.173553  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:25:43.389358  9385 solver.cpp:330] Iteration 6500, Testing net (#0)
I1005 10:25:44.575536  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:25:44.625263  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7137
I1005 10:25:44.625288  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.886399 (* 1 = 0.886399 loss)
I1005 10:25:44.677811  9385 solver.cpp:218] Iteration 6500 (15.4239 iter/s, 6.48345s/100 iters), loss = 0.363087
I1005 10:25:44.677834  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363087 (* 1 = 0.363087 loss)
I1005 10:25:44.677841  9385 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1005 10:25:49.917803  9385 solver.cpp:218] Iteration 6600 (19.0842 iter/s, 5.23993s/100 iters), loss = 0.382761
I1005 10:25:49.917920  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382761 (* 1 = 0.382761 loss)
I1005 10:25:49.917927  9385 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1005 10:25:55.148362  9385 solver.cpp:218] Iteration 6700 (19.119 iter/s, 5.23041s/100 iters), loss = 0.389866
I1005 10:25:55.148404  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389866 (* 1 = 0.389866 loss)
I1005 10:25:55.148424  9385 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1005 10:26:00.394246  9385 solver.cpp:218] Iteration 6800 (19.0635 iter/s, 5.24561s/100 iters), loss = 0.417524
I1005 10:26:00.394284  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417524 (* 1 = 0.417524 loss)
I1005 10:26:00.394289  9385 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1005 10:26:05.626719  9385 solver.cpp:218] Iteration 6900 (19.1117 iter/s, 5.2324s/100 iters), loss = 0.433954
I1005 10:26:05.626750  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433954 (* 1 = 0.433954 loss)
I1005 10:26:05.626758  9385 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1005 10:26:10.609167  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:26:10.818785  9385 solver.cpp:330] Iteration 7000, Testing net (#0)
I1005 10:26:12.002750  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:26:12.052184  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6719
I1005 10:26:12.052208  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05308 (* 1 = 1.05308 loss)
I1005 10:26:12.104389  9385 solver.cpp:218] Iteration 7000 (15.4378 iter/s, 6.47761s/100 iters), loss = 0.373808
I1005 10:26:12.104413  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373808 (* 1 = 0.373808 loss)
I1005 10:26:12.104420  9385 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1005 10:26:17.340692  9385 solver.cpp:218] Iteration 7100 (19.0976 iter/s, 5.23625s/100 iters), loss = 0.276259
I1005 10:26:17.340732  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276259 (* 1 = 0.276259 loss)
I1005 10:26:17.340739  9385 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1005 10:26:22.577352  9385 solver.cpp:218] Iteration 7200 (19.0964 iter/s, 5.23659s/100 iters), loss = 0.434096
I1005 10:26:22.577529  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.434096 (* 1 = 0.434096 loss)
I1005 10:26:22.577548  9385 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1005 10:26:27.808737  9385 solver.cpp:218] Iteration 7300 (19.1161 iter/s, 5.2312s/100 iters), loss = 0.390159
I1005 10:26:27.808768  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390159 (* 1 = 0.390159 loss)
I1005 10:26:27.808774  9385 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1005 10:26:33.046741  9385 solver.cpp:218] Iteration 7400 (19.0915 iter/s, 5.23794s/100 iters), loss = 0.482906
I1005 10:26:33.046769  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.482906 (* 1 = 0.482906 loss)
I1005 10:26:33.046775  9385 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1005 10:26:38.027657  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:26:38.236308  9385 solver.cpp:330] Iteration 7500, Testing net (#0)
I1005 10:26:39.420918  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:26:39.470695  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7605
I1005 10:26:39.470718  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706682 (* 1 = 0.706682 loss)
I1005 10:26:39.523138  9385 solver.cpp:218] Iteration 7500 (15.4408 iter/s, 6.47634s/100 iters), loss = 0.355216
I1005 10:26:39.523165  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355216 (* 1 = 0.355216 loss)
I1005 10:26:39.523171  9385 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1005 10:26:44.767837  9385 solver.cpp:218] Iteration 7600 (19.0671 iter/s, 5.24464s/100 iters), loss = 0.312029
I1005 10:26:44.767876  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312029 (* 1 = 0.312029 loss)
I1005 10:26:44.767881  9385 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1005 10:26:50.008836  9385 solver.cpp:218] Iteration 7700 (19.0806 iter/s, 5.24093s/100 iters), loss = 0.287533
I1005 10:26:50.008865  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287533 (* 1 = 0.287533 loss)
I1005 10:26:50.008872  9385 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1005 10:26:55.237807  9385 solver.cpp:218] Iteration 7800 (19.1244 iter/s, 5.22891s/100 iters), loss = 0.444576
I1005 10:26:55.237897  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444576 (* 1 = 0.444576 loss)
I1005 10:26:55.237908  9385 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1005 10:27:00.466804  9385 solver.cpp:218] Iteration 7900 (19.1247 iter/s, 5.22885s/100 iters), loss = 0.358267
I1005 10:27:00.466833  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358267 (* 1 = 0.358267 loss)
I1005 10:27:00.466840  9385 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1005 10:27:05.443568  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:27:05.652329  9385 solver.cpp:330] Iteration 8000, Testing net (#0)
I1005 10:27:06.838575  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:27:06.888064  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7023
I1005 10:27:06.888099  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.952066 (* 1 = 0.952066 loss)
I1005 10:27:06.940683  9385 solver.cpp:218] Iteration 8000 (15.4468 iter/s, 6.47382s/100 iters), loss = 0.343905
I1005 10:27:06.940711  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343905 (* 1 = 0.343905 loss)
I1005 10:27:06.940717  9385 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1005 10:27:12.176921  9385 solver.cpp:218] Iteration 8100 (19.0979 iter/s, 5.23618s/100 iters), loss = 0.392743
I1005 10:27:12.176960  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392743 (* 1 = 0.392743 loss)
I1005 10:27:12.176966  9385 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1005 10:27:17.416570  9385 solver.cpp:218] Iteration 8200 (19.0855 iter/s, 5.23958s/100 iters), loss = 0.349713
I1005 10:27:17.416599  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349713 (* 1 = 0.349713 loss)
I1005 10:27:17.416605  9385 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1005 10:27:22.660594  9385 solver.cpp:218] Iteration 8300 (19.0695 iter/s, 5.24397s/100 iters), loss = 0.406518
I1005 10:27:22.660634  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406518 (* 1 = 0.406518 loss)
I1005 10:27:22.660641  9385 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1005 10:27:27.889636  9385 solver.cpp:218] Iteration 8400 (19.1242 iter/s, 5.22897s/100 iters), loss = 0.327541
I1005 10:27:27.889771  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327541 (* 1 = 0.327541 loss)
I1005 10:27:27.889788  9385 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1005 10:27:32.871238  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:27:33.080005  9385 solver.cpp:330] Iteration 8500, Testing net (#0)
I1005 10:27:34.269371  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:27:34.319809  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7784
I1005 10:27:34.319845  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.65634 (* 1 = 0.65634 loss)
I1005 10:27:34.373188  9385 solver.cpp:218] Iteration 8500 (15.424 iter/s, 6.4834s/100 iters), loss = 0.28675
I1005 10:27:34.373219  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28675 (* 1 = 0.28675 loss)
I1005 10:27:34.373225  9385 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1005 10:27:39.599452  9385 solver.cpp:218] Iteration 8600 (19.1343 iter/s, 5.2262s/100 iters), loss = 0.329985
I1005 10:27:39.599485  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329985 (* 1 = 0.329985 loss)
I1005 10:27:39.599491  9385 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1005 10:27:44.835563  9385 solver.cpp:218] Iteration 8700 (19.0983 iter/s, 5.23606s/100 iters), loss = 0.453495
I1005 10:27:44.835593  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453495 (* 1 = 0.453495 loss)
I1005 10:27:44.835598  9385 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1005 10:27:50.073814  9385 solver.cpp:218] Iteration 8800 (19.0905 iter/s, 5.23819s/100 iters), loss = 0.363591
I1005 10:27:50.073855  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363591 (* 1 = 0.363591 loss)
I1005 10:27:50.073861  9385 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1005 10:27:55.303834  9385 solver.cpp:218] Iteration 8900 (19.1207 iter/s, 5.22995s/100 iters), loss = 0.426027
I1005 10:27:55.303872  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426027 (* 1 = 0.426027 loss)
I1005 10:27:55.303881  9385 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1005 10:28:00.282124  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:28:00.491945  9385 solver.cpp:330] Iteration 9000, Testing net (#0)
I1005 10:28:01.684801  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:28:01.733669  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7898
I1005 10:28:01.733692  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.612842 (* 1 = 0.612842 loss)
I1005 10:28:01.785866  9385 solver.cpp:218] Iteration 9000 (15.4274 iter/s, 6.48197s/100 iters), loss = 0.312025
I1005 10:28:01.785889  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312025 (* 1 = 0.312025 loss)
I1005 10:28:01.785897  9385 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1005 10:28:07.012446  9385 solver.cpp:218] Iteration 9100 (19.1332 iter/s, 5.22653s/100 iters), loss = 0.342513
I1005 10:28:07.012476  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342513 (* 1 = 0.342513 loss)
I1005 10:28:07.012482  9385 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1005 10:28:12.259498  9385 solver.cpp:218] Iteration 9200 (19.0585 iter/s, 5.24699s/100 iters), loss = 0.414136
I1005 10:28:12.259538  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414136 (* 1 = 0.414136 loss)
I1005 10:28:12.259543  9385 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1005 10:28:17.503391  9385 solver.cpp:218] Iteration 9300 (19.07 iter/s, 5.24383s/100 iters), loss = 0.346764
I1005 10:28:17.503419  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346764 (* 1 = 0.346764 loss)
I1005 10:28:17.503425  9385 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1005 10:28:22.744658  9385 solver.cpp:218] Iteration 9400 (19.0796 iter/s, 5.24121s/100 iters), loss = 0.328056
I1005 10:28:22.744688  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328056 (* 1 = 0.328056 loss)
I1005 10:28:22.744694  9385 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1005 10:28:27.721488  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:28:27.930555  9385 solver.cpp:330] Iteration 9500, Testing net (#0)
I1005 10:28:29.122258  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:28:29.171949  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7693
I1005 10:28:29.171973  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.711329 (* 1 = 0.711329 loss)
I1005 10:28:29.224254  9385 solver.cpp:218] Iteration 9500 (15.4332 iter/s, 6.47954s/100 iters), loss = 0.29628
I1005 10:28:29.224279  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29628 (* 1 = 0.29628 loss)
I1005 10:28:29.224287  9385 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1005 10:28:34.460703  9385 solver.cpp:218] Iteration 9600 (19.0971 iter/s, 5.23639s/100 iters), loss = 0.32796
I1005 10:28:34.460894  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32796 (* 1 = 0.32796 loss)
I1005 10:28:34.460916  9385 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1005 10:28:39.691745  9385 solver.cpp:218] Iteration 9700 (19.1174 iter/s, 5.23084s/100 iters), loss = 0.39409
I1005 10:28:39.691776  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39409 (* 1 = 0.39409 loss)
I1005 10:28:39.691786  9385 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1005 10:28:44.934173  9385 solver.cpp:218] Iteration 9800 (19.0753 iter/s, 5.24237s/100 iters), loss = 0.344748
I1005 10:28:44.934204  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344748 (* 1 = 0.344748 loss)
I1005 10:28:44.934212  9385 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1005 10:28:50.174733  9385 solver.cpp:218] Iteration 9900 (19.0821 iter/s, 5.2405s/100 iters), loss = 0.322821
I1005 10:28:50.174765  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322821 (* 1 = 0.322821 loss)
I1005 10:28:50.174774  9385 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1005 10:28:55.142933  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:28:55.359992  9385 solver.cpp:330] Iteration 10000, Testing net (#0)
I1005 10:28:56.545749  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:28:56.595394  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7176
I1005 10:28:56.595418  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.852742 (* 1 = 0.852742 loss)
I1005 10:28:56.647747  9385 solver.cpp:218] Iteration 10000 (15.4489 iter/s, 6.47296s/100 iters), loss = 0.276486
I1005 10:28:56.647778  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276486 (* 1 = 0.276486 loss)
I1005 10:28:56.647784  9385 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1005 10:29:01.892792  9385 solver.cpp:218] Iteration 10100 (19.0658 iter/s, 5.245s/100 iters), loss = 0.338625
I1005 10:29:01.892832  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338625 (* 1 = 0.338625 loss)
I1005 10:29:01.892838  9385 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1005 10:29:07.126451  9385 solver.cpp:218] Iteration 10200 (19.1074 iter/s, 5.23358s/100 iters), loss = 0.334417
I1005 10:29:07.126606  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334417 (* 1 = 0.334417 loss)
I1005 10:29:07.126615  9385 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1005 10:29:12.369529  9385 solver.cpp:218] Iteration 10300 (19.0734 iter/s, 5.2429s/100 iters), loss = 0.391438
I1005 10:29:12.369568  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391438 (* 1 = 0.391438 loss)
I1005 10:29:12.369575  9385 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1005 10:29:17.605715  9385 solver.cpp:218] Iteration 10400 (19.0981 iter/s, 5.23612s/100 iters), loss = 0.289693
I1005 10:29:17.605756  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289694 (* 1 = 0.289694 loss)
I1005 10:29:17.605760  9385 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1005 10:29:22.586635  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:29:22.795409  9385 solver.cpp:330] Iteration 10500, Testing net (#0)
I1005 10:29:23.981456  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:29:24.031143  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7621
I1005 10:29:24.031168  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.70614 (* 1 = 0.70614 loss)
I1005 10:29:24.083029  9385 solver.cpp:218] Iteration 10500 (15.4387 iter/s, 6.47725s/100 iters), loss = 0.235903
I1005 10:29:24.083053  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235904 (* 1 = 0.235904 loss)
I1005 10:29:24.083060  9385 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1005 10:29:29.323428  9385 solver.cpp:218] Iteration 10600 (19.0827 iter/s, 5.24035s/100 iters), loss = 0.272243
I1005 10:29:29.323468  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272243 (* 1 = 0.272243 loss)
I1005 10:29:29.323474  9385 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1005 10:29:34.572007  9385 solver.cpp:218] Iteration 10700 (19.053 iter/s, 5.24851s/100 iters), loss = 0.310294
I1005 10:29:34.572048  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310294 (* 1 = 0.310294 loss)
I1005 10:29:34.572055  9385 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1005 10:29:39.805536  9385 solver.cpp:218] Iteration 10800 (19.1078 iter/s, 5.23346s/100 iters), loss = 0.420865
I1005 10:29:39.805649  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420865 (* 1 = 0.420865 loss)
I1005 10:29:39.805655  9385 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1005 10:29:45.045775  9385 solver.cpp:218] Iteration 10900 (19.0836 iter/s, 5.24011s/100 iters), loss = 0.242575
I1005 10:29:45.045809  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242575 (* 1 = 0.242575 loss)
I1005 10:29:45.045827  9385 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1005 10:29:50.028275  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:29:50.238116  9385 solver.cpp:330] Iteration 11000, Testing net (#0)
I1005 10:29:51.425079  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:29:51.474547  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6963
I1005 10:29:51.474581  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05389 (* 1 = 1.05389 loss)
I1005 10:29:51.526612  9385 solver.cpp:218] Iteration 11000 (15.4303 iter/s, 6.48078s/100 iters), loss = 0.275652
I1005 10:29:51.526649  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275652 (* 1 = 0.275652 loss)
I1005 10:29:51.526657  9385 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1005 10:29:56.771137  9385 solver.cpp:218] Iteration 11100 (19.0677 iter/s, 5.24446s/100 iters), loss = 0.240104
I1005 10:29:56.771176  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240104 (* 1 = 0.240104 loss)
I1005 10:29:56.771183  9385 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1005 10:30:02.004312  9385 solver.cpp:218] Iteration 11200 (19.1091 iter/s, 5.23311s/100 iters), loss = 0.28577
I1005 10:30:02.004341  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285771 (* 1 = 0.285771 loss)
I1005 10:30:02.004348  9385 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1005 10:30:07.240411  9385 solver.cpp:218] Iteration 11300 (19.0984 iter/s, 5.23604s/100 iters), loss = 0.322694
I1005 10:30:07.240450  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322694 (* 1 = 0.322694 loss)
I1005 10:30:07.240460  9385 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1005 10:30:12.471014  9385 solver.cpp:218] Iteration 11400 (19.1185 iter/s, 5.23054s/100 iters), loss = 0.277042
I1005 10:30:12.471129  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277042 (* 1 = 0.277042 loss)
I1005 10:30:12.471161  9385 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1005 10:30:17.449017  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:30:17.657495  9385 solver.cpp:330] Iteration 11500, Testing net (#0)
I1005 10:30:18.842933  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:30:18.892357  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8032
I1005 10:30:18.892385  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.573948 (* 1 = 0.573948 loss)
I1005 10:30:18.945142  9385 solver.cpp:218] Iteration 11500 (15.4464 iter/s, 6.47399s/100 iters), loss = 0.184795
I1005 10:30:18.945171  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184795 (* 1 = 0.184795 loss)
I1005 10:30:18.945180  9385 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1005 10:30:24.182929  9385 solver.cpp:218] Iteration 11600 (19.0922 iter/s, 5.23774s/100 iters), loss = 0.293337
I1005 10:30:24.182960  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293337 (* 1 = 0.293337 loss)
I1005 10:30:24.182966  9385 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1005 10:30:29.424293  9385 solver.cpp:218] Iteration 11700 (19.0792 iter/s, 5.24131s/100 iters), loss = 0.31749
I1005 10:30:29.424332  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31749 (* 1 = 0.31749 loss)
I1005 10:30:29.424338  9385 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1005 10:30:34.666834  9385 solver.cpp:218] Iteration 11800 (19.075 iter/s, 5.24247s/100 iters), loss = 0.414221
I1005 10:30:34.666874  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414222 (* 1 = 0.414222 loss)
I1005 10:30:34.666880  9385 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1005 10:30:39.893795  9385 solver.cpp:218] Iteration 11900 (19.1318 iter/s, 5.22689s/100 iters), loss = 0.245328
I1005 10:30:39.893836  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245328 (* 1 = 0.245328 loss)
I1005 10:30:39.893841  9385 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1005 10:30:44.878113  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:30:45.087652  9385 solver.cpp:330] Iteration 12000, Testing net (#0)
I1005 10:30:46.278847  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:30:46.328888  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7553
I1005 10:30:46.328925  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.836033 (* 1 = 0.836033 loss)
I1005 10:30:46.382007  9385 solver.cpp:218] Iteration 12000 (15.4127 iter/s, 6.48815s/100 iters), loss = 0.281961
I1005 10:30:46.382040  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281961 (* 1 = 0.281961 loss)
I1005 10:30:46.382048  9385 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1005 10:30:51.612803  9385 solver.cpp:218] Iteration 12100 (19.1178 iter/s, 5.23074s/100 iters), loss = 0.272631
I1005 10:30:51.612833  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272631 (* 1 = 0.272631 loss)
I1005 10:30:51.612839  9385 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1005 10:30:56.847290  9385 solver.cpp:218] Iteration 12200 (19.1043 iter/s, 5.23443s/100 iters), loss = 0.355572
I1005 10:30:56.847318  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355572 (* 1 = 0.355572 loss)
I1005 10:30:56.847324  9385 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1005 10:31:02.084481  9385 solver.cpp:218] Iteration 12300 (19.0944 iter/s, 5.23714s/100 iters), loss = 0.366975
I1005 10:31:02.084511  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366975 (* 1 = 0.366975 loss)
I1005 10:31:02.084516  9385 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1005 10:31:07.318722  9385 solver.cpp:218] Iteration 12400 (19.1052 iter/s, 5.23418s/100 iters), loss = 0.221171
I1005 10:31:07.318756  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221171 (* 1 = 0.221171 loss)
I1005 10:31:07.318764  9385 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1005 10:31:12.298102  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:31:12.507504  9385 solver.cpp:330] Iteration 12500, Testing net (#0)
I1005 10:31:13.701316  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:31:13.751008  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7756
I1005 10:31:13.751044  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687542 (* 1 = 0.687542 loss)
I1005 10:31:13.803098  9385 solver.cpp:218] Iteration 12500 (15.4218 iter/s, 6.48432s/100 iters), loss = 0.266782
I1005 10:31:13.803125  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266782 (* 1 = 0.266782 loss)
I1005 10:31:13.803133  9385 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1005 10:31:19.044008  9385 solver.cpp:218] Iteration 12600 (19.0809 iter/s, 5.24086s/100 iters), loss = 0.41428
I1005 10:31:19.044126  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41428 (* 1 = 0.41428 loss)
I1005 10:31:19.044133  9385 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1005 10:31:24.296727  9385 solver.cpp:218] Iteration 12700 (19.0383 iter/s, 5.25258s/100 iters), loss = 0.313411
I1005 10:31:24.296767  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313411 (* 1 = 0.313411 loss)
I1005 10:31:24.296773  9385 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1005 10:31:29.547554  9385 solver.cpp:218] Iteration 12800 (19.0449 iter/s, 5.25076s/100 iters), loss = 0.346266
I1005 10:31:29.547583  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346266 (* 1 = 0.346266 loss)
I1005 10:31:29.547590  9385 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1005 10:31:34.799456  9385 solver.cpp:218] Iteration 12900 (19.0409 iter/s, 5.25185s/100 iters), loss = 0.280389
I1005 10:31:34.799497  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280389 (* 1 = 0.280389 loss)
I1005 10:31:34.799504  9385 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1005 10:31:39.779973  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:31:39.989286  9385 solver.cpp:330] Iteration 13000, Testing net (#0)
I1005 10:31:41.183573  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:31:41.233597  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7294
I1005 10:31:41.233623  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.906559 (* 1 = 0.906559 loss)
I1005 10:31:41.286159  9385 solver.cpp:218] Iteration 13000 (15.4163 iter/s, 6.48663s/100 iters), loss = 0.202189
I1005 10:31:41.286185  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202189 (* 1 = 0.202189 loss)
I1005 10:31:41.286191  9385 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1005 10:31:46.533442  9385 solver.cpp:218] Iteration 13100 (19.0577 iter/s, 5.24723s/100 iters), loss = 0.319531
I1005 10:31:46.533474  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319531 (* 1 = 0.319531 loss)
I1005 10:31:46.533481  9385 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1005 10:31:51.776046  9385 solver.cpp:218] Iteration 13200 (19.0747 iter/s, 5.24255s/100 iters), loss = 0.336278
I1005 10:31:51.776192  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336279 (* 1 = 0.336279 loss)
I1005 10:31:51.776201  9385 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1005 10:31:57.026931  9385 solver.cpp:218] Iteration 13300 (19.045 iter/s, 5.25072s/100 iters), loss = 0.309676
I1005 10:31:57.026959  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309676 (* 1 = 0.309676 loss)
I1005 10:31:57.026965  9385 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1005 10:32:02.277730  9385 solver.cpp:218] Iteration 13400 (19.0449 iter/s, 5.25075s/100 iters), loss = 0.391496
I1005 10:32:02.277760  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391496 (* 1 = 0.391496 loss)
I1005 10:32:02.277765  9385 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1005 10:32:07.267668  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:32:07.482095  9385 solver.cpp:330] Iteration 13500, Testing net (#0)
I1005 10:32:08.670308  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:32:08.720145  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6489
I1005 10:32:08.720180  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.54986 (* 1 = 1.54986 loss)
I1005 10:32:08.772481  9385 solver.cpp:218] Iteration 13500 (15.3972 iter/s, 6.4947s/100 iters), loss = 0.223527
I1005 10:32:08.772505  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223527 (* 1 = 0.223527 loss)
I1005 10:32:08.772511  9385 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1005 10:32:14.025777  9385 solver.cpp:218] Iteration 13600 (19.0358 iter/s, 5.25325s/100 iters), loss = 0.246138
I1005 10:32:14.025809  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246138 (* 1 = 0.246138 loss)
I1005 10:32:14.025815  9385 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1005 10:32:19.274961  9385 solver.cpp:218] Iteration 13700 (19.0508 iter/s, 5.24913s/100 iters), loss = 0.276218
I1005 10:32:19.274996  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276218 (* 1 = 0.276218 loss)
I1005 10:32:19.275003  9385 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1005 10:32:24.520561  9385 solver.cpp:218] Iteration 13800 (19.0638 iter/s, 5.24554s/100 iters), loss = 0.330701
I1005 10:32:24.520654  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330701 (* 1 = 0.330701 loss)
I1005 10:32:24.520673  9385 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1005 10:32:29.766343  9385 solver.cpp:218] Iteration 13900 (19.0634 iter/s, 5.24567s/100 iters), loss = 0.211128
I1005 10:32:29.766371  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211128 (* 1 = 0.211128 loss)
I1005 10:32:29.766377  9385 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1005 10:32:34.753837  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:32:34.963276  9385 solver.cpp:330] Iteration 14000, Testing net (#0)
I1005 10:32:36.151705  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:32:36.201174  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8028
I1005 10:32:36.201208  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.608575 (* 1 = 0.608575 loss)
I1005 10:32:36.253283  9385 solver.cpp:218] Iteration 14000 (15.4157 iter/s, 6.48689s/100 iters), loss = 0.261273
I1005 10:32:36.253316  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261273 (* 1 = 0.261273 loss)
I1005 10:32:36.253324  9385 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1005 10:32:41.497081  9385 solver.cpp:218] Iteration 14100 (19.0703 iter/s, 5.24374s/100 iters), loss = 0.331558
I1005 10:32:41.497112  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331558 (* 1 = 0.331558 loss)
I1005 10:32:41.497117  9385 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1005 10:32:46.746561  9385 solver.cpp:218] Iteration 14200 (19.0497 iter/s, 5.24942s/100 iters), loss = 0.359538
I1005 10:32:46.746590  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359538 (* 1 = 0.359538 loss)
I1005 10:32:46.746596  9385 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1005 10:32:51.983871  9385 solver.cpp:218] Iteration 14300 (19.094 iter/s, 5.23726s/100 iters), loss = 0.253469
I1005 10:32:51.983901  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253469 (* 1 = 0.253469 loss)
I1005 10:32:51.983908  9385 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1005 10:32:57.229234  9385 solver.cpp:218] Iteration 14400 (19.0647 iter/s, 5.24531s/100 iters), loss = 0.408679
I1005 10:32:57.229341  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408679 (* 1 = 0.408679 loss)
I1005 10:32:57.229358  9385 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1005 10:33:02.219095  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:33:02.428338  9385 solver.cpp:330] Iteration 14500, Testing net (#0)
I1005 10:33:03.617071  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:33:03.666649  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6893
I1005 10:33:03.666683  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.960842 (* 1 = 0.960842 loss)
I1005 10:33:03.718806  9385 solver.cpp:218] Iteration 14500 (15.4096 iter/s, 6.48945s/100 iters), loss = 0.307092
I1005 10:33:03.718832  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307093 (* 1 = 0.307093 loss)
I1005 10:33:03.718837  9385 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1005 10:33:08.968184  9385 solver.cpp:218] Iteration 14600 (19.0501 iter/s, 5.24933s/100 iters), loss = 0.271633
I1005 10:33:08.968225  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271633 (* 1 = 0.271633 loss)
I1005 10:33:08.968231  9385 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1005 10:33:14.219774  9385 solver.cpp:218] Iteration 14700 (19.0421 iter/s, 5.25152s/100 iters), loss = 0.374572
I1005 10:33:14.219805  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374572 (* 1 = 0.374572 loss)
I1005 10:33:14.219810  9385 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1005 10:33:19.463768  9385 solver.cpp:218] Iteration 14800 (19.0696 iter/s, 5.24394s/100 iters), loss = 0.272248
I1005 10:33:19.463801  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272248 (* 1 = 0.272248 loss)
I1005 10:33:19.463809  9385 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1005 10:33:24.697511  9385 solver.cpp:218] Iteration 14900 (19.1071 iter/s, 5.23365s/100 iters), loss = 0.282696
I1005 10:33:24.697540  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282696 (* 1 = 0.282696 loss)
I1005 10:33:24.697546  9385 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1005 10:33:29.683104  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:33:29.892171  9385 solver.cpp:330] Iteration 15000, Testing net (#0)
I1005 10:33:31.079123  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:33:31.128777  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7777
I1005 10:33:31.128801  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.676293 (* 1 = 0.676293 loss)
I1005 10:33:31.180892  9385 solver.cpp:218] Iteration 15000 (15.4242 iter/s, 6.48332s/100 iters), loss = 0.281056
I1005 10:33:31.180927  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281056 (* 1 = 0.281056 loss)
I1005 10:33:31.180935  9385 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1005 10:33:36.430872  9385 solver.cpp:218] Iteration 15100 (19.0479 iter/s, 5.24992s/100 iters), loss = 0.336887
I1005 10:33:36.430902  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336887 (* 1 = 0.336887 loss)
I1005 10:33:36.430907  9385 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1005 10:33:41.680826  9385 solver.cpp:218] Iteration 15200 (19.048 iter/s, 5.2499s/100 iters), loss = 0.184699
I1005 10:33:41.680866  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1847 (* 1 = 0.1847 loss)
I1005 10:33:41.680872  9385 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1005 10:33:46.927588  9385 solver.cpp:218] Iteration 15300 (19.0596 iter/s, 5.2467s/100 iters), loss = 0.239908
I1005 10:33:46.927616  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239908 (* 1 = 0.239908 loss)
I1005 10:33:46.927623  9385 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1005 10:33:52.163913  9385 solver.cpp:218] Iteration 15400 (19.0976 iter/s, 5.23627s/100 iters), loss = 0.233724
I1005 10:33:52.163944  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233724 (* 1 = 0.233724 loss)
I1005 10:33:52.163949  9385 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1005 10:33:57.154021  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:33:57.363292  9385 solver.cpp:330] Iteration 15500, Testing net (#0)
I1005 10:33:58.561450  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:33:58.610711  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7125
I1005 10:33:58.610745  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.960931 (* 1 = 0.960931 loss)
I1005 10:33:58.663188  9385 solver.cpp:218] Iteration 15500 (15.3865 iter/s, 6.49922s/100 iters), loss = 0.325452
I1005 10:33:58.663218  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325452 (* 1 = 0.325452 loss)
I1005 10:33:58.663225  9385 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1005 10:34:03.902070  9385 solver.cpp:218] Iteration 15600 (19.0882 iter/s, 5.23883s/100 iters), loss = 0.242759
I1005 10:34:03.902165  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242759 (* 1 = 0.242759 loss)
I1005 10:34:03.902186  9385 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1005 10:34:09.143915  9385 solver.cpp:218] Iteration 15700 (19.0777 iter/s, 5.24173s/100 iters), loss = 0.309616
I1005 10:34:09.143944  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309616 (* 1 = 0.309616 loss)
I1005 10:34:09.143949  9385 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1005 10:34:14.385527  9385 solver.cpp:218] Iteration 15800 (19.0783 iter/s, 5.24156s/100 iters), loss = 0.271586
I1005 10:34:14.385556  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271586 (* 1 = 0.271586 loss)
I1005 10:34:14.385565  9385 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1005 10:34:19.628753  9385 solver.cpp:218] Iteration 15900 (19.0724 iter/s, 5.24317s/100 iters), loss = 0.277546
I1005 10:34:19.628782  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277546 (* 1 = 0.277546 loss)
I1005 10:34:19.628788  9385 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1005 10:34:24.614186  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:34:24.824489  9385 solver.cpp:330] Iteration 16000, Testing net (#0)
I1005 10:34:26.023859  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:34:26.073400  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7639
I1005 10:34:26.073433  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.727456 (* 1 = 0.727456 loss)
I1005 10:34:26.125880  9385 solver.cpp:218] Iteration 16000 (15.3916 iter/s, 6.49707s/100 iters), loss = 0.248342
I1005 10:34:26.125918  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248342 (* 1 = 0.248342 loss)
I1005 10:34:26.125926  9385 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1005 10:34:31.375656  9385 solver.cpp:218] Iteration 16100 (19.0487 iter/s, 5.24971s/100 iters), loss = 0.248121
I1005 10:34:31.375695  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248121 (* 1 = 0.248121 loss)
I1005 10:34:31.375705  9385 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1005 10:34:36.618163  9385 solver.cpp:218] Iteration 16200 (19.0751 iter/s, 5.24244s/100 iters), loss = 0.306044
I1005 10:34:36.618304  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306044 (* 1 = 0.306044 loss)
I1005 10:34:36.618312  9385 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1005 10:34:41.869165  9385 solver.cpp:218] Iteration 16300 (19.0446 iter/s, 5.25084s/100 iters), loss = 0.295839
I1005 10:34:41.869205  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295839 (* 1 = 0.295839 loss)
I1005 10:34:41.869211  9385 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1005 10:34:47.116801  9385 solver.cpp:218] Iteration 16400 (19.0564 iter/s, 5.24757s/100 iters), loss = 0.351876
I1005 10:34:47.116829  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351876 (* 1 = 0.351876 loss)
I1005 10:34:47.116835  9385 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1005 10:34:52.099306  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:34:52.311532  9385 solver.cpp:330] Iteration 16500, Testing net (#0)
I1005 10:34:53.504688  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:34:53.553990  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7524
I1005 10:34:53.554024  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.831624 (* 1 = 0.831624 loss)
I1005 10:34:53.606225  9385 solver.cpp:218] Iteration 16500 (15.4098 iter/s, 6.48937s/100 iters), loss = 0.267063
I1005 10:34:53.606253  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267063 (* 1 = 0.267063 loss)
I1005 10:34:53.606261  9385 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1005 10:34:58.857003  9385 solver.cpp:218] Iteration 16600 (19.045 iter/s, 5.25072s/100 iters), loss = 0.331026
I1005 10:34:58.857043  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331026 (* 1 = 0.331026 loss)
I1005 10:34:58.857048  9385 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1005 10:35:04.101385  9385 solver.cpp:218] Iteration 16700 (19.0683 iter/s, 5.24432s/100 iters), loss = 0.293682
I1005 10:35:04.101425  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293682 (* 1 = 0.293682 loss)
I1005 10:35:04.101431  9385 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1005 10:35:09.345083  9385 solver.cpp:218] Iteration 16800 (19.0707 iter/s, 5.24364s/100 iters), loss = 0.389596
I1005 10:35:09.345221  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389596 (* 1 = 0.389596 loss)
I1005 10:35:09.345229  9385 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1005 10:35:14.592207  9385 solver.cpp:218] Iteration 16900 (19.0586 iter/s, 5.24696s/100 iters), loss = 0.302391
I1005 10:35:14.592242  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302391 (* 1 = 0.302391 loss)
I1005 10:35:14.592259  9385 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1005 10:35:19.584920  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:35:19.792995  9385 solver.cpp:330] Iteration 17000, Testing net (#0)
I1005 10:35:20.982707  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:35:21.032707  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7188
I1005 10:35:21.032732  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.915068 (* 1 = 0.915068 loss)
I1005 10:35:21.084846  9385 solver.cpp:218] Iteration 17000 (15.4022 iter/s, 6.49259s/100 iters), loss = 0.261683
I1005 10:35:21.084873  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261683 (* 1 = 0.261683 loss)
I1005 10:35:21.084880  9385 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1005 10:35:26.332334  9385 solver.cpp:218] Iteration 17100 (19.0569 iter/s, 5.24744s/100 iters), loss = 0.273864
I1005 10:35:26.332362  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273864 (* 1 = 0.273864 loss)
I1005 10:35:26.332368  9385 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1005 10:35:31.588943  9385 solver.cpp:218] Iteration 17200 (19.0239 iter/s, 5.25656s/100 iters), loss = 0.353536
I1005 10:35:31.588999  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353536 (* 1 = 0.353536 loss)
I1005 10:35:31.589007  9385 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1005 10:35:36.829440  9385 solver.cpp:218] Iteration 17300 (19.0824 iter/s, 5.24042s/100 iters), loss = 0.253752
I1005 10:35:36.829471  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253752 (* 1 = 0.253752 loss)
I1005 10:35:36.829478  9385 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1005 10:35:42.068557  9385 solver.cpp:218] Iteration 17400 (19.0874 iter/s, 5.23906s/100 iters), loss = 0.185995
I1005 10:35:42.068717  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185995 (* 1 = 0.185995 loss)
I1005 10:35:42.068725  9385 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1005 10:35:47.056013  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:35:47.264322  9385 solver.cpp:330] Iteration 17500, Testing net (#0)
I1005 10:35:48.452267  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:35:48.502123  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7481
I1005 10:35:48.502147  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.776165 (* 1 = 0.776165 loss)
I1005 10:35:48.554276  9385 solver.cpp:218] Iteration 17500 (15.4189 iter/s, 6.48554s/100 iters), loss = 0.268106
I1005 10:35:48.554301  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268106 (* 1 = 0.268106 loss)
I1005 10:35:48.554307  9385 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1005 10:35:53.802336  9385 solver.cpp:218] Iteration 17600 (19.0548 iter/s, 5.24801s/100 iters), loss = 0.355229
I1005 10:35:53.802366  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355228 (* 1 = 0.355228 loss)
I1005 10:35:53.802373  9385 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1005 10:35:59.054291  9385 solver.cpp:218] Iteration 17700 (19.0407 iter/s, 5.2519s/100 iters), loss = 0.288837
I1005 10:35:59.054322  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288837 (* 1 = 0.288837 loss)
I1005 10:35:59.054328  9385 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1005 10:36:04.300886  9385 solver.cpp:218] Iteration 17800 (19.0602 iter/s, 5.24654s/100 iters), loss = 0.353472
I1005 10:36:04.300925  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353471 (* 1 = 0.353471 loss)
I1005 10:36:04.300931  9385 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1005 10:36:09.544296  9385 solver.cpp:218] Iteration 17900 (19.0718 iter/s, 5.24335s/100 iters), loss = 0.246482
I1005 10:36:09.544335  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246482 (* 1 = 0.246482 loss)
I1005 10:36:09.544340  9385 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1005 10:36:14.541589  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:36:14.751193  9385 solver.cpp:330] Iteration 18000, Testing net (#0)
I1005 10:36:15.938673  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:36:15.988239  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7044
I1005 10:36:15.988265  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01259 (* 1 = 1.01259 loss)
I1005 10:36:16.040805  9385 solver.cpp:218] Iteration 18000 (15.393 iter/s, 6.49645s/100 iters), loss = 0.20265
I1005 10:36:16.040834  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20265 (* 1 = 0.20265 loss)
I1005 10:36:16.040841  9385 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1005 10:36:21.293622  9385 solver.cpp:218] Iteration 18100 (19.0376 iter/s, 5.25276s/100 iters), loss = 0.29285
I1005 10:36:21.293660  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29285 (* 1 = 0.29285 loss)
I1005 10:36:21.293666  9385 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1005 10:36:26.541893  9385 solver.cpp:218] Iteration 18200 (19.0541 iter/s, 5.24821s/100 iters), loss = 0.260926
I1005 10:36:26.541939  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260926 (* 1 = 0.260926 loss)
I1005 10:36:26.541946  9385 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1005 10:36:31.791079  9385 solver.cpp:218] Iteration 18300 (19.0508 iter/s, 5.24912s/100 iters), loss = 0.32878
I1005 10:36:31.791118  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328779 (* 1 = 0.328779 loss)
I1005 10:36:31.791123  9385 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1005 10:36:37.026932  9385 solver.cpp:218] Iteration 18400 (19.0993 iter/s, 5.23579s/100 iters), loss = 0.190587
I1005 10:36:37.026973  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190587 (* 1 = 0.190587 loss)
I1005 10:36:37.026978  9385 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1005 10:36:42.014185  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:36:42.223491  9385 solver.cpp:330] Iteration 18500, Testing net (#0)
I1005 10:36:43.418920  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:36:43.469511  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7738
I1005 10:36:43.469548  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.782893 (* 1 = 0.782893 loss)
I1005 10:36:43.522306  9385 solver.cpp:218] Iteration 18500 (15.3957 iter/s, 6.49531s/100 iters), loss = 0.203173
I1005 10:36:43.522342  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203173 (* 1 = 0.203173 loss)
I1005 10:36:43.522349  9385 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1005 10:36:48.759824  9385 solver.cpp:218] Iteration 18600 (19.0932 iter/s, 5.23746s/100 iters), loss = 0.308322
I1005 10:36:48.759980  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308322 (* 1 = 0.308322 loss)
I1005 10:36:48.760002  9385 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1005 10:36:54.008769  9385 solver.cpp:218] Iteration 18700 (19.0521 iter/s, 5.24877s/100 iters), loss = 0.217059
I1005 10:36:54.008797  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217059 (* 1 = 0.217059 loss)
I1005 10:36:54.008805  9385 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1005 10:36:59.263345  9385 solver.cpp:218] Iteration 18800 (19.0312 iter/s, 5.25452s/100 iters), loss = 0.313756
I1005 10:36:59.263386  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313756 (* 1 = 0.313756 loss)
I1005 10:36:59.263392  9385 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1005 10:37:04.513770  9385 solver.cpp:218] Iteration 18900 (19.0463 iter/s, 5.25036s/100 iters), loss = 0.28372
I1005 10:37:04.513803  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28372 (* 1 = 0.28372 loss)
I1005 10:37:04.513809  9385 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1005 10:37:09.496779  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:37:09.706529  9385 solver.cpp:330] Iteration 19000, Testing net (#0)
I1005 10:37:10.904580  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:37:10.954324  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7757
I1005 10:37:10.954347  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.700311 (* 1 = 0.700311 loss)
I1005 10:37:11.006433  9385 solver.cpp:218] Iteration 19000 (15.4021 iter/s, 6.4926s/100 iters), loss = 0.185781
I1005 10:37:11.006464  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185781 (* 1 = 0.185781 loss)
I1005 10:37:11.006471  9385 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1005 10:37:16.246381  9385 solver.cpp:218] Iteration 19100 (19.0844 iter/s, 5.23989s/100 iters), loss = 0.265995
I1005 10:37:16.246423  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265995 (* 1 = 0.265995 loss)
I1005 10:37:16.246433  9385 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1005 10:37:21.493402  9385 solver.cpp:218] Iteration 19200 (19.0587 iter/s, 5.24696s/100 iters), loss = 0.311419
I1005 10:37:21.493528  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311419 (* 1 = 0.311419 loss)
I1005 10:37:21.493548  9385 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1005 10:37:26.743131  9385 solver.cpp:218] Iteration 19300 (19.0491 iter/s, 5.24959s/100 iters), loss = 0.306691
I1005 10:37:26.743161  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306691 (* 1 = 0.306691 loss)
I1005 10:37:26.743166  9385 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1005 10:37:31.986770  9385 solver.cpp:218] Iteration 19400 (19.0709 iter/s, 5.24358s/100 iters), loss = 0.302453
I1005 10:37:31.986807  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302453 (* 1 = 0.302453 loss)
I1005 10:37:31.986824  9385 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1005 10:37:36.970481  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:37:37.180907  9385 solver.cpp:330] Iteration 19500, Testing net (#0)
I1005 10:37:38.378931  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:37:38.428737  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7958
I1005 10:37:38.428772  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.630196 (* 1 = 0.630196 loss)
I1005 10:37:38.480993  9385 solver.cpp:218] Iteration 19500 (15.3984 iter/s, 6.49416s/100 iters), loss = 0.230549
I1005 10:37:38.481035  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230549 (* 1 = 0.230549 loss)
I1005 10:37:38.481042  9385 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1005 10:37:43.737884  9385 solver.cpp:218] Iteration 19600 (19.0229 iter/s, 5.25683s/100 iters), loss = 0.280733
I1005 10:37:43.737924  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280733 (* 1 = 0.280733 loss)
I1005 10:37:43.737931  9385 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1005 10:37:48.981109  9385 solver.cpp:218] Iteration 19700 (19.0725 iter/s, 5.24316s/100 iters), loss = 0.29563
I1005 10:37:48.981139  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29563 (* 1 = 0.29563 loss)
I1005 10:37:48.981144  9385 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1005 10:37:54.230917  9385 solver.cpp:218] Iteration 19800 (19.0485 iter/s, 5.24976s/100 iters), loss = 0.212891
I1005 10:37:54.231058  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21289 (* 1 = 0.21289 loss)
I1005 10:37:54.231076  9385 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1005 10:37:59.476502  9385 solver.cpp:218] Iteration 19900 (19.0642 iter/s, 5.24543s/100 iters), loss = 0.210678
I1005 10:37:59.476531  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210678 (* 1 = 0.210678 loss)
I1005 10:37:59.476548  9385 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1005 10:38:04.450973  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:38:04.661589  9385 solver.cpp:330] Iteration 20000, Testing net (#0)
I1005 10:38:05.849611  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:38:05.898938  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7553
I1005 10:38:05.898972  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.777331 (* 1 = 0.777331 loss)
I1005 10:38:05.951093  9385 solver.cpp:218] Iteration 20000 (15.4451 iter/s, 6.47454s/100 iters), loss = 0.184623
I1005 10:38:05.951128  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184623 (* 1 = 0.184623 loss)
I1005 10:38:05.951134  9385 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1005 10:38:11.199241  9385 solver.cpp:218] Iteration 20100 (19.0546 iter/s, 5.24809s/100 iters), loss = 0.282931
I1005 10:38:11.199272  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28293 (* 1 = 0.28293 loss)
I1005 10:38:11.199278  9385 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1005 10:38:16.447628  9385 solver.cpp:218] Iteration 20200 (19.0537 iter/s, 5.24832s/100 iters), loss = 0.299827
I1005 10:38:16.447661  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299827 (* 1 = 0.299827 loss)
I1005 10:38:16.447669  9385 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1005 10:38:21.690589  9385 solver.cpp:218] Iteration 20300 (19.0734 iter/s, 5.24291s/100 iters), loss = 0.286452
I1005 10:38:21.690618  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286452 (* 1 = 0.286452 loss)
I1005 10:38:21.690624  9385 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1005 10:38:26.940306  9385 solver.cpp:218] Iteration 20400 (19.0488 iter/s, 5.24967s/100 iters), loss = 0.212594
I1005 10:38:26.940443  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212594 (* 1 = 0.212594 loss)
I1005 10:38:26.940450  9385 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1005 10:38:31.934334  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:38:32.144865  9385 solver.cpp:330] Iteration 20500, Testing net (#0)
I1005 10:38:33.331724  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:38:33.381641  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7661
I1005 10:38:33.381677  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710532 (* 1 = 0.710532 loss)
I1005 10:38:33.433815  9385 solver.cpp:218] Iteration 20500 (15.4004 iter/s, 6.49335s/100 iters), loss = 0.155684
I1005 10:38:33.433840  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155684 (* 1 = 0.155684 loss)
I1005 10:38:33.433846  9385 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1005 10:38:38.689507  9385 solver.cpp:218] Iteration 20600 (19.0272 iter/s, 5.25564s/100 iters), loss = 0.243538
I1005 10:38:38.689546  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243538 (* 1 = 0.243538 loss)
I1005 10:38:38.689553  9385 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1005 10:38:43.938555  9385 solver.cpp:218] Iteration 20700 (19.0513 iter/s, 5.24899s/100 iters), loss = 0.304334
I1005 10:38:43.938585  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304334 (* 1 = 0.304334 loss)
I1005 10:38:43.938591  9385 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1005 10:38:49.181969  9385 solver.cpp:218] Iteration 20800 (19.0717 iter/s, 5.24336s/100 iters), loss = 0.326478
I1005 10:38:49.182000  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326478 (* 1 = 0.326478 loss)
I1005 10:38:49.182006  9385 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1005 10:38:54.422906  9385 solver.cpp:218] Iteration 20900 (19.0807 iter/s, 5.24089s/100 iters), loss = 0.216495
I1005 10:38:54.422935  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216495 (* 1 = 0.216495 loss)
I1005 10:38:54.422940  9385 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1005 10:38:59.408251  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:38:59.617537  9385 solver.cpp:330] Iteration 21000, Testing net (#0)
I1005 10:39:00.806834  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:39:00.856907  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7811
I1005 10:39:00.856932  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.709943 (* 1 = 0.709943 loss)
I1005 10:39:00.909451  9385 solver.cpp:218] Iteration 21000 (15.4167 iter/s, 6.48649s/100 iters), loss = 0.173172
I1005 10:39:00.909482  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173172 (* 1 = 0.173172 loss)
I1005 10:39:00.909488  9385 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1005 10:39:06.160058  9385 solver.cpp:218] Iteration 21100 (19.0456 iter/s, 5.25055s/100 iters), loss = 0.19827
I1005 10:39:06.160089  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19827 (* 1 = 0.19827 loss)
I1005 10:39:06.160095  9385 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1005 10:39:11.410259  9385 solver.cpp:218] Iteration 21200 (19.0471 iter/s, 5.25015s/100 iters), loss = 0.222199
I1005 10:39:11.410298  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222199 (* 1 = 0.222199 loss)
I1005 10:39:11.410305  9385 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1005 10:39:16.668025  9385 solver.cpp:218] Iteration 21300 (19.0197 iter/s, 5.2577s/100 iters), loss = 0.302534
I1005 10:39:16.668056  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302534 (* 1 = 0.302534 loss)
I1005 10:39:16.668063  9385 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1005 10:39:21.906420  9385 solver.cpp:218] Iteration 21400 (19.09 iter/s, 5.23834s/100 iters), loss = 0.177803
I1005 10:39:21.906451  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177803 (* 1 = 0.177803 loss)
I1005 10:39:21.906457  9385 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1005 10:39:26.896792  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:39:27.107182  9385 solver.cpp:330] Iteration 21500, Testing net (#0)
I1005 10:39:28.298071  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:39:28.348692  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7477
I1005 10:39:28.348719  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.823152 (* 1 = 0.823152 loss)
I1005 10:39:28.402974  9385 solver.cpp:218] Iteration 21500 (15.3929 iter/s, 6.49649s/100 iters), loss = 0.21871
I1005 10:39:28.403033  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21871 (* 1 = 0.21871 loss)
I1005 10:39:28.403041  9385 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1005 10:39:33.648766  9385 solver.cpp:218] Iteration 21600 (19.0633 iter/s, 5.24567s/100 iters), loss = 0.18275
I1005 10:39:33.648893  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182749 (* 1 = 0.182749 loss)
I1005 10:39:33.648900  9385 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1005 10:39:38.901300  9385 solver.cpp:218] Iteration 21700 (19.039 iter/s, 5.25239s/100 iters), loss = 0.20043
I1005 10:39:38.901330  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20043 (* 1 = 0.20043 loss)
I1005 10:39:38.901336  9385 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1005 10:39:44.149979  9385 solver.cpp:218] Iteration 21800 (19.0526 iter/s, 5.24863s/100 iters), loss = 0.320825
I1005 10:39:44.150018  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320825 (* 1 = 0.320825 loss)
I1005 10:39:44.150024  9385 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1005 10:39:49.386307  9385 solver.cpp:218] Iteration 21900 (19.0976 iter/s, 5.23626s/100 iters), loss = 0.177079
I1005 10:39:49.386343  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177079 (* 1 = 0.177079 loss)
I1005 10:39:49.386349  9385 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1005 10:39:54.368561  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:39:54.578197  9385 solver.cpp:330] Iteration 22000, Testing net (#0)
I1005 10:39:55.774682  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:39:55.824615  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6638
I1005 10:39:55.824651  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.19653 (* 1 = 1.19653 loss)
I1005 10:39:55.876665  9385 solver.cpp:218] Iteration 22000 (15.4077 iter/s, 6.49027s/100 iters), loss = 0.190487
I1005 10:39:55.876689  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190487 (* 1 = 0.190487 loss)
I1005 10:39:55.876696  9385 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1005 10:40:01.119248  9385 solver.cpp:218] Iteration 22100 (19.0747 iter/s, 5.24254s/100 iters), loss = 0.270155
I1005 10:40:01.119277  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270155 (* 1 = 0.270155 loss)
I1005 10:40:01.119284  9385 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1005 10:40:06.376335  9385 solver.cpp:218] Iteration 22200 (19.0221 iter/s, 5.25703s/100 iters), loss = 0.216745
I1005 10:40:06.376448  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216745 (* 1 = 0.216745 loss)
I1005 10:40:06.376456  9385 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1005 10:40:11.631386  9385 solver.cpp:218] Iteration 22300 (19.0298 iter/s, 5.25492s/100 iters), loss = 0.336066
I1005 10:40:11.631425  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336066 (* 1 = 0.336066 loss)
I1005 10:40:11.631431  9385 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1005 10:40:16.879539  9385 solver.cpp:218] Iteration 22400 (19.0545 iter/s, 5.24809s/100 iters), loss = 0.140147
I1005 10:40:16.879567  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140147 (* 1 = 0.140147 loss)
I1005 10:40:16.879573  9385 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1005 10:40:21.863962  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:40:22.073654  9385 solver.cpp:330] Iteration 22500, Testing net (#0)
I1005 10:40:23.271713  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:40:23.321424  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6807
I1005 10:40:23.321449  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04681 (* 1 = 1.04681 loss)
I1005 10:40:23.373358  9385 solver.cpp:218] Iteration 22500 (15.3994 iter/s, 6.49377s/100 iters), loss = 0.244936
I1005 10:40:23.373383  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244936 (* 1 = 0.244936 loss)
I1005 10:40:23.373389  9385 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1005 10:40:28.623317  9385 solver.cpp:218] Iteration 22600 (19.048 iter/s, 5.2499s/100 iters), loss = 0.261504
I1005 10:40:28.623347  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261504 (* 1 = 0.261504 loss)
I1005 10:40:28.623363  9385 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1005 10:40:33.868119  9385 solver.cpp:218] Iteration 22700 (19.0667 iter/s, 5.24475s/100 iters), loss = 0.271669
I1005 10:40:33.868150  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271669 (* 1 = 0.271669 loss)
I1005 10:40:33.868157  9385 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1005 10:40:39.118616  9385 solver.cpp:218] Iteration 22800 (19.046 iter/s, 5.25045s/100 iters), loss = 0.265251
I1005 10:40:39.118749  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265251 (* 1 = 0.265251 loss)
I1005 10:40:39.118772  9385 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1005 10:40:44.363659  9385 solver.cpp:218] Iteration 22900 (19.0661 iter/s, 5.2449s/100 iters), loss = 0.183318
I1005 10:40:44.363690  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183317 (* 1 = 0.183317 loss)
I1005 10:40:44.363698  9385 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1005 10:40:49.350214  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:40:49.563974  9385 solver.cpp:330] Iteration 23000, Testing net (#0)
I1005 10:40:50.749173  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:40:50.798475  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7116
I1005 10:40:50.798496  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.941756 (* 1 = 0.941756 loss)
I1005 10:40:50.850528  9385 solver.cpp:218] Iteration 23000 (15.4159 iter/s, 6.48681s/100 iters), loss = 0.206943
I1005 10:40:50.850553  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206943 (* 1 = 0.206943 loss)
I1005 10:40:50.850559  9385 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1005 10:40:56.101402  9385 solver.cpp:218] Iteration 23100 (19.0446 iter/s, 5.25083s/100 iters), loss = 0.224897
I1005 10:40:56.101430  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224897 (* 1 = 0.224897 loss)
I1005 10:40:56.101436  9385 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1005 10:41:01.347909  9385 solver.cpp:218] Iteration 23200 (19.0605 iter/s, 5.24645s/100 iters), loss = 0.198359
I1005 10:41:01.347955  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198359 (* 1 = 0.198359 loss)
I1005 10:41:01.347964  9385 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1005 10:41:06.597162  9385 solver.cpp:218] Iteration 23300 (19.0507 iter/s, 5.24915s/100 iters), loss = 0.274714
I1005 10:41:06.597192  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274714 (* 1 = 0.274714 loss)
I1005 10:41:06.597196  9385 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1005 10:41:11.846935  9385 solver.cpp:218] Iteration 23400 (19.0486 iter/s, 5.24972s/100 iters), loss = 0.169517
I1005 10:41:11.847074  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169516 (* 1 = 0.169516 loss)
I1005 10:41:11.847095  9385 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1005 10:41:16.837483  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:41:17.047065  9385 solver.cpp:330] Iteration 23500, Testing net (#0)
I1005 10:41:18.231271  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:41:18.280321  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.766
I1005 10:41:18.280344  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.730479 (* 1 = 0.730479 loss)
I1005 10:41:18.332953  9385 solver.cpp:218] Iteration 23500 (15.4182 iter/s, 6.48586s/100 iters), loss = 0.218835
I1005 10:41:18.332980  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218834 (* 1 = 0.218834 loss)
I1005 10:41:18.332988  9385 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1005 10:41:23.577013  9385 solver.cpp:218] Iteration 23600 (19.0694 iter/s, 5.24401s/100 iters), loss = 0.209431
I1005 10:41:23.577054  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209431 (* 1 = 0.209431 loss)
I1005 10:41:23.577059  9385 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1005 10:41:28.822757  9385 solver.cpp:218] Iteration 23700 (19.0633 iter/s, 5.24568s/100 iters), loss = 0.266026
I1005 10:41:28.822796  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266026 (* 1 = 0.266026 loss)
I1005 10:41:28.822801  9385 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1005 10:41:34.061312  9385 solver.cpp:218] Iteration 23800 (19.0895 iter/s, 5.23849s/100 iters), loss = 0.352229
I1005 10:41:34.061352  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352229 (* 1 = 0.352229 loss)
I1005 10:41:34.061358  9385 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1005 10:41:39.305678  9385 solver.cpp:218] Iteration 23900 (19.0683 iter/s, 5.24431s/100 iters), loss = 0.263719
I1005 10:41:39.305711  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263719 (* 1 = 0.263719 loss)
I1005 10:41:39.305719  9385 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1005 10:41:44.295312  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:41:44.505177  9385 solver.cpp:330] Iteration 24000, Testing net (#0)
I1005 10:41:45.692997  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:41:45.742738  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7073
I1005 10:41:45.742763  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15823 (* 1 = 1.15823 loss)
I1005 10:41:45.794981  9385 solver.cpp:218] Iteration 24000 (15.4101 iter/s, 6.48925s/100 iters), loss = 0.271602
I1005 10:41:45.795007  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271601 (* 1 = 0.271601 loss)
I1005 10:41:45.795017  9385 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1005 10:41:51.040572  9385 solver.cpp:218] Iteration 24100 (19.0638 iter/s, 5.24555s/100 iters), loss = 0.325756
I1005 10:41:51.040606  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325756 (* 1 = 0.325756 loss)
I1005 10:41:51.040614  9385 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1005 10:41:56.290143  9385 solver.cpp:218] Iteration 24200 (19.0494 iter/s, 5.24951s/100 iters), loss = 0.24383
I1005 10:41:56.290184  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24383 (* 1 = 0.24383 loss)
I1005 10:41:56.290200  9385 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1005 10:42:01.534772  9385 solver.cpp:218] Iteration 24300 (19.0674 iter/s, 5.24457s/100 iters), loss = 0.284608
I1005 10:42:01.534808  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284608 (* 1 = 0.284608 loss)
I1005 10:42:01.534817  9385 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1005 10:42:06.768774  9385 solver.cpp:218] Iteration 24400 (19.106 iter/s, 5.23395s/100 iters), loss = 0.258625
I1005 10:42:06.768805  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258625 (* 1 = 0.258625 loss)
I1005 10:42:06.768813  9385 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1005 10:42:11.751235  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:42:11.960290  9385 solver.cpp:330] Iteration 24500, Testing net (#0)
I1005 10:42:13.148903  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:42:13.198912  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7092
I1005 10:42:13.198937  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02902 (* 1 = 1.02902 loss)
I1005 10:42:13.251731  9385 solver.cpp:218] Iteration 24500 (15.4252 iter/s, 6.4829s/100 iters), loss = 0.20731
I1005 10:42:13.251775  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207309 (* 1 = 0.207309 loss)
I1005 10:42:13.251781  9385 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1005 10:42:18.496242  9385 solver.cpp:218] Iteration 24600 (19.0679 iter/s, 5.24441s/100 iters), loss = 0.285
I1005 10:42:18.496415  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285 (* 1 = 0.285 loss)
I1005 10:42:18.496425  9385 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1005 10:42:23.743264  9385 solver.cpp:218] Iteration 24700 (19.0591 iter/s, 5.24683s/100 iters), loss = 0.267084
I1005 10:42:23.743299  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267084 (* 1 = 0.267084 loss)
I1005 10:42:23.743306  9385 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1005 10:42:28.990377  9385 solver.cpp:218] Iteration 24800 (19.0583 iter/s, 5.24706s/100 iters), loss = 0.201452
I1005 10:42:28.990406  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201452 (* 1 = 0.201452 loss)
I1005 10:42:28.990422  9385 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1005 10:42:34.231161  9385 solver.cpp:218] Iteration 24900 (19.0813 iter/s, 5.24073s/100 iters), loss = 0.250066
I1005 10:42:34.231194  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250065 (* 1 = 0.250065 loss)
I1005 10:42:34.231210  9385 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1005 10:42:39.222198  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:42:39.432049  9385 solver.cpp:330] Iteration 25000, Testing net (#0)
I1005 10:42:40.629029  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:42:40.678735  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6987
I1005 10:42:40.678771  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14533 (* 1 = 1.14533 loss)
I1005 10:42:40.731171  9385 solver.cpp:218] Iteration 25000 (15.3847 iter/s, 6.49996s/100 iters), loss = 0.241694
I1005 10:42:40.731202  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241694 (* 1 = 0.241694 loss)
I1005 10:42:40.731209  9385 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1005 10:42:45.975448  9385 solver.cpp:218] Iteration 25100 (19.0686 iter/s, 5.24422s/100 iters), loss = 0.277949
I1005 10:42:45.975489  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277949 (* 1 = 0.277949 loss)
I1005 10:42:45.975495  9385 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1005 10:42:51.219321  9385 solver.cpp:218] Iteration 25200 (19.0701 iter/s, 5.24381s/100 iters), loss = 0.281242
I1005 10:42:51.219467  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281242 (* 1 = 0.281242 loss)
I1005 10:42:51.219475  9385 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1005 10:42:56.460871  9385 solver.cpp:218] Iteration 25300 (19.0789 iter/s, 5.2414s/100 iters), loss = 0.247572
I1005 10:42:56.460901  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247572 (* 1 = 0.247572 loss)
I1005 10:42:56.460906  9385 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1005 10:43:01.704072  9385 solver.cpp:218] Iteration 25400 (19.0725 iter/s, 5.24315s/100 iters), loss = 0.164964
I1005 10:43:01.704103  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164964 (* 1 = 0.164964 loss)
I1005 10:43:01.704109  9385 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1005 10:43:06.685030  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:43:06.893980  9385 solver.cpp:330] Iteration 25500, Testing net (#0)
I1005 10:43:08.090126  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:43:08.140034  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7285
I1005 10:43:08.140069  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.937775 (* 1 = 0.937775 loss)
I1005 10:43:08.192303  9385 solver.cpp:218] Iteration 25500 (15.4126 iter/s, 6.48818s/100 iters), loss = 0.165469
I1005 10:43:08.192329  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165469 (* 1 = 0.165469 loss)
I1005 10:43:08.192337  9385 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1005 10:43:13.444244  9385 solver.cpp:218] Iteration 25600 (19.0408 iter/s, 5.25189s/100 iters), loss = 0.314906
I1005 10:43:13.444280  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314906 (* 1 = 0.314906 loss)
I1005 10:43:13.444288  9385 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1005 10:43:18.687585  9385 solver.cpp:218] Iteration 25700 (19.072 iter/s, 5.24328s/100 iters), loss = 0.326173
I1005 10:43:18.687615  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326173 (* 1 = 0.326173 loss)
I1005 10:43:18.687621  9385 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1005 10:43:23.935901  9385 solver.cpp:218] Iteration 25800 (19.0539 iter/s, 5.24827s/100 iters), loss = 0.267024
I1005 10:43:23.936020  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267024 (* 1 = 0.267024 loss)
I1005 10:43:23.936028  9385 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1005 10:43:29.183248  9385 solver.cpp:218] Iteration 25900 (19.0577 iter/s, 5.24722s/100 iters), loss = 0.216584
I1005 10:43:29.183290  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216584 (* 1 = 0.216584 loss)
I1005 10:43:29.183295  9385 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1005 10:43:34.166863  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:43:34.381840  9385 solver.cpp:330] Iteration 26000, Testing net (#0)
I1005 10:43:35.574141  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:43:35.624050  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.777
I1005 10:43:35.624074  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.715408 (* 1 = 0.715408 loss)
I1005 10:43:35.676192  9385 solver.cpp:218] Iteration 26000 (15.4015 iter/s, 6.49288s/100 iters), loss = 0.239954
I1005 10:43:35.676223  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239954 (* 1 = 0.239954 loss)
I1005 10:43:35.676229  9385 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1005 10:43:40.922999  9385 solver.cpp:218] Iteration 26100 (19.0594 iter/s, 5.24676s/100 iters), loss = 0.195004
I1005 10:43:40.923032  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195004 (* 1 = 0.195004 loss)
I1005 10:43:40.923048  9385 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1005 10:43:46.165002  9385 solver.cpp:218] Iteration 26200 (19.0769 iter/s, 5.24195s/100 iters), loss = 0.282598
I1005 10:43:46.165032  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282597 (* 1 = 0.282597 loss)
I1005 10:43:46.165038  9385 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1005 10:43:51.412372  9385 solver.cpp:218] Iteration 26300 (19.0574 iter/s, 5.24732s/100 iters), loss = 0.19008
I1005 10:43:51.412401  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19008 (* 1 = 0.19008 loss)
I1005 10:43:51.412407  9385 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1005 10:43:56.657312  9385 solver.cpp:218] Iteration 26400 (19.0662 iter/s, 5.24489s/100 iters), loss = 0.169198
I1005 10:43:56.657449  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169198 (* 1 = 0.169198 loss)
I1005 10:43:56.657455  9385 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1005 10:44:01.650439  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:44:01.859797  9385 solver.cpp:330] Iteration 26500, Testing net (#0)
I1005 10:44:03.048725  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:44:03.098577  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6415
I1005 10:44:03.098601  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31515 (* 1 = 1.31515 loss)
I1005 10:44:03.150960  9385 solver.cpp:218] Iteration 26500 (15.4 iter/s, 6.49349s/100 iters), loss = 0.222317
I1005 10:44:03.150988  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222317 (* 1 = 0.222317 loss)
I1005 10:44:03.151008  9385 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1005 10:44:08.402776  9385 solver.cpp:218] Iteration 26600 (19.0412 iter/s, 5.25176s/100 iters), loss = 0.327394
I1005 10:44:08.402807  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327394 (* 1 = 0.327394 loss)
I1005 10:44:08.402825  9385 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1005 10:44:13.654265  9385 solver.cpp:218] Iteration 26700 (19.0424 iter/s, 5.25143s/100 iters), loss = 0.311535
I1005 10:44:13.654299  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311534 (* 1 = 0.311534 loss)
I1005 10:44:13.654320  9385 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1005 10:44:18.889686  9385 solver.cpp:218] Iteration 26800 (19.1009 iter/s, 5.23537s/100 iters), loss = 0.311131
I1005 10:44:18.889727  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31113 (* 1 = 0.31113 loss)
I1005 10:44:18.889734  9385 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1005 10:44:24.132237  9385 solver.cpp:218] Iteration 26900 (19.0749 iter/s, 5.24249s/100 iters), loss = 0.125693
I1005 10:44:24.132277  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125693 (* 1 = 0.125693 loss)
I1005 10:44:24.132284  9385 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1005 10:44:29.121496  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:44:29.330775  9385 solver.cpp:330] Iteration 27000, Testing net (#0)
I1005 10:44:30.520305  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:44:30.570219  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5762
I1005 10:44:30.570252  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.83293 (* 1 = 1.83293 loss)
I1005 10:44:30.622270  9385 solver.cpp:218] Iteration 27000 (15.4084 iter/s, 6.48997s/100 iters), loss = 0.285767
I1005 10:44:30.622298  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285766 (* 1 = 0.285766 loss)
I1005 10:44:30.622304  9385 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1005 10:44:35.867347  9385 solver.cpp:218] Iteration 27100 (19.0657 iter/s, 5.24503s/100 iters), loss = 0.274756
I1005 10:44:35.867386  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274756 (* 1 = 0.274756 loss)
I1005 10:44:35.867391  9385 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1005 10:44:41.108603  9385 solver.cpp:218] Iteration 27200 (19.0796 iter/s, 5.2412s/100 iters), loss = 0.240587
I1005 10:44:41.108633  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240587 (* 1 = 0.240587 loss)
I1005 10:44:41.108639  9385 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1005 10:44:46.355330  9385 solver.cpp:218] Iteration 27300 (19.0597 iter/s, 5.24667s/100 iters), loss = 0.166612
I1005 10:44:46.355367  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166612 (* 1 = 0.166612 loss)
I1005 10:44:46.355376  9385 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1005 10:44:51.602332  9385 solver.cpp:218] Iteration 27400 (19.0587 iter/s, 5.24694s/100 iters), loss = 0.209022
I1005 10:44:51.602371  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209022 (* 1 = 0.209022 loss)
I1005 10:44:51.602376  9385 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1005 10:44:56.596917  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:44:56.805809  9385 solver.cpp:330] Iteration 27500, Testing net (#0)
I1005 10:44:57.995609  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:44:58.045305  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7527
I1005 10:44:58.045341  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.822548 (* 1 = 0.822548 loss)
I1005 10:44:58.097476  9385 solver.cpp:218] Iteration 27500 (15.3963 iter/s, 6.49508s/100 iters), loss = 0.282972
I1005 10:44:58.097517  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282972 (* 1 = 0.282972 loss)
I1005 10:44:58.097524  9385 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1005 10:45:03.351992  9385 solver.cpp:218] Iteration 27600 (19.0315 iter/s, 5.25445s/100 iters), loss = 0.235203
I1005 10:45:03.352125  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235202 (* 1 = 0.235202 loss)
I1005 10:45:03.352133  9385 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1005 10:45:08.605149  9385 solver.cpp:218] Iteration 27700 (19.0367 iter/s, 5.25301s/100 iters), loss = 0.244775
I1005 10:45:08.605177  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244775 (* 1 = 0.244775 loss)
I1005 10:45:08.605192  9385 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1005 10:45:13.854434  9385 solver.cpp:218] Iteration 27800 (19.0504 iter/s, 5.24924s/100 iters), loss = 0.198577
I1005 10:45:13.854475  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198577 (* 1 = 0.198577 loss)
I1005 10:45:13.854480  9385 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1005 10:45:19.088753  9385 solver.cpp:218] Iteration 27900 (19.1049 iter/s, 5.23426s/100 iters), loss = 0.154319
I1005 10:45:19.088793  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154318 (* 1 = 0.154318 loss)
I1005 10:45:19.088799  9385 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1005 10:45:24.076701  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:45:24.285275  9385 solver.cpp:330] Iteration 28000, Testing net (#0)
I1005 10:45:25.478935  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:45:25.529419  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7088
I1005 10:45:25.529445  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14429 (* 1 = 1.14429 loss)
I1005 10:45:25.581833  9385 solver.cpp:218] Iteration 28000 (15.4012 iter/s, 6.49302s/100 iters), loss = 0.233282
I1005 10:45:25.581876  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233281 (* 1 = 0.233281 loss)
I1005 10:45:25.581882  9385 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1005 10:45:30.818253  9385 solver.cpp:218] Iteration 28100 (19.0972 iter/s, 5.23636s/100 iters), loss = 0.277841
I1005 10:45:30.818281  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277841 (* 1 = 0.277841 loss)
I1005 10:45:30.818286  9385 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1005 10:45:36.068910  9385 solver.cpp:218] Iteration 28200 (19.0454 iter/s, 5.25061s/100 iters), loss = 0.336388
I1005 10:45:36.069006  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336388 (* 1 = 0.336388 loss)
I1005 10:45:36.069023  9385 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1005 10:45:41.324069  9385 solver.cpp:218] Iteration 28300 (19.0293 iter/s, 5.25504s/100 iters), loss = 0.23885
I1005 10:45:41.324110  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238849 (* 1 = 0.238849 loss)
I1005 10:45:41.324116  9385 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1005 10:45:46.575707  9385 solver.cpp:218] Iteration 28400 (19.0419 iter/s, 5.25157s/100 iters), loss = 0.178456
I1005 10:45:46.575739  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178455 (* 1 = 0.178455 loss)
I1005 10:45:46.575745  9385 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1005 10:45:51.559270  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:45:51.767762  9385 solver.cpp:330] Iteration 28500, Testing net (#0)
I1005 10:45:52.965842  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:45:53.015481  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8031
I1005 10:45:53.015516  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.638262 (* 1 = 0.638262 loss)
I1005 10:45:53.067735  9385 solver.cpp:218] Iteration 28500 (15.4036 iter/s, 6.49198s/100 iters), loss = 0.201178
I1005 10:45:53.067760  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201178 (* 1 = 0.201178 loss)
I1005 10:45:53.067767  9385 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1005 10:45:58.308178  9385 solver.cpp:218] Iteration 28600 (19.0826 iter/s, 5.24039s/100 iters), loss = 0.178123
I1005 10:45:58.308218  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178123 (* 1 = 0.178123 loss)
I1005 10:45:58.308226  9385 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1005 10:46:03.552462  9385 solver.cpp:218] Iteration 28700 (19.0689 iter/s, 5.24415s/100 iters), loss = 0.372381
I1005 10:46:03.552494  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372381 (* 1 = 0.372381 loss)
I1005 10:46:03.552500  9385 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1005 10:46:08.798560  9385 solver.cpp:218] Iteration 28800 (19.062 iter/s, 5.24605s/100 iters), loss = 0.246493
I1005 10:46:08.798708  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246493 (* 1 = 0.246493 loss)
I1005 10:46:08.798715  9385 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1005 10:46:14.041600  9385 solver.cpp:218] Iteration 28900 (19.0735 iter/s, 5.24287s/100 iters), loss = 0.220909
I1005 10:46:14.041630  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220909 (* 1 = 0.220909 loss)
I1005 10:46:14.041635  9385 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1005 10:46:19.018745  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:46:19.228196  9385 solver.cpp:330] Iteration 29000, Testing net (#0)
I1005 10:46:20.424824  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:46:20.474632  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7153
I1005 10:46:20.474658  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.949885 (* 1 = 0.949885 loss)
I1005 10:46:20.526937  9385 solver.cpp:218] Iteration 29000 (15.4195 iter/s, 6.48529s/100 iters), loss = 0.220506
I1005 10:46:20.526967  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220506 (* 1 = 0.220506 loss)
I1005 10:46:20.526975  9385 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1005 10:46:25.777739  9385 solver.cpp:218] Iteration 29100 (19.0449 iter/s, 5.25075s/100 iters), loss = 0.148768
I1005 10:46:25.777772  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148767 (* 1 = 0.148767 loss)
I1005 10:46:25.777781  9385 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1005 10:46:31.018684  9385 solver.cpp:218] Iteration 29200 (19.0807 iter/s, 5.24089s/100 iters), loss = 0.243966
I1005 10:46:31.018718  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243966 (* 1 = 0.243966 loss)
I1005 10:46:31.018726  9385 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1005 10:46:36.271478  9385 solver.cpp:218] Iteration 29300 (19.0377 iter/s, 5.25274s/100 iters), loss = 0.24226
I1005 10:46:36.271508  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242259 (* 1 = 0.242259 loss)
I1005 10:46:36.271514  9385 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1005 10:46:41.513236  9385 solver.cpp:218] Iteration 29400 (19.0778 iter/s, 5.24171s/100 iters), loss = 0.197398
I1005 10:46:41.513344  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197398 (* 1 = 0.197398 loss)
I1005 10:46:41.513361  9385 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1005 10:46:46.503978  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:46:46.714052  9385 solver.cpp:330] Iteration 29500, Testing net (#0)
I1005 10:46:47.902151  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:46:47.951799  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7414
I1005 10:46:47.951834  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.879465 (* 1 = 0.879465 loss)
I1005 10:46:48.004062  9385 solver.cpp:218] Iteration 29500 (15.4067 iter/s, 6.4907s/100 iters), loss = 0.266842
I1005 10:46:48.004098  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266841 (* 1 = 0.266841 loss)
I1005 10:46:48.004106  9385 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1005 10:46:53.249286  9385 solver.cpp:218] Iteration 29600 (19.0652 iter/s, 5.24517s/100 iters), loss = 0.232052
I1005 10:46:53.249315  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232051 (* 1 = 0.232051 loss)
I1005 10:46:53.249321  9385 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1005 10:46:58.494758  9385 solver.cpp:218] Iteration 29700 (19.0643 iter/s, 5.24542s/100 iters), loss = 0.303701
I1005 10:46:58.494802  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303701 (* 1 = 0.303701 loss)
I1005 10:46:58.494810  9385 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1005 10:47:03.740428  9385 solver.cpp:218] Iteration 29800 (19.0636 iter/s, 5.2456s/100 iters), loss = 0.261297
I1005 10:47:03.740458  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261297 (* 1 = 0.261297 loss)
I1005 10:47:03.740463  9385 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1005 10:47:08.984911  9385 solver.cpp:218] Iteration 29900 (19.0678 iter/s, 5.24444s/100 iters), loss = 0.297823
I1005 10:47:08.984941  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297823 (* 1 = 0.297823 loss)
I1005 10:47:08.984949  9385 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1005 10:47:13.982997  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:47:14.191740  9385 solver.cpp:330] Iteration 30000, Testing net (#0)
I1005 10:47:15.379611  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:47:15.429255  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7748
I1005 10:47:15.429291  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.666759 (* 1 = 0.666759 loss)
I1005 10:47:15.481894  9385 solver.cpp:218] Iteration 30000 (15.3919 iter/s, 6.49693s/100 iters), loss = 0.264595
I1005 10:47:15.481925  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264595 (* 1 = 0.264595 loss)
I1005 10:47:15.481931  9385 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1005 10:47:20.735134  9385 solver.cpp:218] Iteration 30100 (19.0361 iter/s, 5.25319s/100 iters), loss = 0.206263
I1005 10:47:20.735175  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206263 (* 1 = 0.206263 loss)
I1005 10:47:20.735182  9385 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1005 10:47:25.988725  9385 solver.cpp:218] Iteration 30200 (19.0348 iter/s, 5.25353s/100 iters), loss = 0.256716
I1005 10:47:25.988765  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256716 (* 1 = 0.256716 loss)
I1005 10:47:25.988771  9385 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1005 10:47:31.232548  9385 solver.cpp:218] Iteration 30300 (19.0703 iter/s, 5.24376s/100 iters), loss = 0.308222
I1005 10:47:31.232589  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308222 (* 1 = 0.308222 loss)
I1005 10:47:31.232594  9385 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1005 10:47:36.483774  9385 solver.cpp:218] Iteration 30400 (19.0434 iter/s, 5.25117s/100 iters), loss = 0.292597
I1005 10:47:36.483814  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292597 (* 1 = 0.292597 loss)
I1005 10:47:36.483820  9385 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1005 10:47:41.470372  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:47:41.680505  9385 solver.cpp:330] Iteration 30500, Testing net (#0)
I1005 10:47:42.867113  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:47:42.917021  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7242
I1005 10:47:42.917057  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.956251 (* 1 = 0.956251 loss)
I1005 10:47:42.969166  9385 solver.cpp:218] Iteration 30500 (15.4194 iter/s, 6.48533s/100 iters), loss = 0.26484
I1005 10:47:42.969197  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26484 (* 1 = 0.26484 loss)
I1005 10:47:42.969204  9385 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1005 10:47:48.216910  9385 solver.cpp:218] Iteration 30600 (19.056 iter/s, 5.24769s/100 iters), loss = 0.301244
I1005 10:47:48.217036  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301244 (* 1 = 0.301244 loss)
I1005 10:47:48.217043  9385 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1005 10:47:53.464118  9385 solver.cpp:218] Iteration 30700 (19.0583 iter/s, 5.24707s/100 iters), loss = 0.275705
I1005 10:47:53.464157  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275705 (* 1 = 0.275705 loss)
I1005 10:47:53.464164  9385 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1005 10:47:58.716195  9385 solver.cpp:218] Iteration 30800 (19.0403 iter/s, 5.25202s/100 iters), loss = 0.262272
I1005 10:47:58.716236  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262272 (* 1 = 0.262272 loss)
I1005 10:47:58.716243  9385 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1005 10:48:03.958434  9385 solver.cpp:218] Iteration 30900 (19.076 iter/s, 5.24218s/100 iters), loss = 0.242286
I1005 10:48:03.958475  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242285 (* 1 = 0.242285 loss)
I1005 10:48:03.958482  9385 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1005 10:48:08.954984  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:48:09.165289  9385 solver.cpp:330] Iteration 31000, Testing net (#0)
I1005 10:48:10.357497  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:48:10.408066  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7042
I1005 10:48:10.408092  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06241 (* 1 = 1.06241 loss)
I1005 10:48:10.462472  9385 solver.cpp:218] Iteration 31000 (15.3752 iter/s, 6.50398s/100 iters), loss = 0.16907
I1005 10:48:10.462510  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16907 (* 1 = 0.16907 loss)
I1005 10:48:10.462518  9385 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1005 10:48:15.709141  9385 solver.cpp:218] Iteration 31100 (19.0606 iter/s, 5.24643s/100 iters), loss = 0.213552
I1005 10:48:15.709192  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213551 (* 1 = 0.213551 loss)
I1005 10:48:15.709208  9385 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1005 10:48:20.961381  9385 solver.cpp:218] Iteration 31200 (19.0397 iter/s, 5.25217s/100 iters), loss = 0.200431
I1005 10:48:20.961498  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200431 (* 1 = 0.200431 loss)
I1005 10:48:20.961504  9385 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1005 10:48:26.209098  9385 solver.cpp:218] Iteration 31300 (19.0564 iter/s, 5.24759s/100 iters), loss = 0.244728
I1005 10:48:26.209138  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244728 (* 1 = 0.244728 loss)
I1005 10:48:26.209144  9385 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1005 10:48:31.448235  9385 solver.cpp:218] Iteration 31400 (19.0874 iter/s, 5.23907s/100 iters), loss = 0.246919
I1005 10:48:31.448279  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246919 (* 1 = 0.246919 loss)
I1005 10:48:31.448287  9385 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1005 10:48:36.429024  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:48:36.639117  9385 solver.cpp:330] Iteration 31500, Testing net (#0)
I1005 10:48:37.834338  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:48:37.884222  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7689
I1005 10:48:37.884246  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.740732 (* 1 = 0.740732 loss)
I1005 10:48:37.936386  9385 solver.cpp:218] Iteration 31500 (15.4129 iter/s, 6.48805s/100 iters), loss = 0.23624
I1005 10:48:37.936414  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23624 (* 1 = 0.23624 loss)
I1005 10:48:37.936419  9385 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1005 10:48:43.181313  9385 solver.cpp:218] Iteration 31600 (19.0662 iter/s, 5.24488s/100 iters), loss = 0.239838
I1005 10:48:43.181344  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239838 (* 1 = 0.239838 loss)
I1005 10:48:43.181349  9385 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1005 10:48:48.435951  9385 solver.cpp:218] Iteration 31700 (19.031 iter/s, 5.25459s/100 iters), loss = 0.211359
I1005 10:48:48.435992  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211359 (* 1 = 0.211359 loss)
I1005 10:48:48.435997  9385 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1005 10:48:53.685026  9385 solver.cpp:218] Iteration 31800 (19.0512 iter/s, 5.24902s/100 iters), loss = 0.288269
I1005 10:48:53.685170  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288269 (* 1 = 0.288269 loss)
I1005 10:48:53.685178  9385 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1005 10:48:58.934736  9385 solver.cpp:218] Iteration 31900 (19.0493 iter/s, 5.24955s/100 iters), loss = 0.295675
I1005 10:48:58.934765  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295675 (* 1 = 0.295675 loss)
I1005 10:48:58.934772  9385 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1005 10:49:03.918902  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:49:04.128070  9385 solver.cpp:330] Iteration 32000, Testing net (#0)
I1005 10:49:05.324456  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:49:05.374326  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7315
I1005 10:49:05.374361  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.939957 (* 1 = 0.939957 loss)
I1005 10:49:05.426805  9385 solver.cpp:218] Iteration 32000 (15.4035 iter/s, 6.49202s/100 iters), loss = 0.196523
I1005 10:49:05.426829  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196523 (* 1 = 0.196523 loss)
I1005 10:49:05.426836  9385 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1005 10:49:10.679522  9385 solver.cpp:218] Iteration 32100 (19.0379 iter/s, 5.25267s/100 iters), loss = 0.220792
I1005 10:49:10.679553  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220791 (* 1 = 0.220791 loss)
I1005 10:49:10.679558  9385 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1005 10:49:15.920490  9385 solver.cpp:218] Iteration 32200 (19.0807 iter/s, 5.24091s/100 iters), loss = 0.349451
I1005 10:49:15.920536  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349451 (* 1 = 0.349451 loss)
I1005 10:49:15.920544  9385 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1005 10:49:21.168809  9385 solver.cpp:218] Iteration 32300 (19.0539 iter/s, 5.24826s/100 iters), loss = 0.225681
I1005 10:49:21.168849  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22568 (* 1 = 0.22568 loss)
I1005 10:49:21.168854  9385 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1005 10:49:26.411859  9385 solver.cpp:218] Iteration 32400 (19.0731 iter/s, 5.24299s/100 iters), loss = 0.221056
I1005 10:49:26.411979  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221055 (* 1 = 0.221055 loss)
I1005 10:49:26.411998  9385 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1005 10:49:31.400141  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:49:31.613548  9385 solver.cpp:330] Iteration 32500, Testing net (#0)
I1005 10:49:32.801096  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:49:32.850749  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7902
I1005 10:49:32.850785  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698675 (* 1 = 0.698675 loss)
I1005 10:49:32.903266  9385 solver.cpp:218] Iteration 32500 (15.4053 iter/s, 6.49127s/100 iters), loss = 0.16699
I1005 10:49:32.903290  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16699 (* 1 = 0.16699 loss)
I1005 10:49:32.903296  9385 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1005 10:49:38.153302  9385 solver.cpp:218] Iteration 32600 (19.0477 iter/s, 5.24999s/100 iters), loss = 0.258787
I1005 10:49:38.153336  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258787 (* 1 = 0.258787 loss)
I1005 10:49:38.153344  9385 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1005 10:49:43.399775  9385 solver.cpp:218] Iteration 32700 (19.0606 iter/s, 5.24642s/100 iters), loss = 0.213433
I1005 10:49:43.399824  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213433 (* 1 = 0.213433 loss)
I1005 10:49:43.399844  9385 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1005 10:49:48.645329  9385 solver.cpp:218] Iteration 32800 (19.0641 iter/s, 5.24545s/100 iters), loss = 0.221915
I1005 10:49:48.645361  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221915 (* 1 = 0.221915 loss)
I1005 10:49:48.645370  9385 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1005 10:49:53.888658  9385 solver.cpp:218] Iteration 32900 (19.072 iter/s, 5.24328s/100 iters), loss = 0.246785
I1005 10:49:53.888689  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246785 (* 1 = 0.246785 loss)
I1005 10:49:53.888696  9385 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1005 10:49:58.880985  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:49:59.089725  9385 solver.cpp:330] Iteration 33000, Testing net (#0)
I1005 10:50:00.278798  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:50:00.328124  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7502
I1005 10:50:00.328150  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.810419 (* 1 = 0.810419 loss)
I1005 10:50:00.380479  9385 solver.cpp:218] Iteration 33000 (15.4041 iter/s, 6.49177s/100 iters), loss = 0.207445
I1005 10:50:00.380507  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207445 (* 1 = 0.207445 loss)
I1005 10:50:00.380517  9385 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1005 10:50:05.625833  9385 solver.cpp:218] Iteration 33100 (19.0647 iter/s, 5.24531s/100 iters), loss = 0.312636
I1005 10:50:05.625864  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312635 (* 1 = 0.312635 loss)
I1005 10:50:05.625872  9385 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1005 10:50:10.872993  9385 solver.cpp:218] Iteration 33200 (19.0581 iter/s, 5.24711s/100 iters), loss = 0.186904
I1005 10:50:10.873025  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186904 (* 1 = 0.186904 loss)
I1005 10:50:10.873044  9385 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1005 10:50:16.116725  9385 solver.cpp:218] Iteration 33300 (19.0706 iter/s, 5.24368s/100 iters), loss = 0.382808
I1005 10:50:16.116757  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382807 (* 1 = 0.382807 loss)
I1005 10:50:16.116766  9385 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1005 10:50:21.362216  9385 solver.cpp:218] Iteration 33400 (19.0642 iter/s, 5.24544s/100 iters), loss = 0.194779
I1005 10:50:21.362247  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194779 (* 1 = 0.194779 loss)
I1005 10:50:21.362256  9385 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1005 10:50:26.357224  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:50:26.566779  9385 solver.cpp:330] Iteration 33500, Testing net (#0)
I1005 10:50:27.752281  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:50:27.802021  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7246
I1005 10:50:27.802044  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.900007 (* 1 = 0.900007 loss)
I1005 10:50:27.854550  9385 solver.cpp:218] Iteration 33500 (15.4029 iter/s, 6.49229s/100 iters), loss = 0.161967
I1005 10:50:27.854574  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161967 (* 1 = 0.161967 loss)
I1005 10:50:27.854580  9385 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1005 10:50:33.104416  9385 solver.cpp:218] Iteration 33600 (19.0483 iter/s, 5.24982s/100 iters), loss = 0.240938
I1005 10:50:33.104562  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240937 (* 1 = 0.240937 loss)
I1005 10:50:33.104578  9385 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1005 10:50:38.356750  9385 solver.cpp:218] Iteration 33700 (19.0397 iter/s, 5.25217s/100 iters), loss = 0.180276
I1005 10:50:38.356778  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180275 (* 1 = 0.180275 loss)
I1005 10:50:38.356784  9385 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1005 10:50:43.609552  9385 solver.cpp:218] Iteration 33800 (19.0377 iter/s, 5.25275s/100 iters), loss = 0.207356
I1005 10:50:43.609586  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207356 (* 1 = 0.207356 loss)
I1005 10:50:43.609593  9385 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1005 10:50:48.846273  9385 solver.cpp:218] Iteration 33900 (19.0961 iter/s, 5.23667s/100 iters), loss = 0.19159
I1005 10:50:48.846303  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19159 (* 1 = 0.19159 loss)
I1005 10:50:48.846319  9385 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1005 10:50:53.835139  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:50:54.044330  9385 solver.cpp:330] Iteration 34000, Testing net (#0)
I1005 10:50:55.231700  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:50:55.281358  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.79
I1005 10:50:55.281394  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.650144 (* 1 = 0.650144 loss)
I1005 10:50:55.335095  9385 solver.cpp:218] Iteration 34000 (15.4112 iter/s, 6.48877s/100 iters), loss = 0.192183
I1005 10:50:55.335131  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192182 (* 1 = 0.192182 loss)
I1005 10:50:55.335139  9385 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1005 10:51:00.577235  9385 solver.cpp:218] Iteration 34100 (19.0764 iter/s, 5.24208s/100 iters), loss = 0.243587
I1005 10:51:00.577275  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243587 (* 1 = 0.243587 loss)
I1005 10:51:00.577280  9385 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1005 10:51:05.823691  9385 solver.cpp:218] Iteration 34200 (19.0607 iter/s, 5.24639s/100 iters), loss = 0.219238
I1005 10:51:05.823820  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219238 (* 1 = 0.219238 loss)
I1005 10:51:05.823827  9385 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1005 10:51:11.074220  9385 solver.cpp:218] Iteration 34300 (19.0462 iter/s, 5.25039s/100 iters), loss = 0.273448
I1005 10:51:11.074250  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273448 (* 1 = 0.273448 loss)
I1005 10:51:11.074256  9385 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1005 10:51:16.314321  9385 solver.cpp:218] Iteration 34400 (19.0838 iter/s, 5.24004s/100 iters), loss = 0.234536
I1005 10:51:16.314359  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234536 (* 1 = 0.234536 loss)
I1005 10:51:16.314369  9385 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1005 10:51:21.302768  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:51:21.511481  9385 solver.cpp:330] Iteration 34500, Testing net (#0)
I1005 10:51:22.711302  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:51:22.760768  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7488
I1005 10:51:22.760795  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.850263 (* 1 = 0.850263 loss)
I1005 10:51:22.813015  9385 solver.cpp:218] Iteration 34500 (15.3878 iter/s, 6.49864s/100 iters), loss = 0.22053
I1005 10:51:22.813047  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220529 (* 1 = 0.220529 loss)
I1005 10:51:22.813057  9385 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1005 10:51:28.055071  9385 solver.cpp:218] Iteration 34600 (19.0767 iter/s, 5.242s/100 iters), loss = 0.307464
I1005 10:51:28.055104  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307464 (* 1 = 0.307464 loss)
I1005 10:51:28.055125  9385 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1005 10:51:33.306777  9385 solver.cpp:218] Iteration 34700 (19.0416 iter/s, 5.25165s/100 iters), loss = 0.295572
I1005 10:51:33.306805  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295571 (* 1 = 0.295571 loss)
I1005 10:51:33.306810  9385 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1005 10:51:38.556568  9385 solver.cpp:218] Iteration 34800 (19.0486 iter/s, 5.24974s/100 iters), loss = 0.221513
I1005 10:51:38.556711  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221512 (* 1 = 0.221512 loss)
I1005 10:51:38.556730  9385 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1005 10:51:43.800127  9385 solver.cpp:218] Iteration 34900 (19.0716 iter/s, 5.24341s/100 iters), loss = 0.135898
I1005 10:51:43.800155  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135898 (* 1 = 0.135898 loss)
I1005 10:51:43.800161  9385 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1005 10:51:48.778340  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:51:48.987454  9385 solver.cpp:330] Iteration 35000, Testing net (#0)
I1005 10:51:50.180464  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:51:50.230190  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6804
I1005 10:51:50.230224  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.16157 (* 1 = 1.16157 loss)
I1005 10:51:50.282276  9385 solver.cpp:218] Iteration 35000 (15.4271 iter/s, 6.4821s/100 iters), loss = 0.226492
I1005 10:51:50.282302  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226492 (* 1 = 0.226492 loss)
I1005 10:51:50.282310  9385 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1005 10:51:55.525763  9385 solver.cpp:218] Iteration 35100 (19.0715 iter/s, 5.24344s/100 iters), loss = 0.237458
I1005 10:51:55.525799  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237458 (* 1 = 0.237458 loss)
I1005 10:51:55.525806  9385 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1005 10:52:00.769448  9385 solver.cpp:218] Iteration 35200 (19.0709 iter/s, 5.24359s/100 iters), loss = 0.329091
I1005 10:52:00.769476  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329091 (* 1 = 0.329091 loss)
I1005 10:52:00.769482  9385 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1005 10:52:06.020323  9385 solver.cpp:218] Iteration 35300 (19.0446 iter/s, 5.25083s/100 iters), loss = 0.243116
I1005 10:52:06.020362  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243116 (* 1 = 0.243116 loss)
I1005 10:52:06.020368  9385 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1005 10:52:11.269543  9385 solver.cpp:218] Iteration 35400 (19.0507 iter/s, 5.24915s/100 iters), loss = 0.194287
I1005 10:52:11.269670  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194286 (* 1 = 0.194286 loss)
I1005 10:52:11.269688  9385 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1005 10:52:16.251457  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:52:16.467125  9385 solver.cpp:330] Iteration 35500, Testing net (#0)
I1005 10:52:17.656525  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:52:17.706428  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7799
I1005 10:52:17.706451  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706773 (* 1 = 0.706773 loss)
I1005 10:52:17.758879  9385 solver.cpp:218] Iteration 35500 (15.4102 iter/s, 6.48919s/100 iters), loss = 0.224393
I1005 10:52:17.758903  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224393 (* 1 = 0.224393 loss)
I1005 10:52:17.758909  9385 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1005 10:52:23.009665  9385 solver.cpp:218] Iteration 35600 (19.0449 iter/s, 5.25074s/100 iters), loss = 0.213255
I1005 10:52:23.009706  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213255 (* 1 = 0.213255 loss)
I1005 10:52:23.009713  9385 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1005 10:52:28.245357  9385 solver.cpp:218] Iteration 35700 (19.0999 iter/s, 5.23563s/100 iters), loss = 0.200528
I1005 10:52:28.245388  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200528 (* 1 = 0.200528 loss)
I1005 10:52:28.245402  9385 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1005 10:52:33.494390  9385 solver.cpp:218] Iteration 35800 (19.0513 iter/s, 5.24898s/100 iters), loss = 0.25443
I1005 10:52:33.494418  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254429 (* 1 = 0.254429 loss)
I1005 10:52:33.494424  9385 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1005 10:52:38.738111  9385 solver.cpp:218] Iteration 35900 (19.0706 iter/s, 5.24367s/100 iters), loss = 0.299589
I1005 10:52:38.738142  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299588 (* 1 = 0.299588 loss)
I1005 10:52:38.738157  9385 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1005 10:52:43.730363  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:52:43.939860  9385 solver.cpp:330] Iteration 36000, Testing net (#0)
I1005 10:52:45.128257  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:52:45.177937  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7785
I1005 10:52:45.177971  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.712482 (* 1 = 0.712482 loss)
I1005 10:52:45.230036  9385 solver.cpp:218] Iteration 36000 (15.4039 iter/s, 6.49188s/100 iters), loss = 0.20696
I1005 10:52:45.230064  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20696 (* 1 = 0.20696 loss)
I1005 10:52:45.230072  9385 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1005 10:52:50.479655  9385 solver.cpp:218] Iteration 36100 (19.0492 iter/s, 5.24957s/100 iters), loss = 0.263216
I1005 10:52:50.479684  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263216 (* 1 = 0.263216 loss)
I1005 10:52:50.479691  9385 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1005 10:52:55.729130  9385 solver.cpp:218] Iteration 36200 (19.0497 iter/s, 5.24942s/100 iters), loss = 0.259526
I1005 10:52:55.729172  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259525 (* 1 = 0.259525 loss)
I1005 10:52:55.729179  9385 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1005 10:53:00.967867  9385 solver.cpp:218] Iteration 36300 (19.0888 iter/s, 5.23867s/100 iters), loss = 0.177599
I1005 10:53:00.967909  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177598 (* 1 = 0.177598 loss)
I1005 10:53:00.967916  9385 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1005 10:53:06.216797  9385 solver.cpp:218] Iteration 36400 (19.0517 iter/s, 5.24887s/100 iters), loss = 0.189529
I1005 10:53:06.216837  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189529 (* 1 = 0.189529 loss)
I1005 10:53:06.216843  9385 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1005 10:53:11.206585  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:53:11.416318  9385 solver.cpp:330] Iteration 36500, Testing net (#0)
I1005 10:53:12.603529  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:53:12.653343  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7402
I1005 10:53:12.653378  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.877453 (* 1 = 0.877453 loss)
I1005 10:53:12.705868  9385 solver.cpp:218] Iteration 36500 (15.4107 iter/s, 6.48901s/100 iters), loss = 0.28374
I1005 10:53:12.705891  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28374 (* 1 = 0.28374 loss)
I1005 10:53:12.705899  9385 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1005 10:53:17.953164  9385 solver.cpp:218] Iteration 36600 (19.0576 iter/s, 5.24725s/100 iters), loss = 0.321622
I1005 10:53:17.953276  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321622 (* 1 = 0.321622 loss)
I1005 10:53:17.953294  9385 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1005 10:53:23.198876  9385 solver.cpp:218] Iteration 36700 (19.0636 iter/s, 5.24559s/100 iters), loss = 0.283144
I1005 10:53:23.198909  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283143 (* 1 = 0.283143 loss)
I1005 10:53:23.198915  9385 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1005 10:53:28.447955  9385 solver.cpp:218] Iteration 36800 (19.0512 iter/s, 5.24903s/100 iters), loss = 0.192593
I1005 10:53:28.447986  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192592 (* 1 = 0.192592 loss)
I1005 10:53:28.447993  9385 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1005 10:53:33.689429  9385 solver.cpp:218] Iteration 36900 (19.0788 iter/s, 5.24142s/100 iters), loss = 0.152222
I1005 10:53:33.689458  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152222 (* 1 = 0.152222 loss)
I1005 10:53:33.689474  9385 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1005 10:53:38.687659  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:53:38.897246  9385 solver.cpp:330] Iteration 37000, Testing net (#0)
I1005 10:53:40.085121  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:53:40.134940  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7513
I1005 10:53:40.134985  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.785659 (* 1 = 0.785659 loss)
I1005 10:53:40.187676  9385 solver.cpp:218] Iteration 37000 (15.3889 iter/s, 6.4982s/100 iters), loss = 0.216309
I1005 10:53:40.187706  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216309 (* 1 = 0.216309 loss)
I1005 10:53:40.187713  9385 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1005 10:53:45.443562  9385 solver.cpp:218] Iteration 37100 (19.0265 iter/s, 5.25584s/100 iters), loss = 0.23592
I1005 10:53:45.443591  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23592 (* 1 = 0.23592 loss)
I1005 10:53:45.443598  9385 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1005 10:53:50.699913  9385 solver.cpp:218] Iteration 37200 (19.0248 iter/s, 5.2563s/100 iters), loss = 0.208846
I1005 10:53:50.700052  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208845 (* 1 = 0.208845 loss)
I1005 10:53:50.700059  9385 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1005 10:53:55.957060  9385 solver.cpp:218] Iteration 37300 (19.0223 iter/s, 5.25699s/100 iters), loss = 0.208351
I1005 10:53:55.957100  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208351 (* 1 = 0.208351 loss)
I1005 10:53:55.957106  9385 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1005 10:54:01.197093  9385 solver.cpp:218] Iteration 37400 (19.0841 iter/s, 5.23997s/100 iters), loss = 0.138394
I1005 10:54:01.197134  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138394 (* 1 = 0.138394 loss)
I1005 10:54:01.197140  9385 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1005 10:54:06.185451  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:54:06.394347  9385 solver.cpp:330] Iteration 37500, Testing net (#0)
I1005 10:54:07.589385  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:54:07.638463  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6886
I1005 10:54:07.638489  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21934 (* 1 = 1.21934 loss)
I1005 10:54:07.690978  9385 solver.cpp:218] Iteration 37500 (15.3993 iter/s, 6.49382s/100 iters), loss = 0.24761
I1005 10:54:07.691011  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247609 (* 1 = 0.247609 loss)
I1005 10:54:07.691021  9385 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1005 10:54:12.929322  9385 solver.cpp:218] Iteration 37600 (19.0902 iter/s, 5.23829s/100 iters), loss = 0.214977
I1005 10:54:12.929356  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214976 (* 1 = 0.214976 loss)
I1005 10:54:12.929374  9385 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1005 10:54:18.174829  9385 solver.cpp:218] Iteration 37700 (19.0641 iter/s, 5.24546s/100 iters), loss = 0.282507
I1005 10:54:18.174861  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282507 (* 1 = 0.282507 loss)
I1005 10:54:18.174870  9385 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1005 10:54:23.426715  9385 solver.cpp:218] Iteration 37800 (19.041 iter/s, 5.25184s/100 iters), loss = 0.236077
I1005 10:54:23.426832  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236076 (* 1 = 0.236076 loss)
I1005 10:54:23.426839  9385 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1005 10:54:28.677219  9385 solver.cpp:218] Iteration 37900 (19.0463 iter/s, 5.25037s/100 iters), loss = 0.161738
I1005 10:54:28.677254  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161737 (* 1 = 0.161737 loss)
I1005 10:54:28.677261  9385 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1005 10:54:33.660007  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:54:33.868854  9385 solver.cpp:330] Iteration 38000, Testing net (#0)
I1005 10:54:35.068094  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:54:35.117745  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7233
I1005 10:54:35.117771  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00525 (* 1 = 1.00525 loss)
I1005 10:54:35.170222  9385 solver.cpp:218] Iteration 38000 (15.4013 iter/s, 6.49295s/100 iters), loss = 0.278237
I1005 10:54:35.170253  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278237 (* 1 = 0.278237 loss)
I1005 10:54:35.170259  9385 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1005 10:54:40.416759  9385 solver.cpp:218] Iteration 38100 (19.0604 iter/s, 5.24649s/100 iters), loss = 0.229966
I1005 10:54:40.416795  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229966 (* 1 = 0.229966 loss)
I1005 10:54:40.416803  9385 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1005 10:54:45.661803  9385 solver.cpp:218] Iteration 38200 (19.0658 iter/s, 5.24499s/100 iters), loss = 0.343894
I1005 10:54:45.661834  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343893 (* 1 = 0.343893 loss)
I1005 10:54:45.661839  9385 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1005 10:54:50.908874  9385 solver.cpp:218] Iteration 38300 (19.0584 iter/s, 5.24702s/100 iters), loss = 0.294821
I1005 10:54:50.908902  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29482 (* 1 = 0.29482 loss)
I1005 10:54:50.908908  9385 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1005 10:54:56.147233  9385 solver.cpp:218] Iteration 38400 (19.0901 iter/s, 5.23831s/100 iters), loss = 0.163832
I1005 10:54:56.147347  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163832 (* 1 = 0.163832 loss)
I1005 10:54:56.147354  9385 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1005 10:55:01.128017  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:55:01.339386  9385 solver.cpp:330] Iteration 38500, Testing net (#0)
I1005 10:55:02.531460  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:55:02.581176  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.68
I1005 10:55:02.581210  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26303 (* 1 = 1.26303 loss)
I1005 10:55:02.633630  9385 solver.cpp:218] Iteration 38500 (15.4172 iter/s, 6.48626s/100 iters), loss = 0.224104
I1005 10:55:02.633658  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224104 (* 1 = 0.224104 loss)
I1005 10:55:02.633666  9385 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1005 10:55:07.879081  9385 solver.cpp:218] Iteration 38600 (19.0643 iter/s, 5.2454s/100 iters), loss = 0.20215
I1005 10:55:07.879110  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20215 (* 1 = 0.20215 loss)
I1005 10:55:07.879117  9385 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1005 10:55:13.119906  9385 solver.cpp:218] Iteration 38700 (19.0811 iter/s, 5.24077s/100 iters), loss = 0.214027
I1005 10:55:13.119937  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214027 (* 1 = 0.214027 loss)
I1005 10:55:13.119961  9385 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1005 10:55:18.377941  9385 solver.cpp:218] Iteration 38800 (19.0187 iter/s, 5.25798s/100 iters), loss = 0.188768
I1005 10:55:18.377971  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188767 (* 1 = 0.188767 loss)
I1005 10:55:18.377976  9385 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1005 10:55:23.627305  9385 solver.cpp:218] Iteration 38900 (19.0501 iter/s, 5.24931s/100 iters), loss = 0.176852
I1005 10:55:23.627334  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176852 (* 1 = 0.176852 loss)
I1005 10:55:23.627341  9385 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1005 10:55:28.620520  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:55:28.830340  9385 solver.cpp:330] Iteration 39000, Testing net (#0)
I1005 10:55:30.018743  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:55:30.068523  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7177
I1005 10:55:30.068558  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.947488 (* 1 = 0.947488 loss)
I1005 10:55:30.121186  9385 solver.cpp:218] Iteration 39000 (15.3992 iter/s, 6.49383s/100 iters), loss = 0.157732
I1005 10:55:30.121213  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157732 (* 1 = 0.157732 loss)
I1005 10:55:30.121220  9385 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1005 10:55:35.375660  9385 solver.cpp:218] Iteration 39100 (19.0316 iter/s, 5.25443s/100 iters), loss = 0.209436
I1005 10:55:35.375689  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209435 (* 1 = 0.209435 loss)
I1005 10:55:35.375694  9385 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1005 10:55:40.623769  9385 solver.cpp:218] Iteration 39200 (19.0547 iter/s, 5.24806s/100 iters), loss = 0.275751
I1005 10:55:40.623801  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275751 (* 1 = 0.275751 loss)
I1005 10:55:40.623807  9385 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1005 10:55:45.864061  9385 solver.cpp:218] Iteration 39300 (19.0831 iter/s, 5.24024s/100 iters), loss = 0.260674
I1005 10:55:45.864091  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260674 (* 1 = 0.260674 loss)
I1005 10:55:45.864107  9385 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1005 10:55:51.108464  9385 solver.cpp:218] Iteration 39400 (19.0681 iter/s, 5.24435s/100 iters), loss = 0.276861
I1005 10:55:51.108502  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27686 (* 1 = 0.27686 loss)
I1005 10:55:51.108508  9385 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1005 10:55:56.100035  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:55:56.309166  9385 solver.cpp:330] Iteration 39500, Testing net (#0)
I1005 10:55:57.498046  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:55:57.547819  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7466
I1005 10:55:57.547854  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.784377 (* 1 = 0.784377 loss)
I1005 10:55:57.600169  9385 solver.cpp:218] Iteration 39500 (15.4044 iter/s, 6.49165s/100 iters), loss = 0.161796
I1005 10:55:57.600194  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161796 (* 1 = 0.161796 loss)
I1005 10:55:57.600201  9385 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1005 10:56:02.853214  9385 solver.cpp:218] Iteration 39600 (19.0367 iter/s, 5.253s/100 iters), loss = 0.215186
I1005 10:56:02.853332  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215186 (* 1 = 0.215186 loss)
I1005 10:56:02.853339  9385 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1005 10:56:08.109305  9385 solver.cpp:218] Iteration 39700 (19.026 iter/s, 5.25596s/100 iters), loss = 0.16856
I1005 10:56:08.109335  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16856 (* 1 = 0.16856 loss)
I1005 10:56:08.109341  9385 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1005 10:56:13.356909  9385 solver.cpp:218] Iteration 39800 (19.0565 iter/s, 5.24754s/100 iters), loss = 0.269768
I1005 10:56:13.356947  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269768 (* 1 = 0.269768 loss)
I1005 10:56:13.356953  9385 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1005 10:56:18.603543  9385 solver.cpp:218] Iteration 39900 (19.0601 iter/s, 5.24658s/100 iters), loss = 0.27688
I1005 10:56:18.603571  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27688 (* 1 = 0.27688 loss)
I1005 10:56:18.603576  9385 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1005 10:56:23.599357  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:56:23.808732  9385 solver.cpp:330] Iteration 40000, Testing net (#0)
I1005 10:56:24.997388  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:56:25.047145  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6453
I1005 10:56:25.047180  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31919 (* 1 = 1.31919 loss)
I1005 10:56:25.099604  9385 solver.cpp:218] Iteration 40000 (15.3941 iter/s, 6.49601s/100 iters), loss = 0.192261
I1005 10:56:25.099633  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192261 (* 1 = 0.192261 loss)
I1005 10:56:25.099638  9385 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1005 10:56:25.099642  9385 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1005 10:56:30.346467  9385 solver.cpp:218] Iteration 40100 (19.0592 iter/s, 5.24681s/100 iters), loss = 0.191502
I1005 10:56:30.346506  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191502 (* 1 = 0.191502 loss)
I1005 10:56:30.346511  9385 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1005 10:56:35.595662  9385 solver.cpp:218] Iteration 40200 (19.0508 iter/s, 5.24913s/100 iters), loss = 0.220293
I1005 10:56:35.595801  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220292 (* 1 = 0.220292 loss)
I1005 10:56:35.595819  9385 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1005 10:56:40.849380  9385 solver.cpp:218] Iteration 40300 (19.0347 iter/s, 5.25357s/100 iters), loss = 0.182699
I1005 10:56:40.849422  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182698 (* 1 = 0.182698 loss)
I1005 10:56:40.849428  9385 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1005 10:56:46.089421  9385 solver.cpp:218] Iteration 40400 (19.084 iter/s, 5.23998s/100 iters), loss = 0.0904115
I1005 10:56:46.089452  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0904112 (* 1 = 0.0904112 loss)
I1005 10:56:46.089458  9385 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1005 10:56:51.080971  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:56:51.290457  9385 solver.cpp:330] Iteration 40500, Testing net (#0)
I1005 10:56:52.487128  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:56:52.537608  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8814
I1005 10:56:52.537657  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348755 (* 1 = 0.348755 loss)
I1005 10:56:52.591341  9385 solver.cpp:218] Iteration 40500 (15.3802 iter/s, 6.50186s/100 iters), loss = 0.0946886
I1005 10:56:52.591390  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0946883 (* 1 = 0.0946883 loss)
I1005 10:56:52.591398  9385 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1005 10:56:57.840245  9385 solver.cpp:218] Iteration 40600 (19.052 iter/s, 5.2488s/100 iters), loss = 0.142708
I1005 10:56:57.840284  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142708 (* 1 = 0.142708 loss)
I1005 10:56:57.840291  9385 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1005 10:57:03.094887  9385 solver.cpp:218] Iteration 40700 (19.031 iter/s, 5.25458s/100 iters), loss = 0.114872
I1005 10:57:03.094925  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114872 (* 1 = 0.114872 loss)
I1005 10:57:03.094931  9385 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1005 10:57:08.347748  9385 solver.cpp:218] Iteration 40800 (19.0375 iter/s, 5.2528s/100 iters), loss = 0.1362
I1005 10:57:08.347874  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136199 (* 1 = 0.136199 loss)
I1005 10:57:08.347893  9385 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1005 10:57:13.591475  9385 solver.cpp:218] Iteration 40900 (19.0709 iter/s, 5.24358s/100 iters), loss = 0.102129
I1005 10:57:13.591513  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102128 (* 1 = 0.102128 loss)
I1005 10:57:13.591523  9385 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1005 10:57:18.571825  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:57:18.782229  9385 solver.cpp:330] Iteration 41000, Testing net (#0)
I1005 10:57:19.977211  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:57:20.027166  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8869
I1005 10:57:20.027194  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331942 (* 1 = 0.331942 loss)
I1005 10:57:20.079572  9385 solver.cpp:218] Iteration 41000 (15.4132 iter/s, 6.48795s/100 iters), loss = 0.0922332
I1005 10:57:20.079601  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0922329 (* 1 = 0.0922329 loss)
I1005 10:57:20.079610  9385 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1005 10:57:25.322367  9385 solver.cpp:218] Iteration 41100 (19.074 iter/s, 5.24275s/100 iters), loss = 0.0908495
I1005 10:57:25.322403  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0908492 (* 1 = 0.0908492 loss)
I1005 10:57:25.322412  9385 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1005 10:57:30.569859  9385 solver.cpp:218] Iteration 41200 (19.0569 iter/s, 5.24744s/100 iters), loss = 0.112343
I1005 10:57:30.569890  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112343 (* 1 = 0.112343 loss)
I1005 10:57:30.569900  9385 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1005 10:57:35.816620  9385 solver.cpp:218] Iteration 41300 (19.0596 iter/s, 5.24671s/100 iters), loss = 0.0954012
I1005 10:57:35.816653  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0954009 (* 1 = 0.0954009 loss)
I1005 10:57:35.816671  9385 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1005 10:57:41.059839  9385 solver.cpp:218] Iteration 41400 (19.0724 iter/s, 5.24317s/100 iters), loss = 0.0703652
I1005 10:57:41.060000  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0703648 (* 1 = 0.0703648 loss)
I1005 10:57:41.060024  9385 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1005 10:57:46.043107  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:57:46.252751  9385 solver.cpp:330] Iteration 41500, Testing net (#0)
I1005 10:57:47.448086  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:57:47.497503  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8932
I1005 10:57:47.497529  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316662 (* 1 = 0.316662 loss)
I1005 10:57:47.550146  9385 solver.cpp:218] Iteration 41500 (15.408 iter/s, 6.49013s/100 iters), loss = 0.106482
I1005 10:57:47.550178  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106482 (* 1 = 0.106482 loss)
I1005 10:57:47.550186  9385 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1005 10:57:52.803155  9385 solver.cpp:218] Iteration 41600 (19.0369 iter/s, 5.25296s/100 iters), loss = 0.121723
I1005 10:57:52.803187  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121722 (* 1 = 0.121722 loss)
I1005 10:57:52.803195  9385 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1005 10:57:58.045219  9385 solver.cpp:218] Iteration 41700 (19.0766 iter/s, 5.24201s/100 iters), loss = 0.132811
I1005 10:57:58.045261  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132811 (* 1 = 0.132811 loss)
I1005 10:57:58.045269  9385 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1005 10:58:03.293499  9385 solver.cpp:218] Iteration 41800 (19.0541 iter/s, 5.24822s/100 iters), loss = 0.159517
I1005 10:58:03.293540  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159516 (* 1 = 0.159516 loss)
I1005 10:58:03.293546  9385 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1005 10:58:08.536525  9385 solver.cpp:218] Iteration 41900 (19.0732 iter/s, 5.24297s/100 iters), loss = 0.0596793
I1005 10:58:08.536564  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0596789 (* 1 = 0.0596789 loss)
I1005 10:58:08.536571  9385 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1005 10:58:13.524794  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:58:13.736886  9385 solver.cpp:330] Iteration 42000, Testing net (#0)
I1005 10:58:14.924448  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:58:14.974262  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888
I1005 10:58:14.974287  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344613 (* 1 = 0.344613 loss)
I1005 10:58:15.026442  9385 solver.cpp:218] Iteration 42000 (15.4087 iter/s, 6.48985s/100 iters), loss = 0.0685443
I1005 10:58:15.026468  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0685439 (* 1 = 0.0685439 loss)
I1005 10:58:15.026473  9385 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1005 10:58:20.275956  9385 solver.cpp:218] Iteration 42100 (19.0495 iter/s, 5.24947s/100 iters), loss = 0.117869
I1005 10:58:20.275997  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117869 (* 1 = 0.117869 loss)
I1005 10:58:20.276003  9385 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1005 10:58:25.526057  9385 solver.cpp:218] Iteration 42200 (19.0475 iter/s, 5.25003s/100 iters), loss = 0.106471
I1005 10:58:25.526098  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10647 (* 1 = 0.10647 loss)
I1005 10:58:25.526105  9385 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1005 10:58:30.768930  9385 solver.cpp:218] Iteration 42300 (19.0738 iter/s, 5.24278s/100 iters), loss = 0.107438
I1005 10:58:30.768968  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107438 (* 1 = 0.107438 loss)
I1005 10:58:30.768975  9385 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1005 10:58:36.017338  9385 solver.cpp:218] Iteration 42400 (19.0536 iter/s, 5.24835s/100 iters), loss = 0.0737259
I1005 10:58:36.017379  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0737256 (* 1 = 0.0737256 loss)
I1005 10:58:36.017385  9385 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1005 10:58:41.011366  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:58:41.221124  9385 solver.cpp:330] Iteration 42500, Testing net (#0)
I1005 10:58:42.410471  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:58:42.460391  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8933
I1005 10:58:42.460425  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325144 (* 1 = 0.325144 loss)
I1005 10:58:42.512658  9385 solver.cpp:218] Iteration 42500 (15.3958 iter/s, 6.49526s/100 iters), loss = 0.0698531
I1005 10:58:42.512688  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0698528 (* 1 = 0.0698528 loss)
I1005 10:58:42.512696  9385 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1005 10:58:47.765528  9385 solver.cpp:218] Iteration 42600 (19.0374 iter/s, 5.25282s/100 iters), loss = 0.1048
I1005 10:58:47.765652  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1048 (* 1 = 0.1048 loss)
I1005 10:58:47.765660  9385 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1005 10:58:53.012521  9385 solver.cpp:218] Iteration 42700 (19.059 iter/s, 5.24686s/100 iters), loss = 0.0856511
I1005 10:58:53.012549  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0856507 (* 1 = 0.0856507 loss)
I1005 10:58:53.012557  9385 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1005 10:58:58.251005  9385 solver.cpp:218] Iteration 42800 (19.0897 iter/s, 5.23844s/100 iters), loss = 0.11128
I1005 10:58:58.251037  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11128 (* 1 = 0.11128 loss)
I1005 10:58:58.251045  9385 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1005 10:59:03.494376  9385 solver.cpp:218] Iteration 42900 (19.0719 iter/s, 5.24332s/100 iters), loss = 0.0819959
I1005 10:59:03.494407  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0819954 (* 1 = 0.0819954 loss)
I1005 10:59:03.494415  9385 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1005 10:59:08.482657  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:59:08.692337  9385 solver.cpp:330] Iteration 43000, Testing net (#0)
I1005 10:59:09.881441  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:59:09.930999  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I1005 10:59:09.931036  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301681 (* 1 = 0.301681 loss)
I1005 10:59:09.983794  9385 solver.cpp:218] Iteration 43000 (15.4098 iter/s, 6.48937s/100 iters), loss = 0.0589962
I1005 10:59:09.983829  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589958 (* 1 = 0.0589958 loss)
I1005 10:59:09.983836  9385 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1005 10:59:15.236429  9385 solver.cpp:218] Iteration 43100 (19.0382 iter/s, 5.25258s/100 iters), loss = 0.102304
I1005 10:59:15.236459  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102304 (* 1 = 0.102304 loss)
I1005 10:59:15.236464  9385 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1005 10:59:20.492532  9385 solver.cpp:218] Iteration 43200 (19.0257 iter/s, 5.25605s/100 iters), loss = 0.0978728
I1005 10:59:20.492658  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0978724 (* 1 = 0.0978724 loss)
I1005 10:59:20.492697  9385 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1005 10:59:25.743754  9385 solver.cpp:218] Iteration 43300 (19.0437 iter/s, 5.25109s/100 iters), loss = 0.0663562
I1005 10:59:25.743794  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0663558 (* 1 = 0.0663558 loss)
I1005 10:59:25.743800  9385 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1005 10:59:30.985541  9385 solver.cpp:218] Iteration 43400 (19.0777 iter/s, 5.24173s/100 iters), loss = 0.0457716
I1005 10:59:30.985571  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457712 (* 1 = 0.0457712 loss)
I1005 10:59:30.985577  9385 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1005 10:59:35.978495  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:59:36.188194  9385 solver.cpp:330] Iteration 43500, Testing net (#0)
I1005 10:59:37.374248  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 10:59:37.424258  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9009
I1005 10:59:37.424283  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314137 (* 1 = 0.314137 loss)
I1005 10:59:37.478193  9385 solver.cpp:218] Iteration 43500 (15.4022 iter/s, 6.4926s/100 iters), loss = 0.058648
I1005 10:59:37.478227  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0586476 (* 1 = 0.0586476 loss)
I1005 10:59:37.478233  9385 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1005 10:59:42.724269  9385 solver.cpp:218] Iteration 43600 (19.0621 iter/s, 5.24602s/100 iters), loss = 0.116887
I1005 10:59:42.724300  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116886 (* 1 = 0.116886 loss)
I1005 10:59:42.724306  9385 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1005 10:59:47.969462  9385 solver.cpp:218] Iteration 43700 (19.0653 iter/s, 5.24514s/100 iters), loss = 0.0513976
I1005 10:59:47.969492  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513972 (* 1 = 0.0513972 loss)
I1005 10:59:47.969498  9385 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1005 10:59:53.218436  9385 solver.cpp:218] Iteration 43800 (19.0515 iter/s, 5.24892s/100 iters), loss = 0.087766
I1005 10:59:53.218576  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0877656 (* 1 = 0.0877656 loss)
I1005 10:59:53.218595  9385 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1005 10:59:58.462628  9385 solver.cpp:218] Iteration 43900 (19.0693 iter/s, 5.24404s/100 iters), loss = 0.0647519
I1005 10:59:58.462669  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647515 (* 1 = 0.0647515 loss)
I1005 10:59:58.462689  9385 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1005 11:00:03.452386  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:00:03.662030  9385 solver.cpp:330] Iteration 44000, Testing net (#0)
I1005 11:00:04.859911  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:00:04.909780  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8943
I1005 11:00:04.909816  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331212 (* 1 = 0.331212 loss)
I1005 11:00:04.962002  9385 solver.cpp:218] Iteration 44000 (15.3863 iter/s, 6.49928s/100 iters), loss = 0.0419648
I1005 11:00:04.962033  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419644 (* 1 = 0.0419644 loss)
I1005 11:00:04.962039  9385 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1005 11:00:10.205478  9385 solver.cpp:218] Iteration 44100 (19.0715 iter/s, 5.24343s/100 iters), loss = 0.0672905
I1005 11:00:10.205508  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0672901 (* 1 = 0.0672901 loss)
I1005 11:00:10.205514  9385 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1005 11:00:15.455286  9385 solver.cpp:218] Iteration 44200 (19.0485 iter/s, 5.24976s/100 iters), loss = 0.0771035
I1005 11:00:15.455315  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0771031 (* 1 = 0.0771031 loss)
I1005 11:00:15.455322  9385 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1005 11:00:20.704485  9385 solver.cpp:218] Iteration 44300 (19.0507 iter/s, 5.24915s/100 iters), loss = 0.0549417
I1005 11:00:20.704524  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549413 (* 1 = 0.0549413 loss)
I1005 11:00:20.704530  9385 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1005 11:00:25.948799  9385 solver.cpp:218] Iteration 44400 (19.0685 iter/s, 5.24426s/100 iters), loss = 0.0734937
I1005 11:00:25.948940  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0734932 (* 1 = 0.0734932 loss)
I1005 11:00:25.948961  9385 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1005 11:00:30.924057  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:00:31.134105  9385 solver.cpp:330] Iteration 44500, Testing net (#0)
I1005 11:00:32.328672  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:00:32.378015  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1005 11:00:32.378041  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322141 (* 1 = 0.322141 loss)
I1005 11:00:32.430217  9385 solver.cpp:218] Iteration 44500 (15.4291 iter/s, 6.48126s/100 iters), loss = 0.0561076
I1005 11:00:32.430243  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561071 (* 1 = 0.0561071 loss)
I1005 11:00:32.430249  9385 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1005 11:00:37.680604  9385 solver.cpp:218] Iteration 44600 (19.0464 iter/s, 5.25034s/100 iters), loss = 0.0539833
I1005 11:00:37.680646  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0539828 (* 1 = 0.0539828 loss)
I1005 11:00:37.680654  9385 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1005 11:00:42.923195  9385 solver.cpp:218] Iteration 44700 (19.0748 iter/s, 5.24253s/100 iters), loss = 0.0918192
I1005 11:00:42.923226  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0918188 (* 1 = 0.0918188 loss)
I1005 11:00:42.923234  9385 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1005 11:00:48.171033  9385 solver.cpp:218] Iteration 44800 (19.0556 iter/s, 5.24779s/100 iters), loss = 0.097194
I1005 11:00:48.171062  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0971935 (* 1 = 0.0971935 loss)
I1005 11:00:48.171068  9385 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1005 11:00:53.422600  9385 solver.cpp:218] Iteration 44900 (19.0421 iter/s, 5.25152s/100 iters), loss = 0.140171
I1005 11:00:53.422628  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14017 (* 1 = 0.14017 loss)
I1005 11:00:53.422634  9385 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1005 11:00:58.408337  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:00:58.623716  9385 solver.cpp:330] Iteration 45000, Testing net (#0)
I1005 11:00:59.812656  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:00:59.862327  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9008
I1005 11:00:59.862350  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316295 (* 1 = 0.316295 loss)
I1005 11:00:59.914146  9385 solver.cpp:218] Iteration 45000 (15.4048 iter/s, 6.4915s/100 iters), loss = 0.0343566
I1005 11:00:59.914172  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343562 (* 1 = 0.0343562 loss)
I1005 11:00:59.914178  9385 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1005 11:01:05.166946  9385 solver.cpp:218] Iteration 45100 (19.0376 iter/s, 5.25275s/100 iters), loss = 0.0474525
I1005 11:01:05.166986  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474521 (* 1 = 0.0474521 loss)
I1005 11:01:05.166992  9385 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1005 11:01:10.412256  9385 solver.cpp:218] Iteration 45200 (19.0649 iter/s, 5.24525s/100 iters), loss = 0.0984206
I1005 11:01:10.412292  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0984202 (* 1 = 0.0984202 loss)
I1005 11:01:10.412299  9385 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1005 11:01:15.659212  9385 solver.cpp:218] Iteration 45300 (19.0589 iter/s, 5.2469s/100 iters), loss = 0.1003
I1005 11:01:15.659243  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100299 (* 1 = 0.100299 loss)
I1005 11:01:15.659251  9385 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1005 11:01:20.901865  9385 solver.cpp:218] Iteration 45400 (19.0745 iter/s, 5.2426s/100 iters), loss = 0.0466873
I1005 11:01:20.901898  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466869 (* 1 = 0.0466869 loss)
I1005 11:01:20.901906  9385 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1005 11:01:25.890866  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:01:26.101178  9385 solver.cpp:330] Iteration 45500, Testing net (#0)
I1005 11:01:27.289593  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:01:27.339328  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8952
I1005 11:01:27.339354  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342716 (* 1 = 0.342716 loss)
I1005 11:01:27.392076  9385 solver.cpp:218] Iteration 45500 (15.4079 iter/s, 6.49016s/100 iters), loss = 0.0538257
I1005 11:01:27.392110  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538253 (* 1 = 0.0538253 loss)
I1005 11:01:27.392132  9385 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1005 11:01:32.641901  9385 solver.cpp:218] Iteration 45600 (19.0484 iter/s, 5.24978s/100 iters), loss = 0.0668646
I1005 11:01:32.642042  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0668642 (* 1 = 0.0668642 loss)
I1005 11:01:32.642062  9385 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1005 11:01:37.895566  9385 solver.cpp:218] Iteration 45700 (19.0349 iter/s, 5.25352s/100 iters), loss = 0.0663522
I1005 11:01:37.895596  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0663519 (* 1 = 0.0663519 loss)
I1005 11:01:37.895612  9385 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1005 11:01:43.140908  9385 solver.cpp:218] Iteration 45800 (19.0647 iter/s, 5.24529s/100 iters), loss = 0.076803
I1005 11:01:43.140938  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0768027 (* 1 = 0.0768027 loss)
I1005 11:01:43.140944  9385 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1005 11:01:48.387161  9385 solver.cpp:218] Iteration 45900 (19.0614 iter/s, 5.2462s/100 iters), loss = 0.0230321
I1005 11:01:48.387199  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230317 (* 1 = 0.0230317 loss)
I1005 11:01:48.387207  9385 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1005 11:01:53.381805  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:01:53.590435  9385 solver.cpp:330] Iteration 46000, Testing net (#0)
I1005 11:01:54.779924  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:01:54.829465  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I1005 11:01:54.829490  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317395 (* 1 = 0.317395 loss)
I1005 11:01:54.881779  9385 solver.cpp:218] Iteration 46000 (15.3975 iter/s, 6.49456s/100 iters), loss = 0.0301391
I1005 11:01:54.881810  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301387 (* 1 = 0.0301387 loss)
I1005 11:01:54.881820  9385 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1005 11:02:00.128113  9385 solver.cpp:218] Iteration 46100 (19.0611 iter/s, 5.24629s/100 iters), loss = 0.0661462
I1005 11:02:00.128145  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0661459 (* 1 = 0.0661459 loss)
I1005 11:02:00.128163  9385 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1005 11:02:05.379112  9385 solver.cpp:218] Iteration 46200 (19.0442 iter/s, 5.25094s/100 iters), loss = 0.0646261
I1005 11:02:05.379261  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0646257 (* 1 = 0.0646257 loss)
I1005 11:02:05.379315  9385 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1005 11:02:10.629714  9385 solver.cpp:218] Iteration 46300 (19.046 iter/s, 5.25044s/100 iters), loss = 0.0745798
I1005 11:02:10.629752  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0745795 (* 1 = 0.0745795 loss)
I1005 11:02:10.629772  9385 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1005 11:02:15.863119  9385 solver.cpp:218] Iteration 46400 (19.1084 iter/s, 5.23331s/100 iters), loss = 0.0547794
I1005 11:02:15.863150  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0547791 (* 1 = 0.0547791 loss)
I1005 11:02:15.863158  9385 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1005 11:02:20.847339  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:02:21.057601  9385 solver.cpp:330] Iteration 46500, Testing net (#0)
I1005 11:02:22.245139  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:02:22.294844  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1005 11:02:22.294872  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330415 (* 1 = 0.330415 loss)
I1005 11:02:22.347033  9385 solver.cpp:218] Iteration 46500 (15.4229 iter/s, 6.48386s/100 iters), loss = 0.0533087
I1005 11:02:22.347060  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0533084 (* 1 = 0.0533084 loss)
I1005 11:02:22.347070  9385 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1005 11:02:27.591624  9385 solver.cpp:218] Iteration 46600 (19.0674 iter/s, 5.24454s/100 iters), loss = 0.0585048
I1005 11:02:27.591655  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0585044 (* 1 = 0.0585044 loss)
I1005 11:02:27.591672  9385 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1005 11:02:32.846436  9385 solver.cpp:218] Iteration 46700 (19.0304 iter/s, 5.25476s/100 iters), loss = 0.0318774
I1005 11:02:32.846474  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318771 (* 1 = 0.0318771 loss)
I1005 11:02:32.846480  9385 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1005 11:02:38.098863  9385 solver.cpp:218] Iteration 46800 (19.039 iter/s, 5.25237s/100 iters), loss = 0.0610178
I1005 11:02:38.098979  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0610175 (* 1 = 0.0610175 loss)
I1005 11:02:38.099000  9385 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1005 11:02:43.330907  9385 solver.cpp:218] Iteration 46900 (19.1134 iter/s, 5.23192s/100 iters), loss = 0.0718553
I1005 11:02:43.330937  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.071855 (* 1 = 0.071855 loss)
I1005 11:02:43.330943  9385 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1005 11:02:48.321980  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:02:48.532424  9385 solver.cpp:330] Iteration 47000, Testing net (#0)
I1005 11:02:49.728015  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:02:49.777974  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1005 11:02:49.778010  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32472 (* 1 = 0.32472 loss)
I1005 11:02:49.830349  9385 solver.cpp:218] Iteration 47000 (15.3861 iter/s, 6.49939s/100 iters), loss = 0.0595962
I1005 11:02:49.830384  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0595959 (* 1 = 0.0595959 loss)
I1005 11:02:49.830390  9385 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1005 11:02:55.069250  9385 solver.cpp:218] Iteration 47100 (19.0882 iter/s, 5.23885s/100 iters), loss = 0.076883
I1005 11:02:55.069280  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0768826 (* 1 = 0.0768826 loss)
I1005 11:02:55.069286  9385 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1005 11:03:00.314110  9385 solver.cpp:218] Iteration 47200 (19.0665 iter/s, 5.24481s/100 iters), loss = 0.0836131
I1005 11:03:00.314138  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0836128 (* 1 = 0.0836128 loss)
I1005 11:03:00.314144  9385 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1005 11:03:05.557111  9385 solver.cpp:218] Iteration 47300 (19.0732 iter/s, 5.24295s/100 iters), loss = 0.0521149
I1005 11:03:05.557139  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521146 (* 1 = 0.0521146 loss)
I1005 11:03:05.557145  9385 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1005 11:03:10.804231  9385 solver.cpp:218] Iteration 47400 (19.0583 iter/s, 5.24707s/100 iters), loss = 0.046058
I1005 11:03:10.804390  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460577 (* 1 = 0.0460577 loss)
I1005 11:03:10.804425  9385 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1005 11:03:15.788851  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:03:15.997572  9385 solver.cpp:330] Iteration 47500, Testing net (#0)
I1005 11:03:17.195767  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:03:17.245522  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8966
I1005 11:03:17.245558  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35954 (* 1 = 0.35954 loss)
I1005 11:03:17.298040  9385 solver.cpp:218] Iteration 47500 (15.3997 iter/s, 6.49364s/100 iters), loss = 0.0443207
I1005 11:03:17.298070  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443204 (* 1 = 0.0443204 loss)
I1005 11:03:17.298077  9385 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1005 11:03:22.543120  9385 solver.cpp:218] Iteration 47600 (19.0657 iter/s, 5.24503s/100 iters), loss = 0.0989996
I1005 11:03:22.543167  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0989993 (* 1 = 0.0989993 loss)
I1005 11:03:22.543175  9385 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1005 11:03:27.787492  9385 solver.cpp:218] Iteration 47700 (19.0685 iter/s, 5.24426s/100 iters), loss = 0.0798778
I1005 11:03:27.787524  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0798775 (* 1 = 0.0798775 loss)
I1005 11:03:27.787533  9385 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1005 11:03:33.038586  9385 solver.cpp:218] Iteration 47800 (19.0438 iter/s, 5.25105s/100 iters), loss = 0.0250433
I1005 11:03:33.038619  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025043 (* 1 = 0.025043 loss)
I1005 11:03:33.038627  9385 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1005 11:03:38.285325  9385 solver.cpp:218] Iteration 47900 (19.0597 iter/s, 5.24669s/100 iters), loss = 0.0628538
I1005 11:03:38.285353  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628535 (* 1 = 0.0628535 loss)
I1005 11:03:38.285359  9385 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1005 11:03:43.265317  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:03:43.477174  9385 solver.cpp:330] Iteration 48000, Testing net (#0)
I1005 11:03:44.668656  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:03:44.718044  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I1005 11:03:44.718068  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331184 (* 1 = 0.331184 loss)
I1005 11:03:44.770238  9385 solver.cpp:218] Iteration 48000 (15.4205 iter/s, 6.48486s/100 iters), loss = 0.0784457
I1005 11:03:44.770275  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0784454 (* 1 = 0.0784454 loss)
I1005 11:03:44.770282  9385 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1005 11:03:50.017596  9385 solver.cpp:218] Iteration 48100 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.0474654
I1005 11:03:50.017635  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474651 (* 1 = 0.0474651 loss)
I1005 11:03:50.017642  9385 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1005 11:03:55.254587  9385 solver.cpp:218] Iteration 48200 (19.0952 iter/s, 5.23693s/100 iters), loss = 0.0401742
I1005 11:03:55.254617  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401739 (* 1 = 0.0401739 loss)
I1005 11:03:55.254633  9385 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1005 11:04:00.504277  9385 solver.cpp:218] Iteration 48300 (19.0489 iter/s, 5.24964s/100 iters), loss = 0.0434037
I1005 11:04:00.504307  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434034 (* 1 = 0.0434034 loss)
I1005 11:04:00.504323  9385 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1005 11:04:05.752629  9385 solver.cpp:218] Iteration 48400 (19.0538 iter/s, 5.2483s/100 iters), loss = 0.0384592
I1005 11:04:05.752656  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384589 (* 1 = 0.0384589 loss)
I1005 11:04:05.752662  9385 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1005 11:04:10.742797  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:04:10.951237  9385 solver.cpp:330] Iteration 48500, Testing net (#0)
I1005 11:04:12.139744  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:04:12.189502  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1005 11:04:12.189537  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34223 (* 1 = 0.34223 loss)
I1005 11:04:12.241657  9385 solver.cpp:218] Iteration 48500 (15.4107 iter/s, 6.48898s/100 iters), loss = 0.042977
I1005 11:04:12.241683  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429767 (* 1 = 0.0429767 loss)
I1005 11:04:12.241689  9385 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1005 11:04:17.494561  9385 solver.cpp:218] Iteration 48600 (19.0373 iter/s, 5.25284s/100 iters), loss = 0.0488711
I1005 11:04:17.494704  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488708 (* 1 = 0.0488708 loss)
I1005 11:04:17.494724  9385 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1005 11:04:22.745678  9385 solver.cpp:218] Iteration 48700 (19.0441 iter/s, 5.25096s/100 iters), loss = 0.0458104
I1005 11:04:22.745708  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0458101 (* 1 = 0.0458101 loss)
I1005 11:04:22.745714  9385 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1005 11:04:27.983671  9385 solver.cpp:218] Iteration 48800 (19.0915 iter/s, 5.23794s/100 iters), loss = 0.0568642
I1005 11:04:27.983705  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568639 (* 1 = 0.0568639 loss)
I1005 11:04:27.983723  9385 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1005 11:04:33.226852  9385 solver.cpp:218] Iteration 48900 (19.0726 iter/s, 5.24313s/100 iters), loss = 0.0742443
I1005 11:04:33.226883  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.074244 (* 1 = 0.074244 loss)
I1005 11:04:33.226891  9385 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1005 11:04:38.213779  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:04:38.423188  9385 solver.cpp:330] Iteration 49000, Testing net (#0)
I1005 11:04:39.610738  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:04:39.660642  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1005 11:04:39.660670  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330295 (* 1 = 0.330295 loss)
I1005 11:04:39.713006  9385 solver.cpp:218] Iteration 49000 (15.4176 iter/s, 6.4861s/100 iters), loss = 0.0205832
I1005 11:04:39.713033  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205829 (* 1 = 0.0205829 loss)
I1005 11:04:39.713042  9385 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1005 11:04:44.962782  9385 solver.cpp:218] Iteration 49100 (19.0486 iter/s, 5.24973s/100 iters), loss = 0.0489503
I1005 11:04:44.962815  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04895 (* 1 = 0.04895 loss)
I1005 11:04:44.962833  9385 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1005 11:04:50.215641  9385 solver.cpp:218] Iteration 49200 (19.0374 iter/s, 5.25281s/100 iters), loss = 0.0692741
I1005 11:04:50.215838  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0692739 (* 1 = 0.0692739 loss)
I1005 11:04:50.215858  9385 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1005 11:04:55.462121  9385 solver.cpp:218] Iteration 49300 (19.0611 iter/s, 5.24628s/100 iters), loss = 0.0601663
I1005 11:04:55.462174  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.060166 (* 1 = 0.060166 loss)
I1005 11:04:55.462195  9385 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1005 11:05:00.701861  9385 solver.cpp:218] Iteration 49400 (19.0858 iter/s, 5.23949s/100 iters), loss = 0.0240852
I1005 11:05:00.701891  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240849 (* 1 = 0.0240849 loss)
I1005 11:05:00.701897  9385 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1005 11:05:05.698292  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:05:05.908192  9385 solver.cpp:330] Iteration 49500, Testing net (#0)
I1005 11:05:07.098223  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:05:07.148365  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9
I1005 11:05:07.148401  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351367 (* 1 = 0.351367 loss)
I1005 11:05:07.200989  9385 solver.cpp:218] Iteration 49500 (15.3868 iter/s, 6.49908s/100 iters), loss = 0.0539437
I1005 11:05:07.201022  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0539435 (* 1 = 0.0539435 loss)
I1005 11:05:07.201030  9385 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1005 11:05:12.449630  9385 solver.cpp:218] Iteration 49600 (19.0527 iter/s, 5.24859s/100 iters), loss = 0.0440613
I1005 11:05:12.449669  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044061 (* 1 = 0.044061 loss)
I1005 11:05:12.449676  9385 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1005 11:05:17.699818  9385 solver.cpp:218] Iteration 49700 (19.0472 iter/s, 5.25013s/100 iters), loss = 0.0320912
I1005 11:05:17.699857  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320909 (* 1 = 0.0320909 loss)
I1005 11:05:17.699863  9385 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1005 11:05:22.946329  9385 solver.cpp:218] Iteration 49800 (19.0605 iter/s, 5.24645s/100 iters), loss = 0.0442703
I1005 11:05:22.946441  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04427 (* 1 = 0.04427 loss)
I1005 11:05:22.946449  9385 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1005 11:05:28.184226  9385 solver.cpp:218] Iteration 49900 (19.0921 iter/s, 5.23777s/100 iters), loss = 0.115264
I1005 11:05:28.184257  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115263 (* 1 = 0.115263 loss)
I1005 11:05:28.184263  9385 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1005 11:05:33.173539  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:05:33.382956  9385 solver.cpp:330] Iteration 50000, Testing net (#0)
I1005 11:05:34.577234  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:05:34.627784  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904
I1005 11:05:34.627820  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337336 (* 1 = 0.337336 loss)
I1005 11:05:34.680850  9385 solver.cpp:218] Iteration 50000 (15.3927 iter/s, 6.49657s/100 iters), loss = 0.0426785
I1005 11:05:34.680883  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426782 (* 1 = 0.0426782 loss)
I1005 11:05:34.680891  9385 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1005 11:05:39.919244  9385 solver.cpp:218] Iteration 50100 (19.09 iter/s, 5.23834s/100 iters), loss = 0.0210574
I1005 11:05:39.919282  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210571 (* 1 = 0.0210571 loss)
I1005 11:05:39.919288  9385 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1005 11:05:45.168349  9385 solver.cpp:218] Iteration 50200 (19.0511 iter/s, 5.24904s/100 iters), loss = 0.0797284
I1005 11:05:45.168380  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0797281 (* 1 = 0.0797281 loss)
I1005 11:05:45.168388  9385 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1005 11:05:50.417811  9385 solver.cpp:218] Iteration 50300 (19.0497 iter/s, 5.24941s/100 iters), loss = 0.0239021
I1005 11:05:50.417843  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239018 (* 1 = 0.0239018 loss)
I1005 11:05:50.417851  9385 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1005 11:05:55.660017  9385 solver.cpp:218] Iteration 50400 (19.0761 iter/s, 5.24215s/100 iters), loss = 0.0228475
I1005 11:05:55.660159  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228472 (* 1 = 0.0228472 loss)
I1005 11:05:55.660187  9385 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1005 11:06:00.643440  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:06:00.853390  9385 solver.cpp:330] Iteration 50500, Testing net (#0)
I1005 11:06:02.048812  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:06:02.098598  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9038
I1005 11:06:02.098634  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325149 (* 1 = 0.325149 loss)
I1005 11:06:02.150686  9385 solver.cpp:218] Iteration 50500 (15.4072 iter/s, 6.49049s/100 iters), loss = 0.0561779
I1005 11:06:02.150717  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561776 (* 1 = 0.0561776 loss)
I1005 11:06:02.150724  9385 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1005 11:06:07.389489  9385 solver.cpp:218] Iteration 50600 (19.0885 iter/s, 5.23875s/100 iters), loss = 0.0478547
I1005 11:06:07.389521  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0478544 (* 1 = 0.0478544 loss)
I1005 11:06:07.389528  9385 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1005 11:06:12.637128  9385 solver.cpp:218] Iteration 50700 (19.0564 iter/s, 5.24759s/100 iters), loss = 0.0758234
I1005 11:06:12.637168  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0758231 (* 1 = 0.0758231 loss)
I1005 11:06:12.637174  9385 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1005 11:06:17.885855  9385 solver.cpp:218] Iteration 50800 (19.0525 iter/s, 5.24867s/100 iters), loss = 0.0439739
I1005 11:06:17.885895  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439736 (* 1 = 0.0439736 loss)
I1005 11:06:17.885900  9385 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1005 11:06:23.134207  9385 solver.cpp:218] Iteration 50900 (19.0538 iter/s, 5.24829s/100 iters), loss = 0.0254477
I1005 11:06:23.134248  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254474 (* 1 = 0.0254474 loss)
I1005 11:06:23.134254  9385 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1005 11:06:28.116916  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:06:28.326050  9385 solver.cpp:330] Iteration 51000, Testing net (#0)
I1005 11:06:29.521836  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:06:29.571763  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I1005 11:06:29.571799  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343995 (* 1 = 0.343995 loss)
I1005 11:06:29.623540  9385 solver.cpp:218] Iteration 51000 (15.41 iter/s, 6.48927s/100 iters), loss = 0.0259036
I1005 11:06:29.623575  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259033 (* 1 = 0.0259033 loss)
I1005 11:06:29.623582  9385 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1005 11:06:34.874631  9385 solver.cpp:218] Iteration 51100 (19.0439 iter/s, 5.25104s/100 iters), loss = 0.0398044
I1005 11:06:34.874661  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398041 (* 1 = 0.0398041 loss)
I1005 11:06:34.874667  9385 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1005 11:06:40.119215  9385 solver.cpp:218] Iteration 51200 (19.0675 iter/s, 5.24453s/100 iters), loss = 0.0149646
I1005 11:06:40.119258  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149643 (* 1 = 0.0149643 loss)
I1005 11:06:40.119279  9385 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1005 11:06:45.371342  9385 solver.cpp:218] Iteration 51300 (19.0401 iter/s, 5.25207s/100 iters), loss = 0.0339366
I1005 11:06:45.371369  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339363 (* 1 = 0.0339363 loss)
I1005 11:06:45.371376  9385 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1005 11:06:50.619168  9385 solver.cpp:218] Iteration 51400 (19.0557 iter/s, 5.24778s/100 iters), loss = 0.034852
I1005 11:06:50.619197  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348516 (* 1 = 0.0348516 loss)
I1005 11:06:50.619204  9385 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1005 11:06:55.603443  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:06:55.814393  9385 solver.cpp:330] Iteration 51500, Testing net (#0)
I1005 11:06:57.002459  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:06:57.052306  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9021
I1005 11:06:57.052341  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355975 (* 1 = 0.355975 loss)
I1005 11:06:57.103998  9385 solver.cpp:218] Iteration 51500 (15.4207 iter/s, 6.48478s/100 iters), loss = 0.0370902
I1005 11:06:57.104028  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0370898 (* 1 = 0.0370898 loss)
I1005 11:06:57.104035  9385 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1005 11:07:02.352056  9385 solver.cpp:218] Iteration 51600 (19.0548 iter/s, 5.24801s/100 iters), loss = 0.0568217
I1005 11:07:02.352198  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568214 (* 1 = 0.0568214 loss)
I1005 11:07:02.352205  9385 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1005 11:07:07.595917  9385 solver.cpp:218] Iteration 51700 (19.0705 iter/s, 5.2437s/100 iters), loss = 0.0175793
I1005 11:07:07.595952  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017579 (* 1 = 0.017579 loss)
I1005 11:07:07.595958  9385 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1005 11:07:12.837875  9385 solver.cpp:218] Iteration 51800 (19.077 iter/s, 5.2419s/100 iters), loss = 0.0164584
I1005 11:07:12.837906  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164581 (* 1 = 0.0164581 loss)
I1005 11:07:12.837914  9385 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1005 11:07:18.084636  9385 solver.cpp:218] Iteration 51900 (19.0596 iter/s, 5.24671s/100 iters), loss = 0.0367513
I1005 11:07:18.084668  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036751 (* 1 = 0.036751 loss)
I1005 11:07:18.084676  9385 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1005 11:07:23.073577  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:07:23.283325  9385 solver.cpp:330] Iteration 52000, Testing net (#0)
I1005 11:07:24.471590  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:07:24.521235  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8979
I1005 11:07:24.521260  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364856 (* 1 = 0.364856 loss)
I1005 11:07:24.573299  9385 solver.cpp:218] Iteration 52000 (15.4116 iter/s, 6.48861s/100 iters), loss = 0.023402
I1005 11:07:24.573343  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234016 (* 1 = 0.0234016 loss)
I1005 11:07:24.573350  9385 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1005 11:07:29.826625  9385 solver.cpp:218] Iteration 52100 (19.0358 iter/s, 5.25327s/100 iters), loss = 0.0653559
I1005 11:07:29.826664  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0653556 (* 1 = 0.0653556 loss)
I1005 11:07:29.826670  9385 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1005 11:07:35.075405  9385 solver.cpp:218] Iteration 52200 (19.0523 iter/s, 5.24872s/100 iters), loss = 0.0371181
I1005 11:07:35.075567  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371178 (* 1 = 0.0371178 loss)
I1005 11:07:35.075575  9385 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1005 11:07:40.316606  9385 solver.cpp:218] Iteration 52300 (19.0802 iter/s, 5.24102s/100 iters), loss = 0.0684571
I1005 11:07:40.316635  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0684568 (* 1 = 0.0684568 loss)
I1005 11:07:40.316642  9385 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1005 11:07:45.562971  9385 solver.cpp:218] Iteration 52400 (19.061 iter/s, 5.24632s/100 iters), loss = 0.0358386
I1005 11:07:45.563001  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358382 (* 1 = 0.0358382 loss)
I1005 11:07:45.563007  9385 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1005 11:07:50.552381  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:07:50.762354  9385 solver.cpp:330] Iteration 52500, Testing net (#0)
I1005 11:07:51.949759  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:07:51.999446  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I1005 11:07:51.999472  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360236 (* 1 = 0.360236 loss)
I1005 11:07:52.051818  9385 solver.cpp:218] Iteration 52500 (15.4112 iter/s, 6.4888s/100 iters), loss = 0.0323218
I1005 11:07:52.051848  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323214 (* 1 = 0.0323214 loss)
I1005 11:07:52.051854  9385 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1005 11:07:57.296948  9385 solver.cpp:218] Iteration 52600 (19.0655 iter/s, 5.24508s/100 iters), loss = 0.0381049
I1005 11:07:57.296979  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381045 (* 1 = 0.0381045 loss)
I1005 11:07:57.296985  9385 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1005 11:08:02.544554  9385 solver.cpp:218] Iteration 52700 (19.0565 iter/s, 5.24755s/100 iters), loss = 0.0427249
I1005 11:08:02.544595  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427246 (* 1 = 0.0427246 loss)
I1005 11:08:02.544600  9385 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1005 11:08:07.790417  9385 solver.cpp:218] Iteration 52800 (19.0629 iter/s, 5.2458s/100 iters), loss = 0.0248303
I1005 11:08:07.790534  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02483 (* 1 = 0.02483 loss)
I1005 11:08:07.790541  9385 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1005 11:08:13.022928  9385 solver.cpp:218] Iteration 52900 (19.1117 iter/s, 5.23239s/100 iters), loss = 0.0268537
I1005 11:08:13.022969  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268533 (* 1 = 0.0268533 loss)
I1005 11:08:13.022975  9385 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1005 11:08:18.011183  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:08:18.220595  9385 solver.cpp:330] Iteration 53000, Testing net (#0)
I1005 11:08:19.408073  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:08:19.459367  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8943
I1005 11:08:19.459394  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378096 (* 1 = 0.378096 loss)
I1005 11:08:19.513439  9385 solver.cpp:218] Iteration 53000 (15.4073 iter/s, 6.49045s/100 iters), loss = 0.0325842
I1005 11:08:19.513494  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325838 (* 1 = 0.0325838 loss)
I1005 11:08:19.513505  9385 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1005 11:08:24.759995  9385 solver.cpp:218] Iteration 53100 (19.0605 iter/s, 5.24646s/100 iters), loss = 0.055493
I1005 11:08:24.760028  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554927 (* 1 = 0.0554927 loss)
I1005 11:08:24.760036  9385 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1005 11:08:30.010730  9385 solver.cpp:218] Iteration 53200 (19.0451 iter/s, 5.25069s/100 iters), loss = 0.0469164
I1005 11:08:30.010761  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469161 (* 1 = 0.0469161 loss)
I1005 11:08:30.010771  9385 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1005 11:08:35.252439  9385 solver.cpp:218] Iteration 53300 (19.0779 iter/s, 5.24166s/100 iters), loss = 0.0741726
I1005 11:08:35.252471  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0741723 (* 1 = 0.0741723 loss)
I1005 11:08:35.252480  9385 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1005 11:08:40.491506  9385 solver.cpp:218] Iteration 53400 (19.0876 iter/s, 5.23902s/100 iters), loss = 0.0395599
I1005 11:08:40.491636  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395596 (* 1 = 0.0395596 loss)
I1005 11:08:40.491684  9385 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1005 11:08:45.477607  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:08:45.687249  9385 solver.cpp:330] Iteration 53500, Testing net (#0)
I1005 11:08:46.883673  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:08:46.933398  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8941
I1005 11:08:46.933425  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377978 (* 1 = 0.377978 loss)
I1005 11:08:46.985466  9385 solver.cpp:218] Iteration 53500 (15.3993 iter/s, 6.49381s/100 iters), loss = 0.015776
I1005 11:08:46.985496  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157756 (* 1 = 0.0157756 loss)
I1005 11:08:46.985505  9385 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1005 11:08:52.229099  9385 solver.cpp:218] Iteration 53600 (19.0709 iter/s, 5.24359s/100 iters), loss = 0.0326922
I1005 11:08:52.229133  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326919 (* 1 = 0.0326919 loss)
I1005 11:08:52.229151  9385 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1005 11:08:57.484071  9385 solver.cpp:218] Iteration 53700 (19.0298 iter/s, 5.25492s/100 iters), loss = 0.034718
I1005 11:08:57.484112  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347176 (* 1 = 0.0347176 loss)
I1005 11:08:57.484117  9385 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1005 11:09:02.741556  9385 solver.cpp:218] Iteration 53800 (19.0207 iter/s, 5.25743s/100 iters), loss = 0.041113
I1005 11:09:02.741597  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411127 (* 1 = 0.0411127 loss)
I1005 11:09:02.741602  9385 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1005 11:09:07.991336  9385 solver.cpp:218] Iteration 53900 (19.0486 iter/s, 5.24972s/100 iters), loss = 0.0193207
I1005 11:09:07.991367  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193203 (* 1 = 0.0193203 loss)
I1005 11:09:07.991384  9385 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1005 11:09:12.975023  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:09:13.185226  9385 solver.cpp:330] Iteration 54000, Testing net (#0)
I1005 11:09:14.378434  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:09:14.428275  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8948
I1005 11:09:14.428310  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380873 (* 1 = 0.380873 loss)
I1005 11:09:14.480656  9385 solver.cpp:218] Iteration 54000 (15.4101 iter/s, 6.48927s/100 iters), loss = 0.0266665
I1005 11:09:14.480685  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266662 (* 1 = 0.0266662 loss)
I1005 11:09:14.480692  9385 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1005 11:09:19.730623  9385 solver.cpp:218] Iteration 54100 (19.0479 iter/s, 5.24992s/100 iters), loss = 0.0475862
I1005 11:09:19.730655  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0475858 (* 1 = 0.0475858 loss)
I1005 11:09:19.730661  9385 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1005 11:09:24.972154  9385 solver.cpp:218] Iteration 54200 (19.0786 iter/s, 5.24148s/100 iters), loss = 0.0951707
I1005 11:09:24.972187  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0951703 (* 1 = 0.0951703 loss)
I1005 11:09:24.972193  9385 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1005 11:09:30.221717  9385 solver.cpp:218] Iteration 54300 (19.0494 iter/s, 5.24952s/100 iters), loss = 0.0630363
I1005 11:09:30.221757  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0630359 (* 1 = 0.0630359 loss)
I1005 11:09:30.221763  9385 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1005 11:09:35.473069  9385 solver.cpp:218] Iteration 54400 (19.0429 iter/s, 5.25129s/100 iters), loss = 0.0610967
I1005 11:09:35.473098  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0610963 (* 1 = 0.0610963 loss)
I1005 11:09:35.473104  9385 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1005 11:09:40.457789  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:09:40.673689  9385 solver.cpp:330] Iteration 54500, Testing net (#0)
I1005 11:09:41.860760  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:09:41.910538  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I1005 11:09:41.910573  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35495 (* 1 = 0.35495 loss)
I1005 11:09:41.962777  9385 solver.cpp:218] Iteration 54500 (15.4091 iter/s, 6.48966s/100 iters), loss = 0.0588022
I1005 11:09:41.962802  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0588019 (* 1 = 0.0588019 loss)
I1005 11:09:41.962808  9385 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1005 11:09:47.216018  9385 solver.cpp:218] Iteration 54600 (19.036 iter/s, 5.25319s/100 iters), loss = 0.0348343
I1005 11:09:47.216133  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034834 (* 1 = 0.034834 loss)
I1005 11:09:47.216153  9385 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1005 11:09:52.456578  9385 solver.cpp:218] Iteration 54700 (19.0824 iter/s, 5.24042s/100 iters), loss = 0.0561209
I1005 11:09:52.456624  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561205 (* 1 = 0.0561205 loss)
I1005 11:09:52.456630  9385 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1005 11:09:57.700817  9385 solver.cpp:218] Iteration 54800 (19.0689 iter/s, 5.24414s/100 iters), loss = 0.0446219
I1005 11:09:57.700846  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446216 (* 1 = 0.0446216 loss)
I1005 11:09:57.700852  9385 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1005 11:10:02.945744  9385 solver.cpp:218] Iteration 54900 (19.0662 iter/s, 5.24488s/100 iters), loss = 0.0374363
I1005 11:10:02.945783  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374359 (* 1 = 0.0374359 loss)
I1005 11:10:02.945789  9385 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1005 11:10:07.930904  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:10:08.139948  9385 solver.cpp:330] Iteration 55000, Testing net (#0)
I1005 11:10:09.327869  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:10:09.377423  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1005 11:10:09.377457  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372329 (* 1 = 0.372329 loss)
I1005 11:10:09.430047  9385 solver.cpp:218] Iteration 55000 (15.422 iter/s, 6.48425s/100 iters), loss = 0.0315766
I1005 11:10:09.430071  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315762 (* 1 = 0.0315762 loss)
I1005 11:10:09.430078  9385 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1005 11:10:14.671967  9385 solver.cpp:218] Iteration 55100 (19.0771 iter/s, 5.24188s/100 iters), loss = 0.0267395
I1005 11:10:14.672006  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267391 (* 1 = 0.0267391 loss)
I1005 11:10:14.672011  9385 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1005 11:10:19.917179  9385 solver.cpp:218] Iteration 55200 (19.0652 iter/s, 5.24515s/100 iters), loss = 0.0289702
I1005 11:10:19.917348  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289698 (* 1 = 0.0289698 loss)
I1005 11:10:19.917356  9385 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1005 11:10:25.158524  9385 solver.cpp:218] Iteration 55300 (19.0797 iter/s, 5.24117s/100 iters), loss = 0.085454
I1005 11:10:25.158555  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0854536 (* 1 = 0.0854536 loss)
I1005 11:10:25.158560  9385 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1005 11:10:30.406970  9385 solver.cpp:218] Iteration 55400 (19.0534 iter/s, 5.2484s/100 iters), loss = 0.0449197
I1005 11:10:30.407011  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449194 (* 1 = 0.0449194 loss)
I1005 11:10:30.407017  9385 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1005 11:10:35.395756  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:10:35.605903  9385 solver.cpp:330] Iteration 55500, Testing net (#0)
I1005 11:10:36.793630  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:10:36.843547  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9058
I1005 11:10:36.843570  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353842 (* 1 = 0.353842 loss)
I1005 11:10:36.896049  9385 solver.cpp:218] Iteration 55500 (15.4106 iter/s, 6.48902s/100 iters), loss = 0.0203848
I1005 11:10:36.896075  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203844 (* 1 = 0.0203844 loss)
I1005 11:10:36.896081  9385 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1005 11:10:42.153254  9385 solver.cpp:218] Iteration 55600 (19.0217 iter/s, 5.25716s/100 iters), loss = 0.044895
I1005 11:10:42.153285  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0448946 (* 1 = 0.0448946 loss)
I1005 11:10:42.153291  9385 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1005 11:10:47.409405  9385 solver.cpp:218] Iteration 55700 (19.0255 iter/s, 5.2561s/100 iters), loss = 0.0325093
I1005 11:10:47.409436  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325089 (* 1 = 0.0325089 loss)
I1005 11:10:47.409442  9385 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1005 11:10:52.656644  9385 solver.cpp:218] Iteration 55800 (19.0578 iter/s, 5.24719s/100 iters), loss = 0.0256204
I1005 11:10:52.656761  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02562 (* 1 = 0.02562 loss)
I1005 11:10:52.656780  9385 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1005 11:10:57.898558  9385 solver.cpp:218] Iteration 55900 (19.0774 iter/s, 5.24179s/100 iters), loss = 0.0376698
I1005 11:10:57.898587  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376695 (* 1 = 0.0376695 loss)
I1005 11:10:57.898593  9385 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1005 11:11:02.893062  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:11:03.102453  9385 solver.cpp:330] Iteration 56000, Testing net (#0)
I1005 11:11:04.291481  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:11:04.341042  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I1005 11:11:04.341066  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412186 (* 1 = 0.412186 loss)
I1005 11:11:04.393313  9385 solver.cpp:218] Iteration 56000 (15.3972 iter/s, 6.49471s/100 iters), loss = 0.0224256
I1005 11:11:04.393339  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224252 (* 1 = 0.0224252 loss)
I1005 11:11:04.393347  9385 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1005 11:11:09.645877  9385 solver.cpp:218] Iteration 56100 (19.0385 iter/s, 5.25252s/100 iters), loss = 0.0258291
I1005 11:11:09.645911  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258287 (* 1 = 0.0258287 loss)
I1005 11:11:09.645917  9385 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1005 11:11:14.896994  9385 solver.cpp:218] Iteration 56200 (19.0438 iter/s, 5.25106s/100 iters), loss = 0.0474324
I1005 11:11:14.897023  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474321 (* 1 = 0.0474321 loss)
I1005 11:11:14.897029  9385 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1005 11:11:20.150471  9385 solver.cpp:218] Iteration 56300 (19.0352 iter/s, 5.25343s/100 iters), loss = 0.0273139
I1005 11:11:20.150511  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273136 (* 1 = 0.0273136 loss)
I1005 11:11:20.150516  9385 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1005 11:11:25.387331  9385 solver.cpp:218] Iteration 56400 (19.0956 iter/s, 5.2368s/100 iters), loss = 0.0141918
I1005 11:11:25.387470  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141915 (* 1 = 0.0141915 loss)
I1005 11:11:25.387486  9385 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1005 11:11:30.369668  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:11:30.579218  9385 solver.cpp:330] Iteration 56500, Testing net (#0)
I1005 11:11:31.776600  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:11:31.826582  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8976
I1005 11:11:31.826617  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.399979 (* 1 = 0.399979 loss)
I1005 11:11:31.878667  9385 solver.cpp:218] Iteration 56500 (15.4055 iter/s, 6.49119s/100 iters), loss = 0.0406489
I1005 11:11:31.878700  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406486 (* 1 = 0.0406486 loss)
I1005 11:11:31.878708  9385 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1005 11:11:37.118321  9385 solver.cpp:218] Iteration 56600 (19.0854 iter/s, 5.2396s/100 iters), loss = 0.0245937
I1005 11:11:37.118361  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245933 (* 1 = 0.0245933 loss)
I1005 11:11:37.118368  9385 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1005 11:11:42.360160  9385 solver.cpp:218] Iteration 56700 (19.0775 iter/s, 5.24178s/100 iters), loss = 0.0406551
I1005 11:11:42.360208  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406547 (* 1 = 0.0406547 loss)
I1005 11:11:42.360214  9385 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1005 11:11:47.603986  9385 solver.cpp:218] Iteration 56800 (19.0703 iter/s, 5.24376s/100 iters), loss = 0.0450604
I1005 11:11:47.604032  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450601 (* 1 = 0.0450601 loss)
I1005 11:11:47.604039  9385 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1005 11:11:52.848028  9385 solver.cpp:218] Iteration 56900 (19.0695 iter/s, 5.24398s/100 iters), loss = 0.04699
I1005 11:11:52.848057  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469897 (* 1 = 0.0469897 loss)
I1005 11:11:52.848063  9385 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1005 11:11:57.831514  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:11:58.041098  9385 solver.cpp:330] Iteration 57000, Testing net (#0)
I1005 11:11:59.237718  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:11:59.287534  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8979
I1005 11:11:59.287569  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37836 (* 1 = 0.37836 loss)
I1005 11:11:59.339896  9385 solver.cpp:218] Iteration 57000 (15.404 iter/s, 6.49182s/100 iters), loss = 0.0220464
I1005 11:11:59.339927  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220461 (* 1 = 0.0220461 loss)
I1005 11:11:59.339934  9385 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1005 11:12:04.590481  9385 solver.cpp:218] Iteration 57100 (19.0457 iter/s, 5.25053s/100 iters), loss = 0.040795
I1005 11:12:04.590538  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407947 (* 1 = 0.0407947 loss)
I1005 11:12:04.590545  9385 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1005 11:12:09.835631  9385 solver.cpp:218] Iteration 57200 (19.0656 iter/s, 5.24506s/100 iters), loss = 0.0238931
I1005 11:12:09.835660  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238928 (* 1 = 0.0238928 loss)
I1005 11:12:09.835666  9385 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1005 11:12:15.089409  9385 solver.cpp:218] Iteration 57300 (19.0341 iter/s, 5.25373s/100 iters), loss = 0.0195941
I1005 11:12:15.089448  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195937 (* 1 = 0.0195937 loss)
I1005 11:12:15.089454  9385 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1005 11:12:20.339359  9385 solver.cpp:218] Iteration 57400 (19.048 iter/s, 5.24989s/100 iters), loss = 0.00922778
I1005 11:12:20.339401  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00922746 (* 1 = 0.00922746 loss)
I1005 11:12:20.339406  9385 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1005 11:12:25.322322  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:12:25.534919  9385 solver.cpp:330] Iteration 57500, Testing net (#0)
I1005 11:12:26.725749  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:12:26.775547  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8899
I1005 11:12:26.775583  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422988 (* 1 = 0.422988 loss)
I1005 11:12:26.828048  9385 solver.cpp:218] Iteration 57500 (15.4116 iter/s, 6.48863s/100 iters), loss = 0.0252992
I1005 11:12:26.828076  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252989 (* 1 = 0.0252989 loss)
I1005 11:12:26.828083  9385 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1005 11:12:32.073104  9385 solver.cpp:218] Iteration 57600 (19.0657 iter/s, 5.24501s/100 iters), loss = 0.0481911
I1005 11:12:32.073242  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0481909 (* 1 = 0.0481909 loss)
I1005 11:12:32.073261  9385 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1005 11:12:37.311226  9385 solver.cpp:218] Iteration 57700 (19.0914 iter/s, 5.23797s/100 iters), loss = 0.0297449
I1005 11:12:37.311256  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297446 (* 1 = 0.0297446 loss)
I1005 11:12:37.311262  9385 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1005 11:12:42.554311  9385 solver.cpp:218] Iteration 57800 (19.073 iter/s, 5.24302s/100 iters), loss = 0.0151646
I1005 11:12:42.554342  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151643 (* 1 = 0.0151643 loss)
I1005 11:12:42.554347  9385 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1005 11:12:47.802637  9385 solver.cpp:218] Iteration 57900 (19.0539 iter/s, 5.24828s/100 iters), loss = 0.0414898
I1005 11:12:47.802666  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414895 (* 1 = 0.0414895 loss)
I1005 11:12:47.802682  9385 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1005 11:12:52.791589  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:12:53.001235  9385 solver.cpp:330] Iteration 58000, Testing net (#0)
I1005 11:12:54.188763  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:12:54.238641  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9007
I1005 11:12:54.238674  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389191 (* 1 = 0.389191 loss)
I1005 11:12:54.290984  9385 solver.cpp:218] Iteration 58000 (15.4124 iter/s, 6.4883s/100 iters), loss = 0.0366851
I1005 11:12:54.291008  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366848 (* 1 = 0.0366848 loss)
I1005 11:12:54.291014  9385 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1005 11:12:59.541190  9385 solver.cpp:218] Iteration 58100 (19.047 iter/s, 5.25016s/100 iters), loss = 0.0169663
I1005 11:12:59.541219  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016966 (* 1 = 0.016966 loss)
I1005 11:12:59.541224  9385 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1005 11:13:04.789562  9385 solver.cpp:218] Iteration 58200 (19.0537 iter/s, 5.24832s/100 iters), loss = 0.0138207
I1005 11:13:04.789680  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138204 (* 1 = 0.0138204 loss)
I1005 11:13:04.789686  9385 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1005 11:13:10.027734  9385 solver.cpp:218] Iteration 58300 (19.0911 iter/s, 5.23805s/100 iters), loss = 0.0172708
I1005 11:13:10.027766  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172705 (* 1 = 0.0172705 loss)
I1005 11:13:10.027772  9385 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1005 11:13:15.269037  9385 solver.cpp:218] Iteration 58400 (19.0794 iter/s, 5.24125s/100 iters), loss = 0.0218288
I1005 11:13:15.269068  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218285 (* 1 = 0.0218285 loss)
I1005 11:13:15.269084  9385 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1005 11:13:20.261241  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:13:20.471344  9385 solver.cpp:330] Iteration 58500, Testing net (#0)
I1005 11:13:21.659689  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:13:21.709728  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8981
I1005 11:13:21.709763  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398166 (* 1 = 0.398166 loss)
I1005 11:13:21.761936  9385 solver.cpp:218] Iteration 58500 (15.4016 iter/s, 6.49285s/100 iters), loss = 0.0485519
I1005 11:13:21.761961  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485516 (* 1 = 0.0485516 loss)
I1005 11:13:21.761967  9385 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1005 11:13:27.014120  9385 solver.cpp:218] Iteration 58600 (19.0399 iter/s, 5.25214s/100 iters), loss = 0.0273318
I1005 11:13:27.014159  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273315 (* 1 = 0.0273315 loss)
I1005 11:13:27.014165  9385 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1005 11:13:32.265476  9385 solver.cpp:218] Iteration 58700 (19.0429 iter/s, 5.2513s/100 iters), loss = 0.032287
I1005 11:13:32.265506  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322867 (* 1 = 0.0322867 loss)
I1005 11:13:32.265512  9385 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1005 11:13:37.511082  9385 solver.cpp:218] Iteration 58800 (19.0638 iter/s, 5.24555s/100 iters), loss = 0.0280258
I1005 11:13:37.511229  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280255 (* 1 = 0.0280255 loss)
I1005 11:13:37.511247  9385 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1005 11:13:42.755658  9385 solver.cpp:218] Iteration 58900 (19.068 iter/s, 5.24439s/100 iters), loss = 0.0401459
I1005 11:13:42.755698  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401456 (* 1 = 0.0401456 loss)
I1005 11:13:42.755704  9385 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1005 11:13:47.744607  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:13:47.954514  9385 solver.cpp:330] Iteration 59000, Testing net (#0)
I1005 11:13:49.142972  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:13:49.192545  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8947
I1005 11:13:49.192580  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.416607 (* 1 = 0.416607 loss)
I1005 11:13:49.245079  9385 solver.cpp:218] Iteration 59000 (15.4098 iter/s, 6.48936s/100 iters), loss = 0.0214711
I1005 11:13:49.245111  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214707 (* 1 = 0.0214707 loss)
I1005 11:13:49.245118  9385 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1005 11:13:54.498914  9385 solver.cpp:218] Iteration 59100 (19.0339 iter/s, 5.25378s/100 iters), loss = 0.0128015
I1005 11:13:54.498955  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128012 (* 1 = 0.0128012 loss)
I1005 11:13:54.498961  9385 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1005 11:13:59.746649  9385 solver.cpp:218] Iteration 59200 (19.0561 iter/s, 5.24767s/100 iters), loss = 0.00790088
I1005 11:13:59.746690  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790058 (* 1 = 0.00790058 loss)
I1005 11:13:59.746695  9385 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1005 11:14:04.998096  9385 solver.cpp:218] Iteration 59300 (19.0426 iter/s, 5.25139s/100 iters), loss = 0.0809841
I1005 11:14:04.998127  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0809838 (* 1 = 0.0809838 loss)
I1005 11:14:04.998143  9385 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1005 11:14:10.236812  9385 solver.cpp:218] Iteration 59400 (19.0888 iter/s, 5.23867s/100 iters), loss = 0.0490459
I1005 11:14:10.236958  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0490456 (* 1 = 0.0490456 loss)
I1005 11:14:10.236974  9385 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1005 11:14:15.226363  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:14:15.436969  9385 solver.cpp:330] Iteration 59500, Testing net (#0)
I1005 11:14:16.629637  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:14:16.679877  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8922
I1005 11:14:16.679903  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.430145 (* 1 = 0.430145 loss)
I1005 11:14:16.733348  9385 solver.cpp:218] Iteration 59500 (15.3932 iter/s, 6.49638s/100 iters), loss = 0.0426053
I1005 11:14:16.733383  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042605 (* 1 = 0.042605 loss)
I1005 11:14:16.733391  9385 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1005 11:14:21.977314  9385 solver.cpp:218] Iteration 59600 (19.0697 iter/s, 5.24391s/100 iters), loss = 0.0178545
I1005 11:14:21.977355  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178542 (* 1 = 0.0178542 loss)
I1005 11:14:21.977360  9385 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1005 11:14:27.234252  9385 solver.cpp:218] Iteration 59700 (19.0227 iter/s, 5.25688s/100 iters), loss = 0.027751
I1005 11:14:27.234293  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277507 (* 1 = 0.0277507 loss)
I1005 11:14:27.234299  9385 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1005 11:14:32.487399  9385 solver.cpp:218] Iteration 59800 (19.0364 iter/s, 5.25309s/100 iters), loss = 0.020603
I1005 11:14:32.487439  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206027 (* 1 = 0.0206027 loss)
I1005 11:14:32.487445  9385 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1005 11:14:37.741120  9385 solver.cpp:218] Iteration 59900 (19.0343 iter/s, 5.25366s/100 iters), loss = 0.0336653
I1005 11:14:37.741155  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033665 (* 1 = 0.033665 loss)
I1005 11:14:37.741173  9385 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1005 11:14:42.728421  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:14:42.937316  9385 solver.cpp:330] Iteration 60000, Testing net (#0)
I1005 11:14:44.133579  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:14:44.183125  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8899
I1005 11:14:44.183161  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.432656 (* 1 = 0.432656 loss)
I1005 11:14:44.235267  9385 solver.cpp:218] Iteration 60000 (15.3986 iter/s, 6.4941s/100 iters), loss = 0.0190681
I1005 11:14:44.235296  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190678 (* 1 = 0.0190678 loss)
I1005 11:14:44.235301  9385 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1005 11:14:49.475543  9385 solver.cpp:218] Iteration 60100 (19.0832 iter/s, 5.24022s/100 iters), loss = 0.09006
I1005 11:14:49.475576  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0900597 (* 1 = 0.0900597 loss)
I1005 11:14:49.475584  9385 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1005 11:14:54.722175  9385 solver.cpp:218] Iteration 60200 (19.06 iter/s, 5.24658s/100 iters), loss = 0.0191198
I1005 11:14:54.722206  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191195 (* 1 = 0.0191195 loss)
I1005 11:14:54.722213  9385 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1005 11:14:59.967530  9385 solver.cpp:218] Iteration 60300 (19.0647 iter/s, 5.24531s/100 iters), loss = 0.0225554
I1005 11:14:59.967557  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225552 (* 1 = 0.0225552 loss)
I1005 11:14:59.967563  9385 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1005 11:15:05.211026  9385 solver.cpp:218] Iteration 60400 (19.0714 iter/s, 5.24345s/100 iters), loss = 0.0467315
I1005 11:15:05.211055  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0467312 (* 1 = 0.0467312 loss)
I1005 11:15:05.211061  9385 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1005 11:15:10.194891  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:15:10.404497  9385 solver.cpp:330] Iteration 60500, Testing net (#0)
I1005 11:15:11.601933  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:15:11.651847  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9005
I1005 11:15:11.651882  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374906 (* 1 = 0.374906 loss)
I1005 11:15:11.704509  9385 solver.cpp:218] Iteration 60500 (15.4002 iter/s, 6.49343s/100 iters), loss = 0.0267455
I1005 11:15:11.704538  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267452 (* 1 = 0.0267452 loss)
I1005 11:15:11.704545  9385 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1005 11:15:16.955284  9385 solver.cpp:218] Iteration 60600 (19.045 iter/s, 5.25073s/100 iters), loss = 0.0142131
I1005 11:15:16.955384  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142128 (* 1 = 0.0142128 loss)
I1005 11:15:16.955402  9385 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1005 11:15:22.198192  9385 solver.cpp:218] Iteration 60700 (19.0738 iter/s, 5.24279s/100 iters), loss = 0.0132989
I1005 11:15:22.198225  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132986 (* 1 = 0.0132986 loss)
I1005 11:15:22.198230  9385 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1005 11:15:27.447607  9385 solver.cpp:218] Iteration 60800 (19.0499 iter/s, 5.24937s/100 iters), loss = 0.0332933
I1005 11:15:27.447646  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033293 (* 1 = 0.033293 loss)
I1005 11:15:27.447652  9385 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1005 11:15:32.697557  9385 solver.cpp:218] Iteration 60900 (19.048 iter/s, 5.24989s/100 iters), loss = 0.0129407
I1005 11:15:32.697597  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129404 (* 1 = 0.0129404 loss)
I1005 11:15:32.697603  9385 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1005 11:15:37.689855  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:15:37.900543  9385 solver.cpp:330] Iteration 61000, Testing net (#0)
I1005 11:15:39.090791  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:15:39.140514  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8954
I1005 11:15:39.140549  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.407575 (* 1 = 0.407575 loss)
I1005 11:15:39.192631  9385 solver.cpp:218] Iteration 61000 (15.3964 iter/s, 6.49502s/100 iters), loss = 0.0364836
I1005 11:15:39.192657  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364833 (* 1 = 0.0364833 loss)
I1005 11:15:39.192663  9385 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1005 11:15:44.442466  9385 solver.cpp:218] Iteration 61100 (19.0484 iter/s, 5.24979s/100 iters), loss = 0.0160834
I1005 11:15:44.442507  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160832 (* 1 = 0.0160832 loss)
I1005 11:15:44.442512  9385 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1005 11:15:49.690723  9385 solver.cpp:218] Iteration 61200 (19.0542 iter/s, 5.2482s/100 iters), loss = 0.00842338
I1005 11:15:49.690841  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0084231 (* 1 = 0.0084231 loss)
I1005 11:15:49.690867  9385 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1005 11:15:54.937685  9385 solver.cpp:218] Iteration 61300 (19.0591 iter/s, 5.24684s/100 iters), loss = 0.0157298
I1005 11:15:54.937718  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157295 (* 1 = 0.0157295 loss)
I1005 11:15:54.937736  9385 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1005 11:16:00.189123  9385 solver.cpp:218] Iteration 61400 (19.0426 iter/s, 5.25139s/100 iters), loss = 0.00608119
I1005 11:16:00.189154  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00608093 (* 1 = 0.00608093 loss)
I1005 11:16:00.189163  9385 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1005 11:16:05.183436  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:16:05.393694  9385 solver.cpp:330] Iteration 61500, Testing net (#0)
I1005 11:16:06.582815  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:16:06.632858  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8951
I1005 11:16:06.632884  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.425977 (* 1 = 0.425977 loss)
I1005 11:16:06.685392  9385 solver.cpp:218] Iteration 61500 (15.3936 iter/s, 6.49622s/100 iters), loss = 0.0253512
I1005 11:16:06.685420  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253509 (* 1 = 0.0253509 loss)
I1005 11:16:06.685431  9385 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1005 11:16:11.939501  9385 solver.cpp:218] Iteration 61600 (19.0329 iter/s, 5.25406s/100 iters), loss = 0.0295978
I1005 11:16:11.939532  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295976 (* 1 = 0.0295976 loss)
I1005 11:16:11.939539  9385 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1005 11:16:17.189463  9385 solver.cpp:218] Iteration 61700 (19.0479 iter/s, 5.24991s/100 iters), loss = 0.0480719
I1005 11:16:17.189496  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0480716 (* 1 = 0.0480716 loss)
I1005 11:16:17.189503  9385 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1005 11:16:22.431296  9385 solver.cpp:218] Iteration 61800 (19.0775 iter/s, 5.24178s/100 iters), loss = 0.0251567
I1005 11:16:22.431498  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251564 (* 1 = 0.0251564 loss)
I1005 11:16:22.431509  9385 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1005 11:16:27.675971  9385 solver.cpp:218] Iteration 61900 (19.0677 iter/s, 5.24447s/100 iters), loss = 0.0202349
I1005 11:16:27.676003  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202347 (* 1 = 0.0202347 loss)
I1005 11:16:27.676012  9385 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1005 11:16:32.666048  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:16:32.876499  9385 solver.cpp:330] Iteration 62000, Testing net (#0)
I1005 11:16:34.065470  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:16:34.115408  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.898
I1005 11:16:34.115437  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.410142 (* 1 = 0.410142 loss)
I1005 11:16:34.167889  9385 solver.cpp:218] Iteration 62000 (15.4039 iter/s, 6.49187s/100 iters), loss = 0.0288086
I1005 11:16:34.167928  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288083 (* 1 = 0.0288083 loss)
I1005 11:16:34.167939  9385 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1005 11:16:39.414763  9385 solver.cpp:218] Iteration 62100 (19.0592 iter/s, 5.24682s/100 iters), loss = 0.0180376
I1005 11:16:39.414793  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180373 (* 1 = 0.0180373 loss)
I1005 11:16:39.414799  9385 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1005 11:16:44.665824  9385 solver.cpp:218] Iteration 62200 (19.0439 iter/s, 5.25101s/100 iters), loss = 0.012173
I1005 11:16:44.665866  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121727 (* 1 = 0.0121727 loss)
I1005 11:16:44.665873  9385 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1005 11:16:49.914921  9385 solver.cpp:218] Iteration 62300 (19.0511 iter/s, 5.24904s/100 iters), loss = 0.0241037
I1005 11:16:49.914954  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241034 (* 1 = 0.0241034 loss)
I1005 11:16:49.914973  9385 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1005 11:16:55.157187  9385 solver.cpp:218] Iteration 62400 (19.0759 iter/s, 5.24222s/100 iters), loss = 0.0383096
I1005 11:16:55.157325  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383093 (* 1 = 0.0383093 loss)
I1005 11:16:55.157333  9385 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1005 11:17:00.155834  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:17:00.365563  9385 solver.cpp:330] Iteration 62500, Testing net (#0)
I1005 11:17:01.558410  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:17:01.609539  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8921
I1005 11:17:01.609565  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415691 (* 1 = 0.415691 loss)
I1005 11:17:01.663655  9385 solver.cpp:218] Iteration 62500 (15.3697 iter/s, 6.50632s/100 iters), loss = 0.0159193
I1005 11:17:01.663700  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015919 (* 1 = 0.015919 loss)
I1005 11:17:01.663707  9385 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1005 11:17:06.906970  9385 solver.cpp:218] Iteration 62600 (19.0722 iter/s, 5.24322s/100 iters), loss = 0.0297525
I1005 11:17:06.907009  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297522 (* 1 = 0.0297522 loss)
I1005 11:17:06.907016  9385 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1005 11:17:12.156986  9385 solver.cpp:218] Iteration 62700 (19.0478 iter/s, 5.24996s/100 iters), loss = 0.00602254
I1005 11:17:12.157016  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00602226 (* 1 = 0.00602226 loss)
I1005 11:17:12.157021  9385 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1005 11:17:17.405767  9385 solver.cpp:218] Iteration 62800 (19.0522 iter/s, 5.24873s/100 iters), loss = 0.0749626
I1005 11:17:17.405808  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0749623 (* 1 = 0.0749623 loss)
I1005 11:17:17.405813  9385 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1005 11:17:22.651391  9385 solver.cpp:218] Iteration 62900 (19.0637 iter/s, 5.24556s/100 iters), loss = 0.0480077
I1005 11:17:22.651427  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0480074 (* 1 = 0.0480074 loss)
I1005 11:17:22.651444  9385 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1005 11:17:27.635680  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:17:27.844720  9385 solver.cpp:330] Iteration 63000, Testing net (#0)
I1005 11:17:29.037600  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:17:29.087440  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8982
I1005 11:17:29.087466  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40811 (* 1 = 0.40811 loss)
I1005 11:17:29.139817  9385 solver.cpp:218] Iteration 63000 (15.4122 iter/s, 6.48837s/100 iters), loss = 0.00538861
I1005 11:17:29.139844  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538832 (* 1 = 0.00538832 loss)
I1005 11:17:29.139850  9385 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1005 11:17:34.377974  9385 solver.cpp:218] Iteration 63100 (19.0909 iter/s, 5.23811s/100 iters), loss = 0.0496193
I1005 11:17:34.378013  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049619 (* 1 = 0.049619 loss)
I1005 11:17:34.378020  9385 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1005 11:17:39.627609  9385 solver.cpp:218] Iteration 63200 (19.0492 iter/s, 5.24958s/100 iters), loss = 0.0316149
I1005 11:17:39.627648  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316147 (* 1 = 0.0316147 loss)
I1005 11:17:39.627653  9385 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1005 11:17:44.877663  9385 solver.cpp:218] Iteration 63300 (19.0477 iter/s, 5.24998s/100 iters), loss = 0.0267031
I1005 11:17:44.877696  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267028 (* 1 = 0.0267028 loss)
I1005 11:17:44.877713  9385 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1005 11:17:50.121026  9385 solver.cpp:218] Iteration 63400 (19.0719 iter/s, 5.24331s/100 iters), loss = 0.00802268
I1005 11:17:50.121060  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00802241 (* 1 = 0.00802241 loss)
I1005 11:17:50.121069  9385 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1005 11:17:55.101788  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:17:55.311475  9385 solver.cpp:330] Iteration 63500, Testing net (#0)
I1005 11:17:56.507437  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:17:56.557503  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8877
I1005 11:17:56.557530  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.468564 (* 1 = 0.468564 loss)
I1005 11:17:56.609472  9385 solver.cpp:218] Iteration 63500 (15.4121 iter/s, 6.48839s/100 iters), loss = 0.0173649
I1005 11:17:56.609501  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173647 (* 1 = 0.0173647 loss)
I1005 11:17:56.609510  9385 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1005 11:18:01.858999  9385 solver.cpp:218] Iteration 63600 (19.0495 iter/s, 5.24948s/100 iters), loss = 0.0289248
I1005 11:18:01.859133  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289246 (* 1 = 0.0289246 loss)
I1005 11:18:01.859140  9385 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1005 11:18:07.095685  9385 solver.cpp:218] Iteration 63700 (19.0966 iter/s, 5.23654s/100 iters), loss = 0.084878
I1005 11:18:07.095736  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848777 (* 1 = 0.0848777 loss)
I1005 11:18:07.095752  9385 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1005 11:18:12.345825  9385 solver.cpp:218] Iteration 63800 (19.0474 iter/s, 5.25007s/100 iters), loss = 0.0190554
I1005 11:18:12.345860  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190551 (* 1 = 0.0190551 loss)
I1005 11:18:12.345865  9385 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1005 11:18:17.592607  9385 solver.cpp:218] Iteration 63900 (19.0595 iter/s, 5.24673s/100 iters), loss = 0.0695744
I1005 11:18:17.592635  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0695741 (* 1 = 0.0695741 loss)
I1005 11:18:17.592640  9385 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1005 11:18:22.579414  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:18:22.793823  9385 solver.cpp:330] Iteration 64000, Testing net (#0)
I1005 11:18:23.981775  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:18:24.031141  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.89
I1005 11:18:24.031177  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.445831 (* 1 = 0.445831 loss)
I1005 11:18:24.083540  9385 solver.cpp:218] Iteration 64000 (15.4062 iter/s, 6.49089s/100 iters), loss = 0.00844954
I1005 11:18:24.083570  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844927 (* 1 = 0.00844927 loss)
I1005 11:18:24.083578  9385 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1005 11:18:29.339011  9385 solver.cpp:218] Iteration 64100 (19.028 iter/s, 5.25542s/100 iters), loss = 0.00977778
I1005 11:18:29.339041  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0097775 (* 1 = 0.0097775 loss)
I1005 11:18:29.339046  9385 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1005 11:18:34.586165  9385 solver.cpp:218] Iteration 64200 (19.0581 iter/s, 5.2471s/100 iters), loss = 0.041909
I1005 11:18:34.586283  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419087 (* 1 = 0.0419087 loss)
I1005 11:18:34.586302  9385 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1005 11:18:39.832959  9385 solver.cpp:218] Iteration 64300 (19.0598 iter/s, 5.24664s/100 iters), loss = 0.00844843
I1005 11:18:39.832991  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844814 (* 1 = 0.00844814 loss)
I1005 11:18:39.833008  9385 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1005 11:18:45.079161  9385 solver.cpp:218] Iteration 64400 (19.0616 iter/s, 5.24615s/100 iters), loss = 0.0107063
I1005 11:18:45.079191  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107059 (* 1 = 0.0107059 loss)
I1005 11:18:45.079207  9385 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1005 11:18:50.068440  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:18:50.277686  9385 solver.cpp:330] Iteration 64500, Testing net (#0)
I1005 11:18:51.465945  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:18:51.515867  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8929
I1005 11:18:51.515902  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.435826 (* 1 = 0.435826 loss)
I1005 11:18:51.568194  9385 solver.cpp:218] Iteration 64500 (15.4107 iter/s, 6.48898s/100 iters), loss = 0.0251886
I1005 11:18:51.568224  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251883 (* 1 = 0.0251883 loss)
I1005 11:18:51.568231  9385 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1005 11:18:56.815601  9385 solver.cpp:218] Iteration 64600 (19.0572 iter/s, 5.24736s/100 iters), loss = 0.0458061
I1005 11:18:56.815630  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0458057 (* 1 = 0.0458057 loss)
I1005 11:18:56.815636  9385 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1005 11:19:02.065443  9385 solver.cpp:218] Iteration 64700 (19.0484 iter/s, 5.24979s/100 iters), loss = 0.0152027
I1005 11:19:02.065470  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152023 (* 1 = 0.0152023 loss)
I1005 11:19:02.065476  9385 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1005 11:19:07.302927  9385 solver.cpp:218] Iteration 64800 (19.0933 iter/s, 5.23744s/100 iters), loss = 0.0181441
I1005 11:19:07.303076  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181438 (* 1 = 0.0181438 loss)
I1005 11:19:07.303084  9385 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1005 11:19:12.551352  9385 solver.cpp:218] Iteration 64900 (19.0539 iter/s, 5.24826s/100 iters), loss = 0.0398207
I1005 11:19:12.551393  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398204 (* 1 = 0.0398204 loss)
I1005 11:19:12.551398  9385 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1005 11:19:17.544143  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:19:17.754459  9385 solver.cpp:330] Iteration 65000, Testing net (#0)
I1005 11:19:18.940831  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:19:18.990448  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I1005 11:19:18.990483  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415388 (* 1 = 0.415388 loss)
I1005 11:19:19.042825  9385 solver.cpp:218] Iteration 65000 (15.405 iter/s, 6.49141s/100 iters), loss = 0.0180563
I1005 11:19:19.042851  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018056 (* 1 = 0.018056 loss)
I1005 11:19:19.042857  9385 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1005 11:19:24.293454  9385 solver.cpp:218] Iteration 65100 (19.0455 iter/s, 5.25058s/100 iters), loss = 0.0280863
I1005 11:19:24.293494  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028086 (* 1 = 0.028086 loss)
I1005 11:19:24.293500  9385 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1005 11:19:29.544440  9385 solver.cpp:218] Iteration 65200 (19.0443 iter/s, 5.25093s/100 iters), loss = 0.03186
I1005 11:19:29.544471  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318597 (* 1 = 0.0318597 loss)
I1005 11:19:29.544477  9385 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1005 11:19:34.792125  9385 solver.cpp:218] Iteration 65300 (19.0562 iter/s, 5.24763s/100 iters), loss = 0.0807415
I1005 11:19:34.792158  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0807412 (* 1 = 0.0807412 loss)
I1005 11:19:34.792166  9385 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1005 11:19:40.028022  9385 solver.cpp:218] Iteration 65400 (19.0991 iter/s, 5.23585s/100 iters), loss = 0.0708298
I1005 11:19:40.028141  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708295 (* 1 = 0.0708295 loss)
I1005 11:19:40.028148  9385 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1005 11:19:45.014844  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:19:45.223821  9385 solver.cpp:330] Iteration 65500, Testing net (#0)
I1005 11:19:46.411608  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:19:46.461644  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8986
I1005 11:19:46.461680  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.423249 (* 1 = 0.423249 loss)
I1005 11:19:46.515264  9385 solver.cpp:218] Iteration 65500 (15.4152 iter/s, 6.48711s/100 iters), loss = 0.00705912
I1005 11:19:46.515292  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705876 (* 1 = 0.00705876 loss)
I1005 11:19:46.515298  9385 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1005 11:19:51.761174  9385 solver.cpp:218] Iteration 65600 (19.0626 iter/s, 5.24586s/100 iters), loss = 0.0182997
I1005 11:19:51.761214  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182993 (* 1 = 0.0182993 loss)
I1005 11:19:51.761219  9385 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1005 11:19:57.010805  9385 solver.cpp:218] Iteration 65700 (19.0492 iter/s, 5.24957s/100 iters), loss = 0.0171321
I1005 11:19:57.010835  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171317 (* 1 = 0.0171317 loss)
I1005 11:19:57.010851  9385 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1005 11:20:02.263862  9385 solver.cpp:218] Iteration 65800 (19.0367 iter/s, 5.25301s/100 iters), loss = 0.0209595
I1005 11:20:02.263892  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209591 (* 1 = 0.0209591 loss)
I1005 11:20:02.263898  9385 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1005 11:20:07.504156  9385 solver.cpp:218] Iteration 65900 (19.0831 iter/s, 5.24024s/100 iters), loss = 0.0108658
I1005 11:20:07.504194  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108654 (* 1 = 0.0108654 loss)
I1005 11:20:07.504204  9385 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1005 11:20:12.495498  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:20:12.705576  9385 solver.cpp:330] Iteration 66000, Testing net (#0)
I1005 11:20:13.903447  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:20:13.953341  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8968
I1005 11:20:13.953377  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42389 (* 1 = 0.42389 loss)
I1005 11:20:14.005450  9385 solver.cpp:218] Iteration 66000 (15.3817 iter/s, 6.50124s/100 iters), loss = 0.0182655
I1005 11:20:14.005481  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182651 (* 1 = 0.0182651 loss)
I1005 11:20:14.005487  9385 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1005 11:20:19.243660  9385 solver.cpp:218] Iteration 66100 (19.0907 iter/s, 5.23816s/100 iters), loss = 0.030037
I1005 11:20:19.243690  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300366 (* 1 = 0.0300366 loss)
I1005 11:20:19.243696  9385 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1005 11:20:24.493183  9385 solver.cpp:218] Iteration 66200 (19.0495 iter/s, 5.24947s/100 iters), loss = 0.0100482
I1005 11:20:24.493223  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100478 (* 1 = 0.0100478 loss)
I1005 11:20:24.493229  9385 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1005 11:20:29.737944  9385 solver.cpp:218] Iteration 66300 (19.0669 iter/s, 5.2447s/100 iters), loss = 0.0213704
I1005 11:20:29.737984  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02137 (* 1 = 0.02137 loss)
I1005 11:20:29.737990  9385 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1005 11:20:34.977826  9385 solver.cpp:218] Iteration 66400 (19.0846 iter/s, 5.23982s/100 iters), loss = 0.0302795
I1005 11:20:34.977866  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302791 (* 1 = 0.0302791 loss)
I1005 11:20:34.977872  9385 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1005 11:20:39.959496  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:20:40.169251  9385 solver.cpp:330] Iteration 66500, Testing net (#0)
I1005 11:20:41.363520  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:20:41.413385  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8883
I1005 11:20:41.413410  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47257 (* 1 = 0.47257 loss)
I1005 11:20:41.465380  9385 solver.cpp:218] Iteration 66500 (15.4143 iter/s, 6.48749s/100 iters), loss = 0.0252999
I1005 11:20:41.465411  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252995 (* 1 = 0.0252995 loss)
I1005 11:20:41.465418  9385 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1005 11:20:46.718883  9385 solver.cpp:218] Iteration 66600 (19.0351 iter/s, 5.25345s/100 iters), loss = 0.0581558
I1005 11:20:46.719040  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0581554 (* 1 = 0.0581554 loss)
I1005 11:20:46.719049  9385 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1005 11:20:51.964633  9385 solver.cpp:218] Iteration 66700 (19.0637 iter/s, 5.24558s/100 iters), loss = 0.0268381
I1005 11:20:51.964673  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268377 (* 1 = 0.0268377 loss)
I1005 11:20:51.964679  9385 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1005 11:20:57.213345  9385 solver.cpp:218] Iteration 66800 (19.0525 iter/s, 5.24865s/100 iters), loss = 0.0205095
I1005 11:20:57.213384  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020509 (* 1 = 0.020509 loss)
I1005 11:20:57.213390  9385 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1005 11:21:02.460013  9385 solver.cpp:218] Iteration 66900 (19.0599 iter/s, 5.24661s/100 iters), loss = 0.0284636
I1005 11:21:02.460042  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284632 (* 1 = 0.0284632 loss)
I1005 11:21:02.460048  9385 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1005 11:21:07.443019  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:21:07.659224  9385 solver.cpp:330] Iteration 67000, Testing net (#0)
I1005 11:21:08.849534  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:21:08.899215  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8832
I1005 11:21:08.899240  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.502004 (* 1 = 0.502004 loss)
I1005 11:21:08.951473  9385 solver.cpp:218] Iteration 67000 (15.405 iter/s, 6.49141s/100 iters), loss = 0.0185529
I1005 11:21:08.951498  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185525 (* 1 = 0.0185525 loss)
I1005 11:21:08.951505  9385 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1005 11:21:14.199659  9385 solver.cpp:218] Iteration 67100 (19.0544 iter/s, 5.24814s/100 iters), loss = 0.0334867
I1005 11:21:14.199700  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334863 (* 1 = 0.0334863 loss)
I1005 11:21:14.199707  9385 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1005 11:21:19.441171  9385 solver.cpp:218] Iteration 67200 (19.0787 iter/s, 5.24145s/100 iters), loss = 0.0413219
I1005 11:21:19.441272  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413215 (* 1 = 0.0413215 loss)
I1005 11:21:19.441289  9385 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1005 11:21:24.690600  9385 solver.cpp:218] Iteration 67300 (19.0501 iter/s, 5.24931s/100 iters), loss = 0.0375828
I1005 11:21:24.690639  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375824 (* 1 = 0.0375824 loss)
I1005 11:21:24.690645  9385 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1005 11:21:29.937353  9385 solver.cpp:218] Iteration 67400 (19.0596 iter/s, 5.24669s/100 iters), loss = 0.0559266
I1005 11:21:29.937392  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559262 (* 1 = 0.0559262 loss)
I1005 11:21:29.937399  9385 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1005 11:21:34.932859  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:21:35.142701  9385 solver.cpp:330] Iteration 67500, Testing net (#0)
I1005 11:21:36.330189  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:21:36.380231  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8878
I1005 11:21:36.380266  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.473137 (* 1 = 0.473137 loss)
I1005 11:21:36.432880  9385 solver.cpp:218] Iteration 67500 (15.3953 iter/s, 6.49547s/100 iters), loss = 0.0198556
I1005 11:21:36.432919  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198552 (* 1 = 0.0198552 loss)
I1005 11:21:36.432925  9385 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1005 11:21:41.690014  9385 solver.cpp:218] Iteration 67600 (19.022 iter/s, 5.25708s/100 iters), loss = 0.016106
I1005 11:21:41.690053  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161056 (* 1 = 0.0161056 loss)
I1005 11:21:41.690059  9385 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1005 11:21:46.944281  9385 solver.cpp:218] Iteration 67700 (19.0324 iter/s, 5.2542s/100 iters), loss = 0.0378097
I1005 11:21:46.944321  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0378093 (* 1 = 0.0378093 loss)
I1005 11:21:46.944327  9385 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1005 11:21:52.190158  9385 solver.cpp:218] Iteration 67800 (19.0628 iter/s, 5.24582s/100 iters), loss = 0.0148636
I1005 11:21:52.190318  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148632 (* 1 = 0.0148632 loss)
I1005 11:21:52.190326  9385 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1005 11:21:57.445677  9385 solver.cpp:218] Iteration 67900 (19.0282 iter/s, 5.25534s/100 iters), loss = 0.0327851
I1005 11:21:57.445715  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327848 (* 1 = 0.0327848 loss)
I1005 11:21:57.445721  9385 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1005 11:22:02.435950  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:22:02.644867  9385 solver.cpp:330] Iteration 68000, Testing net (#0)
I1005 11:22:03.834488  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:22:03.884204  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8939
I1005 11:22:03.884240  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.43769 (* 1 = 0.43769 loss)
I1005 11:22:03.936151  9385 solver.cpp:218] Iteration 68000 (15.4073 iter/s, 6.49042s/100 iters), loss = 0.0185403
I1005 11:22:03.936174  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185399 (* 1 = 0.0185399 loss)
I1005 11:22:03.936182  9385 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1005 11:22:09.182305  9385 solver.cpp:218] Iteration 68100 (19.0618 iter/s, 5.24611s/100 iters), loss = 0.0680685
I1005 11:22:09.182337  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0680681 (* 1 = 0.0680681 loss)
I1005 11:22:09.182355  9385 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1005 11:22:14.431313  9385 solver.cpp:218] Iteration 68200 (19.0514 iter/s, 5.24896s/100 iters), loss = 0.00696183
I1005 11:22:14.431345  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00696147 (* 1 = 0.00696147 loss)
I1005 11:22:14.431363  9385 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1005 11:22:19.677676  9385 solver.cpp:218] Iteration 68300 (19.061 iter/s, 5.24631s/100 iters), loss = 0.05047
I1005 11:22:19.677713  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504696 (* 1 = 0.0504696 loss)
I1005 11:22:19.677722  9385 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1005 11:22:24.920110  9385 solver.cpp:218] Iteration 68400 (19.0753 iter/s, 5.24238s/100 iters), loss = 0.0706688
I1005 11:22:24.920228  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0706684 (* 1 = 0.0706684 loss)
I1005 11:22:24.920248  9385 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1005 11:22:29.912430  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:22:30.122948  9385 solver.cpp:330] Iteration 68500, Testing net (#0)
I1005 11:22:31.311096  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:22:31.360849  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8795
I1005 11:22:31.360877  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.495546 (* 1 = 0.495546 loss)
I1005 11:22:31.413003  9385 solver.cpp:218] Iteration 68500 (15.4017 iter/s, 6.49277s/100 iters), loss = 0.0239541
I1005 11:22:31.413033  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239537 (* 1 = 0.0239537 loss)
I1005 11:22:31.413043  9385 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1005 11:22:36.658423  9385 solver.cpp:218] Iteration 68600 (19.0644 iter/s, 5.24537s/100 iters), loss = 0.0145093
I1005 11:22:36.658453  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014509 (* 1 = 0.014509 loss)
I1005 11:22:36.658458  9385 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1005 11:22:41.908934  9385 solver.cpp:218] Iteration 68700 (19.0459 iter/s, 5.25046s/100 iters), loss = 0.00540362
I1005 11:22:41.908964  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054033 (* 1 = 0.0054033 loss)
I1005 11:22:41.908969  9385 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1005 11:22:47.160370  9385 solver.cpp:218] Iteration 68800 (19.0426 iter/s, 5.25139s/100 iters), loss = 0.0294288
I1005 11:22:47.160400  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294285 (* 1 = 0.0294285 loss)
I1005 11:22:47.160406  9385 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1005 11:22:52.398874  9385 solver.cpp:218] Iteration 68900 (19.0896 iter/s, 5.23845s/100 iters), loss = 0.03969
I1005 11:22:52.398903  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396897 (* 1 = 0.0396897 loss)
I1005 11:22:52.398910  9385 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1005 11:22:57.384985  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:22:57.594022  9385 solver.cpp:330] Iteration 69000, Testing net (#0)
I1005 11:22:58.789026  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:22:58.838790  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8914
I1005 11:22:58.838815  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.429874 (* 1 = 0.429874 loss)
I1005 11:22:58.891016  9385 solver.cpp:218] Iteration 69000 (15.4034 iter/s, 6.49209s/100 iters), loss = 0.0163551
I1005 11:22:58.891058  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163548 (* 1 = 0.0163548 loss)
I1005 11:22:58.891077  9385 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1005 11:23:04.128962  9385 solver.cpp:218] Iteration 69100 (19.0917 iter/s, 5.23788s/100 iters), loss = 0.0259716
I1005 11:23:04.129003  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259713 (* 1 = 0.0259713 loss)
I1005 11:23:04.129009  9385 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1005 11:23:09.373816  9385 solver.cpp:218] Iteration 69200 (19.0665 iter/s, 5.2448s/100 iters), loss = 0.00663328
I1005 11:23:09.373857  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663297 (* 1 = 0.00663297 loss)
I1005 11:23:09.373862  9385 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1005 11:23:14.626979  9385 solver.cpp:218] Iteration 69300 (19.0364 iter/s, 5.2531s/100 iters), loss = 0.0134316
I1005 11:23:14.627009  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134313 (* 1 = 0.0134313 loss)
I1005 11:23:14.627015  9385 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1005 11:23:19.869684  9385 solver.cpp:218] Iteration 69400 (19.0743 iter/s, 5.24266s/100 iters), loss = 0.0429288
I1005 11:23:19.869717  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429285 (* 1 = 0.0429285 loss)
I1005 11:23:19.869724  9385 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1005 11:23:24.852447  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:23:25.061914  9385 solver.cpp:330] Iteration 69500, Testing net (#0)
I1005 11:23:26.261993  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:23:26.312057  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8982
I1005 11:23:26.312093  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413149 (* 1 = 0.413149 loss)
I1005 11:23:26.364367  9385 solver.cpp:218] Iteration 69500 (15.3973 iter/s, 6.49463s/100 iters), loss = 0.0094629
I1005 11:23:26.364403  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00946259 (* 1 = 0.00946259 loss)
I1005 11:23:26.364408  9385 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1005 11:23:31.610069  9385 solver.cpp:218] Iteration 69600 (19.0634 iter/s, 5.24564s/100 iters), loss = 0.0174778
I1005 11:23:31.610199  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174775 (* 1 = 0.0174775 loss)
I1005 11:23:31.610219  9385 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1005 11:23:36.859210  9385 solver.cpp:218] Iteration 69700 (19.0513 iter/s, 5.249s/100 iters), loss = 0.00761145
I1005 11:23:36.859249  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00761115 (* 1 = 0.00761115 loss)
I1005 11:23:36.859256  9385 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1005 11:23:42.107481  9385 solver.cpp:218] Iteration 69800 (19.0541 iter/s, 5.24821s/100 iters), loss = 0.0412897
I1005 11:23:42.107519  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412894 (* 1 = 0.0412894 loss)
I1005 11:23:42.107525  9385 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1005 11:23:47.353408  9385 solver.cpp:218] Iteration 69900 (19.0626 iter/s, 5.24587s/100 iters), loss = 0.0182529
I1005 11:23:47.353448  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182526 (* 1 = 0.0182526 loss)
I1005 11:23:47.353454  9385 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1005 11:23:52.333003  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:23:52.544610  9385 solver.cpp:330] Iteration 70000, Testing net (#0)
I1005 11:23:53.738267  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:23:53.788313  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8913
I1005 11:23:53.788348  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.454646 (* 1 = 0.454646 loss)
I1005 11:23:53.840744  9385 solver.cpp:218] Iteration 70000 (15.4148 iter/s, 6.48728s/100 iters), loss = 0.0953011
I1005 11:23:53.840767  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0953009 (* 1 = 0.0953009 loss)
I1005 11:23:53.840773  9385 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1005 11:23:59.096527  9385 solver.cpp:218] Iteration 70100 (19.0268 iter/s, 5.25573s/100 iters), loss = 0.0116088
I1005 11:23:59.096566  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116086 (* 1 = 0.0116086 loss)
I1005 11:23:59.096572  9385 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1005 11:24:04.343328  9385 solver.cpp:218] Iteration 70200 (19.0595 iter/s, 5.24674s/100 iters), loss = 0.0189636
I1005 11:24:04.343479  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189633 (* 1 = 0.0189633 loss)
I1005 11:24:04.343487  9385 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1005 11:24:09.600684  9385 solver.cpp:218] Iteration 70300 (19.0216 iter/s, 5.25719s/100 iters), loss = 0.0981838
I1005 11:24:09.600723  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0981835 (* 1 = 0.0981835 loss)
I1005 11:24:09.600729  9385 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1005 11:24:14.854091  9385 solver.cpp:218] Iteration 70400 (19.0355 iter/s, 5.25335s/100 iters), loss = 0.0377984
I1005 11:24:14.854121  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377981 (* 1 = 0.0377981 loss)
I1005 11:24:14.854127  9385 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1005 11:24:19.853744  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:24:20.063019  9385 solver.cpp:330] Iteration 70500, Testing net (#0)
I1005 11:24:21.250298  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:24:21.300000  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8824
I1005 11:24:21.300034  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.501678 (* 1 = 0.501678 loss)
I1005 11:24:21.351974  9385 solver.cpp:218] Iteration 70500 (15.3897 iter/s, 6.49784s/100 iters), loss = 0.0203854
I1005 11:24:21.352010  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203851 (* 1 = 0.0203851 loss)
I1005 11:24:21.352015  9385 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1005 11:24:26.598165  9385 solver.cpp:218] Iteration 70600 (19.0617 iter/s, 5.24614s/100 iters), loss = 0.055552
I1005 11:24:26.598206  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0555517 (* 1 = 0.0555517 loss)
I1005 11:24:26.598212  9385 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1005 11:24:31.845407  9385 solver.cpp:218] Iteration 70700 (19.0579 iter/s, 5.24718s/100 iters), loss = 0.050829
I1005 11:24:31.845446  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508287 (* 1 = 0.0508287 loss)
I1005 11:24:31.845453  9385 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1005 11:24:37.086657  9385 solver.cpp:218] Iteration 70800 (19.0796 iter/s, 5.24119s/100 iters), loss = 0.0160411
I1005 11:24:37.086772  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160408 (* 1 = 0.0160408 loss)
I1005 11:24:37.086779  9385 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1005 11:24:42.332762  9385 solver.cpp:218] Iteration 70900 (19.0622 iter/s, 5.24598s/100 iters), loss = 0.0265367
I1005 11:24:42.332799  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265364 (* 1 = 0.0265364 loss)
I1005 11:24:42.332805  9385 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1005 11:24:47.325145  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:24:47.535301  9385 solver.cpp:330] Iteration 71000, Testing net (#0)
I1005 11:24:48.722810  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:24:48.772687  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8745
I1005 11:24:48.772722  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.534852 (* 1 = 0.534852 loss)
I1005 11:24:48.824847  9385 solver.cpp:218] Iteration 71000 (15.4035 iter/s, 6.49203s/100 iters), loss = 0.0132723
I1005 11:24:48.824874  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013272 (* 1 = 0.013272 loss)
I1005 11:24:48.824882  9385 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1005 11:24:54.076714  9385 solver.cpp:218] Iteration 71100 (19.041 iter/s, 5.25182s/100 iters), loss = 0.0109101
I1005 11:24:54.076753  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109098 (* 1 = 0.0109098 loss)
I1005 11:24:54.076759  9385 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1005 11:24:59.329124  9385 solver.cpp:218] Iteration 71200 (19.0391 iter/s, 5.25235s/100 iters), loss = 0.0157008
I1005 11:24:59.329166  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157005 (* 1 = 0.0157005 loss)
I1005 11:24:59.329172  9385 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1005 11:25:04.576478  9385 solver.cpp:218] Iteration 71300 (19.0575 iter/s, 5.24729s/100 iters), loss = 0.0644545
I1005 11:25:04.576526  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644542 (* 1 = 0.0644542 loss)
I1005 11:25:04.576534  9385 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1005 11:25:09.824543  9385 solver.cpp:218] Iteration 71400 (19.055 iter/s, 5.24797s/100 iters), loss = 0.00545539
I1005 11:25:09.824647  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545509 (* 1 = 0.00545509 loss)
I1005 11:25:09.824654  9385 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1005 11:25:14.811343  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:25:15.020809  9385 solver.cpp:330] Iteration 71500, Testing net (#0)
I1005 11:25:16.209161  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:25:16.258857  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888
I1005 11:25:16.258893  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.46898 (* 1 = 0.46898 loss)
I1005 11:25:16.311249  9385 solver.cpp:218] Iteration 71500 (15.4164 iter/s, 6.48658s/100 iters), loss = 0.00571605
I1005 11:25:16.311290  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571574 (* 1 = 0.00571574 loss)
I1005 11:25:16.311296  9385 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1005 11:25:21.556601  9385 solver.cpp:218] Iteration 71600 (19.0647 iter/s, 5.24529s/100 iters), loss = 0.0177906
I1005 11:25:21.556629  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177903 (* 1 = 0.0177903 loss)
I1005 11:25:21.556634  9385 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1005 11:25:26.805594  9385 solver.cpp:218] Iteration 71700 (19.0514 iter/s, 5.24895s/100 iters), loss = 0.0168096
I1005 11:25:26.805624  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168093 (* 1 = 0.0168093 loss)
I1005 11:25:26.805629  9385 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1005 11:25:32.056368  9385 solver.cpp:218] Iteration 71800 (19.045 iter/s, 5.25073s/100 iters), loss = 0.00824371
I1005 11:25:32.056401  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00824341 (* 1 = 0.00824341 loss)
I1005 11:25:32.056406  9385 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1005 11:25:37.297260  9385 solver.cpp:218] Iteration 71900 (19.0809 iter/s, 5.24084s/100 iters), loss = 0.0236654
I1005 11:25:37.297291  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236651 (* 1 = 0.0236651 loss)
I1005 11:25:37.297297  9385 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1005 11:25:42.294802  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:25:42.504122  9385 solver.cpp:330] Iteration 72000, Testing net (#0)
I1005 11:25:43.699540  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:25:43.750108  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894
I1005 11:25:43.750133  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.437153 (* 1 = 0.437153 loss)
I1005 11:25:43.803216  9385 solver.cpp:218] Iteration 72000 (15.3707 iter/s, 6.5059s/100 iters), loss = 0.00746799
I1005 11:25:43.803251  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00746769 (* 1 = 0.00746769 loss)
I1005 11:25:43.803258  9385 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1005 11:25:49.045585  9385 solver.cpp:218] Iteration 72100 (19.0755 iter/s, 5.24232s/100 iters), loss = 0.0120998
I1005 11:25:49.045624  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120995 (* 1 = 0.0120995 loss)
I1005 11:25:49.045630  9385 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1005 11:25:54.296252  9385 solver.cpp:218] Iteration 72200 (19.0454 iter/s, 5.25061s/100 iters), loss = 0.0177611
I1005 11:25:54.296293  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177608 (* 1 = 0.0177608 loss)
I1005 11:25:54.296298  9385 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1005 11:25:59.549885  9385 solver.cpp:218] Iteration 72300 (19.0347 iter/s, 5.25357s/100 iters), loss = 0.0222318
I1005 11:25:59.549926  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222315 (* 1 = 0.0222315 loss)
I1005 11:25:59.549932  9385 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1005 11:26:04.800360  9385 solver.cpp:218] Iteration 72400 (19.0461 iter/s, 5.25041s/100 iters), loss = 0.0190683
I1005 11:26:04.800406  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019068 (* 1 = 0.019068 loss)
I1005 11:26:04.800413  9385 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1005 11:26:09.785442  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:26:09.994992  9385 solver.cpp:330] Iteration 72500, Testing net (#0)
I1005 11:26:11.192674  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:26:11.242723  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8909
I1005 11:26:11.242749  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.452637 (* 1 = 0.452637 loss)
I1005 11:26:11.295058  9385 solver.cpp:218] Iteration 72500 (15.3974 iter/s, 6.4946s/100 iters), loss = 0.0121684
I1005 11:26:11.295089  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121681 (* 1 = 0.0121681 loss)
I1005 11:26:11.295095  9385 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1005 11:26:16.535079  9385 solver.cpp:218] Iteration 72600 (19.0841 iter/s, 5.23997s/100 iters), loss = 0.0121955
I1005 11:26:16.535195  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121952 (* 1 = 0.0121952 loss)
I1005 11:26:16.535207  9385 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1005 11:26:21.786619  9385 solver.cpp:218] Iteration 72700 (19.0426 iter/s, 5.25138s/100 iters), loss = 0.005973
I1005 11:26:21.786659  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597269 (* 1 = 0.00597269 loss)
I1005 11:26:21.786665  9385 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1005 11:26:27.036965  9385 solver.cpp:218] Iteration 72800 (19.0466 iter/s, 5.25029s/100 iters), loss = 0.0335942
I1005 11:26:27.037005  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335939 (* 1 = 0.0335939 loss)
I1005 11:26:27.037011  9385 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1005 11:26:32.284173  9385 solver.cpp:218] Iteration 72900 (19.058 iter/s, 5.24715s/100 iters), loss = 0.0148066
I1005 11:26:32.284205  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148063 (* 1 = 0.0148063 loss)
I1005 11:26:32.284214  9385 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1005 11:26:37.268098  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:26:37.477905  9385 solver.cpp:330] Iteration 73000, Testing net (#0)
I1005 11:26:38.678206  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:26:38.728384  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8951
I1005 11:26:38.728410  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.450983 (* 1 = 0.450983 loss)
I1005 11:26:38.780417  9385 solver.cpp:218] Iteration 73000 (15.3936 iter/s, 6.49619s/100 iters), loss = 0.0139166
I1005 11:26:38.780443  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139163 (* 1 = 0.0139163 loss)
I1005 11:26:38.780452  9385 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1005 11:26:44.034237  9385 solver.cpp:218] Iteration 73100 (19.0339 iter/s, 5.25378s/100 iters), loss = 0.0305084
I1005 11:26:44.034271  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305081 (* 1 = 0.0305081 loss)
I1005 11:26:44.034289  9385 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1005 11:26:49.275502  9385 solver.cpp:218] Iteration 73200 (19.0795 iter/s, 5.24121s/100 iters), loss = 0.0508547
I1005 11:26:49.275630  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508544 (* 1 = 0.0508544 loss)
I1005 11:26:49.275650  9385 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1005 11:26:54.521877  9385 solver.cpp:218] Iteration 73300 (19.0613 iter/s, 5.24623s/100 iters), loss = 0.0128399
I1005 11:26:54.521908  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128396 (* 1 = 0.0128396 loss)
I1005 11:26:54.521916  9385 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1005 11:26:59.768102  9385 solver.cpp:218] Iteration 73400 (19.0615 iter/s, 5.24618s/100 iters), loss = 0.0200168
I1005 11:26:59.768134  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200165 (* 1 = 0.0200165 loss)
I1005 11:26:59.768142  9385 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1005 11:27:04.758796  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:27:04.969519  9385 solver.cpp:330] Iteration 73500, Testing net (#0)
I1005 11:27:06.156348  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:27:06.206286  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8773
I1005 11:27:06.206312  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.533093 (* 1 = 0.533093 loss)
I1005 11:27:06.258632  9385 solver.cpp:218] Iteration 73500 (15.4072 iter/s, 6.49048s/100 iters), loss = 0.0293072
I1005 11:27:06.258661  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293069 (* 1 = 0.0293069 loss)
I1005 11:27:06.258671  9385 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1005 11:27:11.511454  9385 solver.cpp:218] Iteration 73600 (19.0376 iter/s, 5.25278s/100 iters), loss = 0.0228835
I1005 11:27:11.511487  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228832 (* 1 = 0.0228832 loss)
I1005 11:27:11.511505  9385 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1005 11:27:16.764847  9385 solver.cpp:218] Iteration 73700 (19.0355 iter/s, 5.25334s/100 iters), loss = 0.0146332
I1005 11:27:16.764883  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146329 (* 1 = 0.0146329 loss)
I1005 11:27:16.764889  9385 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1005 11:27:22.006104  9385 solver.cpp:218] Iteration 73800 (19.0796 iter/s, 5.24121s/100 iters), loss = 0.0372472
I1005 11:27:22.006235  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372468 (* 1 = 0.0372468 loss)
I1005 11:27:22.006242  9385 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1005 11:27:27.253799  9385 solver.cpp:218] Iteration 73900 (19.0565 iter/s, 5.24755s/100 iters), loss = 0.0322442
I1005 11:27:27.253839  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322439 (* 1 = 0.0322439 loss)
I1005 11:27:27.253844  9385 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1005 11:27:32.243391  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:27:32.452955  9385 solver.cpp:330] Iteration 74000, Testing net (#0)
I1005 11:27:33.640969  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:27:33.690623  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8965
I1005 11:27:33.690646  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412488 (* 1 = 0.412488 loss)
I1005 11:27:33.743021  9385 solver.cpp:218] Iteration 74000 (15.4103 iter/s, 6.48917s/100 iters), loss = 0.00569312
I1005 11:27:33.743046  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569279 (* 1 = 0.00569279 loss)
I1005 11:27:33.743052  9385 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1005 11:27:38.987977  9385 solver.cpp:218] Iteration 74100 (19.0661 iter/s, 5.24491s/100 iters), loss = 0.0445042
I1005 11:27:38.988016  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445038 (* 1 = 0.0445038 loss)
I1005 11:27:38.988023  9385 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1005 11:27:44.237051  9385 solver.cpp:218] Iteration 74200 (19.0512 iter/s, 5.24902s/100 iters), loss = 0.0204952
I1005 11:27:44.237081  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204949 (* 1 = 0.0204949 loss)
I1005 11:27:44.237087  9385 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1005 11:27:49.479776  9385 solver.cpp:218] Iteration 74300 (19.0742 iter/s, 5.24268s/100 iters), loss = 0.0264565
I1005 11:27:49.479807  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264561 (* 1 = 0.0264561 loss)
I1005 11:27:49.479823  9385 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1005 11:27:54.723968  9385 solver.cpp:218] Iteration 74400 (19.0689 iter/s, 5.24414s/100 iters), loss = 0.00706077
I1005 11:27:54.724089  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706042 (* 1 = 0.00706042 loss)
I1005 11:27:54.724107  9385 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1005 11:27:59.719127  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:27:59.929145  9385 solver.cpp:330] Iteration 74500, Testing net (#0)
I1005 11:28:01.116827  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:28:01.166462  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8918
I1005 11:28:01.166498  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.470947 (* 1 = 0.470947 loss)
I1005 11:28:01.218724  9385 solver.cpp:218] Iteration 74500 (15.3974 iter/s, 6.49462s/100 iters), loss = 0.0129835
I1005 11:28:01.218752  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129831 (* 1 = 0.0129831 loss)
I1005 11:28:01.218760  9385 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1005 11:28:06.468369  9385 solver.cpp:218] Iteration 74600 (19.0491 iter/s, 5.2496s/100 iters), loss = 0.029822
I1005 11:28:06.468399  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298216 (* 1 = 0.0298216 loss)
I1005 11:28:06.468405  9385 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1005 11:28:11.721674  9385 solver.cpp:218] Iteration 74700 (19.0358 iter/s, 5.25326s/100 iters), loss = 0.0384178
I1005 11:28:11.721705  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384175 (* 1 = 0.0384175 loss)
I1005 11:28:11.721710  9385 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1005 11:28:16.972558  9385 solver.cpp:218] Iteration 74800 (19.0446 iter/s, 5.25083s/100 iters), loss = 0.0368989
I1005 11:28:16.972589  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368986 (* 1 = 0.0368986 loss)
I1005 11:28:16.972596  9385 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1005 11:28:22.212105  9385 solver.cpp:218] Iteration 74900 (19.0858 iter/s, 5.2395s/100 iters), loss = 0.0138882
I1005 11:28:22.212136  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138879 (* 1 = 0.0138879 loss)
I1005 11:28:22.212141  9385 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1005 11:28:27.200727  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:28:27.410429  9385 solver.cpp:330] Iteration 75000, Testing net (#0)
I1005 11:28:28.599835  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:28:28.650601  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8752
I1005 11:28:28.650640  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.523229 (* 1 = 0.523229 loss)
I1005 11:28:28.703747  9385 solver.cpp:218] Iteration 75000 (15.4046 iter/s, 6.49159s/100 iters), loss = 0.0276062
I1005 11:28:28.703793  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276059 (* 1 = 0.0276059 loss)
I1005 11:28:28.703799  9385 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1005 11:28:33.949091  9385 solver.cpp:218] Iteration 75100 (19.0649 iter/s, 5.24525s/100 iters), loss = 0.0223105
I1005 11:28:33.949121  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223101 (* 1 = 0.0223101 loss)
I1005 11:28:33.949137  9385 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1005 11:28:39.196657  9385 solver.cpp:218] Iteration 75200 (19.0566 iter/s, 5.24752s/100 iters), loss = 0.00777289
I1005 11:28:39.196686  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00777252 (* 1 = 0.00777252 loss)
I1005 11:28:39.196692  9385 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1005 11:28:44.447649  9385 solver.cpp:218] Iteration 75300 (19.0442 iter/s, 5.25094s/100 iters), loss = 0.012151
I1005 11:28:44.447684  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121507 (* 1 = 0.0121507 loss)
I1005 11:28:44.447690  9385 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1005 11:28:49.692621  9385 solver.cpp:218] Iteration 75400 (19.0661 iter/s, 5.24492s/100 iters), loss = 0.00760483
I1005 11:28:49.692659  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760444 (* 1 = 0.00760444 loss)
I1005 11:28:49.692667  9385 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1005 11:28:54.681627  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:28:54.891144  9385 solver.cpp:330] Iteration 75500, Testing net (#0)
I1005 11:28:56.088255  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:28:56.138123  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I1005 11:28:56.138156  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40152 (* 1 = 0.40152 loss)
I1005 11:28:56.190485  9385 solver.cpp:218] Iteration 75500 (15.3898 iter/s, 6.49781s/100 iters), loss = 0.0121974
I1005 11:28:56.190515  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012197 (* 1 = 0.012197 loss)
I1005 11:28:56.190523  9385 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1005 11:29:01.432997  9385 solver.cpp:218] Iteration 75600 (19.075 iter/s, 5.24246s/100 iters), loss = 0.0229419
I1005 11:29:01.433171  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229415 (* 1 = 0.0229415 loss)
I1005 11:29:01.433181  9385 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1005 11:29:06.684021  9385 solver.cpp:218] Iteration 75700 (19.0445 iter/s, 5.25085s/100 iters), loss = 0.018877
I1005 11:29:06.684051  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188766 (* 1 = 0.0188766 loss)
I1005 11:29:06.684067  9385 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1005 11:29:11.933043  9385 solver.cpp:218] Iteration 75800 (19.0514 iter/s, 5.24897s/100 iters), loss = 0.0174034
I1005 11:29:11.933082  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017403 (* 1 = 0.017403 loss)
I1005 11:29:11.933089  9385 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1005 11:29:17.175065  9385 solver.cpp:218] Iteration 75900 (19.0768 iter/s, 5.24196s/100 iters), loss = 0.0237399
I1005 11:29:17.175104  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237395 (* 1 = 0.0237395 loss)
I1005 11:29:17.175110  9385 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1005 11:29:22.153787  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:29:22.363755  9385 solver.cpp:330] Iteration 76000, Testing net (#0)
I1005 11:29:23.559353  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:29:23.609025  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.899
I1005 11:29:23.609051  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.428944 (* 1 = 0.428944 loss)
I1005 11:29:23.661526  9385 solver.cpp:218] Iteration 76000 (15.4169 iter/s, 6.48641s/100 iters), loss = 0.00401607
I1005 11:29:23.661561  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401565 (* 1 = 0.00401565 loss)
I1005 11:29:23.661567  9385 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1005 11:29:28.907474  9385 solver.cpp:218] Iteration 76100 (19.0625 iter/s, 5.24589s/100 iters), loss = 0.00771097
I1005 11:29:28.907516  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771055 (* 1 = 0.00771055 loss)
I1005 11:29:28.907523  9385 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1005 11:29:34.145730  9385 solver.cpp:218] Iteration 76200 (19.0905 iter/s, 5.2382s/100 iters), loss = 0.0100384
I1005 11:29:34.145884  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100379 (* 1 = 0.0100379 loss)
I1005 11:29:34.145894  9385 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1005 11:29:39.397315  9385 solver.cpp:218] Iteration 76300 (19.0425 iter/s, 5.25142s/100 iters), loss = 0.00653546
I1005 11:29:39.397356  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653504 (* 1 = 0.00653504 loss)
I1005 11:29:39.397361  9385 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1005 11:29:44.651480  9385 solver.cpp:218] Iteration 76400 (19.0327 iter/s, 5.25411s/100 iters), loss = 0.0126383
I1005 11:29:44.651510  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126379 (* 1 = 0.0126379 loss)
I1005 11:29:44.651515  9385 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1005 11:29:49.633587  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:29:49.848434  9385 solver.cpp:330] Iteration 76500, Testing net (#0)
I1005 11:29:51.036640  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:29:51.086412  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8848
I1005 11:29:51.086447  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.499969 (* 1 = 0.499969 loss)
I1005 11:29:51.139098  9385 solver.cpp:218] Iteration 76500 (15.4141 iter/s, 6.48757s/100 iters), loss = 0.0193741
I1005 11:29:51.139124  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193737 (* 1 = 0.0193737 loss)
I1005 11:29:51.139140  9385 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1005 11:29:56.392513  9385 solver.cpp:218] Iteration 76600 (19.0354 iter/s, 5.25337s/100 iters), loss = 0.0273752
I1005 11:29:56.392540  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273748 (* 1 = 0.0273748 loss)
I1005 11:29:56.392546  9385 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1005 11:30:01.632436  9385 solver.cpp:218] Iteration 76700 (19.0844 iter/s, 5.23988s/100 iters), loss = 0.00689255
I1005 11:30:01.632472  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00689215 (* 1 = 0.00689215 loss)
I1005 11:30:01.632479  9385 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1005 11:30:06.877892  9385 solver.cpp:218] Iteration 76800 (19.0643 iter/s, 5.2454s/100 iters), loss = 0.0460567
I1005 11:30:06.878023  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460562 (* 1 = 0.0460562 loss)
I1005 11:30:06.878041  9385 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1005 11:30:12.122051  9385 solver.cpp:218] Iteration 76900 (19.0693 iter/s, 5.24402s/100 iters), loss = 0.0439968
I1005 11:30:12.122090  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439964 (* 1 = 0.0439964 loss)
I1005 11:30:12.122097  9385 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1005 11:30:17.111459  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:30:17.320364  9385 solver.cpp:330] Iteration 77000, Testing net (#0)
I1005 11:30:18.509588  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:30:18.559517  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I1005 11:30:18.559541  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.450185 (* 1 = 0.450185 loss)
I1005 11:30:18.612205  9385 solver.cpp:218] Iteration 77000 (15.4081 iter/s, 6.49009s/100 iters), loss = 0.010922
I1005 11:30:18.612234  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109216 (* 1 = 0.0109216 loss)
I1005 11:30:18.612241  9385 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1005 11:30:23.857374  9385 solver.cpp:218] Iteration 77100 (19.0653 iter/s, 5.24512s/100 iters), loss = 0.0124094
I1005 11:30:23.857403  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012409 (* 1 = 0.012409 loss)
I1005 11:30:23.857409  9385 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1005 11:30:29.109534  9385 solver.cpp:218] Iteration 77200 (19.04 iter/s, 5.25211s/100 iters), loss = 0.0474012
I1005 11:30:29.109563  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474008 (* 1 = 0.0474008 loss)
I1005 11:30:29.109570  9385 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1005 11:30:34.350304  9385 solver.cpp:218] Iteration 77300 (19.0814 iter/s, 5.24072s/100 iters), loss = 0.0187387
I1005 11:30:34.350335  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187383 (* 1 = 0.0187383 loss)
I1005 11:30:34.350352  9385 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1005 11:30:39.600184  9385 solver.cpp:218] Iteration 77400 (19.0482 iter/s, 5.24983s/100 iters), loss = 0.00320065
I1005 11:30:39.600286  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320024 (* 1 = 0.00320024 loss)
I1005 11:30:39.600303  9385 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1005 11:30:44.593400  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:30:44.803364  9385 solver.cpp:330] Iteration 77500, Testing net (#0)
I1005 11:30:45.990406  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:30:46.039964  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8935
I1005 11:30:46.039988  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.449807 (* 1 = 0.449807 loss)
I1005 11:30:46.092489  9385 solver.cpp:218] Iteration 77500 (15.4031 iter/s, 6.49218s/100 iters), loss = 0.0224845
I1005 11:30:46.092514  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022484 (* 1 = 0.022484 loss)
I1005 11:30:46.092519  9385 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1005 11:30:51.340348  9385 solver.cpp:218] Iteration 77600 (19.0555 iter/s, 5.24782s/100 iters), loss = 0.020357
I1005 11:30:51.340378  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203566 (* 1 = 0.0203566 loss)
I1005 11:30:51.340384  9385 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1005 11:30:56.584738  9385 solver.cpp:218] Iteration 77700 (19.0682 iter/s, 5.24434s/100 iters), loss = 0.0275665
I1005 11:30:56.584767  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275661 (* 1 = 0.0275661 loss)
I1005 11:30:56.584774  9385 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1005 11:31:01.833034  9385 solver.cpp:218] Iteration 77800 (19.054 iter/s, 5.24824s/100 iters), loss = 0.0287102
I1005 11:31:01.833081  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287098 (* 1 = 0.0287098 loss)
I1005 11:31:01.833088  9385 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1005 11:31:07.064920  9385 solver.cpp:218] Iteration 77900 (19.1138 iter/s, 5.23182s/100 iters), loss = 0.00306358
I1005 11:31:07.064949  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306316 (* 1 = 0.00306316 loss)
I1005 11:31:07.064955  9385 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1005 11:31:12.056049  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:31:12.265871  9385 solver.cpp:330] Iteration 78000, Testing net (#0)
I1005 11:31:13.456393  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:31:13.506508  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8884
I1005 11:31:13.506536  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.49147 (* 1 = 0.49147 loss)
I1005 11:31:13.558887  9385 solver.cpp:218] Iteration 78000 (15.399 iter/s, 6.49392s/100 iters), loss = 0.0247047
I1005 11:31:13.558928  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247042 (* 1 = 0.0247042 loss)
I1005 11:31:13.558936  9385 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1005 11:31:18.808312  9385 solver.cpp:218] Iteration 78100 (19.0499 iter/s, 5.24937s/100 iters), loss = 0.0266246
I1005 11:31:18.808351  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266242 (* 1 = 0.0266242 loss)
I1005 11:31:18.808357  9385 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1005 11:31:24.056059  9385 solver.cpp:218] Iteration 78200 (19.056 iter/s, 5.24769s/100 iters), loss = 0.00428319
I1005 11:31:24.056088  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428281 (* 1 = 0.00428281 loss)
I1005 11:31:24.056094  9385 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1005 11:31:29.312929  9385 solver.cpp:218] Iteration 78300 (19.0229 iter/s, 5.25682s/100 iters), loss = 0.022444
I1005 11:31:29.312961  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224436 (* 1 = 0.0224436 loss)
I1005 11:31:29.312968  9385 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1005 11:31:34.555116  9385 solver.cpp:218] Iteration 78400 (19.0762 iter/s, 5.24213s/100 iters), loss = 0.0200227
I1005 11:31:34.555152  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200223 (* 1 = 0.0200223 loss)
I1005 11:31:34.555161  9385 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1005 11:31:39.544705  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:31:39.753787  9385 solver.cpp:330] Iteration 78500, Testing net (#0)
I1005 11:31:40.946918  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:31:40.996953  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I1005 11:31:40.996980  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444277 (* 1 = 0.444277 loss)
I1005 11:31:41.049247  9385 solver.cpp:218] Iteration 78500 (15.3986 iter/s, 6.49408s/100 iters), loss = 0.0151979
I1005 11:31:41.049283  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151975 (* 1 = 0.0151975 loss)
I1005 11:31:41.049293  9385 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1005 11:31:46.287780  9385 solver.cpp:218] Iteration 78600 (19.0895 iter/s, 5.23848s/100 iters), loss = 0.050427
I1005 11:31:46.287963  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504266 (* 1 = 0.0504266 loss)
I1005 11:31:46.287983  9385 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1005 11:31:51.533012  9385 solver.cpp:218] Iteration 78700 (19.0655 iter/s, 5.24507s/100 iters), loss = 0.0156933
I1005 11:31:51.533041  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156929 (* 1 = 0.0156929 loss)
I1005 11:31:51.533046  9385 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1005 11:31:56.783246  9385 solver.cpp:218] Iteration 78800 (19.0469 iter/s, 5.25019s/100 iters), loss = 0.0106866
I1005 11:31:56.783275  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106862 (* 1 = 0.0106862 loss)
I1005 11:31:56.783282  9385 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1005 11:32:02.033212  9385 solver.cpp:218] Iteration 78900 (19.0479 iter/s, 5.24992s/100 iters), loss = 0.0275275
I1005 11:32:02.033241  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275271 (* 1 = 0.0275271 loss)
I1005 11:32:02.033247  9385 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1005 11:32:07.012437  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:32:07.221715  9385 solver.cpp:330] Iteration 79000, Testing net (#0)
I1005 11:32:08.419301  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:32:08.469367  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1005 11:32:08.469393  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426809 (* 1 = 0.426809 loss)
I1005 11:32:08.521839  9385 solver.cpp:218] Iteration 79000 (15.4117 iter/s, 6.48858s/100 iters), loss = 0.0097578
I1005 11:32:08.521867  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00975741 (* 1 = 0.00975741 loss)
I1005 11:32:08.521872  9385 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1005 11:32:13.771541  9385 solver.cpp:218] Iteration 79100 (19.0489 iter/s, 5.24965s/100 iters), loss = 0.012348
I1005 11:32:13.771576  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123476 (* 1 = 0.0123476 loss)
I1005 11:32:13.771584  9385 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1005 11:32:19.017498  9385 solver.cpp:218] Iteration 79200 (19.0625 iter/s, 5.2459s/100 iters), loss = 0.00841658
I1005 11:32:19.017606  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00841618 (* 1 = 0.00841618 loss)
I1005 11:32:19.017612  9385 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1005 11:32:24.273041  9385 solver.cpp:218] Iteration 79300 (19.028 iter/s, 5.25542s/100 iters), loss = 0.0665085
I1005 11:32:24.273080  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665081 (* 1 = 0.0665081 loss)
I1005 11:32:24.273087  9385 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1005 11:32:29.516774  9385 solver.cpp:218] Iteration 79400 (19.0706 iter/s, 5.24368s/100 iters), loss = 0.0180029
I1005 11:32:29.516808  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180025 (* 1 = 0.0180025 loss)
I1005 11:32:29.516815  9385 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1005 11:32:34.497717  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:32:34.710660  9385 solver.cpp:330] Iteration 79500, Testing net (#0)
I1005 11:32:35.902284  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:32:35.952033  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8922
I1005 11:32:35.952059  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.446549 (* 1 = 0.446549 loss)
I1005 11:32:36.004745  9385 solver.cpp:218] Iteration 79500 (15.4133 iter/s, 6.48792s/100 iters), loss = 0.00682182
I1005 11:32:36.004770  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068214 (* 1 = 0.0068214 loss)
I1005 11:32:36.004776  9385 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1005 11:32:41.251893  9385 solver.cpp:218] Iteration 79600 (19.0581 iter/s, 5.2471s/100 iters), loss = 0.00365064
I1005 11:32:41.251932  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365022 (* 1 = 0.00365022 loss)
I1005 11:32:41.251938  9385 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1005 11:32:46.495585  9385 solver.cpp:218] Iteration 79700 (19.0707 iter/s, 5.24363s/100 iters), loss = 0.0129487
I1005 11:32:46.495615  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129483 (* 1 = 0.0129483 loss)
I1005 11:32:46.495631  9385 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1005 11:32:51.747709  9385 solver.cpp:218] Iteration 79800 (19.0401 iter/s, 5.25208s/100 iters), loss = 0.0140567
I1005 11:32:51.747874  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140563 (* 1 = 0.0140563 loss)
I1005 11:32:51.747882  9385 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1005 11:32:56.997385  9385 solver.cpp:218] Iteration 79900 (19.0494 iter/s, 5.2495s/100 iters), loss = 0.00785898
I1005 11:32:56.997416  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785856 (* 1 = 0.00785856 loss)
I1005 11:32:56.997426  9385 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1005 11:33:01.992022  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:33:02.201707  9385 solver.cpp:330] Iteration 80000, Testing net (#0)
I1005 11:33:03.390853  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:33:03.440759  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8905
I1005 11:33:03.440786  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.45353 (* 1 = 0.45353 loss)
I1005 11:33:03.493183  9385 solver.cpp:218] Iteration 80000 (15.3947 iter/s, 6.49575s/100 iters), loss = 0.00506692
I1005 11:33:03.493211  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00506652 (* 1 = 0.00506652 loss)
I1005 11:33:03.493221  9385 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1005 11:33:03.493238  9385 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1005 11:33:08.740607  9385 solver.cpp:218] Iteration 80100 (19.0571 iter/s, 5.24738s/100 iters), loss = 0.0250528
I1005 11:33:08.740641  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250524 (* 1 = 0.0250524 loss)
I1005 11:33:08.740648  9385 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1005 11:33:13.984761  9385 solver.cpp:218] Iteration 80200 (19.069 iter/s, 5.24411s/100 iters), loss = 0.0291854
I1005 11:33:13.984796  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029185 (* 1 = 0.029185 loss)
I1005 11:33:13.984802  9385 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1005 11:33:19.219804  9385 solver.cpp:218] Iteration 80300 (19.1022 iter/s, 5.23499s/100 iters), loss = 0.0160626
I1005 11:33:19.219844  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160622 (* 1 = 0.0160622 loss)
I1005 11:33:19.219851  9385 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1005 11:33:24.461357  9385 solver.cpp:218] Iteration 80400 (19.0785 iter/s, 5.2415s/100 iters), loss = 0.0190846
I1005 11:33:24.461465  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190842 (* 1 = 0.0190842 loss)
I1005 11:33:24.461473  9385 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1005 11:33:29.445752  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:33:29.655685  9385 solver.cpp:330] Iteration 80500, Testing net (#0)
I1005 11:33:30.843425  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:33:30.893057  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9065
I1005 11:33:30.893092  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387478 (* 1 = 0.387478 loss)
I1005 11:33:30.945436  9385 solver.cpp:218] Iteration 80500 (15.4227 iter/s, 6.48395s/100 iters), loss = 0.00334752
I1005 11:33:30.945467  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334713 (* 1 = 0.00334713 loss)
I1005 11:33:30.945474  9385 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1005 11:33:36.195672  9385 solver.cpp:218] Iteration 80600 (19.0469 iter/s, 5.25019s/100 iters), loss = 0.00532128
I1005 11:33:36.195713  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532089 (* 1 = 0.00532089 loss)
I1005 11:33:36.195719  9385 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1005 11:33:41.449246  9385 solver.cpp:218] Iteration 80700 (19.0349 iter/s, 5.25351s/100 iters), loss = 0.011001
I1005 11:33:41.449276  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110006 (* 1 = 0.0110006 loss)
I1005 11:33:41.449282  9385 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1005 11:33:46.691022  9385 solver.cpp:218] Iteration 80800 (19.0777 iter/s, 5.24172s/100 iters), loss = 0.00440463
I1005 11:33:46.691068  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440424 (* 1 = 0.00440424 loss)
I1005 11:33:46.691076  9385 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1005 11:33:51.934346  9385 solver.cpp:218] Iteration 80900 (19.0722 iter/s, 5.24323s/100 iters), loss = 0.0127137
I1005 11:33:51.934387  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127133 (* 1 = 0.0127133 loss)
I1005 11:33:51.934393  9385 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1005 11:33:56.925217  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:33:57.134865  9385 solver.cpp:330] Iteration 81000, Testing net (#0)
I1005 11:33:58.323729  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:33:58.373807  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9115
I1005 11:33:58.373842  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372234 (* 1 = 0.372234 loss)
I1005 11:33:58.425921  9385 solver.cpp:218] Iteration 81000 (15.4047 iter/s, 6.49152s/100 iters), loss = 0.00197803
I1005 11:33:58.425952  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197764 (* 1 = 0.00197764 loss)
I1005 11:33:58.425959  9385 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1005 11:34:03.674859  9385 solver.cpp:218] Iteration 81100 (19.0517 iter/s, 5.24889s/100 iters), loss = 0.0118752
I1005 11:34:03.674891  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118748 (* 1 = 0.0118748 loss)
I1005 11:34:03.674899  9385 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1005 11:34:08.922781  9385 solver.cpp:218] Iteration 81200 (19.0553 iter/s, 5.24787s/100 iters), loss = 0.00790338
I1005 11:34:08.922811  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790298 (* 1 = 0.00790298 loss)
I1005 11:34:08.922816  9385 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1005 11:34:14.172034  9385 solver.cpp:218] Iteration 81300 (19.0505 iter/s, 5.24921s/100 iters), loss = 0.00853274
I1005 11:34:14.172075  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00853233 (* 1 = 0.00853233 loss)
I1005 11:34:14.172080  9385 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1005 11:34:19.411267  9385 solver.cpp:218] Iteration 81400 (19.087 iter/s, 5.23917s/100 iters), loss = 0.017701
I1005 11:34:19.411299  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177005 (* 1 = 0.0177005 loss)
I1005 11:34:19.411317  9385 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1005 11:34:24.403858  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:34:24.614298  9385 solver.cpp:330] Iteration 81500, Testing net (#0)
I1005 11:34:25.813578  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:34:25.863698  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.91
I1005 11:34:25.863724  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372329 (* 1 = 0.372329 loss)
I1005 11:34:25.915941  9385 solver.cpp:218] Iteration 81500 (15.3737 iter/s, 6.50462s/100 iters), loss = 0.00725589
I1005 11:34:25.915976  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725547 (* 1 = 0.00725547 loss)
I1005 11:34:25.915984  9385 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1005 11:34:31.158221  9385 solver.cpp:218] Iteration 81600 (19.0759 iter/s, 5.24223s/100 iters), loss = 0.020962
I1005 11:34:31.158309  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209616 (* 1 = 0.0209616 loss)
I1005 11:34:31.158330  9385 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1005 11:34:36.403724  9385 solver.cpp:218] Iteration 81700 (19.0643 iter/s, 5.2454s/100 iters), loss = 0.0274291
I1005 11:34:36.403764  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274287 (* 1 = 0.0274287 loss)
I1005 11:34:36.403769  9385 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1005 11:34:41.652294  9385 solver.cpp:218] Iteration 81800 (19.053 iter/s, 5.24851s/100 iters), loss = 0.0041129
I1005 11:34:41.652335  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411247 (* 1 = 0.00411247 loss)
I1005 11:34:41.652341  9385 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1005 11:34:46.897281  9385 solver.cpp:218] Iteration 81900 (19.066 iter/s, 5.24493s/100 iters), loss = 0.00934735
I1005 11:34:46.897315  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00934692 (* 1 = 0.00934692 loss)
I1005 11:34:46.897323  9385 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1005 11:34:51.878736  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:34:52.087954  9385 solver.cpp:330] Iteration 82000, Testing net (#0)
I1005 11:34:53.284143  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:34:53.334060  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1005 11:34:53.334087  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368147 (* 1 = 0.368147 loss)
I1005 11:34:53.386312  9385 solver.cpp:218] Iteration 82000 (15.4107 iter/s, 6.48898s/100 iters), loss = 0.001977
I1005 11:34:53.386343  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197657 (* 1 = 0.00197657 loss)
I1005 11:34:53.386353  9385 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1005 11:34:58.621980  9385 solver.cpp:218] Iteration 82100 (19.0999 iter/s, 5.23562s/100 iters), loss = 0.00880416
I1005 11:34:58.622025  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00880373 (* 1 = 0.00880373 loss)
I1005 11:34:58.622041  9385 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1005 11:35:03.867256  9385 solver.cpp:218] Iteration 82200 (19.065 iter/s, 5.24521s/100 iters), loss = 0.00341171
I1005 11:35:03.867395  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341127 (* 1 = 0.00341127 loss)
I1005 11:35:03.867403  9385 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1005 11:35:09.115818  9385 solver.cpp:218] Iteration 82300 (19.0534 iter/s, 5.24841s/100 iters), loss = 0.00891992
I1005 11:35:09.115847  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00891949 (* 1 = 0.00891949 loss)
I1005 11:35:09.115854  9385 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1005 11:35:14.366968  9385 solver.cpp:218] Iteration 82400 (19.0436 iter/s, 5.2511s/100 iters), loss = 0.0186454
I1005 11:35:14.367009  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018645 (* 1 = 0.018645 loss)
I1005 11:35:14.367015  9385 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1005 11:35:19.348135  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:35:19.557621  9385 solver.cpp:330] Iteration 82500, Testing net (#0)
I1005 11:35:20.754473  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:35:20.804559  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1005 11:35:20.804594  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366884 (* 1 = 0.366884 loss)
I1005 11:35:20.856393  9385 solver.cpp:218] Iteration 82500 (15.4098 iter/s, 6.48936s/100 iters), loss = 0.0166153
I1005 11:35:20.856418  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166148 (* 1 = 0.0166148 loss)
I1005 11:35:20.856426  9385 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1005 11:35:26.106118  9385 solver.cpp:218] Iteration 82600 (19.0488 iter/s, 5.24968s/100 iters), loss = 0.0188408
I1005 11:35:26.106148  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188403 (* 1 = 0.0188403 loss)
I1005 11:35:26.106153  9385 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1005 11:35:31.344280  9385 solver.cpp:218] Iteration 82700 (19.0908 iter/s, 5.23811s/100 iters), loss = 0.026231
I1005 11:35:31.344310  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262306 (* 1 = 0.0262306 loss)
I1005 11:35:31.344316  9385 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1005 11:35:36.598876  9385 solver.cpp:218] Iteration 82800 (19.0311 iter/s, 5.25455s/100 iters), loss = 0.0167865
I1005 11:35:36.599000  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167861 (* 1 = 0.0167861 loss)
I1005 11:35:36.599017  9385 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1005 11:35:41.837896  9385 solver.cpp:218] Iteration 82900 (19.0881 iter/s, 5.23888s/100 iters), loss = 0.0082228
I1005 11:35:41.837939  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00822238 (* 1 = 0.00822238 loss)
I1005 11:35:41.837944  9385 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1005 11:35:46.824686  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:35:47.034519  9385 solver.cpp:330] Iteration 83000, Testing net (#0)
I1005 11:35:48.223209  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:35:48.273072  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1005 11:35:48.273108  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370068 (* 1 = 0.370068 loss)
I1005 11:35:48.325510  9385 solver.cpp:218] Iteration 83000 (15.4141 iter/s, 6.48755s/100 iters), loss = 0.00146461
I1005 11:35:48.325537  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146419 (* 1 = 0.00146419 loss)
I1005 11:35:48.325544  9385 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1005 11:35:53.578099  9385 solver.cpp:218] Iteration 83100 (19.0384 iter/s, 5.25254s/100 iters), loss = 0.0473787
I1005 11:35:53.578140  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473782 (* 1 = 0.0473782 loss)
I1005 11:35:53.578145  9385 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1005 11:35:58.831377  9385 solver.cpp:218] Iteration 83200 (19.036 iter/s, 5.25322s/100 iters), loss = 0.0128529
I1005 11:35:58.831423  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128525 (* 1 = 0.0128525 loss)
I1005 11:35:58.831429  9385 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1005 11:36:04.080147  9385 solver.cpp:218] Iteration 83300 (19.0523 iter/s, 5.24871s/100 iters), loss = 0.0076819
I1005 11:36:04.080178  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00768148 (* 1 = 0.00768148 loss)
I1005 11:36:04.080183  9385 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1005 11:36:09.329403  9385 solver.cpp:218] Iteration 83400 (19.0505 iter/s, 5.2492s/100 iters), loss = 0.00598917
I1005 11:36:09.329504  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598875 (* 1 = 0.00598875 loss)
I1005 11:36:09.329520  9385 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1005 11:36:14.322510  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:36:14.531826  9385 solver.cpp:330] Iteration 83500, Testing net (#0)
I1005 11:36:15.719885  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:36:15.769388  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1005 11:36:15.769423  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368075 (* 1 = 0.368075 loss)
I1005 11:36:15.821602  9385 solver.cpp:218] Iteration 83500 (15.4034 iter/s, 6.49208s/100 iters), loss = 0.00628888
I1005 11:36:15.821629  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628845 (* 1 = 0.00628845 loss)
I1005 11:36:15.821635  9385 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1005 11:36:21.075847  9385 solver.cpp:218] Iteration 83600 (19.0324 iter/s, 5.2542s/100 iters), loss = 0.00419801
I1005 11:36:21.075876  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419759 (* 1 = 0.00419759 loss)
I1005 11:36:21.075881  9385 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1005 11:36:26.321818  9385 solver.cpp:218] Iteration 83700 (19.0624 iter/s, 5.24592s/100 iters), loss = 0.00314723
I1005 11:36:26.321848  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031468 (* 1 = 0.0031468 loss)
I1005 11:36:26.321853  9385 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1005 11:36:31.560431  9385 solver.cpp:218] Iteration 83800 (19.0892 iter/s, 5.23856s/100 iters), loss = 0.026577
I1005 11:36:31.560472  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265766 (* 1 = 0.0265766 loss)
I1005 11:36:31.560477  9385 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1005 11:36:36.806026  9385 solver.cpp:218] Iteration 83900 (19.0638 iter/s, 5.24554s/100 iters), loss = 0.00377002
I1005 11:36:36.806067  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376959 (* 1 = 0.00376959 loss)
I1005 11:36:36.806073  9385 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1005 11:36:41.794623  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:36:42.004096  9385 solver.cpp:330] Iteration 84000, Testing net (#0)
I1005 11:36:43.193594  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:36:43.243460  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1005 11:36:43.243496  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369756 (* 1 = 0.369756 loss)
I1005 11:36:43.296226  9385 solver.cpp:218] Iteration 84000 (15.408 iter/s, 6.49014s/100 iters), loss = 0.00219164
I1005 11:36:43.296255  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219121 (* 1 = 0.00219121 loss)
I1005 11:36:43.296263  9385 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1005 11:36:48.548372  9385 solver.cpp:218] Iteration 84100 (19.04 iter/s, 5.2521s/100 iters), loss = 0.0130715
I1005 11:36:48.548413  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130711 (* 1 = 0.0130711 loss)
I1005 11:36:48.548418  9385 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1005 11:36:53.795581  9385 solver.cpp:218] Iteration 84200 (19.058 iter/s, 5.24715s/100 iters), loss = 0.00849434
I1005 11:36:53.795613  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849392 (* 1 = 0.00849392 loss)
I1005 11:36:53.795619  9385 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1005 11:36:59.044129  9385 solver.cpp:218] Iteration 84300 (19.0531 iter/s, 5.2485s/100 iters), loss = 0.00440916
I1005 11:36:59.044162  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440874 (* 1 = 0.00440874 loss)
I1005 11:36:59.044168  9385 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1005 11:37:04.280246  9385 solver.cpp:218] Iteration 84400 (19.0983 iter/s, 5.23607s/100 iters), loss = 0.00910554
I1005 11:37:04.280278  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910512 (* 1 = 0.00910512 loss)
I1005 11:37:04.280284  9385 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1005 11:37:09.271751  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:37:09.480878  9385 solver.cpp:330] Iteration 84500, Testing net (#0)
I1005 11:37:10.673530  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:37:10.723753  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1005 11:37:10.723778  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367935 (* 1 = 0.367935 loss)
I1005 11:37:10.777268  9385 solver.cpp:218] Iteration 84500 (15.3918 iter/s, 6.49697s/100 iters), loss = 0.00282745
I1005 11:37:10.777302  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282704 (* 1 = 0.00282704 loss)
I1005 11:37:10.777309  9385 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1005 11:37:16.018595  9385 solver.cpp:218] Iteration 84600 (19.0793 iter/s, 5.24127s/100 iters), loss = 0.0268096
I1005 11:37:16.018709  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268092 (* 1 = 0.0268092 loss)
I1005 11:37:16.018717  9385 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1005 11:37:21.265493  9385 solver.cpp:218] Iteration 84700 (19.0593 iter/s, 5.24678s/100 iters), loss = 0.0033748
I1005 11:37:21.265523  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337438 (* 1 = 0.00337438 loss)
I1005 11:37:21.265528  9385 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1005 11:37:26.515040  9385 solver.cpp:218] Iteration 84800 (19.0494 iter/s, 5.2495s/100 iters), loss = 0.0159705
I1005 11:37:26.515071  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01597 (* 1 = 0.01597 loss)
I1005 11:37:26.515076  9385 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1005 11:37:31.757903  9385 solver.cpp:218] Iteration 84900 (19.0737 iter/s, 5.24281s/100 iters), loss = 0.00114966
I1005 11:37:31.757949  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114922 (* 1 = 0.00114922 loss)
I1005 11:37:31.757956  9385 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1005 11:37:36.742727  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:37:36.951409  9385 solver.cpp:330] Iteration 85000, Testing net (#0)
I1005 11:37:38.148185  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:37:38.198132  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1005 11:37:38.198165  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37129 (* 1 = 0.37129 loss)
I1005 11:37:38.250603  9385 solver.cpp:218] Iteration 85000 (15.4022 iter/s, 6.4926s/100 iters), loss = 0.0102827
I1005 11:37:38.250643  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102823 (* 1 = 0.0102823 loss)
I1005 11:37:38.250650  9385 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1005 11:37:43.492974  9385 solver.cpp:218] Iteration 85100 (19.0755 iter/s, 5.24231s/100 iters), loss = 0.00834489
I1005 11:37:43.493005  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00834446 (* 1 = 0.00834446 loss)
I1005 11:37:43.493011  9385 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1005 11:37:48.746911  9385 solver.cpp:218] Iteration 85200 (19.0335 iter/s, 5.25389s/100 iters), loss = 0.0110548
I1005 11:37:48.747048  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110543 (* 1 = 0.0110543 loss)
I1005 11:37:48.747066  9385 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1005 11:37:53.999491  9385 solver.cpp:218] Iteration 85300 (19.0388 iter/s, 5.25243s/100 iters), loss = 0.00534145
I1005 11:37:53.999531  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00534101 (* 1 = 0.00534101 loss)
I1005 11:37:53.999536  9385 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1005 11:37:59.247251  9385 solver.cpp:218] Iteration 85400 (19.056 iter/s, 5.2477s/100 iters), loss = 0.01133
I1005 11:37:59.247287  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113296 (* 1 = 0.0113296 loss)
I1005 11:37:59.247305  9385 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1005 11:38:04.229449  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:38:04.438401  9385 solver.cpp:330] Iteration 85500, Testing net (#0)
I1005 11:38:05.631793  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:38:05.681780  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1005 11:38:05.681807  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373021 (* 1 = 0.373021 loss)
I1005 11:38:05.734019  9385 solver.cpp:218] Iteration 85500 (15.4161 iter/s, 6.48672s/100 iters), loss = 0.00253016
I1005 11:38:05.734046  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252971 (* 1 = 0.00252971 loss)
I1005 11:38:05.734056  9385 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1005 11:38:10.977757  9385 solver.cpp:218] Iteration 85600 (19.0705 iter/s, 5.24369s/100 iters), loss = 0.00895278
I1005 11:38:10.977798  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895234 (* 1 = 0.00895234 loss)
I1005 11:38:10.977805  9385 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1005 11:38:16.208814  9385 solver.cpp:218] Iteration 85700 (19.1168 iter/s, 5.23099s/100 iters), loss = 0.0101903
I1005 11:38:16.208844  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101898 (* 1 = 0.0101898 loss)
I1005 11:38:16.208849  9385 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1005 11:38:21.454849  9385 solver.cpp:218] Iteration 85800 (19.0622 iter/s, 5.24599s/100 iters), loss = 0.00343295
I1005 11:38:21.454967  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343251 (* 1 = 0.00343251 loss)
I1005 11:38:21.454975  9385 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1005 11:38:26.703878  9385 solver.cpp:218] Iteration 85900 (19.0516 iter/s, 5.24889s/100 iters), loss = 0.00839136
I1005 11:38:26.703909  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00839092 (* 1 = 0.00839092 loss)
I1005 11:38:26.703915  9385 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1005 11:38:31.691859  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:38:31.906502  9385 solver.cpp:330] Iteration 86000, Testing net (#0)
I1005 11:38:33.096165  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:38:33.146036  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1005 11:38:33.146061  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372331 (* 1 = 0.372331 loss)
I1005 11:38:33.197824  9385 solver.cpp:218] Iteration 86000 (15.3991 iter/s, 6.4939s/100 iters), loss = 0.00360844
I1005 11:38:33.197852  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003608 (* 1 = 0.003608 loss)
I1005 11:38:33.197860  9385 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1005 11:38:38.448421  9385 solver.cpp:218] Iteration 86100 (19.0456 iter/s, 5.25055s/100 iters), loss = 0.00806557
I1005 11:38:38.448452  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00806513 (* 1 = 0.00806513 loss)
I1005 11:38:38.448458  9385 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1005 11:38:43.691399  9385 solver.cpp:218] Iteration 86200 (19.0733 iter/s, 5.24293s/100 iters), loss = 0.0237049
I1005 11:38:43.691437  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237045 (* 1 = 0.0237045 loss)
I1005 11:38:43.691444  9385 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1005 11:38:48.940490  9385 solver.cpp:218] Iteration 86300 (19.0511 iter/s, 5.24903s/100 iters), loss = 0.00665958
I1005 11:38:48.940528  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665914 (* 1 = 0.00665914 loss)
I1005 11:38:48.940534  9385 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1005 11:38:54.184072  9385 solver.cpp:218] Iteration 86400 (19.0711 iter/s, 5.24352s/100 iters), loss = 0.0127012
I1005 11:38:54.184173  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127007 (* 1 = 0.0127007 loss)
I1005 11:38:54.184180  9385 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1005 11:38:59.170439  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:38:59.380334  9385 solver.cpp:330] Iteration 86500, Testing net (#0)
I1005 11:39:00.568271  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:39:00.617776  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1005 11:39:00.617801  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372504 (* 1 = 0.372504 loss)
I1005 11:39:00.670002  9385 solver.cpp:218] Iteration 86500 (15.4183 iter/s, 6.48581s/100 iters), loss = 0.00232018
I1005 11:39:00.670028  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231975 (* 1 = 0.00231975 loss)
I1005 11:39:00.670035  9385 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1005 11:39:05.913370  9385 solver.cpp:218] Iteration 86600 (19.0719 iter/s, 5.24332s/100 iters), loss = 0.00959496
I1005 11:39:05.913399  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00959453 (* 1 = 0.00959453 loss)
I1005 11:39:05.913405  9385 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1005 11:39:11.160008  9385 solver.cpp:218] Iteration 86700 (19.06 iter/s, 5.24659s/100 iters), loss = 0.0117181
I1005 11:39:11.160038  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117177 (* 1 = 0.0117177 loss)
I1005 11:39:11.160044  9385 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1005 11:39:16.403292  9385 solver.cpp:218] Iteration 86800 (19.0722 iter/s, 5.24323s/100 iters), loss = 0.00592176
I1005 11:39:16.403322  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00592133 (* 1 = 0.00592133 loss)
I1005 11:39:16.403328  9385 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1005 11:39:21.648099  9385 solver.cpp:218] Iteration 86900 (19.0667 iter/s, 5.24476s/100 iters), loss = 0.00409905
I1005 11:39:21.648128  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409862 (* 1 = 0.00409862 loss)
I1005 11:39:21.648134  9385 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1005 11:39:26.639117  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:39:26.848428  9385 solver.cpp:330] Iteration 87000, Testing net (#0)
I1005 11:39:28.035943  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:39:28.085983  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I1005 11:39:28.086017  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370147 (* 1 = 0.370147 loss)
I1005 11:39:28.138038  9385 solver.cpp:218] Iteration 87000 (15.4086 iter/s, 6.48989s/100 iters), loss = 0.00144666
I1005 11:39:28.138062  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144623 (* 1 = 0.00144623 loss)
I1005 11:39:28.138069  9385 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1005 11:39:33.391892  9385 solver.cpp:218] Iteration 87100 (19.0338 iter/s, 5.25381s/100 iters), loss = 0.00720717
I1005 11:39:33.391922  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00720675 (* 1 = 0.00720675 loss)
I1005 11:39:33.391927  9385 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1005 11:39:38.641072  9385 solver.cpp:218] Iteration 87200 (19.0508 iter/s, 5.24913s/100 iters), loss = 0.00240505
I1005 11:39:38.641103  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240462 (* 1 = 0.00240462 loss)
I1005 11:39:38.641108  9385 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1005 11:39:43.888345  9385 solver.cpp:218] Iteration 87300 (19.0577 iter/s, 5.24722s/100 iters), loss = 0.0323141
I1005 11:39:43.888381  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323136 (* 1 = 0.0323136 loss)
I1005 11:39:43.888387  9385 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1005 11:39:49.125119  9385 solver.cpp:218] Iteration 87400 (19.0962 iter/s, 5.23664s/100 iters), loss = 0.00875953
I1005 11:39:49.125160  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087591 (* 1 = 0.0087591 loss)
I1005 11:39:49.125166  9385 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1005 11:39:54.114545  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:39:54.324721  9385 solver.cpp:330] Iteration 87500, Testing net (#0)
I1005 11:39:55.513373  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:39:55.563283  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9115
I1005 11:39:55.563309  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370132 (* 1 = 0.370132 loss)
I1005 11:39:55.615646  9385 solver.cpp:218] Iteration 87500 (15.4072 iter/s, 6.49046s/100 iters), loss = 0.0034785
I1005 11:39:55.615680  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347807 (* 1 = 0.00347807 loss)
I1005 11:39:55.615687  9385 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1005 11:40:00.864234  9385 solver.cpp:218] Iteration 87600 (19.0529 iter/s, 5.24854s/100 iters), loss = 0.0426144
I1005 11:40:00.864346  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042614 (* 1 = 0.042614 loss)
I1005 11:40:00.864352  9385 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1005 11:40:06.120849  9385 solver.cpp:218] Iteration 87700 (19.0241 iter/s, 5.25648s/100 iters), loss = 0.00773666
I1005 11:40:06.120889  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00773624 (* 1 = 0.00773624 loss)
I1005 11:40:06.120894  9385 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1005 11:40:11.370694  9385 solver.cpp:218] Iteration 87800 (19.0484 iter/s, 5.24979s/100 iters), loss = 0.00267165
I1005 11:40:11.370725  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267122 (* 1 = 0.00267122 loss)
I1005 11:40:11.370731  9385 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1005 11:40:16.608177  9385 solver.cpp:218] Iteration 87900 (19.0933 iter/s, 5.23743s/100 iters), loss = 0.00674831
I1005 11:40:16.608218  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067479 (* 1 = 0.0067479 loss)
I1005 11:40:16.608224  9385 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1005 11:40:21.600491  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:40:21.809931  9385 solver.cpp:330] Iteration 88000, Testing net (#0)
I1005 11:40:23.004889  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:40:23.054616  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9123
I1005 11:40:23.054649  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371393 (* 1 = 0.371393 loss)
I1005 11:40:23.106878  9385 solver.cpp:218] Iteration 88000 (15.3879 iter/s, 6.49863s/100 iters), loss = 0.00352564
I1005 11:40:23.106942  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352523 (* 1 = 0.00352523 loss)
I1005 11:40:23.106950  9385 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1005 11:40:28.349943  9385 solver.cpp:218] Iteration 88100 (19.0731 iter/s, 5.24298s/100 iters), loss = 0.0238697
I1005 11:40:28.349983  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238693 (* 1 = 0.0238693 loss)
I1005 11:40:28.349990  9385 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1005 11:40:33.589238  9385 solver.cpp:218] Iteration 88200 (19.0867 iter/s, 5.23924s/100 iters), loss = 0.00302441
I1005 11:40:33.589360  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302398 (* 1 = 0.00302398 loss)
I1005 11:40:33.589368  9385 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1005 11:40:38.835345  9385 solver.cpp:218] Iteration 88300 (19.0623 iter/s, 5.24597s/100 iters), loss = 0.0042332
I1005 11:40:38.835386  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423277 (* 1 = 0.00423277 loss)
I1005 11:40:38.835391  9385 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1005 11:40:44.079864  9385 solver.cpp:218] Iteration 88400 (19.0677 iter/s, 5.24446s/100 iters), loss = 0.0102377
I1005 11:40:44.079893  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102373 (* 1 = 0.0102373 loss)
I1005 11:40:44.079900  9385 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1005 11:40:49.064195  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:40:49.273278  9385 solver.cpp:330] Iteration 88500, Testing net (#0)
I1005 11:40:50.472246  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:40:50.522111  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1005 11:40:50.522135  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370394 (* 1 = 0.370394 loss)
I1005 11:40:50.574226  9385 solver.cpp:218] Iteration 88500 (15.3981 iter/s, 6.49432s/100 iters), loss = 0.00730872
I1005 11:40:50.574251  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00730829 (* 1 = 0.00730829 loss)
I1005 11:40:50.574259  9385 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1005 11:40:55.824851  9385 solver.cpp:218] Iteration 88600 (19.0455 iter/s, 5.25058s/100 iters), loss = 0.0122209
I1005 11:40:55.824888  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122205 (* 1 = 0.0122205 loss)
I1005 11:40:55.824897  9385 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1005 11:41:01.063091  9385 solver.cpp:218] Iteration 88700 (19.0906 iter/s, 5.23818s/100 iters), loss = 0.00544036
I1005 11:41:01.063120  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543993 (* 1 = 0.00543993 loss)
I1005 11:41:01.063127  9385 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1005 11:41:06.314332  9385 solver.cpp:218] Iteration 88800 (19.0433 iter/s, 5.25119s/100 iters), loss = 0.00691495
I1005 11:41:06.314481  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691452 (* 1 = 0.00691452 loss)
I1005 11:41:06.314501  9385 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1005 11:41:11.565452  9385 solver.cpp:218] Iteration 88900 (19.0442 iter/s, 5.25095s/100 iters), loss = 0.00628233
I1005 11:41:11.565485  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0062819 (* 1 = 0.0062819 loss)
I1005 11:41:11.565491  9385 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1005 11:41:16.545389  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:41:16.758728  9385 solver.cpp:330] Iteration 89000, Testing net (#0)
I1005 11:41:17.951869  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:41:18.001580  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1005 11:41:18.001616  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368639 (* 1 = 0.368639 loss)
I1005 11:41:18.053870  9385 solver.cpp:218] Iteration 89000 (15.4122 iter/s, 6.48837s/100 iters), loss = 0.00870286
I1005 11:41:18.053903  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00870244 (* 1 = 0.00870244 loss)
I1005 11:41:18.053910  9385 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1005 11:41:23.300781  9385 solver.cpp:218] Iteration 89100 (19.059 iter/s, 5.24686s/100 iters), loss = 0.0148323
I1005 11:41:23.300809  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148319 (* 1 = 0.0148319 loss)
I1005 11:41:23.300815  9385 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1005 11:41:28.538144  9385 solver.cpp:218] Iteration 89200 (19.0938 iter/s, 5.23732s/100 iters), loss = 0.00992737
I1005 11:41:28.538174  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00992695 (* 1 = 0.00992695 loss)
I1005 11:41:28.538179  9385 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1005 11:41:33.784693  9385 solver.cpp:218] Iteration 89300 (19.0603 iter/s, 5.2465s/100 iters), loss = 0.00340086
I1005 11:41:33.784732  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340043 (* 1 = 0.00340043 loss)
I1005 11:41:33.784739  9385 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1005 11:41:39.033823  9385 solver.cpp:218] Iteration 89400 (19.051 iter/s, 5.24907s/100 iters), loss = 0.00922679
I1005 11:41:39.033968  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00922637 (* 1 = 0.00922637 loss)
I1005 11:41:39.033977  9385 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1005 11:41:44.026875  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:41:44.236048  9385 solver.cpp:330] Iteration 89500, Testing net (#0)
I1005 11:41:45.423360  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:41:45.473345  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1005 11:41:45.473371  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370372 (* 1 = 0.370372 loss)
I1005 11:41:45.525583  9385 solver.cpp:218] Iteration 89500 (15.4045 iter/s, 6.4916s/100 iters), loss = 0.00291308
I1005 11:41:45.525614  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291265 (* 1 = 0.00291265 loss)
I1005 11:41:45.525630  9385 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1005 11:41:50.779134  9385 solver.cpp:218] Iteration 89600 (19.0349 iter/s, 5.2535s/100 iters), loss = 0.00297397
I1005 11:41:50.779173  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297354 (* 1 = 0.00297354 loss)
I1005 11:41:50.779180  9385 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1005 11:41:56.035495  9385 solver.cpp:218] Iteration 89700 (19.0248 iter/s, 5.2563s/100 iters), loss = 0.0075213
I1005 11:41:56.035524  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752087 (* 1 = 0.00752087 loss)
I1005 11:41:56.035531  9385 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1005 11:42:01.278980  9385 solver.cpp:218] Iteration 89800 (19.0715 iter/s, 5.24343s/100 iters), loss = 0.00764994
I1005 11:42:01.279021  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00764951 (* 1 = 0.00764951 loss)
I1005 11:42:01.279026  9385 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1005 11:42:06.519959  9385 solver.cpp:218] Iteration 89900 (19.0806 iter/s, 5.24092s/100 iters), loss = 0.00441231
I1005 11:42:06.519989  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00441188 (* 1 = 0.00441188 loss)
I1005 11:42:06.519995  9385 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1005 11:42:11.504312  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:42:11.713515  9385 solver.cpp:330] Iteration 90000, Testing net (#0)
I1005 11:42:12.902559  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:42:12.952169  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1005 11:42:12.952193  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371084 (* 1 = 0.371084 loss)
I1005 11:42:13.004638  9385 solver.cpp:218] Iteration 90000 (15.4211 iter/s, 6.48463s/100 iters), loss = 0.00866389
I1005 11:42:13.004663  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00866345 (* 1 = 0.00866345 loss)
I1005 11:42:13.004670  9385 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1005 11:42:18.249217  9385 solver.cpp:218] Iteration 90100 (19.0675 iter/s, 5.24453s/100 iters), loss = 0.00637939
I1005 11:42:18.249256  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00637896 (* 1 = 0.00637896 loss)
I1005 11:42:18.249261  9385 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1005 11:42:23.497412  9385 solver.cpp:218] Iteration 90200 (19.0544 iter/s, 5.24814s/100 iters), loss = 0.00429704
I1005 11:42:23.497445  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429662 (* 1 = 0.00429662 loss)
I1005 11:42:23.497454  9385 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1005 11:42:28.746145  9385 solver.cpp:218] Iteration 90300 (19.0524 iter/s, 5.24868s/100 iters), loss = 0.0052374
I1005 11:42:28.746186  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523697 (* 1 = 0.00523697 loss)
I1005 11:42:28.746206  9385 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1005 11:42:33.988790  9385 solver.cpp:218] Iteration 90400 (19.0747 iter/s, 5.24255s/100 iters), loss = 0.00170632
I1005 11:42:33.988823  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017059 (* 1 = 0.0017059 loss)
I1005 11:42:33.988831  9385 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1005 11:42:38.983608  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:42:39.193089  9385 solver.cpp:330] Iteration 90500, Testing net (#0)
I1005 11:42:40.381244  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:42:40.431097  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1005 11:42:40.431124  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371057 (* 1 = 0.371057 loss)
I1005 11:42:40.483405  9385 solver.cpp:218] Iteration 90500 (15.3975 iter/s, 6.49457s/100 iters), loss = 0.0105715
I1005 11:42:40.483438  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105711 (* 1 = 0.0105711 loss)
I1005 11:42:40.483449  9385 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1005 11:42:45.737763  9385 solver.cpp:218] Iteration 90600 (19.032 iter/s, 5.25431s/100 iters), loss = 0.0185749
I1005 11:42:45.737884  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185745 (* 1 = 0.0185745 loss)
I1005 11:42:45.737902  9385 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1005 11:42:50.984453  9385 solver.cpp:218] Iteration 90700 (19.0601 iter/s, 5.24656s/100 iters), loss = 0.00266251
I1005 11:42:50.984486  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266209 (* 1 = 0.00266209 loss)
I1005 11:42:50.984494  9385 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1005 11:42:56.233410  9385 solver.cpp:218] Iteration 90800 (19.0516 iter/s, 5.24891s/100 iters), loss = 0.00685866
I1005 11:42:56.233444  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685824 (* 1 = 0.00685824 loss)
I1005 11:42:56.233463  9385 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1005 11:43:01.475558  9385 solver.cpp:218] Iteration 90900 (19.0763 iter/s, 5.2421s/100 iters), loss = 0.0040339
I1005 11:43:01.475592  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403348 (* 1 = 0.00403348 loss)
I1005 11:43:01.475600  9385 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1005 11:43:06.469259  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:43:06.678979  9385 solver.cpp:330] Iteration 91000, Testing net (#0)
I1005 11:43:07.873811  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:43:07.924391  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1005 11:43:07.924419  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375488 (* 1 = 0.375488 loss)
I1005 11:43:07.976723  9385 solver.cpp:218] Iteration 91000 (15.382 iter/s, 6.50111s/100 iters), loss = 0.00539578
I1005 11:43:07.976757  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539536 (* 1 = 0.00539536 loss)
I1005 11:43:07.976766  9385 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1005 11:43:13.225469  9385 solver.cpp:218] Iteration 91100 (19.0523 iter/s, 5.2487s/100 iters), loss = 0.00688794
I1005 11:43:13.225505  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00688752 (* 1 = 0.00688752 loss)
I1005 11:43:13.225523  9385 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1005 11:43:18.479284  9385 solver.cpp:218] Iteration 91200 (19.034 iter/s, 5.25376s/100 iters), loss = 0.00753442
I1005 11:43:18.479493  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00753399 (* 1 = 0.00753399 loss)
I1005 11:43:18.479516  9385 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1005 11:43:23.727373  9385 solver.cpp:218] Iteration 91300 (19.0553 iter/s, 5.24789s/100 iters), loss = 0.0132928
I1005 11:43:23.727406  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132924 (* 1 = 0.0132924 loss)
I1005 11:43:23.727413  9385 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1005 11:43:28.973078  9385 solver.cpp:218] Iteration 91400 (19.0634 iter/s, 5.24565s/100 iters), loss = 0.00576619
I1005 11:43:28.973111  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576577 (* 1 = 0.00576577 loss)
I1005 11:43:28.973120  9385 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1005 11:43:33.957167  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:43:34.165736  9385 solver.cpp:330] Iteration 91500, Testing net (#0)
I1005 11:43:35.361105  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:43:35.410805  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1005 11:43:35.410830  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371744 (* 1 = 0.371744 loss)
I1005 11:43:35.462606  9385 solver.cpp:218] Iteration 91500 (15.4096 iter/s, 6.48948s/100 iters), loss = 0.00570045
I1005 11:43:35.462637  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570003 (* 1 = 0.00570003 loss)
I1005 11:43:35.462646  9385 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1005 11:43:40.706099  9385 solver.cpp:218] Iteration 91600 (19.0714 iter/s, 5.24344s/100 iters), loss = 0.0223997
I1005 11:43:40.706143  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223993 (* 1 = 0.0223993 loss)
I1005 11:43:40.706151  9385 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1005 11:43:45.954071  9385 solver.cpp:218] Iteration 91700 (19.0553 iter/s, 5.24787s/100 iters), loss = 0.00919162
I1005 11:43:45.954111  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091912 (* 1 = 0.0091912 loss)
I1005 11:43:45.954118  9385 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1005 11:43:51.200948  9385 solver.cpp:218] Iteration 91800 (19.0592 iter/s, 5.24682s/100 iters), loss = 0.00763006
I1005 11:43:51.201105  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00762964 (* 1 = 0.00762964 loss)
I1005 11:43:51.201113  9385 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1005 11:43:56.446271  9385 solver.cpp:218] Iteration 91900 (19.0652 iter/s, 5.24515s/100 iters), loss = 0.00686322
I1005 11:43:56.446312  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068628 (* 1 = 0.0068628 loss)
I1005 11:43:56.446318  9385 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1005 11:44:01.434623  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:44:01.645092  9385 solver.cpp:330] Iteration 92000, Testing net (#0)
I1005 11:44:02.839553  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:44:02.889458  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1005 11:44:02.889483  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371473 (* 1 = 0.371473 loss)
I1005 11:44:02.941815  9385 solver.cpp:218] Iteration 92000 (15.3953 iter/s, 6.49549s/100 iters), loss = 0.00554425
I1005 11:44:02.941841  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554383 (* 1 = 0.00554383 loss)
I1005 11:44:02.941848  9385 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1005 11:44:08.191157  9385 solver.cpp:218] Iteration 92100 (19.0502 iter/s, 5.24929s/100 iters), loss = 0.00325543
I1005 11:44:08.191189  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325501 (* 1 = 0.00325501 loss)
I1005 11:44:08.191195  9385 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1005 11:44:13.432006  9385 solver.cpp:218] Iteration 92200 (19.0811 iter/s, 5.2408s/100 iters), loss = 0.00247871
I1005 11:44:13.432037  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247829 (* 1 = 0.00247829 loss)
I1005 11:44:13.432044  9385 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1005 11:44:18.682286  9385 solver.cpp:218] Iteration 92300 (19.0468 iter/s, 5.25023s/100 iters), loss = 0.00475159
I1005 11:44:18.682315  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475117 (* 1 = 0.00475117 loss)
I1005 11:44:18.682322  9385 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1005 11:44:23.929131  9385 solver.cpp:218] Iteration 92400 (19.0592 iter/s, 5.2468s/100 iters), loss = 0.0106281
I1005 11:44:23.929242  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106277 (* 1 = 0.0106277 loss)
I1005 11:44:23.929250  9385 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1005 11:44:28.917418  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:44:29.127856  9385 solver.cpp:330] Iteration 92500, Testing net (#0)
I1005 11:44:30.315223  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:44:30.365207  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1005 11:44:30.365232  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372433 (* 1 = 0.372433 loss)
I1005 11:44:30.417208  9385 solver.cpp:218] Iteration 92500 (15.4132 iter/s, 6.48796s/100 iters), loss = 0.0143378
I1005 11:44:30.417233  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143373 (* 1 = 0.0143373 loss)
I1005 11:44:30.417243  9385 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1005 11:44:35.661948  9385 solver.cpp:218] Iteration 92600 (19.0669 iter/s, 5.2447s/100 iters), loss = 0.0228593
I1005 11:44:35.661981  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228589 (* 1 = 0.0228589 loss)
I1005 11:44:35.661999  9385 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1005 11:44:40.906006  9385 solver.cpp:218] Iteration 92700 (19.0694 iter/s, 5.244s/100 iters), loss = 0.00355416
I1005 11:44:40.906054  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355374 (* 1 = 0.00355374 loss)
I1005 11:44:40.906060  9385 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1005 11:44:46.151460  9385 solver.cpp:218] Iteration 92800 (19.0645 iter/s, 5.24536s/100 iters), loss = 0.00304465
I1005 11:44:46.151499  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304422 (* 1 = 0.00304422 loss)
I1005 11:44:46.151505  9385 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1005 11:44:51.392918  9385 solver.cpp:218] Iteration 92900 (19.0789 iter/s, 5.2414s/100 iters), loss = 0.000920507
I1005 11:44:51.392958  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000920082 (* 1 = 0.000920082 loss)
I1005 11:44:51.392963  9385 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1005 11:44:56.383850  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:44:56.592679  9385 solver.cpp:330] Iteration 93000, Testing net (#0)
I1005 11:44:57.777577  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:44:57.827298  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1005 11:44:57.827332  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37677 (* 1 = 0.37677 loss)
I1005 11:44:57.879401  9385 solver.cpp:218] Iteration 93000 (15.4168 iter/s, 6.48643s/100 iters), loss = 0.00435708
I1005 11:44:57.879429  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435666 (* 1 = 0.00435666 loss)
I1005 11:44:57.879436  9385 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1005 11:45:03.133409  9385 solver.cpp:218] Iteration 93100 (19.0333 iter/s, 5.25396s/100 iters), loss = 0.0102748
I1005 11:45:03.133440  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102743 (* 1 = 0.0102743 loss)
I1005 11:45:03.133447  9385 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1005 11:45:08.385449  9385 solver.cpp:218] Iteration 93200 (19.0404 iter/s, 5.25199s/100 iters), loss = 0.00427128
I1005 11:45:08.385480  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00427086 (* 1 = 0.00427086 loss)
I1005 11:45:08.385488  9385 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1005 11:45:13.629624  9385 solver.cpp:218] Iteration 93300 (19.069 iter/s, 5.24412s/100 iters), loss = 0.0143401
I1005 11:45:13.629663  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143396 (* 1 = 0.0143396 loss)
I1005 11:45:13.629683  9385 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1005 11:45:18.873484  9385 solver.cpp:218] Iteration 93400 (19.0701 iter/s, 5.24381s/100 iters), loss = 0.00354856
I1005 11:45:18.873517  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354813 (* 1 = 0.00354813 loss)
I1005 11:45:18.873525  9385 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1005 11:45:23.864075  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:45:24.073966  9385 solver.cpp:330] Iteration 93500, Testing net (#0)
I1005 11:45:25.262051  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:45:25.312036  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1005 11:45:25.312063  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375127 (* 1 = 0.375127 loss)
I1005 11:45:25.364173  9385 solver.cpp:218] Iteration 93500 (15.4068 iter/s, 6.49064s/100 iters), loss = 0.00670804
I1005 11:45:25.364207  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670761 (* 1 = 0.00670761 loss)
I1005 11:45:25.364217  9385 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1005 11:45:30.609161  9385 solver.cpp:218] Iteration 93600 (19.066 iter/s, 5.24494s/100 iters), loss = 0.00335406
I1005 11:45:30.609282  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335363 (* 1 = 0.00335363 loss)
I1005 11:45:30.609302  9385 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1005 11:45:35.863102  9385 solver.cpp:218] Iteration 93700 (19.0338 iter/s, 5.25381s/100 iters), loss = 0.00651968
I1005 11:45:35.863135  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651924 (* 1 = 0.00651924 loss)
I1005 11:45:35.863152  9385 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1005 11:45:41.114665  9385 solver.cpp:218] Iteration 93800 (19.0421 iter/s, 5.25151s/100 iters), loss = 0.00230622
I1005 11:45:41.114697  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230579 (* 1 = 0.00230579 loss)
I1005 11:45:41.114703  9385 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1005 11:45:46.353523  9385 solver.cpp:218] Iteration 93900 (19.0883 iter/s, 5.23881s/100 iters), loss = 0.00574607
I1005 11:45:46.353554  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574564 (* 1 = 0.00574564 loss)
I1005 11:45:46.353559  9385 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1005 11:45:51.347786  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:45:51.557698  9385 solver.cpp:330] Iteration 94000, Testing net (#0)
I1005 11:45:52.750672  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:45:52.801021  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9123
I1005 11:45:52.801051  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376214 (* 1 = 0.376214 loss)
I1005 11:45:52.854650  9385 solver.cpp:218] Iteration 94000 (15.3821 iter/s, 6.50108s/100 iters), loss = 0.0020661
I1005 11:45:52.854688  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206566 (* 1 = 0.00206566 loss)
I1005 11:45:52.854698  9385 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1005 11:45:58.095970  9385 solver.cpp:218] Iteration 94100 (19.0794 iter/s, 5.24126s/100 iters), loss = 0.00364637
I1005 11:45:58.096002  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364594 (* 1 = 0.00364594 loss)
I1005 11:45:58.096010  9385 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1005 11:46:03.346691  9385 solver.cpp:218] Iteration 94200 (19.0452 iter/s, 5.25067s/100 iters), loss = 0.00325248
I1005 11:46:03.346809  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325205 (* 1 = 0.00325205 loss)
I1005 11:46:03.346829  9385 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1005 11:46:08.597164  9385 solver.cpp:218] Iteration 94300 (19.0464 iter/s, 5.25034s/100 iters), loss = 0.00458544
I1005 11:46:08.597195  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004585 (* 1 = 0.004585 loss)
I1005 11:46:08.597211  9385 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1005 11:46:13.837837  9385 solver.cpp:218] Iteration 94400 (19.0817 iter/s, 5.24062s/100 iters), loss = 0.00577653
I1005 11:46:13.837873  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057761 (* 1 = 0.0057761 loss)
I1005 11:46:13.837882  9385 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1005 11:46:18.821177  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:46:19.030616  9385 solver.cpp:330] Iteration 94500, Testing net (#0)
I1005 11:46:20.225929  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:46:20.275908  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1005 11:46:20.275935  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373174 (* 1 = 0.373174 loss)
I1005 11:46:20.328016  9385 solver.cpp:218] Iteration 94500 (15.408 iter/s, 6.49013s/100 iters), loss = 0.013869
I1005 11:46:20.328069  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138686 (* 1 = 0.0138686 loss)
I1005 11:46:20.328094  9385 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1005 11:46:25.575999  9385 solver.cpp:218] Iteration 94600 (19.0552 iter/s, 5.24792s/100 iters), loss = 0.00731882
I1005 11:46:25.576033  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731838 (* 1 = 0.00731838 loss)
I1005 11:46:25.576042  9385 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1005 11:46:30.829221  9385 solver.cpp:218] Iteration 94700 (19.0361 iter/s, 5.25317s/100 iters), loss = 0.00193563
I1005 11:46:30.829252  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193519 (* 1 = 0.00193519 loss)
I1005 11:46:30.829270  9385 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1005 11:46:36.085868  9385 solver.cpp:218] Iteration 94800 (19.0237 iter/s, 5.2566s/100 iters), loss = 0.0107984
I1005 11:46:36.085983  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010798 (* 1 = 0.010798 loss)
I1005 11:46:36.086004  9385 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1005 11:46:41.343482  9385 solver.cpp:218] Iteration 94900 (19.0205 iter/s, 5.25749s/100 iters), loss = 0.00400125
I1005 11:46:41.343535  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400081 (* 1 = 0.00400081 loss)
I1005 11:46:41.343554  9385 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1005 11:46:46.332949  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:46:46.543172  9385 solver.cpp:330] Iteration 95000, Testing net (#0)
I1005 11:46:47.741194  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:46:47.790912  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1005 11:46:47.790940  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373347 (* 1 = 0.373347 loss)
I1005 11:46:47.843134  9385 solver.cpp:218] Iteration 95000 (15.3856 iter/s, 6.4996s/100 iters), loss = 0.0112188
I1005 11:46:47.843159  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112184 (* 1 = 0.0112184 loss)
I1005 11:46:47.843165  9385 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1005 11:46:53.090226  9385 solver.cpp:218] Iteration 95100 (19.0583 iter/s, 5.24705s/100 iters), loss = 0.00591089
I1005 11:46:53.090267  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00591045 (* 1 = 0.00591045 loss)
I1005 11:46:53.090273  9385 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1005 11:46:58.334630  9385 solver.cpp:218] Iteration 95200 (19.0682 iter/s, 5.24434s/100 iters), loss = 0.013892
I1005 11:46:58.334671  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138915 (* 1 = 0.0138915 loss)
I1005 11:46:58.334676  9385 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1005 11:47:03.581679  9385 solver.cpp:218] Iteration 95300 (19.0586 iter/s, 5.24699s/100 iters), loss = 0.0100541
I1005 11:47:03.581712  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100536 (* 1 = 0.0100536 loss)
I1005 11:47:03.581730  9385 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1005 11:47:08.827034  9385 solver.cpp:218] Iteration 95400 (19.0647 iter/s, 5.2453s/100 iters), loss = 0.0151653
I1005 11:47:08.827210  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151649 (* 1 = 0.0151649 loss)
I1005 11:47:08.827231  9385 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1005 11:47:13.818200  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:47:14.030612  9385 solver.cpp:330] Iteration 95500, Testing net (#0)
I1005 11:47:15.218547  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:47:15.268256  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1005 11:47:15.268281  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374205 (* 1 = 0.374205 loss)
I1005 11:47:15.320721  9385 solver.cpp:218] Iteration 95500 (15.3999 iter/s, 6.49353s/100 iters), loss = 0.00295214
I1005 11:47:15.320746  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295169 (* 1 = 0.00295169 loss)
I1005 11:47:15.320753  9385 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1005 11:47:20.572448  9385 solver.cpp:218] Iteration 95600 (19.0415 iter/s, 5.25168s/100 iters), loss = 0.00720395
I1005 11:47:20.572494  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0072035 (* 1 = 0.0072035 loss)
I1005 11:47:20.572500  9385 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1005 11:47:25.820019  9385 solver.cpp:218] Iteration 95700 (19.0567 iter/s, 5.2475s/100 iters), loss = 0.00403569
I1005 11:47:25.820067  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403525 (* 1 = 0.00403525 loss)
I1005 11:47:25.820075  9385 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1005 11:47:31.060911  9385 solver.cpp:218] Iteration 95800 (19.0811 iter/s, 5.24079s/100 iters), loss = 0.00861284
I1005 11:47:31.060951  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0086124 (* 1 = 0.0086124 loss)
I1005 11:47:31.060957  9385 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1005 11:47:36.306032  9385 solver.cpp:218] Iteration 95900 (19.0656 iter/s, 5.24506s/100 iters), loss = 0.00397728
I1005 11:47:36.306062  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397684 (* 1 = 0.00397684 loss)
I1005 11:47:36.306067  9385 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1005 11:47:41.289769  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:47:41.499645  9385 solver.cpp:330] Iteration 96000, Testing net (#0)
I1005 11:47:42.688858  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:47:42.738456  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1005 11:47:42.738492  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373666 (* 1 = 0.373666 loss)
I1005 11:47:42.790791  9385 solver.cpp:218] Iteration 96000 (15.4209 iter/s, 6.48471s/100 iters), loss = 0.00778969
I1005 11:47:42.790814  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00778925 (* 1 = 0.00778925 loss)
I1005 11:47:42.790822  9385 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1005 11:47:48.034654  9385 solver.cpp:218] Iteration 96100 (19.0701 iter/s, 5.24382s/100 iters), loss = 0.00559096
I1005 11:47:48.034683  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559051 (* 1 = 0.00559051 loss)
I1005 11:47:48.034689  9385 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1005 11:47:53.277635  9385 solver.cpp:218] Iteration 96200 (19.0733 iter/s, 5.24293s/100 iters), loss = 0.00481146
I1005 11:47:53.277667  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481101 (* 1 = 0.00481101 loss)
I1005 11:47:53.277673  9385 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1005 11:47:58.512114  9385 solver.cpp:218] Iteration 96300 (19.1043 iter/s, 5.23443s/100 iters), loss = 0.0081986
I1005 11:47:58.512143  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00819814 (* 1 = 0.00819814 loss)
I1005 11:47:58.512150  9385 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1005 11:48:03.756474  9385 solver.cpp:218] Iteration 96400 (19.0683 iter/s, 5.24431s/100 iters), loss = 0.0101838
I1005 11:48:03.756505  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101833 (* 1 = 0.0101833 loss)
I1005 11:48:03.756510  9385 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1005 11:48:08.747545  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:48:08.957182  9385 solver.cpp:330] Iteration 96500, Testing net (#0)
I1005 11:48:10.142565  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:48:10.192252  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1005 11:48:10.192276  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373516 (* 1 = 0.373516 loss)
I1005 11:48:10.244292  9385 solver.cpp:218] Iteration 96500 (15.4136 iter/s, 6.48777s/100 iters), loss = 0.0149864
I1005 11:48:10.244328  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014986 (* 1 = 0.014986 loss)
I1005 11:48:10.244345  9385 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1005 11:48:15.497663  9385 solver.cpp:218] Iteration 96600 (19.0356 iter/s, 5.25332s/100 iters), loss = 0.00199093
I1005 11:48:15.497798  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199047 (* 1 = 0.00199047 loss)
I1005 11:48:15.497817  9385 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1005 11:48:20.750296  9385 solver.cpp:218] Iteration 96700 (19.0386 iter/s, 5.25248s/100 iters), loss = 0.00659074
I1005 11:48:20.750326  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659027 (* 1 = 0.00659027 loss)
I1005 11:48:20.750332  9385 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1005 11:48:26.001066  9385 solver.cpp:218] Iteration 96800 (19.045 iter/s, 5.25072s/100 iters), loss = 0.00774331
I1005 11:48:26.001107  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774284 (* 1 = 0.00774284 loss)
I1005 11:48:26.001114  9385 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1005 11:48:31.240178  9385 solver.cpp:218] Iteration 96900 (19.0874 iter/s, 5.23905s/100 iters), loss = 0.00344602
I1005 11:48:31.240211  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344555 (* 1 = 0.00344555 loss)
I1005 11:48:31.240216  9385 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1005 11:48:36.229516  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:48:36.438771  9385 solver.cpp:330] Iteration 97000, Testing net (#0)
I1005 11:48:37.625134  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:48:37.675473  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1005 11:48:37.675513  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374396 (* 1 = 0.374396 loss)
I1005 11:48:37.728544  9385 solver.cpp:218] Iteration 97000 (15.4123 iter/s, 6.48831s/100 iters), loss = 0.00142218
I1005 11:48:37.728588  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014217 (* 1 = 0.0014217 loss)
I1005 11:48:37.728595  9385 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1005 11:48:42.979486  9385 solver.cpp:218] Iteration 97100 (19.0445 iter/s, 5.25085s/100 iters), loss = 0.00423149
I1005 11:48:42.979527  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423101 (* 1 = 0.00423101 loss)
I1005 11:48:42.979533  9385 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1005 11:48:48.227565  9385 solver.cpp:218] Iteration 97200 (19.0548 iter/s, 5.24802s/100 iters), loss = 0.0155095
I1005 11:48:48.227689  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015509 (* 1 = 0.015509 loss)
I1005 11:48:48.227697  9385 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1005 11:48:53.482069  9385 solver.cpp:218] Iteration 97300 (19.0318 iter/s, 5.25436s/100 iters), loss = 0.0100926
I1005 11:48:53.482110  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100921 (* 1 = 0.0100921 loss)
I1005 11:48:53.482115  9385 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1005 11:48:58.722038  9385 solver.cpp:218] Iteration 97400 (19.0843 iter/s, 5.23991s/100 iters), loss = 0.00298975
I1005 11:48:58.722075  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298928 (* 1 = 0.00298928 loss)
I1005 11:48:58.722082  9385 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1005 11:49:03.709290  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:49:03.919144  9385 solver.cpp:330] Iteration 97500, Testing net (#0)
I1005 11:49:05.116279  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:49:05.166301  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1005 11:49:05.166326  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376754 (* 1 = 0.376754 loss)
I1005 11:49:05.218343  9385 solver.cpp:218] Iteration 97500 (15.3935 iter/s, 6.49625s/100 iters), loss = 0.00124923
I1005 11:49:05.218379  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124877 (* 1 = 0.00124877 loss)
I1005 11:49:05.218386  9385 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1005 11:49:10.461982  9385 solver.cpp:218] Iteration 97600 (19.0709 iter/s, 5.24359s/100 iters), loss = 0.00483407
I1005 11:49:10.462013  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483361 (* 1 = 0.00483361 loss)
I1005 11:49:10.462018  9385 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1005 11:49:15.705435  9385 solver.cpp:218] Iteration 97700 (19.0716 iter/s, 5.2434s/100 iters), loss = 0.00530774
I1005 11:49:15.705464  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530728 (* 1 = 0.00530728 loss)
I1005 11:49:15.705469  9385 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1005 11:49:20.953197  9385 solver.cpp:218] Iteration 97800 (19.0559 iter/s, 5.24771s/100 iters), loss = 0.0128555
I1005 11:49:20.953294  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012855 (* 1 = 0.012855 loss)
I1005 11:49:20.953300  9385 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1005 11:49:26.191411  9385 solver.cpp:218] Iteration 97900 (19.0909 iter/s, 5.2381s/100 iters), loss = 0.00250426
I1005 11:49:26.191442  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025038 (* 1 = 0.0025038 loss)
I1005 11:49:26.191447  9385 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1005 11:49:31.173419  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:49:31.383463  9385 solver.cpp:330] Iteration 98000, Testing net (#0)
I1005 11:49:32.579677  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:49:32.629645  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1005 11:49:32.629680  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376828 (* 1 = 0.376828 loss)
I1005 11:49:32.682047  9385 solver.cpp:218] Iteration 98000 (15.4069 iter/s, 6.49058s/100 iters), loss = 0.00410402
I1005 11:49:32.682072  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410357 (* 1 = 0.00410357 loss)
I1005 11:49:32.682080  9385 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1005 11:49:37.933138  9385 solver.cpp:218] Iteration 98100 (19.0438 iter/s, 5.25104s/100 iters), loss = 0.00385655
I1005 11:49:37.933183  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038561 (* 1 = 0.0038561 loss)
I1005 11:49:37.933190  9385 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1005 11:49:43.174731  9385 solver.cpp:218] Iteration 98200 (19.0785 iter/s, 5.2415s/100 iters), loss = 0.00310907
I1005 11:49:43.174760  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310862 (* 1 = 0.00310862 loss)
I1005 11:49:43.174765  9385 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1005 11:49:48.427422  9385 solver.cpp:218] Iteration 98300 (19.038 iter/s, 5.25264s/100 iters), loss = 0.00477766
I1005 11:49:48.427451  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477721 (* 1 = 0.00477721 loss)
I1005 11:49:48.427458  9385 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1005 11:49:53.676331  9385 solver.cpp:218] Iteration 98400 (19.0518 iter/s, 5.24886s/100 iters), loss = 0.00140059
I1005 11:49:53.676460  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140014 (* 1 = 0.00140014 loss)
I1005 11:49:53.676467  9385 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1005 11:49:58.659245  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:49:58.873612  9385 solver.cpp:330] Iteration 98500, Testing net (#0)
I1005 11:50:00.062331  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:50:00.112300  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I1005 11:50:00.112334  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374128 (* 1 = 0.374128 loss)
I1005 11:50:00.164770  9385 solver.cpp:218] Iteration 98500 (15.4124 iter/s, 6.48829s/100 iters), loss = 0.00659822
I1005 11:50:00.164798  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659777 (* 1 = 0.00659777 loss)
I1005 11:50:00.164803  9385 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1005 11:50:05.411860  9385 solver.cpp:218] Iteration 98600 (19.0584 iter/s, 5.24704s/100 iters), loss = 0.00480189
I1005 11:50:05.411901  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00480144 (* 1 = 0.00480144 loss)
I1005 11:50:05.411907  9385 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1005 11:50:10.652178  9385 solver.cpp:218] Iteration 98700 (19.083 iter/s, 5.24026s/100 iters), loss = 0.0132263
I1005 11:50:10.652209  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132258 (* 1 = 0.0132258 loss)
I1005 11:50:10.652214  9385 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1005 11:50:15.899338  9385 solver.cpp:218] Iteration 98800 (19.0581 iter/s, 5.24711s/100 iters), loss = 0.00697497
I1005 11:50:15.899369  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00697453 (* 1 = 0.00697453 loss)
I1005 11:50:15.899374  9385 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1005 11:50:21.144549  9385 solver.cpp:218] Iteration 98900 (19.0652 iter/s, 5.24516s/100 iters), loss = 0.00594458
I1005 11:50:21.144580  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594413 (* 1 = 0.00594413 loss)
I1005 11:50:21.144585  9385 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1005 11:50:26.137542  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:50:26.346501  9385 solver.cpp:330] Iteration 99000, Testing net (#0)
I1005 11:50:27.533829  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:50:27.583659  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1005 11:50:27.583684  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37378 (* 1 = 0.37378 loss)
I1005 11:50:27.636204  9385 solver.cpp:218] Iteration 99000 (15.4045 iter/s, 6.49161s/100 iters), loss = 0.0010709
I1005 11:50:27.636230  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107046 (* 1 = 0.00107046 loss)
I1005 11:50:27.636237  9385 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1005 11:50:32.890537  9385 solver.cpp:218] Iteration 99100 (19.0321 iter/s, 5.25429s/100 iters), loss = 0.0254119
I1005 11:50:32.890578  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254114 (* 1 = 0.0254114 loss)
I1005 11:50:32.890584  9385 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1005 11:50:38.141940  9385 solver.cpp:218] Iteration 99200 (19.0427 iter/s, 5.25134s/100 iters), loss = 0.00451326
I1005 11:50:38.141981  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451283 (* 1 = 0.00451283 loss)
I1005 11:50:38.141988  9385 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1005 11:50:43.383666  9385 solver.cpp:218] Iteration 99300 (19.0779 iter/s, 5.24166s/100 iters), loss = 0.00639902
I1005 11:50:43.383709  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00639857 (* 1 = 0.00639857 loss)
I1005 11:50:43.383715  9385 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1005 11:50:48.632671  9385 solver.cpp:218] Iteration 99400 (19.0514 iter/s, 5.24895s/100 iters), loss = 0.0045549
I1005 11:50:48.632702  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455445 (* 1 = 0.00455445 loss)
I1005 11:50:48.632709  9385 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1005 11:50:53.621068  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:50:53.831647  9385 solver.cpp:330] Iteration 99500, Testing net (#0)
I1005 11:50:55.019639  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:50:55.069216  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I1005 11:50:55.069241  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37477 (* 1 = 0.37477 loss)
I1005 11:50:55.121510  9385 solver.cpp:218] Iteration 99500 (15.4112 iter/s, 6.48879s/100 iters), loss = 0.0018904
I1005 11:50:55.121536  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188996 (* 1 = 0.00188996 loss)
I1005 11:50:55.121542  9385 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1005 11:51:00.370173  9385 solver.cpp:218] Iteration 99600 (19.0526 iter/s, 5.24862s/100 iters), loss = 0.00772869
I1005 11:51:00.370275  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00772825 (* 1 = 0.00772825 loss)
I1005 11:51:00.370281  9385 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1005 11:51:05.616042  9385 solver.cpp:218] Iteration 99700 (19.063 iter/s, 5.24575s/100 iters), loss = 0.00523726
I1005 11:51:05.616080  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523682 (* 1 = 0.00523682 loss)
I1005 11:51:05.616087  9385 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1005 11:51:10.863975  9385 solver.cpp:218] Iteration 99800 (19.0553 iter/s, 5.24788s/100 iters), loss = 0.00777031
I1005 11:51:10.864012  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776987 (* 1 = 0.00776987 loss)
I1005 11:51:10.864018  9385 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1005 11:51:16.105036  9385 solver.cpp:218] Iteration 99900 (19.0803 iter/s, 5.24101s/100 iters), loss = 0.00402666
I1005 11:51:16.105065  9385 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402622 (* 1 = 0.00402622 loss)
I1005 11:51:16.105070  9385 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1005 11:51:21.095942  9394 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:51:21.304944  9385 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha1_beta1_etanostudy_2study_nodecay_gauss_iter_100000.caffemodel
I1005 11:51:21.320786  9385 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha1_beta1_etanostudy_2study_nodecay_gauss_iter_100000.solverstate
I1005 11:51:21.335541  9385 solver.cpp:310] Iteration 100000, loss = 0.00164502
I1005 11:51:21.335562  9385 solver.cpp:330] Iteration 100000, Testing net (#0)
I1005 11:51:22.524436  9395 data_layer.cpp:73] Restarting data prefetching from start.
I1005 11:51:22.575454  9385 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1005 11:51:22.575479  9385 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37083 (* 1 = 0.37083 loss)
I1005 11:51:22.575484  9385 solver.cpp:315] Optimization Done.
I1005 11:51:22.575485  9385 caffe.cpp:259] Optimization Done.
