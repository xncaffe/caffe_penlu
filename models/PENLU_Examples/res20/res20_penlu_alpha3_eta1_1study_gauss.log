I0930 20:04:49.932407  4047 caffe.cpp:218] Using GPUs 0
I0930 20:04:49.966195  4047 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0930 20:04:50.195257  4047 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0930 20:04:50.195411  4047 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:04:50.196938  4047 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:04:50.196947  4047 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0930 20:04:50.197093  4047 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0930 20:04:50.197167  4047 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0930 20:04:50.197639  4047 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0930 20:04:50.198011  4047 layer_factory.hpp:77] Creating layer Data1
I0930 20:04:50.198089  4047 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0930 20:04:50.198114  4047 net.cpp:84] Creating Layer Data1
I0930 20:04:50.198119  4047 net.cpp:380] Data1 -> Data1
I0930 20:04:50.198134  4047 net.cpp:380] Data1 -> Data2
I0930 20:04:50.198143  4047 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0930 20:04:50.199570  4047 data_layer.cpp:45] output data size: 100,3,28,28
I0930 20:04:50.201849  4047 net.cpp:122] Setting up Data1
I0930 20:04:50.201872  4047 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0930 20:04:50.201877  4047 net.cpp:129] Top shape: 100 (100)
I0930 20:04:50.201879  4047 net.cpp:137] Memory required for data: 941200
I0930 20:04:50.201885  4047 layer_factory.hpp:77] Creating layer Convolution1
I0930 20:04:50.201903  4047 net.cpp:84] Creating Layer Convolution1
I0930 20:04:50.201907  4047 net.cpp:406] Convolution1 <- Data1
I0930 20:04:50.201916  4047 net.cpp:380] Convolution1 -> Convolution1
I0930 20:04:50.348767  4047 net.cpp:122] Setting up Convolution1
I0930 20:04:50.348790  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.348793  4047 net.cpp:137] Memory required for data: 5958800
I0930 20:04:50.348809  4047 layer_factory.hpp:77] Creating layer BatchNorm1
I0930 20:04:50.348829  4047 net.cpp:84] Creating Layer BatchNorm1
I0930 20:04:50.348845  4047 net.cpp:406] BatchNorm1 <- Convolution1
I0930 20:04:50.348851  4047 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0930 20:04:50.349004  4047 net.cpp:122] Setting up BatchNorm1
I0930 20:04:50.349011  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.349014  4047 net.cpp:137] Memory required for data: 10976400
I0930 20:04:50.349021  4047 layer_factory.hpp:77] Creating layer Scale1
I0930 20:04:50.349041  4047 net.cpp:84] Creating Layer Scale1
I0930 20:04:50.349045  4047 net.cpp:406] Scale1 <- Convolution1
I0930 20:04:50.349050  4047 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0930 20:04:50.349098  4047 layer_factory.hpp:77] Creating layer Scale1
I0930 20:04:50.349184  4047 net.cpp:122] Setting up Scale1
I0930 20:04:50.349190  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.349192  4047 net.cpp:137] Memory required for data: 15994000
I0930 20:04:50.349197  4047 layer_factory.hpp:77] Creating layer penlu1
I0930 20:04:50.349206  4047 net.cpp:84] Creating Layer penlu1
I0930 20:04:50.349210  4047 net.cpp:406] penlu1 <- Convolution1
I0930 20:04:50.349215  4047 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0930 20:04:50.349825  4047 net.cpp:122] Setting up penlu1
I0930 20:04:50.349834  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.349839  4047 net.cpp:137] Memory required for data: 21011600
I0930 20:04:50.349850  4047 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0930 20:04:50.349859  4047 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0930 20:04:50.349864  4047 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0930 20:04:50.349872  4047 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0930 20:04:50.349892  4047 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0930 20:04:50.349936  4047 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0930 20:04:50.349942  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.349956  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.349959  4047 net.cpp:137] Memory required for data: 31046800
I0930 20:04:50.349962  4047 layer_factory.hpp:77] Creating layer Convolution2
I0930 20:04:50.349973  4047 net.cpp:84] Creating Layer Convolution2
I0930 20:04:50.349979  4047 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0930 20:04:50.349987  4047 net.cpp:380] Convolution2 -> Convolution2
I0930 20:04:50.350853  4047 net.cpp:122] Setting up Convolution2
I0930 20:04:50.350864  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.350870  4047 net.cpp:137] Memory required for data: 36064400
I0930 20:04:50.350878  4047 layer_factory.hpp:77] Creating layer BatchNorm2
I0930 20:04:50.350899  4047 net.cpp:84] Creating Layer BatchNorm2
I0930 20:04:50.350906  4047 net.cpp:406] BatchNorm2 <- Convolution2
I0930 20:04:50.350914  4047 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0930 20:04:50.351039  4047 net.cpp:122] Setting up BatchNorm2
I0930 20:04:50.351047  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.351050  4047 net.cpp:137] Memory required for data: 41082000
I0930 20:04:50.351059  4047 layer_factory.hpp:77] Creating layer Scale2
I0930 20:04:50.351069  4047 net.cpp:84] Creating Layer Scale2
I0930 20:04:50.351074  4047 net.cpp:406] Scale2 <- Convolution2
I0930 20:04:50.351081  4047 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0930 20:04:50.351116  4047 layer_factory.hpp:77] Creating layer Scale2
I0930 20:04:50.351198  4047 net.cpp:122] Setting up Scale2
I0930 20:04:50.351204  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.351208  4047 net.cpp:137] Memory required for data: 46099600
I0930 20:04:50.351219  4047 layer_factory.hpp:77] Creating layer penlu2
I0930 20:04:50.351229  4047 net.cpp:84] Creating Layer penlu2
I0930 20:04:50.351234  4047 net.cpp:406] penlu2 <- Convolution2
I0930 20:04:50.351239  4047 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0930 20:04:50.351336  4047 net.cpp:122] Setting up penlu2
I0930 20:04:50.351341  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.351346  4047 net.cpp:137] Memory required for data: 51117200
I0930 20:04:50.351349  4047 layer_factory.hpp:77] Creating layer Convolution3
I0930 20:04:50.351356  4047 net.cpp:84] Creating Layer Convolution3
I0930 20:04:50.351361  4047 net.cpp:406] Convolution3 <- Convolution2
I0930 20:04:50.351364  4047 net.cpp:380] Convolution3 -> Convolution3
I0930 20:04:50.352222  4047 net.cpp:122] Setting up Convolution3
I0930 20:04:50.352232  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.352236  4047 net.cpp:137] Memory required for data: 56134800
I0930 20:04:50.352241  4047 layer_factory.hpp:77] Creating layer BatchNorm3
I0930 20:04:50.352246  4047 net.cpp:84] Creating Layer BatchNorm3
I0930 20:04:50.352249  4047 net.cpp:406] BatchNorm3 <- Convolution3
I0930 20:04:50.352253  4047 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0930 20:04:50.352375  4047 net.cpp:122] Setting up BatchNorm3
I0930 20:04:50.352380  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.352383  4047 net.cpp:137] Memory required for data: 61152400
I0930 20:04:50.352388  4047 layer_factory.hpp:77] Creating layer Scale3
I0930 20:04:50.352393  4047 net.cpp:84] Creating Layer Scale3
I0930 20:04:50.352396  4047 net.cpp:406] Scale3 <- Convolution3
I0930 20:04:50.352401  4047 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0930 20:04:50.352424  4047 layer_factory.hpp:77] Creating layer Scale3
I0930 20:04:50.352497  4047 net.cpp:122] Setting up Scale3
I0930 20:04:50.352502  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.352505  4047 net.cpp:137] Memory required for data: 66170000
I0930 20:04:50.352509  4047 layer_factory.hpp:77] Creating layer Eltwise1
I0930 20:04:50.352514  4047 net.cpp:84] Creating Layer Eltwise1
I0930 20:04:50.352517  4047 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0930 20:04:50.352520  4047 net.cpp:406] Eltwise1 <- Convolution3
I0930 20:04:50.352524  4047 net.cpp:380] Eltwise1 -> Eltwise1
I0930 20:04:50.352541  4047 net.cpp:122] Setting up Eltwise1
I0930 20:04:50.352545  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.352548  4047 net.cpp:137] Memory required for data: 71187600
I0930 20:04:50.352550  4047 layer_factory.hpp:77] Creating layer penlu3
I0930 20:04:50.352556  4047 net.cpp:84] Creating Layer penlu3
I0930 20:04:50.352560  4047 net.cpp:406] penlu3 <- Eltwise1
I0930 20:04:50.352563  4047 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0930 20:04:50.352660  4047 net.cpp:122] Setting up penlu3
I0930 20:04:50.352666  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.352669  4047 net.cpp:137] Memory required for data: 76205200
I0930 20:04:50.352690  4047 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0930 20:04:50.352695  4047 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0930 20:04:50.352697  4047 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0930 20:04:50.352704  4047 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0930 20:04:50.352710  4047 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0930 20:04:50.352741  4047 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0930 20:04:50.352746  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.352749  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.352751  4047 net.cpp:137] Memory required for data: 86240400
I0930 20:04:50.352753  4047 layer_factory.hpp:77] Creating layer Convolution4
I0930 20:04:50.352761  4047 net.cpp:84] Creating Layer Convolution4
I0930 20:04:50.352763  4047 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0930 20:04:50.352768  4047 net.cpp:380] Convolution4 -> Convolution4
I0930 20:04:50.353627  4047 net.cpp:122] Setting up Convolution4
I0930 20:04:50.353638  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.353641  4047 net.cpp:137] Memory required for data: 91258000
I0930 20:04:50.353646  4047 layer_factory.hpp:77] Creating layer BatchNorm4
I0930 20:04:50.353652  4047 net.cpp:84] Creating Layer BatchNorm4
I0930 20:04:50.353655  4047 net.cpp:406] BatchNorm4 <- Convolution4
I0930 20:04:50.353659  4047 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0930 20:04:50.353778  4047 net.cpp:122] Setting up BatchNorm4
I0930 20:04:50.353785  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.353787  4047 net.cpp:137] Memory required for data: 96275600
I0930 20:04:50.353794  4047 layer_factory.hpp:77] Creating layer Scale4
I0930 20:04:50.353799  4047 net.cpp:84] Creating Layer Scale4
I0930 20:04:50.353802  4047 net.cpp:406] Scale4 <- Convolution4
I0930 20:04:50.353806  4047 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0930 20:04:50.353832  4047 layer_factory.hpp:77] Creating layer Scale4
I0930 20:04:50.353902  4047 net.cpp:122] Setting up Scale4
I0930 20:04:50.353907  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.353910  4047 net.cpp:137] Memory required for data: 101293200
I0930 20:04:50.353914  4047 layer_factory.hpp:77] Creating layer penlu4
I0930 20:04:50.353921  4047 net.cpp:84] Creating Layer penlu4
I0930 20:04:50.353924  4047 net.cpp:406] penlu4 <- Convolution4
I0930 20:04:50.353929  4047 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0930 20:04:50.354025  4047 net.cpp:122] Setting up penlu4
I0930 20:04:50.354032  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.354034  4047 net.cpp:137] Memory required for data: 106310800
I0930 20:04:50.354038  4047 layer_factory.hpp:77] Creating layer Convolution5
I0930 20:04:50.354046  4047 net.cpp:84] Creating Layer Convolution5
I0930 20:04:50.354049  4047 net.cpp:406] Convolution5 <- Convolution4
I0930 20:04:50.354053  4047 net.cpp:380] Convolution5 -> Convolution5
I0930 20:04:50.354943  4047 net.cpp:122] Setting up Convolution5
I0930 20:04:50.354953  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.354965  4047 net.cpp:137] Memory required for data: 111328400
I0930 20:04:50.354970  4047 layer_factory.hpp:77] Creating layer BatchNorm5
I0930 20:04:50.354974  4047 net.cpp:84] Creating Layer BatchNorm5
I0930 20:04:50.354977  4047 net.cpp:406] BatchNorm5 <- Convolution5
I0930 20:04:50.354982  4047 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0930 20:04:50.355113  4047 net.cpp:122] Setting up BatchNorm5
I0930 20:04:50.355118  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.355129  4047 net.cpp:137] Memory required for data: 116346000
I0930 20:04:50.355134  4047 layer_factory.hpp:77] Creating layer Scale5
I0930 20:04:50.355139  4047 net.cpp:84] Creating Layer Scale5
I0930 20:04:50.355141  4047 net.cpp:406] Scale5 <- Convolution5
I0930 20:04:50.355145  4047 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0930 20:04:50.355178  4047 layer_factory.hpp:77] Creating layer Scale5
I0930 20:04:50.355276  4047 net.cpp:122] Setting up Scale5
I0930 20:04:50.355283  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.355294  4047 net.cpp:137] Memory required for data: 121363600
I0930 20:04:50.355298  4047 layer_factory.hpp:77] Creating layer Eltwise2
I0930 20:04:50.355303  4047 net.cpp:84] Creating Layer Eltwise2
I0930 20:04:50.355305  4047 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0930 20:04:50.355309  4047 net.cpp:406] Eltwise2 <- Convolution5
I0930 20:04:50.355312  4047 net.cpp:380] Eltwise2 -> Eltwise2
I0930 20:04:50.355326  4047 net.cpp:122] Setting up Eltwise2
I0930 20:04:50.355332  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.355334  4047 net.cpp:137] Memory required for data: 126381200
I0930 20:04:50.355337  4047 layer_factory.hpp:77] Creating layer penlu5
I0930 20:04:50.355341  4047 net.cpp:84] Creating Layer penlu5
I0930 20:04:50.355345  4047 net.cpp:406] penlu5 <- Eltwise2
I0930 20:04:50.355350  4047 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0930 20:04:50.355449  4047 net.cpp:122] Setting up penlu5
I0930 20:04:50.355455  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.355458  4047 net.cpp:137] Memory required for data: 131398800
I0930 20:04:50.355463  4047 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0930 20:04:50.355466  4047 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0930 20:04:50.355469  4047 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0930 20:04:50.355473  4047 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0930 20:04:50.355478  4047 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0930 20:04:50.355499  4047 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0930 20:04:50.355504  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.355507  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.355510  4047 net.cpp:137] Memory required for data: 141434000
I0930 20:04:50.355512  4047 layer_factory.hpp:77] Creating layer Convolution6
I0930 20:04:50.355520  4047 net.cpp:84] Creating Layer Convolution6
I0930 20:04:50.355522  4047 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0930 20:04:50.355526  4047 net.cpp:380] Convolution6 -> Convolution6
I0930 20:04:50.356395  4047 net.cpp:122] Setting up Convolution6
I0930 20:04:50.356405  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.356408  4047 net.cpp:137] Memory required for data: 146451600
I0930 20:04:50.356412  4047 layer_factory.hpp:77] Creating layer BatchNorm6
I0930 20:04:50.356418  4047 net.cpp:84] Creating Layer BatchNorm6
I0930 20:04:50.356422  4047 net.cpp:406] BatchNorm6 <- Convolution6
I0930 20:04:50.356426  4047 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0930 20:04:50.356554  4047 net.cpp:122] Setting up BatchNorm6
I0930 20:04:50.356559  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.356561  4047 net.cpp:137] Memory required for data: 151469200
I0930 20:04:50.356566  4047 layer_factory.hpp:77] Creating layer Scale6
I0930 20:04:50.356571  4047 net.cpp:84] Creating Layer Scale6
I0930 20:04:50.356575  4047 net.cpp:406] Scale6 <- Convolution6
I0930 20:04:50.356577  4047 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0930 20:04:50.356604  4047 layer_factory.hpp:77] Creating layer Scale6
I0930 20:04:50.356678  4047 net.cpp:122] Setting up Scale6
I0930 20:04:50.356683  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.356686  4047 net.cpp:137] Memory required for data: 156486800
I0930 20:04:50.356690  4047 layer_factory.hpp:77] Creating layer penlu6
I0930 20:04:50.356696  4047 net.cpp:84] Creating Layer penlu6
I0930 20:04:50.356699  4047 net.cpp:406] penlu6 <- Convolution6
I0930 20:04:50.356703  4047 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0930 20:04:50.356804  4047 net.cpp:122] Setting up penlu6
I0930 20:04:50.356809  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.356812  4047 net.cpp:137] Memory required for data: 161504400
I0930 20:04:50.356817  4047 layer_factory.hpp:77] Creating layer Convolution7
I0930 20:04:50.356832  4047 net.cpp:84] Creating Layer Convolution7
I0930 20:04:50.356834  4047 net.cpp:406] Convolution7 <- Convolution6
I0930 20:04:50.356839  4047 net.cpp:380] Convolution7 -> Convolution7
I0930 20:04:50.357383  4047 net.cpp:122] Setting up Convolution7
I0930 20:04:50.357391  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.357395  4047 net.cpp:137] Memory required for data: 166522000
I0930 20:04:50.357399  4047 layer_factory.hpp:77] Creating layer BatchNorm7
I0930 20:04:50.357405  4047 net.cpp:84] Creating Layer BatchNorm7
I0930 20:04:50.357409  4047 net.cpp:406] BatchNorm7 <- Convolution7
I0930 20:04:50.357414  4047 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0930 20:04:50.357537  4047 net.cpp:122] Setting up BatchNorm7
I0930 20:04:50.357542  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.357544  4047 net.cpp:137] Memory required for data: 171539600
I0930 20:04:50.357554  4047 layer_factory.hpp:77] Creating layer Scale7
I0930 20:04:50.357563  4047 net.cpp:84] Creating Layer Scale7
I0930 20:04:50.357566  4047 net.cpp:406] Scale7 <- Convolution7
I0930 20:04:50.357569  4047 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0930 20:04:50.357594  4047 layer_factory.hpp:77] Creating layer Scale7
I0930 20:04:50.357667  4047 net.cpp:122] Setting up Scale7
I0930 20:04:50.357672  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.357676  4047 net.cpp:137] Memory required for data: 176557200
I0930 20:04:50.357679  4047 layer_factory.hpp:77] Creating layer Eltwise3
I0930 20:04:50.357683  4047 net.cpp:84] Creating Layer Eltwise3
I0930 20:04:50.357687  4047 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0930 20:04:50.357689  4047 net.cpp:406] Eltwise3 <- Convolution7
I0930 20:04:50.357693  4047 net.cpp:380] Eltwise3 -> Eltwise3
I0930 20:04:50.357708  4047 net.cpp:122] Setting up Eltwise3
I0930 20:04:50.357712  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.357715  4047 net.cpp:137] Memory required for data: 181574800
I0930 20:04:50.357717  4047 layer_factory.hpp:77] Creating layer penlu7
I0930 20:04:50.357722  4047 net.cpp:84] Creating Layer penlu7
I0930 20:04:50.357725  4047 net.cpp:406] penlu7 <- Eltwise3
I0930 20:04:50.357729  4047 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0930 20:04:50.357831  4047 net.cpp:122] Setting up penlu7
I0930 20:04:50.357836  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.357838  4047 net.cpp:137] Memory required for data: 186592400
I0930 20:04:50.357843  4047 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0930 20:04:50.357847  4047 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0930 20:04:50.357851  4047 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0930 20:04:50.357853  4047 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0930 20:04:50.357858  4047 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0930 20:04:50.357880  4047 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0930 20:04:50.357884  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.357888  4047 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:04:50.357890  4047 net.cpp:137] Memory required for data: 196627600
I0930 20:04:50.357892  4047 layer_factory.hpp:77] Creating layer Convolution8
I0930 20:04:50.357899  4047 net.cpp:84] Creating Layer Convolution8
I0930 20:04:50.357903  4047 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0930 20:04:50.357906  4047 net.cpp:380] Convolution8 -> Convolution8
I0930 20:04:50.359071  4047 net.cpp:122] Setting up Convolution8
I0930 20:04:50.359081  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.359084  4047 net.cpp:137] Memory required for data: 199136400
I0930 20:04:50.359099  4047 layer_factory.hpp:77] Creating layer BatchNorm8
I0930 20:04:50.359105  4047 net.cpp:84] Creating Layer BatchNorm8
I0930 20:04:50.359109  4047 net.cpp:406] BatchNorm8 <- Convolution8
I0930 20:04:50.359113  4047 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0930 20:04:50.359261  4047 net.cpp:122] Setting up BatchNorm8
I0930 20:04:50.359266  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.359268  4047 net.cpp:137] Memory required for data: 201645200
I0930 20:04:50.359273  4047 layer_factory.hpp:77] Creating layer Scale8
I0930 20:04:50.359280  4047 net.cpp:84] Creating Layer Scale8
I0930 20:04:50.359285  4047 net.cpp:406] Scale8 <- Convolution8
I0930 20:04:50.359292  4047 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0930 20:04:50.359329  4047 layer_factory.hpp:77] Creating layer Scale8
I0930 20:04:50.359431  4047 net.cpp:122] Setting up Scale8
I0930 20:04:50.359441  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.359446  4047 net.cpp:137] Memory required for data: 204154000
I0930 20:04:50.359453  4047 layer_factory.hpp:77] Creating layer Convolution9
I0930 20:04:50.359464  4047 net.cpp:84] Creating Layer Convolution9
I0930 20:04:50.359470  4047 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I0930 20:04:50.359477  4047 net.cpp:380] Convolution9 -> Convolution9
I0930 20:04:50.361203  4047 net.cpp:122] Setting up Convolution9
I0930 20:04:50.361215  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.361218  4047 net.cpp:137] Memory required for data: 206662800
I0930 20:04:50.361224  4047 layer_factory.hpp:77] Creating layer BatchNorm9
I0930 20:04:50.361230  4047 net.cpp:84] Creating Layer BatchNorm9
I0930 20:04:50.361234  4047 net.cpp:406] BatchNorm9 <- Convolution9
I0930 20:04:50.361238  4047 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0930 20:04:50.361379  4047 net.cpp:122] Setting up BatchNorm9
I0930 20:04:50.361384  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.361387  4047 net.cpp:137] Memory required for data: 209171600
I0930 20:04:50.361392  4047 layer_factory.hpp:77] Creating layer Scale9
I0930 20:04:50.361397  4047 net.cpp:84] Creating Layer Scale9
I0930 20:04:50.361402  4047 net.cpp:406] Scale9 <- Convolution9
I0930 20:04:50.361404  4047 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0930 20:04:50.361430  4047 layer_factory.hpp:77] Creating layer Scale9
I0930 20:04:50.361505  4047 net.cpp:122] Setting up Scale9
I0930 20:04:50.361510  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.361512  4047 net.cpp:137] Memory required for data: 211680400
I0930 20:04:50.361516  4047 layer_factory.hpp:77] Creating layer penlu8
I0930 20:04:50.361521  4047 net.cpp:84] Creating Layer penlu8
I0930 20:04:50.361526  4047 net.cpp:406] penlu8 <- Convolution9
I0930 20:04:50.361529  4047 net.cpp:367] penlu8 -> Convolution9 (in-place)
I0930 20:04:50.361632  4047 net.cpp:122] Setting up penlu8
I0930 20:04:50.361637  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.361640  4047 net.cpp:137] Memory required for data: 214189200
I0930 20:04:50.361644  4047 layer_factory.hpp:77] Creating layer Convolution10
I0930 20:04:50.361652  4047 net.cpp:84] Creating Layer Convolution10
I0930 20:04:50.361655  4047 net.cpp:406] Convolution10 <- Convolution9
I0930 20:04:50.361660  4047 net.cpp:380] Convolution10 -> Convolution10
I0930 20:04:50.362869  4047 net.cpp:122] Setting up Convolution10
I0930 20:04:50.362880  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.362884  4047 net.cpp:137] Memory required for data: 216698000
I0930 20:04:50.362887  4047 layer_factory.hpp:77] Creating layer BatchNorm10
I0930 20:04:50.362895  4047 net.cpp:84] Creating Layer BatchNorm10
I0930 20:04:50.362898  4047 net.cpp:406] BatchNorm10 <- Convolution10
I0930 20:04:50.362901  4047 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0930 20:04:50.363032  4047 net.cpp:122] Setting up BatchNorm10
I0930 20:04:50.363037  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.363040  4047 net.cpp:137] Memory required for data: 219206800
I0930 20:04:50.363045  4047 layer_factory.hpp:77] Creating layer Scale10
I0930 20:04:50.363050  4047 net.cpp:84] Creating Layer Scale10
I0930 20:04:50.363054  4047 net.cpp:406] Scale10 <- Convolution10
I0930 20:04:50.363057  4047 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0930 20:04:50.363095  4047 layer_factory.hpp:77] Creating layer Scale10
I0930 20:04:50.363169  4047 net.cpp:122] Setting up Scale10
I0930 20:04:50.363175  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.363178  4047 net.cpp:137] Memory required for data: 221715600
I0930 20:04:50.363183  4047 layer_factory.hpp:77] Creating layer Eltwise4
I0930 20:04:50.363186  4047 net.cpp:84] Creating Layer Eltwise4
I0930 20:04:50.363190  4047 net.cpp:406] Eltwise4 <- Convolution8
I0930 20:04:50.363193  4047 net.cpp:406] Eltwise4 <- Convolution10
I0930 20:04:50.363198  4047 net.cpp:380] Eltwise4 -> Eltwise4
I0930 20:04:50.363214  4047 net.cpp:122] Setting up Eltwise4
I0930 20:04:50.363219  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.363221  4047 net.cpp:137] Memory required for data: 224224400
I0930 20:04:50.363224  4047 layer_factory.hpp:77] Creating layer penlu9
I0930 20:04:50.363229  4047 net.cpp:84] Creating Layer penlu9
I0930 20:04:50.363232  4047 net.cpp:406] penlu9 <- Eltwise4
I0930 20:04:50.363237  4047 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0930 20:04:50.363342  4047 net.cpp:122] Setting up penlu9
I0930 20:04:50.363346  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.363349  4047 net.cpp:137] Memory required for data: 226733200
I0930 20:04:50.363354  4047 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0930 20:04:50.363359  4047 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0930 20:04:50.363363  4047 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0930 20:04:50.363365  4047 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0930 20:04:50.363370  4047 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0930 20:04:50.363392  4047 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0930 20:04:50.363397  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.363401  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.363404  4047 net.cpp:137] Memory required for data: 231750800
I0930 20:04:50.363406  4047 layer_factory.hpp:77] Creating layer Convolution11
I0930 20:04:50.363412  4047 net.cpp:84] Creating Layer Convolution11
I0930 20:04:50.363415  4047 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I0930 20:04:50.363420  4047 net.cpp:380] Convolution11 -> Convolution11
I0930 20:04:50.364482  4047 net.cpp:122] Setting up Convolution11
I0930 20:04:50.364492  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.364496  4047 net.cpp:137] Memory required for data: 234259600
I0930 20:04:50.364500  4047 layer_factory.hpp:77] Creating layer BatchNorm11
I0930 20:04:50.364507  4047 net.cpp:84] Creating Layer BatchNorm11
I0930 20:04:50.364511  4047 net.cpp:406] BatchNorm11 <- Convolution11
I0930 20:04:50.364514  4047 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0930 20:04:50.364645  4047 net.cpp:122] Setting up BatchNorm11
I0930 20:04:50.364651  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.364655  4047 net.cpp:137] Memory required for data: 236768400
I0930 20:04:50.364660  4047 layer_factory.hpp:77] Creating layer Scale11
I0930 20:04:50.364665  4047 net.cpp:84] Creating Layer Scale11
I0930 20:04:50.364667  4047 net.cpp:406] Scale11 <- Convolution11
I0930 20:04:50.364670  4047 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0930 20:04:50.364698  4047 layer_factory.hpp:77] Creating layer Scale11
I0930 20:04:50.364774  4047 net.cpp:122] Setting up Scale11
I0930 20:04:50.364781  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.364784  4047 net.cpp:137] Memory required for data: 239277200
I0930 20:04:50.364789  4047 layer_factory.hpp:77] Creating layer penlu10
I0930 20:04:50.364794  4047 net.cpp:84] Creating Layer penlu10
I0930 20:04:50.364796  4047 net.cpp:406] penlu10 <- Convolution11
I0930 20:04:50.364801  4047 net.cpp:367] penlu10 -> Convolution11 (in-place)
I0930 20:04:50.364907  4047 net.cpp:122] Setting up penlu10
I0930 20:04:50.364912  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.364922  4047 net.cpp:137] Memory required for data: 241786000
I0930 20:04:50.364926  4047 layer_factory.hpp:77] Creating layer Convolution12
I0930 20:04:50.364934  4047 net.cpp:84] Creating Layer Convolution12
I0930 20:04:50.364938  4047 net.cpp:406] Convolution12 <- Convolution11
I0930 20:04:50.364943  4047 net.cpp:380] Convolution12 -> Convolution12
I0930 20:04:50.366004  4047 net.cpp:122] Setting up Convolution12
I0930 20:04:50.366015  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.366019  4047 net.cpp:137] Memory required for data: 244294800
I0930 20:04:50.366024  4047 layer_factory.hpp:77] Creating layer BatchNorm12
I0930 20:04:50.366030  4047 net.cpp:84] Creating Layer BatchNorm12
I0930 20:04:50.366034  4047 net.cpp:406] BatchNorm12 <- Convolution12
I0930 20:04:50.366037  4047 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0930 20:04:50.366168  4047 net.cpp:122] Setting up BatchNorm12
I0930 20:04:50.366173  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.366176  4047 net.cpp:137] Memory required for data: 246803600
I0930 20:04:50.366181  4047 layer_factory.hpp:77] Creating layer Scale12
I0930 20:04:50.366186  4047 net.cpp:84] Creating Layer Scale12
I0930 20:04:50.366189  4047 net.cpp:406] Scale12 <- Convolution12
I0930 20:04:50.366192  4047 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0930 20:04:50.366219  4047 layer_factory.hpp:77] Creating layer Scale12
I0930 20:04:50.366295  4047 net.cpp:122] Setting up Scale12
I0930 20:04:50.366300  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.366303  4047 net.cpp:137] Memory required for data: 249312400
I0930 20:04:50.366307  4047 layer_factory.hpp:77] Creating layer Eltwise5
I0930 20:04:50.366312  4047 net.cpp:84] Creating Layer Eltwise5
I0930 20:04:50.366315  4047 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0930 20:04:50.366318  4047 net.cpp:406] Eltwise5 <- Convolution12
I0930 20:04:50.366323  4047 net.cpp:380] Eltwise5 -> Eltwise5
I0930 20:04:50.366338  4047 net.cpp:122] Setting up Eltwise5
I0930 20:04:50.366343  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.366345  4047 net.cpp:137] Memory required for data: 251821200
I0930 20:04:50.366348  4047 layer_factory.hpp:77] Creating layer penlu11
I0930 20:04:50.366354  4047 net.cpp:84] Creating Layer penlu11
I0930 20:04:50.366358  4047 net.cpp:406] penlu11 <- Eltwise5
I0930 20:04:50.366361  4047 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0930 20:04:50.366467  4047 net.cpp:122] Setting up penlu11
I0930 20:04:50.366473  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.366477  4047 net.cpp:137] Memory required for data: 254330000
I0930 20:04:50.366480  4047 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0930 20:04:50.366484  4047 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0930 20:04:50.366487  4047 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0930 20:04:50.366492  4047 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0930 20:04:50.366497  4047 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0930 20:04:50.366525  4047 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0930 20:04:50.366533  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.366539  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.366541  4047 net.cpp:137] Memory required for data: 259347600
I0930 20:04:50.366544  4047 layer_factory.hpp:77] Creating layer Convolution13
I0930 20:04:50.366551  4047 net.cpp:84] Creating Layer Convolution13
I0930 20:04:50.366555  4047 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I0930 20:04:50.366559  4047 net.cpp:380] Convolution13 -> Convolution13
I0930 20:04:50.367625  4047 net.cpp:122] Setting up Convolution13
I0930 20:04:50.367635  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.367640  4047 net.cpp:137] Memory required for data: 261856400
I0930 20:04:50.367645  4047 layer_factory.hpp:77] Creating layer BatchNorm13
I0930 20:04:50.367650  4047 net.cpp:84] Creating Layer BatchNorm13
I0930 20:04:50.367660  4047 net.cpp:406] BatchNorm13 <- Convolution13
I0930 20:04:50.367666  4047 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0930 20:04:50.367800  4047 net.cpp:122] Setting up BatchNorm13
I0930 20:04:50.367805  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.367808  4047 net.cpp:137] Memory required for data: 264365200
I0930 20:04:50.367815  4047 layer_factory.hpp:77] Creating layer Scale13
I0930 20:04:50.367818  4047 net.cpp:84] Creating Layer Scale13
I0930 20:04:50.367822  4047 net.cpp:406] Scale13 <- Convolution13
I0930 20:04:50.367825  4047 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0930 20:04:50.367853  4047 layer_factory.hpp:77] Creating layer Scale13
I0930 20:04:50.367929  4047 net.cpp:122] Setting up Scale13
I0930 20:04:50.367935  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.367938  4047 net.cpp:137] Memory required for data: 266874000
I0930 20:04:50.367943  4047 layer_factory.hpp:77] Creating layer penlu12
I0930 20:04:50.367949  4047 net.cpp:84] Creating Layer penlu12
I0930 20:04:50.367951  4047 net.cpp:406] penlu12 <- Convolution13
I0930 20:04:50.367955  4047 net.cpp:367] penlu12 -> Convolution13 (in-place)
I0930 20:04:50.368060  4047 net.cpp:122] Setting up penlu12
I0930 20:04:50.368065  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.368068  4047 net.cpp:137] Memory required for data: 269382800
I0930 20:04:50.368073  4047 layer_factory.hpp:77] Creating layer Convolution14
I0930 20:04:50.368082  4047 net.cpp:84] Creating Layer Convolution14
I0930 20:04:50.368084  4047 net.cpp:406] Convolution14 <- Convolution13
I0930 20:04:50.368088  4047 net.cpp:380] Convolution14 -> Convolution14
I0930 20:04:50.369158  4047 net.cpp:122] Setting up Convolution14
I0930 20:04:50.369169  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.369173  4047 net.cpp:137] Memory required for data: 271891600
I0930 20:04:50.369189  4047 layer_factory.hpp:77] Creating layer BatchNorm14
I0930 20:04:50.369199  4047 net.cpp:84] Creating Layer BatchNorm14
I0930 20:04:50.369202  4047 net.cpp:406] BatchNorm14 <- Convolution14
I0930 20:04:50.369206  4047 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0930 20:04:50.369340  4047 net.cpp:122] Setting up BatchNorm14
I0930 20:04:50.369346  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.369349  4047 net.cpp:137] Memory required for data: 274400400
I0930 20:04:50.369354  4047 layer_factory.hpp:77] Creating layer Scale14
I0930 20:04:50.369359  4047 net.cpp:84] Creating Layer Scale14
I0930 20:04:50.369364  4047 net.cpp:406] Scale14 <- Convolution14
I0930 20:04:50.369366  4047 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0930 20:04:50.369395  4047 layer_factory.hpp:77] Creating layer Scale14
I0930 20:04:50.369470  4047 net.cpp:122] Setting up Scale14
I0930 20:04:50.369475  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.369478  4047 net.cpp:137] Memory required for data: 276909200
I0930 20:04:50.369482  4047 layer_factory.hpp:77] Creating layer Eltwise6
I0930 20:04:50.369488  4047 net.cpp:84] Creating Layer Eltwise6
I0930 20:04:50.369489  4047 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0930 20:04:50.369493  4047 net.cpp:406] Eltwise6 <- Convolution14
I0930 20:04:50.369495  4047 net.cpp:380] Eltwise6 -> Eltwise6
I0930 20:04:50.369511  4047 net.cpp:122] Setting up Eltwise6
I0930 20:04:50.369515  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.369518  4047 net.cpp:137] Memory required for data: 279418000
I0930 20:04:50.369519  4047 layer_factory.hpp:77] Creating layer penlu13
I0930 20:04:50.369525  4047 net.cpp:84] Creating Layer penlu13
I0930 20:04:50.369527  4047 net.cpp:406] penlu13 <- Eltwise6
I0930 20:04:50.369530  4047 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0930 20:04:50.369635  4047 net.cpp:122] Setting up penlu13
I0930 20:04:50.369640  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.369642  4047 net.cpp:137] Memory required for data: 281926800
I0930 20:04:50.369647  4047 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0930 20:04:50.369657  4047 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0930 20:04:50.369658  4047 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0930 20:04:50.369663  4047 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0930 20:04:50.369668  4047 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0930 20:04:50.369689  4047 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0930 20:04:50.369694  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.369698  4047 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:04:50.369699  4047 net.cpp:137] Memory required for data: 286944400
I0930 20:04:50.369701  4047 layer_factory.hpp:77] Creating layer Convolution15
I0930 20:04:50.369707  4047 net.cpp:84] Creating Layer Convolution15
I0930 20:04:50.369709  4047 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I0930 20:04:50.369714  4047 net.cpp:380] Convolution15 -> Convolution15
I0930 20:04:50.370627  4047 net.cpp:122] Setting up Convolution15
I0930 20:04:50.370637  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.370640  4047 net.cpp:137] Memory required for data: 288198800
I0930 20:04:50.370645  4047 layer_factory.hpp:77] Creating layer BatchNorm15
I0930 20:04:50.370649  4047 net.cpp:84] Creating Layer BatchNorm15
I0930 20:04:50.370652  4047 net.cpp:406] BatchNorm15 <- Convolution15
I0930 20:04:50.370656  4047 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0930 20:04:50.370787  4047 net.cpp:122] Setting up BatchNorm15
I0930 20:04:50.370791  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.370795  4047 net.cpp:137] Memory required for data: 289453200
I0930 20:04:50.370798  4047 layer_factory.hpp:77] Creating layer Scale15
I0930 20:04:50.370802  4047 net.cpp:84] Creating Layer Scale15
I0930 20:04:50.370805  4047 net.cpp:406] Scale15 <- Convolution15
I0930 20:04:50.370808  4047 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0930 20:04:50.370836  4047 layer_factory.hpp:77] Creating layer Scale15
I0930 20:04:50.370911  4047 net.cpp:122] Setting up Scale15
I0930 20:04:50.370915  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.370918  4047 net.cpp:137] Memory required for data: 290707600
I0930 20:04:50.370921  4047 layer_factory.hpp:77] Creating layer Convolution16
I0930 20:04:50.370929  4047 net.cpp:84] Creating Layer Convolution16
I0930 20:04:50.370931  4047 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I0930 20:04:50.370935  4047 net.cpp:380] Convolution16 -> Convolution16
I0930 20:04:50.372716  4047 net.cpp:122] Setting up Convolution16
I0930 20:04:50.372725  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.372728  4047 net.cpp:137] Memory required for data: 291962000
I0930 20:04:50.372733  4047 layer_factory.hpp:77] Creating layer BatchNorm16
I0930 20:04:50.372740  4047 net.cpp:84] Creating Layer BatchNorm16
I0930 20:04:50.372741  4047 net.cpp:406] BatchNorm16 <- Convolution16
I0930 20:04:50.372745  4047 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0930 20:04:50.372876  4047 net.cpp:122] Setting up BatchNorm16
I0930 20:04:50.372881  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.372884  4047 net.cpp:137] Memory required for data: 293216400
I0930 20:04:50.372889  4047 layer_factory.hpp:77] Creating layer Scale16
I0930 20:04:50.372892  4047 net.cpp:84] Creating Layer Scale16
I0930 20:04:50.372895  4047 net.cpp:406] Scale16 <- Convolution16
I0930 20:04:50.372897  4047 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0930 20:04:50.372925  4047 layer_factory.hpp:77] Creating layer Scale16
I0930 20:04:50.372997  4047 net.cpp:122] Setting up Scale16
I0930 20:04:50.373003  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.373004  4047 net.cpp:137] Memory required for data: 294470800
I0930 20:04:50.373008  4047 layer_factory.hpp:77] Creating layer penlu14
I0930 20:04:50.373013  4047 net.cpp:84] Creating Layer penlu14
I0930 20:04:50.373015  4047 net.cpp:406] penlu14 <- Convolution16
I0930 20:04:50.373019  4047 net.cpp:367] penlu14 -> Convolution16 (in-place)
I0930 20:04:50.373131  4047 net.cpp:122] Setting up penlu14
I0930 20:04:50.373136  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.373137  4047 net.cpp:137] Memory required for data: 295725200
I0930 20:04:50.373142  4047 layer_factory.hpp:77] Creating layer Convolution17
I0930 20:04:50.373148  4047 net.cpp:84] Creating Layer Convolution17
I0930 20:04:50.373150  4047 net.cpp:406] Convolution17 <- Convolution16
I0930 20:04:50.373154  4047 net.cpp:380] Convolution17 -> Convolution17
I0930 20:04:50.374804  4047 net.cpp:122] Setting up Convolution17
I0930 20:04:50.374814  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.374815  4047 net.cpp:137] Memory required for data: 296979600
I0930 20:04:50.374821  4047 layer_factory.hpp:77] Creating layer BatchNorm17
I0930 20:04:50.374826  4047 net.cpp:84] Creating Layer BatchNorm17
I0930 20:04:50.374830  4047 net.cpp:406] BatchNorm17 <- Convolution17
I0930 20:04:50.374832  4047 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0930 20:04:50.374966  4047 net.cpp:122] Setting up BatchNorm17
I0930 20:04:50.374970  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.374974  4047 net.cpp:137] Memory required for data: 298234000
I0930 20:04:50.374977  4047 layer_factory.hpp:77] Creating layer Scale17
I0930 20:04:50.374981  4047 net.cpp:84] Creating Layer Scale17
I0930 20:04:50.374984  4047 net.cpp:406] Scale17 <- Convolution17
I0930 20:04:50.374987  4047 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0930 20:04:50.375013  4047 layer_factory.hpp:77] Creating layer Scale17
I0930 20:04:50.375092  4047 net.cpp:122] Setting up Scale17
I0930 20:04:50.375097  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.375098  4047 net.cpp:137] Memory required for data: 299488400
I0930 20:04:50.375102  4047 layer_factory.hpp:77] Creating layer Eltwise7
I0930 20:04:50.375107  4047 net.cpp:84] Creating Layer Eltwise7
I0930 20:04:50.375109  4047 net.cpp:406] Eltwise7 <- Convolution15
I0930 20:04:50.375113  4047 net.cpp:406] Eltwise7 <- Convolution17
I0930 20:04:50.375115  4047 net.cpp:380] Eltwise7 -> Eltwise7
I0930 20:04:50.375130  4047 net.cpp:122] Setting up Eltwise7
I0930 20:04:50.375133  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.375135  4047 net.cpp:137] Memory required for data: 300742800
I0930 20:04:50.375138  4047 layer_factory.hpp:77] Creating layer penlu15
I0930 20:04:50.375144  4047 net.cpp:84] Creating Layer penlu15
I0930 20:04:50.375145  4047 net.cpp:406] penlu15 <- Eltwise7
I0930 20:04:50.375149  4047 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0930 20:04:50.375300  4047 net.cpp:122] Setting up penlu15
I0930 20:04:50.375308  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.375313  4047 net.cpp:137] Memory required for data: 301997200
I0930 20:04:50.375320  4047 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0930 20:04:50.375326  4047 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0930 20:04:50.375339  4047 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0930 20:04:50.375345  4047 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0930 20:04:50.375351  4047 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0930 20:04:50.375381  4047 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0930 20:04:50.375387  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.375392  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.375396  4047 net.cpp:137] Memory required for data: 304506000
I0930 20:04:50.375399  4047 layer_factory.hpp:77] Creating layer Convolution18
I0930 20:04:50.375407  4047 net.cpp:84] Creating Layer Convolution18
I0930 20:04:50.375411  4047 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I0930 20:04:50.375418  4047 net.cpp:380] Convolution18 -> Convolution18
I0930 20:04:50.377751  4047 net.cpp:122] Setting up Convolution18
I0930 20:04:50.377763  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.377768  4047 net.cpp:137] Memory required for data: 305760400
I0930 20:04:50.377784  4047 layer_factory.hpp:77] Creating layer BatchNorm18
I0930 20:04:50.377792  4047 net.cpp:84] Creating Layer BatchNorm18
I0930 20:04:50.377797  4047 net.cpp:406] BatchNorm18 <- Convolution18
I0930 20:04:50.377804  4047 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0930 20:04:50.378046  4047 net.cpp:122] Setting up BatchNorm18
I0930 20:04:50.378063  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.378067  4047 net.cpp:137] Memory required for data: 307014800
I0930 20:04:50.378075  4047 layer_factory.hpp:77] Creating layer Scale18
I0930 20:04:50.378082  4047 net.cpp:84] Creating Layer Scale18
I0930 20:04:50.378087  4047 net.cpp:406] Scale18 <- Convolution18
I0930 20:04:50.378092  4047 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0930 20:04:50.378135  4047 layer_factory.hpp:77] Creating layer Scale18
I0930 20:04:50.378232  4047 net.cpp:122] Setting up Scale18
I0930 20:04:50.378238  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.378240  4047 net.cpp:137] Memory required for data: 308269200
I0930 20:04:50.378244  4047 layer_factory.hpp:77] Creating layer penlu16
I0930 20:04:50.378250  4047 net.cpp:84] Creating Layer penlu16
I0930 20:04:50.378253  4047 net.cpp:406] penlu16 <- Convolution18
I0930 20:04:50.378257  4047 net.cpp:367] penlu16 -> Convolution18 (in-place)
I0930 20:04:50.378363  4047 net.cpp:122] Setting up penlu16
I0930 20:04:50.378367  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.378370  4047 net.cpp:137] Memory required for data: 309523600
I0930 20:04:50.378373  4047 layer_factory.hpp:77] Creating layer Convolution19
I0930 20:04:50.378381  4047 net.cpp:84] Creating Layer Convolution19
I0930 20:04:50.378382  4047 net.cpp:406] Convolution19 <- Convolution18
I0930 20:04:50.378386  4047 net.cpp:380] Convolution19 -> Convolution19
I0930 20:04:50.380489  4047 net.cpp:122] Setting up Convolution19
I0930 20:04:50.380501  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.380513  4047 net.cpp:137] Memory required for data: 310778000
I0930 20:04:50.380519  4047 layer_factory.hpp:77] Creating layer BatchNorm19
I0930 20:04:50.380525  4047 net.cpp:84] Creating Layer BatchNorm19
I0930 20:04:50.380528  4047 net.cpp:406] BatchNorm19 <- Convolution19
I0930 20:04:50.380533  4047 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0930 20:04:50.380686  4047 net.cpp:122] Setting up BatchNorm19
I0930 20:04:50.380690  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.380693  4047 net.cpp:137] Memory required for data: 312032400
I0930 20:04:50.380697  4047 layer_factory.hpp:77] Creating layer Scale19
I0930 20:04:50.380702  4047 net.cpp:84] Creating Layer Scale19
I0930 20:04:50.380705  4047 net.cpp:406] Scale19 <- Convolution19
I0930 20:04:50.380708  4047 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0930 20:04:50.380733  4047 layer_factory.hpp:77] Creating layer Scale19
I0930 20:04:50.380810  4047 net.cpp:122] Setting up Scale19
I0930 20:04:50.380815  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.380817  4047 net.cpp:137] Memory required for data: 313286800
I0930 20:04:50.380820  4047 layer_factory.hpp:77] Creating layer Eltwise8
I0930 20:04:50.380825  4047 net.cpp:84] Creating Layer Eltwise8
I0930 20:04:50.380828  4047 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0930 20:04:50.380831  4047 net.cpp:406] Eltwise8 <- Convolution19
I0930 20:04:50.380836  4047 net.cpp:380] Eltwise8 -> Eltwise8
I0930 20:04:50.380851  4047 net.cpp:122] Setting up Eltwise8
I0930 20:04:50.380854  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.380856  4047 net.cpp:137] Memory required for data: 314541200
I0930 20:04:50.380858  4047 layer_factory.hpp:77] Creating layer penlu17
I0930 20:04:50.380863  4047 net.cpp:84] Creating Layer penlu17
I0930 20:04:50.380867  4047 net.cpp:406] penlu17 <- Eltwise8
I0930 20:04:50.380870  4047 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0930 20:04:50.380973  4047 net.cpp:122] Setting up penlu17
I0930 20:04:50.380978  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.380988  4047 net.cpp:137] Memory required for data: 315795600
I0930 20:04:50.380993  4047 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0930 20:04:50.380997  4047 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0930 20:04:50.381000  4047 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0930 20:04:50.381003  4047 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0930 20:04:50.381009  4047 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0930 20:04:50.381032  4047 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0930 20:04:50.381036  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.381039  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.381042  4047 net.cpp:137] Memory required for data: 318304400
I0930 20:04:50.381043  4047 layer_factory.hpp:77] Creating layer Convolution20
I0930 20:04:50.381050  4047 net.cpp:84] Creating Layer Convolution20
I0930 20:04:50.381053  4047 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I0930 20:04:50.381057  4047 net.cpp:380] Convolution20 -> Convolution20
I0930 20:04:50.382694  4047 net.cpp:122] Setting up Convolution20
I0930 20:04:50.382704  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.382706  4047 net.cpp:137] Memory required for data: 319558800
I0930 20:04:50.382711  4047 layer_factory.hpp:77] Creating layer BatchNorm20
I0930 20:04:50.382717  4047 net.cpp:84] Creating Layer BatchNorm20
I0930 20:04:50.382721  4047 net.cpp:406] BatchNorm20 <- Convolution20
I0930 20:04:50.382725  4047 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0930 20:04:50.382855  4047 net.cpp:122] Setting up BatchNorm20
I0930 20:04:50.382860  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.382863  4047 net.cpp:137] Memory required for data: 320813200
I0930 20:04:50.382866  4047 layer_factory.hpp:77] Creating layer Scale20
I0930 20:04:50.382874  4047 net.cpp:84] Creating Layer Scale20
I0930 20:04:50.382876  4047 net.cpp:406] Scale20 <- Convolution20
I0930 20:04:50.382879  4047 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0930 20:04:50.382906  4047 layer_factory.hpp:77] Creating layer Scale20
I0930 20:04:50.382980  4047 net.cpp:122] Setting up Scale20
I0930 20:04:50.382985  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.382988  4047 net.cpp:137] Memory required for data: 322067600
I0930 20:04:50.382992  4047 layer_factory.hpp:77] Creating layer penlu18
I0930 20:04:50.382998  4047 net.cpp:84] Creating Layer penlu18
I0930 20:04:50.383002  4047 net.cpp:406] penlu18 <- Convolution20
I0930 20:04:50.383005  4047 net.cpp:367] penlu18 -> Convolution20 (in-place)
I0930 20:04:50.383108  4047 net.cpp:122] Setting up penlu18
I0930 20:04:50.383112  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.383114  4047 net.cpp:137] Memory required for data: 323322000
I0930 20:04:50.383118  4047 layer_factory.hpp:77] Creating layer Convolution21
I0930 20:04:50.383124  4047 net.cpp:84] Creating Layer Convolution21
I0930 20:04:50.383127  4047 net.cpp:406] Convolution21 <- Convolution20
I0930 20:04:50.383131  4047 net.cpp:380] Convolution21 -> Convolution21
I0930 20:04:50.385355  4047 net.cpp:122] Setting up Convolution21
I0930 20:04:50.385363  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.385366  4047 net.cpp:137] Memory required for data: 324576400
I0930 20:04:50.385371  4047 layer_factory.hpp:77] Creating layer BatchNorm21
I0930 20:04:50.385376  4047 net.cpp:84] Creating Layer BatchNorm21
I0930 20:04:50.385380  4047 net.cpp:406] BatchNorm21 <- Convolution21
I0930 20:04:50.385383  4047 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0930 20:04:50.385514  4047 net.cpp:122] Setting up BatchNorm21
I0930 20:04:50.385519  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.385520  4047 net.cpp:137] Memory required for data: 325830800
I0930 20:04:50.385525  4047 layer_factory.hpp:77] Creating layer Scale21
I0930 20:04:50.385530  4047 net.cpp:84] Creating Layer Scale21
I0930 20:04:50.385532  4047 net.cpp:406] Scale21 <- Convolution21
I0930 20:04:50.385541  4047 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0930 20:04:50.385570  4047 layer_factory.hpp:77] Creating layer Scale21
I0930 20:04:50.385646  4047 net.cpp:122] Setting up Scale21
I0930 20:04:50.385650  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.385653  4047 net.cpp:137] Memory required for data: 327085200
I0930 20:04:50.385656  4047 layer_factory.hpp:77] Creating layer Eltwise9
I0930 20:04:50.385660  4047 net.cpp:84] Creating Layer Eltwise9
I0930 20:04:50.385663  4047 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0930 20:04:50.385665  4047 net.cpp:406] Eltwise9 <- Convolution21
I0930 20:04:50.385669  4047 net.cpp:380] Eltwise9 -> Eltwise9
I0930 20:04:50.385684  4047 net.cpp:122] Setting up Eltwise9
I0930 20:04:50.385687  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.385689  4047 net.cpp:137] Memory required for data: 328339600
I0930 20:04:50.385691  4047 layer_factory.hpp:77] Creating layer penlu19
I0930 20:04:50.385696  4047 net.cpp:84] Creating Layer penlu19
I0930 20:04:50.385699  4047 net.cpp:406] penlu19 <- Eltwise9
I0930 20:04:50.385701  4047 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0930 20:04:50.385807  4047 net.cpp:122] Setting up penlu19
I0930 20:04:50.385812  4047 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:04:50.385814  4047 net.cpp:137] Memory required for data: 329594000
I0930 20:04:50.385818  4047 layer_factory.hpp:77] Creating layer Pooling1
I0930 20:04:50.385823  4047 net.cpp:84] Creating Layer Pooling1
I0930 20:04:50.385825  4047 net.cpp:406] Pooling1 <- Eltwise9
I0930 20:04:50.385828  4047 net.cpp:380] Pooling1 -> Pooling1
I0930 20:04:50.385972  4047 net.cpp:122] Setting up Pooling1
I0930 20:04:50.385978  4047 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0930 20:04:50.385982  4047 net.cpp:137] Memory required for data: 329619600
I0930 20:04:50.385983  4047 layer_factory.hpp:77] Creating layer InnerProduct1
I0930 20:04:50.385993  4047 net.cpp:84] Creating Layer InnerProduct1
I0930 20:04:50.385994  4047 net.cpp:406] InnerProduct1 <- Pooling1
I0930 20:04:50.385999  4047 net.cpp:380] InnerProduct1 -> InnerProduct1
I0930 20:04:50.386091  4047 net.cpp:122] Setting up InnerProduct1
I0930 20:04:50.386096  4047 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:04:50.386098  4047 net.cpp:137] Memory required for data: 329623600
I0930 20:04:50.386101  4047 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:04:50.386106  4047 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0930 20:04:50.386109  4047 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0930 20:04:50.386111  4047 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0930 20:04:50.386116  4047 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0930 20:04:50.386121  4047 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:04:50.386624  4047 net.cpp:122] Setting up SoftmaxWithLoss1
I0930 20:04:50.386633  4047 net.cpp:129] Top shape: (1)
I0930 20:04:50.386636  4047 net.cpp:132]     with loss weight 1
I0930 20:04:50.386647  4047 net.cpp:137] Memory required for data: 329623604
I0930 20:04:50.386649  4047 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0930 20:04:50.386652  4047 net.cpp:198] InnerProduct1 needs backward computation.
I0930 20:04:50.386654  4047 net.cpp:198] Pooling1 needs backward computation.
I0930 20:04:50.386656  4047 net.cpp:198] penlu19 needs backward computation.
I0930 20:04:50.386658  4047 net.cpp:198] Eltwise9 needs backward computation.
I0930 20:04:50.386660  4047 net.cpp:198] Scale21 needs backward computation.
I0930 20:04:50.386662  4047 net.cpp:198] BatchNorm21 needs backward computation.
I0930 20:04:50.386664  4047 net.cpp:198] Convolution21 needs backward computation.
I0930 20:04:50.386667  4047 net.cpp:198] penlu18 needs backward computation.
I0930 20:04:50.386668  4047 net.cpp:198] Scale20 needs backward computation.
I0930 20:04:50.386670  4047 net.cpp:198] BatchNorm20 needs backward computation.
I0930 20:04:50.386672  4047 net.cpp:198] Convolution20 needs backward computation.
I0930 20:04:50.386674  4047 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0930 20:04:50.386683  4047 net.cpp:198] penlu17 needs backward computation.
I0930 20:04:50.386685  4047 net.cpp:198] Eltwise8 needs backward computation.
I0930 20:04:50.386688  4047 net.cpp:198] Scale19 needs backward computation.
I0930 20:04:50.386689  4047 net.cpp:198] BatchNorm19 needs backward computation.
I0930 20:04:50.386692  4047 net.cpp:198] Convolution19 needs backward computation.
I0930 20:04:50.386693  4047 net.cpp:198] penlu16 needs backward computation.
I0930 20:04:50.386695  4047 net.cpp:198] Scale18 needs backward computation.
I0930 20:04:50.386698  4047 net.cpp:198] BatchNorm18 needs backward computation.
I0930 20:04:50.386699  4047 net.cpp:198] Convolution18 needs backward computation.
I0930 20:04:50.386701  4047 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0930 20:04:50.386704  4047 net.cpp:198] penlu15 needs backward computation.
I0930 20:04:50.386706  4047 net.cpp:198] Eltwise7 needs backward computation.
I0930 20:04:50.386708  4047 net.cpp:198] Scale17 needs backward computation.
I0930 20:04:50.386710  4047 net.cpp:198] BatchNorm17 needs backward computation.
I0930 20:04:50.386713  4047 net.cpp:198] Convolution17 needs backward computation.
I0930 20:04:50.386714  4047 net.cpp:198] penlu14 needs backward computation.
I0930 20:04:50.386716  4047 net.cpp:198] Scale16 needs backward computation.
I0930 20:04:50.386718  4047 net.cpp:198] BatchNorm16 needs backward computation.
I0930 20:04:50.386720  4047 net.cpp:198] Convolution16 needs backward computation.
I0930 20:04:50.386723  4047 net.cpp:198] Scale15 needs backward computation.
I0930 20:04:50.386725  4047 net.cpp:198] BatchNorm15 needs backward computation.
I0930 20:04:50.386728  4047 net.cpp:198] Convolution15 needs backward computation.
I0930 20:04:50.386729  4047 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0930 20:04:50.386731  4047 net.cpp:198] penlu13 needs backward computation.
I0930 20:04:50.386734  4047 net.cpp:198] Eltwise6 needs backward computation.
I0930 20:04:50.386736  4047 net.cpp:198] Scale14 needs backward computation.
I0930 20:04:50.386739  4047 net.cpp:198] BatchNorm14 needs backward computation.
I0930 20:04:50.386740  4047 net.cpp:198] Convolution14 needs backward computation.
I0930 20:04:50.386744  4047 net.cpp:198] penlu12 needs backward computation.
I0930 20:04:50.386745  4047 net.cpp:198] Scale13 needs backward computation.
I0930 20:04:50.386747  4047 net.cpp:198] BatchNorm13 needs backward computation.
I0930 20:04:50.386749  4047 net.cpp:198] Convolution13 needs backward computation.
I0930 20:04:50.386752  4047 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0930 20:04:50.386754  4047 net.cpp:198] penlu11 needs backward computation.
I0930 20:04:50.386756  4047 net.cpp:198] Eltwise5 needs backward computation.
I0930 20:04:50.386759  4047 net.cpp:198] Scale12 needs backward computation.
I0930 20:04:50.386771  4047 net.cpp:198] BatchNorm12 needs backward computation.
I0930 20:04:50.386773  4047 net.cpp:198] Convolution12 needs backward computation.
I0930 20:04:50.386775  4047 net.cpp:198] penlu10 needs backward computation.
I0930 20:04:50.386778  4047 net.cpp:198] Scale11 needs backward computation.
I0930 20:04:50.386780  4047 net.cpp:198] BatchNorm11 needs backward computation.
I0930 20:04:50.386782  4047 net.cpp:198] Convolution11 needs backward computation.
I0930 20:04:50.386785  4047 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0930 20:04:50.386787  4047 net.cpp:198] penlu9 needs backward computation.
I0930 20:04:50.386800  4047 net.cpp:198] Eltwise4 needs backward computation.
I0930 20:04:50.386801  4047 net.cpp:198] Scale10 needs backward computation.
I0930 20:04:50.386804  4047 net.cpp:198] BatchNorm10 needs backward computation.
I0930 20:04:50.386806  4047 net.cpp:198] Convolution10 needs backward computation.
I0930 20:04:50.386808  4047 net.cpp:198] penlu8 needs backward computation.
I0930 20:04:50.386811  4047 net.cpp:198] Scale9 needs backward computation.
I0930 20:04:50.386816  4047 net.cpp:198] BatchNorm9 needs backward computation.
I0930 20:04:50.386817  4047 net.cpp:198] Convolution9 needs backward computation.
I0930 20:04:50.386821  4047 net.cpp:198] Scale8 needs backward computation.
I0930 20:04:50.386822  4047 net.cpp:198] BatchNorm8 needs backward computation.
I0930 20:04:50.386824  4047 net.cpp:198] Convolution8 needs backward computation.
I0930 20:04:50.386827  4047 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0930 20:04:50.386829  4047 net.cpp:198] penlu7 needs backward computation.
I0930 20:04:50.386831  4047 net.cpp:198] Eltwise3 needs backward computation.
I0930 20:04:50.386834  4047 net.cpp:198] Scale7 needs backward computation.
I0930 20:04:50.386837  4047 net.cpp:198] BatchNorm7 needs backward computation.
I0930 20:04:50.386838  4047 net.cpp:198] Convolution7 needs backward computation.
I0930 20:04:50.386840  4047 net.cpp:198] penlu6 needs backward computation.
I0930 20:04:50.386842  4047 net.cpp:198] Scale6 needs backward computation.
I0930 20:04:50.386844  4047 net.cpp:198] BatchNorm6 needs backward computation.
I0930 20:04:50.386847  4047 net.cpp:198] Convolution6 needs backward computation.
I0930 20:04:50.386849  4047 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0930 20:04:50.386852  4047 net.cpp:198] penlu5 needs backward computation.
I0930 20:04:50.386854  4047 net.cpp:198] Eltwise2 needs backward computation.
I0930 20:04:50.386857  4047 net.cpp:198] Scale5 needs backward computation.
I0930 20:04:50.386859  4047 net.cpp:198] BatchNorm5 needs backward computation.
I0930 20:04:50.386862  4047 net.cpp:198] Convolution5 needs backward computation.
I0930 20:04:50.386863  4047 net.cpp:198] penlu4 needs backward computation.
I0930 20:04:50.386865  4047 net.cpp:198] Scale4 needs backward computation.
I0930 20:04:50.386868  4047 net.cpp:198] BatchNorm4 needs backward computation.
I0930 20:04:50.386869  4047 net.cpp:198] Convolution4 needs backward computation.
I0930 20:04:50.386873  4047 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0930 20:04:50.386874  4047 net.cpp:198] penlu3 needs backward computation.
I0930 20:04:50.386876  4047 net.cpp:198] Eltwise1 needs backward computation.
I0930 20:04:50.386879  4047 net.cpp:198] Scale3 needs backward computation.
I0930 20:04:50.386881  4047 net.cpp:198] BatchNorm3 needs backward computation.
I0930 20:04:50.386883  4047 net.cpp:198] Convolution3 needs backward computation.
I0930 20:04:50.386885  4047 net.cpp:198] penlu2 needs backward computation.
I0930 20:04:50.386888  4047 net.cpp:198] Scale2 needs backward computation.
I0930 20:04:50.386891  4047 net.cpp:198] BatchNorm2 needs backward computation.
I0930 20:04:50.386894  4047 net.cpp:198] Convolution2 needs backward computation.
I0930 20:04:50.386896  4047 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0930 20:04:50.386899  4047 net.cpp:198] penlu1 needs backward computation.
I0930 20:04:50.386901  4047 net.cpp:198] Scale1 needs backward computation.
I0930 20:04:50.386904  4047 net.cpp:198] BatchNorm1 needs backward computation.
I0930 20:04:50.386905  4047 net.cpp:198] Convolution1 needs backward computation.
I0930 20:04:50.386909  4047 net.cpp:200] Data1 does not need backward computation.
I0930 20:04:50.386910  4047 net.cpp:242] This network produces output SoftmaxWithLoss1
I0930 20:04:50.386942  4047 net.cpp:255] Network initialization done.
I0930 20:04:50.388638  4047 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:04:50.388646  4047 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0930 20:04:50.388650  4047 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:04:50.388723  4047 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0930 20:04:50.389189  4047 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 3
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0930 20:04:50.389436  4047 layer_factory.hpp:77] Creating layer Data1
I0930 20:04:50.389472  4047 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0930 20:04:50.389482  4047 net.cpp:84] Creating Layer Data1
I0930 20:04:50.389487  4047 net.cpp:380] Data1 -> Data1
I0930 20:04:50.389492  4047 net.cpp:380] Data1 -> Data2
I0930 20:04:50.389497  4047 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0930 20:04:50.389607  4047 data_layer.cpp:45] output data size: 100,3,32,32
I0930 20:04:50.393364  4047 net.cpp:122] Setting up Data1
I0930 20:04:50.393381  4047 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0930 20:04:50.393385  4047 net.cpp:129] Top shape: 100 (100)
I0930 20:04:50.393388  4047 net.cpp:137] Memory required for data: 1229200
I0930 20:04:50.393393  4047 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0930 20:04:50.393400  4047 net.cpp:84] Creating Layer Data2_Data1_1_split
I0930 20:04:50.393404  4047 net.cpp:406] Data2_Data1_1_split <- Data2
I0930 20:04:50.393409  4047 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0930 20:04:50.393416  4047 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0930 20:04:50.393458  4047 net.cpp:122] Setting up Data2_Data1_1_split
I0930 20:04:50.393463  4047 net.cpp:129] Top shape: 100 (100)
I0930 20:04:50.393479  4047 net.cpp:129] Top shape: 100 (100)
I0930 20:04:50.393481  4047 net.cpp:137] Memory required for data: 1230000
I0930 20:04:50.393483  4047 layer_factory.hpp:77] Creating layer Convolution1
I0930 20:04:50.393493  4047 net.cpp:84] Creating Layer Convolution1
I0930 20:04:50.393496  4047 net.cpp:406] Convolution1 <- Data1
I0930 20:04:50.393499  4047 net.cpp:380] Convolution1 -> Convolution1
I0930 20:04:50.394623  4047 net.cpp:122] Setting up Convolution1
I0930 20:04:50.394632  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.394635  4047 net.cpp:137] Memory required for data: 7783600
I0930 20:04:50.394642  4047 layer_factory.hpp:77] Creating layer BatchNorm1
I0930 20:04:50.394647  4047 net.cpp:84] Creating Layer BatchNorm1
I0930 20:04:50.394650  4047 net.cpp:406] BatchNorm1 <- Convolution1
I0930 20:04:50.394654  4047 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0930 20:04:50.394789  4047 net.cpp:122] Setting up BatchNorm1
I0930 20:04:50.394793  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.394796  4047 net.cpp:137] Memory required for data: 14337200
I0930 20:04:50.394804  4047 layer_factory.hpp:77] Creating layer Scale1
I0930 20:04:50.394809  4047 net.cpp:84] Creating Layer Scale1
I0930 20:04:50.394811  4047 net.cpp:406] Scale1 <- Convolution1
I0930 20:04:50.394815  4047 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0930 20:04:50.394845  4047 layer_factory.hpp:77] Creating layer Scale1
I0930 20:04:50.394920  4047 net.cpp:122] Setting up Scale1
I0930 20:04:50.394927  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.394928  4047 net.cpp:137] Memory required for data: 20890800
I0930 20:04:50.394932  4047 layer_factory.hpp:77] Creating layer penlu1
I0930 20:04:50.394938  4047 net.cpp:84] Creating Layer penlu1
I0930 20:04:50.394940  4047 net.cpp:406] penlu1 <- Convolution1
I0930 20:04:50.394943  4047 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0930 20:04:50.395061  4047 net.cpp:122] Setting up penlu1
I0930 20:04:50.395064  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.395072  4047 net.cpp:137] Memory required for data: 27444400
I0930 20:04:50.395077  4047 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0930 20:04:50.395084  4047 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0930 20:04:50.395087  4047 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0930 20:04:50.395089  4047 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0930 20:04:50.395093  4047 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0930 20:04:50.395117  4047 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0930 20:04:50.395121  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.395124  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.395128  4047 net.cpp:137] Memory required for data: 40551600
I0930 20:04:50.395129  4047 layer_factory.hpp:77] Creating layer Convolution2
I0930 20:04:50.395135  4047 net.cpp:84] Creating Layer Convolution2
I0930 20:04:50.395138  4047 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0930 20:04:50.395143  4047 net.cpp:380] Convolution2 -> Convolution2
I0930 20:04:50.395766  4047 net.cpp:122] Setting up Convolution2
I0930 20:04:50.395774  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.395777  4047 net.cpp:137] Memory required for data: 47105200
I0930 20:04:50.395781  4047 layer_factory.hpp:77] Creating layer BatchNorm2
I0930 20:04:50.395787  4047 net.cpp:84] Creating Layer BatchNorm2
I0930 20:04:50.395789  4047 net.cpp:406] BatchNorm2 <- Convolution2
I0930 20:04:50.395793  4047 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0930 20:04:50.395941  4047 net.cpp:122] Setting up BatchNorm2
I0930 20:04:50.395946  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.395947  4047 net.cpp:137] Memory required for data: 53658800
I0930 20:04:50.395952  4047 layer_factory.hpp:77] Creating layer Scale2
I0930 20:04:50.395957  4047 net.cpp:84] Creating Layer Scale2
I0930 20:04:50.395967  4047 net.cpp:406] Scale2 <- Convolution2
I0930 20:04:50.395972  4047 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0930 20:04:50.396073  4047 layer_factory.hpp:77] Creating layer Scale2
I0930 20:04:50.396147  4047 net.cpp:122] Setting up Scale2
I0930 20:04:50.396154  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.396157  4047 net.cpp:137] Memory required for data: 60212400
I0930 20:04:50.396163  4047 layer_factory.hpp:77] Creating layer penlu2
I0930 20:04:50.396169  4047 net.cpp:84] Creating Layer penlu2
I0930 20:04:50.396172  4047 net.cpp:406] penlu2 <- Convolution2
I0930 20:04:50.396175  4047 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0930 20:04:50.396288  4047 net.cpp:122] Setting up penlu2
I0930 20:04:50.396292  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.396296  4047 net.cpp:137] Memory required for data: 66766000
I0930 20:04:50.396301  4047 layer_factory.hpp:77] Creating layer Convolution3
I0930 20:04:50.396308  4047 net.cpp:84] Creating Layer Convolution3
I0930 20:04:50.396311  4047 net.cpp:406] Convolution3 <- Convolution2
I0930 20:04:50.396317  4047 net.cpp:380] Convolution3 -> Convolution3
I0930 20:04:50.397238  4047 net.cpp:122] Setting up Convolution3
I0930 20:04:50.397246  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.397249  4047 net.cpp:137] Memory required for data: 73319600
I0930 20:04:50.397253  4047 layer_factory.hpp:77] Creating layer BatchNorm3
I0930 20:04:50.397260  4047 net.cpp:84] Creating Layer BatchNorm3
I0930 20:04:50.397263  4047 net.cpp:406] BatchNorm3 <- Convolution3
I0930 20:04:50.397266  4047 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0930 20:04:50.397408  4047 net.cpp:122] Setting up BatchNorm3
I0930 20:04:50.397415  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.397418  4047 net.cpp:137] Memory required for data: 79873200
I0930 20:04:50.397423  4047 layer_factory.hpp:77] Creating layer Scale3
I0930 20:04:50.397426  4047 net.cpp:84] Creating Layer Scale3
I0930 20:04:50.397429  4047 net.cpp:406] Scale3 <- Convolution3
I0930 20:04:50.397433  4047 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0930 20:04:50.397548  4047 layer_factory.hpp:77] Creating layer Scale3
I0930 20:04:50.397622  4047 net.cpp:122] Setting up Scale3
I0930 20:04:50.397629  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.397630  4047 net.cpp:137] Memory required for data: 86426800
I0930 20:04:50.397634  4047 layer_factory.hpp:77] Creating layer Eltwise1
I0930 20:04:50.397639  4047 net.cpp:84] Creating Layer Eltwise1
I0930 20:04:50.397641  4047 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0930 20:04:50.397644  4047 net.cpp:406] Eltwise1 <- Convolution3
I0930 20:04:50.397649  4047 net.cpp:380] Eltwise1 -> Eltwise1
I0930 20:04:50.397666  4047 net.cpp:122] Setting up Eltwise1
I0930 20:04:50.397670  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.397675  4047 net.cpp:137] Memory required for data: 92980400
I0930 20:04:50.397677  4047 layer_factory.hpp:77] Creating layer penlu3
I0930 20:04:50.397682  4047 net.cpp:84] Creating Layer penlu3
I0930 20:04:50.397686  4047 net.cpp:406] penlu3 <- Eltwise1
I0930 20:04:50.397691  4047 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0930 20:04:50.397802  4047 net.cpp:122] Setting up penlu3
I0930 20:04:50.397807  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.397809  4047 net.cpp:137] Memory required for data: 99534000
I0930 20:04:50.397814  4047 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0930 20:04:50.397819  4047 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0930 20:04:50.397820  4047 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0930 20:04:50.397825  4047 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0930 20:04:50.397830  4047 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0930 20:04:50.397852  4047 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0930 20:04:50.397855  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.397864  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.397866  4047 net.cpp:137] Memory required for data: 112641200
I0930 20:04:50.397868  4047 layer_factory.hpp:77] Creating layer Convolution4
I0930 20:04:50.397876  4047 net.cpp:84] Creating Layer Convolution4
I0930 20:04:50.397878  4047 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0930 20:04:50.397882  4047 net.cpp:380] Convolution4 -> Convolution4
I0930 20:04:50.398814  4047 net.cpp:122] Setting up Convolution4
I0930 20:04:50.398823  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.398828  4047 net.cpp:137] Memory required for data: 119194800
I0930 20:04:50.398833  4047 layer_factory.hpp:77] Creating layer BatchNorm4
I0930 20:04:50.398838  4047 net.cpp:84] Creating Layer BatchNorm4
I0930 20:04:50.398840  4047 net.cpp:406] BatchNorm4 <- Convolution4
I0930 20:04:50.398844  4047 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0930 20:04:50.399068  4047 net.cpp:122] Setting up BatchNorm4
I0930 20:04:50.399073  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.399075  4047 net.cpp:137] Memory required for data: 125748400
I0930 20:04:50.399083  4047 layer_factory.hpp:77] Creating layer Scale4
I0930 20:04:50.399087  4047 net.cpp:84] Creating Layer Scale4
I0930 20:04:50.399091  4047 net.cpp:406] Scale4 <- Convolution4
I0930 20:04:50.399093  4047 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0930 20:04:50.399124  4047 layer_factory.hpp:77] Creating layer Scale4
I0930 20:04:50.399199  4047 net.cpp:122] Setting up Scale4
I0930 20:04:50.399204  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.399205  4047 net.cpp:137] Memory required for data: 132302000
I0930 20:04:50.399209  4047 layer_factory.hpp:77] Creating layer penlu4
I0930 20:04:50.399214  4047 net.cpp:84] Creating Layer penlu4
I0930 20:04:50.399217  4047 net.cpp:406] penlu4 <- Convolution4
I0930 20:04:50.399221  4047 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0930 20:04:50.399333  4047 net.cpp:122] Setting up penlu4
I0930 20:04:50.399338  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.399340  4047 net.cpp:137] Memory required for data: 138855600
I0930 20:04:50.399344  4047 layer_factory.hpp:77] Creating layer Convolution5
I0930 20:04:50.399351  4047 net.cpp:84] Creating Layer Convolution5
I0930 20:04:50.399353  4047 net.cpp:406] Convolution5 <- Convolution4
I0930 20:04:50.399358  4047 net.cpp:380] Convolution5 -> Convolution5
I0930 20:04:50.400609  4047 net.cpp:122] Setting up Convolution5
I0930 20:04:50.400616  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.400619  4047 net.cpp:137] Memory required for data: 145409200
I0930 20:04:50.400625  4047 layer_factory.hpp:77] Creating layer BatchNorm5
I0930 20:04:50.400631  4047 net.cpp:84] Creating Layer BatchNorm5
I0930 20:04:50.400635  4047 net.cpp:406] BatchNorm5 <- Convolution5
I0930 20:04:50.400637  4047 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0930 20:04:50.400773  4047 net.cpp:122] Setting up BatchNorm5
I0930 20:04:50.400777  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.400779  4047 net.cpp:137] Memory required for data: 151962800
I0930 20:04:50.400784  4047 layer_factory.hpp:77] Creating layer Scale5
I0930 20:04:50.400789  4047 net.cpp:84] Creating Layer Scale5
I0930 20:04:50.400790  4047 net.cpp:406] Scale5 <- Convolution5
I0930 20:04:50.400794  4047 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0930 20:04:50.400820  4047 layer_factory.hpp:77] Creating layer Scale5
I0930 20:04:50.400894  4047 net.cpp:122] Setting up Scale5
I0930 20:04:50.400899  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.400902  4047 net.cpp:137] Memory required for data: 158516400
I0930 20:04:50.400904  4047 layer_factory.hpp:77] Creating layer Eltwise2
I0930 20:04:50.400908  4047 net.cpp:84] Creating Layer Eltwise2
I0930 20:04:50.400910  4047 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0930 20:04:50.400914  4047 net.cpp:406] Eltwise2 <- Convolution5
I0930 20:04:50.400918  4047 net.cpp:380] Eltwise2 -> Eltwise2
I0930 20:04:50.400941  4047 net.cpp:122] Setting up Eltwise2
I0930 20:04:50.400945  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.400948  4047 net.cpp:137] Memory required for data: 165070000
I0930 20:04:50.400949  4047 layer_factory.hpp:77] Creating layer penlu5
I0930 20:04:50.400954  4047 net.cpp:84] Creating Layer penlu5
I0930 20:04:50.400957  4047 net.cpp:406] penlu5 <- Eltwise2
I0930 20:04:50.400960  4047 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0930 20:04:50.401073  4047 net.cpp:122] Setting up penlu5
I0930 20:04:50.401077  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.401079  4047 net.cpp:137] Memory required for data: 171623600
I0930 20:04:50.401083  4047 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0930 20:04:50.401087  4047 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0930 20:04:50.401089  4047 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0930 20:04:50.401093  4047 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0930 20:04:50.401096  4047 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0930 20:04:50.401121  4047 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0930 20:04:50.401125  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.401129  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.401130  4047 net.cpp:137] Memory required for data: 184730800
I0930 20:04:50.401132  4047 layer_factory.hpp:77] Creating layer Convolution6
I0930 20:04:50.401139  4047 net.cpp:84] Creating Layer Convolution6
I0930 20:04:50.401141  4047 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0930 20:04:50.401145  4047 net.cpp:380] Convolution6 -> Convolution6
I0930 20:04:50.402048  4047 net.cpp:122] Setting up Convolution6
I0930 20:04:50.402058  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.402060  4047 net.cpp:137] Memory required for data: 191284400
I0930 20:04:50.402065  4047 layer_factory.hpp:77] Creating layer BatchNorm6
I0930 20:04:50.402070  4047 net.cpp:84] Creating Layer BatchNorm6
I0930 20:04:50.402072  4047 net.cpp:406] BatchNorm6 <- Convolution6
I0930 20:04:50.402076  4047 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0930 20:04:50.402211  4047 net.cpp:122] Setting up BatchNorm6
I0930 20:04:50.402215  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.402217  4047 net.cpp:137] Memory required for data: 197838000
I0930 20:04:50.402222  4047 layer_factory.hpp:77] Creating layer Scale6
I0930 20:04:50.402226  4047 net.cpp:84] Creating Layer Scale6
I0930 20:04:50.402230  4047 net.cpp:406] Scale6 <- Convolution6
I0930 20:04:50.402232  4047 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0930 20:04:50.402258  4047 layer_factory.hpp:77] Creating layer Scale6
I0930 20:04:50.402330  4047 net.cpp:122] Setting up Scale6
I0930 20:04:50.402335  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.402338  4047 net.cpp:137] Memory required for data: 204391600
I0930 20:04:50.402340  4047 layer_factory.hpp:77] Creating layer penlu6
I0930 20:04:50.402345  4047 net.cpp:84] Creating Layer penlu6
I0930 20:04:50.402348  4047 net.cpp:406] penlu6 <- Convolution6
I0930 20:04:50.402351  4047 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0930 20:04:50.402464  4047 net.cpp:122] Setting up penlu6
I0930 20:04:50.402469  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.402472  4047 net.cpp:137] Memory required for data: 210945200
I0930 20:04:50.402475  4047 layer_factory.hpp:77] Creating layer Convolution7
I0930 20:04:50.402482  4047 net.cpp:84] Creating Layer Convolution7
I0930 20:04:50.402484  4047 net.cpp:406] Convolution7 <- Convolution6
I0930 20:04:50.402488  4047 net.cpp:380] Convolution7 -> Convolution7
I0930 20:04:50.403399  4047 net.cpp:122] Setting up Convolution7
I0930 20:04:50.403409  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.403411  4047 net.cpp:137] Memory required for data: 217498800
I0930 20:04:50.403415  4047 layer_factory.hpp:77] Creating layer BatchNorm7
I0930 20:04:50.403424  4047 net.cpp:84] Creating Layer BatchNorm7
I0930 20:04:50.403431  4047 net.cpp:406] BatchNorm7 <- Convolution7
I0930 20:04:50.403436  4047 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0930 20:04:50.403571  4047 net.cpp:122] Setting up BatchNorm7
I0930 20:04:50.403575  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.403578  4047 net.cpp:137] Memory required for data: 224052400
I0930 20:04:50.403587  4047 layer_factory.hpp:77] Creating layer Scale7
I0930 20:04:50.403592  4047 net.cpp:84] Creating Layer Scale7
I0930 20:04:50.403594  4047 net.cpp:406] Scale7 <- Convolution7
I0930 20:04:50.403597  4047 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0930 20:04:50.403626  4047 layer_factory.hpp:77] Creating layer Scale7
I0930 20:04:50.403702  4047 net.cpp:122] Setting up Scale7
I0930 20:04:50.403707  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.403709  4047 net.cpp:137] Memory required for data: 230606000
I0930 20:04:50.403713  4047 layer_factory.hpp:77] Creating layer Eltwise3
I0930 20:04:50.403717  4047 net.cpp:84] Creating Layer Eltwise3
I0930 20:04:50.403719  4047 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0930 20:04:50.403723  4047 net.cpp:406] Eltwise3 <- Convolution7
I0930 20:04:50.403726  4047 net.cpp:380] Eltwise3 -> Eltwise3
I0930 20:04:50.403741  4047 net.cpp:122] Setting up Eltwise3
I0930 20:04:50.403745  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.403746  4047 net.cpp:137] Memory required for data: 237159600
I0930 20:04:50.403748  4047 layer_factory.hpp:77] Creating layer penlu7
I0930 20:04:50.403753  4047 net.cpp:84] Creating Layer penlu7
I0930 20:04:50.403755  4047 net.cpp:406] penlu7 <- Eltwise3
I0930 20:04:50.403759  4047 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0930 20:04:50.403873  4047 net.cpp:122] Setting up penlu7
I0930 20:04:50.403878  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.403880  4047 net.cpp:137] Memory required for data: 243713200
I0930 20:04:50.403884  4047 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0930 20:04:50.403888  4047 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0930 20:04:50.403890  4047 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0930 20:04:50.403893  4047 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0930 20:04:50.403898  4047 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0930 20:04:50.403919  4047 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0930 20:04:50.403923  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.403926  4047 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:04:50.403928  4047 net.cpp:137] Memory required for data: 256820400
I0930 20:04:50.403930  4047 layer_factory.hpp:77] Creating layer Convolution8
I0930 20:04:50.403936  4047 net.cpp:84] Creating Layer Convolution8
I0930 20:04:50.403939  4047 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0930 20:04:50.403942  4047 net.cpp:380] Convolution8 -> Convolution8
I0930 20:04:50.404840  4047 net.cpp:122] Setting up Convolution8
I0930 20:04:50.404848  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.404851  4047 net.cpp:137] Memory required for data: 260097200
I0930 20:04:50.404855  4047 layer_factory.hpp:77] Creating layer BatchNorm8
I0930 20:04:50.404860  4047 net.cpp:84] Creating Layer BatchNorm8
I0930 20:04:50.404862  4047 net.cpp:406] BatchNorm8 <- Convolution8
I0930 20:04:50.404866  4047 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0930 20:04:50.404997  4047 net.cpp:122] Setting up BatchNorm8
I0930 20:04:50.405001  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.405004  4047 net.cpp:137] Memory required for data: 263374000
I0930 20:04:50.405009  4047 layer_factory.hpp:77] Creating layer Scale8
I0930 20:04:50.405012  4047 net.cpp:84] Creating Layer Scale8
I0930 20:04:50.408989  4047 net.cpp:406] Scale8 <- Convolution8
I0930 20:04:50.408998  4047 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0930 20:04:50.409044  4047 layer_factory.hpp:77] Creating layer Scale8
I0930 20:04:50.409174  4047 net.cpp:122] Setting up Scale8
I0930 20:04:50.409183  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.409188  4047 net.cpp:137] Memory required for data: 266650800
I0930 20:04:50.409194  4047 layer_factory.hpp:77] Creating layer Convolution9
I0930 20:04:50.409206  4047 net.cpp:84] Creating Layer Convolution9
I0930 20:04:50.409212  4047 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I0930 20:04:50.409220  4047 net.cpp:380] Convolution9 -> Convolution9
I0930 20:04:50.410683  4047 net.cpp:122] Setting up Convolution9
I0930 20:04:50.410696  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.410699  4047 net.cpp:137] Memory required for data: 269927600
I0930 20:04:50.410706  4047 layer_factory.hpp:77] Creating layer BatchNorm9
I0930 20:04:50.410713  4047 net.cpp:84] Creating Layer BatchNorm9
I0930 20:04:50.410718  4047 net.cpp:406] BatchNorm9 <- Convolution9
I0930 20:04:50.410723  4047 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0930 20:04:50.410912  4047 net.cpp:122] Setting up BatchNorm9
I0930 20:04:50.410920  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.410924  4047 net.cpp:137] Memory required for data: 273204400
I0930 20:04:50.410933  4047 layer_factory.hpp:77] Creating layer Scale9
I0930 20:04:50.410940  4047 net.cpp:84] Creating Layer Scale9
I0930 20:04:50.410945  4047 net.cpp:406] Scale9 <- Convolution9
I0930 20:04:50.410951  4047 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0930 20:04:50.410995  4047 layer_factory.hpp:77] Creating layer Scale9
I0930 20:04:50.411109  4047 net.cpp:122] Setting up Scale9
I0930 20:04:50.411118  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.411123  4047 net.cpp:137] Memory required for data: 276481200
I0930 20:04:50.411128  4047 layer_factory.hpp:77] Creating layer penlu8
I0930 20:04:50.411139  4047 net.cpp:84] Creating Layer penlu8
I0930 20:04:50.411142  4047 net.cpp:406] penlu8 <- Convolution9
I0930 20:04:50.411149  4047 net.cpp:367] penlu8 -> Convolution9 (in-place)
I0930 20:04:50.411310  4047 net.cpp:122] Setting up penlu8
I0930 20:04:50.411316  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.411319  4047 net.cpp:137] Memory required for data: 279758000
I0930 20:04:50.411324  4047 layer_factory.hpp:77] Creating layer Convolution10
I0930 20:04:50.411334  4047 net.cpp:84] Creating Layer Convolution10
I0930 20:04:50.411339  4047 net.cpp:406] Convolution10 <- Convolution9
I0930 20:04:50.411345  4047 net.cpp:380] Convolution10 -> Convolution10
I0930 20:04:50.412977  4047 net.cpp:122] Setting up Convolution10
I0930 20:04:50.412986  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.412989  4047 net.cpp:137] Memory required for data: 283034800
I0930 20:04:50.412993  4047 layer_factory.hpp:77] Creating layer BatchNorm10
I0930 20:04:50.412998  4047 net.cpp:84] Creating Layer BatchNorm10
I0930 20:04:50.413002  4047 net.cpp:406] BatchNorm10 <- Convolution10
I0930 20:04:50.413005  4047 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0930 20:04:50.413143  4047 net.cpp:122] Setting up BatchNorm10
I0930 20:04:50.413148  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.413151  4047 net.cpp:137] Memory required for data: 286311600
I0930 20:04:50.413156  4047 layer_factory.hpp:77] Creating layer Scale10
I0930 20:04:50.413159  4047 net.cpp:84] Creating Layer Scale10
I0930 20:04:50.413161  4047 net.cpp:406] Scale10 <- Convolution10
I0930 20:04:50.413166  4047 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0930 20:04:50.413192  4047 layer_factory.hpp:77] Creating layer Scale10
I0930 20:04:50.413269  4047 net.cpp:122] Setting up Scale10
I0930 20:04:50.413275  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.413276  4047 net.cpp:137] Memory required for data: 289588400
I0930 20:04:50.413280  4047 layer_factory.hpp:77] Creating layer Eltwise4
I0930 20:04:50.413285  4047 net.cpp:84] Creating Layer Eltwise4
I0930 20:04:50.413286  4047 net.cpp:406] Eltwise4 <- Convolution8
I0930 20:04:50.413290  4047 net.cpp:406] Eltwise4 <- Convolution10
I0930 20:04:50.413300  4047 net.cpp:380] Eltwise4 -> Eltwise4
I0930 20:04:50.413314  4047 net.cpp:122] Setting up Eltwise4
I0930 20:04:50.413318  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.413321  4047 net.cpp:137] Memory required for data: 292865200
I0930 20:04:50.413322  4047 layer_factory.hpp:77] Creating layer penlu9
I0930 20:04:50.413327  4047 net.cpp:84] Creating Layer penlu9
I0930 20:04:50.413331  4047 net.cpp:406] penlu9 <- Eltwise4
I0930 20:04:50.413334  4047 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0930 20:04:50.413451  4047 net.cpp:122] Setting up penlu9
I0930 20:04:50.413456  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.413458  4047 net.cpp:137] Memory required for data: 296142000
I0930 20:04:50.413462  4047 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0930 20:04:50.413466  4047 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0930 20:04:50.413468  4047 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0930 20:04:50.413472  4047 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0930 20:04:50.413476  4047 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0930 20:04:50.413499  4047 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0930 20:04:50.413503  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.413506  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.413508  4047 net.cpp:137] Memory required for data: 302695600
I0930 20:04:50.413511  4047 layer_factory.hpp:77] Creating layer Convolution11
I0930 20:04:50.413516  4047 net.cpp:84] Creating Layer Convolution11
I0930 20:04:50.413519  4047 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I0930 20:04:50.413523  4047 net.cpp:380] Convolution11 -> Convolution11
I0930 20:04:50.414708  4047 net.cpp:122] Setting up Convolution11
I0930 20:04:50.414717  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.414729  4047 net.cpp:137] Memory required for data: 305972400
I0930 20:04:50.414733  4047 layer_factory.hpp:77] Creating layer BatchNorm11
I0930 20:04:50.414739  4047 net.cpp:84] Creating Layer BatchNorm11
I0930 20:04:50.414741  4047 net.cpp:406] BatchNorm11 <- Convolution11
I0930 20:04:50.414746  4047 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0930 20:04:50.414883  4047 net.cpp:122] Setting up BatchNorm11
I0930 20:04:50.414887  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.414890  4047 net.cpp:137] Memory required for data: 309249200
I0930 20:04:50.414894  4047 layer_factory.hpp:77] Creating layer Scale11
I0930 20:04:50.414899  4047 net.cpp:84] Creating Layer Scale11
I0930 20:04:50.414901  4047 net.cpp:406] Scale11 <- Convolution11
I0930 20:04:50.414904  4047 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0930 20:04:50.414932  4047 layer_factory.hpp:77] Creating layer Scale11
I0930 20:04:50.415009  4047 net.cpp:122] Setting up Scale11
I0930 20:04:50.415014  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.415015  4047 net.cpp:137] Memory required for data: 312526000
I0930 20:04:50.415019  4047 layer_factory.hpp:77] Creating layer penlu10
I0930 20:04:50.415024  4047 net.cpp:84] Creating Layer penlu10
I0930 20:04:50.415027  4047 net.cpp:406] penlu10 <- Convolution11
I0930 20:04:50.415031  4047 net.cpp:367] penlu10 -> Convolution11 (in-place)
I0930 20:04:50.415140  4047 net.cpp:122] Setting up penlu10
I0930 20:04:50.415144  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.415146  4047 net.cpp:137] Memory required for data: 315802800
I0930 20:04:50.415150  4047 layer_factory.hpp:77] Creating layer Convolution12
I0930 20:04:50.415158  4047 net.cpp:84] Creating Layer Convolution12
I0930 20:04:50.415160  4047 net.cpp:406] Convolution12 <- Convolution11
I0930 20:04:50.415165  4047 net.cpp:380] Convolution12 -> Convolution12
I0930 20:04:50.415910  4047 net.cpp:122] Setting up Convolution12
I0930 20:04:50.415917  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.415920  4047 net.cpp:137] Memory required for data: 319079600
I0930 20:04:50.415931  4047 layer_factory.hpp:77] Creating layer BatchNorm12
I0930 20:04:50.415936  4047 net.cpp:84] Creating Layer BatchNorm12
I0930 20:04:50.415940  4047 net.cpp:406] BatchNorm12 <- Convolution12
I0930 20:04:50.415942  4047 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0930 20:04:50.416079  4047 net.cpp:122] Setting up BatchNorm12
I0930 20:04:50.416083  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.416085  4047 net.cpp:137] Memory required for data: 322356400
I0930 20:04:50.416090  4047 layer_factory.hpp:77] Creating layer Scale12
I0930 20:04:50.416095  4047 net.cpp:84] Creating Layer Scale12
I0930 20:04:50.416096  4047 net.cpp:406] Scale12 <- Convolution12
I0930 20:04:50.416100  4047 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0930 20:04:50.416127  4047 layer_factory.hpp:77] Creating layer Scale12
I0930 20:04:50.416204  4047 net.cpp:122] Setting up Scale12
I0930 20:04:50.416209  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.416211  4047 net.cpp:137] Memory required for data: 325633200
I0930 20:04:50.416215  4047 layer_factory.hpp:77] Creating layer Eltwise5
I0930 20:04:50.416220  4047 net.cpp:84] Creating Layer Eltwise5
I0930 20:04:50.416224  4047 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0930 20:04:50.416226  4047 net.cpp:406] Eltwise5 <- Convolution12
I0930 20:04:50.416229  4047 net.cpp:380] Eltwise5 -> Eltwise5
I0930 20:04:50.416242  4047 net.cpp:122] Setting up Eltwise5
I0930 20:04:50.416246  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.416249  4047 net.cpp:137] Memory required for data: 328910000
I0930 20:04:50.416250  4047 layer_factory.hpp:77] Creating layer penlu11
I0930 20:04:50.416255  4047 net.cpp:84] Creating Layer penlu11
I0930 20:04:50.416259  4047 net.cpp:406] penlu11 <- Eltwise5
I0930 20:04:50.416261  4047 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0930 20:04:50.416375  4047 net.cpp:122] Setting up penlu11
I0930 20:04:50.416379  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.416381  4047 net.cpp:137] Memory required for data: 332186800
I0930 20:04:50.416385  4047 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0930 20:04:50.416389  4047 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0930 20:04:50.416391  4047 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0930 20:04:50.416396  4047 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0930 20:04:50.416400  4047 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0930 20:04:50.416426  4047 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0930 20:04:50.416430  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.416434  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.416435  4047 net.cpp:137] Memory required for data: 338740400
I0930 20:04:50.416437  4047 layer_factory.hpp:77] Creating layer Convolution13
I0930 20:04:50.416443  4047 net.cpp:84] Creating Layer Convolution13
I0930 20:04:50.416445  4047 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I0930 20:04:50.416450  4047 net.cpp:380] Convolution13 -> Convolution13
I0930 20:04:50.417526  4047 net.cpp:122] Setting up Convolution13
I0930 20:04:50.417536  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.417538  4047 net.cpp:137] Memory required for data: 342017200
I0930 20:04:50.417542  4047 layer_factory.hpp:77] Creating layer BatchNorm13
I0930 20:04:50.417547  4047 net.cpp:84] Creating Layer BatchNorm13
I0930 20:04:50.417551  4047 net.cpp:406] BatchNorm13 <- Convolution13
I0930 20:04:50.417554  4047 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0930 20:04:50.417690  4047 net.cpp:122] Setting up BatchNorm13
I0930 20:04:50.417695  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.417696  4047 net.cpp:137] Memory required for data: 345294000
I0930 20:04:50.417701  4047 layer_factory.hpp:77] Creating layer Scale13
I0930 20:04:50.417706  4047 net.cpp:84] Creating Layer Scale13
I0930 20:04:50.417707  4047 net.cpp:406] Scale13 <- Convolution13
I0930 20:04:50.417717  4047 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0930 20:04:50.417747  4047 layer_factory.hpp:77] Creating layer Scale13
I0930 20:04:50.417824  4047 net.cpp:122] Setting up Scale13
I0930 20:04:50.417829  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.417830  4047 net.cpp:137] Memory required for data: 348570800
I0930 20:04:50.417834  4047 layer_factory.hpp:77] Creating layer penlu12
I0930 20:04:50.417840  4047 net.cpp:84] Creating Layer penlu12
I0930 20:04:50.417843  4047 net.cpp:406] penlu12 <- Convolution13
I0930 20:04:50.417846  4047 net.cpp:367] penlu12 -> Convolution13 (in-place)
I0930 20:04:50.417958  4047 net.cpp:122] Setting up penlu12
I0930 20:04:50.417963  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.417964  4047 net.cpp:137] Memory required for data: 351847600
I0930 20:04:50.417968  4047 layer_factory.hpp:77] Creating layer Convolution14
I0930 20:04:50.417979  4047 net.cpp:84] Creating Layer Convolution14
I0930 20:04:50.417981  4047 net.cpp:406] Convolution14 <- Convolution13
I0930 20:04:50.417985  4047 net.cpp:380] Convolution14 -> Convolution14
I0930 20:04:50.419078  4047 net.cpp:122] Setting up Convolution14
I0930 20:04:50.419087  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.419090  4047 net.cpp:137] Memory required for data: 355124400
I0930 20:04:50.419106  4047 layer_factory.hpp:77] Creating layer BatchNorm14
I0930 20:04:50.419112  4047 net.cpp:84] Creating Layer BatchNorm14
I0930 20:04:50.419116  4047 net.cpp:406] BatchNorm14 <- Convolution14
I0930 20:04:50.419119  4047 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0930 20:04:50.419265  4047 net.cpp:122] Setting up BatchNorm14
I0930 20:04:50.419268  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.419271  4047 net.cpp:137] Memory required for data: 358401200
I0930 20:04:50.419276  4047 layer_factory.hpp:77] Creating layer Scale14
I0930 20:04:50.419281  4047 net.cpp:84] Creating Layer Scale14
I0930 20:04:50.419283  4047 net.cpp:406] Scale14 <- Convolution14
I0930 20:04:50.419286  4047 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0930 20:04:50.419314  4047 layer_factory.hpp:77] Creating layer Scale14
I0930 20:04:50.419391  4047 net.cpp:122] Setting up Scale14
I0930 20:04:50.419396  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.419399  4047 net.cpp:137] Memory required for data: 361678000
I0930 20:04:50.419402  4047 layer_factory.hpp:77] Creating layer Eltwise6
I0930 20:04:50.419406  4047 net.cpp:84] Creating Layer Eltwise6
I0930 20:04:50.419409  4047 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0930 20:04:50.419411  4047 net.cpp:406] Eltwise6 <- Convolution14
I0930 20:04:50.419415  4047 net.cpp:380] Eltwise6 -> Eltwise6
I0930 20:04:50.419427  4047 net.cpp:122] Setting up Eltwise6
I0930 20:04:50.419431  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.419433  4047 net.cpp:137] Memory required for data: 364954800
I0930 20:04:50.419435  4047 layer_factory.hpp:77] Creating layer penlu13
I0930 20:04:50.419441  4047 net.cpp:84] Creating Layer penlu13
I0930 20:04:50.419443  4047 net.cpp:406] penlu13 <- Eltwise6
I0930 20:04:50.419446  4047 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0930 20:04:50.419562  4047 net.cpp:122] Setting up penlu13
I0930 20:04:50.419566  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.419569  4047 net.cpp:137] Memory required for data: 368231600
I0930 20:04:50.419574  4047 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0930 20:04:50.419576  4047 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0930 20:04:50.419579  4047 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0930 20:04:50.419582  4047 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0930 20:04:50.440110  4047 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0930 20:04:50.440161  4047 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0930 20:04:50.440170  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.440176  4047 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:04:50.440188  4047 net.cpp:137] Memory required for data: 374785200
I0930 20:04:50.440193  4047 layer_factory.hpp:77] Creating layer Convolution15
I0930 20:04:50.440206  4047 net.cpp:84] Creating Layer Convolution15
I0930 20:04:50.440210  4047 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I0930 20:04:50.440217  4047 net.cpp:380] Convolution15 -> Convolution15
I0930 20:04:50.441658  4047 net.cpp:122] Setting up Convolution15
I0930 20:04:50.441670  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.441675  4047 net.cpp:137] Memory required for data: 376423600
I0930 20:04:50.441682  4047 layer_factory.hpp:77] Creating layer BatchNorm15
I0930 20:04:50.441690  4047 net.cpp:84] Creating Layer BatchNorm15
I0930 20:04:50.441695  4047 net.cpp:406] BatchNorm15 <- Convolution15
I0930 20:04:50.441701  4047 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0930 20:04:50.441902  4047 net.cpp:122] Setting up BatchNorm15
I0930 20:04:50.441910  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.441913  4047 net.cpp:137] Memory required for data: 378062000
I0930 20:04:50.441922  4047 layer_factory.hpp:77] Creating layer Scale15
I0930 20:04:50.441928  4047 net.cpp:84] Creating Layer Scale15
I0930 20:04:50.441932  4047 net.cpp:406] Scale15 <- Convolution15
I0930 20:04:50.441938  4047 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0930 20:04:50.441979  4047 layer_factory.hpp:77] Creating layer Scale15
I0930 20:04:50.442106  4047 net.cpp:122] Setting up Scale15
I0930 20:04:50.442114  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.442118  4047 net.cpp:137] Memory required for data: 379700400
I0930 20:04:50.442126  4047 layer_factory.hpp:77] Creating layer Convolution16
I0930 20:04:50.442136  4047 net.cpp:84] Creating Layer Convolution16
I0930 20:04:50.442140  4047 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I0930 20:04:50.442148  4047 net.cpp:380] Convolution16 -> Convolution16
I0930 20:04:50.443989  4047 net.cpp:122] Setting up Convolution16
I0930 20:04:50.444000  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.444001  4047 net.cpp:137] Memory required for data: 381338800
I0930 20:04:50.444006  4047 layer_factory.hpp:77] Creating layer BatchNorm16
I0930 20:04:50.444011  4047 net.cpp:84] Creating Layer BatchNorm16
I0930 20:04:50.444015  4047 net.cpp:406] BatchNorm16 <- Convolution16
I0930 20:04:50.444018  4047 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0930 20:04:50.444159  4047 net.cpp:122] Setting up BatchNorm16
I0930 20:04:50.444164  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.444165  4047 net.cpp:137] Memory required for data: 382977200
I0930 20:04:50.444170  4047 layer_factory.hpp:77] Creating layer Scale16
I0930 20:04:50.444175  4047 net.cpp:84] Creating Layer Scale16
I0930 20:04:50.444176  4047 net.cpp:406] Scale16 <- Convolution16
I0930 20:04:50.444180  4047 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0930 20:04:50.444208  4047 layer_factory.hpp:77] Creating layer Scale16
I0930 20:04:50.444288  4047 net.cpp:122] Setting up Scale16
I0930 20:04:50.444291  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.444294  4047 net.cpp:137] Memory required for data: 384615600
I0930 20:04:50.444298  4047 layer_factory.hpp:77] Creating layer penlu14
I0930 20:04:50.444303  4047 net.cpp:84] Creating Layer penlu14
I0930 20:04:50.444306  4047 net.cpp:406] penlu14 <- Convolution16
I0930 20:04:50.444311  4047 net.cpp:367] penlu14 -> Convolution16 (in-place)
I0930 20:04:50.444422  4047 net.cpp:122] Setting up penlu14
I0930 20:04:50.444427  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.444429  4047 net.cpp:137] Memory required for data: 386254000
I0930 20:04:50.444434  4047 layer_factory.hpp:77] Creating layer Convolution17
I0930 20:04:50.444440  4047 net.cpp:84] Creating Layer Convolution17
I0930 20:04:50.444442  4047 net.cpp:406] Convolution17 <- Convolution16
I0930 20:04:50.444447  4047 net.cpp:380] Convolution17 -> Convolution17
I0930 20:04:50.446238  4047 net.cpp:122] Setting up Convolution17
I0930 20:04:50.446255  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.446259  4047 net.cpp:137] Memory required for data: 387892400
I0930 20:04:50.446262  4047 layer_factory.hpp:77] Creating layer BatchNorm17
I0930 20:04:50.446269  4047 net.cpp:84] Creating Layer BatchNorm17
I0930 20:04:50.446271  4047 net.cpp:406] BatchNorm17 <- Convolution17
I0930 20:04:50.446275  4047 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0930 20:04:50.446419  4047 net.cpp:122] Setting up BatchNorm17
I0930 20:04:50.446424  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.446426  4047 net.cpp:137] Memory required for data: 389530800
I0930 20:04:50.446431  4047 layer_factory.hpp:77] Creating layer Scale17
I0930 20:04:50.446435  4047 net.cpp:84] Creating Layer Scale17
I0930 20:04:50.446437  4047 net.cpp:406] Scale17 <- Convolution17
I0930 20:04:50.446440  4047 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0930 20:04:50.446470  4047 layer_factory.hpp:77] Creating layer Scale17
I0930 20:04:50.446564  4047 net.cpp:122] Setting up Scale17
I0930 20:04:50.446570  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.446573  4047 net.cpp:137] Memory required for data: 391169200
I0930 20:04:50.446576  4047 layer_factory.hpp:77] Creating layer Eltwise7
I0930 20:04:50.446580  4047 net.cpp:84] Creating Layer Eltwise7
I0930 20:04:50.446583  4047 net.cpp:406] Eltwise7 <- Convolution15
I0930 20:04:50.446585  4047 net.cpp:406] Eltwise7 <- Convolution17
I0930 20:04:50.446589  4047 net.cpp:380] Eltwise7 -> Eltwise7
I0930 20:04:50.446606  4047 net.cpp:122] Setting up Eltwise7
I0930 20:04:50.446610  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.446612  4047 net.cpp:137] Memory required for data: 392807600
I0930 20:04:50.446614  4047 layer_factory.hpp:77] Creating layer penlu15
I0930 20:04:50.446620  4047 net.cpp:84] Creating Layer penlu15
I0930 20:04:50.446622  4047 net.cpp:406] penlu15 <- Eltwise7
I0930 20:04:50.446626  4047 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0930 20:04:50.446739  4047 net.cpp:122] Setting up penlu15
I0930 20:04:50.446743  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.446745  4047 net.cpp:137] Memory required for data: 394446000
I0930 20:04:50.446750  4047 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0930 20:04:50.446754  4047 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0930 20:04:50.446756  4047 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0930 20:04:50.446760  4047 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0930 20:04:50.446764  4047 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0930 20:04:50.446789  4047 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0930 20:04:50.446792  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.446795  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.446797  4047 net.cpp:137] Memory required for data: 397722800
I0930 20:04:50.446799  4047 layer_factory.hpp:77] Creating layer Convolution18
I0930 20:04:50.446805  4047 net.cpp:84] Creating Layer Convolution18
I0930 20:04:50.446807  4047 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I0930 20:04:50.446812  4047 net.cpp:380] Convolution18 -> Convolution18
I0930 20:04:50.448509  4047 net.cpp:122] Setting up Convolution18
I0930 20:04:50.448518  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.448521  4047 net.cpp:137] Memory required for data: 399361200
I0930 20:04:50.448525  4047 layer_factory.hpp:77] Creating layer BatchNorm18
I0930 20:04:50.448530  4047 net.cpp:84] Creating Layer BatchNorm18
I0930 20:04:50.448534  4047 net.cpp:406] BatchNorm18 <- Convolution18
I0930 20:04:50.448537  4047 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0930 20:04:50.448678  4047 net.cpp:122] Setting up BatchNorm18
I0930 20:04:50.448683  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.448685  4047 net.cpp:137] Memory required for data: 400999600
I0930 20:04:50.448690  4047 layer_factory.hpp:77] Creating layer Scale18
I0930 20:04:50.448700  4047 net.cpp:84] Creating Layer Scale18
I0930 20:04:50.448704  4047 net.cpp:406] Scale18 <- Convolution18
I0930 20:04:50.448706  4047 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0930 20:04:50.448737  4047 layer_factory.hpp:77] Creating layer Scale18
I0930 20:04:50.448818  4047 net.cpp:122] Setting up Scale18
I0930 20:04:50.448823  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.448825  4047 net.cpp:137] Memory required for data: 402638000
I0930 20:04:50.448829  4047 layer_factory.hpp:77] Creating layer penlu16
I0930 20:04:50.448834  4047 net.cpp:84] Creating Layer penlu16
I0930 20:04:50.448837  4047 net.cpp:406] penlu16 <- Convolution18
I0930 20:04:50.448840  4047 net.cpp:367] penlu16 -> Convolution18 (in-place)
I0930 20:04:50.448956  4047 net.cpp:122] Setting up penlu16
I0930 20:04:50.448961  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.448962  4047 net.cpp:137] Memory required for data: 404276400
I0930 20:04:50.448967  4047 layer_factory.hpp:77] Creating layer Convolution19
I0930 20:04:50.448974  4047 net.cpp:84] Creating Layer Convolution19
I0930 20:04:50.448976  4047 net.cpp:406] Convolution19 <- Convolution18
I0930 20:04:50.448981  4047 net.cpp:380] Convolution19 -> Convolution19
I0930 20:04:50.450683  4047 net.cpp:122] Setting up Convolution19
I0930 20:04:50.450692  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.450695  4047 net.cpp:137] Memory required for data: 405914800
I0930 20:04:50.450700  4047 layer_factory.hpp:77] Creating layer BatchNorm19
I0930 20:04:50.450704  4047 net.cpp:84] Creating Layer BatchNorm19
I0930 20:04:50.450707  4047 net.cpp:406] BatchNorm19 <- Convolution19
I0930 20:04:50.450711  4047 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0930 20:04:50.450853  4047 net.cpp:122] Setting up BatchNorm19
I0930 20:04:50.450857  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.450860  4047 net.cpp:137] Memory required for data: 407553200
I0930 20:04:50.450865  4047 layer_factory.hpp:77] Creating layer Scale19
I0930 20:04:50.450868  4047 net.cpp:84] Creating Layer Scale19
I0930 20:04:50.450871  4047 net.cpp:406] Scale19 <- Convolution19
I0930 20:04:50.450875  4047 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0930 20:04:50.450903  4047 layer_factory.hpp:77] Creating layer Scale19
I0930 20:04:50.450984  4047 net.cpp:122] Setting up Scale19
I0930 20:04:50.450989  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.450990  4047 net.cpp:137] Memory required for data: 409191600
I0930 20:04:50.450994  4047 layer_factory.hpp:77] Creating layer Eltwise8
I0930 20:04:50.450999  4047 net.cpp:84] Creating Layer Eltwise8
I0930 20:04:50.451001  4047 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0930 20:04:50.451004  4047 net.cpp:406] Eltwise8 <- Convolution19
I0930 20:04:50.451007  4047 net.cpp:380] Eltwise8 -> Eltwise8
I0930 20:04:50.451025  4047 net.cpp:122] Setting up Eltwise8
I0930 20:04:50.451027  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.451030  4047 net.cpp:137] Memory required for data: 410830000
I0930 20:04:50.451032  4047 layer_factory.hpp:77] Creating layer penlu17
I0930 20:04:50.451037  4047 net.cpp:84] Creating Layer penlu17
I0930 20:04:50.451040  4047 net.cpp:406] penlu17 <- Eltwise8
I0930 20:04:50.451043  4047 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0930 20:04:50.451158  4047 net.cpp:122] Setting up penlu17
I0930 20:04:50.451161  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.451164  4047 net.cpp:137] Memory required for data: 412468400
I0930 20:04:50.451167  4047 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0930 20:04:50.451172  4047 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0930 20:04:50.451174  4047 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0930 20:04:50.451177  4047 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0930 20:04:50.451181  4047 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0930 20:04:50.451205  4047 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0930 20:04:50.451215  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.451218  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.451220  4047 net.cpp:137] Memory required for data: 415745200
I0930 20:04:50.451223  4047 layer_factory.hpp:77] Creating layer Convolution20
I0930 20:04:50.451230  4047 net.cpp:84] Creating Layer Convolution20
I0930 20:04:50.451231  4047 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I0930 20:04:50.451237  4047 net.cpp:380] Convolution20 -> Convolution20
I0930 20:04:50.453253  4047 net.cpp:122] Setting up Convolution20
I0930 20:04:50.453261  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.453264  4047 net.cpp:137] Memory required for data: 417383600
I0930 20:04:50.453269  4047 layer_factory.hpp:77] Creating layer BatchNorm20
I0930 20:04:50.453274  4047 net.cpp:84] Creating Layer BatchNorm20
I0930 20:04:50.453276  4047 net.cpp:406] BatchNorm20 <- Convolution20
I0930 20:04:50.453280  4047 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0930 20:04:50.453426  4047 net.cpp:122] Setting up BatchNorm20
I0930 20:04:50.453430  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.453433  4047 net.cpp:137] Memory required for data: 419022000
I0930 20:04:50.453438  4047 layer_factory.hpp:77] Creating layer Scale20
I0930 20:04:50.453441  4047 net.cpp:84] Creating Layer Scale20
I0930 20:04:50.453444  4047 net.cpp:406] Scale20 <- Convolution20
I0930 20:04:50.453449  4047 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0930 20:04:50.453478  4047 layer_factory.hpp:77] Creating layer Scale20
I0930 20:04:50.453560  4047 net.cpp:122] Setting up Scale20
I0930 20:04:50.453564  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.453567  4047 net.cpp:137] Memory required for data: 420660400
I0930 20:04:50.453570  4047 layer_factory.hpp:77] Creating layer penlu18
I0930 20:04:50.453575  4047 net.cpp:84] Creating Layer penlu18
I0930 20:04:50.453578  4047 net.cpp:406] penlu18 <- Convolution20
I0930 20:04:50.453583  4047 net.cpp:367] penlu18 -> Convolution20 (in-place)
I0930 20:04:50.453694  4047 net.cpp:122] Setting up penlu18
I0930 20:04:50.453699  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.453701  4047 net.cpp:137] Memory required for data: 422298800
I0930 20:04:50.453706  4047 layer_factory.hpp:77] Creating layer Convolution21
I0930 20:04:50.453711  4047 net.cpp:84] Creating Layer Convolution21
I0930 20:04:50.453714  4047 net.cpp:406] Convolution21 <- Convolution20
I0930 20:04:50.453718  4047 net.cpp:380] Convolution21 -> Convolution21
I0930 20:04:50.455762  4047 net.cpp:122] Setting up Convolution21
I0930 20:04:50.455771  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.455773  4047 net.cpp:137] Memory required for data: 423937200
I0930 20:04:50.455778  4047 layer_factory.hpp:77] Creating layer BatchNorm21
I0930 20:04:50.455783  4047 net.cpp:84] Creating Layer BatchNorm21
I0930 20:04:50.455786  4047 net.cpp:406] BatchNorm21 <- Convolution21
I0930 20:04:50.455790  4047 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0930 20:04:50.455929  4047 net.cpp:122] Setting up BatchNorm21
I0930 20:04:50.455934  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.455935  4047 net.cpp:137] Memory required for data: 425575600
I0930 20:04:50.455940  4047 layer_factory.hpp:77] Creating layer Scale21
I0930 20:04:50.455945  4047 net.cpp:84] Creating Layer Scale21
I0930 20:04:50.455947  4047 net.cpp:406] Scale21 <- Convolution21
I0930 20:04:50.455950  4047 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0930 20:04:50.471074  4047 layer_factory.hpp:77] Creating layer Scale21
I0930 20:04:50.471210  4047 net.cpp:122] Setting up Scale21
I0930 20:04:50.471218  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.471222  4047 net.cpp:137] Memory required for data: 427214000
I0930 20:04:50.471230  4047 layer_factory.hpp:77] Creating layer Eltwise9
I0930 20:04:50.471236  4047 net.cpp:84] Creating Layer Eltwise9
I0930 20:04:50.471240  4047 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0930 20:04:50.471256  4047 net.cpp:406] Eltwise9 <- Convolution21
I0930 20:04:50.471263  4047 net.cpp:380] Eltwise9 -> Eltwise9
I0930 20:04:50.471290  4047 net.cpp:122] Setting up Eltwise9
I0930 20:04:50.471297  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.471302  4047 net.cpp:137] Memory required for data: 428852400
I0930 20:04:50.471307  4047 layer_factory.hpp:77] Creating layer penlu19
I0930 20:04:50.471315  4047 net.cpp:84] Creating Layer penlu19
I0930 20:04:50.471319  4047 net.cpp:406] penlu19 <- Eltwise9
I0930 20:04:50.471325  4047 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0930 20:04:50.471510  4047 net.cpp:122] Setting up penlu19
I0930 20:04:50.471519  4047 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:04:50.471524  4047 net.cpp:137] Memory required for data: 430490800
I0930 20:04:50.471532  4047 layer_factory.hpp:77] Creating layer Pooling1
I0930 20:04:50.471539  4047 net.cpp:84] Creating Layer Pooling1
I0930 20:04:50.471544  4047 net.cpp:406] Pooling1 <- Eltwise9
I0930 20:04:50.471551  4047 net.cpp:380] Pooling1 -> Pooling1
I0930 20:04:50.471762  4047 net.cpp:122] Setting up Pooling1
I0930 20:04:50.471772  4047 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0930 20:04:50.471777  4047 net.cpp:137] Memory required for data: 430516400
I0930 20:04:50.471781  4047 layer_factory.hpp:77] Creating layer InnerProduct1
I0930 20:04:50.471791  4047 net.cpp:84] Creating Layer InnerProduct1
I0930 20:04:50.471796  4047 net.cpp:406] InnerProduct1 <- Pooling1
I0930 20:04:50.471802  4047 net.cpp:380] InnerProduct1 -> InnerProduct1
I0930 20:04:50.471954  4047 net.cpp:122] Setting up InnerProduct1
I0930 20:04:50.471962  4047 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:04:50.471966  4047 net.cpp:137] Memory required for data: 430520400
I0930 20:04:50.471974  4047 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0930 20:04:50.471981  4047 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0930 20:04:50.471984  4047 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0930 20:04:50.471992  4047 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0930 20:04:50.472000  4047 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0930 20:04:50.472045  4047 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0930 20:04:50.472051  4047 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:04:50.472056  4047 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:04:50.472060  4047 net.cpp:137] Memory required for data: 430528400
I0930 20:04:50.472064  4047 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:04:50.472071  4047 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0930 20:04:50.472075  4047 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0930 20:04:50.472080  4047 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0930 20:04:50.472085  4047 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0930 20:04:50.472092  4047 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:04:50.472350  4047 net.cpp:122] Setting up SoftmaxWithLoss1
I0930 20:04:50.472359  4047 net.cpp:129] Top shape: (1)
I0930 20:04:50.472363  4047 net.cpp:132]     with loss weight 1
I0930 20:04:50.472374  4047 net.cpp:137] Memory required for data: 430528404
I0930 20:04:50.472378  4047 layer_factory.hpp:77] Creating layer Accuracy1
I0930 20:04:50.472386  4047 net.cpp:84] Creating Layer Accuracy1
I0930 20:04:50.472390  4047 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0930 20:04:50.472396  4047 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0930 20:04:50.472401  4047 net.cpp:380] Accuracy1 -> Accuracy1
I0930 20:04:50.472410  4047 net.cpp:122] Setting up Accuracy1
I0930 20:04:50.472415  4047 net.cpp:129] Top shape: (1)
I0930 20:04:50.472419  4047 net.cpp:137] Memory required for data: 430528408
I0930 20:04:50.472424  4047 net.cpp:200] Accuracy1 does not need backward computation.
I0930 20:04:50.472427  4047 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0930 20:04:50.472440  4047 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0930 20:04:50.472443  4047 net.cpp:198] InnerProduct1 needs backward computation.
I0930 20:04:50.472447  4047 net.cpp:198] Pooling1 needs backward computation.
I0930 20:04:50.472451  4047 net.cpp:198] penlu19 needs backward computation.
I0930 20:04:50.472455  4047 net.cpp:198] Eltwise9 needs backward computation.
I0930 20:04:50.472460  4047 net.cpp:198] Scale21 needs backward computation.
I0930 20:04:50.472463  4047 net.cpp:198] BatchNorm21 needs backward computation.
I0930 20:04:50.472467  4047 net.cpp:198] Convolution21 needs backward computation.
I0930 20:04:50.472470  4047 net.cpp:198] penlu18 needs backward computation.
I0930 20:04:50.472474  4047 net.cpp:198] Scale20 needs backward computation.
I0930 20:04:50.472478  4047 net.cpp:198] BatchNorm20 needs backward computation.
I0930 20:04:50.472481  4047 net.cpp:198] Convolution20 needs backward computation.
I0930 20:04:50.472486  4047 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0930 20:04:50.472489  4047 net.cpp:198] penlu17 needs backward computation.
I0930 20:04:50.472493  4047 net.cpp:198] Eltwise8 needs backward computation.
I0930 20:04:50.472497  4047 net.cpp:198] Scale19 needs backward computation.
I0930 20:04:50.472501  4047 net.cpp:198] BatchNorm19 needs backward computation.
I0930 20:04:50.472506  4047 net.cpp:198] Convolution19 needs backward computation.
I0930 20:04:50.472508  4047 net.cpp:198] penlu16 needs backward computation.
I0930 20:04:50.472512  4047 net.cpp:198] Scale18 needs backward computation.
I0930 20:04:50.472514  4047 net.cpp:198] BatchNorm18 needs backward computation.
I0930 20:04:50.472517  4047 net.cpp:198] Convolution18 needs backward computation.
I0930 20:04:50.472522  4047 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0930 20:04:50.472525  4047 net.cpp:198] penlu15 needs backward computation.
I0930 20:04:50.472532  4047 net.cpp:198] Eltwise7 needs backward computation.
I0930 20:04:50.472535  4047 net.cpp:198] Scale17 needs backward computation.
I0930 20:04:50.472539  4047 net.cpp:198] BatchNorm17 needs backward computation.
I0930 20:04:50.472543  4047 net.cpp:198] Convolution17 needs backward computation.
I0930 20:04:50.472548  4047 net.cpp:198] penlu14 needs backward computation.
I0930 20:04:50.472550  4047 net.cpp:198] Scale16 needs backward computation.
I0930 20:04:50.472554  4047 net.cpp:198] BatchNorm16 needs backward computation.
I0930 20:04:50.472558  4047 net.cpp:198] Convolution16 needs backward computation.
I0930 20:04:50.472563  4047 net.cpp:198] Scale15 needs backward computation.
I0930 20:04:50.472566  4047 net.cpp:198] BatchNorm15 needs backward computation.
I0930 20:04:50.472570  4047 net.cpp:198] Convolution15 needs backward computation.
I0930 20:04:50.472574  4047 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0930 20:04:50.472579  4047 net.cpp:198] penlu13 needs backward computation.
I0930 20:04:50.472582  4047 net.cpp:198] Eltwise6 needs backward computation.
I0930 20:04:50.472586  4047 net.cpp:198] Scale14 needs backward computation.
I0930 20:04:50.472590  4047 net.cpp:198] BatchNorm14 needs backward computation.
I0930 20:04:50.472594  4047 net.cpp:198] Convolution14 needs backward computation.
I0930 20:04:50.472599  4047 net.cpp:198] penlu12 needs backward computation.
I0930 20:04:50.472602  4047 net.cpp:198] Scale13 needs backward computation.
I0930 20:04:50.472605  4047 net.cpp:198] BatchNorm13 needs backward computation.
I0930 20:04:50.473805  4047 net.cpp:198] Convolution13 needs backward computation.
I0930 20:04:50.473822  4047 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0930 20:04:50.473825  4047 net.cpp:198] penlu11 needs backward computation.
I0930 20:04:50.473827  4047 net.cpp:198] Eltwise5 needs backward computation.
I0930 20:04:50.473830  4047 net.cpp:198] Scale12 needs backward computation.
I0930 20:04:50.473832  4047 net.cpp:198] BatchNorm12 needs backward computation.
I0930 20:04:50.473841  4047 net.cpp:198] Convolution12 needs backward computation.
I0930 20:04:50.473845  4047 net.cpp:198] penlu10 needs backward computation.
I0930 20:04:50.473846  4047 net.cpp:198] Scale11 needs backward computation.
I0930 20:04:50.473848  4047 net.cpp:198] BatchNorm11 needs backward computation.
I0930 20:04:50.473850  4047 net.cpp:198] Convolution11 needs backward computation.
I0930 20:04:50.473853  4047 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0930 20:04:50.473855  4047 net.cpp:198] penlu9 needs backward computation.
I0930 20:04:50.473858  4047 net.cpp:198] Eltwise4 needs backward computation.
I0930 20:04:50.473861  4047 net.cpp:198] Scale10 needs backward computation.
I0930 20:04:50.473863  4047 net.cpp:198] BatchNorm10 needs backward computation.
I0930 20:04:50.473865  4047 net.cpp:198] Convolution10 needs backward computation.
I0930 20:04:50.473867  4047 net.cpp:198] penlu8 needs backward computation.
I0930 20:04:50.473870  4047 net.cpp:198] Scale9 needs backward computation.
I0930 20:04:50.473872  4047 net.cpp:198] BatchNorm9 needs backward computation.
I0930 20:04:50.473875  4047 net.cpp:198] Convolution9 needs backward computation.
I0930 20:04:50.473877  4047 net.cpp:198] Scale8 needs backward computation.
I0930 20:04:50.473879  4047 net.cpp:198] BatchNorm8 needs backward computation.
I0930 20:04:50.473881  4047 net.cpp:198] Convolution8 needs backward computation.
I0930 20:04:50.473884  4047 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0930 20:04:50.473886  4047 net.cpp:198] penlu7 needs backward computation.
I0930 20:04:50.473889  4047 net.cpp:198] Eltwise3 needs backward computation.
I0930 20:04:50.473891  4047 net.cpp:198] Scale7 needs backward computation.
I0930 20:04:50.473894  4047 net.cpp:198] BatchNorm7 needs backward computation.
I0930 20:04:50.473896  4047 net.cpp:198] Convolution7 needs backward computation.
I0930 20:04:50.473898  4047 net.cpp:198] penlu6 needs backward computation.
I0930 20:04:50.473901  4047 net.cpp:198] Scale6 needs backward computation.
I0930 20:04:50.473902  4047 net.cpp:198] BatchNorm6 needs backward computation.
I0930 20:04:50.473904  4047 net.cpp:198] Convolution6 needs backward computation.
I0930 20:04:50.473907  4047 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0930 20:04:50.473909  4047 net.cpp:198] penlu5 needs backward computation.
I0930 20:04:50.473912  4047 net.cpp:198] Eltwise2 needs backward computation.
I0930 20:04:50.473915  4047 net.cpp:198] Scale5 needs backward computation.
I0930 20:04:50.473917  4047 net.cpp:198] BatchNorm5 needs backward computation.
I0930 20:04:50.473919  4047 net.cpp:198] Convolution5 needs backward computation.
I0930 20:04:50.473922  4047 net.cpp:198] penlu4 needs backward computation.
I0930 20:04:50.473924  4047 net.cpp:198] Scale4 needs backward computation.
I0930 20:04:50.473927  4047 net.cpp:198] BatchNorm4 needs backward computation.
I0930 20:04:50.473928  4047 net.cpp:198] Convolution4 needs backward computation.
I0930 20:04:50.473932  4047 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0930 20:04:50.473933  4047 net.cpp:198] penlu3 needs backward computation.
I0930 20:04:50.473935  4047 net.cpp:198] Eltwise1 needs backward computation.
I0930 20:04:50.473938  4047 net.cpp:198] Scale3 needs backward computation.
I0930 20:04:50.473940  4047 net.cpp:198] BatchNorm3 needs backward computation.
I0930 20:04:50.473942  4047 net.cpp:198] Convolution3 needs backward computation.
I0930 20:04:50.473945  4047 net.cpp:198] penlu2 needs backward computation.
I0930 20:04:50.473948  4047 net.cpp:198] Scale2 needs backward computation.
I0930 20:04:50.473950  4047 net.cpp:198] BatchNorm2 needs backward computation.
I0930 20:04:50.473953  4047 net.cpp:198] Convolution2 needs backward computation.
I0930 20:04:50.473954  4047 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0930 20:04:50.473958  4047 net.cpp:198] penlu1 needs backward computation.
I0930 20:04:50.473959  4047 net.cpp:198] Scale1 needs backward computation.
I0930 20:04:50.473964  4047 net.cpp:198] BatchNorm1 needs backward computation.
I0930 20:04:50.473966  4047 net.cpp:198] Convolution1 needs backward computation.
I0930 20:04:50.473970  4047 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0930 20:04:50.473973  4047 net.cpp:200] Data1 does not need backward computation.
I0930 20:04:50.473974  4047 net.cpp:242] This network produces output Accuracy1
I0930 20:04:50.473978  4047 net.cpp:242] This network produces output SoftmaxWithLoss1
I0930 20:04:50.474014  4047 net.cpp:255] Network initialization done.
I0930 20:04:50.474288  4047 solver.cpp:56] Solver scaffolding done.
I0930 20:04:50.479630  4047 caffe.cpp:248] Starting Optimization
I0930 20:04:50.479637  4047 solver.cpp:272] Solving resnet_cifar10
I0930 20:04:50.479640  4047 solver.cpp:273] Learning Rate Policy: multistep
I0930 20:04:50.481597  4047 solver.cpp:330] Iteration 0, Testing net (#0)
I0930 20:04:51.705251  4057 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:04:51.754884  4047 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0930 20:04:51.754920  4047 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0930 20:04:51.827754  4047 solver.cpp:218] Iteration 0 (0 iter/s, 1.34804s/100 iters), loss = 2.30869
I0930 20:04:51.827781  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30869 (* 1 = 2.30869 loss)
I0930 20:04:51.827791  4047 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0930 20:04:57.060434  4047 solver.cpp:218] Iteration 100 (19.1109 iter/s, 5.23262s/100 iters), loss = 1.61328
I0930 20:04:57.060463  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.61328 (* 1 = 1.61328 loss)
I0930 20:04:57.060469  4047 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0930 20:05:02.294088  4047 solver.cpp:218] Iteration 200 (19.1074 iter/s, 5.23359s/100 iters), loss = 1.765
I0930 20:05:02.294127  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.765 (* 1 = 1.765 loss)
I0930 20:05:02.294133  4047 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0930 20:05:07.515576  4047 solver.cpp:218] Iteration 300 (19.1519 iter/s, 5.22141s/100 iters), loss = 1.39518
I0930 20:05:07.515614  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.39518 (* 1 = 1.39518 loss)
I0930 20:05:07.515622  4047 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0930 20:05:12.745095  4047 solver.cpp:218] Iteration 400 (19.1226 iter/s, 5.22941s/100 iters), loss = 1.18787
I0930 20:05:12.745124  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.18787 (* 1 = 1.18787 loss)
I0930 20:05:12.745131  4047 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0930 20:05:17.717839  4056 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:05:17.927088  4047 solver.cpp:330] Iteration 500, Testing net (#0)
I0930 20:05:19.113016  4057 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:05:19.163038  4047 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4437
I0930 20:05:19.163072  4047 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.71801 (* 1 = 1.71801 loss)
I0930 20:05:19.215309  4047 solver.cpp:218] Iteration 500 (15.4556 iter/s, 6.47014s/100 iters), loss = 1.22278
I0930 20:05:19.215335  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.22278 (* 1 = 1.22278 loss)
I0930 20:05:19.215342  4047 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0930 20:05:24.450181  4047 solver.cpp:218] Iteration 600 (19.1029 iter/s, 5.23481s/100 iters), loss = 1.10617
I0930 20:05:24.450264  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10617 (* 1 = 1.10617 loss)
I0930 20:05:24.450271  4047 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0930 20:05:29.691717  4047 solver.cpp:218] Iteration 700 (19.0788 iter/s, 5.24142s/100 iters), loss = 1.15362
I0930 20:05:29.691758  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15362 (* 1 = 1.15362 loss)
I0930 20:05:29.691764  4047 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0930 20:05:34.930796  4047 solver.cpp:218] Iteration 800 (19.0876 iter/s, 5.23901s/100 iters), loss = 1.11072
I0930 20:05:34.930825  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11072 (* 1 = 1.11072 loss)
I0930 20:05:34.930831  4047 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0930 20:05:40.163794  4047 solver.cpp:218] Iteration 900 (19.1097 iter/s, 5.23293s/100 iters), loss = 0.894301
I0930 20:05:40.163831  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.894301 (* 1 = 0.894301 loss)
I0930 20:05:40.163851  4047 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0930 20:05:45.143741  4056 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:05:45.353210  4047 solver.cpp:330] Iteration 1000, Testing net (#0)
I0930 20:05:46.543005  4057 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:05:46.593753  4047 solver.cpp:397]     Test net output #0: Accuracy1 = 0.467
I0930 20:05:46.593802  4047 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.71384 (* 1 = 1.71384 loss)
I0930 20:05:46.647552  4047 solver.cpp:218] Iteration 1000 (15.4233 iter/s, 6.48368s/100 iters), loss = 1.03832
I0930 20:05:46.647595  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03832 (* 1 = 1.03832 loss)
I0930 20:05:46.647603  4047 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0930 20:05:51.883267  4047 solver.cpp:218] Iteration 1100 (19.1 iter/s, 5.23561s/100 iters), loss = 0.898047
I0930 20:05:51.883298  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.898047 (* 1 = 0.898047 loss)
I0930 20:05:51.883314  4047 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0930 20:05:57.113932  4047 solver.cpp:218] Iteration 1200 (19.1183 iter/s, 5.2306s/100 iters), loss = 0.978026
I0930 20:05:57.114050  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.978026 (* 1 = 0.978026 loss)
I0930 20:05:57.114058  4047 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0930 20:06:02.334393  4047 solver.cpp:218] Iteration 1300 (19.1559 iter/s, 5.22031s/100 iters), loss = 87.3365
I0930 20:06:02.334426  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0930 20:06:02.334445  4047 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0930 20:06:07.545289  4047 solver.cpp:218] Iteration 1400 (19.1908 iter/s, 5.21083s/100 iters), loss = 87.3365
I0930 20:06:07.545330  4047 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0930 20:06:07.545341  4047 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0930 20:06:12.496260  4056 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:06:12.704849  4047 solver.cpp:330] Iteration 1500, Testing net (#0)
I0930 20:06:13.872570  4057 data_layer.cpp:73] Restarting data prefetching from start.
