I1001 09:18:30.927386  4916 caffe.cpp:218] Using GPUs 0
I1001 09:18:30.952138  4916 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1001 09:18:31.181262  4916 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res20/res20_relu_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_cifar_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1001 09:18:31.181413  4916 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_cifar_train_test.prototxt
I1001 09:18:31.182596  4916 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_cifar_train_test.prototxt
I1001 09:18:31.182606  4916 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1001 09:18:31.182734  4916 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1001 09:18:31.182799  4916 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1001 09:18:31.183154  4916 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1001 09:18:31.183555  4916 layer_factory.hpp:77] Creating layer Data1
I1001 09:18:31.183650  4916 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1001 09:18:31.183673  4916 net.cpp:84] Creating Layer Data1
I1001 09:18:31.183681  4916 net.cpp:380] Data1 -> Data1
I1001 09:18:31.183701  4916 net.cpp:380] Data1 -> Data2
I1001 09:18:31.183712  4916 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1001 09:18:31.185133  4916 data_layer.cpp:45] output data size: 100,3,28,28
I1001 09:18:31.187435  4916 net.cpp:122] Setting up Data1
I1001 09:18:31.187460  4916 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1001 09:18:31.187465  4916 net.cpp:129] Top shape: 100 (100)
I1001 09:18:31.187467  4916 net.cpp:137] Memory required for data: 941200
I1001 09:18:31.187474  4916 layer_factory.hpp:77] Creating layer Convolution1
I1001 09:18:31.187492  4916 net.cpp:84] Creating Layer Convolution1
I1001 09:18:31.187499  4916 net.cpp:406] Convolution1 <- Data1
I1001 09:18:31.187507  4916 net.cpp:380] Convolution1 -> Convolution1
I1001 09:18:31.333942  4916 net.cpp:122] Setting up Convolution1
I1001 09:18:31.333967  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.333971  4916 net.cpp:137] Memory required for data: 5958800
I1001 09:18:31.333986  4916 layer_factory.hpp:77] Creating layer BatchNorm1
I1001 09:18:31.334007  4916 net.cpp:84] Creating Layer BatchNorm1
I1001 09:18:31.334010  4916 net.cpp:406] BatchNorm1 <- Convolution1
I1001 09:18:31.334026  4916 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1001 09:18:31.334173  4916 net.cpp:122] Setting up BatchNorm1
I1001 09:18:31.334179  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.334182  4916 net.cpp:137] Memory required for data: 10976400
I1001 09:18:31.334189  4916 layer_factory.hpp:77] Creating layer Scale1
I1001 09:18:31.334214  4916 net.cpp:84] Creating Layer Scale1
I1001 09:18:31.334218  4916 net.cpp:406] Scale1 <- Convolution1
I1001 09:18:31.334223  4916 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1001 09:18:31.334264  4916 layer_factory.hpp:77] Creating layer Scale1
I1001 09:18:31.334364  4916 net.cpp:122] Setting up Scale1
I1001 09:18:31.334370  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.334375  4916 net.cpp:137] Memory required for data: 15994000
I1001 09:18:31.334393  4916 layer_factory.hpp:77] Creating layer ReLU1
I1001 09:18:31.334401  4916 net.cpp:84] Creating Layer ReLU1
I1001 09:18:31.334405  4916 net.cpp:406] ReLU1 <- Convolution1
I1001 09:18:31.334411  4916 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1001 09:18:31.334575  4916 net.cpp:122] Setting up ReLU1
I1001 09:18:31.334584  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.334589  4916 net.cpp:137] Memory required for data: 21011600
I1001 09:18:31.334604  4916 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1001 09:18:31.334611  4916 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1001 09:18:31.334615  4916 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1001 09:18:31.334621  4916 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1001 09:18:31.334630  4916 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1001 09:18:31.334666  4916 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1001 09:18:31.334671  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.334687  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.334692  4916 net.cpp:137] Memory required for data: 31046800
I1001 09:18:31.334697  4916 layer_factory.hpp:77] Creating layer Convolution2
I1001 09:18:31.334707  4916 net.cpp:84] Creating Layer Convolution2
I1001 09:18:31.334710  4916 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1001 09:18:31.334717  4916 net.cpp:380] Convolution2 -> Convolution2
I1001 09:18:31.335546  4916 net.cpp:122] Setting up Convolution2
I1001 09:18:31.335557  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.335573  4916 net.cpp:137] Memory required for data: 36064400
I1001 09:18:31.335583  4916 layer_factory.hpp:77] Creating layer BatchNorm2
I1001 09:18:31.335590  4916 net.cpp:84] Creating Layer BatchNorm2
I1001 09:18:31.335595  4916 net.cpp:406] BatchNorm2 <- Convolution2
I1001 09:18:31.335602  4916 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1001 09:18:31.335728  4916 net.cpp:122] Setting up BatchNorm2
I1001 09:18:31.335734  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.335737  4916 net.cpp:137] Memory required for data: 41082000
I1001 09:18:31.335753  4916 layer_factory.hpp:77] Creating layer Scale2
I1001 09:18:31.335759  4916 net.cpp:84] Creating Layer Scale2
I1001 09:18:31.335763  4916 net.cpp:406] Scale2 <- Convolution2
I1001 09:18:31.335767  4916 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1001 09:18:31.335803  4916 layer_factory.hpp:77] Creating layer Scale2
I1001 09:18:31.335892  4916 net.cpp:122] Setting up Scale2
I1001 09:18:31.335898  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.335903  4916 net.cpp:137] Memory required for data: 46099600
I1001 09:18:31.335921  4916 layer_factory.hpp:77] Creating layer ReLU2
I1001 09:18:31.335927  4916 net.cpp:84] Creating Layer ReLU2
I1001 09:18:31.335930  4916 net.cpp:406] ReLU2 <- Convolution2
I1001 09:18:31.335937  4916 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1001 09:18:31.336364  4916 net.cpp:122] Setting up ReLU2
I1001 09:18:31.336374  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.336378  4916 net.cpp:137] Memory required for data: 51117200
I1001 09:18:31.336383  4916 layer_factory.hpp:77] Creating layer Convolution3
I1001 09:18:31.336393  4916 net.cpp:84] Creating Layer Convolution3
I1001 09:18:31.336397  4916 net.cpp:406] Convolution3 <- Convolution2
I1001 09:18:31.336405  4916 net.cpp:380] Convolution3 -> Convolution3
I1001 09:18:31.336899  4916 net.cpp:122] Setting up Convolution3
I1001 09:18:31.336908  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.336913  4916 net.cpp:137] Memory required for data: 56134800
I1001 09:18:31.336921  4916 layer_factory.hpp:77] Creating layer BatchNorm3
I1001 09:18:31.336927  4916 net.cpp:84] Creating Layer BatchNorm3
I1001 09:18:31.336931  4916 net.cpp:406] BatchNorm3 <- Convolution3
I1001 09:18:31.336937  4916 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1001 09:18:31.337052  4916 net.cpp:122] Setting up BatchNorm3
I1001 09:18:31.337059  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.337062  4916 net.cpp:137] Memory required for data: 61152400
I1001 09:18:31.337072  4916 layer_factory.hpp:77] Creating layer Scale3
I1001 09:18:31.337096  4916 net.cpp:84] Creating Layer Scale3
I1001 09:18:31.337110  4916 net.cpp:406] Scale3 <- Convolution3
I1001 09:18:31.337116  4916 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1001 09:18:31.337143  4916 layer_factory.hpp:77] Creating layer Scale3
I1001 09:18:31.337215  4916 net.cpp:122] Setting up Scale3
I1001 09:18:31.337221  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.337225  4916 net.cpp:137] Memory required for data: 66170000
I1001 09:18:31.337232  4916 layer_factory.hpp:77] Creating layer Eltwise1
I1001 09:18:31.337239  4916 net.cpp:84] Creating Layer Eltwise1
I1001 09:18:31.337242  4916 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1001 09:18:31.337247  4916 net.cpp:406] Eltwise1 <- Convolution3
I1001 09:18:31.337254  4916 net.cpp:380] Eltwise1 -> Eltwise1
I1001 09:18:31.337272  4916 net.cpp:122] Setting up Eltwise1
I1001 09:18:31.337277  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.337281  4916 net.cpp:137] Memory required for data: 71187600
I1001 09:18:31.337286  4916 layer_factory.hpp:77] Creating layer ReLU3
I1001 09:18:31.337292  4916 net.cpp:84] Creating Layer ReLU3
I1001 09:18:31.337296  4916 net.cpp:406] ReLU3 <- Eltwise1
I1001 09:18:31.337302  4916 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1001 09:18:31.337725  4916 net.cpp:122] Setting up ReLU3
I1001 09:18:31.337735  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.337740  4916 net.cpp:137] Memory required for data: 76205200
I1001 09:18:31.337745  4916 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1001 09:18:31.337751  4916 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1001 09:18:31.337756  4916 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1001 09:18:31.337762  4916 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1001 09:18:31.337769  4916 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1001 09:18:31.337796  4916 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1001 09:18:31.337802  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.337807  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.337811  4916 net.cpp:137] Memory required for data: 86240400
I1001 09:18:31.337815  4916 layer_factory.hpp:77] Creating layer Convolution4
I1001 09:18:31.337826  4916 net.cpp:84] Creating Layer Convolution4
I1001 09:18:31.337829  4916 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1001 09:18:31.337836  4916 net.cpp:380] Convolution4 -> Convolution4
I1001 09:18:31.338657  4916 net.cpp:122] Setting up Convolution4
I1001 09:18:31.338668  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.338675  4916 net.cpp:137] Memory required for data: 91258000
I1001 09:18:31.338682  4916 layer_factory.hpp:77] Creating layer BatchNorm4
I1001 09:18:31.338688  4916 net.cpp:84] Creating Layer BatchNorm4
I1001 09:18:31.338692  4916 net.cpp:406] BatchNorm4 <- Convolution4
I1001 09:18:31.338699  4916 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1001 09:18:31.338814  4916 net.cpp:122] Setting up BatchNorm4
I1001 09:18:31.338819  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.338824  4916 net.cpp:137] Memory required for data: 96275600
I1001 09:18:31.338831  4916 layer_factory.hpp:77] Creating layer Scale4
I1001 09:18:31.338837  4916 net.cpp:84] Creating Layer Scale4
I1001 09:18:31.338841  4916 net.cpp:406] Scale4 <- Convolution4
I1001 09:18:31.338847  4916 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1001 09:18:31.338874  4916 layer_factory.hpp:77] Creating layer Scale4
I1001 09:18:31.338943  4916 net.cpp:122] Setting up Scale4
I1001 09:18:31.338949  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.338953  4916 net.cpp:137] Memory required for data: 101293200
I1001 09:18:31.338960  4916 layer_factory.hpp:77] Creating layer ReLU4
I1001 09:18:31.338965  4916 net.cpp:84] Creating Layer ReLU4
I1001 09:18:31.338970  4916 net.cpp:406] ReLU4 <- Convolution4
I1001 09:18:31.338975  4916 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1001 09:18:31.339107  4916 net.cpp:122] Setting up ReLU4
I1001 09:18:31.339115  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.339120  4916 net.cpp:137] Memory required for data: 106310800
I1001 09:18:31.339124  4916 layer_factory.hpp:77] Creating layer Convolution5
I1001 09:18:31.339133  4916 net.cpp:84] Creating Layer Convolution5
I1001 09:18:31.339138  4916 net.cpp:406] Convolution5 <- Convolution4
I1001 09:18:31.339144  4916 net.cpp:380] Convolution5 -> Convolution5
I1001 09:18:31.339952  4916 net.cpp:122] Setting up Convolution5
I1001 09:18:31.339963  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.339968  4916 net.cpp:137] Memory required for data: 111328400
I1001 09:18:31.339975  4916 layer_factory.hpp:77] Creating layer BatchNorm5
I1001 09:18:31.339982  4916 net.cpp:84] Creating Layer BatchNorm5
I1001 09:18:31.339987  4916 net.cpp:406] BatchNorm5 <- Convolution5
I1001 09:18:31.339993  4916 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1001 09:18:31.340111  4916 net.cpp:122] Setting up BatchNorm5
I1001 09:18:31.340117  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.340121  4916 net.cpp:137] Memory required for data: 116346000
I1001 09:18:31.340132  4916 layer_factory.hpp:77] Creating layer Scale5
I1001 09:18:31.340138  4916 net.cpp:84] Creating Layer Scale5
I1001 09:18:31.340142  4916 net.cpp:406] Scale5 <- Convolution5
I1001 09:18:31.340147  4916 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1001 09:18:31.340175  4916 layer_factory.hpp:77] Creating layer Scale5
I1001 09:18:31.340246  4916 net.cpp:122] Setting up Scale5
I1001 09:18:31.340251  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.340255  4916 net.cpp:137] Memory required for data: 121363600
I1001 09:18:31.340262  4916 layer_factory.hpp:77] Creating layer Eltwise2
I1001 09:18:31.340268  4916 net.cpp:84] Creating Layer Eltwise2
I1001 09:18:31.340272  4916 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1001 09:18:31.340278  4916 net.cpp:406] Eltwise2 <- Convolution5
I1001 09:18:31.340283  4916 net.cpp:380] Eltwise2 -> Eltwise2
I1001 09:18:31.340301  4916 net.cpp:122] Setting up Eltwise2
I1001 09:18:31.340306  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.340309  4916 net.cpp:137] Memory required for data: 126381200
I1001 09:18:31.340314  4916 layer_factory.hpp:77] Creating layer ReLU5
I1001 09:18:31.340320  4916 net.cpp:84] Creating Layer ReLU5
I1001 09:18:31.340324  4916 net.cpp:406] ReLU5 <- Eltwise2
I1001 09:18:31.340329  4916 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1001 09:18:31.340435  4916 net.cpp:122] Setting up ReLU5
I1001 09:18:31.340441  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.340446  4916 net.cpp:137] Memory required for data: 131398800
I1001 09:18:31.340451  4916 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1001 09:18:31.340456  4916 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1001 09:18:31.340461  4916 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1001 09:18:31.340466  4916 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1001 09:18:31.340473  4916 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1001 09:18:31.340497  4916 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1001 09:18:31.340502  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.340507  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.340512  4916 net.cpp:137] Memory required for data: 141434000
I1001 09:18:31.340517  4916 layer_factory.hpp:77] Creating layer Convolution6
I1001 09:18:31.340525  4916 net.cpp:84] Creating Layer Convolution6
I1001 09:18:31.340528  4916 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1001 09:18:31.340535  4916 net.cpp:380] Convolution6 -> Convolution6
I1001 09:18:31.341346  4916 net.cpp:122] Setting up Convolution6
I1001 09:18:31.341356  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.341362  4916 net.cpp:137] Memory required for data: 146451600
I1001 09:18:31.341369  4916 layer_factory.hpp:77] Creating layer BatchNorm6
I1001 09:18:31.341382  4916 net.cpp:84] Creating Layer BatchNorm6
I1001 09:18:31.341387  4916 net.cpp:406] BatchNorm6 <- Convolution6
I1001 09:18:31.341394  4916 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1001 09:18:31.341516  4916 net.cpp:122] Setting up BatchNorm6
I1001 09:18:31.341521  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.341526  4916 net.cpp:137] Memory required for data: 151469200
I1001 09:18:31.341534  4916 layer_factory.hpp:77] Creating layer Scale6
I1001 09:18:31.341540  4916 net.cpp:84] Creating Layer Scale6
I1001 09:18:31.341544  4916 net.cpp:406] Scale6 <- Convolution6
I1001 09:18:31.341550  4916 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1001 09:18:31.341578  4916 layer_factory.hpp:77] Creating layer Scale6
I1001 09:18:31.341650  4916 net.cpp:122] Setting up Scale6
I1001 09:18:31.341655  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.341660  4916 net.cpp:137] Memory required for data: 156486800
I1001 09:18:31.341665  4916 layer_factory.hpp:77] Creating layer ReLU6
I1001 09:18:31.341671  4916 net.cpp:84] Creating Layer ReLU6
I1001 09:18:31.341675  4916 net.cpp:406] ReLU6 <- Convolution6
I1001 09:18:31.341681  4916 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1001 09:18:31.341786  4916 net.cpp:122] Setting up ReLU6
I1001 09:18:31.341794  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.341799  4916 net.cpp:137] Memory required for data: 161504400
I1001 09:18:31.341804  4916 layer_factory.hpp:77] Creating layer Convolution7
I1001 09:18:31.341812  4916 net.cpp:84] Creating Layer Convolution7
I1001 09:18:31.341815  4916 net.cpp:406] Convolution7 <- Convolution6
I1001 09:18:31.341822  4916 net.cpp:380] Convolution7 -> Convolution7
I1001 09:18:31.342670  4916 net.cpp:122] Setting up Convolution7
I1001 09:18:31.342681  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.342687  4916 net.cpp:137] Memory required for data: 166522000
I1001 09:18:31.342692  4916 layer_factory.hpp:77] Creating layer BatchNorm7
I1001 09:18:31.342700  4916 net.cpp:84] Creating Layer BatchNorm7
I1001 09:18:31.342703  4916 net.cpp:406] BatchNorm7 <- Convolution7
I1001 09:18:31.342710  4916 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1001 09:18:31.342835  4916 net.cpp:122] Setting up BatchNorm7
I1001 09:18:31.342842  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.342846  4916 net.cpp:137] Memory required for data: 171539600
I1001 09:18:31.342854  4916 layer_factory.hpp:77] Creating layer Scale7
I1001 09:18:31.342864  4916 net.cpp:84] Creating Layer Scale7
I1001 09:18:31.342866  4916 net.cpp:406] Scale7 <- Convolution7
I1001 09:18:31.342872  4916 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1001 09:18:31.342901  4916 layer_factory.hpp:77] Creating layer Scale7
I1001 09:18:31.342975  4916 net.cpp:122] Setting up Scale7
I1001 09:18:31.342981  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.342985  4916 net.cpp:137] Memory required for data: 176557200
I1001 09:18:31.342993  4916 layer_factory.hpp:77] Creating layer Eltwise3
I1001 09:18:31.342999  4916 net.cpp:84] Creating Layer Eltwise3
I1001 09:18:31.343003  4916 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1001 09:18:31.343008  4916 net.cpp:406] Eltwise3 <- Convolution7
I1001 09:18:31.343014  4916 net.cpp:380] Eltwise3 -> Eltwise3
I1001 09:18:31.343032  4916 net.cpp:122] Setting up Eltwise3
I1001 09:18:31.343039  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.343052  4916 net.cpp:137] Memory required for data: 181574800
I1001 09:18:31.343056  4916 layer_factory.hpp:77] Creating layer ReLU7
I1001 09:18:31.343063  4916 net.cpp:84] Creating Layer ReLU7
I1001 09:18:31.343067  4916 net.cpp:406] ReLU7 <- Eltwise3
I1001 09:18:31.343072  4916 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1001 09:18:31.343195  4916 net.cpp:122] Setting up ReLU7
I1001 09:18:31.343204  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.343207  4916 net.cpp:137] Memory required for data: 186592400
I1001 09:18:31.343212  4916 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1001 09:18:31.343225  4916 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1001 09:18:31.343230  4916 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1001 09:18:31.343237  4916 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1001 09:18:31.343243  4916 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1001 09:18:31.343271  4916 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1001 09:18:31.343277  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.343282  4916 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1001 09:18:31.343286  4916 net.cpp:137] Memory required for data: 196627600
I1001 09:18:31.343291  4916 layer_factory.hpp:77] Creating layer Convolution8
I1001 09:18:31.343300  4916 net.cpp:84] Creating Layer Convolution8
I1001 09:18:31.343304  4916 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1001 09:18:31.343312  4916 net.cpp:380] Convolution8 -> Convolution8
I1001 09:18:31.344449  4916 net.cpp:122] Setting up Convolution8
I1001 09:18:31.344460  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.344475  4916 net.cpp:137] Memory required for data: 199136400
I1001 09:18:31.344485  4916 layer_factory.hpp:77] Creating layer BatchNorm8
I1001 09:18:31.344491  4916 net.cpp:84] Creating Layer BatchNorm8
I1001 09:18:31.344496  4916 net.cpp:406] BatchNorm8 <- Convolution8
I1001 09:18:31.344511  4916 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1001 09:18:31.344642  4916 net.cpp:122] Setting up BatchNorm8
I1001 09:18:31.344650  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.344653  4916 net.cpp:137] Memory required for data: 201645200
I1001 09:18:31.344661  4916 layer_factory.hpp:77] Creating layer Scale8
I1001 09:18:31.344667  4916 net.cpp:84] Creating Layer Scale8
I1001 09:18:31.344671  4916 net.cpp:406] Scale8 <- Convolution8
I1001 09:18:31.344677  4916 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1001 09:18:31.344707  4916 layer_factory.hpp:77] Creating layer Scale8
I1001 09:18:31.344779  4916 net.cpp:122] Setting up Scale8
I1001 09:18:31.344786  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.344790  4916 net.cpp:137] Memory required for data: 204154000
I1001 09:18:31.344797  4916 layer_factory.hpp:77] Creating layer Convolution9
I1001 09:18:31.344807  4916 net.cpp:84] Creating Layer Convolution9
I1001 09:18:31.344811  4916 net.cpp:406] Convolution9 <- Eltwise3_ReLU7_0_split_1
I1001 09:18:31.344818  4916 net.cpp:380] Convolution9 -> Convolution9
I1001 09:18:31.346726  4916 net.cpp:122] Setting up Convolution9
I1001 09:18:31.346738  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.346741  4916 net.cpp:137] Memory required for data: 206662800
I1001 09:18:31.346757  4916 layer_factory.hpp:77] Creating layer BatchNorm9
I1001 09:18:31.346762  4916 net.cpp:84] Creating Layer BatchNorm9
I1001 09:18:31.346766  4916 net.cpp:406] BatchNorm9 <- Convolution9
I1001 09:18:31.346781  4916 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1001 09:18:31.346930  4916 net.cpp:122] Setting up BatchNorm9
I1001 09:18:31.346935  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.346936  4916 net.cpp:137] Memory required for data: 209171600
I1001 09:18:31.346941  4916 layer_factory.hpp:77] Creating layer Scale9
I1001 09:18:31.346946  4916 net.cpp:84] Creating Layer Scale9
I1001 09:18:31.346958  4916 net.cpp:406] Scale9 <- Convolution9
I1001 09:18:31.346963  4916 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1001 09:18:31.347008  4916 layer_factory.hpp:77] Creating layer Scale9
I1001 09:18:31.347103  4916 net.cpp:122] Setting up Scale9
I1001 09:18:31.347110  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.347112  4916 net.cpp:137] Memory required for data: 211680400
I1001 09:18:31.347115  4916 layer_factory.hpp:77] Creating layer ReLU8
I1001 09:18:31.347121  4916 net.cpp:84] Creating Layer ReLU8
I1001 09:18:31.347122  4916 net.cpp:406] ReLU8 <- Convolution9
I1001 09:18:31.347127  4916 net.cpp:367] ReLU8 -> Convolution9 (in-place)
I1001 09:18:31.347252  4916 net.cpp:122] Setting up ReLU8
I1001 09:18:31.347259  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.347262  4916 net.cpp:137] Memory required for data: 214189200
I1001 09:18:31.347265  4916 layer_factory.hpp:77] Creating layer Convolution10
I1001 09:18:31.347272  4916 net.cpp:84] Creating Layer Convolution10
I1001 09:18:31.347276  4916 net.cpp:406] Convolution10 <- Convolution9
I1001 09:18:31.347281  4916 net.cpp:380] Convolution10 -> Convolution10
I1001 09:18:31.348466  4916 net.cpp:122] Setting up Convolution10
I1001 09:18:31.348476  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.348489  4916 net.cpp:137] Memory required for data: 216698000
I1001 09:18:31.348500  4916 layer_factory.hpp:77] Creating layer BatchNorm10
I1001 09:18:31.348516  4916 net.cpp:84] Creating Layer BatchNorm10
I1001 09:18:31.348520  4916 net.cpp:406] BatchNorm10 <- Convolution10
I1001 09:18:31.348533  4916 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1001 09:18:31.348665  4916 net.cpp:122] Setting up BatchNorm10
I1001 09:18:31.348671  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.348683  4916 net.cpp:137] Memory required for data: 219206800
I1001 09:18:31.348688  4916 layer_factory.hpp:77] Creating layer Scale10
I1001 09:18:31.348693  4916 net.cpp:84] Creating Layer Scale10
I1001 09:18:31.348696  4916 net.cpp:406] Scale10 <- Convolution10
I1001 09:18:31.348701  4916 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1001 09:18:31.348726  4916 layer_factory.hpp:77] Creating layer Scale10
I1001 09:18:31.348801  4916 net.cpp:122] Setting up Scale10
I1001 09:18:31.348808  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.348809  4916 net.cpp:137] Memory required for data: 221715600
I1001 09:18:31.348814  4916 layer_factory.hpp:77] Creating layer Eltwise4
I1001 09:18:31.348819  4916 net.cpp:84] Creating Layer Eltwise4
I1001 09:18:31.348824  4916 net.cpp:406] Eltwise4 <- Convolution8
I1001 09:18:31.348826  4916 net.cpp:406] Eltwise4 <- Convolution10
I1001 09:18:31.348830  4916 net.cpp:380] Eltwise4 -> Eltwise4
I1001 09:18:31.348846  4916 net.cpp:122] Setting up Eltwise4
I1001 09:18:31.348851  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.348855  4916 net.cpp:137] Memory required for data: 224224400
I1001 09:18:31.348856  4916 layer_factory.hpp:77] Creating layer ReLU9
I1001 09:18:31.348860  4916 net.cpp:84] Creating Layer ReLU9
I1001 09:18:31.348863  4916 net.cpp:406] ReLU9 <- Eltwise4
I1001 09:18:31.348866  4916 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1001 09:18:31.349299  4916 net.cpp:122] Setting up ReLU9
I1001 09:18:31.349308  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.349313  4916 net.cpp:137] Memory required for data: 226733200
I1001 09:18:31.349314  4916 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1001 09:18:31.349320  4916 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1001 09:18:31.349324  4916 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1001 09:18:31.349328  4916 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1001 09:18:31.349333  4916 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1001 09:18:31.349360  4916 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1001 09:18:31.349365  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.349370  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.349372  4916 net.cpp:137] Memory required for data: 231750800
I1001 09:18:31.349375  4916 layer_factory.hpp:77] Creating layer Convolution11
I1001 09:18:31.349381  4916 net.cpp:84] Creating Layer Convolution11
I1001 09:18:31.349385  4916 net.cpp:406] Convolution11 <- Eltwise4_ReLU9_0_split_0
I1001 09:18:31.349390  4916 net.cpp:380] Convolution11 -> Convolution11
I1001 09:18:31.350097  4916 net.cpp:122] Setting up Convolution11
I1001 09:18:31.350106  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.350109  4916 net.cpp:137] Memory required for data: 234259600
I1001 09:18:31.350114  4916 layer_factory.hpp:77] Creating layer BatchNorm11
I1001 09:18:31.350127  4916 net.cpp:84] Creating Layer BatchNorm11
I1001 09:18:31.350131  4916 net.cpp:406] BatchNorm11 <- Convolution11
I1001 09:18:31.350136  4916 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1001 09:18:31.350262  4916 net.cpp:122] Setting up BatchNorm11
I1001 09:18:31.350267  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.350270  4916 net.cpp:137] Memory required for data: 236768400
I1001 09:18:31.350275  4916 layer_factory.hpp:77] Creating layer Scale11
I1001 09:18:31.350281  4916 net.cpp:84] Creating Layer Scale11
I1001 09:18:31.350283  4916 net.cpp:406] Scale11 <- Convolution11
I1001 09:18:31.350286  4916 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1001 09:18:31.350313  4916 layer_factory.hpp:77] Creating layer Scale11
I1001 09:18:31.350389  4916 net.cpp:122] Setting up Scale11
I1001 09:18:31.350394  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.350397  4916 net.cpp:137] Memory required for data: 239277200
I1001 09:18:31.350401  4916 layer_factory.hpp:77] Creating layer ReLU10
I1001 09:18:31.350407  4916 net.cpp:84] Creating Layer ReLU10
I1001 09:18:31.350410  4916 net.cpp:406] ReLU10 <- Convolution11
I1001 09:18:31.350414  4916 net.cpp:367] ReLU10 -> Convolution11 (in-place)
I1001 09:18:31.350869  4916 net.cpp:122] Setting up ReLU10
I1001 09:18:31.350879  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.350883  4916 net.cpp:137] Memory required for data: 241786000
I1001 09:18:31.350885  4916 layer_factory.hpp:77] Creating layer Convolution12
I1001 09:18:31.350893  4916 net.cpp:84] Creating Layer Convolution12
I1001 09:18:31.350898  4916 net.cpp:406] Convolution12 <- Convolution11
I1001 09:18:31.350901  4916 net.cpp:380] Convolution12 -> Convolution12
I1001 09:18:31.351935  4916 net.cpp:122] Setting up Convolution12
I1001 09:18:31.351945  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.351949  4916 net.cpp:137] Memory required for data: 244294800
I1001 09:18:31.351953  4916 layer_factory.hpp:77] Creating layer BatchNorm12
I1001 09:18:31.351959  4916 net.cpp:84] Creating Layer BatchNorm12
I1001 09:18:31.351963  4916 net.cpp:406] BatchNorm12 <- Convolution12
I1001 09:18:31.351968  4916 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1001 09:18:31.352097  4916 net.cpp:122] Setting up BatchNorm12
I1001 09:18:31.352102  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.352104  4916 net.cpp:137] Memory required for data: 246803600
I1001 09:18:31.352109  4916 layer_factory.hpp:77] Creating layer Scale12
I1001 09:18:31.352114  4916 net.cpp:84] Creating Layer Scale12
I1001 09:18:31.352118  4916 net.cpp:406] Scale12 <- Convolution12
I1001 09:18:31.352121  4916 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1001 09:18:31.352149  4916 layer_factory.hpp:77] Creating layer Scale12
I1001 09:18:31.352222  4916 net.cpp:122] Setting up Scale12
I1001 09:18:31.352227  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.352231  4916 net.cpp:137] Memory required for data: 249312400
I1001 09:18:31.352234  4916 layer_factory.hpp:77] Creating layer Eltwise5
I1001 09:18:31.352241  4916 net.cpp:84] Creating Layer Eltwise5
I1001 09:18:31.352243  4916 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I1001 09:18:31.352246  4916 net.cpp:406] Eltwise5 <- Convolution12
I1001 09:18:31.352250  4916 net.cpp:380] Eltwise5 -> Eltwise5
I1001 09:18:31.352267  4916 net.cpp:122] Setting up Eltwise5
I1001 09:18:31.352272  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.352274  4916 net.cpp:137] Memory required for data: 251821200
I1001 09:18:31.352277  4916 layer_factory.hpp:77] Creating layer ReLU11
I1001 09:18:31.352280  4916 net.cpp:84] Creating Layer ReLU11
I1001 09:18:31.352283  4916 net.cpp:406] ReLU11 <- Eltwise5
I1001 09:18:31.352288  4916 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1001 09:18:31.352401  4916 net.cpp:122] Setting up ReLU11
I1001 09:18:31.352408  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.352411  4916 net.cpp:137] Memory required for data: 254330000
I1001 09:18:31.352421  4916 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1001 09:18:31.352427  4916 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1001 09:18:31.352429  4916 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1001 09:18:31.352434  4916 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1001 09:18:31.352439  4916 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1001 09:18:31.352465  4916 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1001 09:18:31.352470  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.352474  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.352478  4916 net.cpp:137] Memory required for data: 259347600
I1001 09:18:31.352479  4916 layer_factory.hpp:77] Creating layer Convolution13
I1001 09:18:31.352486  4916 net.cpp:84] Creating Layer Convolution13
I1001 09:18:31.352490  4916 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I1001 09:18:31.352494  4916 net.cpp:380] Convolution13 -> Convolution13
I1001 09:18:31.353549  4916 net.cpp:122] Setting up Convolution13
I1001 09:18:31.353559  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.353564  4916 net.cpp:137] Memory required for data: 261856400
I1001 09:18:31.353567  4916 layer_factory.hpp:77] Creating layer BatchNorm13
I1001 09:18:31.353574  4916 net.cpp:84] Creating Layer BatchNorm13
I1001 09:18:31.353577  4916 net.cpp:406] BatchNorm13 <- Convolution13
I1001 09:18:31.353581  4916 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1001 09:18:31.353709  4916 net.cpp:122] Setting up BatchNorm13
I1001 09:18:31.353715  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.353718  4916 net.cpp:137] Memory required for data: 264365200
I1001 09:18:31.353724  4916 layer_factory.hpp:77] Creating layer Scale13
I1001 09:18:31.353727  4916 net.cpp:84] Creating Layer Scale13
I1001 09:18:31.353731  4916 net.cpp:406] Scale13 <- Convolution13
I1001 09:18:31.353734  4916 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1001 09:18:31.353762  4916 layer_factory.hpp:77] Creating layer Scale13
I1001 09:18:31.353837  4916 net.cpp:122] Setting up Scale13
I1001 09:18:31.353842  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.353845  4916 net.cpp:137] Memory required for data: 266874000
I1001 09:18:31.353849  4916 layer_factory.hpp:77] Creating layer ReLU12
I1001 09:18:31.353854  4916 net.cpp:84] Creating Layer ReLU12
I1001 09:18:31.353857  4916 net.cpp:406] ReLU12 <- Convolution13
I1001 09:18:31.353862  4916 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1001 09:18:31.353974  4916 net.cpp:122] Setting up ReLU12
I1001 09:18:31.353981  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.353984  4916 net.cpp:137] Memory required for data: 269382800
I1001 09:18:31.353987  4916 layer_factory.hpp:77] Creating layer Convolution14
I1001 09:18:31.353996  4916 net.cpp:84] Creating Layer Convolution14
I1001 09:18:31.353999  4916 net.cpp:406] Convolution14 <- Convolution13
I1001 09:18:31.354004  4916 net.cpp:380] Convolution14 -> Convolution14
I1001 09:18:31.355068  4916 net.cpp:122] Setting up Convolution14
I1001 09:18:31.355079  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.355083  4916 net.cpp:137] Memory required for data: 271891600
I1001 09:18:31.355103  4916 layer_factory.hpp:77] Creating layer BatchNorm14
I1001 09:18:31.355111  4916 net.cpp:84] Creating Layer BatchNorm14
I1001 09:18:31.355115  4916 net.cpp:406] BatchNorm14 <- Convolution14
I1001 09:18:31.355129  4916 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1001 09:18:31.355260  4916 net.cpp:122] Setting up BatchNorm14
I1001 09:18:31.355267  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.355268  4916 net.cpp:137] Memory required for data: 274400400
I1001 09:18:31.355274  4916 layer_factory.hpp:77] Creating layer Scale14
I1001 09:18:31.355279  4916 net.cpp:84] Creating Layer Scale14
I1001 09:18:31.355283  4916 net.cpp:406] Scale14 <- Convolution14
I1001 09:18:31.355293  4916 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1001 09:18:31.355330  4916 layer_factory.hpp:77] Creating layer Scale14
I1001 09:18:31.355415  4916 net.cpp:122] Setting up Scale14
I1001 09:18:31.355420  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.355423  4916 net.cpp:137] Memory required for data: 276909200
I1001 09:18:31.355427  4916 layer_factory.hpp:77] Creating layer Eltwise6
I1001 09:18:31.355432  4916 net.cpp:84] Creating Layer Eltwise6
I1001 09:18:31.355437  4916 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I1001 09:18:31.355438  4916 net.cpp:406] Eltwise6 <- Convolution14
I1001 09:18:31.355443  4916 net.cpp:380] Eltwise6 -> Eltwise6
I1001 09:18:31.355458  4916 net.cpp:122] Setting up Eltwise6
I1001 09:18:31.355461  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.355463  4916 net.cpp:137] Memory required for data: 279418000
I1001 09:18:31.355465  4916 layer_factory.hpp:77] Creating layer ReLU13
I1001 09:18:31.355468  4916 net.cpp:84] Creating Layer ReLU13
I1001 09:18:31.355471  4916 net.cpp:406] ReLU13 <- Eltwise6
I1001 09:18:31.355474  4916 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1001 09:18:31.355587  4916 net.cpp:122] Setting up ReLU13
I1001 09:18:31.355592  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.355594  4916 net.cpp:137] Memory required for data: 281926800
I1001 09:18:31.355597  4916 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1001 09:18:31.355602  4916 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1001 09:18:31.355605  4916 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1001 09:18:31.355608  4916 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1001 09:18:31.355612  4916 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1001 09:18:31.355638  4916 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1001 09:18:31.355643  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.355645  4916 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1001 09:18:31.355648  4916 net.cpp:137] Memory required for data: 286944400
I1001 09:18:31.355649  4916 layer_factory.hpp:77] Creating layer Convolution15
I1001 09:18:31.355656  4916 net.cpp:84] Creating Layer Convolution15
I1001 09:18:31.355659  4916 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1001 09:18:31.355664  4916 net.cpp:380] Convolution15 -> Convolution15
I1001 09:18:31.356573  4916 net.cpp:122] Setting up Convolution15
I1001 09:18:31.356582  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.356585  4916 net.cpp:137] Memory required for data: 288198800
I1001 09:18:31.356590  4916 layer_factory.hpp:77] Creating layer BatchNorm15
I1001 09:18:31.356595  4916 net.cpp:84] Creating Layer BatchNorm15
I1001 09:18:31.356597  4916 net.cpp:406] BatchNorm15 <- Convolution15
I1001 09:18:31.356601  4916 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1001 09:18:31.356729  4916 net.cpp:122] Setting up BatchNorm15
I1001 09:18:31.356734  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.356735  4916 net.cpp:137] Memory required for data: 289453200
I1001 09:18:31.356739  4916 layer_factory.hpp:77] Creating layer Scale15
I1001 09:18:31.356744  4916 net.cpp:84] Creating Layer Scale15
I1001 09:18:31.356746  4916 net.cpp:406] Scale15 <- Convolution15
I1001 09:18:31.356750  4916 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1001 09:18:31.356776  4916 layer_factory.hpp:77] Creating layer Scale15
I1001 09:18:31.356850  4916 net.cpp:122] Setting up Scale15
I1001 09:18:31.356855  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.356858  4916 net.cpp:137] Memory required for data: 290707600
I1001 09:18:31.356861  4916 layer_factory.hpp:77] Creating layer Convolution16
I1001 09:18:31.356868  4916 net.cpp:84] Creating Layer Convolution16
I1001 09:18:31.356870  4916 net.cpp:406] Convolution16 <- Eltwise6_ReLU13_0_split_1
I1001 09:18:31.356874  4916 net.cpp:380] Convolution16 -> Convolution16
I1001 09:18:31.358662  4916 net.cpp:122] Setting up Convolution16
I1001 09:18:31.358672  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.358681  4916 net.cpp:137] Memory required for data: 291962000
I1001 09:18:31.358686  4916 layer_factory.hpp:77] Creating layer BatchNorm16
I1001 09:18:31.358691  4916 net.cpp:84] Creating Layer BatchNorm16
I1001 09:18:31.358695  4916 net.cpp:406] BatchNorm16 <- Convolution16
I1001 09:18:31.358698  4916 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1001 09:18:31.358830  4916 net.cpp:122] Setting up BatchNorm16
I1001 09:18:31.358834  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.358837  4916 net.cpp:137] Memory required for data: 293216400
I1001 09:18:31.358841  4916 layer_factory.hpp:77] Creating layer Scale16
I1001 09:18:31.358845  4916 net.cpp:84] Creating Layer Scale16
I1001 09:18:31.358849  4916 net.cpp:406] Scale16 <- Convolution16
I1001 09:18:31.358851  4916 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1001 09:18:31.358880  4916 layer_factory.hpp:77] Creating layer Scale16
I1001 09:18:31.358952  4916 net.cpp:122] Setting up Scale16
I1001 09:18:31.358958  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.358959  4916 net.cpp:137] Memory required for data: 294470800
I1001 09:18:31.358963  4916 layer_factory.hpp:77] Creating layer ReLU14
I1001 09:18:31.358968  4916 net.cpp:84] Creating Layer ReLU14
I1001 09:18:31.358969  4916 net.cpp:406] ReLU14 <- Convolution16
I1001 09:18:31.358973  4916 net.cpp:367] ReLU14 -> Convolution16 (in-place)
I1001 09:18:31.359086  4916 net.cpp:122] Setting up ReLU14
I1001 09:18:31.359092  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.359094  4916 net.cpp:137] Memory required for data: 295725200
I1001 09:18:31.359097  4916 layer_factory.hpp:77] Creating layer Convolution17
I1001 09:18:31.359104  4916 net.cpp:84] Creating Layer Convolution17
I1001 09:18:31.359107  4916 net.cpp:406] Convolution17 <- Convolution16
I1001 09:18:31.359112  4916 net.cpp:380] Convolution17 -> Convolution17
I1001 09:18:31.361445  4916 net.cpp:122] Setting up Convolution17
I1001 09:18:31.361465  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.361469  4916 net.cpp:137] Memory required for data: 296979600
I1001 09:18:31.361474  4916 layer_factory.hpp:77] Creating layer BatchNorm17
I1001 09:18:31.361490  4916 net.cpp:84] Creating Layer BatchNorm17
I1001 09:18:31.361492  4916 net.cpp:406] BatchNorm17 <- Convolution17
I1001 09:18:31.361497  4916 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1001 09:18:31.361650  4916 net.cpp:122] Setting up BatchNorm17
I1001 09:18:31.361655  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.361667  4916 net.cpp:137] Memory required for data: 298234000
I1001 09:18:31.361672  4916 layer_factory.hpp:77] Creating layer Scale17
I1001 09:18:31.361687  4916 net.cpp:84] Creating Layer Scale17
I1001 09:18:31.361691  4916 net.cpp:406] Scale17 <- Convolution17
I1001 09:18:31.361696  4916 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1001 09:18:31.361724  4916 layer_factory.hpp:77] Creating layer Scale17
I1001 09:18:31.361819  4916 net.cpp:122] Setting up Scale17
I1001 09:18:31.361826  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.361829  4916 net.cpp:137] Memory required for data: 299488400
I1001 09:18:31.361834  4916 layer_factory.hpp:77] Creating layer Eltwise7
I1001 09:18:31.361840  4916 net.cpp:84] Creating Layer Eltwise7
I1001 09:18:31.361842  4916 net.cpp:406] Eltwise7 <- Convolution15
I1001 09:18:31.361845  4916 net.cpp:406] Eltwise7 <- Convolution17
I1001 09:18:31.361851  4916 net.cpp:380] Eltwise7 -> Eltwise7
I1001 09:18:31.361870  4916 net.cpp:122] Setting up Eltwise7
I1001 09:18:31.361874  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.361877  4916 net.cpp:137] Memory required for data: 300742800
I1001 09:18:31.361879  4916 layer_factory.hpp:77] Creating layer ReLU15
I1001 09:18:31.361883  4916 net.cpp:84] Creating Layer ReLU15
I1001 09:18:31.361886  4916 net.cpp:406] ReLU15 <- Eltwise7
I1001 09:18:31.361888  4916 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1001 09:18:31.362037  4916 net.cpp:122] Setting up ReLU15
I1001 09:18:31.362056  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.362061  4916 net.cpp:137] Memory required for data: 301997200
I1001 09:18:31.362064  4916 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1001 09:18:31.362071  4916 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1001 09:18:31.362078  4916 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1001 09:18:31.362084  4916 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1001 09:18:31.362092  4916 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1001 09:18:31.362134  4916 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1001 09:18:31.362143  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.362149  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.362151  4916 net.cpp:137] Memory required for data: 304506000
I1001 09:18:31.362156  4916 layer_factory.hpp:77] Creating layer Convolution18
I1001 09:18:31.362164  4916 net.cpp:84] Creating Layer Convolution18
I1001 09:18:31.362166  4916 net.cpp:406] Convolution18 <- Eltwise7_ReLU15_0_split_0
I1001 09:18:31.362172  4916 net.cpp:380] Convolution18 -> Convolution18
I1001 09:18:31.363886  4916 net.cpp:122] Setting up Convolution18
I1001 09:18:31.363898  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.363904  4916 net.cpp:137] Memory required for data: 305760400
I1001 09:18:31.363911  4916 layer_factory.hpp:77] Creating layer BatchNorm18
I1001 09:18:31.363922  4916 net.cpp:84] Creating Layer BatchNorm18
I1001 09:18:31.363929  4916 net.cpp:406] BatchNorm18 <- Convolution18
I1001 09:18:31.363945  4916 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1001 09:18:31.364116  4916 net.cpp:122] Setting up BatchNorm18
I1001 09:18:31.364125  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.364128  4916 net.cpp:137] Memory required for data: 307014800
I1001 09:18:31.364146  4916 layer_factory.hpp:77] Creating layer Scale18
I1001 09:18:31.364164  4916 net.cpp:84] Creating Layer Scale18
I1001 09:18:31.364171  4916 net.cpp:406] Scale18 <- Convolution18
I1001 09:18:31.364187  4916 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1001 09:18:31.364241  4916 layer_factory.hpp:77] Creating layer Scale18
I1001 09:18:31.364326  4916 net.cpp:122] Setting up Scale18
I1001 09:18:31.364333  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.364338  4916 net.cpp:137] Memory required for data: 308269200
I1001 09:18:31.364346  4916 layer_factory.hpp:77] Creating layer ReLU16
I1001 09:18:31.364353  4916 net.cpp:84] Creating Layer ReLU16
I1001 09:18:31.364358  4916 net.cpp:406] ReLU16 <- Convolution18
I1001 09:18:31.364364  4916 net.cpp:367] ReLU16 -> Convolution18 (in-place)
I1001 09:18:31.364810  4916 net.cpp:122] Setting up ReLU16
I1001 09:18:31.364830  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.364835  4916 net.cpp:137] Memory required for data: 309523600
I1001 09:18:31.364840  4916 layer_factory.hpp:77] Creating layer Convolution19
I1001 09:18:31.364850  4916 net.cpp:84] Creating Layer Convolution19
I1001 09:18:31.364856  4916 net.cpp:406] Convolution19 <- Convolution18
I1001 09:18:31.364874  4916 net.cpp:380] Convolution19 -> Convolution19
I1001 09:18:31.366853  4916 net.cpp:122] Setting up Convolution19
I1001 09:18:31.366864  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.366869  4916 net.cpp:137] Memory required for data: 310778000
I1001 09:18:31.366888  4916 layer_factory.hpp:77] Creating layer BatchNorm19
I1001 09:18:31.366897  4916 net.cpp:84] Creating Layer BatchNorm19
I1001 09:18:31.366904  4916 net.cpp:406] BatchNorm19 <- Convolution19
I1001 09:18:31.366911  4916 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1001 09:18:31.367059  4916 net.cpp:122] Setting up BatchNorm19
I1001 09:18:31.367067  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.367071  4916 net.cpp:137] Memory required for data: 312032400
I1001 09:18:31.367095  4916 layer_factory.hpp:77] Creating layer Scale19
I1001 09:18:31.367103  4916 net.cpp:84] Creating Layer Scale19
I1001 09:18:31.367115  4916 net.cpp:406] Scale19 <- Convolution19
I1001 09:18:31.367123  4916 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1001 09:18:31.367158  4916 layer_factory.hpp:77] Creating layer Scale19
I1001 09:18:31.367244  4916 net.cpp:122] Setting up Scale19
I1001 09:18:31.367252  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.367256  4916 net.cpp:137] Memory required for data: 313286800
I1001 09:18:31.367264  4916 layer_factory.hpp:77] Creating layer Eltwise8
I1001 09:18:31.367271  4916 net.cpp:84] Creating Layer Eltwise8
I1001 09:18:31.367277  4916 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1001 09:18:31.367283  4916 net.cpp:406] Eltwise8 <- Convolution19
I1001 09:18:31.367290  4916 net.cpp:380] Eltwise8 -> Eltwise8
I1001 09:18:31.367311  4916 net.cpp:122] Setting up Eltwise8
I1001 09:18:31.367318  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.367322  4916 net.cpp:137] Memory required for data: 314541200
I1001 09:18:31.367327  4916 layer_factory.hpp:77] Creating layer ReLU17
I1001 09:18:31.367336  4916 net.cpp:84] Creating Layer ReLU17
I1001 09:18:31.367341  4916 net.cpp:406] ReLU17 <- Eltwise8
I1001 09:18:31.367346  4916 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1001 09:18:31.367467  4916 net.cpp:122] Setting up ReLU17
I1001 09:18:31.367476  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.367480  4916 net.cpp:137] Memory required for data: 315795600
I1001 09:18:31.367486  4916 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1001 09:18:31.367493  4916 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1001 09:18:31.367498  4916 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1001 09:18:31.367504  4916 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1001 09:18:31.367513  4916 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1001 09:18:31.367545  4916 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1001 09:18:31.367552  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.367558  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.367563  4916 net.cpp:137] Memory required for data: 318304400
I1001 09:18:31.367566  4916 layer_factory.hpp:77] Creating layer Convolution20
I1001 09:18:31.367578  4916 net.cpp:84] Creating Layer Convolution20
I1001 09:18:31.367583  4916 net.cpp:406] Convolution20 <- Eltwise8_ReLU17_0_split_0
I1001 09:18:31.367590  4916 net.cpp:380] Convolution20 -> Convolution20
I1001 09:18:31.369217  4916 net.cpp:122] Setting up Convolution20
I1001 09:18:31.369228  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.369233  4916 net.cpp:137] Memory required for data: 319558800
I1001 09:18:31.369240  4916 layer_factory.hpp:77] Creating layer BatchNorm20
I1001 09:18:31.369249  4916 net.cpp:84] Creating Layer BatchNorm20
I1001 09:18:31.369256  4916 net.cpp:406] BatchNorm20 <- Convolution20
I1001 09:18:31.369261  4916 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1001 09:18:31.369398  4916 net.cpp:122] Setting up BatchNorm20
I1001 09:18:31.369405  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.369410  4916 net.cpp:137] Memory required for data: 320813200
I1001 09:18:31.369417  4916 layer_factory.hpp:77] Creating layer Scale20
I1001 09:18:31.369424  4916 net.cpp:84] Creating Layer Scale20
I1001 09:18:31.369429  4916 net.cpp:406] Scale20 <- Convolution20
I1001 09:18:31.369436  4916 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1001 09:18:31.369469  4916 layer_factory.hpp:77] Creating layer Scale20
I1001 09:18:31.369552  4916 net.cpp:122] Setting up Scale20
I1001 09:18:31.369560  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.369563  4916 net.cpp:137] Memory required for data: 322067600
I1001 09:18:31.369570  4916 layer_factory.hpp:77] Creating layer ReLU18
I1001 09:18:31.369578  4916 net.cpp:84] Creating Layer ReLU18
I1001 09:18:31.369583  4916 net.cpp:406] ReLU18 <- Convolution20
I1001 09:18:31.369588  4916 net.cpp:367] ReLU18 -> Convolution20 (in-place)
I1001 09:18:31.369710  4916 net.cpp:122] Setting up ReLU18
I1001 09:18:31.369724  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.369732  4916 net.cpp:137] Memory required for data: 323322000
I1001 09:18:31.369737  4916 layer_factory.hpp:77] Creating layer Convolution21
I1001 09:18:31.369748  4916 net.cpp:84] Creating Layer Convolution21
I1001 09:18:31.369752  4916 net.cpp:406] Convolution21 <- Convolution20
I1001 09:18:31.369756  4916 net.cpp:380] Convolution21 -> Convolution21
I1001 09:18:31.371687  4916 net.cpp:122] Setting up Convolution21
I1001 09:18:31.371695  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.371698  4916 net.cpp:137] Memory required for data: 324576400
I1001 09:18:31.371703  4916 layer_factory.hpp:77] Creating layer BatchNorm21
I1001 09:18:31.371709  4916 net.cpp:84] Creating Layer BatchNorm21
I1001 09:18:31.371712  4916 net.cpp:406] BatchNorm21 <- Convolution21
I1001 09:18:31.371716  4916 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1001 09:18:31.371850  4916 net.cpp:122] Setting up BatchNorm21
I1001 09:18:31.371855  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.371856  4916 net.cpp:137] Memory required for data: 325830800
I1001 09:18:31.371860  4916 layer_factory.hpp:77] Creating layer Scale21
I1001 09:18:31.371865  4916 net.cpp:84] Creating Layer Scale21
I1001 09:18:31.371867  4916 net.cpp:406] Scale21 <- Convolution21
I1001 09:18:31.371870  4916 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1001 09:18:31.371897  4916 layer_factory.hpp:77] Creating layer Scale21
I1001 09:18:31.371973  4916 net.cpp:122] Setting up Scale21
I1001 09:18:31.371978  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.371979  4916 net.cpp:137] Memory required for data: 327085200
I1001 09:18:31.371982  4916 layer_factory.hpp:77] Creating layer Eltwise9
I1001 09:18:31.371987  4916 net.cpp:84] Creating Layer Eltwise9
I1001 09:18:31.371990  4916 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1001 09:18:31.371992  4916 net.cpp:406] Eltwise9 <- Convolution21
I1001 09:18:31.371995  4916 net.cpp:380] Eltwise9 -> Eltwise9
I1001 09:18:31.372011  4916 net.cpp:122] Setting up Eltwise9
I1001 09:18:31.372014  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.372016  4916 net.cpp:137] Memory required for data: 328339600
I1001 09:18:31.372018  4916 layer_factory.hpp:77] Creating layer ReLU19
I1001 09:18:31.372023  4916 net.cpp:84] Creating Layer ReLU19
I1001 09:18:31.372025  4916 net.cpp:406] ReLU19 <- Eltwise9
I1001 09:18:31.372028  4916 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1001 09:18:31.372144  4916 net.cpp:122] Setting up ReLU19
I1001 09:18:31.372150  4916 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1001 09:18:31.372153  4916 net.cpp:137] Memory required for data: 329594000
I1001 09:18:31.372155  4916 layer_factory.hpp:77] Creating layer Pooling1
I1001 09:18:31.372159  4916 net.cpp:84] Creating Layer Pooling1
I1001 09:18:31.372161  4916 net.cpp:406] Pooling1 <- Eltwise9
I1001 09:18:31.372165  4916 net.cpp:380] Pooling1 -> Pooling1
I1001 09:18:31.372304  4916 net.cpp:122] Setting up Pooling1
I1001 09:18:31.372310  4916 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1001 09:18:31.372313  4916 net.cpp:137] Memory required for data: 329619600
I1001 09:18:31.372315  4916 layer_factory.hpp:77] Creating layer InnerProduct1
I1001 09:18:31.372324  4916 net.cpp:84] Creating Layer InnerProduct1
I1001 09:18:31.372328  4916 net.cpp:406] InnerProduct1 <- Pooling1
I1001 09:18:31.372330  4916 net.cpp:380] InnerProduct1 -> InnerProduct1
I1001 09:18:31.372426  4916 net.cpp:122] Setting up InnerProduct1
I1001 09:18:31.372431  4916 net.cpp:129] Top shape: 100 10 (1000)
I1001 09:18:31.372432  4916 net.cpp:137] Memory required for data: 329623600
I1001 09:18:31.372437  4916 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 09:18:31.372440  4916 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1001 09:18:31.372442  4916 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1001 09:18:31.372445  4916 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1001 09:18:31.372450  4916 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1001 09:18:31.372462  4916 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 09:18:31.372953  4916 net.cpp:122] Setting up SoftmaxWithLoss1
I1001 09:18:31.372961  4916 net.cpp:129] Top shape: (1)
I1001 09:18:31.372963  4916 net.cpp:132]     with loss weight 1
I1001 09:18:31.372977  4916 net.cpp:137] Memory required for data: 329623604
I1001 09:18:31.372979  4916 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1001 09:18:31.372982  4916 net.cpp:198] InnerProduct1 needs backward computation.
I1001 09:18:31.372984  4916 net.cpp:198] Pooling1 needs backward computation.
I1001 09:18:31.372987  4916 net.cpp:198] ReLU19 needs backward computation.
I1001 09:18:31.372988  4916 net.cpp:198] Eltwise9 needs backward computation.
I1001 09:18:31.372990  4916 net.cpp:198] Scale21 needs backward computation.
I1001 09:18:31.372992  4916 net.cpp:198] BatchNorm21 needs backward computation.
I1001 09:18:31.372994  4916 net.cpp:198] Convolution21 needs backward computation.
I1001 09:18:31.372997  4916 net.cpp:198] ReLU18 needs backward computation.
I1001 09:18:31.372998  4916 net.cpp:198] Scale20 needs backward computation.
I1001 09:18:31.373000  4916 net.cpp:198] BatchNorm20 needs backward computation.
I1001 09:18:31.373003  4916 net.cpp:198] Convolution20 needs backward computation.
I1001 09:18:31.373004  4916 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1001 09:18:31.373006  4916 net.cpp:198] ReLU17 needs backward computation.
I1001 09:18:31.373008  4916 net.cpp:198] Eltwise8 needs backward computation.
I1001 09:18:31.373010  4916 net.cpp:198] Scale19 needs backward computation.
I1001 09:18:31.373013  4916 net.cpp:198] BatchNorm19 needs backward computation.
I1001 09:18:31.373014  4916 net.cpp:198] Convolution19 needs backward computation.
I1001 09:18:31.373016  4916 net.cpp:198] ReLU16 needs backward computation.
I1001 09:18:31.373018  4916 net.cpp:198] Scale18 needs backward computation.
I1001 09:18:31.373020  4916 net.cpp:198] BatchNorm18 needs backward computation.
I1001 09:18:31.373023  4916 net.cpp:198] Convolution18 needs backward computation.
I1001 09:18:31.373024  4916 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1001 09:18:31.373028  4916 net.cpp:198] ReLU15 needs backward computation.
I1001 09:18:31.373029  4916 net.cpp:198] Eltwise7 needs backward computation.
I1001 09:18:31.373031  4916 net.cpp:198] Scale17 needs backward computation.
I1001 09:18:31.373034  4916 net.cpp:198] BatchNorm17 needs backward computation.
I1001 09:18:31.373035  4916 net.cpp:198] Convolution17 needs backward computation.
I1001 09:18:31.373039  4916 net.cpp:198] ReLU14 needs backward computation.
I1001 09:18:31.373040  4916 net.cpp:198] Scale16 needs backward computation.
I1001 09:18:31.373042  4916 net.cpp:198] BatchNorm16 needs backward computation.
I1001 09:18:31.373044  4916 net.cpp:198] Convolution16 needs backward computation.
I1001 09:18:31.373046  4916 net.cpp:198] Scale15 needs backward computation.
I1001 09:18:31.373049  4916 net.cpp:198] BatchNorm15 needs backward computation.
I1001 09:18:31.373050  4916 net.cpp:198] Convolution15 needs backward computation.
I1001 09:18:31.373054  4916 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1001 09:18:31.373055  4916 net.cpp:198] ReLU13 needs backward computation.
I1001 09:18:31.373057  4916 net.cpp:198] Eltwise6 needs backward computation.
I1001 09:18:31.373060  4916 net.cpp:198] Scale14 needs backward computation.
I1001 09:18:31.373062  4916 net.cpp:198] BatchNorm14 needs backward computation.
I1001 09:18:31.373064  4916 net.cpp:198] Convolution14 needs backward computation.
I1001 09:18:31.373066  4916 net.cpp:198] ReLU12 needs backward computation.
I1001 09:18:31.373070  4916 net.cpp:198] Scale13 needs backward computation.
I1001 09:18:31.373071  4916 net.cpp:198] BatchNorm13 needs backward computation.
I1001 09:18:31.373073  4916 net.cpp:198] Convolution13 needs backward computation.
I1001 09:18:31.373075  4916 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1001 09:18:31.373083  4916 net.cpp:198] ReLU11 needs backward computation.
I1001 09:18:31.373086  4916 net.cpp:198] Eltwise5 needs backward computation.
I1001 09:18:31.373090  4916 net.cpp:198] Scale12 needs backward computation.
I1001 09:18:31.373091  4916 net.cpp:198] BatchNorm12 needs backward computation.
I1001 09:18:31.373093  4916 net.cpp:198] Convolution12 needs backward computation.
I1001 09:18:31.373095  4916 net.cpp:198] ReLU10 needs backward computation.
I1001 09:18:31.373098  4916 net.cpp:198] Scale11 needs backward computation.
I1001 09:18:31.373100  4916 net.cpp:198] BatchNorm11 needs backward computation.
I1001 09:18:31.373102  4916 net.cpp:198] Convolution11 needs backward computation.
I1001 09:18:31.373105  4916 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1001 09:18:31.373106  4916 net.cpp:198] ReLU9 needs backward computation.
I1001 09:18:31.373109  4916 net.cpp:198] Eltwise4 needs backward computation.
I1001 09:18:31.373111  4916 net.cpp:198] Scale10 needs backward computation.
I1001 09:18:31.373114  4916 net.cpp:198] BatchNorm10 needs backward computation.
I1001 09:18:31.373116  4916 net.cpp:198] Convolution10 needs backward computation.
I1001 09:18:31.373118  4916 net.cpp:198] ReLU8 needs backward computation.
I1001 09:18:31.373121  4916 net.cpp:198] Scale9 needs backward computation.
I1001 09:18:31.373123  4916 net.cpp:198] BatchNorm9 needs backward computation.
I1001 09:18:31.373126  4916 net.cpp:198] Convolution9 needs backward computation.
I1001 09:18:31.373128  4916 net.cpp:198] Scale8 needs backward computation.
I1001 09:18:31.373131  4916 net.cpp:198] BatchNorm8 needs backward computation.
I1001 09:18:31.373132  4916 net.cpp:198] Convolution8 needs backward computation.
I1001 09:18:31.373136  4916 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1001 09:18:31.373137  4916 net.cpp:198] ReLU7 needs backward computation.
I1001 09:18:31.373139  4916 net.cpp:198] Eltwise3 needs backward computation.
I1001 09:18:31.373142  4916 net.cpp:198] Scale7 needs backward computation.
I1001 09:18:31.373144  4916 net.cpp:198] BatchNorm7 needs backward computation.
I1001 09:18:31.373147  4916 net.cpp:198] Convolution7 needs backward computation.
I1001 09:18:31.373149  4916 net.cpp:198] ReLU6 needs backward computation.
I1001 09:18:31.373152  4916 net.cpp:198] Scale6 needs backward computation.
I1001 09:18:31.373153  4916 net.cpp:198] BatchNorm6 needs backward computation.
I1001 09:18:31.373155  4916 net.cpp:198] Convolution6 needs backward computation.
I1001 09:18:31.373158  4916 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1001 09:18:31.373160  4916 net.cpp:198] ReLU5 needs backward computation.
I1001 09:18:31.373162  4916 net.cpp:198] Eltwise2 needs backward computation.
I1001 09:18:31.373165  4916 net.cpp:198] Scale5 needs backward computation.
I1001 09:18:31.373167  4916 net.cpp:198] BatchNorm5 needs backward computation.
I1001 09:18:31.373170  4916 net.cpp:198] Convolution5 needs backward computation.
I1001 09:18:31.373172  4916 net.cpp:198] ReLU4 needs backward computation.
I1001 09:18:31.373174  4916 net.cpp:198] Scale4 needs backward computation.
I1001 09:18:31.373176  4916 net.cpp:198] BatchNorm4 needs backward computation.
I1001 09:18:31.373178  4916 net.cpp:198] Convolution4 needs backward computation.
I1001 09:18:31.373180  4916 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1001 09:18:31.373183  4916 net.cpp:198] ReLU3 needs backward computation.
I1001 09:18:31.373185  4916 net.cpp:198] Eltwise1 needs backward computation.
I1001 09:18:31.373188  4916 net.cpp:198] Scale3 needs backward computation.
I1001 09:18:31.373190  4916 net.cpp:198] BatchNorm3 needs backward computation.
I1001 09:18:31.373193  4916 net.cpp:198] Convolution3 needs backward computation.
I1001 09:18:31.373195  4916 net.cpp:198] ReLU2 needs backward computation.
I1001 09:18:31.373198  4916 net.cpp:198] Scale2 needs backward computation.
I1001 09:18:31.373200  4916 net.cpp:198] BatchNorm2 needs backward computation.
I1001 09:18:31.373203  4916 net.cpp:198] Convolution2 needs backward computation.
I1001 09:18:31.373209  4916 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1001 09:18:31.373212  4916 net.cpp:198] ReLU1 needs backward computation.
I1001 09:18:31.373214  4916 net.cpp:198] Scale1 needs backward computation.
I1001 09:18:31.373216  4916 net.cpp:198] BatchNorm1 needs backward computation.
I1001 09:18:31.373219  4916 net.cpp:198] Convolution1 needs backward computation.
I1001 09:18:31.373221  4916 net.cpp:200] Data1 does not need backward computation.
I1001 09:18:31.373224  4916 net.cpp:242] This network produces output SoftmaxWithLoss1
I1001 09:18:31.373256  4916 net.cpp:255] Network initialization done.
I1001 09:18:31.374560  4916 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_cifar_train_test.prototxt
I1001 09:18:31.374568  4916 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1001 09:18:31.374573  4916 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_cifar_train_test.prototxt
I1001 09:18:31.374639  4916 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1001 09:18:31.374991  4916 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1001 09:18:31.375219  4916 layer_factory.hpp:77] Creating layer Data1
I1001 09:18:31.375255  4916 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1001 09:18:31.375265  4916 net.cpp:84] Creating Layer Data1
I1001 09:18:31.375269  4916 net.cpp:380] Data1 -> Data1
I1001 09:18:31.375274  4916 net.cpp:380] Data1 -> Data2
I1001 09:18:31.375280  4916 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1001 09:18:31.375391  4916 data_layer.cpp:45] output data size: 100,3,32,32
I1001 09:18:31.379127  4916 net.cpp:122] Setting up Data1
I1001 09:18:31.379145  4916 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1001 09:18:31.379150  4916 net.cpp:129] Top shape: 100 (100)
I1001 09:18:31.379153  4916 net.cpp:137] Memory required for data: 1229200
I1001 09:18:31.379156  4916 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1001 09:18:31.379164  4916 net.cpp:84] Creating Layer Data2_Data1_1_split
I1001 09:18:31.379168  4916 net.cpp:406] Data2_Data1_1_split <- Data2
I1001 09:18:31.379171  4916 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1001 09:18:31.379179  4916 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1001 09:18:31.379217  4916 net.cpp:122] Setting up Data2_Data1_1_split
I1001 09:18:31.379221  4916 net.cpp:129] Top shape: 100 (100)
I1001 09:18:31.379225  4916 net.cpp:129] Top shape: 100 (100)
I1001 09:18:31.379226  4916 net.cpp:137] Memory required for data: 1230000
I1001 09:18:31.379228  4916 layer_factory.hpp:77] Creating layer Convolution1
I1001 09:18:31.379238  4916 net.cpp:84] Creating Layer Convolution1
I1001 09:18:31.379240  4916 net.cpp:406] Convolution1 <- Data1
I1001 09:18:31.379245  4916 net.cpp:380] Convolution1 -> Convolution1
I1001 09:18:31.380393  4916 net.cpp:122] Setting up Convolution1
I1001 09:18:31.380403  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.380404  4916 net.cpp:137] Memory required for data: 7783600
I1001 09:18:31.380411  4916 layer_factory.hpp:77] Creating layer BatchNorm1
I1001 09:18:31.380417  4916 net.cpp:84] Creating Layer BatchNorm1
I1001 09:18:31.380420  4916 net.cpp:406] BatchNorm1 <- Convolution1
I1001 09:18:31.380424  4916 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1001 09:18:31.380600  4916 net.cpp:122] Setting up BatchNorm1
I1001 09:18:31.380605  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.380607  4916 net.cpp:137] Memory required for data: 14337200
I1001 09:18:31.380614  4916 layer_factory.hpp:77] Creating layer Scale1
I1001 09:18:31.380635  4916 net.cpp:84] Creating Layer Scale1
I1001 09:18:31.380638  4916 net.cpp:406] Scale1 <- Convolution1
I1001 09:18:31.380642  4916 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1001 09:18:31.380672  4916 layer_factory.hpp:77] Creating layer Scale1
I1001 09:18:31.380748  4916 net.cpp:122] Setting up Scale1
I1001 09:18:31.380753  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.380755  4916 net.cpp:137] Memory required for data: 20890800
I1001 09:18:31.380759  4916 layer_factory.hpp:77] Creating layer ReLU1
I1001 09:18:31.380767  4916 net.cpp:84] Creating Layer ReLU1
I1001 09:18:31.380769  4916 net.cpp:406] ReLU1 <- Convolution1
I1001 09:18:31.380774  4916 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1001 09:18:31.380889  4916 net.cpp:122] Setting up ReLU1
I1001 09:18:31.380897  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.380899  4916 net.cpp:137] Memory required for data: 27444400
I1001 09:18:31.380901  4916 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1001 09:18:31.380905  4916 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1001 09:18:31.380908  4916 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1001 09:18:31.380911  4916 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1001 09:18:31.380915  4916 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1001 09:18:31.380944  4916 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1001 09:18:31.380947  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.380956  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.380959  4916 net.cpp:137] Memory required for data: 40551600
I1001 09:18:31.380960  4916 layer_factory.hpp:77] Creating layer Convolution2
I1001 09:18:31.380970  4916 net.cpp:84] Creating Layer Convolution2
I1001 09:18:31.380972  4916 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1001 09:18:31.380976  4916 net.cpp:380] Convolution2 -> Convolution2
I1001 09:18:31.381893  4916 net.cpp:122] Setting up Convolution2
I1001 09:18:31.381901  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.381904  4916 net.cpp:137] Memory required for data: 47105200
I1001 09:18:31.381911  4916 layer_factory.hpp:77] Creating layer BatchNorm2
I1001 09:18:31.381917  4916 net.cpp:84] Creating Layer BatchNorm2
I1001 09:18:31.381920  4916 net.cpp:406] BatchNorm2 <- Convolution2
I1001 09:18:31.381924  4916 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1001 09:18:31.382138  4916 net.cpp:122] Setting up BatchNorm2
I1001 09:18:31.382144  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.382146  4916 net.cpp:137] Memory required for data: 53658800
I1001 09:18:31.382151  4916 layer_factory.hpp:77] Creating layer Scale2
I1001 09:18:31.382156  4916 net.cpp:84] Creating Layer Scale2
I1001 09:18:31.382158  4916 net.cpp:406] Scale2 <- Convolution2
I1001 09:18:31.382161  4916 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1001 09:18:31.382189  4916 layer_factory.hpp:77] Creating layer Scale2
I1001 09:18:31.382263  4916 net.cpp:122] Setting up Scale2
I1001 09:18:31.382267  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.382269  4916 net.cpp:137] Memory required for data: 60212400
I1001 09:18:31.382273  4916 layer_factory.hpp:77] Creating layer ReLU2
I1001 09:18:31.382278  4916 net.cpp:84] Creating Layer ReLU2
I1001 09:18:31.382280  4916 net.cpp:406] ReLU2 <- Convolution2
I1001 09:18:31.382283  4916 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1001 09:18:31.382397  4916 net.cpp:122] Setting up ReLU2
I1001 09:18:31.382403  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.382410  4916 net.cpp:137] Memory required for data: 66766000
I1001 09:18:31.382411  4916 layer_factory.hpp:77] Creating layer Convolution3
I1001 09:18:31.382419  4916 net.cpp:84] Creating Layer Convolution3
I1001 09:18:31.382421  4916 net.cpp:406] Convolution3 <- Convolution2
I1001 09:18:31.382426  4916 net.cpp:380] Convolution3 -> Convolution3
I1001 09:18:31.383482  4916 net.cpp:122] Setting up Convolution3
I1001 09:18:31.383491  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.383494  4916 net.cpp:137] Memory required for data: 73319600
I1001 09:18:31.383498  4916 layer_factory.hpp:77] Creating layer BatchNorm3
I1001 09:18:31.383504  4916 net.cpp:84] Creating Layer BatchNorm3
I1001 09:18:31.383507  4916 net.cpp:406] BatchNorm3 <- Convolution3
I1001 09:18:31.383512  4916 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1001 09:18:31.383646  4916 net.cpp:122] Setting up BatchNorm3
I1001 09:18:31.383651  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.383652  4916 net.cpp:137] Memory required for data: 79873200
I1001 09:18:31.383661  4916 layer_factory.hpp:77] Creating layer Scale3
I1001 09:18:31.383667  4916 net.cpp:84] Creating Layer Scale3
I1001 09:18:31.383671  4916 net.cpp:406] Scale3 <- Convolution3
I1001 09:18:31.383673  4916 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1001 09:18:31.383702  4916 layer_factory.hpp:77] Creating layer Scale3
I1001 09:18:31.383776  4916 net.cpp:122] Setting up Scale3
I1001 09:18:31.383780  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.383782  4916 net.cpp:137] Memory required for data: 86426800
I1001 09:18:31.383791  4916 layer_factory.hpp:77] Creating layer Eltwise1
I1001 09:18:31.383796  4916 net.cpp:84] Creating Layer Eltwise1
I1001 09:18:31.383800  4916 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1001 09:18:31.383803  4916 net.cpp:406] Eltwise1 <- Convolution3
I1001 09:18:31.383806  4916 net.cpp:380] Eltwise1 -> Eltwise1
I1001 09:18:31.383824  4916 net.cpp:122] Setting up Eltwise1
I1001 09:18:31.383828  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.383831  4916 net.cpp:137] Memory required for data: 92980400
I1001 09:18:31.383832  4916 layer_factory.hpp:77] Creating layer ReLU3
I1001 09:18:31.383839  4916 net.cpp:84] Creating Layer ReLU3
I1001 09:18:31.383841  4916 net.cpp:406] ReLU3 <- Eltwise1
I1001 09:18:31.383844  4916 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1001 09:18:31.383961  4916 net.cpp:122] Setting up ReLU3
I1001 09:18:31.383967  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.383970  4916 net.cpp:137] Memory required for data: 99534000
I1001 09:18:31.383972  4916 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1001 09:18:31.383977  4916 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1001 09:18:31.383982  4916 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1001 09:18:31.383986  4916 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1001 09:18:31.383991  4916 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1001 09:18:31.384018  4916 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1001 09:18:31.384022  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.384026  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.384027  4916 net.cpp:137] Memory required for data: 112641200
I1001 09:18:31.384029  4916 layer_factory.hpp:77] Creating layer Convolution4
I1001 09:18:31.384035  4916 net.cpp:84] Creating Layer Convolution4
I1001 09:18:31.384038  4916 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1001 09:18:31.384042  4916 net.cpp:380] Convolution4 -> Convolution4
I1001 09:18:31.385062  4916 net.cpp:122] Setting up Convolution4
I1001 09:18:31.385072  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.385074  4916 net.cpp:137] Memory required for data: 119194800
I1001 09:18:31.385079  4916 layer_factory.hpp:77] Creating layer BatchNorm4
I1001 09:18:31.385084  4916 net.cpp:84] Creating Layer BatchNorm4
I1001 09:18:31.385087  4916 net.cpp:406] BatchNorm4 <- Convolution4
I1001 09:18:31.385092  4916 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1001 09:18:31.385226  4916 net.cpp:122] Setting up BatchNorm4
I1001 09:18:31.385231  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.385232  4916 net.cpp:137] Memory required for data: 125748400
I1001 09:18:31.385237  4916 layer_factory.hpp:77] Creating layer Scale4
I1001 09:18:31.385249  4916 net.cpp:84] Creating Layer Scale4
I1001 09:18:31.385254  4916 net.cpp:406] Scale4 <- Convolution4
I1001 09:18:31.385258  4916 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1001 09:18:31.385288  4916 layer_factory.hpp:77] Creating layer Scale4
I1001 09:18:31.385362  4916 net.cpp:122] Setting up Scale4
I1001 09:18:31.385367  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.385370  4916 net.cpp:137] Memory required for data: 132302000
I1001 09:18:31.385373  4916 layer_factory.hpp:77] Creating layer ReLU4
I1001 09:18:31.385377  4916 net.cpp:84] Creating Layer ReLU4
I1001 09:18:31.385380  4916 net.cpp:406] ReLU4 <- Convolution4
I1001 09:18:31.385390  4916 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1001 09:18:31.385506  4916 net.cpp:122] Setting up ReLU4
I1001 09:18:31.385512  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.385514  4916 net.cpp:137] Memory required for data: 138855600
I1001 09:18:31.385516  4916 layer_factory.hpp:77] Creating layer Convolution5
I1001 09:18:31.385524  4916 net.cpp:84] Creating Layer Convolution5
I1001 09:18:31.385525  4916 net.cpp:406] Convolution5 <- Convolution4
I1001 09:18:31.385530  4916 net.cpp:380] Convolution5 -> Convolution5
I1001 09:18:31.386777  4916 net.cpp:122] Setting up Convolution5
I1001 09:18:31.386786  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.386788  4916 net.cpp:137] Memory required for data: 145409200
I1001 09:18:31.386793  4916 layer_factory.hpp:77] Creating layer BatchNorm5
I1001 09:18:31.386800  4916 net.cpp:84] Creating Layer BatchNorm5
I1001 09:18:31.386801  4916 net.cpp:406] BatchNorm5 <- Convolution5
I1001 09:18:31.386806  4916 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1001 09:18:31.386943  4916 net.cpp:122] Setting up BatchNorm5
I1001 09:18:31.386948  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.386950  4916 net.cpp:137] Memory required for data: 151962800
I1001 09:18:31.386957  4916 layer_factory.hpp:77] Creating layer Scale5
I1001 09:18:31.386961  4916 net.cpp:84] Creating Layer Scale5
I1001 09:18:31.386965  4916 net.cpp:406] Scale5 <- Convolution5
I1001 09:18:31.386968  4916 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1001 09:18:31.386997  4916 layer_factory.hpp:77] Creating layer Scale5
I1001 09:18:31.387073  4916 net.cpp:122] Setting up Scale5
I1001 09:18:31.387078  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.387079  4916 net.cpp:137] Memory required for data: 158516400
I1001 09:18:31.387084  4916 layer_factory.hpp:77] Creating layer Eltwise2
I1001 09:18:31.387086  4916 net.cpp:84] Creating Layer Eltwise2
I1001 09:18:31.387089  4916 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1001 09:18:31.387092  4916 net.cpp:406] Eltwise2 <- Convolution5
I1001 09:18:31.387095  4916 net.cpp:380] Eltwise2 -> Eltwise2
I1001 09:18:31.387110  4916 net.cpp:122] Setting up Eltwise2
I1001 09:18:31.387115  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.387116  4916 net.cpp:137] Memory required for data: 165070000
I1001 09:18:31.387118  4916 layer_factory.hpp:77] Creating layer ReLU5
I1001 09:18:31.387121  4916 net.cpp:84] Creating Layer ReLU5
I1001 09:18:31.387125  4916 net.cpp:406] ReLU5 <- Eltwise2
I1001 09:18:31.387126  4916 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1001 09:18:31.387567  4916 net.cpp:122] Setting up ReLU5
I1001 09:18:31.387575  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.387578  4916 net.cpp:137] Memory required for data: 171623600
I1001 09:18:31.387580  4916 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1001 09:18:31.387584  4916 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1001 09:18:31.387588  4916 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1001 09:18:31.387591  4916 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1001 09:18:31.387595  4916 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1001 09:18:31.387626  4916 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1001 09:18:31.387630  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.387640  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.387642  4916 net.cpp:137] Memory required for data: 184730800
I1001 09:18:31.387645  4916 layer_factory.hpp:77] Creating layer Convolution6
I1001 09:18:31.387651  4916 net.cpp:84] Creating Layer Convolution6
I1001 09:18:31.387655  4916 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1001 09:18:31.387658  4916 net.cpp:380] Convolution6 -> Convolution6
I1001 09:18:31.388227  4916 net.cpp:122] Setting up Convolution6
I1001 09:18:31.388234  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.388237  4916 net.cpp:137] Memory required for data: 191284400
I1001 09:18:31.388242  4916 layer_factory.hpp:77] Creating layer BatchNorm6
I1001 09:18:31.388245  4916 net.cpp:84] Creating Layer BatchNorm6
I1001 09:18:31.388248  4916 net.cpp:406] BatchNorm6 <- Convolution6
I1001 09:18:31.388252  4916 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1001 09:18:31.388387  4916 net.cpp:122] Setting up BatchNorm6
I1001 09:18:31.388391  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.388393  4916 net.cpp:137] Memory required for data: 197838000
I1001 09:18:31.388398  4916 layer_factory.hpp:77] Creating layer Scale6
I1001 09:18:31.388402  4916 net.cpp:84] Creating Layer Scale6
I1001 09:18:31.388406  4916 net.cpp:406] Scale6 <- Convolution6
I1001 09:18:31.388408  4916 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1001 09:18:31.388435  4916 layer_factory.hpp:77] Creating layer Scale6
I1001 09:18:31.388512  4916 net.cpp:122] Setting up Scale6
I1001 09:18:31.388516  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.388519  4916 net.cpp:137] Memory required for data: 204391600
I1001 09:18:31.388522  4916 layer_factory.hpp:77] Creating layer ReLU6
I1001 09:18:31.388525  4916 net.cpp:84] Creating Layer ReLU6
I1001 09:18:31.388527  4916 net.cpp:406] ReLU6 <- Convolution6
I1001 09:18:31.388531  4916 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1001 09:18:31.388970  4916 net.cpp:122] Setting up ReLU6
I1001 09:18:31.388978  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.388980  4916 net.cpp:137] Memory required for data: 210945200
I1001 09:18:31.388983  4916 layer_factory.hpp:77] Creating layer Convolution7
I1001 09:18:31.388990  4916 net.cpp:84] Creating Layer Convolution7
I1001 09:18:31.388993  4916 net.cpp:406] Convolution7 <- Convolution6
I1001 09:18:31.388998  4916 net.cpp:380] Convolution7 -> Convolution7
I1001 09:18:31.389900  4916 net.cpp:122] Setting up Convolution7
I1001 09:18:31.389909  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.389911  4916 net.cpp:137] Memory required for data: 217498800
I1001 09:18:31.389915  4916 layer_factory.hpp:77] Creating layer BatchNorm7
I1001 09:18:31.389922  4916 net.cpp:84] Creating Layer BatchNorm7
I1001 09:18:31.389925  4916 net.cpp:406] BatchNorm7 <- Convolution7
I1001 09:18:31.389930  4916 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1001 09:18:31.390065  4916 net.cpp:122] Setting up BatchNorm7
I1001 09:18:31.390070  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.390072  4916 net.cpp:137] Memory required for data: 224052400
I1001 09:18:31.390076  4916 layer_factory.hpp:77] Creating layer Scale7
I1001 09:18:31.390082  4916 net.cpp:84] Creating Layer Scale7
I1001 09:18:31.390085  4916 net.cpp:406] Scale7 <- Convolution7
I1001 09:18:31.390089  4916 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1001 09:18:31.390115  4916 layer_factory.hpp:77] Creating layer Scale7
I1001 09:18:31.390193  4916 net.cpp:122] Setting up Scale7
I1001 09:18:31.390197  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.390200  4916 net.cpp:137] Memory required for data: 230606000
I1001 09:18:31.390203  4916 layer_factory.hpp:77] Creating layer Eltwise3
I1001 09:18:31.390208  4916 net.cpp:84] Creating Layer Eltwise3
I1001 09:18:31.390209  4916 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1001 09:18:31.390213  4916 net.cpp:406] Eltwise3 <- Convolution7
I1001 09:18:31.390223  4916 net.cpp:380] Eltwise3 -> Eltwise3
I1001 09:18:31.390239  4916 net.cpp:122] Setting up Eltwise3
I1001 09:18:31.390244  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.390246  4916 net.cpp:137] Memory required for data: 237159600
I1001 09:18:31.390249  4916 layer_factory.hpp:77] Creating layer ReLU7
I1001 09:18:31.390251  4916 net.cpp:84] Creating Layer ReLU7
I1001 09:18:31.390254  4916 net.cpp:406] ReLU7 <- Eltwise3
I1001 09:18:31.390256  4916 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1001 09:18:31.390373  4916 net.cpp:122] Setting up ReLU7
I1001 09:18:31.390379  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.390381  4916 net.cpp:137] Memory required for data: 243713200
I1001 09:18:31.390384  4916 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1001 09:18:31.390388  4916 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1001 09:18:31.390389  4916 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1001 09:18:31.390393  4916 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1001 09:18:31.390396  4916 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1001 09:18:31.390424  4916 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1001 09:18:31.390429  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.390431  4916 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1001 09:18:31.390432  4916 net.cpp:137] Memory required for data: 256820400
I1001 09:18:31.390435  4916 layer_factory.hpp:77] Creating layer Convolution8
I1001 09:18:31.390441  4916 net.cpp:84] Creating Layer Convolution8
I1001 09:18:31.390444  4916 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1001 09:18:31.390449  4916 net.cpp:380] Convolution8 -> Convolution8
I1001 09:18:31.391322  4916 net.cpp:122] Setting up Convolution8
I1001 09:18:31.391330  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.391333  4916 net.cpp:137] Memory required for data: 260097200
I1001 09:18:31.391337  4916 layer_factory.hpp:77] Creating layer BatchNorm8
I1001 09:18:31.391343  4916 net.cpp:84] Creating Layer BatchNorm8
I1001 09:18:31.391346  4916 net.cpp:406] BatchNorm8 <- Convolution8
I1001 09:18:31.391350  4916 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1001 09:18:31.391481  4916 net.cpp:122] Setting up BatchNorm8
I1001 09:18:31.391485  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.391487  4916 net.cpp:137] Memory required for data: 263374000
I1001 09:18:31.391491  4916 layer_factory.hpp:77] Creating layer Scale8
I1001 09:18:31.391495  4916 net.cpp:84] Creating Layer Scale8
I1001 09:18:31.391499  4916 net.cpp:406] Scale8 <- Convolution8
I1001 09:18:31.391502  4916 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1001 09:18:31.391530  4916 layer_factory.hpp:77] Creating layer Scale8
I1001 09:18:31.391607  4916 net.cpp:122] Setting up Scale8
I1001 09:18:31.391610  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.391613  4916 net.cpp:137] Memory required for data: 266650800
I1001 09:18:31.391616  4916 layer_factory.hpp:77] Creating layer Convolution9
I1001 09:18:31.391623  4916 net.cpp:84] Creating Layer Convolution9
I1001 09:18:31.391625  4916 net.cpp:406] Convolution9 <- Eltwise3_ReLU7_0_split_1
I1001 09:18:31.391630  4916 net.cpp:380] Convolution9 -> Convolution9
I1001 09:18:31.392602  4916 net.cpp:122] Setting up Convolution9
I1001 09:18:31.392611  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.392613  4916 net.cpp:137] Memory required for data: 269927600
I1001 09:18:31.392617  4916 layer_factory.hpp:77] Creating layer BatchNorm9
I1001 09:18:31.392622  4916 net.cpp:84] Creating Layer BatchNorm9
I1001 09:18:31.392624  4916 net.cpp:406] BatchNorm9 <- Convolution9
I1001 09:18:31.392629  4916 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1001 09:18:31.392761  4916 net.cpp:122] Setting up BatchNorm9
I1001 09:18:31.392765  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.392767  4916 net.cpp:137] Memory required for data: 273204400
I1001 09:18:31.392772  4916 layer_factory.hpp:77] Creating layer Scale9
I1001 09:18:31.392782  4916 net.cpp:84] Creating Layer Scale9
I1001 09:18:31.392786  4916 net.cpp:406] Scale9 <- Convolution9
I1001 09:18:31.392788  4916 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1001 09:18:31.392817  4916 layer_factory.hpp:77] Creating layer Scale9
I1001 09:18:31.392894  4916 net.cpp:122] Setting up Scale9
I1001 09:18:31.392897  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.392899  4916 net.cpp:137] Memory required for data: 276481200
I1001 09:18:31.392904  4916 layer_factory.hpp:77] Creating layer ReLU8
I1001 09:18:31.392906  4916 net.cpp:84] Creating Layer ReLU8
I1001 09:18:31.392910  4916 net.cpp:406] ReLU8 <- Convolution9
I1001 09:18:31.392912  4916 net.cpp:367] ReLU8 -> Convolution9 (in-place)
I1001 09:18:31.393084  4916 net.cpp:122] Setting up ReLU8
I1001 09:18:31.393092  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.393095  4916 net.cpp:137] Memory required for data: 279758000
I1001 09:18:31.393097  4916 layer_factory.hpp:77] Creating layer Convolution10
I1001 09:18:31.393105  4916 net.cpp:84] Creating Layer Convolution10
I1001 09:18:31.393107  4916 net.cpp:406] Convolution10 <- Convolution9
I1001 09:18:31.393115  4916 net.cpp:380] Convolution10 -> Convolution10
I1001 09:18:31.394222  4916 net.cpp:122] Setting up Convolution10
I1001 09:18:31.394230  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.394232  4916 net.cpp:137] Memory required for data: 283034800
I1001 09:18:31.394243  4916 layer_factory.hpp:77] Creating layer BatchNorm10
I1001 09:18:31.394249  4916 net.cpp:84] Creating Layer BatchNorm10
I1001 09:18:31.394253  4916 net.cpp:406] BatchNorm10 <- Convolution10
I1001 09:18:31.394256  4916 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1001 09:18:31.394409  4916 net.cpp:122] Setting up BatchNorm10
I1001 09:18:31.394417  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.394419  4916 net.cpp:137] Memory required for data: 286311600
I1001 09:18:31.394424  4916 layer_factory.hpp:77] Creating layer Scale10
I1001 09:18:31.394429  4916 net.cpp:84] Creating Layer Scale10
I1001 09:18:31.394433  4916 net.cpp:406] Scale10 <- Convolution10
I1001 09:18:31.394435  4916 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1001 09:18:31.394465  4916 layer_factory.hpp:77] Creating layer Scale10
I1001 09:18:31.394587  4916 net.cpp:122] Setting up Scale10
I1001 09:18:31.394603  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.394606  4916 net.cpp:137] Memory required for data: 289588400
I1001 09:18:31.394610  4916 layer_factory.hpp:77] Creating layer Eltwise4
I1001 09:18:31.394616  4916 net.cpp:84] Creating Layer Eltwise4
I1001 09:18:31.394618  4916 net.cpp:406] Eltwise4 <- Convolution8
I1001 09:18:31.394621  4916 net.cpp:406] Eltwise4 <- Convolution10
I1001 09:18:31.394625  4916 net.cpp:380] Eltwise4 -> Eltwise4
I1001 09:18:31.394640  4916 net.cpp:122] Setting up Eltwise4
I1001 09:18:31.394654  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.394656  4916 net.cpp:137] Memory required for data: 292865200
I1001 09:18:31.394659  4916 layer_factory.hpp:77] Creating layer ReLU9
I1001 09:18:31.394664  4916 net.cpp:84] Creating Layer ReLU9
I1001 09:18:31.394667  4916 net.cpp:406] ReLU9 <- Eltwise4
I1001 09:18:31.394671  4916 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1001 09:18:31.394845  4916 net.cpp:122] Setting up ReLU9
I1001 09:18:31.394861  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.394865  4916 net.cpp:137] Memory required for data: 296142000
I1001 09:18:31.394866  4916 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1001 09:18:31.394870  4916 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1001 09:18:31.394872  4916 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1001 09:18:31.394876  4916 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1001 09:18:31.394881  4916 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1001 09:18:31.394909  4916 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1001 09:18:31.394920  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.394923  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.394925  4916 net.cpp:137] Memory required for data: 302695600
I1001 09:18:31.394927  4916 layer_factory.hpp:77] Creating layer Convolution11
I1001 09:18:31.394934  4916 net.cpp:84] Creating Layer Convolution11
I1001 09:18:31.394937  4916 net.cpp:406] Convolution11 <- Eltwise4_ReLU9_0_split_0
I1001 09:18:31.394942  4916 net.cpp:380] Convolution11 -> Convolution11
I1001 09:18:31.396417  4916 net.cpp:122] Setting up Convolution11
I1001 09:18:31.396427  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.396430  4916 net.cpp:137] Memory required for data: 305972400
I1001 09:18:31.396435  4916 layer_factory.hpp:77] Creating layer BatchNorm11
I1001 09:18:31.396440  4916 net.cpp:84] Creating Layer BatchNorm11
I1001 09:18:31.396441  4916 net.cpp:406] BatchNorm11 <- Convolution11
I1001 09:18:31.396446  4916 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1001 09:18:31.396587  4916 net.cpp:122] Setting up BatchNorm11
I1001 09:18:31.396592  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.396595  4916 net.cpp:137] Memory required for data: 309249200
I1001 09:18:31.396600  4916 layer_factory.hpp:77] Creating layer Scale11
I1001 09:18:31.396603  4916 net.cpp:84] Creating Layer Scale11
I1001 09:18:31.396605  4916 net.cpp:406] Scale11 <- Convolution11
I1001 09:18:31.396610  4916 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1001 09:18:31.396649  4916 layer_factory.hpp:77] Creating layer Scale11
I1001 09:18:31.396731  4916 net.cpp:122] Setting up Scale11
I1001 09:18:31.396735  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.396737  4916 net.cpp:137] Memory required for data: 312526000
I1001 09:18:31.396741  4916 layer_factory.hpp:77] Creating layer ReLU10
I1001 09:18:31.396745  4916 net.cpp:84] Creating Layer ReLU10
I1001 09:18:31.396747  4916 net.cpp:406] ReLU10 <- Convolution11
I1001 09:18:31.396751  4916 net.cpp:367] ReLU10 -> Convolution11 (in-place)
I1001 09:18:31.396872  4916 net.cpp:122] Setting up ReLU10
I1001 09:18:31.396878  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.396881  4916 net.cpp:137] Memory required for data: 315802800
I1001 09:18:31.396883  4916 layer_factory.hpp:77] Creating layer Convolution12
I1001 09:18:31.396893  4916 net.cpp:84] Creating Layer Convolution12
I1001 09:18:31.396894  4916 net.cpp:406] Convolution12 <- Convolution11
I1001 09:18:31.396900  4916 net.cpp:380] Convolution12 -> Convolution12
I1001 09:18:31.398046  4916 net.cpp:122] Setting up Convolution12
I1001 09:18:31.398054  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.398057  4916 net.cpp:137] Memory required for data: 319079600
I1001 09:18:31.398061  4916 layer_factory.hpp:77] Creating layer BatchNorm12
I1001 09:18:31.398068  4916 net.cpp:84] Creating Layer BatchNorm12
I1001 09:18:31.398072  4916 net.cpp:406] BatchNorm12 <- Convolution12
I1001 09:18:31.398075  4916 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1001 09:18:31.398217  4916 net.cpp:122] Setting up BatchNorm12
I1001 09:18:31.398221  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.398224  4916 net.cpp:137] Memory required for data: 322356400
I1001 09:18:31.398228  4916 layer_factory.hpp:77] Creating layer Scale12
I1001 09:18:31.398233  4916 net.cpp:84] Creating Layer Scale12
I1001 09:18:31.398236  4916 net.cpp:406] Scale12 <- Convolution12
I1001 09:18:31.398239  4916 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1001 09:18:31.398269  4916 layer_factory.hpp:77] Creating layer Scale12
I1001 09:18:31.398350  4916 net.cpp:122] Setting up Scale12
I1001 09:18:31.398355  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.398356  4916 net.cpp:137] Memory required for data: 325633200
I1001 09:18:31.398360  4916 layer_factory.hpp:77] Creating layer Eltwise5
I1001 09:18:31.398365  4916 net.cpp:84] Creating Layer Eltwise5
I1001 09:18:31.398367  4916 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I1001 09:18:31.398378  4916 net.cpp:406] Eltwise5 <- Convolution12
I1001 09:18:31.398383  4916 net.cpp:380] Eltwise5 -> Eltwise5
I1001 09:18:31.398398  4916 net.cpp:122] Setting up Eltwise5
I1001 09:18:31.398402  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.398404  4916 net.cpp:137] Memory required for data: 328910000
I1001 09:18:31.398406  4916 layer_factory.hpp:77] Creating layer ReLU11
I1001 09:18:31.398411  4916 net.cpp:84] Creating Layer ReLU11
I1001 09:18:31.398413  4916 net.cpp:406] ReLU11 <- Eltwise5
I1001 09:18:31.398416  4916 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1001 09:18:31.398561  4916 net.cpp:122] Setting up ReLU11
I1001 09:18:31.398569  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.398571  4916 net.cpp:137] Memory required for data: 332186800
I1001 09:18:31.398573  4916 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1001 09:18:31.398577  4916 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1001 09:18:31.398581  4916 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1001 09:18:31.398583  4916 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1001 09:18:31.398587  4916 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1001 09:18:31.398619  4916 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1001 09:18:31.398624  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.398627  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.398629  4916 net.cpp:137] Memory required for data: 338740400
I1001 09:18:31.398641  4916 layer_factory.hpp:77] Creating layer Convolution13
I1001 09:18:31.398649  4916 net.cpp:84] Creating Layer Convolution13
I1001 09:18:31.398653  4916 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I1001 09:18:31.398656  4916 net.cpp:380] Convolution13 -> Convolution13
I1001 09:18:31.399765  4916 net.cpp:122] Setting up Convolution13
I1001 09:18:31.399775  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.399777  4916 net.cpp:137] Memory required for data: 342017200
I1001 09:18:31.399781  4916 layer_factory.hpp:77] Creating layer BatchNorm13
I1001 09:18:31.399787  4916 net.cpp:84] Creating Layer BatchNorm13
I1001 09:18:31.399791  4916 net.cpp:406] BatchNorm13 <- Convolution13
I1001 09:18:31.399794  4916 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1001 09:18:31.399936  4916 net.cpp:122] Setting up BatchNorm13
I1001 09:18:31.399940  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.399942  4916 net.cpp:137] Memory required for data: 345294000
I1001 09:18:31.399947  4916 layer_factory.hpp:77] Creating layer Scale13
I1001 09:18:31.399952  4916 net.cpp:84] Creating Layer Scale13
I1001 09:18:31.399955  4916 net.cpp:406] Scale13 <- Convolution13
I1001 09:18:31.399957  4916 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1001 09:18:31.399986  4916 layer_factory.hpp:77] Creating layer Scale13
I1001 09:18:31.400063  4916 net.cpp:122] Setting up Scale13
I1001 09:18:31.400068  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.400070  4916 net.cpp:137] Memory required for data: 348570800
I1001 09:18:31.400074  4916 layer_factory.hpp:77] Creating layer ReLU12
I1001 09:18:31.400077  4916 net.cpp:84] Creating Layer ReLU12
I1001 09:18:31.400079  4916 net.cpp:406] ReLU12 <- Convolution13
I1001 09:18:31.400084  4916 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1001 09:18:31.400521  4916 net.cpp:122] Setting up ReLU12
I1001 09:18:31.400528  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.400532  4916 net.cpp:137] Memory required for data: 351847600
I1001 09:18:31.400533  4916 layer_factory.hpp:77] Creating layer Convolution14
I1001 09:18:31.400545  4916 net.cpp:84] Creating Layer Convolution14
I1001 09:18:31.400548  4916 net.cpp:406] Convolution14 <- Convolution13
I1001 09:18:31.400553  4916 net.cpp:380] Convolution14 -> Convolution14
I1001 09:18:31.401607  4916 net.cpp:122] Setting up Convolution14
I1001 09:18:31.401615  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.401618  4916 net.cpp:137] Memory required for data: 355124400
I1001 09:18:31.401628  4916 layer_factory.hpp:77] Creating layer BatchNorm14
I1001 09:18:31.401633  4916 net.cpp:84] Creating Layer BatchNorm14
I1001 09:18:31.401635  4916 net.cpp:406] BatchNorm14 <- Convolution14
I1001 09:18:31.401640  4916 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1001 09:18:31.401777  4916 net.cpp:122] Setting up BatchNorm14
I1001 09:18:31.401780  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.401783  4916 net.cpp:137] Memory required for data: 358401200
I1001 09:18:31.401787  4916 layer_factory.hpp:77] Creating layer Scale14
I1001 09:18:31.401792  4916 net.cpp:84] Creating Layer Scale14
I1001 09:18:31.401793  4916 net.cpp:406] Scale14 <- Convolution14
I1001 09:18:31.401798  4916 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1001 09:18:31.401824  4916 layer_factory.hpp:77] Creating layer Scale14
I1001 09:18:31.401902  4916 net.cpp:122] Setting up Scale14
I1001 09:18:31.401906  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.401908  4916 net.cpp:137] Memory required for data: 361678000
I1001 09:18:31.401912  4916 layer_factory.hpp:77] Creating layer Eltwise6
I1001 09:18:31.401916  4916 net.cpp:84] Creating Layer Eltwise6
I1001 09:18:31.401919  4916 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I1001 09:18:31.401922  4916 net.cpp:406] Eltwise6 <- Convolution14
I1001 09:18:31.401926  4916 net.cpp:380] Eltwise6 -> Eltwise6
I1001 09:18:31.401938  4916 net.cpp:122] Setting up Eltwise6
I1001 09:18:31.401942  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.401944  4916 net.cpp:137] Memory required for data: 364954800
I1001 09:18:31.401947  4916 layer_factory.hpp:77] Creating layer ReLU13
I1001 09:18:31.401949  4916 net.cpp:84] Creating Layer ReLU13
I1001 09:18:31.401952  4916 net.cpp:406] ReLU13 <- Eltwise6
I1001 09:18:31.401955  4916 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1001 09:18:31.402071  4916 net.cpp:122] Setting up ReLU13
I1001 09:18:31.402077  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.402079  4916 net.cpp:137] Memory required for data: 368231600
I1001 09:18:31.402082  4916 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1001 09:18:31.402086  4916 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1001 09:18:31.402088  4916 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1001 09:18:31.402091  4916 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1001 09:18:31.402096  4916 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1001 09:18:31.402123  4916 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1001 09:18:31.402127  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.402129  4916 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1001 09:18:31.402132  4916 net.cpp:137] Memory required for data: 374785200
I1001 09:18:31.402134  4916 layer_factory.hpp:77] Creating layer Convolution15
I1001 09:18:31.402140  4916 net.cpp:84] Creating Layer Convolution15
I1001 09:18:31.402143  4916 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1001 09:18:31.402148  4916 net.cpp:380] Convolution15 -> Convolution15
I1001 09:18:31.403144  4916 net.cpp:122] Setting up Convolution15
I1001 09:18:31.403153  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.403156  4916 net.cpp:137] Memory required for data: 376423600
I1001 09:18:31.403159  4916 layer_factory.hpp:77] Creating layer BatchNorm15
I1001 09:18:31.403165  4916 net.cpp:84] Creating Layer BatchNorm15
I1001 09:18:31.403167  4916 net.cpp:406] BatchNorm15 <- Convolution15
I1001 09:18:31.403172  4916 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1001 09:18:31.403316  4916 net.cpp:122] Setting up BatchNorm15
I1001 09:18:31.403319  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.403321  4916 net.cpp:137] Memory required for data: 378062000
I1001 09:18:31.403326  4916 layer_factory.hpp:77] Creating layer Scale15
I1001 09:18:31.403331  4916 net.cpp:84] Creating Layer Scale15
I1001 09:18:31.403333  4916 net.cpp:406] Scale15 <- Convolution15
I1001 09:18:31.403342  4916 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1001 09:18:31.403373  4916 layer_factory.hpp:77] Creating layer Scale15
I1001 09:18:31.403452  4916 net.cpp:122] Setting up Scale15
I1001 09:18:31.403457  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.403460  4916 net.cpp:137] Memory required for data: 379700400
I1001 09:18:31.403463  4916 layer_factory.hpp:77] Creating layer Convolution16
I1001 09:18:31.403470  4916 net.cpp:84] Creating Layer Convolution16
I1001 09:18:31.403472  4916 net.cpp:406] Convolution16 <- Eltwise6_ReLU13_0_split_1
I1001 09:18:31.403476  4916 net.cpp:380] Convolution16 -> Convolution16
I1001 09:18:31.404755  4916 net.cpp:122] Setting up Convolution16
I1001 09:18:31.404763  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.404767  4916 net.cpp:137] Memory required for data: 381338800
I1001 09:18:31.404770  4916 layer_factory.hpp:77] Creating layer BatchNorm16
I1001 09:18:31.404775  4916 net.cpp:84] Creating Layer BatchNorm16
I1001 09:18:31.404778  4916 net.cpp:406] BatchNorm16 <- Convolution16
I1001 09:18:31.404783  4916 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1001 09:18:31.404922  4916 net.cpp:122] Setting up BatchNorm16
I1001 09:18:31.404927  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.404928  4916 net.cpp:137] Memory required for data: 382977200
I1001 09:18:31.404932  4916 layer_factory.hpp:77] Creating layer Scale16
I1001 09:18:31.404937  4916 net.cpp:84] Creating Layer Scale16
I1001 09:18:31.404939  4916 net.cpp:406] Scale16 <- Convolution16
I1001 09:18:31.404942  4916 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1001 09:18:31.404971  4916 layer_factory.hpp:77] Creating layer Scale16
I1001 09:18:31.405051  4916 net.cpp:122] Setting up Scale16
I1001 09:18:31.405055  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.405058  4916 net.cpp:137] Memory required for data: 384615600
I1001 09:18:31.405061  4916 layer_factory.hpp:77] Creating layer ReLU14
I1001 09:18:31.405064  4916 net.cpp:84] Creating Layer ReLU14
I1001 09:18:31.405067  4916 net.cpp:406] ReLU14 <- Convolution16
I1001 09:18:31.405071  4916 net.cpp:367] ReLU14 -> Convolution16 (in-place)
I1001 09:18:31.405187  4916 net.cpp:122] Setting up ReLU14
I1001 09:18:31.405192  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.405194  4916 net.cpp:137] Memory required for data: 386254000
I1001 09:18:31.405197  4916 layer_factory.hpp:77] Creating layer Convolution17
I1001 09:18:31.405205  4916 net.cpp:84] Creating Layer Convolution17
I1001 09:18:31.405206  4916 net.cpp:406] Convolution17 <- Convolution16
I1001 09:18:31.405210  4916 net.cpp:380] Convolution17 -> Convolution17
I1001 09:18:31.406893  4916 net.cpp:122] Setting up Convolution17
I1001 09:18:31.406901  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.406903  4916 net.cpp:137] Memory required for data: 387892400
I1001 09:18:31.406908  4916 layer_factory.hpp:77] Creating layer BatchNorm17
I1001 09:18:31.406913  4916 net.cpp:84] Creating Layer BatchNorm17
I1001 09:18:31.406916  4916 net.cpp:406] BatchNorm17 <- Convolution17
I1001 09:18:31.406920  4916 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1001 09:18:31.407063  4916 net.cpp:122] Setting up BatchNorm17
I1001 09:18:31.407066  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.407068  4916 net.cpp:137] Memory required for data: 389530800
I1001 09:18:31.407073  4916 layer_factory.hpp:77] Creating layer Scale17
I1001 09:18:31.407078  4916 net.cpp:84] Creating Layer Scale17
I1001 09:18:31.407080  4916 net.cpp:406] Scale17 <- Convolution17
I1001 09:18:31.407083  4916 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1001 09:18:31.407112  4916 layer_factory.hpp:77] Creating layer Scale17
I1001 09:18:31.407191  4916 net.cpp:122] Setting up Scale17
I1001 09:18:31.407196  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.407197  4916 net.cpp:137] Memory required for data: 391169200
I1001 09:18:31.407202  4916 layer_factory.hpp:77] Creating layer Eltwise7
I1001 09:18:31.407212  4916 net.cpp:84] Creating Layer Eltwise7
I1001 09:18:31.407215  4916 net.cpp:406] Eltwise7 <- Convolution15
I1001 09:18:31.407218  4916 net.cpp:406] Eltwise7 <- Convolution17
I1001 09:18:31.407222  4916 net.cpp:380] Eltwise7 -> Eltwise7
I1001 09:18:31.407239  4916 net.cpp:122] Setting up Eltwise7
I1001 09:18:31.407243  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.407245  4916 net.cpp:137] Memory required for data: 392807600
I1001 09:18:31.407248  4916 layer_factory.hpp:77] Creating layer ReLU15
I1001 09:18:31.407251  4916 net.cpp:84] Creating Layer ReLU15
I1001 09:18:31.407253  4916 net.cpp:406] ReLU15 <- Eltwise7
I1001 09:18:31.407256  4916 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1001 09:18:31.407371  4916 net.cpp:122] Setting up ReLU15
I1001 09:18:31.407377  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.407378  4916 net.cpp:137] Memory required for data: 394446000
I1001 09:18:31.407382  4916 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1001 09:18:31.407384  4916 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1001 09:18:31.407387  4916 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1001 09:18:31.407390  4916 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1001 09:18:31.423701  4916 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1001 09:18:31.423755  4916 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1001 09:18:31.423765  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.423770  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.423774  4916 net.cpp:137] Memory required for data: 397722800
I1001 09:18:31.423779  4916 layer_factory.hpp:77] Creating layer Convolution18
I1001 09:18:31.423789  4916 net.cpp:84] Creating Layer Convolution18
I1001 09:18:31.423794  4916 net.cpp:406] Convolution18 <- Eltwise7_ReLU15_0_split_0
I1001 09:18:31.423801  4916 net.cpp:380] Convolution18 -> Convolution18
I1001 09:18:31.425781  4916 net.cpp:122] Setting up Convolution18
I1001 09:18:31.425789  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.425792  4916 net.cpp:137] Memory required for data: 399361200
I1001 09:18:31.425797  4916 layer_factory.hpp:77] Creating layer BatchNorm18
I1001 09:18:31.425803  4916 net.cpp:84] Creating Layer BatchNorm18
I1001 09:18:31.425806  4916 net.cpp:406] BatchNorm18 <- Convolution18
I1001 09:18:31.425809  4916 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1001 09:18:31.425956  4916 net.cpp:122] Setting up BatchNorm18
I1001 09:18:31.425961  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.425963  4916 net.cpp:137] Memory required for data: 400999600
I1001 09:18:31.425968  4916 layer_factory.hpp:77] Creating layer Scale18
I1001 09:18:31.425972  4916 net.cpp:84] Creating Layer Scale18
I1001 09:18:31.425976  4916 net.cpp:406] Scale18 <- Convolution18
I1001 09:18:31.425978  4916 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1001 09:18:31.426009  4916 layer_factory.hpp:77] Creating layer Scale18
I1001 09:18:31.426092  4916 net.cpp:122] Setting up Scale18
I1001 09:18:31.426096  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.426098  4916 net.cpp:137] Memory required for data: 402638000
I1001 09:18:31.426102  4916 layer_factory.hpp:77] Creating layer ReLU16
I1001 09:18:31.426106  4916 net.cpp:84] Creating Layer ReLU16
I1001 09:18:31.426110  4916 net.cpp:406] ReLU16 <- Convolution18
I1001 09:18:31.426112  4916 net.cpp:367] ReLU16 -> Convolution18 (in-place)
I1001 09:18:31.426384  4916 net.cpp:122] Setting up ReLU16
I1001 09:18:31.426393  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.426398  4916 net.cpp:137] Memory required for data: 404276400
I1001 09:18:31.426401  4916 layer_factory.hpp:77] Creating layer Convolution19
I1001 09:18:31.426411  4916 net.cpp:84] Creating Layer Convolution19
I1001 09:18:31.426415  4916 net.cpp:406] Convolution19 <- Convolution18
I1001 09:18:31.426422  4916 net.cpp:380] Convolution19 -> Convolution19
I1001 09:18:31.428243  4916 net.cpp:122] Setting up Convolution19
I1001 09:18:31.428261  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.428263  4916 net.cpp:137] Memory required for data: 405914800
I1001 09:18:31.428268  4916 layer_factory.hpp:77] Creating layer BatchNorm19
I1001 09:18:31.428273  4916 net.cpp:84] Creating Layer BatchNorm19
I1001 09:18:31.428277  4916 net.cpp:406] BatchNorm19 <- Convolution19
I1001 09:18:31.428280  4916 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1001 09:18:31.428431  4916 net.cpp:122] Setting up BatchNorm19
I1001 09:18:31.428436  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.428437  4916 net.cpp:137] Memory required for data: 407553200
I1001 09:18:31.428453  4916 layer_factory.hpp:77] Creating layer Scale19
I1001 09:18:31.428458  4916 net.cpp:84] Creating Layer Scale19
I1001 09:18:31.428462  4916 net.cpp:406] Scale19 <- Convolution19
I1001 09:18:31.428464  4916 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1001 09:18:31.428496  4916 layer_factory.hpp:77] Creating layer Scale19
I1001 09:18:31.428580  4916 net.cpp:122] Setting up Scale19
I1001 09:18:31.428583  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.428586  4916 net.cpp:137] Memory required for data: 409191600
I1001 09:18:31.428589  4916 layer_factory.hpp:77] Creating layer Eltwise8
I1001 09:18:31.428593  4916 net.cpp:84] Creating Layer Eltwise8
I1001 09:18:31.428596  4916 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1001 09:18:31.428599  4916 net.cpp:406] Eltwise8 <- Convolution19
I1001 09:18:31.428602  4916 net.cpp:380] Eltwise8 -> Eltwise8
I1001 09:18:31.428622  4916 net.cpp:122] Setting up Eltwise8
I1001 09:18:31.428627  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.428628  4916 net.cpp:137] Memory required for data: 410830000
I1001 09:18:31.428630  4916 layer_factory.hpp:77] Creating layer ReLU17
I1001 09:18:31.428634  4916 net.cpp:84] Creating Layer ReLU17
I1001 09:18:31.428637  4916 net.cpp:406] ReLU17 <- Eltwise8
I1001 09:18:31.428640  4916 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1001 09:18:31.428762  4916 net.cpp:122] Setting up ReLU17
I1001 09:18:31.428768  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.428771  4916 net.cpp:137] Memory required for data: 412468400
I1001 09:18:31.428772  4916 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1001 09:18:31.428776  4916 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1001 09:18:31.428778  4916 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1001 09:18:31.428782  4916 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1001 09:18:31.428787  4916 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1001 09:18:31.428817  4916 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1001 09:18:31.428820  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.428823  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.428825  4916 net.cpp:137] Memory required for data: 415745200
I1001 09:18:31.428828  4916 layer_factory.hpp:77] Creating layer Convolution20
I1001 09:18:31.428834  4916 net.cpp:84] Creating Layer Convolution20
I1001 09:18:31.428836  4916 net.cpp:406] Convolution20 <- Eltwise8_ReLU17_0_split_0
I1001 09:18:31.428841  4916 net.cpp:380] Convolution20 -> Convolution20
I1001 09:18:31.430905  4916 net.cpp:122] Setting up Convolution20
I1001 09:18:31.430914  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.430917  4916 net.cpp:137] Memory required for data: 417383600
I1001 09:18:31.430923  4916 layer_factory.hpp:77] Creating layer BatchNorm20
I1001 09:18:31.430928  4916 net.cpp:84] Creating Layer BatchNorm20
I1001 09:18:31.430932  4916 net.cpp:406] BatchNorm20 <- Convolution20
I1001 09:18:31.430935  4916 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1001 09:18:31.431087  4916 net.cpp:122] Setting up BatchNorm20
I1001 09:18:31.431092  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.431093  4916 net.cpp:137] Memory required for data: 419022000
I1001 09:18:31.431098  4916 layer_factory.hpp:77] Creating layer Scale20
I1001 09:18:31.431109  4916 net.cpp:84] Creating Layer Scale20
I1001 09:18:31.431113  4916 net.cpp:406] Scale20 <- Convolution20
I1001 09:18:31.431116  4916 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1001 09:18:31.431147  4916 layer_factory.hpp:77] Creating layer Scale20
I1001 09:18:31.431233  4916 net.cpp:122] Setting up Scale20
I1001 09:18:31.431237  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.431239  4916 net.cpp:137] Memory required for data: 420660400
I1001 09:18:31.431243  4916 layer_factory.hpp:77] Creating layer ReLU18
I1001 09:18:31.431247  4916 net.cpp:84] Creating Layer ReLU18
I1001 09:18:31.431251  4916 net.cpp:406] ReLU18 <- Convolution20
I1001 09:18:31.431253  4916 net.cpp:367] ReLU18 -> Convolution20 (in-place)
I1001 09:18:31.431707  4916 net.cpp:122] Setting up ReLU18
I1001 09:18:31.431715  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.431717  4916 net.cpp:137] Memory required for data: 422298800
I1001 09:18:31.431720  4916 layer_factory.hpp:77] Creating layer Convolution21
I1001 09:18:31.431727  4916 net.cpp:84] Creating Layer Convolution21
I1001 09:18:31.431730  4916 net.cpp:406] Convolution21 <- Convolution20
I1001 09:18:31.431736  4916 net.cpp:380] Convolution21 -> Convolution21
I1001 09:18:31.433102  4916 net.cpp:122] Setting up Convolution21
I1001 09:18:31.433110  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.433112  4916 net.cpp:137] Memory required for data: 423937200
I1001 09:18:31.433117  4916 layer_factory.hpp:77] Creating layer BatchNorm21
I1001 09:18:31.433122  4916 net.cpp:84] Creating Layer BatchNorm21
I1001 09:18:31.433125  4916 net.cpp:406] BatchNorm21 <- Convolution21
I1001 09:18:31.433128  4916 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1001 09:18:31.433279  4916 net.cpp:122] Setting up BatchNorm21
I1001 09:18:31.433282  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.433285  4916 net.cpp:137] Memory required for data: 425575600
I1001 09:18:31.433290  4916 layer_factory.hpp:77] Creating layer Scale21
I1001 09:18:31.433295  4916 net.cpp:84] Creating Layer Scale21
I1001 09:18:31.433296  4916 net.cpp:406] Scale21 <- Convolution21
I1001 09:18:31.433300  4916 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1001 09:18:31.433329  4916 layer_factory.hpp:77] Creating layer Scale21
I1001 09:18:31.433413  4916 net.cpp:122] Setting up Scale21
I1001 09:18:31.433418  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.433420  4916 net.cpp:137] Memory required for data: 427214000
I1001 09:18:31.433424  4916 layer_factory.hpp:77] Creating layer Eltwise9
I1001 09:18:31.433429  4916 net.cpp:84] Creating Layer Eltwise9
I1001 09:18:31.433430  4916 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1001 09:18:31.433434  4916 net.cpp:406] Eltwise9 <- Convolution21
I1001 09:18:31.433436  4916 net.cpp:380] Eltwise9 -> Eltwise9
I1001 09:18:31.433454  4916 net.cpp:122] Setting up Eltwise9
I1001 09:18:31.433459  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.433460  4916 net.cpp:137] Memory required for data: 428852400
I1001 09:18:31.433462  4916 layer_factory.hpp:77] Creating layer ReLU19
I1001 09:18:31.433465  4916 net.cpp:84] Creating Layer ReLU19
I1001 09:18:31.433468  4916 net.cpp:406] ReLU19 <- Eltwise9
I1001 09:18:31.433471  4916 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1001 09:18:31.433943  4916 net.cpp:122] Setting up ReLU19
I1001 09:18:31.433953  4916 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1001 09:18:31.433954  4916 net.cpp:137] Memory required for data: 430490800
I1001 09:18:31.433957  4916 layer_factory.hpp:77] Creating layer Pooling1
I1001 09:18:31.433962  4916 net.cpp:84] Creating Layer Pooling1
I1001 09:18:31.433965  4916 net.cpp:406] Pooling1 <- Eltwise9
I1001 09:18:31.433969  4916 net.cpp:380] Pooling1 -> Pooling1
I1001 09:18:31.434100  4916 net.cpp:122] Setting up Pooling1
I1001 09:18:31.434108  4916 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1001 09:18:31.434110  4916 net.cpp:137] Memory required for data: 430516400
I1001 09:18:31.434113  4916 layer_factory.hpp:77] Creating layer InnerProduct1
I1001 09:18:31.434124  4916 net.cpp:84] Creating Layer InnerProduct1
I1001 09:18:31.434126  4916 net.cpp:406] InnerProduct1 <- Pooling1
I1001 09:18:31.434134  4916 net.cpp:380] InnerProduct1 -> InnerProduct1
I1001 09:18:31.434240  4916 net.cpp:122] Setting up InnerProduct1
I1001 09:18:31.434245  4916 net.cpp:129] Top shape: 100 10 (1000)
I1001 09:18:31.434248  4916 net.cpp:137] Memory required for data: 430520400
I1001 09:18:31.434252  4916 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1001 09:18:31.434257  4916 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1001 09:18:31.434259  4916 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1001 09:18:31.434263  4916 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1001 09:18:31.434267  4916 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1001 09:18:31.434295  4916 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1001 09:18:31.434299  4916 net.cpp:129] Top shape: 100 10 (1000)
I1001 09:18:31.434303  4916 net.cpp:129] Top shape: 100 10 (1000)
I1001 09:18:31.434304  4916 net.cpp:137] Memory required for data: 430528400
I1001 09:18:31.434306  4916 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 09:18:31.434310  4916 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1001 09:18:31.434314  4916 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1001 09:18:31.434316  4916 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1001 09:18:31.434320  4916 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1001 09:18:31.434324  4916 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1001 09:18:31.434509  4916 net.cpp:122] Setting up SoftmaxWithLoss1
I1001 09:18:31.434515  4916 net.cpp:129] Top shape: (1)
I1001 09:18:31.434517  4916 net.cpp:132]     with loss weight 1
I1001 09:18:31.434540  4916 net.cpp:137] Memory required for data: 430528404
I1001 09:18:31.434543  4916 layer_factory.hpp:77] Creating layer Accuracy1
I1001 09:18:31.434550  4916 net.cpp:84] Creating Layer Accuracy1
I1001 09:18:31.434552  4916 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1001 09:18:31.434564  4916 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1001 09:18:31.434568  4916 net.cpp:380] Accuracy1 -> Accuracy1
I1001 09:18:31.434574  4916 net.cpp:122] Setting up Accuracy1
I1001 09:18:31.434577  4916 net.cpp:129] Top shape: (1)
I1001 09:18:31.434581  4916 net.cpp:137] Memory required for data: 430528408
I1001 09:18:31.434582  4916 net.cpp:200] Accuracy1 does not need backward computation.
I1001 09:18:31.434586  4916 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1001 09:18:31.434588  4916 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1001 09:18:31.434590  4916 net.cpp:198] InnerProduct1 needs backward computation.
I1001 09:18:31.434592  4916 net.cpp:198] Pooling1 needs backward computation.
I1001 09:18:31.434594  4916 net.cpp:198] ReLU19 needs backward computation.
I1001 09:18:31.434597  4916 net.cpp:198] Eltwise9 needs backward computation.
I1001 09:18:31.434599  4916 net.cpp:198] Scale21 needs backward computation.
I1001 09:18:31.434602  4916 net.cpp:198] BatchNorm21 needs backward computation.
I1001 09:18:31.434603  4916 net.cpp:198] Convolution21 needs backward computation.
I1001 09:18:31.434605  4916 net.cpp:198] ReLU18 needs backward computation.
I1001 09:18:31.434607  4916 net.cpp:198] Scale20 needs backward computation.
I1001 09:18:31.434609  4916 net.cpp:198] BatchNorm20 needs backward computation.
I1001 09:18:31.434612  4916 net.cpp:198] Convolution20 needs backward computation.
I1001 09:18:31.434614  4916 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1001 09:18:31.434617  4916 net.cpp:198] ReLU17 needs backward computation.
I1001 09:18:31.434618  4916 net.cpp:198] Eltwise8 needs backward computation.
I1001 09:18:31.434620  4916 net.cpp:198] Scale19 needs backward computation.
I1001 09:18:31.434623  4916 net.cpp:198] BatchNorm19 needs backward computation.
I1001 09:18:31.434631  4916 net.cpp:198] Convolution19 needs backward computation.
I1001 09:18:31.434633  4916 net.cpp:198] ReLU16 needs backward computation.
I1001 09:18:31.434636  4916 net.cpp:198] Scale18 needs backward computation.
I1001 09:18:31.434638  4916 net.cpp:198] BatchNorm18 needs backward computation.
I1001 09:18:31.434640  4916 net.cpp:198] Convolution18 needs backward computation.
I1001 09:18:31.434643  4916 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1001 09:18:31.434644  4916 net.cpp:198] ReLU15 needs backward computation.
I1001 09:18:31.434648  4916 net.cpp:198] Eltwise7 needs backward computation.
I1001 09:18:31.434649  4916 net.cpp:198] Scale17 needs backward computation.
I1001 09:18:31.434653  4916 net.cpp:198] BatchNorm17 needs backward computation.
I1001 09:18:31.434654  4916 net.cpp:198] Convolution17 needs backward computation.
I1001 09:18:31.434656  4916 net.cpp:198] ReLU14 needs backward computation.
I1001 09:18:31.434659  4916 net.cpp:198] Scale16 needs backward computation.
I1001 09:18:31.454455  4916 net.cpp:198] BatchNorm16 needs backward computation.
I1001 09:18:31.454464  4916 net.cpp:198] Convolution16 needs backward computation.
I1001 09:18:31.454469  4916 net.cpp:198] Scale15 needs backward computation.
I1001 09:18:31.454473  4916 net.cpp:198] BatchNorm15 needs backward computation.
I1001 09:18:31.454478  4916 net.cpp:198] Convolution15 needs backward computation.
I1001 09:18:31.454481  4916 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1001 09:18:31.454486  4916 net.cpp:198] ReLU13 needs backward computation.
I1001 09:18:31.454490  4916 net.cpp:198] Eltwise6 needs backward computation.
I1001 09:18:31.454495  4916 net.cpp:198] Scale14 needs backward computation.
I1001 09:18:31.454499  4916 net.cpp:198] BatchNorm14 needs backward computation.
I1001 09:18:31.454502  4916 net.cpp:198] Convolution14 needs backward computation.
I1001 09:18:31.454506  4916 net.cpp:198] ReLU12 needs backward computation.
I1001 09:18:31.454510  4916 net.cpp:198] Scale13 needs backward computation.
I1001 09:18:31.454514  4916 net.cpp:198] BatchNorm13 needs backward computation.
I1001 09:18:31.454519  4916 net.cpp:198] Convolution13 needs backward computation.
I1001 09:18:31.454530  4916 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1001 09:18:31.454535  4916 net.cpp:198] ReLU11 needs backward computation.
I1001 09:18:31.454540  4916 net.cpp:198] Eltwise5 needs backward computation.
I1001 09:18:31.454545  4916 net.cpp:198] Scale12 needs backward computation.
I1001 09:18:31.454548  4916 net.cpp:198] BatchNorm12 needs backward computation.
I1001 09:18:31.454552  4916 net.cpp:198] Convolution12 needs backward computation.
I1001 09:18:31.454556  4916 net.cpp:198] ReLU10 needs backward computation.
I1001 09:18:31.454560  4916 net.cpp:198] Scale11 needs backward computation.
I1001 09:18:31.454565  4916 net.cpp:198] BatchNorm11 needs backward computation.
I1001 09:18:31.454568  4916 net.cpp:198] Convolution11 needs backward computation.
I1001 09:18:31.454572  4916 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1001 09:18:31.454576  4916 net.cpp:198] ReLU9 needs backward computation.
I1001 09:18:31.454581  4916 net.cpp:198] Eltwise4 needs backward computation.
I1001 09:18:31.454586  4916 net.cpp:198] Scale10 needs backward computation.
I1001 09:18:31.454588  4916 net.cpp:198] BatchNorm10 needs backward computation.
I1001 09:18:31.454592  4916 net.cpp:198] Convolution10 needs backward computation.
I1001 09:18:31.454597  4916 net.cpp:198] ReLU8 needs backward computation.
I1001 09:18:31.454602  4916 net.cpp:198] Scale9 needs backward computation.
I1001 09:18:31.454605  4916 net.cpp:198] BatchNorm9 needs backward computation.
I1001 09:18:31.454609  4916 net.cpp:198] Convolution9 needs backward computation.
I1001 09:18:31.454613  4916 net.cpp:198] Scale8 needs backward computation.
I1001 09:18:31.454617  4916 net.cpp:198] BatchNorm8 needs backward computation.
I1001 09:18:31.454618  4916 net.cpp:198] Convolution8 needs backward computation.
I1001 09:18:31.454628  4916 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1001 09:18:31.454632  4916 net.cpp:198] ReLU7 needs backward computation.
I1001 09:18:31.454633  4916 net.cpp:198] Eltwise3 needs backward computation.
I1001 09:18:31.454637  4916 net.cpp:198] Scale7 needs backward computation.
I1001 09:18:31.454638  4916 net.cpp:198] BatchNorm7 needs backward computation.
I1001 09:18:31.454641  4916 net.cpp:198] Convolution7 needs backward computation.
I1001 09:18:31.454643  4916 net.cpp:198] ReLU6 needs backward computation.
I1001 09:18:31.454646  4916 net.cpp:198] Scale6 needs backward computation.
I1001 09:18:31.454648  4916 net.cpp:198] BatchNorm6 needs backward computation.
I1001 09:18:31.454650  4916 net.cpp:198] Convolution6 needs backward computation.
I1001 09:18:31.454653  4916 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1001 09:18:31.454656  4916 net.cpp:198] ReLU5 needs backward computation.
I1001 09:18:31.454658  4916 net.cpp:198] Eltwise2 needs backward computation.
I1001 09:18:31.454663  4916 net.cpp:198] Scale5 needs backward computation.
I1001 09:18:31.454664  4916 net.cpp:198] BatchNorm5 needs backward computation.
I1001 09:18:31.454666  4916 net.cpp:198] Convolution5 needs backward computation.
I1001 09:18:31.454669  4916 net.cpp:198] ReLU4 needs backward computation.
I1001 09:18:31.454671  4916 net.cpp:198] Scale4 needs backward computation.
I1001 09:18:31.454674  4916 net.cpp:198] BatchNorm4 needs backward computation.
I1001 09:18:31.454676  4916 net.cpp:198] Convolution4 needs backward computation.
I1001 09:18:31.454679  4916 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1001 09:18:31.454682  4916 net.cpp:198] ReLU3 needs backward computation.
I1001 09:18:31.454684  4916 net.cpp:198] Eltwise1 needs backward computation.
I1001 09:18:31.454687  4916 net.cpp:198] Scale3 needs backward computation.
I1001 09:18:31.454690  4916 net.cpp:198] BatchNorm3 needs backward computation.
I1001 09:18:31.454692  4916 net.cpp:198] Convolution3 needs backward computation.
I1001 09:18:31.454695  4916 net.cpp:198] ReLU2 needs backward computation.
I1001 09:18:31.454697  4916 net.cpp:198] Scale2 needs backward computation.
I1001 09:18:31.454699  4916 net.cpp:198] BatchNorm2 needs backward computation.
I1001 09:18:31.454702  4916 net.cpp:198] Convolution2 needs backward computation.
I1001 09:18:31.454704  4916 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1001 09:18:31.454707  4916 net.cpp:198] ReLU1 needs backward computation.
I1001 09:18:31.454710  4916 net.cpp:198] Scale1 needs backward computation.
I1001 09:18:31.454712  4916 net.cpp:198] BatchNorm1 needs backward computation.
I1001 09:18:31.454715  4916 net.cpp:198] Convolution1 needs backward computation.
I1001 09:18:31.454720  4916 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1001 09:18:31.454722  4916 net.cpp:200] Data1 does not need backward computation.
I1001 09:18:31.454725  4916 net.cpp:242] This network produces output Accuracy1
I1001 09:18:31.454727  4916 net.cpp:242] This network produces output SoftmaxWithLoss1
I1001 09:18:31.454766  4916 net.cpp:255] Network initialization done.
I1001 09:18:31.454994  4916 solver.cpp:56] Solver scaffolding done.
I1001 09:18:31.459184  4916 caffe.cpp:248] Starting Optimization
I1001 09:18:31.459192  4916 solver.cpp:272] Solving resnet_cifar10
I1001 09:18:31.459194  4916 solver.cpp:273] Learning Rate Policy: multistep
I1001 09:18:31.460600  4916 solver.cpp:330] Iteration 0, Testing net (#0)
I1001 09:18:32.578351  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:18:32.623201  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1001 09:18:32.623229  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1001 09:18:32.687170  4916 solver.cpp:218] Iteration 0 (0 iter/s, 1.2279s/100 iters), loss = 2.30082
I1001 09:18:32.687202  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30082 (* 1 = 2.30082 loss)
I1001 09:18:32.687243  4916 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1001 09:18:37.476258  4916 solver.cpp:218] Iteration 100 (20.8812 iter/s, 4.78901s/100 iters), loss = 1.65259
I1001 09:18:37.476296  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.65259 (* 1 = 1.65259 loss)
I1001 09:18:37.476302  4916 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1001 09:18:42.266176  4916 solver.cpp:218] Iteration 200 (20.8776 iter/s, 4.78983s/100 iters), loss = 1.76261
I1001 09:18:42.266206  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.76261 (* 1 = 1.76261 loss)
I1001 09:18:42.266222  4916 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1001 09:18:47.061272  4916 solver.cpp:218] Iteration 300 (20.855 iter/s, 4.795s/100 iters), loss = 1.39174
I1001 09:18:47.061309  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.39174 (* 1 = 1.39174 loss)
I1001 09:18:47.061326  4916 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1001 09:18:51.848336  4916 solver.cpp:218] Iteration 400 (20.8902 iter/s, 4.78694s/100 iters), loss = 1.14747
I1001 09:18:51.848366  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14747 (* 1 = 1.14747 loss)
I1001 09:18:51.848372  4916 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1001 09:18:56.397922  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:18:56.588158  4916 solver.cpp:330] Iteration 500, Testing net (#0)
I1001 09:18:57.658823  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:18:57.703831  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2486
I1001 09:18:57.703856  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.76275 (* 1 = 3.76275 loss)
I1001 09:18:57.751899  4916 solver.cpp:218] Iteration 500 (16.9392 iter/s, 5.90347s/100 iters), loss = 1.25285
I1001 09:18:57.751924  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25285 (* 1 = 1.25285 loss)
I1001 09:18:57.751931  4916 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1001 09:19:02.552690  4916 solver.cpp:218] Iteration 600 (20.8302 iter/s, 4.80071s/100 iters), loss = 1.03346
I1001 09:19:02.552886  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03346 (* 1 = 1.03346 loss)
I1001 09:19:02.552893  4916 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1001 09:19:07.344496  4916 solver.cpp:218] Iteration 700 (20.87 iter/s, 4.79156s/100 iters), loss = 1.25665
I1001 09:19:07.344535  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25665 (* 1 = 1.25665 loss)
I1001 09:19:07.344542  4916 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1001 09:19:12.147182  4916 solver.cpp:218] Iteration 800 (20.8221 iter/s, 4.80259s/100 iters), loss = 1.05798
I1001 09:19:12.147222  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05798 (* 1 = 1.05798 loss)
I1001 09:19:12.147228  4916 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1001 09:19:16.939852  4916 solver.cpp:218] Iteration 900 (20.8656 iter/s, 4.79258s/100 iters), loss = 0.837773
I1001 09:19:16.939887  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.837773 (* 1 = 0.837773 loss)
I1001 09:19:16.939893  4916 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1001 09:19:21.498801  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:19:21.690827  4916 solver.cpp:330] Iteration 1000, Testing net (#0)
I1001 09:19:22.761648  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:19:22.807184  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2305
I1001 09:19:22.807219  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 6.13845 (* 1 = 6.13845 loss)
I1001 09:19:22.855809  4916 solver.cpp:218] Iteration 1000 (16.9037 iter/s, 5.91586s/100 iters), loss = 1.01199
I1001 09:19:22.855845  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01199 (* 1 = 1.01199 loss)
I1001 09:19:22.855851  4916 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1001 09:19:27.661154  4916 solver.cpp:218] Iteration 1100 (20.8106 iter/s, 4.80525s/100 iters), loss = 0.765271
I1001 09:19:27.661182  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.765271 (* 1 = 0.765271 loss)
I1001 09:19:27.661188  4916 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1001 09:19:32.463714  4916 solver.cpp:218] Iteration 1200 (20.8226 iter/s, 4.80248s/100 iters), loss = 0.820841
I1001 09:19:32.463747  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.820841 (* 1 = 0.820841 loss)
I1001 09:19:32.463763  4916 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1001 09:19:37.261430  4916 solver.cpp:218] Iteration 1300 (20.8436 iter/s, 4.79763s/100 iters), loss = 0.835543
I1001 09:19:37.261586  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.835543 (* 1 = 0.835543 loss)
I1001 09:19:37.261605  4916 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1001 09:19:42.063403  4916 solver.cpp:218] Iteration 1400 (20.8257 iter/s, 4.80176s/100 iters), loss = 0.680032
I1001 09:19:42.063432  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.680032 (* 1 = 0.680032 loss)
I1001 09:19:42.063438  4916 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1001 09:19:46.620260  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:19:46.811282  4916 solver.cpp:330] Iteration 1500, Testing net (#0)
I1001 09:19:47.888116  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:19:47.933315  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4938
I1001 09:19:47.933351  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.76168 (* 1 = 1.76168 loss)
I1001 09:19:47.981889  4916 solver.cpp:218] Iteration 1500 (16.8965 iter/s, 5.9184s/100 iters), loss = 0.895211
I1001 09:19:47.981927  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.895211 (* 1 = 0.895211 loss)
I1001 09:19:47.981935  4916 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1001 09:19:52.778548  4916 solver.cpp:218] Iteration 1600 (20.8482 iter/s, 4.79657s/100 iters), loss = 0.591911
I1001 09:19:52.778589  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.591911 (* 1 = 0.591911 loss)
I1001 09:19:52.778594  4916 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1001 09:19:57.583390  4916 solver.cpp:218] Iteration 1700 (20.8127 iter/s, 4.80475s/100 iters), loss = 0.734138
I1001 09:19:57.583420  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.734138 (* 1 = 0.734138 loss)
I1001 09:19:57.583426  4916 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1001 09:20:02.397799  4916 solver.cpp:218] Iteration 1800 (20.7713 iter/s, 4.81433s/100 iters), loss = 0.703596
I1001 09:20:02.397840  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.703596 (* 1 = 0.703596 loss)
I1001 09:20:02.397846  4916 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1001 09:20:07.196144  4916 solver.cpp:218] Iteration 1900 (20.8409 iter/s, 4.79825s/100 iters), loss = 0.553819
I1001 09:20:07.196185  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.553819 (* 1 = 0.553819 loss)
I1001 09:20:07.196192  4916 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1001 09:20:11.765146  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:20:11.956845  4916 solver.cpp:330] Iteration 2000, Testing net (#0)
I1001 09:20:13.027385  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:20:13.072803  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5588
I1001 09:20:13.072836  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.33414 (* 1 = 1.33414 loss)
I1001 09:20:13.121193  4916 solver.cpp:218] Iteration 2000 (16.8778 iter/s, 5.92495s/100 iters), loss = 0.76113
I1001 09:20:13.121218  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.76113 (* 1 = 0.76113 loss)
I1001 09:20:13.121224  4916 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1001 09:20:17.925920  4916 solver.cpp:218] Iteration 2100 (20.8132 iter/s, 4.80465s/100 iters), loss = 0.471818
I1001 09:20:17.925961  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471818 (* 1 = 0.471818 loss)
I1001 09:20:17.925966  4916 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1001 09:20:22.773492  4916 solver.cpp:218] Iteration 2200 (20.6293 iter/s, 4.84748s/100 iters), loss = 0.593456
I1001 09:20:22.773526  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.593456 (* 1 = 0.593456 loss)
I1001 09:20:22.773533  4916 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1001 09:20:27.632719  4916 solver.cpp:218] Iteration 2300 (20.5798 iter/s, 4.85914s/100 iters), loss = 0.632978
I1001 09:20:27.632750  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.632978 (* 1 = 0.632978 loss)
I1001 09:20:27.632755  4916 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1001 09:20:32.439795  4916 solver.cpp:218] Iteration 2400 (20.803 iter/s, 4.80699s/100 iters), loss = 0.525618
I1001 09:20:32.439826  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.525618 (* 1 = 0.525618 loss)
I1001 09:20:32.439831  4916 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1001 09:20:37.026916  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:20:37.219120  4916 solver.cpp:330] Iteration 2500, Testing net (#0)
I1001 09:20:38.300114  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:20:38.345072  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5218
I1001 09:20:38.345099  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.56555 (* 1 = 1.56555 loss)
I1001 09:20:38.393401  4916 solver.cpp:218] Iteration 2500 (16.7968 iter/s, 5.95352s/100 iters), loss = 0.686503
I1001 09:20:38.393437  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.686503 (* 1 = 0.686503 loss)
I1001 09:20:38.393455  4916 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1001 09:20:43.213477  4916 solver.cpp:218] Iteration 2600 (20.7469 iter/s, 4.81999s/100 iters), loss = 0.415722
I1001 09:20:43.213774  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415722 (* 1 = 0.415722 loss)
I1001 09:20:43.213784  4916 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1001 09:20:48.074422  4916 solver.cpp:218] Iteration 2700 (20.5738 iter/s, 4.86055s/100 iters), loss = 0.545697
I1001 09:20:48.074455  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545697 (* 1 = 0.545697 loss)
I1001 09:20:48.074460  4916 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1001 09:20:52.915266  4916 solver.cpp:218] Iteration 2800 (20.6579 iter/s, 4.84076s/100 iters), loss = 0.669358
I1001 09:20:52.915311  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.669358 (* 1 = 0.669358 loss)
I1001 09:20:52.915319  4916 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1001 09:20:57.761759  4916 solver.cpp:218] Iteration 2900 (20.634 iter/s, 4.84637s/100 iters), loss = 0.507901
I1001 09:20:57.761795  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.507901 (* 1 = 0.507901 loss)
I1001 09:20:57.761801  4916 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1001 09:21:02.371331  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:21:02.563655  4916 solver.cpp:330] Iteration 3000, Testing net (#0)
I1001 09:21:03.662042  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:21:03.708559  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6212
I1001 09:21:03.708587  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15748 (* 1 = 1.15748 loss)
I1001 09:21:03.758816  4916 solver.cpp:218] Iteration 3000 (16.6751 iter/s, 5.99696s/100 iters), loss = 0.545586
I1001 09:21:03.758858  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545586 (* 1 = 0.545586 loss)
I1001 09:21:03.758867  4916 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1001 09:21:08.620982  4916 solver.cpp:218] Iteration 3100 (20.5674 iter/s, 4.86207s/100 iters), loss = 0.351602
I1001 09:21:08.621018  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351602 (* 1 = 0.351602 loss)
I1001 09:21:08.621035  4916 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1001 09:21:13.447316  4916 solver.cpp:218] Iteration 3200 (20.7201 iter/s, 4.82624s/100 iters), loss = 0.51705
I1001 09:21:13.447491  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51705 (* 1 = 0.51705 loss)
I1001 09:21:13.447525  4916 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1001 09:21:18.289746  4916 solver.cpp:218] Iteration 3300 (20.6517 iter/s, 4.84221s/100 iters), loss = 0.474418
I1001 09:21:18.289783  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474418 (* 1 = 0.474418 loss)
I1001 09:21:18.289790  4916 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1001 09:21:23.133793  4916 solver.cpp:218] Iteration 3400 (20.6443 iter/s, 4.84395s/100 iters), loss = 0.528414
I1001 09:21:23.133846  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.528414 (* 1 = 0.528414 loss)
I1001 09:21:23.133857  4916 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1001 09:21:27.785228  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:21:27.977632  4916 solver.cpp:330] Iteration 3500, Testing net (#0)
I1001 09:21:29.060339  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:21:29.106580  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7121
I1001 09:21:29.106616  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.850525 (* 1 = 0.850525 loss)
I1001 09:21:29.155736  4916 solver.cpp:218] Iteration 3500 (16.6063 iter/s, 6.02181s/100 iters), loss = 0.569026
I1001 09:21:29.155786  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.569026 (* 1 = 0.569026 loss)
I1001 09:21:29.155793  4916 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1001 09:21:34.000325  4916 solver.cpp:218] Iteration 3600 (20.642 iter/s, 4.84449s/100 iters), loss = 0.420284
I1001 09:21:34.000362  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420284 (* 1 = 0.420284 loss)
I1001 09:21:34.000370  4916 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1001 09:21:38.852250  4916 solver.cpp:218] Iteration 3700 (20.6108 iter/s, 4.85183s/100 iters), loss = 0.427001
I1001 09:21:38.852296  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427001 (* 1 = 0.427001 loss)
I1001 09:21:38.852305  4916 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1001 09:21:43.683693  4916 solver.cpp:218] Iteration 3800 (20.6983 iter/s, 4.83131s/100 iters), loss = 0.413484
I1001 09:21:43.683776  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413484 (* 1 = 0.413484 loss)
I1001 09:21:43.683787  4916 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1001 09:21:48.516121  4916 solver.cpp:218] Iteration 3900 (20.6941 iter/s, 4.8323s/100 iters), loss = 0.446739
I1001 09:21:48.516170  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446739 (* 1 = 0.446739 loss)
I1001 09:21:48.516177  4916 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1001 09:21:53.095569  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:21:53.290417  4916 solver.cpp:330] Iteration 4000, Testing net (#0)
I1001 09:21:54.367658  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:21:54.412583  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7119
I1001 09:21:54.412619  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.842293 (* 1 = 0.842293 loss)
I1001 09:21:54.461912  4916 solver.cpp:218] Iteration 4000 (16.8189 iter/s, 5.94569s/100 iters), loss = 0.45161
I1001 09:21:54.461961  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45161 (* 1 = 0.45161 loss)
I1001 09:21:54.461968  4916 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1001 09:21:59.286101  4916 solver.cpp:218] Iteration 4100 (20.7293 iter/s, 4.8241s/100 iters), loss = 0.402822
I1001 09:21:59.286159  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402822 (* 1 = 0.402822 loss)
I1001 09:21:59.286178  4916 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1001 09:22:04.100044  4916 solver.cpp:218] Iteration 4200 (20.7734 iter/s, 4.81384s/100 iters), loss = 0.53494
I1001 09:22:04.100085  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.53494 (* 1 = 0.53494 loss)
I1001 09:22:04.100092  4916 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1001 09:22:08.923326  4916 solver.cpp:218] Iteration 4300 (20.7332 iter/s, 4.82319s/100 iters), loss = 0.55419
I1001 09:22:08.923360  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.55419 (* 1 = 0.55419 loss)
I1001 09:22:08.923368  4916 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1001 09:22:13.730625  4916 solver.cpp:218] Iteration 4400 (20.802 iter/s, 4.80722s/100 iters), loss = 0.485583
I1001 09:22:13.730722  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.485583 (* 1 = 0.485583 loss)
I1001 09:22:13.730732  4916 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1001 09:22:18.306712  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:22:18.500864  4916 solver.cpp:330] Iteration 4500, Testing net (#0)
I1001 09:22:19.577951  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:22:19.623347  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6
I1001 09:22:19.623386  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28632 (* 1 = 1.28632 loss)
I1001 09:22:19.671953  4916 solver.cpp:218] Iteration 4500 (16.8317 iter/s, 5.94118s/100 iters), loss = 0.524046
I1001 09:22:19.671998  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524046 (* 1 = 0.524046 loss)
I1001 09:22:19.672006  4916 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1001 09:22:24.496242  4916 solver.cpp:218] Iteration 4600 (20.7288 iter/s, 4.8242s/100 iters), loss = 0.407636
I1001 09:22:24.496290  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407636 (* 1 = 0.407636 loss)
I1001 09:22:24.496299  4916 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1001 09:22:29.319802  4916 solver.cpp:218] Iteration 4700 (20.732 iter/s, 4.82346s/100 iters), loss = 0.417849
I1001 09:22:29.319840  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417849 (* 1 = 0.417849 loss)
I1001 09:22:29.319859  4916 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1001 09:22:34.131695  4916 solver.cpp:218] Iteration 4800 (20.7822 iter/s, 4.81181s/100 iters), loss = 0.42034
I1001 09:22:34.131743  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420339 (* 1 = 0.420339 loss)
I1001 09:22:34.131752  4916 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1001 09:22:38.984127  4916 solver.cpp:218] Iteration 4900 (20.6086 iter/s, 4.85234s/100 iters), loss = 0.339719
I1001 09:22:38.984177  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339719 (* 1 = 0.339719 loss)
I1001 09:22:38.984185  4916 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1001 09:22:43.566575  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:22:43.767529  4916 solver.cpp:330] Iteration 5000, Testing net (#0)
I1001 09:22:44.871522  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:22:44.916961  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6917
I1001 09:22:44.916998  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.898454 (* 1 = 0.898454 loss)
I1001 09:22:44.965204  4916 solver.cpp:218] Iteration 5000 (16.7196 iter/s, 5.98099s/100 iters), loss = 0.469167
I1001 09:22:44.965251  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469167 (* 1 = 0.469167 loss)
I1001 09:22:44.965260  4916 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1001 09:22:49.796412  4916 solver.cpp:218] Iteration 5100 (20.6992 iter/s, 4.83111s/100 iters), loss = 0.447559
I1001 09:22:49.796458  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447559 (* 1 = 0.447559 loss)
I1001 09:22:49.796466  4916 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1001 09:22:54.654705  4916 solver.cpp:218] Iteration 5200 (20.5837 iter/s, 4.8582s/100 iters), loss = 0.455924
I1001 09:22:54.654741  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.455924 (* 1 = 0.455924 loss)
I1001 09:22:54.654749  4916 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1001 09:22:59.481185  4916 solver.cpp:218] Iteration 5300 (20.7194 iter/s, 4.8264s/100 iters), loss = 0.524864
I1001 09:22:59.481235  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524864 (* 1 = 0.524864 loss)
I1001 09:22:59.481243  4916 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1001 09:23:04.325464  4916 solver.cpp:218] Iteration 5400 (20.6433 iter/s, 4.84419s/100 iters), loss = 0.435395
I1001 09:23:04.325498  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435395 (* 1 = 0.435395 loss)
I1001 09:23:04.325505  4916 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1001 09:23:08.922117  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:23:09.118703  4916 solver.cpp:330] Iteration 5500, Testing net (#0)
I1001 09:23:10.197567  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:23:10.242943  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7274
I1001 09:23:10.242981  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780873 (* 1 = 0.780873 loss)
I1001 09:23:10.291223  4916 solver.cpp:218] Iteration 5500 (16.7625 iter/s, 5.96568s/100 iters), loss = 0.45121
I1001 09:23:10.291267  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45121 (* 1 = 0.45121 loss)
I1001 09:23:10.291275  4916 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1001 09:23:15.127187  4916 solver.cpp:218] Iteration 5600 (20.6788 iter/s, 4.83588s/100 iters), loss = 0.382695
I1001 09:23:15.127334  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382695 (* 1 = 0.382695 loss)
I1001 09:23:15.127346  4916 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1001 09:23:20.018731  4916 solver.cpp:218] Iteration 5700 (20.4442 iter/s, 4.89137s/100 iters), loss = 0.41572
I1001 09:23:20.018790  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41572 (* 1 = 0.41572 loss)
I1001 09:23:20.018811  4916 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1001 09:23:24.848134  4916 solver.cpp:218] Iteration 5800 (20.7069 iter/s, 4.82931s/100 iters), loss = 0.304096
I1001 09:23:24.848171  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304096 (* 1 = 0.304096 loss)
I1001 09:23:24.848189  4916 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1001 09:23:29.677461  4916 solver.cpp:218] Iteration 5900 (20.7072 iter/s, 4.82925s/100 iters), loss = 0.439642
I1001 09:23:29.677500  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439642 (* 1 = 0.439642 loss)
I1001 09:23:29.677516  4916 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1001 09:23:34.247052  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:23:34.439739  4916 solver.cpp:330] Iteration 6000, Testing net (#0)
I1001 09:23:35.520521  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:23:35.565701  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7163
I1001 09:23:35.565735  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.844225 (* 1 = 0.844225 loss)
I1001 09:23:35.614114  4916 solver.cpp:218] Iteration 6000 (16.8447 iter/s, 5.93658s/100 iters), loss = 0.395366
I1001 09:23:35.614161  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395366 (* 1 = 0.395366 loss)
I1001 09:23:35.614167  4916 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1001 09:23:40.421816  4916 solver.cpp:218] Iteration 6100 (20.8003 iter/s, 4.80762s/100 iters), loss = 0.357621
I1001 09:23:40.421859  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357621 (* 1 = 0.357621 loss)
I1001 09:23:40.421866  4916 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1001 09:23:45.246053  4916 solver.cpp:218] Iteration 6200 (20.729 iter/s, 4.82416s/100 iters), loss = 0.428833
I1001 09:23:45.246155  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428833 (* 1 = 0.428833 loss)
I1001 09:23:45.246165  4916 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1001 09:23:50.058404  4916 solver.cpp:218] Iteration 6300 (20.7804 iter/s, 4.81222s/100 iters), loss = 0.466522
I1001 09:23:50.058452  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466521 (* 1 = 0.466521 loss)
I1001 09:23:50.058465  4916 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1001 09:23:54.865119  4916 solver.cpp:218] Iteration 6400 (20.8053 iter/s, 4.80647s/100 iters), loss = 0.432466
I1001 09:23:54.865155  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432466 (* 1 = 0.432466 loss)
I1001 09:23:54.865164  4916 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1001 09:23:59.443506  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:23:59.635601  4916 solver.cpp:330] Iteration 6500, Testing net (#0)
I1001 09:24:00.710085  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:24:00.755090  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7469
I1001 09:24:00.755125  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.745664 (* 1 = 0.745664 loss)
I1001 09:24:00.802983  4916 solver.cpp:218] Iteration 6500 (16.8413 iter/s, 5.93779s/100 iters), loss = 0.476288
I1001 09:24:00.803030  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476288 (* 1 = 0.476288 loss)
I1001 09:24:00.803037  4916 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1001 09:24:05.627765  4916 solver.cpp:218] Iteration 6600 (20.7267 iter/s, 4.8247s/100 iters), loss = 0.307531
I1001 09:24:05.627811  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307531 (* 1 = 0.307531 loss)
I1001 09:24:05.627818  4916 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1001 09:24:10.429556  4916 solver.cpp:218] Iteration 6700 (20.8259 iter/s, 4.80171s/100 iters), loss = 0.319589
I1001 09:24:10.429594  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319589 (* 1 = 0.319589 loss)
I1001 09:24:10.429612  4916 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1001 09:24:15.262102  4916 solver.cpp:218] Iteration 6800 (20.6933 iter/s, 4.83248s/100 iters), loss = 0.396155
I1001 09:24:15.262210  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396155 (* 1 = 0.396155 loss)
I1001 09:24:15.262235  4916 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1001 09:24:20.080657  4916 solver.cpp:218] Iteration 6900 (20.7537 iter/s, 4.81842s/100 iters), loss = 0.311625
I1001 09:24:20.080724  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311625 (* 1 = 0.311625 loss)
I1001 09:24:20.080734  4916 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1001 09:24:24.670415  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:24:24.862155  4916 solver.cpp:330] Iteration 7000, Testing net (#0)
I1001 09:24:25.940379  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:24:25.985596  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6493
I1001 09:24:25.985626  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10373 (* 1 = 1.10373 loss)
I1001 09:24:26.035490  4916 solver.cpp:218] Iteration 7000 (16.7935 iter/s, 5.9547s/100 iters), loss = 0.404325
I1001 09:24:26.035548  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404325 (* 1 = 0.404325 loss)
I1001 09:24:26.035578  4916 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1001 09:24:30.854786  4916 solver.cpp:218] Iteration 7100 (20.7503 iter/s, 4.81921s/100 iters), loss = 0.297518
I1001 09:24:30.854833  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297518 (* 1 = 0.297518 loss)
I1001 09:24:30.854841  4916 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1001 09:24:35.669508  4916 solver.cpp:218] Iteration 7200 (20.77 iter/s, 4.81465s/100 iters), loss = 0.477245
I1001 09:24:35.669551  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.477244 (* 1 = 0.477244 loss)
I1001 09:24:35.669559  4916 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1001 09:24:40.470794  4916 solver.cpp:218] Iteration 7300 (20.8281 iter/s, 4.80121s/100 iters), loss = 0.480449
I1001 09:24:40.470829  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480449 (* 1 = 0.480449 loss)
I1001 09:24:40.470847  4916 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1001 09:24:45.289475  4916 solver.cpp:218] Iteration 7400 (20.7528 iter/s, 4.81862s/100 iters), loss = 0.370715
I1001 09:24:45.289551  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370715 (* 1 = 0.370715 loss)
I1001 09:24:45.289561  4916 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1001 09:24:49.864286  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:24:50.061056  4916 solver.cpp:330] Iteration 7500, Testing net (#0)
I1001 09:24:51.140002  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:24:51.185376  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7412
I1001 09:24:51.185403  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.763004 (* 1 = 0.763004 loss)
I1001 09:24:51.233829  4916 solver.cpp:218] Iteration 7500 (16.823 iter/s, 5.94424s/100 iters), loss = 0.409314
I1001 09:24:51.233866  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409314 (* 1 = 0.409314 loss)
I1001 09:24:51.233875  4916 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1001 09:24:56.048637  4916 solver.cpp:218] Iteration 7600 (20.7696 iter/s, 4.81474s/100 iters), loss = 0.288387
I1001 09:24:56.048691  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288387 (* 1 = 0.288387 loss)
I1001 09:24:56.048703  4916 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1001 09:25:00.873430  4916 solver.cpp:218] Iteration 7700 (20.7268 iter/s, 4.82468s/100 iters), loss = 0.437433
I1001 09:25:00.873466  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437433 (* 1 = 0.437433 loss)
I1001 09:25:00.873478  4916 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1001 09:25:05.694422  4916 solver.cpp:218] Iteration 7800 (20.7429 iter/s, 4.82093s/100 iters), loss = 0.450289
I1001 09:25:05.694461  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450289 (* 1 = 0.450289 loss)
I1001 09:25:05.694481  4916 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1001 09:25:10.505774  4916 solver.cpp:218] Iteration 7900 (20.7845 iter/s, 4.81128s/100 iters), loss = 0.275417
I1001 09:25:10.505823  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275417 (* 1 = 0.275417 loss)
I1001 09:25:10.505834  4916 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1001 09:25:15.119493  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:25:15.312139  4916 solver.cpp:330] Iteration 8000, Testing net (#0)
I1001 09:25:16.385573  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:25:16.430577  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7555
I1001 09:25:16.430613  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.747983 (* 1 = 0.747983 loss)
I1001 09:25:16.479084  4916 solver.cpp:218] Iteration 8000 (16.7413 iter/s, 5.97324s/100 iters), loss = 0.456055
I1001 09:25:16.479132  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456055 (* 1 = 0.456055 loss)
I1001 09:25:16.479140  4916 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1001 09:25:21.301097  4916 solver.cpp:218] Iteration 8100 (20.7386 iter/s, 4.82194s/100 iters), loss = 0.329335
I1001 09:25:21.301131  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329335 (* 1 = 0.329335 loss)
I1001 09:25:21.301148  4916 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1001 09:25:26.118782  4916 solver.cpp:218] Iteration 8200 (20.7572 iter/s, 4.81761s/100 iters), loss = 0.429362
I1001 09:25:26.118845  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429362 (* 1 = 0.429362 loss)
I1001 09:25:26.118854  4916 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1001 09:25:30.937615  4916 solver.cpp:218] Iteration 8300 (20.7523 iter/s, 4.81875s/100 iters), loss = 0.399957
I1001 09:25:30.937650  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399957 (* 1 = 0.399957 loss)
I1001 09:25:30.937669  4916 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1001 09:25:35.761214  4916 solver.cpp:218] Iteration 8400 (20.7318 iter/s, 4.8235s/100 iters), loss = 0.328972
I1001 09:25:35.761262  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328972 (* 1 = 0.328972 loss)
I1001 09:25:35.761270  4916 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1001 09:25:40.334724  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:25:40.526677  4916 solver.cpp:330] Iteration 8500, Testing net (#0)
I1001 09:25:41.612926  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:25:41.658119  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6834
I1001 09:25:41.658148  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.924444 (* 1 = 0.924444 loss)
I1001 09:25:41.706624  4916 solver.cpp:218] Iteration 8500 (16.8199 iter/s, 5.94534s/100 iters), loss = 0.322358
I1001 09:25:41.706668  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322358 (* 1 = 0.322358 loss)
I1001 09:25:41.706676  4916 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1001 09:25:46.521340  4916 solver.cpp:218] Iteration 8600 (20.77 iter/s, 4.81464s/100 iters), loss = 0.301821
I1001 09:25:46.521466  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301821 (* 1 = 0.301821 loss)
I1001 09:25:46.521489  4916 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1001 09:25:51.341027  4916 solver.cpp:218] Iteration 8700 (20.7489 iter/s, 4.81954s/100 iters), loss = 0.461601
I1001 09:25:51.341068  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461601 (* 1 = 0.461601 loss)
I1001 09:25:51.341075  4916 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1001 09:25:56.167505  4916 solver.cpp:218] Iteration 8800 (20.7194 iter/s, 4.8264s/100 iters), loss = 0.36757
I1001 09:25:56.167549  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36757 (* 1 = 0.36757 loss)
I1001 09:25:56.167562  4916 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1001 09:26:00.987272  4916 solver.cpp:218] Iteration 8900 (20.7483 iter/s, 4.81966s/100 iters), loss = 0.299431
I1001 09:26:00.987310  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299431 (* 1 = 0.299431 loss)
I1001 09:26:00.987331  4916 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1001 09:26:05.563520  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:26:05.755815  4916 solver.cpp:330] Iteration 9000, Testing net (#0)
I1001 09:26:06.831483  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:26:06.876593  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7514
I1001 09:26:06.876621  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.725412 (* 1 = 0.725412 loss)
I1001 09:26:06.925096  4916 solver.cpp:218] Iteration 9000 (16.8414 iter/s, 5.93776s/100 iters), loss = 0.300973
I1001 09:26:06.925132  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300973 (* 1 = 0.300973 loss)
I1001 09:26:06.925151  4916 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1001 09:26:11.749195  4916 solver.cpp:218] Iteration 9100 (20.7296 iter/s, 4.82403s/100 iters), loss = 0.345386
I1001 09:26:11.749234  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345386 (* 1 = 0.345386 loss)
I1001 09:26:11.749255  4916 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1001 09:26:16.566548  4916 solver.cpp:218] Iteration 9200 (20.7586 iter/s, 4.81729s/100 iters), loss = 0.34434
I1001 09:26:16.566650  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34434 (* 1 = 0.34434 loss)
I1001 09:26:16.566663  4916 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1001 09:26:21.396883  4916 solver.cpp:218] Iteration 9300 (20.703 iter/s, 4.83022s/100 iters), loss = 0.408154
I1001 09:26:21.396935  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408154 (* 1 = 0.408154 loss)
I1001 09:26:21.396946  4916 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1001 09:26:26.230160  4916 solver.cpp:218] Iteration 9400 (20.6902 iter/s, 4.83321s/100 iters), loss = 0.216301
I1001 09:26:26.230204  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216301 (* 1 = 0.216301 loss)
I1001 09:26:26.230224  4916 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1001 09:26:30.813575  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:26:31.005797  4916 solver.cpp:330] Iteration 9500, Testing net (#0)
I1001 09:26:32.085618  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:26:32.131911  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7613
I1001 09:26:32.131939  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.721402 (* 1 = 0.721402 loss)
I1001 09:26:32.181476  4916 solver.cpp:218] Iteration 9500 (16.8032 iter/s, 5.95124s/100 iters), loss = 0.328298
I1001 09:26:32.181529  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328298 (* 1 = 0.328298 loss)
I1001 09:26:32.181537  4916 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1001 09:26:37.004390  4916 solver.cpp:218] Iteration 9600 (20.7347 iter/s, 4.82283s/100 iters), loss = 0.231208
I1001 09:26:37.004436  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231208 (* 1 = 0.231208 loss)
I1001 09:26:37.004444  4916 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1001 09:26:41.854579  4916 solver.cpp:218] Iteration 9700 (20.6181 iter/s, 4.85011s/100 iters), loss = 0.342504
I1001 09:26:41.854629  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342504 (* 1 = 0.342504 loss)
I1001 09:26:41.854636  4916 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1001 09:26:46.716054  4916 solver.cpp:218] Iteration 9800 (20.5702 iter/s, 4.86139s/100 iters), loss = 0.318818
I1001 09:26:46.716194  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318818 (* 1 = 0.318818 loss)
I1001 09:26:46.716205  4916 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1001 09:26:51.578137  4916 solver.cpp:218] Iteration 9900 (20.5682 iter/s, 4.86187s/100 iters), loss = 0.288297
I1001 09:26:51.578183  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288297 (* 1 = 0.288297 loss)
I1001 09:26:51.578192  4916 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1001 09:26:56.212720  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:26:56.407297  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_10000.caffemodel
I1001 09:26:56.414191  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_10000.solverstate
I1001 09:26:56.415457  4916 solver.cpp:330] Iteration 10000, Testing net (#0)
I1001 09:26:57.497380  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:26:57.543618  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7602
I1001 09:26:57.543651  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.749852 (* 1 = 0.749852 loss)
I1001 09:26:57.593950  4916 solver.cpp:218] Iteration 10000 (16.6231 iter/s, 6.01573s/100 iters), loss = 0.366072
I1001 09:26:57.593989  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366072 (* 1 = 0.366072 loss)
I1001 09:26:57.593997  4916 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1001 09:27:02.465386  4916 solver.cpp:218] Iteration 10100 (20.5281 iter/s, 4.87137s/100 iters), loss = 0.342029
I1001 09:27:02.465437  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342029 (* 1 = 0.342029 loss)
I1001 09:27:02.465445  4916 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1001 09:27:07.328883  4916 solver.cpp:218] Iteration 10200 (20.5616 iter/s, 4.86343s/100 iters), loss = 0.366575
I1001 09:27:07.328924  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366575 (* 1 = 0.366575 loss)
I1001 09:27:07.328932  4916 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1001 09:27:12.202973  4916 solver.cpp:218] Iteration 10300 (20.517 iter/s, 4.87402s/100 iters), loss = 0.300728
I1001 09:27:12.203032  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300728 (* 1 = 0.300728 loss)
I1001 09:27:12.203055  4916 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1001 09:27:17.019153  4916 solver.cpp:218] Iteration 10400 (20.7637 iter/s, 4.8161s/100 iters), loss = 0.35855
I1001 09:27:17.019259  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35855 (* 1 = 0.35855 loss)
I1001 09:27:17.019271  4916 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1001 09:27:21.643134  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:27:21.836127  4916 solver.cpp:330] Iteration 10500, Testing net (#0)
I1001 09:27:22.915036  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:27:22.961170  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7382
I1001 09:27:22.961199  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.791068 (* 1 = 0.791068 loss)
I1001 09:27:23.010939  4916 solver.cpp:218] Iteration 10500 (16.69 iter/s, 5.99162s/100 iters), loss = 0.259241
I1001 09:27:23.010993  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259241 (* 1 = 0.259241 loss)
I1001 09:27:23.011003  4916 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1001 09:27:27.840809  4916 solver.cpp:218] Iteration 10600 (20.7048 iter/s, 4.8298s/100 iters), loss = 0.223555
I1001 09:27:27.840853  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223555 (* 1 = 0.223555 loss)
I1001 09:27:27.840862  4916 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1001 09:27:32.688408  4916 solver.cpp:218] Iteration 10700 (20.629 iter/s, 4.84753s/100 iters), loss = 0.316428
I1001 09:27:32.688452  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316429 (* 1 = 0.316429 loss)
I1001 09:27:32.688458  4916 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1001 09:27:37.550637  4916 solver.cpp:218] Iteration 10800 (20.567 iter/s, 4.86216s/100 iters), loss = 0.474176
I1001 09:27:37.550674  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474176 (* 1 = 0.474176 loss)
I1001 09:27:37.550693  4916 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1001 09:27:42.423799  4916 solver.cpp:218] Iteration 10900 (20.5208 iter/s, 4.8731s/100 iters), loss = 0.369948
I1001 09:27:42.423841  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369948 (* 1 = 0.369948 loss)
I1001 09:27:42.423851  4916 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1001 09:27:47.020520  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:27:47.220386  4916 solver.cpp:330] Iteration 11000, Testing net (#0)
I1001 09:27:48.323187  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:27:48.368523  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.779
I1001 09:27:48.368553  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.714605 (* 1 = 0.714605 loss)
I1001 09:27:48.417332  4916 solver.cpp:218] Iteration 11000 (16.6848 iter/s, 5.99346s/100 iters), loss = 0.388448
I1001 09:27:48.417371  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388448 (* 1 = 0.388448 loss)
I1001 09:27:48.417379  4916 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1001 09:27:53.332134  4916 solver.cpp:218] Iteration 11100 (20.3471 iter/s, 4.9147s/100 iters), loss = 0.323092
I1001 09:27:53.332183  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323092 (* 1 = 0.323092 loss)
I1001 09:27:53.332192  4916 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1001 09:27:58.213119  4916 solver.cpp:218] Iteration 11200 (20.488 iter/s, 4.88091s/100 iters), loss = 0.348018
I1001 09:27:58.213147  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348018 (* 1 = 0.348018 loss)
I1001 09:27:58.213153  4916 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1001 09:28:03.037638  4916 solver.cpp:218] Iteration 11300 (20.7277 iter/s, 4.82446s/100 iters), loss = 0.319888
I1001 09:28:03.037669  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319888 (* 1 = 0.319888 loss)
I1001 09:28:03.037678  4916 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1001 09:28:07.849649  4916 solver.cpp:218] Iteration 11400 (20.7816 iter/s, 4.81195s/100 iters), loss = 0.270137
I1001 09:28:07.849680  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270137 (* 1 = 0.270137 loss)
I1001 09:28:07.849685  4916 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1001 09:28:12.456398  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:28:12.648411  4916 solver.cpp:330] Iteration 11500, Testing net (#0)
I1001 09:28:13.719779  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:28:13.764951  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7778
I1001 09:28:13.764995  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.662793 (* 1 = 0.662793 loss)
I1001 09:28:13.813217  4916 solver.cpp:218] Iteration 11500 (16.7686 iter/s, 5.96351s/100 iters), loss = 0.27707
I1001 09:28:13.813242  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27707 (* 1 = 0.27707 loss)
I1001 09:28:13.813249  4916 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1001 09:28:18.631032  4916 solver.cpp:218] Iteration 11600 (20.7565 iter/s, 4.81776s/100 iters), loss = 0.235043
I1001 09:28:18.631220  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235044 (* 1 = 0.235044 loss)
I1001 09:28:18.631228  4916 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1001 09:28:23.444783  4916 solver.cpp:218] Iteration 11700 (20.7747 iter/s, 4.81354s/100 iters), loss = 0.251631
I1001 09:28:23.444818  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251632 (* 1 = 0.251632 loss)
I1001 09:28:23.444824  4916 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1001 09:28:28.246922  4916 solver.cpp:218] Iteration 11800 (20.8243 iter/s, 4.80208s/100 iters), loss = 0.281451
I1001 09:28:28.246963  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281451 (* 1 = 0.281451 loss)
I1001 09:28:28.246968  4916 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1001 09:28:33.054538  4916 solver.cpp:218] Iteration 11900 (20.8007 iter/s, 4.80754s/100 iters), loss = 0.341704
I1001 09:28:33.054579  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341704 (* 1 = 0.341704 loss)
I1001 09:28:33.054594  4916 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1001 09:28:37.617177  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:28:37.809399  4916 solver.cpp:330] Iteration 12000, Testing net (#0)
I1001 09:28:38.889731  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:28:38.934943  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7351
I1001 09:28:38.934967  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.768538 (* 1 = 0.768538 loss)
I1001 09:28:38.983938  4916 solver.cpp:218] Iteration 12000 (16.8653 iter/s, 5.92933s/100 iters), loss = 0.341651
I1001 09:28:38.983968  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341651 (* 1 = 0.341651 loss)
I1001 09:28:38.983974  4916 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1001 09:28:43.789640  4916 solver.cpp:218] Iteration 12100 (20.809 iter/s, 4.80561s/100 iters), loss = 0.210212
I1001 09:28:43.789672  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210212 (* 1 = 0.210212 loss)
I1001 09:28:43.789677  4916 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1001 09:28:48.606144  4916 solver.cpp:218] Iteration 12200 (20.7622 iter/s, 4.81645s/100 iters), loss = 0.314076
I1001 09:28:48.606176  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314076 (* 1 = 0.314076 loss)
I1001 09:28:48.606182  4916 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1001 09:28:53.421269  4916 solver.cpp:218] Iteration 12300 (20.7682 iter/s, 4.81506s/100 iters), loss = 0.293709
I1001 09:28:53.421375  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293709 (* 1 = 0.293709 loss)
I1001 09:28:53.421383  4916 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1001 09:28:58.264986  4916 solver.cpp:218] Iteration 12400 (20.6459 iter/s, 4.84359s/100 iters), loss = 0.226873
I1001 09:28:58.265027  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226873 (* 1 = 0.226873 loss)
I1001 09:28:58.265033  4916 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1001 09:29:02.885272  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:29:03.076823  4916 solver.cpp:330] Iteration 12500, Testing net (#0)
I1001 09:29:04.170090  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:29:04.215764  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7228
I1001 09:29:04.215801  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.895084 (* 1 = 0.895084 loss)
I1001 09:29:04.263181  4916 solver.cpp:218] Iteration 12500 (16.6719 iter/s, 5.99812s/100 iters), loss = 0.285591
I1001 09:29:04.263208  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285591 (* 1 = 0.285591 loss)
I1001 09:29:04.263216  4916 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1001 09:29:09.068162  4916 solver.cpp:218] Iteration 12600 (20.812 iter/s, 4.80493s/100 iters), loss = 0.363813
I1001 09:29:09.068194  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363813 (* 1 = 0.363813 loss)
I1001 09:29:09.068202  4916 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1001 09:29:13.864519  4916 solver.cpp:218] Iteration 12700 (20.8494 iter/s, 4.7963s/100 iters), loss = 0.333394
I1001 09:29:13.864560  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333394 (* 1 = 0.333394 loss)
I1001 09:29:13.864567  4916 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1001 09:29:18.674417  4916 solver.cpp:218] Iteration 12800 (20.7908 iter/s, 4.80983s/100 iters), loss = 0.374617
I1001 09:29:18.674448  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374617 (* 1 = 0.374617 loss)
I1001 09:29:18.674454  4916 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1001 09:29:23.486932  4916 solver.cpp:218] Iteration 12900 (20.7794 iter/s, 4.81246s/100 iters), loss = 0.290433
I1001 09:29:23.487099  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290433 (* 1 = 0.290433 loss)
I1001 09:29:23.487109  4916 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1001 09:29:28.067493  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:29:28.259059  4916 solver.cpp:330] Iteration 13000, Testing net (#0)
I1001 09:29:29.338812  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:29:29.384091  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7676
I1001 09:29:29.384129  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.685597 (* 1 = 0.685597 loss)
I1001 09:29:29.432410  4916 solver.cpp:218] Iteration 13000 (16.82 iter/s, 5.94529s/100 iters), loss = 0.378123
I1001 09:29:29.432441  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378123 (* 1 = 0.378123 loss)
I1001 09:29:29.432448  4916 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1001 09:29:34.249166  4916 solver.cpp:218] Iteration 13100 (20.7611 iter/s, 4.8167s/100 iters), loss = 0.246971
I1001 09:29:34.249197  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246971 (* 1 = 0.246971 loss)
I1001 09:29:34.249202  4916 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1001 09:29:39.075691  4916 solver.cpp:218] Iteration 13200 (20.7191 iter/s, 4.82647s/100 iters), loss = 0.336566
I1001 09:29:39.075721  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336566 (* 1 = 0.336566 loss)
I1001 09:29:39.075728  4916 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1001 09:29:43.872622  4916 solver.cpp:218] Iteration 13300 (20.8469 iter/s, 4.79688s/100 iters), loss = 0.366507
I1001 09:29:43.872654  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366507 (* 1 = 0.366507 loss)
I1001 09:29:43.872660  4916 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1001 09:29:48.684993  4916 solver.cpp:218] Iteration 13400 (20.78 iter/s, 4.81232s/100 iters), loss = 0.251155
I1001 09:29:48.685032  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251155 (* 1 = 0.251155 loss)
I1001 09:29:48.685039  4916 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1001 09:29:53.258344  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:29:53.449831  4916 solver.cpp:330] Iteration 13500, Testing net (#0)
I1001 09:29:54.523275  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:29:54.568823  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7823
I1001 09:29:54.568859  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.666032 (* 1 = 0.666032 loss)
I1001 09:29:54.616864  4916 solver.cpp:218] Iteration 13500 (16.8583 iter/s, 5.93181s/100 iters), loss = 0.411166
I1001 09:29:54.616888  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411166 (* 1 = 0.411166 loss)
I1001 09:29:54.616895  4916 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1001 09:29:59.427299  4916 solver.cpp:218] Iteration 13600 (20.7884 iter/s, 4.81038s/100 iters), loss = 0.341982
I1001 09:29:59.427340  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341982 (* 1 = 0.341982 loss)
I1001 09:29:59.427345  4916 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1001 09:30:04.220708  4916 solver.cpp:218] Iteration 13700 (20.8623 iter/s, 4.79335s/100 iters), loss = 0.273849
I1001 09:30:04.220749  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273849 (* 1 = 0.273849 loss)
I1001 09:30:04.220755  4916 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1001 09:30:09.028017  4916 solver.cpp:218] Iteration 13800 (20.8019 iter/s, 4.80724s/100 iters), loss = 0.32744
I1001 09:30:09.028060  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32744 (* 1 = 0.32744 loss)
I1001 09:30:09.028066  4916 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1001 09:30:13.830642  4916 solver.cpp:218] Iteration 13900 (20.8222 iter/s, 4.80256s/100 iters), loss = 0.251663
I1001 09:30:13.830683  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251662 (* 1 = 0.251662 loss)
I1001 09:30:13.830689  4916 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1001 09:30:18.402050  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:30:18.594475  4916 solver.cpp:330] Iteration 14000, Testing net (#0)
I1001 09:30:19.668324  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:30:19.713903  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7876
I1001 09:30:19.713928  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.637193 (* 1 = 0.637193 loss)
I1001 09:30:19.761850  4916 solver.cpp:218] Iteration 14000 (16.8602 iter/s, 5.93114s/100 iters), loss = 0.276718
I1001 09:30:19.761884  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276718 (* 1 = 0.276718 loss)
I1001 09:30:19.761891  4916 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1001 09:30:24.575850  4916 solver.cpp:218] Iteration 14100 (20.773 iter/s, 4.81394s/100 iters), loss = 0.377027
I1001 09:30:24.575984  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377027 (* 1 = 0.377027 loss)
I1001 09:30:24.575991  4916 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1001 09:30:29.388938  4916 solver.cpp:218] Iteration 14200 (20.7773 iter/s, 4.81294s/100 iters), loss = 0.359145
I1001 09:30:29.388969  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359145 (* 1 = 0.359145 loss)
I1001 09:30:29.388975  4916 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1001 09:30:34.190901  4916 solver.cpp:218] Iteration 14300 (20.8251 iter/s, 4.80191s/100 iters), loss = 0.334509
I1001 09:30:34.190942  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334509 (* 1 = 0.334509 loss)
I1001 09:30:34.190948  4916 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1001 09:30:39.000386  4916 solver.cpp:218] Iteration 14400 (20.7925 iter/s, 4.80942s/100 iters), loss = 0.237496
I1001 09:30:39.000427  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237496 (* 1 = 0.237496 loss)
I1001 09:30:39.000432  4916 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1001 09:30:43.567602  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:30:43.760304  4916 solver.cpp:330] Iteration 14500, Testing net (#0)
I1001 09:30:44.845726  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:30:44.890786  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7871
I1001 09:30:44.890822  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.62853 (* 1 = 0.62853 loss)
I1001 09:30:44.939348  4916 solver.cpp:218] Iteration 14500 (16.8382 iter/s, 5.93889s/100 iters), loss = 0.298485
I1001 09:30:44.939374  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298485 (* 1 = 0.298485 loss)
I1001 09:30:44.939381  4916 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1001 09:30:49.738667  4916 solver.cpp:218] Iteration 14600 (20.8365 iter/s, 4.79927s/100 iters), loss = 0.314647
I1001 09:30:49.738698  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314647 (* 1 = 0.314647 loss)
I1001 09:30:49.738714  4916 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1001 09:30:54.540802  4916 solver.cpp:218] Iteration 14700 (20.8243 iter/s, 4.80208s/100 iters), loss = 0.273852
I1001 09:30:54.540845  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273852 (* 1 = 0.273852 loss)
I1001 09:30:54.540853  4916 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1001 09:30:59.346685  4916 solver.cpp:218] Iteration 14800 (20.8081 iter/s, 4.80582s/100 iters), loss = 0.252939
I1001 09:30:59.346838  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252939 (* 1 = 0.252939 loss)
I1001 09:30:59.346846  4916 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1001 09:31:04.147198  4916 solver.cpp:218] Iteration 14900 (20.8318 iter/s, 4.80035s/100 iters), loss = 0.258745
I1001 09:31:04.147239  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258745 (* 1 = 0.258745 loss)
I1001 09:31:04.147246  4916 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1001 09:31:08.728549  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:31:08.920593  4916 solver.cpp:330] Iteration 15000, Testing net (#0)
I1001 09:31:09.996840  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:31:10.042009  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.807
I1001 09:31:10.042033  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.567743 (* 1 = 0.567743 loss)
I1001 09:31:10.090132  4916 solver.cpp:218] Iteration 15000 (16.827 iter/s, 5.94284s/100 iters), loss = 0.251574
I1001 09:31:10.090155  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251574 (* 1 = 0.251574 loss)
I1001 09:31:10.090162  4916 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1001 09:31:14.941606  4916 solver.cpp:218] Iteration 15100 (20.6125 iter/s, 4.85142s/100 iters), loss = 0.257186
I1001 09:31:14.941646  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257186 (* 1 = 0.257186 loss)
I1001 09:31:14.941653  4916 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1001 09:31:19.807420  4916 solver.cpp:218] Iteration 15200 (20.5518 iter/s, 4.86574s/100 iters), loss = 0.288205
I1001 09:31:19.807451  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288205 (* 1 = 0.288205 loss)
I1001 09:31:19.807468  4916 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1001 09:31:24.682513  4916 solver.cpp:218] Iteration 15300 (20.5127 iter/s, 4.87504s/100 iters), loss = 0.291922
I1001 09:31:24.682544  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291922 (* 1 = 0.291922 loss)
I1001 09:31:24.682550  4916 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1001 09:31:29.493333  4916 solver.cpp:218] Iteration 15400 (20.7867 iter/s, 4.81076s/100 iters), loss = 0.258219
I1001 09:31:29.493460  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258219 (* 1 = 0.258219 loss)
I1001 09:31:29.493479  4916 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1001 09:31:34.087492  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:31:34.281592  4916 solver.cpp:330] Iteration 15500, Testing net (#0)
I1001 09:31:35.382273  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:31:35.427814  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7113
I1001 09:31:35.427839  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01178 (* 1 = 1.01178 loss)
I1001 09:31:35.476153  4916 solver.cpp:218] Iteration 15500 (16.7149 iter/s, 5.98268s/100 iters), loss = 0.236495
I1001 09:31:35.476186  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236495 (* 1 = 0.236495 loss)
I1001 09:31:35.476193  4916 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1001 09:31:40.324512  4916 solver.cpp:218] Iteration 15600 (20.6258 iter/s, 4.84829s/100 iters), loss = 0.31428
I1001 09:31:40.324542  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31428 (* 1 = 0.31428 loss)
I1001 09:31:40.324549  4916 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1001 09:31:45.173522  4916 solver.cpp:218] Iteration 15700 (20.623 iter/s, 4.84895s/100 iters), loss = 0.364631
I1001 09:31:45.173557  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364631 (* 1 = 0.364631 loss)
I1001 09:31:45.173563  4916 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1001 09:31:50.057464  4916 solver.cpp:218] Iteration 15800 (20.4755 iter/s, 4.88388s/100 iters), loss = 0.287325
I1001 09:31:50.057516  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287325 (* 1 = 0.287325 loss)
I1001 09:31:50.057538  4916 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1001 09:31:54.965867  4916 solver.cpp:218] Iteration 15900 (20.3736 iter/s, 4.9083s/100 iters), loss = 0.175059
I1001 09:31:54.965898  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175059 (* 1 = 0.175059 loss)
I1001 09:31:54.965904  4916 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1001 09:31:59.607302  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:31:59.798842  4916 solver.cpp:330] Iteration 16000, Testing net (#0)
I1001 09:32:00.873661  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:32:00.918591  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6527
I1001 09:32:00.918625  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2191 (* 1 = 1.2191 loss)
I1001 09:32:00.967124  4916 solver.cpp:218] Iteration 16000 (16.6633 iter/s, 6.0012s/100 iters), loss = 0.23358
I1001 09:32:00.967150  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23358 (* 1 = 0.23358 loss)
I1001 09:32:00.967157  4916 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1001 09:32:05.834909  4916 solver.cpp:218] Iteration 16100 (20.5434 iter/s, 4.86773s/100 iters), loss = 0.265024
I1001 09:32:05.834951  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265024 (* 1 = 0.265024 loss)
I1001 09:32:05.834959  4916 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1001 09:32:10.653249  4916 solver.cpp:218] Iteration 16200 (20.7543 iter/s, 4.81828s/100 iters), loss = 0.254923
I1001 09:32:10.653280  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254923 (* 1 = 0.254923 loss)
I1001 09:32:10.653287  4916 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1001 09:32:15.499044  4916 solver.cpp:218] Iteration 16300 (20.6367 iter/s, 4.84574s/100 iters), loss = 0.273057
I1001 09:32:15.499074  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273057 (* 1 = 0.273057 loss)
I1001 09:32:15.499080  4916 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1001 09:32:20.336835  4916 solver.cpp:218] Iteration 16400 (20.6708 iter/s, 4.83773s/100 iters), loss = 0.220066
I1001 09:32:20.336877  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220066 (* 1 = 0.220066 loss)
I1001 09:32:20.336885  4916 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1001 09:32:24.956537  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:32:25.149045  4916 solver.cpp:330] Iteration 16500, Testing net (#0)
I1001 09:32:26.234964  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:32:26.280974  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8062
I1001 09:32:26.281009  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.589167 (* 1 = 0.589167 loss)
I1001 09:32:26.329286  4916 solver.cpp:218] Iteration 16500 (16.6879 iter/s, 5.99238s/100 iters), loss = 0.274883
I1001 09:32:26.329321  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274883 (* 1 = 0.274883 loss)
I1001 09:32:26.329329  4916 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1001 09:32:31.141230  4916 solver.cpp:218] Iteration 16600 (20.7819 iter/s, 4.81189s/100 iters), loss = 0.323933
I1001 09:32:31.141329  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323933 (* 1 = 0.323933 loss)
I1001 09:32:31.141345  4916 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1001 09:32:35.943835  4916 solver.cpp:218] Iteration 16700 (20.8226 iter/s, 4.80248s/100 iters), loss = 0.439276
I1001 09:32:35.943876  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439276 (* 1 = 0.439276 loss)
I1001 09:32:35.943882  4916 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1001 09:32:40.739590  4916 solver.cpp:218] Iteration 16800 (20.8521 iter/s, 4.79569s/100 iters), loss = 0.279344
I1001 09:32:40.739631  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279344 (* 1 = 0.279344 loss)
I1001 09:32:40.739637  4916 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1001 09:32:45.544885  4916 solver.cpp:218] Iteration 16900 (20.8107 iter/s, 4.80523s/100 iters), loss = 0.243647
I1001 09:32:45.544915  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243647 (* 1 = 0.243647 loss)
I1001 09:32:45.544921  4916 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1001 09:32:50.112299  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:32:50.308485  4916 solver.cpp:330] Iteration 17000, Testing net (#0)
I1001 09:32:51.379130  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:32:51.424418  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7851
I1001 09:32:51.424454  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.661681 (* 1 = 0.661681 loss)
I1001 09:32:51.472746  4916 solver.cpp:218] Iteration 17000 (16.8697 iter/s, 5.9278s/100 iters), loss = 0.301872
I1001 09:32:51.472777  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301872 (* 1 = 0.301872 loss)
I1001 09:32:51.472784  4916 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1001 09:32:56.282676  4916 solver.cpp:218] Iteration 17100 (20.7906 iter/s, 4.80988s/100 iters), loss = 0.28475
I1001 09:32:56.282711  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28475 (* 1 = 0.28475 loss)
I1001 09:32:56.282717  4916 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1001 09:33:01.083981  4916 solver.cpp:218] Iteration 17200 (20.8279 iter/s, 4.80124s/100 iters), loss = 0.282354
I1001 09:33:01.084010  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282354 (* 1 = 0.282354 loss)
I1001 09:33:01.084017  4916 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1001 09:33:05.895587  4916 solver.cpp:218] Iteration 17300 (20.7833 iter/s, 4.81155s/100 iters), loss = 0.351978
I1001 09:33:05.895681  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351978 (* 1 = 0.351978 loss)
I1001 09:33:05.895699  4916 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1001 09:33:10.696357  4916 solver.cpp:218] Iteration 17400 (20.8305 iter/s, 4.80065s/100 iters), loss = 0.328078
I1001 09:33:10.696388  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328078 (* 1 = 0.328078 loss)
I1001 09:33:10.696393  4916 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1001 09:33:15.265595  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:33:15.457315  4916 solver.cpp:330] Iteration 17500, Testing net (#0)
I1001 09:33:16.528273  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:33:16.573801  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7561
I1001 09:33:16.573825  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.7479 (* 1 = 0.7479 loss)
I1001 09:33:16.622212  4916 solver.cpp:218] Iteration 17500 (16.8754 iter/s, 5.9258s/100 iters), loss = 0.25551
I1001 09:33:16.622236  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255509 (* 1 = 0.255509 loss)
I1001 09:33:16.622242  4916 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1001 09:33:21.434100  4916 solver.cpp:218] Iteration 17600 (20.7821 iter/s, 4.81184s/100 iters), loss = 0.228002
I1001 09:33:21.434130  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228002 (* 1 = 0.228002 loss)
I1001 09:33:21.434136  4916 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1001 09:33:26.252495  4916 solver.cpp:218] Iteration 17700 (20.754 iter/s, 4.81834s/100 iters), loss = 0.293224
I1001 09:33:26.252538  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293224 (* 1 = 0.293224 loss)
I1001 09:33:26.252545  4916 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1001 09:33:31.063251  4916 solver.cpp:218] Iteration 17800 (20.7872 iter/s, 4.81065s/100 iters), loss = 0.294901
I1001 09:33:31.063292  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294901 (* 1 = 0.294901 loss)
I1001 09:33:31.063297  4916 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1001 09:33:35.881873  4916 solver.cpp:218] Iteration 17900 (20.7531 iter/s, 4.81856s/100 iters), loss = 0.222428
I1001 09:33:35.881916  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222428 (* 1 = 0.222428 loss)
I1001 09:33:35.881920  4916 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1001 09:33:40.462218  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:33:40.654791  4916 solver.cpp:330] Iteration 18000, Testing net (#0)
I1001 09:33:41.737267  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:33:41.782408  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7817
I1001 09:33:41.782443  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.667718 (* 1 = 0.667718 loss)
I1001 09:33:41.830696  4916 solver.cpp:218] Iteration 18000 (16.8102 iter/s, 5.94876s/100 iters), loss = 0.289977
I1001 09:33:41.830720  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289977 (* 1 = 0.289977 loss)
I1001 09:33:41.830726  4916 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1001 09:33:46.640534  4916 solver.cpp:218] Iteration 18100 (20.7909 iter/s, 4.80979s/100 iters), loss = 0.2918
I1001 09:33:46.640563  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2918 (* 1 = 0.2918 loss)
I1001 09:33:46.640579  4916 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1001 09:33:51.458211  4916 solver.cpp:218] Iteration 18200 (20.7571 iter/s, 4.81763s/100 iters), loss = 0.27686
I1001 09:33:51.458241  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27686 (* 1 = 0.27686 loss)
I1001 09:33:51.458246  4916 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1001 09:33:56.277791  4916 solver.cpp:218] Iteration 18300 (20.7489 iter/s, 4.81952s/100 iters), loss = 0.202179
I1001 09:33:56.277827  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202179 (* 1 = 0.202179 loss)
I1001 09:33:56.277833  4916 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1001 09:34:01.091145  4916 solver.cpp:218] Iteration 18400 (20.7758 iter/s, 4.81329s/100 iters), loss = 0.213725
I1001 09:34:01.091174  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213724 (* 1 = 0.213724 loss)
I1001 09:34:01.091190  4916 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1001 09:34:05.667812  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:34:05.860266  4916 solver.cpp:330] Iteration 18500, Testing net (#0)
I1001 09:34:06.932732  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:34:06.978070  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7977
I1001 09:34:06.978104  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.621005 (* 1 = 0.621005 loss)
I1001 09:34:07.026528  4916 solver.cpp:218] Iteration 18500 (16.8483 iter/s, 5.93533s/100 iters), loss = 0.260217
I1001 09:34:07.026552  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260217 (* 1 = 0.260217 loss)
I1001 09:34:07.026559  4916 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1001 09:34:11.846516  4916 solver.cpp:218] Iteration 18600 (20.7471 iter/s, 4.81994s/100 iters), loss = 0.276955
I1001 09:34:11.846688  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276955 (* 1 = 0.276955 loss)
I1001 09:34:11.846696  4916 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1001 09:34:16.657209  4916 solver.cpp:218] Iteration 18700 (20.7878 iter/s, 4.81051s/100 iters), loss = 0.316037
I1001 09:34:16.657249  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316037 (* 1 = 0.316037 loss)
I1001 09:34:16.657255  4916 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1001 09:34:21.473425  4916 solver.cpp:218] Iteration 18800 (20.7635 iter/s, 4.81615s/100 iters), loss = 0.264752
I1001 09:34:21.473465  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264752 (* 1 = 0.264752 loss)
I1001 09:34:21.473471  4916 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1001 09:34:26.296716  4916 solver.cpp:218] Iteration 18900 (20.733 iter/s, 4.82323s/100 iters), loss = 0.226487
I1001 09:34:26.296761  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226487 (* 1 = 0.226487 loss)
I1001 09:34:26.296768  4916 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1001 09:34:30.873333  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:34:31.065827  4916 solver.cpp:330] Iteration 19000, Testing net (#0)
I1001 09:34:32.145800  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:34:32.192549  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I1001 09:34:32.192579  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.657863 (* 1 = 0.657863 loss)
I1001 09:34:32.242005  4916 solver.cpp:218] Iteration 19000 (16.8203 iter/s, 5.94521s/100 iters), loss = 0.251728
I1001 09:34:32.242050  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251728 (* 1 = 0.251728 loss)
I1001 09:34:32.242058  4916 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1001 09:34:37.053238  4916 solver.cpp:218] Iteration 19100 (20.7852 iter/s, 4.81112s/100 iters), loss = 0.286145
I1001 09:34:37.053268  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286145 (* 1 = 0.286145 loss)
I1001 09:34:37.053274  4916 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1001 09:34:41.873556  4916 solver.cpp:218] Iteration 19200 (20.7458 iter/s, 4.82026s/100 iters), loss = 0.31879
I1001 09:34:41.873702  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31879 (* 1 = 0.31879 loss)
I1001 09:34:41.873708  4916 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1001 09:34:46.687657  4916 solver.cpp:218] Iteration 19300 (20.773 iter/s, 4.81395s/100 iters), loss = 0.271596
I1001 09:34:46.687686  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271596 (* 1 = 0.271596 loss)
I1001 09:34:46.687692  4916 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1001 09:34:51.504204  4916 solver.cpp:218] Iteration 19400 (20.762 iter/s, 4.81649s/100 iters), loss = 0.233569
I1001 09:34:51.504245  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233569 (* 1 = 0.233569 loss)
I1001 09:34:51.504251  4916 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1001 09:34:56.078822  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:34:56.275014  4916 solver.cpp:330] Iteration 19500, Testing net (#0)
I1001 09:34:57.349532  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:34:57.394369  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8005
I1001 09:34:57.394404  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.610413 (* 1 = 0.610413 loss)
I1001 09:34:57.442832  4916 solver.cpp:218] Iteration 19500 (16.8391 iter/s, 5.93856s/100 iters), loss = 0.338921
I1001 09:34:57.442860  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338921 (* 1 = 0.338921 loss)
I1001 09:34:57.442867  4916 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1001 09:35:02.257632  4916 solver.cpp:218] Iteration 19600 (20.7696 iter/s, 4.81473s/100 iters), loss = 0.258809
I1001 09:35:02.257704  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258809 (* 1 = 0.258809 loss)
I1001 09:35:02.257711  4916 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1001 09:35:07.069676  4916 solver.cpp:218] Iteration 19700 (20.7816 iter/s, 4.81196s/100 iters), loss = 0.272428
I1001 09:35:07.069717  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272428 (* 1 = 0.272428 loss)
I1001 09:35:07.069722  4916 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1001 09:35:11.887389  4916 solver.cpp:218] Iteration 19800 (20.757 iter/s, 4.81765s/100 iters), loss = 0.280755
I1001 09:35:11.887518  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280755 (* 1 = 0.280755 loss)
I1001 09:35:11.887526  4916 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1001 09:35:16.698348  4916 solver.cpp:218] Iteration 19900 (20.7865 iter/s, 4.81081s/100 iters), loss = 0.174829
I1001 09:35:16.698390  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174829 (* 1 = 0.174829 loss)
I1001 09:35:16.698395  4916 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1001 09:35:21.285620  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:35:21.478008  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_20000.caffemodel
I1001 09:35:21.482107  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_20000.solverstate
I1001 09:35:21.483402  4916 solver.cpp:330] Iteration 20000, Testing net (#0)
I1001 09:35:22.556473  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:35:22.601941  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8115
I1001 09:35:22.601966  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.556435 (* 1 = 0.556435 loss)
I1001 09:35:22.650207  4916 solver.cpp:218] Iteration 20000 (16.8017 iter/s, 5.95179s/100 iters), loss = 0.236952
I1001 09:35:22.650229  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236952 (* 1 = 0.236952 loss)
I1001 09:35:22.650236  4916 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1001 09:35:27.469596  4916 solver.cpp:218] Iteration 20100 (20.7497 iter/s, 4.81934s/100 iters), loss = 0.216896
I1001 09:35:27.469636  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216896 (* 1 = 0.216896 loss)
I1001 09:35:27.469642  4916 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1001 09:35:32.289186  4916 solver.cpp:218] Iteration 20200 (20.7489 iter/s, 4.81953s/100 iters), loss = 0.285095
I1001 09:35:32.289222  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285095 (* 1 = 0.285095 loss)
I1001 09:35:32.289229  4916 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1001 09:35:37.101454  4916 solver.cpp:218] Iteration 20300 (20.7805 iter/s, 4.81221s/100 iters), loss = 0.338763
I1001 09:35:37.101495  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338763 (* 1 = 0.338763 loss)
I1001 09:35:37.101500  4916 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1001 09:35:41.916934  4916 solver.cpp:218] Iteration 20400 (20.7666 iter/s, 4.81542s/100 iters), loss = 0.250735
I1001 09:35:41.917049  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250735 (* 1 = 0.250735 loss)
I1001 09:35:41.917065  4916 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1001 09:35:46.490308  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:35:46.681790  4916 solver.cpp:330] Iteration 20500, Testing net (#0)
I1001 09:35:47.762199  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:35:47.807943  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7621
I1001 09:35:47.807978  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.738864 (* 1 = 0.738864 loss)
I1001 09:35:47.856570  4916 solver.cpp:218] Iteration 20500 (16.8364 iter/s, 5.9395s/100 iters), loss = 0.228772
I1001 09:35:47.856595  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228773 (* 1 = 0.228773 loss)
I1001 09:35:47.856602  4916 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1001 09:35:52.659633  4916 solver.cpp:218] Iteration 20600 (20.8202 iter/s, 4.80302s/100 iters), loss = 0.194761
I1001 09:35:52.659663  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194762 (* 1 = 0.194762 loss)
I1001 09:35:52.659668  4916 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1001 09:35:57.475553  4916 solver.cpp:218] Iteration 20700 (20.7647 iter/s, 4.81587s/100 iters), loss = 0.333389
I1001 09:35:57.475584  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333389 (* 1 = 0.333389 loss)
I1001 09:35:57.475589  4916 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1001 09:36:02.299065  4916 solver.cpp:218] Iteration 20800 (20.732 iter/s, 4.82346s/100 iters), loss = 0.291743
I1001 09:36:02.299100  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291743 (* 1 = 0.291743 loss)
I1001 09:36:02.299108  4916 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1001 09:36:07.112779  4916 solver.cpp:218] Iteration 20900 (20.7742 iter/s, 4.81366s/100 iters), loss = 0.226535
I1001 09:36:07.112809  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226535 (* 1 = 0.226535 loss)
I1001 09:36:07.112815  4916 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1001 09:36:11.698352  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:36:11.889711  4916 solver.cpp:330] Iteration 21000, Testing net (#0)
I1001 09:36:12.963537  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:36:13.008808  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7937
I1001 09:36:13.008843  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.626545 (* 1 = 0.626545 loss)
I1001 09:36:13.057132  4916 solver.cpp:218] Iteration 21000 (16.8228 iter/s, 5.9443s/100 iters), loss = 0.190385
I1001 09:36:13.057157  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190385 (* 1 = 0.190385 loss)
I1001 09:36:13.057163  4916 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1001 09:36:17.879318  4916 solver.cpp:218] Iteration 21100 (20.7377 iter/s, 4.82214s/100 iters), loss = 0.208238
I1001 09:36:17.879348  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208238 (* 1 = 0.208238 loss)
I1001 09:36:17.879354  4916 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1001 09:36:22.685372  4916 solver.cpp:218] Iteration 21200 (20.8073 iter/s, 4.806s/100 iters), loss = 0.206105
I1001 09:36:22.685412  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206105 (* 1 = 0.206105 loss)
I1001 09:36:22.685418  4916 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1001 09:36:27.499878  4916 solver.cpp:218] Iteration 21300 (20.7708 iter/s, 4.81444s/100 iters), loss = 0.223728
I1001 09:36:27.499907  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223728 (* 1 = 0.223728 loss)
I1001 09:36:27.499913  4916 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1001 09:36:32.316251  4916 solver.cpp:218] Iteration 21400 (20.7627 iter/s, 4.81632s/100 iters), loss = 0.213062
I1001 09:36:32.316287  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213062 (* 1 = 0.213062 loss)
I1001 09:36:32.316293  4916 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1001 09:36:36.884637  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:36:37.077226  4916 solver.cpp:330] Iteration 21500, Testing net (#0)
I1001 09:36:38.155005  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:36:38.200608  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7729
I1001 09:36:38.200646  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.732173 (* 1 = 0.732173 loss)
I1001 09:36:38.250666  4916 solver.cpp:218] Iteration 21500 (16.851 iter/s, 5.93435s/100 iters), loss = 0.291929
I1001 09:36:38.250700  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291929 (* 1 = 0.291929 loss)
I1001 09:36:38.250706  4916 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1001 09:36:43.061244  4916 solver.cpp:218] Iteration 21600 (20.7878 iter/s, 4.81052s/100 iters), loss = 0.25518
I1001 09:36:43.061383  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25518 (* 1 = 0.25518 loss)
I1001 09:36:43.061399  4916 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1001 09:36:47.879520  4916 solver.cpp:218] Iteration 21700 (20.755 iter/s, 4.81812s/100 iters), loss = 0.302654
I1001 09:36:47.879561  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302654 (* 1 = 0.302654 loss)
I1001 09:36:47.879567  4916 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1001 09:36:52.693585  4916 solver.cpp:218] Iteration 21800 (20.7727 iter/s, 4.814s/100 iters), loss = 0.340464
I1001 09:36:52.693627  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340464 (* 1 = 0.340464 loss)
I1001 09:36:52.693634  4916 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1001 09:36:57.516494  4916 solver.cpp:218] Iteration 21900 (20.7347 iter/s, 4.82284s/100 iters), loss = 0.254345
I1001 09:36:57.516523  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254345 (* 1 = 0.254345 loss)
I1001 09:36:57.516530  4916 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1001 09:37:02.089953  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:37:02.287328  4916 solver.cpp:330] Iteration 22000, Testing net (#0)
I1001 09:37:03.362190  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:37:03.407788  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8177
I1001 09:37:03.407824  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55607 (* 1 = 0.55607 loss)
I1001 09:37:03.456104  4916 solver.cpp:218] Iteration 22000 (16.8363 iter/s, 5.93956s/100 iters), loss = 0.245833
I1001 09:37:03.456128  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245834 (* 1 = 0.245834 loss)
I1001 09:37:03.456135  4916 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1001 09:37:08.272887  4916 solver.cpp:218] Iteration 22100 (20.761 iter/s, 4.81673s/100 iters), loss = 0.274976
I1001 09:37:08.272931  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274976 (* 1 = 0.274976 loss)
I1001 09:37:08.272938  4916 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1001 09:37:13.082231  4916 solver.cpp:218] Iteration 22200 (20.7933 iter/s, 4.80925s/100 iters), loss = 0.323411
I1001 09:37:13.082347  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323411 (* 1 = 0.323411 loss)
I1001 09:37:13.082355  4916 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1001 09:37:17.896303  4916 solver.cpp:218] Iteration 22300 (20.773 iter/s, 4.81394s/100 iters), loss = 0.260835
I1001 09:37:17.896344  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260835 (* 1 = 0.260835 loss)
I1001 09:37:17.896350  4916 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1001 09:37:22.695621  4916 solver.cpp:218] Iteration 22400 (20.8366 iter/s, 4.79925s/100 iters), loss = 0.26018
I1001 09:37:22.695650  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26018 (* 1 = 0.26018 loss)
I1001 09:37:22.695657  4916 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1001 09:37:27.273669  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:37:27.465467  4916 solver.cpp:330] Iteration 22500, Testing net (#0)
I1001 09:37:28.537804  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:37:28.583140  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7506
I1001 09:37:28.583176  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.854726 (* 1 = 0.854726 loss)
I1001 09:37:28.631919  4916 solver.cpp:218] Iteration 22500 (16.8457 iter/s, 5.93624s/100 iters), loss = 0.20304
I1001 09:37:28.631945  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20304 (* 1 = 0.20304 loss)
I1001 09:37:28.631952  4916 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1001 09:37:33.444571  4916 solver.cpp:218] Iteration 22600 (20.7788 iter/s, 4.8126s/100 iters), loss = 0.202493
I1001 09:37:33.444600  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202493 (* 1 = 0.202493 loss)
I1001 09:37:33.444607  4916 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1001 09:37:38.266973  4916 solver.cpp:218] Iteration 22700 (20.7368 iter/s, 4.82235s/100 iters), loss = 0.306283
I1001 09:37:38.267007  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306283 (* 1 = 0.306283 loss)
I1001 09:37:38.267015  4916 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1001 09:37:43.077608  4916 solver.cpp:218] Iteration 22800 (20.7875 iter/s, 4.81058s/100 iters), loss = 0.363547
I1001 09:37:43.077649  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363547 (* 1 = 0.363547 loss)
I1001 09:37:43.077656  4916 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1001 09:37:47.896772  4916 solver.cpp:218] Iteration 22900 (20.7508 iter/s, 4.8191s/100 iters), loss = 0.29282
I1001 09:37:47.896896  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29282 (* 1 = 0.29282 loss)
I1001 09:37:47.896903  4916 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1001 09:37:52.472621  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:37:52.665719  4916 solver.cpp:330] Iteration 23000, Testing net (#0)
I1001 09:37:53.747725  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:37:53.792688  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7881
I1001 09:37:53.792724  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691138 (* 1 = 0.691138 loss)
I1001 09:37:53.841218  4916 solver.cpp:218] Iteration 23000 (16.8228 iter/s, 5.9443s/100 iters), loss = 0.233297
I1001 09:37:53.841250  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233297 (* 1 = 0.233297 loss)
I1001 09:37:53.841258  4916 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1001 09:37:58.652216  4916 solver.cpp:218] Iteration 23100 (20.7859 iter/s, 4.81094s/100 iters), loss = 0.23638
I1001 09:37:58.652256  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23638 (* 1 = 0.23638 loss)
I1001 09:37:58.652262  4916 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1001 09:38:03.465674  4916 solver.cpp:218] Iteration 23200 (20.7754 iter/s, 4.8134s/100 iters), loss = 0.181014
I1001 09:38:03.465714  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181014 (* 1 = 0.181014 loss)
I1001 09:38:03.465720  4916 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1001 09:38:08.276739  4916 solver.cpp:218] Iteration 23300 (20.7857 iter/s, 4.811s/100 iters), loss = 0.297346
I1001 09:38:08.276785  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297346 (* 1 = 0.297346 loss)
I1001 09:38:08.276793  4916 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1001 09:38:13.085836  4916 solver.cpp:218] Iteration 23400 (20.7944 iter/s, 4.80899s/100 iters), loss = 0.314711
I1001 09:38:13.085877  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314711 (* 1 = 0.314711 loss)
I1001 09:38:13.085883  4916 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1001 09:38:17.660818  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:38:17.853111  4916 solver.cpp:330] Iteration 23500, Testing net (#0)
I1001 09:38:18.928130  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:38:18.973570  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7245
I1001 09:38:18.973597  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.896656 (* 1 = 0.896656 loss)
I1001 09:38:19.022485  4916 solver.cpp:218] Iteration 23500 (16.8447 iter/s, 5.93659s/100 iters), loss = 0.313976
I1001 09:38:19.022509  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313976 (* 1 = 0.313976 loss)
I1001 09:38:19.022516  4916 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1001 09:38:23.842377  4916 solver.cpp:218] Iteration 23600 (20.7476 iter/s, 4.81984s/100 iters), loss = 0.236126
I1001 09:38:23.842418  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236126 (* 1 = 0.236126 loss)
I1001 09:38:23.842424  4916 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1001 09:38:28.651914  4916 solver.cpp:218] Iteration 23700 (20.7923 iter/s, 4.80947s/100 iters), loss = 0.191491
I1001 09:38:28.651945  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191491 (* 1 = 0.191491 loss)
I1001 09:38:28.651962  4916 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1001 09:38:33.478484  4916 solver.cpp:218] Iteration 23800 (20.7189 iter/s, 4.82652s/100 iters), loss = 0.343057
I1001 09:38:33.478528  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343057 (* 1 = 0.343057 loss)
I1001 09:38:33.478534  4916 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1001 09:38:38.301278  4916 solver.cpp:218] Iteration 23900 (20.7352 iter/s, 4.82273s/100 iters), loss = 0.228589
I1001 09:38:38.301313  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228589 (* 1 = 0.228589 loss)
I1001 09:38:38.301321  4916 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1001 09:38:42.878497  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:38:43.071069  4916 solver.cpp:330] Iteration 24000, Testing net (#0)
I1001 09:38:44.151165  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:38:44.197567  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7041
I1001 09:38:44.197604  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06091 (* 1 = 1.06091 loss)
I1001 09:38:44.247733  4916 solver.cpp:218] Iteration 24000 (16.8169 iter/s, 5.94639s/100 iters), loss = 0.234402
I1001 09:38:44.247779  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234402 (* 1 = 0.234402 loss)
I1001 09:38:44.247788  4916 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1001 09:38:49.056744  4916 solver.cpp:218] Iteration 24100 (20.7946 iter/s, 4.80894s/100 iters), loss = 0.235082
I1001 09:38:49.056876  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235082 (* 1 = 0.235082 loss)
I1001 09:38:49.056884  4916 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1001 09:38:53.873371  4916 solver.cpp:218] Iteration 24200 (20.762 iter/s, 4.81648s/100 iters), loss = 0.271996
I1001 09:38:53.873400  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271996 (* 1 = 0.271996 loss)
I1001 09:38:53.873406  4916 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1001 09:38:58.683549  4916 solver.cpp:218] Iteration 24300 (20.7895 iter/s, 4.81012s/100 iters), loss = 0.218359
I1001 09:38:58.683589  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218359 (* 1 = 0.218359 loss)
I1001 09:38:58.683595  4916 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1001 09:39:03.499930  4916 solver.cpp:218] Iteration 24400 (20.7628 iter/s, 4.81632s/100 iters), loss = 0.38303
I1001 09:39:03.499970  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38303 (* 1 = 0.38303 loss)
I1001 09:39:03.499976  4916 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1001 09:39:08.073117  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:39:08.270417  4916 solver.cpp:330] Iteration 24500, Testing net (#0)
I1001 09:39:09.344683  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:39:09.390215  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7588
I1001 09:39:09.390251  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.700604 (* 1 = 0.700604 loss)
I1001 09:39:09.438943  4916 solver.cpp:218] Iteration 24500 (16.838 iter/s, 5.93895s/100 iters), loss = 0.268051
I1001 09:39:09.438967  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268051 (* 1 = 0.268051 loss)
I1001 09:39:09.438974  4916 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1001 09:39:14.261639  4916 solver.cpp:218] Iteration 24600 (20.7355 iter/s, 4.82265s/100 iters), loss = 0.296679
I1001 09:39:14.261672  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296679 (* 1 = 0.296679 loss)
I1001 09:39:14.261680  4916 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1001 09:39:19.072475  4916 solver.cpp:218] Iteration 24700 (20.7866 iter/s, 4.81078s/100 iters), loss = 0.287322
I1001 09:39:19.072655  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287322 (* 1 = 0.287322 loss)
I1001 09:39:19.072664  4916 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1001 09:39:23.892392  4916 solver.cpp:218] Iteration 24800 (20.7481 iter/s, 4.81973s/100 iters), loss = 0.37029
I1001 09:39:23.892424  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37029 (* 1 = 0.37029 loss)
I1001 09:39:23.892431  4916 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1001 09:39:28.704340  4916 solver.cpp:218] Iteration 24900 (20.7818 iter/s, 4.8119s/100 iters), loss = 0.242241
I1001 09:39:28.704380  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242241 (* 1 = 0.242241 loss)
I1001 09:39:28.704386  4916 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1001 09:39:33.290693  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:39:33.483016  4916 solver.cpp:330] Iteration 25000, Testing net (#0)
I1001 09:39:34.555171  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:39:34.600301  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8319
I1001 09:39:34.600335  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.502423 (* 1 = 0.502423 loss)
I1001 09:39:34.649171  4916 solver.cpp:218] Iteration 25000 (16.8215 iter/s, 5.94477s/100 iters), loss = 0.246997
I1001 09:39:34.649194  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246997 (* 1 = 0.246997 loss)
I1001 09:39:34.649201  4916 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1001 09:39:39.464821  4916 solver.cpp:218] Iteration 25100 (20.7658 iter/s, 4.8156s/100 iters), loss = 0.281928
I1001 09:39:39.464862  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281928 (* 1 = 0.281928 loss)
I1001 09:39:39.464869  4916 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1001 09:39:44.277894  4916 solver.cpp:218] Iteration 25200 (20.777 iter/s, 4.81301s/100 iters), loss = 0.310993
I1001 09:39:44.277930  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310993 (* 1 = 0.310993 loss)
I1001 09:39:44.277937  4916 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1001 09:39:49.086380  4916 solver.cpp:218] Iteration 25300 (20.7968 iter/s, 4.80843s/100 iters), loss = 0.261372
I1001 09:39:49.086475  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261372 (* 1 = 0.261372 loss)
I1001 09:39:49.086485  4916 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1001 09:39:53.903192  4916 solver.cpp:218] Iteration 25400 (20.7611 iter/s, 4.8167s/100 iters), loss = 0.160268
I1001 09:39:53.903221  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160268 (* 1 = 0.160268 loss)
I1001 09:39:53.903239  4916 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1001 09:39:58.477440  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:39:58.670815  4916 solver.cpp:330] Iteration 25500, Testing net (#0)
I1001 09:39:59.755149  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:39:59.800267  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7889
I1001 09:39:59.800293  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648384 (* 1 = 0.648384 loss)
I1001 09:39:59.849161  4916 solver.cpp:218] Iteration 25500 (16.8183 iter/s, 5.94592s/100 iters), loss = 0.259449
I1001 09:39:59.849186  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259449 (* 1 = 0.259449 loss)
I1001 09:39:59.849194  4916 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1001 09:40:04.658409  4916 solver.cpp:218] Iteration 25600 (20.7935 iter/s, 4.8092s/100 iters), loss = 0.245351
I1001 09:40:04.658449  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245351 (* 1 = 0.245351 loss)
I1001 09:40:04.658455  4916 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1001 09:40:09.475831  4916 solver.cpp:218] Iteration 25700 (20.7583 iter/s, 4.81735s/100 iters), loss = 0.255733
I1001 09:40:09.475863  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255733 (* 1 = 0.255733 loss)
I1001 09:40:09.475872  4916 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1001 09:40:14.291733  4916 solver.cpp:218] Iteration 25800 (20.7648 iter/s, 4.81584s/100 iters), loss = 0.336195
I1001 09:40:14.291767  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336195 (* 1 = 0.336195 loss)
I1001 09:40:14.291776  4916 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1001 09:40:19.108912  4916 solver.cpp:218] Iteration 25900 (20.7593 iter/s, 4.81712s/100 iters), loss = 0.188696
I1001 09:40:19.109051  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188695 (* 1 = 0.188695 loss)
I1001 09:40:19.109063  4916 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1001 09:40:23.693672  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:40:23.886915  4916 solver.cpp:330] Iteration 26000, Testing net (#0)
I1001 09:40:24.961947  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:40:25.008106  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8137
I1001 09:40:25.008142  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.557507 (* 1 = 0.557507 loss)
I1001 09:40:25.057241  4916 solver.cpp:218] Iteration 26000 (16.8119 iter/s, 5.94817s/100 iters), loss = 0.247064
I1001 09:40:25.057266  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247064 (* 1 = 0.247064 loss)
I1001 09:40:25.057273  4916 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1001 09:40:29.870499  4916 solver.cpp:218] Iteration 26100 (20.7762 iter/s, 4.81321s/100 iters), loss = 0.314537
I1001 09:40:29.870530  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314537 (* 1 = 0.314537 loss)
I1001 09:40:29.870537  4916 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1001 09:40:34.672790  4916 solver.cpp:218] Iteration 26200 (20.8236 iter/s, 4.80224s/100 iters), loss = 0.320646
I1001 09:40:34.672829  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320646 (* 1 = 0.320646 loss)
I1001 09:40:34.672835  4916 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1001 09:40:39.487915  4916 solver.cpp:218] Iteration 26300 (20.7682 iter/s, 4.81506s/100 iters), loss = 0.350183
I1001 09:40:39.487956  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350182 (* 1 = 0.350182 loss)
I1001 09:40:39.487962  4916 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1001 09:40:44.301479  4916 solver.cpp:218] Iteration 26400 (20.7749 iter/s, 4.8135s/100 iters), loss = 0.17306
I1001 09:40:44.301527  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17306 (* 1 = 0.17306 loss)
I1001 09:40:44.301535  4916 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1001 09:40:48.875458  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:40:49.067857  4916 solver.cpp:330] Iteration 26500, Testing net (#0)
I1001 09:40:50.146266  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:40:50.193229  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7835
I1001 09:40:50.193254  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.621343 (* 1 = 0.621343 loss)
I1001 09:40:50.242499  4916 solver.cpp:218] Iteration 26500 (16.8324 iter/s, 5.94092s/100 iters), loss = 0.198824
I1001 09:40:50.242557  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198824 (* 1 = 0.198824 loss)
I1001 09:40:50.242575  4916 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1001 09:40:55.046385  4916 solver.cpp:218] Iteration 26600 (20.817 iter/s, 4.80377s/100 iters), loss = 0.172411
I1001 09:40:55.046414  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172411 (* 1 = 0.172411 loss)
I1001 09:40:55.046420  4916 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1001 09:40:59.865216  4916 solver.cpp:218] Iteration 26700 (20.7522 iter/s, 4.81878s/100 iters), loss = 0.302192
I1001 09:40:59.865257  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302192 (* 1 = 0.302192 loss)
I1001 09:40:59.865263  4916 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1001 09:41:04.676311  4916 solver.cpp:218] Iteration 26800 (20.7856 iter/s, 4.81103s/100 iters), loss = 0.27892
I1001 09:41:04.676352  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27892 (* 1 = 0.27892 loss)
I1001 09:41:04.676357  4916 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1001 09:41:09.498791  4916 solver.cpp:218] Iteration 26900 (20.7365 iter/s, 4.82241s/100 iters), loss = 0.174719
I1001 09:41:09.498832  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174718 (* 1 = 0.174718 loss)
I1001 09:41:09.498838  4916 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1001 09:41:14.070719  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:41:14.267846  4916 solver.cpp:330] Iteration 27000, Testing net (#0)
I1001 09:41:15.343134  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:41:15.388713  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7509
I1001 09:41:15.388738  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.784055 (* 1 = 0.784055 loss)
I1001 09:41:15.437386  4916 solver.cpp:218] Iteration 27000 (16.8392 iter/s, 5.93853s/100 iters), loss = 0.235345
I1001 09:41:15.437412  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235345 (* 1 = 0.235345 loss)
I1001 09:41:15.437418  4916 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1001 09:41:20.252277  4916 solver.cpp:218] Iteration 27100 (20.7691 iter/s, 4.81484s/100 iters), loss = 0.169519
I1001 09:41:20.252408  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169519 (* 1 = 0.169519 loss)
I1001 09:41:20.252418  4916 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1001 09:41:25.064476  4916 solver.cpp:218] Iteration 27200 (20.7813 iter/s, 4.81203s/100 iters), loss = 0.322611
I1001 09:41:25.064517  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322611 (* 1 = 0.322611 loss)
I1001 09:41:25.064522  4916 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1001 09:41:29.879323  4916 solver.cpp:218] Iteration 27300 (20.7694 iter/s, 4.81478s/100 iters), loss = 0.270458
I1001 09:41:29.879362  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270458 (* 1 = 0.270458 loss)
I1001 09:41:29.879369  4916 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1001 09:41:34.690608  4916 solver.cpp:218] Iteration 27400 (20.7847 iter/s, 4.81122s/100 iters), loss = 0.269859
I1001 09:41:34.690649  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269859 (* 1 = 0.269859 loss)
I1001 09:41:34.690654  4916 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1001 09:41:39.273092  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:41:39.464417  4916 solver.cpp:330] Iteration 27500, Testing net (#0)
I1001 09:41:40.538583  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:41:40.584010  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8062
I1001 09:41:40.584046  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.599562 (* 1 = 0.599562 loss)
I1001 09:41:40.632906  4916 solver.cpp:218] Iteration 27500 (16.8287 iter/s, 5.94224s/100 iters), loss = 0.214944
I1001 09:41:40.632930  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214944 (* 1 = 0.214944 loss)
I1001 09:41:40.632936  4916 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1001 09:41:45.450175  4916 solver.cpp:218] Iteration 27600 (20.7589 iter/s, 4.81722s/100 iters), loss = 0.16187
I1001 09:41:45.450217  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16187 (* 1 = 0.16187 loss)
I1001 09:41:45.450222  4916 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1001 09:41:50.271044  4916 solver.cpp:218] Iteration 27700 (20.7435 iter/s, 4.82079s/100 iters), loss = 0.248264
I1001 09:41:50.271198  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248264 (* 1 = 0.248264 loss)
I1001 09:41:50.271209  4916 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1001 09:41:55.083004  4916 solver.cpp:218] Iteration 27800 (20.7823 iter/s, 4.81179s/100 iters), loss = 0.258311
I1001 09:41:55.083045  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258311 (* 1 = 0.258311 loss)
I1001 09:41:55.083050  4916 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1001 09:41:59.907327  4916 solver.cpp:218] Iteration 27900 (20.7286 iter/s, 4.82426s/100 iters), loss = 0.167314
I1001 09:41:59.907367  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167314 (* 1 = 0.167314 loss)
I1001 09:41:59.907373  4916 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1001 09:42:04.481446  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:42:04.674001  4916 solver.cpp:330] Iteration 28000, Testing net (#0)
I1001 09:42:05.755750  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:42:05.800513  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7379
I1001 09:42:05.800547  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.806658 (* 1 = 0.806658 loss)
I1001 09:42:05.849261  4916 solver.cpp:218] Iteration 28000 (16.8297 iter/s, 5.94187s/100 iters), loss = 0.24725
I1001 09:42:05.849292  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24725 (* 1 = 0.24725 loss)
I1001 09:42:05.849299  4916 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1001 09:42:10.657094  4916 solver.cpp:218] Iteration 28100 (20.7996 iter/s, 4.80778s/100 iters), loss = 0.200865
I1001 09:42:10.657135  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200864 (* 1 = 0.200864 loss)
I1001 09:42:10.657141  4916 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1001 09:42:15.474697  4916 solver.cpp:218] Iteration 28200 (20.7575 iter/s, 4.81754s/100 iters), loss = 0.254575
I1001 09:42:15.474738  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254575 (* 1 = 0.254575 loss)
I1001 09:42:15.474745  4916 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1001 09:42:20.295742  4916 solver.cpp:218] Iteration 28300 (20.7427 iter/s, 4.82098s/100 iters), loss = 0.268324
I1001 09:42:20.295886  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268323 (* 1 = 0.268323 loss)
I1001 09:42:20.295912  4916 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1001 09:42:25.101063  4916 solver.cpp:218] Iteration 28400 (20.8109 iter/s, 4.80517s/100 iters), loss = 0.193999
I1001 09:42:25.101104  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193999 (* 1 = 0.193999 loss)
I1001 09:42:25.101109  4916 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1001 09:42:29.685654  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:42:29.879214  4916 solver.cpp:330] Iteration 28500, Testing net (#0)
I1001 09:42:30.954246  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:42:30.999599  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6844
I1001 09:42:30.999634  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0059 (* 1 = 1.0059 loss)
I1001 09:42:31.048039  4916 solver.cpp:218] Iteration 28500 (16.8154 iter/s, 5.94692s/100 iters), loss = 0.215026
I1001 09:42:31.048063  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215025 (* 1 = 0.215025 loss)
I1001 09:42:31.048069  4916 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1001 09:42:35.869300  4916 solver.cpp:218] Iteration 28600 (20.7417 iter/s, 4.82122s/100 iters), loss = 0.298705
I1001 09:42:35.869339  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298705 (* 1 = 0.298705 loss)
I1001 09:42:35.869345  4916 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1001 09:42:40.682708  4916 solver.cpp:218] Iteration 28700 (20.7756 iter/s, 4.81334s/100 iters), loss = 0.281456
I1001 09:42:40.682747  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281455 (* 1 = 0.281455 loss)
I1001 09:42:40.682754  4916 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1001 09:42:45.507988  4916 solver.cpp:218] Iteration 28800 (20.7244 iter/s, 4.82522s/100 iters), loss = 0.211673
I1001 09:42:45.508018  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211673 (* 1 = 0.211673 loss)
I1001 09:42:45.508024  4916 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1001 09:42:50.325397  4916 solver.cpp:218] Iteration 28900 (20.7583 iter/s, 4.81735s/100 iters), loss = 0.17344
I1001 09:42:50.325517  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173439 (* 1 = 0.173439 loss)
I1001 09:42:50.325536  4916 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1001 09:42:54.899668  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:42:55.092010  4916 solver.cpp:330] Iteration 29000, Testing net (#0)
I1001 09:42:56.171028  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:42:56.217309  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7947
I1001 09:42:56.217346  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.613577 (* 1 = 0.613577 loss)
I1001 09:42:56.267218  4916 solver.cpp:218] Iteration 29000 (16.8304 iter/s, 5.94164s/100 iters), loss = 0.206363
I1001 09:42:56.267253  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206363 (* 1 = 0.206363 loss)
I1001 09:42:56.267261  4916 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1001 09:43:01.075989  4916 solver.cpp:218] Iteration 29100 (20.7956 iter/s, 4.80871s/100 iters), loss = 0.263781
I1001 09:43:01.076030  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263781 (* 1 = 0.263781 loss)
I1001 09:43:01.076035  4916 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1001 09:43:05.880470  4916 solver.cpp:218] Iteration 29200 (20.8142 iter/s, 4.80442s/100 iters), loss = 0.323552
I1001 09:43:05.880511  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323552 (* 1 = 0.323552 loss)
I1001 09:43:05.880517  4916 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1001 09:43:10.691929  4916 solver.cpp:218] Iteration 29300 (20.784 iter/s, 4.8114s/100 iters), loss = 0.260163
I1001 09:43:10.691969  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260163 (* 1 = 0.260163 loss)
I1001 09:43:10.691975  4916 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1001 09:43:15.509565  4916 solver.cpp:218] Iteration 29400 (20.7573 iter/s, 4.81757s/100 iters), loss = 0.182404
I1001 09:43:15.509595  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182404 (* 1 = 0.182404 loss)
I1001 09:43:15.509601  4916 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1001 09:43:20.080447  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:43:20.279803  4916 solver.cpp:330] Iteration 29500, Testing net (#0)
I1001 09:43:21.355171  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:43:21.400213  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8289
I1001 09:43:21.400246  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.503208 (* 1 = 0.503208 loss)
I1001 09:43:21.449148  4916 solver.cpp:218] Iteration 29500 (16.8363 iter/s, 5.93953s/100 iters), loss = 0.21037
I1001 09:43:21.449183  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21037 (* 1 = 0.21037 loss)
I1001 09:43:21.449192  4916 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1001 09:43:26.272187  4916 solver.cpp:218] Iteration 29600 (20.7341 iter/s, 4.82298s/100 iters), loss = 0.204156
I1001 09:43:26.272222  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204156 (* 1 = 0.204156 loss)
I1001 09:43:26.272228  4916 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1001 09:43:31.082726  4916 solver.cpp:218] Iteration 29700 (20.788 iter/s, 4.81048s/100 iters), loss = 0.254317
I1001 09:43:31.082756  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254316 (* 1 = 0.254316 loss)
I1001 09:43:31.082762  4916 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1001 09:43:35.899343  4916 solver.cpp:218] Iteration 29800 (20.7617 iter/s, 4.81656s/100 iters), loss = 0.221354
I1001 09:43:35.899384  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221354 (* 1 = 0.221354 loss)
I1001 09:43:35.899389  4916 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1001 09:43:40.708284  4916 solver.cpp:218] Iteration 29900 (20.7949 iter/s, 4.80888s/100 iters), loss = 0.162448
I1001 09:43:40.708314  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162448 (* 1 = 0.162448 loss)
I1001 09:43:40.708330  4916 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1001 09:43:45.281834  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:43:45.473978  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_30000.caffemodel
I1001 09:43:45.478267  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_30000.solverstate
I1001 09:43:45.479501  4916 solver.cpp:330] Iteration 30000, Testing net (#0)
I1001 09:43:46.552157  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:43:46.597777  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6888
I1001 09:43:46.597813  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02432 (* 1 = 1.02432 loss)
I1001 09:43:46.646451  4916 solver.cpp:218] Iteration 30000 (16.8404 iter/s, 5.93812s/100 iters), loss = 0.248031
I1001 09:43:46.646478  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248031 (* 1 = 0.248031 loss)
I1001 09:43:46.646486  4916 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1001 09:43:51.464563  4916 solver.cpp:218] Iteration 30100 (20.7552 iter/s, 4.81806s/100 iters), loss = 0.244976
I1001 09:43:51.464705  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244976 (* 1 = 0.244976 loss)
I1001 09:43:51.464725  4916 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1001 09:43:56.282632  4916 solver.cpp:218] Iteration 30200 (20.7559 iter/s, 4.81791s/100 iters), loss = 0.307418
I1001 09:43:56.282675  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307418 (* 1 = 0.307418 loss)
I1001 09:43:56.282682  4916 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1001 09:44:01.098896  4916 solver.cpp:218] Iteration 30300 (20.7634 iter/s, 4.81617s/100 iters), loss = 0.280794
I1001 09:44:01.098937  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280794 (* 1 = 0.280794 loss)
I1001 09:44:01.098943  4916 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1001 09:44:05.917250  4916 solver.cpp:218] Iteration 30400 (20.7542 iter/s, 4.81829s/100 iters), loss = 0.122782
I1001 09:44:05.917290  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122782 (* 1 = 0.122782 loss)
I1001 09:44:05.917296  4916 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1001 09:44:10.491567  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:44:10.685006  4916 solver.cpp:330] Iteration 30500, Testing net (#0)
I1001 09:44:11.769582  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:44:11.814982  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8256
I1001 09:44:11.815018  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.527121 (* 1 = 0.527121 loss)
I1001 09:44:11.863426  4916 solver.cpp:218] Iteration 30500 (16.8177 iter/s, 5.94612s/100 iters), loss = 0.187396
I1001 09:44:11.863461  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187396 (* 1 = 0.187396 loss)
I1001 09:44:11.863467  4916 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1001 09:44:16.672974  4916 solver.cpp:218] Iteration 30600 (20.7922 iter/s, 4.80949s/100 iters), loss = 0.228963
I1001 09:44:16.673014  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228963 (* 1 = 0.228963 loss)
I1001 09:44:16.673020  4916 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1001 09:44:21.492691  4916 solver.cpp:218] Iteration 30700 (20.7484 iter/s, 4.81966s/100 iters), loss = 0.250619
I1001 09:44:21.492820  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250619 (* 1 = 0.250619 loss)
I1001 09:44:21.492837  4916 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1001 09:44:26.310206  4916 solver.cpp:218] Iteration 30800 (20.7582 iter/s, 4.81737s/100 iters), loss = 0.241922
I1001 09:44:26.310247  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241922 (* 1 = 0.241922 loss)
I1001 09:44:26.310256  4916 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1001 09:44:31.121814  4916 solver.cpp:218] Iteration 30900 (20.7833 iter/s, 4.81155s/100 iters), loss = 0.208046
I1001 09:44:31.121855  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208046 (* 1 = 0.208046 loss)
I1001 09:44:31.121860  4916 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1001 09:44:35.699498  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:44:35.892639  4916 solver.cpp:330] Iteration 31000, Testing net (#0)
I1001 09:44:36.966691  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:44:37.011637  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8152
I1001 09:44:37.011673  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.544152 (* 1 = 0.544152 loss)
I1001 09:44:37.059797  4916 solver.cpp:218] Iteration 31000 (16.8409 iter/s, 5.93792s/100 iters), loss = 0.229407
I1001 09:44:37.059823  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229407 (* 1 = 0.229407 loss)
I1001 09:44:37.059829  4916 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1001 09:44:41.877264  4916 solver.cpp:218] Iteration 31100 (20.758 iter/s, 4.81742s/100 iters), loss = 0.252868
I1001 09:44:41.877305  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252867 (* 1 = 0.252867 loss)
I1001 09:44:41.877311  4916 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1001 09:44:46.689703  4916 solver.cpp:218] Iteration 31200 (20.7797 iter/s, 4.81238s/100 iters), loss = 0.30924
I1001 09:44:46.689743  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30924 (* 1 = 0.30924 loss)
I1001 09:44:46.689749  4916 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1001 09:44:51.514499  4916 solver.cpp:218] Iteration 31300 (20.7265 iter/s, 4.82474s/100 iters), loss = 0.279739
I1001 09:44:51.514627  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279739 (* 1 = 0.279739 loss)
I1001 09:44:51.514636  4916 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1001 09:44:56.340855  4916 solver.cpp:218] Iteration 31400 (20.7202 iter/s, 4.82622s/100 iters), loss = 0.206778
I1001 09:44:56.340903  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206777 (* 1 = 0.206777 loss)
I1001 09:44:56.340910  4916 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1001 09:45:00.916791  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:45:01.109200  4916 solver.cpp:330] Iteration 31500, Testing net (#0)
I1001 09:45:02.188053  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:45:02.234907  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7614
I1001 09:45:02.234961  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.810224 (* 1 = 0.810224 loss)
I1001 09:45:02.284199  4916 solver.cpp:218] Iteration 31500 (16.8258 iter/s, 5.94324s/100 iters), loss = 0.238048
I1001 09:45:02.284245  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238048 (* 1 = 0.238048 loss)
I1001 09:45:02.284252  4916 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1001 09:45:07.102263  4916 solver.cpp:218] Iteration 31600 (20.7556 iter/s, 4.81797s/100 iters), loss = 0.288174
I1001 09:45:07.102303  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288174 (* 1 = 0.288174 loss)
I1001 09:45:07.102309  4916 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1001 09:45:11.924690  4916 solver.cpp:218] Iteration 31700 (20.7367 iter/s, 4.82236s/100 iters), loss = 0.286022
I1001 09:45:11.924731  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286022 (* 1 = 0.286022 loss)
I1001 09:45:11.924736  4916 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1001 09:45:16.732924  4916 solver.cpp:218] Iteration 31800 (20.7979 iter/s, 4.80817s/100 iters), loss = 0.306122
I1001 09:45:16.732965  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306121 (* 1 = 0.306121 loss)
I1001 09:45:16.732971  4916 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1001 09:45:21.548686  4916 solver.cpp:218] Iteration 31900 (20.7654 iter/s, 4.8157s/100 iters), loss = 0.194142
I1001 09:45:21.548825  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194142 (* 1 = 0.194142 loss)
I1001 09:45:21.548833  4916 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1001 09:45:26.119290  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:45:26.317088  4916 solver.cpp:330] Iteration 32000, Testing net (#0)
I1001 09:45:27.392370  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:45:27.437901  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8098
I1001 09:45:27.437935  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.582755 (* 1 = 0.582755 loss)
I1001 09:45:27.486829  4916 solver.cpp:218] Iteration 32000 (16.8407 iter/s, 5.93798s/100 iters), loss = 0.182406
I1001 09:45:27.486865  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182405 (* 1 = 0.182405 loss)
I1001 09:45:27.486871  4916 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1001 09:45:32.302561  4916 solver.cpp:218] Iteration 32100 (20.7655 iter/s, 4.81567s/100 iters), loss = 0.258122
I1001 09:45:32.302606  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258122 (* 1 = 0.258122 loss)
I1001 09:45:32.302613  4916 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1001 09:45:37.116982  4916 solver.cpp:218] Iteration 32200 (20.7712 iter/s, 4.81435s/100 iters), loss = 0.214831
I1001 09:45:37.117013  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214831 (* 1 = 0.214831 loss)
I1001 09:45:37.117030  4916 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1001 09:45:41.940748  4916 solver.cpp:218] Iteration 32300 (20.7309 iter/s, 4.82371s/100 iters), loss = 0.421011
I1001 09:45:41.940788  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42101 (* 1 = 0.42101 loss)
I1001 09:45:41.940794  4916 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1001 09:45:46.748725  4916 solver.cpp:218] Iteration 32400 (20.799 iter/s, 4.80791s/100 iters), loss = 0.127291
I1001 09:45:46.748755  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127291 (* 1 = 0.127291 loss)
I1001 09:45:46.748771  4916 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1001 09:45:51.331245  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:45:51.523610  4916 solver.cpp:330] Iteration 32500, Testing net (#0)
I1001 09:45:52.597612  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:45:52.643133  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8183
I1001 09:45:52.643159  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.561172 (* 1 = 0.561172 loss)
I1001 09:45:52.691721  4916 solver.cpp:218] Iteration 32500 (16.8267 iter/s, 5.94295s/100 iters), loss = 0.164525
I1001 09:45:52.691745  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164525 (* 1 = 0.164525 loss)
I1001 09:45:52.691751  4916 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1001 09:45:57.510818  4916 solver.cpp:218] Iteration 32600 (20.751 iter/s, 4.81905s/100 iters), loss = 0.373435
I1001 09:45:57.510848  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373435 (* 1 = 0.373435 loss)
I1001 09:45:57.510854  4916 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1001 09:46:02.323679  4916 solver.cpp:218] Iteration 32700 (20.7779 iter/s, 4.81281s/100 iters), loss = 0.299626
I1001 09:46:02.323714  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299626 (* 1 = 0.299626 loss)
I1001 09:46:02.323720  4916 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1001 09:46:07.131619  4916 solver.cpp:218] Iteration 32800 (20.7992 iter/s, 4.80788s/100 iters), loss = 0.225903
I1001 09:46:07.131659  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225903 (* 1 = 0.225903 loss)
I1001 09:46:07.131665  4916 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1001 09:46:11.942227  4916 solver.cpp:218] Iteration 32900 (20.7877 iter/s, 4.81054s/100 iters), loss = 0.193067
I1001 09:46:11.942257  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193067 (* 1 = 0.193067 loss)
I1001 09:46:11.942263  4916 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1001 09:46:16.503581  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:46:16.696019  4916 solver.cpp:330] Iteration 33000, Testing net (#0)
I1001 09:46:17.778384  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:46:17.823945  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8173
I1001 09:46:17.823979  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.538573 (* 1 = 0.538573 loss)
I1001 09:46:17.872747  4916 solver.cpp:218] Iteration 33000 (16.8621 iter/s, 5.93047s/100 iters), loss = 0.227277
I1001 09:46:17.872777  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227277 (* 1 = 0.227277 loss)
I1001 09:46:17.872784  4916 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1001 09:46:22.683637  4916 solver.cpp:218] Iteration 33100 (20.7864 iter/s, 4.81084s/100 iters), loss = 0.215367
I1001 09:46:22.683760  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215367 (* 1 = 0.215367 loss)
I1001 09:46:22.683779  4916 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1001 09:46:27.504045  4916 solver.cpp:218] Iteration 33200 (20.7457 iter/s, 4.82027s/100 iters), loss = 0.236883
I1001 09:46:27.504076  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236883 (* 1 = 0.236883 loss)
I1001 09:46:27.504082  4916 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1001 09:46:32.318164  4916 solver.cpp:218] Iteration 33300 (20.7725 iter/s, 4.81406s/100 iters), loss = 0.275791
I1001 09:46:32.318202  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275791 (* 1 = 0.275791 loss)
I1001 09:46:32.318210  4916 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1001 09:46:37.129763  4916 solver.cpp:218] Iteration 33400 (20.7834 iter/s, 4.81154s/100 iters), loss = 0.217321
I1001 09:46:37.129803  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217321 (* 1 = 0.217321 loss)
I1001 09:46:37.129809  4916 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1001 09:46:41.708894  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:46:41.899169  4916 solver.cpp:330] Iteration 33500, Testing net (#0)
I1001 09:46:42.972654  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:46:43.017913  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8149
I1001 09:46:43.017949  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.546785 (* 1 = 0.546785 loss)
I1001 09:46:43.066577  4916 solver.cpp:218] Iteration 33500 (16.8442 iter/s, 5.93675s/100 iters), loss = 0.171658
I1001 09:46:43.066599  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171658 (* 1 = 0.171658 loss)
I1001 09:46:43.066606  4916 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1001 09:46:47.884528  4916 solver.cpp:218] Iteration 33600 (20.7559 iter/s, 4.81791s/100 iters), loss = 0.206914
I1001 09:46:47.884568  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206914 (* 1 = 0.206914 loss)
I1001 09:46:47.884575  4916 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1001 09:46:52.693708  4916 solver.cpp:218] Iteration 33700 (20.7939 iter/s, 4.80911s/100 iters), loss = 0.24295
I1001 09:46:52.693819  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24295 (* 1 = 0.24295 loss)
I1001 09:46:52.693827  4916 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1001 09:46:57.512087  4916 solver.cpp:218] Iteration 33800 (20.7544 iter/s, 4.81825s/100 iters), loss = 0.281776
I1001 09:46:57.512130  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281776 (* 1 = 0.281776 loss)
I1001 09:46:57.512136  4916 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1001 09:47:02.320955  4916 solver.cpp:218] Iteration 33900 (20.7952 iter/s, 4.8088s/100 iters), loss = 0.24523
I1001 09:47:02.320997  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24523 (* 1 = 0.24523 loss)
I1001 09:47:02.321004  4916 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1001 09:47:06.893015  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:47:07.085685  4916 solver.cpp:330] Iteration 34000, Testing net (#0)
I1001 09:47:08.164325  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:47:08.210005  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7862
I1001 09:47:08.210043  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.680253 (* 1 = 0.680253 loss)
I1001 09:47:08.260082  4916 solver.cpp:218] Iteration 34000 (16.8377 iter/s, 5.93905s/100 iters), loss = 0.225389
I1001 09:47:08.260120  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225388 (* 1 = 0.225388 loss)
I1001 09:47:08.260128  4916 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1001 09:47:13.073979  4916 solver.cpp:218] Iteration 34100 (20.7735 iter/s, 4.81383s/100 iters), loss = 0.292328
I1001 09:47:13.074009  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292328 (* 1 = 0.292328 loss)
I1001 09:47:13.074015  4916 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1001 09:47:17.891863  4916 solver.cpp:218] Iteration 34200 (20.7562 iter/s, 4.81783s/100 iters), loss = 0.263867
I1001 09:47:17.891904  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263867 (* 1 = 0.263867 loss)
I1001 09:47:17.891911  4916 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1001 09:47:22.704303  4916 solver.cpp:218] Iteration 34300 (20.7798 iter/s, 4.81238s/100 iters), loss = 0.220259
I1001 09:47:22.704444  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220259 (* 1 = 0.220259 loss)
I1001 09:47:22.704452  4916 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1001 09:47:27.527132  4916 solver.cpp:218] Iteration 34400 (20.7354 iter/s, 4.82267s/100 iters), loss = 0.204006
I1001 09:47:27.527161  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204006 (* 1 = 0.204006 loss)
I1001 09:47:27.527168  4916 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1001 09:47:32.102900  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:47:32.301404  4916 solver.cpp:330] Iteration 34500, Testing net (#0)
I1001 09:47:33.376456  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:47:33.421574  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8156
I1001 09:47:33.421609  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55437 (* 1 = 0.55437 loss)
I1001 09:47:33.470013  4916 solver.cpp:218] Iteration 34500 (16.827 iter/s, 5.94283s/100 iters), loss = 0.349941
I1001 09:47:33.470036  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349941 (* 1 = 0.349941 loss)
I1001 09:47:33.470043  4916 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1001 09:47:38.283052  4916 solver.cpp:218] Iteration 34600 (20.7771 iter/s, 4.81299s/100 iters), loss = 0.302851
I1001 09:47:38.283098  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302851 (* 1 = 0.302851 loss)
I1001 09:47:38.283107  4916 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1001 09:47:43.089639  4916 solver.cpp:218] Iteration 34700 (20.8052 iter/s, 4.80649s/100 iters), loss = 0.260531
I1001 09:47:43.089671  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260531 (* 1 = 0.260531 loss)
I1001 09:47:43.089687  4916 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1001 09:47:47.901942  4916 solver.cpp:218] Iteration 34800 (20.7803 iter/s, 4.81225s/100 iters), loss = 0.283399
I1001 09:47:47.901983  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283399 (* 1 = 0.283399 loss)
I1001 09:47:47.901988  4916 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1001 09:47:52.711074  4916 solver.cpp:218] Iteration 34900 (20.794 iter/s, 4.80907s/100 iters), loss = 0.145013
I1001 09:47:52.711189  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145013 (* 1 = 0.145013 loss)
I1001 09:47:52.711196  4916 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1001 09:47:57.289075  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:47:57.481515  4916 solver.cpp:330] Iteration 35000, Testing net (#0)
I1001 09:47:58.556517  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:47:58.601574  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7992
I1001 09:47:58.601600  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.60692 (* 1 = 0.60692 loss)
I1001 09:47:58.650034  4916 solver.cpp:218] Iteration 35000 (16.8383 iter/s, 5.93883s/100 iters), loss = 0.16111
I1001 09:47:58.650068  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16111 (* 1 = 0.16111 loss)
I1001 09:47:58.650074  4916 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1001 09:48:03.461180  4916 solver.cpp:218] Iteration 35100 (20.7853 iter/s, 4.81109s/100 iters), loss = 0.254784
I1001 09:48:03.461221  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254784 (* 1 = 0.254784 loss)
I1001 09:48:03.461227  4916 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1001 09:48:08.279803  4916 solver.cpp:218] Iteration 35200 (20.7531 iter/s, 4.81856s/100 iters), loss = 0.213393
I1001 09:48:08.279839  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213393 (* 1 = 0.213393 loss)
I1001 09:48:08.279846  4916 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1001 09:48:13.093020  4916 solver.cpp:218] Iteration 35300 (20.7764 iter/s, 4.81316s/100 iters), loss = 0.222632
I1001 09:48:13.093050  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222632 (* 1 = 0.222632 loss)
I1001 09:48:13.093056  4916 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1001 09:48:17.907938  4916 solver.cpp:218] Iteration 35400 (20.769 iter/s, 4.81486s/100 iters), loss = 0.279646
I1001 09:48:17.907984  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279646 (* 1 = 0.279646 loss)
I1001 09:48:17.907991  4916 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1001 09:48:22.479481  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:48:22.671870  4916 solver.cpp:330] Iteration 35500, Testing net (#0)
I1001 09:48:23.754114  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:48:23.799314  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7875
I1001 09:48:23.799350  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.681195 (* 1 = 0.681195 loss)
I1001 09:48:23.847584  4916 solver.cpp:218] Iteration 35500 (16.8362 iter/s, 5.93958s/100 iters), loss = 0.170721
I1001 09:48:23.847612  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170721 (* 1 = 0.170721 loss)
I1001 09:48:23.847620  4916 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1001 09:48:28.657755  4916 solver.cpp:218] Iteration 35600 (20.7895 iter/s, 4.81012s/100 iters), loss = 0.18855
I1001 09:48:28.657795  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18855 (* 1 = 0.18855 loss)
I1001 09:48:28.657801  4916 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1001 09:48:33.475687  4916 solver.cpp:218] Iteration 35700 (20.7561 iter/s, 4.81787s/100 iters), loss = 0.23202
I1001 09:48:33.475728  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23202 (* 1 = 0.23202 loss)
I1001 09:48:33.475734  4916 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1001 09:48:38.291164  4916 solver.cpp:218] Iteration 35800 (20.7667 iter/s, 4.81541s/100 iters), loss = 0.317591
I1001 09:48:38.291208  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317591 (* 1 = 0.317591 loss)
I1001 09:48:38.291215  4916 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1001 09:48:43.101500  4916 solver.cpp:218] Iteration 35900 (20.789 iter/s, 4.81024s/100 iters), loss = 0.208268
I1001 09:48:43.101541  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208268 (* 1 = 0.208268 loss)
I1001 09:48:43.101547  4916 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1001 09:48:47.678949  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:48:47.872014  4916 solver.cpp:330] Iteration 36000, Testing net (#0)
I1001 09:48:48.945969  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:48:48.991546  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8323
I1001 09:48:48.991581  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.510081 (* 1 = 0.510081 loss)
I1001 09:48:49.039969  4916 solver.cpp:218] Iteration 36000 (16.8395 iter/s, 5.93841s/100 iters), loss = 0.127633
I1001 09:48:49.039994  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127633 (* 1 = 0.127633 loss)
I1001 09:48:49.040000  4916 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1001 09:48:53.863485  4916 solver.cpp:218] Iteration 36100 (20.732 iter/s, 4.82346s/100 iters), loss = 0.201779
I1001 09:48:53.863627  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201779 (* 1 = 0.201779 loss)
I1001 09:48:53.863636  4916 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1001 09:48:58.674222  4916 solver.cpp:218] Iteration 36200 (20.7875 iter/s, 4.81059s/100 iters), loss = 0.283596
I1001 09:48:58.674263  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283596 (* 1 = 0.283596 loss)
I1001 09:48:58.674268  4916 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1001 09:49:03.495770  4916 solver.cpp:218] Iteration 36300 (20.7405 iter/s, 4.82149s/100 iters), loss = 0.31049
I1001 09:49:03.495812  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31049 (* 1 = 0.31049 loss)
I1001 09:49:03.495818  4916 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1001 09:49:08.313112  4916 solver.cpp:218] Iteration 36400 (20.7586 iter/s, 4.81728s/100 iters), loss = 0.192111
I1001 09:49:08.313158  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192111 (* 1 = 0.192111 loss)
I1001 09:49:08.313165  4916 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1001 09:49:12.886668  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:49:13.079481  4916 solver.cpp:330] Iteration 36500, Testing net (#0)
I1001 09:49:14.154503  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:49:14.200505  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8013
I1001 09:49:14.200541  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640909 (* 1 = 0.640909 loss)
I1001 09:49:14.250020  4916 solver.cpp:218] Iteration 36500 (16.8441 iter/s, 5.9368s/100 iters), loss = 0.209275
I1001 09:49:14.250056  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209275 (* 1 = 0.209275 loss)
I1001 09:49:14.250062  4916 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1001 09:49:19.063380  4916 solver.cpp:218] Iteration 36600 (20.7758 iter/s, 4.8133s/100 iters), loss = 0.236792
I1001 09:49:19.063408  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236792 (* 1 = 0.236792 loss)
I1001 09:49:19.063415  4916 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1001 09:49:23.877141  4916 solver.cpp:218] Iteration 36700 (20.774 iter/s, 4.81371s/100 iters), loss = 0.218678
I1001 09:49:23.877243  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218678 (* 1 = 0.218678 loss)
I1001 09:49:23.877260  4916 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1001 09:49:28.687228  4916 solver.cpp:218] Iteration 36800 (20.7902 iter/s, 4.80996s/100 iters), loss = 0.166549
I1001 09:49:28.687268  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166549 (* 1 = 0.166549 loss)
I1001 09:49:28.687275  4916 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1001 09:49:33.504760  4916 solver.cpp:218] Iteration 36900 (20.7578 iter/s, 4.81747s/100 iters), loss = 0.115108
I1001 09:49:33.504801  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115108 (* 1 = 0.115108 loss)
I1001 09:49:33.504807  4916 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1001 09:49:38.079448  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:49:38.278295  4916 solver.cpp:330] Iteration 37000, Testing net (#0)
I1001 09:49:39.354871  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:49:39.400199  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7959
I1001 09:49:39.400240  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.631097 (* 1 = 0.631097 loss)
I1001 09:49:39.448735  4916 solver.cpp:218] Iteration 37000 (16.8239 iter/s, 5.94391s/100 iters), loss = 0.183181
I1001 09:49:39.448760  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183181 (* 1 = 0.183181 loss)
I1001 09:49:39.448766  4916 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1001 09:49:44.260854  4916 solver.cpp:218] Iteration 37100 (20.7811 iter/s, 4.81206s/100 iters), loss = 0.309874
I1001 09:49:44.260906  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309874 (* 1 = 0.309874 loss)
I1001 09:49:44.260915  4916 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1001 09:49:49.076896  4916 solver.cpp:218] Iteration 37200 (20.7644 iter/s, 4.81594s/100 iters), loss = 0.155496
I1001 09:49:49.076926  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155496 (* 1 = 0.155496 loss)
I1001 09:49:49.076932  4916 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1001 09:49:53.897756  4916 solver.cpp:218] Iteration 37300 (20.7434 iter/s, 4.82081s/100 iters), loss = 0.199976
I1001 09:49:53.897900  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199976 (* 1 = 0.199976 loss)
I1001 09:49:53.897908  4916 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1001 09:49:58.707835  4916 solver.cpp:218] Iteration 37400 (20.7904 iter/s, 4.80992s/100 iters), loss = 0.225133
I1001 09:49:58.707865  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225134 (* 1 = 0.225134 loss)
I1001 09:49:58.707871  4916 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1001 09:50:03.289033  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:50:03.481361  4916 solver.cpp:330] Iteration 37500, Testing net (#0)
I1001 09:50:04.555315  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:50:04.600358  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8347
I1001 09:50:04.600394  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.51686 (* 1 = 0.51686 loss)
I1001 09:50:04.648564  4916 solver.cpp:218] Iteration 37500 (16.8331 iter/s, 5.94067s/100 iters), loss = 0.171079
I1001 09:50:04.648589  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171079 (* 1 = 0.171079 loss)
I1001 09:50:04.648597  4916 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1001 09:50:09.464198  4916 solver.cpp:218] Iteration 37600 (20.7659 iter/s, 4.81559s/100 iters), loss = 0.250884
I1001 09:50:09.464239  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250884 (* 1 = 0.250884 loss)
I1001 09:50:09.464246  4916 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1001 09:50:14.277542  4916 solver.cpp:218] Iteration 37700 (20.7759 iter/s, 4.81328s/100 iters), loss = 0.164538
I1001 09:50:14.277588  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164538 (* 1 = 0.164538 loss)
I1001 09:50:14.277606  4916 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1001 09:50:19.088579  4916 solver.cpp:218] Iteration 37800 (20.7858 iter/s, 4.81097s/100 iters), loss = 0.219993
I1001 09:50:19.088609  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219994 (* 1 = 0.219994 loss)
I1001 09:50:19.088615  4916 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1001 09:50:23.908123  4916 solver.cpp:218] Iteration 37900 (20.7491 iter/s, 4.81949s/100 iters), loss = 0.16317
I1001 09:50:23.908224  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16317 (* 1 = 0.16317 loss)
I1001 09:50:23.908231  4916 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1001 09:50:28.515971  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:50:28.713093  4916 solver.cpp:330] Iteration 38000, Testing net (#0)
I1001 09:50:29.804919  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:50:29.850100  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8072
I1001 09:50:29.850136  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.570273 (* 1 = 0.570273 loss)
I1001 09:50:29.898775  4916 solver.cpp:218] Iteration 38000 (16.693 iter/s, 5.99053s/100 iters), loss = 0.18558
I1001 09:50:29.898800  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18558 (* 1 = 0.18558 loss)
I1001 09:50:29.898808  4916 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1001 09:50:34.710721  4916 solver.cpp:218] Iteration 38100 (20.7818 iter/s, 4.81189s/100 iters), loss = 0.197341
I1001 09:50:34.710770  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197341 (* 1 = 0.197341 loss)
I1001 09:50:34.710777  4916 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1001 09:50:39.536267  4916 solver.cpp:218] Iteration 38200 (20.7234 iter/s, 4.82547s/100 iters), loss = 0.182137
I1001 09:50:39.536309  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182137 (* 1 = 0.182137 loss)
I1001 09:50:39.536314  4916 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1001 09:50:44.367128  4916 solver.cpp:218] Iteration 38300 (20.7005 iter/s, 4.83079s/100 iters), loss = 0.209224
I1001 09:50:44.367172  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209224 (* 1 = 0.209224 loss)
I1001 09:50:44.367182  4916 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1001 09:50:49.189457  4916 solver.cpp:218] Iteration 38400 (20.7373 iter/s, 4.82223s/100 iters), loss = 0.175037
I1001 09:50:49.189487  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175037 (* 1 = 0.175037 loss)
I1001 09:50:49.189492  4916 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1001 09:50:53.769069  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:50:53.961998  4916 solver.cpp:330] Iteration 38500, Testing net (#0)
I1001 09:50:55.037950  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:50:55.083101  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.817
I1001 09:50:55.083127  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558572 (* 1 = 0.558572 loss)
I1001 09:50:55.131561  4916 solver.cpp:218] Iteration 38500 (16.8292 iter/s, 5.94205s/100 iters), loss = 0.212643
I1001 09:50:55.131585  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212643 (* 1 = 0.212643 loss)
I1001 09:50:55.131592  4916 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1001 09:50:59.946007  4916 solver.cpp:218] Iteration 38600 (20.771 iter/s, 4.8144s/100 iters), loss = 0.299751
I1001 09:50:59.946045  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299751 (* 1 = 0.299751 loss)
I1001 09:50:59.946051  4916 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1001 09:51:04.759511  4916 solver.cpp:218] Iteration 38700 (20.7752 iter/s, 4.81344s/100 iters), loss = 0.260658
I1001 09:51:04.759552  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260659 (* 1 = 0.260659 loss)
I1001 09:51:04.759557  4916 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1001 09:51:09.581593  4916 solver.cpp:218] Iteration 38800 (20.7382 iter/s, 4.82202s/100 iters), loss = 0.265037
I1001 09:51:09.581624  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265037 (* 1 = 0.265037 loss)
I1001 09:51:09.581629  4916 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1001 09:51:14.408897  4916 solver.cpp:218] Iteration 38900 (20.7163 iter/s, 4.82712s/100 iters), loss = 0.134413
I1001 09:51:14.408934  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134413 (* 1 = 0.134413 loss)
I1001 09:51:14.408942  4916 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1001 09:51:18.982787  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:51:19.175515  4916 solver.cpp:330] Iteration 39000, Testing net (#0)
I1001 09:51:20.256706  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:51:20.302759  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.825
I1001 09:51:20.302788  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555355 (* 1 = 0.555355 loss)
I1001 09:51:20.352250  4916 solver.cpp:218] Iteration 39000 (16.8257 iter/s, 5.94329s/100 iters), loss = 0.145189
I1001 09:51:20.352298  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145189 (* 1 = 0.145189 loss)
I1001 09:51:20.352304  4916 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1001 09:51:25.167680  4916 solver.cpp:218] Iteration 39100 (20.7669 iter/s, 4.81536s/100 iters), loss = 0.250724
I1001 09:51:25.167806  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250724 (* 1 = 0.250724 loss)
I1001 09:51:25.167815  4916 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1001 09:51:29.990041  4916 solver.cpp:218] Iteration 39200 (20.7374 iter/s, 4.82221s/100 iters), loss = 0.227134
I1001 09:51:29.990070  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227134 (* 1 = 0.227134 loss)
I1001 09:51:29.990077  4916 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1001 09:51:34.806876  4916 solver.cpp:218] Iteration 39300 (20.7607 iter/s, 4.81678s/100 iters), loss = 0.200017
I1001 09:51:34.806906  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200017 (* 1 = 0.200017 loss)
I1001 09:51:34.806912  4916 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1001 09:51:39.725736  4916 solver.cpp:218] Iteration 39400 (20.3301 iter/s, 4.91881s/100 iters), loss = 0.134417
I1001 09:51:39.725767  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134417 (* 1 = 0.134417 loss)
I1001 09:51:39.725774  4916 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1001 09:51:44.354811  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:51:44.552889  4916 solver.cpp:330] Iteration 39500, Testing net (#0)
I1001 09:51:45.640424  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:51:45.685582  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.807
I1001 09:51:45.685619  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.602372 (* 1 = 0.602372 loss)
I1001 09:51:45.734438  4916 solver.cpp:218] Iteration 39500 (16.6427 iter/s, 6.00865s/100 iters), loss = 0.274131
I1001 09:51:45.734463  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274131 (* 1 = 0.274131 loss)
I1001 09:51:45.734470  4916 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1001 09:51:50.575551  4916 solver.cpp:218] Iteration 39600 (20.6566 iter/s, 4.84106s/100 iters), loss = 0.176902
I1001 09:51:50.575580  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176902 (* 1 = 0.176902 loss)
I1001 09:51:50.575587  4916 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1001 09:51:55.391269  4916 solver.cpp:218] Iteration 39700 (20.7656 iter/s, 4.81566s/100 iters), loss = 0.215141
I1001 09:51:55.391389  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215141 (* 1 = 0.215141 loss)
I1001 09:51:55.391407  4916 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1001 09:52:00.267843  4916 solver.cpp:218] Iteration 39800 (20.5067 iter/s, 4.87644s/100 iters), loss = 0.254242
I1001 09:52:00.267874  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254242 (* 1 = 0.254242 loss)
I1001 09:52:00.267879  4916 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1001 09:52:05.091819  4916 solver.cpp:218] Iteration 39900 (20.73 iter/s, 4.82392s/100 iters), loss = 0.154601
I1001 09:52:05.091859  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154601 (* 1 = 0.154601 loss)
I1001 09:52:05.091866  4916 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1001 09:52:09.670056  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:52:09.862422  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_40000.caffemodel
I1001 09:52:09.866641  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_40000.solverstate
I1001 09:52:09.867887  4916 solver.cpp:330] Iteration 40000, Testing net (#0)
I1001 09:52:10.942279  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:52:10.988051  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8349
I1001 09:52:10.988086  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.488282 (* 1 = 0.488282 loss)
I1001 09:52:11.038516  4916 solver.cpp:218] Iteration 40000 (16.8162 iter/s, 5.94664s/100 iters), loss = 0.202022
I1001 09:52:11.038547  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202022 (* 1 = 0.202022 loss)
I1001 09:52:11.038552  4916 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1001 09:52:11.038556  4916 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1001 09:52:15.908047  4916 solver.cpp:218] Iteration 40100 (20.5361 iter/s, 4.86948s/100 iters), loss = 0.237202
I1001 09:52:15.908087  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237202 (* 1 = 0.237202 loss)
I1001 09:52:15.908093  4916 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1001 09:52:20.728900  4916 solver.cpp:218] Iteration 40200 (20.7435 iter/s, 4.82079s/100 iters), loss = 0.134167
I1001 09:52:20.728929  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134167 (* 1 = 0.134167 loss)
I1001 09:52:20.728935  4916 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1001 09:52:25.558537  4916 solver.cpp:218] Iteration 40300 (20.7057 iter/s, 4.82959s/100 iters), loss = 0.126065
I1001 09:52:25.558663  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126065 (* 1 = 0.126065 loss)
I1001 09:52:25.558670  4916 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1001 09:52:30.398711  4916 solver.cpp:218] Iteration 40400 (20.661 iter/s, 4.84003s/100 iters), loss = 0.0820232
I1001 09:52:30.398741  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0820234 (* 1 = 0.0820234 loss)
I1001 09:52:30.398746  4916 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1001 09:52:34.968451  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:52:35.161242  4916 solver.cpp:330] Iteration 40500, Testing net (#0)
I1001 09:52:36.243219  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:52:36.287706  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1001 09:52:36.287741  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301038 (* 1 = 0.301038 loss)
I1001 09:52:36.336663  4916 solver.cpp:218] Iteration 40500 (16.841 iter/s, 5.9379s/100 iters), loss = 0.104685
I1001 09:52:36.336709  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104686 (* 1 = 0.104686 loss)
I1001 09:52:36.336716  4916 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1001 09:52:41.159356  4916 solver.cpp:218] Iteration 40600 (20.7356 iter/s, 4.82263s/100 iters), loss = 0.106632
I1001 09:52:41.159389  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106632 (* 1 = 0.106632 loss)
I1001 09:52:41.159395  4916 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1001 09:52:45.976723  4916 solver.cpp:218] Iteration 40700 (20.7584 iter/s, 4.81732s/100 iters), loss = 0.14289
I1001 09:52:45.976763  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14289 (* 1 = 0.14289 loss)
I1001 09:52:45.976768  4916 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1001 09:52:50.822443  4916 solver.cpp:218] Iteration 40800 (20.637 iter/s, 4.84566s/100 iters), loss = 0.132073
I1001 09:52:50.822474  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132074 (* 1 = 0.132074 loss)
I1001 09:52:50.822491  4916 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1001 09:52:55.663182  4916 solver.cpp:218] Iteration 40900 (20.6582 iter/s, 4.84069s/100 iters), loss = 0.0726806
I1001 09:52:55.663295  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0726808 (* 1 = 0.0726808 loss)
I1001 09:52:55.663306  4916 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1001 09:53:00.261652  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:53:00.457605  4916 solver.cpp:330] Iteration 41000, Testing net (#0)
I1001 09:53:01.536280  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:53:01.581642  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1001 09:53:01.581677  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295277 (* 1 = 0.295277 loss)
I1001 09:53:01.630072  4916 solver.cpp:218] Iteration 41000 (16.7595 iter/s, 5.96676s/100 iters), loss = 0.115174
I1001 09:53:01.630100  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115174 (* 1 = 0.115174 loss)
I1001 09:53:01.630107  4916 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1001 09:53:06.461665  4916 solver.cpp:218] Iteration 41100 (20.6973 iter/s, 4.83154s/100 iters), loss = 0.101513
I1001 09:53:06.461706  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101513 (* 1 = 0.101513 loss)
I1001 09:53:06.461712  4916 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1001 09:53:11.318819  4916 solver.cpp:218] Iteration 41200 (20.5885 iter/s, 4.85709s/100 iters), loss = 0.130809
I1001 09:53:11.318862  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130809 (* 1 = 0.130809 loss)
I1001 09:53:11.318871  4916 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1001 09:53:16.215881  4916 solver.cpp:218] Iteration 41300 (20.4208 iter/s, 4.89696s/100 iters), loss = 0.0902429
I1001 09:53:16.215936  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0902431 (* 1 = 0.0902431 loss)
I1001 09:53:16.215958  4916 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1001 09:53:21.153395  4916 solver.cpp:218] Iteration 41400 (20.2534 iter/s, 4.93744s/100 iters), loss = 0.0741148
I1001 09:53:21.153432  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.074115 (* 1 = 0.074115 loss)
I1001 09:53:21.153440  4916 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1001 09:53:25.842859  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:53:26.041983  4916 solver.cpp:330] Iteration 41500, Testing net (#0)
I1001 09:53:27.143345  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:53:27.191346  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9007
I1001 09:53:27.191372  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299475 (* 1 = 0.299475 loss)
I1001 09:53:27.240546  4916 solver.cpp:218] Iteration 41500 (16.4282 iter/s, 6.08709s/100 iters), loss = 0.0656859
I1001 09:53:27.240582  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0656861 (* 1 = 0.0656861 loss)
I1001 09:53:27.240589  4916 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1001 09:53:32.159991  4916 solver.cpp:218] Iteration 41600 (20.3277 iter/s, 4.91938s/100 iters), loss = 0.118626
I1001 09:53:32.160025  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118627 (* 1 = 0.118627 loss)
I1001 09:53:32.160032  4916 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1001 09:53:37.023103  4916 solver.cpp:218] Iteration 41700 (20.5632 iter/s, 4.86305s/100 iters), loss = 0.111516
I1001 09:53:37.023134  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111516 (* 1 = 0.111516 loss)
I1001 09:53:37.023141  4916 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1001 09:53:41.874090  4916 solver.cpp:218] Iteration 41800 (20.6146 iter/s, 4.85093s/100 iters), loss = 0.0730736
I1001 09:53:41.874133  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0730738 (* 1 = 0.0730738 loss)
I1001 09:53:41.874141  4916 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1001 09:53:46.728907  4916 solver.cpp:218] Iteration 41900 (20.5984 iter/s, 4.85475s/100 iters), loss = 0.0653108
I1001 09:53:46.728938  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.065311 (* 1 = 0.065311 loss)
I1001 09:53:46.728945  4916 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1001 09:53:51.322623  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:53:51.515136  4916 solver.cpp:330] Iteration 42000, Testing net (#0)
I1001 09:53:52.589735  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:53:52.634789  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I1001 09:53:52.634825  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284659 (* 1 = 0.284659 loss)
I1001 09:53:52.683756  4916 solver.cpp:218] Iteration 42000 (16.7932 iter/s, 5.9548s/100 iters), loss = 0.134112
I1001 09:53:52.683785  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134112 (* 1 = 0.134112 loss)
I1001 09:53:52.683792  4916 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1001 09:53:57.519557  4916 solver.cpp:218] Iteration 42100 (20.6793 iter/s, 4.83575s/100 iters), loss = 0.167499
I1001 09:53:57.519744  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1675 (* 1 = 0.1675 loss)
I1001 09:53:57.519753  4916 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1001 09:54:02.375720  4916 solver.cpp:218] Iteration 42200 (20.5932 iter/s, 4.85597s/100 iters), loss = 0.128239
I1001 09:54:02.375754  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128239 (* 1 = 0.128239 loss)
I1001 09:54:02.375761  4916 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1001 09:54:07.237066  4916 solver.cpp:218] Iteration 42300 (20.5707 iter/s, 4.86129s/100 iters), loss = 0.0897519
I1001 09:54:07.237099  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.089752 (* 1 = 0.089752 loss)
I1001 09:54:07.237105  4916 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1001 09:54:12.118762  4916 solver.cpp:218] Iteration 42400 (20.4849 iter/s, 4.88164s/100 iters), loss = 0.0614464
I1001 09:54:12.118793  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0614465 (* 1 = 0.0614465 loss)
I1001 09:54:12.118809  4916 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1001 09:54:16.724704  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:54:16.917695  4916 solver.cpp:330] Iteration 42500, Testing net (#0)
I1001 09:54:17.998114  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:54:18.043491  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I1001 09:54:18.043527  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281008 (* 1 = 0.281008 loss)
I1001 09:54:18.091722  4916 solver.cpp:218] Iteration 42500 (16.7423 iter/s, 5.97291s/100 iters), loss = 0.0650702
I1001 09:54:18.091745  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650704 (* 1 = 0.0650704 loss)
I1001 09:54:18.091753  4916 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1001 09:54:22.935364  4916 solver.cpp:218] Iteration 42600 (20.6459 iter/s, 4.84358s/100 iters), loss = 0.0867909
I1001 09:54:22.935428  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0867911 (* 1 = 0.0867911 loss)
I1001 09:54:22.935441  4916 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1001 09:54:27.767526  4916 solver.cpp:218] Iteration 42700 (20.695 iter/s, 4.83208s/100 iters), loss = 0.148193
I1001 09:54:27.767616  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148193 (* 1 = 0.148193 loss)
I1001 09:54:27.767632  4916 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1001 09:54:32.592684  4916 solver.cpp:218] Iteration 42800 (20.7252 iter/s, 4.82505s/100 iters), loss = 0.0533327
I1001 09:54:32.592715  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0533328 (* 1 = 0.0533328 loss)
I1001 09:54:32.592720  4916 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1001 09:54:37.400665  4916 solver.cpp:218] Iteration 42900 (20.799 iter/s, 4.80793s/100 iters), loss = 0.0260973
I1001 09:54:37.400696  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260974 (* 1 = 0.0260974 loss)
I1001 09:54:37.400702  4916 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1001 09:54:41.982173  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:54:42.175422  4916 solver.cpp:330] Iteration 43000, Testing net (#0)
I1001 09:54:43.248996  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:54:43.294829  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I1001 09:54:43.294864  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288549 (* 1 = 0.288549 loss)
I1001 09:54:43.343730  4916 solver.cpp:218] Iteration 43000 (16.8265 iter/s, 5.94302s/100 iters), loss = 0.0773222
I1001 09:54:43.343752  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0773223 (* 1 = 0.0773223 loss)
I1001 09:54:43.343760  4916 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1001 09:54:48.160406  4916 solver.cpp:218] Iteration 43100 (20.7614 iter/s, 4.81663s/100 iters), loss = 0.0764011
I1001 09:54:48.160447  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0764012 (* 1 = 0.0764012 loss)
I1001 09:54:48.160454  4916 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1001 09:54:52.966225  4916 solver.cpp:218] Iteration 43200 (20.8084 iter/s, 4.80575s/100 iters), loss = 0.088636
I1001 09:54:52.966266  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0886362 (* 1 = 0.0886362 loss)
I1001 09:54:52.966271  4916 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1001 09:54:57.786572  4916 solver.cpp:218] Iteration 43300 (20.7457 iter/s, 4.82028s/100 iters), loss = 0.0669672
I1001 09:54:57.786700  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0669673 (* 1 = 0.0669673 loss)
I1001 09:54:57.786706  4916 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1001 09:55:02.600257  4916 solver.cpp:218] Iteration 43400 (20.7747 iter/s, 4.81354s/100 iters), loss = 0.0732099
I1001 09:55:02.600301  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732101 (* 1 = 0.0732101 loss)
I1001 09:55:02.600306  4916 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1001 09:55:07.169155  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:55:07.361630  4916 solver.cpp:330] Iteration 43500, Testing net (#0)
I1001 09:55:08.444984  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:55:08.490686  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9007
I1001 09:55:08.490711  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304553 (* 1 = 0.304553 loss)
I1001 09:55:08.539113  4916 solver.cpp:218] Iteration 43500 (16.8385 iter/s, 5.93879s/100 iters), loss = 0.119498
I1001 09:55:08.539145  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119498 (* 1 = 0.119498 loss)
I1001 09:55:08.539151  4916 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1001 09:55:13.351953  4916 solver.cpp:218] Iteration 43600 (20.778 iter/s, 4.81278s/100 iters), loss = 0.0988431
I1001 09:55:13.351982  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0988433 (* 1 = 0.0988433 loss)
I1001 09:55:13.351987  4916 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1001 09:55:18.239653  4916 solver.cpp:218] Iteration 43700 (20.4597 iter/s, 4.88765s/100 iters), loss = 0.0782438
I1001 09:55:18.239694  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0782439 (* 1 = 0.0782439 loss)
I1001 09:55:18.239699  4916 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1001 09:55:23.077147  4916 solver.cpp:218] Iteration 43800 (20.6721 iter/s, 4.83743s/100 iters), loss = 0.0967445
I1001 09:55:23.077179  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0967446 (* 1 = 0.0967446 loss)
I1001 09:55:23.077186  4916 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1001 09:55:27.902899  4916 solver.cpp:218] Iteration 43900 (20.7224 iter/s, 4.8257s/100 iters), loss = 0.0888345
I1001 09:55:27.902988  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0888346 (* 1 = 0.0888346 loss)
I1001 09:55:27.902995  4916 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1001 09:55:32.486385  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:55:32.679774  4916 solver.cpp:330] Iteration 44000, Testing net (#0)
I1001 09:55:33.754863  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:55:33.800336  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1001 09:55:33.800361  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280518 (* 1 = 0.280518 loss)
I1001 09:55:33.849264  4916 solver.cpp:218] Iteration 44000 (16.8173 iter/s, 5.94626s/100 iters), loss = 0.0500985
I1001 09:55:33.849288  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0500987 (* 1 = 0.0500987 loss)
I1001 09:55:33.849295  4916 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1001 09:55:38.672149  4916 solver.cpp:218] Iteration 44100 (20.7347 iter/s, 4.82283s/100 iters), loss = 0.160647
I1001 09:55:38.672185  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160647 (* 1 = 0.160647 loss)
I1001 09:55:38.672193  4916 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1001 09:55:43.497460  4916 solver.cpp:218] Iteration 44200 (20.7243 iter/s, 4.82525s/100 iters), loss = 0.0749609
I1001 09:55:43.497491  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.074961 (* 1 = 0.074961 loss)
I1001 09:55:43.497499  4916 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1001 09:55:48.312705  4916 solver.cpp:218] Iteration 44300 (20.7676 iter/s, 4.81519s/100 iters), loss = 0.0415173
I1001 09:55:48.312747  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0415175 (* 1 = 0.0415175 loss)
I1001 09:55:48.312752  4916 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1001 09:55:53.123674  4916 solver.cpp:218] Iteration 44400 (20.7861 iter/s, 4.8109s/100 iters), loss = 0.0678572
I1001 09:55:53.123729  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0678573 (* 1 = 0.0678573 loss)
I1001 09:55:53.123751  4916 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1001 09:55:57.739840  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:55:57.932242  4916 solver.cpp:330] Iteration 44500, Testing net (#0)
I1001 09:55:59.007030  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:55:59.052400  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I1001 09:55:59.052435  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284885 (* 1 = 0.284885 loss)
I1001 09:55:59.100981  4916 solver.cpp:218] Iteration 44500 (16.7301 iter/s, 5.97724s/100 iters), loss = 0.0478275
I1001 09:55:59.101006  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0478276 (* 1 = 0.0478276 loss)
I1001 09:55:59.101012  4916 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1001 09:56:03.925415  4916 solver.cpp:218] Iteration 44600 (20.728 iter/s, 4.82439s/100 iters), loss = 0.0922488
I1001 09:56:03.925448  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0922489 (* 1 = 0.0922489 loss)
I1001 09:56:03.925464  4916 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1001 09:56:08.749138  4916 solver.cpp:218] Iteration 44700 (20.7311 iter/s, 4.82367s/100 iters), loss = 0.0579814
I1001 09:56:08.749169  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579815 (* 1 = 0.0579815 loss)
I1001 09:56:08.749176  4916 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1001 09:56:13.560174  4916 solver.cpp:218] Iteration 44800 (20.7858 iter/s, 4.81098s/100 iters), loss = 0.0932217
I1001 09:56:13.560204  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0932218 (* 1 = 0.0932218 loss)
I1001 09:56:13.560220  4916 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1001 09:56:18.386382  4916 solver.cpp:218] Iteration 44900 (20.7204 iter/s, 4.82615s/100 iters), loss = 0.0820625
I1001 09:56:18.386412  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0820626 (* 1 = 0.0820626 loss)
I1001 09:56:18.386428  4916 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1001 09:56:22.959743  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:56:23.152823  4916 solver.cpp:330] Iteration 45000, Testing net (#0)
I1001 09:56:24.232925  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:56:24.278461  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8996
I1001 09:56:24.278496  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304907 (* 1 = 0.304907 loss)
I1001 09:56:24.326903  4916 solver.cpp:218] Iteration 45000 (16.8337 iter/s, 5.94047s/100 iters), loss = 0.0733441
I1001 09:56:24.326930  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0733442 (* 1 = 0.0733442 loss)
I1001 09:56:24.326936  4916 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1001 09:56:29.138103  4916 solver.cpp:218] Iteration 45100 (20.7851 iter/s, 4.81115s/100 iters), loss = 0.0983419
I1001 09:56:29.138345  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0983419 (* 1 = 0.0983419 loss)
I1001 09:56:29.138355  4916 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1001 09:56:33.955996  4916 solver.cpp:218] Iteration 45200 (20.7572 iter/s, 4.81761s/100 iters), loss = 0.0686467
I1001 09:56:33.956027  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686467 (* 1 = 0.0686467 loss)
I1001 09:56:33.956043  4916 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1001 09:56:38.770220  4916 solver.cpp:218] Iteration 45300 (20.772 iter/s, 4.81417s/100 iters), loss = 0.0416882
I1001 09:56:38.770251  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416882 (* 1 = 0.0416882 loss)
I1001 09:56:38.770267  4916 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1001 09:56:43.579176  4916 solver.cpp:218] Iteration 45400 (20.7948 iter/s, 4.80891s/100 iters), loss = 0.0729543
I1001 09:56:43.579206  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729543 (* 1 = 0.0729543 loss)
I1001 09:56:43.579222  4916 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1001 09:56:48.161833  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:56:48.355069  4916 solver.cpp:330] Iteration 45500, Testing net (#0)
I1001 09:56:49.427860  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:56:49.473495  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9058
I1001 09:56:49.473520  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.281068 (* 1 = 0.281068 loss)
I1001 09:56:49.522017  4916 solver.cpp:218] Iteration 45500 (16.8271 iter/s, 5.94279s/100 iters), loss = 0.0785892
I1001 09:56:49.522043  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0785892 (* 1 = 0.0785892 loss)
I1001 09:56:49.522059  4916 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1001 09:56:54.342864  4916 solver.cpp:218] Iteration 45600 (20.7435 iter/s, 4.82079s/100 iters), loss = 0.103688
I1001 09:56:54.342895  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103688 (* 1 = 0.103688 loss)
I1001 09:56:54.342909  4916 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1001 09:56:59.154949  4916 solver.cpp:218] Iteration 45700 (20.7812 iter/s, 4.81203s/100 iters), loss = 0.112362
I1001 09:56:59.155089  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112362 (* 1 = 0.112362 loss)
I1001 09:56:59.155109  4916 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1001 09:57:03.979176  4916 solver.cpp:218] Iteration 45800 (20.7295 iter/s, 4.82404s/100 iters), loss = 0.0463021
I1001 09:57:03.979205  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463021 (* 1 = 0.0463021 loss)
I1001 09:57:03.979220  4916 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1001 09:57:08.803128  4916 solver.cpp:218] Iteration 45900 (20.7301 iter/s, 4.8239s/100 iters), loss = 0.0449687
I1001 09:57:08.803158  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449687 (* 1 = 0.0449687 loss)
I1001 09:57:08.803174  4916 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1001 09:57:13.375835  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:57:13.568362  4916 solver.cpp:330] Iteration 46000, Testing net (#0)
I1001 09:57:14.648706  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:57:14.694303  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1001 09:57:14.694339  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296104 (* 1 = 0.296104 loss)
I1001 09:57:14.742802  4916 solver.cpp:218] Iteration 46000 (16.8361 iter/s, 5.93962s/100 iters), loss = 0.0459442
I1001 09:57:14.742833  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459442 (* 1 = 0.0459442 loss)
I1001 09:57:14.742839  4916 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1001 09:57:19.557298  4916 solver.cpp:218] Iteration 46100 (20.7708 iter/s, 4.81444s/100 iters), loss = 0.0593675
I1001 09:57:19.557329  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0593675 (* 1 = 0.0593675 loss)
I1001 09:57:19.557335  4916 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1001 09:57:24.376823  4916 solver.cpp:218] Iteration 46200 (20.7492 iter/s, 4.81947s/100 iters), loss = 0.0703804
I1001 09:57:24.376853  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0703804 (* 1 = 0.0703804 loss)
I1001 09:57:24.376860  4916 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1001 09:57:29.186746  4916 solver.cpp:218] Iteration 46300 (20.7906 iter/s, 4.80987s/100 iters), loss = 0.079243
I1001 09:57:29.186877  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.079243 (* 1 = 0.079243 loss)
I1001 09:57:29.186895  4916 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1001 09:57:34.009791  4916 solver.cpp:218] Iteration 46400 (20.7344 iter/s, 4.8229s/100 iters), loss = 0.0540401
I1001 09:57:34.009824  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0540401 (* 1 = 0.0540401 loss)
I1001 09:57:34.009829  4916 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1001 09:57:38.597452  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:57:38.790555  4916 solver.cpp:330] Iteration 46500, Testing net (#0)
I1001 09:57:39.864466  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:57:39.909528  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1001 09:57:39.909553  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30497 (* 1 = 0.30497 loss)
I1001 09:57:39.958484  4916 solver.cpp:218] Iteration 46500 (16.8106 iter/s, 5.94864s/100 iters), loss = 0.0416785
I1001 09:57:39.958509  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416785 (* 1 = 0.0416785 loss)
I1001 09:57:39.958529  4916 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1001 09:57:44.783329  4916 solver.cpp:218] Iteration 46600 (20.7263 iter/s, 4.8248s/100 iters), loss = 0.0536779
I1001 09:57:44.783360  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536779 (* 1 = 0.0536779 loss)
I1001 09:57:44.783367  4916 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1001 09:57:49.582067  4916 solver.cpp:218] Iteration 46700 (20.839 iter/s, 4.79869s/100 iters), loss = 0.0532107
I1001 09:57:49.582098  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532107 (* 1 = 0.0532107 loss)
I1001 09:57:49.582103  4916 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1001 09:57:54.413060  4916 solver.cpp:218] Iteration 46800 (20.6999 iter/s, 4.83094s/100 iters), loss = 0.0363681
I1001 09:57:54.413091  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363681 (* 1 = 0.0363681 loss)
I1001 09:57:54.413099  4916 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1001 09:57:59.254099  4916 solver.cpp:218] Iteration 46900 (20.657 iter/s, 4.84098s/100 iters), loss = 0.0714007
I1001 09:57:59.254235  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0714007 (* 1 = 0.0714007 loss)
I1001 09:57:59.254245  4916 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1001 09:58:03.844590  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:58:04.037751  4916 solver.cpp:330] Iteration 47000, Testing net (#0)
I1001 09:58:05.111399  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:58:05.157583  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9075
I1001 09:58:05.157609  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287444 (* 1 = 0.287444 loss)
I1001 09:58:05.206753  4916 solver.cpp:218] Iteration 47000 (16.7997 iter/s, 5.9525s/100 iters), loss = 0.0818934
I1001 09:58:05.206789  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0818934 (* 1 = 0.0818934 loss)
I1001 09:58:05.206796  4916 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1001 09:58:10.021703  4916 solver.cpp:218] Iteration 47100 (20.7689 iter/s, 4.81489s/100 iters), loss = 0.0924666
I1001 09:58:10.021744  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0924666 (* 1 = 0.0924666 loss)
I1001 09:58:10.021749  4916 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1001 09:58:14.935106  4916 solver.cpp:218] Iteration 47200 (20.3528 iter/s, 4.91333s/100 iters), loss = 0.0476677
I1001 09:58:14.935137  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476677 (* 1 = 0.0476677 loss)
I1001 09:58:14.935143  4916 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1001 09:58:20.000677  4916 solver.cpp:218] Iteration 47300 (19.7413 iter/s, 5.06552s/100 iters), loss = 0.036426
I1001 09:58:20.000710  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036426 (* 1 = 0.036426 loss)
I1001 09:58:20.000730  4916 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1001 09:58:24.836640  4916 solver.cpp:218] Iteration 47400 (20.6786 iter/s, 4.83591s/100 iters), loss = 0.0618151
I1001 09:58:24.836680  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618151 (* 1 = 0.0618151 loss)
I1001 09:58:24.836686  4916 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1001 09:58:29.496158  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:58:29.696137  4916 solver.cpp:330] Iteration 47500, Testing net (#0)
I1001 09:58:30.798449  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:58:30.843461  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9026
I1001 09:58:30.843497  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304456 (* 1 = 0.304456 loss)
I1001 09:58:30.892354  4916 solver.cpp:218] Iteration 47500 (16.5135 iter/s, 6.05565s/100 iters), loss = 0.0580303
I1001 09:58:30.892382  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580303 (* 1 = 0.0580303 loss)
I1001 09:58:30.892390  4916 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1001 09:58:35.862815  4916 solver.cpp:218] Iteration 47600 (20.1191 iter/s, 4.9704s/100 iters), loss = 0.0299633
I1001 09:58:35.862851  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299633 (* 1 = 0.0299633 loss)
I1001 09:58:35.862869  4916 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1001 09:58:40.769876  4916 solver.cpp:218] Iteration 47700 (20.379 iter/s, 4.907s/100 iters), loss = 0.0775245
I1001 09:58:40.769915  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0775245 (* 1 = 0.0775245 loss)
I1001 09:58:40.769922  4916 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1001 09:58:45.640703  4916 solver.cpp:218] Iteration 47800 (20.5307 iter/s, 4.87077s/100 iters), loss = 0.0444044
I1001 09:58:45.640744  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444044 (* 1 = 0.0444044 loss)
I1001 09:58:45.640750  4916 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1001 09:58:50.560117  4916 solver.cpp:218] Iteration 47900 (20.328 iter/s, 4.91933s/100 iters), loss = 0.0587382
I1001 09:58:50.560178  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0587382 (* 1 = 0.0587382 loss)
I1001 09:58:50.560185  4916 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1001 09:58:55.139276  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:58:55.334264  4916 solver.cpp:330] Iteration 48000, Testing net (#0)
I1001 09:58:56.452826  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:58:56.502418  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9036
I1001 09:58:56.502444  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306937 (* 1 = 0.306937 loss)
I1001 09:58:56.552795  4916 solver.cpp:218] Iteration 48000 (16.6883 iter/s, 5.99221s/100 iters), loss = 0.0482282
I1001 09:58:56.552831  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482282 (* 1 = 0.0482282 loss)
I1001 09:58:56.552839  4916 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1001 09:59:01.511355  4916 solver.cpp:218] Iteration 48100 (20.1674 iter/s, 4.9585s/100 iters), loss = 0.0443433
I1001 09:59:01.511481  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443434 (* 1 = 0.0443434 loss)
I1001 09:59:01.511488  4916 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1001 09:59:06.519507  4916 solver.cpp:218] Iteration 48200 (19.968 iter/s, 5.00801s/100 iters), loss = 0.0791841
I1001 09:59:06.519548  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0791842 (* 1 = 0.0791842 loss)
I1001 09:59:06.519554  4916 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1001 09:59:11.366122  4916 solver.cpp:218] Iteration 48300 (20.6332 iter/s, 4.84655s/100 iters), loss = 0.0498963
I1001 09:59:11.366158  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0498963 (* 1 = 0.0498963 loss)
I1001 09:59:11.366166  4916 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1001 09:59:16.228997  4916 solver.cpp:218] Iteration 48400 (20.5642 iter/s, 4.86282s/100 iters), loss = 0.066539
I1001 09:59:16.229029  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665391 (* 1 = 0.0665391 loss)
I1001 09:59:16.229046  4916 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1001 09:59:20.864030  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:59:21.056627  4916 solver.cpp:330] Iteration 48500, Testing net (#0)
I1001 09:59:22.142477  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:59:22.187714  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9043
I1001 09:59:22.187739  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300145 (* 1 = 0.300145 loss)
I1001 09:59:22.236758  4916 solver.cpp:218] Iteration 48500 (16.6453 iter/s, 6.00771s/100 iters), loss = 0.0806295
I1001 09:59:22.236783  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0806295 (* 1 = 0.0806295 loss)
I1001 09:59:22.236790  4916 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1001 09:59:27.127744  4916 solver.cpp:218] Iteration 48600 (20.446 iter/s, 4.89094s/100 iters), loss = 0.0552753
I1001 09:59:27.127776  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552753 (* 1 = 0.0552753 loss)
I1001 09:59:27.127784  4916 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1001 09:59:31.949350  4916 solver.cpp:218] Iteration 48700 (20.7402 iter/s, 4.82155s/100 iters), loss = 0.0541884
I1001 09:59:31.949492  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541884 (* 1 = 0.0541884 loss)
I1001 09:59:31.949501  4916 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1001 09:59:36.774972  4916 solver.cpp:218] Iteration 48800 (20.7234 iter/s, 4.82546s/100 iters), loss = 0.0323895
I1001 09:59:36.775002  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323895 (* 1 = 0.0323895 loss)
I1001 09:59:36.775007  4916 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1001 09:59:41.590695  4916 solver.cpp:218] Iteration 48900 (20.7655 iter/s, 4.81567s/100 iters), loss = 0.0311418
I1001 09:59:41.590735  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311418 (* 1 = 0.0311418 loss)
I1001 09:59:41.590741  4916 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1001 09:59:46.160444  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:59:46.352226  4916 solver.cpp:330] Iteration 49000, Testing net (#0)
I1001 09:59:47.434886  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 09:59:47.480810  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1001 09:59:47.480836  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30217 (* 1 = 0.30217 loss)
I1001 09:59:47.529611  4916 solver.cpp:218] Iteration 49000 (16.8383 iter/s, 5.93885s/100 iters), loss = 0.0376781
I1001 09:59:47.529649  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376782 (* 1 = 0.0376782 loss)
I1001 09:59:47.529655  4916 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1001 09:59:52.366258  4916 solver.cpp:218] Iteration 49100 (20.6757 iter/s, 4.83659s/100 iters), loss = 0.039459
I1001 09:59:52.366300  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039459 (* 1 = 0.039459 loss)
I1001 09:59:52.366307  4916 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1001 09:59:57.220253  4916 solver.cpp:218] Iteration 49200 (20.6019 iter/s, 4.85393s/100 iters), loss = 0.0593753
I1001 09:59:57.220283  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0593753 (* 1 = 0.0593753 loss)
I1001 09:59:57.220289  4916 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1001 10:00:02.058243  4916 solver.cpp:218] Iteration 49300 (20.67 iter/s, 4.83794s/100 iters), loss = 0.0513037
I1001 10:00:02.058421  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513037 (* 1 = 0.0513037 loss)
I1001 10:00:02.058431  4916 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1001 10:00:06.883255  4916 solver.cpp:218] Iteration 49400 (20.7261 iter/s, 4.82483s/100 iters), loss = 0.0479432
I1001 10:00:06.883296  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479432 (* 1 = 0.0479432 loss)
I1001 10:00:06.883301  4916 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1001 10:00:11.468873  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:00:11.661332  4916 solver.cpp:330] Iteration 49500, Testing net (#0)
I1001 10:00:12.737890  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:00:12.783536  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9046
I1001 10:00:12.783571  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309045 (* 1 = 0.309045 loss)
I1001 10:00:12.832124  4916 solver.cpp:218] Iteration 49500 (16.8101 iter/s, 5.9488s/100 iters), loss = 0.109442
I1001 10:00:12.832164  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109442 (* 1 = 0.109442 loss)
I1001 10:00:12.832170  4916 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1001 10:00:17.658054  4916 solver.cpp:218] Iteration 49600 (20.7217 iter/s, 4.82586s/100 iters), loss = 0.0459507
I1001 10:00:17.658085  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459507 (* 1 = 0.0459507 loss)
I1001 10:00:17.658092  4916 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1001 10:00:22.472836  4916 solver.cpp:218] Iteration 49700 (20.7696 iter/s, 4.81473s/100 iters), loss = 0.127253
I1001 10:00:22.472875  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127253 (* 1 = 0.127253 loss)
I1001 10:00:22.472882  4916 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1001 10:00:27.300209  4916 solver.cpp:218] Iteration 49800 (20.7155 iter/s, 4.82731s/100 iters), loss = 0.0665202
I1001 10:00:27.300240  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665203 (* 1 = 0.0665203 loss)
I1001 10:00:27.300246  4916 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1001 10:00:32.112371  4916 solver.cpp:218] Iteration 49900 (20.7809 iter/s, 4.81211s/100 iters), loss = 0.0590217
I1001 10:00:32.112484  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0590217 (* 1 = 0.0590217 loss)
I1001 10:00:32.112502  4916 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1001 10:00:36.695058  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:00:36.889863  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_50000.caffemodel
I1001 10:00:36.894330  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_50000.solverstate
I1001 10:00:36.895608  4916 solver.cpp:330] Iteration 50000, Testing net (#0)
I1001 10:00:37.972199  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:00:38.017907  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9065
I1001 10:00:38.017935  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310048 (* 1 = 0.310048 loss)
I1001 10:00:38.066184  4916 solver.cpp:218] Iteration 50000 (16.7963 iter/s, 5.95369s/100 iters), loss = 0.0191836
I1001 10:00:38.066213  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191837 (* 1 = 0.0191837 loss)
I1001 10:00:38.066220  4916 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1001 10:00:42.884107  4916 solver.cpp:218] Iteration 50100 (20.756 iter/s, 4.81787s/100 iters), loss = 0.0724467
I1001 10:00:42.884147  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0724468 (* 1 = 0.0724468 loss)
I1001 10:00:42.884155  4916 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1001 10:00:47.706650  4916 solver.cpp:218] Iteration 50200 (20.7362 iter/s, 4.82248s/100 iters), loss = 0.0509512
I1001 10:00:47.706689  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0509513 (* 1 = 0.0509513 loss)
I1001 10:00:47.706696  4916 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1001 10:00:52.517956  4916 solver.cpp:218] Iteration 50300 (20.7846 iter/s, 4.81125s/100 iters), loss = 0.0406451
I1001 10:00:52.517997  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406452 (* 1 = 0.0406452 loss)
I1001 10:00:52.518003  4916 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1001 10:00:57.344501  4916 solver.cpp:218] Iteration 50400 (20.719 iter/s, 4.82648s/100 iters), loss = 0.0268069
I1001 10:00:57.344532  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026807 (* 1 = 0.026807 loss)
I1001 10:00:57.344540  4916 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1001 10:01:01.920585  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:01:02.114272  4916 solver.cpp:330] Iteration 50500, Testing net (#0)
I1001 10:01:03.201539  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:01:03.247434  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9056
I1001 10:01:03.247459  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319373 (* 1 = 0.319373 loss)
I1001 10:01:03.296244  4916 solver.cpp:218] Iteration 50500 (16.802 iter/s, 5.95169s/100 iters), loss = 0.0715878
I1001 10:01:03.296273  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0715879 (* 1 = 0.0715879 loss)
I1001 10:01:03.296280  4916 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1001 10:01:08.114372  4916 solver.cpp:218] Iteration 50600 (20.7552 iter/s, 4.81808s/100 iters), loss = 0.0703334
I1001 10:01:08.114413  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0703335 (* 1 = 0.0703335 loss)
I1001 10:01:08.114418  4916 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1001 10:01:12.940671  4916 solver.cpp:218] Iteration 50700 (20.7201 iter/s, 4.82624s/100 iters), loss = 0.0544266
I1001 10:01:12.940703  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0544267 (* 1 = 0.0544267 loss)
I1001 10:01:12.940719  4916 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1001 10:01:17.764302  4916 solver.cpp:218] Iteration 50800 (20.7315 iter/s, 4.82358s/100 iters), loss = 0.0475877
I1001 10:01:17.764336  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0475878 (* 1 = 0.0475878 loss)
I1001 10:01:17.764344  4916 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1001 10:01:22.578127  4916 solver.cpp:218] Iteration 50900 (20.7737 iter/s, 4.81377s/100 iters), loss = 0.0505666
I1001 10:01:22.578161  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0505667 (* 1 = 0.0505667 loss)
I1001 10:01:22.578177  4916 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1001 10:01:27.157007  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:01:27.349910  4916 solver.cpp:330] Iteration 51000, Testing net (#0)
I1001 10:01:28.425545  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:01:28.470751  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I1001 10:01:28.470787  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311575 (* 1 = 0.311575 loss)
I1001 10:01:28.519165  4916 solver.cpp:218] Iteration 51000 (16.8322 iter/s, 5.94098s/100 iters), loss = 0.0357772
I1001 10:01:28.519191  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357774 (* 1 = 0.0357774 loss)
I1001 10:01:28.519197  4916 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1001 10:01:33.338624  4916 solver.cpp:218] Iteration 51100 (20.7494 iter/s, 4.81942s/100 iters), loss = 0.0463903
I1001 10:01:33.338798  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463904 (* 1 = 0.0463904 loss)
I1001 10:01:33.338806  4916 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1001 10:01:38.150135  4916 solver.cpp:218] Iteration 51200 (20.7843 iter/s, 4.81133s/100 iters), loss = 0.0762608
I1001 10:01:38.150177  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0762609 (* 1 = 0.0762609 loss)
I1001 10:01:38.150182  4916 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1001 10:01:42.971949  4916 solver.cpp:218] Iteration 51300 (20.7393 iter/s, 4.82175s/100 iters), loss = 0.0840716
I1001 10:01:42.971982  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0840717 (* 1 = 0.0840717 loss)
I1001 10:01:42.971997  4916 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1001 10:01:47.791275  4916 solver.cpp:218] Iteration 51400 (20.7506 iter/s, 4.81914s/100 iters), loss = 0.0327895
I1001 10:01:47.791308  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327896 (* 1 = 0.0327896 loss)
I1001 10:01:47.791316  4916 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1001 10:01:52.364255  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:01:52.557121  4916 solver.cpp:330] Iteration 51500, Testing net (#0)
I1001 10:01:53.642346  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:01:53.687458  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9042
I1001 10:01:53.687495  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322839 (* 1 = 0.322839 loss)
I1001 10:01:53.736546  4916 solver.cpp:218] Iteration 51500 (16.8202 iter/s, 5.94522s/100 iters), loss = 0.07832
I1001 10:01:53.736580  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0783201 (* 1 = 0.0783201 loss)
I1001 10:01:53.736588  4916 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1001 10:01:58.549347  4916 solver.cpp:218] Iteration 51600 (20.7782 iter/s, 4.81275s/100 iters), loss = 0.0337761
I1001 10:01:58.549377  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337762 (* 1 = 0.0337762 loss)
I1001 10:01:58.549383  4916 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1001 10:02:03.376178  4916 solver.cpp:218] Iteration 51700 (20.7177 iter/s, 4.82678s/100 iters), loss = 0.0452958
I1001 10:02:03.376283  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452958 (* 1 = 0.0452958 loss)
I1001 10:02:03.376301  4916 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1001 10:02:08.194118  4916 solver.cpp:218] Iteration 51800 (20.7563 iter/s, 4.81781s/100 iters), loss = 0.0439084
I1001 10:02:08.194164  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439085 (* 1 = 0.0439085 loss)
I1001 10:02:08.194170  4916 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1001 10:02:13.011941  4916 solver.cpp:218] Iteration 51900 (20.7565 iter/s, 4.81776s/100 iters), loss = 0.0182303
I1001 10:02:13.011971  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182304 (* 1 = 0.0182304 loss)
I1001 10:02:13.011978  4916 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1001 10:02:17.592092  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:02:17.784741  4916 solver.cpp:330] Iteration 52000, Testing net (#0)
I1001 10:02:18.860225  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:02:18.905124  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1001 10:02:18.905159  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313305 (* 1 = 0.313305 loss)
I1001 10:02:18.954113  4916 solver.cpp:218] Iteration 52000 (16.829 iter/s, 5.94212s/100 iters), loss = 0.0287042
I1001 10:02:18.954139  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287043 (* 1 = 0.0287043 loss)
I1001 10:02:18.954146  4916 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1001 10:02:23.779347  4916 solver.cpp:218] Iteration 52100 (20.7246 iter/s, 4.82518s/100 iters), loss = 0.0558611
I1001 10:02:23.779379  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558612 (* 1 = 0.0558612 loss)
I1001 10:02:23.779397  4916 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1001 10:02:28.679824  4916 solver.cpp:218] Iteration 52200 (20.4064 iter/s, 4.90042s/100 iters), loss = 0.0306551
I1001 10:02:28.679858  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306552 (* 1 = 0.0306552 loss)
I1001 10:02:28.679865  4916 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1001 10:02:33.595738  4916 solver.cpp:218] Iteration 52300 (20.3423 iter/s, 4.91586s/100 iters), loss = 0.0418239
I1001 10:02:33.595882  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418239 (* 1 = 0.0418239 loss)
I1001 10:02:33.595901  4916 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1001 10:02:38.441918  4916 solver.cpp:218] Iteration 52400 (20.6355 iter/s, 4.84602s/100 iters), loss = 0.0506923
I1001 10:02:38.441963  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0506924 (* 1 = 0.0506924 loss)
I1001 10:02:38.441972  4916 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1001 10:02:43.062258  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:02:43.255379  4916 solver.cpp:330] Iteration 52500, Testing net (#0)
I1001 10:02:44.336766  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:02:44.385732  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9001
I1001 10:02:44.385762  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334972 (* 1 = 0.334972 loss)
I1001 10:02:44.436017  4916 solver.cpp:218] Iteration 52500 (16.6834 iter/s, 5.994s/100 iters), loss = 0.0560079
I1001 10:02:44.436070  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056008 (* 1 = 0.056008 loss)
I1001 10:02:44.436089  4916 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1001 10:02:49.274832  4916 solver.cpp:218] Iteration 52600 (20.6666 iter/s, 4.83872s/100 iters), loss = 0.0285609
I1001 10:02:49.274863  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028561 (* 1 = 0.028561 loss)
I1001 10:02:49.274868  4916 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1001 10:02:54.142380  4916 solver.cpp:218] Iteration 52700 (20.5445 iter/s, 4.86749s/100 iters), loss = 0.0816983
I1001 10:02:54.142432  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816984 (* 1 = 0.0816984 loss)
I1001 10:02:54.142439  4916 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1001 10:02:59.002704  4916 solver.cpp:218] Iteration 52800 (20.575 iter/s, 4.86026s/100 iters), loss = 0.0568431
I1001 10:02:59.002745  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568433 (* 1 = 0.0568433 loss)
I1001 10:02:59.002751  4916 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1001 10:03:03.902029  4916 solver.cpp:218] Iteration 52900 (20.4112 iter/s, 4.89926s/100 iters), loss = 0.0269967
I1001 10:03:03.902148  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269968 (* 1 = 0.0269968 loss)
I1001 10:03:03.902154  4916 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1001 10:03:08.549027  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:03:08.745869  4916 solver.cpp:330] Iteration 53000, Testing net (#0)
I1001 10:03:09.847668  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:03:09.893095  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8991
I1001 10:03:09.893121  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326925 (* 1 = 0.326925 loss)
I1001 10:03:09.943048  4916 solver.cpp:218] Iteration 53000 (16.5539 iter/s, 6.04088s/100 iters), loss = 0.0183313
I1001 10:03:09.943105  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183314 (* 1 = 0.0183314 loss)
I1001 10:03:09.943125  4916 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1001 10:03:14.784844  4916 solver.cpp:218] Iteration 53100 (20.6554 iter/s, 4.84134s/100 iters), loss = 0.0550479
I1001 10:03:14.784878  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055048 (* 1 = 0.055048 loss)
I1001 10:03:14.784888  4916 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1001 10:03:19.592985  4916 solver.cpp:218] Iteration 53200 (20.7983 iter/s, 4.80808s/100 iters), loss = 0.0412016
I1001 10:03:19.593019  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412017 (* 1 = 0.0412017 loss)
I1001 10:03:19.593037  4916 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1001 10:03:24.415745  4916 solver.cpp:218] Iteration 53300 (20.7352 iter/s, 4.82271s/100 iters), loss = 0.0491009
I1001 10:03:24.415779  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491009 (* 1 = 0.0491009 loss)
I1001 10:03:24.415798  4916 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1001 10:03:29.234781  4916 solver.cpp:218] Iteration 53400 (20.7513 iter/s, 4.81898s/100 iters), loss = 0.024416
I1001 10:03:29.234823  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244161 (* 1 = 0.0244161 loss)
I1001 10:03:29.234843  4916 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1001 10:03:33.809507  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:03:34.002631  4916 solver.cpp:330] Iteration 53500, Testing net (#0)
I1001 10:03:35.077569  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:03:35.122958  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8996
I1001 10:03:35.122985  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347136 (* 1 = 0.347136 loss)
I1001 10:03:35.171473  4916 solver.cpp:218] Iteration 53500 (16.8452 iter/s, 5.93642s/100 iters), loss = 0.0154666
I1001 10:03:35.171512  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154666 (* 1 = 0.0154666 loss)
I1001 10:03:35.171533  4916 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1001 10:03:39.991981  4916 solver.cpp:218] Iteration 53600 (20.745 iter/s, 4.82045s/100 iters), loss = 0.0217315
I1001 10:03:39.992015  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217315 (* 1 = 0.0217315 loss)
I1001 10:03:39.992033  4916 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1001 10:03:44.805485  4916 solver.cpp:218] Iteration 53700 (20.7751 iter/s, 4.81345s/100 iters), loss = 0.0122855
I1001 10:03:44.805519  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122856 (* 1 = 0.0122856 loss)
I1001 10:03:44.805539  4916 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1001 10:03:49.605598  4916 solver.cpp:218] Iteration 53800 (20.8331 iter/s, 4.80006s/100 iters), loss = 0.0355666
I1001 10:03:49.605633  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355667 (* 1 = 0.0355667 loss)
I1001 10:03:49.605641  4916 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1001 10:03:54.427384  4916 solver.cpp:218] Iteration 53900 (20.7394 iter/s, 4.82173s/100 iters), loss = 0.0389635
I1001 10:03:54.427418  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389636 (* 1 = 0.0389636 loss)
I1001 10:03:54.427428  4916 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1001 10:03:58.996853  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:03:59.189929  4916 solver.cpp:330] Iteration 54000, Testing net (#0)
I1001 10:04:00.273048  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:04:00.318490  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8993
I1001 10:04:00.318516  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338383 (* 1 = 0.338383 loss)
I1001 10:04:00.367507  4916 solver.cpp:218] Iteration 54000 (16.8348 iter/s, 5.94007s/100 iters), loss = 0.0200803
I1001 10:04:00.367535  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200804 (* 1 = 0.0200804 loss)
I1001 10:04:00.367544  4916 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1001 10:04:05.182790  4916 solver.cpp:218] Iteration 54100 (20.7674 iter/s, 4.81523s/100 iters), loss = 0.0804165
I1001 10:04:05.182960  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0804166 (* 1 = 0.0804166 loss)
I1001 10:04:05.182986  4916 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1001 10:04:10.007385  4916 solver.cpp:218] Iteration 54200 (20.7279 iter/s, 4.82441s/100 iters), loss = 0.0306885
I1001 10:04:10.007419  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306886 (* 1 = 0.0306886 loss)
I1001 10:04:10.007439  4916 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1001 10:04:14.829224  4916 solver.cpp:218] Iteration 54300 (20.7392 iter/s, 4.82179s/100 iters), loss = 0.0466491
I1001 10:04:14.829258  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466492 (* 1 = 0.0466492 loss)
I1001 10:04:14.829277  4916 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1001 10:04:19.639200  4916 solver.cpp:218] Iteration 54400 (20.7904 iter/s, 4.80992s/100 iters), loss = 0.0190892
I1001 10:04:19.639232  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190893 (* 1 = 0.0190893 loss)
I1001 10:04:19.639251  4916 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1001 10:04:24.220795  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:04:24.413290  4916 solver.cpp:330] Iteration 54500, Testing net (#0)
I1001 10:04:25.487545  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:04:25.533123  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8954
I1001 10:04:25.533149  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358677 (* 1 = 0.358677 loss)
I1001 10:04:25.581641  4916 solver.cpp:218] Iteration 54500 (16.8282 iter/s, 5.94239s/100 iters), loss = 0.0118364
I1001 10:04:25.581667  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118364 (* 1 = 0.0118364 loss)
I1001 10:04:25.581676  4916 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1001 10:04:30.395196  4916 solver.cpp:218] Iteration 54600 (20.7749 iter/s, 4.81351s/100 iters), loss = 0.0592734
I1001 10:04:30.395228  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0592734 (* 1 = 0.0592734 loss)
I1001 10:04:30.395236  4916 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1001 10:04:35.208783  4916 solver.cpp:218] Iteration 54700 (20.7748 iter/s, 4.81353s/100 iters), loss = 0.15883
I1001 10:04:35.208889  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15883 (* 1 = 0.15883 loss)
I1001 10:04:35.208906  4916 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1001 10:04:40.022114  4916 solver.cpp:218] Iteration 54800 (20.7763 iter/s, 4.81318s/100 iters), loss = 0.0250174
I1001 10:04:40.022156  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250174 (* 1 = 0.0250174 loss)
I1001 10:04:40.022162  4916 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1001 10:04:44.842288  4916 solver.cpp:218] Iteration 54900 (20.7464 iter/s, 4.82011s/100 iters), loss = 0.0839519
I1001 10:04:44.842329  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.083952 (* 1 = 0.083952 loss)
I1001 10:04:44.842335  4916 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1001 10:04:49.417356  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:04:49.609906  4916 solver.cpp:330] Iteration 55000, Testing net (#0)
I1001 10:04:50.694329  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:04:50.739728  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I1001 10:04:50.739763  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321667 (* 1 = 0.321667 loss)
I1001 10:04:50.788503  4916 solver.cpp:218] Iteration 55000 (16.8176 iter/s, 5.94616s/100 iters), loss = 0.0259433
I1001 10:04:50.788537  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259434 (* 1 = 0.0259434 loss)
I1001 10:04:50.788543  4916 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1001 10:04:55.602885  4916 solver.cpp:218] Iteration 55100 (20.7713 iter/s, 4.81433s/100 iters), loss = 0.0264712
I1001 10:04:55.602926  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264713 (* 1 = 0.0264713 loss)
I1001 10:04:55.602931  4916 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1001 10:05:00.428069  4916 solver.cpp:218] Iteration 55200 (20.7249 iter/s, 4.82512s/100 iters), loss = 0.0410862
I1001 10:05:00.428114  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410863 (* 1 = 0.0410863 loss)
I1001 10:05:00.428131  4916 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1001 10:05:05.241199  4916 solver.cpp:218] Iteration 55300 (20.7768 iter/s, 4.81307s/100 iters), loss = 0.0768761
I1001 10:05:05.241376  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0768761 (* 1 = 0.0768761 loss)
I1001 10:05:05.241395  4916 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1001 10:05:10.065068  4916 solver.cpp:218] Iteration 55400 (20.7313 iter/s, 4.82363s/100 iters), loss = 0.0134469
I1001 10:05:10.065109  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013447 (* 1 = 0.013447 loss)
I1001 10:05:10.065115  4916 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1001 10:05:14.647886  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:05:14.840486  4916 solver.cpp:330] Iteration 55500, Testing net (#0)
I1001 10:05:15.914950  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:05:15.960485  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8961
I1001 10:05:15.960520  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35331 (* 1 = 0.35331 loss)
I1001 10:05:16.009413  4916 solver.cpp:218] Iteration 55500 (16.8229 iter/s, 5.94429s/100 iters), loss = 0.0360638
I1001 10:05:16.009438  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360639 (* 1 = 0.0360639 loss)
I1001 10:05:16.009444  4916 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1001 10:05:20.826251  4916 solver.cpp:218] Iteration 55600 (20.7607 iter/s, 4.81679s/100 iters), loss = 0.0479779
I1001 10:05:20.826292  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047978 (* 1 = 0.047978 loss)
I1001 10:05:20.826297  4916 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1001 10:05:25.636626  4916 solver.cpp:218] Iteration 55700 (20.7887 iter/s, 4.81031s/100 iters), loss = 0.0928153
I1001 10:05:25.636656  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0928154 (* 1 = 0.0928154 loss)
I1001 10:05:25.636662  4916 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1001 10:05:30.453544  4916 solver.cpp:218] Iteration 55800 (20.7604 iter/s, 4.81687s/100 iters), loss = 0.0365496
I1001 10:05:30.453577  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365496 (* 1 = 0.0365496 loss)
I1001 10:05:30.453593  4916 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1001 10:05:35.267710  4916 solver.cpp:218] Iteration 55900 (20.7723 iter/s, 4.81411s/100 iters), loss = 0.0312174
I1001 10:05:35.267825  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312174 (* 1 = 0.0312174 loss)
I1001 10:05:35.267834  4916 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1001 10:05:39.845603  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:05:40.037909  4916 solver.cpp:330] Iteration 56000, Testing net (#0)
I1001 10:05:41.111420  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:05:41.157027  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1001 10:05:41.157063  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324423 (* 1 = 0.324423 loss)
I1001 10:05:41.206243  4916 solver.cpp:218] Iteration 56000 (16.8397 iter/s, 5.93836s/100 iters), loss = 0.0354468
I1001 10:05:41.206288  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354468 (* 1 = 0.0354468 loss)
I1001 10:05:41.206295  4916 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1001 10:05:46.027642  4916 solver.cpp:218] Iteration 56100 (20.7413 iter/s, 4.8213s/100 iters), loss = 0.0331577
I1001 10:05:46.027683  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331578 (* 1 = 0.0331578 loss)
I1001 10:05:46.027689  4916 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1001 10:05:50.849820  4916 solver.cpp:218] Iteration 56200 (20.7378 iter/s, 4.82211s/100 iters), loss = 0.0159019
I1001 10:05:50.849850  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159019 (* 1 = 0.0159019 loss)
I1001 10:05:50.849856  4916 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1001 10:05:55.661852  4916 solver.cpp:218] Iteration 56300 (20.7815 iter/s, 4.81198s/100 iters), loss = 0.0356476
I1001 10:05:55.661891  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356477 (* 1 = 0.0356477 loss)
I1001 10:05:55.661897  4916 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1001 10:06:00.483680  4916 solver.cpp:218] Iteration 56400 (20.7393 iter/s, 4.82176s/100 iters), loss = 0.0124548
I1001 10:06:00.483721  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124549 (* 1 = 0.0124549 loss)
I1001 10:06:00.483726  4916 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1001 10:06:05.059106  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:06:05.252429  4916 solver.cpp:330] Iteration 56500, Testing net (#0)
I1001 10:06:06.331224  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:06:06.376905  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8997
I1001 10:06:06.376940  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353378 (* 1 = 0.353378 loss)
I1001 10:06:06.425664  4916 solver.cpp:218] Iteration 56500 (16.8295 iter/s, 5.94193s/100 iters), loss = 0.0340247
I1001 10:06:06.425689  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340248 (* 1 = 0.0340248 loss)
I1001 10:06:06.425695  4916 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1001 10:06:11.233569  4916 solver.cpp:218] Iteration 56600 (20.7993 iter/s, 4.80786s/100 iters), loss = 0.0360616
I1001 10:06:11.233603  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360617 (* 1 = 0.0360617 loss)
I1001 10:06:11.233610  4916 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1001 10:06:16.089071  4916 solver.cpp:218] Iteration 56700 (20.5954 iter/s, 4.85544s/100 iters), loss = 0.021584
I1001 10:06:16.089104  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215841 (* 1 = 0.0215841 loss)
I1001 10:06:16.089113  4916 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1001 10:06:20.916069  4916 solver.cpp:218] Iteration 56800 (20.7172 iter/s, 4.82691s/100 iters), loss = 0.0267098
I1001 10:06:20.916105  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267099 (* 1 = 0.0267099 loss)
I1001 10:06:20.916113  4916 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1001 10:06:25.731535  4916 solver.cpp:218] Iteration 56900 (20.7667 iter/s, 4.81541s/100 iters), loss = 0.0357241
I1001 10:06:25.731567  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357242 (* 1 = 0.0357242 loss)
I1001 10:06:25.731573  4916 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1001 10:06:30.314515  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:06:30.507279  4916 solver.cpp:330] Iteration 57000, Testing net (#0)
I1001 10:06:31.582329  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:06:31.628059  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8999
I1001 10:06:31.628085  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34756 (* 1 = 0.34756 loss)
I1001 10:06:31.676805  4916 solver.cpp:218] Iteration 57000 (16.8203 iter/s, 5.94521s/100 iters), loss = 0.0634542
I1001 10:06:31.676832  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0634543 (* 1 = 0.0634543 loss)
I1001 10:06:31.676839  4916 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1001 10:06:36.499264  4916 solver.cpp:218] Iteration 57100 (20.7365 iter/s, 4.82241s/100 iters), loss = 0.0241842
I1001 10:06:36.499387  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241843 (* 1 = 0.0241843 loss)
I1001 10:06:36.499393  4916 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1001 10:06:41.317284  4916 solver.cpp:218] Iteration 57200 (20.756 iter/s, 4.81788s/100 iters), loss = 0.0274032
I1001 10:06:41.317320  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274033 (* 1 = 0.0274033 loss)
I1001 10:06:41.317327  4916 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1001 10:06:46.135723  4916 solver.cpp:218] Iteration 57300 (20.7539 iter/s, 4.81838s/100 iters), loss = 0.0542069
I1001 10:06:46.135763  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054207 (* 1 = 0.054207 loss)
I1001 10:06:46.135769  4916 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1001 10:06:50.956408  4916 solver.cpp:218] Iteration 57400 (20.7444 iter/s, 4.82059s/100 iters), loss = 0.0395734
I1001 10:06:50.956439  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395735 (* 1 = 0.0395735 loss)
I1001 10:06:50.956444  4916 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1001 10:06:55.526051  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:06:55.718518  4916 solver.cpp:330] Iteration 57500, Testing net (#0)
I1001 10:06:56.800189  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:06:56.846067  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.901
I1001 10:06:56.846093  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352325 (* 1 = 0.352325 loss)
I1001 10:06:56.895154  4916 solver.cpp:218] Iteration 57500 (16.8388 iter/s, 5.93866s/100 iters), loss = 0.0608294
I1001 10:06:56.895180  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0608295 (* 1 = 0.0608295 loss)
I1001 10:06:56.895186  4916 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1001 10:07:01.710777  4916 solver.cpp:218] Iteration 57600 (20.766 iter/s, 4.81558s/100 iters), loss = 0.0295192
I1001 10:07:01.710808  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295193 (* 1 = 0.0295193 loss)
I1001 10:07:01.710824  4916 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1001 10:07:06.529934  4916 solver.cpp:218] Iteration 57700 (20.7507 iter/s, 4.81911s/100 iters), loss = 0.0416007
I1001 10:07:06.530093  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416007 (* 1 = 0.0416007 loss)
I1001 10:07:06.530112  4916 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1001 10:07:11.347761  4916 solver.cpp:218] Iteration 57800 (20.757 iter/s, 4.81765s/100 iters), loss = 0.0243274
I1001 10:07:11.347808  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243275 (* 1 = 0.0243275 loss)
I1001 10:07:11.347816  4916 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1001 10:07:16.163022  4916 solver.cpp:218] Iteration 57900 (20.7685 iter/s, 4.81499s/100 iters), loss = 0.0234915
I1001 10:07:16.163053  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234916 (* 1 = 0.0234916 loss)
I1001 10:07:16.163058  4916 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1001 10:07:20.750579  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:07:20.942840  4916 solver.cpp:330] Iteration 58000, Testing net (#0)
I1001 10:07:22.018823  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:07:22.064195  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8981
I1001 10:07:22.064231  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370332 (* 1 = 0.370332 loss)
I1001 10:07:22.112829  4916 solver.cpp:218] Iteration 58000 (16.8074 iter/s, 5.94976s/100 iters), loss = 0.0709462
I1001 10:07:22.112857  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0709463 (* 1 = 0.0709463 loss)
I1001 10:07:22.112865  4916 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1001 10:07:26.937196  4916 solver.cpp:218] Iteration 58100 (20.7283 iter/s, 4.82432s/100 iters), loss = 0.0547402
I1001 10:07:26.937235  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0547403 (* 1 = 0.0547403 loss)
I1001 10:07:26.937242  4916 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1001 10:07:31.753015  4916 solver.cpp:218] Iteration 58200 (20.7652 iter/s, 4.81576s/100 iters), loss = 0.0322499
I1001 10:07:31.753046  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03225 (* 1 = 0.03225 loss)
I1001 10:07:31.753062  4916 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1001 10:07:36.576618  4916 solver.cpp:218] Iteration 58300 (20.7316 iter/s, 4.82355s/100 iters), loss = 0.0361376
I1001 10:07:36.576766  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361377 (* 1 = 0.0361377 loss)
I1001 10:07:36.576774  4916 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1001 10:07:41.395308  4916 solver.cpp:218] Iteration 58400 (20.7533 iter/s, 4.81852s/100 iters), loss = 0.0300446
I1001 10:07:41.395344  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300447 (* 1 = 0.0300447 loss)
I1001 10:07:41.395351  4916 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1001 10:07:45.970347  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:07:46.163094  4916 solver.cpp:330] Iteration 58500, Testing net (#0)
I1001 10:07:47.238265  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:07:47.284400  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9007
I1001 10:07:47.284428  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35606 (* 1 = 0.35606 loss)
I1001 10:07:47.334213  4916 solver.cpp:218] Iteration 58500 (16.8383 iter/s, 5.93885s/100 iters), loss = 0.0197562
I1001 10:07:47.334259  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197563 (* 1 = 0.0197563 loss)
I1001 10:07:47.334265  4916 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1001 10:07:52.153884  4916 solver.cpp:218] Iteration 58600 (20.7487 iter/s, 4.81957s/100 iters), loss = 0.0488766
I1001 10:07:52.153924  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488767 (* 1 = 0.0488767 loss)
I1001 10:07:52.153931  4916 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1001 10:07:56.979254  4916 solver.cpp:218] Iteration 58700 (20.7241 iter/s, 4.8253s/100 iters), loss = 0.0470486
I1001 10:07:56.979295  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0470487 (* 1 = 0.0470487 loss)
I1001 10:07:56.979301  4916 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1001 10:08:01.794128  4916 solver.cpp:218] Iteration 58800 (20.7693 iter/s, 4.81481s/100 iters), loss = 0.0230439
I1001 10:08:01.794175  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023044 (* 1 = 0.023044 loss)
I1001 10:08:01.794183  4916 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1001 10:08:06.625934  4916 solver.cpp:218] Iteration 58900 (20.6965 iter/s, 4.83174s/100 iters), loss = 0.0269993
I1001 10:08:06.626049  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269994 (* 1 = 0.0269994 loss)
I1001 10:08:06.626066  4916 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1001 10:08:11.202074  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:08:11.401386  4916 solver.cpp:330] Iteration 59000, Testing net (#0)
I1001 10:08:12.479317  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:08:12.524709  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8989
I1001 10:08:12.524734  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360229 (* 1 = 0.360229 loss)
I1001 10:08:12.573251  4916 solver.cpp:218] Iteration 59000 (16.8147 iter/s, 5.94718s/100 iters), loss = 0.0412873
I1001 10:08:12.573276  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412874 (* 1 = 0.0412874 loss)
I1001 10:08:12.573283  4916 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1001 10:08:17.391883  4916 solver.cpp:218] Iteration 59100 (20.753 iter/s, 4.81858s/100 iters), loss = 0.04698
I1001 10:08:17.391927  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469801 (* 1 = 0.0469801 loss)
I1001 10:08:17.391945  4916 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1001 10:08:22.212288  4916 solver.cpp:218] Iteration 59200 (20.7457 iter/s, 4.82028s/100 iters), loss = 0.0495597
I1001 10:08:22.212329  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0495597 (* 1 = 0.0495597 loss)
I1001 10:08:22.212337  4916 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1001 10:08:27.035825  4916 solver.cpp:218] Iteration 59300 (20.732 iter/s, 4.82347s/100 iters), loss = 0.0380019
I1001 10:08:27.035856  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.038002 (* 1 = 0.038002 loss)
I1001 10:08:27.035863  4916 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1001 10:08:31.848322  4916 solver.cpp:218] Iteration 59400 (20.7795 iter/s, 4.81244s/100 iters), loss = 0.0472628
I1001 10:08:31.848352  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0472629 (* 1 = 0.0472629 loss)
I1001 10:08:31.848358  4916 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1001 10:08:36.423391  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:08:36.614784  4916 solver.cpp:330] Iteration 59500, Testing net (#0)
I1001 10:08:37.690408  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:08:37.735782  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1001 10:08:37.735817  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336434 (* 1 = 0.336434 loss)
I1001 10:08:37.784482  4916 solver.cpp:218] Iteration 59500 (16.8461 iter/s, 5.9361s/100 iters), loss = 0.0610501
I1001 10:08:37.784510  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0610502 (* 1 = 0.0610502 loss)
I1001 10:08:37.784518  4916 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1001 10:08:42.602653  4916 solver.cpp:218] Iteration 59600 (20.755 iter/s, 4.81812s/100 iters), loss = 0.0446917
I1001 10:08:42.602692  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446918 (* 1 = 0.0446918 loss)
I1001 10:08:42.602697  4916 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1001 10:08:47.421352  4916 solver.cpp:218] Iteration 59700 (20.7528 iter/s, 4.81864s/100 iters), loss = 0.0350685
I1001 10:08:47.421399  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350685 (* 1 = 0.0350685 loss)
I1001 10:08:47.421406  4916 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1001 10:08:52.236585  4916 solver.cpp:218] Iteration 59800 (20.7678 iter/s, 4.81514s/100 iters), loss = 0.0220261
I1001 10:08:52.236627  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220262 (* 1 = 0.0220262 loss)
I1001 10:08:52.236634  4916 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1001 10:08:57.062081  4916 solver.cpp:218] Iteration 59900 (20.7235 iter/s, 4.82543s/100 iters), loss = 0.0974206
I1001 10:08:57.062110  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0974206 (* 1 = 0.0974206 loss)
I1001 10:08:57.062117  4916 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1001 10:09:01.639737  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:09:01.832762  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_60000.caffemodel
I1001 10:09:01.837090  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_60000.solverstate
I1001 10:09:01.838351  4916 solver.cpp:330] Iteration 60000, Testing net (#0)
I1001 10:09:02.924763  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:09:02.970396  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9055
I1001 10:09:02.970430  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33825 (* 1 = 0.33825 loss)
I1001 10:09:03.019219  4916 solver.cpp:218] Iteration 60000 (16.7867 iter/s, 5.95709s/100 iters), loss = 0.0376635
I1001 10:09:03.019244  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376636 (* 1 = 0.0376636 loss)
I1001 10:09:03.019251  4916 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1001 10:09:07.833937  4916 solver.cpp:218] Iteration 60100 (20.7698 iter/s, 4.81467s/100 iters), loss = 0.0277726
I1001 10:09:07.834043  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277726 (* 1 = 0.0277726 loss)
I1001 10:09:07.834051  4916 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1001 10:09:12.657680  4916 solver.cpp:218] Iteration 60200 (20.7313 iter/s, 4.82363s/100 iters), loss = 0.0200702
I1001 10:09:12.657711  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200702 (* 1 = 0.0200702 loss)
I1001 10:09:12.657716  4916 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1001 10:09:17.472338  4916 solver.cpp:218] Iteration 60300 (20.7701 iter/s, 4.81461s/100 iters), loss = 0.0220686
I1001 10:09:17.472383  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220687 (* 1 = 0.0220687 loss)
I1001 10:09:17.472391  4916 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1001 10:09:22.290177  4916 solver.cpp:218] Iteration 60400 (20.7566 iter/s, 4.81774s/100 iters), loss = 0.0146399
I1001 10:09:22.290207  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01464 (* 1 = 0.01464 loss)
I1001 10:09:22.290213  4916 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1001 10:09:26.870805  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:09:27.063995  4916 solver.cpp:330] Iteration 60500, Testing net (#0)
I1001 10:09:28.140661  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:09:28.186437  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8956
I1001 10:09:28.186472  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37352 (* 1 = 0.37352 loss)
I1001 10:09:28.234735  4916 solver.cpp:218] Iteration 60500 (16.8224 iter/s, 5.94447s/100 iters), loss = 0.0396266
I1001 10:09:28.234761  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396267 (* 1 = 0.0396267 loss)
I1001 10:09:28.234768  4916 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1001 10:09:33.056406  4916 solver.cpp:218] Iteration 60600 (20.7399 iter/s, 4.82163s/100 iters), loss = 0.0434494
I1001 10:09:33.056449  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434495 (* 1 = 0.0434495 loss)
I1001 10:09:33.056455  4916 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1001 10:09:37.870061  4916 solver.cpp:218] Iteration 60700 (20.7745 iter/s, 4.8136s/100 iters), loss = 0.0454056
I1001 10:09:37.870199  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454057 (* 1 = 0.0454057 loss)
I1001 10:09:37.870220  4916 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1001 10:09:42.696705  4916 solver.cpp:218] Iteration 60800 (20.719 iter/s, 4.8265s/100 iters), loss = 0.025843
I1001 10:09:42.696744  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025843 (* 1 = 0.025843 loss)
I1001 10:09:42.696750  4916 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1001 10:09:47.572870  4916 solver.cpp:218] Iteration 60900 (20.5082 iter/s, 4.87611s/100 iters), loss = 0.00452611
I1001 10:09:47.572904  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452615 (* 1 = 0.00452615 loss)
I1001 10:09:47.572911  4916 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1001 10:09:52.172794  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:09:52.368206  4916 solver.cpp:330] Iteration 61000, Testing net (#0)
I1001 10:09:53.460232  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:09:53.505991  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9003
I1001 10:09:53.506017  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348763 (* 1 = 0.348763 loss)
I1001 10:09:53.555207  4916 solver.cpp:218] Iteration 61000 (16.716 iter/s, 5.98228s/100 iters), loss = 0.0298075
I1001 10:09:53.555239  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298075 (* 1 = 0.0298075 loss)
I1001 10:09:53.555246  4916 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1001 10:09:58.388828  4916 solver.cpp:218] Iteration 61100 (20.6886 iter/s, 4.83357s/100 iters), loss = 0.0198321
I1001 10:09:58.388867  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198321 (* 1 = 0.0198321 loss)
I1001 10:09:58.388875  4916 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1001 10:10:03.219594  4916 solver.cpp:218] Iteration 61200 (20.7009 iter/s, 4.83071s/100 iters), loss = 0.0243472
I1001 10:10:03.219635  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243473 (* 1 = 0.0243473 loss)
I1001 10:10:03.219641  4916 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1001 10:10:08.047920  4916 solver.cpp:218] Iteration 61300 (20.7114 iter/s, 4.82827s/100 iters), loss = 0.01175
I1001 10:10:08.048046  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01175 (* 1 = 0.01175 loss)
I1001 10:10:08.048054  4916 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1001 10:10:12.867617  4916 solver.cpp:218] Iteration 61400 (20.7488 iter/s, 4.81955s/100 iters), loss = 0.0301675
I1001 10:10:12.867646  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301675 (* 1 = 0.0301675 loss)
I1001 10:10:12.867662  4916 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1001 10:10:17.446310  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:10:17.642021  4916 solver.cpp:330] Iteration 61500, Testing net (#0)
I1001 10:10:18.717434  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:10:18.762796  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1001 10:10:18.762831  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347163 (* 1 = 0.347163 loss)
I1001 10:10:18.811550  4916 solver.cpp:218] Iteration 61500 (16.824 iter/s, 5.94388s/100 iters), loss = 0.00954013
I1001 10:10:18.811578  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00954016 (* 1 = 0.00954016 loss)
I1001 10:10:18.811583  4916 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1001 10:10:23.632815  4916 solver.cpp:218] Iteration 61600 (20.7417 iter/s, 4.82122s/100 iters), loss = 0.0507026
I1001 10:10:23.632846  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0507026 (* 1 = 0.0507026 loss)
I1001 10:10:23.632854  4916 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1001 10:10:28.448614  4916 solver.cpp:218] Iteration 61700 (20.7652 iter/s, 4.81575s/100 iters), loss = 0.0384802
I1001 10:10:28.448655  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384802 (* 1 = 0.0384802 loss)
I1001 10:10:28.448662  4916 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1001 10:10:33.276178  4916 solver.cpp:218] Iteration 61800 (20.7147 iter/s, 4.8275s/100 iters), loss = 0.0439317
I1001 10:10:33.276208  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439318 (* 1 = 0.0439318 loss)
I1001 10:10:33.276214  4916 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1001 10:10:38.087661  4916 solver.cpp:218] Iteration 61900 (20.7838 iter/s, 4.81143s/100 iters), loss = 0.0297728
I1001 10:10:38.087805  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297728 (* 1 = 0.0297728 loss)
I1001 10:10:38.087812  4916 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1001 10:10:42.671169  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:10:42.863323  4916 solver.cpp:330] Iteration 62000, Testing net (#0)
I1001 10:10:43.938100  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:10:43.983822  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.905
I1001 10:10:43.983847  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338109 (* 1 = 0.338109 loss)
I1001 10:10:44.032337  4916 solver.cpp:218] Iteration 62000 (16.8222 iter/s, 5.94451s/100 iters), loss = 0.0105901
I1001 10:10:44.032361  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105901 (* 1 = 0.0105901 loss)
I1001 10:10:44.032368  4916 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1001 10:10:48.854410  4916 solver.cpp:218] Iteration 62100 (20.7382 iter/s, 4.82203s/100 iters), loss = 0.0234318
I1001 10:10:48.854440  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234318 (* 1 = 0.0234318 loss)
I1001 10:10:48.854456  4916 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1001 10:10:53.675204  4916 solver.cpp:218] Iteration 62200 (20.7437 iter/s, 4.82074s/100 iters), loss = 0.017959
I1001 10:10:53.675235  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017959 (* 1 = 0.017959 loss)
I1001 10:10:53.675241  4916 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1001 10:10:58.487855  4916 solver.cpp:218] Iteration 62300 (20.7788 iter/s, 4.8126s/100 iters), loss = 0.0145569
I1001 10:10:58.487885  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145569 (* 1 = 0.0145569 loss)
I1001 10:10:58.487891  4916 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1001 10:11:03.311501  4916 solver.cpp:218] Iteration 62400 (20.7314 iter/s, 4.82359s/100 iters), loss = 0.0359058
I1001 10:11:03.311532  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359058 (* 1 = 0.0359058 loss)
I1001 10:11:03.311538  4916 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1001 10:11:07.884814  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:11:08.077193  4916 solver.cpp:330] Iteration 62500, Testing net (#0)
I1001 10:11:09.161108  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:11:09.206346  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8997
I1001 10:11:09.206382  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348997 (* 1 = 0.348997 loss)
I1001 10:11:09.254796  4916 solver.cpp:218] Iteration 62500 (16.8258 iter/s, 5.94324s/100 iters), loss = 0.0276775
I1001 10:11:09.254822  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276775 (* 1 = 0.0276775 loss)
I1001 10:11:09.254829  4916 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1001 10:11:14.067188  4916 solver.cpp:218] Iteration 62600 (20.7799 iter/s, 4.81234s/100 iters), loss = 0.0276581
I1001 10:11:14.067219  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276581 (* 1 = 0.0276581 loss)
I1001 10:11:14.067224  4916 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1001 10:11:18.887428  4916 solver.cpp:218] Iteration 62700 (20.7461 iter/s, 4.82019s/100 iters), loss = 0.0787682
I1001 10:11:18.887459  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0787682 (* 1 = 0.0787682 loss)
I1001 10:11:18.887473  4916 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1001 10:11:23.711025  4916 solver.cpp:218] Iteration 62800 (20.7316 iter/s, 4.82354s/100 iters), loss = 0.0153961
I1001 10:11:23.711060  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153961 (* 1 = 0.0153961 loss)
I1001 10:11:23.711066  4916 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1001 10:11:28.530596  4916 solver.cpp:218] Iteration 62900 (20.749 iter/s, 4.81951s/100 iters), loss = 0.0324125
I1001 10:11:28.530627  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324126 (* 1 = 0.0324126 loss)
I1001 10:11:28.530632  4916 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1001 10:11:33.116852  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:11:33.310093  4916 solver.cpp:330] Iteration 63000, Testing net (#0)
I1001 10:11:34.386184  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:11:34.431890  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1001 10:11:34.431924  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351194 (* 1 = 0.351194 loss)
I1001 10:11:34.480567  4916 solver.cpp:218] Iteration 63000 (16.807 iter/s, 5.94992s/100 iters), loss = 0.0143134
I1001 10:11:34.480593  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143134 (* 1 = 0.0143134 loss)
I1001 10:11:34.480600  4916 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1001 10:11:39.305131  4916 solver.cpp:218] Iteration 63100 (20.7275 iter/s, 4.82452s/100 iters), loss = 0.0487636
I1001 10:11:39.305279  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0487637 (* 1 = 0.0487637 loss)
I1001 10:11:39.305286  4916 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1001 10:11:44.125365  4916 solver.cpp:218] Iteration 63200 (20.7466 iter/s, 4.82007s/100 iters), loss = 0.0251375
I1001 10:11:44.125406  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251375 (* 1 = 0.0251375 loss)
I1001 10:11:44.125411  4916 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1001 10:11:48.944622  4916 solver.cpp:218] Iteration 63300 (20.7504 iter/s, 4.81919s/100 iters), loss = 0.0320366
I1001 10:11:48.944675  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320366 (* 1 = 0.0320366 loss)
I1001 10:11:48.944696  4916 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1001 10:11:53.768200  4916 solver.cpp:218] Iteration 63400 (20.7322 iter/s, 4.82342s/100 iters), loss = 0.0142127
I1001 10:11:53.768234  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142127 (* 1 = 0.0142127 loss)
I1001 10:11:53.768240  4916 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1001 10:11:58.344571  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:11:58.537518  4916 solver.cpp:330] Iteration 63500, Testing net (#0)
I1001 10:11:59.624766  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:11:59.670606  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8969
I1001 10:11:59.670642  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379334 (* 1 = 0.379334 loss)
I1001 10:11:59.719164  4916 solver.cpp:218] Iteration 63500 (16.8041 iter/s, 5.95091s/100 iters), loss = 0.0211554
I1001 10:11:59.719194  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211554 (* 1 = 0.0211554 loss)
I1001 10:11:59.719200  4916 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1001 10:12:04.535416  4916 solver.cpp:218] Iteration 63600 (20.7633 iter/s, 4.8162s/100 iters), loss = 0.0409029
I1001 10:12:04.535446  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409029 (* 1 = 0.0409029 loss)
I1001 10:12:04.535451  4916 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1001 10:12:09.362911  4916 solver.cpp:218] Iteration 63700 (20.7149 iter/s, 4.82745s/100 iters), loss = 0.0609155
I1001 10:12:09.363096  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0609155 (* 1 = 0.0609155 loss)
I1001 10:12:09.363106  4916 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1001 10:12:14.181380  4916 solver.cpp:218] Iteration 63800 (20.7544 iter/s, 4.81827s/100 iters), loss = 0.0158931
I1001 10:12:14.181421  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158931 (* 1 = 0.0158931 loss)
I1001 10:12:14.181427  4916 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1001 10:12:19.005453  4916 solver.cpp:218] Iteration 63900 (20.7298 iter/s, 4.82398s/100 iters), loss = 0.0120149
I1001 10:12:19.005483  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120148 (* 1 = 0.0120148 loss)
I1001 10:12:19.005489  4916 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1001 10:12:23.586634  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:12:23.779072  4916 solver.cpp:330] Iteration 64000, Testing net (#0)
I1001 10:12:24.853920  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:12:24.899524  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9022
I1001 10:12:24.899560  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375911 (* 1 = 0.375911 loss)
I1001 10:12:24.948527  4916 solver.cpp:218] Iteration 64000 (16.8265 iter/s, 5.94302s/100 iters), loss = 0.0206974
I1001 10:12:24.948555  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206973 (* 1 = 0.0206973 loss)
I1001 10:12:24.948572  4916 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1001 10:12:29.767345  4916 solver.cpp:218] Iteration 64100 (20.7522 iter/s, 4.81877s/100 iters), loss = 0.0181382
I1001 10:12:29.767376  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181382 (* 1 = 0.0181382 loss)
I1001 10:12:29.767382  4916 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1001 10:12:34.582631  4916 solver.cpp:218] Iteration 64200 (20.7674 iter/s, 4.81523s/100 iters), loss = 0.065114
I1001 10:12:34.582671  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.065114 (* 1 = 0.065114 loss)
I1001 10:12:34.582677  4916 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1001 10:12:39.403237  4916 solver.cpp:218] Iteration 64300 (20.7445 iter/s, 4.82054s/100 iters), loss = 0.0415824
I1001 10:12:39.403463  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0415824 (* 1 = 0.0415824 loss)
I1001 10:12:39.403483  4916 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1001 10:12:44.214859  4916 solver.cpp:218] Iteration 64400 (20.7845 iter/s, 4.81128s/100 iters), loss = 0.0176486
I1001 10:12:44.214889  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176486 (* 1 = 0.0176486 loss)
I1001 10:12:44.214895  4916 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1001 10:12:48.797379  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:12:48.990651  4916 solver.cpp:330] Iteration 64500, Testing net (#0)
I1001 10:12:50.066009  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:12:50.111491  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9011
I1001 10:12:50.111526  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364294 (* 1 = 0.364294 loss)
I1001 10:12:50.160349  4916 solver.cpp:218] Iteration 64500 (16.8196 iter/s, 5.94544s/100 iters), loss = 0.061644
I1001 10:12:50.160374  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061644 (* 1 = 0.061644 loss)
I1001 10:12:50.160380  4916 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1001 10:12:54.987475  4916 solver.cpp:218] Iteration 64600 (20.7165 iter/s, 4.82708s/100 iters), loss = 0.0133835
I1001 10:12:54.987509  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133835 (* 1 = 0.0133835 loss)
I1001 10:12:54.987515  4916 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1001 10:12:59.809423  4916 solver.cpp:218] Iteration 64700 (20.7387 iter/s, 4.8219s/100 iters), loss = 0.0119308
I1001 10:12:59.809453  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119307 (* 1 = 0.0119307 loss)
I1001 10:12:59.809458  4916 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1001 10:13:04.621549  4916 solver.cpp:218] Iteration 64800 (20.7811 iter/s, 4.81207s/100 iters), loss = 0.0660979
I1001 10:13:04.621582  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660979 (* 1 = 0.0660979 loss)
I1001 10:13:04.621590  4916 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1001 10:13:09.444967  4916 solver.cpp:218] Iteration 64900 (20.7324 iter/s, 4.82337s/100 iters), loss = 0.0347933
I1001 10:13:09.445070  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347934 (* 1 = 0.0347934 loss)
I1001 10:13:09.445077  4916 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1001 10:13:14.020975  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:13:14.214179  4916 solver.cpp:330] Iteration 65000, Testing net (#0)
I1001 10:13:15.296396  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:13:15.341523  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I1001 10:13:15.341559  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.407001 (* 1 = 0.407001 loss)
I1001 10:13:15.390046  4916 solver.cpp:218] Iteration 65000 (16.821 iter/s, 5.94496s/100 iters), loss = 0.0317799
I1001 10:13:15.390071  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317799 (* 1 = 0.0317799 loss)
I1001 10:13:15.390079  4916 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1001 10:13:20.206509  4916 solver.cpp:218] Iteration 65100 (20.7623 iter/s, 4.81642s/100 iters), loss = 0.0508337
I1001 10:13:20.206542  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508337 (* 1 = 0.0508337 loss)
I1001 10:13:20.206557  4916 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1001 10:13:25.026110  4916 solver.cpp:218] Iteration 65200 (20.7489 iter/s, 4.81953s/100 iters), loss = 0.0827667
I1001 10:13:25.026140  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0827667 (* 1 = 0.0827667 loss)
I1001 10:13:25.026156  4916 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1001 10:13:29.846091  4916 solver.cpp:218] Iteration 65300 (20.7472 iter/s, 4.81993s/100 iters), loss = 0.0248578
I1001 10:13:29.846127  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248578 (* 1 = 0.0248578 loss)
I1001 10:13:29.846148  4916 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1001 10:13:34.662025  4916 solver.cpp:218] Iteration 65400 (20.7652 iter/s, 4.81575s/100 iters), loss = 0.0437426
I1001 10:13:34.662055  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437426 (* 1 = 0.0437426 loss)
I1001 10:13:34.662061  4916 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1001 10:13:39.246002  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:13:39.439332  4916 solver.cpp:330] Iteration 65500, Testing net (#0)
I1001 10:13:40.515039  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:13:40.560658  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9009
I1001 10:13:40.560693  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37598 (* 1 = 0.37598 loss)
I1001 10:13:40.609216  4916 solver.cpp:218] Iteration 65500 (16.8148 iter/s, 5.94714s/100 iters), loss = 0.00905231
I1001 10:13:40.609242  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090523 (* 1 = 0.0090523 loss)
I1001 10:13:40.609249  4916 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1001 10:13:45.436481  4916 solver.cpp:218] Iteration 65600 (20.7159 iter/s, 4.82721s/100 iters), loss = 0.0378736
I1001 10:13:45.436529  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0378736 (* 1 = 0.0378736 loss)
I1001 10:13:45.436535  4916 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1001 10:13:50.247663  4916 solver.cpp:218] Iteration 65700 (20.7852 iter/s, 4.81111s/100 iters), loss = 0.0312265
I1001 10:13:50.247731  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312265 (* 1 = 0.0312265 loss)
I1001 10:13:50.247741  4916 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1001 10:13:55.073400  4916 solver.cpp:218] Iteration 65800 (20.7226 iter/s, 4.82565s/100 iters), loss = 0.0347759
I1001 10:13:55.073442  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347759 (* 1 = 0.0347759 loss)
I1001 10:13:55.073458  4916 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1001 10:13:59.901027  4916 solver.cpp:218] Iteration 65900 (20.7144 iter/s, 4.82756s/100 iters), loss = 0.0108133
I1001 10:13:59.901058  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108133 (* 1 = 0.0108133 loss)
I1001 10:13:59.901064  4916 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1001 10:14:04.472522  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:14:04.664858  4916 solver.cpp:330] Iteration 66000, Testing net (#0)
I1001 10:14:05.748224  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:14:05.793926  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8974
I1001 10:14:05.793951  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380801 (* 1 = 0.380801 loss)
I1001 10:14:05.842895  4916 solver.cpp:218] Iteration 66000 (16.8299 iter/s, 5.94181s/100 iters), loss = 0.0464509
I1001 10:14:05.842923  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464508 (* 1 = 0.0464508 loss)
I1001 10:14:05.842929  4916 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1001 10:14:10.655911  4916 solver.cpp:218] Iteration 66100 (20.7772 iter/s, 4.81297s/100 iters), loss = 0.0120287
I1001 10:14:10.656024  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120287 (* 1 = 0.0120287 loss)
I1001 10:14:10.656041  4916 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1001 10:14:15.456987  4916 solver.cpp:218] Iteration 66200 (20.8292 iter/s, 4.80095s/100 iters), loss = 0.0318362
I1001 10:14:15.457018  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318361 (* 1 = 0.0318361 loss)
I1001 10:14:15.457024  4916 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1001 10:14:20.270212  4916 solver.cpp:218] Iteration 66300 (20.7763 iter/s, 4.81317s/100 iters), loss = 0.031542
I1001 10:14:20.270246  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031542 (* 1 = 0.031542 loss)
I1001 10:14:20.270254  4916 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1001 10:14:25.095650  4916 solver.cpp:218] Iteration 66400 (20.7238 iter/s, 4.82538s/100 iters), loss = 0.0148738
I1001 10:14:25.095680  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148738 (* 1 = 0.0148738 loss)
I1001 10:14:25.095686  4916 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1001 10:14:29.681470  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:14:29.872869  4916 solver.cpp:330] Iteration 66500, Testing net (#0)
I1001 10:14:30.947674  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:14:30.993227  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9003
I1001 10:14:30.993261  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38009 (* 1 = 0.38009 loss)
I1001 10:14:31.041739  4916 solver.cpp:218] Iteration 66500 (16.8179 iter/s, 5.94604s/100 iters), loss = 0.0128241
I1001 10:14:31.041769  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128241 (* 1 = 0.0128241 loss)
I1001 10:14:31.041774  4916 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1001 10:14:35.871170  4916 solver.cpp:218] Iteration 66600 (20.7066 iter/s, 4.82938s/100 iters), loss = 0.022616
I1001 10:14:35.871201  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022616 (* 1 = 0.022616 loss)
I1001 10:14:35.871217  4916 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1001 10:14:40.686978  4916 solver.cpp:218] Iteration 66700 (20.7652 iter/s, 4.81576s/100 iters), loss = 0.0194454
I1001 10:14:40.687093  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194454 (* 1 = 0.0194454 loss)
I1001 10:14:40.687108  4916 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1001 10:14:45.513840  4916 solver.cpp:218] Iteration 66800 (20.718 iter/s, 4.82673s/100 iters), loss = 0.038934
I1001 10:14:45.513870  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.038934 (* 1 = 0.038934 loss)
I1001 10:14:45.513876  4916 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1001 10:14:50.328296  4916 solver.cpp:218] Iteration 66900 (20.771 iter/s, 4.8144s/100 iters), loss = 0.0232774
I1001 10:14:50.328341  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232774 (* 1 = 0.0232774 loss)
I1001 10:14:50.328349  4916 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1001 10:14:54.907671  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:14:55.100083  4916 solver.cpp:330] Iteration 67000, Testing net (#0)
I1001 10:14:56.174130  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:14:56.219938  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1001 10:14:56.219962  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379466 (* 1 = 0.379466 loss)
I1001 10:14:56.269021  4916 solver.cpp:218] Iteration 67000 (16.8332 iter/s, 5.94062s/100 iters), loss = 0.0123775
I1001 10:14:56.269069  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123775 (* 1 = 0.0123775 loss)
I1001 10:14:56.269088  4916 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1001 10:15:01.092335  4916 solver.cpp:218] Iteration 67100 (20.733 iter/s, 4.82322s/100 iters), loss = 0.0100501
I1001 10:15:01.092376  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01005 (* 1 = 0.01005 loss)
I1001 10:15:01.092382  4916 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1001 10:15:05.913161  4916 solver.cpp:218] Iteration 67200 (20.7436 iter/s, 4.82077s/100 iters), loss = 0.0103646
I1001 10:15:05.913192  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103646 (* 1 = 0.0103646 loss)
I1001 10:15:05.913197  4916 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1001 10:15:10.722028  4916 solver.cpp:218] Iteration 67300 (20.7951 iter/s, 4.80882s/100 iters), loss = 0.0366724
I1001 10:15:10.722143  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366724 (* 1 = 0.0366724 loss)
I1001 10:15:10.722162  4916 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1001 10:15:15.587278  4916 solver.cpp:218] Iteration 67400 (20.5545 iter/s, 4.86512s/100 iters), loss = 0.0455451
I1001 10:15:15.587307  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455451 (* 1 = 0.0455451 loss)
I1001 10:15:15.587323  4916 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1001 10:15:20.184649  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:15:20.385888  4916 solver.cpp:330] Iteration 67500, Testing net (#0)
I1001 10:15:21.473318  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:15:21.517498  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8985
I1001 10:15:21.517523  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384544 (* 1 = 0.384544 loss)
I1001 10:15:21.564718  4916 solver.cpp:218] Iteration 67500 (16.7297 iter/s, 5.97739s/100 iters), loss = 0.0317491
I1001 10:15:21.564744  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317491 (* 1 = 0.0317491 loss)
I1001 10:15:21.564750  4916 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1001 10:15:26.411797  4916 solver.cpp:218] Iteration 67600 (20.6312 iter/s, 4.84702s/100 iters), loss = 0.0239101
I1001 10:15:26.411837  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239101 (* 1 = 0.0239101 loss)
I1001 10:15:26.411859  4916 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1001 10:15:31.235868  4916 solver.cpp:218] Iteration 67700 (20.7296 iter/s, 4.82401s/100 iters), loss = 0.0528166
I1001 10:15:31.235904  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0528166 (* 1 = 0.0528166 loss)
I1001 10:15:31.235922  4916 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1001 10:15:36.102771  4916 solver.cpp:218] Iteration 67800 (20.5472 iter/s, 4.86685s/100 iters), loss = 0.0293602
I1001 10:15:36.102807  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293603 (* 1 = 0.0293603 loss)
I1001 10:15:36.102825  4916 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1001 10:15:40.931229  4916 solver.cpp:218] Iteration 67900 (20.7108 iter/s, 4.82841s/100 iters), loss = 0.0251997
I1001 10:15:40.931361  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251997 (* 1 = 0.0251997 loss)
I1001 10:15:40.931388  4916 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1001 10:15:45.515481  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:15:45.707794  4916 solver.cpp:330] Iteration 68000, Testing net (#0)
I1001 10:15:46.783154  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:15:46.828805  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9006
I1001 10:15:46.828832  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364587 (* 1 = 0.364587 loss)
I1001 10:15:46.877384  4916 solver.cpp:218] Iteration 68000 (16.818 iter/s, 5.94601s/100 iters), loss = 0.0116097
I1001 10:15:46.877419  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116097 (* 1 = 0.0116097 loss)
I1001 10:15:46.877429  4916 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1001 10:15:51.696295  4916 solver.cpp:218] Iteration 68100 (20.7518 iter/s, 4.81885s/100 iters), loss = 0.0180981
I1001 10:15:51.696326  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180982 (* 1 = 0.0180982 loss)
I1001 10:15:51.696346  4916 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1001 10:15:56.513249  4916 solver.cpp:218] Iteration 68200 (20.7602 iter/s, 4.8169s/100 iters), loss = 0.021916
I1001 10:15:56.513285  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021916 (* 1 = 0.021916 loss)
I1001 10:15:56.513295  4916 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1001 10:16:01.330160  4916 solver.cpp:218] Iteration 68300 (20.7604 iter/s, 4.81686s/100 iters), loss = 0.0153854
I1001 10:16:01.330194  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153854 (* 1 = 0.0153854 loss)
I1001 10:16:01.330214  4916 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1001 10:16:06.153241  4916 solver.cpp:218] Iteration 68400 (20.7339 iter/s, 4.82303s/100 iters), loss = 0.0563638
I1001 10:16:06.153275  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0563638 (* 1 = 0.0563638 loss)
I1001 10:16:06.153285  4916 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1001 10:16:10.726660  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:16:10.919082  4916 solver.cpp:330] Iteration 68500, Testing net (#0)
I1001 10:16:12.003571  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:16:12.048844  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1001 10:16:12.048872  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382662 (* 1 = 0.382662 loss)
I1001 10:16:12.097126  4916 solver.cpp:218] Iteration 68500 (16.8242 iter/s, 5.94383s/100 iters), loss = 0.0222508
I1001 10:16:12.097154  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222508 (* 1 = 0.0222508 loss)
I1001 10:16:12.097164  4916 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1001 10:16:16.912078  4916 solver.cpp:218] Iteration 68600 (20.7688 iter/s, 4.8149s/100 iters), loss = 0.0224856
I1001 10:16:16.912112  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224856 (* 1 = 0.0224856 loss)
I1001 10:16:16.912132  4916 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1001 10:16:21.737285  4916 solver.cpp:218] Iteration 68700 (20.7247 iter/s, 4.82515s/100 iters), loss = 0.0393
I1001 10:16:21.737321  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393 (* 1 = 0.0393 loss)
I1001 10:16:21.737331  4916 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1001 10:16:26.556864  4916 solver.cpp:218] Iteration 68800 (20.749 iter/s, 4.81951s/100 iters), loss = 0.0300167
I1001 10:16:26.556903  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300167 (* 1 = 0.0300167 loss)
I1001 10:16:26.556913  4916 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1001 10:16:31.370544  4916 solver.cpp:218] Iteration 68900 (20.7744 iter/s, 4.81362s/100 iters), loss = 0.00556332
I1001 10:16:31.370576  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556331 (* 1 = 0.00556331 loss)
I1001 10:16:31.370582  4916 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1001 10:16:35.947685  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:16:36.140933  4916 solver.cpp:330] Iteration 69000, Testing net (#0)
I1001 10:16:37.215029  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:16:37.260175  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8888
I1001 10:16:37.260201  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.430554 (* 1 = 0.430554 loss)
I1001 10:16:37.308773  4916 solver.cpp:218] Iteration 69000 (16.8402 iter/s, 5.93818s/100 iters), loss = 0.0413469
I1001 10:16:37.308796  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413469 (* 1 = 0.0413469 loss)
I1001 10:16:37.308804  4916 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1001 10:16:42.126701  4916 solver.cpp:218] Iteration 69100 (20.756 iter/s, 4.81788s/100 iters), loss = 0.0191233
I1001 10:16:42.126847  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191233 (* 1 = 0.0191233 loss)
I1001 10:16:42.126857  4916 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1001 10:16:46.934864  4916 solver.cpp:218] Iteration 69200 (20.7987 iter/s, 4.80799s/100 iters), loss = 0.0181356
I1001 10:16:46.934895  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181357 (* 1 = 0.0181357 loss)
I1001 10:16:46.934900  4916 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1001 10:16:51.757010  4916 solver.cpp:218] Iteration 69300 (20.7379 iter/s, 4.82209s/100 iters), loss = 0.0239901
I1001 10:16:51.757041  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239901 (* 1 = 0.0239901 loss)
I1001 10:16:51.757047  4916 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1001 10:16:56.582741  4916 solver.cpp:218] Iteration 69400 (20.7225 iter/s, 4.82567s/100 iters), loss = 0.0294728
I1001 10:16:56.582784  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294728 (* 1 = 0.0294728 loss)
I1001 10:16:56.582792  4916 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1001 10:17:01.156272  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:17:01.348781  4916 solver.cpp:330] Iteration 69500, Testing net (#0)
I1001 10:17:02.429846  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:17:02.475988  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8964
I1001 10:17:02.476013  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.396283 (* 1 = 0.396283 loss)
I1001 10:17:02.525866  4916 solver.cpp:218] Iteration 69500 (16.8264 iter/s, 5.94305s/100 iters), loss = 0.0334197
I1001 10:17:02.525903  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334198 (* 1 = 0.0334198 loss)
I1001 10:17:02.525912  4916 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1001 10:17:07.338402  4916 solver.cpp:218] Iteration 69600 (20.7793 iter/s, 4.81247s/100 iters), loss = 0.0501818
I1001 10:17:07.338433  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0501818 (* 1 = 0.0501818 loss)
I1001 10:17:07.338439  4916 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1001 10:17:12.156534  4916 solver.cpp:218] Iteration 69700 (20.7552 iter/s, 4.81808s/100 iters), loss = 0.0590445
I1001 10:17:12.156672  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0590445 (* 1 = 0.0590445 loss)
I1001 10:17:12.156689  4916 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1001 10:17:16.969724  4916 solver.cpp:218] Iteration 69800 (20.7769 iter/s, 4.81304s/100 iters), loss = 0.0307794
I1001 10:17:16.969766  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307795 (* 1 = 0.0307795 loss)
I1001 10:17:16.969772  4916 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1001 10:17:21.783064  4916 solver.cpp:218] Iteration 69900 (20.7759 iter/s, 4.81327s/100 iters), loss = 0.0155417
I1001 10:17:21.783095  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155417 (* 1 = 0.0155417 loss)
I1001 10:17:21.783104  4916 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1001 10:17:26.359073  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:17:26.556401  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_70000.caffemodel
I1001 10:17:26.560573  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_70000.solverstate
I1001 10:17:26.561807  4916 solver.cpp:330] Iteration 70000, Testing net (#0)
I1001 10:17:27.635984  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:17:27.681496  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I1001 10:17:27.681531  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402745 (* 1 = 0.402745 loss)
I1001 10:17:27.730132  4916 solver.cpp:218] Iteration 70000 (16.8158 iter/s, 5.94678s/100 iters), loss = 0.0150163
I1001 10:17:27.730159  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150164 (* 1 = 0.0150164 loss)
I1001 10:17:27.730166  4916 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1001 10:17:32.549412  4916 solver.cpp:218] Iteration 70100 (20.7502 iter/s, 4.81923s/100 iters), loss = 0.0146435
I1001 10:17:32.549454  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146436 (* 1 = 0.0146436 loss)
I1001 10:17:32.549461  4916 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1001 10:17:37.364006  4916 solver.cpp:218] Iteration 70200 (20.7706 iter/s, 4.8145s/100 iters), loss = 0.0179326
I1001 10:17:37.364037  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179327 (* 1 = 0.0179327 loss)
I1001 10:17:37.364042  4916 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1001 10:17:42.192272  4916 solver.cpp:218] Iteration 70300 (20.7116 iter/s, 4.82822s/100 iters), loss = 0.018395
I1001 10:17:42.192390  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183951 (* 1 = 0.0183951 loss)
I1001 10:17:42.192399  4916 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1001 10:17:47.004854  4916 solver.cpp:218] Iteration 70400 (20.7796 iter/s, 4.81241s/100 iters), loss = 0.0118034
I1001 10:17:47.004884  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118035 (* 1 = 0.0118035 loss)
I1001 10:17:47.004890  4916 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1001 10:17:51.590029  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:17:51.782307  4916 solver.cpp:330] Iteration 70500, Testing net (#0)
I1001 10:17:52.857509  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:17:52.902727  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9006
I1001 10:17:52.902763  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371222 (* 1 = 0.371222 loss)
I1001 10:17:52.951534  4916 solver.cpp:218] Iteration 70500 (16.8162 iter/s, 5.94663s/100 iters), loss = 0.0393234
I1001 10:17:52.951557  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393235 (* 1 = 0.0393235 loss)
I1001 10:17:52.951565  4916 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1001 10:17:57.780246  4916 solver.cpp:218] Iteration 70600 (20.7096 iter/s, 4.82867s/100 iters), loss = 0.0360877
I1001 10:17:57.780287  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360878 (* 1 = 0.0360878 loss)
I1001 10:17:57.780293  4916 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1001 10:18:02.601799  4916 solver.cpp:218] Iteration 70700 (20.7405 iter/s, 4.82149s/100 iters), loss = 0.0388811
I1001 10:18:02.601830  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388811 (* 1 = 0.0388811 loss)
I1001 10:18:02.601837  4916 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1001 10:18:07.412873  4916 solver.cpp:218] Iteration 70800 (20.7856 iter/s, 4.81102s/100 iters), loss = 0.0157835
I1001 10:18:07.412916  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157836 (* 1 = 0.0157836 loss)
I1001 10:18:07.412921  4916 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1001 10:18:12.231403  4916 solver.cpp:218] Iteration 70900 (20.7535 iter/s, 4.81847s/100 iters), loss = 0.0157361
I1001 10:18:12.231577  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157361 (* 1 = 0.0157361 loss)
I1001 10:18:12.231585  4916 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1001 10:18:16.804235  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:18:16.996811  4916 solver.cpp:330] Iteration 71000, Testing net (#0)
I1001 10:18:18.079232  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:18:18.124428  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I1001 10:18:18.124464  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.396523 (* 1 = 0.396523 loss)
I1001 10:18:18.173084  4916 solver.cpp:218] Iteration 71000 (16.8308 iter/s, 5.9415s/100 iters), loss = 0.0159828
I1001 10:18:18.173115  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159829 (* 1 = 0.0159829 loss)
I1001 10:18:18.173121  4916 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1001 10:18:22.989697  4916 solver.cpp:218] Iteration 71100 (20.7617 iter/s, 4.81656s/100 iters), loss = 0.0767094
I1001 10:18:22.989727  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0767095 (* 1 = 0.0767095 loss)
I1001 10:18:22.989732  4916 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1001 10:18:27.816566  4916 solver.cpp:218] Iteration 71200 (20.7176 iter/s, 4.82682s/100 iters), loss = 0.0539554
I1001 10:18:27.816607  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0539554 (* 1 = 0.0539554 loss)
I1001 10:18:27.816613  4916 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1001 10:18:32.644618  4916 solver.cpp:218] Iteration 71300 (20.7125 iter/s, 4.82799s/100 iters), loss = 0.0283524
I1001 10:18:32.644651  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283524 (* 1 = 0.0283524 loss)
I1001 10:18:32.644659  4916 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1001 10:18:37.464090  4916 solver.cpp:218] Iteration 71400 (20.7494 iter/s, 4.81942s/100 iters), loss = 0.0237378
I1001 10:18:37.464123  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237379 (* 1 = 0.0237379 loss)
I1001 10:18:37.464129  4916 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1001 10:18:42.045500  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:18:42.237779  4916 solver.cpp:330] Iteration 71500, Testing net (#0)
I1001 10:18:43.313899  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:18:43.358968  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8977
I1001 10:18:43.359002  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393049 (* 1 = 0.393049 loss)
I1001 10:18:43.407661  4916 solver.cpp:218] Iteration 71500 (16.8251 iter/s, 5.94352s/100 iters), loss = 0.0239375
I1001 10:18:43.407685  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239375 (* 1 = 0.0239375 loss)
I1001 10:18:43.407692  4916 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1001 10:18:48.228600  4916 solver.cpp:218] Iteration 71600 (20.743 iter/s, 4.82089s/100 iters), loss = 0.0307108
I1001 10:18:48.228631  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307108 (* 1 = 0.0307108 loss)
I1001 10:18:48.228636  4916 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1001 10:18:53.042052  4916 solver.cpp:218] Iteration 71700 (20.7753 iter/s, 4.8134s/100 iters), loss = 0.029453
I1001 10:18:53.042083  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029453 (* 1 = 0.029453 loss)
I1001 10:18:53.042088  4916 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1001 10:18:57.857849  4916 solver.cpp:218] Iteration 71800 (20.7652 iter/s, 4.81575s/100 iters), loss = 0.0260682
I1001 10:18:57.857892  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260682 (* 1 = 0.0260682 loss)
I1001 10:18:57.857899  4916 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1001 10:19:02.674425  4916 solver.cpp:218] Iteration 71900 (20.7619 iter/s, 4.81651s/100 iters), loss = 0.0182935
I1001 10:19:02.674458  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182935 (* 1 = 0.0182935 loss)
I1001 10:19:02.674464  4916 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1001 10:19:07.247936  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:19:07.440758  4916 solver.cpp:330] Iteration 72000, Testing net (#0)
I1001 10:19:08.525045  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:19:08.571395  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8991
I1001 10:19:08.571432  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391602 (* 1 = 0.391602 loss)
I1001 10:19:08.620964  4916 solver.cpp:218] Iteration 72000 (16.8167 iter/s, 5.94648s/100 iters), loss = 0.0141998
I1001 10:19:08.620998  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141997 (* 1 = 0.0141997 loss)
I1001 10:19:08.621006  4916 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1001 10:19:13.433550  4916 solver.cpp:218] Iteration 72100 (20.7791 iter/s, 4.81253s/100 iters), loss = 0.0217522
I1001 10:19:13.433647  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217522 (* 1 = 0.0217522 loss)
I1001 10:19:13.433666  4916 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1001 10:19:18.256785  4916 solver.cpp:218] Iteration 72200 (20.7334 iter/s, 4.82313s/100 iters), loss = 0.0729273
I1001 10:19:18.256816  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729273 (* 1 = 0.0729273 loss)
I1001 10:19:18.256825  4916 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1001 10:19:23.074128  4916 solver.cpp:218] Iteration 72300 (20.7586 iter/s, 4.81729s/100 iters), loss = 0.00940556
I1001 10:19:23.074159  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00940553 (* 1 = 0.00940553 loss)
I1001 10:19:23.074175  4916 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1001 10:19:27.899685  4916 solver.cpp:218] Iteration 72400 (20.7232 iter/s, 4.8255s/100 iters), loss = 0.0252318
I1001 10:19:27.899715  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252318 (* 1 = 0.0252318 loss)
I1001 10:19:27.899721  4916 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1001 10:19:32.485159  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:19:32.678901  4916 solver.cpp:330] Iteration 72500, Testing net (#0)
I1001 10:19:33.754767  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:19:33.800462  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1001 10:19:33.800498  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370022 (* 1 = 0.370022 loss)
I1001 10:19:33.849370  4916 solver.cpp:218] Iteration 72500 (16.8078 iter/s, 5.94964s/100 iters), loss = 0.0639712
I1001 10:19:33.849395  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0639711 (* 1 = 0.0639711 loss)
I1001 10:19:33.849402  4916 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1001 10:19:38.677790  4916 solver.cpp:218] Iteration 72600 (20.7109 iter/s, 4.82837s/100 iters), loss = 0.034189
I1001 10:19:38.677822  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034189 (* 1 = 0.034189 loss)
I1001 10:19:38.677829  4916 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1001 10:19:43.492184  4916 solver.cpp:218] Iteration 72700 (20.7713 iter/s, 4.81434s/100 iters), loss = 0.0341727
I1001 10:19:43.492292  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341727 (* 1 = 0.0341727 loss)
I1001 10:19:43.492300  4916 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1001 10:19:48.312206  4916 solver.cpp:218] Iteration 72800 (20.7473 iter/s, 4.81989s/100 iters), loss = 0.0366051
I1001 10:19:48.312237  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366051 (* 1 = 0.0366051 loss)
I1001 10:19:48.312243  4916 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1001 10:19:53.126250  4916 solver.cpp:218] Iteration 72900 (20.7728 iter/s, 4.81399s/100 iters), loss = 0.0108738
I1001 10:19:53.126292  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108738 (* 1 = 0.0108738 loss)
I1001 10:19:53.126298  4916 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1001 10:19:57.710265  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:19:57.903277  4916 solver.cpp:330] Iteration 73000, Testing net (#0)
I1001 10:19:58.979630  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:19:59.025055  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9009
I1001 10:19:59.025090  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.400572 (* 1 = 0.400572 loss)
I1001 10:19:59.073796  4916 solver.cpp:218] Iteration 73000 (16.8139 iter/s, 5.94744s/100 iters), loss = 0.00643044
I1001 10:19:59.073822  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643041 (* 1 = 0.00643041 loss)
I1001 10:19:59.073828  4916 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1001 10:20:03.906232  4916 solver.cpp:218] Iteration 73100 (20.6937 iter/s, 4.83239s/100 iters), loss = 0.0094807
I1001 10:20:03.906275  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00948067 (* 1 = 0.00948067 loss)
I1001 10:20:03.906281  4916 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1001 10:20:08.733527  4916 solver.cpp:218] Iteration 73200 (20.7158 iter/s, 4.82723s/100 iters), loss = 0.0105395
I1001 10:20:08.733570  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105395 (* 1 = 0.0105395 loss)
I1001 10:20:08.733577  4916 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1001 10:20:13.547168  4916 solver.cpp:218] Iteration 73300 (20.7746 iter/s, 4.81358s/100 iters), loss = 0.043309
I1001 10:20:13.547292  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433089 (* 1 = 0.0433089 loss)
I1001 10:20:13.547309  4916 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1001 10:20:18.371614  4916 solver.cpp:218] Iteration 73400 (20.7284 iter/s, 4.8243s/100 iters), loss = 0.0341609
I1001 10:20:18.371644  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341609 (* 1 = 0.0341609 loss)
I1001 10:20:18.371650  4916 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1001 10:20:22.935658  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:20:23.127460  4916 solver.cpp:330] Iteration 73500, Testing net (#0)
I1001 10:20:24.213714  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:20:24.259054  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8947
I1001 10:20:24.259079  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.414757 (* 1 = 0.414757 loss)
I1001 10:20:24.307626  4916 solver.cpp:218] Iteration 73500 (16.8465 iter/s, 5.93595s/100 iters), loss = 0.0128941
I1001 10:20:24.307658  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128941 (* 1 = 0.0128941 loss)
I1001 10:20:24.307665  4916 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1001 10:20:29.119868  4916 solver.cpp:218] Iteration 73600 (20.7806 iter/s, 4.81218s/100 iters), loss = 0.0264196
I1001 10:20:29.119897  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264196 (* 1 = 0.0264196 loss)
I1001 10:20:29.119904  4916 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1001 10:20:33.938640  4916 solver.cpp:218] Iteration 73700 (20.7524 iter/s, 4.81872s/100 iters), loss = 0.0265442
I1001 10:20:33.938681  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265442 (* 1 = 0.0265442 loss)
I1001 10:20:33.938688  4916 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1001 10:20:38.762115  4916 solver.cpp:218] Iteration 73800 (20.7322 iter/s, 4.82341s/100 iters), loss = 0.0119985
I1001 10:20:38.762150  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119984 (* 1 = 0.0119984 loss)
I1001 10:20:38.762166  4916 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1001 10:20:43.573721  4916 solver.cpp:218] Iteration 73900 (20.7833 iter/s, 4.81155s/100 iters), loss = 0.0190845
I1001 10:20:43.573868  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190844 (* 1 = 0.0190844 loss)
I1001 10:20:43.573886  4916 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1001 10:20:48.155750  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:20:48.348536  4916 solver.cpp:330] Iteration 74000, Testing net (#0)
I1001 10:20:49.425045  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:20:49.470819  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9008
I1001 10:20:49.470854  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38821 (* 1 = 0.38821 loss)
I1001 10:20:49.519453  4916 solver.cpp:218] Iteration 74000 (16.8193 iter/s, 5.94557s/100 iters), loss = 0.014363
I1001 10:20:49.519475  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014363 (* 1 = 0.014363 loss)
I1001 10:20:49.519482  4916 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1001 10:20:54.344508  4916 solver.cpp:218] Iteration 74100 (20.7253 iter/s, 4.82501s/100 iters), loss = 0.0855255
I1001 10:20:54.344539  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0855255 (* 1 = 0.0855255 loss)
I1001 10:20:54.344545  4916 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1001 10:20:59.158861  4916 solver.cpp:218] Iteration 74200 (20.7714 iter/s, 4.8143s/100 iters), loss = 0.0763483
I1001 10:20:59.158890  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0763482 (* 1 = 0.0763482 loss)
I1001 10:20:59.158896  4916 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1001 10:21:03.988903  4916 solver.cpp:218] Iteration 74300 (20.704 iter/s, 4.82999s/100 iters), loss = 0.0305521
I1001 10:21:03.988934  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305521 (* 1 = 0.0305521 loss)
I1001 10:21:03.988940  4916 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1001 10:21:08.813506  4916 solver.cpp:218] Iteration 74400 (20.7273 iter/s, 4.82455s/100 iters), loss = 0.0180901
I1001 10:21:08.813537  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180901 (* 1 = 0.0180901 loss)
I1001 10:21:08.813544  4916 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1001 10:21:13.382431  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:21:13.576802  4916 solver.cpp:330] Iteration 74500, Testing net (#0)
I1001 10:21:14.658854  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:21:14.704579  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8986
I1001 10:21:14.704617  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405148 (* 1 = 0.405148 loss)
I1001 10:21:14.753423  4916 solver.cpp:218] Iteration 74500 (16.8354 iter/s, 5.93986s/100 iters), loss = 0.012839
I1001 10:21:14.753455  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012839 (* 1 = 0.012839 loss)
I1001 10:21:14.753463  4916 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1001 10:21:19.569109  4916 solver.cpp:218] Iteration 74600 (20.7657 iter/s, 4.81563s/100 iters), loss = 0.0272512
I1001 10:21:19.569149  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272512 (* 1 = 0.0272512 loss)
I1001 10:21:19.569155  4916 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1001 10:21:24.380920  4916 solver.cpp:218] Iteration 74700 (20.7825 iter/s, 4.81175s/100 iters), loss = 0.054748
I1001 10:21:24.380950  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054748 (* 1 = 0.054748 loss)
I1001 10:21:24.380956  4916 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1001 10:21:29.192766  4916 solver.cpp:218] Iteration 74800 (20.7823 iter/s, 4.8118s/100 iters), loss = 0.0156895
I1001 10:21:29.192807  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156895 (* 1 = 0.0156895 loss)
I1001 10:21:29.192813  4916 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1001 10:21:34.009500  4916 solver.cpp:218] Iteration 74900 (20.7612 iter/s, 4.81667s/100 iters), loss = 0.0324262
I1001 10:21:34.009531  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324262 (* 1 = 0.0324262 loss)
I1001 10:21:34.009538  4916 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1001 10:21:38.594650  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:21:38.787139  4916 solver.cpp:330] Iteration 75000, Testing net (#0)
I1001 10:21:39.861423  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:21:39.906719  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8959
I1001 10:21:39.906754  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403026 (* 1 = 0.403026 loss)
I1001 10:21:39.956095  4916 solver.cpp:218] Iteration 75000 (16.8165 iter/s, 5.94654s/100 iters), loss = 0.0234318
I1001 10:21:39.956122  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234318 (* 1 = 0.0234318 loss)
I1001 10:21:39.956128  4916 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1001 10:21:44.780802  4916 solver.cpp:218] Iteration 75100 (20.7269 iter/s, 4.82465s/100 iters), loss = 0.064606
I1001 10:21:44.780928  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064606 (* 1 = 0.064606 loss)
I1001 10:21:44.780936  4916 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1001 10:21:49.598474  4916 solver.cpp:218] Iteration 75200 (20.7575 iter/s, 4.81752s/100 iters), loss = 0.0241606
I1001 10:21:49.598505  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241606 (* 1 = 0.0241606 loss)
I1001 10:21:49.598522  4916 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1001 10:21:54.420739  4916 solver.cpp:218] Iteration 75300 (20.7374 iter/s, 4.82221s/100 iters), loss = 0.060195
I1001 10:21:54.420770  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.060195 (* 1 = 0.060195 loss)
I1001 10:21:54.420776  4916 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1001 10:21:59.234365  4916 solver.cpp:218] Iteration 75400 (20.7746 iter/s, 4.81357s/100 iters), loss = 0.0110804
I1001 10:21:59.234395  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110803 (* 1 = 0.0110803 loss)
I1001 10:21:59.234400  4916 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1001 10:22:03.818783  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:22:04.011778  4916 solver.cpp:330] Iteration 75500, Testing net (#0)
I1001 10:22:05.087088  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:22:05.132660  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8899
I1001 10:22:05.132688  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.438208 (* 1 = 0.438208 loss)
I1001 10:22:05.181246  4916 solver.cpp:218] Iteration 75500 (16.8157 iter/s, 5.94683s/100 iters), loss = 0.0265744
I1001 10:22:05.181277  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265744 (* 1 = 0.0265744 loss)
I1001 10:22:05.181287  4916 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1001 10:22:10.001057  4916 solver.cpp:218] Iteration 75600 (20.7479 iter/s, 4.81976s/100 iters), loss = 0.0772754
I1001 10:22:10.001091  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0772754 (* 1 = 0.0772754 loss)
I1001 10:22:10.001109  4916 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1001 10:22:14.817178  4916 solver.cpp:218] Iteration 75700 (20.7638 iter/s, 4.81607s/100 iters), loss = 0.00976487
I1001 10:22:14.817322  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00976486 (* 1 = 0.00976486 loss)
I1001 10:22:14.817359  4916 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1001 10:22:19.630684  4916 solver.cpp:218] Iteration 75800 (20.7756 iter/s, 4.81335s/100 iters), loss = 0.0257274
I1001 10:22:19.630719  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257274 (* 1 = 0.0257274 loss)
I1001 10:22:19.630728  4916 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1001 10:22:24.460085  4916 solver.cpp:218] Iteration 75900 (20.7068 iter/s, 4.82934s/100 iters), loss = 0.017392
I1001 10:22:24.460120  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017392 (* 1 = 0.017392 loss)
I1001 10:22:24.460129  4916 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1001 10:22:29.036208  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:22:29.229475  4916 solver.cpp:330] Iteration 76000, Testing net (#0)
I1001 10:22:30.314913  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:22:30.360306  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8935
I1001 10:22:30.360332  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412524 (* 1 = 0.412524 loss)
I1001 10:22:30.409284  4916 solver.cpp:218] Iteration 76000 (16.8092 iter/s, 5.94911s/100 iters), loss = 0.0226854
I1001 10:22:30.409314  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226854 (* 1 = 0.0226854 loss)
I1001 10:22:30.409323  4916 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1001 10:22:35.225982  4916 solver.cpp:218] Iteration 76100 (20.7613 iter/s, 4.81665s/100 iters), loss = 0.0287841
I1001 10:22:35.226016  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287841 (* 1 = 0.0287841 loss)
I1001 10:22:35.226023  4916 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1001 10:22:40.050915  4916 solver.cpp:218] Iteration 76200 (20.7259 iter/s, 4.82488s/100 iters), loss = 0.0217355
I1001 10:22:40.050948  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217355 (* 1 = 0.0217355 loss)
I1001 10:22:40.050966  4916 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1001 10:22:44.877600  4916 solver.cpp:218] Iteration 76300 (20.7184 iter/s, 4.82663s/100 iters), loss = 0.0283003
I1001 10:22:44.877710  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283003 (* 1 = 0.0283003 loss)
I1001 10:22:44.877733  4916 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1001 10:22:49.691815  4916 solver.cpp:218] Iteration 76400 (20.7724 iter/s, 4.81409s/100 iters), loss = 0.0420486
I1001 10:22:49.691850  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420485 (* 1 = 0.0420485 loss)
I1001 10:22:49.691869  4916 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1001 10:22:54.269316  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:22:54.461982  4916 solver.cpp:330] Iteration 76500, Testing net (#0)
I1001 10:22:55.536206  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:22:55.581607  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8982
I1001 10:22:55.581634  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378811 (* 1 = 0.378811 loss)
I1001 10:22:55.630115  4916 solver.cpp:218] Iteration 76500 (16.84 iter/s, 5.93825s/100 iters), loss = 0.0160107
I1001 10:22:55.630139  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160107 (* 1 = 0.0160107 loss)
I1001 10:22:55.630146  4916 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1001 10:23:00.447496  4916 solver.cpp:218] Iteration 76600 (20.7584 iter/s, 4.81734s/100 iters), loss = 0.0387665
I1001 10:23:00.447528  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387665 (* 1 = 0.0387665 loss)
I1001 10:23:00.447544  4916 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1001 10:23:05.257356  4916 solver.cpp:218] Iteration 76700 (20.7909 iter/s, 4.80981s/100 iters), loss = 0.0679377
I1001 10:23:05.257387  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0679377 (* 1 = 0.0679377 loss)
I1001 10:23:05.257405  4916 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1001 10:23:10.081864  4916 solver.cpp:218] Iteration 76800 (20.7278 iter/s, 4.82445s/100 iters), loss = 0.0258956
I1001 10:23:10.081895  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258956 (* 1 = 0.0258956 loss)
I1001 10:23:10.081900  4916 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1001 10:23:14.903004  4916 solver.cpp:218] Iteration 76900 (20.7422 iter/s, 4.82109s/100 iters), loss = 0.0217157
I1001 10:23:14.903136  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217157 (* 1 = 0.0217157 loss)
I1001 10:23:14.903156  4916 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1001 10:23:19.477115  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:23:19.670120  4916 solver.cpp:330] Iteration 77000, Testing net (#0)
I1001 10:23:20.753304  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:23:20.799082  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9002
I1001 10:23:20.799118  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382926 (* 1 = 0.382926 loss)
I1001 10:23:20.847924  4916 solver.cpp:218] Iteration 77000 (16.8215 iter/s, 5.94478s/100 iters), loss = 0.0132332
I1001 10:23:20.847955  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132332 (* 1 = 0.0132332 loss)
I1001 10:23:20.847962  4916 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1001 10:23:25.663722  4916 solver.cpp:218] Iteration 77100 (20.7652 iter/s, 4.81575s/100 iters), loss = 0.061781
I1001 10:23:25.663763  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0617811 (* 1 = 0.0617811 loss)
I1001 10:23:25.663769  4916 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1001 10:23:30.488099  4916 solver.cpp:218] Iteration 77200 (20.7283 iter/s, 4.82431s/100 iters), loss = 0.0817829
I1001 10:23:30.488131  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0817829 (* 1 = 0.0817829 loss)
I1001 10:23:30.488147  4916 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1001 10:23:35.304848  4916 solver.cpp:218] Iteration 77300 (20.7611 iter/s, 4.8167s/100 iters), loss = 0.050452
I1001 10:23:35.304880  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050452 (* 1 = 0.050452 loss)
I1001 10:23:35.304898  4916 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1001 10:23:40.128371  4916 solver.cpp:218] Iteration 77400 (20.732 iter/s, 4.82347s/100 iters), loss = 0.0157857
I1001 10:23:40.128403  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157857 (* 1 = 0.0157857 loss)
I1001 10:23:40.128410  4916 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1001 10:23:44.705325  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:23:44.897609  4916 solver.cpp:330] Iteration 77500, Testing net (#0)
I1001 10:23:45.973584  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:23:46.019196  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8976
I1001 10:23:46.019232  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.408921 (* 1 = 0.408921 loss)
I1001 10:23:46.067203  4916 solver.cpp:218] Iteration 77500 (16.8385 iter/s, 5.93878s/100 iters), loss = 0.0138571
I1001 10:23:46.067229  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138571 (* 1 = 0.0138571 loss)
I1001 10:23:46.067235  4916 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1001 10:23:50.886163  4916 solver.cpp:218] Iteration 77600 (20.7516 iter/s, 4.81891s/100 iters), loss = 0.0219308
I1001 10:23:50.886204  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219308 (* 1 = 0.0219308 loss)
I1001 10:23:50.886210  4916 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1001 10:23:55.694775  4916 solver.cpp:218] Iteration 77700 (20.7963 iter/s, 4.80855s/100 iters), loss = 0.0328065
I1001 10:23:55.694804  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328065 (* 1 = 0.0328065 loss)
I1001 10:23:55.694810  4916 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1001 10:24:00.518661  4916 solver.cpp:218] Iteration 77800 (20.7304 iter/s, 4.82383s/100 iters), loss = 0.0201168
I1001 10:24:00.518692  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201168 (* 1 = 0.0201168 loss)
I1001 10:24:00.518698  4916 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1001 10:24:05.334522  4916 solver.cpp:218] Iteration 77900 (20.765 iter/s, 4.8158s/100 iters), loss = 0.0574251
I1001 10:24:05.334559  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574251 (* 1 = 0.0574251 loss)
I1001 10:24:05.334568  4916 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1001 10:24:09.920689  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:24:10.112893  4916 solver.cpp:330] Iteration 78000, Testing net (#0)
I1001 10:24:11.187980  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:24:11.233672  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8884
I1001 10:24:11.233708  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.446579 (* 1 = 0.446579 loss)
I1001 10:24:11.282588  4916 solver.cpp:218] Iteration 78000 (16.8123 iter/s, 5.94801s/100 iters), loss = 0.0234061
I1001 10:24:11.282613  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234061 (* 1 = 0.0234061 loss)
I1001 10:24:11.282620  4916 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1001 10:24:16.100381  4916 solver.cpp:218] Iteration 78100 (20.7566 iter/s, 4.81775s/100 iters), loss = 0.0134701
I1001 10:24:16.100529  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134701 (* 1 = 0.0134701 loss)
I1001 10:24:16.100538  4916 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1001 10:24:20.925496  4916 solver.cpp:218] Iteration 78200 (20.7256 iter/s, 4.82495s/100 iters), loss = 0.0118895
I1001 10:24:20.925528  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118895 (* 1 = 0.0118895 loss)
I1001 10:24:20.925534  4916 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1001 10:24:25.743126  4916 solver.cpp:218] Iteration 78300 (20.7573 iter/s, 4.81758s/100 iters), loss = 0.0365621
I1001 10:24:25.743157  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365621 (* 1 = 0.0365621 loss)
I1001 10:24:25.743163  4916 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1001 10:24:30.564913  4916 solver.cpp:218] Iteration 78400 (20.7396 iter/s, 4.82169s/100 iters), loss = 0.0335486
I1001 10:24:30.564944  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335486 (* 1 = 0.0335486 loss)
I1001 10:24:30.564951  4916 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1001 10:24:35.136708  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:24:35.330622  4916 solver.cpp:330] Iteration 78500, Testing net (#0)
I1001 10:24:36.412379  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:24:36.457641  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8896
I1001 10:24:36.457677  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444634 (* 1 = 0.444634 loss)
I1001 10:24:36.506474  4916 solver.cpp:218] Iteration 78500 (16.8307 iter/s, 5.94151s/100 iters), loss = 0.0453087
I1001 10:24:36.506508  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453087 (* 1 = 0.0453087 loss)
I1001 10:24:36.506515  4916 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1001 10:24:41.320834  4916 solver.cpp:218] Iteration 78600 (20.7714 iter/s, 4.81431s/100 iters), loss = 0.0210895
I1001 10:24:41.320876  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210895 (* 1 = 0.0210895 loss)
I1001 10:24:41.320883  4916 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1001 10:24:46.143661  4916 solver.cpp:218] Iteration 78700 (20.7351 iter/s, 4.82273s/100 iters), loss = 0.0393231
I1001 10:24:46.143788  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393231 (* 1 = 0.0393231 loss)
I1001 10:24:46.143795  4916 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1001 10:24:50.971346  4916 solver.cpp:218] Iteration 78800 (20.7145 iter/s, 4.82754s/100 iters), loss = 0.0251391
I1001 10:24:50.971377  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251391 (* 1 = 0.0251391 loss)
I1001 10:24:50.971384  4916 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1001 10:24:55.785526  4916 solver.cpp:218] Iteration 78900 (20.7722 iter/s, 4.81413s/100 iters), loss = 0.014043
I1001 10:24:55.785555  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014043 (* 1 = 0.014043 loss)
I1001 10:24:55.785562  4916 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1001 10:25:00.369444  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:25:00.561843  4916 solver.cpp:330] Iteration 79000, Testing net (#0)
I1001 10:25:01.636694  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:25:01.682091  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1001 10:25:01.682127  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389508 (* 1 = 0.389508 loss)
I1001 10:25:01.730712  4916 solver.cpp:218] Iteration 79000 (16.8205 iter/s, 5.94513s/100 iters), loss = 0.00860748
I1001 10:25:01.730736  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0086075 (* 1 = 0.0086075 loss)
I1001 10:25:01.730743  4916 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1001 10:25:06.558012  4916 solver.cpp:218] Iteration 79100 (20.7157 iter/s, 4.82725s/100 iters), loss = 0.0146602
I1001 10:25:06.558040  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146602 (* 1 = 0.0146602 loss)
I1001 10:25:06.558046  4916 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1001 10:25:11.373833  4916 solver.cpp:218] Iteration 79200 (20.7651 iter/s, 4.81577s/100 iters), loss = 0.0281353
I1001 10:25:11.373870  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281353 (* 1 = 0.0281353 loss)
I1001 10:25:11.373878  4916 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1001 10:25:16.192970  4916 solver.cpp:218] Iteration 79300 (20.7509 iter/s, 4.81908s/100 iters), loss = 0.0170375
I1001 10:25:16.193070  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170376 (* 1 = 0.0170376 loss)
I1001 10:25:16.193089  4916 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1001 10:25:21.015329  4916 solver.cpp:218] Iteration 79400 (20.7374 iter/s, 4.82222s/100 iters), loss = 0.0315187
I1001 10:25:21.015362  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315187 (* 1 = 0.0315187 loss)
I1001 10:25:21.015367  4916 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1001 10:25:25.586797  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:25:25.780704  4916 solver.cpp:330] Iteration 79500, Testing net (#0)
I1001 10:25:26.862711  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:25:26.907976  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1001 10:25:26.908010  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371089 (* 1 = 0.371089 loss)
I1001 10:25:26.956802  4916 solver.cpp:218] Iteration 79500 (16.831 iter/s, 5.94142s/100 iters), loss = 0.0281132
I1001 10:25:26.956825  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281132 (* 1 = 0.0281132 loss)
I1001 10:25:26.956832  4916 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1001 10:25:31.768138  4916 solver.cpp:218] Iteration 79600 (20.7844 iter/s, 4.81129s/100 iters), loss = 0.0421154
I1001 10:25:31.768169  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0421154 (* 1 = 0.0421154 loss)
I1001 10:25:31.768187  4916 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1001 10:25:36.620671  4916 solver.cpp:218] Iteration 79700 (20.608 iter/s, 4.85248s/100 iters), loss = 0.0683769
I1001 10:25:36.620712  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068377 (* 1 = 0.068377 loss)
I1001 10:25:36.620718  4916 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1001 10:25:41.465631  4916 solver.cpp:218] Iteration 79800 (20.6403 iter/s, 4.8449s/100 iters), loss = 0.051338
I1001 10:25:41.465667  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513381 (* 1 = 0.0513381 loss)
I1001 10:25:41.465674  4916 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1001 10:25:46.292320  4916 solver.cpp:218] Iteration 79900 (20.7184 iter/s, 4.82664s/100 iters), loss = 0.0148067
I1001 10:25:46.292487  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148067 (* 1 = 0.0148067 loss)
I1001 10:25:46.292507  4916 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1001 10:25:50.875780  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:25:51.067167  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_80000.caffemodel
I1001 10:25:51.071794  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_80000.solverstate
I1001 10:25:51.073107  4916 solver.cpp:330] Iteration 80000, Testing net (#0)
I1001 10:25:52.146297  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:25:52.189589  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8982
I1001 10:25:52.189615  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.39787 (* 1 = 0.39787 loss)
I1001 10:25:52.237335  4916 solver.cpp:218] Iteration 80000 (16.8213 iter/s, 5.94484s/100 iters), loss = 0.0266628
I1001 10:25:52.237360  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266628 (* 1 = 0.0266628 loss)
I1001 10:25:52.237366  4916 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1001 10:25:52.237370  4916 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1001 10:25:57.057196  4916 solver.cpp:218] Iteration 80100 (20.7477 iter/s, 4.81982s/100 iters), loss = 0.0518099
I1001 10:25:57.057237  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518099 (* 1 = 0.0518099 loss)
I1001 10:25:57.057243  4916 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1001 10:26:01.866284  4916 solver.cpp:218] Iteration 80200 (20.7942 iter/s, 4.80903s/100 iters), loss = 0.0122396
I1001 10:26:01.866325  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122396 (* 1 = 0.0122396 loss)
I1001 10:26:01.866331  4916 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1001 10:26:06.679159  4916 solver.cpp:218] Iteration 80300 (20.7779 iter/s, 4.81282s/100 iters), loss = 0.016105
I1001 10:26:06.679190  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016105 (* 1 = 0.016105 loss)
I1001 10:26:06.679196  4916 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1001 10:26:11.488780  4916 solver.cpp:218] Iteration 80400 (20.7919 iter/s, 4.80957s/100 iters), loss = 0.0289157
I1001 10:26:11.488814  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289157 (* 1 = 0.0289157 loss)
I1001 10:26:11.488821  4916 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1001 10:26:16.061676  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:26:16.251734  4916 solver.cpp:330] Iteration 80500, Testing net (#0)
I1001 10:26:17.325976  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:26:17.370841  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1001 10:26:17.370877  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347045 (* 1 = 0.347045 loss)
I1001 10:26:17.419613  4916 solver.cpp:218] Iteration 80500 (16.8612 iter/s, 5.93078s/100 iters), loss = 0.0434455
I1001 10:26:17.419649  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434455 (* 1 = 0.0434455 loss)
I1001 10:26:17.419657  4916 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1001 10:26:22.230206  4916 solver.cpp:218] Iteration 80600 (20.7877 iter/s, 4.81054s/100 iters), loss = 0.0436473
I1001 10:26:22.230235  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436473 (* 1 = 0.0436473 loss)
I1001 10:26:22.230242  4916 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1001 10:26:27.050618  4916 solver.cpp:218] Iteration 80700 (20.7453 iter/s, 4.82037s/100 iters), loss = 0.0368194
I1001 10:26:27.050660  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368194 (* 1 = 0.0368194 loss)
I1001 10:26:27.050667  4916 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1001 10:26:31.858163  4916 solver.cpp:218] Iteration 80800 (20.8009 iter/s, 4.80748s/100 iters), loss = 0.0165819
I1001 10:26:31.858194  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016582 (* 1 = 0.016582 loss)
I1001 10:26:31.858201  4916 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1001 10:26:36.716498  4916 solver.cpp:218] Iteration 80900 (20.5834 iter/s, 4.85829s/100 iters), loss = 0.0251574
I1001 10:26:36.716528  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251574 (* 1 = 0.0251574 loss)
I1001 10:26:36.716534  4916 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1001 10:26:41.300302  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:26:41.498442  4916 solver.cpp:330] Iteration 81000, Testing net (#0)
I1001 10:26:42.576099  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:26:42.621596  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9091
I1001 10:26:42.621631  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340761 (* 1 = 0.340761 loss)
I1001 10:26:42.670472  4916 solver.cpp:218] Iteration 81000 (16.7956 iter/s, 5.95393s/100 iters), loss = 0.0432564
I1001 10:26:42.670497  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432564 (* 1 = 0.0432564 loss)
I1001 10:26:42.670505  4916 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1001 10:26:47.555603  4916 solver.cpp:218] Iteration 81100 (20.4705 iter/s, 4.88509s/100 iters), loss = 0.0472311
I1001 10:26:47.555723  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0472312 (* 1 = 0.0472312 loss)
I1001 10:26:47.555732  4916 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1001 10:26:52.489975  4916 solver.cpp:218] Iteration 81200 (20.2666 iter/s, 4.93424s/100 iters), loss = 0.0154752
I1001 10:26:52.490005  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154752 (* 1 = 0.0154752 loss)
I1001 10:26:52.490011  4916 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1001 10:26:57.310509  4916 solver.cpp:218] Iteration 81300 (20.7448 iter/s, 4.82049s/100 iters), loss = 0.00994654
I1001 10:26:57.310541  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00994656 (* 1 = 0.00994656 loss)
I1001 10:26:57.310547  4916 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1001 10:27:02.122401  4916 solver.cpp:218] Iteration 81400 (20.7821 iter/s, 4.81184s/100 iters), loss = 0.00922573
I1001 10:27:02.122431  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00922574 (* 1 = 0.00922574 loss)
I1001 10:27:02.122437  4916 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1001 10:27:06.704237  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:27:06.896903  4916 solver.cpp:330] Iteration 81500, Testing net (#0)
I1001 10:27:07.972396  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:27:08.017858  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1001 10:27:08.017894  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339054 (* 1 = 0.339054 loss)
I1001 10:27:08.066498  4916 solver.cpp:218] Iteration 81500 (16.8236 iter/s, 5.94405s/100 iters), loss = 0.0116711
I1001 10:27:08.066522  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116712 (* 1 = 0.0116712 loss)
I1001 10:27:08.066529  4916 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1001 10:27:12.895647  4916 solver.cpp:218] Iteration 81600 (20.7078 iter/s, 4.8291s/100 iters), loss = 0.00848685
I1001 10:27:12.895678  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00848686 (* 1 = 0.00848686 loss)
I1001 10:27:12.895686  4916 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1001 10:27:17.721988  4916 solver.cpp:218] Iteration 81700 (20.7199 iter/s, 4.82629s/100 iters), loss = 0.0206464
I1001 10:27:17.722164  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206464 (* 1 = 0.0206464 loss)
I1001 10:27:17.722172  4916 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1001 10:27:22.538082  4916 solver.cpp:218] Iteration 81800 (20.7645 iter/s, 4.8159s/100 iters), loss = 0.00886033
I1001 10:27:22.538112  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00886035 (* 1 = 0.00886035 loss)
I1001 10:27:22.538120  4916 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1001 10:27:27.378010  4916 solver.cpp:218] Iteration 81900 (20.6617 iter/s, 4.83988s/100 iters), loss = 0.019641
I1001 10:27:27.378041  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019641 (* 1 = 0.019641 loss)
I1001 10:27:27.378051  4916 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1001 10:27:31.953189  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:27:32.146899  4916 solver.cpp:330] Iteration 82000, Testing net (#0)
I1001 10:27:33.230813  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:27:33.276372  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1001 10:27:33.276407  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336958 (* 1 = 0.336958 loss)
I1001 10:27:33.324867  4916 solver.cpp:218] Iteration 82000 (16.8158 iter/s, 5.9468s/100 iters), loss = 0.0108942
I1001 10:27:33.324908  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108942 (* 1 = 0.0108942 loss)
I1001 10:27:33.324915  4916 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1001 10:27:38.173702  4916 solver.cpp:218] Iteration 82100 (20.6238 iter/s, 4.84877s/100 iters), loss = 0.0131
I1001 10:27:38.173733  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131 (* 1 = 0.0131 loss)
I1001 10:27:38.173739  4916 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1001 10:27:43.075419  4916 solver.cpp:218] Iteration 82200 (20.4012 iter/s, 4.90166s/100 iters), loss = 0.00729878
I1001 10:27:43.075453  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0072988 (* 1 = 0.0072988 loss)
I1001 10:27:43.075472  4916 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1001 10:27:47.911025  4916 solver.cpp:218] Iteration 82300 (20.6802 iter/s, 4.83555s/100 iters), loss = 0.0239692
I1001 10:27:47.911126  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239692 (* 1 = 0.0239692 loss)
I1001 10:27:47.911134  4916 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1001 10:27:52.718639  4916 solver.cpp:218] Iteration 82400 (20.8008 iter/s, 4.8075s/100 iters), loss = 0.0108425
I1001 10:27:52.718679  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108425 (* 1 = 0.0108425 loss)
I1001 10:27:52.718685  4916 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1001 10:27:57.298115  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:27:57.492100  4916 solver.cpp:330] Iteration 82500, Testing net (#0)
I1001 10:27:58.567167  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:27:58.612820  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1001 10:27:58.612854  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338282 (* 1 = 0.338282 loss)
I1001 10:27:58.661491  4916 solver.cpp:218] Iteration 82500 (16.8271 iter/s, 5.94279s/100 iters), loss = 0.0112468
I1001 10:27:58.661515  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112469 (* 1 = 0.0112469 loss)
I1001 10:27:58.661532  4916 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1001 10:28:03.503113  4916 solver.cpp:218] Iteration 82600 (20.6544 iter/s, 4.84157s/100 iters), loss = 0.0251805
I1001 10:28:03.503154  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251806 (* 1 = 0.0251806 loss)
I1001 10:28:03.503160  4916 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1001 10:28:08.320073  4916 solver.cpp:218] Iteration 82700 (20.7603 iter/s, 4.8169s/100 iters), loss = 0.00417053
I1001 10:28:08.320113  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417057 (* 1 = 0.00417057 loss)
I1001 10:28:08.320121  4916 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1001 10:28:13.144623  4916 solver.cpp:218] Iteration 82800 (20.7276 iter/s, 4.82449s/100 iters), loss = 0.022852
I1001 10:28:13.144668  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022852 (* 1 = 0.022852 loss)
I1001 10:28:13.144675  4916 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1001 10:28:17.981930  4916 solver.cpp:218] Iteration 82900 (20.6729 iter/s, 4.83724s/100 iters), loss = 0.0359676
I1001 10:28:17.982112  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359676 (* 1 = 0.0359676 loss)
I1001 10:28:17.982121  4916 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1001 10:28:22.568423  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:28:22.761572  4916 solver.cpp:330] Iteration 83000, Testing net (#0)
I1001 10:28:23.854092  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:28:23.899977  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1001 10:28:23.900003  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337313 (* 1 = 0.337313 loss)
I1001 10:28:23.948597  4916 solver.cpp:218] Iteration 83000 (16.7603 iter/s, 5.96648s/100 iters), loss = 0.00758211
I1001 10:28:23.948632  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00758214 (* 1 = 0.00758214 loss)
I1001 10:28:23.948649  4916 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1001 10:28:28.767489  4916 solver.cpp:218] Iteration 83100 (20.7519 iter/s, 4.81884s/100 iters), loss = 0.0191447
I1001 10:28:28.767519  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191447 (* 1 = 0.0191447 loss)
I1001 10:28:28.767525  4916 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1001 10:28:33.597059  4916 solver.cpp:218] Iteration 83200 (20.706 iter/s, 4.82951s/100 iters), loss = 0.0106004
I1001 10:28:33.597095  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106004 (* 1 = 0.0106004 loss)
I1001 10:28:33.597102  4916 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1001 10:28:38.468914  4916 solver.cpp:218] Iteration 83300 (20.5263 iter/s, 4.8718s/100 iters), loss = 0.0647083
I1001 10:28:38.468960  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647084 (* 1 = 0.0647084 loss)
I1001 10:28:38.468966  4916 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1001 10:28:43.340684  4916 solver.cpp:218] Iteration 83400 (20.5268 iter/s, 4.87167s/100 iters), loss = 0.0282508
I1001 10:28:43.340718  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282508 (* 1 = 0.0282508 loss)
I1001 10:28:43.340725  4916 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1001 10:28:47.981145  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:28:48.176026  4916 solver.cpp:330] Iteration 83500, Testing net (#0)
I1001 10:28:49.265282  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:28:49.310542  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1001 10:28:49.310580  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338585 (* 1 = 0.338585 loss)
I1001 10:28:49.361434  4916 solver.cpp:218] Iteration 83500 (16.6094 iter/s, 6.02069s/100 iters), loss = 0.02248
I1001 10:28:49.361479  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02248 (* 1 = 0.02248 loss)
I1001 10:28:49.361486  4916 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1001 10:28:54.248204  4916 solver.cpp:218] Iteration 83600 (20.4639 iter/s, 4.88666s/100 iters), loss = 0.0131445
I1001 10:28:54.248241  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131445 (* 1 = 0.0131445 loss)
I1001 10:28:54.248248  4916 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1001 10:28:59.125566  4916 solver.cpp:218] Iteration 83700 (20.5031 iter/s, 4.87731s/100 iters), loss = 0.00635909
I1001 10:28:59.125607  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063591 (* 1 = 0.0063591 loss)
I1001 10:28:59.125612  4916 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1001 10:29:03.974831  4916 solver.cpp:218] Iteration 83800 (20.6219 iter/s, 4.84921s/100 iters), loss = 0.0122244
I1001 10:29:03.974862  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122244 (* 1 = 0.0122244 loss)
I1001 10:29:03.974879  4916 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1001 10:29:08.853771  4916 solver.cpp:218] Iteration 83900 (20.4965 iter/s, 4.87889s/100 iters), loss = 0.0233808
I1001 10:29:08.853828  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233808 (* 1 = 0.0233808 loss)
I1001 10:29:08.853845  4916 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1001 10:29:13.504153  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:29:13.697674  4916 solver.cpp:330] Iteration 84000, Testing net (#0)
I1001 10:29:14.790593  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:29:14.836658  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1001 10:29:14.836694  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335544 (* 1 = 0.335544 loss)
I1001 10:29:14.885299  4916 solver.cpp:218] Iteration 84000 (16.5797 iter/s, 6.03146s/100 iters), loss = 0.00617023
I1001 10:29:14.885330  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00617023 (* 1 = 0.00617023 loss)
I1001 10:29:14.885337  4916 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1001 10:29:19.771548  4916 solver.cpp:218] Iteration 84100 (20.4658 iter/s, 4.88619s/100 iters), loss = 0.00951585
I1001 10:29:19.771679  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951585 (* 1 = 0.00951585 loss)
I1001 10:29:19.771700  4916 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1001 10:29:24.670048  4916 solver.cpp:218] Iteration 84200 (20.415 iter/s, 4.89836s/100 iters), loss = 0.0287376
I1001 10:29:24.670089  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287376 (* 1 = 0.0287376 loss)
I1001 10:29:24.670094  4916 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1001 10:29:29.564193  4916 solver.cpp:218] Iteration 84300 (20.4328 iter/s, 4.89408s/100 iters), loss = 0.0077067
I1001 10:29:29.564229  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00770669 (* 1 = 0.00770669 loss)
I1001 10:29:29.564236  4916 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1001 10:29:34.417084  4916 solver.cpp:218] Iteration 84400 (20.6065 iter/s, 4.85284s/100 iters), loss = 0.0119699
I1001 10:29:34.417115  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119699 (* 1 = 0.0119699 loss)
I1001 10:29:34.417121  4916 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1001 10:29:39.064378  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:29:39.259153  4916 solver.cpp:330] Iteration 84500, Testing net (#0)
I1001 10:29:40.334628  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:29:40.380048  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.911
I1001 10:29:40.380084  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336932 (* 1 = 0.336932 loss)
I1001 10:29:40.429591  4916 solver.cpp:218] Iteration 84500 (16.6322 iter/s, 6.01245s/100 iters), loss = 0.00792903
I1001 10:29:40.429622  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00792903 (* 1 = 0.00792903 loss)
I1001 10:29:40.429630  4916 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1001 10:29:45.335707  4916 solver.cpp:218] Iteration 84600 (20.383 iter/s, 4.90606s/100 iters), loss = 0.00386633
I1001 10:29:45.335741  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386634 (* 1 = 0.00386634 loss)
I1001 10:29:45.335748  4916 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1001 10:29:50.202378  4916 solver.cpp:218] Iteration 84700 (20.5482 iter/s, 4.86661s/100 iters), loss = 0.0188946
I1001 10:29:50.202486  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188946 (* 1 = 0.0188946 loss)
I1001 10:29:50.202504  4916 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1001 10:29:55.076035  4916 solver.cpp:218] Iteration 84800 (20.519 iter/s, 4.87354s/100 iters), loss = 0.00630849
I1001 10:29:55.076066  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063085 (* 1 = 0.0063085 loss)
I1001 10:29:55.076072  4916 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1001 10:29:59.918758  4916 solver.cpp:218] Iteration 84900 (20.6498 iter/s, 4.84267s/100 iters), loss = 0.00465406
I1001 10:29:59.918789  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465407 (* 1 = 0.00465407 loss)
I1001 10:29:59.918807  4916 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1001 10:30:04.555521  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:30:04.752840  4916 solver.cpp:330] Iteration 85000, Testing net (#0)
I1001 10:30:05.838541  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:30:05.883883  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1001 10:30:05.883919  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337604 (* 1 = 0.337604 loss)
I1001 10:30:05.932260  4916 solver.cpp:218] Iteration 85000 (16.6294 iter/s, 6.01345s/100 iters), loss = 0.0041611
I1001 10:30:05.932292  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416111 (* 1 = 0.00416111 loss)
I1001 10:30:05.932298  4916 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1001 10:30:10.796056  4916 solver.cpp:218] Iteration 85100 (20.5603 iter/s, 4.86374s/100 iters), loss = 0.00888078
I1001 10:30:10.796097  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0088808 (* 1 = 0.0088808 loss)
I1001 10:30:10.796103  4916 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1001 10:30:15.649212  4916 solver.cpp:218] Iteration 85200 (20.6054 iter/s, 4.8531s/100 iters), loss = 0.00861024
I1001 10:30:15.649245  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00861025 (* 1 = 0.00861025 loss)
I1001 10:30:15.649263  4916 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1001 10:30:20.502928  4916 solver.cpp:218] Iteration 85300 (20.603 iter/s, 4.85366s/100 iters), loss = 0.055102
I1001 10:30:20.503046  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055102 (* 1 = 0.055102 loss)
I1001 10:30:20.503054  4916 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1001 10:30:25.342407  4916 solver.cpp:218] Iteration 85400 (20.6639 iter/s, 4.83935s/100 iters), loss = 0.0161764
I1001 10:30:25.342447  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161764 (* 1 = 0.0161764 loss)
I1001 10:30:25.342453  4916 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1001 10:30:29.952215  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:30:30.152544  4916 solver.cpp:330] Iteration 85500, Testing net (#0)
I1001 10:30:31.250515  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:30:31.296167  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1001 10:30:31.296192  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33693 (* 1 = 0.33693 loss)
I1001 10:30:31.344868  4916 solver.cpp:218] Iteration 85500 (16.66 iter/s, 6.0024s/100 iters), loss = 0.0379576
I1001 10:30:31.344895  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0379576 (* 1 = 0.0379576 loss)
I1001 10:30:31.344902  4916 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1001 10:30:36.224773  4916 solver.cpp:218] Iteration 85600 (20.4924 iter/s, 4.87985s/100 iters), loss = 0.012369
I1001 10:30:36.224807  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012369 (* 1 = 0.012369 loss)
I1001 10:30:36.224815  4916 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1001 10:30:41.084867  4916 solver.cpp:218] Iteration 85700 (20.576 iter/s, 4.86004s/100 iters), loss = 0.0134415
I1001 10:30:41.084904  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134415 (* 1 = 0.0134415 loss)
I1001 10:30:41.084914  4916 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1001 10:30:45.936602  4916 solver.cpp:218] Iteration 85800 (20.6114 iter/s, 4.85168s/100 iters), loss = 0.00486276
I1001 10:30:45.936637  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486275 (* 1 = 0.00486275 loss)
I1001 10:30:45.936646  4916 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1001 10:30:50.761152  4916 solver.cpp:218] Iteration 85900 (20.7276 iter/s, 4.8245s/100 iters), loss = 0.00261873
I1001 10:30:50.761250  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261872 (* 1 = 0.00261872 loss)
I1001 10:30:50.761258  4916 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1001 10:30:55.340325  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:30:55.533399  4916 solver.cpp:330] Iteration 86000, Testing net (#0)
I1001 10:30:56.614576  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:30:56.659888  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1001 10:30:56.659915  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338621 (* 1 = 0.338621 loss)
I1001 10:30:56.708984  4916 solver.cpp:218] Iteration 86000 (16.8132 iter/s, 5.94771s/100 iters), loss = 0.00887796
I1001 10:30:56.709020  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00887795 (* 1 = 0.00887795 loss)
I1001 10:30:56.709029  4916 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1001 10:31:01.524653  4916 solver.cpp:218] Iteration 86100 (20.7658 iter/s, 4.81562s/100 iters), loss = 0.0261517
I1001 10:31:01.524694  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261517 (* 1 = 0.0261517 loss)
I1001 10:31:01.524700  4916 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1001 10:31:06.340188  4916 solver.cpp:218] Iteration 86200 (20.7664 iter/s, 4.81547s/100 iters), loss = 0.0277447
I1001 10:31:06.340216  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277447 (* 1 = 0.0277447 loss)
I1001 10:31:06.340224  4916 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1001 10:31:11.156488  4916 solver.cpp:218] Iteration 86300 (20.763 iter/s, 4.81625s/100 iters), loss = 0.00354064
I1001 10:31:11.156517  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354064 (* 1 = 0.00354064 loss)
I1001 10:31:11.156523  4916 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1001 10:31:15.977360  4916 solver.cpp:218] Iteration 86400 (20.7434 iter/s, 4.82082s/100 iters), loss = 0.00497646
I1001 10:31:15.977401  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497646 (* 1 = 0.00497646 loss)
I1001 10:31:15.977406  4916 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1001 10:31:20.564616  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:31:20.759877  4916 solver.cpp:330] Iteration 86500, Testing net (#0)
I1001 10:31:21.834671  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:31:21.879770  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1001 10:31:21.879803  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338185 (* 1 = 0.338185 loss)
I1001 10:31:21.928150  4916 solver.cpp:218] Iteration 86500 (16.8047 iter/s, 5.95073s/100 iters), loss = 0.0183216
I1001 10:31:21.928181  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183216 (* 1 = 0.0183216 loss)
I1001 10:31:21.928189  4916 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1001 10:31:26.774396  4916 solver.cpp:218] Iteration 86600 (20.6348 iter/s, 4.84619s/100 iters), loss = 0.0148126
I1001 10:31:26.774430  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148126 (* 1 = 0.0148126 loss)
I1001 10:31:26.774436  4916 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1001 10:31:31.606223  4916 solver.cpp:218] Iteration 86700 (20.6964 iter/s, 4.83177s/100 iters), loss = 0.00473164
I1001 10:31:31.606254  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473163 (* 1 = 0.00473163 loss)
I1001 10:31:31.606261  4916 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1001 10:31:36.473680  4916 solver.cpp:218] Iteration 86800 (20.5458 iter/s, 4.86717s/100 iters), loss = 0.00412558
I1001 10:31:36.473711  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412556 (* 1 = 0.00412556 loss)
I1001 10:31:36.473718  4916 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1001 10:31:41.296628  4916 solver.cpp:218] Iteration 86900 (20.7344 iter/s, 4.8229s/100 iters), loss = 0.00823707
I1001 10:31:41.296672  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823705 (* 1 = 0.00823705 loss)
I1001 10:31:41.296679  4916 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1001 10:31:45.896944  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:31:46.089534  4916 solver.cpp:330] Iteration 87000, Testing net (#0)
I1001 10:31:47.167641  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:31:47.213127  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1001 10:31:47.213163  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340337 (* 1 = 0.340337 loss)
I1001 10:31:47.261565  4916 solver.cpp:218] Iteration 87000 (16.7648 iter/s, 5.96488s/100 iters), loss = 0.00601797
I1001 10:31:47.261595  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601796 (* 1 = 0.00601796 loss)
I1001 10:31:47.261602  4916 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1001 10:31:52.087748  4916 solver.cpp:218] Iteration 87100 (20.7205 iter/s, 4.82613s/100 iters), loss = 0.00456266
I1001 10:31:52.087860  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456265 (* 1 = 0.00456265 loss)
I1001 10:31:52.087877  4916 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1001 10:31:56.913985  4916 solver.cpp:218] Iteration 87200 (20.7206 iter/s, 4.82611s/100 iters), loss = 0.0202347
I1001 10:31:56.914016  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202347 (* 1 = 0.0202347 loss)
I1001 10:31:56.914032  4916 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1001 10:32:01.773200  4916 solver.cpp:218] Iteration 87300 (20.5797 iter/s, 4.85916s/100 iters), loss = 0.00902766
I1001 10:32:01.773238  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902766 (* 1 = 0.00902766 loss)
I1001 10:32:01.773247  4916 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1001 10:32:06.643188  4916 solver.cpp:218] Iteration 87400 (20.5342 iter/s, 4.86993s/100 iters), loss = 0.00319258
I1001 10:32:06.643218  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319257 (* 1 = 0.00319257 loss)
I1001 10:32:06.643224  4916 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1001 10:32:11.240998  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:32:11.439581  4916 solver.cpp:330] Iteration 87500, Testing net (#0)
I1001 10:32:12.519846  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:32:12.565373  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1001 10:32:12.565408  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339744 (* 1 = 0.339744 loss)
I1001 10:32:12.614332  4916 solver.cpp:218] Iteration 87500 (16.7474 iter/s, 5.97109s/100 iters), loss = 0.00936741
I1001 10:32:12.614359  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00936741 (* 1 = 0.00936741 loss)
I1001 10:32:12.614365  4916 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1001 10:32:17.431450  4916 solver.cpp:218] Iteration 87600 (20.7595 iter/s, 4.81707s/100 iters), loss = 0.00609427
I1001 10:32:17.431488  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609427 (* 1 = 0.00609427 loss)
I1001 10:32:17.431496  4916 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1001 10:32:22.253404  4916 solver.cpp:218] Iteration 87700 (20.7387 iter/s, 4.8219s/100 iters), loss = 0.00389429
I1001 10:32:22.253554  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389429 (* 1 = 0.00389429 loss)
I1001 10:32:22.253576  4916 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1001 10:32:27.081383  4916 solver.cpp:218] Iteration 87800 (20.7133 iter/s, 4.82782s/100 iters), loss = 0.00429635
I1001 10:32:27.081414  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429634 (* 1 = 0.00429634 loss)
I1001 10:32:27.081420  4916 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1001 10:32:31.894884  4916 solver.cpp:218] Iteration 87900 (20.7751 iter/s, 4.81345s/100 iters), loss = 0.00403238
I1001 10:32:31.894917  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403236 (* 1 = 0.00403236 loss)
I1001 10:32:31.894923  4916 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1001 10:32:36.473731  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:32:36.666399  4916 solver.cpp:330] Iteration 88000, Testing net (#0)
I1001 10:32:37.740270  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:32:37.785770  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9115
I1001 10:32:37.785795  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340939 (* 1 = 0.340939 loss)
I1001 10:32:37.834095  4916 solver.cpp:218] Iteration 88000 (16.8375 iter/s, 5.93912s/100 iters), loss = 0.00302343
I1001 10:32:37.834123  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302342 (* 1 = 0.00302342 loss)
I1001 10:32:37.834131  4916 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1001 10:32:42.651039  4916 solver.cpp:218] Iteration 88100 (20.7603 iter/s, 4.8169s/100 iters), loss = 0.00795679
I1001 10:32:42.651082  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00795678 (* 1 = 0.00795678 loss)
I1001 10:32:42.651088  4916 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1001 10:32:47.471134  4916 solver.cpp:218] Iteration 88200 (20.7468 iter/s, 4.82003s/100 iters), loss = 0.028196
I1001 10:32:47.471169  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028196 (* 1 = 0.028196 loss)
I1001 10:32:47.471176  4916 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1001 10:32:52.295388  4916 solver.cpp:218] Iteration 88300 (20.7288 iter/s, 4.8242s/100 iters), loss = 0.0115742
I1001 10:32:52.295485  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115742 (* 1 = 0.0115742 loss)
I1001 10:32:52.295501  4916 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1001 10:32:57.121812  4916 solver.cpp:218] Iteration 88400 (20.7198 iter/s, 4.82631s/100 iters), loss = 0.0215137
I1001 10:32:57.121845  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215136 (* 1 = 0.0215136 loss)
I1001 10:32:57.121851  4916 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1001 10:33:01.695981  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:33:01.888120  4916 solver.cpp:330] Iteration 88500, Testing net (#0)
I1001 10:33:02.971565  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:33:03.017143  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1001 10:33:03.017179  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338415 (* 1 = 0.338415 loss)
I1001 10:33:03.065881  4916 solver.cpp:218] Iteration 88500 (16.8236 iter/s, 5.94402s/100 iters), loss = 0.00662498
I1001 10:33:03.065907  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00662496 (* 1 = 0.00662496 loss)
I1001 10:33:03.065913  4916 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1001 10:33:07.879545  4916 solver.cpp:218] Iteration 88600 (20.7744 iter/s, 4.81361s/100 iters), loss = 0.022603
I1001 10:33:07.879575  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022603 (* 1 = 0.022603 loss)
I1001 10:33:07.879592  4916 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1001 10:33:12.703768  4916 solver.cpp:218] Iteration 88700 (20.7289 iter/s, 4.82417s/100 iters), loss = 0.0135099
I1001 10:33:12.703806  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135098 (* 1 = 0.0135098 loss)
I1001 10:33:12.703812  4916 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1001 10:33:17.518707  4916 solver.cpp:218] Iteration 88800 (20.769 iter/s, 4.81488s/100 iters), loss = 0.00750049
I1001 10:33:17.518740  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750046 (* 1 = 0.00750046 loss)
I1001 10:33:17.518748  4916 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1001 10:33:22.329123  4916 solver.cpp:218] Iteration 88900 (20.7885 iter/s, 4.81036s/100 iters), loss = 0.00379445
I1001 10:33:22.329265  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379441 (* 1 = 0.00379441 loss)
I1001 10:33:22.329283  4916 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1001 10:33:26.910235  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:33:27.102855  4916 solver.cpp:330] Iteration 89000, Testing net (#0)
I1001 10:33:28.177196  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:33:28.222491  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.91
I1001 10:33:28.222528  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338302 (* 1 = 0.338302 loss)
I1001 10:33:28.271443  4916 solver.cpp:218] Iteration 89000 (16.8289 iter/s, 5.94216s/100 iters), loss = 0.0234601
I1001 10:33:28.271468  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234601 (* 1 = 0.0234601 loss)
I1001 10:33:28.271474  4916 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1001 10:33:33.090394  4916 solver.cpp:218] Iteration 89100 (20.7516 iter/s, 4.8189s/100 iters), loss = 0.0070789
I1001 10:33:33.090423  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707887 (* 1 = 0.00707887 loss)
I1001 10:33:33.090430  4916 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1001 10:33:37.905638  4916 solver.cpp:218] Iteration 89200 (20.7676 iter/s, 4.8152s/100 iters), loss = 0.0252943
I1001 10:33:37.905668  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252943 (* 1 = 0.0252943 loss)
I1001 10:33:37.905674  4916 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1001 10:33:42.729956  4916 solver.cpp:218] Iteration 89300 (20.7285 iter/s, 4.82426s/100 iters), loss = 0.00908756
I1001 10:33:42.729987  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00908753 (* 1 = 0.00908753 loss)
I1001 10:33:42.729993  4916 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1001 10:33:47.551558  4916 solver.cpp:218] Iteration 89400 (20.7403 iter/s, 4.82154s/100 iters), loss = 0.00193259
I1001 10:33:47.551599  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193256 (* 1 = 0.00193256 loss)
I1001 10:33:47.551612  4916 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1001 10:33:52.130144  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:33:52.322811  4916 solver.cpp:330] Iteration 89500, Testing net (#0)
I1001 10:33:53.401195  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:33:53.446508  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9105
I1001 10:33:53.446550  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338175 (* 1 = 0.338175 loss)
I1001 10:33:53.497005  4916 solver.cpp:218] Iteration 89500 (16.8199 iter/s, 5.94535s/100 iters), loss = 0.0083195
I1001 10:33:53.497047  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831948 (* 1 = 0.00831948 loss)
I1001 10:33:53.497058  4916 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1001 10:33:58.320313  4916 solver.cpp:218] Iteration 89600 (20.7329 iter/s, 4.82325s/100 iters), loss = 0.0057669
I1001 10:33:58.320346  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576687 (* 1 = 0.00576687 loss)
I1001 10:33:58.320354  4916 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1001 10:34:03.143743  4916 solver.cpp:218] Iteration 89700 (20.7324 iter/s, 4.82338s/100 iters), loss = 0.00500437
I1001 10:34:03.143784  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500434 (* 1 = 0.00500434 loss)
I1001 10:34:03.143790  4916 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1001 10:34:07.958086  4916 solver.cpp:218] Iteration 89800 (20.7715 iter/s, 4.81428s/100 iters), loss = 0.0468129
I1001 10:34:07.958117  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0468128 (* 1 = 0.0468128 loss)
I1001 10:34:07.958122  4916 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1001 10:34:12.782294  4916 solver.cpp:218] Iteration 89900 (20.729 iter/s, 4.82416s/100 iters), loss = 0.00785566
I1001 10:34:12.782325  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785563 (* 1 = 0.00785563 loss)
I1001 10:34:12.782332  4916 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1001 10:34:17.350742  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:34:17.547595  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_90000.caffemodel
I1001 10:34:17.552121  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_90000.solverstate
I1001 10:34:17.553470  4916 solver.cpp:330] Iteration 90000, Testing net (#0)
I1001 10:34:18.631309  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:34:18.676262  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1001 10:34:18.676297  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33806 (* 1 = 0.33806 loss)
I1001 10:34:18.724931  4916 solver.cpp:218] Iteration 90000 (16.8277 iter/s, 5.94259s/100 iters), loss = 0.00825129
I1001 10:34:18.724957  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825125 (* 1 = 0.00825125 loss)
I1001 10:34:18.724964  4916 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1001 10:34:23.544474  4916 solver.cpp:218] Iteration 90100 (20.7491 iter/s, 4.8195s/100 iters), loss = 0.00864407
I1001 10:34:23.544616  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00864404 (* 1 = 0.00864404 loss)
I1001 10:34:23.544625  4916 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1001 10:34:28.363250  4916 solver.cpp:218] Iteration 90200 (20.7528 iter/s, 4.81863s/100 iters), loss = 0.00412868
I1001 10:34:28.363289  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412865 (* 1 = 0.00412865 loss)
I1001 10:34:28.363296  4916 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1001 10:34:33.188174  4916 solver.cpp:218] Iteration 90300 (20.7259 iter/s, 4.82487s/100 iters), loss = 0.00523755
I1001 10:34:33.188207  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523752 (* 1 = 0.00523752 loss)
I1001 10:34:33.188213  4916 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1001 10:34:38.002529  4916 solver.cpp:218] Iteration 90400 (20.7714 iter/s, 4.8143s/100 iters), loss = 0.00112115
I1001 10:34:38.002559  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112111 (* 1 = 0.00112111 loss)
I1001 10:34:38.002565  4916 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1001 10:34:42.581468  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:34:42.774482  4916 solver.cpp:330] Iteration 90500, Testing net (#0)
I1001 10:34:43.850692  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:34:43.895555  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1001 10:34:43.895589  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338036 (* 1 = 0.338036 loss)
I1001 10:34:43.944154  4916 solver.cpp:218] Iteration 90500 (16.8306 iter/s, 5.94157s/100 iters), loss = 0.0107487
I1001 10:34:43.944185  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107487 (* 1 = 0.0107487 loss)
I1001 10:34:43.944191  4916 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1001 10:34:48.764266  4916 solver.cpp:218] Iteration 90600 (20.7466 iter/s, 4.82006s/100 iters), loss = 0.0131396
I1001 10:34:48.764294  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131396 (* 1 = 0.0131396 loss)
I1001 10:34:48.764310  4916 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1001 10:34:53.581307  4916 solver.cpp:218] Iteration 90700 (20.7598 iter/s, 4.81699s/100 iters), loss = 0.0107703
I1001 10:34:53.581450  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107702 (* 1 = 0.0107702 loss)
I1001 10:34:53.581459  4916 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1001 10:34:58.394274  4916 solver.cpp:218] Iteration 90800 (20.7779 iter/s, 4.81281s/100 iters), loss = 0.00350589
I1001 10:34:58.394317  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350585 (* 1 = 0.00350585 loss)
I1001 10:34:58.394323  4916 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1001 10:35:03.214166  4916 solver.cpp:218] Iteration 90900 (20.7476 iter/s, 4.81983s/100 iters), loss = 0.00451339
I1001 10:35:03.214198  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451335 (* 1 = 0.00451335 loss)
I1001 10:35:03.214205  4916 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1001 10:35:07.786494  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:35:07.978817  4916 solver.cpp:330] Iteration 91000, Testing net (#0)
I1001 10:35:09.063415  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:35:09.108615  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1001 10:35:09.108651  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337492 (* 1 = 0.337492 loss)
I1001 10:35:09.157594  4916 solver.cpp:218] Iteration 91000 (16.8255 iter/s, 5.94337s/100 iters), loss = 0.0174875
I1001 10:35:09.157635  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174875 (* 1 = 0.0174875 loss)
I1001 10:35:09.157644  4916 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1001 10:35:13.969918  4916 solver.cpp:218] Iteration 91100 (20.7802 iter/s, 4.81226s/100 iters), loss = 0.0106864
I1001 10:35:13.969959  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106864 (* 1 = 0.0106864 loss)
I1001 10:35:13.969965  4916 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1001 10:35:18.795619  4916 solver.cpp:218] Iteration 91200 (20.7226 iter/s, 4.82564s/100 iters), loss = 0.0135757
I1001 10:35:18.795646  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135757 (* 1 = 0.0135757 loss)
I1001 10:35:18.795652  4916 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1001 10:35:23.620762  4916 solver.cpp:218] Iteration 91300 (20.725 iter/s, 4.8251s/100 iters), loss = 0.0119961
I1001 10:35:23.620887  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011996 (* 1 = 0.011996 loss)
I1001 10:35:23.620906  4916 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1001 10:35:28.440196  4916 solver.cpp:218] Iteration 91400 (20.7499 iter/s, 4.8193s/100 iters), loss = 0.00405785
I1001 10:35:28.440227  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040578 (* 1 = 0.0040578 loss)
I1001 10:35:28.440232  4916 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1001 10:35:33.022274  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:35:33.214581  4916 solver.cpp:330] Iteration 91500, Testing net (#0)
I1001 10:35:34.288760  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:35:34.334259  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1001 10:35:34.334283  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338087 (* 1 = 0.338087 loss)
I1001 10:35:34.382848  4916 solver.cpp:218] Iteration 91500 (16.8276 iter/s, 5.9426s/100 iters), loss = 0.0058357
I1001 10:35:34.382874  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583565 (* 1 = 0.00583565 loss)
I1001 10:35:34.382880  4916 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1001 10:35:39.202996  4916 solver.cpp:218] Iteration 91600 (20.7464 iter/s, 4.8201s/100 iters), loss = 0.0128298
I1001 10:35:39.203027  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128297 (* 1 = 0.0128297 loss)
I1001 10:35:39.203032  4916 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1001 10:35:44.017366  4916 solver.cpp:218] Iteration 91700 (20.7714 iter/s, 4.81432s/100 iters), loss = 0.00358326
I1001 10:35:44.017397  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358322 (* 1 = 0.00358322 loss)
I1001 10:35:44.017403  4916 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1001 10:35:48.833950  4916 solver.cpp:218] Iteration 91800 (20.7618 iter/s, 4.81653s/100 iters), loss = 0.00752723
I1001 10:35:48.833992  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752719 (* 1 = 0.00752719 loss)
I1001 10:35:48.833997  4916 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1001 10:35:53.656378  4916 solver.cpp:218] Iteration 91900 (20.7367 iter/s, 4.82236s/100 iters), loss = 0.0176827
I1001 10:35:53.656528  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176826 (* 1 = 0.0176826 loss)
I1001 10:35:53.656548  4916 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1001 10:35:58.230325  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:35:58.423419  4916 solver.cpp:330] Iteration 92000, Testing net (#0)
I1001 10:35:59.500478  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:35:59.546834  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.911
I1001 10:35:59.546869  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336649 (* 1 = 0.336649 loss)
I1001 10:35:59.596807  4916 solver.cpp:218] Iteration 92000 (16.8343 iter/s, 5.94027s/100 iters), loss = 0.0129543
I1001 10:35:59.596843  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129543 (* 1 = 0.0129543 loss)
I1001 10:35:59.596850  4916 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1001 10:36:04.410573  4916 solver.cpp:218] Iteration 92100 (20.774 iter/s, 4.81371s/100 iters), loss = 0.00812386
I1001 10:36:04.410603  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00812384 (* 1 = 0.00812384 loss)
I1001 10:36:04.410609  4916 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1001 10:36:09.234969  4916 solver.cpp:218] Iteration 92200 (20.7282 iter/s, 4.82435s/100 iters), loss = 0.00914745
I1001 10:36:09.235010  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914743 (* 1 = 0.00914743 loss)
I1001 10:36:09.235016  4916 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1001 10:36:14.046834  4916 solver.cpp:218] Iteration 92300 (20.7822 iter/s, 4.8118s/100 iters), loss = 0.00629368
I1001 10:36:14.046864  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00629366 (* 1 = 0.00629366 loss)
I1001 10:36:14.046870  4916 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1001 10:36:18.874063  4916 solver.cpp:218] Iteration 92400 (20.716 iter/s, 4.82718s/100 iters), loss = 0.00600997
I1001 10:36:18.874094  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600996 (* 1 = 0.00600996 loss)
I1001 10:36:18.874100  4916 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1001 10:36:23.447980  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:36:23.645133  4916 solver.cpp:330] Iteration 92500, Testing net (#0)
I1001 10:36:24.723316  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:36:24.769165  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1001 10:36:24.769201  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339173 (* 1 = 0.339173 loss)
I1001 10:36:24.818752  4916 solver.cpp:218] Iteration 92500 (16.8219 iter/s, 5.94463s/100 iters), loss = 0.00412616
I1001 10:36:24.818783  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412615 (* 1 = 0.00412615 loss)
I1001 10:36:24.818790  4916 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1001 10:36:29.632062  4916 solver.cpp:218] Iteration 92600 (20.776 iter/s, 4.81326s/100 iters), loss = 0.00710684
I1001 10:36:29.632097  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710683 (* 1 = 0.00710683 loss)
I1001 10:36:29.632103  4916 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1001 10:36:34.444461  4916 solver.cpp:218] Iteration 92700 (20.7799 iter/s, 4.81235s/100 iters), loss = 0.0167299
I1001 10:36:34.444491  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167299 (* 1 = 0.0167299 loss)
I1001 10:36:34.444497  4916 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1001 10:36:39.263037  4916 solver.cpp:218] Iteration 92800 (20.7532 iter/s, 4.81852s/100 iters), loss = 0.0285476
I1001 10:36:39.263088  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285476 (* 1 = 0.0285476 loss)
I1001 10:36:39.263095  4916 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1001 10:36:44.065865  4916 solver.cpp:218] Iteration 92900 (20.8217 iter/s, 4.80267s/100 iters), loss = 0.00195885
I1001 10:36:44.065907  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195883 (* 1 = 0.00195883 loss)
I1001 10:36:44.065912  4916 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1001 10:36:48.646423  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:36:48.839052  4916 solver.cpp:330] Iteration 93000, Testing net (#0)
I1001 10:36:49.915164  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:36:49.960480  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1001 10:36:49.960515  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339339 (* 1 = 0.339339 loss)
I1001 10:36:50.009390  4916 solver.cpp:218] Iteration 93000 (16.8252 iter/s, 5.94347s/100 iters), loss = 0.0136775
I1001 10:36:50.009415  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136775 (* 1 = 0.0136775 loss)
I1001 10:36:50.009423  4916 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1001 10:36:54.834475  4916 solver.cpp:218] Iteration 93100 (20.7252 iter/s, 4.82504s/100 iters), loss = 0.0088425
I1001 10:36:54.834578  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00884249 (* 1 = 0.00884249 loss)
I1001 10:36:54.834585  4916 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1001 10:36:59.659927  4916 solver.cpp:218] Iteration 93200 (20.724 iter/s, 4.82532s/100 iters), loss = 0.0159454
I1001 10:36:59.659960  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159454 (* 1 = 0.0159454 loss)
I1001 10:36:59.659967  4916 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1001 10:37:04.480577  4916 solver.cpp:218] Iteration 93300 (20.7443 iter/s, 4.8206s/100 iters), loss = 0.00827076
I1001 10:37:04.480618  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827075 (* 1 = 0.00827075 loss)
I1001 10:37:04.480624  4916 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1001 10:37:09.295097  4916 solver.cpp:218] Iteration 93400 (20.7712 iter/s, 4.81437s/100 iters), loss = 0.035671
I1001 10:37:09.295140  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035671 (* 1 = 0.035671 loss)
I1001 10:37:09.295147  4916 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1001 10:37:13.864912  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:37:14.057718  4916 solver.cpp:330] Iteration 93500, Testing net (#0)
I1001 10:37:15.140074  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:37:15.185559  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1001 10:37:15.185585  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337433 (* 1 = 0.337433 loss)
I1001 10:37:15.234133  4916 solver.cpp:218] Iteration 93500 (16.838 iter/s, 5.93893s/100 iters), loss = 0.0187335
I1001 10:37:15.234163  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187335 (* 1 = 0.0187335 loss)
I1001 10:37:15.234170  4916 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1001 10:37:20.044548  4916 solver.cpp:218] Iteration 93600 (20.7885 iter/s, 4.81036s/100 iters), loss = 0.0109032
I1001 10:37:20.044576  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109032 (* 1 = 0.0109032 loss)
I1001 10:37:20.044582  4916 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1001 10:37:24.862988  4916 solver.cpp:218] Iteration 93700 (20.7538 iter/s, 4.81839s/100 iters), loss = 0.0137815
I1001 10:37:24.863143  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137815 (* 1 = 0.0137815 loss)
I1001 10:37:24.863152  4916 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1001 10:37:29.680012  4916 solver.cpp:218] Iteration 93800 (20.7604 iter/s, 4.81686s/100 iters), loss = 0.0101348
I1001 10:37:29.680055  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101348 (* 1 = 0.0101348 loss)
I1001 10:37:29.680063  4916 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1001 10:37:34.491706  4916 solver.cpp:218] Iteration 93900 (20.7831 iter/s, 4.8116s/100 iters), loss = 0.0121246
I1001 10:37:34.491736  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121246 (* 1 = 0.0121246 loss)
I1001 10:37:34.491742  4916 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1001 10:37:39.075753  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:37:39.268167  4916 solver.cpp:330] Iteration 94000, Testing net (#0)
I1001 10:37:40.343874  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:37:40.389379  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1001 10:37:40.389415  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339518 (* 1 = 0.339518 loss)
I1001 10:37:40.437880  4916 solver.cpp:218] Iteration 94000 (16.8177 iter/s, 5.94612s/100 iters), loss = 0.00444118
I1001 10:37:40.437904  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444118 (* 1 = 0.00444118 loss)
I1001 10:37:40.437911  4916 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1001 10:37:45.259804  4916 solver.cpp:218] Iteration 94100 (20.7388 iter/s, 4.82188s/100 iters), loss = 0.0106264
I1001 10:37:45.259838  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106264 (* 1 = 0.0106264 loss)
I1001 10:37:45.259845  4916 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1001 10:37:50.069136  4916 solver.cpp:218] Iteration 94200 (20.7931 iter/s, 4.80928s/100 iters), loss = 0.0125553
I1001 10:37:50.069166  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125553 (* 1 = 0.0125553 loss)
I1001 10:37:50.069172  4916 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1001 10:37:54.888073  4916 solver.cpp:218] Iteration 94300 (20.7517 iter/s, 4.81888s/100 iters), loss = 0.0067194
I1001 10:37:54.888177  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067194 (* 1 = 0.0067194 loss)
I1001 10:37:54.888185  4916 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1001 10:37:59.714049  4916 solver.cpp:218] Iteration 94400 (20.7219 iter/s, 4.8258s/100 iters), loss = 0.00152904
I1001 10:37:59.714088  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152904 (* 1 = 0.00152904 loss)
I1001 10:37:59.714097  4916 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1001 10:38:04.312289  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:38:04.507547  4916 solver.cpp:330] Iteration 94500, Testing net (#0)
I1001 10:38:05.592571  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:38:05.636958  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1001 10:38:05.636984  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33978 (* 1 = 0.33978 loss)
I1001 10:38:05.684682  4916 solver.cpp:218] Iteration 94500 (16.7488 iter/s, 5.97058s/100 iters), loss = 0.00263157
I1001 10:38:05.684712  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263157 (* 1 = 0.00263157 loss)
I1001 10:38:05.684720  4916 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1001 10:38:10.523473  4916 solver.cpp:218] Iteration 94600 (20.6667 iter/s, 4.83871s/100 iters), loss = 0.00680182
I1001 10:38:10.523504  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680182 (* 1 = 0.00680182 loss)
I1001 10:38:10.523510  4916 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1001 10:38:15.373502  4916 solver.cpp:218] Iteration 94700 (20.6187 iter/s, 4.84997s/100 iters), loss = 0.00702085
I1001 10:38:15.373531  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702085 (* 1 = 0.00702085 loss)
I1001 10:38:15.373538  4916 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1001 10:38:20.200554  4916 solver.cpp:218] Iteration 94800 (20.7168 iter/s, 4.827s/100 iters), loss = 0.00687349
I1001 10:38:20.200584  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068735 (* 1 = 0.0068735 loss)
I1001 10:38:20.200590  4916 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1001 10:38:25.061877  4916 solver.cpp:218] Iteration 94900 (20.5708 iter/s, 4.86127s/100 iters), loss = 0.0035541
I1001 10:38:25.062014  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355411 (* 1 = 0.00355411 loss)
I1001 10:38:25.062024  4916 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1001 10:38:29.650418  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:38:29.845948  4916 solver.cpp:330] Iteration 95000, Testing net (#0)
I1001 10:38:30.924612  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:38:30.969745  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1001 10:38:30.969780  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339999 (* 1 = 0.339999 loss)
I1001 10:38:31.018005  4916 solver.cpp:218] Iteration 95000 (16.79 iter/s, 5.95593s/100 iters), loss = 0.00864594
I1001 10:38:31.018030  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00864595 (* 1 = 0.00864595 loss)
I1001 10:38:31.018038  4916 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1001 10:38:35.871476  4916 solver.cpp:218] Iteration 95100 (20.604 iter/s, 4.85342s/100 iters), loss = 0.00746573
I1001 10:38:35.871511  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00746573 (* 1 = 0.00746573 loss)
I1001 10:38:35.871518  4916 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1001 10:38:40.687738  4916 solver.cpp:218] Iteration 95200 (20.7633 iter/s, 4.8162s/100 iters), loss = 0.00863123
I1001 10:38:40.687769  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00863123 (* 1 = 0.00863123 loss)
I1001 10:38:40.687785  4916 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1001 10:38:45.513341  4916 solver.cpp:218] Iteration 95300 (20.723 iter/s, 4.82555s/100 iters), loss = 0.00909705
I1001 10:38:45.513383  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00909705 (* 1 = 0.00909705 loss)
I1001 10:38:45.513389  4916 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1001 10:38:50.323248  4916 solver.cpp:218] Iteration 95400 (20.7907 iter/s, 4.80985s/100 iters), loss = 0.00236477
I1001 10:38:50.323290  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236477 (* 1 = 0.00236477 loss)
I1001 10:38:50.323295  4916 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1001 10:38:54.904374  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:38:55.098469  4916 solver.cpp:330] Iteration 95500, Testing net (#0)
I1001 10:38:56.173436  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:38:56.219125  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1001 10:38:56.219151  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34019 (* 1 = 0.34019 loss)
I1001 10:38:56.267787  4916 solver.cpp:218] Iteration 95500 (16.8223 iter/s, 5.94448s/100 iters), loss = 0.00190015
I1001 10:38:56.267815  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190015 (* 1 = 0.00190015 loss)
I1001 10:38:56.267823  4916 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1001 10:39:01.090381  4916 solver.cpp:218] Iteration 95600 (20.7359 iter/s, 4.82254s/100 iters), loss = 0.00397841
I1001 10:39:01.090415  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039784 (* 1 = 0.0039784 loss)
I1001 10:39:01.090423  4916 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1001 10:39:05.900480  4916 solver.cpp:218] Iteration 95700 (20.7898 iter/s, 4.81005s/100 iters), loss = 0.0153483
I1001 10:39:05.900513  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153483 (* 1 = 0.0153483 loss)
I1001 10:39:05.900532  4916 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1001 10:39:10.714845  4916 solver.cpp:218] Iteration 95800 (20.7714 iter/s, 4.81431s/100 iters), loss = 0.00350678
I1001 10:39:10.714887  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350678 (* 1 = 0.00350678 loss)
I1001 10:39:10.714893  4916 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1001 10:39:15.537195  4916 solver.cpp:218] Iteration 95900 (20.737 iter/s, 4.82229s/100 iters), loss = 0.0209373
I1001 10:39:15.537225  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209373 (* 1 = 0.0209373 loss)
I1001 10:39:15.537231  4916 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1001 10:39:20.113497  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:39:20.305058  4916 solver.cpp:330] Iteration 96000, Testing net (#0)
I1001 10:39:21.388862  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:39:21.434417  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1001 10:39:21.434453  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342339 (* 1 = 0.342339 loss)
I1001 10:39:21.483261  4916 solver.cpp:218] Iteration 96000 (16.818 iter/s, 5.94601s/100 iters), loss = 0.00704836
I1001 10:39:21.483296  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704836 (* 1 = 0.00704836 loss)
I1001 10:39:21.483304  4916 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1001 10:39:26.297220  4916 solver.cpp:218] Iteration 96100 (20.7732 iter/s, 4.8139s/100 iters), loss = 0.00759546
I1001 10:39:26.297379  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00759545 (* 1 = 0.00759545 loss)
I1001 10:39:26.297389  4916 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1001 10:39:31.123733  4916 solver.cpp:218] Iteration 96200 (20.7196 iter/s, 4.82635s/100 iters), loss = 0.0135115
I1001 10:39:31.123764  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135115 (* 1 = 0.0135115 loss)
I1001 10:39:31.123780  4916 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1001 10:39:35.946213  4916 solver.cpp:218] Iteration 96300 (20.7365 iter/s, 4.82242s/100 iters), loss = 0.023971
I1001 10:39:35.946246  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023971 (* 1 = 0.023971 loss)
I1001 10:39:35.946254  4916 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1001 10:39:40.755415  4916 solver.cpp:218] Iteration 96400 (20.7939 iter/s, 4.80911s/100 iters), loss = 0.0533532
I1001 10:39:40.755446  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0533532 (* 1 = 0.0533532 loss)
I1001 10:39:40.755453  4916 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1001 10:39:45.336395  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:39:45.529350  4916 solver.cpp:330] Iteration 96500, Testing net (#0)
I1001 10:39:46.603847  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:39:46.649557  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1001 10:39:46.649581  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34145 (* 1 = 0.34145 loss)
I1001 10:39:46.698209  4916 solver.cpp:218] Iteration 96500 (16.8272 iter/s, 5.94274s/100 iters), loss = 0.00448223
I1001 10:39:46.698238  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448222 (* 1 = 0.00448222 loss)
I1001 10:39:46.698246  4916 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1001 10:39:51.520326  4916 solver.cpp:218] Iteration 96600 (20.738 iter/s, 4.82207s/100 iters), loss = 0.00944393
I1001 10:39:51.520366  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00944393 (* 1 = 0.00944393 loss)
I1001 10:39:51.520373  4916 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1001 10:39:56.327643  4916 solver.cpp:218] Iteration 96700 (20.8019 iter/s, 4.80726s/100 iters), loss = 0.0156561
I1001 10:39:56.327785  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156561 (* 1 = 0.0156561 loss)
I1001 10:39:56.327791  4916 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1001 10:40:01.152302  4916 solver.cpp:218] Iteration 96800 (20.7275 iter/s, 4.8245s/100 iters), loss = 0.0215561
I1001 10:40:01.152333  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215561 (* 1 = 0.0215561 loss)
I1001 10:40:01.152339  4916 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1001 10:40:05.981570  4916 solver.cpp:218] Iteration 96900 (20.7073 iter/s, 4.82921s/100 iters), loss = 0.00658854
I1001 10:40:05.981601  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658854 (* 1 = 0.00658854 loss)
I1001 10:40:05.981608  4916 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1001 10:40:10.555546  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:40:10.747792  4916 solver.cpp:330] Iteration 97000, Testing net (#0)
I1001 10:40:11.833308  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:40:11.878829  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1001 10:40:11.878855  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341256 (* 1 = 0.341256 loss)
I1001 10:40:11.927433  4916 solver.cpp:218] Iteration 97000 (16.8186 iter/s, 5.94581s/100 iters), loss = 0.00670058
I1001 10:40:11.927465  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670058 (* 1 = 0.00670058 loss)
I1001 10:40:11.927472  4916 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1001 10:40:16.742282  4916 solver.cpp:218] Iteration 97100 (20.7693 iter/s, 4.8148s/100 iters), loss = 0.00578488
I1001 10:40:16.742323  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00578488 (* 1 = 0.00578488 loss)
I1001 10:40:16.742329  4916 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1001 10:40:21.529686  4916 solver.cpp:218] Iteration 97200 (20.8884 iter/s, 4.78734s/100 iters), loss = 0.00910243
I1001 10:40:21.529726  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910242 (* 1 = 0.00910242 loss)
I1001 10:40:21.529732  4916 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1001 10:40:26.347440  4916 solver.cpp:218] Iteration 97300 (20.7568 iter/s, 4.81769s/100 iters), loss = 0.00716882
I1001 10:40:26.347595  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716881 (* 1 = 0.00716881 loss)
I1001 10:40:26.347604  4916 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1001 10:40:31.160224  4916 solver.cpp:218] Iteration 97400 (20.7789 iter/s, 4.81258s/100 iters), loss = 0.00921713
I1001 10:40:31.160255  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00921712 (* 1 = 0.00921712 loss)
I1001 10:40:31.160261  4916 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1001 10:40:35.735110  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:40:35.927434  4916 solver.cpp:330] Iteration 97500, Testing net (#0)
I1001 10:40:37.000917  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:40:37.046422  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1001 10:40:37.046458  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341016 (* 1 = 0.341016 loss)
I1001 10:40:37.094755  4916 solver.cpp:218] Iteration 97500 (16.8507 iter/s, 5.93448s/100 iters), loss = 0.00870601
I1001 10:40:37.094780  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00870601 (* 1 = 0.00870601 loss)
I1001 10:40:37.094787  4916 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1001 10:40:41.916867  4916 solver.cpp:218] Iteration 97600 (20.738 iter/s, 4.82206s/100 iters), loss = 0.00748684
I1001 10:40:41.916900  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00748685 (* 1 = 0.00748685 loss)
I1001 10:40:41.916909  4916 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1001 10:40:46.732033  4916 solver.cpp:218] Iteration 97700 (20.7679 iter/s, 4.81511s/100 iters), loss = 0.0184109
I1001 10:40:46.732067  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184109 (* 1 = 0.0184109 loss)
I1001 10:40:46.732076  4916 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1001 10:40:51.555371  4916 solver.cpp:218] Iteration 97800 (20.7328 iter/s, 4.82328s/100 iters), loss = 0.0027015
I1001 10:40:51.555407  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027015 (* 1 = 0.0027015 loss)
I1001 10:40:51.555416  4916 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1001 10:40:56.376240  4916 solver.cpp:218] Iteration 97900 (20.7434 iter/s, 4.82082s/100 iters), loss = 0.00149328
I1001 10:40:56.376376  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149329 (* 1 = 0.00149329 loss)
I1001 10:40:56.376418  4916 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1001 10:41:00.964067  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:41:01.156808  4916 solver.cpp:330] Iteration 98000, Testing net (#0)
I1001 10:41:02.231992  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:41:02.277148  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1001 10:41:02.277178  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340606 (* 1 = 0.340606 loss)
I1001 10:41:02.326071  4916 solver.cpp:218] Iteration 98000 (16.8076 iter/s, 5.94968s/100 iters), loss = 0.00521312
I1001 10:41:02.326102  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521312 (* 1 = 0.00521312 loss)
I1001 10:41:02.326112  4916 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1001 10:41:07.150805  4916 solver.cpp:218] Iteration 98100 (20.7267 iter/s, 4.82469s/100 iters), loss = 0.00825378
I1001 10:41:07.150838  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825378 (* 1 = 0.00825378 loss)
I1001 10:41:07.150857  4916 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1001 10:41:11.977478  4916 solver.cpp:218] Iteration 98200 (20.7184 iter/s, 4.82662s/100 iters), loss = 0.0118148
I1001 10:41:11.977510  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118148 (* 1 = 0.0118148 loss)
I1001 10:41:11.977530  4916 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1001 10:41:16.791039  4916 solver.cpp:218] Iteration 98300 (20.7749 iter/s, 4.81351s/100 iters), loss = 0.0114081
I1001 10:41:16.791072  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114081 (* 1 = 0.0114081 loss)
I1001 10:41:16.791091  4916 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1001 10:41:21.612694  4916 solver.cpp:218] Iteration 98400 (20.74 iter/s, 4.8216s/100 iters), loss = 0.00191361
I1001 10:41:21.612726  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191361 (* 1 = 0.00191361 loss)
I1001 10:41:21.612735  4916 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1001 10:41:26.190596  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:41:26.382726  4916 solver.cpp:330] Iteration 98500, Testing net (#0)
I1001 10:41:27.462606  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:41:27.507966  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1001 10:41:27.507992  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341985 (* 1 = 0.341985 loss)
I1001 10:41:27.556620  4916 solver.cpp:218] Iteration 98500 (16.8241 iter/s, 5.94384s/100 iters), loss = 0.0155381
I1001 10:41:27.556650  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155381 (* 1 = 0.0155381 loss)
I1001 10:41:27.556660  4916 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1001 10:41:32.364992  4916 solver.cpp:218] Iteration 98600 (20.7973 iter/s, 4.80832s/100 iters), loss = 0.00683825
I1001 10:41:32.365027  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683824 (* 1 = 0.00683824 loss)
I1001 10:41:32.365046  4916 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1001 10:41:37.189373  4916 solver.cpp:218] Iteration 98700 (20.7283 iter/s, 4.82433s/100 iters), loss = 0.00498838
I1001 10:41:37.189406  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00498838 (* 1 = 0.00498838 loss)
I1001 10:41:37.189415  4916 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1001 10:41:42.015663  4916 solver.cpp:218] Iteration 98800 (20.7201 iter/s, 4.82624s/100 iters), loss = 0.0380127
I1001 10:41:42.015697  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380127 (* 1 = 0.0380127 loss)
I1001 10:41:42.015707  4916 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1001 10:41:46.835711  4916 solver.cpp:218] Iteration 98900 (20.7469 iter/s, 4.82s/100 iters), loss = 0.00452434
I1001 10:41:46.835747  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452435 (* 1 = 0.00452435 loss)
I1001 10:41:46.835767  4916 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1001 10:41:51.421452  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:41:51.614620  4916 solver.cpp:330] Iteration 99000, Testing net (#0)
I1001 10:41:52.689266  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:41:52.734755  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1001 10:41:52.734791  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343075 (* 1 = 0.343075 loss)
I1001 10:41:52.783725  4916 solver.cpp:218] Iteration 99000 (16.8125 iter/s, 5.94796s/100 iters), loss = 0.0128653
I1001 10:41:52.783749  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128653 (* 1 = 0.0128653 loss)
I1001 10:41:52.783756  4916 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1001 10:41:57.611196  4916 solver.cpp:218] Iteration 99100 (20.715 iter/s, 4.82743s/100 iters), loss = 0.00451674
I1001 10:41:57.611317  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451674 (* 1 = 0.00451674 loss)
I1001 10:41:57.611335  4916 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1001 10:42:02.422688  4916 solver.cpp:218] Iteration 99200 (20.7842 iter/s, 4.81135s/100 iters), loss = 0.0262102
I1001 10:42:02.422720  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262102 (* 1 = 0.0262102 loss)
I1001 10:42:02.422726  4916 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1001 10:42:07.243002  4916 solver.cpp:218] Iteration 99300 (20.7458 iter/s, 4.82026s/100 iters), loss = 0.0111759
I1001 10:42:07.243034  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111759 (* 1 = 0.0111759 loss)
I1001 10:42:07.243042  4916 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1001 10:42:12.073220  4916 solver.cpp:218] Iteration 99400 (20.7042 iter/s, 4.82993s/100 iters), loss = 0.00859031
I1001 10:42:12.073251  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00859032 (* 1 = 0.00859032 loss)
I1001 10:42:12.073257  4916 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1001 10:42:16.691633  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:42:16.885291  4916 solver.cpp:330] Iteration 99500, Testing net (#0)
I1001 10:42:17.971546  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:42:18.017319  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1001 10:42:18.017345  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342415 (* 1 = 0.342415 loss)
I1001 10:42:18.065491  4916 solver.cpp:218] Iteration 99500 (16.6883 iter/s, 5.99222s/100 iters), loss = 0.0073382
I1001 10:42:18.065515  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00733821 (* 1 = 0.00733821 loss)
I1001 10:42:18.065522  4916 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1001 10:42:22.887060  4916 solver.cpp:218] Iteration 99600 (20.7403 iter/s, 4.82152s/100 iters), loss = 0.00530479
I1001 10:42:22.887091  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530481 (* 1 = 0.00530481 loss)
I1001 10:42:22.887097  4916 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1001 10:42:27.755769  4916 solver.cpp:218] Iteration 99700 (20.5396 iter/s, 4.86866s/100 iters), loss = 0.0172135
I1001 10:42:27.755944  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172135 (* 1 = 0.0172135 loss)
I1001 10:42:27.755952  4916 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1001 10:42:32.596917  4916 solver.cpp:218] Iteration 99800 (20.6571 iter/s, 4.84095s/100 iters), loss = 0.00724296
I1001 10:42:32.596957  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00724297 (* 1 = 0.00724297 loss)
I1001 10:42:32.596966  4916 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1001 10:42:37.421919  4916 solver.cpp:218] Iteration 99900 (20.7256 iter/s, 4.82494s/100 iters), loss = 0.00326443
I1001 10:42:37.421960  4916 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326444 (* 1 = 0.00326444 loss)
I1001 10:42:37.421967  4916 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1001 10:42:42.011159  4925 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:42:42.203933  4916 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_100000.caffemodel
I1001 10:42:42.208628  4916 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_relu_gauss_iter_100000.solverstate
I1001 10:42:42.221855  4916 solver.cpp:310] Iteration 100000, loss = 0.00666015
I1001 10:42:42.221873  4916 solver.cpp:330] Iteration 100000, Testing net (#0)
I1001 10:42:43.296807  4926 data_layer.cpp:73] Restarting data prefetching from start.
I1001 10:42:43.342304  4916 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1001 10:42:43.342340  4916 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343943 (* 1 = 0.343943 loss)
I1001 10:42:43.342346  4916 solver.cpp:315] Optimization Done.
I1001 10:42:43.342348  4916 caffe.cpp:259] Optimization Done.
