I1005 13:00:39.744974  9519 caffe.cpp:218] Using GPUs 0
I1005 13:00:39.768915  9519 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1005 13:00:40.002451  9519 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha2_beta1_etanostudy_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1005 13:00:40.002615  9519 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 13:00:40.004220  9519 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 13:00:40.004230  9519 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 13:00:40.004348  9519 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1005 13:00:40.004392  9519 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1005 13:00:40.004874  9519 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1005 13:00:40.005213  9519 layer_factory.hpp:77] Creating layer Data1
I1005 13:00:40.005291  9519 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1005 13:00:40.005316  9519 net.cpp:84] Creating Layer Data1
I1005 13:00:40.005321  9519 net.cpp:380] Data1 -> Data1
I1005 13:00:40.005338  9519 net.cpp:380] Data1 -> Data2
I1005 13:00:40.005347  9519 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 13:00:40.006799  9519 data_layer.cpp:45] output data size: 100,3,28,28
I1005 13:00:40.009081  9519 net.cpp:122] Setting up Data1
I1005 13:00:40.009094  9519 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1005 13:00:40.009099  9519 net.cpp:129] Top shape: 100 (100)
I1005 13:00:40.009101  9519 net.cpp:137] Memory required for data: 941200
I1005 13:00:40.009107  9519 layer_factory.hpp:77] Creating layer Convolution1
I1005 13:00:40.009125  9519 net.cpp:84] Creating Layer Convolution1
I1005 13:00:40.009130  9519 net.cpp:406] Convolution1 <- Data1
I1005 13:00:40.009138  9519 net.cpp:380] Convolution1 -> Convolution1
I1005 13:00:40.156307  9519 net.cpp:122] Setting up Convolution1
I1005 13:00:40.156330  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.156334  9519 net.cpp:137] Memory required for data: 5958800
I1005 13:00:40.156348  9519 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 13:00:40.156368  9519 net.cpp:84] Creating Layer BatchNorm1
I1005 13:00:40.156373  9519 net.cpp:406] BatchNorm1 <- Convolution1
I1005 13:00:40.156376  9519 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 13:00:40.156525  9519 net.cpp:122] Setting up BatchNorm1
I1005 13:00:40.156532  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.156533  9519 net.cpp:137] Memory required for data: 10976400
I1005 13:00:40.156541  9519 layer_factory.hpp:77] Creating layer Scale1
I1005 13:00:40.156561  9519 net.cpp:84] Creating Layer Scale1
I1005 13:00:40.156563  9519 net.cpp:406] Scale1 <- Convolution1
I1005 13:00:40.156568  9519 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 13:00:40.156627  9519 layer_factory.hpp:77] Creating layer Scale1
I1005 13:00:40.156724  9519 net.cpp:122] Setting up Scale1
I1005 13:00:40.156729  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.156733  9519 net.cpp:137] Memory required for data: 15994000
I1005 13:00:40.156736  9519 layer_factory.hpp:77] Creating layer penlu1
I1005 13:00:40.156744  9519 net.cpp:84] Creating Layer penlu1
I1005 13:00:40.156747  9519 net.cpp:406] penlu1 <- Convolution1
I1005 13:00:40.156761  9519 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1005 13:00:40.157366  9519 net.cpp:122] Setting up penlu1
I1005 13:00:40.157374  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.157377  9519 net.cpp:137] Memory required for data: 21011600
I1005 13:00:40.157384  9519 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1005 13:00:40.157403  9519 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1005 13:00:40.157405  9519 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1005 13:00:40.157409  9519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1005 13:00:40.157426  9519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1005 13:00:40.157459  9519 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1005 13:00:40.157475  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.157479  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.157480  9519 net.cpp:137] Memory required for data: 31046800
I1005 13:00:40.157482  9519 layer_factory.hpp:77] Creating layer Convolution2
I1005 13:00:40.157490  9519 net.cpp:84] Creating Layer Convolution2
I1005 13:00:40.157492  9519 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1005 13:00:40.157496  9519 net.cpp:380] Convolution2 -> Convolution2
I1005 13:00:40.158344  9519 net.cpp:122] Setting up Convolution2
I1005 13:00:40.158354  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.158356  9519 net.cpp:137] Memory required for data: 36064400
I1005 13:00:40.158360  9519 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 13:00:40.158386  9519 net.cpp:84] Creating Layer BatchNorm2
I1005 13:00:40.158390  9519 net.cpp:406] BatchNorm2 <- Convolution2
I1005 13:00:40.158403  9519 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 13:00:40.158546  9519 net.cpp:122] Setting up BatchNorm2
I1005 13:00:40.158552  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.158555  9519 net.cpp:137] Memory required for data: 41082000
I1005 13:00:40.158560  9519 layer_factory.hpp:77] Creating layer Scale2
I1005 13:00:40.158565  9519 net.cpp:84] Creating Layer Scale2
I1005 13:00:40.158566  9519 net.cpp:406] Scale2 <- Convolution2
I1005 13:00:40.158569  9519 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 13:00:40.158613  9519 layer_factory.hpp:77] Creating layer Scale2
I1005 13:00:40.158700  9519 net.cpp:122] Setting up Scale2
I1005 13:00:40.158705  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.158707  9519 net.cpp:137] Memory required for data: 46099600
I1005 13:00:40.158713  9519 layer_factory.hpp:77] Creating layer penlu2
I1005 13:00:40.158718  9519 net.cpp:84] Creating Layer penlu2
I1005 13:00:40.158720  9519 net.cpp:406] penlu2 <- Convolution2
I1005 13:00:40.158723  9519 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1005 13:00:40.158835  9519 net.cpp:122] Setting up penlu2
I1005 13:00:40.158840  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.158843  9519 net.cpp:137] Memory required for data: 51117200
I1005 13:00:40.158846  9519 layer_factory.hpp:77] Creating layer Convolution3
I1005 13:00:40.158852  9519 net.cpp:84] Creating Layer Convolution3
I1005 13:00:40.158855  9519 net.cpp:406] Convolution3 <- Convolution2
I1005 13:00:40.158859  9519 net.cpp:380] Convolution3 -> Convolution3
I1005 13:00:40.159700  9519 net.cpp:122] Setting up Convolution3
I1005 13:00:40.159709  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.159713  9519 net.cpp:137] Memory required for data: 56134800
I1005 13:00:40.159718  9519 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 13:00:40.159723  9519 net.cpp:84] Creating Layer BatchNorm3
I1005 13:00:40.159724  9519 net.cpp:406] BatchNorm3 <- Convolution3
I1005 13:00:40.159739  9519 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 13:00:40.159863  9519 net.cpp:122] Setting up BatchNorm3
I1005 13:00:40.159868  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.159870  9519 net.cpp:137] Memory required for data: 61152400
I1005 13:00:40.159875  9519 layer_factory.hpp:77] Creating layer Scale3
I1005 13:00:40.159879  9519 net.cpp:84] Creating Layer Scale3
I1005 13:00:40.159881  9519 net.cpp:406] Scale3 <- Convolution3
I1005 13:00:40.159884  9519 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 13:00:40.159926  9519 layer_factory.hpp:77] Creating layer Scale3
I1005 13:00:40.160013  9519 net.cpp:122] Setting up Scale3
I1005 13:00:40.160018  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.160020  9519 net.cpp:137] Memory required for data: 66170000
I1005 13:00:40.160024  9519 layer_factory.hpp:77] Creating layer Eltwise1
I1005 13:00:40.160028  9519 net.cpp:84] Creating Layer Eltwise1
I1005 13:00:40.160032  9519 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1005 13:00:40.160034  9519 net.cpp:406] Eltwise1 <- Convolution3
I1005 13:00:40.160037  9519 net.cpp:380] Eltwise1 -> Eltwise1
I1005 13:00:40.160063  9519 net.cpp:122] Setting up Eltwise1
I1005 13:00:40.160078  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.160079  9519 net.cpp:137] Memory required for data: 71187600
I1005 13:00:40.160081  9519 layer_factory.hpp:77] Creating layer penlu3
I1005 13:00:40.160086  9519 net.cpp:84] Creating Layer penlu3
I1005 13:00:40.160089  9519 net.cpp:406] penlu3 <- Eltwise1
I1005 13:00:40.160092  9519 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1005 13:00:40.160204  9519 net.cpp:122] Setting up penlu3
I1005 13:00:40.160209  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.160212  9519 net.cpp:137] Memory required for data: 76205200
I1005 13:00:40.160223  9519 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1005 13:00:40.160226  9519 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1005 13:00:40.160239  9519 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1005 13:00:40.160243  9519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1005 13:00:40.160248  9519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1005 13:00:40.160293  9519 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1005 13:00:40.160307  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.160310  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.160311  9519 net.cpp:137] Memory required for data: 86240400
I1005 13:00:40.160313  9519 layer_factory.hpp:77] Creating layer Convolution4
I1005 13:00:40.160320  9519 net.cpp:84] Creating Layer Convolution4
I1005 13:00:40.160322  9519 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1005 13:00:40.160336  9519 net.cpp:380] Convolution4 -> Convolution4
I1005 13:00:40.161188  9519 net.cpp:122] Setting up Convolution4
I1005 13:00:40.161198  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.161201  9519 net.cpp:137] Memory required for data: 91258000
I1005 13:00:40.161206  9519 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 13:00:40.161209  9519 net.cpp:84] Creating Layer BatchNorm4
I1005 13:00:40.161212  9519 net.cpp:406] BatchNorm4 <- Convolution4
I1005 13:00:40.161226  9519 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 13:00:40.161368  9519 net.cpp:122] Setting up BatchNorm4
I1005 13:00:40.161373  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.161376  9519 net.cpp:137] Memory required for data: 96275600
I1005 13:00:40.161383  9519 layer_factory.hpp:77] Creating layer Scale4
I1005 13:00:40.161387  9519 net.cpp:84] Creating Layer Scale4
I1005 13:00:40.161391  9519 net.cpp:406] Scale4 <- Convolution4
I1005 13:00:40.161402  9519 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 13:00:40.161435  9519 layer_factory.hpp:77] Creating layer Scale4
I1005 13:00:40.161522  9519 net.cpp:122] Setting up Scale4
I1005 13:00:40.161527  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.161530  9519 net.cpp:137] Memory required for data: 101293200
I1005 13:00:40.161533  9519 layer_factory.hpp:77] Creating layer penlu4
I1005 13:00:40.161538  9519 net.cpp:84] Creating Layer penlu4
I1005 13:00:40.161541  9519 net.cpp:406] penlu4 <- Convolution4
I1005 13:00:40.161545  9519 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1005 13:00:40.161658  9519 net.cpp:122] Setting up penlu4
I1005 13:00:40.161662  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.161664  9519 net.cpp:137] Memory required for data: 106310800
I1005 13:00:40.161669  9519 layer_factory.hpp:77] Creating layer Convolution5
I1005 13:00:40.161686  9519 net.cpp:84] Creating Layer Convolution5
I1005 13:00:40.161689  9519 net.cpp:406] Convolution5 <- Convolution4
I1005 13:00:40.161695  9519 net.cpp:380] Convolution5 -> Convolution5
I1005 13:00:40.162575  9519 net.cpp:122] Setting up Convolution5
I1005 13:00:40.162585  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.162588  9519 net.cpp:137] Memory required for data: 111328400
I1005 13:00:40.162593  9519 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 13:00:40.162598  9519 net.cpp:84] Creating Layer BatchNorm5
I1005 13:00:40.162612  9519 net.cpp:406] BatchNorm5 <- Convolution5
I1005 13:00:40.162616  9519 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 13:00:40.162750  9519 net.cpp:122] Setting up BatchNorm5
I1005 13:00:40.162755  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.162756  9519 net.cpp:137] Memory required for data: 116346000
I1005 13:00:40.162761  9519 layer_factory.hpp:77] Creating layer Scale5
I1005 13:00:40.162765  9519 net.cpp:84] Creating Layer Scale5
I1005 13:00:40.162767  9519 net.cpp:406] Scale5 <- Convolution5
I1005 13:00:40.162771  9519 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 13:00:40.162823  9519 layer_factory.hpp:77] Creating layer Scale5
I1005 13:00:40.162919  9519 net.cpp:122] Setting up Scale5
I1005 13:00:40.162925  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.162935  9519 net.cpp:137] Memory required for data: 121363600
I1005 13:00:40.162940  9519 layer_factory.hpp:77] Creating layer Eltwise2
I1005 13:00:40.162943  9519 net.cpp:84] Creating Layer Eltwise2
I1005 13:00:40.162946  9519 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1005 13:00:40.162950  9519 net.cpp:406] Eltwise2 <- Convolution5
I1005 13:00:40.162953  9519 net.cpp:380] Eltwise2 -> Eltwise2
I1005 13:00:40.162968  9519 net.cpp:122] Setting up Eltwise2
I1005 13:00:40.162982  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.162984  9519 net.cpp:137] Memory required for data: 126381200
I1005 13:00:40.162986  9519 layer_factory.hpp:77] Creating layer penlu5
I1005 13:00:40.163000  9519 net.cpp:84] Creating Layer penlu5
I1005 13:00:40.163002  9519 net.cpp:406] penlu5 <- Eltwise2
I1005 13:00:40.163007  9519 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1005 13:00:40.163130  9519 net.cpp:122] Setting up penlu5
I1005 13:00:40.163136  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.163138  9519 net.cpp:137] Memory required for data: 131398800
I1005 13:00:40.163153  9519 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1005 13:00:40.163157  9519 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1005 13:00:40.163161  9519 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1005 13:00:40.163164  9519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1005 13:00:40.163168  9519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1005 13:00:40.163202  9519 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1005 13:00:40.163205  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.163209  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.163221  9519 net.cpp:137] Memory required for data: 141434000
I1005 13:00:40.163223  9519 layer_factory.hpp:77] Creating layer Convolution6
I1005 13:00:40.163230  9519 net.cpp:84] Creating Layer Convolution6
I1005 13:00:40.163233  9519 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1005 13:00:40.163238  9519 net.cpp:380] Convolution6 -> Convolution6
I1005 13:00:40.164132  9519 net.cpp:122] Setting up Convolution6
I1005 13:00:40.164144  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.164147  9519 net.cpp:137] Memory required for data: 146451600
I1005 13:00:40.164152  9519 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 13:00:40.164157  9519 net.cpp:84] Creating Layer BatchNorm6
I1005 13:00:40.164160  9519 net.cpp:406] BatchNorm6 <- Convolution6
I1005 13:00:40.164165  9519 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 13:00:40.164297  9519 net.cpp:122] Setting up BatchNorm6
I1005 13:00:40.164304  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.164306  9519 net.cpp:137] Memory required for data: 151469200
I1005 13:00:40.164310  9519 layer_factory.hpp:77] Creating layer Scale6
I1005 13:00:40.164315  9519 net.cpp:84] Creating Layer Scale6
I1005 13:00:40.164319  9519 net.cpp:406] Scale6 <- Convolution6
I1005 13:00:40.164322  9519 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 13:00:40.164348  9519 layer_factory.hpp:77] Creating layer Scale6
I1005 13:00:40.164424  9519 net.cpp:122] Setting up Scale6
I1005 13:00:40.164430  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.164433  9519 net.cpp:137] Memory required for data: 156486800
I1005 13:00:40.164436  9519 layer_factory.hpp:77] Creating layer penlu6
I1005 13:00:40.164443  9519 net.cpp:84] Creating Layer penlu6
I1005 13:00:40.164446  9519 net.cpp:406] penlu6 <- Convolution6
I1005 13:00:40.164450  9519 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1005 13:00:40.164557  9519 net.cpp:122] Setting up penlu6
I1005 13:00:40.164562  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.164566  9519 net.cpp:137] Memory required for data: 161504400
I1005 13:00:40.164577  9519 layer_factory.hpp:77] Creating layer Convolution7
I1005 13:00:40.164585  9519 net.cpp:84] Creating Layer Convolution7
I1005 13:00:40.164588  9519 net.cpp:406] Convolution7 <- Convolution6
I1005 13:00:40.164593  9519 net.cpp:380] Convolution7 -> Convolution7
I1005 13:00:40.165158  9519 net.cpp:122] Setting up Convolution7
I1005 13:00:40.165168  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.165170  9519 net.cpp:137] Memory required for data: 166522000
I1005 13:00:40.165175  9519 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 13:00:40.165180  9519 net.cpp:84] Creating Layer BatchNorm7
I1005 13:00:40.165184  9519 net.cpp:406] BatchNorm7 <- Convolution7
I1005 13:00:40.165189  9519 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 13:00:40.165318  9519 net.cpp:122] Setting up BatchNorm7
I1005 13:00:40.165323  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.165326  9519 net.cpp:137] Memory required for data: 171539600
I1005 13:00:40.165336  9519 layer_factory.hpp:77] Creating layer Scale7
I1005 13:00:40.165344  9519 net.cpp:84] Creating Layer Scale7
I1005 13:00:40.165347  9519 net.cpp:406] Scale7 <- Convolution7
I1005 13:00:40.165350  9519 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 13:00:40.165377  9519 layer_factory.hpp:77] Creating layer Scale7
I1005 13:00:40.165454  9519 net.cpp:122] Setting up Scale7
I1005 13:00:40.165459  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.165462  9519 net.cpp:137] Memory required for data: 176557200
I1005 13:00:40.165467  9519 layer_factory.hpp:77] Creating layer Eltwise3
I1005 13:00:40.165472  9519 net.cpp:84] Creating Layer Eltwise3
I1005 13:00:40.165474  9519 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1005 13:00:40.165477  9519 net.cpp:406] Eltwise3 <- Convolution7
I1005 13:00:40.165480  9519 net.cpp:380] Eltwise3 -> Eltwise3
I1005 13:00:40.165495  9519 net.cpp:122] Setting up Eltwise3
I1005 13:00:40.165500  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.165503  9519 net.cpp:137] Memory required for data: 181574800
I1005 13:00:40.165505  9519 layer_factory.hpp:77] Creating layer penlu7
I1005 13:00:40.165511  9519 net.cpp:84] Creating Layer penlu7
I1005 13:00:40.165514  9519 net.cpp:406] penlu7 <- Eltwise3
I1005 13:00:40.165518  9519 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1005 13:00:40.165622  9519 net.cpp:122] Setting up penlu7
I1005 13:00:40.165628  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.165632  9519 net.cpp:137] Memory required for data: 186592400
I1005 13:00:40.165635  9519 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1005 13:00:40.165640  9519 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1005 13:00:40.165643  9519 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1005 13:00:40.165647  9519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1005 13:00:40.165652  9519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1005 13:00:40.165673  9519 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1005 13:00:40.165678  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.165681  9519 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 13:00:40.165684  9519 net.cpp:137] Memory required for data: 196627600
I1005 13:00:40.165686  9519 layer_factory.hpp:77] Creating layer Convolution8
I1005 13:00:40.165693  9519 net.cpp:84] Creating Layer Convolution8
I1005 13:00:40.165696  9519 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1005 13:00:40.165699  9519 net.cpp:380] Convolution8 -> Convolution8
I1005 13:00:40.166887  9519 net.cpp:122] Setting up Convolution8
I1005 13:00:40.166896  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.166899  9519 net.cpp:137] Memory required for data: 199136400
I1005 13:00:40.166904  9519 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 13:00:40.166911  9519 net.cpp:84] Creating Layer BatchNorm8
I1005 13:00:40.166914  9519 net.cpp:406] BatchNorm8 <- Convolution8
I1005 13:00:40.166918  9519 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 13:00:40.167059  9519 net.cpp:122] Setting up BatchNorm8
I1005 13:00:40.167065  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.167068  9519 net.cpp:137] Memory required for data: 201645200
I1005 13:00:40.167073  9519 layer_factory.hpp:77] Creating layer Scale8
I1005 13:00:40.167078  9519 net.cpp:84] Creating Layer Scale8
I1005 13:00:40.167080  9519 net.cpp:406] Scale8 <- Convolution8
I1005 13:00:40.167084  9519 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 13:00:40.167110  9519 layer_factory.hpp:77] Creating layer Scale8
I1005 13:00:40.167186  9519 net.cpp:122] Setting up Scale8
I1005 13:00:40.167191  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.167192  9519 net.cpp:137] Memory required for data: 204154000
I1005 13:00:40.167196  9519 layer_factory.hpp:77] Creating layer Convolution9
I1005 13:00:40.167204  9519 net.cpp:84] Creating Layer Convolution9
I1005 13:00:40.167207  9519 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1005 13:00:40.167212  9519 net.cpp:380] Convolution9 -> Convolution9
I1005 13:00:40.168743  9519 net.cpp:122] Setting up Convolution9
I1005 13:00:40.168756  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.168758  9519 net.cpp:137] Memory required for data: 206662800
I1005 13:00:40.168763  9519 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 13:00:40.168769  9519 net.cpp:84] Creating Layer BatchNorm9
I1005 13:00:40.168772  9519 net.cpp:406] BatchNorm9 <- Convolution9
I1005 13:00:40.168777  9519 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 13:00:40.168910  9519 net.cpp:122] Setting up BatchNorm9
I1005 13:00:40.168916  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.168918  9519 net.cpp:137] Memory required for data: 209171600
I1005 13:00:40.168923  9519 layer_factory.hpp:77] Creating layer Scale9
I1005 13:00:40.168928  9519 net.cpp:84] Creating Layer Scale9
I1005 13:00:40.168931  9519 net.cpp:406] Scale9 <- Convolution9
I1005 13:00:40.168936  9519 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 13:00:40.168962  9519 layer_factory.hpp:77] Creating layer Scale9
I1005 13:00:40.169034  9519 net.cpp:122] Setting up Scale9
I1005 13:00:40.169039  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.169042  9519 net.cpp:137] Memory required for data: 211680400
I1005 13:00:40.169046  9519 layer_factory.hpp:77] Creating layer penlu8
I1005 13:00:40.169052  9519 net.cpp:84] Creating Layer penlu8
I1005 13:00:40.169055  9519 net.cpp:406] penlu8 <- Convolution9
I1005 13:00:40.169059  9519 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1005 13:00:40.169162  9519 net.cpp:122] Setting up penlu8
I1005 13:00:40.169167  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.169170  9519 net.cpp:137] Memory required for data: 214189200
I1005 13:00:40.169175  9519 layer_factory.hpp:77] Creating layer Convolution10
I1005 13:00:40.169183  9519 net.cpp:84] Creating Layer Convolution10
I1005 13:00:40.169185  9519 net.cpp:406] Convolution10 <- Convolution9
I1005 13:00:40.169200  9519 net.cpp:380] Convolution10 -> Convolution10
I1005 13:00:40.170305  9519 net.cpp:122] Setting up Convolution10
I1005 13:00:40.170315  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.170320  9519 net.cpp:137] Memory required for data: 216698000
I1005 13:00:40.170325  9519 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 13:00:40.170331  9519 net.cpp:84] Creating Layer BatchNorm10
I1005 13:00:40.170333  9519 net.cpp:406] BatchNorm10 <- Convolution10
I1005 13:00:40.170338  9519 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 13:00:40.170467  9519 net.cpp:122] Setting up BatchNorm10
I1005 13:00:40.170472  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.170475  9519 net.cpp:137] Memory required for data: 219206800
I1005 13:00:40.170480  9519 layer_factory.hpp:77] Creating layer Scale10
I1005 13:00:40.170485  9519 net.cpp:84] Creating Layer Scale10
I1005 13:00:40.170487  9519 net.cpp:406] Scale10 <- Convolution10
I1005 13:00:40.170498  9519 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 13:00:40.170547  9519 layer_factory.hpp:77] Creating layer Scale10
I1005 13:00:40.170634  9519 net.cpp:122] Setting up Scale10
I1005 13:00:40.170639  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.170641  9519 net.cpp:137] Memory required for data: 221715600
I1005 13:00:40.170645  9519 layer_factory.hpp:77] Creating layer Eltwise4
I1005 13:00:40.170650  9519 net.cpp:84] Creating Layer Eltwise4
I1005 13:00:40.170653  9519 net.cpp:406] Eltwise4 <- Convolution8
I1005 13:00:40.170656  9519 net.cpp:406] Eltwise4 <- Convolution10
I1005 13:00:40.170660  9519 net.cpp:380] Eltwise4 -> Eltwise4
I1005 13:00:40.170676  9519 net.cpp:122] Setting up Eltwise4
I1005 13:00:40.170680  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.170683  9519 net.cpp:137] Memory required for data: 224224400
I1005 13:00:40.170686  9519 layer_factory.hpp:77] Creating layer penlu9
I1005 13:00:40.170691  9519 net.cpp:84] Creating Layer penlu9
I1005 13:00:40.170694  9519 net.cpp:406] penlu9 <- Eltwise4
I1005 13:00:40.170698  9519 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1005 13:00:40.170804  9519 net.cpp:122] Setting up penlu9
I1005 13:00:40.170809  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.170811  9519 net.cpp:137] Memory required for data: 226733200
I1005 13:00:40.170816  9519 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1005 13:00:40.170820  9519 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1005 13:00:40.170824  9519 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1005 13:00:40.170827  9519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1005 13:00:40.170831  9519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1005 13:00:40.170855  9519 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1005 13:00:40.170858  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.170862  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.170864  9519 net.cpp:137] Memory required for data: 231750800
I1005 13:00:40.170867  9519 layer_factory.hpp:77] Creating layer Convolution11
I1005 13:00:40.170872  9519 net.cpp:84] Creating Layer Convolution11
I1005 13:00:40.170876  9519 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1005 13:00:40.170881  9519 net.cpp:380] Convolution11 -> Convolution11
I1005 13:00:40.171917  9519 net.cpp:122] Setting up Convolution11
I1005 13:00:40.171928  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.171931  9519 net.cpp:137] Memory required for data: 234259600
I1005 13:00:40.171936  9519 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 13:00:40.171941  9519 net.cpp:84] Creating Layer BatchNorm11
I1005 13:00:40.171944  9519 net.cpp:406] BatchNorm11 <- Convolution11
I1005 13:00:40.171948  9519 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 13:00:40.172080  9519 net.cpp:122] Setting up BatchNorm11
I1005 13:00:40.172085  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.172087  9519 net.cpp:137] Memory required for data: 236768400
I1005 13:00:40.172092  9519 layer_factory.hpp:77] Creating layer Scale11
I1005 13:00:40.172096  9519 net.cpp:84] Creating Layer Scale11
I1005 13:00:40.172101  9519 net.cpp:406] Scale11 <- Convolution11
I1005 13:00:40.172103  9519 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 13:00:40.172129  9519 layer_factory.hpp:77] Creating layer Scale11
I1005 13:00:40.172204  9519 net.cpp:122] Setting up Scale11
I1005 13:00:40.172209  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.172212  9519 net.cpp:137] Memory required for data: 239277200
I1005 13:00:40.172216  9519 layer_factory.hpp:77] Creating layer penlu10
I1005 13:00:40.172221  9519 net.cpp:84] Creating Layer penlu10
I1005 13:00:40.172224  9519 net.cpp:406] penlu10 <- Convolution11
I1005 13:00:40.172228  9519 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1005 13:00:40.172332  9519 net.cpp:122] Setting up penlu10
I1005 13:00:40.172336  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.172348  9519 net.cpp:137] Memory required for data: 241786000
I1005 13:00:40.172353  9519 layer_factory.hpp:77] Creating layer Convolution12
I1005 13:00:40.172363  9519 net.cpp:84] Creating Layer Convolution12
I1005 13:00:40.172368  9519 net.cpp:406] Convolution12 <- Convolution11
I1005 13:00:40.172384  9519 net.cpp:380] Convolution12 -> Convolution12
I1005 13:00:40.173485  9519 net.cpp:122] Setting up Convolution12
I1005 13:00:40.173496  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.173499  9519 net.cpp:137] Memory required for data: 244294800
I1005 13:00:40.173504  9519 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 13:00:40.173511  9519 net.cpp:84] Creating Layer BatchNorm12
I1005 13:00:40.173516  9519 net.cpp:406] BatchNorm12 <- Convolution12
I1005 13:00:40.173518  9519 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 13:00:40.173647  9519 net.cpp:122] Setting up BatchNorm12
I1005 13:00:40.173653  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.173656  9519 net.cpp:137] Memory required for data: 246803600
I1005 13:00:40.173660  9519 layer_factory.hpp:77] Creating layer Scale12
I1005 13:00:40.173666  9519 net.cpp:84] Creating Layer Scale12
I1005 13:00:40.173668  9519 net.cpp:406] Scale12 <- Convolution12
I1005 13:00:40.173672  9519 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 13:00:40.173698  9519 layer_factory.hpp:77] Creating layer Scale12
I1005 13:00:40.173774  9519 net.cpp:122] Setting up Scale12
I1005 13:00:40.173779  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.173781  9519 net.cpp:137] Memory required for data: 249312400
I1005 13:00:40.173785  9519 layer_factory.hpp:77] Creating layer Eltwise5
I1005 13:00:40.173790  9519 net.cpp:84] Creating Layer Eltwise5
I1005 13:00:40.173794  9519 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1005 13:00:40.173796  9519 net.cpp:406] Eltwise5 <- Convolution12
I1005 13:00:40.173800  9519 net.cpp:380] Eltwise5 -> Eltwise5
I1005 13:00:40.173816  9519 net.cpp:122] Setting up Eltwise5
I1005 13:00:40.173821  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.173823  9519 net.cpp:137] Memory required for data: 251821200
I1005 13:00:40.173825  9519 layer_factory.hpp:77] Creating layer penlu11
I1005 13:00:40.173831  9519 net.cpp:84] Creating Layer penlu11
I1005 13:00:40.173835  9519 net.cpp:406] penlu11 <- Eltwise5
I1005 13:00:40.173837  9519 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1005 13:00:40.173943  9519 net.cpp:122] Setting up penlu11
I1005 13:00:40.173948  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.173950  9519 net.cpp:137] Memory required for data: 254330000
I1005 13:00:40.173954  9519 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1005 13:00:40.173959  9519 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1005 13:00:40.173962  9519 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1005 13:00:40.173966  9519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1005 13:00:40.173971  9519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1005 13:00:40.173993  9519 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1005 13:00:40.173997  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.174000  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.174003  9519 net.cpp:137] Memory required for data: 259347600
I1005 13:00:40.174005  9519 layer_factory.hpp:77] Creating layer Convolution13
I1005 13:00:40.174012  9519 net.cpp:84] Creating Layer Convolution13
I1005 13:00:40.174015  9519 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1005 13:00:40.174019  9519 net.cpp:380] Convolution13 -> Convolution13
I1005 13:00:40.175086  9519 net.cpp:122] Setting up Convolution13
I1005 13:00:40.175096  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.175101  9519 net.cpp:137] Memory required for data: 261856400
I1005 13:00:40.175104  9519 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 13:00:40.175110  9519 net.cpp:84] Creating Layer BatchNorm13
I1005 13:00:40.175120  9519 net.cpp:406] BatchNorm13 <- Convolution13
I1005 13:00:40.175124  9519 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 13:00:40.175256  9519 net.cpp:122] Setting up BatchNorm13
I1005 13:00:40.175262  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.175264  9519 net.cpp:137] Memory required for data: 264365200
I1005 13:00:40.175269  9519 layer_factory.hpp:77] Creating layer Scale13
I1005 13:00:40.175274  9519 net.cpp:84] Creating Layer Scale13
I1005 13:00:40.175277  9519 net.cpp:406] Scale13 <- Convolution13
I1005 13:00:40.175281  9519 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 13:00:40.175308  9519 layer_factory.hpp:77] Creating layer Scale13
I1005 13:00:40.175382  9519 net.cpp:122] Setting up Scale13
I1005 13:00:40.175387  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.175390  9519 net.cpp:137] Memory required for data: 266874000
I1005 13:00:40.175395  9519 layer_factory.hpp:77] Creating layer penlu12
I1005 13:00:40.175400  9519 net.cpp:84] Creating Layer penlu12
I1005 13:00:40.175403  9519 net.cpp:406] penlu12 <- Convolution13
I1005 13:00:40.175407  9519 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1005 13:00:40.175511  9519 net.cpp:122] Setting up penlu12
I1005 13:00:40.175516  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.175519  9519 net.cpp:137] Memory required for data: 269382800
I1005 13:00:40.175523  9519 layer_factory.hpp:77] Creating layer Convolution14
I1005 13:00:40.175532  9519 net.cpp:84] Creating Layer Convolution14
I1005 13:00:40.175535  9519 net.cpp:406] Convolution14 <- Convolution13
I1005 13:00:40.175539  9519 net.cpp:380] Convolution14 -> Convolution14
I1005 13:00:40.176584  9519 net.cpp:122] Setting up Convolution14
I1005 13:00:40.176595  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.176599  9519 net.cpp:137] Memory required for data: 271891600
I1005 13:00:40.176614  9519 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 13:00:40.176623  9519 net.cpp:84] Creating Layer BatchNorm14
I1005 13:00:40.176627  9519 net.cpp:406] BatchNorm14 <- Convolution14
I1005 13:00:40.176631  9519 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 13:00:40.176761  9519 net.cpp:122] Setting up BatchNorm14
I1005 13:00:40.176767  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.176770  9519 net.cpp:137] Memory required for data: 274400400
I1005 13:00:40.176775  9519 layer_factory.hpp:77] Creating layer Scale14
I1005 13:00:40.176780  9519 net.cpp:84] Creating Layer Scale14
I1005 13:00:40.176784  9519 net.cpp:406] Scale14 <- Convolution14
I1005 13:00:40.176786  9519 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 13:00:40.176815  9519 layer_factory.hpp:77] Creating layer Scale14
I1005 13:00:40.176888  9519 net.cpp:122] Setting up Scale14
I1005 13:00:40.176893  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.176895  9519 net.cpp:137] Memory required for data: 276909200
I1005 13:00:40.176899  9519 layer_factory.hpp:77] Creating layer Eltwise6
I1005 13:00:40.176904  9519 net.cpp:84] Creating Layer Eltwise6
I1005 13:00:40.176908  9519 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1005 13:00:40.176909  9519 net.cpp:406] Eltwise6 <- Convolution14
I1005 13:00:40.176913  9519 net.cpp:380] Eltwise6 -> Eltwise6
I1005 13:00:40.176928  9519 net.cpp:122] Setting up Eltwise6
I1005 13:00:40.176933  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.176934  9519 net.cpp:137] Memory required for data: 279418000
I1005 13:00:40.176936  9519 layer_factory.hpp:77] Creating layer penlu13
I1005 13:00:40.176942  9519 net.cpp:84] Creating Layer penlu13
I1005 13:00:40.176944  9519 net.cpp:406] penlu13 <- Eltwise6
I1005 13:00:40.176947  9519 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1005 13:00:40.177073  9519 net.cpp:122] Setting up penlu13
I1005 13:00:40.177076  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.177078  9519 net.cpp:137] Memory required for data: 281926800
I1005 13:00:40.177083  9519 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1005 13:00:40.177093  9519 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1005 13:00:40.177096  9519 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1005 13:00:40.177099  9519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1005 13:00:40.177103  9519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1005 13:00:40.177126  9519 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1005 13:00:40.177130  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.177134  9519 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 13:00:40.177135  9519 net.cpp:137] Memory required for data: 286944400
I1005 13:00:40.177137  9519 layer_factory.hpp:77] Creating layer Convolution15
I1005 13:00:40.177142  9519 net.cpp:84] Creating Layer Convolution15
I1005 13:00:40.177145  9519 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1005 13:00:40.177150  9519 net.cpp:380] Convolution15 -> Convolution15
I1005 13:00:40.178037  9519 net.cpp:122] Setting up Convolution15
I1005 13:00:40.178046  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.178050  9519 net.cpp:137] Memory required for data: 288198800
I1005 13:00:40.178053  9519 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 13:00:40.178058  9519 net.cpp:84] Creating Layer BatchNorm15
I1005 13:00:40.178061  9519 net.cpp:406] BatchNorm15 <- Convolution15
I1005 13:00:40.178066  9519 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 13:00:40.178196  9519 net.cpp:122] Setting up BatchNorm15
I1005 13:00:40.178201  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.178203  9519 net.cpp:137] Memory required for data: 289453200
I1005 13:00:40.178208  9519 layer_factory.hpp:77] Creating layer Scale15
I1005 13:00:40.178212  9519 net.cpp:84] Creating Layer Scale15
I1005 13:00:40.178215  9519 net.cpp:406] Scale15 <- Convolution15
I1005 13:00:40.178217  9519 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 13:00:40.178244  9519 layer_factory.hpp:77] Creating layer Scale15
I1005 13:00:40.178320  9519 net.cpp:122] Setting up Scale15
I1005 13:00:40.178324  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.178326  9519 net.cpp:137] Memory required for data: 290707600
I1005 13:00:40.178330  9519 layer_factory.hpp:77] Creating layer Convolution16
I1005 13:00:40.178336  9519 net.cpp:84] Creating Layer Convolution16
I1005 13:00:40.178339  9519 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1005 13:00:40.178344  9519 net.cpp:380] Convolution16 -> Convolution16
I1005 13:00:40.180135  9519 net.cpp:122] Setting up Convolution16
I1005 13:00:40.180145  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.180147  9519 net.cpp:137] Memory required for data: 291962000
I1005 13:00:40.180151  9519 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 13:00:40.180157  9519 net.cpp:84] Creating Layer BatchNorm16
I1005 13:00:40.180160  9519 net.cpp:406] BatchNorm16 <- Convolution16
I1005 13:00:40.180163  9519 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 13:00:40.180296  9519 net.cpp:122] Setting up BatchNorm16
I1005 13:00:40.180301  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.180304  9519 net.cpp:137] Memory required for data: 293216400
I1005 13:00:40.180307  9519 layer_factory.hpp:77] Creating layer Scale16
I1005 13:00:40.180312  9519 net.cpp:84] Creating Layer Scale16
I1005 13:00:40.180315  9519 net.cpp:406] Scale16 <- Convolution16
I1005 13:00:40.180317  9519 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 13:00:40.180346  9519 layer_factory.hpp:77] Creating layer Scale16
I1005 13:00:40.180420  9519 net.cpp:122] Setting up Scale16
I1005 13:00:40.180425  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.180428  9519 net.cpp:137] Memory required for data: 294470800
I1005 13:00:40.180431  9519 layer_factory.hpp:77] Creating layer penlu14
I1005 13:00:40.180436  9519 net.cpp:84] Creating Layer penlu14
I1005 13:00:40.180438  9519 net.cpp:406] penlu14 <- Convolution16
I1005 13:00:40.180450  9519 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1005 13:00:40.180557  9519 net.cpp:122] Setting up penlu14
I1005 13:00:40.180562  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.180563  9519 net.cpp:137] Memory required for data: 295725200
I1005 13:00:40.180567  9519 layer_factory.hpp:77] Creating layer Convolution17
I1005 13:00:40.180574  9519 net.cpp:84] Creating Layer Convolution17
I1005 13:00:40.180577  9519 net.cpp:406] Convolution17 <- Convolution16
I1005 13:00:40.180582  9519 net.cpp:380] Convolution17 -> Convolution17
I1005 13:00:40.182236  9519 net.cpp:122] Setting up Convolution17
I1005 13:00:40.182246  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.182250  9519 net.cpp:137] Memory required for data: 296979600
I1005 13:00:40.182255  9519 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 13:00:40.182260  9519 net.cpp:84] Creating Layer BatchNorm17
I1005 13:00:40.182265  9519 net.cpp:406] BatchNorm17 <- Convolution17
I1005 13:00:40.182267  9519 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 13:00:40.182406  9519 net.cpp:122] Setting up BatchNorm17
I1005 13:00:40.182411  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.182415  9519 net.cpp:137] Memory required for data: 298234000
I1005 13:00:40.182420  9519 layer_factory.hpp:77] Creating layer Scale17
I1005 13:00:40.182423  9519 net.cpp:84] Creating Layer Scale17
I1005 13:00:40.182425  9519 net.cpp:406] Scale17 <- Convolution17
I1005 13:00:40.182430  9519 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 13:00:40.182457  9519 layer_factory.hpp:77] Creating layer Scale17
I1005 13:00:40.182543  9519 net.cpp:122] Setting up Scale17
I1005 13:00:40.182548  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.182550  9519 net.cpp:137] Memory required for data: 299488400
I1005 13:00:40.182554  9519 layer_factory.hpp:77] Creating layer Eltwise7
I1005 13:00:40.182560  9519 net.cpp:84] Creating Layer Eltwise7
I1005 13:00:40.182564  9519 net.cpp:406] Eltwise7 <- Convolution15
I1005 13:00:40.182566  9519 net.cpp:406] Eltwise7 <- Convolution17
I1005 13:00:40.182570  9519 net.cpp:380] Eltwise7 -> Eltwise7
I1005 13:00:40.182587  9519 net.cpp:122] Setting up Eltwise7
I1005 13:00:40.182591  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.182595  9519 net.cpp:137] Memory required for data: 300742800
I1005 13:00:40.182596  9519 layer_factory.hpp:77] Creating layer penlu15
I1005 13:00:40.182601  9519 net.cpp:84] Creating Layer penlu15
I1005 13:00:40.182605  9519 net.cpp:406] penlu15 <- Eltwise7
I1005 13:00:40.182607  9519 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1005 13:00:40.182718  9519 net.cpp:122] Setting up penlu15
I1005 13:00:40.182723  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.182725  9519 net.cpp:137] Memory required for data: 301997200
I1005 13:00:40.182729  9519 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1005 13:00:40.182734  9519 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1005 13:00:40.182736  9519 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1005 13:00:40.182740  9519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1005 13:00:40.182744  9519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1005 13:00:40.182766  9519 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1005 13:00:40.182770  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.182773  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.182775  9519 net.cpp:137] Memory required for data: 304506000
I1005 13:00:40.182777  9519 layer_factory.hpp:77] Creating layer Convolution18
I1005 13:00:40.182783  9519 net.cpp:84] Creating Layer Convolution18
I1005 13:00:40.182786  9519 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1005 13:00:40.182790  9519 net.cpp:380] Convolution18 -> Convolution18
I1005 13:00:40.184769  9519 net.cpp:122] Setting up Convolution18
I1005 13:00:40.184779  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.184793  9519 net.cpp:137] Memory required for data: 305760400
I1005 13:00:40.184814  9519 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 13:00:40.184821  9519 net.cpp:84] Creating Layer BatchNorm18
I1005 13:00:40.184825  9519 net.cpp:406] BatchNorm18 <- Convolution18
I1005 13:00:40.184829  9519 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 13:00:40.184973  9519 net.cpp:122] Setting up BatchNorm18
I1005 13:00:40.184978  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.184989  9519 net.cpp:137] Memory required for data: 307014800
I1005 13:00:40.184994  9519 layer_factory.hpp:77] Creating layer Scale18
I1005 13:00:40.184999  9519 net.cpp:84] Creating Layer Scale18
I1005 13:00:40.185001  9519 net.cpp:406] Scale18 <- Convolution18
I1005 13:00:40.185004  9519 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 13:00:40.185053  9519 layer_factory.hpp:77] Creating layer Scale18
I1005 13:00:40.185148  9519 net.cpp:122] Setting up Scale18
I1005 13:00:40.185154  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.185156  9519 net.cpp:137] Memory required for data: 308269200
I1005 13:00:40.185160  9519 layer_factory.hpp:77] Creating layer penlu16
I1005 13:00:40.185165  9519 net.cpp:84] Creating Layer penlu16
I1005 13:00:40.185168  9519 net.cpp:406] penlu16 <- Convolution18
I1005 13:00:40.185171  9519 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1005 13:00:40.185312  9519 net.cpp:122] Setting up penlu16
I1005 13:00:40.185317  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.185319  9519 net.cpp:137] Memory required for data: 309523600
I1005 13:00:40.185323  9519 layer_factory.hpp:77] Creating layer Convolution19
I1005 13:00:40.185330  9519 net.cpp:84] Creating Layer Convolution19
I1005 13:00:40.185333  9519 net.cpp:406] Convolution19 <- Convolution18
I1005 13:00:40.185346  9519 net.cpp:380] Convolution19 -> Convolution19
I1005 13:00:40.187518  9519 net.cpp:122] Setting up Convolution19
I1005 13:00:40.187528  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.187531  9519 net.cpp:137] Memory required for data: 310778000
I1005 13:00:40.187536  9519 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 13:00:40.187541  9519 net.cpp:84] Creating Layer BatchNorm19
I1005 13:00:40.187543  9519 net.cpp:406] BatchNorm19 <- Convolution19
I1005 13:00:40.187558  9519 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 13:00:40.187700  9519 net.cpp:122] Setting up BatchNorm19
I1005 13:00:40.187705  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.187707  9519 net.cpp:137] Memory required for data: 312032400
I1005 13:00:40.187711  9519 layer_factory.hpp:77] Creating layer Scale19
I1005 13:00:40.187716  9519 net.cpp:84] Creating Layer Scale19
I1005 13:00:40.187718  9519 net.cpp:406] Scale19 <- Convolution19
I1005 13:00:40.187721  9519 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 13:00:40.187767  9519 layer_factory.hpp:77] Creating layer Scale19
I1005 13:00:40.187865  9519 net.cpp:122] Setting up Scale19
I1005 13:00:40.187870  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.187871  9519 net.cpp:137] Memory required for data: 313286800
I1005 13:00:40.187875  9519 layer_factory.hpp:77] Creating layer Eltwise8
I1005 13:00:40.187878  9519 net.cpp:84] Creating Layer Eltwise8
I1005 13:00:40.187881  9519 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1005 13:00:40.187885  9519 net.cpp:406] Eltwise8 <- Convolution19
I1005 13:00:40.187898  9519 net.cpp:380] Eltwise8 -> Eltwise8
I1005 13:00:40.187914  9519 net.cpp:122] Setting up Eltwise8
I1005 13:00:40.187927  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.187929  9519 net.cpp:137] Memory required for data: 314541200
I1005 13:00:40.187932  9519 layer_factory.hpp:77] Creating layer penlu17
I1005 13:00:40.187937  9519 net.cpp:84] Creating Layer penlu17
I1005 13:00:40.187939  9519 net.cpp:406] penlu17 <- Eltwise8
I1005 13:00:40.187942  9519 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1005 13:00:40.188071  9519 net.cpp:122] Setting up penlu17
I1005 13:00:40.188076  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.188084  9519 net.cpp:137] Memory required for data: 315795600
I1005 13:00:40.188089  9519 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1005 13:00:40.188103  9519 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1005 13:00:40.188107  9519 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1005 13:00:40.188112  9519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1005 13:00:40.188117  9519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1005 13:00:40.188169  9519 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1005 13:00:40.188172  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.188175  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.188177  9519 net.cpp:137] Memory required for data: 318304400
I1005 13:00:40.188179  9519 layer_factory.hpp:77] Creating layer Convolution20
I1005 13:00:40.188186  9519 net.cpp:84] Creating Layer Convolution20
I1005 13:00:40.188204  9519 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1005 13:00:40.188207  9519 net.cpp:380] Convolution20 -> Convolution20
I1005 13:00:40.189860  9519 net.cpp:122] Setting up Convolution20
I1005 13:00:40.189869  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.189872  9519 net.cpp:137] Memory required for data: 319558800
I1005 13:00:40.189877  9519 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 13:00:40.189882  9519 net.cpp:84] Creating Layer BatchNorm20
I1005 13:00:40.189895  9519 net.cpp:406] BatchNorm20 <- Convolution20
I1005 13:00:40.189900  9519 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 13:00:40.190040  9519 net.cpp:122] Setting up BatchNorm20
I1005 13:00:40.190045  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.190057  9519 net.cpp:137] Memory required for data: 320813200
I1005 13:00:40.190062  9519 layer_factory.hpp:77] Creating layer Scale20
I1005 13:00:40.190068  9519 net.cpp:84] Creating Layer Scale20
I1005 13:00:40.190070  9519 net.cpp:406] Scale20 <- Convolution20
I1005 13:00:40.190073  9519 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 13:00:40.190109  9519 layer_factory.hpp:77] Creating layer Scale20
I1005 13:00:40.190196  9519 net.cpp:122] Setting up Scale20
I1005 13:00:40.190201  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.190204  9519 net.cpp:137] Memory required for data: 322067600
I1005 13:00:40.190208  9519 layer_factory.hpp:77] Creating layer penlu18
I1005 13:00:40.190214  9519 net.cpp:84] Creating Layer penlu18
I1005 13:00:40.190217  9519 net.cpp:406] penlu18 <- Convolution20
I1005 13:00:40.190220  9519 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1005 13:00:40.190335  9519 net.cpp:122] Setting up penlu18
I1005 13:00:40.190338  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.190340  9519 net.cpp:137] Memory required for data: 323322000
I1005 13:00:40.190345  9519 layer_factory.hpp:77] Creating layer Convolution21
I1005 13:00:40.190351  9519 net.cpp:84] Creating Layer Convolution21
I1005 13:00:40.190353  9519 net.cpp:406] Convolution21 <- Convolution20
I1005 13:00:40.190357  9519 net.cpp:380] Convolution21 -> Convolution21
I1005 13:00:40.192827  9519 net.cpp:122] Setting up Convolution21
I1005 13:00:40.192836  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.192839  9519 net.cpp:137] Memory required for data: 324576400
I1005 13:00:40.192844  9519 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 13:00:40.192850  9519 net.cpp:84] Creating Layer BatchNorm21
I1005 13:00:40.192852  9519 net.cpp:406] BatchNorm21 <- Convolution21
I1005 13:00:40.192857  9519 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 13:00:40.192989  9519 net.cpp:122] Setting up BatchNorm21
I1005 13:00:40.192994  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.192996  9519 net.cpp:137] Memory required for data: 325830800
I1005 13:00:40.193001  9519 layer_factory.hpp:77] Creating layer Scale21
I1005 13:00:40.193006  9519 net.cpp:84] Creating Layer Scale21
I1005 13:00:40.193014  9519 net.cpp:406] Scale21 <- Convolution21
I1005 13:00:40.193017  9519 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 13:00:40.193044  9519 layer_factory.hpp:77] Creating layer Scale21
I1005 13:00:40.193122  9519 net.cpp:122] Setting up Scale21
I1005 13:00:40.193126  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.193128  9519 net.cpp:137] Memory required for data: 327085200
I1005 13:00:40.193132  9519 layer_factory.hpp:77] Creating layer Eltwise9
I1005 13:00:40.193136  9519 net.cpp:84] Creating Layer Eltwise9
I1005 13:00:40.193140  9519 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1005 13:00:40.193141  9519 net.cpp:406] Eltwise9 <- Convolution21
I1005 13:00:40.193145  9519 net.cpp:380] Eltwise9 -> Eltwise9
I1005 13:00:40.193161  9519 net.cpp:122] Setting up Eltwise9
I1005 13:00:40.193164  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.193166  9519 net.cpp:137] Memory required for data: 328339600
I1005 13:00:40.193168  9519 layer_factory.hpp:77] Creating layer penlu19
I1005 13:00:40.193174  9519 net.cpp:84] Creating Layer penlu19
I1005 13:00:40.193176  9519 net.cpp:406] penlu19 <- Eltwise9
I1005 13:00:40.193179  9519 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1005 13:00:40.193285  9519 net.cpp:122] Setting up penlu19
I1005 13:00:40.193289  9519 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 13:00:40.193291  9519 net.cpp:137] Memory required for data: 329594000
I1005 13:00:40.193295  9519 layer_factory.hpp:77] Creating layer Pooling1
I1005 13:00:40.193300  9519 net.cpp:84] Creating Layer Pooling1
I1005 13:00:40.193303  9519 net.cpp:406] Pooling1 <- Eltwise9
I1005 13:00:40.193306  9519 net.cpp:380] Pooling1 -> Pooling1
I1005 13:00:40.193449  9519 net.cpp:122] Setting up Pooling1
I1005 13:00:40.193457  9519 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 13:00:40.193460  9519 net.cpp:137] Memory required for data: 329619600
I1005 13:00:40.193462  9519 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 13:00:40.193471  9519 net.cpp:84] Creating Layer InnerProduct1
I1005 13:00:40.193475  9519 net.cpp:406] InnerProduct1 <- Pooling1
I1005 13:00:40.193478  9519 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 13:00:40.193572  9519 net.cpp:122] Setting up InnerProduct1
I1005 13:00:40.193576  9519 net.cpp:129] Top shape: 100 10 (1000)
I1005 13:00:40.193578  9519 net.cpp:137] Memory required for data: 329623600
I1005 13:00:40.193583  9519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 13:00:40.193586  9519 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 13:00:40.193589  9519 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1005 13:00:40.193593  9519 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1005 13:00:40.193595  9519 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 13:00:40.193601  9519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 13:00:40.194093  9519 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 13:00:40.194102  9519 net.cpp:129] Top shape: (1)
I1005 13:00:40.194104  9519 net.cpp:132]     with loss weight 1
I1005 13:00:40.194116  9519 net.cpp:137] Memory required for data: 329623604
I1005 13:00:40.194118  9519 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 13:00:40.194121  9519 net.cpp:198] InnerProduct1 needs backward computation.
I1005 13:00:40.194123  9519 net.cpp:198] Pooling1 needs backward computation.
I1005 13:00:40.194125  9519 net.cpp:198] penlu19 needs backward computation.
I1005 13:00:40.194128  9519 net.cpp:198] Eltwise9 needs backward computation.
I1005 13:00:40.194130  9519 net.cpp:198] Scale21 needs backward computation.
I1005 13:00:40.194133  9519 net.cpp:198] BatchNorm21 needs backward computation.
I1005 13:00:40.194134  9519 net.cpp:198] Convolution21 needs backward computation.
I1005 13:00:40.194136  9519 net.cpp:198] penlu18 needs backward computation.
I1005 13:00:40.194139  9519 net.cpp:198] Scale20 needs backward computation.
I1005 13:00:40.194139  9519 net.cpp:198] BatchNorm20 needs backward computation.
I1005 13:00:40.194141  9519 net.cpp:198] Convolution20 needs backward computation.
I1005 13:00:40.194149  9519 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1005 13:00:40.194152  9519 net.cpp:198] penlu17 needs backward computation.
I1005 13:00:40.194154  9519 net.cpp:198] Eltwise8 needs backward computation.
I1005 13:00:40.194156  9519 net.cpp:198] Scale19 needs backward computation.
I1005 13:00:40.194159  9519 net.cpp:198] BatchNorm19 needs backward computation.
I1005 13:00:40.194160  9519 net.cpp:198] Convolution19 needs backward computation.
I1005 13:00:40.194162  9519 net.cpp:198] penlu16 needs backward computation.
I1005 13:00:40.194164  9519 net.cpp:198] Scale18 needs backward computation.
I1005 13:00:40.194166  9519 net.cpp:198] BatchNorm18 needs backward computation.
I1005 13:00:40.194169  9519 net.cpp:198] Convolution18 needs backward computation.
I1005 13:00:40.194170  9519 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1005 13:00:40.194172  9519 net.cpp:198] penlu15 needs backward computation.
I1005 13:00:40.194175  9519 net.cpp:198] Eltwise7 needs backward computation.
I1005 13:00:40.194177  9519 net.cpp:198] Scale17 needs backward computation.
I1005 13:00:40.194180  9519 net.cpp:198] BatchNorm17 needs backward computation.
I1005 13:00:40.194181  9519 net.cpp:198] Convolution17 needs backward computation.
I1005 13:00:40.194183  9519 net.cpp:198] penlu14 needs backward computation.
I1005 13:00:40.194185  9519 net.cpp:198] Scale16 needs backward computation.
I1005 13:00:40.194187  9519 net.cpp:198] BatchNorm16 needs backward computation.
I1005 13:00:40.194190  9519 net.cpp:198] Convolution16 needs backward computation.
I1005 13:00:40.194192  9519 net.cpp:198] Scale15 needs backward computation.
I1005 13:00:40.194195  9519 net.cpp:198] BatchNorm15 needs backward computation.
I1005 13:00:40.194197  9519 net.cpp:198] Convolution15 needs backward computation.
I1005 13:00:40.194200  9519 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1005 13:00:40.194202  9519 net.cpp:198] penlu13 needs backward computation.
I1005 13:00:40.194205  9519 net.cpp:198] Eltwise6 needs backward computation.
I1005 13:00:40.194207  9519 net.cpp:198] Scale14 needs backward computation.
I1005 13:00:40.194211  9519 net.cpp:198] BatchNorm14 needs backward computation.
I1005 13:00:40.194212  9519 net.cpp:198] Convolution14 needs backward computation.
I1005 13:00:40.194214  9519 net.cpp:198] penlu12 needs backward computation.
I1005 13:00:40.194216  9519 net.cpp:198] Scale13 needs backward computation.
I1005 13:00:40.194218  9519 net.cpp:198] BatchNorm13 needs backward computation.
I1005 13:00:40.194221  9519 net.cpp:198] Convolution13 needs backward computation.
I1005 13:00:40.194223  9519 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1005 13:00:40.194226  9519 net.cpp:198] penlu11 needs backward computation.
I1005 13:00:40.194227  9519 net.cpp:198] Eltwise5 needs backward computation.
I1005 13:00:40.194231  9519 net.cpp:198] Scale12 needs backward computation.
I1005 13:00:40.194232  9519 net.cpp:198] BatchNorm12 needs backward computation.
I1005 13:00:40.194234  9519 net.cpp:198] Convolution12 needs backward computation.
I1005 13:00:40.194236  9519 net.cpp:198] penlu10 needs backward computation.
I1005 13:00:40.194238  9519 net.cpp:198] Scale11 needs backward computation.
I1005 13:00:40.194241  9519 net.cpp:198] BatchNorm11 needs backward computation.
I1005 13:00:40.194243  9519 net.cpp:198] Convolution11 needs backward computation.
I1005 13:00:40.194245  9519 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1005 13:00:40.194247  9519 net.cpp:198] penlu9 needs backward computation.
I1005 13:00:40.194249  9519 net.cpp:198] Eltwise4 needs backward computation.
I1005 13:00:40.194252  9519 net.cpp:198] Scale10 needs backward computation.
I1005 13:00:40.194254  9519 net.cpp:198] BatchNorm10 needs backward computation.
I1005 13:00:40.194257  9519 net.cpp:198] Convolution10 needs backward computation.
I1005 13:00:40.194258  9519 net.cpp:198] penlu8 needs backward computation.
I1005 13:00:40.194262  9519 net.cpp:198] Scale9 needs backward computation.
I1005 13:00:40.194267  9519 net.cpp:198] BatchNorm9 needs backward computation.
I1005 13:00:40.194268  9519 net.cpp:198] Convolution9 needs backward computation.
I1005 13:00:40.194270  9519 net.cpp:198] Scale8 needs backward computation.
I1005 13:00:40.194273  9519 net.cpp:198] BatchNorm8 needs backward computation.
I1005 13:00:40.194275  9519 net.cpp:198] Convolution8 needs backward computation.
I1005 13:00:40.194278  9519 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1005 13:00:40.194280  9519 net.cpp:198] penlu7 needs backward computation.
I1005 13:00:40.194283  9519 net.cpp:198] Eltwise3 needs backward computation.
I1005 13:00:40.194285  9519 net.cpp:198] Scale7 needs backward computation.
I1005 13:00:40.194288  9519 net.cpp:198] BatchNorm7 needs backward computation.
I1005 13:00:40.194289  9519 net.cpp:198] Convolution7 needs backward computation.
I1005 13:00:40.194291  9519 net.cpp:198] penlu6 needs backward computation.
I1005 13:00:40.194293  9519 net.cpp:198] Scale6 needs backward computation.
I1005 13:00:40.194295  9519 net.cpp:198] BatchNorm6 needs backward computation.
I1005 13:00:40.194298  9519 net.cpp:198] Convolution6 needs backward computation.
I1005 13:00:40.194300  9519 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1005 13:00:40.194303  9519 net.cpp:198] penlu5 needs backward computation.
I1005 13:00:40.194304  9519 net.cpp:198] Eltwise2 needs backward computation.
I1005 13:00:40.194308  9519 net.cpp:198] Scale5 needs backward computation.
I1005 13:00:40.194309  9519 net.cpp:198] BatchNorm5 needs backward computation.
I1005 13:00:40.194313  9519 net.cpp:198] Convolution5 needs backward computation.
I1005 13:00:40.194314  9519 net.cpp:198] penlu4 needs backward computation.
I1005 13:00:40.194316  9519 net.cpp:198] Scale4 needs backward computation.
I1005 13:00:40.194319  9519 net.cpp:198] BatchNorm4 needs backward computation.
I1005 13:00:40.194320  9519 net.cpp:198] Convolution4 needs backward computation.
I1005 13:00:40.194324  9519 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1005 13:00:40.194325  9519 net.cpp:198] penlu3 needs backward computation.
I1005 13:00:40.194327  9519 net.cpp:198] Eltwise1 needs backward computation.
I1005 13:00:40.194330  9519 net.cpp:198] Scale3 needs backward computation.
I1005 13:00:40.194332  9519 net.cpp:198] BatchNorm3 needs backward computation.
I1005 13:00:40.194334  9519 net.cpp:198] Convolution3 needs backward computation.
I1005 13:00:40.194336  9519 net.cpp:198] penlu2 needs backward computation.
I1005 13:00:40.194339  9519 net.cpp:198] Scale2 needs backward computation.
I1005 13:00:40.194341  9519 net.cpp:198] BatchNorm2 needs backward computation.
I1005 13:00:40.194344  9519 net.cpp:198] Convolution2 needs backward computation.
I1005 13:00:40.194345  9519 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1005 13:00:40.194349  9519 net.cpp:198] penlu1 needs backward computation.
I1005 13:00:40.194350  9519 net.cpp:198] Scale1 needs backward computation.
I1005 13:00:40.194352  9519 net.cpp:198] BatchNorm1 needs backward computation.
I1005 13:00:40.194355  9519 net.cpp:198] Convolution1 needs backward computation.
I1005 13:00:40.194357  9519 net.cpp:200] Data1 does not need backward computation.
I1005 13:00:40.194360  9519 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 13:00:40.194392  9519 net.cpp:255] Network initialization done.
I1005 13:00:40.196126  9519 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 13:00:40.196135  9519 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 13:00:40.196138  9519 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 13:00:40.196223  9519 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1005 13:00:40.196687  9519 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1005 13:00:40.196936  9519 layer_factory.hpp:77] Creating layer Data1
I1005 13:00:40.196975  9519 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1005 13:00:40.196985  9519 net.cpp:84] Creating Layer Data1
I1005 13:00:40.196990  9519 net.cpp:380] Data1 -> Data1
I1005 13:00:40.196995  9519 net.cpp:380] Data1 -> Data2
I1005 13:00:40.197001  9519 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 13:00:40.197109  9519 data_layer.cpp:45] output data size: 100,3,32,32
I1005 13:00:40.201110  9519 net.cpp:122] Setting up Data1
I1005 13:00:40.201131  9519 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 13:00:40.201135  9519 net.cpp:129] Top shape: 100 (100)
I1005 13:00:40.201138  9519 net.cpp:137] Memory required for data: 1229200
I1005 13:00:40.201143  9519 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1005 13:00:40.201153  9519 net.cpp:84] Creating Layer Data2_Data1_1_split
I1005 13:00:40.201155  9519 net.cpp:406] Data2_Data1_1_split <- Data2
I1005 13:00:40.201160  9519 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1005 13:00:40.201167  9519 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1005 13:00:40.201217  9519 net.cpp:122] Setting up Data2_Data1_1_split
I1005 13:00:40.201222  9519 net.cpp:129] Top shape: 100 (100)
I1005 13:00:40.201241  9519 net.cpp:129] Top shape: 100 (100)
I1005 13:00:40.201243  9519 net.cpp:137] Memory required for data: 1230000
I1005 13:00:40.201246  9519 layer_factory.hpp:77] Creating layer Convolution1
I1005 13:00:40.201256  9519 net.cpp:84] Creating Layer Convolution1
I1005 13:00:40.201258  9519 net.cpp:406] Convolution1 <- Data1
I1005 13:00:40.201262  9519 net.cpp:380] Convolution1 -> Convolution1
I1005 13:00:40.202376  9519 net.cpp:122] Setting up Convolution1
I1005 13:00:40.202385  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.202389  9519 net.cpp:137] Memory required for data: 7783600
I1005 13:00:40.202395  9519 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 13:00:40.202401  9519 net.cpp:84] Creating Layer BatchNorm1
I1005 13:00:40.202404  9519 net.cpp:406] BatchNorm1 <- Convolution1
I1005 13:00:40.202407  9519 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 13:00:40.202574  9519 net.cpp:122] Setting up BatchNorm1
I1005 13:00:40.202581  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.202584  9519 net.cpp:137] Memory required for data: 14337200
I1005 13:00:40.202590  9519 layer_factory.hpp:77] Creating layer Scale1
I1005 13:00:40.202597  9519 net.cpp:84] Creating Layer Scale1
I1005 13:00:40.202600  9519 net.cpp:406] Scale1 <- Convolution1
I1005 13:00:40.202603  9519 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 13:00:40.202632  9519 layer_factory.hpp:77] Creating layer Scale1
I1005 13:00:40.202708  9519 net.cpp:122] Setting up Scale1
I1005 13:00:40.202711  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.202714  9519 net.cpp:137] Memory required for data: 20890800
I1005 13:00:40.202719  9519 layer_factory.hpp:77] Creating layer penlu1
I1005 13:00:40.202725  9519 net.cpp:84] Creating Layer penlu1
I1005 13:00:40.202728  9519 net.cpp:406] penlu1 <- Convolution1
I1005 13:00:40.202731  9519 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1005 13:00:40.202847  9519 net.cpp:122] Setting up penlu1
I1005 13:00:40.202852  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.202853  9519 net.cpp:137] Memory required for data: 27444400
I1005 13:00:40.202860  9519 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1005 13:00:40.202865  9519 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1005 13:00:40.202872  9519 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1005 13:00:40.202875  9519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1005 13:00:40.202879  9519 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1005 13:00:40.202903  9519 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1005 13:00:40.202908  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.202910  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.202913  9519 net.cpp:137] Memory required for data: 40551600
I1005 13:00:40.202915  9519 layer_factory.hpp:77] Creating layer Convolution2
I1005 13:00:40.202921  9519 net.cpp:84] Creating Layer Convolution2
I1005 13:00:40.202924  9519 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1005 13:00:40.202929  9519 net.cpp:380] Convolution2 -> Convolution2
I1005 13:00:40.203536  9519 net.cpp:122] Setting up Convolution2
I1005 13:00:40.203543  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.203546  9519 net.cpp:137] Memory required for data: 47105200
I1005 13:00:40.203550  9519 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 13:00:40.203557  9519 net.cpp:84] Creating Layer BatchNorm2
I1005 13:00:40.203559  9519 net.cpp:406] BatchNorm2 <- Convolution2
I1005 13:00:40.203563  9519 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 13:00:40.203806  9519 net.cpp:122] Setting up BatchNorm2
I1005 13:00:40.203812  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.203819  9519 net.cpp:137] Memory required for data: 53658800
I1005 13:00:40.203822  9519 layer_factory.hpp:77] Creating layer Scale2
I1005 13:00:40.203827  9519 net.cpp:84] Creating Layer Scale2
I1005 13:00:40.203838  9519 net.cpp:406] Scale2 <- Convolution2
I1005 13:00:40.203843  9519 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 13:00:40.203871  9519 layer_factory.hpp:77] Creating layer Scale2
I1005 13:00:40.203946  9519 net.cpp:122] Setting up Scale2
I1005 13:00:40.203951  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.203956  9519 net.cpp:137] Memory required for data: 60212400
I1005 13:00:40.203963  9519 layer_factory.hpp:77] Creating layer penlu2
I1005 13:00:40.203969  9519 net.cpp:84] Creating Layer penlu2
I1005 13:00:40.203971  9519 net.cpp:406] penlu2 <- Convolution2
I1005 13:00:40.203975  9519 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1005 13:00:40.204094  9519 net.cpp:122] Setting up penlu2
I1005 13:00:40.204098  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.204102  9519 net.cpp:137] Memory required for data: 66766000
I1005 13:00:40.204107  9519 layer_factory.hpp:77] Creating layer Convolution3
I1005 13:00:40.204113  9519 net.cpp:84] Creating Layer Convolution3
I1005 13:00:40.204115  9519 net.cpp:406] Convolution3 <- Convolution2
I1005 13:00:40.204119  9519 net.cpp:380] Convolution3 -> Convolution3
I1005 13:00:40.205162  9519 net.cpp:122] Setting up Convolution3
I1005 13:00:40.205170  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.205173  9519 net.cpp:137] Memory required for data: 73319600
I1005 13:00:40.205178  9519 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 13:00:40.205184  9519 net.cpp:84] Creating Layer BatchNorm3
I1005 13:00:40.205188  9519 net.cpp:406] BatchNorm3 <- Convolution3
I1005 13:00:40.205190  9519 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 13:00:40.205325  9519 net.cpp:122] Setting up BatchNorm3
I1005 13:00:40.205329  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.205332  9519 net.cpp:137] Memory required for data: 79873200
I1005 13:00:40.205338  9519 layer_factory.hpp:77] Creating layer Scale3
I1005 13:00:40.205341  9519 net.cpp:84] Creating Layer Scale3
I1005 13:00:40.205344  9519 net.cpp:406] Scale3 <- Convolution3
I1005 13:00:40.205348  9519 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 13:00:40.205374  9519 layer_factory.hpp:77] Creating layer Scale3
I1005 13:00:40.205447  9519 net.cpp:122] Setting up Scale3
I1005 13:00:40.205452  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.205454  9519 net.cpp:137] Memory required for data: 86426800
I1005 13:00:40.205458  9519 layer_factory.hpp:77] Creating layer Eltwise1
I1005 13:00:40.205463  9519 net.cpp:84] Creating Layer Eltwise1
I1005 13:00:40.205466  9519 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1005 13:00:40.205471  9519 net.cpp:406] Eltwise1 <- Convolution3
I1005 13:00:40.205473  9519 net.cpp:380] Eltwise1 -> Eltwise1
I1005 13:00:40.205489  9519 net.cpp:122] Setting up Eltwise1
I1005 13:00:40.205494  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.205497  9519 net.cpp:137] Memory required for data: 92980400
I1005 13:00:40.205498  9519 layer_factory.hpp:77] Creating layer penlu3
I1005 13:00:40.205503  9519 net.cpp:84] Creating Layer penlu3
I1005 13:00:40.205507  9519 net.cpp:406] penlu3 <- Eltwise1
I1005 13:00:40.205509  9519 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1005 13:00:40.205622  9519 net.cpp:122] Setting up penlu3
I1005 13:00:40.205627  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.205629  9519 net.cpp:137] Memory required for data: 99534000
I1005 13:00:40.205634  9519 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1005 13:00:40.205639  9519 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1005 13:00:40.205641  9519 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1005 13:00:40.205644  9519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1005 13:00:40.205649  9519 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1005 13:00:40.205672  9519 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1005 13:00:40.205675  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.205684  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.205687  9519 net.cpp:137] Memory required for data: 112641200
I1005 13:00:40.205690  9519 layer_factory.hpp:77] Creating layer Convolution4
I1005 13:00:40.205696  9519 net.cpp:84] Creating Layer Convolution4
I1005 13:00:40.205699  9519 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1005 13:00:40.205703  9519 net.cpp:380] Convolution4 -> Convolution4
I1005 13:00:40.206764  9519 net.cpp:122] Setting up Convolution4
I1005 13:00:40.206775  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.206778  9519 net.cpp:137] Memory required for data: 119194800
I1005 13:00:40.206782  9519 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 13:00:40.206787  9519 net.cpp:84] Creating Layer BatchNorm4
I1005 13:00:40.206790  9519 net.cpp:406] BatchNorm4 <- Convolution4
I1005 13:00:40.206795  9519 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 13:00:40.206926  9519 net.cpp:122] Setting up BatchNorm4
I1005 13:00:40.206930  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.206933  9519 net.cpp:137] Memory required for data: 125748400
I1005 13:00:40.206943  9519 layer_factory.hpp:77] Creating layer Scale4
I1005 13:00:40.206946  9519 net.cpp:84] Creating Layer Scale4
I1005 13:00:40.206949  9519 net.cpp:406] Scale4 <- Convolution4
I1005 13:00:40.206953  9519 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 13:00:40.206980  9519 layer_factory.hpp:77] Creating layer Scale4
I1005 13:00:40.207054  9519 net.cpp:122] Setting up Scale4
I1005 13:00:40.207058  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.207060  9519 net.cpp:137] Memory required for data: 132302000
I1005 13:00:40.207064  9519 layer_factory.hpp:77] Creating layer penlu4
I1005 13:00:40.207069  9519 net.cpp:84] Creating Layer penlu4
I1005 13:00:40.207072  9519 net.cpp:406] penlu4 <- Convolution4
I1005 13:00:40.207077  9519 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1005 13:00:40.207190  9519 net.cpp:122] Setting up penlu4
I1005 13:00:40.207195  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.207206  9519 net.cpp:137] Memory required for data: 138855600
I1005 13:00:40.207209  9519 layer_factory.hpp:77] Creating layer Convolution5
I1005 13:00:40.207216  9519 net.cpp:84] Creating Layer Convolution5
I1005 13:00:40.207218  9519 net.cpp:406] Convolution5 <- Convolution4
I1005 13:00:40.207222  9519 net.cpp:380] Convolution5 -> Convolution5
I1005 13:00:40.208487  9519 net.cpp:122] Setting up Convolution5
I1005 13:00:40.208494  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.208498  9519 net.cpp:137] Memory required for data: 145409200
I1005 13:00:40.208503  9519 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 13:00:40.208508  9519 net.cpp:84] Creating Layer BatchNorm5
I1005 13:00:40.208510  9519 net.cpp:406] BatchNorm5 <- Convolution5
I1005 13:00:40.208514  9519 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 13:00:40.208648  9519 net.cpp:122] Setting up BatchNorm5
I1005 13:00:40.208653  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.208655  9519 net.cpp:137] Memory required for data: 151962800
I1005 13:00:40.208660  9519 layer_factory.hpp:77] Creating layer Scale5
I1005 13:00:40.208664  9519 net.cpp:84] Creating Layer Scale5
I1005 13:00:40.208667  9519 net.cpp:406] Scale5 <- Convolution5
I1005 13:00:40.208670  9519 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 13:00:40.208696  9519 layer_factory.hpp:77] Creating layer Scale5
I1005 13:00:40.208772  9519 net.cpp:122] Setting up Scale5
I1005 13:00:40.208777  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.208780  9519 net.cpp:137] Memory required for data: 158516400
I1005 13:00:40.208783  9519 layer_factory.hpp:77] Creating layer Eltwise2
I1005 13:00:40.208786  9519 net.cpp:84] Creating Layer Eltwise2
I1005 13:00:40.208789  9519 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1005 13:00:40.208792  9519 net.cpp:406] Eltwise2 <- Convolution5
I1005 13:00:40.208796  9519 net.cpp:380] Eltwise2 -> Eltwise2
I1005 13:00:40.208822  9519 net.cpp:122] Setting up Eltwise2
I1005 13:00:40.208825  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.208827  9519 net.cpp:137] Memory required for data: 165070000
I1005 13:00:40.208829  9519 layer_factory.hpp:77] Creating layer penlu5
I1005 13:00:40.208833  9519 net.cpp:84] Creating Layer penlu5
I1005 13:00:40.208837  9519 net.cpp:406] penlu5 <- Eltwise2
I1005 13:00:40.208839  9519 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1005 13:00:40.208953  9519 net.cpp:122] Setting up penlu5
I1005 13:00:40.208958  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.208961  9519 net.cpp:137] Memory required for data: 171623600
I1005 13:00:40.208964  9519 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1005 13:00:40.208968  9519 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1005 13:00:40.208971  9519 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1005 13:00:40.208973  9519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1005 13:00:40.208977  9519 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1005 13:00:40.209000  9519 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1005 13:00:40.209004  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.209007  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.209009  9519 net.cpp:137] Memory required for data: 184730800
I1005 13:00:40.209012  9519 layer_factory.hpp:77] Creating layer Convolution6
I1005 13:00:40.209018  9519 net.cpp:84] Creating Layer Convolution6
I1005 13:00:40.209020  9519 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1005 13:00:40.209024  9519 net.cpp:380] Convolution6 -> Convolution6
I1005 13:00:40.209926  9519 net.cpp:122] Setting up Convolution6
I1005 13:00:40.209936  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.209939  9519 net.cpp:137] Memory required for data: 191284400
I1005 13:00:40.209944  9519 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 13:00:40.209947  9519 net.cpp:84] Creating Layer BatchNorm6
I1005 13:00:40.209950  9519 net.cpp:406] BatchNorm6 <- Convolution6
I1005 13:00:40.209954  9519 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 13:00:40.210089  9519 net.cpp:122] Setting up BatchNorm6
I1005 13:00:40.210093  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.210095  9519 net.cpp:137] Memory required for data: 197838000
I1005 13:00:40.210100  9519 layer_factory.hpp:77] Creating layer Scale6
I1005 13:00:40.210104  9519 net.cpp:84] Creating Layer Scale6
I1005 13:00:40.210106  9519 net.cpp:406] Scale6 <- Convolution6
I1005 13:00:40.210109  9519 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 13:00:40.210135  9519 layer_factory.hpp:77] Creating layer Scale6
I1005 13:00:40.210209  9519 net.cpp:122] Setting up Scale6
I1005 13:00:40.210214  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.210216  9519 net.cpp:137] Memory required for data: 204391600
I1005 13:00:40.210219  9519 layer_factory.hpp:77] Creating layer penlu6
I1005 13:00:40.210225  9519 net.cpp:84] Creating Layer penlu6
I1005 13:00:40.210227  9519 net.cpp:406] penlu6 <- Convolution6
I1005 13:00:40.210230  9519 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1005 13:00:40.210345  9519 net.cpp:122] Setting up penlu6
I1005 13:00:40.210350  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.210352  9519 net.cpp:137] Memory required for data: 210945200
I1005 13:00:40.210356  9519 layer_factory.hpp:77] Creating layer Convolution7
I1005 13:00:40.210364  9519 net.cpp:84] Creating Layer Convolution7
I1005 13:00:40.210366  9519 net.cpp:406] Convolution7 <- Convolution6
I1005 13:00:40.210371  9519 net.cpp:380] Convolution7 -> Convolution7
I1005 13:00:40.211305  9519 net.cpp:122] Setting up Convolution7
I1005 13:00:40.211314  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.211318  9519 net.cpp:137] Memory required for data: 217498800
I1005 13:00:40.211323  9519 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 13:00:40.211335  9519 net.cpp:84] Creating Layer BatchNorm7
I1005 13:00:40.211338  9519 net.cpp:406] BatchNorm7 <- Convolution7
I1005 13:00:40.211344  9519 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 13:00:40.211483  9519 net.cpp:122] Setting up BatchNorm7
I1005 13:00:40.211488  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.211489  9519 net.cpp:137] Memory required for data: 224052400
I1005 13:00:40.211499  9519 layer_factory.hpp:77] Creating layer Scale7
I1005 13:00:40.211503  9519 net.cpp:84] Creating Layer Scale7
I1005 13:00:40.211506  9519 net.cpp:406] Scale7 <- Convolution7
I1005 13:00:40.211509  9519 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 13:00:40.211539  9519 layer_factory.hpp:77] Creating layer Scale7
I1005 13:00:40.211616  9519 net.cpp:122] Setting up Scale7
I1005 13:00:40.211621  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.211623  9519 net.cpp:137] Memory required for data: 230606000
I1005 13:00:40.211627  9519 layer_factory.hpp:77] Creating layer Eltwise3
I1005 13:00:40.211630  9519 net.cpp:84] Creating Layer Eltwise3
I1005 13:00:40.211633  9519 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1005 13:00:40.211637  9519 net.cpp:406] Eltwise3 <- Convolution7
I1005 13:00:40.211639  9519 net.cpp:380] Eltwise3 -> Eltwise3
I1005 13:00:40.211655  9519 net.cpp:122] Setting up Eltwise3
I1005 13:00:40.211659  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.211661  9519 net.cpp:137] Memory required for data: 237159600
I1005 13:00:40.211663  9519 layer_factory.hpp:77] Creating layer penlu7
I1005 13:00:40.211668  9519 net.cpp:84] Creating Layer penlu7
I1005 13:00:40.211670  9519 net.cpp:406] penlu7 <- Eltwise3
I1005 13:00:40.211674  9519 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1005 13:00:40.211792  9519 net.cpp:122] Setting up penlu7
I1005 13:00:40.211796  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.211799  9519 net.cpp:137] Memory required for data: 243713200
I1005 13:00:40.211803  9519 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1005 13:00:40.211807  9519 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1005 13:00:40.211809  9519 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1005 13:00:40.211812  9519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1005 13:00:40.211815  9519 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1005 13:00:40.211839  9519 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1005 13:00:40.211843  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.211845  9519 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 13:00:40.211848  9519 net.cpp:137] Memory required for data: 256820400
I1005 13:00:40.211849  9519 layer_factory.hpp:77] Creating layer Convolution8
I1005 13:00:40.211855  9519 net.cpp:84] Creating Layer Convolution8
I1005 13:00:40.211858  9519 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1005 13:00:40.211863  9519 net.cpp:380] Convolution8 -> Convolution8
I1005 13:00:40.212749  9519 net.cpp:122] Setting up Convolution8
I1005 13:00:40.212757  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.212759  9519 net.cpp:137] Memory required for data: 260097200
I1005 13:00:40.212764  9519 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 13:00:40.212769  9519 net.cpp:84] Creating Layer BatchNorm8
I1005 13:00:40.212771  9519 net.cpp:406] BatchNorm8 <- Convolution8
I1005 13:00:40.212775  9519 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 13:00:40.212904  9519 net.cpp:122] Setting up BatchNorm8
I1005 13:00:40.212909  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.212911  9519 net.cpp:137] Memory required for data: 263374000
I1005 13:00:40.212915  9519 layer_factory.hpp:77] Creating layer Scale8
I1005 13:00:40.212919  9519 net.cpp:84] Creating Layer Scale8
I1005 13:00:40.214507  9519 net.cpp:406] Scale8 <- Convolution8
I1005 13:00:40.214511  9519 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 13:00:40.214553  9519 layer_factory.hpp:77] Creating layer Scale8
I1005 13:00:40.214646  9519 net.cpp:122] Setting up Scale8
I1005 13:00:40.214653  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.214654  9519 net.cpp:137] Memory required for data: 266650800
I1005 13:00:40.214658  9519 layer_factory.hpp:77] Creating layer Convolution9
I1005 13:00:40.214665  9519 net.cpp:84] Creating Layer Convolution9
I1005 13:00:40.214668  9519 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1005 13:00:40.214673  9519 net.cpp:380] Convolution9 -> Convolution9
I1005 13:00:40.215732  9519 net.cpp:122] Setting up Convolution9
I1005 13:00:40.215741  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.215744  9519 net.cpp:137] Memory required for data: 269927600
I1005 13:00:40.215749  9519 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 13:00:40.215754  9519 net.cpp:84] Creating Layer BatchNorm9
I1005 13:00:40.215766  9519 net.cpp:406] BatchNorm9 <- Convolution9
I1005 13:00:40.215770  9519 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 13:00:40.215935  9519 net.cpp:122] Setting up BatchNorm9
I1005 13:00:40.215945  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.215950  9519 net.cpp:137] Memory required for data: 273204400
I1005 13:00:40.215957  9519 layer_factory.hpp:77] Creating layer Scale9
I1005 13:00:40.215966  9519 net.cpp:84] Creating Layer Scale9
I1005 13:00:40.215971  9519 net.cpp:406] Scale9 <- Convolution9
I1005 13:00:40.215977  9519 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 13:00:40.216018  9519 layer_factory.hpp:77] Creating layer Scale9
I1005 13:00:40.216150  9519 net.cpp:122] Setting up Scale9
I1005 13:00:40.216158  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.216161  9519 net.cpp:137] Memory required for data: 276481200
I1005 13:00:40.216166  9519 layer_factory.hpp:77] Creating layer penlu8
I1005 13:00:40.216172  9519 net.cpp:84] Creating Layer penlu8
I1005 13:00:40.216184  9519 net.cpp:406] penlu8 <- Convolution9
I1005 13:00:40.216189  9519 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1005 13:00:40.216353  9519 net.cpp:122] Setting up penlu8
I1005 13:00:40.216363  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.216368  9519 net.cpp:137] Memory required for data: 279758000
I1005 13:00:40.216377  9519 layer_factory.hpp:77] Creating layer Convolution10
I1005 13:00:40.216387  9519 net.cpp:84] Creating Layer Convolution10
I1005 13:00:40.216392  9519 net.cpp:406] Convolution10 <- Convolution9
I1005 13:00:40.216397  9519 net.cpp:380] Convolution10 -> Convolution10
I1005 13:00:40.217546  9519 net.cpp:122] Setting up Convolution10
I1005 13:00:40.217556  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.217558  9519 net.cpp:137] Memory required for data: 283034800
I1005 13:00:40.217563  9519 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 13:00:40.217568  9519 net.cpp:84] Creating Layer BatchNorm10
I1005 13:00:40.217571  9519 net.cpp:406] BatchNorm10 <- Convolution10
I1005 13:00:40.217576  9519 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 13:00:40.217711  9519 net.cpp:122] Setting up BatchNorm10
I1005 13:00:40.217716  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.217718  9519 net.cpp:137] Memory required for data: 286311600
I1005 13:00:40.217723  9519 layer_factory.hpp:77] Creating layer Scale10
I1005 13:00:40.217727  9519 net.cpp:84] Creating Layer Scale10
I1005 13:00:40.217730  9519 net.cpp:406] Scale10 <- Convolution10
I1005 13:00:40.217733  9519 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 13:00:40.217761  9519 layer_factory.hpp:77] Creating layer Scale10
I1005 13:00:40.217849  9519 net.cpp:122] Setting up Scale10
I1005 13:00:40.217854  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.217855  9519 net.cpp:137] Memory required for data: 289588400
I1005 13:00:40.217859  9519 layer_factory.hpp:77] Creating layer Eltwise4
I1005 13:00:40.217864  9519 net.cpp:84] Creating Layer Eltwise4
I1005 13:00:40.217865  9519 net.cpp:406] Eltwise4 <- Convolution8
I1005 13:00:40.217869  9519 net.cpp:406] Eltwise4 <- Convolution10
I1005 13:00:40.217880  9519 net.cpp:380] Eltwise4 -> Eltwise4
I1005 13:00:40.217895  9519 net.cpp:122] Setting up Eltwise4
I1005 13:00:40.217907  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.217909  9519 net.cpp:137] Memory required for data: 292865200
I1005 13:00:40.217911  9519 layer_factory.hpp:77] Creating layer penlu9
I1005 13:00:40.217917  9519 net.cpp:84] Creating Layer penlu9
I1005 13:00:40.217919  9519 net.cpp:406] penlu9 <- Eltwise4
I1005 13:00:40.217923  9519 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1005 13:00:40.218040  9519 net.cpp:122] Setting up penlu9
I1005 13:00:40.218045  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.218047  9519 net.cpp:137] Memory required for data: 296142000
I1005 13:00:40.218051  9519 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1005 13:00:40.218055  9519 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1005 13:00:40.218057  9519 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1005 13:00:40.218060  9519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1005 13:00:40.218065  9519 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1005 13:00:40.218088  9519 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1005 13:00:40.218092  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.218096  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.218097  9519 net.cpp:137] Memory required for data: 302695600
I1005 13:00:40.218099  9519 layer_factory.hpp:77] Creating layer Convolution11
I1005 13:00:40.218106  9519 net.cpp:84] Creating Layer Convolution11
I1005 13:00:40.218108  9519 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1005 13:00:40.218112  9519 net.cpp:380] Convolution11 -> Convolution11
I1005 13:00:40.219209  9519 net.cpp:122] Setting up Convolution11
I1005 13:00:40.219218  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.219220  9519 net.cpp:137] Memory required for data: 305972400
I1005 13:00:40.219224  9519 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 13:00:40.219229  9519 net.cpp:84] Creating Layer BatchNorm11
I1005 13:00:40.219233  9519 net.cpp:406] BatchNorm11 <- Convolution11
I1005 13:00:40.219236  9519 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 13:00:40.219368  9519 net.cpp:122] Setting up BatchNorm11
I1005 13:00:40.219372  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.219375  9519 net.cpp:137] Memory required for data: 309249200
I1005 13:00:40.219379  9519 layer_factory.hpp:77] Creating layer Scale11
I1005 13:00:40.219383  9519 net.cpp:84] Creating Layer Scale11
I1005 13:00:40.219385  9519 net.cpp:406] Scale11 <- Convolution11
I1005 13:00:40.219389  9519 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 13:00:40.219415  9519 layer_factory.hpp:77] Creating layer Scale11
I1005 13:00:40.219491  9519 net.cpp:122] Setting up Scale11
I1005 13:00:40.219494  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.219497  9519 net.cpp:137] Memory required for data: 312526000
I1005 13:00:40.219501  9519 layer_factory.hpp:77] Creating layer penlu10
I1005 13:00:40.219506  9519 net.cpp:84] Creating Layer penlu10
I1005 13:00:40.219508  9519 net.cpp:406] penlu10 <- Convolution11
I1005 13:00:40.219511  9519 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1005 13:00:40.219619  9519 net.cpp:122] Setting up penlu10
I1005 13:00:40.219624  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.219626  9519 net.cpp:137] Memory required for data: 315802800
I1005 13:00:40.219630  9519 layer_factory.hpp:77] Creating layer Convolution12
I1005 13:00:40.219637  9519 net.cpp:84] Creating Layer Convolution12
I1005 13:00:40.219640  9519 net.cpp:406] Convolution12 <- Convolution11
I1005 13:00:40.219645  9519 net.cpp:380] Convolution12 -> Convolution12
I1005 13:00:40.220365  9519 net.cpp:122] Setting up Convolution12
I1005 13:00:40.220371  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.220374  9519 net.cpp:137] Memory required for data: 319079600
I1005 13:00:40.220384  9519 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 13:00:40.220388  9519 net.cpp:84] Creating Layer BatchNorm12
I1005 13:00:40.220391  9519 net.cpp:406] BatchNorm12 <- Convolution12
I1005 13:00:40.220396  9519 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 13:00:40.220530  9519 net.cpp:122] Setting up BatchNorm12
I1005 13:00:40.220533  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.220535  9519 net.cpp:137] Memory required for data: 322356400
I1005 13:00:40.220541  9519 layer_factory.hpp:77] Creating layer Scale12
I1005 13:00:40.220544  9519 net.cpp:84] Creating Layer Scale12
I1005 13:00:40.220546  9519 net.cpp:406] Scale12 <- Convolution12
I1005 13:00:40.220549  9519 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 13:00:40.220577  9519 layer_factory.hpp:77] Creating layer Scale12
I1005 13:00:40.220651  9519 net.cpp:122] Setting up Scale12
I1005 13:00:40.220655  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.220657  9519 net.cpp:137] Memory required for data: 325633200
I1005 13:00:40.220661  9519 layer_factory.hpp:77] Creating layer Eltwise5
I1005 13:00:40.220665  9519 net.cpp:84] Creating Layer Eltwise5
I1005 13:00:40.220669  9519 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1005 13:00:40.220671  9519 net.cpp:406] Eltwise5 <- Convolution12
I1005 13:00:40.220674  9519 net.cpp:380] Eltwise5 -> Eltwise5
I1005 13:00:40.220686  9519 net.cpp:122] Setting up Eltwise5
I1005 13:00:40.220690  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.220691  9519 net.cpp:137] Memory required for data: 328910000
I1005 13:00:40.220695  9519 layer_factory.hpp:77] Creating layer penlu11
I1005 13:00:40.220700  9519 net.cpp:84] Creating Layer penlu11
I1005 13:00:40.220702  9519 net.cpp:406] penlu11 <- Eltwise5
I1005 13:00:40.220705  9519 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1005 13:00:40.220818  9519 net.cpp:122] Setting up penlu11
I1005 13:00:40.220821  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.220824  9519 net.cpp:137] Memory required for data: 332186800
I1005 13:00:40.220827  9519 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1005 13:00:40.220831  9519 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1005 13:00:40.220834  9519 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1005 13:00:40.220837  9519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1005 13:00:40.220841  9519 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1005 13:00:40.220866  9519 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1005 13:00:40.220870  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.220873  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.220876  9519 net.cpp:137] Memory required for data: 338740400
I1005 13:00:40.220878  9519 layer_factory.hpp:77] Creating layer Convolution13
I1005 13:00:40.220885  9519 net.cpp:84] Creating Layer Convolution13
I1005 13:00:40.220886  9519 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1005 13:00:40.220890  9519 net.cpp:380] Convolution13 -> Convolution13
I1005 13:00:40.221937  9519 net.cpp:122] Setting up Convolution13
I1005 13:00:40.221946  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.221948  9519 net.cpp:137] Memory required for data: 342017200
I1005 13:00:40.221952  9519 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 13:00:40.221957  9519 net.cpp:84] Creating Layer BatchNorm13
I1005 13:00:40.221961  9519 net.cpp:406] BatchNorm13 <- Convolution13
I1005 13:00:40.221964  9519 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 13:00:40.222097  9519 net.cpp:122] Setting up BatchNorm13
I1005 13:00:40.222101  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.222103  9519 net.cpp:137] Memory required for data: 345294000
I1005 13:00:40.222108  9519 layer_factory.hpp:77] Creating layer Scale13
I1005 13:00:40.222113  9519 net.cpp:84] Creating Layer Scale13
I1005 13:00:40.222115  9519 net.cpp:406] Scale13 <- Convolution13
I1005 13:00:40.222126  9519 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 13:00:40.222153  9519 layer_factory.hpp:77] Creating layer Scale13
I1005 13:00:40.222231  9519 net.cpp:122] Setting up Scale13
I1005 13:00:40.222235  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.222239  9519 net.cpp:137] Memory required for data: 348570800
I1005 13:00:40.222242  9519 layer_factory.hpp:77] Creating layer penlu12
I1005 13:00:40.222247  9519 net.cpp:84] Creating Layer penlu12
I1005 13:00:40.222250  9519 net.cpp:406] penlu12 <- Convolution13
I1005 13:00:40.222254  9519 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1005 13:00:40.222362  9519 net.cpp:122] Setting up penlu12
I1005 13:00:40.222368  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.222369  9519 net.cpp:137] Memory required for data: 351847600
I1005 13:00:40.222373  9519 layer_factory.hpp:77] Creating layer Convolution14
I1005 13:00:40.222383  9519 net.cpp:84] Creating Layer Convolution14
I1005 13:00:40.222385  9519 net.cpp:406] Convolution14 <- Convolution13
I1005 13:00:40.222389  9519 net.cpp:380] Convolution14 -> Convolution14
I1005 13:00:40.223449  9519 net.cpp:122] Setting up Convolution14
I1005 13:00:40.223457  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.223460  9519 net.cpp:137] Memory required for data: 355124400
I1005 13:00:40.223474  9519 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 13:00:40.223479  9519 net.cpp:84] Creating Layer BatchNorm14
I1005 13:00:40.223482  9519 net.cpp:406] BatchNorm14 <- Convolution14
I1005 13:00:40.223486  9519 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 13:00:40.223619  9519 net.cpp:122] Setting up BatchNorm14
I1005 13:00:40.223623  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.223625  9519 net.cpp:137] Memory required for data: 358401200
I1005 13:00:40.223633  9519 layer_factory.hpp:77] Creating layer Scale14
I1005 13:00:40.223636  9519 net.cpp:84] Creating Layer Scale14
I1005 13:00:40.223639  9519 net.cpp:406] Scale14 <- Convolution14
I1005 13:00:40.223641  9519 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 13:00:40.223668  9519 layer_factory.hpp:77] Creating layer Scale14
I1005 13:00:40.223744  9519 net.cpp:122] Setting up Scale14
I1005 13:00:40.223749  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.223752  9519 net.cpp:137] Memory required for data: 361678000
I1005 13:00:40.223754  9519 layer_factory.hpp:77] Creating layer Eltwise6
I1005 13:00:40.223758  9519 net.cpp:84] Creating Layer Eltwise6
I1005 13:00:40.223762  9519 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1005 13:00:40.223764  9519 net.cpp:406] Eltwise6 <- Convolution14
I1005 13:00:40.223767  9519 net.cpp:380] Eltwise6 -> Eltwise6
I1005 13:00:40.223779  9519 net.cpp:122] Setting up Eltwise6
I1005 13:00:40.223783  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.223785  9519 net.cpp:137] Memory required for data: 364954800
I1005 13:00:40.223788  9519 layer_factory.hpp:77] Creating layer penlu13
I1005 13:00:40.223793  9519 net.cpp:84] Creating Layer penlu13
I1005 13:00:40.223795  9519 net.cpp:406] penlu13 <- Eltwise6
I1005 13:00:40.223798  9519 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1005 13:00:40.223912  9519 net.cpp:122] Setting up penlu13
I1005 13:00:40.223917  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.223918  9519 net.cpp:137] Memory required for data: 368231600
I1005 13:00:40.223922  9519 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1005 13:00:40.223927  9519 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1005 13:00:40.223928  9519 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1005 13:00:40.223932  9519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1005 13:00:40.245002  9519 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1005 13:00:40.245043  9519 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1005 13:00:40.245048  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.245059  9519 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 13:00:40.245062  9519 net.cpp:137] Memory required for data: 374785200
I1005 13:00:40.245065  9519 layer_factory.hpp:77] Creating layer Convolution15
I1005 13:00:40.245075  9519 net.cpp:84] Creating Layer Convolution15
I1005 13:00:40.245079  9519 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1005 13:00:40.245084  9519 net.cpp:380] Convolution15 -> Convolution15
I1005 13:00:40.246119  9519 net.cpp:122] Setting up Convolution15
I1005 13:00:40.246129  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.246130  9519 net.cpp:137] Memory required for data: 376423600
I1005 13:00:40.246135  9519 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 13:00:40.246141  9519 net.cpp:84] Creating Layer BatchNorm15
I1005 13:00:40.246145  9519 net.cpp:406] BatchNorm15 <- Convolution15
I1005 13:00:40.246147  9519 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 13:00:40.246312  9519 net.cpp:122] Setting up BatchNorm15
I1005 13:00:40.246317  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.246320  9519 net.cpp:137] Memory required for data: 378062000
I1005 13:00:40.246325  9519 layer_factory.hpp:77] Creating layer Scale15
I1005 13:00:40.246328  9519 net.cpp:84] Creating Layer Scale15
I1005 13:00:40.246331  9519 net.cpp:406] Scale15 <- Convolution15
I1005 13:00:40.246335  9519 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 13:00:40.246367  9519 layer_factory.hpp:77] Creating layer Scale15
I1005 13:00:40.246497  9519 net.cpp:122] Setting up Scale15
I1005 13:00:40.246508  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.246512  9519 net.cpp:137] Memory required for data: 379700400
I1005 13:00:40.246529  9519 layer_factory.hpp:77] Creating layer Convolution16
I1005 13:00:40.246543  9519 net.cpp:84] Creating Layer Convolution16
I1005 13:00:40.246549  9519 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1005 13:00:40.246558  9519 net.cpp:380] Convolution16 -> Convolution16
I1005 13:00:40.247989  9519 net.cpp:122] Setting up Convolution16
I1005 13:00:40.247999  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.248003  9519 net.cpp:137] Memory required for data: 381338800
I1005 13:00:40.248008  9519 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 13:00:40.248013  9519 net.cpp:84] Creating Layer BatchNorm16
I1005 13:00:40.248014  9519 net.cpp:406] BatchNorm16 <- Convolution16
I1005 13:00:40.248019  9519 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 13:00:40.248162  9519 net.cpp:122] Setting up BatchNorm16
I1005 13:00:40.248167  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.248169  9519 net.cpp:137] Memory required for data: 382977200
I1005 13:00:40.248174  9519 layer_factory.hpp:77] Creating layer Scale16
I1005 13:00:40.248178  9519 net.cpp:84] Creating Layer Scale16
I1005 13:00:40.248181  9519 net.cpp:406] Scale16 <- Convolution16
I1005 13:00:40.248185  9519 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 13:00:40.248212  9519 layer_factory.hpp:77] Creating layer Scale16
I1005 13:00:40.248294  9519 net.cpp:122] Setting up Scale16
I1005 13:00:40.248299  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.248301  9519 net.cpp:137] Memory required for data: 384615600
I1005 13:00:40.248306  9519 layer_factory.hpp:77] Creating layer penlu14
I1005 13:00:40.248311  9519 net.cpp:84] Creating Layer penlu14
I1005 13:00:40.248313  9519 net.cpp:406] penlu14 <- Convolution16
I1005 13:00:40.248317  9519 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1005 13:00:40.248441  9519 net.cpp:122] Setting up penlu14
I1005 13:00:40.248446  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.248448  9519 net.cpp:137] Memory required for data: 386254000
I1005 13:00:40.248452  9519 layer_factory.hpp:77] Creating layer Convolution17
I1005 13:00:40.248461  9519 net.cpp:84] Creating Layer Convolution17
I1005 13:00:40.248463  9519 net.cpp:406] Convolution17 <- Convolution16
I1005 13:00:40.248467  9519 net.cpp:380] Convolution17 -> Convolution17
I1005 13:00:40.250342  9519 net.cpp:122] Setting up Convolution17
I1005 13:00:40.250355  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.250360  9519 net.cpp:137] Memory required for data: 387892400
I1005 13:00:40.250367  9519 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 13:00:40.250376  9519 net.cpp:84] Creating Layer BatchNorm17
I1005 13:00:40.250381  9519 net.cpp:406] BatchNorm17 <- Convolution17
I1005 13:00:40.250387  9519 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 13:00:40.250572  9519 net.cpp:122] Setting up BatchNorm17
I1005 13:00:40.250579  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.250582  9519 net.cpp:137] Memory required for data: 389530800
I1005 13:00:40.250587  9519 layer_factory.hpp:77] Creating layer Scale17
I1005 13:00:40.250591  9519 net.cpp:84] Creating Layer Scale17
I1005 13:00:40.250594  9519 net.cpp:406] Scale17 <- Convolution17
I1005 13:00:40.250597  9519 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 13:00:40.250628  9519 layer_factory.hpp:77] Creating layer Scale17
I1005 13:00:40.250711  9519 net.cpp:122] Setting up Scale17
I1005 13:00:40.250715  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.250717  9519 net.cpp:137] Memory required for data: 391169200
I1005 13:00:40.250721  9519 layer_factory.hpp:77] Creating layer Eltwise7
I1005 13:00:40.250726  9519 net.cpp:84] Creating Layer Eltwise7
I1005 13:00:40.250728  9519 net.cpp:406] Eltwise7 <- Convolution15
I1005 13:00:40.250731  9519 net.cpp:406] Eltwise7 <- Convolution17
I1005 13:00:40.250735  9519 net.cpp:380] Eltwise7 -> Eltwise7
I1005 13:00:40.250752  9519 net.cpp:122] Setting up Eltwise7
I1005 13:00:40.250756  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.250758  9519 net.cpp:137] Memory required for data: 392807600
I1005 13:00:40.250761  9519 layer_factory.hpp:77] Creating layer penlu15
I1005 13:00:40.250766  9519 net.cpp:84] Creating Layer penlu15
I1005 13:00:40.250768  9519 net.cpp:406] penlu15 <- Eltwise7
I1005 13:00:40.250771  9519 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1005 13:00:40.250886  9519 net.cpp:122] Setting up penlu15
I1005 13:00:40.250890  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.250892  9519 net.cpp:137] Memory required for data: 394446000
I1005 13:00:40.250897  9519 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1005 13:00:40.250901  9519 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1005 13:00:40.250903  9519 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1005 13:00:40.250906  9519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1005 13:00:40.250910  9519 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1005 13:00:40.250938  9519 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1005 13:00:40.250942  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.250946  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.250947  9519 net.cpp:137] Memory required for data: 397722800
I1005 13:00:40.250949  9519 layer_factory.hpp:77] Creating layer Convolution18
I1005 13:00:40.250955  9519 net.cpp:84] Creating Layer Convolution18
I1005 13:00:40.250958  9519 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1005 13:00:40.250962  9519 net.cpp:380] Convolution18 -> Convolution18
I1005 13:00:40.252740  9519 net.cpp:122] Setting up Convolution18
I1005 13:00:40.252749  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.252753  9519 net.cpp:137] Memory required for data: 399361200
I1005 13:00:40.252756  9519 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 13:00:40.252763  9519 net.cpp:84] Creating Layer BatchNorm18
I1005 13:00:40.252765  9519 net.cpp:406] BatchNorm18 <- Convolution18
I1005 13:00:40.252768  9519 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 13:00:40.252913  9519 net.cpp:122] Setting up BatchNorm18
I1005 13:00:40.252918  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.252920  9519 net.cpp:137] Memory required for data: 400999600
I1005 13:00:40.252925  9519 layer_factory.hpp:77] Creating layer Scale18
I1005 13:00:40.252936  9519 net.cpp:84] Creating Layer Scale18
I1005 13:00:40.252939  9519 net.cpp:406] Scale18 <- Convolution18
I1005 13:00:40.252943  9519 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 13:00:40.252974  9519 layer_factory.hpp:77] Creating layer Scale18
I1005 13:00:40.253056  9519 net.cpp:122] Setting up Scale18
I1005 13:00:40.253059  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.253062  9519 net.cpp:137] Memory required for data: 402638000
I1005 13:00:40.253065  9519 layer_factory.hpp:77] Creating layer penlu16
I1005 13:00:40.253070  9519 net.cpp:84] Creating Layer penlu16
I1005 13:00:40.253073  9519 net.cpp:406] penlu16 <- Convolution18
I1005 13:00:40.253077  9519 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1005 13:00:40.253192  9519 net.cpp:122] Setting up penlu16
I1005 13:00:40.253196  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.253198  9519 net.cpp:137] Memory required for data: 404276400
I1005 13:00:40.253203  9519 layer_factory.hpp:77] Creating layer Convolution19
I1005 13:00:40.253209  9519 net.cpp:84] Creating Layer Convolution19
I1005 13:00:40.253211  9519 net.cpp:406] Convolution19 <- Convolution18
I1005 13:00:40.253216  9519 net.cpp:380] Convolution19 -> Convolution19
I1005 13:00:40.254956  9519 net.cpp:122] Setting up Convolution19
I1005 13:00:40.254964  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.254967  9519 net.cpp:137] Memory required for data: 405914800
I1005 13:00:40.254971  9519 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 13:00:40.254977  9519 net.cpp:84] Creating Layer BatchNorm19
I1005 13:00:40.254981  9519 net.cpp:406] BatchNorm19 <- Convolution19
I1005 13:00:40.254983  9519 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 13:00:40.255129  9519 net.cpp:122] Setting up BatchNorm19
I1005 13:00:40.255133  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.255136  9519 net.cpp:137] Memory required for data: 407553200
I1005 13:00:40.255141  9519 layer_factory.hpp:77] Creating layer Scale19
I1005 13:00:40.255144  9519 net.cpp:84] Creating Layer Scale19
I1005 13:00:40.255147  9519 net.cpp:406] Scale19 <- Convolution19
I1005 13:00:40.255151  9519 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 13:00:40.255179  9519 layer_factory.hpp:77] Creating layer Scale19
I1005 13:00:40.255261  9519 net.cpp:122] Setting up Scale19
I1005 13:00:40.255266  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.255269  9519 net.cpp:137] Memory required for data: 409191600
I1005 13:00:40.255272  9519 layer_factory.hpp:77] Creating layer Eltwise8
I1005 13:00:40.255276  9519 net.cpp:84] Creating Layer Eltwise8
I1005 13:00:40.255280  9519 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1005 13:00:40.255282  9519 net.cpp:406] Eltwise8 <- Convolution19
I1005 13:00:40.255285  9519 net.cpp:380] Eltwise8 -> Eltwise8
I1005 13:00:40.255303  9519 net.cpp:122] Setting up Eltwise8
I1005 13:00:40.255307  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.255309  9519 net.cpp:137] Memory required for data: 410830000
I1005 13:00:40.255311  9519 layer_factory.hpp:77] Creating layer penlu17
I1005 13:00:40.255317  9519 net.cpp:84] Creating Layer penlu17
I1005 13:00:40.255319  9519 net.cpp:406] penlu17 <- Eltwise8
I1005 13:00:40.255322  9519 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1005 13:00:40.255439  9519 net.cpp:122] Setting up penlu17
I1005 13:00:40.255442  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.255445  9519 net.cpp:137] Memory required for data: 412468400
I1005 13:00:40.255450  9519 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1005 13:00:40.255452  9519 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1005 13:00:40.255455  9519 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1005 13:00:40.255460  9519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1005 13:00:40.255463  9519 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1005 13:00:40.255486  9519 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1005 13:00:40.255497  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.255501  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.255502  9519 net.cpp:137] Memory required for data: 415745200
I1005 13:00:40.255504  9519 layer_factory.hpp:77] Creating layer Convolution20
I1005 13:00:40.255511  9519 net.cpp:84] Creating Layer Convolution20
I1005 13:00:40.255513  9519 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1005 13:00:40.255517  9519 net.cpp:380] Convolution20 -> Convolution20
I1005 13:00:40.257525  9519 net.cpp:122] Setting up Convolution20
I1005 13:00:40.257535  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.257539  9519 net.cpp:137] Memory required for data: 417383600
I1005 13:00:40.257542  9519 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 13:00:40.257547  9519 net.cpp:84] Creating Layer BatchNorm20
I1005 13:00:40.257550  9519 net.cpp:406] BatchNorm20 <- Convolution20
I1005 13:00:40.257555  9519 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 13:00:40.257704  9519 net.cpp:122] Setting up BatchNorm20
I1005 13:00:40.257709  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.257711  9519 net.cpp:137] Memory required for data: 419022000
I1005 13:00:40.257716  9519 layer_factory.hpp:77] Creating layer Scale20
I1005 13:00:40.257720  9519 net.cpp:84] Creating Layer Scale20
I1005 13:00:40.257722  9519 net.cpp:406] Scale20 <- Convolution20
I1005 13:00:40.257726  9519 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 13:00:40.257755  9519 layer_factory.hpp:77] Creating layer Scale20
I1005 13:00:40.257838  9519 net.cpp:122] Setting up Scale20
I1005 13:00:40.257843  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.257844  9519 net.cpp:137] Memory required for data: 420660400
I1005 13:00:40.257848  9519 layer_factory.hpp:77] Creating layer penlu18
I1005 13:00:40.257853  9519 net.cpp:84] Creating Layer penlu18
I1005 13:00:40.257855  9519 net.cpp:406] penlu18 <- Convolution20
I1005 13:00:40.257859  9519 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1005 13:00:40.257973  9519 net.cpp:122] Setting up penlu18
I1005 13:00:40.257977  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.257980  9519 net.cpp:137] Memory required for data: 422298800
I1005 13:00:40.257984  9519 layer_factory.hpp:77] Creating layer Convolution21
I1005 13:00:40.257990  9519 net.cpp:84] Creating Layer Convolution21
I1005 13:00:40.257993  9519 net.cpp:406] Convolution21 <- Convolution20
I1005 13:00:40.257997  9519 net.cpp:380] Convolution21 -> Convolution21
I1005 13:00:40.260036  9519 net.cpp:122] Setting up Convolution21
I1005 13:00:40.260046  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.260048  9519 net.cpp:137] Memory required for data: 423937200
I1005 13:00:40.260053  9519 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 13:00:40.260058  9519 net.cpp:84] Creating Layer BatchNorm21
I1005 13:00:40.260061  9519 net.cpp:406] BatchNorm21 <- Convolution21
I1005 13:00:40.260066  9519 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 13:00:40.260208  9519 net.cpp:122] Setting up BatchNorm21
I1005 13:00:40.260213  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.260215  9519 net.cpp:137] Memory required for data: 425575600
I1005 13:00:40.260221  9519 layer_factory.hpp:77] Creating layer Scale21
I1005 13:00:40.260224  9519 net.cpp:84] Creating Layer Scale21
I1005 13:00:40.260227  9519 net.cpp:406] Scale21 <- Convolution21
I1005 13:00:40.260231  9519 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 13:00:40.275503  9519 layer_factory.hpp:77] Creating layer Scale21
I1005 13:00:40.275604  9519 net.cpp:122] Setting up Scale21
I1005 13:00:40.275610  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.275612  9519 net.cpp:137] Memory required for data: 427214000
I1005 13:00:40.275617  9519 layer_factory.hpp:77] Creating layer Eltwise9
I1005 13:00:40.275621  9519 net.cpp:84] Creating Layer Eltwise9
I1005 13:00:40.275624  9519 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1005 13:00:40.275636  9519 net.cpp:406] Eltwise9 <- Convolution21
I1005 13:00:40.275641  9519 net.cpp:380] Eltwise9 -> Eltwise9
I1005 13:00:40.275662  9519 net.cpp:122] Setting up Eltwise9
I1005 13:00:40.275666  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.275668  9519 net.cpp:137] Memory required for data: 428852400
I1005 13:00:40.275671  9519 layer_factory.hpp:77] Creating layer penlu19
I1005 13:00:40.275676  9519 net.cpp:84] Creating Layer penlu19
I1005 13:00:40.275679  9519 net.cpp:406] penlu19 <- Eltwise9
I1005 13:00:40.275683  9519 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1005 13:00:40.275810  9519 net.cpp:122] Setting up penlu19
I1005 13:00:40.275815  9519 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 13:00:40.275816  9519 net.cpp:137] Memory required for data: 430490800
I1005 13:00:40.275821  9519 layer_factory.hpp:77] Creating layer Pooling1
I1005 13:00:40.275826  9519 net.cpp:84] Creating Layer Pooling1
I1005 13:00:40.275828  9519 net.cpp:406] Pooling1 <- Eltwise9
I1005 13:00:40.275833  9519 net.cpp:380] Pooling1 -> Pooling1
I1005 13:00:40.275982  9519 net.cpp:122] Setting up Pooling1
I1005 13:00:40.275990  9519 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 13:00:40.275992  9519 net.cpp:137] Memory required for data: 430516400
I1005 13:00:40.275995  9519 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 13:00:40.276001  9519 net.cpp:84] Creating Layer InnerProduct1
I1005 13:00:40.276005  9519 net.cpp:406] InnerProduct1 <- Pooling1
I1005 13:00:40.276008  9519 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 13:00:40.276118  9519 net.cpp:122] Setting up InnerProduct1
I1005 13:00:40.276123  9519 net.cpp:129] Top shape: 100 10 (1000)
I1005 13:00:40.276124  9519 net.cpp:137] Memory required for data: 430520400
I1005 13:00:40.276129  9519 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1005 13:00:40.276132  9519 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1005 13:00:40.276135  9519 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1005 13:00:40.276139  9519 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1005 13:00:40.276146  9519 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1005 13:00:40.276175  9519 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1005 13:00:40.276180  9519 net.cpp:129] Top shape: 100 10 (1000)
I1005 13:00:40.276182  9519 net.cpp:129] Top shape: 100 10 (1000)
I1005 13:00:40.276185  9519 net.cpp:137] Memory required for data: 430528400
I1005 13:00:40.276187  9519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 13:00:40.276191  9519 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 13:00:40.276195  9519 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1005 13:00:40.276197  9519 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1005 13:00:40.276201  9519 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 13:00:40.276206  9519 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 13:00:40.276406  9519 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 13:00:40.276412  9519 net.cpp:129] Top shape: (1)
I1005 13:00:40.276414  9519 net.cpp:132]     with loss weight 1
I1005 13:00:40.276422  9519 net.cpp:137] Memory required for data: 430528404
I1005 13:00:40.276424  9519 layer_factory.hpp:77] Creating layer Accuracy1
I1005 13:00:40.276434  9519 net.cpp:84] Creating Layer Accuracy1
I1005 13:00:40.276437  9519 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1005 13:00:40.276440  9519 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1005 13:00:40.276444  9519 net.cpp:380] Accuracy1 -> Accuracy1
I1005 13:00:40.276450  9519 net.cpp:122] Setting up Accuracy1
I1005 13:00:40.276454  9519 net.cpp:129] Top shape: (1)
I1005 13:00:40.276456  9519 net.cpp:137] Memory required for data: 430528408
I1005 13:00:40.276459  9519 net.cpp:200] Accuracy1 does not need backward computation.
I1005 13:00:40.276461  9519 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 13:00:40.276470  9519 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1005 13:00:40.276473  9519 net.cpp:198] InnerProduct1 needs backward computation.
I1005 13:00:40.276476  9519 net.cpp:198] Pooling1 needs backward computation.
I1005 13:00:40.276479  9519 net.cpp:198] penlu19 needs backward computation.
I1005 13:00:40.276480  9519 net.cpp:198] Eltwise9 needs backward computation.
I1005 13:00:40.276484  9519 net.cpp:198] Scale21 needs backward computation.
I1005 13:00:40.276485  9519 net.cpp:198] BatchNorm21 needs backward computation.
I1005 13:00:40.276487  9519 net.cpp:198] Convolution21 needs backward computation.
I1005 13:00:40.276490  9519 net.cpp:198] penlu18 needs backward computation.
I1005 13:00:40.276492  9519 net.cpp:198] Scale20 needs backward computation.
I1005 13:00:40.276494  9519 net.cpp:198] BatchNorm20 needs backward computation.
I1005 13:00:40.276496  9519 net.cpp:198] Convolution20 needs backward computation.
I1005 13:00:40.276499  9519 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1005 13:00:40.276501  9519 net.cpp:198] penlu17 needs backward computation.
I1005 13:00:40.276504  9519 net.cpp:198] Eltwise8 needs backward computation.
I1005 13:00:40.276506  9519 net.cpp:198] Scale19 needs backward computation.
I1005 13:00:40.276509  9519 net.cpp:198] BatchNorm19 needs backward computation.
I1005 13:00:40.276510  9519 net.cpp:198] Convolution19 needs backward computation.
I1005 13:00:40.276512  9519 net.cpp:198] penlu16 needs backward computation.
I1005 13:00:40.276515  9519 net.cpp:198] Scale18 needs backward computation.
I1005 13:00:40.276516  9519 net.cpp:198] BatchNorm18 needs backward computation.
I1005 13:00:40.276520  9519 net.cpp:198] Convolution18 needs backward computation.
I1005 13:00:40.276521  9519 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1005 13:00:40.276525  9519 net.cpp:198] penlu15 needs backward computation.
I1005 13:00:40.276526  9519 net.cpp:198] Eltwise7 needs backward computation.
I1005 13:00:40.276530  9519 net.cpp:198] Scale17 needs backward computation.
I1005 13:00:40.276531  9519 net.cpp:198] BatchNorm17 needs backward computation.
I1005 13:00:40.276541  9519 net.cpp:198] Convolution17 needs backward computation.
I1005 13:00:40.276543  9519 net.cpp:198] penlu14 needs backward computation.
I1005 13:00:40.276546  9519 net.cpp:198] Scale16 needs backward computation.
I1005 13:00:40.276548  9519 net.cpp:198] BatchNorm16 needs backward computation.
I1005 13:00:40.276551  9519 net.cpp:198] Convolution16 needs backward computation.
I1005 13:00:40.276552  9519 net.cpp:198] Scale15 needs backward computation.
I1005 13:00:40.276554  9519 net.cpp:198] BatchNorm15 needs backward computation.
I1005 13:00:40.276556  9519 net.cpp:198] Convolution15 needs backward computation.
I1005 13:00:40.276559  9519 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1005 13:00:40.276563  9519 net.cpp:198] penlu13 needs backward computation.
I1005 13:00:40.276566  9519 net.cpp:198] Eltwise6 needs backward computation.
I1005 13:00:40.276568  9519 net.cpp:198] Scale14 needs backward computation.
I1005 13:00:40.276571  9519 net.cpp:198] BatchNorm14 needs backward computation.
I1005 13:00:40.276572  9519 net.cpp:198] Convolution14 needs backward computation.
I1005 13:00:40.276574  9519 net.cpp:198] penlu12 needs backward computation.
I1005 13:00:40.276576  9519 net.cpp:198] Scale13 needs backward computation.
I1005 13:00:40.276578  9519 net.cpp:198] BatchNorm13 needs backward computation.
I1005 13:00:40.277456  9519 net.cpp:198] Convolution13 needs backward computation.
I1005 13:00:40.277467  9519 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1005 13:00:40.277472  9519 net.cpp:198] penlu11 needs backward computation.
I1005 13:00:40.277475  9519 net.cpp:198] Eltwise5 needs backward computation.
I1005 13:00:40.277479  9519 net.cpp:198] Scale12 needs backward computation.
I1005 13:00:40.277483  9519 net.cpp:198] BatchNorm12 needs backward computation.
I1005 13:00:40.277495  9519 net.cpp:198] Convolution12 needs backward computation.
I1005 13:00:40.277498  9519 net.cpp:198] penlu10 needs backward computation.
I1005 13:00:40.277500  9519 net.cpp:198] Scale11 needs backward computation.
I1005 13:00:40.277503  9519 net.cpp:198] BatchNorm11 needs backward computation.
I1005 13:00:40.277505  9519 net.cpp:198] Convolution11 needs backward computation.
I1005 13:00:40.277508  9519 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1005 13:00:40.277510  9519 net.cpp:198] penlu9 needs backward computation.
I1005 13:00:40.277513  9519 net.cpp:198] Eltwise4 needs backward computation.
I1005 13:00:40.277515  9519 net.cpp:198] Scale10 needs backward computation.
I1005 13:00:40.277518  9519 net.cpp:198] BatchNorm10 needs backward computation.
I1005 13:00:40.277520  9519 net.cpp:198] Convolution10 needs backward computation.
I1005 13:00:40.277523  9519 net.cpp:198] penlu8 needs backward computation.
I1005 13:00:40.277525  9519 net.cpp:198] Scale9 needs backward computation.
I1005 13:00:40.277528  9519 net.cpp:198] BatchNorm9 needs backward computation.
I1005 13:00:40.277529  9519 net.cpp:198] Convolution9 needs backward computation.
I1005 13:00:40.277532  9519 net.cpp:198] Scale8 needs backward computation.
I1005 13:00:40.277534  9519 net.cpp:198] BatchNorm8 needs backward computation.
I1005 13:00:40.277536  9519 net.cpp:198] Convolution8 needs backward computation.
I1005 13:00:40.277539  9519 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1005 13:00:40.277542  9519 net.cpp:198] penlu7 needs backward computation.
I1005 13:00:40.277544  9519 net.cpp:198] Eltwise3 needs backward computation.
I1005 13:00:40.277547  9519 net.cpp:198] Scale7 needs backward computation.
I1005 13:00:40.277549  9519 net.cpp:198] BatchNorm7 needs backward computation.
I1005 13:00:40.277551  9519 net.cpp:198] Convolution7 needs backward computation.
I1005 13:00:40.277554  9519 net.cpp:198] penlu6 needs backward computation.
I1005 13:00:40.277556  9519 net.cpp:198] Scale6 needs backward computation.
I1005 13:00:40.277559  9519 net.cpp:198] BatchNorm6 needs backward computation.
I1005 13:00:40.277560  9519 net.cpp:198] Convolution6 needs backward computation.
I1005 13:00:40.277564  9519 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1005 13:00:40.277566  9519 net.cpp:198] penlu5 needs backward computation.
I1005 13:00:40.277568  9519 net.cpp:198] Eltwise2 needs backward computation.
I1005 13:00:40.277571  9519 net.cpp:198] Scale5 needs backward computation.
I1005 13:00:40.277575  9519 net.cpp:198] BatchNorm5 needs backward computation.
I1005 13:00:40.277576  9519 net.cpp:198] Convolution5 needs backward computation.
I1005 13:00:40.277578  9519 net.cpp:198] penlu4 needs backward computation.
I1005 13:00:40.277581  9519 net.cpp:198] Scale4 needs backward computation.
I1005 13:00:40.277583  9519 net.cpp:198] BatchNorm4 needs backward computation.
I1005 13:00:40.277585  9519 net.cpp:198] Convolution4 needs backward computation.
I1005 13:00:40.277588  9519 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1005 13:00:40.277590  9519 net.cpp:198] penlu3 needs backward computation.
I1005 13:00:40.277592  9519 net.cpp:198] Eltwise1 needs backward computation.
I1005 13:00:40.277595  9519 net.cpp:198] Scale3 needs backward computation.
I1005 13:00:40.277598  9519 net.cpp:198] BatchNorm3 needs backward computation.
I1005 13:00:40.277601  9519 net.cpp:198] Convolution3 needs backward computation.
I1005 13:00:40.277602  9519 net.cpp:198] penlu2 needs backward computation.
I1005 13:00:40.277606  9519 net.cpp:198] Scale2 needs backward computation.
I1005 13:00:40.277607  9519 net.cpp:198] BatchNorm2 needs backward computation.
I1005 13:00:40.277611  9519 net.cpp:198] Convolution2 needs backward computation.
I1005 13:00:40.277612  9519 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1005 13:00:40.277616  9519 net.cpp:198] penlu1 needs backward computation.
I1005 13:00:40.277618  9519 net.cpp:198] Scale1 needs backward computation.
I1005 13:00:40.277623  9519 net.cpp:198] BatchNorm1 needs backward computation.
I1005 13:00:40.277626  9519 net.cpp:198] Convolution1 needs backward computation.
I1005 13:00:40.277628  9519 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1005 13:00:40.277631  9519 net.cpp:200] Data1 does not need backward computation.
I1005 13:00:40.277633  9519 net.cpp:242] This network produces output Accuracy1
I1005 13:00:40.277637  9519 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 13:00:40.277673  9519 net.cpp:255] Network initialization done.
I1005 13:00:40.277930  9519 solver.cpp:56] Solver scaffolding done.
I1005 13:00:40.283223  9519 caffe.cpp:248] Starting Optimization
I1005 13:00:40.283231  9519 solver.cpp:272] Solving resnet_cifar10
I1005 13:00:40.283232  9519 solver.cpp:273] Learning Rate Policy: multistep
I1005 13:00:40.285164  9519 solver.cpp:330] Iteration 0, Testing net (#0)
I1005 13:00:41.505690  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:00:41.554734  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1005 13:00:41.554760  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1005 13:00:41.628067  9519 solver.cpp:218] Iteration 0 (0 iter/s, 1.34477s/100 iters), loss = 2.30376
I1005 13:00:41.628098  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30376 (* 1 = 2.30376 loss)
I1005 13:00:41.628113  9519 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1005 13:00:46.863417  9519 solver.cpp:218] Iteration 100 (19.1011 iter/s, 5.2353s/100 iters), loss = 1.55042
I1005 13:00:46.863458  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55042 (* 1 = 1.55042 loss)
I1005 13:00:46.863464  9519 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1005 13:00:52.104385  9519 solver.cpp:218] Iteration 200 (19.0807 iter/s, 5.24091s/100 iters), loss = 1.73064
I1005 13:00:52.104414  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.73064 (* 1 = 1.73064 loss)
I1005 13:00:52.104420  9519 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1005 13:00:57.349414  9519 solver.cpp:218] Iteration 300 (19.0659 iter/s, 5.24498s/100 iters), loss = 1.38662
I1005 13:00:57.349455  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.38662 (* 1 = 1.38662 loss)
I1005 13:00:57.349462  9519 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1005 13:01:02.590219  9519 solver.cpp:218] Iteration 400 (19.0813 iter/s, 5.24074s/100 iters), loss = 1.1186
I1005 13:01:02.590252  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.1186 (* 1 = 1.1186 loss)
I1005 13:01:02.590258  9519 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1005 13:01:07.564308  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:01:07.774219  9519 solver.cpp:330] Iteration 500, Testing net (#0)
I1005 13:01:08.967870  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:01:09.017190  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4132
I1005 13:01:09.017225  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.98691 (* 1 = 1.98691 loss)
I1005 13:01:09.069130  9519 solver.cpp:218] Iteration 500 (15.4348 iter/s, 6.47886s/100 iters), loss = 1.13751
I1005 13:01:09.069155  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13751 (* 1 = 1.13751 loss)
I1005 13:01:09.069162  9519 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1005 13:01:14.313541  9519 solver.cpp:218] Iteration 600 (19.0681 iter/s, 5.24436s/100 iters), loss = 1.09469
I1005 13:01:14.313624  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09469 (* 1 = 1.09469 loss)
I1005 13:01:14.313642  9519 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1005 13:01:19.557585  9519 solver.cpp:218] Iteration 700 (19.0697 iter/s, 5.24391s/100 iters), loss = 1.09738
I1005 13:01:19.557626  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09738 (* 1 = 1.09738 loss)
I1005 13:01:19.557632  9519 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1005 13:01:24.803709  9519 solver.cpp:218] Iteration 800 (19.0619 iter/s, 5.24606s/100 iters), loss = 1.00874
I1005 13:01:24.803741  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00874 (* 1 = 1.00874 loss)
I1005 13:01:24.803761  9519 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1005 13:01:30.048888  9519 solver.cpp:218] Iteration 900 (19.0653 iter/s, 5.24513s/100 iters), loss = 0.887305
I1005 13:01:30.048921  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.887305 (* 1 = 0.887305 loss)
I1005 13:01:30.048930  9519 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1005 13:01:35.026823  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:01:35.237174  9519 solver.cpp:330] Iteration 1000, Testing net (#0)
I1005 13:01:36.427443  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:01:36.476824  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5251
I1005 13:01:36.476852  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.35112 (* 1 = 1.35112 loss)
I1005 13:01:36.529129  9519 solver.cpp:218] Iteration 1000 (15.4317 iter/s, 6.48019s/100 iters), loss = 0.939741
I1005 13:01:36.529165  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.939741 (* 1 = 0.939741 loss)
I1005 13:01:36.529175  9519 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1005 13:01:41.782270  9519 solver.cpp:218] Iteration 1100 (19.0364 iter/s, 5.25308s/100 iters), loss = 0.87266
I1005 13:01:41.782301  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.87266 (* 1 = 0.87266 loss)
I1005 13:01:41.782311  9519 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1005 13:01:47.023164  9519 solver.cpp:218] Iteration 1200 (19.0809 iter/s, 5.24084s/100 iters), loss = 0.927401
I1005 13:01:47.023250  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.927401 (* 1 = 0.927401 loss)
I1005 13:01:47.023268  9519 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1005 13:01:52.277832  9519 solver.cpp:218] Iteration 1300 (19.0311 iter/s, 5.25456s/100 iters), loss = 0.855676
I1005 13:01:52.277879  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.855676 (* 1 = 0.855676 loss)
I1005 13:01:52.277886  9519 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1005 13:01:57.533229  9519 solver.cpp:218] Iteration 1400 (19.0283 iter/s, 5.25533s/100 iters), loss = 0.727469
I1005 13:01:57.533269  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.727469 (* 1 = 0.727469 loss)
I1005 13:01:57.533275  9519 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1005 13:02:02.523738  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:02:02.733232  9519 solver.cpp:330] Iteration 1500, Testing net (#0)
I1005 13:02:03.918368  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:02:03.967990  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.548
I1005 13:02:03.968024  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21239 (* 1 = 1.21239 loss)
I1005 13:02:04.020345  9519 solver.cpp:218] Iteration 1500 (15.4153 iter/s, 6.48706s/100 iters), loss = 0.864591
I1005 13:02:04.020372  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.864591 (* 1 = 0.864591 loss)
I1005 13:02:04.020380  9519 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1005 13:02:09.270469  9519 solver.cpp:218] Iteration 1600 (19.0473 iter/s, 5.25007s/100 iters), loss = 0.732376
I1005 13:02:09.270511  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.732376 (* 1 = 0.732376 loss)
I1005 13:02:09.270517  9519 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1005 13:02:14.519038  9519 solver.cpp:218] Iteration 1700 (19.0531 iter/s, 5.2485s/100 iters), loss = 0.779482
I1005 13:02:14.519083  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.779482 (* 1 = 0.779482 loss)
I1005 13:02:14.519090  9519 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1005 13:02:19.760437  9519 solver.cpp:218] Iteration 1800 (19.0791 iter/s, 5.24133s/100 iters), loss = 0.744901
I1005 13:02:19.760612  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.744901 (* 1 = 0.744901 loss)
I1005 13:02:19.760630  9519 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1005 13:02:25.008915  9519 solver.cpp:218] Iteration 1900 (19.0539 iter/s, 5.24828s/100 iters), loss = 0.768443
I1005 13:02:25.008944  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.768443 (* 1 = 0.768443 loss)
I1005 13:02:25.008950  9519 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1005 13:02:29.998306  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:02:30.207787  9519 solver.cpp:330] Iteration 2000, Testing net (#0)
I1005 13:02:31.391443  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:02:31.440925  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5075
I1005 13:02:31.440960  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36039 (* 1 = 1.36039 loss)
I1005 13:02:31.493365  9519 solver.cpp:218] Iteration 2000 (15.4216 iter/s, 6.4844s/100 iters), loss = 0.708386
I1005 13:02:31.493389  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.708386 (* 1 = 0.708386 loss)
I1005 13:02:31.493396  9519 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1005 13:02:36.749502  9519 solver.cpp:218] Iteration 2100 (19.0256 iter/s, 5.25609s/100 iters), loss = 0.714702
I1005 13:02:36.749531  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.714702 (* 1 = 0.714702 loss)
I1005 13:02:36.749537  9519 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1005 13:02:42.002658  9519 solver.cpp:218] Iteration 2200 (19.0364 iter/s, 5.2531s/100 iters), loss = 0.592253
I1005 13:02:42.002701  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.592253 (* 1 = 0.592253 loss)
I1005 13:02:42.002707  9519 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1005 13:02:47.246542  9519 solver.cpp:218] Iteration 2300 (19.0701 iter/s, 5.24382s/100 iters), loss = 0.610186
I1005 13:02:47.246582  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.610186 (* 1 = 0.610186 loss)
I1005 13:02:47.246588  9519 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1005 13:02:52.492252  9519 solver.cpp:218] Iteration 2400 (19.0634 iter/s, 5.24565s/100 iters), loss = 0.617854
I1005 13:02:52.492353  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.617854 (* 1 = 0.617854 loss)
I1005 13:02:52.492379  9519 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1005 13:02:57.482167  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:02:57.692224  9519 solver.cpp:330] Iteration 2500, Testing net (#0)
I1005 13:02:58.876152  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:02:58.925565  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4586
I1005 13:02:58.925593  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.49492 (* 1 = 1.49492 loss)
I1005 13:02:58.977767  9519 solver.cpp:218] Iteration 2500 (15.4193 iter/s, 6.48539s/100 iters), loss = 0.723291
I1005 13:02:58.977800  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.723291 (* 1 = 0.723291 loss)
I1005 13:02:58.977809  9519 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1005 13:03:04.224664  9519 solver.cpp:218] Iteration 2600 (19.0591 iter/s, 5.24684s/100 iters), loss = 0.507857
I1005 13:03:04.224705  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.507857 (* 1 = 0.507857 loss)
I1005 13:03:04.224711  9519 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1005 13:03:09.467607  9519 solver.cpp:218] Iteration 2700 (19.0735 iter/s, 5.24288s/100 iters), loss = 0.630951
I1005 13:03:09.467636  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.630951 (* 1 = 0.630951 loss)
I1005 13:03:09.467643  9519 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1005 13:03:14.716240  9519 solver.cpp:218] Iteration 2800 (19.0528 iter/s, 5.24858s/100 iters), loss = 0.603679
I1005 13:03:14.716274  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603679 (* 1 = 0.603679 loss)
I1005 13:03:14.716294  9519 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1005 13:03:19.960081  9519 solver.cpp:218] Iteration 2900 (19.0702 iter/s, 5.24379s/100 iters), loss = 0.50497
I1005 13:03:19.960113  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50497 (* 1 = 0.50497 loss)
I1005 13:03:19.960119  9519 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1005 13:03:24.951592  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:03:25.160679  9519 solver.cpp:330] Iteration 3000, Testing net (#0)
I1005 13:03:26.349876  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:03:26.400588  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5837
I1005 13:03:26.400612  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.20866 (* 1 = 1.20866 loss)
I1005 13:03:26.454385  9519 solver.cpp:218] Iteration 3000 (15.3983 iter/s, 6.49424s/100 iters), loss = 0.562538
I1005 13:03:26.454422  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.562538 (* 1 = 0.562538 loss)
I1005 13:03:26.454430  9519 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1005 13:03:31.698321  9519 solver.cpp:218] Iteration 3100 (19.0699 iter/s, 5.24388s/100 iters), loss = 0.475175
I1005 13:03:31.698361  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.475175 (* 1 = 0.475175 loss)
I1005 13:03:31.698367  9519 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1005 13:03:36.945679  9519 solver.cpp:218] Iteration 3200 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.664444
I1005 13:03:36.945709  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.664444 (* 1 = 0.664444 loss)
I1005 13:03:36.945716  9519 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1005 13:03:42.195276  9519 solver.cpp:218] Iteration 3300 (19.0493 iter/s, 5.24954s/100 iters), loss = 0.524977
I1005 13:03:42.195307  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524977 (* 1 = 0.524977 loss)
I1005 13:03:42.195314  9519 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1005 13:03:47.444619  9519 solver.cpp:218] Iteration 3400 (19.0502 iter/s, 5.24929s/100 iters), loss = 0.463034
I1005 13:03:47.444654  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463034 (* 1 = 0.463034 loss)
I1005 13:03:47.444661  9519 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1005 13:03:52.420436  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:03:52.629776  9519 solver.cpp:330] Iteration 3500, Testing net (#0)
I1005 13:03:53.822712  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:03:53.872210  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5893
I1005 13:03:53.872244  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15477 (* 1 = 1.15477 loss)
I1005 13:03:53.924283  9519 solver.cpp:218] Iteration 3500 (15.433 iter/s, 6.4796s/100 iters), loss = 0.56535
I1005 13:03:53.924321  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.56535 (* 1 = 0.56535 loss)
I1005 13:03:53.924329  9519 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1005 13:03:59.163805  9519 solver.cpp:218] Iteration 3600 (19.0859 iter/s, 5.23946s/100 iters), loss = 0.386252
I1005 13:03:59.163928  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386252 (* 1 = 0.386252 loss)
I1005 13:03:59.163935  9519 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1005 13:04:04.413879  9519 solver.cpp:218] Iteration 3700 (19.0479 iter/s, 5.24993s/100 iters), loss = 0.509645
I1005 13:04:04.413910  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509645 (* 1 = 0.509645 loss)
I1005 13:04:04.413926  9519 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1005 13:04:09.667170  9519 solver.cpp:218] Iteration 3800 (19.0359 iter/s, 5.25324s/100 iters), loss = 0.544042
I1005 13:04:09.667201  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.544042 (* 1 = 0.544042 loss)
I1005 13:04:09.667217  9519 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1005 13:04:14.924235  9519 solver.cpp:218] Iteration 3900 (19.0222 iter/s, 5.25701s/100 iters), loss = 0.4617
I1005 13:04:14.924268  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4617 (* 1 = 0.4617 loss)
I1005 13:04:14.924273  9519 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1005 13:04:19.906956  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:04:20.115824  9519 solver.cpp:330] Iteration 4000, Testing net (#0)
I1005 13:04:21.311678  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:04:21.361209  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6533
I1005 13:04:21.361244  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01474 (* 1 = 1.01474 loss)
I1005 13:04:21.413211  9519 solver.cpp:218] Iteration 4000 (15.4109 iter/s, 6.48892s/100 iters), loss = 0.419282
I1005 13:04:21.413241  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419282 (* 1 = 0.419282 loss)
I1005 13:04:21.413249  9519 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1005 13:04:26.661566  9519 solver.cpp:218] Iteration 4100 (19.0538 iter/s, 5.2483s/100 iters), loss = 0.361933
I1005 13:04:26.661607  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361933 (* 1 = 0.361933 loss)
I1005 13:04:26.661614  9519 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1005 13:04:31.900492  9519 solver.cpp:218] Iteration 4200 (19.0881 iter/s, 5.23886s/100 iters), loss = 0.469364
I1005 13:04:31.900635  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469364 (* 1 = 0.469364 loss)
I1005 13:04:31.900645  9519 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1005 13:04:37.147395  9519 solver.cpp:218] Iteration 4300 (19.0595 iter/s, 5.24674s/100 iters), loss = 0.563336
I1005 13:04:37.147439  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.563336 (* 1 = 0.563336 loss)
I1005 13:04:37.147444  9519 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1005 13:04:42.399715  9519 solver.cpp:218] Iteration 4400 (19.0394 iter/s, 5.25225s/100 iters), loss = 0.373452
I1005 13:04:42.399756  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373452 (* 1 = 0.373452 loss)
I1005 13:04:42.399762  9519 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1005 13:04:47.388324  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:04:47.601653  9519 solver.cpp:330] Iteration 4500, Testing net (#0)
I1005 13:04:48.785565  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:04:48.835250  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6476
I1005 13:04:48.835276  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05307 (* 1 = 1.05307 loss)
I1005 13:04:48.887655  9519 solver.cpp:218] Iteration 4500 (15.4134 iter/s, 6.48788s/100 iters), loss = 0.485527
I1005 13:04:48.887688  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.485527 (* 1 = 0.485527 loss)
I1005 13:04:48.887696  9519 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1005 13:04:54.139679  9519 solver.cpp:218] Iteration 4600 (19.0405 iter/s, 5.25197s/100 iters), loss = 0.493518
I1005 13:04:54.139709  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.493518 (* 1 = 0.493518 loss)
I1005 13:04:54.139715  9519 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1005 13:04:59.389683  9519 solver.cpp:218] Iteration 4700 (19.0478 iter/s, 5.24995s/100 iters), loss = 0.41337
I1005 13:04:59.389725  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41337 (* 1 = 0.41337 loss)
I1005 13:04:59.389735  9519 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1005 13:05:04.639050  9519 solver.cpp:218] Iteration 4800 (19.0503 iter/s, 5.24926s/100 iters), loss = 0.509365
I1005 13:05:04.639159  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509365 (* 1 = 0.509365 loss)
I1005 13:05:04.639166  9519 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1005 13:05:09.890779  9519 solver.cpp:218] Iteration 4900 (19.0418 iter/s, 5.2516s/100 iters), loss = 0.447779
I1005 13:05:09.890827  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447779 (* 1 = 0.447779 loss)
I1005 13:05:09.890836  9519 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1005 13:05:14.876436  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:05:15.085229  9519 solver.cpp:330] Iteration 5000, Testing net (#0)
I1005 13:05:16.271431  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:05:16.320726  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7224
I1005 13:05:16.320761  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.812256 (* 1 = 0.812256 loss)
I1005 13:05:16.372826  9519 solver.cpp:218] Iteration 5000 (15.4274 iter/s, 6.48198s/100 iters), loss = 0.451891
I1005 13:05:16.372864  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451891 (* 1 = 0.451891 loss)
I1005 13:05:16.372872  9519 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1005 13:05:21.620342  9519 solver.cpp:218] Iteration 5100 (19.0568 iter/s, 5.24746s/100 iters), loss = 0.356637
I1005 13:05:21.620383  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356637 (* 1 = 0.356637 loss)
I1005 13:05:21.620388  9519 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1005 13:05:26.861663  9519 solver.cpp:218] Iteration 5200 (19.0794 iter/s, 5.24126s/100 iters), loss = 0.438283
I1005 13:05:26.861704  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438283 (* 1 = 0.438283 loss)
I1005 13:05:26.861711  9519 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1005 13:05:32.101053  9519 solver.cpp:218] Iteration 5300 (19.0864 iter/s, 5.23933s/100 iters), loss = 0.366321
I1005 13:05:32.101088  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366321 (* 1 = 0.366321 loss)
I1005 13:05:32.101094  9519 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1005 13:05:37.350445  9519 solver.cpp:218] Iteration 5400 (19.05 iter/s, 5.24934s/100 iters), loss = 0.391147
I1005 13:05:37.350601  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391147 (* 1 = 0.391147 loss)
I1005 13:05:37.350622  9519 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1005 13:05:42.345577  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:05:42.555583  9519 solver.cpp:330] Iteration 5500, Testing net (#0)
I1005 13:05:43.739707  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:05:43.789250  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6756
I1005 13:05:43.789288  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.990871 (* 1 = 0.990871 loss)
I1005 13:05:43.841893  9519 solver.cpp:218] Iteration 5500 (15.4053 iter/s, 6.49127s/100 iters), loss = 0.386068
I1005 13:05:43.841925  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386068 (* 1 = 0.386068 loss)
I1005 13:05:43.841933  9519 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1005 13:05:49.093616  9519 solver.cpp:218] Iteration 5600 (19.0416 iter/s, 5.25167s/100 iters), loss = 0.450162
I1005 13:05:49.093662  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450162 (* 1 = 0.450162 loss)
I1005 13:05:49.093669  9519 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1005 13:05:54.344149  9519 solver.cpp:218] Iteration 5700 (19.0459 iter/s, 5.25046s/100 iters), loss = 0.382424
I1005 13:05:54.344190  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382424 (* 1 = 0.382424 loss)
I1005 13:05:54.344197  9519 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1005 13:05:59.595886  9519 solver.cpp:218] Iteration 5800 (19.0415 iter/s, 5.25167s/100 iters), loss = 0.34082
I1005 13:05:59.595928  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34082 (* 1 = 0.34082 loss)
I1005 13:05:59.595935  9519 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1005 13:06:04.838584  9519 solver.cpp:218] Iteration 5900 (19.0744 iter/s, 5.24264s/100 iters), loss = 0.330717
I1005 13:06:04.838621  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330717 (* 1 = 0.330717 loss)
I1005 13:06:04.838639  9519 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1005 13:06:09.827888  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:06:10.037021  9519 solver.cpp:330] Iteration 6000, Testing net (#0)
I1005 13:06:11.223716  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:06:11.273597  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6764
I1005 13:06:11.273624  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.903439 (* 1 = 0.903439 loss)
I1005 13:06:11.327040  9519 solver.cpp:218] Iteration 6000 (15.4121 iter/s, 6.4884s/100 iters), loss = 0.352627
I1005 13:06:11.327077  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352627 (* 1 = 0.352627 loss)
I1005 13:06:11.327085  9519 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1005 13:06:16.574781  9519 solver.cpp:218] Iteration 6100 (19.056 iter/s, 5.24768s/100 iters), loss = 0.383185
I1005 13:06:16.574823  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383185 (* 1 = 0.383185 loss)
I1005 13:06:16.574831  9519 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1005 13:06:21.824379  9519 solver.cpp:218] Iteration 6200 (19.0493 iter/s, 5.24954s/100 iters), loss = 0.454352
I1005 13:06:21.824420  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454352 (* 1 = 0.454352 loss)
I1005 13:06:21.824426  9519 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1005 13:06:27.081203  9519 solver.cpp:218] Iteration 6300 (19.0231 iter/s, 5.25676s/100 iters), loss = 0.454634
I1005 13:06:27.081244  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454634 (* 1 = 0.454634 loss)
I1005 13:06:27.081250  9519 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1005 13:06:32.330025  9519 solver.cpp:218] Iteration 6400 (19.0521 iter/s, 5.24876s/100 iters), loss = 0.443779
I1005 13:06:32.330063  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443779 (* 1 = 0.443779 loss)
I1005 13:06:32.330071  9519 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1005 13:06:37.319142  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:06:37.528926  9519 solver.cpp:330] Iteration 6500, Testing net (#0)
I1005 13:06:38.723909  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:06:38.773689  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7106
I1005 13:06:38.773725  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.884761 (* 1 = 0.884761 loss)
I1005 13:06:38.825877  9519 solver.cpp:218] Iteration 6500 (15.3946 iter/s, 6.49579s/100 iters), loss = 0.454669
I1005 13:06:38.825908  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454669 (* 1 = 0.454669 loss)
I1005 13:06:38.825915  9519 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1005 13:06:44.082988  9519 solver.cpp:218] Iteration 6600 (19.0221 iter/s, 5.25706s/100 iters), loss = 0.346342
I1005 13:06:44.083068  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346342 (* 1 = 0.346342 loss)
I1005 13:06:44.083086  9519 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1005 13:06:49.344115  9519 solver.cpp:218] Iteration 6700 (19.0077 iter/s, 5.26103s/100 iters), loss = 0.46014
I1005 13:06:49.344156  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46014 (* 1 = 0.46014 loss)
I1005 13:06:49.344162  9519 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1005 13:06:54.601491  9519 solver.cpp:218] Iteration 6800 (19.0211 iter/s, 5.25732s/100 iters), loss = 0.415722
I1005 13:06:54.601522  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415722 (* 1 = 0.415722 loss)
I1005 13:06:54.601529  9519 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1005 13:06:59.854326  9519 solver.cpp:218] Iteration 6900 (19.0375 iter/s, 5.25278s/100 iters), loss = 0.397242
I1005 13:06:59.854356  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397242 (* 1 = 0.397242 loss)
I1005 13:06:59.854362  9519 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1005 13:07:04.840922  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:07:05.050720  9519 solver.cpp:330] Iteration 7000, Testing net (#0)
I1005 13:07:06.243890  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:07:06.293706  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6444
I1005 13:07:06.293742  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1999 (* 1 = 1.1999 loss)
I1005 13:07:06.346253  9519 solver.cpp:218] Iteration 7000 (15.4039 iter/s, 6.49188s/100 iters), loss = 0.258643
I1005 13:07:06.346279  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258643 (* 1 = 0.258643 loss)
I1005 13:07:06.346285  9519 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1005 13:07:11.605283  9519 solver.cpp:218] Iteration 7100 (19.0151 iter/s, 5.25898s/100 iters), loss = 0.321805
I1005 13:07:11.605314  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321805 (* 1 = 0.321805 loss)
I1005 13:07:11.605321  9519 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1005 13:07:16.857282  9519 solver.cpp:218] Iteration 7200 (19.0406 iter/s, 5.25194s/100 iters), loss = 0.402036
I1005 13:07:16.857417  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402036 (* 1 = 0.402036 loss)
I1005 13:07:16.857457  9519 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1005 13:07:22.119619  9519 solver.cpp:218] Iteration 7300 (19.0035 iter/s, 5.26218s/100 iters), loss = 0.41755
I1005 13:07:22.119660  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41755 (* 1 = 0.41755 loss)
I1005 13:07:22.119668  9519 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1005 13:07:27.382468  9519 solver.cpp:218] Iteration 7400 (19.0013 iter/s, 5.26279s/100 iters), loss = 0.400508
I1005 13:07:27.382509  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400508 (* 1 = 0.400508 loss)
I1005 13:07:27.382515  9519 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1005 13:07:32.378286  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:07:32.591835  9519 solver.cpp:330] Iteration 7500, Testing net (#0)
I1005 13:07:33.779706  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:07:33.829555  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.67
I1005 13:07:33.829581  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00389 (* 1 = 1.00389 loss)
I1005 13:07:33.882095  9519 solver.cpp:218] Iteration 7500 (15.3856 iter/s, 6.49957s/100 iters), loss = 0.304651
I1005 13:07:33.882122  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304651 (* 1 = 0.304651 loss)
I1005 13:07:33.882128  9519 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1005 13:07:39.142282  9519 solver.cpp:218] Iteration 7600 (19.0109 iter/s, 5.26014s/100 iters), loss = 0.272884
I1005 13:07:39.142313  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272884 (* 1 = 0.272884 loss)
I1005 13:07:39.142319  9519 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1005 13:07:44.390576  9519 solver.cpp:218] Iteration 7700 (19.054 iter/s, 5.24823s/100 iters), loss = 0.329434
I1005 13:07:44.390611  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329434 (* 1 = 0.329434 loss)
I1005 13:07:44.390619  9519 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1005 13:07:49.643884  9519 solver.cpp:218] Iteration 7800 (19.0358 iter/s, 5.25325s/100 iters), loss = 0.356104
I1005 13:07:49.643996  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356104 (* 1 = 0.356104 loss)
I1005 13:07:49.644016  9519 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1005 13:07:54.905504  9519 solver.cpp:218] Iteration 7900 (19.006 iter/s, 5.26149s/100 iters), loss = 0.387454
I1005 13:07:54.905547  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387454 (* 1 = 0.387454 loss)
I1005 13:07:54.905553  9519 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1005 13:07:59.906376  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:08:00.115658  9519 solver.cpp:330] Iteration 8000, Testing net (#0)
I1005 13:08:01.305163  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:08:01.354842  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7642
I1005 13:08:01.354877  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.688676 (* 1 = 0.688676 loss)
I1005 13:08:01.407441  9519 solver.cpp:218] Iteration 8000 (15.3802 iter/s, 6.50187s/100 iters), loss = 0.325371
I1005 13:08:01.407469  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325371 (* 1 = 0.325371 loss)
I1005 13:08:01.407474  9519 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1005 13:08:06.665102  9519 solver.cpp:218] Iteration 8100 (19.0201 iter/s, 5.25761s/100 iters), loss = 0.387868
I1005 13:08:06.665143  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387868 (* 1 = 0.387868 loss)
I1005 13:08:06.665149  9519 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1005 13:08:11.922099  9519 solver.cpp:218] Iteration 8200 (19.0225 iter/s, 5.25694s/100 iters), loss = 0.32397
I1005 13:08:11.922142  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32397 (* 1 = 0.32397 loss)
I1005 13:08:11.922149  9519 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1005 13:08:17.166740  9519 solver.cpp:218] Iteration 8300 (19.0673 iter/s, 5.24458s/100 iters), loss = 0.403112
I1005 13:08:17.166770  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403112 (* 1 = 0.403112 loss)
I1005 13:08:17.166776  9519 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1005 13:08:22.421113  9519 solver.cpp:218] Iteration 8400 (19.032 iter/s, 5.25432s/100 iters), loss = 0.326284
I1005 13:08:22.421260  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326284 (* 1 = 0.326284 loss)
I1005 13:08:22.421268  9519 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1005 13:08:27.417273  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:08:27.626502  9519 solver.cpp:330] Iteration 8500, Testing net (#0)
I1005 13:08:28.813957  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:08:28.863590  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5621
I1005 13:08:28.863626  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.66205 (* 1 = 1.66205 loss)
I1005 13:08:28.916406  9519 solver.cpp:218] Iteration 8500 (15.3962 iter/s, 6.49512s/100 iters), loss = 0.320398
I1005 13:08:28.916443  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320398 (* 1 = 0.320398 loss)
I1005 13:08:28.916450  9519 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1005 13:08:34.168462  9519 solver.cpp:218] Iteration 8600 (19.0404 iter/s, 5.252s/100 iters), loss = 0.335562
I1005 13:08:34.168491  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335562 (* 1 = 0.335562 loss)
I1005 13:08:34.168498  9519 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1005 13:08:39.424370  9519 solver.cpp:218] Iteration 8700 (19.0264 iter/s, 5.25586s/100 iters), loss = 0.396162
I1005 13:08:39.424401  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396162 (* 1 = 0.396162 loss)
I1005 13:08:39.424407  9519 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1005 13:08:44.680518  9519 solver.cpp:218] Iteration 8800 (19.0255 iter/s, 5.2561s/100 iters), loss = 0.266192
I1005 13:08:44.680552  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266192 (* 1 = 0.266192 loss)
I1005 13:08:44.680559  9519 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1005 13:08:49.928040  9519 solver.cpp:218] Iteration 8900 (19.0568 iter/s, 5.24747s/100 iters), loss = 0.310829
I1005 13:08:49.928072  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310829 (* 1 = 0.310829 loss)
I1005 13:08:49.928079  9519 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1005 13:08:54.924252  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:08:55.133646  9519 solver.cpp:330] Iteration 9000, Testing net (#0)
I1005 13:08:56.324339  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:08:56.375200  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6282
I1005 13:08:56.375229  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.30559 (* 1 = 1.30559 loss)
I1005 13:08:56.429450  9519 solver.cpp:218] Iteration 9000 (15.3814 iter/s, 6.50135s/100 iters), loss = 0.257635
I1005 13:08:56.429486  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257635 (* 1 = 0.257635 loss)
I1005 13:08:56.429494  9519 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1005 13:09:01.684716  9519 solver.cpp:218] Iteration 9100 (19.0287 iter/s, 5.25521s/100 iters), loss = 0.280874
I1005 13:09:01.684746  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280874 (* 1 = 0.280874 loss)
I1005 13:09:01.684752  9519 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1005 13:09:06.948457  9519 solver.cpp:218] Iteration 9200 (18.9981 iter/s, 5.26369s/100 iters), loss = 0.290371
I1005 13:09:06.948488  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290371 (* 1 = 0.290371 loss)
I1005 13:09:06.948494  9519 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1005 13:09:12.205456  9519 solver.cpp:218] Iteration 9300 (19.0225 iter/s, 5.25694s/100 iters), loss = 0.350292
I1005 13:09:12.205487  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350292 (* 1 = 0.350292 loss)
I1005 13:09:12.205493  9519 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1005 13:09:17.456478  9519 solver.cpp:218] Iteration 9400 (19.0441 iter/s, 5.25097s/100 iters), loss = 0.325959
I1005 13:09:17.456524  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325959 (* 1 = 0.325959 loss)
I1005 13:09:17.456532  9519 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1005 13:09:22.439160  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:09:22.648375  9519 solver.cpp:330] Iteration 9500, Testing net (#0)
I1005 13:09:23.842604  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:09:23.892529  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7272
I1005 13:09:23.892555  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.828922 (* 1 = 0.828922 loss)
I1005 13:09:23.945202  9519 solver.cpp:218] Iteration 9500 (15.4116 iter/s, 6.48862s/100 iters), loss = 0.310024
I1005 13:09:23.945237  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310024 (* 1 = 0.310024 loss)
I1005 13:09:23.945245  9519 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1005 13:09:29.194859  9519 solver.cpp:218] Iteration 9600 (19.0491 iter/s, 5.2496s/100 iters), loss = 0.259867
I1005 13:09:29.194972  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259867 (* 1 = 0.259867 loss)
I1005 13:09:29.194989  9519 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1005 13:09:34.451377  9519 solver.cpp:218] Iteration 9700 (19.0245 iter/s, 5.25639s/100 iters), loss = 0.342216
I1005 13:09:34.451411  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342216 (* 1 = 0.342216 loss)
I1005 13:09:34.451426  9519 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1005 13:09:39.710044  9519 solver.cpp:218] Iteration 9800 (19.0164 iter/s, 5.25862s/100 iters), loss = 0.35171
I1005 13:09:39.710075  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35171 (* 1 = 0.35171 loss)
I1005 13:09:39.710081  9519 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1005 13:09:44.974009  9519 solver.cpp:218] Iteration 9900 (18.9973 iter/s, 5.26391s/100 iters), loss = 0.315688
I1005 13:09:44.974050  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315688 (* 1 = 0.315688 loss)
I1005 13:09:44.974056  9519 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1005 13:09:49.960439  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:09:50.169421  9519 solver.cpp:330] Iteration 10000, Testing net (#0)
I1005 13:09:51.365797  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:09:51.415251  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7867
I1005 13:09:51.415284  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684574 (* 1 = 0.684574 loss)
I1005 13:09:51.467742  9519 solver.cpp:218] Iteration 10000 (15.3996 iter/s, 6.49367s/100 iters), loss = 0.272931
I1005 13:09:51.467769  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272931 (* 1 = 0.272931 loss)
I1005 13:09:51.467777  9519 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1005 13:09:56.732285  9519 solver.cpp:218] Iteration 10100 (18.9952 iter/s, 5.26449s/100 iters), loss = 0.356222
I1005 13:09:56.732316  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356222 (* 1 = 0.356222 loss)
I1005 13:09:56.732323  9519 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1005 13:10:01.979032  9519 solver.cpp:218] Iteration 10200 (19.0596 iter/s, 5.24669s/100 iters), loss = 0.29631
I1005 13:10:01.979182  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29631 (* 1 = 0.29631 loss)
I1005 13:10:01.979190  9519 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1005 13:10:07.231575  9519 solver.cpp:218] Iteration 10300 (19.039 iter/s, 5.25238s/100 iters), loss = 0.345668
I1005 13:10:07.231604  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345668 (* 1 = 0.345668 loss)
I1005 13:10:07.231611  9519 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1005 13:10:12.490465  9519 solver.cpp:218] Iteration 10400 (19.0156 iter/s, 5.25884s/100 iters), loss = 0.318017
I1005 13:10:12.490496  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318017 (* 1 = 0.318017 loss)
I1005 13:10:12.490512  9519 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1005 13:10:17.482563  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:10:17.693322  9519 solver.cpp:330] Iteration 10500, Testing net (#0)
I1005 13:10:18.881381  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:10:18.930891  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7817
I1005 13:10:18.930928  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648515 (* 1 = 0.648515 loss)
I1005 13:10:18.983085  9519 solver.cpp:218] Iteration 10500 (15.4022 iter/s, 6.49257s/100 iters), loss = 0.307778
I1005 13:10:18.983132  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307778 (* 1 = 0.307778 loss)
I1005 13:10:18.983139  9519 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1005 13:10:24.241786  9519 solver.cpp:218] Iteration 10600 (19.0163 iter/s, 5.25864s/100 iters), loss = 0.380531
I1005 13:10:24.241816  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380531 (* 1 = 0.380531 loss)
I1005 13:10:24.241822  9519 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1005 13:10:29.497786  9519 solver.cpp:218] Iteration 10700 (19.0261 iter/s, 5.25595s/100 iters), loss = 0.259405
I1005 13:10:29.497822  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259405 (* 1 = 0.259405 loss)
I1005 13:10:29.497828  9519 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1005 13:10:34.749678  9519 solver.cpp:218] Iteration 10800 (19.041 iter/s, 5.25184s/100 iters), loss = 0.264924
I1005 13:10:34.749799  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264924 (* 1 = 0.264924 loss)
I1005 13:10:34.749816  9519 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1005 13:10:40.014478  9519 solver.cpp:218] Iteration 10900 (18.9945 iter/s, 5.26467s/100 iters), loss = 0.269941
I1005 13:10:40.014509  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269941 (* 1 = 0.269941 loss)
I1005 13:10:40.014528  9519 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1005 13:10:45.011809  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:10:45.221535  9519 solver.cpp:330] Iteration 11000, Testing net (#0)
I1005 13:10:46.409919  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:10:46.459789  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7443
I1005 13:10:46.459815  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.830943 (* 1 = 0.830943 loss)
I1005 13:10:46.512306  9519 solver.cpp:218] Iteration 11000 (15.3899 iter/s, 6.49778s/100 iters), loss = 0.306533
I1005 13:10:46.512343  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306533 (* 1 = 0.306533 loss)
I1005 13:10:46.512351  9519 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1005 13:10:51.776952  9519 solver.cpp:218] Iteration 11100 (18.9948 iter/s, 5.26459s/100 iters), loss = 0.301874
I1005 13:10:51.776995  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301875 (* 1 = 0.301875 loss)
I1005 13:10:51.777001  9519 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1005 13:10:57.105499  9519 solver.cpp:218] Iteration 11200 (18.7671 iter/s, 5.32848s/100 iters), loss = 0.418354
I1005 13:10:57.105551  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418354 (* 1 = 0.418354 loss)
I1005 13:10:57.105569  9519 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1005 13:11:02.474745  9519 solver.cpp:218] Iteration 11300 (18.6254 iter/s, 5.369s/100 iters), loss = 0.430861
I1005 13:11:02.474784  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430861 (* 1 = 0.430861 loss)
I1005 13:11:02.474805  9519 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1005 13:11:07.834791  9519 solver.cpp:218] Iteration 11400 (18.6569 iter/s, 5.35994s/100 iters), loss = 0.277116
I1005 13:11:07.834940  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277116 (* 1 = 0.277116 loss)
I1005 13:11:07.834980  9519 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1005 13:11:12.888303  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:11:13.097653  9519 solver.cpp:330] Iteration 11500, Testing net (#0)
I1005 13:11:14.289407  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:11:14.338507  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7451
I1005 13:11:14.338549  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.80367 (* 1 = 0.80367 loss)
I1005 13:11:14.391687  9519 solver.cpp:218] Iteration 11500 (15.2516 iter/s, 6.55669s/100 iters), loss = 0.304325
I1005 13:11:14.391731  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304325 (* 1 = 0.304325 loss)
I1005 13:11:14.391741  9519 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1005 13:11:19.814721  9519 solver.cpp:218] Iteration 11600 (18.4408 iter/s, 5.42277s/100 iters), loss = 0.381817
I1005 13:11:19.814755  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381817 (* 1 = 0.381817 loss)
I1005 13:11:19.814764  9519 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1005 13:11:25.151257  9519 solver.cpp:218] Iteration 11700 (18.7389 iter/s, 5.33648s/100 iters), loss = 0.342315
I1005 13:11:25.151288  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342315 (* 1 = 0.342315 loss)
I1005 13:11:25.151293  9519 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1005 13:11:30.409461  9519 solver.cpp:218] Iteration 11800 (19.0181 iter/s, 5.25815s/100 iters), loss = 0.311011
I1005 13:11:30.409492  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311011 (* 1 = 0.311011 loss)
I1005 13:11:30.409497  9519 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1005 13:11:35.663419  9519 solver.cpp:218] Iteration 11900 (19.0335 iter/s, 5.25391s/100 iters), loss = 0.395731
I1005 13:11:35.663450  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395731 (* 1 = 0.395731 loss)
I1005 13:11:35.663466  9519 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1005 13:11:40.654734  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:11:40.864270  9519 solver.cpp:330] Iteration 12000, Testing net (#0)
I1005 13:11:42.058594  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:11:42.108357  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7775
I1005 13:11:42.108386  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.673679 (* 1 = 0.673679 loss)
I1005 13:11:42.161000  9519 solver.cpp:218] Iteration 12000 (15.3905 iter/s, 6.49753s/100 iters), loss = 0.239271
I1005 13:11:42.161036  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239271 (* 1 = 0.239271 loss)
I1005 13:11:42.161046  9519 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1005 13:11:47.418165  9519 solver.cpp:218] Iteration 12100 (19.0219 iter/s, 5.25711s/100 iters), loss = 0.294844
I1005 13:11:47.418205  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294844 (* 1 = 0.294844 loss)
I1005 13:11:47.418225  9519 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1005 13:11:52.670971  9519 solver.cpp:218] Iteration 12200 (19.0378 iter/s, 5.25271s/100 iters), loss = 0.28291
I1005 13:11:52.671005  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28291 (* 1 = 0.28291 loss)
I1005 13:11:52.671013  9519 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1005 13:11:57.929666  9519 solver.cpp:218] Iteration 12300 (19.0163 iter/s, 5.25864s/100 iters), loss = 0.27136
I1005 13:11:57.929699  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27136 (* 1 = 0.27136 loss)
I1005 13:11:57.929707  9519 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1005 13:12:03.189613  9519 solver.cpp:218] Iteration 12400 (19.0118 iter/s, 5.2599s/100 iters), loss = 0.362477
I1005 13:12:03.189647  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362477 (* 1 = 0.362477 loss)
I1005 13:12:03.189656  9519 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1005 13:12:08.182629  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:12:08.397817  9519 solver.cpp:330] Iteration 12500, Testing net (#0)
I1005 13:12:09.589695  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:12:09.639390  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8047
I1005 13:12:09.639425  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.589141 (* 1 = 0.589141 loss)
I1005 13:12:09.691433  9519 solver.cpp:218] Iteration 12500 (15.3804 iter/s, 6.50177s/100 iters), loss = 0.356968
I1005 13:12:09.691468  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356968 (* 1 = 0.356968 loss)
I1005 13:12:09.691476  9519 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1005 13:12:14.950310  9519 solver.cpp:218] Iteration 12600 (19.0156 iter/s, 5.25883s/100 iters), loss = 0.253753
I1005 13:12:14.950448  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253753 (* 1 = 0.253753 loss)
I1005 13:12:14.950456  9519 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1005 13:12:20.202147  9519 solver.cpp:218] Iteration 12700 (19.0415 iter/s, 5.25169s/100 iters), loss = 0.258549
I1005 13:12:20.202180  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258548 (* 1 = 0.258548 loss)
I1005 13:12:20.202198  9519 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1005 13:12:25.463569  9519 solver.cpp:218] Iteration 12800 (19.0065 iter/s, 5.26137s/100 iters), loss = 0.210743
I1005 13:12:25.463610  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210743 (* 1 = 0.210743 loss)
I1005 13:12:25.463615  9519 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1005 13:12:30.716714  9519 solver.cpp:218] Iteration 12900 (19.0364 iter/s, 5.25309s/100 iters), loss = 0.319801
I1005 13:12:30.716744  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319801 (* 1 = 0.319801 loss)
I1005 13:12:30.716761  9519 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1005 13:12:35.719907  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:12:35.929899  9519 solver.cpp:330] Iteration 13000, Testing net (#0)
I1005 13:12:37.118479  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:12:37.168539  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6449
I1005 13:12:37.168563  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2122 (* 1 = 1.2122 loss)
I1005 13:12:37.220998  9519 solver.cpp:218] Iteration 13000 (15.3746 iter/s, 6.50424s/100 iters), loss = 0.327687
I1005 13:12:37.221026  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327687 (* 1 = 0.327687 loss)
I1005 13:12:37.221037  9519 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1005 13:12:42.481034  9519 solver.cpp:218] Iteration 13100 (19.0115 iter/s, 5.25999s/100 iters), loss = 0.285906
I1005 13:12:42.481067  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285906 (* 1 = 0.285906 loss)
I1005 13:12:42.481086  9519 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1005 13:12:47.744096  9519 solver.cpp:218] Iteration 13200 (19.0005 iter/s, 5.26301s/100 iters), loss = 0.284548
I1005 13:12:47.744240  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284548 (* 1 = 0.284548 loss)
I1005 13:12:47.744257  9519 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1005 13:12:53.001176  9519 solver.cpp:218] Iteration 13300 (19.0225 iter/s, 5.25693s/100 iters), loss = 0.344978
I1005 13:12:53.001217  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344978 (* 1 = 0.344978 loss)
I1005 13:12:53.001224  9519 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1005 13:12:58.260871  9519 solver.cpp:218] Iteration 13400 (19.0127 iter/s, 5.25963s/100 iters), loss = 0.232665
I1005 13:12:58.260911  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232665 (* 1 = 0.232665 loss)
I1005 13:12:58.260917  9519 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1005 13:13:03.264142  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:13:03.474735  9519 solver.cpp:330] Iteration 13500, Testing net (#0)
I1005 13:13:04.663791  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:13:04.713270  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7033
I1005 13:13:04.713295  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09931 (* 1 = 1.09931 loss)
I1005 13:13:04.765432  9519 solver.cpp:218] Iteration 13500 (15.374 iter/s, 6.5045s/100 iters), loss = 0.28891
I1005 13:13:04.765465  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28891 (* 1 = 0.28891 loss)
I1005 13:13:04.765472  9519 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1005 13:13:10.031165  9519 solver.cpp:218] Iteration 13600 (18.9909 iter/s, 5.26568s/100 iters), loss = 0.24021
I1005 13:13:10.031206  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24021 (* 1 = 0.24021 loss)
I1005 13:13:10.031213  9519 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1005 13:13:15.291468  9519 solver.cpp:218] Iteration 13700 (19.0105 iter/s, 5.26024s/100 iters), loss = 0.322401
I1005 13:13:15.291509  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322401 (* 1 = 0.322401 loss)
I1005 13:13:15.291515  9519 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1005 13:13:20.547724  9519 solver.cpp:218] Iteration 13800 (19.0252 iter/s, 5.25619s/100 iters), loss = 0.337153
I1005 13:13:20.547878  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337153 (* 1 = 0.337153 loss)
I1005 13:13:20.547888  9519 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1005 13:13:25.794656  9519 solver.cpp:218] Iteration 13900 (19.0594 iter/s, 5.24676s/100 iters), loss = 0.279683
I1005 13:13:25.794699  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279683 (* 1 = 0.279683 loss)
I1005 13:13:25.794705  9519 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1005 13:13:30.789645  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:13:31.000304  9519 solver.cpp:330] Iteration 14000, Testing net (#0)
I1005 13:13:32.187238  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:13:32.236928  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7393
I1005 13:13:32.236964  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.837116 (* 1 = 0.837116 loss)
I1005 13:13:32.290429  9519 solver.cpp:218] Iteration 14000 (15.3948 iter/s, 6.49571s/100 iters), loss = 0.250825
I1005 13:13:32.290475  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250825 (* 1 = 0.250825 loss)
I1005 13:13:32.290483  9519 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1005 13:13:37.547579  9519 solver.cpp:218] Iteration 14100 (19.0221 iter/s, 5.25705s/100 iters), loss = 0.321983
I1005 13:13:37.547610  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321983 (* 1 = 0.321983 loss)
I1005 13:13:37.547616  9519 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1005 13:13:42.807904  9519 solver.cpp:218] Iteration 14200 (19.0104 iter/s, 5.26028s/100 iters), loss = 0.415206
I1005 13:13:42.807945  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415206 (* 1 = 0.415206 loss)
I1005 13:13:42.807951  9519 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1005 13:13:48.066649  9519 solver.cpp:218] Iteration 14300 (19.0162 iter/s, 5.25869s/100 iters), loss = 0.316591
I1005 13:13:48.066680  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316591 (* 1 = 0.316591 loss)
I1005 13:13:48.066687  9519 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1005 13:13:53.313138  9519 solver.cpp:218] Iteration 14400 (19.0605 iter/s, 5.24644s/100 iters), loss = 0.316748
I1005 13:13:53.313308  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316748 (* 1 = 0.316748 loss)
I1005 13:13:53.313318  9519 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1005 13:13:58.305671  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:13:58.515031  9519 solver.cpp:330] Iteration 14500, Testing net (#0)
I1005 13:13:59.708173  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:13:59.757975  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8234
I1005 13:13:59.758011  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.516078 (* 1 = 0.516078 loss)
I1005 13:13:59.810521  9519 solver.cpp:218] Iteration 14500 (15.3913 iter/s, 6.4972s/100 iters), loss = 0.353972
I1005 13:13:59.810554  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353972 (* 1 = 0.353972 loss)
I1005 13:13:59.810561  9519 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1005 13:14:05.056933  9519 solver.cpp:218] Iteration 14600 (19.0608 iter/s, 5.24636s/100 iters), loss = 0.365407
I1005 13:14:05.056977  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365407 (* 1 = 0.365407 loss)
I1005 13:14:05.056983  9519 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1005 13:14:10.310578  9519 solver.cpp:218] Iteration 14700 (19.0346 iter/s, 5.25358s/100 iters), loss = 0.326549
I1005 13:14:10.310619  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326549 (* 1 = 0.326549 loss)
I1005 13:14:10.310626  9519 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1005 13:14:15.565774  9519 solver.cpp:218] Iteration 14800 (19.029 iter/s, 5.25513s/100 iters), loss = 0.263191
I1005 13:14:15.565804  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263191 (* 1 = 0.263191 loss)
I1005 13:14:15.565810  9519 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1005 13:14:20.815341  9519 solver.cpp:218] Iteration 14900 (19.0494 iter/s, 5.24952s/100 iters), loss = 0.256307
I1005 13:14:20.815383  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256307 (* 1 = 0.256307 loss)
I1005 13:14:20.815389  9519 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1005 13:14:25.799180  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:14:26.008095  9519 solver.cpp:330] Iteration 15000, Testing net (#0)
I1005 13:14:27.206116  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:14:27.255672  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7029
I1005 13:14:27.255697  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04119 (* 1 = 1.04119 loss)
I1005 13:14:27.307945  9519 solver.cpp:218] Iteration 15000 (15.4023 iter/s, 6.49255s/100 iters), loss = 0.228197
I1005 13:14:27.307970  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228197 (* 1 = 0.228197 loss)
I1005 13:14:27.307976  9519 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1005 13:14:32.561270  9519 solver.cpp:218] Iteration 15100 (19.0357 iter/s, 5.25328s/100 iters), loss = 0.28603
I1005 13:14:32.561306  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28603 (* 1 = 0.28603 loss)
I1005 13:14:32.561313  9519 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1005 13:14:37.811995  9519 solver.cpp:218] Iteration 15200 (19.0452 iter/s, 5.25067s/100 iters), loss = 0.316478
I1005 13:14:37.812036  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316478 (* 1 = 0.316478 loss)
I1005 13:14:37.812041  9519 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1005 13:14:43.075625  9519 solver.cpp:218] Iteration 15300 (18.9985 iter/s, 5.26357s/100 iters), loss = 0.268079
I1005 13:14:43.075664  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268079 (* 1 = 0.268079 loss)
I1005 13:14:43.075670  9519 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1005 13:14:48.330744  9519 solver.cpp:218] Iteration 15400 (19.0293 iter/s, 5.25506s/100 iters), loss = 0.236663
I1005 13:14:48.330775  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236663 (* 1 = 0.236663 loss)
I1005 13:14:48.330780  9519 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1005 13:14:53.320158  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:14:53.534406  9519 solver.cpp:330] Iteration 15500, Testing net (#0)
I1005 13:14:54.723417  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:14:54.773044  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7438
I1005 13:14:54.773080  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.78918 (* 1 = 0.78918 loss)
I1005 13:14:54.825685  9519 solver.cpp:218] Iteration 15500 (15.3967 iter/s, 6.49489s/100 iters), loss = 0.360985
I1005 13:14:54.825726  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360985 (* 1 = 0.360985 loss)
I1005 13:14:54.825740  9519 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1005 13:15:00.085486  9519 solver.cpp:218] Iteration 15600 (19.0123 iter/s, 5.25974s/100 iters), loss = 0.259796
I1005 13:15:00.085657  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259796 (* 1 = 0.259796 loss)
I1005 13:15:00.085664  9519 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1005 13:15:05.336697  9519 solver.cpp:218] Iteration 15700 (19.0439 iter/s, 5.25102s/100 iters), loss = 0.273328
I1005 13:15:05.336740  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273328 (* 1 = 0.273328 loss)
I1005 13:15:05.336748  9519 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1005 13:15:10.593574  9519 solver.cpp:218] Iteration 15800 (19.0229 iter/s, 5.25682s/100 iters), loss = 0.331769
I1005 13:15:10.593605  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331768 (* 1 = 0.331768 loss)
I1005 13:15:10.593621  9519 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1005 13:15:15.851300  9519 solver.cpp:218] Iteration 15900 (19.0198 iter/s, 5.25768s/100 iters), loss = 0.371485
I1005 13:15:15.851341  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371485 (* 1 = 0.371485 loss)
I1005 13:15:15.851346  9519 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1005 13:15:20.850988  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:15:21.060426  9519 solver.cpp:330] Iteration 16000, Testing net (#0)
I1005 13:15:22.247748  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:15:22.297454  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7633
I1005 13:15:22.297480  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.723352 (* 1 = 0.723352 loss)
I1005 13:15:22.349870  9519 solver.cpp:218] Iteration 16000 (15.3881 iter/s, 6.49851s/100 iters), loss = 0.282121
I1005 13:15:22.349896  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282121 (* 1 = 0.282121 loss)
I1005 13:15:22.349913  9519 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1005 13:15:27.613030  9519 solver.cpp:218] Iteration 16100 (19.0002 iter/s, 5.26311s/100 iters), loss = 0.224868
I1005 13:15:27.613061  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224868 (* 1 = 0.224868 loss)
I1005 13:15:27.613067  9519 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1005 13:15:32.875208  9519 solver.cpp:218] Iteration 16200 (19.0037 iter/s, 5.26213s/100 iters), loss = 0.274336
I1005 13:15:32.875309  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274336 (* 1 = 0.274336 loss)
I1005 13:15:32.875326  9519 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1005 13:15:38.126673  9519 solver.cpp:218] Iteration 16300 (19.0427 iter/s, 5.25135s/100 iters), loss = 0.308562
I1005 13:15:38.126704  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308562 (* 1 = 0.308562 loss)
I1005 13:15:38.126710  9519 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1005 13:15:43.375483  9519 solver.cpp:218] Iteration 16400 (19.0521 iter/s, 5.24876s/100 iters), loss = 0.233326
I1005 13:15:43.375512  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233326 (* 1 = 0.233326 loss)
I1005 13:15:43.375519  9519 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1005 13:15:48.372076  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:15:48.582291  9519 solver.cpp:330] Iteration 16500, Testing net (#0)
I1005 13:15:49.769878  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:15:49.819835  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7169
I1005 13:15:49.819859  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.924143 (* 1 = 0.924143 loss)
I1005 13:15:49.871996  9519 solver.cpp:218] Iteration 16500 (15.393 iter/s, 6.49647s/100 iters), loss = 0.263966
I1005 13:15:49.872030  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263966 (* 1 = 0.263966 loss)
I1005 13:15:49.872036  9519 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1005 13:15:55.129870  9519 solver.cpp:218] Iteration 16600 (19.0193 iter/s, 5.25782s/100 iters), loss = 0.220807
I1005 13:15:55.129900  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220807 (* 1 = 0.220807 loss)
I1005 13:15:55.129907  9519 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1005 13:16:00.387365  9519 solver.cpp:218] Iteration 16700 (19.0206 iter/s, 5.25745s/100 iters), loss = 0.32091
I1005 13:16:00.387405  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32091 (* 1 = 0.32091 loss)
I1005 13:16:00.387411  9519 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1005 13:16:05.648999  9519 solver.cpp:218] Iteration 16800 (19.0057 iter/s, 5.26158s/100 iters), loss = 0.186667
I1005 13:16:05.649173  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186667 (* 1 = 0.186667 loss)
I1005 13:16:05.649183  9519 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1005 13:16:10.896589  9519 solver.cpp:218] Iteration 16900 (19.0571 iter/s, 5.2474s/100 iters), loss = 0.298446
I1005 13:16:10.896622  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298446 (* 1 = 0.298446 loss)
I1005 13:16:10.896631  9519 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1005 13:16:15.902230  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:16:16.112872  9519 solver.cpp:330] Iteration 17000, Testing net (#0)
I1005 13:16:17.300683  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:16:17.351994  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7351
I1005 13:16:17.352021  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.826296 (* 1 = 0.826296 loss)
I1005 13:16:17.405694  9519 solver.cpp:218] Iteration 17000 (15.3632 iter/s, 6.50905s/100 iters), loss = 0.220563
I1005 13:16:17.405740  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220563 (* 1 = 0.220563 loss)
I1005 13:16:17.405761  9519 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1005 13:16:22.660753  9519 solver.cpp:218] Iteration 17100 (19.0296 iter/s, 5.25496s/100 iters), loss = 0.213786
I1005 13:16:22.660784  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213786 (* 1 = 0.213786 loss)
I1005 13:16:22.660802  9519 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1005 13:16:27.919286  9519 solver.cpp:218] Iteration 17200 (19.0169 iter/s, 5.25848s/100 iters), loss = 0.34714
I1005 13:16:27.919318  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34714 (* 1 = 0.34714 loss)
I1005 13:16:27.919337  9519 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1005 13:16:33.173406  9519 solver.cpp:218] Iteration 17300 (19.0329 iter/s, 5.25406s/100 iters), loss = 0.324882
I1005 13:16:33.173440  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324882 (* 1 = 0.324882 loss)
I1005 13:16:33.173449  9519 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1005 13:16:38.423629  9519 solver.cpp:218] Iteration 17400 (19.047 iter/s, 5.25017s/100 iters), loss = 0.231329
I1005 13:16:38.423822  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231329 (* 1 = 0.231329 loss)
I1005 13:16:38.423835  9519 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1005 13:16:43.416173  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:16:43.626052  9519 solver.cpp:330] Iteration 17500, Testing net (#0)
I1005 13:16:44.822403  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:16:44.871973  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7796
I1005 13:16:44.872000  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.676155 (* 1 = 0.676155 loss)
I1005 13:16:44.924286  9519 solver.cpp:218] Iteration 17500 (15.3835 iter/s, 6.50049s/100 iters), loss = 0.215586
I1005 13:16:44.924320  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215586 (* 1 = 0.215586 loss)
I1005 13:16:44.924329  9519 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1005 13:16:50.175242  9519 solver.cpp:218] Iteration 17600 (19.0443 iter/s, 5.2509s/100 iters), loss = 0.2226
I1005 13:16:50.175276  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222601 (* 1 = 0.222601 loss)
I1005 13:16:50.175283  9519 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1005 13:16:55.435484  9519 solver.cpp:218] Iteration 17700 (19.0107 iter/s, 5.26019s/100 iters), loss = 0.281
I1005 13:16:55.435518  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281 (* 1 = 0.281 loss)
I1005 13:16:55.435525  9519 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1005 13:17:00.700986  9519 solver.cpp:218] Iteration 17800 (18.9917 iter/s, 5.26545s/100 iters), loss = 0.309584
I1005 13:17:00.701025  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309584 (* 1 = 0.309584 loss)
I1005 13:17:00.701031  9519 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1005 13:17:05.960398  9519 solver.cpp:218] Iteration 17900 (19.0137 iter/s, 5.25936s/100 iters), loss = 0.331332
I1005 13:17:05.960431  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331332 (* 1 = 0.331332 loss)
I1005 13:17:05.960439  9519 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1005 13:17:10.950906  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:17:11.160862  9519 solver.cpp:330] Iteration 18000, Testing net (#0)
I1005 13:17:12.356489  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:17:12.406005  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7492
I1005 13:17:12.406031  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.801623 (* 1 = 0.801623 loss)
I1005 13:17:12.458588  9519 solver.cpp:218] Iteration 18000 (15.389 iter/s, 6.49814s/100 iters), loss = 0.20483
I1005 13:17:12.458621  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20483 (* 1 = 0.20483 loss)
I1005 13:17:12.458631  9519 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1005 13:17:17.716632  9519 solver.cpp:218] Iteration 18100 (19.0187 iter/s, 5.25799s/100 iters), loss = 0.294492
I1005 13:17:17.716665  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294492 (* 1 = 0.294492 loss)
I1005 13:17:17.716673  9519 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1005 13:17:22.965418  9519 solver.cpp:218] Iteration 18200 (19.0522 iter/s, 5.24873s/100 iters), loss = 0.253914
I1005 13:17:22.965454  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253914 (* 1 = 0.253914 loss)
I1005 13:17:22.965463  9519 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1005 13:17:28.224714  9519 solver.cpp:218] Iteration 18300 (19.0141 iter/s, 5.25924s/100 iters), loss = 0.316895
I1005 13:17:28.224747  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316895 (* 1 = 0.316895 loss)
I1005 13:17:28.224766  9519 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1005 13:17:33.481369  9519 solver.cpp:218] Iteration 18400 (19.0237 iter/s, 5.2566s/100 iters), loss = 0.204464
I1005 13:17:33.481400  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204464 (* 1 = 0.204464 loss)
I1005 13:17:33.481418  9519 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1005 13:17:38.479462  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:17:38.691867  9519 solver.cpp:330] Iteration 18500, Testing net (#0)
I1005 13:17:39.880306  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:17:39.929914  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.752
I1005 13:17:39.929940  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.83089 (* 1 = 0.83089 loss)
I1005 13:17:39.982199  9519 solver.cpp:218] Iteration 18500 (15.3828 iter/s, 6.50078s/100 iters), loss = 0.244874
I1005 13:17:39.982229  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244874 (* 1 = 0.244874 loss)
I1005 13:17:39.982239  9519 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1005 13:17:45.241065  9519 solver.cpp:218] Iteration 18600 (19.0157 iter/s, 5.25882s/100 iters), loss = 0.279187
I1005 13:17:45.241216  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279187 (* 1 = 0.279187 loss)
I1005 13:17:45.241226  9519 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1005 13:17:50.493594  9519 solver.cpp:218] Iteration 18700 (19.0391 iter/s, 5.25236s/100 iters), loss = 0.239476
I1005 13:17:50.493633  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239476 (* 1 = 0.239476 loss)
I1005 13:17:50.493643  9519 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1005 13:17:55.747239  9519 solver.cpp:218] Iteration 18800 (19.0346 iter/s, 5.25359s/100 iters), loss = 0.230184
I1005 13:17:55.747272  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230184 (* 1 = 0.230184 loss)
I1005 13:17:55.747280  9519 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1005 13:18:01.001983  9519 solver.cpp:218] Iteration 18900 (19.0306 iter/s, 5.2547s/100 iters), loss = 0.325163
I1005 13:18:01.002018  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325163 (* 1 = 0.325163 loss)
I1005 13:18:01.002027  9519 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1005 13:18:05.997938  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:18:06.208412  9519 solver.cpp:330] Iteration 19000, Testing net (#0)
I1005 13:18:07.395207  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:18:07.445080  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6566
I1005 13:18:07.445106  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.22676 (* 1 = 1.22676 loss)
I1005 13:18:07.497593  9519 solver.cpp:218] Iteration 19000 (15.3951 iter/s, 6.49556s/100 iters), loss = 0.271776
I1005 13:18:07.497625  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271777 (* 1 = 0.271777 loss)
I1005 13:18:07.497634  9519 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1005 13:18:12.752588  9519 solver.cpp:218] Iteration 19100 (19.0297 iter/s, 5.25495s/100 iters), loss = 0.252379
I1005 13:18:12.752622  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252379 (* 1 = 0.252379 loss)
I1005 13:18:12.752630  9519 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1005 13:18:18.008875  9519 solver.cpp:218] Iteration 19200 (19.025 iter/s, 5.25623s/100 iters), loss = 0.27134
I1005 13:18:18.008994  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27134 (* 1 = 0.27134 loss)
I1005 13:18:18.009013  9519 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1005 13:18:23.261376  9519 solver.cpp:218] Iteration 19300 (19.039 iter/s, 5.25237s/100 iters), loss = 0.265643
I1005 13:18:23.261411  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265643 (* 1 = 0.265643 loss)
I1005 13:18:23.261420  9519 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1005 13:18:28.515596  9519 solver.cpp:218] Iteration 19400 (19.0325 iter/s, 5.25417s/100 iters), loss = 0.304663
I1005 13:18:28.515628  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304663 (* 1 = 0.304663 loss)
I1005 13:18:28.515637  9519 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1005 13:18:33.517943  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:18:33.728009  9519 solver.cpp:330] Iteration 19500, Testing net (#0)
I1005 13:18:34.915031  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:18:34.964474  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7113
I1005 13:18:34.964503  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01994 (* 1 = 1.01994 loss)
I1005 13:18:35.017092  9519 solver.cpp:218] Iteration 19500 (15.3812 iter/s, 6.50144s/100 iters), loss = 0.183166
I1005 13:18:35.017128  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183166 (* 1 = 0.183166 loss)
I1005 13:18:35.017138  9519 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1005 13:18:40.277305  9519 solver.cpp:218] Iteration 19600 (19.0108 iter/s, 5.26016s/100 iters), loss = 0.2299
I1005 13:18:40.277348  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2299 (* 1 = 0.2299 loss)
I1005 13:18:40.277355  9519 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1005 13:18:45.534895  9519 solver.cpp:218] Iteration 19700 (19.0203 iter/s, 5.25753s/100 iters), loss = 0.161325
I1005 13:18:45.534935  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161325 (* 1 = 0.161325 loss)
I1005 13:18:45.534942  9519 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1005 13:18:50.792171  9519 solver.cpp:218] Iteration 19800 (19.0215 iter/s, 5.25722s/100 iters), loss = 0.286306
I1005 13:18:50.792304  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286306 (* 1 = 0.286306 loss)
I1005 13:18:50.792322  9519 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1005 13:18:56.037168  9519 solver.cpp:218] Iteration 19900 (19.0663 iter/s, 5.24485s/100 iters), loss = 0.251543
I1005 13:18:56.037197  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251543 (* 1 = 0.251543 loss)
I1005 13:18:56.037204  9519 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1005 13:19:01.034137  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:19:01.243903  9519 solver.cpp:330] Iteration 20000, Testing net (#0)
I1005 13:19:02.433977  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:19:02.484824  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7249
I1005 13:19:02.484850  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00694 (* 1 = 1.00694 loss)
I1005 13:19:02.538183  9519 solver.cpp:218] Iteration 20000 (15.3823 iter/s, 6.50096s/100 iters), loss = 0.237319
I1005 13:19:02.538228  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237319 (* 1 = 0.237319 loss)
I1005 13:19:02.538235  9519 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1005 13:19:07.788254  9519 solver.cpp:218] Iteration 20100 (19.0477 iter/s, 5.24998s/100 iters), loss = 0.17657
I1005 13:19:07.788283  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17657 (* 1 = 0.17657 loss)
I1005 13:19:07.788290  9519 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1005 13:19:13.051847  9519 solver.cpp:218] Iteration 20200 (18.9986 iter/s, 5.26355s/100 iters), loss = 0.225347
I1005 13:19:13.051878  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225347 (* 1 = 0.225347 loss)
I1005 13:19:13.051895  9519 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1005 13:19:18.313165  9519 solver.cpp:218] Iteration 20300 (19.0068 iter/s, 5.26127s/100 iters), loss = 0.297281
I1005 13:19:18.313206  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297281 (* 1 = 0.297281 loss)
I1005 13:19:18.313212  9519 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1005 13:19:23.561816  9519 solver.cpp:218] Iteration 20400 (19.0527 iter/s, 5.24859s/100 iters), loss = 0.206342
I1005 13:19:23.561959  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206342 (* 1 = 0.206342 loss)
I1005 13:19:23.561978  9519 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1005 13:19:28.553719  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:19:28.762486  9519 solver.cpp:330] Iteration 20500, Testing net (#0)
I1005 13:19:29.961307  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:19:30.011167  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7569
I1005 13:19:30.011191  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.782441 (* 1 = 0.782441 loss)
I1005 13:19:30.063524  9519 solver.cpp:218] Iteration 20500 (15.3809 iter/s, 6.50156s/100 iters), loss = 0.208436
I1005 13:19:30.063557  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208436 (* 1 = 0.208436 loss)
I1005 13:19:30.063565  9519 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1005 13:19:35.309648  9519 solver.cpp:218] Iteration 20600 (19.0619 iter/s, 5.24608s/100 iters), loss = 0.187643
I1005 13:19:35.309690  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187643 (* 1 = 0.187643 loss)
I1005 13:19:35.309697  9519 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1005 13:19:40.561761  9519 solver.cpp:218] Iteration 20700 (19.0402 iter/s, 5.25205s/100 iters), loss = 0.247883
I1005 13:19:40.561802  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247883 (* 1 = 0.247883 loss)
I1005 13:19:40.561808  9519 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1005 13:19:45.815361  9519 solver.cpp:218] Iteration 20800 (19.0348 iter/s, 5.25354s/100 iters), loss = 0.284375
I1005 13:19:45.815400  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284375 (* 1 = 0.284375 loss)
I1005 13:19:45.815407  9519 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1005 13:19:51.067456  9519 solver.cpp:218] Iteration 20900 (19.0402 iter/s, 5.25204s/100 iters), loss = 0.27717
I1005 13:19:51.067497  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27717 (* 1 = 0.27717 loss)
I1005 13:19:51.067503  9519 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1005 13:19:56.051371  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:19:56.260203  9519 solver.cpp:330] Iteration 21000, Testing net (#0)
I1005 13:19:57.455803  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:19:57.504876  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7687
I1005 13:19:57.504901  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.762667 (* 1 = 0.762667 loss)
I1005 13:19:57.557292  9519 solver.cpp:218] Iteration 21000 (15.4089 iter/s, 6.48977s/100 iters), loss = 0.348378
I1005 13:19:57.557320  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348378 (* 1 = 0.348378 loss)
I1005 13:19:57.557327  9519 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1005 13:20:02.819553  9519 solver.cpp:218] Iteration 21100 (19.0034 iter/s, 5.26221s/100 iters), loss = 0.215802
I1005 13:20:02.819583  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215802 (* 1 = 0.215802 loss)
I1005 13:20:02.819588  9519 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1005 13:20:08.070262  9519 solver.cpp:218] Iteration 21200 (19.0452 iter/s, 5.25066s/100 iters), loss = 0.318638
I1005 13:20:08.070293  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318638 (* 1 = 0.318638 loss)
I1005 13:20:08.070300  9519 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1005 13:20:13.335041  9519 solver.cpp:218] Iteration 21300 (18.9943 iter/s, 5.26473s/100 iters), loss = 0.1893
I1005 13:20:13.335070  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1893 (* 1 = 0.1893 loss)
I1005 13:20:13.335077  9519 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1005 13:20:18.591447  9519 solver.cpp:218] Iteration 21400 (19.0246 iter/s, 5.25636s/100 iters), loss = 0.240666
I1005 13:20:18.591488  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240666 (* 1 = 0.240666 loss)
I1005 13:20:18.591495  9519 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1005 13:20:23.596166  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:20:23.805763  9519 solver.cpp:330] Iteration 21500, Testing net (#0)
I1005 13:20:24.992061  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:20:25.041610  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.759
I1005 13:20:25.041645  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.764072 (* 1 = 0.764072 loss)
I1005 13:20:25.094022  9519 solver.cpp:218] Iteration 21500 (15.3787 iter/s, 6.50252s/100 iters), loss = 0.208205
I1005 13:20:25.094049  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208205 (* 1 = 0.208205 loss)
I1005 13:20:25.094056  9519 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1005 13:20:30.354828  9519 solver.cpp:218] Iteration 21600 (19.0087 iter/s, 5.26076s/100 iters), loss = 0.246577
I1005 13:20:30.354959  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246577 (* 1 = 0.246577 loss)
I1005 13:20:30.354976  9519 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1005 13:20:35.610245  9519 solver.cpp:218] Iteration 21700 (19.0285 iter/s, 5.25527s/100 iters), loss = 0.214313
I1005 13:20:35.610281  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214313 (* 1 = 0.214313 loss)
I1005 13:20:35.610290  9519 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1005 13:20:40.858045  9519 solver.cpp:218] Iteration 21800 (19.0558 iter/s, 5.24775s/100 iters), loss = 0.28055
I1005 13:20:40.858085  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28055 (* 1 = 0.28055 loss)
I1005 13:20:40.858091  9519 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1005 13:20:46.115476  9519 solver.cpp:218] Iteration 21900 (19.0209 iter/s, 5.25737s/100 iters), loss = 0.233123
I1005 13:20:46.115506  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233124 (* 1 = 0.233124 loss)
I1005 13:20:46.115512  9519 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1005 13:20:51.116050  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:20:51.326125  9519 solver.cpp:330] Iteration 22000, Testing net (#0)
I1005 13:20:52.513577  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:20:52.563563  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6584
I1005 13:20:52.563588  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31499 (* 1 = 1.31499 loss)
I1005 13:20:52.615866  9519 solver.cpp:218] Iteration 22000 (15.3838 iter/s, 6.50034s/100 iters), loss = 0.205123
I1005 13:20:52.615895  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205123 (* 1 = 0.205123 loss)
I1005 13:20:52.615901  9519 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1005 13:20:57.869302  9519 solver.cpp:218] Iteration 22100 (19.0353 iter/s, 5.25339s/100 iters), loss = 0.344506
I1005 13:20:57.869343  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344506 (* 1 = 0.344506 loss)
I1005 13:20:57.869350  9519 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1005 13:21:03.132447  9519 solver.cpp:218] Iteration 22200 (19.0003 iter/s, 5.26309s/100 iters), loss = 0.230031
I1005 13:21:03.132589  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230031 (* 1 = 0.230031 loss)
I1005 13:21:03.132598  9519 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1005 13:21:08.386952  9519 solver.cpp:218] Iteration 22300 (19.0318 iter/s, 5.25436s/100 iters), loss = 0.238717
I1005 13:21:08.386999  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238717 (* 1 = 0.238717 loss)
I1005 13:21:08.387008  9519 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1005 13:21:13.643005  9519 solver.cpp:218] Iteration 22400 (19.026 iter/s, 5.25596s/100 iters), loss = 0.276675
I1005 13:21:13.643038  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276675 (* 1 = 0.276675 loss)
I1005 13:21:13.643046  9519 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1005 13:21:18.639714  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:21:18.849552  9519 solver.cpp:330] Iteration 22500, Testing net (#0)
I1005 13:21:20.038228  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:21:20.087956  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.805
I1005 13:21:20.087992  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.589653 (* 1 = 0.589653 loss)
I1005 13:21:20.140414  9519 solver.cpp:218] Iteration 22500 (15.3909 iter/s, 6.49736s/100 iters), loss = 0.228035
I1005 13:21:20.140447  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228035 (* 1 = 0.228035 loss)
I1005 13:21:20.140455  9519 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1005 13:21:25.400447  9519 solver.cpp:218] Iteration 22600 (19.0115 iter/s, 5.25998s/100 iters), loss = 0.231251
I1005 13:21:25.400488  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231251 (* 1 = 0.231251 loss)
I1005 13:21:25.400494  9519 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1005 13:21:30.655649  9519 solver.cpp:218] Iteration 22700 (19.029 iter/s, 5.25514s/100 iters), loss = 0.333145
I1005 13:21:30.655680  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333145 (* 1 = 0.333145 loss)
I1005 13:21:30.655696  9519 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1005 13:21:35.919706  9519 solver.cpp:218] Iteration 22800 (18.9969 iter/s, 5.26401s/100 iters), loss = 0.238961
I1005 13:21:35.919833  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238961 (* 1 = 0.238961 loss)
I1005 13:21:35.919840  9519 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1005 13:21:41.169775  9519 solver.cpp:218] Iteration 22900 (19.0479 iter/s, 5.24992s/100 iters), loss = 0.216605
I1005 13:21:41.169823  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216605 (* 1 = 0.216605 loss)
I1005 13:21:41.169831  9519 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1005 13:21:46.149900  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:21:46.359835  9519 solver.cpp:330] Iteration 23000, Testing net (#0)
I1005 13:21:47.556668  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:21:47.606703  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7628
I1005 13:21:47.606729  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.768694 (* 1 = 0.768694 loss)
I1005 13:21:47.658700  9519 solver.cpp:218] Iteration 23000 (15.411 iter/s, 6.48886s/100 iters), loss = 0.197605
I1005 13:21:47.658731  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197605 (* 1 = 0.197605 loss)
I1005 13:21:47.658738  9519 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1005 13:21:52.916237  9519 solver.cpp:218] Iteration 23100 (19.0205 iter/s, 5.25749s/100 iters), loss = 0.23768
I1005 13:21:52.916280  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23768 (* 1 = 0.23768 loss)
I1005 13:21:52.916286  9519 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1005 13:21:58.180460  9519 solver.cpp:218] Iteration 23200 (18.9964 iter/s, 5.26416s/100 iters), loss = 0.299651
I1005 13:21:58.180501  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299651 (* 1 = 0.299651 loss)
I1005 13:21:58.180507  9519 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1005 13:22:03.441712  9519 solver.cpp:218] Iteration 23300 (19.0071 iter/s, 5.26119s/100 iters), loss = 0.238754
I1005 13:22:03.441753  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238754 (* 1 = 0.238754 loss)
I1005 13:22:03.441761  9519 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1005 13:22:08.695804  9519 solver.cpp:218] Iteration 23400 (19.033 iter/s, 5.25403s/100 iters), loss = 0.268709
I1005 13:22:08.695919  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268709 (* 1 = 0.268709 loss)
I1005 13:22:08.695930  9519 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1005 13:22:13.690662  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:22:13.901093  9519 solver.cpp:330] Iteration 23500, Testing net (#0)
I1005 13:22:15.093737  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:22:15.143302  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8078
I1005 13:22:15.143337  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.58246 (* 1 = 0.58246 loss)
I1005 13:22:15.195328  9519 solver.cpp:218] Iteration 23500 (15.3861 iter/s, 6.49939s/100 iters), loss = 0.160929
I1005 13:22:15.195360  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160929 (* 1 = 0.160929 loss)
I1005 13:22:15.195367  9519 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1005 13:22:20.452657  9519 solver.cpp:218] Iteration 23600 (19.0213 iter/s, 5.25728s/100 iters), loss = 0.221742
I1005 13:22:20.452715  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221742 (* 1 = 0.221742 loss)
I1005 13:22:20.452723  9519 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1005 13:22:25.709298  9519 solver.cpp:218] Iteration 23700 (19.024 iter/s, 5.25653s/100 iters), loss = 0.327163
I1005 13:22:25.709329  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327163 (* 1 = 0.327163 loss)
I1005 13:22:25.709336  9519 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1005 13:22:30.967217  9519 solver.cpp:218] Iteration 23800 (19.0191 iter/s, 5.25787s/100 iters), loss = 0.237579
I1005 13:22:30.967249  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237579 (* 1 = 0.237579 loss)
I1005 13:22:30.967255  9519 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1005 13:22:36.217993  9519 solver.cpp:218] Iteration 23900 (19.045 iter/s, 5.25073s/100 iters), loss = 0.229042
I1005 13:22:36.218024  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229042 (* 1 = 0.229042 loss)
I1005 13:22:36.218029  9519 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1005 13:22:41.209558  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:22:41.421458  9519 solver.cpp:330] Iteration 24000, Testing net (#0)
I1005 13:22:42.615772  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:22:42.665380  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7697
I1005 13:22:42.665406  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.749102 (* 1 = 0.749102 loss)
I1005 13:22:42.717366  9519 solver.cpp:218] Iteration 24000 (15.3862 iter/s, 6.49933s/100 iters), loss = 0.277771
I1005 13:22:42.717396  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277772 (* 1 = 0.277772 loss)
I1005 13:22:42.717404  9519 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1005 13:22:47.974828  9519 solver.cpp:218] Iteration 24100 (19.0208 iter/s, 5.25742s/100 iters), loss = 0.218961
I1005 13:22:47.974858  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218961 (* 1 = 0.218961 loss)
I1005 13:22:47.974874  9519 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1005 13:22:53.224236  9519 solver.cpp:218] Iteration 24200 (19.0499 iter/s, 5.24936s/100 iters), loss = 0.227091
I1005 13:22:53.224267  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227091 (* 1 = 0.227091 loss)
I1005 13:22:53.224272  9519 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1005 13:22:58.478503  9519 solver.cpp:218] Iteration 24300 (19.0323 iter/s, 5.25422s/100 iters), loss = 0.294469
I1005 13:22:58.478552  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294469 (* 1 = 0.294469 loss)
I1005 13:22:58.478559  9519 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1005 13:23:03.734380  9519 solver.cpp:218] Iteration 24400 (19.0265 iter/s, 5.25583s/100 iters), loss = 0.231347
I1005 13:23:03.734413  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231347 (* 1 = 0.231347 loss)
I1005 13:23:03.734422  9519 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1005 13:23:08.736274  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:23:08.946576  9519 solver.cpp:330] Iteration 24500, Testing net (#0)
I1005 13:23:10.133479  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:23:10.183279  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7258
I1005 13:23:10.183305  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.950035 (* 1 = 0.950035 loss)
I1005 13:23:10.235962  9519 solver.cpp:218] Iteration 24500 (15.381 iter/s, 6.50153s/100 iters), loss = 0.296978
I1005 13:23:10.236001  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296978 (* 1 = 0.296978 loss)
I1005 13:23:10.236011  9519 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1005 13:23:15.503118  9519 solver.cpp:218] Iteration 24600 (18.9858 iter/s, 5.2671s/100 iters), loss = 0.247835
I1005 13:23:15.503258  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247835 (* 1 = 0.247835 loss)
I1005 13:23:15.503276  9519 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1005 13:23:20.771883  9519 solver.cpp:218] Iteration 24700 (18.9803 iter/s, 5.26862s/100 iters), loss = 0.236671
I1005 13:23:20.771914  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236671 (* 1 = 0.236671 loss)
I1005 13:23:20.771929  9519 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1005 13:23:26.028939  9519 solver.cpp:218] Iteration 24800 (19.0222 iter/s, 5.257s/100 iters), loss = 0.297592
I1005 13:23:26.028971  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297592 (* 1 = 0.297592 loss)
I1005 13:23:26.028978  9519 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1005 13:23:31.292701  9519 solver.cpp:218] Iteration 24900 (18.998 iter/s, 5.26371s/100 iters), loss = 0.22884
I1005 13:23:31.292732  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22884 (* 1 = 0.22884 loss)
I1005 13:23:31.292748  9519 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1005 13:23:36.296978  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:23:36.506860  9519 solver.cpp:330] Iteration 25000, Testing net (#0)
I1005 13:23:37.694574  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:23:37.743744  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6265
I1005 13:23:37.743772  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.53048 (* 1 = 1.53048 loss)
I1005 13:23:37.796202  9519 solver.cpp:218] Iteration 25000 (15.3764 iter/s, 6.50345s/100 iters), loss = 0.205796
I1005 13:23:37.796226  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205796 (* 1 = 0.205796 loss)
I1005 13:23:37.796233  9519 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1005 13:23:43.059576  9519 solver.cpp:218] Iteration 25100 (18.9994 iter/s, 5.26333s/100 iters), loss = 0.38822
I1005 13:23:43.059620  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38822 (* 1 = 0.38822 loss)
I1005 13:23:43.059626  9519 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1005 13:23:48.317971  9519 solver.cpp:218] Iteration 25200 (19.0174 iter/s, 5.25833s/100 iters), loss = 0.252194
I1005 13:23:48.318079  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252194 (* 1 = 0.252194 loss)
I1005 13:23:48.318086  9519 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1005 13:23:53.579367  9519 solver.cpp:218] Iteration 25300 (19.0068 iter/s, 5.26127s/100 iters), loss = 0.251979
I1005 13:23:53.579413  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251979 (* 1 = 0.251979 loss)
I1005 13:23:53.579421  9519 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1005 13:23:58.833349  9519 solver.cpp:218] Iteration 25400 (19.0334 iter/s, 5.25392s/100 iters), loss = 0.18121
I1005 13:23:58.833379  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18121 (* 1 = 0.18121 loss)
I1005 13:23:58.833385  9519 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1005 13:24:03.839682  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:24:04.050564  9519 solver.cpp:330] Iteration 25500, Testing net (#0)
I1005 13:24:05.239341  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:24:05.288883  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7019
I1005 13:24:05.288918  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04062 (* 1 = 1.04062 loss)
I1005 13:24:05.341012  9519 solver.cpp:218] Iteration 25500 (15.3666 iter/s, 6.50761s/100 iters), loss = 0.243248
I1005 13:24:05.341044  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243248 (* 1 = 0.243248 loss)
I1005 13:24:05.341053  9519 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1005 13:24:10.602811  9519 solver.cpp:218] Iteration 25600 (19.0051 iter/s, 5.26175s/100 iters), loss = 0.218031
I1005 13:24:10.602854  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218031 (* 1 = 0.218031 loss)
I1005 13:24:10.602859  9519 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1005 13:24:15.865157  9519 solver.cpp:218] Iteration 25700 (19.0031 iter/s, 5.26229s/100 iters), loss = 0.237971
I1005 13:24:15.865198  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237971 (* 1 = 0.237971 loss)
I1005 13:24:15.865205  9519 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1005 13:24:21.123811  9519 solver.cpp:218] Iteration 25800 (19.0165 iter/s, 5.25859s/100 iters), loss = 0.265709
I1005 13:24:21.123971  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265709 (* 1 = 0.265709 loss)
I1005 13:24:21.123980  9519 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1005 13:24:26.367664  9519 solver.cpp:218] Iteration 25900 (19.0706 iter/s, 5.24368s/100 iters), loss = 0.168331
I1005 13:24:26.367709  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168332 (* 1 = 0.168332 loss)
I1005 13:24:26.367717  9519 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1005 13:24:31.368504  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:24:31.578614  9519 solver.cpp:330] Iteration 26000, Testing net (#0)
I1005 13:24:32.773228  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:24:32.822839  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7867
I1005 13:24:32.822867  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663122 (* 1 = 0.663122 loss)
I1005 13:24:32.875201  9519 solver.cpp:218] Iteration 26000 (15.367 iter/s, 6.50744s/100 iters), loss = 0.24666
I1005 13:24:32.875231  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24666 (* 1 = 0.24666 loss)
I1005 13:24:32.875237  9519 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1005 13:24:38.125529  9519 solver.cpp:218] Iteration 26100 (19.0466 iter/s, 5.25028s/100 iters), loss = 0.15534
I1005 13:24:38.125571  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15534 (* 1 = 0.15534 loss)
I1005 13:24:38.125576  9519 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1005 13:24:43.381081  9519 solver.cpp:218] Iteration 26200 (19.0277 iter/s, 5.25549s/100 iters), loss = 0.242595
I1005 13:24:43.381122  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242595 (* 1 = 0.242595 loss)
I1005 13:24:43.381129  9519 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1005 13:24:48.641384  9519 solver.cpp:218] Iteration 26300 (19.0105 iter/s, 5.26025s/100 iters), loss = 0.289934
I1005 13:24:48.641414  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289934 (* 1 = 0.289934 loss)
I1005 13:24:48.641422  9519 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1005 13:24:53.896986  9519 solver.cpp:218] Iteration 26400 (19.0275 iter/s, 5.25555s/100 iters), loss = 0.187263
I1005 13:24:53.897107  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187263 (* 1 = 0.187263 loss)
I1005 13:24:53.897127  9519 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1005 13:24:58.884654  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:24:59.094326  9519 solver.cpp:330] Iteration 26500, Testing net (#0)
I1005 13:25:00.292361  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:25:00.341948  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I1005 13:25:00.341974  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.642134 (* 1 = 0.642134 loss)
I1005 13:25:00.394610  9519 solver.cpp:218] Iteration 26500 (15.3906 iter/s, 6.49749s/100 iters), loss = 0.184503
I1005 13:25:00.394635  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184503 (* 1 = 0.184503 loss)
I1005 13:25:00.394642  9519 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1005 13:25:05.657378  9519 solver.cpp:218] Iteration 26600 (19.0016 iter/s, 5.26272s/100 iters), loss = 0.23125
I1005 13:25:05.657413  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23125 (* 1 = 0.23125 loss)
I1005 13:25:05.657419  9519 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1005 13:25:10.906623  9519 solver.cpp:218] Iteration 26700 (19.0505 iter/s, 5.24919s/100 iters), loss = 0.277105
I1005 13:25:10.906656  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277105 (* 1 = 0.277105 loss)
I1005 13:25:10.906661  9519 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1005 13:25:16.161448  9519 solver.cpp:218] Iteration 26800 (19.0303 iter/s, 5.25477s/100 iters), loss = 0.28266
I1005 13:25:16.161480  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282661 (* 1 = 0.282661 loss)
I1005 13:25:16.161487  9519 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1005 13:25:21.413988  9519 solver.cpp:218] Iteration 26900 (19.0386 iter/s, 5.25249s/100 iters), loss = 0.227156
I1005 13:25:21.414019  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227156 (* 1 = 0.227156 loss)
I1005 13:25:21.414024  9519 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1005 13:25:26.408061  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:25:26.623605  9519 solver.cpp:330] Iteration 27000, Testing net (#0)
I1005 13:25:27.811818  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:25:27.861613  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7401
I1005 13:25:27.861640  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.798662 (* 1 = 0.798662 loss)
I1005 13:25:27.914153  9519 solver.cpp:218] Iteration 27000 (15.3843 iter/s, 6.50012s/100 iters), loss = 0.263261
I1005 13:25:27.914181  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263262 (* 1 = 0.263262 loss)
I1005 13:25:27.914191  9519 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1005 13:25:33.170460  9519 solver.cpp:218] Iteration 27100 (19.0249 iter/s, 5.25626s/100 iters), loss = 0.207739
I1005 13:25:33.170496  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207739 (* 1 = 0.207739 loss)
I1005 13:25:33.170505  9519 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1005 13:25:38.426072  9519 solver.cpp:218] Iteration 27200 (19.0275 iter/s, 5.25555s/100 iters), loss = 0.260349
I1005 13:25:38.426110  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260349 (* 1 = 0.260349 loss)
I1005 13:25:38.426128  9519 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1005 13:25:43.681871  9519 solver.cpp:218] Iteration 27300 (19.0269 iter/s, 5.25571s/100 iters), loss = 0.286452
I1005 13:25:43.681911  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286452 (* 1 = 0.286452 loss)
I1005 13:25:43.681917  9519 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1005 13:25:48.942934  9519 solver.cpp:218] Iteration 27400 (19.0078 iter/s, 5.26101s/100 iters), loss = 0.157077
I1005 13:25:48.942976  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157077 (* 1 = 0.157077 loss)
I1005 13:25:48.942982  9519 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1005 13:25:53.949004  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:25:54.158962  9519 solver.cpp:330] Iteration 27500, Testing net (#0)
I1005 13:25:55.346843  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:25:55.396325  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.779
I1005 13:25:55.396363  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.714554 (* 1 = 0.714554 loss)
I1005 13:25:55.448580  9519 solver.cpp:218] Iteration 27500 (15.3714 iter/s, 6.50559s/100 iters), loss = 0.208437
I1005 13:25:55.448611  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208437 (* 1 = 0.208437 loss)
I1005 13:25:55.448618  9519 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1005 13:26:00.711966  9519 solver.cpp:218] Iteration 27600 (18.9994 iter/s, 5.26333s/100 iters), loss = 0.250307
I1005 13:26:00.712110  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250307 (* 1 = 0.250307 loss)
I1005 13:26:00.712129  9519 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1005 13:26:05.970916  9519 solver.cpp:218] Iteration 27700 (19.0158 iter/s, 5.2588s/100 iters), loss = 0.219543
I1005 13:26:05.970948  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219543 (* 1 = 0.219543 loss)
I1005 13:26:05.970957  9519 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1005 13:26:11.224732  9519 solver.cpp:218] Iteration 27800 (19.034 iter/s, 5.25376s/100 iters), loss = 0.21769
I1005 13:26:11.224763  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21769 (* 1 = 0.21769 loss)
I1005 13:26:11.224771  9519 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1005 13:26:16.476861  9519 solver.cpp:218] Iteration 27900 (19.0401 iter/s, 5.25208s/100 iters), loss = 0.126476
I1005 13:26:16.476891  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126476 (* 1 = 0.126476 loss)
I1005 13:26:16.476897  9519 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1005 13:26:21.476757  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:26:21.686574  9519 solver.cpp:330] Iteration 28000, Testing net (#0)
I1005 13:26:22.873090  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:26:22.922729  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7876
I1005 13:26:22.922765  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.655819 (* 1 = 0.655819 loss)
I1005 13:26:22.975080  9519 solver.cpp:218] Iteration 28000 (15.3889 iter/s, 6.49817s/100 iters), loss = 0.170351
I1005 13:26:22.975111  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170352 (* 1 = 0.170352 loss)
I1005 13:26:22.975117  9519 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1005 13:26:28.229512  9519 solver.cpp:218] Iteration 28100 (19.0317 iter/s, 5.25438s/100 iters), loss = 0.230557
I1005 13:26:28.229542  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230557 (* 1 = 0.230557 loss)
I1005 13:26:28.229548  9519 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1005 13:26:33.494241  9519 solver.cpp:218] Iteration 28200 (18.9945 iter/s, 5.26468s/100 iters), loss = 0.256577
I1005 13:26:33.494339  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256577 (* 1 = 0.256577 loss)
I1005 13:26:33.494355  9519 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1005 13:26:38.762056  9519 solver.cpp:218] Iteration 28300 (18.9836 iter/s, 5.2677s/100 iters), loss = 0.310873
I1005 13:26:38.762089  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310873 (* 1 = 0.310873 loss)
I1005 13:26:38.762094  9519 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1005 13:26:44.009562  9519 solver.cpp:218] Iteration 28400 (19.0569 iter/s, 5.24746s/100 iters), loss = 0.20665
I1005 13:26:44.009604  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20665 (* 1 = 0.20665 loss)
I1005 13:26:44.009610  9519 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1005 13:26:49.018215  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:26:49.228271  9519 solver.cpp:330] Iteration 28500, Testing net (#0)
I1005 13:26:50.415320  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:26:50.465867  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7591
I1005 13:26:50.465904  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.788372 (* 1 = 0.788372 loss)
I1005 13:26:50.519222  9519 solver.cpp:218] Iteration 28500 (15.3619 iter/s, 6.5096s/100 iters), loss = 0.210237
I1005 13:26:50.519259  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210238 (* 1 = 0.210238 loss)
I1005 13:26:50.519268  9519 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1005 13:26:55.769583  9519 solver.cpp:218] Iteration 28600 (19.0465 iter/s, 5.25031s/100 iters), loss = 0.230297
I1005 13:26:55.769613  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230297 (* 1 = 0.230297 loss)
I1005 13:26:55.769619  9519 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1005 13:27:01.025595  9519 solver.cpp:218] Iteration 28700 (19.026 iter/s, 5.25596s/100 iters), loss = 0.347428
I1005 13:27:01.025625  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347428 (* 1 = 0.347428 loss)
I1005 13:27:01.025631  9519 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1005 13:27:06.283717  9519 solver.cpp:218] Iteration 28800 (19.0184 iter/s, 5.25807s/100 iters), loss = 0.31857
I1005 13:27:06.283875  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31857 (* 1 = 0.31857 loss)
I1005 13:27:06.283884  9519 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1005 13:27:11.535526  9519 solver.cpp:218] Iteration 28900 (19.0417 iter/s, 5.25163s/100 iters), loss = 0.126375
I1005 13:27:11.535573  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126375 (* 1 = 0.126375 loss)
I1005 13:27:11.535579  9519 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1005 13:27:16.531330  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:27:16.741101  9519 solver.cpp:330] Iteration 29000, Testing net (#0)
I1005 13:27:17.938002  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:27:17.987563  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7705
I1005 13:27:17.987599  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706604 (* 1 = 0.706604 loss)
I1005 13:27:18.039669  9519 solver.cpp:218] Iteration 29000 (15.375 iter/s, 6.50405s/100 iters), loss = 0.170332
I1005 13:27:18.039696  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170332 (* 1 = 0.170332 loss)
I1005 13:27:18.039703  9519 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1005 13:27:23.292273  9519 solver.cpp:218] Iteration 29100 (19.0383 iter/s, 5.25256s/100 iters), loss = 0.170414
I1005 13:27:23.292304  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170414 (* 1 = 0.170414 loss)
I1005 13:27:23.292320  9519 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1005 13:27:28.554074  9519 solver.cpp:218] Iteration 29200 (19.0051 iter/s, 5.26175s/100 iters), loss = 0.220389
I1005 13:27:28.554124  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220389 (* 1 = 0.220389 loss)
I1005 13:27:28.554131  9519 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1005 13:27:33.816165  9519 solver.cpp:218] Iteration 29300 (19.0041 iter/s, 5.26203s/100 iters), loss = 0.26635
I1005 13:27:33.816196  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26635 (* 1 = 0.26635 loss)
I1005 13:27:33.816211  9519 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1005 13:27:39.071427  9519 solver.cpp:218] Iteration 29400 (19.0287 iter/s, 5.25521s/100 iters), loss = 0.18233
I1005 13:27:39.071574  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18233 (* 1 = 0.18233 loss)
I1005 13:27:39.071583  9519 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1005 13:27:44.062011  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:27:44.272035  9519 solver.cpp:330] Iteration 29500, Testing net (#0)
I1005 13:27:45.467061  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:27:45.517021  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7009
I1005 13:27:45.517057  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03195 (* 1 = 1.03195 loss)
I1005 13:27:45.569594  9519 solver.cpp:218] Iteration 29500 (15.3893 iter/s, 6.49801s/100 iters), loss = 0.185771
I1005 13:27:45.569633  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185772 (* 1 = 0.185772 loss)
I1005 13:27:45.569638  9519 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1005 13:27:50.832815  9519 solver.cpp:218] Iteration 29600 (19 iter/s, 5.26316s/100 iters), loss = 0.273395
I1005 13:27:50.832857  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273396 (* 1 = 0.273396 loss)
I1005 13:27:50.832864  9519 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1005 13:27:56.082592  9519 solver.cpp:218] Iteration 29700 (19.0486 iter/s, 5.24972s/100 iters), loss = 0.269839
I1005 13:27:56.082621  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269839 (* 1 = 0.269839 loss)
I1005 13:27:56.082628  9519 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1005 13:28:01.345237  9519 solver.cpp:218] Iteration 29800 (19.002 iter/s, 5.2626s/100 iters), loss = 0.314499
I1005 13:28:01.345276  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314499 (* 1 = 0.314499 loss)
I1005 13:28:01.345283  9519 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1005 13:28:06.604518  9519 solver.cpp:218] Iteration 29900 (19.0142 iter/s, 5.25922s/100 iters), loss = 0.273844
I1005 13:28:06.604548  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273844 (* 1 = 0.273844 loss)
I1005 13:28:06.604564  9519 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1005 13:28:11.612871  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:28:11.824401  9519 solver.cpp:330] Iteration 30000, Testing net (#0)
I1005 13:28:13.012995  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:28:13.062347  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6664
I1005 13:28:13.062372  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10579 (* 1 = 1.10579 loss)
I1005 13:28:13.114723  9519 solver.cpp:218] Iteration 30000 (15.3606 iter/s, 6.51015s/100 iters), loss = 0.203237
I1005 13:28:13.114749  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203237 (* 1 = 0.203237 loss)
I1005 13:28:13.114756  9519 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1005 13:28:18.378222  9519 solver.cpp:218] Iteration 30100 (18.9989 iter/s, 5.26345s/100 iters), loss = 0.26383
I1005 13:28:18.378262  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26383 (* 1 = 0.26383 loss)
I1005 13:28:18.378269  9519 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1005 13:28:23.643908  9519 solver.cpp:218] Iteration 30200 (18.9911 iter/s, 5.26563s/100 iters), loss = 0.248704
I1005 13:28:23.643956  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248704 (* 1 = 0.248704 loss)
I1005 13:28:23.643965  9519 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1005 13:28:28.897840  9519 solver.cpp:218] Iteration 30300 (19.0339 iter/s, 5.25379s/100 iters), loss = 0.226087
I1005 13:28:28.897871  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226087 (* 1 = 0.226087 loss)
I1005 13:28:28.897876  9519 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1005 13:28:34.154147  9519 solver.cpp:218] Iteration 30400 (19.0249 iter/s, 5.25626s/100 iters), loss = 0.114801
I1005 13:28:34.154177  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114801 (* 1 = 0.114801 loss)
I1005 13:28:34.154193  9519 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1005 13:28:39.155267  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:28:39.365977  9519 solver.cpp:330] Iteration 30500, Testing net (#0)
I1005 13:28:40.553752  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:28:40.603483  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7404
I1005 13:28:40.603518  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.890626 (* 1 = 0.890626 loss)
I1005 13:28:40.655725  9519 solver.cpp:218] Iteration 30500 (15.381 iter/s, 6.50153s/100 iters), loss = 0.199155
I1005 13:28:40.655761  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199155 (* 1 = 0.199155 loss)
I1005 13:28:40.655766  9519 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1005 13:28:45.918254  9519 solver.cpp:218] Iteration 30600 (19.0025 iter/s, 5.26248s/100 iters), loss = 0.267433
I1005 13:28:45.918360  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267433 (* 1 = 0.267433 loss)
I1005 13:28:45.918367  9519 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1005 13:28:51.183060  9519 solver.cpp:218] Iteration 30700 (18.9945 iter/s, 5.26469s/100 iters), loss = 0.20012
I1005 13:28:51.183101  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20012 (* 1 = 0.20012 loss)
I1005 13:28:51.183107  9519 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1005 13:28:56.445827  9519 solver.cpp:218] Iteration 30800 (19.0016 iter/s, 5.2627s/100 iters), loss = 0.234285
I1005 13:28:56.445878  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234285 (* 1 = 0.234285 loss)
I1005 13:28:56.445885  9519 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1005 13:29:01.709820  9519 solver.cpp:218] Iteration 30900 (18.9973 iter/s, 5.2639s/100 iters), loss = 0.178672
I1005 13:29:01.709862  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178672 (* 1 = 0.178672 loss)
I1005 13:29:01.709867  9519 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1005 13:29:06.717841  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:29:06.928223  9519 solver.cpp:330] Iteration 31000, Testing net (#0)
I1005 13:29:08.115660  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:29:08.164983  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8018
I1005 13:29:08.165017  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.612516 (* 1 = 0.612516 loss)
I1005 13:29:08.217413  9519 solver.cpp:218] Iteration 31000 (15.3668 iter/s, 6.50753s/100 iters), loss = 0.269586
I1005 13:29:08.217450  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269586 (* 1 = 0.269586 loss)
I1005 13:29:08.217458  9519 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1005 13:29:13.481034  9519 solver.cpp:218] Iteration 31100 (18.9985 iter/s, 5.26357s/100 iters), loss = 0.186239
I1005 13:29:13.481063  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186239 (* 1 = 0.186239 loss)
I1005 13:29:13.481068  9519 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1005 13:29:18.743507  9519 solver.cpp:218] Iteration 31200 (19.0027 iter/s, 5.26242s/100 iters), loss = 0.203222
I1005 13:29:18.743664  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203222 (* 1 = 0.203222 loss)
I1005 13:29:18.743671  9519 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1005 13:29:24.003634  9519 solver.cpp:218] Iteration 31300 (19.0115 iter/s, 5.25997s/100 iters), loss = 0.1874
I1005 13:29:24.003664  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1874 (* 1 = 0.1874 loss)
I1005 13:29:24.003670  9519 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1005 13:29:29.250591  9519 solver.cpp:218] Iteration 31400 (19.0588 iter/s, 5.24691s/100 iters), loss = 0.127354
I1005 13:29:29.250633  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127354 (* 1 = 0.127354 loss)
I1005 13:29:29.250639  9519 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1005 13:29:34.254420  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:29:34.465546  9519 solver.cpp:330] Iteration 31500, Testing net (#0)
I1005 13:29:35.662202  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:29:35.711808  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.799
I1005 13:29:35.711836  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.636275 (* 1 = 0.636275 loss)
I1005 13:29:35.764299  9519 solver.cpp:218] Iteration 31500 (15.3524 iter/s, 6.51365s/100 iters), loss = 0.15591
I1005 13:29:35.764334  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155911 (* 1 = 0.155911 loss)
I1005 13:29:35.764354  9519 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1005 13:29:41.019966  9519 solver.cpp:218] Iteration 31600 (19.0273 iter/s, 5.25561s/100 iters), loss = 0.250152
I1005 13:29:41.019996  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250152 (* 1 = 0.250152 loss)
I1005 13:29:41.020004  9519 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1005 13:29:46.284626  9519 solver.cpp:218] Iteration 31700 (18.9948 iter/s, 5.26461s/100 iters), loss = 0.238764
I1005 13:29:46.284667  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238765 (* 1 = 0.238765 loss)
I1005 13:29:46.284673  9519 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1005 13:29:51.548559  9519 solver.cpp:218] Iteration 31800 (18.9974 iter/s, 5.26387s/100 iters), loss = 0.243484
I1005 13:29:51.548702  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243484 (* 1 = 0.243484 loss)
I1005 13:29:51.548746  9519 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1005 13:29:56.810029  9519 solver.cpp:218] Iteration 31900 (19.0066 iter/s, 5.26132s/100 iters), loss = 0.159359
I1005 13:29:56.810062  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159359 (* 1 = 0.159359 loss)
I1005 13:29:56.810081  9519 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1005 13:30:01.805115  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:30:02.015903  9519 solver.cpp:330] Iteration 32000, Testing net (#0)
I1005 13:30:03.211475  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:30:03.260980  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7646
I1005 13:30:03.261008  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.775715 (* 1 = 0.775715 loss)
I1005 13:30:03.313689  9519 solver.cpp:218] Iteration 32000 (15.3761 iter/s, 6.50361s/100 iters), loss = 0.198714
I1005 13:30:03.313716  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198714 (* 1 = 0.198714 loss)
I1005 13:30:03.313736  9519 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1005 13:30:08.566903  9519 solver.cpp:218] Iteration 32100 (19.0361 iter/s, 5.25317s/100 iters), loss = 0.324731
I1005 13:30:08.566944  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324732 (* 1 = 0.324732 loss)
I1005 13:30:08.566954  9519 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1005 13:30:13.807983  9519 solver.cpp:218] Iteration 32200 (19.0802 iter/s, 5.24103s/100 iters), loss = 0.248084
I1005 13:30:13.808020  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248084 (* 1 = 0.248084 loss)
I1005 13:30:13.808038  9519 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1005 13:30:19.067350  9519 solver.cpp:218] Iteration 32300 (19.0139 iter/s, 5.25932s/100 iters), loss = 0.217008
I1005 13:30:19.067381  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217008 (* 1 = 0.217008 loss)
I1005 13:30:19.067387  9519 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1005 13:30:24.326124  9519 solver.cpp:218] Iteration 32400 (19.016 iter/s, 5.25872s/100 iters), loss = 0.153179
I1005 13:30:24.326269  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153179 (* 1 = 0.153179 loss)
I1005 13:30:24.326277  9519 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1005 13:30:29.322037  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:30:29.538046  9519 solver.cpp:330] Iteration 32500, Testing net (#0)
I1005 13:30:30.728595  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:30:30.778095  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7384
I1005 13:30:30.778128  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.889069 (* 1 = 0.889069 loss)
I1005 13:30:30.830806  9519 solver.cpp:218] Iteration 32500 (15.3739 iter/s, 6.50453s/100 iters), loss = 0.195468
I1005 13:30:30.830835  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195468 (* 1 = 0.195468 loss)
I1005 13:30:30.830842  9519 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1005 13:30:36.097049  9519 solver.cpp:218] Iteration 32600 (18.989 iter/s, 5.2662s/100 iters), loss = 0.196477
I1005 13:30:36.097079  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196477 (* 1 = 0.196477 loss)
I1005 13:30:36.097085  9519 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1005 13:30:41.352694  9519 solver.cpp:218] Iteration 32700 (19.0273 iter/s, 5.25559s/100 iters), loss = 0.249371
I1005 13:30:41.352741  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249372 (* 1 = 0.249372 loss)
I1005 13:30:41.352748  9519 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1005 13:30:46.595634  9519 solver.cpp:218] Iteration 32800 (19.0735 iter/s, 5.24288s/100 iters), loss = 0.207756
I1005 13:30:46.595667  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207756 (* 1 = 0.207756 loss)
I1005 13:30:46.595685  9519 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1005 13:30:51.855325  9519 solver.cpp:218] Iteration 32900 (19.0127 iter/s, 5.25964s/100 iters), loss = 0.211929
I1005 13:30:51.855360  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211929 (* 1 = 0.211929 loss)
I1005 13:30:51.855378  9519 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1005 13:30:56.842980  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:30:57.051962  9519 solver.cpp:330] Iteration 33000, Testing net (#0)
I1005 13:30:58.239526  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:30:58.289517  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7724
I1005 13:30:58.289546  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.761455 (* 1 = 0.761455 loss)
I1005 13:30:58.341928  9519 solver.cpp:218] Iteration 33000 (15.4165 iter/s, 6.48655s/100 iters), loss = 0.201316
I1005 13:30:58.341964  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201316 (* 1 = 0.201316 loss)
I1005 13:30:58.341974  9519 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1005 13:31:03.600328  9519 solver.cpp:218] Iteration 33100 (19.0174 iter/s, 5.25835s/100 iters), loss = 0.252172
I1005 13:31:03.600361  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252172 (* 1 = 0.252172 loss)
I1005 13:31:03.600369  9519 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1005 13:31:08.862587  9519 solver.cpp:218] Iteration 33200 (19.0035 iter/s, 5.2622s/100 iters), loss = 0.196912
I1005 13:31:08.862622  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196912 (* 1 = 0.196912 loss)
I1005 13:31:08.862640  9519 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1005 13:31:14.120376  9519 solver.cpp:218] Iteration 33300 (19.0196 iter/s, 5.25774s/100 iters), loss = 0.229866
I1005 13:31:14.120411  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229866 (* 1 = 0.229866 loss)
I1005 13:31:14.120430  9519 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1005 13:31:19.381273  9519 solver.cpp:218] Iteration 33400 (19.0084 iter/s, 5.26085s/100 iters), loss = 0.196157
I1005 13:31:19.381306  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196158 (* 1 = 0.196158 loss)
I1005 13:31:19.381325  9519 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1005 13:31:24.388037  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:31:24.598827  9519 solver.cpp:330] Iteration 33500, Testing net (#0)
I1005 13:31:25.785518  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:31:25.835247  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7982
I1005 13:31:25.835274  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619549 (* 1 = 0.619549 loss)
I1005 13:31:25.887526  9519 solver.cpp:218] Iteration 33500 (15.3699 iter/s, 6.5062s/100 iters), loss = 0.188317
I1005 13:31:25.887562  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188317 (* 1 = 0.188317 loss)
I1005 13:31:25.887573  9519 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1005 13:31:31.154070  9519 solver.cpp:218] Iteration 33600 (18.988 iter/s, 5.26649s/100 iters), loss = 0.20817
I1005 13:31:31.154212  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20817 (* 1 = 0.20817 loss)
I1005 13:31:31.154223  9519 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1005 13:31:36.419057  9519 solver.cpp:218] Iteration 33700 (18.9939 iter/s, 5.26484s/100 iters), loss = 0.260185
I1005 13:31:36.419100  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260185 (* 1 = 0.260185 loss)
I1005 13:31:36.419106  9519 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1005 13:31:41.673378  9519 solver.cpp:218] Iteration 33800 (19.0322 iter/s, 5.25426s/100 iters), loss = 0.255155
I1005 13:31:41.673413  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255155 (* 1 = 0.255155 loss)
I1005 13:31:41.673421  9519 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1005 13:31:46.923689  9519 solver.cpp:218] Iteration 33900 (19.0468 iter/s, 5.25023s/100 iters), loss = 0.197165
I1005 13:31:46.923720  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197165 (* 1 = 0.197165 loss)
I1005 13:31:46.923737  9519 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1005 13:31:51.919847  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:31:52.129313  9519 solver.cpp:330] Iteration 34000, Testing net (#0)
I1005 13:31:53.316247  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:31:53.365803  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7925
I1005 13:31:53.365851  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.638868 (* 1 = 0.638868 loss)
I1005 13:31:53.419466  9519 solver.cpp:218] Iteration 34000 (15.3947 iter/s, 6.49573s/100 iters), loss = 0.227346
I1005 13:31:53.419502  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227346 (* 1 = 0.227346 loss)
I1005 13:31:53.419508  9519 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1005 13:31:58.679392  9519 solver.cpp:218] Iteration 34100 (19.0119 iter/s, 5.25987s/100 iters), loss = 0.240092
I1005 13:31:58.679425  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240092 (* 1 = 0.240092 loss)
I1005 13:31:58.679433  9519 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1005 13:32:03.948163  9519 solver.cpp:218] Iteration 34200 (18.9799 iter/s, 5.26872s/100 iters), loss = 0.287446
I1005 13:32:03.948298  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287446 (* 1 = 0.287446 loss)
I1005 13:32:03.948348  9519 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1005 13:32:09.216843  9519 solver.cpp:218] Iteration 34300 (18.9806 iter/s, 5.26854s/100 iters), loss = 0.183748
I1005 13:32:09.216876  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183748 (* 1 = 0.183748 loss)
I1005 13:32:09.216881  9519 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1005 13:32:14.466198  9519 solver.cpp:218] Iteration 34400 (19.0502 iter/s, 5.2493s/100 iters), loss = 0.214999
I1005 13:32:14.466250  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214999 (* 1 = 0.214999 loss)
I1005 13:32:14.466259  9519 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1005 13:32:19.466441  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:32:19.675366  9519 solver.cpp:330] Iteration 34500, Testing net (#0)
I1005 13:32:20.871865  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:32:20.921624  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7646
I1005 13:32:20.921660  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.820999 (* 1 = 0.820999 loss)
I1005 13:32:20.974093  9519 solver.cpp:218] Iteration 34500 (15.3662 iter/s, 6.5078s/100 iters), loss = 0.189584
I1005 13:32:20.974124  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189584 (* 1 = 0.189584 loss)
I1005 13:32:20.974131  9519 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1005 13:32:26.225369  9519 solver.cpp:218] Iteration 34600 (19.0432 iter/s, 5.25123s/100 iters), loss = 0.261776
I1005 13:32:26.225399  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261776 (* 1 = 0.261776 loss)
I1005 13:32:26.225405  9519 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1005 13:32:31.485417  9519 solver.cpp:218] Iteration 34700 (19.0114 iter/s, 5.26s/100 iters), loss = 0.266671
I1005 13:32:31.485457  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266671 (* 1 = 0.266671 loss)
I1005 13:32:31.485463  9519 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1005 13:32:36.747644  9519 solver.cpp:218] Iteration 34800 (19.0036 iter/s, 5.26217s/100 iters), loss = 0.168867
I1005 13:32:36.747776  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168867 (* 1 = 0.168867 loss)
I1005 13:32:36.747793  9519 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1005 13:32:42.006613  9519 solver.cpp:218] Iteration 34900 (19.0157 iter/s, 5.25882s/100 iters), loss = 0.243324
I1005 13:32:42.006657  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243324 (* 1 = 0.243324 loss)
I1005 13:32:42.006664  9519 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1005 13:32:47.007380  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:32:47.218019  9519 solver.cpp:330] Iteration 35000, Testing net (#0)
I1005 13:32:48.417071  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:32:48.466720  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.794
I1005 13:32:48.466756  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.647741 (* 1 = 0.647741 loss)
I1005 13:32:48.519155  9519 solver.cpp:218] Iteration 35000 (15.3551 iter/s, 6.51248s/100 iters), loss = 0.139618
I1005 13:32:48.519194  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139618 (* 1 = 0.139618 loss)
I1005 13:32:48.519201  9519 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1005 13:32:53.786363  9519 solver.cpp:218] Iteration 35100 (18.9856 iter/s, 5.26715s/100 iters), loss = 0.280683
I1005 13:32:53.786404  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280684 (* 1 = 0.280684 loss)
I1005 13:32:53.786411  9519 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1005 13:32:59.048017  9519 solver.cpp:218] Iteration 35200 (19.0057 iter/s, 5.26159s/100 iters), loss = 0.19689
I1005 13:32:59.048058  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19689 (* 1 = 0.19689 loss)
I1005 13:32:59.048064  9519 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1005 13:33:04.315064  9519 solver.cpp:218] Iteration 35300 (18.9862 iter/s, 5.26699s/100 iters), loss = 0.155654
I1005 13:33:04.315105  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155654 (* 1 = 0.155654 loss)
I1005 13:33:04.315111  9519 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1005 13:33:09.573604  9519 solver.cpp:218] Iteration 35400 (19.0169 iter/s, 5.25848s/100 iters), loss = 0.254217
I1005 13:33:09.573731  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254217 (* 1 = 0.254217 loss)
I1005 13:33:09.573751  9519 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1005 13:33:14.575670  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:33:14.788300  9519 solver.cpp:330] Iteration 35500, Testing net (#0)
I1005 13:33:15.976766  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:33:16.026561  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7689
I1005 13:33:16.026588  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.793415 (* 1 = 0.793415 loss)
I1005 13:33:16.078969  9519 solver.cpp:218] Iteration 35500 (15.3723 iter/s, 6.50523s/100 iters), loss = 0.281019
I1005 13:33:16.078999  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281019 (* 1 = 0.281019 loss)
I1005 13:33:16.079008  9519 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1005 13:33:21.342890  9519 solver.cpp:218] Iteration 35600 (18.9974 iter/s, 5.26387s/100 iters), loss = 0.185919
I1005 13:33:21.342922  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18592 (* 1 = 0.18592 loss)
I1005 13:33:21.342941  9519 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1005 13:33:26.605780  9519 solver.cpp:218] Iteration 35700 (19.0012 iter/s, 5.26284s/100 iters), loss = 0.257381
I1005 13:33:26.605818  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257381 (* 1 = 0.257381 loss)
I1005 13:33:26.605837  9519 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1005 13:33:31.862815  9519 solver.cpp:218] Iteration 35800 (19.0223 iter/s, 5.25698s/100 iters), loss = 0.234707
I1005 13:33:31.862848  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234707 (* 1 = 0.234707 loss)
I1005 13:33:31.862857  9519 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1005 13:33:37.124361  9519 solver.cpp:218] Iteration 35900 (19.006 iter/s, 5.2615s/100 iters), loss = 0.201006
I1005 13:33:37.124397  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201006 (* 1 = 0.201006 loss)
I1005 13:33:37.124415  9519 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1005 13:33:42.132238  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:33:42.341424  9519 solver.cpp:330] Iteration 36000, Testing net (#0)
I1005 13:33:43.525920  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:33:43.575511  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7365
I1005 13:33:43.575538  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.904183 (* 1 = 0.904183 loss)
I1005 13:33:43.628152  9519 solver.cpp:218] Iteration 36000 (15.3758 iter/s, 6.50374s/100 iters), loss = 0.221183
I1005 13:33:43.628181  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221183 (* 1 = 0.221183 loss)
I1005 13:33:43.628190  9519 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1005 13:33:48.899864  9519 solver.cpp:218] Iteration 36100 (18.9693 iter/s, 5.27167s/100 iters), loss = 0.221676
I1005 13:33:48.899899  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221676 (* 1 = 0.221676 loss)
I1005 13:33:48.899916  9519 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1005 13:33:54.169555  9519 solver.cpp:218] Iteration 36200 (18.9766 iter/s, 5.26964s/100 iters), loss = 0.142408
I1005 13:33:54.169589  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142408 (* 1 = 0.142408 loss)
I1005 13:33:54.169596  9519 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1005 13:33:59.425979  9519 solver.cpp:218] Iteration 36300 (19.0245 iter/s, 5.25637s/100 iters), loss = 0.269459
I1005 13:33:59.426029  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269459 (* 1 = 0.269459 loss)
I1005 13:33:59.426049  9519 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1005 13:34:04.687206  9519 solver.cpp:218] Iteration 36400 (19.0073 iter/s, 5.26112s/100 iters), loss = 0.200696
I1005 13:34:04.687240  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200696 (* 1 = 0.200696 loss)
I1005 13:34:04.687248  9519 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1005 13:34:09.689442  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:34:09.899729  9519 solver.cpp:330] Iteration 36500, Testing net (#0)
I1005 13:34:11.087855  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:34:11.137842  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7894
I1005 13:34:11.137871  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.702692 (* 1 = 0.702692 loss)
I1005 13:34:11.190240  9519 solver.cpp:218] Iteration 36500 (15.3775 iter/s, 6.50299s/100 iters), loss = 0.148718
I1005 13:34:11.190275  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148718 (* 1 = 0.148718 loss)
I1005 13:34:11.190284  9519 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1005 13:34:16.449245  9519 solver.cpp:218] Iteration 36600 (19.0152 iter/s, 5.25896s/100 iters), loss = 0.316824
I1005 13:34:16.449342  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316824 (* 1 = 0.316824 loss)
I1005 13:34:16.449358  9519 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1005 13:34:21.711683  9519 solver.cpp:218] Iteration 36700 (19.003 iter/s, 5.26233s/100 iters), loss = 0.218415
I1005 13:34:21.711711  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218415 (* 1 = 0.218415 loss)
I1005 13:34:21.711716  9519 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1005 13:34:26.980844  9519 solver.cpp:218] Iteration 36800 (18.9785 iter/s, 5.26911s/100 iters), loss = 0.248714
I1005 13:34:26.980875  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248714 (* 1 = 0.248714 loss)
I1005 13:34:26.980881  9519 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1005 13:34:32.219760  9519 solver.cpp:218] Iteration 36900 (19.0881 iter/s, 5.23886s/100 iters), loss = 0.167783
I1005 13:34:32.219799  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167783 (* 1 = 0.167783 loss)
I1005 13:34:32.219806  9519 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1005 13:34:37.225335  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:34:37.434128  9519 solver.cpp:330] Iteration 37000, Testing net (#0)
I1005 13:34:38.630029  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:34:38.680609  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8117
I1005 13:34:38.680655  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.573654 (* 1 = 0.573654 loss)
I1005 13:34:38.733814  9519 solver.cpp:218] Iteration 37000 (15.3515 iter/s, 6.514s/100 iters), loss = 0.328149
I1005 13:34:38.733846  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328149 (* 1 = 0.328149 loss)
I1005 13:34:38.733853  9519 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1005 13:34:43.989230  9519 solver.cpp:218] Iteration 37100 (19.0282 iter/s, 5.25537s/100 iters), loss = 0.293154
I1005 13:34:43.989262  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293154 (* 1 = 0.293154 loss)
I1005 13:34:43.989269  9519 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1005 13:34:49.255833  9519 solver.cpp:218] Iteration 37200 (18.9878 iter/s, 5.26655s/100 iters), loss = 0.218357
I1005 13:34:49.255945  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218357 (* 1 = 0.218357 loss)
I1005 13:34:49.255952  9519 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1005 13:34:54.514190  9519 solver.cpp:218] Iteration 37300 (19.0178 iter/s, 5.25824s/100 iters), loss = 0.257967
I1005 13:34:54.514230  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257967 (* 1 = 0.257967 loss)
I1005 13:34:54.514236  9519 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1005 13:34:59.766625  9519 solver.cpp:218] Iteration 37400 (19.039 iter/s, 5.25238s/100 iters), loss = 0.108369
I1005 13:34:59.766657  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108369 (* 1 = 0.108369 loss)
I1005 13:34:59.766664  9519 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1005 13:35:04.758780  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:35:04.968892  9519 solver.cpp:330] Iteration 37500, Testing net (#0)
I1005 13:35:06.160017  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:35:06.209692  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8159
I1005 13:35:06.209727  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.573151 (* 1 = 0.573151 loss)
I1005 13:35:06.262197  9519 solver.cpp:218] Iteration 37500 (15.3952 iter/s, 6.49552s/100 iters), loss = 0.176835
I1005 13:35:06.262223  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176836 (* 1 = 0.176836 loss)
I1005 13:35:06.262230  9519 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1005 13:35:11.519078  9519 solver.cpp:218] Iteration 37600 (19.0229 iter/s, 5.25683s/100 iters), loss = 0.268759
I1005 13:35:11.519117  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268759 (* 1 = 0.268759 loss)
I1005 13:35:11.519125  9519 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1005 13:35:16.787510  9519 solver.cpp:218] Iteration 37700 (18.9812 iter/s, 5.26838s/100 iters), loss = 0.219282
I1005 13:35:16.787551  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219282 (* 1 = 0.219282 loss)
I1005 13:35:16.787557  9519 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1005 13:35:22.051941  9519 solver.cpp:218] Iteration 37800 (18.9956 iter/s, 5.26437s/100 iters), loss = 0.296145
I1005 13:35:22.052057  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296145 (* 1 = 0.296145 loss)
I1005 13:35:22.052063  9519 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1005 13:35:27.314821  9519 solver.cpp:218] Iteration 37900 (19.0015 iter/s, 5.26276s/100 iters), loss = 0.223675
I1005 13:35:27.314851  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223675 (* 1 = 0.223675 loss)
I1005 13:35:27.314857  9519 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1005 13:35:32.307934  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:35:32.520467  9519 solver.cpp:330] Iteration 38000, Testing net (#0)
I1005 13:35:33.710011  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:35:33.759621  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7188
I1005 13:35:33.759655  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06075 (* 1 = 1.06075 loss)
I1005 13:35:33.812211  9519 solver.cpp:218] Iteration 38000 (15.3909 iter/s, 6.49734s/100 iters), loss = 0.143423
I1005 13:35:33.812243  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143423 (* 1 = 0.143423 loss)
I1005 13:35:33.812250  9519 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1005 13:35:39.075404  9519 solver.cpp:218] Iteration 38100 (19.0001 iter/s, 5.26314s/100 iters), loss = 0.202746
I1005 13:35:39.075433  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202746 (* 1 = 0.202746 loss)
I1005 13:35:39.075439  9519 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1005 13:35:44.331567  9519 solver.cpp:218] Iteration 38200 (19.0255 iter/s, 5.25612s/100 iters), loss = 0.171034
I1005 13:35:44.331598  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171034 (* 1 = 0.171034 loss)
I1005 13:35:44.331605  9519 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1005 13:35:49.596341  9519 solver.cpp:218] Iteration 38300 (18.9943 iter/s, 5.26473s/100 iters), loss = 0.16789
I1005 13:35:49.596382  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16789 (* 1 = 0.16789 loss)
I1005 13:35:49.596387  9519 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1005 13:35:54.854624  9519 solver.cpp:218] Iteration 38400 (19.0178 iter/s, 5.25822s/100 iters), loss = 0.148747
I1005 13:35:54.854755  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148747 (* 1 = 0.148747 loss)
I1005 13:35:54.854763  9519 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1005 13:35:59.861632  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:36:00.070868  9519 solver.cpp:330] Iteration 38500, Testing net (#0)
I1005 13:36:01.257635  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:36:01.307263  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7865
I1005 13:36:01.307288  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.643287 (* 1 = 0.643287 loss)
I1005 13:36:01.359632  9519 solver.cpp:218] Iteration 38500 (15.3731 iter/s, 6.50487s/100 iters), loss = 0.202152
I1005 13:36:01.359658  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202152 (* 1 = 0.202152 loss)
I1005 13:36:01.359666  9519 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1005 13:36:06.626857  9519 solver.cpp:218] Iteration 38600 (18.9855 iter/s, 5.26718s/100 iters), loss = 0.267984
I1005 13:36:06.626898  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267984 (* 1 = 0.267984 loss)
I1005 13:36:06.626904  9519 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1005 13:36:11.891577  9519 solver.cpp:218] Iteration 38700 (18.9946 iter/s, 5.26466s/100 iters), loss = 0.244795
I1005 13:36:11.891618  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244795 (* 1 = 0.244795 loss)
I1005 13:36:11.891625  9519 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1005 13:36:17.152168  9519 solver.cpp:218] Iteration 38800 (19.0095 iter/s, 5.26053s/100 iters), loss = 0.235808
I1005 13:36:17.152199  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235808 (* 1 = 0.235808 loss)
I1005 13:36:17.152205  9519 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1005 13:36:22.404544  9519 solver.cpp:218] Iteration 38900 (19.0392 iter/s, 5.25233s/100 iters), loss = 0.161762
I1005 13:36:22.404585  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161762 (* 1 = 0.161762 loss)
I1005 13:36:22.404592  9519 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1005 13:36:27.410987  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:36:27.621315  9519 solver.cpp:330] Iteration 39000, Testing net (#0)
I1005 13:36:28.808225  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:36:28.857700  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6149
I1005 13:36:28.857736  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.73362 (* 1 = 1.73362 loss)
I1005 13:36:28.909517  9519 solver.cpp:218] Iteration 39000 (15.373 iter/s, 6.50492s/100 iters), loss = 0.19637
I1005 13:36:28.909541  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19637 (* 1 = 0.19637 loss)
I1005 13:36:28.909548  9519 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1005 13:36:34.172768  9519 solver.cpp:218] Iteration 39100 (18.9998 iter/s, 5.26321s/100 iters), loss = 0.195864
I1005 13:36:34.172809  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195864 (* 1 = 0.195864 loss)
I1005 13:36:34.172816  9519 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1005 13:36:39.436337  9519 solver.cpp:218] Iteration 39200 (18.9987 iter/s, 5.26351s/100 iters), loss = 0.336405
I1005 13:36:39.436378  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336405 (* 1 = 0.336405 loss)
I1005 13:36:39.436383  9519 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1005 13:36:44.698056  9519 solver.cpp:218] Iteration 39300 (19.0054 iter/s, 5.26166s/100 iters), loss = 0.258886
I1005 13:36:44.698096  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258886 (* 1 = 0.258886 loss)
I1005 13:36:44.698117  9519 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1005 13:36:49.956388  9519 solver.cpp:218] Iteration 39400 (19.0178 iter/s, 5.25824s/100 iters), loss = 0.141507
I1005 13:36:49.956421  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141507 (* 1 = 0.141507 loss)
I1005 13:36:49.956439  9519 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1005 13:36:54.962949  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:36:55.173616  9519 solver.cpp:330] Iteration 39500, Testing net (#0)
I1005 13:36:56.359004  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:36:56.408562  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.805
I1005 13:36:56.408589  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.591636 (* 1 = 0.591636 loss)
I1005 13:36:56.462208  9519 solver.cpp:218] Iteration 39500 (15.371 iter/s, 6.50576s/100 iters), loss = 0.268225
I1005 13:36:56.462285  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268225 (* 1 = 0.268225 loss)
I1005 13:36:56.462296  9519 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1005 13:37:01.723971  9519 solver.cpp:218] Iteration 39600 (19.0054 iter/s, 5.26166s/100 iters), loss = 0.242794
I1005 13:37:01.724093  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242794 (* 1 = 0.242794 loss)
I1005 13:37:01.724112  9519 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1005 13:37:06.991044  9519 solver.cpp:218] Iteration 39700 (18.9863 iter/s, 5.26694s/100 iters), loss = 0.193632
I1005 13:37:06.991077  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193632 (* 1 = 0.193632 loss)
I1005 13:37:06.991096  9519 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1005 13:37:12.258846  9519 solver.cpp:218] Iteration 39800 (18.9834 iter/s, 5.26775s/100 iters), loss = 0.230228
I1005 13:37:12.258880  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230228 (* 1 = 0.230228 loss)
I1005 13:37:12.258903  9519 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1005 13:37:17.509447  9519 solver.cpp:218] Iteration 39900 (19.0456 iter/s, 5.25055s/100 iters), loss = 0.101396
I1005 13:37:17.509490  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101396 (* 1 = 0.101396 loss)
I1005 13:37:17.509510  9519 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1005 13:37:22.505949  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:37:22.716526  9519 solver.cpp:330] Iteration 40000, Testing net (#0)
I1005 13:37:23.910917  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:37:23.960662  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7037
I1005 13:37:23.960690  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05301 (* 1 = 1.05301 loss)
I1005 13:37:24.013222  9519 solver.cpp:218] Iteration 40000 (15.3761 iter/s, 6.50362s/100 iters), loss = 0.151761
I1005 13:37:24.013257  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151761 (* 1 = 0.151761 loss)
I1005 13:37:24.013267  9519 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1005 13:37:24.013270  9519 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1005 13:37:29.264370  9519 solver.cpp:218] Iteration 40100 (19.0436 iter/s, 5.2511s/100 iters), loss = 0.136795
I1005 13:37:29.264405  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136795 (* 1 = 0.136795 loss)
I1005 13:37:29.264423  9519 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1005 13:37:34.524507  9519 solver.cpp:218] Iteration 40200 (19.0111 iter/s, 5.26009s/100 iters), loss = 0.166878
I1005 13:37:34.524693  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166878 (* 1 = 0.166878 loss)
I1005 13:37:34.524704  9519 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1005 13:37:39.795264  9519 solver.cpp:218] Iteration 40300 (18.9733 iter/s, 5.27056s/100 iters), loss = 0.17788
I1005 13:37:39.795295  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17788 (* 1 = 0.17788 loss)
I1005 13:37:39.795300  9519 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1005 13:37:45.057149  9519 solver.cpp:218] Iteration 40400 (19.0048 iter/s, 5.26184s/100 iters), loss = 0.157053
I1005 13:37:45.057181  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157053 (* 1 = 0.157053 loss)
I1005 13:37:45.057188  9519 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1005 13:37:50.049762  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:37:50.260594  9519 solver.cpp:330] Iteration 40500, Testing net (#0)
I1005 13:37:51.456993  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:37:51.506628  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8951
I1005 13:37:51.506664  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30538 (* 1 = 0.30538 loss)
I1005 13:37:51.559141  9519 solver.cpp:218] Iteration 40500 (15.38 iter/s, 6.50195s/100 iters), loss = 0.137803
I1005 13:37:51.559168  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137803 (* 1 = 0.137803 loss)
I1005 13:37:51.559175  9519 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1005 13:37:56.826293  9519 solver.cpp:218] Iteration 40600 (18.9858 iter/s, 5.2671s/100 iters), loss = 0.167349
I1005 13:37:56.826324  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167349 (* 1 = 0.167349 loss)
I1005 13:37:56.826331  9519 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1005 13:38:02.084686  9519 solver.cpp:218] Iteration 40700 (19.0174 iter/s, 5.25834s/100 iters), loss = 0.0741209
I1005 13:38:02.084717  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0741211 (* 1 = 0.0741211 loss)
I1005 13:38:02.084724  9519 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1005 13:38:07.349095  9519 solver.cpp:218] Iteration 40800 (18.9957 iter/s, 5.26436s/100 iters), loss = 0.140572
I1005 13:38:07.349254  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140572 (* 1 = 0.140572 loss)
I1005 13:38:07.349262  9519 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1005 13:38:12.613762  9519 solver.cpp:218] Iteration 40900 (18.9952 iter/s, 5.26449s/100 iters), loss = 0.117619
I1005 13:38:12.613802  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117619 (* 1 = 0.117619 loss)
I1005 13:38:12.613808  9519 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1005 13:38:17.613322  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:38:17.826077  9519 solver.cpp:330] Iteration 41000, Testing net (#0)
I1005 13:38:19.010406  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:38:19.059924  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8978
I1005 13:38:19.059958  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298591 (* 1 = 0.298591 loss)
I1005 13:38:19.112071  9519 solver.cpp:218] Iteration 41000 (15.3888 iter/s, 6.49825s/100 iters), loss = 0.0652224
I1005 13:38:19.112098  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0652226 (* 1 = 0.0652226 loss)
I1005 13:38:19.112105  9519 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1005 13:38:24.377485  9519 solver.cpp:218] Iteration 41100 (18.992 iter/s, 5.26537s/100 iters), loss = 0.128358
I1005 13:38:24.377516  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128358 (* 1 = 0.128358 loss)
I1005 13:38:24.377521  9519 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1005 13:38:29.641927  9519 solver.cpp:218] Iteration 41200 (18.9956 iter/s, 5.26439s/100 iters), loss = 0.0588989
I1005 13:38:29.641963  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.058899 (* 1 = 0.058899 loss)
I1005 13:38:29.641970  9519 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1005 13:38:34.905283  9519 solver.cpp:218] Iteration 41300 (18.9995 iter/s, 5.2633s/100 iters), loss = 0.123851
I1005 13:38:34.905315  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123851 (* 1 = 0.123851 loss)
I1005 13:38:34.905321  9519 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1005 13:38:40.169816  9519 solver.cpp:218] Iteration 41400 (18.9952 iter/s, 5.26449s/100 iters), loss = 0.0832386
I1005 13:38:40.169951  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0832388 (* 1 = 0.0832388 loss)
I1005 13:38:40.169970  9519 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1005 13:38:45.180518  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:38:45.390583  9519 solver.cpp:330] Iteration 41500, Testing net (#0)
I1005 13:38:46.577394  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:38:46.627075  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I1005 13:38:46.627110  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292657 (* 1 = 0.292657 loss)
I1005 13:38:46.679721  9519 solver.cpp:218] Iteration 41500 (15.3615 iter/s, 6.50977s/100 iters), loss = 0.0872602
I1005 13:38:46.679761  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0872604 (* 1 = 0.0872604 loss)
I1005 13:38:46.679769  9519 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1005 13:38:51.942580  9519 solver.cpp:218] Iteration 41600 (19.0012 iter/s, 5.26281s/100 iters), loss = 0.119777
I1005 13:38:51.942610  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119777 (* 1 = 0.119777 loss)
I1005 13:38:51.942616  9519 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1005 13:38:57.205050  9519 solver.cpp:218] Iteration 41700 (19.0026 iter/s, 5.26242s/100 iters), loss = 0.184292
I1005 13:38:57.205091  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184292 (* 1 = 0.184292 loss)
I1005 13:38:57.205097  9519 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1005 13:39:02.459895  9519 solver.cpp:218] Iteration 41800 (19.0303 iter/s, 5.25479s/100 iters), loss = 0.0543281
I1005 13:39:02.459928  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0543283 (* 1 = 0.0543283 loss)
I1005 13:39:02.459935  9519 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1005 13:39:07.718698  9519 solver.cpp:218] Iteration 41900 (19.0159 iter/s, 5.25875s/100 iters), loss = 0.0716643
I1005 13:39:07.718727  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716644 (* 1 = 0.0716644 loss)
I1005 13:39:07.718734  9519 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1005 13:39:12.730177  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:39:12.938843  9519 solver.cpp:330] Iteration 42000, Testing net (#0)
I1005 13:39:14.126852  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:39:14.176357  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1005 13:39:14.176383  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297068 (* 1 = 0.297068 loss)
I1005 13:39:14.228559  9519 solver.cpp:218] Iteration 42000 (15.3614 iter/s, 6.50981s/100 iters), loss = 0.113488
I1005 13:39:14.228592  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113488 (* 1 = 0.113488 loss)
I1005 13:39:14.228600  9519 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1005 13:39:19.494189  9519 solver.cpp:218] Iteration 42100 (18.9913 iter/s, 5.26558s/100 iters), loss = 0.133005
I1005 13:39:19.494232  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133006 (* 1 = 0.133006 loss)
I1005 13:39:19.494238  9519 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1005 13:39:24.757135  9519 solver.cpp:218] Iteration 42200 (19.001 iter/s, 5.26288s/100 iters), loss = 0.0911067
I1005 13:39:24.757165  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0911068 (* 1 = 0.0911068 loss)
I1005 13:39:24.757171  9519 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1005 13:39:30.021749  9519 solver.cpp:218] Iteration 42300 (18.9949 iter/s, 5.26456s/100 iters), loss = 0.0861248
I1005 13:39:30.021780  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.086125 (* 1 = 0.086125 loss)
I1005 13:39:30.021786  9519 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1005 13:39:35.272681  9519 solver.cpp:218] Iteration 42400 (19.0444 iter/s, 5.25088s/100 iters), loss = 0.0446555
I1005 13:39:35.272723  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446557 (* 1 = 0.0446557 loss)
I1005 13:39:35.272729  9519 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1005 13:39:40.276690  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:39:40.486452  9519 solver.cpp:330] Iteration 42500, Testing net (#0)
I1005 13:39:41.677490  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:39:41.727705  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1005 13:39:41.727733  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291974 (* 1 = 0.291974 loss)
I1005 13:39:41.780501  9519 solver.cpp:218] Iteration 42500 (15.3663 iter/s, 6.50776s/100 iters), loss = 0.0956701
I1005 13:39:41.780541  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0956703 (* 1 = 0.0956703 loss)
I1005 13:39:41.780551  9519 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1005 13:39:47.037171  9519 solver.cpp:218] Iteration 42600 (19.0236 iter/s, 5.25662s/100 iters), loss = 0.0946365
I1005 13:39:47.037326  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0946367 (* 1 = 0.0946367 loss)
I1005 13:39:47.037339  9519 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1005 13:39:52.301265  9519 solver.cpp:218] Iteration 42700 (18.9972 iter/s, 5.26394s/100 iters), loss = 0.133635
I1005 13:39:52.301300  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133635 (* 1 = 0.133635 loss)
I1005 13:39:52.301318  9519 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1005 13:39:57.562707  9519 solver.cpp:218] Iteration 42800 (19.0064 iter/s, 5.26139s/100 iters), loss = 0.101758
I1005 13:39:57.562739  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101758 (* 1 = 0.101758 loss)
I1005 13:39:57.562746  9519 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1005 13:40:02.824900  9519 solver.cpp:218] Iteration 42900 (19.0037 iter/s, 5.26214s/100 iters), loss = 0.0522176
I1005 13:40:02.824931  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0522178 (* 1 = 0.0522178 loss)
I1005 13:40:02.824937  9519 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1005 13:40:07.814429  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:40:08.023351  9519 solver.cpp:330] Iteration 43000, Testing net (#0)
I1005 13:40:09.219154  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:40:09.268909  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1005 13:40:09.268934  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28708 (* 1 = 0.28708 loss)
I1005 13:40:09.321087  9519 solver.cpp:218] Iteration 43000 (15.3938 iter/s, 6.49614s/100 iters), loss = 0.0400816
I1005 13:40:09.321116  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400818 (* 1 = 0.0400818 loss)
I1005 13:40:09.321123  9519 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1005 13:40:14.576196  9519 solver.cpp:218] Iteration 43100 (19.0293 iter/s, 5.25506s/100 iters), loss = 0.0990858
I1005 13:40:14.576243  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0990861 (* 1 = 0.0990861 loss)
I1005 13:40:14.576251  9519 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1005 13:40:19.837218  9519 solver.cpp:218] Iteration 43200 (19.0081 iter/s, 5.26092s/100 iters), loss = 0.145093
I1005 13:40:19.837373  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145093 (* 1 = 0.145093 loss)
I1005 13:40:19.837379  9519 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1005 13:40:25.103513  9519 solver.cpp:218] Iteration 43300 (18.9893 iter/s, 5.26613s/100 iters), loss = 0.0485459
I1005 13:40:25.103548  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485461 (* 1 = 0.0485461 loss)
I1005 13:40:25.103556  9519 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1005 13:40:30.358785  9519 solver.cpp:218] Iteration 43400 (19.0287 iter/s, 5.25522s/100 iters), loss = 0.0560067
I1005 13:40:30.358819  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560069 (* 1 = 0.0560069 loss)
I1005 13:40:30.358827  9519 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1005 13:40:35.346801  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:40:35.559917  9519 solver.cpp:330] Iteration 43500, Testing net (#0)
I1005 13:40:36.749014  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:40:36.798746  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1005 13:40:36.798784  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308293 (* 1 = 0.308293 loss)
I1005 13:40:36.851318  9519 solver.cpp:218] Iteration 43500 (15.4024 iter/s, 6.49249s/100 iters), loss = 0.0550276
I1005 13:40:36.851346  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550278 (* 1 = 0.0550278 loss)
I1005 13:40:36.851352  9519 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1005 13:40:42.114370  9519 solver.cpp:218] Iteration 43600 (19.0006 iter/s, 5.263s/100 iters), loss = 0.141439
I1005 13:40:42.114401  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141439 (* 1 = 0.141439 loss)
I1005 13:40:42.114408  9519 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1005 13:40:47.374650  9519 solver.cpp:218] Iteration 43700 (19.0106 iter/s, 5.26023s/100 iters), loss = 0.114143
I1005 13:40:47.374691  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114143 (* 1 = 0.114143 loss)
I1005 13:40:47.374697  9519 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1005 13:40:52.643405  9519 solver.cpp:218] Iteration 43800 (18.98 iter/s, 5.2687s/100 iters), loss = 0.13692
I1005 13:40:52.643551  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13692 (* 1 = 0.13692 loss)
I1005 13:40:52.643559  9519 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1005 13:40:57.910398  9519 solver.cpp:218] Iteration 43900 (18.9867 iter/s, 5.26684s/100 iters), loss = 0.0861772
I1005 13:40:57.910439  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0861775 (* 1 = 0.0861775 loss)
I1005 13:40:57.910445  9519 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1005 13:41:02.921452  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:41:03.131507  9519 solver.cpp:330] Iteration 44000, Testing net (#0)
I1005 13:41:04.319221  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:41:04.369086  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I1005 13:41:04.369122  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302203 (* 1 = 0.302203 loss)
I1005 13:41:04.421420  9519 solver.cpp:218] Iteration 44000 (15.3587 iter/s, 6.51097s/100 iters), loss = 0.106653
I1005 13:41:04.421454  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106653 (* 1 = 0.106653 loss)
I1005 13:41:04.421461  9519 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1005 13:41:09.689287  9519 solver.cpp:218] Iteration 44100 (18.9832 iter/s, 5.26782s/100 iters), loss = 0.166905
I1005 13:41:09.689338  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166905 (* 1 = 0.166905 loss)
I1005 13:41:09.689345  9519 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1005 13:41:14.956775  9519 solver.cpp:218] Iteration 44200 (18.9846 iter/s, 5.26743s/100 iters), loss = 0.104907
I1005 13:41:14.956806  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104907 (* 1 = 0.104907 loss)
I1005 13:41:14.956823  9519 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1005 13:41:20.214920  9519 solver.cpp:218] Iteration 44300 (19.0183 iter/s, 5.2581s/100 iters), loss = 0.0551554
I1005 13:41:20.214951  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0551557 (* 1 = 0.0551557 loss)
I1005 13:41:20.214968  9519 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1005 13:41:25.470481  9519 solver.cpp:218] Iteration 44400 (19.0276 iter/s, 5.25551s/100 iters), loss = 0.0377237
I1005 13:41:25.470624  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037724 (* 1 = 0.037724 loss)
I1005 13:41:25.470643  9519 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1005 13:41:30.470970  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:41:30.681145  9519 solver.cpp:330] Iteration 44500, Testing net (#0)
I1005 13:41:31.868048  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:41:31.917932  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I1005 13:41:31.917955  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310405 (* 1 = 0.310405 loss)
I1005 13:41:31.970026  9519 solver.cpp:218] Iteration 44500 (15.386 iter/s, 6.4994s/100 iters), loss = 0.0986082
I1005 13:41:31.970057  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0986085 (* 1 = 0.0986085 loss)
I1005 13:41:31.970063  9519 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1005 13:41:37.233141  9519 solver.cpp:218] Iteration 44600 (19.0003 iter/s, 5.26307s/100 iters), loss = 0.10411
I1005 13:41:37.233182  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10411 (* 1 = 0.10411 loss)
I1005 13:41:37.233188  9519 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1005 13:41:42.498947  9519 solver.cpp:218] Iteration 44700 (18.9907 iter/s, 5.26575s/100 iters), loss = 0.0834969
I1005 13:41:42.498980  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0834972 (* 1 = 0.0834972 loss)
I1005 13:41:42.498986  9519 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1005 13:41:47.762248  9519 solver.cpp:218] Iteration 44800 (18.9997 iter/s, 5.26325s/100 iters), loss = 0.0760259
I1005 13:41:47.762286  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0760262 (* 1 = 0.0760262 loss)
I1005 13:41:47.762306  9519 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1005 13:41:53.015424  9519 solver.cpp:218] Iteration 44900 (19.0363 iter/s, 5.25312s/100 iters), loss = 0.0217498
I1005 13:41:53.015458  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217501 (* 1 = 0.0217501 loss)
I1005 13:41:53.015466  9519 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1005 13:41:58.023718  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:41:58.233604  9519 solver.cpp:330] Iteration 45000, Testing net (#0)
I1005 13:41:59.420951  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:41:59.471277  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9063
I1005 13:41:59.471328  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295509 (* 1 = 0.295509 loss)
I1005 13:41:59.524433  9519 solver.cpp:218] Iteration 45000 (15.3634 iter/s, 6.50896s/100 iters), loss = 0.0727465
I1005 13:41:59.524482  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0727468 (* 1 = 0.0727468 loss)
I1005 13:41:59.524489  9519 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1005 13:42:04.787626  9519 solver.cpp:218] Iteration 45100 (19.0002 iter/s, 5.26309s/100 iters), loss = 0.0513266
I1005 13:42:04.787657  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513269 (* 1 = 0.0513269 loss)
I1005 13:42:04.787662  9519 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1005 13:42:10.055388  9519 solver.cpp:218] Iteration 45200 (18.9836 iter/s, 5.26771s/100 iters), loss = 0.0643789
I1005 13:42:10.055418  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0643791 (* 1 = 0.0643791 loss)
I1005 13:42:10.055424  9519 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1005 13:42:15.318142  9519 solver.cpp:218] Iteration 45300 (19.0016 iter/s, 5.26271s/100 iters), loss = 0.0780502
I1005 13:42:15.318186  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0780504 (* 1 = 0.0780504 loss)
I1005 13:42:15.318192  9519 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1005 13:42:20.569072  9519 solver.cpp:218] Iteration 45400 (19.0445 iter/s, 5.25087s/100 iters), loss = 0.0813318
I1005 13:42:20.569114  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0813321 (* 1 = 0.0813321 loss)
I1005 13:42:20.569123  9519 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1005 13:42:25.567049  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:42:25.777382  9519 solver.cpp:330] Iteration 45500, Testing net (#0)
I1005 13:42:26.973600  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:42:27.023401  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9059
I1005 13:42:27.023427  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305258 (* 1 = 0.305258 loss)
I1005 13:42:27.075675  9519 solver.cpp:218] Iteration 45500 (15.3691 iter/s, 6.50654s/100 iters), loss = 0.038629
I1005 13:42:27.075702  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386292 (* 1 = 0.0386292 loss)
I1005 13:42:27.075709  9519 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1005 13:42:32.332173  9519 solver.cpp:218] Iteration 45600 (19.0243 iter/s, 5.25645s/100 iters), loss = 0.0838385
I1005 13:42:32.332293  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0838387 (* 1 = 0.0838387 loss)
I1005 13:42:32.332301  9519 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1005 13:42:37.598134  9519 solver.cpp:218] Iteration 45700 (18.9904 iter/s, 5.26582s/100 iters), loss = 0.099233
I1005 13:42:37.598165  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0992332 (* 1 = 0.0992332 loss)
I1005 13:42:37.598170  9519 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1005 13:42:42.866734  9519 solver.cpp:218] Iteration 45800 (18.9805 iter/s, 5.26855s/100 iters), loss = 0.0863813
I1005 13:42:42.866775  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0863815 (* 1 = 0.0863815 loss)
I1005 13:42:42.866781  9519 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1005 13:42:48.132606  9519 solver.cpp:218] Iteration 45900 (18.9904 iter/s, 5.26581s/100 iters), loss = 0.0860813
I1005 13:42:48.132647  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0860816 (* 1 = 0.0860816 loss)
I1005 13:42:48.132654  9519 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1005 13:42:53.124392  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:42:53.335333  9519 solver.cpp:330] Iteration 46000, Testing net (#0)
I1005 13:42:54.528532  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:42:54.578146  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8979
I1005 13:42:54.578181  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341548 (* 1 = 0.341548 loss)
I1005 13:42:54.630597  9519 solver.cpp:218] Iteration 46000 (15.3895 iter/s, 6.49793s/100 iters), loss = 0.0785837
I1005 13:42:54.630622  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0785839 (* 1 = 0.0785839 loss)
I1005 13:42:54.630630  9519 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1005 13:42:59.897471  9519 solver.cpp:218] Iteration 46100 (18.9868 iter/s, 5.26683s/100 iters), loss = 0.124878
I1005 13:42:59.897501  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124878 (* 1 = 0.124878 loss)
I1005 13:42:59.897507  9519 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1005 13:43:05.152396  9519 solver.cpp:218] Iteration 46200 (19.0299 iter/s, 5.25488s/100 iters), loss = 0.0948909
I1005 13:43:05.152506  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0948911 (* 1 = 0.0948911 loss)
I1005 13:43:05.152514  9519 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1005 13:43:10.416699  9519 solver.cpp:218] Iteration 46300 (18.9963 iter/s, 5.26418s/100 iters), loss = 0.0470461
I1005 13:43:10.416740  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0470464 (* 1 = 0.0470464 loss)
I1005 13:43:10.416746  9519 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1005 13:43:15.678809  9519 solver.cpp:218] Iteration 46400 (19.004 iter/s, 5.26205s/100 iters), loss = 0.0422473
I1005 13:43:15.678840  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422476 (* 1 = 0.0422476 loss)
I1005 13:43:15.678846  9519 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1005 13:43:20.678570  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:43:20.889627  9519 solver.cpp:330] Iteration 46500, Testing net (#0)
I1005 13:43:22.075690  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:43:22.125484  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9021
I1005 13:43:22.125510  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328413 (* 1 = 0.328413 loss)
I1005 13:43:22.177814  9519 solver.cpp:218] Iteration 46500 (15.3871 iter/s, 6.49896s/100 iters), loss = 0.0589123
I1005 13:43:22.177844  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589126 (* 1 = 0.0589126 loss)
I1005 13:43:22.177850  9519 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1005 13:43:27.439157  9519 solver.cpp:218] Iteration 46600 (19.0067 iter/s, 5.2613s/100 iters), loss = 0.0377086
I1005 13:43:27.439188  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377088 (* 1 = 0.0377088 loss)
I1005 13:43:27.439193  9519 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1005 13:43:32.704969  9519 solver.cpp:218] Iteration 46700 (18.9906 iter/s, 5.26576s/100 iters), loss = 0.0425847
I1005 13:43:32.705009  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042585 (* 1 = 0.042585 loss)
I1005 13:43:32.705018  9519 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1005 13:43:37.964759  9519 solver.cpp:218] Iteration 46800 (19.0125 iter/s, 5.2597s/100 iters), loss = 0.0618653
I1005 13:43:37.964875  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618655 (* 1 = 0.0618655 loss)
I1005 13:43:37.964882  9519 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1005 13:43:43.224685  9519 solver.cpp:218] Iteration 46900 (19.0121 iter/s, 5.2598s/100 iters), loss = 0.0414749
I1005 13:43:43.224715  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414751 (* 1 = 0.0414751 loss)
I1005 13:43:43.224721  9519 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1005 13:43:48.227658  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:43:48.437474  9519 solver.cpp:330] Iteration 47000, Testing net (#0)
I1005 13:43:49.625329  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:43:49.675019  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9008
I1005 13:43:49.675043  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326798 (* 1 = 0.326798 loss)
I1005 13:43:49.727766  9519 solver.cpp:218] Iteration 47000 (15.3774 iter/s, 6.50304s/100 iters), loss = 0.115845
I1005 13:43:49.727794  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115845 (* 1 = 0.115845 loss)
I1005 13:43:49.727802  9519 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1005 13:43:54.992455  9519 solver.cpp:218] Iteration 47100 (18.9946 iter/s, 5.26464s/100 iters), loss = 0.0558347
I1005 13:43:54.992486  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558349 (* 1 = 0.0558349 loss)
I1005 13:43:54.992491  9519 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1005 13:44:00.259872  9519 solver.cpp:218] Iteration 47200 (18.9848 iter/s, 5.26736s/100 iters), loss = 0.0948167
I1005 13:44:00.259902  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0948169 (* 1 = 0.0948169 loss)
I1005 13:44:00.259918  9519 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1005 13:44:05.512353  9519 solver.cpp:218] Iteration 47300 (19.0388 iter/s, 5.25243s/100 iters), loss = 0.0469538
I1005 13:44:05.512409  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469541 (* 1 = 0.0469541 loss)
I1005 13:44:05.512426  9519 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1005 13:44:10.771077  9519 solver.cpp:218] Iteration 47400 (19.0164 iter/s, 5.25862s/100 iters), loss = 0.0564493
I1005 13:44:10.771204  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0564496 (* 1 = 0.0564496 loss)
I1005 13:44:10.771214  9519 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1005 13:44:15.778820  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:44:15.989058  9519 solver.cpp:330] Iteration 47500, Testing net (#0)
I1005 13:44:17.174902  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:44:17.224582  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8974
I1005 13:44:17.224611  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348574 (* 1 = 0.348574 loss)
I1005 13:44:17.276856  9519 solver.cpp:218] Iteration 47500 (15.3713 iter/s, 6.50564s/100 iters), loss = 0.0238863
I1005 13:44:17.276885  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238866 (* 1 = 0.0238866 loss)
I1005 13:44:17.276892  9519 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1005 13:44:22.546936  9519 solver.cpp:218] Iteration 47600 (18.9752 iter/s, 5.27003s/100 iters), loss = 0.037118
I1005 13:44:22.546970  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371183 (* 1 = 0.0371183 loss)
I1005 13:44:22.546979  9519 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1005 13:44:27.814564  9519 solver.cpp:218] Iteration 47700 (18.9841 iter/s, 5.26758s/100 iters), loss = 0.0777268
I1005 13:44:27.814599  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.077727 (* 1 = 0.077727 loss)
I1005 13:44:27.814606  9519 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1005 13:44:33.081373  9519 solver.cpp:218] Iteration 47800 (18.987 iter/s, 5.26676s/100 iters), loss = 0.0321015
I1005 13:44:33.081408  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321018 (* 1 = 0.0321018 loss)
I1005 13:44:33.081431  9519 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1005 13:44:38.336944  9519 solver.cpp:218] Iteration 47900 (19.0276 iter/s, 5.25552s/100 iters), loss = 0.0193567
I1005 13:44:38.336977  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019357 (* 1 = 0.019357 loss)
I1005 13:44:38.336985  9519 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1005 13:44:43.343652  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:44:43.554247  9519 solver.cpp:330] Iteration 48000, Testing net (#0)
I1005 13:44:44.749069  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:44:44.798773  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9036
I1005 13:44:44.798800  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326097 (* 1 = 0.326097 loss)
I1005 13:44:44.851430  9519 solver.cpp:218] Iteration 48000 (15.3505 iter/s, 6.51444s/100 iters), loss = 0.0414237
I1005 13:44:44.851466  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041424 (* 1 = 0.041424 loss)
I1005 13:44:44.851475  9519 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1005 13:44:50.104005  9519 solver.cpp:218] Iteration 48100 (19.0385 iter/s, 5.25252s/100 iters), loss = 0.0681486
I1005 13:44:50.104048  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0681488 (* 1 = 0.0681488 loss)
I1005 13:44:50.104053  9519 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1005 13:44:55.366722  9519 solver.cpp:218] Iteration 48200 (19.0018 iter/s, 5.26266s/100 iters), loss = 0.0479758
I1005 13:44:55.366770  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047976 (* 1 = 0.047976 loss)
I1005 13:44:55.366777  9519 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1005 13:45:00.631361  9519 solver.cpp:218] Iteration 48300 (18.9949 iter/s, 5.26458s/100 iters), loss = 0.047963
I1005 13:45:00.631392  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479632 (* 1 = 0.0479632 loss)
I1005 13:45:00.631398  9519 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1005 13:45:05.890667  9519 solver.cpp:218] Iteration 48400 (19.0141 iter/s, 5.25926s/100 iters), loss = 0.0509601
I1005 13:45:05.890708  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0509603 (* 1 = 0.0509603 loss)
I1005 13:45:05.890715  9519 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1005 13:45:10.885951  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:45:11.096280  9519 solver.cpp:330] Iteration 48500, Testing net (#0)
I1005 13:45:12.292531  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:45:12.342043  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908
I1005 13:45:12.342078  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307581 (* 1 = 0.307581 loss)
I1005 13:45:12.394328  9519 solver.cpp:218] Iteration 48500 (15.3761 iter/s, 6.5036s/100 iters), loss = 0.086161
I1005 13:45:12.394361  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0861612 (* 1 = 0.0861612 loss)
I1005 13:45:12.394367  9519 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1005 13:45:17.654886  9519 solver.cpp:218] Iteration 48600 (19.0096 iter/s, 5.26051s/100 iters), loss = 0.0675831
I1005 13:45:17.655025  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0675834 (* 1 = 0.0675834 loss)
I1005 13:45:17.655033  9519 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1005 13:45:22.906090  9519 solver.cpp:218] Iteration 48700 (19.0439 iter/s, 5.25103s/100 iters), loss = 0.0144737
I1005 13:45:22.906122  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144739 (* 1 = 0.0144739 loss)
I1005 13:45:22.906137  9519 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1005 13:45:28.164239  9519 solver.cpp:218] Iteration 48800 (19.0183 iter/s, 5.2581s/100 iters), loss = 0.0690622
I1005 13:45:28.164276  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0690625 (* 1 = 0.0690625 loss)
I1005 13:45:28.164294  9519 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1005 13:45:33.419754  9519 solver.cpp:218] Iteration 48900 (19.0278 iter/s, 5.25546s/100 iters), loss = 0.0102668
I1005 13:45:33.419787  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102671 (* 1 = 0.0102671 loss)
I1005 13:45:33.419795  9519 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1005 13:45:38.409308  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:45:38.625082  9519 solver.cpp:330] Iteration 49000, Testing net (#0)
I1005 13:45:39.817107  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:45:39.866879  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8973
I1005 13:45:39.866904  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347374 (* 1 = 0.347374 loss)
I1005 13:45:39.919443  9519 solver.cpp:218] Iteration 49000 (15.3855 iter/s, 6.49964s/100 iters), loss = 0.0543982
I1005 13:45:39.919468  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0543985 (* 1 = 0.0543985 loss)
I1005 13:45:39.919476  9519 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1005 13:45:45.187120  9519 solver.cpp:218] Iteration 49100 (18.9839 iter/s, 5.26763s/100 iters), loss = 0.0404465
I1005 13:45:45.187162  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404468 (* 1 = 0.0404468 loss)
I1005 13:45:45.187168  9519 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1005 13:45:50.444336  9519 solver.cpp:218] Iteration 49200 (19.0217 iter/s, 5.25716s/100 iters), loss = 0.0346071
I1005 13:45:50.444516  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346073 (* 1 = 0.0346073 loss)
I1005 13:45:50.444543  9519 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1005 13:45:55.701355  9519 solver.cpp:218] Iteration 49300 (19.0229 iter/s, 5.25684s/100 iters), loss = 0.106885
I1005 13:45:55.701386  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106885 (* 1 = 0.106885 loss)
I1005 13:45:55.701393  9519 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1005 13:46:00.967308  9519 solver.cpp:218] Iteration 49400 (18.9901 iter/s, 5.26589s/100 iters), loss = 0.0360858
I1005 13:46:00.967370  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036086 (* 1 = 0.036086 loss)
I1005 13:46:00.967375  9519 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1005 13:46:05.973897  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:46:06.184847  9519 solver.cpp:330] Iteration 49500, Testing net (#0)
I1005 13:46:07.369829  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:46:07.419775  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8995
I1005 13:46:07.419800  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348567 (* 1 = 0.348567 loss)
I1005 13:46:07.472157  9519 solver.cpp:218] Iteration 49500 (15.3733 iter/s, 6.50477s/100 iters), loss = 0.044164
I1005 13:46:07.472189  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441642 (* 1 = 0.0441642 loss)
I1005 13:46:07.472198  9519 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1005 13:46:12.740460  9519 solver.cpp:218] Iteration 49600 (18.9816 iter/s, 5.26825s/100 iters), loss = 0.033939
I1005 13:46:12.740501  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339392 (* 1 = 0.0339392 loss)
I1005 13:46:12.740507  9519 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1005 13:46:18.001608  9519 solver.cpp:218] Iteration 49700 (19.0075 iter/s, 5.26109s/100 iters), loss = 0.0991717
I1005 13:46:18.001639  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0991719 (* 1 = 0.0991719 loss)
I1005 13:46:18.001646  9519 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1005 13:46:23.256317  9519 solver.cpp:218] Iteration 49800 (19.0307 iter/s, 5.25466s/100 iters), loss = 0.0242512
I1005 13:46:23.256433  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242514 (* 1 = 0.0242514 loss)
I1005 13:46:23.256450  9519 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1005 13:46:28.520124  9519 solver.cpp:218] Iteration 49900 (18.9981 iter/s, 5.26368s/100 iters), loss = 0.0173473
I1005 13:46:28.520156  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173475 (* 1 = 0.0173475 loss)
I1005 13:46:28.520162  9519 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1005 13:46:33.526757  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:46:33.736874  9519 solver.cpp:330] Iteration 50000, Testing net (#0)
I1005 13:46:34.922487  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:46:34.972066  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I1005 13:46:34.972100  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326722 (* 1 = 0.326722 loss)
I1005 13:46:35.024538  9519 solver.cpp:218] Iteration 50000 (15.3743 iter/s, 6.50437s/100 iters), loss = 0.0348655
I1005 13:46:35.024565  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348657 (* 1 = 0.0348657 loss)
I1005 13:46:35.024572  9519 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1005 13:46:40.292404  9519 solver.cpp:218] Iteration 50100 (18.9832 iter/s, 5.26782s/100 iters), loss = 0.0419356
I1005 13:46:40.292434  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419358 (* 1 = 0.0419358 loss)
I1005 13:46:40.292440  9519 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1005 13:46:45.562271  9519 solver.cpp:218] Iteration 50200 (18.976 iter/s, 5.26982s/100 iters), loss = 0.0770912
I1005 13:46:45.562312  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0770914 (* 1 = 0.0770914 loss)
I1005 13:46:45.562319  9519 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1005 13:46:50.825717  9519 solver.cpp:218] Iteration 50300 (18.9992 iter/s, 5.26339s/100 iters), loss = 0.0580567
I1005 13:46:50.825750  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580569 (* 1 = 0.0580569 loss)
I1005 13:46:50.825758  9519 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1005 13:46:56.078752  9519 solver.cpp:218] Iteration 50400 (19.0368 iter/s, 5.25298s/100 iters), loss = 0.032362
I1005 13:46:56.078893  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323622 (* 1 = 0.0323622 loss)
I1005 13:46:56.078912  9519 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1005 13:47:01.080765  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:47:01.291334  9519 solver.cpp:330] Iteration 50500, Testing net (#0)
I1005 13:47:02.476991  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:47:02.527117  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I1005 13:47:02.527153  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340372 (* 1 = 0.340372 loss)
I1005 13:47:02.580664  9519 solver.cpp:218] Iteration 50500 (15.3805 iter/s, 6.50176s/100 iters), loss = 0.024815
I1005 13:47:02.580698  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248152 (* 1 = 0.0248152 loss)
I1005 13:47:02.580705  9519 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1005 13:47:07.838030  9519 solver.cpp:218] Iteration 50600 (19.0211 iter/s, 5.25732s/100 iters), loss = 0.023379
I1005 13:47:07.838062  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233792 (* 1 = 0.0233792 loss)
I1005 13:47:07.838068  9519 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1005 13:47:13.103224  9519 solver.cpp:218] Iteration 50700 (18.9928 iter/s, 5.26515s/100 iters), loss = 0.0410908
I1005 13:47:13.103266  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041091 (* 1 = 0.041091 loss)
I1005 13:47:13.103271  9519 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1005 13:47:18.371606  9519 solver.cpp:218] Iteration 50800 (18.9814 iter/s, 5.26832s/100 iters), loss = 0.0264382
I1005 13:47:18.371637  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264384 (* 1 = 0.0264384 loss)
I1005 13:47:18.371644  9519 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1005 13:47:23.631501  9519 solver.cpp:218] Iteration 50900 (19.012 iter/s, 5.25984s/100 iters), loss = 0.0574987
I1005 13:47:23.631539  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574989 (* 1 = 0.0574989 loss)
I1005 13:47:23.631546  9519 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1005 13:47:28.633752  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:47:28.844763  9519 solver.cpp:330] Iteration 51000, Testing net (#0)
I1005 13:47:30.038179  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:47:30.087661  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9021
I1005 13:47:30.087687  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338873 (* 1 = 0.338873 loss)
I1005 13:47:30.140041  9519 solver.cpp:218] Iteration 51000 (15.3646 iter/s, 6.50849s/100 iters), loss = 0.0365114
I1005 13:47:30.140071  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365116 (* 1 = 0.0365116 loss)
I1005 13:47:30.140077  9519 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1005 13:47:35.396064  9519 solver.cpp:218] Iteration 51100 (19.026 iter/s, 5.25597s/100 iters), loss = 0.0471804
I1005 13:47:35.396106  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0471806 (* 1 = 0.0471806 loss)
I1005 13:47:35.396111  9519 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1005 13:47:40.661564  9519 solver.cpp:218] Iteration 51200 (18.9918 iter/s, 5.26544s/100 iters), loss = 0.030278
I1005 13:47:40.661607  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302782 (* 1 = 0.0302782 loss)
I1005 13:47:40.661613  9519 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1005 13:47:45.924911  9519 solver.cpp:218] Iteration 51300 (18.9995 iter/s, 5.26329s/100 iters), loss = 0.0433848
I1005 13:47:45.924952  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043385 (* 1 = 0.043385 loss)
I1005 13:47:45.924958  9519 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1005 13:47:51.180908  9519 solver.cpp:218] Iteration 51400 (19.0261 iter/s, 5.25594s/100 iters), loss = 0.0350375
I1005 13:47:51.180948  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350377 (* 1 = 0.0350377 loss)
I1005 13:47:51.180954  9519 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1005 13:47:56.177985  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:47:56.387392  9519 solver.cpp:330] Iteration 51500, Testing net (#0)
I1005 13:47:57.581797  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:47:57.631737  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I1005 13:47:57.631772  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333513 (* 1 = 0.333513 loss)
I1005 13:47:57.684502  9519 solver.cpp:218] Iteration 51500 (15.3762 iter/s, 6.50354s/100 iters), loss = 0.0357695
I1005 13:47:57.684528  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357697 (* 1 = 0.0357697 loss)
I1005 13:47:57.684535  9519 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1005 13:48:02.951242  9519 solver.cpp:218] Iteration 51600 (18.9873 iter/s, 5.26669s/100 iters), loss = 0.0732344
I1005 13:48:02.951351  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732347 (* 1 = 0.0732347 loss)
I1005 13:48:02.951370  9519 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1005 13:48:08.211015  9519 solver.cpp:218] Iteration 51700 (19.0127 iter/s, 5.25965s/100 iters), loss = 0.025564
I1005 13:48:08.211047  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255642 (* 1 = 0.0255642 loss)
I1005 13:48:08.211053  9519 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1005 13:48:13.474736  9519 solver.cpp:218] Iteration 51800 (18.9981 iter/s, 5.26367s/100 iters), loss = 0.0175431
I1005 13:48:13.474777  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175433 (* 1 = 0.0175433 loss)
I1005 13:48:13.474783  9519 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1005 13:48:18.738790  9519 solver.cpp:218] Iteration 51900 (18.997 iter/s, 5.26399s/100 iters), loss = 0.0379036
I1005 13:48:18.738821  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0379038 (* 1 = 0.0379038 loss)
I1005 13:48:18.738826  9519 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1005 13:48:23.749721  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:48:23.960507  9519 solver.cpp:330] Iteration 52000, Testing net (#0)
I1005 13:48:25.147413  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:48:25.196900  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9013
I1005 13:48:25.196924  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351206 (* 1 = 0.351206 loss)
I1005 13:48:25.249416  9519 solver.cpp:218] Iteration 52000 (15.3596 iter/s, 6.51058s/100 iters), loss = 0.0240232
I1005 13:48:25.249449  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240234 (* 1 = 0.0240234 loss)
I1005 13:48:25.249456  9519 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1005 13:48:30.513180  9519 solver.cpp:218] Iteration 52100 (18.998 iter/s, 5.26371s/100 iters), loss = 0.0425161
I1005 13:48:30.513208  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425163 (* 1 = 0.0425163 loss)
I1005 13:48:30.513214  9519 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1005 13:48:35.774222  9519 solver.cpp:218] Iteration 52200 (19.0078 iter/s, 5.26099s/100 iters), loss = 0.0289031
I1005 13:48:35.774369  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289033 (* 1 = 0.0289033 loss)
I1005 13:48:35.774377  9519 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1005 13:48:41.036886  9519 solver.cpp:218] Iteration 52300 (19.0024 iter/s, 5.26248s/100 iters), loss = 0.0583211
I1005 13:48:41.036926  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0583213 (* 1 = 0.0583213 loss)
I1005 13:48:41.036932  9519 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1005 13:48:46.298722  9519 solver.cpp:218] Iteration 52400 (19.005 iter/s, 5.26178s/100 iters), loss = 0.0514256
I1005 13:48:46.298753  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514258 (* 1 = 0.0514258 loss)
I1005 13:48:46.298758  9519 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1005 13:48:51.307344  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:48:51.518121  9519 solver.cpp:330] Iteration 52500, Testing net (#0)
I1005 13:48:52.703184  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:48:52.752526  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9038
I1005 13:48:52.752549  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335236 (* 1 = 0.335236 loss)
I1005 13:48:52.804810  9519 solver.cpp:218] Iteration 52500 (15.3703 iter/s, 6.50604s/100 iters), loss = 0.0265943
I1005 13:48:52.804836  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265945 (* 1 = 0.0265945 loss)
I1005 13:48:52.804843  9519 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1005 13:48:58.068711  9519 solver.cpp:218] Iteration 52600 (18.9975 iter/s, 5.26386s/100 iters), loss = 0.0512354
I1005 13:48:58.068742  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0512356 (* 1 = 0.0512356 loss)
I1005 13:48:58.068747  9519 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1005 13:49:03.333129  9519 solver.cpp:218] Iteration 52700 (18.9956 iter/s, 5.26437s/100 iters), loss = 0.0695283
I1005 13:49:03.333159  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0695285 (* 1 = 0.0695285 loss)
I1005 13:49:03.333176  9519 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1005 13:49:08.592372  9519 solver.cpp:218] Iteration 52800 (19.0143 iter/s, 5.25919s/100 iters), loss = 0.0383744
I1005 13:49:08.592468  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383746 (* 1 = 0.0383746 loss)
I1005 13:49:08.592483  9519 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1005 13:49:13.853482  9519 solver.cpp:218] Iteration 52900 (19.0079 iter/s, 5.26097s/100 iters), loss = 0.031153
I1005 13:49:13.853518  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311532 (* 1 = 0.0311532 loss)
I1005 13:49:13.853526  9519 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1005 13:49:18.856114  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:49:19.066110  9519 solver.cpp:330] Iteration 53000, Testing net (#0)
I1005 13:49:20.250514  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:49:20.300246  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I1005 13:49:20.300269  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361234 (* 1 = 0.361234 loss)
I1005 13:49:20.352824  9519 solver.cpp:218] Iteration 53000 (15.3863 iter/s, 6.49929s/100 iters), loss = 0.0602479
I1005 13:49:20.352856  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602481 (* 1 = 0.0602481 loss)
I1005 13:49:20.352864  9519 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1005 13:49:25.612355  9519 solver.cpp:218] Iteration 53100 (19.0133 iter/s, 5.25948s/100 iters), loss = 0.0438328
I1005 13:49:25.612385  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043833 (* 1 = 0.043833 loss)
I1005 13:49:25.612391  9519 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1005 13:49:30.876325  9519 solver.cpp:218] Iteration 53200 (18.9973 iter/s, 5.26392s/100 iters), loss = 0.0349716
I1005 13:49:30.876365  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349718 (* 1 = 0.0349718 loss)
I1005 13:49:30.876371  9519 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1005 13:49:36.143774  9519 solver.cpp:218] Iteration 53300 (18.9847 iter/s, 5.26739s/100 iters), loss = 0.0433131
I1005 13:49:36.143815  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433133 (* 1 = 0.0433133 loss)
I1005 13:49:36.143821  9519 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1005 13:49:41.398761  9519 solver.cpp:218] Iteration 53400 (19.0298 iter/s, 5.25493s/100 iters), loss = 0.0383733
I1005 13:49:41.398876  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383735 (* 1 = 0.0383735 loss)
I1005 13:49:41.398883  9519 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1005 13:49:46.405427  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:49:46.615604  9519 solver.cpp:330] Iteration 53500, Testing net (#0)
I1005 13:49:47.810459  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:49:47.859817  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9058
I1005 13:49:47.859843  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331426 (* 1 = 0.331426 loss)
I1005 13:49:47.912142  9519 solver.cpp:218] Iteration 53500 (15.3533 iter/s, 6.51325s/100 iters), loss = 0.0176063
I1005 13:49:47.912176  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176066 (* 1 = 0.0176066 loss)
I1005 13:49:47.912185  9519 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1005 13:49:53.166937  9519 solver.cpp:218] Iteration 53600 (19.0304 iter/s, 5.25474s/100 iters), loss = 0.0765402
I1005 13:49:53.166970  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765404 (* 1 = 0.0765404 loss)
I1005 13:49:53.166980  9519 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1005 13:49:58.430289  9519 solver.cpp:218] Iteration 53700 (18.9995 iter/s, 5.2633s/100 iters), loss = 0.0632652
I1005 13:49:58.430323  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0632655 (* 1 = 0.0632655 loss)
I1005 13:49:58.430341  9519 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1005 13:50:03.692978  9519 solver.cpp:218] Iteration 53800 (19.0019 iter/s, 5.26264s/100 iters), loss = 0.0562586
I1005 13:50:03.693009  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0562589 (* 1 = 0.0562589 loss)
I1005 13:50:03.693015  9519 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1005 13:50:08.952286  9519 solver.cpp:218] Iteration 53900 (19.0141 iter/s, 5.25926s/100 iters), loss = 0.0213523
I1005 13:50:08.952317  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213525 (* 1 = 0.0213525 loss)
I1005 13:50:08.952323  9519 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1005 13:50:13.950083  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:50:14.160323  9519 solver.cpp:330] Iteration 54000, Testing net (#0)
I1005 13:50:15.354564  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:50:15.404358  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9052
I1005 13:50:15.404395  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333579 (* 1 = 0.333579 loss)
I1005 13:50:15.456573  9519 solver.cpp:218] Iteration 54000 (15.3746 iter/s, 6.50424s/100 iters), loss = 0.0482901
I1005 13:50:15.456600  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482904 (* 1 = 0.0482904 loss)
I1005 13:50:15.456607  9519 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1005 13:50:20.715540  9519 solver.cpp:218] Iteration 54100 (19.0153 iter/s, 5.25892s/100 iters), loss = 0.0523779
I1005 13:50:20.715580  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0523781 (* 1 = 0.0523781 loss)
I1005 13:50:20.715589  9519 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1005 13:50:25.978360  9519 solver.cpp:218] Iteration 54200 (19.0014 iter/s, 5.26276s/100 iters), loss = 0.0620504
I1005 13:50:25.978401  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620507 (* 1 = 0.0620507 loss)
I1005 13:50:25.978407  9519 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1005 13:50:31.241677  9519 solver.cpp:218] Iteration 54300 (18.9996 iter/s, 5.26326s/100 iters), loss = 0.0390494
I1005 13:50:31.241717  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390496 (* 1 = 0.0390496 loss)
I1005 13:50:31.241724  9519 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1005 13:50:36.500701  9519 solver.cpp:218] Iteration 54400 (19.0151 iter/s, 5.25897s/100 iters), loss = 0.0321456
I1005 13:50:36.500733  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321458 (* 1 = 0.0321458 loss)
I1005 13:50:36.500741  9519 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1005 13:50:41.489651  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:50:41.707046  9519 solver.cpp:330] Iteration 54500, Testing net (#0)
I1005 13:50:42.896056  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:50:42.945708  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9071
I1005 13:50:42.945734  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329594 (* 1 = 0.329594 loss)
I1005 13:50:42.997902  9519 solver.cpp:218] Iteration 54500 (15.3914 iter/s, 6.49715s/100 iters), loss = 0.0357547
I1005 13:50:42.997936  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035755 (* 1 = 0.035755 loss)
I1005 13:50:42.997943  9519 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1005 13:50:48.258536  9519 solver.cpp:218] Iteration 54600 (19.0093 iter/s, 5.26058s/100 iters), loss = 0.0406138
I1005 13:50:48.258729  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406141 (* 1 = 0.0406141 loss)
I1005 13:50:48.258738  9519 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1005 13:50:53.510931  9519 solver.cpp:218] Iteration 54700 (19.0397 iter/s, 5.25218s/100 iters), loss = 0.0372673
I1005 13:50:53.510974  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372676 (* 1 = 0.0372676 loss)
I1005 13:50:53.510982  9519 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1005 13:50:58.771999  9519 solver.cpp:218] Iteration 54800 (19.0078 iter/s, 5.261s/100 iters), loss = 0.0338058
I1005 13:50:58.772033  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338061 (* 1 = 0.0338061 loss)
I1005 13:50:58.772052  9519 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1005 13:51:04.034477  9519 solver.cpp:218] Iteration 54900 (19.0026 iter/s, 5.26243s/100 iters), loss = 0.0330584
I1005 13:51:04.034512  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330587 (* 1 = 0.0330587 loss)
I1005 13:51:04.034519  9519 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1005 13:51:09.036660  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:51:09.246943  9519 solver.cpp:330] Iteration 55000, Testing net (#0)
I1005 13:51:10.433974  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:51:10.483999  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9042
I1005 13:51:10.484025  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348918 (* 1 = 0.348918 loss)
I1005 13:51:10.536408  9519 solver.cpp:218] Iteration 55000 (15.3802 iter/s, 6.50188s/100 iters), loss = 0.0733896
I1005 13:51:10.536438  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0733899 (* 1 = 0.0733899 loss)
I1005 13:51:10.536448  9519 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1005 13:51:15.807173  9519 solver.cpp:218] Iteration 55100 (18.9727 iter/s, 5.27072s/100 iters), loss = 0.0130764
I1005 13:51:15.807206  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130766 (* 1 = 0.0130766 loss)
I1005 13:51:15.807215  9519 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1005 13:51:21.075424  9519 solver.cpp:218] Iteration 55200 (18.9818 iter/s, 5.2682s/100 iters), loss = 0.0681141
I1005 13:51:21.075570  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0681144 (* 1 = 0.0681144 loss)
I1005 13:51:21.075604  9519 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1005 13:51:26.328887  9519 solver.cpp:218] Iteration 55300 (19.0357 iter/s, 5.2533s/100 iters), loss = 0.0151908
I1005 13:51:26.328922  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151911 (* 1 = 0.0151911 loss)
I1005 13:51:26.328932  9519 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1005 13:51:31.587630  9519 solver.cpp:218] Iteration 55400 (19.0161 iter/s, 5.25869s/100 iters), loss = 0.0341337
I1005 13:51:31.587662  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034134 (* 1 = 0.034134 loss)
I1005 13:51:31.587682  9519 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1005 13:51:36.589752  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:51:36.799877  9519 solver.cpp:330] Iteration 55500, Testing net (#0)
I1005 13:51:37.986640  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:51:38.036305  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9013
I1005 13:51:38.036341  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373896 (* 1 = 0.373896 loss)
I1005 13:51:38.088444  9519 solver.cpp:218] Iteration 55500 (15.3828 iter/s, 6.50076s/100 iters), loss = 0.0188439
I1005 13:51:38.088477  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188441 (* 1 = 0.0188441 loss)
I1005 13:51:38.088485  9519 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1005 13:51:43.347323  9519 solver.cpp:218] Iteration 55600 (19.0157 iter/s, 5.25882s/100 iters), loss = 0.0394471
I1005 13:51:43.347357  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394474 (* 1 = 0.0394474 loss)
I1005 13:51:43.347374  9519 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1005 13:51:48.609599  9519 solver.cpp:218] Iteration 55700 (19.0034 iter/s, 5.26223s/100 iters), loss = 0.0584747
I1005 13:51:48.609630  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0584749 (* 1 = 0.0584749 loss)
I1005 13:51:48.609637  9519 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1005 13:51:53.871088  9519 solver.cpp:218] Iteration 55800 (19.0062 iter/s, 5.26144s/100 iters), loss = 0.0862649
I1005 13:51:53.871207  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0862651 (* 1 = 0.0862651 loss)
I1005 13:51:53.871215  9519 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1005 13:51:59.121098  9519 solver.cpp:218] Iteration 55900 (19.048 iter/s, 5.24988s/100 iters), loss = 0.0270298
I1005 13:51:59.121131  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02703 (* 1 = 0.02703 loss)
I1005 13:51:59.121140  9519 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1005 13:52:04.125808  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:52:04.336385  9519 solver.cpp:330] Iteration 56000, Testing net (#0)
I1005 13:52:05.522495  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:52:05.573683  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9014
I1005 13:52:05.573709  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363947 (* 1 = 0.363947 loss)
I1005 13:52:05.627853  9519 solver.cpp:218] Iteration 56000 (15.3688 iter/s, 6.50671s/100 iters), loss = 0.0367837
I1005 13:52:05.627889  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367839 (* 1 = 0.0367839 loss)
I1005 13:52:05.627897  9519 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1005 13:52:10.889031  9519 solver.cpp:218] Iteration 56100 (19.0073 iter/s, 5.26112s/100 iters), loss = 0.0363734
I1005 13:52:10.889061  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363737 (* 1 = 0.0363737 loss)
I1005 13:52:10.889067  9519 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1005 13:52:16.156445  9519 solver.cpp:218] Iteration 56200 (18.9848 iter/s, 5.26737s/100 iters), loss = 0.0552489
I1005 13:52:16.156486  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552491 (* 1 = 0.0552491 loss)
I1005 13:52:16.156491  9519 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1005 13:52:21.423092  9519 solver.cpp:218] Iteration 56300 (18.9876 iter/s, 5.26659s/100 iters), loss = 0.0300285
I1005 13:52:21.423135  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300288 (* 1 = 0.0300288 loss)
I1005 13:52:21.423141  9519 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1005 13:52:26.680272  9519 solver.cpp:218] Iteration 56400 (19.0218 iter/s, 5.25712s/100 iters), loss = 0.0502572
I1005 13:52:26.680421  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0502575 (* 1 = 0.0502575 loss)
I1005 13:52:26.680430  9519 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1005 13:52:31.677320  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:52:31.887660  9519 solver.cpp:330] Iteration 56500, Testing net (#0)
I1005 13:52:33.082823  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:52:33.132611  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9029
I1005 13:52:33.132647  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354777 (* 1 = 0.354777 loss)
I1005 13:52:33.185070  9519 solver.cpp:218] Iteration 56500 (15.3736 iter/s, 6.50464s/100 iters), loss = 0.0235107
I1005 13:52:33.185113  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023511 (* 1 = 0.023511 loss)
I1005 13:52:33.185120  9519 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1005 13:52:38.441347  9519 solver.cpp:218] Iteration 56600 (19.0251 iter/s, 5.25622s/100 iters), loss = 0.0281576
I1005 13:52:38.441378  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281579 (* 1 = 0.0281579 loss)
I1005 13:52:38.441385  9519 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1005 13:52:43.704928  9519 solver.cpp:218] Iteration 56700 (18.9986 iter/s, 5.26353s/100 iters), loss = 0.0361891
I1005 13:52:43.704969  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361894 (* 1 = 0.0361894 loss)
I1005 13:52:43.704977  9519 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1005 13:52:48.971772  9519 solver.cpp:218] Iteration 56800 (18.9869 iter/s, 5.26679s/100 iters), loss = 0.0448368
I1005 13:52:48.971813  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0448371 (* 1 = 0.0448371 loss)
I1005 13:52:48.971818  9519 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1005 13:52:54.230756  9519 solver.cpp:218] Iteration 56900 (19.0153 iter/s, 5.25893s/100 iters), loss = 0.0124218
I1005 13:52:54.230787  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124221 (* 1 = 0.0124221 loss)
I1005 13:52:54.230792  9519 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1005 13:52:59.226667  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:52:59.437731  9519 solver.cpp:330] Iteration 57000, Testing net (#0)
I1005 13:53:00.633960  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:53:00.684033  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1005 13:53:00.684059  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35878 (* 1 = 0.35878 loss)
I1005 13:53:00.735957  9519 solver.cpp:218] Iteration 57000 (15.3724 iter/s, 6.50515s/100 iters), loss = 0.0308377
I1005 13:53:00.735988  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308379 (* 1 = 0.0308379 loss)
I1005 13:53:00.735996  9519 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1005 13:53:06.001536  9519 solver.cpp:218] Iteration 57100 (18.9914 iter/s, 5.26553s/100 iters), loss = 0.0325172
I1005 13:53:06.001569  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325174 (* 1 = 0.0325174 loss)
I1005 13:53:06.001574  9519 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1005 13:53:11.257589  9519 solver.cpp:218] Iteration 57200 (19.0259 iter/s, 5.256s/100 iters), loss = 0.0242876
I1005 13:53:11.257622  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242879 (* 1 = 0.0242879 loss)
I1005 13:53:11.257637  9519 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1005 13:53:16.519376  9519 solver.cpp:218] Iteration 57300 (19.0051 iter/s, 5.26174s/100 iters), loss = 0.0538566
I1005 13:53:16.519407  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538569 (* 1 = 0.0538569 loss)
I1005 13:53:16.519412  9519 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1005 13:53:21.778239  9519 solver.cpp:218] Iteration 57400 (19.0157 iter/s, 5.25881s/100 iters), loss = 0.0349658
I1005 13:53:21.778270  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349661 (* 1 = 0.0349661 loss)
I1005 13:53:21.778275  9519 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1005 13:53:26.781556  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:53:26.991642  9519 solver.cpp:330] Iteration 57500, Testing net (#0)
I1005 13:53:28.178848  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:53:28.228687  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.907
I1005 13:53:28.228721  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338915 (* 1 = 0.338915 loss)
I1005 13:53:28.281131  9519 solver.cpp:218] Iteration 57500 (15.3779 iter/s, 6.50285s/100 iters), loss = 0.0307027
I1005 13:53:28.281169  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030703 (* 1 = 0.030703 loss)
I1005 13:53:28.281177  9519 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1005 13:53:33.542552  9519 solver.cpp:218] Iteration 57600 (19.0065 iter/s, 5.26136s/100 iters), loss = 0.0297537
I1005 13:53:33.542707  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297539 (* 1 = 0.0297539 loss)
I1005 13:53:33.542724  9519 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1005 13:53:38.806804  9519 solver.cpp:218] Iteration 57700 (18.9966 iter/s, 5.26409s/100 iters), loss = 0.0151432
I1005 13:53:38.806841  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151435 (* 1 = 0.0151435 loss)
I1005 13:53:38.806849  9519 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1005 13:53:44.061025  9519 solver.cpp:218] Iteration 57800 (19.0326 iter/s, 5.25414s/100 iters), loss = 0.0327034
I1005 13:53:44.061058  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327036 (* 1 = 0.0327036 loss)
I1005 13:53:44.061064  9519 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1005 13:53:49.319649  9519 solver.cpp:218] Iteration 57900 (19.0166 iter/s, 5.25858s/100 iters), loss = 0.0435284
I1005 13:53:49.319681  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0435286 (* 1 = 0.0435286 loss)
I1005 13:53:49.319690  9519 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1005 13:53:54.326817  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:53:54.537124  9519 solver.cpp:330] Iteration 58000, Testing net (#0)
I1005 13:53:55.724342  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:53:55.774168  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8991
I1005 13:53:55.774205  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392493 (* 1 = 0.392493 loss)
I1005 13:53:55.826762  9519 solver.cpp:218] Iteration 58000 (15.3679 iter/s, 6.50707s/100 iters), loss = 0.0383709
I1005 13:53:55.826800  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383712 (* 1 = 0.0383712 loss)
I1005 13:53:55.826807  9519 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1005 13:54:01.095038  9519 solver.cpp:218] Iteration 58100 (18.9817 iter/s, 5.26822s/100 iters), loss = 0.0199374
I1005 13:54:01.095079  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199377 (* 1 = 0.0199377 loss)
I1005 13:54:01.095085  9519 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1005 13:54:06.358620  9519 solver.cpp:218] Iteration 58200 (18.9987 iter/s, 5.26352s/100 iters), loss = 0.0217346
I1005 13:54:06.358741  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217349 (* 1 = 0.0217349 loss)
I1005 13:54:06.358758  9519 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1005 13:54:11.619700  9519 solver.cpp:218] Iteration 58300 (19.008 iter/s, 5.26094s/100 iters), loss = 0.0199096
I1005 13:54:11.619748  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199099 (* 1 = 0.0199099 loss)
I1005 13:54:11.619755  9519 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1005 13:54:16.879652  9519 solver.cpp:218] Iteration 58400 (19.0118 iter/s, 5.25989s/100 iters), loss = 0.0230658
I1005 13:54:16.879693  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230661 (* 1 = 0.0230661 loss)
I1005 13:54:16.879699  9519 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1005 13:54:21.885731  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:54:22.096292  9519 solver.cpp:330] Iteration 58500, Testing net (#0)
I1005 13:54:23.284163  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:54:23.333930  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9011
I1005 13:54:23.333966  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381171 (* 1 = 0.381171 loss)
I1005 13:54:23.386148  9519 solver.cpp:218] Iteration 58500 (15.3694 iter/s, 6.50644s/100 iters), loss = 0.0149051
I1005 13:54:23.386183  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149054 (* 1 = 0.0149054 loss)
I1005 13:54:23.386189  9519 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1005 13:54:28.655949  9519 solver.cpp:218] Iteration 58600 (18.9762 iter/s, 5.26975s/100 iters), loss = 0.0144927
I1005 13:54:28.655982  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014493 (* 1 = 0.014493 loss)
I1005 13:54:28.655988  9519 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1005 13:54:33.921465  9519 solver.cpp:218] Iteration 58700 (18.9917 iter/s, 5.26547s/100 iters), loss = 0.0240743
I1005 13:54:33.921507  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240746 (* 1 = 0.0240746 loss)
I1005 13:54:33.921514  9519 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1005 13:54:39.190364  9519 solver.cpp:218] Iteration 58800 (18.9795 iter/s, 5.26884s/100 iters), loss = 0.0266202
I1005 13:54:39.190506  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266204 (* 1 = 0.0266204 loss)
I1005 13:54:39.190515  9519 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1005 13:54:44.446049  9519 solver.cpp:218] Iteration 58900 (19.0275 iter/s, 5.25554s/100 iters), loss = 0.0500014
I1005 13:54:44.446092  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0500017 (* 1 = 0.0500017 loss)
I1005 13:54:44.446099  9519 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1005 13:54:49.455446  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:54:49.665645  9519 solver.cpp:330] Iteration 59000, Testing net (#0)
I1005 13:54:50.859936  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:54:50.909654  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I1005 13:54:50.909680  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36249 (* 1 = 0.36249 loss)
I1005 13:54:50.962218  9519 solver.cpp:218] Iteration 59000 (15.3466 iter/s, 6.51611s/100 iters), loss = 0.0191091
I1005 13:54:50.962250  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191093 (* 1 = 0.0191093 loss)
I1005 13:54:50.962257  9519 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1005 13:54:56.219954  9519 solver.cpp:218] Iteration 59100 (19.0198 iter/s, 5.25768s/100 iters), loss = 0.0218798
I1005 13:54:56.219986  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02188 (* 1 = 0.02188 loss)
I1005 13:54:56.219992  9519 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1005 13:55:01.488512  9519 solver.cpp:218] Iteration 59200 (18.9807 iter/s, 5.2685s/100 iters), loss = 0.0655512
I1005 13:55:01.488553  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655515 (* 1 = 0.0655515 loss)
I1005 13:55:01.488559  9519 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1005 13:55:06.753288  9519 solver.cpp:218] Iteration 59300 (18.9944 iter/s, 5.26472s/100 iters), loss = 0.0135617
I1005 13:55:06.753329  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013562 (* 1 = 0.013562 loss)
I1005 13:55:06.753335  9519 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1005 13:55:12.022013  9519 solver.cpp:218] Iteration 59400 (18.9801 iter/s, 5.26867s/100 iters), loss = 0.0169683
I1005 13:55:12.022172  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169686 (* 1 = 0.0169686 loss)
I1005 13:55:12.022181  9519 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1005 13:55:17.023094  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:55:17.233220  9519 solver.cpp:330] Iteration 59500, Testing net (#0)
I1005 13:55:18.429915  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:55:18.479869  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I1005 13:55:18.479903  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.425979 (* 1 = 0.425979 loss)
I1005 13:55:18.532366  9519 solver.cpp:218] Iteration 59500 (15.3605 iter/s, 6.51019s/100 iters), loss = 0.0309753
I1005 13:55:18.532403  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309756 (* 1 = 0.0309756 loss)
I1005 13:55:18.532410  9519 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1005 13:55:23.799790  9519 solver.cpp:218] Iteration 59600 (18.9848 iter/s, 5.26736s/100 iters), loss = 0.060283
I1005 13:55:23.799826  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602833 (* 1 = 0.0602833 loss)
I1005 13:55:23.799835  9519 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1005 13:55:29.062144  9519 solver.cpp:218] Iteration 59700 (19.0031 iter/s, 5.2623s/100 iters), loss = 0.0285163
I1005 13:55:29.062186  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285166 (* 1 = 0.0285166 loss)
I1005 13:55:29.062192  9519 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1005 13:55:34.330483  9519 solver.cpp:218] Iteration 59800 (18.9815 iter/s, 5.26828s/100 iters), loss = 0.040962
I1005 13:55:34.330526  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409623 (* 1 = 0.0409623 loss)
I1005 13:55:34.330534  9519 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1005 13:55:39.593089  9519 solver.cpp:218] Iteration 59900 (19.0022 iter/s, 5.26255s/100 iters), loss = 0.00906671
I1005 13:55:39.593122  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00906702 (* 1 = 0.00906702 loss)
I1005 13:55:39.593128  9519 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1005 13:55:44.592355  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:55:44.808501  9519 solver.cpp:330] Iteration 60000, Testing net (#0)
I1005 13:55:45.996366  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:55:46.046277  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I1005 13:55:46.046301  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361272 (* 1 = 0.361272 loss)
I1005 13:55:46.098515  9519 solver.cpp:218] Iteration 60000 (15.3719 iter/s, 6.50538s/100 iters), loss = 0.0454028
I1005 13:55:46.098546  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454031 (* 1 = 0.0454031 loss)
I1005 13:55:46.098552  9519 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1005 13:55:51.363931  9519 solver.cpp:218] Iteration 60100 (18.992 iter/s, 5.26537s/100 iters), loss = 0.063637
I1005 13:55:51.363973  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0636373 (* 1 = 0.0636373 loss)
I1005 13:55:51.363979  9519 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1005 13:55:56.622879  9519 solver.cpp:218] Iteration 60200 (19.0154 iter/s, 5.25888s/100 iters), loss = 0.0493029
I1005 13:55:56.622917  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493032 (* 1 = 0.0493032 loss)
I1005 13:55:56.622936  9519 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1005 13:56:01.886580  9519 solver.cpp:218] Iteration 60300 (18.9984 iter/s, 5.26361s/100 iters), loss = 0.0378824
I1005 13:56:01.886621  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0378827 (* 1 = 0.0378827 loss)
I1005 13:56:01.886627  9519 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1005 13:56:07.147960  9519 solver.cpp:218] Iteration 60400 (19.0066 iter/s, 5.26132s/100 iters), loss = 0.00912129
I1005 13:56:07.148005  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091216 (* 1 = 0.0091216 loss)
I1005 13:56:07.148010  9519 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1005 13:56:12.154959  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:56:12.365664  9519 solver.cpp:330] Iteration 60500, Testing net (#0)
I1005 13:56:13.552680  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:56:13.602530  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8967
I1005 13:56:13.602566  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.396049 (* 1 = 0.396049 loss)
I1005 13:56:13.654688  9519 solver.cpp:218] Iteration 60500 (15.3688 iter/s, 6.50667s/100 iters), loss = 0.03989
I1005 13:56:13.654716  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398903 (* 1 = 0.0398903 loss)
I1005 13:56:13.654723  9519 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1005 13:56:18.922646  9519 solver.cpp:218] Iteration 60600 (18.9828 iter/s, 5.26791s/100 iters), loss = 0.030309
I1005 13:56:18.922786  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303093 (* 1 = 0.0303093 loss)
I1005 13:56:18.922804  9519 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1005 13:56:24.190865  9519 solver.cpp:218] Iteration 60700 (18.9823 iter/s, 5.26807s/100 iters), loss = 0.0595884
I1005 13:56:24.190904  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0595887 (* 1 = 0.0595887 loss)
I1005 13:56:24.190910  9519 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1005 13:56:29.446404  9519 solver.cpp:218] Iteration 60800 (19.0278 iter/s, 5.25548s/100 iters), loss = 0.061009
I1005 13:56:29.446445  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0610093 (* 1 = 0.0610093 loss)
I1005 13:56:29.446451  9519 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1005 13:56:34.696398  9519 solver.cpp:218] Iteration 60900 (19.0479 iter/s, 5.24993s/100 iters), loss = 0.05932
I1005 13:56:34.696437  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0593203 (* 1 = 0.0593203 loss)
I1005 13:56:34.696444  9519 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1005 13:56:39.702913  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:56:39.913451  9519 solver.cpp:330] Iteration 61000, Testing net (#0)
I1005 13:56:41.099694  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:56:41.149348  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8904
I1005 13:56:41.149374  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.430441 (* 1 = 0.430441 loss)
I1005 13:56:41.201818  9519 solver.cpp:218] Iteration 61000 (15.3719 iter/s, 6.50536s/100 iters), loss = 0.0325586
I1005 13:56:41.201849  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325589 (* 1 = 0.0325589 loss)
I1005 13:56:41.201856  9519 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1005 13:56:46.464356  9519 solver.cpp:218] Iteration 61100 (19.0024 iter/s, 5.26249s/100 iters), loss = 0.0162698
I1005 13:56:46.464397  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162701 (* 1 = 0.0162701 loss)
I1005 13:56:46.464403  9519 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1005 13:56:51.729782  9519 solver.cpp:218] Iteration 61200 (18.992 iter/s, 5.26536s/100 iters), loss = 0.0168422
I1005 13:56:51.729899  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168425 (* 1 = 0.0168425 loss)
I1005 13:56:51.729917  9519 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1005 13:56:56.993350  9519 solver.cpp:218] Iteration 61300 (18.999 iter/s, 5.26343s/100 iters), loss = 0.00904655
I1005 13:56:56.993403  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00904684 (* 1 = 0.00904684 loss)
I1005 13:56:56.993412  9519 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1005 13:57:02.246738  9519 solver.cpp:218] Iteration 61400 (19.0356 iter/s, 5.25332s/100 iters), loss = 0.0140309
I1005 13:57:02.246769  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140312 (* 1 = 0.0140312 loss)
I1005 13:57:02.246775  9519 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1005 13:57:07.250645  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:57:07.461096  9519 solver.cpp:330] Iteration 61500, Testing net (#0)
I1005 13:57:08.652664  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:57:08.703366  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8908
I1005 13:57:08.703395  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424676 (* 1 = 0.424676 loss)
I1005 13:57:08.757997  9519 solver.cpp:218] Iteration 61500 (15.3581 iter/s, 6.51121s/100 iters), loss = 0.0237949
I1005 13:57:08.758034  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237952 (* 1 = 0.0237952 loss)
I1005 13:57:08.758041  9519 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1005 13:57:14.012747  9519 solver.cpp:218] Iteration 61600 (19.0306 iter/s, 5.25469s/100 iters), loss = 0.0262148
I1005 13:57:14.012786  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262151 (* 1 = 0.0262151 loss)
I1005 13:57:14.012792  9519 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1005 13:57:19.274030  9519 solver.cpp:218] Iteration 61700 (19.007 iter/s, 5.26123s/100 iters), loss = 0.0155525
I1005 13:57:19.274070  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155528 (* 1 = 0.0155528 loss)
I1005 13:57:19.274075  9519 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1005 13:57:24.535594  9519 solver.cpp:218] Iteration 61800 (19.0059 iter/s, 5.26151s/100 iters), loss = 0.0108874
I1005 13:57:24.535724  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108877 (* 1 = 0.0108877 loss)
I1005 13:57:24.535732  9519 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1005 13:57:29.790890  9519 solver.cpp:218] Iteration 61900 (19.0289 iter/s, 5.25516s/100 iters), loss = 0.0219399
I1005 13:57:29.790935  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219402 (* 1 = 0.0219402 loss)
I1005 13:57:29.790942  9519 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1005 13:57:34.789439  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:57:34.999629  9519 solver.cpp:330] Iteration 62000, Testing net (#0)
I1005 13:57:36.197580  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:57:36.247478  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I1005 13:57:36.247501  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359692 (* 1 = 0.359692 loss)
I1005 13:57:36.299536  9519 solver.cpp:218] Iteration 62000 (15.3643 iter/s, 6.50859s/100 iters), loss = 0.0162778
I1005 13:57:36.299563  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162781 (* 1 = 0.0162781 loss)
I1005 13:57:36.299571  9519 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1005 13:57:41.559533  9519 solver.cpp:218] Iteration 62100 (19.0116 iter/s, 5.25995s/100 iters), loss = 0.0447582
I1005 13:57:41.559577  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447585 (* 1 = 0.0447585 loss)
I1005 13:57:41.559584  9519 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1005 13:57:46.829726  9519 solver.cpp:218] Iteration 62200 (18.9749 iter/s, 5.27013s/100 iters), loss = 0.017315
I1005 13:57:46.829766  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173154 (* 1 = 0.0173154 loss)
I1005 13:57:46.829772  9519 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1005 13:57:52.098271  9519 solver.cpp:218] Iteration 62300 (18.9808 iter/s, 5.26849s/100 iters), loss = 0.01085
I1005 13:57:52.098300  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108503 (* 1 = 0.0108503 loss)
I1005 13:57:52.098306  9519 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1005 13:57:57.359509  9519 solver.cpp:218] Iteration 62400 (19.0071 iter/s, 5.26119s/100 iters), loss = 0.0239519
I1005 13:57:57.359659  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239522 (* 1 = 0.0239522 loss)
I1005 13:57:57.359668  9519 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1005 13:58:02.359344  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:58:02.569272  9519 solver.cpp:330] Iteration 62500, Testing net (#0)
I1005 13:58:03.762114  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:58:03.811697  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I1005 13:58:03.811733  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384491 (* 1 = 0.384491 loss)
I1005 13:58:03.863934  9519 solver.cpp:218] Iteration 62500 (15.3745 iter/s, 6.50426s/100 iters), loss = 0.0289257
I1005 13:58:03.863958  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028926 (* 1 = 0.028926 loss)
I1005 13:58:03.863965  9519 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1005 13:58:09.124362  9519 solver.cpp:218] Iteration 62600 (19.01 iter/s, 5.26038s/100 iters), loss = 0.0176216
I1005 13:58:09.124397  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176219 (* 1 = 0.0176219 loss)
I1005 13:58:09.124415  9519 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1005 13:58:14.379165  9519 solver.cpp:218] Iteration 62700 (19.0304 iter/s, 5.25475s/100 iters), loss = 0.0284985
I1005 13:58:14.379199  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284988 (* 1 = 0.0284988 loss)
I1005 13:58:14.379218  9519 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1005 13:58:19.647788  9519 solver.cpp:218] Iteration 62800 (18.9805 iter/s, 5.26857s/100 iters), loss = 0.0344911
I1005 13:58:19.647820  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344914 (* 1 = 0.0344914 loss)
I1005 13:58:19.647828  9519 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1005 13:58:24.916218  9519 solver.cpp:218] Iteration 62900 (18.9812 iter/s, 5.26838s/100 iters), loss = 0.00825704
I1005 13:58:24.916251  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825739 (* 1 = 0.00825739 loss)
I1005 13:58:24.916260  9519 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1005 13:58:29.925564  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:58:30.135471  9519 solver.cpp:330] Iteration 63000, Testing net (#0)
I1005 13:58:31.323449  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:58:31.373309  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8986
I1005 13:58:31.373335  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387232 (* 1 = 0.387232 loss)
I1005 13:58:31.425843  9519 solver.cpp:218] Iteration 63000 (15.362 iter/s, 6.50958s/100 iters), loss = 0.0231673
I1005 13:58:31.425878  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231676 (* 1 = 0.0231676 loss)
I1005 13:58:31.425887  9519 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1005 13:58:36.692777  9519 solver.cpp:218] Iteration 63100 (18.9866 iter/s, 5.26688s/100 iters), loss = 0.0523404
I1005 13:58:36.692812  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0523408 (* 1 = 0.0523408 loss)
I1005 13:58:36.692821  9519 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1005 13:58:41.960810  9519 solver.cpp:218] Iteration 63200 (18.9826 iter/s, 5.26798s/100 iters), loss = 0.021348
I1005 13:58:41.960844  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213483 (* 1 = 0.0213483 loss)
I1005 13:58:41.960852  9519 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1005 13:58:47.222924  9519 solver.cpp:218] Iteration 63300 (19.004 iter/s, 5.26206s/100 iters), loss = 0.0305785
I1005 13:58:47.222959  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305788 (* 1 = 0.0305788 loss)
I1005 13:58:47.222967  9519 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1005 13:58:52.480562  9519 solver.cpp:218] Iteration 63400 (19.0201 iter/s, 5.25759s/100 iters), loss = 0.0438121
I1005 13:58:52.480597  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438125 (* 1 = 0.0438125 loss)
I1005 13:58:52.480607  9519 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1005 13:58:57.485435  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:58:57.695632  9519 solver.cpp:330] Iteration 63500, Testing net (#0)
I1005 13:58:58.884035  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:58:58.933986  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I1005 13:58:58.934013  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420745 (* 1 = 0.420745 loss)
I1005 13:58:58.986240  9519 solver.cpp:218] Iteration 63500 (15.3713 iter/s, 6.50563s/100 iters), loss = 0.0149346
I1005 13:58:58.986273  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014935 (* 1 = 0.014935 loss)
I1005 13:58:58.986282  9519 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1005 13:59:04.251796  9519 solver.cpp:218] Iteration 63600 (18.9915 iter/s, 5.2655s/100 iters), loss = 0.0178826
I1005 13:59:04.251919  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178829 (* 1 = 0.0178829 loss)
I1005 13:59:04.251936  9519 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1005 13:59:09.519094  9519 solver.cpp:218] Iteration 63700 (18.9856 iter/s, 5.26716s/100 iters), loss = 0.0326106
I1005 13:59:09.519135  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326109 (* 1 = 0.0326109 loss)
I1005 13:59:09.519142  9519 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1005 13:59:14.786379  9519 solver.cpp:218] Iteration 63800 (18.9853 iter/s, 5.26722s/100 iters), loss = 0.0117159
I1005 13:59:14.786417  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117162 (* 1 = 0.0117162 loss)
I1005 13:59:14.786423  9519 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1005 13:59:20.038691  9519 solver.cpp:218] Iteration 63900 (19.0394 iter/s, 5.25226s/100 iters), loss = 0.00590029
I1005 13:59:20.038733  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00590056 (* 1 = 0.00590056 loss)
I1005 13:59:20.038739  9519 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1005 13:59:25.049170  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:59:25.259230  9519 solver.cpp:330] Iteration 64000, Testing net (#0)
I1005 13:59:26.448596  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:59:26.498714  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8847
I1005 13:59:26.498749  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.472222 (* 1 = 0.472222 loss)
I1005 13:59:26.551221  9519 solver.cpp:218] Iteration 64000 (15.3551 iter/s, 6.51247s/100 iters), loss = 0.0160135
I1005 13:59:26.551249  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160138 (* 1 = 0.0160138 loss)
I1005 13:59:26.551255  9519 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1005 13:59:31.814625  9519 solver.cpp:218] Iteration 64100 (18.9993 iter/s, 5.26336s/100 iters), loss = 0.031064
I1005 13:59:31.814654  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310643 (* 1 = 0.0310643 loss)
I1005 13:59:31.814661  9519 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1005 13:59:37.085047  9519 solver.cpp:218] Iteration 64200 (18.974 iter/s, 5.27037s/100 iters), loss = 0.0135735
I1005 13:59:37.085192  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135737 (* 1 = 0.0135737 loss)
I1005 13:59:37.085201  9519 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1005 13:59:42.348037  9519 solver.cpp:218] Iteration 64300 (19.0011 iter/s, 5.26284s/100 iters), loss = 0.0407793
I1005 13:59:42.348079  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407796 (* 1 = 0.0407796 loss)
I1005 13:59:42.348086  9519 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1005 13:59:47.602283  9519 solver.cpp:218] Iteration 64400 (19.0324 iter/s, 5.25418s/100 iters), loss = 0.0137448
I1005 13:59:47.602326  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137451 (* 1 = 0.0137451 loss)
I1005 13:59:47.602334  9519 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1005 13:59:52.609809  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:59:52.819582  9519 solver.cpp:330] Iteration 64500, Testing net (#0)
I1005 13:59:54.009233  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 13:59:54.058506  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I1005 13:59:54.058545  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353507 (* 1 = 0.353507 loss)
I1005 13:59:54.110641  9519 solver.cpp:218] Iteration 64500 (15.3651 iter/s, 6.50827s/100 iters), loss = 0.036043
I1005 13:59:54.110694  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360433 (* 1 = 0.0360433 loss)
I1005 13:59:54.110705  9519 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1005 13:59:59.368671  9519 solver.cpp:218] Iteration 64600 (19.0187 iter/s, 5.25798s/100 iters), loss = 0.0583626
I1005 13:59:59.368705  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0583628 (* 1 = 0.0583628 loss)
I1005 13:59:59.368723  9519 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1005 14:00:04.640036  9519 solver.cpp:218] Iteration 64700 (18.9706 iter/s, 5.27131s/100 iters), loss = 0.0195662
I1005 14:00:04.640070  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195665 (* 1 = 0.0195665 loss)
I1005 14:00:04.640089  9519 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1005 14:00:09.913440  9519 solver.cpp:218] Iteration 64800 (18.9633 iter/s, 5.27336s/100 iters), loss = 0.0112081
I1005 14:00:09.913578  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112084 (* 1 = 0.0112084 loss)
I1005 14:00:09.913621  9519 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1005 14:00:15.181375  9519 solver.cpp:218] Iteration 64900 (18.9833 iter/s, 5.26779s/100 iters), loss = 0.0177219
I1005 14:00:15.181407  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177222 (* 1 = 0.0177222 loss)
I1005 14:00:15.181416  9519 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1005 14:00:20.181666  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:00:20.391685  9519 solver.cpp:330] Iteration 65000, Testing net (#0)
I1005 14:00:21.587666  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:00:21.637223  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9043
I1005 14:00:21.637251  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372626 (* 1 = 0.372626 loss)
I1005 14:00:21.689676  9519 solver.cpp:218] Iteration 65000 (15.3651 iter/s, 6.50825s/100 iters), loss = 0.0115502
I1005 14:00:21.689705  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115505 (* 1 = 0.0115505 loss)
I1005 14:00:21.689714  9519 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1005 14:00:26.953416  9519 solver.cpp:218] Iteration 65100 (18.9981 iter/s, 5.26369s/100 iters), loss = 0.0190183
I1005 14:00:26.953450  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190186 (* 1 = 0.0190186 loss)
I1005 14:00:26.953459  9519 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1005 14:00:32.210005  9519 solver.cpp:218] Iteration 65200 (19.024 iter/s, 5.25653s/100 iters), loss = 0.0201948
I1005 14:00:32.210037  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201951 (* 1 = 0.0201951 loss)
I1005 14:00:32.210057  9519 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1005 14:00:37.468773  9519 solver.cpp:218] Iteration 65300 (19.016 iter/s, 5.25872s/100 iters), loss = 0.0157926
I1005 14:00:37.468806  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157929 (* 1 = 0.0157929 loss)
I1005 14:00:37.468814  9519 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1005 14:00:42.724905  9519 solver.cpp:218] Iteration 65400 (19.0256 iter/s, 5.25608s/100 iters), loss = 0.010565
I1005 14:00:42.725026  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105653 (* 1 = 0.0105653 loss)
I1005 14:00:42.725046  9519 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1005 14:00:47.728860  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:00:47.941678  9519 solver.cpp:330] Iteration 65500, Testing net (#0)
I1005 14:00:49.127562  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:00:49.177119  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I1005 14:00:49.177155  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409666 (* 1 = 0.409666 loss)
I1005 14:00:49.229266  9519 solver.cpp:218] Iteration 65500 (15.3746 iter/s, 6.50424s/100 iters), loss = 0.0263565
I1005 14:00:49.229297  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263567 (* 1 = 0.0263567 loss)
I1005 14:00:49.229305  9519 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1005 14:00:54.495064  9519 solver.cpp:218] Iteration 65600 (18.9907 iter/s, 5.26575s/100 iters), loss = 0.0336421
I1005 14:00:54.495093  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336424 (* 1 = 0.0336424 loss)
I1005 14:00:54.495098  9519 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1005 14:00:59.761023  9519 solver.cpp:218] Iteration 65700 (18.9901 iter/s, 5.26591s/100 iters), loss = 0.00575905
I1005 14:00:59.761071  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575931 (* 1 = 0.00575931 loss)
I1005 14:00:59.761078  9519 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1005 14:01:05.022874  9519 solver.cpp:218] Iteration 65800 (19.0051 iter/s, 5.26176s/100 iters), loss = 0.0210622
I1005 14:01:05.022915  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210624 (* 1 = 0.0210624 loss)
I1005 14:01:05.022922  9519 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1005 14:01:10.286680  9519 solver.cpp:218] Iteration 65900 (18.9979 iter/s, 5.26375s/100 iters), loss = 0.0103084
I1005 14:01:10.286710  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103086 (* 1 = 0.0103086 loss)
I1005 14:01:10.286717  9519 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1005 14:01:15.290138  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:01:15.499922  9519 solver.cpp:330] Iteration 66000, Testing net (#0)
I1005 14:01:16.687459  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:01:16.737314  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I1005 14:01:16.737350  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376938 (* 1 = 0.376938 loss)
I1005 14:01:16.789619  9519 solver.cpp:218] Iteration 66000 (15.3778 iter/s, 6.50289s/100 iters), loss = 0.0271501
I1005 14:01:16.789647  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271504 (* 1 = 0.0271504 loss)
I1005 14:01:16.789654  9519 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1005 14:01:22.049089  9519 solver.cpp:218] Iteration 66100 (19.0135 iter/s, 5.25942s/100 iters), loss = 0.0150487
I1005 14:01:22.049119  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015049 (* 1 = 0.015049 loss)
I1005 14:01:22.049127  9519 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1005 14:01:27.311486  9519 solver.cpp:218] Iteration 66200 (19.0029 iter/s, 5.26235s/100 iters), loss = 0.0135162
I1005 14:01:27.311514  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135164 (* 1 = 0.0135164 loss)
I1005 14:01:27.311523  9519 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1005 14:01:32.563592  9519 solver.cpp:218] Iteration 66300 (19.0401 iter/s, 5.25206s/100 iters), loss = 0.0450313
I1005 14:01:32.563623  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450316 (* 1 = 0.0450316 loss)
I1005 14:01:32.563629  9519 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1005 14:01:37.825548  9519 solver.cpp:218] Iteration 66400 (19.0045 iter/s, 5.26191s/100 iters), loss = 0.00998989
I1005 14:01:37.825579  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00999014 (* 1 = 0.00999014 loss)
I1005 14:01:37.825585  9519 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1005 14:01:42.830559  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:01:43.039880  9519 solver.cpp:330] Iteration 66500, Testing net (#0)
I1005 14:01:44.226339  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:01:44.275540  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8978
I1005 14:01:44.275566  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.408148 (* 1 = 0.408148 loss)
I1005 14:01:44.327862  9519 solver.cpp:218] Iteration 66500 (15.3793 iter/s, 6.50227s/100 iters), loss = 0.0242239
I1005 14:01:44.327895  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242241 (* 1 = 0.0242241 loss)
I1005 14:01:44.327903  9519 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1005 14:01:49.594600  9519 solver.cpp:218] Iteration 66600 (18.9873 iter/s, 5.26669s/100 iters), loss = 0.0318044
I1005 14:01:49.594758  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318046 (* 1 = 0.0318046 loss)
I1005 14:01:49.594766  9519 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1005 14:01:54.863724  9519 solver.cpp:218] Iteration 66700 (18.9791 iter/s, 5.26896s/100 iters), loss = 0.00495489
I1005 14:01:54.863755  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495515 (* 1 = 0.00495515 loss)
I1005 14:01:54.863761  9519 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1005 14:02:00.129818  9519 solver.cpp:218] Iteration 66800 (18.9896 iter/s, 5.26604s/100 iters), loss = 0.0201312
I1005 14:02:00.129863  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201315 (* 1 = 0.0201315 loss)
I1005 14:02:00.129868  9519 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1005 14:02:05.386046  9519 solver.cpp:218] Iteration 66900 (19.0253 iter/s, 5.25617s/100 iters), loss = 0.0207096
I1005 14:02:05.386086  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207099 (* 1 = 0.0207099 loss)
I1005 14:02:05.386093  9519 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1005 14:02:10.390082  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:02:10.600775  9519 solver.cpp:330] Iteration 67000, Testing net (#0)
I1005 14:02:11.790483  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:02:11.840797  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1005 14:02:11.840823  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389876 (* 1 = 0.389876 loss)
I1005 14:02:11.894172  9519 solver.cpp:218] Iteration 67000 (15.3655 iter/s, 6.50807s/100 iters), loss = 0.0337659
I1005 14:02:11.894207  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337662 (* 1 = 0.0337662 loss)
I1005 14:02:11.894214  9519 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1005 14:02:17.151091  9519 solver.cpp:218] Iteration 67100 (19.0227 iter/s, 5.25687s/100 iters), loss = 0.0483066
I1005 14:02:17.151123  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483068 (* 1 = 0.0483068 loss)
I1005 14:02:17.151129  9519 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1005 14:02:22.417130  9519 solver.cpp:218] Iteration 67200 (18.9898 iter/s, 5.26599s/100 iters), loss = 0.00715447
I1005 14:02:22.417239  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715472 (* 1 = 0.00715472 loss)
I1005 14:02:22.417248  9519 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1005 14:02:27.687608  9519 solver.cpp:218] Iteration 67300 (18.9741 iter/s, 5.27035s/100 iters), loss = 0.0151458
I1005 14:02:27.687641  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151461 (* 1 = 0.0151461 loss)
I1005 14:02:27.687649  9519 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1005 14:02:32.950583  9519 solver.cpp:218] Iteration 67400 (19.0008 iter/s, 5.26293s/100 iters), loss = 0.0113176
I1005 14:02:32.950619  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113179 (* 1 = 0.0113179 loss)
I1005 14:02:32.950629  9519 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1005 14:02:37.951575  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:02:38.162214  9519 solver.cpp:330] Iteration 67500, Testing net (#0)
I1005 14:02:39.358659  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:02:39.408377  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I1005 14:02:39.408403  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373373 (* 1 = 0.373373 loss)
I1005 14:02:39.460682  9519 solver.cpp:218] Iteration 67500 (15.3609 iter/s, 6.51004s/100 iters), loss = 0.0238635
I1005 14:02:39.460726  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238637 (* 1 = 0.0238637 loss)
I1005 14:02:39.460742  9519 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1005 14:02:44.721906  9519 solver.cpp:218] Iteration 67600 (19.0072 iter/s, 5.26116s/100 iters), loss = 0.0328982
I1005 14:02:44.721945  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328984 (* 1 = 0.0328984 loss)
I1005 14:02:44.721952  9519 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1005 14:02:49.982269  9519 solver.cpp:218] Iteration 67700 (19.0103 iter/s, 5.26031s/100 iters), loss = 0.0170648
I1005 14:02:49.982300  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017065 (* 1 = 0.017065 loss)
I1005 14:02:49.982306  9519 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1005 14:02:55.241297  9519 solver.cpp:218] Iteration 67800 (19.0151 iter/s, 5.25898s/100 iters), loss = 0.00513923
I1005 14:02:55.241438  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513949 (* 1 = 0.00513949 loss)
I1005 14:02:55.241456  9519 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1005 14:03:00.499003  9519 solver.cpp:218] Iteration 67900 (19.0203 iter/s, 5.25755s/100 iters), loss = 0.0261543
I1005 14:03:00.499034  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261546 (* 1 = 0.0261546 loss)
I1005 14:03:00.499040  9519 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1005 14:03:05.497345  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:03:05.709789  9519 solver.cpp:330] Iteration 68000, Testing net (#0)
I1005 14:03:06.901245  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:03:06.951062  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I1005 14:03:06.951097  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.425117 (* 1 = 0.425117 loss)
I1005 14:03:07.003597  9519 solver.cpp:218] Iteration 68000 (15.3739 iter/s, 6.50455s/100 iters), loss = 0.00365227
I1005 14:03:07.003624  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365253 (* 1 = 0.00365253 loss)
I1005 14:03:07.003630  9519 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1005 14:03:12.267083  9519 solver.cpp:218] Iteration 68100 (18.999 iter/s, 5.26344s/100 iters), loss = 0.0351265
I1005 14:03:12.267117  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351267 (* 1 = 0.0351267 loss)
I1005 14:03:12.267132  9519 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1005 14:03:17.522016  9519 solver.cpp:218] Iteration 68200 (19.0299 iter/s, 5.25488s/100 iters), loss = 0.0161043
I1005 14:03:17.522045  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161046 (* 1 = 0.0161046 loss)
I1005 14:03:17.522052  9519 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1005 14:03:22.783886  9519 solver.cpp:218] Iteration 68300 (19.0048 iter/s, 5.26182s/100 iters), loss = 0.0273833
I1005 14:03:22.783916  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273836 (* 1 = 0.0273836 loss)
I1005 14:03:22.783932  9519 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1005 14:03:28.046239  9519 solver.cpp:218] Iteration 68400 (19.0031 iter/s, 5.26231s/100 iters), loss = 0.00995878
I1005 14:03:28.046351  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00995905 (* 1 = 0.00995905 loss)
I1005 14:03:28.046358  9519 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1005 14:03:33.051589  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:03:33.260500  9519 solver.cpp:330] Iteration 68500, Testing net (#0)
I1005 14:03:34.446795  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:03:34.496407  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.896
I1005 14:03:34.496433  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.407274 (* 1 = 0.407274 loss)
I1005 14:03:34.548840  9519 solver.cpp:218] Iteration 68500 (15.3788 iter/s, 6.50248s/100 iters), loss = 0.0348136
I1005 14:03:34.548867  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348138 (* 1 = 0.0348138 loss)
I1005 14:03:34.548874  9519 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1005 14:03:39.808310  9519 solver.cpp:218] Iteration 68600 (19.0135 iter/s, 5.25942s/100 iters), loss = 0.0364571
I1005 14:03:39.808339  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364574 (* 1 = 0.0364574 loss)
I1005 14:03:39.808356  9519 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1005 14:03:45.065558  9519 solver.cpp:218] Iteration 68700 (19.0215 iter/s, 5.2572s/100 iters), loss = 0.0565756
I1005 14:03:45.065587  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0565758 (* 1 = 0.0565758 loss)
I1005 14:03:45.065594  9519 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1005 14:03:50.315707  9519 solver.cpp:218] Iteration 68800 (19.0473 iter/s, 5.2501s/100 iters), loss = 0.0366871
I1005 14:03:50.315739  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366874 (* 1 = 0.0366874 loss)
I1005 14:03:50.315745  9519 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1005 14:03:55.572805  9519 solver.cpp:218] Iteration 68900 (19.0221 iter/s, 5.25705s/100 iters), loss = 0.0175459
I1005 14:03:55.572836  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175462 (* 1 = 0.0175462 loss)
I1005 14:03:55.572852  9519 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1005 14:04:00.580549  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:04:00.790534  9519 solver.cpp:330] Iteration 69000, Testing net (#0)
I1005 14:04:01.976907  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:04:02.026501  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8908
I1005 14:04:02.026540  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427365 (* 1 = 0.427365 loss)
I1005 14:04:02.078935  9519 solver.cpp:218] Iteration 69000 (15.3702 iter/s, 6.50608s/100 iters), loss = 0.0120893
I1005 14:04:02.078963  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120896 (* 1 = 0.0120896 loss)
I1005 14:04:02.078969  9519 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1005 14:04:07.347661  9519 solver.cpp:218] Iteration 69100 (18.9801 iter/s, 5.26868s/100 iters), loss = 0.0345332
I1005 14:04:07.347692  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345335 (* 1 = 0.0345335 loss)
I1005 14:04:07.347697  9519 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1005 14:04:12.617594  9519 solver.cpp:218] Iteration 69200 (18.9758 iter/s, 5.26988s/100 iters), loss = 0.0137363
I1005 14:04:12.617625  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137365 (* 1 = 0.0137365 loss)
I1005 14:04:12.617632  9519 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1005 14:04:17.888890  9519 solver.cpp:218] Iteration 69300 (18.9709 iter/s, 5.27124s/100 iters), loss = 0.0228538
I1005 14:04:17.888934  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228541 (* 1 = 0.0228541 loss)
I1005 14:04:17.888942  9519 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1005 14:04:23.144821  9519 solver.cpp:218] Iteration 69400 (19.0267 iter/s, 5.25578s/100 iters), loss = 0.0214489
I1005 14:04:23.144853  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214492 (* 1 = 0.0214492 loss)
I1005 14:04:23.144860  9519 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1005 14:04:28.149720  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:04:28.358939  9519 solver.cpp:330] Iteration 69500, Testing net (#0)
I1005 14:04:29.545732  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:04:29.595341  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8956
I1005 14:04:29.595377  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420926 (* 1 = 0.420926 loss)
I1005 14:04:29.648751  9519 solver.cpp:218] Iteration 69500 (15.3754 iter/s, 6.50388s/100 iters), loss = 0.0443053
I1005 14:04:29.648785  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443056 (* 1 = 0.0443056 loss)
I1005 14:04:29.648792  9519 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1005 14:04:34.905375  9519 solver.cpp:218] Iteration 69600 (19.0238 iter/s, 5.25657s/100 iters), loss = 0.00496849
I1005 14:04:34.905515  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496876 (* 1 = 0.00496876 loss)
I1005 14:04:34.905522  9519 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1005 14:04:40.169776  9519 solver.cpp:218] Iteration 69700 (18.996 iter/s, 5.26425s/100 iters), loss = 0.00645705
I1005 14:04:40.169806  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064573 (* 1 = 0.0064573 loss)
I1005 14:04:40.169812  9519 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1005 14:04:45.433138  9519 solver.cpp:218] Iteration 69800 (18.9994 iter/s, 5.26331s/100 iters), loss = 0.0128095
I1005 14:04:45.433168  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128098 (* 1 = 0.0128098 loss)
I1005 14:04:45.433174  9519 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1005 14:04:50.690382  9519 solver.cpp:218] Iteration 69900 (19.0216 iter/s, 5.25718s/100 iters), loss = 0.0113009
I1005 14:04:50.690431  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113011 (* 1 = 0.0113011 loss)
I1005 14:04:50.690439  9519 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1005 14:04:55.695724  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:04:55.905757  9519 solver.cpp:330] Iteration 70000, Testing net (#0)
I1005 14:04:57.099545  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:04:57.149410  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8937
I1005 14:04:57.149435  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.423473 (* 1 = 0.423473 loss)
I1005 14:04:57.201234  9519 solver.cpp:218] Iteration 70000 (15.3593 iter/s, 6.51073s/100 iters), loss = 0.0173616
I1005 14:04:57.201267  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173619 (* 1 = 0.0173619 loss)
I1005 14:04:57.201274  9519 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1005 14:05:02.461406  9519 solver.cpp:218] Iteration 70100 (19.011 iter/s, 5.26012s/100 iters), loss = 0.0477142
I1005 14:05:02.461448  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477144 (* 1 = 0.0477144 loss)
I1005 14:05:02.461454  9519 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1005 14:05:07.725256  9519 solver.cpp:218] Iteration 70200 (18.9977 iter/s, 5.26379s/100 iters), loss = 0.0204767
I1005 14:05:07.725364  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204769 (* 1 = 0.0204769 loss)
I1005 14:05:07.725373  9519 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1005 14:05:12.992662  9519 solver.cpp:218] Iteration 70300 (18.9851 iter/s, 5.26728s/100 iters), loss = 0.050623
I1005 14:05:12.992693  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0506232 (* 1 = 0.0506232 loss)
I1005 14:05:12.992699  9519 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1005 14:05:18.250075  9519 solver.cpp:218] Iteration 70400 (19.0209 iter/s, 5.25737s/100 iters), loss = 0.0105693
I1005 14:05:18.250107  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105695 (* 1 = 0.0105695 loss)
I1005 14:05:18.250113  9519 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1005 14:05:23.247090  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:05:23.457644  9519 solver.cpp:330] Iteration 70500, Testing net (#0)
I1005 14:05:24.652786  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:05:24.702853  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8895
I1005 14:05:24.702878  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.453844 (* 1 = 0.453844 loss)
I1005 14:05:24.755275  9519 solver.cpp:218] Iteration 70500 (15.3724 iter/s, 6.50515s/100 iters), loss = 0.0218454
I1005 14:05:24.755300  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218456 (* 1 = 0.0218456 loss)
I1005 14:05:24.755306  9519 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1005 14:05:30.017120  9519 solver.cpp:218] Iteration 70600 (19.0049 iter/s, 5.2618s/100 iters), loss = 0.0118529
I1005 14:05:30.017153  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118531 (* 1 = 0.0118531 loss)
I1005 14:05:30.017169  9519 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1005 14:05:35.274963  9519 solver.cpp:218] Iteration 70700 (19.0194 iter/s, 5.25779s/100 iters), loss = 0.0179629
I1005 14:05:35.274996  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179631 (* 1 = 0.0179631 loss)
I1005 14:05:35.275002  9519 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1005 14:05:40.539626  9519 solver.cpp:218] Iteration 70800 (18.9947 iter/s, 5.26461s/100 iters), loss = 0.0166349
I1005 14:05:40.539763  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166351 (* 1 = 0.0166351 loss)
I1005 14:05:40.539782  9519 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1005 14:05:45.802711  9519 solver.cpp:218] Iteration 70900 (19.0008 iter/s, 5.26295s/100 iters), loss = 0.0182797
I1005 14:05:45.802747  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182799 (* 1 = 0.0182799 loss)
I1005 14:05:45.802765  9519 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1005 14:05:50.810412  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:05:51.023159  9519 solver.cpp:330] Iteration 71000, Testing net (#0)
I1005 14:05:52.211189  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:05:52.261041  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8947
I1005 14:05:52.261075  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.428365 (* 1 = 0.428365 loss)
I1005 14:05:52.313638  9519 solver.cpp:218] Iteration 71000 (15.3589 iter/s, 6.51088s/100 iters), loss = 0.00941245
I1005 14:05:52.313673  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00941267 (* 1 = 0.00941267 loss)
I1005 14:05:52.313679  9519 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1005 14:05:57.582079  9519 solver.cpp:218] Iteration 71100 (18.9811 iter/s, 5.26839s/100 iters), loss = 0.0292432
I1005 14:05:57.582120  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292434 (* 1 = 0.0292434 loss)
I1005 14:05:57.582126  9519 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1005 14:06:02.850059  9519 solver.cpp:218] Iteration 71200 (18.9829 iter/s, 5.26791s/100 iters), loss = 0.0168094
I1005 14:06:02.850093  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168096 (* 1 = 0.0168096 loss)
I1005 14:06:02.850100  9519 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1005 14:06:08.105360  9519 solver.cpp:218] Iteration 71300 (19.0286 iter/s, 5.25525s/100 iters), loss = 0.0119089
I1005 14:06:08.105389  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119092 (* 1 = 0.0119092 loss)
I1005 14:06:08.105396  9519 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1005 14:06:13.365476  9519 solver.cpp:218] Iteration 71400 (19.0112 iter/s, 5.26007s/100 iters), loss = 0.0322561
I1005 14:06:13.365607  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322563 (* 1 = 0.0322563 loss)
I1005 14:06:13.365623  9519 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1005 14:06:18.365622  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:06:18.575551  9519 solver.cpp:330] Iteration 71500, Testing net (#0)
I1005 14:06:19.761380  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:06:19.811187  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8862
I1005 14:06:19.811213  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477556 (* 1 = 0.477556 loss)
I1005 14:06:19.863334  9519 solver.cpp:218] Iteration 71500 (15.39 iter/s, 6.49771s/100 iters), loss = 0.0202714
I1005 14:06:19.863361  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202716 (* 1 = 0.0202716 loss)
I1005 14:06:19.863368  9519 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1005 14:06:25.131373  9519 solver.cpp:218] Iteration 71600 (18.9826 iter/s, 5.26799s/100 iters), loss = 0.00329816
I1005 14:06:25.131414  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00329837 (* 1 = 0.00329837 loss)
I1005 14:06:25.131422  9519 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1005 14:06:30.397106  9519 solver.cpp:218] Iteration 71700 (18.9909 iter/s, 5.26567s/100 iters), loss = 0.0733338
I1005 14:06:30.397146  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.073334 (* 1 = 0.073334 loss)
I1005 14:06:30.397152  9519 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1005 14:06:35.654732  9519 solver.cpp:218] Iteration 71800 (19.0202 iter/s, 5.25757s/100 iters), loss = 0.0442018
I1005 14:06:35.654770  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044202 (* 1 = 0.044202 loss)
I1005 14:06:35.654778  9519 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1005 14:06:40.913501  9519 solver.cpp:218] Iteration 71900 (19.0161 iter/s, 5.25871s/100 iters), loss = 0.0485587
I1005 14:06:40.913542  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485589 (* 1 = 0.0485589 loss)
I1005 14:06:40.913548  9519 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1005 14:06:45.920030  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:06:46.129564  9519 solver.cpp:330] Iteration 72000, Testing net (#0)
I1005 14:06:47.315819  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:06:47.366003  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I1005 14:06:47.366029  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.417537 (* 1 = 0.417537 loss)
I1005 14:06:47.418453  9519 solver.cpp:218] Iteration 72000 (15.373 iter/s, 6.5049s/100 iters), loss = 0.0145865
I1005 14:06:47.418483  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145867 (* 1 = 0.0145867 loss)
I1005 14:06:47.418489  9519 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1005 14:06:52.688390  9519 solver.cpp:218] Iteration 72100 (18.9757 iter/s, 5.26989s/100 iters), loss = 0.0133629
I1005 14:06:52.688431  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133631 (* 1 = 0.0133631 loss)
I1005 14:06:52.688436  9519 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1005 14:06:57.948096  9519 solver.cpp:218] Iteration 72200 (19.0127 iter/s, 5.25965s/100 iters), loss = 0.0120774
I1005 14:06:57.948125  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120776 (* 1 = 0.0120776 loss)
I1005 14:06:57.948132  9519 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1005 14:07:03.211251  9519 solver.cpp:218] Iteration 72300 (19.0002 iter/s, 5.2631s/100 iters), loss = 0.0216477
I1005 14:07:03.211282  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216479 (* 1 = 0.0216479 loss)
I1005 14:07:03.211288  9519 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1005 14:07:08.461161  9519 solver.cpp:218] Iteration 72400 (19.0481 iter/s, 5.24986s/100 iters), loss = 0.012152
I1005 14:07:08.461190  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121522 (* 1 = 0.0121522 loss)
I1005 14:07:08.461197  9519 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1005 14:07:13.462548  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:07:13.672847  9519 solver.cpp:330] Iteration 72500, Testing net (#0)
I1005 14:07:14.867808  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:07:14.917891  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8847
I1005 14:07:14.917928  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.478502 (* 1 = 0.478502 loss)
I1005 14:07:14.970408  9519 solver.cpp:218] Iteration 72500 (15.3629 iter/s, 6.5092s/100 iters), loss = 0.0439515
I1005 14:07:14.970440  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439517 (* 1 = 0.0439517 loss)
I1005 14:07:14.970448  9519 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1005 14:07:20.226687  9519 solver.cpp:218] Iteration 72600 (19.025 iter/s, 5.25623s/100 iters), loss = 0.0109937
I1005 14:07:20.226855  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109939 (* 1 = 0.0109939 loss)
I1005 14:07:20.226863  9519 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1005 14:07:25.493563  9519 solver.cpp:218] Iteration 72700 (18.9872 iter/s, 5.26671s/100 iters), loss = 0.047442
I1005 14:07:25.493595  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474422 (* 1 = 0.0474422 loss)
I1005 14:07:25.493611  9519 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1005 14:07:30.759227  9519 solver.cpp:218] Iteration 72800 (18.9911 iter/s, 5.26561s/100 iters), loss = 0.0100787
I1005 14:07:30.759256  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100789 (* 1 = 0.0100789 loss)
I1005 14:07:30.759263  9519 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1005 14:07:36.024165  9519 solver.cpp:218] Iteration 72900 (18.9937 iter/s, 5.26489s/100 iters), loss = 0.00623785
I1005 14:07:36.024200  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623805 (* 1 = 0.00623805 loss)
I1005 14:07:36.024207  9519 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1005 14:07:41.021375  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:07:41.231389  9519 solver.cpp:330] Iteration 73000, Testing net (#0)
I1005 14:07:42.426636  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:07:42.476390  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.896
I1005 14:07:42.476428  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412069 (* 1 = 0.412069 loss)
I1005 14:07:42.529122  9519 solver.cpp:218] Iteration 73000 (15.373 iter/s, 6.5049s/100 iters), loss = 0.0213283
I1005 14:07:42.529155  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213285 (* 1 = 0.0213285 loss)
I1005 14:07:42.529162  9519 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1005 14:07:47.790573  9519 solver.cpp:218] Iteration 73100 (19.0064 iter/s, 5.2614s/100 iters), loss = 0.0218282
I1005 14:07:47.790607  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218285 (* 1 = 0.0218285 loss)
I1005 14:07:47.790616  9519 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1005 14:07:53.046762  9519 solver.cpp:218] Iteration 73200 (19.0254 iter/s, 5.25614s/100 iters), loss = 0.0349655
I1005 14:07:53.046875  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349657 (* 1 = 0.0349657 loss)
I1005 14:07:53.046885  9519 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1005 14:07:58.315451  9519 solver.cpp:218] Iteration 73300 (18.9805 iter/s, 5.26857s/100 iters), loss = 0.0207199
I1005 14:07:58.315480  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207201 (* 1 = 0.0207201 loss)
I1005 14:07:58.315487  9519 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1005 14:08:03.573253  9519 solver.cpp:218] Iteration 73400 (19.0195 iter/s, 5.25775s/100 iters), loss = 0.0305175
I1005 14:08:03.573283  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305177 (* 1 = 0.0305177 loss)
I1005 14:08:03.573289  9519 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1005 14:08:08.566666  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:08:08.782073  9519 solver.cpp:330] Iteration 73500, Testing net (#0)
I1005 14:08:09.971962  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:08:10.020949  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8886
I1005 14:08:10.020983  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.472389 (* 1 = 0.472389 loss)
I1005 14:08:10.073523  9519 solver.cpp:218] Iteration 73500 (15.3841 iter/s, 6.50023s/100 iters), loss = 0.00577462
I1005 14:08:10.073549  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00577485 (* 1 = 0.00577485 loss)
I1005 14:08:10.073555  9519 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1005 14:08:15.344280  9519 solver.cpp:218] Iteration 73600 (18.9728 iter/s, 5.27071s/100 iters), loss = 0.0203243
I1005 14:08:15.344321  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203245 (* 1 = 0.0203245 loss)
I1005 14:08:15.344327  9519 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1005 14:08:20.601390  9519 solver.cpp:218] Iteration 73700 (19.0221 iter/s, 5.25705s/100 iters), loss = 0.0283323
I1005 14:08:20.601423  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283325 (* 1 = 0.0283325 loss)
I1005 14:08:20.601428  9519 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1005 14:08:25.871548  9519 solver.cpp:218] Iteration 73800 (18.9749 iter/s, 5.27011s/100 iters), loss = 0.0116028
I1005 14:08:25.871673  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116031 (* 1 = 0.0116031 loss)
I1005 14:08:25.871683  9519 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1005 14:08:31.134687  9519 solver.cpp:218] Iteration 73900 (19.0006 iter/s, 5.263s/100 iters), loss = 0.0577856
I1005 14:08:31.134727  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577858 (* 1 = 0.0577858 loss)
I1005 14:08:31.134733  9519 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1005 14:08:36.138098  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:08:36.348074  9519 solver.cpp:330] Iteration 74000, Testing net (#0)
I1005 14:08:37.533980  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:08:37.583947  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8984
I1005 14:08:37.583983  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426211 (* 1 = 0.426211 loss)
I1005 14:08:37.636701  9519 solver.cpp:218] Iteration 74000 (15.38 iter/s, 6.50196s/100 iters), loss = 0.0236632
I1005 14:08:37.636734  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236634 (* 1 = 0.0236634 loss)
I1005 14:08:37.636741  9519 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1005 14:08:42.902146  9519 solver.cpp:218] Iteration 74100 (18.9919 iter/s, 5.26539s/100 iters), loss = 0.0288988
I1005 14:08:42.902186  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028899 (* 1 = 0.028899 loss)
I1005 14:08:42.902192  9519 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1005 14:08:48.170003  9519 solver.cpp:218] Iteration 74200 (18.9833 iter/s, 5.2678s/100 iters), loss = 0.00453577
I1005 14:08:48.170035  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004536 (* 1 = 0.004536 loss)
I1005 14:08:48.170042  9519 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1005 14:08:53.427428  9519 solver.cpp:218] Iteration 74300 (19.0209 iter/s, 5.25738s/100 iters), loss = 0.00327165
I1005 14:08:53.427460  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327187 (* 1 = 0.00327187 loss)
I1005 14:08:53.427466  9519 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1005 14:08:58.691753  9519 solver.cpp:218] Iteration 74400 (18.996 iter/s, 5.26428s/100 iters), loss = 0.0313684
I1005 14:08:58.691885  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313686 (* 1 = 0.0313686 loss)
I1005 14:08:58.691892  9519 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1005 14:09:03.699319  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:09:03.908751  9519 solver.cpp:330] Iteration 74500, Testing net (#0)
I1005 14:09:05.093710  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:09:05.143059  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8923
I1005 14:09:05.143095  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427612 (* 1 = 0.427612 loss)
I1005 14:09:05.195297  9519 solver.cpp:218] Iteration 74500 (15.3766 iter/s, 6.5034s/100 iters), loss = 0.0107872
I1005 14:09:05.195328  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107874 (* 1 = 0.0107874 loss)
I1005 14:09:05.195335  9519 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1005 14:09:10.460391  9519 solver.cpp:218] Iteration 74600 (18.9932 iter/s, 5.26505s/100 iters), loss = 0.013506
I1005 14:09:10.460420  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135062 (* 1 = 0.0135062 loss)
I1005 14:09:10.460425  9519 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1005 14:09:15.727176  9519 solver.cpp:218] Iteration 74700 (18.9871 iter/s, 5.26674s/100 iters), loss = 0.0178618
I1005 14:09:15.727205  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017862 (* 1 = 0.017862 loss)
I1005 14:09:15.727222  9519 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1005 14:09:20.993350  9519 solver.cpp:218] Iteration 74800 (18.9893 iter/s, 5.26613s/100 iters), loss = 0.0321216
I1005 14:09:20.993391  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321218 (* 1 = 0.0321218 loss)
I1005 14:09:20.993397  9519 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1005 14:09:26.247699  9519 solver.cpp:218] Iteration 74900 (19.0321 iter/s, 5.25429s/100 iters), loss = 0.00626749
I1005 14:09:26.247730  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00626767 (* 1 = 0.00626767 loss)
I1005 14:09:26.247736  9519 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1005 14:09:31.252866  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:09:31.464028  9519 solver.cpp:330] Iteration 75000, Testing net (#0)
I1005 14:09:32.650274  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:09:32.701625  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.899
I1005 14:09:32.701663  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.416401 (* 1 = 0.416401 loss)
I1005 14:09:32.755518  9519 solver.cpp:218] Iteration 75000 (15.3663 iter/s, 6.50777s/100 iters), loss = 0.0384101
I1005 14:09:32.755571  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384103 (* 1 = 0.0384103 loss)
I1005 14:09:32.755589  9519 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1005 14:09:38.011981  9519 solver.cpp:218] Iteration 75100 (19.0245 iter/s, 5.25637s/100 iters), loss = 0.0367281
I1005 14:09:38.012012  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367282 (* 1 = 0.0367282 loss)
I1005 14:09:38.012017  9519 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1005 14:09:43.277094  9519 solver.cpp:218] Iteration 75200 (18.9931 iter/s, 5.26506s/100 iters), loss = 0.00879254
I1005 14:09:43.277146  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087927 (* 1 = 0.0087927 loss)
I1005 14:09:43.277153  9519 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1005 14:09:48.545054  9519 solver.cpp:218] Iteration 75300 (18.9829 iter/s, 5.26789s/100 iters), loss = 0.0111824
I1005 14:09:48.545083  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111826 (* 1 = 0.0111826 loss)
I1005 14:09:48.545089  9519 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1005 14:09:53.796141  9519 solver.cpp:218] Iteration 75400 (19.0439 iter/s, 5.25103s/100 iters), loss = 0.00328478
I1005 14:09:53.796180  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328495 (* 1 = 0.00328495 loss)
I1005 14:09:53.796187  9519 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1005 14:09:58.796108  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:09:59.006011  9519 solver.cpp:330] Iteration 75500, Testing net (#0)
I1005 14:10:00.201066  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:10:00.250952  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.892
I1005 14:10:00.250978  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.45035 (* 1 = 0.45035 loss)
I1005 14:10:00.303596  9519 solver.cpp:218] Iteration 75500 (15.3671 iter/s, 6.5074s/100 iters), loss = 0.0366102
I1005 14:10:00.303624  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366104 (* 1 = 0.0366104 loss)
I1005 14:10:00.303632  9519 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1005 14:10:05.556610  9519 solver.cpp:218] Iteration 75600 (19.0369 iter/s, 5.25296s/100 iters), loss = 0.0285402
I1005 14:10:05.556752  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285404 (* 1 = 0.0285404 loss)
I1005 14:10:05.556773  9519 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1005 14:10:10.817265  9519 solver.cpp:218] Iteration 75700 (19.0096 iter/s, 5.2605s/100 iters), loss = 0.0217814
I1005 14:10:10.817293  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217815 (* 1 = 0.0217815 loss)
I1005 14:10:10.817299  9519 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1005 14:10:16.081720  9519 solver.cpp:218] Iteration 75800 (18.9955 iter/s, 5.26441s/100 iters), loss = 0.0243082
I1005 14:10:16.081753  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243084 (* 1 = 0.0243084 loss)
I1005 14:10:16.081759  9519 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1005 14:10:21.338531  9519 solver.cpp:218] Iteration 75900 (19.0231 iter/s, 5.25675s/100 iters), loss = 0.0215997
I1005 14:10:21.338562  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215999 (* 1 = 0.0215999 loss)
I1005 14:10:21.338568  9519 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1005 14:10:26.332484  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:10:26.543009  9519 solver.cpp:330] Iteration 76000, Testing net (#0)
I1005 14:10:27.740991  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:10:27.790385  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I1005 14:10:27.790410  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424005 (* 1 = 0.424005 loss)
I1005 14:10:27.842548  9519 solver.cpp:218] Iteration 76000 (15.3752 iter/s, 6.50397s/100 iters), loss = 0.0179893
I1005 14:10:27.842574  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179895 (* 1 = 0.0179895 loss)
I1005 14:10:27.842581  9519 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1005 14:10:33.109308  9519 solver.cpp:218] Iteration 76100 (18.9872 iter/s, 5.26672s/100 iters), loss = 0.0147592
I1005 14:10:33.109340  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147594 (* 1 = 0.0147594 loss)
I1005 14:10:33.109347  9519 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1005 14:10:38.364537  9519 solver.cpp:218] Iteration 76200 (19.0288 iter/s, 5.25518s/100 iters), loss = 0.0100621
I1005 14:10:38.364652  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100623 (* 1 = 0.0100623 loss)
I1005 14:10:38.364660  9519 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1005 14:10:43.631086  9519 solver.cpp:218] Iteration 76300 (18.9882 iter/s, 5.26642s/100 iters), loss = 0.0215258
I1005 14:10:43.631127  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215259 (* 1 = 0.0215259 loss)
I1005 14:10:43.631134  9519 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1005 14:10:48.891480  9519 solver.cpp:218] Iteration 76400 (19.0102 iter/s, 5.26034s/100 iters), loss = 0.0121965
I1005 14:10:48.891513  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121967 (* 1 = 0.0121967 loss)
I1005 14:10:48.891532  9519 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1005 14:10:53.893671  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:10:54.104585  9519 solver.cpp:330] Iteration 76500, Testing net (#0)
I1005 14:10:55.292733  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:10:55.342850  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8937
I1005 14:10:55.342878  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444122 (* 1 = 0.444122 loss)
I1005 14:10:55.395289  9519 solver.cpp:218] Iteration 76500 (15.3757 iter/s, 6.50376s/100 iters), loss = 0.0207616
I1005 14:10:55.395320  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207618 (* 1 = 0.0207618 loss)
I1005 14:10:55.395330  9519 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1005 14:11:00.663671  9519 solver.cpp:218] Iteration 76600 (18.9813 iter/s, 5.26833s/100 iters), loss = 0.0242002
I1005 14:11:00.663705  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242004 (* 1 = 0.0242004 loss)
I1005 14:11:00.663724  9519 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1005 14:11:05.926751  9519 solver.cpp:218] Iteration 76700 (19.0005 iter/s, 5.26302s/100 iters), loss = 0.0193921
I1005 14:11:05.926798  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193923 (* 1 = 0.0193923 loss)
I1005 14:11:05.926818  9519 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1005 14:11:11.190309  9519 solver.cpp:218] Iteration 76800 (18.9989 iter/s, 5.26347s/100 iters), loss = 0.0143271
I1005 14:11:11.190479  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143272 (* 1 = 0.0143272 loss)
I1005 14:11:11.190500  9519 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1005 14:11:16.451571  9519 solver.cpp:218] Iteration 76900 (19.0074 iter/s, 5.2611s/100 iters), loss = 0.0601158
I1005 14:11:16.451601  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.060116 (* 1 = 0.060116 loss)
I1005 14:11:16.451607  9519 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1005 14:11:21.458115  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:11:21.667665  9519 solver.cpp:330] Iteration 77000, Testing net (#0)
I1005 14:11:22.854286  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:11:22.903957  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8938
I1005 14:11:22.903992  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.440577 (* 1 = 0.440577 loss)
I1005 14:11:22.956214  9519 solver.cpp:218] Iteration 77000 (15.3737 iter/s, 6.5046s/100 iters), loss = 0.0153939
I1005 14:11:22.956244  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153941 (* 1 = 0.0153941 loss)
I1005 14:11:22.956251  9519 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1005 14:11:28.225028  9519 solver.cpp:218] Iteration 77100 (18.9798 iter/s, 5.26876s/100 iters), loss = 0.00643808
I1005 14:11:28.225067  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643825 (* 1 = 0.00643825 loss)
I1005 14:11:28.225073  9519 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1005 14:11:33.489151  9519 solver.cpp:218] Iteration 77200 (18.9967 iter/s, 5.26407s/100 iters), loss = 0.0381653
I1005 14:11:33.489181  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381655 (* 1 = 0.0381655 loss)
I1005 14:11:33.489188  9519 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1005 14:11:38.747674  9519 solver.cpp:218] Iteration 77300 (19.0169 iter/s, 5.25847s/100 iters), loss = 0.00868579
I1005 14:11:38.747710  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868594 (* 1 = 0.00868594 loss)
I1005 14:11:38.747717  9519 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1005 14:11:44.000417  9519 solver.cpp:218] Iteration 77400 (19.0379 iter/s, 5.25269s/100 iters), loss = 0.0718718
I1005 14:11:44.000519  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0718719 (* 1 = 0.0718719 loss)
I1005 14:11:44.000527  9519 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1005 14:11:49.001371  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:11:49.211354  9519 solver.cpp:330] Iteration 77500, Testing net (#0)
I1005 14:11:50.397867  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:11:50.447700  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8916
I1005 14:11:50.447736  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426155 (* 1 = 0.426155 loss)
I1005 14:11:50.499827  9519 solver.cpp:218] Iteration 77500 (15.3863 iter/s, 6.49929s/100 iters), loss = 0.0329258
I1005 14:11:50.499858  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032926 (* 1 = 0.032926 loss)
I1005 14:11:50.499866  9519 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1005 14:11:55.761332  9519 solver.cpp:218] Iteration 77600 (19.0061 iter/s, 5.26146s/100 iters), loss = 0.0226922
I1005 14:11:55.761373  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226923 (* 1 = 0.0226923 loss)
I1005 14:11:55.761379  9519 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1005 14:12:01.030728  9519 solver.cpp:218] Iteration 77700 (18.9777 iter/s, 5.26934s/100 iters), loss = 0.0066568
I1005 14:12:01.030768  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665694 (* 1 = 0.00665694 loss)
I1005 14:12:01.030774  9519 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1005 14:12:06.296353  9519 solver.cpp:218] Iteration 77800 (18.9913 iter/s, 5.26557s/100 iters), loss = 0.0137819
I1005 14:12:06.296396  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013782 (* 1 = 0.013782 loss)
I1005 14:12:06.296401  9519 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1005 14:12:11.547356  9519 solver.cpp:218] Iteration 77900 (19.0442 iter/s, 5.25094s/100 iters), loss = 0.0191788
I1005 14:12:11.547397  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191789 (* 1 = 0.0191789 loss)
I1005 14:12:11.547404  9519 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1005 14:12:16.553939  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:12:16.763418  9519 solver.cpp:330] Iteration 78000, Testing net (#0)
I1005 14:12:17.958170  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:12:18.007851  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8906
I1005 14:12:18.007887  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.491192 (* 1 = 0.491192 loss)
I1005 14:12:18.060257  9519 solver.cpp:218] Iteration 78000 (15.3543 iter/s, 6.51284s/100 iters), loss = 0.0269235
I1005 14:12:18.060290  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269236 (* 1 = 0.0269236 loss)
I1005 14:12:18.060297  9519 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1005 14:12:23.320109  9519 solver.cpp:218] Iteration 78100 (19.0121 iter/s, 5.2598s/100 iters), loss = 0.0427641
I1005 14:12:23.320142  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427642 (* 1 = 0.0427642 loss)
I1005 14:12:23.320147  9519 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1005 14:12:28.588304  9519 solver.cpp:218] Iteration 78200 (18.982 iter/s, 5.26815s/100 iters), loss = 0.080209
I1005 14:12:28.588342  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0802092 (* 1 = 0.0802092 loss)
I1005 14:12:28.588348  9519 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1005 14:12:33.854281  9519 solver.cpp:218] Iteration 78300 (18.99 iter/s, 5.26592s/100 iters), loss = 0.0229888
I1005 14:12:33.854322  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229889 (* 1 = 0.0229889 loss)
I1005 14:12:33.854328  9519 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1005 14:12:39.114722  9519 solver.cpp:218] Iteration 78400 (19.01 iter/s, 5.26038s/100 iters), loss = 0.0164389
I1005 14:12:39.114764  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164391 (* 1 = 0.0164391 loss)
I1005 14:12:39.114770  9519 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1005 14:12:44.108325  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:12:44.319309  9519 solver.cpp:330] Iteration 78500, Testing net (#0)
I1005 14:12:45.511289  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:12:45.561090  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8859
I1005 14:12:45.561125  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.504731 (* 1 = 0.504731 loss)
I1005 14:12:45.613469  9519 solver.cpp:218] Iteration 78500 (15.3877 iter/s, 6.49869s/100 iters), loss = 0.0479641
I1005 14:12:45.613497  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479642 (* 1 = 0.0479642 loss)
I1005 14:12:45.613504  9519 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1005 14:12:50.877943  9519 solver.cpp:218] Iteration 78600 (18.9954 iter/s, 5.26442s/100 iters), loss = 0.0124441
I1005 14:12:50.878079  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124442 (* 1 = 0.0124442 loss)
I1005 14:12:50.878089  9519 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1005 14:12:56.136137  9519 solver.cpp:218] Iteration 78700 (19.0186 iter/s, 5.25802s/100 iters), loss = 0.0271246
I1005 14:12:56.136171  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271248 (* 1 = 0.0271248 loss)
I1005 14:12:56.136181  9519 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1005 14:13:01.402871  9519 solver.cpp:218] Iteration 78800 (18.9873 iter/s, 5.26669s/100 iters), loss = 0.0176382
I1005 14:13:01.402912  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176383 (* 1 = 0.0176383 loss)
I1005 14:13:01.402918  9519 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1005 14:13:06.664523  9519 solver.cpp:218] Iteration 78900 (19.0057 iter/s, 5.26159s/100 iters), loss = 0.0429548
I1005 14:13:06.664564  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429549 (* 1 = 0.0429549 loss)
I1005 14:13:06.664571  9519 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1005 14:13:11.666985  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:13:11.884250  9519 solver.cpp:330] Iteration 79000, Testing net (#0)
I1005 14:13:13.071333  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:13:13.121053  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I1005 14:13:13.121089  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.432587 (* 1 = 0.432587 loss)
I1005 14:13:13.173553  9519 solver.cpp:218] Iteration 79000 (15.3634 iter/s, 6.50897s/100 iters), loss = 0.054775
I1005 14:13:13.173578  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0547751 (* 1 = 0.0547751 loss)
I1005 14:13:13.173585  9519 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1005 14:13:18.435915  9519 solver.cpp:218] Iteration 79100 (19.003 iter/s, 5.26232s/100 iters), loss = 0.014438
I1005 14:13:18.435945  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144381 (* 1 = 0.0144381 loss)
I1005 14:13:18.435951  9519 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1005 14:13:23.692616  9519 solver.cpp:218] Iteration 79200 (19.0235 iter/s, 5.25665s/100 iters), loss = 0.0128776
I1005 14:13:23.692719  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128777 (* 1 = 0.0128777 loss)
I1005 14:13:23.692741  9519 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1005 14:13:28.953652  9519 solver.cpp:218] Iteration 79300 (19.0082 iter/s, 5.2609s/100 iters), loss = 0.0297842
I1005 14:13:28.953687  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297843 (* 1 = 0.0297843 loss)
I1005 14:13:28.953696  9519 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1005 14:13:34.213881  9519 solver.cpp:218] Iteration 79400 (19.0108 iter/s, 5.26018s/100 iters), loss = 0.0242708
I1005 14:13:34.213912  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242709 (* 1 = 0.0242709 loss)
I1005 14:13:34.213918  9519 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1005 14:13:39.220346  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:13:39.430641  9519 solver.cpp:330] Iteration 79500, Testing net (#0)
I1005 14:13:40.617264  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:13:40.667084  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8929
I1005 14:13:40.667109  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.437052 (* 1 = 0.437052 loss)
I1005 14:13:40.719511  9519 solver.cpp:218] Iteration 79500 (15.3714 iter/s, 6.50558s/100 iters), loss = 0.0645786
I1005 14:13:40.719544  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0645787 (* 1 = 0.0645787 loss)
I1005 14:13:40.719552  9519 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1005 14:13:45.985939  9519 solver.cpp:218] Iteration 79600 (18.9884 iter/s, 5.26638s/100 iters), loss = 0.00987967
I1005 14:13:45.985980  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00987977 (* 1 = 0.00987977 loss)
I1005 14:13:45.985986  9519 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1005 14:13:51.251442  9519 solver.cpp:218] Iteration 79700 (18.9917 iter/s, 5.26544s/100 iters), loss = 0.0464785
I1005 14:13:51.251484  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464786 (* 1 = 0.0464786 loss)
I1005 14:13:51.251492  9519 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1005 14:13:56.514808  9519 solver.cpp:218] Iteration 79800 (18.9995 iter/s, 5.26331s/100 iters), loss = 0.0160006
I1005 14:13:56.514919  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160007 (* 1 = 0.0160007 loss)
I1005 14:13:56.514927  9519 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1005 14:14:01.775339  9519 solver.cpp:218] Iteration 79900 (19.0099 iter/s, 5.2604s/100 iters), loss = 0.00654881
I1005 14:14:01.775380  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00654894 (* 1 = 0.00654894 loss)
I1005 14:14:01.775387  9519 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1005 14:14:06.779101  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:14:06.989580  9519 solver.cpp:330] Iteration 80000, Testing net (#0)
I1005 14:14:08.175954  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:14:08.225287  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8998
I1005 14:14:08.225313  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413567 (* 1 = 0.413567 loss)
I1005 14:14:08.277835  9519 solver.cpp:218] Iteration 80000 (15.3788 iter/s, 6.50244s/100 iters), loss = 0.00896577
I1005 14:14:08.277868  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0089659 (* 1 = 0.0089659 loss)
I1005 14:14:08.277874  9519 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1005 14:14:08.277878  9519 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1005 14:14:13.547422  9519 solver.cpp:218] Iteration 80100 (18.977 iter/s, 5.26954s/100 iters), loss = 0.0171546
I1005 14:14:13.547463  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171547 (* 1 = 0.0171547 loss)
I1005 14:14:13.547469  9519 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1005 14:14:18.812175  9519 solver.cpp:218] Iteration 80200 (18.9945 iter/s, 5.26469s/100 iters), loss = 0.0276822
I1005 14:14:18.812218  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276824 (* 1 = 0.0276824 loss)
I1005 14:14:18.812225  9519 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1005 14:14:24.080873  9519 solver.cpp:218] Iteration 80300 (18.9802 iter/s, 5.26864s/100 iters), loss = 0.0101248
I1005 14:14:24.080914  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010125 (* 1 = 0.010125 loss)
I1005 14:14:24.080920  9519 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1005 14:14:29.331883  9519 solver.cpp:218] Iteration 80400 (19.0442 iter/s, 5.25095s/100 iters), loss = 0.0115881
I1005 14:14:29.331989  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115882 (* 1 = 0.0115882 loss)
I1005 14:14:29.331996  9519 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1005 14:14:34.339328  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:14:34.549744  9519 solver.cpp:330] Iteration 80500, Testing net (#0)
I1005 14:14:35.740655  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:14:35.791004  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908
I1005 14:14:35.791043  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378112 (* 1 = 0.378112 loss)
I1005 14:14:35.844805  9519 solver.cpp:218] Iteration 80500 (15.3544 iter/s, 6.51281s/100 iters), loss = 0.0096103
I1005 14:14:35.844852  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00961044 (* 1 = 0.00961044 loss)
I1005 14:14:35.844861  9519 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1005 14:14:41.104849  9519 solver.cpp:218] Iteration 80600 (19.0116 iter/s, 5.25994s/100 iters), loss = 0.0180816
I1005 14:14:41.104892  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180817 (* 1 = 0.0180817 loss)
I1005 14:14:41.104898  9519 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1005 14:14:46.373180  9519 solver.cpp:218] Iteration 80700 (18.9816 iter/s, 5.26827s/100 iters), loss = 0.0169534
I1005 14:14:46.373222  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169535 (* 1 = 0.0169535 loss)
I1005 14:14:46.373229  9519 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1005 14:14:51.634819  9519 solver.cpp:218] Iteration 80800 (19.0057 iter/s, 5.26158s/100 iters), loss = 0.00362551
I1005 14:14:51.634851  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362563 (* 1 = 0.00362563 loss)
I1005 14:14:51.634857  9519 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1005 14:14:56.887917  9519 solver.cpp:218] Iteration 80900 (19.0366 iter/s, 5.25305s/100 iters), loss = 0.0070271
I1005 14:14:56.887951  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702722 (* 1 = 0.00702722 loss)
I1005 14:14:56.887959  9519 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1005 14:15:01.887897  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:15:02.098466  9519 solver.cpp:330] Iteration 81000, Testing net (#0)
I1005 14:15:03.289613  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:15:03.339078  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1005 14:15:03.339114  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366682 (* 1 = 0.366682 loss)
I1005 14:15:03.391371  9519 solver.cpp:218] Iteration 81000 (15.3766 iter/s, 6.5034s/100 iters), loss = 0.00369107
I1005 14:15:03.391397  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369118 (* 1 = 0.00369118 loss)
I1005 14:15:03.391404  9519 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1005 14:15:08.649653  9519 solver.cpp:218] Iteration 81100 (19.0178 iter/s, 5.25823s/100 iters), loss = 0.0125752
I1005 14:15:08.649695  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125753 (* 1 = 0.0125753 loss)
I1005 14:15:08.649701  9519 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1005 14:15:13.919035  9519 solver.cpp:218] Iteration 81200 (18.9778 iter/s, 5.26932s/100 iters), loss = 0.00636363
I1005 14:15:13.919076  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636374 (* 1 = 0.00636374 loss)
I1005 14:15:13.919082  9519 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1005 14:15:19.186184  9519 solver.cpp:218] Iteration 81300 (18.9858 iter/s, 5.26709s/100 iters), loss = 0.00429312
I1005 14:15:19.186225  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429323 (* 1 = 0.00429323 loss)
I1005 14:15:19.186231  9519 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1005 14:15:24.452116  9519 solver.cpp:218] Iteration 81400 (18.9902 iter/s, 5.26587s/100 iters), loss = 0.00509413
I1005 14:15:24.452157  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00509424 (* 1 = 0.00509424 loss)
I1005 14:15:24.452163  9519 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1005 14:15:29.453284  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:15:29.663424  9519 solver.cpp:330] Iteration 81500, Testing net (#0)
I1005 14:15:30.858155  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:15:30.907876  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1005 14:15:30.907912  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368161 (* 1 = 0.368161 loss)
I1005 14:15:30.960234  9519 solver.cpp:218] Iteration 81500 (15.3656 iter/s, 6.50806s/100 iters), loss = 0.0111275
I1005 14:15:30.960259  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111276 (* 1 = 0.0111276 loss)
I1005 14:15:30.960265  9519 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1005 14:15:36.228538  9519 solver.cpp:218] Iteration 81600 (18.9816 iter/s, 5.26826s/100 iters), loss = 0.0165059
I1005 14:15:36.228657  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016506 (* 1 = 0.016506 loss)
I1005 14:15:36.228675  9519 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1005 14:15:41.483815  9519 solver.cpp:218] Iteration 81700 (19.029 iter/s, 5.25514s/100 iters), loss = 0.0350335
I1005 14:15:41.483857  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350336 (* 1 = 0.0350336 loss)
I1005 14:15:41.483865  9519 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1005 14:15:46.747593  9519 solver.cpp:218] Iteration 81800 (18.998 iter/s, 5.26372s/100 iters), loss = 0.0162584
I1005 14:15:46.747633  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162585 (* 1 = 0.0162585 loss)
I1005 14:15:46.747639  9519 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1005 14:15:52.007333  9519 solver.cpp:218] Iteration 81900 (19.0125 iter/s, 5.25969s/100 iters), loss = 0.0166379
I1005 14:15:52.007371  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166381 (* 1 = 0.0166381 loss)
I1005 14:15:52.007377  9519 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1005 14:15:57.009161  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:15:57.219377  9519 solver.cpp:330] Iteration 82000, Testing net (#0)
I1005 14:15:58.408183  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:15:58.457983  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1005 14:15:58.458016  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367773 (* 1 = 0.367773 loss)
I1005 14:15:58.510449  9519 solver.cpp:218] Iteration 82000 (15.3774 iter/s, 6.50306s/100 iters), loss = 0.019573
I1005 14:15:58.510476  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195731 (* 1 = 0.0195731 loss)
I1005 14:15:58.510483  9519 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1005 14:16:03.780733  9519 solver.cpp:218] Iteration 82100 (18.9745 iter/s, 5.27024s/100 iters), loss = 0.00591364
I1005 14:16:03.780766  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00591376 (* 1 = 0.00591376 loss)
I1005 14:16:03.780772  9519 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1005 14:16:09.052043  9519 solver.cpp:218] Iteration 82200 (18.9708 iter/s, 5.27126s/100 iters), loss = 0.015204
I1005 14:16:09.052172  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152041 (* 1 = 0.0152041 loss)
I1005 14:16:09.052181  9519 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1005 14:16:14.310603  9519 solver.cpp:218] Iteration 82300 (19.0171 iter/s, 5.25842s/100 iters), loss = 0.0284574
I1005 14:16:14.310636  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284575 (* 1 = 0.0284575 loss)
I1005 14:16:14.310642  9519 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1005 14:16:19.575471  9519 solver.cpp:218] Iteration 82400 (18.994 iter/s, 5.26482s/100 iters), loss = 0.0201752
I1005 14:16:19.575503  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201754 (* 1 = 0.0201754 loss)
I1005 14:16:19.575510  9519 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1005 14:16:24.580217  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:16:24.790755  9519 solver.cpp:330] Iteration 82500, Testing net (#0)
I1005 14:16:25.977437  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:16:26.027156  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1005 14:16:26.027182  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369397 (* 1 = 0.369397 loss)
I1005 14:16:26.079497  9519 solver.cpp:218] Iteration 82500 (15.3752 iter/s, 6.50398s/100 iters), loss = 0.0167046
I1005 14:16:26.079524  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167047 (* 1 = 0.0167047 loss)
I1005 14:16:26.079530  9519 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1005 14:16:31.345086  9519 solver.cpp:218] Iteration 82600 (18.9914 iter/s, 5.26554s/100 iters), loss = 0.031129
I1005 14:16:31.345126  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311292 (* 1 = 0.0311292 loss)
I1005 14:16:31.345134  9519 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1005 14:16:36.609155  9519 solver.cpp:218] Iteration 82700 (18.9969 iter/s, 5.26401s/100 iters), loss = 0.00515954
I1005 14:16:36.609191  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515968 (* 1 = 0.00515968 loss)
I1005 14:16:36.609197  9519 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1005 14:16:41.862462  9519 solver.cpp:218] Iteration 82800 (19.0358 iter/s, 5.25325s/100 iters), loss = 0.0118079
I1005 14:16:41.862627  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011808 (* 1 = 0.011808 loss)
I1005 14:16:41.862645  9519 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1005 14:16:47.121273  9519 solver.cpp:218] Iteration 82900 (19.0165 iter/s, 5.2586s/100 iters), loss = 0.00341544
I1005 14:16:47.121304  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341557 (* 1 = 0.00341557 loss)
I1005 14:16:47.121309  9519 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1005 14:16:52.127897  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:16:52.338011  9519 solver.cpp:330] Iteration 83000, Testing net (#0)
I1005 14:16:53.524852  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:16:53.574622  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1005 14:16:53.574657  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367077 (* 1 = 0.367077 loss)
I1005 14:16:53.627255  9519 solver.cpp:218] Iteration 83000 (15.3706 iter/s, 6.50593s/100 iters), loss = 0.0222113
I1005 14:16:53.627287  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222114 (* 1 = 0.0222114 loss)
I1005 14:16:53.627295  9519 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1005 14:16:58.891679  9519 solver.cpp:218] Iteration 83100 (18.9956 iter/s, 5.26437s/100 iters), loss = 0.0446554
I1005 14:16:58.891719  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446555 (* 1 = 0.0446555 loss)
I1005 14:16:58.891726  9519 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1005 14:17:04.160114  9519 solver.cpp:218] Iteration 83200 (18.9812 iter/s, 5.26838s/100 iters), loss = 0.0103126
I1005 14:17:04.160152  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103127 (* 1 = 0.0103127 loss)
I1005 14:17:04.160158  9519 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1005 14:17:09.431018  9519 solver.cpp:218] Iteration 83300 (18.9723 iter/s, 5.27085s/100 iters), loss = 0.00392618
I1005 14:17:09.431049  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039263 (* 1 = 0.0039263 loss)
I1005 14:17:09.431056  9519 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1005 14:17:14.682371  9519 solver.cpp:218] Iteration 83400 (19.0429 iter/s, 5.2513s/100 iters), loss = 0.00349956
I1005 14:17:14.682505  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349968 (* 1 = 0.00349968 loss)
I1005 14:17:14.682529  9519 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1005 14:17:19.689085  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:17:19.898818  9519 solver.cpp:330] Iteration 83500, Testing net (#0)
I1005 14:17:21.094261  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:17:21.143873  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1005 14:17:21.143910  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364244 (* 1 = 0.364244 loss)
I1005 14:17:21.196389  9519 solver.cpp:218] Iteration 83500 (15.3519 iter/s, 6.51386s/100 iters), loss = 0.00578884
I1005 14:17:21.196421  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00578896 (* 1 = 0.00578896 loss)
I1005 14:17:21.196429  9519 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1005 14:17:26.448899  9519 solver.cpp:218] Iteration 83600 (19.0387 iter/s, 5.25246s/100 iters), loss = 0.0248159
I1005 14:17:26.448930  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024816 (* 1 = 0.024816 loss)
I1005 14:17:26.448935  9519 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1005 14:17:31.709233  9519 solver.cpp:218] Iteration 83700 (19.0104 iter/s, 5.26029s/100 iters), loss = 0.010964
I1005 14:17:31.709264  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109641 (* 1 = 0.0109641 loss)
I1005 14:17:31.709270  9519 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1005 14:17:36.971709  9519 solver.cpp:218] Iteration 83800 (19.0026 iter/s, 5.26243s/100 iters), loss = 0.0116642
I1005 14:17:36.971740  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116643 (* 1 = 0.0116643 loss)
I1005 14:17:36.971748  9519 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1005 14:17:42.234607  9519 solver.cpp:218] Iteration 83900 (19.0011 iter/s, 5.26285s/100 iters), loss = 0.0055894
I1005 14:17:42.234642  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558951 (* 1 = 0.00558951 loss)
I1005 14:17:42.234650  9519 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1005 14:17:47.228461  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:17:47.438905  9519 solver.cpp:330] Iteration 84000, Testing net (#0)
I1005 14:17:48.635308  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:17:48.685353  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9099
I1005 14:17:48.685379  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365697 (* 1 = 0.365697 loss)
I1005 14:17:48.737433  9519 solver.cpp:218] Iteration 84000 (15.3781 iter/s, 6.50277s/100 iters), loss = 0.00600102
I1005 14:17:48.737468  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600112 (* 1 = 0.00600112 loss)
I1005 14:17:48.737478  9519 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1005 14:17:54.006436  9519 solver.cpp:218] Iteration 84100 (18.9791 iter/s, 5.26895s/100 iters), loss = 0.00877596
I1005 14:17:54.006474  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877606 (* 1 = 0.00877606 loss)
I1005 14:17:54.006484  9519 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1005 14:17:59.264834  9519 solver.cpp:218] Iteration 84200 (19.0174 iter/s, 5.25834s/100 iters), loss = 0.0138645
I1005 14:17:59.264876  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138646 (* 1 = 0.0138646 loss)
I1005 14:17:59.264883  9519 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1005 14:18:04.533342  9519 solver.cpp:218] Iteration 84300 (18.9809 iter/s, 5.26844s/100 iters), loss = 0.00388643
I1005 14:18:04.533383  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388655 (* 1 = 0.00388655 loss)
I1005 14:18:04.533390  9519 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1005 14:18:09.796792  9519 solver.cpp:218] Iteration 84400 (18.9992 iter/s, 5.26339s/100 iters), loss = 0.0129903
I1005 14:18:09.796823  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129904 (* 1 = 0.0129904 loss)
I1005 14:18:09.796829  9519 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1005 14:18:14.798633  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:18:15.014031  9519 solver.cpp:330] Iteration 84500, Testing net (#0)
I1005 14:18:16.199656  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:18:16.249267  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1005 14:18:16.249302  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366688 (* 1 = 0.366688 loss)
I1005 14:18:16.301591  9519 solver.cpp:218] Iteration 84500 (15.3734 iter/s, 6.50475s/100 iters), loss = 0.00338196
I1005 14:18:16.301617  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338208 (* 1 = 0.00338208 loss)
I1005 14:18:16.301625  9519 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1005 14:18:21.566741  9519 solver.cpp:218] Iteration 84600 (18.993 iter/s, 5.26511s/100 iters), loss = 0.0293267
I1005 14:18:21.566881  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293268 (* 1 = 0.0293268 loss)
I1005 14:18:21.566890  9519 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1005 14:18:26.831168  9519 solver.cpp:218] Iteration 84700 (18.996 iter/s, 5.26427s/100 iters), loss = 0.00382177
I1005 14:18:26.831218  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382187 (* 1 = 0.00382187 loss)
I1005 14:18:26.831236  9519 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1005 14:18:32.089000  9519 solver.cpp:218] Iteration 84800 (19.0196 iter/s, 5.25773s/100 iters), loss = 0.00452853
I1005 14:18:32.089041  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452864 (* 1 = 0.00452864 loss)
I1005 14:18:32.089047  9519 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1005 14:18:37.352025  9519 solver.cpp:218] Iteration 84900 (19.0007 iter/s, 5.26296s/100 iters), loss = 0.00459026
I1005 14:18:37.352056  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459036 (* 1 = 0.00459036 loss)
I1005 14:18:37.352061  9519 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1005 14:18:42.360828  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:18:42.570278  9519 solver.cpp:330] Iteration 85000, Testing net (#0)
I1005 14:18:43.757091  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:18:43.807170  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1005 14:18:43.807206  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366375 (* 1 = 0.366375 loss)
I1005 14:18:43.859566  9519 solver.cpp:218] Iteration 85000 (15.3669 iter/s, 6.50749s/100 iters), loss = 0.00512695
I1005 14:18:43.859598  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512704 (* 1 = 0.00512704 loss)
I1005 14:18:43.859606  9519 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1005 14:18:49.122424  9519 solver.cpp:218] Iteration 85100 (19.0013 iter/s, 5.2628s/100 iters), loss = 0.0246626
I1005 14:18:49.122453  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246626 (* 1 = 0.0246626 loss)
I1005 14:18:49.122459  9519 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1005 14:18:54.386210  9519 solver.cpp:218] Iteration 85200 (18.9979 iter/s, 5.26374s/100 iters), loss = 0.0161091
I1005 14:18:54.386337  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161092 (* 1 = 0.0161092 loss)
I1005 14:18:54.386345  9519 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1005 14:18:59.645411  9519 solver.cpp:218] Iteration 85300 (19.0148 iter/s, 5.25906s/100 iters), loss = 0.00502733
I1005 14:18:59.645452  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502741 (* 1 = 0.00502741 loss)
I1005 14:18:59.645458  9519 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1005 14:19:04.907475  9519 solver.cpp:218] Iteration 85400 (19.0042 iter/s, 5.26201s/100 iters), loss = 0.00988957
I1005 14:19:04.907518  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00988966 (* 1 = 0.00988966 loss)
I1005 14:19:04.907524  9519 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1005 14:19:09.912323  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:19:10.122573  9519 solver.cpp:330] Iteration 85500, Testing net (#0)
I1005 14:19:11.309546  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:19:11.359370  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1005 14:19:11.359406  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365817 (* 1 = 0.365817 loss)
I1005 14:19:11.411360  9519 solver.cpp:218] Iteration 85500 (15.3756 iter/s, 6.50383s/100 iters), loss = 0.0157606
I1005 14:19:11.411393  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157606 (* 1 = 0.0157606 loss)
I1005 14:19:11.411401  9519 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1005 14:19:16.676676  9519 solver.cpp:218] Iteration 85600 (18.9924 iter/s, 5.26527s/100 iters), loss = 0.0107053
I1005 14:19:16.676717  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107054 (* 1 = 0.0107054 loss)
I1005 14:19:16.676723  9519 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1005 14:19:21.948256  9519 solver.cpp:218] Iteration 85700 (18.9699 iter/s, 5.27152s/100 iters), loss = 0.0224847
I1005 14:19:21.948297  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224848 (* 1 = 0.0224848 loss)
I1005 14:19:21.948303  9519 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1005 14:19:27.215101  9519 solver.cpp:218] Iteration 85800 (18.9869 iter/s, 5.26678s/100 iters), loss = 0.00796112
I1005 14:19:27.215275  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796119 (* 1 = 0.00796119 loss)
I1005 14:19:27.215282  9519 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1005 14:19:32.468672  9519 solver.cpp:218] Iteration 85900 (19.0354 iter/s, 5.25338s/100 iters), loss = 0.00403764
I1005 14:19:32.468714  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403771 (* 1 = 0.00403771 loss)
I1005 14:19:32.468721  9519 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1005 14:19:37.473992  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:19:37.684592  9519 solver.cpp:330] Iteration 86000, Testing net (#0)
I1005 14:19:38.876411  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:19:38.926919  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1005 14:19:38.926967  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366394 (* 1 = 0.366394 loss)
I1005 14:19:38.980278  9519 solver.cpp:218] Iteration 86000 (15.3573 iter/s, 6.51155s/100 iters), loss = 0.00800935
I1005 14:19:38.980325  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00800943 (* 1 = 0.00800943 loss)
I1005 14:19:38.980334  9519 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1005 14:19:44.232820  9519 solver.cpp:218] Iteration 86100 (19.0388 iter/s, 5.25244s/100 iters), loss = 0.00576222
I1005 14:19:44.232847  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057623 (* 1 = 0.0057623 loss)
I1005 14:19:44.232853  9519 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1005 14:19:49.490358  9519 solver.cpp:218] Iteration 86200 (19.0205 iter/s, 5.25749s/100 iters), loss = 0.00400067
I1005 14:19:49.490399  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400075 (* 1 = 0.00400075 loss)
I1005 14:19:49.490406  9519 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1005 14:19:54.749131  9519 solver.cpp:218] Iteration 86300 (19.0161 iter/s, 5.25871s/100 iters), loss = 0.00580974
I1005 14:19:54.749162  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00580982 (* 1 = 0.00580982 loss)
I1005 14:19:54.749168  9519 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1005 14:20:00.007108  9519 solver.cpp:218] Iteration 86400 (19.0189 iter/s, 5.25792s/100 iters), loss = 0.0112801
I1005 14:20:00.007239  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112801 (* 1 = 0.0112801 loss)
I1005 14:20:00.007248  9519 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1005 14:20:04.997593  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:20:05.207708  9519 solver.cpp:330] Iteration 86500, Testing net (#0)
I1005 14:20:06.403637  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:20:06.453634  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9097
I1005 14:20:06.453668  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366464 (* 1 = 0.366464 loss)
I1005 14:20:06.506014  9519 solver.cpp:218] Iteration 86500 (15.3875 iter/s, 6.49876s/100 iters), loss = 0.00711279
I1005 14:20:06.506049  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00711285 (* 1 = 0.00711285 loss)
I1005 14:20:06.506057  9519 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1005 14:20:11.767519  9519 solver.cpp:218] Iteration 86600 (19.0061 iter/s, 5.26146s/100 iters), loss = 0.00934381
I1005 14:20:11.767557  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00934387 (* 1 = 0.00934387 loss)
I1005 14:20:11.767565  9519 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1005 14:20:17.034039  9519 solver.cpp:218] Iteration 86700 (18.9881 iter/s, 5.26646s/100 iters), loss = 0.00670883
I1005 14:20:17.034078  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670889 (* 1 = 0.00670889 loss)
I1005 14:20:17.034085  9519 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1005 14:20:22.306550  9519 solver.cpp:218] Iteration 86800 (18.9665 iter/s, 5.27245s/100 iters), loss = 0.00386205
I1005 14:20:22.306578  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386211 (* 1 = 0.00386211 loss)
I1005 14:20:22.306584  9519 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1005 14:20:27.564134  9519 solver.cpp:218] Iteration 86900 (19.0203 iter/s, 5.25754s/100 iters), loss = 0.00595964
I1005 14:20:27.564174  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595969 (* 1 = 0.00595969 loss)
I1005 14:20:27.564182  9519 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1005 14:20:32.557179  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:20:32.769297  9519 solver.cpp:330] Iteration 87000, Testing net (#0)
I1005 14:20:33.959939  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:20:34.009732  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9115
I1005 14:20:34.009768  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363986 (* 1 = 0.363986 loss)
I1005 14:20:34.062304  9519 solver.cpp:218] Iteration 87000 (15.3891 iter/s, 6.49812s/100 iters), loss = 0.0397457
I1005 14:20:34.062330  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397458 (* 1 = 0.0397458 loss)
I1005 14:20:34.062336  9519 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1005 14:20:39.325408  9519 solver.cpp:218] Iteration 87100 (19.0004 iter/s, 5.26305s/100 iters), loss = 0.00307594
I1005 14:20:39.325438  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307599 (* 1 = 0.00307599 loss)
I1005 14:20:39.325444  9519 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1005 14:20:44.581040  9519 solver.cpp:218] Iteration 87200 (19.0274 iter/s, 5.25558s/100 iters), loss = 0.0110818
I1005 14:20:44.581082  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110819 (* 1 = 0.0110819 loss)
I1005 14:20:44.581089  9519 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1005 14:20:49.846810  9519 solver.cpp:218] Iteration 87300 (18.9908 iter/s, 5.26571s/100 iters), loss = 0.00445448
I1005 14:20:49.846840  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445453 (* 1 = 0.00445453 loss)
I1005 14:20:49.846848  9519 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1005 14:20:55.111310  9519 solver.cpp:218] Iteration 87400 (18.9953 iter/s, 5.26445s/100 iters), loss = 0.00354012
I1005 14:20:55.111342  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354017 (* 1 = 0.00354017 loss)
I1005 14:20:55.111348  9519 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1005 14:21:00.119093  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:21:00.330951  9519 solver.cpp:330] Iteration 87500, Testing net (#0)
I1005 14:21:01.515363  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:21:01.565330  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1005 14:21:01.565354  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365391 (* 1 = 0.365391 loss)
I1005 14:21:01.617624  9519 solver.cpp:218] Iteration 87500 (15.3698 iter/s, 6.50627s/100 iters), loss = 0.0112289
I1005 14:21:01.617666  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011229 (* 1 = 0.011229 loss)
I1005 14:21:01.617672  9519 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1005 14:21:06.882443  9519 solver.cpp:218] Iteration 87600 (18.9942 iter/s, 5.26476s/100 iters), loss = 0.0115104
I1005 14:21:06.882560  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115105 (* 1 = 0.0115105 loss)
I1005 14:21:06.882567  9519 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1005 14:21:12.147567  9519 solver.cpp:218] Iteration 87700 (18.9934 iter/s, 5.26499s/100 iters), loss = 0.00990548
I1005 14:21:12.147598  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00990554 (* 1 = 0.00990554 loss)
I1005 14:21:12.147604  9519 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1005 14:21:17.403303  9519 solver.cpp:218] Iteration 87800 (19.027 iter/s, 5.25569s/100 iters), loss = 0.00343506
I1005 14:21:17.403345  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343512 (* 1 = 0.00343512 loss)
I1005 14:21:17.403352  9519 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1005 14:21:22.661859  9519 solver.cpp:218] Iteration 87900 (19.0168 iter/s, 5.2585s/100 iters), loss = 0.0206551
I1005 14:21:22.661901  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206552 (* 1 = 0.0206552 loss)
I1005 14:21:22.661907  9519 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1005 14:21:27.663547  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:21:27.873692  9519 solver.cpp:330] Iteration 88000, Testing net (#0)
I1005 14:21:29.060286  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:21:29.109923  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1005 14:21:29.109948  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366365 (* 1 = 0.366365 loss)
I1005 14:21:29.162326  9519 solver.cpp:218] Iteration 88000 (15.3836 iter/s, 6.50041s/100 iters), loss = 0.0115752
I1005 14:21:29.162353  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115753 (* 1 = 0.0115753 loss)
I1005 14:21:29.162360  9519 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1005 14:21:34.426565  9519 solver.cpp:218] Iteration 88100 (18.9963 iter/s, 5.26419s/100 iters), loss = 0.0186444
I1005 14:21:34.426606  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186445 (* 1 = 0.0186445 loss)
I1005 14:21:34.426612  9519 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1005 14:21:39.698695  9519 solver.cpp:218] Iteration 88200 (18.9679 iter/s, 5.27207s/100 iters), loss = 0.0195099
I1005 14:21:39.698824  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01951 (* 1 = 0.01951 loss)
I1005 14:21:39.698843  9519 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1005 14:21:44.966801  9519 solver.cpp:218] Iteration 88300 (18.9827 iter/s, 5.26796s/100 iters), loss = 0.00367647
I1005 14:21:44.966837  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367653 (* 1 = 0.00367653 loss)
I1005 14:21:44.966845  9519 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1005 14:21:50.224711  9519 solver.cpp:218] Iteration 88400 (19.0192 iter/s, 5.25786s/100 iters), loss = 0.00989657
I1005 14:21:50.224752  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00989663 (* 1 = 0.00989663 loss)
I1005 14:21:50.224758  9519 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1005 14:21:55.232856  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:21:55.443656  9519 solver.cpp:330] Iteration 88500, Testing net (#0)
I1005 14:21:56.628907  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:21:56.678490  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1005 14:21:56.678529  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363972 (* 1 = 0.363972 loss)
I1005 14:21:56.731196  9519 solver.cpp:218] Iteration 88500 (15.3694 iter/s, 6.50643s/100 iters), loss = 0.00564284
I1005 14:21:56.731233  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0056429 (* 1 = 0.0056429 loss)
I1005 14:21:56.731241  9519 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1005 14:22:01.992601  9519 solver.cpp:218] Iteration 88600 (19.0065 iter/s, 5.26135s/100 iters), loss = 0.0145714
I1005 14:22:01.992630  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145715 (* 1 = 0.0145715 loss)
I1005 14:22:01.992636  9519 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1005 14:22:07.254137  9519 solver.cpp:218] Iteration 88700 (19.006 iter/s, 5.26149s/100 iters), loss = 0.0189234
I1005 14:22:07.254179  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189235 (* 1 = 0.0189235 loss)
I1005 14:22:07.254184  9519 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1005 14:22:12.516346  9519 solver.cpp:218] Iteration 88800 (19.0036 iter/s, 5.26215s/100 iters), loss = 0.00749998
I1005 14:22:12.516499  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750004 (* 1 = 0.00750004 loss)
I1005 14:22:12.516507  9519 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1005 14:22:17.770783  9519 solver.cpp:218] Iteration 88900 (19.0321 iter/s, 5.25427s/100 iters), loss = 0.0124031
I1005 14:22:17.770819  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124031 (* 1 = 0.0124031 loss)
I1005 14:22:17.770829  9519 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1005 14:22:22.775890  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:22:22.987393  9519 solver.cpp:330] Iteration 89000, Testing net (#0)
I1005 14:22:24.182564  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:22:24.232455  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1005 14:22:24.232481  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367268 (* 1 = 0.367268 loss)
I1005 14:22:24.284968  9519 solver.cpp:218] Iteration 89000 (15.3512 iter/s, 6.51413s/100 iters), loss = 0.00445612
I1005 14:22:24.285003  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445619 (* 1 = 0.00445619 loss)
I1005 14:22:24.285013  9519 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1005 14:22:29.542120  9519 solver.cpp:218] Iteration 89100 (19.0219 iter/s, 5.2571s/100 iters), loss = 0.00728169
I1005 14:22:29.542171  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728175 (* 1 = 0.00728175 loss)
I1005 14:22:29.542187  9519 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1005 14:22:34.812237  9519 solver.cpp:218] Iteration 89200 (18.9751 iter/s, 5.27006s/100 iters), loss = 0.0086703
I1005 14:22:34.812268  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867036 (* 1 = 0.00867036 loss)
I1005 14:22:34.812274  9519 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1005 14:22:40.082265  9519 solver.cpp:218] Iteration 89300 (18.9754 iter/s, 5.26998s/100 iters), loss = 0.00829787
I1005 14:22:40.082306  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829794 (* 1 = 0.00829794 loss)
I1005 14:22:40.082312  9519 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1005 14:22:45.344393  9519 solver.cpp:218] Iteration 89400 (19.0039 iter/s, 5.26206s/100 iters), loss = 0.00348595
I1005 14:22:45.344535  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348602 (* 1 = 0.00348602 loss)
I1005 14:22:45.344543  9519 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1005 14:22:50.341408  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:22:50.551489  9519 solver.cpp:330] Iteration 89500, Testing net (#0)
I1005 14:22:51.743930  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:22:51.793725  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9099
I1005 14:22:51.793751  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367139 (* 1 = 0.367139 loss)
I1005 14:22:51.845947  9519 solver.cpp:218] Iteration 89500 (15.3813 iter/s, 6.50141s/100 iters), loss = 0.00482261
I1005 14:22:51.845973  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482268 (* 1 = 0.00482268 loss)
I1005 14:22:51.845980  9519 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1005 14:22:57.111340  9519 solver.cpp:218] Iteration 89600 (18.9921 iter/s, 5.26535s/100 iters), loss = 0.00210932
I1005 14:22:57.111383  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210938 (* 1 = 0.00210938 loss)
I1005 14:22:57.111390  9519 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1005 14:23:02.367660  9519 solver.cpp:218] Iteration 89700 (19.0249 iter/s, 5.25626s/100 iters), loss = 0.0057675
I1005 14:23:02.367691  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576758 (* 1 = 0.00576758 loss)
I1005 14:23:02.367698  9519 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1005 14:23:07.630182  9519 solver.cpp:218] Iteration 89800 (19.0025 iter/s, 5.26247s/100 iters), loss = 0.00431408
I1005 14:23:07.630224  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431416 (* 1 = 0.00431416 loss)
I1005 14:23:07.630231  9519 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1005 14:23:12.896528  9519 solver.cpp:218] Iteration 89900 (18.9887 iter/s, 5.26629s/100 iters), loss = 0.00448947
I1005 14:23:12.896570  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448955 (* 1 = 0.00448955 loss)
I1005 14:23:12.896577  9519 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1005 14:23:17.900249  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:23:18.112054  9519 solver.cpp:330] Iteration 90000, Testing net (#0)
I1005 14:23:19.299334  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:23:19.348858  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1005 14:23:19.348883  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364849 (* 1 = 0.364849 loss)
I1005 14:23:19.400957  9519 solver.cpp:218] Iteration 90000 (15.3743 iter/s, 6.50437s/100 iters), loss = 0.00575041
I1005 14:23:19.400986  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575048 (* 1 = 0.00575048 loss)
I1005 14:23:19.400992  9519 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1005 14:23:24.661624  9519 solver.cpp:218] Iteration 90100 (19.0092 iter/s, 5.26062s/100 iters), loss = 0.0116441
I1005 14:23:24.661653  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116442 (* 1 = 0.0116442 loss)
I1005 14:23:24.661659  9519 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1005 14:23:29.923662  9519 solver.cpp:218] Iteration 90200 (19.0042 iter/s, 5.26199s/100 iters), loss = 0.011119
I1005 14:23:29.923701  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011119 (* 1 = 0.011119 loss)
I1005 14:23:29.923708  9519 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1005 14:23:35.181465  9519 solver.cpp:218] Iteration 90300 (19.0196 iter/s, 5.25775s/100 iters), loss = 0.0181514
I1005 14:23:35.181506  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181514 (* 1 = 0.0181514 loss)
I1005 14:23:35.181514  9519 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1005 14:23:40.440603  9519 solver.cpp:218] Iteration 90400 (19.0147 iter/s, 5.25908s/100 iters), loss = 0.00256612
I1005 14:23:40.440642  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256619 (* 1 = 0.00256619 loss)
I1005 14:23:40.440649  9519 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1005 14:23:45.441736  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:23:45.650964  9519 solver.cpp:330] Iteration 90500, Testing net (#0)
I1005 14:23:46.838364  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:23:46.888135  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1005 14:23:46.888178  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366246 (* 1 = 0.366246 loss)
I1005 14:23:46.940259  9519 solver.cpp:218] Iteration 90500 (15.3856 iter/s, 6.4996s/100 iters), loss = 0.00957053
I1005 14:23:46.940291  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957059 (* 1 = 0.00957059 loss)
I1005 14:23:46.940299  9519 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1005 14:23:52.202607  9519 solver.cpp:218] Iteration 90600 (19.0031 iter/s, 5.2623s/100 iters), loss = 0.00391851
I1005 14:23:52.202736  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391858 (* 1 = 0.00391858 loss)
I1005 14:23:52.202754  9519 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1005 14:23:57.466439  9519 solver.cpp:218] Iteration 90700 (18.9981 iter/s, 5.26369s/100 iters), loss = 0.00669708
I1005 14:23:57.466490  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669715 (* 1 = 0.00669715 loss)
I1005 14:23:57.466497  9519 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1005 14:24:02.726658  9519 solver.cpp:218] Iteration 90800 (19.0108 iter/s, 5.26016s/100 iters), loss = 0.00330584
I1005 14:24:02.726688  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330591 (* 1 = 0.00330591 loss)
I1005 14:24:02.726696  9519 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1005 14:24:07.987382  9519 solver.cpp:218] Iteration 90900 (19.009 iter/s, 5.26067s/100 iters), loss = 0.00189771
I1005 14:24:07.987413  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189778 (* 1 = 0.00189778 loss)
I1005 14:24:07.987429  9519 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1005 14:24:12.994307  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:24:13.204557  9519 solver.cpp:330] Iteration 91000, Testing net (#0)
I1005 14:24:14.391940  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:24:14.442078  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.911
I1005 14:24:14.442116  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366417 (* 1 = 0.366417 loss)
I1005 14:24:14.494473  9519 solver.cpp:218] Iteration 91000 (15.368 iter/s, 6.50704s/100 iters), loss = 0.00611072
I1005 14:24:14.494506  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00611079 (* 1 = 0.00611079 loss)
I1005 14:24:14.494513  9519 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1005 14:24:19.760102  9519 solver.cpp:218] Iteration 91100 (18.9913 iter/s, 5.26557s/100 iters), loss = 0.0146646
I1005 14:24:19.760131  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146647 (* 1 = 0.0146647 loss)
I1005 14:24:19.760138  9519 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1005 14:24:25.022861  9519 solver.cpp:218] Iteration 91200 (19.0016 iter/s, 5.26271s/100 iters), loss = 0.0121218
I1005 14:24:25.022965  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121219 (* 1 = 0.0121219 loss)
I1005 14:24:25.022984  9519 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1005 14:24:30.282697  9519 solver.cpp:218] Iteration 91300 (19.0124 iter/s, 5.25973s/100 iters), loss = 0.0215349
I1005 14:24:30.282732  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021535 (* 1 = 0.021535 loss)
I1005 14:24:30.282738  9519 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1005 14:24:35.532130  9519 solver.cpp:218] Iteration 91400 (19.0499 iter/s, 5.24938s/100 iters), loss = 0.00664399
I1005 14:24:35.532167  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664405 (* 1 = 0.00664405 loss)
I1005 14:24:35.532177  9519 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1005 14:24:40.531139  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:24:40.741683  9519 solver.cpp:330] Iteration 91500, Testing net (#0)
I1005 14:24:41.933078  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:24:41.983126  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.91
I1005 14:24:41.983152  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368898 (* 1 = 0.368898 loss)
I1005 14:24:42.036656  9519 solver.cpp:218] Iteration 91500 (15.374 iter/s, 6.50448s/100 iters), loss = 0.00317949
I1005 14:24:42.036705  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317955 (* 1 = 0.00317955 loss)
I1005 14:24:42.036713  9519 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1005 14:24:47.293434  9519 solver.cpp:218] Iteration 91600 (19.0233 iter/s, 5.25672s/100 iters), loss = 0.0138547
I1005 14:24:47.293478  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138547 (* 1 = 0.0138547 loss)
I1005 14:24:47.293483  9519 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1005 14:24:52.547755  9519 solver.cpp:218] Iteration 91700 (19.0322 iter/s, 5.25426s/100 iters), loss = 0.00133677
I1005 14:24:52.547785  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133683 (* 1 = 0.00133683 loss)
I1005 14:24:52.547791  9519 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1005 14:24:57.814314  9519 solver.cpp:218] Iteration 91800 (18.9879 iter/s, 5.26651s/100 iters), loss = 0.00284551
I1005 14:24:57.814450  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284557 (* 1 = 0.00284557 loss)
I1005 14:24:57.814457  9519 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1005 14:25:03.080121  9519 solver.cpp:218] Iteration 91900 (18.991 iter/s, 5.26566s/100 iters), loss = 0.00195643
I1005 14:25:03.080152  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195649 (* 1 = 0.00195649 loss)
I1005 14:25:03.080159  9519 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1005 14:25:08.079512  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:25:08.289893  9519 solver.cpp:330] Iteration 92000, Testing net (#0)
I1005 14:25:09.487876  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:25:09.537789  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1005 14:25:09.537814  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369368 (* 1 = 0.369368 loss)
I1005 14:25:09.590215  9519 solver.cpp:218] Iteration 92000 (15.3609 iter/s, 6.51005s/100 iters), loss = 0.0150339
I1005 14:25:09.590248  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015034 (* 1 = 0.015034 loss)
I1005 14:25:09.590256  9519 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1005 14:25:14.848191  9519 solver.cpp:218] Iteration 92100 (19.0189 iter/s, 5.25792s/100 iters), loss = 0.00647475
I1005 14:25:14.848227  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00647481 (* 1 = 0.00647481 loss)
I1005 14:25:14.848234  9519 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1005 14:25:20.112148  9519 solver.cpp:218] Iteration 92200 (18.9973 iter/s, 5.2639s/100 iters), loss = 0.00308845
I1005 14:25:20.112177  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030885 (* 1 = 0.0030885 loss)
I1005 14:25:20.112184  9519 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1005 14:25:25.367527  9519 solver.cpp:218] Iteration 92300 (19.0283 iter/s, 5.25533s/100 iters), loss = 0.0112427
I1005 14:25:25.367558  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112428 (* 1 = 0.0112428 loss)
I1005 14:25:25.367565  9519 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1005 14:25:30.629957  9519 solver.cpp:218] Iteration 92400 (19.0028 iter/s, 5.26238s/100 iters), loss = 0.00678972
I1005 14:25:30.630072  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678977 (* 1 = 0.00678977 loss)
I1005 14:25:30.630080  9519 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1005 14:25:35.626891  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:25:35.840639  9519 solver.cpp:330] Iteration 92500, Testing net (#0)
I1005 14:25:37.031564  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:25:37.080509  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1005 14:25:37.080535  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367457 (* 1 = 0.367457 loss)
I1005 14:25:37.133102  9519 solver.cpp:218] Iteration 92500 (15.3775 iter/s, 6.50302s/100 iters), loss = 0.00463489
I1005 14:25:37.133127  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463494 (* 1 = 0.00463494 loss)
I1005 14:25:37.133134  9519 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1005 14:25:42.402993  9519 solver.cpp:218] Iteration 92600 (18.9759 iter/s, 5.26985s/100 iters), loss = 0.00979402
I1005 14:25:42.403025  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00979408 (* 1 = 0.00979408 loss)
I1005 14:25:42.403043  9519 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1005 14:25:47.662878  9519 solver.cpp:218] Iteration 92700 (19.012 iter/s, 5.25984s/100 iters), loss = 0.00392944
I1005 14:25:47.662909  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392949 (* 1 = 0.00392949 loss)
I1005 14:25:47.662925  9519 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1005 14:25:52.929395  9519 solver.cpp:218] Iteration 92800 (18.9881 iter/s, 5.26647s/100 iters), loss = 0.010972
I1005 14:25:52.929426  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109721 (* 1 = 0.0109721 loss)
I1005 14:25:52.929432  9519 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1005 14:25:58.193698  9519 solver.cpp:218] Iteration 92900 (18.996 iter/s, 5.26425s/100 iters), loss = 0.0091558
I1005 14:25:58.193730  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915586 (* 1 = 0.00915586 loss)
I1005 14:25:58.193747  9519 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1005 14:26:03.192545  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:26:03.402475  9519 solver.cpp:330] Iteration 93000, Testing net (#0)
I1005 14:26:04.589694  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:26:04.639447  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1005 14:26:04.639475  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366788 (* 1 = 0.366788 loss)
I1005 14:26:04.692013  9519 solver.cpp:218] Iteration 93000 (15.3887 iter/s, 6.49827s/100 iters), loss = 0.0355115
I1005 14:26:04.692044  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355115 (* 1 = 0.0355115 loss)
I1005 14:26:04.692054  9519 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1005 14:26:09.954543  9519 solver.cpp:218] Iteration 93100 (19.0024 iter/s, 5.26248s/100 iters), loss = 0.003551
I1005 14:26:09.954584  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355105 (* 1 = 0.00355105 loss)
I1005 14:26:09.954591  9519 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1005 14:26:15.220206  9519 solver.cpp:218] Iteration 93200 (18.9912 iter/s, 5.2656s/100 iters), loss = 0.0026611
I1005 14:26:15.220249  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266115 (* 1 = 0.00266115 loss)
I1005 14:26:15.220257  9519 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1005 14:26:20.477687  9519 solver.cpp:218] Iteration 93300 (19.0207 iter/s, 5.25742s/100 iters), loss = 0.00626836
I1005 14:26:20.477718  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00626841 (* 1 = 0.00626841 loss)
I1005 14:26:20.477725  9519 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1005 14:26:25.740437  9519 solver.cpp:218] Iteration 93400 (19.0017 iter/s, 5.2627s/100 iters), loss = 0.00251343
I1005 14:26:25.740478  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251348 (* 1 = 0.00251348 loss)
I1005 14:26:25.740484  9519 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1005 14:26:30.746840  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:26:30.957605  9519 solver.cpp:330] Iteration 93500, Testing net (#0)
I1005 14:26:32.145105  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:26:32.194876  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1005 14:26:32.194911  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367399 (* 1 = 0.367399 loss)
I1005 14:26:32.247161  9519 solver.cpp:218] Iteration 93500 (15.3688 iter/s, 6.50667s/100 iters), loss = 0.00175191
I1005 14:26:32.247195  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175196 (* 1 = 0.00175196 loss)
I1005 14:26:32.247201  9519 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1005 14:26:37.514714  9519 solver.cpp:218] Iteration 93600 (18.9843 iter/s, 5.26751s/100 iters), loss = 0.00599088
I1005 14:26:37.514834  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599093 (* 1 = 0.00599093 loss)
I1005 14:26:37.514854  9519 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1005 14:26:42.779561  9519 solver.cpp:218] Iteration 93700 (18.9944 iter/s, 5.26472s/100 iters), loss = 0.00852602
I1005 14:26:42.779597  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00852606 (* 1 = 0.00852606 loss)
I1005 14:26:42.779615  9519 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1005 14:26:48.052078  9519 solver.cpp:218] Iteration 93800 (18.9665 iter/s, 5.27246s/100 iters), loss = 0.00881479
I1005 14:26:48.052117  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00881483 (* 1 = 0.00881483 loss)
I1005 14:26:48.052127  9519 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1005 14:26:53.304110  9519 solver.cpp:218] Iteration 93900 (19.0405 iter/s, 5.25198s/100 iters), loss = 0.00224424
I1005 14:26:53.304145  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224429 (* 1 = 0.00224429 loss)
I1005 14:26:53.304164  9519 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1005 14:26:58.312074  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:26:58.522809  9519 solver.cpp:330] Iteration 94000, Testing net (#0)
I1005 14:26:59.708989  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:26:59.758381  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1005 14:26:59.758420  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366195 (* 1 = 0.366195 loss)
I1005 14:26:59.811866  9519 solver.cpp:218] Iteration 94000 (15.3664 iter/s, 6.5077s/100 iters), loss = 0.00254714
I1005 14:26:59.811902  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254719 (* 1 = 0.00254719 loss)
I1005 14:26:59.811910  9519 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1005 14:27:05.066495  9519 solver.cpp:218] Iteration 94100 (19.031 iter/s, 5.25458s/100 iters), loss = 0.0042102
I1005 14:27:05.066529  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421025 (* 1 = 0.00421025 loss)
I1005 14:27:05.066545  9519 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1005 14:27:10.331969  9519 solver.cpp:218] Iteration 94200 (18.9918 iter/s, 5.26542s/100 iters), loss = 0.0331798
I1005 14:27:10.332098  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331799 (* 1 = 0.0331799 loss)
I1005 14:27:10.332105  9519 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1005 14:27:15.599211  9519 solver.cpp:218] Iteration 94300 (18.9858 iter/s, 5.2671s/100 iters), loss = 0.00176384
I1005 14:27:15.599261  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176389 (* 1 = 0.00176389 loss)
I1005 14:27:15.599278  9519 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1005 14:27:20.852658  9519 solver.cpp:218] Iteration 94400 (19.0354 iter/s, 5.25338s/100 iters), loss = 0.00532252
I1005 14:27:20.852696  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532258 (* 1 = 0.00532258 loss)
I1005 14:27:20.852705  9519 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1005 14:27:25.855237  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:27:26.064957  9519 solver.cpp:330] Iteration 94500, Testing net (#0)
I1005 14:27:27.260308  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:27:27.310369  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.91
I1005 14:27:27.310397  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366771 (* 1 = 0.366771 loss)
I1005 14:27:27.362849  9519 solver.cpp:218] Iteration 94500 (15.3607 iter/s, 6.51014s/100 iters), loss = 0.00425179
I1005 14:27:27.362879  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425184 (* 1 = 0.00425184 loss)
I1005 14:27:27.362885  9519 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1005 14:27:32.618309  9519 solver.cpp:218] Iteration 94600 (19.028 iter/s, 5.25541s/100 iters), loss = 0.0171301
I1005 14:27:32.618340  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171302 (* 1 = 0.0171302 loss)
I1005 14:27:32.618346  9519 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1005 14:27:37.887317  9519 solver.cpp:218] Iteration 94700 (18.9791 iter/s, 5.26895s/100 iters), loss = 0.00311254
I1005 14:27:37.887347  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311259 (* 1 = 0.00311259 loss)
I1005 14:27:37.887353  9519 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1005 14:27:43.136384  9519 solver.cpp:218] Iteration 94800 (19.0512 iter/s, 5.24902s/100 iters), loss = 0.00363577
I1005 14:27:43.136507  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363582 (* 1 = 0.00363582 loss)
I1005 14:27:43.136524  9519 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1005 14:27:48.394443  9519 solver.cpp:218] Iteration 94900 (19.0189 iter/s, 5.25793s/100 iters), loss = 0.00285757
I1005 14:27:48.394474  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285763 (* 1 = 0.00285763 loss)
I1005 14:27:48.394490  9519 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1005 14:27:53.387810  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:27:53.597955  9519 solver.cpp:330] Iteration 95000, Testing net (#0)
I1005 14:27:54.790555  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:27:54.840260  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1005 14:27:54.840296  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367276 (* 1 = 0.367276 loss)
I1005 14:27:54.892431  9519 solver.cpp:218] Iteration 95000 (15.3895 iter/s, 6.49794s/100 iters), loss = 0.0149396
I1005 14:27:54.892457  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149397 (* 1 = 0.0149397 loss)
I1005 14:27:54.892462  9519 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1005 14:28:00.162514  9519 solver.cpp:218] Iteration 95100 (18.9752 iter/s, 5.27003s/100 iters), loss = 0.0112015
I1005 14:28:00.162567  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112016 (* 1 = 0.0112016 loss)
I1005 14:28:00.162585  9519 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1005 14:28:05.421154  9519 solver.cpp:218] Iteration 95200 (19.0166 iter/s, 5.25858s/100 iters), loss = 0.00227553
I1005 14:28:05.421185  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227559 (* 1 = 0.00227559 loss)
I1005 14:28:05.421192  9519 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1005 14:28:10.688661  9519 solver.cpp:218] Iteration 95300 (18.9845 iter/s, 5.26746s/100 iters), loss = 0.00895101
I1005 14:28:10.688691  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895106 (* 1 = 0.00895106 loss)
I1005 14:28:10.688697  9519 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1005 14:28:15.955391  9519 solver.cpp:218] Iteration 95400 (18.9873 iter/s, 5.26668s/100 iters), loss = 0.00375545
I1005 14:28:15.955554  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037555 (* 1 = 0.0037555 loss)
I1005 14:28:15.955564  9519 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1005 14:28:20.957422  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:28:21.170070  9519 solver.cpp:330] Iteration 95500, Testing net (#0)
I1005 14:28:22.357048  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:28:22.406652  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1005 14:28:22.406687  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367089 (* 1 = 0.367089 loss)
I1005 14:28:22.459033  9519 solver.cpp:218] Iteration 95500 (15.3764 iter/s, 6.50347s/100 iters), loss = 0.00259569
I1005 14:28:22.459059  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259574 (* 1 = 0.00259574 loss)
I1005 14:28:22.459066  9519 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1005 14:28:27.720023  9519 solver.cpp:218] Iteration 95600 (19.008 iter/s, 5.26095s/100 iters), loss = 0.00535178
I1005 14:28:27.720053  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535183 (* 1 = 0.00535183 loss)
I1005 14:28:27.720059  9519 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1005 14:28:32.979712  9519 solver.cpp:218] Iteration 95700 (19.0127 iter/s, 5.25964s/100 iters), loss = 0.00464378
I1005 14:28:32.979746  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00464383 (* 1 = 0.00464383 loss)
I1005 14:28:32.979753  9519 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1005 14:28:38.235920  9519 solver.cpp:218] Iteration 95800 (19.0253 iter/s, 5.25616s/100 iters), loss = 0.00613924
I1005 14:28:38.235951  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613929 (* 1 = 0.00613929 loss)
I1005 14:28:38.235957  9519 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1005 14:28:43.497208  9519 solver.cpp:218] Iteration 95900 (19.0069 iter/s, 5.26124s/100 iters), loss = 0.00548133
I1005 14:28:43.497241  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548137 (* 1 = 0.00548137 loss)
I1005 14:28:43.497246  9519 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1005 14:28:48.505250  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:28:48.715095  9519 solver.cpp:330] Iteration 96000, Testing net (#0)
I1005 14:28:49.901415  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:28:49.951329  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9092
I1005 14:28:49.951364  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370332 (* 1 = 0.370332 loss)
I1005 14:28:50.004077  9519 solver.cpp:218] Iteration 96000 (15.3685 iter/s, 6.50682s/100 iters), loss = 0.00409363
I1005 14:28:50.004102  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409367 (* 1 = 0.00409367 loss)
I1005 14:28:50.004119  9519 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1005 14:28:55.267349  9519 solver.cpp:218] Iteration 96100 (18.9997 iter/s, 5.26323s/100 iters), loss = 0.0139472
I1005 14:28:55.267390  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139473 (* 1 = 0.0139473 loss)
I1005 14:28:55.267396  9519 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1005 14:29:00.537322  9519 solver.cpp:218] Iteration 96200 (18.9756 iter/s, 5.26991s/100 iters), loss = 0.00593483
I1005 14:29:00.537351  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00593487 (* 1 = 0.00593487 loss)
I1005 14:29:00.537358  9519 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1005 14:29:05.796932  9519 solver.cpp:218] Iteration 96300 (19.013 iter/s, 5.25956s/100 iters), loss = 0.0235683
I1005 14:29:05.796977  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235684 (* 1 = 0.0235684 loss)
I1005 14:29:05.796983  9519 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1005 14:29:11.058213  9519 solver.cpp:218] Iteration 96400 (19.0071 iter/s, 5.26119s/100 iters), loss = 0.00245684
I1005 14:29:11.058243  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245688 (* 1 = 0.00245688 loss)
I1005 14:29:11.058249  9519 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1005 14:29:16.060315  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:29:16.271042  9519 solver.cpp:330] Iteration 96500, Testing net (#0)
I1005 14:29:17.457717  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:29:17.507381  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1005 14:29:17.507413  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37177 (* 1 = 0.37177 loss)
I1005 14:29:17.559576  9519 solver.cpp:218] Iteration 96500 (15.3815 iter/s, 6.50131s/100 iters), loss = 0.00991916
I1005 14:29:17.559608  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00991919 (* 1 = 0.00991919 loss)
I1005 14:29:17.559615  9519 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1005 14:29:22.823252  9519 solver.cpp:218] Iteration 96600 (18.9983 iter/s, 5.26363s/100 iters), loss = 0.00488946
I1005 14:29:22.823376  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0048895 (* 1 = 0.0048895 loss)
I1005 14:29:22.823385  9519 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1005 14:29:28.090392  9519 solver.cpp:218] Iteration 96700 (18.9861 iter/s, 5.26701s/100 iters), loss = 0.00668173
I1005 14:29:28.090427  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00668176 (* 1 = 0.00668176 loss)
I1005 14:29:28.090436  9519 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1005 14:29:33.356940  9519 solver.cpp:218] Iteration 96800 (18.988 iter/s, 5.26649s/100 iters), loss = 0.00715052
I1005 14:29:33.356992  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715054 (* 1 = 0.00715054 loss)
I1005 14:29:33.356997  9519 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1005 14:29:38.614526  9519 solver.cpp:218] Iteration 96900 (19.0204 iter/s, 5.25752s/100 iters), loss = 0.00291343
I1005 14:29:38.614560  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291346 (* 1 = 0.00291346 loss)
I1005 14:29:38.614569  9519 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1005 14:29:43.623842  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:29:43.834127  9519 solver.cpp:330] Iteration 97000, Testing net (#0)
I1005 14:29:45.026904  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:29:45.076931  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9081
I1005 14:29:45.076961  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370506 (* 1 = 0.370506 loss)
I1005 14:29:45.129519  9519 solver.cpp:218] Iteration 97000 (15.3493 iter/s, 6.51494s/100 iters), loss = 0.00466166
I1005 14:29:45.129555  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466168 (* 1 = 0.00466168 loss)
I1005 14:29:45.129565  9519 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1005 14:29:50.383460  9519 solver.cpp:218] Iteration 97100 (19.0336 iter/s, 5.25388s/100 iters), loss = 0.00840648
I1005 14:29:50.383492  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0084065 (* 1 = 0.0084065 loss)
I1005 14:29:50.383498  9519 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1005 14:29:55.648200  9519 solver.cpp:218] Iteration 97200 (18.9945 iter/s, 5.26469s/100 iters), loss = 0.012414
I1005 14:29:55.648313  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124141 (* 1 = 0.0124141 loss)
I1005 14:29:55.648330  9519 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1005 14:30:00.919034  9519 solver.cpp:218] Iteration 97300 (18.9728 iter/s, 5.27072s/100 iters), loss = 0.00448006
I1005 14:30:00.919061  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448008 (* 1 = 0.00448008 loss)
I1005 14:30:00.919067  9519 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1005 14:30:06.175360  9519 solver.cpp:218] Iteration 97400 (19.0249 iter/s, 5.25628s/100 iters), loss = 0.00197192
I1005 14:30:06.175393  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197194 (* 1 = 0.00197194 loss)
I1005 14:30:06.175400  9519 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1005 14:30:11.172690  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:30:11.383106  9519 solver.cpp:330] Iteration 97500, Testing net (#0)
I1005 14:30:12.575459  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:30:12.625010  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1005 14:30:12.625036  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371714 (* 1 = 0.371714 loss)
I1005 14:30:12.677386  9519 solver.cpp:218] Iteration 97500 (15.3799 iter/s, 6.50198s/100 iters), loss = 0.00569131
I1005 14:30:12.677422  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569133 (* 1 = 0.00569133 loss)
I1005 14:30:12.677428  9519 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1005 14:30:17.936842  9519 solver.cpp:218] Iteration 97600 (19.0136 iter/s, 5.2594s/100 iters), loss = 0.0197826
I1005 14:30:17.936888  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197826 (* 1 = 0.0197826 loss)
I1005 14:30:17.936895  9519 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1005 14:30:23.196936  9519 solver.cpp:218] Iteration 97700 (19.0114 iter/s, 5.26s/100 iters), loss = 0.00740534
I1005 14:30:23.196976  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00740536 (* 1 = 0.00740536 loss)
I1005 14:30:23.196982  9519 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1005 14:30:28.464607  9519 solver.cpp:218] Iteration 97800 (18.9839 iter/s, 5.26762s/100 iters), loss = 0.0128967
I1005 14:30:28.464749  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128967 (* 1 = 0.0128967 loss)
I1005 14:30:28.464757  9519 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1005 14:30:33.722892  9519 solver.cpp:218] Iteration 97900 (19.0182 iter/s, 5.25813s/100 iters), loss = 0.00345619
I1005 14:30:33.722921  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345621 (* 1 = 0.00345621 loss)
I1005 14:30:33.722929  9519 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1005 14:30:38.725069  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:30:38.941344  9519 solver.cpp:330] Iteration 98000, Testing net (#0)
I1005 14:30:40.130684  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:30:40.180099  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1005 14:30:40.180135  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368677 (* 1 = 0.368677 loss)
I1005 14:30:40.232270  9519 solver.cpp:218] Iteration 98000 (15.3626 iter/s, 6.50933s/100 iters), loss = 0.00217206
I1005 14:30:40.232297  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217208 (* 1 = 0.00217208 loss)
I1005 14:30:40.232305  9519 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1005 14:30:45.500309  9519 solver.cpp:218] Iteration 98100 (18.9826 iter/s, 5.26799s/100 iters), loss = 0.00213742
I1005 14:30:45.500349  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213744 (* 1 = 0.00213744 loss)
I1005 14:30:45.500355  9519 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1005 14:30:50.752460  9519 solver.cpp:218] Iteration 98200 (19.04 iter/s, 5.25209s/100 iters), loss = 0.0159895
I1005 14:30:50.752491  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159896 (* 1 = 0.0159896 loss)
I1005 14:30:50.752508  9519 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1005 14:30:56.017865  9519 solver.cpp:218] Iteration 98300 (18.9921 iter/s, 5.26535s/100 iters), loss = 0.0128851
I1005 14:30:56.017906  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128852 (* 1 = 0.0128852 loss)
I1005 14:30:56.017912  9519 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1005 14:31:01.280189  9519 solver.cpp:218] Iteration 98400 (19.0032 iter/s, 5.26227s/100 iters), loss = 0.00776426
I1005 14:31:01.280316  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776429 (* 1 = 0.00776429 loss)
I1005 14:31:01.280324  9519 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1005 14:31:06.284433  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:31:06.494448  9519 solver.cpp:330] Iteration 98500, Testing net (#0)
I1005 14:31:07.681915  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:31:07.731720  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1005 14:31:07.731747  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368578 (* 1 = 0.368578 loss)
I1005 14:31:07.783921  9519 solver.cpp:218] Iteration 98500 (15.3761 iter/s, 6.50359s/100 iters), loss = 0.00771628
I1005 14:31:07.783949  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771631 (* 1 = 0.00771631 loss)
I1005 14:31:07.783957  9519 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1005 14:31:13.053159  9519 solver.cpp:218] Iteration 98600 (18.9782 iter/s, 5.26919s/100 iters), loss = 0.00393802
I1005 14:31:13.053200  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393805 (* 1 = 0.00393805 loss)
I1005 14:31:13.053205  9519 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1005 14:31:18.323951  9519 solver.cpp:218] Iteration 98700 (18.9727 iter/s, 5.27073s/100 iters), loss = 0.00329672
I1005 14:31:18.323984  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00329675 (* 1 = 0.00329675 loss)
I1005 14:31:18.324003  9519 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1005 14:31:23.582002  9519 solver.cpp:218] Iteration 98800 (19.0186 iter/s, 5.258s/100 iters), loss = 0.00603065
I1005 14:31:23.582051  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603068 (* 1 = 0.00603068 loss)
I1005 14:31:23.582059  9519 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1005 14:31:28.850596  9519 solver.cpp:218] Iteration 98900 (18.9806 iter/s, 5.26855s/100 iters), loss = 0.00556347
I1005 14:31:28.850633  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055635 (* 1 = 0.0055635 loss)
I1005 14:31:28.850642  9519 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1005 14:31:33.863167  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:31:34.073721  9519 solver.cpp:330] Iteration 99000, Testing net (#0)
I1005 14:31:35.261090  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:31:35.311033  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9123
I1005 14:31:35.311069  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367579 (* 1 = 0.367579 loss)
I1005 14:31:35.363281  9519 solver.cpp:218] Iteration 99000 (15.3548 iter/s, 6.51263s/100 iters), loss = 0.0109609
I1005 14:31:35.363319  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010961 (* 1 = 0.010961 loss)
I1005 14:31:35.363327  9519 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1005 14:31:40.629906  9519 solver.cpp:218] Iteration 99100 (18.9877 iter/s, 5.26657s/100 iters), loss = 0.00699245
I1005 14:31:40.629947  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00699248 (* 1 = 0.00699248 loss)
I1005 14:31:40.629954  9519 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1005 14:31:45.897423  9519 solver.cpp:218] Iteration 99200 (18.9845 iter/s, 5.26746s/100 iters), loss = 0.00239842
I1005 14:31:45.897457  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239845 (* 1 = 0.00239845 loss)
I1005 14:31:45.897465  9519 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1005 14:31:51.164630  9519 solver.cpp:218] Iteration 99300 (18.9856 iter/s, 5.26716s/100 iters), loss = 0.00440525
I1005 14:31:51.164674  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440528 (* 1 = 0.00440528 loss)
I1005 14:31:51.164682  9519 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1005 14:31:56.419751  9519 solver.cpp:218] Iteration 99400 (19.0293 iter/s, 5.25506s/100 iters), loss = 0.00168399
I1005 14:31:56.419786  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168402 (* 1 = 0.00168402 loss)
I1005 14:31:56.419795  9519 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1005 14:32:01.431308  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:32:01.642139  9519 solver.cpp:330] Iteration 99500, Testing net (#0)
I1005 14:32:02.830210  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:32:02.881103  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1005 14:32:02.881129  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368041 (* 1 = 0.368041 loss)
I1005 14:32:02.935093  9519 solver.cpp:218] Iteration 99500 (15.3485 iter/s, 6.51529s/100 iters), loss = 0.00503154
I1005 14:32:02.935142  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503157 (* 1 = 0.00503157 loss)
I1005 14:32:02.935149  9519 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1005 14:32:08.194296  9519 solver.cpp:218] Iteration 99600 (19.0145 iter/s, 5.25914s/100 iters), loss = 0.00502671
I1005 14:32:08.194434  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502674 (* 1 = 0.00502674 loss)
I1005 14:32:08.194442  9519 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1005 14:32:13.457986  9519 solver.cpp:218] Iteration 99700 (18.9986 iter/s, 5.26354s/100 iters), loss = 0.00347887
I1005 14:32:13.458020  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034789 (* 1 = 0.0034789 loss)
I1005 14:32:13.458039  9519 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1005 14:32:18.721824  9519 solver.cpp:218] Iteration 99800 (18.9977 iter/s, 5.26379s/100 iters), loss = 0.0185327
I1005 14:32:18.721865  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185328 (* 1 = 0.0185328 loss)
I1005 14:32:18.721871  9519 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1005 14:32:23.981598  9519 solver.cpp:218] Iteration 99900 (19.0124 iter/s, 5.25972s/100 iters), loss = 0.00721806
I1005 14:32:23.981636  9519 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721808 (* 1 = 0.00721808 loss)
I1005 14:32:23.981642  9519 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1005 14:32:28.978044  9528 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:32:29.188261  9519 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha2_beta1_etanostudy_2study_2decay_gauss_iter_100000.caffemodel
I1005 14:32:29.196296  9519 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha2_beta1_etanostudy_2study_2decay_gauss_iter_100000.solverstate
I1005 14:32:29.210433  9519 solver.cpp:310] Iteration 100000, loss = 0.0169576
I1005 14:32:29.210453  9519 solver.cpp:330] Iteration 100000, Testing net (#0)
I1005 14:32:30.403446  9529 data_layer.cpp:73] Restarting data prefetching from start.
I1005 14:32:30.453290  9519 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1005 14:32:30.453315  9519 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369607 (* 1 = 0.369607 loss)
I1005 14:32:30.453320  9519 solver.cpp:315] Optimization Done.
I1005 14:32:30.453321  9519 caffe.cpp:259] Optimization Done.
