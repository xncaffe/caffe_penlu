I1005 15:22:12.720779  9606 caffe.cpp:218] Using GPUs 0
I1005 15:22:12.741281  9606 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1005 15:22:12.956472  9606 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha1_beta1_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1005 15:22:12.956621  9606 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 15:22:12.958112  9606 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 15:22:12.958122  9606 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 15:22:12.958266  9606 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1005 15:22:12.958356  9606 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1005 15:22:12.958844  9606 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I1005 15:22:12.959235  9606 layer_factory.hpp:77] Creating layer Data1
I1005 15:22:12.959316  9606 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1005 15:22:12.959339  9606 net.cpp:84] Creating Layer Data1
I1005 15:22:12.959345  9606 net.cpp:380] Data1 -> Data1
I1005 15:22:12.959364  9606 net.cpp:380] Data1 -> Data2
I1005 15:22:12.959373  9606 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 15:22:12.960817  9606 data_layer.cpp:45] output data size: 100,3,28,28
I1005 15:22:12.963122  9606 net.cpp:122] Setting up Data1
I1005 15:22:12.963146  9606 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1005 15:22:12.963151  9606 net.cpp:129] Top shape: 100 (100)
I1005 15:22:12.963153  9606 net.cpp:137] Memory required for data: 941200
I1005 15:22:12.963160  9606 layer_factory.hpp:77] Creating layer Convolution1
I1005 15:22:12.963178  9606 net.cpp:84] Creating Layer Convolution1
I1005 15:22:12.963183  9606 net.cpp:406] Convolution1 <- Data1
I1005 15:22:12.963191  9606 net.cpp:380] Convolution1 -> Convolution1
I1005 15:22:13.110810  9606 net.cpp:122] Setting up Convolution1
I1005 15:22:13.110834  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.110838  9606 net.cpp:137] Memory required for data: 5958800
I1005 15:22:13.110853  9606 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 15:22:13.110873  9606 net.cpp:84] Creating Layer BatchNorm1
I1005 15:22:13.110877  9606 net.cpp:406] BatchNorm1 <- Convolution1
I1005 15:22:13.110893  9606 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 15:22:13.111037  9606 net.cpp:122] Setting up BatchNorm1
I1005 15:22:13.111043  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.111045  9606 net.cpp:137] Memory required for data: 10976400
I1005 15:22:13.111053  9606 layer_factory.hpp:77] Creating layer Scale1
I1005 15:22:13.111073  9606 net.cpp:84] Creating Layer Scale1
I1005 15:22:13.111075  9606 net.cpp:406] Scale1 <- Convolution1
I1005 15:22:13.111080  9606 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 15:22:13.111140  9606 layer_factory.hpp:77] Creating layer Scale1
I1005 15:22:13.111253  9606 net.cpp:122] Setting up Scale1
I1005 15:22:13.111258  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.111261  9606 net.cpp:137] Memory required for data: 15994000
I1005 15:22:13.111266  9606 layer_factory.hpp:77] Creating layer penlu1
I1005 15:22:13.111275  9606 net.cpp:84] Creating Layer penlu1
I1005 15:22:13.111287  9606 net.cpp:406] penlu1 <- Convolution1
I1005 15:22:13.111291  9606 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1005 15:22:13.111915  9606 net.cpp:122] Setting up penlu1
I1005 15:22:13.111925  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.111928  9606 net.cpp:137] Memory required for data: 21011600
I1005 15:22:13.111935  9606 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1005 15:22:13.111953  9606 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1005 15:22:13.111956  9606 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1005 15:22:13.111960  9606 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1005 15:22:13.111979  9606 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1005 15:22:13.112021  9606 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1005 15:22:13.112026  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.112040  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.112042  9606 net.cpp:137] Memory required for data: 31046800
I1005 15:22:13.112045  9606 layer_factory.hpp:77] Creating layer Convolution2
I1005 15:22:13.112061  9606 net.cpp:84] Creating Layer Convolution2
I1005 15:22:13.112063  9606 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1005 15:22:13.112077  9606 net.cpp:380] Convolution2 -> Convolution2
I1005 15:22:13.112920  9606 net.cpp:122] Setting up Convolution2
I1005 15:22:13.112929  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.112933  9606 net.cpp:137] Memory required for data: 36064400
I1005 15:22:13.112948  9606 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 15:22:13.112964  9606 net.cpp:84] Creating Layer BatchNorm2
I1005 15:22:13.112968  9606 net.cpp:406] BatchNorm2 <- Convolution2
I1005 15:22:13.112972  9606 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 15:22:13.113118  9606 net.cpp:122] Setting up BatchNorm2
I1005 15:22:13.113124  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.113127  9606 net.cpp:137] Memory required for data: 41082000
I1005 15:22:13.113142  9606 layer_factory.hpp:77] Creating layer Scale2
I1005 15:22:13.113148  9606 net.cpp:84] Creating Layer Scale2
I1005 15:22:13.113162  9606 net.cpp:406] Scale2 <- Convolution2
I1005 15:22:13.113165  9606 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 15:22:13.113201  9606 layer_factory.hpp:77] Creating layer Scale2
I1005 15:22:13.113322  9606 net.cpp:122] Setting up Scale2
I1005 15:22:13.113328  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.113332  9606 net.cpp:137] Memory required for data: 46099600
I1005 15:22:13.113348  9606 layer_factory.hpp:77] Creating layer penlu2
I1005 15:22:13.113368  9606 net.cpp:84] Creating Layer penlu2
I1005 15:22:13.113373  9606 net.cpp:406] penlu2 <- Convolution2
I1005 15:22:13.113376  9606 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1005 15:22:13.113488  9606 net.cpp:122] Setting up penlu2
I1005 15:22:13.113494  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.113497  9606 net.cpp:137] Memory required for data: 51117200
I1005 15:22:13.113502  9606 layer_factory.hpp:77] Creating layer Convolution3
I1005 15:22:13.113508  9606 net.cpp:84] Creating Layer Convolution3
I1005 15:22:13.113512  9606 net.cpp:406] Convolution3 <- Convolution2
I1005 15:22:13.113514  9606 net.cpp:380] Convolution3 -> Convolution3
I1005 15:22:13.114333  9606 net.cpp:122] Setting up Convolution3
I1005 15:22:13.114343  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.114347  9606 net.cpp:137] Memory required for data: 56134800
I1005 15:22:13.114352  9606 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 15:22:13.114357  9606 net.cpp:84] Creating Layer BatchNorm3
I1005 15:22:13.114361  9606 net.cpp:406] BatchNorm3 <- Convolution3
I1005 15:22:13.114364  9606 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 15:22:13.114480  9606 net.cpp:122] Setting up BatchNorm3
I1005 15:22:13.114485  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.114487  9606 net.cpp:137] Memory required for data: 61152400
I1005 15:22:13.114492  9606 layer_factory.hpp:77] Creating layer Scale3
I1005 15:22:13.114497  9606 net.cpp:84] Creating Layer Scale3
I1005 15:22:13.114500  9606 net.cpp:406] Scale3 <- Convolution3
I1005 15:22:13.114503  9606 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 15:22:13.114533  9606 layer_factory.hpp:77] Creating layer Scale3
I1005 15:22:13.114603  9606 net.cpp:122] Setting up Scale3
I1005 15:22:13.114609  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.114612  9606 net.cpp:137] Memory required for data: 66170000
I1005 15:22:13.114616  9606 layer_factory.hpp:77] Creating layer Eltwise1
I1005 15:22:13.114621  9606 net.cpp:84] Creating Layer Eltwise1
I1005 15:22:13.114624  9606 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1005 15:22:13.114627  9606 net.cpp:406] Eltwise1 <- Convolution3
I1005 15:22:13.114630  9606 net.cpp:380] Eltwise1 -> Eltwise1
I1005 15:22:13.114647  9606 net.cpp:122] Setting up Eltwise1
I1005 15:22:13.114651  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.114655  9606 net.cpp:137] Memory required for data: 71187600
I1005 15:22:13.114657  9606 layer_factory.hpp:77] Creating layer penlu3
I1005 15:22:13.114662  9606 net.cpp:84] Creating Layer penlu3
I1005 15:22:13.114665  9606 net.cpp:406] penlu3 <- Eltwise1
I1005 15:22:13.114668  9606 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1005 15:22:13.114763  9606 net.cpp:122] Setting up penlu3
I1005 15:22:13.114769  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.114773  9606 net.cpp:137] Memory required for data: 76205200
I1005 15:22:13.114784  9606 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1005 15:22:13.114789  9606 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1005 15:22:13.114791  9606 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1005 15:22:13.114795  9606 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1005 15:22:13.114800  9606 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1005 15:22:13.114821  9606 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1005 15:22:13.114826  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.114830  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.114832  9606 net.cpp:137] Memory required for data: 86240400
I1005 15:22:13.114835  9606 layer_factory.hpp:77] Creating layer Convolution4
I1005 15:22:13.114842  9606 net.cpp:84] Creating Layer Convolution4
I1005 15:22:13.114845  9606 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1005 15:22:13.114850  9606 net.cpp:380] Convolution4 -> Convolution4
I1005 15:22:13.115661  9606 net.cpp:122] Setting up Convolution4
I1005 15:22:13.115671  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.115675  9606 net.cpp:137] Memory required for data: 91258000
I1005 15:22:13.115679  9606 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 15:22:13.115685  9606 net.cpp:84] Creating Layer BatchNorm4
I1005 15:22:13.115689  9606 net.cpp:406] BatchNorm4 <- Convolution4
I1005 15:22:13.115692  9606 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 15:22:13.115804  9606 net.cpp:122] Setting up BatchNorm4
I1005 15:22:13.115810  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.115813  9606 net.cpp:137] Memory required for data: 96275600
I1005 15:22:13.115820  9606 layer_factory.hpp:77] Creating layer Scale4
I1005 15:22:13.115825  9606 net.cpp:84] Creating Layer Scale4
I1005 15:22:13.115829  9606 net.cpp:406] Scale4 <- Convolution4
I1005 15:22:13.115833  9606 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 15:22:13.115856  9606 layer_factory.hpp:77] Creating layer Scale4
I1005 15:22:13.115922  9606 net.cpp:122] Setting up Scale4
I1005 15:22:13.115927  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.115931  9606 net.cpp:137] Memory required for data: 101293200
I1005 15:22:13.115936  9606 layer_factory.hpp:77] Creating layer penlu4
I1005 15:22:13.115941  9606 net.cpp:84] Creating Layer penlu4
I1005 15:22:13.115944  9606 net.cpp:406] penlu4 <- Convolution4
I1005 15:22:13.115947  9606 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1005 15:22:13.116039  9606 net.cpp:122] Setting up penlu4
I1005 15:22:13.116044  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.116047  9606 net.cpp:137] Memory required for data: 106310800
I1005 15:22:13.116052  9606 layer_factory.hpp:77] Creating layer Convolution5
I1005 15:22:13.116060  9606 net.cpp:84] Creating Layer Convolution5
I1005 15:22:13.116062  9606 net.cpp:406] Convolution5 <- Convolution4
I1005 15:22:13.116066  9606 net.cpp:380] Convolution5 -> Convolution5
I1005 15:22:13.116888  9606 net.cpp:122] Setting up Convolution5
I1005 15:22:13.116899  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.116901  9606 net.cpp:137] Memory required for data: 111328400
I1005 15:22:13.116906  9606 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 15:22:13.116912  9606 net.cpp:84] Creating Layer BatchNorm5
I1005 15:22:13.116915  9606 net.cpp:406] BatchNorm5 <- Convolution5
I1005 15:22:13.116919  9606 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 15:22:13.117035  9606 net.cpp:122] Setting up BatchNorm5
I1005 15:22:13.117041  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.117044  9606 net.cpp:137] Memory required for data: 116346000
I1005 15:22:13.117049  9606 layer_factory.hpp:77] Creating layer Scale5
I1005 15:22:13.117054  9606 net.cpp:84] Creating Layer Scale5
I1005 15:22:13.117058  9606 net.cpp:406] Scale5 <- Convolution5
I1005 15:22:13.117060  9606 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 15:22:13.117085  9606 layer_factory.hpp:77] Creating layer Scale5
I1005 15:22:13.117162  9606 net.cpp:122] Setting up Scale5
I1005 15:22:13.117168  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.117172  9606 net.cpp:137] Memory required for data: 121363600
I1005 15:22:13.117175  9606 layer_factory.hpp:77] Creating layer Eltwise2
I1005 15:22:13.117180  9606 net.cpp:84] Creating Layer Eltwise2
I1005 15:22:13.117183  9606 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1005 15:22:13.117187  9606 net.cpp:406] Eltwise2 <- Convolution5
I1005 15:22:13.117190  9606 net.cpp:380] Eltwise2 -> Eltwise2
I1005 15:22:13.117204  9606 net.cpp:122] Setting up Eltwise2
I1005 15:22:13.117209  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.117213  9606 net.cpp:137] Memory required for data: 126381200
I1005 15:22:13.117214  9606 layer_factory.hpp:77] Creating layer penlu5
I1005 15:22:13.117219  9606 net.cpp:84] Creating Layer penlu5
I1005 15:22:13.117223  9606 net.cpp:406] penlu5 <- Eltwise2
I1005 15:22:13.117226  9606 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1005 15:22:13.117322  9606 net.cpp:122] Setting up penlu5
I1005 15:22:13.117328  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.117331  9606 net.cpp:137] Memory required for data: 131398800
I1005 15:22:13.117336  9606 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1005 15:22:13.117339  9606 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1005 15:22:13.117342  9606 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1005 15:22:13.117346  9606 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1005 15:22:13.117350  9606 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1005 15:22:13.117372  9606 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1005 15:22:13.117377  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.117380  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.117383  9606 net.cpp:137] Memory required for data: 141434000
I1005 15:22:13.117385  9606 layer_factory.hpp:77] Creating layer Convolution6
I1005 15:22:13.117391  9606 net.cpp:84] Creating Layer Convolution6
I1005 15:22:13.117394  9606 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1005 15:22:13.117398  9606 net.cpp:380] Convolution6 -> Convolution6
I1005 15:22:13.118275  9606 net.cpp:122] Setting up Convolution6
I1005 15:22:13.118285  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.118289  9606 net.cpp:137] Memory required for data: 146451600
I1005 15:22:13.118294  9606 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 15:22:13.118299  9606 net.cpp:84] Creating Layer BatchNorm6
I1005 15:22:13.118304  9606 net.cpp:406] BatchNorm6 <- Convolution6
I1005 15:22:13.118307  9606 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 15:22:13.118436  9606 net.cpp:122] Setting up BatchNorm6
I1005 15:22:13.118441  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.118444  9606 net.cpp:137] Memory required for data: 151469200
I1005 15:22:13.118449  9606 layer_factory.hpp:77] Creating layer Scale6
I1005 15:22:13.118454  9606 net.cpp:84] Creating Layer Scale6
I1005 15:22:13.118456  9606 net.cpp:406] Scale6 <- Convolution6
I1005 15:22:13.118460  9606 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 15:22:13.118484  9606 layer_factory.hpp:77] Creating layer Scale6
I1005 15:22:13.118559  9606 net.cpp:122] Setting up Scale6
I1005 15:22:13.118566  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.118568  9606 net.cpp:137] Memory required for data: 156486800
I1005 15:22:13.118572  9606 layer_factory.hpp:77] Creating layer penlu6
I1005 15:22:13.118578  9606 net.cpp:84] Creating Layer penlu6
I1005 15:22:13.118582  9606 net.cpp:406] penlu6 <- Convolution6
I1005 15:22:13.118585  9606 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1005 15:22:13.118682  9606 net.cpp:122] Setting up penlu6
I1005 15:22:13.118687  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.118690  9606 net.cpp:137] Memory required for data: 161504400
I1005 15:22:13.118702  9606 layer_factory.hpp:77] Creating layer Convolution7
I1005 15:22:13.118710  9606 net.cpp:84] Creating Layer Convolution7
I1005 15:22:13.118712  9606 net.cpp:406] Convolution7 <- Convolution6
I1005 15:22:13.118716  9606 net.cpp:380] Convolution7 -> Convolution7
I1005 15:22:13.119228  9606 net.cpp:122] Setting up Convolution7
I1005 15:22:13.119237  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.119240  9606 net.cpp:137] Memory required for data: 166522000
I1005 15:22:13.119244  9606 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 15:22:13.119249  9606 net.cpp:84] Creating Layer BatchNorm7
I1005 15:22:13.119252  9606 net.cpp:406] BatchNorm7 <- Convolution7
I1005 15:22:13.119256  9606 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 15:22:13.119381  9606 net.cpp:122] Setting up BatchNorm7
I1005 15:22:13.119386  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.119390  9606 net.cpp:137] Memory required for data: 171539600
I1005 15:22:13.119400  9606 layer_factory.hpp:77] Creating layer Scale7
I1005 15:22:13.119406  9606 net.cpp:84] Creating Layer Scale7
I1005 15:22:13.119410  9606 net.cpp:406] Scale7 <- Convolution7
I1005 15:22:13.119413  9606 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 15:22:13.119439  9606 layer_factory.hpp:77] Creating layer Scale7
I1005 15:22:13.119513  9606 net.cpp:122] Setting up Scale7
I1005 15:22:13.119518  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.119521  9606 net.cpp:137] Memory required for data: 176557200
I1005 15:22:13.119525  9606 layer_factory.hpp:77] Creating layer Eltwise3
I1005 15:22:13.119530  9606 net.cpp:84] Creating Layer Eltwise3
I1005 15:22:13.119534  9606 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1005 15:22:13.119536  9606 net.cpp:406] Eltwise3 <- Convolution7
I1005 15:22:13.119539  9606 net.cpp:380] Eltwise3 -> Eltwise3
I1005 15:22:13.119554  9606 net.cpp:122] Setting up Eltwise3
I1005 15:22:13.119560  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.119562  9606 net.cpp:137] Memory required for data: 181574800
I1005 15:22:13.119565  9606 layer_factory.hpp:77] Creating layer penlu7
I1005 15:22:13.119570  9606 net.cpp:84] Creating Layer penlu7
I1005 15:22:13.119573  9606 net.cpp:406] penlu7 <- Eltwise3
I1005 15:22:13.119576  9606 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1005 15:22:13.119678  9606 net.cpp:122] Setting up penlu7
I1005 15:22:13.119684  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.119688  9606 net.cpp:137] Memory required for data: 186592400
I1005 15:22:13.119691  9606 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1005 15:22:13.119695  9606 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1005 15:22:13.119699  9606 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1005 15:22:13.119702  9606 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1005 15:22:13.119707  9606 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1005 15:22:13.119729  9606 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1005 15:22:13.119732  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.119736  9606 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 15:22:13.119740  9606 net.cpp:137] Memory required for data: 196627600
I1005 15:22:13.119741  9606 layer_factory.hpp:77] Creating layer Convolution8
I1005 15:22:13.119747  9606 net.cpp:84] Creating Layer Convolution8
I1005 15:22:13.119750  9606 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1005 15:22:13.119755  9606 net.cpp:380] Convolution8 -> Convolution8
I1005 15:22:13.120872  9606 net.cpp:122] Setting up Convolution8
I1005 15:22:13.120882  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.120885  9606 net.cpp:137] Memory required for data: 199136400
I1005 15:22:13.120890  9606 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 15:22:13.120896  9606 net.cpp:84] Creating Layer BatchNorm8
I1005 15:22:13.120899  9606 net.cpp:406] BatchNorm8 <- Convolution8
I1005 15:22:13.120903  9606 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 15:22:13.121063  9606 net.cpp:122] Setting up BatchNorm8
I1005 15:22:13.121070  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.121073  9606 net.cpp:137] Memory required for data: 201645200
I1005 15:22:13.121088  9606 layer_factory.hpp:77] Creating layer Scale8
I1005 15:22:13.121093  9606 net.cpp:84] Creating Layer Scale8
I1005 15:22:13.121096  9606 net.cpp:406] Scale8 <- Convolution8
I1005 15:22:13.121100  9606 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 15:22:13.121135  9606 layer_factory.hpp:77] Creating layer Scale8
I1005 15:22:13.121208  9606 net.cpp:122] Setting up Scale8
I1005 15:22:13.121214  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.121217  9606 net.cpp:137] Memory required for data: 204154000
I1005 15:22:13.121222  9606 layer_factory.hpp:77] Creating layer Convolution9
I1005 15:22:13.121229  9606 net.cpp:84] Creating Layer Convolution9
I1005 15:22:13.121232  9606 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1005 15:22:13.121237  9606 net.cpp:380] Convolution9 -> Convolution9
I1005 15:22:13.122548  9606 net.cpp:122] Setting up Convolution9
I1005 15:22:13.122570  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.122572  9606 net.cpp:137] Memory required for data: 206662800
I1005 15:22:13.122587  9606 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 15:22:13.122592  9606 net.cpp:84] Creating Layer BatchNorm9
I1005 15:22:13.122596  9606 net.cpp:406] BatchNorm9 <- Convolution9
I1005 15:22:13.122601  9606 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 15:22:13.122736  9606 net.cpp:122] Setting up BatchNorm9
I1005 15:22:13.122742  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.122745  9606 net.cpp:137] Memory required for data: 209171600
I1005 15:22:13.122750  9606 layer_factory.hpp:77] Creating layer Scale9
I1005 15:22:13.122756  9606 net.cpp:84] Creating Layer Scale9
I1005 15:22:13.122759  9606 net.cpp:406] Scale9 <- Convolution9
I1005 15:22:13.122766  9606 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 15:22:13.122795  9606 layer_factory.hpp:77] Creating layer Scale9
I1005 15:22:13.122901  9606 net.cpp:122] Setting up Scale9
I1005 15:22:13.122916  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.122918  9606 net.cpp:137] Memory required for data: 211680400
I1005 15:22:13.122922  9606 layer_factory.hpp:77] Creating layer penlu8
I1005 15:22:13.122942  9606 net.cpp:84] Creating Layer penlu8
I1005 15:22:13.122946  9606 net.cpp:406] penlu8 <- Convolution9
I1005 15:22:13.122963  9606 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1005 15:22:13.123092  9606 net.cpp:122] Setting up penlu8
I1005 15:22:13.123098  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.123101  9606 net.cpp:137] Memory required for data: 214189200
I1005 15:22:13.123106  9606 layer_factory.hpp:77] Creating layer Convolution10
I1005 15:22:13.123111  9606 net.cpp:84] Creating Layer Convolution10
I1005 15:22:13.123126  9606 net.cpp:406] Convolution10 <- Convolution9
I1005 15:22:13.123129  9606 net.cpp:380] Convolution10 -> Convolution10
I1005 15:22:13.124208  9606 net.cpp:122] Setting up Convolution10
I1005 15:22:13.124229  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.124233  9606 net.cpp:137] Memory required for data: 216698000
I1005 15:22:13.124238  9606 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 15:22:13.124253  9606 net.cpp:84] Creating Layer BatchNorm10
I1005 15:22:13.124255  9606 net.cpp:406] BatchNorm10 <- Convolution10
I1005 15:22:13.124259  9606 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 15:22:13.124462  9606 net.cpp:122] Setting up BatchNorm10
I1005 15:22:13.124469  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.124480  9606 net.cpp:137] Memory required for data: 219206800
I1005 15:22:13.124485  9606 layer_factory.hpp:77] Creating layer Scale10
I1005 15:22:13.124498  9606 net.cpp:84] Creating Layer Scale10
I1005 15:22:13.124501  9606 net.cpp:406] Scale10 <- Convolution10
I1005 15:22:13.124505  9606 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 15:22:13.124559  9606 layer_factory.hpp:77] Creating layer Scale10
I1005 15:22:13.124685  9606 net.cpp:122] Setting up Scale10
I1005 15:22:13.124689  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.124702  9606 net.cpp:137] Memory required for data: 221715600
I1005 15:22:13.124706  9606 layer_factory.hpp:77] Creating layer Eltwise4
I1005 15:22:13.124711  9606 net.cpp:84] Creating Layer Eltwise4
I1005 15:22:13.124713  9606 net.cpp:406] Eltwise4 <- Convolution8
I1005 15:22:13.124727  9606 net.cpp:406] Eltwise4 <- Convolution10
I1005 15:22:13.124732  9606 net.cpp:380] Eltwise4 -> Eltwise4
I1005 15:22:13.124749  9606 net.cpp:122] Setting up Eltwise4
I1005 15:22:13.124763  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.124765  9606 net.cpp:137] Memory required for data: 224224400
I1005 15:22:13.124776  9606 layer_factory.hpp:77] Creating layer penlu9
I1005 15:22:13.124783  9606 net.cpp:84] Creating Layer penlu9
I1005 15:22:13.124784  9606 net.cpp:406] penlu9 <- Eltwise4
I1005 15:22:13.124799  9606 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1005 15:22:13.124960  9606 net.cpp:122] Setting up penlu9
I1005 15:22:13.124966  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.124969  9606 net.cpp:137] Memory required for data: 226733200
I1005 15:22:13.124974  9606 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1005 15:22:13.124977  9606 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1005 15:22:13.124990  9606 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1005 15:22:13.124994  9606 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1005 15:22:13.125000  9606 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1005 15:22:13.125044  9606 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1005 15:22:13.125049  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.125052  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.125054  9606 net.cpp:137] Memory required for data: 231750800
I1005 15:22:13.125056  9606 layer_factory.hpp:77] Creating layer Convolution11
I1005 15:22:13.125062  9606 net.cpp:84] Creating Layer Convolution11
I1005 15:22:13.125077  9606 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1005 15:22:13.125082  9606 net.cpp:380] Convolution11 -> Convolution11
I1005 15:22:13.126211  9606 net.cpp:122] Setting up Convolution11
I1005 15:22:13.126232  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.126235  9606 net.cpp:137] Memory required for data: 234259600
I1005 15:22:13.126240  9606 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 15:22:13.126245  9606 net.cpp:84] Creating Layer BatchNorm11
I1005 15:22:13.126248  9606 net.cpp:406] BatchNorm11 <- Convolution11
I1005 15:22:13.126252  9606 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 15:22:13.126411  9606 net.cpp:122] Setting up BatchNorm11
I1005 15:22:13.126417  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.126430  9606 net.cpp:137] Memory required for data: 236768400
I1005 15:22:13.126435  9606 layer_factory.hpp:77] Creating layer Scale11
I1005 15:22:13.126438  9606 net.cpp:84] Creating Layer Scale11
I1005 15:22:13.126441  9606 net.cpp:406] Scale11 <- Convolution11
I1005 15:22:13.126444  9606 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 15:22:13.126492  9606 layer_factory.hpp:77] Creating layer Scale11
I1005 15:22:13.126576  9606 net.cpp:122] Setting up Scale11
I1005 15:22:13.126583  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.126586  9606 net.cpp:137] Memory required for data: 239277200
I1005 15:22:13.126591  9606 layer_factory.hpp:77] Creating layer penlu10
I1005 15:22:13.126596  9606 net.cpp:84] Creating Layer penlu10
I1005 15:22:13.126600  9606 net.cpp:406] penlu10 <- Convolution11
I1005 15:22:13.126603  9606 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1005 15:22:13.126718  9606 net.cpp:122] Setting up penlu10
I1005 15:22:13.126722  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.126741  9606 net.cpp:137] Memory required for data: 241786000
I1005 15:22:13.126746  9606 layer_factory.hpp:77] Creating layer Convolution12
I1005 15:22:13.126754  9606 net.cpp:84] Creating Layer Convolution12
I1005 15:22:13.126757  9606 net.cpp:406] Convolution12 <- Convolution11
I1005 15:22:13.126762  9606 net.cpp:380] Convolution12 -> Convolution12
I1005 15:22:13.127785  9606 net.cpp:122] Setting up Convolution12
I1005 15:22:13.127795  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.127809  9606 net.cpp:137] Memory required for data: 244294800
I1005 15:22:13.127813  9606 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 15:22:13.127820  9606 net.cpp:84] Creating Layer BatchNorm12
I1005 15:22:13.127822  9606 net.cpp:406] BatchNorm12 <- Convolution12
I1005 15:22:13.127826  9606 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 15:22:13.127964  9606 net.cpp:122] Setting up BatchNorm12
I1005 15:22:13.127969  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.127981  9606 net.cpp:137] Memory required for data: 246803600
I1005 15:22:13.127986  9606 layer_factory.hpp:77] Creating layer Scale12
I1005 15:22:13.127990  9606 net.cpp:84] Creating Layer Scale12
I1005 15:22:13.127993  9606 net.cpp:406] Scale12 <- Convolution12
I1005 15:22:13.127997  9606 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 15:22:13.128026  9606 layer_factory.hpp:77] Creating layer Scale12
I1005 15:22:13.128100  9606 net.cpp:122] Setting up Scale12
I1005 15:22:13.128105  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.128108  9606 net.cpp:137] Memory required for data: 249312400
I1005 15:22:13.128113  9606 layer_factory.hpp:77] Creating layer Eltwise5
I1005 15:22:13.128118  9606 net.cpp:84] Creating Layer Eltwise5
I1005 15:22:13.128121  9606 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1005 15:22:13.128124  9606 net.cpp:406] Eltwise5 <- Convolution12
I1005 15:22:13.128129  9606 net.cpp:380] Eltwise5 -> Eltwise5
I1005 15:22:13.128144  9606 net.cpp:122] Setting up Eltwise5
I1005 15:22:13.128149  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.128152  9606 net.cpp:137] Memory required for data: 251821200
I1005 15:22:13.128155  9606 layer_factory.hpp:77] Creating layer penlu11
I1005 15:22:13.128160  9606 net.cpp:84] Creating Layer penlu11
I1005 15:22:13.128163  9606 net.cpp:406] penlu11 <- Eltwise5
I1005 15:22:13.128167  9606 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1005 15:22:13.128273  9606 net.cpp:122] Setting up penlu11
I1005 15:22:13.128279  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.128283  9606 net.cpp:137] Memory required for data: 254330000
I1005 15:22:13.128286  9606 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1005 15:22:13.128293  9606 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1005 15:22:13.128295  9606 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1005 15:22:13.128298  9606 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1005 15:22:13.128304  9606 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1005 15:22:13.128326  9606 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1005 15:22:13.128331  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.128335  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.128338  9606 net.cpp:137] Memory required for data: 259347600
I1005 15:22:13.128340  9606 layer_factory.hpp:77] Creating layer Convolution13
I1005 15:22:13.128347  9606 net.cpp:84] Creating Layer Convolution13
I1005 15:22:13.128350  9606 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1005 15:22:13.128356  9606 net.cpp:380] Convolution13 -> Convolution13
I1005 15:22:13.129397  9606 net.cpp:122] Setting up Convolution13
I1005 15:22:13.129407  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.129411  9606 net.cpp:137] Memory required for data: 261856400
I1005 15:22:13.129416  9606 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 15:22:13.129422  9606 net.cpp:84] Creating Layer BatchNorm13
I1005 15:22:13.129431  9606 net.cpp:406] BatchNorm13 <- Convolution13
I1005 15:22:13.129436  9606 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 15:22:13.129570  9606 net.cpp:122] Setting up BatchNorm13
I1005 15:22:13.129576  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.129580  9606 net.cpp:137] Memory required for data: 264365200
I1005 15:22:13.129585  9606 layer_factory.hpp:77] Creating layer Scale13
I1005 15:22:13.129588  9606 net.cpp:84] Creating Layer Scale13
I1005 15:22:13.129592  9606 net.cpp:406] Scale13 <- Convolution13
I1005 15:22:13.129595  9606 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 15:22:13.129624  9606 layer_factory.hpp:77] Creating layer Scale13
I1005 15:22:13.129701  9606 net.cpp:122] Setting up Scale13
I1005 15:22:13.129706  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.129709  9606 net.cpp:137] Memory required for data: 266874000
I1005 15:22:13.129714  9606 layer_factory.hpp:77] Creating layer penlu12
I1005 15:22:13.129719  9606 net.cpp:84] Creating Layer penlu12
I1005 15:22:13.129724  9606 net.cpp:406] penlu12 <- Convolution13
I1005 15:22:13.129727  9606 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1005 15:22:13.129834  9606 net.cpp:122] Setting up penlu12
I1005 15:22:13.129840  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.129843  9606 net.cpp:137] Memory required for data: 269382800
I1005 15:22:13.129848  9606 layer_factory.hpp:77] Creating layer Convolution14
I1005 15:22:13.129855  9606 net.cpp:84] Creating Layer Convolution14
I1005 15:22:13.129858  9606 net.cpp:406] Convolution14 <- Convolution13
I1005 15:22:13.129863  9606 net.cpp:380] Convolution14 -> Convolution14
I1005 15:22:13.130913  9606 net.cpp:122] Setting up Convolution14
I1005 15:22:13.130923  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.130928  9606 net.cpp:137] Memory required for data: 271891600
I1005 15:22:13.130942  9606 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 15:22:13.130952  9606 net.cpp:84] Creating Layer BatchNorm14
I1005 15:22:13.130956  9606 net.cpp:406] BatchNorm14 <- Convolution14
I1005 15:22:13.130960  9606 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 15:22:13.131093  9606 net.cpp:122] Setting up BatchNorm14
I1005 15:22:13.131098  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.131101  9606 net.cpp:137] Memory required for data: 274400400
I1005 15:22:13.131106  9606 layer_factory.hpp:77] Creating layer Scale14
I1005 15:22:13.131111  9606 net.cpp:84] Creating Layer Scale14
I1005 15:22:13.131114  9606 net.cpp:406] Scale14 <- Convolution14
I1005 15:22:13.131117  9606 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 15:22:13.131147  9606 layer_factory.hpp:77] Creating layer Scale14
I1005 15:22:13.131225  9606 net.cpp:122] Setting up Scale14
I1005 15:22:13.131232  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.131234  9606 net.cpp:137] Memory required for data: 276909200
I1005 15:22:13.131238  9606 layer_factory.hpp:77] Creating layer Eltwise6
I1005 15:22:13.131242  9606 net.cpp:84] Creating Layer Eltwise6
I1005 15:22:13.131245  9606 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1005 15:22:13.131248  9606 net.cpp:406] Eltwise6 <- Convolution14
I1005 15:22:13.131252  9606 net.cpp:380] Eltwise6 -> Eltwise6
I1005 15:22:13.131268  9606 net.cpp:122] Setting up Eltwise6
I1005 15:22:13.131271  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.131274  9606 net.cpp:137] Memory required for data: 279418000
I1005 15:22:13.131276  9606 layer_factory.hpp:77] Creating layer penlu13
I1005 15:22:13.131281  9606 net.cpp:84] Creating Layer penlu13
I1005 15:22:13.131284  9606 net.cpp:406] penlu13 <- Eltwise6
I1005 15:22:13.131289  9606 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1005 15:22:13.131393  9606 net.cpp:122] Setting up penlu13
I1005 15:22:13.131398  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.131402  9606 net.cpp:137] Memory required for data: 281926800
I1005 15:22:13.131405  9606 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1005 15:22:13.131417  9606 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1005 15:22:13.131420  9606 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1005 15:22:13.131423  9606 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1005 15:22:13.131428  9606 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1005 15:22:13.131451  9606 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1005 15:22:13.131455  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.131459  9606 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 15:22:13.131461  9606 net.cpp:137] Memory required for data: 286944400
I1005 15:22:13.131464  9606 layer_factory.hpp:77] Creating layer Convolution15
I1005 15:22:13.131469  9606 net.cpp:84] Creating Layer Convolution15
I1005 15:22:13.131472  9606 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1005 15:22:13.131476  9606 net.cpp:380] Convolution15 -> Convolution15
I1005 15:22:13.132364  9606 net.cpp:122] Setting up Convolution15
I1005 15:22:13.132374  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.132375  9606 net.cpp:137] Memory required for data: 288198800
I1005 15:22:13.132380  9606 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 15:22:13.132385  9606 net.cpp:84] Creating Layer BatchNorm15
I1005 15:22:13.132388  9606 net.cpp:406] BatchNorm15 <- Convolution15
I1005 15:22:13.132392  9606 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 15:22:13.132521  9606 net.cpp:122] Setting up BatchNorm15
I1005 15:22:13.132526  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.132529  9606 net.cpp:137] Memory required for data: 289453200
I1005 15:22:13.132534  9606 layer_factory.hpp:77] Creating layer Scale15
I1005 15:22:13.132537  9606 net.cpp:84] Creating Layer Scale15
I1005 15:22:13.132540  9606 net.cpp:406] Scale15 <- Convolution15
I1005 15:22:13.132544  9606 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 15:22:13.132570  9606 layer_factory.hpp:77] Creating layer Scale15
I1005 15:22:13.132644  9606 net.cpp:122] Setting up Scale15
I1005 15:22:13.132649  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.132652  9606 net.cpp:137] Memory required for data: 290707600
I1005 15:22:13.132655  9606 layer_factory.hpp:77] Creating layer Convolution16
I1005 15:22:13.132663  9606 net.cpp:84] Creating Layer Convolution16
I1005 15:22:13.132665  9606 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1005 15:22:13.132669  9606 net.cpp:380] Convolution16 -> Convolution16
I1005 15:22:13.134454  9606 net.cpp:122] Setting up Convolution16
I1005 15:22:13.134464  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.134466  9606 net.cpp:137] Memory required for data: 291962000
I1005 15:22:13.134471  9606 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 15:22:13.134476  9606 net.cpp:84] Creating Layer BatchNorm16
I1005 15:22:13.134479  9606 net.cpp:406] BatchNorm16 <- Convolution16
I1005 15:22:13.134485  9606 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 15:22:13.134636  9606 net.cpp:122] Setting up BatchNorm16
I1005 15:22:13.134644  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.134645  9606 net.cpp:137] Memory required for data: 293216400
I1005 15:22:13.134650  9606 layer_factory.hpp:77] Creating layer Scale16
I1005 15:22:13.134655  9606 net.cpp:84] Creating Layer Scale16
I1005 15:22:13.134658  9606 net.cpp:406] Scale16 <- Convolution16
I1005 15:22:13.134661  9606 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 15:22:13.134690  9606 layer_factory.hpp:77] Creating layer Scale16
I1005 15:22:13.134766  9606 net.cpp:122] Setting up Scale16
I1005 15:22:13.134771  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.134773  9606 net.cpp:137] Memory required for data: 294470800
I1005 15:22:13.134778  9606 layer_factory.hpp:77] Creating layer penlu14
I1005 15:22:13.134783  9606 net.cpp:84] Creating Layer penlu14
I1005 15:22:13.134784  9606 net.cpp:406] penlu14 <- Convolution16
I1005 15:22:13.134798  9606 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1005 15:22:13.134905  9606 net.cpp:122] Setting up penlu14
I1005 15:22:13.134910  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.134913  9606 net.cpp:137] Memory required for data: 295725200
I1005 15:22:13.134917  9606 layer_factory.hpp:77] Creating layer Convolution17
I1005 15:22:13.134924  9606 net.cpp:84] Creating Layer Convolution17
I1005 15:22:13.134927  9606 net.cpp:406] Convolution17 <- Convolution16
I1005 15:22:13.134932  9606 net.cpp:380] Convolution17 -> Convolution17
I1005 15:22:13.136603  9606 net.cpp:122] Setting up Convolution17
I1005 15:22:13.136612  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.136615  9606 net.cpp:137] Memory required for data: 296979600
I1005 15:22:13.136620  9606 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 15:22:13.136626  9606 net.cpp:84] Creating Layer BatchNorm17
I1005 15:22:13.136629  9606 net.cpp:406] BatchNorm17 <- Convolution17
I1005 15:22:13.136632  9606 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 15:22:13.136771  9606 net.cpp:122] Setting up BatchNorm17
I1005 15:22:13.136776  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.136780  9606 net.cpp:137] Memory required for data: 298234000
I1005 15:22:13.136785  9606 layer_factory.hpp:77] Creating layer Scale17
I1005 15:22:13.136788  9606 net.cpp:84] Creating Layer Scale17
I1005 15:22:13.136791  9606 net.cpp:406] Scale17 <- Convolution17
I1005 15:22:13.136795  9606 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 15:22:13.136823  9606 layer_factory.hpp:77] Creating layer Scale17
I1005 15:22:13.136904  9606 net.cpp:122] Setting up Scale17
I1005 15:22:13.136910  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.136912  9606 net.cpp:137] Memory required for data: 299488400
I1005 15:22:13.136917  9606 layer_factory.hpp:77] Creating layer Eltwise7
I1005 15:22:13.136922  9606 net.cpp:84] Creating Layer Eltwise7
I1005 15:22:13.136925  9606 net.cpp:406] Eltwise7 <- Convolution15
I1005 15:22:13.136929  9606 net.cpp:406] Eltwise7 <- Convolution17
I1005 15:22:13.136932  9606 net.cpp:380] Eltwise7 -> Eltwise7
I1005 15:22:13.136950  9606 net.cpp:122] Setting up Eltwise7
I1005 15:22:13.136955  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.136958  9606 net.cpp:137] Memory required for data: 300742800
I1005 15:22:13.136960  9606 layer_factory.hpp:77] Creating layer penlu15
I1005 15:22:13.136966  9606 net.cpp:84] Creating Layer penlu15
I1005 15:22:13.136970  9606 net.cpp:406] penlu15 <- Eltwise7
I1005 15:22:13.136973  9606 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1005 15:22:13.137085  9606 net.cpp:122] Setting up penlu15
I1005 15:22:13.137091  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.137094  9606 net.cpp:137] Memory required for data: 301997200
I1005 15:22:13.137099  9606 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1005 15:22:13.137102  9606 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1005 15:22:13.137104  9606 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1005 15:22:13.137109  9606 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1005 15:22:13.137112  9606 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1005 15:22:13.137136  9606 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1005 15:22:13.137140  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.137143  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.137146  9606 net.cpp:137] Memory required for data: 304506000
I1005 15:22:13.137148  9606 layer_factory.hpp:77] Creating layer Convolution18
I1005 15:22:13.137154  9606 net.cpp:84] Creating Layer Convolution18
I1005 15:22:13.137156  9606 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1005 15:22:13.137161  9606 net.cpp:380] Convolution18 -> Convolution18
I1005 15:22:13.139180  9606 net.cpp:122] Setting up Convolution18
I1005 15:22:13.139190  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.139204  9606 net.cpp:137] Memory required for data: 305760400
I1005 15:22:13.139217  9606 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 15:22:13.139222  9606 net.cpp:84] Creating Layer BatchNorm18
I1005 15:22:13.139226  9606 net.cpp:406] BatchNorm18 <- Convolution18
I1005 15:22:13.139232  9606 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 15:22:13.139369  9606 net.cpp:122] Setting up BatchNorm18
I1005 15:22:13.139374  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.139377  9606 net.cpp:137] Memory required for data: 307014800
I1005 15:22:13.139382  9606 layer_factory.hpp:77] Creating layer Scale18
I1005 15:22:13.139387  9606 net.cpp:84] Creating Layer Scale18
I1005 15:22:13.139390  9606 net.cpp:406] Scale18 <- Convolution18
I1005 15:22:13.139394  9606 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 15:22:13.139422  9606 layer_factory.hpp:77] Creating layer Scale18
I1005 15:22:13.139502  9606 net.cpp:122] Setting up Scale18
I1005 15:22:13.139508  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.139510  9606 net.cpp:137] Memory required for data: 308269200
I1005 15:22:13.139514  9606 layer_factory.hpp:77] Creating layer penlu16
I1005 15:22:13.139519  9606 net.cpp:84] Creating Layer penlu16
I1005 15:22:13.139523  9606 net.cpp:406] penlu16 <- Convolution18
I1005 15:22:13.139528  9606 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1005 15:22:13.139638  9606 net.cpp:122] Setting up penlu16
I1005 15:22:13.139644  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.139647  9606 net.cpp:137] Memory required for data: 309523600
I1005 15:22:13.139652  9606 layer_factory.hpp:77] Creating layer Convolution19
I1005 15:22:13.139658  9606 net.cpp:84] Creating Layer Convolution19
I1005 15:22:13.139662  9606 net.cpp:406] Convolution19 <- Convolution18
I1005 15:22:13.139667  9606 net.cpp:380] Convolution19 -> Convolution19
I1005 15:22:13.141808  9606 net.cpp:122] Setting up Convolution19
I1005 15:22:13.141819  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.141822  9606 net.cpp:137] Memory required for data: 310778000
I1005 15:22:13.141839  9606 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 15:22:13.141856  9606 net.cpp:84] Creating Layer BatchNorm19
I1005 15:22:13.141860  9606 net.cpp:406] BatchNorm19 <- Convolution19
I1005 15:22:13.141875  9606 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 15:22:13.142040  9606 net.cpp:122] Setting up BatchNorm19
I1005 15:22:13.142046  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.142060  9606 net.cpp:137] Memory required for data: 312032400
I1005 15:22:13.142066  9606 layer_factory.hpp:77] Creating layer Scale19
I1005 15:22:13.142071  9606 net.cpp:84] Creating Layer Scale19
I1005 15:22:13.142073  9606 net.cpp:406] Scale19 <- Convolution19
I1005 15:22:13.142077  9606 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 15:22:13.142115  9606 layer_factory.hpp:77] Creating layer Scale19
I1005 15:22:13.142213  9606 net.cpp:122] Setting up Scale19
I1005 15:22:13.142218  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.142221  9606 net.cpp:137] Memory required for data: 313286800
I1005 15:22:13.142236  9606 layer_factory.hpp:77] Creating layer Eltwise8
I1005 15:22:13.142241  9606 net.cpp:84] Creating Layer Eltwise8
I1005 15:22:13.142246  9606 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1005 15:22:13.142248  9606 net.cpp:406] Eltwise8 <- Convolution19
I1005 15:22:13.142253  9606 net.cpp:380] Eltwise8 -> Eltwise8
I1005 15:22:13.142271  9606 net.cpp:122] Setting up Eltwise8
I1005 15:22:13.142276  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.142278  9606 net.cpp:137] Memory required for data: 314541200
I1005 15:22:13.142280  9606 layer_factory.hpp:77] Creating layer penlu17
I1005 15:22:13.142287  9606 net.cpp:84] Creating Layer penlu17
I1005 15:22:13.142289  9606 net.cpp:406] penlu17 <- Eltwise8
I1005 15:22:13.142293  9606 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1005 15:22:13.142401  9606 net.cpp:122] Setting up penlu17
I1005 15:22:13.142407  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.142417  9606 net.cpp:137] Memory required for data: 315795600
I1005 15:22:13.142422  9606 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1005 15:22:13.142426  9606 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1005 15:22:13.142429  9606 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1005 15:22:13.142434  9606 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1005 15:22:13.142439  9606 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1005 15:22:13.142463  9606 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1005 15:22:13.142469  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.142473  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.142475  9606 net.cpp:137] Memory required for data: 318304400
I1005 15:22:13.142478  9606 layer_factory.hpp:77] Creating layer Convolution20
I1005 15:22:13.142485  9606 net.cpp:84] Creating Layer Convolution20
I1005 15:22:13.142488  9606 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1005 15:22:13.142493  9606 net.cpp:380] Convolution20 -> Convolution20
I1005 15:22:13.144171  9606 net.cpp:122] Setting up Convolution20
I1005 15:22:13.144181  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.144186  9606 net.cpp:137] Memory required for data: 319558800
I1005 15:22:13.144191  9606 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 15:22:13.144197  9606 net.cpp:84] Creating Layer BatchNorm20
I1005 15:22:13.144201  9606 net.cpp:406] BatchNorm20 <- Convolution20
I1005 15:22:13.144206  9606 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 15:22:13.144340  9606 net.cpp:122] Setting up BatchNorm20
I1005 15:22:13.144346  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.144349  9606 net.cpp:137] Memory required for data: 320813200
I1005 15:22:13.144354  9606 layer_factory.hpp:77] Creating layer Scale20
I1005 15:22:13.144361  9606 net.cpp:84] Creating Layer Scale20
I1005 15:22:13.144364  9606 net.cpp:406] Scale20 <- Convolution20
I1005 15:22:13.144368  9606 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 15:22:13.144397  9606 layer_factory.hpp:77] Creating layer Scale20
I1005 15:22:13.144476  9606 net.cpp:122] Setting up Scale20
I1005 15:22:13.144482  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.144485  9606 net.cpp:137] Memory required for data: 322067600
I1005 15:22:13.144490  9606 layer_factory.hpp:77] Creating layer penlu18
I1005 15:22:13.144495  9606 net.cpp:84] Creating Layer penlu18
I1005 15:22:13.144498  9606 net.cpp:406] penlu18 <- Convolution20
I1005 15:22:13.144502  9606 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1005 15:22:13.144610  9606 net.cpp:122] Setting up penlu18
I1005 15:22:13.144615  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.144618  9606 net.cpp:137] Memory required for data: 323322000
I1005 15:22:13.144623  9606 layer_factory.hpp:77] Creating layer Convolution21
I1005 15:22:13.144629  9606 net.cpp:84] Creating Layer Convolution21
I1005 15:22:13.144631  9606 net.cpp:406] Convolution21 <- Convolution20
I1005 15:22:13.144635  9606 net.cpp:380] Convolution21 -> Convolution21
I1005 15:22:13.147297  9606 net.cpp:122] Setting up Convolution21
I1005 15:22:13.147307  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.147310  9606 net.cpp:137] Memory required for data: 324576400
I1005 15:22:13.147315  9606 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 15:22:13.147321  9606 net.cpp:84] Creating Layer BatchNorm21
I1005 15:22:13.147325  9606 net.cpp:406] BatchNorm21 <- Convolution21
I1005 15:22:13.147327  9606 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 15:22:13.147462  9606 net.cpp:122] Setting up BatchNorm21
I1005 15:22:13.147467  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.147469  9606 net.cpp:137] Memory required for data: 325830800
I1005 15:22:13.147475  9606 layer_factory.hpp:77] Creating layer Scale21
I1005 15:22:13.147478  9606 net.cpp:84] Creating Layer Scale21
I1005 15:22:13.147481  9606 net.cpp:406] Scale21 <- Convolution21
I1005 15:22:13.147493  9606 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 15:22:13.147522  9606 layer_factory.hpp:77] Creating layer Scale21
I1005 15:22:13.147600  9606 net.cpp:122] Setting up Scale21
I1005 15:22:13.147604  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.147608  9606 net.cpp:137] Memory required for data: 327085200
I1005 15:22:13.147611  9606 layer_factory.hpp:77] Creating layer Eltwise9
I1005 15:22:13.147615  9606 net.cpp:84] Creating Layer Eltwise9
I1005 15:22:13.147619  9606 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1005 15:22:13.147621  9606 net.cpp:406] Eltwise9 <- Convolution21
I1005 15:22:13.147624  9606 net.cpp:380] Eltwise9 -> Eltwise9
I1005 15:22:13.147640  9606 net.cpp:122] Setting up Eltwise9
I1005 15:22:13.147644  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.147646  9606 net.cpp:137] Memory required for data: 328339600
I1005 15:22:13.147649  9606 layer_factory.hpp:77] Creating layer penlu19
I1005 15:22:13.147653  9606 net.cpp:84] Creating Layer penlu19
I1005 15:22:13.147656  9606 net.cpp:406] penlu19 <- Eltwise9
I1005 15:22:13.147660  9606 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1005 15:22:13.147768  9606 net.cpp:122] Setting up penlu19
I1005 15:22:13.147773  9606 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 15:22:13.147775  9606 net.cpp:137] Memory required for data: 329594000
I1005 15:22:13.147779  9606 layer_factory.hpp:77] Creating layer Pooling1
I1005 15:22:13.147784  9606 net.cpp:84] Creating Layer Pooling1
I1005 15:22:13.147788  9606 net.cpp:406] Pooling1 <- Eltwise9
I1005 15:22:13.147790  9606 net.cpp:380] Pooling1 -> Pooling1
I1005 15:22:13.147936  9606 net.cpp:122] Setting up Pooling1
I1005 15:22:13.147943  9606 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 15:22:13.147945  9606 net.cpp:137] Memory required for data: 329619600
I1005 15:22:13.147948  9606 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 15:22:13.147956  9606 net.cpp:84] Creating Layer InnerProduct1
I1005 15:22:13.147959  9606 net.cpp:406] InnerProduct1 <- Pooling1
I1005 15:22:13.147964  9606 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 15:22:13.148058  9606 net.cpp:122] Setting up InnerProduct1
I1005 15:22:13.148063  9606 net.cpp:129] Top shape: 100 10 (1000)
I1005 15:22:13.148066  9606 net.cpp:137] Memory required for data: 329623600
I1005 15:22:13.148071  9606 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 15:22:13.148074  9606 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 15:22:13.148077  9606 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1005 15:22:13.148080  9606 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1005 15:22:13.148084  9606 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 15:22:13.148090  9606 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 15:22:13.148583  9606 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 15:22:13.148592  9606 net.cpp:129] Top shape: (1)
I1005 15:22:13.148594  9606 net.cpp:132]     with loss weight 1
I1005 15:22:13.148607  9606 net.cpp:137] Memory required for data: 329623604
I1005 15:22:13.148609  9606 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 15:22:13.148612  9606 net.cpp:198] InnerProduct1 needs backward computation.
I1005 15:22:13.148614  9606 net.cpp:198] Pooling1 needs backward computation.
I1005 15:22:13.148617  9606 net.cpp:198] penlu19 needs backward computation.
I1005 15:22:13.148618  9606 net.cpp:198] Eltwise9 needs backward computation.
I1005 15:22:13.148620  9606 net.cpp:198] Scale21 needs backward computation.
I1005 15:22:13.148622  9606 net.cpp:198] BatchNorm21 needs backward computation.
I1005 15:22:13.148624  9606 net.cpp:198] Convolution21 needs backward computation.
I1005 15:22:13.148627  9606 net.cpp:198] penlu18 needs backward computation.
I1005 15:22:13.148629  9606 net.cpp:198] Scale20 needs backward computation.
I1005 15:22:13.148630  9606 net.cpp:198] BatchNorm20 needs backward computation.
I1005 15:22:13.148633  9606 net.cpp:198] Convolution20 needs backward computation.
I1005 15:22:13.148640  9606 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1005 15:22:13.148643  9606 net.cpp:198] penlu17 needs backward computation.
I1005 15:22:13.148645  9606 net.cpp:198] Eltwise8 needs backward computation.
I1005 15:22:13.148648  9606 net.cpp:198] Scale19 needs backward computation.
I1005 15:22:13.148650  9606 net.cpp:198] BatchNorm19 needs backward computation.
I1005 15:22:13.148653  9606 net.cpp:198] Convolution19 needs backward computation.
I1005 15:22:13.148654  9606 net.cpp:198] penlu16 needs backward computation.
I1005 15:22:13.148656  9606 net.cpp:198] Scale18 needs backward computation.
I1005 15:22:13.148658  9606 net.cpp:198] BatchNorm18 needs backward computation.
I1005 15:22:13.148660  9606 net.cpp:198] Convolution18 needs backward computation.
I1005 15:22:13.148663  9606 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1005 15:22:13.148665  9606 net.cpp:198] penlu15 needs backward computation.
I1005 15:22:13.148668  9606 net.cpp:198] Eltwise7 needs backward computation.
I1005 15:22:13.148670  9606 net.cpp:198] Scale17 needs backward computation.
I1005 15:22:13.148672  9606 net.cpp:198] BatchNorm17 needs backward computation.
I1005 15:22:13.148677  9606 net.cpp:198] Convolution17 needs backward computation.
I1005 15:22:13.148679  9606 net.cpp:198] penlu14 needs backward computation.
I1005 15:22:13.148682  9606 net.cpp:198] Scale16 needs backward computation.
I1005 15:22:13.148684  9606 net.cpp:198] BatchNorm16 needs backward computation.
I1005 15:22:13.148686  9606 net.cpp:198] Convolution16 needs backward computation.
I1005 15:22:13.148689  9606 net.cpp:198] Scale15 needs backward computation.
I1005 15:22:13.148691  9606 net.cpp:198] BatchNorm15 needs backward computation.
I1005 15:22:13.148694  9606 net.cpp:198] Convolution15 needs backward computation.
I1005 15:22:13.148695  9606 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1005 15:22:13.148699  9606 net.cpp:198] penlu13 needs backward computation.
I1005 15:22:13.148700  9606 net.cpp:198] Eltwise6 needs backward computation.
I1005 15:22:13.148703  9606 net.cpp:198] Scale14 needs backward computation.
I1005 15:22:13.148705  9606 net.cpp:198] BatchNorm14 needs backward computation.
I1005 15:22:13.148707  9606 net.cpp:198] Convolution14 needs backward computation.
I1005 15:22:13.148710  9606 net.cpp:198] penlu12 needs backward computation.
I1005 15:22:13.148712  9606 net.cpp:198] Scale13 needs backward computation.
I1005 15:22:13.148715  9606 net.cpp:198] BatchNorm13 needs backward computation.
I1005 15:22:13.148716  9606 net.cpp:198] Convolution13 needs backward computation.
I1005 15:22:13.148720  9606 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1005 15:22:13.148722  9606 net.cpp:198] penlu11 needs backward computation.
I1005 15:22:13.148725  9606 net.cpp:198] Eltwise5 needs backward computation.
I1005 15:22:13.148726  9606 net.cpp:198] Scale12 needs backward computation.
I1005 15:22:13.148730  9606 net.cpp:198] BatchNorm12 needs backward computation.
I1005 15:22:13.148731  9606 net.cpp:198] Convolution12 needs backward computation.
I1005 15:22:13.148733  9606 net.cpp:198] penlu10 needs backward computation.
I1005 15:22:13.148736  9606 net.cpp:198] Scale11 needs backward computation.
I1005 15:22:13.148738  9606 net.cpp:198] BatchNorm11 needs backward computation.
I1005 15:22:13.148741  9606 net.cpp:198] Convolution11 needs backward computation.
I1005 15:22:13.148742  9606 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1005 15:22:13.148746  9606 net.cpp:198] penlu9 needs backward computation.
I1005 15:22:13.148747  9606 net.cpp:198] Eltwise4 needs backward computation.
I1005 15:22:13.148751  9606 net.cpp:198] Scale10 needs backward computation.
I1005 15:22:13.148752  9606 net.cpp:198] BatchNorm10 needs backward computation.
I1005 15:22:13.148754  9606 net.cpp:198] Convolution10 needs backward computation.
I1005 15:22:13.148757  9606 net.cpp:198] penlu8 needs backward computation.
I1005 15:22:13.148759  9606 net.cpp:198] Scale9 needs backward computation.
I1005 15:22:13.148766  9606 net.cpp:198] BatchNorm9 needs backward computation.
I1005 15:22:13.148767  9606 net.cpp:198] Convolution9 needs backward computation.
I1005 15:22:13.148771  9606 net.cpp:198] Scale8 needs backward computation.
I1005 15:22:13.148772  9606 net.cpp:198] BatchNorm8 needs backward computation.
I1005 15:22:13.148774  9606 net.cpp:198] Convolution8 needs backward computation.
I1005 15:22:13.148777  9606 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1005 15:22:13.148779  9606 net.cpp:198] penlu7 needs backward computation.
I1005 15:22:13.148782  9606 net.cpp:198] Eltwise3 needs backward computation.
I1005 15:22:13.148784  9606 net.cpp:198] Scale7 needs backward computation.
I1005 15:22:13.148787  9606 net.cpp:198] BatchNorm7 needs backward computation.
I1005 15:22:13.148789  9606 net.cpp:198] Convolution7 needs backward computation.
I1005 15:22:13.148792  9606 net.cpp:198] penlu6 needs backward computation.
I1005 15:22:13.148793  9606 net.cpp:198] Scale6 needs backward computation.
I1005 15:22:13.148795  9606 net.cpp:198] BatchNorm6 needs backward computation.
I1005 15:22:13.148798  9606 net.cpp:198] Convolution6 needs backward computation.
I1005 15:22:13.148800  9606 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1005 15:22:13.148803  9606 net.cpp:198] penlu5 needs backward computation.
I1005 15:22:13.148805  9606 net.cpp:198] Eltwise2 needs backward computation.
I1005 15:22:13.148808  9606 net.cpp:198] Scale5 needs backward computation.
I1005 15:22:13.148810  9606 net.cpp:198] BatchNorm5 needs backward computation.
I1005 15:22:13.148813  9606 net.cpp:198] Convolution5 needs backward computation.
I1005 15:22:13.148815  9606 net.cpp:198] penlu4 needs backward computation.
I1005 15:22:13.148818  9606 net.cpp:198] Scale4 needs backward computation.
I1005 15:22:13.148819  9606 net.cpp:198] BatchNorm4 needs backward computation.
I1005 15:22:13.148823  9606 net.cpp:198] Convolution4 needs backward computation.
I1005 15:22:13.148824  9606 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1005 15:22:13.148828  9606 net.cpp:198] penlu3 needs backward computation.
I1005 15:22:13.148829  9606 net.cpp:198] Eltwise1 needs backward computation.
I1005 15:22:13.148831  9606 net.cpp:198] Scale3 needs backward computation.
I1005 15:22:13.148834  9606 net.cpp:198] BatchNorm3 needs backward computation.
I1005 15:22:13.148836  9606 net.cpp:198] Convolution3 needs backward computation.
I1005 15:22:13.148838  9606 net.cpp:198] penlu2 needs backward computation.
I1005 15:22:13.148841  9606 net.cpp:198] Scale2 needs backward computation.
I1005 15:22:13.148844  9606 net.cpp:198] BatchNorm2 needs backward computation.
I1005 15:22:13.148845  9606 net.cpp:198] Convolution2 needs backward computation.
I1005 15:22:13.148849  9606 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1005 15:22:13.148850  9606 net.cpp:198] penlu1 needs backward computation.
I1005 15:22:13.148854  9606 net.cpp:198] Scale1 needs backward computation.
I1005 15:22:13.148855  9606 net.cpp:198] BatchNorm1 needs backward computation.
I1005 15:22:13.148857  9606 net.cpp:198] Convolution1 needs backward computation.
I1005 15:22:13.148860  9606 net.cpp:200] Data1 does not need backward computation.
I1005 15:22:13.148862  9606 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 15:22:13.148895  9606 net.cpp:255] Network initialization done.
I1005 15:22:13.150585  9606 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 15:22:13.150593  9606 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 15:22:13.150599  9606 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I1005 15:22:13.150703  9606 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1005 15:22:13.151181  9606 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I1005 15:22:13.151432  9606 layer_factory.hpp:77] Creating layer Data1
I1005 15:22:13.151471  9606 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1005 15:22:13.151482  9606 net.cpp:84] Creating Layer Data1
I1005 15:22:13.151486  9606 net.cpp:380] Data1 -> Data1
I1005 15:22:13.151494  9606 net.cpp:380] Data1 -> Data2
I1005 15:22:13.151499  9606 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 15:22:13.151608  9606 data_layer.cpp:45] output data size: 100,3,32,32
I1005 15:22:13.155485  9606 net.cpp:122] Setting up Data1
I1005 15:22:13.155506  9606 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 15:22:13.155511  9606 net.cpp:129] Top shape: 100 (100)
I1005 15:22:13.155514  9606 net.cpp:137] Memory required for data: 1229200
I1005 15:22:13.155519  9606 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1005 15:22:13.155529  9606 net.cpp:84] Creating Layer Data2_Data1_1_split
I1005 15:22:13.155531  9606 net.cpp:406] Data2_Data1_1_split <- Data2
I1005 15:22:13.155536  9606 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1005 15:22:13.155544  9606 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1005 15:22:13.155606  9606 net.cpp:122] Setting up Data2_Data1_1_split
I1005 15:22:13.155613  9606 net.cpp:129] Top shape: 100 (100)
I1005 15:22:13.155630  9606 net.cpp:129] Top shape: 100 (100)
I1005 15:22:13.155633  9606 net.cpp:137] Memory required for data: 1230000
I1005 15:22:13.155635  9606 layer_factory.hpp:77] Creating layer Convolution1
I1005 15:22:13.155645  9606 net.cpp:84] Creating Layer Convolution1
I1005 15:22:13.155648  9606 net.cpp:406] Convolution1 <- Data1
I1005 15:22:13.155652  9606 net.cpp:380] Convolution1 -> Convolution1
I1005 15:22:13.156780  9606 net.cpp:122] Setting up Convolution1
I1005 15:22:13.156791  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.156795  9606 net.cpp:137] Memory required for data: 7783600
I1005 15:22:13.156802  9606 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 15:22:13.156807  9606 net.cpp:84] Creating Layer BatchNorm1
I1005 15:22:13.156810  9606 net.cpp:406] BatchNorm1 <- Convolution1
I1005 15:22:13.156814  9606 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 15:22:13.156952  9606 net.cpp:122] Setting up BatchNorm1
I1005 15:22:13.156958  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.156960  9606 net.cpp:137] Memory required for data: 14337200
I1005 15:22:13.156967  9606 layer_factory.hpp:77] Creating layer Scale1
I1005 15:22:13.156973  9606 net.cpp:84] Creating Layer Scale1
I1005 15:22:13.156977  9606 net.cpp:406] Scale1 <- Convolution1
I1005 15:22:13.156980  9606 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 15:22:13.157011  9606 layer_factory.hpp:77] Creating layer Scale1
I1005 15:22:13.157085  9606 net.cpp:122] Setting up Scale1
I1005 15:22:13.157090  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.157093  9606 net.cpp:137] Memory required for data: 20890800
I1005 15:22:13.157096  9606 layer_factory.hpp:77] Creating layer penlu1
I1005 15:22:13.157104  9606 net.cpp:84] Creating Layer penlu1
I1005 15:22:13.157106  9606 net.cpp:406] penlu1 <- Convolution1
I1005 15:22:13.157110  9606 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1005 15:22:13.157227  9606 net.cpp:122] Setting up penlu1
I1005 15:22:13.157232  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.157236  9606 net.cpp:137] Memory required for data: 27444400
I1005 15:22:13.157243  9606 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1005 15:22:13.157248  9606 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1005 15:22:13.157250  9606 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1005 15:22:13.157253  9606 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1005 15:22:13.157259  9606 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1005 15:22:13.157289  9606 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1005 15:22:13.157292  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.157296  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.157299  9606 net.cpp:137] Memory required for data: 40551600
I1005 15:22:13.157300  9606 layer_factory.hpp:77] Creating layer Convolution2
I1005 15:22:13.157306  9606 net.cpp:84] Creating Layer Convolution2
I1005 15:22:13.157310  9606 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1005 15:22:13.157315  9606 net.cpp:380] Convolution2 -> Convolution2
I1005 15:22:13.157920  9606 net.cpp:122] Setting up Convolution2
I1005 15:22:13.157928  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.157932  9606 net.cpp:137] Memory required for data: 47105200
I1005 15:22:13.157937  9606 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 15:22:13.157943  9606 net.cpp:84] Creating Layer BatchNorm2
I1005 15:22:13.157945  9606 net.cpp:406] BatchNorm2 <- Convolution2
I1005 15:22:13.157950  9606 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 15:22:13.158200  9606 net.cpp:122] Setting up BatchNorm2
I1005 15:22:13.158206  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.158210  9606 net.cpp:137] Memory required for data: 53658800
I1005 15:22:13.158215  9606 layer_factory.hpp:77] Creating layer Scale2
I1005 15:22:13.158219  9606 net.cpp:84] Creating Layer Scale2
I1005 15:22:13.158231  9606 net.cpp:406] Scale2 <- Convolution2
I1005 15:22:13.158236  9606 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 15:22:13.158265  9606 layer_factory.hpp:77] Creating layer Scale2
I1005 15:22:13.158341  9606 net.cpp:122] Setting up Scale2
I1005 15:22:13.158346  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.158349  9606 net.cpp:137] Memory required for data: 60212400
I1005 15:22:13.158354  9606 layer_factory.hpp:77] Creating layer penlu2
I1005 15:22:13.158360  9606 net.cpp:84] Creating Layer penlu2
I1005 15:22:13.158367  9606 net.cpp:406] penlu2 <- Convolution2
I1005 15:22:13.158371  9606 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1005 15:22:13.158488  9606 net.cpp:122] Setting up penlu2
I1005 15:22:13.158493  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.158496  9606 net.cpp:137] Memory required for data: 66766000
I1005 15:22:13.158501  9606 layer_factory.hpp:77] Creating layer Convolution3
I1005 15:22:13.158509  9606 net.cpp:84] Creating Layer Convolution3
I1005 15:22:13.158510  9606 net.cpp:406] Convolution3 <- Convolution2
I1005 15:22:13.158514  9606 net.cpp:380] Convolution3 -> Convolution3
I1005 15:22:13.159588  9606 net.cpp:122] Setting up Convolution3
I1005 15:22:13.159598  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.159601  9606 net.cpp:137] Memory required for data: 73319600
I1005 15:22:13.159606  9606 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 15:22:13.159611  9606 net.cpp:84] Creating Layer BatchNorm3
I1005 15:22:13.159613  9606 net.cpp:406] BatchNorm3 <- Convolution3
I1005 15:22:13.159618  9606 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 15:22:13.159752  9606 net.cpp:122] Setting up BatchNorm3
I1005 15:22:13.159756  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.159759  9606 net.cpp:137] Memory required for data: 79873200
I1005 15:22:13.159763  9606 layer_factory.hpp:77] Creating layer Scale3
I1005 15:22:13.159767  9606 net.cpp:84] Creating Layer Scale3
I1005 15:22:13.159770  9606 net.cpp:406] Scale3 <- Convolution3
I1005 15:22:13.159773  9606 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 15:22:13.159801  9606 layer_factory.hpp:77] Creating layer Scale3
I1005 15:22:13.159874  9606 net.cpp:122] Setting up Scale3
I1005 15:22:13.159880  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.159883  9606 net.cpp:137] Memory required for data: 86426800
I1005 15:22:13.159888  9606 layer_factory.hpp:77] Creating layer Eltwise1
I1005 15:22:13.159891  9606 net.cpp:84] Creating Layer Eltwise1
I1005 15:22:13.159894  9606 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1005 15:22:13.159896  9606 net.cpp:406] Eltwise1 <- Convolution3
I1005 15:22:13.159901  9606 net.cpp:380] Eltwise1 -> Eltwise1
I1005 15:22:13.159917  9606 net.cpp:122] Setting up Eltwise1
I1005 15:22:13.159921  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.159924  9606 net.cpp:137] Memory required for data: 92980400
I1005 15:22:13.159926  9606 layer_factory.hpp:77] Creating layer penlu3
I1005 15:22:13.159932  9606 net.cpp:84] Creating Layer penlu3
I1005 15:22:13.159935  9606 net.cpp:406] penlu3 <- Eltwise1
I1005 15:22:13.159942  9606 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1005 15:22:13.160059  9606 net.cpp:122] Setting up penlu3
I1005 15:22:13.160064  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.160068  9606 net.cpp:137] Memory required for data: 99534000
I1005 15:22:13.160071  9606 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1005 15:22:13.160075  9606 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1005 15:22:13.160079  9606 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1005 15:22:13.160084  9606 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1005 15:22:13.160087  9606 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1005 15:22:13.160111  9606 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1005 15:22:13.160120  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.160130  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.160131  9606 net.cpp:137] Memory required for data: 112641200
I1005 15:22:13.160135  9606 layer_factory.hpp:77] Creating layer Convolution4
I1005 15:22:13.160141  9606 net.cpp:84] Creating Layer Convolution4
I1005 15:22:13.160143  9606 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1005 15:22:13.160147  9606 net.cpp:380] Convolution4 -> Convolution4
I1005 15:22:13.161181  9606 net.cpp:122] Setting up Convolution4
I1005 15:22:13.161190  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.161193  9606 net.cpp:137] Memory required for data: 119194800
I1005 15:22:13.161198  9606 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 15:22:13.161203  9606 net.cpp:84] Creating Layer BatchNorm4
I1005 15:22:13.161206  9606 net.cpp:406] BatchNorm4 <- Convolution4
I1005 15:22:13.161212  9606 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 15:22:13.161345  9606 net.cpp:122] Setting up BatchNorm4
I1005 15:22:13.161350  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.161356  9606 net.cpp:137] Memory required for data: 125748400
I1005 15:22:13.161365  9606 layer_factory.hpp:77] Creating layer Scale4
I1005 15:22:13.161371  9606 net.cpp:84] Creating Layer Scale4
I1005 15:22:13.161375  9606 net.cpp:406] Scale4 <- Convolution4
I1005 15:22:13.161377  9606 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 15:22:13.161407  9606 layer_factory.hpp:77] Creating layer Scale4
I1005 15:22:13.161484  9606 net.cpp:122] Setting up Scale4
I1005 15:22:13.161489  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.161494  9606 net.cpp:137] Memory required for data: 132302000
I1005 15:22:13.161497  9606 layer_factory.hpp:77] Creating layer penlu4
I1005 15:22:13.161504  9606 net.cpp:84] Creating Layer penlu4
I1005 15:22:13.161506  9606 net.cpp:406] penlu4 <- Convolution4
I1005 15:22:13.161510  9606 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1005 15:22:13.161628  9606 net.cpp:122] Setting up penlu4
I1005 15:22:13.161633  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.161635  9606 net.cpp:137] Memory required for data: 138855600
I1005 15:22:13.161639  9606 layer_factory.hpp:77] Creating layer Convolution5
I1005 15:22:13.161646  9606 net.cpp:84] Creating Layer Convolution5
I1005 15:22:13.161648  9606 net.cpp:406] Convolution5 <- Convolution4
I1005 15:22:13.161653  9606 net.cpp:380] Convolution5 -> Convolution5
I1005 15:22:13.162914  9606 net.cpp:122] Setting up Convolution5
I1005 15:22:13.162923  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.162926  9606 net.cpp:137] Memory required for data: 145409200
I1005 15:22:13.162931  9606 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 15:22:13.162937  9606 net.cpp:84] Creating Layer BatchNorm5
I1005 15:22:13.162940  9606 net.cpp:406] BatchNorm5 <- Convolution5
I1005 15:22:13.162943  9606 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 15:22:13.163081  9606 net.cpp:122] Setting up BatchNorm5
I1005 15:22:13.163086  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.163089  9606 net.cpp:137] Memory required for data: 151962800
I1005 15:22:13.163094  9606 layer_factory.hpp:77] Creating layer Scale5
I1005 15:22:13.163099  9606 net.cpp:84] Creating Layer Scale5
I1005 15:22:13.163100  9606 net.cpp:406] Scale5 <- Convolution5
I1005 15:22:13.163103  9606 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 15:22:13.163131  9606 layer_factory.hpp:77] Creating layer Scale5
I1005 15:22:13.163208  9606 net.cpp:122] Setting up Scale5
I1005 15:22:13.163213  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.163214  9606 net.cpp:137] Memory required for data: 158516400
I1005 15:22:13.163218  9606 layer_factory.hpp:77] Creating layer Eltwise2
I1005 15:22:13.163223  9606 net.cpp:84] Creating Layer Eltwise2
I1005 15:22:13.163225  9606 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1005 15:22:13.163229  9606 net.cpp:406] Eltwise2 <- Convolution5
I1005 15:22:13.163233  9606 net.cpp:380] Eltwise2 -> Eltwise2
I1005 15:22:13.163256  9606 net.cpp:122] Setting up Eltwise2
I1005 15:22:13.163261  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.163264  9606 net.cpp:137] Memory required for data: 165070000
I1005 15:22:13.163266  9606 layer_factory.hpp:77] Creating layer penlu5
I1005 15:22:13.163271  9606 net.cpp:84] Creating Layer penlu5
I1005 15:22:13.163275  9606 net.cpp:406] penlu5 <- Eltwise2
I1005 15:22:13.163277  9606 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1005 15:22:13.163393  9606 net.cpp:122] Setting up penlu5
I1005 15:22:13.163398  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.163399  9606 net.cpp:137] Memory required for data: 171623600
I1005 15:22:13.163403  9606 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1005 15:22:13.163408  9606 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1005 15:22:13.163409  9606 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1005 15:22:13.163413  9606 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1005 15:22:13.163416  9606 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1005 15:22:13.163442  9606 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1005 15:22:13.163447  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.163450  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.163453  9606 net.cpp:137] Memory required for data: 184730800
I1005 15:22:13.163455  9606 layer_factory.hpp:77] Creating layer Convolution6
I1005 15:22:13.163461  9606 net.cpp:84] Creating Layer Convolution6
I1005 15:22:13.163465  9606 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1005 15:22:13.163468  9606 net.cpp:380] Convolution6 -> Convolution6
I1005 15:22:13.164394  9606 net.cpp:122] Setting up Convolution6
I1005 15:22:13.164403  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.164405  9606 net.cpp:137] Memory required for data: 191284400
I1005 15:22:13.164410  9606 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 15:22:13.164415  9606 net.cpp:84] Creating Layer BatchNorm6
I1005 15:22:13.164418  9606 net.cpp:406] BatchNorm6 <- Convolution6
I1005 15:22:13.164422  9606 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 15:22:13.164561  9606 net.cpp:122] Setting up BatchNorm6
I1005 15:22:13.164566  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.164567  9606 net.cpp:137] Memory required for data: 197838000
I1005 15:22:13.164572  9606 layer_factory.hpp:77] Creating layer Scale6
I1005 15:22:13.164577  9606 net.cpp:84] Creating Layer Scale6
I1005 15:22:13.164578  9606 net.cpp:406] Scale6 <- Convolution6
I1005 15:22:13.164582  9606 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 15:22:13.164609  9606 layer_factory.hpp:77] Creating layer Scale6
I1005 15:22:13.164685  9606 net.cpp:122] Setting up Scale6
I1005 15:22:13.164690  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.164692  9606 net.cpp:137] Memory required for data: 204391600
I1005 15:22:13.164695  9606 layer_factory.hpp:77] Creating layer penlu6
I1005 15:22:13.164701  9606 net.cpp:84] Creating Layer penlu6
I1005 15:22:13.164703  9606 net.cpp:406] penlu6 <- Convolution6
I1005 15:22:13.164707  9606 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1005 15:22:13.164825  9606 net.cpp:122] Setting up penlu6
I1005 15:22:13.164829  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.164832  9606 net.cpp:137] Memory required for data: 210945200
I1005 15:22:13.164836  9606 layer_factory.hpp:77] Creating layer Convolution7
I1005 15:22:13.164844  9606 net.cpp:84] Creating Layer Convolution7
I1005 15:22:13.164846  9606 net.cpp:406] Convolution7 <- Convolution6
I1005 15:22:13.164849  9606 net.cpp:380] Convolution7 -> Convolution7
I1005 15:22:13.165745  9606 net.cpp:122] Setting up Convolution7
I1005 15:22:13.165755  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.165757  9606 net.cpp:137] Memory required for data: 217498800
I1005 15:22:13.165761  9606 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 15:22:13.165776  9606 net.cpp:84] Creating Layer BatchNorm7
I1005 15:22:13.165778  9606 net.cpp:406] BatchNorm7 <- Convolution7
I1005 15:22:13.165782  9606 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 15:22:13.165920  9606 net.cpp:122] Setting up BatchNorm7
I1005 15:22:13.165925  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.165927  9606 net.cpp:137] Memory required for data: 224052400
I1005 15:22:13.165937  9606 layer_factory.hpp:77] Creating layer Scale7
I1005 15:22:13.165943  9606 net.cpp:84] Creating Layer Scale7
I1005 15:22:13.165946  9606 net.cpp:406] Scale7 <- Convolution7
I1005 15:22:13.165951  9606 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 15:22:13.165979  9606 layer_factory.hpp:77] Creating layer Scale7
I1005 15:22:13.166069  9606 net.cpp:122] Setting up Scale7
I1005 15:22:13.166074  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.166076  9606 net.cpp:137] Memory required for data: 230606000
I1005 15:22:13.166081  9606 layer_factory.hpp:77] Creating layer Eltwise3
I1005 15:22:13.166085  9606 net.cpp:84] Creating Layer Eltwise3
I1005 15:22:13.166087  9606 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1005 15:22:13.166100  9606 net.cpp:406] Eltwise3 <- Convolution7
I1005 15:22:13.166103  9606 net.cpp:380] Eltwise3 -> Eltwise3
I1005 15:22:13.166119  9606 net.cpp:122] Setting up Eltwise3
I1005 15:22:13.166123  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.166126  9606 net.cpp:137] Memory required for data: 237159600
I1005 15:22:13.166127  9606 layer_factory.hpp:77] Creating layer penlu7
I1005 15:22:13.166132  9606 net.cpp:84] Creating Layer penlu7
I1005 15:22:13.166134  9606 net.cpp:406] penlu7 <- Eltwise3
I1005 15:22:13.166139  9606 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1005 15:22:13.166255  9606 net.cpp:122] Setting up penlu7
I1005 15:22:13.166260  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.166262  9606 net.cpp:137] Memory required for data: 243713200
I1005 15:22:13.166266  9606 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1005 15:22:13.166270  9606 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1005 15:22:13.166272  9606 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1005 15:22:13.166276  9606 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1005 15:22:13.166280  9606 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1005 15:22:13.166303  9606 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1005 15:22:13.166307  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.166311  9606 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 15:22:13.166313  9606 net.cpp:137] Memory required for data: 256820400
I1005 15:22:13.166316  9606 layer_factory.hpp:77] Creating layer Convolution8
I1005 15:22:13.166321  9606 net.cpp:84] Creating Layer Convolution8
I1005 15:22:13.166324  9606 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1005 15:22:13.166327  9606 net.cpp:380] Convolution8 -> Convolution8
I1005 15:22:13.167270  9606 net.cpp:122] Setting up Convolution8
I1005 15:22:13.167279  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.167282  9606 net.cpp:137] Memory required for data: 260097200
I1005 15:22:13.167287  9606 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 15:22:13.167292  9606 net.cpp:84] Creating Layer BatchNorm8
I1005 15:22:13.167295  9606 net.cpp:406] BatchNorm8 <- Convolution8
I1005 15:22:13.167299  9606 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 15:22:13.167433  9606 net.cpp:122] Setting up BatchNorm8
I1005 15:22:13.167438  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.167439  9606 net.cpp:137] Memory required for data: 263374000
I1005 15:22:13.167444  9606 layer_factory.hpp:77] Creating layer Scale8
I1005 15:22:13.167448  9606 net.cpp:84] Creating Layer Scale8
I1005 15:22:13.169216  9606 net.cpp:406] Scale8 <- Convolution8
I1005 15:22:13.169229  9606 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 15:22:13.169270  9606 layer_factory.hpp:77] Creating layer Scale8
I1005 15:22:13.169378  9606 net.cpp:122] Setting up Scale8
I1005 15:22:13.169384  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.169386  9606 net.cpp:137] Memory required for data: 266650800
I1005 15:22:13.169390  9606 layer_factory.hpp:77] Creating layer Convolution9
I1005 15:22:13.169396  9606 net.cpp:84] Creating Layer Convolution9
I1005 15:22:13.169399  9606 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I1005 15:22:13.169404  9606 net.cpp:380] Convolution9 -> Convolution9
I1005 15:22:13.170439  9606 net.cpp:122] Setting up Convolution9
I1005 15:22:13.170447  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.170450  9606 net.cpp:137] Memory required for data: 269927600
I1005 15:22:13.170455  9606 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 15:22:13.170461  9606 net.cpp:84] Creating Layer BatchNorm9
I1005 15:22:13.170464  9606 net.cpp:406] BatchNorm9 <- Convolution9
I1005 15:22:13.170469  9606 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 15:22:13.170634  9606 net.cpp:122] Setting up BatchNorm9
I1005 15:22:13.170640  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.170642  9606 net.cpp:137] Memory required for data: 273204400
I1005 15:22:13.170650  9606 layer_factory.hpp:77] Creating layer Scale9
I1005 15:22:13.170655  9606 net.cpp:84] Creating Layer Scale9
I1005 15:22:13.170657  9606 net.cpp:406] Scale9 <- Convolution9
I1005 15:22:13.170660  9606 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 15:22:13.170693  9606 layer_factory.hpp:77] Creating layer Scale9
I1005 15:22:13.170784  9606 net.cpp:122] Setting up Scale9
I1005 15:22:13.170789  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.170791  9606 net.cpp:137] Memory required for data: 276481200
I1005 15:22:13.170805  9606 layer_factory.hpp:77] Creating layer penlu8
I1005 15:22:13.170814  9606 net.cpp:84] Creating Layer penlu8
I1005 15:22:13.170815  9606 net.cpp:406] penlu8 <- Convolution9
I1005 15:22:13.170819  9606 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1005 15:22:13.170954  9606 net.cpp:122] Setting up penlu8
I1005 15:22:13.170959  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.170961  9606 net.cpp:137] Memory required for data: 279758000
I1005 15:22:13.170966  9606 layer_factory.hpp:77] Creating layer Convolution10
I1005 15:22:13.170974  9606 net.cpp:84] Creating Layer Convolution10
I1005 15:22:13.170976  9606 net.cpp:406] Convolution10 <- Convolution9
I1005 15:22:13.170980  9606 net.cpp:380] Convolution10 -> Convolution10
I1005 15:22:13.172097  9606 net.cpp:122] Setting up Convolution10
I1005 15:22:13.172107  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.172109  9606 net.cpp:137] Memory required for data: 283034800
I1005 15:22:13.172114  9606 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 15:22:13.172119  9606 net.cpp:84] Creating Layer BatchNorm10
I1005 15:22:13.172122  9606 net.cpp:406] BatchNorm10 <- Convolution10
I1005 15:22:13.172127  9606 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 15:22:13.172263  9606 net.cpp:122] Setting up BatchNorm10
I1005 15:22:13.172268  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.172271  9606 net.cpp:137] Memory required for data: 286311600
I1005 15:22:13.172276  9606 layer_factory.hpp:77] Creating layer Scale10
I1005 15:22:13.172281  9606 net.cpp:84] Creating Layer Scale10
I1005 15:22:13.172282  9606 net.cpp:406] Scale10 <- Convolution10
I1005 15:22:13.172286  9606 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 15:22:13.172314  9606 layer_factory.hpp:77] Creating layer Scale10
I1005 15:22:13.172392  9606 net.cpp:122] Setting up Scale10
I1005 15:22:13.172396  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.172399  9606 net.cpp:137] Memory required for data: 289588400
I1005 15:22:13.172404  9606 layer_factory.hpp:77] Creating layer Eltwise4
I1005 15:22:13.172408  9606 net.cpp:84] Creating Layer Eltwise4
I1005 15:22:13.172411  9606 net.cpp:406] Eltwise4 <- Convolution8
I1005 15:22:13.172415  9606 net.cpp:406] Eltwise4 <- Convolution10
I1005 15:22:13.172425  9606 net.cpp:380] Eltwise4 -> Eltwise4
I1005 15:22:13.172439  9606 net.cpp:122] Setting up Eltwise4
I1005 15:22:13.172443  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.172446  9606 net.cpp:137] Memory required for data: 292865200
I1005 15:22:13.172448  9606 layer_factory.hpp:77] Creating layer penlu9
I1005 15:22:13.172454  9606 net.cpp:84] Creating Layer penlu9
I1005 15:22:13.172457  9606 net.cpp:406] penlu9 <- Eltwise4
I1005 15:22:13.172461  9606 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1005 15:22:13.172590  9606 net.cpp:122] Setting up penlu9
I1005 15:22:13.172595  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.172597  9606 net.cpp:137] Memory required for data: 296142000
I1005 15:22:13.172602  9606 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1005 15:22:13.172606  9606 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1005 15:22:13.172610  9606 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1005 15:22:13.172613  9606 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1005 15:22:13.172617  9606 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1005 15:22:13.172642  9606 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1005 15:22:13.172646  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.172649  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.172652  9606 net.cpp:137] Memory required for data: 302695600
I1005 15:22:13.172654  9606 layer_factory.hpp:77] Creating layer Convolution11
I1005 15:22:13.172662  9606 net.cpp:84] Creating Layer Convolution11
I1005 15:22:13.172664  9606 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I1005 15:22:13.172668  9606 net.cpp:380] Convolution11 -> Convolution11
I1005 15:22:13.173833  9606 net.cpp:122] Setting up Convolution11
I1005 15:22:13.173842  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.173844  9606 net.cpp:137] Memory required for data: 305972400
I1005 15:22:13.173849  9606 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 15:22:13.173856  9606 net.cpp:84] Creating Layer BatchNorm11
I1005 15:22:13.173858  9606 net.cpp:406] BatchNorm11 <- Convolution11
I1005 15:22:13.173861  9606 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 15:22:13.174000  9606 net.cpp:122] Setting up BatchNorm11
I1005 15:22:13.174005  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.174007  9606 net.cpp:137] Memory required for data: 309249200
I1005 15:22:13.174012  9606 layer_factory.hpp:77] Creating layer Scale11
I1005 15:22:13.174017  9606 net.cpp:84] Creating Layer Scale11
I1005 15:22:13.174019  9606 net.cpp:406] Scale11 <- Convolution11
I1005 15:22:13.174023  9606 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 15:22:13.174052  9606 layer_factory.hpp:77] Creating layer Scale11
I1005 15:22:13.174151  9606 net.cpp:122] Setting up Scale11
I1005 15:22:13.174155  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.174159  9606 net.cpp:137] Memory required for data: 312526000
I1005 15:22:13.174162  9606 layer_factory.hpp:77] Creating layer penlu10
I1005 15:22:13.174167  9606 net.cpp:84] Creating Layer penlu10
I1005 15:22:13.174170  9606 net.cpp:406] penlu10 <- Convolution11
I1005 15:22:13.174175  9606 net.cpp:367] penlu10 -> Convolution11 (in-place)
I1005 15:22:13.174285  9606 net.cpp:122] Setting up penlu10
I1005 15:22:13.174290  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.174293  9606 net.cpp:137] Memory required for data: 315802800
I1005 15:22:13.174298  9606 layer_factory.hpp:77] Creating layer Convolution12
I1005 15:22:13.174304  9606 net.cpp:84] Creating Layer Convolution12
I1005 15:22:13.174306  9606 net.cpp:406] Convolution12 <- Convolution11
I1005 15:22:13.174311  9606 net.cpp:380] Convolution12 -> Convolution12
I1005 15:22:13.175062  9606 net.cpp:122] Setting up Convolution12
I1005 15:22:13.175071  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.175073  9606 net.cpp:137] Memory required for data: 319079600
I1005 15:22:13.175084  9606 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 15:22:13.175091  9606 net.cpp:84] Creating Layer BatchNorm12
I1005 15:22:13.175093  9606 net.cpp:406] BatchNorm12 <- Convolution12
I1005 15:22:13.175097  9606 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 15:22:13.175251  9606 net.cpp:122] Setting up BatchNorm12
I1005 15:22:13.175256  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.175257  9606 net.cpp:137] Memory required for data: 322356400
I1005 15:22:13.175262  9606 layer_factory.hpp:77] Creating layer Scale12
I1005 15:22:13.175267  9606 net.cpp:84] Creating Layer Scale12
I1005 15:22:13.175269  9606 net.cpp:406] Scale12 <- Convolution12
I1005 15:22:13.175273  9606 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 15:22:13.175312  9606 layer_factory.hpp:77] Creating layer Scale12
I1005 15:22:13.175391  9606 net.cpp:122] Setting up Scale12
I1005 15:22:13.175396  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.175400  9606 net.cpp:137] Memory required for data: 325633200
I1005 15:22:13.175403  9606 layer_factory.hpp:77] Creating layer Eltwise5
I1005 15:22:13.175407  9606 net.cpp:84] Creating Layer Eltwise5
I1005 15:22:13.175410  9606 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1005 15:22:13.175412  9606 net.cpp:406] Eltwise5 <- Convolution12
I1005 15:22:13.175416  9606 net.cpp:380] Eltwise5 -> Eltwise5
I1005 15:22:13.175431  9606 net.cpp:122] Setting up Eltwise5
I1005 15:22:13.175434  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.175437  9606 net.cpp:137] Memory required for data: 328910000
I1005 15:22:13.175439  9606 layer_factory.hpp:77] Creating layer penlu11
I1005 15:22:13.175444  9606 net.cpp:84] Creating Layer penlu11
I1005 15:22:13.175447  9606 net.cpp:406] penlu11 <- Eltwise5
I1005 15:22:13.175451  9606 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1005 15:22:13.175567  9606 net.cpp:122] Setting up penlu11
I1005 15:22:13.175572  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.175575  9606 net.cpp:137] Memory required for data: 332186800
I1005 15:22:13.175578  9606 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1005 15:22:13.175583  9606 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1005 15:22:13.175586  9606 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1005 15:22:13.175590  9606 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1005 15:22:13.175593  9606 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1005 15:22:13.175621  9606 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1005 15:22:13.175626  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.175629  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.175631  9606 net.cpp:137] Memory required for data: 338740400
I1005 15:22:13.175634  9606 layer_factory.hpp:77] Creating layer Convolution13
I1005 15:22:13.175640  9606 net.cpp:84] Creating Layer Convolution13
I1005 15:22:13.175642  9606 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I1005 15:22:13.175647  9606 net.cpp:380] Convolution13 -> Convolution13
I1005 15:22:13.176740  9606 net.cpp:122] Setting up Convolution13
I1005 15:22:13.176749  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.176753  9606 net.cpp:137] Memory required for data: 342017200
I1005 15:22:13.176758  9606 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 15:22:13.176761  9606 net.cpp:84] Creating Layer BatchNorm13
I1005 15:22:13.176764  9606 net.cpp:406] BatchNorm13 <- Convolution13
I1005 15:22:13.176769  9606 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 15:22:13.176906  9606 net.cpp:122] Setting up BatchNorm13
I1005 15:22:13.176911  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.176914  9606 net.cpp:137] Memory required for data: 345294000
I1005 15:22:13.176919  9606 layer_factory.hpp:77] Creating layer Scale13
I1005 15:22:13.176923  9606 net.cpp:84] Creating Layer Scale13
I1005 15:22:13.176925  9606 net.cpp:406] Scale13 <- Convolution13
I1005 15:22:13.176935  9606 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 15:22:13.176965  9606 layer_factory.hpp:77] Creating layer Scale13
I1005 15:22:13.177045  9606 net.cpp:122] Setting up Scale13
I1005 15:22:13.177050  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.177053  9606 net.cpp:137] Memory required for data: 348570800
I1005 15:22:13.177057  9606 layer_factory.hpp:77] Creating layer penlu12
I1005 15:22:13.177063  9606 net.cpp:84] Creating Layer penlu12
I1005 15:22:13.177065  9606 net.cpp:406] penlu12 <- Convolution13
I1005 15:22:13.177069  9606 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1005 15:22:13.177181  9606 net.cpp:122] Setting up penlu12
I1005 15:22:13.177186  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.177188  9606 net.cpp:137] Memory required for data: 351847600
I1005 15:22:13.177193  9606 layer_factory.hpp:77] Creating layer Convolution14
I1005 15:22:13.177204  9606 net.cpp:84] Creating Layer Convolution14
I1005 15:22:13.177207  9606 net.cpp:406] Convolution14 <- Convolution13
I1005 15:22:13.177212  9606 net.cpp:380] Convolution14 -> Convolution14
I1005 15:22:13.178313  9606 net.cpp:122] Setting up Convolution14
I1005 15:22:13.178321  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.178324  9606 net.cpp:137] Memory required for data: 355124400
I1005 15:22:13.178340  9606 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 15:22:13.178346  9606 net.cpp:84] Creating Layer BatchNorm14
I1005 15:22:13.178349  9606 net.cpp:406] BatchNorm14 <- Convolution14
I1005 15:22:13.178352  9606 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 15:22:13.178513  9606 net.cpp:122] Setting up BatchNorm14
I1005 15:22:13.178517  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.178524  9606 net.cpp:137] Memory required for data: 358401200
I1005 15:22:13.178530  9606 layer_factory.hpp:77] Creating layer Scale14
I1005 15:22:13.178534  9606 net.cpp:84] Creating Layer Scale14
I1005 15:22:13.178537  9606 net.cpp:406] Scale14 <- Convolution14
I1005 15:22:13.178541  9606 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 15:22:13.178570  9606 layer_factory.hpp:77] Creating layer Scale14
I1005 15:22:13.178652  9606 net.cpp:122] Setting up Scale14
I1005 15:22:13.178655  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.178658  9606 net.cpp:137] Memory required for data: 361678000
I1005 15:22:13.178663  9606 layer_factory.hpp:77] Creating layer Eltwise6
I1005 15:22:13.178666  9606 net.cpp:84] Creating Layer Eltwise6
I1005 15:22:13.178668  9606 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I1005 15:22:13.178671  9606 net.cpp:406] Eltwise6 <- Convolution14
I1005 15:22:13.178675  9606 net.cpp:380] Eltwise6 -> Eltwise6
I1005 15:22:13.178689  9606 net.cpp:122] Setting up Eltwise6
I1005 15:22:13.178694  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.178695  9606 net.cpp:137] Memory required for data: 364954800
I1005 15:22:13.178697  9606 layer_factory.hpp:77] Creating layer penlu13
I1005 15:22:13.178704  9606 net.cpp:84] Creating Layer penlu13
I1005 15:22:13.178707  9606 net.cpp:406] penlu13 <- Eltwise6
I1005 15:22:13.178710  9606 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1005 15:22:13.178828  9606 net.cpp:122] Setting up penlu13
I1005 15:22:13.178833  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.178835  9606 net.cpp:137] Memory required for data: 368231600
I1005 15:22:13.178840  9606 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1005 15:22:13.178844  9606 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1005 15:22:13.178848  9606 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1005 15:22:13.178850  9606 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1005 15:22:13.199666  9606 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1005 15:22:13.199712  9606 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1005 15:22:13.199718  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.199723  9606 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 15:22:13.199733  9606 net.cpp:137] Memory required for data: 374785200
I1005 15:22:13.199736  9606 layer_factory.hpp:77] Creating layer Convolution15
I1005 15:22:13.199743  9606 net.cpp:84] Creating Layer Convolution15
I1005 15:22:13.199746  9606 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1005 15:22:13.199753  9606 net.cpp:380] Convolution15 -> Convolution15
I1005 15:22:13.200798  9606 net.cpp:122] Setting up Convolution15
I1005 15:22:13.200808  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.200810  9606 net.cpp:137] Memory required for data: 376423600
I1005 15:22:13.200816  9606 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 15:22:13.200822  9606 net.cpp:84] Creating Layer BatchNorm15
I1005 15:22:13.200825  9606 net.cpp:406] BatchNorm15 <- Convolution15
I1005 15:22:13.200830  9606 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 15:22:13.200986  9606 net.cpp:122] Setting up BatchNorm15
I1005 15:22:13.200992  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.200994  9606 net.cpp:137] Memory required for data: 378062000
I1005 15:22:13.201000  9606 layer_factory.hpp:77] Creating layer Scale15
I1005 15:22:13.201004  9606 net.cpp:84] Creating Layer Scale15
I1005 15:22:13.201007  9606 net.cpp:406] Scale15 <- Convolution15
I1005 15:22:13.201011  9606 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 15:22:13.201045  9606 layer_factory.hpp:77] Creating layer Scale15
I1005 15:22:13.201133  9606 net.cpp:122] Setting up Scale15
I1005 15:22:13.201138  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.201140  9606 net.cpp:137] Memory required for data: 379700400
I1005 15:22:13.201144  9606 layer_factory.hpp:77] Creating layer Convolution16
I1005 15:22:13.201153  9606 net.cpp:84] Creating Layer Convolution16
I1005 15:22:13.201156  9606 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I1005 15:22:13.201161  9606 net.cpp:380] Convolution16 -> Convolution16
I1005 15:22:13.202581  9606 net.cpp:122] Setting up Convolution16
I1005 15:22:13.202591  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.202594  9606 net.cpp:137] Memory required for data: 381338800
I1005 15:22:13.202600  9606 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 15:22:13.202605  9606 net.cpp:84] Creating Layer BatchNorm16
I1005 15:22:13.202610  9606 net.cpp:406] BatchNorm16 <- Convolution16
I1005 15:22:13.202613  9606 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 15:22:13.202766  9606 net.cpp:122] Setting up BatchNorm16
I1005 15:22:13.202771  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.202774  9606 net.cpp:137] Memory required for data: 382977200
I1005 15:22:13.202778  9606 layer_factory.hpp:77] Creating layer Scale16
I1005 15:22:13.202785  9606 net.cpp:84] Creating Layer Scale16
I1005 15:22:13.202786  9606 net.cpp:406] Scale16 <- Convolution16
I1005 15:22:13.202790  9606 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 15:22:13.202819  9606 layer_factory.hpp:77] Creating layer Scale16
I1005 15:22:13.202900  9606 net.cpp:122] Setting up Scale16
I1005 15:22:13.202904  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.202908  9606 net.cpp:137] Memory required for data: 384615600
I1005 15:22:13.202911  9606 layer_factory.hpp:77] Creating layer penlu14
I1005 15:22:13.202917  9606 net.cpp:84] Creating Layer penlu14
I1005 15:22:13.202919  9606 net.cpp:406] penlu14 <- Convolution16
I1005 15:22:13.202924  9606 net.cpp:367] penlu14 -> Convolution16 (in-place)
I1005 15:22:13.203047  9606 net.cpp:122] Setting up penlu14
I1005 15:22:13.203052  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.203055  9606 net.cpp:137] Memory required for data: 386254000
I1005 15:22:13.203059  9606 layer_factory.hpp:77] Creating layer Convolution17
I1005 15:22:13.203068  9606 net.cpp:84] Creating Layer Convolution17
I1005 15:22:13.203070  9606 net.cpp:406] Convolution17 <- Convolution16
I1005 15:22:13.203074  9606 net.cpp:380] Convolution17 -> Convolution17
I1005 15:22:13.204890  9606 net.cpp:122] Setting up Convolution17
I1005 15:22:13.204900  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.204902  9606 net.cpp:137] Memory required for data: 387892400
I1005 15:22:13.204907  9606 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 15:22:13.204911  9606 net.cpp:84] Creating Layer BatchNorm17
I1005 15:22:13.204915  9606 net.cpp:406] BatchNorm17 <- Convolution17
I1005 15:22:13.204918  9606 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 15:22:13.205065  9606 net.cpp:122] Setting up BatchNorm17
I1005 15:22:13.205070  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.205073  9606 net.cpp:137] Memory required for data: 389530800
I1005 15:22:13.205077  9606 layer_factory.hpp:77] Creating layer Scale17
I1005 15:22:13.205082  9606 net.cpp:84] Creating Layer Scale17
I1005 15:22:13.205085  9606 net.cpp:406] Scale17 <- Convolution17
I1005 15:22:13.205087  9606 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 15:22:13.205117  9606 layer_factory.hpp:77] Creating layer Scale17
I1005 15:22:13.205201  9606 net.cpp:122] Setting up Scale17
I1005 15:22:13.205205  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.205209  9606 net.cpp:137] Memory required for data: 391169200
I1005 15:22:13.205211  9606 layer_factory.hpp:77] Creating layer Eltwise7
I1005 15:22:13.205216  9606 net.cpp:84] Creating Layer Eltwise7
I1005 15:22:13.205219  9606 net.cpp:406] Eltwise7 <- Convolution15
I1005 15:22:13.205222  9606 net.cpp:406] Eltwise7 <- Convolution17
I1005 15:22:13.205225  9606 net.cpp:380] Eltwise7 -> Eltwise7
I1005 15:22:13.205243  9606 net.cpp:122] Setting up Eltwise7
I1005 15:22:13.205247  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.205250  9606 net.cpp:137] Memory required for data: 392807600
I1005 15:22:13.205252  9606 layer_factory.hpp:77] Creating layer penlu15
I1005 15:22:13.205257  9606 net.cpp:84] Creating Layer penlu15
I1005 15:22:13.205260  9606 net.cpp:406] penlu15 <- Eltwise7
I1005 15:22:13.205265  9606 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1005 15:22:13.205379  9606 net.cpp:122] Setting up penlu15
I1005 15:22:13.205384  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.205386  9606 net.cpp:137] Memory required for data: 394446000
I1005 15:22:13.205391  9606 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1005 15:22:13.205395  9606 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1005 15:22:13.205397  9606 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1005 15:22:13.205400  9606 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1005 15:22:13.205404  9606 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1005 15:22:13.205430  9606 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1005 15:22:13.205433  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.205436  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.205440  9606 net.cpp:137] Memory required for data: 397722800
I1005 15:22:13.205441  9606 layer_factory.hpp:77] Creating layer Convolution18
I1005 15:22:13.205447  9606 net.cpp:84] Creating Layer Convolution18
I1005 15:22:13.205449  9606 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I1005 15:22:13.205454  9606 net.cpp:380] Convolution18 -> Convolution18
I1005 15:22:13.207152  9606 net.cpp:122] Setting up Convolution18
I1005 15:22:13.207164  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.207165  9606 net.cpp:137] Memory required for data: 399361200
I1005 15:22:13.207170  9606 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 15:22:13.207175  9606 net.cpp:84] Creating Layer BatchNorm18
I1005 15:22:13.207177  9606 net.cpp:406] BatchNorm18 <- Convolution18
I1005 15:22:13.207182  9606 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 15:22:13.207326  9606 net.cpp:122] Setting up BatchNorm18
I1005 15:22:13.207332  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.207334  9606 net.cpp:137] Memory required for data: 400999600
I1005 15:22:13.207340  9606 layer_factory.hpp:77] Creating layer Scale18
I1005 15:22:13.207351  9606 net.cpp:84] Creating Layer Scale18
I1005 15:22:13.207355  9606 net.cpp:406] Scale18 <- Convolution18
I1005 15:22:13.207358  9606 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 15:22:13.207388  9606 layer_factory.hpp:77] Creating layer Scale18
I1005 15:22:13.207471  9606 net.cpp:122] Setting up Scale18
I1005 15:22:13.207476  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.207479  9606 net.cpp:137] Memory required for data: 402638000
I1005 15:22:13.207482  9606 layer_factory.hpp:77] Creating layer penlu16
I1005 15:22:13.207487  9606 net.cpp:84] Creating Layer penlu16
I1005 15:22:13.207490  9606 net.cpp:406] penlu16 <- Convolution18
I1005 15:22:13.207494  9606 net.cpp:367] penlu16 -> Convolution18 (in-place)
I1005 15:22:13.207609  9606 net.cpp:122] Setting up penlu16
I1005 15:22:13.207614  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.207617  9606 net.cpp:137] Memory required for data: 404276400
I1005 15:22:13.207621  9606 layer_factory.hpp:77] Creating layer Convolution19
I1005 15:22:13.207628  9606 net.cpp:84] Creating Layer Convolution19
I1005 15:22:13.207630  9606 net.cpp:406] Convolution19 <- Convolution18
I1005 15:22:13.207635  9606 net.cpp:380] Convolution19 -> Convolution19
I1005 15:22:13.209322  9606 net.cpp:122] Setting up Convolution19
I1005 15:22:13.209331  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.209333  9606 net.cpp:137] Memory required for data: 405914800
I1005 15:22:13.209338  9606 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 15:22:13.209343  9606 net.cpp:84] Creating Layer BatchNorm19
I1005 15:22:13.209347  9606 net.cpp:406] BatchNorm19 <- Convolution19
I1005 15:22:13.209350  9606 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 15:22:13.209496  9606 net.cpp:122] Setting up BatchNorm19
I1005 15:22:13.209501  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.209503  9606 net.cpp:137] Memory required for data: 407553200
I1005 15:22:13.209507  9606 layer_factory.hpp:77] Creating layer Scale19
I1005 15:22:13.209512  9606 net.cpp:84] Creating Layer Scale19
I1005 15:22:13.209514  9606 net.cpp:406] Scale19 <- Convolution19
I1005 15:22:13.209517  9606 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 15:22:13.209547  9606 layer_factory.hpp:77] Creating layer Scale19
I1005 15:22:13.209630  9606 net.cpp:122] Setting up Scale19
I1005 15:22:13.209636  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.209638  9606 net.cpp:137] Memory required for data: 409191600
I1005 15:22:13.209642  9606 layer_factory.hpp:77] Creating layer Eltwise8
I1005 15:22:13.209646  9606 net.cpp:84] Creating Layer Eltwise8
I1005 15:22:13.209650  9606 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1005 15:22:13.209652  9606 net.cpp:406] Eltwise8 <- Convolution19
I1005 15:22:13.209656  9606 net.cpp:380] Eltwise8 -> Eltwise8
I1005 15:22:13.209673  9606 net.cpp:122] Setting up Eltwise8
I1005 15:22:13.209677  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.209679  9606 net.cpp:137] Memory required for data: 410830000
I1005 15:22:13.209681  9606 layer_factory.hpp:77] Creating layer penlu17
I1005 15:22:13.209688  9606 net.cpp:84] Creating Layer penlu17
I1005 15:22:13.209691  9606 net.cpp:406] penlu17 <- Eltwise8
I1005 15:22:13.209694  9606 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1005 15:22:13.209830  9606 net.cpp:122] Setting up penlu17
I1005 15:22:13.209836  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.209837  9606 net.cpp:137] Memory required for data: 412468400
I1005 15:22:13.209841  9606 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1005 15:22:13.209846  9606 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1005 15:22:13.209848  9606 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1005 15:22:13.209852  9606 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1005 15:22:13.209856  9606 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1005 15:22:13.209882  9606 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1005 15:22:13.209892  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.209894  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.209897  9606 net.cpp:137] Memory required for data: 415745200
I1005 15:22:13.209899  9606 layer_factory.hpp:77] Creating layer Convolution20
I1005 15:22:13.209905  9606 net.cpp:84] Creating Layer Convolution20
I1005 15:22:13.209908  9606 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I1005 15:22:13.209913  9606 net.cpp:380] Convolution20 -> Convolution20
I1005 15:22:13.211930  9606 net.cpp:122] Setting up Convolution20
I1005 15:22:13.211940  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.211942  9606 net.cpp:137] Memory required for data: 417383600
I1005 15:22:13.211947  9606 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 15:22:13.211952  9606 net.cpp:84] Creating Layer BatchNorm20
I1005 15:22:13.211956  9606 net.cpp:406] BatchNorm20 <- Convolution20
I1005 15:22:13.211959  9606 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 15:22:13.212108  9606 net.cpp:122] Setting up BatchNorm20
I1005 15:22:13.212113  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.212116  9606 net.cpp:137] Memory required for data: 419022000
I1005 15:22:13.212121  9606 layer_factory.hpp:77] Creating layer Scale20
I1005 15:22:13.212124  9606 net.cpp:84] Creating Layer Scale20
I1005 15:22:13.212127  9606 net.cpp:406] Scale20 <- Convolution20
I1005 15:22:13.212132  9606 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 15:22:13.212162  9606 layer_factory.hpp:77] Creating layer Scale20
I1005 15:22:13.212247  9606 net.cpp:122] Setting up Scale20
I1005 15:22:13.212251  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.212255  9606 net.cpp:137] Memory required for data: 420660400
I1005 15:22:13.212258  9606 layer_factory.hpp:77] Creating layer penlu18
I1005 15:22:13.212263  9606 net.cpp:84] Creating Layer penlu18
I1005 15:22:13.212266  9606 net.cpp:406] penlu18 <- Convolution20
I1005 15:22:13.212270  9606 net.cpp:367] penlu18 -> Convolution20 (in-place)
I1005 15:22:13.212385  9606 net.cpp:122] Setting up penlu18
I1005 15:22:13.212389  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.212393  9606 net.cpp:137] Memory required for data: 422298800
I1005 15:22:13.212396  9606 layer_factory.hpp:77] Creating layer Convolution21
I1005 15:22:13.212404  9606 net.cpp:84] Creating Layer Convolution21
I1005 15:22:13.212406  9606 net.cpp:406] Convolution21 <- Convolution20
I1005 15:22:13.212410  9606 net.cpp:380] Convolution21 -> Convolution21
I1005 15:22:13.214432  9606 net.cpp:122] Setting up Convolution21
I1005 15:22:13.214442  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.214444  9606 net.cpp:137] Memory required for data: 423937200
I1005 15:22:13.214448  9606 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 15:22:13.214454  9606 net.cpp:84] Creating Layer BatchNorm21
I1005 15:22:13.214457  9606 net.cpp:406] BatchNorm21 <- Convolution21
I1005 15:22:13.214460  9606 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 15:22:13.214612  9606 net.cpp:122] Setting up BatchNorm21
I1005 15:22:13.214618  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.214620  9606 net.cpp:137] Memory required for data: 425575600
I1005 15:22:13.214625  9606 layer_factory.hpp:77] Creating layer Scale21
I1005 15:22:13.214629  9606 net.cpp:84] Creating Layer Scale21
I1005 15:22:13.214632  9606 net.cpp:406] Scale21 <- Convolution21
I1005 15:22:13.214635  9606 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 15:22:13.230218  9606 layer_factory.hpp:77] Creating layer Scale21
I1005 15:22:13.230319  9606 net.cpp:122] Setting up Scale21
I1005 15:22:13.230324  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.230327  9606 net.cpp:137] Memory required for data: 427214000
I1005 15:22:13.230332  9606 layer_factory.hpp:77] Creating layer Eltwise9
I1005 15:22:13.230337  9606 net.cpp:84] Creating Layer Eltwise9
I1005 15:22:13.230340  9606 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1005 15:22:13.230351  9606 net.cpp:406] Eltwise9 <- Convolution21
I1005 15:22:13.230356  9606 net.cpp:380] Eltwise9 -> Eltwise9
I1005 15:22:13.230377  9606 net.cpp:122] Setting up Eltwise9
I1005 15:22:13.230382  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.230384  9606 net.cpp:137] Memory required for data: 428852400
I1005 15:22:13.230387  9606 layer_factory.hpp:77] Creating layer penlu19
I1005 15:22:13.230393  9606 net.cpp:84] Creating Layer penlu19
I1005 15:22:13.230396  9606 net.cpp:406] penlu19 <- Eltwise9
I1005 15:22:13.230401  9606 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1005 15:22:13.230538  9606 net.cpp:122] Setting up penlu19
I1005 15:22:13.230545  9606 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 15:22:13.230548  9606 net.cpp:137] Memory required for data: 430490800
I1005 15:22:13.230553  9606 layer_factory.hpp:77] Creating layer Pooling1
I1005 15:22:13.230559  9606 net.cpp:84] Creating Layer Pooling1
I1005 15:22:13.230562  9606 net.cpp:406] Pooling1 <- Eltwise9
I1005 15:22:13.230566  9606 net.cpp:380] Pooling1 -> Pooling1
I1005 15:22:13.230718  9606 net.cpp:122] Setting up Pooling1
I1005 15:22:13.230726  9606 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 15:22:13.230729  9606 net.cpp:137] Memory required for data: 430516400
I1005 15:22:13.230732  9606 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 15:22:13.230737  9606 net.cpp:84] Creating Layer InnerProduct1
I1005 15:22:13.230741  9606 net.cpp:406] InnerProduct1 <- Pooling1
I1005 15:22:13.230746  9606 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 15:22:13.230856  9606 net.cpp:122] Setting up InnerProduct1
I1005 15:22:13.230861  9606 net.cpp:129] Top shape: 100 10 (1000)
I1005 15:22:13.230865  9606 net.cpp:137] Memory required for data: 430520400
I1005 15:22:13.230868  9606 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1005 15:22:13.230873  9606 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1005 15:22:13.230876  9606 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1005 15:22:13.230880  9606 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1005 15:22:13.230885  9606 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1005 15:22:13.230914  9606 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1005 15:22:13.230919  9606 net.cpp:129] Top shape: 100 10 (1000)
I1005 15:22:13.230923  9606 net.cpp:129] Top shape: 100 10 (1000)
I1005 15:22:13.230926  9606 net.cpp:137] Memory required for data: 430528400
I1005 15:22:13.230927  9606 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 15:22:13.230931  9606 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 15:22:13.230934  9606 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1005 15:22:13.230938  9606 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1005 15:22:13.230942  9606 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 15:22:13.230947  9606 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 15:22:13.231144  9606 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 15:22:13.231151  9606 net.cpp:129] Top shape: (1)
I1005 15:22:13.231154  9606 net.cpp:132]     with loss weight 1
I1005 15:22:13.231161  9606 net.cpp:137] Memory required for data: 430528404
I1005 15:22:13.231164  9606 layer_factory.hpp:77] Creating layer Accuracy1
I1005 15:22:13.231174  9606 net.cpp:84] Creating Layer Accuracy1
I1005 15:22:13.231178  9606 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1005 15:22:13.231181  9606 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1005 15:22:13.231185  9606 net.cpp:380] Accuracy1 -> Accuracy1
I1005 15:22:13.231192  9606 net.cpp:122] Setting up Accuracy1
I1005 15:22:13.231195  9606 net.cpp:129] Top shape: (1)
I1005 15:22:13.231199  9606 net.cpp:137] Memory required for data: 430528408
I1005 15:22:13.231200  9606 net.cpp:200] Accuracy1 does not need backward computation.
I1005 15:22:13.231204  9606 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 15:22:13.231215  9606 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1005 15:22:13.231217  9606 net.cpp:198] InnerProduct1 needs backward computation.
I1005 15:22:13.231220  9606 net.cpp:198] Pooling1 needs backward computation.
I1005 15:22:13.231222  9606 net.cpp:198] penlu19 needs backward computation.
I1005 15:22:13.231225  9606 net.cpp:198] Eltwise9 needs backward computation.
I1005 15:22:13.231227  9606 net.cpp:198] Scale21 needs backward computation.
I1005 15:22:13.231230  9606 net.cpp:198] BatchNorm21 needs backward computation.
I1005 15:22:13.231231  9606 net.cpp:198] Convolution21 needs backward computation.
I1005 15:22:13.231235  9606 net.cpp:198] penlu18 needs backward computation.
I1005 15:22:13.231236  9606 net.cpp:198] Scale20 needs backward computation.
I1005 15:22:13.231238  9606 net.cpp:198] BatchNorm20 needs backward computation.
I1005 15:22:13.231241  9606 net.cpp:198] Convolution20 needs backward computation.
I1005 15:22:13.231243  9606 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1005 15:22:13.231246  9606 net.cpp:198] penlu17 needs backward computation.
I1005 15:22:13.231248  9606 net.cpp:198] Eltwise8 needs backward computation.
I1005 15:22:13.231251  9606 net.cpp:198] Scale19 needs backward computation.
I1005 15:22:13.231253  9606 net.cpp:198] BatchNorm19 needs backward computation.
I1005 15:22:13.231256  9606 net.cpp:198] Convolution19 needs backward computation.
I1005 15:22:13.231258  9606 net.cpp:198] penlu16 needs backward computation.
I1005 15:22:13.231261  9606 net.cpp:198] Scale18 needs backward computation.
I1005 15:22:13.231262  9606 net.cpp:198] BatchNorm18 needs backward computation.
I1005 15:22:13.231264  9606 net.cpp:198] Convolution18 needs backward computation.
I1005 15:22:13.231267  9606 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1005 15:22:13.231269  9606 net.cpp:198] penlu15 needs backward computation.
I1005 15:22:13.231272  9606 net.cpp:198] Eltwise7 needs backward computation.
I1005 15:22:13.231274  9606 net.cpp:198] Scale17 needs backward computation.
I1005 15:22:13.231277  9606 net.cpp:198] BatchNorm17 needs backward computation.
I1005 15:22:13.231279  9606 net.cpp:198] Convolution17 needs backward computation.
I1005 15:22:13.231281  9606 net.cpp:198] penlu14 needs backward computation.
I1005 15:22:13.231284  9606 net.cpp:198] Scale16 needs backward computation.
I1005 15:22:13.231287  9606 net.cpp:198] BatchNorm16 needs backward computation.
I1005 15:22:13.231288  9606 net.cpp:198] Convolution16 needs backward computation.
I1005 15:22:13.231292  9606 net.cpp:198] Scale15 needs backward computation.
I1005 15:22:13.231294  9606 net.cpp:198] BatchNorm15 needs backward computation.
I1005 15:22:13.231297  9606 net.cpp:198] Convolution15 needs backward computation.
I1005 15:22:13.231299  9606 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1005 15:22:13.231302  9606 net.cpp:198] penlu13 needs backward computation.
I1005 15:22:13.231304  9606 net.cpp:198] Eltwise6 needs backward computation.
I1005 15:22:13.231307  9606 net.cpp:198] Scale14 needs backward computation.
I1005 15:22:13.231310  9606 net.cpp:198] BatchNorm14 needs backward computation.
I1005 15:22:13.231312  9606 net.cpp:198] Convolution14 needs backward computation.
I1005 15:22:13.231315  9606 net.cpp:198] penlu12 needs backward computation.
I1005 15:22:13.231317  9606 net.cpp:198] Scale13 needs backward computation.
I1005 15:22:13.231320  9606 net.cpp:198] BatchNorm13 needs backward computation.
I1005 15:22:13.232190  9606 net.cpp:198] Convolution13 needs backward computation.
I1005 15:22:13.232210  9606 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1005 15:22:13.232213  9606 net.cpp:198] penlu11 needs backward computation.
I1005 15:22:13.232215  9606 net.cpp:198] Eltwise5 needs backward computation.
I1005 15:22:13.232218  9606 net.cpp:198] Scale12 needs backward computation.
I1005 15:22:13.232221  9606 net.cpp:198] BatchNorm12 needs backward computation.
I1005 15:22:13.232230  9606 net.cpp:198] Convolution12 needs backward computation.
I1005 15:22:13.232234  9606 net.cpp:198] penlu10 needs backward computation.
I1005 15:22:13.232235  9606 net.cpp:198] Scale11 needs backward computation.
I1005 15:22:13.232239  9606 net.cpp:198] BatchNorm11 needs backward computation.
I1005 15:22:13.232240  9606 net.cpp:198] Convolution11 needs backward computation.
I1005 15:22:13.232244  9606 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1005 15:22:13.232246  9606 net.cpp:198] penlu9 needs backward computation.
I1005 15:22:13.232249  9606 net.cpp:198] Eltwise4 needs backward computation.
I1005 15:22:13.232260  9606 net.cpp:198] Scale10 needs backward computation.
I1005 15:22:13.232262  9606 net.cpp:198] BatchNorm10 needs backward computation.
I1005 15:22:13.232265  9606 net.cpp:198] Convolution10 needs backward computation.
I1005 15:22:13.232277  9606 net.cpp:198] penlu8 needs backward computation.
I1005 15:22:13.232280  9606 net.cpp:198] Scale9 needs backward computation.
I1005 15:22:13.232281  9606 net.cpp:198] BatchNorm9 needs backward computation.
I1005 15:22:13.232283  9606 net.cpp:198] Convolution9 needs backward computation.
I1005 15:22:13.232286  9606 net.cpp:198] Scale8 needs backward computation.
I1005 15:22:13.232288  9606 net.cpp:198] BatchNorm8 needs backward computation.
I1005 15:22:13.232291  9606 net.cpp:198] Convolution8 needs backward computation.
I1005 15:22:13.232293  9606 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1005 15:22:13.232296  9606 net.cpp:198] penlu7 needs backward computation.
I1005 15:22:13.232298  9606 net.cpp:198] Eltwise3 needs backward computation.
I1005 15:22:13.232301  9606 net.cpp:198] Scale7 needs backward computation.
I1005 15:22:13.232303  9606 net.cpp:198] BatchNorm7 needs backward computation.
I1005 15:22:13.232306  9606 net.cpp:198] Convolution7 needs backward computation.
I1005 15:22:13.232308  9606 net.cpp:198] penlu6 needs backward computation.
I1005 15:22:13.232311  9606 net.cpp:198] Scale6 needs backward computation.
I1005 15:22:13.232312  9606 net.cpp:198] BatchNorm6 needs backward computation.
I1005 15:22:13.232314  9606 net.cpp:198] Convolution6 needs backward computation.
I1005 15:22:13.232317  9606 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1005 15:22:13.232319  9606 net.cpp:198] penlu5 needs backward computation.
I1005 15:22:13.232322  9606 net.cpp:198] Eltwise2 needs backward computation.
I1005 15:22:13.232326  9606 net.cpp:198] Scale5 needs backward computation.
I1005 15:22:13.232327  9606 net.cpp:198] BatchNorm5 needs backward computation.
I1005 15:22:13.232329  9606 net.cpp:198] Convolution5 needs backward computation.
I1005 15:22:13.232331  9606 net.cpp:198] penlu4 needs backward computation.
I1005 15:22:13.232334  9606 net.cpp:198] Scale4 needs backward computation.
I1005 15:22:13.232336  9606 net.cpp:198] BatchNorm4 needs backward computation.
I1005 15:22:13.232338  9606 net.cpp:198] Convolution4 needs backward computation.
I1005 15:22:13.232342  9606 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1005 15:22:13.232343  9606 net.cpp:198] penlu3 needs backward computation.
I1005 15:22:13.232347  9606 net.cpp:198] Eltwise1 needs backward computation.
I1005 15:22:13.232349  9606 net.cpp:198] Scale3 needs backward computation.
I1005 15:22:13.232352  9606 net.cpp:198] BatchNorm3 needs backward computation.
I1005 15:22:13.232353  9606 net.cpp:198] Convolution3 needs backward computation.
I1005 15:22:13.232357  9606 net.cpp:198] penlu2 needs backward computation.
I1005 15:22:13.232358  9606 net.cpp:198] Scale2 needs backward computation.
I1005 15:22:13.232360  9606 net.cpp:198] BatchNorm2 needs backward computation.
I1005 15:22:13.232363  9606 net.cpp:198] Convolution2 needs backward computation.
I1005 15:22:13.232365  9606 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1005 15:22:13.232368  9606 net.cpp:198] penlu1 needs backward computation.
I1005 15:22:13.232370  9606 net.cpp:198] Scale1 needs backward computation.
I1005 15:22:13.232378  9606 net.cpp:198] BatchNorm1 needs backward computation.
I1005 15:22:13.232379  9606 net.cpp:198] Convolution1 needs backward computation.
I1005 15:22:13.232383  9606 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1005 15:22:13.232386  9606 net.cpp:200] Data1 does not need backward computation.
I1005 15:22:13.232388  9606 net.cpp:242] This network produces output Accuracy1
I1005 15:22:13.232391  9606 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 15:22:13.232425  9606 net.cpp:255] Network initialization done.
I1005 15:22:13.232676  9606 solver.cpp:56] Solver scaffolding done.
I1005 15:22:13.238245  9606 caffe.cpp:248] Starting Optimization
I1005 15:22:13.238255  9606 solver.cpp:272] Solving resnet_cifar10
I1005 15:22:13.238257  9606 solver.cpp:273] Learning Rate Policy: multistep
I1005 15:22:13.240188  9606 solver.cpp:330] Iteration 0, Testing net (#0)
I1005 15:22:14.464231  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:22:14.513278  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1005 15:22:14.513312  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1005 15:22:14.586176  9606 solver.cpp:218] Iteration 0 (0 iter/s, 1.34784s/100 iters), loss = 2.29453
I1005 15:22:14.586202  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.29453 (* 1 = 2.29453 loss)
I1005 15:22:14.586217  9606 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1005 15:22:19.818454  9606 solver.cpp:218] Iteration 100 (19.1124 iter/s, 5.2322s/100 iters), loss = 1.58819
I1005 15:22:19.818483  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.58819 (* 1 = 1.58819 loss)
I1005 15:22:19.818490  9606 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1005 15:22:25.047690  9606 solver.cpp:218] Iteration 200 (19.1236 iter/s, 5.22915s/100 iters), loss = 1.49328
I1005 15:22:25.047719  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.49328 (* 1 = 1.49328 loss)
I1005 15:22:25.047725  9606 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1005 15:22:30.270109  9606 solver.cpp:218] Iteration 300 (19.1485 iter/s, 5.22233s/100 iters), loss = 1.25352
I1005 15:22:30.270144  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25352 (* 1 = 1.25352 loss)
I1005 15:22:30.270153  9606 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1005 15:22:35.494179  9606 solver.cpp:218] Iteration 400 (19.1425 iter/s, 5.22397s/100 iters), loss = 1.04825
I1005 15:22:35.494220  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04825 (* 1 = 1.04825 loss)
I1005 15:22:35.494225  9606 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1005 15:22:40.461367  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:22:40.669507  9606 solver.cpp:330] Iteration 500, Testing net (#0)
I1005 15:22:41.851846  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:22:41.901005  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3477
I1005 15:22:41.901031  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.66988 (* 1 = 2.66988 loss)
I1005 15:22:41.952770  9606 solver.cpp:218] Iteration 500 (15.4835 iter/s, 6.45849s/100 iters), loss = 1.14079
I1005 15:22:41.952800  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14079 (* 1 = 1.14079 loss)
I1005 15:22:41.952808  9606 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1005 15:22:47.180016  9606 solver.cpp:218] Iteration 600 (19.1308 iter/s, 5.22716s/100 iters), loss = 1.06981
I1005 15:22:47.180089  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06981 (* 1 = 1.06981 loss)
I1005 15:22:47.180096  9606 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1005 15:22:52.402801  9606 solver.cpp:218] Iteration 700 (19.1473 iter/s, 5.22266s/100 iters), loss = 1.01947
I1005 15:22:52.402842  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01947 (* 1 = 1.01947 loss)
I1005 15:22:52.402848  9606 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1005 15:22:57.623149  9606 solver.cpp:218] Iteration 800 (19.1562 iter/s, 5.22025s/100 iters), loss = 1.00661
I1005 15:22:57.623191  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00661 (* 1 = 1.00661 loss)
I1005 15:22:57.623198  9606 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1005 15:23:02.839177  9606 solver.cpp:218] Iteration 900 (19.172 iter/s, 5.21593s/100 iters), loss = 0.844418
I1005 15:23:02.839218  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.844418 (* 1 = 0.844418 loss)
I1005 15:23:02.839226  9606 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1005 15:23:07.800132  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:23:08.009623  9606 solver.cpp:330] Iteration 1000, Testing net (#0)
I1005 15:23:09.193344  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:23:09.243629  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5329
I1005 15:23:09.243656  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.45388 (* 1 = 1.45388 loss)
I1005 15:23:09.297828  9606 solver.cpp:218] Iteration 1000 (15.4834 iter/s, 6.45855s/100 iters), loss = 0.934499
I1005 15:23:09.297878  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.934499 (* 1 = 0.934499 loss)
I1005 15:23:09.297886  9606 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1005 15:23:14.532438  9606 solver.cpp:218] Iteration 1100 (19.1041 iter/s, 5.23448s/100 iters), loss = 0.638256
I1005 15:23:14.532477  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.638256 (* 1 = 0.638256 loss)
I1005 15:23:14.532483  9606 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1005 15:23:19.767860  9606 solver.cpp:218] Iteration 1200 (19.101 iter/s, 5.23533s/100 iters), loss = 0.762747
I1005 15:23:19.768007  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.762747 (* 1 = 0.762747 loss)
I1005 15:23:19.768024  9606 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1005 15:23:25.003907  9606 solver.cpp:218] Iteration 1300 (19.0991 iter/s, 5.23585s/100 iters), loss = 0.821132
I1005 15:23:25.003937  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.821132 (* 1 = 0.821132 loss)
I1005 15:23:25.003953  9606 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1005 15:23:30.228694  9606 solver.cpp:218] Iteration 1400 (19.1398 iter/s, 5.2247s/100 iters), loss = 0.726193
I1005 15:23:30.228727  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.726193 (* 1 = 0.726193 loss)
I1005 15:23:30.228744  9606 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1005 15:23:35.191699  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:23:35.399683  9606 solver.cpp:330] Iteration 1500, Testing net (#0)
I1005 15:23:36.593238  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:23:36.642737  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5119
I1005 15:23:36.642773  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.48456 (* 1 = 1.48456 loss)
I1005 15:23:36.695089  9606 solver.cpp:218] Iteration 1500 (15.4648 iter/s, 6.46631s/100 iters), loss = 0.763403
I1005 15:23:36.695122  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.763403 (* 1 = 0.763403 loss)
I1005 15:23:36.695128  9606 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1005 15:23:41.920042  9606 solver.cpp:218] Iteration 1600 (19.1392 iter/s, 5.22487s/100 iters), loss = 0.617023
I1005 15:23:41.920074  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.617023 (* 1 = 0.617023 loss)
I1005 15:23:41.920081  9606 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1005 15:23:47.150396  9606 solver.cpp:218] Iteration 1700 (19.1195 iter/s, 5.23027s/100 iters), loss = 0.630686
I1005 15:23:47.150436  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.630686 (* 1 = 0.630686 loss)
I1005 15:23:47.150442  9606 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1005 15:23:52.382750  9606 solver.cpp:218] Iteration 1800 (19.1122 iter/s, 5.23226s/100 iters), loss = 0.638197
I1005 15:23:52.382881  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.638197 (* 1 = 0.638197 loss)
I1005 15:23:52.382889  9606 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1005 15:23:57.615860  9606 solver.cpp:218] Iteration 1900 (19.1097 iter/s, 5.23293s/100 iters), loss = 0.628072
I1005 15:23:57.615907  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.628072 (* 1 = 0.628072 loss)
I1005 15:23:57.615916  9606 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1005 15:24:02.581290  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:24:02.789826  9606 solver.cpp:330] Iteration 2000, Testing net (#0)
I1005 15:24:03.981963  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:24:04.031507  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6432
I1005 15:24:04.031543  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02039 (* 1 = 1.02039 loss)
I1005 15:24:04.083698  9606 solver.cpp:218] Iteration 2000 (15.4614 iter/s, 6.46774s/100 iters), loss = 0.611679
I1005 15:24:04.083724  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.611679 (* 1 = 0.611679 loss)
I1005 15:24:04.083731  9606 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1005 15:24:09.303480  9606 solver.cpp:218] Iteration 2100 (19.1582 iter/s, 5.2197s/100 iters), loss = 0.536243
I1005 15:24:09.303519  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.536243 (* 1 = 0.536243 loss)
I1005 15:24:09.303529  9606 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1005 15:24:14.537264  9606 solver.cpp:218] Iteration 2200 (19.1071 iter/s, 5.23367s/100 iters), loss = 0.503778
I1005 15:24:14.537305  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503778 (* 1 = 0.503778 loss)
I1005 15:24:14.537312  9606 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1005 15:24:19.769763  9606 solver.cpp:218] Iteration 2300 (19.1116 iter/s, 5.23241s/100 iters), loss = 0.635602
I1005 15:24:19.769810  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.635602 (* 1 = 0.635602 loss)
I1005 15:24:19.769819  9606 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1005 15:24:25.005012  9606 solver.cpp:218] Iteration 2400 (19.1016 iter/s, 5.23516s/100 iters), loss = 0.597874
I1005 15:24:25.005111  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.597874 (* 1 = 0.597874 loss)
I1005 15:24:25.005118  9606 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1005 15:24:29.965538  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:24:30.174588  9606 solver.cpp:330] Iteration 2500, Testing net (#0)
I1005 15:24:31.364519  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:24:31.414006  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6162
I1005 15:24:31.414032  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11623 (* 1 = 1.11623 loss)
I1005 15:24:31.466253  9606 solver.cpp:218] Iteration 2500 (15.4773 iter/s, 6.46109s/100 iters), loss = 0.577271
I1005 15:24:31.466284  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577271 (* 1 = 0.577271 loss)
I1005 15:24:31.466295  9606 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1005 15:24:36.700906  9606 solver.cpp:218] Iteration 2600 (19.1037 iter/s, 5.23458s/100 iters), loss = 0.524881
I1005 15:24:36.700940  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524881 (* 1 = 0.524881 loss)
I1005 15:24:36.700959  9606 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1005 15:24:41.930085  9606 solver.cpp:218] Iteration 2700 (19.1237 iter/s, 5.2291s/100 iters), loss = 0.665509
I1005 15:24:41.930119  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.665509 (* 1 = 0.665509 loss)
I1005 15:24:41.930138  9606 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1005 15:24:47.171105  9606 solver.cpp:218] Iteration 2800 (19.0805 iter/s, 5.24095s/100 iters), loss = 0.537361
I1005 15:24:47.171139  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.537361 (* 1 = 0.537361 loss)
I1005 15:24:47.171157  9606 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1005 15:24:52.412400  9606 solver.cpp:218] Iteration 2900 (19.0795 iter/s, 5.24122s/100 iters), loss = 0.521587
I1005 15:24:52.412433  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.521587 (* 1 = 0.521587 loss)
I1005 15:24:52.412452  9606 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1005 15:24:57.382954  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:24:57.595679  9606 solver.cpp:330] Iteration 3000, Testing net (#0)
I1005 15:24:58.777712  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:24:58.827172  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6131
I1005 15:24:58.827199  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13699 (* 1 = 1.13699 loss)
I1005 15:24:58.879534  9606 solver.cpp:218] Iteration 3000 (15.463 iter/s, 6.46706s/100 iters), loss = 0.454648
I1005 15:24:58.879566  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454648 (* 1 = 0.454648 loss)
I1005 15:24:58.879586  9606 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1005 15:25:04.122275  9606 solver.cpp:218] Iteration 3100 (19.0742 iter/s, 5.24267s/100 iters), loss = 0.486823
I1005 15:25:04.122308  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486823 (* 1 = 0.486823 loss)
I1005 15:25:04.122328  9606 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1005 15:25:09.358338  9606 solver.cpp:218] Iteration 3200 (19.0986 iter/s, 5.23599s/100 iters), loss = 0.474106
I1005 15:25:09.358379  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474106 (* 1 = 0.474106 loss)
I1005 15:25:09.358399  9606 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1005 15:25:14.597205  9606 solver.cpp:218] Iteration 3300 (19.0885 iter/s, 5.23876s/100 iters), loss = 0.511241
I1005 15:25:14.597239  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511241 (* 1 = 0.511241 loss)
I1005 15:25:14.597247  9606 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1005 15:25:19.829612  9606 solver.cpp:218] Iteration 3400 (19.1119 iter/s, 5.23234s/100 iters), loss = 0.562293
I1005 15:25:19.829645  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.562293 (* 1 = 0.562293 loss)
I1005 15:25:19.829663  9606 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1005 15:25:24.805559  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:25:25.014945  9606 solver.cpp:330] Iteration 3500, Testing net (#0)
I1005 15:25:26.200688  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:25:26.250432  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7133
I1005 15:25:26.250459  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.872145 (* 1 = 0.872145 loss)
I1005 15:25:26.302603  9606 solver.cpp:218] Iteration 3500 (15.449 iter/s, 6.47292s/100 iters), loss = 0.415532
I1005 15:25:26.302630  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415532 (* 1 = 0.415532 loss)
I1005 15:25:26.302639  9606 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1005 15:25:31.536871  9606 solver.cpp:218] Iteration 3600 (19.1051 iter/s, 5.2342s/100 iters), loss = 0.432466
I1005 15:25:31.536991  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432466 (* 1 = 0.432466 loss)
I1005 15:25:31.537012  9606 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1005 15:25:36.776477  9606 solver.cpp:218] Iteration 3700 (19.086 iter/s, 5.23946s/100 iters), loss = 0.488556
I1005 15:25:36.776511  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488556 (* 1 = 0.488556 loss)
I1005 15:25:36.776530  9606 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1005 15:25:42.010359  9606 solver.cpp:218] Iteration 3800 (19.1065 iter/s, 5.23382s/100 iters), loss = 0.473423
I1005 15:25:42.010391  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.473423 (* 1 = 0.473423 loss)
I1005 15:25:42.010399  9606 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1005 15:25:47.255125  9606 solver.cpp:218] Iteration 3900 (19.0669 iter/s, 5.2447s/100 iters), loss = 0.459036
I1005 15:25:47.255167  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459036 (* 1 = 0.459036 loss)
I1005 15:25:47.255172  9606 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1005 15:25:52.233283  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:25:52.442322  9606 solver.cpp:330] Iteration 4000, Testing net (#0)
I1005 15:25:53.625073  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:25:53.674712  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6423
I1005 15:25:53.674747  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03083 (* 1 = 1.03083 loss)
I1005 15:25:53.726925  9606 solver.cpp:218] Iteration 4000 (15.4518 iter/s, 6.47173s/100 iters), loss = 0.448481
I1005 15:25:53.726953  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448481 (* 1 = 0.448481 loss)
I1005 15:25:53.726959  9606 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1005 15:25:58.972508  9606 solver.cpp:218] Iteration 4100 (19.0639 iter/s, 5.24553s/100 iters), loss = 0.45063
I1005 15:25:58.972550  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45063 (* 1 = 0.45063 loss)
I1005 15:25:58.972556  9606 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1005 15:26:04.208634  9606 solver.cpp:218] Iteration 4200 (19.0983 iter/s, 5.23606s/100 iters), loss = 0.448017
I1005 15:26:04.208768  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448017 (* 1 = 0.448017 loss)
I1005 15:26:04.208775  9606 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1005 15:26:09.439903  9606 solver.cpp:218] Iteration 4300 (19.1164 iter/s, 5.23111s/100 iters), loss = 0.428085
I1005 15:26:09.439936  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428085 (* 1 = 0.428085 loss)
I1005 15:26:09.439944  9606 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1005 15:26:14.672533  9606 solver.cpp:218] Iteration 4400 (19.1111 iter/s, 5.23257s/100 iters), loss = 0.390155
I1005 15:26:14.672574  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390155 (* 1 = 0.390155 loss)
I1005 15:26:14.672580  9606 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1005 15:26:19.644517  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:26:19.853835  9606 solver.cpp:330] Iteration 4500, Testing net (#0)
I1005 15:26:21.038074  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:26:21.087688  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7001
I1005 15:26:21.087715  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.874639 (* 1 = 0.874639 loss)
I1005 15:26:21.140200  9606 solver.cpp:218] Iteration 4500 (15.4617 iter/s, 6.4676s/100 iters), loss = 0.417556
I1005 15:26:21.140229  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417556 (* 1 = 0.417556 loss)
I1005 15:26:21.140239  9606 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1005 15:26:26.380630  9606 solver.cpp:218] Iteration 4600 (19.0826 iter/s, 5.24037s/100 iters), loss = 0.476949
I1005 15:26:26.380661  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476949 (* 1 = 0.476949 loss)
I1005 15:26:26.380679  9606 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1005 15:26:31.625017  9606 solver.cpp:218] Iteration 4700 (19.0682 iter/s, 5.24433s/100 iters), loss = 0.412221
I1005 15:26:31.625047  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412221 (* 1 = 0.412221 loss)
I1005 15:26:31.625053  9606 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1005 15:26:36.863986  9606 solver.cpp:218] Iteration 4800 (19.0879 iter/s, 5.23891s/100 iters), loss = 0.39848
I1005 15:26:36.864120  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39848 (* 1 = 0.39848 loss)
I1005 15:26:36.864137  9606 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1005 15:26:42.096599  9606 solver.cpp:218] Iteration 4900 (19.1115 iter/s, 5.23245s/100 iters), loss = 0.419517
I1005 15:26:42.096629  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419517 (* 1 = 0.419517 loss)
I1005 15:26:42.096635  9606 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1005 15:26:47.073277  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:26:47.281905  9606 solver.cpp:330] Iteration 5000, Testing net (#0)
I1005 15:26:48.475077  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:26:48.525439  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7455
I1005 15:26:48.525465  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.736005 (* 1 = 0.736005 loss)
I1005 15:26:48.577761  9606 solver.cpp:218] Iteration 5000 (15.4295 iter/s, 6.4811s/100 iters), loss = 0.373446
I1005 15:26:48.577793  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373446 (* 1 = 0.373446 loss)
I1005 15:26:48.577800  9606 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1005 15:26:53.807111  9606 solver.cpp:218] Iteration 5100 (19.1231 iter/s, 5.22929s/100 iters), loss = 0.39515
I1005 15:26:53.807142  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39515 (* 1 = 0.39515 loss)
I1005 15:26:53.807157  9606 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1005 15:26:59.041590  9606 solver.cpp:218] Iteration 5200 (19.1043 iter/s, 5.23442s/100 iters), loss = 0.378685
I1005 15:26:59.041620  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378685 (* 1 = 0.378685 loss)
I1005 15:26:59.041626  9606 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1005 15:27:04.278947  9606 solver.cpp:218] Iteration 5300 (19.0938 iter/s, 5.2373s/100 iters), loss = 0.503143
I1005 15:27:04.278988  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503143 (* 1 = 0.503143 loss)
I1005 15:27:04.278995  9606 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1005 15:27:09.515919  9606 solver.cpp:218] Iteration 5400 (19.0953 iter/s, 5.2369s/100 iters), loss = 0.380649
I1005 15:27:09.516047  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380649 (* 1 = 0.380649 loss)
I1005 15:27:09.516067  9606 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1005 15:27:14.488188  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:27:14.697916  9606 solver.cpp:330] Iteration 5500, Testing net (#0)
I1005 15:27:15.890224  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:27:15.939067  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7418
I1005 15:27:15.939103  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.753252 (* 1 = 0.753252 loss)
I1005 15:27:15.991067  9606 solver.cpp:218] Iteration 5500 (15.4441 iter/s, 6.47496s/100 iters), loss = 0.356054
I1005 15:27:15.991101  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356054 (* 1 = 0.356054 loss)
I1005 15:27:15.991108  9606 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1005 15:27:21.220015  9606 solver.cpp:218] Iteration 5600 (19.1245 iter/s, 5.22888s/100 iters), loss = 0.406214
I1005 15:27:21.220047  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406214 (* 1 = 0.406214 loss)
I1005 15:27:21.220055  9606 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1005 15:27:26.456847  9606 solver.cpp:218] Iteration 5700 (19.0957 iter/s, 5.23677s/100 iters), loss = 0.415259
I1005 15:27:26.456881  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415259 (* 1 = 0.415259 loss)
I1005 15:27:26.456889  9606 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1005 15:27:31.697757  9606 solver.cpp:218] Iteration 5800 (19.0809 iter/s, 5.24085s/100 iters), loss = 0.386284
I1005 15:27:31.697790  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386284 (* 1 = 0.386284 loss)
I1005 15:27:31.697809  9606 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1005 15:27:36.935288  9606 solver.cpp:218] Iteration 5900 (19.0932 iter/s, 5.23747s/100 iters), loss = 0.354222
I1005 15:27:36.935320  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354222 (* 1 = 0.354222 loss)
I1005 15:27:36.935328  9606 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1005 15:27:41.900068  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:27:42.108598  9606 solver.cpp:330] Iteration 6000, Testing net (#0)
I1005 15:27:43.299940  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:27:43.349692  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7862
I1005 15:27:43.349717  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.636685 (* 1 = 0.636685 loss)
I1005 15:27:43.401955  9606 solver.cpp:218] Iteration 6000 (15.4641 iter/s, 6.46661s/100 iters), loss = 0.355382
I1005 15:27:43.401983  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355382 (* 1 = 0.355382 loss)
I1005 15:27:43.401990  9606 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1005 15:27:48.644675  9606 solver.cpp:218] Iteration 6100 (19.0743 iter/s, 5.24266s/100 iters), loss = 0.427221
I1005 15:27:48.644708  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427221 (* 1 = 0.427221 loss)
I1005 15:27:48.644716  9606 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1005 15:27:53.878698  9606 solver.cpp:218] Iteration 6200 (19.106 iter/s, 5.23396s/100 iters), loss = 0.361445
I1005 15:27:53.878729  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361445 (* 1 = 0.361445 loss)
I1005 15:27:53.878736  9606 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1005 15:27:59.119405  9606 solver.cpp:218] Iteration 6300 (19.0816 iter/s, 5.24065s/100 iters), loss = 0.334508
I1005 15:27:59.119434  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334508 (* 1 = 0.334508 loss)
I1005 15:27:59.119441  9606 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1005 15:28:04.369153  9606 solver.cpp:218] Iteration 6400 (19.0488 iter/s, 5.24969s/100 iters), loss = 0.414835
I1005 15:28:04.369194  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414835 (* 1 = 0.414835 loss)
I1005 15:28:04.369200  9606 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1005 15:28:09.344349  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:28:09.559654  9606 solver.cpp:330] Iteration 6500, Testing net (#0)
I1005 15:28:10.745227  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:28:10.794822  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7198
I1005 15:28:10.794858  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.839225 (* 1 = 0.839225 loss)
I1005 15:28:10.847424  9606 solver.cpp:218] Iteration 6500 (15.4364 iter/s, 6.4782s/100 iters), loss = 0.386567
I1005 15:28:10.847448  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386567 (* 1 = 0.386567 loss)
I1005 15:28:10.847456  9606 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1005 15:28:16.091011  9606 solver.cpp:218] Iteration 6600 (19.0711 iter/s, 5.24353s/100 iters), loss = 0.310617
I1005 15:28:16.091123  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310617 (* 1 = 0.310617 loss)
I1005 15:28:16.091130  9606 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1005 15:28:21.327030  9606 solver.cpp:218] Iteration 6700 (19.099 iter/s, 5.23589s/100 iters), loss = 0.452804
I1005 15:28:21.327077  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452804 (* 1 = 0.452804 loss)
I1005 15:28:21.327085  9606 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1005 15:28:26.566643  9606 solver.cpp:218] Iteration 6800 (19.0858 iter/s, 5.2395s/100 iters), loss = 0.391047
I1005 15:28:26.566676  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391047 (* 1 = 0.391047 loss)
I1005 15:28:26.566694  9606 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1005 15:28:31.806885  9606 solver.cpp:218] Iteration 6900 (19.0833 iter/s, 5.24018s/100 iters), loss = 0.389019
I1005 15:28:31.806918  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389019 (* 1 = 0.389019 loss)
I1005 15:28:31.806937  9606 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1005 15:28:36.786626  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:28:36.995872  9606 solver.cpp:330] Iteration 7000, Testing net (#0)
I1005 15:28:38.181597  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:28:38.231161  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7691
I1005 15:28:38.231190  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.690056 (* 1 = 0.690056 loss)
I1005 15:28:38.283529  9606 solver.cpp:218] Iteration 7000 (15.4402 iter/s, 6.47658s/100 iters), loss = 0.34188
I1005 15:28:38.283561  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34188 (* 1 = 0.34188 loss)
I1005 15:28:38.283571  9606 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1005 15:28:43.528147  9606 solver.cpp:218] Iteration 7100 (19.0674 iter/s, 5.24456s/100 iters), loss = 0.375096
I1005 15:28:43.528180  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375096 (* 1 = 0.375096 loss)
I1005 15:28:43.528198  9606 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1005 15:28:48.772416  9606 solver.cpp:218] Iteration 7200 (19.0687 iter/s, 5.2442s/100 iters), loss = 0.387098
I1005 15:28:48.772558  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387098 (* 1 = 0.387098 loss)
I1005 15:28:48.772578  9606 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1005 15:28:54.004117  9606 solver.cpp:218] Iteration 7300 (19.1149 iter/s, 5.23153s/100 iters), loss = 0.370497
I1005 15:28:54.004148  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370497 (* 1 = 0.370497 loss)
I1005 15:28:54.004154  9606 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1005 15:28:59.241912  9606 solver.cpp:218] Iteration 7400 (19.0922 iter/s, 5.23774s/100 iters), loss = 0.288466
I1005 15:28:59.241945  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288466 (* 1 = 0.288466 loss)
I1005 15:28:59.241961  9606 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1005 15:29:04.224982  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:29:04.433962  9606 solver.cpp:330] Iteration 7500, Testing net (#0)
I1005 15:29:05.621377  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:29:05.670961  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6857
I1005 15:29:05.670996  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06884 (* 1 = 1.06884 loss)
I1005 15:29:05.722996  9606 solver.cpp:218] Iteration 7500 (15.4297 iter/s, 6.48102s/100 iters), loss = 0.288328
I1005 15:29:05.723042  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288328 (* 1 = 0.288328 loss)
I1005 15:29:05.723049  9606 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1005 15:29:10.972527  9606 solver.cpp:218] Iteration 7600 (19.0496 iter/s, 5.24946s/100 iters), loss = 0.357057
I1005 15:29:10.972569  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357057 (* 1 = 0.357057 loss)
I1005 15:29:10.972575  9606 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1005 15:29:16.214819  9606 solver.cpp:218] Iteration 7700 (19.0759 iter/s, 5.24222s/100 iters), loss = 0.337459
I1005 15:29:16.214853  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337459 (* 1 = 0.337459 loss)
I1005 15:29:16.214869  9606 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1005 15:29:21.452091  9606 solver.cpp:218] Iteration 7800 (19.0941 iter/s, 5.23721s/100 iters), loss = 0.260421
I1005 15:29:21.452198  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260421 (* 1 = 0.260421 loss)
I1005 15:29:21.452206  9606 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1005 15:29:26.690265  9606 solver.cpp:218] Iteration 7900 (19.0911 iter/s, 5.23804s/100 iters), loss = 0.354543
I1005 15:29:26.690295  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354543 (* 1 = 0.354543 loss)
I1005 15:29:26.690312  9606 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1005 15:29:31.669296  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:29:31.878892  9606 solver.cpp:330] Iteration 8000, Testing net (#0)
I1005 15:29:33.062988  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:29:33.112347  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7859
I1005 15:29:33.112392  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.62437 (* 1 = 0.62437 loss)
I1005 15:29:33.165042  9606 solver.cpp:218] Iteration 8000 (15.4447 iter/s, 6.47472s/100 iters), loss = 0.303385
I1005 15:29:33.165069  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303385 (* 1 = 0.303385 loss)
I1005 15:29:33.165076  9606 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1005 15:29:38.407822  9606 solver.cpp:218] Iteration 8100 (19.074 iter/s, 5.24273s/100 iters), loss = 0.438281
I1005 15:29:38.407862  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438281 (* 1 = 0.438281 loss)
I1005 15:29:38.407868  9606 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1005 15:29:43.648808  9606 solver.cpp:218] Iteration 8200 (19.0806 iter/s, 5.24092s/100 iters), loss = 0.328047
I1005 15:29:43.648851  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328047 (* 1 = 0.328047 loss)
I1005 15:29:43.648857  9606 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1005 15:29:48.902299  9606 solver.cpp:218] Iteration 8300 (19.0352 iter/s, 5.25342s/100 iters), loss = 0.29083
I1005 15:29:48.902339  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29083 (* 1 = 0.29083 loss)
I1005 15:29:48.902346  9606 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1005 15:29:54.141281  9606 solver.cpp:218] Iteration 8400 (19.0879 iter/s, 5.23892s/100 iters), loss = 0.341756
I1005 15:29:54.141423  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341756 (* 1 = 0.341756 loss)
I1005 15:29:54.141441  9606 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1005 15:29:59.126250  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:29:59.334928  9606 solver.cpp:330] Iteration 8500, Testing net (#0)
I1005 15:30:00.530185  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:30:00.580922  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6831
I1005 15:30:00.580960  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.975133 (* 1 = 0.975133 loss)
I1005 15:30:00.633277  9606 solver.cpp:218] Iteration 8500 (15.404 iter/s, 6.49183s/100 iters), loss = 0.334149
I1005 15:30:00.633311  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334149 (* 1 = 0.334149 loss)
I1005 15:30:00.633318  9606 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1005 15:30:05.866209  9606 solver.cpp:218] Iteration 8600 (19.11 iter/s, 5.23287s/100 iters), loss = 0.356539
I1005 15:30:05.866240  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356539 (* 1 = 0.356539 loss)
I1005 15:30:05.866246  9606 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1005 15:30:11.107378  9606 solver.cpp:218] Iteration 8700 (19.0799 iter/s, 5.24111s/100 iters), loss = 0.311688
I1005 15:30:11.107408  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311688 (* 1 = 0.311688 loss)
I1005 15:30:11.107424  9606 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1005 15:30:16.351905  9606 solver.cpp:218] Iteration 8800 (19.0677 iter/s, 5.24447s/100 iters), loss = 0.299995
I1005 15:30:16.351934  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299995 (* 1 = 0.299995 loss)
I1005 15:30:16.351951  9606 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1005 15:30:21.594224  9606 solver.cpp:218] Iteration 8900 (19.0757 iter/s, 5.24226s/100 iters), loss = 0.284806
I1005 15:30:21.594259  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284807 (* 1 = 0.284807 loss)
I1005 15:30:21.594267  9606 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1005 15:30:26.566584  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:30:26.776201  9606 solver.cpp:330] Iteration 9000, Testing net (#0)
I1005 15:30:27.969954  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:30:28.019201  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7419
I1005 15:30:28.019227  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.815597 (* 1 = 0.815597 loss)
I1005 15:30:28.071491  9606 solver.cpp:218] Iteration 9000 (15.4388 iter/s, 6.47721s/100 iters), loss = 0.366491
I1005 15:30:28.071523  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366491 (* 1 = 0.366491 loss)
I1005 15:30:28.071533  9606 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1005 15:30:33.310849  9606 solver.cpp:218] Iteration 9100 (19.0865 iter/s, 5.2393s/100 iters), loss = 0.327071
I1005 15:30:33.310904  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327071 (* 1 = 0.327071 loss)
I1005 15:30:33.310930  9606 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1005 15:30:38.557209  9606 solver.cpp:218] Iteration 9200 (19.0615 iter/s, 5.24618s/100 iters), loss = 0.318341
I1005 15:30:38.557240  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318341 (* 1 = 0.318341 loss)
I1005 15:30:38.557245  9606 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1005 15:30:43.803787  9606 solver.cpp:218] Iteration 9300 (19.0602 iter/s, 5.24652s/100 iters), loss = 0.326295
I1005 15:30:43.803818  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326295 (* 1 = 0.326295 loss)
I1005 15:30:43.803825  9606 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1005 15:30:49.048661  9606 solver.cpp:218] Iteration 9400 (19.0664 iter/s, 5.24482s/100 iters), loss = 0.324545
I1005 15:30:49.048732  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324545 (* 1 = 0.324545 loss)
I1005 15:30:49.048753  9606 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1005 15:30:54.024354  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:30:54.234156  9606 solver.cpp:330] Iteration 9500, Testing net (#0)
I1005 15:30:55.427808  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:30:55.477495  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7767
I1005 15:30:55.477530  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.671934 (* 1 = 0.671934 loss)
I1005 15:30:55.529937  9606 solver.cpp:218] Iteration 9500 (15.4293 iter/s, 6.48119s/100 iters), loss = 0.25179
I1005 15:30:55.529963  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25179 (* 1 = 0.25179 loss)
I1005 15:30:55.529969  9606 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1005 15:31:00.773041  9606 solver.cpp:218] Iteration 9600 (19.0729 iter/s, 5.24305s/100 iters), loss = 0.331278
I1005 15:31:00.773159  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331279 (* 1 = 0.331279 loss)
I1005 15:31:00.773178  9606 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1005 15:31:06.008716  9606 solver.cpp:218] Iteration 9700 (19.1003 iter/s, 5.23553s/100 iters), loss = 0.324658
I1005 15:31:06.008747  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324658 (* 1 = 0.324658 loss)
I1005 15:31:06.008754  9606 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1005 15:31:11.255367  9606 solver.cpp:218] Iteration 9800 (19.06 iter/s, 5.24659s/100 iters), loss = 0.313209
I1005 15:31:11.255408  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313209 (* 1 = 0.313209 loss)
I1005 15:31:11.255414  9606 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1005 15:31:16.504117  9606 solver.cpp:218] Iteration 9900 (19.0524 iter/s, 5.24868s/100 iters), loss = 0.314038
I1005 15:31:16.504158  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314038 (* 1 = 0.314038 loss)
I1005 15:31:16.504163  9606 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1005 15:31:21.485193  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:31:21.696867  9606 solver.cpp:330] Iteration 10000, Testing net (#0)
I1005 15:31:22.882211  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:31:22.931996  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6172
I1005 15:31:22.932032  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37478 (* 1 = 1.37478 loss)
I1005 15:31:22.984380  9606 solver.cpp:218] Iteration 10000 (15.4316 iter/s, 6.48019s/100 iters), loss = 0.305585
I1005 15:31:22.984405  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305585 (* 1 = 0.305585 loss)
I1005 15:31:22.984412  9606 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1005 15:31:28.228726  9606 solver.cpp:218] Iteration 10100 (19.0683 iter/s, 5.24429s/100 iters), loss = 0.392937
I1005 15:31:28.228756  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392937 (* 1 = 0.392937 loss)
I1005 15:31:28.228763  9606 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1005 15:31:33.469494  9606 solver.cpp:218] Iteration 10200 (19.0814 iter/s, 5.24071s/100 iters), loss = 0.298969
I1005 15:31:33.469665  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29897 (* 1 = 0.29897 loss)
I1005 15:31:33.469674  9606 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1005 15:31:38.710311  9606 solver.cpp:218] Iteration 10300 (19.0817 iter/s, 5.24063s/100 iters), loss = 0.337836
I1005 15:31:38.710341  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337836 (* 1 = 0.337836 loss)
I1005 15:31:38.710348  9606 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1005 15:31:43.957237  9606 solver.cpp:218] Iteration 10400 (19.059 iter/s, 5.24687s/100 iters), loss = 0.269352
I1005 15:31:43.957285  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269352 (* 1 = 0.269352 loss)
I1005 15:31:43.957291  9606 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1005 15:31:48.937819  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:31:49.146946  9606 solver.cpp:330] Iteration 10500, Testing net (#0)
I1005 15:31:50.334882  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:31:50.384591  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7371
I1005 15:31:50.384626  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.820113 (* 1 = 0.820113 loss)
I1005 15:31:50.437150  9606 solver.cpp:218] Iteration 10500 (15.4325 iter/s, 6.47984s/100 iters), loss = 0.301481
I1005 15:31:50.437180  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301482 (* 1 = 0.301482 loss)
I1005 15:31:50.437186  9606 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1005 15:31:55.679266  9606 solver.cpp:218] Iteration 10600 (19.0765 iter/s, 5.24206s/100 iters), loss = 0.335295
I1005 15:31:55.679296  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335296 (* 1 = 0.335296 loss)
I1005 15:31:55.679302  9606 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1005 15:32:00.927615  9606 solver.cpp:218] Iteration 10700 (19.0538 iter/s, 5.24829s/100 iters), loss = 0.306675
I1005 15:32:00.927647  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306676 (* 1 = 0.306676 loss)
I1005 15:32:00.927664  9606 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1005 15:32:06.167199  9606 solver.cpp:218] Iteration 10800 (19.0857 iter/s, 5.23952s/100 iters), loss = 0.272177
I1005 15:32:06.167313  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272178 (* 1 = 0.272178 loss)
I1005 15:32:06.167320  9606 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1005 15:32:11.413795  9606 solver.cpp:218] Iteration 10900 (19.0604 iter/s, 5.24647s/100 iters), loss = 0.366374
I1005 15:32:11.413827  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366374 (* 1 = 0.366374 loss)
I1005 15:32:11.413836  9606 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1005 15:32:16.399807  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:32:16.608448  9606 solver.cpp:330] Iteration 11000, Testing net (#0)
I1005 15:32:17.796804  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:32:17.846591  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7799
I1005 15:32:17.846627  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.679109 (* 1 = 0.679109 loss)
I1005 15:32:17.898866  9606 solver.cpp:218] Iteration 11000 (15.4202 iter/s, 6.48501s/100 iters), loss = 0.207714
I1005 15:32:17.898898  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207714 (* 1 = 0.207714 loss)
I1005 15:32:17.898905  9606 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1005 15:32:23.149241  9606 solver.cpp:218] Iteration 11100 (19.0465 iter/s, 5.25032s/100 iters), loss = 0.328312
I1005 15:32:23.149281  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328313 (* 1 = 0.328313 loss)
I1005 15:32:23.149287  9606 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1005 15:32:28.391486  9606 solver.cpp:218] Iteration 11200 (19.076 iter/s, 5.24218s/100 iters), loss = 0.272441
I1005 15:32:28.391515  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272441 (* 1 = 0.272441 loss)
I1005 15:32:28.391522  9606 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1005 15:32:33.634824  9606 solver.cpp:218] Iteration 11300 (19.072 iter/s, 5.24328s/100 iters), loss = 0.273306
I1005 15:32:33.634855  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273306 (* 1 = 0.273306 loss)
I1005 15:32:33.634862  9606 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1005 15:32:38.872537  9606 solver.cpp:218] Iteration 11400 (19.0925 iter/s, 5.23766s/100 iters), loss = 0.307288
I1005 15:32:38.872638  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307288 (* 1 = 0.307288 loss)
I1005 15:32:38.872656  9606 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1005 15:32:43.855340  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:32:44.064755  9606 solver.cpp:330] Iteration 11500, Testing net (#0)
I1005 15:32:45.251658  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:32:45.302232  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8153
I1005 15:32:45.302280  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.557428 (* 1 = 0.557428 loss)
I1005 15:32:45.355518  9606 solver.cpp:218] Iteration 11500 (15.4253 iter/s, 6.48285s/100 iters), loss = 0.241891
I1005 15:32:45.355554  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241891 (* 1 = 0.241891 loss)
I1005 15:32:45.355572  9606 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1005 15:32:50.598167  9606 solver.cpp:218] Iteration 11600 (19.0747 iter/s, 5.24255s/100 iters), loss = 0.249788
I1005 15:32:50.598206  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249788 (* 1 = 0.249788 loss)
I1005 15:32:50.598212  9606 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1005 15:32:55.839293  9606 solver.cpp:218] Iteration 11700 (19.0801 iter/s, 5.24107s/100 iters), loss = 0.346087
I1005 15:32:55.839334  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346087 (* 1 = 0.346087 loss)
I1005 15:32:55.839340  9606 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1005 15:33:01.088078  9606 solver.cpp:218] Iteration 11800 (19.0523 iter/s, 5.24872s/100 iters), loss = 0.39521
I1005 15:33:01.088119  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39521 (* 1 = 0.39521 loss)
I1005 15:33:01.088125  9606 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1005 15:33:06.327742  9606 solver.cpp:218] Iteration 11900 (19.0854 iter/s, 5.2396s/100 iters), loss = 0.237544
I1005 15:33:06.327791  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237544 (* 1 = 0.237544 loss)
I1005 15:33:06.327798  9606 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1005 15:33:11.312860  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:33:11.522815  9606 solver.cpp:330] Iteration 12000, Testing net (#0)
I1005 15:33:12.715296  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:33:12.764784  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6975
I1005 15:33:12.764811  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.952885 (* 1 = 0.952885 loss)
I1005 15:33:12.817076  9606 solver.cpp:218] Iteration 12000 (15.4101 iter/s, 6.48926s/100 iters), loss = 0.287094
I1005 15:33:12.817111  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287094 (* 1 = 0.287094 loss)
I1005 15:33:12.817131  9606 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1005 15:33:18.052793  9606 solver.cpp:218] Iteration 12100 (19.0998 iter/s, 5.23566s/100 iters), loss = 0.336297
I1005 15:33:18.052825  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336297 (* 1 = 0.336297 loss)
I1005 15:33:18.052834  9606 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1005 15:33:23.293794  9606 solver.cpp:218] Iteration 12200 (19.0805 iter/s, 5.24095s/100 iters), loss = 0.297672
I1005 15:33:23.293828  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297672 (* 1 = 0.297672 loss)
I1005 15:33:23.293838  9606 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1005 15:33:28.533401  9606 solver.cpp:218] Iteration 12300 (19.0856 iter/s, 5.23955s/100 iters), loss = 0.22545
I1005 15:33:28.533433  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225451 (* 1 = 0.225451 loss)
I1005 15:33:28.533442  9606 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1005 15:33:33.779181  9606 solver.cpp:218] Iteration 12400 (19.0631 iter/s, 5.24573s/100 iters), loss = 0.279844
I1005 15:33:33.779215  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279844 (* 1 = 0.279844 loss)
I1005 15:33:33.779224  9606 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1005 15:33:38.750042  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:33:38.960041  9606 solver.cpp:330] Iteration 12500, Testing net (#0)
I1005 15:33:40.153329  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:33:40.203011  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7771
I1005 15:33:40.203039  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.67463 (* 1 = 0.67463 loss)
I1005 15:33:40.255311  9606 solver.cpp:218] Iteration 12500 (15.4415 iter/s, 6.47608s/100 iters), loss = 0.317525
I1005 15:33:40.255343  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317525 (* 1 = 0.317525 loss)
I1005 15:33:40.255368  9606 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1005 15:33:45.503038  9606 solver.cpp:218] Iteration 12600 (19.0561 iter/s, 5.24767s/100 iters), loss = 0.347201
I1005 15:33:45.503186  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347201 (* 1 = 0.347201 loss)
I1005 15:33:45.503209  9606 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1005 15:33:50.742676  9606 solver.cpp:218] Iteration 12700 (19.086 iter/s, 5.23945s/100 iters), loss = 0.388892
I1005 15:33:50.742717  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388892 (* 1 = 0.388892 loss)
I1005 15:33:50.742724  9606 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1005 15:33:55.993541  9606 solver.cpp:218] Iteration 12800 (19.0447 iter/s, 5.2508s/100 iters), loss = 0.371979
I1005 15:33:55.993571  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371979 (* 1 = 0.371979 loss)
I1005 15:33:55.993577  9606 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1005 15:34:01.243227  9606 solver.cpp:218] Iteration 12900 (19.049 iter/s, 5.24963s/100 iters), loss = 0.227919
I1005 15:34:01.243257  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22792 (* 1 = 0.22792 loss)
I1005 15:34:01.243264  9606 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1005 15:34:06.216807  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:34:06.430485  9606 solver.cpp:330] Iteration 13000, Testing net (#0)
I1005 15:34:07.619998  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:34:07.669932  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.815
I1005 15:34:07.669967  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.574333 (* 1 = 0.574333 loss)
I1005 15:34:07.722460  9606 solver.cpp:218] Iteration 13000 (15.4341 iter/s, 6.47918s/100 iters), loss = 0.275463
I1005 15:34:07.722494  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275463 (* 1 = 0.275463 loss)
I1005 15:34:07.722503  9606 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1005 15:34:12.964670  9606 solver.cpp:218] Iteration 13100 (19.0761 iter/s, 5.24215s/100 iters), loss = 0.312613
I1005 15:34:12.964702  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312613 (* 1 = 0.312613 loss)
I1005 15:34:12.964709  9606 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1005 15:34:18.201458  9606 solver.cpp:218] Iteration 13200 (19.0959 iter/s, 5.23673s/100 iters), loss = 0.234259
I1005 15:34:18.201609  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23426 (* 1 = 0.23426 loss)
I1005 15:34:18.201618  9606 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1005 15:34:23.448705  9606 solver.cpp:218] Iteration 13300 (19.0582 iter/s, 5.24708s/100 iters), loss = 0.378342
I1005 15:34:23.448747  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378342 (* 1 = 0.378342 loss)
I1005 15:34:23.448753  9606 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1005 15:34:28.696974  9606 solver.cpp:218] Iteration 13400 (19.0541 iter/s, 5.24821s/100 iters), loss = 0.215949
I1005 15:34:28.697015  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21595 (* 1 = 0.21595 loss)
I1005 15:34:28.697021  9606 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1005 15:34:33.685570  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:34:33.894858  9606 solver.cpp:330] Iteration 13500, Testing net (#0)
I1005 15:34:35.081595  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:34:35.131233  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7345
I1005 15:34:35.131268  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833639 (* 1 = 0.833639 loss)
I1005 15:34:35.183220  9606 solver.cpp:218] Iteration 13500 (15.4174 iter/s, 6.48618s/100 iters), loss = 0.263549
I1005 15:34:35.183246  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263549 (* 1 = 0.263549 loss)
I1005 15:34:35.183254  9606 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1005 15:34:40.430142  9606 solver.cpp:218] Iteration 13600 (19.059 iter/s, 5.24687s/100 iters), loss = 0.286457
I1005 15:34:40.430173  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286457 (* 1 = 0.286457 loss)
I1005 15:34:40.430181  9606 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1005 15:34:45.676125  9606 solver.cpp:218] Iteration 13700 (19.0624 iter/s, 5.24593s/100 iters), loss = 0.396376
I1005 15:34:45.676156  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396376 (* 1 = 0.396376 loss)
I1005 15:34:45.676162  9606 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1005 15:34:50.911929  9606 solver.cpp:218] Iteration 13800 (19.0995 iter/s, 5.23575s/100 iters), loss = 0.276695
I1005 15:34:50.912045  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276696 (* 1 = 0.276696 loss)
I1005 15:34:50.912052  9606 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1005 15:34:56.156270  9606 solver.cpp:218] Iteration 13900 (19.0686 iter/s, 5.24421s/100 iters), loss = 0.293117
I1005 15:34:56.156299  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293117 (* 1 = 0.293117 loss)
I1005 15:34:56.156306  9606 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1005 15:35:01.139729  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:35:01.348832  9606 solver.cpp:330] Iteration 14000, Testing net (#0)
I1005 15:35:02.535671  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:35:02.585043  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7828
I1005 15:35:02.585078  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.674695 (* 1 = 0.674695 loss)
I1005 15:35:02.637186  9606 solver.cpp:218] Iteration 14000 (15.43 iter/s, 6.48087s/100 iters), loss = 0.228527
I1005 15:35:02.637212  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228527 (* 1 = 0.228527 loss)
I1005 15:35:02.637218  9606 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1005 15:35:07.884536  9606 solver.cpp:218] Iteration 14100 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.218832
I1005 15:35:07.884565  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218833 (* 1 = 0.218833 loss)
I1005 15:35:07.884572  9606 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1005 15:35:13.127336  9606 solver.cpp:218] Iteration 14200 (19.074 iter/s, 5.24275s/100 iters), loss = 0.346134
I1005 15:35:13.127379  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346134 (* 1 = 0.346134 loss)
I1005 15:35:13.127385  9606 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1005 15:35:18.367141  9606 solver.cpp:218] Iteration 14300 (19.0849 iter/s, 5.23973s/100 iters), loss = 0.252092
I1005 15:35:18.367192  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252092 (* 1 = 0.252092 loss)
I1005 15:35:18.367199  9606 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1005 15:35:23.610117  9606 solver.cpp:218] Iteration 14400 (19.0735 iter/s, 5.24287s/100 iters), loss = 0.235967
I1005 15:35:23.610245  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235967 (* 1 = 0.235967 loss)
I1005 15:35:23.610252  9606 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1005 15:35:28.596578  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:35:28.806028  9606 solver.cpp:330] Iteration 14500, Testing net (#0)
I1005 15:35:29.990566  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:35:30.039862  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7425
I1005 15:35:30.039886  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780614 (* 1 = 0.780614 loss)
I1005 15:35:30.092118  9606 solver.cpp:218] Iteration 14500 (15.4277 iter/s, 6.48185s/100 iters), loss = 0.208389
I1005 15:35:30.092149  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208389 (* 1 = 0.208389 loss)
I1005 15:35:30.092156  9606 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1005 15:35:35.334781  9606 solver.cpp:218] Iteration 14600 (19.0745 iter/s, 5.24261s/100 iters), loss = 0.299134
I1005 15:35:35.334815  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299134 (* 1 = 0.299134 loss)
I1005 15:35:35.334820  9606 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1005 15:35:40.577685  9606 solver.cpp:218] Iteration 14700 (19.0736 iter/s, 5.24285s/100 iters), loss = 0.374138
I1005 15:35:40.577718  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374139 (* 1 = 0.374139 loss)
I1005 15:35:40.577726  9606 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1005 15:35:45.819310  9606 solver.cpp:218] Iteration 14800 (19.0783 iter/s, 5.24157s/100 iters), loss = 0.263268
I1005 15:35:45.819344  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263269 (* 1 = 0.263269 loss)
I1005 15:35:45.819353  9606 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1005 15:35:51.056533  9606 solver.cpp:218] Iteration 14900 (19.0943 iter/s, 5.23717s/100 iters), loss = 0.258228
I1005 15:35:51.056567  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258228 (* 1 = 0.258228 loss)
I1005 15:35:51.056588  9606 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1005 15:35:56.032838  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:35:56.242100  9606 solver.cpp:330] Iteration 15000, Testing net (#0)
I1005 15:35:57.434546  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:35:57.485105  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7523
I1005 15:35:57.485133  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.816959 (* 1 = 0.816959 loss)
I1005 15:35:57.538503  9606 solver.cpp:218] Iteration 15000 (15.4275 iter/s, 6.48191s/100 iters), loss = 0.260248
I1005 15:35:57.538547  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260249 (* 1 = 0.260249 loss)
I1005 15:35:57.538558  9606 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1005 15:36:02.779764  9606 solver.cpp:218] Iteration 15100 (19.0796 iter/s, 5.2412s/100 iters), loss = 0.265409
I1005 15:36:02.779799  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265409 (* 1 = 0.265409 loss)
I1005 15:36:02.779808  9606 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1005 15:36:08.028309  9606 solver.cpp:218] Iteration 15200 (19.0531 iter/s, 5.24848s/100 iters), loss = 0.295559
I1005 15:36:08.028342  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295559 (* 1 = 0.295559 loss)
I1005 15:36:08.028360  9606 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1005 15:36:13.279361  9606 solver.cpp:218] Iteration 15300 (19.044 iter/s, 5.251s/100 iters), loss = 0.273956
I1005 15:36:13.279400  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273956 (* 1 = 0.273956 loss)
I1005 15:36:13.279423  9606 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1005 15:36:18.527015  9606 solver.cpp:218] Iteration 15400 (19.0563 iter/s, 5.24759s/100 iters), loss = 0.222052
I1005 15:36:18.527061  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222052 (* 1 = 0.222052 loss)
I1005 15:36:18.527070  9606 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1005 15:36:23.506939  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:36:23.716509  9606 solver.cpp:330] Iteration 15500, Testing net (#0)
I1005 15:36:24.908605  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:36:24.958268  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.765
I1005 15:36:24.958297  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.721698 (* 1 = 0.721698 loss)
I1005 15:36:25.010493  9606 solver.cpp:218] Iteration 15500 (15.4241 iter/s, 6.48338s/100 iters), loss = 0.2758
I1005 15:36:25.010532  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275801 (* 1 = 0.275801 loss)
I1005 15:36:25.010565  9606 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1005 15:36:30.242391  9606 solver.cpp:218] Iteration 15600 (19.1138 iter/s, 5.23183s/100 iters), loss = 0.310346
I1005 15:36:30.242525  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310346 (* 1 = 0.310346 loss)
I1005 15:36:30.242535  9606 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1005 15:36:35.484896  9606 solver.cpp:218] Iteration 15700 (19.0754 iter/s, 5.24236s/100 iters), loss = 0.382106
I1005 15:36:35.484936  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382106 (* 1 = 0.382106 loss)
I1005 15:36:35.484942  9606 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1005 15:36:40.725991  9606 solver.cpp:218] Iteration 15800 (19.0802 iter/s, 5.24103s/100 iters), loss = 0.342201
I1005 15:36:40.726022  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342201 (* 1 = 0.342201 loss)
I1005 15:36:40.726030  9606 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1005 15:36:45.969418  9606 solver.cpp:218] Iteration 15900 (19.0717 iter/s, 5.24337s/100 iters), loss = 0.307754
I1005 15:36:45.969451  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307755 (* 1 = 0.307755 loss)
I1005 15:36:45.969460  9606 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1005 15:36:50.944699  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:36:51.153693  9606 solver.cpp:330] Iteration 16000, Testing net (#0)
I1005 15:36:52.349149  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:36:52.398808  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.767
I1005 15:36:52.398835  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739071 (* 1 = 0.739071 loss)
I1005 15:36:52.450820  9606 solver.cpp:218] Iteration 16000 (15.4289 iter/s, 6.48135s/100 iters), loss = 0.184278
I1005 15:36:52.450853  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184278 (* 1 = 0.184278 loss)
I1005 15:36:52.450862  9606 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1005 15:36:57.701279  9606 solver.cpp:218] Iteration 16100 (19.0461 iter/s, 5.25041s/100 iters), loss = 0.261629
I1005 15:36:57.701314  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26163 (* 1 = 0.26163 loss)
I1005 15:36:57.701333  9606 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1005 15:37:02.940122  9606 solver.cpp:218] Iteration 16200 (19.0884 iter/s, 5.23879s/100 iters), loss = 0.355089
I1005 15:37:02.940227  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355089 (* 1 = 0.355089 loss)
I1005 15:37:02.940253  9606 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1005 15:37:08.187402  9606 solver.cpp:218] Iteration 16300 (19.0579 iter/s, 5.24716s/100 iters), loss = 0.289433
I1005 15:37:08.187435  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289433 (* 1 = 0.289433 loss)
I1005 15:37:08.187453  9606 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1005 15:37:13.435669  9606 solver.cpp:218] Iteration 16400 (19.0541 iter/s, 5.24821s/100 iters), loss = 0.271324
I1005 15:37:13.435705  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271324 (* 1 = 0.271324 loss)
I1005 15:37:13.435724  9606 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1005 15:37:18.411254  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:37:18.624573  9606 solver.cpp:330] Iteration 16500, Testing net (#0)
I1005 15:37:19.810712  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:37:19.860160  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7831
I1005 15:37:19.860195  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.688044 (* 1 = 0.688044 loss)
I1005 15:37:19.912505  9606 solver.cpp:218] Iteration 16500 (15.4398 iter/s, 6.47678s/100 iters), loss = 0.28291
I1005 15:37:19.912534  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28291 (* 1 = 0.28291 loss)
I1005 15:37:19.912544  9606 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1005 15:37:25.159514  9606 solver.cpp:218] Iteration 16600 (19.0587 iter/s, 5.24696s/100 iters), loss = 0.328258
I1005 15:37:25.159546  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328259 (* 1 = 0.328259 loss)
I1005 15:37:25.159554  9606 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1005 15:37:30.397207  9606 solver.cpp:218] Iteration 16700 (19.0926 iter/s, 5.23764s/100 iters), loss = 0.292709
I1005 15:37:30.397243  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292709 (* 1 = 0.292709 loss)
I1005 15:37:30.397259  9606 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1005 15:37:35.640934  9606 solver.cpp:218] Iteration 16800 (19.0708 iter/s, 5.24363s/100 iters), loss = 0.211907
I1005 15:37:35.641067  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211907 (* 1 = 0.211907 loss)
I1005 15:37:35.641084  9606 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1005 15:37:40.894724  9606 solver.cpp:218] Iteration 16900 (19.0344 iter/s, 5.25365s/100 iters), loss = 0.297273
I1005 15:37:40.894754  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297273 (* 1 = 0.297273 loss)
I1005 15:37:40.894760  9606 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1005 15:37:45.879897  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:37:46.089124  9606 solver.cpp:330] Iteration 17000, Testing net (#0)
I1005 15:37:47.273432  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:37:47.322772  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7697
I1005 15:37:47.322806  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706051 (* 1 = 0.706051 loss)
I1005 15:37:47.375341  9606 solver.cpp:218] Iteration 17000 (15.4307 iter/s, 6.48057s/100 iters), loss = 0.173519
I1005 15:37:47.375373  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17352 (* 1 = 0.17352 loss)
I1005 15:37:47.375380  9606 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1005 15:37:52.626464  9606 solver.cpp:218] Iteration 17100 (19.0437 iter/s, 5.25107s/100 iters), loss = 0.328141
I1005 15:37:52.626504  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328142 (* 1 = 0.328142 loss)
I1005 15:37:52.626510  9606 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1005 15:37:57.873984  9606 solver.cpp:218] Iteration 17200 (19.0569 iter/s, 5.24745s/100 iters), loss = 0.330889
I1005 15:37:57.874014  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330889 (* 1 = 0.330889 loss)
I1005 15:37:57.874020  9606 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1005 15:38:03.110337  9606 solver.cpp:218] Iteration 17300 (19.0974 iter/s, 5.2363s/100 iters), loss = 0.2406
I1005 15:38:03.110378  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240601 (* 1 = 0.240601 loss)
I1005 15:38:03.110384  9606 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1005 15:38:08.355792  9606 solver.cpp:218] Iteration 17400 (19.0644 iter/s, 5.24539s/100 iters), loss = 0.238457
I1005 15:38:08.355958  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238458 (* 1 = 0.238458 loss)
I1005 15:38:08.355967  9606 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1005 15:38:13.338721  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:38:13.548480  9606 solver.cpp:330] Iteration 17500, Testing net (#0)
I1005 15:38:14.734189  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:38:14.783612  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8163
I1005 15:38:14.783638  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.57999 (* 1 = 0.57999 loss)
I1005 15:38:14.835472  9606 solver.cpp:218] Iteration 17500 (15.4333 iter/s, 6.4795s/100 iters), loss = 0.272463
I1005 15:38:14.835505  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272463 (* 1 = 0.272463 loss)
I1005 15:38:14.835511  9606 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1005 15:38:20.077738  9606 solver.cpp:218] Iteration 17600 (19.0759 iter/s, 5.24221s/100 iters), loss = 0.305833
I1005 15:38:20.077767  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305833 (* 1 = 0.305833 loss)
I1005 15:38:20.077774  9606 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1005 15:38:25.322752  9606 solver.cpp:218] Iteration 17700 (19.0659 iter/s, 5.24496s/100 iters), loss = 0.299963
I1005 15:38:25.322784  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299963 (* 1 = 0.299963 loss)
I1005 15:38:25.322793  9606 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1005 15:38:30.568591  9606 solver.cpp:218] Iteration 17800 (19.0629 iter/s, 5.24579s/100 iters), loss = 0.321554
I1005 15:38:30.568629  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321554 (* 1 = 0.321554 loss)
I1005 15:38:30.568639  9606 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1005 15:38:35.805953  9606 solver.cpp:218] Iteration 17900 (19.0938 iter/s, 5.23731s/100 iters), loss = 0.184734
I1005 15:38:35.805986  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184734 (* 1 = 0.184734 loss)
I1005 15:38:35.805994  9606 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1005 15:38:40.787576  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:38:40.997337  9606 solver.cpp:330] Iteration 18000, Testing net (#0)
I1005 15:38:42.183594  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:38:42.233484  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7747
I1005 15:38:42.233510  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.712769 (* 1 = 0.712769 loss)
I1005 15:38:42.285992  9606 solver.cpp:218] Iteration 18000 (15.4321 iter/s, 6.47999s/100 iters), loss = 0.252241
I1005 15:38:42.286021  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252242 (* 1 = 0.252242 loss)
I1005 15:38:42.286031  9606 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1005 15:38:47.531116  9606 solver.cpp:218] Iteration 18100 (19.0655 iter/s, 5.24508s/100 iters), loss = 0.22961
I1005 15:38:47.531146  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22961 (* 1 = 0.22961 loss)
I1005 15:38:47.531152  9606 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1005 15:38:52.777112  9606 solver.cpp:218] Iteration 18200 (19.0623 iter/s, 5.24594s/100 iters), loss = 0.236942
I1005 15:38:52.777143  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236942 (* 1 = 0.236942 loss)
I1005 15:38:52.777149  9606 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1005 15:38:58.018235  9606 solver.cpp:218] Iteration 18300 (19.0801 iter/s, 5.24107s/100 iters), loss = 0.265677
I1005 15:38:58.018276  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265677 (* 1 = 0.265677 loss)
I1005 15:38:58.018283  9606 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1005 15:39:03.253167  9606 solver.cpp:218] Iteration 18400 (19.1027 iter/s, 5.23487s/100 iters), loss = 0.223942
I1005 15:39:03.253208  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223942 (* 1 = 0.223942 loss)
I1005 15:39:03.253214  9606 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1005 15:39:08.235513  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:39:08.444998  9606 solver.cpp:330] Iteration 18500, Testing net (#0)
I1005 15:39:09.639384  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:39:09.688338  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7687
I1005 15:39:09.688362  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.851556 (* 1 = 0.851556 loss)
I1005 15:39:09.740360  9606 solver.cpp:218] Iteration 18500 (15.4151 iter/s, 6.48713s/100 iters), loss = 0.290688
I1005 15:39:09.740392  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290688 (* 1 = 0.290688 loss)
I1005 15:39:09.740399  9606 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1005 15:39:14.985388  9606 solver.cpp:218] Iteration 18600 (19.0659 iter/s, 5.24498s/100 iters), loss = 0.314924
I1005 15:39:14.985553  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314924 (* 1 = 0.314924 loss)
I1005 15:39:14.985563  9606 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1005 15:39:20.237309  9606 solver.cpp:218] Iteration 18700 (19.0413 iter/s, 5.25174s/100 iters), loss = 0.323381
I1005 15:39:20.237340  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323381 (* 1 = 0.323381 loss)
I1005 15:39:20.237356  9606 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1005 15:39:25.487385  9606 solver.cpp:218] Iteration 18800 (19.0475 iter/s, 5.25003s/100 iters), loss = 0.332563
I1005 15:39:25.487416  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332563 (* 1 = 0.332563 loss)
I1005 15:39:25.487421  9606 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1005 15:39:30.736402  9606 solver.cpp:218] Iteration 18900 (19.0514 iter/s, 5.24897s/100 iters), loss = 0.180239
I1005 15:39:30.736433  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180239 (* 1 = 0.180239 loss)
I1005 15:39:30.736440  9606 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1005 15:39:35.718273  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:39:35.928086  9606 solver.cpp:330] Iteration 19000, Testing net (#0)
I1005 15:39:37.122004  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:39:37.172051  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6705
I1005 15:39:37.172083  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08089 (* 1 = 1.08089 loss)
I1005 15:39:37.224251  9606 solver.cpp:218] Iteration 19000 (15.4135 iter/s, 6.4878s/100 iters), loss = 0.246713
I1005 15:39:37.224280  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246713 (* 1 = 0.246713 loss)
I1005 15:39:37.224287  9606 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1005 15:39:42.465000  9606 solver.cpp:218] Iteration 19100 (19.0814 iter/s, 5.2407s/100 iters), loss = 0.273991
I1005 15:39:42.465036  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273991 (* 1 = 0.273991 loss)
I1005 15:39:42.465044  9606 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1005 15:39:47.710559  9606 solver.cpp:218] Iteration 19200 (19.064 iter/s, 5.2455s/100 iters), loss = 0.160379
I1005 15:39:47.710702  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16038 (* 1 = 0.16038 loss)
I1005 15:39:47.710723  9606 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1005 15:39:52.951706  9606 solver.cpp:218] Iteration 19300 (19.0803 iter/s, 5.24102s/100 iters), loss = 0.241527
I1005 15:39:52.951738  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241527 (* 1 = 0.241527 loss)
I1005 15:39:52.951756  9606 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1005 15:39:58.198643  9606 solver.cpp:218] Iteration 19400 (19.0589 iter/s, 5.24689s/100 iters), loss = 0.215281
I1005 15:39:58.198675  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215281 (* 1 = 0.215281 loss)
I1005 15:39:58.198694  9606 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1005 15:40:03.173939  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:40:03.385191  9606 solver.cpp:330] Iteration 19500, Testing net (#0)
I1005 15:40:04.582072  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:40:04.632040  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7314
I1005 15:40:04.632066  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.894437 (* 1 = 0.894437 loss)
I1005 15:40:04.684289  9606 solver.cpp:218] Iteration 19500 (15.4188 iter/s, 6.4856s/100 iters), loss = 0.187764
I1005 15:40:04.684320  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187765 (* 1 = 0.187765 loss)
I1005 15:40:04.684327  9606 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1005 15:40:09.935345  9606 solver.cpp:218] Iteration 19600 (19.044 iter/s, 5.251s/100 iters), loss = 0.205503
I1005 15:40:09.935381  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205504 (* 1 = 0.205504 loss)
I1005 15:40:09.935389  9606 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1005 15:40:15.180399  9606 solver.cpp:218] Iteration 19700 (19.0658 iter/s, 5.245s/100 iters), loss = 0.302146
I1005 15:40:15.180430  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302146 (* 1 = 0.302146 loss)
I1005 15:40:15.180438  9606 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1005 15:40:20.431061  9606 solver.cpp:218] Iteration 19800 (19.0454 iter/s, 5.25061s/100 iters), loss = 0.34108
I1005 15:40:20.431183  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341081 (* 1 = 0.341081 loss)
I1005 15:40:20.431191  9606 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1005 15:40:25.681713  9606 solver.cpp:218] Iteration 19900 (19.0458 iter/s, 5.25051s/100 iters), loss = 0.286447
I1005 15:40:25.681743  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286447 (* 1 = 0.286447 loss)
I1005 15:40:25.681749  9606 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1005 15:40:30.666689  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:40:30.876987  9606 solver.cpp:330] Iteration 20000, Testing net (#0)
I1005 15:40:32.061796  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:40:32.111667  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7792
I1005 15:40:32.111692  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.67508 (* 1 = 0.67508 loss)
I1005 15:40:32.163889  9606 solver.cpp:218] Iteration 20000 (15.427 iter/s, 6.48213s/100 iters), loss = 0.233769
I1005 15:40:32.163915  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233769 (* 1 = 0.233769 loss)
I1005 15:40:32.163923  9606 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1005 15:40:37.411124  9606 solver.cpp:218] Iteration 20100 (19.0578 iter/s, 5.24719s/100 iters), loss = 0.257205
I1005 15:40:37.411154  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257205 (* 1 = 0.257205 loss)
I1005 15:40:37.411160  9606 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1005 15:40:42.658021  9606 solver.cpp:218] Iteration 20200 (19.0591 iter/s, 5.24685s/100 iters), loss = 0.232939
I1005 15:40:42.658054  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232939 (* 1 = 0.232939 loss)
I1005 15:40:42.658061  9606 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1005 15:40:47.895256  9606 solver.cpp:218] Iteration 20300 (19.0942 iter/s, 5.23718s/100 iters), loss = 0.233778
I1005 15:40:47.895288  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233779 (* 1 = 0.233779 loss)
I1005 15:40:47.895295  9606 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1005 15:40:53.150643  9606 solver.cpp:218] Iteration 20400 (19.0283 iter/s, 5.25534s/100 iters), loss = 0.258099
I1005 15:40:53.150773  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258099 (* 1 = 0.258099 loss)
I1005 15:40:53.150790  9606 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1005 15:40:58.140632  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:40:58.349807  9606 solver.cpp:330] Iteration 20500, Testing net (#0)
I1005 15:40:59.535645  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:40:59.585501  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7575
I1005 15:40:59.585528  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.789329 (* 1 = 0.789329 loss)
I1005 15:40:59.637389  9606 solver.cpp:218] Iteration 20500 (15.4164 iter/s, 6.48661s/100 iters), loss = 0.170637
I1005 15:40:59.637414  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170637 (* 1 = 0.170637 loss)
I1005 15:40:59.637421  9606 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1005 15:41:04.889091  9606 solver.cpp:218] Iteration 20600 (19.0416 iter/s, 5.25165s/100 iters), loss = 0.278003
I1005 15:41:04.889130  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278003 (* 1 = 0.278003 loss)
I1005 15:41:04.889137  9606 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1005 15:41:10.145107  9606 solver.cpp:218] Iteration 20700 (19.026 iter/s, 5.25596s/100 iters), loss = 0.324788
I1005 15:41:10.145146  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324788 (* 1 = 0.324788 loss)
I1005 15:41:10.145153  9606 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1005 15:41:15.389075  9606 solver.cpp:218] Iteration 20800 (19.0698 iter/s, 5.2439s/100 iters), loss = 0.261567
I1005 15:41:15.389111  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261568 (* 1 = 0.261568 loss)
I1005 15:41:15.389119  9606 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1005 15:41:20.635635  9606 solver.cpp:218] Iteration 20900 (19.0603 iter/s, 5.24651s/100 iters), loss = 0.226931
I1005 15:41:20.635665  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226931 (* 1 = 0.226931 loss)
I1005 15:41:20.635671  9606 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1005 15:41:25.619441  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:41:25.828925  9606 solver.cpp:330] Iteration 21000, Testing net (#0)
I1005 15:41:27.015000  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:41:27.064790  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7594
I1005 15:41:27.064815  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.736938 (* 1 = 0.736938 loss)
I1005 15:41:27.117033  9606 solver.cpp:218] Iteration 21000 (15.4289 iter/s, 6.48134s/100 iters), loss = 0.254257
I1005 15:41:27.117064  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254258 (* 1 = 0.254258 loss)
I1005 15:41:27.117071  9606 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1005 15:41:32.366875  9606 solver.cpp:218] Iteration 21100 (19.0484 iter/s, 5.24979s/100 iters), loss = 0.200352
I1005 15:41:32.366915  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200352 (* 1 = 0.200352 loss)
I1005 15:41:32.366921  9606 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1005 15:41:37.620653  9606 solver.cpp:218] Iteration 21200 (19.0341 iter/s, 5.25372s/100 iters), loss = 0.226737
I1005 15:41:37.620693  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226737 (* 1 = 0.226737 loss)
I1005 15:41:37.620699  9606 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1005 15:41:42.872903  9606 solver.cpp:218] Iteration 21300 (19.0397 iter/s, 5.25219s/100 iters), loss = 0.269836
I1005 15:41:42.872946  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269837 (* 1 = 0.269837 loss)
I1005 15:41:42.872954  9606 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1005 15:41:48.114780  9606 solver.cpp:218] Iteration 21400 (19.0774 iter/s, 5.24182s/100 iters), loss = 0.239324
I1005 15:41:48.114811  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239324 (* 1 = 0.239324 loss)
I1005 15:41:48.114819  9606 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1005 15:41:53.106369  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:41:53.315721  9606 solver.cpp:330] Iteration 21500, Testing net (#0)
I1005 15:41:54.506924  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:41:54.557056  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7634
I1005 15:41:54.557083  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733886 (* 1 = 0.733886 loss)
I1005 15:41:54.610462  9606 solver.cpp:218] Iteration 21500 (15.395 iter/s, 6.49563s/100 iters), loss = 0.240941
I1005 15:41:54.610502  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240941 (* 1 = 0.240941 loss)
I1005 15:41:54.610509  9606 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1005 15:41:59.857342  9606 solver.cpp:218] Iteration 21600 (19.0592 iter/s, 5.24682s/100 iters), loss = 0.320504
I1005 15:41:59.857445  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320505 (* 1 = 0.320505 loss)
I1005 15:41:59.857455  9606 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1005 15:42:05.112733  9606 solver.cpp:218] Iteration 21700 (19.0285 iter/s, 5.25527s/100 iters), loss = 0.293484
I1005 15:42:05.112773  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293485 (* 1 = 0.293485 loss)
I1005 15:42:05.112779  9606 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1005 15:42:10.361348  9606 solver.cpp:218] Iteration 21800 (19.0529 iter/s, 5.24856s/100 iters), loss = 0.249844
I1005 15:42:10.361387  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249845 (* 1 = 0.249845 loss)
I1005 15:42:10.361393  9606 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1005 15:42:15.608837  9606 solver.cpp:218] Iteration 21900 (19.057 iter/s, 5.24743s/100 iters), loss = 0.259415
I1005 15:42:15.608883  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259415 (* 1 = 0.259415 loss)
I1005 15:42:15.608891  9606 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1005 15:42:20.590420  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:42:20.800602  9606 solver.cpp:330] Iteration 22000, Testing net (#0)
I1005 15:42:21.994174  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:42:22.043659  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7001
I1005 15:42:22.043694  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09424 (* 1 = 1.09424 loss)
I1005 15:42:22.095937  9606 solver.cpp:218] Iteration 22000 (15.4154 iter/s, 6.48704s/100 iters), loss = 0.191412
I1005 15:42:22.095964  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191412 (* 1 = 0.191412 loss)
I1005 15:42:22.095971  9606 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1005 15:42:27.335342  9606 solver.cpp:218] Iteration 22100 (19.0863 iter/s, 5.23936s/100 iters), loss = 0.326455
I1005 15:42:27.335382  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326455 (* 1 = 0.326455 loss)
I1005 15:42:27.335389  9606 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1005 15:42:32.586493  9606 solver.cpp:218] Iteration 22200 (19.0437 iter/s, 5.25109s/100 iters), loss = 0.372863
I1005 15:42:32.586616  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372863 (* 1 = 0.372863 loss)
I1005 15:42:32.586632  9606 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1005 15:42:37.844751  9606 solver.cpp:218] Iteration 22300 (19.0182 iter/s, 5.25813s/100 iters), loss = 0.260429
I1005 15:42:37.844780  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26043 (* 1 = 0.26043 loss)
I1005 15:42:37.844786  9606 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1005 15:42:43.102214  9606 solver.cpp:218] Iteration 22400 (19.0208 iter/s, 5.25741s/100 iters), loss = 0.20799
I1005 15:42:43.102246  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20799 (* 1 = 0.20799 loss)
I1005 15:42:43.102252  9606 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1005 15:42:48.080685  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:42:48.290005  9606 solver.cpp:330] Iteration 22500, Testing net (#0)
I1005 15:42:49.482355  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:42:49.532045  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7298
I1005 15:42:49.532073  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.99846 (* 1 = 0.99846 loss)
I1005 15:42:49.584169  9606 solver.cpp:218] Iteration 22500 (15.4276 iter/s, 6.48191s/100 iters), loss = 0.197343
I1005 15:42:49.584201  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197343 (* 1 = 0.197343 loss)
I1005 15:42:49.584213  9606 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1005 15:42:54.830914  9606 solver.cpp:218] Iteration 22600 (19.0596 iter/s, 5.2467s/100 iters), loss = 0.224553
I1005 15:42:54.830945  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224553 (* 1 = 0.224553 loss)
I1005 15:42:54.830952  9606 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1005 15:43:00.066678  9606 solver.cpp:218] Iteration 22700 (19.0996 iter/s, 5.23571s/100 iters), loss = 0.419761
I1005 15:43:00.066709  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419761 (* 1 = 0.419761 loss)
I1005 15:43:00.066716  9606 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1005 15:43:05.314766  9606 solver.cpp:218] Iteration 22800 (19.0547 iter/s, 5.24804s/100 iters), loss = 0.230543
I1005 15:43:05.314899  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230543 (* 1 = 0.230543 loss)
I1005 15:43:05.314906  9606 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1005 15:43:10.563836  9606 solver.cpp:218] Iteration 22900 (19.0515 iter/s, 5.24893s/100 iters), loss = 0.240761
I1005 15:43:10.563866  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240761 (* 1 = 0.240761 loss)
I1005 15:43:10.563872  9606 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1005 15:43:15.552597  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:43:15.764672  9606 solver.cpp:330] Iteration 23000, Testing net (#0)
I1005 15:43:16.949545  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:43:16.999032  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6976
I1005 15:43:16.999066  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.16794 (* 1 = 1.16794 loss)
I1005 15:43:17.051353  9606 solver.cpp:218] Iteration 23000 (15.4143 iter/s, 6.48747s/100 iters), loss = 0.283269
I1005 15:43:17.051381  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28327 (* 1 = 0.28327 loss)
I1005 15:43:17.051388  9606 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1005 15:43:22.303555  9606 solver.cpp:218] Iteration 23100 (19.0398 iter/s, 5.25216s/100 iters), loss = 0.2009
I1005 15:43:22.303596  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2009 (* 1 = 0.2009 loss)
I1005 15:43:22.303603  9606 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1005 15:43:27.555980  9606 solver.cpp:218] Iteration 23200 (19.0391 iter/s, 5.25236s/100 iters), loss = 0.251511
I1005 15:43:27.556017  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251511 (* 1 = 0.251511 loss)
I1005 15:43:27.556025  9606 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1005 15:43:32.804458  9606 solver.cpp:218] Iteration 23300 (19.0533 iter/s, 5.24842s/100 iters), loss = 0.252795
I1005 15:43:32.804488  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252796 (* 1 = 0.252796 loss)
I1005 15:43:32.804494  9606 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1005 15:43:38.061755  9606 solver.cpp:218] Iteration 23400 (19.0214 iter/s, 5.25725s/100 iters), loss = 0.219988
I1005 15:43:38.061895  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219989 (* 1 = 0.219989 loss)
I1005 15:43:38.061903  9606 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1005 15:43:43.051307  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:43:43.261293  9606 solver.cpp:330] Iteration 23500, Testing net (#0)
I1005 15:43:44.445384  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:43:44.494990  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.751
I1005 15:43:44.495014  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.751149 (* 1 = 0.751149 loss)
I1005 15:43:44.547325  9606 solver.cpp:218] Iteration 23500 (15.4192 iter/s, 6.48541s/100 iters), loss = 0.236994
I1005 15:43:44.547353  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236994 (* 1 = 0.236994 loss)
I1005 15:43:44.547359  9606 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1005 15:43:49.799052  9606 solver.cpp:218] Iteration 23600 (19.0415 iter/s, 5.25168s/100 iters), loss = 0.29627
I1005 15:43:49.799093  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29627 (* 1 = 0.29627 loss)
I1005 15:43:49.799099  9606 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1005 15:43:55.050832  9606 solver.cpp:218] Iteration 23700 (19.0414 iter/s, 5.25172s/100 iters), loss = 0.302417
I1005 15:43:55.050861  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302417 (* 1 = 0.302417 loss)
I1005 15:43:55.050868  9606 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1005 15:44:00.296347  9606 solver.cpp:218] Iteration 23800 (19.0641 iter/s, 5.24547s/100 iters), loss = 0.174207
I1005 15:44:00.296377  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174208 (* 1 = 0.174208 loss)
I1005 15:44:00.296383  9606 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1005 15:44:05.551389  9606 solver.cpp:218] Iteration 23900 (19.0295 iter/s, 5.25499s/100 iters), loss = 0.286531
I1005 15:44:05.551420  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286532 (* 1 = 0.286532 loss)
I1005 15:44:05.551426  9606 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1005 15:44:10.544242  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:44:10.754201  9606 solver.cpp:330] Iteration 24000, Testing net (#0)
I1005 15:44:11.940769  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:44:11.989920  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7164
I1005 15:44:11.989945  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.96977 (* 1 = 0.96977 loss)
I1005 15:44:12.042248  9606 solver.cpp:218] Iteration 24000 (15.4064 iter/s, 6.49081s/100 iters), loss = 0.26703
I1005 15:44:12.042292  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267031 (* 1 = 0.267031 loss)
I1005 15:44:12.042299  9606 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1005 15:44:17.298130  9606 solver.cpp:218] Iteration 24100 (19.0266 iter/s, 5.25581s/100 iters), loss = 0.195831
I1005 15:44:17.298169  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195831 (* 1 = 0.195831 loss)
I1005 15:44:17.298176  9606 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1005 15:44:22.553133  9606 solver.cpp:218] Iteration 24200 (19.0297 iter/s, 5.25494s/100 iters), loss = 0.3266
I1005 15:44:22.553174  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326601 (* 1 = 0.326601 loss)
I1005 15:44:22.553179  9606 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1005 15:44:27.805649  9606 solver.cpp:218] Iteration 24300 (19.0387 iter/s, 5.25246s/100 iters), loss = 0.280192
I1005 15:44:27.805691  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280192 (* 1 = 0.280192 loss)
I1005 15:44:27.805698  9606 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1005 15:44:33.049351  9606 solver.cpp:218] Iteration 24400 (19.0707 iter/s, 5.24364s/100 iters), loss = 0.153622
I1005 15:44:33.049384  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153622 (* 1 = 0.153622 loss)
I1005 15:44:33.049391  9606 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1005 15:44:38.033974  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:44:38.242728  9606 solver.cpp:330] Iteration 24500, Testing net (#0)
I1005 15:44:39.429046  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:44:39.480172  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8015
I1005 15:44:39.480211  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.585669 (* 1 = 0.585669 loss)
I1005 15:44:39.533270  9606 solver.cpp:218] Iteration 24500 (15.4229 iter/s, 6.48387s/100 iters), loss = 0.211182
I1005 15:44:39.533319  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211183 (* 1 = 0.211183 loss)
I1005 15:44:39.533327  9606 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1005 15:44:44.778503  9606 solver.cpp:218] Iteration 24600 (19.0653 iter/s, 5.24514s/100 iters), loss = 0.182619
I1005 15:44:44.778652  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182619 (* 1 = 0.182619 loss)
I1005 15:44:44.778661  9606 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1005 15:44:50.032241  9606 solver.cpp:218] Iteration 24700 (19.0347 iter/s, 5.25357s/100 iters), loss = 0.23139
I1005 15:44:50.032271  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231391 (* 1 = 0.231391 loss)
I1005 15:44:50.032277  9606 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1005 15:44:55.284946  9606 solver.cpp:218] Iteration 24800 (19.038 iter/s, 5.25265s/100 iters), loss = 0.18285
I1005 15:44:55.284979  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18285 (* 1 = 0.18285 loss)
I1005 15:44:55.284998  9606 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1005 15:45:00.537137  9606 solver.cpp:218] Iteration 24900 (19.0399 iter/s, 5.25213s/100 iters), loss = 0.17282
I1005 15:45:00.537178  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172821 (* 1 = 0.172821 loss)
I1005 15:45:00.537197  9606 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1005 15:45:05.520711  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:45:05.730566  9606 solver.cpp:330] Iteration 25000, Testing net (#0)
I1005 15:45:06.924870  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:45:06.974491  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8258
I1005 15:45:06.974519  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.507851 (* 1 = 0.507851 loss)
I1005 15:45:07.026726  9606 solver.cpp:218] Iteration 25000 (15.4095 iter/s, 6.4895s/100 iters), loss = 0.198612
I1005 15:45:07.026754  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198612 (* 1 = 0.198612 loss)
I1005 15:45:07.026764  9606 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1005 15:45:12.271947  9606 solver.cpp:218] Iteration 25100 (19.0651 iter/s, 5.24517s/100 iters), loss = 0.256144
I1005 15:45:12.271980  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256145 (* 1 = 0.256145 loss)
I1005 15:45:12.271997  9606 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1005 15:45:17.524330  9606 solver.cpp:218] Iteration 25200 (19.0392 iter/s, 5.25233s/100 iters), loss = 0.289647
I1005 15:45:17.524462  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289648 (* 1 = 0.289648 loss)
I1005 15:45:17.524482  9606 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1005 15:45:22.776468  9606 solver.cpp:218] Iteration 25300 (19.0404 iter/s, 5.25199s/100 iters), loss = 0.233797
I1005 15:45:22.776504  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233797 (* 1 = 0.233797 loss)
I1005 15:45:22.776513  9606 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1005 15:45:28.026106  9606 solver.cpp:218] Iteration 25400 (19.0491 iter/s, 5.24959s/100 iters), loss = 0.291545
I1005 15:45:28.026139  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291545 (* 1 = 0.291545 loss)
I1005 15:45:28.026159  9606 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1005 15:45:33.006417  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:45:33.216231  9606 solver.cpp:330] Iteration 25500, Testing net (#0)
I1005 15:45:34.411217  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:45:34.460894  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7952
I1005 15:45:34.460922  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.613756 (* 1 = 0.613756 loss)
I1005 15:45:34.513061  9606 solver.cpp:218] Iteration 25500 (15.4157 iter/s, 6.4869s/100 iters), loss = 0.243049
I1005 15:45:34.513089  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24305 (* 1 = 0.24305 loss)
I1005 15:45:34.513099  9606 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1005 15:45:39.764434  9606 solver.cpp:218] Iteration 25600 (19.0428 iter/s, 5.25132s/100 iters), loss = 0.22374
I1005 15:45:39.764468  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22374 (* 1 = 0.22374 loss)
I1005 15:45:39.764477  9606 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1005 15:45:45.010906  9606 solver.cpp:218] Iteration 25700 (19.0606 iter/s, 5.24642s/100 iters), loss = 0.18567
I1005 15:45:45.010939  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18567 (* 1 = 0.18567 loss)
I1005 15:45:45.010948  9606 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1005 15:45:50.270115  9606 solver.cpp:218] Iteration 25800 (19.0144 iter/s, 5.25916s/100 iters), loss = 0.259122
I1005 15:45:50.270288  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259122 (* 1 = 0.259122 loss)
I1005 15:45:50.270299  9606 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1005 15:45:55.526262  9606 solver.cpp:218] Iteration 25900 (19.026 iter/s, 5.25596s/100 iters), loss = 0.235183
I1005 15:45:55.526294  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235183 (* 1 = 0.235183 loss)
I1005 15:45:55.526302  9606 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1005 15:46:00.513973  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:46:00.726291  9606 solver.cpp:330] Iteration 26000, Testing net (#0)
I1005 15:46:01.912359  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:46:01.962019  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8104
I1005 15:46:01.962046  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.579908 (* 1 = 0.579908 loss)
I1005 15:46:02.014530  9606 solver.cpp:218] Iteration 26000 (15.4126 iter/s, 6.48822s/100 iters), loss = 0.196438
I1005 15:46:02.014561  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196438 (* 1 = 0.196438 loss)
I1005 15:46:02.014570  9606 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1005 15:46:07.267738  9606 solver.cpp:218] Iteration 26100 (19.0362 iter/s, 5.25316s/100 iters), loss = 0.209582
I1005 15:46:07.267772  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209583 (* 1 = 0.209583 loss)
I1005 15:46:07.267781  9606 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1005 15:46:12.514874  9606 solver.cpp:218] Iteration 26200 (19.0582 iter/s, 5.24708s/100 iters), loss = 0.234426
I1005 15:46:12.514914  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234427 (* 1 = 0.234427 loss)
I1005 15:46:12.514925  9606 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1005 15:46:17.765656  9606 solver.cpp:218] Iteration 26300 (19.045 iter/s, 5.25073s/100 iters), loss = 0.235199
I1005 15:46:17.765691  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235199 (* 1 = 0.235199 loss)
I1005 15:46:17.765698  9606 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1005 15:46:23.020479  9606 solver.cpp:218] Iteration 26400 (19.0303 iter/s, 5.25477s/100 iters), loss = 0.196246
I1005 15:46:23.020601  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196247 (* 1 = 0.196247 loss)
I1005 15:46:23.020622  9606 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1005 15:46:28.015393  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:46:28.225280  9606 solver.cpp:330] Iteration 26500, Testing net (#0)
I1005 15:46:29.411603  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:46:29.461153  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7681
I1005 15:46:29.461179  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.78832 (* 1 = 0.78832 loss)
I1005 15:46:29.513478  9606 solver.cpp:218] Iteration 26500 (15.4015 iter/s, 6.49287s/100 iters), loss = 0.26199
I1005 15:46:29.513506  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261991 (* 1 = 0.261991 loss)
I1005 15:46:29.513530  9606 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1005 15:46:34.770495  9606 solver.cpp:218] Iteration 26600 (19.0224 iter/s, 5.25697s/100 iters), loss = 0.248854
I1005 15:46:34.770532  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248855 (* 1 = 0.248855 loss)
I1005 15:46:34.770541  9606 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1005 15:46:40.028414  9606 solver.cpp:218] Iteration 26700 (19.0191 iter/s, 5.25787s/100 iters), loss = 0.28816
I1005 15:46:40.028447  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288161 (* 1 = 0.288161 loss)
I1005 15:46:40.028455  9606 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1005 15:46:45.275368  9606 solver.cpp:218] Iteration 26800 (19.0589 iter/s, 5.2469s/100 iters), loss = 0.268899
I1005 15:46:45.275403  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2689 (* 1 = 0.2689 loss)
I1005 15:46:45.275421  9606 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1005 15:46:50.534059  9606 solver.cpp:218] Iteration 26900 (19.0163 iter/s, 5.25864s/100 iters), loss = 0.218298
I1005 15:46:50.534090  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218299 (* 1 = 0.218299 loss)
I1005 15:46:50.534099  9606 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1005 15:46:55.524626  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:46:55.734833  9606 solver.cpp:330] Iteration 27000, Testing net (#0)
I1005 15:46:56.921437  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:46:56.970631  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7786
I1005 15:46:56.970659  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.721296 (* 1 = 0.721296 loss)
I1005 15:46:57.022874  9606 solver.cpp:218] Iteration 27000 (15.4112 iter/s, 6.48877s/100 iters), loss = 0.194685
I1005 15:46:57.022912  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194686 (* 1 = 0.194686 loss)
I1005 15:46:57.022922  9606 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1005 15:47:02.272871  9606 solver.cpp:218] Iteration 27100 (19.0478 iter/s, 5.24995s/100 iters), loss = 0.323202
I1005 15:47:02.272903  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323203 (* 1 = 0.323203 loss)
I1005 15:47:02.272912  9606 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1005 15:47:07.524899  9606 solver.cpp:218] Iteration 27200 (19.0405 iter/s, 5.25197s/100 iters), loss = 0.268072
I1005 15:47:07.524932  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268072 (* 1 = 0.268072 loss)
I1005 15:47:07.524940  9606 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1005 15:47:12.779058  9606 solver.cpp:218] Iteration 27300 (19.0327 iter/s, 5.25411s/100 iters), loss = 0.185933
I1005 15:47:12.779093  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185933 (* 1 = 0.185933 loss)
I1005 15:47:12.779101  9606 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1005 15:47:18.023869  9606 solver.cpp:218] Iteration 27400 (19.0667 iter/s, 5.24475s/100 iters), loss = 0.304549
I1005 15:47:18.023905  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30455 (* 1 = 0.30455 loss)
I1005 15:47:18.023914  9606 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1005 15:47:23.009534  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:47:23.219696  9606 solver.cpp:330] Iteration 27500, Testing net (#0)
I1005 15:47:24.407307  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:47:24.457978  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7565
I1005 15:47:24.458015  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.750731 (* 1 = 0.750731 loss)
I1005 15:47:24.511948  9606 solver.cpp:218] Iteration 27500 (15.413 iter/s, 6.48803s/100 iters), loss = 0.254305
I1005 15:47:24.511988  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254306 (* 1 = 0.254306 loss)
I1005 15:47:24.512007  9606 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1005 15:47:29.760478  9606 solver.cpp:218] Iteration 27600 (19.054 iter/s, 5.24823s/100 iters), loss = 0.332324
I1005 15:47:29.760606  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332325 (* 1 = 0.332325 loss)
I1005 15:47:29.760613  9606 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1005 15:47:35.012064  9606 solver.cpp:218] Iteration 27700 (19.0424 iter/s, 5.25144s/100 iters), loss = 0.375264
I1005 15:47:35.012107  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375265 (* 1 = 0.375265 loss)
I1005 15:47:35.012115  9606 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1005 15:47:40.266252  9606 solver.cpp:218] Iteration 27800 (19.0326 iter/s, 5.25413s/100 iters), loss = 0.221254
I1005 15:47:40.266294  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221255 (* 1 = 0.221255 loss)
I1005 15:47:40.266300  9606 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1005 15:47:45.509985  9606 solver.cpp:218] Iteration 27900 (19.0706 iter/s, 5.24367s/100 iters), loss = 0.148855
I1005 15:47:45.510031  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148855 (* 1 = 0.148855 loss)
I1005 15:47:45.510040  9606 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1005 15:47:50.493563  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:47:50.702893  9606 solver.cpp:330] Iteration 28000, Testing net (#0)
I1005 15:47:51.892536  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:47:51.942104  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7898
I1005 15:47:51.942127  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.628993 (* 1 = 0.628993 loss)
I1005 15:47:51.994524  9606 solver.cpp:218] Iteration 28000 (15.4215 iter/s, 6.48444s/100 iters), loss = 0.195321
I1005 15:47:51.994568  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195321 (* 1 = 0.195321 loss)
I1005 15:47:51.994587  9606 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1005 15:47:57.237560  9606 solver.cpp:218] Iteration 28100 (19.0731 iter/s, 5.24297s/100 iters), loss = 0.190751
I1005 15:47:57.237589  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190751 (* 1 = 0.190751 loss)
I1005 15:47:57.237596  9606 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1005 15:48:02.491428  9606 solver.cpp:218] Iteration 28200 (19.0338 iter/s, 5.25382s/100 iters), loss = 0.38673
I1005 15:48:02.491544  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386731 (* 1 = 0.386731 loss)
I1005 15:48:02.491551  9606 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1005 15:48:07.742418  9606 solver.cpp:218] Iteration 28300 (19.0445 iter/s, 5.25086s/100 iters), loss = 0.213946
I1005 15:48:07.742447  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213947 (* 1 = 0.213947 loss)
I1005 15:48:07.742453  9606 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1005 15:48:12.997442  9606 solver.cpp:218] Iteration 28400 (19.0296 iter/s, 5.25498s/100 iters), loss = 0.148923
I1005 15:48:12.997484  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148924 (* 1 = 0.148924 loss)
I1005 15:48:12.997491  9606 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1005 15:48:17.982201  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:48:18.191035  9606 solver.cpp:330] Iteration 28500, Testing net (#0)
I1005 15:48:19.386808  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:48:19.435637  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.804
I1005 15:48:19.435672  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.606223 (* 1 = 0.606223 loss)
I1005 15:48:19.487953  9606 solver.cpp:218] Iteration 28500 (15.4073 iter/s, 6.49045s/100 iters), loss = 0.180917
I1005 15:48:19.487983  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180917 (* 1 = 0.180917 loss)
I1005 15:48:19.487989  9606 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1005 15:48:24.744333  9606 solver.cpp:218] Iteration 28600 (19.0247 iter/s, 5.25633s/100 iters), loss = 0.256209
I1005 15:48:24.744374  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256209 (* 1 = 0.256209 loss)
I1005 15:48:24.744380  9606 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1005 15:48:29.987774  9606 solver.cpp:218] Iteration 28700 (19.0717 iter/s, 5.24338s/100 iters), loss = 0.236168
I1005 15:48:29.987808  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236169 (* 1 = 0.236169 loss)
I1005 15:48:29.987815  9606 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1005 15:48:35.239358  9606 solver.cpp:218] Iteration 28800 (19.0421 iter/s, 5.25153s/100 iters), loss = 0.215784
I1005 15:48:35.239491  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215785 (* 1 = 0.215785 loss)
I1005 15:48:35.239509  9606 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1005 15:48:40.487941  9606 solver.cpp:218] Iteration 28900 (19.0533 iter/s, 5.24844s/100 iters), loss = 0.128817
I1005 15:48:40.487970  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128817 (* 1 = 0.128817 loss)
I1005 15:48:40.487977  9606 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1005 15:48:45.473134  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:48:45.687120  9606 solver.cpp:330] Iteration 29000, Testing net (#0)
I1005 15:48:46.874439  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:48:46.923894  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.77
I1005 15:48:46.923929  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.754547 (* 1 = 0.754547 loss)
I1005 15:48:46.976210  9606 solver.cpp:218] Iteration 29000 (15.4125 iter/s, 6.48822s/100 iters), loss = 0.23164
I1005 15:48:46.976234  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23164 (* 1 = 0.23164 loss)
I1005 15:48:46.976241  9606 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1005 15:48:52.222766  9606 solver.cpp:218] Iteration 29100 (19.0603 iter/s, 5.24651s/100 iters), loss = 0.228578
I1005 15:48:52.222796  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228579 (* 1 = 0.228579 loss)
I1005 15:48:52.222802  9606 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1005 15:48:57.466616  9606 solver.cpp:218] Iteration 29200 (19.0702 iter/s, 5.24379s/100 iters), loss = 0.202824
I1005 15:48:57.466666  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202825 (* 1 = 0.202825 loss)
I1005 15:48:57.466675  9606 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1005 15:49:02.718538  9606 solver.cpp:218] Iteration 29300 (19.041 iter/s, 5.25182s/100 iters), loss = 0.209634
I1005 15:49:02.718569  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209634 (* 1 = 0.209634 loss)
I1005 15:49:02.718575  9606 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1005 15:49:07.971213  9606 solver.cpp:218] Iteration 29400 (19.0381 iter/s, 5.25263s/100 iters), loss = 0.221084
I1005 15:49:07.971359  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221085 (* 1 = 0.221085 loss)
I1005 15:49:07.971366  9606 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1005 15:49:12.962937  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:49:13.173060  9606 solver.cpp:330] Iteration 29500, Testing net (#0)
I1005 15:49:14.360909  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:49:14.410778  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7858
I1005 15:49:14.410804  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.689541 (* 1 = 0.689541 loss)
I1005 15:49:14.463500  9606 solver.cpp:218] Iteration 29500 (15.4033 iter/s, 6.49213s/100 iters), loss = 0.203181
I1005 15:49:14.463527  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203182 (* 1 = 0.203182 loss)
I1005 15:49:14.463534  9606 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1005 15:49:19.717607  9606 solver.cpp:218] Iteration 29600 (19.0329 iter/s, 5.25406s/100 iters), loss = 0.304445
I1005 15:49:19.717645  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304445 (* 1 = 0.304445 loss)
I1005 15:49:19.717651  9606 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1005 15:49:24.966511  9606 solver.cpp:218] Iteration 29700 (19.0518 iter/s, 5.24885s/100 iters), loss = 0.257953
I1005 15:49:24.966553  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257954 (* 1 = 0.257954 loss)
I1005 15:49:24.966559  9606 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1005 15:49:30.210638  9606 solver.cpp:218] Iteration 29800 (19.0692 iter/s, 5.24406s/100 iters), loss = 0.265563
I1005 15:49:30.210678  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265564 (* 1 = 0.265564 loss)
I1005 15:49:30.210685  9606 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1005 15:49:35.460634  9606 solver.cpp:218] Iteration 29900 (19.0478 iter/s, 5.24994s/100 iters), loss = 0.242356
I1005 15:49:35.460675  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242356 (* 1 = 0.242356 loss)
I1005 15:49:35.460680  9606 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1005 15:49:40.452208  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:49:40.661192  9606 solver.cpp:330] Iteration 30000, Testing net (#0)
I1005 15:49:41.846937  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:49:41.896301  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8206
I1005 15:49:41.896337  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.523412 (* 1 = 0.523412 loss)
I1005 15:49:41.948895  9606 solver.cpp:218] Iteration 30000 (15.4126 iter/s, 6.4882s/100 iters), loss = 0.161271
I1005 15:49:41.948928  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161272 (* 1 = 0.161272 loss)
I1005 15:49:41.948935  9606 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1005 15:49:47.207262  9606 solver.cpp:218] Iteration 30100 (19.0175 iter/s, 5.25832s/100 iters), loss = 0.189119
I1005 15:49:47.207293  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189119 (* 1 = 0.189119 loss)
I1005 15:49:47.207309  9606 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1005 15:49:52.463546  9606 solver.cpp:218] Iteration 30200 (19.025 iter/s, 5.25624s/100 iters), loss = 0.396054
I1005 15:49:52.463577  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396054 (* 1 = 0.396054 loss)
I1005 15:49:52.463583  9606 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1005 15:49:57.719306  9606 solver.cpp:218] Iteration 30300 (19.0269 iter/s, 5.25571s/100 iters), loss = 0.182326
I1005 15:49:57.719338  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182326 (* 1 = 0.182326 loss)
I1005 15:49:57.719346  9606 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1005 15:50:02.964608  9606 solver.cpp:218] Iteration 30400 (19.0649 iter/s, 5.24525s/100 iters), loss = 0.203047
I1005 15:50:02.964640  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203048 (* 1 = 0.203048 loss)
I1005 15:50:02.964646  9606 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1005 15:50:07.951788  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:50:08.161291  9606 solver.cpp:330] Iteration 30500, Testing net (#0)
I1005 15:50:09.347497  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:50:09.397269  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8014
I1005 15:50:09.397303  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.600498 (* 1 = 0.600498 loss)
I1005 15:50:09.450989  9606 solver.cpp:218] Iteration 30500 (15.417 iter/s, 6.48633s/100 iters), loss = 0.157299
I1005 15:50:09.451025  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1573 (* 1 = 0.1573 loss)
I1005 15:50:09.451033  9606 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1005 15:50:14.706001  9606 solver.cpp:218] Iteration 30600 (19.0297 iter/s, 5.25496s/100 iters), loss = 0.262853
I1005 15:50:14.706149  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262854 (* 1 = 0.262854 loss)
I1005 15:50:14.706157  9606 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1005 15:50:19.952764  9606 solver.cpp:218] Iteration 30700 (19.06 iter/s, 5.2466s/100 iters), loss = 0.277707
I1005 15:50:19.952803  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277708 (* 1 = 0.277708 loss)
I1005 15:50:19.952808  9606 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1005 15:50:25.208767  9606 solver.cpp:218] Iteration 30800 (19.0261 iter/s, 5.25595s/100 iters), loss = 0.211086
I1005 15:50:25.208807  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211087 (* 1 = 0.211087 loss)
I1005 15:50:25.208813  9606 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1005 15:50:30.452143  9606 solver.cpp:218] Iteration 30900 (19.0719 iter/s, 5.24331s/100 iters), loss = 0.190295
I1005 15:50:30.452183  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190295 (* 1 = 0.190295 loss)
I1005 15:50:30.452189  9606 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1005 15:50:35.445149  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:50:35.655203  9606 solver.cpp:330] Iteration 31000, Testing net (#0)
I1005 15:50:36.848088  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:50:36.897656  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8126
I1005 15:50:36.897682  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55935 (* 1 = 0.55935 loss)
I1005 15:50:36.949668  9606 solver.cpp:218] Iteration 31000 (15.3906 iter/s, 6.49747s/100 iters), loss = 0.18285
I1005 15:50:36.949702  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18285 (* 1 = 0.18285 loss)
I1005 15:50:36.949720  9606 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1005 15:50:42.196791  9606 solver.cpp:218] Iteration 31100 (19.0582 iter/s, 5.24707s/100 iters), loss = 0.252548
I1005 15:50:42.196825  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252548 (* 1 = 0.252548 loss)
I1005 15:50:42.196843  9606 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1005 15:50:47.454237  9606 solver.cpp:218] Iteration 31200 (19.0208 iter/s, 5.25739s/100 iters), loss = 0.270392
I1005 15:50:47.454380  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270392 (* 1 = 0.270392 loss)
I1005 15:50:47.454424  9606 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1005 15:50:52.707582  9606 solver.cpp:218] Iteration 31300 (19.0361 iter/s, 5.25319s/100 iters), loss = 0.230947
I1005 15:50:52.707617  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230948 (* 1 = 0.230948 loss)
I1005 15:50:52.707624  9606 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1005 15:50:57.959208  9606 solver.cpp:218] Iteration 31400 (19.0419 iter/s, 5.25158s/100 iters), loss = 0.187708
I1005 15:50:57.959241  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187709 (* 1 = 0.187709 loss)
I1005 15:50:57.959249  9606 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1005 15:51:02.941331  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:51:03.151525  9606 solver.cpp:330] Iteration 31500, Testing net (#0)
I1005 15:51:04.341274  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:51:04.390866  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7854
I1005 15:51:04.390892  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.70985 (* 1 = 0.70985 loss)
I1005 15:51:04.443579  9606 solver.cpp:218] Iteration 31500 (15.4218 iter/s, 6.48432s/100 iters), loss = 0.270736
I1005 15:51:04.443614  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270737 (* 1 = 0.270737 loss)
I1005 15:51:04.443624  9606 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1005 15:51:09.696269  9606 solver.cpp:218] Iteration 31600 (19.0381 iter/s, 5.25263s/100 iters), loss = 0.294251
I1005 15:51:09.696303  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294251 (* 1 = 0.294251 loss)
I1005 15:51:09.696310  9606 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1005 15:51:14.942260  9606 solver.cpp:218] Iteration 31700 (19.0624 iter/s, 5.24594s/100 iters), loss = 0.318092
I1005 15:51:14.942299  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318092 (* 1 = 0.318092 loss)
I1005 15:51:14.942306  9606 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1005 15:51:20.201833  9606 solver.cpp:218] Iteration 31800 (19.0132 iter/s, 5.25952s/100 iters), loss = 0.236024
I1005 15:51:20.201966  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236025 (* 1 = 0.236025 loss)
I1005 15:51:20.201972  9606 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1005 15:51:25.461839  9606 solver.cpp:218] Iteration 31900 (19.0119 iter/s, 5.25986s/100 iters), loss = 0.196022
I1005 15:51:25.461880  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196023 (* 1 = 0.196023 loss)
I1005 15:51:25.461886  9606 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1005 15:51:30.449282  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:51:30.665004  9606 solver.cpp:330] Iteration 32000, Testing net (#0)
I1005 15:51:31.849418  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:51:31.899050  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8046
I1005 15:51:31.899085  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.599771 (* 1 = 0.599771 loss)
I1005 15:51:31.951591  9606 solver.cpp:218] Iteration 32000 (15.409 iter/s, 6.4897s/100 iters), loss = 0.217413
I1005 15:51:31.951617  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217413 (* 1 = 0.217413 loss)
I1005 15:51:31.951623  9606 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1005 15:51:37.209259  9606 solver.cpp:218] Iteration 32100 (19.02 iter/s, 5.25762s/100 iters), loss = 0.298904
I1005 15:51:37.209298  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298904 (* 1 = 0.298904 loss)
I1005 15:51:37.209306  9606 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1005 15:51:42.456168  9606 solver.cpp:218] Iteration 32200 (19.0591 iter/s, 5.24685s/100 iters), loss = 0.234389
I1005 15:51:42.456213  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23439 (* 1 = 0.23439 loss)
I1005 15:51:42.456220  9606 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1005 15:51:47.703354  9606 solver.cpp:218] Iteration 32300 (19.0581 iter/s, 5.24712s/100 iters), loss = 0.221785
I1005 15:51:47.703384  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221785 (* 1 = 0.221785 loss)
I1005 15:51:47.703390  9606 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1005 15:51:52.952795  9606 solver.cpp:218] Iteration 32400 (19.0498 iter/s, 5.24939s/100 iters), loss = 0.15281
I1005 15:51:52.952908  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15281 (* 1 = 0.15281 loss)
I1005 15:51:52.952914  9606 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1005 15:51:57.943620  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:51:58.153137  9606 solver.cpp:330] Iteration 32500, Testing net (#0)
I1005 15:51:59.338970  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:51:59.388790  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7815
I1005 15:51:59.388826  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.756322 (* 1 = 0.756322 loss)
I1005 15:51:59.441259  9606 solver.cpp:218] Iteration 32500 (15.4123 iter/s, 6.48834s/100 iters), loss = 0.21432
I1005 15:51:59.441292  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21432 (* 1 = 0.21432 loss)
I1005 15:51:59.441298  9606 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1005 15:52:04.698801  9606 solver.cpp:218] Iteration 32600 (19.0205 iter/s, 5.25749s/100 iters), loss = 0.240329
I1005 15:52:04.698832  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24033 (* 1 = 0.24033 loss)
I1005 15:52:04.698837  9606 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1005 15:52:09.963862  9606 solver.cpp:218] Iteration 32700 (18.9933 iter/s, 5.26501s/100 iters), loss = 0.212814
I1005 15:52:09.963892  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212814 (* 1 = 0.212814 loss)
I1005 15:52:09.963912  9606 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1005 15:52:15.214763  9606 solver.cpp:218] Iteration 32800 (19.0445 iter/s, 5.25085s/100 iters), loss = 0.195898
I1005 15:52:15.214795  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195899 (* 1 = 0.195899 loss)
I1005 15:52:15.214812  9606 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1005 15:52:20.475910  9606 solver.cpp:218] Iteration 32900 (19.0074 iter/s, 5.2611s/100 iters), loss = 0.201834
I1005 15:52:20.475939  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201834 (* 1 = 0.201834 loss)
I1005 15:52:20.475945  9606 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1005 15:52:25.474112  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:52:25.683615  9606 solver.cpp:330] Iteration 33000, Testing net (#0)
I1005 15:52:26.868506  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:52:26.918041  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7796
I1005 15:52:26.918076  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.669074 (* 1 = 0.669074 loss)
I1005 15:52:26.970393  9606 solver.cpp:218] Iteration 33000 (15.3978 iter/s, 6.49444s/100 iters), loss = 0.218291
I1005 15:52:26.970434  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218291 (* 1 = 0.218291 loss)
I1005 15:52:26.970441  9606 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1005 15:52:32.219132  9606 solver.cpp:218] Iteration 33100 (19.0524 iter/s, 5.24868s/100 iters), loss = 0.246718
I1005 15:52:32.219162  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246718 (* 1 = 0.246718 loss)
I1005 15:52:32.219169  9606 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1005 15:52:37.468986  9606 solver.cpp:218] Iteration 33200 (19.0483 iter/s, 5.2498s/100 iters), loss = 0.31831
I1005 15:52:37.469017  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318311 (* 1 = 0.318311 loss)
I1005 15:52:37.469022  9606 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1005 15:52:42.719306  9606 solver.cpp:218] Iteration 33300 (19.0466 iter/s, 5.25027s/100 iters), loss = 0.143662
I1005 15:52:42.719341  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143662 (* 1 = 0.143662 loss)
I1005 15:52:42.719347  9606 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1005 15:52:47.964524  9606 solver.cpp:218] Iteration 33400 (19.0652 iter/s, 5.24516s/100 iters), loss = 0.206574
I1005 15:52:47.964557  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206574 (* 1 = 0.206574 loss)
I1005 15:52:47.964563  9606 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1005 15:52:52.956992  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:52:53.167116  9606 solver.cpp:330] Iteration 33500, Testing net (#0)
I1005 15:52:54.353637  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:52:54.403245  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.786
I1005 15:52:54.403270  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.664246 (* 1 = 0.664246 loss)
I1005 15:52:54.456851  9606 solver.cpp:218] Iteration 33500 (15.4029 iter/s, 6.49227s/100 iters), loss = 0.210843
I1005 15:52:54.456890  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210844 (* 1 = 0.210844 loss)
I1005 15:52:54.456897  9606 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1005 15:52:59.710593  9606 solver.cpp:218] Iteration 33600 (19.0343 iter/s, 5.25368s/100 iters), loss = 0.169407
I1005 15:52:59.710733  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169408 (* 1 = 0.169408 loss)
I1005 15:52:59.710741  9606 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1005 15:53:04.968704  9606 solver.cpp:218] Iteration 33700 (19.0188 iter/s, 5.25796s/100 iters), loss = 0.250881
I1005 15:53:04.968744  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250882 (* 1 = 0.250882 loss)
I1005 15:53:04.968750  9606 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1005 15:53:10.227720  9606 solver.cpp:218] Iteration 33800 (19.0152 iter/s, 5.25896s/100 iters), loss = 0.218748
I1005 15:53:10.227749  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218748 (* 1 = 0.218748 loss)
I1005 15:53:10.227754  9606 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1005 15:53:15.476212  9606 solver.cpp:218] Iteration 33900 (19.0533 iter/s, 5.24844s/100 iters), loss = 0.212652
I1005 15:53:15.476249  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212653 (* 1 = 0.212653 loss)
I1005 15:53:15.476258  9606 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1005 15:53:20.461640  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:53:20.670740  9606 solver.cpp:330] Iteration 34000, Testing net (#0)
I1005 15:53:21.862016  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:53:21.911692  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8177
I1005 15:53:21.911717  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.570292 (* 1 = 0.570292 loss)
I1005 15:53:21.963851  9606 solver.cpp:218] Iteration 34000 (15.414 iter/s, 6.48759s/100 iters), loss = 0.171596
I1005 15:53:21.963882  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171596 (* 1 = 0.171596 loss)
I1005 15:53:21.963889  9606 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1005 15:53:27.210857  9606 solver.cpp:218] Iteration 34100 (19.0587 iter/s, 5.24695s/100 iters), loss = 0.170906
I1005 15:53:27.210888  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170907 (* 1 = 0.170907 loss)
I1005 15:53:27.210894  9606 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1005 15:53:32.460551  9606 solver.cpp:218] Iteration 34200 (19.0489 iter/s, 5.24965s/100 iters), loss = 0.277543
I1005 15:53:32.460678  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277544 (* 1 = 0.277544 loss)
I1005 15:53:32.460695  9606 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1005 15:53:37.714821  9606 solver.cpp:218] Iteration 34300 (19.0326 iter/s, 5.25414s/100 iters), loss = 0.211194
I1005 15:53:37.714853  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211194 (* 1 = 0.211194 loss)
I1005 15:53:37.714859  9606 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1005 15:53:42.970166  9606 solver.cpp:218] Iteration 34400 (19.0284 iter/s, 5.2553s/100 iters), loss = 0.340175
I1005 15:53:42.970198  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340176 (* 1 = 0.340176 loss)
I1005 15:53:42.970204  9606 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1005 15:53:47.953197  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:53:48.162432  9606 solver.cpp:330] Iteration 34500, Testing net (#0)
I1005 15:53:49.355028  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:53:49.404588  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8054
I1005 15:53:49.404613  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.610984 (* 1 = 0.610984 loss)
I1005 15:53:49.456892  9606 solver.cpp:218] Iteration 34500 (15.4162 iter/s, 6.48668s/100 iters), loss = 0.244508
I1005 15:53:49.456920  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244509 (* 1 = 0.244509 loss)
I1005 15:53:49.456926  9606 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1005 15:53:54.714213  9606 solver.cpp:218] Iteration 34600 (19.0213 iter/s, 5.25727s/100 iters), loss = 0.203783
I1005 15:53:54.714249  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203784 (* 1 = 0.203784 loss)
I1005 15:53:54.714257  9606 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1005 15:53:59.952765  9606 solver.cpp:218] Iteration 34700 (19.0894 iter/s, 5.2385s/100 iters), loss = 0.237279
I1005 15:53:59.952796  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237279 (* 1 = 0.237279 loss)
I1005 15:53:59.952803  9606 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1005 15:54:05.207618  9606 solver.cpp:218] Iteration 34800 (19.0302 iter/s, 5.2548s/100 iters), loss = 0.225497
I1005 15:54:05.207757  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225497 (* 1 = 0.225497 loss)
I1005 15:54:05.207788  9606 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1005 15:54:10.455948  9606 solver.cpp:218] Iteration 34900 (19.0542 iter/s, 5.24819s/100 iters), loss = 0.1706
I1005 15:54:10.455981  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1706 (* 1 = 0.1706 loss)
I1005 15:54:10.455988  9606 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1005 15:54:15.441138  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:54:15.655951  9606 solver.cpp:330] Iteration 35000, Testing net (#0)
I1005 15:54:16.843538  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:54:16.893292  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7671
I1005 15:54:16.893327  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.7707 (* 1 = 0.7707 loss)
I1005 15:54:16.945412  9606 solver.cpp:218] Iteration 35000 (15.4097 iter/s, 6.48942s/100 iters), loss = 0.247953
I1005 15:54:16.945441  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247954 (* 1 = 0.247954 loss)
I1005 15:54:16.945447  9606 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1005 15:54:22.196539  9606 solver.cpp:218] Iteration 35100 (19.0437 iter/s, 5.25108s/100 iters), loss = 0.298521
I1005 15:54:22.196570  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298521 (* 1 = 0.298521 loss)
I1005 15:54:22.196575  9606 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1005 15:54:27.444423  9606 solver.cpp:218] Iteration 35200 (19.0555 iter/s, 5.24783s/100 iters), loss = 0.243902
I1005 15:54:27.444461  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243902 (* 1 = 0.243902 loss)
I1005 15:54:27.444478  9606 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1005 15:54:32.696980  9606 solver.cpp:218] Iteration 35300 (19.0387 iter/s, 5.25247s/100 iters), loss = 0.221634
I1005 15:54:32.697021  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221635 (* 1 = 0.221635 loss)
I1005 15:54:32.697026  9606 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1005 15:54:37.953444  9606 solver.cpp:218] Iteration 35400 (19.0244 iter/s, 5.2564s/100 iters), loss = 0.175629
I1005 15:54:37.953552  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175629 (* 1 = 0.175629 loss)
I1005 15:54:37.953558  9606 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1005 15:54:42.946331  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:54:43.156011  9606 solver.cpp:330] Iteration 35500, Testing net (#0)
I1005 15:54:44.341310  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:54:44.390812  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.779
I1005 15:54:44.390856  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.678832 (* 1 = 0.678832 loss)
I1005 15:54:44.443369  9606 solver.cpp:218] Iteration 35500 (15.4088 iter/s, 6.4898s/100 iters), loss = 0.21817
I1005 15:54:44.443405  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21817 (* 1 = 0.21817 loss)
I1005 15:54:44.443413  9606 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1005 15:54:49.701391  9606 solver.cpp:218] Iteration 35600 (19.0188 iter/s, 5.25797s/100 iters), loss = 0.213339
I1005 15:54:49.701421  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213339 (* 1 = 0.213339 loss)
I1005 15:54:49.701437  9606 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1005 15:54:54.949177  9606 solver.cpp:218] Iteration 35700 (19.0558 iter/s, 5.24774s/100 iters), loss = 0.321834
I1005 15:54:54.949218  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321835 (* 1 = 0.321835 loss)
I1005 15:54:54.949224  9606 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1005 15:55:00.188010  9606 solver.cpp:218] Iteration 35800 (19.0884 iter/s, 5.23877s/100 iters), loss = 0.345675
I1005 15:55:00.188040  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345676 (* 1 = 0.345676 loss)
I1005 15:55:00.188046  9606 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1005 15:55:05.439599  9606 solver.cpp:218] Iteration 35900 (19.042 iter/s, 5.25154s/100 iters), loss = 0.126666
I1005 15:55:05.439627  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126666 (* 1 = 0.126666 loss)
I1005 15:55:05.439633  9606 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1005 15:55:10.433269  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:55:10.642343  9606 solver.cpp:330] Iteration 36000, Testing net (#0)
I1005 15:55:11.828585  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:55:11.878306  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8335
I1005 15:55:11.878341  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490361 (* 1 = 0.490361 loss)
I1005 15:55:11.930788  9606 solver.cpp:218] Iteration 36000 (15.4056 iter/s, 6.49114s/100 iters), loss = 0.177019
I1005 15:55:11.930814  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177019 (* 1 = 0.177019 loss)
I1005 15:55:11.930821  9606 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1005 15:55:17.188076  9606 solver.cpp:218] Iteration 36100 (19.0214 iter/s, 5.25725s/100 iters), loss = 0.269609
I1005 15:55:17.188117  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269609 (* 1 = 0.269609 loss)
I1005 15:55:17.188122  9606 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1005 15:55:22.443716  9606 solver.cpp:218] Iteration 36200 (19.0274 iter/s, 5.25558s/100 iters), loss = 0.196944
I1005 15:55:22.443744  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196945 (* 1 = 0.196945 loss)
I1005 15:55:22.443750  9606 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1005 15:55:27.696868  9606 solver.cpp:218] Iteration 36300 (19.0364 iter/s, 5.2531s/100 iters), loss = 0.222313
I1005 15:55:27.696902  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222314 (* 1 = 0.222314 loss)
I1005 15:55:27.696908  9606 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1005 15:55:32.945451  9606 solver.cpp:218] Iteration 36400 (19.0529 iter/s, 5.24853s/100 iters), loss = 0.230862
I1005 15:55:32.945482  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230863 (* 1 = 0.230863 loss)
I1005 15:55:32.945488  9606 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1005 15:55:37.939514  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:55:38.148591  9606 solver.cpp:330] Iteration 36500, Testing net (#0)
I1005 15:55:39.333529  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:55:39.382670  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7771
I1005 15:55:39.382706  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.705185 (* 1 = 0.705185 loss)
I1005 15:55:39.434931  9606 solver.cpp:218] Iteration 36500 (15.4097 iter/s, 6.48943s/100 iters), loss = 0.213437
I1005 15:55:39.434964  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213437 (* 1 = 0.213437 loss)
I1005 15:55:39.434972  9606 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1005 15:55:44.687288  9606 solver.cpp:218] Iteration 36600 (19.0393 iter/s, 5.25231s/100 iters), loss = 0.253408
I1005 15:55:44.687377  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253409 (* 1 = 0.253409 loss)
I1005 15:55:44.687384  9606 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1005 15:55:49.939901  9606 solver.cpp:218] Iteration 36700 (19.0385 iter/s, 5.25251s/100 iters), loss = 0.288244
I1005 15:55:49.939940  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288245 (* 1 = 0.288245 loss)
I1005 15:55:49.939946  9606 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1005 15:55:55.196871  9606 solver.cpp:218] Iteration 36800 (19.0226 iter/s, 5.25691s/100 iters), loss = 0.21928
I1005 15:55:55.196900  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21928 (* 1 = 0.21928 loss)
I1005 15:55:55.196907  9606 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1005 15:56:00.445410  9606 solver.cpp:218] Iteration 36900 (19.0531 iter/s, 5.24848s/100 iters), loss = 0.312791
I1005 15:56:00.445454  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312792 (* 1 = 0.312792 loss)
I1005 15:56:00.445462  9606 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1005 15:56:05.443522  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:56:05.653944  9606 solver.cpp:330] Iteration 37000, Testing net (#0)
I1005 15:56:06.849859  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:56:06.899566  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7966
I1005 15:56:06.899592  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.615518 (* 1 = 0.615518 loss)
I1005 15:56:06.952142  9606 solver.cpp:218] Iteration 37000 (15.3688 iter/s, 6.50667s/100 iters), loss = 0.202357
I1005 15:56:06.952174  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202357 (* 1 = 0.202357 loss)
I1005 15:56:06.952181  9606 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1005 15:56:12.199405  9606 solver.cpp:218] Iteration 37100 (19.0577 iter/s, 5.24721s/100 iters), loss = 0.24941
I1005 15:56:12.199446  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24941 (* 1 = 0.24941 loss)
I1005 15:56:12.199452  9606 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1005 15:56:17.456749  9606 solver.cpp:218] Iteration 37200 (19.0212 iter/s, 5.25728s/100 iters), loss = 0.307907
I1005 15:56:17.456894  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307907 (* 1 = 0.307907 loss)
I1005 15:56:17.456912  9606 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1005 15:56:22.711395  9606 solver.cpp:218] Iteration 37300 (19.0314 iter/s, 5.25448s/100 iters), loss = 0.260686
I1005 15:56:22.711427  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260687 (* 1 = 0.260687 loss)
I1005 15:56:22.711447  9606 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1005 15:56:27.965198  9606 solver.cpp:218] Iteration 37400 (19.034 iter/s, 5.25376s/100 iters), loss = 0.180507
I1005 15:56:27.965231  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180508 (* 1 = 0.180508 loss)
I1005 15:56:27.965250  9606 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1005 15:56:32.947201  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:56:33.157562  9606 solver.cpp:330] Iteration 37500, Testing net (#0)
I1005 15:56:34.348493  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:56:34.397955  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7941
I1005 15:56:34.398005  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.656909 (* 1 = 0.656909 loss)
I1005 15:56:34.450125  9606 solver.cpp:218] Iteration 37500 (15.4205 iter/s, 6.48488s/100 iters), loss = 0.299707
I1005 15:56:34.450153  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299708 (* 1 = 0.299708 loss)
I1005 15:56:34.450160  9606 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1005 15:56:39.692956  9606 solver.cpp:218] Iteration 37600 (19.0738 iter/s, 5.24278s/100 iters), loss = 0.237817
I1005 15:56:39.692991  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237818 (* 1 = 0.237818 loss)
I1005 15:56:39.692998  9606 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1005 15:56:44.931665  9606 solver.cpp:218] Iteration 37700 (19.0889 iter/s, 5.23866s/100 iters), loss = 0.286544
I1005 15:56:44.931696  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286545 (* 1 = 0.286545 loss)
I1005 15:56:44.931712  9606 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1005 15:56:50.178036  9606 solver.cpp:218] Iteration 37800 (19.061 iter/s, 5.24632s/100 iters), loss = 0.275368
I1005 15:56:50.178160  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275368 (* 1 = 0.275368 loss)
I1005 15:56:50.178177  9606 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1005 15:56:55.432967  9606 solver.cpp:218] Iteration 37900 (19.0302 iter/s, 5.25479s/100 iters), loss = 0.214749
I1005 15:56:55.432998  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21475 (* 1 = 0.21475 loss)
I1005 15:56:55.433004  9606 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1005 15:57:00.415791  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:57:00.632827  9606 solver.cpp:330] Iteration 38000, Testing net (#0)
I1005 15:57:01.819540  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:57:01.869277  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8351
I1005 15:57:01.869312  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.49014 (* 1 = 0.49014 loss)
I1005 15:57:01.921569  9606 solver.cpp:218] Iteration 38000 (15.4118 iter/s, 6.48855s/100 iters), loss = 0.163959
I1005 15:57:01.921602  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16396 (* 1 = 0.16396 loss)
I1005 15:57:01.921609  9606 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1005 15:57:07.179437  9606 solver.cpp:218] Iteration 38100 (19.0193 iter/s, 5.25782s/100 iters), loss = 0.265116
I1005 15:57:07.179471  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265117 (* 1 = 0.265117 loss)
I1005 15:57:07.179478  9606 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1005 15:57:12.423326  9606 solver.cpp:218] Iteration 38200 (19.07 iter/s, 5.24384s/100 iters), loss = 0.29487
I1005 15:57:12.423354  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294871 (* 1 = 0.294871 loss)
I1005 15:57:12.423360  9606 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1005 15:57:17.676702  9606 solver.cpp:218] Iteration 38300 (19.0355 iter/s, 5.25333s/100 iters), loss = 0.240672
I1005 15:57:17.676731  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240673 (* 1 = 0.240673 loss)
I1005 15:57:17.676738  9606 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1005 15:57:22.929915  9606 solver.cpp:218] Iteration 38400 (19.0361 iter/s, 5.25316s/100 iters), loss = 0.227217
I1005 15:57:22.930030  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227217 (* 1 = 0.227217 loss)
I1005 15:57:22.930038  9606 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1005 15:57:27.918568  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:57:28.128475  9606 solver.cpp:330] Iteration 38500, Testing net (#0)
I1005 15:57:29.314937  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:57:29.364675  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6856
I1005 15:57:29.364698  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11503 (* 1 = 1.11503 loss)
I1005 15:57:29.417194  9606 solver.cpp:218] Iteration 38500 (15.4151 iter/s, 6.48715s/100 iters), loss = 0.161244
I1005 15:57:29.417223  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161244 (* 1 = 0.161244 loss)
I1005 15:57:29.417229  9606 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1005 15:57:34.671731  9606 solver.cpp:218] Iteration 38600 (19.0313 iter/s, 5.25449s/100 iters), loss = 0.275719
I1005 15:57:34.671761  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275719 (* 1 = 0.275719 loss)
I1005 15:57:34.671767  9606 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1005 15:57:39.927016  9606 solver.cpp:218] Iteration 38700 (19.0286 iter/s, 5.25524s/100 iters), loss = 0.232678
I1005 15:57:39.927057  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232678 (* 1 = 0.232678 loss)
I1005 15:57:39.927064  9606 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1005 15:57:45.174506  9606 solver.cpp:218] Iteration 38800 (19.0569 iter/s, 5.24743s/100 iters), loss = 0.203007
I1005 15:57:45.174540  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203008 (* 1 = 0.203008 loss)
I1005 15:57:45.174546  9606 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1005 15:57:50.436280  9606 solver.cpp:218] Iteration 38900 (19.0052 iter/s, 5.26172s/100 iters), loss = 0.188004
I1005 15:57:50.436321  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188004 (* 1 = 0.188004 loss)
I1005 15:57:50.436326  9606 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1005 15:57:55.433804  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:57:55.644388  9606 solver.cpp:330] Iteration 39000, Testing net (#0)
I1005 15:57:56.831437  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:57:56.880934  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7981
I1005 15:57:56.880967  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.730989 (* 1 = 0.730989 loss)
I1005 15:57:56.933429  9606 solver.cpp:218] Iteration 39000 (15.3915 iter/s, 6.4971s/100 iters), loss = 0.224696
I1005 15:57:56.933456  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224697 (* 1 = 0.224697 loss)
I1005 15:57:56.933464  9606 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1005 15:58:02.191498  9606 solver.cpp:218] Iteration 39100 (19.0185 iter/s, 5.25803s/100 iters), loss = 0.329829
I1005 15:58:02.191537  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32983 (* 1 = 0.32983 loss)
I1005 15:58:02.191543  9606 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1005 15:58:07.440803  9606 solver.cpp:218] Iteration 39200 (19.0504 iter/s, 5.24925s/100 iters), loss = 0.265705
I1005 15:58:07.440843  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265706 (* 1 = 0.265706 loss)
I1005 15:58:07.440850  9606 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1005 15:58:12.693570  9606 solver.cpp:218] Iteration 39300 (19.0378 iter/s, 5.2527s/100 iters), loss = 0.132971
I1005 15:58:12.693616  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132971 (* 1 = 0.132971 loss)
I1005 15:58:12.693624  9606 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1005 15:58:17.941798  9606 solver.cpp:218] Iteration 39400 (19.0543 iter/s, 5.24817s/100 iters), loss = 0.259866
I1005 15:58:17.941839  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259867 (* 1 = 0.259867 loss)
I1005 15:58:17.941844  9606 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1005 15:58:22.932276  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:58:23.141247  9606 solver.cpp:330] Iteration 39500, Testing net (#0)
I1005 15:58:24.325224  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:58:24.374682  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.845
I1005 15:58:24.374718  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47479 (* 1 = 0.47479 loss)
I1005 15:58:24.427181  9606 solver.cpp:218] Iteration 39500 (15.4194 iter/s, 6.48533s/100 iters), loss = 0.170218
I1005 15:58:24.427217  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170218 (* 1 = 0.170218 loss)
I1005 15:58:24.427232  9606 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1005 15:58:29.682687  9606 solver.cpp:218] Iteration 39600 (19.0279 iter/s, 5.25545s/100 iters), loss = 0.213606
I1005 15:58:29.682778  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213607 (* 1 = 0.213607 loss)
I1005 15:58:29.682796  9606 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1005 15:58:34.939748  9606 solver.cpp:218] Iteration 39700 (19.0224 iter/s, 5.25696s/100 iters), loss = 0.246191
I1005 15:58:34.939779  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246192 (* 1 = 0.246192 loss)
I1005 15:58:34.939784  9606 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1005 15:58:40.195456  9606 solver.cpp:218] Iteration 39800 (19.0271 iter/s, 5.25566s/100 iters), loss = 0.216348
I1005 15:58:40.195485  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216349 (* 1 = 0.216349 loss)
I1005 15:58:40.195492  9606 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1005 15:58:45.443034  9606 solver.cpp:218] Iteration 39900 (19.0566 iter/s, 5.24753s/100 iters), loss = 0.245206
I1005 15:58:45.443066  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245207 (* 1 = 0.245207 loss)
I1005 15:58:45.443073  9606 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1005 15:58:50.433570  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:58:50.643376  9606 solver.cpp:330] Iteration 40000, Testing net (#0)
I1005 15:58:51.834228  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:58:51.883950  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7947
I1005 15:58:51.883976  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.617871 (* 1 = 0.617871 loss)
I1005 15:58:51.936568  9606 solver.cpp:218] Iteration 40000 (15.4001 iter/s, 6.49348s/100 iters), loss = 0.167763
I1005 15:58:51.936597  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167764 (* 1 = 0.167764 loss)
I1005 15:58:51.936604  9606 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1005 15:58:51.936606  9606 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1005 15:58:57.180734  9606 solver.cpp:218] Iteration 40100 (19.069 iter/s, 5.24412s/100 iters), loss = 0.167757
I1005 15:58:57.180765  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167757 (* 1 = 0.167757 loss)
I1005 15:58:57.180771  9606 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1005 15:59:02.434008  9606 solver.cpp:218] Iteration 40200 (19.0359 iter/s, 5.25323s/100 iters), loss = 0.197946
I1005 15:59:02.434161  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197947 (* 1 = 0.197947 loss)
I1005 15:59:02.434182  9606 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1005 15:59:07.685338  9606 solver.cpp:218] Iteration 40300 (19.0434 iter/s, 5.25116s/100 iters), loss = 0.147137
I1005 15:59:07.685370  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147138 (* 1 = 0.147138 loss)
I1005 15:59:07.685389  9606 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1005 15:59:12.942891  9606 solver.cpp:218] Iteration 40400 (19.0205 iter/s, 5.2575s/100 iters), loss = 0.0974967
I1005 15:59:12.942924  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0974973 (* 1 = 0.0974973 loss)
I1005 15:59:12.942934  9606 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1005 15:59:17.930019  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:59:18.139353  9606 solver.cpp:330] Iteration 40500, Testing net (#0)
I1005 15:59:19.336282  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:59:19.386348  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I1005 15:59:19.386373  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307781 (* 1 = 0.307781 loss)
I1005 15:59:19.438778  9606 solver.cpp:218] Iteration 40500 (15.3945 iter/s, 6.49584s/100 iters), loss = 0.135569
I1005 15:59:19.438808  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135569 (* 1 = 0.135569 loss)
I1005 15:59:19.438818  9606 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1005 15:59:24.698655  9606 solver.cpp:218] Iteration 40600 (19.012 iter/s, 5.25983s/100 iters), loss = 0.134453
I1005 15:59:24.698693  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134453 (* 1 = 0.134453 loss)
I1005 15:59:24.698701  9606 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1005 15:59:29.947793  9606 solver.cpp:218] Iteration 40700 (19.0509 iter/s, 5.24908s/100 iters), loss = 0.144318
I1005 15:59:29.947825  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144318 (* 1 = 0.144318 loss)
I1005 15:59:29.947844  9606 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1005 15:59:35.206660  9606 solver.cpp:218] Iteration 40800 (19.0157 iter/s, 5.25882s/100 iters), loss = 0.0938797
I1005 15:59:35.206806  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0938802 (* 1 = 0.0938802 loss)
I1005 15:59:35.206830  9606 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1005 15:59:40.459522  9606 solver.cpp:218] Iteration 40900 (19.0378 iter/s, 5.25271s/100 iters), loss = 0.0795704
I1005 15:59:40.459555  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0795709 (* 1 = 0.0795709 loss)
I1005 15:59:40.459574  9606 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1005 15:59:45.444063  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:59:45.658958  9606 solver.cpp:330] Iteration 41000, Testing net (#0)
I1005 15:59:46.846854  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 15:59:46.896342  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I1005 15:59:46.896369  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.289403 (* 1 = 0.289403 loss)
I1005 15:59:46.948396  9606 solver.cpp:218] Iteration 41000 (15.4111 iter/s, 6.48883s/100 iters), loss = 0.0674239
I1005 15:59:46.948424  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0674244 (* 1 = 0.0674244 loss)
I1005 15:59:46.948433  9606 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1005 15:59:52.202020  9606 solver.cpp:218] Iteration 41100 (19.0346 iter/s, 5.25358s/100 iters), loss = 0.129946
I1005 15:59:52.202051  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129947 (* 1 = 0.129947 loss)
I1005 15:59:52.202059  9606 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1005 15:59:57.445693  9606 solver.cpp:218] Iteration 41200 (19.0708 iter/s, 5.24362s/100 iters), loss = 0.0895477
I1005 15:59:57.445725  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0895482 (* 1 = 0.0895482 loss)
I1005 15:59:57.445734  9606 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1005 16:00:02.697721  9606 solver.cpp:218] Iteration 41300 (19.0404 iter/s, 5.25198s/100 iters), loss = 0.0913036
I1005 16:00:02.697754  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0913041 (* 1 = 0.0913041 loss)
I1005 16:00:02.697762  9606 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1005 16:00:07.953687  9606 solver.cpp:218] Iteration 41400 (19.0262 iter/s, 5.25592s/100 iters), loss = 0.151629
I1005 16:00:07.953809  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151629 (* 1 = 0.151629 loss)
I1005 16:00:07.953825  9606 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1005 16:00:12.952914  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:00:13.163388  9606 solver.cpp:330] Iteration 41500, Testing net (#0)
I1005 16:00:14.349367  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:00:14.398890  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I1005 16:00:14.398923  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291643 (* 1 = 0.291643 loss)
I1005 16:00:14.451344  9606 solver.cpp:218] Iteration 41500 (15.3905 iter/s, 6.49752s/100 iters), loss = 0.0620423
I1005 16:00:14.451369  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620427 (* 1 = 0.0620427 loss)
I1005 16:00:14.451375  9606 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1005 16:00:19.709714  9606 solver.cpp:218] Iteration 41600 (19.0175 iter/s, 5.25833s/100 iters), loss = 0.11301
I1005 16:00:19.709754  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113011 (* 1 = 0.113011 loss)
I1005 16:00:19.709760  9606 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1005 16:00:24.962465  9606 solver.cpp:218] Iteration 41700 (19.0379 iter/s, 5.25269s/100 iters), loss = 0.118355
I1005 16:00:24.962504  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118355 (* 1 = 0.118355 loss)
I1005 16:00:24.962512  9606 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1005 16:00:30.204038  9606 solver.cpp:218] Iteration 41800 (19.0784 iter/s, 5.24152s/100 iters), loss = 0.100867
I1005 16:00:30.204082  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100867 (* 1 = 0.100867 loss)
I1005 16:00:30.204087  9606 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1005 16:00:35.456470  9606 solver.cpp:218] Iteration 41900 (19.039 iter/s, 5.25237s/100 iters), loss = 0.100917
I1005 16:00:35.456511  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100917 (* 1 = 0.100917 loss)
I1005 16:00:35.456516  9606 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1005 16:00:40.449182  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:00:40.659914  9606 solver.cpp:330] Iteration 42000, Testing net (#0)
I1005 16:00:41.847900  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:00:41.897665  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I1005 16:00:41.897701  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286338 (* 1 = 0.286338 loss)
I1005 16:00:41.949901  9606 solver.cpp:218] Iteration 42000 (15.4003 iter/s, 6.49337s/100 iters), loss = 0.0891461
I1005 16:00:41.949928  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0891465 (* 1 = 0.0891465 loss)
I1005 16:00:41.949934  9606 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1005 16:00:47.207979  9606 solver.cpp:218] Iteration 42100 (19.0185 iter/s, 5.25803s/100 iters), loss = 0.157059
I1005 16:00:47.208019  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157059 (* 1 = 0.157059 loss)
I1005 16:00:47.208025  9606 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1005 16:00:52.462731  9606 solver.cpp:218] Iteration 42200 (19.0306 iter/s, 5.25469s/100 iters), loss = 0.138114
I1005 16:00:52.462762  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138114 (* 1 = 0.138114 loss)
I1005 16:00:52.462769  9606 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1005 16:00:57.718750  9606 solver.cpp:218] Iteration 42300 (19.026 iter/s, 5.25597s/100 iters), loss = 0.10127
I1005 16:00:57.718786  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10127 (* 1 = 0.10127 loss)
I1005 16:00:57.718793  9606 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1005 16:01:02.966099  9606 solver.cpp:218] Iteration 42400 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.0702046
I1005 16:01:02.966127  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0702051 (* 1 = 0.0702051 loss)
I1005 16:01:02.966133  9606 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1005 16:01:07.965256  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:01:08.174389  9606 solver.cpp:330] Iteration 42500, Testing net (#0)
I1005 16:01:09.358847  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:01:09.408383  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I1005 16:01:09.408418  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288749 (* 1 = 0.288749 loss)
I1005 16:01:09.460943  9606 solver.cpp:218] Iteration 42500 (15.3969 iter/s, 6.4948s/100 iters), loss = 0.090335
I1005 16:01:09.460988  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0903354 (* 1 = 0.0903354 loss)
I1005 16:01:09.461005  9606 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1005 16:01:14.718806  9606 solver.cpp:218] Iteration 42600 (19.0193 iter/s, 5.2578s/100 iters), loss = 0.111006
I1005 16:01:14.718926  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111006 (* 1 = 0.111006 loss)
I1005 16:01:14.718935  9606 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1005 16:01:19.974007  9606 solver.cpp:218] Iteration 42700 (19.0292 iter/s, 5.25507s/100 iters), loss = 0.0831599
I1005 16:01:19.974037  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0831603 (* 1 = 0.0831603 loss)
I1005 16:01:19.974043  9606 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1005 16:01:25.223305  9606 solver.cpp:218] Iteration 42800 (19.0503 iter/s, 5.24925s/100 iters), loss = 0.0687136
I1005 16:01:25.223346  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068714 (* 1 = 0.068714 loss)
I1005 16:01:25.223361  9606 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1005 16:01:30.464570  9606 solver.cpp:218] Iteration 42900 (19.0796 iter/s, 5.24121s/100 iters), loss = 0.0516393
I1005 16:01:30.464612  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516397 (* 1 = 0.0516397 loss)
I1005 16:01:30.464618  9606 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1005 16:01:35.456655  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:01:35.666641  9606 solver.cpp:330] Iteration 43000, Testing net (#0)
I1005 16:01:36.862483  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:01:36.912122  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I1005 16:01:36.912147  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326652 (* 1 = 0.326652 loss)
I1005 16:01:36.964148  9606 solver.cpp:218] Iteration 43000 (15.3858 iter/s, 6.49952s/100 iters), loss = 0.0561552
I1005 16:01:36.964195  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561556 (* 1 = 0.0561556 loss)
I1005 16:01:36.964212  9606 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1005 16:01:42.214334  9606 solver.cpp:218] Iteration 43100 (19.0472 iter/s, 5.25012s/100 iters), loss = 0.153922
I1005 16:01:42.214375  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153922 (* 1 = 0.153922 loss)
I1005 16:01:42.214382  9606 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1005 16:01:47.469454  9606 solver.cpp:218] Iteration 43200 (19.0293 iter/s, 5.25506s/100 iters), loss = 0.091671
I1005 16:01:47.469624  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0916713 (* 1 = 0.0916713 loss)
I1005 16:01:47.469635  9606 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1005 16:01:52.723067  9606 solver.cpp:218] Iteration 43300 (19.0352 iter/s, 5.25343s/100 iters), loss = 0.106666
I1005 16:01:52.723098  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106666 (* 1 = 0.106666 loss)
I1005 16:01:52.723107  9606 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1005 16:01:57.979172  9606 solver.cpp:218] Iteration 43400 (19.0257 iter/s, 5.25606s/100 iters), loss = 0.0383829
I1005 16:01:57.979204  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383832 (* 1 = 0.0383832 loss)
I1005 16:01:57.979210  9606 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1005 16:02:02.962441  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:02:03.171682  9606 solver.cpp:330] Iteration 43500, Testing net (#0)
I1005 16:02:04.365762  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:02:04.415470  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I1005 16:02:04.415506  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296796 (* 1 = 0.296796 loss)
I1005 16:02:04.467669  9606 solver.cpp:218] Iteration 43500 (15.412 iter/s, 6.48844s/100 iters), loss = 0.0594999
I1005 16:02:04.467705  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0595002 (* 1 = 0.0595002 loss)
I1005 16:02:04.467711  9606 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1005 16:02:09.722409  9606 solver.cpp:218] Iteration 43600 (19.0306 iter/s, 5.25468s/100 iters), loss = 0.102107
I1005 16:02:09.722442  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102107 (* 1 = 0.102107 loss)
I1005 16:02:09.722450  9606 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1005 16:02:14.966784  9606 solver.cpp:218] Iteration 43700 (19.0682 iter/s, 5.24432s/100 iters), loss = 0.081996
I1005 16:02:14.966821  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0819963 (* 1 = 0.0819963 loss)
I1005 16:02:14.966827  9606 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1005 16:02:20.214668  9606 solver.cpp:218] Iteration 43800 (19.0555 iter/s, 5.24783s/100 iters), loss = 0.0549502
I1005 16:02:20.214774  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549505 (* 1 = 0.0549505 loss)
I1005 16:02:20.214782  9606 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1005 16:02:25.470397  9606 solver.cpp:218] Iteration 43900 (19.0273 iter/s, 5.25561s/100 iters), loss = 0.059955
I1005 16:02:25.470438  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0599554 (* 1 = 0.0599554 loss)
I1005 16:02:25.470444  9606 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1005 16:02:30.451354  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:02:30.668205  9606 solver.cpp:330] Iteration 44000, Testing net (#0)
I1005 16:02:31.855336  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:02:31.905236  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9072
I1005 16:02:31.905272  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291077 (* 1 = 0.291077 loss)
I1005 16:02:31.957568  9606 solver.cpp:218] Iteration 44000 (15.4152 iter/s, 6.48711s/100 iters), loss = 0.0426946
I1005 16:02:31.957594  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426949 (* 1 = 0.0426949 loss)
I1005 16:02:31.957602  9606 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1005 16:02:37.213683  9606 solver.cpp:218] Iteration 44100 (19.0256 iter/s, 5.25607s/100 iters), loss = 0.0940605
I1005 16:02:37.213723  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0940608 (* 1 = 0.0940608 loss)
I1005 16:02:37.213729  9606 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1005 16:02:42.463613  9606 solver.cpp:218] Iteration 44200 (19.0481 iter/s, 5.24987s/100 iters), loss = 0.0733208
I1005 16:02:42.463641  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0733212 (* 1 = 0.0733212 loss)
I1005 16:02:42.463647  9606 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1005 16:02:47.719564  9606 solver.cpp:218] Iteration 44300 (19.0262 iter/s, 5.25591s/100 iters), loss = 0.0959556
I1005 16:02:47.719594  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0959559 (* 1 = 0.0959559 loss)
I1005 16:02:47.719600  9606 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1005 16:02:52.975349  9606 solver.cpp:218] Iteration 44400 (19.0268 iter/s, 5.25574s/100 iters), loss = 0.0615918
I1005 16:02:52.975497  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615921 (* 1 = 0.0615921 loss)
I1005 16:02:52.975505  9606 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1005 16:02:57.967526  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:02:58.177078  9606 solver.cpp:330] Iteration 44500, Testing net (#0)
I1005 16:02:59.363760  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:02:59.413769  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1005 16:02:59.413805  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292915 (* 1 = 0.292915 loss)
I1005 16:02:59.466470  9606 solver.cpp:218] Iteration 44500 (15.406 iter/s, 6.49096s/100 iters), loss = 0.0642478
I1005 16:02:59.466495  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0642482 (* 1 = 0.0642482 loss)
I1005 16:02:59.466502  9606 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1005 16:03:04.720610  9606 solver.cpp:218] Iteration 44600 (19.0328 iter/s, 5.2541s/100 iters), loss = 0.0945045
I1005 16:03:04.720649  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0945049 (* 1 = 0.0945049 loss)
I1005 16:03:04.720656  9606 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1005 16:03:09.973381  9606 solver.cpp:218] Iteration 44700 (19.0378 iter/s, 5.25271s/100 iters), loss = 0.101593
I1005 16:03:09.973420  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101593 (* 1 = 0.101593 loss)
I1005 16:03:09.973428  9606 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1005 16:03:15.217831  9606 solver.cpp:218] Iteration 44800 (19.068 iter/s, 5.24439s/100 iters), loss = 0.0731128
I1005 16:03:15.217872  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0731131 (* 1 = 0.0731131 loss)
I1005 16:03:15.217880  9606 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1005 16:03:20.475343  9606 solver.cpp:218] Iteration 44900 (19.0206 iter/s, 5.25745s/100 iters), loss = 0.0771867
I1005 16:03:20.475394  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.077187 (* 1 = 0.077187 loss)
I1005 16:03:20.475400  9606 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1005 16:03:25.472378  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:03:25.682374  9606 solver.cpp:330] Iteration 45000, Testing net (#0)
I1005 16:03:26.867017  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:03:26.916620  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9059
I1005 16:03:26.916647  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296366 (* 1 = 0.296366 loss)
I1005 16:03:26.969013  9606 solver.cpp:218] Iteration 45000 (15.3998 iter/s, 6.49361s/100 iters), loss = 0.051164
I1005 16:03:26.969040  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511643 (* 1 = 0.0511643 loss)
I1005 16:03:26.969046  9606 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1005 16:03:32.227264  9606 solver.cpp:218] Iteration 45100 (19.0179 iter/s, 5.25821s/100 iters), loss = 0.081297
I1005 16:03:32.227293  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0812973 (* 1 = 0.0812973 loss)
I1005 16:03:32.227299  9606 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1005 16:03:37.484602  9606 solver.cpp:218] Iteration 45200 (19.0212 iter/s, 5.25729s/100 iters), loss = 0.110117
I1005 16:03:37.484632  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110117 (* 1 = 0.110117 loss)
I1005 16:03:37.484638  9606 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1005 16:03:42.725930  9606 solver.cpp:218] Iteration 45300 (19.0793 iter/s, 5.24128s/100 iters), loss = 0.0473993
I1005 16:03:42.725963  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473996 (* 1 = 0.0473996 loss)
I1005 16:03:42.725970  9606 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1005 16:03:47.974617  9606 solver.cpp:218] Iteration 45400 (19.0526 iter/s, 5.24863s/100 iters), loss = 0.0313359
I1005 16:03:47.974658  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313363 (* 1 = 0.0313363 loss)
I1005 16:03:47.974665  9606 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1005 16:03:52.967887  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:03:53.178449  9606 solver.cpp:330] Iteration 45500, Testing net (#0)
I1005 16:03:54.364704  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:03:54.414505  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I1005 16:03:54.414532  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313159 (* 1 = 0.313159 loss)
I1005 16:03:54.466801  9606 solver.cpp:218] Iteration 45500 (15.4033 iter/s, 6.49213s/100 iters), loss = 0.0629899
I1005 16:03:54.466827  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0629902 (* 1 = 0.0629902 loss)
I1005 16:03:54.466835  9606 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1005 16:03:59.720602  9606 solver.cpp:218] Iteration 45600 (19.034 iter/s, 5.25375s/100 iters), loss = 0.103608
I1005 16:03:59.720736  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103608 (* 1 = 0.103608 loss)
I1005 16:03:59.720753  9606 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1005 16:04:04.977924  9606 solver.cpp:218] Iteration 45700 (19.0216 iter/s, 5.25718s/100 iters), loss = 0.0770383
I1005 16:04:04.977957  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0770386 (* 1 = 0.0770386 loss)
I1005 16:04:04.977962  9606 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1005 16:04:10.235468  9606 solver.cpp:218] Iteration 45800 (19.0205 iter/s, 5.25749s/100 iters), loss = 0.0656705
I1005 16:04:10.235508  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0656708 (* 1 = 0.0656708 loss)
I1005 16:04:10.235514  9606 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1005 16:04:15.487051  9606 solver.cpp:218] Iteration 45900 (19.0421 iter/s, 5.25153s/100 iters), loss = 0.0513748
I1005 16:04:15.487085  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513752 (* 1 = 0.0513752 loss)
I1005 16:04:15.487092  9606 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1005 16:04:20.484704  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:04:20.694649  9606 solver.cpp:330] Iteration 46000, Testing net (#0)
I1005 16:04:21.889842  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:04:21.939712  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8971
I1005 16:04:21.939749  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331958 (* 1 = 0.331958 loss)
I1005 16:04:21.991919  9606 solver.cpp:218] Iteration 46000 (15.3732 iter/s, 6.50482s/100 iters), loss = 0.0302439
I1005 16:04:21.991950  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302442 (* 1 = 0.0302442 loss)
I1005 16:04:21.991956  9606 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1005 16:04:27.242453  9606 solver.cpp:218] Iteration 46100 (19.0459 iter/s, 5.25049s/100 iters), loss = 0.0417265
I1005 16:04:27.242485  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417269 (* 1 = 0.0417269 loss)
I1005 16:04:27.242491  9606 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1005 16:04:32.492280  9606 solver.cpp:218] Iteration 46200 (19.0484 iter/s, 5.24978s/100 iters), loss = 0.0711701
I1005 16:04:32.492460  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0711705 (* 1 = 0.0711705 loss)
I1005 16:04:32.492468  9606 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1005 16:04:37.748065  9606 solver.cpp:218] Iteration 46300 (19.0274 iter/s, 5.25559s/100 iters), loss = 0.0617171
I1005 16:04:37.748108  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0617174 (* 1 = 0.0617174 loss)
I1005 16:04:37.748114  9606 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1005 16:04:43.004813  9606 solver.cpp:218] Iteration 46400 (19.0234 iter/s, 5.25669s/100 iters), loss = 0.0873537
I1005 16:04:43.004843  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0873541 (* 1 = 0.0873541 loss)
I1005 16:04:43.004850  9606 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1005 16:04:47.992146  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:04:48.202245  9606 solver.cpp:330] Iteration 46500, Testing net (#0)
I1005 16:04:49.396757  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:04:49.446571  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9025
I1005 16:04:49.446596  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319967 (* 1 = 0.319967 loss)
I1005 16:04:49.498915  9606 solver.cpp:218] Iteration 46500 (15.3987 iter/s, 6.49406s/100 iters), loss = 0.0363041
I1005 16:04:49.498941  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363045 (* 1 = 0.0363045 loss)
I1005 16:04:49.498947  9606 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1005 16:04:54.757460  9606 solver.cpp:218] Iteration 46600 (19.0168 iter/s, 5.2585s/100 iters), loss = 0.0294957
I1005 16:04:54.757496  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294961 (* 1 = 0.0294961 loss)
I1005 16:04:54.757503  9606 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1005 16:05:00.001340  9606 solver.cpp:218] Iteration 46700 (19.0702 iter/s, 5.24379s/100 iters), loss = 0.0587417
I1005 16:05:00.001370  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0587421 (* 1 = 0.0587421 loss)
I1005 16:05:00.001375  9606 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1005 16:05:05.260284  9606 solver.cpp:218] Iteration 46800 (19.0154 iter/s, 5.25889s/100 iters), loss = 0.0490198
I1005 16:05:05.260429  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0490202 (* 1 = 0.0490202 loss)
I1005 16:05:05.260437  9606 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1005 16:05:10.520475  9606 solver.cpp:218] Iteration 46900 (19.0113 iter/s, 5.26004s/100 iters), loss = 0.0555705
I1005 16:05:10.520504  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0555709 (* 1 = 0.0555709 loss)
I1005 16:05:10.520510  9606 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1005 16:05:15.505604  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:05:15.719974  9606 solver.cpp:330] Iteration 47000, Testing net (#0)
I1005 16:05:16.907074  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:05:16.956559  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1005 16:05:16.956584  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319685 (* 1 = 0.319685 loss)
I1005 16:05:17.008780  9606 solver.cpp:218] Iteration 47000 (15.4125 iter/s, 6.48826s/100 iters), loss = 0.0602863
I1005 16:05:17.008805  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602867 (* 1 = 0.0602867 loss)
I1005 16:05:17.008822  9606 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1005 16:05:22.260354  9606 solver.cpp:218] Iteration 47100 (19.0421 iter/s, 5.25153s/100 iters), loss = 0.0726242
I1005 16:05:22.260385  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0726246 (* 1 = 0.0726246 loss)
I1005 16:05:22.260390  9606 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1005 16:05:27.502748  9606 solver.cpp:218] Iteration 47200 (19.0754 iter/s, 5.24234s/100 iters), loss = 0.0943425
I1005 16:05:27.502781  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0943429 (* 1 = 0.0943429 loss)
I1005 16:05:27.502799  9606 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1005 16:05:32.753759  9606 solver.cpp:218] Iteration 47300 (19.0441 iter/s, 5.25096s/100 iters), loss = 0.0577218
I1005 16:05:32.753788  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577222 (* 1 = 0.0577222 loss)
I1005 16:05:32.753794  9606 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1005 16:05:38.009462  9606 solver.cpp:218] Iteration 47400 (19.0271 iter/s, 5.25566s/100 iters), loss = 0.0483607
I1005 16:05:38.009569  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048361 (* 1 = 0.048361 loss)
I1005 16:05:38.009585  9606 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1005 16:05:43.006629  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:05:43.216364  9606 solver.cpp:330] Iteration 47500, Testing net (#0)
I1005 16:05:44.400773  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:05:44.450321  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1005 16:05:44.450356  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298765 (* 1 = 0.298765 loss)
I1005 16:05:44.502285  9606 solver.cpp:218] Iteration 47500 (15.4019 iter/s, 6.4927s/100 iters), loss = 0.0321627
I1005 16:05:44.502311  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321631 (* 1 = 0.0321631 loss)
I1005 16:05:44.502318  9606 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1005 16:05:49.762008  9606 solver.cpp:218] Iteration 47600 (19.0126 iter/s, 5.25968s/100 iters), loss = 0.118959
I1005 16:05:49.762051  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11896 (* 1 = 0.11896 loss)
I1005 16:05:49.762058  9606 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1005 16:05:55.020099  9606 solver.cpp:218] Iteration 47700 (19.0185 iter/s, 5.25803s/100 iters), loss = 0.118964
I1005 16:05:55.020140  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118964 (* 1 = 0.118964 loss)
I1005 16:05:55.020146  9606 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1005 16:06:00.265698  9606 solver.cpp:218] Iteration 47800 (19.0638 iter/s, 5.24554s/100 iters), loss = 0.0574113
I1005 16:06:00.265739  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574116 (* 1 = 0.0574116 loss)
I1005 16:06:00.265746  9606 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1005 16:06:05.518467  9606 solver.cpp:218] Iteration 47900 (19.0378 iter/s, 5.25271s/100 iters), loss = 0.0473702
I1005 16:06:05.518497  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473706 (* 1 = 0.0473706 loss)
I1005 16:06:05.518503  9606 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1005 16:06:10.505115  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:06:10.715386  9606 solver.cpp:330] Iteration 48000, Testing net (#0)
I1005 16:06:11.900209  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:06:11.949831  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I1005 16:06:11.949854  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322388 (* 1 = 0.322388 loss)
I1005 16:06:12.002079  9606 solver.cpp:218] Iteration 48000 (15.4236 iter/s, 6.48357s/100 iters), loss = 0.0262461
I1005 16:06:12.002107  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262464 (* 1 = 0.0262464 loss)
I1005 16:06:12.002113  9606 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1005 16:06:17.257995  9606 solver.cpp:218] Iteration 48100 (19.0263 iter/s, 5.25587s/100 iters), loss = 0.125712
I1005 16:06:17.258024  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125713 (* 1 = 0.125713 loss)
I1005 16:06:17.258030  9606 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1005 16:06:22.511289  9606 solver.cpp:218] Iteration 48200 (19.0358 iter/s, 5.25325s/100 iters), loss = 0.104802
I1005 16:06:22.511319  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104802 (* 1 = 0.104802 loss)
I1005 16:06:22.511325  9606 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1005 16:06:27.770076  9606 solver.cpp:218] Iteration 48300 (19.016 iter/s, 5.25874s/100 iters), loss = 0.0497942
I1005 16:06:27.770119  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497946 (* 1 = 0.0497946 loss)
I1005 16:06:27.770126  9606 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1005 16:06:33.022704  9606 solver.cpp:218] Iteration 48400 (19.0384 iter/s, 5.25254s/100 iters), loss = 0.0498667
I1005 16:06:33.022734  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0498671 (* 1 = 0.0498671 loss)
I1005 16:06:33.022740  9606 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1005 16:06:38.018882  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:06:38.228997  9606 solver.cpp:330] Iteration 48500, Testing net (#0)
I1005 16:06:39.416213  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:06:39.465595  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9062
I1005 16:06:39.465618  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315487 (* 1 = 0.315487 loss)
I1005 16:06:39.517873  9606 solver.cpp:218] Iteration 48500 (15.3962 iter/s, 6.49511s/100 iters), loss = 0.0295027
I1005 16:06:39.517935  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295031 (* 1 = 0.0295031 loss)
I1005 16:06:39.517942  9606 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1005 16:06:44.777945  9606 solver.cpp:218] Iteration 48600 (19.0115 iter/s, 5.25996s/100 iters), loss = 0.0862099
I1005 16:06:44.778105  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0862103 (* 1 = 0.0862103 loss)
I1005 16:06:44.778113  9606 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1005 16:06:50.035073  9606 solver.cpp:218] Iteration 48700 (19.0224 iter/s, 5.25695s/100 iters), loss = 0.0507781
I1005 16:06:50.035114  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0507785 (* 1 = 0.0507785 loss)
I1005 16:06:50.035120  9606 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1005 16:06:55.289187  9606 solver.cpp:218] Iteration 48800 (19.0329 iter/s, 5.25406s/100 iters), loss = 0.0690816
I1005 16:06:55.289216  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.069082 (* 1 = 0.069082 loss)
I1005 16:06:55.289222  9606 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1005 16:07:00.533427  9606 solver.cpp:218] Iteration 48900 (19.0687 iter/s, 5.24419s/100 iters), loss = 0.0589859
I1005 16:07:00.533468  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589862 (* 1 = 0.0589862 loss)
I1005 16:07:00.533475  9606 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1005 16:07:05.519491  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:07:05.729218  9606 solver.cpp:330] Iteration 49000, Testing net (#0)
I1005 16:07:06.920410  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:07:06.969439  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9044
I1005 16:07:06.969475  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308967 (* 1 = 0.308967 loss)
I1005 16:07:07.021679  9606 solver.cpp:218] Iteration 49000 (15.4127 iter/s, 6.48816s/100 iters), loss = 0.0383656
I1005 16:07:07.021709  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.038366 (* 1 = 0.038366 loss)
I1005 16:07:07.021716  9606 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1005 16:07:12.269810  9606 solver.cpp:218] Iteration 49100 (19.0546 iter/s, 5.24808s/100 iters), loss = 0.080523
I1005 16:07:12.269853  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805233 (* 1 = 0.0805233 loss)
I1005 16:07:12.269860  9606 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1005 16:07:17.520655  9606 solver.cpp:218] Iteration 49200 (19.0448 iter/s, 5.25079s/100 iters), loss = 0.0818754
I1005 16:07:17.520815  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0818757 (* 1 = 0.0818757 loss)
I1005 16:07:17.520823  9606 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1005 16:07:22.777894  9606 solver.cpp:218] Iteration 49300 (19.022 iter/s, 5.25706s/100 iters), loss = 0.0453167
I1005 16:07:22.777930  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045317 (* 1 = 0.045317 loss)
I1005 16:07:22.777937  9606 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1005 16:07:28.027230  9606 solver.cpp:218] Iteration 49400 (19.0502 iter/s, 5.24928s/100 iters), loss = 0.0569562
I1005 16:07:28.027261  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0569565 (* 1 = 0.0569565 loss)
I1005 16:07:28.027266  9606 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1005 16:07:33.006829  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:07:33.216807  9606 solver.cpp:330] Iteration 49500, Testing net (#0)
I1005 16:07:34.411278  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:07:34.461114  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9002
I1005 16:07:34.461151  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327148 (* 1 = 0.327148 loss)
I1005 16:07:34.513275  9606 solver.cpp:218] Iteration 49500 (15.4178 iter/s, 6.486s/100 iters), loss = 0.0363358
I1005 16:07:34.513301  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036336 (* 1 = 0.036336 loss)
I1005 16:07:34.513309  9606 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1005 16:07:39.768993  9606 solver.cpp:218] Iteration 49600 (19.0271 iter/s, 5.25567s/100 iters), loss = 0.0771732
I1005 16:07:39.769029  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0771734 (* 1 = 0.0771734 loss)
I1005 16:07:39.769037  9606 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1005 16:07:45.013036  9606 solver.cpp:218] Iteration 49700 (19.0694 iter/s, 5.24399s/100 iters), loss = 0.0499135
I1005 16:07:45.013075  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499137 (* 1 = 0.0499137 loss)
I1005 16:07:45.013082  9606 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1005 16:07:50.260270  9606 solver.cpp:218] Iteration 49800 (19.0579 iter/s, 5.24718s/100 iters), loss = 0.0240517
I1005 16:07:50.260406  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024052 (* 1 = 0.024052 loss)
I1005 16:07:50.260423  9606 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1005 16:07:55.511344  9606 solver.cpp:218] Iteration 49900 (19.0443 iter/s, 5.25092s/100 iters), loss = 0.0307076
I1005 16:07:55.511373  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307079 (* 1 = 0.0307079 loss)
I1005 16:07:55.511379  9606 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1005 16:08:00.497813  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:08:00.712841  9606 solver.cpp:330] Iteration 50000, Testing net (#0)
I1005 16:08:01.899592  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:08:01.949400  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I1005 16:08:01.949426  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335932 (* 1 = 0.335932 loss)
I1005 16:08:02.001852  9606 solver.cpp:218] Iteration 50000 (15.4072 iter/s, 6.49046s/100 iters), loss = 0.0312209
I1005 16:08:02.001880  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312212 (* 1 = 0.0312212 loss)
I1005 16:08:02.001886  9606 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1005 16:08:07.264274  9606 solver.cpp:218] Iteration 50100 (19.0028 iter/s, 5.26238s/100 iters), loss = 0.0823032
I1005 16:08:07.264318  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0823034 (* 1 = 0.0823034 loss)
I1005 16:08:07.264325  9606 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1005 16:08:12.510797  9606 solver.cpp:218] Iteration 50200 (19.0605 iter/s, 5.24646s/100 iters), loss = 0.0524141
I1005 16:08:12.510854  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0524144 (* 1 = 0.0524144 loss)
I1005 16:08:12.510860  9606 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1005 16:08:17.765954  9606 solver.cpp:218] Iteration 50300 (19.0292 iter/s, 5.25508s/100 iters), loss = 0.0574017
I1005 16:08:17.765987  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057402 (* 1 = 0.057402 loss)
I1005 16:08:17.766006  9606 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1005 16:08:23.022032  9606 solver.cpp:218] Iteration 50400 (19.0258 iter/s, 5.25603s/100 iters), loss = 0.0257173
I1005 16:08:23.022158  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257176 (* 1 = 0.0257176 loss)
I1005 16:08:23.022178  9606 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1005 16:08:28.015921  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:08:28.224704  9606 solver.cpp:330] Iteration 50500, Testing net (#0)
I1005 16:08:29.410405  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:08:29.460166  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8988
I1005 16:08:29.460199  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359111 (* 1 = 0.359111 loss)
I1005 16:08:29.512503  9606 solver.cpp:218] Iteration 50500 (15.4075 iter/s, 6.49034s/100 iters), loss = 0.0483985
I1005 16:08:29.512528  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483988 (* 1 = 0.0483988 loss)
I1005 16:08:29.512534  9606 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1005 16:08:34.764701  9606 solver.cpp:218] Iteration 50600 (19.0398 iter/s, 5.25215s/100 iters), loss = 0.123021
I1005 16:08:34.764731  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123022 (* 1 = 0.123022 loss)
I1005 16:08:34.764737  9606 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1005 16:08:40.014995  9606 solver.cpp:218] Iteration 50700 (19.0467 iter/s, 5.25024s/100 iters), loss = 0.0672921
I1005 16:08:40.015025  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0672923 (* 1 = 0.0672923 loss)
I1005 16:08:40.015033  9606 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1005 16:08:45.259111  9606 solver.cpp:218] Iteration 50800 (19.0692 iter/s, 5.24407s/100 iters), loss = 0.0555136
I1005 16:08:45.259152  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0555138 (* 1 = 0.0555138 loss)
I1005 16:08:45.259158  9606 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1005 16:08:50.512475  9606 solver.cpp:218] Iteration 50900 (19.0356 iter/s, 5.25331s/100 iters), loss = 0.0258472
I1005 16:08:50.512506  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258475 (* 1 = 0.0258475 loss)
I1005 16:08:50.512511  9606 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1005 16:08:55.500524  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:08:55.709583  9606 solver.cpp:330] Iteration 51000, Testing net (#0)
I1005 16:08:56.894076  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:08:56.943544  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I1005 16:08:56.943569  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357072 (* 1 = 0.357072 loss)
I1005 16:08:56.995905  9606 solver.cpp:218] Iteration 51000 (15.424 iter/s, 6.48339s/100 iters), loss = 0.0556248
I1005 16:08:56.995931  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055625 (* 1 = 0.055625 loss)
I1005 16:08:56.995950  9606 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1005 16:09:02.254683  9606 solver.cpp:218] Iteration 51100 (19.016 iter/s, 5.25873s/100 iters), loss = 0.0381735
I1005 16:09:02.254722  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381737 (* 1 = 0.0381737 loss)
I1005 16:09:02.254729  9606 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1005 16:09:07.510242  9606 solver.cpp:218] Iteration 51200 (19.0277 iter/s, 5.2555s/100 iters), loss = 0.0766946
I1005 16:09:07.510272  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0766948 (* 1 = 0.0766948 loss)
I1005 16:09:07.510277  9606 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1005 16:09:12.761054  9606 solver.cpp:218] Iteration 51300 (19.0449 iter/s, 5.25076s/100 iters), loss = 0.0242577
I1005 16:09:12.761087  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024258 (* 1 = 0.024258 loss)
I1005 16:09:12.761095  9606 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1005 16:09:18.001843  9606 solver.cpp:218] Iteration 51400 (19.0813 iter/s, 5.24074s/100 iters), loss = 0.0223131
I1005 16:09:18.001874  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223133 (* 1 = 0.0223133 loss)
I1005 16:09:18.001881  9606 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1005 16:09:22.988121  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:09:23.197918  9606 solver.cpp:330] Iteration 51500, Testing net (#0)
I1005 16:09:24.384660  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:09:24.434468  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I1005 16:09:24.434494  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322349 (* 1 = 0.322349 loss)
I1005 16:09:24.486613  9606 solver.cpp:218] Iteration 51500 (15.4209 iter/s, 6.48472s/100 iters), loss = 0.0254248
I1005 16:09:24.486652  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254251 (* 1 = 0.0254251 loss)
I1005 16:09:24.486660  9606 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1005 16:09:29.740972  9606 solver.cpp:218] Iteration 51600 (19.032 iter/s, 5.2543s/100 iters), loss = 0.0788085
I1005 16:09:29.741130  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0788088 (* 1 = 0.0788088 loss)
I1005 16:09:29.741137  9606 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1005 16:09:34.998859  9606 solver.cpp:218] Iteration 51700 (19.0197 iter/s, 5.25771s/100 iters), loss = 0.0445677
I1005 16:09:34.998899  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445679 (* 1 = 0.0445679 loss)
I1005 16:09:34.998905  9606 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1005 16:09:40.258635  9606 solver.cpp:218] Iteration 51800 (19.0124 iter/s, 5.25972s/100 iters), loss = 0.042031
I1005 16:09:40.258674  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420312 (* 1 = 0.0420312 loss)
I1005 16:09:40.258680  9606 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1005 16:09:45.508493  9606 solver.cpp:218] Iteration 51900 (19.0483 iter/s, 5.2498s/100 iters), loss = 0.032048
I1005 16:09:45.508523  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320483 (* 1 = 0.0320483 loss)
I1005 16:09:45.508529  9606 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1005 16:09:50.503554  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:09:50.713826  9606 solver.cpp:330] Iteration 52000, Testing net (#0)
I1005 16:09:51.909046  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:09:51.958405  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9001
I1005 16:09:51.958431  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350163 (* 1 = 0.350163 loss)
I1005 16:09:52.010681  9606 solver.cpp:218] Iteration 52000 (15.3795 iter/s, 6.50214s/100 iters), loss = 0.0562659
I1005 16:09:52.010712  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0562661 (* 1 = 0.0562661 loss)
I1005 16:09:52.010720  9606 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1005 16:09:57.259673  9606 solver.cpp:218] Iteration 52100 (19.0515 iter/s, 5.24894s/100 iters), loss = 0.0710385
I1005 16:09:57.259704  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0710387 (* 1 = 0.0710387 loss)
I1005 16:09:57.259721  9606 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1005 16:10:02.517431  9606 solver.cpp:218] Iteration 52200 (19.0197 iter/s, 5.25771s/100 iters), loss = 0.0476956
I1005 16:10:02.517804  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476958 (* 1 = 0.0476958 loss)
I1005 16:10:02.517854  9606 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1005 16:10:07.769130  9606 solver.cpp:218] Iteration 52300 (19.0429 iter/s, 5.25131s/100 iters), loss = 0.123606
I1005 16:10:07.769162  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123606 (* 1 = 0.123606 loss)
I1005 16:10:07.769170  9606 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1005 16:10:13.022557  9606 solver.cpp:218] Iteration 52400 (19.0355 iter/s, 5.25336s/100 iters), loss = 0.0291061
I1005 16:10:13.022589  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291063 (* 1 = 0.0291063 loss)
I1005 16:10:13.022596  9606 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1005 16:10:18.001646  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:10:18.211776  9606 solver.cpp:330] Iteration 52500, Testing net (#0)
I1005 16:10:19.403000  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:10:19.452728  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9001
I1005 16:10:19.452764  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353283 (* 1 = 0.353283 loss)
I1005 16:10:19.504956  9606 solver.cpp:218] Iteration 52500 (15.4265 iter/s, 6.48235s/100 iters), loss = 0.0624661
I1005 16:10:19.504981  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0624663 (* 1 = 0.0624663 loss)
I1005 16:10:19.504988  9606 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1005 16:10:24.761158  9606 solver.cpp:218] Iteration 52600 (19.0253 iter/s, 5.25616s/100 iters), loss = 0.0307985
I1005 16:10:24.761193  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307987 (* 1 = 0.0307987 loss)
I1005 16:10:24.761201  9606 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1005 16:10:30.008942  9606 solver.cpp:218] Iteration 52700 (19.0559 iter/s, 5.24773s/100 iters), loss = 0.0453097
I1005 16:10:30.008983  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453099 (* 1 = 0.0453099 loss)
I1005 16:10:30.008991  9606 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1005 16:10:35.269024  9606 solver.cpp:218] Iteration 52800 (19.0113 iter/s, 5.26003s/100 iters), loss = 0.0352858
I1005 16:10:35.269172  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352861 (* 1 = 0.0352861 loss)
I1005 16:10:35.269181  9606 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1005 16:10:40.525661  9606 solver.cpp:218] Iteration 52900 (19.0242 iter/s, 5.25647s/100 iters), loss = 0.00725265
I1005 16:10:40.525691  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725287 (* 1 = 0.00725287 loss)
I1005 16:10:40.525698  9606 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1005 16:10:45.510923  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:10:45.728710  9606 solver.cpp:330] Iteration 53000, Testing net (#0)
I1005 16:10:46.917209  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:10:46.966913  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I1005 16:10:46.966949  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367296 (* 1 = 0.367296 loss)
I1005 16:10:47.018985  9606 solver.cpp:218] Iteration 53000 (15.4005 iter/s, 6.49328s/100 iters), loss = 0.0226814
I1005 16:10:47.019012  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226816 (* 1 = 0.0226816 loss)
I1005 16:10:47.019019  9606 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1005 16:10:52.275419  9606 solver.cpp:218] Iteration 53100 (19.0245 iter/s, 5.25639s/100 iters), loss = 0.0937563
I1005 16:10:52.275449  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0937565 (* 1 = 0.0937565 loss)
I1005 16:10:52.275455  9606 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1005 16:10:57.517431  9606 solver.cpp:218] Iteration 53200 (19.0768 iter/s, 5.24196s/100 iters), loss = 0.0657371
I1005 16:10:57.517473  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0657373 (* 1 = 0.0657373 loss)
I1005 16:10:57.517479  9606 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1005 16:11:02.768410  9606 solver.cpp:218] Iteration 53300 (19.0443 iter/s, 5.25092s/100 iters), loss = 0.0378706
I1005 16:11:02.768441  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0378708 (* 1 = 0.0378708 loss)
I1005 16:11:02.768448  9606 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1005 16:11:08.021906  9606 solver.cpp:218] Iteration 53400 (19.0351 iter/s, 5.25345s/100 iters), loss = 0.0377897
I1005 16:11:08.022027  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377899 (* 1 = 0.0377899 loss)
I1005 16:11:08.022033  9606 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1005 16:11:13.014026  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:11:13.223544  9606 solver.cpp:330] Iteration 53500, Testing net (#0)
I1005 16:11:14.409883  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:11:14.459589  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I1005 16:11:14.459623  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344619 (* 1 = 0.344619 loss)
I1005 16:11:14.511765  9606 solver.cpp:218] Iteration 53500 (15.409 iter/s, 6.48973s/100 iters), loss = 0.0358445
I1005 16:11:14.511790  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358447 (* 1 = 0.0358447 loss)
I1005 16:11:14.511797  9606 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1005 16:11:19.767662  9606 solver.cpp:218] Iteration 53600 (19.0264 iter/s, 5.25585s/100 iters), loss = 0.0575288
I1005 16:11:19.767689  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057529 (* 1 = 0.057529 loss)
I1005 16:11:19.767695  9606 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1005 16:11:25.025107  9606 solver.cpp:218] Iteration 53700 (19.0208 iter/s, 5.2574s/100 iters), loss = 0.0730354
I1005 16:11:25.025137  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0730356 (* 1 = 0.0730356 loss)
I1005 16:11:25.025143  9606 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1005 16:11:30.270473  9606 solver.cpp:218] Iteration 53800 (19.0646 iter/s, 5.24532s/100 iters), loss = 0.0269505
I1005 16:11:30.270503  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269507 (* 1 = 0.0269507 loss)
I1005 16:11:30.270509  9606 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1005 16:11:35.523905  9606 solver.cpp:218] Iteration 53900 (19.0353 iter/s, 5.25339s/100 iters), loss = 0.0233555
I1005 16:11:35.523934  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233557 (* 1 = 0.0233557 loss)
I1005 16:11:35.523939  9606 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1005 16:11:40.513586  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:11:40.723830  9606 solver.cpp:330] Iteration 54000, Testing net (#0)
I1005 16:11:41.909692  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:11:41.959605  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8968
I1005 16:11:41.959631  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382414 (* 1 = 0.382414 loss)
I1005 16:11:42.011901  9606 solver.cpp:218] Iteration 54000 (15.4132 iter/s, 6.48795s/100 iters), loss = 0.0297216
I1005 16:11:42.011929  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297218 (* 1 = 0.0297218 loss)
I1005 16:11:42.011939  9606 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1005 16:11:47.269172  9606 solver.cpp:218] Iteration 54100 (19.0214 iter/s, 5.25723s/100 iters), loss = 0.0408883
I1005 16:11:47.269204  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408885 (* 1 = 0.0408885 loss)
I1005 16:11:47.269222  9606 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1005 16:11:52.522799  9606 solver.cpp:218] Iteration 54200 (19.0346 iter/s, 5.25358s/100 iters), loss = 0.0456981
I1005 16:11:52.522831  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456983 (* 1 = 0.0456983 loss)
I1005 16:11:52.522850  9606 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1005 16:11:57.770406  9606 solver.cpp:218] Iteration 54300 (19.0565 iter/s, 5.24756s/100 iters), loss = 0.0227875
I1005 16:11:57.770442  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227877 (* 1 = 0.0227877 loss)
I1005 16:11:57.770448  9606 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1005 16:12:03.018465  9606 solver.cpp:218] Iteration 54400 (19.0549 iter/s, 5.24801s/100 iters), loss = 0.0207213
I1005 16:12:03.018504  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207215 (* 1 = 0.0207215 loss)
I1005 16:12:03.018510  9606 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1005 16:12:08.010699  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:12:08.220294  9606 solver.cpp:330] Iteration 54500, Testing net (#0)
I1005 16:12:09.409059  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:12:09.458780  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8918
I1005 16:12:09.458806  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.386773 (* 1 = 0.386773 loss)
I1005 16:12:09.510946  9606 solver.cpp:218] Iteration 54500 (15.4026 iter/s, 6.49243s/100 iters), loss = 0.0406157
I1005 16:12:09.510973  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406159 (* 1 = 0.0406159 loss)
I1005 16:12:09.510980  9606 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1005 16:12:14.771026  9606 solver.cpp:218] Iteration 54600 (19.0113 iter/s, 5.26004s/100 iters), loss = 0.0880811
I1005 16:12:14.771134  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0880813 (* 1 = 0.0880813 loss)
I1005 16:12:14.771152  9606 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1005 16:12:20.025228  9606 solver.cpp:218] Iteration 54700 (19.0328 iter/s, 5.25408s/100 iters), loss = 0.0639002
I1005 16:12:20.025259  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0639004 (* 1 = 0.0639004 loss)
I1005 16:12:20.025275  9606 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1005 16:12:25.279911  9606 solver.cpp:218] Iteration 54800 (19.0308 iter/s, 5.25464s/100 iters), loss = 0.0792022
I1005 16:12:25.279940  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0792024 (* 1 = 0.0792024 loss)
I1005 16:12:25.279947  9606 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1005 16:12:30.526633  9606 solver.cpp:218] Iteration 54900 (19.0597 iter/s, 5.24668s/100 iters), loss = 0.0374398
I1005 16:12:30.526674  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03744 (* 1 = 0.03744 loss)
I1005 16:12:30.526680  9606 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1005 16:12:35.517624  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:12:35.726969  9606 solver.cpp:330] Iteration 55000, Testing net (#0)
I1005 16:12:36.918207  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:12:36.967768  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I1005 16:12:36.967804  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349277 (* 1 = 0.349277 loss)
I1005 16:12:37.020311  9606 solver.cpp:218] Iteration 55000 (15.3997 iter/s, 6.49362s/100 iters), loss = 0.0323143
I1005 16:12:37.020344  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323146 (* 1 = 0.0323146 loss)
I1005 16:12:37.020350  9606 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1005 16:12:42.266484  9606 solver.cpp:218] Iteration 55100 (19.0617 iter/s, 5.24613s/100 iters), loss = 0.0396179
I1005 16:12:42.266527  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396181 (* 1 = 0.0396181 loss)
I1005 16:12:42.266535  9606 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1005 16:12:47.521024  9606 solver.cpp:218] Iteration 55200 (19.0314 iter/s, 5.25448s/100 iters), loss = 0.0430508
I1005 16:12:47.521154  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043051 (* 1 = 0.043051 loss)
I1005 16:12:47.521162  9606 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1005 16:12:52.778556  9606 solver.cpp:218] Iteration 55300 (19.0208 iter/s, 5.2574s/100 iters), loss = 0.0261025
I1005 16:12:52.778596  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261028 (* 1 = 0.0261028 loss)
I1005 16:12:52.778602  9606 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1005 16:12:58.035259  9606 solver.cpp:218] Iteration 55400 (19.0235 iter/s, 5.25664s/100 iters), loss = 0.0139921
I1005 16:12:58.035290  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139923 (* 1 = 0.0139923 loss)
I1005 16:12:58.035295  9606 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1005 16:13:03.018121  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:13:03.228232  9606 solver.cpp:330] Iteration 55500, Testing net (#0)
I1005 16:13:04.424151  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:13:04.474031  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9025
I1005 16:13:04.474066  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355566 (* 1 = 0.355566 loss)
I1005 16:13:04.526535  9606 solver.cpp:218] Iteration 55500 (15.4054 iter/s, 6.49122s/100 iters), loss = 0.0110504
I1005 16:13:04.526561  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110506 (* 1 = 0.0110506 loss)
I1005 16:13:04.526567  9606 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1005 16:13:09.779300  9606 solver.cpp:218] Iteration 55600 (19.0378 iter/s, 5.25271s/100 iters), loss = 0.113578
I1005 16:13:09.779335  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113578 (* 1 = 0.113578 loss)
I1005 16:13:09.779342  9606 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1005 16:13:15.024847  9606 solver.cpp:218] Iteration 55700 (19.064 iter/s, 5.24549s/100 iters), loss = 0.0976433
I1005 16:13:15.024888  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0976435 (* 1 = 0.0976435 loss)
I1005 16:13:15.024893  9606 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1005 16:13:20.274395  9606 solver.cpp:218] Iteration 55800 (19.0495 iter/s, 5.24949s/100 iters), loss = 0.0543794
I1005 16:13:20.274513  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0543796 (* 1 = 0.0543796 loss)
I1005 16:13:20.274556  9606 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1005 16:13:25.528395  9606 solver.cpp:218] Iteration 55900 (19.0336 iter/s, 5.25387s/100 iters), loss = 0.0341738
I1005 16:13:25.528435  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034174 (* 1 = 0.034174 loss)
I1005 16:13:25.528441  9606 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1005 16:13:30.513211  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:13:30.727811  9606 solver.cpp:330] Iteration 56000, Testing net (#0)
I1005 16:13:31.916224  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:13:31.965960  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8979
I1005 16:13:31.965996  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377676 (* 1 = 0.377676 loss)
I1005 16:13:32.018035  9606 solver.cpp:218] Iteration 56000 (15.4093 iter/s, 6.48959s/100 iters), loss = 0.0233608
I1005 16:13:32.018061  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023361 (* 1 = 0.023361 loss)
I1005 16:13:32.018067  9606 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1005 16:13:37.274196  9606 solver.cpp:218] Iteration 56100 (19.0254 iter/s, 5.25612s/100 iters), loss = 0.0357109
I1005 16:13:37.274240  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357112 (* 1 = 0.0357112 loss)
I1005 16:13:37.274246  9606 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1005 16:13:42.517400  9606 solver.cpp:218] Iteration 56200 (19.0725 iter/s, 5.24314s/100 iters), loss = 0.0252045
I1005 16:13:42.517433  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252048 (* 1 = 0.0252048 loss)
I1005 16:13:42.517452  9606 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1005 16:13:47.776607  9606 solver.cpp:218] Iteration 56300 (19.0145 iter/s, 5.25916s/100 iters), loss = 0.0525188
I1005 16:13:47.776639  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.052519 (* 1 = 0.052519 loss)
I1005 16:13:47.776648  9606 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1005 16:13:53.036095  9606 solver.cpp:218] Iteration 56400 (19.0134 iter/s, 5.25944s/100 iters), loss = 0.0138706
I1005 16:13:53.036200  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138709 (* 1 = 0.0138709 loss)
I1005 16:13:53.036216  9606 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1005 16:13:58.029952  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:13:58.239313  9606 solver.cpp:330] Iteration 56500, Testing net (#0)
I1005 16:13:59.424548  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:13:59.474164  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8946
I1005 16:13:59.474200  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385094 (* 1 = 0.385094 loss)
I1005 16:13:59.526240  9606 solver.cpp:218] Iteration 56500 (15.4083 iter/s, 6.49002s/100 iters), loss = 0.0206922
I1005 16:13:59.526278  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206924 (* 1 = 0.0206924 loss)
I1005 16:13:59.526284  9606 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1005 16:14:04.785051  9606 solver.cpp:218] Iteration 56600 (19.0159 iter/s, 5.25875s/100 iters), loss = 0.0605944
I1005 16:14:04.785090  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0605946 (* 1 = 0.0605946 loss)
I1005 16:14:04.785096  9606 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1005 16:14:10.038286  9606 solver.cpp:218] Iteration 56700 (19.0361 iter/s, 5.25318s/100 iters), loss = 0.0769097
I1005 16:14:10.038328  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0769099 (* 1 = 0.0769099 loss)
I1005 16:14:10.038336  9606 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1005 16:14:15.284752  9606 solver.cpp:218] Iteration 56800 (19.0607 iter/s, 5.2464s/100 iters), loss = 0.048291
I1005 16:14:15.284783  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482913 (* 1 = 0.0482913 loss)
I1005 16:14:15.284790  9606 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1005 16:14:20.540467  9606 solver.cpp:218] Iteration 56900 (19.0271 iter/s, 5.25567s/100 iters), loss = 0.0634624
I1005 16:14:20.540508  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0634627 (* 1 = 0.0634627 loss)
I1005 16:14:20.540513  9606 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1005 16:14:25.533826  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:14:25.743748  9606 solver.cpp:330] Iteration 57000, Testing net (#0)
I1005 16:14:26.929529  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:14:26.978786  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9045
I1005 16:14:26.978821  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351313 (* 1 = 0.351313 loss)
I1005 16:14:27.031281  9606 solver.cpp:218] Iteration 57000 (15.4065 iter/s, 6.49076s/100 iters), loss = 0.0173598
I1005 16:14:27.031307  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173601 (* 1 = 0.0173601 loss)
I1005 16:14:27.031324  9606 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1005 16:14:32.287166  9606 solver.cpp:218] Iteration 57100 (19.0264 iter/s, 5.25584s/100 iters), loss = 0.011784
I1005 16:14:32.287206  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117842 (* 1 = 0.0117842 loss)
I1005 16:14:32.287212  9606 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1005 16:14:37.542587  9606 solver.cpp:218] Iteration 57200 (19.0282 iter/s, 5.25536s/100 iters), loss = 0.0311419
I1005 16:14:37.542628  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311422 (* 1 = 0.0311422 loss)
I1005 16:14:37.542634  9606 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1005 16:14:42.794715  9606 solver.cpp:218] Iteration 57300 (19.0401 iter/s, 5.25207s/100 iters), loss = 0.0892737
I1005 16:14:42.794750  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.089274 (* 1 = 0.089274 loss)
I1005 16:14:42.794757  9606 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1005 16:14:48.039481  9606 solver.cpp:218] Iteration 57400 (19.0668 iter/s, 5.24472s/100 iters), loss = 0.0247687
I1005 16:14:48.039511  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247689 (* 1 = 0.0247689 loss)
I1005 16:14:48.039517  9606 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1005 16:14:53.027127  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:14:53.236657  9606 solver.cpp:330] Iteration 57500, Testing net (#0)
I1005 16:14:54.423370  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:14:54.473315  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I1005 16:14:54.473342  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337497 (* 1 = 0.337497 loss)
I1005 16:14:54.525481  9606 solver.cpp:218] Iteration 57500 (15.4179 iter/s, 6.48596s/100 iters), loss = 0.0148569
I1005 16:14:54.525511  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148571 (* 1 = 0.0148571 loss)
I1005 16:14:54.525519  9606 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1005 16:14:59.780911  9606 solver.cpp:218] Iteration 57600 (19.0281 iter/s, 5.25538s/100 iters), loss = 0.0431973
I1005 16:14:59.781016  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0431975 (* 1 = 0.0431975 loss)
I1005 16:14:59.781038  9606 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1005 16:15:05.033674  9606 solver.cpp:218] Iteration 57700 (19.038 iter/s, 5.25265s/100 iters), loss = 0.0321754
I1005 16:15:05.033710  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321756 (* 1 = 0.0321756 loss)
I1005 16:15:05.033717  9606 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1005 16:15:10.286352  9606 solver.cpp:218] Iteration 57800 (19.0381 iter/s, 5.25263s/100 iters), loss = 0.0100045
I1005 16:15:10.286394  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100047 (* 1 = 0.0100047 loss)
I1005 16:15:10.286401  9606 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1005 16:15:15.531615  9606 solver.cpp:218] Iteration 57900 (19.065 iter/s, 5.24521s/100 iters), loss = 0.0395855
I1005 16:15:15.531656  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395856 (* 1 = 0.0395856 loss)
I1005 16:15:15.531662  9606 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1005 16:15:20.525164  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:15:20.734849  9606 solver.cpp:330] Iteration 58000, Testing net (#0)
I1005 16:15:21.931321  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:15:21.980942  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1005 16:15:21.980970  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353739 (* 1 = 0.353739 loss)
I1005 16:15:22.033083  9606 solver.cpp:218] Iteration 58000 (15.3813 iter/s, 6.50141s/100 iters), loss = 0.0185129
I1005 16:15:22.033114  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185131 (* 1 = 0.0185131 loss)
I1005 16:15:22.033123  9606 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1005 16:15:27.283105  9606 solver.cpp:218] Iteration 58100 (19.0477 iter/s, 5.24998s/100 iters), loss = 0.0167374
I1005 16:15:27.283138  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167376 (* 1 = 0.0167376 loss)
I1005 16:15:27.283148  9606 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1005 16:15:32.540402  9606 solver.cpp:218] Iteration 58200 (19.0214 iter/s, 5.25725s/100 iters), loss = 0.0284952
I1005 16:15:32.540544  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284954 (* 1 = 0.0284954 loss)
I1005 16:15:32.540582  9606 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1005 16:15:37.794184  9606 solver.cpp:218] Iteration 58300 (19.0345 iter/s, 5.25363s/100 iters), loss = 0.0301575
I1005 16:15:37.794217  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301578 (* 1 = 0.0301578 loss)
I1005 16:15:37.794224  9606 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1005 16:15:43.047315  9606 solver.cpp:218] Iteration 58400 (19.0365 iter/s, 5.25308s/100 iters), loss = 0.0263125
I1005 16:15:43.047348  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263127 (* 1 = 0.0263127 loss)
I1005 16:15:43.047358  9606 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1005 16:15:48.031625  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:15:48.241299  9606 solver.cpp:330] Iteration 58500, Testing net (#0)
I1005 16:15:49.431108  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:15:49.480767  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1005 16:15:49.480792  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376002 (* 1 = 0.376002 loss)
I1005 16:15:49.532872  9606 solver.cpp:218] Iteration 58500 (15.419 iter/s, 6.48551s/100 iters), loss = 0.0367548
I1005 16:15:49.532904  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367549 (* 1 = 0.0367549 loss)
I1005 16:15:49.532912  9606 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1005 16:15:54.782346  9606 solver.cpp:218] Iteration 58600 (19.0497 iter/s, 5.24942s/100 iters), loss = 0.0368306
I1005 16:15:54.782392  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368308 (* 1 = 0.0368308 loss)
I1005 16:15:54.782399  9606 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1005 16:16:00.030777  9606 solver.cpp:218] Iteration 58700 (19.0536 iter/s, 5.24834s/100 iters), loss = 0.0931354
I1005 16:16:00.030817  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0931356 (* 1 = 0.0931356 loss)
I1005 16:16:00.030823  9606 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1005 16:16:05.293278  9606 solver.cpp:218] Iteration 58800 (19.0026 iter/s, 5.26244s/100 iters), loss = 0.0567238
I1005 16:16:05.293419  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056724 (* 1 = 0.056724 loss)
I1005 16:16:05.293437  9606 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1005 16:16:10.550431  9606 solver.cpp:218] Iteration 58900 (19.0223 iter/s, 5.257s/100 iters), loss = 0.018337
I1005 16:16:10.550460  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183372 (* 1 = 0.0183372 loss)
I1005 16:16:10.550467  9606 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1005 16:16:15.536747  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:16:15.753545  9606 solver.cpp:330] Iteration 59000, Testing net (#0)
I1005 16:16:16.941709  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:16:16.990918  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I1005 16:16:16.990953  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365363 (* 1 = 0.365363 loss)
I1005 16:16:17.042973  9606 solver.cpp:218] Iteration 59000 (15.4024 iter/s, 6.49249s/100 iters), loss = 0.0164057
I1005 16:16:17.043009  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164058 (* 1 = 0.0164058 loss)
I1005 16:16:17.043015  9606 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1005 16:16:22.302109  9606 solver.cpp:218] Iteration 59100 (19.0147 iter/s, 5.25909s/100 iters), loss = 0.038896
I1005 16:16:22.302150  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388962 (* 1 = 0.0388962 loss)
I1005 16:16:22.302155  9606 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1005 16:16:27.549893  9606 solver.cpp:218] Iteration 59200 (19.0559 iter/s, 5.24772s/100 iters), loss = 0.0684243
I1005 16:16:27.549932  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0684245 (* 1 = 0.0684245 loss)
I1005 16:16:27.549938  9606 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1005 16:16:32.802707  9606 solver.cpp:218] Iteration 59300 (19.0376 iter/s, 5.25276s/100 iters), loss = 0.0212425
I1005 16:16:32.802748  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212427 (* 1 = 0.0212427 loss)
I1005 16:16:32.802754  9606 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1005 16:16:38.058468  9606 solver.cpp:218] Iteration 59400 (19.0269 iter/s, 5.2557s/100 iters), loss = 0.0231331
I1005 16:16:38.058601  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231333 (* 1 = 0.0231333 loss)
I1005 16:16:38.058620  9606 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1005 16:16:43.053289  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:16:43.263244  9606 solver.cpp:330] Iteration 59500, Testing net (#0)
I1005 16:16:44.450796  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:16:44.500524  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904
I1005 16:16:44.500558  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36218 (* 1 = 0.36218 loss)
I1005 16:16:44.552973  9606 solver.cpp:218] Iteration 59500 (15.398 iter/s, 6.49436s/100 iters), loss = 0.0168341
I1005 16:16:44.553000  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168343 (* 1 = 0.0168343 loss)
I1005 16:16:44.553007  9606 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1005 16:16:49.806818  9606 solver.cpp:218] Iteration 59600 (19.0338 iter/s, 5.2538s/100 iters), loss = 0.0123547
I1005 16:16:49.806859  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123549 (* 1 = 0.0123549 loss)
I1005 16:16:49.806864  9606 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1005 16:16:55.063217  9606 solver.cpp:218] Iteration 59700 (19.0246 iter/s, 5.25634s/100 iters), loss = 0.0700764
I1005 16:16:55.063248  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0700765 (* 1 = 0.0700765 loss)
I1005 16:16:55.063254  9606 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1005 16:17:00.310737  9606 solver.cpp:218] Iteration 59800 (19.0568 iter/s, 5.24747s/100 iters), loss = 0.0154689
I1005 16:17:00.310780  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015469 (* 1 = 0.015469 loss)
I1005 16:17:00.310786  9606 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1005 16:17:05.568488  9606 solver.cpp:218] Iteration 59900 (19.0197 iter/s, 5.25769s/100 iters), loss = 0.0232542
I1005 16:17:05.568529  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232544 (* 1 = 0.0232544 loss)
I1005 16:17:05.568536  9606 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1005 16:17:10.561295  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:17:10.770690  9606 solver.cpp:330] Iteration 60000, Testing net (#0)
I1005 16:17:11.956599  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:17:12.006302  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9044
I1005 16:17:12.006338  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371318 (* 1 = 0.371318 loss)
I1005 16:17:12.058748  9606 solver.cpp:218] Iteration 60000 (15.4078 iter/s, 6.49021s/100 iters), loss = 0.0149705
I1005 16:17:12.058776  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149707 (* 1 = 0.0149707 loss)
I1005 16:17:12.058784  9606 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1005 16:17:17.310686  9606 solver.cpp:218] Iteration 60100 (19.0407 iter/s, 5.2519s/100 iters), loss = 0.0201679
I1005 16:17:17.310716  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201681 (* 1 = 0.0201681 loss)
I1005 16:17:17.310721  9606 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1005 16:17:22.560840  9606 solver.cpp:218] Iteration 60200 (19.0472 iter/s, 5.25011s/100 iters), loss = 0.055285
I1005 16:17:22.560869  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552852 (* 1 = 0.0552852 loss)
I1005 16:17:22.560885  9606 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1005 16:17:27.810389  9606 solver.cpp:218] Iteration 60300 (19.0495 iter/s, 5.24949s/100 iters), loss = 0.0147991
I1005 16:17:27.810422  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147992 (* 1 = 0.0147992 loss)
I1005 16:17:27.810430  9606 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1005 16:17:33.057227  9606 solver.cpp:218] Iteration 60400 (19.0593 iter/s, 5.24679s/100 iters), loss = 0.0578346
I1005 16:17:33.057257  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0578348 (* 1 = 0.0578348 loss)
I1005 16:17:33.057263  9606 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1005 16:17:38.050871  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:17:38.260612  9606 solver.cpp:330] Iteration 60500, Testing net (#0)
I1005 16:17:39.447285  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:17:39.497198  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9003
I1005 16:17:39.497233  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382089 (* 1 = 0.382089 loss)
I1005 16:17:39.549685  9606 solver.cpp:218] Iteration 60500 (15.4026 iter/s, 6.49241s/100 iters), loss = 0.056069
I1005 16:17:39.549734  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560691 (* 1 = 0.0560691 loss)
I1005 16:17:39.549742  9606 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1005 16:17:44.805949  9606 solver.cpp:218] Iteration 60600 (19.0251 iter/s, 5.25621s/100 iters), loss = 0.0267544
I1005 16:17:44.806107  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267545 (* 1 = 0.0267545 loss)
I1005 16:17:44.806115  9606 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1005 16:17:50.064296  9606 solver.cpp:218] Iteration 60700 (19.018 iter/s, 5.25817s/100 iters), loss = 0.0238327
I1005 16:17:50.064327  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238329 (* 1 = 0.0238329 loss)
I1005 16:17:50.064332  9606 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1005 16:17:55.311640  9606 solver.cpp:218] Iteration 60800 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.0360313
I1005 16:17:55.311671  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360314 (* 1 = 0.0360314 loss)
I1005 16:17:55.311676  9606 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1005 16:18:00.563225  9606 solver.cpp:218] Iteration 60900 (19.042 iter/s, 5.25154s/100 iters), loss = 0.00626419
I1005 16:18:00.563256  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00626434 (* 1 = 0.00626434 loss)
I1005 16:18:00.563261  9606 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1005 16:18:05.557196  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:18:05.766973  9606 solver.cpp:330] Iteration 61000, Testing net (#0)
I1005 16:18:06.959491  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:18:07.009240  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I1005 16:18:07.009268  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403409 (* 1 = 0.403409 loss)
I1005 16:18:07.061569  9606 solver.cpp:218] Iteration 61000 (15.3886 iter/s, 6.4983s/100 iters), loss = 0.0454186
I1005 16:18:07.061609  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454187 (* 1 = 0.0454187 loss)
I1005 16:18:07.061620  9606 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1005 16:18:12.307143  9606 solver.cpp:218] Iteration 61100 (19.0639 iter/s, 5.24552s/100 iters), loss = 0.0115268
I1005 16:18:12.307195  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011527 (* 1 = 0.011527 loss)
I1005 16:18:12.307201  9606 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1005 16:18:17.559211  9606 solver.cpp:218] Iteration 61200 (19.0403 iter/s, 5.25201s/100 iters), loss = 0.0712009
I1005 16:18:17.559340  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.071201 (* 1 = 0.071201 loss)
I1005 16:18:17.559346  9606 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1005 16:18:22.808814  9606 solver.cpp:218] Iteration 61300 (19.0496 iter/s, 5.24946s/100 iters), loss = 0.0178129
I1005 16:18:22.808852  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017813 (* 1 = 0.017813 loss)
I1005 16:18:22.808858  9606 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1005 16:18:28.067703  9606 solver.cpp:218] Iteration 61400 (19.0156 iter/s, 5.25883s/100 iters), loss = 0.0195267
I1005 16:18:28.067744  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195268 (* 1 = 0.0195268 loss)
I1005 16:18:28.067750  9606 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1005 16:18:33.053459  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:18:33.263444  9606 solver.cpp:330] Iteration 61500, Testing net (#0)
I1005 16:18:34.458721  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:18:34.508594  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8988
I1005 16:18:34.508618  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389212 (* 1 = 0.389212 loss)
I1005 16:18:34.560976  9606 solver.cpp:218] Iteration 61500 (15.4007 iter/s, 6.49322s/100 iters), loss = 0.0131605
I1005 16:18:34.561002  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131606 (* 1 = 0.0131606 loss)
I1005 16:18:34.561009  9606 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1005 16:18:39.819320  9606 solver.cpp:218] Iteration 61600 (19.0176 iter/s, 5.2583s/100 iters), loss = 0.0484485
I1005 16:18:39.819365  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0484487 (* 1 = 0.0484487 loss)
I1005 16:18:39.819372  9606 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1005 16:18:45.070346  9606 solver.cpp:218] Iteration 61700 (19.0441 iter/s, 5.25096s/100 iters), loss = 0.0275139
I1005 16:18:45.070389  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027514 (* 1 = 0.027514 loss)
I1005 16:18:45.070394  9606 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1005 16:18:50.326217  9606 solver.cpp:218] Iteration 61800 (19.0265 iter/s, 5.25581s/100 iters), loss = 0.0285047
I1005 16:18:50.326339  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285048 (* 1 = 0.0285048 loss)
I1005 16:18:50.326346  9606 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1005 16:18:55.577762  9606 solver.cpp:218] Iteration 61900 (19.0425 iter/s, 5.25141s/100 iters), loss = 0.023255
I1005 16:18:55.577803  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232551 (* 1 = 0.0232551 loss)
I1005 16:18:55.577811  9606 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1005 16:19:00.564190  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:19:00.778965  9606 solver.cpp:330] Iteration 62000, Testing net (#0)
I1005 16:19:01.966406  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:19:02.015836  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I1005 16:19:02.015869  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35469 (* 1 = 0.35469 loss)
I1005 16:19:02.068325  9606 solver.cpp:218] Iteration 62000 (15.4071 iter/s, 6.49051s/100 iters), loss = 0.0145361
I1005 16:19:02.068351  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145362 (* 1 = 0.0145362 loss)
I1005 16:19:02.068358  9606 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1005 16:19:07.321385  9606 solver.cpp:218] Iteration 62100 (19.0367 iter/s, 5.25302s/100 iters), loss = 0.0332077
I1005 16:19:07.321415  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332078 (* 1 = 0.0332078 loss)
I1005 16:19:07.321422  9606 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1005 16:19:12.565044  9606 solver.cpp:218] Iteration 62200 (19.0708 iter/s, 5.24361s/100 iters), loss = 0.0537871
I1005 16:19:12.565076  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0537872 (* 1 = 0.0537872 loss)
I1005 16:19:12.565085  9606 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1005 16:19:17.822232  9606 solver.cpp:218] Iteration 62300 (19.0218 iter/s, 5.25714s/100 iters), loss = 0.0373577
I1005 16:19:17.822263  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0373578 (* 1 = 0.0373578 loss)
I1005 16:19:17.822283  9606 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1005 16:19:23.076853  9606 solver.cpp:218] Iteration 62400 (19.031 iter/s, 5.25457s/100 iters), loss = 0.0214556
I1005 16:19:23.076957  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214557 (* 1 = 0.0214557 loss)
I1005 16:19:23.076994  9606 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1005 16:19:28.071235  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:19:28.280849  9606 solver.cpp:330] Iteration 62500, Testing net (#0)
I1005 16:19:29.467667  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:19:29.517472  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I1005 16:19:29.517498  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346243 (* 1 = 0.346243 loss)
I1005 16:19:29.569591  9606 solver.cpp:218] Iteration 62500 (15.4021 iter/s, 6.49262s/100 iters), loss = 0.0163259
I1005 16:19:29.569619  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163261 (* 1 = 0.0163261 loss)
I1005 16:19:29.569628  9606 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1005 16:19:34.826653  9606 solver.cpp:218] Iteration 62600 (19.0222 iter/s, 5.25702s/100 iters), loss = 0.0359
I1005 16:19:34.826684  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359001 (* 1 = 0.0359001 loss)
I1005 16:19:34.826702  9606 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1005 16:19:40.080286  9606 solver.cpp:218] Iteration 62700 (19.0346 iter/s, 5.25358s/100 iters), loss = 0.0273467
I1005 16:19:40.080315  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273468 (* 1 = 0.0273468 loss)
I1005 16:19:40.080322  9606 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1005 16:19:45.323928  9606 solver.cpp:218] Iteration 62800 (19.0709 iter/s, 5.24359s/100 iters), loss = 0.0383313
I1005 16:19:45.323958  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383314 (* 1 = 0.0383314 loss)
I1005 16:19:45.323964  9606 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1005 16:19:50.577191  9606 solver.cpp:218] Iteration 62900 (19.036 iter/s, 5.25322s/100 iters), loss = 0.0126399
I1005 16:19:50.577232  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01264 (* 1 = 0.01264 loss)
I1005 16:19:50.577239  9606 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1005 16:19:55.566467  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:19:55.776063  9606 solver.cpp:330] Iteration 63000, Testing net (#0)
I1005 16:19:56.961586  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:19:57.011265  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9038
I1005 16:19:57.011298  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365661 (* 1 = 0.365661 loss)
I1005 16:19:57.063602  9606 solver.cpp:218] Iteration 63000 (15.417 iter/s, 6.48636s/100 iters), loss = 0.0343269
I1005 16:19:57.063627  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034327 (* 1 = 0.034327 loss)
I1005 16:19:57.063634  9606 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1005 16:20:02.321157  9606 solver.cpp:218] Iteration 63100 (19.0204 iter/s, 5.25751s/100 iters), loss = 0.0574218
I1005 16:20:02.321197  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057422 (* 1 = 0.057422 loss)
I1005 16:20:02.321203  9606 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1005 16:20:07.580538  9606 solver.cpp:218] Iteration 63200 (19.0139 iter/s, 5.25932s/100 iters), loss = 0.0413944
I1005 16:20:07.580569  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413945 (* 1 = 0.0413945 loss)
I1005 16:20:07.580574  9606 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1005 16:20:12.839059  9606 solver.cpp:218] Iteration 63300 (19.0169 iter/s, 5.25847s/100 iters), loss = 0.0620513
I1005 16:20:12.839097  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620514 (* 1 = 0.0620514 loss)
I1005 16:20:12.839103  9606 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1005 16:20:18.090867  9606 solver.cpp:218] Iteration 63400 (19.0414 iter/s, 5.25172s/100 iters), loss = 0.0125351
I1005 16:20:18.090898  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125352 (* 1 = 0.0125352 loss)
I1005 16:20:18.090914  9606 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1005 16:20:23.086815  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:20:23.296408  9606 solver.cpp:330] Iteration 63500, Testing net (#0)
I1005 16:20:24.483131  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:20:24.532793  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8912
I1005 16:20:24.532829  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.418803 (* 1 = 0.418803 loss)
I1005 16:20:24.585117  9606 solver.cpp:218] Iteration 63500 (15.3983 iter/s, 6.4942s/100 iters), loss = 0.029839
I1005 16:20:24.585150  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298391 (* 1 = 0.0298391 loss)
I1005 16:20:24.585157  9606 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1005 16:20:29.839020  9606 solver.cpp:218] Iteration 63600 (19.0336 iter/s, 5.25386s/100 iters), loss = 0.0181476
I1005 16:20:29.839125  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181477 (* 1 = 0.0181477 loss)
I1005 16:20:29.839143  9606 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1005 16:20:35.095391  9606 solver.cpp:218] Iteration 63700 (19.025 iter/s, 5.25625s/100 iters), loss = 0.0519021
I1005 16:20:35.095430  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519023 (* 1 = 0.0519023 loss)
I1005 16:20:35.095437  9606 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1005 16:20:40.347671  9606 solver.cpp:218] Iteration 63800 (19.0396 iter/s, 5.25222s/100 iters), loss = 0.0399824
I1005 16:20:40.347702  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399825 (* 1 = 0.0399825 loss)
I1005 16:20:40.347708  9606 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1005 16:20:45.595530  9606 solver.cpp:218] Iteration 63900 (19.0556 iter/s, 5.2478s/100 iters), loss = 0.0354557
I1005 16:20:45.595564  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354559 (* 1 = 0.0354559 loss)
I1005 16:20:45.595571  9606 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1005 16:20:50.588965  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:20:50.798872  9606 solver.cpp:330] Iteration 64000, Testing net (#0)
I1005 16:20:51.993021  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:20:52.042490  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I1005 16:20:52.042515  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367627 (* 1 = 0.367627 loss)
I1005 16:20:52.094802  9606 solver.cpp:218] Iteration 64000 (15.3865 iter/s, 6.49922s/100 iters), loss = 0.0180648
I1005 16:20:52.094840  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180649 (* 1 = 0.0180649 loss)
I1005 16:20:52.094857  9606 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1005 16:20:57.338805  9606 solver.cpp:218] Iteration 64100 (19.0696 iter/s, 5.24395s/100 iters), loss = 0.0209649
I1005 16:20:57.338835  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020965 (* 1 = 0.020965 loss)
I1005 16:20:57.338841  9606 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1005 16:21:02.597429  9606 solver.cpp:218] Iteration 64200 (19.0165 iter/s, 5.25858s/100 iters), loss = 0.0322303
I1005 16:21:02.597550  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322305 (* 1 = 0.0322305 loss)
I1005 16:21:02.597568  9606 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1005 16:21:07.852874  9606 solver.cpp:218] Iteration 64300 (19.0284 iter/s, 5.25531s/100 iters), loss = 0.0923747
I1005 16:21:07.852905  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0923748 (* 1 = 0.0923748 loss)
I1005 16:21:07.852921  9606 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1005 16:21:13.106705  9606 solver.cpp:218] Iteration 64400 (19.0339 iter/s, 5.25378s/100 iters), loss = 0.0303792
I1005 16:21:13.106737  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303794 (* 1 = 0.0303794 loss)
I1005 16:21:13.106745  9606 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1005 16:21:18.091131  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:21:18.300215  9606 solver.cpp:330] Iteration 64500, Testing net (#0)
I1005 16:21:19.491068  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:21:19.540815  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9046
I1005 16:21:19.540850  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366676 (* 1 = 0.366676 loss)
I1005 16:21:19.592972  9606 solver.cpp:218] Iteration 64500 (15.4173 iter/s, 6.48622s/100 iters), loss = 0.0724831
I1005 16:21:19.592996  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0724832 (* 1 = 0.0724832 loss)
I1005 16:21:19.593003  9606 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1005 16:21:24.847055  9606 solver.cpp:218] Iteration 64600 (19.033 iter/s, 5.25404s/100 iters), loss = 0.0541716
I1005 16:21:24.847091  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541718 (* 1 = 0.0541718 loss)
I1005 16:21:24.847100  9606 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1005 16:21:30.096783  9606 solver.cpp:218] Iteration 64700 (19.0488 iter/s, 5.24967s/100 iters), loss = 0.046173
I1005 16:21:30.096814  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461731 (* 1 = 0.0461731 loss)
I1005 16:21:30.096822  9606 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1005 16:21:35.351488  9606 solver.cpp:218] Iteration 64800 (19.0307 iter/s, 5.25466s/100 iters), loss = 0.0872033
I1005 16:21:35.351645  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0872034 (* 1 = 0.0872034 loss)
I1005 16:21:35.351653  9606 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1005 16:21:40.603572  9606 solver.cpp:218] Iteration 64900 (19.0406 iter/s, 5.25192s/100 iters), loss = 0.048563
I1005 16:21:40.603602  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485632 (* 1 = 0.0485632 loss)
I1005 16:21:40.603607  9606 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1005 16:21:45.585682  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:21:45.803643  9606 solver.cpp:330] Iteration 65000, Testing net (#0)
I1005 16:21:46.991911  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:21:47.041384  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I1005 16:21:47.041419  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42523 (* 1 = 0.42523 loss)
I1005 16:21:47.093943  9606 solver.cpp:218] Iteration 65000 (15.4075 iter/s, 6.49033s/100 iters), loss = 0.0506641
I1005 16:21:47.093968  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0506642 (* 1 = 0.0506642 loss)
I1005 16:21:47.093976  9606 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1005 16:21:52.352982  9606 solver.cpp:218] Iteration 65100 (19.0151 iter/s, 5.25899s/100 iters), loss = 0.0495821
I1005 16:21:52.353021  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0495823 (* 1 = 0.0495823 loss)
I1005 16:21:52.353029  9606 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1005 16:21:57.598788  9606 solver.cpp:218] Iteration 65200 (19.0631 iter/s, 5.24575s/100 iters), loss = 0.0602835
I1005 16:21:57.598829  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602837 (* 1 = 0.0602837 loss)
I1005 16:21:57.598834  9606 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1005 16:22:02.849534  9606 solver.cpp:218] Iteration 65300 (19.0451 iter/s, 5.25069s/100 iters), loss = 0.0118232
I1005 16:22:02.849565  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118234 (* 1 = 0.0118234 loss)
I1005 16:22:02.849583  9606 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1005 16:22:08.100517  9606 solver.cpp:218] Iteration 65400 (19.0442 iter/s, 5.25094s/100 iters), loss = 0.0150686
I1005 16:22:08.100668  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150688 (* 1 = 0.0150688 loss)
I1005 16:22:08.100679  9606 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1005 16:22:13.086508  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:22:13.296918  9606 solver.cpp:330] Iteration 65500, Testing net (#0)
I1005 16:22:14.483424  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:22:14.533095  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8961
I1005 16:22:14.533121  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424525 (* 1 = 0.424525 loss)
I1005 16:22:14.585170  9606 solver.cpp:218] Iteration 65500 (15.4214 iter/s, 6.48449s/100 iters), loss = 0.0223591
I1005 16:22:14.585201  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223593 (* 1 = 0.0223593 loss)
I1005 16:22:14.585209  9606 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1005 16:22:19.840135  9606 solver.cpp:218] Iteration 65600 (19.0298 iter/s, 5.25492s/100 iters), loss = 0.0517502
I1005 16:22:19.840169  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0517504 (* 1 = 0.0517504 loss)
I1005 16:22:19.840188  9606 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1005 16:22:25.097553  9606 solver.cpp:218] Iteration 65700 (19.0209 iter/s, 5.25737s/100 iters), loss = 0.0167846
I1005 16:22:25.097586  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167848 (* 1 = 0.0167848 loss)
I1005 16:22:25.097595  9606 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1005 16:22:30.343541  9606 solver.cpp:218] Iteration 65800 (19.0624 iter/s, 5.24594s/100 iters), loss = 0.0100365
I1005 16:22:30.343576  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100367 (* 1 = 0.0100367 loss)
I1005 16:22:30.343585  9606 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1005 16:22:35.601833  9606 solver.cpp:218] Iteration 65900 (19.0178 iter/s, 5.25824s/100 iters), loss = 0.0226836
I1005 16:22:35.601866  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226838 (* 1 = 0.0226838 loss)
I1005 16:22:35.601873  9606 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1005 16:22:40.590908  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:22:40.799410  9606 solver.cpp:330] Iteration 66000, Testing net (#0)
I1005 16:22:41.985692  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:22:42.035594  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.905
I1005 16:22:42.035620  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369823 (* 1 = 0.369823 loss)
I1005 16:22:42.087671  9606 solver.cpp:218] Iteration 66000 (15.4183 iter/s, 6.48579s/100 iters), loss = 0.0269894
I1005 16:22:42.087703  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269896 (* 1 = 0.0269896 loss)
I1005 16:22:42.087713  9606 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1005 16:22:47.349139  9606 solver.cpp:218] Iteration 66100 (19.0063 iter/s, 5.26143s/100 iters), loss = 0.0254046
I1005 16:22:47.349169  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254048 (* 1 = 0.0254048 loss)
I1005 16:22:47.349175  9606 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1005 16:22:52.606036  9606 solver.cpp:218] Iteration 66200 (19.0228 iter/s, 5.25685s/100 iters), loss = 0.00853441
I1005 16:22:52.606065  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00853458 (* 1 = 0.00853458 loss)
I1005 16:22:52.606071  9606 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1005 16:22:57.858208  9606 solver.cpp:218] Iteration 66300 (19.0399 iter/s, 5.25212s/100 iters), loss = 0.024895
I1005 16:22:57.858242  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248952 (* 1 = 0.0248952 loss)
I1005 16:22:57.858249  9606 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1005 16:23:03.104182  9606 solver.cpp:218] Iteration 66400 (19.0624 iter/s, 5.24592s/100 iters), loss = 0.00800447
I1005 16:23:03.104212  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00800465 (* 1 = 0.00800465 loss)
I1005 16:23:03.104228  9606 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1005 16:23:08.095295  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:23:08.305548  9606 solver.cpp:330] Iteration 66500, Testing net (#0)
I1005 16:23:09.492043  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:23:09.541836  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8964
I1005 16:23:09.541872  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406761 (* 1 = 0.406761 loss)
I1005 16:23:09.593999  9606 solver.cpp:218] Iteration 66500 (15.4089 iter/s, 6.48977s/100 iters), loss = 0.0134454
I1005 16:23:09.594025  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134455 (* 1 = 0.0134455 loss)
I1005 16:23:09.594032  9606 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1005 16:23:14.851253  9606 solver.cpp:218] Iteration 66600 (19.0215 iter/s, 5.25721s/100 iters), loss = 0.0961321
I1005 16:23:14.851400  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0961323 (* 1 = 0.0961323 loss)
I1005 16:23:14.851418  9606 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1005 16:23:20.110867  9606 solver.cpp:218] Iteration 66700 (19.0134 iter/s, 5.25946s/100 iters), loss = 0.0716119
I1005 16:23:20.110894  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.071612 (* 1 = 0.071612 loss)
I1005 16:23:20.110900  9606 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1005 16:23:25.367497  9606 solver.cpp:218] Iteration 66800 (19.0238 iter/s, 5.25659s/100 iters), loss = 0.0184212
I1005 16:23:25.367527  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184214 (* 1 = 0.0184214 loss)
I1005 16:23:25.367533  9606 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1005 16:23:30.611896  9606 solver.cpp:218] Iteration 66900 (19.0681 iter/s, 5.24435s/100 iters), loss = 0.0197974
I1005 16:23:30.611937  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197976 (* 1 = 0.0197976 loss)
I1005 16:23:30.611943  9606 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1005 16:23:35.600453  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:23:35.811132  9606 solver.cpp:330] Iteration 67000, Testing net (#0)
I1005 16:23:37.003108  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:23:37.052968  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9022
I1005 16:23:37.052994  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37319 (* 1 = 0.37319 loss)
I1005 16:23:37.105026  9606 solver.cpp:218] Iteration 67000 (15.401 iter/s, 6.49307s/100 iters), loss = 0.00855412
I1005 16:23:37.105058  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00855428 (* 1 = 0.00855428 loss)
I1005 16:23:37.105067  9606 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1005 16:23:42.344482  9606 solver.cpp:218] Iteration 67100 (19.0861 iter/s, 5.2394s/100 iters), loss = 0.0303874
I1005 16:23:42.344516  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303876 (* 1 = 0.0303876 loss)
I1005 16:23:42.344523  9606 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1005 16:23:47.594063  9606 solver.cpp:218] Iteration 67200 (19.0493 iter/s, 5.24953s/100 iters), loss = 0.0580221
I1005 16:23:47.594187  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580223 (* 1 = 0.0580223 loss)
I1005 16:23:47.594207  9606 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1005 16:23:52.845268  9606 solver.cpp:218] Iteration 67300 (19.0437 iter/s, 5.25107s/100 iters), loss = 0.0303869
I1005 16:23:52.845300  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030387 (* 1 = 0.030387 loss)
I1005 16:23:52.845309  9606 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1005 16:23:58.093739  9606 solver.cpp:218] Iteration 67400 (19.0533 iter/s, 5.24842s/100 iters), loss = 0.0351481
I1005 16:23:58.093770  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351482 (* 1 = 0.0351482 loss)
I1005 16:23:58.093777  9606 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1005 16:24:03.076297  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:24:03.286193  9606 solver.cpp:330] Iteration 67500, Testing net (#0)
I1005 16:24:04.479754  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:24:04.529680  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9014
I1005 16:24:04.529705  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383827 (* 1 = 0.383827 loss)
I1005 16:24:04.582170  9606 solver.cpp:218] Iteration 67500 (15.4122 iter/s, 6.48838s/100 iters), loss = 0.0215218
I1005 16:24:04.582202  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215219 (* 1 = 0.0215219 loss)
I1005 16:24:04.582209  9606 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1005 16:24:09.836161  9606 solver.cpp:218] Iteration 67600 (19.0333 iter/s, 5.25394s/100 iters), loss = 0.0117974
I1005 16:24:09.836201  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117975 (* 1 = 0.0117975 loss)
I1005 16:24:09.836220  9606 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1005 16:24:15.084276  9606 solver.cpp:218] Iteration 67700 (19.0548 iter/s, 5.24803s/100 iters), loss = 0.0223386
I1005 16:24:15.084317  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223387 (* 1 = 0.0223387 loss)
I1005 16:24:15.084323  9606 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1005 16:24:20.339431  9606 solver.cpp:218] Iteration 67800 (19.0291 iter/s, 5.2551s/100 iters), loss = 0.0307412
I1005 16:24:20.339566  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307414 (* 1 = 0.0307414 loss)
I1005 16:24:20.339584  9606 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1005 16:24:25.597625  9606 solver.cpp:218] Iteration 67900 (19.0185 iter/s, 5.25804s/100 iters), loss = 0.00963696
I1005 16:24:25.597654  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00963714 (* 1 = 0.00963714 loss)
I1005 16:24:25.597671  9606 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1005 16:24:30.582648  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:24:30.795783  9606 solver.cpp:330] Iteration 68000, Testing net (#0)
I1005 16:24:31.984254  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:24:32.033896  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8984
I1005 16:24:32.033921  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.390074 (* 1 = 0.390074 loss)
I1005 16:24:32.086380  9606 solver.cpp:218] Iteration 68000 (15.4114 iter/s, 6.48871s/100 iters), loss = 0.00868899
I1005 16:24:32.086405  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868917 (* 1 = 0.00868917 loss)
I1005 16:24:32.086411  9606 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1005 16:24:37.343637  9606 solver.cpp:218] Iteration 68100 (19.0215 iter/s, 5.25721s/100 iters), loss = 0.0194948
I1005 16:24:37.343667  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194949 (* 1 = 0.0194949 loss)
I1005 16:24:37.343672  9606 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1005 16:24:42.591537  9606 solver.cpp:218] Iteration 68200 (19.0554 iter/s, 5.24785s/100 iters), loss = 0.0601323
I1005 16:24:42.591567  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0601325 (* 1 = 0.0601325 loss)
I1005 16:24:42.591583  9606 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1005 16:24:47.847121  9606 solver.cpp:218] Iteration 68300 (19.0276 iter/s, 5.25554s/100 iters), loss = 0.023547
I1005 16:24:47.847156  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235472 (* 1 = 0.0235472 loss)
I1005 16:24:47.847172  9606 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1005 16:24:53.103435  9606 solver.cpp:218] Iteration 68400 (19.0249 iter/s, 5.25627s/100 iters), loss = 0.0396912
I1005 16:24:53.103572  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396913 (* 1 = 0.0396913 loss)
I1005 16:24:53.103579  9606 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1005 16:24:58.097847  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:24:58.307762  9606 solver.cpp:330] Iteration 68500, Testing net (#0)
I1005 16:24:59.494377  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:24:59.543572  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8983
I1005 16:24:59.543607  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387525 (* 1 = 0.387525 loss)
I1005 16:24:59.595930  9606 solver.cpp:218] Iteration 68500 (15.4027 iter/s, 6.49235s/100 iters), loss = 0.0251275
I1005 16:24:59.595955  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251276 (* 1 = 0.0251276 loss)
I1005 16:24:59.595963  9606 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1005 16:25:04.855453  9606 solver.cpp:218] Iteration 68600 (19.0133 iter/s, 5.25948s/100 iters), loss = 0.0292908
I1005 16:25:04.855481  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292909 (* 1 = 0.0292909 loss)
I1005 16:25:04.855497  9606 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1005 16:25:10.114073  9606 solver.cpp:218] Iteration 68700 (19.0166 iter/s, 5.25857s/100 iters), loss = 0.0336929
I1005 16:25:10.114102  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336931 (* 1 = 0.0336931 loss)
I1005 16:25:10.114109  9606 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1005 16:25:15.358562  9606 solver.cpp:218] Iteration 68800 (19.0678 iter/s, 5.24444s/100 iters), loss = 0.0402628
I1005 16:25:15.358604  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040263 (* 1 = 0.040263 loss)
I1005 16:25:15.358611  9606 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1005 16:25:20.606637  9606 solver.cpp:218] Iteration 68900 (19.0548 iter/s, 5.24801s/100 iters), loss = 0.0212926
I1005 16:25:20.606690  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212928 (* 1 = 0.0212928 loss)
I1005 16:25:20.606705  9606 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1005 16:25:25.594765  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:25:25.804978  9606 solver.cpp:330] Iteration 69000, Testing net (#0)
I1005 16:25:26.988976  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:25:27.038313  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8867
I1005 16:25:27.038336  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.445009 (* 1 = 0.445009 loss)
I1005 16:25:27.090514  9606 solver.cpp:218] Iteration 69000 (15.423 iter/s, 6.48381s/100 iters), loss = 0.0614298
I1005 16:25:27.090545  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.06143 (* 1 = 0.06143 loss)
I1005 16:25:27.090553  9606 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1005 16:25:32.342963  9606 solver.cpp:218] Iteration 69100 (19.0389 iter/s, 5.2524s/100 iters), loss = 0.0853489
I1005 16:25:32.343011  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0853491 (* 1 = 0.0853491 loss)
I1005 16:25:32.343017  9606 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1005 16:25:37.599349  9606 solver.cpp:218] Iteration 69200 (19.0247 iter/s, 5.25632s/100 iters), loss = 0.0149653
I1005 16:25:37.599380  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149655 (* 1 = 0.0149655 loss)
I1005 16:25:37.599395  9606 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1005 16:25:42.858976  9606 solver.cpp:218] Iteration 69300 (19.0129 iter/s, 5.25958s/100 iters), loss = 0.0123316
I1005 16:25:42.859011  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123318 (* 1 = 0.0123318 loss)
I1005 16:25:42.859019  9606 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1005 16:25:48.114198  9606 solver.cpp:218] Iteration 69400 (19.029 iter/s, 5.25514s/100 iters), loss = 0.00883449
I1005 16:25:48.114228  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00883467 (* 1 = 0.00883467 loss)
I1005 16:25:48.114244  9606 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1005 16:25:53.111641  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:25:53.320680  9606 solver.cpp:330] Iteration 69500, Testing net (#0)
I1005 16:25:54.507593  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:25:54.557699  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I1005 16:25:54.557734  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.429943 (* 1 = 0.429943 loss)
I1005 16:25:54.609905  9606 solver.cpp:218] Iteration 69500 (15.3949 iter/s, 6.49566s/100 iters), loss = 0.0110327
I1005 16:25:54.609935  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110329 (* 1 = 0.0110329 loss)
I1005 16:25:54.609942  9606 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1005 16:25:59.864500  9606 solver.cpp:218] Iteration 69600 (19.0311 iter/s, 5.25455s/100 iters), loss = 0.00587472
I1005 16:25:59.864647  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00587488 (* 1 = 0.00587488 loss)
I1005 16:25:59.864665  9606 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1005 16:26:05.116485  9606 solver.cpp:218] Iteration 69700 (19.041 iter/s, 5.25182s/100 iters), loss = 0.032553
I1005 16:26:05.116528  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325532 (* 1 = 0.0325532 loss)
I1005 16:26:05.116534  9606 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1005 16:26:10.367897  9606 solver.cpp:218] Iteration 69800 (19.0427 iter/s, 5.25135s/100 iters), loss = 0.028205
I1005 16:26:10.367929  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282052 (* 1 = 0.0282052 loss)
I1005 16:26:10.367938  9606 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1005 16:26:15.612380  9606 solver.cpp:218] Iteration 69900 (19.0678 iter/s, 5.24443s/100 iters), loss = 0.019695
I1005 16:26:15.612414  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196952 (* 1 = 0.0196952 loss)
I1005 16:26:15.612432  9606 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1005 16:26:20.602607  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:26:20.812407  9606 solver.cpp:330] Iteration 70000, Testing net (#0)
I1005 16:26:22.006657  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:26:22.056486  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.902
I1005 16:26:22.056522  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381609 (* 1 = 0.381609 loss)
I1005 16:26:22.108898  9606 solver.cpp:218] Iteration 70000 (15.393 iter/s, 6.49646s/100 iters), loss = 0.0381993
I1005 16:26:22.108929  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381995 (* 1 = 0.0381995 loss)
I1005 16:26:22.108937  9606 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1005 16:26:27.357069  9606 solver.cpp:218] Iteration 70100 (19.0544 iter/s, 5.24812s/100 iters), loss = 0.0620321
I1005 16:26:27.357100  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620323 (* 1 = 0.0620323 loss)
I1005 16:26:27.357106  9606 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1005 16:26:32.617344  9606 solver.cpp:218] Iteration 70200 (19.0106 iter/s, 5.26023s/100 iters), loss = 0.0234333
I1005 16:26:32.617462  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234335 (* 1 = 0.0234335 loss)
I1005 16:26:32.617478  9606 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1005 16:26:37.876626  9606 solver.cpp:218] Iteration 70300 (19.0145 iter/s, 5.25916s/100 iters), loss = 0.0358381
I1005 16:26:37.876672  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358383 (* 1 = 0.0358383 loss)
I1005 16:26:37.876678  9606 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1005 16:26:43.138489  9606 solver.cpp:218] Iteration 70400 (19.0049 iter/s, 5.2618s/100 iters), loss = 0.0518554
I1005 16:26:43.138521  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518556 (* 1 = 0.0518556 loss)
I1005 16:26:43.138530  9606 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1005 16:26:48.124030  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:26:48.334060  9606 solver.cpp:330] Iteration 70500, Testing net (#0)
I1005 16:26:49.531745  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:26:49.581611  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I1005 16:26:49.581646  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3693 (* 1 = 0.3693 loss)
I1005 16:26:49.634091  9606 solver.cpp:218] Iteration 70500 (15.3951 iter/s, 6.49556s/100 iters), loss = 0.0410497
I1005 16:26:49.634117  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410499 (* 1 = 0.0410499 loss)
I1005 16:26:49.634124  9606 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1005 16:26:54.882647  9606 solver.cpp:218] Iteration 70600 (19.053 iter/s, 5.24851s/100 iters), loss = 0.0159847
I1005 16:26:54.882683  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159849 (* 1 = 0.0159849 loss)
I1005 16:26:54.882689  9606 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1005 16:27:00.125259  9606 solver.cpp:218] Iteration 70700 (19.0747 iter/s, 5.24256s/100 iters), loss = 0.0162724
I1005 16:27:00.125288  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162725 (* 1 = 0.0162725 loss)
I1005 16:27:00.125294  9606 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1005 16:27:05.381691  9606 solver.cpp:218] Iteration 70800 (19.0245 iter/s, 5.25638s/100 iters), loss = 0.0170091
I1005 16:27:05.381868  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170093 (* 1 = 0.0170093 loss)
I1005 16:27:05.381876  9606 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1005 16:27:10.637147  9606 solver.cpp:218] Iteration 70900 (19.0285 iter/s, 5.25528s/100 iters), loss = 0.0205858
I1005 16:27:10.637187  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205859 (* 1 = 0.0205859 loss)
I1005 16:27:10.637193  9606 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1005 16:27:15.624855  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:27:15.841274  9606 solver.cpp:330] Iteration 71000, Testing net (#0)
I1005 16:27:17.028895  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:27:17.078490  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.89
I1005 16:27:17.078527  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.436092 (* 1 = 0.436092 loss)
I1005 16:27:17.131016  9606 solver.cpp:218] Iteration 71000 (15.3993 iter/s, 6.49381s/100 iters), loss = 0.0325834
I1005 16:27:17.131048  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325836 (* 1 = 0.0325836 loss)
I1005 16:27:17.131055  9606 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1005 16:27:22.390843  9606 solver.cpp:218] Iteration 71100 (19.0122 iter/s, 5.25978s/100 iters), loss = 0.0284532
I1005 16:27:22.390883  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284534 (* 1 = 0.0284534 loss)
I1005 16:27:22.390889  9606 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1005 16:27:27.638422  9606 solver.cpp:218] Iteration 71200 (19.0566 iter/s, 5.24752s/100 iters), loss = 0.00914738
I1005 16:27:27.638458  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914754 (* 1 = 0.00914754 loss)
I1005 16:27:27.638476  9606 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1005 16:27:32.895829  9606 solver.cpp:218] Iteration 71300 (19.021 iter/s, 5.25736s/100 iters), loss = 0.0644035
I1005 16:27:32.895864  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644037 (* 1 = 0.0644037 loss)
I1005 16:27:32.895881  9606 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1005 16:27:38.152806  9606 solver.cpp:218] Iteration 71400 (19.0225 iter/s, 5.25693s/100 iters), loss = 0.0116418
I1005 16:27:38.152921  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116419 (* 1 = 0.0116419 loss)
I1005 16:27:38.152930  9606 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1005 16:27:43.144577  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:27:43.354638  9606 solver.cpp:330] Iteration 71500, Testing net (#0)
I1005 16:27:44.541666  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:27:44.591410  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8935
I1005 16:27:44.591435  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422086 (* 1 = 0.422086 loss)
I1005 16:27:44.643126  9606 solver.cpp:218] Iteration 71500 (15.4078 iter/s, 6.4902s/100 iters), loss = 0.0101722
I1005 16:27:44.643151  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101724 (* 1 = 0.0101724 loss)
I1005 16:27:44.643157  9606 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1005 16:27:49.896734  9606 solver.cpp:218] Iteration 71600 (19.0347 iter/s, 5.25357s/100 iters), loss = 0.0368744
I1005 16:27:49.896775  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368746 (* 1 = 0.0368746 loss)
I1005 16:27:49.896780  9606 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1005 16:27:55.151729  9606 solver.cpp:218] Iteration 71700 (19.0297 iter/s, 5.25494s/100 iters), loss = 0.0432159
I1005 16:27:55.151760  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432161 (* 1 = 0.0432161 loss)
I1005 16:27:55.151769  9606 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1005 16:28:00.400102  9606 solver.cpp:218] Iteration 71800 (19.0537 iter/s, 5.24833s/100 iters), loss = 0.00823229
I1005 16:28:00.400132  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823246 (* 1 = 0.00823246 loss)
I1005 16:28:00.400141  9606 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1005 16:28:05.661038  9606 solver.cpp:218] Iteration 71900 (19.0082 iter/s, 5.26088s/100 iters), loss = 0.0674224
I1005 16:28:05.661069  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0674226 (* 1 = 0.0674226 loss)
I1005 16:28:05.661077  9606 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1005 16:28:10.657332  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:28:10.866291  9606 solver.cpp:330] Iteration 72000, Testing net (#0)
I1005 16:28:12.051219  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:28:12.100965  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8961
I1005 16:28:12.100988  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.430193 (* 1 = 0.430193 loss)
I1005 16:28:12.153096  9606 solver.cpp:218] Iteration 72000 (15.4035 iter/s, 6.49201s/100 iters), loss = 0.0262635
I1005 16:28:12.153125  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262637 (* 1 = 0.0262637 loss)
I1005 16:28:12.153131  9606 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1005 16:28:17.412534  9606 solver.cpp:218] Iteration 72100 (19.0136 iter/s, 5.25939s/100 iters), loss = 0.041655
I1005 16:28:17.412575  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416551 (* 1 = 0.0416551 loss)
I1005 16:28:17.412580  9606 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1005 16:28:22.669426  9606 solver.cpp:218] Iteration 72200 (19.0229 iter/s, 5.25683s/100 iters), loss = 0.0350756
I1005 16:28:22.669466  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350758 (* 1 = 0.0350758 loss)
I1005 16:28:22.669472  9606 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1005 16:28:27.924934  9606 solver.cpp:218] Iteration 72300 (19.0279 iter/s, 5.25545s/100 iters), loss = 0.0107341
I1005 16:28:27.924968  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107343 (* 1 = 0.0107343 loss)
I1005 16:28:27.924986  9606 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1005 16:28:33.172591  9606 solver.cpp:218] Iteration 72400 (19.0564 iter/s, 5.24757s/100 iters), loss = 0.0433322
I1005 16:28:33.172621  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433324 (* 1 = 0.0433324 loss)
I1005 16:28:33.172636  9606 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1005 16:28:38.163310  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:28:38.373167  9606 solver.cpp:330] Iteration 72500, Testing net (#0)
I1005 16:28:39.559422  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:28:39.608743  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1005 16:28:39.608779  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387204 (* 1 = 0.387204 loss)
I1005 16:28:39.661381  9606 solver.cpp:218] Iteration 72500 (15.4113 iter/s, 6.48874s/100 iters), loss = 0.0255429
I1005 16:28:39.661427  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255431 (* 1 = 0.0255431 loss)
I1005 16:28:39.661433  9606 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1005 16:28:44.916376  9606 solver.cpp:218] Iteration 72600 (19.0299 iter/s, 5.25489s/100 iters), loss = 0.020576
I1005 16:28:44.916514  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205762 (* 1 = 0.0205762 loss)
I1005 16:28:44.916522  9606 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1005 16:28:50.172878  9606 solver.cpp:218] Iteration 72700 (19.0246 iter/s, 5.25635s/100 iters), loss = 0.0417977
I1005 16:28:50.172909  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417979 (* 1 = 0.0417979 loss)
I1005 16:28:50.172914  9606 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1005 16:28:55.413847  9606 solver.cpp:218] Iteration 72800 (19.0806 iter/s, 5.24092s/100 iters), loss = 0.0146637
I1005 16:28:55.413888  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146639 (* 1 = 0.0146639 loss)
I1005 16:28:55.413906  9606 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1005 16:29:00.660217  9606 solver.cpp:218] Iteration 72900 (19.061 iter/s, 5.24631s/100 iters), loss = 0.00493846
I1005 16:29:00.660248  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493867 (* 1 = 0.00493867 loss)
I1005 16:29:00.660255  9606 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1005 16:29:05.656857  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:29:05.867103  9606 solver.cpp:330] Iteration 73000, Testing net (#0)
I1005 16:29:07.060863  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:29:07.110728  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9026
I1005 16:29:07.110762  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389478 (* 1 = 0.389478 loss)
I1005 16:29:07.162802  9606 solver.cpp:218] Iteration 73000 (15.3786 iter/s, 6.50253s/100 iters), loss = 0.0081004
I1005 16:29:07.162833  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810062 (* 1 = 0.00810062 loss)
I1005 16:29:07.162840  9606 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1005 16:29:12.414002  9606 solver.cpp:218] Iteration 73100 (19.0435 iter/s, 5.25115s/100 iters), loss = 0.0325427
I1005 16:29:12.414043  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032543 (* 1 = 0.032543 loss)
I1005 16:29:12.414050  9606 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1005 16:29:17.669340  9606 solver.cpp:218] Iteration 73200 (19.0285 iter/s, 5.25528s/100 iters), loss = 0.0287083
I1005 16:29:17.669450  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287085 (* 1 = 0.0287085 loss)
I1005 16:29:17.669457  9606 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1005 16:29:22.923195  9606 solver.cpp:218] Iteration 73300 (19.0341 iter/s, 5.25373s/100 iters), loss = 0.0166742
I1005 16:29:22.923225  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166744 (* 1 = 0.0166744 loss)
I1005 16:29:22.923231  9606 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1005 16:29:28.173846  9606 solver.cpp:218] Iteration 73400 (19.0454 iter/s, 5.2506s/100 iters), loss = 0.0368087
I1005 16:29:28.173877  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368089 (* 1 = 0.0368089 loss)
I1005 16:29:28.173883  9606 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1005 16:29:33.155148  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:29:33.365044  9606 solver.cpp:330] Iteration 73500, Testing net (#0)
I1005 16:29:34.557204  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:29:34.606974  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I1005 16:29:34.606998  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372564 (* 1 = 0.372564 loss)
I1005 16:29:34.659376  9606 solver.cpp:218] Iteration 73500 (15.4191 iter/s, 6.48548s/100 iters), loss = 0.0117234
I1005 16:29:34.659407  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117236 (* 1 = 0.0117236 loss)
I1005 16:29:34.659415  9606 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1005 16:29:39.916038  9606 solver.cpp:218] Iteration 73600 (19.0237 iter/s, 5.25661s/100 iters), loss = 0.0518223
I1005 16:29:39.916072  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518225 (* 1 = 0.0518225 loss)
I1005 16:29:39.916079  9606 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1005 16:29:45.162910  9606 solver.cpp:218] Iteration 73700 (19.0592 iter/s, 5.24682s/100 iters), loss = 0.073225
I1005 16:29:45.162950  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732253 (* 1 = 0.0732253 loss)
I1005 16:29:45.162956  9606 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1005 16:29:50.420783  9606 solver.cpp:218] Iteration 73800 (19.0193 iter/s, 5.25782s/100 iters), loss = 0.0103458
I1005 16:29:50.420910  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103461 (* 1 = 0.0103461 loss)
I1005 16:29:50.420928  9606 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1005 16:29:55.679214  9606 solver.cpp:218] Iteration 73900 (19.0176 iter/s, 5.25829s/100 iters), loss = 0.0210828
I1005 16:29:55.679256  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021083 (* 1 = 0.021083 loss)
I1005 16:29:55.679263  9606 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1005 16:30:00.666901  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:30:00.882933  9606 solver.cpp:330] Iteration 74000, Testing net (#0)
I1005 16:30:02.068825  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:30:02.118803  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I1005 16:30:02.118827  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362975 (* 1 = 0.362975 loss)
I1005 16:30:02.171100  9606 solver.cpp:218] Iteration 74000 (15.404 iter/s, 6.49183s/100 iters), loss = 0.028735
I1005 16:30:02.171124  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287352 (* 1 = 0.0287352 loss)
I1005 16:30:02.171131  9606 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1005 16:30:07.407785  9606 solver.cpp:218] Iteration 74100 (19.0962 iter/s, 5.23664s/100 iters), loss = 0.0144461
I1005 16:30:07.407832  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144463 (* 1 = 0.0144463 loss)
I1005 16:30:07.407840  9606 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1005 16:30:12.651130  9606 solver.cpp:218] Iteration 74200 (19.072 iter/s, 5.24328s/100 iters), loss = 0.0508942
I1005 16:30:12.651160  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508945 (* 1 = 0.0508945 loss)
I1005 16:30:12.651165  9606 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1005 16:30:17.905216  9606 solver.cpp:218] Iteration 74300 (19.033 iter/s, 5.25404s/100 iters), loss = 0.0131961
I1005 16:30:17.905257  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131963 (* 1 = 0.0131963 loss)
I1005 16:30:17.905263  9606 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1005 16:30:23.160768  9606 solver.cpp:218] Iteration 74400 (19.0277 iter/s, 5.2555s/100 iters), loss = 0.0158697
I1005 16:30:23.160890  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158699 (* 1 = 0.0158699 loss)
I1005 16:30:23.160907  9606 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1005 16:30:28.159541  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:30:28.369117  9606 solver.cpp:330] Iteration 74500, Testing net (#0)
I1005 16:30:29.554630  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:30:29.604502  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8826
I1005 16:30:29.604538  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.483474 (* 1 = 0.483474 loss)
I1005 16:30:29.656796  9606 solver.cpp:218] Iteration 74500 (15.3943 iter/s, 6.49591s/100 iters), loss = 0.010332
I1005 16:30:29.656821  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103322 (* 1 = 0.0103322 loss)
I1005 16:30:29.656827  9606 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1005 16:30:34.918038  9606 solver.cpp:218] Iteration 74600 (19.0071 iter/s, 5.2612s/100 iters), loss = 0.0176026
I1005 16:30:34.918078  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176028 (* 1 = 0.0176028 loss)
I1005 16:30:34.918084  9606 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1005 16:30:40.175856  9606 solver.cpp:218] Iteration 74700 (19.0195 iter/s, 5.25776s/100 iters), loss = 0.0186376
I1005 16:30:40.175886  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186377 (* 1 = 0.0186377 loss)
I1005 16:30:40.175892  9606 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1005 16:30:45.423802  9606 solver.cpp:218] Iteration 74800 (19.0553 iter/s, 5.2479s/100 iters), loss = 0.0163404
I1005 16:30:45.423836  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163406 (* 1 = 0.0163406 loss)
I1005 16:30:45.423842  9606 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1005 16:30:50.679679  9606 solver.cpp:218] Iteration 74900 (19.0265 iter/s, 5.25583s/100 iters), loss = 0.0149417
I1005 16:30:50.679713  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149419 (* 1 = 0.0149419 loss)
I1005 16:30:50.679731  9606 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1005 16:30:55.664654  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:30:55.874461  9606 solver.cpp:330] Iteration 75000, Testing net (#0)
I1005 16:30:57.061034  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:30:57.110637  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1005 16:30:57.110671  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36886 (* 1 = 0.36886 loss)
I1005 16:30:57.162736  9606 solver.cpp:218] Iteration 75000 (15.4249 iter/s, 6.48301s/100 iters), loss = 0.0416484
I1005 16:30:57.162770  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416486 (* 1 = 0.0416486 loss)
I1005 16:30:57.162778  9606 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1005 16:31:02.415293  9606 solver.cpp:218] Iteration 75100 (19.0385 iter/s, 5.25251s/100 iters), loss = 0.0804187
I1005 16:31:02.415333  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0804189 (* 1 = 0.0804189 loss)
I1005 16:31:02.415339  9606 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1005 16:31:07.667800  9606 solver.cpp:218] Iteration 75200 (19.0387 iter/s, 5.25245s/100 iters), loss = 0.0272975
I1005 16:31:07.667829  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272977 (* 1 = 0.0272977 loss)
I1005 16:31:07.667835  9606 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1005 16:31:12.920219  9606 solver.cpp:218] Iteration 75300 (19.039 iter/s, 5.25237s/100 iters), loss = 0.078351
I1005 16:31:12.920258  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0783512 (* 1 = 0.0783512 loss)
I1005 16:31:12.920264  9606 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1005 16:31:18.167776  9606 solver.cpp:218] Iteration 75400 (19.0567 iter/s, 5.24751s/100 iters), loss = 0.0151123
I1005 16:31:18.167806  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151125 (* 1 = 0.0151125 loss)
I1005 16:31:18.167821  9606 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1005 16:31:23.160480  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:31:23.370260  9606 solver.cpp:330] Iteration 75500, Testing net (#0)
I1005 16:31:24.556141  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:31:24.605851  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I1005 16:31:24.605887  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409383 (* 1 = 0.409383 loss)
I1005 16:31:24.658016  9606 solver.cpp:218] Iteration 75500 (15.4079 iter/s, 6.49019s/100 iters), loss = 0.00752469
I1005 16:31:24.658043  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0075249 (* 1 = 0.0075249 loss)
I1005 16:31:24.658059  9606 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1005 16:31:29.914608  9606 solver.cpp:218] Iteration 75600 (19.0239 iter/s, 5.25655s/100 iters), loss = 0.0204624
I1005 16:31:29.914749  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204626 (* 1 = 0.0204626 loss)
I1005 16:31:29.914769  9606 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1005 16:31:35.168721  9606 solver.cpp:218] Iteration 75700 (19.0332 iter/s, 5.25397s/100 iters), loss = 0.0121089
I1005 16:31:35.168761  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121091 (* 1 = 0.0121091 loss)
I1005 16:31:35.168766  9606 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1005 16:31:40.424285  9606 solver.cpp:218] Iteration 75800 (19.0277 iter/s, 5.25551s/100 iters), loss = 0.0303161
I1005 16:31:40.424325  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303163 (* 1 = 0.0303163 loss)
I1005 16:31:40.424330  9606 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1005 16:31:45.670703  9606 solver.cpp:218] Iteration 75900 (19.0608 iter/s, 5.24636s/100 iters), loss = 0.0489426
I1005 16:31:45.670737  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489428 (* 1 = 0.0489428 loss)
I1005 16:31:45.670743  9606 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1005 16:31:50.658552  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:31:50.868923  9606 solver.cpp:330] Iteration 76000, Testing net (#0)
I1005 16:31:52.061837  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:31:52.111385  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8948
I1005 16:31:52.111421  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409071 (* 1 = 0.409071 loss)
I1005 16:31:52.163789  9606 solver.cpp:218] Iteration 76000 (15.4011 iter/s, 6.49304s/100 iters), loss = 0.00862131
I1005 16:31:52.163830  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0086215 (* 1 = 0.0086215 loss)
I1005 16:31:52.163837  9606 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1005 16:31:57.411142  9606 solver.cpp:218] Iteration 76100 (19.0574 iter/s, 5.24729s/100 iters), loss = 0.00715143
I1005 16:31:57.411173  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715163 (* 1 = 0.00715163 loss)
I1005 16:31:57.411180  9606 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1005 16:32:02.665256  9606 solver.cpp:218] Iteration 76200 (19.0329 iter/s, 5.25407s/100 iters), loss = 0.00603246
I1005 16:32:02.665395  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603267 (* 1 = 0.00603267 loss)
I1005 16:32:02.665428  9606 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1005 16:32:07.920393  9606 solver.cpp:218] Iteration 76300 (19.0295 iter/s, 5.25499s/100 iters), loss = 0.0482344
I1005 16:32:07.920428  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482346 (* 1 = 0.0482346 loss)
I1005 16:32:07.920445  9606 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1005 16:32:13.175753  9606 solver.cpp:218] Iteration 76400 (19.0284 iter/s, 5.25531s/100 iters), loss = 0.0155747
I1005 16:32:13.175786  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155749 (* 1 = 0.0155749 loss)
I1005 16:32:13.175794  9606 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1005 16:32:18.160737  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:32:18.371783  9606 solver.cpp:330] Iteration 76500, Testing net (#0)
I1005 16:32:19.566165  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:32:19.616224  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I1005 16:32:19.616250  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.415874 (* 1 = 0.415874 loss)
I1005 16:32:19.668763  9606 solver.cpp:218] Iteration 76500 (15.4013 iter/s, 6.49296s/100 iters), loss = 0.0469621
I1005 16:32:19.668789  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469624 (* 1 = 0.0469624 loss)
I1005 16:32:19.668799  9606 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1005 16:32:24.922777  9606 solver.cpp:218] Iteration 76600 (19.0332 iter/s, 5.25397s/100 iters), loss = 0.0107124
I1005 16:32:24.922814  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107126 (* 1 = 0.0107126 loss)
I1005 16:32:24.922824  9606 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1005 16:32:30.170743  9606 solver.cpp:218] Iteration 76700 (19.0552 iter/s, 5.24791s/100 iters), loss = 0.0230258
I1005 16:32:30.170775  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023026 (* 1 = 0.023026 loss)
I1005 16:32:30.170794  9606 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1005 16:32:35.423514  9606 solver.cpp:218] Iteration 76800 (19.0377 iter/s, 5.25272s/100 iters), loss = 0.0262849
I1005 16:32:35.423678  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262851 (* 1 = 0.0262851 loss)
I1005 16:32:35.423689  9606 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1005 16:32:40.677548  9606 solver.cpp:218] Iteration 76900 (19.0336 iter/s, 5.25386s/100 iters), loss = 0.05112
I1005 16:32:40.677580  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511202 (* 1 = 0.0511202 loss)
I1005 16:32:40.677588  9606 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1005 16:32:45.662291  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:32:45.878296  9606 solver.cpp:330] Iteration 77000, Testing net (#0)
I1005 16:32:47.065493  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:32:47.115274  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9045
I1005 16:32:47.115300  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371235 (* 1 = 0.371235 loss)
I1005 16:32:47.167332  9606 solver.cpp:218] Iteration 77000 (15.4089 iter/s, 6.48974s/100 iters), loss = 0.016611
I1005 16:32:47.167361  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166112 (* 1 = 0.0166112 loss)
I1005 16:32:47.167379  9606 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1005 16:32:52.425869  9606 solver.cpp:218] Iteration 77100 (19.0169 iter/s, 5.25849s/100 iters), loss = 0.0260255
I1005 16:32:52.425902  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260257 (* 1 = 0.0260257 loss)
I1005 16:32:52.425921  9606 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1005 16:32:57.672415  9606 solver.cpp:218] Iteration 77200 (19.0603 iter/s, 5.24649s/100 iters), loss = 0.0232016
I1005 16:32:57.672456  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232018 (* 1 = 0.0232018 loss)
I1005 16:32:57.672463  9606 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1005 16:33:02.927490  9606 solver.cpp:218] Iteration 77300 (19.0294 iter/s, 5.25502s/100 iters), loss = 0.026385
I1005 16:33:02.927520  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263852 (* 1 = 0.0263852 loss)
I1005 16:33:02.927525  9606 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1005 16:33:08.183614  9606 solver.cpp:218] Iteration 77400 (19.0256 iter/s, 5.25608s/100 iters), loss = 0.0551822
I1005 16:33:08.183753  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0551824 (* 1 = 0.0551824 loss)
I1005 16:33:08.183760  9606 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1005 16:33:13.174595  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:33:13.384878  9606 solver.cpp:330] Iteration 77500, Testing net (#0)
I1005 16:33:14.571064  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:33:14.620982  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8997
I1005 16:33:14.621018  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.401513 (* 1 = 0.401513 loss)
I1005 16:33:14.673823  9606 solver.cpp:218] Iteration 77500 (15.4082 iter/s, 6.49007s/100 iters), loss = 0.0347123
I1005 16:33:14.673849  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347125 (* 1 = 0.0347125 loss)
I1005 16:33:14.673856  9606 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1005 16:33:19.918315  9606 solver.cpp:218] Iteration 77600 (19.0678 iter/s, 5.24445s/100 iters), loss = 0.0234546
I1005 16:33:19.918344  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234548 (* 1 = 0.0234548 loss)
I1005 16:33:19.918350  9606 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1005 16:33:25.171993  9606 solver.cpp:218] Iteration 77700 (19.0345 iter/s, 5.25363s/100 iters), loss = 0.0197745
I1005 16:33:25.172024  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197748 (* 1 = 0.0197748 loss)
I1005 16:33:25.172040  9606 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1005 16:33:30.416801  9606 solver.cpp:218] Iteration 77800 (19.0666 iter/s, 5.24476s/100 iters), loss = 0.0130904
I1005 16:33:30.416831  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130907 (* 1 = 0.0130907 loss)
I1005 16:33:30.416837  9606 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1005 16:33:35.672830  9606 solver.cpp:218] Iteration 77900 (19.0259 iter/s, 5.25598s/100 iters), loss = 0.0079503
I1005 16:33:35.672870  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00795054 (* 1 = 0.00795054 loss)
I1005 16:33:35.672876  9606 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1005 16:33:40.669713  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:33:40.879516  9606 solver.cpp:330] Iteration 78000, Testing net (#0)
I1005 16:33:42.064539  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:33:42.114277  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.897
I1005 16:33:42.114313  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.434353 (* 1 = 0.434353 loss)
I1005 16:33:42.166302  9606 solver.cpp:218] Iteration 78000 (15.4002 iter/s, 6.49342s/100 iters), loss = 0.0558808
I1005 16:33:42.166328  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055881 (* 1 = 0.055881 loss)
I1005 16:33:42.166335  9606 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1005 16:33:47.421442  9606 solver.cpp:218] Iteration 78100 (19.0292 iter/s, 5.25509s/100 iters), loss = 0.0599714
I1005 16:33:47.421483  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0599716 (* 1 = 0.0599716 loss)
I1005 16:33:47.421489  9606 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1005 16:33:52.681485  9606 solver.cpp:218] Iteration 78200 (19.0115 iter/s, 5.25998s/100 iters), loss = 0.0422064
I1005 16:33:52.681525  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422067 (* 1 = 0.0422067 loss)
I1005 16:33:52.681531  9606 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1005 16:33:57.935117  9606 solver.cpp:218] Iteration 78300 (19.0347 iter/s, 5.25357s/100 iters), loss = 0.0611769
I1005 16:33:57.935153  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0611771 (* 1 = 0.0611771 loss)
I1005 16:33:57.935160  9606 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1005 16:34:03.187014  9606 solver.cpp:218] Iteration 78400 (19.0409 iter/s, 5.25185s/100 iters), loss = 0.00570784
I1005 16:34:03.187055  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570807 (* 1 = 0.00570807 loss)
I1005 16:34:03.187062  9606 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1005 16:34:08.182081  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:34:08.392706  9606 solver.cpp:330] Iteration 78500, Testing net (#0)
I1005 16:34:09.577616  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:34:09.626956  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8818
I1005 16:34:09.626991  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.486672 (* 1 = 0.486672 loss)
I1005 16:34:09.679347  9606 solver.cpp:218] Iteration 78500 (15.4029 iter/s, 6.49227s/100 iters), loss = 0.0224753
I1005 16:34:09.679391  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224755 (* 1 = 0.0224755 loss)
I1005 16:34:09.679399  9606 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1005 16:34:14.930821  9606 solver.cpp:218] Iteration 78600 (19.0425 iter/s, 5.25141s/100 iters), loss = 0.0160157
I1005 16:34:14.930954  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016016 (* 1 = 0.016016 loss)
I1005 16:34:14.930963  9606 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1005 16:34:20.182287  9606 solver.cpp:218] Iteration 78700 (19.0428 iter/s, 5.25132s/100 iters), loss = 0.0253241
I1005 16:34:20.182319  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253243 (* 1 = 0.0253243 loss)
I1005 16:34:20.182327  9606 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1005 16:34:25.435834  9606 solver.cpp:218] Iteration 78800 (19.0349 iter/s, 5.2535s/100 iters), loss = 0.029537
I1005 16:34:25.435864  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295372 (* 1 = 0.0295372 loss)
I1005 16:34:25.435870  9606 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1005 16:34:30.681505  9606 solver.cpp:218] Iteration 78900 (19.0635 iter/s, 5.24562s/100 iters), loss = 0.0291754
I1005 16:34:30.681537  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291756 (* 1 = 0.0291756 loss)
I1005 16:34:30.681543  9606 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1005 16:34:35.675488  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:34:35.885478  9606 solver.cpp:330] Iteration 79000, Testing net (#0)
I1005 16:34:37.077204  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:34:37.126899  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8969
I1005 16:34:37.126924  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426404 (* 1 = 0.426404 loss)
I1005 16:34:37.179121  9606 solver.cpp:218] Iteration 79000 (15.3904 iter/s, 6.49757s/100 iters), loss = 0.0174889
I1005 16:34:37.179150  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174892 (* 1 = 0.0174892 loss)
I1005 16:34:37.179157  9606 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1005 16:34:42.422607  9606 solver.cpp:218] Iteration 79100 (19.0715 iter/s, 5.24343s/100 iters), loss = 0.0273169
I1005 16:34:42.422637  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273172 (* 1 = 0.0273172 loss)
I1005 16:34:42.422644  9606 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1005 16:34:47.677496  9606 solver.cpp:218] Iteration 79200 (19.0301 iter/s, 5.25484s/100 iters), loss = 0.0476113
I1005 16:34:47.677613  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476116 (* 1 = 0.0476116 loss)
I1005 16:34:47.677620  9606 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1005 16:34:52.928895  9606 solver.cpp:218] Iteration 79300 (19.043 iter/s, 5.25128s/100 iters), loss = 0.0294119
I1005 16:34:52.928925  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294121 (* 1 = 0.0294121 loss)
I1005 16:34:52.928930  9606 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1005 16:34:58.182597  9606 solver.cpp:218] Iteration 79400 (19.0344 iter/s, 5.25365s/100 iters), loss = 0.0104764
I1005 16:34:58.182636  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104767 (* 1 = 0.0104767 loss)
I1005 16:34:58.182643  9606 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1005 16:35:03.167179  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:35:03.376965  9606 solver.cpp:330] Iteration 79500, Testing net (#0)
I1005 16:35:04.569514  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:35:04.619056  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8859
I1005 16:35:04.619091  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.485652 (* 1 = 0.485652 loss)
I1005 16:35:04.671217  9606 solver.cpp:218] Iteration 79500 (15.4117 iter/s, 6.48857s/100 iters), loss = 0.0140224
I1005 16:35:04.671243  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140227 (* 1 = 0.0140227 loss)
I1005 16:35:04.671250  9606 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1005 16:35:09.922852  9606 solver.cpp:218] Iteration 79600 (19.0419 iter/s, 5.25159s/100 iters), loss = 0.0112951
I1005 16:35:09.922885  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112953 (* 1 = 0.0112953 loss)
I1005 16:35:09.922894  9606 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1005 16:35:15.172207  9606 solver.cpp:218] Iteration 79700 (19.0501 iter/s, 5.24931s/100 iters), loss = 0.0111103
I1005 16:35:15.172240  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111105 (* 1 = 0.0111105 loss)
I1005 16:35:15.172255  9606 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1005 16:35:20.429267  9606 solver.cpp:218] Iteration 79800 (19.0222 iter/s, 5.25701s/100 iters), loss = 0.0446733
I1005 16:35:20.429404  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446735 (* 1 = 0.0446735 loss)
I1005 16:35:20.429448  9606 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1005 16:35:25.680827  9606 solver.cpp:218] Iteration 79900 (19.0425 iter/s, 5.25142s/100 iters), loss = 0.0184636
I1005 16:35:25.680868  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184639 (* 1 = 0.0184639 loss)
I1005 16:35:25.680874  9606 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1005 16:35:30.662551  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:35:30.878999  9606 solver.cpp:330] Iteration 80000, Testing net (#0)
I1005 16:35:32.068353  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:35:32.118140  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8916
I1005 16:35:32.118167  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.463205 (* 1 = 0.463205 loss)
I1005 16:35:32.170334  9606 solver.cpp:218] Iteration 80000 (15.4096 iter/s, 6.48945s/100 iters), loss = 0.00450358
I1005 16:35:32.170361  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450383 (* 1 = 0.00450383 loss)
I1005 16:35:32.170369  9606 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1005 16:35:32.170375  9606 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1005 16:35:37.427784  9606 solver.cpp:218] Iteration 80100 (19.0208 iter/s, 5.25741s/100 iters), loss = 0.0531523
I1005 16:35:37.427815  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0531526 (* 1 = 0.0531526 loss)
I1005 16:35:37.427822  9606 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1005 16:35:42.672230  9606 solver.cpp:218] Iteration 80200 (19.068 iter/s, 5.2444s/100 iters), loss = 0.0217429
I1005 16:35:42.672261  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217431 (* 1 = 0.0217431 loss)
I1005 16:35:42.672279  9606 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1005 16:35:47.927227  9606 solver.cpp:218] Iteration 80300 (19.0297 iter/s, 5.25494s/100 iters), loss = 0.0254203
I1005 16:35:47.927258  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254205 (* 1 = 0.0254205 loss)
I1005 16:35:47.927265  9606 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1005 16:35:53.175539  9606 solver.cpp:218] Iteration 80400 (19.0539 iter/s, 5.24827s/100 iters), loss = 0.0110194
I1005 16:35:53.175639  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110196 (* 1 = 0.0110196 loss)
I1005 16:35:53.175655  9606 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1005 16:35:58.164994  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:35:58.375337  9606 solver.cpp:330] Iteration 80500, Testing net (#0)
I1005 16:35:59.561071  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:35:59.610775  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9091
I1005 16:35:59.610810  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374501 (* 1 = 0.374501 loss)
I1005 16:35:59.663250  9606 solver.cpp:218] Iteration 80500 (15.414 iter/s, 6.4876s/100 iters), loss = 0.0210397
I1005 16:35:59.663275  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210399 (* 1 = 0.0210399 loss)
I1005 16:35:59.663280  9606 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1005 16:36:04.923178  9606 solver.cpp:218] Iteration 80600 (19.0118 iter/s, 5.25989s/100 iters), loss = 0.00933085
I1005 16:36:04.923207  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00933108 (* 1 = 0.00933108 loss)
I1005 16:36:04.923213  9606 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1005 16:36:10.181021  9606 solver.cpp:218] Iteration 80700 (19.0194 iter/s, 5.25779s/100 iters), loss = 0.0086963
I1005 16:36:10.181051  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869653 (* 1 = 0.00869653 loss)
I1005 16:36:10.181056  9606 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1005 16:36:15.428186  9606 solver.cpp:218] Iteration 80800 (19.0581 iter/s, 5.24712s/100 iters), loss = 0.0170035
I1005 16:36:15.428220  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170037 (* 1 = 0.0170037 loss)
I1005 16:36:15.428225  9606 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1005 16:36:20.686218  9606 solver.cpp:218] Iteration 80900 (19.0187 iter/s, 5.25798s/100 iters), loss = 0.00539376
I1005 16:36:20.686249  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539398 (* 1 = 0.00539398 loss)
I1005 16:36:20.686259  9606 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1005 16:36:25.680716  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:36:25.890761  9606 solver.cpp:330] Iteration 81000, Testing net (#0)
I1005 16:36:27.075651  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:36:27.125408  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9123
I1005 16:36:27.125433  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354869 (* 1 = 0.354869 loss)
I1005 16:36:27.177645  9606 solver.cpp:218] Iteration 81000 (15.405 iter/s, 6.49138s/100 iters), loss = 0.0131345
I1005 16:36:27.177670  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131347 (* 1 = 0.0131347 loss)
I1005 16:36:27.177677  9606 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1005 16:36:32.432533  9606 solver.cpp:218] Iteration 81100 (19.0301 iter/s, 5.25484s/100 iters), loss = 0.0118988
I1005 16:36:32.432562  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011899 (* 1 = 0.011899 loss)
I1005 16:36:32.432569  9606 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1005 16:36:37.689894  9606 solver.cpp:218] Iteration 81200 (19.0211 iter/s, 5.25732s/100 iters), loss = 0.00888034
I1005 16:36:37.689936  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00888056 (* 1 = 0.00888056 loss)
I1005 16:36:37.689942  9606 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1005 16:36:42.941429  9606 solver.cpp:218] Iteration 81300 (19.0423 iter/s, 5.25148s/100 iters), loss = 0.00601939
I1005 16:36:42.941464  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0060196 (* 1 = 0.0060196 loss)
I1005 16:36:42.941470  9606 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1005 16:36:48.190546  9606 solver.cpp:218] Iteration 81400 (19.051 iter/s, 5.24907s/100 iters), loss = 0.0193326
I1005 16:36:48.190578  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193328 (* 1 = 0.0193328 loss)
I1005 16:36:48.190587  9606 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1005 16:36:53.186348  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:36:53.397106  9606 solver.cpp:330] Iteration 81500, Testing net (#0)
I1005 16:36:54.583776  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:36:54.633553  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1005 16:36:54.633577  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344189 (* 1 = 0.344189 loss)
I1005 16:36:54.685909  9606 solver.cpp:218] Iteration 81500 (15.3957 iter/s, 6.49532s/100 iters), loss = 0.0227044
I1005 16:36:54.685932  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227046 (* 1 = 0.0227046 loss)
I1005 16:36:54.685940  9606 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1005 16:36:59.945489  9606 solver.cpp:218] Iteration 81600 (19.0131 iter/s, 5.25954s/100 iters), loss = 0.00551455
I1005 16:36:59.945617  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551478 (* 1 = 0.00551478 loss)
I1005 16:36:59.945624  9606 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1005 16:37:05.203593  9606 solver.cpp:218] Iteration 81700 (19.0188 iter/s, 5.25796s/100 iters), loss = 0.00718233
I1005 16:37:05.203634  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00718255 (* 1 = 0.00718255 loss)
I1005 16:37:05.203639  9606 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1005 16:37:10.462218  9606 solver.cpp:218] Iteration 81800 (19.0166 iter/s, 5.25857s/100 iters), loss = 0.0297807
I1005 16:37:10.462256  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029781 (* 1 = 0.029781 loss)
I1005 16:37:10.462261  9606 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1005 16:37:15.708444  9606 solver.cpp:218] Iteration 81900 (19.0615 iter/s, 5.24617s/100 iters), loss = 0.0175455
I1005 16:37:15.708478  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175457 (* 1 = 0.0175457 loss)
I1005 16:37:15.708495  9606 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1005 16:37:20.699141  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:37:20.908183  9606 solver.cpp:330] Iteration 82000, Testing net (#0)
I1005 16:37:22.099802  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:37:22.149571  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1005 16:37:22.149597  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346896 (* 1 = 0.346896 loss)
I1005 16:37:22.201614  9606 solver.cpp:218] Iteration 82000 (15.4009 iter/s, 6.49312s/100 iters), loss = 0.00435232
I1005 16:37:22.201647  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435252 (* 1 = 0.00435252 loss)
I1005 16:37:22.201654  9606 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1005 16:37:27.449898  9606 solver.cpp:218] Iteration 82100 (19.054 iter/s, 5.24823s/100 iters), loss = 0.00973701
I1005 16:37:27.449928  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00973721 (* 1 = 0.00973721 loss)
I1005 16:37:27.449934  9606 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1005 16:37:32.700544  9606 solver.cpp:218] Iteration 82200 (19.0454 iter/s, 5.2506s/100 iters), loss = 0.0157214
I1005 16:37:32.700695  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157216 (* 1 = 0.0157216 loss)
I1005 16:37:32.700702  9606 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1005 16:37:37.955766  9606 solver.cpp:218] Iteration 82300 (19.0292 iter/s, 5.25507s/100 iters), loss = 0.00558842
I1005 16:37:37.955811  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558862 (* 1 = 0.00558862 loss)
I1005 16:37:37.955816  9606 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1005 16:37:43.213407  9606 solver.cpp:218] Iteration 82400 (19.0201 iter/s, 5.25758s/100 iters), loss = 0.0308592
I1005 16:37:43.213438  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308594 (* 1 = 0.0308594 loss)
I1005 16:37:43.213443  9606 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1005 16:37:48.197705  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:37:48.407296  9606 solver.cpp:330] Iteration 82500, Testing net (#0)
I1005 16:37:49.601924  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:37:49.651747  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1005 16:37:49.651773  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341646 (* 1 = 0.341646 loss)
I1005 16:37:49.703655  9606 solver.cpp:218] Iteration 82500 (15.4078 iter/s, 6.4902s/100 iters), loss = 0.0127032
I1005 16:37:49.703683  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127034 (* 1 = 0.0127034 loss)
I1005 16:37:49.703691  9606 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1005 16:37:54.958631  9606 solver.cpp:218] Iteration 82600 (19.0297 iter/s, 5.25493s/100 iters), loss = 0.0211429
I1005 16:37:54.958664  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211431 (* 1 = 0.0211431 loss)
I1005 16:37:54.958673  9606 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1005 16:38:00.203969  9606 solver.cpp:218] Iteration 82700 (19.0648 iter/s, 5.24528s/100 iters), loss = 0.012896
I1005 16:38:00.204000  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128963 (* 1 = 0.0128963 loss)
I1005 16:38:00.204006  9606 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1005 16:38:05.453390  9606 solver.cpp:218] Iteration 82800 (19.0499 iter/s, 5.24937s/100 iters), loss = 0.0131262
I1005 16:38:05.453562  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131264 (* 1 = 0.0131264 loss)
I1005 16:38:05.453570  9606 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1005 16:38:10.707953  9606 solver.cpp:218] Iteration 82900 (19.0317 iter/s, 5.25438s/100 iters), loss = 0.00291551
I1005 16:38:10.707983  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291572 (* 1 = 0.00291572 loss)
I1005 16:38:10.707999  9606 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1005 16:38:15.688657  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:38:15.903271  9606 solver.cpp:330] Iteration 83000, Testing net (#0)
I1005 16:38:17.089473  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:38:17.139164  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I1005 16:38:17.139199  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341042 (* 1 = 0.341042 loss)
I1005 16:38:17.191025  9606 solver.cpp:218] Iteration 83000 (15.4249 iter/s, 6.48302s/100 iters), loss = 0.00231123
I1005 16:38:17.191061  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231143 (* 1 = 0.00231143 loss)
I1005 16:38:17.191067  9606 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1005 16:38:22.446405  9606 solver.cpp:218] Iteration 83100 (19.0283 iter/s, 5.25532s/100 iters), loss = 0.0058518
I1005 16:38:22.446445  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005852 (* 1 = 0.005852 loss)
I1005 16:38:22.446452  9606 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1005 16:38:27.691599  9606 solver.cpp:218] Iteration 83200 (19.0653 iter/s, 5.24514s/100 iters), loss = 0.0205713
I1005 16:38:27.691639  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205715 (* 1 = 0.0205715 loss)
I1005 16:38:27.691645  9606 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1005 16:38:32.942901  9606 solver.cpp:218] Iteration 83300 (19.0431 iter/s, 5.25124s/100 iters), loss = 0.0121548
I1005 16:38:32.942942  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012155 (* 1 = 0.012155 loss)
I1005 16:38:32.942948  9606 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1005 16:38:38.200708  9606 solver.cpp:218] Iteration 83400 (19.0195 iter/s, 5.25775s/100 iters), loss = 0.00968078
I1005 16:38:38.200810  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968098 (* 1 = 0.00968098 loss)
I1005 16:38:38.200817  9606 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1005 16:38:43.197726  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:38:43.408336  9606 solver.cpp:330] Iteration 83500, Testing net (#0)
I1005 16:38:44.595353  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:38:44.645076  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1005 16:38:44.645102  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339403 (* 1 = 0.339403 loss)
I1005 16:38:44.697291  9606 solver.cpp:218] Iteration 83500 (15.393 iter/s, 6.49647s/100 iters), loss = 0.0141791
I1005 16:38:44.697324  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141793 (* 1 = 0.0141793 loss)
I1005 16:38:44.697331  9606 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1005 16:38:49.952313  9606 solver.cpp:218] Iteration 83600 (19.0296 iter/s, 5.25498s/100 iters), loss = 0.0120704
I1005 16:38:49.952343  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120706 (* 1 = 0.0120706 loss)
I1005 16:38:49.952359  9606 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1005 16:38:55.203629  9606 solver.cpp:218] Iteration 83700 (19.043 iter/s, 5.25127s/100 iters), loss = 0.00661201
I1005 16:38:55.203670  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00661222 (* 1 = 0.00661222 loss)
I1005 16:38:55.203676  9606 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1005 16:39:00.447960  9606 solver.cpp:218] Iteration 83800 (19.0684 iter/s, 5.24427s/100 iters), loss = 0.0159585
I1005 16:39:00.447993  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159587 (* 1 = 0.0159587 loss)
I1005 16:39:00.448009  9606 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1005 16:39:05.698448  9606 solver.cpp:218] Iteration 83900 (19.046 iter/s, 5.25044s/100 iters), loss = 0.015077
I1005 16:39:05.698489  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150772 (* 1 = 0.0150772 loss)
I1005 16:39:05.698496  9606 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1005 16:39:10.688386  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:39:10.898851  9606 solver.cpp:330] Iteration 84000, Testing net (#0)
I1005 16:39:12.083387  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:39:12.132686  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1005 16:39:12.132709  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339103 (* 1 = 0.339103 loss)
I1005 16:39:12.184860  9606 solver.cpp:218] Iteration 84000 (15.417 iter/s, 6.48636s/100 iters), loss = 0.00943271
I1005 16:39:12.184885  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943293 (* 1 = 0.00943293 loss)
I1005 16:39:12.184892  9606 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1005 16:39:17.440448  9606 solver.cpp:218] Iteration 84100 (19.0275 iter/s, 5.25554s/100 iters), loss = 0.0111289
I1005 16:39:17.440479  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111291 (* 1 = 0.0111291 loss)
I1005 16:39:17.440485  9606 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1005 16:39:22.695330  9606 solver.cpp:218] Iteration 84200 (19.0301 iter/s, 5.25484s/100 iters), loss = 0.00911331
I1005 16:39:22.695371  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00911352 (* 1 = 0.00911352 loss)
I1005 16:39:22.695377  9606 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1005 16:39:27.952262  9606 solver.cpp:218] Iteration 84300 (19.0227 iter/s, 5.25687s/100 iters), loss = 0.00200973
I1005 16:39:27.952297  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200995 (* 1 = 0.00200995 loss)
I1005 16:39:27.952304  9606 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1005 16:39:33.200182  9606 solver.cpp:218] Iteration 84400 (19.0554 iter/s, 5.24787s/100 iters), loss = 0.00677364
I1005 16:39:33.200212  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00677386 (* 1 = 0.00677386 loss)
I1005 16:39:33.200217  9606 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1005 16:39:38.197204  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:39:38.407253  9606 solver.cpp:330] Iteration 84500, Testing net (#0)
I1005 16:39:39.593212  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:39:39.643043  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1005 16:39:39.643069  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34206 (* 1 = 0.34206 loss)
I1005 16:39:39.695121  9606 solver.cpp:218] Iteration 84500 (15.3967 iter/s, 6.49489s/100 iters), loss = 0.0148595
I1005 16:39:39.695152  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148597 (* 1 = 0.0148597 loss)
I1005 16:39:39.695158  9606 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1005 16:39:44.947531  9606 solver.cpp:218] Iteration 84600 (19.0391 iter/s, 5.25236s/100 iters), loss = 0.0290224
I1005 16:39:44.947640  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290226 (* 1 = 0.0290226 loss)
I1005 16:39:44.947649  9606 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1005 16:39:50.200891  9606 solver.cpp:218] Iteration 84700 (19.0359 iter/s, 5.25324s/100 iters), loss = 0.0193196
I1005 16:39:50.200932  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193198 (* 1 = 0.0193198 loss)
I1005 16:39:50.200937  9606 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1005 16:39:55.453482  9606 solver.cpp:218] Iteration 84800 (19.0384 iter/s, 5.25253s/100 iters), loss = 0.0104983
I1005 16:39:55.453512  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104986 (* 1 = 0.0104986 loss)
I1005 16:39:55.453518  9606 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1005 16:40:00.699986  9606 solver.cpp:218] Iteration 84900 (19.0605 iter/s, 5.24646s/100 iters), loss = 0.00184587
I1005 16:40:00.700026  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018461 (* 1 = 0.0018461 loss)
I1005 16:40:00.700033  9606 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1005 16:40:05.689574  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:40:05.899202  9606 solver.cpp:330] Iteration 85000, Testing net (#0)
I1005 16:40:07.093528  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:40:07.142874  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1005 16:40:07.142910  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341082 (* 1 = 0.341082 loss)
I1005 16:40:07.195322  9606 solver.cpp:218] Iteration 85000 (15.3958 iter/s, 6.49528s/100 iters), loss = 0.0160575
I1005 16:40:07.195376  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160577 (* 1 = 0.0160577 loss)
I1005 16:40:07.195384  9606 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1005 16:40:12.443876  9606 solver.cpp:218] Iteration 85100 (19.0531 iter/s, 5.24848s/100 iters), loss = 0.0173347
I1005 16:40:12.443909  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017335 (* 1 = 0.017335 loss)
I1005 16:40:12.443925  9606 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1005 16:40:17.700141  9606 solver.cpp:218] Iteration 85200 (19.0251 iter/s, 5.25622s/100 iters), loss = 0.0174591
I1005 16:40:17.700279  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174593 (* 1 = 0.0174593 loss)
I1005 16:40:17.700297  9606 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1005 16:40:22.956938  9606 solver.cpp:218] Iteration 85300 (19.0235 iter/s, 5.25665s/100 iters), loss = 0.01166
I1005 16:40:22.956969  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116602 (* 1 = 0.0116602 loss)
I1005 16:40:22.956984  9606 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1005 16:40:28.211864  9606 solver.cpp:218] Iteration 85400 (19.0299 iter/s, 5.25488s/100 iters), loss = 0.00359726
I1005 16:40:28.211895  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359748 (* 1 = 0.00359748 loss)
I1005 16:40:28.211911  9606 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1005 16:40:33.194171  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:40:33.404696  9606 solver.cpp:330] Iteration 85500, Testing net (#0)
I1005 16:40:34.598631  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:40:34.648234  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1005 16:40:34.648269  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340285 (* 1 = 0.340285 loss)
I1005 16:40:34.700309  9606 solver.cpp:218] Iteration 85500 (15.4121 iter/s, 6.48839s/100 iters), loss = 0.00990316
I1005 16:40:34.700342  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00990337 (* 1 = 0.00990337 loss)
I1005 16:40:34.700361  9606 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1005 16:40:39.953493  9606 solver.cpp:218] Iteration 85600 (19.0363 iter/s, 5.25313s/100 iters), loss = 0.0346009
I1005 16:40:39.953527  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346011 (* 1 = 0.0346011 loss)
I1005 16:40:39.953536  9606 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1005 16:40:45.198302  9606 solver.cpp:218] Iteration 85700 (19.0667 iter/s, 5.24476s/100 iters), loss = 0.0194687
I1005 16:40:45.198341  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019469 (* 1 = 0.019469 loss)
I1005 16:40:45.198348  9606 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1005 16:40:50.454243  9606 solver.cpp:218] Iteration 85800 (19.0263 iter/s, 5.25589s/100 iters), loss = 0.0160657
I1005 16:40:50.454385  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160659 (* 1 = 0.0160659 loss)
I1005 16:40:50.454391  9606 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1005 16:40:55.710517  9606 solver.cpp:218] Iteration 85900 (19.0254 iter/s, 5.25612s/100 iters), loss = 0.00562754
I1005 16:40:55.710561  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562774 (* 1 = 0.00562774 loss)
I1005 16:40:55.710566  9606 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1005 16:41:00.695340  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:41:00.912482  9606 solver.cpp:330] Iteration 86000, Testing net (#0)
I1005 16:41:02.102327  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:41:02.152215  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1005 16:41:02.152249  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33949 (* 1 = 0.33949 loss)
I1005 16:41:02.204540  9606 solver.cpp:218] Iteration 86000 (15.3989 iter/s, 6.49396s/100 iters), loss = 0.00990732
I1005 16:41:02.204566  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00990753 (* 1 = 0.00990753 loss)
I1005 16:41:02.204574  9606 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1005 16:41:07.461256  9606 solver.cpp:218] Iteration 86100 (19.0234 iter/s, 5.25667s/100 iters), loss = 0.00642295
I1005 16:41:07.461297  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642315 (* 1 = 0.00642315 loss)
I1005 16:41:07.461303  9606 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1005 16:41:12.711587  9606 solver.cpp:218] Iteration 86200 (19.0466 iter/s, 5.25027s/100 iters), loss = 0.0115034
I1005 16:41:12.711627  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115036 (* 1 = 0.0115036 loss)
I1005 16:41:12.711632  9606 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1005 16:41:17.968691  9606 solver.cpp:218] Iteration 86300 (19.0221 iter/s, 5.25704s/100 iters), loss = 0.0154389
I1005 16:41:17.968721  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154391 (* 1 = 0.0154391 loss)
I1005 16:41:17.968736  9606 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1005 16:41:23.221304  9606 solver.cpp:218] Iteration 86400 (19.0383 iter/s, 5.25257s/100 iters), loss = 0.0269623
I1005 16:41:23.221437  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269625 (* 1 = 0.0269625 loss)
I1005 16:41:23.221456  9606 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1005 16:41:28.214661  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:41:28.425127  9606 solver.cpp:330] Iteration 86500, Testing net (#0)
I1005 16:41:29.611361  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:41:29.660887  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1005 16:41:29.660922  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340055 (* 1 = 0.340055 loss)
I1005 16:41:29.713331  9606 solver.cpp:218] Iteration 86500 (15.4039 iter/s, 6.49188s/100 iters), loss = 0.00474968
I1005 16:41:29.713361  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474988 (* 1 = 0.00474988 loss)
I1005 16:41:29.713367  9606 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1005 16:41:34.971245  9606 solver.cpp:218] Iteration 86600 (19.0191 iter/s, 5.25787s/100 iters), loss = 0.00952785
I1005 16:41:34.971284  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952805 (* 1 = 0.00952805 loss)
I1005 16:41:34.971290  9606 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1005 16:41:40.227427  9606 solver.cpp:218] Iteration 86700 (19.0254 iter/s, 5.25612s/100 iters), loss = 0.0265857
I1005 16:41:40.227468  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265859 (* 1 = 0.0265859 loss)
I1005 16:41:40.227474  9606 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1005 16:41:45.476289  9606 solver.cpp:218] Iteration 86800 (19.052 iter/s, 5.2488s/100 iters), loss = 0.00491316
I1005 16:41:45.476332  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491337 (* 1 = 0.00491337 loss)
I1005 16:41:45.476339  9606 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1005 16:41:50.739408  9606 solver.cpp:218] Iteration 86900 (19.0004 iter/s, 5.26306s/100 iters), loss = 0.00520496
I1005 16:41:50.739439  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520518 (* 1 = 0.00520518 loss)
I1005 16:41:50.739444  9606 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1005 16:41:55.737268  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:41:55.947408  9606 solver.cpp:330] Iteration 87000, Testing net (#0)
I1005 16:41:57.131443  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:41:57.181092  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1005 16:41:57.181128  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33986 (* 1 = 0.33986 loss)
I1005 16:41:57.233634  9606 solver.cpp:218] Iteration 87000 (15.3984 iter/s, 6.49418s/100 iters), loss = 0.00700535
I1005 16:41:57.233660  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700557 (* 1 = 0.00700557 loss)
I1005 16:41:57.233667  9606 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1005 16:42:02.493717  9606 solver.cpp:218] Iteration 87100 (19.0113 iter/s, 5.26004s/100 iters), loss = 0.0124847
I1005 16:42:02.493757  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124849 (* 1 = 0.0124849 loss)
I1005 16:42:02.493763  9606 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1005 16:42:07.746078  9606 solver.cpp:218] Iteration 87200 (19.0393 iter/s, 5.2523s/100 iters), loss = 0.00946754
I1005 16:42:07.746119  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00946776 (* 1 = 0.00946776 loss)
I1005 16:42:07.746124  9606 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1005 16:42:13.002498  9606 solver.cpp:218] Iteration 87300 (19.0246 iter/s, 5.25636s/100 iters), loss = 0.00869079
I1005 16:42:13.002545  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869102 (* 1 = 0.00869102 loss)
I1005 16:42:13.002553  9606 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1005 16:42:18.247038  9606 solver.cpp:218] Iteration 87400 (19.0678 iter/s, 5.24445s/100 iters), loss = 0.00451963
I1005 16:42:18.247067  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451986 (* 1 = 0.00451986 loss)
I1005 16:42:18.247083  9606 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1005 16:42:23.239778  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:42:23.449159  9606 solver.cpp:330] Iteration 87500, Testing net (#0)
I1005 16:42:24.634930  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:42:24.685015  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1005 16:42:24.685041  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34194 (* 1 = 0.34194 loss)
I1005 16:42:24.737509  9606 solver.cpp:218] Iteration 87500 (15.4073 iter/s, 6.49043s/100 iters), loss = 0.00350003
I1005 16:42:24.737545  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350026 (* 1 = 0.00350026 loss)
I1005 16:42:24.737553  9606 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1005 16:42:29.991727  9606 solver.cpp:218] Iteration 87600 (19.0325 iter/s, 5.25417s/100 iters), loss = 0.0188841
I1005 16:42:29.991835  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188843 (* 1 = 0.0188843 loss)
I1005 16:42:29.991844  9606 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1005 16:42:35.245646  9606 solver.cpp:218] Iteration 87700 (19.0339 iter/s, 5.25379s/100 iters), loss = 0.011287
I1005 16:42:35.245676  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112872 (* 1 = 0.0112872 loss)
I1005 16:42:35.245682  9606 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1005 16:42:40.501621  9606 solver.cpp:218] Iteration 87800 (19.0261 iter/s, 5.25592s/100 iters), loss = 0.0046405
I1005 16:42:40.501662  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00464074 (* 1 = 0.00464074 loss)
I1005 16:42:40.501667  9606 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1005 16:42:45.748193  9606 solver.cpp:218] Iteration 87900 (19.0603 iter/s, 5.24651s/100 iters), loss = 0.00248908
I1005 16:42:45.748242  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248931 (* 1 = 0.00248931 loss)
I1005 16:42:45.748250  9606 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1005 16:42:50.741168  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:42:50.950819  9606 solver.cpp:330] Iteration 88000, Testing net (#0)
I1005 16:42:52.145265  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:42:52.194924  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1005 16:42:52.194958  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342299 (* 1 = 0.342299 loss)
I1005 16:42:52.247472  9606 solver.cpp:218] Iteration 88000 (15.3865 iter/s, 6.49918s/100 iters), loss = 0.0133886
I1005 16:42:52.247506  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133888 (* 1 = 0.0133888 loss)
I1005 16:42:52.247514  9606 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1005 16:42:57.485195  9606 solver.cpp:218] Iteration 88100 (19.0924 iter/s, 5.23768s/100 iters), loss = 0.00860798
I1005 16:42:57.485225  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00860821 (* 1 = 0.00860821 loss)
I1005 16:42:57.485241  9606 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1005 16:43:02.738860  9606 solver.cpp:218] Iteration 88200 (19.0345 iter/s, 5.25362s/100 iters), loss = 0.00684547
I1005 16:43:02.738987  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068457 (* 1 = 0.0068457 loss)
I1005 16:43:02.738994  9606 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1005 16:43:07.993710  9606 solver.cpp:218] Iteration 88300 (19.0306 iter/s, 5.2547s/100 iters), loss = 0.00976012
I1005 16:43:07.993749  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00976035 (* 1 = 0.00976035 loss)
I1005 16:43:07.993755  9606 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1005 16:43:13.250244  9606 solver.cpp:218] Iteration 88400 (19.0241 iter/s, 5.25648s/100 iters), loss = 0.00201543
I1005 16:43:13.250274  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201566 (* 1 = 0.00201566 loss)
I1005 16:43:13.250282  9606 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1005 16:43:18.232723  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:43:18.442394  9606 solver.cpp:330] Iteration 88500, Testing net (#0)
I1005 16:43:19.638103  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:43:19.687940  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1005 16:43:19.687968  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343899 (* 1 = 0.343899 loss)
I1005 16:43:19.740185  9606 solver.cpp:218] Iteration 88500 (15.4086 iter/s, 6.4899s/100 iters), loss = 0.0208276
I1005 16:43:19.740216  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208278 (* 1 = 0.0208278 loss)
I1005 16:43:19.740226  9606 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1005 16:43:24.996027  9606 solver.cpp:218] Iteration 88600 (19.0266 iter/s, 5.25579s/100 iters), loss = 0.0125478
I1005 16:43:24.996064  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012548 (* 1 = 0.012548 loss)
I1005 16:43:24.996074  9606 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1005 16:43:30.246709  9606 solver.cpp:218] Iteration 88700 (19.0453 iter/s, 5.25063s/100 iters), loss = 0.0105804
I1005 16:43:30.246743  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105806 (* 1 = 0.0105806 loss)
I1005 16:43:30.246752  9606 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1005 16:43:35.501384  9606 solver.cpp:218] Iteration 88800 (19.0308 iter/s, 5.25463s/100 iters), loss = 0.00372343
I1005 16:43:35.501554  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372366 (* 1 = 0.00372366 loss)
I1005 16:43:35.501562  9606 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1005 16:43:40.755396  9606 solver.cpp:218] Iteration 88900 (19.0337 iter/s, 5.25383s/100 iters), loss = 0.0118927
I1005 16:43:40.755437  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011893 (* 1 = 0.011893 loss)
I1005 16:43:40.755444  9606 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1005 16:43:45.738776  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:43:45.953384  9606 solver.cpp:330] Iteration 89000, Testing net (#0)
I1005 16:43:47.140738  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:43:47.190454  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1005 16:43:47.190488  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343995 (* 1 = 0.343995 loss)
I1005 16:43:47.242522  9606 solver.cpp:218] Iteration 89000 (15.4153 iter/s, 6.48707s/100 iters), loss = 0.00767705
I1005 16:43:47.242558  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00767728 (* 1 = 0.00767728 loss)
I1005 16:43:47.242574  9606 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1005 16:43:52.496039  9606 solver.cpp:218] Iteration 89100 (19.0351 iter/s, 5.25346s/100 iters), loss = 0.031924
I1005 16:43:52.496068  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319242 (* 1 = 0.0319242 loss)
I1005 16:43:52.496074  9606 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1005 16:43:57.740571  9606 solver.cpp:218] Iteration 89200 (19.0677 iter/s, 5.24448s/100 iters), loss = 0.0156796
I1005 16:43:57.740602  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156798 (* 1 = 0.0156798 loss)
I1005 16:43:57.740609  9606 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1005 16:44:02.998327  9606 solver.cpp:218] Iteration 89300 (19.0197 iter/s, 5.25771s/100 iters), loss = 0.00567434
I1005 16:44:02.998368  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567457 (* 1 = 0.00567457 loss)
I1005 16:44:02.998373  9606 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1005 16:44:08.252856  9606 solver.cpp:218] Iteration 89400 (19.0314 iter/s, 5.25447s/100 iters), loss = 0.0115601
I1005 16:44:08.252936  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115603 (* 1 = 0.0115603 loss)
I1005 16:44:08.252943  9606 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1005 16:44:13.247854  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:44:13.457602  9606 solver.cpp:330] Iteration 89500, Testing net (#0)
I1005 16:44:14.645354  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:44:14.694821  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1005 16:44:14.694857  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343544 (* 1 = 0.343544 loss)
I1005 16:44:14.746592  9606 solver.cpp:218] Iteration 89500 (15.3997 iter/s, 6.49364s/100 iters), loss = 0.0125628
I1005 16:44:14.746618  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125631 (* 1 = 0.0125631 loss)
I1005 16:44:14.746625  9606 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1005 16:44:20.004479  9606 solver.cpp:218] Iteration 89600 (19.0192 iter/s, 5.25785s/100 iters), loss = 0.00991348
I1005 16:44:20.004508  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00991372 (* 1 = 0.00991372 loss)
I1005 16:44:20.004515  9606 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1005 16:44:25.261909  9606 solver.cpp:218] Iteration 89700 (19.0209 iter/s, 5.25738s/100 iters), loss = 0.00768321
I1005 16:44:25.261945  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00768344 (* 1 = 0.00768344 loss)
I1005 16:44:25.261967  9606 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1005 16:44:30.509388  9606 solver.cpp:218] Iteration 89800 (19.0569 iter/s, 5.24743s/100 iters), loss = 0.00705594
I1005 16:44:30.509423  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705617 (* 1 = 0.00705617 loss)
I1005 16:44:30.509431  9606 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1005 16:44:35.764660  9606 solver.cpp:218] Iteration 89900 (19.0287 iter/s, 5.25522s/100 iters), loss = 0.00230406
I1005 16:44:35.764693  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230429 (* 1 = 0.00230429 loss)
I1005 16:44:35.764701  9606 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1005 16:44:40.756166  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:44:40.966475  9606 solver.cpp:330] Iteration 90000, Testing net (#0)
I1005 16:44:42.152963  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:44:42.202983  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1005 16:44:42.203011  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344112 (* 1 = 0.344112 loss)
I1005 16:44:42.254990  9606 solver.cpp:218] Iteration 90000 (15.4076 iter/s, 6.49028s/100 iters), loss = 0.0051381
I1005 16:44:42.255019  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513834 (* 1 = 0.00513834 loss)
I1005 16:44:42.255028  9606 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1005 16:44:47.504750  9606 solver.cpp:218] Iteration 90100 (19.0487 iter/s, 5.24971s/100 iters), loss = 0.0037806
I1005 16:44:47.504782  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00378083 (* 1 = 0.00378083 loss)
I1005 16:44:47.504801  9606 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1005 16:44:52.759621  9606 solver.cpp:218] Iteration 90200 (19.0301 iter/s, 5.25482s/100 iters), loss = 0.00591836
I1005 16:44:52.759654  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059186 (* 1 = 0.0059186 loss)
I1005 16:44:52.759661  9606 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1005 16:44:58.017252  9606 solver.cpp:218] Iteration 90300 (19.0202 iter/s, 5.25758s/100 iters), loss = 0.0180254
I1005 16:44:58.017290  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180256 (* 1 = 0.0180256 loss)
I1005 16:44:58.017309  9606 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1005 16:45:03.265808  9606 solver.cpp:218] Iteration 90400 (19.0532 iter/s, 5.24847s/100 iters), loss = 0.00419297
I1005 16:45:03.265841  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419322 (* 1 = 0.00419322 loss)
I1005 16:45:03.265859  9606 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1005 16:45:08.262755  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:45:08.472987  9606 solver.cpp:330] Iteration 90500, Testing net (#0)
I1005 16:45:09.659123  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:45:09.709120  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1005 16:45:09.709146  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343338 (* 1 = 0.343338 loss)
I1005 16:45:09.761360  9606 solver.cpp:218] Iteration 90500 (15.3953 iter/s, 6.4955s/100 iters), loss = 0.00477252
I1005 16:45:09.761415  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477278 (* 1 = 0.00477278 loss)
I1005 16:45:09.761440  9606 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1005 16:45:15.016309  9606 solver.cpp:218] Iteration 90600 (19.03 iter/s, 5.25486s/100 iters), loss = 0.00657705
I1005 16:45:15.016436  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0065773 (* 1 = 0.0065773 loss)
I1005 16:45:15.016456  9606 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1005 16:45:20.268340  9606 solver.cpp:218] Iteration 90700 (19.0407 iter/s, 5.2519s/100 iters), loss = 0.00448121
I1005 16:45:20.268373  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448146 (* 1 = 0.00448146 loss)
I1005 16:45:20.268390  9606 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1005 16:45:25.517817  9606 solver.cpp:218] Iteration 90800 (19.0497 iter/s, 5.24943s/100 iters), loss = 0.0102551
I1005 16:45:25.517849  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102553 (* 1 = 0.0102553 loss)
I1005 16:45:25.517868  9606 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1005 16:45:30.761934  9606 solver.cpp:218] Iteration 90900 (19.0692 iter/s, 5.24406s/100 iters), loss = 0.00242039
I1005 16:45:30.761979  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242063 (* 1 = 0.00242063 loss)
I1005 16:45:30.761998  9606 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1005 16:45:35.753003  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:45:35.962194  9606 solver.cpp:330] Iteration 91000, Testing net (#0)
I1005 16:45:37.158008  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:45:37.207816  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1005 16:45:37.207844  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34349 (* 1 = 0.34349 loss)
I1005 16:45:37.259979  9606 solver.cpp:218] Iteration 91000 (15.3895 iter/s, 6.49795s/100 iters), loss = 0.0201959
I1005 16:45:37.260015  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201962 (* 1 = 0.0201962 loss)
I1005 16:45:37.260025  9606 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1005 16:45:42.506772  9606 solver.cpp:218] Iteration 91100 (19.0595 iter/s, 5.24674s/100 iters), loss = 0.00662108
I1005 16:45:42.506805  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00662132 (* 1 = 0.00662132 loss)
I1005 16:45:42.506824  9606 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1005 16:45:47.761101  9606 solver.cpp:218] Iteration 91200 (19.0321 iter/s, 5.25428s/100 iters), loss = 0.017737
I1005 16:45:47.761237  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177373 (* 1 = 0.0177373 loss)
I1005 16:45:47.761263  9606 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1005 16:45:53.018965  9606 solver.cpp:218] Iteration 91300 (19.0196 iter/s, 5.25773s/100 iters), loss = 0.00972661
I1005 16:45:53.019006  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00972686 (* 1 = 0.00972686 loss)
I1005 16:45:53.019011  9606 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1005 16:45:58.281003  9606 solver.cpp:218] Iteration 91400 (19.0042 iter/s, 5.26198s/100 iters), loss = 0.0148774
I1005 16:45:58.281038  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148776 (* 1 = 0.0148776 loss)
I1005 16:45:58.281046  9606 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1005 16:46:03.263571  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:46:03.474243  9606 solver.cpp:330] Iteration 91500, Testing net (#0)
I1005 16:46:04.667655  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:46:04.717581  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1005 16:46:04.717607  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345099 (* 1 = 0.345099 loss)
I1005 16:46:04.770071  9606 solver.cpp:218] Iteration 91500 (15.4107 iter/s, 6.48902s/100 iters), loss = 0.0043038
I1005 16:46:04.770099  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430404 (* 1 = 0.00430404 loss)
I1005 16:46:04.770109  9606 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1005 16:46:10.022845  9606 solver.cpp:218] Iteration 91600 (19.0377 iter/s, 5.25272s/100 iters), loss = 0.00907127
I1005 16:46:10.022881  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00907151 (* 1 = 0.00907151 loss)
I1005 16:46:10.022900  9606 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1005 16:46:15.268157  9606 solver.cpp:218] Iteration 91700 (19.065 iter/s, 5.24522s/100 iters), loss = 0.00292436
I1005 16:46:15.268198  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029246 (* 1 = 0.0029246 loss)
I1005 16:46:15.268203  9606 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1005 16:46:20.522200  9606 solver.cpp:218] Iteration 91800 (19.0332 iter/s, 5.25399s/100 iters), loss = 0.00756163
I1005 16:46:20.522382  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00756187 (* 1 = 0.00756187 loss)
I1005 16:46:20.522394  9606 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1005 16:46:25.777390  9606 solver.cpp:218] Iteration 91900 (19.0295 iter/s, 5.25499s/100 iters), loss = 0.00127431
I1005 16:46:25.777441  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127455 (* 1 = 0.00127455 loss)
I1005 16:46:25.777458  9606 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1005 16:46:30.762393  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:46:30.980054  9606 solver.cpp:330] Iteration 92000, Testing net (#0)
I1005 16:46:32.168776  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:46:32.218367  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1005 16:46:32.218394  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34085 (* 1 = 0.34085 loss)
I1005 16:46:32.270668  9606 solver.cpp:218] Iteration 92000 (15.4007 iter/s, 6.49321s/100 iters), loss = 0.0133517
I1005 16:46:32.270699  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133519 (* 1 = 0.0133519 loss)
I1005 16:46:32.270710  9606 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1005 16:46:37.525526  9606 solver.cpp:218] Iteration 92100 (19.0302 iter/s, 5.25482s/100 iters), loss = 0.0119668
I1005 16:46:37.525557  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011967 (* 1 = 0.011967 loss)
I1005 16:46:37.525575  9606 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1005 16:46:42.771975  9606 solver.cpp:218] Iteration 92200 (19.0607 iter/s, 5.2464s/100 iters), loss = 0.00494629
I1005 16:46:42.772013  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00494652 (* 1 = 0.00494652 loss)
I1005 16:46:42.772022  9606 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1005 16:46:48.030355  9606 solver.cpp:218] Iteration 92300 (19.0175 iter/s, 5.25833s/100 iters), loss = 0.0101776
I1005 16:46:48.030395  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101778 (* 1 = 0.0101778 loss)
I1005 16:46:48.030400  9606 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1005 16:46:53.283800  9606 solver.cpp:218] Iteration 92400 (19.0353 iter/s, 5.25339s/100 iters), loss = 0.00694273
I1005 16:46:53.283918  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00694296 (* 1 = 0.00694296 loss)
I1005 16:46:53.283926  9606 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1005 16:46:58.279351  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:46:58.488548  9606 solver.cpp:330] Iteration 92500, Testing net (#0)
I1005 16:46:59.677283  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:46:59.725834  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1005 16:46:59.725859  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342917 (* 1 = 0.342917 loss)
I1005 16:46:59.778578  9606 solver.cpp:218] Iteration 92500 (15.3973 iter/s, 6.49465s/100 iters), loss = 0.0296612
I1005 16:46:59.778609  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296614 (* 1 = 0.0296614 loss)
I1005 16:46:59.778617  9606 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1005 16:47:05.049489  9606 solver.cpp:218] Iteration 92600 (18.9722 iter/s, 5.27086s/100 iters), loss = 0.00375546
I1005 16:47:05.049528  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375569 (* 1 = 0.00375569 loss)
I1005 16:47:05.049535  9606 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1005 16:47:10.298579  9606 solver.cpp:218] Iteration 92700 (19.0511 iter/s, 5.24903s/100 iters), loss = 0.00364092
I1005 16:47:10.298621  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364115 (* 1 = 0.00364115 loss)
I1005 16:47:10.298627  9606 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1005 16:47:15.543637  9606 solver.cpp:218] Iteration 92800 (19.0658 iter/s, 5.245s/100 iters), loss = 0.0158709
I1005 16:47:15.543678  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158711 (* 1 = 0.0158711 loss)
I1005 16:47:15.543684  9606 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1005 16:47:20.796727  9606 solver.cpp:218] Iteration 92900 (19.0366 iter/s, 5.25303s/100 iters), loss = 0.00465384
I1005 16:47:20.796757  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465406 (* 1 = 0.00465406 loss)
I1005 16:47:20.796763  9606 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1005 16:47:25.791266  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:47:25.999900  9606 solver.cpp:330] Iteration 93000, Testing net (#0)
I1005 16:47:27.184370  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:47:27.233021  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1005 16:47:27.233057  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340964 (* 1 = 0.340964 loss)
I1005 16:47:27.284590  9606 solver.cpp:218] Iteration 93000 (15.4135 iter/s, 6.48782s/100 iters), loss = 0.00456641
I1005 16:47:27.284626  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456663 (* 1 = 0.00456663 loss)
I1005 16:47:27.284633  9606 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1005 16:47:32.531954  9606 solver.cpp:218] Iteration 93100 (19.0574 iter/s, 5.24731s/100 iters), loss = 0.00491649
I1005 16:47:32.531983  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491671 (* 1 = 0.00491671 loss)
I1005 16:47:32.531988  9606 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1005 16:47:37.784024  9606 solver.cpp:218] Iteration 93200 (19.0403 iter/s, 5.25203s/100 iters), loss = 0.00228528
I1005 16:47:37.784054  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228549 (* 1 = 0.00228549 loss)
I1005 16:47:37.784060  9606 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1005 16:47:43.060264  9606 solver.cpp:218] Iteration 93300 (18.9531 iter/s, 5.27619s/100 iters), loss = 0.00649991
I1005 16:47:43.060302  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650013 (* 1 = 0.00650013 loss)
I1005 16:47:43.060308  9606 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1005 16:47:48.303671  9606 solver.cpp:218] Iteration 93400 (19.0718 iter/s, 5.24335s/100 iters), loss = 0.0030435
I1005 16:47:48.303714  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304372 (* 1 = 0.00304372 loss)
I1005 16:47:48.303719  9606 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1005 16:47:53.289533  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:47:53.499810  9606 solver.cpp:330] Iteration 93500, Testing net (#0)
I1005 16:47:54.687511  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:47:54.737449  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1005 16:47:54.737476  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343324 (* 1 = 0.343324 loss)
I1005 16:47:54.790038  9606 solver.cpp:218] Iteration 93500 (15.4171 iter/s, 6.48631s/100 iters), loss = 0.00835153
I1005 16:47:54.790089  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00835175 (* 1 = 0.00835175 loss)
I1005 16:47:54.790107  9606 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1005 16:48:00.040581  9606 solver.cpp:218] Iteration 93600 (19.046 iter/s, 5.25045s/100 iters), loss = 0.0285208
I1005 16:48:00.040693  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028521 (* 1 = 0.028521 loss)
I1005 16:48:00.040699  9606 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1005 16:48:05.293963  9606 solver.cpp:218] Iteration 93700 (19.0358 iter/s, 5.25326s/100 iters), loss = 0.00466074
I1005 16:48:05.293993  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466096 (* 1 = 0.00466096 loss)
I1005 16:48:05.293998  9606 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1005 16:48:10.549499  9606 solver.cpp:218] Iteration 93800 (19.0277 iter/s, 5.25549s/100 iters), loss = 0.0179592
I1005 16:48:10.549530  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179594 (* 1 = 0.0179594 loss)
I1005 16:48:10.549535  9606 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1005 16:48:15.799032  9606 solver.cpp:218] Iteration 93900 (19.0495 iter/s, 5.24948s/100 iters), loss = 0.00240977
I1005 16:48:15.799079  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241 (* 1 = 0.00241 loss)
I1005 16:48:15.799087  9606 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1005 16:48:20.792111  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:48:21.001431  9606 solver.cpp:330] Iteration 94000, Testing net (#0)
I1005 16:48:22.194934  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:48:22.244489  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1005 16:48:22.244514  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34333 (* 1 = 0.34333 loss)
I1005 16:48:22.296658  9606 solver.cpp:218] Iteration 94000 (15.3905 iter/s, 6.49753s/100 iters), loss = 0.00273116
I1005 16:48:22.296690  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273139 (* 1 = 0.00273139 loss)
I1005 16:48:22.296697  9606 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1005 16:48:27.544630  9606 solver.cpp:218] Iteration 94100 (19.0552 iter/s, 5.24792s/100 iters), loss = 0.007553
I1005 16:48:27.544659  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755323 (* 1 = 0.00755323 loss)
I1005 16:48:27.544667  9606 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1005 16:48:32.793561  9606 solver.cpp:218] Iteration 94200 (19.0517 iter/s, 5.24888s/100 iters), loss = 0.0143449
I1005 16:48:32.793697  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143452 (* 1 = 0.0143452 loss)
I1005 16:48:32.793742  9606 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1005 16:48:38.043949  9606 solver.cpp:218] Iteration 94300 (19.0467 iter/s, 5.25025s/100 iters), loss = 0.00414231
I1005 16:48:38.043982  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414254 (* 1 = 0.00414254 loss)
I1005 16:48:38.043989  9606 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1005 16:48:43.298017  9606 solver.cpp:218] Iteration 94400 (19.033 iter/s, 5.25402s/100 iters), loss = 0.0250421
I1005 16:48:43.298051  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250423 (* 1 = 0.0250423 loss)
I1005 16:48:43.298069  9606 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1005 16:48:48.284463  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:48:48.494180  9606 solver.cpp:330] Iteration 94500, Testing net (#0)
I1005 16:48:49.687525  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:48:49.737211  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1005 16:48:49.737237  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343121 (* 1 = 0.343121 loss)
I1005 16:48:49.789315  9606 solver.cpp:218] Iteration 94500 (15.4053 iter/s, 6.49125s/100 iters), loss = 0.0145193
I1005 16:48:49.789343  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145195 (* 1 = 0.0145195 loss)
I1005 16:48:49.789362  9606 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1005 16:48:55.047328  9606 solver.cpp:218] Iteration 94600 (19.0188 iter/s, 5.25796s/100 iters), loss = 0.00491172
I1005 16:48:55.047368  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491196 (* 1 = 0.00491196 loss)
I1005 16:48:55.047387  9606 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1005 16:49:00.293902  9606 solver.cpp:218] Iteration 94700 (19.0604 iter/s, 5.24649s/100 iters), loss = 0.00867363
I1005 16:49:00.293933  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867387 (* 1 = 0.00867387 loss)
I1005 16:49:00.293949  9606 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1005 16:49:05.549464  9606 solver.cpp:218] Iteration 94800 (19.0276 iter/s, 5.25551s/100 iters), loss = 0.00323757
I1005 16:49:05.549610  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032378 (* 1 = 0.0032378 loss)
I1005 16:49:05.549638  9606 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1005 16:49:10.806543  9606 solver.cpp:218] Iteration 94900 (19.0225 iter/s, 5.25692s/100 iters), loss = 0.00495753
I1005 16:49:10.806577  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495777 (* 1 = 0.00495777 loss)
I1005 16:49:10.806596  9606 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1005 16:49:15.792129  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:49:16.006784  9606 solver.cpp:330] Iteration 95000, Testing net (#0)
I1005 16:49:17.193775  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:49:17.243649  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1005 16:49:17.243675  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344456 (* 1 = 0.344456 loss)
I1005 16:49:17.296063  9606 solver.cpp:218] Iteration 95000 (15.4096 iter/s, 6.48947s/100 iters), loss = 0.001161
I1005 16:49:17.296092  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116123 (* 1 = 0.00116123 loss)
I1005 16:49:17.296103  9606 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1005 16:49:22.551934  9606 solver.cpp:218] Iteration 95100 (19.0265 iter/s, 5.25583s/100 iters), loss = 0.00953731
I1005 16:49:22.551965  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00953754 (* 1 = 0.00953754 loss)
I1005 16:49:22.551973  9606 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1005 16:49:27.796108  9606 solver.cpp:218] Iteration 95200 (19.069 iter/s, 5.24412s/100 iters), loss = 0.00434557
I1005 16:49:27.796144  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434579 (* 1 = 0.00434579 loss)
I1005 16:49:27.796164  9606 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1005 16:49:33.047382  9606 solver.cpp:218] Iteration 95300 (19.0433 iter/s, 5.25119s/100 iters), loss = 0.00471711
I1005 16:49:33.047415  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471732 (* 1 = 0.00471732 loss)
I1005 16:49:33.047422  9606 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1005 16:49:38.303249  9606 solver.cpp:218] Iteration 95400 (19.0265 iter/s, 5.25582s/100 iters), loss = 0.0089279
I1005 16:49:38.303377  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00892812 (* 1 = 0.00892812 loss)
I1005 16:49:38.303390  9606 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1005 16:49:43.296615  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:49:43.507181  9606 solver.cpp:330] Iteration 95500, Testing net (#0)
I1005 16:49:44.692036  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:49:44.741858  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1005 16:49:44.741892  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342465 (* 1 = 0.342465 loss)
I1005 16:49:44.793974  9606 solver.cpp:218] Iteration 95500 (15.4069 iter/s, 6.49061s/100 iters), loss = 0.0107234
I1005 16:49:44.794000  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107237 (* 1 = 0.0107237 loss)
I1005 16:49:44.794008  9606 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1005 16:49:50.054777  9606 solver.cpp:218] Iteration 95600 (19.0087 iter/s, 5.26076s/100 iters), loss = 0.0171787
I1005 16:49:50.054806  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171789 (* 1 = 0.0171789 loss)
I1005 16:49:50.054812  9606 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1005 16:49:55.310163  9606 solver.cpp:218] Iteration 95700 (19.0283 iter/s, 5.25534s/100 iters), loss = 0.00660784
I1005 16:49:55.310205  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660806 (* 1 = 0.00660806 loss)
I1005 16:49:55.310211  9606 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1005 16:50:00.556982  9606 solver.cpp:218] Iteration 95800 (19.0594 iter/s, 5.24676s/100 iters), loss = 0.0102862
I1005 16:50:00.557013  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102865 (* 1 = 0.0102865 loss)
I1005 16:50:00.557018  9606 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1005 16:50:05.811754  9606 solver.cpp:218] Iteration 95900 (19.0305 iter/s, 5.25473s/100 iters), loss = 0.00168287
I1005 16:50:05.811795  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168308 (* 1 = 0.00168308 loss)
I1005 16:50:05.811801  9606 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1005 16:50:10.803215  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:50:11.012987  9606 solver.cpp:330] Iteration 96000, Testing net (#0)
I1005 16:50:12.198573  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:50:12.248481  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1005 16:50:12.248517  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343066 (* 1 = 0.343066 loss)
I1005 16:50:12.300412  9606 solver.cpp:218] Iteration 96000 (15.4116 iter/s, 6.4886s/100 iters), loss = 0.00210116
I1005 16:50:12.300449  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210137 (* 1 = 0.00210137 loss)
I1005 16:50:12.300457  9606 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1005 16:50:17.552517  9606 solver.cpp:218] Iteration 96100 (19.0402 iter/s, 5.25205s/100 iters), loss = 0.0103365
I1005 16:50:17.552546  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103367 (* 1 = 0.0103367 loss)
I1005 16:50:17.552552  9606 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1005 16:50:22.811079  9606 solver.cpp:218] Iteration 96200 (19.0168 iter/s, 5.25851s/100 iters), loss = 0.00897395
I1005 16:50:22.811120  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00897416 (* 1 = 0.00897416 loss)
I1005 16:50:22.811126  9606 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1005 16:50:28.068723  9606 solver.cpp:218] Iteration 96300 (19.0201 iter/s, 5.25758s/100 iters), loss = 0.00895497
I1005 16:50:28.068769  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895518 (* 1 = 0.00895518 loss)
I1005 16:50:28.068776  9606 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1005 16:50:33.316723  9606 solver.cpp:218] Iteration 96400 (19.0552 iter/s, 5.2479s/100 iters), loss = 0.00120371
I1005 16:50:33.316764  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120392 (* 1 = 0.00120392 loss)
I1005 16:50:33.316771  9606 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1005 16:50:38.312503  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:50:38.522788  9606 solver.cpp:330] Iteration 96500, Testing net (#0)
I1005 16:50:39.709842  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:50:39.759680  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I1005 16:50:39.759714  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344999 (* 1 = 0.344999 loss)
I1005 16:50:39.812937  9606 solver.cpp:218] Iteration 96500 (15.3937 iter/s, 6.49615s/100 iters), loss = 0.00830981
I1005 16:50:39.812983  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831002 (* 1 = 0.00831002 loss)
I1005 16:50:39.812990  9606 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1005 16:50:45.070366  9606 solver.cpp:218] Iteration 96600 (19.0211 iter/s, 5.25733s/100 iters), loss = 0.0185153
I1005 16:50:45.070464  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185155 (* 1 = 0.0185155 loss)
I1005 16:50:45.070480  9606 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1005 16:50:50.328943  9606 solver.cpp:218] Iteration 96700 (19.017 iter/s, 5.25846s/100 iters), loss = 0.00395865
I1005 16:50:50.328972  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395886 (* 1 = 0.00395886 loss)
I1005 16:50:50.328979  9606 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1005 16:50:55.582228  9606 solver.cpp:218] Iteration 96800 (19.0359 iter/s, 5.25324s/100 iters), loss = 0.00439113
I1005 16:50:55.582260  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439134 (* 1 = 0.00439134 loss)
I1005 16:50:55.582276  9606 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1005 16:51:00.830032  9606 solver.cpp:218] Iteration 96900 (19.0558 iter/s, 5.24776s/100 iters), loss = 0.00521666
I1005 16:51:00.830067  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521687 (* 1 = 0.00521687 loss)
I1005 16:51:00.830075  9606 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1005 16:51:05.817729  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:51:06.027624  9606 solver.cpp:330] Iteration 97000, Testing net (#0)
I1005 16:51:07.217736  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:51:07.267572  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1005 16:51:07.267607  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344638 (* 1 = 0.344638 loss)
I1005 16:51:07.319586  9606 solver.cpp:218] Iteration 97000 (15.4095 iter/s, 6.4895s/100 iters), loss = 0.00671832
I1005 16:51:07.319617  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671853 (* 1 = 0.00671853 loss)
I1005 16:51:07.319624  9606 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1005 16:51:12.568737  9606 solver.cpp:218] Iteration 97100 (19.0509 iter/s, 5.2491s/100 iters), loss = 0.00546844
I1005 16:51:12.568776  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546865 (* 1 = 0.00546865 loss)
I1005 16:51:12.568783  9606 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1005 16:51:17.828274  9606 solver.cpp:218] Iteration 97200 (19.0133 iter/s, 5.25948s/100 iters), loss = 0.0111308
I1005 16:51:17.828402  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011131 (* 1 = 0.011131 loss)
I1005 16:51:17.828419  9606 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1005 16:51:23.088604  9606 solver.cpp:218] Iteration 97300 (19.0107 iter/s, 5.26019s/100 iters), loss = 0.0121591
I1005 16:51:23.088644  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121593 (* 1 = 0.0121593 loss)
I1005 16:51:23.088650  9606 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1005 16:51:28.350010  9606 solver.cpp:218] Iteration 97400 (19.0065 iter/s, 5.26135s/100 iters), loss = 0.00310983
I1005 16:51:28.350044  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311004 (* 1 = 0.00311004 loss)
I1005 16:51:28.350050  9606 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1005 16:51:33.337533  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:51:33.547550  9606 solver.cpp:330] Iteration 97500, Testing net (#0)
I1005 16:51:34.743585  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:51:34.793409  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1005 16:51:34.793444  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343973 (* 1 = 0.343973 loss)
I1005 16:51:34.845522  9606 solver.cpp:218] Iteration 97500 (15.3954 iter/s, 6.49547s/100 iters), loss = 0.0099302
I1005 16:51:34.845551  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00993042 (* 1 = 0.00993042 loss)
I1005 16:51:34.845558  9606 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1005 16:51:40.098503  9606 solver.cpp:218] Iteration 97600 (19.037 iter/s, 5.25294s/100 iters), loss = 0.00812756
I1005 16:51:40.098539  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00812777 (* 1 = 0.00812777 loss)
I1005 16:51:40.098546  9606 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1005 16:51:45.342283  9606 solver.cpp:218] Iteration 97700 (19.0704 iter/s, 5.24373s/100 iters), loss = 0.00813201
I1005 16:51:45.342325  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00813222 (* 1 = 0.00813222 loss)
I1005 16:51:45.342331  9606 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1005 16:51:50.592659  9606 solver.cpp:218] Iteration 97800 (19.0465 iter/s, 5.25032s/100 iters), loss = 0.00615228
I1005 16:51:50.592778  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615248 (* 1 = 0.00615248 loss)
I1005 16:51:50.592785  9606 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1005 16:51:55.847041  9606 solver.cpp:218] Iteration 97900 (19.0322 iter/s, 5.25425s/100 iters), loss = 0.00379019
I1005 16:51:55.847071  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379039 (* 1 = 0.00379039 loss)
I1005 16:51:55.847076  9606 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1005 16:52:00.833576  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:52:01.050797  9606 solver.cpp:330] Iteration 98000, Testing net (#0)
I1005 16:52:02.238279  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:52:02.287175  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1005 16:52:02.287211  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345168 (* 1 = 0.345168 loss)
I1005 16:52:02.339447  9606 solver.cpp:218] Iteration 98000 (15.4027 iter/s, 6.49236s/100 iters), loss = 0.00972815
I1005 16:52:02.339475  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00972836 (* 1 = 0.00972836 loss)
I1005 16:52:02.339483  9606 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1005 16:52:07.600088  9606 solver.cpp:218] Iteration 98100 (19.0093 iter/s, 5.2606s/100 iters), loss = 0.00865807
I1005 16:52:07.600119  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00865828 (* 1 = 0.00865828 loss)
I1005 16:52:07.600126  9606 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1005 16:52:12.852826  9606 solver.cpp:218] Iteration 98200 (19.0379 iter/s, 5.25269s/100 iters), loss = 0.00206886
I1005 16:52:12.852864  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206906 (* 1 = 0.00206906 loss)
I1005 16:52:12.852871  9606 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1005 16:52:18.109699  9606 solver.cpp:218] Iteration 98300 (19.0229 iter/s, 5.25682s/100 iters), loss = 0.00557842
I1005 16:52:18.109738  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557862 (* 1 = 0.00557862 loss)
I1005 16:52:18.109745  9606 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1005 16:52:23.370932  9606 solver.cpp:218] Iteration 98400 (19.0072 iter/s, 5.26118s/100 iters), loss = 0.00412993
I1005 16:52:23.371063  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413013 (* 1 = 0.00413013 loss)
I1005 16:52:23.371071  9606 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1005 16:52:28.362853  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:52:28.572295  9606 solver.cpp:330] Iteration 98500, Testing net (#0)
I1005 16:52:29.760470  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:52:29.810276  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1005 16:52:29.810300  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346749 (* 1 = 0.346749 loss)
I1005 16:52:29.862462  9606 solver.cpp:218] Iteration 98500 (15.405 iter/s, 6.49139s/100 iters), loss = 0.0103608
I1005 16:52:29.862488  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010361 (* 1 = 0.010361 loss)
I1005 16:52:29.862494  9606 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1005 16:52:35.117403  9606 solver.cpp:218] Iteration 98600 (19.0299 iter/s, 5.25489s/100 iters), loss = 0.00739654
I1005 16:52:35.117444  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00739674 (* 1 = 0.00739674 loss)
I1005 16:52:35.117450  9606 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1005 16:52:40.371218  9606 solver.cpp:218] Iteration 98700 (19.034 iter/s, 5.25376s/100 iters), loss = 0.011621
I1005 16:52:40.371249  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116212 (* 1 = 0.0116212 loss)
I1005 16:52:40.371255  9606 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1005 16:52:45.620748  9606 solver.cpp:218] Iteration 98800 (19.0495 iter/s, 5.24948s/100 iters), loss = 0.00506065
I1005 16:52:45.620790  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00506085 (* 1 = 0.00506085 loss)
I1005 16:52:45.620796  9606 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1005 16:52:50.879246  9606 solver.cpp:218] Iteration 98900 (19.017 iter/s, 5.25844s/100 iters), loss = 0.00560091
I1005 16:52:50.879276  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00560111 (* 1 = 0.00560111 loss)
I1005 16:52:50.879281  9606 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1005 16:52:55.878398  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:52:56.088239  9606 solver.cpp:330] Iteration 99000, Testing net (#0)
I1005 16:52:57.273356  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:52:57.323046  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1005 16:52:57.323072  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348714 (* 1 = 0.348714 loss)
I1005 16:52:57.375574  9606 solver.cpp:218] Iteration 99000 (15.3934 iter/s, 6.49628s/100 iters), loss = 0.00512554
I1005 16:52:57.375603  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512574 (* 1 = 0.00512574 loss)
I1005 16:52:57.375610  9606 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1005 16:53:02.634366  9606 solver.cpp:218] Iteration 99100 (19.0159 iter/s, 5.25875s/100 iters), loss = 0.010317
I1005 16:53:02.634395  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103172 (* 1 = 0.0103172 loss)
I1005 16:53:02.634402  9606 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1005 16:53:07.892339  9606 solver.cpp:218] Iteration 99200 (19.0189 iter/s, 5.25793s/100 iters), loss = 0.00733572
I1005 16:53:07.892370  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00733593 (* 1 = 0.00733593 loss)
I1005 16:53:07.892376  9606 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1005 16:53:13.152505  9606 solver.cpp:218] Iteration 99300 (19.011 iter/s, 5.26012s/100 iters), loss = 0.00690747
I1005 16:53:13.152534  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00690768 (* 1 = 0.00690768 loss)
I1005 16:53:13.152541  9606 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1005 16:53:18.398735  9606 solver.cpp:218] Iteration 99400 (19.0615 iter/s, 5.24618s/100 iters), loss = 0.00240281
I1005 16:53:18.398777  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240303 (* 1 = 0.00240303 loss)
I1005 16:53:18.398782  9606 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1005 16:53:23.387555  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:53:23.597657  9606 solver.cpp:330] Iteration 99500, Testing net (#0)
I1005 16:53:24.783700  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:53:24.833806  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1005 16:53:24.833832  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346904 (* 1 = 0.346904 loss)
I1005 16:53:24.887342  9606 solver.cpp:218] Iteration 99500 (15.4118 iter/s, 6.48855s/100 iters), loss = 0.00926603
I1005 16:53:24.887377  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00926624 (* 1 = 0.00926624 loss)
I1005 16:53:24.887385  9606 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1005 16:53:30.142144  9606 solver.cpp:218] Iteration 99600 (19.0304 iter/s, 5.25475s/100 iters), loss = 0.00867131
I1005 16:53:30.142253  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867153 (* 1 = 0.00867153 loss)
I1005 16:53:30.142261  9606 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1005 16:53:35.399758  9606 solver.cpp:218] Iteration 99700 (19.0205 iter/s, 5.25749s/100 iters), loss = 0.00362523
I1005 16:53:35.399788  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362545 (* 1 = 0.00362545 loss)
I1005 16:53:35.399794  9606 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1005 16:53:40.661929  9606 solver.cpp:218] Iteration 99800 (19.0038 iter/s, 5.26212s/100 iters), loss = 0.00211203
I1005 16:53:40.661959  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211224 (* 1 = 0.00211224 loss)
I1005 16:53:40.661965  9606 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1005 16:53:45.918114  9606 solver.cpp:218] Iteration 99900 (19.0254 iter/s, 5.25613s/100 iters), loss = 0.00422597
I1005 16:53:45.918150  9606 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422619 (* 1 = 0.00422619 loss)
I1005 16:53:45.918159  9606 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1005 16:53:50.910027  9614 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:53:51.119593  9606 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha1_beta1_2study_2decay_gauss_iter_100000.caffemodel
I1005 16:53:51.127678  9606 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_alpha1_beta1_2study_2decay_gauss_iter_100000.solverstate
I1005 16:53:51.141659  9606 solver.cpp:310] Iteration 100000, loss = 0.00651615
I1005 16:53:51.141681  9606 solver.cpp:330] Iteration 100000, Testing net (#0)
I1005 16:53:52.336978  9615 data_layer.cpp:73] Restarting data prefetching from start.
I1005 16:53:52.387207  9606 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1005 16:53:52.387233  9606 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34666 (* 1 = 0.34666 loss)
I1005 16:53:52.387236  9606 solver.cpp:315] Optimization Done.
I1005 16:53:52.387239  9606 caffe.cpp:259] Optimization Done.
