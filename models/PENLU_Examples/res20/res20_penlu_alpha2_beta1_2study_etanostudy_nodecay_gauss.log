I0930 20:11:10.180878  4070 caffe.cpp:218] Using GPUs 0
I0930 20:11:10.218613  4070 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0930 20:11:10.446496  4070 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I0930 20:11:10.446658  4070 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:11:10.448184  4070 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:11:10.448194  4070 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0930 20:11:10.448338  4070 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0930 20:11:10.448411  4070 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0930 20:11:10.448886  4070 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0930 20:11:10.449249  4070 layer_factory.hpp:77] Creating layer Data1
I0930 20:11:10.449327  4070 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I0930 20:11:10.449352  4070 net.cpp:84] Creating Layer Data1
I0930 20:11:10.449357  4070 net.cpp:380] Data1 -> Data1
I0930 20:11:10.449375  4070 net.cpp:380] Data1 -> Data2
I0930 20:11:10.449383  4070 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0930 20:11:10.450825  4070 data_layer.cpp:45] output data size: 100,3,28,28
I0930 20:11:10.453088  4070 net.cpp:122] Setting up Data1
I0930 20:11:10.453100  4070 net.cpp:129] Top shape: 100 3 28 28 (235200)
I0930 20:11:10.453104  4070 net.cpp:129] Top shape: 100 (100)
I0930 20:11:10.453107  4070 net.cpp:137] Memory required for data: 941200
I0930 20:11:10.453112  4070 layer_factory.hpp:77] Creating layer Convolution1
I0930 20:11:10.453130  4070 net.cpp:84] Creating Layer Convolution1
I0930 20:11:10.453135  4070 net.cpp:406] Convolution1 <- Data1
I0930 20:11:10.453145  4070 net.cpp:380] Convolution1 -> Convolution1
I0930 20:11:10.605248  4070 net.cpp:122] Setting up Convolution1
I0930 20:11:10.605273  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.605275  4070 net.cpp:137] Memory required for data: 5958800
I0930 20:11:10.605290  4070 layer_factory.hpp:77] Creating layer BatchNorm1
I0930 20:11:10.605305  4070 net.cpp:84] Creating Layer BatchNorm1
I0930 20:11:10.605324  4070 net.cpp:406] BatchNorm1 <- Convolution1
I0930 20:11:10.605331  4070 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0930 20:11:10.605473  4070 net.cpp:122] Setting up BatchNorm1
I0930 20:11:10.605480  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.605484  4070 net.cpp:137] Memory required for data: 10976400
I0930 20:11:10.605491  4070 layer_factory.hpp:77] Creating layer Scale1
I0930 20:11:10.605500  4070 net.cpp:84] Creating Layer Scale1
I0930 20:11:10.605504  4070 net.cpp:406] Scale1 <- Convolution1
I0930 20:11:10.605510  4070 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0930 20:11:10.605569  4070 layer_factory.hpp:77] Creating layer Scale1
I0930 20:11:10.605679  4070 net.cpp:122] Setting up Scale1
I0930 20:11:10.605685  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.605698  4070 net.cpp:137] Memory required for data: 15994000
I0930 20:11:10.605705  4070 layer_factory.hpp:77] Creating layer penlu1
I0930 20:11:10.605718  4070 net.cpp:84] Creating Layer penlu1
I0930 20:11:10.605725  4070 net.cpp:406] penlu1 <- Convolution1
I0930 20:11:10.605741  4070 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0930 20:11:10.606367  4070 net.cpp:122] Setting up penlu1
I0930 20:11:10.606377  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.606391  4070 net.cpp:137] Memory required for data: 21011600
I0930 20:11:10.606401  4070 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0930 20:11:10.606420  4070 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0930 20:11:10.606425  4070 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0930 20:11:10.606432  4070 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0930 20:11:10.606452  4070 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0930 20:11:10.606494  4070 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0930 20:11:10.606500  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.606506  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.606511  4070 net.cpp:137] Memory required for data: 31046800
I0930 20:11:10.606518  4070 layer_factory.hpp:77] Creating layer Convolution2
I0930 20:11:10.606546  4070 net.cpp:84] Creating Layer Convolution2
I0930 20:11:10.606552  4070 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0930 20:11:10.606559  4070 net.cpp:380] Convolution2 -> Convolution2
I0930 20:11:10.607424  4070 net.cpp:122] Setting up Convolution2
I0930 20:11:10.607434  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.607447  4070 net.cpp:137] Memory required for data: 36064400
I0930 20:11:10.607452  4070 layer_factory.hpp:77] Creating layer BatchNorm2
I0930 20:11:10.607473  4070 net.cpp:84] Creating Layer BatchNorm2
I0930 20:11:10.607481  4070 net.cpp:406] BatchNorm2 <- Convolution2
I0930 20:11:10.607486  4070 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0930 20:11:10.607622  4070 net.cpp:122] Setting up BatchNorm2
I0930 20:11:10.607630  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.607642  4070 net.cpp:137] Memory required for data: 41082000
I0930 20:11:10.607647  4070 layer_factory.hpp:77] Creating layer Scale2
I0930 20:11:10.607653  4070 net.cpp:84] Creating Layer Scale2
I0930 20:11:10.607661  4070 net.cpp:406] Scale2 <- Convolution2
I0930 20:11:10.607667  4070 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0930 20:11:10.607707  4070 layer_factory.hpp:77] Creating layer Scale2
I0930 20:11:10.607789  4070 net.cpp:122] Setting up Scale2
I0930 20:11:10.607795  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.607800  4070 net.cpp:137] Memory required for data: 46099600
I0930 20:11:10.607811  4070 layer_factory.hpp:77] Creating layer penlu2
I0930 20:11:10.607821  4070 net.cpp:84] Creating Layer penlu2
I0930 20:11:10.607826  4070 net.cpp:406] penlu2 <- Convolution2
I0930 20:11:10.607831  4070 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0930 20:11:10.607929  4070 net.cpp:122] Setting up penlu2
I0930 20:11:10.607935  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.607939  4070 net.cpp:137] Memory required for data: 51117200
I0930 20:11:10.607944  4070 layer_factory.hpp:77] Creating layer Convolution3
I0930 20:11:10.607951  4070 net.cpp:84] Creating Layer Convolution3
I0930 20:11:10.607954  4070 net.cpp:406] Convolution3 <- Convolution2
I0930 20:11:10.607959  4070 net.cpp:380] Convolution3 -> Convolution3
I0930 20:11:10.608803  4070 net.cpp:122] Setting up Convolution3
I0930 20:11:10.608814  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.608819  4070 net.cpp:137] Memory required for data: 56134800
I0930 20:11:10.608824  4070 layer_factory.hpp:77] Creating layer BatchNorm3
I0930 20:11:10.608829  4070 net.cpp:84] Creating Layer BatchNorm3
I0930 20:11:10.608832  4070 net.cpp:406] BatchNorm3 <- Convolution3
I0930 20:11:10.608836  4070 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0930 20:11:10.608954  4070 net.cpp:122] Setting up BatchNorm3
I0930 20:11:10.608960  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.608963  4070 net.cpp:137] Memory required for data: 61152400
I0930 20:11:10.608968  4070 layer_factory.hpp:77] Creating layer Scale3
I0930 20:11:10.608973  4070 net.cpp:84] Creating Layer Scale3
I0930 20:11:10.608976  4070 net.cpp:406] Scale3 <- Convolution3
I0930 20:11:10.608980  4070 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0930 20:11:10.609004  4070 layer_factory.hpp:77] Creating layer Scale3
I0930 20:11:10.609086  4070 net.cpp:122] Setting up Scale3
I0930 20:11:10.609092  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.609096  4070 net.cpp:137] Memory required for data: 66170000
I0930 20:11:10.609099  4070 layer_factory.hpp:77] Creating layer Eltwise1
I0930 20:11:10.609104  4070 net.cpp:84] Creating Layer Eltwise1
I0930 20:11:10.609107  4070 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0930 20:11:10.609110  4070 net.cpp:406] Eltwise1 <- Convolution3
I0930 20:11:10.609113  4070 net.cpp:380] Eltwise1 -> Eltwise1
I0930 20:11:10.609133  4070 net.cpp:122] Setting up Eltwise1
I0930 20:11:10.609148  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.609149  4070 net.cpp:137] Memory required for data: 71187600
I0930 20:11:10.609163  4070 layer_factory.hpp:77] Creating layer penlu3
I0930 20:11:10.609167  4070 net.cpp:84] Creating Layer penlu3
I0930 20:11:10.609169  4070 net.cpp:406] penlu3 <- Eltwise1
I0930 20:11:10.609174  4070 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0930 20:11:10.609289  4070 net.cpp:122] Setting up penlu3
I0930 20:11:10.609295  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.609298  4070 net.cpp:137] Memory required for data: 76205200
I0930 20:11:10.609310  4070 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0930 20:11:10.609315  4070 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0930 20:11:10.609318  4070 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0930 20:11:10.609321  4070 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0930 20:11:10.609326  4070 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0930 20:11:10.609349  4070 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0930 20:11:10.609355  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.609359  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.609361  4070 net.cpp:137] Memory required for data: 86240400
I0930 20:11:10.609364  4070 layer_factory.hpp:77] Creating layer Convolution4
I0930 20:11:10.609371  4070 net.cpp:84] Creating Layer Convolution4
I0930 20:11:10.609375  4070 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0930 20:11:10.609378  4070 net.cpp:380] Convolution4 -> Convolution4
I0930 20:11:10.610229  4070 net.cpp:122] Setting up Convolution4
I0930 20:11:10.610239  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.610244  4070 net.cpp:137] Memory required for data: 91258000
I0930 20:11:10.610249  4070 layer_factory.hpp:77] Creating layer BatchNorm4
I0930 20:11:10.610255  4070 net.cpp:84] Creating Layer BatchNorm4
I0930 20:11:10.610257  4070 net.cpp:406] BatchNorm4 <- Convolution4
I0930 20:11:10.610261  4070 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0930 20:11:10.610379  4070 net.cpp:122] Setting up BatchNorm4
I0930 20:11:10.610385  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.610388  4070 net.cpp:137] Memory required for data: 96275600
I0930 20:11:10.610396  4070 layer_factory.hpp:77] Creating layer Scale4
I0930 20:11:10.610401  4070 net.cpp:84] Creating Layer Scale4
I0930 20:11:10.610404  4070 net.cpp:406] Scale4 <- Convolution4
I0930 20:11:10.610407  4070 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0930 20:11:10.610432  4070 layer_factory.hpp:77] Creating layer Scale4
I0930 20:11:10.610515  4070 net.cpp:122] Setting up Scale4
I0930 20:11:10.610527  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.610529  4070 net.cpp:137] Memory required for data: 101293200
I0930 20:11:10.610533  4070 layer_factory.hpp:77] Creating layer penlu4
I0930 20:11:10.610539  4070 net.cpp:84] Creating Layer penlu4
I0930 20:11:10.610543  4070 net.cpp:406] penlu4 <- Convolution4
I0930 20:11:10.610548  4070 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0930 20:11:10.610649  4070 net.cpp:122] Setting up penlu4
I0930 20:11:10.610654  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.610657  4070 net.cpp:137] Memory required for data: 106310800
I0930 20:11:10.610662  4070 layer_factory.hpp:77] Creating layer Convolution5
I0930 20:11:10.610669  4070 net.cpp:84] Creating Layer Convolution5
I0930 20:11:10.610673  4070 net.cpp:406] Convolution5 <- Convolution4
I0930 20:11:10.610677  4070 net.cpp:380] Convolution5 -> Convolution5
I0930 20:11:10.611596  4070 net.cpp:122] Setting up Convolution5
I0930 20:11:10.611608  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.611611  4070 net.cpp:137] Memory required for data: 111328400
I0930 20:11:10.611615  4070 layer_factory.hpp:77] Creating layer BatchNorm5
I0930 20:11:10.611624  4070 net.cpp:84] Creating Layer BatchNorm5
I0930 20:11:10.611627  4070 net.cpp:406] BatchNorm5 <- Convolution5
I0930 20:11:10.611631  4070 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0930 20:11:10.611778  4070 net.cpp:122] Setting up BatchNorm5
I0930 20:11:10.611784  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.611786  4070 net.cpp:137] Memory required for data: 116346000
I0930 20:11:10.611791  4070 layer_factory.hpp:77] Creating layer Scale5
I0930 20:11:10.611798  4070 net.cpp:84] Creating Layer Scale5
I0930 20:11:10.611800  4070 net.cpp:406] Scale5 <- Convolution5
I0930 20:11:10.611804  4070 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0930 20:11:10.611830  4070 layer_factory.hpp:77] Creating layer Scale5
I0930 20:11:10.611918  4070 net.cpp:122] Setting up Scale5
I0930 20:11:10.611925  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.611927  4070 net.cpp:137] Memory required for data: 121363600
I0930 20:11:10.611932  4070 layer_factory.hpp:77] Creating layer Eltwise2
I0930 20:11:10.611937  4070 net.cpp:84] Creating Layer Eltwise2
I0930 20:11:10.611940  4070 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0930 20:11:10.611944  4070 net.cpp:406] Eltwise2 <- Convolution5
I0930 20:11:10.611948  4070 net.cpp:380] Eltwise2 -> Eltwise2
I0930 20:11:10.611964  4070 net.cpp:122] Setting up Eltwise2
I0930 20:11:10.611969  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.611971  4070 net.cpp:137] Memory required for data: 126381200
I0930 20:11:10.611974  4070 layer_factory.hpp:77] Creating layer penlu5
I0930 20:11:10.611979  4070 net.cpp:84] Creating Layer penlu5
I0930 20:11:10.611982  4070 net.cpp:406] penlu5 <- Eltwise2
I0930 20:11:10.611986  4070 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0930 20:11:10.612089  4070 net.cpp:122] Setting up penlu5
I0930 20:11:10.612095  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.612098  4070 net.cpp:137] Memory required for data: 131398800
I0930 20:11:10.612103  4070 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0930 20:11:10.612107  4070 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0930 20:11:10.612109  4070 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0930 20:11:10.612113  4070 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0930 20:11:10.612118  4070 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0930 20:11:10.612139  4070 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0930 20:11:10.612144  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.612148  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.612150  4070 net.cpp:137] Memory required for data: 141434000
I0930 20:11:10.612152  4070 layer_factory.hpp:77] Creating layer Convolution6
I0930 20:11:10.612160  4070 net.cpp:84] Creating Layer Convolution6
I0930 20:11:10.612164  4070 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0930 20:11:10.612167  4070 net.cpp:380] Convolution6 -> Convolution6
I0930 20:11:10.613052  4070 net.cpp:122] Setting up Convolution6
I0930 20:11:10.613062  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.613066  4070 net.cpp:137] Memory required for data: 146451600
I0930 20:11:10.613071  4070 layer_factory.hpp:77] Creating layer BatchNorm6
I0930 20:11:10.613076  4070 net.cpp:84] Creating Layer BatchNorm6
I0930 20:11:10.613080  4070 net.cpp:406] BatchNorm6 <- Convolution6
I0930 20:11:10.613085  4070 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0930 20:11:10.613214  4070 net.cpp:122] Setting up BatchNorm6
I0930 20:11:10.613220  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.613224  4070 net.cpp:137] Memory required for data: 151469200
I0930 20:11:10.613229  4070 layer_factory.hpp:77] Creating layer Scale6
I0930 20:11:10.613234  4070 net.cpp:84] Creating Layer Scale6
I0930 20:11:10.613237  4070 net.cpp:406] Scale6 <- Convolution6
I0930 20:11:10.613241  4070 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0930 20:11:10.613266  4070 layer_factory.hpp:77] Creating layer Scale6
I0930 20:11:10.613343  4070 net.cpp:122] Setting up Scale6
I0930 20:11:10.613348  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.613353  4070 net.cpp:137] Memory required for data: 156486800
I0930 20:11:10.613356  4070 layer_factory.hpp:77] Creating layer penlu6
I0930 20:11:10.613363  4070 net.cpp:84] Creating Layer penlu6
I0930 20:11:10.613365  4070 net.cpp:406] penlu6 <- Convolution6
I0930 20:11:10.613370  4070 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0930 20:11:10.613476  4070 net.cpp:122] Setting up penlu6
I0930 20:11:10.613482  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.613485  4070 net.cpp:137] Memory required for data: 161504400
I0930 20:11:10.613489  4070 layer_factory.hpp:77] Creating layer Convolution7
I0930 20:11:10.613503  4070 net.cpp:84] Creating Layer Convolution7
I0930 20:11:10.613507  4070 net.cpp:406] Convolution7 <- Convolution6
I0930 20:11:10.613512  4070 net.cpp:380] Convolution7 -> Convolution7
I0930 20:11:10.614068  4070 net.cpp:122] Setting up Convolution7
I0930 20:11:10.614078  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.614081  4070 net.cpp:137] Memory required for data: 166522000
I0930 20:11:10.614086  4070 layer_factory.hpp:77] Creating layer BatchNorm7
I0930 20:11:10.614091  4070 net.cpp:84] Creating Layer BatchNorm7
I0930 20:11:10.614094  4070 net.cpp:406] BatchNorm7 <- Convolution7
I0930 20:11:10.614099  4070 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0930 20:11:10.614225  4070 net.cpp:122] Setting up BatchNorm7
I0930 20:11:10.614231  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.614234  4070 net.cpp:137] Memory required for data: 171539600
I0930 20:11:10.614244  4070 layer_factory.hpp:77] Creating layer Scale7
I0930 20:11:10.614253  4070 net.cpp:84] Creating Layer Scale7
I0930 20:11:10.614256  4070 net.cpp:406] Scale7 <- Convolution7
I0930 20:11:10.614260  4070 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0930 20:11:10.614287  4070 layer_factory.hpp:77] Creating layer Scale7
I0930 20:11:10.614362  4070 net.cpp:122] Setting up Scale7
I0930 20:11:10.614367  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.614370  4070 net.cpp:137] Memory required for data: 176557200
I0930 20:11:10.614374  4070 layer_factory.hpp:77] Creating layer Eltwise3
I0930 20:11:10.614379  4070 net.cpp:84] Creating Layer Eltwise3
I0930 20:11:10.614382  4070 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0930 20:11:10.614387  4070 net.cpp:406] Eltwise3 <- Convolution7
I0930 20:11:10.614389  4070 net.cpp:380] Eltwise3 -> Eltwise3
I0930 20:11:10.614405  4070 net.cpp:122] Setting up Eltwise3
I0930 20:11:10.614410  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.614414  4070 net.cpp:137] Memory required for data: 181574800
I0930 20:11:10.614416  4070 layer_factory.hpp:77] Creating layer penlu7
I0930 20:11:10.614421  4070 net.cpp:84] Creating Layer penlu7
I0930 20:11:10.614424  4070 net.cpp:406] penlu7 <- Eltwise3
I0930 20:11:10.614428  4070 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0930 20:11:10.614542  4070 net.cpp:122] Setting up penlu7
I0930 20:11:10.614548  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.614552  4070 net.cpp:137] Memory required for data: 186592400
I0930 20:11:10.614555  4070 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0930 20:11:10.614560  4070 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0930 20:11:10.614564  4070 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0930 20:11:10.614567  4070 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0930 20:11:10.614572  4070 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0930 20:11:10.614594  4070 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0930 20:11:10.614599  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.614603  4070 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I0930 20:11:10.614606  4070 net.cpp:137] Memory required for data: 196627600
I0930 20:11:10.614609  4070 layer_factory.hpp:77] Creating layer Convolution8
I0930 20:11:10.614614  4070 net.cpp:84] Creating Layer Convolution8
I0930 20:11:10.614617  4070 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0930 20:11:10.614622  4070 net.cpp:380] Convolution8 -> Convolution8
I0930 20:11:10.615772  4070 net.cpp:122] Setting up Convolution8
I0930 20:11:10.615782  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.615787  4070 net.cpp:137] Memory required for data: 199136400
I0930 20:11:10.615792  4070 layer_factory.hpp:77] Creating layer BatchNorm8
I0930 20:11:10.615797  4070 net.cpp:84] Creating Layer BatchNorm8
I0930 20:11:10.615802  4070 net.cpp:406] BatchNorm8 <- Convolution8
I0930 20:11:10.615814  4070 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0930 20:11:10.615988  4070 net.cpp:122] Setting up BatchNorm8
I0930 20:11:10.615998  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.616004  4070 net.cpp:137] Memory required for data: 201645200
I0930 20:11:10.616014  4070 layer_factory.hpp:77] Creating layer Scale8
I0930 20:11:10.616022  4070 net.cpp:84] Creating Layer Scale8
I0930 20:11:10.616029  4070 net.cpp:406] Scale8 <- Convolution8
I0930 20:11:10.616034  4070 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0930 20:11:10.616072  4070 layer_factory.hpp:77] Creating layer Scale8
I0930 20:11:10.616178  4070 net.cpp:122] Setting up Scale8
I0930 20:11:10.616186  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.616191  4070 net.cpp:137] Memory required for data: 204154000
I0930 20:11:10.616199  4070 layer_factory.hpp:77] Creating layer Convolution9
I0930 20:11:10.616209  4070 net.cpp:84] Creating Layer Convolution9
I0930 20:11:10.616215  4070 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I0930 20:11:10.616222  4070 net.cpp:380] Convolution9 -> Convolution9
I0930 20:11:10.617981  4070 net.cpp:122] Setting up Convolution9
I0930 20:11:10.617992  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.617995  4070 net.cpp:137] Memory required for data: 206662800
I0930 20:11:10.618010  4070 layer_factory.hpp:77] Creating layer BatchNorm9
I0930 20:11:10.618016  4070 net.cpp:84] Creating Layer BatchNorm9
I0930 20:11:10.618021  4070 net.cpp:406] BatchNorm9 <- Convolution9
I0930 20:11:10.618026  4070 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0930 20:11:10.618191  4070 net.cpp:122] Setting up BatchNorm9
I0930 20:11:10.618196  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.618199  4070 net.cpp:137] Memory required for data: 209171600
I0930 20:11:10.618216  4070 layer_factory.hpp:77] Creating layer Scale9
I0930 20:11:10.618221  4070 net.cpp:84] Creating Layer Scale9
I0930 20:11:10.618224  4070 net.cpp:406] Scale9 <- Convolution9
I0930 20:11:10.618229  4070 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0930 20:11:10.618264  4070 layer_factory.hpp:77] Creating layer Scale9
I0930 20:11:10.618357  4070 net.cpp:122] Setting up Scale9
I0930 20:11:10.618363  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.618366  4070 net.cpp:137] Memory required for data: 211680400
I0930 20:11:10.618381  4070 layer_factory.hpp:77] Creating layer penlu8
I0930 20:11:10.618387  4070 net.cpp:84] Creating Layer penlu8
I0930 20:11:10.618391  4070 net.cpp:406] penlu8 <- Convolution9
I0930 20:11:10.618396  4070 net.cpp:367] penlu8 -> Convolution9 (in-place)
I0930 20:11:10.618500  4070 net.cpp:122] Setting up penlu8
I0930 20:11:10.618505  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.618510  4070 net.cpp:137] Memory required for data: 214189200
I0930 20:11:10.618513  4070 layer_factory.hpp:77] Creating layer Convolution10
I0930 20:11:10.618525  4070 net.cpp:84] Creating Layer Convolution10
I0930 20:11:10.618530  4070 net.cpp:406] Convolution10 <- Convolution9
I0930 20:11:10.618535  4070 net.cpp:380] Convolution10 -> Convolution10
I0930 20:11:10.619582  4070 net.cpp:122] Setting up Convolution10
I0930 20:11:10.619592  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.619596  4070 net.cpp:137] Memory required for data: 216698000
I0930 20:11:10.619601  4070 layer_factory.hpp:77] Creating layer BatchNorm10
I0930 20:11:10.619606  4070 net.cpp:84] Creating Layer BatchNorm10
I0930 20:11:10.619611  4070 net.cpp:406] BatchNorm10 <- Convolution10
I0930 20:11:10.619614  4070 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0930 20:11:10.619743  4070 net.cpp:122] Setting up BatchNorm10
I0930 20:11:10.619750  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.619752  4070 net.cpp:137] Memory required for data: 219206800
I0930 20:11:10.619757  4070 layer_factory.hpp:77] Creating layer Scale10
I0930 20:11:10.619762  4070 net.cpp:84] Creating Layer Scale10
I0930 20:11:10.619765  4070 net.cpp:406] Scale10 <- Convolution10
I0930 20:11:10.619770  4070 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0930 20:11:10.619804  4070 layer_factory.hpp:77] Creating layer Scale10
I0930 20:11:10.619891  4070 net.cpp:122] Setting up Scale10
I0930 20:11:10.619897  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.619901  4070 net.cpp:137] Memory required for data: 221715600
I0930 20:11:10.619905  4070 layer_factory.hpp:77] Creating layer Eltwise4
I0930 20:11:10.619910  4070 net.cpp:84] Creating Layer Eltwise4
I0930 20:11:10.619915  4070 net.cpp:406] Eltwise4 <- Convolution8
I0930 20:11:10.619917  4070 net.cpp:406] Eltwise4 <- Convolution10
I0930 20:11:10.619922  4070 net.cpp:380] Eltwise4 -> Eltwise4
I0930 20:11:10.619938  4070 net.cpp:122] Setting up Eltwise4
I0930 20:11:10.619945  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.619948  4070 net.cpp:137] Memory required for data: 224224400
I0930 20:11:10.619951  4070 layer_factory.hpp:77] Creating layer penlu9
I0930 20:11:10.619964  4070 net.cpp:84] Creating Layer penlu9
I0930 20:11:10.619967  4070 net.cpp:406] penlu9 <- Eltwise4
I0930 20:11:10.619972  4070 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0930 20:11:10.620076  4070 net.cpp:122] Setting up penlu9
I0930 20:11:10.620082  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.620085  4070 net.cpp:137] Memory required for data: 226733200
I0930 20:11:10.620090  4070 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0930 20:11:10.620095  4070 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0930 20:11:10.620098  4070 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0930 20:11:10.620101  4070 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0930 20:11:10.620106  4070 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0930 20:11:10.620129  4070 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0930 20:11:10.620134  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.620138  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.620141  4070 net.cpp:137] Memory required for data: 231750800
I0930 20:11:10.620143  4070 layer_factory.hpp:77] Creating layer Convolution11
I0930 20:11:10.620151  4070 net.cpp:84] Creating Layer Convolution11
I0930 20:11:10.620154  4070 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I0930 20:11:10.620159  4070 net.cpp:380] Convolution11 -> Convolution11
I0930 20:11:10.621197  4070 net.cpp:122] Setting up Convolution11
I0930 20:11:10.621208  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.621212  4070 net.cpp:137] Memory required for data: 234259600
I0930 20:11:10.621217  4070 layer_factory.hpp:77] Creating layer BatchNorm11
I0930 20:11:10.621222  4070 net.cpp:84] Creating Layer BatchNorm11
I0930 20:11:10.621225  4070 net.cpp:406] BatchNorm11 <- Convolution11
I0930 20:11:10.621230  4070 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0930 20:11:10.621361  4070 net.cpp:122] Setting up BatchNorm11
I0930 20:11:10.621367  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.621371  4070 net.cpp:137] Memory required for data: 236768400
I0930 20:11:10.621376  4070 layer_factory.hpp:77] Creating layer Scale11
I0930 20:11:10.621381  4070 net.cpp:84] Creating Layer Scale11
I0930 20:11:10.621384  4070 net.cpp:406] Scale11 <- Convolution11
I0930 20:11:10.621388  4070 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0930 20:11:10.621414  4070 layer_factory.hpp:77] Creating layer Scale11
I0930 20:11:10.621490  4070 net.cpp:122] Setting up Scale11
I0930 20:11:10.621496  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.621500  4070 net.cpp:137] Memory required for data: 239277200
I0930 20:11:10.621503  4070 layer_factory.hpp:77] Creating layer penlu10
I0930 20:11:10.621510  4070 net.cpp:84] Creating Layer penlu10
I0930 20:11:10.621513  4070 net.cpp:406] penlu10 <- Convolution11
I0930 20:11:10.621517  4070 net.cpp:367] penlu10 -> Convolution11 (in-place)
I0930 20:11:10.621623  4070 net.cpp:122] Setting up penlu10
I0930 20:11:10.621629  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.621639  4070 net.cpp:137] Memory required for data: 241786000
I0930 20:11:10.621644  4070 layer_factory.hpp:77] Creating layer Convolution12
I0930 20:11:10.621650  4070 net.cpp:84] Creating Layer Convolution12
I0930 20:11:10.621654  4070 net.cpp:406] Convolution12 <- Convolution11
I0930 20:11:10.621659  4070 net.cpp:380] Convolution12 -> Convolution12
I0930 20:11:10.622709  4070 net.cpp:122] Setting up Convolution12
I0930 20:11:10.622720  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.622722  4070 net.cpp:137] Memory required for data: 244294800
I0930 20:11:10.622727  4070 layer_factory.hpp:77] Creating layer BatchNorm12
I0930 20:11:10.622733  4070 net.cpp:84] Creating Layer BatchNorm12
I0930 20:11:10.622737  4070 net.cpp:406] BatchNorm12 <- Convolution12
I0930 20:11:10.622740  4070 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0930 20:11:10.622872  4070 net.cpp:122] Setting up BatchNorm12
I0930 20:11:10.622879  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.622881  4070 net.cpp:137] Memory required for data: 246803600
I0930 20:11:10.622886  4070 layer_factory.hpp:77] Creating layer Scale12
I0930 20:11:10.622891  4070 net.cpp:84] Creating Layer Scale12
I0930 20:11:10.622895  4070 net.cpp:406] Scale12 <- Convolution12
I0930 20:11:10.622898  4070 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0930 20:11:10.622926  4070 layer_factory.hpp:77] Creating layer Scale12
I0930 20:11:10.623001  4070 net.cpp:122] Setting up Scale12
I0930 20:11:10.623006  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.623010  4070 net.cpp:137] Memory required for data: 249312400
I0930 20:11:10.623014  4070 layer_factory.hpp:77] Creating layer Eltwise5
I0930 20:11:10.623019  4070 net.cpp:84] Creating Layer Eltwise5
I0930 20:11:10.623023  4070 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0930 20:11:10.623025  4070 net.cpp:406] Eltwise5 <- Convolution12
I0930 20:11:10.623029  4070 net.cpp:380] Eltwise5 -> Eltwise5
I0930 20:11:10.623046  4070 net.cpp:122] Setting up Eltwise5
I0930 20:11:10.623051  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.623054  4070 net.cpp:137] Memory required for data: 251821200
I0930 20:11:10.623057  4070 layer_factory.hpp:77] Creating layer penlu11
I0930 20:11:10.623062  4070 net.cpp:84] Creating Layer penlu11
I0930 20:11:10.623065  4070 net.cpp:406] penlu11 <- Eltwise5
I0930 20:11:10.623070  4070 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0930 20:11:10.623174  4070 net.cpp:122] Setting up penlu11
I0930 20:11:10.623180  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.623183  4070 net.cpp:137] Memory required for data: 254330000
I0930 20:11:10.623188  4070 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0930 20:11:10.623193  4070 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0930 20:11:10.623198  4070 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0930 20:11:10.623200  4070 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0930 20:11:10.623205  4070 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0930 20:11:10.623229  4070 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0930 20:11:10.623234  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.623237  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.623241  4070 net.cpp:137] Memory required for data: 259347600
I0930 20:11:10.623244  4070 layer_factory.hpp:77] Creating layer Convolution13
I0930 20:11:10.623250  4070 net.cpp:84] Creating Layer Convolution13
I0930 20:11:10.623252  4070 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I0930 20:11:10.623257  4070 net.cpp:380] Convolution13 -> Convolution13
I0930 20:11:10.624296  4070 net.cpp:122] Setting up Convolution13
I0930 20:11:10.624306  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.624310  4070 net.cpp:137] Memory required for data: 261856400
I0930 20:11:10.624315  4070 layer_factory.hpp:77] Creating layer BatchNorm13
I0930 20:11:10.624321  4070 net.cpp:84] Creating Layer BatchNorm13
I0930 20:11:10.624332  4070 net.cpp:406] BatchNorm13 <- Convolution13
I0930 20:11:10.624337  4070 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0930 20:11:10.624469  4070 net.cpp:122] Setting up BatchNorm13
I0930 20:11:10.624475  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.624480  4070 net.cpp:137] Memory required for data: 264365200
I0930 20:11:10.624485  4070 layer_factory.hpp:77] Creating layer Scale13
I0930 20:11:10.624490  4070 net.cpp:84] Creating Layer Scale13
I0930 20:11:10.624492  4070 net.cpp:406] Scale13 <- Convolution13
I0930 20:11:10.624495  4070 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0930 20:11:10.624524  4070 layer_factory.hpp:77] Creating layer Scale13
I0930 20:11:10.624601  4070 net.cpp:122] Setting up Scale13
I0930 20:11:10.624608  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.624611  4070 net.cpp:137] Memory required for data: 266874000
I0930 20:11:10.624615  4070 layer_factory.hpp:77] Creating layer penlu12
I0930 20:11:10.624621  4070 net.cpp:84] Creating Layer penlu12
I0930 20:11:10.624624  4070 net.cpp:406] penlu12 <- Convolution13
I0930 20:11:10.624629  4070 net.cpp:367] penlu12 -> Convolution13 (in-place)
I0930 20:11:10.624737  4070 net.cpp:122] Setting up penlu12
I0930 20:11:10.624742  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.624745  4070 net.cpp:137] Memory required for data: 269382800
I0930 20:11:10.624750  4070 layer_factory.hpp:77] Creating layer Convolution14
I0930 20:11:10.624758  4070 net.cpp:84] Creating Layer Convolution14
I0930 20:11:10.624761  4070 net.cpp:406] Convolution14 <- Convolution13
I0930 20:11:10.624765  4070 net.cpp:380] Convolution14 -> Convolution14
I0930 20:11:10.625835  4070 net.cpp:122] Setting up Convolution14
I0930 20:11:10.625846  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.625849  4070 net.cpp:137] Memory required for data: 271891600
I0930 20:11:10.625867  4070 layer_factory.hpp:77] Creating layer BatchNorm14
I0930 20:11:10.625877  4070 net.cpp:84] Creating Layer BatchNorm14
I0930 20:11:10.625881  4070 net.cpp:406] BatchNorm14 <- Convolution14
I0930 20:11:10.625885  4070 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0930 20:11:10.626026  4070 net.cpp:122] Setting up BatchNorm14
I0930 20:11:10.626032  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.626036  4070 net.cpp:137] Memory required for data: 274400400
I0930 20:11:10.626041  4070 layer_factory.hpp:77] Creating layer Scale14
I0930 20:11:10.626046  4070 net.cpp:84] Creating Layer Scale14
I0930 20:11:10.626049  4070 net.cpp:406] Scale14 <- Convolution14
I0930 20:11:10.626052  4070 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0930 20:11:10.626080  4070 layer_factory.hpp:77] Creating layer Scale14
I0930 20:11:10.626158  4070 net.cpp:122] Setting up Scale14
I0930 20:11:10.626164  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.626166  4070 net.cpp:137] Memory required for data: 276909200
I0930 20:11:10.626170  4070 layer_factory.hpp:77] Creating layer Eltwise6
I0930 20:11:10.626174  4070 net.cpp:84] Creating Layer Eltwise6
I0930 20:11:10.626178  4070 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0930 20:11:10.626180  4070 net.cpp:406] Eltwise6 <- Convolution14
I0930 20:11:10.626183  4070 net.cpp:380] Eltwise6 -> Eltwise6
I0930 20:11:10.626200  4070 net.cpp:122] Setting up Eltwise6
I0930 20:11:10.626204  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.626206  4070 net.cpp:137] Memory required for data: 279418000
I0930 20:11:10.626209  4070 layer_factory.hpp:77] Creating layer penlu13
I0930 20:11:10.626214  4070 net.cpp:84] Creating Layer penlu13
I0930 20:11:10.626216  4070 net.cpp:406] penlu13 <- Eltwise6
I0930 20:11:10.626220  4070 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0930 20:11:10.626325  4070 net.cpp:122] Setting up penlu13
I0930 20:11:10.626329  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.626332  4070 net.cpp:137] Memory required for data: 281926800
I0930 20:11:10.626335  4070 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0930 20:11:10.626346  4070 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0930 20:11:10.626348  4070 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0930 20:11:10.626353  4070 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0930 20:11:10.626355  4070 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0930 20:11:10.626379  4070 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0930 20:11:10.626384  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.626396  4070 net.cpp:129] Top shape: 100 32 14 14 (627200)
I0930 20:11:10.626399  4070 net.cpp:137] Memory required for data: 286944400
I0930 20:11:10.626401  4070 layer_factory.hpp:77] Creating layer Convolution15
I0930 20:11:10.626406  4070 net.cpp:84] Creating Layer Convolution15
I0930 20:11:10.626410  4070 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I0930 20:11:10.626415  4070 net.cpp:380] Convolution15 -> Convolution15
I0930 20:11:10.627405  4070 net.cpp:122] Setting up Convolution15
I0930 20:11:10.627414  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.627418  4070 net.cpp:137] Memory required for data: 288198800
I0930 20:11:10.627423  4070 layer_factory.hpp:77] Creating layer BatchNorm15
I0930 20:11:10.627427  4070 net.cpp:84] Creating Layer BatchNorm15
I0930 20:11:10.627430  4070 net.cpp:406] BatchNorm15 <- Convolution15
I0930 20:11:10.627434  4070 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0930 20:11:10.627564  4070 net.cpp:122] Setting up BatchNorm15
I0930 20:11:10.627568  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.627570  4070 net.cpp:137] Memory required for data: 289453200
I0930 20:11:10.627575  4070 layer_factory.hpp:77] Creating layer Scale15
I0930 20:11:10.627579  4070 net.cpp:84] Creating Layer Scale15
I0930 20:11:10.627581  4070 net.cpp:406] Scale15 <- Convolution15
I0930 20:11:10.627585  4070 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0930 20:11:10.627611  4070 layer_factory.hpp:77] Creating layer Scale15
I0930 20:11:10.627686  4070 net.cpp:122] Setting up Scale15
I0930 20:11:10.627691  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.627692  4070 net.cpp:137] Memory required for data: 290707600
I0930 20:11:10.627696  4070 layer_factory.hpp:77] Creating layer Convolution16
I0930 20:11:10.627703  4070 net.cpp:84] Creating Layer Convolution16
I0930 20:11:10.627707  4070 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I0930 20:11:10.627710  4070 net.cpp:380] Convolution16 -> Convolution16
I0930 20:11:10.629586  4070 net.cpp:122] Setting up Convolution16
I0930 20:11:10.629597  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.629601  4070 net.cpp:137] Memory required for data: 291962000
I0930 20:11:10.629604  4070 layer_factory.hpp:77] Creating layer BatchNorm16
I0930 20:11:10.629609  4070 net.cpp:84] Creating Layer BatchNorm16
I0930 20:11:10.629612  4070 net.cpp:406] BatchNorm16 <- Convolution16
I0930 20:11:10.629617  4070 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0930 20:11:10.629747  4070 net.cpp:122] Setting up BatchNorm16
I0930 20:11:10.629752  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.629755  4070 net.cpp:137] Memory required for data: 293216400
I0930 20:11:10.629760  4070 layer_factory.hpp:77] Creating layer Scale16
I0930 20:11:10.629763  4070 net.cpp:84] Creating Layer Scale16
I0930 20:11:10.629766  4070 net.cpp:406] Scale16 <- Convolution16
I0930 20:11:10.629770  4070 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0930 20:11:10.629796  4070 layer_factory.hpp:77] Creating layer Scale16
I0930 20:11:10.629870  4070 net.cpp:122] Setting up Scale16
I0930 20:11:10.629874  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.629876  4070 net.cpp:137] Memory required for data: 294470800
I0930 20:11:10.629880  4070 layer_factory.hpp:77] Creating layer penlu14
I0930 20:11:10.629885  4070 net.cpp:84] Creating Layer penlu14
I0930 20:11:10.629887  4070 net.cpp:406] penlu14 <- Convolution16
I0930 20:11:10.629894  4070 net.cpp:367] penlu14 -> Convolution16 (in-place)
I0930 20:11:10.630010  4070 net.cpp:122] Setting up penlu14
I0930 20:11:10.630015  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.630018  4070 net.cpp:137] Memory required for data: 295725200
I0930 20:11:10.630023  4070 layer_factory.hpp:77] Creating layer Convolution17
I0930 20:11:10.630029  4070 net.cpp:84] Creating Layer Convolution17
I0930 20:11:10.630033  4070 net.cpp:406] Convolution17 <- Convolution16
I0930 20:11:10.630036  4070 net.cpp:380] Convolution17 -> Convolution17
I0930 20:11:10.631692  4070 net.cpp:122] Setting up Convolution17
I0930 20:11:10.631701  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.631705  4070 net.cpp:137] Memory required for data: 296979600
I0930 20:11:10.631711  4070 layer_factory.hpp:77] Creating layer BatchNorm17
I0930 20:11:10.631714  4070 net.cpp:84] Creating Layer BatchNorm17
I0930 20:11:10.631717  4070 net.cpp:406] BatchNorm17 <- Convolution17
I0930 20:11:10.631721  4070 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0930 20:11:10.631893  4070 net.cpp:122] Setting up BatchNorm17
I0930 20:11:10.631906  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.631911  4070 net.cpp:137] Memory required for data: 298234000
I0930 20:11:10.631918  4070 layer_factory.hpp:77] Creating layer Scale17
I0930 20:11:10.631927  4070 net.cpp:84] Creating Layer Scale17
I0930 20:11:10.631932  4070 net.cpp:406] Scale17 <- Convolution17
I0930 20:11:10.631938  4070 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0930 20:11:10.631979  4070 layer_factory.hpp:77] Creating layer Scale17
I0930 20:11:10.632098  4070 net.cpp:122] Setting up Scale17
I0930 20:11:10.632109  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.632114  4070 net.cpp:137] Memory required for data: 299488400
I0930 20:11:10.632122  4070 layer_factory.hpp:77] Creating layer Eltwise7
I0930 20:11:10.632130  4070 net.cpp:84] Creating Layer Eltwise7
I0930 20:11:10.632135  4070 net.cpp:406] Eltwise7 <- Convolution15
I0930 20:11:10.632141  4070 net.cpp:406] Eltwise7 <- Convolution17
I0930 20:11:10.632148  4070 net.cpp:380] Eltwise7 -> Eltwise7
I0930 20:11:10.632174  4070 net.cpp:122] Setting up Eltwise7
I0930 20:11:10.632181  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.632186  4070 net.cpp:137] Memory required for data: 300742800
I0930 20:11:10.632190  4070 layer_factory.hpp:77] Creating layer penlu15
I0930 20:11:10.632200  4070 net.cpp:84] Creating Layer penlu15
I0930 20:11:10.632206  4070 net.cpp:406] penlu15 <- Eltwise7
I0930 20:11:10.632215  4070 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0930 20:11:10.632371  4070 net.cpp:122] Setting up penlu15
I0930 20:11:10.632380  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.632385  4070 net.cpp:137] Memory required for data: 301997200
I0930 20:11:10.632391  4070 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0930 20:11:10.632398  4070 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0930 20:11:10.632402  4070 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0930 20:11:10.632407  4070 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0930 20:11:10.632414  4070 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0930 20:11:10.632447  4070 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0930 20:11:10.632453  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.632458  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.632462  4070 net.cpp:137] Memory required for data: 304506000
I0930 20:11:10.632465  4070 layer_factory.hpp:77] Creating layer Convolution18
I0930 20:11:10.632474  4070 net.cpp:84] Creating Layer Convolution18
I0930 20:11:10.632478  4070 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I0930 20:11:10.632485  4070 net.cpp:380] Convolution18 -> Convolution18
I0930 20:11:10.634899  4070 net.cpp:122] Setting up Convolution18
I0930 20:11:10.634910  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.634913  4070 net.cpp:137] Memory required for data: 305760400
I0930 20:11:10.634925  4070 layer_factory.hpp:77] Creating layer BatchNorm18
I0930 20:11:10.634930  4070 net.cpp:84] Creating Layer BatchNorm18
I0930 20:11:10.634932  4070 net.cpp:406] BatchNorm18 <- Convolution18
I0930 20:11:10.634938  4070 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0930 20:11:10.635069  4070 net.cpp:122] Setting up BatchNorm18
I0930 20:11:10.635073  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.635076  4070 net.cpp:137] Memory required for data: 307014800
I0930 20:11:10.635080  4070 layer_factory.hpp:77] Creating layer Scale18
I0930 20:11:10.635084  4070 net.cpp:84] Creating Layer Scale18
I0930 20:11:10.635087  4070 net.cpp:406] Scale18 <- Convolution18
I0930 20:11:10.635090  4070 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0930 20:11:10.635118  4070 layer_factory.hpp:77] Creating layer Scale18
I0930 20:11:10.635193  4070 net.cpp:122] Setting up Scale18
I0930 20:11:10.635198  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.635200  4070 net.cpp:137] Memory required for data: 308269200
I0930 20:11:10.635205  4070 layer_factory.hpp:77] Creating layer penlu16
I0930 20:11:10.635208  4070 net.cpp:84] Creating Layer penlu16
I0930 20:11:10.635211  4070 net.cpp:406] penlu16 <- Convolution18
I0930 20:11:10.635215  4070 net.cpp:367] penlu16 -> Convolution18 (in-place)
I0930 20:11:10.635321  4070 net.cpp:122] Setting up penlu16
I0930 20:11:10.635326  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.635329  4070 net.cpp:137] Memory required for data: 309523600
I0930 20:11:10.635334  4070 layer_factory.hpp:77] Creating layer Convolution19
I0930 20:11:10.635339  4070 net.cpp:84] Creating Layer Convolution19
I0930 20:11:10.635342  4070 net.cpp:406] Convolution19 <- Convolution18
I0930 20:11:10.635346  4070 net.cpp:380] Convolution19 -> Convolution19
I0930 20:11:10.637394  4070 net.cpp:122] Setting up Convolution19
I0930 20:11:10.637405  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.637409  4070 net.cpp:137] Memory required for data: 310778000
I0930 20:11:10.637425  4070 layer_factory.hpp:77] Creating layer BatchNorm19
I0930 20:11:10.637432  4070 net.cpp:84] Creating Layer BatchNorm19
I0930 20:11:10.637435  4070 net.cpp:406] BatchNorm19 <- Convolution19
I0930 20:11:10.637439  4070 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0930 20:11:10.637585  4070 net.cpp:122] Setting up BatchNorm19
I0930 20:11:10.637591  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.637594  4070 net.cpp:137] Memory required for data: 312032400
I0930 20:11:10.637600  4070 layer_factory.hpp:77] Creating layer Scale19
I0930 20:11:10.637605  4070 net.cpp:84] Creating Layer Scale19
I0930 20:11:10.637607  4070 net.cpp:406] Scale19 <- Convolution19
I0930 20:11:10.637612  4070 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0930 20:11:10.637640  4070 layer_factory.hpp:77] Creating layer Scale19
I0930 20:11:10.637719  4070 net.cpp:122] Setting up Scale19
I0930 20:11:10.637725  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.637728  4070 net.cpp:137] Memory required for data: 313286800
I0930 20:11:10.637732  4070 layer_factory.hpp:77] Creating layer Eltwise8
I0930 20:11:10.637738  4070 net.cpp:84] Creating Layer Eltwise8
I0930 20:11:10.637742  4070 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0930 20:11:10.637744  4070 net.cpp:406] Eltwise8 <- Convolution19
I0930 20:11:10.637749  4070 net.cpp:380] Eltwise8 -> Eltwise8
I0930 20:11:10.637765  4070 net.cpp:122] Setting up Eltwise8
I0930 20:11:10.637770  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.637773  4070 net.cpp:137] Memory required for data: 314541200
I0930 20:11:10.637775  4070 layer_factory.hpp:77] Creating layer penlu17
I0930 20:11:10.637781  4070 net.cpp:84] Creating Layer penlu17
I0930 20:11:10.637784  4070 net.cpp:406] penlu17 <- Eltwise8
I0930 20:11:10.637789  4070 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0930 20:11:10.637897  4070 net.cpp:122] Setting up penlu17
I0930 20:11:10.637902  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.637912  4070 net.cpp:137] Memory required for data: 315795600
I0930 20:11:10.637917  4070 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0930 20:11:10.637923  4070 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0930 20:11:10.637925  4070 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0930 20:11:10.637928  4070 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0930 20:11:10.637934  4070 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0930 20:11:10.637959  4070 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0930 20:11:10.637964  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.637969  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.637971  4070 net.cpp:137] Memory required for data: 318304400
I0930 20:11:10.637974  4070 layer_factory.hpp:77] Creating layer Convolution20
I0930 20:11:10.637980  4070 net.cpp:84] Creating Layer Convolution20
I0930 20:11:10.637984  4070 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I0930 20:11:10.637989  4070 net.cpp:380] Convolution20 -> Convolution20
I0930 20:11:10.639677  4070 net.cpp:122] Setting up Convolution20
I0930 20:11:10.639688  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.639691  4070 net.cpp:137] Memory required for data: 319558800
I0930 20:11:10.639696  4070 layer_factory.hpp:77] Creating layer BatchNorm20
I0930 20:11:10.639703  4070 net.cpp:84] Creating Layer BatchNorm20
I0930 20:11:10.639705  4070 net.cpp:406] BatchNorm20 <- Convolution20
I0930 20:11:10.639709  4070 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0930 20:11:10.639845  4070 net.cpp:122] Setting up BatchNorm20
I0930 20:11:10.639852  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.639855  4070 net.cpp:137] Memory required for data: 320813200
I0930 20:11:10.639860  4070 layer_factory.hpp:77] Creating layer Scale20
I0930 20:11:10.639864  4070 net.cpp:84] Creating Layer Scale20
I0930 20:11:10.639868  4070 net.cpp:406] Scale20 <- Convolution20
I0930 20:11:10.639871  4070 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0930 20:11:10.639900  4070 layer_factory.hpp:77] Creating layer Scale20
I0930 20:11:10.639979  4070 net.cpp:122] Setting up Scale20
I0930 20:11:10.639984  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.639988  4070 net.cpp:137] Memory required for data: 322067600
I0930 20:11:10.639992  4070 layer_factory.hpp:77] Creating layer penlu18
I0930 20:11:10.639998  4070 net.cpp:84] Creating Layer penlu18
I0930 20:11:10.640002  4070 net.cpp:406] penlu18 <- Convolution20
I0930 20:11:10.640005  4070 net.cpp:367] penlu18 -> Convolution20 (in-place)
I0930 20:11:10.640115  4070 net.cpp:122] Setting up penlu18
I0930 20:11:10.640118  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.640120  4070 net.cpp:137] Memory required for data: 323322000
I0930 20:11:10.640125  4070 layer_factory.hpp:77] Creating layer Convolution21
I0930 20:11:10.640132  4070 net.cpp:84] Creating Layer Convolution21
I0930 20:11:10.640135  4070 net.cpp:406] Convolution21 <- Convolution20
I0930 20:11:10.640138  4070 net.cpp:380] Convolution21 -> Convolution21
I0930 20:11:10.642438  4070 net.cpp:122] Setting up Convolution21
I0930 20:11:10.642447  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.642451  4070 net.cpp:137] Memory required for data: 324576400
I0930 20:11:10.642465  4070 layer_factory.hpp:77] Creating layer BatchNorm21
I0930 20:11:10.642470  4070 net.cpp:84] Creating Layer BatchNorm21
I0930 20:11:10.642473  4070 net.cpp:406] BatchNorm21 <- Convolution21
I0930 20:11:10.642477  4070 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0930 20:11:10.642626  4070 net.cpp:122] Setting up BatchNorm21
I0930 20:11:10.642632  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.642633  4070 net.cpp:137] Memory required for data: 325830800
I0930 20:11:10.642638  4070 layer_factory.hpp:77] Creating layer Scale21
I0930 20:11:10.642643  4070 net.cpp:84] Creating Layer Scale21
I0930 20:11:10.642645  4070 net.cpp:406] Scale21 <- Convolution21
I0930 20:11:10.642657  4070 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0930 20:11:10.642688  4070 layer_factory.hpp:77] Creating layer Scale21
I0930 20:11:10.642777  4070 net.cpp:122] Setting up Scale21
I0930 20:11:10.642782  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.642784  4070 net.cpp:137] Memory required for data: 327085200
I0930 20:11:10.642788  4070 layer_factory.hpp:77] Creating layer Eltwise9
I0930 20:11:10.642793  4070 net.cpp:84] Creating Layer Eltwise9
I0930 20:11:10.642796  4070 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0930 20:11:10.642798  4070 net.cpp:406] Eltwise9 <- Convolution21
I0930 20:11:10.642802  4070 net.cpp:380] Eltwise9 -> Eltwise9
I0930 20:11:10.642818  4070 net.cpp:122] Setting up Eltwise9
I0930 20:11:10.642822  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.642824  4070 net.cpp:137] Memory required for data: 328339600
I0930 20:11:10.642827  4070 layer_factory.hpp:77] Creating layer penlu19
I0930 20:11:10.642832  4070 net.cpp:84] Creating Layer penlu19
I0930 20:11:10.642834  4070 net.cpp:406] penlu19 <- Eltwise9
I0930 20:11:10.642838  4070 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0930 20:11:10.642948  4070 net.cpp:122] Setting up penlu19
I0930 20:11:10.642953  4070 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0930 20:11:10.642956  4070 net.cpp:137] Memory required for data: 329594000
I0930 20:11:10.642959  4070 layer_factory.hpp:77] Creating layer Pooling1
I0930 20:11:10.642966  4070 net.cpp:84] Creating Layer Pooling1
I0930 20:11:10.642967  4070 net.cpp:406] Pooling1 <- Eltwise9
I0930 20:11:10.642971  4070 net.cpp:380] Pooling1 -> Pooling1
I0930 20:11:10.643124  4070 net.cpp:122] Setting up Pooling1
I0930 20:11:10.643131  4070 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0930 20:11:10.643133  4070 net.cpp:137] Memory required for data: 329619600
I0930 20:11:10.643136  4070 layer_factory.hpp:77] Creating layer InnerProduct1
I0930 20:11:10.643146  4070 net.cpp:84] Creating Layer InnerProduct1
I0930 20:11:10.643147  4070 net.cpp:406] InnerProduct1 <- Pooling1
I0930 20:11:10.643152  4070 net.cpp:380] InnerProduct1 -> InnerProduct1
I0930 20:11:10.643254  4070 net.cpp:122] Setting up InnerProduct1
I0930 20:11:10.643259  4070 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:11:10.643261  4070 net.cpp:137] Memory required for data: 329623600
I0930 20:11:10.643265  4070 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:11:10.643270  4070 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0930 20:11:10.643271  4070 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0930 20:11:10.643275  4070 net.cpp:406] SoftmaxWithLoss1 <- Data2
I0930 20:11:10.643278  4070 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0930 20:11:10.643283  4070 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:11:10.643829  4070 net.cpp:122] Setting up SoftmaxWithLoss1
I0930 20:11:10.643837  4070 net.cpp:129] Top shape: (1)
I0930 20:11:10.643839  4070 net.cpp:132]     with loss weight 1
I0930 20:11:10.643851  4070 net.cpp:137] Memory required for data: 329623604
I0930 20:11:10.643854  4070 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0930 20:11:10.643857  4070 net.cpp:198] InnerProduct1 needs backward computation.
I0930 20:11:10.643858  4070 net.cpp:198] Pooling1 needs backward computation.
I0930 20:11:10.643862  4070 net.cpp:198] penlu19 needs backward computation.
I0930 20:11:10.643862  4070 net.cpp:198] Eltwise9 needs backward computation.
I0930 20:11:10.643865  4070 net.cpp:198] Scale21 needs backward computation.
I0930 20:11:10.643867  4070 net.cpp:198] BatchNorm21 needs backward computation.
I0930 20:11:10.643869  4070 net.cpp:198] Convolution21 needs backward computation.
I0930 20:11:10.643872  4070 net.cpp:198] penlu18 needs backward computation.
I0930 20:11:10.643873  4070 net.cpp:198] Scale20 needs backward computation.
I0930 20:11:10.643875  4070 net.cpp:198] BatchNorm20 needs backward computation.
I0930 20:11:10.643877  4070 net.cpp:198] Convolution20 needs backward computation.
I0930 20:11:10.643879  4070 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0930 20:11:10.643889  4070 net.cpp:198] penlu17 needs backward computation.
I0930 20:11:10.643892  4070 net.cpp:198] Eltwise8 needs backward computation.
I0930 20:11:10.643894  4070 net.cpp:198] Scale19 needs backward computation.
I0930 20:11:10.643898  4070 net.cpp:198] BatchNorm19 needs backward computation.
I0930 20:11:10.643899  4070 net.cpp:198] Convolution19 needs backward computation.
I0930 20:11:10.643901  4070 net.cpp:198] penlu16 needs backward computation.
I0930 20:11:10.643903  4070 net.cpp:198] Scale18 needs backward computation.
I0930 20:11:10.643905  4070 net.cpp:198] BatchNorm18 needs backward computation.
I0930 20:11:10.643908  4070 net.cpp:198] Convolution18 needs backward computation.
I0930 20:11:10.643910  4070 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0930 20:11:10.643913  4070 net.cpp:198] penlu15 needs backward computation.
I0930 20:11:10.643914  4070 net.cpp:198] Eltwise7 needs backward computation.
I0930 20:11:10.643918  4070 net.cpp:198] Scale17 needs backward computation.
I0930 20:11:10.643920  4070 net.cpp:198] BatchNorm17 needs backward computation.
I0930 20:11:10.643923  4070 net.cpp:198] Convolution17 needs backward computation.
I0930 20:11:10.643924  4070 net.cpp:198] penlu14 needs backward computation.
I0930 20:11:10.643926  4070 net.cpp:198] Scale16 needs backward computation.
I0930 20:11:10.643929  4070 net.cpp:198] BatchNorm16 needs backward computation.
I0930 20:11:10.643931  4070 net.cpp:198] Convolution16 needs backward computation.
I0930 20:11:10.643934  4070 net.cpp:198] Scale15 needs backward computation.
I0930 20:11:10.643935  4070 net.cpp:198] BatchNorm15 needs backward computation.
I0930 20:11:10.643939  4070 net.cpp:198] Convolution15 needs backward computation.
I0930 20:11:10.643940  4070 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0930 20:11:10.643942  4070 net.cpp:198] penlu13 needs backward computation.
I0930 20:11:10.643945  4070 net.cpp:198] Eltwise6 needs backward computation.
I0930 20:11:10.643947  4070 net.cpp:198] Scale14 needs backward computation.
I0930 20:11:10.643950  4070 net.cpp:198] BatchNorm14 needs backward computation.
I0930 20:11:10.643952  4070 net.cpp:198] Convolution14 needs backward computation.
I0930 20:11:10.643954  4070 net.cpp:198] penlu12 needs backward computation.
I0930 20:11:10.643956  4070 net.cpp:198] Scale13 needs backward computation.
I0930 20:11:10.643959  4070 net.cpp:198] BatchNorm13 needs backward computation.
I0930 20:11:10.643961  4070 net.cpp:198] Convolution13 needs backward computation.
I0930 20:11:10.643963  4070 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0930 20:11:10.643966  4070 net.cpp:198] penlu11 needs backward computation.
I0930 20:11:10.643968  4070 net.cpp:198] Eltwise5 needs backward computation.
I0930 20:11:10.643971  4070 net.cpp:198] Scale12 needs backward computation.
I0930 20:11:10.643973  4070 net.cpp:198] BatchNorm12 needs backward computation.
I0930 20:11:10.643975  4070 net.cpp:198] Convolution12 needs backward computation.
I0930 20:11:10.643977  4070 net.cpp:198] penlu10 needs backward computation.
I0930 20:11:10.643980  4070 net.cpp:198] Scale11 needs backward computation.
I0930 20:11:10.643982  4070 net.cpp:198] BatchNorm11 needs backward computation.
I0930 20:11:10.643985  4070 net.cpp:198] Convolution11 needs backward computation.
I0930 20:11:10.643986  4070 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0930 20:11:10.643990  4070 net.cpp:198] penlu9 needs backward computation.
I0930 20:11:10.643991  4070 net.cpp:198] Eltwise4 needs backward computation.
I0930 20:11:10.643995  4070 net.cpp:198] Scale10 needs backward computation.
I0930 20:11:10.643996  4070 net.cpp:198] BatchNorm10 needs backward computation.
I0930 20:11:10.643998  4070 net.cpp:198] Convolution10 needs backward computation.
I0930 20:11:10.644001  4070 net.cpp:198] penlu8 needs backward computation.
I0930 20:11:10.644003  4070 net.cpp:198] Scale9 needs backward computation.
I0930 20:11:10.644008  4070 net.cpp:198] BatchNorm9 needs backward computation.
I0930 20:11:10.644011  4070 net.cpp:198] Convolution9 needs backward computation.
I0930 20:11:10.644013  4070 net.cpp:198] Scale8 needs backward computation.
I0930 20:11:10.644016  4070 net.cpp:198] BatchNorm8 needs backward computation.
I0930 20:11:10.644018  4070 net.cpp:198] Convolution8 needs backward computation.
I0930 20:11:10.644021  4070 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0930 20:11:10.644023  4070 net.cpp:198] penlu7 needs backward computation.
I0930 20:11:10.644026  4070 net.cpp:198] Eltwise3 needs backward computation.
I0930 20:11:10.644028  4070 net.cpp:198] Scale7 needs backward computation.
I0930 20:11:10.644031  4070 net.cpp:198] BatchNorm7 needs backward computation.
I0930 20:11:10.644032  4070 net.cpp:198] Convolution7 needs backward computation.
I0930 20:11:10.644034  4070 net.cpp:198] penlu6 needs backward computation.
I0930 20:11:10.644037  4070 net.cpp:198] Scale6 needs backward computation.
I0930 20:11:10.644038  4070 net.cpp:198] BatchNorm6 needs backward computation.
I0930 20:11:10.644042  4070 net.cpp:198] Convolution6 needs backward computation.
I0930 20:11:10.644043  4070 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0930 20:11:10.644045  4070 net.cpp:198] penlu5 needs backward computation.
I0930 20:11:10.644048  4070 net.cpp:198] Eltwise2 needs backward computation.
I0930 20:11:10.644050  4070 net.cpp:198] Scale5 needs backward computation.
I0930 20:11:10.644052  4070 net.cpp:198] BatchNorm5 needs backward computation.
I0930 20:11:10.644055  4070 net.cpp:198] Convolution5 needs backward computation.
I0930 20:11:10.644057  4070 net.cpp:198] penlu4 needs backward computation.
I0930 20:11:10.644059  4070 net.cpp:198] Scale4 needs backward computation.
I0930 20:11:10.644062  4070 net.cpp:198] BatchNorm4 needs backward computation.
I0930 20:11:10.644063  4070 net.cpp:198] Convolution4 needs backward computation.
I0930 20:11:10.644067  4070 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0930 20:11:10.644068  4070 net.cpp:198] penlu3 needs backward computation.
I0930 20:11:10.644070  4070 net.cpp:198] Eltwise1 needs backward computation.
I0930 20:11:10.644073  4070 net.cpp:198] Scale3 needs backward computation.
I0930 20:11:10.644075  4070 net.cpp:198] BatchNorm3 needs backward computation.
I0930 20:11:10.644078  4070 net.cpp:198] Convolution3 needs backward computation.
I0930 20:11:10.644080  4070 net.cpp:198] penlu2 needs backward computation.
I0930 20:11:10.644083  4070 net.cpp:198] Scale2 needs backward computation.
I0930 20:11:10.644084  4070 net.cpp:198] BatchNorm2 needs backward computation.
I0930 20:11:10.644086  4070 net.cpp:198] Convolution2 needs backward computation.
I0930 20:11:10.644089  4070 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0930 20:11:10.644091  4070 net.cpp:198] penlu1 needs backward computation.
I0930 20:11:10.644093  4070 net.cpp:198] Scale1 needs backward computation.
I0930 20:11:10.644096  4070 net.cpp:198] BatchNorm1 needs backward computation.
I0930 20:11:10.644098  4070 net.cpp:198] Convolution1 needs backward computation.
I0930 20:11:10.644100  4070 net.cpp:200] Data1 does not need backward computation.
I0930 20:11:10.644103  4070 net.cpp:242] This network produces output SoftmaxWithLoss1
I0930 20:11:10.644134  4070 net.cpp:255] Network initialization done.
I0930 20:11:10.645865  4070 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:11:10.645874  4070 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0930 20:11:10.645879  4070 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res20/res20_penlu_gauss.prototxt
I0930 20:11:10.645952  4070 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0930 20:11:10.646476  4070 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0930 20:11:10.646750  4070 layer_factory.hpp:77] Creating layer Data1
I0930 20:11:10.646791  4070 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I0930 20:11:10.646801  4070 net.cpp:84] Creating Layer Data1
I0930 20:11:10.646806  4070 net.cpp:380] Data1 -> Data1
I0930 20:11:10.646811  4070 net.cpp:380] Data1 -> Data2
I0930 20:11:10.646816  4070 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I0930 20:11:10.646929  4070 data_layer.cpp:45] output data size: 100,3,32,32
I0930 20:11:10.650840  4070 net.cpp:122] Setting up Data1
I0930 20:11:10.650858  4070 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0930 20:11:10.650862  4070 net.cpp:129] Top shape: 100 (100)
I0930 20:11:10.650864  4070 net.cpp:137] Memory required for data: 1229200
I0930 20:11:10.650869  4070 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0930 20:11:10.650878  4070 net.cpp:84] Creating Layer Data2_Data1_1_split
I0930 20:11:10.650882  4070 net.cpp:406] Data2_Data1_1_split <- Data2
I0930 20:11:10.650887  4070 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0930 20:11:10.650893  4070 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0930 20:11:10.650933  4070 net.cpp:122] Setting up Data2_Data1_1_split
I0930 20:11:10.650938  4070 net.cpp:129] Top shape: 100 (100)
I0930 20:11:10.650954  4070 net.cpp:129] Top shape: 100 (100)
I0930 20:11:10.650955  4070 net.cpp:137] Memory required for data: 1230000
I0930 20:11:10.650957  4070 layer_factory.hpp:77] Creating layer Convolution1
I0930 20:11:10.650967  4070 net.cpp:84] Creating Layer Convolution1
I0930 20:11:10.650969  4070 net.cpp:406] Convolution1 <- Data1
I0930 20:11:10.650974  4070 net.cpp:380] Convolution1 -> Convolution1
I0930 20:11:10.652081  4070 net.cpp:122] Setting up Convolution1
I0930 20:11:10.652089  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.652092  4070 net.cpp:137] Memory required for data: 7783600
I0930 20:11:10.652101  4070 layer_factory.hpp:77] Creating layer BatchNorm1
I0930 20:11:10.652106  4070 net.cpp:84] Creating Layer BatchNorm1
I0930 20:11:10.652107  4070 net.cpp:406] BatchNorm1 <- Convolution1
I0930 20:11:10.652112  4070 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0930 20:11:10.652246  4070 net.cpp:122] Setting up BatchNorm1
I0930 20:11:10.652251  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.652256  4070 net.cpp:137] Memory required for data: 14337200
I0930 20:11:10.652263  4070 layer_factory.hpp:77] Creating layer Scale1
I0930 20:11:10.652268  4070 net.cpp:84] Creating Layer Scale1
I0930 20:11:10.652271  4070 net.cpp:406] Scale1 <- Convolution1
I0930 20:11:10.652274  4070 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0930 20:11:10.652304  4070 layer_factory.hpp:77] Creating layer Scale1
I0930 20:11:10.652379  4070 net.cpp:122] Setting up Scale1
I0930 20:11:10.652384  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.652385  4070 net.cpp:137] Memory required for data: 20890800
I0930 20:11:10.652391  4070 layer_factory.hpp:77] Creating layer penlu1
I0930 20:11:10.652396  4070 net.cpp:84] Creating Layer penlu1
I0930 20:11:10.652400  4070 net.cpp:406] penlu1 <- Convolution1
I0930 20:11:10.652406  4070 net.cpp:367] penlu1 -> Convolution1 (in-place)
I0930 20:11:10.652525  4070 net.cpp:122] Setting up penlu1
I0930 20:11:10.652530  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.652534  4070 net.cpp:137] Memory required for data: 27444400
I0930 20:11:10.652539  4070 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I0930 20:11:10.652544  4070 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I0930 20:11:10.652547  4070 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I0930 20:11:10.652550  4070 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I0930 20:11:10.652554  4070 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I0930 20:11:10.652580  4070 net.cpp:122] Setting up Convolution1_penlu1_0_split
I0930 20:11:10.652585  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.652587  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.652592  4070 net.cpp:137] Memory required for data: 40551600
I0930 20:11:10.652595  4070 layer_factory.hpp:77] Creating layer Convolution2
I0930 20:11:10.652601  4070 net.cpp:84] Creating Layer Convolution2
I0930 20:11:10.652602  4070 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I0930 20:11:10.652607  4070 net.cpp:380] Convolution2 -> Convolution2
I0930 20:11:10.653190  4070 net.cpp:122] Setting up Convolution2
I0930 20:11:10.653198  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.653201  4070 net.cpp:137] Memory required for data: 47105200
I0930 20:11:10.653205  4070 layer_factory.hpp:77] Creating layer BatchNorm2
I0930 20:11:10.653211  4070 net.cpp:84] Creating Layer BatchNorm2
I0930 20:11:10.653214  4070 net.cpp:406] BatchNorm2 <- Convolution2
I0930 20:11:10.653218  4070 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0930 20:11:10.653465  4070 net.cpp:122] Setting up BatchNorm2
I0930 20:11:10.653471  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.653475  4070 net.cpp:137] Memory required for data: 53658800
I0930 20:11:10.653479  4070 layer_factory.hpp:77] Creating layer Scale2
I0930 20:11:10.653483  4070 net.cpp:84] Creating Layer Scale2
I0930 20:11:10.653496  4070 net.cpp:406] Scale2 <- Convolution2
I0930 20:11:10.653503  4070 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0930 20:11:10.653532  4070 layer_factory.hpp:77] Creating layer Scale2
I0930 20:11:10.653604  4070 net.cpp:122] Setting up Scale2
I0930 20:11:10.653612  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.653614  4070 net.cpp:137] Memory required for data: 60212400
I0930 20:11:10.653620  4070 layer_factory.hpp:77] Creating layer penlu2
I0930 20:11:10.653626  4070 net.cpp:84] Creating Layer penlu2
I0930 20:11:10.653630  4070 net.cpp:406] penlu2 <- Convolution2
I0930 20:11:10.653633  4070 net.cpp:367] penlu2 -> Convolution2 (in-place)
I0930 20:11:10.653782  4070 net.cpp:122] Setting up penlu2
I0930 20:11:10.653787  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.653790  4070 net.cpp:137] Memory required for data: 66766000
I0930 20:11:10.653795  4070 layer_factory.hpp:77] Creating layer Convolution3
I0930 20:11:10.653810  4070 net.cpp:84] Creating Layer Convolution3
I0930 20:11:10.653812  4070 net.cpp:406] Convolution3 <- Convolution2
I0930 20:11:10.653817  4070 net.cpp:380] Convolution3 -> Convolution3
I0930 20:11:10.654745  4070 net.cpp:122] Setting up Convolution3
I0930 20:11:10.654754  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.654757  4070 net.cpp:137] Memory required for data: 73319600
I0930 20:11:10.654762  4070 layer_factory.hpp:77] Creating layer BatchNorm3
I0930 20:11:10.654767  4070 net.cpp:84] Creating Layer BatchNorm3
I0930 20:11:10.654769  4070 net.cpp:406] BatchNorm3 <- Convolution3
I0930 20:11:10.654773  4070 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0930 20:11:10.654994  4070 net.cpp:122] Setting up BatchNorm3
I0930 20:11:10.654999  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.655001  4070 net.cpp:137] Memory required for data: 79873200
I0930 20:11:10.655006  4070 layer_factory.hpp:77] Creating layer Scale3
I0930 20:11:10.655010  4070 net.cpp:84] Creating Layer Scale3
I0930 20:11:10.655014  4070 net.cpp:406] Scale3 <- Convolution3
I0930 20:11:10.655016  4070 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0930 20:11:10.655043  4070 layer_factory.hpp:77] Creating layer Scale3
I0930 20:11:10.655117  4070 net.cpp:122] Setting up Scale3
I0930 20:11:10.655123  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.655125  4070 net.cpp:137] Memory required for data: 86426800
I0930 20:11:10.655129  4070 layer_factory.hpp:77] Creating layer Eltwise1
I0930 20:11:10.655135  4070 net.cpp:84] Creating Layer Eltwise1
I0930 20:11:10.655138  4070 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I0930 20:11:10.655140  4070 net.cpp:406] Eltwise1 <- Convolution3
I0930 20:11:10.655144  4070 net.cpp:380] Eltwise1 -> Eltwise1
I0930 20:11:10.655163  4070 net.cpp:122] Setting up Eltwise1
I0930 20:11:10.655165  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.655169  4070 net.cpp:137] Memory required for data: 92980400
I0930 20:11:10.655174  4070 layer_factory.hpp:77] Creating layer penlu3
I0930 20:11:10.655179  4070 net.cpp:84] Creating Layer penlu3
I0930 20:11:10.655182  4070 net.cpp:406] penlu3 <- Eltwise1
I0930 20:11:10.655186  4070 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I0930 20:11:10.655300  4070 net.cpp:122] Setting up penlu3
I0930 20:11:10.655305  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.655308  4070 net.cpp:137] Memory required for data: 99534000
I0930 20:11:10.655311  4070 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I0930 20:11:10.655316  4070 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I0930 20:11:10.655318  4070 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I0930 20:11:10.655323  4070 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I0930 20:11:10.655326  4070 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I0930 20:11:10.655349  4070 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I0930 20:11:10.655352  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.655364  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.655366  4070 net.cpp:137] Memory required for data: 112641200
I0930 20:11:10.655371  4070 layer_factory.hpp:77] Creating layer Convolution4
I0930 20:11:10.655378  4070 net.cpp:84] Creating Layer Convolution4
I0930 20:11:10.655383  4070 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I0930 20:11:10.655387  4070 net.cpp:380] Convolution4 -> Convolution4
I0930 20:11:10.656421  4070 net.cpp:122] Setting up Convolution4
I0930 20:11:10.656431  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.656435  4070 net.cpp:137] Memory required for data: 119194800
I0930 20:11:10.656440  4070 layer_factory.hpp:77] Creating layer BatchNorm4
I0930 20:11:10.656445  4070 net.cpp:84] Creating Layer BatchNorm4
I0930 20:11:10.656446  4070 net.cpp:406] BatchNorm4 <- Convolution4
I0930 20:11:10.656450  4070 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0930 20:11:10.656584  4070 net.cpp:122] Setting up BatchNorm4
I0930 20:11:10.656589  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.656590  4070 net.cpp:137] Memory required for data: 125748400
I0930 20:11:10.656599  4070 layer_factory.hpp:77] Creating layer Scale4
I0930 20:11:10.656602  4070 net.cpp:84] Creating Layer Scale4
I0930 20:11:10.656605  4070 net.cpp:406] Scale4 <- Convolution4
I0930 20:11:10.656608  4070 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0930 20:11:10.656638  4070 layer_factory.hpp:77] Creating layer Scale4
I0930 20:11:10.656714  4070 net.cpp:122] Setting up Scale4
I0930 20:11:10.656719  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.656721  4070 net.cpp:137] Memory required for data: 132302000
I0930 20:11:10.656725  4070 layer_factory.hpp:77] Creating layer penlu4
I0930 20:11:10.656730  4070 net.cpp:84] Creating Layer penlu4
I0930 20:11:10.656733  4070 net.cpp:406] penlu4 <- Convolution4
I0930 20:11:10.656738  4070 net.cpp:367] penlu4 -> Convolution4 (in-place)
I0930 20:11:10.656855  4070 net.cpp:122] Setting up penlu4
I0930 20:11:10.656860  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.656862  4070 net.cpp:137] Memory required for data: 138855600
I0930 20:11:10.656867  4070 layer_factory.hpp:77] Creating layer Convolution5
I0930 20:11:10.656873  4070 net.cpp:84] Creating Layer Convolution5
I0930 20:11:10.656875  4070 net.cpp:406] Convolution5 <- Convolution4
I0930 20:11:10.656879  4070 net.cpp:380] Convolution5 -> Convolution5
I0930 20:11:10.658118  4070 net.cpp:122] Setting up Convolution5
I0930 20:11:10.658126  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.658129  4070 net.cpp:137] Memory required for data: 145409200
I0930 20:11:10.658133  4070 layer_factory.hpp:77] Creating layer BatchNorm5
I0930 20:11:10.658139  4070 net.cpp:84] Creating Layer BatchNorm5
I0930 20:11:10.658141  4070 net.cpp:406] BatchNorm5 <- Convolution5
I0930 20:11:10.658145  4070 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0930 20:11:10.658280  4070 net.cpp:122] Setting up BatchNorm5
I0930 20:11:10.658285  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.658288  4070 net.cpp:137] Memory required for data: 151962800
I0930 20:11:10.658293  4070 layer_factory.hpp:77] Creating layer Scale5
I0930 20:11:10.658296  4070 net.cpp:84] Creating Layer Scale5
I0930 20:11:10.658309  4070 net.cpp:406] Scale5 <- Convolution5
I0930 20:11:10.658313  4070 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0930 20:11:10.658341  4070 layer_factory.hpp:77] Creating layer Scale5
I0930 20:11:10.658440  4070 net.cpp:122] Setting up Scale5
I0930 20:11:10.658444  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.658447  4070 net.cpp:137] Memory required for data: 158516400
I0930 20:11:10.658450  4070 layer_factory.hpp:77] Creating layer Eltwise2
I0930 20:11:10.658455  4070 net.cpp:84] Creating Layer Eltwise2
I0930 20:11:10.658458  4070 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I0930 20:11:10.658462  4070 net.cpp:406] Eltwise2 <- Convolution5
I0930 20:11:10.658464  4070 net.cpp:380] Eltwise2 -> Eltwise2
I0930 20:11:10.658489  4070 net.cpp:122] Setting up Eltwise2
I0930 20:11:10.658494  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.658496  4070 net.cpp:137] Memory required for data: 165070000
I0930 20:11:10.658499  4070 layer_factory.hpp:77] Creating layer penlu5
I0930 20:11:10.658504  4070 net.cpp:84] Creating Layer penlu5
I0930 20:11:10.658506  4070 net.cpp:406] penlu5 <- Eltwise2
I0930 20:11:10.658510  4070 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I0930 20:11:10.658638  4070 net.cpp:122] Setting up penlu5
I0930 20:11:10.658644  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.658646  4070 net.cpp:137] Memory required for data: 171623600
I0930 20:11:10.658650  4070 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I0930 20:11:10.658654  4070 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I0930 20:11:10.658656  4070 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I0930 20:11:10.658660  4070 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I0930 20:11:10.658664  4070 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I0930 20:11:10.658690  4070 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I0930 20:11:10.658694  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.658699  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.658700  4070 net.cpp:137] Memory required for data: 184730800
I0930 20:11:10.658702  4070 layer_factory.hpp:77] Creating layer Convolution6
I0930 20:11:10.658709  4070 net.cpp:84] Creating Layer Convolution6
I0930 20:11:10.658711  4070 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I0930 20:11:10.658715  4070 net.cpp:380] Convolution6 -> Convolution6
I0930 20:11:10.659693  4070 net.cpp:122] Setting up Convolution6
I0930 20:11:10.659701  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.659703  4070 net.cpp:137] Memory required for data: 191284400
I0930 20:11:10.659708  4070 layer_factory.hpp:77] Creating layer BatchNorm6
I0930 20:11:10.659713  4070 net.cpp:84] Creating Layer BatchNorm6
I0930 20:11:10.659715  4070 net.cpp:406] BatchNorm6 <- Convolution6
I0930 20:11:10.659719  4070 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0930 20:11:10.659858  4070 net.cpp:122] Setting up BatchNorm6
I0930 20:11:10.659863  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.659865  4070 net.cpp:137] Memory required for data: 197838000
I0930 20:11:10.659870  4070 layer_factory.hpp:77] Creating layer Scale6
I0930 20:11:10.659874  4070 net.cpp:84] Creating Layer Scale6
I0930 20:11:10.659876  4070 net.cpp:406] Scale6 <- Convolution6
I0930 20:11:10.659880  4070 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0930 20:11:10.659909  4070 layer_factory.hpp:77] Creating layer Scale6
I0930 20:11:10.659986  4070 net.cpp:122] Setting up Scale6
I0930 20:11:10.659991  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.659993  4070 net.cpp:137] Memory required for data: 204391600
I0930 20:11:10.659996  4070 layer_factory.hpp:77] Creating layer penlu6
I0930 20:11:10.660002  4070 net.cpp:84] Creating Layer penlu6
I0930 20:11:10.660004  4070 net.cpp:406] penlu6 <- Convolution6
I0930 20:11:10.660008  4070 net.cpp:367] penlu6 -> Convolution6 (in-place)
I0930 20:11:10.660127  4070 net.cpp:122] Setting up penlu6
I0930 20:11:10.660132  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.660135  4070 net.cpp:137] Memory required for data: 210945200
I0930 20:11:10.660147  4070 layer_factory.hpp:77] Creating layer Convolution7
I0930 20:11:10.660156  4070 net.cpp:84] Creating Layer Convolution7
I0930 20:11:10.660157  4070 net.cpp:406] Convolution7 <- Convolution6
I0930 20:11:10.660161  4070 net.cpp:380] Convolution7 -> Convolution7
I0930 20:11:10.661113  4070 net.cpp:122] Setting up Convolution7
I0930 20:11:10.661121  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.661124  4070 net.cpp:137] Memory required for data: 217498800
I0930 20:11:10.661128  4070 layer_factory.hpp:77] Creating layer BatchNorm7
I0930 20:11:10.661136  4070 net.cpp:84] Creating Layer BatchNorm7
I0930 20:11:10.661147  4070 net.cpp:406] BatchNorm7 <- Convolution7
I0930 20:11:10.661152  4070 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0930 20:11:10.661288  4070 net.cpp:122] Setting up BatchNorm7
I0930 20:11:10.661293  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.661295  4070 net.cpp:137] Memory required for data: 224052400
I0930 20:11:10.661306  4070 layer_factory.hpp:77] Creating layer Scale7
I0930 20:11:10.661311  4070 net.cpp:84] Creating Layer Scale7
I0930 20:11:10.661314  4070 net.cpp:406] Scale7 <- Convolution7
I0930 20:11:10.661316  4070 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0930 20:11:10.661345  4070 layer_factory.hpp:77] Creating layer Scale7
I0930 20:11:10.661422  4070 net.cpp:122] Setting up Scale7
I0930 20:11:10.661427  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.661429  4070 net.cpp:137] Memory required for data: 230606000
I0930 20:11:10.661433  4070 layer_factory.hpp:77] Creating layer Eltwise3
I0930 20:11:10.661437  4070 net.cpp:84] Creating Layer Eltwise3
I0930 20:11:10.661439  4070 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I0930 20:11:10.661442  4070 net.cpp:406] Eltwise3 <- Convolution7
I0930 20:11:10.661447  4070 net.cpp:380] Eltwise3 -> Eltwise3
I0930 20:11:10.661461  4070 net.cpp:122] Setting up Eltwise3
I0930 20:11:10.661465  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.661468  4070 net.cpp:137] Memory required for data: 237159600
I0930 20:11:10.661469  4070 layer_factory.hpp:77] Creating layer penlu7
I0930 20:11:10.661474  4070 net.cpp:84] Creating Layer penlu7
I0930 20:11:10.661476  4070 net.cpp:406] penlu7 <- Eltwise3
I0930 20:11:10.661480  4070 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I0930 20:11:10.661597  4070 net.cpp:122] Setting up penlu7
I0930 20:11:10.661602  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.661604  4070 net.cpp:137] Memory required for data: 243713200
I0930 20:11:10.661608  4070 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I0930 20:11:10.661612  4070 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I0930 20:11:10.661614  4070 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I0930 20:11:10.661617  4070 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I0930 20:11:10.661622  4070 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I0930 20:11:10.661644  4070 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I0930 20:11:10.661648  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.661651  4070 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0930 20:11:10.661653  4070 net.cpp:137] Memory required for data: 256820400
I0930 20:11:10.661655  4070 layer_factory.hpp:77] Creating layer Convolution8
I0930 20:11:10.661661  4070 net.cpp:84] Creating Layer Convolution8
I0930 20:11:10.661664  4070 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I0930 20:11:10.661669  4070 net.cpp:380] Convolution8 -> Convolution8
I0930 20:11:10.662550  4070 net.cpp:122] Setting up Convolution8
I0930 20:11:10.662559  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.662561  4070 net.cpp:137] Memory required for data: 260097200
I0930 20:11:10.662566  4070 layer_factory.hpp:77] Creating layer BatchNorm8
I0930 20:11:10.662571  4070 net.cpp:84] Creating Layer BatchNorm8
I0930 20:11:10.662573  4070 net.cpp:406] BatchNorm8 <- Convolution8
I0930 20:11:10.662577  4070 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0930 20:11:10.662708  4070 net.cpp:122] Setting up BatchNorm8
I0930 20:11:10.662713  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.662714  4070 net.cpp:137] Memory required for data: 263374000
I0930 20:11:10.662719  4070 layer_factory.hpp:77] Creating layer Scale8
I0930 20:11:10.662724  4070 net.cpp:84] Creating Layer Scale8
I0930 20:11:10.665652  4070 net.cpp:406] Scale8 <- Convolution8
I0930 20:11:10.665659  4070 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0930 20:11:10.665706  4070 layer_factory.hpp:77] Creating layer Scale8
I0930 20:11:10.665834  4070 net.cpp:122] Setting up Scale8
I0930 20:11:10.665843  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.665848  4070 net.cpp:137] Memory required for data: 266650800
I0930 20:11:10.665855  4070 layer_factory.hpp:77] Creating layer Convolution9
I0930 20:11:10.665865  4070 net.cpp:84] Creating Layer Convolution9
I0930 20:11:10.665870  4070 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_1
I0930 20:11:10.665879  4070 net.cpp:380] Convolution9 -> Convolution9
I0930 20:11:10.667366  4070 net.cpp:122] Setting up Convolution9
I0930 20:11:10.667378  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.667383  4070 net.cpp:137] Memory required for data: 269927600
I0930 20:11:10.667390  4070 layer_factory.hpp:77] Creating layer BatchNorm9
I0930 20:11:10.667397  4070 net.cpp:84] Creating Layer BatchNorm9
I0930 20:11:10.667402  4070 net.cpp:406] BatchNorm9 <- Convolution9
I0930 20:11:10.667407  4070 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0930 20:11:10.667598  4070 net.cpp:122] Setting up BatchNorm9
I0930 20:11:10.667608  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.667611  4070 net.cpp:137] Memory required for data: 273204400
I0930 20:11:10.667619  4070 layer_factory.hpp:77] Creating layer Scale9
I0930 20:11:10.667628  4070 net.cpp:84] Creating Layer Scale9
I0930 20:11:10.667631  4070 net.cpp:406] Scale9 <- Convolution9
I0930 20:11:10.667637  4070 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0930 20:11:10.667683  4070 layer_factory.hpp:77] Creating layer Scale9
I0930 20:11:10.667801  4070 net.cpp:122] Setting up Scale9
I0930 20:11:10.667810  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.667814  4070 net.cpp:137] Memory required for data: 276481200
I0930 20:11:10.667820  4070 layer_factory.hpp:77] Creating layer penlu8
I0930 20:11:10.667830  4070 net.cpp:84] Creating Layer penlu8
I0930 20:11:10.667835  4070 net.cpp:406] penlu8 <- Convolution9
I0930 20:11:10.667842  4070 net.cpp:367] penlu8 -> Convolution9 (in-place)
I0930 20:11:10.667990  4070 net.cpp:122] Setting up penlu8
I0930 20:11:10.667999  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.668001  4070 net.cpp:137] Memory required for data: 279758000
I0930 20:11:10.668009  4070 layer_factory.hpp:77] Creating layer Convolution10
I0930 20:11:10.668017  4070 net.cpp:84] Creating Layer Convolution10
I0930 20:11:10.668022  4070 net.cpp:406] Convolution10 <- Convolution9
I0930 20:11:10.668028  4070 net.cpp:380] Convolution10 -> Convolution10
I0930 20:11:10.669657  4070 net.cpp:122] Setting up Convolution10
I0930 20:11:10.669667  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.669670  4070 net.cpp:137] Memory required for data: 283034800
I0930 20:11:10.669674  4070 layer_factory.hpp:77] Creating layer BatchNorm10
I0930 20:11:10.669679  4070 net.cpp:84] Creating Layer BatchNorm10
I0930 20:11:10.669682  4070 net.cpp:406] BatchNorm10 <- Convolution10
I0930 20:11:10.669687  4070 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0930 20:11:10.669823  4070 net.cpp:122] Setting up BatchNorm10
I0930 20:11:10.669827  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.669829  4070 net.cpp:137] Memory required for data: 286311600
I0930 20:11:10.669834  4070 layer_factory.hpp:77] Creating layer Scale10
I0930 20:11:10.669838  4070 net.cpp:84] Creating Layer Scale10
I0930 20:11:10.669842  4070 net.cpp:406] Scale10 <- Convolution10
I0930 20:11:10.669844  4070 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0930 20:11:10.669872  4070 layer_factory.hpp:77] Creating layer Scale10
I0930 20:11:10.669950  4070 net.cpp:122] Setting up Scale10
I0930 20:11:10.669955  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.669957  4070 net.cpp:137] Memory required for data: 289588400
I0930 20:11:10.669961  4070 layer_factory.hpp:77] Creating layer Eltwise4
I0930 20:11:10.669966  4070 net.cpp:84] Creating Layer Eltwise4
I0930 20:11:10.669968  4070 net.cpp:406] Eltwise4 <- Convolution8
I0930 20:11:10.669971  4070 net.cpp:406] Eltwise4 <- Convolution10
I0930 20:11:10.669982  4070 net.cpp:380] Eltwise4 -> Eltwise4
I0930 20:11:10.669997  4070 net.cpp:122] Setting up Eltwise4
I0930 20:11:10.670001  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.670003  4070 net.cpp:137] Memory required for data: 292865200
I0930 20:11:10.670006  4070 layer_factory.hpp:77] Creating layer penlu9
I0930 20:11:10.670011  4070 net.cpp:84] Creating Layer penlu9
I0930 20:11:10.670013  4070 net.cpp:406] penlu9 <- Eltwise4
I0930 20:11:10.670017  4070 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I0930 20:11:10.670133  4070 net.cpp:122] Setting up penlu9
I0930 20:11:10.670138  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.670140  4070 net.cpp:137] Memory required for data: 296142000
I0930 20:11:10.670145  4070 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I0930 20:11:10.670148  4070 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I0930 20:11:10.670151  4070 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I0930 20:11:10.670156  4070 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I0930 20:11:10.670159  4070 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I0930 20:11:10.670182  4070 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I0930 20:11:10.670186  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.670189  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.670192  4070 net.cpp:137] Memory required for data: 302695600
I0930 20:11:10.670193  4070 layer_factory.hpp:77] Creating layer Convolution11
I0930 20:11:10.670200  4070 net.cpp:84] Creating Layer Convolution11
I0930 20:11:10.670202  4070 net.cpp:406] Convolution11 <- Eltwise4_penlu9_0_split_0
I0930 20:11:10.670207  4070 net.cpp:380] Convolution11 -> Convolution11
I0930 20:11:10.671295  4070 net.cpp:122] Setting up Convolution11
I0930 20:11:10.671304  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.671308  4070 net.cpp:137] Memory required for data: 305972400
I0930 20:11:10.671311  4070 layer_factory.hpp:77] Creating layer BatchNorm11
I0930 20:11:10.671316  4070 net.cpp:84] Creating Layer BatchNorm11
I0930 20:11:10.671319  4070 net.cpp:406] BatchNorm11 <- Convolution11
I0930 20:11:10.671324  4070 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0930 20:11:10.671460  4070 net.cpp:122] Setting up BatchNorm11
I0930 20:11:10.671465  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.671468  4070 net.cpp:137] Memory required for data: 309249200
I0930 20:11:10.671471  4070 layer_factory.hpp:77] Creating layer Scale11
I0930 20:11:10.671476  4070 net.cpp:84] Creating Layer Scale11
I0930 20:11:10.671479  4070 net.cpp:406] Scale11 <- Convolution11
I0930 20:11:10.671483  4070 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0930 20:11:10.671510  4070 layer_factory.hpp:77] Creating layer Scale11
I0930 20:11:10.671588  4070 net.cpp:122] Setting up Scale11
I0930 20:11:10.671593  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.671596  4070 net.cpp:137] Memory required for data: 312526000
I0930 20:11:10.671599  4070 layer_factory.hpp:77] Creating layer penlu10
I0930 20:11:10.671604  4070 net.cpp:84] Creating Layer penlu10
I0930 20:11:10.671607  4070 net.cpp:406] penlu10 <- Convolution11
I0930 20:11:10.671612  4070 net.cpp:367] penlu10 -> Convolution11 (in-place)
I0930 20:11:10.671721  4070 net.cpp:122] Setting up penlu10
I0930 20:11:10.671726  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.671728  4070 net.cpp:137] Memory required for data: 315802800
I0930 20:11:10.671732  4070 layer_factory.hpp:77] Creating layer Convolution12
I0930 20:11:10.671739  4070 net.cpp:84] Creating Layer Convolution12
I0930 20:11:10.671741  4070 net.cpp:406] Convolution12 <- Convolution11
I0930 20:11:10.671746  4070 net.cpp:380] Convolution12 -> Convolution12
I0930 20:11:10.672492  4070 net.cpp:122] Setting up Convolution12
I0930 20:11:10.672500  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.672503  4070 net.cpp:137] Memory required for data: 319079600
I0930 20:11:10.672514  4070 layer_factory.hpp:77] Creating layer BatchNorm12
I0930 20:11:10.672519  4070 net.cpp:84] Creating Layer BatchNorm12
I0930 20:11:10.672523  4070 net.cpp:406] BatchNorm12 <- Convolution12
I0930 20:11:10.672525  4070 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0930 20:11:10.672664  4070 net.cpp:122] Setting up BatchNorm12
I0930 20:11:10.672669  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.672672  4070 net.cpp:137] Memory required for data: 322356400
I0930 20:11:10.672677  4070 layer_factory.hpp:77] Creating layer Scale12
I0930 20:11:10.672680  4070 net.cpp:84] Creating Layer Scale12
I0930 20:11:10.672683  4070 net.cpp:406] Scale12 <- Convolution12
I0930 20:11:10.672685  4070 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0930 20:11:10.672713  4070 layer_factory.hpp:77] Creating layer Scale12
I0930 20:11:10.672791  4070 net.cpp:122] Setting up Scale12
I0930 20:11:10.672797  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.672799  4070 net.cpp:137] Memory required for data: 325633200
I0930 20:11:10.672803  4070 layer_factory.hpp:77] Creating layer Eltwise5
I0930 20:11:10.672807  4070 net.cpp:84] Creating Layer Eltwise5
I0930 20:11:10.672809  4070 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I0930 20:11:10.672812  4070 net.cpp:406] Eltwise5 <- Convolution12
I0930 20:11:10.672816  4070 net.cpp:380] Eltwise5 -> Eltwise5
I0930 20:11:10.672829  4070 net.cpp:122] Setting up Eltwise5
I0930 20:11:10.672833  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.672835  4070 net.cpp:137] Memory required for data: 328910000
I0930 20:11:10.672838  4070 layer_factory.hpp:77] Creating layer penlu11
I0930 20:11:10.672843  4070 net.cpp:84] Creating Layer penlu11
I0930 20:11:10.672845  4070 net.cpp:406] penlu11 <- Eltwise5
I0930 20:11:10.672849  4070 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I0930 20:11:10.672965  4070 net.cpp:122] Setting up penlu11
I0930 20:11:10.672969  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.672971  4070 net.cpp:137] Memory required for data: 332186800
I0930 20:11:10.672976  4070 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I0930 20:11:10.672979  4070 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I0930 20:11:10.672981  4070 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I0930 20:11:10.672986  4070 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I0930 20:11:10.672991  4070 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I0930 20:11:10.673017  4070 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I0930 20:11:10.673020  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.673024  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.673027  4070 net.cpp:137] Memory required for data: 338740400
I0930 20:11:10.673028  4070 layer_factory.hpp:77] Creating layer Convolution13
I0930 20:11:10.673034  4070 net.cpp:84] Creating Layer Convolution13
I0930 20:11:10.673036  4070 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_0
I0930 20:11:10.673043  4070 net.cpp:380] Convolution13 -> Convolution13
I0930 20:11:10.674116  4070 net.cpp:122] Setting up Convolution13
I0930 20:11:10.674125  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.674129  4070 net.cpp:137] Memory required for data: 342017200
I0930 20:11:10.674132  4070 layer_factory.hpp:77] Creating layer BatchNorm13
I0930 20:11:10.674137  4070 net.cpp:84] Creating Layer BatchNorm13
I0930 20:11:10.674140  4070 net.cpp:406] BatchNorm13 <- Convolution13
I0930 20:11:10.674144  4070 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0930 20:11:10.674281  4070 net.cpp:122] Setting up BatchNorm13
I0930 20:11:10.674286  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.674288  4070 net.cpp:137] Memory required for data: 345294000
I0930 20:11:10.674293  4070 layer_factory.hpp:77] Creating layer Scale13
I0930 20:11:10.674298  4070 net.cpp:84] Creating Layer Scale13
I0930 20:11:10.674300  4070 net.cpp:406] Scale13 <- Convolution13
I0930 20:11:10.674309  4070 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0930 20:11:10.674340  4070 layer_factory.hpp:77] Creating layer Scale13
I0930 20:11:10.674418  4070 net.cpp:122] Setting up Scale13
I0930 20:11:10.674423  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.674425  4070 net.cpp:137] Memory required for data: 348570800
I0930 20:11:10.674429  4070 layer_factory.hpp:77] Creating layer penlu12
I0930 20:11:10.674434  4070 net.cpp:84] Creating Layer penlu12
I0930 20:11:10.674437  4070 net.cpp:406] penlu12 <- Convolution13
I0930 20:11:10.674440  4070 net.cpp:367] penlu12 -> Convolution13 (in-place)
I0930 20:11:10.674561  4070 net.cpp:122] Setting up penlu12
I0930 20:11:10.674567  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.674569  4070 net.cpp:137] Memory required for data: 351847600
I0930 20:11:10.674574  4070 layer_factory.hpp:77] Creating layer Convolution14
I0930 20:11:10.674584  4070 net.cpp:84] Creating Layer Convolution14
I0930 20:11:10.674587  4070 net.cpp:406] Convolution14 <- Convolution13
I0930 20:11:10.674590  4070 net.cpp:380] Convolution14 -> Convolution14
I0930 20:11:10.675698  4070 net.cpp:122] Setting up Convolution14
I0930 20:11:10.675706  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.675709  4070 net.cpp:137] Memory required for data: 355124400
I0930 20:11:10.675726  4070 layer_factory.hpp:77] Creating layer BatchNorm14
I0930 20:11:10.675741  4070 net.cpp:84] Creating Layer BatchNorm14
I0930 20:11:10.675745  4070 net.cpp:406] BatchNorm14 <- Convolution14
I0930 20:11:10.675748  4070 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0930 20:11:10.675895  4070 net.cpp:122] Setting up BatchNorm14
I0930 20:11:10.675900  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.675904  4070 net.cpp:137] Memory required for data: 358401200
I0930 20:11:10.675907  4070 layer_factory.hpp:77] Creating layer Scale14
I0930 20:11:10.675911  4070 net.cpp:84] Creating Layer Scale14
I0930 20:11:10.675915  4070 net.cpp:406] Scale14 <- Convolution14
I0930 20:11:10.675917  4070 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0930 20:11:10.675945  4070 layer_factory.hpp:77] Creating layer Scale14
I0930 20:11:10.676024  4070 net.cpp:122] Setting up Scale14
I0930 20:11:10.676029  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.676033  4070 net.cpp:137] Memory required for data: 361678000
I0930 20:11:10.676036  4070 layer_factory.hpp:77] Creating layer Eltwise6
I0930 20:11:10.676039  4070 net.cpp:84] Creating Layer Eltwise6
I0930 20:11:10.676043  4070 net.cpp:406] Eltwise6 <- Eltwise5_penlu11_0_split_1
I0930 20:11:10.676045  4070 net.cpp:406] Eltwise6 <- Convolution14
I0930 20:11:10.676048  4070 net.cpp:380] Eltwise6 -> Eltwise6
I0930 20:11:10.676062  4070 net.cpp:122] Setting up Eltwise6
I0930 20:11:10.676065  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.676069  4070 net.cpp:137] Memory required for data: 364954800
I0930 20:11:10.676070  4070 layer_factory.hpp:77] Creating layer penlu13
I0930 20:11:10.676075  4070 net.cpp:84] Creating Layer penlu13
I0930 20:11:10.676077  4070 net.cpp:406] penlu13 <- Eltwise6
I0930 20:11:10.676081  4070 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I0930 20:11:10.676198  4070 net.cpp:122] Setting up penlu13
I0930 20:11:10.676203  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.676204  4070 net.cpp:137] Memory required for data: 368231600
I0930 20:11:10.676208  4070 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I0930 20:11:10.676213  4070 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I0930 20:11:10.676214  4070 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I0930 20:11:10.676218  4070 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I0930 20:11:10.696760  4070 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I0930 20:11:10.696854  4070 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I0930 20:11:10.696866  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.696871  4070 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0930 20:11:10.696887  4070 net.cpp:137] Memory required for data: 374785200
I0930 20:11:10.696893  4070 layer_factory.hpp:77] Creating layer Convolution15
I0930 20:11:10.696909  4070 net.cpp:84] Creating Layer Convolution15
I0930 20:11:10.696915  4070 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I0930 20:11:10.696924  4070 net.cpp:380] Convolution15 -> Convolution15
I0930 20:11:10.698467  4070 net.cpp:122] Setting up Convolution15
I0930 20:11:10.698479  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.698483  4070 net.cpp:137] Memory required for data: 376423600
I0930 20:11:10.698493  4070 layer_factory.hpp:77] Creating layer BatchNorm15
I0930 20:11:10.698499  4070 net.cpp:84] Creating Layer BatchNorm15
I0930 20:11:10.698503  4070 net.cpp:406] BatchNorm15 <- Convolution15
I0930 20:11:10.698509  4070 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0930 20:11:10.698738  4070 net.cpp:122] Setting up BatchNorm15
I0930 20:11:10.698748  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.698753  4070 net.cpp:137] Memory required for data: 378062000
I0930 20:11:10.698763  4070 layer_factory.hpp:77] Creating layer Scale15
I0930 20:11:10.698770  4070 net.cpp:84] Creating Layer Scale15
I0930 20:11:10.698774  4070 net.cpp:406] Scale15 <- Convolution15
I0930 20:11:10.698781  4070 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0930 20:11:10.698832  4070 layer_factory.hpp:77] Creating layer Scale15
I0930 20:11:10.698959  4070 net.cpp:122] Setting up Scale15
I0930 20:11:10.698978  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.698982  4070 net.cpp:137] Memory required for data: 379700400
I0930 20:11:10.698987  4070 layer_factory.hpp:77] Creating layer Convolution16
I0930 20:11:10.698994  4070 net.cpp:84] Creating Layer Convolution16
I0930 20:11:10.698997  4070 net.cpp:406] Convolution16 <- Eltwise6_penlu13_0_split_1
I0930 20:11:10.699002  4070 net.cpp:380] Convolution16 -> Convolution16
I0930 20:11:10.700767  4070 net.cpp:122] Setting up Convolution16
I0930 20:11:10.700778  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.700780  4070 net.cpp:137] Memory required for data: 381338800
I0930 20:11:10.700785  4070 layer_factory.hpp:77] Creating layer BatchNorm16
I0930 20:11:10.700789  4070 net.cpp:84] Creating Layer BatchNorm16
I0930 20:11:10.700793  4070 net.cpp:406] BatchNorm16 <- Convolution16
I0930 20:11:10.700798  4070 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0930 20:11:10.700938  4070 net.cpp:122] Setting up BatchNorm16
I0930 20:11:10.700942  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.700945  4070 net.cpp:137] Memory required for data: 382977200
I0930 20:11:10.700949  4070 layer_factory.hpp:77] Creating layer Scale16
I0930 20:11:10.700953  4070 net.cpp:84] Creating Layer Scale16
I0930 20:11:10.700956  4070 net.cpp:406] Scale16 <- Convolution16
I0930 20:11:10.700960  4070 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0930 20:11:10.700989  4070 layer_factory.hpp:77] Creating layer Scale16
I0930 20:11:10.701069  4070 net.cpp:122] Setting up Scale16
I0930 20:11:10.701074  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.701076  4070 net.cpp:137] Memory required for data: 384615600
I0930 20:11:10.701081  4070 layer_factory.hpp:77] Creating layer penlu14
I0930 20:11:10.701086  4070 net.cpp:84] Creating Layer penlu14
I0930 20:11:10.701089  4070 net.cpp:406] penlu14 <- Convolution16
I0930 20:11:10.701093  4070 net.cpp:367] penlu14 -> Convolution16 (in-place)
I0930 20:11:10.701207  4070 net.cpp:122] Setting up penlu14
I0930 20:11:10.701213  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.701215  4070 net.cpp:137] Memory required for data: 386254000
I0930 20:11:10.701220  4070 layer_factory.hpp:77] Creating layer Convolution17
I0930 20:11:10.701226  4070 net.cpp:84] Creating Layer Convolution17
I0930 20:11:10.701230  4070 net.cpp:406] Convolution17 <- Convolution16
I0930 20:11:10.701233  4070 net.cpp:380] Convolution17 -> Convolution17
I0930 20:11:10.702949  4070 net.cpp:122] Setting up Convolution17
I0930 20:11:10.702965  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.702968  4070 net.cpp:137] Memory required for data: 387892400
I0930 20:11:10.702972  4070 layer_factory.hpp:77] Creating layer BatchNorm17
I0930 20:11:10.702978  4070 net.cpp:84] Creating Layer BatchNorm17
I0930 20:11:10.702980  4070 net.cpp:406] BatchNorm17 <- Convolution17
I0930 20:11:10.702985  4070 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0930 20:11:10.703130  4070 net.cpp:122] Setting up BatchNorm17
I0930 20:11:10.703135  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.703136  4070 net.cpp:137] Memory required for data: 389530800
I0930 20:11:10.703141  4070 layer_factory.hpp:77] Creating layer Scale17
I0930 20:11:10.703145  4070 net.cpp:84] Creating Layer Scale17
I0930 20:11:10.703147  4070 net.cpp:406] Scale17 <- Convolution17
I0930 20:11:10.703150  4070 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0930 20:11:10.703181  4070 layer_factory.hpp:77] Creating layer Scale17
I0930 20:11:10.703263  4070 net.cpp:122] Setting up Scale17
I0930 20:11:10.703269  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.703270  4070 net.cpp:137] Memory required for data: 391169200
I0930 20:11:10.703274  4070 layer_factory.hpp:77] Creating layer Eltwise7
I0930 20:11:10.703279  4070 net.cpp:84] Creating Layer Eltwise7
I0930 20:11:10.703281  4070 net.cpp:406] Eltwise7 <- Convolution15
I0930 20:11:10.703284  4070 net.cpp:406] Eltwise7 <- Convolution17
I0930 20:11:10.703287  4070 net.cpp:380] Eltwise7 -> Eltwise7
I0930 20:11:10.703307  4070 net.cpp:122] Setting up Eltwise7
I0930 20:11:10.703311  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.703313  4070 net.cpp:137] Memory required for data: 392807600
I0930 20:11:10.703315  4070 layer_factory.hpp:77] Creating layer penlu15
I0930 20:11:10.703321  4070 net.cpp:84] Creating Layer penlu15
I0930 20:11:10.703323  4070 net.cpp:406] penlu15 <- Eltwise7
I0930 20:11:10.703328  4070 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I0930 20:11:10.703441  4070 net.cpp:122] Setting up penlu15
I0930 20:11:10.703446  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.703449  4070 net.cpp:137] Memory required for data: 394446000
I0930 20:11:10.703452  4070 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I0930 20:11:10.703456  4070 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I0930 20:11:10.703459  4070 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I0930 20:11:10.703462  4070 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I0930 20:11:10.703466  4070 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I0930 20:11:10.703490  4070 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I0930 20:11:10.703495  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.703497  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.703500  4070 net.cpp:137] Memory required for data: 397722800
I0930 20:11:10.703502  4070 layer_factory.hpp:77] Creating layer Convolution18
I0930 20:11:10.703507  4070 net.cpp:84] Creating Layer Convolution18
I0930 20:11:10.703510  4070 net.cpp:406] Convolution18 <- Eltwise7_penlu15_0_split_0
I0930 20:11:10.703514  4070 net.cpp:380] Convolution18 -> Convolution18
I0930 20:11:10.705206  4070 net.cpp:122] Setting up Convolution18
I0930 20:11:10.705215  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.705217  4070 net.cpp:137] Memory required for data: 399361200
I0930 20:11:10.705222  4070 layer_factory.hpp:77] Creating layer BatchNorm18
I0930 20:11:10.705227  4070 net.cpp:84] Creating Layer BatchNorm18
I0930 20:11:10.705230  4070 net.cpp:406] BatchNorm18 <- Convolution18
I0930 20:11:10.705235  4070 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0930 20:11:10.705376  4070 net.cpp:122] Setting up BatchNorm18
I0930 20:11:10.705380  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.705384  4070 net.cpp:137] Memory required for data: 400999600
I0930 20:11:10.705387  4070 layer_factory.hpp:77] Creating layer Scale18
I0930 20:11:10.705399  4070 net.cpp:84] Creating Layer Scale18
I0930 20:11:10.705401  4070 net.cpp:406] Scale18 <- Convolution18
I0930 20:11:10.705404  4070 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0930 20:11:10.705435  4070 layer_factory.hpp:77] Creating layer Scale18
I0930 20:11:10.705516  4070 net.cpp:122] Setting up Scale18
I0930 20:11:10.705521  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.705523  4070 net.cpp:137] Memory required for data: 402638000
I0930 20:11:10.705528  4070 layer_factory.hpp:77] Creating layer penlu16
I0930 20:11:10.705533  4070 net.cpp:84] Creating Layer penlu16
I0930 20:11:10.705534  4070 net.cpp:406] penlu16 <- Convolution18
I0930 20:11:10.705539  4070 net.cpp:367] penlu16 -> Convolution18 (in-place)
I0930 20:11:10.705653  4070 net.cpp:122] Setting up penlu16
I0930 20:11:10.705658  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.705660  4070 net.cpp:137] Memory required for data: 404276400
I0930 20:11:10.705665  4070 layer_factory.hpp:77] Creating layer Convolution19
I0930 20:11:10.705672  4070 net.cpp:84] Creating Layer Convolution19
I0930 20:11:10.705674  4070 net.cpp:406] Convolution19 <- Convolution18
I0930 20:11:10.705678  4070 net.cpp:380] Convolution19 -> Convolution19
I0930 20:11:10.707394  4070 net.cpp:122] Setting up Convolution19
I0930 20:11:10.707403  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.707406  4070 net.cpp:137] Memory required for data: 405914800
I0930 20:11:10.707412  4070 layer_factory.hpp:77] Creating layer BatchNorm19
I0930 20:11:10.707417  4070 net.cpp:84] Creating Layer BatchNorm19
I0930 20:11:10.707419  4070 net.cpp:406] BatchNorm19 <- Convolution19
I0930 20:11:10.707422  4070 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0930 20:11:10.707566  4070 net.cpp:122] Setting up BatchNorm19
I0930 20:11:10.707571  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.707573  4070 net.cpp:137] Memory required for data: 407553200
I0930 20:11:10.707577  4070 layer_factory.hpp:77] Creating layer Scale19
I0930 20:11:10.707581  4070 net.cpp:84] Creating Layer Scale19
I0930 20:11:10.707584  4070 net.cpp:406] Scale19 <- Convolution19
I0930 20:11:10.707587  4070 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0930 20:11:10.707617  4070 layer_factory.hpp:77] Creating layer Scale19
I0930 20:11:10.707697  4070 net.cpp:122] Setting up Scale19
I0930 20:11:10.707702  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.707705  4070 net.cpp:137] Memory required for data: 409191600
I0930 20:11:10.707708  4070 layer_factory.hpp:77] Creating layer Eltwise8
I0930 20:11:10.707712  4070 net.cpp:84] Creating Layer Eltwise8
I0930 20:11:10.707715  4070 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I0930 20:11:10.707718  4070 net.cpp:406] Eltwise8 <- Convolution19
I0930 20:11:10.707721  4070 net.cpp:380] Eltwise8 -> Eltwise8
I0930 20:11:10.707739  4070 net.cpp:122] Setting up Eltwise8
I0930 20:11:10.707743  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.707746  4070 net.cpp:137] Memory required for data: 410830000
I0930 20:11:10.707747  4070 layer_factory.hpp:77] Creating layer penlu17
I0930 20:11:10.707753  4070 net.cpp:84] Creating Layer penlu17
I0930 20:11:10.707756  4070 net.cpp:406] penlu17 <- Eltwise8
I0930 20:11:10.707759  4070 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I0930 20:11:10.707875  4070 net.cpp:122] Setting up penlu17
I0930 20:11:10.707878  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.707880  4070 net.cpp:137] Memory required for data: 412468400
I0930 20:11:10.707885  4070 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I0930 20:11:10.707890  4070 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I0930 20:11:10.707891  4070 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I0930 20:11:10.707895  4070 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I0930 20:11:10.707900  4070 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I0930 20:11:10.707923  4070 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I0930 20:11:10.707933  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.707937  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.707939  4070 net.cpp:137] Memory required for data: 415745200
I0930 20:11:10.707942  4070 layer_factory.hpp:77] Creating layer Convolution20
I0930 20:11:10.707947  4070 net.cpp:84] Creating Layer Convolution20
I0930 20:11:10.707949  4070 net.cpp:406] Convolution20 <- Eltwise8_penlu17_0_split_0
I0930 20:11:10.707954  4070 net.cpp:380] Convolution20 -> Convolution20
I0930 20:11:10.710047  4070 net.cpp:122] Setting up Convolution20
I0930 20:11:10.710055  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.710058  4070 net.cpp:137] Memory required for data: 417383600
I0930 20:11:10.710063  4070 layer_factory.hpp:77] Creating layer BatchNorm20
I0930 20:11:10.710068  4070 net.cpp:84] Creating Layer BatchNorm20
I0930 20:11:10.710072  4070 net.cpp:406] BatchNorm20 <- Convolution20
I0930 20:11:10.710075  4070 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0930 20:11:10.710233  4070 net.cpp:122] Setting up BatchNorm20
I0930 20:11:10.710237  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.710240  4070 net.cpp:137] Memory required for data: 419022000
I0930 20:11:10.710244  4070 layer_factory.hpp:77] Creating layer Scale20
I0930 20:11:10.710248  4070 net.cpp:84] Creating Layer Scale20
I0930 20:11:10.710252  4070 net.cpp:406] Scale20 <- Convolution20
I0930 20:11:10.710256  4070 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0930 20:11:10.710285  4070 layer_factory.hpp:77] Creating layer Scale20
I0930 20:11:10.710367  4070 net.cpp:122] Setting up Scale20
I0930 20:11:10.710372  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.710374  4070 net.cpp:137] Memory required for data: 420660400
I0930 20:11:10.710378  4070 layer_factory.hpp:77] Creating layer penlu18
I0930 20:11:10.710384  4070 net.cpp:84] Creating Layer penlu18
I0930 20:11:10.710387  4070 net.cpp:406] penlu18 <- Convolution20
I0930 20:11:10.710391  4070 net.cpp:367] penlu18 -> Convolution20 (in-place)
I0930 20:11:10.710505  4070 net.cpp:122] Setting up penlu18
I0930 20:11:10.710510  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.710511  4070 net.cpp:137] Memory required for data: 422298800
I0930 20:11:10.710516  4070 layer_factory.hpp:77] Creating layer Convolution21
I0930 20:11:10.710527  4070 net.cpp:84] Creating Layer Convolution21
I0930 20:11:10.710531  4070 net.cpp:406] Convolution21 <- Convolution20
I0930 20:11:10.710536  4070 net.cpp:380] Convolution21 -> Convolution21
I0930 20:11:10.712586  4070 net.cpp:122] Setting up Convolution21
I0930 20:11:10.712595  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.712599  4070 net.cpp:137] Memory required for data: 423937200
I0930 20:11:10.712604  4070 layer_factory.hpp:77] Creating layer BatchNorm21
I0930 20:11:10.712608  4070 net.cpp:84] Creating Layer BatchNorm21
I0930 20:11:10.712611  4070 net.cpp:406] BatchNorm21 <- Convolution21
I0930 20:11:10.712615  4070 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0930 20:11:10.712759  4070 net.cpp:122] Setting up BatchNorm21
I0930 20:11:10.712764  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.712766  4070 net.cpp:137] Memory required for data: 425575600
I0930 20:11:10.712771  4070 layer_factory.hpp:77] Creating layer Scale21
I0930 20:11:10.712774  4070 net.cpp:84] Creating Layer Scale21
I0930 20:11:10.712777  4070 net.cpp:406] Scale21 <- Convolution21
I0930 20:11:10.712780  4070 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0930 20:11:10.727813  4070 layer_factory.hpp:77] Creating layer Scale21
I0930 20:11:10.727943  4070 net.cpp:122] Setting up Scale21
I0930 20:11:10.727952  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.727957  4070 net.cpp:137] Memory required for data: 427214000
I0930 20:11:10.727963  4070 layer_factory.hpp:77] Creating layer Eltwise9
I0930 20:11:10.727970  4070 net.cpp:84] Creating Layer Eltwise9
I0930 20:11:10.727975  4070 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I0930 20:11:10.727991  4070 net.cpp:406] Eltwise9 <- Convolution21
I0930 20:11:10.727999  4070 net.cpp:380] Eltwise9 -> Eltwise9
I0930 20:11:10.728026  4070 net.cpp:122] Setting up Eltwise9
I0930 20:11:10.728034  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.728046  4070 net.cpp:137] Memory required for data: 428852400
I0930 20:11:10.728050  4070 layer_factory.hpp:77] Creating layer penlu19
I0930 20:11:10.728060  4070 net.cpp:84] Creating Layer penlu19
I0930 20:11:10.728065  4070 net.cpp:406] penlu19 <- Eltwise9
I0930 20:11:10.728070  4070 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I0930 20:11:10.728263  4070 net.cpp:122] Setting up penlu19
I0930 20:11:10.728271  4070 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0930 20:11:10.728276  4070 net.cpp:137] Memory required for data: 430490800
I0930 20:11:10.728282  4070 layer_factory.hpp:77] Creating layer Pooling1
I0930 20:11:10.728291  4070 net.cpp:84] Creating Layer Pooling1
I0930 20:11:10.728294  4070 net.cpp:406] Pooling1 <- Eltwise9
I0930 20:11:10.728301  4070 net.cpp:380] Pooling1 -> Pooling1
I0930 20:11:10.728502  4070 net.cpp:122] Setting up Pooling1
I0930 20:11:10.728512  4070 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0930 20:11:10.728515  4070 net.cpp:137] Memory required for data: 430516400
I0930 20:11:10.728519  4070 layer_factory.hpp:77] Creating layer InnerProduct1
I0930 20:11:10.728528  4070 net.cpp:84] Creating Layer InnerProduct1
I0930 20:11:10.728533  4070 net.cpp:406] InnerProduct1 <- Pooling1
I0930 20:11:10.728539  4070 net.cpp:380] InnerProduct1 -> InnerProduct1
I0930 20:11:10.728679  4070 net.cpp:122] Setting up InnerProduct1
I0930 20:11:10.728687  4070 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:11:10.728690  4070 net.cpp:137] Memory required for data: 430520400
I0930 20:11:10.728698  4070 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0930 20:11:10.728703  4070 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0930 20:11:10.728708  4070 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0930 20:11:10.728714  4070 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0930 20:11:10.728721  4070 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0930 20:11:10.728760  4070 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0930 20:11:10.728767  4070 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:11:10.728772  4070 net.cpp:129] Top shape: 100 10 (1000)
I0930 20:11:10.728775  4070 net.cpp:137] Memory required for data: 430528400
I0930 20:11:10.728780  4070 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:11:10.728786  4070 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0930 20:11:10.728790  4070 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0930 20:11:10.728796  4070 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0930 20:11:10.728801  4070 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0930 20:11:10.728809  4070 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0930 20:11:10.729073  4070 net.cpp:122] Setting up SoftmaxWithLoss1
I0930 20:11:10.729082  4070 net.cpp:129] Top shape: (1)
I0930 20:11:10.729086  4070 net.cpp:132]     with loss weight 1
I0930 20:11:10.729097  4070 net.cpp:137] Memory required for data: 430528404
I0930 20:11:10.729101  4070 layer_factory.hpp:77] Creating layer Accuracy1
I0930 20:11:10.729110  4070 net.cpp:84] Creating Layer Accuracy1
I0930 20:11:10.729113  4070 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0930 20:11:10.729120  4070 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I0930 20:11:10.729125  4070 net.cpp:380] Accuracy1 -> Accuracy1
I0930 20:11:10.729133  4070 net.cpp:122] Setting up Accuracy1
I0930 20:11:10.729140  4070 net.cpp:129] Top shape: (1)
I0930 20:11:10.729143  4070 net.cpp:137] Memory required for data: 430528408
I0930 20:11:10.729147  4070 net.cpp:200] Accuracy1 does not need backward computation.
I0930 20:11:10.729151  4070 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0930 20:11:10.729163  4070 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0930 20:11:10.729167  4070 net.cpp:198] InnerProduct1 needs backward computation.
I0930 20:11:10.729171  4070 net.cpp:198] Pooling1 needs backward computation.
I0930 20:11:10.729176  4070 net.cpp:198] penlu19 needs backward computation.
I0930 20:11:10.729179  4070 net.cpp:198] Eltwise9 needs backward computation.
I0930 20:11:10.729184  4070 net.cpp:198] Scale21 needs backward computation.
I0930 20:11:10.729187  4070 net.cpp:198] BatchNorm21 needs backward computation.
I0930 20:11:10.729192  4070 net.cpp:198] Convolution21 needs backward computation.
I0930 20:11:10.729195  4070 net.cpp:198] penlu18 needs backward computation.
I0930 20:11:10.729199  4070 net.cpp:198] Scale20 needs backward computation.
I0930 20:11:10.729203  4070 net.cpp:198] BatchNorm20 needs backward computation.
I0930 20:11:10.729207  4070 net.cpp:198] Convolution20 needs backward computation.
I0930 20:11:10.729210  4070 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I0930 20:11:10.729215  4070 net.cpp:198] penlu17 needs backward computation.
I0930 20:11:10.729219  4070 net.cpp:198] Eltwise8 needs backward computation.
I0930 20:11:10.729225  4070 net.cpp:198] Scale19 needs backward computation.
I0930 20:11:10.729229  4070 net.cpp:198] BatchNorm19 needs backward computation.
I0930 20:11:10.729233  4070 net.cpp:198] Convolution19 needs backward computation.
I0930 20:11:10.729238  4070 net.cpp:198] penlu16 needs backward computation.
I0930 20:11:10.729241  4070 net.cpp:198] Scale18 needs backward computation.
I0930 20:11:10.729245  4070 net.cpp:198] BatchNorm18 needs backward computation.
I0930 20:11:10.729249  4070 net.cpp:198] Convolution18 needs backward computation.
I0930 20:11:10.729254  4070 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I0930 20:11:10.729257  4070 net.cpp:198] penlu15 needs backward computation.
I0930 20:11:10.729261  4070 net.cpp:198] Eltwise7 needs backward computation.
I0930 20:11:10.729265  4070 net.cpp:198] Scale17 needs backward computation.
I0930 20:11:10.729269  4070 net.cpp:198] BatchNorm17 needs backward computation.
I0930 20:11:10.729274  4070 net.cpp:198] Convolution17 needs backward computation.
I0930 20:11:10.729277  4070 net.cpp:198] penlu14 needs backward computation.
I0930 20:11:10.729281  4070 net.cpp:198] Scale16 needs backward computation.
I0930 20:11:10.729285  4070 net.cpp:198] BatchNorm16 needs backward computation.
I0930 20:11:10.729290  4070 net.cpp:198] Convolution16 needs backward computation.
I0930 20:11:10.729293  4070 net.cpp:198] Scale15 needs backward computation.
I0930 20:11:10.729297  4070 net.cpp:198] BatchNorm15 needs backward computation.
I0930 20:11:10.729301  4070 net.cpp:198] Convolution15 needs backward computation.
I0930 20:11:10.729305  4070 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I0930 20:11:10.729310  4070 net.cpp:198] penlu13 needs backward computation.
I0930 20:11:10.729315  4070 net.cpp:198] Eltwise6 needs backward computation.
I0930 20:11:10.729318  4070 net.cpp:198] Scale14 needs backward computation.
I0930 20:11:10.729322  4070 net.cpp:198] BatchNorm14 needs backward computation.
I0930 20:11:10.729326  4070 net.cpp:198] Convolution14 needs backward computation.
I0930 20:11:10.729331  4070 net.cpp:198] penlu12 needs backward computation.
I0930 20:11:10.729334  4070 net.cpp:198] Scale13 needs backward computation.
I0930 20:11:10.729338  4070 net.cpp:198] BatchNorm13 needs backward computation.
I0930 20:11:10.730484  4070 net.cpp:198] Convolution13 needs backward computation.
I0930 20:11:10.730492  4070 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I0930 20:11:10.730495  4070 net.cpp:198] penlu11 needs backward computation.
I0930 20:11:10.730499  4070 net.cpp:198] Eltwise5 needs backward computation.
I0930 20:11:10.730501  4070 net.cpp:198] Scale12 needs backward computation.
I0930 20:11:10.730504  4070 net.cpp:198] BatchNorm12 needs backward computation.
I0930 20:11:10.730512  4070 net.cpp:198] Convolution12 needs backward computation.
I0930 20:11:10.730515  4070 net.cpp:198] penlu10 needs backward computation.
I0930 20:11:10.730517  4070 net.cpp:198] Scale11 needs backward computation.
I0930 20:11:10.730530  4070 net.cpp:198] BatchNorm11 needs backward computation.
I0930 20:11:10.730535  4070 net.cpp:198] Convolution11 needs backward computation.
I0930 20:11:10.730537  4070 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I0930 20:11:10.730540  4070 net.cpp:198] penlu9 needs backward computation.
I0930 20:11:10.730542  4070 net.cpp:198] Eltwise4 needs backward computation.
I0930 20:11:10.730545  4070 net.cpp:198] Scale10 needs backward computation.
I0930 20:11:10.730547  4070 net.cpp:198] BatchNorm10 needs backward computation.
I0930 20:11:10.730551  4070 net.cpp:198] Convolution10 needs backward computation.
I0930 20:11:10.730552  4070 net.cpp:198] penlu8 needs backward computation.
I0930 20:11:10.730556  4070 net.cpp:198] Scale9 needs backward computation.
I0930 20:11:10.730557  4070 net.cpp:198] BatchNorm9 needs backward computation.
I0930 20:11:10.730559  4070 net.cpp:198] Convolution9 needs backward computation.
I0930 20:11:10.730562  4070 net.cpp:198] Scale8 needs backward computation.
I0930 20:11:10.730564  4070 net.cpp:198] BatchNorm8 needs backward computation.
I0930 20:11:10.730567  4070 net.cpp:198] Convolution8 needs backward computation.
I0930 20:11:10.730569  4070 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I0930 20:11:10.730572  4070 net.cpp:198] penlu7 needs backward computation.
I0930 20:11:10.730574  4070 net.cpp:198] Eltwise3 needs backward computation.
I0930 20:11:10.730577  4070 net.cpp:198] Scale7 needs backward computation.
I0930 20:11:10.730579  4070 net.cpp:198] BatchNorm7 needs backward computation.
I0930 20:11:10.730581  4070 net.cpp:198] Convolution7 needs backward computation.
I0930 20:11:10.730584  4070 net.cpp:198] penlu6 needs backward computation.
I0930 20:11:10.730587  4070 net.cpp:198] Scale6 needs backward computation.
I0930 20:11:10.730588  4070 net.cpp:198] BatchNorm6 needs backward computation.
I0930 20:11:10.730592  4070 net.cpp:198] Convolution6 needs backward computation.
I0930 20:11:10.730593  4070 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I0930 20:11:10.730597  4070 net.cpp:198] penlu5 needs backward computation.
I0930 20:11:10.730598  4070 net.cpp:198] Eltwise2 needs backward computation.
I0930 20:11:10.730602  4070 net.cpp:198] Scale5 needs backward computation.
I0930 20:11:10.730603  4070 net.cpp:198] BatchNorm5 needs backward computation.
I0930 20:11:10.730605  4070 net.cpp:198] Convolution5 needs backward computation.
I0930 20:11:10.730608  4070 net.cpp:198] penlu4 needs backward computation.
I0930 20:11:10.730610  4070 net.cpp:198] Scale4 needs backward computation.
I0930 20:11:10.730612  4070 net.cpp:198] BatchNorm4 needs backward computation.
I0930 20:11:10.730615  4070 net.cpp:198] Convolution4 needs backward computation.
I0930 20:11:10.730618  4070 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I0930 20:11:10.730620  4070 net.cpp:198] penlu3 needs backward computation.
I0930 20:11:10.730623  4070 net.cpp:198] Eltwise1 needs backward computation.
I0930 20:11:10.730625  4070 net.cpp:198] Scale3 needs backward computation.
I0930 20:11:10.730628  4070 net.cpp:198] BatchNorm3 needs backward computation.
I0930 20:11:10.730630  4070 net.cpp:198] Convolution3 needs backward computation.
I0930 20:11:10.730633  4070 net.cpp:198] penlu2 needs backward computation.
I0930 20:11:10.730635  4070 net.cpp:198] Scale2 needs backward computation.
I0930 20:11:10.730638  4070 net.cpp:198] BatchNorm2 needs backward computation.
I0930 20:11:10.730640  4070 net.cpp:198] Convolution2 needs backward computation.
I0930 20:11:10.730643  4070 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I0930 20:11:10.730645  4070 net.cpp:198] penlu1 needs backward computation.
I0930 20:11:10.730648  4070 net.cpp:198] Scale1 needs backward computation.
I0930 20:11:10.730654  4070 net.cpp:198] BatchNorm1 needs backward computation.
I0930 20:11:10.730656  4070 net.cpp:198] Convolution1 needs backward computation.
I0930 20:11:10.730659  4070 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I0930 20:11:10.730662  4070 net.cpp:200] Data1 does not need backward computation.
I0930 20:11:10.730664  4070 net.cpp:242] This network produces output Accuracy1
I0930 20:11:10.730667  4070 net.cpp:242] This network produces output SoftmaxWithLoss1
I0930 20:11:10.730703  4070 net.cpp:255] Network initialization done.
I0930 20:11:10.730960  4070 solver.cpp:56] Solver scaffolding done.
I0930 20:11:10.736398  4070 caffe.cpp:248] Starting Optimization
I0930 20:11:10.736404  4070 solver.cpp:272] Solving resnet_cifar10
I0930 20:11:10.736407  4070 solver.cpp:273] Learning Rate Policy: multistep
I0930 20:11:10.738364  4070 solver.cpp:330] Iteration 0, Testing net (#0)
I0930 20:11:11.963186  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:11:12.012656  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I0930 20:11:12.012681  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0930 20:11:12.085888  4070 solver.cpp:218] Iteration 0 (0 iter/s, 1.34941s/100 iters), loss = 2.30386
I0930 20:11:12.085913  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30386 (* 1 = 2.30386 loss)
I0930 20:11:12.085927  4070 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0930 20:11:17.321177  4070 solver.cpp:218] Iteration 100 (19.1014 iter/s, 5.23522s/100 iters), loss = 1.56582
I0930 20:11:17.321209  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.56582 (* 1 = 1.56582 loss)
I0930 20:11:17.321216  4070 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0930 20:11:22.547202  4070 solver.cpp:218] Iteration 200 (19.1353 iter/s, 5.22594s/100 iters), loss = 1.80856
I0930 20:11:22.547255  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.80856 (* 1 = 1.80856 loss)
I0930 20:11:22.547273  4070 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0930 20:11:27.776994  4070 solver.cpp:218] Iteration 300 (19.1217 iter/s, 5.22966s/100 iters), loss = 1.31868
I0930 20:11:27.777035  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31868 (* 1 = 1.31868 loss)
I0930 20:11:27.777041  4070 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0930 20:11:33.003767  4070 solver.cpp:218] Iteration 400 (19.1326 iter/s, 5.22668s/100 iters), loss = 1.07388
I0930 20:11:33.003806  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.07388 (* 1 = 1.07388 loss)
I0930 20:11:33.003813  4070 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0930 20:11:37.969496  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:11:38.178148  4070 solver.cpp:330] Iteration 500, Testing net (#0)
I0930 20:11:39.359720  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:11:39.409277  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4106
I0930 20:11:39.409312  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.05705 (* 1 = 2.05705 loss)
I0930 20:11:39.461331  4070 solver.cpp:218] Iteration 500 (15.4859 iter/s, 6.45747s/100 iters), loss = 1.2765
I0930 20:11:39.461355  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.2765 (* 1 = 1.2765 loss)
I0930 20:11:39.461362  4070 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0930 20:11:44.687345  4070 solver.cpp:218] Iteration 600 (19.1353 iter/s, 5.22594s/100 iters), loss = 1.05075
I0930 20:11:44.687414  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05075 (* 1 = 1.05075 loss)
I0930 20:11:44.687422  4070 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0930 20:11:49.916816  4070 solver.cpp:218] Iteration 700 (19.1228 iter/s, 5.22935s/100 iters), loss = 1.15385
I0930 20:11:49.916857  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15385 (* 1 = 1.15385 loss)
I0930 20:11:49.916864  4070 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0930 20:11:55.131908  4070 solver.cpp:218] Iteration 800 (19.1754 iter/s, 5.215s/100 iters), loss = 1.13189
I0930 20:11:55.131938  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13189 (* 1 = 1.13189 loss)
I0930 20:11:55.131944  4070 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0930 20:12:00.365213  4070 solver.cpp:218] Iteration 900 (19.1087 iter/s, 5.23323s/100 iters), loss = 0.879448
I0930 20:12:00.365247  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.879448 (* 1 = 0.879448 loss)
I0930 20:12:00.365254  4070 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0930 20:12:05.343346  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:12:05.552877  4070 solver.cpp:330] Iteration 1000, Testing net (#0)
I0930 20:12:06.734571  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:12:06.784572  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4657
I0930 20:12:06.784607  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.00495 (* 1 = 2.00495 loss)
I0930 20:12:06.836779  4070 solver.cpp:218] Iteration 1000 (15.4524 iter/s, 6.47148s/100 iters), loss = 1.03891
I0930 20:12:06.836803  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03891 (* 1 = 1.03891 loss)
I0930 20:12:06.836810  4070 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0930 20:12:12.075809  4070 solver.cpp:218] Iteration 1100 (19.0878 iter/s, 5.23896s/100 iters), loss = 0.940358
I0930 20:12:12.075850  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.940358 (* 1 = 0.940358 loss)
I0930 20:12:12.075855  4070 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0930 20:12:17.314496  4070 solver.cpp:218] Iteration 1200 (19.0891 iter/s, 5.2386s/100 iters), loss = 0.98336
I0930 20:12:17.314659  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.98336 (* 1 = 0.98336 loss)
I0930 20:12:17.314668  4070 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0930 20:12:22.539837  4070 solver.cpp:218] Iteration 1300 (19.1383 iter/s, 5.22514s/100 iters), loss = 0.899362
I0930 20:12:22.539872  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.899362 (* 1 = 0.899362 loss)
I0930 20:12:22.539880  4070 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0930 20:12:27.770928  4070 solver.cpp:218] Iteration 1400 (19.1168 iter/s, 5.23101s/100 iters), loss = 0.76001
I0930 20:12:27.770970  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.76001 (* 1 = 0.76001 loss)
I0930 20:12:27.770977  4070 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0930 20:12:32.744627  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:12:32.953619  4070 solver.cpp:330] Iteration 1500, Testing net (#0)
I0930 20:12:34.136507  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:12:34.186594  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4496
I0930 20:12:34.186627  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.28899 (* 1 = 2.28899 loss)
I0930 20:12:34.239258  4070 solver.cpp:218] Iteration 1500 (15.4602 iter/s, 6.46824s/100 iters), loss = 0.89302
I0930 20:12:34.239281  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.89302 (* 1 = 0.89302 loss)
I0930 20:12:34.239289  4070 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0930 20:12:39.475594  4070 solver.cpp:218] Iteration 1600 (19.0976 iter/s, 5.23627s/100 iters), loss = 0.747045
I0930 20:12:39.475623  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.747045 (* 1 = 0.747045 loss)
I0930 20:12:39.475630  4070 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0930 20:12:44.711724  4070 solver.cpp:218] Iteration 1700 (19.0983 iter/s, 5.23606s/100 iters), loss = 0.940686
I0930 20:12:44.711753  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.940686 (* 1 = 0.940686 loss)
I0930 20:12:44.711760  4070 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0930 20:12:49.952569  4070 solver.cpp:218] Iteration 1800 (19.0812 iter/s, 5.24077s/100 iters), loss = 0.780317
I0930 20:12:49.952695  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.780317 (* 1 = 0.780317 loss)
I0930 20:12:49.952703  4070 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0930 20:12:55.183140  4070 solver.cpp:218] Iteration 1900 (19.119 iter/s, 5.23041s/100 iters), loss = 0.657132
I0930 20:12:55.183179  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.657132 (* 1 = 0.657132 loss)
I0930 20:12:55.183185  4070 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0930 20:13:00.159150  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:13:00.369067  4070 solver.cpp:330] Iteration 2000, Testing net (#0)
I0930 20:13:01.552304  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:13:01.602417  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5102
I0930 20:13:01.602444  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.02347 (* 1 = 2.02347 loss)
I0930 20:13:01.657099  4070 solver.cpp:218] Iteration 2000 (15.4467 iter/s, 6.47387s/100 iters), loss = 0.85689
I0930 20:13:01.657146  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.85689 (* 1 = 0.85689 loss)
I0930 20:13:01.657155  4070 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0930 20:13:06.891253  4070 solver.cpp:218] Iteration 2100 (19.1057 iter/s, 5.23404s/100 iters), loss = 0.60613
I0930 20:13:06.891283  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.60613 (* 1 = 0.60613 loss)
I0930 20:13:06.891290  4070 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0930 20:13:12.124166  4070 solver.cpp:218] Iteration 2200 (19.1101 iter/s, 5.23284s/100 iters), loss = 0.823935
I0930 20:13:12.124197  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.823935 (* 1 = 0.823935 loss)
I0930 20:13:12.124202  4070 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0930 20:13:17.355119  4070 solver.cpp:218] Iteration 2300 (19.1172 iter/s, 5.23088s/100 iters), loss = 0.670758
I0930 20:13:17.355161  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.670758 (* 1 = 0.670758 loss)
I0930 20:13:17.355168  4070 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0930 20:13:22.585278  4070 solver.cpp:218] Iteration 2400 (19.1202 iter/s, 5.23008s/100 iters), loss = 0.653295
I0930 20:13:22.585403  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.653295 (* 1 = 0.653295 loss)
I0930 20:13:22.585412  4070 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0930 20:13:27.558068  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:13:27.767514  4070 solver.cpp:330] Iteration 2500, Testing net (#0)
I0930 20:13:28.959018  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:13:29.008672  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5686
I0930 20:13:29.008697  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.57098 (* 1 = 1.57098 loss)
I0930 20:13:29.060942  4070 solver.cpp:218] Iteration 2500 (15.4428 iter/s, 6.4755s/100 iters), loss = 0.804083
I0930 20:13:29.060972  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.804083 (* 1 = 0.804083 loss)
I0930 20:13:29.060979  4070 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0930 20:13:34.293370  4070 solver.cpp:218] Iteration 2600 (19.1118 iter/s, 5.23236s/100 iters), loss = 0.613161
I0930 20:13:34.293409  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.613161 (* 1 = 0.613161 loss)
I0930 20:13:34.293416  4070 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0930 20:13:39.527089  4070 solver.cpp:218] Iteration 2700 (19.1071 iter/s, 5.23365s/100 iters), loss = 0.666711
I0930 20:13:39.527118  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.666711 (* 1 = 0.666711 loss)
I0930 20:13:39.527124  4070 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0930 20:13:44.766474  4070 solver.cpp:218] Iteration 2800 (19.0865 iter/s, 5.23932s/100 iters), loss = 0.713636
I0930 20:13:44.766515  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.713636 (* 1 = 0.713636 loss)
I0930 20:13:44.766522  4070 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0930 20:13:50.003993  4070 solver.cpp:218] Iteration 2900 (19.0933 iter/s, 5.23745s/100 iters), loss = 0.633257
I0930 20:13:50.004022  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.633257 (* 1 = 0.633257 loss)
I0930 20:13:50.004029  4070 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0930 20:13:54.971427  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:13:55.180483  4070 solver.cpp:330] Iteration 3000, Testing net (#0)
I0930 20:13:56.368701  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:13:56.418416  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6321
I0930 20:13:56.418452  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14449 (* 1 = 1.14449 loss)
I0930 20:13:56.470695  4070 solver.cpp:218] Iteration 3000 (15.464 iter/s, 6.46664s/100 iters), loss = 0.764379
I0930 20:13:56.470721  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.764379 (* 1 = 0.764379 loss)
I0930 20:13:56.470727  4070 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0930 20:14:01.704629  4070 solver.cpp:218] Iteration 3100 (19.1063 iter/s, 5.23388s/100 iters), loss = 0.52667
I0930 20:14:01.704672  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52667 (* 1 = 0.52667 loss)
I0930 20:14:01.704679  4070 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0930 20:14:06.934828  4070 solver.cpp:218] Iteration 3200 (19.12 iter/s, 5.23012s/100 iters), loss = 0.609199
I0930 20:14:06.934870  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.609199 (* 1 = 0.609199 loss)
I0930 20:14:06.934875  4070 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0930 20:14:12.168637  4070 solver.cpp:218] Iteration 3300 (19.1068 iter/s, 5.23374s/100 iters), loss = 0.699626
I0930 20:14:12.168666  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.699626 (* 1 = 0.699626 loss)
I0930 20:14:12.168671  4070 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0930 20:14:17.409690  4070 solver.cpp:218] Iteration 3400 (19.0803 iter/s, 5.241s/100 iters), loss = 0.582541
I0930 20:14:17.409721  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.582541 (* 1 = 0.582541 loss)
I0930 20:14:17.409728  4070 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0930 20:14:22.377925  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:14:22.591493  4070 solver.cpp:330] Iteration 3500, Testing net (#0)
I0930 20:14:23.779050  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:14:23.828800  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5487
I0930 20:14:23.828835  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.60101 (* 1 = 1.60101 loss)
I0930 20:14:23.880650  4070 solver.cpp:218] Iteration 3500 (15.4538 iter/s, 6.4709s/100 iters), loss = 0.673684
I0930 20:14:23.880676  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.673684 (* 1 = 0.673684 loss)
I0930 20:14:23.880682  4070 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0930 20:14:29.116539  4070 solver.cpp:218] Iteration 3600 (19.0992 iter/s, 5.23583s/100 iters), loss = 0.501002
I0930 20:14:29.116645  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501002 (* 1 = 0.501002 loss)
I0930 20:14:29.116657  4070 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0930 20:14:34.344420  4070 solver.cpp:218] Iteration 3700 (19.1287 iter/s, 5.22775s/100 iters), loss = 0.642962
I0930 20:14:34.344460  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.642962 (* 1 = 0.642962 loss)
I0930 20:14:34.344465  4070 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0930 20:14:39.583113  4070 solver.cpp:218] Iteration 3800 (19.089 iter/s, 5.23863s/100 iters), loss = 0.599351
I0930 20:14:39.583143  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.599351 (* 1 = 0.599351 loss)
I0930 20:14:39.583150  4070 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0930 20:14:44.819386  4070 solver.cpp:218] Iteration 3900 (19.0978 iter/s, 5.23622s/100 iters), loss = 0.587455
I0930 20:14:44.819425  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.587455 (* 1 = 0.587455 loss)
I0930 20:14:44.819432  4070 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0930 20:14:49.791122  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:14:50.000201  4070 solver.cpp:330] Iteration 4000, Testing net (#0)
I0930 20:14:51.182706  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:14:51.232741  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.621
I0930 20:14:51.232776  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13725 (* 1 = 1.13725 loss)
I0930 20:14:51.285313  4070 solver.cpp:218] Iteration 4000 (15.4658 iter/s, 6.46586s/100 iters), loss = 0.631245
I0930 20:14:51.285339  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.631245 (* 1 = 0.631245 loss)
I0930 20:14:51.285346  4070 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0930 20:14:56.519799  4070 solver.cpp:218] Iteration 4100 (19.1043 iter/s, 5.23443s/100 iters), loss = 0.443985
I0930 20:14:56.519841  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443985 (* 1 = 0.443985 loss)
I0930 20:14:56.519848  4070 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0930 20:15:01.751999  4070 solver.cpp:218] Iteration 4200 (19.1127 iter/s, 5.23213s/100 iters), loss = 0.557657
I0930 20:15:01.752130  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.557657 (* 1 = 0.557657 loss)
I0930 20:15:01.752153  4070 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0930 20:15:06.982275  4070 solver.cpp:218] Iteration 4300 (19.12 iter/s, 5.23012s/100 iters), loss = 0.612864
I0930 20:15:06.982311  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.612864 (* 1 = 0.612864 loss)
I0930 20:15:06.982318  4070 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0930 20:15:12.224432  4070 solver.cpp:218] Iteration 4400 (19.0763 iter/s, 5.2421s/100 iters), loss = 0.555366
I0930 20:15:12.224463  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555366 (* 1 = 0.555366 loss)
I0930 20:15:12.224472  4070 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0930 20:15:17.200567  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:15:17.410792  4070 solver.cpp:330] Iteration 4500, Testing net (#0)
I0930 20:15:18.595266  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:15:18.644441  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6529
I0930 20:15:18.644466  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06182 (* 1 = 1.06182 loss)
I0930 20:15:18.697408  4070 solver.cpp:218] Iteration 4500 (15.449 iter/s, 6.47292s/100 iters), loss = 0.510252
I0930 20:15:18.697433  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510252 (* 1 = 0.510252 loss)
I0930 20:15:18.697440  4070 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0930 20:15:23.935290  4070 solver.cpp:218] Iteration 4600 (19.0919 iter/s, 5.23783s/100 iters), loss = 0.454454
I0930 20:15:23.935319  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454454 (* 1 = 0.454454 loss)
I0930 20:15:23.935326  4070 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0930 20:15:29.175277  4070 solver.cpp:218] Iteration 4700 (19.0842 iter/s, 5.23992s/100 iters), loss = 0.578809
I0930 20:15:29.175307  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.578809 (* 1 = 0.578809 loss)
I0930 20:15:29.175315  4070 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0930 20:15:34.407485  4070 solver.cpp:218] Iteration 4800 (19.1126 iter/s, 5.23215s/100 iters), loss = 0.58555
I0930 20:15:34.407624  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.58555 (* 1 = 0.58555 loss)
I0930 20:15:34.407646  4070 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0930 20:15:39.645529  4070 solver.cpp:218] Iteration 4900 (19.0917 iter/s, 5.23788s/100 iters), loss = 0.554535
I0930 20:15:39.645563  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.554535 (* 1 = 0.554535 loss)
I0930 20:15:39.645582  4070 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0930 20:15:44.628525  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:15:44.837910  4070 solver.cpp:330] Iteration 5000, Testing net (#0)
I0930 20:15:46.020423  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:15:46.070086  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5636
I0930 20:15:46.070121  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.49931 (* 1 = 1.49931 loss)
I0930 20:15:46.122490  4070 solver.cpp:218] Iteration 5000 (15.4395 iter/s, 6.47691s/100 iters), loss = 0.565686
I0930 20:15:46.122514  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565686 (* 1 = 0.565686 loss)
I0930 20:15:46.122524  4070 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0930 20:15:51.364991  4070 solver.cpp:218] Iteration 5100 (19.075 iter/s, 5.24245s/100 iters), loss = 0.473887
I0930 20:15:51.365021  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.473887 (* 1 = 0.473887 loss)
I0930 20:15:51.365030  4070 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0930 20:15:56.609833  4070 solver.cpp:218] Iteration 5200 (19.0666 iter/s, 5.24478s/100 iters), loss = 0.519738
I0930 20:15:56.609863  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519738 (* 1 = 0.519738 loss)
I0930 20:15:56.609872  4070 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0930 20:16:01.846247  4070 solver.cpp:218] Iteration 5300 (19.0972 iter/s, 5.23636s/100 iters), loss = 0.482172
I0930 20:16:01.846290  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.482172 (* 1 = 0.482172 loss)
I0930 20:16:01.846297  4070 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0930 20:16:07.082341  4070 solver.cpp:218] Iteration 5400 (19.0985 iter/s, 5.23603s/100 iters), loss = 0.460357
I0930 20:16:07.082484  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460357 (* 1 = 0.460357 loss)
I0930 20:16:07.082494  4070 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0930 20:16:12.063635  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:16:12.272861  4070 solver.cpp:330] Iteration 5500, Testing net (#0)
I0930 20:16:13.455313  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:16:13.505188  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6328
I0930 20:16:13.505223  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.19591 (* 1 = 1.19591 loss)
I0930 20:16:13.558656  4070 solver.cpp:218] Iteration 5500 (15.4413 iter/s, 6.47616s/100 iters), loss = 0.430854
I0930 20:16:13.558694  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430854 (* 1 = 0.430854 loss)
I0930 20:16:13.558712  4070 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0930 20:16:18.796592  4070 solver.cpp:218] Iteration 5600 (19.0919 iter/s, 5.23783s/100 iters), loss = 0.386813
I0930 20:16:18.796622  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386813 (* 1 = 0.386813 loss)
I0930 20:16:18.796638  4070 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0930 20:16:24.030414  4070 solver.cpp:218] Iteration 5700 (19.1067 iter/s, 5.23377s/100 iters), loss = 0.565956
I0930 20:16:24.030443  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565956 (* 1 = 0.565956 loss)
I0930 20:16:24.030449  4070 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0930 20:16:29.263170  4070 solver.cpp:218] Iteration 5800 (19.1106 iter/s, 5.2327s/100 iters), loss = 0.501141
I0930 20:16:29.263211  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501141 (* 1 = 0.501141 loss)
I0930 20:16:29.263216  4070 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0930 20:16:34.492985  4070 solver.cpp:218] Iteration 5900 (19.1214 iter/s, 5.22975s/100 iters), loss = 0.442654
I0930 20:16:34.493026  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442654 (* 1 = 0.442654 loss)
I0930 20:16:34.493032  4070 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0930 20:16:39.465641  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:16:39.674351  4070 solver.cpp:330] Iteration 6000, Testing net (#0)
I0930 20:16:40.863956  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:16:40.913697  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6973
I0930 20:16:40.913724  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.86651 (* 1 = 0.86651 loss)
I0930 20:16:40.966311  4070 solver.cpp:218] Iteration 6000 (15.4482 iter/s, 6.47325s/100 iters), loss = 0.487666
I0930 20:16:40.966346  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.487666 (* 1 = 0.487666 loss)
I0930 20:16:40.966356  4070 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0930 20:16:46.186224  4070 solver.cpp:218] Iteration 6100 (19.1576 iter/s, 5.21986s/100 iters), loss = 0.371244
I0930 20:16:46.186256  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371244 (* 1 = 0.371244 loss)
I0930 20:16:46.186275  4070 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0930 20:16:51.425822  4070 solver.cpp:218] Iteration 6200 (19.0856 iter/s, 5.23954s/100 iters), loss = 0.543502
I0930 20:16:51.425853  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.543502 (* 1 = 0.543502 loss)
I0930 20:16:51.425871  4070 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0930 20:16:56.665509  4070 solver.cpp:218] Iteration 6300 (19.0853 iter/s, 5.23963s/100 iters), loss = 0.581112
I0930 20:16:56.665540  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.581112 (* 1 = 0.581112 loss)
I0930 20:16:56.665545  4070 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0930 20:17:01.905350  4070 solver.cpp:218] Iteration 6400 (19.0848 iter/s, 5.23979s/100 iters), loss = 0.498547
I0930 20:17:01.905380  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498547 (* 1 = 0.498547 loss)
I0930 20:17:01.905386  4070 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0930 20:17:06.870517  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:17:07.079807  4070 solver.cpp:330] Iteration 6500, Testing net (#0)
I0930 20:17:08.268322  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:17:08.317914  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7517
I0930 20:17:08.317948  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.70764 (* 1 = 0.70764 loss)
I0930 20:17:08.370252  4070 solver.cpp:218] Iteration 6500 (15.4683 iter/s, 6.46485s/100 iters), loss = 0.405862
I0930 20:17:08.370277  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405862 (* 1 = 0.405862 loss)
I0930 20:17:08.370285  4070 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0930 20:17:13.594291  4070 solver.cpp:218] Iteration 6600 (19.1425 iter/s, 5.22399s/100 iters), loss = 0.414422
I0930 20:17:13.594403  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414422 (* 1 = 0.414422 loss)
I0930 20:17:13.594413  4070 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0930 20:17:18.824683  4070 solver.cpp:218] Iteration 6700 (19.1196 iter/s, 5.23024s/100 iters), loss = 0.464438
I0930 20:17:18.824715  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464438 (* 1 = 0.464438 loss)
I0930 20:17:18.824724  4070 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0930 20:17:24.059936  4070 solver.cpp:218] Iteration 6800 (19.1015 iter/s, 5.23519s/100 iters), loss = 0.531065
I0930 20:17:24.059967  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.531065 (* 1 = 0.531065 loss)
I0930 20:17:24.059985  4070 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0930 20:17:29.298771  4070 solver.cpp:218] Iteration 6900 (19.0884 iter/s, 5.23878s/100 iters), loss = 0.509765
I0930 20:17:29.298812  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509765 (* 1 = 0.509765 loss)
I0930 20:17:29.298818  4070 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0930 20:17:34.267913  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:17:34.477308  4070 solver.cpp:330] Iteration 7000, Testing net (#0)
I0930 20:17:35.670119  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:17:35.720043  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7321
I0930 20:17:35.720067  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.78917 (* 1 = 0.78917 loss)
I0930 20:17:35.772132  4070 solver.cpp:218] Iteration 7000 (15.4481 iter/s, 6.47329s/100 iters), loss = 0.441085
I0930 20:17:35.772157  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441085 (* 1 = 0.441085 loss)
I0930 20:17:35.772164  4070 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0930 20:17:41.014717  4070 solver.cpp:218] Iteration 7100 (19.0747 iter/s, 5.24253s/100 iters), loss = 0.426271
I0930 20:17:41.014750  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426271 (* 1 = 0.426271 loss)
I0930 20:17:41.014755  4070 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0930 20:17:46.243794  4070 solver.cpp:218] Iteration 7200 (19.1241 iter/s, 5.22902s/100 iters), loss = 0.468528
I0930 20:17:46.243902  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468528 (* 1 = 0.468528 loss)
I0930 20:17:46.243919  4070 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0930 20:17:51.485855  4070 solver.cpp:218] Iteration 7300 (19.077 iter/s, 5.24193s/100 iters), loss = 0.487438
I0930 20:17:51.485895  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.487438 (* 1 = 0.487438 loss)
I0930 20:17:51.485900  4070 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0930 20:17:56.719765  4070 solver.cpp:218] Iteration 7400 (19.1064 iter/s, 5.23385s/100 iters), loss = 0.443732
I0930 20:17:56.719795  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443732 (* 1 = 0.443732 loss)
I0930 20:17:56.719801  4070 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0930 20:18:01.692533  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:18:01.903700  4070 solver.cpp:330] Iteration 7500, Testing net (#0)
I0930 20:18:03.084302  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:18:03.134112  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.743
I0930 20:18:03.134146  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.729041 (* 1 = 0.729041 loss)
I0930 20:18:03.186390  4070 solver.cpp:218] Iteration 7500 (15.4641 iter/s, 6.46657s/100 iters), loss = 0.427442
I0930 20:18:03.186416  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427442 (* 1 = 0.427442 loss)
I0930 20:18:03.186424  4070 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0930 20:18:08.423195  4070 solver.cpp:218] Iteration 7600 (19.0958 iter/s, 5.23675s/100 iters), loss = 0.430407
I0930 20:18:08.423228  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430407 (* 1 = 0.430407 loss)
I0930 20:18:08.423233  4070 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0930 20:18:13.650933  4070 solver.cpp:218] Iteration 7700 (19.1289 iter/s, 5.22768s/100 iters), loss = 0.475661
I0930 20:18:13.650977  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.475661 (* 1 = 0.475661 loss)
I0930 20:18:13.650985  4070 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0930 20:18:18.883936  4070 solver.cpp:218] Iteration 7800 (19.1099 iter/s, 5.2329s/100 iters), loss = 0.564247
I0930 20:18:18.884034  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.564247 (* 1 = 0.564247 loss)
I0930 20:18:18.884052  4070 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0930 20:18:24.118299  4070 solver.cpp:218] Iteration 7900 (19.105 iter/s, 5.23424s/100 iters), loss = 0.408139
I0930 20:18:24.118330  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408139 (* 1 = 0.408139 loss)
I0930 20:18:24.118335  4070 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0930 20:18:29.098217  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:18:29.307611  4070 solver.cpp:330] Iteration 8000, Testing net (#0)
I0930 20:18:30.489924  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:18:30.539621  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7765
I0930 20:18:30.539656  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.650587 (* 1 = 0.650587 loss)
I0930 20:18:30.591684  4070 solver.cpp:218] Iteration 8000 (15.448 iter/s, 6.47333s/100 iters), loss = 0.47194
I0930 20:18:30.591709  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47194 (* 1 = 0.47194 loss)
I0930 20:18:30.591717  4070 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0930 20:18:35.842972  4070 solver.cpp:218] Iteration 8100 (19.0431 iter/s, 5.25124s/100 iters), loss = 0.373883
I0930 20:18:35.843005  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373883 (* 1 = 0.373883 loss)
I0930 20:18:35.843024  4070 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0930 20:18:41.087296  4070 solver.cpp:218] Iteration 8200 (19.0684 iter/s, 5.24427s/100 iters), loss = 0.409662
I0930 20:18:41.087332  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409662 (* 1 = 0.409662 loss)
I0930 20:18:41.087339  4070 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0930 20:18:46.321991  4070 solver.cpp:218] Iteration 8300 (19.1035 iter/s, 5.23464s/100 iters), loss = 0.464754
I0930 20:18:46.322031  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464754 (* 1 = 0.464754 loss)
I0930 20:18:46.322036  4070 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0930 20:18:51.567353  4070 solver.cpp:218] Iteration 8400 (19.0647 iter/s, 5.2453s/100 iters), loss = 0.472121
I0930 20:18:51.567513  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472121 (* 1 = 0.472121 loss)
I0930 20:18:51.567522  4070 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0930 20:18:56.547982  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:18:56.757990  4070 solver.cpp:330] Iteration 8500, Testing net (#0)
I0930 20:18:57.943207  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:18:57.993088  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.792
I0930 20:18:57.993114  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.605661 (* 1 = 0.605661 loss)
I0930 20:18:58.045191  4070 solver.cpp:218] Iteration 8500 (15.4377 iter/s, 6.47766s/100 iters), loss = 0.412293
I0930 20:18:58.045219  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412293 (* 1 = 0.412293 loss)
I0930 20:18:58.045229  4070 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0930 20:19:03.290485  4070 solver.cpp:218] Iteration 8600 (19.0649 iter/s, 5.24524s/100 iters), loss = 0.443579
I0930 20:19:03.290516  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443579 (* 1 = 0.443579 loss)
I0930 20:19:03.290534  4070 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0930 20:19:08.534441  4070 solver.cpp:218] Iteration 8700 (19.0698 iter/s, 5.2439s/100 iters), loss = 0.518966
I0930 20:19:08.534471  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518966 (* 1 = 0.518966 loss)
I0930 20:19:08.534477  4070 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0930 20:19:13.778455  4070 solver.cpp:218] Iteration 8800 (19.0696 iter/s, 5.24396s/100 iters), loss = 0.532793
I0930 20:19:13.778486  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.532793 (* 1 = 0.532793 loss)
I0930 20:19:13.778493  4070 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0930 20:19:19.017554  4070 solver.cpp:218] Iteration 8900 (19.0875 iter/s, 5.23904s/100 iters), loss = 0.444068
I0930 20:19:19.017594  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444068 (* 1 = 0.444068 loss)
I0930 20:19:19.017601  4070 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0930 20:19:24.002396  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:19:24.211755  4070 solver.cpp:330] Iteration 9000, Testing net (#0)
I0930 20:19:25.393970  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:19:25.443574  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7279
I0930 20:19:25.443617  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.804331 (* 1 = 0.804331 loss)
I0930 20:19:25.495645  4070 solver.cpp:218] Iteration 9000 (15.4368 iter/s, 6.47803s/100 iters), loss = 0.361788
I0930 20:19:25.495667  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361788 (* 1 = 0.361788 loss)
I0930 20:19:25.495674  4070 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0930 20:19:30.740775  4070 solver.cpp:218] Iteration 9100 (19.0655 iter/s, 5.24508s/100 iters), loss = 0.383236
I0930 20:19:30.740814  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383236 (* 1 = 0.383236 loss)
I0930 20:19:30.740820  4070 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0930 20:19:35.981353  4070 solver.cpp:218] Iteration 9200 (19.0821 iter/s, 5.24051s/100 iters), loss = 0.355253
I0930 20:19:35.981391  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355253 (* 1 = 0.355253 loss)
I0930 20:19:35.981397  4070 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0930 20:19:41.216979  4070 solver.cpp:218] Iteration 9300 (19.1002 iter/s, 5.23556s/100 iters), loss = 0.440773
I0930 20:19:41.217018  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440773 (* 1 = 0.440773 loss)
I0930 20:19:41.217025  4070 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0930 20:19:46.451498  4070 solver.cpp:218] Iteration 9400 (19.1042 iter/s, 5.23445s/100 iters), loss = 0.36816
I0930 20:19:46.451537  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36816 (* 1 = 0.36816 loss)
I0930 20:19:46.451544  4070 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0930 20:19:51.435664  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:19:51.645514  4070 solver.cpp:330] Iteration 9500, Testing net (#0)
I0930 20:19:52.836872  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:19:52.886929  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7974
I0930 20:19:52.886965  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.606216 (* 1 = 0.606216 loss)
I0930 20:19:52.939584  4070 solver.cpp:218] Iteration 9500 (15.413 iter/s, 6.48802s/100 iters), loss = 0.356109
I0930 20:19:52.939613  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356109 (* 1 = 0.356109 loss)
I0930 20:19:52.939620  4070 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0930 20:19:58.178594  4070 solver.cpp:218] Iteration 9600 (19.0878 iter/s, 5.23896s/100 iters), loss = 0.407664
I0930 20:19:58.178755  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407664 (* 1 = 0.407664 loss)
I0930 20:19:58.178776  4070 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0930 20:20:03.433478  4070 solver.cpp:218] Iteration 9700 (19.0305 iter/s, 5.25472s/100 iters), loss = 0.520211
I0930 20:20:03.433508  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520211 (* 1 = 0.520211 loss)
I0930 20:20:03.433524  4070 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0930 20:20:08.682024  4070 solver.cpp:218] Iteration 9800 (19.0531 iter/s, 5.24849s/100 iters), loss = 0.425706
I0930 20:20:08.682054  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425706 (* 1 = 0.425706 loss)
I0930 20:20:08.682071  4070 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0930 20:20:13.931627  4070 solver.cpp:218] Iteration 9900 (19.0493 iter/s, 5.24955s/100 iters), loss = 0.390788
I0930 20:20:13.931658  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390788 (* 1 = 0.390788 loss)
I0930 20:20:13.931674  4070 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0930 20:20:18.912780  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:20:19.123304  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_10000.caffemodel
I0930 20:20:19.131613  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_10000.solverstate
I0930 20:20:19.132972  4070 solver.cpp:330] Iteration 10000, Testing net (#0)
I0930 20:20:20.324666  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:20:20.374428  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7501
I0930 20:20:20.374452  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.736079 (* 1 = 0.736079 loss)
I0930 20:20:20.426862  4070 solver.cpp:218] Iteration 10000 (15.396 iter/s, 6.49518s/100 iters), loss = 0.429818
I0930 20:20:20.426887  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429818 (* 1 = 0.429818 loss)
I0930 20:20:20.426892  4070 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0930 20:20:25.670406  4070 solver.cpp:218] Iteration 10100 (19.0712 iter/s, 5.2435s/100 iters), loss = 0.281092
I0930 20:20:25.670442  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281092 (* 1 = 0.281092 loss)
I0930 20:20:25.670449  4070 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0930 20:20:30.911746  4070 solver.cpp:218] Iteration 10200 (19.0793 iter/s, 5.24128s/100 iters), loss = 0.367179
I0930 20:20:30.911878  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367179 (* 1 = 0.367179 loss)
I0930 20:20:30.911896  4070 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0930 20:20:36.153029  4070 solver.cpp:218] Iteration 10300 (19.0798 iter/s, 5.24114s/100 iters), loss = 0.550903
I0930 20:20:36.153059  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.550903 (* 1 = 0.550903 loss)
I0930 20:20:36.153064  4070 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0930 20:20:41.399128  4070 solver.cpp:218] Iteration 10400 (19.062 iter/s, 5.24605s/100 iters), loss = 0.402725
I0930 20:20:41.399161  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402725 (* 1 = 0.402725 loss)
I0930 20:20:41.399170  4070 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0930 20:20:46.371091  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:20:46.582108  4070 solver.cpp:330] Iteration 10500, Testing net (#0)
I0930 20:20:47.772301  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:20:47.822376  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7394
I0930 20:20:47.822410  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.851269 (* 1 = 0.851269 loss)
I0930 20:20:47.874915  4070 solver.cpp:218] Iteration 10500 (15.4423 iter/s, 6.47573s/100 iters), loss = 0.309287
I0930 20:20:47.874943  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309287 (* 1 = 0.309287 loss)
I0930 20:20:47.874950  4070 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0930 20:20:53.117422  4070 solver.cpp:218] Iteration 10600 (19.075 iter/s, 5.24246s/100 iters), loss = 0.400333
I0930 20:20:53.117452  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400333 (* 1 = 0.400333 loss)
I0930 20:20:53.117458  4070 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0930 20:20:58.348418  4070 solver.cpp:218] Iteration 10700 (19.117 iter/s, 5.23094s/100 iters), loss = 0.410305
I0930 20:20:58.348448  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410305 (* 1 = 0.410305 loss)
I0930 20:20:58.348464  4070 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0930 20:21:03.600584  4070 solver.cpp:218] Iteration 10800 (19.04 iter/s, 5.25211s/100 iters), loss = 0.347493
I0930 20:21:03.600675  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347493 (* 1 = 0.347493 loss)
I0930 20:21:03.600693  4070 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0930 20:21:08.845314  4070 solver.cpp:218] Iteration 10900 (19.0671 iter/s, 5.24463s/100 iters), loss = 0.346782
I0930 20:21:08.845353  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346782 (* 1 = 0.346782 loss)
I0930 20:21:08.845360  4070 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0930 20:21:13.825467  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:21:14.035306  4070 solver.cpp:330] Iteration 11000, Testing net (#0)
I0930 20:21:15.221673  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:21:15.271621  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7725
I0930 20:21:15.271656  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663 (* 1 = 0.663 loss)
I0930 20:21:15.324292  4070 solver.cpp:218] Iteration 11000 (15.4347 iter/s, 6.47892s/100 iters), loss = 0.40767
I0930 20:21:15.324317  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40767 (* 1 = 0.40767 loss)
I0930 20:21:15.324324  4070 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0930 20:21:20.570374  4070 solver.cpp:218] Iteration 11100 (19.062 iter/s, 5.24604s/100 iters), loss = 0.386247
I0930 20:21:20.570402  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386247 (* 1 = 0.386247 loss)
I0930 20:21:20.570408  4070 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0930 20:21:25.815942  4070 solver.cpp:218] Iteration 11200 (19.0639 iter/s, 5.2455s/100 iters), loss = 0.43659
I0930 20:21:25.816004  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43659 (* 1 = 0.43659 loss)
I0930 20:21:25.816011  4070 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0930 20:21:31.056529  4070 solver.cpp:218] Iteration 11300 (19.0824 iter/s, 5.24042s/100 iters), loss = 0.571222
I0930 20:21:31.056556  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.571222 (* 1 = 0.571222 loss)
I0930 20:21:31.056562  4070 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0930 20:21:36.300343  4070 solver.cpp:218] Iteration 11400 (19.0703 iter/s, 5.24376s/100 iters), loss = 0.356891
I0930 20:21:36.300472  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356891 (* 1 = 0.356891 loss)
I0930 20:21:36.300490  4070 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0930 20:21:41.288664  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:21:41.498697  4070 solver.cpp:330] Iteration 11500, Testing net (#0)
I0930 20:21:42.682682  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:21:42.732376  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7555
I0930 20:21:42.732411  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.77203 (* 1 = 0.77203 loss)
I0930 20:21:42.784677  4070 solver.cpp:218] Iteration 11500 (15.4221 iter/s, 6.48419s/100 iters), loss = 0.446988
I0930 20:21:42.784706  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446988 (* 1 = 0.446988 loss)
I0930 20:21:42.784713  4070 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0930 20:21:48.034404  4070 solver.cpp:218] Iteration 11600 (19.0488 iter/s, 5.24968s/100 iters), loss = 0.322315
I0930 20:21:48.034433  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322315 (* 1 = 0.322315 loss)
I0930 20:21:48.034440  4070 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0930 20:21:53.284023  4070 solver.cpp:218] Iteration 11700 (19.0492 iter/s, 5.24956s/100 iters), loss = 0.34502
I0930 20:21:53.284060  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34502 (* 1 = 0.34502 loss)
I0930 20:21:53.284067  4070 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0930 20:21:58.515895  4070 solver.cpp:218] Iteration 11800 (19.1138 iter/s, 5.23181s/100 iters), loss = 0.359642
I0930 20:21:58.515935  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359642 (* 1 = 0.359642 loss)
I0930 20:21:58.515940  4070 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0930 20:22:03.759207  4070 solver.cpp:218] Iteration 11900 (19.0721 iter/s, 5.24325s/100 iters), loss = 0.274242
I0930 20:22:03.759248  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274242 (* 1 = 0.274242 loss)
I0930 20:22:03.759253  4070 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0930 20:22:08.742575  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:22:08.952668  4070 solver.cpp:330] Iteration 12000, Testing net (#0)
I0930 20:22:10.138285  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:22:10.188426  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8081
I0930 20:22:10.188450  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.566513 (* 1 = 0.566513 loss)
I0930 20:22:10.240633  4070 solver.cpp:218] Iteration 12000 (15.4289 iter/s, 6.48136s/100 iters), loss = 0.349191
I0930 20:22:10.240669  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349191 (* 1 = 0.349191 loss)
I0930 20:22:10.240676  4070 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0930 20:22:15.482532  4070 solver.cpp:218] Iteration 12100 (19.0773 iter/s, 5.24184s/100 iters), loss = 0.357157
I0930 20:22:15.482571  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357158 (* 1 = 0.357158 loss)
I0930 20:22:15.482578  4070 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0930 20:22:20.730901  4070 solver.cpp:218] Iteration 12200 (19.0538 iter/s, 5.2483s/100 iters), loss = 0.438242
I0930 20:22:20.730933  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438242 (* 1 = 0.438242 loss)
I0930 20:22:20.730940  4070 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0930 20:22:25.979495  4070 solver.cpp:218] Iteration 12300 (19.0529 iter/s, 5.24854s/100 iters), loss = 0.41007
I0930 20:22:25.979524  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41007 (* 1 = 0.41007 loss)
I0930 20:22:25.979531  4070 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0930 20:22:31.214349  4070 solver.cpp:218] Iteration 12400 (19.1029 iter/s, 5.2348s/100 iters), loss = 0.340638
I0930 20:22:31.214377  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340639 (* 1 = 0.340639 loss)
I0930 20:22:31.214383  4070 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0930 20:22:36.200212  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:22:36.409806  4070 solver.cpp:330] Iteration 12500, Testing net (#0)
I0930 20:22:37.596086  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:22:37.647132  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7507
I0930 20:22:37.647159  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.745351 (* 1 = 0.745351 loss)
I0930 20:22:37.701553  4070 solver.cpp:218] Iteration 12500 (15.4151 iter/s, 6.48715s/100 iters), loss = 0.310252
I0930 20:22:37.701616  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310252 (* 1 = 0.310252 loss)
I0930 20:22:37.701639  4070 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0930 20:22:42.943305  4070 solver.cpp:218] Iteration 12600 (19.078 iter/s, 5.24165s/100 iters), loss = 0.294617
I0930 20:22:42.943464  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294617 (* 1 = 0.294617 loss)
I0930 20:22:42.943472  4070 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0930 20:22:48.189388  4070 solver.cpp:218] Iteration 12700 (19.0625 iter/s, 5.2459s/100 iters), loss = 0.370995
I0930 20:22:48.189429  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370995 (* 1 = 0.370995 loss)
I0930 20:22:48.189435  4070 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0930 20:22:53.434693  4070 solver.cpp:218] Iteration 12800 (19.0649 iter/s, 5.24524s/100 iters), loss = 0.478563
I0930 20:22:53.434733  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.478563 (* 1 = 0.478563 loss)
I0930 20:22:53.434739  4070 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0930 20:22:58.676048  4070 solver.cpp:218] Iteration 12900 (19.0793 iter/s, 5.24129s/100 iters), loss = 0.428773
I0930 20:22:58.676095  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428773 (* 1 = 0.428773 loss)
I0930 20:22:58.676100  4070 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0930 20:23:03.659620  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:23:03.867887  4070 solver.cpp:330] Iteration 13000, Testing net (#0)
I0930 20:23:05.066100  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:23:05.116461  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7607
I0930 20:23:05.116485  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.719981 (* 1 = 0.719981 loss)
I0930 20:23:05.168575  4070 solver.cpp:218] Iteration 13000 (15.4026 iter/s, 6.49242s/100 iters), loss = 0.42238
I0930 20:23:05.168606  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42238 (* 1 = 0.42238 loss)
I0930 20:23:05.168612  4070 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0930 20:23:10.408860  4070 solver.cpp:218] Iteration 13100 (19.0831 iter/s, 5.24023s/100 iters), loss = 0.315226
I0930 20:23:10.408900  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315226 (* 1 = 0.315226 loss)
I0930 20:23:10.408905  4070 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0930 20:23:15.656924  4070 solver.cpp:218] Iteration 13200 (19.0549 iter/s, 5.248s/100 iters), loss = 0.390718
I0930 20:23:15.657091  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390718 (* 1 = 0.390718 loss)
I0930 20:23:15.657099  4070 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0930 20:23:20.909415  4070 solver.cpp:218] Iteration 13300 (19.0393 iter/s, 5.2523s/100 iters), loss = 0.460341
I0930 20:23:20.909446  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460341 (* 1 = 0.460341 loss)
I0930 20:23:20.909462  4070 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0930 20:23:26.158341  4070 solver.cpp:218] Iteration 13400 (19.0517 iter/s, 5.24887s/100 iters), loss = 0.313238
I0930 20:23:26.158371  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313238 (* 1 = 0.313238 loss)
I0930 20:23:26.158376  4070 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0930 20:23:31.134505  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:23:31.344406  4070 solver.cpp:330] Iteration 13500, Testing net (#0)
I0930 20:23:32.535109  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:23:32.585007  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8039
I0930 20:23:32.585042  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.572586 (* 1 = 0.572586 loss)
I0930 20:23:32.637678  4070 solver.cpp:218] Iteration 13500 (15.4338 iter/s, 6.47928s/100 iters), loss = 0.33632
I0930 20:23:32.637706  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33632 (* 1 = 0.33632 loss)
I0930 20:23:32.637712  4070 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0930 20:23:37.877264  4070 solver.cpp:218] Iteration 13600 (19.0857 iter/s, 5.23953s/100 iters), loss = 0.399557
I0930 20:23:37.877295  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399557 (* 1 = 0.399557 loss)
I0930 20:23:37.877301  4070 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0930 20:23:43.110179  4070 solver.cpp:218] Iteration 13700 (19.11 iter/s, 5.23286s/100 iters), loss = 0.320263
I0930 20:23:43.110208  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320263 (* 1 = 0.320263 loss)
I0930 20:23:43.110224  4070 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0930 20:23:48.356097  4070 solver.cpp:218] Iteration 13800 (19.0626 iter/s, 5.24587s/100 iters), loss = 0.461388
I0930 20:23:48.356215  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461388 (* 1 = 0.461388 loss)
I0930 20:23:48.356221  4070 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0930 20:23:53.603341  4070 solver.cpp:218] Iteration 13900 (19.0581 iter/s, 5.24711s/100 iters), loss = 0.340764
I0930 20:23:53.603371  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340764 (* 1 = 0.340764 loss)
I0930 20:23:53.603386  4070 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0930 20:23:58.583923  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:23:58.799729  4070 solver.cpp:330] Iteration 14000, Testing net (#0)
I0930 20:23:59.985527  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:24:00.035133  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7649
I0930 20:24:00.035157  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706959 (* 1 = 0.706959 loss)
I0930 20:24:00.087501  4070 solver.cpp:218] Iteration 14000 (15.4223 iter/s, 6.48411s/100 iters), loss = 0.361755
I0930 20:24:00.087524  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361755 (* 1 = 0.361755 loss)
I0930 20:24:00.087532  4070 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0930 20:24:05.336872  4070 solver.cpp:218] Iteration 14100 (19.0501 iter/s, 5.24932s/100 iters), loss = 0.315073
I0930 20:24:05.336916  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315073 (* 1 = 0.315073 loss)
I0930 20:24:05.336923  4070 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0930 20:24:10.577620  4070 solver.cpp:218] Iteration 14200 (19.0815 iter/s, 5.24067s/100 iters), loss = 0.35234
I0930 20:24:10.577657  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35234 (* 1 = 0.35234 loss)
I0930 20:24:10.577666  4070 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0930 20:24:15.818066  4070 solver.cpp:218] Iteration 14300 (19.0826 iter/s, 5.24039s/100 iters), loss = 0.415588
I0930 20:24:15.818107  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415589 (* 1 = 0.415589 loss)
I0930 20:24:15.818114  4070 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0930 20:24:21.059149  4070 solver.cpp:218] Iteration 14400 (19.0803 iter/s, 5.24102s/100 iters), loss = 0.281277
I0930 20:24:21.059293  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281277 (* 1 = 0.281277 loss)
I0930 20:24:21.059301  4070 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0930 20:24:26.040683  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:24:26.249935  4070 solver.cpp:330] Iteration 14500, Testing net (#0)
I0930 20:24:27.432709  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:24:27.482499  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8041
I0930 20:24:27.482525  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.574024 (* 1 = 0.574024 loss)
I0930 20:24:27.534629  4070 solver.cpp:218] Iteration 14500 (15.4433 iter/s, 6.47532s/100 iters), loss = 0.352722
I0930 20:24:27.534657  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352722 (* 1 = 0.352722 loss)
I0930 20:24:27.534664  4070 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0930 20:24:32.779889  4070 solver.cpp:218] Iteration 14600 (19.065 iter/s, 5.2452s/100 iters), loss = 0.370988
I0930 20:24:32.779928  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370988 (* 1 = 0.370988 loss)
I0930 20:24:32.779934  4070 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0930 20:24:38.022163  4070 solver.cpp:218] Iteration 14700 (19.0759 iter/s, 5.24221s/100 iters), loss = 0.388588
I0930 20:24:38.022192  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388588 (* 1 = 0.388588 loss)
I0930 20:24:38.022198  4070 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0930 20:24:43.256750  4070 solver.cpp:218] Iteration 14800 (19.1039 iter/s, 5.23454s/100 iters), loss = 0.420779
I0930 20:24:43.256790  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420779 (* 1 = 0.420779 loss)
I0930 20:24:43.256796  4070 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0930 20:24:48.504192  4070 solver.cpp:218] Iteration 14900 (19.0571 iter/s, 5.24738s/100 iters), loss = 0.387284
I0930 20:24:48.504233  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387284 (* 1 = 0.387284 loss)
I0930 20:24:48.504248  4070 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0930 20:24:53.489987  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:24:53.699651  4070 solver.cpp:330] Iteration 15000, Testing net (#0)
I0930 20:24:54.886435  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:24:54.936368  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7667
I0930 20:24:54.936403  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.735236 (* 1 = 0.735236 loss)
I0930 20:24:54.988785  4070 solver.cpp:218] Iteration 15000 (15.4213 iter/s, 6.48453s/100 iters), loss = 0.370885
I0930 20:24:54.988809  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370885 (* 1 = 0.370885 loss)
I0930 20:24:54.988816  4070 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0930 20:25:00.240839  4070 solver.cpp:218] Iteration 15100 (19.0403 iter/s, 5.25201s/100 iters), loss = 0.28082
I0930 20:25:00.240881  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28082 (* 1 = 0.28082 loss)
I0930 20:25:00.240888  4070 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0930 20:25:05.487141  4070 solver.cpp:218] Iteration 15200 (19.0613 iter/s, 5.24624s/100 iters), loss = 0.442467
I0930 20:25:05.487182  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442467 (* 1 = 0.442467 loss)
I0930 20:25:05.487190  4070 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0930 20:25:10.725535  4070 solver.cpp:218] Iteration 15300 (19.0901 iter/s, 5.23833s/100 iters), loss = 0.368615
I0930 20:25:10.725581  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368614 (* 1 = 0.368614 loss)
I0930 20:25:10.725589  4070 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0930 20:25:15.968430  4070 solver.cpp:218] Iteration 15400 (19.0738 iter/s, 5.24279s/100 iters), loss = 0.329536
I0930 20:25:15.968459  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329536 (* 1 = 0.329536 loss)
I0930 20:25:15.968466  4070 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0930 20:25:20.950266  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:25:21.159827  4070 solver.cpp:330] Iteration 15500, Testing net (#0)
I0930 20:25:22.343809  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:25:22.393713  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7418
I0930 20:25:22.393748  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.8388 (* 1 = 0.8388 loss)
I0930 20:25:22.445835  4070 solver.cpp:218] Iteration 15500 (15.4384 iter/s, 6.47735s/100 iters), loss = 0.341491
I0930 20:25:22.445859  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341491 (* 1 = 0.341491 loss)
I0930 20:25:22.445866  4070 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0930 20:25:27.688352  4070 solver.cpp:218] Iteration 15600 (19.075 iter/s, 5.24247s/100 iters), loss = 0.240598
I0930 20:25:27.688498  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240598 (* 1 = 0.240598 loss)
I0930 20:25:27.688505  4070 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0930 20:25:32.929558  4070 solver.cpp:218] Iteration 15700 (19.0801 iter/s, 5.24105s/100 iters), loss = 0.387664
I0930 20:25:32.929587  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387664 (* 1 = 0.387664 loss)
I0930 20:25:32.929594  4070 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0930 20:25:38.177863  4070 solver.cpp:218] Iteration 15800 (19.054 iter/s, 5.24825s/100 iters), loss = 0.331954
I0930 20:25:38.177904  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331954 (* 1 = 0.331954 loss)
I0930 20:25:38.177911  4070 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0930 20:25:43.417912  4070 solver.cpp:218] Iteration 15900 (19.084 iter/s, 5.23998s/100 iters), loss = 0.382508
I0930 20:25:43.417942  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382508 (* 1 = 0.382508 loss)
I0930 20:25:43.417948  4070 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0930 20:25:48.402878  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:25:48.612788  4070 solver.cpp:330] Iteration 16000, Testing net (#0)
I0930 20:25:49.805197  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:25:49.856101  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.776
I0930 20:25:49.856127  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.667888 (* 1 = 0.667888 loss)
I0930 20:25:49.908464  4070 solver.cpp:218] Iteration 16000 (15.4071 iter/s, 6.4905s/100 iters), loss = 0.287708
I0930 20:25:49.908494  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287708 (* 1 = 0.287708 loss)
I0930 20:25:49.908501  4070 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0930 20:25:55.137786  4070 solver.cpp:218] Iteration 16100 (19.1231 iter/s, 5.22927s/100 iters), loss = 0.388913
I0930 20:25:55.137816  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388913 (* 1 = 0.388913 loss)
I0930 20:25:55.137831  4070 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0930 20:26:00.379397  4070 solver.cpp:218] Iteration 16200 (19.0783 iter/s, 5.24155s/100 iters), loss = 0.341414
I0930 20:26:00.379523  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341414 (* 1 = 0.341414 loss)
I0930 20:26:00.379529  4070 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0930 20:26:05.618808  4070 solver.cpp:218] Iteration 16300 (19.0867 iter/s, 5.23926s/100 iters), loss = 0.340421
I0930 20:26:05.618849  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340421 (* 1 = 0.340421 loss)
I0930 20:26:05.618854  4070 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0930 20:26:10.856964  4070 solver.cpp:218] Iteration 16400 (19.0909 iter/s, 5.23809s/100 iters), loss = 0.296447
I0930 20:26:10.857009  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296447 (* 1 = 0.296447 loss)
I0930 20:26:10.857017  4070 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0930 20:26:15.829200  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:26:16.038189  4070 solver.cpp:330] Iteration 16500, Testing net (#0)
I0930 20:26:17.229933  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:26:17.279305  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8061
I0930 20:26:17.279350  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.587742 (* 1 = 0.587742 loss)
I0930 20:26:17.332140  4070 solver.cpp:218] Iteration 16500 (15.4439 iter/s, 6.47507s/100 iters), loss = 0.274822
I0930 20:26:17.332171  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274822 (* 1 = 0.274822 loss)
I0930 20:26:17.332178  4070 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0930 20:26:22.568570  4070 solver.cpp:218] Iteration 16600 (19.0972 iter/s, 5.23637s/100 iters), loss = 0.3265
I0930 20:26:22.568601  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3265 (* 1 = 0.3265 loss)
I0930 20:26:22.568608  4070 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0930 20:26:27.817454  4070 solver.cpp:218] Iteration 16700 (19.0519 iter/s, 5.24883s/100 iters), loss = 0.369105
I0930 20:26:27.817494  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369104 (* 1 = 0.369104 loss)
I0930 20:26:27.817500  4070 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0930 20:26:33.066454  4070 solver.cpp:218] Iteration 16800 (19.0515 iter/s, 5.24894s/100 iters), loss = 0.412154
I0930 20:26:33.066562  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412154 (* 1 = 0.412154 loss)
I0930 20:26:33.066570  4070 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0930 20:26:38.313284  4070 solver.cpp:218] Iteration 16900 (19.0596 iter/s, 5.2467s/100 iters), loss = 0.334137
I0930 20:26:38.313324  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334137 (* 1 = 0.334137 loss)
I0930 20:26:38.313331  4070 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0930 20:26:43.286871  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:26:43.496014  4070 solver.cpp:330] Iteration 17000, Testing net (#0)
I0930 20:26:44.685061  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:26:44.734994  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8076
I0930 20:26:44.735019  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.572845 (* 1 = 0.572845 loss)
I0930 20:26:44.787282  4070 solver.cpp:218] Iteration 17000 (15.4466 iter/s, 6.47393s/100 iters), loss = 0.25633
I0930 20:26:44.787308  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25633 (* 1 = 0.25633 loss)
I0930 20:26:44.787315  4070 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0930 20:26:50.031626  4070 solver.cpp:218] Iteration 17100 (19.0683 iter/s, 5.24429s/100 iters), loss = 0.29553
I0930 20:26:50.031656  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29553 (* 1 = 0.29553 loss)
I0930 20:26:50.031661  4070 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0930 20:26:55.266376  4070 solver.cpp:218] Iteration 17200 (19.1033 iter/s, 5.2347s/100 iters), loss = 0.304602
I0930 20:26:55.266405  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304602 (* 1 = 0.304602 loss)
I0930 20:26:55.266412  4070 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0930 20:27:00.509690  4070 solver.cpp:218] Iteration 17300 (19.0721 iter/s, 5.24326s/100 iters), loss = 0.447344
I0930 20:27:00.509732  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447344 (* 1 = 0.447344 loss)
I0930 20:27:00.509737  4070 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0930 20:27:05.758810  4070 solver.cpp:218] Iteration 17400 (19.051 iter/s, 5.24906s/100 iters), loss = 0.299546
I0930 20:27:05.758973  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299546 (* 1 = 0.299546 loss)
I0930 20:27:05.758981  4070 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0930 20:27:10.743623  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:27:10.955617  4070 solver.cpp:330] Iteration 17500, Testing net (#0)
I0930 20:27:12.139340  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:27:12.189473  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8094
I0930 20:27:12.189508  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.581244 (* 1 = 0.581244 loss)
I0930 20:27:12.242245  4070 solver.cpp:218] Iteration 17500 (15.4243 iter/s, 6.48326s/100 iters), loss = 0.316808
I0930 20:27:12.242275  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316808 (* 1 = 0.316808 loss)
I0930 20:27:12.242282  4070 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0930 20:27:17.490456  4070 solver.cpp:218] Iteration 17600 (19.0543 iter/s, 5.24816s/100 iters), loss = 0.329792
I0930 20:27:17.490494  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329792 (* 1 = 0.329792 loss)
I0930 20:27:17.490500  4070 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0930 20:27:22.734639  4070 solver.cpp:218] Iteration 17700 (19.069 iter/s, 5.24412s/100 iters), loss = 0.456553
I0930 20:27:22.734686  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456553 (* 1 = 0.456553 loss)
I0930 20:27:22.734694  4070 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0930 20:27:27.974768  4070 solver.cpp:218] Iteration 17800 (19.0839 iter/s, 5.24003s/100 iters), loss = 0.455666
I0930 20:27:27.974808  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.455666 (* 1 = 0.455666 loss)
I0930 20:27:27.974814  4070 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0930 20:27:33.223315  4070 solver.cpp:218] Iteration 17900 (19.0531 iter/s, 5.24849s/100 iters), loss = 0.191507
I0930 20:27:33.223356  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191507 (* 1 = 0.191507 loss)
I0930 20:27:33.223361  4070 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0930 20:27:38.207644  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:27:38.415810  4070 solver.cpp:330] Iteration 18000, Testing net (#0)
I0930 20:27:39.600389  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:27:39.649932  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7723
I0930 20:27:39.649966  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.686805 (* 1 = 0.686805 loss)
I0930 20:27:39.702448  4070 solver.cpp:218] Iteration 18000 (15.4343 iter/s, 6.47907s/100 iters), loss = 0.324702
I0930 20:27:39.702484  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324703 (* 1 = 0.324703 loss)
I0930 20:27:39.702492  4070 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0930 20:27:44.948725  4070 solver.cpp:218] Iteration 18100 (19.0613 iter/s, 5.24622s/100 iters), loss = 0.317829
I0930 20:27:44.948755  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317829 (* 1 = 0.317829 loss)
I0930 20:27:44.948765  4070 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0930 20:27:50.194520  4070 solver.cpp:218] Iteration 18200 (19.0631 iter/s, 5.24574s/100 iters), loss = 0.361847
I0930 20:27:50.194561  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361847 (* 1 = 0.361847 loss)
I0930 20:27:50.194566  4070 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0930 20:27:55.431602  4070 solver.cpp:218] Iteration 18300 (19.0948 iter/s, 5.23702s/100 iters), loss = 0.322875
I0930 20:27:55.431641  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322875 (* 1 = 0.322875 loss)
I0930 20:27:55.431648  4070 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0930 20:28:00.686322  4070 solver.cpp:218] Iteration 18400 (19.0307 iter/s, 5.25466s/100 iters), loss = 0.364683
I0930 20:28:00.686352  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364683 (* 1 = 0.364683 loss)
I0930 20:28:00.686357  4070 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0930 20:28:05.674165  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:28:05.883316  4070 solver.cpp:330] Iteration 18500, Testing net (#0)
I0930 20:28:07.065374  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:28:07.114995  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8242
I0930 20:28:07.115018  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.523359 (* 1 = 0.523359 loss)
I0930 20:28:07.167552  4070 solver.cpp:218] Iteration 18500 (15.4293 iter/s, 6.48118s/100 iters), loss = 0.35985
I0930 20:28:07.167577  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35985 (* 1 = 0.35985 loss)
I0930 20:28:07.167583  4070 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0930 20:28:12.413391  4070 solver.cpp:218] Iteration 18600 (19.0629 iter/s, 5.24579s/100 iters), loss = 0.264256
I0930 20:28:12.413519  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264256 (* 1 = 0.264256 loss)
I0930 20:28:12.413527  4070 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0930 20:28:17.663537  4070 solver.cpp:218] Iteration 18700 (19.0476 iter/s, 5.25s/100 iters), loss = 0.42399
I0930 20:28:17.663568  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42399 (* 1 = 0.42399 loss)
I0930 20:28:17.663574  4070 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0930 20:28:22.908198  4070 solver.cpp:218] Iteration 18800 (19.0672 iter/s, 5.24461s/100 iters), loss = 0.375519
I0930 20:28:22.908229  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375519 (* 1 = 0.375519 loss)
I0930 20:28:22.908246  4070 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0930 20:28:28.145826  4070 solver.cpp:218] Iteration 18900 (19.0928 iter/s, 5.23758s/100 iters), loss = 0.356197
I0930 20:28:28.145866  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356197 (* 1 = 0.356197 loss)
I0930 20:28:28.145872  4070 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0930 20:28:33.131578  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:28:33.341312  4070 solver.cpp:330] Iteration 19000, Testing net (#0)
I0930 20:28:34.526052  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:28:34.576122  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7558
I0930 20:28:34.576156  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.770282 (* 1 = 0.770282 loss)
I0930 20:28:34.629509  4070 solver.cpp:218] Iteration 19000 (15.4235 iter/s, 6.48362s/100 iters), loss = 0.284821
I0930 20:28:34.629540  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284821 (* 1 = 0.284821 loss)
I0930 20:28:34.629547  4070 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0930 20:28:39.876438  4070 solver.cpp:218] Iteration 19100 (19.059 iter/s, 5.24688s/100 iters), loss = 0.320782
I0930 20:28:39.876468  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320782 (* 1 = 0.320782 loss)
I0930 20:28:39.876474  4070 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0930 20:28:45.129475  4070 solver.cpp:218] Iteration 19200 (19.0368 iter/s, 5.25299s/100 iters), loss = 0.330992
I0930 20:28:45.129560  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330992 (* 1 = 0.330992 loss)
I0930 20:28:45.129567  4070 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0930 20:28:50.382944  4070 solver.cpp:218] Iteration 19300 (19.0354 iter/s, 5.25337s/100 iters), loss = 0.337272
I0930 20:28:50.382984  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337272 (* 1 = 0.337272 loss)
I0930 20:28:50.382992  4070 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0930 20:28:55.624744  4070 solver.cpp:218] Iteration 19400 (19.0777 iter/s, 5.24174s/100 iters), loss = 0.276054
I0930 20:28:55.624780  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276054 (* 1 = 0.276054 loss)
I0930 20:28:55.624788  4070 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0930 20:29:00.604143  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:29:00.814010  4070 solver.cpp:330] Iteration 19500, Testing net (#0)
I0930 20:29:02.006814  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:29:02.056603  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8166
I0930 20:29:02.056640  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558431 (* 1 = 0.558431 loss)
I0930 20:29:02.109092  4070 solver.cpp:218] Iteration 19500 (15.4219 iter/s, 6.48429s/100 iters), loss = 0.275442
I0930 20:29:02.109128  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275442 (* 1 = 0.275442 loss)
I0930 20:29:02.109135  4070 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0930 20:29:07.345000  4070 solver.cpp:218] Iteration 19600 (19.0991 iter/s, 5.23585s/100 iters), loss = 0.314387
I0930 20:29:07.345028  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314387 (* 1 = 0.314387 loss)
I0930 20:29:07.345034  4070 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0930 20:29:12.585434  4070 solver.cpp:218] Iteration 19700 (19.0826 iter/s, 5.24038s/100 iters), loss = 0.270204
I0930 20:29:12.585464  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270205 (* 1 = 0.270205 loss)
I0930 20:29:12.585469  4070 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0930 20:29:17.824194  4070 solver.cpp:218] Iteration 19800 (19.0887 iter/s, 5.23871s/100 iters), loss = 0.404806
I0930 20:29:17.824333  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404806 (* 1 = 0.404806 loss)
I0930 20:29:17.824352  4070 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0930 20:29:23.065618  4070 solver.cpp:218] Iteration 19900 (19.0793 iter/s, 5.24127s/100 iters), loss = 0.331524
I0930 20:29:23.065649  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331524 (* 1 = 0.331524 loss)
I0930 20:29:23.065655  4070 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0930 20:29:28.037243  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:29:28.245746  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_20000.caffemodel
I0930 20:29:28.250782  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_20000.solverstate
I0930 20:29:28.252137  4070 solver.cpp:330] Iteration 20000, Testing net (#0)
I0930 20:29:29.444653  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:29:29.494789  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8137
I0930 20:29:29.494823  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.542833 (* 1 = 0.542833 loss)
I0930 20:29:29.547049  4070 solver.cpp:218] Iteration 20000 (15.4288 iter/s, 6.48138s/100 iters), loss = 0.253635
I0930 20:29:29.547072  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253636 (* 1 = 0.253636 loss)
I0930 20:29:29.547080  4070 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0930 20:29:34.795260  4070 solver.cpp:218] Iteration 20100 (19.0543 iter/s, 5.24817s/100 iters), loss = 0.265958
I0930 20:29:34.795298  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265958 (* 1 = 0.265958 loss)
I0930 20:29:34.795305  4070 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0930 20:29:40.035998  4070 solver.cpp:218] Iteration 20200 (19.0815 iter/s, 5.24068s/100 iters), loss = 0.262449
I0930 20:29:40.036028  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26245 (* 1 = 0.26245 loss)
I0930 20:29:40.036044  4070 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0930 20:29:45.281909  4070 solver.cpp:218] Iteration 20300 (19.0626 iter/s, 5.24586s/100 iters), loss = 0.42638
I0930 20:29:45.281939  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42638 (* 1 = 0.42638 loss)
I0930 20:29:45.281945  4070 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0930 20:29:50.530308  4070 solver.cpp:218] Iteration 20400 (19.0536 iter/s, 5.24835s/100 iters), loss = 0.259791
I0930 20:29:50.530473  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259791 (* 1 = 0.259791 loss)
I0930 20:29:50.530491  4070 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0930 20:29:55.504429  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:29:55.716964  4070 solver.cpp:330] Iteration 20500, Testing net (#0)
I0930 20:29:56.906183  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:29:56.956312  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7262
I0930 20:29:56.956346  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.881783 (* 1 = 0.881783 loss)
I0930 20:29:57.008693  4070 solver.cpp:218] Iteration 20500 (15.4364 iter/s, 6.47821s/100 iters), loss = 0.278121
I0930 20:29:57.008723  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278121 (* 1 = 0.278121 loss)
I0930 20:29:57.008729  4070 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0930 20:30:02.250237  4070 solver.cpp:218] Iteration 20600 (19.0785 iter/s, 5.2415s/100 iters), loss = 0.360327
I0930 20:30:02.250267  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360327 (* 1 = 0.360327 loss)
I0930 20:30:02.250272  4070 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0930 20:30:07.482076  4070 solver.cpp:218] Iteration 20700 (19.1139 iter/s, 5.23179s/100 iters), loss = 0.282734
I0930 20:30:07.482106  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282734 (* 1 = 0.282734 loss)
I0930 20:30:07.482111  4070 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0930 20:30:12.724141  4070 solver.cpp:218] Iteration 20800 (19.0766 iter/s, 5.24201s/100 iters), loss = 0.295967
I0930 20:30:12.724182  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295967 (* 1 = 0.295967 loss)
I0930 20:30:12.724189  4070 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0930 20:30:17.971881  4070 solver.cpp:218] Iteration 20900 (19.056 iter/s, 5.24768s/100 iters), loss = 0.303878
I0930 20:30:17.971911  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303878 (* 1 = 0.303878 loss)
I0930 20:30:17.971917  4070 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0930 20:30:22.957419  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:30:23.166692  4070 solver.cpp:330] Iteration 21000, Testing net (#0)
I0930 20:30:24.350415  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:30:24.400358  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7687
I0930 20:30:24.400391  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.692806 (* 1 = 0.692806 loss)
I0930 20:30:24.452833  4070 solver.cpp:218] Iteration 21000 (15.43 iter/s, 6.4809s/100 iters), loss = 0.304751
I0930 20:30:24.452858  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304751 (* 1 = 0.304751 loss)
I0930 20:30:24.452864  4070 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0930 20:30:29.701793  4070 solver.cpp:218] Iteration 21100 (19.0516 iter/s, 5.24892s/100 iters), loss = 0.333058
I0930 20:30:29.701822  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333058 (* 1 = 0.333058 loss)
I0930 20:30:29.701838  4070 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0930 20:30:34.949337  4070 solver.cpp:218] Iteration 21200 (19.0567 iter/s, 5.2475s/100 iters), loss = 0.256858
I0930 20:30:34.949368  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256858 (* 1 = 0.256858 loss)
I0930 20:30:34.949373  4070 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0930 20:30:40.192777  4070 solver.cpp:218] Iteration 21300 (19.0716 iter/s, 5.24339s/100 iters), loss = 0.418523
I0930 20:30:40.192806  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418523 (* 1 = 0.418523 loss)
I0930 20:30:40.192811  4070 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0930 20:30:45.437031  4070 solver.cpp:218] Iteration 21400 (19.0687 iter/s, 5.2442s/100 iters), loss = 0.2401
I0930 20:30:45.437070  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2401 (* 1 = 0.2401 loss)
I0930 20:30:45.437077  4070 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0930 20:30:50.415155  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:30:50.625394  4070 solver.cpp:330] Iteration 21500, Testing net (#0)
I0930 20:30:51.809036  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:30:51.858549  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8349
I0930 20:30:51.858584  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.498969 (* 1 = 0.498969 loss)
I0930 20:30:51.911126  4070 solver.cpp:218] Iteration 21500 (15.4463 iter/s, 6.47404s/100 iters), loss = 0.259058
I0930 20:30:51.911154  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259058 (* 1 = 0.259058 loss)
I0930 20:30:51.911160  4070 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0930 20:30:57.154673  4070 solver.cpp:218] Iteration 21600 (19.0712 iter/s, 5.2435s/100 iters), loss = 0.280054
I0930 20:30:57.154811  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280054 (* 1 = 0.280054 loss)
I0930 20:30:57.154829  4070 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0930 20:31:02.397131  4070 solver.cpp:218] Iteration 21700 (19.0756 iter/s, 5.2423s/100 iters), loss = 0.282532
I0930 20:31:02.397171  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282532 (* 1 = 0.282532 loss)
I0930 20:31:02.397177  4070 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0930 20:31:07.629115  4070 solver.cpp:218] Iteration 21800 (19.1135 iter/s, 5.23192s/100 iters), loss = 0.335235
I0930 20:31:07.629150  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335235 (* 1 = 0.335235 loss)
I0930 20:31:07.629168  4070 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0930 20:31:12.873212  4070 solver.cpp:218] Iteration 21900 (19.0694 iter/s, 5.24401s/100 iters), loss = 0.260537
I0930 20:31:12.873244  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260537 (* 1 = 0.260537 loss)
I0930 20:31:12.873258  4070 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0930 20:31:17.862263  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:31:18.072156  4070 solver.cpp:330] Iteration 22000, Testing net (#0)
I0930 20:31:19.254493  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:31:19.304201  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8426
I0930 20:31:19.304235  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.461844 (* 1 = 0.461844 loss)
I0930 20:31:19.356742  4070 solver.cpp:218] Iteration 22000 (15.4238 iter/s, 6.48348s/100 iters), loss = 0.226775
I0930 20:31:19.356766  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226775 (* 1 = 0.226775 loss)
I0930 20:31:19.356772  4070 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0930 20:31:24.609431  4070 solver.cpp:218] Iteration 22100 (19.038 iter/s, 5.25264s/100 iters), loss = 0.261918
I0930 20:31:24.609469  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261918 (* 1 = 0.261918 loss)
I0930 20:31:24.609475  4070 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0930 20:31:29.854223  4070 solver.cpp:218] Iteration 22200 (19.0668 iter/s, 5.24473s/100 iters), loss = 0.290918
I0930 20:31:29.854333  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290918 (* 1 = 0.290918 loss)
I0930 20:31:29.854351  4070 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0930 20:31:35.097062  4070 solver.cpp:218] Iteration 22300 (19.0741 iter/s, 5.2427s/100 iters), loss = 0.355068
I0930 20:31:35.097100  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355068 (* 1 = 0.355068 loss)
I0930 20:31:35.097106  4070 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0930 20:31:40.334580  4070 solver.cpp:218] Iteration 22400 (19.0932 iter/s, 5.23746s/100 iters), loss = 0.256843
I0930 20:31:40.334610  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256843 (* 1 = 0.256843 loss)
I0930 20:31:40.334616  4070 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0930 20:31:45.319687  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:31:45.529223  4070 solver.cpp:330] Iteration 22500, Testing net (#0)
I0930 20:31:46.716620  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:31:46.767833  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.839
I0930 20:31:46.767859  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.474465 (* 1 = 0.474465 loss)
I0930 20:31:46.821133  4070 solver.cpp:218] Iteration 22500 (15.4166 iter/s, 6.4865s/100 iters), loss = 0.23383
I0930 20:31:46.821166  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23383 (* 1 = 0.23383 loss)
I0930 20:31:46.821172  4070 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0930 20:31:52.060108  4070 solver.cpp:218] Iteration 22600 (19.0879 iter/s, 5.23892s/100 iters), loss = 0.370474
I0930 20:31:52.060137  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370474 (* 1 = 0.370474 loss)
I0930 20:31:52.060142  4070 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0930 20:31:57.308015  4070 solver.cpp:218] Iteration 22700 (19.0554 iter/s, 5.24786s/100 iters), loss = 0.315481
I0930 20:31:57.308044  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315481 (* 1 = 0.315481 loss)
I0930 20:31:57.308049  4070 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0930 20:32:02.558718  4070 solver.cpp:218] Iteration 22800 (19.0452 iter/s, 5.25065s/100 iters), loss = 0.405089
I0930 20:32:02.558867  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405089 (* 1 = 0.405089 loss)
I0930 20:32:02.558885  4070 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0930 20:32:07.809227  4070 solver.cpp:218] Iteration 22900 (19.0464 iter/s, 5.25034s/100 iters), loss = 0.316555
I0930 20:32:07.809262  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316555 (* 1 = 0.316555 loss)
I0930 20:32:07.809269  4070 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0930 20:32:12.786870  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:32:12.996909  4070 solver.cpp:330] Iteration 23000, Testing net (#0)
I0930 20:32:14.189373  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:32:14.239289  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7515
I0930 20:32:14.239325  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.825295 (* 1 = 0.825295 loss)
I0930 20:32:14.291332  4070 solver.cpp:218] Iteration 23000 (15.4273 iter/s, 6.48201s/100 iters), loss = 0.300694
I0930 20:32:14.291357  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300694 (* 1 = 0.300694 loss)
I0930 20:32:14.291364  4070 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0930 20:32:19.528048  4070 solver.cpp:218] Iteration 23100 (19.0961 iter/s, 5.23667s/100 iters), loss = 0.297707
I0930 20:32:19.528077  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297707 (* 1 = 0.297707 loss)
I0930 20:32:19.528084  4070 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0930 20:32:24.769855  4070 solver.cpp:218] Iteration 23200 (19.0776 iter/s, 5.24176s/100 iters), loss = 0.289869
I0930 20:32:24.769894  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289869 (* 1 = 0.289869 loss)
I0930 20:32:24.769901  4070 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0930 20:32:30.014371  4070 solver.cpp:218] Iteration 23300 (19.0678 iter/s, 5.24446s/100 iters), loss = 0.375949
I0930 20:32:30.014401  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375949 (* 1 = 0.375949 loss)
I0930 20:32:30.014408  4070 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0930 20:32:35.261137  4070 solver.cpp:218] Iteration 23400 (19.0596 iter/s, 5.24671s/100 iters), loss = 0.247004
I0930 20:32:35.261267  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247004 (* 1 = 0.247004 loss)
I0930 20:32:35.261276  4070 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0930 20:32:40.230783  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:32:40.440356  4070 solver.cpp:330] Iteration 23500, Testing net (#0)
I0930 20:32:41.634968  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:32:41.685137  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7741
I0930 20:32:41.685160  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.72892 (* 1 = 0.72892 loss)
I0930 20:32:41.737511  4070 solver.cpp:218] Iteration 23500 (15.4411 iter/s, 6.47624s/100 iters), loss = 0.266954
I0930 20:32:41.737534  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266954 (* 1 = 0.266954 loss)
I0930 20:32:41.737540  4070 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0930 20:32:46.980129  4070 solver.cpp:218] Iteration 23600 (19.0746 iter/s, 5.24257s/100 iters), loss = 0.371405
I0930 20:32:46.980159  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371405 (* 1 = 0.371405 loss)
I0930 20:32:46.980165  4070 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0930 20:32:52.217159  4070 solver.cpp:218] Iteration 23700 (19.095 iter/s, 5.23698s/100 iters), loss = 0.308471
I0930 20:32:52.217200  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308471 (* 1 = 0.308471 loss)
I0930 20:32:52.217206  4070 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0930 20:32:57.468894  4070 solver.cpp:218] Iteration 23800 (19.0416 iter/s, 5.25167s/100 iters), loss = 0.329506
I0930 20:32:57.468926  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329506 (* 1 = 0.329506 loss)
I0930 20:32:57.468935  4070 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0930 20:33:02.708199  4070 solver.cpp:218] Iteration 23900 (19.0867 iter/s, 5.23925s/100 iters), loss = 0.317069
I0930 20:33:02.708230  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317069 (* 1 = 0.317069 loss)
I0930 20:33:02.708238  4070 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0930 20:33:07.690510  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:33:07.903753  4070 solver.cpp:330] Iteration 24000, Testing net (#0)
I0930 20:33:09.088070  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:33:09.138064  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7922
I0930 20:33:09.138098  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.657342 (* 1 = 0.657342 loss)
I0930 20:33:09.190572  4070 solver.cpp:218] Iteration 24000 (15.4266 iter/s, 6.48232s/100 iters), loss = 0.228451
I0930 20:33:09.190599  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228451 (* 1 = 0.228451 loss)
I0930 20:33:09.190606  4070 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0930 20:33:14.438774  4070 solver.cpp:218] Iteration 24100 (19.0543 iter/s, 5.24816s/100 iters), loss = 0.252208
I0930 20:33:14.438814  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252208 (* 1 = 0.252208 loss)
I0930 20:33:14.438820  4070 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0930 20:33:19.679859  4070 solver.cpp:218] Iteration 24200 (19.0803 iter/s, 5.24102s/100 iters), loss = 0.274239
I0930 20:33:19.679895  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274239 (* 1 = 0.274239 loss)
I0930 20:33:19.679903  4070 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0930 20:33:24.921630  4070 solver.cpp:218] Iteration 24300 (19.0777 iter/s, 5.24171s/100 iters), loss = 0.271516
I0930 20:33:24.921660  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271516 (* 1 = 0.271516 loss)
I0930 20:33:24.921665  4070 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0930 20:33:30.169368  4070 solver.cpp:218] Iteration 24400 (19.056 iter/s, 5.24768s/100 iters), loss = 0.359398
I0930 20:33:30.169399  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359398 (* 1 = 0.359398 loss)
I0930 20:33:30.169405  4070 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0930 20:33:35.162842  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:33:35.372488  4070 solver.cpp:330] Iteration 24500, Testing net (#0)
I0930 20:33:36.555578  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:33:36.605478  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8209
I0930 20:33:36.605511  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.530747 (* 1 = 0.530747 loss)
I0930 20:33:36.657966  4070 solver.cpp:218] Iteration 24500 (15.4118 iter/s, 6.48855s/100 iters), loss = 0.365052
I0930 20:33:36.657992  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365052 (* 1 = 0.365052 loss)
I0930 20:33:36.657999  4070 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0930 20:33:41.907655  4070 solver.cpp:218] Iteration 24600 (19.0489 iter/s, 5.24964s/100 iters), loss = 0.267303
I0930 20:33:41.907783  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267303 (* 1 = 0.267303 loss)
I0930 20:33:41.907791  4070 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0930 20:33:47.157063  4070 solver.cpp:218] Iteration 24700 (19.0503 iter/s, 5.24926s/100 iters), loss = 0.351494
I0930 20:33:47.157095  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351493 (* 1 = 0.351493 loss)
I0930 20:33:47.157102  4070 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0930 20:33:52.392392  4070 solver.cpp:218] Iteration 24800 (19.1012 iter/s, 5.23528s/100 iters), loss = 0.380408
I0930 20:33:52.392421  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380408 (* 1 = 0.380408 loss)
I0930 20:33:52.392427  4070 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0930 20:33:57.642716  4070 solver.cpp:218] Iteration 24900 (19.0466 iter/s, 5.25027s/100 iters), loss = 0.227549
I0930 20:33:57.642748  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227549 (* 1 = 0.227549 loss)
I0930 20:33:57.642755  4070 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0930 20:34:02.624258  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:34:02.834327  4070 solver.cpp:330] Iteration 25000, Testing net (#0)
I0930 20:34:04.018023  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:34:04.067690  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.81
I0930 20:34:04.067713  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55795 (* 1 = 0.55795 loss)
I0930 20:34:04.120235  4070 solver.cpp:218] Iteration 25000 (15.4381 iter/s, 6.47746s/100 iters), loss = 0.336031
I0930 20:34:04.120260  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336031 (* 1 = 0.336031 loss)
I0930 20:34:04.120265  4070 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0930 20:34:09.365288  4070 solver.cpp:218] Iteration 25100 (19.0657 iter/s, 5.24501s/100 iters), loss = 0.282854
I0930 20:34:09.365316  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282854 (* 1 = 0.282854 loss)
I0930 20:34:09.365322  4070 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0930 20:34:14.607535  4070 solver.cpp:218] Iteration 25200 (19.076 iter/s, 5.2422s/100 iters), loss = 0.224378
I0930 20:34:14.607651  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224378 (* 1 = 0.224378 loss)
I0930 20:34:14.607658  4070 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0930 20:34:19.852006  4070 solver.cpp:218] Iteration 25300 (19.0682 iter/s, 5.24435s/100 iters), loss = 0.3298
I0930 20:34:19.852051  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3298 (* 1 = 0.3298 loss)
I0930 20:34:19.852057  4070 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0930 20:34:25.095568  4070 solver.cpp:218] Iteration 25400 (19.0714 iter/s, 5.24347s/100 iters), loss = 0.279247
I0930 20:34:25.095608  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279247 (* 1 = 0.279247 loss)
I0930 20:34:25.095614  4070 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0930 20:34:30.081341  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:34:30.291075  4070 solver.cpp:330] Iteration 25500, Testing net (#0)
I0930 20:34:31.475548  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:34:31.525689  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8174
I0930 20:34:31.525713  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.541359 (* 1 = 0.541359 loss)
I0930 20:34:31.577914  4070 solver.cpp:218] Iteration 25500 (15.4267 iter/s, 6.48228s/100 iters), loss = 0.21729
I0930 20:34:31.577942  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217289 (* 1 = 0.217289 loss)
I0930 20:34:31.577949  4070 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0930 20:34:36.822343  4070 solver.cpp:218] Iteration 25600 (19.068 iter/s, 5.24438s/100 iters), loss = 0.232722
I0930 20:34:36.822373  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232722 (* 1 = 0.232722 loss)
I0930 20:34:36.822379  4070 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0930 20:34:42.067342  4070 solver.cpp:218] Iteration 25700 (19.066 iter/s, 5.24495s/100 iters), loss = 0.350098
I0930 20:34:42.067380  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350098 (* 1 = 0.350098 loss)
I0930 20:34:42.067386  4070 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0930 20:34:47.317229  4070 solver.cpp:218] Iteration 25800 (19.0482 iter/s, 5.24983s/100 iters), loss = 0.403369
I0930 20:34:47.317359  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403369 (* 1 = 0.403369 loss)
I0930 20:34:47.317368  4070 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0930 20:34:52.554770  4070 solver.cpp:218] Iteration 25900 (19.0935 iter/s, 5.23739s/100 iters), loss = 0.242137
I0930 20:34:52.554801  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242137 (* 1 = 0.242137 loss)
I0930 20:34:52.554807  4070 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0930 20:34:57.536936  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:34:57.746996  4070 solver.cpp:330] Iteration 26000, Testing net (#0)
I0930 20:34:58.936626  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:34:58.986480  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7937
I0930 20:34:58.986515  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.634687 (* 1 = 0.634687 loss)
I0930 20:34:59.038978  4070 solver.cpp:218] Iteration 26000 (15.4222 iter/s, 6.48415s/100 iters), loss = 0.245321
I0930 20:34:59.039011  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245321 (* 1 = 0.245321 loss)
I0930 20:34:59.039017  4070 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0930 20:35:04.273946  4070 solver.cpp:218] Iteration 26100 (19.1025 iter/s, 5.23491s/100 iters), loss = 0.259773
I0930 20:35:04.273977  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259773 (* 1 = 0.259773 loss)
I0930 20:35:04.273983  4070 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0930 20:35:09.524379  4070 solver.cpp:218] Iteration 26200 (19.0462 iter/s, 5.25038s/100 iters), loss = 0.314629
I0930 20:35:09.524420  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314629 (* 1 = 0.314629 loss)
I0930 20:35:09.524425  4070 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0930 20:35:14.773484  4070 solver.cpp:218] Iteration 26300 (19.0511 iter/s, 5.24904s/100 iters), loss = 0.302565
I0930 20:35:14.773525  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302565 (* 1 = 0.302565 loss)
I0930 20:35:14.773531  4070 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0930 20:35:20.022156  4070 solver.cpp:218] Iteration 26400 (19.0527 iter/s, 5.24861s/100 iters), loss = 0.332413
I0930 20:35:20.022296  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332413 (* 1 = 0.332413 loss)
I0930 20:35:20.022305  4070 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0930 20:35:25.000021  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:35:25.209141  4070 solver.cpp:330] Iteration 26500, Testing net (#0)
I0930 20:35:26.403218  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:35:26.453233  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8122
I0930 20:35:26.453255  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.575599 (* 1 = 0.575599 loss)
I0930 20:35:26.505872  4070 solver.cpp:218] Iteration 26500 (15.4236 iter/s, 6.48356s/100 iters), loss = 0.210923
I0930 20:35:26.505898  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210923 (* 1 = 0.210923 loss)
I0930 20:35:26.505905  4070 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0930 20:35:31.748566  4070 solver.cpp:218] Iteration 26600 (19.0744 iter/s, 5.24264s/100 iters), loss = 0.290325
I0930 20:35:31.748610  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290324 (* 1 = 0.290324 loss)
I0930 20:35:31.748618  4070 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0930 20:35:36.989349  4070 solver.cpp:218] Iteration 26700 (19.0815 iter/s, 5.24069s/100 iters), loss = 0.309439
I0930 20:35:36.989388  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309439 (* 1 = 0.309439 loss)
I0930 20:35:36.989394  4070 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0930 20:35:42.233831  4070 solver.cpp:218] Iteration 26800 (19.0679 iter/s, 5.24442s/100 iters), loss = 0.259588
I0930 20:35:42.233871  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259588 (* 1 = 0.259588 loss)
I0930 20:35:42.233877  4070 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0930 20:35:47.479559  4070 solver.cpp:218] Iteration 26900 (19.0634 iter/s, 5.24567s/100 iters), loss = 0.285877
I0930 20:35:47.479590  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285877 (* 1 = 0.285877 loss)
I0930 20:35:47.479596  4070 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0930 20:35:52.454841  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:35:52.666944  4070 solver.cpp:330] Iteration 27000, Testing net (#0)
I0930 20:35:53.860368  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:35:53.910465  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8096
I0930 20:35:53.910500  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.618141 (* 1 = 0.618141 loss)
I0930 20:35:53.963050  4070 solver.cpp:218] Iteration 27000 (15.4239 iter/s, 6.48344s/100 iters), loss = 0.307531
I0930 20:35:53.963091  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307531 (* 1 = 0.307531 loss)
I0930 20:35:53.963107  4070 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0930 20:35:59.218720  4070 solver.cpp:218] Iteration 27100 (19.0273 iter/s, 5.25561s/100 iters), loss = 0.312169
I0930 20:35:59.218761  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312169 (* 1 = 0.312169 loss)
I0930 20:35:59.218767  4070 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0930 20:36:04.461195  4070 solver.cpp:218] Iteration 27200 (19.0752 iter/s, 5.24241s/100 iters), loss = 0.288447
I0930 20:36:04.461236  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288447 (* 1 = 0.288447 loss)
I0930 20:36:04.461241  4070 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0930 20:36:09.712970  4070 solver.cpp:218] Iteration 27300 (19.0414 iter/s, 5.25171s/100 iters), loss = 0.275342
I0930 20:36:09.713001  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275342 (* 1 = 0.275342 loss)
I0930 20:36:09.713016  4070 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0930 20:36:14.967703  4070 solver.cpp:218] Iteration 27400 (19.0306 iter/s, 5.25468s/100 iters), loss = 0.331981
I0930 20:36:14.967743  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331981 (* 1 = 0.331981 loss)
I0930 20:36:14.967749  4070 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0930 20:36:19.951766  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:36:20.162019  4070 solver.cpp:330] Iteration 27500, Testing net (#0)
I0930 20:36:21.348062  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:36:21.398097  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8194
I0930 20:36:21.398120  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.534031 (* 1 = 0.534031 loss)
I0930 20:36:21.450520  4070 solver.cpp:218] Iteration 27500 (15.4255 iter/s, 6.48275s/100 iters), loss = 0.238143
I0930 20:36:21.450546  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238143 (* 1 = 0.238143 loss)
I0930 20:36:21.450552  4070 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0930 20:36:26.693313  4070 solver.cpp:218] Iteration 27600 (19.074 iter/s, 5.24275s/100 iters), loss = 0.246604
I0930 20:36:26.693437  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246604 (* 1 = 0.246604 loss)
I0930 20:36:26.693444  4070 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0930 20:36:31.931802  4070 solver.cpp:218] Iteration 27700 (19.09 iter/s, 5.23834s/100 iters), loss = 0.311034
I0930 20:36:31.931834  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311034 (* 1 = 0.311034 loss)
I0930 20:36:31.931840  4070 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0930 20:36:37.171412  4070 solver.cpp:218] Iteration 27800 (19.0856 iter/s, 5.23956s/100 iters), loss = 0.266575
I0930 20:36:37.171452  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266575 (* 1 = 0.266575 loss)
I0930 20:36:37.171458  4070 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0930 20:36:42.417168  4070 solver.cpp:218] Iteration 27900 (19.0633 iter/s, 5.24569s/100 iters), loss = 0.223132
I0930 20:36:42.417199  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223132 (* 1 = 0.223132 loss)
I0930 20:36:42.417204  4070 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0930 20:36:47.399440  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:36:47.609935  4070 solver.cpp:330] Iteration 28000, Testing net (#0)
I0930 20:36:48.794884  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:36:48.845134  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8253
I0930 20:36:48.845158  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.541431 (* 1 = 0.541431 loss)
I0930 20:36:48.897848  4070 solver.cpp:218] Iteration 28000 (15.4306 iter/s, 6.48063s/100 iters), loss = 0.266167
I0930 20:36:48.897874  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266167 (* 1 = 0.266167 loss)
I0930 20:36:48.897881  4070 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0930 20:36:54.146637  4070 solver.cpp:218] Iteration 28100 (19.0522 iter/s, 5.24874s/100 iters), loss = 0.288536
I0930 20:36:54.146666  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288536 (* 1 = 0.288536 loss)
I0930 20:36:54.146672  4070 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0930 20:36:59.396811  4070 solver.cpp:218] Iteration 28200 (19.0472 iter/s, 5.25012s/100 iters), loss = 0.268289
I0930 20:36:59.396953  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268289 (* 1 = 0.268289 loss)
I0930 20:36:59.396961  4070 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0930 20:37:04.638783  4070 solver.cpp:218] Iteration 28300 (19.0774 iter/s, 5.24182s/100 iters), loss = 0.332485
I0930 20:37:04.638818  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332484 (* 1 = 0.332484 loss)
I0930 20:37:04.638824  4070 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0930 20:37:09.885092  4070 solver.cpp:218] Iteration 28400 (19.0612 iter/s, 5.24626s/100 iters), loss = 0.237858
I0930 20:37:09.885121  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237858 (* 1 = 0.237858 loss)
I0930 20:37:09.885138  4070 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0930 20:37:14.867144  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:37:15.077493  4070 solver.cpp:330] Iteration 28500, Testing net (#0)
I0930 20:37:16.262688  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:37:16.312114  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7987
I0930 20:37:16.312137  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.615212 (* 1 = 0.615212 loss)
I0930 20:37:16.364514  4070 solver.cpp:218] Iteration 28500 (15.4336 iter/s, 6.47937s/100 iters), loss = 0.180572
I0930 20:37:16.364539  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180572 (* 1 = 0.180572 loss)
I0930 20:37:16.364547  4070 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0930 20:37:21.610890  4070 solver.cpp:218] Iteration 28600 (19.061 iter/s, 5.24632s/100 iters), loss = 0.33891
I0930 20:37:21.610919  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33891 (* 1 = 0.33891 loss)
I0930 20:37:21.610924  4070 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0930 20:37:26.859854  4070 solver.cpp:218] Iteration 28700 (19.0516 iter/s, 5.24891s/100 iters), loss = 0.275188
I0930 20:37:26.859894  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275188 (* 1 = 0.275188 loss)
I0930 20:37:26.859900  4070 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0930 20:37:32.106748  4070 solver.cpp:218] Iteration 28800 (19.0591 iter/s, 5.24683s/100 iters), loss = 0.32602
I0930 20:37:32.106919  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32602 (* 1 = 0.32602 loss)
I0930 20:37:32.106952  4070 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0930 20:37:37.349354  4070 solver.cpp:218] Iteration 28900 (19.0752 iter/s, 5.24242s/100 iters), loss = 0.187897
I0930 20:37:37.349385  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187897 (* 1 = 0.187897 loss)
I0930 20:37:37.349403  4070 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0930 20:37:42.334947  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:37:42.543843  4070 solver.cpp:330] Iteration 29000, Testing net (#0)
I0930 20:37:43.731832  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:37:43.782402  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7805
I0930 20:37:43.782439  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.685192 (* 1 = 0.685192 loss)
I0930 20:37:43.836977  4070 solver.cpp:218] Iteration 29000 (15.4141 iter/s, 6.48757s/100 iters), loss = 0.188838
I0930 20:37:43.837011  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188838 (* 1 = 0.188838 loss)
I0930 20:37:43.837018  4070 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0930 20:37:49.075407  4070 solver.cpp:218] Iteration 29100 (19.0899 iter/s, 5.23838s/100 iters), loss = 0.25806
I0930 20:37:49.075436  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25806 (* 1 = 0.25806 loss)
I0930 20:37:49.075443  4070 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0930 20:37:54.322139  4070 solver.cpp:218] Iteration 29200 (19.0597 iter/s, 5.24668s/100 iters), loss = 0.27261
I0930 20:37:54.322177  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27261 (* 1 = 0.27261 loss)
I0930 20:37:54.322183  4070 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0930 20:37:59.557996  4070 solver.cpp:218] Iteration 29300 (19.0993 iter/s, 5.2358s/100 iters), loss = 0.23688
I0930 20:37:59.558025  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23688 (* 1 = 0.23688 loss)
I0930 20:37:59.558030  4070 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0930 20:38:04.795462  4070 solver.cpp:218] Iteration 29400 (19.0934 iter/s, 5.23741s/100 iters), loss = 0.171267
I0930 20:38:04.795578  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171267 (* 1 = 0.171267 loss)
I0930 20:38:04.795595  4070 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0930 20:38:09.775326  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:38:09.985559  4070 solver.cpp:330] Iteration 29500, Testing net (#0)
I0930 20:38:11.177976  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:38:11.227955  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8016
I0930 20:38:11.227990  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.577467 (* 1 = 0.577467 loss)
I0930 20:38:11.280120  4070 solver.cpp:218] Iteration 29500 (15.4213 iter/s, 6.48454s/100 iters), loss = 0.315669
I0930 20:38:11.280148  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315669 (* 1 = 0.315669 loss)
I0930 20:38:11.280155  4070 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0930 20:38:16.515709  4070 solver.cpp:218] Iteration 29600 (19.1002 iter/s, 5.23554s/100 iters), loss = 0.205261
I0930 20:38:16.515739  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205261 (* 1 = 0.205261 loss)
I0930 20:38:16.515746  4070 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0930 20:38:21.768268  4070 solver.cpp:218] Iteration 29700 (19.0385 iter/s, 5.25251s/100 iters), loss = 0.330832
I0930 20:38:21.768308  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330831 (* 1 = 0.330831 loss)
I0930 20:38:21.768314  4070 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0930 20:38:27.014361  4070 solver.cpp:218] Iteration 29800 (19.062 iter/s, 5.24603s/100 iters), loss = 0.304431
I0930 20:38:27.014391  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304431 (* 1 = 0.304431 loss)
I0930 20:38:27.014398  4070 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0930 20:38:32.267158  4070 solver.cpp:218] Iteration 29900 (19.0377 iter/s, 5.25274s/100 iters), loss = 0.291992
I0930 20:38:32.267197  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291992 (* 1 = 0.291992 loss)
I0930 20:38:32.267204  4070 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0930 20:38:37.244094  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:38:37.454828  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_30000.caffemodel
I0930 20:38:37.459975  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_30000.solverstate
I0930 20:38:37.461331  4070 solver.cpp:330] Iteration 30000, Testing net (#0)
I0930 20:38:38.652551  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:38:38.702558  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7942
I0930 20:38:38.702581  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.614326 (* 1 = 0.614326 loss)
I0930 20:38:38.755038  4070 solver.cpp:218] Iteration 30000 (15.4135 iter/s, 6.48782s/100 iters), loss = 0.24691
I0930 20:38:38.755064  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24691 (* 1 = 0.24691 loss)
I0930 20:38:38.755071  4070 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0930 20:38:44.000038  4070 solver.cpp:218] Iteration 30100 (19.0659 iter/s, 5.24495s/100 iters), loss = 0.291948
I0930 20:38:44.000079  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291947 (* 1 = 0.291947 loss)
I0930 20:38:44.000085  4070 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0930 20:38:49.241259  4070 solver.cpp:218] Iteration 30200 (19.0797 iter/s, 5.24116s/100 iters), loss = 0.26577
I0930 20:38:49.241299  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26577 (* 1 = 0.26577 loss)
I0930 20:38:49.241305  4070 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0930 20:38:54.489171  4070 solver.cpp:218] Iteration 30300 (19.0554 iter/s, 5.24785s/100 iters), loss = 0.259847
I0930 20:38:54.489212  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259847 (* 1 = 0.259847 loss)
I0930 20:38:54.489219  4070 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0930 20:38:59.737380  4070 solver.cpp:218] Iteration 30400 (19.0543 iter/s, 5.24815s/100 iters), loss = 0.236549
I0930 20:38:59.737419  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236549 (* 1 = 0.236549 loss)
I0930 20:38:59.737426  4070 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0930 20:39:04.717114  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:39:04.933533  4070 solver.cpp:330] Iteration 30500, Testing net (#0)
I0930 20:39:06.119192  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:39:06.169324  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8152
I0930 20:39:06.169358  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583195 (* 1 = 0.583195 loss)
I0930 20:39:06.221873  4070 solver.cpp:218] Iteration 30500 (15.4215 iter/s, 6.48444s/100 iters), loss = 0.274706
I0930 20:39:06.221899  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274706 (* 1 = 0.274706 loss)
I0930 20:39:06.221905  4070 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0930 20:39:11.471582  4070 solver.cpp:218] Iteration 30600 (19.0488 iter/s, 5.24967s/100 iters), loss = 0.205306
I0930 20:39:11.471717  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205306 (* 1 = 0.205306 loss)
I0930 20:39:11.471725  4070 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0930 20:39:16.707777  4070 solver.cpp:218] Iteration 30700 (19.0984 iter/s, 5.23605s/100 iters), loss = 0.317242
I0930 20:39:16.707828  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317242 (* 1 = 0.317242 loss)
I0930 20:39:16.707835  4070 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0930 20:39:21.955787  4070 solver.cpp:218] Iteration 30800 (19.0552 iter/s, 5.24791s/100 iters), loss = 0.311277
I0930 20:39:21.955816  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311277 (* 1 = 0.311277 loss)
I0930 20:39:21.955821  4070 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0930 20:39:27.204231  4070 solver.cpp:218] Iteration 30900 (19.0534 iter/s, 5.2484s/100 iters), loss = 0.209449
I0930 20:39:27.204269  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209449 (* 1 = 0.209449 loss)
I0930 20:39:27.204275  4070 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0930 20:39:32.186333  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:39:32.396216  4070 solver.cpp:330] Iteration 31000, Testing net (#0)
I0930 20:39:33.579331  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:39:33.629539  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7843
I0930 20:39:33.629573  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.669593 (* 1 = 0.669593 loss)
I0930 20:39:33.682193  4070 solver.cpp:218] Iteration 31000 (15.4371 iter/s, 6.4779s/100 iters), loss = 0.261696
I0930 20:39:33.682229  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261696 (* 1 = 0.261696 loss)
I0930 20:39:33.682235  4070 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0930 20:39:38.921258  4070 solver.cpp:218] Iteration 31100 (19.0876 iter/s, 5.23901s/100 iters), loss = 0.401343
I0930 20:39:38.921288  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401343 (* 1 = 0.401343 loss)
I0930 20:39:38.921304  4070 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0930 20:39:44.164358  4070 solver.cpp:218] Iteration 31200 (19.0729 iter/s, 5.24305s/100 iters), loss = 0.247369
I0930 20:39:44.164474  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247369 (* 1 = 0.247369 loss)
I0930 20:39:44.164491  4070 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0930 20:39:49.401854  4070 solver.cpp:218] Iteration 31300 (19.0935 iter/s, 5.23737s/100 iters), loss = 0.318057
I0930 20:39:49.401883  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318057 (* 1 = 0.318057 loss)
I0930 20:39:49.401888  4070 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0930 20:39:54.647066  4070 solver.cpp:218] Iteration 31400 (19.0652 iter/s, 5.24516s/100 iters), loss = 0.241936
I0930 20:39:54.647095  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241936 (* 1 = 0.241936 loss)
I0930 20:39:54.647101  4070 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0930 20:39:59.629678  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:39:59.840013  4070 solver.cpp:330] Iteration 31500, Testing net (#0)
I0930 20:40:01.025346  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:40:01.074841  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8409
I0930 20:40:01.074874  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.457443 (* 1 = 0.457443 loss)
I0930 20:40:01.127286  4070 solver.cpp:218] Iteration 31500 (15.4317 iter/s, 6.48017s/100 iters), loss = 0.303577
I0930 20:40:01.127321  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303577 (* 1 = 0.303577 loss)
I0930 20:40:01.127327  4070 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0930 20:40:06.379700  4070 solver.cpp:218] Iteration 31600 (19.0391 iter/s, 5.25236s/100 iters), loss = 0.16747
I0930 20:40:06.379730  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16747 (* 1 = 0.16747 loss)
I0930 20:40:06.379736  4070 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0930 20:40:11.631415  4070 solver.cpp:218] Iteration 31700 (19.0416 iter/s, 5.25166s/100 iters), loss = 0.242258
I0930 20:40:11.631446  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242258 (* 1 = 0.242258 loss)
I0930 20:40:11.631463  4070 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0930 20:40:16.880961  4070 solver.cpp:218] Iteration 31800 (19.0495 iter/s, 5.24949s/100 iters), loss = 0.316682
I0930 20:40:16.881105  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316682 (* 1 = 0.316682 loss)
I0930 20:40:16.881114  4070 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0930 20:40:22.117708  4070 solver.cpp:218] Iteration 31900 (19.0965 iter/s, 5.23656s/100 iters), loss = 0.284355
I0930 20:40:22.117738  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284355 (* 1 = 0.284355 loss)
I0930 20:40:22.117743  4070 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0930 20:40:27.096019  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:40:27.304677  4070 solver.cpp:330] Iteration 32000, Testing net (#0)
I0930 20:40:28.489075  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:40:28.538923  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8417
I0930 20:40:28.538949  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.487672 (* 1 = 0.487672 loss)
I0930 20:40:28.591413  4070 solver.cpp:218] Iteration 32000 (15.4472 iter/s, 6.47366s/100 iters), loss = 0.165302
I0930 20:40:28.591444  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165302 (* 1 = 0.165302 loss)
I0930 20:40:28.591454  4070 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0930 20:40:33.840607  4070 solver.cpp:218] Iteration 32100 (19.0507 iter/s, 5.24915s/100 iters), loss = 0.214804
I0930 20:40:33.840638  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214804 (* 1 = 0.214804 loss)
I0930 20:40:33.840646  4070 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0930 20:40:39.082864  4070 solver.cpp:218] Iteration 32200 (19.0759 iter/s, 5.24221s/100 iters), loss = 0.32694
I0930 20:40:39.082895  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32694 (* 1 = 0.32694 loss)
I0930 20:40:39.082903  4070 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0930 20:40:44.324370  4070 solver.cpp:218] Iteration 32300 (19.0787 iter/s, 5.24145s/100 iters), loss = 0.314585
I0930 20:40:44.324404  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314585 (* 1 = 0.314585 loss)
I0930 20:40:44.324422  4070 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0930 20:40:49.567356  4070 solver.cpp:218] Iteration 32400 (19.0733 iter/s, 5.24293s/100 iters), loss = 0.213743
I0930 20:40:49.567490  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213743 (* 1 = 0.213743 loss)
I0930 20:40:49.567510  4070 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0930 20:40:54.552183  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:40:54.761734  4070 solver.cpp:330] Iteration 32500, Testing net (#0)
I0930 20:40:55.955178  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:40:56.004642  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7889
I0930 20:40:56.004678  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.736424 (* 1 = 0.736424 loss)
I0930 20:40:56.057579  4070 solver.cpp:218] Iteration 32500 (15.4081 iter/s, 6.49007s/100 iters), loss = 0.271758
I0930 20:40:56.057612  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271758 (* 1 = 0.271758 loss)
I0930 20:40:56.057621  4070 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0930 20:41:01.296007  4070 solver.cpp:218] Iteration 32600 (19.0899 iter/s, 5.23838s/100 iters), loss = 0.297557
I0930 20:41:01.296041  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297557 (* 1 = 0.297557 loss)
I0930 20:41:01.296051  4070 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0930 20:41:06.538655  4070 solver.cpp:218] Iteration 32700 (19.0745 iter/s, 5.2426s/100 iters), loss = 0.365545
I0930 20:41:06.538696  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365545 (* 1 = 0.365545 loss)
I0930 20:41:06.538702  4070 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0930 20:41:11.781359  4070 solver.cpp:218] Iteration 32800 (19.0743 iter/s, 5.24264s/100 iters), loss = 0.311446
I0930 20:41:11.781391  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311446 (* 1 = 0.311446 loss)
I0930 20:41:11.781410  4070 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0930 20:41:17.022835  4070 solver.cpp:218] Iteration 32900 (19.0788 iter/s, 5.24142s/100 iters), loss = 0.233293
I0930 20:41:17.022871  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233293 (* 1 = 0.233293 loss)
I0930 20:41:17.022881  4070 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0930 20:41:21.998560  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:41:22.207979  4070 solver.cpp:330] Iteration 33000, Testing net (#0)
I0930 20:41:23.399108  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:41:23.449131  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8125
I0930 20:41:23.449156  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.60788 (* 1 = 0.60788 loss)
I0930 20:41:23.501657  4070 solver.cpp:218] Iteration 33000 (15.435 iter/s, 6.47877s/100 iters), loss = 0.221506
I0930 20:41:23.501685  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221507 (* 1 = 0.221507 loss)
I0930 20:41:23.501695  4070 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0930 20:41:28.745504  4070 solver.cpp:218] Iteration 33100 (19.0702 iter/s, 5.2438s/100 iters), loss = 0.17665
I0930 20:41:28.745544  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17665 (* 1 = 0.17665 loss)
I0930 20:41:28.745564  4070 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0930 20:41:33.995152  4070 solver.cpp:218] Iteration 33200 (19.0492 iter/s, 5.24956s/100 iters), loss = 0.217697
I0930 20:41:33.995193  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217697 (* 1 = 0.217697 loss)
I0930 20:41:33.995198  4070 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0930 20:41:39.250017  4070 solver.cpp:218] Iteration 33300 (19.0302 iter/s, 5.2548s/100 iters), loss = 0.270217
I0930 20:41:39.250059  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270217 (* 1 = 0.270217 loss)
I0930 20:41:39.250064  4070 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0930 20:41:44.501829  4070 solver.cpp:218] Iteration 33400 (19.0413 iter/s, 5.25175s/100 iters), loss = 0.27648
I0930 20:41:44.501869  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27648 (* 1 = 0.27648 loss)
I0930 20:41:44.501874  4070 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0930 20:41:49.480520  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:41:49.691143  4070 solver.cpp:330] Iteration 33500, Testing net (#0)
I0930 20:41:50.885233  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:41:50.935271  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7938
I0930 20:41:50.935305  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61845 (* 1 = 0.61845 loss)
I0930 20:41:50.987721  4070 solver.cpp:218] Iteration 33500 (15.4182 iter/s, 6.48583s/100 iters), loss = 0.230983
I0930 20:41:50.987747  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230983 (* 1 = 0.230983 loss)
I0930 20:41:50.987754  4070 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0930 20:41:56.238768  4070 solver.cpp:218] Iteration 33600 (19.044 iter/s, 5.251s/100 iters), loss = 0.247464
I0930 20:41:56.238879  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247465 (* 1 = 0.247465 loss)
I0930 20:41:56.238896  4070 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0930 20:42:01.479343  4070 solver.cpp:218] Iteration 33700 (19.0823 iter/s, 5.24044s/100 iters), loss = 0.267697
I0930 20:42:01.479373  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267697 (* 1 = 0.267697 loss)
I0930 20:42:01.479389  4070 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0930 20:42:06.727486  4070 solver.cpp:218] Iteration 33800 (19.0545 iter/s, 5.24809s/100 iters), loss = 0.297166
I0930 20:42:06.727516  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297166 (* 1 = 0.297166 loss)
I0930 20:42:06.727532  4070 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0930 20:42:11.972952  4070 solver.cpp:218] Iteration 33900 (19.0643 iter/s, 5.24542s/100 iters), loss = 0.218011
I0930 20:42:11.972981  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218011 (* 1 = 0.218011 loss)
I0930 20:42:11.972997  4070 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0930 20:42:16.960199  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:42:17.170505  4070 solver.cpp:330] Iteration 34000, Testing net (#0)
I0930 20:42:18.355576  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:42:18.405447  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8388
I0930 20:42:18.405472  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47657 (* 1 = 0.47657 loss)
I0930 20:42:18.458151  4070 solver.cpp:218] Iteration 34000 (15.4198 iter/s, 6.48515s/100 iters), loss = 0.201025
I0930 20:42:18.458176  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201025 (* 1 = 0.201025 loss)
I0930 20:42:18.458184  4070 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0930 20:42:23.705338  4070 solver.cpp:218] Iteration 34100 (19.058 iter/s, 5.24714s/100 iters), loss = 0.172044
I0930 20:42:23.705369  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172044 (* 1 = 0.172044 loss)
I0930 20:42:23.705375  4070 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0930 20:42:28.949592  4070 solver.cpp:218] Iteration 34200 (19.0687 iter/s, 5.2442s/100 iters), loss = 0.292422
I0930 20:42:28.949698  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292422 (* 1 = 0.292422 loss)
I0930 20:42:28.949708  4070 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0930 20:42:34.186494  4070 solver.cpp:218] Iteration 34300 (19.0959 iter/s, 5.23674s/100 iters), loss = 0.2225
I0930 20:42:34.186527  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2225 (* 1 = 0.2225 loss)
I0930 20:42:34.186532  4070 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0930 20:42:39.432351  4070 solver.cpp:218] Iteration 34400 (19.0628 iter/s, 5.24581s/100 iters), loss = 0.243066
I0930 20:42:39.432389  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243066 (* 1 = 0.243066 loss)
I0930 20:42:39.432405  4070 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0930 20:42:44.416872  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:42:44.626693  4070 solver.cpp:330] Iteration 34500, Testing net (#0)
I0930 20:42:45.810200  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:42:45.860121  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8016
I0930 20:42:45.860144  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.58061 (* 1 = 0.58061 loss)
I0930 20:42:45.912762  4070 solver.cpp:218] Iteration 34500 (15.4313 iter/s, 6.48036s/100 iters), loss = 0.243192
I0930 20:42:45.912786  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243192 (* 1 = 0.243192 loss)
I0930 20:42:45.912791  4070 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0930 20:42:51.159441  4070 solver.cpp:218] Iteration 34600 (19.0598 iter/s, 5.24663s/100 iters), loss = 0.286762
I0930 20:42:51.159472  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286762 (* 1 = 0.286762 loss)
I0930 20:42:51.159479  4070 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0930 20:42:56.399013  4070 solver.cpp:218] Iteration 34700 (19.0857 iter/s, 5.23951s/100 iters), loss = 0.224541
I0930 20:42:56.399044  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224542 (* 1 = 0.224542 loss)
I0930 20:42:56.399050  4070 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0930 20:43:01.631063  4070 solver.cpp:218] Iteration 34800 (19.1132 iter/s, 5.232s/100 iters), loss = 0.293128
I0930 20:43:01.631214  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293128 (* 1 = 0.293128 loss)
I0930 20:43:01.631232  4070 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0930 20:43:06.884232  4070 solver.cpp:218] Iteration 34900 (19.0367 iter/s, 5.253s/100 iters), loss = 0.249524
I0930 20:43:06.884263  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249524 (* 1 = 0.249524 loss)
I0930 20:43:06.884268  4070 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0930 20:43:11.866734  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:43:12.076869  4070 solver.cpp:330] Iteration 35000, Testing net (#0)
I0930 20:43:13.261555  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:43:13.311475  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8138
I0930 20:43:13.311501  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.559822 (* 1 = 0.559822 loss)
I0930 20:43:13.363952  4070 solver.cpp:218] Iteration 35000 (15.4329 iter/s, 6.47967s/100 iters), loss = 0.241476
I0930 20:43:13.363981  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241476 (* 1 = 0.241476 loss)
I0930 20:43:13.363991  4070 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0930 20:43:18.616571  4070 solver.cpp:218] Iteration 35100 (19.0383 iter/s, 5.25257s/100 iters), loss = 0.213297
I0930 20:43:18.616603  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213298 (* 1 = 0.213298 loss)
I0930 20:43:18.616611  4070 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0930 20:43:23.868787  4070 solver.cpp:218] Iteration 35200 (19.0398 iter/s, 5.25216s/100 iters), loss = 0.258933
I0930 20:43:23.868818  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258933 (* 1 = 0.258933 loss)
I0930 20:43:23.868835  4070 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0930 20:43:29.120077  4070 solver.cpp:218] Iteration 35300 (19.0431 iter/s, 5.25124s/100 iters), loss = 0.313212
I0930 20:43:29.120107  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313212 (* 1 = 0.313212 loss)
I0930 20:43:29.120113  4070 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0930 20:43:34.362637  4070 solver.cpp:218] Iteration 35400 (19.0748 iter/s, 5.24251s/100 iters), loss = 0.242532
I0930 20:43:34.362751  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242532 (* 1 = 0.242532 loss)
I0930 20:43:34.362768  4070 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0930 20:43:39.346925  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:43:39.557185  4070 solver.cpp:330] Iteration 35500, Testing net (#0)
I0930 20:43:40.744138  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:43:40.794692  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8001
I0930 20:43:40.794718  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.615774 (* 1 = 0.615774 loss)
I0930 20:43:40.848738  4070 solver.cpp:218] Iteration 35500 (15.4179 iter/s, 6.48597s/100 iters), loss = 0.19826
I0930 20:43:40.848784  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19826 (* 1 = 0.19826 loss)
I0930 20:43:40.848793  4070 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0930 20:43:46.086268  4070 solver.cpp:218] Iteration 35600 (19.0933 iter/s, 5.23743s/100 iters), loss = 0.251998
I0930 20:43:46.086309  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251998 (* 1 = 0.251998 loss)
I0930 20:43:46.086315  4070 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0930 20:43:51.333348  4070 solver.cpp:218] Iteration 35700 (19.0584 iter/s, 5.24702s/100 iters), loss = 0.349634
I0930 20:43:51.333375  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349634 (* 1 = 0.349634 loss)
I0930 20:43:51.333381  4070 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0930 20:43:56.580456  4070 solver.cpp:218] Iteration 35800 (19.0583 iter/s, 5.24706s/100 iters), loss = 0.31462
I0930 20:43:56.580484  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314621 (* 1 = 0.314621 loss)
I0930 20:43:56.580489  4070 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0930 20:44:01.822713  4070 solver.cpp:218] Iteration 35900 (19.076 iter/s, 5.2422s/100 iters), loss = 0.176317
I0930 20:44:01.822749  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176317 (* 1 = 0.176317 loss)
I0930 20:44:01.822757  4070 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0930 20:44:06.803094  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:44:07.011443  4070 solver.cpp:330] Iteration 36000, Testing net (#0)
I0930 20:44:08.204059  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:44:08.253794  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8418
I0930 20:44:08.253829  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.471533 (* 1 = 0.471533 loss)
I0930 20:44:08.306581  4070 solver.cpp:218] Iteration 36000 (15.423 iter/s, 6.48381s/100 iters), loss = 0.22629
I0930 20:44:08.306604  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22629 (* 1 = 0.22629 loss)
I0930 20:44:08.306612  4070 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0930 20:44:13.547240  4070 solver.cpp:218] Iteration 36100 (19.0817 iter/s, 5.24061s/100 iters), loss = 0.282825
I0930 20:44:13.547281  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282825 (* 1 = 0.282825 loss)
I0930 20:44:13.547287  4070 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0930 20:44:18.800619  4070 solver.cpp:218] Iteration 36200 (19.0356 iter/s, 5.25332s/100 iters), loss = 0.223992
I0930 20:44:18.800648  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223992 (* 1 = 0.223992 loss)
I0930 20:44:18.800654  4070 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0930 20:44:24.042814  4070 solver.cpp:218] Iteration 36300 (19.0762 iter/s, 5.24214s/100 iters), loss = 0.225014
I0930 20:44:24.042842  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225014 (* 1 = 0.225014 loss)
I0930 20:44:24.042847  4070 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0930 20:44:29.285008  4070 solver.cpp:218] Iteration 36400 (19.0762 iter/s, 5.24215s/100 iters), loss = 0.24629
I0930 20:44:29.285048  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24629 (* 1 = 0.24629 loss)
I0930 20:44:29.285054  4070 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0930 20:44:34.258980  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:44:34.467629  4070 solver.cpp:330] Iteration 36500, Testing net (#0)
I0930 20:44:35.654467  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:44:35.703872  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8261
I0930 20:44:35.703907  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.521549 (* 1 = 0.521549 loss)
I0930 20:44:35.756801  4070 solver.cpp:218] Iteration 36500 (15.4518 iter/s, 6.47174s/100 iters), loss = 0.164239
I0930 20:44:35.756824  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164239 (* 1 = 0.164239 loss)
I0930 20:44:35.756830  4070 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0930 20:44:41.005283  4070 solver.cpp:218] Iteration 36600 (19.0533 iter/s, 5.24843s/100 iters), loss = 0.175546
I0930 20:44:41.005471  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175546 (* 1 = 0.175546 loss)
I0930 20:44:41.005482  4070 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0930 20:44:46.243484  4070 solver.cpp:218] Iteration 36700 (19.0913 iter/s, 5.238s/100 iters), loss = 0.305657
I0930 20:44:46.243525  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305657 (* 1 = 0.305657 loss)
I0930 20:44:46.243531  4070 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0930 20:44:51.493113  4070 solver.cpp:218] Iteration 36800 (19.0492 iter/s, 5.24957s/100 iters), loss = 0.270823
I0930 20:44:51.493142  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270823 (* 1 = 0.270823 loss)
I0930 20:44:51.493149  4070 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0930 20:44:56.742723  4070 solver.cpp:218] Iteration 36900 (19.0492 iter/s, 5.24956s/100 iters), loss = 0.304758
I0930 20:44:56.742753  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304759 (* 1 = 0.304759 loss)
I0930 20:44:56.742759  4070 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0930 20:45:01.721998  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:45:01.939194  4070 solver.cpp:330] Iteration 37000, Testing net (#0)
I0930 20:45:03.124933  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:45:03.174541  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.661
I0930 20:45:03.174576  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.46073 (* 1 = 1.46073 loss)
I0930 20:45:03.227042  4070 solver.cpp:218] Iteration 37000 (15.4219 iter/s, 6.48427s/100 iters), loss = 0.22476
I0930 20:45:03.227073  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22476 (* 1 = 0.22476 loss)
I0930 20:45:03.227082  4070 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0930 20:45:08.473551  4070 solver.cpp:218] Iteration 37100 (19.0605 iter/s, 5.24646s/100 iters), loss = 0.259819
I0930 20:45:08.473582  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259819 (* 1 = 0.259819 loss)
I0930 20:45:08.473598  4070 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0930 20:45:13.706461  4070 solver.cpp:218] Iteration 37200 (19.11 iter/s, 5.23286s/100 iters), loss = 0.300822
I0930 20:45:13.706573  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300822 (* 1 = 0.300822 loss)
I0930 20:45:13.706581  4070 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0930 20:45:18.952153  4070 solver.cpp:218] Iteration 37300 (19.0637 iter/s, 5.24556s/100 iters), loss = 0.277793
I0930 20:45:18.952194  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277793 (* 1 = 0.277793 loss)
I0930 20:45:18.952200  4070 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0930 20:45:24.190284  4070 solver.cpp:218] Iteration 37400 (19.091 iter/s, 5.23807s/100 iters), loss = 0.19537
I0930 20:45:24.190313  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19537 (* 1 = 0.19537 loss)
I0930 20:45:24.190318  4070 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0930 20:45:29.175923  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:45:29.386152  4070 solver.cpp:330] Iteration 37500, Testing net (#0)
I0930 20:45:30.570322  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:45:30.620151  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7403
I0930 20:45:30.620175  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.831361 (* 1 = 0.831361 loss)
I0930 20:45:30.672566  4070 solver.cpp:218] Iteration 37500 (15.4268 iter/s, 6.48223s/100 iters), loss = 0.169391
I0930 20:45:30.672595  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169392 (* 1 = 0.169392 loss)
I0930 20:45:30.672602  4070 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0930 20:45:35.920301  4070 solver.cpp:218] Iteration 37600 (19.056 iter/s, 5.24769s/100 iters), loss = 0.210396
I0930 20:45:35.920333  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210396 (* 1 = 0.210396 loss)
I0930 20:45:35.920351  4070 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0930 20:45:41.164160  4070 solver.cpp:218] Iteration 37700 (19.0701 iter/s, 5.24381s/100 iters), loss = 0.185066
I0930 20:45:41.164193  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185067 (* 1 = 0.185067 loss)
I0930 20:45:41.164212  4070 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0930 20:45:46.400691  4070 solver.cpp:218] Iteration 37800 (19.0968 iter/s, 5.23648s/100 iters), loss = 0.28881
I0930 20:45:46.400893  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28881 (* 1 = 0.28881 loss)
I0930 20:45:46.400914  4070 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0930 20:45:51.646770  4070 solver.cpp:218] Iteration 37900 (19.0626 iter/s, 5.24587s/100 iters), loss = 0.236374
I0930 20:45:51.646811  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236375 (* 1 = 0.236375 loss)
I0930 20:45:51.646816  4070 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0930 20:45:56.623289  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:45:56.833586  4070 solver.cpp:330] Iteration 38000, Testing net (#0)
I0930 20:45:58.017674  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:45:58.067548  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8167
I0930 20:45:58.067580  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.550068 (* 1 = 0.550068 loss)
I0930 20:45:58.120051  4070 solver.cpp:218] Iteration 38000 (15.4483 iter/s, 6.47322s/100 iters), loss = 0.258354
I0930 20:45:58.120075  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258354 (* 1 = 0.258354 loss)
I0930 20:45:58.120082  4070 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0930 20:46:03.367620  4070 solver.cpp:218] Iteration 38100 (19.0566 iter/s, 5.24752s/100 iters), loss = 0.167244
I0930 20:46:03.367660  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167244 (* 1 = 0.167244 loss)
I0930 20:46:03.367666  4070 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0930 20:46:08.615027  4070 solver.cpp:218] Iteration 38200 (19.0572 iter/s, 5.24735s/100 iters), loss = 0.274133
I0930 20:46:08.615067  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274134 (* 1 = 0.274134 loss)
I0930 20:46:08.615072  4070 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0930 20:46:13.857462  4070 solver.cpp:218] Iteration 38300 (19.0753 iter/s, 5.24237s/100 iters), loss = 0.269157
I0930 20:46:13.857508  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269157 (* 1 = 0.269157 loss)
I0930 20:46:13.857516  4070 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0930 20:46:19.104540  4070 solver.cpp:218] Iteration 38400 (19.0585 iter/s, 5.24701s/100 iters), loss = 0.233208
I0930 20:46:19.104614  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233209 (* 1 = 0.233209 loss)
I0930 20:46:19.104621  4070 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0930 20:46:24.092931  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:46:24.302063  4070 solver.cpp:330] Iteration 38500, Testing net (#0)
I0930 20:46:25.486572  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:46:25.536716  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8223
I0930 20:46:25.536751  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.574155 (* 1 = 0.574155 loss)
I0930 20:46:25.589422  4070 solver.cpp:218] Iteration 38500 (15.4207 iter/s, 6.48479s/100 iters), loss = 0.275738
I0930 20:46:25.589452  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275738 (* 1 = 0.275738 loss)
I0930 20:46:25.589459  4070 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0930 20:46:30.838697  4070 solver.cpp:218] Iteration 38600 (19.0504 iter/s, 5.24923s/100 iters), loss = 0.200969
I0930 20:46:30.838737  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20097 (* 1 = 0.20097 loss)
I0930 20:46:30.838743  4070 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0930 20:46:36.087448  4070 solver.cpp:218] Iteration 38700 (19.0524 iter/s, 5.24869s/100 iters), loss = 0.223169
I0930 20:46:36.087488  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223169 (* 1 = 0.223169 loss)
I0930 20:46:36.087494  4070 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0930 20:46:41.336592  4070 solver.cpp:218] Iteration 38800 (19.0509 iter/s, 5.24908s/100 iters), loss = 0.281832
I0930 20:46:41.336621  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281832 (* 1 = 0.281832 loss)
I0930 20:46:41.336627  4070 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0930 20:46:46.571005  4070 solver.cpp:218] Iteration 38900 (19.1045 iter/s, 5.23436s/100 iters), loss = 0.235595
I0930 20:46:46.571035  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235595 (* 1 = 0.235595 loss)
I0930 20:46:46.571041  4070 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0930 20:46:51.552742  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:46:51.762162  4070 solver.cpp:330] Iteration 39000, Testing net (#0)
I0930 20:46:52.951614  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:46:53.001737  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8456
I0930 20:46:53.001763  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.480392 (* 1 = 0.480392 loss)
I0930 20:46:53.054292  4070 solver.cpp:218] Iteration 39000 (15.4244 iter/s, 6.48323s/100 iters), loss = 0.233441
I0930 20:46:53.054327  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233442 (* 1 = 0.233442 loss)
I0930 20:46:53.054333  4070 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0930 20:46:58.286429  4070 solver.cpp:218] Iteration 39100 (19.1129 iter/s, 5.23208s/100 iters), loss = 0.171988
I0930 20:46:58.286476  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171988 (* 1 = 0.171988 loss)
I0930 20:46:58.286484  4070 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0930 20:47:03.529151  4070 solver.cpp:218] Iteration 39200 (19.0743 iter/s, 5.24266s/100 iters), loss = 0.319867
I0930 20:47:03.529181  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319868 (* 1 = 0.319868 loss)
I0930 20:47:03.529186  4070 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0930 20:47:08.775213  4070 solver.cpp:218] Iteration 39300 (19.0621 iter/s, 5.24601s/100 iters), loss = 0.36975
I0930 20:47:08.775249  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36975 (* 1 = 0.36975 loss)
I0930 20:47:08.775259  4070 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0930 20:47:14.022338  4070 solver.cpp:218] Iteration 39400 (19.0583 iter/s, 5.24707s/100 iters), loss = 0.331029
I0930 20:47:14.022374  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331029 (* 1 = 0.331029 loss)
I0930 20:47:14.022383  4070 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0930 20:47:18.997473  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:47:19.207700  4070 solver.cpp:330] Iteration 39500, Testing net (#0)
I0930 20:47:20.403105  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:47:20.453303  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7887
I0930 20:47:20.453330  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.732376 (* 1 = 0.732376 loss)
I0930 20:47:20.505556  4070 solver.cpp:218] Iteration 39500 (15.4246 iter/s, 6.48316s/100 iters), loss = 0.170181
I0930 20:47:20.505586  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170181 (* 1 = 0.170181 loss)
I0930 20:47:20.505595  4070 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0930 20:47:25.746793  4070 solver.cpp:218] Iteration 39600 (19.0797 iter/s, 5.24118s/100 iters), loss = 0.116102
I0930 20:47:25.746961  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116102 (* 1 = 0.116102 loss)
I0930 20:47:25.747000  4070 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0930 20:47:30.987112  4070 solver.cpp:218] Iteration 39700 (19.0835 iter/s, 5.24013s/100 iters), loss = 0.225214
I0930 20:47:30.987146  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225214 (* 1 = 0.225214 loss)
I0930 20:47:30.987164  4070 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0930 20:47:36.229591  4070 solver.cpp:218] Iteration 39800 (19.0751 iter/s, 5.24242s/100 iters), loss = 0.344355
I0930 20:47:36.229624  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344355 (* 1 = 0.344355 loss)
I0930 20:47:36.229632  4070 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0930 20:47:41.471556  4070 solver.cpp:218] Iteration 39900 (19.077 iter/s, 5.24191s/100 iters), loss = 0.191624
I0930 20:47:41.471598  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191624 (* 1 = 0.191624 loss)
I0930 20:47:41.471603  4070 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0930 20:47:46.441205  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:47:46.651701  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_40000.caffemodel
I0930 20:47:46.656595  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_40000.solverstate
I0930 20:47:46.657899  4070 solver.cpp:330] Iteration 40000, Testing net (#0)
I0930 20:47:47.848641  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:47:47.898936  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7835
I0930 20:47:47.898972  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.672361 (* 1 = 0.672361 loss)
I0930 20:47:47.951309  4070 solver.cpp:218] Iteration 40000 (15.4328 iter/s, 6.47969s/100 iters), loss = 0.215404
I0930 20:47:47.951335  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215404 (* 1 = 0.215404 loss)
I0930 20:47:47.951341  4070 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0930 20:47:47.951344  4070 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0930 20:47:53.201243  4070 solver.cpp:218] Iteration 40100 (19.048 iter/s, 5.24989s/100 iters), loss = 0.238428
I0930 20:47:53.201273  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238428 (* 1 = 0.238428 loss)
I0930 20:47:53.201279  4070 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0930 20:47:58.438887  4070 solver.cpp:218] Iteration 40200 (19.0927 iter/s, 5.2376s/100 iters), loss = 0.185285
I0930 20:47:58.439043  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185285 (* 1 = 0.185285 loss)
I0930 20:47:58.439051  4070 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0930 20:48:03.690488  4070 solver.cpp:218] Iteration 40300 (19.0424 iter/s, 5.25144s/100 iters), loss = 0.181618
I0930 20:48:03.690531  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181619 (* 1 = 0.181619 loss)
I0930 20:48:03.690537  4070 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0930 20:48:08.944279  4070 solver.cpp:218] Iteration 40400 (19.0341 iter/s, 5.25373s/100 iters), loss = 0.167123
I0930 20:48:08.944319  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167123 (* 1 = 0.167123 loss)
I0930 20:48:08.944325  4070 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0930 20:48:13.932462  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:48:14.143708  4070 solver.cpp:330] Iteration 40500, Testing net (#0)
I0930 20:48:15.327884  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:48:15.378237  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I0930 20:48:15.378270  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303444 (* 1 = 0.303444 loss)
I0930 20:48:15.430338  4070 solver.cpp:218] Iteration 40500 (15.4178 iter/s, 6.486s/100 iters), loss = 0.115958
I0930 20:48:15.430364  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115958 (* 1 = 0.115958 loss)
I0930 20:48:15.430371  4070 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0930 20:48:20.678007  4070 solver.cpp:218] Iteration 40600 (19.0562 iter/s, 5.24762s/100 iters), loss = 0.192817
I0930 20:48:20.678047  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192817 (* 1 = 0.192817 loss)
I0930 20:48:20.678053  4070 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0930 20:48:25.923132  4070 solver.cpp:218] Iteration 40700 (19.0655 iter/s, 5.24507s/100 iters), loss = 0.136087
I0930 20:48:25.923176  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136087 (* 1 = 0.136087 loss)
I0930 20:48:25.923182  4070 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0930 20:48:31.163344  4070 solver.cpp:218] Iteration 40800 (19.0834 iter/s, 5.24015s/100 iters), loss = 0.13537
I0930 20:48:31.163476  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13537 (* 1 = 0.13537 loss)
I0930 20:48:31.163485  4070 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0930 20:48:36.412441  4070 solver.cpp:218] Iteration 40900 (19.0514 iter/s, 5.24895s/100 iters), loss = 0.0936287
I0930 20:48:36.412480  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0936288 (* 1 = 0.0936288 loss)
I0930 20:48:36.412487  4070 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0930 20:48:41.400693  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:48:41.610441  4070 solver.cpp:330] Iteration 41000, Testing net (#0)
I0930 20:48:42.795465  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:48:42.845542  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.895
I0930 20:48:42.845566  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30398 (* 1 = 0.30398 loss)
I0930 20:48:42.897974  4070 solver.cpp:218] Iteration 41000 (15.4191 iter/s, 6.48548s/100 iters), loss = 0.133856
I0930 20:48:42.897997  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133856 (* 1 = 0.133856 loss)
I0930 20:48:42.898003  4070 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0930 20:48:48.154979  4070 solver.cpp:218] Iteration 41100 (19.0224 iter/s, 5.25696s/100 iters), loss = 0.139575
I0930 20:48:48.155019  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139575 (* 1 = 0.139575 loss)
I0930 20:48:48.155025  4070 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0930 20:48:53.408212  4070 solver.cpp:218] Iteration 41200 (19.0361 iter/s, 5.25318s/100 iters), loss = 0.105286
I0930 20:48:53.408252  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105286 (* 1 = 0.105286 loss)
I0930 20:48:53.408258  4070 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0930 20:48:58.646140  4070 solver.cpp:218] Iteration 41300 (19.0917 iter/s, 5.23787s/100 iters), loss = 0.134422
I0930 20:48:58.646181  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134423 (* 1 = 0.134423 loss)
I0930 20:48:58.646188  4070 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0930 20:49:03.896462  4070 solver.cpp:218] Iteration 41400 (19.0467 iter/s, 5.25026s/100 iters), loss = 0.0741723
I0930 20:49:03.896543  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0741724 (* 1 = 0.0741724 loss)
I0930 20:49:03.896561  4070 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0930 20:49:08.884773  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:49:09.094524  4070 solver.cpp:330] Iteration 41500, Testing net (#0)
I0930 20:49:10.279096  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:49:10.329262  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8953
I0930 20:49:10.329285  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303527 (* 1 = 0.303527 loss)
I0930 20:49:10.381817  4070 solver.cpp:218] Iteration 41500 (15.4196 iter/s, 6.48526s/100 iters), loss = 0.110344
I0930 20:49:10.381844  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110344 (* 1 = 0.110344 loss)
I0930 20:49:10.381852  4070 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0930 20:49:15.630501  4070 solver.cpp:218] Iteration 41600 (19.0526 iter/s, 5.24864s/100 iters), loss = 0.157483
I0930 20:49:15.630537  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157483 (* 1 = 0.157483 loss)
I0930 20:49:15.630555  4070 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0930 20:49:20.877282  4070 solver.cpp:218] Iteration 41700 (19.0595 iter/s, 5.24672s/100 iters), loss = 0.126429
I0930 20:49:20.877315  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126429 (* 1 = 0.126429 loss)
I0930 20:49:20.877332  4070 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0930 20:49:26.124544  4070 solver.cpp:218] Iteration 41800 (19.0577 iter/s, 5.24721s/100 iters), loss = 0.107685
I0930 20:49:26.124578  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107685 (* 1 = 0.107685 loss)
I0930 20:49:26.124596  4070 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0930 20:49:31.369506  4070 solver.cpp:218] Iteration 41900 (19.0661 iter/s, 5.24491s/100 iters), loss = 0.091715
I0930 20:49:31.369537  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0917151 (* 1 = 0.0917151 loss)
I0930 20:49:31.369555  4070 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0930 20:49:36.362342  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:49:36.572691  4070 solver.cpp:330] Iteration 42000, Testing net (#0)
I0930 20:49:37.760154  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:49:37.810885  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8964
I0930 20:49:37.810921  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307645 (* 1 = 0.307645 loss)
I0930 20:49:37.865377  4070 solver.cpp:218] Iteration 42000 (15.3945 iter/s, 6.49581s/100 iters), loss = 0.0721874
I0930 20:49:37.865414  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721874 (* 1 = 0.0721874 loss)
I0930 20:49:37.865422  4070 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0930 20:49:43.103796  4070 solver.cpp:218] Iteration 42100 (19.09 iter/s, 5.23836s/100 iters), loss = 0.13825
I0930 20:49:43.103824  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13825 (* 1 = 0.13825 loss)
I0930 20:49:43.103830  4070 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0930 20:49:48.348698  4070 solver.cpp:218] Iteration 42200 (19.0663 iter/s, 5.24485s/100 iters), loss = 0.138335
I0930 20:49:48.348737  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138335 (* 1 = 0.138335 loss)
I0930 20:49:48.348743  4070 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0930 20:49:53.590970  4070 solver.cpp:218] Iteration 42300 (19.0759 iter/s, 5.24221s/100 iters), loss = 0.133108
I0930 20:49:53.591011  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133108 (* 1 = 0.133108 loss)
I0930 20:49:53.591017  4070 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0930 20:49:58.826794  4070 solver.cpp:218] Iteration 42400 (19.0994 iter/s, 5.23576s/100 iters), loss = 0.100653
I0930 20:49:58.826830  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100653 (* 1 = 0.100653 loss)
I0930 20:49:58.826838  4070 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0930 20:50:03.797775  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:50:04.007243  4070 solver.cpp:330] Iteration 42500, Testing net (#0)
I0930 20:50:05.197489  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:50:05.247460  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9005
I0930 20:50:05.247485  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296377 (* 1 = 0.296377 loss)
I0930 20:50:05.299876  4070 solver.cpp:218] Iteration 42500 (15.4487 iter/s, 6.47303s/100 iters), loss = 0.0314912
I0930 20:50:05.299907  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314913 (* 1 = 0.0314913 loss)
I0930 20:50:05.299914  4070 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0930 20:50:10.537119  4070 solver.cpp:218] Iteration 42600 (19.0942 iter/s, 5.23719s/100 iters), loss = 0.213818
I0930 20:50:10.537245  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213818 (* 1 = 0.213818 loss)
I0930 20:50:10.537251  4070 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0930 20:50:15.781157  4070 solver.cpp:218] Iteration 42700 (19.0698 iter/s, 5.2439s/100 iters), loss = 0.0981906
I0930 20:50:15.781190  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0981906 (* 1 = 0.0981906 loss)
I0930 20:50:15.781208  4070 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0930 20:50:21.027158  4070 solver.cpp:218] Iteration 42800 (19.0623 iter/s, 5.24595s/100 iters), loss = 0.085568
I0930 20:50:21.027187  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0855681 (* 1 = 0.0855681 loss)
I0930 20:50:21.027194  4070 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0930 20:50:26.281533  4070 solver.cpp:218] Iteration 42900 (19.0319 iter/s, 5.25432s/100 iters), loss = 0.125229
I0930 20:50:26.281574  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125229 (* 1 = 0.125229 loss)
I0930 20:50:26.281579  4070 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0930 20:50:31.263070  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:50:31.473249  4070 solver.cpp:330] Iteration 43000, Testing net (#0)
I0930 20:50:32.667301  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:50:32.717053  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9017
I0930 20:50:32.717088  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297744 (* 1 = 0.297744 loss)
I0930 20:50:32.769557  4070 solver.cpp:218] Iteration 43000 (15.4132 iter/s, 6.48796s/100 iters), loss = 0.042874
I0930 20:50:32.769593  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042874 (* 1 = 0.042874 loss)
I0930 20:50:32.769599  4070 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0930 20:50:38.021337  4070 solver.cpp:218] Iteration 43100 (19.0414 iter/s, 5.25172s/100 iters), loss = 0.0980514
I0930 20:50:38.021371  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0980514 (* 1 = 0.0980514 loss)
I0930 20:50:38.021378  4070 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0930 20:50:43.264798  4070 solver.cpp:218] Iteration 43200 (19.0716 iter/s, 5.2434s/100 iters), loss = 0.0839452
I0930 20:50:43.264896  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0839453 (* 1 = 0.0839453 loss)
I0930 20:50:43.264904  4070 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0930 20:50:48.517771  4070 solver.cpp:218] Iteration 43300 (19.0372 iter/s, 5.25286s/100 iters), loss = 0.128948
I0930 20:50:48.517812  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128948 (* 1 = 0.128948 loss)
I0930 20:50:48.517817  4070 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0930 20:50:53.763202  4070 solver.cpp:218] Iteration 43400 (19.0644 iter/s, 5.24537s/100 iters), loss = 0.0550327
I0930 20:50:53.763242  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550327 (* 1 = 0.0550327 loss)
I0930 20:50:53.763247  4070 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0930 20:50:58.742194  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:50:58.956229  4070 solver.cpp:330] Iteration 43500, Testing net (#0)
I0930 20:51:00.142786  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:51:00.193186  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9006
I0930 20:51:00.193219  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298698 (* 1 = 0.298698 loss)
I0930 20:51:00.246271  4070 solver.cpp:218] Iteration 43500 (15.4249 iter/s, 6.48301s/100 iters), loss = 0.10503
I0930 20:51:00.246295  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10503 (* 1 = 0.10503 loss)
I0930 20:51:00.246302  4070 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0930 20:51:05.498327  4070 solver.cpp:218] Iteration 43600 (19.0403 iter/s, 5.25201s/100 iters), loss = 0.0897847
I0930 20:51:05.498368  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0897848 (* 1 = 0.0897848 loss)
I0930 20:51:05.498373  4070 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0930 20:51:10.738663  4070 solver.cpp:218] Iteration 43700 (19.083 iter/s, 5.24027s/100 iters), loss = 0.105796
I0930 20:51:10.738705  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105796 (* 1 = 0.105796 loss)
I0930 20:51:10.738710  4070 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0930 20:51:15.985654  4070 solver.cpp:218] Iteration 43800 (19.0588 iter/s, 5.24693s/100 iters), loss = 0.0728799
I0930 20:51:15.985791  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0728799 (* 1 = 0.0728799 loss)
I0930 20:51:15.985821  4070 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0930 20:51:21.237187  4070 solver.cpp:218] Iteration 43900 (19.0426 iter/s, 5.25138s/100 iters), loss = 0.0980964
I0930 20:51:21.237220  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0980965 (* 1 = 0.0980965 loss)
I0930 20:51:21.237227  4070 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0930 20:51:26.228327  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:51:26.438279  4070 solver.cpp:330] Iteration 44000, Testing net (#0)
I0930 20:51:27.623790  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:51:27.673578  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9026
I0930 20:51:27.673604  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293889 (* 1 = 0.293889 loss)
I0930 20:51:27.726631  4070 solver.cpp:218] Iteration 44000 (15.4098 iter/s, 6.4894s/100 iters), loss = 0.0422471
I0930 20:51:27.726657  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422472 (* 1 = 0.0422472 loss)
I0930 20:51:27.726667  4070 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0930 20:51:32.976155  4070 solver.cpp:218] Iteration 44100 (19.0495 iter/s, 5.24947s/100 iters), loss = 0.0845071
I0930 20:51:32.976189  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0845071 (* 1 = 0.0845071 loss)
I0930 20:51:32.976196  4070 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0930 20:51:38.219544  4070 solver.cpp:218] Iteration 44200 (19.0718 iter/s, 5.24334s/100 iters), loss = 0.061801
I0930 20:51:38.219574  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061801 (* 1 = 0.061801 loss)
I0930 20:51:38.219580  4070 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0930 20:51:43.458406  4070 solver.cpp:218] Iteration 44300 (19.0883 iter/s, 5.23881s/100 iters), loss = 0.0797974
I0930 20:51:43.458446  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0797975 (* 1 = 0.0797975 loss)
I0930 20:51:43.458452  4070 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0930 20:51:48.709158  4070 solver.cpp:218] Iteration 44400 (19.0451 iter/s, 5.25069s/100 iters), loss = 0.0787914
I0930 20:51:48.709264  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0787915 (* 1 = 0.0787915 loss)
I0930 20:51:48.709270  4070 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0930 20:51:53.698122  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:51:53.908541  4070 solver.cpp:330] Iteration 44500, Testing net (#0)
I0930 20:51:55.092285  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:51:55.142030  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8976
I0930 20:51:55.142065  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308337 (* 1 = 0.308337 loss)
I0930 20:51:55.194289  4070 solver.cpp:218] Iteration 44500 (15.4202 iter/s, 6.48501s/100 iters), loss = 0.0598551
I0930 20:51:55.194314  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0598551 (* 1 = 0.0598551 loss)
I0930 20:51:55.194321  4070 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0930 20:52:00.447557  4070 solver.cpp:218] Iteration 44600 (19.0359 iter/s, 5.25322s/100 iters), loss = 0.10995
I0930 20:52:00.447597  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10995 (* 1 = 0.10995 loss)
I0930 20:52:00.447603  4070 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0930 20:52:05.700150  4070 solver.cpp:218] Iteration 44700 (19.0384 iter/s, 5.25253s/100 iters), loss = 0.12274
I0930 20:52:05.700192  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12274 (* 1 = 0.12274 loss)
I0930 20:52:05.700198  4070 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0930 20:52:10.949214  4070 solver.cpp:218] Iteration 44800 (19.0512 iter/s, 5.249s/100 iters), loss = 0.0998294
I0930 20:52:10.949247  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0998294 (* 1 = 0.0998294 loss)
I0930 20:52:10.949254  4070 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0930 20:52:16.189986  4070 solver.cpp:218] Iteration 44900 (19.0814 iter/s, 5.24072s/100 iters), loss = 0.0978446
I0930 20:52:16.190016  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0978447 (* 1 = 0.0978447 loss)
I0930 20:52:16.190021  4070 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0930 20:52:21.174262  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:52:21.384377  4070 solver.cpp:330] Iteration 45000, Testing net (#0)
I0930 20:52:22.571772  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:52:22.622009  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9006
I0930 20:52:22.622042  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302211 (* 1 = 0.302211 loss)
I0930 20:52:22.674538  4070 solver.cpp:218] Iteration 45000 (15.4214 iter/s, 6.4845s/100 iters), loss = 0.0804027
I0930 20:52:22.674563  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0804028 (* 1 = 0.0804028 loss)
I0930 20:52:22.674569  4070 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0930 20:52:27.920047  4070 solver.cpp:218] Iteration 45100 (19.0641 iter/s, 5.24546s/100 iters), loss = 0.0850949
I0930 20:52:27.920087  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.085095 (* 1 = 0.085095 loss)
I0930 20:52:27.920094  4070 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0930 20:52:33.162542  4070 solver.cpp:218] Iteration 45200 (19.0751 iter/s, 5.24243s/100 iters), loss = 0.0639597
I0930 20:52:33.162573  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0639597 (* 1 = 0.0639597 loss)
I0930 20:52:33.162580  4070 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0930 20:52:38.410410  4070 solver.cpp:218] Iteration 45300 (19.0556 iter/s, 5.24781s/100 iters), loss = 0.0670542
I0930 20:52:38.410449  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0670543 (* 1 = 0.0670543 loss)
I0930 20:52:38.410455  4070 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0930 20:52:43.648962  4070 solver.cpp:218] Iteration 45400 (19.0895 iter/s, 5.23849s/100 iters), loss = 0.0914285
I0930 20:52:43.649003  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914285 (* 1 = 0.0914285 loss)
I0930 20:52:43.649009  4070 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0930 20:52:48.635000  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:52:48.844503  4070 solver.cpp:330] Iteration 45500, Testing net (#0)
I0930 20:52:50.038784  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:52:50.088804  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I0930 20:52:50.088838  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320393 (* 1 = 0.320393 loss)
I0930 20:52:50.141252  4070 solver.cpp:218] Iteration 45500 (15.403 iter/s, 6.49223s/100 iters), loss = 0.0409952
I0930 20:52:50.141281  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409953 (* 1 = 0.0409953 loss)
I0930 20:52:50.141288  4070 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0930 20:52:55.383378  4070 solver.cpp:218] Iteration 45600 (19.0764 iter/s, 5.24208s/100 iters), loss = 0.125216
I0930 20:52:55.383520  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125216 (* 1 = 0.125216 loss)
I0930 20:52:55.383528  4070 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0930 20:53:00.633108  4070 solver.cpp:218] Iteration 45700 (19.0492 iter/s, 5.24957s/100 iters), loss = 0.0471178
I0930 20:53:00.633136  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0471179 (* 1 = 0.0471179 loss)
I0930 20:53:00.633141  4070 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0930 20:53:05.883339  4070 solver.cpp:218] Iteration 45800 (19.047 iter/s, 5.25018s/100 iters), loss = 0.107031
I0930 20:53:05.883368  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107031 (* 1 = 0.107031 loss)
I0930 20:53:05.883384  4070 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0930 20:53:11.123579  4070 solver.cpp:218] Iteration 45900 (19.0833 iter/s, 5.24019s/100 iters), loss = 0.0519766
I0930 20:53:11.123608  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519766 (* 1 = 0.0519766 loss)
I0930 20:53:11.123615  4070 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0930 20:53:16.098253  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:53:16.307771  4070 solver.cpp:330] Iteration 46000, Testing net (#0)
I0930 20:53:17.501703  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:53:17.551729  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I0930 20:53:17.551755  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301015 (* 1 = 0.301015 loss)
I0930 20:53:17.604070  4070 solver.cpp:218] Iteration 46000 (15.4311 iter/s, 6.48044s/100 iters), loss = 0.0626273
I0930 20:53:17.604102  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0626274 (* 1 = 0.0626274 loss)
I0930 20:53:17.604109  4070 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0930 20:53:22.843225  4070 solver.cpp:218] Iteration 46100 (19.0873 iter/s, 5.23909s/100 iters), loss = 0.0621635
I0930 20:53:22.843258  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0621635 (* 1 = 0.0621635 loss)
I0930 20:53:22.843266  4070 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0930 20:53:28.084457  4070 solver.cpp:218] Iteration 46200 (19.0797 iter/s, 5.24118s/100 iters), loss = 0.0831107
I0930 20:53:28.084604  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0831107 (* 1 = 0.0831107 loss)
I0930 20:53:28.084617  4070 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0930 20:53:33.334872  4070 solver.cpp:218] Iteration 46300 (19.0467 iter/s, 5.25026s/100 iters), loss = 0.103174
I0930 20:53:33.334913  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103174 (* 1 = 0.103174 loss)
I0930 20:53:33.334919  4070 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0930 20:53:38.591950  4070 solver.cpp:218] Iteration 46400 (19.0222 iter/s, 5.25702s/100 iters), loss = 0.0584294
I0930 20:53:38.591991  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0584294 (* 1 = 0.0584294 loss)
I0930 20:53:38.591997  4070 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0930 20:53:43.573104  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:53:43.784570  4070 solver.cpp:330] Iteration 46500, Testing net (#0)
I0930 20:53:44.975230  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:53:45.024756  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.895
I0930 20:53:45.024791  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328483 (* 1 = 0.328483 loss)
I0930 20:53:45.077208  4070 solver.cpp:218] Iteration 46500 (15.4197 iter/s, 6.4852s/100 iters), loss = 0.0302474
I0930 20:53:45.077234  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302473 (* 1 = 0.0302473 loss)
I0930 20:53:45.077240  4070 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0930 20:53:50.328234  4070 solver.cpp:218] Iteration 46600 (19.0441 iter/s, 5.25098s/100 iters), loss = 0.0648413
I0930 20:53:50.328275  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0648413 (* 1 = 0.0648413 loss)
I0930 20:53:50.328281  4070 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0930 20:53:55.563338  4070 solver.cpp:218] Iteration 46700 (19.102 iter/s, 5.23504s/100 iters), loss = 0.0927343
I0930 20:53:55.563369  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0927343 (* 1 = 0.0927343 loss)
I0930 20:53:55.563374  4070 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0930 20:54:00.802619  4070 solver.cpp:218] Iteration 46800 (19.0868 iter/s, 5.23923s/100 iters), loss = 0.0496284
I0930 20:54:00.802804  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496283 (* 1 = 0.0496283 loss)
I0930 20:54:00.802812  4070 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0930 20:54:06.049484  4070 solver.cpp:218] Iteration 46900 (19.0597 iter/s, 5.24666s/100 iters), loss = 0.0857686
I0930 20:54:06.049513  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0857686 (* 1 = 0.0857686 loss)
I0930 20:54:06.049518  4070 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0930 20:54:11.025954  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:54:11.236385  4070 solver.cpp:330] Iteration 47000, Testing net (#0)
I0930 20:54:12.422616  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:54:12.472709  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9001
I0930 20:54:12.472735  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310446 (* 1 = 0.310446 loss)
I0930 20:54:12.525688  4070 solver.cpp:218] Iteration 47000 (15.4413 iter/s, 6.47616s/100 iters), loss = 0.0824844
I0930 20:54:12.525715  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0824844 (* 1 = 0.0824844 loss)
I0930 20:54:12.525723  4070 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0930 20:54:17.775774  4070 solver.cpp:218] Iteration 47100 (19.0475 iter/s, 5.25004s/100 iters), loss = 0.0880109
I0930 20:54:17.775806  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0880109 (* 1 = 0.0880109 loss)
I0930 20:54:17.775815  4070 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0930 20:54:23.022254  4070 solver.cpp:218] Iteration 47200 (19.0606 iter/s, 5.24643s/100 iters), loss = 0.0451414
I0930 20:54:23.022291  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451415 (* 1 = 0.0451415 loss)
I0930 20:54:23.022300  4070 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0930 20:54:28.261868  4070 solver.cpp:218] Iteration 47300 (19.0856 iter/s, 5.23956s/100 iters), loss = 0.0558399
I0930 20:54:28.261898  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558399 (* 1 = 0.0558399 loss)
I0930 20:54:28.261904  4070 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0930 20:54:33.509774  4070 solver.cpp:218] Iteration 47400 (19.0554 iter/s, 5.24786s/100 iters), loss = 0.0504056
I0930 20:54:33.509894  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504056 (* 1 = 0.0504056 loss)
I0930 20:54:33.509912  4070 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0930 20:54:38.497879  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:54:38.708575  4070 solver.cpp:330] Iteration 47500, Testing net (#0)
I0930 20:54:39.893597  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:54:39.943689  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8967
I0930 20:54:39.943714  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32221 (* 1 = 0.32221 loss)
I0930 20:54:39.995826  4070 solver.cpp:218] Iteration 47500 (15.418 iter/s, 6.48592s/100 iters), loss = 0.0349729
I0930 20:54:39.995854  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349729 (* 1 = 0.0349729 loss)
I0930 20:54:39.995862  4070 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0930 20:54:45.241082  4070 solver.cpp:218] Iteration 47600 (19.065 iter/s, 5.24521s/100 iters), loss = 0.0816636
I0930 20:54:45.241123  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816636 (* 1 = 0.0816636 loss)
I0930 20:54:45.241129  4070 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0930 20:54:50.489341  4070 solver.cpp:218] Iteration 47700 (19.0542 iter/s, 5.2482s/100 iters), loss = 0.0508591
I0930 20:54:50.489375  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508591 (* 1 = 0.0508591 loss)
I0930 20:54:50.489392  4070 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0930 20:54:55.731576  4070 solver.cpp:218] Iteration 47800 (19.076 iter/s, 5.24219s/100 iters), loss = 0.116978
I0930 20:54:55.731606  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116978 (* 1 = 0.116978 loss)
I0930 20:54:55.731611  4070 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0930 20:55:00.976377  4070 solver.cpp:218] Iteration 47900 (19.0667 iter/s, 5.24475s/100 iters), loss = 0.0780481
I0930 20:55:00.976418  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0780481 (* 1 = 0.0780481 loss)
I0930 20:55:00.976424  4070 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0930 20:55:05.961045  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:55:06.171628  4070 solver.cpp:330] Iteration 48000, Testing net (#0)
I0930 20:55:07.357147  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:55:07.407311  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I0930 20:55:07.407346  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338996 (* 1 = 0.338996 loss)
I0930 20:55:07.459471  4070 solver.cpp:218] Iteration 48000 (15.4249 iter/s, 6.48303s/100 iters), loss = 0.0515033
I0930 20:55:07.459499  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515033 (* 1 = 0.0515033 loss)
I0930 20:55:07.459506  4070 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0930 20:55:12.712430  4070 solver.cpp:218] Iteration 48100 (19.0371 iter/s, 5.25291s/100 iters), loss = 0.0650646
I0930 20:55:12.712460  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650645 (* 1 = 0.0650645 loss)
I0930 20:55:12.712466  4070 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0930 20:55:17.958806  4070 solver.cpp:218] Iteration 48200 (19.061 iter/s, 5.24633s/100 iters), loss = 0.0871639
I0930 20:55:17.958834  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0871638 (* 1 = 0.0871638 loss)
I0930 20:55:17.958840  4070 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0930 20:55:23.204958  4070 solver.cpp:218] Iteration 48300 (19.0618 iter/s, 5.2461s/100 iters), loss = 0.0989357
I0930 20:55:23.204989  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0989356 (* 1 = 0.0989356 loss)
I0930 20:55:23.204996  4070 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0930 20:55:28.446755  4070 solver.cpp:218] Iteration 48400 (19.0776 iter/s, 5.24175s/100 iters), loss = 0.0295805
I0930 20:55:28.446796  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295804 (* 1 = 0.0295804 loss)
I0930 20:55:28.446802  4070 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0930 20:55:33.430233  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:55:33.640457  4070 solver.cpp:330] Iteration 48500, Testing net (#0)
I0930 20:55:34.827579  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:55:34.879271  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8997
I0930 20:55:34.879307  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328929 (* 1 = 0.328929 loss)
I0930 20:55:34.932708  4070 solver.cpp:218] Iteration 48500 (15.4181 iter/s, 6.48589s/100 iters), loss = 0.0694999
I0930 20:55:34.932752  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0694999 (* 1 = 0.0694999 loss)
I0930 20:55:34.932760  4070 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0930 20:55:40.174147  4070 solver.cpp:218] Iteration 48600 (19.0791 iter/s, 5.24133s/100 iters), loss = 0.035429
I0930 20:55:40.174263  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035429 (* 1 = 0.035429 loss)
I0930 20:55:40.174280  4070 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0930 20:55:45.417774  4070 solver.cpp:218] Iteration 48700 (19.0712 iter/s, 5.2435s/100 iters), loss = 0.0737596
I0930 20:55:45.417807  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0737596 (* 1 = 0.0737596 loss)
I0930 20:55:45.417814  4070 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0930 20:55:50.663802  4070 solver.cpp:218] Iteration 48800 (19.0622 iter/s, 5.24598s/100 iters), loss = 0.0785811
I0930 20:55:50.663831  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0785811 (* 1 = 0.0785811 loss)
I0930 20:55:50.663836  4070 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0930 20:55:55.909798  4070 solver.cpp:218] Iteration 48900 (19.0624 iter/s, 5.24594s/100 iters), loss = 0.0196652
I0930 20:55:55.909834  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196652 (* 1 = 0.0196652 loss)
I0930 20:55:55.909842  4070 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0930 20:56:00.891616  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:56:01.101752  4070 solver.cpp:330] Iteration 49000, Testing net (#0)
I0930 20:56:02.295714  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:56:02.345968  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9008
I0930 20:56:02.345990  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312145 (* 1 = 0.312145 loss)
I0930 20:56:02.399314  4070 solver.cpp:218] Iteration 49000 (15.4096 iter/s, 6.48946s/100 iters), loss = 0.0401701
I0930 20:56:02.399341  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04017 (* 1 = 0.04017 loss)
I0930 20:56:02.399348  4070 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0930 20:56:07.636405  4070 solver.cpp:218] Iteration 49100 (19.0947 iter/s, 5.23704s/100 iters), loss = 0.0313368
I0930 20:56:07.636446  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313368 (* 1 = 0.0313368 loss)
I0930 20:56:07.636452  4070 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0930 20:56:12.887848  4070 solver.cpp:218] Iteration 49200 (19.0426 iter/s, 5.25138s/100 iters), loss = 0.0570854
I0930 20:56:12.887981  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0570853 (* 1 = 0.0570853 loss)
I0930 20:56:12.888000  4070 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0930 20:56:18.138520  4070 solver.cpp:218] Iteration 49300 (19.0457 iter/s, 5.25053s/100 iters), loss = 0.0531152
I0930 20:56:18.138551  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0531152 (* 1 = 0.0531152 loss)
I0930 20:56:18.138557  4070 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0930 20:56:23.386317  4070 solver.cpp:218] Iteration 49400 (19.0558 iter/s, 5.24774s/100 iters), loss = 0.028755
I0930 20:56:23.386358  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028755 (* 1 = 0.028755 loss)
I0930 20:56:23.386364  4070 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0930 20:56:28.362939  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:56:28.572824  4070 solver.cpp:330] Iteration 49500, Testing net (#0)
I0930 20:56:29.765707  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:56:29.815609  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9003
I0930 20:56:29.815635  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317997 (* 1 = 0.317997 loss)
I0930 20:56:29.868047  4070 solver.cpp:218] Iteration 49500 (15.4281 iter/s, 6.48167s/100 iters), loss = 0.0403531
I0930 20:56:29.868073  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403531 (* 1 = 0.0403531 loss)
I0930 20:56:29.868083  4070 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0930 20:56:35.110348  4070 solver.cpp:218] Iteration 49600 (19.0758 iter/s, 5.24225s/100 iters), loss = 0.0704811
I0930 20:56:35.110381  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0704811 (* 1 = 0.0704811 loss)
I0930 20:56:35.110391  4070 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0930 20:56:40.348479  4070 solver.cpp:218] Iteration 49700 (19.091 iter/s, 5.23808s/100 iters), loss = 0.0799831
I0930 20:56:40.348511  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0799832 (* 1 = 0.0799832 loss)
I0930 20:56:40.348520  4070 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0930 20:56:45.600318  4070 solver.cpp:218] Iteration 49800 (19.0411 iter/s, 5.25179s/100 iters), loss = 0.101894
I0930 20:56:45.600487  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101894 (* 1 = 0.101894 loss)
I0930 20:56:45.600510  4070 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0930 20:56:50.854450  4070 solver.cpp:218] Iteration 49900 (19.0333 iter/s, 5.25396s/100 iters), loss = 0.0897836
I0930 20:56:50.854481  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0897837 (* 1 = 0.0897837 loss)
I0930 20:56:50.854497  4070 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0930 20:56:55.831323  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:56:56.047075  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_50000.caffemodel
I0930 20:56:56.052388  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_50000.solverstate
I0930 20:56:56.053781  4070 solver.cpp:330] Iteration 50000, Testing net (#0)
I0930 20:56:57.240603  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:56:57.290880  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9006
I0930 20:56:57.290906  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318696 (* 1 = 0.318696 loss)
I0930 20:56:57.343471  4070 solver.cpp:218] Iteration 50000 (15.4108 iter/s, 6.48897s/100 iters), loss = 0.0434884
I0930 20:56:57.343497  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434885 (* 1 = 0.0434885 loss)
I0930 20:56:57.343506  4070 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0930 20:57:02.595911  4070 solver.cpp:218] Iteration 50100 (19.0389 iter/s, 5.2524s/100 iters), loss = 0.0997313
I0930 20:57:02.595944  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0997314 (* 1 = 0.0997314 loss)
I0930 20:57:02.595963  4070 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0930 20:57:07.838562  4070 solver.cpp:218] Iteration 50200 (19.0745 iter/s, 5.2426s/100 iters), loss = 0.0317821
I0930 20:57:07.838598  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317821 (* 1 = 0.0317821 loss)
I0930 20:57:07.838608  4070 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0930 20:57:13.081475  4070 solver.cpp:218] Iteration 50300 (19.0736 iter/s, 5.24286s/100 iters), loss = 0.0757134
I0930 20:57:13.081506  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0757134 (* 1 = 0.0757134 loss)
I0930 20:57:13.081514  4070 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0930 20:57:18.328817  4070 solver.cpp:218] Iteration 50400 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.0599563
I0930 20:57:18.328922  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0599563 (* 1 = 0.0599563 loss)
I0930 20:57:18.328936  4070 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0930 20:57:23.308861  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:57:23.517983  4070 solver.cpp:330] Iteration 50500, Testing net (#0)
I0930 20:57:24.701730  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:57:24.751530  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8978
I0930 20:57:24.751564  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330892 (* 1 = 0.330892 loss)
I0930 20:57:24.804021  4070 solver.cpp:218] Iteration 50500 (15.4438 iter/s, 6.47509s/100 iters), loss = 0.0404494
I0930 20:57:24.804047  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404494 (* 1 = 0.0404494 loss)
I0930 20:57:24.804054  4070 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0930 20:57:30.052829  4070 solver.cpp:218] Iteration 50600 (19.0521 iter/s, 5.24876s/100 iters), loss = 0.0769463
I0930 20:57:30.052858  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0769463 (* 1 = 0.0769463 loss)
I0930 20:57:30.052875  4070 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0930 20:57:35.304597  4070 solver.cpp:218] Iteration 50700 (19.0414 iter/s, 5.25172s/100 iters), loss = 0.0536581
I0930 20:57:35.304627  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536582 (* 1 = 0.0536582 loss)
I0930 20:57:35.304633  4070 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0930 20:57:40.541955  4070 solver.cpp:218] Iteration 50800 (19.0938 iter/s, 5.23731s/100 iters), loss = 0.0816285
I0930 20:57:40.541995  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816285 (* 1 = 0.0816285 loss)
I0930 20:57:40.542001  4070 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0930 20:57:45.786156  4070 solver.cpp:218] Iteration 50900 (19.0689 iter/s, 5.24414s/100 iters), loss = 0.0859333
I0930 20:57:45.786196  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0859334 (* 1 = 0.0859334 loss)
I0930 20:57:45.786202  4070 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0930 20:57:50.774705  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:57:50.985018  4070 solver.cpp:330] Iteration 51000, Testing net (#0)
I0930 20:57:52.168751  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:57:52.218813  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8926
I0930 20:57:52.218847  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352428 (* 1 = 0.352428 loss)
I0930 20:57:52.271598  4070 solver.cpp:218] Iteration 51000 (15.4193 iter/s, 6.48538s/100 iters), loss = 0.0365076
I0930 20:57:52.271623  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365076 (* 1 = 0.0365076 loss)
I0930 20:57:52.271631  4070 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0930 20:57:57.498708  4070 solver.cpp:218] Iteration 51100 (19.1312 iter/s, 5.22707s/100 iters), loss = 0.0350644
I0930 20:57:57.498738  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350645 (* 1 = 0.0350645 loss)
I0930 20:57:57.498744  4070 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0930 20:58:02.742214  4070 solver.cpp:218] Iteration 51200 (19.0714 iter/s, 5.24346s/100 iters), loss = 0.0556243
I0930 20:58:02.742246  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556243 (* 1 = 0.0556243 loss)
I0930 20:58:02.742264  4070 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0930 20:58:07.981344  4070 solver.cpp:218] Iteration 51300 (19.0873 iter/s, 5.23908s/100 iters), loss = 0.0356251
I0930 20:58:07.981382  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356252 (* 1 = 0.0356252 loss)
I0930 20:58:07.981391  4070 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0930 20:58:13.215147  4070 solver.cpp:218] Iteration 51400 (19.1068 iter/s, 5.23375s/100 iters), loss = 0.0669009
I0930 20:58:13.215184  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.066901 (* 1 = 0.066901 loss)
I0930 20:58:13.215203  4070 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0930 20:58:18.204071  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:58:18.414336  4070 solver.cpp:330] Iteration 51500, Testing net (#0)
I0930 20:58:19.598624  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:58:19.648927  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8993
I0930 20:58:19.648952  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326615 (* 1 = 0.326615 loss)
I0930 20:58:19.701612  4070 solver.cpp:218] Iteration 51500 (15.4169 iter/s, 6.48641s/100 iters), loss = 0.0307226
I0930 20:58:19.701639  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307227 (* 1 = 0.0307227 loss)
I0930 20:58:19.701659  4070 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0930 20:58:24.951287  4070 solver.cpp:218] Iteration 51600 (19.049 iter/s, 5.24963s/100 iters), loss = 0.0902138
I0930 20:58:24.951390  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0902139 (* 1 = 0.0902139 loss)
I0930 20:58:24.951416  4070 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0930 20:58:30.202472  4070 solver.cpp:218] Iteration 51700 (19.0438 iter/s, 5.25106s/100 iters), loss = 0.0243605
I0930 20:58:30.202503  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243606 (* 1 = 0.0243606 loss)
I0930 20:58:30.202512  4070 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0930 20:58:35.451947  4070 solver.cpp:218] Iteration 51800 (19.0497 iter/s, 5.24942s/100 iters), loss = 0.115065
I0930 20:58:35.451980  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115065 (* 1 = 0.115065 loss)
I0930 20:58:35.451989  4070 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0930 20:58:40.690282  4070 solver.cpp:218] Iteration 51900 (19.0902 iter/s, 5.23828s/100 iters), loss = 0.0330262
I0930 20:58:40.690315  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330263 (* 1 = 0.0330263 loss)
I0930 20:58:40.690322  4070 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0930 20:58:45.669631  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:58:45.878391  4070 solver.cpp:330] Iteration 52000, Testing net (#0)
I0930 20:58:47.069109  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:58:47.118770  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9021
I0930 20:58:47.118798  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318245 (* 1 = 0.318245 loss)
I0930 20:58:47.171479  4070 solver.cpp:218] Iteration 52000 (15.4294 iter/s, 6.48114s/100 iters), loss = 0.0371943
I0930 20:58:47.171514  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371943 (* 1 = 0.0371943 loss)
I0930 20:58:47.171524  4070 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0930 20:58:52.407651  4070 solver.cpp:218] Iteration 52100 (19.0981 iter/s, 5.23611s/100 iters), loss = 0.0444336
I0930 20:58:52.407685  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444337 (* 1 = 0.0444337 loss)
I0930 20:58:52.407702  4070 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0930 20:58:57.647197  4070 solver.cpp:218] Iteration 52200 (19.0858 iter/s, 5.23949s/100 iters), loss = 0.0536727
I0930 20:58:57.647346  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536728 (* 1 = 0.0536728 loss)
I0930 20:58:57.647395  4070 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0930 20:59:02.894783  4070 solver.cpp:218] Iteration 52300 (19.057 iter/s, 5.24742s/100 iters), loss = 0.0947085
I0930 20:59:02.894815  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0947085 (* 1 = 0.0947085 loss)
I0930 20:59:02.894824  4070 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0930 20:59:08.142132  4070 solver.cpp:218] Iteration 52400 (19.0574 iter/s, 5.2473s/100 iters), loss = 0.0899339
I0930 20:59:08.142165  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.089934 (* 1 = 0.089934 loss)
I0930 20:59:08.142184  4070 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0930 20:59:13.115646  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:59:13.324906  4070 solver.cpp:330] Iteration 52500, Testing net (#0)
I0930 20:59:14.518980  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:59:14.568948  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8981
I0930 20:59:14.568974  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345677 (* 1 = 0.345677 loss)
I0930 20:59:14.621598  4070 solver.cpp:218] Iteration 52500 (15.4335 iter/s, 6.47942s/100 iters), loss = 0.0221906
I0930 20:59:14.621625  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221907 (* 1 = 0.0221907 loss)
I0930 20:59:14.621635  4070 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0930 20:59:19.864015  4070 solver.cpp:218] Iteration 52600 (19.0753 iter/s, 5.24237s/100 iters), loss = 0.0236383
I0930 20:59:19.864053  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236384 (* 1 = 0.0236384 loss)
I0930 20:59:19.864070  4070 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0930 20:59:25.110610  4070 solver.cpp:218] Iteration 52700 (19.0603 iter/s, 5.2465s/100 iters), loss = 0.0612076
I0930 20:59:25.110638  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0612076 (* 1 = 0.0612076 loss)
I0930 20:59:25.110643  4070 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0930 20:59:30.360818  4070 solver.cpp:218] Iteration 52800 (19.047 iter/s, 5.25016s/100 iters), loss = 0.0330571
I0930 20:59:30.360944  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330572 (* 1 = 0.0330572 loss)
I0930 20:59:30.360952  4070 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0930 20:59:35.605644  4070 solver.cpp:218] Iteration 52900 (19.0669 iter/s, 5.24468s/100 iters), loss = 0.0398209
I0930 20:59:35.605684  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398209 (* 1 = 0.0398209 loss)
I0930 20:59:35.605690  4070 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0930 20:59:40.581629  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:59:40.790906  4070 solver.cpp:330] Iteration 53000, Testing net (#0)
I0930 20:59:41.981869  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 20:59:42.031985  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8933
I0930 20:59:42.032011  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360461 (* 1 = 0.360461 loss)
I0930 20:59:42.084312  4070 solver.cpp:218] Iteration 53000 (15.4354 iter/s, 6.47861s/100 iters), loss = 0.036155
I0930 20:59:42.084337  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036155 (* 1 = 0.036155 loss)
I0930 20:59:42.084344  4070 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0930 20:59:47.330320  4070 solver.cpp:218] Iteration 53100 (19.0623 iter/s, 5.24596s/100 iters), loss = 0.0931688
I0930 20:59:47.330361  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0931689 (* 1 = 0.0931689 loss)
I0930 20:59:47.330368  4070 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0930 20:59:52.565739  4070 solver.cpp:218] Iteration 53200 (19.1009 iter/s, 5.23536s/100 iters), loss = 0.0578196
I0930 20:59:52.565768  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0578197 (* 1 = 0.0578197 loss)
I0930 20:59:52.565774  4070 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0930 20:59:57.817078  4070 solver.cpp:218] Iteration 53300 (19.0429 iter/s, 5.25129s/100 iters), loss = 0.0507072
I0930 20:59:57.817117  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0507073 (* 1 = 0.0507073 loss)
I0930 20:59:57.817123  4070 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0930 21:00:03.071494  4070 solver.cpp:218] Iteration 53400 (19.0318 iter/s, 5.25436s/100 iters), loss = 0.0175741
I0930 21:00:03.071602  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175742 (* 1 = 0.0175742 loss)
I0930 21:00:03.071617  4070 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0930 21:00:08.060705  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:00:08.270975  4070 solver.cpp:330] Iteration 53500, Testing net (#0)
I0930 21:00:09.455480  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:00:09.505240  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.895
I0930 21:00:09.505266  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355843 (* 1 = 0.355843 loss)
I0930 21:00:09.557920  4070 solver.cpp:218] Iteration 53500 (15.4171 iter/s, 6.48631s/100 iters), loss = 0.0490755
I0930 21:00:09.557948  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0490756 (* 1 = 0.0490756 loss)
I0930 21:00:09.557958  4070 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0930 21:00:14.809146  4070 solver.cpp:218] Iteration 53600 (19.0433 iter/s, 5.25118s/100 iters), loss = 0.0390663
I0930 21:00:14.809180  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390664 (* 1 = 0.0390664 loss)
I0930 21:00:14.809197  4070 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0930 21:00:20.054759  4070 solver.cpp:218] Iteration 53700 (19.0638 iter/s, 5.24555s/100 iters), loss = 0.0449856
I0930 21:00:20.054793  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449857 (* 1 = 0.0449857 loss)
I0930 21:00:20.054802  4070 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0930 21:00:25.289940  4070 solver.cpp:218] Iteration 53800 (19.1017 iter/s, 5.23513s/100 iters), loss = 0.0327247
I0930 21:00:25.289974  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327248 (* 1 = 0.0327248 loss)
I0930 21:00:25.289993  4070 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0930 21:00:30.536358  4070 solver.cpp:218] Iteration 53900 (19.0608 iter/s, 5.24637s/100 iters), loss = 0.0356237
I0930 21:00:30.536392  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356238 (* 1 = 0.0356238 loss)
I0930 21:00:30.536411  4070 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0930 21:00:35.522178  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:00:35.732340  4070 solver.cpp:330] Iteration 54000, Testing net (#0)
I0930 21:00:36.915697  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:00:36.965572  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I0930 21:00:36.965598  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322943 (* 1 = 0.322943 loss)
I0930 21:00:37.018282  4070 solver.cpp:218] Iteration 54000 (15.4276 iter/s, 6.48187s/100 iters), loss = 0.056798
I0930 21:00:37.018309  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056798 (* 1 = 0.056798 loss)
I0930 21:00:37.018318  4070 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0930 21:00:42.265863  4070 solver.cpp:218] Iteration 54100 (19.0566 iter/s, 5.24753s/100 iters), loss = 0.0278988
I0930 21:00:42.265894  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278988 (* 1 = 0.0278988 loss)
I0930 21:00:42.265902  4070 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0930 21:00:47.510669  4070 solver.cpp:218] Iteration 54200 (19.0667 iter/s, 5.24475s/100 iters), loss = 0.032877
I0930 21:00:47.510704  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032877 (* 1 = 0.032877 loss)
I0930 21:00:47.510711  4070 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0930 21:00:52.755825  4070 solver.cpp:218] Iteration 54300 (19.0654 iter/s, 5.2451s/100 iters), loss = 0.0398242
I0930 21:00:52.755864  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398242 (* 1 = 0.0398242 loss)
I0930 21:00:52.755870  4070 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0930 21:00:58.007688  4070 solver.cpp:218] Iteration 54400 (19.0411 iter/s, 5.2518s/100 iters), loss = 0.0954857
I0930 21:00:58.007727  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0954858 (* 1 = 0.0954858 loss)
I0930 21:00:58.007735  4070 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0930 21:01:02.994570  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:01:03.204934  4070 solver.cpp:330] Iteration 54500, Testing net (#0)
I0930 21:01:04.391296  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:01:04.441503  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.899
I0930 21:01:04.441535  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339827 (* 1 = 0.339827 loss)
I0930 21:01:04.493790  4070 solver.cpp:218] Iteration 54500 (15.4177 iter/s, 6.48604s/100 iters), loss = 0.0555534
I0930 21:01:04.493818  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0555534 (* 1 = 0.0555534 loss)
I0930 21:01:04.493824  4070 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0930 21:01:09.741091  4070 solver.cpp:218] Iteration 54600 (19.0576 iter/s, 5.24725s/100 iters), loss = 0.139609
I0930 21:01:09.741232  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139609 (* 1 = 0.139609 loss)
I0930 21:01:09.741240  4070 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0930 21:01:14.983057  4070 solver.cpp:218] Iteration 54700 (19.0774 iter/s, 5.24182s/100 iters), loss = 0.0549759
I0930 21:01:14.983098  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054976 (* 1 = 0.054976 loss)
I0930 21:01:14.983103  4070 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0930 21:01:20.230936  4070 solver.cpp:218] Iteration 54800 (19.0555 iter/s, 5.24782s/100 iters), loss = 0.0686494
I0930 21:01:20.230969  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686494 (* 1 = 0.0686494 loss)
I0930 21:01:20.230988  4070 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0930 21:01:25.461649  4070 solver.cpp:218] Iteration 54900 (19.118 iter/s, 5.23066s/100 iters), loss = 0.0567422
I0930 21:01:25.461681  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0567422 (* 1 = 0.0567422 loss)
I0930 21:01:25.461699  4070 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0930 21:01:30.452222  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:01:30.661921  4070 solver.cpp:330] Iteration 55000, Testing net (#0)
I0930 21:01:31.847232  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:01:31.898208  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9006
I0930 21:01:31.898236  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347541 (* 1 = 0.347541 loss)
I0930 21:01:31.952098  4070 solver.cpp:218] Iteration 55000 (15.4074 iter/s, 6.4904s/100 iters), loss = 0.0186278
I0930 21:01:31.952133  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186279 (* 1 = 0.0186279 loss)
I0930 21:01:31.952142  4070 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0930 21:01:37.190245  4070 solver.cpp:218] Iteration 55100 (19.0909 iter/s, 5.23809s/100 iters), loss = 0.0296556
I0930 21:01:37.190274  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296557 (* 1 = 0.0296557 loss)
I0930 21:01:37.190279  4070 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0930 21:01:42.436370  4070 solver.cpp:218] Iteration 55200 (19.0619 iter/s, 5.24608s/100 iters), loss = 0.0448652
I0930 21:01:42.436478  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0448653 (* 1 = 0.0448653 loss)
I0930 21:01:42.436486  4070 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0930 21:01:47.684267  4070 solver.cpp:218] Iteration 55300 (19.0557 iter/s, 5.24777s/100 iters), loss = 0.0412679
I0930 21:01:47.684307  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041268 (* 1 = 0.041268 loss)
I0930 21:01:47.684314  4070 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0930 21:01:52.929739  4070 solver.cpp:218] Iteration 55400 (19.0643 iter/s, 5.24541s/100 iters), loss = 0.0303783
I0930 21:01:52.929786  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303783 (* 1 = 0.0303783 loss)
I0930 21:01:52.929795  4070 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0930 21:01:57.908321  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:01:58.117395  4070 solver.cpp:330] Iteration 55500, Testing net (#0)
I0930 21:01:59.307579  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:01:59.357854  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I0930 21:01:59.357888  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350627 (* 1 = 0.350627 loss)
I0930 21:01:59.410552  4070 solver.cpp:218] Iteration 55500 (15.4311 iter/s, 6.48042s/100 iters), loss = 0.0336604
I0930 21:01:59.410580  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336604 (* 1 = 0.0336604 loss)
I0930 21:01:59.410588  4070 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0930 21:02:04.650413  4070 solver.cpp:218] Iteration 55600 (19.0847 iter/s, 5.23981s/100 iters), loss = 0.0343991
I0930 21:02:04.650444  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343992 (* 1 = 0.0343992 loss)
I0930 21:02:04.650451  4070 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0930 21:02:09.896020  4070 solver.cpp:218] Iteration 55700 (19.0638 iter/s, 5.24556s/100 iters), loss = 0.0513264
I0930 21:02:09.896055  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513264 (* 1 = 0.0513264 loss)
I0930 21:02:09.896061  4070 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0930 21:02:15.139825  4070 solver.cpp:218] Iteration 55800 (19.0703 iter/s, 5.24376s/100 iters), loss = 0.0844465
I0930 21:02:15.139930  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0844465 (* 1 = 0.0844465 loss)
I0930 21:02:15.139937  4070 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0930 21:02:20.389709  4070 solver.cpp:218] Iteration 55900 (19.0485 iter/s, 5.24977s/100 iters), loss = 0.0324674
I0930 21:02:20.389739  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324675 (* 1 = 0.0324675 loss)
I0930 21:02:20.389744  4070 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0930 21:02:25.366937  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:02:25.577080  4070 solver.cpp:330] Iteration 56000, Testing net (#0)
I0930 21:02:26.771196  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:02:26.821164  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.895
I0930 21:02:26.821198  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367919 (* 1 = 0.367919 loss)
I0930 21:02:26.873515  4070 solver.cpp:218] Iteration 56000 (15.4232 iter/s, 6.48376s/100 iters), loss = 0.0349894
I0930 21:02:26.873543  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349895 (* 1 = 0.0349895 loss)
I0930 21:02:26.873549  4070 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0930 21:02:32.119833  4070 solver.cpp:218] Iteration 56100 (19.0612 iter/s, 5.24627s/100 iters), loss = 0.0300532
I0930 21:02:32.119865  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300532 (* 1 = 0.0300532 loss)
I0930 21:02:32.119873  4070 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0930 21:02:37.351454  4070 solver.cpp:218] Iteration 56200 (19.1147 iter/s, 5.23156s/100 iters), loss = 0.0399219
I0930 21:02:37.351495  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399219 (* 1 = 0.0399219 loss)
I0930 21:02:37.351500  4070 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0930 21:02:42.595860  4070 solver.cpp:218] Iteration 56300 (19.0682 iter/s, 5.24435s/100 iters), loss = 0.0710582
I0930 21:02:42.595901  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0710582 (* 1 = 0.0710582 loss)
I0930 21:02:42.595906  4070 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0930 21:02:47.839141  4070 solver.cpp:218] Iteration 56400 (19.0723 iter/s, 5.24321s/100 iters), loss = 0.0799705
I0930 21:02:47.839303  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0799705 (* 1 = 0.0799705 loss)
I0930 21:02:47.839313  4070 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0930 21:02:52.813688  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:02:53.028882  4070 solver.cpp:330] Iteration 56500, Testing net (#0)
I0930 21:02:54.215435  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:02:54.265492  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8895
I0930 21:02:54.265527  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393937 (* 1 = 0.393937 loss)
I0930 21:02:54.317893  4070 solver.cpp:218] Iteration 56500 (15.4355 iter/s, 6.47859s/100 iters), loss = 0.0529151
I0930 21:02:54.317916  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0529151 (* 1 = 0.0529151 loss)
I0930 21:02:54.317922  4070 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0930 21:02:59.562690  4070 solver.cpp:218] Iteration 56600 (19.0667 iter/s, 5.24475s/100 iters), loss = 0.0645521
I0930 21:02:59.562719  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0645521 (* 1 = 0.0645521 loss)
I0930 21:02:59.562726  4070 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0930 21:03:04.802094  4070 solver.cpp:218] Iteration 56700 (19.0863 iter/s, 5.23935s/100 iters), loss = 0.0264271
I0930 21:03:04.802124  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264271 (* 1 = 0.0264271 loss)
I0930 21:03:04.802129  4070 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0930 21:03:10.051551  4070 solver.cpp:218] Iteration 56800 (19.0498 iter/s, 5.2494s/100 iters), loss = 0.0730203
I0930 21:03:10.051579  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0730203 (* 1 = 0.0730203 loss)
I0930 21:03:10.051585  4070 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0930 21:03:15.301851  4070 solver.cpp:218] Iteration 56900 (19.0467 iter/s, 5.25025s/100 iters), loss = 0.0174539
I0930 21:03:15.301894  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174539 (* 1 = 0.0174539 loss)
I0930 21:03:15.301900  4070 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0930 21:03:20.283381  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:03:20.492889  4070 solver.cpp:330] Iteration 57000, Testing net (#0)
I0930 21:03:21.677872  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:03:21.728137  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I0930 21:03:21.728163  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369957 (* 1 = 0.369957 loss)
I0930 21:03:21.780812  4070 solver.cpp:218] Iteration 57000 (15.4347 iter/s, 6.4789s/100 iters), loss = 0.0463998
I0930 21:03:21.780835  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463998 (* 1 = 0.0463998 loss)
I0930 21:03:21.780841  4070 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0930 21:03:27.026769  4070 solver.cpp:218] Iteration 57100 (19.0625 iter/s, 5.24591s/100 iters), loss = 0.0157718
I0930 21:03:27.026798  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157718 (* 1 = 0.0157718 loss)
I0930 21:03:27.026805  4070 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0930 21:03:32.270958  4070 solver.cpp:218] Iteration 57200 (19.0689 iter/s, 5.24413s/100 iters), loss = 0.0222957
I0930 21:03:32.270988  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222957 (* 1 = 0.0222957 loss)
I0930 21:03:32.270994  4070 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0930 21:03:37.508183  4070 solver.cpp:218] Iteration 57300 (19.0943 iter/s, 5.23718s/100 iters), loss = 0.0403356
I0930 21:03:37.508222  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403355 (* 1 = 0.0403355 loss)
I0930 21:03:37.508229  4070 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0930 21:03:42.750062  4070 solver.cpp:218] Iteration 57400 (19.0773 iter/s, 5.24182s/100 iters), loss = 0.0708259
I0930 21:03:42.750102  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708258 (* 1 = 0.0708258 loss)
I0930 21:03:42.750108  4070 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0930 21:03:47.736701  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:03:47.946847  4070 solver.cpp:330] Iteration 57500, Testing net (#0)
I0930 21:03:49.132066  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:03:49.182114  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8962
I0930 21:03:49.182148  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364228 (* 1 = 0.364228 loss)
I0930 21:03:49.234501  4070 solver.cpp:218] Iteration 57500 (15.4217 iter/s, 6.48438s/100 iters), loss = 0.0269289
I0930 21:03:49.234529  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269288 (* 1 = 0.0269288 loss)
I0930 21:03:49.234536  4070 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0930 21:03:54.481246  4070 solver.cpp:218] Iteration 57600 (19.0596 iter/s, 5.24669s/100 iters), loss = 0.054236
I0930 21:03:54.481349  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054236 (* 1 = 0.054236 loss)
I0930 21:03:54.481357  4070 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0930 21:03:59.731096  4070 solver.cpp:218] Iteration 57700 (19.0486 iter/s, 5.24974s/100 iters), loss = 0.0231305
I0930 21:03:59.731127  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231304 (* 1 = 0.0231304 loss)
I0930 21:03:59.731133  4070 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0930 21:04:04.976366  4070 solver.cpp:218] Iteration 57800 (19.065 iter/s, 5.24522s/100 iters), loss = 0.0525812
I0930 21:04:04.976402  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0525811 (* 1 = 0.0525811 loss)
I0930 21:04:04.976408  4070 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0930 21:04:10.220060  4070 solver.cpp:218] Iteration 57900 (19.0707 iter/s, 5.24364s/100 iters), loss = 0.0606253
I0930 21:04:10.220089  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0606252 (* 1 = 0.0606252 loss)
I0930 21:04:10.220095  4070 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0930 21:04:15.210230  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:04:15.420114  4070 solver.cpp:330] Iteration 58000, Testing net (#0)
I0930 21:04:16.603250  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:04:16.653100  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8966
I0930 21:04:16.653126  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363209 (* 1 = 0.363209 loss)
I0930 21:04:16.705466  4070 solver.cpp:218] Iteration 58000 (15.4194 iter/s, 6.48536s/100 iters), loss = 0.0246646
I0930 21:04:16.705492  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246646 (* 1 = 0.0246646 loss)
I0930 21:04:16.705497  4070 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0930 21:04:21.954768  4070 solver.cpp:218] Iteration 58100 (19.0503 iter/s, 5.24925s/100 iters), loss = 0.0800156
I0930 21:04:21.954797  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0800155 (* 1 = 0.0800155 loss)
I0930 21:04:21.954803  4070 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0930 21:04:27.201989  4070 solver.cpp:218] Iteration 58200 (19.0579 iter/s, 5.24717s/100 iters), loss = 0.0121416
I0930 21:04:27.202105  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121414 (* 1 = 0.0121414 loss)
I0930 21:04:27.202122  4070 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0930 21:04:32.446893  4070 solver.cpp:218] Iteration 58300 (19.0666 iter/s, 5.24477s/100 iters), loss = 0.0614992
I0930 21:04:32.446923  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0614991 (* 1 = 0.0614991 loss)
I0930 21:04:32.446929  4070 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0930 21:04:37.686652  4070 solver.cpp:218] Iteration 58400 (19.085 iter/s, 5.23971s/100 iters), loss = 0.00965555
I0930 21:04:37.686683  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00965543 (* 1 = 0.00965543 loss)
I0930 21:04:37.686689  4070 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0930 21:04:42.676137  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:04:42.886080  4070 solver.cpp:330] Iteration 58500, Testing net (#0)
I0930 21:04:44.081398  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:04:44.131821  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.891
I0930 21:04:44.131858  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385671 (* 1 = 0.385671 loss)
I0930 21:04:44.184263  4070 solver.cpp:218] Iteration 58500 (15.3904 iter/s, 6.49756s/100 iters), loss = 0.0738735
I0930 21:04:44.184294  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0738733 (* 1 = 0.0738733 loss)
I0930 21:04:44.184301  4070 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0930 21:04:49.429092  4070 solver.cpp:218] Iteration 58600 (19.0666 iter/s, 5.24478s/100 iters), loss = 0.0276712
I0930 21:04:49.429133  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276711 (* 1 = 0.0276711 loss)
I0930 21:04:49.429139  4070 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0930 21:04:54.677275  4070 solver.cpp:218] Iteration 58700 (19.0544 iter/s, 5.24812s/100 iters), loss = 0.0573695
I0930 21:04:54.677316  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0573693 (* 1 = 0.0573693 loss)
I0930 21:04:54.677322  4070 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0930 21:04:59.923861  4070 solver.cpp:218] Iteration 58800 (19.0602 iter/s, 5.24652s/100 iters), loss = 0.0204403
I0930 21:04:59.923975  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204402 (* 1 = 0.0204402 loss)
I0930 21:04:59.923982  4070 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0930 21:05:05.170727  4070 solver.cpp:218] Iteration 58900 (19.0595 iter/s, 5.24673s/100 iters), loss = 0.0369958
I0930 21:05:05.170758  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369957 (* 1 = 0.0369957 loss)
I0930 21:05:05.170775  4070 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0930 21:05:10.148356  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:05:10.358371  4070 solver.cpp:330] Iteration 59000, Testing net (#0)
I0930 21:05:11.551316  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:05:11.601282  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8919
I0930 21:05:11.601316  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385299 (* 1 = 0.385299 loss)
I0930 21:05:11.653985  4070 solver.cpp:218] Iteration 59000 (15.4245 iter/s, 6.48321s/100 iters), loss = 0.0466668
I0930 21:05:11.654007  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466666 (* 1 = 0.0466666 loss)
I0930 21:05:11.654013  4070 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0930 21:05:16.889678  4070 solver.cpp:218] Iteration 59100 (19.0998 iter/s, 5.23565s/100 iters), loss = 0.0407986
I0930 21:05:16.889713  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407985 (* 1 = 0.0407985 loss)
I0930 21:05:16.889719  4070 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0930 21:05:22.130208  4070 solver.cpp:218] Iteration 59200 (19.0823 iter/s, 5.24047s/100 iters), loss = 0.026982
I0930 21:05:22.130246  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269818 (* 1 = 0.0269818 loss)
I0930 21:05:22.130252  4070 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0930 21:05:27.377831  4070 solver.cpp:218] Iteration 59300 (19.0565 iter/s, 5.24757s/100 iters), loss = 0.0757632
I0930 21:05:27.377871  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.075763 (* 1 = 0.075763 loss)
I0930 21:05:27.377877  4070 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0930 21:05:32.633231  4070 solver.cpp:218] Iteration 59400 (19.0283 iter/s, 5.25534s/100 iters), loss = 0.0457926
I0930 21:05:32.633389  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457925 (* 1 = 0.0457925 loss)
I0930 21:05:32.633397  4070 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0930 21:05:37.610219  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:05:37.819973  4070 solver.cpp:330] Iteration 59500, Testing net (#0)
I0930 21:05:39.013921  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:05:39.063999  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8988
I0930 21:05:39.064033  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355057 (* 1 = 0.355057 loss)
I0930 21:05:39.116263  4070 solver.cpp:218] Iteration 59500 (15.4253 iter/s, 6.48287s/100 iters), loss = 0.0298584
I0930 21:05:39.116293  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298582 (* 1 = 0.0298582 loss)
I0930 21:05:39.116302  4070 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0930 21:05:44.367856  4070 solver.cpp:218] Iteration 59600 (19.042 iter/s, 5.25154s/100 iters), loss = 0.0362163
I0930 21:05:44.367897  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362162 (* 1 = 0.0362162 loss)
I0930 21:05:44.367902  4070 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0930 21:05:49.612639  4070 solver.cpp:218] Iteration 59700 (19.0668 iter/s, 5.24472s/100 iters), loss = 0.0185881
I0930 21:05:49.612680  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185879 (* 1 = 0.0185879 loss)
I0930 21:05:49.612686  4070 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0930 21:05:54.860412  4070 solver.cpp:218] Iteration 59800 (19.0559 iter/s, 5.24771s/100 iters), loss = 0.0442413
I0930 21:05:54.860445  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0442411 (* 1 = 0.0442411 loss)
I0930 21:05:54.860452  4070 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0930 21:06:00.106273  4070 solver.cpp:218] Iteration 59900 (19.0628 iter/s, 5.24581s/100 iters), loss = 0.107975
I0930 21:06:00.106304  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107975 (* 1 = 0.107975 loss)
I0930 21:06:00.106320  4070 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0930 21:06:05.089442  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:06:05.299321  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_60000.caffemodel
I0930 21:06:05.304258  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_60000.solverstate
I0930 21:06:05.305594  4070 solver.cpp:330] Iteration 60000, Testing net (#0)
I0930 21:06:06.491588  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:06:06.541999  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.893
I0930 21:06:06.542022  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.396472 (* 1 = 0.396472 loss)
I0930 21:06:06.594470  4070 solver.cpp:218] Iteration 60000 (15.4127 iter/s, 6.48815s/100 iters), loss = 0.0596344
I0930 21:06:06.594493  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0596342 (* 1 = 0.0596342 loss)
I0930 21:06:06.594499  4070 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0930 21:06:11.834540  4070 solver.cpp:218] Iteration 60100 (19.0839 iter/s, 5.24003s/100 iters), loss = 0.0644689
I0930 21:06:11.834579  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644688 (* 1 = 0.0644688 loss)
I0930 21:06:11.834585  4070 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0930 21:06:17.078761  4070 solver.cpp:218] Iteration 60200 (19.0688 iter/s, 5.24416s/100 iters), loss = 0.0583463
I0930 21:06:17.078796  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0583462 (* 1 = 0.0583462 loss)
I0930 21:06:17.078804  4070 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0930 21:06:22.319628  4070 solver.cpp:218] Iteration 60300 (19.081 iter/s, 5.24081s/100 iters), loss = 0.0819261
I0930 21:06:22.319666  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.081926 (* 1 = 0.081926 loss)
I0930 21:06:22.319672  4070 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0930 21:06:27.572197  4070 solver.cpp:218] Iteration 60400 (19.0385 iter/s, 5.25251s/100 iters), loss = 0.0418654
I0930 21:06:27.572238  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418652 (* 1 = 0.0418652 loss)
I0930 21:06:27.572245  4070 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0930 21:06:32.561509  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:06:32.771756  4070 solver.cpp:330] Iteration 60500, Testing net (#0)
I0930 21:06:33.957958  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:06:34.007791  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.895
I0930 21:06:34.007824  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362926 (* 1 = 0.362926 loss)
I0930 21:06:34.060027  4070 solver.cpp:218] Iteration 60500 (15.4136 iter/s, 6.48777s/100 iters), loss = 0.063017
I0930 21:06:34.060050  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0630167 (* 1 = 0.0630167 loss)
I0930 21:06:34.060057  4070 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0930 21:06:39.308212  4070 solver.cpp:218] Iteration 60600 (19.0544 iter/s, 5.24814s/100 iters), loss = 0.0127192
I0930 21:06:39.308372  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012719 (* 1 = 0.012719 loss)
I0930 21:06:39.308380  4070 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0930 21:06:44.553373  4070 solver.cpp:218] Iteration 60700 (19.0658 iter/s, 5.24499s/100 iters), loss = 0.0317594
I0930 21:06:44.553402  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317592 (* 1 = 0.0317592 loss)
I0930 21:06:44.553408  4070 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0930 21:06:49.790818  4070 solver.cpp:218] Iteration 60800 (19.0935 iter/s, 5.2374s/100 iters), loss = 0.0386235
I0930 21:06:49.790848  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0386233 (* 1 = 0.0386233 loss)
I0930 21:06:49.790863  4070 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0930 21:06:55.036887  4070 solver.cpp:218] Iteration 60900 (19.0621 iter/s, 5.24602s/100 iters), loss = 0.0208249
I0930 21:06:55.036917  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208247 (* 1 = 0.0208247 loss)
I0930 21:06:55.036923  4070 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0930 21:07:00.019465  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:07:00.230072  4070 solver.cpp:330] Iteration 61000, Testing net (#0)
I0930 21:07:01.413661  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:07:01.463884  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8954
I0930 21:07:01.463917  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372635 (* 1 = 0.372635 loss)
I0930 21:07:01.516808  4070 solver.cpp:218] Iteration 61000 (15.4324 iter/s, 6.47987s/100 iters), loss = 0.0204273
I0930 21:07:01.516837  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020427 (* 1 = 0.020427 loss)
I0930 21:07:01.516844  4070 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0930 21:07:06.762806  4070 solver.cpp:218] Iteration 61100 (19.0623 iter/s, 5.24595s/100 iters), loss = 0.0192254
I0930 21:07:06.762846  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192252 (* 1 = 0.0192252 loss)
I0930 21:07:06.762852  4070 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0930 21:07:12.014724  4070 solver.cpp:218] Iteration 61200 (19.0409 iter/s, 5.25186s/100 iters), loss = 0.0223503
I0930 21:07:12.014883  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223501 (* 1 = 0.0223501 loss)
I0930 21:07:12.014890  4070 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0930 21:07:17.264163  4070 solver.cpp:218] Iteration 61300 (19.0503 iter/s, 5.24927s/100 iters), loss = 0.0446302
I0930 21:07:17.264194  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446299 (* 1 = 0.0446299 loss)
I0930 21:07:17.264209  4070 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0930 21:07:22.507304  4070 solver.cpp:218] Iteration 61400 (19.0727 iter/s, 5.24309s/100 iters), loss = 0.0243138
I0930 21:07:22.507333  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243136 (* 1 = 0.0243136 loss)
I0930 21:07:22.507349  4070 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0930 21:07:27.497073  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:07:27.706972  4070 solver.cpp:330] Iteration 61500, Testing net (#0)
I0930 21:07:28.894640  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:07:28.946288  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8928
I0930 21:07:28.946316  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398523 (* 1 = 0.398523 loss)
I0930 21:07:28.999269  4070 solver.cpp:218] Iteration 61500 (15.4038 iter/s, 6.49191s/100 iters), loss = 0.0376572
I0930 21:07:28.999301  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376569 (* 1 = 0.0376569 loss)
I0930 21:07:28.999308  4070 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0930 21:07:34.237701  4070 solver.cpp:218] Iteration 61600 (19.0899 iter/s, 5.23838s/100 iters), loss = 0.072161
I0930 21:07:34.237741  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721607 (* 1 = 0.0721607 loss)
I0930 21:07:34.237748  4070 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0930 21:07:39.481205  4070 solver.cpp:218] Iteration 61700 (19.0714 iter/s, 5.24344s/100 iters), loss = 0.12863
I0930 21:07:39.481245  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128629 (* 1 = 0.128629 loss)
I0930 21:07:39.481251  4070 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0930 21:07:44.725059  4070 solver.cpp:218] Iteration 61800 (19.0702 iter/s, 5.24379s/100 iters), loss = 0.0348509
I0930 21:07:44.725215  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348506 (* 1 = 0.0348506 loss)
I0930 21:07:44.725224  4070 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0930 21:07:49.970546  4070 solver.cpp:218] Iteration 61900 (19.0647 iter/s, 5.24531s/100 iters), loss = 0.025375
I0930 21:07:49.970590  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253748 (* 1 = 0.0253748 loss)
I0930 21:07:49.970597  4070 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0930 21:07:54.952666  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:07:55.162151  4070 solver.cpp:330] Iteration 62000, Testing net (#0)
I0930 21:07:56.356616  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:07:56.406426  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8956
I0930 21:07:56.406462  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373514 (* 1 = 0.373514 loss)
I0930 21:07:56.458577  4070 solver.cpp:218] Iteration 62000 (15.4132 iter/s, 6.48794s/100 iters), loss = 0.0338184
I0930 21:07:56.458602  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338182 (* 1 = 0.0338182 loss)
I0930 21:07:56.458609  4070 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0930 21:08:01.699205  4070 solver.cpp:218] Iteration 62100 (19.0818 iter/s, 5.24058s/100 iters), loss = 0.0933614
I0930 21:08:01.699235  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0933611 (* 1 = 0.0933611 loss)
I0930 21:08:01.699242  4070 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0930 21:08:06.950542  4070 solver.cpp:218] Iteration 62200 (19.043 iter/s, 5.25128s/100 iters), loss = 0.0461112
I0930 21:08:06.950582  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046111 (* 1 = 0.046111 loss)
I0930 21:08:06.950589  4070 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0930 21:08:12.199489  4070 solver.cpp:218] Iteration 62300 (19.0517 iter/s, 5.24889s/100 iters), loss = 0.0307284
I0930 21:08:12.199522  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307281 (* 1 = 0.0307281 loss)
I0930 21:08:12.199539  4070 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0930 21:08:17.447844  4070 solver.cpp:218] Iteration 62400 (19.0538 iter/s, 5.2483s/100 iters), loss = 0.0269123
I0930 21:08:17.447990  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269121 (* 1 = 0.0269121 loss)
I0930 21:08:17.448040  4070 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0930 21:08:22.426081  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:08:22.636425  4070 solver.cpp:330] Iteration 62500, Testing net (#0)
I0930 21:08:23.828677  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:08:23.878904  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8984
I0930 21:08:23.878931  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368248 (* 1 = 0.368248 loss)
I0930 21:08:23.931876  4070 solver.cpp:218] Iteration 62500 (15.4229 iter/s, 6.48388s/100 iters), loss = 0.0262068
I0930 21:08:23.931905  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262065 (* 1 = 0.0262065 loss)
I0930 21:08:23.931924  4070 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0930 21:08:29.175741  4070 solver.cpp:218] Iteration 62600 (19.0701 iter/s, 5.24382s/100 iters), loss = 0.0308714
I0930 21:08:29.175779  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308712 (* 1 = 0.0308712 loss)
I0930 21:08:29.175799  4070 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0930 21:08:34.412955  4070 solver.cpp:218] Iteration 62700 (19.0943 iter/s, 5.23716s/100 iters), loss = 0.0362358
I0930 21:08:34.412986  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362355 (* 1 = 0.0362355 loss)
I0930 21:08:34.413004  4070 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0930 21:08:39.657371  4070 solver.cpp:218] Iteration 62800 (19.0681 iter/s, 5.24436s/100 iters), loss = 0.0107045
I0930 21:08:39.657404  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107043 (* 1 = 0.0107043 loss)
I0930 21:08:39.657413  4070 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0930 21:08:44.908768  4070 solver.cpp:218] Iteration 62900 (19.0427 iter/s, 5.25134s/100 iters), loss = 0.0343732
I0930 21:08:44.908802  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034373 (* 1 = 0.034373 loss)
I0930 21:08:44.908809  4070 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0930 21:08:49.888777  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:08:50.104753  4070 solver.cpp:330] Iteration 63000, Testing net (#0)
I0930 21:08:51.290302  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:08:51.340507  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8934
I0930 21:08:51.340529  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409351 (* 1 = 0.409351 loss)
I0930 21:08:51.392824  4070 solver.cpp:218] Iteration 63000 (15.4226 iter/s, 6.484s/100 iters), loss = 0.0146332
I0930 21:08:51.392848  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014633 (* 1 = 0.014633 loss)
I0930 21:08:51.392855  4070 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0930 21:08:56.639117  4070 solver.cpp:218] Iteration 63100 (19.0612 iter/s, 5.24625s/100 iters), loss = 0.0506479
I0930 21:08:56.639159  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0506477 (* 1 = 0.0506477 loss)
I0930 21:08:56.639166  4070 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0930 21:09:01.883389  4070 solver.cpp:218] Iteration 63200 (19.0687 iter/s, 5.2442s/100 iters), loss = 0.0399376
I0930 21:09:01.883426  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399373 (* 1 = 0.0399373 loss)
I0930 21:09:01.883433  4070 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0930 21:09:07.133703  4070 solver.cpp:218] Iteration 63300 (19.0467 iter/s, 5.25026s/100 iters), loss = 0.0331245
I0930 21:09:07.133744  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331242 (* 1 = 0.0331242 loss)
I0930 21:09:07.133749  4070 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0930 21:09:12.379492  4070 solver.cpp:218] Iteration 63400 (19.0631 iter/s, 5.24573s/100 iters), loss = 0.00945146
I0930 21:09:12.379532  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00945118 (* 1 = 0.00945118 loss)
I0930 21:09:12.379539  4070 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0930 21:09:17.358089  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:09:17.568819  4070 solver.cpp:330] Iteration 63500, Testing net (#0)
I0930 21:09:18.755111  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:09:18.805032  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8929
I0930 21:09:18.805064  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413051 (* 1 = 0.413051 loss)
I0930 21:09:18.857739  4070 solver.cpp:218] Iteration 63500 (15.4364 iter/s, 6.47819s/100 iters), loss = 0.0391532
I0930 21:09:18.857764  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391529 (* 1 = 0.0391529 loss)
I0930 21:09:18.857770  4070 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0930 21:09:24.100955  4070 solver.cpp:218] Iteration 63600 (19.0725 iter/s, 5.24316s/100 iters), loss = 0.032627
I0930 21:09:24.101106  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326267 (* 1 = 0.0326267 loss)
I0930 21:09:24.101114  4070 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0930 21:09:29.347676  4070 solver.cpp:218] Iteration 63700 (19.0602 iter/s, 5.24655s/100 iters), loss = 0.0308776
I0930 21:09:29.347707  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308773 (* 1 = 0.0308773 loss)
I0930 21:09:29.347712  4070 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0930 21:09:34.587435  4070 solver.cpp:218] Iteration 63800 (19.085 iter/s, 5.23971s/100 iters), loss = 0.023564
I0930 21:09:34.587466  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235637 (* 1 = 0.0235637 loss)
I0930 21:09:34.587471  4070 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0930 21:09:39.835490  4070 solver.cpp:218] Iteration 63900 (19.0549 iter/s, 5.248s/100 iters), loss = 0.0406249
I0930 21:09:39.835527  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406246 (* 1 = 0.0406246 loss)
I0930 21:09:39.835536  4070 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0930 21:09:44.824721  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:09:45.033810  4070 solver.cpp:330] Iteration 64000, Testing net (#0)
I0930 21:09:46.219004  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:09:46.269047  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.89
I0930 21:09:46.269071  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422745 (* 1 = 0.422745 loss)
I0930 21:09:46.321555  4070 solver.cpp:218] Iteration 64000 (15.4178 iter/s, 6.48601s/100 iters), loss = 0.0426892
I0930 21:09:46.321579  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426889 (* 1 = 0.0426889 loss)
I0930 21:09:46.321585  4070 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I0930 21:09:51.570420  4070 solver.cpp:218] Iteration 64100 (19.0519 iter/s, 5.24882s/100 iters), loss = 0.0258258
I0930 21:09:51.570448  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258254 (* 1 = 0.0258254 loss)
I0930 21:09:51.570454  4070 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I0930 21:09:56.813536  4070 solver.cpp:218] Iteration 64200 (19.0728 iter/s, 5.24307s/100 iters), loss = 0.0730977
I0930 21:09:56.813671  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0730974 (* 1 = 0.0730974 loss)
I0930 21:09:56.813678  4070 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I0930 21:10:02.053594  4070 solver.cpp:218] Iteration 64300 (19.0843 iter/s, 5.2399s/100 iters), loss = 0.0422902
I0930 21:10:02.053628  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422898 (* 1 = 0.0422898 loss)
I0930 21:10:02.053637  4070 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I0930 21:10:07.292312  4070 solver.cpp:218] Iteration 64400 (19.0888 iter/s, 5.23867s/100 iters), loss = 0.0474728
I0930 21:10:07.292342  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474725 (* 1 = 0.0474725 loss)
I0930 21:10:07.292348  4070 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I0930 21:10:12.278110  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:10:12.487740  4070 solver.cpp:330] Iteration 64500, Testing net (#0)
I0930 21:10:13.672221  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:10:13.722385  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8945
I0930 21:10:13.722410  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.402504 (* 1 = 0.402504 loss)
I0930 21:10:13.775140  4070 solver.cpp:218] Iteration 64500 (15.4255 iter/s, 6.48278s/100 iters), loss = 0.0271304
I0930 21:10:13.775164  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271301 (* 1 = 0.0271301 loss)
I0930 21:10:13.775171  4070 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I0930 21:10:19.026787  4070 solver.cpp:218] Iteration 64600 (19.0418 iter/s, 5.2516s/100 iters), loss = 0.0467297
I0930 21:10:19.026816  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0467294 (* 1 = 0.0467294 loss)
I0930 21:10:19.026823  4070 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I0930 21:10:24.280798  4070 solver.cpp:218] Iteration 64700 (19.0333 iter/s, 5.25396s/100 iters), loss = 0.0486533
I0930 21:10:24.280838  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048653 (* 1 = 0.048653 loss)
I0930 21:10:24.280844  4070 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I0930 21:10:29.528342  4070 solver.cpp:218] Iteration 64800 (19.0568 iter/s, 5.24748s/100 iters), loss = 0.0448281
I0930 21:10:29.528496  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0448277 (* 1 = 0.0448277 loss)
I0930 21:10:29.528508  4070 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I0930 21:10:34.766144  4070 solver.cpp:218] Iteration 64900 (19.0926 iter/s, 5.23764s/100 iters), loss = 0.0185474
I0930 21:10:34.766173  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185471 (* 1 = 0.0185471 loss)
I0930 21:10:34.766180  4070 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I0930 21:10:39.750253  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:10:39.959332  4070 solver.cpp:330] Iteration 65000, Testing net (#0)
I0930 21:10:41.152523  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:10:41.202062  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8875
I0930 21:10:41.202087  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411511 (* 1 = 0.411511 loss)
I0930 21:10:41.254441  4070 solver.cpp:218] Iteration 65000 (15.4125 iter/s, 6.48825s/100 iters), loss = 0.0384958
I0930 21:10:41.254470  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384955 (* 1 = 0.0384955 loss)
I0930 21:10:41.254477  4070 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I0930 21:10:46.490809  4070 solver.cpp:218] Iteration 65100 (19.0974 iter/s, 5.23632s/100 iters), loss = 0.0242076
I0930 21:10:46.490838  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242072 (* 1 = 0.0242072 loss)
I0930 21:10:46.490844  4070 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I0930 21:10:51.737730  4070 solver.cpp:218] Iteration 65200 (19.059 iter/s, 5.24687s/100 iters), loss = 0.014491
I0930 21:10:51.737763  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144907 (* 1 = 0.0144907 loss)
I0930 21:10:51.737782  4070 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I0930 21:10:56.987229  4070 solver.cpp:218] Iteration 65300 (19.0496 iter/s, 5.24945s/100 iters), loss = 0.0249008
I0930 21:10:56.987258  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249005 (* 1 = 0.0249005 loss)
I0930 21:10:56.987263  4070 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I0930 21:11:02.235945  4070 solver.cpp:218] Iteration 65400 (19.0525 iter/s, 5.24866s/100 iters), loss = 0.0308873
I0930 21:11:02.236114  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030887 (* 1 = 0.030887 loss)
I0930 21:11:02.236124  4070 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I0930 21:11:07.213874  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:11:07.424163  4070 solver.cpp:330] Iteration 65500, Testing net (#0)
I0930 21:11:08.616041  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:11:08.666046  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8909
I0930 21:11:08.666081  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.421579 (* 1 = 0.421579 loss)
I0930 21:11:08.718463  4070 solver.cpp:218] Iteration 65500 (15.4265 iter/s, 6.48233s/100 iters), loss = 0.00957505
I0930 21:11:08.718493  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957473 (* 1 = 0.00957473 loss)
I0930 21:11:08.718500  4070 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I0930 21:11:13.963699  4070 solver.cpp:218] Iteration 65600 (19.0651 iter/s, 5.24517s/100 iters), loss = 0.0233307
I0930 21:11:13.963735  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233304 (* 1 = 0.0233304 loss)
I0930 21:11:13.963742  4070 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I0930 21:11:19.203349  4070 solver.cpp:218] Iteration 65700 (19.0855 iter/s, 5.23959s/100 iters), loss = 0.0284301
I0930 21:11:19.203380  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284298 (* 1 = 0.0284298 loss)
I0930 21:11:19.203387  4070 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I0930 21:11:24.450369  4070 solver.cpp:218] Iteration 65800 (19.0586 iter/s, 5.24697s/100 iters), loss = 0.0765604
I0930 21:11:24.450402  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0765601 (* 1 = 0.0765601 loss)
I0930 21:11:24.450420  4070 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I0930 21:11:29.697005  4070 solver.cpp:218] Iteration 65900 (19.06 iter/s, 5.24659s/100 iters), loss = 0.0109435
I0930 21:11:29.697036  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109432 (* 1 = 0.0109432 loss)
I0930 21:11:29.697046  4070 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I0930 21:11:34.671506  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:11:34.881342  4070 solver.cpp:330] Iteration 66000, Testing net (#0)
I0930 21:11:36.071557  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:11:36.121529  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8927
I0930 21:11:36.121554  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422325 (* 1 = 0.422325 loss)
I0930 21:11:36.174159  4070 solver.cpp:218] Iteration 66000 (15.439 iter/s, 6.4771s/100 iters), loss = 0.0329824
I0930 21:11:36.174183  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329821 (* 1 = 0.0329821 loss)
I0930 21:11:36.174190  4070 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I0930 21:11:41.420346  4070 solver.cpp:218] Iteration 66100 (19.0616 iter/s, 5.24614s/100 iters), loss = 0.0904511
I0930 21:11:41.420385  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0904508 (* 1 = 0.0904508 loss)
I0930 21:11:41.420392  4070 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I0930 21:11:46.660979  4070 solver.cpp:218] Iteration 66200 (19.0819 iter/s, 5.24057s/100 iters), loss = 0.0940268
I0930 21:11:46.661007  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0940265 (* 1 = 0.0940265 loss)
I0930 21:11:46.661013  4070 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I0930 21:11:51.911495  4070 solver.cpp:218] Iteration 66300 (19.0459 iter/s, 5.25047s/100 iters), loss = 0.0340658
I0930 21:11:51.911535  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340656 (* 1 = 0.0340656 loss)
I0930 21:11:51.911541  4070 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I0930 21:11:57.163741  4070 solver.cpp:218] Iteration 66400 (19.0397 iter/s, 5.25218s/100 iters), loss = 0.0338389
I0930 21:11:57.163781  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338386 (* 1 = 0.0338386 loss)
I0930 21:11:57.163786  4070 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I0930 21:12:02.151701  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:12:02.361876  4070 solver.cpp:330] Iteration 66500, Testing net (#0)
I0930 21:12:03.547241  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:12:03.597460  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8804
I0930 21:12:03.597494  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.475919 (* 1 = 0.475919 loss)
I0930 21:12:03.650516  4070 solver.cpp:218] Iteration 66500 (15.4161 iter/s, 6.48671s/100 iters), loss = 0.0156785
I0930 21:12:03.650563  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156783 (* 1 = 0.0156783 loss)
I0930 21:12:03.650569  4070 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I0930 21:12:08.902379  4070 solver.cpp:218] Iteration 66600 (19.0411 iter/s, 5.25179s/100 iters), loss = 0.0352107
I0930 21:12:08.902474  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352104 (* 1 = 0.0352104 loss)
I0930 21:12:08.902493  4070 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I0930 21:12:14.149974  4070 solver.cpp:218] Iteration 66700 (19.0567 iter/s, 5.24749s/100 iters), loss = 0.0357281
I0930 21:12:14.150007  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357279 (* 1 = 0.0357279 loss)
I0930 21:12:14.150014  4070 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I0930 21:12:19.386634  4070 solver.cpp:218] Iteration 66800 (19.0965 iter/s, 5.23657s/100 iters), loss = 0.062269
I0930 21:12:19.386674  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0622688 (* 1 = 0.0622688 loss)
I0930 21:12:19.386680  4070 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I0930 21:12:24.630239  4070 solver.cpp:218] Iteration 66900 (19.0711 iter/s, 5.24354s/100 iters), loss = 0.0134094
I0930 21:12:24.630270  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134091 (* 1 = 0.0134091 loss)
I0930 21:12:24.630285  4070 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I0930 21:12:29.612947  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:12:29.823484  4070 solver.cpp:330] Iteration 67000, Testing net (#0)
I0930 21:12:31.007622  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:12:31.057518  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8913
I0930 21:12:31.057541  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40523 (* 1 = 0.40523 loss)
I0930 21:12:31.110080  4070 solver.cpp:218] Iteration 67000 (15.4326 iter/s, 6.47979s/100 iters), loss = 0.0329995
I0930 21:12:31.110103  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329992 (* 1 = 0.0329992 loss)
I0930 21:12:31.110110  4070 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I0930 21:12:36.358798  4070 solver.cpp:218] Iteration 67100 (19.0524 iter/s, 5.24867s/100 iters), loss = 0.0208502
I0930 21:12:36.358837  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02085 (* 1 = 0.02085 loss)
I0930 21:12:36.358844  4070 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I0930 21:12:41.607094  4070 solver.cpp:218] Iteration 67200 (19.054 iter/s, 5.24823s/100 iters), loss = 0.115695
I0930 21:12:41.607230  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115695 (* 1 = 0.115695 loss)
I0930 21:12:41.607237  4070 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I0930 21:12:46.846772  4070 solver.cpp:218] Iteration 67300 (19.0857 iter/s, 5.23952s/100 iters), loss = 0.0418628
I0930 21:12:46.846801  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418626 (* 1 = 0.0418626 loss)
I0930 21:12:46.846807  4070 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I0930 21:12:52.099067  4070 solver.cpp:218] Iteration 67400 (19.0395 iter/s, 5.25225s/100 iters), loss = 0.0384532
I0930 21:12:52.099099  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.038453 (* 1 = 0.038453 loss)
I0930 21:12:52.099107  4070 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I0930 21:12:57.087651  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:12:57.297935  4070 solver.cpp:330] Iteration 67500, Testing net (#0)
I0930 21:12:58.483178  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:12:58.533248  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8938
I0930 21:12:58.533283  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.395863 (* 1 = 0.395863 loss)
I0930 21:12:58.586089  4070 solver.cpp:218] Iteration 67500 (15.4155 iter/s, 6.48697s/100 iters), loss = 0.0144469
I0930 21:12:58.586115  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144466 (* 1 = 0.0144466 loss)
I0930 21:12:58.586122  4070 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I0930 21:13:03.830855  4070 solver.cpp:218] Iteration 67600 (19.0668 iter/s, 5.24472s/100 iters), loss = 0.0441731
I0930 21:13:03.830884  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441728 (* 1 = 0.0441728 loss)
I0930 21:13:03.830890  4070 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I0930 21:13:09.072441  4070 solver.cpp:218] Iteration 67700 (19.0784 iter/s, 5.24154s/100 iters), loss = 0.0475384
I0930 21:13:09.072470  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0475381 (* 1 = 0.0475381 loss)
I0930 21:13:09.072475  4070 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I0930 21:13:14.317328  4070 solver.cpp:218] Iteration 67800 (19.0664 iter/s, 5.24484s/100 iters), loss = 0.0562767
I0930 21:13:14.317430  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0562765 (* 1 = 0.0562765 loss)
I0930 21:13:14.317448  4070 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I0930 21:13:19.552544  4070 solver.cpp:218] Iteration 67900 (19.1018 iter/s, 5.2351s/100 iters), loss = 0.0502729
I0930 21:13:19.552573  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0502726 (* 1 = 0.0502726 loss)
I0930 21:13:19.552579  4070 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I0930 21:13:24.537472  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:13:24.746587  4070 solver.cpp:330] Iteration 68000, Testing net (#0)
I0930 21:13:25.932555  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:13:25.983575  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8995
I0930 21:13:25.983613  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367829 (* 1 = 0.367829 loss)
I0930 21:13:26.037598  4070 solver.cpp:218] Iteration 68000 (15.4202 iter/s, 6.485s/100 iters), loss = 0.0340352
I0930 21:13:26.037644  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034035 (* 1 = 0.034035 loss)
I0930 21:13:26.037652  4070 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I0930 21:13:31.279428  4070 solver.cpp:218] Iteration 68100 (19.0777 iter/s, 5.24173s/100 iters), loss = 0.0156262
I0930 21:13:31.279465  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015626 (* 1 = 0.015626 loss)
I0930 21:13:31.279482  4070 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I0930 21:13:36.530134  4070 solver.cpp:218] Iteration 68200 (19.0453 iter/s, 5.25065s/100 iters), loss = 0.0248922
I0930 21:13:36.530163  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024892 (* 1 = 0.024892 loss)
I0930 21:13:36.530169  4070 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I0930 21:13:41.778206  4070 solver.cpp:218] Iteration 68300 (19.0548 iter/s, 5.24803s/100 iters), loss = 0.0666005
I0930 21:13:41.778234  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666003 (* 1 = 0.0666003 loss)
I0930 21:13:41.778240  4070 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I0930 21:13:47.016954  4070 solver.cpp:218] Iteration 68400 (19.0887 iter/s, 5.2387s/100 iters), loss = 0.0656275
I0930 21:13:47.017094  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0656273 (* 1 = 0.0656273 loss)
I0930 21:13:47.017102  4070 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I0930 21:13:51.998409  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:13:52.207881  4070 solver.cpp:330] Iteration 68500, Testing net (#0)
I0930 21:13:53.403018  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:13:53.453243  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8808
I0930 21:13:53.453277  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.460426 (* 1 = 0.460426 loss)
I0930 21:13:53.506012  4070 solver.cpp:218] Iteration 68500 (15.4109 iter/s, 6.48891s/100 iters), loss = 0.0243249
I0930 21:13:53.506041  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243247 (* 1 = 0.0243247 loss)
I0930 21:13:53.506047  4070 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I0930 21:13:58.741204  4070 solver.cpp:218] Iteration 68600 (19.1017 iter/s, 5.23515s/100 iters), loss = 0.0417018
I0930 21:13:58.741233  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417016 (* 1 = 0.0417016 loss)
I0930 21:13:58.741240  4070 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I0930 21:14:03.984009  4070 solver.cpp:218] Iteration 68700 (19.074 iter/s, 5.24275s/100 iters), loss = 0.026273
I0930 21:14:03.984050  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262727 (* 1 = 0.0262727 loss)
I0930 21:14:03.984056  4070 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I0930 21:14:09.231299  4070 solver.cpp:218] Iteration 68800 (19.0577 iter/s, 5.24722s/100 iters), loss = 0.0524385
I0930 21:14:09.231328  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0524383 (* 1 = 0.0524383 loss)
I0930 21:14:09.231334  4070 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I0930 21:14:14.478061  4070 solver.cpp:218] Iteration 68900 (19.0596 iter/s, 5.24671s/100 iters), loss = 0.0140838
I0930 21:14:14.478091  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140835 (* 1 = 0.0140835 loss)
I0930 21:14:14.478097  4070 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I0930 21:14:19.451817  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:14:19.660580  4070 solver.cpp:330] Iteration 69000, Testing net (#0)
I0930 21:14:20.856096  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:14:20.906116  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.888
I0930 21:14:20.906162  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413804 (* 1 = 0.413804 loss)
I0930 21:14:20.958837  4070 solver.cpp:218] Iteration 69000 (15.4304 iter/s, 6.48072s/100 iters), loss = 0.0308553
I0930 21:14:20.958861  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030855 (* 1 = 0.030855 loss)
I0930 21:14:20.958868  4070 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I0930 21:14:26.209043  4070 solver.cpp:218] Iteration 69100 (19.047 iter/s, 5.25016s/100 iters), loss = 0.0959039
I0930 21:14:26.209076  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0959037 (* 1 = 0.0959037 loss)
I0930 21:14:26.209094  4070 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I0930 21:14:31.449784  4070 solver.cpp:218] Iteration 69200 (19.0815 iter/s, 5.24068s/100 iters), loss = 0.0762642
I0930 21:14:31.449813  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0762639 (* 1 = 0.0762639 loss)
I0930 21:14:31.449829  4070 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I0930 21:14:36.698000  4070 solver.cpp:218] Iteration 69300 (19.0543 iter/s, 5.24817s/100 iters), loss = 0.0348765
I0930 21:14:36.698030  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348762 (* 1 = 0.0348762 loss)
I0930 21:14:36.698046  4070 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I0930 21:14:41.948215  4070 solver.cpp:218] Iteration 69400 (19.047 iter/s, 5.25016s/100 iters), loss = 0.0402531
I0930 21:14:41.948245  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402529 (* 1 = 0.0402529 loss)
I0930 21:14:41.948259  4070 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I0930 21:14:46.925307  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:14:47.139941  4070 solver.cpp:330] Iteration 69500, Testing net (#0)
I0930 21:14:48.326844  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:14:48.376873  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8856
I0930 21:14:48.376906  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.466405 (* 1 = 0.466405 loss)
I0930 21:14:48.429363  4070 solver.cpp:218] Iteration 69500 (15.4295 iter/s, 6.4811s/100 iters), loss = 0.0194343
I0930 21:14:48.429397  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019434 (* 1 = 0.019434 loss)
I0930 21:14:48.429404  4070 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I0930 21:14:53.675979  4070 solver.cpp:218] Iteration 69600 (19.0601 iter/s, 5.24656s/100 iters), loss = 0.0631073
I0930 21:14:53.676095  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0631071 (* 1 = 0.0631071 loss)
I0930 21:14:53.676103  4070 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I0930 21:14:58.916519  4070 solver.cpp:218] Iteration 69700 (19.0825 iter/s, 5.24041s/100 iters), loss = 0.0336551
I0930 21:14:58.916568  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336548 (* 1 = 0.0336548 loss)
I0930 21:14:58.916575  4070 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I0930 21:15:04.169545  4070 solver.cpp:218] Iteration 69800 (19.0369 iter/s, 5.25296s/100 iters), loss = 0.0340258
I0930 21:15:04.169576  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340256 (* 1 = 0.0340256 loss)
I0930 21:15:04.169584  4070 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I0930 21:15:09.420240  4070 solver.cpp:218] Iteration 69900 (19.0453 iter/s, 5.25064s/100 iters), loss = 0.0539152
I0930 21:15:09.420281  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0539149 (* 1 = 0.0539149 loss)
I0930 21:15:09.420289  4070 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I0930 21:15:14.410629  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:15:14.620898  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_70000.caffemodel
I0930 21:15:14.626045  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_70000.solverstate
I0930 21:15:14.627447  4070 solver.cpp:330] Iteration 70000, Testing net (#0)
I0930 21:15:15.811797  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:15:15.862238  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8829
I0930 21:15:15.862272  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477212 (* 1 = 0.477212 loss)
I0930 21:15:15.914902  4070 solver.cpp:218] Iteration 70000 (15.3974 iter/s, 6.4946s/100 iters), loss = 0.0168525
I0930 21:15:15.914929  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168522 (* 1 = 0.0168522 loss)
I0930 21:15:15.914937  4070 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I0930 21:15:21.167481  4070 solver.cpp:218] Iteration 70100 (19.0384 iter/s, 5.25253s/100 iters), loss = 0.0176766
I0930 21:15:21.167520  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176763 (* 1 = 0.0176763 loss)
I0930 21:15:21.167526  4070 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I0930 21:15:26.415736  4070 solver.cpp:218] Iteration 70200 (19.0542 iter/s, 5.2482s/100 iters), loss = 0.0745529
I0930 21:15:26.415896  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0745526 (* 1 = 0.0745526 loss)
I0930 21:15:26.415904  4070 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I0930 21:15:31.655541  4070 solver.cpp:218] Iteration 70300 (19.0853 iter/s, 5.23963s/100 iters), loss = 0.0446202
I0930 21:15:31.655571  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04462 (* 1 = 0.04462 loss)
I0930 21:15:31.655577  4070 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I0930 21:15:36.901468  4070 solver.cpp:218] Iteration 70400 (19.0626 iter/s, 5.24588s/100 iters), loss = 0.0559849
I0930 21:15:36.901495  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559846 (* 1 = 0.0559846 loss)
I0930 21:15:36.901501  4070 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I0930 21:15:41.882686  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:15:42.091363  4070 solver.cpp:330] Iteration 70500, Testing net (#0)
I0930 21:15:43.276832  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:15:43.326808  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8957
I0930 21:15:43.326843  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394648 (* 1 = 0.394648 loss)
I0930 21:15:43.379828  4070 solver.cpp:218] Iteration 70500 (15.4361 iter/s, 6.47831s/100 iters), loss = 0.0306843
I0930 21:15:43.379855  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030684 (* 1 = 0.030684 loss)
I0930 21:15:43.379861  4070 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I0930 21:15:48.625408  4070 solver.cpp:218] Iteration 70600 (19.0638 iter/s, 5.24554s/100 iters), loss = 0.0295364
I0930 21:15:48.625437  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295361 (* 1 = 0.0295361 loss)
I0930 21:15:48.625443  4070 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I0930 21:15:53.873085  4070 solver.cpp:218] Iteration 70700 (19.0562 iter/s, 5.24763s/100 iters), loss = 0.0242751
I0930 21:15:53.873113  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242748 (* 1 = 0.0242748 loss)
I0930 21:15:53.873119  4070 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I0930 21:15:59.119024  4070 solver.cpp:218] Iteration 70800 (19.0625 iter/s, 5.24589s/100 iters), loss = 0.0479978
I0930 21:15:59.119199  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479975 (* 1 = 0.0479975 loss)
I0930 21:15:59.119217  4070 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I0930 21:16:04.363919  4070 solver.cpp:218] Iteration 70900 (19.0669 iter/s, 5.24468s/100 iters), loss = 0.0526494
I0930 21:16:04.363948  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.052649 (* 1 = 0.052649 loss)
I0930 21:16:04.363955  4070 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I0930 21:16:09.350067  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:16:09.560415  4070 solver.cpp:330] Iteration 71000, Testing net (#0)
I0930 21:16:10.743955  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:16:10.793864  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8942
I0930 21:16:10.793900  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.397767 (* 1 = 0.397767 loss)
I0930 21:16:10.846601  4070 solver.cpp:218] Iteration 71000 (15.4258 iter/s, 6.48263s/100 iters), loss = 0.0125153
I0930 21:16:10.846624  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125149 (* 1 = 0.0125149 loss)
I0930 21:16:10.846632  4070 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I0930 21:16:16.098824  4070 solver.cpp:218] Iteration 71100 (19.0397 iter/s, 5.25218s/100 iters), loss = 0.0397821
I0930 21:16:16.098853  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397818 (* 1 = 0.0397818 loss)
I0930 21:16:16.098860  4070 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I0930 21:16:21.343582  4070 solver.cpp:218] Iteration 71200 (19.0668 iter/s, 5.24471s/100 iters), loss = 0.0566671
I0930 21:16:21.343611  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0566668 (* 1 = 0.0566668 loss)
I0930 21:16:21.343616  4070 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I0930 21:16:26.583099  4070 solver.cpp:218] Iteration 71300 (19.0859 iter/s, 5.23947s/100 iters), loss = 0.05901
I0930 21:16:26.583128  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0590097 (* 1 = 0.0590097 loss)
I0930 21:16:26.583134  4070 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I0930 21:16:31.818537  4070 solver.cpp:218] Iteration 71400 (19.1008 iter/s, 5.23539s/100 iters), loss = 0.0292586
I0930 21:16:31.818671  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292583 (* 1 = 0.0292583 loss)
I0930 21:16:31.818689  4070 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I0930 21:16:36.800616  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:16:37.010437  4070 solver.cpp:330] Iteration 71500, Testing net (#0)
I0930 21:16:38.202926  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:16:38.252810  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8829
I0930 21:16:38.252835  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.482336 (* 1 = 0.482336 loss)
I0930 21:16:38.305174  4070 solver.cpp:218] Iteration 71500 (15.4167 iter/s, 6.48649s/100 iters), loss = 0.0353298
I0930 21:16:38.305207  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353295 (* 1 = 0.0353295 loss)
I0930 21:16:38.305213  4070 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I0930 21:16:43.544875  4070 solver.cpp:218] Iteration 71600 (19.0853 iter/s, 5.23964s/100 iters), loss = 0.0330194
I0930 21:16:43.544914  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033019 (* 1 = 0.033019 loss)
I0930 21:16:43.544919  4070 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I0930 21:16:48.791426  4070 solver.cpp:218] Iteration 71700 (19.0604 iter/s, 5.24649s/100 iters), loss = 0.0936187
I0930 21:16:48.791465  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0936184 (* 1 = 0.0936184 loss)
I0930 21:16:48.791471  4070 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I0930 21:16:54.039111  4070 solver.cpp:218] Iteration 71800 (19.0562 iter/s, 5.24763s/100 iters), loss = 0.0694452
I0930 21:16:54.039139  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0694448 (* 1 = 0.0694448 loss)
I0930 21:16:54.039145  4070 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I0930 21:16:59.283772  4070 solver.cpp:218] Iteration 71900 (19.0672 iter/s, 5.24461s/100 iters), loss = 0.0296829
I0930 21:16:59.283812  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296826 (* 1 = 0.0296826 loss)
I0930 21:16:59.283819  4070 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I0930 21:17:04.260279  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:17:04.473904  4070 solver.cpp:330] Iteration 72000, Testing net (#0)
I0930 21:17:05.668567  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:17:05.718118  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8929
I0930 21:17:05.718152  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.41257 (* 1 = 0.41257 loss)
I0930 21:17:05.770795  4070 solver.cpp:218] Iteration 72000 (15.4155 iter/s, 6.48696s/100 iters), loss = 0.0553634
I0930 21:17:05.770818  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553631 (* 1 = 0.0553631 loss)
I0930 21:17:05.770825  4070 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I0930 21:17:11.010356  4070 solver.cpp:218] Iteration 72100 (19.0857 iter/s, 5.23951s/100 iters), loss = 0.0362963
I0930 21:17:11.010402  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036296 (* 1 = 0.036296 loss)
I0930 21:17:11.010411  4070 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I0930 21:17:16.251487  4070 solver.cpp:218] Iteration 72200 (19.0802 iter/s, 5.24103s/100 iters), loss = 0.0425336
I0930 21:17:16.251528  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0425333 (* 1 = 0.0425333 loss)
I0930 21:17:16.251533  4070 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I0930 21:17:21.492182  4070 solver.cpp:218] Iteration 72300 (19.0817 iter/s, 5.24063s/100 iters), loss = 0.0307228
I0930 21:17:21.492211  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307225 (* 1 = 0.0307225 loss)
I0930 21:17:21.492218  4070 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I0930 21:17:26.733822  4070 solver.cpp:218] Iteration 72400 (19.0782 iter/s, 5.24159s/100 iters), loss = 0.0156743
I0930 21:17:26.733861  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015674 (* 1 = 0.015674 loss)
I0930 21:17:26.733867  4070 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I0930 21:17:31.709172  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:17:31.919912  4070 solver.cpp:330] Iteration 72500, Testing net (#0)
I0930 21:17:33.113243  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:17:33.163383  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8942
I0930 21:17:33.163416  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.407338 (* 1 = 0.407338 loss)
I0930 21:17:33.215595  4070 solver.cpp:218] Iteration 72500 (15.428 iter/s, 6.48172s/100 iters), loss = 0.016707
I0930 21:17:33.215620  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167067 (* 1 = 0.0167067 loss)
I0930 21:17:33.215627  4070 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I0930 21:17:38.467784  4070 solver.cpp:218] Iteration 72600 (19.0398 iter/s, 5.25214s/100 iters), loss = 0.0466554
I0930 21:17:38.467929  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466551 (* 1 = 0.0466551 loss)
I0930 21:17:38.467938  4070 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I0930 21:17:43.708160  4070 solver.cpp:218] Iteration 72700 (19.0832 iter/s, 5.24022s/100 iters), loss = 0.0183629
I0930 21:17:43.708190  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183625 (* 1 = 0.0183625 loss)
I0930 21:17:43.708206  4070 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I0930 21:17:48.957283  4070 solver.cpp:218] Iteration 72800 (19.051 iter/s, 5.24907s/100 iters), loss = 0.0355961
I0930 21:17:48.957322  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355957 (* 1 = 0.0355957 loss)
I0930 21:17:48.957329  4070 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I0930 21:17:54.208010  4070 solver.cpp:218] Iteration 72900 (19.0452 iter/s, 5.25067s/100 iters), loss = 0.0397076
I0930 21:17:54.208050  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397072 (* 1 = 0.0397072 loss)
I0930 21:17:54.208055  4070 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I0930 21:17:59.190547  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:17:59.402055  4070 solver.cpp:330] Iteration 73000, Testing net (#0)
I0930 21:18:00.587443  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:18:00.637257  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8829
I0930 21:18:00.637292  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.4813 (* 1 = 0.4813 loss)
I0930 21:18:00.689604  4070 solver.cpp:218] Iteration 73000 (15.4284 iter/s, 6.48154s/100 iters), loss = 0.0203978
I0930 21:18:00.689630  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203975 (* 1 = 0.0203975 loss)
I0930 21:18:00.689647  4070 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I0930 21:18:05.935443  4070 solver.cpp:218] Iteration 73100 (19.0629 iter/s, 5.24579s/100 iters), loss = 0.0320458
I0930 21:18:05.935474  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320454 (* 1 = 0.0320454 loss)
I0930 21:18:05.935480  4070 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I0930 21:18:11.178355  4070 solver.cpp:218] Iteration 73200 (19.0736 iter/s, 5.24285s/100 iters), loss = 0.0192364
I0930 21:18:11.178529  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019236 (* 1 = 0.019236 loss)
I0930 21:18:11.178539  4070 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I0930 21:18:16.417702  4070 solver.cpp:218] Iteration 73300 (19.087 iter/s, 5.23916s/100 iters), loss = 0.0147967
I0930 21:18:16.417742  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147963 (* 1 = 0.0147963 loss)
I0930 21:18:16.417747  4070 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I0930 21:18:21.668792  4070 solver.cpp:218] Iteration 73400 (19.0439 iter/s, 5.25103s/100 iters), loss = 0.0762981
I0930 21:18:21.668831  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0762978 (* 1 = 0.0762978 loss)
I0930 21:18:21.668838  4070 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I0930 21:18:26.654841  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:18:26.865366  4070 solver.cpp:330] Iteration 73500, Testing net (#0)
I0930 21:18:28.049697  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:18:28.099620  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I0930 21:18:28.099654  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406666 (* 1 = 0.406666 loss)
I0930 21:18:28.152103  4070 solver.cpp:218] Iteration 73500 (15.4244 iter/s, 6.48325s/100 iters), loss = 0.103314
I0930 21:18:28.152127  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103313 (* 1 = 0.103313 loss)
I0930 21:18:28.152134  4070 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I0930 21:18:33.401964  4070 solver.cpp:218] Iteration 73600 (19.0483 iter/s, 5.24981s/100 iters), loss = 0.0197127
I0930 21:18:33.402004  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197123 (* 1 = 0.0197123 loss)
I0930 21:18:33.402009  4070 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I0930 21:18:38.648852  4070 solver.cpp:218] Iteration 73700 (19.0591 iter/s, 5.24683s/100 iters), loss = 0.0331564
I0930 21:18:38.648883  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331561 (* 1 = 0.0331561 loss)
I0930 21:18:38.648891  4070 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I0930 21:18:43.887596  4070 solver.cpp:218] Iteration 73800 (19.0887 iter/s, 5.23869s/100 iters), loss = 0.0101899
I0930 21:18:43.887725  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101896 (* 1 = 0.0101896 loss)
I0930 21:18:43.887744  4070 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I0930 21:18:49.134272  4070 solver.cpp:218] Iteration 73900 (19.0602 iter/s, 5.24654s/100 iters), loss = 0.0378487
I0930 21:18:49.134301  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0378483 (* 1 = 0.0378483 loss)
I0930 21:18:49.134307  4070 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I0930 21:18:54.113078  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:18:54.322371  4070 solver.cpp:330] Iteration 74000, Testing net (#0)
I0930 21:18:55.509291  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:18:55.559577  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8874
I0930 21:18:55.559603  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.441081 (* 1 = 0.441081 loss)
I0930 21:18:55.612265  4070 solver.cpp:218] Iteration 74000 (15.437 iter/s, 6.47795s/100 iters), loss = 0.0140125
I0930 21:18:55.612298  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140121 (* 1 = 0.0140121 loss)
I0930 21:18:55.612320  4070 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I0930 21:19:00.856326  4070 solver.cpp:218] Iteration 74100 (19.0694 iter/s, 5.24401s/100 iters), loss = 0.0843552
I0930 21:19:00.856359  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0843549 (* 1 = 0.0843549 loss)
I0930 21:19:00.856366  4070 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I0930 21:19:06.106910  4070 solver.cpp:218] Iteration 74200 (19.0457 iter/s, 5.25054s/100 iters), loss = 0.0185774
I0930 21:19:06.106945  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185771 (* 1 = 0.0185771 loss)
I0930 21:19:06.106962  4070 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I0930 21:19:11.357653  4070 solver.cpp:218] Iteration 74300 (19.0451 iter/s, 5.25069s/100 iters), loss = 0.0589815
I0930 21:19:11.357688  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589811 (* 1 = 0.0589811 loss)
I0930 21:19:11.357697  4070 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I0930 21:19:16.599426  4070 solver.cpp:218] Iteration 74400 (19.0777 iter/s, 5.24172s/100 iters), loss = 0.00944791
I0930 21:19:16.599560  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00944756 (* 1 = 0.00944756 loss)
I0930 21:19:16.599577  4070 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I0930 21:19:21.585901  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:19:21.794672  4070 solver.cpp:330] Iteration 74500, Testing net (#0)
I0930 21:19:22.982987  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:19:23.034195  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8861
I0930 21:19:23.034222  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.443166 (* 1 = 0.443166 loss)
I0930 21:19:23.089112  4070 solver.cpp:218] Iteration 74500 (15.4094 iter/s, 6.48954s/100 iters), loss = 0.0166891
I0930 21:19:23.089149  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166887 (* 1 = 0.0166887 loss)
I0930 21:19:23.089169  4070 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I0930 21:19:28.330927  4070 solver.cpp:218] Iteration 74600 (19.0777 iter/s, 5.24172s/100 iters), loss = 0.0225442
I0930 21:19:28.330957  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225438 (* 1 = 0.0225438 loss)
I0930 21:19:28.330965  4070 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I0930 21:19:33.580787  4070 solver.cpp:218] Iteration 74700 (19.0483 iter/s, 5.24981s/100 iters), loss = 0.0955968
I0930 21:19:33.580819  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0955965 (* 1 = 0.0955965 loss)
I0930 21:19:33.580837  4070 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I0930 21:19:38.823441  4070 solver.cpp:218] Iteration 74800 (19.0745 iter/s, 5.2426s/100 iters), loss = 0.038274
I0930 21:19:38.823473  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382737 (* 1 = 0.0382737 loss)
I0930 21:19:38.823482  4070 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I0930 21:19:44.063076  4070 solver.cpp:218] Iteration 74900 (19.0855 iter/s, 5.23958s/100 iters), loss = 0.0488654
I0930 21:19:44.063114  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488651 (* 1 = 0.0488651 loss)
I0930 21:19:44.063133  4070 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I0930 21:19:49.039125  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:19:49.248620  4070 solver.cpp:330] Iteration 75000, Testing net (#0)
I0930 21:19:50.441323  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:19:50.491333  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8886
I0930 21:19:50.491360  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426011 (* 1 = 0.426011 loss)
I0930 21:19:50.544023  4070 solver.cpp:218] Iteration 75000 (15.43 iter/s, 6.48089s/100 iters), loss = 0.0419112
I0930 21:19:50.544054  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0419109 (* 1 = 0.0419109 loss)
I0930 21:19:50.544064  4070 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I0930 21:19:55.785928  4070 solver.cpp:218] Iteration 75100 (19.0772 iter/s, 5.24186s/100 iters), loss = 0.0401243
I0930 21:19:55.785961  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040124 (* 1 = 0.040124 loss)
I0930 21:19:55.785979  4070 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I0930 21:20:01.034332  4070 solver.cpp:218] Iteration 75200 (19.0536 iter/s, 5.24835s/100 iters), loss = 0.0455161
I0930 21:20:01.034373  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455158 (* 1 = 0.0455158 loss)
I0930 21:20:01.034379  4070 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I0930 21:20:06.278048  4070 solver.cpp:218] Iteration 75300 (19.0707 iter/s, 5.24366s/100 iters), loss = 0.0363386
I0930 21:20:06.278087  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363383 (* 1 = 0.0363383 loss)
I0930 21:20:06.278093  4070 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I0930 21:20:11.518688  4070 solver.cpp:218] Iteration 75400 (19.0819 iter/s, 5.24058s/100 iters), loss = 0.0199152
I0930 21:20:11.518719  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199149 (* 1 = 0.0199149 loss)
I0930 21:20:11.518725  4070 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I0930 21:20:16.494413  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:20:16.703227  4070 solver.cpp:330] Iteration 75500, Testing net (#0)
I0930 21:20:17.896646  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:20:17.946549  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8939
I0930 21:20:17.946584  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405738 (* 1 = 0.405738 loss)
I0930 21:20:17.998937  4070 solver.cpp:218] Iteration 75500 (15.4316 iter/s, 6.4802s/100 iters), loss = 0.00726305
I0930 21:20:17.998970  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00726272 (* 1 = 0.00726272 loss)
I0930 21:20:17.998976  4070 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I0930 21:20:23.243522  4070 solver.cpp:218] Iteration 75600 (19.0675 iter/s, 5.24453s/100 iters), loss = 0.057072
I0930 21:20:23.243681  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0570716 (* 1 = 0.0570716 loss)
I0930 21:20:23.243691  4070 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I0930 21:20:28.481894  4070 solver.cpp:218] Iteration 75700 (19.0905 iter/s, 5.23821s/100 iters), loss = 0.0458447
I0930 21:20:28.481935  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0458443 (* 1 = 0.0458443 loss)
I0930 21:20:28.481940  4070 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I0930 21:20:33.728386  4070 solver.cpp:218] Iteration 75800 (19.0606 iter/s, 5.24643s/100 iters), loss = 0.0778586
I0930 21:20:33.728428  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0778582 (* 1 = 0.0778582 loss)
I0930 21:20:33.728435  4070 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I0930 21:20:38.966361  4070 solver.cpp:218] Iteration 75900 (19.0916 iter/s, 5.23791s/100 iters), loss = 0.043157
I0930 21:20:38.966392  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0431567 (* 1 = 0.0431567 loss)
I0930 21:20:38.966408  4070 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I0930 21:20:43.939412  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:20:44.156445  4070 solver.cpp:330] Iteration 76000, Testing net (#0)
I0930 21:20:45.345084  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:20:45.395206  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8978
I0930 21:20:45.395232  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398746 (* 1 = 0.398746 loss)
I0930 21:20:45.447489  4070 solver.cpp:218] Iteration 76000 (15.4295 iter/s, 6.48108s/100 iters), loss = 0.0104504
I0930 21:20:45.447521  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01045 (* 1 = 0.01045 loss)
I0930 21:20:45.447530  4070 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I0930 21:20:50.693058  4070 solver.cpp:218] Iteration 76100 (19.0639 iter/s, 5.24552s/100 iters), loss = 0.111065
I0930 21:20:50.693090  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111065 (* 1 = 0.111065 loss)
I0930 21:20:50.693109  4070 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I0930 21:20:55.931082  4070 solver.cpp:218] Iteration 76200 (19.0914 iter/s, 5.23797s/100 iters), loss = 0.0690576
I0930 21:20:55.931226  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0690572 (* 1 = 0.0690572 loss)
I0930 21:20:55.931273  4070 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I0930 21:21:01.179348  4070 solver.cpp:218] Iteration 76300 (19.0545 iter/s, 5.24811s/100 iters), loss = 0.0564781
I0930 21:21:01.179379  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0564778 (* 1 = 0.0564778 loss)
I0930 21:21:01.179399  4070 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I0930 21:21:06.424836  4070 solver.cpp:218] Iteration 76400 (19.0642 iter/s, 5.24544s/100 iters), loss = 0.0125425
I0930 21:21:06.424868  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125422 (* 1 = 0.0125422 loss)
I0930 21:21:06.424876  4070 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I0930 21:21:11.402501  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:21:11.610769  4070 solver.cpp:330] Iteration 76500, Testing net (#0)
I0930 21:21:12.794179  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:21:12.843925  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8947
I0930 21:21:12.843950  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.401703 (* 1 = 0.401703 loss)
I0930 21:21:12.896446  4070 solver.cpp:218] Iteration 76500 (15.4522 iter/s, 6.47156s/100 iters), loss = 0.0340248
I0930 21:21:12.896469  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340245 (* 1 = 0.0340245 loss)
I0930 21:21:12.896476  4070 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I0930 21:21:18.139338  4070 solver.cpp:218] Iteration 76600 (19.0736 iter/s, 5.24285s/100 iters), loss = 0.0181925
I0930 21:21:18.139366  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181922 (* 1 = 0.0181922 loss)
I0930 21:21:18.139372  4070 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I0930 21:21:23.380466  4070 solver.cpp:218] Iteration 76700 (19.08 iter/s, 5.24108s/100 iters), loss = 0.0447755
I0930 21:21:23.380496  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447751 (* 1 = 0.0447751 loss)
I0930 21:21:23.380501  4070 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I0930 21:21:28.615880  4070 solver.cpp:218] Iteration 76800 (19.1009 iter/s, 5.23536s/100 iters), loss = 0.0552788
I0930 21:21:28.616005  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552784 (* 1 = 0.0552784 loss)
I0930 21:21:28.616024  4070 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I0930 21:21:33.866547  4070 solver.cpp:218] Iteration 76900 (19.0457 iter/s, 5.25052s/100 iters), loss = 0.0122493
I0930 21:21:33.866595  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012249 (* 1 = 0.012249 loss)
I0930 21:21:33.866601  4070 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I0930 21:21:38.860234  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:21:39.070729  4070 solver.cpp:330] Iteration 77000, Testing net (#0)
I0930 21:21:40.257221  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:21:40.306752  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8772
I0930 21:21:40.306777  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.48177 (* 1 = 0.48177 loss)
I0930 21:21:40.359462  4070 solver.cpp:218] Iteration 77000 (15.4016 iter/s, 6.49285s/100 iters), loss = 0.0334588
I0930 21:21:40.359490  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334585 (* 1 = 0.0334585 loss)
I0930 21:21:40.359498  4070 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I0930 21:21:45.605490  4070 solver.cpp:218] Iteration 77100 (19.0622 iter/s, 5.24598s/100 iters), loss = 0.0103913
I0930 21:21:45.605521  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010391 (* 1 = 0.010391 loss)
I0930 21:21:45.605526  4070 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I0930 21:21:50.858541  4070 solver.cpp:218] Iteration 77200 (19.0368 iter/s, 5.25299s/100 iters), loss = 0.0578908
I0930 21:21:50.858582  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0578905 (* 1 = 0.0578905 loss)
I0930 21:21:50.858588  4070 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I0930 21:21:56.102597  4070 solver.cpp:218] Iteration 77300 (19.0694 iter/s, 5.24399s/100 iters), loss = 0.0429339
I0930 21:21:56.102632  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0429336 (* 1 = 0.0429336 loss)
I0930 21:21:56.102639  4070 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I0930 21:22:01.338105  4070 solver.cpp:218] Iteration 77400 (19.1007 iter/s, 5.23542s/100 iters), loss = 0.0203116
I0930 21:22:01.338212  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203113 (* 1 = 0.0203113 loss)
I0930 21:22:01.338228  4070 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I0930 21:22:06.321460  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:22:06.530714  4070 solver.cpp:330] Iteration 77500, Testing net (#0)
I0930 21:22:07.716616  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:22:07.766619  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I0930 21:22:07.766644  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42309 (* 1 = 0.42309 loss)
I0930 21:22:07.818946  4070 solver.cpp:218] Iteration 77500 (15.4304 iter/s, 6.48072s/100 iters), loss = 0.0320944
I0930 21:22:07.818974  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320941 (* 1 = 0.0320941 loss)
I0930 21:22:07.818981  4070 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I0930 21:22:13.059216  4070 solver.cpp:218] Iteration 77600 (19.0832 iter/s, 5.24022s/100 iters), loss = 0.0144603
I0930 21:22:13.059249  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01446 (* 1 = 0.01446 loss)
I0930 21:22:13.059258  4070 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I0930 21:22:18.310137  4070 solver.cpp:218] Iteration 77700 (19.0445 iter/s, 5.25087s/100 iters), loss = 0.0659265
I0930 21:22:18.310168  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0659262 (* 1 = 0.0659262 loss)
I0930 21:22:18.310186  4070 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I0930 21:22:23.559074  4070 solver.cpp:218] Iteration 77800 (19.0517 iter/s, 5.24889s/100 iters), loss = 0.0710909
I0930 21:22:23.559114  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0710907 (* 1 = 0.0710907 loss)
I0930 21:22:23.559120  4070 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I0930 21:22:28.799849  4070 solver.cpp:218] Iteration 77900 (19.0814 iter/s, 5.24072s/100 iters), loss = 0.00824153
I0930 21:22:28.799888  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0082413 (* 1 = 0.0082413 loss)
I0930 21:22:28.799895  4070 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I0930 21:22:33.788705  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:22:33.999035  4070 solver.cpp:330] Iteration 78000, Testing net (#0)
I0930 21:22:35.190729  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:22:35.241920  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8892
I0930 21:22:35.241955  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.432746 (* 1 = 0.432746 loss)
I0930 21:22:35.294548  4070 solver.cpp:218] Iteration 78000 (15.3973 iter/s, 6.49464s/100 iters), loss = 0.014474
I0930 21:22:35.294584  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144738 (* 1 = 0.0144738 loss)
I0930 21:22:35.294591  4070 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I0930 21:22:40.531726  4070 solver.cpp:218] Iteration 78100 (19.0944 iter/s, 5.23713s/100 iters), loss = 0.0497657
I0930 21:22:40.531766  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497655 (* 1 = 0.0497655 loss)
I0930 21:22:40.531772  4070 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I0930 21:22:45.776947  4070 solver.cpp:218] Iteration 78200 (19.0652 iter/s, 5.24516s/100 iters), loss = 0.0297112
I0930 21:22:45.776985  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029711 (* 1 = 0.029711 loss)
I0930 21:22:45.776991  4070 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I0930 21:22:51.024600  4070 solver.cpp:218] Iteration 78300 (19.0563 iter/s, 5.24759s/100 iters), loss = 0.0487677
I0930 21:22:51.024628  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0487674 (* 1 = 0.0487674 loss)
I0930 21:22:51.024634  4070 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I0930 21:22:56.268342  4070 solver.cpp:218] Iteration 78400 (19.0705 iter/s, 5.24369s/100 iters), loss = 0.0432459
I0930 21:22:56.268373  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432457 (* 1 = 0.0432457 loss)
I0930 21:22:56.268380  4070 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I0930 21:23:01.242108  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:23:01.451961  4070 solver.cpp:330] Iteration 78500, Testing net (#0)
I0930 21:23:02.645329  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:23:02.695657  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8871
I0930 21:23:02.695691  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.423923 (* 1 = 0.423923 loss)
I0930 21:23:02.748741  4070 solver.cpp:218] Iteration 78500 (15.4313 iter/s, 6.48035s/100 iters), loss = 0.0344483
I0930 21:23:02.748769  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344481 (* 1 = 0.0344481 loss)
I0930 21:23:02.748776  4070 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I0930 21:23:07.992187  4070 solver.cpp:218] Iteration 78600 (19.0716 iter/s, 5.2434s/100 iters), loss = 0.0162606
I0930 21:23:07.992312  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162603 (* 1 = 0.0162603 loss)
I0930 21:23:07.992331  4070 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I0930 21:23:13.237675  4070 solver.cpp:218] Iteration 78700 (19.0645 iter/s, 5.24535s/100 iters), loss = 0.0237652
I0930 21:23:13.237705  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023765 (* 1 = 0.023765 loss)
I0930 21:23:13.237721  4070 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I0930 21:23:18.489574  4070 solver.cpp:218] Iteration 78800 (19.0409 iter/s, 5.25185s/100 iters), loss = 0.0241193
I0930 21:23:18.489614  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241191 (* 1 = 0.0241191 loss)
I0930 21:23:18.489619  4070 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I0930 21:23:23.739611  4070 solver.cpp:218] Iteration 78900 (19.0477 iter/s, 5.24998s/100 iters), loss = 0.0253323
I0930 21:23:23.739641  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025332 (* 1 = 0.025332 loss)
I0930 21:23:23.739647  4070 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I0930 21:23:28.714944  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:23:28.924471  4070 solver.cpp:330] Iteration 79000, Testing net (#0)
I0930 21:23:30.115916  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:23:30.166013  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8916
I0930 21:23:30.166038  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.419893 (* 1 = 0.419893 loss)
I0930 21:23:30.218387  4070 solver.cpp:218] Iteration 79000 (15.4351 iter/s, 6.47873s/100 iters), loss = 0.0262567
I0930 21:23:30.218413  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262564 (* 1 = 0.0262564 loss)
I0930 21:23:30.218420  4070 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I0930 21:23:35.468260  4070 solver.cpp:218] Iteration 79100 (19.0483 iter/s, 5.24983s/100 iters), loss = 0.0493713
I0930 21:23:35.468288  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493711 (* 1 = 0.0493711 loss)
I0930 21:23:35.468294  4070 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I0930 21:23:40.707968  4070 solver.cpp:218] Iteration 79200 (19.0852 iter/s, 5.23966s/100 iters), loss = 0.0575678
I0930 21:23:40.708106  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575676 (* 1 = 0.0575676 loss)
I0930 21:23:40.708123  4070 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I0930 21:23:45.951884  4070 solver.cpp:218] Iteration 79300 (19.0702 iter/s, 5.24377s/100 iters), loss = 0.0222686
I0930 21:23:45.951925  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222684 (* 1 = 0.0222684 loss)
I0930 21:23:45.951930  4070 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I0930 21:23:51.198864  4070 solver.cpp:218] Iteration 79400 (19.0588 iter/s, 5.24692s/100 iters), loss = 0.0159351
I0930 21:23:51.198897  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159348 (* 1 = 0.0159348 loss)
I0930 21:23:51.198905  4070 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I0930 21:23:56.185887  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:23:56.396931  4070 solver.cpp:330] Iteration 79500, Testing net (#0)
I0930 21:23:57.582731  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:23:57.632654  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8968
I0930 21:23:57.632679  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.411657 (* 1 = 0.411657 loss)
I0930 21:23:57.685547  4070 solver.cpp:218] Iteration 79500 (15.4163 iter/s, 6.48663s/100 iters), loss = 0.0337331
I0930 21:23:57.685573  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337328 (* 1 = 0.0337328 loss)
I0930 21:23:57.685583  4070 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I0930 21:24:02.929466  4070 solver.cpp:218] Iteration 79600 (19.0699 iter/s, 5.24387s/100 iters), loss = 0.040428
I0930 21:24:02.929500  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404277 (* 1 = 0.0404277 loss)
I0930 21:24:02.929509  4070 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I0930 21:24:08.178154  4070 solver.cpp:218] Iteration 79700 (19.0526 iter/s, 5.24863s/100 iters), loss = 0.0314358
I0930 21:24:08.178189  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314355 (* 1 = 0.0314355 loss)
I0930 21:24:08.178195  4070 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I0930 21:24:13.416199  4070 solver.cpp:218] Iteration 79800 (19.0913 iter/s, 5.23799s/100 iters), loss = 0.0230067
I0930 21:24:13.416313  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230064 (* 1 = 0.0230064 loss)
I0930 21:24:13.416339  4070 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I0930 21:24:18.660791  4070 solver.cpp:218] Iteration 79900 (19.0677 iter/s, 5.24447s/100 iters), loss = 0.0660435
I0930 21:24:18.660826  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660432 (* 1 = 0.0660432 loss)
I0930 21:24:18.660835  4070 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I0930 21:24:23.638916  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:24:23.848716  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_80000.caffemodel
I0930 21:24:23.853602  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_80000.solverstate
I0930 21:24:23.854893  4070 solver.cpp:330] Iteration 80000, Testing net (#0)
I0930 21:24:25.039592  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:24:25.089570  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8832
I0930 21:24:25.089604  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.487704 (* 1 = 0.487704 loss)
I0930 21:24:25.142140  4070 solver.cpp:218] Iteration 80000 (15.429 iter/s, 6.4813s/100 iters), loss = 0.0363301
I0930 21:24:25.142166  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363299 (* 1 = 0.0363299 loss)
I0930 21:24:25.142172  4070 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I0930 21:24:25.142175  4070 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0930 21:24:30.385555  4070 solver.cpp:218] Iteration 80100 (19.0717 iter/s, 5.24337s/100 iters), loss = 0.052942
I0930 21:24:30.385593  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0529417 (* 1 = 0.0529417 loss)
I0930 21:24:30.385599  4070 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0930 21:24:35.629920  4070 solver.cpp:218] Iteration 80200 (19.0683 iter/s, 5.24431s/100 iters), loss = 0.0706395
I0930 21:24:35.629948  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0706392 (* 1 = 0.0706392 loss)
I0930 21:24:35.629954  4070 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0930 21:24:40.870697  4070 solver.cpp:218] Iteration 80300 (19.0813 iter/s, 5.24073s/100 iters), loss = 0.0305559
I0930 21:24:40.870728  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305556 (* 1 = 0.0305556 loss)
I0930 21:24:40.870733  4070 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0930 21:24:46.120251  4070 solver.cpp:218] Iteration 80400 (19.0494 iter/s, 5.24951s/100 iters), loss = 0.00400727
I0930 21:24:46.120396  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400698 (* 1 = 0.00400698 loss)
I0930 21:24:46.120414  4070 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0930 21:24:51.110399  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:24:51.320590  4070 solver.cpp:330] Iteration 80500, Testing net (#0)
I0930 21:24:52.503564  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:24:52.553360  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I0930 21:24:52.553395  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379628 (* 1 = 0.379628 loss)
I0930 21:24:52.605865  4070 solver.cpp:218] Iteration 80500 (15.4191 iter/s, 6.48545s/100 iters), loss = 0.00869867
I0930 21:24:52.605890  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869837 (* 1 = 0.00869837 loss)
I0930 21:24:52.605897  4070 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0930 21:24:57.858074  4070 solver.cpp:218] Iteration 80600 (19.0398 iter/s, 5.25217s/100 iters), loss = 0.0417778
I0930 21:24:57.858114  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417775 (* 1 = 0.0417775 loss)
I0930 21:24:57.858120  4070 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0930 21:25:03.108983  4070 solver.cpp:218] Iteration 80700 (19.0445 iter/s, 5.25085s/100 iters), loss = 0.0177697
I0930 21:25:03.109012  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177694 (* 1 = 0.0177694 loss)
I0930 21:25:03.109019  4070 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0930 21:25:08.359097  4070 solver.cpp:218] Iteration 80800 (19.0474 iter/s, 5.25007s/100 iters), loss = 0.0250519
I0930 21:25:08.359127  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250517 (* 1 = 0.0250517 loss)
I0930 21:25:08.359133  4070 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0930 21:25:13.599328  4070 solver.cpp:218] Iteration 80900 (19.0833 iter/s, 5.24018s/100 iters), loss = 0.00294728
I0930 21:25:13.599370  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294699 (* 1 = 0.00294699 loss)
I0930 21:25:13.599375  4070 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0930 21:25:18.582033  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:25:18.792062  4070 solver.cpp:330] Iteration 81000, Testing net (#0)
I0930 21:25:19.976491  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:25:20.027040  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9053
I0930 21:25:20.027074  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366859 (* 1 = 0.366859 loss)
I0930 21:25:20.081533  4070 solver.cpp:218] Iteration 81000 (15.427 iter/s, 6.48214s/100 iters), loss = 0.0431253
I0930 21:25:20.081578  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043125 (* 1 = 0.043125 loss)
I0930 21:25:20.081585  4070 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0930 21:25:25.323340  4070 solver.cpp:218] Iteration 81100 (19.0777 iter/s, 5.24171s/100 iters), loss = 0.0155192
I0930 21:25:25.323374  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155189 (* 1 = 0.0155189 loss)
I0930 21:25:25.323379  4070 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0930 21:25:30.574662  4070 solver.cpp:218] Iteration 81200 (19.043 iter/s, 5.25127s/100 iters), loss = 0.0667855
I0930 21:25:30.574712  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0667852 (* 1 = 0.0667852 loss)
I0930 21:25:30.574718  4070 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0930 21:25:35.826999  4070 solver.cpp:218] Iteration 81300 (19.0394 iter/s, 5.25227s/100 iters), loss = 0.0640673
I0930 21:25:35.827030  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064067 (* 1 = 0.064067 loss)
I0930 21:25:35.827036  4070 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0930 21:25:41.062860  4070 solver.cpp:218] Iteration 81400 (19.0993 iter/s, 5.23581s/100 iters), loss = 0.0300267
I0930 21:25:41.062896  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300264 (* 1 = 0.0300264 loss)
I0930 21:25:41.062903  4070 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0930 21:25:46.045565  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:25:46.254765  4070 solver.cpp:330] Iteration 81500, Testing net (#0)
I0930 21:25:47.448180  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:25:47.498366  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I0930 21:25:47.498401  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364934 (* 1 = 0.364934 loss)
I0930 21:25:47.551000  4070 solver.cpp:218] Iteration 81500 (15.4129 iter/s, 6.48808s/100 iters), loss = 0.0201999
I0930 21:25:47.551043  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201996 (* 1 = 0.0201996 loss)
I0930 21:25:47.551050  4070 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0930 21:25:52.792057  4070 solver.cpp:218] Iteration 81600 (19.0804 iter/s, 5.24099s/100 iters), loss = 0.0208555
I0930 21:25:52.792186  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208552 (* 1 = 0.0208552 loss)
I0930 21:25:52.792193  4070 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0930 21:25:58.036680  4070 solver.cpp:218] Iteration 81700 (19.0677 iter/s, 5.24448s/100 iters), loss = 0.00788551
I0930 21:25:58.036710  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0078852 (* 1 = 0.0078852 loss)
I0930 21:25:58.036715  4070 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0930 21:26:03.280352  4070 solver.cpp:218] Iteration 81800 (19.0708 iter/s, 5.24362s/100 iters), loss = 0.00996747
I0930 21:26:03.280385  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00996715 (* 1 = 0.00996715 loss)
I0930 21:26:03.280400  4070 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0930 21:26:08.518026  4070 solver.cpp:218] Iteration 81900 (19.0926 iter/s, 5.23762s/100 iters), loss = 0.00845736
I0930 21:26:08.518057  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00845706 (* 1 = 0.00845706 loss)
I0930 21:26:08.518064  4070 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0930 21:26:13.488214  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:26:13.697626  4070 solver.cpp:330] Iteration 82000, Testing net (#0)
I0930 21:26:14.888955  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:26:14.939004  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9075
I0930 21:26:14.939030  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364297 (* 1 = 0.364297 loss)
I0930 21:26:14.991869  4070 solver.cpp:218] Iteration 82000 (15.4469 iter/s, 6.47379s/100 iters), loss = 0.00756139
I0930 21:26:14.991894  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0075611 (* 1 = 0.0075611 loss)
I0930 21:26:14.991900  4070 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0930 21:26:20.239987  4070 solver.cpp:218] Iteration 82100 (19.0546 iter/s, 5.24807s/100 iters), loss = 0.0167424
I0930 21:26:20.240022  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167421 (* 1 = 0.0167421 loss)
I0930 21:26:20.240030  4070 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0930 21:26:25.477329  4070 solver.cpp:218] Iteration 82200 (19.094 iter/s, 5.23726s/100 iters), loss = 0.025572
I0930 21:26:25.477478  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255717 (* 1 = 0.0255717 loss)
I0930 21:26:25.477486  4070 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0930 21:26:30.719851  4070 solver.cpp:218] Iteration 82300 (19.0754 iter/s, 5.24236s/100 iters), loss = 0.0133582
I0930 21:26:30.719890  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133579 (* 1 = 0.0133579 loss)
I0930 21:26:30.719897  4070 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0930 21:26:35.968710  4070 solver.cpp:218] Iteration 82400 (19.052 iter/s, 5.2488s/100 iters), loss = 0.0304114
I0930 21:26:35.968750  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304111 (* 1 = 0.0304111 loss)
I0930 21:26:35.968755  4070 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0930 21:26:40.947379  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:26:41.163503  4070 solver.cpp:330] Iteration 82500, Testing net (#0)
I0930 21:26:42.350165  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:26:42.400449  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I0930 21:26:42.400483  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364557 (* 1 = 0.364557 loss)
I0930 21:26:42.452661  4070 solver.cpp:218] Iteration 82500 (15.4228 iter/s, 6.48389s/100 iters), loss = 0.00985556
I0930 21:26:42.452692  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00985527 (* 1 = 0.00985527 loss)
I0930 21:26:42.452700  4070 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0930 21:26:47.696241  4070 solver.cpp:218] Iteration 82600 (19.0711 iter/s, 5.24353s/100 iters), loss = 0.0250312
I0930 21:26:47.696282  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250309 (* 1 = 0.0250309 loss)
I0930 21:26:47.696288  4070 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0930 21:26:52.934725  4070 solver.cpp:218] Iteration 82700 (19.0897 iter/s, 5.23842s/100 iters), loss = 0.030792
I0930 21:26:52.934765  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307917 (* 1 = 0.0307917 loss)
I0930 21:26:52.934772  4070 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0930 21:26:58.175709  4070 solver.cpp:218] Iteration 82800 (19.0806 iter/s, 5.24092s/100 iters), loss = 0.020519
I0930 21:26:58.175845  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205187 (* 1 = 0.0205187 loss)
I0930 21:26:58.175853  4070 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0930 21:27:03.419127  4070 solver.cpp:218] Iteration 82900 (19.0721 iter/s, 5.24326s/100 iters), loss = 0.00356534
I0930 21:27:03.419157  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356505 (* 1 = 0.00356505 loss)
I0930 21:27:03.419162  4070 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0930 21:27:08.408135  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:27:08.618083  4070 solver.cpp:330] Iteration 83000, Testing net (#0)
I0930 21:27:09.802350  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:27:09.852375  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I0930 21:27:09.852409  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361582 (* 1 = 0.361582 loss)
I0930 21:27:09.905139  4070 solver.cpp:218] Iteration 83000 (15.4179 iter/s, 6.48596s/100 iters), loss = 0.00835911
I0930 21:27:09.905164  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00835881 (* 1 = 0.00835881 loss)
I0930 21:27:09.905170  4070 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0930 21:27:15.148481  4070 solver.cpp:218] Iteration 83100 (19.072 iter/s, 5.2433s/100 iters), loss = 0.015214
I0930 21:27:15.148520  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152137 (* 1 = 0.0152137 loss)
I0930 21:27:15.148526  4070 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0930 21:27:20.397518  4070 solver.cpp:218] Iteration 83200 (19.0514 iter/s, 5.24897s/100 iters), loss = 0.00793818
I0930 21:27:20.397547  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00793789 (* 1 = 0.00793789 loss)
I0930 21:27:20.397553  4070 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0930 21:27:25.627902  4070 solver.cpp:218] Iteration 83300 (19.1192 iter/s, 5.23033s/100 iters), loss = 0.0300305
I0930 21:27:25.627931  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300302 (* 1 = 0.0300302 loss)
I0930 21:27:25.627936  4070 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0930 21:27:30.872071  4070 solver.cpp:218] Iteration 83400 (19.069 iter/s, 5.24412s/100 iters), loss = 0.00744838
I0930 21:27:30.872203  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00744809 (* 1 = 0.00744809 loss)
I0930 21:27:30.872210  4070 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0930 21:27:35.845993  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:27:36.056681  4070 solver.cpp:330] Iteration 83500, Testing net (#0)
I0930 21:27:37.240347  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:27:37.290383  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9072
I0930 21:27:37.290417  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366023 (* 1 = 0.366023 loss)
I0930 21:27:37.342799  4070 solver.cpp:218] Iteration 83500 (15.4546 iter/s, 6.47058s/100 iters), loss = 0.013849
I0930 21:27:37.342824  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138487 (* 1 = 0.0138487 loss)
I0930 21:27:37.342831  4070 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0930 21:27:42.586884  4070 solver.cpp:218] Iteration 83600 (19.0693 iter/s, 5.24404s/100 iters), loss = 0.0124492
I0930 21:27:42.586925  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124489 (* 1 = 0.0124489 loss)
I0930 21:27:42.586930  4070 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0930 21:27:47.830729  4070 solver.cpp:218] Iteration 83700 (19.0702 iter/s, 5.24378s/100 iters), loss = 0.0112632
I0930 21:27:47.830759  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112629 (* 1 = 0.0112629 loss)
I0930 21:27:47.830765  4070 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0930 21:27:53.069836  4070 solver.cpp:218] Iteration 83800 (19.0874 iter/s, 5.23906s/100 iters), loss = 0.0198673
I0930 21:27:53.069874  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198671 (* 1 = 0.0198671 loss)
I0930 21:27:53.069881  4070 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0930 21:27:58.315639  4070 solver.cpp:218] Iteration 83900 (19.0631 iter/s, 5.24575s/100 iters), loss = 0.00400347
I0930 21:27:58.315668  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400318 (* 1 = 0.00400318 loss)
I0930 21:27:58.315673  4070 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0930 21:28:03.303499  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:28:03.513253  4070 solver.cpp:330] Iteration 84000, Testing net (#0)
I0930 21:28:04.696614  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:28:04.746335  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9071
I0930 21:28:04.746369  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367531 (* 1 = 0.367531 loss)
I0930 21:28:04.798835  4070 solver.cpp:218] Iteration 84000 (15.4246 iter/s, 6.48314s/100 iters), loss = 0.00570181
I0930 21:28:04.798857  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570153 (* 1 = 0.00570153 loss)
I0930 21:28:04.798864  4070 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0930 21:28:10.047875  4070 solver.cpp:218] Iteration 84100 (19.0513 iter/s, 5.249s/100 iters), loss = 0.0176139
I0930 21:28:10.047905  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176136 (* 1 = 0.0176136 loss)
I0930 21:28:10.047910  4070 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0930 21:28:15.291129  4070 solver.cpp:218] Iteration 84200 (19.0723 iter/s, 5.2432s/100 iters), loss = 0.0104136
I0930 21:28:15.291159  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104133 (* 1 = 0.0104133 loss)
I0930 21:28:15.291167  4070 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0930 21:28:20.537192  4070 solver.cpp:218] Iteration 84300 (19.0621 iter/s, 5.24601s/100 iters), loss = 0.0330579
I0930 21:28:20.537235  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330576 (* 1 = 0.0330576 loss)
I0930 21:28:20.537241  4070 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0930 21:28:25.772184  4070 solver.cpp:218] Iteration 84400 (19.1025 iter/s, 5.23493s/100 iters), loss = 0.00373954
I0930 21:28:25.772220  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373923 (* 1 = 0.00373923 loss)
I0930 21:28:25.772228  4070 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0930 21:28:30.757441  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:28:30.966831  4070 solver.cpp:330] Iteration 84500, Testing net (#0)
I0930 21:28:32.157153  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:28:32.207981  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9071
I0930 21:28:32.208016  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369535 (* 1 = 0.369535 loss)
I0930 21:28:32.261507  4070 solver.cpp:218] Iteration 84500 (15.4101 iter/s, 6.48927s/100 iters), loss = 0.0151026
I0930 21:28:32.261539  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151023 (* 1 = 0.0151023 loss)
I0930 21:28:32.261546  4070 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0930 21:28:37.492409  4070 solver.cpp:218] Iteration 84600 (19.1174 iter/s, 5.23085s/100 iters), loss = 0.00601675
I0930 21:28:37.492555  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601643 (* 1 = 0.00601643 loss)
I0930 21:28:37.492575  4070 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0930 21:28:42.738641  4070 solver.cpp:218] Iteration 84700 (19.0619 iter/s, 5.24607s/100 iters), loss = 0.0226142
I0930 21:28:42.738680  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226139 (* 1 = 0.0226139 loss)
I0930 21:28:42.738687  4070 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0930 21:28:47.987362  4070 solver.cpp:218] Iteration 84800 (19.0525 iter/s, 5.24866s/100 iters), loss = 0.00850559
I0930 21:28:47.987404  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0085053 (* 1 = 0.0085053 loss)
I0930 21:28:47.987411  4070 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0930 21:28:53.236027  4070 solver.cpp:218] Iteration 84900 (19.0527 iter/s, 5.2486s/100 iters), loss = 0.0208223
I0930 21:28:53.236073  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020822 (* 1 = 0.020822 loss)
I0930 21:28:53.236079  4070 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0930 21:28:58.213534  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:28:58.423936  4070 solver.cpp:330] Iteration 85000, Testing net (#0)
I0930 21:28:59.618647  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:28:59.668571  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I0930 21:28:59.668594  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367772 (* 1 = 0.367772 loss)
I0930 21:28:59.721242  4070 solver.cpp:218] Iteration 85000 (15.4198 iter/s, 6.48515s/100 iters), loss = 0.0200745
I0930 21:28:59.721277  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200742 (* 1 = 0.0200742 loss)
I0930 21:28:59.721285  4070 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0930 21:29:04.964752  4070 solver.cpp:218] Iteration 85100 (19.0714 iter/s, 5.24346s/100 iters), loss = 0.0086532
I0930 21:29:04.964792  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00865292 (* 1 = 0.00865292 loss)
I0930 21:29:04.964798  4070 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0930 21:29:10.205920  4070 solver.cpp:218] Iteration 85200 (19.08 iter/s, 5.2411s/100 iters), loss = 0.0127179
I0930 21:29:10.206066  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127176 (* 1 = 0.0127176 loss)
I0930 21:29:10.206074  4070 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0930 21:29:15.446645  4070 solver.cpp:218] Iteration 85300 (19.0819 iter/s, 5.24057s/100 iters), loss = 0.0204022
I0930 21:29:15.446674  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204019 (* 1 = 0.0204019 loss)
I0930 21:29:15.446681  4070 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0930 21:29:20.691807  4070 solver.cpp:218] Iteration 85400 (19.0654 iter/s, 5.24511s/100 iters), loss = 0.00880153
I0930 21:29:20.691848  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00880126 (* 1 = 0.00880126 loss)
I0930 21:29:20.691854  4070 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0930 21:29:25.666110  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:29:25.875650  4070 solver.cpp:330] Iteration 85500, Testing net (#0)
I0930 21:29:27.068123  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:29:27.118265  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I0930 21:29:27.118299  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364524 (* 1 = 0.364524 loss)
I0930 21:29:27.170799  4070 solver.cpp:218] Iteration 85500 (15.4346 iter/s, 6.47893s/100 iters), loss = 0.0212623
I0930 21:29:27.170825  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212621 (* 1 = 0.0212621 loss)
I0930 21:29:27.170832  4070 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0930 21:29:32.422155  4070 solver.cpp:218] Iteration 85600 (19.0429 iter/s, 5.2513s/100 iters), loss = 0.00760316
I0930 21:29:32.422185  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0076029 (* 1 = 0.0076029 loss)
I0930 21:29:32.422193  4070 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0930 21:29:37.659971  4070 solver.cpp:218] Iteration 85700 (19.0921 iter/s, 5.23777s/100 iters), loss = 0.0125243
I0930 21:29:37.660001  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012524 (* 1 = 0.012524 loss)
I0930 21:29:37.660006  4070 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0930 21:29:42.910727  4070 solver.cpp:218] Iteration 85800 (19.0451 iter/s, 5.25071s/100 iters), loss = 0.0215805
I0930 21:29:42.910817  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215802 (* 1 = 0.0215802 loss)
I0930 21:29:42.910835  4070 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0930 21:29:48.159867  4070 solver.cpp:218] Iteration 85900 (19.0511 iter/s, 5.24904s/100 iters), loss = 0.00783252
I0930 21:29:48.159907  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783225 (* 1 = 0.00783225 loss)
I0930 21:29:48.159914  4070 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0930 21:29:53.144816  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:29:53.356462  4070 solver.cpp:330] Iteration 86000, Testing net (#0)
I0930 21:29:54.541553  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:29:54.591747  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9078
I0930 21:29:54.591784  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364498 (* 1 = 0.364498 loss)
I0930 21:29:54.644196  4070 solver.cpp:218] Iteration 86000 (15.4219 iter/s, 6.48427s/100 iters), loss = 0.0100712
I0930 21:29:54.644220  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100709 (* 1 = 0.0100709 loss)
I0930 21:29:54.644227  4070 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0930 21:29:59.884033  4070 solver.cpp:218] Iteration 86100 (19.0847 iter/s, 5.23979s/100 iters), loss = 0.00384061
I0930 21:29:59.884073  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384035 (* 1 = 0.00384035 loss)
I0930 21:29:59.884079  4070 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0930 21:30:05.123149  4070 solver.cpp:218] Iteration 86200 (19.0874 iter/s, 5.23905s/100 iters), loss = 0.0177208
I0930 21:30:05.123194  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177206 (* 1 = 0.0177206 loss)
I0930 21:30:05.123201  4070 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0930 21:30:10.363610  4070 solver.cpp:218] Iteration 86300 (19.0827 iter/s, 5.24036s/100 iters), loss = 0.0494814
I0930 21:30:10.363651  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494811 (* 1 = 0.0494811 loss)
I0930 21:30:10.363657  4070 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0930 21:30:15.608896  4070 solver.cpp:218] Iteration 86400 (19.065 iter/s, 5.24522s/100 iters), loss = 0.00665197
I0930 21:30:15.609028  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665171 (* 1 = 0.00665171 loss)
I0930 21:30:15.609035  4070 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0930 21:30:20.595002  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:30:20.805464  4070 solver.cpp:330] Iteration 86500, Testing net (#0)
I0930 21:30:21.988819  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:30:22.039064  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I0930 21:30:22.039088  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368267 (* 1 = 0.368267 loss)
I0930 21:30:22.091783  4070 solver.cpp:218] Iteration 86500 (15.4256 iter/s, 6.48275s/100 iters), loss = 0.00905692
I0930 21:30:22.091811  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00905665 (* 1 = 0.00905665 loss)
I0930 21:30:22.091819  4070 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0930 21:30:27.339078  4070 solver.cpp:218] Iteration 86600 (19.0576 iter/s, 5.24725s/100 iters), loss = 0.0183215
I0930 21:30:27.339118  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183212 (* 1 = 0.0183212 loss)
I0930 21:30:27.339124  4070 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0930 21:30:32.587834  4070 solver.cpp:218] Iteration 86700 (19.0524 iter/s, 5.24869s/100 iters), loss = 0.0270837
I0930 21:30:32.587874  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270834 (* 1 = 0.0270834 loss)
I0930 21:30:32.587880  4070 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0930 21:30:37.829855  4070 solver.cpp:218] Iteration 86800 (19.0768 iter/s, 5.24196s/100 iters), loss = 0.0143754
I0930 21:30:37.829895  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143751 (* 1 = 0.0143751 loss)
I0930 21:30:37.829900  4070 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0930 21:30:43.079018  4070 solver.cpp:218] Iteration 86900 (19.0509 iter/s, 5.2491s/100 iters), loss = 0.00662122
I0930 21:30:43.079049  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00662095 (* 1 = 0.00662095 loss)
I0930 21:30:43.079056  4070 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0930 21:30:48.059188  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:30:48.268882  4070 solver.cpp:330] Iteration 87000, Testing net (#0)
I0930 21:30:49.453078  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:30:49.502394  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.907
I0930 21:30:49.502419  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367322 (* 1 = 0.367322 loss)
I0930 21:30:49.554841  4070 solver.cpp:218] Iteration 87000 (15.4422 iter/s, 6.47577s/100 iters), loss = 0.00902335
I0930 21:30:49.554872  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902307 (* 1 = 0.00902307 loss)
I0930 21:30:49.554878  4070 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0930 21:30:54.797241  4070 solver.cpp:218] Iteration 87100 (19.0754 iter/s, 5.24235s/100 iters), loss = 0.0115538
I0930 21:30:54.797272  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115535 (* 1 = 0.0115535 loss)
I0930 21:30:54.797287  4070 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0930 21:31:00.038982  4070 solver.cpp:218] Iteration 87200 (19.0778 iter/s, 5.24169s/100 iters), loss = 0.0142025
I0930 21:31:00.039011  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142022 (* 1 = 0.0142022 loss)
I0930 21:31:00.039016  4070 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0930 21:31:05.289639  4070 solver.cpp:218] Iteration 87300 (19.0454 iter/s, 5.25061s/100 iters), loss = 0.00939341
I0930 21:31:05.289670  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00939313 (* 1 = 0.00939313 loss)
I0930 21:31:05.289677  4070 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0930 21:31:10.532395  4070 solver.cpp:218] Iteration 87400 (19.0741 iter/s, 5.2427s/100 iters), loss = 0.00388603
I0930 21:31:10.532438  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388576 (* 1 = 0.00388576 loss)
I0930 21:31:10.532445  4070 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0930 21:31:15.522230  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:31:15.731781  4070 solver.cpp:330] Iteration 87500, Testing net (#0)
I0930 21:31:16.916360  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:31:16.966400  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9078
I0930 21:31:16.966434  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367235 (* 1 = 0.367235 loss)
I0930 21:31:17.020242  4070 solver.cpp:218] Iteration 87500 (15.4136 iter/s, 6.48778s/100 iters), loss = 0.0158071
I0930 21:31:17.020277  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158069 (* 1 = 0.0158069 loss)
I0930 21:31:17.020284  4070 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0930 21:31:22.273973  4070 solver.cpp:218] Iteration 87600 (19.0343 iter/s, 5.25367s/100 iters), loss = 0.0123655
I0930 21:31:22.274107  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123652 (* 1 = 0.0123652 loss)
I0930 21:31:22.274124  4070 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0930 21:31:27.527621  4070 solver.cpp:218] Iteration 87700 (19.0349 iter/s, 5.2535s/100 iters), loss = 0.0250758
I0930 21:31:27.527662  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250755 (* 1 = 0.0250755 loss)
I0930 21:31:27.527668  4070 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0930 21:31:32.775470  4070 solver.cpp:218] Iteration 87800 (19.0557 iter/s, 5.24779s/100 iters), loss = 0.00612545
I0930 21:31:32.775501  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612516 (* 1 = 0.00612516 loss)
I0930 21:31:32.775516  4070 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0930 21:31:38.015722  4070 solver.cpp:218] Iteration 87900 (19.0832 iter/s, 5.2402s/100 iters), loss = 0.00848598
I0930 21:31:38.015754  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00848569 (* 1 = 0.00848569 loss)
I0930 21:31:38.015761  4070 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0930 21:31:42.999477  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:31:43.208142  4070 solver.cpp:330] Iteration 88000, Testing net (#0)
I0930 21:31:44.397626  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:31:44.447701  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9085
I0930 21:31:44.447736  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365396 (* 1 = 0.365396 loss)
I0930 21:31:44.500080  4070 solver.cpp:218] Iteration 88000 (15.422 iter/s, 6.48426s/100 iters), loss = 0.036217
I0930 21:31:44.500113  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362168 (* 1 = 0.0362168 loss)
I0930 21:31:44.500120  4070 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0930 21:31:49.737107  4070 solver.cpp:218] Iteration 88100 (19.095 iter/s, 5.23697s/100 iters), loss = 0.0116939
I0930 21:31:49.737148  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116936 (* 1 = 0.0116936 loss)
I0930 21:31:49.737154  4070 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0930 21:31:54.979091  4070 solver.cpp:218] Iteration 88200 (19.077 iter/s, 5.24192s/100 iters), loss = 0.0150326
I0930 21:31:54.979235  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150323 (* 1 = 0.0150323 loss)
I0930 21:31:54.979243  4070 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0930 21:32:00.225446  4070 solver.cpp:218] Iteration 88300 (19.0614 iter/s, 5.2462s/100 iters), loss = 0.0436373
I0930 21:32:00.225476  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043637 (* 1 = 0.043637 loss)
I0930 21:32:00.225483  4070 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0930 21:32:05.467948  4070 solver.cpp:218] Iteration 88400 (19.0751 iter/s, 5.24245s/100 iters), loss = 0.0118499
I0930 21:32:05.467981  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118496 (* 1 = 0.0118496 loss)
I0930 21:32:05.467998  4070 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0930 21:32:10.447947  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:32:10.659523  4070 solver.cpp:330] Iteration 88500, Testing net (#0)
I0930 21:32:11.852087  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:32:11.901979  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9059
I0930 21:32:11.902004  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373379 (* 1 = 0.373379 loss)
I0930 21:32:11.954319  4070 solver.cpp:218] Iteration 88500 (15.4171 iter/s, 6.48632s/100 iters), loss = 0.0131606
I0930 21:32:11.954347  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131603 (* 1 = 0.0131603 loss)
I0930 21:32:11.954365  4070 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0930 21:32:17.202508  4070 solver.cpp:218] Iteration 88600 (19.0544 iter/s, 5.24814s/100 iters), loss = 0.0109496
I0930 21:32:17.202543  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109493 (* 1 = 0.0109493 loss)
I0930 21:32:17.202551  4070 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0930 21:32:22.443585  4070 solver.cpp:218] Iteration 88700 (19.0802 iter/s, 5.24102s/100 iters), loss = 0.0084973
I0930 21:32:22.443625  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849701 (* 1 = 0.00849701 loss)
I0930 21:32:22.443631  4070 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0930 21:32:27.687275  4070 solver.cpp:218] Iteration 88800 (19.0708 iter/s, 5.24363s/100 iters), loss = 0.0340666
I0930 21:32:27.687399  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340663 (* 1 = 0.0340663 loss)
I0930 21:32:27.687418  4070 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0930 21:32:32.934036  4070 solver.cpp:218] Iteration 88900 (19.0599 iter/s, 5.24663s/100 iters), loss = 0.0036078
I0930 21:32:32.934077  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360751 (* 1 = 0.00360751 loss)
I0930 21:32:32.934095  4070 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0930 21:32:37.909343  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:32:38.122040  4070 solver.cpp:330] Iteration 89000, Testing net (#0)
I0930 21:32:39.311087  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:32:39.361141  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I0930 21:32:39.361167  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373146 (* 1 = 0.373146 loss)
I0930 21:32:39.413538  4070 solver.cpp:218] Iteration 89000 (15.4334 iter/s, 6.47944s/100 iters), loss = 0.0242145
I0930 21:32:39.413570  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242143 (* 1 = 0.0242143 loss)
I0930 21:32:39.413579  4070 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0930 21:32:44.653026  4070 solver.cpp:218] Iteration 89100 (19.086 iter/s, 5.23944s/100 iters), loss = 0.00500573
I0930 21:32:44.653062  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500544 (* 1 = 0.00500544 loss)
I0930 21:32:44.653081  4070 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0930 21:32:49.889051  4070 solver.cpp:218] Iteration 89200 (19.0987 iter/s, 5.23597s/100 iters), loss = 0.0191311
I0930 21:32:49.889081  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191308 (* 1 = 0.0191308 loss)
I0930 21:32:49.889086  4070 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0930 21:32:55.132925  4070 solver.cpp:218] Iteration 89300 (19.0701 iter/s, 5.24382s/100 iters), loss = 0.00938988
I0930 21:32:55.132958  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00938959 (* 1 = 0.00938959 loss)
I0930 21:32:55.132967  4070 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0930 21:33:00.385076  4070 solver.cpp:218] Iteration 89400 (19.04 iter/s, 5.2521s/100 iters), loss = 0.00274484
I0930 21:33:00.385217  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274455 (* 1 = 0.00274455 loss)
I0930 21:33:00.385238  4070 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0930 21:33:05.371158  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:33:05.580871  4070 solver.cpp:330] Iteration 89500, Testing net (#0)
I0930 21:33:06.766474  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:33:06.816336  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I0930 21:33:06.816371  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374698 (* 1 = 0.374698 loss)
I0930 21:33:06.868890  4070 solver.cpp:218] Iteration 89500 (15.4234 iter/s, 6.48367s/100 iters), loss = 0.0136997
I0930 21:33:06.868916  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136995 (* 1 = 0.0136995 loss)
I0930 21:33:06.868924  4070 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0930 21:33:12.120190  4070 solver.cpp:218] Iteration 89600 (19.0431 iter/s, 5.25125s/100 iters), loss = 0.00750396
I0930 21:33:12.120224  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750368 (* 1 = 0.00750368 loss)
I0930 21:33:12.120234  4070 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0930 21:33:17.361927  4070 solver.cpp:218] Iteration 89700 (19.0778 iter/s, 5.24168s/100 iters), loss = 0.0232167
I0930 21:33:17.361969  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232164 (* 1 = 0.0232164 loss)
I0930 21:33:17.361975  4070 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0930 21:33:22.603138  4070 solver.cpp:218] Iteration 89800 (19.0798 iter/s, 5.24115s/100 iters), loss = 0.0283637
I0930 21:33:22.603178  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283635 (* 1 = 0.0283635 loss)
I0930 21:33:22.603184  4070 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0930 21:33:27.847179  4070 solver.cpp:218] Iteration 89900 (19.0695 iter/s, 5.24398s/100 iters), loss = 0.00428537
I0930 21:33:27.847209  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428509 (* 1 = 0.00428509 loss)
I0930 21:33:27.847225  4070 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0930 21:33:32.833458  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:33:33.043519  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_90000.caffemodel
I0930 21:33:33.048633  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_90000.solverstate
I0930 21:33:33.050020  4070 solver.cpp:330] Iteration 90000, Testing net (#0)
I0930 21:33:34.235237  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:33:34.285455  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9081
I0930 21:33:34.285490  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372263 (* 1 = 0.372263 loss)
I0930 21:33:34.338604  4070 solver.cpp:218] Iteration 90000 (15.4051 iter/s, 6.49138s/100 iters), loss = 0.0230397
I0930 21:33:34.338629  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230394 (* 1 = 0.0230394 loss)
I0930 21:33:34.338635  4070 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0930 21:33:39.585271  4070 solver.cpp:218] Iteration 90100 (19.0599 iter/s, 5.24662s/100 iters), loss = 0.024701
I0930 21:33:39.585310  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247007 (* 1 = 0.0247007 loss)
I0930 21:33:39.585317  4070 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0930 21:33:44.836439  4070 solver.cpp:218] Iteration 90200 (19.0436 iter/s, 5.25111s/100 iters), loss = 0.013485
I0930 21:33:44.836467  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134847 (* 1 = 0.0134847 loss)
I0930 21:33:44.836474  4070 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0930 21:33:50.083534  4070 solver.cpp:218] Iteration 90300 (19.0584 iter/s, 5.24704s/100 iters), loss = 0.00829604
I0930 21:33:50.083578  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829576 (* 1 = 0.00829576 loss)
I0930 21:33:50.083596  4070 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0930 21:33:55.323098  4070 solver.cpp:218] Iteration 90400 (19.0858 iter/s, 5.2395s/100 iters), loss = 0.00242685
I0930 21:33:55.323138  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242656 (* 1 = 0.00242656 loss)
I0930 21:33:55.323144  4070 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0930 21:34:00.306638  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:34:00.516017  4070 solver.cpp:330] Iteration 90500, Testing net (#0)
I0930 21:34:01.704169  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:34:01.753989  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9081
I0930 21:34:01.754024  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37413 (* 1 = 0.37413 loss)
I0930 21:34:01.806790  4070 solver.cpp:218] Iteration 90500 (15.4234 iter/s, 6.48363s/100 iters), loss = 0.0111615
I0930 21:34:01.806816  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111612 (* 1 = 0.0111612 loss)
I0930 21:34:01.806823  4070 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0930 21:34:07.049876  4070 solver.cpp:218] Iteration 90600 (19.0729 iter/s, 5.24304s/100 iters), loss = 0.0104766
I0930 21:34:07.049998  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104764 (* 1 = 0.0104764 loss)
I0930 21:34:07.050016  4070 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0930 21:34:12.292773  4070 solver.cpp:218] Iteration 90700 (19.0739 iter/s, 5.24277s/100 iters), loss = 0.0237434
I0930 21:34:12.292803  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237431 (* 1 = 0.0237431 loss)
I0930 21:34:12.292809  4070 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0930 21:34:17.540004  4070 solver.cpp:218] Iteration 90800 (19.0578 iter/s, 5.24718s/100 iters), loss = 0.0191097
I0930 21:34:17.540045  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191094 (* 1 = 0.0191094 loss)
I0930 21:34:17.540051  4070 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0930 21:34:22.781545  4070 solver.cpp:218] Iteration 90900 (19.0786 iter/s, 5.24148s/100 iters), loss = 0.0324314
I0930 21:34:22.781589  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324311 (* 1 = 0.0324311 loss)
I0930 21:34:22.781595  4070 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0930 21:34:27.767602  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:34:27.977690  4070 solver.cpp:330] Iteration 91000, Testing net (#0)
I0930 21:34:29.166415  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:34:29.216928  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9064
I0930 21:34:29.216953  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378278 (* 1 = 0.378278 loss)
I0930 21:34:29.270993  4070 solver.cpp:218] Iteration 91000 (15.4098 iter/s, 6.48939s/100 iters), loss = 0.00304848
I0930 21:34:29.271040  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304819 (* 1 = 0.00304819 loss)
I0930 21:34:29.271049  4070 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0930 21:34:34.511545  4070 solver.cpp:218] Iteration 91100 (19.0822 iter/s, 5.24049s/100 iters), loss = 0.00774081
I0930 21:34:34.511575  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774052 (* 1 = 0.00774052 loss)
I0930 21:34:34.511581  4070 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0930 21:34:39.762262  4070 solver.cpp:218] Iteration 91200 (19.0452 iter/s, 5.25067s/100 iters), loss = 0.0156355
I0930 21:34:39.762434  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156352 (* 1 = 0.0156352 loss)
I0930 21:34:39.762444  4070 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0930 21:34:45.001865  4070 solver.cpp:218] Iteration 91300 (19.0861 iter/s, 5.23943s/100 iters), loss = 0.00927183
I0930 21:34:45.001895  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00927154 (* 1 = 0.00927154 loss)
I0930 21:34:45.001901  4070 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0930 21:34:50.239624  4070 solver.cpp:218] Iteration 91400 (19.0923 iter/s, 5.23771s/100 iters), loss = 0.0113232
I0930 21:34:50.239657  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113229 (* 1 = 0.0113229 loss)
I0930 21:34:50.239665  4070 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0930 21:34:55.215517  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:34:55.424479  4070 solver.cpp:330] Iteration 91500, Testing net (#0)
I0930 21:34:56.616757  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:34:56.666743  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9078
I0930 21:34:56.666767  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377078 (* 1 = 0.377078 loss)
I0930 21:34:56.719215  4070 solver.cpp:218] Iteration 91500 (15.4332 iter/s, 6.47954s/100 iters), loss = 0.00415339
I0930 21:34:56.719247  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415309 (* 1 = 0.00415309 loss)
I0930 21:34:56.719255  4070 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0930 21:35:01.961716  4070 solver.cpp:218] Iteration 91600 (19.075 iter/s, 5.24245s/100 iters), loss = 0.0126865
I0930 21:35:01.961745  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126862 (* 1 = 0.0126862 loss)
I0930 21:35:01.961761  4070 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0930 21:35:07.212772  4070 solver.cpp:218] Iteration 91700 (19.044 iter/s, 5.25101s/100 iters), loss = 0.00431676
I0930 21:35:07.212803  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431648 (* 1 = 0.00431648 loss)
I0930 21:35:07.212819  4070 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0930 21:35:12.463353  4070 solver.cpp:218] Iteration 91800 (19.0457 iter/s, 5.25053s/100 iters), loss = 0.00650726
I0930 21:35:12.463485  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650697 (* 1 = 0.00650697 loss)
I0930 21:35:12.463493  4070 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0930 21:35:17.717445  4070 solver.cpp:218] Iteration 91900 (19.0333 iter/s, 5.25395s/100 iters), loss = 0.00244414
I0930 21:35:17.717476  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244386 (* 1 = 0.00244386 loss)
I0930 21:35:17.717494  4070 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0930 21:35:22.702088  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:35:22.912307  4070 solver.cpp:330] Iteration 92000, Testing net (#0)
I0930 21:35:24.104975  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:35:24.154747  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I0930 21:35:24.154780  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379198 (* 1 = 0.379198 loss)
I0930 21:35:24.207152  4070 solver.cpp:218] Iteration 92000 (15.4091 iter/s, 6.48965s/100 iters), loss = 0.0034368
I0930 21:35:24.207177  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343651 (* 1 = 0.00343651 loss)
I0930 21:35:24.207185  4070 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0930 21:35:29.457690  4070 solver.cpp:218] Iteration 92100 (19.0458 iter/s, 5.25049s/100 iters), loss = 0.00711942
I0930 21:35:29.457720  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00711913 (* 1 = 0.00711913 loss)
I0930 21:35:29.457726  4070 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0930 21:35:34.692692  4070 solver.cpp:218] Iteration 92200 (19.1024 iter/s, 5.23495s/100 iters), loss = 0.010043
I0930 21:35:34.692720  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100427 (* 1 = 0.0100427 loss)
I0930 21:35:34.692736  4070 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0930 21:35:39.938433  4070 solver.cpp:218] Iteration 92300 (19.0633 iter/s, 5.24569s/100 iters), loss = 0.0152159
I0930 21:35:39.938462  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152156 (* 1 = 0.0152156 loss)
I0930 21:35:39.938468  4070 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0930 21:35:45.183207  4070 solver.cpp:218] Iteration 92400 (19.0668 iter/s, 5.24472s/100 iters), loss = 0.0105855
I0930 21:35:45.183369  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105852 (* 1 = 0.0105852 loss)
I0930 21:35:45.183378  4070 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0930 21:35:50.163070  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:35:50.376376  4070 solver.cpp:330] Iteration 92500, Testing net (#0)
I0930 21:35:51.562695  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:35:51.612334  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I0930 21:35:51.612368  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376564 (* 1 = 0.376564 loss)
I0930 21:35:51.664587  4070 solver.cpp:218] Iteration 92500 (15.4292 iter/s, 6.48121s/100 iters), loss = 0.00689519
I0930 21:35:51.664610  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068949 (* 1 = 0.0068949 loss)
I0930 21:35:51.664618  4070 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0930 21:35:56.911337  4070 solver.cpp:218] Iteration 92600 (19.0596 iter/s, 5.24671s/100 iters), loss = 0.0110243
I0930 21:35:56.911377  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011024 (* 1 = 0.011024 loss)
I0930 21:35:56.911383  4070 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0930 21:36:02.152110  4070 solver.cpp:218] Iteration 92700 (19.0814 iter/s, 5.24071s/100 iters), loss = 0.0211586
I0930 21:36:02.152156  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211583 (* 1 = 0.0211583 loss)
I0930 21:36:02.152164  4070 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0930 21:36:07.395397  4070 solver.cpp:218] Iteration 92800 (19.0724 iter/s, 5.24319s/100 iters), loss = 0.024119
I0930 21:36:07.395438  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241187 (* 1 = 0.0241187 loss)
I0930 21:36:07.395444  4070 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0930 21:36:12.643128  4070 solver.cpp:218] Iteration 92900 (19.0561 iter/s, 5.24767s/100 iters), loss = 0.00289065
I0930 21:36:12.643158  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289037 (* 1 = 0.00289037 loss)
I0930 21:36:12.643165  4070 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0930 21:36:17.620537  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:36:17.830283  4070 solver.cpp:330] Iteration 93000, Testing net (#0)
I0930 21:36:19.016170  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:36:19.066175  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I0930 21:36:19.066210  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379287 (* 1 = 0.379287 loss)
I0930 21:36:19.118762  4070 solver.cpp:218] Iteration 93000 (15.4426 iter/s, 6.47558s/100 iters), loss = 0.0101241
I0930 21:36:19.118785  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101238 (* 1 = 0.0101238 loss)
I0930 21:36:19.118793  4070 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0930 21:36:24.362749  4070 solver.cpp:218] Iteration 93100 (19.0696 iter/s, 5.24394s/100 iters), loss = 0.0058811
I0930 21:36:24.362789  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588082 (* 1 = 0.00588082 loss)
I0930 21:36:24.362795  4070 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0930 21:36:29.604701  4070 solver.cpp:218] Iteration 93200 (19.0771 iter/s, 5.24189s/100 iters), loss = 0.0203373
I0930 21:36:29.604750  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020337 (* 1 = 0.020337 loss)
I0930 21:36:29.604756  4070 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0930 21:36:34.841711  4070 solver.cpp:218] Iteration 93300 (19.0951 iter/s, 5.23694s/100 iters), loss = 0.00207384
I0930 21:36:34.841750  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207356 (* 1 = 0.00207356 loss)
I0930 21:36:34.841755  4070 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0930 21:36:40.089766  4070 solver.cpp:218] Iteration 93400 (19.0549 iter/s, 5.24799s/100 iters), loss = 0.00385872
I0930 21:36:40.089797  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385844 (* 1 = 0.00385844 loss)
I0930 21:36:40.089802  4070 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0930 21:36:45.065021  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:36:45.274183  4070 solver.cpp:330] Iteration 93500, Testing net (#0)
I0930 21:36:46.460361  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:36:46.510082  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9092
I0930 21:36:46.510118  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372801 (* 1 = 0.372801 loss)
I0930 21:36:46.562400  4070 solver.cpp:218] Iteration 93500 (15.4498 iter/s, 6.47259s/100 iters), loss = 0.0143762
I0930 21:36:46.562427  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143759 (* 1 = 0.0143759 loss)
I0930 21:36:46.562435  4070 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0930 21:36:51.814517  4070 solver.cpp:218] Iteration 93600 (19.0401 iter/s, 5.25207s/100 iters), loss = 0.00832339
I0930 21:36:51.814692  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00832311 (* 1 = 0.00832311 loss)
I0930 21:36:51.814702  4070 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0930 21:36:57.063277  4070 solver.cpp:218] Iteration 93700 (19.0528 iter/s, 5.24857s/100 iters), loss = 0.0127342
I0930 21:36:57.063315  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012734 (* 1 = 0.012734 loss)
I0930 21:36:57.063324  4070 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0930 21:37:02.307842  4070 solver.cpp:218] Iteration 93800 (19.0676 iter/s, 5.2445s/100 iters), loss = 0.019659
I0930 21:37:02.307879  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196587 (* 1 = 0.0196587 loss)
I0930 21:37:02.307898  4070 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0930 21:37:07.547824  4070 solver.cpp:218] Iteration 93900 (19.0844 iter/s, 5.23989s/100 iters), loss = 0.00193093
I0930 21:37:07.547854  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193066 (* 1 = 0.00193066 loss)
I0930 21:37:07.547870  4070 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0930 21:37:12.532217  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:37:12.742259  4070 solver.cpp:330] Iteration 94000, Testing net (#0)
I0930 21:37:13.926328  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:37:13.976068  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I0930 21:37:13.976102  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376434 (* 1 = 0.376434 loss)
I0930 21:37:14.028349  4070 solver.cpp:218] Iteration 94000 (15.431 iter/s, 6.48047s/100 iters), loss = 0.00590167
I0930 21:37:14.028380  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059014 (* 1 = 0.0059014 loss)
I0930 21:37:14.028388  4070 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0930 21:37:19.271944  4070 solver.cpp:218] Iteration 94100 (19.0711 iter/s, 5.24355s/100 iters), loss = 0.00800991
I0930 21:37:19.271984  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00800964 (* 1 = 0.00800964 loss)
I0930 21:37:19.271991  4070 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0930 21:37:24.516695  4070 solver.cpp:218] Iteration 94200 (19.0669 iter/s, 5.24469s/100 iters), loss = 0.0205579
I0930 21:37:24.516868  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205576 (* 1 = 0.0205576 loss)
I0930 21:37:24.516877  4070 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0930 21:37:29.761965  4070 solver.cpp:218] Iteration 94300 (19.0655 iter/s, 5.24509s/100 iters), loss = 0.0156295
I0930 21:37:29.762006  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156292 (* 1 = 0.0156292 loss)
I0930 21:37:29.762012  4070 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0930 21:37:35.002893  4070 solver.cpp:218] Iteration 94400 (19.0808 iter/s, 5.24087s/100 iters), loss = 0.0290981
I0930 21:37:35.002923  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290978 (* 1 = 0.0290978 loss)
I0930 21:37:35.002928  4070 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0930 21:37:39.990809  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:37:40.200920  4070 solver.cpp:330] Iteration 94500, Testing net (#0)
I0930 21:37:41.395568  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:37:41.445632  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I0930 21:37:41.445668  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379268 (* 1 = 0.379268 loss)
I0930 21:37:41.498600  4070 solver.cpp:218] Iteration 94500 (15.3949 iter/s, 6.49566s/100 iters), loss = 0.0155913
I0930 21:37:41.498642  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155911 (* 1 = 0.0155911 loss)
I0930 21:37:41.498649  4070 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0930 21:37:46.733489  4070 solver.cpp:218] Iteration 94600 (19.1028 iter/s, 5.23483s/100 iters), loss = 0.00790331
I0930 21:37:46.733530  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790304 (* 1 = 0.00790304 loss)
I0930 21:37:46.733536  4070 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0930 21:37:51.977331  4070 solver.cpp:218] Iteration 94700 (19.0702 iter/s, 5.24378s/100 iters), loss = 0.0122104
I0930 21:37:51.977360  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122101 (* 1 = 0.0122101 loss)
I0930 21:37:51.977366  4070 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0930 21:37:57.223824  4070 solver.cpp:218] Iteration 94800 (19.0605 iter/s, 5.24644s/100 iters), loss = 0.00555561
I0930 21:37:57.223943  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555534 (* 1 = 0.00555534 loss)
I0930 21:37:57.223950  4070 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0930 21:38:02.472033  4070 solver.cpp:218] Iteration 94900 (19.0546 iter/s, 5.24808s/100 iters), loss = 0.0239766
I0930 21:38:02.472064  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239763 (* 1 = 0.0239763 loss)
I0930 21:38:02.472069  4070 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0930 21:38:07.441655  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:38:07.651747  4070 solver.cpp:330] Iteration 95000, Testing net (#0)
I0930 21:38:08.840435  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:38:08.890641  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.907
I0930 21:38:08.890668  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37722 (* 1 = 0.37722 loss)
I0930 21:38:08.943632  4070 solver.cpp:218] Iteration 95000 (15.4523 iter/s, 6.47155s/100 iters), loss = 0.00802876
I0930 21:38:08.943660  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0080285 (* 1 = 0.0080285 loss)
I0930 21:38:08.943670  4070 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0930 21:38:14.181162  4070 solver.cpp:218] Iteration 95100 (19.0931 iter/s, 5.23748s/100 iters), loss = 0.0134231
I0930 21:38:14.181197  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134228 (* 1 = 0.0134228 loss)
I0930 21:38:14.181205  4070 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0930 21:38:19.427367  4070 solver.cpp:218] Iteration 95200 (19.0616 iter/s, 5.24615s/100 iters), loss = 0.0129292
I0930 21:38:19.427407  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129289 (* 1 = 0.0129289 loss)
I0930 21:38:19.427413  4070 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0930 21:38:24.681366  4070 solver.cpp:218] Iteration 95300 (19.0333 iter/s, 5.25394s/100 iters), loss = 0.0237838
I0930 21:38:24.681397  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237835 (* 1 = 0.0237835 loss)
I0930 21:38:24.681403  4070 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0930 21:38:29.932396  4070 solver.cpp:218] Iteration 95400 (19.0441 iter/s, 5.25098s/100 iters), loss = 0.009353
I0930 21:38:29.932507  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00935273 (* 1 = 0.00935273 loss)
I0930 21:38:29.932524  4070 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0930 21:38:34.906191  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:38:35.118775  4070 solver.cpp:330] Iteration 95500, Testing net (#0)
I0930 21:38:36.309921  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:38:36.359843  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I0930 21:38:36.359869  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379284 (* 1 = 0.379284 loss)
I0930 21:38:36.412235  4070 solver.cpp:218] Iteration 95500 (15.4328 iter/s, 6.47971s/100 iters), loss = 0.00345409
I0930 21:38:36.412264  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345383 (* 1 = 0.00345383 loss)
I0930 21:38:36.412274  4070 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0930 21:38:41.665254  4070 solver.cpp:218] Iteration 95600 (19.0369 iter/s, 5.25297s/100 iters), loss = 0.00481117
I0930 21:38:41.665285  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481091 (* 1 = 0.00481091 loss)
I0930 21:38:41.665294  4070 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0930 21:38:46.906175  4070 solver.cpp:218] Iteration 95700 (19.0808 iter/s, 5.24087s/100 iters), loss = 0.0136255
I0930 21:38:46.906208  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136253 (* 1 = 0.0136253 loss)
I0930 21:38:46.906215  4070 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0930 21:38:52.151268  4070 solver.cpp:218] Iteration 95800 (19.0656 iter/s, 5.24504s/100 iters), loss = 0.00777036
I0930 21:38:52.151300  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00777009 (* 1 = 0.00777009 loss)
I0930 21:38:52.151309  4070 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0930 21:38:57.394314  4070 solver.cpp:218] Iteration 95900 (19.0731 iter/s, 5.24299s/100 iters), loss = 0.00412162
I0930 21:38:57.394345  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412136 (* 1 = 0.00412136 loss)
I0930 21:38:57.394354  4070 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0930 21:39:02.382987  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:39:02.592360  4070 solver.cpp:330] Iteration 96000, Testing net (#0)
I0930 21:39:03.777815  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:39:03.827754  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I0930 21:39:03.827780  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376218 (* 1 = 0.376218 loss)
I0930 21:39:03.880188  4070 solver.cpp:218] Iteration 96000 (15.4183 iter/s, 6.48582s/100 iters), loss = 0.0113782
I0930 21:39:03.880216  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011378 (* 1 = 0.011378 loss)
I0930 21:39:03.880223  4070 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0930 21:39:09.133842  4070 solver.cpp:218] Iteration 96100 (19.0346 iter/s, 5.2536s/100 iters), loss = 0.0100999
I0930 21:39:09.133872  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100996 (* 1 = 0.0100996 loss)
I0930 21:39:09.133879  4070 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0930 21:39:14.383359  4070 solver.cpp:218] Iteration 96200 (19.0496 iter/s, 5.24946s/100 iters), loss = 0.013265
I0930 21:39:14.383390  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132648 (* 1 = 0.0132648 loss)
I0930 21:39:14.383397  4070 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0930 21:39:19.624845  4070 solver.cpp:218] Iteration 96300 (19.0787 iter/s, 5.24143s/100 iters), loss = 0.0179356
I0930 21:39:19.624886  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179353 (* 1 = 0.0179353 loss)
I0930 21:39:19.624891  4070 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0930 21:39:24.875224  4070 solver.cpp:218] Iteration 96400 (19.0465 iter/s, 5.25032s/100 iters), loss = 0.0148871
I0930 21:39:24.875267  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148868 (* 1 = 0.0148868 loss)
I0930 21:39:24.875272  4070 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0930 21:39:29.863580  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:39:30.074050  4070 solver.cpp:330] Iteration 96500, Testing net (#0)
I0930 21:39:31.259137  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:39:31.309149  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I0930 21:39:31.309182  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382794 (* 1 = 0.382794 loss)
I0930 21:39:31.361461  4070 solver.cpp:218] Iteration 96500 (15.4174 iter/s, 6.48617s/100 iters), loss = 0.011681
I0930 21:39:31.361490  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116807 (* 1 = 0.0116807 loss)
I0930 21:39:31.361496  4070 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0930 21:39:36.609025  4070 solver.cpp:218] Iteration 96600 (19.0566 iter/s, 5.24751s/100 iters), loss = 0.00704042
I0930 21:39:36.609135  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704016 (* 1 = 0.00704016 loss)
I0930 21:39:36.609153  4070 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0930 21:39:41.847496  4070 solver.cpp:218] Iteration 96700 (19.09 iter/s, 5.23835s/100 iters), loss = 0.0259347
I0930 21:39:41.847527  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259344 (* 1 = 0.0259344 loss)
I0930 21:39:41.847534  4070 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0930 21:39:47.083585  4070 solver.cpp:218] Iteration 96800 (19.0984 iter/s, 5.23604s/100 iters), loss = 0.0082266
I0930 21:39:47.083628  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00822634 (* 1 = 0.00822634 loss)
I0930 21:39:47.083636  4070 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0930 21:39:52.329581  4070 solver.cpp:218] Iteration 96900 (19.0624 iter/s, 5.24593s/100 iters), loss = 0.00403679
I0930 21:39:52.329622  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403652 (* 1 = 0.00403652 loss)
I0930 21:39:52.329627  4070 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0930 21:39:57.314009  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:39:57.523036  4070 solver.cpp:330] Iteration 97000, Testing net (#0)
I0930 21:39:58.706776  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:39:58.756552  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I0930 21:39:58.756575  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380609 (* 1 = 0.380609 loss)
I0930 21:39:58.808909  4070 solver.cpp:218] Iteration 97000 (15.4338 iter/s, 6.47927s/100 iters), loss = 0.00597032
I0930 21:39:58.808933  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597006 (* 1 = 0.00597006 loss)
I0930 21:39:58.808940  4070 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0930 21:40:04.062222  4070 solver.cpp:218] Iteration 97100 (19.0358 iter/s, 5.25327s/100 iters), loss = 0.00602997
I0930 21:40:04.062250  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0060297 (* 1 = 0.0060297 loss)
I0930 21:40:04.062256  4070 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0930 21:40:09.312695  4070 solver.cpp:218] Iteration 97200 (19.0461 iter/s, 5.25042s/100 iters), loss = 0.0048057
I0930 21:40:09.312819  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00480543 (* 1 = 0.00480543 loss)
I0930 21:40:09.312827  4070 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0930 21:40:14.561908  4070 solver.cpp:218] Iteration 97300 (19.051 iter/s, 5.24908s/100 iters), loss = 0.00702842
I0930 21:40:14.561941  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702816 (* 1 = 0.00702816 loss)
I0930 21:40:14.561949  4070 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0930 21:40:19.800545  4070 solver.cpp:218] Iteration 97400 (19.0891 iter/s, 5.23859s/100 iters), loss = 0.0216422
I0930 21:40:19.800575  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216419 (* 1 = 0.0216419 loss)
I0930 21:40:19.800590  4070 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0930 21:40:24.780376  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:40:24.990497  4070 solver.cpp:330] Iteration 97500, Testing net (#0)
I0930 21:40:26.176275  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:40:26.226743  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9084
I0930 21:40:26.226778  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380985 (* 1 = 0.380985 loss)
I0930 21:40:26.281008  4070 solver.cpp:218] Iteration 97500 (15.4311 iter/s, 6.48041s/100 iters), loss = 0.00553359
I0930 21:40:26.281041  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553332 (* 1 = 0.00553332 loss)
I0930 21:40:26.281049  4070 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0930 21:40:31.518568  4070 solver.cpp:218] Iteration 97600 (19.0931 iter/s, 5.2375s/100 iters), loss = 0.0132719
I0930 21:40:31.518597  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132717 (* 1 = 0.0132717 loss)
I0930 21:40:31.518604  4070 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0930 21:40:36.765511  4070 solver.cpp:218] Iteration 97700 (19.0589 iter/s, 5.24689s/100 iters), loss = 0.00579854
I0930 21:40:36.765552  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579828 (* 1 = 0.00579828 loss)
I0930 21:40:36.765558  4070 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0930 21:40:42.015553  4070 solver.cpp:218] Iteration 97800 (19.0477 iter/s, 5.24998s/100 iters), loss = 0.0225613
I0930 21:40:42.015662  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022561 (* 1 = 0.022561 loss)
I0930 21:40:42.015669  4070 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0930 21:40:47.261929  4070 solver.cpp:218] Iteration 97900 (19.0612 iter/s, 5.24625s/100 iters), loss = 0.00852484
I0930 21:40:47.261968  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00852458 (* 1 = 0.00852458 loss)
I0930 21:40:47.261986  4070 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0930 21:40:52.246280  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:40:52.456143  4070 solver.cpp:330] Iteration 98000, Testing net (#0)
I0930 21:40:53.650208  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:40:53.700327  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I0930 21:40:53.700352  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383279 (* 1 = 0.383279 loss)
I0930 21:40:53.752635  4070 solver.cpp:218] Iteration 98000 (15.4069 iter/s, 6.49061s/100 iters), loss = 0.0123412
I0930 21:40:53.752671  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123409 (* 1 = 0.0123409 loss)
I0930 21:40:53.752677  4070 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0930 21:40:58.989863  4070 solver.cpp:218] Iteration 98100 (19.0943 iter/s, 5.23717s/100 iters), loss = 0.0115706
I0930 21:40:58.989902  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115703 (* 1 = 0.0115703 loss)
I0930 21:40:58.989908  4070 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0930 21:41:04.239802  4070 solver.cpp:218] Iteration 98200 (19.0481 iter/s, 5.24988s/100 iters), loss = 0.00644909
I0930 21:41:04.239841  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644882 (* 1 = 0.00644882 loss)
I0930 21:41:04.239847  4070 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0930 21:41:09.484220  4070 solver.cpp:218] Iteration 98300 (19.0681 iter/s, 5.24436s/100 iters), loss = 0.00999437
I0930 21:41:09.484259  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0099941 (* 1 = 0.0099941 loss)
I0930 21:41:09.484266  4070 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0930 21:41:14.730190  4070 solver.cpp:218] Iteration 98400 (19.0625 iter/s, 5.24591s/100 iters), loss = 0.00363221
I0930 21:41:14.730352  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363194 (* 1 = 0.00363194 loss)
I0930 21:41:14.730361  4070 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0930 21:41:19.707550  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:41:19.917203  4070 solver.cpp:330] Iteration 98500, Testing net (#0)
I0930 21:41:21.108351  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:41:21.158251  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I0930 21:41:21.158284  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385937 (* 1 = 0.385937 loss)
I0930 21:41:21.210563  4070 solver.cpp:218] Iteration 98500 (15.4316 iter/s, 6.4802s/100 iters), loss = 0.00491357
I0930 21:41:21.210590  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0049133 (* 1 = 0.0049133 loss)
I0930 21:41:21.210597  4070 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0930 21:41:26.462611  4070 solver.cpp:218] Iteration 98600 (19.0404 iter/s, 5.252s/100 iters), loss = 0.0133056
I0930 21:41:26.462651  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133053 (* 1 = 0.0133053 loss)
I0930 21:41:26.462657  4070 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0930 21:41:31.703037  4070 solver.cpp:218] Iteration 98700 (19.0826 iter/s, 5.24037s/100 iters), loss = 0.0124351
I0930 21:41:31.703065  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124349 (* 1 = 0.0124349 loss)
I0930 21:41:31.703071  4070 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0930 21:41:36.949141  4070 solver.cpp:218] Iteration 98800 (19.062 iter/s, 5.24605s/100 iters), loss = 0.00271685
I0930 21:41:36.949180  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271659 (* 1 = 0.00271659 loss)
I0930 21:41:36.949187  4070 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0930 21:41:42.200798  4070 solver.cpp:218] Iteration 98900 (19.0418 iter/s, 5.2516s/100 iters), loss = 0.00209591
I0930 21:41:42.200826  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209564 (* 1 = 0.00209564 loss)
I0930 21:41:42.200842  4070 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0930 21:41:47.178798  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:41:47.393406  4070 solver.cpp:330] Iteration 99000, Testing net (#0)
I0930 21:41:48.576162  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:41:48.626304  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I0930 21:41:48.626338  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387175 (* 1 = 0.387175 loss)
I0930 21:41:48.678817  4070 solver.cpp:218] Iteration 99000 (15.4369 iter/s, 6.47797s/100 iters), loss = 0.00727771
I0930 21:41:48.678841  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727743 (* 1 = 0.00727743 loss)
I0930 21:41:48.678848  4070 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0930 21:41:53.922945  4070 solver.cpp:218] Iteration 99100 (19.0691 iter/s, 5.24408s/100 iters), loss = 0.00954987
I0930 21:41:53.922973  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00954959 (* 1 = 0.00954959 loss)
I0930 21:41:53.922978  4070 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0930 21:41:59.158700  4070 solver.cpp:218] Iteration 99200 (19.0996 iter/s, 5.2357s/100 iters), loss = 0.0185969
I0930 21:41:59.158733  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185966 (* 1 = 0.0185966 loss)
I0930 21:41:59.158740  4070 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0930 21:42:04.398166  4070 solver.cpp:218] Iteration 99300 (19.0861 iter/s, 5.23941s/100 iters), loss = 0.0159121
I0930 21:42:04.398205  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159118 (* 1 = 0.0159118 loss)
I0930 21:42:04.398211  4070 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0930 21:42:09.644001  4070 solver.cpp:218] Iteration 99400 (19.063 iter/s, 5.24577s/100 iters), loss = 0.00686014
I0930 21:42:09.644042  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685985 (* 1 = 0.00685985 loss)
I0930 21:42:09.644047  4070 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0930 21:42:14.625650  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:42:14.835584  4070 solver.cpp:330] Iteration 99500, Testing net (#0)
I0930 21:42:16.019982  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:42:16.069991  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.907
I0930 21:42:16.070025  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385242 (* 1 = 0.385242 loss)
I0930 21:42:16.122783  4070 solver.cpp:218] Iteration 99500 (15.4351 iter/s, 6.47872s/100 iters), loss = 0.0336425
I0930 21:42:16.122812  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336422 (* 1 = 0.0336422 loss)
I0930 21:42:16.122819  4070 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0930 21:42:21.370959  4070 solver.cpp:218] Iteration 99600 (19.0544 iter/s, 5.24812s/100 iters), loss = 0.00867849
I0930 21:42:21.371129  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867821 (* 1 = 0.00867821 loss)
I0930 21:42:21.371150  4070 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0930 21:42:26.618769  4070 solver.cpp:218] Iteration 99700 (19.0562 iter/s, 5.24763s/100 iters), loss = 0.01135
I0930 21:42:26.618799  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113497 (* 1 = 0.0113497 loss)
I0930 21:42:26.618805  4070 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0930 21:42:31.856695  4070 solver.cpp:218] Iteration 99800 (19.0917 iter/s, 5.23787s/100 iters), loss = 0.015695
I0930 21:42:31.856726  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156948 (* 1 = 0.0156948 loss)
I0930 21:42:31.856742  4070 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0930 21:42:37.104122  4070 solver.cpp:218] Iteration 99900 (19.0571 iter/s, 5.24738s/100 iters), loss = 0.00828817
I0930 21:42:37.104152  4070 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00828788 (* 1 = 0.00828788 loss)
I0930 21:42:37.104158  4070 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0930 21:42:42.083209  4079 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:42:42.292071  4070 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_100000.caffemodel
I0930 21:42:42.297080  4070 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res20/res20_penlu_aipha2_eta1_1study_gauss_iter_100000.solverstate
I0930 21:42:42.310976  4070 solver.cpp:310] Iteration 100000, loss = 0.0128255
I0930 21:42:42.310995  4070 solver.cpp:330] Iteration 100000, Testing net (#0)
I0930 21:42:43.494982  4080 data_layer.cpp:73] Restarting data prefetching from start.
I0930 21:42:43.544903  4070 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I0930 21:42:43.544937  4070 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37998 (* 1 = 0.37998 loss)
I0930 21:42:43.544942  4070 solver.cpp:315] Optimization Done.
I0930 21:42:43.544945  4070 caffe.cpp:259] Optimization Done.
