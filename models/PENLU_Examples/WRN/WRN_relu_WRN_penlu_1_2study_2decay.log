I1013 22:23:57.435982 13701 caffe.cpp:218] Using GPUs 0
I1013 22:23:57.454665 13701 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1013 22:23:57.672541 13701 solver.cpp:44] Initializing solver from parameters: 
test_iter: 200
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/WRN/WRN_penlu_1_2study_2decay"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
stepvalue: 50000
stepvalue: 80000
type: "Nesterov"
I1013 22:23:57.672688 13701 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1013 22:23:57.674245 13701 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1013 22:23:57.674255 13701 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1013 22:23:57.674398 13701 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1013 22:23:57.674471 13701 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1013 22:23:57.674942 13701 net.cpp:51] Initializing net from parameters: 
name: "wrn_28_10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar100/cifar100_train_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution4"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution4"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Eltwise1"
  top: "Eltwise1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution5"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution5"
  top: "Convolution6"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution6"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Eltwise2"
  top: "Eltwise2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution7"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution7"
  top: "Convolution8"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Eltwise3"
  top: "Eltwise3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution13"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Eltwise5"
  top: "Eltwise5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Eltwise6"
  top: "Eltwise6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Eltwise7"
  top: "Eltwise7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution22"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution21"
  bottom: "Convolution22"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Eltwise9"
  top: "Eltwise9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution24"
  bottom: "Eltwise9"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Eltwise10"
  top: "Eltwise10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution25"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution26"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Eltwise11"
  top: "Eltwise11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution27"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution28"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise12"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 100
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
I1013 22:23:57.675499 13701 layer_factory.hpp:77] Creating layer cifar
I1013 22:23:57.675596 13701 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar100/cifar100_train_lmdb
I1013 22:23:57.675621 13701 net.cpp:84] Creating Layer cifar
I1013 22:23:57.675628 13701 net.cpp:380] cifar -> data
I1013 22:23:57.675650 13701 net.cpp:380] cifar -> label
I1013 22:23:57.675665 13701 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto
I1013 22:23:57.677117 13701 data_layer.cpp:45] output data size: 50,3,28,28
I1013 22:23:57.678411 13701 net.cpp:122] Setting up cifar
I1013 22:23:57.678422 13701 net.cpp:129] Top shape: 50 3 28 28 (117600)
I1013 22:23:57.678426 13701 net.cpp:129] Top shape: 50 (50)
I1013 22:23:57.678428 13701 net.cpp:137] Memory required for data: 470600
I1013 22:23:57.678433 13701 layer_factory.hpp:77] Creating layer Convolution1
I1013 22:23:57.678449 13701 net.cpp:84] Creating Layer Convolution1
I1013 22:23:57.678453 13701 net.cpp:406] Convolution1 <- data
I1013 22:23:57.678462 13701 net.cpp:380] Convolution1 -> Convolution1
I1013 22:23:57.825779 13701 net.cpp:122] Setting up Convolution1
I1013 22:23:57.825804 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:57.825808 13701 net.cpp:137] Memory required for data: 2979400
I1013 22:23:57.825822 13701 layer_factory.hpp:77] Creating layer BatchNorm1
I1013 22:23:57.825845 13701 net.cpp:84] Creating Layer BatchNorm1
I1013 22:23:57.825858 13701 net.cpp:406] BatchNorm1 <- Convolution1
I1013 22:23:57.825863 13701 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1013 22:23:57.826019 13701 net.cpp:122] Setting up BatchNorm1
I1013 22:23:57.826025 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:57.826026 13701 net.cpp:137] Memory required for data: 5488200
I1013 22:23:57.826035 13701 layer_factory.hpp:77] Creating layer Scale1
I1013 22:23:57.826056 13701 net.cpp:84] Creating Layer Scale1
I1013 22:23:57.826058 13701 net.cpp:406] Scale1 <- Convolution1
I1013 22:23:57.826061 13701 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1013 22:23:57.826112 13701 layer_factory.hpp:77] Creating layer Scale1
I1013 22:23:57.826246 13701 net.cpp:122] Setting up Scale1
I1013 22:23:57.826251 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:57.826252 13701 net.cpp:137] Memory required for data: 7997000
I1013 22:23:57.826267 13701 layer_factory.hpp:77] Creating layer penlu1
I1013 22:23:57.826292 13701 net.cpp:84] Creating Layer penlu1
I1013 22:23:57.826293 13701 net.cpp:406] penlu1 <- Convolution1
I1013 22:23:57.826297 13701 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1013 22:23:57.826915 13701 net.cpp:122] Setting up penlu1
I1013 22:23:57.826925 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:57.826937 13701 net.cpp:137] Memory required for data: 10505800
I1013 22:23:57.826944 13701 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1013 22:23:57.826962 13701 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1013 22:23:57.826967 13701 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1013 22:23:57.826970 13701 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1013 22:23:57.826975 13701 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1013 22:23:57.827023 13701 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1013 22:23:57.827035 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:57.827039 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:57.827041 13701 net.cpp:137] Memory required for data: 15523400
I1013 22:23:57.827044 13701 layer_factory.hpp:77] Creating layer Convolution2
I1013 22:23:57.827050 13701 net.cpp:84] Creating Layer Convolution2
I1013 22:23:57.827054 13701 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1013 22:23:57.827069 13701 net.cpp:380] Convolution2 -> Convolution2
I1013 22:23:57.829155 13701 net.cpp:122] Setting up Convolution2
I1013 22:23:57.829165 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.829169 13701 net.cpp:137] Memory required for data: 40611400
I1013 22:23:57.829172 13701 layer_factory.hpp:77] Creating layer BatchNorm2
I1013 22:23:57.829177 13701 net.cpp:84] Creating Layer BatchNorm2
I1013 22:23:57.829180 13701 net.cpp:406] BatchNorm2 <- Convolution2
I1013 22:23:57.829193 13701 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1013 22:23:57.829349 13701 net.cpp:122] Setting up BatchNorm2
I1013 22:23:57.829354 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.829356 13701 net.cpp:137] Memory required for data: 65699400
I1013 22:23:57.829360 13701 layer_factory.hpp:77] Creating layer Scale2
I1013 22:23:57.829365 13701 net.cpp:84] Creating Layer Scale2
I1013 22:23:57.829368 13701 net.cpp:406] Scale2 <- Convolution2
I1013 22:23:57.829371 13701 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1013 22:23:57.829406 13701 layer_factory.hpp:77] Creating layer Scale2
I1013 22:23:57.829488 13701 net.cpp:122] Setting up Scale2
I1013 22:23:57.829494 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.829497 13701 net.cpp:137] Memory required for data: 90787400
I1013 22:23:57.829510 13701 layer_factory.hpp:77] Creating layer penlu2
I1013 22:23:57.829516 13701 net.cpp:84] Creating Layer penlu2
I1013 22:23:57.829519 13701 net.cpp:406] penlu2 <- Convolution2
I1013 22:23:57.829524 13701 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1013 22:23:57.830183 13701 net.cpp:122] Setting up penlu2
I1013 22:23:57.830193 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.830195 13701 net.cpp:137] Memory required for data: 115875400
I1013 22:23:57.830202 13701 layer_factory.hpp:77] Creating layer Convolution3
I1013 22:23:57.830210 13701 net.cpp:84] Creating Layer Convolution3
I1013 22:23:57.830214 13701 net.cpp:406] Convolution3 <- Convolution2
I1013 22:23:57.830217 13701 net.cpp:380] Convolution3 -> Convolution3
I1013 22:23:57.836314 13701 net.cpp:122] Setting up Convolution3
I1013 22:23:57.836324 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.836328 13701 net.cpp:137] Memory required for data: 140963400
I1013 22:23:57.836331 13701 layer_factory.hpp:77] Creating layer Convolution4
I1013 22:23:57.836349 13701 net.cpp:84] Creating Layer Convolution4
I1013 22:23:57.836354 13701 net.cpp:406] Convolution4 <- Convolution1_penlu1_0_split_1
I1013 22:23:57.836357 13701 net.cpp:380] Convolution4 -> Convolution4
I1013 22:23:57.837258 13701 net.cpp:122] Setting up Convolution4
I1013 22:23:57.837270 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.837272 13701 net.cpp:137] Memory required for data: 166051400
I1013 22:23:57.837276 13701 layer_factory.hpp:77] Creating layer Eltwise1
I1013 22:23:57.837281 13701 net.cpp:84] Creating Layer Eltwise1
I1013 22:23:57.837292 13701 net.cpp:406] Eltwise1 <- Convolution3
I1013 22:23:57.837296 13701 net.cpp:406] Eltwise1 <- Convolution4
I1013 22:23:57.837299 13701 net.cpp:380] Eltwise1 -> Eltwise1
I1013 22:23:57.837333 13701 net.cpp:122] Setting up Eltwise1
I1013 22:23:57.837339 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.837342 13701 net.cpp:137] Memory required for data: 191139400
I1013 22:23:57.837343 13701 layer_factory.hpp:77] Creating layer BatchNorm3
I1013 22:23:57.837349 13701 net.cpp:84] Creating Layer BatchNorm3
I1013 22:23:57.837352 13701 net.cpp:406] BatchNorm3 <- Eltwise1
I1013 22:23:57.837355 13701 net.cpp:367] BatchNorm3 -> Eltwise1 (in-place)
I1013 22:23:57.837501 13701 net.cpp:122] Setting up BatchNorm3
I1013 22:23:57.837507 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.837508 13701 net.cpp:137] Memory required for data: 216227400
I1013 22:23:57.837513 13701 layer_factory.hpp:77] Creating layer Scale3
I1013 22:23:57.837518 13701 net.cpp:84] Creating Layer Scale3
I1013 22:23:57.837522 13701 net.cpp:406] Scale3 <- Eltwise1
I1013 22:23:57.837525 13701 net.cpp:367] Scale3 -> Eltwise1 (in-place)
I1013 22:23:57.837553 13701 layer_factory.hpp:77] Creating layer Scale3
I1013 22:23:57.837628 13701 net.cpp:122] Setting up Scale3
I1013 22:23:57.837636 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.837641 13701 net.cpp:137] Memory required for data: 241315400
I1013 22:23:57.837647 13701 layer_factory.hpp:77] Creating layer penlu3
I1013 22:23:57.837656 13701 net.cpp:84] Creating Layer penlu3
I1013 22:23:57.837667 13701 net.cpp:406] penlu3 <- Eltwise1
I1013 22:23:57.837677 13701 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1013 22:23:57.837888 13701 net.cpp:122] Setting up penlu3
I1013 22:23:57.837898 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.837901 13701 net.cpp:137] Memory required for data: 266403400
I1013 22:23:57.837924 13701 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1013 22:23:57.837935 13701 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1013 22:23:57.837940 13701 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1013 22:23:57.837946 13701 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1013 22:23:57.837956 13701 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1013 22:23:57.837987 13701 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1013 22:23:57.837994 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.837999 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.838004 13701 net.cpp:137] Memory required for data: 316579400
I1013 22:23:57.838009 13701 layer_factory.hpp:77] Creating layer Convolution5
I1013 22:23:57.838021 13701 net.cpp:84] Creating Layer Convolution5
I1013 22:23:57.838026 13701 net.cpp:406] Convolution5 <- Eltwise1_penlu3_0_split_0
I1013 22:23:57.838032 13701 net.cpp:380] Convolution5 -> Convolution5
I1013 22:23:57.845129 13701 net.cpp:122] Setting up Convolution5
I1013 22:23:57.845142 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.845147 13701 net.cpp:137] Memory required for data: 341667400
I1013 22:23:57.845155 13701 layer_factory.hpp:77] Creating layer BatchNorm4
I1013 22:23:57.845165 13701 net.cpp:84] Creating Layer BatchNorm4
I1013 22:23:57.845170 13701 net.cpp:406] BatchNorm4 <- Convolution5
I1013 22:23:57.845178 13701 net.cpp:367] BatchNorm4 -> Convolution5 (in-place)
I1013 22:23:57.845325 13701 net.cpp:122] Setting up BatchNorm4
I1013 22:23:57.845333 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.845337 13701 net.cpp:137] Memory required for data: 366755400
I1013 22:23:57.845360 13701 layer_factory.hpp:77] Creating layer Scale4
I1013 22:23:57.845368 13701 net.cpp:84] Creating Layer Scale4
I1013 22:23:57.845372 13701 net.cpp:406] Scale4 <- Convolution5
I1013 22:23:57.845381 13701 net.cpp:367] Scale4 -> Convolution5 (in-place)
I1013 22:23:57.845425 13701 layer_factory.hpp:77] Creating layer Scale4
I1013 22:23:57.845510 13701 net.cpp:122] Setting up Scale4
I1013 22:23:57.845526 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.845531 13701 net.cpp:137] Memory required for data: 391843400
I1013 22:23:57.845538 13701 layer_factory.hpp:77] Creating layer penlu4
I1013 22:23:57.845548 13701 net.cpp:84] Creating Layer penlu4
I1013 22:23:57.845553 13701 net.cpp:406] penlu4 <- Convolution5
I1013 22:23:57.845561 13701 net.cpp:367] penlu4 -> Convolution5 (in-place)
I1013 22:23:57.845728 13701 net.cpp:122] Setting up penlu4
I1013 22:23:57.845736 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.845741 13701 net.cpp:137] Memory required for data: 416931400
I1013 22:23:57.845748 13701 layer_factory.hpp:77] Creating layer Convolution6
I1013 22:23:57.845757 13701 net.cpp:84] Creating Layer Convolution6
I1013 22:23:57.845762 13701 net.cpp:406] Convolution6 <- Convolution5
I1013 22:23:57.845772 13701 net.cpp:380] Convolution6 -> Convolution6
I1013 22:23:57.852490 13701 net.cpp:122] Setting up Convolution6
I1013 22:23:57.852504 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.852509 13701 net.cpp:137] Memory required for data: 442019400
I1013 22:23:57.852515 13701 layer_factory.hpp:77] Creating layer Eltwise2
I1013 22:23:57.852526 13701 net.cpp:84] Creating Layer Eltwise2
I1013 22:23:57.852532 13701 net.cpp:406] Eltwise2 <- Convolution6
I1013 22:23:57.852537 13701 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1013 22:23:57.852545 13701 net.cpp:380] Eltwise2 -> Eltwise2
I1013 22:23:57.852572 13701 net.cpp:122] Setting up Eltwise2
I1013 22:23:57.852579 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.852583 13701 net.cpp:137] Memory required for data: 467107400
I1013 22:23:57.852587 13701 layer_factory.hpp:77] Creating layer BatchNorm5
I1013 22:23:57.852594 13701 net.cpp:84] Creating Layer BatchNorm5
I1013 22:23:57.852599 13701 net.cpp:406] BatchNorm5 <- Eltwise2
I1013 22:23:57.852607 13701 net.cpp:367] BatchNorm5 -> Eltwise2 (in-place)
I1013 22:23:57.852746 13701 net.cpp:122] Setting up BatchNorm5
I1013 22:23:57.852754 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.852758 13701 net.cpp:137] Memory required for data: 492195400
I1013 22:23:57.852767 13701 layer_factory.hpp:77] Creating layer Scale5
I1013 22:23:57.852776 13701 net.cpp:84] Creating Layer Scale5
I1013 22:23:57.852780 13701 net.cpp:406] Scale5 <- Eltwise2
I1013 22:23:57.852788 13701 net.cpp:367] Scale5 -> Eltwise2 (in-place)
I1013 22:23:57.852821 13701 layer_factory.hpp:77] Creating layer Scale5
I1013 22:23:57.852912 13701 net.cpp:122] Setting up Scale5
I1013 22:23:57.852919 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.852924 13701 net.cpp:137] Memory required for data: 517283400
I1013 22:23:57.852931 13701 layer_factory.hpp:77] Creating layer penlu5
I1013 22:23:57.852941 13701 net.cpp:84] Creating Layer penlu5
I1013 22:23:57.852946 13701 net.cpp:406] penlu5 <- Eltwise2
I1013 22:23:57.852954 13701 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1013 22:23:57.853124 13701 net.cpp:122] Setting up penlu5
I1013 22:23:57.853132 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.853137 13701 net.cpp:137] Memory required for data: 542371400
I1013 22:23:57.853145 13701 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1013 22:23:57.853152 13701 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1013 22:23:57.853157 13701 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1013 22:23:57.853163 13701 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1013 22:23:57.853173 13701 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1013 22:23:57.853201 13701 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1013 22:23:57.853209 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.853214 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.853220 13701 net.cpp:137] Memory required for data: 592547400
I1013 22:23:57.853224 13701 layer_factory.hpp:77] Creating layer Convolution7
I1013 22:23:57.853230 13701 net.cpp:84] Creating Layer Convolution7
I1013 22:23:57.853241 13701 net.cpp:406] Convolution7 <- Eltwise2_penlu5_0_split_0
I1013 22:23:57.853246 13701 net.cpp:380] Convolution7 -> Convolution7
I1013 22:23:57.859824 13701 net.cpp:122] Setting up Convolution7
I1013 22:23:57.859840 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.859843 13701 net.cpp:137] Memory required for data: 617635400
I1013 22:23:57.859848 13701 layer_factory.hpp:77] Creating layer BatchNorm6
I1013 22:23:57.859858 13701 net.cpp:84] Creating Layer BatchNorm6
I1013 22:23:57.859874 13701 net.cpp:406] BatchNorm6 <- Convolution7
I1013 22:23:57.859882 13701 net.cpp:367] BatchNorm6 -> Convolution7 (in-place)
I1013 22:23:57.860033 13701 net.cpp:122] Setting up BatchNorm6
I1013 22:23:57.860038 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.860040 13701 net.cpp:137] Memory required for data: 642723400
I1013 22:23:57.860045 13701 layer_factory.hpp:77] Creating layer Scale6
I1013 22:23:57.860051 13701 net.cpp:84] Creating Layer Scale6
I1013 22:23:57.860054 13701 net.cpp:406] Scale6 <- Convolution7
I1013 22:23:57.860059 13701 net.cpp:367] Scale6 -> Convolution7 (in-place)
I1013 22:23:57.860111 13701 layer_factory.hpp:77] Creating layer Scale6
I1013 22:23:57.860193 13701 net.cpp:122] Setting up Scale6
I1013 22:23:57.860198 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.860200 13701 net.cpp:137] Memory required for data: 667811400
I1013 22:23:57.860204 13701 layer_factory.hpp:77] Creating layer penlu6
I1013 22:23:57.860210 13701 net.cpp:84] Creating Layer penlu6
I1013 22:23:57.860213 13701 net.cpp:406] penlu6 <- Convolution7
I1013 22:23:57.860219 13701 net.cpp:367] penlu6 -> Convolution7 (in-place)
I1013 22:23:57.860385 13701 net.cpp:122] Setting up penlu6
I1013 22:23:57.860391 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.860394 13701 net.cpp:137] Memory required for data: 692899400
I1013 22:23:57.860397 13701 layer_factory.hpp:77] Creating layer Convolution8
I1013 22:23:57.860404 13701 net.cpp:84] Creating Layer Convolution8
I1013 22:23:57.860407 13701 net.cpp:406] Convolution8 <- Convolution7
I1013 22:23:57.860412 13701 net.cpp:380] Convolution8 -> Convolution8
I1013 22:23:57.866973 13701 net.cpp:122] Setting up Convolution8
I1013 22:23:57.866984 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.866987 13701 net.cpp:137] Memory required for data: 717987400
I1013 22:23:57.866991 13701 layer_factory.hpp:77] Creating layer Eltwise3
I1013 22:23:57.867000 13701 net.cpp:84] Creating Layer Eltwise3
I1013 22:23:57.867004 13701 net.cpp:406] Eltwise3 <- Convolution8
I1013 22:23:57.867023 13701 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1013 22:23:57.867029 13701 net.cpp:380] Eltwise3 -> Eltwise3
I1013 22:23:57.867063 13701 net.cpp:122] Setting up Eltwise3
I1013 22:23:57.867069 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.867070 13701 net.cpp:137] Memory required for data: 743075400
I1013 22:23:57.867074 13701 layer_factory.hpp:77] Creating layer BatchNorm7
I1013 22:23:57.867079 13701 net.cpp:84] Creating Layer BatchNorm7
I1013 22:23:57.867080 13701 net.cpp:406] BatchNorm7 <- Eltwise3
I1013 22:23:57.867084 13701 net.cpp:367] BatchNorm7 -> Eltwise3 (in-place)
I1013 22:23:57.867215 13701 net.cpp:122] Setting up BatchNorm7
I1013 22:23:57.867220 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.867223 13701 net.cpp:137] Memory required for data: 768163400
I1013 22:23:57.867228 13701 layer_factory.hpp:77] Creating layer Scale7
I1013 22:23:57.867233 13701 net.cpp:84] Creating Layer Scale7
I1013 22:23:57.867234 13701 net.cpp:406] Scale7 <- Eltwise3
I1013 22:23:57.867238 13701 net.cpp:367] Scale7 -> Eltwise3 (in-place)
I1013 22:23:57.867269 13701 layer_factory.hpp:77] Creating layer Scale7
I1013 22:23:57.867348 13701 net.cpp:122] Setting up Scale7
I1013 22:23:57.867354 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.867357 13701 net.cpp:137] Memory required for data: 793251400
I1013 22:23:57.867360 13701 layer_factory.hpp:77] Creating layer penlu7
I1013 22:23:57.867377 13701 net.cpp:84] Creating Layer penlu7
I1013 22:23:57.867380 13701 net.cpp:406] penlu7 <- Eltwise3
I1013 22:23:57.867386 13701 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1013 22:23:57.867544 13701 net.cpp:122] Setting up penlu7
I1013 22:23:57.867550 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.867552 13701 net.cpp:137] Memory required for data: 818339400
I1013 22:23:57.867564 13701 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1013 22:23:57.867570 13701 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1013 22:23:57.867575 13701 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1013 22:23:57.867580 13701 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1013 22:23:57.867586 13701 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1013 22:23:57.867612 13701 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1013 22:23:57.867617 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.867620 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.867622 13701 net.cpp:137] Memory required for data: 868515400
I1013 22:23:57.867625 13701 layer_factory.hpp:77] Creating layer Convolution9
I1013 22:23:57.867630 13701 net.cpp:84] Creating Layer Convolution9
I1013 22:23:57.867632 13701 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_0
I1013 22:23:57.867637 13701 net.cpp:380] Convolution9 -> Convolution9
I1013 22:23:57.874199 13701 net.cpp:122] Setting up Convolution9
I1013 22:23:57.874210 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.874215 13701 net.cpp:137] Memory required for data: 893603400
I1013 22:23:57.874220 13701 layer_factory.hpp:77] Creating layer BatchNorm8
I1013 22:23:57.874227 13701 net.cpp:84] Creating Layer BatchNorm8
I1013 22:23:57.874231 13701 net.cpp:406] BatchNorm8 <- Convolution9
I1013 22:23:57.874238 13701 net.cpp:367] BatchNorm8 -> Convolution9 (in-place)
I1013 22:23:57.874377 13701 net.cpp:122] Setting up BatchNorm8
I1013 22:23:57.874382 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.874387 13701 net.cpp:137] Memory required for data: 918691400
I1013 22:23:57.874392 13701 layer_factory.hpp:77] Creating layer Scale8
I1013 22:23:57.874397 13701 net.cpp:84] Creating Layer Scale8
I1013 22:23:57.874402 13701 net.cpp:406] Scale8 <- Convolution9
I1013 22:23:57.874408 13701 net.cpp:367] Scale8 -> Convolution9 (in-place)
I1013 22:23:57.874436 13701 layer_factory.hpp:77] Creating layer Scale8
I1013 22:23:57.874519 13701 net.cpp:122] Setting up Scale8
I1013 22:23:57.874526 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.874529 13701 net.cpp:137] Memory required for data: 943779400
I1013 22:23:57.874536 13701 layer_factory.hpp:77] Creating layer penlu8
I1013 22:23:57.874544 13701 net.cpp:84] Creating Layer penlu8
I1013 22:23:57.874547 13701 net.cpp:406] penlu8 <- Convolution9
I1013 22:23:57.874553 13701 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1013 22:23:57.874712 13701 net.cpp:122] Setting up penlu8
I1013 22:23:57.874719 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.874723 13701 net.cpp:137] Memory required for data: 968867400
I1013 22:23:57.874730 13701 layer_factory.hpp:77] Creating layer Convolution10
I1013 22:23:57.874737 13701 net.cpp:84] Creating Layer Convolution10
I1013 22:23:57.874742 13701 net.cpp:406] Convolution10 <- Convolution9
I1013 22:23:57.874747 13701 net.cpp:380] Convolution10 -> Convolution10
I1013 22:23:57.881347 13701 net.cpp:122] Setting up Convolution10
I1013 22:23:57.881359 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.881366 13701 net.cpp:137] Memory required for data: 993955400
I1013 22:23:57.881371 13701 layer_factory.hpp:77] Creating layer Eltwise4
I1013 22:23:57.881378 13701 net.cpp:84] Creating Layer Eltwise4
I1013 22:23:57.881383 13701 net.cpp:406] Eltwise4 <- Convolution10
I1013 22:23:57.881387 13701 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1013 22:23:57.881392 13701 net.cpp:380] Eltwise4 -> Eltwise4
I1013 22:23:57.881417 13701 net.cpp:122] Setting up Eltwise4
I1013 22:23:57.881431 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.881436 13701 net.cpp:137] Memory required for data: 1019043400
I1013 22:23:57.881440 13701 layer_factory.hpp:77] Creating layer Eltwise4_Eltwise4_0_split
I1013 22:23:57.881448 13701 net.cpp:84] Creating Layer Eltwise4_Eltwise4_0_split
I1013 22:23:57.881451 13701 net.cpp:406] Eltwise4_Eltwise4_0_split <- Eltwise4
I1013 22:23:57.881458 13701 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I1013 22:23:57.881465 13701 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I1013 22:23:57.881494 13701 net.cpp:122] Setting up Eltwise4_Eltwise4_0_split
I1013 22:23:57.881500 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.881505 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:57.881510 13701 net.cpp:137] Memory required for data: 1069219400
I1013 22:23:57.881513 13701 layer_factory.hpp:77] Creating layer Convolution11
I1013 22:23:57.881523 13701 net.cpp:84] Creating Layer Convolution11
I1013 22:23:57.881527 13701 net.cpp:406] Convolution11 <- Eltwise4_Eltwise4_0_split_0
I1013 22:23:57.881533 13701 net.cpp:380] Convolution11 -> Convolution11
I1013 22:23:57.893610 13701 net.cpp:122] Setting up Convolution11
I1013 22:23:57.893627 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.893630 13701 net.cpp:137] Memory required for data: 1081763400
I1013 22:23:57.893635 13701 layer_factory.hpp:77] Creating layer BatchNorm9
I1013 22:23:57.893643 13701 net.cpp:84] Creating Layer BatchNorm9
I1013 22:23:57.893648 13701 net.cpp:406] BatchNorm9 <- Convolution11
I1013 22:23:57.893666 13701 net.cpp:367] BatchNorm9 -> Convolution11 (in-place)
I1013 22:23:57.893836 13701 net.cpp:122] Setting up BatchNorm9
I1013 22:23:57.893841 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.893853 13701 net.cpp:137] Memory required for data: 1094307400
I1013 22:23:57.893859 13701 layer_factory.hpp:77] Creating layer Scale9
I1013 22:23:57.893865 13701 net.cpp:84] Creating Layer Scale9
I1013 22:23:57.893868 13701 net.cpp:406] Scale9 <- Convolution11
I1013 22:23:57.893877 13701 net.cpp:367] Scale9 -> Convolution11 (in-place)
I1013 22:23:57.893935 13701 layer_factory.hpp:77] Creating layer Scale9
I1013 22:23:57.894044 13701 net.cpp:122] Setting up Scale9
I1013 22:23:57.894049 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.894052 13701 net.cpp:137] Memory required for data: 1106851400
I1013 22:23:57.894055 13701 layer_factory.hpp:77] Creating layer penlu9
I1013 22:23:57.894062 13701 net.cpp:84] Creating Layer penlu9
I1013 22:23:57.894064 13701 net.cpp:406] penlu9 <- Convolution11
I1013 22:23:57.894070 13701 net.cpp:367] penlu9 -> Convolution11 (in-place)
I1013 22:23:57.894223 13701 net.cpp:122] Setting up penlu9
I1013 22:23:57.894229 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.894232 13701 net.cpp:137] Memory required for data: 1119395400
I1013 22:23:57.894237 13701 layer_factory.hpp:77] Creating layer Convolution12
I1013 22:23:57.894243 13701 net.cpp:84] Creating Layer Convolution12
I1013 22:23:57.894246 13701 net.cpp:406] Convolution12 <- Convolution11
I1013 22:23:57.894253 13701 net.cpp:380] Convolution12 -> Convolution12
I1013 22:23:57.915899 13701 net.cpp:122] Setting up Convolution12
I1013 22:23:57.915926 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.915930 13701 net.cpp:137] Memory required for data: 1131939400
I1013 22:23:57.915935 13701 layer_factory.hpp:77] Creating layer Convolution13
I1013 22:23:57.915948 13701 net.cpp:84] Creating Layer Convolution13
I1013 22:23:57.915956 13701 net.cpp:406] Convolution13 <- Eltwise4_Eltwise4_0_split_1
I1013 22:23:57.915964 13701 net.cpp:380] Convolution13 -> Convolution13
I1013 22:23:57.918198 13701 net.cpp:122] Setting up Convolution13
I1013 22:23:57.918213 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.918218 13701 net.cpp:137] Memory required for data: 1144483400
I1013 22:23:57.918226 13701 layer_factory.hpp:77] Creating layer Eltwise5
I1013 22:23:57.918272 13701 net.cpp:84] Creating Layer Eltwise5
I1013 22:23:57.918287 13701 net.cpp:406] Eltwise5 <- Convolution12
I1013 22:23:57.918308 13701 net.cpp:406] Eltwise5 <- Convolution13
I1013 22:23:57.918326 13701 net.cpp:380] Eltwise5 -> Eltwise5
I1013 22:23:57.918371 13701 net.cpp:122] Setting up Eltwise5
I1013 22:23:57.918380 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.918396 13701 net.cpp:137] Memory required for data: 1157027400
I1013 22:23:57.918401 13701 layer_factory.hpp:77] Creating layer BatchNorm10
I1013 22:23:57.918417 13701 net.cpp:84] Creating Layer BatchNorm10
I1013 22:23:57.918431 13701 net.cpp:406] BatchNorm10 <- Eltwise5
I1013 22:23:57.918437 13701 net.cpp:367] BatchNorm10 -> Eltwise5 (in-place)
I1013 22:23:57.918668 13701 net.cpp:122] Setting up BatchNorm10
I1013 22:23:57.918680 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.918695 13701 net.cpp:137] Memory required for data: 1169571400
I1013 22:23:57.918715 13701 layer_factory.hpp:77] Creating layer Scale10
I1013 22:23:57.918735 13701 net.cpp:84] Creating Layer Scale10
I1013 22:23:57.918740 13701 net.cpp:406] Scale10 <- Eltwise5
I1013 22:23:57.918756 13701 net.cpp:367] Scale10 -> Eltwise5 (in-place)
I1013 22:23:57.918844 13701 layer_factory.hpp:77] Creating layer Scale10
I1013 22:23:57.919013 13701 net.cpp:122] Setting up Scale10
I1013 22:23:57.919021 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.919024 13701 net.cpp:137] Memory required for data: 1182115400
I1013 22:23:57.919028 13701 layer_factory.hpp:77] Creating layer penlu10
I1013 22:23:57.919051 13701 net.cpp:84] Creating Layer penlu10
I1013 22:23:57.919055 13701 net.cpp:406] penlu10 <- Eltwise5
I1013 22:23:57.919059 13701 net.cpp:367] penlu10 -> Eltwise5 (in-place)
I1013 22:23:57.919222 13701 net.cpp:122] Setting up penlu10
I1013 22:23:57.919227 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.919230 13701 net.cpp:137] Memory required for data: 1194659400
I1013 22:23:57.919234 13701 layer_factory.hpp:77] Creating layer Eltwise5_penlu10_0_split
I1013 22:23:57.919239 13701 net.cpp:84] Creating Layer Eltwise5_penlu10_0_split
I1013 22:23:57.919243 13701 net.cpp:406] Eltwise5_penlu10_0_split <- Eltwise5
I1013 22:23:57.919247 13701 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_0
I1013 22:23:57.919251 13701 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_1
I1013 22:23:57.919276 13701 net.cpp:122] Setting up Eltwise5_penlu10_0_split
I1013 22:23:57.919281 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.919284 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.919286 13701 net.cpp:137] Memory required for data: 1219747400
I1013 22:23:57.919288 13701 layer_factory.hpp:77] Creating layer Convolution14
I1013 22:23:57.919294 13701 net.cpp:84] Creating Layer Convolution14
I1013 22:23:57.919298 13701 net.cpp:406] Convolution14 <- Eltwise5_penlu10_0_split_0
I1013 22:23:57.919302 13701 net.cpp:380] Convolution14 -> Convolution14
I1013 22:23:57.941048 13701 net.cpp:122] Setting up Convolution14
I1013 22:23:57.941062 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.941066 13701 net.cpp:137] Memory required for data: 1232291400
I1013 22:23:57.941079 13701 layer_factory.hpp:77] Creating layer BatchNorm11
I1013 22:23:57.941085 13701 net.cpp:84] Creating Layer BatchNorm11
I1013 22:23:57.941099 13701 net.cpp:406] BatchNorm11 <- Convolution14
I1013 22:23:57.941104 13701 net.cpp:367] BatchNorm11 -> Convolution14 (in-place)
I1013 22:23:57.941282 13701 net.cpp:122] Setting up BatchNorm11
I1013 22:23:57.941287 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.941298 13701 net.cpp:137] Memory required for data: 1244835400
I1013 22:23:57.941303 13701 layer_factory.hpp:77] Creating layer Scale11
I1013 22:23:57.941308 13701 net.cpp:84] Creating Layer Scale11
I1013 22:23:57.941310 13701 net.cpp:406] Scale11 <- Convolution14
I1013 22:23:57.941316 13701 net.cpp:367] Scale11 -> Convolution14 (in-place)
I1013 22:23:57.941359 13701 layer_factory.hpp:77] Creating layer Scale11
I1013 22:23:57.941443 13701 net.cpp:122] Setting up Scale11
I1013 22:23:57.941448 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.941450 13701 net.cpp:137] Memory required for data: 1257379400
I1013 22:23:57.941454 13701 layer_factory.hpp:77] Creating layer penlu11
I1013 22:23:57.941460 13701 net.cpp:84] Creating Layer penlu11
I1013 22:23:57.941463 13701 net.cpp:406] penlu11 <- Convolution14
I1013 22:23:57.941468 13701 net.cpp:367] penlu11 -> Convolution14 (in-place)
I1013 22:23:57.941619 13701 net.cpp:122] Setting up penlu11
I1013 22:23:57.941625 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.941628 13701 net.cpp:137] Memory required for data: 1269923400
I1013 22:23:57.941632 13701 layer_factory.hpp:77] Creating layer Convolution15
I1013 22:23:57.941639 13701 net.cpp:84] Creating Layer Convolution15
I1013 22:23:57.941642 13701 net.cpp:406] Convolution15 <- Convolution14
I1013 22:23:57.941648 13701 net.cpp:380] Convolution15 -> Convolution15
I1013 22:23:57.963908 13701 net.cpp:122] Setting up Convolution15
I1013 22:23:57.963929 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.963932 13701 net.cpp:137] Memory required for data: 1282467400
I1013 22:23:57.963937 13701 layer_factory.hpp:77] Creating layer Eltwise6
I1013 22:23:57.963948 13701 net.cpp:84] Creating Layer Eltwise6
I1013 22:23:57.963953 13701 net.cpp:406] Eltwise6 <- Convolution15
I1013 22:23:57.963968 13701 net.cpp:406] Eltwise6 <- Eltwise5_penlu10_0_split_1
I1013 22:23:57.963971 13701 net.cpp:380] Eltwise6 -> Eltwise6
I1013 22:23:57.964016 13701 net.cpp:122] Setting up Eltwise6
I1013 22:23:57.964031 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.964033 13701 net.cpp:137] Memory required for data: 1295011400
I1013 22:23:57.964035 13701 layer_factory.hpp:77] Creating layer BatchNorm12
I1013 22:23:57.964040 13701 net.cpp:84] Creating Layer BatchNorm12
I1013 22:23:57.964043 13701 net.cpp:406] BatchNorm12 <- Eltwise6
I1013 22:23:57.964046 13701 net.cpp:367] BatchNorm12 -> Eltwise6 (in-place)
I1013 22:23:57.964231 13701 net.cpp:122] Setting up BatchNorm12
I1013 22:23:57.964236 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.964238 13701 net.cpp:137] Memory required for data: 1307555400
I1013 22:23:57.964243 13701 layer_factory.hpp:77] Creating layer Scale12
I1013 22:23:57.964249 13701 net.cpp:84] Creating Layer Scale12
I1013 22:23:57.964251 13701 net.cpp:406] Scale12 <- Eltwise6
I1013 22:23:57.964254 13701 net.cpp:367] Scale12 -> Eltwise6 (in-place)
I1013 22:23:57.964320 13701 layer_factory.hpp:77] Creating layer Scale12
I1013 22:23:57.964473 13701 net.cpp:122] Setting up Scale12
I1013 22:23:57.964479 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.964481 13701 net.cpp:137] Memory required for data: 1320099400
I1013 22:23:57.964485 13701 layer_factory.hpp:77] Creating layer penlu12
I1013 22:23:57.964493 13701 net.cpp:84] Creating Layer penlu12
I1013 22:23:57.964494 13701 net.cpp:406] penlu12 <- Eltwise6
I1013 22:23:57.964498 13701 net.cpp:367] penlu12 -> Eltwise6 (in-place)
I1013 22:23:57.964682 13701 net.cpp:122] Setting up penlu12
I1013 22:23:57.964689 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.964690 13701 net.cpp:137] Memory required for data: 1332643400
I1013 22:23:57.964694 13701 layer_factory.hpp:77] Creating layer Eltwise6_penlu12_0_split
I1013 22:23:57.964705 13701 net.cpp:84] Creating Layer Eltwise6_penlu12_0_split
I1013 22:23:57.964707 13701 net.cpp:406] Eltwise6_penlu12_0_split <- Eltwise6
I1013 22:23:57.964721 13701 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_0
I1013 22:23:57.964727 13701 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_1
I1013 22:23:57.964773 13701 net.cpp:122] Setting up Eltwise6_penlu12_0_split
I1013 22:23:57.964788 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.964790 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.964792 13701 net.cpp:137] Memory required for data: 1357731400
I1013 22:23:57.964824 13701 layer_factory.hpp:77] Creating layer Convolution16
I1013 22:23:57.964840 13701 net.cpp:84] Creating Layer Convolution16
I1013 22:23:57.964845 13701 net.cpp:406] Convolution16 <- Eltwise6_penlu12_0_split_0
I1013 22:23:57.964848 13701 net.cpp:380] Convolution16 -> Convolution16
I1013 22:23:57.986970 13701 net.cpp:122] Setting up Convolution16
I1013 22:23:57.986989 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.986994 13701 net.cpp:137] Memory required for data: 1370275400
I1013 22:23:57.986999 13701 layer_factory.hpp:77] Creating layer BatchNorm13
I1013 22:23:57.987006 13701 net.cpp:84] Creating Layer BatchNorm13
I1013 22:23:57.987020 13701 net.cpp:406] BatchNorm13 <- Convolution16
I1013 22:23:57.987025 13701 net.cpp:367] BatchNorm13 -> Convolution16 (in-place)
I1013 22:23:57.987221 13701 net.cpp:122] Setting up BatchNorm13
I1013 22:23:57.987226 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.987228 13701 net.cpp:137] Memory required for data: 1382819400
I1013 22:23:57.987234 13701 layer_factory.hpp:77] Creating layer Scale13
I1013 22:23:57.987239 13701 net.cpp:84] Creating Layer Scale13
I1013 22:23:57.987242 13701 net.cpp:406] Scale13 <- Convolution16
I1013 22:23:57.987246 13701 net.cpp:367] Scale13 -> Convolution16 (in-place)
I1013 22:23:57.987313 13701 layer_factory.hpp:77] Creating layer Scale13
I1013 22:23:57.987458 13701 net.cpp:122] Setting up Scale13
I1013 22:23:57.987463 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.987465 13701 net.cpp:137] Memory required for data: 1395363400
I1013 22:23:57.987469 13701 layer_factory.hpp:77] Creating layer penlu13
I1013 22:23:57.987475 13701 net.cpp:84] Creating Layer penlu13
I1013 22:23:57.987478 13701 net.cpp:406] penlu13 <- Convolution16
I1013 22:23:57.987483 13701 net.cpp:367] penlu13 -> Convolution16 (in-place)
I1013 22:23:57.987668 13701 net.cpp:122] Setting up penlu13
I1013 22:23:57.987673 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:57.987675 13701 net.cpp:137] Memory required for data: 1407907400
I1013 22:23:57.987680 13701 layer_factory.hpp:77] Creating layer Convolution17
I1013 22:23:57.987687 13701 net.cpp:84] Creating Layer Convolution17
I1013 22:23:57.987689 13701 net.cpp:406] Convolution17 <- Convolution16
I1013 22:23:57.987704 13701 net.cpp:380] Convolution17 -> Convolution17
I1013 22:23:58.009212 13701 net.cpp:122] Setting up Convolution17
I1013 22:23:58.009232 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.009235 13701 net.cpp:137] Memory required for data: 1420451400
I1013 22:23:58.009240 13701 layer_factory.hpp:77] Creating layer Eltwise7
I1013 22:23:58.009259 13701 net.cpp:84] Creating Layer Eltwise7
I1013 22:23:58.009263 13701 net.cpp:406] Eltwise7 <- Convolution17
I1013 22:23:58.009268 13701 net.cpp:406] Eltwise7 <- Eltwise6_penlu12_0_split_1
I1013 22:23:58.009282 13701 net.cpp:380] Eltwise7 -> Eltwise7
I1013 22:23:58.009318 13701 net.cpp:122] Setting up Eltwise7
I1013 22:23:58.009335 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.009340 13701 net.cpp:137] Memory required for data: 1432995400
I1013 22:23:58.009352 13701 layer_factory.hpp:77] Creating layer BatchNorm14
I1013 22:23:58.009359 13701 net.cpp:84] Creating Layer BatchNorm14
I1013 22:23:58.009364 13701 net.cpp:406] BatchNorm14 <- Eltwise7
I1013 22:23:58.009369 13701 net.cpp:367] BatchNorm14 -> Eltwise7 (in-place)
I1013 22:23:58.009624 13701 net.cpp:122] Setting up BatchNorm14
I1013 22:23:58.009634 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.009647 13701 net.cpp:137] Memory required for data: 1445539400
I1013 22:23:58.009665 13701 layer_factory.hpp:77] Creating layer Scale14
I1013 22:23:58.009675 13701 net.cpp:84] Creating Layer Scale14
I1013 22:23:58.009680 13701 net.cpp:406] Scale14 <- Eltwise7
I1013 22:23:58.009694 13701 net.cpp:367] Scale14 -> Eltwise7 (in-place)
I1013 22:23:58.009784 13701 layer_factory.hpp:77] Creating layer Scale14
I1013 22:23:58.009969 13701 net.cpp:122] Setting up Scale14
I1013 22:23:58.009989 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.010002 13701 net.cpp:137] Memory required for data: 1458083400
I1013 22:23:58.010007 13701 layer_factory.hpp:77] Creating layer penlu14
I1013 22:23:58.010025 13701 net.cpp:84] Creating Layer penlu14
I1013 22:23:58.010028 13701 net.cpp:406] penlu14 <- Eltwise7
I1013 22:23:58.010033 13701 net.cpp:367] penlu14 -> Eltwise7 (in-place)
I1013 22:23:58.010236 13701 net.cpp:122] Setting up penlu14
I1013 22:23:58.010241 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.010253 13701 net.cpp:137] Memory required for data: 1470627400
I1013 22:23:58.010282 13701 layer_factory.hpp:77] Creating layer Eltwise7_penlu14_0_split
I1013 22:23:58.010287 13701 net.cpp:84] Creating Layer Eltwise7_penlu14_0_split
I1013 22:23:58.010289 13701 net.cpp:406] Eltwise7_penlu14_0_split <- Eltwise7
I1013 22:23:58.010293 13701 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_0
I1013 22:23:58.010298 13701 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_1
I1013 22:23:58.010334 13701 net.cpp:122] Setting up Eltwise7_penlu14_0_split
I1013 22:23:58.010339 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.010351 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.010354 13701 net.cpp:137] Memory required for data: 1495715400
I1013 22:23:58.010356 13701 layer_factory.hpp:77] Creating layer Convolution18
I1013 22:23:58.010373 13701 net.cpp:84] Creating Layer Convolution18
I1013 22:23:58.010376 13701 net.cpp:406] Convolution18 <- Eltwise7_penlu14_0_split_0
I1013 22:23:58.010380 13701 net.cpp:380] Convolution18 -> Convolution18
I1013 22:23:58.032297 13701 net.cpp:122] Setting up Convolution18
I1013 22:23:58.032312 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.032315 13701 net.cpp:137] Memory required for data: 1508259400
I1013 22:23:58.032320 13701 layer_factory.hpp:77] Creating layer BatchNorm15
I1013 22:23:58.032326 13701 net.cpp:84] Creating Layer BatchNorm15
I1013 22:23:58.032330 13701 net.cpp:406] BatchNorm15 <- Convolution18
I1013 22:23:58.032335 13701 net.cpp:367] BatchNorm15 -> Convolution18 (in-place)
I1013 22:23:58.032536 13701 net.cpp:122] Setting up BatchNorm15
I1013 22:23:58.032541 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.032543 13701 net.cpp:137] Memory required for data: 1520803400
I1013 22:23:58.032548 13701 layer_factory.hpp:77] Creating layer Scale15
I1013 22:23:58.032553 13701 net.cpp:84] Creating Layer Scale15
I1013 22:23:58.032555 13701 net.cpp:406] Scale15 <- Convolution18
I1013 22:23:58.032570 13701 net.cpp:367] Scale15 -> Convolution18 (in-place)
I1013 22:23:58.032626 13701 layer_factory.hpp:77] Creating layer Scale15
I1013 22:23:58.032753 13701 net.cpp:122] Setting up Scale15
I1013 22:23:58.032758 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.032760 13701 net.cpp:137] Memory required for data: 1533347400
I1013 22:23:58.032764 13701 layer_factory.hpp:77] Creating layer penlu15
I1013 22:23:58.032769 13701 net.cpp:84] Creating Layer penlu15
I1013 22:23:58.032773 13701 net.cpp:406] penlu15 <- Convolution18
I1013 22:23:58.032776 13701 net.cpp:367] penlu15 -> Convolution18 (in-place)
I1013 22:23:58.032948 13701 net.cpp:122] Setting up penlu15
I1013 22:23:58.032954 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.032958 13701 net.cpp:137] Memory required for data: 1545891400
I1013 22:23:58.032961 13701 layer_factory.hpp:77] Creating layer Convolution19
I1013 22:23:58.032968 13701 net.cpp:84] Creating Layer Convolution19
I1013 22:23:58.032969 13701 net.cpp:406] Convolution19 <- Convolution18
I1013 22:23:58.032984 13701 net.cpp:380] Convolution19 -> Convolution19
I1013 22:23:58.055184 13701 net.cpp:122] Setting up Convolution19
I1013 22:23:58.055214 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.055217 13701 net.cpp:137] Memory required for data: 1558435400
I1013 22:23:58.055223 13701 layer_factory.hpp:77] Creating layer Eltwise8
I1013 22:23:58.055243 13701 net.cpp:84] Creating Layer Eltwise8
I1013 22:23:58.055258 13701 net.cpp:406] Eltwise8 <- Convolution19
I1013 22:23:58.055263 13701 net.cpp:406] Eltwise8 <- Eltwise7_penlu14_0_split_1
I1013 22:23:58.055268 13701 net.cpp:380] Eltwise8 -> Eltwise8
I1013 22:23:58.055325 13701 net.cpp:122] Setting up Eltwise8
I1013 22:23:58.055341 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.055343 13701 net.cpp:137] Memory required for data: 1570979400
I1013 22:23:58.055346 13701 layer_factory.hpp:77] Creating layer Eltwise8_Eltwise8_0_split
I1013 22:23:58.055357 13701 net.cpp:84] Creating Layer Eltwise8_Eltwise8_0_split
I1013 22:23:58.055361 13701 net.cpp:406] Eltwise8_Eltwise8_0_split <- Eltwise8
I1013 22:23:58.055364 13701 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I1013 22:23:58.055378 13701 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I1013 22:23:58.055415 13701 net.cpp:122] Setting up Eltwise8_Eltwise8_0_split
I1013 22:23:58.055429 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.055433 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.055444 13701 net.cpp:137] Memory required for data: 1596067400
I1013 22:23:58.055445 13701 layer_factory.hpp:77] Creating layer Convolution20
I1013 22:23:58.055464 13701 net.cpp:84] Creating Layer Convolution20
I1013 22:23:58.055465 13701 net.cpp:406] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I1013 22:23:58.055470 13701 net.cpp:380] Convolution20 -> Convolution20
I1013 22:23:58.097779 13701 net.cpp:122] Setting up Convolution20
I1013 22:23:58.097810 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.097813 13701 net.cpp:137] Memory required for data: 1602339400
I1013 22:23:58.097820 13701 layer_factory.hpp:77] Creating layer BatchNorm16
I1013 22:23:58.097839 13701 net.cpp:84] Creating Layer BatchNorm16
I1013 22:23:58.097843 13701 net.cpp:406] BatchNorm16 <- Convolution20
I1013 22:23:58.097849 13701 net.cpp:367] BatchNorm16 -> Convolution20 (in-place)
I1013 22:23:58.098043 13701 net.cpp:122] Setting up BatchNorm16
I1013 22:23:58.098049 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.098052 13701 net.cpp:137] Memory required for data: 1608611400
I1013 22:23:58.098067 13701 layer_factory.hpp:77] Creating layer Scale16
I1013 22:23:58.098073 13701 net.cpp:84] Creating Layer Scale16
I1013 22:23:58.098086 13701 net.cpp:406] Scale16 <- Convolution20
I1013 22:23:58.098089 13701 net.cpp:367] Scale16 -> Convolution20 (in-place)
I1013 22:23:58.098132 13701 layer_factory.hpp:77] Creating layer Scale16
I1013 22:23:58.098248 13701 net.cpp:122] Setting up Scale16
I1013 22:23:58.098253 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.098254 13701 net.cpp:137] Memory required for data: 1614883400
I1013 22:23:58.098258 13701 layer_factory.hpp:77] Creating layer penlu16
I1013 22:23:58.098263 13701 net.cpp:84] Creating Layer penlu16
I1013 22:23:58.098265 13701 net.cpp:406] penlu16 <- Convolution20
I1013 22:23:58.098270 13701 net.cpp:367] penlu16 -> Convolution20 (in-place)
I1013 22:23:58.098942 13701 net.cpp:122] Setting up penlu16
I1013 22:23:58.098951 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.098953 13701 net.cpp:137] Memory required for data: 1621155400
I1013 22:23:58.098958 13701 layer_factory.hpp:77] Creating layer Convolution21
I1013 22:23:58.098965 13701 net.cpp:84] Creating Layer Convolution21
I1013 22:23:58.098978 13701 net.cpp:406] Convolution21 <- Convolution20
I1013 22:23:58.098984 13701 net.cpp:380] Convolution21 -> Convolution21
I1013 22:23:58.182837 13701 net.cpp:122] Setting up Convolution21
I1013 22:23:58.182859 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.182863 13701 net.cpp:137] Memory required for data: 1627427400
I1013 22:23:58.182869 13701 layer_factory.hpp:77] Creating layer Convolution22
I1013 22:23:58.182893 13701 net.cpp:84] Creating Layer Convolution22
I1013 22:23:58.182896 13701 net.cpp:406] Convolution22 <- Eltwise8_Eltwise8_0_split_1
I1013 22:23:58.182914 13701 net.cpp:380] Convolution22 -> Convolution22
I1013 22:23:58.188246 13701 net.cpp:122] Setting up Convolution22
I1013 22:23:58.188256 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.188259 13701 net.cpp:137] Memory required for data: 1633699400
I1013 22:23:58.188262 13701 layer_factory.hpp:77] Creating layer Eltwise9
I1013 22:23:58.188268 13701 net.cpp:84] Creating Layer Eltwise9
I1013 22:23:58.188271 13701 net.cpp:406] Eltwise9 <- Convolution21
I1013 22:23:58.188274 13701 net.cpp:406] Eltwise9 <- Convolution22
I1013 22:23:58.188288 13701 net.cpp:380] Eltwise9 -> Eltwise9
I1013 22:23:58.188329 13701 net.cpp:122] Setting up Eltwise9
I1013 22:23:58.188334 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.188336 13701 net.cpp:137] Memory required for data: 1639971400
I1013 22:23:58.188349 13701 layer_factory.hpp:77] Creating layer BatchNorm17
I1013 22:23:58.188354 13701 net.cpp:84] Creating Layer BatchNorm17
I1013 22:23:58.188356 13701 net.cpp:406] BatchNorm17 <- Eltwise9
I1013 22:23:58.188370 13701 net.cpp:367] BatchNorm17 -> Eltwise9 (in-place)
I1013 22:23:58.188549 13701 net.cpp:122] Setting up BatchNorm17
I1013 22:23:58.188555 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.188556 13701 net.cpp:137] Memory required for data: 1646243400
I1013 22:23:58.188561 13701 layer_factory.hpp:77] Creating layer Scale17
I1013 22:23:58.188570 13701 net.cpp:84] Creating Layer Scale17
I1013 22:23:58.188572 13701 net.cpp:406] Scale17 <- Eltwise9
I1013 22:23:58.188575 13701 net.cpp:367] Scale17 -> Eltwise9 (in-place)
I1013 22:23:58.188624 13701 layer_factory.hpp:77] Creating layer Scale17
I1013 22:23:58.188729 13701 net.cpp:122] Setting up Scale17
I1013 22:23:58.188733 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.188735 13701 net.cpp:137] Memory required for data: 1652515400
I1013 22:23:58.188740 13701 layer_factory.hpp:77] Creating layer penlu17
I1013 22:23:58.188745 13701 net.cpp:84] Creating Layer penlu17
I1013 22:23:58.188747 13701 net.cpp:406] penlu17 <- Eltwise9
I1013 22:23:58.188751 13701 net.cpp:367] penlu17 -> Eltwise9 (in-place)
I1013 22:23:58.188896 13701 net.cpp:122] Setting up penlu17
I1013 22:23:58.188902 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.188905 13701 net.cpp:137] Memory required for data: 1658787400
I1013 22:23:58.188908 13701 layer_factory.hpp:77] Creating layer Eltwise9_penlu17_0_split
I1013 22:23:58.188912 13701 net.cpp:84] Creating Layer Eltwise9_penlu17_0_split
I1013 22:23:58.188915 13701 net.cpp:406] Eltwise9_penlu17_0_split <- Eltwise9
I1013 22:23:58.188918 13701 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_0
I1013 22:23:58.188923 13701 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_1
I1013 22:23:58.188961 13701 net.cpp:122] Setting up Eltwise9_penlu17_0_split
I1013 22:23:58.188966 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.188968 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.188979 13701 net.cpp:137] Memory required for data: 1671331400
I1013 22:23:58.188982 13701 layer_factory.hpp:77] Creating layer Convolution23
I1013 22:23:58.188987 13701 net.cpp:84] Creating Layer Convolution23
I1013 22:23:58.188999 13701 net.cpp:406] Convolution23 <- Eltwise9_penlu17_0_split_0
I1013 22:23:58.189003 13701 net.cpp:380] Convolution23 -> Convolution23
I1013 22:23:58.272460 13701 net.cpp:122] Setting up Convolution23
I1013 22:23:58.272493 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.272496 13701 net.cpp:137] Memory required for data: 1677603400
I1013 22:23:58.272502 13701 layer_factory.hpp:77] Creating layer BatchNorm18
I1013 22:23:58.272512 13701 net.cpp:84] Creating Layer BatchNorm18
I1013 22:23:58.272527 13701 net.cpp:406] BatchNorm18 <- Convolution23
I1013 22:23:58.272532 13701 net.cpp:367] BatchNorm18 -> Convolution23 (in-place)
I1013 22:23:58.272711 13701 net.cpp:122] Setting up BatchNorm18
I1013 22:23:58.272717 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.272729 13701 net.cpp:137] Memory required for data: 1683875400
I1013 22:23:58.272761 13701 layer_factory.hpp:77] Creating layer Scale18
I1013 22:23:58.272778 13701 net.cpp:84] Creating Layer Scale18
I1013 22:23:58.272781 13701 net.cpp:406] Scale18 <- Convolution23
I1013 22:23:58.272797 13701 net.cpp:367] Scale18 -> Convolution23 (in-place)
I1013 22:23:58.272860 13701 layer_factory.hpp:77] Creating layer Scale18
I1013 22:23:58.272975 13701 net.cpp:122] Setting up Scale18
I1013 22:23:58.272980 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.272982 13701 net.cpp:137] Memory required for data: 1690147400
I1013 22:23:58.272985 13701 layer_factory.hpp:77] Creating layer penlu18
I1013 22:23:58.272992 13701 net.cpp:84] Creating Layer penlu18
I1013 22:23:58.273010 13701 net.cpp:406] penlu18 <- Convolution23
I1013 22:23:58.273015 13701 net.cpp:367] penlu18 -> Convolution23 (in-place)
I1013 22:23:58.273206 13701 net.cpp:122] Setting up penlu18
I1013 22:23:58.273211 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.273213 13701 net.cpp:137] Memory required for data: 1696419400
I1013 22:23:58.273217 13701 layer_factory.hpp:77] Creating layer Convolution24
I1013 22:23:58.273224 13701 net.cpp:84] Creating Layer Convolution24
I1013 22:23:58.273242 13701 net.cpp:406] Convolution24 <- Convolution23
I1013 22:23:58.273247 13701 net.cpp:380] Convolution24 -> Convolution24
I1013 22:23:58.357262 13701 net.cpp:122] Setting up Convolution24
I1013 22:23:58.357295 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.357300 13701 net.cpp:137] Memory required for data: 1702691400
I1013 22:23:58.357306 13701 layer_factory.hpp:77] Creating layer Eltwise10
I1013 22:23:58.357326 13701 net.cpp:84] Creating Layer Eltwise10
I1013 22:23:58.357331 13701 net.cpp:406] Eltwise10 <- Convolution24
I1013 22:23:58.357336 13701 net.cpp:406] Eltwise10 <- Eltwise9_penlu17_0_split_1
I1013 22:23:58.357343 13701 net.cpp:380] Eltwise10 -> Eltwise10
I1013 22:23:58.357400 13701 net.cpp:122] Setting up Eltwise10
I1013 22:23:58.357405 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.357408 13701 net.cpp:137] Memory required for data: 1708963400
I1013 22:23:58.357410 13701 layer_factory.hpp:77] Creating layer BatchNorm19
I1013 22:23:58.357415 13701 net.cpp:84] Creating Layer BatchNorm19
I1013 22:23:58.357419 13701 net.cpp:406] BatchNorm19 <- Eltwise10
I1013 22:23:58.357424 13701 net.cpp:367] BatchNorm19 -> Eltwise10 (in-place)
I1013 22:23:58.357627 13701 net.cpp:122] Setting up BatchNorm19
I1013 22:23:58.357632 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.357635 13701 net.cpp:137] Memory required for data: 1715235400
I1013 22:23:58.357640 13701 layer_factory.hpp:77] Creating layer Scale19
I1013 22:23:58.357645 13701 net.cpp:84] Creating Layer Scale19
I1013 22:23:58.357647 13701 net.cpp:406] Scale19 <- Eltwise10
I1013 22:23:58.357651 13701 net.cpp:367] Scale19 -> Eltwise10 (in-place)
I1013 22:23:58.357722 13701 layer_factory.hpp:77] Creating layer Scale19
I1013 22:23:58.357854 13701 net.cpp:122] Setting up Scale19
I1013 22:23:58.357859 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.357861 13701 net.cpp:137] Memory required for data: 1721507400
I1013 22:23:58.357864 13701 layer_factory.hpp:77] Creating layer penlu19
I1013 22:23:58.357870 13701 net.cpp:84] Creating Layer penlu19
I1013 22:23:58.357872 13701 net.cpp:406] penlu19 <- Eltwise10
I1013 22:23:58.357877 13701 net.cpp:367] penlu19 -> Eltwise10 (in-place)
I1013 22:23:58.358052 13701 net.cpp:122] Setting up penlu19
I1013 22:23:58.358058 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.358060 13701 net.cpp:137] Memory required for data: 1727779400
I1013 22:23:58.358065 13701 layer_factory.hpp:77] Creating layer Eltwise10_penlu19_0_split
I1013 22:23:58.358069 13701 net.cpp:84] Creating Layer Eltwise10_penlu19_0_split
I1013 22:23:58.358072 13701 net.cpp:406] Eltwise10_penlu19_0_split <- Eltwise10
I1013 22:23:58.358077 13701 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_0
I1013 22:23:58.358080 13701 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_1
I1013 22:23:58.358158 13701 net.cpp:122] Setting up Eltwise10_penlu19_0_split
I1013 22:23:58.358173 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.358177 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.358180 13701 net.cpp:137] Memory required for data: 1740323400
I1013 22:23:58.358182 13701 layer_factory.hpp:77] Creating layer Convolution25
I1013 22:23:58.358189 13701 net.cpp:84] Creating Layer Convolution25
I1013 22:23:58.358193 13701 net.cpp:406] Convolution25 <- Eltwise10_penlu19_0_split_0
I1013 22:23:58.358197 13701 net.cpp:380] Convolution25 -> Convolution25
I1013 22:23:58.442014 13701 net.cpp:122] Setting up Convolution25
I1013 22:23:58.442036 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.442040 13701 net.cpp:137] Memory required for data: 1746595400
I1013 22:23:58.442049 13701 layer_factory.hpp:77] Creating layer BatchNorm20
I1013 22:23:58.442059 13701 net.cpp:84] Creating Layer BatchNorm20
I1013 22:23:58.442075 13701 net.cpp:406] BatchNorm20 <- Convolution25
I1013 22:23:58.442080 13701 net.cpp:367] BatchNorm20 -> Convolution25 (in-place)
I1013 22:23:58.442286 13701 net.cpp:122] Setting up BatchNorm20
I1013 22:23:58.442291 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.442293 13701 net.cpp:137] Memory required for data: 1752867400
I1013 22:23:58.442298 13701 layer_factory.hpp:77] Creating layer Scale20
I1013 22:23:58.442304 13701 net.cpp:84] Creating Layer Scale20
I1013 22:23:58.442307 13701 net.cpp:406] Scale20 <- Convolution25
I1013 22:23:58.442322 13701 net.cpp:367] Scale20 -> Convolution25 (in-place)
I1013 22:23:58.442384 13701 layer_factory.hpp:77] Creating layer Scale20
I1013 22:23:58.442513 13701 net.cpp:122] Setting up Scale20
I1013 22:23:58.442519 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.442522 13701 net.cpp:137] Memory required for data: 1759139400
I1013 22:23:58.442525 13701 layer_factory.hpp:77] Creating layer penlu20
I1013 22:23:58.442530 13701 net.cpp:84] Creating Layer penlu20
I1013 22:23:58.442533 13701 net.cpp:406] penlu20 <- Convolution25
I1013 22:23:58.442538 13701 net.cpp:367] penlu20 -> Convolution25 (in-place)
I1013 22:23:58.442689 13701 net.cpp:122] Setting up penlu20
I1013 22:23:58.442694 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.442697 13701 net.cpp:137] Memory required for data: 1765411400
I1013 22:23:58.442701 13701 layer_factory.hpp:77] Creating layer Convolution26
I1013 22:23:58.442708 13701 net.cpp:84] Creating Layer Convolution26
I1013 22:23:58.442711 13701 net.cpp:406] Convolution26 <- Convolution25
I1013 22:23:58.442725 13701 net.cpp:380] Convolution26 -> Convolution26
I1013 22:23:58.526376 13701 net.cpp:122] Setting up Convolution26
I1013 22:23:58.526397 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.526401 13701 net.cpp:137] Memory required for data: 1771683400
I1013 22:23:58.526408 13701 layer_factory.hpp:77] Creating layer Eltwise11
I1013 22:23:58.526427 13701 net.cpp:84] Creating Layer Eltwise11
I1013 22:23:58.526432 13701 net.cpp:406] Eltwise11 <- Convolution26
I1013 22:23:58.526439 13701 net.cpp:406] Eltwise11 <- Eltwise10_penlu19_0_split_1
I1013 22:23:58.526444 13701 net.cpp:380] Eltwise11 -> Eltwise11
I1013 22:23:58.526487 13701 net.cpp:122] Setting up Eltwise11
I1013 22:23:58.526492 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.526494 13701 net.cpp:137] Memory required for data: 1777955400
I1013 22:23:58.526496 13701 layer_factory.hpp:77] Creating layer BatchNorm21
I1013 22:23:58.526502 13701 net.cpp:84] Creating Layer BatchNorm21
I1013 22:23:58.526504 13701 net.cpp:406] BatchNorm21 <- Eltwise11
I1013 22:23:58.526520 13701 net.cpp:367] BatchNorm21 -> Eltwise11 (in-place)
I1013 22:23:58.526696 13701 net.cpp:122] Setting up BatchNorm21
I1013 22:23:58.526702 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.526705 13701 net.cpp:137] Memory required for data: 1784227400
I1013 22:23:58.526710 13701 layer_factory.hpp:77] Creating layer Scale21
I1013 22:23:58.526715 13701 net.cpp:84] Creating Layer Scale21
I1013 22:23:58.526739 13701 net.cpp:406] Scale21 <- Eltwise11
I1013 22:23:58.526743 13701 net.cpp:367] Scale21 -> Eltwise11 (in-place)
I1013 22:23:58.526789 13701 layer_factory.hpp:77] Creating layer Scale21
I1013 22:23:58.526897 13701 net.cpp:122] Setting up Scale21
I1013 22:23:58.526902 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.526914 13701 net.cpp:137] Memory required for data: 1790499400
I1013 22:23:58.526918 13701 layer_factory.hpp:77] Creating layer penlu21
I1013 22:23:58.526924 13701 net.cpp:84] Creating Layer penlu21
I1013 22:23:58.526927 13701 net.cpp:406] penlu21 <- Eltwise11
I1013 22:23:58.526932 13701 net.cpp:367] penlu21 -> Eltwise11 (in-place)
I1013 22:23:58.527067 13701 net.cpp:122] Setting up penlu21
I1013 22:23:58.527073 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.527076 13701 net.cpp:137] Memory required for data: 1796771400
I1013 22:23:58.527081 13701 layer_factory.hpp:77] Creating layer Eltwise11_penlu21_0_split
I1013 22:23:58.527086 13701 net.cpp:84] Creating Layer Eltwise11_penlu21_0_split
I1013 22:23:58.527088 13701 net.cpp:406] Eltwise11_penlu21_0_split <- Eltwise11
I1013 22:23:58.527091 13701 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_0
I1013 22:23:58.527107 13701 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_1
I1013 22:23:58.527145 13701 net.cpp:122] Setting up Eltwise11_penlu21_0_split
I1013 22:23:58.527150 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.527153 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.527166 13701 net.cpp:137] Memory required for data: 1809315400
I1013 22:23:58.527169 13701 layer_factory.hpp:77] Creating layer Convolution27
I1013 22:23:58.527176 13701 net.cpp:84] Creating Layer Convolution27
I1013 22:23:58.527179 13701 net.cpp:406] Convolution27 <- Eltwise11_penlu21_0_split_0
I1013 22:23:58.527184 13701 net.cpp:380] Convolution27 -> Convolution27
I1013 22:23:58.610561 13701 net.cpp:122] Setting up Convolution27
I1013 22:23:58.610589 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.610592 13701 net.cpp:137] Memory required for data: 1815587400
I1013 22:23:58.610599 13701 layer_factory.hpp:77] Creating layer BatchNorm22
I1013 22:23:58.610620 13701 net.cpp:84] Creating Layer BatchNorm22
I1013 22:23:58.610626 13701 net.cpp:406] BatchNorm22 <- Convolution27
I1013 22:23:58.610646 13701 net.cpp:367] BatchNorm22 -> Convolution27 (in-place)
I1013 22:23:58.610869 13701 net.cpp:122] Setting up BatchNorm22
I1013 22:23:58.610877 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.610879 13701 net.cpp:137] Memory required for data: 1821859400
I1013 22:23:58.610884 13701 layer_factory.hpp:77] Creating layer Scale22
I1013 22:23:58.610891 13701 net.cpp:84] Creating Layer Scale22
I1013 22:23:58.610894 13701 net.cpp:406] Scale22 <- Convolution27
I1013 22:23:58.610908 13701 net.cpp:367] Scale22 -> Convolution27 (in-place)
I1013 22:23:58.610973 13701 layer_factory.hpp:77] Creating layer Scale22
I1013 22:23:58.611104 13701 net.cpp:122] Setting up Scale22
I1013 22:23:58.611109 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.611111 13701 net.cpp:137] Memory required for data: 1828131400
I1013 22:23:58.611126 13701 layer_factory.hpp:77] Creating layer penlu22
I1013 22:23:58.611133 13701 net.cpp:84] Creating Layer penlu22
I1013 22:23:58.611136 13701 net.cpp:406] penlu22 <- Convolution27
I1013 22:23:58.611141 13701 net.cpp:367] penlu22 -> Convolution27 (in-place)
I1013 22:23:58.611310 13701 net.cpp:122] Setting up penlu22
I1013 22:23:58.611315 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.611317 13701 net.cpp:137] Memory required for data: 1834403400
I1013 22:23:58.611322 13701 layer_factory.hpp:77] Creating layer Convolution28
I1013 22:23:58.611330 13701 net.cpp:84] Creating Layer Convolution28
I1013 22:23:58.611332 13701 net.cpp:406] Convolution28 <- Convolution27
I1013 22:23:58.611346 13701 net.cpp:380] Convolution28 -> Convolution28
I1013 22:23:58.694823 13701 net.cpp:122] Setting up Convolution28
I1013 22:23:58.694861 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.694865 13701 net.cpp:137] Memory required for data: 1840675400
I1013 22:23:58.694872 13701 layer_factory.hpp:77] Creating layer Eltwise12
I1013 22:23:58.694891 13701 net.cpp:84] Creating Layer Eltwise12
I1013 22:23:58.694896 13701 net.cpp:406] Eltwise12 <- Convolution28
I1013 22:23:58.694901 13701 net.cpp:406] Eltwise12 <- Eltwise11_penlu21_0_split_1
I1013 22:23:58.694917 13701 net.cpp:380] Eltwise12 -> Eltwise12
I1013 22:23:58.694952 13701 net.cpp:122] Setting up Eltwise12
I1013 22:23:58.694967 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:58.694969 13701 net.cpp:137] Memory required for data: 1846947400
I1013 22:23:58.694984 13701 layer_factory.hpp:77] Creating layer Pooling1
I1013 22:23:58.694990 13701 net.cpp:84] Creating Layer Pooling1
I1013 22:23:58.694993 13701 net.cpp:406] Pooling1 <- Eltwise12
I1013 22:23:58.694998 13701 net.cpp:380] Pooling1 -> Pooling1
I1013 22:23:58.695585 13701 net.cpp:122] Setting up Pooling1
I1013 22:23:58.695596 13701 net.cpp:129] Top shape: 50 640 1 1 (32000)
I1013 22:23:58.695598 13701 net.cpp:137] Memory required for data: 1847075400
I1013 22:23:58.695601 13701 layer_factory.hpp:77] Creating layer InnerProduct1
I1013 22:23:58.695612 13701 net.cpp:84] Creating Layer InnerProduct1
I1013 22:23:58.695626 13701 net.cpp:406] InnerProduct1 <- Pooling1
I1013 22:23:58.695628 13701 net.cpp:380] InnerProduct1 -> InnerProduct1
I1013 22:23:58.695806 13701 net.cpp:122] Setting up InnerProduct1
I1013 22:23:58.695812 13701 net.cpp:129] Top shape: 50 100 (5000)
I1013 22:23:58.695814 13701 net.cpp:137] Memory required for data: 1847095400
I1013 22:23:58.695818 13701 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1013 22:23:58.695823 13701 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1013 22:23:58.695825 13701 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1013 22:23:58.695828 13701 net.cpp:406] SoftmaxWithLoss1 <- label
I1013 22:23:58.695842 13701 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1013 22:23:58.695849 13701 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1013 22:23:58.696096 13701 net.cpp:122] Setting up SoftmaxWithLoss1
I1013 22:23:58.696105 13701 net.cpp:129] Top shape: (1)
I1013 22:23:58.696106 13701 net.cpp:132]     with loss weight 1
I1013 22:23:58.696120 13701 net.cpp:137] Memory required for data: 1847095404
I1013 22:23:58.696122 13701 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1013 22:23:58.696135 13701 net.cpp:198] InnerProduct1 needs backward computation.
I1013 22:23:58.696138 13701 net.cpp:198] Pooling1 needs backward computation.
I1013 22:23:58.696141 13701 net.cpp:198] Eltwise12 needs backward computation.
I1013 22:23:58.696142 13701 net.cpp:198] Convolution28 needs backward computation.
I1013 22:23:58.696156 13701 net.cpp:198] penlu22 needs backward computation.
I1013 22:23:58.696163 13701 net.cpp:198] Scale22 needs backward computation.
I1013 22:23:58.696166 13701 net.cpp:198] BatchNorm22 needs backward computation.
I1013 22:23:58.696168 13701 net.cpp:198] Convolution27 needs backward computation.
I1013 22:23:58.696180 13701 net.cpp:198] Eltwise11_penlu21_0_split needs backward computation.
I1013 22:23:58.696183 13701 net.cpp:198] penlu21 needs backward computation.
I1013 22:23:58.696187 13701 net.cpp:198] Scale21 needs backward computation.
I1013 22:23:58.696198 13701 net.cpp:198] BatchNorm21 needs backward computation.
I1013 22:23:58.696202 13701 net.cpp:198] Eltwise11 needs backward computation.
I1013 22:23:58.696204 13701 net.cpp:198] Convolution26 needs backward computation.
I1013 22:23:58.696215 13701 net.cpp:198] penlu20 needs backward computation.
I1013 22:23:58.696218 13701 net.cpp:198] Scale20 needs backward computation.
I1013 22:23:58.696220 13701 net.cpp:198] BatchNorm20 needs backward computation.
I1013 22:23:58.696223 13701 net.cpp:198] Convolution25 needs backward computation.
I1013 22:23:58.696238 13701 net.cpp:198] Eltwise10_penlu19_0_split needs backward computation.
I1013 22:23:58.696240 13701 net.cpp:198] penlu19 needs backward computation.
I1013 22:23:58.696250 13701 net.cpp:198] Scale19 needs backward computation.
I1013 22:23:58.696254 13701 net.cpp:198] BatchNorm19 needs backward computation.
I1013 22:23:58.696256 13701 net.cpp:198] Eltwise10 needs backward computation.
I1013 22:23:58.696259 13701 net.cpp:198] Convolution24 needs backward computation.
I1013 22:23:58.696262 13701 net.cpp:198] penlu18 needs backward computation.
I1013 22:23:58.696265 13701 net.cpp:198] Scale18 needs backward computation.
I1013 22:23:58.696267 13701 net.cpp:198] BatchNorm18 needs backward computation.
I1013 22:23:58.696269 13701 net.cpp:198] Convolution23 needs backward computation.
I1013 22:23:58.696272 13701 net.cpp:198] Eltwise9_penlu17_0_split needs backward computation.
I1013 22:23:58.696285 13701 net.cpp:198] penlu17 needs backward computation.
I1013 22:23:58.696287 13701 net.cpp:198] Scale17 needs backward computation.
I1013 22:23:58.696290 13701 net.cpp:198] BatchNorm17 needs backward computation.
I1013 22:23:58.696291 13701 net.cpp:198] Eltwise9 needs backward computation.
I1013 22:23:58.696295 13701 net.cpp:198] Convolution22 needs backward computation.
I1013 22:23:58.696297 13701 net.cpp:198] Convolution21 needs backward computation.
I1013 22:23:58.696300 13701 net.cpp:198] penlu16 needs backward computation.
I1013 22:23:58.696302 13701 net.cpp:198] Scale16 needs backward computation.
I1013 22:23:58.696305 13701 net.cpp:198] BatchNorm16 needs backward computation.
I1013 22:23:58.696307 13701 net.cpp:198] Convolution20 needs backward computation.
I1013 22:23:58.696310 13701 net.cpp:198] Eltwise8_Eltwise8_0_split needs backward computation.
I1013 22:23:58.696312 13701 net.cpp:198] Eltwise8 needs backward computation.
I1013 22:23:58.696316 13701 net.cpp:198] Convolution19 needs backward computation.
I1013 22:23:58.696318 13701 net.cpp:198] penlu15 needs backward computation.
I1013 22:23:58.696321 13701 net.cpp:198] Scale15 needs backward computation.
I1013 22:23:58.696323 13701 net.cpp:198] BatchNorm15 needs backward computation.
I1013 22:23:58.696326 13701 net.cpp:198] Convolution18 needs backward computation.
I1013 22:23:58.696328 13701 net.cpp:198] Eltwise7_penlu14_0_split needs backward computation.
I1013 22:23:58.696331 13701 net.cpp:198] penlu14 needs backward computation.
I1013 22:23:58.696333 13701 net.cpp:198] Scale14 needs backward computation.
I1013 22:23:58.696336 13701 net.cpp:198] BatchNorm14 needs backward computation.
I1013 22:23:58.696338 13701 net.cpp:198] Eltwise7 needs backward computation.
I1013 22:23:58.696341 13701 net.cpp:198] Convolution17 needs backward computation.
I1013 22:23:58.696344 13701 net.cpp:198] penlu13 needs backward computation.
I1013 22:23:58.696346 13701 net.cpp:198] Scale13 needs backward computation.
I1013 22:23:58.696348 13701 net.cpp:198] BatchNorm13 needs backward computation.
I1013 22:23:58.696352 13701 net.cpp:198] Convolution16 needs backward computation.
I1013 22:23:58.696353 13701 net.cpp:198] Eltwise6_penlu12_0_split needs backward computation.
I1013 22:23:58.696357 13701 net.cpp:198] penlu12 needs backward computation.
I1013 22:23:58.696359 13701 net.cpp:198] Scale12 needs backward computation.
I1013 22:23:58.696362 13701 net.cpp:198] BatchNorm12 needs backward computation.
I1013 22:23:58.696363 13701 net.cpp:198] Eltwise6 needs backward computation.
I1013 22:23:58.696367 13701 net.cpp:198] Convolution15 needs backward computation.
I1013 22:23:58.696368 13701 net.cpp:198] penlu11 needs backward computation.
I1013 22:23:58.696372 13701 net.cpp:198] Scale11 needs backward computation.
I1013 22:23:58.696373 13701 net.cpp:198] BatchNorm11 needs backward computation.
I1013 22:23:58.696377 13701 net.cpp:198] Convolution14 needs backward computation.
I1013 22:23:58.696378 13701 net.cpp:198] Eltwise5_penlu10_0_split needs backward computation.
I1013 22:23:58.696382 13701 net.cpp:198] penlu10 needs backward computation.
I1013 22:23:58.696383 13701 net.cpp:198] Scale10 needs backward computation.
I1013 22:23:58.696385 13701 net.cpp:198] BatchNorm10 needs backward computation.
I1013 22:23:58.696391 13701 net.cpp:198] Eltwise5 needs backward computation.
I1013 22:23:58.696394 13701 net.cpp:198] Convolution13 needs backward computation.
I1013 22:23:58.696398 13701 net.cpp:198] Convolution12 needs backward computation.
I1013 22:23:58.696399 13701 net.cpp:198] penlu9 needs backward computation.
I1013 22:23:58.696403 13701 net.cpp:198] Scale9 needs backward computation.
I1013 22:23:58.696405 13701 net.cpp:198] BatchNorm9 needs backward computation.
I1013 22:23:58.696408 13701 net.cpp:198] Convolution11 needs backward computation.
I1013 22:23:58.696409 13701 net.cpp:198] Eltwise4_Eltwise4_0_split needs backward computation.
I1013 22:23:58.696413 13701 net.cpp:198] Eltwise4 needs backward computation.
I1013 22:23:58.696416 13701 net.cpp:198] Convolution10 needs backward computation.
I1013 22:23:58.696419 13701 net.cpp:198] penlu8 needs backward computation.
I1013 22:23:58.696422 13701 net.cpp:198] Scale8 needs backward computation.
I1013 22:23:58.696424 13701 net.cpp:198] BatchNorm8 needs backward computation.
I1013 22:23:58.696427 13701 net.cpp:198] Convolution9 needs backward computation.
I1013 22:23:58.696430 13701 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1013 22:23:58.696432 13701 net.cpp:198] penlu7 needs backward computation.
I1013 22:23:58.696435 13701 net.cpp:198] Scale7 needs backward computation.
I1013 22:23:58.696439 13701 net.cpp:198] BatchNorm7 needs backward computation.
I1013 22:23:58.696440 13701 net.cpp:198] Eltwise3 needs backward computation.
I1013 22:23:58.696444 13701 net.cpp:198] Convolution8 needs backward computation.
I1013 22:23:58.696446 13701 net.cpp:198] penlu6 needs backward computation.
I1013 22:23:58.696449 13701 net.cpp:198] Scale6 needs backward computation.
I1013 22:23:58.696450 13701 net.cpp:198] BatchNorm6 needs backward computation.
I1013 22:23:58.696454 13701 net.cpp:198] Convolution7 needs backward computation.
I1013 22:23:58.696457 13701 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1013 22:23:58.696460 13701 net.cpp:198] penlu5 needs backward computation.
I1013 22:23:58.696462 13701 net.cpp:198] Scale5 needs backward computation.
I1013 22:23:58.696465 13701 net.cpp:198] BatchNorm5 needs backward computation.
I1013 22:23:58.696467 13701 net.cpp:198] Eltwise2 needs backward computation.
I1013 22:23:58.696470 13701 net.cpp:198] Convolution6 needs backward computation.
I1013 22:23:58.696472 13701 net.cpp:198] penlu4 needs backward computation.
I1013 22:23:58.696475 13701 net.cpp:198] Scale4 needs backward computation.
I1013 22:23:58.696477 13701 net.cpp:198] BatchNorm4 needs backward computation.
I1013 22:23:58.696480 13701 net.cpp:198] Convolution5 needs backward computation.
I1013 22:23:58.696482 13701 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1013 22:23:58.696485 13701 net.cpp:198] penlu3 needs backward computation.
I1013 22:23:58.696487 13701 net.cpp:198] Scale3 needs backward computation.
I1013 22:23:58.696491 13701 net.cpp:198] BatchNorm3 needs backward computation.
I1013 22:23:58.696492 13701 net.cpp:198] Eltwise1 needs backward computation.
I1013 22:23:58.696494 13701 net.cpp:198] Convolution4 needs backward computation.
I1013 22:23:58.696498 13701 net.cpp:198] Convolution3 needs backward computation.
I1013 22:23:58.696501 13701 net.cpp:198] penlu2 needs backward computation.
I1013 22:23:58.696503 13701 net.cpp:198] Scale2 needs backward computation.
I1013 22:23:58.696506 13701 net.cpp:198] BatchNorm2 needs backward computation.
I1013 22:23:58.696508 13701 net.cpp:198] Convolution2 needs backward computation.
I1013 22:23:58.696511 13701 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1013 22:23:58.696513 13701 net.cpp:198] penlu1 needs backward computation.
I1013 22:23:58.696516 13701 net.cpp:198] Scale1 needs backward computation.
I1013 22:23:58.696518 13701 net.cpp:198] BatchNorm1 needs backward computation.
I1013 22:23:58.696521 13701 net.cpp:198] Convolution1 needs backward computation.
I1013 22:23:58.696523 13701 net.cpp:200] cifar does not need backward computation.
I1013 22:23:58.696529 13701 net.cpp:242] This network produces output SoftmaxWithLoss1
I1013 22:23:58.696574 13701 net.cpp:255] Network initialization done.
I1013 22:23:58.698526 13701 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1013 22:23:58.698536 13701 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1013 22:23:58.698541 13701 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1013 22:23:58.698629 13701 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1013 22:23:58.699106 13701 net.cpp:51] Initializing net from parameters: 
name: "wrn_28_10"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar100/cifar100_test_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution4"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution4"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Eltwise1"
  top: "Eltwise1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution5"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution5"
  top: "Convolution6"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution6"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Eltwise2"
  top: "Eltwise2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution7"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution7"
  top: "Convolution8"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Eltwise3"
  top: "Eltwise3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution13"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Eltwise5"
  top: "Eltwise5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Eltwise6"
  top: "Eltwise6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Eltwise7"
  top: "Eltwise7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution22"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution21"
  bottom: "Convolution22"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Eltwise9"
  top: "Eltwise9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution24"
  bottom: "Eltwise9"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Eltwise10"
  top: "Eltwise10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution25"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution26"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Eltwise11"
  top: "Eltwise11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution27"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution28"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise12"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 100
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I1013 22:23:58.699434 13701 layer_factory.hpp:77] Creating layer cifar
I1013 22:23:58.699482 13701 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar100/cifar100_test_lmdb
I1013 22:23:58.699493 13701 net.cpp:84] Creating Layer cifar
I1013 22:23:58.699506 13701 net.cpp:380] cifar -> data
I1013 22:23:58.699513 13701 net.cpp:380] cifar -> label
I1013 22:23:58.699518 13701 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto
I1013 22:23:58.699645 13701 data_layer.cpp:45] output data size: 50,3,28,28
I1013 22:23:58.700275 13701 net.cpp:122] Setting up cifar
I1013 22:23:58.700283 13701 net.cpp:129] Top shape: 50 3 28 28 (117600)
I1013 22:23:58.700286 13701 net.cpp:129] Top shape: 50 (50)
I1013 22:23:58.700289 13701 net.cpp:137] Memory required for data: 470600
I1013 22:23:58.700290 13701 layer_factory.hpp:77] Creating layer label_cifar_1_split
I1013 22:23:58.700296 13701 net.cpp:84] Creating Layer label_cifar_1_split
I1013 22:23:58.700299 13701 net.cpp:406] label_cifar_1_split <- label
I1013 22:23:58.700302 13701 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1013 22:23:58.700307 13701 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1013 22:23:58.700367 13701 net.cpp:122] Setting up label_cifar_1_split
I1013 22:23:58.700372 13701 net.cpp:129] Top shape: 50 (50)
I1013 22:23:58.700376 13701 net.cpp:129] Top shape: 50 (50)
I1013 22:23:58.700377 13701 net.cpp:137] Memory required for data: 471000
I1013 22:23:58.700379 13701 layer_factory.hpp:77] Creating layer Convolution1
I1013 22:23:58.700387 13701 net.cpp:84] Creating Layer Convolution1
I1013 22:23:58.700388 13701 net.cpp:406] Convolution1 <- data
I1013 22:23:58.700392 13701 net.cpp:380] Convolution1 -> Convolution1
I1013 22:23:58.701519 13701 net.cpp:122] Setting up Convolution1
I1013 22:23:58.701527 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:58.701530 13701 net.cpp:137] Memory required for data: 2979800
I1013 22:23:58.701537 13701 layer_factory.hpp:77] Creating layer BatchNorm1
I1013 22:23:58.701544 13701 net.cpp:84] Creating Layer BatchNorm1
I1013 22:23:58.701546 13701 net.cpp:406] BatchNorm1 <- Convolution1
I1013 22:23:58.701550 13701 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1013 22:23:58.701712 13701 net.cpp:122] Setting up BatchNorm1
I1013 22:23:58.701717 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:58.701720 13701 net.cpp:137] Memory required for data: 5488600
I1013 22:23:58.701727 13701 layer_factory.hpp:77] Creating layer Scale1
I1013 22:23:58.701732 13701 net.cpp:84] Creating Layer Scale1
I1013 22:23:58.701735 13701 net.cpp:406] Scale1 <- Convolution1
I1013 22:23:58.701738 13701 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1013 22:23:58.701776 13701 layer_factory.hpp:77] Creating layer Scale1
I1013 22:23:58.701956 13701 net.cpp:122] Setting up Scale1
I1013 22:23:58.701969 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:58.701972 13701 net.cpp:137] Memory required for data: 7997400
I1013 22:23:58.701977 13701 layer_factory.hpp:77] Creating layer penlu1
I1013 22:23:58.701985 13701 net.cpp:84] Creating Layer penlu1
I1013 22:23:58.701995 13701 net.cpp:406] penlu1 <- Convolution1
I1013 22:23:58.702000 13701 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1013 22:23:58.702136 13701 net.cpp:122] Setting up penlu1
I1013 22:23:58.702141 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:58.702142 13701 net.cpp:137] Memory required for data: 10506200
I1013 22:23:58.702149 13701 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1013 22:23:58.702153 13701 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1013 22:23:58.702155 13701 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1013 22:23:58.702158 13701 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1013 22:23:58.702163 13701 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1013 22:23:58.702189 13701 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1013 22:23:58.702195 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:58.702198 13701 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1013 22:23:58.702200 13701 net.cpp:137] Memory required for data: 15523800
I1013 22:23:58.702203 13701 layer_factory.hpp:77] Creating layer Convolution2
I1013 22:23:58.702214 13701 net.cpp:84] Creating Layer Convolution2
I1013 22:23:58.702217 13701 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1013 22:23:58.702221 13701 net.cpp:380] Convolution2 -> Convolution2
I1013 22:23:58.703879 13701 net.cpp:122] Setting up Convolution2
I1013 22:23:58.703888 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.703891 13701 net.cpp:137] Memory required for data: 40611800
I1013 22:23:58.703894 13701 layer_factory.hpp:77] Creating layer BatchNorm2
I1013 22:23:58.703900 13701 net.cpp:84] Creating Layer BatchNorm2
I1013 22:23:58.703903 13701 net.cpp:406] BatchNorm2 <- Convolution2
I1013 22:23:58.703907 13701 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1013 22:23:58.704066 13701 net.cpp:122] Setting up BatchNorm2
I1013 22:23:58.704069 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.704072 13701 net.cpp:137] Memory required for data: 65699800
I1013 22:23:58.704077 13701 layer_factory.hpp:77] Creating layer Scale2
I1013 22:23:58.704082 13701 net.cpp:84] Creating Layer Scale2
I1013 22:23:58.704085 13701 net.cpp:406] Scale2 <- Convolution2
I1013 22:23:58.704088 13701 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1013 22:23:58.704118 13701 layer_factory.hpp:77] Creating layer Scale2
I1013 22:23:58.704210 13701 net.cpp:122] Setting up Scale2
I1013 22:23:58.704215 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.704216 13701 net.cpp:137] Memory required for data: 90787800
I1013 22:23:58.704221 13701 layer_factory.hpp:77] Creating layer penlu2
I1013 22:23:58.704226 13701 net.cpp:84] Creating Layer penlu2
I1013 22:23:58.704228 13701 net.cpp:406] penlu2 <- Convolution2
I1013 22:23:58.704231 13701 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1013 22:23:58.704434 13701 net.cpp:122] Setting up penlu2
I1013 22:23:58.704439 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.704442 13701 net.cpp:137] Memory required for data: 115875800
I1013 22:23:58.704449 13701 layer_factory.hpp:77] Creating layer Convolution3
I1013 22:23:58.704454 13701 net.cpp:84] Creating Layer Convolution3
I1013 22:23:58.704457 13701 net.cpp:406] Convolution3 <- Convolution2
I1013 22:23:58.704460 13701 net.cpp:380] Convolution3 -> Convolution3
I1013 22:23:58.712896 13701 net.cpp:122] Setting up Convolution3
I1013 22:23:58.712908 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.712911 13701 net.cpp:137] Memory required for data: 140963800
I1013 22:23:58.712915 13701 layer_factory.hpp:77] Creating layer Convolution4
I1013 22:23:58.712924 13701 net.cpp:84] Creating Layer Convolution4
I1013 22:23:58.712926 13701 net.cpp:406] Convolution4 <- Convolution1_penlu1_0_split_1
I1013 22:23:58.712931 13701 net.cpp:380] Convolution4 -> Convolution4
I1013 22:23:58.713927 13701 net.cpp:122] Setting up Convolution4
I1013 22:23:58.713937 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.713946 13701 net.cpp:137] Memory required for data: 166051800
I1013 22:23:58.713950 13701 layer_factory.hpp:77] Creating layer Eltwise1
I1013 22:23:58.713956 13701 net.cpp:84] Creating Layer Eltwise1
I1013 22:23:58.713959 13701 net.cpp:406] Eltwise1 <- Convolution3
I1013 22:23:58.713963 13701 net.cpp:406] Eltwise1 <- Convolution4
I1013 22:23:58.713966 13701 net.cpp:380] Eltwise1 -> Eltwise1
I1013 22:23:58.713989 13701 net.cpp:122] Setting up Eltwise1
I1013 22:23:58.713992 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.713994 13701 net.cpp:137] Memory required for data: 191139800
I1013 22:23:58.713997 13701 layer_factory.hpp:77] Creating layer BatchNorm3
I1013 22:23:58.714002 13701 net.cpp:84] Creating Layer BatchNorm3
I1013 22:23:58.714004 13701 net.cpp:406] BatchNorm3 <- Eltwise1
I1013 22:23:58.714007 13701 net.cpp:367] BatchNorm3 -> Eltwise1 (in-place)
I1013 22:23:58.714165 13701 net.cpp:122] Setting up BatchNorm3
I1013 22:23:58.714169 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.714171 13701 net.cpp:137] Memory required for data: 216227800
I1013 22:23:58.714176 13701 layer_factory.hpp:77] Creating layer Scale3
I1013 22:23:58.714182 13701 net.cpp:84] Creating Layer Scale3
I1013 22:23:58.714184 13701 net.cpp:406] Scale3 <- Eltwise1
I1013 22:23:58.714187 13701 net.cpp:367] Scale3 -> Eltwise1 (in-place)
I1013 22:23:58.714220 13701 layer_factory.hpp:77] Creating layer Scale3
I1013 22:23:58.714311 13701 net.cpp:122] Setting up Scale3
I1013 22:23:58.714316 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.714318 13701 net.cpp:137] Memory required for data: 241315800
I1013 22:23:58.714321 13701 layer_factory.hpp:77] Creating layer penlu3
I1013 22:23:58.714329 13701 net.cpp:84] Creating Layer penlu3
I1013 22:23:58.714331 13701 net.cpp:406] penlu3 <- Eltwise1
I1013 22:23:58.714335 13701 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1013 22:23:58.714534 13701 net.cpp:122] Setting up penlu3
I1013 22:23:58.714538 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.714540 13701 net.cpp:137] Memory required for data: 266403800
I1013 22:23:58.714545 13701 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1013 22:23:58.714550 13701 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1013 22:23:58.714551 13701 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1013 22:23:58.714555 13701 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1013 22:23:58.714560 13701 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1013 22:23:58.714584 13701 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1013 22:23:58.714588 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.714591 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.714593 13701 net.cpp:137] Memory required for data: 316579800
I1013 22:23:58.714596 13701 layer_factory.hpp:77] Creating layer Convolution5
I1013 22:23:58.714602 13701 net.cpp:84] Creating Layer Convolution5
I1013 22:23:58.714606 13701 net.cpp:406] Convolution5 <- Eltwise1_penlu3_0_split_0
I1013 22:23:58.714608 13701 net.cpp:380] Convolution5 -> Convolution5
I1013 22:23:58.722590 13701 net.cpp:122] Setting up Convolution5
I1013 22:23:58.722601 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.722604 13701 net.cpp:137] Memory required for data: 341667800
I1013 22:23:58.722609 13701 layer_factory.hpp:77] Creating layer BatchNorm4
I1013 22:23:58.722617 13701 net.cpp:84] Creating Layer BatchNorm4
I1013 22:23:58.722621 13701 net.cpp:406] BatchNorm4 <- Convolution5
I1013 22:23:58.722625 13701 net.cpp:367] BatchNorm4 -> Convolution5 (in-place)
I1013 22:23:58.722815 13701 net.cpp:122] Setting up BatchNorm4
I1013 22:23:58.722820 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.722822 13701 net.cpp:137] Memory required for data: 366755800
I1013 22:23:58.722831 13701 layer_factory.hpp:77] Creating layer Scale4
I1013 22:23:58.722837 13701 net.cpp:84] Creating Layer Scale4
I1013 22:23:58.722839 13701 net.cpp:406] Scale4 <- Convolution5
I1013 22:23:58.722851 13701 net.cpp:367] Scale4 -> Convolution5 (in-place)
I1013 22:23:58.722889 13701 layer_factory.hpp:77] Creating layer Scale4
I1013 22:23:58.722981 13701 net.cpp:122] Setting up Scale4
I1013 22:23:58.722986 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.722988 13701 net.cpp:137] Memory required for data: 391843800
I1013 22:23:58.722992 13701 layer_factory.hpp:77] Creating layer penlu4
I1013 22:23:58.722998 13701 net.cpp:84] Creating Layer penlu4
I1013 22:23:58.723001 13701 net.cpp:406] penlu4 <- Convolution5
I1013 22:23:58.723004 13701 net.cpp:367] penlu4 -> Convolution5 (in-place)
I1013 22:23:58.723201 13701 net.cpp:122] Setting up penlu4
I1013 22:23:58.723206 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.723207 13701 net.cpp:137] Memory required for data: 416931800
I1013 22:23:58.723212 13701 layer_factory.hpp:77] Creating layer Convolution6
I1013 22:23:58.723217 13701 net.cpp:84] Creating Layer Convolution6
I1013 22:23:58.723220 13701 net.cpp:406] Convolution6 <- Convolution5
I1013 22:23:58.723223 13701 net.cpp:380] Convolution6 -> Convolution6
I1013 22:23:58.731514 13701 net.cpp:122] Setting up Convolution6
I1013 22:23:58.731523 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.731525 13701 net.cpp:137] Memory required for data: 442019800
I1013 22:23:58.731529 13701 layer_factory.hpp:77] Creating layer Eltwise2
I1013 22:23:58.731535 13701 net.cpp:84] Creating Layer Eltwise2
I1013 22:23:58.731537 13701 net.cpp:406] Eltwise2 <- Convolution6
I1013 22:23:58.731541 13701 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1013 22:23:58.731545 13701 net.cpp:380] Eltwise2 -> Eltwise2
I1013 22:23:58.731570 13701 net.cpp:122] Setting up Eltwise2
I1013 22:23:58.731575 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.731576 13701 net.cpp:137] Memory required for data: 467107800
I1013 22:23:58.731578 13701 layer_factory.hpp:77] Creating layer BatchNorm5
I1013 22:23:58.731582 13701 net.cpp:84] Creating Layer BatchNorm5
I1013 22:23:58.731585 13701 net.cpp:406] BatchNorm5 <- Eltwise2
I1013 22:23:58.731588 13701 net.cpp:367] BatchNorm5 -> Eltwise2 (in-place)
I1013 22:23:58.731743 13701 net.cpp:122] Setting up BatchNorm5
I1013 22:23:58.731748 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.731750 13701 net.cpp:137] Memory required for data: 492195800
I1013 22:23:58.731755 13701 layer_factory.hpp:77] Creating layer Scale5
I1013 22:23:58.731760 13701 net.cpp:84] Creating Layer Scale5
I1013 22:23:58.731761 13701 net.cpp:406] Scale5 <- Eltwise2
I1013 22:23:58.731765 13701 net.cpp:367] Scale5 -> Eltwise2 (in-place)
I1013 22:23:58.731796 13701 layer_factory.hpp:77] Creating layer Scale5
I1013 22:23:58.731890 13701 net.cpp:122] Setting up Scale5
I1013 22:23:58.731894 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.731896 13701 net.cpp:137] Memory required for data: 517283800
I1013 22:23:58.731900 13701 layer_factory.hpp:77] Creating layer penlu5
I1013 22:23:58.731906 13701 net.cpp:84] Creating Layer penlu5
I1013 22:23:58.731909 13701 net.cpp:406] penlu5 <- Eltwise2
I1013 22:23:58.731911 13701 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1013 22:23:58.732105 13701 net.cpp:122] Setting up penlu5
I1013 22:23:58.732110 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.732111 13701 net.cpp:137] Memory required for data: 542371800
I1013 22:23:58.732115 13701 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1013 22:23:58.732120 13701 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1013 22:23:58.732122 13701 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1013 22:23:58.732125 13701 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1013 22:23:58.732131 13701 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1013 22:23:58.732157 13701 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1013 22:23:58.732162 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.732165 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.732175 13701 net.cpp:137] Memory required for data: 592547800
I1013 22:23:58.732177 13701 layer_factory.hpp:77] Creating layer Convolution7
I1013 22:23:58.732184 13701 net.cpp:84] Creating Layer Convolution7
I1013 22:23:58.732187 13701 net.cpp:406] Convolution7 <- Eltwise2_penlu5_0_split_0
I1013 22:23:58.732190 13701 net.cpp:380] Convolution7 -> Convolution7
I1013 22:23:58.740344 13701 net.cpp:122] Setting up Convolution7
I1013 22:23:58.740352 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.740355 13701 net.cpp:137] Memory required for data: 617635800
I1013 22:23:58.740360 13701 layer_factory.hpp:77] Creating layer BatchNorm6
I1013 22:23:58.740365 13701 net.cpp:84] Creating Layer BatchNorm6
I1013 22:23:58.740368 13701 net.cpp:406] BatchNorm6 <- Convolution7
I1013 22:23:58.740372 13701 net.cpp:367] BatchNorm6 -> Convolution7 (in-place)
I1013 22:23:58.740533 13701 net.cpp:122] Setting up BatchNorm6
I1013 22:23:58.740538 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.740540 13701 net.cpp:137] Memory required for data: 642723800
I1013 22:23:58.740545 13701 layer_factory.hpp:77] Creating layer Scale6
I1013 22:23:58.740550 13701 net.cpp:84] Creating Layer Scale6
I1013 22:23:58.740551 13701 net.cpp:406] Scale6 <- Convolution7
I1013 22:23:58.740555 13701 net.cpp:367] Scale6 -> Convolution7 (in-place)
I1013 22:23:58.740588 13701 layer_factory.hpp:77] Creating layer Scale6
I1013 22:23:58.740679 13701 net.cpp:122] Setting up Scale6
I1013 22:23:58.740684 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.740686 13701 net.cpp:137] Memory required for data: 667811800
I1013 22:23:58.740689 13701 layer_factory.hpp:77] Creating layer penlu6
I1013 22:23:58.740695 13701 net.cpp:84] Creating Layer penlu6
I1013 22:23:58.740698 13701 net.cpp:406] penlu6 <- Convolution7
I1013 22:23:58.740701 13701 net.cpp:367] penlu6 -> Convolution7 (in-place)
I1013 22:23:58.740896 13701 net.cpp:122] Setting up penlu6
I1013 22:23:58.740900 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.740902 13701 net.cpp:137] Memory required for data: 692899800
I1013 22:23:58.740906 13701 layer_factory.hpp:77] Creating layer Convolution8
I1013 22:23:58.740917 13701 net.cpp:84] Creating Layer Convolution8
I1013 22:23:58.740919 13701 net.cpp:406] Convolution8 <- Convolution7
I1013 22:23:58.740923 13701 net.cpp:380] Convolution8 -> Convolution8
I1013 22:23:58.749066 13701 net.cpp:122] Setting up Convolution8
I1013 22:23:58.749074 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.749078 13701 net.cpp:137] Memory required for data: 717987800
I1013 22:23:58.749081 13701 layer_factory.hpp:77] Creating layer Eltwise3
I1013 22:23:58.749086 13701 net.cpp:84] Creating Layer Eltwise3
I1013 22:23:58.749089 13701 net.cpp:406] Eltwise3 <- Convolution8
I1013 22:23:58.749092 13701 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1013 22:23:58.749096 13701 net.cpp:380] Eltwise3 -> Eltwise3
I1013 22:23:58.749119 13701 net.cpp:122] Setting up Eltwise3
I1013 22:23:58.749125 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.749126 13701 net.cpp:137] Memory required for data: 743075800
I1013 22:23:58.749128 13701 layer_factory.hpp:77] Creating layer BatchNorm7
I1013 22:23:58.749132 13701 net.cpp:84] Creating Layer BatchNorm7
I1013 22:23:58.749135 13701 net.cpp:406] BatchNorm7 <- Eltwise3
I1013 22:23:58.749138 13701 net.cpp:367] BatchNorm7 -> Eltwise3 (in-place)
I1013 22:23:58.749291 13701 net.cpp:122] Setting up BatchNorm7
I1013 22:23:58.749296 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.749299 13701 net.cpp:137] Memory required for data: 768163800
I1013 22:23:58.749303 13701 layer_factory.hpp:77] Creating layer Scale7
I1013 22:23:58.749307 13701 net.cpp:84] Creating Layer Scale7
I1013 22:23:58.749310 13701 net.cpp:406] Scale7 <- Eltwise3
I1013 22:23:58.749313 13701 net.cpp:367] Scale7 -> Eltwise3 (in-place)
I1013 22:23:58.749346 13701 layer_factory.hpp:77] Creating layer Scale7
I1013 22:23:58.749435 13701 net.cpp:122] Setting up Scale7
I1013 22:23:58.749447 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.749450 13701 net.cpp:137] Memory required for data: 793251800
I1013 22:23:58.749454 13701 layer_factory.hpp:77] Creating layer penlu7
I1013 22:23:58.749459 13701 net.cpp:84] Creating Layer penlu7
I1013 22:23:58.749461 13701 net.cpp:406] penlu7 <- Eltwise3
I1013 22:23:58.749465 13701 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1013 22:23:58.749660 13701 net.cpp:122] Setting up penlu7
I1013 22:23:58.749665 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.749667 13701 net.cpp:137] Memory required for data: 818339800
I1013 22:23:58.749678 13701 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1013 22:23:58.749683 13701 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1013 22:23:58.749686 13701 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1013 22:23:58.749688 13701 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1013 22:23:58.749693 13701 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1013 22:23:58.749721 13701 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1013 22:23:58.749724 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.749727 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.749729 13701 net.cpp:137] Memory required for data: 868515800
I1013 22:23:58.749732 13701 layer_factory.hpp:77] Creating layer Convolution9
I1013 22:23:58.749737 13701 net.cpp:84] Creating Layer Convolution9
I1013 22:23:58.749739 13701 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_0
I1013 22:23:58.749743 13701 net.cpp:380] Convolution9 -> Convolution9
I1013 22:23:58.758340 13701 net.cpp:122] Setting up Convolution9
I1013 22:23:58.758352 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.758355 13701 net.cpp:137] Memory required for data: 893603800
I1013 22:23:58.758359 13701 layer_factory.hpp:77] Creating layer BatchNorm8
I1013 22:23:58.758366 13701 net.cpp:84] Creating Layer BatchNorm8
I1013 22:23:58.758370 13701 net.cpp:406] BatchNorm8 <- Convolution9
I1013 22:23:58.758374 13701 net.cpp:367] BatchNorm8 -> Convolution9 (in-place)
I1013 22:23:58.758549 13701 net.cpp:122] Setting up BatchNorm8
I1013 22:23:58.758555 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.758558 13701 net.cpp:137] Memory required for data: 918691800
I1013 22:23:58.758563 13701 layer_factory.hpp:77] Creating layer Scale8
I1013 22:23:58.758568 13701 net.cpp:84] Creating Layer Scale8
I1013 22:23:58.758570 13701 net.cpp:406] Scale8 <- Convolution9
I1013 22:23:58.758574 13701 net.cpp:367] Scale8 -> Convolution9 (in-place)
I1013 22:23:58.758610 13701 layer_factory.hpp:77] Creating layer Scale8
I1013 22:23:58.758707 13701 net.cpp:122] Setting up Scale8
I1013 22:23:58.758711 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.758713 13701 net.cpp:137] Memory required for data: 943779800
I1013 22:23:58.758718 13701 layer_factory.hpp:77] Creating layer penlu8
I1013 22:23:58.758724 13701 net.cpp:84] Creating Layer penlu8
I1013 22:23:58.758726 13701 net.cpp:406] penlu8 <- Convolution9
I1013 22:23:58.758730 13701 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1013 22:23:58.758955 13701 net.cpp:122] Setting up penlu8
I1013 22:23:58.758960 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.758962 13701 net.cpp:137] Memory required for data: 968867800
I1013 22:23:58.758967 13701 layer_factory.hpp:77] Creating layer Convolution10
I1013 22:23:58.758975 13701 net.cpp:84] Creating Layer Convolution10
I1013 22:23:58.758976 13701 net.cpp:406] Convolution10 <- Convolution9
I1013 22:23:58.758980 13701 net.cpp:380] Convolution10 -> Convolution10
I1013 22:23:58.767127 13701 net.cpp:122] Setting up Convolution10
I1013 22:23:58.767146 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.767159 13701 net.cpp:137] Memory required for data: 993955800
I1013 22:23:58.767163 13701 layer_factory.hpp:77] Creating layer Eltwise4
I1013 22:23:58.767179 13701 net.cpp:84] Creating Layer Eltwise4
I1013 22:23:58.767200 13701 net.cpp:406] Eltwise4 <- Convolution10
I1013 22:23:58.767204 13701 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1013 22:23:58.767210 13701 net.cpp:380] Eltwise4 -> Eltwise4
I1013 22:23:58.767262 13701 net.cpp:122] Setting up Eltwise4
I1013 22:23:58.767266 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.767268 13701 net.cpp:137] Memory required for data: 1019043800
I1013 22:23:58.767271 13701 layer_factory.hpp:77] Creating layer Eltwise4_Eltwise4_0_split
I1013 22:23:58.767276 13701 net.cpp:84] Creating Layer Eltwise4_Eltwise4_0_split
I1013 22:23:58.767277 13701 net.cpp:406] Eltwise4_Eltwise4_0_split <- Eltwise4
I1013 22:23:58.767282 13701 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I1013 22:23:58.767285 13701 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I1013 22:23:58.767313 13701 net.cpp:122] Setting up Eltwise4_Eltwise4_0_split
I1013 22:23:58.767318 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.767320 13701 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1013 22:23:58.767323 13701 net.cpp:137] Memory required for data: 1069219800
I1013 22:23:58.767324 13701 layer_factory.hpp:77] Creating layer Convolution11
I1013 22:23:58.767330 13701 net.cpp:84] Creating Layer Convolution11
I1013 22:23:58.767333 13701 net.cpp:406] Convolution11 <- Eltwise4_Eltwise4_0_split_0
I1013 22:23:58.767336 13701 net.cpp:380] Convolution11 -> Convolution11
I1013 22:23:58.781321 13701 net.cpp:122] Setting up Convolution11
I1013 22:23:58.781329 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.781332 13701 net.cpp:137] Memory required for data: 1081763800
I1013 22:23:58.781337 13701 layer_factory.hpp:77] Creating layer BatchNorm9
I1013 22:23:58.781342 13701 net.cpp:84] Creating Layer BatchNorm9
I1013 22:23:58.781344 13701 net.cpp:406] BatchNorm9 <- Convolution11
I1013 22:23:58.781348 13701 net.cpp:367] BatchNorm9 -> Convolution11 (in-place)
I1013 22:23:58.781523 13701 net.cpp:122] Setting up BatchNorm9
I1013 22:23:58.781528 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.781530 13701 net.cpp:137] Memory required for data: 1094307800
I1013 22:23:58.781535 13701 layer_factory.hpp:77] Creating layer Scale9
I1013 22:23:58.781539 13701 net.cpp:84] Creating Layer Scale9
I1013 22:23:58.781543 13701 net.cpp:406] Scale9 <- Convolution11
I1013 22:23:58.781545 13701 net.cpp:367] Scale9 -> Convolution11 (in-place)
I1013 22:23:58.781582 13701 layer_factory.hpp:77] Creating layer Scale9
I1013 22:23:58.781673 13701 net.cpp:122] Setting up Scale9
I1013 22:23:58.781678 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.781680 13701 net.cpp:137] Memory required for data: 1106851800
I1013 22:23:58.781683 13701 layer_factory.hpp:77] Creating layer penlu9
I1013 22:23:58.781688 13701 net.cpp:84] Creating Layer penlu9
I1013 22:23:58.781692 13701 net.cpp:406] penlu9 <- Convolution11
I1013 22:23:58.781695 13701 net.cpp:367] penlu9 -> Convolution11 (in-place)
I1013 22:23:58.781860 13701 net.cpp:122] Setting up penlu9
I1013 22:23:58.781864 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.781867 13701 net.cpp:137] Memory required for data: 1119395800
I1013 22:23:58.781872 13701 layer_factory.hpp:77] Creating layer Convolution12
I1013 22:23:58.781877 13701 net.cpp:84] Creating Layer Convolution12
I1013 22:23:58.781879 13701 net.cpp:406] Convolution12 <- Convolution11
I1013 22:23:58.781883 13701 net.cpp:380] Convolution12 -> Convolution12
I1013 22:23:58.809420 13701 net.cpp:122] Setting up Convolution12
I1013 22:23:58.809450 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.809454 13701 net.cpp:137] Memory required for data: 1131939800
I1013 22:23:58.809459 13701 layer_factory.hpp:77] Creating layer Convolution13
I1013 22:23:58.809482 13701 net.cpp:84] Creating Layer Convolution13
I1013 22:23:58.809486 13701 net.cpp:406] Convolution13 <- Eltwise4_Eltwise4_0_split_1
I1013 22:23:58.809491 13701 net.cpp:380] Convolution13 -> Convolution13
I1013 22:23:58.812191 13701 net.cpp:122] Setting up Convolution13
I1013 22:23:58.812221 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.812223 13701 net.cpp:137] Memory required for data: 1144483800
I1013 22:23:58.812227 13701 layer_factory.hpp:77] Creating layer Eltwise5
I1013 22:23:58.812233 13701 net.cpp:84] Creating Layer Eltwise5
I1013 22:23:58.812247 13701 net.cpp:406] Eltwise5 <- Convolution12
I1013 22:23:58.812249 13701 net.cpp:406] Eltwise5 <- Convolution13
I1013 22:23:58.812253 13701 net.cpp:380] Eltwise5 -> Eltwise5
I1013 22:23:58.812288 13701 net.cpp:122] Setting up Eltwise5
I1013 22:23:58.812301 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.812304 13701 net.cpp:137] Memory required for data: 1157027800
I1013 22:23:58.812305 13701 layer_factory.hpp:77] Creating layer BatchNorm10
I1013 22:23:58.812321 13701 net.cpp:84] Creating Layer BatchNorm10
I1013 22:23:58.812324 13701 net.cpp:406] BatchNorm10 <- Eltwise5
I1013 22:23:58.812327 13701 net.cpp:367] BatchNorm10 -> Eltwise5 (in-place)
I1013 22:23:58.812521 13701 net.cpp:122] Setting up BatchNorm10
I1013 22:23:58.812526 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.812539 13701 net.cpp:137] Memory required for data: 1169571800
I1013 22:23:58.812544 13701 layer_factory.hpp:77] Creating layer Scale10
I1013 22:23:58.812549 13701 net.cpp:84] Creating Layer Scale10
I1013 22:23:58.812562 13701 net.cpp:406] Scale10 <- Eltwise5
I1013 22:23:58.812566 13701 net.cpp:367] Scale10 -> Eltwise5 (in-place)
I1013 22:23:58.812623 13701 layer_factory.hpp:77] Creating layer Scale10
I1013 22:23:58.812755 13701 net.cpp:122] Setting up Scale10
I1013 22:23:58.812759 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.812772 13701 net.cpp:137] Memory required for data: 1182115800
I1013 22:23:58.812777 13701 layer_factory.hpp:77] Creating layer penlu10
I1013 22:23:58.812783 13701 net.cpp:84] Creating Layer penlu10
I1013 22:23:58.812794 13701 net.cpp:406] penlu10 <- Eltwise5
I1013 22:23:58.812798 13701 net.cpp:367] penlu10 -> Eltwise5 (in-place)
I1013 22:23:58.812988 13701 net.cpp:122] Setting up penlu10
I1013 22:23:58.812994 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.813006 13701 net.cpp:137] Memory required for data: 1194659800
I1013 22:23:58.813011 13701 layer_factory.hpp:77] Creating layer Eltwise5_penlu10_0_split
I1013 22:23:58.813015 13701 net.cpp:84] Creating Layer Eltwise5_penlu10_0_split
I1013 22:23:58.813017 13701 net.cpp:406] Eltwise5_penlu10_0_split <- Eltwise5
I1013 22:23:58.813022 13701 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_0
I1013 22:23:58.813030 13701 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_1
I1013 22:23:58.813067 13701 net.cpp:122] Setting up Eltwise5_penlu10_0_split
I1013 22:23:58.813072 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.813086 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.813087 13701 net.cpp:137] Memory required for data: 1219747800
I1013 22:23:58.813089 13701 layer_factory.hpp:77] Creating layer Convolution14
I1013 22:23:58.813096 13701 net.cpp:84] Creating Layer Convolution14
I1013 22:23:58.813098 13701 net.cpp:406] Convolution14 <- Eltwise5_penlu10_0_split_0
I1013 22:23:58.813102 13701 net.cpp:380] Convolution14 -> Convolution14
I1013 22:23:58.840484 13701 net.cpp:122] Setting up Convolution14
I1013 22:23:58.840503 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.840507 13701 net.cpp:137] Memory required for data: 1232291800
I1013 22:23:58.840512 13701 layer_factory.hpp:77] Creating layer BatchNorm11
I1013 22:23:58.840522 13701 net.cpp:84] Creating Layer BatchNorm11
I1013 22:23:58.840535 13701 net.cpp:406] BatchNorm11 <- Convolution14
I1013 22:23:58.840540 13701 net.cpp:367] BatchNorm11 -> Convolution14 (in-place)
I1013 22:23:58.840756 13701 net.cpp:122] Setting up BatchNorm11
I1013 22:23:58.840761 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.840764 13701 net.cpp:137] Memory required for data: 1244835800
I1013 22:23:58.840770 13701 layer_factory.hpp:77] Creating layer Scale11
I1013 22:23:58.840793 13701 net.cpp:84] Creating Layer Scale11
I1013 22:23:58.840796 13701 net.cpp:406] Scale11 <- Convolution14
I1013 22:23:58.840800 13701 net.cpp:367] Scale11 -> Convolution14 (in-place)
I1013 22:23:58.840869 13701 layer_factory.hpp:77] Creating layer Scale11
I1013 22:23:58.840986 13701 net.cpp:122] Setting up Scale11
I1013 22:23:58.840991 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.840993 13701 net.cpp:137] Memory required for data: 1257379800
I1013 22:23:58.841007 13701 layer_factory.hpp:77] Creating layer penlu11
I1013 22:23:58.841024 13701 net.cpp:84] Creating Layer penlu11
I1013 22:23:58.841028 13701 net.cpp:406] penlu11 <- Convolution14
I1013 22:23:58.841032 13701 net.cpp:367] penlu11 -> Convolution14 (in-place)
I1013 22:23:58.841744 13701 net.cpp:122] Setting up penlu11
I1013 22:23:58.841753 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.841756 13701 net.cpp:137] Memory required for data: 1269923800
I1013 22:23:58.841761 13701 layer_factory.hpp:77] Creating layer Convolution15
I1013 22:23:58.841768 13701 net.cpp:84] Creating Layer Convolution15
I1013 22:23:58.841771 13701 net.cpp:406] Convolution15 <- Convolution14
I1013 22:23:58.841786 13701 net.cpp:380] Convolution15 -> Convolution15
I1013 22:23:58.868907 13701 net.cpp:122] Setting up Convolution15
I1013 22:23:58.868927 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.868930 13701 net.cpp:137] Memory required for data: 1282467800
I1013 22:23:58.868935 13701 layer_factory.hpp:77] Creating layer Eltwise6
I1013 22:23:58.868945 13701 net.cpp:84] Creating Layer Eltwise6
I1013 22:23:58.868959 13701 net.cpp:406] Eltwise6 <- Convolution15
I1013 22:23:58.868964 13701 net.cpp:406] Eltwise6 <- Eltwise5_penlu10_0_split_1
I1013 22:23:58.868978 13701 net.cpp:380] Eltwise6 -> Eltwise6
I1013 22:23:58.869015 13701 net.cpp:122] Setting up Eltwise6
I1013 22:23:58.869029 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.869031 13701 net.cpp:137] Memory required for data: 1295011800
I1013 22:23:58.869033 13701 layer_factory.hpp:77] Creating layer BatchNorm12
I1013 22:23:58.869048 13701 net.cpp:84] Creating Layer BatchNorm12
I1013 22:23:58.869051 13701 net.cpp:406] BatchNorm12 <- Eltwise6
I1013 22:23:58.869055 13701 net.cpp:367] BatchNorm12 -> Eltwise6 (in-place)
I1013 22:23:58.869279 13701 net.cpp:122] Setting up BatchNorm12
I1013 22:23:58.869284 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.869287 13701 net.cpp:137] Memory required for data: 1307555800
I1013 22:23:58.869292 13701 layer_factory.hpp:77] Creating layer Scale12
I1013 22:23:58.869297 13701 net.cpp:84] Creating Layer Scale12
I1013 22:23:58.869299 13701 net.cpp:406] Scale12 <- Eltwise6
I1013 22:23:58.869302 13701 net.cpp:367] Scale12 -> Eltwise6 (in-place)
I1013 22:23:58.869374 13701 layer_factory.hpp:77] Creating layer Scale12
I1013 22:23:58.869534 13701 net.cpp:122] Setting up Scale12
I1013 22:23:58.869539 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.869541 13701 net.cpp:137] Memory required for data: 1320099800
I1013 22:23:58.869545 13701 layer_factory.hpp:77] Creating layer penlu12
I1013 22:23:58.869556 13701 net.cpp:84] Creating Layer penlu12
I1013 22:23:58.869570 13701 net.cpp:406] penlu12 <- Eltwise6
I1013 22:23:58.869573 13701 net.cpp:367] penlu12 -> Eltwise6 (in-place)
I1013 22:23:58.869774 13701 net.cpp:122] Setting up penlu12
I1013 22:23:58.869781 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.869782 13701 net.cpp:137] Memory required for data: 1332643800
I1013 22:23:58.869787 13701 layer_factory.hpp:77] Creating layer Eltwise6_penlu12_0_split
I1013 22:23:58.869792 13701 net.cpp:84] Creating Layer Eltwise6_penlu12_0_split
I1013 22:23:58.869794 13701 net.cpp:406] Eltwise6_penlu12_0_split <- Eltwise6
I1013 22:23:58.869797 13701 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_0
I1013 22:23:58.869812 13701 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_1
I1013 22:23:58.869874 13701 net.cpp:122] Setting up Eltwise6_penlu12_0_split
I1013 22:23:58.869887 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.869900 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.869902 13701 net.cpp:137] Memory required for data: 1357731800
I1013 22:23:58.869905 13701 layer_factory.hpp:77] Creating layer Convolution16
I1013 22:23:58.869925 13701 net.cpp:84] Creating Layer Convolution16
I1013 22:23:58.869938 13701 net.cpp:406] Convolution16 <- Eltwise6_penlu12_0_split_0
I1013 22:23:58.869942 13701 net.cpp:380] Convolution16 -> Convolution16
I1013 22:23:58.897341 13701 net.cpp:122] Setting up Convolution16
I1013 22:23:58.897359 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.897362 13701 net.cpp:137] Memory required for data: 1370275800
I1013 22:23:58.897368 13701 layer_factory.hpp:77] Creating layer BatchNorm13
I1013 22:23:58.897377 13701 net.cpp:84] Creating Layer BatchNorm13
I1013 22:23:58.897392 13701 net.cpp:406] BatchNorm13 <- Convolution16
I1013 22:23:58.897397 13701 net.cpp:367] BatchNorm13 -> Convolution16 (in-place)
I1013 22:23:58.897619 13701 net.cpp:122] Setting up BatchNorm13
I1013 22:23:58.897624 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.897625 13701 net.cpp:137] Memory required for data: 1382819800
I1013 22:23:58.897630 13701 layer_factory.hpp:77] Creating layer Scale13
I1013 22:23:58.897636 13701 net.cpp:84] Creating Layer Scale13
I1013 22:23:58.897639 13701 net.cpp:406] Scale13 <- Convolution16
I1013 22:23:58.897641 13701 net.cpp:367] Scale13 -> Convolution16 (in-place)
I1013 22:23:58.897716 13701 layer_factory.hpp:77] Creating layer Scale13
I1013 22:23:58.897846 13701 net.cpp:122] Setting up Scale13
I1013 22:23:58.897851 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.897853 13701 net.cpp:137] Memory required for data: 1395363800
I1013 22:23:58.897857 13701 layer_factory.hpp:77] Creating layer penlu13
I1013 22:23:58.897863 13701 net.cpp:84] Creating Layer penlu13
I1013 22:23:58.897866 13701 net.cpp:406] penlu13 <- Convolution16
I1013 22:23:58.897869 13701 net.cpp:367] penlu13 -> Convolution16 (in-place)
I1013 22:23:58.898102 13701 net.cpp:122] Setting up penlu13
I1013 22:23:58.898108 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.898110 13701 net.cpp:137] Memory required for data: 1407907800
I1013 22:23:58.898114 13701 layer_factory.hpp:77] Creating layer Convolution17
I1013 22:23:58.898121 13701 net.cpp:84] Creating Layer Convolution17
I1013 22:23:58.898124 13701 net.cpp:406] Convolution17 <- Convolution16
I1013 22:23:58.898138 13701 net.cpp:380] Convolution17 -> Convolution17
I1013 22:23:58.925753 13701 net.cpp:122] Setting up Convolution17
I1013 22:23:58.925773 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.925776 13701 net.cpp:137] Memory required for data: 1420451800
I1013 22:23:58.925782 13701 layer_factory.hpp:77] Creating layer Eltwise7
I1013 22:23:58.925791 13701 net.cpp:84] Creating Layer Eltwise7
I1013 22:23:58.925804 13701 net.cpp:406] Eltwise7 <- Convolution17
I1013 22:23:58.925809 13701 net.cpp:406] Eltwise7 <- Eltwise6_penlu12_0_split_1
I1013 22:23:58.925813 13701 net.cpp:380] Eltwise7 -> Eltwise7
I1013 22:23:58.925855 13701 net.cpp:122] Setting up Eltwise7
I1013 22:23:58.925860 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.925863 13701 net.cpp:137] Memory required for data: 1432995800
I1013 22:23:58.925864 13701 layer_factory.hpp:77] Creating layer BatchNorm14
I1013 22:23:58.925869 13701 net.cpp:84] Creating Layer BatchNorm14
I1013 22:23:58.925873 13701 net.cpp:406] BatchNorm14 <- Eltwise7
I1013 22:23:58.925875 13701 net.cpp:367] BatchNorm14 -> Eltwise7 (in-place)
I1013 22:23:58.926106 13701 net.cpp:122] Setting up BatchNorm14
I1013 22:23:58.926112 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.926115 13701 net.cpp:137] Memory required for data: 1445539800
I1013 22:23:58.926120 13701 layer_factory.hpp:77] Creating layer Scale14
I1013 22:23:58.926125 13701 net.cpp:84] Creating Layer Scale14
I1013 22:23:58.926126 13701 net.cpp:406] Scale14 <- Eltwise7
I1013 22:23:58.926151 13701 net.cpp:367] Scale14 -> Eltwise7 (in-place)
I1013 22:23:58.926205 13701 layer_factory.hpp:77] Creating layer Scale14
I1013 22:23:58.926323 13701 net.cpp:122] Setting up Scale14
I1013 22:23:58.926329 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.926342 13701 net.cpp:137] Memory required for data: 1458083800
I1013 22:23:58.926347 13701 layer_factory.hpp:77] Creating layer penlu14
I1013 22:23:58.926352 13701 net.cpp:84] Creating Layer penlu14
I1013 22:23:58.926353 13701 net.cpp:406] penlu14 <- Eltwise7
I1013 22:23:58.926357 13701 net.cpp:367] penlu14 -> Eltwise7 (in-place)
I1013 22:23:58.926558 13701 net.cpp:122] Setting up penlu14
I1013 22:23:58.926563 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.926565 13701 net.cpp:137] Memory required for data: 1470627800
I1013 22:23:58.926602 13701 layer_factory.hpp:77] Creating layer Eltwise7_penlu14_0_split
I1013 22:23:58.926607 13701 net.cpp:84] Creating Layer Eltwise7_penlu14_0_split
I1013 22:23:58.926610 13701 net.cpp:406] Eltwise7_penlu14_0_split <- Eltwise7
I1013 22:23:58.926614 13701 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_0
I1013 22:23:58.926627 13701 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_1
I1013 22:23:58.926681 13701 net.cpp:122] Setting up Eltwise7_penlu14_0_split
I1013 22:23:58.926693 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.926697 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.926698 13701 net.cpp:137] Memory required for data: 1495715800
I1013 22:23:58.926710 13701 layer_factory.hpp:77] Creating layer Convolution18
I1013 22:23:58.926718 13701 net.cpp:84] Creating Layer Convolution18
I1013 22:23:58.926720 13701 net.cpp:406] Convolution18 <- Eltwise7_penlu14_0_split_0
I1013 22:23:58.926734 13701 net.cpp:380] Convolution18 -> Convolution18
I1013 22:23:58.954195 13701 net.cpp:122] Setting up Convolution18
I1013 22:23:58.954224 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.954227 13701 net.cpp:137] Memory required for data: 1508259800
I1013 22:23:58.954232 13701 layer_factory.hpp:77] Creating layer BatchNorm15
I1013 22:23:58.954251 13701 net.cpp:84] Creating Layer BatchNorm15
I1013 22:23:58.954255 13701 net.cpp:406] BatchNorm15 <- Convolution18
I1013 22:23:58.954260 13701 net.cpp:367] BatchNorm15 -> Convolution18 (in-place)
I1013 22:23:58.954474 13701 net.cpp:122] Setting up BatchNorm15
I1013 22:23:58.954480 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.954493 13701 net.cpp:137] Memory required for data: 1520803800
I1013 22:23:58.954499 13701 layer_factory.hpp:77] Creating layer Scale15
I1013 22:23:58.954504 13701 net.cpp:84] Creating Layer Scale15
I1013 22:23:58.954516 13701 net.cpp:406] Scale15 <- Convolution18
I1013 22:23:58.954522 13701 net.cpp:367] Scale15 -> Convolution18 (in-place)
I1013 22:23:58.954586 13701 layer_factory.hpp:77] Creating layer Scale15
I1013 22:23:58.954718 13701 net.cpp:122] Setting up Scale15
I1013 22:23:58.954723 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.954726 13701 net.cpp:137] Memory required for data: 1533347800
I1013 22:23:58.954730 13701 layer_factory.hpp:77] Creating layer penlu15
I1013 22:23:58.954736 13701 net.cpp:84] Creating Layer penlu15
I1013 22:23:58.954738 13701 net.cpp:406] penlu15 <- Convolution18
I1013 22:23:58.954742 13701 net.cpp:367] penlu15 -> Convolution18 (in-place)
I1013 22:23:58.954946 13701 net.cpp:122] Setting up penlu15
I1013 22:23:58.954952 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.954954 13701 net.cpp:137] Memory required for data: 1545891800
I1013 22:23:58.954959 13701 layer_factory.hpp:77] Creating layer Convolution19
I1013 22:23:58.954965 13701 net.cpp:84] Creating Layer Convolution19
I1013 22:23:58.954968 13701 net.cpp:406] Convolution19 <- Convolution18
I1013 22:23:58.954982 13701 net.cpp:380] Convolution19 -> Convolution19
I1013 22:23:58.982281 13701 net.cpp:122] Setting up Convolution19
I1013 22:23:58.982300 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.982313 13701 net.cpp:137] Memory required for data: 1558435800
I1013 22:23:58.982328 13701 layer_factory.hpp:77] Creating layer Eltwise8
I1013 22:23:58.982338 13701 net.cpp:84] Creating Layer Eltwise8
I1013 22:23:58.982342 13701 net.cpp:406] Eltwise8 <- Convolution19
I1013 22:23:58.982347 13701 net.cpp:406] Eltwise8 <- Eltwise7_penlu14_0_split_1
I1013 22:23:58.982352 13701 net.cpp:380] Eltwise8 -> Eltwise8
I1013 22:23:58.982406 13701 net.cpp:122] Setting up Eltwise8
I1013 22:23:58.982420 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.982422 13701 net.cpp:137] Memory required for data: 1570979800
I1013 22:23:58.982424 13701 layer_factory.hpp:77] Creating layer Eltwise8_Eltwise8_0_split
I1013 22:23:58.982439 13701 net.cpp:84] Creating Layer Eltwise8_Eltwise8_0_split
I1013 22:23:58.982441 13701 net.cpp:406] Eltwise8_Eltwise8_0_split <- Eltwise8
I1013 22:23:58.982445 13701 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I1013 22:23:58.982460 13701 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I1013 22:23:58.982511 13701 net.cpp:122] Setting up Eltwise8_Eltwise8_0_split
I1013 22:23:58.982517 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.982529 13701 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1013 22:23:58.982532 13701 net.cpp:137] Memory required for data: 1596067800
I1013 22:23:58.982533 13701 layer_factory.hpp:77] Creating layer Convolution20
I1013 22:23:58.982551 13701 net.cpp:84] Creating Layer Convolution20
I1013 22:23:58.982554 13701 net.cpp:406] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I1013 22:23:58.982560 13701 net.cpp:380] Convolution20 -> Convolution20
I1013 22:23:59.035020 13701 net.cpp:122] Setting up Convolution20
I1013 22:23:59.035042 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.035044 13701 net.cpp:137] Memory required for data: 1602339800
I1013 22:23:59.035050 13701 layer_factory.hpp:77] Creating layer BatchNorm16
I1013 22:23:59.035070 13701 net.cpp:84] Creating Layer BatchNorm16
I1013 22:23:59.035075 13701 net.cpp:406] BatchNorm16 <- Convolution20
I1013 22:23:59.035080 13701 net.cpp:367] BatchNorm16 -> Convolution20 (in-place)
I1013 22:23:59.035300 13701 net.cpp:122] Setting up BatchNorm16
I1013 22:23:59.035306 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.035308 13701 net.cpp:137] Memory required for data: 1608611800
I1013 22:23:59.035313 13701 layer_factory.hpp:77] Creating layer Scale16
I1013 22:23:59.035320 13701 net.cpp:84] Creating Layer Scale16
I1013 22:23:59.035321 13701 net.cpp:406] Scale16 <- Convolution20
I1013 22:23:59.035325 13701 net.cpp:367] Scale16 -> Convolution20 (in-place)
I1013 22:23:59.035394 13701 layer_factory.hpp:77] Creating layer Scale16
I1013 22:23:59.035553 13701 net.cpp:122] Setting up Scale16
I1013 22:23:59.035558 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.035560 13701 net.cpp:137] Memory required for data: 1614883800
I1013 22:23:59.035564 13701 layer_factory.hpp:77] Creating layer penlu16
I1013 22:23:59.035570 13701 net.cpp:84] Creating Layer penlu16
I1013 22:23:59.035573 13701 net.cpp:406] penlu16 <- Convolution20
I1013 22:23:59.035578 13701 net.cpp:367] penlu16 -> Convolution20 (in-place)
I1013 22:23:59.035756 13701 net.cpp:122] Setting up penlu16
I1013 22:23:59.035763 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.035764 13701 net.cpp:137] Memory required for data: 1621155800
I1013 22:23:59.035768 13701 layer_factory.hpp:77] Creating layer Convolution21
I1013 22:23:59.035776 13701 net.cpp:84] Creating Layer Convolution21
I1013 22:23:59.035779 13701 net.cpp:406] Convolution21 <- Convolution20
I1013 22:23:59.035792 13701 net.cpp:380] Convolution21 -> Convolution21
I1013 22:23:59.140161 13701 net.cpp:122] Setting up Convolution21
I1013 22:23:59.140183 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.140187 13701 net.cpp:137] Memory required for data: 1627427800
I1013 22:23:59.140192 13701 layer_factory.hpp:77] Creating layer Convolution22
I1013 22:23:59.140240 13701 net.cpp:84] Creating Layer Convolution22
I1013 22:23:59.140245 13701 net.cpp:406] Convolution22 <- Eltwise8_Eltwise8_0_split_1
I1013 22:23:59.140254 13701 net.cpp:380] Convolution22 -> Convolution22
I1013 22:23:59.146751 13701 net.cpp:122] Setting up Convolution22
I1013 22:23:59.146761 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.146764 13701 net.cpp:137] Memory required for data: 1633699800
I1013 22:23:59.146769 13701 layer_factory.hpp:77] Creating layer Eltwise9
I1013 22:23:59.146787 13701 net.cpp:84] Creating Layer Eltwise9
I1013 22:23:59.146790 13701 net.cpp:406] Eltwise9 <- Convolution21
I1013 22:23:59.146795 13701 net.cpp:406] Eltwise9 <- Convolution22
I1013 22:23:59.146808 13701 net.cpp:380] Eltwise9 -> Eltwise9
I1013 22:23:59.146853 13701 net.cpp:122] Setting up Eltwise9
I1013 22:23:59.146858 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.146872 13701 net.cpp:137] Memory required for data: 1639971800
I1013 22:23:59.146875 13701 layer_factory.hpp:77] Creating layer BatchNorm17
I1013 22:23:59.146881 13701 net.cpp:84] Creating Layer BatchNorm17
I1013 22:23:59.146893 13701 net.cpp:406] BatchNorm17 <- Eltwise9
I1013 22:23:59.146896 13701 net.cpp:367] BatchNorm17 -> Eltwise9 (in-place)
I1013 22:23:59.147088 13701 net.cpp:122] Setting up BatchNorm17
I1013 22:23:59.147092 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.147094 13701 net.cpp:137] Memory required for data: 1646243800
I1013 22:23:59.147099 13701 layer_factory.hpp:77] Creating layer Scale17
I1013 22:23:59.147105 13701 net.cpp:84] Creating Layer Scale17
I1013 22:23:59.147109 13701 net.cpp:406] Scale17 <- Eltwise9
I1013 22:23:59.147121 13701 net.cpp:367] Scale17 -> Eltwise9 (in-place)
I1013 22:23:59.147166 13701 layer_factory.hpp:77] Creating layer Scale17
I1013 22:23:59.147281 13701 net.cpp:122] Setting up Scale17
I1013 22:23:59.147286 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.147289 13701 net.cpp:137] Memory required for data: 1652515800
I1013 22:23:59.147292 13701 layer_factory.hpp:77] Creating layer penlu17
I1013 22:23:59.147308 13701 net.cpp:84] Creating Layer penlu17
I1013 22:23:59.147311 13701 net.cpp:406] penlu17 <- Eltwise9
I1013 22:23:59.147315 13701 net.cpp:367] penlu17 -> Eltwise9 (in-place)
I1013 22:23:59.147470 13701 net.cpp:122] Setting up penlu17
I1013 22:23:59.147475 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.147477 13701 net.cpp:137] Memory required for data: 1658787800
I1013 22:23:59.147482 13701 layer_factory.hpp:77] Creating layer Eltwise9_penlu17_0_split
I1013 22:23:59.147497 13701 net.cpp:84] Creating Layer Eltwise9_penlu17_0_split
I1013 22:23:59.147500 13701 net.cpp:406] Eltwise9_penlu17_0_split <- Eltwise9
I1013 22:23:59.147503 13701 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_0
I1013 22:23:59.147507 13701 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_1
I1013 22:23:59.147548 13701 net.cpp:122] Setting up Eltwise9_penlu17_0_split
I1013 22:23:59.147553 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.147557 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.147558 13701 net.cpp:137] Memory required for data: 1671331800
I1013 22:23:59.147570 13701 layer_factory.hpp:77] Creating layer Convolution23
I1013 22:23:59.147575 13701 net.cpp:84] Creating Layer Convolution23
I1013 22:23:59.147578 13701 net.cpp:406] Convolution23 <- Eltwise9_penlu17_0_split_0
I1013 22:23:59.147583 13701 net.cpp:380] Convolution23 -> Convolution23
I1013 22:23:59.252117 13701 net.cpp:122] Setting up Convolution23
I1013 22:23:59.252140 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.252142 13701 net.cpp:137] Memory required for data: 1677603800
I1013 22:23:59.252147 13701 layer_factory.hpp:77] Creating layer BatchNorm18
I1013 22:23:59.252157 13701 net.cpp:84] Creating Layer BatchNorm18
I1013 22:23:59.252163 13701 net.cpp:406] BatchNorm18 <- Convolution23
I1013 22:23:59.252177 13701 net.cpp:367] BatchNorm18 -> Convolution23 (in-place)
I1013 22:23:59.252401 13701 net.cpp:122] Setting up BatchNorm18
I1013 22:23:59.252408 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.252409 13701 net.cpp:137] Memory required for data: 1683875800
I1013 22:23:59.252414 13701 layer_factory.hpp:77] Creating layer Scale18
I1013 22:23:59.252420 13701 net.cpp:84] Creating Layer Scale18
I1013 22:23:59.252424 13701 net.cpp:406] Scale18 <- Convolution23
I1013 22:23:59.252426 13701 net.cpp:367] Scale18 -> Convolution23 (in-place)
I1013 22:23:59.252496 13701 layer_factory.hpp:77] Creating layer Scale18
I1013 22:23:59.252655 13701 net.cpp:122] Setting up Scale18
I1013 22:23:59.252660 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.252662 13701 net.cpp:137] Memory required for data: 1690147800
I1013 22:23:59.252666 13701 layer_factory.hpp:77] Creating layer penlu18
I1013 22:23:59.252672 13701 net.cpp:84] Creating Layer penlu18
I1013 22:23:59.252676 13701 net.cpp:406] penlu18 <- Convolution23
I1013 22:23:59.252678 13701 net.cpp:367] penlu18 -> Convolution23 (in-place)
I1013 22:23:59.252859 13701 net.cpp:122] Setting up penlu18
I1013 22:23:59.252866 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.252867 13701 net.cpp:137] Memory required for data: 1696419800
I1013 22:23:59.252871 13701 layer_factory.hpp:77] Creating layer Convolution24
I1013 22:23:59.252879 13701 net.cpp:84] Creating Layer Convolution24
I1013 22:23:59.252882 13701 net.cpp:406] Convolution24 <- Convolution23
I1013 22:23:59.252897 13701 net.cpp:380] Convolution24 -> Convolution24
I1013 22:23:59.356922 13701 net.cpp:122] Setting up Convolution24
I1013 22:23:59.356945 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.356950 13701 net.cpp:137] Memory required for data: 1702691800
I1013 22:23:59.356956 13701 layer_factory.hpp:77] Creating layer Eltwise10
I1013 22:23:59.356977 13701 net.cpp:84] Creating Layer Eltwise10
I1013 22:23:59.356983 13701 net.cpp:406] Eltwise10 <- Convolution24
I1013 22:23:59.357003 13701 net.cpp:406] Eltwise10 <- Eltwise9_penlu17_0_split_1
I1013 22:23:59.357008 13701 net.cpp:380] Eltwise10 -> Eltwise10
I1013 22:23:59.357072 13701 net.cpp:122] Setting up Eltwise10
I1013 22:23:59.357087 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.357089 13701 net.cpp:137] Memory required for data: 1708963800
I1013 22:23:59.357106 13701 layer_factory.hpp:77] Creating layer BatchNorm19
I1013 22:23:59.357112 13701 net.cpp:84] Creating Layer BatchNorm19
I1013 22:23:59.357125 13701 net.cpp:406] BatchNorm19 <- Eltwise10
I1013 22:23:59.357127 13701 net.cpp:367] BatchNorm19 -> Eltwise10 (in-place)
I1013 22:23:59.357352 13701 net.cpp:122] Setting up BatchNorm19
I1013 22:23:59.357358 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.357360 13701 net.cpp:137] Memory required for data: 1715235800
I1013 22:23:59.357365 13701 layer_factory.hpp:77] Creating layer Scale19
I1013 22:23:59.357372 13701 net.cpp:84] Creating Layer Scale19
I1013 22:23:59.357373 13701 net.cpp:406] Scale19 <- Eltwise10
I1013 22:23:59.357376 13701 net.cpp:367] Scale19 -> Eltwise10 (in-place)
I1013 22:23:59.357450 13701 layer_factory.hpp:77] Creating layer Scale19
I1013 22:23:59.357611 13701 net.cpp:122] Setting up Scale19
I1013 22:23:59.357616 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.357619 13701 net.cpp:137] Memory required for data: 1721507800
I1013 22:23:59.357622 13701 layer_factory.hpp:77] Creating layer penlu19
I1013 22:23:59.357628 13701 net.cpp:84] Creating Layer penlu19
I1013 22:23:59.357631 13701 net.cpp:406] penlu19 <- Eltwise10
I1013 22:23:59.357635 13701 net.cpp:367] penlu19 -> Eltwise10 (in-place)
I1013 22:23:59.357820 13701 net.cpp:122] Setting up penlu19
I1013 22:23:59.357826 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.357828 13701 net.cpp:137] Memory required for data: 1727779800
I1013 22:23:59.357832 13701 layer_factory.hpp:77] Creating layer Eltwise10_penlu19_0_split
I1013 22:23:59.357836 13701 net.cpp:84] Creating Layer Eltwise10_penlu19_0_split
I1013 22:23:59.357839 13701 net.cpp:406] Eltwise10_penlu19_0_split <- Eltwise10
I1013 22:23:59.357864 13701 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_0
I1013 22:23:59.357880 13701 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_1
I1013 22:23:59.357940 13701 net.cpp:122] Setting up Eltwise10_penlu19_0_split
I1013 22:23:59.357959 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.357961 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.357964 13701 net.cpp:137] Memory required for data: 1740323800
I1013 22:23:59.357965 13701 layer_factory.hpp:77] Creating layer Convolution25
I1013 22:23:59.357972 13701 net.cpp:84] Creating Layer Convolution25
I1013 22:23:59.357975 13701 net.cpp:406] Convolution25 <- Eltwise10_penlu19_0_split_0
I1013 22:23:59.357980 13701 net.cpp:380] Convolution25 -> Convolution25
I1013 22:23:59.462164 13701 net.cpp:122] Setting up Convolution25
I1013 22:23:59.462189 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.462193 13701 net.cpp:137] Memory required for data: 1746595800
I1013 22:23:59.462200 13701 layer_factory.hpp:77] Creating layer BatchNorm20
I1013 22:23:59.462210 13701 net.cpp:84] Creating Layer BatchNorm20
I1013 22:23:59.462225 13701 net.cpp:406] BatchNorm20 <- Convolution25
I1013 22:23:59.462231 13701 net.cpp:367] BatchNorm20 -> Convolution25 (in-place)
I1013 22:23:59.462468 13701 net.cpp:122] Setting up BatchNorm20
I1013 22:23:59.462476 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.462477 13701 net.cpp:137] Memory required for data: 1752867800
I1013 22:23:59.462483 13701 layer_factory.hpp:77] Creating layer Scale20
I1013 22:23:59.462489 13701 net.cpp:84] Creating Layer Scale20
I1013 22:23:59.462492 13701 net.cpp:406] Scale20 <- Convolution25
I1013 22:23:59.462507 13701 net.cpp:367] Scale20 -> Convolution25 (in-place)
I1013 22:23:59.462580 13701 layer_factory.hpp:77] Creating layer Scale20
I1013 22:23:59.462702 13701 net.cpp:122] Setting up Scale20
I1013 22:23:59.462707 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.462709 13701 net.cpp:137] Memory required for data: 1759139800
I1013 22:23:59.462713 13701 layer_factory.hpp:77] Creating layer penlu20
I1013 22:23:59.462720 13701 net.cpp:84] Creating Layer penlu20
I1013 22:23:59.462723 13701 net.cpp:406] penlu20 <- Convolution25
I1013 22:23:59.462736 13701 net.cpp:367] penlu20 -> Convolution25 (in-place)
I1013 22:23:59.462896 13701 net.cpp:122] Setting up penlu20
I1013 22:23:59.462901 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.462903 13701 net.cpp:137] Memory required for data: 1765411800
I1013 22:23:59.462908 13701 layer_factory.hpp:77] Creating layer Convolution26
I1013 22:23:59.462915 13701 net.cpp:84] Creating Layer Convolution26
I1013 22:23:59.462918 13701 net.cpp:406] Convolution26 <- Convolution25
I1013 22:23:59.462932 13701 net.cpp:380] Convolution26 -> Convolution26
I1013 22:23:59.567215 13701 net.cpp:122] Setting up Convolution26
I1013 22:23:59.567239 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.567241 13701 net.cpp:137] Memory required for data: 1771683800
I1013 22:23:59.567248 13701 layer_factory.hpp:77] Creating layer Eltwise11
I1013 22:23:59.567268 13701 net.cpp:84] Creating Layer Eltwise11
I1013 22:23:59.567273 13701 net.cpp:406] Eltwise11 <- Convolution26
I1013 22:23:59.567279 13701 net.cpp:406] Eltwise11 <- Eltwise10_penlu19_0_split_1
I1013 22:23:59.567296 13701 net.cpp:380] Eltwise11 -> Eltwise11
I1013 22:23:59.567351 13701 net.cpp:122] Setting up Eltwise11
I1013 22:23:59.567358 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.567359 13701 net.cpp:137] Memory required for data: 1777955800
I1013 22:23:59.567373 13701 layer_factory.hpp:77] Creating layer BatchNorm21
I1013 22:23:59.567378 13701 net.cpp:84] Creating Layer BatchNorm21
I1013 22:23:59.567390 13701 net.cpp:406] BatchNorm21 <- Eltwise11
I1013 22:23:59.567394 13701 net.cpp:367] BatchNorm21 -> Eltwise11 (in-place)
I1013 22:23:59.567625 13701 net.cpp:122] Setting up BatchNorm21
I1013 22:23:59.567629 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.567643 13701 net.cpp:137] Memory required for data: 1784227800
I1013 22:23:59.567659 13701 layer_factory.hpp:77] Creating layer Scale21
I1013 22:23:59.567665 13701 net.cpp:84] Creating Layer Scale21
I1013 22:23:59.567667 13701 net.cpp:406] Scale21 <- Eltwise11
I1013 22:23:59.567682 13701 net.cpp:367] Scale21 -> Eltwise11 (in-place)
I1013 22:23:59.567746 13701 layer_factory.hpp:77] Creating layer Scale21
I1013 22:23:59.567868 13701 net.cpp:122] Setting up Scale21
I1013 22:23:59.567874 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.567876 13701 net.cpp:137] Memory required for data: 1790499800
I1013 22:23:59.567879 13701 layer_factory.hpp:77] Creating layer penlu21
I1013 22:23:59.567885 13701 net.cpp:84] Creating Layer penlu21
I1013 22:23:59.567888 13701 net.cpp:406] penlu21 <- Eltwise11
I1013 22:23:59.567891 13701 net.cpp:367] penlu21 -> Eltwise11 (in-place)
I1013 22:23:59.568063 13701 net.cpp:122] Setting up penlu21
I1013 22:23:59.568068 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.568070 13701 net.cpp:137] Memory required for data: 1796771800
I1013 22:23:59.568075 13701 layer_factory.hpp:77] Creating layer Eltwise11_penlu21_0_split
I1013 22:23:59.568079 13701 net.cpp:84] Creating Layer Eltwise11_penlu21_0_split
I1013 22:23:59.568081 13701 net.cpp:406] Eltwise11_penlu21_0_split <- Eltwise11
I1013 22:23:59.568089 13701 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_0
I1013 22:23:59.568102 13701 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_1
I1013 22:23:59.568150 13701 net.cpp:122] Setting up Eltwise11_penlu21_0_split
I1013 22:23:59.568156 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.568158 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.568161 13701 net.cpp:137] Memory required for data: 1809315800
I1013 22:23:59.568163 13701 layer_factory.hpp:77] Creating layer Convolution27
I1013 22:23:59.568169 13701 net.cpp:84] Creating Layer Convolution27
I1013 22:23:59.568171 13701 net.cpp:406] Convolution27 <- Eltwise11_penlu21_0_split_0
I1013 22:23:59.568176 13701 net.cpp:380] Convolution27 -> Convolution27
I1013 22:23:59.672487 13701 net.cpp:122] Setting up Convolution27
I1013 22:23:59.672513 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.672515 13701 net.cpp:137] Memory required for data: 1815587800
I1013 22:23:59.672524 13701 layer_factory.hpp:77] Creating layer BatchNorm22
I1013 22:23:59.672533 13701 net.cpp:84] Creating Layer BatchNorm22
I1013 22:23:59.672549 13701 net.cpp:406] BatchNorm22 <- Convolution27
I1013 22:23:59.672556 13701 net.cpp:367] BatchNorm22 -> Convolution27 (in-place)
I1013 22:23:59.672796 13701 net.cpp:122] Setting up BatchNorm22
I1013 22:23:59.672802 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.672804 13701 net.cpp:137] Memory required for data: 1821859800
I1013 22:23:59.672809 13701 layer_factory.hpp:77] Creating layer Scale22
I1013 22:23:59.672816 13701 net.cpp:84] Creating Layer Scale22
I1013 22:23:59.672818 13701 net.cpp:406] Scale22 <- Convolution27
I1013 22:23:59.672832 13701 net.cpp:367] Scale22 -> Convolution27 (in-place)
I1013 22:23:59.672896 13701 layer_factory.hpp:77] Creating layer Scale22
I1013 22:23:59.673061 13701 net.cpp:122] Setting up Scale22
I1013 22:23:59.673068 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.673069 13701 net.cpp:137] Memory required for data: 1828131800
I1013 22:23:59.673074 13701 layer_factory.hpp:77] Creating layer penlu22
I1013 22:23:59.673080 13701 net.cpp:84] Creating Layer penlu22
I1013 22:23:59.673084 13701 net.cpp:406] penlu22 <- Convolution27
I1013 22:23:59.673097 13701 net.cpp:367] penlu22 -> Convolution27 (in-place)
I1013 22:23:59.673270 13701 net.cpp:122] Setting up penlu22
I1013 22:23:59.673276 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.673279 13701 net.cpp:137] Memory required for data: 1834403800
I1013 22:23:59.673283 13701 layer_factory.hpp:77] Creating layer Convolution28
I1013 22:23:59.673290 13701 net.cpp:84] Creating Layer Convolution28
I1013 22:23:59.673315 13701 net.cpp:406] Convolution28 <- Convolution27
I1013 22:23:59.673332 13701 net.cpp:380] Convolution28 -> Convolution28
I1013 22:23:59.777521 13701 net.cpp:122] Setting up Convolution28
I1013 22:23:59.777545 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.777549 13701 net.cpp:137] Memory required for data: 1840675800
I1013 22:23:59.777556 13701 layer_factory.hpp:77] Creating layer Eltwise12
I1013 22:23:59.777577 13701 net.cpp:84] Creating Layer Eltwise12
I1013 22:23:59.777583 13701 net.cpp:406] Eltwise12 <- Convolution28
I1013 22:23:59.777603 13701 net.cpp:406] Eltwise12 <- Eltwise11_penlu21_0_split_1
I1013 22:23:59.777607 13701 net.cpp:380] Eltwise12 -> Eltwise12
I1013 22:23:59.777683 13701 net.cpp:122] Setting up Eltwise12
I1013 22:23:59.777688 13701 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1013 22:23:59.777704 13701 net.cpp:137] Memory required for data: 1846947800
I1013 22:23:59.777706 13701 layer_factory.hpp:77] Creating layer Pooling1
I1013 22:23:59.777712 13701 net.cpp:84] Creating Layer Pooling1
I1013 22:23:59.777725 13701 net.cpp:406] Pooling1 <- Eltwise12
I1013 22:23:59.777741 13701 net.cpp:380] Pooling1 -> Pooling1
I1013 22:23:59.777935 13701 net.cpp:122] Setting up Pooling1
I1013 22:23:59.777943 13701 net.cpp:129] Top shape: 50 640 1 1 (32000)
I1013 22:23:59.777945 13701 net.cpp:137] Memory required for data: 1847075800
I1013 22:23:59.777948 13701 layer_factory.hpp:77] Creating layer InnerProduct1
I1013 22:23:59.777952 13701 net.cpp:84] Creating Layer InnerProduct1
I1013 22:23:59.777956 13701 net.cpp:406] InnerProduct1 <- Pooling1
I1013 22:23:59.777959 13701 net.cpp:380] InnerProduct1 -> InnerProduct1
I1013 22:23:59.778784 13701 net.cpp:122] Setting up InnerProduct1
I1013 22:23:59.778794 13701 net.cpp:129] Top shape: 50 100 (5000)
I1013 22:23:59.778795 13701 net.cpp:137] Memory required for data: 1847095800
I1013 22:23:59.778800 13701 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1013 22:23:59.778805 13701 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1013 22:23:59.778808 13701 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1013 22:23:59.778823 13701 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1013 22:23:59.778831 13701 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1013 22:23:59.778923 13701 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1013 22:23:59.778936 13701 net.cpp:129] Top shape: 50 100 (5000)
I1013 22:23:59.778939 13701 net.cpp:129] Top shape: 50 100 (5000)
I1013 22:23:59.778941 13701 net.cpp:137] Memory required for data: 1847135800
I1013 22:23:59.778944 13701 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1013 22:23:59.778959 13701 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1013 22:23:59.778961 13701 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1013 22:23:59.778964 13701 net.cpp:406] SoftmaxWithLoss1 <- label_cifar_1_split_0
I1013 22:23:59.778978 13701 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1013 22:23:59.778983 13701 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1013 22:23:59.779675 13701 net.cpp:122] Setting up SoftmaxWithLoss1
I1013 22:23:59.779685 13701 net.cpp:129] Top shape: (1)
I1013 22:23:59.779687 13701 net.cpp:132]     with loss weight 1
I1013 22:23:59.779695 13701 net.cpp:137] Memory required for data: 1847135804
I1013 22:23:59.779697 13701 layer_factory.hpp:77] Creating layer accuracy
I1013 22:23:59.779714 13701 net.cpp:84] Creating Layer accuracy
I1013 22:23:59.779719 13701 net.cpp:406] accuracy <- InnerProduct1_InnerProduct1_0_split_1
I1013 22:23:59.779722 13701 net.cpp:406] accuracy <- label_cifar_1_split_1
I1013 22:23:59.779737 13701 net.cpp:380] accuracy -> accuracy
I1013 22:23:59.779744 13701 net.cpp:122] Setting up accuracy
I1013 22:23:59.779748 13701 net.cpp:129] Top shape: (1)
I1013 22:23:59.779750 13701 net.cpp:137] Memory required for data: 1847135808
I1013 22:23:59.779752 13701 net.cpp:200] accuracy does not need backward computation.
I1013 22:23:59.779785 13701 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1013 22:23:59.779790 13701 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1013 22:23:59.779793 13701 net.cpp:198] InnerProduct1 needs backward computation.
I1013 22:23:59.779804 13701 net.cpp:198] Pooling1 needs backward computation.
I1013 22:23:59.779806 13701 net.cpp:198] Eltwise12 needs backward computation.
I1013 22:23:59.779809 13701 net.cpp:198] Convolution28 needs backward computation.
I1013 22:23:59.779822 13701 net.cpp:198] penlu22 needs backward computation.
I1013 22:23:59.779825 13701 net.cpp:198] Scale22 needs backward computation.
I1013 22:23:59.779829 13701 net.cpp:198] BatchNorm22 needs backward computation.
I1013 22:23:59.779830 13701 net.cpp:198] Convolution27 needs backward computation.
I1013 22:23:59.779834 13701 net.cpp:198] Eltwise11_penlu21_0_split needs backward computation.
I1013 22:23:59.779835 13701 net.cpp:198] penlu21 needs backward computation.
I1013 22:23:59.779839 13701 net.cpp:198] Scale21 needs backward computation.
I1013 22:23:59.779840 13701 net.cpp:198] BatchNorm21 needs backward computation.
I1013 22:23:59.779842 13701 net.cpp:198] Eltwise11 needs backward computation.
I1013 22:23:59.779845 13701 net.cpp:198] Convolution26 needs backward computation.
I1013 22:23:59.779848 13701 net.cpp:198] penlu20 needs backward computation.
I1013 22:23:59.779851 13701 net.cpp:198] Scale20 needs backward computation.
I1013 22:23:59.779853 13701 net.cpp:198] BatchNorm20 needs backward computation.
I1013 22:23:59.779856 13701 net.cpp:198] Convolution25 needs backward computation.
I1013 22:23:59.779858 13701 net.cpp:198] Eltwise10_penlu19_0_split needs backward computation.
I1013 22:23:59.779861 13701 net.cpp:198] penlu19 needs backward computation.
I1013 22:23:59.779865 13701 net.cpp:198] Scale19 needs backward computation.
I1013 22:23:59.779866 13701 net.cpp:198] BatchNorm19 needs backward computation.
I1013 22:23:59.779868 13701 net.cpp:198] Eltwise10 needs backward computation.
I1013 22:23:59.779871 13701 net.cpp:198] Convolution24 needs backward computation.
I1013 22:23:59.779875 13701 net.cpp:198] penlu18 needs backward computation.
I1013 22:23:59.779877 13701 net.cpp:198] Scale18 needs backward computation.
I1013 22:23:59.779880 13701 net.cpp:198] BatchNorm18 needs backward computation.
I1013 22:23:59.779881 13701 net.cpp:198] Convolution23 needs backward computation.
I1013 22:23:59.779893 13701 net.cpp:198] Eltwise9_penlu17_0_split needs backward computation.
I1013 22:23:59.779897 13701 net.cpp:198] penlu17 needs backward computation.
I1013 22:23:59.779899 13701 net.cpp:198] Scale17 needs backward computation.
I1013 22:23:59.779902 13701 net.cpp:198] BatchNorm17 needs backward computation.
I1013 22:23:59.779906 13701 net.cpp:198] Eltwise9 needs backward computation.
I1013 22:23:59.779908 13701 net.cpp:198] Convolution22 needs backward computation.
I1013 22:23:59.779911 13701 net.cpp:198] Convolution21 needs backward computation.
I1013 22:23:59.779914 13701 net.cpp:198] penlu16 needs backward computation.
I1013 22:23:59.779917 13701 net.cpp:198] Scale16 needs backward computation.
I1013 22:23:59.779918 13701 net.cpp:198] BatchNorm16 needs backward computation.
I1013 22:23:59.779920 13701 net.cpp:198] Convolution20 needs backward computation.
I1013 22:23:59.779924 13701 net.cpp:198] Eltwise8_Eltwise8_0_split needs backward computation.
I1013 22:23:59.779927 13701 net.cpp:198] Eltwise8 needs backward computation.
I1013 22:23:59.779932 13701 net.cpp:198] Convolution19 needs backward computation.
I1013 22:23:59.779934 13701 net.cpp:198] penlu15 needs backward computation.
I1013 22:23:59.779937 13701 net.cpp:198] Scale15 needs backward computation.
I1013 22:23:59.779939 13701 net.cpp:198] BatchNorm15 needs backward computation.
I1013 22:23:59.779942 13701 net.cpp:198] Convolution18 needs backward computation.
I1013 22:23:59.779944 13701 net.cpp:198] Eltwise7_penlu14_0_split needs backward computation.
I1013 22:23:59.779947 13701 net.cpp:198] penlu14 needs backward computation.
I1013 22:23:59.779954 13701 net.cpp:198] Scale14 needs backward computation.
I1013 22:23:59.779956 13701 net.cpp:198] BatchNorm14 needs backward computation.
I1013 22:23:59.779958 13701 net.cpp:198] Eltwise7 needs backward computation.
I1013 22:23:59.779961 13701 net.cpp:198] Convolution17 needs backward computation.
I1013 22:23:59.779964 13701 net.cpp:198] penlu13 needs backward computation.
I1013 22:23:59.779968 13701 net.cpp:198] Scale13 needs backward computation.
I1013 22:23:59.779969 13701 net.cpp:198] BatchNorm13 needs backward computation.
I1013 22:23:59.779971 13701 net.cpp:198] Convolution16 needs backward computation.
I1013 22:23:59.779974 13701 net.cpp:198] Eltwise6_penlu12_0_split needs backward computation.
I1013 22:23:59.779978 13701 net.cpp:198] penlu12 needs backward computation.
I1013 22:23:59.779980 13701 net.cpp:198] Scale12 needs backward computation.
I1013 22:23:59.779983 13701 net.cpp:198] BatchNorm12 needs backward computation.
I1013 22:23:59.779985 13701 net.cpp:198] Eltwise6 needs backward computation.
I1013 22:23:59.779989 13701 net.cpp:198] Convolution15 needs backward computation.
I1013 22:23:59.779990 13701 net.cpp:198] penlu11 needs backward computation.
I1013 22:23:59.779994 13701 net.cpp:198] Scale11 needs backward computation.
I1013 22:23:59.779995 13701 net.cpp:198] BatchNorm11 needs backward computation.
I1013 22:23:59.779997 13701 net.cpp:198] Convolution14 needs backward computation.
I1013 22:23:59.780000 13701 net.cpp:198] Eltwise5_penlu10_0_split needs backward computation.
I1013 22:23:59.780004 13701 net.cpp:198] penlu10 needs backward computation.
I1013 22:23:59.780006 13701 net.cpp:198] Scale10 needs backward computation.
I1013 22:23:59.780009 13701 net.cpp:198] BatchNorm10 needs backward computation.
I1013 22:23:59.780010 13701 net.cpp:198] Eltwise5 needs backward computation.
I1013 22:23:59.780014 13701 net.cpp:198] Convolution13 needs backward computation.
I1013 22:23:59.780016 13701 net.cpp:198] Convolution12 needs backward computation.
I1013 22:23:59.780019 13701 net.cpp:198] penlu9 needs backward computation.
I1013 22:23:59.780021 13701 net.cpp:198] Scale9 needs backward computation.
I1013 22:23:59.780023 13701 net.cpp:198] BatchNorm9 needs backward computation.
I1013 22:23:59.780025 13701 net.cpp:198] Convolution11 needs backward computation.
I1013 22:23:59.780030 13701 net.cpp:198] Eltwise4_Eltwise4_0_split needs backward computation.
I1013 22:23:59.780032 13701 net.cpp:198] Eltwise4 needs backward computation.
I1013 22:23:59.780035 13701 net.cpp:198] Convolution10 needs backward computation.
I1013 22:23:59.780038 13701 net.cpp:198] penlu8 needs backward computation.
I1013 22:23:59.780042 13701 net.cpp:198] Scale8 needs backward computation.
I1013 22:23:59.780045 13701 net.cpp:198] BatchNorm8 needs backward computation.
I1013 22:23:59.780046 13701 net.cpp:198] Convolution9 needs backward computation.
I1013 22:23:59.780050 13701 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1013 22:23:59.780052 13701 net.cpp:198] penlu7 needs backward computation.
I1013 22:23:59.780055 13701 net.cpp:198] Scale7 needs backward computation.
I1013 22:23:59.780057 13701 net.cpp:198] BatchNorm7 needs backward computation.
I1013 22:23:59.780059 13701 net.cpp:198] Eltwise3 needs backward computation.
I1013 22:23:59.780062 13701 net.cpp:198] Convolution8 needs backward computation.
I1013 22:23:59.780066 13701 net.cpp:198] penlu6 needs backward computation.
I1013 22:23:59.780067 13701 net.cpp:198] Scale6 needs backward computation.
I1013 22:23:59.780069 13701 net.cpp:198] BatchNorm6 needs backward computation.
I1013 22:23:59.780072 13701 net.cpp:198] Convolution7 needs backward computation.
I1013 22:23:59.780074 13701 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1013 22:23:59.780078 13701 net.cpp:198] penlu5 needs backward computation.
I1013 22:23:59.780081 13701 net.cpp:198] Scale5 needs backward computation.
I1013 22:23:59.780082 13701 net.cpp:198] BatchNorm5 needs backward computation.
I1013 22:23:59.780089 13701 net.cpp:198] Eltwise2 needs backward computation.
I1013 22:23:59.780092 13701 net.cpp:198] Convolution6 needs backward computation.
I1013 22:23:59.780094 13701 net.cpp:198] penlu4 needs backward computation.
I1013 22:23:59.780098 13701 net.cpp:198] Scale4 needs backward computation.
I1013 22:23:59.780102 13701 net.cpp:198] BatchNorm4 needs backward computation.
I1013 22:23:59.780103 13701 net.cpp:198] Convolution5 needs backward computation.
I1013 22:23:59.780107 13701 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1013 22:23:59.780109 13701 net.cpp:198] penlu3 needs backward computation.
I1013 22:23:59.780112 13701 net.cpp:198] Scale3 needs backward computation.
I1013 22:23:59.780113 13701 net.cpp:198] BatchNorm3 needs backward computation.
I1013 22:23:59.780117 13701 net.cpp:198] Eltwise1 needs backward computation.
I1013 22:23:59.780119 13701 net.cpp:198] Convolution4 needs backward computation.
I1013 22:23:59.780122 13701 net.cpp:198] Convolution3 needs backward computation.
I1013 22:23:59.780125 13701 net.cpp:198] penlu2 needs backward computation.
I1013 22:23:59.780128 13701 net.cpp:198] Scale2 needs backward computation.
I1013 22:23:59.780130 13701 net.cpp:198] BatchNorm2 needs backward computation.
I1013 22:23:59.780133 13701 net.cpp:198] Convolution2 needs backward computation.
I1013 22:23:59.780135 13701 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1013 22:23:59.780138 13701 net.cpp:198] penlu1 needs backward computation.
I1013 22:23:59.780140 13701 net.cpp:198] Scale1 needs backward computation.
I1013 22:23:59.780143 13701 net.cpp:198] BatchNorm1 needs backward computation.
I1013 22:23:59.780145 13701 net.cpp:198] Convolution1 needs backward computation.
I1013 22:23:59.780148 13701 net.cpp:200] label_cifar_1_split does not need backward computation.
I1013 22:23:59.780153 13701 net.cpp:200] cifar does not need backward computation.
I1013 22:23:59.780154 13701 net.cpp:242] This network produces output SoftmaxWithLoss1
I1013 22:23:59.780158 13701 net.cpp:242] This network produces output accuracy
I1013 22:23:59.780203 13701 net.cpp:255] Network initialization done.
I1013 22:23:59.780547 13701 solver.cpp:56] Solver scaffolding done.
I1013 22:23:59.786845 13701 caffe.cpp:248] Starting Optimization
I1013 22:23:59.786851 13701 solver.cpp:272] Solving wrn_28_10
I1013 22:23:59.786854 13701 solver.cpp:273] Learning Rate Policy: multistep
I1013 22:24:00.146342 13701 solver.cpp:218] Iteration 0 (-9.16316e-32 iter/s, 0.359456s/100 iters), loss = 4.60517
I1013 22:24:00.146373 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 4.60517 (* 1 = 4.60517 loss)
I1013 22:24:00.146399 13701 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1013 22:24:30.554860 13701 solver.cpp:218] Iteration 100 (3.28855 iter/s, 30.4085s/100 iters), loss = 3.61366
I1013 22:24:30.554930 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.61366 (* 1 = 3.61366 loss)
I1013 22:24:30.554937 13701 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1013 22:25:01.211330 13701 solver.cpp:218] Iteration 200 (3.26196 iter/s, 30.6564s/100 iters), loss = 3.62142
I1013 22:25:01.211470 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.62142 (* 1 = 3.62142 loss)
I1013 22:25:01.211477 13701 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1013 22:25:31.772202 13701 solver.cpp:218] Iteration 300 (3.27217 iter/s, 30.5607s/100 iters), loss = 3.52088
I1013 22:25:31.772349 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.52088 (* 1 = 3.52088 loss)
I1013 22:25:31.772368 13701 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1013 22:26:02.356484 13701 solver.cpp:218] Iteration 400 (3.26967 iter/s, 30.5841s/100 iters), loss = 3.44983
I1013 22:26:02.356586 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.44983 (* 1 = 3.44983 loss)
I1013 22:26:02.356593 13701 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1013 22:26:32.644163 13701 solver.cpp:330] Iteration 500, Testing net (#0)
I1013 22:26:49.324177 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:26:49.663678 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 3.2669 (* 1 = 3.2669 loss)
I1013 22:26:49.663693 13701 solver.cpp:397]     Test net output #1: accuracy = 0.1922
I1013 22:26:49.962545 13701 solver.cpp:218] Iteration 500 (2.10058 iter/s, 47.606s/100 iters), loss = 3.14631
I1013 22:26:49.962574 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.14631 (* 1 = 3.14631 loss)
I1013 22:26:49.962581 13701 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1013 22:27:20.602639 13701 solver.cpp:218] Iteration 600 (3.2637 iter/s, 30.6401s/100 iters), loss = 3.18931
I1013 22:27:20.602735 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.18931 (* 1 = 3.18931 loss)
I1013 22:27:20.602742 13701 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1013 22:27:51.222976 13701 solver.cpp:218] Iteration 700 (3.26581 iter/s, 30.6202s/100 iters), loss = 2.87523
I1013 22:27:51.223115 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.87523 (* 1 = 2.87523 loss)
I1013 22:27:51.223124 13701 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1013 22:28:21.823519 13701 solver.cpp:218] Iteration 800 (3.26793 iter/s, 30.6004s/100 iters), loss = 2.65445
I1013 22:28:21.823627 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.65445 (* 1 = 2.65445 loss)
I1013 22:28:21.823643 13701 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1013 22:28:52.474695 13701 solver.cpp:218] Iteration 900 (3.26253 iter/s, 30.6511s/100 iters), loss = 2.60735
I1013 22:28:52.474792 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.60735 (* 1 = 2.60735 loss)
I1013 22:28:52.474797 13701 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1013 22:29:21.523126 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:29:22.740123 13701 solver.cpp:330] Iteration 1000, Testing net (#0)
I1013 22:29:39.377079 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:29:39.717155 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.8105 (* 1 = 2.8105 loss)
I1013 22:29:39.717171 13701 solver.cpp:397]     Test net output #1: accuracy = 0.2833
I1013 22:29:40.017886 13701 solver.cpp:218] Iteration 1000 (2.10335 iter/s, 47.5431s/100 iters), loss = 2.64676
I1013 22:29:40.017917 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.64676 (* 1 = 2.64676 loss)
I1013 22:29:40.017925 13701 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1013 22:30:10.616639 13701 solver.cpp:218] Iteration 1100 (3.26811 iter/s, 30.5987s/100 iters), loss = 2.73839
I1013 22:30:10.616775 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.73839 (* 1 = 2.73839 loss)
I1013 22:30:10.616782 13701 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1013 22:30:41.203975 13701 solver.cpp:218] Iteration 1200 (3.26934 iter/s, 30.5872s/100 iters), loss = 2.74753
I1013 22:30:41.204110 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.74753 (* 1 = 2.74753 loss)
I1013 22:30:41.204116 13701 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1013 22:31:11.818716 13701 solver.cpp:218] Iteration 1300 (3.26641 iter/s, 30.6146s/100 iters), loss = 2.77137
I1013 22:31:11.818830 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.77137 (* 1 = 2.77137 loss)
I1013 22:31:11.818837 13701 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1013 22:31:42.405786 13701 solver.cpp:218] Iteration 1400 (3.26937 iter/s, 30.587s/100 iters), loss = 2.41484
I1013 22:31:42.405864 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.41484 (* 1 = 2.41484 loss)
I1013 22:31:42.405882 13701 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1013 22:32:12.697345 13701 solver.cpp:330] Iteration 1500, Testing net (#0)
I1013 22:32:29.361678 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:32:29.702323 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.55095 (* 1 = 2.55095 loss)
I1013 22:32:29.702339 13701 solver.cpp:397]     Test net output #1: accuracy = 0.3406
I1013 22:32:30.005058 13701 solver.cpp:218] Iteration 1500 (2.10088 iter/s, 47.5992s/100 iters), loss = 2.23128
I1013 22:32:30.005086 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.23128 (* 1 = 2.23128 loss)
I1013 22:32:30.005093 13701 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1013 22:33:00.617230 13701 solver.cpp:218] Iteration 1600 (3.26668 iter/s, 30.6122s/100 iters), loss = 2.56036
I1013 22:33:00.617358 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.56036 (* 1 = 2.56036 loss)
I1013 22:33:00.617365 13701 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1013 22:33:31.212182 13701 solver.cpp:218] Iteration 1700 (3.26853 iter/s, 30.5948s/100 iters), loss = 2.39087
I1013 22:33:31.212291 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.39087 (* 1 = 2.39087 loss)
I1013 22:33:31.212306 13701 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1013 22:34:01.817867 13701 solver.cpp:218] Iteration 1800 (3.26738 iter/s, 30.6056s/100 iters), loss = 2.06103
I1013 22:34:01.817965 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.06103 (* 1 = 2.06103 loss)
I1013 22:34:01.817983 13701 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1013 22:34:32.419083 13701 solver.cpp:218] Iteration 1900 (3.26785 iter/s, 30.6011s/100 iters), loss = 2.21548
I1013 22:34:32.419174 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.21548 (* 1 = 2.21548 loss)
I1013 22:34:32.419190 13701 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1013 22:35:01.503965 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:35:02.720319 13701 solver.cpp:330] Iteration 2000, Testing net (#0)
I1013 22:35:19.358184 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:35:19.699650 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.31944 (* 1 = 2.31944 loss)
I1013 22:35:19.699666 13701 solver.cpp:397]     Test net output #1: accuracy = 0.3847
I1013 22:35:20.002137 13701 solver.cpp:218] Iteration 2000 (2.10159 iter/s, 47.583s/100 iters), loss = 2.06728
I1013 22:35:20.002169 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.06728 (* 1 = 2.06728 loss)
I1013 22:35:20.002176 13701 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1013 22:35:50.576798 13701 solver.cpp:218] Iteration 2100 (3.27068 iter/s, 30.5746s/100 iters), loss = 2.43621
I1013 22:35:50.576925 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.43621 (* 1 = 2.43621 loss)
I1013 22:35:50.576933 13701 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1013 22:36:21.174196 13701 solver.cpp:218] Iteration 2200 (3.26826 iter/s, 30.5973s/100 iters), loss = 2.22215
I1013 22:36:21.174302 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.22215 (* 1 = 2.22215 loss)
I1013 22:36:21.174309 13701 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1013 22:36:51.773385 13701 solver.cpp:218] Iteration 2300 (3.26807 iter/s, 30.5991s/100 iters), loss = 2.29055
I1013 22:36:51.774091 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.29055 (* 1 = 2.29055 loss)
I1013 22:36:51.774101 13701 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1013 22:37:22.329094 13701 solver.cpp:218] Iteration 2400 (3.27279 iter/s, 30.555s/100 iters), loss = 2.06568
I1013 22:37:22.329233 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.06568 (* 1 = 2.06568 loss)
I1013 22:37:22.329241 13701 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1013 22:37:52.654021 13701 solver.cpp:330] Iteration 2500, Testing net (#0)
I1013 22:38:09.279304 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:38:09.619331 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.16782 (* 1 = 2.16782 loss)
I1013 22:38:09.619349 13701 solver.cpp:397]     Test net output #1: accuracy = 0.4239
I1013 22:38:09.920248 13701 solver.cpp:218] Iteration 2500 (2.10124 iter/s, 47.591s/100 iters), loss = 1.72522
I1013 22:38:09.920282 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.72522 (* 1 = 1.72522 loss)
I1013 22:38:09.920290 13701 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1013 22:38:40.570457 13701 solver.cpp:218] Iteration 2600 (3.26262 iter/s, 30.6502s/100 iters), loss = 2.11982
I1013 22:38:40.570588 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.11982 (* 1 = 2.11982 loss)
I1013 22:38:40.570595 13701 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1013 22:39:11.181361 13701 solver.cpp:218] Iteration 2700 (3.26682 iter/s, 30.6108s/100 iters), loss = 1.90219
I1013 22:39:11.181506 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.90219 (* 1 = 1.90219 loss)
I1013 22:39:11.181514 13701 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1013 22:39:41.806046 13701 solver.cpp:218] Iteration 2800 (3.26535 iter/s, 30.6245s/100 iters), loss = 1.74358
I1013 22:39:41.806160 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.74358 (* 1 = 1.74358 loss)
I1013 22:39:41.806179 13701 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1013 22:40:12.412664 13701 solver.cpp:218] Iteration 2900 (3.26728 iter/s, 30.6065s/100 iters), loss = 1.91462
I1013 22:40:12.412804 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.91462 (* 1 = 1.91462 loss)
I1013 22:40:12.412812 13701 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1013 22:40:41.509366 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:40:42.736485 13701 solver.cpp:330] Iteration 3000, Testing net (#0)
I1013 22:40:59.400034 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:40:59.740662 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.02641 (* 1 = 2.02641 loss)
I1013 22:40:59.740679 13701 solver.cpp:397]     Test net output #1: accuracy = 0.4554
I1013 22:41:00.041313 13701 solver.cpp:218] Iteration 3000 (2.09958 iter/s, 47.6285s/100 iters), loss = 1.59355
I1013 22:41:00.041348 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.59355 (* 1 = 1.59355 loss)
I1013 22:41:00.041354 13701 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1013 22:41:30.615605 13701 solver.cpp:218] Iteration 3100 (3.27072 iter/s, 30.5743s/100 iters), loss = 1.99687
I1013 22:41:30.615746 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.99687 (* 1 = 1.99687 loss)
I1013 22:41:30.615756 13701 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1013 22:42:01.268906 13701 solver.cpp:218] Iteration 3200 (3.26231 iter/s, 30.6532s/100 iters), loss = 2.06418
I1013 22:42:01.269004 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.06418 (* 1 = 2.06418 loss)
I1013 22:42:01.269011 13701 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1013 22:42:31.880609 13701 solver.cpp:218] Iteration 3300 (3.26673 iter/s, 30.6116s/100 iters), loss = 2.05114
I1013 22:42:31.880738 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.05114 (* 1 = 2.05114 loss)
I1013 22:42:31.880745 13701 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1013 22:43:02.459527 13701 solver.cpp:218] Iteration 3400 (3.27024 iter/s, 30.5788s/100 iters), loss = 1.95183
I1013 22:43:02.459669 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.95183 (* 1 = 1.95183 loss)
I1013 22:43:02.459677 13701 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1013 22:43:32.774093 13701 solver.cpp:330] Iteration 3500, Testing net (#0)
I1013 22:43:49.431905 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:43:49.773299 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.9263 (* 1 = 1.9263 loss)
I1013 22:43:49.773315 13701 solver.cpp:397]     Test net output #1: accuracy = 0.4719
I1013 22:43:50.075217 13701 solver.cpp:218] Iteration 3500 (2.10015 iter/s, 47.6156s/100 iters), loss = 1.56756
I1013 22:43:50.075244 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.56756 (* 1 = 1.56756 loss)
I1013 22:43:50.075251 13701 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1013 22:44:20.681529 13701 solver.cpp:218] Iteration 3600 (3.2673 iter/s, 30.6063s/100 iters), loss = 1.69061
I1013 22:44:20.681707 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.69061 (* 1 = 1.69061 loss)
I1013 22:44:20.681726 13701 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1013 22:44:51.264166 13701 solver.cpp:218] Iteration 3700 (3.26985 iter/s, 30.5825s/100 iters), loss = 1.69472
I1013 22:44:51.264299 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.69472 (* 1 = 1.69472 loss)
I1013 22:44:51.264307 13701 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1013 22:45:21.865989 13701 solver.cpp:218] Iteration 3800 (3.26779 iter/s, 30.6017s/100 iters), loss = 1.4198
I1013 22:45:21.866101 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.4198 (* 1 = 1.4198 loss)
I1013 22:45:21.866107 13701 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1013 22:45:52.462296 13701 solver.cpp:218] Iteration 3900 (3.26838 iter/s, 30.5962s/100 iters), loss = 1.85082
I1013 22:45:52.462373 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.85082 (* 1 = 1.85082 loss)
I1013 22:45:52.462389 13701 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1013 22:46:21.625910 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:46:22.853510 13701 solver.cpp:330] Iteration 4000, Testing net (#0)
I1013 22:46:39.509227 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:46:39.848618 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.84396 (* 1 = 1.84396 loss)
I1013 22:46:39.848634 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5002
I1013 22:46:40.149790 13701 solver.cpp:218] Iteration 4000 (2.09699 iter/s, 47.6874s/100 iters), loss = 1.35954
I1013 22:46:40.149817 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.35954 (* 1 = 1.35954 loss)
I1013 22:46:40.149823 13701 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1013 22:47:10.825884 13701 solver.cpp:218] Iteration 4100 (3.25987 iter/s, 30.6761s/100 iters), loss = 1.62302
I1013 22:47:10.826026 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.62302 (* 1 = 1.62302 loss)
I1013 22:47:10.826033 13701 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1013 22:47:41.427783 13701 solver.cpp:218] Iteration 4200 (3.26779 iter/s, 30.6018s/100 iters), loss = 1.85235
I1013 22:47:41.427920 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.85235 (* 1 = 1.85235 loss)
I1013 22:47:41.427927 13701 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1013 22:48:12.075961 13701 solver.cpp:218] Iteration 4300 (3.26285 iter/s, 30.648s/100 iters), loss = 1.81108
I1013 22:48:12.076074 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.81108 (* 1 = 1.81108 loss)
I1013 22:48:12.076082 13701 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1013 22:48:42.717458 13701 solver.cpp:218] Iteration 4400 (3.26356 iter/s, 30.6414s/100 iters), loss = 1.76871
I1013 22:48:42.717602 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.76871 (* 1 = 1.76871 loss)
I1013 22:48:42.717612 13701 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1013 22:49:13.029449 13701 solver.cpp:330] Iteration 4500, Testing net (#0)
I1013 22:49:29.714143 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:49:30.054841 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.78374 (* 1 = 1.78374 loss)
I1013 22:49:30.054857 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5135
I1013 22:49:30.356328 13701 solver.cpp:218] Iteration 4500 (2.09913 iter/s, 47.6387s/100 iters), loss = 1.29021
I1013 22:49:30.356360 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.29021 (* 1 = 1.29021 loss)
I1013 22:49:30.356367 13701 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1013 22:50:00.962396 13701 solver.cpp:218] Iteration 4600 (3.26733 iter/s, 30.606s/100 iters), loss = 1.61702
I1013 22:50:00.962512 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.61702 (* 1 = 1.61702 loss)
I1013 22:50:00.962520 13701 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1013 22:50:31.622339 13701 solver.cpp:218] Iteration 4700 (3.2616 iter/s, 30.6598s/100 iters), loss = 1.49931
I1013 22:50:31.622990 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.49931 (* 1 = 1.49931 loss)
I1013 22:50:31.622997 13701 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1013 22:51:02.231530 13701 solver.cpp:218] Iteration 4800 (3.26706 iter/s, 30.6085s/100 iters), loss = 1.2345
I1013 22:51:02.231676 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.2345 (* 1 = 1.2345 loss)
I1013 22:51:02.231685 13701 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1013 22:51:32.860829 13701 solver.cpp:218] Iteration 4900 (3.26486 iter/s, 30.6292s/100 iters), loss = 1.56999
I1013 22:51:32.860939 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.56999 (* 1 = 1.56999 loss)
I1013 22:51:32.860945 13701 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1013 22:52:01.981926 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:52:03.200886 13701 solver.cpp:330] Iteration 5000, Testing net (#0)
I1013 22:52:19.846132 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:52:20.189322 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.70885 (* 1 = 1.70885 loss)
I1013 22:52:20.189337 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5288
I1013 22:52:20.491045 13701 solver.cpp:218] Iteration 5000 (2.09951 iter/s, 47.6301s/100 iters), loss = 1.07324
I1013 22:52:20.491075 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.07324 (* 1 = 1.07324 loss)
I1013 22:52:20.491080 13701 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1013 22:52:51.150020 13701 solver.cpp:218] Iteration 5100 (3.26169 iter/s, 30.659s/100 iters), loss = 1.69104
I1013 22:52:51.150120 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.69104 (* 1 = 1.69104 loss)
I1013 22:52:51.150126 13701 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1013 22:53:21.823974 13701 solver.cpp:218] Iteration 5200 (3.2601 iter/s, 30.6739s/100 iters), loss = 1.65596
I1013 22:53:21.824120 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.65596 (* 1 = 1.65596 loss)
I1013 22:53:21.824128 13701 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1013 22:53:52.495375 13701 solver.cpp:218] Iteration 5300 (3.26038 iter/s, 30.6713s/100 iters), loss = 1.59032
I1013 22:53:52.495497 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.59032 (* 1 = 1.59032 loss)
I1013 22:53:52.495514 13701 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1013 22:54:23.136070 13701 solver.cpp:218] Iteration 5400 (3.26365 iter/s, 30.6406s/100 iters), loss = 1.4928
I1013 22:54:23.136204 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.4928 (* 1 = 1.4928 loss)
I1013 22:54:23.136222 13701 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1013 22:54:53.476439 13701 solver.cpp:330] Iteration 5500, Testing net (#0)
I1013 22:55:10.152415 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:55:10.494205 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.67348 (* 1 = 1.67348 loss)
I1013 22:55:10.494220 13701 solver.cpp:397]     Test net output #1: accuracy = 0.539
I1013 22:55:10.797343 13701 solver.cpp:218] Iteration 5500 (2.09814 iter/s, 47.6612s/100 iters), loss = 1.34703
I1013 22:55:10.797374 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.34703 (* 1 = 1.34703 loss)
I1013 22:55:10.797381 13701 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1013 22:55:41.461987 13701 solver.cpp:218] Iteration 5600 (3.26109 iter/s, 30.6646s/100 iters), loss = 1.53178
I1013 22:55:41.462124 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.53178 (* 1 = 1.53178 loss)
I1013 22:55:41.462131 13701 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1013 22:56:12.101945 13701 solver.cpp:218] Iteration 5700 (3.26373 iter/s, 30.6398s/100 iters), loss = 1.44423
I1013 22:56:12.102061 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.44423 (* 1 = 1.44423 loss)
I1013 22:56:12.102067 13701 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1013 22:56:42.756260 13701 solver.cpp:218] Iteration 5800 (3.26219 iter/s, 30.6542s/100 iters), loss = 1.13656
I1013 22:56:42.756431 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13656 (* 1 = 1.13656 loss)
I1013 22:56:42.756453 13701 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1013 22:57:13.365932 13701 solver.cpp:218] Iteration 5900 (3.26696 iter/s, 30.6095s/100 iters), loss = 1.54298
I1013 22:57:13.366057 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.54298 (* 1 = 1.54298 loss)
I1013 22:57:13.366065 13701 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1013 22:57:42.498994 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:57:43.732245 13701 solver.cpp:330] Iteration 6000, Testing net (#0)
I1013 22:58:00.357868 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 22:58:00.697631 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60312 (* 1 = 1.60312 loss)
I1013 22:58:00.697648 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5552
I1013 22:58:00.997977 13701 solver.cpp:218] Iteration 6000 (2.09943 iter/s, 47.6319s/100 iters), loss = 1.19505
I1013 22:58:00.998005 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.19505 (* 1 = 1.19505 loss)
I1013 22:58:00.998013 13701 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1013 22:58:31.626521 13701 solver.cpp:218] Iteration 6100 (3.26493 iter/s, 30.6285s/100 iters), loss = 1.39542
I1013 22:58:31.626665 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.39542 (* 1 = 1.39542 loss)
I1013 22:58:31.626674 13701 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1013 22:59:02.235652 13701 solver.cpp:218] Iteration 6200 (3.26701 iter/s, 30.609s/100 iters), loss = 1.44457
I1013 22:59:02.235776 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.44457 (* 1 = 1.44457 loss)
I1013 22:59:02.235785 13701 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1013 22:59:32.824406 13701 solver.cpp:218] Iteration 6300 (3.26919 iter/s, 30.5886s/100 iters), loss = 1.43844
I1013 22:59:32.824554 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.43844 (* 1 = 1.43844 loss)
I1013 22:59:32.824574 13701 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1013 23:00:03.453716 13701 solver.cpp:218] Iteration 6400 (3.26486 iter/s, 30.6292s/100 iters), loss = 1.21982
I1013 23:00:03.453853 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.21982 (* 1 = 1.21982 loss)
I1013 23:00:03.453861 13701 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1013 23:00:33.753566 13701 solver.cpp:330] Iteration 6500, Testing net (#0)
I1013 23:00:50.438968 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:00:50.780166 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62032 (* 1 = 1.62032 loss)
I1013 23:00:50.780182 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5514
I1013 23:00:51.081126 13701 solver.cpp:218] Iteration 6500 (2.09964 iter/s, 47.6273s/100 iters), loss = 1.16831
I1013 23:00:51.081156 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16831 (* 1 = 1.16831 loss)
I1013 23:00:51.081162 13701 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1013 23:01:21.672349 13701 solver.cpp:218] Iteration 6600 (3.26891 iter/s, 30.5912s/100 iters), loss = 1.42652
I1013 23:01:21.672483 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.42652 (* 1 = 1.42652 loss)
I1013 23:01:21.672492 13701 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1013 23:01:52.301362 13701 solver.cpp:218] Iteration 6700 (3.26489 iter/s, 30.6289s/100 iters), loss = 1.10846
I1013 23:01:52.301503 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10846 (* 1 = 1.10846 loss)
I1013 23:01:52.301522 13701 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1013 23:02:22.888387 13701 solver.cpp:218] Iteration 6800 (3.26937 iter/s, 30.5869s/100 iters), loss = 0.979244
I1013 23:02:22.888527 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.979244 (* 1 = 0.979244 loss)
I1013 23:02:22.888535 13701 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1013 23:02:53.481355 13701 solver.cpp:218] Iteration 6900 (3.26874 iter/s, 30.5928s/100 iters), loss = 1.30906
I1013 23:02:53.481519 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.30906 (* 1 = 1.30906 loss)
I1013 23:02:53.481528 13701 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1013 23:03:22.554287 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:03:23.771827 13701 solver.cpp:330] Iteration 7000, Testing net (#0)
I1013 23:03:40.407152 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:03:40.746026 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55252 (* 1 = 1.55252 loss)
I1013 23:03:40.746040 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5692
I1013 23:03:41.046118 13701 solver.cpp:218] Iteration 7000 (2.1024 iter/s, 47.5646s/100 iters), loss = 0.781585
I1013 23:03:41.046144 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.781585 (* 1 = 0.781585 loss)
I1013 23:03:41.046150 13701 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1013 23:04:11.639508 13701 solver.cpp:218] Iteration 7100 (3.26868 iter/s, 30.5934s/100 iters), loss = 1.34956
I1013 23:04:11.639652 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.34956 (* 1 = 1.34956 loss)
I1013 23:04:11.639662 13701 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1013 23:04:42.283893 13701 solver.cpp:218] Iteration 7200 (3.26325 iter/s, 30.6443s/100 iters), loss = 1.36133
I1013 23:04:42.283989 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.36133 (* 1 = 1.36133 loss)
I1013 23:04:42.284005 13701 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1013 23:05:12.879068 13701 solver.cpp:218] Iteration 7300 (3.2685 iter/s, 30.5951s/100 iters), loss = 1.21587
I1013 23:05:12.879182 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.21587 (* 1 = 1.21587 loss)
I1013 23:05:12.879191 13701 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1013 23:05:43.490893 13701 solver.cpp:218] Iteration 7400 (3.26672 iter/s, 30.6117s/100 iters), loss = 1.18517
I1013 23:05:43.491024 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.18517 (* 1 = 1.18517 loss)
I1013 23:05:43.491032 13701 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1013 23:06:13.798787 13701 solver.cpp:330] Iteration 7500, Testing net (#0)
I1013 23:06:30.477393 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:06:30.818969 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55873 (* 1 = 1.55873 loss)
I1013 23:06:30.818985 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5689
I1013 23:06:31.122835 13701 solver.cpp:218] Iteration 7500 (2.09944 iter/s, 47.6318s/100 iters), loss = 1.12816
I1013 23:06:31.122864 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12816 (* 1 = 1.12816 loss)
I1013 23:06:31.122871 13701 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1013 23:07:01.739945 13701 solver.cpp:218] Iteration 7600 (3.26615 iter/s, 30.6171s/100 iters), loss = 1.23714
I1013 23:07:01.740087 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.23714 (* 1 = 1.23714 loss)
I1013 23:07:01.740097 13701 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1013 23:07:32.403671 13701 solver.cpp:218] Iteration 7700 (3.2612 iter/s, 30.6636s/100 iters), loss = 1.02458
I1013 23:07:32.403800 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02458 (* 1 = 1.02458 loss)
I1013 23:07:32.403808 13701 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1013 23:08:03.005722 13701 solver.cpp:218] Iteration 7800 (3.26777 iter/s, 30.6019s/100 iters), loss = 0.80716
I1013 23:08:03.005858 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.80716 (* 1 = 0.80716 loss)
I1013 23:08:03.005866 13701 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1013 23:08:33.649991 13701 solver.cpp:218] Iteration 7900 (3.26327 iter/s, 30.6441s/100 iters), loss = 1.15984
I1013 23:08:33.650142 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15984 (* 1 = 1.15984 loss)
I1013 23:08:33.650162 13701 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1013 23:09:02.767869 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:09:03.993953 13701 solver.cpp:330] Iteration 8000, Testing net (#0)
I1013 23:09:20.656496 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:09:20.997633 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.51669 (* 1 = 1.51669 loss)
I1013 23:09:20.997649 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5834
I1013 23:09:21.300348 13701 solver.cpp:218] Iteration 8000 (2.09863 iter/s, 47.6502s/100 iters), loss = 0.708872
I1013 23:09:21.300379 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.708872 (* 1 = 0.708872 loss)
I1013 23:09:21.300386 13701 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1013 23:09:51.916260 13701 solver.cpp:218] Iteration 8100 (3.26628 iter/s, 30.6159s/100 iters), loss = 1.09041
I1013 23:09:51.916373 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09041 (* 1 = 1.09041 loss)
I1013 23:09:51.916380 13701 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1013 23:10:22.543967 13701 solver.cpp:218] Iteration 8200 (3.26503 iter/s, 30.6276s/100 iters), loss = 1.18484
I1013 23:10:22.544104 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.18484 (* 1 = 1.18484 loss)
I1013 23:10:22.544112 13701 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1013 23:10:53.116082 13701 solver.cpp:218] Iteration 8300 (3.27097 iter/s, 30.572s/100 iters), loss = 1.17613
I1013 23:10:53.116209 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17613 (* 1 = 1.17613 loss)
I1013 23:10:53.116216 13701 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1013 23:11:23.752210 13701 solver.cpp:218] Iteration 8400 (3.26413 iter/s, 30.636s/100 iters), loss = 1.00361
I1013 23:11:23.752327 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00361 (* 1 = 1.00361 loss)
I1013 23:11:23.752346 13701 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1013 23:11:54.012359 13701 solver.cpp:330] Iteration 8500, Testing net (#0)
I1013 23:12:10.692430 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:12:11.031790 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50104 (* 1 = 1.50104 loss)
I1013 23:12:11.031803 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5899
I1013 23:12:11.333706 13701 solver.cpp:218] Iteration 8500 (2.10166 iter/s, 47.5814s/100 iters), loss = 1.13006
I1013 23:12:11.333735 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13006 (* 1 = 1.13006 loss)
I1013 23:12:11.333741 13701 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1013 23:12:41.942145 13701 solver.cpp:218] Iteration 8600 (3.26708 iter/s, 30.6084s/100 iters), loss = 1.23755
I1013 23:12:41.942242 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.23755 (* 1 = 1.23755 loss)
I1013 23:12:41.942250 13701 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1013 23:13:12.534693 13701 solver.cpp:218] Iteration 8700 (3.26878 iter/s, 30.5925s/100 iters), loss = 1.06391
I1013 23:13:12.534828 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06391 (* 1 = 1.06391 loss)
I1013 23:13:12.534837 13701 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1013 23:13:43.196147 13701 solver.cpp:218] Iteration 8800 (3.26144 iter/s, 30.6613s/100 iters), loss = 0.673416
I1013 23:13:43.196262 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.673416 (* 1 = 0.673416 loss)
I1013 23:13:43.196269 13701 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1013 23:14:13.813310 13701 solver.cpp:218] Iteration 8900 (3.26615 iter/s, 30.6171s/100 iters), loss = 1.01207
I1013 23:14:13.813421 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01207 (* 1 = 1.01207 loss)
I1013 23:14:13.813429 13701 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1013 23:14:42.910444 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:14:44.146930 13701 solver.cpp:330] Iteration 9000, Testing net (#0)
I1013 23:15:00.810828 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:15:01.154330 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.45536 (* 1 = 1.45536 loss)
I1013 23:15:01.154345 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5975
I1013 23:15:01.457664 13701 solver.cpp:218] Iteration 9000 (2.09889 iter/s, 47.6443s/100 iters), loss = 0.655617
I1013 23:15:01.457693 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.655617 (* 1 = 0.655617 loss)
I1013 23:15:01.457700 13701 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1013 23:15:32.094180 13701 solver.cpp:218] Iteration 9100 (3.26408 iter/s, 30.6365s/100 iters), loss = 1.16754
I1013 23:15:32.094319 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16754 (* 1 = 1.16754 loss)
I1013 23:15:32.094327 13701 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1013 23:16:02.744237 13701 solver.cpp:218] Iteration 9200 (3.26265 iter/s, 30.6499s/100 iters), loss = 0.885993
I1013 23:16:02.744382 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.885993 (* 1 = 0.885993 loss)
I1013 23:16:02.744392 13701 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1013 23:16:33.403452 13701 solver.cpp:218] Iteration 9300 (3.26168 iter/s, 30.6591s/100 iters), loss = 0.809402
I1013 23:16:33.403571 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.809402 (* 1 = 0.809402 loss)
I1013 23:16:33.403578 13701 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1013 23:17:04.053316 13701 solver.cpp:218] Iteration 9400 (3.26267 iter/s, 30.6498s/100 iters), loss = 0.986862
I1013 23:17:04.053413 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.986862 (* 1 = 0.986862 loss)
I1013 23:17:04.053421 13701 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1013 23:17:34.364377 13701 solver.cpp:330] Iteration 9500, Testing net (#0)
I1013 23:17:51.008249 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:17:51.349594 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5145 (* 1 = 1.5145 loss)
I1013 23:17:51.349609 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5937
I1013 23:17:51.651646 13701 solver.cpp:218] Iteration 9500 (2.10092 iter/s, 47.5982s/100 iters), loss = 0.919804
I1013 23:17:51.651681 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.919804 (* 1 = 0.919804 loss)
I1013 23:17:51.651687 13701 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I1013 23:18:22.252307 13701 solver.cpp:218] Iteration 9600 (3.26791 iter/s, 30.6006s/100 iters), loss = 1.16197
I1013 23:18:22.252418 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16197 (* 1 = 1.16197 loss)
I1013 23:18:22.252424 13701 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I1013 23:18:52.874217 13701 solver.cpp:218] Iteration 9700 (3.26565 iter/s, 30.6218s/100 iters), loss = 0.986027
I1013 23:18:52.874351 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.986027 (* 1 = 0.986027 loss)
I1013 23:18:52.874367 13701 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I1013 23:19:23.476238 13701 solver.cpp:218] Iteration 9800 (3.26777 iter/s, 30.6019s/100 iters), loss = 0.692955
I1013 23:19:23.476358 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.692955 (* 1 = 0.692955 loss)
I1013 23:19:23.476366 13701 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I1013 23:19:54.063493 13701 solver.cpp:218] Iteration 9900 (3.26935 iter/s, 30.5871s/100 iters), loss = 0.814308
I1013 23:19:54.063601 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.814308 (* 1 = 0.814308 loss)
I1013 23:19:54.063608 13701 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I1013 23:20:23.164345 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:20:24.392537 13701 solver.cpp:330] Iteration 10000, Testing net (#0)
I1013 23:20:41.042037 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:20:41.381673 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.43566 (* 1 = 1.43566 loss)
I1013 23:20:41.381690 13701 solver.cpp:397]     Test net output #1: accuracy = 0.606
I1013 23:20:41.685326 13701 solver.cpp:218] Iteration 10000 (2.09988 iter/s, 47.6217s/100 iters), loss = 0.796466
I1013 23:20:41.685364 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.796466 (* 1 = 0.796466 loss)
I1013 23:20:41.685371 13701 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I1013 23:21:12.282196 13701 solver.cpp:218] Iteration 10100 (3.26831 iter/s, 30.5968s/100 iters), loss = 1.0816
I1013 23:21:12.282305 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.0816 (* 1 = 1.0816 loss)
I1013 23:21:12.282311 13701 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I1013 23:21:42.870808 13701 solver.cpp:218] Iteration 10200 (3.2692 iter/s, 30.5885s/100 iters), loss = 0.998567
I1013 23:21:42.870913 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.998567 (* 1 = 0.998567 loss)
I1013 23:21:42.870921 13701 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I1013 23:22:13.137315 13701 solver.cpp:218] Iteration 10300 (3.30399 iter/s, 30.2664s/100 iters), loss = 0.710764
I1013 23:22:13.137428 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.710764 (* 1 = 0.710764 loss)
I1013 23:22:13.137434 13701 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I1013 23:22:42.063762 13701 solver.cpp:218] Iteration 10400 (3.45706 iter/s, 28.9263s/100 iters), loss = 0.982453
I1013 23:22:42.063793 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.982453 (* 1 = 0.982453 loss)
I1013 23:22:42.063799 13701 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I1013 23:23:10.727394 13701 solver.cpp:330] Iteration 10500, Testing net (#0)
I1013 23:23:26.580739 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:23:26.906025 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.51922 (* 1 = 1.51922 loss)
I1013 23:23:26.906040 13701 solver.cpp:397]     Test net output #1: accuracy = 0.5949
I1013 23:23:27.190486 13701 solver.cpp:218] Iteration 10500 (2.21598 iter/s, 45.1267s/100 iters), loss = 0.804806
I1013 23:23:27.190512 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.804806 (* 1 = 0.804806 loss)
I1013 23:23:27.190520 13701 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I1013 23:23:56.128084 13701 solver.cpp:218] Iteration 10600 (3.45571 iter/s, 28.9376s/100 iters), loss = 1.13526
I1013 23:23:56.128217 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13526 (* 1 = 1.13526 loss)
I1013 23:23:56.128224 13701 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I1013 23:24:25.197854 13701 solver.cpp:218] Iteration 10700 (3.44001 iter/s, 29.0697s/100 iters), loss = 0.839645
I1013 23:24:25.197892 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.839645 (* 1 = 0.839645 loss)
I1013 23:24:25.197898 13701 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I1013 23:24:54.271828 13701 solver.cpp:218] Iteration 10800 (3.4395 iter/s, 29.074s/100 iters), loss = 0.522314
I1013 23:24:54.271962 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.522314 (* 1 = 0.522314 loss)
I1013 23:24:54.271968 13701 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I1013 23:25:23.347968 13701 solver.cpp:218] Iteration 10900 (3.43926 iter/s, 29.076s/100 iters), loss = 0.856012
I1013 23:25:23.347998 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.856012 (* 1 = 0.856012 loss)
I1013 23:25:23.348004 13701 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I1013 23:25:51.015069 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:25:52.182293 13701 solver.cpp:330] Iteration 11000, Testing net (#0)
I1013 23:26:08.103684 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:26:08.429054 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.43066 (* 1 = 1.43066 loss)
I1013 23:26:08.429069 13701 solver.cpp:397]     Test net output #1: accuracy = 0.611
I1013 23:26:08.716329 13701 solver.cpp:218] Iteration 11000 (2.20418 iter/s, 45.3684s/100 iters), loss = 0.39448
I1013 23:26:08.716380 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39448 (* 1 = 0.39448 loss)
I1013 23:26:08.716397 13701 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I1013 23:26:37.803329 13701 solver.cpp:218] Iteration 11100 (3.43797 iter/s, 29.0869s/100 iters), loss = 0.831696
I1013 23:26:37.803495 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.831696 (* 1 = 0.831696 loss)
I1013 23:26:37.803505 13701 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I1013 23:27:06.904263 13701 solver.cpp:218] Iteration 11200 (3.43633 iter/s, 29.1008s/100 iters), loss = 0.938672
I1013 23:27:06.904295 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.938672 (* 1 = 0.938672 loss)
I1013 23:27:06.904302 13701 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I1013 23:27:35.987191 13701 solver.cpp:218] Iteration 11300 (3.43844 iter/s, 29.0829s/100 iters), loss = 0.930604
I1013 23:27:35.987306 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.930604 (* 1 = 0.930604 loss)
I1013 23:27:35.987313 13701 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I1013 23:28:05.066391 13701 solver.cpp:218] Iteration 11400 (3.43889 iter/s, 29.0791s/100 iters), loss = 0.772332
I1013 23:28:05.066422 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.772332 (* 1 = 0.772332 loss)
I1013 23:28:05.066428 13701 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I1013 23:28:33.872478 13701 solver.cpp:330] Iteration 11500, Testing net (#0)
I1013 23:28:49.795356 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:28:50.120939 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48899 (* 1 = 1.48899 loss)
I1013 23:28:50.120954 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6082
I1013 23:28:50.404212 13701 solver.cpp:218] Iteration 11500 (2.20566 iter/s, 45.3378s/100 iters), loss = 1.00687
I1013 23:28:50.404239 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00687 (* 1 = 1.00687 loss)
I1013 23:28:50.404247 13701 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I1013 23:29:19.494477 13701 solver.cpp:218] Iteration 11600 (3.43758 iter/s, 29.0903s/100 iters), loss = 0.92767
I1013 23:29:19.494590 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.92767 (* 1 = 0.92767 loss)
I1013 23:29:19.494608 13701 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I1013 23:29:48.570308 13701 solver.cpp:218] Iteration 11700 (3.43929 iter/s, 29.0758s/100 iters), loss = 0.676137
I1013 23:29:48.570343 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.676137 (* 1 = 0.676137 loss)
I1013 23:29:48.570350 13701 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I1013 23:30:17.648543 13701 solver.cpp:218] Iteration 11800 (3.439 iter/s, 29.0782s/100 iters), loss = 0.603001
I1013 23:30:17.648694 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603001 (* 1 = 0.603001 loss)
I1013 23:30:17.648705 13701 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I1013 23:30:46.728011 13701 solver.cpp:218] Iteration 11900 (3.43887 iter/s, 29.0794s/100 iters), loss = 0.731212
I1013 23:30:46.728042 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.731212 (* 1 = 0.731212 loss)
I1013 23:30:46.728049 13701 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I1013 23:31:14.385514 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:31:15.549285 13701 solver.cpp:330] Iteration 12000, Testing net (#0)
I1013 23:31:31.472790 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:31:31.798652 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.43468 (* 1 = 1.43468 loss)
I1013 23:31:31.798669 13701 solver.cpp:397]     Test net output #1: accuracy = 0.61
I1013 23:31:32.083621 13701 solver.cpp:218] Iteration 12000 (2.2048 iter/s, 45.3556s/100 iters), loss = 0.50548
I1013 23:31:32.083647 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50548 (* 1 = 0.50548 loss)
I1013 23:31:32.083653 13701 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I1013 23:32:01.186372 13701 solver.cpp:218] Iteration 12100 (3.4361 iter/s, 29.1028s/100 iters), loss = 0.860545
I1013 23:32:01.186513 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.860545 (* 1 = 0.860545 loss)
I1013 23:32:01.186522 13701 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I1013 23:32:30.300182 13701 solver.cpp:218] Iteration 12200 (3.43481 iter/s, 29.1137s/100 iters), loss = 0.959984
I1013 23:32:30.300213 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.959984 (* 1 = 0.959984 loss)
I1013 23:32:30.300218 13701 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I1013 23:32:59.403631 13701 solver.cpp:218] Iteration 12300 (3.43602 iter/s, 29.1035s/100 iters), loss = 0.687468
I1013 23:32:59.403756 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.687468 (* 1 = 0.687468 loss)
I1013 23:32:59.403764 13701 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I1013 23:33:28.506856 13701 solver.cpp:218] Iteration 12400 (3.43606 iter/s, 29.1031s/100 iters), loss = 0.648294
I1013 23:33:28.506887 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.648294 (* 1 = 0.648294 loss)
I1013 23:33:28.506893 13701 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I1013 23:33:57.332576 13701 solver.cpp:330] Iteration 12500, Testing net (#0)
I1013 23:34:13.262910 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:34:13.588373 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.471 (* 1 = 1.471 loss)
I1013 23:34:13.588388 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6114
I1013 23:34:13.872359 13701 solver.cpp:218] Iteration 12500 (2.20432 iter/s, 45.3655s/100 iters), loss = 0.874141
I1013 23:34:13.872391 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.874141 (* 1 = 0.874141 loss)
I1013 23:34:13.872397 13701 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I1013 23:34:42.962036 13701 solver.cpp:218] Iteration 12600 (3.43764 iter/s, 29.0897s/100 iters), loss = 0.81069
I1013 23:34:42.962184 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.81069 (* 1 = 0.81069 loss)
I1013 23:34:42.962196 13701 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I1013 23:35:12.086434 13701 solver.cpp:218] Iteration 12700 (3.43356 iter/s, 29.1243s/100 iters), loss = 0.77818
I1013 23:35:12.086465 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.77818 (* 1 = 0.77818 loss)
I1013 23:35:12.086472 13701 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I1013 23:35:41.238538 13701 solver.cpp:218] Iteration 12800 (3.43028 iter/s, 29.1521s/100 iters), loss = 0.511805
I1013 23:35:41.238634 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511805 (* 1 = 0.511805 loss)
I1013 23:35:41.238652 13701 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I1013 23:36:10.394130 13701 solver.cpp:218] Iteration 12900 (3.42988 iter/s, 29.1556s/100 iters), loss = 0.7172
I1013 23:36:10.394160 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.7172 (* 1 = 0.7172 loss)
I1013 23:36:10.394166 13701 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I1013 23:36:38.105212 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:36:39.272492 13701 solver.cpp:330] Iteration 13000, Testing net (#0)
I1013 23:36:55.187638 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:36:55.512025 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44916 (* 1 = 1.44916 loss)
I1013 23:36:55.512040 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6177
I1013 23:36:55.797566 13701 solver.cpp:218] Iteration 13000 (2.20247 iter/s, 45.4035s/100 iters), loss = 0.691502
I1013 23:36:55.797598 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.691502 (* 1 = 0.691502 loss)
I1013 23:36:55.797605 13701 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I1013 23:37:24.918953 13701 solver.cpp:218] Iteration 13100 (3.4339 iter/s, 29.1214s/100 iters), loss = 0.713208
I1013 23:37:24.919065 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.713208 (* 1 = 0.713208 loss)
I1013 23:37:24.919073 13701 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I1013 23:37:54.042629 13701 solver.cpp:218] Iteration 13200 (3.43364 iter/s, 29.1236s/100 iters), loss = 0.534306
I1013 23:37:54.042660 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534306 (* 1 = 0.534306 loss)
I1013 23:37:54.042667 13701 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I1013 23:38:23.171619 13701 solver.cpp:218] Iteration 13300 (3.433 iter/s, 29.129s/100 iters), loss = 0.768986
I1013 23:38:23.171735 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.768986 (* 1 = 0.768986 loss)
I1013 23:38:23.171742 13701 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I1013 23:38:52.275233 13701 solver.cpp:218] Iteration 13400 (3.43601 iter/s, 29.1035s/100 iters), loss = 0.656889
I1013 23:38:52.275262 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.656889 (* 1 = 0.656889 loss)
I1013 23:38:52.275269 13701 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I1013 23:39:21.108078 13701 solver.cpp:330] Iteration 13500, Testing net (#0)
I1013 23:39:37.026016 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:39:37.352368 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48236 (* 1 = 1.48236 loss)
I1013 23:39:37.352383 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6133
I1013 23:39:37.637049 13701 solver.cpp:218] Iteration 13500 (2.2045 iter/s, 45.3619s/100 iters), loss = 0.866504
I1013 23:39:37.637078 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.866504 (* 1 = 0.866504 loss)
I1013 23:39:37.637084 13701 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I1013 23:40:06.734411 13701 solver.cpp:218] Iteration 13600 (3.43674 iter/s, 29.0974s/100 iters), loss = 0.865599
I1013 23:40:06.734527 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.865599 (* 1 = 0.865599 loss)
I1013 23:40:06.734545 13701 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I1013 23:40:35.818594 13701 solver.cpp:218] Iteration 13700 (3.4383 iter/s, 29.0841s/100 iters), loss = 0.445678
I1013 23:40:35.818624 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445678 (* 1 = 0.445678 loss)
I1013 23:40:35.818629 13701 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I1013 23:41:04.911456 13701 solver.cpp:218] Iteration 13800 (3.43727 iter/s, 29.0929s/100 iters), loss = 0.660383
I1013 23:41:04.911581 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.660383 (* 1 = 0.660383 loss)
I1013 23:41:04.911589 13701 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I1013 23:41:34.006120 13701 solver.cpp:218] Iteration 13900 (3.43707 iter/s, 29.0946s/100 iters), loss = 0.640358
I1013 23:41:34.006152 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.640358 (* 1 = 0.640358 loss)
I1013 23:41:34.006158 13701 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I1013 23:42:01.646661 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:42:02.810791 13701 solver.cpp:330] Iteration 14000, Testing net (#0)
I1013 23:42:18.737637 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:42:19.062939 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.42775 (* 1 = 1.42775 loss)
I1013 23:42:19.062955 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6258
I1013 23:42:19.347056 13701 solver.cpp:218] Iteration 14000 (2.20551 iter/s, 45.341s/100 iters), loss = 0.431152
I1013 23:42:19.347087 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431152 (* 1 = 0.431152 loss)
I1013 23:42:19.347095 13701 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I1013 23:42:48.431576 13701 solver.cpp:218] Iteration 14100 (3.43825 iter/s, 29.0845s/100 iters), loss = 0.753065
I1013 23:42:48.431718 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.753065 (* 1 = 0.753065 loss)
I1013 23:42:48.431727 13701 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I1013 23:43:17.539314 13701 solver.cpp:218] Iteration 14200 (3.43552 iter/s, 29.1076s/100 iters), loss = 0.695072
I1013 23:43:17.539343 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.695072 (* 1 = 0.695072 loss)
I1013 23:43:17.539348 13701 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I1013 23:43:46.654181 13701 solver.cpp:218] Iteration 14300 (3.43467 iter/s, 29.1149s/100 iters), loss = 0.551798
I1013 23:43:46.654366 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.551798 (* 1 = 0.551798 loss)
I1013 23:43:46.654386 13701 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I1013 23:44:15.772713 13701 solver.cpp:218] Iteration 14400 (3.43425 iter/s, 29.1184s/100 iters), loss = 0.41839
I1013 23:44:15.772745 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41839 (* 1 = 0.41839 loss)
I1013 23:44:15.772753 13701 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I1013 23:44:44.619055 13701 solver.cpp:330] Iteration 14500, Testing net (#0)
I1013 23:45:00.542397 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:45:00.868549 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.46363 (* 1 = 1.46363 loss)
I1013 23:45:00.868564 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6236
I1013 23:45:01.152062 13701 solver.cpp:218] Iteration 14500 (2.20364 iter/s, 45.3794s/100 iters), loss = 0.816662
I1013 23:45:01.152091 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.816662 (* 1 = 0.816662 loss)
I1013 23:45:01.152096 13701 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I1013 23:45:30.254093 13701 solver.cpp:218] Iteration 14600 (3.43618 iter/s, 29.102s/100 iters), loss = 0.834114
I1013 23:45:30.254202 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.834114 (* 1 = 0.834114 loss)
I1013 23:45:30.254209 13701 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I1013 23:45:59.342793 13701 solver.cpp:218] Iteration 14700 (3.43777 iter/s, 29.0886s/100 iters), loss = 0.474514
I1013 23:45:59.342823 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474514 (* 1 = 0.474514 loss)
I1013 23:45:59.342828 13701 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I1013 23:46:28.440723 13701 solver.cpp:218] Iteration 14800 (3.43667 iter/s, 29.0979s/100 iters), loss = 0.541106
I1013 23:46:28.440841 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541106 (* 1 = 0.541106 loss)
I1013 23:46:28.440850 13701 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I1013 23:46:57.542120 13701 solver.cpp:218] Iteration 14900 (3.43627 iter/s, 29.1013s/100 iters), loss = 0.666498
I1013 23:46:57.542150 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.666498 (* 1 = 0.666498 loss)
I1013 23:46:57.542155 13701 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I1013 23:47:25.219445 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:47:26.383994 13701 solver.cpp:330] Iteration 15000, Testing net (#0)
I1013 23:47:42.307150 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:47:42.633076 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.47557 (* 1 = 1.47557 loss)
I1013 23:47:42.633091 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6157
I1013 23:47:42.918862 13701 solver.cpp:218] Iteration 15000 (2.20377 iter/s, 45.3768s/100 iters), loss = 0.398199
I1013 23:47:42.918889 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398199 (* 1 = 0.398199 loss)
I1013 23:47:42.918896 13701 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I1013 23:48:12.034157 13701 solver.cpp:218] Iteration 15100 (3.43462 iter/s, 29.1153s/100 iters), loss = 0.718518
I1013 23:48:12.034296 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.718518 (* 1 = 0.718518 loss)
I1013 23:48:12.034306 13701 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I1013 23:48:41.159809 13701 solver.cpp:218] Iteration 15200 (3.43341 iter/s, 29.1256s/100 iters), loss = 0.464707
I1013 23:48:41.159839 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464707 (* 1 = 0.464707 loss)
I1013 23:48:41.159845 13701 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I1013 23:49:10.277534 13701 solver.cpp:218] Iteration 15300 (3.43433 iter/s, 29.1177s/100 iters), loss = 0.697298
I1013 23:49:10.277698 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.697298 (* 1 = 0.697298 loss)
I1013 23:49:10.277709 13701 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I1013 23:49:39.393038 13701 solver.cpp:218] Iteration 15400 (3.43461 iter/s, 29.1154s/100 iters), loss = 0.732744
I1013 23:49:39.393067 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.732744 (* 1 = 0.732744 loss)
I1013 23:49:39.393074 13701 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I1013 23:50:08.235258 13701 solver.cpp:330] Iteration 15500, Testing net (#0)
I1013 23:50:24.152395 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:50:24.478770 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53981 (* 1 = 1.53981 loss)
I1013 23:50:24.478783 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6182
I1013 23:50:24.763777 13701 solver.cpp:218] Iteration 15500 (2.20406 iter/s, 45.3708s/100 iters), loss = 0.807521
I1013 23:50:24.763809 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.807521 (* 1 = 0.807521 loss)
I1013 23:50:24.763815 13701 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I1013 23:50:53.840523 13701 solver.cpp:218] Iteration 15600 (3.43917 iter/s, 29.0768s/100 iters), loss = 0.748983
I1013 23:50:53.840663 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.748983 (* 1 = 0.748983 loss)
I1013 23:50:53.840672 13701 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I1013 23:51:22.914801 13701 solver.cpp:218] Iteration 15700 (3.43948 iter/s, 29.0742s/100 iters), loss = 0.564282
I1013 23:51:22.914830 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.564282 (* 1 = 0.564282 loss)
I1013 23:51:22.914836 13701 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I1013 23:51:52.002394 13701 solver.cpp:218] Iteration 15800 (3.43789 iter/s, 29.0876s/100 iters), loss = 0.230734
I1013 23:51:52.002495 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230734 (* 1 = 0.230734 loss)
I1013 23:51:52.002502 13701 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I1013 23:52:21.105103 13701 solver.cpp:218] Iteration 15900 (3.43611 iter/s, 29.1027s/100 iters), loss = 0.619917
I1013 23:52:21.105132 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.619917 (* 1 = 0.619917 loss)
I1013 23:52:21.105139 13701 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I1013 23:52:48.775228 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:52:49.940543 13701 solver.cpp:330] Iteration 16000, Testing net (#0)
I1013 23:53:05.864854 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:53:06.189402 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44806 (* 1 = 1.44806 loss)
I1013 23:53:06.189416 13701 solver.cpp:397]     Test net output #1: accuracy = 0.632
I1013 23:53:06.473637 13701 solver.cpp:218] Iteration 16000 (2.20417 iter/s, 45.3686s/100 iters), loss = 0.311072
I1013 23:53:06.473665 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311072 (* 1 = 0.311072 loss)
I1013 23:53:06.473672 13701 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I1013 23:53:35.563683 13701 solver.cpp:218] Iteration 16100 (3.4376 iter/s, 29.0901s/100 iters), loss = 0.544009
I1013 23:53:35.563822 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.544009 (* 1 = 0.544009 loss)
I1013 23:53:35.563829 13701 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I1013 23:54:04.664158 13701 solver.cpp:218] Iteration 16200 (3.43638 iter/s, 29.1004s/100 iters), loss = 0.542484
I1013 23:54:04.664192 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.542485 (* 1 = 0.542485 loss)
I1013 23:54:04.664198 13701 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I1013 23:54:33.768817 13701 solver.cpp:218] Iteration 16300 (3.43587 iter/s, 29.1047s/100 iters), loss = 0.634146
I1013 23:54:33.768918 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.634146 (* 1 = 0.634146 loss)
I1013 23:54:33.768925 13701 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I1013 23:55:02.882987 13701 solver.cpp:218] Iteration 16400 (3.43476 iter/s, 29.1141s/100 iters), loss = 0.805709
I1013 23:55:02.883016 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.805709 (* 1 = 0.805709 loss)
I1013 23:55:02.883023 13701 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I1013 23:55:31.719231 13701 solver.cpp:330] Iteration 16500, Testing net (#0)
I1013 23:55:47.641324 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:55:47.967483 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.46934 (* 1 = 1.46934 loss)
I1013 23:55:47.967497 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6307
I1013 23:55:48.252729 13701 solver.cpp:218] Iteration 16500 (2.20411 iter/s, 45.3698s/100 iters), loss = 0.514898
I1013 23:55:48.252766 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.514898 (* 1 = 0.514898 loss)
I1013 23:55:48.252774 13701 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I1013 23:56:17.329942 13701 solver.cpp:218] Iteration 16600 (3.43912 iter/s, 29.0772s/100 iters), loss = 0.563882
I1013 23:56:17.330075 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.563883 (* 1 = 0.563883 loss)
I1013 23:56:17.330080 13701 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I1013 23:56:46.413998 13701 solver.cpp:218] Iteration 16700 (3.43832 iter/s, 29.084s/100 iters), loss = 0.49814
I1013 23:56:46.414029 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498141 (* 1 = 0.498141 loss)
I1013 23:56:46.414036 13701 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I1013 23:57:15.492058 13701 solver.cpp:218] Iteration 16800 (3.43902 iter/s, 29.0781s/100 iters), loss = 0.571928
I1013 23:57:15.492195 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.571928 (* 1 = 0.571928 loss)
I1013 23:57:15.492203 13701 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I1013 23:57:44.582361 13701 solver.cpp:218] Iteration 16900 (3.43758 iter/s, 29.0902s/100 iters), loss = 0.691538
I1013 23:57:44.582393 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.691538 (* 1 = 0.691538 loss)
I1013 23:57:44.582399 13701 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I1013 23:58:12.199892 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:58:13.363231 13701 solver.cpp:330] Iteration 17000, Testing net (#0)
I1013 23:58:29.287253 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1013 23:58:29.613497 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.51227 (* 1 = 1.51227 loss)
I1013 23:58:29.613513 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6183
I1013 23:58:29.898007 13701 solver.cpp:218] Iteration 17000 (2.20674 iter/s, 45.3157s/100 iters), loss = 0.280893
I1013 23:58:29.898036 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280894 (* 1 = 0.280894 loss)
I1013 23:58:29.898043 13701 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I1013 23:58:58.972996 13701 solver.cpp:218] Iteration 17100 (3.43938 iter/s, 29.075s/100 iters), loss = 0.555979
I1013 23:58:58.973134 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.55598 (* 1 = 0.55598 loss)
I1013 23:58:58.973140 13701 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I1013 23:59:28.054563 13701 solver.cpp:218] Iteration 17200 (3.43861 iter/s, 29.0815s/100 iters), loss = 0.399869
I1013 23:59:28.054592 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39987 (* 1 = 0.39987 loss)
I1013 23:59:28.054599 13701 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I1013 23:59:57.159899 13701 solver.cpp:218] Iteration 17300 (3.43579 iter/s, 29.1054s/100 iters), loss = 0.530966
I1013 23:59:57.160038 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.530967 (* 1 = 0.530967 loss)
I1013 23:59:57.160048 13701 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I1014 00:00:26.277513 13701 solver.cpp:218] Iteration 17400 (3.43436 iter/s, 29.1175s/100 iters), loss = 0.367599
I1014 00:00:26.277542 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367599 (* 1 = 0.367599 loss)
I1014 00:00:26.277549 13701 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I1014 00:00:55.102116 13701 solver.cpp:330] Iteration 17500, Testing net (#0)
I1014 00:01:11.020120 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:01:11.345880 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50639 (* 1 = 1.50639 loss)
I1014 00:01:11.345896 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6268
I1014 00:01:11.631095 13701 solver.cpp:218] Iteration 17500 (2.2049 iter/s, 45.3536s/100 iters), loss = 0.502034
I1014 00:01:11.631139 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502035 (* 1 = 0.502035 loss)
I1014 00:01:11.631147 13701 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I1014 00:01:40.709642 13701 solver.cpp:218] Iteration 17600 (3.43896 iter/s, 29.0785s/100 iters), loss = 0.670144
I1014 00:01:40.709782 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.670144 (* 1 = 0.670144 loss)
I1014 00:01:40.709789 13701 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I1014 00:02:09.803804 13701 solver.cpp:218] Iteration 17700 (3.43713 iter/s, 29.0941s/100 iters), loss = 0.396931
I1014 00:02:09.803838 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396932 (* 1 = 0.396932 loss)
I1014 00:02:09.803845 13701 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I1014 00:02:38.878396 13701 solver.cpp:218] Iteration 17800 (3.43943 iter/s, 29.0746s/100 iters), loss = 0.424933
I1014 00:02:38.878464 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424934 (* 1 = 0.424934 loss)
I1014 00:02:38.878471 13701 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I1014 00:03:07.963968 13701 solver.cpp:218] Iteration 17900 (3.43813 iter/s, 29.0856s/100 iters), loss = 0.364483
I1014 00:03:07.963997 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364483 (* 1 = 0.364483 loss)
I1014 00:03:07.964004 13701 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I1014 00:03:35.619276 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:03:36.781908 13701 solver.cpp:330] Iteration 18000, Testing net (#0)
I1014 00:03:52.703459 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:03:53.029352 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.51687 (* 1 = 1.51687 loss)
I1014 00:03:53.029366 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6224
I1014 00:03:53.314165 13701 solver.cpp:218] Iteration 18000 (2.20506 iter/s, 45.3502s/100 iters), loss = 0.277095
I1014 00:03:53.314191 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277095 (* 1 = 0.277095 loss)
I1014 00:03:53.314198 13701 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I1014 00:04:22.403354 13701 solver.cpp:218] Iteration 18100 (3.4377 iter/s, 29.0892s/100 iters), loss = 0.582726
I1014 00:04:22.403496 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.582727 (* 1 = 0.582727 loss)
I1014 00:04:22.403503 13701 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I1014 00:04:51.500294 13701 solver.cpp:218] Iteration 18200 (3.4368 iter/s, 29.0968s/100 iters), loss = 0.522264
I1014 00:04:51.500324 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.522264 (* 1 = 0.522264 loss)
I1014 00:04:51.500329 13701 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I1014 00:05:20.615495 13701 solver.cpp:218] Iteration 18300 (3.43463 iter/s, 29.1152s/100 iters), loss = 0.247966
I1014 00:05:20.615639 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247966 (* 1 = 0.247966 loss)
I1014 00:05:20.615648 13701 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I1014 00:05:49.743716 13701 solver.cpp:218] Iteration 18400 (3.43311 iter/s, 29.1281s/100 iters), loss = 0.349823
I1014 00:05:49.743748 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349824 (* 1 = 0.349824 loss)
I1014 00:05:49.743754 13701 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I1014 00:06:18.573709 13701 solver.cpp:330] Iteration 18500, Testing net (#0)
I1014 00:06:34.493573 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:06:34.819020 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5192 (* 1 = 1.5192 loss)
I1014 00:06:34.819034 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6302
I1014 00:06:35.104418 13701 solver.cpp:218] Iteration 18500 (2.20455 iter/s, 45.3607s/100 iters), loss = 0.474054
I1014 00:06:35.104449 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.474055 (* 1 = 0.474055 loss)
I1014 00:06:35.104456 13701 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I1014 00:07:04.257647 13701 solver.cpp:218] Iteration 18600 (3.43015 iter/s, 29.1532s/100 iters), loss = 0.504885
I1014 00:07:04.257793 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.504885 (* 1 = 0.504885 loss)
I1014 00:07:04.257802 13701 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I1014 00:07:33.414207 13701 solver.cpp:218] Iteration 18700 (3.42977 iter/s, 29.1565s/100 iters), loss = 0.388585
I1014 00:07:33.414237 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388586 (* 1 = 0.388586 loss)
I1014 00:07:33.414243 13701 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I1014 00:08:02.578320 13701 solver.cpp:218] Iteration 18800 (3.42887 iter/s, 29.1641s/100 iters), loss = 0.520002
I1014 00:08:02.578465 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520003 (* 1 = 0.520003 loss)
I1014 00:08:02.578485 13701 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I1014 00:08:31.742439 13701 solver.cpp:218] Iteration 18900 (3.42888 iter/s, 29.164s/100 iters), loss = 0.57968
I1014 00:08:31.742470 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.579681 (* 1 = 0.579681 loss)
I1014 00:08:31.742477 13701 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I1014 00:08:59.432839 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:09:00.599874 13701 solver.cpp:330] Iteration 19000, Testing net (#0)
I1014 00:09:16.521018 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:09:16.847113 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50688 (* 1 = 1.50688 loss)
I1014 00:09:16.847129 13701 solver.cpp:397]     Test net output #1: accuracy = 0.632
I1014 00:09:17.131026 13701 solver.cpp:218] Iteration 19000 (2.2032 iter/s, 45.3886s/100 iters), loss = 0.633158
I1014 00:09:17.131057 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.633159 (* 1 = 0.633159 loss)
I1014 00:09:17.131063 13701 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I1014 00:09:46.259505 13701 solver.cpp:218] Iteration 19100 (3.43306 iter/s, 29.1285s/100 iters), loss = 0.493134
I1014 00:09:46.259654 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.493134 (* 1 = 0.493134 loss)
I1014 00:09:46.259661 13701 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I1014 00:10:15.411123 13701 solver.cpp:218] Iteration 19200 (3.43035 iter/s, 29.1515s/100 iters), loss = 0.365194
I1014 00:10:15.411157 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365194 (* 1 = 0.365194 loss)
I1014 00:10:15.411165 13701 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I1014 00:10:44.566217 13701 solver.cpp:218] Iteration 19300 (3.42993 iter/s, 29.1551s/100 iters), loss = 0.342043
I1014 00:10:44.566315 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342044 (* 1 = 0.342044 loss)
I1014 00:10:44.566323 13701 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I1014 00:11:13.716332 13701 solver.cpp:218] Iteration 19400 (3.43052 iter/s, 29.1501s/100 iters), loss = 0.394098
I1014 00:11:13.716365 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394099 (* 1 = 0.394099 loss)
I1014 00:11:13.716372 13701 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I1014 00:11:42.595037 13701 solver.cpp:330] Iteration 19500, Testing net (#0)
I1014 00:11:58.523135 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:11:58.849285 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.49874 (* 1 = 1.49874 loss)
I1014 00:11:58.849301 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6341
I1014 00:11:59.133559 13701 solver.cpp:218] Iteration 19500 (2.20181 iter/s, 45.4173s/100 iters), loss = 0.609172
I1014 00:11:59.133594 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.609172 (* 1 = 0.609172 loss)
I1014 00:11:59.133600 13701 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I1014 00:12:28.265288 13701 solver.cpp:218] Iteration 19600 (3.43268 iter/s, 29.1317s/100 iters), loss = 0.389841
I1014 00:12:28.265408 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389842 (* 1 = 0.389842 loss)
I1014 00:12:28.265424 13701 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I1014 00:12:57.425691 13701 solver.cpp:218] Iteration 19700 (3.42932 iter/s, 29.1603s/100 iters), loss = 0.402209
I1014 00:12:57.425725 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402209 (* 1 = 0.402209 loss)
I1014 00:12:57.425734 13701 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I1014 00:13:26.584069 13701 solver.cpp:218] Iteration 19800 (3.42955 iter/s, 29.1584s/100 iters), loss = 0.367984
I1014 00:13:26.584229 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367984 (* 1 = 0.367984 loss)
I1014 00:13:26.584240 13701 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I1014 00:13:55.742182 13701 solver.cpp:218] Iteration 19900 (3.42959 iter/s, 29.158s/100 iters), loss = 0.531639
I1014 00:13:55.742225 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.53164 (* 1 = 0.53164 loss)
I1014 00:13:55.742233 13701 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I1014 00:14:23.458912 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:14:24.624164 13701 solver.cpp:330] Iteration 20000, Testing net (#0)
I1014 00:14:40.546059 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:14:40.871248 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.49288 (* 1 = 1.49288 loss)
I1014 00:14:40.871263 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6392
I1014 00:14:41.155853 13701 solver.cpp:218] Iteration 20000 (2.20198 iter/s, 45.4137s/100 iters), loss = 0.276454
I1014 00:14:41.155881 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276454 (* 1 = 0.276454 loss)
I1014 00:14:41.155889 13701 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I1014 00:15:10.270434 13701 solver.cpp:218] Iteration 20100 (3.4347 iter/s, 29.1146s/100 iters), loss = 0.544293
I1014 00:15:10.270576 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.544294 (* 1 = 0.544294 loss)
I1014 00:15:10.270583 13701 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I1014 00:15:39.389118 13701 solver.cpp:218] Iteration 20200 (3.43423 iter/s, 29.1186s/100 iters), loss = 0.376211
I1014 00:15:39.389160 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376212 (* 1 = 0.376212 loss)
I1014 00:15:39.389168 13701 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I1014 00:16:08.502578 13701 solver.cpp:218] Iteration 20300 (3.43484 iter/s, 29.1135s/100 iters), loss = 0.424499
I1014 00:16:08.502625 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424499 (* 1 = 0.424499 loss)
I1014 00:16:08.502631 13701 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I1014 00:16:37.619798 13701 solver.cpp:218] Iteration 20400 (3.43439 iter/s, 29.1172s/100 iters), loss = 0.457245
I1014 00:16:37.619843 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457246 (* 1 = 0.457246 loss)
I1014 00:16:37.619849 13701 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I1014 00:17:06.436494 13701 solver.cpp:330] Iteration 20500, Testing net (#0)
I1014 00:17:22.356274 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:17:22.682418 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.47729 (* 1 = 1.47729 loss)
I1014 00:17:22.682435 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6431
I1014 00:17:22.966564 13701 solver.cpp:218] Iteration 20500 (2.20523 iter/s, 45.3468s/100 iters), loss = 0.378178
I1014 00:17:22.966590 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378179 (* 1 = 0.378179 loss)
I1014 00:17:22.966598 13701 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I1014 00:17:52.081022 13701 solver.cpp:218] Iteration 20600 (3.43472 iter/s, 29.1145s/100 iters), loss = 0.313829
I1014 00:17:52.081148 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31383 (* 1 = 0.31383 loss)
I1014 00:17:52.081156 13701 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I1014 00:18:21.238394 13701 solver.cpp:218] Iteration 20700 (3.42967 iter/s, 29.1573s/100 iters), loss = 0.354417
I1014 00:18:21.238428 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354418 (* 1 = 0.354418 loss)
I1014 00:18:21.238435 13701 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I1014 00:18:50.392297 13701 solver.cpp:218] Iteration 20800 (3.43007 iter/s, 29.1539s/100 iters), loss = 0.328993
I1014 00:18:50.392411 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328993 (* 1 = 0.328993 loss)
I1014 00:18:50.392419 13701 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I1014 00:19:19.551803 13701 solver.cpp:218] Iteration 20900 (3.42942 iter/s, 29.1594s/100 iters), loss = 0.577146
I1014 00:19:19.551838 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577146 (* 1 = 0.577146 loss)
I1014 00:19:19.551846 13701 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I1014 00:19:47.261855 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:19:48.428558 13701 solver.cpp:330] Iteration 21000, Testing net (#0)
I1014 00:20:04.352720 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:20:04.678169 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5068 (* 1 = 1.5068 loss)
I1014 00:20:04.678185 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6433
I1014 00:20:04.963321 13701 solver.cpp:218] Iteration 21000 (2.20208 iter/s, 45.4116s/100 iters), loss = 0.397098
I1014 00:20:04.963348 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397099 (* 1 = 0.397099 loss)
I1014 00:20:04.963354 13701 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I1014 00:20:34.074666 13701 solver.cpp:218] Iteration 21100 (3.43509 iter/s, 29.1114s/100 iters), loss = 0.491844
I1014 00:20:34.074775 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.491845 (* 1 = 0.491845 loss)
I1014 00:20:34.074792 13701 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I1014 00:21:03.203858 13701 solver.cpp:218] Iteration 21200 (3.43299 iter/s, 29.1291s/100 iters), loss = 0.317955
I1014 00:21:03.203888 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317956 (* 1 = 0.317956 loss)
I1014 00:21:03.203894 13701 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I1014 00:21:32.321648 13701 solver.cpp:218] Iteration 21300 (3.43432 iter/s, 29.1178s/100 iters), loss = 0.407421
I1014 00:21:32.321790 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407421 (* 1 = 0.407421 loss)
I1014 00:21:32.321799 13701 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I1014 00:22:01.436815 13701 solver.cpp:218] Iteration 21400 (3.43465 iter/s, 29.1151s/100 iters), loss = 0.336282
I1014 00:22:01.436844 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336283 (* 1 = 0.336283 loss)
I1014 00:22:01.436851 13701 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I1014 00:22:30.266561 13701 solver.cpp:330] Iteration 21500, Testing net (#0)
I1014 00:22:46.187783 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:22:46.513855 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.532 (* 1 = 1.532 loss)
I1014 00:22:46.513870 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6351
I1014 00:22:46.798662 13701 solver.cpp:218] Iteration 21500 (2.20449 iter/s, 45.3619s/100 iters), loss = 0.24447
I1014 00:22:46.798691 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244471 (* 1 = 0.244471 loss)
I1014 00:22:46.798696 13701 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I1014 00:23:15.900758 13701 solver.cpp:218] Iteration 21600 (3.43618 iter/s, 29.1021s/100 iters), loss = 0.500779
I1014 00:23:15.900876 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50078 (* 1 = 0.50078 loss)
I1014 00:23:15.900894 13701 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I1014 00:23:45.019395 13701 solver.cpp:218] Iteration 21700 (3.43424 iter/s, 29.1186s/100 iters), loss = 0.280334
I1014 00:23:45.019425 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280334 (* 1 = 0.280334 loss)
I1014 00:23:45.019431 13701 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I1014 00:24:14.133162 13701 solver.cpp:218] Iteration 21800 (3.4348 iter/s, 29.1138s/100 iters), loss = 0.332401
I1014 00:24:14.133303 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332402 (* 1 = 0.332402 loss)
I1014 00:24:14.133322 13701 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I1014 00:24:43.219403 13701 solver.cpp:218] Iteration 21900 (3.43806 iter/s, 29.0861s/100 iters), loss = 0.444913
I1014 00:24:43.219434 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444914 (* 1 = 0.444914 loss)
I1014 00:24:43.219439 13701 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I1014 00:25:10.864670 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:25:12.030133 13701 solver.cpp:330] Iteration 22000, Testing net (#0)
I1014 00:25:27.947068 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:25:28.272797 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48827 (* 1 = 1.48827 loss)
I1014 00:25:28.272812 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6477
I1014 00:25:28.556632 13701 solver.cpp:218] Iteration 22000 (2.20569 iter/s, 45.3373s/100 iters), loss = 0.209032
I1014 00:25:28.556665 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209033 (* 1 = 0.209033 loss)
I1014 00:25:28.556674 13701 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I1014 00:25:57.631433 13701 solver.cpp:218] Iteration 22100 (3.4394 iter/s, 29.0748s/100 iters), loss = 0.282993
I1014 00:25:57.631577 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282994 (* 1 = 0.282994 loss)
I1014 00:25:57.631587 13701 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I1014 00:26:26.733667 13701 solver.cpp:218] Iteration 22200 (3.43617 iter/s, 29.1021s/100 iters), loss = 0.448694
I1014 00:26:26.733700 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448695 (* 1 = 0.448695 loss)
I1014 00:26:26.733705 13701 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I1014 00:26:55.841891 13701 solver.cpp:218] Iteration 22300 (3.43545 iter/s, 29.1082s/100 iters), loss = 0.38794
I1014 00:26:55.842033 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38794 (* 1 = 0.38794 loss)
I1014 00:26:55.842042 13701 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I1014 00:27:24.951679 13701 solver.cpp:218] Iteration 22400 (3.43528 iter/s, 29.1097s/100 iters), loss = 0.470308
I1014 00:27:24.951709 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.470309 (* 1 = 0.470309 loss)
I1014 00:27:24.951714 13701 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I1014 00:27:53.781112 13701 solver.cpp:330] Iteration 22500, Testing net (#0)
I1014 00:28:09.706568 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:28:10.032763 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59006 (* 1 = 1.59006 loss)
I1014 00:28:10.032776 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6268
I1014 00:28:10.318126 13701 solver.cpp:218] Iteration 22500 (2.20427 iter/s, 45.3665s/100 iters), loss = 0.394976
I1014 00:28:10.318167 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394977 (* 1 = 0.394977 loss)
I1014 00:28:10.318184 13701 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I1014 00:28:39.389045 13701 solver.cpp:218] Iteration 22600 (3.43987 iter/s, 29.0709s/100 iters), loss = 0.270686
I1014 00:28:39.389210 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270687 (* 1 = 0.270687 loss)
I1014 00:28:39.389221 13701 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I1014 00:29:08.476550 13701 solver.cpp:218] Iteration 22700 (3.43792 iter/s, 29.0874s/100 iters), loss = 0.17043
I1014 00:29:08.476594 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170431 (* 1 = 0.170431 loss)
I1014 00:29:08.476601 13701 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I1014 00:29:37.562299 13701 solver.cpp:218] Iteration 22800 (3.43811 iter/s, 29.0858s/100 iters), loss = 0.333276
I1014 00:29:37.562440 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333277 (* 1 = 0.333277 loss)
I1014 00:29:37.562448 13701 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I1014 00:30:06.645423 13701 solver.cpp:218] Iteration 22900 (3.43843 iter/s, 29.083s/100 iters), loss = 0.358618
I1014 00:30:06.645457 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358619 (* 1 = 0.358619 loss)
I1014 00:30:06.645464 13701 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I1014 00:30:34.291610 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:30:35.455904 13701 solver.cpp:330] Iteration 23000, Testing net (#0)
I1014 00:30:51.379174 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:30:51.705886 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53748 (* 1 = 1.53748 loss)
I1014 00:30:51.705904 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6352
I1014 00:30:51.989677 13701 solver.cpp:218] Iteration 23000 (2.20535 iter/s, 45.3443s/100 iters), loss = 0.402431
I1014 00:30:51.989714 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402432 (* 1 = 0.402432 loss)
I1014 00:30:51.989722 13701 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I1014 00:31:21.063769 13701 solver.cpp:218] Iteration 23100 (3.43949 iter/s, 29.0741s/100 iters), loss = 0.337237
I1014 00:31:21.063858 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337238 (* 1 = 0.337238 loss)
I1014 00:31:21.063874 13701 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I1014 00:31:50.161937 13701 solver.cpp:218] Iteration 23200 (3.43665 iter/s, 29.0981s/100 iters), loss = 0.352985
I1014 00:31:50.161968 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352986 (* 1 = 0.352986 loss)
I1014 00:31:50.161974 13701 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I1014 00:32:19.260195 13701 solver.cpp:218] Iteration 23300 (3.43663 iter/s, 29.0983s/100 iters), loss = 0.26075
I1014 00:32:19.260311 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260751 (* 1 = 0.260751 loss)
I1014 00:32:19.260319 13701 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I1014 00:32:48.359460 13701 solver.cpp:218] Iteration 23400 (3.43652 iter/s, 29.0992s/100 iters), loss = 0.279124
I1014 00:32:48.359490 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279125 (* 1 = 0.279125 loss)
I1014 00:32:48.359496 13701 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I1014 00:33:17.175127 13701 solver.cpp:330] Iteration 23500, Testing net (#0)
I1014 00:33:33.093798 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:33:33.420087 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56197 (* 1 = 1.56197 loss)
I1014 00:33:33.420104 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6294
I1014 00:33:33.704912 13701 solver.cpp:218] Iteration 23500 (2.20529 iter/s, 45.3455s/100 iters), loss = 0.502141
I1014 00:33:33.704946 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502141 (* 1 = 0.502141 loss)
I1014 00:33:33.704952 13701 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I1014 00:34:02.771435 13701 solver.cpp:218] Iteration 23600 (3.44038 iter/s, 29.0665s/100 iters), loss = 0.456369
I1014 00:34:02.771565 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45637 (* 1 = 0.45637 loss)
I1014 00:34:02.771574 13701 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I1014 00:34:31.863260 13701 solver.cpp:218] Iteration 23700 (3.4374 iter/s, 29.0917s/100 iters), loss = 0.570205
I1014 00:34:31.863291 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.570206 (* 1 = 0.570206 loss)
I1014 00:34:31.863297 13701 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I1014 00:35:00.965879 13701 solver.cpp:218] Iteration 23800 (3.43612 iter/s, 29.1026s/100 iters), loss = 0.263206
I1014 00:35:00.966054 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263207 (* 1 = 0.263207 loss)
I1014 00:35:00.966063 13701 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I1014 00:35:30.443953 13701 solver.cpp:218] Iteration 23900 (3.39237 iter/s, 29.478s/100 iters), loss = 0.371838
I1014 00:35:30.443982 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371839 (* 1 = 0.371839 loss)
I1014 00:35:30.443989 13701 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I1014 00:36:00.086346 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:36:01.333454 13701 solver.cpp:330] Iteration 24000, Testing net (#0)
I1014 00:36:18.177345 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:36:18.517896 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55749 (* 1 = 1.55749 loss)
I1014 00:36:18.517912 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6375
I1014 00:36:18.823000 13701 solver.cpp:218] Iteration 24000 (2.06701 iter/s, 48.3791s/100 iters), loss = 0.188289
I1014 00:36:18.823034 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18829 (* 1 = 0.18829 loss)
I1014 00:36:18.823040 13701 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I1014 00:36:49.420270 13701 solver.cpp:218] Iteration 24100 (3.26827 iter/s, 30.5973s/100 iters), loss = 0.494101
I1014 00:36:49.420382 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494102 (* 1 = 0.494102 loss)
I1014 00:36:49.420389 13701 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I1014 00:37:19.975939 13701 solver.cpp:218] Iteration 24200 (3.27272 iter/s, 30.5556s/100 iters), loss = 0.221167
I1014 00:37:19.976080 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221168 (* 1 = 0.221168 loss)
I1014 00:37:19.976089 13701 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I1014 00:37:50.530472 13701 solver.cpp:218] Iteration 24300 (3.27285 iter/s, 30.5544s/100 iters), loss = 0.285602
I1014 00:37:50.530611 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285603 (* 1 = 0.285603 loss)
I1014 00:37:50.530619 13701 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I1014 00:38:21.099546 13701 solver.cpp:218] Iteration 24400 (3.27129 iter/s, 30.569s/100 iters), loss = 0.372435
I1014 00:38:21.099658 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372436 (* 1 = 0.372436 loss)
I1014 00:38:21.099676 13701 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I1014 00:38:51.398736 13701 solver.cpp:330] Iteration 24500, Testing net (#0)
I1014 00:39:08.020437 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:39:08.360546 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58675 (* 1 = 1.58675 loss)
I1014 00:39:08.360561 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6346
I1014 00:39:08.660883 13701 solver.cpp:218] Iteration 24500 (2.10255 iter/s, 47.5613s/100 iters), loss = 0.322031
I1014 00:39:08.660917 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322032 (* 1 = 0.322032 loss)
I1014 00:39:08.660923 13701 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I1014 00:39:39.286414 13701 solver.cpp:218] Iteration 24600 (3.26525 iter/s, 30.6255s/100 iters), loss = 0.396857
I1014 00:39:39.286561 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396858 (* 1 = 0.396858 loss)
I1014 00:39:39.286569 13701 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I1014 00:40:09.894783 13701 solver.cpp:218] Iteration 24700 (3.26709 iter/s, 30.6082s/100 iters), loss = 0.332645
I1014 00:40:09.894881 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332646 (* 1 = 0.332646 loss)
I1014 00:40:09.894887 13701 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I1014 00:40:40.549531 13701 solver.cpp:218] Iteration 24800 (3.26215 iter/s, 30.6547s/100 iters), loss = 0.407104
I1014 00:40:40.549716 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407104 (* 1 = 0.407104 loss)
I1014 00:40:40.549726 13701 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I1014 00:41:11.192167 13701 solver.cpp:218] Iteration 24900 (3.26344 iter/s, 30.6425s/100 iters), loss = 0.302715
I1014 00:41:11.192289 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302716 (* 1 = 0.302716 loss)
I1014 00:41:11.192296 13701 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I1014 00:41:40.364796 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:41:41.596351 13701 solver.cpp:330] Iteration 25000, Testing net (#0)
I1014 00:41:58.252590 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:41:58.597157 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54283 (* 1 = 1.54283 loss)
I1014 00:41:58.597172 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6415
I1014 00:41:58.900555 13701 solver.cpp:218] Iteration 25000 (2.09607 iter/s, 47.7083s/100 iters), loss = 0.319246
I1014 00:41:58.900585 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319247 (* 1 = 0.319247 loss)
I1014 00:41:58.900593 13701 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I1014 00:42:29.578272 13701 solver.cpp:218] Iteration 25100 (3.2597 iter/s, 30.6777s/100 iters), loss = 0.446814
I1014 00:42:29.578383 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446814 (* 1 = 0.446814 loss)
I1014 00:42:29.578392 13701 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I1014 00:43:00.282932 13701 solver.cpp:218] Iteration 25200 (3.25684 iter/s, 30.7046s/100 iters), loss = 0.382346
I1014 00:43:00.283074 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382347 (* 1 = 0.382347 loss)
I1014 00:43:00.283083 13701 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I1014 00:43:31.020862 13701 solver.cpp:218] Iteration 25300 (3.25332 iter/s, 30.7378s/100 iters), loss = 0.326028
I1014 00:43:31.021001 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326029 (* 1 = 0.326029 loss)
I1014 00:43:31.021008 13701 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I1014 00:44:01.728585 13701 solver.cpp:218] Iteration 25400 (3.25652 iter/s, 30.7076s/100 iters), loss = 0.300756
I1014 00:44:01.728724 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300756 (* 1 = 0.300756 loss)
I1014 00:44:01.728731 13701 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I1014 00:44:32.133944 13701 solver.cpp:330] Iteration 25500, Testing net (#0)
I1014 00:44:48.873201 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:44:49.215382 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61047 (* 1 = 1.61047 loss)
I1014 00:44:49.215399 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6363
I1014 00:44:49.519142 13701 solver.cpp:218] Iteration 25500 (2.09247 iter/s, 47.7904s/100 iters), loss = 0.541033
I1014 00:44:49.519176 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541034 (* 1 = 0.541034 loss)
I1014 00:44:49.519183 13701 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I1014 00:45:20.303519 13701 solver.cpp:218] Iteration 25600 (3.2484 iter/s, 30.7844s/100 iters), loss = 0.361284
I1014 00:45:20.303630 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361285 (* 1 = 0.361285 loss)
I1014 00:45:20.303647 13701 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I1014 00:45:51.054020 13701 solver.cpp:218] Iteration 25700 (3.25199 iter/s, 30.7504s/100 iters), loss = 0.343943
I1014 00:45:51.054157 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343944 (* 1 = 0.343944 loss)
I1014 00:45:51.054164 13701 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I1014 00:46:21.772109 13701 solver.cpp:218] Iteration 25800 (3.25542 iter/s, 30.718s/100 iters), loss = 0.283611
I1014 00:46:21.772279 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283612 (* 1 = 0.283612 loss)
I1014 00:46:21.772287 13701 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I1014 00:46:52.552839 13701 solver.cpp:218] Iteration 25900 (3.2488 iter/s, 30.7806s/100 iters), loss = 0.272401
I1014 00:46:52.552979 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272402 (* 1 = 0.272402 loss)
I1014 00:46:52.552987 13701 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I1014 00:47:21.756497 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:47:22.989125 13701 solver.cpp:330] Iteration 26000, Testing net (#0)
I1014 00:47:39.685164 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:47:40.026024 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62424 (* 1 = 1.62424 loss)
I1014 00:47:40.026041 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6331
I1014 00:47:40.330418 13701 solver.cpp:218] Iteration 26000 (2.09304 iter/s, 47.7775s/100 iters), loss = 0.217065
I1014 00:47:40.330452 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217065 (* 1 = 0.217065 loss)
I1014 00:47:40.330461 13701 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I1014 00:48:11.090112 13701 solver.cpp:218] Iteration 26100 (3.25101 iter/s, 30.7597s/100 iters), loss = 0.439312
I1014 00:48:11.090224 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439313 (* 1 = 0.439313 loss)
I1014 00:48:11.090231 13701 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I1014 00:48:41.774884 13701 solver.cpp:218] Iteration 26200 (3.25896 iter/s, 30.6847s/100 iters), loss = 0.206877
I1014 00:48:41.774996 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206878 (* 1 = 0.206878 loss)
I1014 00:48:41.775012 13701 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I1014 00:49:12.484313 13701 solver.cpp:218] Iteration 26300 (3.25634 iter/s, 30.7093s/100 iters), loss = 0.370484
I1014 00:49:12.484413 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370485 (* 1 = 0.370485 loss)
I1014 00:49:12.484431 13701 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I1014 00:49:43.159298 13701 solver.cpp:218] Iteration 26400 (3.25999 iter/s, 30.6749s/100 iters), loss = 0.298243
I1014 00:49:43.159440 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298244 (* 1 = 0.298244 loss)
I1014 00:49:43.159449 13701 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I1014 00:50:13.554095 13701 solver.cpp:330] Iteration 26500, Testing net (#0)
I1014 00:50:30.256834 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:50:30.598559 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59141 (* 1 = 1.59141 loss)
I1014 00:50:30.598577 13701 solver.cpp:397]     Test net output #1: accuracy = 0.637
I1014 00:50:30.903044 13701 solver.cpp:218] Iteration 26500 (2.09452 iter/s, 47.7436s/100 iters), loss = 0.266707
I1014 00:50:30.903076 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266708 (* 1 = 0.266708 loss)
I1014 00:50:30.903084 13701 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I1014 00:51:01.519953 13701 solver.cpp:218] Iteration 26600 (3.26617 iter/s, 30.6169s/100 iters), loss = 0.152145
I1014 00:51:01.520092 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152146 (* 1 = 0.152146 loss)
I1014 00:51:01.520100 13701 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I1014 00:51:32.179987 13701 solver.cpp:218] Iteration 26700 (3.26159 iter/s, 30.6599s/100 iters), loss = 0.424484
I1014 00:51:32.180089 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424485 (* 1 = 0.424485 loss)
I1014 00:51:32.180096 13701 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I1014 00:52:02.826731 13701 solver.cpp:218] Iteration 26800 (3.263 iter/s, 30.6467s/100 iters), loss = 0.144662
I1014 00:52:02.826831 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144663 (* 1 = 0.144663 loss)
I1014 00:52:02.826839 13701 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I1014 00:52:33.447716 13701 solver.cpp:218] Iteration 26900 (3.26574 iter/s, 30.6209s/100 iters), loss = 0.522445
I1014 00:52:33.447890 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.522446 (* 1 = 0.522446 loss)
I1014 00:52:33.447899 13701 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I1014 00:53:02.585824 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:53:03.806083 13701 solver.cpp:330] Iteration 27000, Testing net (#0)
I1014 00:53:20.499485 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:53:20.841979 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55908 (* 1 = 1.55908 loss)
I1014 00:53:20.841995 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6452
I1014 00:53:21.144749 13701 solver.cpp:218] Iteration 27000 (2.09657 iter/s, 47.6969s/100 iters), loss = 0.255576
I1014 00:53:21.144784 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255577 (* 1 = 0.255577 loss)
I1014 00:53:21.144793 13701 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I1014 00:53:51.803964 13701 solver.cpp:218] Iteration 27100 (3.26167 iter/s, 30.6592s/100 iters), loss = 0.298425
I1014 00:53:51.804111 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298426 (* 1 = 0.298426 loss)
I1014 00:53:51.804121 13701 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I1014 00:54:22.432075 13701 solver.cpp:218] Iteration 27200 (3.26499 iter/s, 30.628s/100 iters), loss = 0.335457
I1014 00:54:22.432214 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335458 (* 1 = 0.335458 loss)
I1014 00:54:22.432222 13701 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I1014 00:54:53.102100 13701 solver.cpp:218] Iteration 27300 (3.26053 iter/s, 30.6699s/100 iters), loss = 0.339075
I1014 00:54:53.102236 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339076 (* 1 = 0.339076 loss)
I1014 00:54:53.102242 13701 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I1014 00:55:23.744602 13701 solver.cpp:218] Iteration 27400 (3.26345 iter/s, 30.6424s/100 iters), loss = 0.228136
I1014 00:55:23.744750 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228137 (* 1 = 0.228137 loss)
I1014 00:55:23.744760 13701 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I1014 00:55:54.100777 13701 solver.cpp:330] Iteration 27500, Testing net (#0)
I1014 00:56:10.763836 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:56:11.104198 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5881 (* 1 = 1.5881 loss)
I1014 00:56:11.104215 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6364
I1014 00:56:11.406595 13701 solver.cpp:218] Iteration 27500 (2.09811 iter/s, 47.6619s/100 iters), loss = 0.303652
I1014 00:56:11.406625 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303653 (* 1 = 0.303653 loss)
I1014 00:56:11.406632 13701 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I1014 00:56:42.073691 13701 solver.cpp:218] Iteration 27600 (3.26083 iter/s, 30.6671s/100 iters), loss = 0.379835
I1014 00:56:42.073833 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379836 (* 1 = 0.379836 loss)
I1014 00:56:42.073842 13701 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I1014 00:57:12.732067 13701 solver.cpp:218] Iteration 27700 (3.26177 iter/s, 30.6582s/100 iters), loss = 0.404704
I1014 00:57:12.732200 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404705 (* 1 = 0.404705 loss)
I1014 00:57:12.732208 13701 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I1014 00:57:43.418488 13701 solver.cpp:218] Iteration 27800 (3.25878 iter/s, 30.6863s/100 iters), loss = 0.340299
I1014 00:57:43.418629 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3403 (* 1 = 0.3403 loss)
I1014 00:57:43.418637 13701 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I1014 00:58:14.047837 13701 solver.cpp:218] Iteration 27900 (3.26486 iter/s, 30.6292s/100 iters), loss = 0.398809
I1014 00:58:14.047986 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39881 (* 1 = 0.39881 loss)
I1014 00:58:14.048005 13701 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I1014 00:58:43.175704 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:58:44.403959 13701 solver.cpp:330] Iteration 28000, Testing net (#0)
I1014 00:59:01.033761 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 00:59:01.373415 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59495 (* 1 = 1.59495 loss)
I1014 00:59:01.373431 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6344
I1014 00:59:01.678228 13701 solver.cpp:218] Iteration 28000 (2.09951 iter/s, 47.6303s/100 iters), loss = 0.284139
I1014 00:59:01.678264 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28414 (* 1 = 0.28414 loss)
I1014 00:59:01.678272 13701 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I1014 00:59:32.350057 13701 solver.cpp:218] Iteration 28100 (3.26032 iter/s, 30.6718s/100 iters), loss = 0.241438
I1014 00:59:32.350198 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241439 (* 1 = 0.241439 loss)
I1014 00:59:32.350206 13701 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I1014 01:00:03.017793 13701 solver.cpp:218] Iteration 28200 (3.26077 iter/s, 30.6676s/100 iters), loss = 0.245359
I1014 01:00:03.017858 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24536 (* 1 = 0.24536 loss)
I1014 01:00:03.017865 13701 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I1014 01:00:33.653674 13701 solver.cpp:218] Iteration 28300 (3.26415 iter/s, 30.6358s/100 iters), loss = 0.397386
I1014 01:00:33.653810 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397387 (* 1 = 0.397387 loss)
I1014 01:00:33.653820 13701 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I1014 01:01:04.309782 13701 solver.cpp:218] Iteration 28400 (3.26201 iter/s, 30.656s/100 iters), loss = 0.284551
I1014 01:01:04.309936 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284552 (* 1 = 0.284552 loss)
I1014 01:01:04.309955 13701 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I1014 01:01:34.660771 13701 solver.cpp:330] Iteration 28500, Testing net (#0)
I1014 01:01:51.300113 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:01:51.637990 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56674 (* 1 = 1.56674 loss)
I1014 01:01:51.638006 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6481
I1014 01:01:51.939318 13701 solver.cpp:218] Iteration 28500 (2.09954 iter/s, 47.6294s/100 iters), loss = 0.229274
I1014 01:01:51.939347 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229275 (* 1 = 0.229275 loss)
I1014 01:01:51.939354 13701 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I1014 01:02:22.580991 13701 solver.cpp:218] Iteration 28600 (3.26353 iter/s, 30.6417s/100 iters), loss = 0.316645
I1014 01:02:22.581132 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316646 (* 1 = 0.316646 loss)
I1014 01:02:22.581140 13701 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I1014 01:02:53.235721 13701 solver.cpp:218] Iteration 28700 (3.26215 iter/s, 30.6546s/100 iters), loss = 0.170177
I1014 01:02:53.235865 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170178 (* 1 = 0.170178 loss)
I1014 01:02:53.235872 13701 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I1014 01:03:23.863893 13701 solver.cpp:218] Iteration 28800 (3.26498 iter/s, 30.628s/100 iters), loss = 0.255339
I1014 01:03:23.863998 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255341 (* 1 = 0.255341 loss)
I1014 01:03:23.864007 13701 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I1014 01:03:54.457689 13701 solver.cpp:218] Iteration 28900 (3.26865 iter/s, 30.5937s/100 iters), loss = 0.241418
I1014 01:03:54.457847 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241419 (* 1 = 0.241419 loss)
I1014 01:03:54.457865 13701 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I1014 01:04:23.564549 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:04:24.788882 13701 solver.cpp:330] Iteration 29000, Testing net (#0)
I1014 01:04:41.415124 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:04:41.754834 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61022 (* 1 = 1.61022 loss)
I1014 01:04:41.754850 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6389
I1014 01:04:42.056665 13701 solver.cpp:218] Iteration 29000 (2.10089 iter/s, 47.5988s/100 iters), loss = 0.180829
I1014 01:04:42.056694 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18083 (* 1 = 0.18083 loss)
I1014 01:04:42.056701 13701 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I1014 01:05:12.666568 13701 solver.cpp:218] Iteration 29100 (3.26692 iter/s, 30.6099s/100 iters), loss = 0.363272
I1014 01:05:12.666723 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363273 (* 1 = 0.363273 loss)
I1014 01:05:12.666733 13701 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I1014 01:05:43.265611 13701 solver.cpp:218] Iteration 29200 (3.26809 iter/s, 30.5989s/100 iters), loss = 0.277539
I1014 01:05:43.265708 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27754 (* 1 = 0.27754 loss)
I1014 01:05:43.265724 13701 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I1014 01:06:13.877846 13701 solver.cpp:218] Iteration 29300 (3.26668 iter/s, 30.6121s/100 iters), loss = 0.268795
I1014 01:06:13.877980 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268797 (* 1 = 0.268797 loss)
I1014 01:06:13.878001 13701 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I1014 01:06:44.478838 13701 solver.cpp:218] Iteration 29400 (3.26788 iter/s, 30.6009s/100 iters), loss = 0.173792
I1014 01:06:44.478987 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173793 (* 1 = 0.173793 loss)
I1014 01:06:44.478996 13701 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I1014 01:07:14.843072 13701 solver.cpp:330] Iteration 29500, Testing net (#0)
I1014 01:07:31.450644 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:07:31.789649 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60897 (* 1 = 1.60897 loss)
I1014 01:07:31.789664 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6332
I1014 01:07:32.089622 13701 solver.cpp:218] Iteration 29500 (2.10037 iter/s, 47.6107s/100 iters), loss = 0.301955
I1014 01:07:32.089649 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301956 (* 1 = 0.301956 loss)
I1014 01:07:32.089655 13701 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I1014 01:08:02.664166 13701 solver.cpp:218] Iteration 29600 (3.2707 iter/s, 30.5745s/100 iters), loss = 0.409468
I1014 01:08:02.664312 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409469 (* 1 = 0.409469 loss)
I1014 01:08:02.664319 13701 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I1014 01:08:33.260973 13701 solver.cpp:218] Iteration 29700 (3.26833 iter/s, 30.5967s/100 iters), loss = 0.274031
I1014 01:08:33.261099 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274032 (* 1 = 0.274032 loss)
I1014 01:08:33.261106 13701 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I1014 01:09:03.848309 13701 solver.cpp:218] Iteration 29800 (3.26934 iter/s, 30.5872s/100 iters), loss = 0.308682
I1014 01:09:03.848451 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308683 (* 1 = 0.308683 loss)
I1014 01:09:03.848459 13701 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I1014 01:09:34.445955 13701 solver.cpp:218] Iteration 29900 (3.26824 iter/s, 30.5975s/100 iters), loss = 0.338247
I1014 01:09:34.446099 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338248 (* 1 = 0.338248 loss)
I1014 01:09:34.446108 13701 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I1014 01:10:03.515211 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:10:04.750001 13701 solver.cpp:330] Iteration 30000, Testing net (#0)
I1014 01:10:21.414448 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:10:21.755976 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55694 (* 1 = 1.55694 loss)
I1014 01:10:21.755992 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6478
I1014 01:10:22.060777 13701 solver.cpp:218] Iteration 30000 (2.10019 iter/s, 47.6147s/100 iters), loss = 0.222357
I1014 01:10:22.060806 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222358 (* 1 = 0.222358 loss)
I1014 01:10:22.060811 13701 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I1014 01:10:52.656163 13701 solver.cpp:218] Iteration 30100 (3.26847 iter/s, 30.5954s/100 iters), loss = 0.312274
I1014 01:10:52.656308 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312275 (* 1 = 0.312275 loss)
I1014 01:10:52.656316 13701 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I1014 01:11:23.265296 13701 solver.cpp:218] Iteration 30200 (3.26701 iter/s, 30.609s/100 iters), loss = 0.2351
I1014 01:11:23.265396 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235101 (* 1 = 0.235101 loss)
I1014 01:11:23.265403 13701 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I1014 01:11:53.924518 13701 solver.cpp:218] Iteration 30300 (3.26167 iter/s, 30.6591s/100 iters), loss = 0.213461
I1014 01:11:53.924660 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213462 (* 1 = 0.213462 loss)
I1014 01:11:53.924669 13701 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I1014 01:12:24.523458 13701 solver.cpp:218] Iteration 30400 (3.2681 iter/s, 30.5988s/100 iters), loss = 0.519714
I1014 01:12:24.523599 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519715 (* 1 = 0.519715 loss)
I1014 01:12:24.523608 13701 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I1014 01:12:54.793633 13701 solver.cpp:330] Iteration 30500, Testing net (#0)
I1014 01:13:11.440814 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:13:11.779989 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58459 (* 1 = 1.58459 loss)
I1014 01:13:11.780004 13701 solver.cpp:397]     Test net output #1: accuracy = 0.645
I1014 01:13:12.080981 13701 solver.cpp:218] Iteration 30500 (2.10272 iter/s, 47.5574s/100 iters), loss = 0.151978
I1014 01:13:12.081009 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151979 (* 1 = 0.151979 loss)
I1014 01:13:12.081015 13701 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I1014 01:13:42.750370 13701 solver.cpp:218] Iteration 30600 (3.26058 iter/s, 30.6694s/100 iters), loss = 0.455226
I1014 01:13:42.750452 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.455227 (* 1 = 0.455227 loss)
I1014 01:13:42.750468 13701 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I1014 01:14:13.363904 13701 solver.cpp:218] Iteration 30700 (3.26654 iter/s, 30.6135s/100 iters), loss = 0.42627
I1014 01:14:13.364009 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426271 (* 1 = 0.426271 loss)
I1014 01:14:13.364017 13701 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I1014 01:14:44.026515 13701 solver.cpp:218] Iteration 30800 (3.26131 iter/s, 30.6625s/100 iters), loss = 0.272883
I1014 01:14:44.026609 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272884 (* 1 = 0.272884 loss)
I1014 01:14:44.026615 13701 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I1014 01:15:14.603524 13701 solver.cpp:218] Iteration 30900 (3.27044 iter/s, 30.5769s/100 iters), loss = 0.51342
I1014 01:15:14.603672 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.513421 (* 1 = 0.513421 loss)
I1014 01:15:14.603680 13701 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I1014 01:15:43.673967 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:15:44.899377 13701 solver.cpp:330] Iteration 31000, Testing net (#0)
I1014 01:16:01.546548 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:16:01.885910 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.64674 (* 1 = 1.64674 loss)
I1014 01:16:01.885928 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6351
I1014 01:16:02.189750 13701 solver.cpp:218] Iteration 31000 (2.10145 iter/s, 47.5861s/100 iters), loss = 0.105306
I1014 01:16:02.189779 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105308 (* 1 = 0.105308 loss)
I1014 01:16:02.189785 13701 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I1014 01:16:32.859156 13701 solver.cpp:218] Iteration 31100 (3.26058 iter/s, 30.6694s/100 iters), loss = 0.324461
I1014 01:16:32.859308 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324463 (* 1 = 0.324463 loss)
I1014 01:16:32.859316 13701 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I1014 01:17:03.494799 13701 solver.cpp:218] Iteration 31200 (3.26419 iter/s, 30.6355s/100 iters), loss = 0.401657
I1014 01:17:03.494901 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401658 (* 1 = 0.401658 loss)
I1014 01:17:03.494910 13701 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I1014 01:17:34.081465 13701 solver.cpp:218] Iteration 31300 (3.26941 iter/s, 30.5866s/100 iters), loss = 0.241908
I1014 01:17:34.081547 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241909 (* 1 = 0.241909 loss)
I1014 01:17:34.081570 13701 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I1014 01:18:04.729190 13701 solver.cpp:218] Iteration 31400 (3.26289 iter/s, 30.6476s/100 iters), loss = 0.235976
I1014 01:18:04.729333 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235977 (* 1 = 0.235977 loss)
I1014 01:18:04.729343 13701 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I1014 01:18:35.088608 13701 solver.cpp:330] Iteration 31500, Testing net (#0)
I1014 01:18:51.688390 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:18:52.031563 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59786 (* 1 = 1.59786 loss)
I1014 01:18:52.031576 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6389
I1014 01:18:52.336196 13701 solver.cpp:218] Iteration 31500 (2.10054 iter/s, 47.6069s/100 iters), loss = 0.232103
I1014 01:18:52.336226 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232104 (* 1 = 0.232104 loss)
I1014 01:18:52.336233 13701 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I1014 01:19:22.978961 13701 solver.cpp:218] Iteration 31600 (3.26342 iter/s, 30.6427s/100 iters), loss = 0.253495
I1014 01:19:22.979104 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253496 (* 1 = 0.253496 loss)
I1014 01:19:22.979111 13701 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I1014 01:19:53.534844 13701 solver.cpp:218] Iteration 31700 (3.27271 iter/s, 30.5557s/100 iters), loss = 0.190393
I1014 01:19:53.534987 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190394 (* 1 = 0.190394 loss)
I1014 01:19:53.534996 13701 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I1014 01:20:24.107554 13701 solver.cpp:218] Iteration 31800 (3.27091 iter/s, 30.5726s/100 iters), loss = 0.350853
I1014 01:20:24.107694 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350854 (* 1 = 0.350854 loss)
I1014 01:20:24.107702 13701 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I1014 01:20:54.707989 13701 solver.cpp:218] Iteration 31900 (3.26794 iter/s, 30.6003s/100 iters), loss = 0.188499
I1014 01:20:54.708106 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188501 (* 1 = 0.188501 loss)
I1014 01:20:54.708123 13701 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I1014 01:21:23.812752 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:21:25.025854 13701 solver.cpp:330] Iteration 32000, Testing net (#0)
I1014 01:21:41.675307 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:21:42.017101 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.64165 (* 1 = 1.64165 loss)
I1014 01:21:42.017114 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6408
I1014 01:21:42.318869 13701 solver.cpp:218] Iteration 32000 (2.10036 iter/s, 47.6108s/100 iters), loss = 0.067063
I1014 01:21:42.318909 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0670642 (* 1 = 0.0670642 loss)
I1014 01:21:42.318917 13701 sgd_solver.cpp:105] Iteration 32000, lr = 0.01
I1014 01:22:12.912199 13701 solver.cpp:218] Iteration 32100 (3.26869 iter/s, 30.5933s/100 iters), loss = 0.195938
I1014 01:22:12.912289 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195939 (* 1 = 0.195939 loss)
I1014 01:22:12.912307 13701 sgd_solver.cpp:105] Iteration 32100, lr = 0.01
I1014 01:22:43.463644 13701 solver.cpp:218] Iteration 32200 (3.27318 iter/s, 30.5514s/100 iters), loss = 0.216227
I1014 01:22:43.463737 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216229 (* 1 = 0.216229 loss)
I1014 01:22:43.463745 13701 sgd_solver.cpp:105] Iteration 32200, lr = 0.01
I1014 01:23:14.017349 13701 solver.cpp:218] Iteration 32300 (3.27293 iter/s, 30.5536s/100 iters), loss = 0.416896
I1014 01:23:14.017485 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416898 (* 1 = 0.416898 loss)
I1014 01:23:14.017493 13701 sgd_solver.cpp:105] Iteration 32300, lr = 0.01
I1014 01:23:44.609529 13701 solver.cpp:218] Iteration 32400 (3.26882 iter/s, 30.5921s/100 iters), loss = 0.200475
I1014 01:23:44.609592 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200476 (* 1 = 0.200476 loss)
I1014 01:23:44.609601 13701 sgd_solver.cpp:105] Iteration 32400, lr = 0.01
I1014 01:24:14.898414 13701 solver.cpp:330] Iteration 32500, Testing net (#0)
I1014 01:24:31.522583 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:24:31.866875 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59156 (* 1 = 1.59156 loss)
I1014 01:24:31.866891 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6424
I1014 01:24:32.170569 13701 solver.cpp:218] Iteration 32500 (2.10256 iter/s, 47.561s/100 iters), loss = 0.246127
I1014 01:24:32.170598 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246128 (* 1 = 0.246128 loss)
I1014 01:24:32.170604 13701 sgd_solver.cpp:105] Iteration 32500, lr = 0.01
I1014 01:25:02.747709 13701 solver.cpp:218] Iteration 32600 (3.27042 iter/s, 30.5771s/100 iters), loss = 0.324329
I1014 01:25:02.747809 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32433 (* 1 = 0.32433 loss)
I1014 01:25:02.747817 13701 sgd_solver.cpp:105] Iteration 32600, lr = 0.01
I1014 01:25:33.322507 13701 solver.cpp:218] Iteration 32700 (3.27068 iter/s, 30.5747s/100 iters), loss = 0.330258
I1014 01:25:33.322602 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33026 (* 1 = 0.33026 loss)
I1014 01:25:33.322609 13701 sgd_solver.cpp:105] Iteration 32700, lr = 0.01
I1014 01:26:03.860380 13701 solver.cpp:218] Iteration 32800 (3.27463 iter/s, 30.5378s/100 iters), loss = 0.225325
I1014 01:26:03.860497 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225326 (* 1 = 0.225326 loss)
I1014 01:26:03.860505 13701 sgd_solver.cpp:105] Iteration 32800, lr = 0.01
I1014 01:26:34.448945 13701 solver.cpp:218] Iteration 32900 (3.26921 iter/s, 30.5885s/100 iters), loss = 0.213324
I1014 01:26:34.449054 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213326 (* 1 = 0.213326 loss)
I1014 01:26:34.449070 13701 sgd_solver.cpp:105] Iteration 32900, lr = 0.01
I1014 01:27:03.512665 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:27:04.741593 13701 solver.cpp:330] Iteration 33000, Testing net (#0)
I1014 01:27:21.400370 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:27:21.741111 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.66543 (* 1 = 1.66543 loss)
I1014 01:27:21.741127 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6387
I1014 01:27:22.043370 13701 solver.cpp:218] Iteration 33000 (2.10109 iter/s, 47.5943s/100 iters), loss = 0.130067
I1014 01:27:22.043396 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130068 (* 1 = 0.130068 loss)
I1014 01:27:22.043403 13701 sgd_solver.cpp:105] Iteration 33000, lr = 0.01
I1014 01:27:52.648397 13701 solver.cpp:218] Iteration 33100 (3.26744 iter/s, 30.605s/100 iters), loss = 0.334493
I1014 01:27:52.648571 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334494 (* 1 = 0.334494 loss)
I1014 01:27:52.648589 13701 sgd_solver.cpp:105] Iteration 33100, lr = 0.01
I1014 01:28:23.232873 13701 solver.cpp:218] Iteration 33200 (3.26965 iter/s, 30.5843s/100 iters), loss = 0.306899
I1014 01:28:23.233014 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306901 (* 1 = 0.306901 loss)
I1014 01:28:23.233022 13701 sgd_solver.cpp:105] Iteration 33200, lr = 0.01
I1014 01:28:53.801059 13701 solver.cpp:218] Iteration 33300 (3.27139 iter/s, 30.5681s/100 iters), loss = 0.459648
I1014 01:28:53.801209 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459649 (* 1 = 0.459649 loss)
I1014 01:28:53.801216 13701 sgd_solver.cpp:105] Iteration 33300, lr = 0.01
I1014 01:29:24.425511 13701 solver.cpp:218] Iteration 33400 (3.26538 iter/s, 30.6243s/100 iters), loss = 0.201665
I1014 01:29:24.425648 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201666 (* 1 = 0.201666 loss)
I1014 01:29:24.425657 13701 sgd_solver.cpp:105] Iteration 33400, lr = 0.01
I1014 01:29:54.719784 13701 solver.cpp:330] Iteration 33500, Testing net (#0)
I1014 01:30:11.367133 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:30:11.708457 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61851 (* 1 = 1.61851 loss)
I1014 01:30:11.708473 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6468
I1014 01:30:12.012835 13701 solver.cpp:218] Iteration 33500 (2.10141 iter/s, 47.5872s/100 iters), loss = 0.338365
I1014 01:30:12.012866 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338367 (* 1 = 0.338367 loss)
I1014 01:30:12.012871 13701 sgd_solver.cpp:105] Iteration 33500, lr = 0.01
I1014 01:30:42.708652 13701 solver.cpp:218] Iteration 33600 (3.25778 iter/s, 30.6958s/100 iters), loss = 0.374303
I1014 01:30:42.708776 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374304 (* 1 = 0.374304 loss)
I1014 01:30:42.708786 13701 sgd_solver.cpp:105] Iteration 33600, lr = 0.01
I1014 01:31:13.332849 13701 solver.cpp:218] Iteration 33700 (3.2654 iter/s, 30.6241s/100 iters), loss = 0.259076
I1014 01:31:13.332988 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259077 (* 1 = 0.259077 loss)
I1014 01:31:13.332993 13701 sgd_solver.cpp:105] Iteration 33700, lr = 0.01
I1014 01:31:43.931030 13701 solver.cpp:218] Iteration 33800 (3.26818 iter/s, 30.5981s/100 iters), loss = 0.236763
I1014 01:31:43.931172 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236764 (* 1 = 0.236764 loss)
I1014 01:31:43.931181 13701 sgd_solver.cpp:105] Iteration 33800, lr = 0.01
I1014 01:32:14.602749 13701 solver.cpp:218] Iteration 33900 (3.26035 iter/s, 30.6716s/100 iters), loss = 0.246343
I1014 01:32:14.602913 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246344 (* 1 = 0.246344 loss)
I1014 01:32:14.602922 13701 sgd_solver.cpp:105] Iteration 33900, lr = 0.01
I1014 01:32:43.766507 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:32:44.988626 13701 solver.cpp:330] Iteration 34000, Testing net (#0)
I1014 01:33:01.648185 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:33:01.988425 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63337 (* 1 = 1.63337 loss)
I1014 01:33:01.988440 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6482
I1014 01:33:02.294291 13701 solver.cpp:218] Iteration 34000 (2.09681 iter/s, 47.6914s/100 iters), loss = 0.420891
I1014 01:33:02.294322 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420892 (* 1 = 0.420892 loss)
I1014 01:33:02.294329 13701 sgd_solver.cpp:105] Iteration 34000, lr = 0.01
I1014 01:33:32.889688 13701 solver.cpp:218] Iteration 34100 (3.26847 iter/s, 30.5954s/100 iters), loss = 0.554298
I1014 01:33:32.889787 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.5543 (* 1 = 0.5543 loss)
I1014 01:33:32.889806 13701 sgd_solver.cpp:105] Iteration 34100, lr = 0.01
I1014 01:34:03.506808 13701 solver.cpp:218] Iteration 34200 (3.26616 iter/s, 30.617s/100 iters), loss = 0.21413
I1014 01:34:03.506940 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214132 (* 1 = 0.214132 loss)
I1014 01:34:03.506956 13701 sgd_solver.cpp:105] Iteration 34200, lr = 0.01
I1014 01:34:34.112825 13701 solver.cpp:218] Iteration 34300 (3.26734 iter/s, 30.6059s/100 iters), loss = 0.294796
I1014 01:34:34.112972 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294797 (* 1 = 0.294797 loss)
I1014 01:34:34.112979 13701 sgd_solver.cpp:105] Iteration 34300, lr = 0.01
I1014 01:35:04.696828 13701 solver.cpp:218] Iteration 34400 (3.2697 iter/s, 30.5839s/100 iters), loss = 0.209814
I1014 01:35:04.696965 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209815 (* 1 = 0.209815 loss)
I1014 01:35:04.696974 13701 sgd_solver.cpp:105] Iteration 34400, lr = 0.01
I1014 01:35:34.978502 13701 solver.cpp:330] Iteration 34500, Testing net (#0)
I1014 01:35:51.625577 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:35:51.965626 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57445 (* 1 = 1.57445 loss)
I1014 01:35:51.965642 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6538
I1014 01:35:52.267655 13701 solver.cpp:218] Iteration 34500 (2.10213 iter/s, 47.5707s/100 iters), loss = 0.287405
I1014 01:35:52.267684 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287406 (* 1 = 0.287406 loss)
I1014 01:35:52.267691 13701 sgd_solver.cpp:105] Iteration 34500, lr = 0.01
I1014 01:36:22.837296 13701 solver.cpp:218] Iteration 34600 (3.27122 iter/s, 30.5696s/100 iters), loss = 0.223522
I1014 01:36:22.837419 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223523 (* 1 = 0.223523 loss)
I1014 01:36:22.837426 13701 sgd_solver.cpp:105] Iteration 34600, lr = 0.01
I1014 01:36:53.451619 13701 solver.cpp:218] Iteration 34700 (3.26646 iter/s, 30.6142s/100 iters), loss = 0.192109
I1014 01:36:53.451769 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19211 (* 1 = 0.19211 loss)
I1014 01:36:53.451776 13701 sgd_solver.cpp:105] Iteration 34700, lr = 0.01
I1014 01:37:24.052351 13701 solver.cpp:218] Iteration 34800 (3.26791 iter/s, 30.6006s/100 iters), loss = 0.155215
I1014 01:37:24.052460 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155216 (* 1 = 0.155216 loss)
I1014 01:37:24.052477 13701 sgd_solver.cpp:105] Iteration 34800, lr = 0.01
I1014 01:37:54.660646 13701 solver.cpp:218] Iteration 34900 (3.2671 iter/s, 30.6082s/100 iters), loss = 0.333582
I1014 01:37:54.660791 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333583 (* 1 = 0.333583 loss)
I1014 01:37:54.660800 13701 sgd_solver.cpp:105] Iteration 34900, lr = 0.01
I1014 01:38:23.744326 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:38:24.963739 13701 solver.cpp:330] Iteration 35000, Testing net (#0)
I1014 01:38:41.610714 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:38:41.951165 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58829 (* 1 = 1.58829 loss)
I1014 01:38:41.951180 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6448
I1014 01:38:42.253666 13701 solver.cpp:218] Iteration 35000 (2.10115 iter/s, 47.5929s/100 iters), loss = 0.312771
I1014 01:38:42.253695 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312772 (* 1 = 0.312772 loss)
I1014 01:38:42.253701 13701 sgd_solver.cpp:105] Iteration 35000, lr = 0.01
I1014 01:39:12.828477 13701 solver.cpp:218] Iteration 35100 (3.27067 iter/s, 30.5748s/100 iters), loss = 0.262698
I1014 01:39:12.828599 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262699 (* 1 = 0.262699 loss)
I1014 01:39:12.828608 13701 sgd_solver.cpp:105] Iteration 35100, lr = 0.01
I1014 01:39:43.422179 13701 solver.cpp:218] Iteration 35200 (3.26866 iter/s, 30.5936s/100 iters), loss = 0.305741
I1014 01:39:43.422322 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305743 (* 1 = 0.305743 loss)
I1014 01:39:43.422329 13701 sgd_solver.cpp:105] Iteration 35200, lr = 0.01
I1014 01:40:13.988811 13701 solver.cpp:218] Iteration 35300 (3.27156 iter/s, 30.5665s/100 iters), loss = 0.0704181
I1014 01:40:13.988977 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0704194 (* 1 = 0.0704194 loss)
I1014 01:40:13.988986 13701 sgd_solver.cpp:105] Iteration 35300, lr = 0.01
I1014 01:40:44.606113 13701 solver.cpp:218] Iteration 35400 (3.26614 iter/s, 30.6172s/100 iters), loss = 0.223884
I1014 01:40:44.606220 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223885 (* 1 = 0.223885 loss)
I1014 01:40:44.606226 13701 sgd_solver.cpp:105] Iteration 35400, lr = 0.01
I1014 01:41:14.918822 13701 solver.cpp:330] Iteration 35500, Testing net (#0)
I1014 01:41:31.560886 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:41:31.899752 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61722 (* 1 = 1.61722 loss)
I1014 01:41:31.899768 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6443
I1014 01:41:32.200078 13701 solver.cpp:218] Iteration 35500 (2.10111 iter/s, 47.5939s/100 iters), loss = 0.273007
I1014 01:41:32.200106 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273009 (* 1 = 0.273009 loss)
I1014 01:41:32.200114 13701 sgd_solver.cpp:105] Iteration 35500, lr = 0.01
I1014 01:42:02.768436 13701 solver.cpp:218] Iteration 35600 (3.27136 iter/s, 30.5683s/100 iters), loss = 0.559177
I1014 01:42:02.768574 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.559178 (* 1 = 0.559178 loss)
I1014 01:42:02.768582 13701 sgd_solver.cpp:105] Iteration 35600, lr = 0.01
I1014 01:42:33.367481 13701 solver.cpp:218] Iteration 35700 (3.26809 iter/s, 30.5989s/100 iters), loss = 0.411079
I1014 01:42:33.367573 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41108 (* 1 = 0.41108 loss)
I1014 01:42:33.367579 13701 sgd_solver.cpp:105] Iteration 35700, lr = 0.01
I1014 01:43:03.962916 13701 solver.cpp:218] Iteration 35800 (3.26847 iter/s, 30.5954s/100 iters), loss = 0.10269
I1014 01:43:03.963016 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102692 (* 1 = 0.102692 loss)
I1014 01:43:03.963024 13701 sgd_solver.cpp:105] Iteration 35800, lr = 0.01
I1014 01:43:34.524710 13701 solver.cpp:218] Iteration 35900 (3.27207 iter/s, 30.5617s/100 iters), loss = 0.23647
I1014 01:43:34.524799 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236472 (* 1 = 0.236472 loss)
I1014 01:43:34.524822 13701 sgd_solver.cpp:105] Iteration 35900, lr = 0.01
I1014 01:44:03.596987 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:44:04.831302 13701 solver.cpp:330] Iteration 36000, Testing net (#0)
I1014 01:44:21.440515 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:44:21.783005 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56178 (* 1 = 1.56178 loss)
I1014 01:44:21.783020 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6574
I1014 01:44:22.086082 13701 solver.cpp:218] Iteration 36000 (2.10255 iter/s, 47.5613s/100 iters), loss = 0.0643432
I1014 01:44:22.086113 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0643443 (* 1 = 0.0643443 loss)
I1014 01:44:22.086120 13701 sgd_solver.cpp:105] Iteration 36000, lr = 0.01
I1014 01:44:52.745126 13701 solver.cpp:218] Iteration 36100 (3.26168 iter/s, 30.659s/100 iters), loss = 0.121695
I1014 01:44:52.745282 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121696 (* 1 = 0.121696 loss)
I1014 01:44:52.745291 13701 sgd_solver.cpp:105] Iteration 36100, lr = 0.01
I1014 01:45:23.327090 13701 solver.cpp:218] Iteration 36200 (3.26992 iter/s, 30.5818s/100 iters), loss = 0.181571
I1014 01:45:23.327236 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181572 (* 1 = 0.181572 loss)
I1014 01:45:23.327245 13701 sgd_solver.cpp:105] Iteration 36200, lr = 0.01
I1014 01:45:53.877673 13701 solver.cpp:218] Iteration 36300 (3.27327 iter/s, 30.5504s/100 iters), loss = 0.505208
I1014 01:45:53.877774 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505209 (* 1 = 0.505209 loss)
I1014 01:45:53.877791 13701 sgd_solver.cpp:105] Iteration 36300, lr = 0.01
I1014 01:46:24.473460 13701 solver.cpp:218] Iteration 36400 (3.26843 iter/s, 30.5957s/100 iters), loss = 0.422666
I1014 01:46:24.473580 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422668 (* 1 = 0.422668 loss)
I1014 01:46:24.473588 13701 sgd_solver.cpp:105] Iteration 36400, lr = 0.01
I1014 01:46:54.747225 13701 solver.cpp:330] Iteration 36500, Testing net (#0)
I1014 01:47:11.381108 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:47:11.722218 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62961 (* 1 = 1.62961 loss)
I1014 01:47:11.722234 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6443
I1014 01:47:12.021981 13701 solver.cpp:218] Iteration 36500 (2.10312 iter/s, 47.5484s/100 iters), loss = 0.292134
I1014 01:47:12.022011 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292135 (* 1 = 0.292135 loss)
I1014 01:47:12.022017 13701 sgd_solver.cpp:105] Iteration 36500, lr = 0.01
I1014 01:47:42.634886 13701 solver.cpp:218] Iteration 36600 (3.2666 iter/s, 30.6129s/100 iters), loss = 0.33897
I1014 01:47:42.635022 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338971 (* 1 = 0.338971 loss)
I1014 01:47:42.635031 13701 sgd_solver.cpp:105] Iteration 36600, lr = 0.01
I1014 01:48:13.198714 13701 solver.cpp:218] Iteration 36700 (3.27186 iter/s, 30.5637s/100 iters), loss = 0.0838703
I1014 01:48:13.198858 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0838714 (* 1 = 0.0838714 loss)
I1014 01:48:13.198865 13701 sgd_solver.cpp:105] Iteration 36700, lr = 0.01
I1014 01:48:43.774643 13701 solver.cpp:218] Iteration 36800 (3.27056 iter/s, 30.5758s/100 iters), loss = 0.143405
I1014 01:48:43.774786 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143406 (* 1 = 0.143406 loss)
I1014 01:48:43.774794 13701 sgd_solver.cpp:105] Iteration 36800, lr = 0.01
I1014 01:49:14.340039 13701 solver.cpp:218] Iteration 36900 (3.27169 iter/s, 30.5653s/100 iters), loss = 0.231152
I1014 01:49:14.340144 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231153 (* 1 = 0.231153 loss)
I1014 01:49:14.340162 13701 sgd_solver.cpp:105] Iteration 36900, lr = 0.01
I1014 01:49:43.368927 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:49:44.600766 13701 solver.cpp:330] Iteration 37000, Testing net (#0)
I1014 01:50:01.188618 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:50:01.530534 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62697 (* 1 = 1.62697 loss)
I1014 01:50:01.530550 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6459
I1014 01:50:01.836694 13701 solver.cpp:218] Iteration 37000 (2.10542 iter/s, 47.4966s/100 iters), loss = 0.170549
I1014 01:50:01.836725 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17055 (* 1 = 0.17055 loss)
I1014 01:50:01.836732 13701 sgd_solver.cpp:105] Iteration 37000, lr = 0.01
I1014 01:50:32.440527 13701 solver.cpp:218] Iteration 37100 (3.26757 iter/s, 30.6038s/100 iters), loss = 0.23193
I1014 01:50:32.440671 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231931 (* 1 = 0.231931 loss)
I1014 01:50:32.440680 13701 sgd_solver.cpp:105] Iteration 37100, lr = 0.01
I1014 01:51:03.004664 13701 solver.cpp:218] Iteration 37200 (3.27182 iter/s, 30.564s/100 iters), loss = 0.20153
I1014 01:51:03.004808 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201531 (* 1 = 0.201531 loss)
I1014 01:51:03.004817 13701 sgd_solver.cpp:105] Iteration 37200, lr = 0.01
I1014 01:51:33.579290 13701 solver.cpp:218] Iteration 37300 (3.2707 iter/s, 30.5745s/100 iters), loss = 0.167677
I1014 01:51:33.579401 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167678 (* 1 = 0.167678 loss)
I1014 01:51:33.579408 13701 sgd_solver.cpp:105] Iteration 37300, lr = 0.01
I1014 01:52:04.157843 13701 solver.cpp:218] Iteration 37400 (3.27028 iter/s, 30.5785s/100 iters), loss = 0.222817
I1014 01:52:04.157977 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222819 (* 1 = 0.222819 loss)
I1014 01:52:04.157995 13701 sgd_solver.cpp:105] Iteration 37400, lr = 0.01
I1014 01:52:34.512890 13701 solver.cpp:330] Iteration 37500, Testing net (#0)
I1014 01:52:51.119045 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:52:51.461367 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57295 (* 1 = 1.57295 loss)
I1014 01:52:51.461383 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6499
I1014 01:52:51.762720 13701 solver.cpp:218] Iteration 37500 (2.10063 iter/s, 47.6048s/100 iters), loss = 0.156858
I1014 01:52:51.762749 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156859 (* 1 = 0.156859 loss)
I1014 01:52:51.762756 13701 sgd_solver.cpp:105] Iteration 37500, lr = 0.01
I1014 01:53:22.377760 13701 solver.cpp:218] Iteration 37600 (3.26637 iter/s, 30.615s/100 iters), loss = 0.249634
I1014 01:53:22.377900 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249635 (* 1 = 0.249635 loss)
I1014 01:53:22.377908 13701 sgd_solver.cpp:105] Iteration 37600, lr = 0.01
I1014 01:53:52.967037 13701 solver.cpp:218] Iteration 37700 (3.26913 iter/s, 30.5891s/100 iters), loss = 0.332435
I1014 01:53:52.967136 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332437 (* 1 = 0.332437 loss)
I1014 01:53:52.967154 13701 sgd_solver.cpp:105] Iteration 37700, lr = 0.01
I1014 01:54:23.584295 13701 solver.cpp:218] Iteration 37800 (3.26614 iter/s, 30.6172s/100 iters), loss = 0.156592
I1014 01:54:23.586236 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156593 (* 1 = 0.156593 loss)
I1014 01:54:23.586246 13701 sgd_solver.cpp:105] Iteration 37800, lr = 0.01
I1014 01:54:54.191401 13701 solver.cpp:218] Iteration 37900 (3.26742 iter/s, 30.6052s/100 iters), loss = 0.440842
I1014 01:54:54.191491 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440843 (* 1 = 0.440843 loss)
I1014 01:54:54.191509 13701 sgd_solver.cpp:105] Iteration 37900, lr = 0.01
I1014 01:55:23.282678 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:55:24.514585 13701 solver.cpp:330] Iteration 38000, Testing net (#0)
I1014 01:55:41.114756 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:55:41.457926 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60293 (* 1 = 1.60293 loss)
I1014 01:55:41.457942 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6483
I1014 01:55:41.759368 13701 solver.cpp:218] Iteration 38000 (2.10226 iter/s, 47.5679s/100 iters), loss = 0.130435
I1014 01:55:41.759402 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130437 (* 1 = 0.130437 loss)
I1014 01:55:41.759418 13701 sgd_solver.cpp:105] Iteration 38000, lr = 0.01
I1014 01:56:12.303063 13701 solver.cpp:218] Iteration 38100 (3.274 iter/s, 30.5437s/100 iters), loss = 0.303739
I1014 01:56:12.303172 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303741 (* 1 = 0.303741 loss)
I1014 01:56:12.303179 13701 sgd_solver.cpp:105] Iteration 38100, lr = 0.01
I1014 01:56:42.887241 13701 solver.cpp:218] Iteration 38200 (3.26967 iter/s, 30.5841s/100 iters), loss = 0.330034
I1014 01:56:42.887712 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330035 (* 1 = 0.330035 loss)
I1014 01:56:42.887722 13701 sgd_solver.cpp:105] Iteration 38200, lr = 0.01
I1014 01:57:13.465778 13701 solver.cpp:218] Iteration 38300 (3.27032 iter/s, 30.5781s/100 iters), loss = 0.133345
I1014 01:57:13.465922 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133346 (* 1 = 0.133346 loss)
I1014 01:57:13.465929 13701 sgd_solver.cpp:105] Iteration 38300, lr = 0.01
I1014 01:57:44.013581 13701 solver.cpp:218] Iteration 38400 (3.27357 iter/s, 30.5477s/100 iters), loss = 0.289634
I1014 01:57:44.013923 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289635 (* 1 = 0.289635 loss)
I1014 01:57:44.013947 13701 sgd_solver.cpp:105] Iteration 38400, lr = 0.01
I1014 01:58:14.302354 13701 solver.cpp:330] Iteration 38500, Testing net (#0)
I1014 01:58:30.953295 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 01:58:31.296684 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53186 (* 1 = 1.53186 loss)
I1014 01:58:31.296700 13701 solver.cpp:397]     Test net output #1: accuracy = 0.659
I1014 01:58:31.596735 13701 solver.cpp:218] Iteration 38500 (2.1016 iter/s, 47.5828s/100 iters), loss = 0.287763
I1014 01:58:31.596770 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287764 (* 1 = 0.287764 loss)
I1014 01:58:31.596776 13701 sgd_solver.cpp:105] Iteration 38500, lr = 0.01
I1014 01:59:02.159240 13701 solver.cpp:218] Iteration 38600 (3.27199 iter/s, 30.5625s/100 iters), loss = 0.127637
I1014 01:59:02.159380 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127638 (* 1 = 0.127638 loss)
I1014 01:59:02.159389 13701 sgd_solver.cpp:105] Iteration 38600, lr = 0.01
I1014 01:59:32.747181 13701 solver.cpp:218] Iteration 38700 (3.26928 iter/s, 30.5878s/100 iters), loss = 0.334366
I1014 01:59:32.747315 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334367 (* 1 = 0.334367 loss)
I1014 01:59:32.747323 13701 sgd_solver.cpp:105] Iteration 38700, lr = 0.01
I1014 02:00:03.307660 13701 solver.cpp:218] Iteration 38800 (3.27221 iter/s, 30.5604s/100 iters), loss = 0.130307
I1014 02:00:03.307811 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130308 (* 1 = 0.130308 loss)
I1014 02:00:03.307821 13701 sgd_solver.cpp:105] Iteration 38800, lr = 0.01
I1014 02:00:33.896945 13701 solver.cpp:218] Iteration 38900 (3.26913 iter/s, 30.5891s/100 iters), loss = 0.139384
I1014 02:00:33.897089 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139385 (* 1 = 0.139385 loss)
I1014 02:00:33.897097 13701 sgd_solver.cpp:105] Iteration 38900, lr = 0.01
I1014 02:01:02.969230 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:01:04.190932 13701 solver.cpp:330] Iteration 39000, Testing net (#0)
I1014 02:01:20.845098 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:01:21.183495 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.65143 (* 1 = 1.65143 loss)
I1014 02:01:21.183509 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6427
I1014 02:01:21.484731 13701 solver.cpp:218] Iteration 39000 (2.10139 iter/s, 47.5877s/100 iters), loss = 0.140142
I1014 02:01:21.484764 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140143 (* 1 = 0.140143 loss)
I1014 02:01:21.484771 13701 sgd_solver.cpp:105] Iteration 39000, lr = 0.01
I1014 02:01:52.020866 13701 solver.cpp:218] Iteration 39100 (3.27481 iter/s, 30.5361s/100 iters), loss = 0.311462
I1014 02:01:52.020989 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311463 (* 1 = 0.311463 loss)
I1014 02:01:52.021006 13701 sgd_solver.cpp:105] Iteration 39100, lr = 0.01
I1014 02:02:22.557235 13701 solver.cpp:218] Iteration 39200 (3.2748 iter/s, 30.5363s/100 iters), loss = 0.260257
I1014 02:02:22.558095 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260258 (* 1 = 0.260258 loss)
I1014 02:02:22.558104 13701 sgd_solver.cpp:105] Iteration 39200, lr = 0.01
I1014 02:02:53.108817 13701 solver.cpp:218] Iteration 39300 (3.27324 iter/s, 30.5507s/100 iters), loss = 0.135151
I1014 02:02:53.108917 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135152 (* 1 = 0.135152 loss)
I1014 02:02:53.108934 13701 sgd_solver.cpp:105] Iteration 39300, lr = 0.01
I1014 02:03:23.688139 13701 solver.cpp:218] Iteration 39400 (3.27019 iter/s, 30.5792s/100 iters), loss = 0.32016
I1014 02:03:23.688283 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320161 (* 1 = 0.320161 loss)
I1014 02:03:23.688292 13701 sgd_solver.cpp:105] Iteration 39400, lr = 0.01
I1014 02:03:53.963471 13701 solver.cpp:330] Iteration 39500, Testing net (#0)
I1014 02:04:10.594748 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:04:10.934842 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58659 (* 1 = 1.58659 loss)
I1014 02:04:10.934857 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6476
I1014 02:04:11.237505 13701 solver.cpp:218] Iteration 39500 (2.10308 iter/s, 47.5492s/100 iters), loss = 0.337159
I1014 02:04:11.237536 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33716 (* 1 = 0.33716 loss)
I1014 02:04:11.237542 13701 sgd_solver.cpp:105] Iteration 39500, lr = 0.01
I1014 02:04:41.839131 13701 solver.cpp:218] Iteration 39600 (3.2678 iter/s, 30.6016s/100 iters), loss = 0.275876
I1014 02:04:41.839268 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275877 (* 1 = 0.275877 loss)
I1014 02:04:41.839277 13701 sgd_solver.cpp:105] Iteration 39600, lr = 0.01
I1014 02:05:12.438668 13701 solver.cpp:218] Iteration 39700 (3.26804 iter/s, 30.5994s/100 iters), loss = 0.319321
I1014 02:05:12.438808 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319322 (* 1 = 0.319322 loss)
I1014 02:05:12.438817 13701 sgd_solver.cpp:105] Iteration 39700, lr = 0.01
I1014 02:05:43.040112 13701 solver.cpp:218] Iteration 39800 (3.26783 iter/s, 30.6013s/100 iters), loss = 0.0894648
I1014 02:05:43.040251 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0894657 (* 1 = 0.0894657 loss)
I1014 02:05:43.040261 13701 sgd_solver.cpp:105] Iteration 39800, lr = 0.01
I1014 02:06:13.619168 13701 solver.cpp:218] Iteration 39900 (3.27023 iter/s, 30.5789s/100 iters), loss = 0.1498
I1014 02:06:13.619310 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149801 (* 1 = 0.149801 loss)
I1014 02:06:13.619319 13701 sgd_solver.cpp:105] Iteration 39900, lr = 0.01
I1014 02:06:42.677435 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:06:43.901664 13701 solver.cpp:330] Iteration 40000, Testing net (#0)
I1014 02:07:00.512159 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:07:00.850786 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58744 (* 1 = 1.58744 loss)
I1014 02:07:00.850803 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6523
I1014 02:07:01.154615 13701 solver.cpp:218] Iteration 40000 (2.1037 iter/s, 47.5353s/100 iters), loss = 0.246435
I1014 02:07:01.154646 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246436 (* 1 = 0.246436 loss)
I1014 02:07:01.154654 13701 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1014 02:07:31.726069 13701 solver.cpp:218] Iteration 40100 (3.27103 iter/s, 30.5714s/100 iters), loss = 0.360743
I1014 02:07:31.726212 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360745 (* 1 = 0.360745 loss)
I1014 02:07:31.726220 13701 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1014 02:08:02.255578 13701 solver.cpp:218] Iteration 40200 (3.27553 iter/s, 30.5294s/100 iters), loss = 0.171729
I1014 02:08:02.255621 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17173 (* 1 = 0.17173 loss)
I1014 02:08:02.255628 13701 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1014 02:08:32.799299 13701 solver.cpp:218] Iteration 40300 (3.274 iter/s, 30.5437s/100 iters), loss = 0.227507
I1014 02:08:32.799412 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227508 (* 1 = 0.227508 loss)
I1014 02:08:32.799419 13701 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1014 02:09:03.404191 13701 solver.cpp:218] Iteration 40400 (3.26746 iter/s, 30.6048s/100 iters), loss = 0.20171
I1014 02:09:03.404300 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201711 (* 1 = 0.201711 loss)
I1014 02:09:03.404307 13701 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1014 02:09:33.729162 13701 solver.cpp:330] Iteration 40500, Testing net (#0)
I1014 02:09:50.379215 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:09:50.724347 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58618 (* 1 = 1.58618 loss)
I1014 02:09:50.724364 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6509
I1014 02:09:51.025733 13701 solver.cpp:218] Iteration 40500 (2.09989 iter/s, 47.6215s/100 iters), loss = 0.268625
I1014 02:09:51.025761 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268626 (* 1 = 0.268626 loss)
I1014 02:09:51.025768 13701 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1014 02:10:21.586078 13701 solver.cpp:218] Iteration 40600 (3.27222 iter/s, 30.5603s/100 iters), loss = 0.191347
I1014 02:10:21.586205 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191348 (* 1 = 0.191348 loss)
I1014 02:10:21.586220 13701 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1014 02:10:52.109472 13701 solver.cpp:218] Iteration 40700 (3.27619 iter/s, 30.5233s/100 iters), loss = 0.199205
I1014 02:10:52.109587 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199206 (* 1 = 0.199206 loss)
I1014 02:10:52.109594 13701 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1014 02:11:22.666470 13701 solver.cpp:218] Iteration 40800 (3.27258 iter/s, 30.5569s/100 iters), loss = 0.147168
I1014 02:11:22.666620 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147169 (* 1 = 0.147169 loss)
I1014 02:11:22.666630 13701 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1014 02:11:53.234833 13701 solver.cpp:218] Iteration 40900 (3.27137 iter/s, 30.5682s/100 iters), loss = 0.333864
I1014 02:11:53.234982 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333865 (* 1 = 0.333865 loss)
I1014 02:11:53.234989 13701 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1014 02:12:22.290843 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:12:23.511991 13701 solver.cpp:330] Iteration 41000, Testing net (#0)
I1014 02:12:40.153960 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:12:40.494237 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59322 (* 1 = 1.59322 loss)
I1014 02:12:40.494252 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6507
I1014 02:12:40.798210 13701 solver.cpp:218] Iteration 41000 (2.10246 iter/s, 47.5632s/100 iters), loss = 0.0703666
I1014 02:12:40.798246 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0703677 (* 1 = 0.0703677 loss)
I1014 02:12:40.798254 13701 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1014 02:13:11.332476 13701 solver.cpp:218] Iteration 41100 (3.27501 iter/s, 30.5342s/100 iters), loss = 0.20869
I1014 02:13:11.332571 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208692 (* 1 = 0.208692 loss)
I1014 02:13:11.332578 13701 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1014 02:13:41.898345 13701 solver.cpp:218] Iteration 41200 (3.27163 iter/s, 30.5658s/100 iters), loss = 0.175769
I1014 02:13:41.898486 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17577 (* 1 = 0.17577 loss)
I1014 02:13:41.898495 13701 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1014 02:14:12.461794 13701 solver.cpp:218] Iteration 41300 (3.2719 iter/s, 30.5633s/100 iters), loss = 0.208747
I1014 02:14:12.461905 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208748 (* 1 = 0.208748 loss)
I1014 02:14:12.461912 13701 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1014 02:14:43.035696 13701 solver.cpp:218] Iteration 41400 (3.27077 iter/s, 30.5738s/100 iters), loss = 0.2044
I1014 02:14:43.035856 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204401 (* 1 = 0.204401 loss)
I1014 02:14:43.035866 13701 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1014 02:15:13.329028 13701 solver.cpp:330] Iteration 41500, Testing net (#0)
I1014 02:15:29.925346 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:15:30.265141 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55361 (* 1 = 1.55361 loss)
I1014 02:15:30.265157 13701 solver.cpp:397]     Test net output #1: accuracy = 0.656
I1014 02:15:30.565625 13701 solver.cpp:218] Iteration 41500 (2.10394 iter/s, 47.5298s/100 iters), loss = 0.247467
I1014 02:15:30.565661 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247468 (* 1 = 0.247468 loss)
I1014 02:15:30.565668 13701 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1014 02:16:01.174232 13701 solver.cpp:218] Iteration 41600 (3.26706 iter/s, 30.6086s/100 iters), loss = 0.322387
I1014 02:16:01.174407 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322388 (* 1 = 0.322388 loss)
I1014 02:16:01.174417 13701 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1014 02:16:31.681828 13701 solver.cpp:218] Iteration 41700 (3.27789 iter/s, 30.5074s/100 iters), loss = 0.246069
I1014 02:16:31.681928 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24607 (* 1 = 0.24607 loss)
I1014 02:16:31.681936 13701 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1014 02:17:02.224611 13701 solver.cpp:218] Iteration 41800 (3.27411 iter/s, 30.5427s/100 iters), loss = 0.0875873
I1014 02:17:02.224706 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0875884 (* 1 = 0.0875884 loss)
I1014 02:17:02.224714 13701 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1014 02:17:32.745543 13701 solver.cpp:218] Iteration 41900 (3.27645 iter/s, 30.5208s/100 iters), loss = 0.223154
I1014 02:17:32.745668 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223155 (* 1 = 0.223155 loss)
I1014 02:17:32.745676 13701 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1014 02:18:01.782948 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:18:03.005028 13701 solver.cpp:330] Iteration 42000, Testing net (#0)
I1014 02:18:19.660890 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:18:20.000300 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61629 (* 1 = 1.61629 loss)
I1014 02:18:20.000316 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6527
I1014 02:18:20.299763 13701 solver.cpp:218] Iteration 42000 (2.10287 iter/s, 47.5541s/100 iters), loss = 0.348349
I1014 02:18:20.299803 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34835 (* 1 = 0.34835 loss)
I1014 02:18:20.299809 13701 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1014 02:18:50.868454 13701 solver.cpp:218] Iteration 42100 (3.27132 iter/s, 30.5687s/100 iters), loss = 0.358722
I1014 02:18:50.868598 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358724 (* 1 = 0.358724 loss)
I1014 02:18:50.868605 13701 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1014 02:19:21.444985 13701 solver.cpp:218] Iteration 42200 (3.2705 iter/s, 30.5764s/100 iters), loss = 0.179711
I1014 02:19:21.445121 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179712 (* 1 = 0.179712 loss)
I1014 02:19:21.445128 13701 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1014 02:19:51.995741 13701 solver.cpp:218] Iteration 42300 (3.27326 iter/s, 30.5506s/100 iters), loss = 0.19811
I1014 02:19:51.995882 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198111 (* 1 = 0.198111 loss)
I1014 02:19:51.995890 13701 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1014 02:20:22.584790 13701 solver.cpp:218] Iteration 42400 (3.26916 iter/s, 30.5889s/100 iters), loss = 0.271952
I1014 02:20:22.584902 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271953 (* 1 = 0.271953 loss)
I1014 02:20:22.584921 13701 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1014 02:20:52.825880 13701 solver.cpp:330] Iteration 42500, Testing net (#0)
I1014 02:21:09.448318 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:21:09.790158 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60749 (* 1 = 1.60749 loss)
I1014 02:21:09.790174 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6507
I1014 02:21:10.093041 13701 solver.cpp:218] Iteration 42500 (2.1049 iter/s, 47.5082s/100 iters), loss = 0.202004
I1014 02:21:10.093071 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202005 (* 1 = 0.202005 loss)
I1014 02:21:10.093078 13701 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1014 02:21:40.696239 13701 solver.cpp:218] Iteration 42600 (3.26764 iter/s, 30.6032s/100 iters), loss = 0.151022
I1014 02:21:40.696393 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151024 (* 1 = 0.151024 loss)
I1014 02:21:40.696400 13701 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1014 02:22:11.308696 13701 solver.cpp:218] Iteration 42700 (3.26666 iter/s, 30.6123s/100 iters), loss = 0.186528
I1014 02:22:11.308809 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186529 (* 1 = 0.186529 loss)
I1014 02:22:11.308816 13701 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1014 02:22:41.821966 13701 solver.cpp:218] Iteration 42800 (3.27727 iter/s, 30.5132s/100 iters), loss = 0.251971
I1014 02:22:41.822099 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251972 (* 1 = 0.251972 loss)
I1014 02:22:41.822108 13701 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1014 02:23:12.432358 13701 solver.cpp:218] Iteration 42900 (3.26688 iter/s, 30.6103s/100 iters), loss = 0.322608
I1014 02:23:12.432457 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322609 (* 1 = 0.322609 loss)
I1014 02:23:12.432474 13701 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1014 02:23:41.515204 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:23:42.742300 13701 solver.cpp:330] Iteration 43000, Testing net (#0)
I1014 02:23:59.351639 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:23:59.691002 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60526 (* 1 = 1.60526 loss)
I1014 02:23:59.691018 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6532
I1014 02:23:59.992897 13701 solver.cpp:218] Iteration 43000 (2.10259 iter/s, 47.5605s/100 iters), loss = 0.113362
I1014 02:23:59.992926 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113364 (* 1 = 0.113364 loss)
I1014 02:23:59.992933 13701 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1014 02:24:30.560731 13701 solver.cpp:218] Iteration 43100 (3.27142 iter/s, 30.5678s/100 iters), loss = 0.143171
I1014 02:24:30.560860 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143172 (* 1 = 0.143172 loss)
I1014 02:24:30.560868 13701 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1014 02:25:01.130623 13701 solver.cpp:218] Iteration 43200 (3.27121 iter/s, 30.5698s/100 iters), loss = 0.24283
I1014 02:25:01.130708 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242831 (* 1 = 0.242831 loss)
I1014 02:25:01.130720 13701 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1014 02:25:31.754496 13701 solver.cpp:218] Iteration 43300 (3.26543 iter/s, 30.6238s/100 iters), loss = 0.114971
I1014 02:25:31.754622 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114972 (* 1 = 0.114972 loss)
I1014 02:25:31.754631 13701 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1014 02:26:02.336283 13701 solver.cpp:218] Iteration 43400 (3.26993 iter/s, 30.5817s/100 iters), loss = 0.359202
I1014 02:26:02.336378 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359203 (* 1 = 0.359203 loss)
I1014 02:26:02.336385 13701 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1014 02:26:32.639278 13701 solver.cpp:330] Iteration 43500, Testing net (#0)
I1014 02:26:49.296649 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:26:49.637699 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60439 (* 1 = 1.60439 loss)
I1014 02:26:49.637717 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6446
I1014 02:26:49.942109 13701 solver.cpp:218] Iteration 43500 (2.10059 iter/s, 47.6057s/100 iters), loss = 0.167251
I1014 02:26:49.942139 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167252 (* 1 = 0.167252 loss)
I1014 02:26:49.942147 13701 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1014 02:27:20.520457 13701 solver.cpp:218] Iteration 43600 (3.27029 iter/s, 30.5783s/100 iters), loss = 0.212119
I1014 02:27:20.520596 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21212 (* 1 = 0.21212 loss)
I1014 02:27:20.520603 13701 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1014 02:27:51.091447 13701 solver.cpp:218] Iteration 43700 (3.27109 iter/s, 30.5709s/100 iters), loss = 0.102933
I1014 02:27:51.091598 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102934 (* 1 = 0.102934 loss)
I1014 02:27:51.091605 13701 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1014 02:28:21.656518 13701 solver.cpp:218] Iteration 43800 (3.27172 iter/s, 30.5649s/100 iters), loss = 0.0424409
I1014 02:28:21.656666 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0424418 (* 1 = 0.0424418 loss)
I1014 02:28:21.656674 13701 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1014 02:28:52.217298 13701 solver.cpp:218] Iteration 43900 (3.27218 iter/s, 30.5606s/100 iters), loss = 0.306096
I1014 02:28:52.217450 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306097 (* 1 = 0.306097 loss)
I1014 02:28:52.217470 13701 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1014 02:29:21.288889 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:29:22.513056 13701 solver.cpp:330] Iteration 44000, Testing net (#0)
I1014 02:29:39.115219 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:29:39.457859 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62524 (* 1 = 1.62524 loss)
I1014 02:29:39.457875 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6513
I1014 02:29:39.760615 13701 solver.cpp:218] Iteration 44000 (2.10335 iter/s, 47.5432s/100 iters), loss = 0.103239
I1014 02:29:39.760653 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10324 (* 1 = 0.10324 loss)
I1014 02:29:39.760661 13701 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1014 02:30:10.358256 13701 solver.cpp:218] Iteration 44100 (3.26823 iter/s, 30.5976s/100 iters), loss = 0.262321
I1014 02:30:10.358397 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262322 (* 1 = 0.262322 loss)
I1014 02:30:10.358405 13701 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1014 02:30:40.939774 13701 solver.cpp:218] Iteration 44200 (3.26996 iter/s, 30.5814s/100 iters), loss = 0.270941
I1014 02:30:40.939867 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270942 (* 1 = 0.270942 loss)
I1014 02:30:40.939873 13701 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1014 02:31:11.541749 13701 solver.cpp:218] Iteration 44300 (3.26777 iter/s, 30.6019s/100 iters), loss = 0.071207
I1014 02:31:11.541936 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712079 (* 1 = 0.0712079 loss)
I1014 02:31:11.541947 13701 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1014 02:31:42.127871 13701 solver.cpp:218] Iteration 44400 (3.26947 iter/s, 30.586s/100 iters), loss = 0.125045
I1014 02:31:42.127982 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125046 (* 1 = 0.125046 loss)
I1014 02:31:42.127990 13701 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1014 02:32:12.377866 13701 solver.cpp:330] Iteration 44500, Testing net (#0)
I1014 02:32:29.010211 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:32:29.349452 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53035 (* 1 = 1.53035 loss)
I1014 02:32:29.349467 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6602
I1014 02:32:29.651924 13701 solver.cpp:218] Iteration 44500 (2.1042 iter/s, 47.524s/100 iters), loss = 0.218013
I1014 02:32:29.651959 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218014 (* 1 = 0.218014 loss)
I1014 02:32:29.651968 13701 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1014 02:33:00.231647 13701 solver.cpp:218] Iteration 44600 (3.27014 iter/s, 30.5797s/100 iters), loss = 0.15936
I1014 02:33:00.231745 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159361 (* 1 = 0.159361 loss)
I1014 02:33:00.231763 13701 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1014 02:33:30.836361 13701 solver.cpp:218] Iteration 44700 (3.26748 iter/s, 30.6046s/100 iters), loss = 0.176566
I1014 02:33:30.836509 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176567 (* 1 = 0.176567 loss)
I1014 02:33:30.836519 13701 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1014 02:34:01.472381 13701 solver.cpp:218] Iteration 44800 (3.26415 iter/s, 30.6359s/100 iters), loss = 0.299099
I1014 02:34:01.472527 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2991 (* 1 = 0.2991 loss)
I1014 02:34:01.472538 13701 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1014 02:34:32.117019 13701 solver.cpp:218] Iteration 44900 (3.26323 iter/s, 30.6445s/100 iters), loss = 0.15202
I1014 02:34:32.117156 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152021 (* 1 = 0.152021 loss)
I1014 02:34:32.117164 13701 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1014 02:35:01.235551 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:35:02.468590 13701 solver.cpp:330] Iteration 45000, Testing net (#0)
I1014 02:35:19.084883 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:35:19.423508 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58112 (* 1 = 1.58112 loss)
I1014 02:35:19.423524 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6531
I1014 02:35:19.723947 13701 solver.cpp:218] Iteration 45000 (2.10054 iter/s, 47.6068s/100 iters), loss = 0.188698
I1014 02:35:19.723984 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188699 (* 1 = 0.188699 loss)
I1014 02:35:19.723992 13701 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1014 02:35:50.350682 13701 solver.cpp:218] Iteration 45100 (3.26512 iter/s, 30.6267s/100 iters), loss = 0.179711
I1014 02:35:50.350824 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179712 (* 1 = 0.179712 loss)
I1014 02:35:50.350833 13701 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1014 02:36:20.989678 13701 solver.cpp:218] Iteration 45200 (3.26383 iter/s, 30.6389s/100 iters), loss = 0.168368
I1014 02:36:20.989804 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168369 (* 1 = 0.168369 loss)
I1014 02:36:20.989811 13701 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1014 02:36:51.570277 13701 solver.cpp:218] Iteration 45300 (3.27006 iter/s, 30.5805s/100 iters), loss = 0.170839
I1014 02:36:51.570402 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17084 (* 1 = 0.17084 loss)
I1014 02:36:51.570413 13701 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1014 02:37:22.183025 13701 solver.cpp:218] Iteration 45400 (3.26662 iter/s, 30.6126s/100 iters), loss = 0.19305
I1014 02:37:22.183135 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193051 (* 1 = 0.193051 loss)
I1014 02:37:22.183152 13701 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1014 02:37:52.511445 13701 solver.cpp:330] Iteration 45500, Testing net (#0)
I1014 02:38:09.130887 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:38:09.474488 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61761 (* 1 = 1.61761 loss)
I1014 02:38:09.474504 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6467
I1014 02:38:09.779742 13701 solver.cpp:218] Iteration 45500 (2.10099 iter/s, 47.5966s/100 iters), loss = 0.172818
I1014 02:38:09.779780 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172819 (* 1 = 0.172819 loss)
I1014 02:38:09.779788 13701 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1014 02:38:40.404839 13701 solver.cpp:218] Iteration 45600 (3.2653 iter/s, 30.6251s/100 iters), loss = 0.320094
I1014 02:38:40.404981 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320095 (* 1 = 0.320095 loss)
I1014 02:38:40.404990 13701 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1014 02:39:10.971989 13701 solver.cpp:218] Iteration 45700 (3.2715 iter/s, 30.567s/100 iters), loss = 0.23859
I1014 02:39:10.972100 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23859 (* 1 = 0.23859 loss)
I1014 02:39:10.972118 13701 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1014 02:39:41.523598 13701 solver.cpp:218] Iteration 45800 (3.27316 iter/s, 30.5515s/100 iters), loss = 0.123136
I1014 02:39:41.523720 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123137 (* 1 = 0.123137 loss)
I1014 02:39:41.523728 13701 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1014 02:40:12.129107 13701 solver.cpp:218] Iteration 45900 (3.2674 iter/s, 30.6054s/100 iters), loss = 0.243969
I1014 02:40:12.129176 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24397 (* 1 = 0.24397 loss)
I1014 02:40:12.129184 13701 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1014 02:40:41.174707 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:40:42.410377 13701 solver.cpp:330] Iteration 46000, Testing net (#0)
I1014 02:40:59.030477 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:40:59.370692 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57199 (* 1 = 1.57199 loss)
I1014 02:40:59.370707 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6587
I1014 02:40:59.670734 13701 solver.cpp:218] Iteration 46000 (2.10342 iter/s, 47.5416s/100 iters), loss = 0.194805
I1014 02:40:59.670771 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194806 (* 1 = 0.194806 loss)
I1014 02:40:59.670778 13701 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1014 02:41:30.241255 13701 solver.cpp:218] Iteration 46100 (3.27113 iter/s, 30.5705s/100 iters), loss = 0.159323
I1014 02:41:30.241400 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159324 (* 1 = 0.159324 loss)
I1014 02:41:30.241407 13701 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1014 02:42:00.842018 13701 solver.cpp:218] Iteration 46200 (3.26791 iter/s, 30.6006s/100 iters), loss = 0.362585
I1014 02:42:00.842133 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362586 (* 1 = 0.362586 loss)
I1014 02:42:00.842151 13701 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1014 02:42:31.372411 13701 solver.cpp:218] Iteration 46300 (3.27544 iter/s, 30.5303s/100 iters), loss = 0.285648
I1014 02:42:31.372506 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285649 (* 1 = 0.285649 loss)
I1014 02:42:31.372522 13701 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1014 02:43:02.010341 13701 solver.cpp:218] Iteration 46400 (3.26394 iter/s, 30.6378s/100 iters), loss = 0.203231
I1014 02:43:02.010471 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203232 (* 1 = 0.203232 loss)
I1014 02:43:02.010480 13701 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1014 02:43:32.300560 13701 solver.cpp:330] Iteration 46500, Testing net (#0)
I1014 02:43:48.966256 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:43:49.310884 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63766 (* 1 = 1.63766 loss)
I1014 02:43:49.310899 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6472
I1014 02:43:49.611943 13701 solver.cpp:218] Iteration 46500 (2.10077 iter/s, 47.6015s/100 iters), loss = 0.207688
I1014 02:43:49.611976 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207689 (* 1 = 0.207689 loss)
I1014 02:43:49.611984 13701 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1014 02:44:20.170804 13701 solver.cpp:218] Iteration 46600 (3.27238 iter/s, 30.5588s/100 iters), loss = 0.251785
I1014 02:44:20.170949 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251785 (* 1 = 0.251785 loss)
I1014 02:44:20.170958 13701 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1014 02:44:50.685653 13701 solver.cpp:218] Iteration 46700 (3.27711 iter/s, 30.5147s/100 iters), loss = 0.274767
I1014 02:44:50.685797 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274768 (* 1 = 0.274768 loss)
I1014 02:44:50.685807 13701 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1014 02:45:21.293514 13701 solver.cpp:218] Iteration 46800 (3.26715 iter/s, 30.6077s/100 iters), loss = 0.0538782
I1014 02:45:21.293653 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.053879 (* 1 = 0.053879 loss)
I1014 02:45:21.293661 13701 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1014 02:45:51.885131 13701 solver.cpp:218] Iteration 46900 (3.26888 iter/s, 30.5915s/100 iters), loss = 0.214024
I1014 02:45:51.885264 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214024 (* 1 = 0.214024 loss)
I1014 02:45:51.885272 13701 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1014 02:46:20.946007 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:46:22.165980 13701 solver.cpp:330] Iteration 47000, Testing net (#0)
I1014 02:46:38.776464 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:46:39.115654 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57642 (* 1 = 1.57642 loss)
I1014 02:46:39.115669 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6554
I1014 02:46:39.416750 13701 solver.cpp:218] Iteration 47000 (2.10387 iter/s, 47.5315s/100 iters), loss = 0.16466
I1014 02:46:39.416784 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164661 (* 1 = 0.164661 loss)
I1014 02:46:39.416790 13701 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1014 02:47:10.009049 13701 solver.cpp:218] Iteration 47100 (3.2688 iter/s, 30.5923s/100 iters), loss = 0.147999
I1014 02:47:10.009158 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148 (* 1 = 0.148 loss)
I1014 02:47:10.009176 13701 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1014 02:47:40.557857 13701 solver.cpp:218] Iteration 47200 (3.27346 iter/s, 30.5487s/100 iters), loss = 0.270237
I1014 02:47:40.558002 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270238 (* 1 = 0.270238 loss)
I1014 02:47:40.558012 13701 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1014 02:48:11.099925 13701 solver.cpp:218] Iteration 47300 (3.27419 iter/s, 30.5419s/100 iters), loss = 0.0917393
I1014 02:48:11.100036 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.09174 (* 1 = 0.09174 loss)
I1014 02:48:11.100044 13701 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1014 02:48:41.685619 13701 solver.cpp:218] Iteration 47400 (3.26951 iter/s, 30.5856s/100 iters), loss = 0.420123
I1014 02:48:41.685758 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420124 (* 1 = 0.420124 loss)
I1014 02:48:41.685767 13701 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1014 02:49:12.009101 13701 solver.cpp:330] Iteration 47500, Testing net (#0)
I1014 02:49:28.624688 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:49:28.964105 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58162 (* 1 = 1.58162 loss)
I1014 02:49:28.964121 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6514
I1014 02:49:29.263840 13701 solver.cpp:218] Iteration 47500 (2.10181 iter/s, 47.5781s/100 iters), loss = 0.169812
I1014 02:49:29.263872 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169812 (* 1 = 0.169812 loss)
I1014 02:49:29.263880 13701 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1014 02:49:59.848222 13701 solver.cpp:218] Iteration 47600 (3.26965 iter/s, 30.5844s/100 iters), loss = 0.391035
I1014 02:49:59.848368 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391036 (* 1 = 0.391036 loss)
I1014 02:49:59.848377 13701 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1014 02:50:30.432736 13701 solver.cpp:218] Iteration 47700 (3.26964 iter/s, 30.5844s/100 iters), loss = 0.0919901
I1014 02:50:30.432837 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0919906 (* 1 = 0.0919906 loss)
I1014 02:50:30.432844 13701 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1014 02:51:01.005964 13701 solver.cpp:218] Iteration 47800 (3.27085 iter/s, 30.5731s/100 iters), loss = 0.259784
I1014 02:51:01.006496 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259785 (* 1 = 0.259785 loss)
I1014 02:51:01.006505 13701 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1014 02:51:31.639657 13701 solver.cpp:218] Iteration 47900 (3.26444 iter/s, 30.6332s/100 iters), loss = 0.119275
I1014 02:51:31.639793 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119276 (* 1 = 0.119276 loss)
I1014 02:51:31.639801 13701 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1014 02:52:00.729948 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:52:01.954962 13701 solver.cpp:330] Iteration 48000, Testing net (#0)
I1014 02:52:18.539016 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:52:18.877460 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63742 (* 1 = 1.63742 loss)
I1014 02:52:18.877475 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6494
I1014 02:52:19.179806 13701 solver.cpp:218] Iteration 48000 (2.10349 iter/s, 47.54s/100 iters), loss = 0.124628
I1014 02:52:19.179839 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124628 (* 1 = 0.124628 loss)
I1014 02:52:19.179847 13701 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1014 02:52:49.770486 13701 solver.cpp:218] Iteration 48100 (3.26897 iter/s, 30.5907s/100 iters), loss = 0.203083
I1014 02:52:49.771042 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203084 (* 1 = 0.203084 loss)
I1014 02:52:49.771059 13701 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1014 02:53:20.400313 13701 solver.cpp:218] Iteration 48200 (3.26485 iter/s, 30.6293s/100 iters), loss = 0.236532
I1014 02:53:20.400470 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236533 (* 1 = 0.236533 loss)
I1014 02:53:20.400478 13701 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1014 02:53:50.974151 13701 solver.cpp:218] Iteration 48300 (3.27079 iter/s, 30.5737s/100 iters), loss = 0.45717
I1014 02:53:50.974267 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45717 (* 1 = 0.45717 loss)
I1014 02:53:50.974284 13701 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1014 02:54:21.561293 13701 solver.cpp:218] Iteration 48400 (3.26936 iter/s, 30.587s/100 iters), loss = 0.306263
I1014 02:54:21.561398 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306263 (* 1 = 0.306263 loss)
I1014 02:54:21.561408 13701 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1014 02:54:51.833874 13701 solver.cpp:330] Iteration 48500, Testing net (#0)
I1014 02:55:08.425133 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:55:08.765179 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.65525 (* 1 = 1.65525 loss)
I1014 02:55:08.765195 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6454
I1014 02:55:09.064633 13701 solver.cpp:218] Iteration 48500 (2.10512 iter/s, 47.5032s/100 iters), loss = 0.326414
I1014 02:55:09.064669 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326415 (* 1 = 0.326415 loss)
I1014 02:55:09.064677 13701 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1014 02:55:39.657102 13701 solver.cpp:218] Iteration 48600 (3.26878 iter/s, 30.5924s/100 iters), loss = 0.245955
I1014 02:55:39.657214 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245955 (* 1 = 0.245955 loss)
I1014 02:55:39.657232 13701 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1014 02:56:10.245036 13701 solver.cpp:218] Iteration 48700 (3.26927 iter/s, 30.5878s/100 iters), loss = 0.263959
I1014 02:56:10.245182 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263959 (* 1 = 0.263959 loss)
I1014 02:56:10.245189 13701 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1014 02:56:40.830685 13701 solver.cpp:218] Iteration 48800 (3.26952 iter/s, 30.5855s/100 iters), loss = 0.144506
I1014 02:56:40.830780 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144506 (* 1 = 0.144506 loss)
I1014 02:56:40.830798 13701 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1014 02:57:11.428772 13701 solver.cpp:218] Iteration 48900 (3.26819 iter/s, 30.598s/100 iters), loss = 0.175653
I1014 02:57:11.428856 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175653 (* 1 = 0.175653 loss)
I1014 02:57:11.428874 13701 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1014 02:57:40.485882 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:57:41.713513 13701 solver.cpp:330] Iteration 49000, Testing net (#0)
I1014 02:57:58.284072 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 02:57:58.624161 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60055 (* 1 = 1.60055 loss)
I1014 02:57:58.624177 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6552
I1014 02:57:58.928031 13701 solver.cpp:218] Iteration 49000 (2.1053 iter/s, 47.4992s/100 iters), loss = 0.115585
I1014 02:57:58.928061 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115585 (* 1 = 0.115585 loss)
I1014 02:57:58.928069 13701 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1014 02:58:29.503147 13701 solver.cpp:218] Iteration 49100 (3.27064 iter/s, 30.5751s/100 iters), loss = 0.175826
I1014 02:58:29.503305 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175827 (* 1 = 0.175827 loss)
I1014 02:58:29.503325 13701 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1014 02:59:00.048548 13701 solver.cpp:218] Iteration 49200 (3.27383 iter/s, 30.5453s/100 iters), loss = 0.205816
I1014 02:59:00.048650 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205816 (* 1 = 0.205816 loss)
I1014 02:59:00.048667 13701 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1014 02:59:30.594704 13701 solver.cpp:218] Iteration 49300 (3.27374 iter/s, 30.5461s/100 iters), loss = 0.0947587
I1014 02:59:30.594811 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.094759 (* 1 = 0.094759 loss)
I1014 02:59:30.594818 13701 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1014 03:00:01.189245 13701 solver.cpp:218] Iteration 49400 (3.26857 iter/s, 30.5944s/100 iters), loss = 0.378773
I1014 03:00:01.189385 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378773 (* 1 = 0.378773 loss)
I1014 03:00:01.189394 13701 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1014 03:00:31.505682 13701 solver.cpp:330] Iteration 49500, Testing net (#0)
I1014 03:00:48.105779 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:00:48.445662 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59582 (* 1 = 1.59582 loss)
I1014 03:00:48.445677 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6575
I1014 03:00:48.747385 13701 solver.cpp:218] Iteration 49500 (2.1027 iter/s, 47.558s/100 iters), loss = 0.259332
I1014 03:00:48.747419 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259333 (* 1 = 0.259333 loss)
I1014 03:00:48.747426 13701 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1014 03:01:19.330169 13701 solver.cpp:218] Iteration 49600 (3.26982 iter/s, 30.5828s/100 iters), loss = 0.380311
I1014 03:01:19.330315 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380311 (* 1 = 0.380311 loss)
I1014 03:01:19.330323 13701 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1014 03:01:49.916996 13701 solver.cpp:218] Iteration 49700 (3.2694 iter/s, 30.5867s/100 iters), loss = 0.274873
I1014 03:01:49.917084 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274873 (* 1 = 0.274873 loss)
I1014 03:01:49.917101 13701 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1014 03:02:20.485193 13701 solver.cpp:218] Iteration 49800 (3.27138 iter/s, 30.5681s/100 iters), loss = 0.180236
I1014 03:02:20.485297 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180236 (* 1 = 0.180236 loss)
I1014 03:02:20.485306 13701 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1014 03:02:51.107882 13701 solver.cpp:218] Iteration 49900 (3.26556 iter/s, 30.6226s/100 iters), loss = 0.219965
I1014 03:02:51.107980 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219965 (* 1 = 0.219965 loss)
I1014 03:02:51.107998 13701 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1014 03:03:20.189551 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:03:21.420228 13701 solver.cpp:330] Iteration 50000, Testing net (#0)
I1014 03:03:37.979655 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:03:38.319432 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63708 (* 1 = 1.63708 loss)
I1014 03:03:38.319447 13701 solver.cpp:397]     Test net output #1: accuracy = 0.6488
I1014 03:03:38.620221 13701 solver.cpp:218] Iteration 50000 (2.10472 iter/s, 47.5123s/100 iters), loss = 0.144681
I1014 03:03:38.620255 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144682 (* 1 = 0.144682 loss)
I1014 03:03:38.620261 13701 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1014 03:03:38.620265 13701 sgd_solver.cpp:105] Iteration 50000, lr = 0.001
I1014 03:04:09.235549 13701 solver.cpp:218] Iteration 50100 (3.26634 iter/s, 30.6153s/100 iters), loss = 0.448682
I1014 03:04:09.235695 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448683 (* 1 = 0.448683 loss)
I1014 03:04:09.235704 13701 sgd_solver.cpp:105] Iteration 50100, lr = 0.001
I1014 03:04:39.802275 13701 solver.cpp:218] Iteration 50200 (3.27155 iter/s, 30.5666s/100 iters), loss = 0.204033
I1014 03:04:39.802382 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204033 (* 1 = 0.204033 loss)
I1014 03:04:39.802390 13701 sgd_solver.cpp:105] Iteration 50200, lr = 0.001
I1014 03:05:10.416615 13701 solver.cpp:218] Iteration 50300 (3.26645 iter/s, 30.6142s/100 iters), loss = 0.225924
I1014 03:05:10.416723 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225924 (* 1 = 0.225924 loss)
I1014 03:05:10.416741 13701 sgd_solver.cpp:105] Iteration 50300, lr = 0.001
I1014 03:05:40.956321 13701 solver.cpp:218] Iteration 50400 (3.27444 iter/s, 30.5396s/100 iters), loss = 0.0322813
I1014 03:05:40.956437 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322814 (* 1 = 0.0322814 loss)
I1014 03:05:40.956445 13701 sgd_solver.cpp:105] Iteration 50400, lr = 0.001
I1014 03:06:11.280510 13701 solver.cpp:330] Iteration 50500, Testing net (#0)
I1014 03:06:27.863488 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:06:28.202837 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.28046 (* 1 = 1.28046 loss)
I1014 03:06:28.202852 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7129
I1014 03:06:28.503307 13701 solver.cpp:218] Iteration 50500 (2.10319 iter/s, 47.5469s/100 iters), loss = 0.0953369
I1014 03:06:28.503342 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0953371 (* 1 = 0.0953371 loss)
I1014 03:06:28.503350 13701 sgd_solver.cpp:105] Iteration 50500, lr = 0.001
I1014 03:06:59.032904 13701 solver.cpp:218] Iteration 50600 (3.27551 iter/s, 30.5296s/100 iters), loss = 0.104455
I1014 03:06:59.033557 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104455 (* 1 = 0.104455 loss)
I1014 03:06:59.033565 13701 sgd_solver.cpp:105] Iteration 50600, lr = 0.001
I1014 03:07:29.560668 13701 solver.cpp:218] Iteration 50700 (3.27578 iter/s, 30.5271s/100 iters), loss = 0.114591
I1014 03:07:29.560783 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114591 (* 1 = 0.114591 loss)
I1014 03:07:29.560792 13701 sgd_solver.cpp:105] Iteration 50700, lr = 0.001
I1014 03:08:00.079905 13701 solver.cpp:218] Iteration 50800 (3.27663 iter/s, 30.5191s/100 iters), loss = 0.0274516
I1014 03:08:00.080046 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274518 (* 1 = 0.0274518 loss)
I1014 03:08:00.080055 13701 sgd_solver.cpp:105] Iteration 50800, lr = 0.001
I1014 03:08:30.655001 13701 solver.cpp:218] Iteration 50900 (3.27065 iter/s, 30.575s/100 iters), loss = 0.0338143
I1014 03:08:30.655120 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338145 (* 1 = 0.0338145 loss)
I1014 03:08:30.655138 13701 sgd_solver.cpp:105] Iteration 50900, lr = 0.001
I1014 03:08:59.753635 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:09:00.980417 13701 solver.cpp:330] Iteration 51000, Testing net (#0)
I1014 03:09:17.556555 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:09:17.895663 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.24238 (* 1 = 1.24238 loss)
I1014 03:09:17.895678 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7202
I1014 03:09:18.195111 13701 solver.cpp:218] Iteration 51000 (2.10349 iter/s, 47.54s/100 iters), loss = 0.0180232
I1014 03:09:18.195140 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180234 (* 1 = 0.0180234 loss)
I1014 03:09:18.195147 13701 sgd_solver.cpp:105] Iteration 51000, lr = 0.001
I1014 03:09:48.732889 13701 solver.cpp:218] Iteration 51100 (3.27464 iter/s, 30.5378s/100 iters), loss = 0.063157
I1014 03:09:48.733316 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0631572 (* 1 = 0.0631572 loss)
I1014 03:09:48.733324 13701 sgd_solver.cpp:105] Iteration 51100, lr = 0.001
I1014 03:10:19.339118 13701 solver.cpp:218] Iteration 51200 (3.26735 iter/s, 30.6058s/100 iters), loss = 0.047972
I1014 03:10:19.339262 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479722 (* 1 = 0.0479722 loss)
I1014 03:10:19.339270 13701 sgd_solver.cpp:105] Iteration 51200, lr = 0.001
I1014 03:10:49.896374 13701 solver.cpp:218] Iteration 51300 (3.27256 iter/s, 30.5571s/100 iters), loss = 0.183267
I1014 03:10:49.896486 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183267 (* 1 = 0.183267 loss)
I1014 03:10:49.896494 13701 sgd_solver.cpp:105] Iteration 51300, lr = 0.001
I1014 03:11:20.513270 13701 solver.cpp:218] Iteration 51400 (3.26618 iter/s, 30.6168s/100 iters), loss = 0.0326596
I1014 03:11:20.513414 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326598 (* 1 = 0.0326598 loss)
I1014 03:11:20.513423 13701 sgd_solver.cpp:105] Iteration 51400, lr = 0.001
I1014 03:11:50.772722 13701 solver.cpp:330] Iteration 51500, Testing net (#0)
I1014 03:12:07.370121 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:12:07.710012 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.23475 (* 1 = 1.23475 loss)
I1014 03:12:07.710028 13701 solver.cpp:397]     Test net output #1: accuracy = 0.722
I1014 03:12:08.011646 13701 solver.cpp:218] Iteration 51500 (2.10534 iter/s, 47.4982s/100 iters), loss = 0.102425
I1014 03:12:08.011674 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102425 (* 1 = 0.102425 loss)
I1014 03:12:08.011682 13701 sgd_solver.cpp:105] Iteration 51500, lr = 0.001
I1014 03:12:38.512629 13701 solver.cpp:218] Iteration 51600 (3.27859 iter/s, 30.501s/100 iters), loss = 0.0454658
I1014 03:12:38.512770 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454661 (* 1 = 0.0454661 loss)
I1014 03:12:38.512778 13701 sgd_solver.cpp:105] Iteration 51600, lr = 0.001
I1014 03:13:09.065835 13701 solver.cpp:218] Iteration 51700 (3.27299 iter/s, 30.5531s/100 iters), loss = 0.0695405
I1014 03:13:09.065974 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0695408 (* 1 = 0.0695408 loss)
I1014 03:13:09.065982 13701 sgd_solver.cpp:105] Iteration 51700, lr = 0.001
I1014 03:13:39.631723 13701 solver.cpp:218] Iteration 51800 (3.27163 iter/s, 30.5658s/100 iters), loss = 0.0421417
I1014 03:13:39.631866 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0421419 (* 1 = 0.0421419 loss)
I1014 03:13:39.631875 13701 sgd_solver.cpp:105] Iteration 51800, lr = 0.001
I1014 03:14:10.152832 13701 solver.cpp:218] Iteration 51900 (3.27643 iter/s, 30.521s/100 iters), loss = 0.0291063
I1014 03:14:10.152971 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291065 (* 1 = 0.0291065 loss)
I1014 03:14:10.152981 13701 sgd_solver.cpp:105] Iteration 51900, lr = 0.001
I1014 03:14:39.190599 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:14:40.409004 13701 solver.cpp:330] Iteration 52000, Testing net (#0)
I1014 03:14:56.993436 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:14:57.332968 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21962 (* 1 = 1.21962 loss)
I1014 03:14:57.332983 13701 solver.cpp:397]     Test net output #1: accuracy = 0.727
I1014 03:14:57.633553 13701 solver.cpp:218] Iteration 52000 (2.10612 iter/s, 47.4806s/100 iters), loss = 0.00762426
I1014 03:14:57.633590 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0076245 (* 1 = 0.0076245 loss)
I1014 03:14:57.633597 13701 sgd_solver.cpp:105] Iteration 52000, lr = 0.001
I1014 03:15:28.188926 13701 solver.cpp:218] Iteration 52100 (3.27275 iter/s, 30.5553s/100 iters), loss = 0.130627
I1014 03:15:28.189800 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130627 (* 1 = 0.130627 loss)
I1014 03:15:28.189808 13701 sgd_solver.cpp:105] Iteration 52100, lr = 0.001
I1014 03:15:58.747174 13701 solver.cpp:218] Iteration 52200 (3.27253 iter/s, 30.5574s/100 iters), loss = 0.0592278
I1014 03:15:58.747318 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.059228 (* 1 = 0.059228 loss)
I1014 03:15:58.747326 13701 sgd_solver.cpp:105] Iteration 52200, lr = 0.001
I1014 03:16:29.283699 13701 solver.cpp:218] Iteration 52300 (3.27478 iter/s, 30.5364s/100 iters), loss = 0.0524817
I1014 03:16:29.283825 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0524819 (* 1 = 0.0524819 loss)
I1014 03:16:29.283833 13701 sgd_solver.cpp:105] Iteration 52300, lr = 0.001
I1014 03:16:59.864410 13701 solver.cpp:218] Iteration 52400 (3.27005 iter/s, 30.5806s/100 iters), loss = 0.0252314
I1014 03:16:59.864923 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252317 (* 1 = 0.0252317 loss)
I1014 03:16:59.864940 13701 sgd_solver.cpp:105] Iteration 52400, lr = 0.001
I1014 03:17:30.126845 13701 solver.cpp:330] Iteration 52500, Testing net (#0)
I1014 03:17:46.778216 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:17:47.120311 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21582 (* 1 = 1.21582 loss)
I1014 03:17:47.120324 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7248
I1014 03:17:47.423887 13701 solver.cpp:218] Iteration 52500 (2.10265 iter/s, 47.559s/100 iters), loss = 0.0358063
I1014 03:17:47.423921 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358065 (* 1 = 0.0358065 loss)
I1014 03:17:47.423929 13701 sgd_solver.cpp:105] Iteration 52500, lr = 0.001
I1014 03:18:17.982942 13701 solver.cpp:218] Iteration 52600 (3.27236 iter/s, 30.559s/100 iters), loss = 0.0739329
I1014 03:18:17.983053 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0739331 (* 1 = 0.0739331 loss)
I1014 03:18:17.983060 13701 sgd_solver.cpp:105] Iteration 52600, lr = 0.001
I1014 03:18:48.578536 13701 solver.cpp:218] Iteration 52700 (3.26846 iter/s, 30.5955s/100 iters), loss = 0.00467542
I1014 03:18:48.578634 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467567 (* 1 = 0.00467567 loss)
I1014 03:18:48.578640 13701 sgd_solver.cpp:105] Iteration 52700, lr = 0.001
I1014 03:19:19.099282 13701 solver.cpp:218] Iteration 52800 (3.27647 iter/s, 30.5207s/100 iters), loss = 0.00699805
I1014 03:19:19.099392 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069983 (* 1 = 0.0069983 loss)
I1014 03:19:19.099398 13701 sgd_solver.cpp:105] Iteration 52800, lr = 0.001
I1014 03:19:49.668467 13701 solver.cpp:218] Iteration 52900 (3.27128 iter/s, 30.5691s/100 iters), loss = 0.0133369
I1014 03:19:49.668608 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133372 (* 1 = 0.0133372 loss)
I1014 03:19:49.668617 13701 sgd_solver.cpp:105] Iteration 52900, lr = 0.001
I1014 03:20:18.666393 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:20:19.891118 13701 solver.cpp:330] Iteration 53000, Testing net (#0)
I1014 03:20:36.463425 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:20:36.804132 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.2114 (* 1 = 1.2114 loss)
I1014 03:20:36.804147 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7284
I1014 03:20:37.106644 13701 solver.cpp:218] Iteration 53000 (2.10801 iter/s, 47.438s/100 iters), loss = 0.0307906
I1014 03:20:37.106675 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307908 (* 1 = 0.0307908 loss)
I1014 03:20:37.106683 13701 sgd_solver.cpp:105] Iteration 53000, lr = 0.001
I1014 03:21:07.655623 13701 solver.cpp:218] Iteration 53100 (3.27343 iter/s, 30.549s/100 iters), loss = 0.0400695
I1014 03:21:07.655787 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400698 (* 1 = 0.0400698 loss)
I1014 03:21:07.655809 13701 sgd_solver.cpp:105] Iteration 53100, lr = 0.001
I1014 03:21:38.161869 13701 solver.cpp:218] Iteration 53200 (3.27803 iter/s, 30.5061s/100 iters), loss = 0.0375863
I1014 03:21:38.162015 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375866 (* 1 = 0.0375866 loss)
I1014 03:21:38.162024 13701 sgd_solver.cpp:105] Iteration 53200, lr = 0.001
I1014 03:22:08.694862 13701 solver.cpp:218] Iteration 53300 (3.27516 iter/s, 30.5329s/100 iters), loss = 0.0351367
I1014 03:22:08.695003 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035137 (* 1 = 0.035137 loss)
I1014 03:22:08.695013 13701 sgd_solver.cpp:105] Iteration 53300, lr = 0.001
I1014 03:22:39.189065 13701 solver.cpp:218] Iteration 53400 (3.27933 iter/s, 30.4941s/100 iters), loss = 0.0155179
I1014 03:22:39.189208 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155182 (* 1 = 0.0155182 loss)
I1014 03:22:39.189218 13701 sgd_solver.cpp:105] Iteration 53400, lr = 0.001
I1014 03:23:09.416293 13701 solver.cpp:330] Iteration 53500, Testing net (#0)
I1014 03:23:26.024410 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:23:26.363934 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21288 (* 1 = 1.21288 loss)
I1014 03:23:26.363950 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7281
I1014 03:23:26.665838 13701 solver.cpp:218] Iteration 53500 (2.1063 iter/s, 47.4766s/100 iters), loss = 0.0191056
I1014 03:23:26.665870 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191059 (* 1 = 0.0191059 loss)
I1014 03:23:26.665876 13701 sgd_solver.cpp:105] Iteration 53500, lr = 0.001
I1014 03:23:57.166553 13701 solver.cpp:218] Iteration 53600 (3.27861 iter/s, 30.5007s/100 iters), loss = 0.0486559
I1014 03:23:57.166692 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486562 (* 1 = 0.0486562 loss)
I1014 03:23:57.166700 13701 sgd_solver.cpp:105] Iteration 53600, lr = 0.001
I1014 03:24:27.734355 13701 solver.cpp:218] Iteration 53700 (3.27143 iter/s, 30.5677s/100 iters), loss = 0.00606611
I1014 03:24:27.734486 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00606639 (* 1 = 0.00606639 loss)
I1014 03:24:27.734494 13701 sgd_solver.cpp:105] Iteration 53700, lr = 0.001
I1014 03:24:58.235714 13701 solver.cpp:218] Iteration 53800 (3.27855 iter/s, 30.5012s/100 iters), loss = 0.0197962
I1014 03:24:58.235857 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197965 (* 1 = 0.0197965 loss)
I1014 03:24:58.235867 13701 sgd_solver.cpp:105] Iteration 53800, lr = 0.001
I1014 03:25:28.774843 13701 solver.cpp:218] Iteration 53900 (3.2745 iter/s, 30.539s/100 iters), loss = 0.0125748
I1014 03:25:28.774986 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125751 (* 1 = 0.0125751 loss)
I1014 03:25:28.774994 13701 sgd_solver.cpp:105] Iteration 53900, lr = 0.001
I1014 03:25:57.756873 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:25:58.971403 13701 solver.cpp:330] Iteration 54000, Testing net (#0)
I1014 03:26:15.589284 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:26:15.927940 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20748 (* 1 = 1.20748 loss)
I1014 03:26:15.927955 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7299
I1014 03:26:16.229558 13701 solver.cpp:218] Iteration 54000 (2.10728 iter/s, 47.4546s/100 iters), loss = 0.0393625
I1014 03:26:16.229588 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393628 (* 1 = 0.0393628 loss)
I1014 03:26:16.229595 13701 sgd_solver.cpp:105] Iteration 54000, lr = 0.001
I1014 03:26:46.767660 13701 solver.cpp:218] Iteration 54100 (3.2746 iter/s, 30.5381s/100 iters), loss = 0.036075
I1014 03:26:46.767796 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360753 (* 1 = 0.0360753 loss)
I1014 03:26:46.767803 13701 sgd_solver.cpp:105] Iteration 54100, lr = 0.001
I1014 03:27:17.302305 13701 solver.cpp:218] Iteration 54200 (3.27498 iter/s, 30.5345s/100 iters), loss = 0.017637
I1014 03:27:17.302446 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176373 (* 1 = 0.0176373 loss)
I1014 03:27:17.302464 13701 sgd_solver.cpp:105] Iteration 54200, lr = 0.001
I1014 03:27:47.854995 13701 solver.cpp:218] Iteration 54300 (3.27305 iter/s, 30.5526s/100 iters), loss = 0.0206715
I1014 03:27:47.855132 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206718 (* 1 = 0.0206718 loss)
I1014 03:27:47.855141 13701 sgd_solver.cpp:105] Iteration 54300, lr = 0.001
I1014 03:28:18.360023 13701 solver.cpp:218] Iteration 54400 (3.27816 iter/s, 30.5049s/100 iters), loss = 0.0141752
I1014 03:28:18.360164 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141755 (* 1 = 0.0141755 loss)
I1014 03:28:18.360173 13701 sgd_solver.cpp:105] Iteration 54400, lr = 0.001
I1014 03:28:48.633455 13701 solver.cpp:330] Iteration 54500, Testing net (#0)
I1014 03:29:05.222456 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:29:05.562022 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21075 (* 1 = 1.21075 loss)
I1014 03:29:05.562038 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7296
I1014 03:29:05.862166 13701 solver.cpp:218] Iteration 54500 (2.10517 iter/s, 47.502s/100 iters), loss = 0.0177875
I1014 03:29:05.862197 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177877 (* 1 = 0.0177877 loss)
I1014 03:29:05.862205 13701 sgd_solver.cpp:105] Iteration 54500, lr = 0.001
I1014 03:29:36.433809 13701 solver.cpp:218] Iteration 54600 (3.27101 iter/s, 30.5716s/100 iters), loss = 0.0455448
I1014 03:29:36.433946 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455451 (* 1 = 0.0455451 loss)
I1014 03:29:36.433954 13701 sgd_solver.cpp:105] Iteration 54600, lr = 0.001
I1014 03:30:06.955620 13701 solver.cpp:218] Iteration 54700 (3.27636 iter/s, 30.5217s/100 iters), loss = 0.018445
I1014 03:30:06.955759 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184453 (* 1 = 0.0184453 loss)
I1014 03:30:06.955765 13701 sgd_solver.cpp:105] Iteration 54700, lr = 0.001
I1014 03:30:37.509904 13701 solver.cpp:218] Iteration 54800 (3.27288 iter/s, 30.5542s/100 iters), loss = 0.0022028
I1014 03:30:37.510047 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220311 (* 1 = 0.00220311 loss)
I1014 03:30:37.510056 13701 sgd_solver.cpp:105] Iteration 54800, lr = 0.001
I1014 03:31:08.090252 13701 solver.cpp:218] Iteration 54900 (3.27009 iter/s, 30.5802s/100 iters), loss = 0.0142562
I1014 03:31:08.090384 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142565 (* 1 = 0.0142565 loss)
I1014 03:31:08.090392 13701 sgd_solver.cpp:105] Iteration 54900, lr = 0.001
I1014 03:31:37.152613 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:31:38.377012 13701 solver.cpp:330] Iteration 55000, Testing net (#0)
I1014 03:31:54.999874 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:31:55.340510 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20951 (* 1 = 1.20951 loss)
I1014 03:31:55.340524 13701 solver.cpp:397]     Test net output #1: accuracy = 0.73
I1014 03:31:55.642906 13701 solver.cpp:218] Iteration 55000 (2.10294 iter/s, 47.5525s/100 iters), loss = 0.010441
I1014 03:31:55.642940 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104413 (* 1 = 0.0104413 loss)
I1014 03:31:55.642956 13701 sgd_solver.cpp:105] Iteration 55000, lr = 0.001
I1014 03:32:26.185884 13701 solver.cpp:218] Iteration 55100 (3.27408 iter/s, 30.543s/100 iters), loss = 0.0157497
I1014 03:32:26.185998 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01575 (* 1 = 0.01575 loss)
I1014 03:32:26.186017 13701 sgd_solver.cpp:105] Iteration 55100, lr = 0.001
I1014 03:32:56.731020 13701 solver.cpp:218] Iteration 55200 (3.27386 iter/s, 30.545s/100 iters), loss = 0.0216157
I1014 03:32:56.731168 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021616 (* 1 = 0.021616 loss)
I1014 03:32:56.731176 13701 sgd_solver.cpp:105] Iteration 55200, lr = 0.001
I1014 03:33:27.229228 13701 solver.cpp:218] Iteration 55300 (3.2789 iter/s, 30.4981s/100 iters), loss = 0.0289641
I1014 03:33:27.229336 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289644 (* 1 = 0.0289644 loss)
I1014 03:33:27.229343 13701 sgd_solver.cpp:105] Iteration 55300, lr = 0.001
I1014 03:33:57.804929 13701 solver.cpp:218] Iteration 55400 (3.27058 iter/s, 30.5756s/100 iters), loss = 0.00828838
I1014 03:33:57.805068 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00828869 (* 1 = 0.00828869 loss)
I1014 03:33:57.805075 13701 sgd_solver.cpp:105] Iteration 55400, lr = 0.001
I1014 03:34:28.020748 13701 solver.cpp:330] Iteration 55500, Testing net (#0)
I1014 03:34:44.647166 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:34:44.987293 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20685 (* 1 = 1.20685 loss)
I1014 03:34:44.987310 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7312
I1014 03:34:45.290222 13701 solver.cpp:218] Iteration 55500 (2.10592 iter/s, 47.4852s/100 iters), loss = 0.0134172
I1014 03:34:45.290262 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134176 (* 1 = 0.0134176 loss)
I1014 03:34:45.290269 13701 sgd_solver.cpp:105] Iteration 55500, lr = 0.001
I1014 03:35:15.806913 13701 solver.cpp:218] Iteration 55600 (3.2769 iter/s, 30.5167s/100 iters), loss = 0.00745269
I1014 03:35:15.807060 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.007453 (* 1 = 0.007453 loss)
I1014 03:35:15.807068 13701 sgd_solver.cpp:105] Iteration 55600, lr = 0.001
I1014 03:35:46.338084 13701 solver.cpp:218] Iteration 55700 (3.27536 iter/s, 30.531s/100 iters), loss = 0.00953525
I1014 03:35:46.338181 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00953555 (* 1 = 0.00953555 loss)
I1014 03:35:46.338197 13701 sgd_solver.cpp:105] Iteration 55700, lr = 0.001
I1014 03:36:16.912811 13701 solver.cpp:218] Iteration 55800 (3.27068 iter/s, 30.5746s/100 iters), loss = 0.0146097
I1014 03:36:16.912958 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01461 (* 1 = 0.01461 loss)
I1014 03:36:16.912967 13701 sgd_solver.cpp:105] Iteration 55800, lr = 0.001
I1014 03:36:47.433955 13701 solver.cpp:218] Iteration 55900 (3.27643 iter/s, 30.521s/100 iters), loss = 0.00713357
I1014 03:36:47.434098 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713387 (* 1 = 0.00713387 loss)
I1014 03:36:47.434106 13701 sgd_solver.cpp:105] Iteration 55900, lr = 0.001
I1014 03:37:16.493127 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:37:17.716837 13701 solver.cpp:330] Iteration 56000, Testing net (#0)
I1014 03:37:34.326097 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:37:34.667173 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20498 (* 1 = 1.20498 loss)
I1014 03:37:34.667188 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7311
I1014 03:37:34.970190 13701 solver.cpp:218] Iteration 56000 (2.10366 iter/s, 47.5361s/100 iters), loss = 0.0103009
I1014 03:37:34.970227 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103012 (* 1 = 0.0103012 loss)
I1014 03:37:34.970233 13701 sgd_solver.cpp:105] Iteration 56000, lr = 0.001
I1014 03:38:05.487691 13701 solver.cpp:218] Iteration 56100 (3.27681 iter/s, 30.5175s/100 iters), loss = 0.02142
I1014 03:38:05.487799 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214203 (* 1 = 0.0214203 loss)
I1014 03:38:05.487817 13701 sgd_solver.cpp:105] Iteration 56100, lr = 0.001
I1014 03:38:36.033540 13701 solver.cpp:218] Iteration 56200 (3.27378 iter/s, 30.5458s/100 iters), loss = 0.0385028
I1014 03:38:36.033709 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385031 (* 1 = 0.0385031 loss)
I1014 03:38:36.033718 13701 sgd_solver.cpp:105] Iteration 56200, lr = 0.001
I1014 03:39:06.575420 13701 solver.cpp:218] Iteration 56300 (3.27421 iter/s, 30.5417s/100 iters), loss = 0.0620691
I1014 03:39:06.575565 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620694 (* 1 = 0.0620694 loss)
I1014 03:39:06.575574 13701 sgd_solver.cpp:105] Iteration 56300, lr = 0.001
I1014 03:39:37.080106 13701 solver.cpp:218] Iteration 56400 (3.2782 iter/s, 30.5045s/100 iters), loss = 0.0110777
I1014 03:39:37.080234 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110781 (* 1 = 0.0110781 loss)
I1014 03:39:37.080241 13701 sgd_solver.cpp:105] Iteration 56400, lr = 0.001
I1014 03:40:07.297683 13701 solver.cpp:330] Iteration 56500, Testing net (#0)
I1014 03:40:23.901187 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:40:24.242851 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20339 (* 1 = 1.20339 loss)
I1014 03:40:24.242864 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7292
I1014 03:40:24.544114 13701 solver.cpp:218] Iteration 56500 (2.10686 iter/s, 47.4639s/100 iters), loss = 0.00858203
I1014 03:40:24.544160 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858233 (* 1 = 0.00858233 loss)
I1014 03:40:24.544168 13701 sgd_solver.cpp:105] Iteration 56500, lr = 0.001
I1014 03:40:55.104521 13701 solver.cpp:218] Iteration 56600 (3.27221 iter/s, 30.5604s/100 iters), loss = 0.00416964
I1014 03:40:55.104662 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416994 (* 1 = 0.00416994 loss)
I1014 03:40:55.104671 13701 sgd_solver.cpp:105] Iteration 56600, lr = 0.001
I1014 03:41:25.651592 13701 solver.cpp:218] Iteration 56700 (3.27365 iter/s, 30.5469s/100 iters), loss = 0.00999433
I1014 03:41:25.651731 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00999463 (* 1 = 0.00999463 loss)
I1014 03:41:25.651741 13701 sgd_solver.cpp:105] Iteration 56700, lr = 0.001
I1014 03:41:56.205222 13701 solver.cpp:218] Iteration 56800 (3.27295 iter/s, 30.5535s/100 iters), loss = 0.00678388
I1014 03:41:56.205351 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678418 (* 1 = 0.00678418 loss)
I1014 03:41:56.205358 13701 sgd_solver.cpp:105] Iteration 56800, lr = 0.001
I1014 03:42:26.759851 13701 solver.cpp:218] Iteration 56900 (3.27284 iter/s, 30.5545s/100 iters), loss = 0.00978824
I1014 03:42:26.760155 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978853 (* 1 = 0.00978853 loss)
I1014 03:42:26.760174 13701 sgd_solver.cpp:105] Iteration 56900, lr = 0.001
I1014 03:42:55.781451 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:42:56.995936 13701 solver.cpp:330] Iteration 57000, Testing net (#0)
I1014 03:43:13.640862 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:43:13.983629 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20594 (* 1 = 1.20594 loss)
I1014 03:43:13.983645 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7323
I1014 03:43:14.286406 13701 solver.cpp:218] Iteration 57000 (2.1041 iter/s, 47.5263s/100 iters), loss = 0.0215186
I1014 03:43:14.286439 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215189 (* 1 = 0.0215189 loss)
I1014 03:43:14.286448 13701 sgd_solver.cpp:105] Iteration 57000, lr = 0.001
I1014 03:43:44.802350 13701 solver.cpp:218] Iteration 57100 (3.27698 iter/s, 30.5159s/100 iters), loss = 0.0167
I1014 03:43:44.802448 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167002 (* 1 = 0.0167002 loss)
I1014 03:43:44.802455 13701 sgd_solver.cpp:105] Iteration 57100, lr = 0.001
I1014 03:44:15.342746 13701 solver.cpp:218] Iteration 57200 (3.27436 iter/s, 30.5403s/100 iters), loss = 0.0103966
I1014 03:44:15.342916 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103969 (* 1 = 0.0103969 loss)
I1014 03:44:15.342924 13701 sgd_solver.cpp:105] Iteration 57200, lr = 0.001
I1014 03:44:45.875082 13701 solver.cpp:218] Iteration 57300 (3.27523 iter/s, 30.5322s/100 iters), loss = 0.0175436
I1014 03:44:45.875226 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175439 (* 1 = 0.0175439 loss)
I1014 03:44:45.875234 13701 sgd_solver.cpp:105] Iteration 57300, lr = 0.001
I1014 03:45:16.475328 13701 solver.cpp:218] Iteration 57400 (3.26796 iter/s, 30.6001s/100 iters), loss = 0.0055512
I1014 03:45:16.475443 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555149 (* 1 = 0.00555149 loss)
I1014 03:45:16.475461 13701 sgd_solver.cpp:105] Iteration 57400, lr = 0.001
I1014 03:45:46.713641 13701 solver.cpp:330] Iteration 57500, Testing net (#0)
I1014 03:46:03.401866 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:46:03.742038 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.2065 (* 1 = 1.2065 loss)
I1014 03:46:03.742054 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7325
I1014 03:46:04.046851 13701 solver.cpp:218] Iteration 57500 (2.1021 iter/s, 47.5714s/100 iters), loss = 0.0299339
I1014 03:46:04.046885 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299342 (* 1 = 0.0299342 loss)
I1014 03:46:04.046892 13701 sgd_solver.cpp:105] Iteration 57500, lr = 0.001
I1014 03:46:34.566995 13701 solver.cpp:218] Iteration 57600 (3.27653 iter/s, 30.5201s/100 iters), loss = 0.00774354
I1014 03:46:34.567136 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774383 (* 1 = 0.00774383 loss)
I1014 03:46:34.567143 13701 sgd_solver.cpp:105] Iteration 57600, lr = 0.001
I1014 03:47:05.123406 13701 solver.cpp:218] Iteration 57700 (3.27265 iter/s, 30.5563s/100 iters), loss = 0.00877145
I1014 03:47:05.123517 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877174 (* 1 = 0.00877174 loss)
I1014 03:47:05.123535 13701 sgd_solver.cpp:105] Iteration 57700, lr = 0.001
I1014 03:47:35.645170 13701 solver.cpp:218] Iteration 57800 (3.27636 iter/s, 30.5217s/100 iters), loss = 0.00280198
I1014 03:47:35.645277 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280228 (* 1 = 0.00280228 loss)
I1014 03:47:35.645285 13701 sgd_solver.cpp:105] Iteration 57800, lr = 0.001
I1014 03:48:06.215013 13701 solver.cpp:218] Iteration 57900 (3.27121 iter/s, 30.5697s/100 iters), loss = 0.0100305
I1014 03:48:06.215116 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100308 (* 1 = 0.0100308 loss)
I1014 03:48:06.215133 13701 sgd_solver.cpp:105] Iteration 57900, lr = 0.001
I1014 03:48:35.252892 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:48:36.474913 13701 solver.cpp:330] Iteration 58000, Testing net (#0)
I1014 03:48:53.040978 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:48:53.378129 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20241 (* 1 = 1.20241 loss)
I1014 03:48:53.378144 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7353
I1014 03:48:53.678983 13701 solver.cpp:218] Iteration 58000 (2.10687 iter/s, 47.4639s/100 iters), loss = 0.00898935
I1014 03:48:53.679020 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00898964 (* 1 = 0.00898964 loss)
I1014 03:48:53.679028 13701 sgd_solver.cpp:105] Iteration 58000, lr = 0.001
I1014 03:49:24.252467 13701 solver.cpp:218] Iteration 58100 (3.27081 iter/s, 30.5735s/100 iters), loss = 0.0227481
I1014 03:49:24.252607 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227484 (* 1 = 0.0227484 loss)
I1014 03:49:24.252615 13701 sgd_solver.cpp:105] Iteration 58100, lr = 0.001
I1014 03:49:54.778724 13701 solver.cpp:218] Iteration 58200 (3.27588 iter/s, 30.5261s/100 iters), loss = 0.013654
I1014 03:49:54.778969 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136543 (* 1 = 0.0136543 loss)
I1014 03:49:54.778975 13701 sgd_solver.cpp:105] Iteration 58200, lr = 0.001
I1014 03:50:25.316548 13701 solver.cpp:218] Iteration 58300 (3.27465 iter/s, 30.5376s/100 iters), loss = 0.0952408
I1014 03:50:25.316684 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0952411 (* 1 = 0.0952411 loss)
I1014 03:50:25.316701 13701 sgd_solver.cpp:105] Iteration 58300, lr = 0.001
I1014 03:50:55.856353 13701 solver.cpp:218] Iteration 58400 (3.27443 iter/s, 30.5397s/100 iters), loss = 0.00446914
I1014 03:50:55.856498 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446944 (* 1 = 0.00446944 loss)
I1014 03:50:55.856508 13701 sgd_solver.cpp:105] Iteration 58400, lr = 0.001
I1014 03:51:26.154757 13701 solver.cpp:330] Iteration 58500, Testing net (#0)
I1014 03:51:42.798863 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:51:43.140189 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20468 (* 1 = 1.20468 loss)
I1014 03:51:43.140204 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7323
I1014 03:51:43.440377 13701 solver.cpp:218] Iteration 58500 (2.10155 iter/s, 47.5839s/100 iters), loss = 0.0139719
I1014 03:51:43.440407 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139722 (* 1 = 0.0139722 loss)
I1014 03:51:43.440413 13701 sgd_solver.cpp:105] Iteration 58500, lr = 0.001
I1014 03:52:13.985090 13701 solver.cpp:218] Iteration 58600 (3.27389 iter/s, 30.5447s/100 iters), loss = 0.00515929
I1014 03:52:13.985224 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515958 (* 1 = 0.00515958 loss)
I1014 03:52:13.985234 13701 sgd_solver.cpp:105] Iteration 58600, lr = 0.001
I1014 03:52:44.538991 13701 solver.cpp:218] Iteration 58700 (3.27292 iter/s, 30.5538s/100 iters), loss = 0.0313816
I1014 03:52:44.539126 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313819 (* 1 = 0.0313819 loss)
I1014 03:52:44.539144 13701 sgd_solver.cpp:105] Iteration 58700, lr = 0.001
I1014 03:53:15.150204 13701 solver.cpp:218] Iteration 58800 (3.26679 iter/s, 30.6111s/100 iters), loss = 0.0204823
I1014 03:53:15.150323 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204826 (* 1 = 0.0204826 loss)
I1014 03:53:15.150341 13701 sgd_solver.cpp:105] Iteration 58800, lr = 0.001
I1014 03:53:45.688997 13701 solver.cpp:218] Iteration 58900 (3.27454 iter/s, 30.5387s/100 iters), loss = 0.0103543
I1014 03:53:45.689082 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103546 (* 1 = 0.0103546 loss)
I1014 03:53:45.689100 13701 sgd_solver.cpp:105] Iteration 58900, lr = 0.001
I1014 03:54:14.714527 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:54:15.956380 13701 solver.cpp:330] Iteration 59000, Testing net (#0)
I1014 03:54:32.533756 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:54:32.874182 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20048 (* 1 = 1.20048 loss)
I1014 03:54:32.874198 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7325
I1014 03:54:33.174160 13701 solver.cpp:218] Iteration 59000 (2.10592 iter/s, 47.4851s/100 iters), loss = 0.00618092
I1014 03:54:33.174187 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618121 (* 1 = 0.00618121 loss)
I1014 03:54:33.174194 13701 sgd_solver.cpp:105] Iteration 59000, lr = 0.001
I1014 03:55:03.721066 13701 solver.cpp:218] Iteration 59100 (3.27366 iter/s, 30.5469s/100 iters), loss = 0.0137638
I1014 03:55:03.721207 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137641 (* 1 = 0.0137641 loss)
I1014 03:55:03.721216 13701 sgd_solver.cpp:105] Iteration 59100, lr = 0.001
I1014 03:55:34.238694 13701 solver.cpp:218] Iteration 59200 (3.27681 iter/s, 30.5175s/100 iters), loss = 0.0135694
I1014 03:55:34.238834 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135696 (* 1 = 0.0135696 loss)
I1014 03:55:34.238843 13701 sgd_solver.cpp:105] Iteration 59200, lr = 0.001
I1014 03:56:04.784253 13701 solver.cpp:218] Iteration 59300 (3.27381 iter/s, 30.5454s/100 iters), loss = 0.0269296
I1014 03:56:04.784410 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269299 (* 1 = 0.0269299 loss)
I1014 03:56:04.784420 13701 sgd_solver.cpp:105] Iteration 59300, lr = 0.001
I1014 03:56:35.354670 13701 solver.cpp:218] Iteration 59400 (3.27115 iter/s, 30.5703s/100 iters), loss = 0.0110999
I1014 03:56:35.354816 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111002 (* 1 = 0.0111002 loss)
I1014 03:56:35.354826 13701 sgd_solver.cpp:105] Iteration 59400, lr = 0.001
I1014 03:57:05.632732 13701 solver.cpp:330] Iteration 59500, Testing net (#0)
I1014 03:57:22.212262 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:57:22.551929 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20035 (* 1 = 1.20035 loss)
I1014 03:57:22.551945 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7324
I1014 03:57:22.854712 13701 solver.cpp:218] Iteration 59500 (2.10527 iter/s, 47.4999s/100 iters), loss = 0.00686875
I1014 03:57:22.854740 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00686905 (* 1 = 0.00686905 loss)
I1014 03:57:22.854746 13701 sgd_solver.cpp:105] Iteration 59500, lr = 0.001
I1014 03:57:53.441484 13701 solver.cpp:218] Iteration 59600 (3.26939 iter/s, 30.5867s/100 iters), loss = 0.00750798
I1014 03:57:53.441599 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750828 (* 1 = 0.00750828 loss)
I1014 03:57:53.441607 13701 sgd_solver.cpp:105] Iteration 59600, lr = 0.001
I1014 03:58:23.983901 13701 solver.cpp:218] Iteration 59700 (3.27415 iter/s, 30.5423s/100 iters), loss = 0.00824463
I1014 03:58:23.983980 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00824493 (* 1 = 0.00824493 loss)
I1014 03:58:23.983996 13701 sgd_solver.cpp:105] Iteration 59700, lr = 0.001
I1014 03:58:54.512676 13701 solver.cpp:218] Iteration 59800 (3.27561 iter/s, 30.5287s/100 iters), loss = 0.016621
I1014 03:58:54.512814 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166213 (* 1 = 0.0166213 loss)
I1014 03:58:54.512822 13701 sgd_solver.cpp:105] Iteration 59800, lr = 0.001
I1014 03:59:25.057370 13701 solver.cpp:218] Iteration 59900 (3.2739 iter/s, 30.5446s/100 iters), loss = 0.00823826
I1014 03:59:25.057512 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823856 (* 1 = 0.00823856 loss)
I1014 03:59:25.057519 13701 sgd_solver.cpp:105] Iteration 59900, lr = 0.001
I1014 03:59:54.069078 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 03:59:55.286211 13701 solver.cpp:330] Iteration 60000, Testing net (#0)
I1014 04:00:11.921131 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:00:12.258776 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19975 (* 1 = 1.19975 loss)
I1014 04:00:12.258791 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7344
I1014 04:00:12.558491 13701 solver.cpp:218] Iteration 60000 (2.10522 iter/s, 47.501s/100 iters), loss = 0.0171407
I1014 04:00:12.558526 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017141 (* 1 = 0.017141 loss)
I1014 04:00:12.558533 13701 sgd_solver.cpp:105] Iteration 60000, lr = 0.001
I1014 04:00:43.103696 13701 solver.cpp:218] Iteration 60100 (3.27384 iter/s, 30.5452s/100 iters), loss = 0.0169655
I1014 04:00:43.103822 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169658 (* 1 = 0.0169658 loss)
I1014 04:00:43.103829 13701 sgd_solver.cpp:105] Iteration 60100, lr = 0.001
I1014 04:01:13.650527 13701 solver.cpp:218] Iteration 60200 (3.27367 iter/s, 30.5467s/100 iters), loss = 0.0262792
I1014 04:01:13.650665 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262795 (* 1 = 0.0262795 loss)
I1014 04:01:13.650674 13701 sgd_solver.cpp:105] Iteration 60200, lr = 0.001
I1014 04:01:44.170810 13701 solver.cpp:218] Iteration 60300 (3.27652 iter/s, 30.5202s/100 iters), loss = 0.0226384
I1014 04:01:44.170953 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226387 (* 1 = 0.0226387 loss)
I1014 04:01:44.170961 13701 sgd_solver.cpp:105] Iteration 60300, lr = 0.001
I1014 04:02:14.733289 13701 solver.cpp:218] Iteration 60400 (3.272 iter/s, 30.5623s/100 iters), loss = 0.00978329
I1014 04:02:14.733465 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978359 (* 1 = 0.00978359 loss)
I1014 04:02:14.733484 13701 sgd_solver.cpp:105] Iteration 60400, lr = 0.001
I1014 04:02:44.971724 13701 solver.cpp:330] Iteration 60500, Testing net (#0)
I1014 04:03:01.575847 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:03:01.912911 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19937 (* 1 = 1.19937 loss)
I1014 04:03:01.912925 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7324
I1014 04:03:02.212458 13701 solver.cpp:218] Iteration 60500 (2.10619 iter/s, 47.479s/100 iters), loss = 0.0123243
I1014 04:03:02.212487 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123246 (* 1 = 0.0123246 loss)
I1014 04:03:02.212493 13701 sgd_solver.cpp:105] Iteration 60500, lr = 0.001
I1014 04:03:32.792860 13701 solver.cpp:218] Iteration 60600 (3.27007 iter/s, 30.5804s/100 iters), loss = 0.00403819
I1014 04:03:32.792963 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403848 (* 1 = 0.00403848 loss)
I1014 04:03:32.792984 13701 sgd_solver.cpp:105] Iteration 60600, lr = 0.001
I1014 04:04:03.348616 13701 solver.cpp:218] Iteration 60700 (3.27272 iter/s, 30.5557s/100 iters), loss = 0.00251066
I1014 04:04:03.348759 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251095 (* 1 = 0.00251095 loss)
I1014 04:04:03.348767 13701 sgd_solver.cpp:105] Iteration 60700, lr = 0.001
I1014 04:04:33.912603 13701 solver.cpp:218] Iteration 60800 (3.27184 iter/s, 30.5639s/100 iters), loss = 0.0103356
I1014 04:04:33.912734 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103359 (* 1 = 0.0103359 loss)
I1014 04:04:33.912741 13701 sgd_solver.cpp:105] Iteration 60800, lr = 0.001
I1014 04:05:04.443197 13701 solver.cpp:218] Iteration 60900 (3.27542 iter/s, 30.5305s/100 iters), loss = 0.00474206
I1014 04:05:04.443341 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474235 (* 1 = 0.00474235 loss)
I1014 04:05:04.443349 13701 sgd_solver.cpp:105] Iteration 60900, lr = 0.001
I1014 04:05:33.469964 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:05:34.692509 13701 solver.cpp:330] Iteration 61000, Testing net (#0)
I1014 04:05:51.242496 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:05:51.581010 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19713 (* 1 = 1.19713 loss)
I1014 04:05:51.581025 13701 solver.cpp:397]     Test net output #1: accuracy = 0.734
I1014 04:05:51.880870 13701 solver.cpp:218] Iteration 61000 (2.10804 iter/s, 47.4375s/100 iters), loss = 0.0115166
I1014 04:05:51.880899 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115169 (* 1 = 0.0115169 loss)
I1014 04:05:51.880905 13701 sgd_solver.cpp:105] Iteration 61000, lr = 0.001
I1014 04:06:22.489161 13701 solver.cpp:218] Iteration 61100 (3.26709 iter/s, 30.6083s/100 iters), loss = 0.00801713
I1014 04:06:22.489270 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00801742 (* 1 = 0.00801742 loss)
I1014 04:06:22.489276 13701 sgd_solver.cpp:105] Iteration 61100, lr = 0.001
I1014 04:06:53.093135 13701 solver.cpp:218] Iteration 61200 (3.26756 iter/s, 30.6039s/100 iters), loss = 0.0105593
I1014 04:06:53.093276 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105596 (* 1 = 0.0105596 loss)
I1014 04:06:53.093286 13701 sgd_solver.cpp:105] Iteration 61200, lr = 0.001
I1014 04:07:23.568094 13701 solver.cpp:218] Iteration 61300 (3.2814 iter/s, 30.4748s/100 iters), loss = 0.0121546
I1014 04:07:23.568238 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121549 (* 1 = 0.0121549 loss)
I1014 04:07:23.568248 13701 sgd_solver.cpp:105] Iteration 61300, lr = 0.001
I1014 04:07:54.140723 13701 solver.cpp:218] Iteration 61400 (3.27091 iter/s, 30.5725s/100 iters), loss = 0.00808803
I1014 04:07:54.140873 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00808833 (* 1 = 0.00808833 loss)
I1014 04:07:54.140883 13701 sgd_solver.cpp:105] Iteration 61400, lr = 0.001
I1014 04:08:24.384366 13701 solver.cpp:330] Iteration 61500, Testing net (#0)
I1014 04:08:40.937386 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:08:41.283535 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19531 (* 1 = 1.19531 loss)
I1014 04:08:41.283550 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7339
I1014 04:08:41.590004 13701 solver.cpp:218] Iteration 61500 (2.10752 iter/s, 47.4491s/100 iters), loss = 0.0122196
I1014 04:08:41.590039 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122199 (* 1 = 0.0122199 loss)
I1014 04:08:41.590047 13701 sgd_solver.cpp:105] Iteration 61500, lr = 0.001
I1014 04:09:12.190183 13701 solver.cpp:218] Iteration 61600 (3.26796 iter/s, 30.6002s/100 iters), loss = 0.00444113
I1014 04:09:12.190328 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444142 (* 1 = 0.00444142 loss)
I1014 04:09:12.190336 13701 sgd_solver.cpp:105] Iteration 61600, lr = 0.001
I1014 04:09:42.748200 13701 solver.cpp:218] Iteration 61700 (3.27248 iter/s, 30.5579s/100 iters), loss = 0.0018278
I1014 04:09:42.748340 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018281 (* 1 = 0.0018281 loss)
I1014 04:09:42.748349 13701 sgd_solver.cpp:105] Iteration 61700, lr = 0.001
I1014 04:10:13.317153 13701 solver.cpp:218] Iteration 61800 (3.27131 iter/s, 30.5688s/100 iters), loss = 0.0095954
I1014 04:10:13.317288 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0095957 (* 1 = 0.0095957 loss)
I1014 04:10:13.317296 13701 sgd_solver.cpp:105] Iteration 61800, lr = 0.001
I1014 04:10:43.888667 13701 solver.cpp:218] Iteration 61900 (3.27103 iter/s, 30.5714s/100 iters), loss = 0.00284733
I1014 04:10:43.888764 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284763 (* 1 = 0.00284763 loss)
I1014 04:10:43.888772 13701 sgd_solver.cpp:105] Iteration 61900, lr = 0.001
I1014 04:11:12.924716 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:11:14.148609 13701 solver.cpp:330] Iteration 62000, Testing net (#0)
I1014 04:11:30.742882 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:11:31.083479 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19483 (* 1 = 1.19483 loss)
I1014 04:11:31.083494 13701 solver.cpp:397]     Test net output #1: accuracy = 0.734
I1014 04:11:31.384850 13701 solver.cpp:218] Iteration 62000 (2.10544 iter/s, 47.4961s/100 iters), loss = 0.00692111
I1014 04:11:31.384887 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692141 (* 1 = 0.00692141 loss)
I1014 04:11:31.384894 13701 sgd_solver.cpp:105] Iteration 62000, lr = 0.001
I1014 04:12:01.899924 13701 solver.cpp:218] Iteration 62100 (3.27707 iter/s, 30.515s/100 iters), loss = 0.00906003
I1014 04:12:01.900028 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00906033 (* 1 = 0.00906033 loss)
I1014 04:12:01.900044 13701 sgd_solver.cpp:105] Iteration 62100, lr = 0.001
I1014 04:12:32.455428 13701 solver.cpp:218] Iteration 62200 (3.27274 iter/s, 30.5554s/100 iters), loss = 0.00836885
I1014 04:12:32.455533 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00836914 (* 1 = 0.00836914 loss)
I1014 04:12:32.455550 13701 sgd_solver.cpp:105] Iteration 62200, lr = 0.001
I1014 04:13:02.999878 13701 solver.cpp:218] Iteration 62300 (3.27393 iter/s, 30.5444s/100 iters), loss = 0.0169845
I1014 04:13:03.000008 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169848 (* 1 = 0.0169848 loss)
I1014 04:13:03.000017 13701 sgd_solver.cpp:105] Iteration 62300, lr = 0.001
I1014 04:13:33.503921 13701 solver.cpp:218] Iteration 62400 (3.27827 iter/s, 30.5039s/100 iters), loss = 0.00309066
I1014 04:13:33.504827 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309095 (* 1 = 0.00309095 loss)
I1014 04:13:33.504835 13701 sgd_solver.cpp:105] Iteration 62400, lr = 0.001
I1014 04:14:03.707240 13701 solver.cpp:330] Iteration 62500, Testing net (#0)
I1014 04:14:20.327064 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:14:20.667047 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19269 (* 1 = 1.19269 loss)
I1014 04:14:20.667063 13701 solver.cpp:397]     Test net output #1: accuracy = 0.733
I1014 04:14:20.968868 13701 solver.cpp:218] Iteration 62500 (2.10686 iter/s, 47.4641s/100 iters), loss = 0.00679253
I1014 04:14:20.968897 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679282 (* 1 = 0.00679282 loss)
I1014 04:14:20.968904 13701 sgd_solver.cpp:105] Iteration 62500, lr = 0.001
I1014 04:14:51.546702 13701 solver.cpp:218] Iteration 62600 (3.27035 iter/s, 30.5778s/100 iters), loss = 0.00663299
I1014 04:14:51.546851 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663329 (* 1 = 0.00663329 loss)
I1014 04:14:51.546860 13701 sgd_solver.cpp:105] Iteration 62600, lr = 0.001
I1014 04:15:22.063645 13701 solver.cpp:218] Iteration 62700 (3.27688 iter/s, 30.5168s/100 iters), loss = 0.00840745
I1014 04:15:22.063756 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00840774 (* 1 = 0.00840774 loss)
I1014 04:15:22.063765 13701 sgd_solver.cpp:105] Iteration 62700, lr = 0.001
I1014 04:15:52.558087 13701 solver.cpp:218] Iteration 62800 (3.2793 iter/s, 30.4943s/100 iters), loss = 0.00663918
I1014 04:15:52.558179 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663947 (* 1 = 0.00663947 loss)
I1014 04:15:52.558197 13701 sgd_solver.cpp:105] Iteration 62800, lr = 0.001
I1014 04:16:23.043802 13701 solver.cpp:218] Iteration 62900 (3.28023 iter/s, 30.4856s/100 iters), loss = 0.00815562
I1014 04:16:23.043855 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081559 (* 1 = 0.0081559 loss)
I1014 04:16:23.043862 13701 sgd_solver.cpp:105] Iteration 62900, lr = 0.001
I1014 04:16:52.016551 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:16:53.232653 13701 solver.cpp:330] Iteration 63000, Testing net (#0)
I1014 04:17:09.740139 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:17:10.077222 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19112 (* 1 = 1.19112 loss)
I1014 04:17:10.077239 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7341
I1014 04:17:10.377859 13701 solver.cpp:218] Iteration 63000 (2.11265 iter/s, 47.334s/100 iters), loss = 0.0273835
I1014 04:17:10.377897 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273838 (* 1 = 0.0273838 loss)
I1014 04:17:10.377904 13701 sgd_solver.cpp:105] Iteration 63000, lr = 0.001
I1014 04:17:40.859184 13701 solver.cpp:218] Iteration 63100 (3.2807 iter/s, 30.4813s/100 iters), loss = 0.0108925
I1014 04:17:40.859293 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108928 (* 1 = 0.0108928 loss)
I1014 04:17:40.859300 13701 sgd_solver.cpp:105] Iteration 63100, lr = 0.001
I1014 04:18:11.344250 13701 solver.cpp:218] Iteration 63200 (3.2803 iter/s, 30.485s/100 iters), loss = 0.00714764
I1014 04:18:11.344362 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00714793 (* 1 = 0.00714793 loss)
I1014 04:18:11.344369 13701 sgd_solver.cpp:105] Iteration 63200, lr = 0.001
I1014 04:18:41.824069 13701 solver.cpp:218] Iteration 63300 (3.28087 iter/s, 30.4797s/100 iters), loss = 0.0211786
I1014 04:18:41.824177 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211789 (* 1 = 0.0211789 loss)
I1014 04:18:41.824194 13701 sgd_solver.cpp:105] Iteration 63300, lr = 0.001
I1014 04:19:12.298444 13701 solver.cpp:218] Iteration 63400 (3.28146 iter/s, 30.4743s/100 iters), loss = 0.00454832
I1014 04:19:12.298552 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454861 (* 1 = 0.00454861 loss)
I1014 04:19:12.298560 13701 sgd_solver.cpp:105] Iteration 63400, lr = 0.001
I1014 04:19:42.487393 13701 solver.cpp:330] Iteration 63500, Testing net (#0)
I1014 04:19:59.019995 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:19:59.357748 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18826 (* 1 = 1.18826 loss)
I1014 04:19:59.357764 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7355
I1014 04:19:59.656672 13701 solver.cpp:218] Iteration 63500 (2.11157 iter/s, 47.3581s/100 iters), loss = 0.0106695
I1014 04:19:59.656709 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106698 (* 1 = 0.0106698 loss)
I1014 04:19:59.656716 13701 sgd_solver.cpp:105] Iteration 63500, lr = 0.001
I1014 04:20:30.134146 13701 solver.cpp:218] Iteration 63600 (3.28111 iter/s, 30.4774s/100 iters), loss = 0.00446781
I1014 04:20:30.134258 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0044681 (* 1 = 0.0044681 loss)
I1014 04:20:30.134265 13701 sgd_solver.cpp:105] Iteration 63600, lr = 0.001
I1014 04:21:00.613452 13701 solver.cpp:218] Iteration 63700 (3.28092 iter/s, 30.4792s/100 iters), loss = 0.00451844
I1014 04:21:00.613569 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451873 (* 1 = 0.00451873 loss)
I1014 04:21:00.613575 13701 sgd_solver.cpp:105] Iteration 63700, lr = 0.001
I1014 04:21:31.097673 13701 solver.cpp:218] Iteration 63800 (3.2804 iter/s, 30.4841s/100 iters), loss = 0.00572483
I1014 04:21:31.097815 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572512 (* 1 = 0.00572512 loss)
I1014 04:21:31.097823 13701 sgd_solver.cpp:105] Iteration 63800, lr = 0.001
I1014 04:22:01.561874 13701 solver.cpp:218] Iteration 63900 (3.28256 iter/s, 30.4641s/100 iters), loss = 0.00409501
I1014 04:22:01.562021 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040953 (* 1 = 0.0040953 loss)
I1014 04:22:01.562031 13701 sgd_solver.cpp:105] Iteration 63900, lr = 0.001
I1014 04:22:30.532066 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:22:31.756808 13701 solver.cpp:330] Iteration 64000, Testing net (#0)
I1014 04:22:48.283710 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:22:48.620795 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18845 (* 1 = 1.18845 loss)
I1014 04:22:48.620811 13701 solver.cpp:397]     Test net output #1: accuracy = 0.735
I1014 04:22:48.919797 13701 solver.cpp:218] Iteration 64000 (2.11158 iter/s, 47.3578s/100 iters), loss = 0.00667214
I1014 04:22:48.919826 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667243 (* 1 = 0.00667243 loss)
I1014 04:22:48.919833 13701 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I1014 04:23:19.387332 13701 solver.cpp:218] Iteration 64100 (3.28218 iter/s, 30.4675s/100 iters), loss = 0.0179202
I1014 04:23:19.387440 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179205 (* 1 = 0.0179205 loss)
I1014 04:23:19.387456 13701 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I1014 04:23:49.859257 13701 solver.cpp:218] Iteration 64200 (3.28172 iter/s, 30.4718s/100 iters), loss = 0.00776305
I1014 04:23:49.859395 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776334 (* 1 = 0.00776334 loss)
I1014 04:23:49.859403 13701 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I1014 04:24:20.350286 13701 solver.cpp:218] Iteration 64300 (3.27967 iter/s, 30.4909s/100 iters), loss = 0.0083803
I1014 04:24:20.350435 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00838058 (* 1 = 0.00838058 loss)
I1014 04:24:20.350445 13701 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I1014 04:24:50.835666 13701 solver.cpp:218] Iteration 64400 (3.28028 iter/s, 30.4852s/100 iters), loss = 0.0203228
I1014 04:24:50.835788 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203231 (* 1 = 0.0203231 loss)
I1014 04:24:50.835794 13701 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I1014 04:25:21.019870 13701 solver.cpp:330] Iteration 64500, Testing net (#0)
I1014 04:25:37.551575 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:25:37.889662 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18738 (* 1 = 1.18738 loss)
I1014 04:25:37.889677 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7343
I1014 04:25:38.188554 13701 solver.cpp:218] Iteration 64500 (2.11181 iter/s, 47.3528s/100 iters), loss = 0.00407204
I1014 04:25:38.188582 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407233 (* 1 = 0.00407233 loss)
I1014 04:25:38.188590 13701 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I1014 04:26:08.655117 13701 solver.cpp:218] Iteration 64600 (3.28229 iter/s, 30.4665s/100 iters), loss = 0.00725155
I1014 04:26:08.655267 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725183 (* 1 = 0.00725183 loss)
I1014 04:26:08.655275 13701 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I1014 04:26:39.129338 13701 solver.cpp:218] Iteration 64700 (3.28148 iter/s, 30.4741s/100 iters), loss = 0.00373166
I1014 04:26:39.129474 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373195 (* 1 = 0.00373195 loss)
I1014 04:26:39.129482 13701 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I1014 04:27:09.603226 13701 solver.cpp:218] Iteration 64800 (3.28151 iter/s, 30.4738s/100 iters), loss = 0.0090512
I1014 04:27:09.603343 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00905149 (* 1 = 0.00905149 loss)
I1014 04:27:09.603350 13701 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I1014 04:27:40.057535 13701 solver.cpp:218] Iteration 64900 (3.28362 iter/s, 30.4542s/100 iters), loss = 0.00379121
I1014 04:27:40.057673 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037915 (* 1 = 0.0037915 loss)
I1014 04:27:40.057682 13701 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I1014 04:28:09.016973 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:28:10.233731 13701 solver.cpp:330] Iteration 65000, Testing net (#0)
I1014 04:28:26.762616 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:28:27.099551 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1871 (* 1 = 1.1871 loss)
I1014 04:28:27.099566 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7358
I1014 04:28:27.397889 13701 solver.cpp:218] Iteration 65000 (2.11237 iter/s, 47.3402s/100 iters), loss = 0.0105179
I1014 04:28:27.397925 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105181 (* 1 = 0.0105181 loss)
I1014 04:28:27.397933 13701 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I1014 04:28:57.879688 13701 solver.cpp:218] Iteration 65100 (3.28065 iter/s, 30.4818s/100 iters), loss = 0.0105472
I1014 04:28:57.879797 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105474 (* 1 = 0.0105474 loss)
I1014 04:28:57.879815 13701 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I1014 04:29:28.364336 13701 solver.cpp:218] Iteration 65200 (3.28035 iter/s, 30.4845s/100 iters), loss = 0.0074972
I1014 04:29:28.364485 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074975 (* 1 = 0.0074975 loss)
I1014 04:29:28.364507 13701 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I1014 04:29:58.835474 13701 solver.cpp:218] Iteration 65300 (3.28181 iter/s, 30.471s/100 iters), loss = 0.013793
I1014 04:29:58.835583 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137933 (* 1 = 0.0137933 loss)
I1014 04:29:58.835593 13701 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I1014 04:30:29.312605 13701 solver.cpp:218] Iteration 65400 (3.28116 iter/s, 30.477s/100 iters), loss = 0.0135957
I1014 04:30:29.312748 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135959 (* 1 = 0.0135959 loss)
I1014 04:30:29.312772 13701 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I1014 04:30:59.512387 13701 solver.cpp:330] Iteration 65500, Testing net (#0)
I1014 04:31:16.031646 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:31:16.367383 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18484 (* 1 = 1.18484 loss)
I1014 04:31:16.367400 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7346
I1014 04:31:16.666677 13701 solver.cpp:218] Iteration 65500 (2.11176 iter/s, 47.354s/100 iters), loss = 0.0118818
I1014 04:31:16.666710 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118821 (* 1 = 0.0118821 loss)
I1014 04:31:16.666719 13701 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I1014 04:31:47.128674 13701 solver.cpp:218] Iteration 65600 (3.28278 iter/s, 30.462s/100 iters), loss = 0.00532996
I1014 04:31:47.128806 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533026 (* 1 = 0.00533026 loss)
I1014 04:31:47.128816 13701 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I1014 04:32:17.593992 13701 solver.cpp:218] Iteration 65700 (3.28243 iter/s, 30.4652s/100 iters), loss = 0.00778574
I1014 04:32:17.594136 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00778604 (* 1 = 0.00778604 loss)
I1014 04:32:17.594156 13701 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I1014 04:32:48.070399 13701 solver.cpp:218] Iteration 65800 (3.28124 iter/s, 30.4763s/100 iters), loss = 0.00569081
I1014 04:32:48.070498 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569111 (* 1 = 0.00569111 loss)
I1014 04:32:48.070508 13701 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I1014 04:33:18.555270 13701 solver.cpp:218] Iteration 65900 (3.28033 iter/s, 30.4848s/100 iters), loss = 0.00693002
I1014 04:33:18.555428 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693031 (* 1 = 0.00693031 loss)
I1014 04:33:18.555461 13701 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I1014 04:33:47.504796 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:33:48.726632 13701 solver.cpp:330] Iteration 66000, Testing net (#0)
I1014 04:34:05.240591 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:34:05.577821 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18383 (* 1 = 1.18383 loss)
I1014 04:34:05.577838 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7335
I1014 04:34:05.874425 13701 solver.cpp:218] Iteration 66000 (2.11332 iter/s, 47.319s/100 iters), loss = 0.00941449
I1014 04:34:05.874460 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00941479 (* 1 = 0.00941479 loss)
I1014 04:34:05.874470 13701 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I1014 04:34:36.350692 13701 solver.cpp:218] Iteration 66100 (3.28124 iter/s, 30.4762s/100 iters), loss = 0.01014
I1014 04:34:36.350844 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101403 (* 1 = 0.0101403 loss)
I1014 04:34:36.350853 13701 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I1014 04:35:06.859728 13701 solver.cpp:218] Iteration 66200 (3.27773 iter/s, 30.5089s/100 iters), loss = 0.00966421
I1014 04:35:06.859838 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00966451 (* 1 = 0.00966451 loss)
I1014 04:35:06.859844 13701 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I1014 04:35:37.350550 13701 solver.cpp:218] Iteration 66300 (3.27969 iter/s, 30.4907s/100 iters), loss = 0.014179
I1014 04:35:37.350646 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141793 (* 1 = 0.0141793 loss)
I1014 04:35:37.350653 13701 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I1014 04:36:07.844981 13701 solver.cpp:218] Iteration 66400 (3.2793 iter/s, 30.4943s/100 iters), loss = 0.00537145
I1014 04:36:07.846312 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00537174 (* 1 = 0.00537174 loss)
I1014 04:36:07.846328 13701 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I1014 04:36:38.045004 13701 solver.cpp:330] Iteration 66500, Testing net (#0)
I1014 04:36:54.575820 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:36:54.913449 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18209 (* 1 = 1.18209 loss)
I1014 04:36:54.913463 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7364
I1014 04:36:55.214870 13701 solver.cpp:218] Iteration 66500 (2.1111 iter/s, 47.3686s/100 iters), loss = 0.00461788
I1014 04:36:55.214905 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461818 (* 1 = 0.00461818 loss)
I1014 04:36:55.214913 13701 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I1014 04:37:25.691897 13701 solver.cpp:218] Iteration 66600 (3.28116 iter/s, 30.477s/100 iters), loss = 0.00272407
I1014 04:37:25.692025 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272437 (* 1 = 0.00272437 loss)
I1014 04:37:25.692044 13701 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I1014 04:37:56.147742 13701 solver.cpp:218] Iteration 66700 (3.28345 iter/s, 30.4557s/100 iters), loss = 0.00300479
I1014 04:37:56.147850 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300508 (* 1 = 0.00300508 loss)
I1014 04:37:56.147858 13701 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I1014 04:38:26.617012 13701 solver.cpp:218] Iteration 66800 (3.28201 iter/s, 30.4692s/100 iters), loss = 0.00367749
I1014 04:38:26.617143 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367778 (* 1 = 0.00367778 loss)
I1014 04:38:26.617151 13701 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I1014 04:38:57.076889 13701 solver.cpp:218] Iteration 66900 (3.28302 iter/s, 30.4598s/100 iters), loss = 0.00716454
I1014 04:38:57.076997 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716484 (* 1 = 0.00716484 loss)
I1014 04:38:57.077003 13701 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I1014 04:39:26.032552 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:39:27.254709 13701 solver.cpp:330] Iteration 67000, Testing net (#0)
I1014 04:39:43.773764 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:39:44.113765 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1805 (* 1 = 1.1805 loss)
I1014 04:39:44.113780 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7349
I1014 04:39:44.413308 13701 solver.cpp:218] Iteration 67000 (2.11254 iter/s, 47.3363s/100 iters), loss = 0.00394868
I1014 04:39:44.413342 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394898 (* 1 = 0.00394898 loss)
I1014 04:39:44.413349 13701 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I1014 04:40:14.877347 13701 solver.cpp:218] Iteration 67100 (3.28256 iter/s, 30.464s/100 iters), loss = 0.00690861
I1014 04:40:14.877460 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00690891 (* 1 = 0.00690891 loss)
I1014 04:40:14.877466 13701 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I1014 04:40:45.343176 13701 solver.cpp:218] Iteration 67200 (3.28238 iter/s, 30.4657s/100 iters), loss = 0.0165684
I1014 04:40:45.343288 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165687 (* 1 = 0.0165687 loss)
I1014 04:40:45.343297 13701 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I1014 04:41:15.827019 13701 solver.cpp:218] Iteration 67300 (3.28044 iter/s, 30.4837s/100 iters), loss = 0.00645611
I1014 04:41:15.827162 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064564 (* 1 = 0.0064564 loss)
I1014 04:41:15.827172 13701 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I1014 04:41:46.309098 13701 solver.cpp:218] Iteration 67400 (3.28063 iter/s, 30.4819s/100 iters), loss = 0.00921372
I1014 04:41:46.309242 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00921401 (* 1 = 0.00921401 loss)
I1014 04:41:46.309252 13701 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I1014 04:42:16.491565 13701 solver.cpp:330] Iteration 67500, Testing net (#0)
I1014 04:42:32.996616 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:42:33.334552 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1776 (* 1 = 1.1776 loss)
I1014 04:42:33.334566 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7355
I1014 04:42:33.635675 13701 solver.cpp:218] Iteration 67500 (2.11298 iter/s, 47.3265s/100 iters), loss = 0.00551001
I1014 04:42:33.635710 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055103 (* 1 = 0.0055103 loss)
I1014 04:42:33.635715 13701 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I1014 04:43:04.098273 13701 solver.cpp:218] Iteration 67600 (3.28272 iter/s, 30.4626s/100 iters), loss = 0.00340486
I1014 04:43:04.098402 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340514 (* 1 = 0.00340514 loss)
I1014 04:43:04.098422 13701 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I1014 04:43:34.556182 13701 solver.cpp:218] Iteration 67700 (3.28323 iter/s, 30.4578s/100 iters), loss = 0.00302293
I1014 04:43:34.556296 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302321 (* 1 = 0.00302321 loss)
I1014 04:43:34.556313 13701 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I1014 04:44:05.012745 13701 solver.cpp:218] Iteration 67800 (3.28337 iter/s, 30.4565s/100 iters), loss = 0.00312639
I1014 04:44:05.012883 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312667 (* 1 = 0.00312667 loss)
I1014 04:44:05.012890 13701 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I1014 04:44:35.472281 13701 solver.cpp:218] Iteration 67900 (3.28306 iter/s, 30.4594s/100 iters), loss = 0.00636488
I1014 04:44:35.472422 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636516 (* 1 = 0.00636516 loss)
I1014 04:44:35.472432 13701 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I1014 04:45:04.419724 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:45:05.641616 13701 solver.cpp:330] Iteration 68000, Testing net (#0)
I1014 04:45:22.166211 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:45:22.504155 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17539 (* 1 = 1.17539 loss)
I1014 04:45:22.504171 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7372
I1014 04:45:22.803232 13701 solver.cpp:218] Iteration 68000 (2.11279 iter/s, 47.3308s/100 iters), loss = 0.00634756
I1014 04:45:22.803261 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00634784 (* 1 = 0.00634784 loss)
I1014 04:45:22.803267 13701 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I1014 04:45:53.305546 13701 solver.cpp:218] Iteration 68100 (3.27844 iter/s, 30.5023s/100 iters), loss = 0.0112578
I1014 04:45:53.305681 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112581 (* 1 = 0.0112581 loss)
I1014 04:45:53.305690 13701 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I1014 04:46:23.797976 13701 solver.cpp:218] Iteration 68200 (3.27952 iter/s, 30.4923s/100 iters), loss = 0.0110025
I1014 04:46:23.798082 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110028 (* 1 = 0.0110028 loss)
I1014 04:46:23.798089 13701 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I1014 04:46:54.306684 13701 solver.cpp:218] Iteration 68300 (3.27776 iter/s, 30.5086s/100 iters), loss = 0.0100734
I1014 04:46:54.306823 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100737 (* 1 = 0.0100737 loss)
I1014 04:46:54.306830 13701 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I1014 04:47:24.796977 13701 solver.cpp:218] Iteration 68400 (3.27975 iter/s, 30.4902s/100 iters), loss = 0.00459955
I1014 04:47:24.797108 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459982 (* 1 = 0.00459982 loss)
I1014 04:47:24.797116 13701 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I1014 04:47:55.001235 13701 solver.cpp:330] Iteration 68500, Testing net (#0)
I1014 04:48:11.519845 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:48:11.856679 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17363 (* 1 = 1.17363 loss)
I1014 04:48:11.856694 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7355
I1014 04:48:12.156903 13701 solver.cpp:218] Iteration 68500 (2.11149 iter/s, 47.3598s/100 iters), loss = 0.0074914
I1014 04:48:12.156930 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00749167 (* 1 = 0.00749167 loss)
I1014 04:48:12.156936 13701 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I1014 04:48:42.657281 13701 solver.cpp:218] Iteration 68600 (3.27865 iter/s, 30.5004s/100 iters), loss = 0.0037145
I1014 04:48:42.657454 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371477 (* 1 = 0.00371477 loss)
I1014 04:48:42.657464 13701 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I1014 04:49:13.157227 13701 solver.cpp:218] Iteration 68700 (3.27871 iter/s, 30.4998s/100 iters), loss = 0.00403586
I1014 04:49:13.157337 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403613 (* 1 = 0.00403613 loss)
I1014 04:49:13.157346 13701 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I1014 04:49:43.665367 13701 solver.cpp:218] Iteration 68800 (3.27782 iter/s, 30.508s/100 iters), loss = 0.00293189
I1014 04:49:43.665505 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293216 (* 1 = 0.00293216 loss)
I1014 04:49:43.665513 13701 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I1014 04:50:14.170258 13701 solver.cpp:218] Iteration 68900 (3.27818 iter/s, 30.5048s/100 iters), loss = 0.00436354
I1014 04:50:14.170367 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436381 (* 1 = 0.00436381 loss)
I1014 04:50:14.170375 13701 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I1014 04:50:43.173161 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:50:44.393563 13701 solver.cpp:330] Iteration 69000, Testing net (#0)
I1014 04:51:00.909627 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:51:01.247516 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17138 (* 1 = 1.17138 loss)
I1014 04:51:01.247531 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7367
I1014 04:51:01.547384 13701 solver.cpp:218] Iteration 69000 (2.11073 iter/s, 47.377s/100 iters), loss = 0.00413839
I1014 04:51:01.547420 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413867 (* 1 = 0.00413867 loss)
I1014 04:51:01.547427 13701 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I1014 04:51:32.036103 13701 solver.cpp:218] Iteration 69100 (3.2799 iter/s, 30.4887s/100 iters), loss = 0.00730857
I1014 04:51:32.036242 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00730885 (* 1 = 0.00730885 loss)
I1014 04:51:32.036252 13701 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I1014 04:52:02.517078 13701 solver.cpp:218] Iteration 69200 (3.28075 iter/s, 30.4808s/100 iters), loss = 0.00863809
I1014 04:52:02.517221 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00863837 (* 1 = 0.00863837 loss)
I1014 04:52:02.517230 13701 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I1014 04:52:33.011924 13701 solver.cpp:218] Iteration 69300 (3.27926 iter/s, 30.4947s/100 iters), loss = 0.0156218
I1014 04:52:33.012061 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015622 (* 1 = 0.015622 loss)
I1014 04:52:33.012068 13701 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I1014 04:53:03.506028 13701 solver.cpp:218] Iteration 69400 (3.27934 iter/s, 30.494s/100 iters), loss = 0.00415973
I1014 04:53:03.506155 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416 (* 1 = 0.00416 loss)
I1014 04:53:03.506162 13701 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I1014 04:53:33.718780 13701 solver.cpp:330] Iteration 69500, Testing net (#0)
I1014 04:53:50.249044 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:53:50.587733 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17093 (* 1 = 1.17093 loss)
I1014 04:53:50.587751 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7371
I1014 04:53:50.886312 13701 solver.cpp:218] Iteration 69500 (2.11059 iter/s, 47.3802s/100 iters), loss = 0.0066457
I1014 04:53:50.886343 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664597 (* 1 = 0.00664597 loss)
I1014 04:53:50.886349 13701 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I1014 04:54:21.379781 13701 solver.cpp:218] Iteration 69600 (3.27939 iter/s, 30.4934s/100 iters), loss = 0.00369458
I1014 04:54:21.379911 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369485 (* 1 = 0.00369485 loss)
I1014 04:54:21.379935 13701 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I1014 04:54:51.858593 13701 solver.cpp:218] Iteration 69700 (3.28098 iter/s, 30.4787s/100 iters), loss = 0.00245762
I1014 04:54:51.858705 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245789 (* 1 = 0.00245789 loss)
I1014 04:54:51.858714 13701 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I1014 04:55:22.326617 13701 solver.cpp:218] Iteration 69800 (3.28214 iter/s, 30.4679s/100 iters), loss = 0.0054569
I1014 04:55:22.326728 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545717 (* 1 = 0.00545717 loss)
I1014 04:55:22.326748 13701 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I1014 04:55:52.805371 13701 solver.cpp:218] Iteration 69900 (3.28098 iter/s, 30.4787s/100 iters), loss = 0.00432618
I1014 04:55:52.805515 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432645 (* 1 = 0.00432645 loss)
I1014 04:55:52.805522 13701 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I1014 04:56:21.792867 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:56:23.009852 13701 solver.cpp:330] Iteration 70000, Testing net (#0)
I1014 04:56:39.538064 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:56:39.875816 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16857 (* 1 = 1.16857 loss)
I1014 04:56:39.875831 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7366
I1014 04:56:40.175691 13701 solver.cpp:218] Iteration 70000 (2.11103 iter/s, 47.3702s/100 iters), loss = 0.00795569
I1014 04:56:40.175734 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00795597 (* 1 = 0.00795597 loss)
I1014 04:56:40.175740 13701 sgd_solver.cpp:105] Iteration 70000, lr = 0.001
I1014 04:57:10.667477 13701 solver.cpp:218] Iteration 70100 (3.27958 iter/s, 30.4918s/100 iters), loss = 0.00916141
I1014 04:57:10.667565 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00916168 (* 1 = 0.00916168 loss)
I1014 04:57:10.667584 13701 sgd_solver.cpp:105] Iteration 70100, lr = 0.001
I1014 04:57:41.190822 13701 solver.cpp:218] Iteration 70200 (3.27619 iter/s, 30.5233s/100 iters), loss = 0.0066897
I1014 04:57:41.190963 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00668997 (* 1 = 0.00668997 loss)
I1014 04:57:41.190970 13701 sgd_solver.cpp:105] Iteration 70200, lr = 0.001
I1014 04:58:11.689146 13701 solver.cpp:218] Iteration 70300 (3.27888 iter/s, 30.4982s/100 iters), loss = 0.0171185
I1014 04:58:11.689266 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171187 (* 1 = 0.0171187 loss)
I1014 04:58:11.689273 13701 sgd_solver.cpp:105] Iteration 70300, lr = 0.001
I1014 04:58:42.178429 13701 solver.cpp:218] Iteration 70400 (3.27985 iter/s, 30.4892s/100 iters), loss = 0.00471336
I1014 04:58:42.178529 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471363 (* 1 = 0.00471363 loss)
I1014 04:58:42.178547 13701 sgd_solver.cpp:105] Iteration 70400, lr = 0.001
I1014 04:59:12.388249 13701 solver.cpp:330] Iteration 70500, Testing net (#0)
I1014 04:59:28.900370 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 04:59:29.237983 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16754 (* 1 = 1.16754 loss)
I1014 04:59:29.237998 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7366
I1014 04:59:29.536991 13701 solver.cpp:218] Iteration 70500 (2.11155 iter/s, 47.3585s/100 iters), loss = 0.00669738
I1014 04:59:29.537027 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669765 (* 1 = 0.00669765 loss)
I1014 04:59:29.537035 13701 sgd_solver.cpp:105] Iteration 70500, lr = 0.001
I1014 05:00:00.028573 13701 solver.cpp:218] Iteration 70600 (3.2796 iter/s, 30.4916s/100 iters), loss = 0.00668612
I1014 05:00:00.028723 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00668639 (* 1 = 0.00668639 loss)
I1014 05:00:00.028746 13701 sgd_solver.cpp:105] Iteration 70600, lr = 0.001
I1014 05:00:30.535678 13701 solver.cpp:218] Iteration 70700 (3.27794 iter/s, 30.507s/100 iters), loss = 0.00878726
I1014 05:00:30.535867 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00878754 (* 1 = 0.00878754 loss)
I1014 05:00:30.535883 13701 sgd_solver.cpp:105] Iteration 70700, lr = 0.001
I1014 05:01:01.049268 13701 solver.cpp:218] Iteration 70800 (3.27725 iter/s, 30.5134s/100 iters), loss = 0.00520813
I1014 05:01:01.049386 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052084 (* 1 = 0.0052084 loss)
I1014 05:01:01.049409 13701 sgd_solver.cpp:105] Iteration 70800, lr = 0.001
I1014 05:01:31.562490 13701 solver.cpp:218] Iteration 70900 (3.27728 iter/s, 30.5131s/100 iters), loss = 0.00270313
I1014 05:01:31.563026 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027034 (* 1 = 0.0027034 loss)
I1014 05:01:31.563050 13701 sgd_solver.cpp:105] Iteration 70900, lr = 0.001
I1014 05:02:00.546561 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:02:01.767052 13701 solver.cpp:330] Iteration 71000, Testing net (#0)
I1014 05:02:18.280347 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:02:18.617682 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16584 (* 1 = 1.16584 loss)
I1014 05:02:18.617698 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7368
I1014 05:02:18.915864 13701 solver.cpp:218] Iteration 71000 (2.1118 iter/s, 47.3529s/100 iters), loss = 0.0210077
I1014 05:02:18.915899 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021008 (* 1 = 0.021008 loss)
I1014 05:02:18.915907 13701 sgd_solver.cpp:105] Iteration 71000, lr = 0.001
I1014 05:02:49.395611 13701 solver.cpp:218] Iteration 71100 (3.28087 iter/s, 30.4797s/100 iters), loss = 0.0103686
I1014 05:02:49.395743 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103689 (* 1 = 0.0103689 loss)
I1014 05:02:49.395754 13701 sgd_solver.cpp:105] Iteration 71100, lr = 0.001
I1014 05:03:19.857635 13701 solver.cpp:218] Iteration 71200 (3.28279 iter/s, 30.4619s/100 iters), loss = 0.00406827
I1014 05:03:19.857784 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406854 (* 1 = 0.00406854 loss)
I1014 05:03:19.857806 13701 sgd_solver.cpp:105] Iteration 71200, lr = 0.001
I1014 05:03:50.343994 13701 solver.cpp:218] Iteration 71300 (3.28017 iter/s, 30.4862s/100 iters), loss = 0.0101876
I1014 05:03:50.344144 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101879 (* 1 = 0.0101879 loss)
I1014 05:03:50.344167 13701 sgd_solver.cpp:105] Iteration 71300, lr = 0.001
I1014 05:04:20.820395 13701 solver.cpp:218] Iteration 71400 (3.28124 iter/s, 30.4763s/100 iters), loss = 0.00706842
I1014 05:04:20.820888 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706869 (* 1 = 0.00706869 loss)
I1014 05:04:20.820912 13701 sgd_solver.cpp:105] Iteration 71400, lr = 0.001
I1014 05:04:50.994235 13701 solver.cpp:330] Iteration 71500, Testing net (#0)
I1014 05:05:07.525995 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:05:07.864959 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16487 (* 1 = 1.16487 loss)
I1014 05:05:07.864975 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7367
I1014 05:05:08.164896 13701 solver.cpp:218] Iteration 71500 (2.1122 iter/s, 47.344s/100 iters), loss = 0.00637763
I1014 05:05:08.164928 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063779 (* 1 = 0.0063779 loss)
I1014 05:05:08.164937 13701 sgd_solver.cpp:105] Iteration 71500, lr = 0.001
I1014 05:05:38.633623 13701 solver.cpp:218] Iteration 71600 (3.28206 iter/s, 30.4687s/100 iters), loss = 0.00592204
I1014 05:05:38.633695 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00592231 (* 1 = 0.00592231 loss)
I1014 05:05:38.633705 13701 sgd_solver.cpp:105] Iteration 71600, lr = 0.001
I1014 05:06:09.103183 13701 solver.cpp:218] Iteration 71700 (3.28197 iter/s, 30.4695s/100 iters), loss = 0.00606737
I1014 05:06:09.103329 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00606764 (* 1 = 0.00606764 loss)
I1014 05:06:09.103353 13701 sgd_solver.cpp:105] Iteration 71700, lr = 0.001
I1014 05:06:39.570480 13701 solver.cpp:218] Iteration 71800 (3.28222 iter/s, 30.4672s/100 iters), loss = 0.00240008
I1014 05:06:39.570600 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240036 (* 1 = 0.00240036 loss)
I1014 05:06:39.570618 13701 sgd_solver.cpp:105] Iteration 71800, lr = 0.001
I1014 05:07:10.053514 13701 solver.cpp:218] Iteration 71900 (3.28053 iter/s, 30.4829s/100 iters), loss = 0.00431795
I1014 05:07:10.053645 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431823 (* 1 = 0.00431823 loss)
I1014 05:07:10.053654 13701 sgd_solver.cpp:105] Iteration 71900, lr = 0.001
I1014 05:07:39.005111 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:07:40.225535 13701 solver.cpp:330] Iteration 72000, Testing net (#0)
I1014 05:07:56.752097 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:07:57.089798 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16339 (* 1 = 1.16339 loss)
I1014 05:07:57.089813 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7372
I1014 05:07:57.390329 13701 solver.cpp:218] Iteration 72000 (2.11253 iter/s, 47.3367s/100 iters), loss = 0.00420642
I1014 05:07:57.390365 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042067 (* 1 = 0.0042067 loss)
I1014 05:07:57.390373 13701 sgd_solver.cpp:105] Iteration 72000, lr = 0.001
I1014 05:08:27.891782 13701 solver.cpp:218] Iteration 72100 (3.27854 iter/s, 30.5014s/100 iters), loss = 0.00594093
I1014 05:08:27.891929 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059412 (* 1 = 0.0059412 loss)
I1014 05:08:27.891938 13701 sgd_solver.cpp:105] Iteration 72100, lr = 0.001
I1014 05:08:58.384966 13701 solver.cpp:218] Iteration 72200 (3.27944 iter/s, 30.493s/100 iters), loss = 0.00397035
I1014 05:08:58.385068 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397063 (* 1 = 0.00397063 loss)
I1014 05:08:58.385087 13701 sgd_solver.cpp:105] Iteration 72200, lr = 0.001
I1014 05:09:28.889719 13701 solver.cpp:218] Iteration 72300 (3.27819 iter/s, 30.5047s/100 iters), loss = 0.0146821
I1014 05:09:28.889853 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146824 (* 1 = 0.0146824 loss)
I1014 05:09:28.889860 13701 sgd_solver.cpp:105] Iteration 72300, lr = 0.001
I1014 05:09:59.388172 13701 solver.cpp:218] Iteration 72400 (3.27887 iter/s, 30.4983s/100 iters), loss = 0.0122197
I1014 05:09:59.388244 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01222 (* 1 = 0.01222 loss)
I1014 05:09:59.388262 13701 sgd_solver.cpp:105] Iteration 72400, lr = 0.001
I1014 05:10:29.596904 13701 solver.cpp:330] Iteration 72500, Testing net (#0)
I1014 05:10:46.112978 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:10:46.450765 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16241 (* 1 = 1.16241 loss)
I1014 05:10:46.450780 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7369
I1014 05:10:46.751889 13701 solver.cpp:218] Iteration 72500 (2.11132 iter/s, 47.3637s/100 iters), loss = 0.00380345
I1014 05:10:46.751921 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380373 (* 1 = 0.00380373 loss)
I1014 05:10:46.751929 13701 sgd_solver.cpp:105] Iteration 72500, lr = 0.001
I1014 05:11:17.237709 13701 solver.cpp:218] Iteration 72600 (3.28022 iter/s, 30.4858s/100 iters), loss = 0.00621479
I1014 05:11:17.237835 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00621507 (* 1 = 0.00621507 loss)
I1014 05:11:17.237843 13701 sgd_solver.cpp:105] Iteration 72600, lr = 0.001
I1014 05:11:47.725251 13701 solver.cpp:218] Iteration 72700 (3.28004 iter/s, 30.4874s/100 iters), loss = 0.00455685
I1014 05:11:47.725359 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455713 (* 1 = 0.00455713 loss)
I1014 05:11:47.725366 13701 sgd_solver.cpp:105] Iteration 72700, lr = 0.001
I1014 05:12:18.215585 13701 solver.cpp:218] Iteration 72800 (3.27974 iter/s, 30.4902s/100 iters), loss = 0.00324541
I1014 05:12:18.215704 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324569 (* 1 = 0.00324569 loss)
I1014 05:12:18.215713 13701 sgd_solver.cpp:105] Iteration 72800, lr = 0.001
I1014 05:12:48.693998 13701 solver.cpp:218] Iteration 72900 (3.28102 iter/s, 30.4783s/100 iters), loss = 0.00243544
I1014 05:12:48.694136 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243571 (* 1 = 0.00243571 loss)
I1014 05:12:48.694145 13701 sgd_solver.cpp:105] Iteration 72900, lr = 0.001
I1014 05:13:17.659343 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:13:18.878131 13701 solver.cpp:330] Iteration 73000, Testing net (#0)
I1014 05:13:35.384583 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:13:35.722054 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16004 (* 1 = 1.16004 loss)
I1014 05:13:35.722070 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7369
I1014 05:13:36.021455 13701 solver.cpp:218] Iteration 73000 (2.11294 iter/s, 47.3273s/100 iters), loss = 0.00456733
I1014 05:13:36.021484 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456761 (* 1 = 0.00456761 loss)
I1014 05:13:36.021492 13701 sgd_solver.cpp:105] Iteration 73000, lr = 0.001
I1014 05:14:06.526295 13701 solver.cpp:218] Iteration 73100 (3.27817 iter/s, 30.5048s/100 iters), loss = 0.0100542
I1014 05:14:06.526444 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100545 (* 1 = 0.0100545 loss)
I1014 05:14:06.526453 13701 sgd_solver.cpp:105] Iteration 73100, lr = 0.001
I1014 05:14:37.048056 13701 solver.cpp:218] Iteration 73200 (3.27637 iter/s, 30.5216s/100 iters), loss = 0.00307062
I1014 05:14:37.048142 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030709 (* 1 = 0.0030709 loss)
I1014 05:14:37.048151 13701 sgd_solver.cpp:105] Iteration 73200, lr = 0.001
I1014 05:15:07.560788 13701 solver.cpp:218] Iteration 73300 (3.27733 iter/s, 30.5127s/100 iters), loss = 0.00744285
I1014 05:15:07.560930 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00744313 (* 1 = 0.00744313 loss)
I1014 05:15:07.560938 13701 sgd_solver.cpp:105] Iteration 73300, lr = 0.001
I1014 05:15:38.082072 13701 solver.cpp:218] Iteration 73400 (3.27642 iter/s, 30.5212s/100 iters), loss = 0.00485193
I1014 05:15:38.082165 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00485221 (* 1 = 0.00485221 loss)
I1014 05:15:38.082183 13701 sgd_solver.cpp:105] Iteration 73400, lr = 0.001
I1014 05:16:08.285418 13701 solver.cpp:330] Iteration 73500, Testing net (#0)
I1014 05:16:24.803750 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:16:25.142699 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15862 (* 1 = 1.15862 loss)
I1014 05:16:25.142714 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7371
I1014 05:16:25.446409 13701 solver.cpp:218] Iteration 73500 (2.1113 iter/s, 47.3643s/100 iters), loss = 0.00427
I1014 05:16:25.446444 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00427028 (* 1 = 0.00427028 loss)
I1014 05:16:25.446450 13701 sgd_solver.cpp:105] Iteration 73500, lr = 0.001
I1014 05:16:55.929644 13701 solver.cpp:218] Iteration 73600 (3.28049 iter/s, 30.4832s/100 iters), loss = 0.0040437
I1014 05:16:55.929742 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404398 (* 1 = 0.00404398 loss)
I1014 05:16:55.929759 13701 sgd_solver.cpp:105] Iteration 73600, lr = 0.001
I1014 05:17:26.409370 13701 solver.cpp:218] Iteration 73700 (3.28088 iter/s, 30.4796s/100 iters), loss = 0.00337923
I1014 05:17:26.409466 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337952 (* 1 = 0.00337952 loss)
I1014 05:17:26.409483 13701 sgd_solver.cpp:105] Iteration 73700, lr = 0.001
I1014 05:17:56.895217 13701 solver.cpp:218] Iteration 73800 (3.28022 iter/s, 30.4858s/100 iters), loss = 0.00478037
I1014 05:17:56.895373 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00478066 (* 1 = 0.00478066 loss)
I1014 05:17:56.895382 13701 sgd_solver.cpp:105] Iteration 73800, lr = 0.001
I1014 05:18:27.369365 13701 solver.cpp:218] Iteration 73900 (3.28149 iter/s, 30.474s/100 iters), loss = 0.00448833
I1014 05:18:27.369482 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448862 (* 1 = 0.00448862 loss)
I1014 05:18:27.369501 13701 sgd_solver.cpp:105] Iteration 73900, lr = 0.001
I1014 05:18:56.314802 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:18:57.535843 13701 solver.cpp:330] Iteration 74000, Testing net (#0)
I1014 05:19:14.050722 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:19:14.389427 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15711 (* 1 = 1.15711 loss)
I1014 05:19:14.389442 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1014 05:19:14.689700 13701 solver.cpp:218] Iteration 74000 (2.11326 iter/s, 47.3202s/100 iters), loss = 0.00814356
I1014 05:19:14.689733 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00814385 (* 1 = 0.00814385 loss)
I1014 05:19:14.689741 13701 sgd_solver.cpp:105] Iteration 74000, lr = 0.001
I1014 05:19:45.157068 13701 solver.cpp:218] Iteration 74100 (3.2822 iter/s, 30.4673s/100 iters), loss = 0.0135248
I1014 05:19:45.157207 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135251 (* 1 = 0.0135251 loss)
I1014 05:19:45.157213 13701 sgd_solver.cpp:105] Iteration 74100, lr = 0.001
I1014 05:20:15.626441 13701 solver.cpp:218] Iteration 74200 (3.282 iter/s, 30.4692s/100 iters), loss = 0.00970387
I1014 05:20:15.626585 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00970416 (* 1 = 0.00970416 loss)
I1014 05:20:15.626595 13701 sgd_solver.cpp:105] Iteration 74200, lr = 0.001
I1014 05:20:46.101260 13701 solver.cpp:218] Iteration 74300 (3.28141 iter/s, 30.4747s/100 iters), loss = 0.0104786
I1014 05:20:46.101361 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104789 (* 1 = 0.0104789 loss)
I1014 05:20:46.101367 13701 sgd_solver.cpp:105] Iteration 74300, lr = 0.001
I1014 05:21:16.572386 13701 solver.cpp:218] Iteration 74400 (3.28181 iter/s, 30.471s/100 iters), loss = 0.00563108
I1014 05:21:16.572530 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563137 (* 1 = 0.00563137 loss)
I1014 05:21:16.572537 13701 sgd_solver.cpp:105] Iteration 74400, lr = 0.001
I1014 05:21:46.747148 13701 solver.cpp:330] Iteration 74500, Testing net (#0)
I1014 05:22:03.252465 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:22:03.590687 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15466 (* 1 = 1.15466 loss)
I1014 05:22:03.590701 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7379
I1014 05:22:03.892494 13701 solver.cpp:218] Iteration 74500 (2.11327 iter/s, 47.32s/100 iters), loss = 0.00857723
I1014 05:22:03.892525 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00857752 (* 1 = 0.00857752 loss)
I1014 05:22:03.892532 13701 sgd_solver.cpp:105] Iteration 74500, lr = 0.001
I1014 05:22:34.357360 13701 solver.cpp:218] Iteration 74600 (3.28247 iter/s, 30.4648s/100 iters), loss = 0.00651068
I1014 05:22:34.357503 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651097 (* 1 = 0.00651097 loss)
I1014 05:22:34.357512 13701 sgd_solver.cpp:105] Iteration 74600, lr = 0.001
I1014 05:23:04.855397 13701 solver.cpp:218] Iteration 74700 (3.27891 iter/s, 30.4979s/100 iters), loss = 0.00286044
I1014 05:23:04.855484 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286072 (* 1 = 0.00286072 loss)
I1014 05:23:04.855492 13701 sgd_solver.cpp:105] Iteration 74700, lr = 0.001
I1014 05:23:35.354135 13701 solver.cpp:218] Iteration 74800 (3.27883 iter/s, 30.4987s/100 iters), loss = 0.00352454
I1014 05:23:35.354244 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352483 (* 1 = 0.00352483 loss)
I1014 05:23:35.354251 13701 sgd_solver.cpp:105] Iteration 74800, lr = 0.001
I1014 05:24:05.858445 13701 solver.cpp:218] Iteration 74900 (3.27824 iter/s, 30.5042s/100 iters), loss = 0.00628706
I1014 05:24:05.858613 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628734 (* 1 = 0.00628734 loss)
I1014 05:24:05.858623 13701 sgd_solver.cpp:105] Iteration 74900, lr = 0.001
I1014 05:24:34.852102 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:24:36.072295 13701 solver.cpp:330] Iteration 75000, Testing net (#0)
I1014 05:24:52.574494 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:24:52.911726 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15334 (* 1 = 1.15334 loss)
I1014 05:24:52.911741 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7376
I1014 05:24:53.211060 13701 solver.cpp:218] Iteration 75000 (2.11182 iter/s, 47.3525s/100 iters), loss = 0.00410577
I1014 05:24:53.211096 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410607 (* 1 = 0.00410607 loss)
I1014 05:24:53.211102 13701 sgd_solver.cpp:105] Iteration 75000, lr = 0.001
I1014 05:25:23.692224 13701 solver.cpp:218] Iteration 75100 (3.28072 iter/s, 30.4811s/100 iters), loss = 0.0143622
I1014 05:25:23.692339 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143625 (* 1 = 0.0143625 loss)
I1014 05:25:23.692356 13701 sgd_solver.cpp:105] Iteration 75100, lr = 0.001
I1014 05:25:54.191710 13701 solver.cpp:218] Iteration 75200 (3.27875 iter/s, 30.4994s/100 iters), loss = 0.00507939
I1014 05:25:54.191848 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507968 (* 1 = 0.00507968 loss)
I1014 05:25:54.191855 13701 sgd_solver.cpp:105] Iteration 75200, lr = 0.001
I1014 05:26:24.676355 13701 solver.cpp:218] Iteration 75300 (3.28035 iter/s, 30.4845s/100 iters), loss = 0.00810635
I1014 05:26:24.676489 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810664 (* 1 = 0.00810664 loss)
I1014 05:26:24.676497 13701 sgd_solver.cpp:105] Iteration 75300, lr = 0.001
I1014 05:26:55.180400 13701 solver.cpp:218] Iteration 75400 (3.27827 iter/s, 30.5039s/100 iters), loss = 0.00671553
I1014 05:26:55.180510 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671582 (* 1 = 0.00671582 loss)
I1014 05:26:55.180516 13701 sgd_solver.cpp:105] Iteration 75400, lr = 0.001
I1014 05:27:25.364861 13701 solver.cpp:330] Iteration 75500, Testing net (#0)
I1014 05:27:41.873280 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:27:42.210217 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15238 (* 1 = 1.15238 loss)
I1014 05:27:42.210232 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7383
I1014 05:27:42.511234 13701 solver.cpp:218] Iteration 75500 (2.11279 iter/s, 47.3307s/100 iters), loss = 0.011004
I1014 05:27:42.511268 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110043 (* 1 = 0.0110043 loss)
I1014 05:27:42.511276 13701 sgd_solver.cpp:105] Iteration 75500, lr = 0.001
I1014 05:28:13.027145 13701 solver.cpp:218] Iteration 75600 (3.27698 iter/s, 30.5159s/100 iters), loss = 0.00295121
I1014 05:28:13.027279 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029515 (* 1 = 0.0029515 loss)
I1014 05:28:13.027287 13701 sgd_solver.cpp:105] Iteration 75600, lr = 0.001
I1014 05:28:43.542969 13701 solver.cpp:218] Iteration 75700 (3.277 iter/s, 30.5157s/100 iters), loss = 0.00507831
I1014 05:28:43.543112 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507861 (* 1 = 0.00507861 loss)
I1014 05:28:43.543120 13701 sgd_solver.cpp:105] Iteration 75700, lr = 0.001
I1014 05:29:14.088302 13701 solver.cpp:218] Iteration 75800 (3.27384 iter/s, 30.5452s/100 iters), loss = 0.00487237
I1014 05:29:14.088423 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487266 (* 1 = 0.00487266 loss)
I1014 05:29:14.088429 13701 sgd_solver.cpp:105] Iteration 75800, lr = 0.001
I1014 05:29:44.620209 13701 solver.cpp:218] Iteration 75900 (3.27527 iter/s, 30.5318s/100 iters), loss = 0.00576074
I1014 05:29:44.620371 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576104 (* 1 = 0.00576104 loss)
I1014 05:29:44.620383 13701 sgd_solver.cpp:105] Iteration 75900, lr = 0.001
I1014 05:30:13.639869 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:30:14.871323 13701 solver.cpp:330] Iteration 76000, Testing net (#0)
I1014 05:30:31.440618 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:30:31.781456 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.151 (* 1 = 1.151 loss)
I1014 05:30:31.781471 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7376
I1014 05:30:32.083972 13701 solver.cpp:218] Iteration 76000 (2.10688 iter/s, 47.4636s/100 iters), loss = 0.00546986
I1014 05:30:32.084002 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00547015 (* 1 = 0.00547015 loss)
I1014 05:30:32.084007 13701 sgd_solver.cpp:105] Iteration 76000, lr = 0.001
I1014 05:31:02.589938 13701 solver.cpp:218] Iteration 76100 (3.27805 iter/s, 30.5059s/100 iters), loss = 0.00481932
I1014 05:31:02.590061 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481961 (* 1 = 0.00481961 loss)
I1014 05:31:02.590070 13701 sgd_solver.cpp:105] Iteration 76100, lr = 0.001
I1014 05:31:33.097790 13701 solver.cpp:218] Iteration 76200 (3.27786 iter/s, 30.5077s/100 iters), loss = 0.00623096
I1014 05:31:33.097941 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623126 (* 1 = 0.00623126 loss)
I1014 05:31:33.097960 13701 sgd_solver.cpp:105] Iteration 76200, lr = 0.001
I1014 05:32:03.611274 13701 solver.cpp:218] Iteration 76300 (3.27726 iter/s, 30.5133s/100 iters), loss = 0.013805
I1014 05:32:03.611377 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138053 (* 1 = 0.0138053 loss)
I1014 05:32:03.611384 13701 sgd_solver.cpp:105] Iteration 76300, lr = 0.001
I1014 05:32:34.103575 13701 solver.cpp:218] Iteration 76400 (3.27953 iter/s, 30.4922s/100 iters), loss = 0.00403527
I1014 05:32:34.103667 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403556 (* 1 = 0.00403556 loss)
I1014 05:32:34.103684 13701 sgd_solver.cpp:105] Iteration 76400, lr = 0.001
I1014 05:33:04.336493 13701 solver.cpp:330] Iteration 76500, Testing net (#0)
I1014 05:33:20.888095 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:33:21.229230 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14963 (* 1 = 1.14963 loss)
I1014 05:33:21.229245 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7359
I1014 05:33:21.531165 13701 solver.cpp:218] Iteration 76500 (2.10848 iter/s, 47.4275s/100 iters), loss = 0.0119965
I1014 05:33:21.531211 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119968 (* 1 = 0.0119968 loss)
I1014 05:33:21.531219 13701 sgd_solver.cpp:105] Iteration 76500, lr = 0.001
I1014 05:33:52.016140 13701 solver.cpp:218] Iteration 76600 (3.28031 iter/s, 30.4849s/100 iters), loss = 0.00364353
I1014 05:33:52.016273 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364382 (* 1 = 0.00364382 loss)
I1014 05:33:52.016281 13701 sgd_solver.cpp:105] Iteration 76600, lr = 0.001
I1014 05:34:22.542961 13701 solver.cpp:218] Iteration 76700 (3.27582 iter/s, 30.5267s/100 iters), loss = 0.00399453
I1014 05:34:22.543088 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399483 (* 1 = 0.00399483 loss)
I1014 05:34:22.543097 13701 sgd_solver.cpp:105] Iteration 76700, lr = 0.001
I1014 05:34:53.037797 13701 solver.cpp:218] Iteration 76800 (3.27926 iter/s, 30.4947s/100 iters), loss = 0.00484454
I1014 05:34:53.037942 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00484484 (* 1 = 0.00484484 loss)
I1014 05:34:53.037961 13701 sgd_solver.cpp:105] Iteration 76800, lr = 0.001
I1014 05:35:23.582999 13701 solver.cpp:218] Iteration 76900 (3.27385 iter/s, 30.5451s/100 iters), loss = 0.00407113
I1014 05:35:23.583124 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407142 (* 1 = 0.00407142 loss)
I1014 05:35:23.583132 13701 sgd_solver.cpp:105] Iteration 76900, lr = 0.001
I1014 05:35:52.553967 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:35:53.773797 13701 solver.cpp:330] Iteration 77000, Testing net (#0)
I1014 05:36:10.372002 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:36:10.710095 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14778 (* 1 = 1.14778 loss)
I1014 05:36:10.710111 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7359
I1014 05:36:11.010391 13701 solver.cpp:218] Iteration 77000 (2.10849 iter/s, 47.4273s/100 iters), loss = 0.00702123
I1014 05:36:11.010426 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702152 (* 1 = 0.00702152 loss)
I1014 05:36:11.010432 13701 sgd_solver.cpp:105] Iteration 77000, lr = 0.001
I1014 05:36:41.546615 13701 solver.cpp:218] Iteration 77100 (3.2748 iter/s, 30.5362s/100 iters), loss = 0.0061504
I1014 05:36:41.546730 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615068 (* 1 = 0.00615068 loss)
I1014 05:36:41.546747 13701 sgd_solver.cpp:105] Iteration 77100, lr = 0.001
I1014 05:37:12.018617 13701 solver.cpp:218] Iteration 77200 (3.28171 iter/s, 30.4719s/100 iters), loss = 0.00587481
I1014 05:37:12.018728 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00587509 (* 1 = 0.00587509 loss)
I1014 05:37:12.018735 13701 sgd_solver.cpp:105] Iteration 77200, lr = 0.001
I1014 05:37:42.500252 13701 solver.cpp:218] Iteration 77300 (3.28067 iter/s, 30.4815s/100 iters), loss = 0.00734804
I1014 05:37:42.500347 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00734833 (* 1 = 0.00734833 loss)
I1014 05:37:42.500365 13701 sgd_solver.cpp:105] Iteration 77300, lr = 0.001
I1014 05:38:13.026309 13701 solver.cpp:218] Iteration 77400 (3.2759 iter/s, 30.526s/100 iters), loss = 0.00283157
I1014 05:38:13.026419 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283186 (* 1 = 0.00283186 loss)
I1014 05:38:13.026427 13701 sgd_solver.cpp:105] Iteration 77400, lr = 0.001
I1014 05:38:43.202380 13701 solver.cpp:330] Iteration 77500, Testing net (#0)
I1014 05:38:59.785540 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:39:00.123996 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14586 (* 1 = 1.14586 loss)
I1014 05:39:00.124011 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7377
I1014 05:39:00.429584 13701 solver.cpp:218] Iteration 77500 (2.10956 iter/s, 47.4032s/100 iters), loss = 0.00457278
I1014 05:39:00.429618 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457307 (* 1 = 0.00457307 loss)
I1014 05:39:00.429626 13701 sgd_solver.cpp:105] Iteration 77500, lr = 0.001
I1014 05:39:30.926568 13701 solver.cpp:218] Iteration 77600 (3.27902 iter/s, 30.497s/100 iters), loss = 0.00356006
I1014 05:39:30.926672 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356035 (* 1 = 0.00356035 loss)
I1014 05:39:30.926690 13701 sgd_solver.cpp:105] Iteration 77600, lr = 0.001
I1014 05:40:01.405551 13701 solver.cpp:218] Iteration 77700 (3.28096 iter/s, 30.4789s/100 iters), loss = 0.00509438
I1014 05:40:01.405675 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00509467 (* 1 = 0.00509467 loss)
I1014 05:40:01.405683 13701 sgd_solver.cpp:105] Iteration 77700, lr = 0.001
I1014 05:40:31.889096 13701 solver.cpp:218] Iteration 77800 (3.28047 iter/s, 30.4834s/100 iters), loss = 0.0043294
I1014 05:40:31.889235 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432968 (* 1 = 0.00432968 loss)
I1014 05:40:31.889245 13701 sgd_solver.cpp:105] Iteration 77800, lr = 0.001
I1014 05:41:02.473487 13701 solver.cpp:218] Iteration 77900 (3.26966 iter/s, 30.5843s/100 iters), loss = 0.00380245
I1014 05:41:02.473625 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380274 (* 1 = 0.00380274 loss)
I1014 05:41:02.473645 13701 sgd_solver.cpp:105] Iteration 77900, lr = 0.001
I1014 05:41:31.470412 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:41:32.693240 13701 solver.cpp:330] Iteration 78000, Testing net (#0)
I1014 05:41:49.239617 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:41:49.583644 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14544 (* 1 = 1.14544 loss)
I1014 05:41:49.583660 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7375
I1014 05:41:49.888259 13701 solver.cpp:218] Iteration 78000 (2.10905 iter/s, 47.4146s/100 iters), loss = 0.00704354
I1014 05:41:49.888288 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704383 (* 1 = 0.00704383 loss)
I1014 05:41:49.888294 13701 sgd_solver.cpp:105] Iteration 78000, lr = 0.001
I1014 05:42:20.382618 13701 solver.cpp:218] Iteration 78100 (3.2793 iter/s, 30.4943s/100 iters), loss = 0.00573933
I1014 05:42:20.382766 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573962 (* 1 = 0.00573962 loss)
I1014 05:42:20.382776 13701 sgd_solver.cpp:105] Iteration 78100, lr = 0.001
I1014 05:42:50.884434 13701 solver.cpp:218] Iteration 78200 (3.27851 iter/s, 30.5017s/100 iters), loss = 0.00796352
I1014 05:42:50.884574 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796381 (* 1 = 0.00796381 loss)
I1014 05:42:50.884583 13701 sgd_solver.cpp:105] Iteration 78200, lr = 0.001
I1014 05:43:21.383237 13701 solver.cpp:218] Iteration 78300 (3.27883 iter/s, 30.4987s/100 iters), loss = 0.0148056
I1014 05:43:21.383348 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148059 (* 1 = 0.0148059 loss)
I1014 05:43:21.383357 13701 sgd_solver.cpp:105] Iteration 78300, lr = 0.001
I1014 05:43:51.890712 13701 solver.cpp:218] Iteration 78400 (3.2779 iter/s, 30.5074s/100 iters), loss = 0.00621215
I1014 05:43:51.890789 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00621243 (* 1 = 0.00621243 loss)
I1014 05:43:51.890805 13701 sgd_solver.cpp:105] Iteration 78400, lr = 0.001
I1014 05:44:22.076848 13701 solver.cpp:330] Iteration 78500, Testing net (#0)
I1014 05:44:38.665493 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:44:39.006683 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14487 (* 1 = 1.14487 loss)
I1014 05:44:39.006698 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7366
I1014 05:44:39.305616 13701 solver.cpp:218] Iteration 78500 (2.10904 iter/s, 47.4148s/100 iters), loss = 0.00402846
I1014 05:44:39.305651 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402874 (* 1 = 0.00402874 loss)
I1014 05:44:39.305660 13701 sgd_solver.cpp:105] Iteration 78500, lr = 0.001
I1014 05:45:09.840842 13701 solver.cpp:218] Iteration 78600 (3.27491 iter/s, 30.5352s/100 iters), loss = 0.00436241
I1014 05:45:09.840971 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043627 (* 1 = 0.0043627 loss)
I1014 05:45:09.840991 13701 sgd_solver.cpp:105] Iteration 78600, lr = 0.001
I1014 05:45:40.373991 13701 solver.cpp:218] Iteration 78700 (3.27514 iter/s, 30.533s/100 iters), loss = 0.00697528
I1014 05:45:40.374083 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00697557 (* 1 = 0.00697557 loss)
I1014 05:45:40.374099 13701 sgd_solver.cpp:105] Iteration 78700, lr = 0.001
I1014 05:46:10.855156 13701 solver.cpp:218] Iteration 78800 (3.28072 iter/s, 30.4811s/100 iters), loss = 0.00672125
I1014 05:46:10.855271 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00672154 (* 1 = 0.00672154 loss)
I1014 05:46:10.855279 13701 sgd_solver.cpp:105] Iteration 78800, lr = 0.001
I1014 05:46:41.395221 13701 solver.cpp:218] Iteration 78900 (3.2744 iter/s, 30.54s/100 iters), loss = 0.00431867
I1014 05:46:41.395366 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431896 (* 1 = 0.00431896 loss)
I1014 05:46:41.395375 13701 sgd_solver.cpp:105] Iteration 78900, lr = 0.001
I1014 05:47:10.420573 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:47:11.640552 13701 solver.cpp:330] Iteration 79000, Testing net (#0)
I1014 05:47:28.213994 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:47:28.553761 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14186 (* 1 = 1.14186 loss)
I1014 05:47:28.553777 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7374
I1014 05:47:28.852682 13701 solver.cpp:218] Iteration 79000 (2.10716 iter/s, 47.4573s/100 iters), loss = 0.00377254
I1014 05:47:28.852716 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377283 (* 1 = 0.00377283 loss)
I1014 05:47:28.852735 13701 sgd_solver.cpp:105] Iteration 79000, lr = 0.001
I1014 05:47:59.404431 13701 solver.cpp:218] Iteration 79100 (3.27314 iter/s, 30.5517s/100 iters), loss = 0.0116359
I1014 05:47:59.404572 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116362 (* 1 = 0.0116362 loss)
I1014 05:47:59.404580 13701 sgd_solver.cpp:105] Iteration 79100, lr = 0.001
I1014 05:48:29.955404 13701 solver.cpp:218] Iteration 79200 (3.27323 iter/s, 30.5508s/100 iters), loss = 0.00462136
I1014 05:48:29.955803 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462165 (* 1 = 0.00462165 loss)
I1014 05:48:29.955821 13701 sgd_solver.cpp:105] Iteration 79200, lr = 0.001
I1014 05:49:00.482823 13701 solver.cpp:218] Iteration 79300 (3.27579 iter/s, 30.527s/100 iters), loss = 0.00897724
I1014 05:49:00.482960 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00897753 (* 1 = 0.00897753 loss)
I1014 05:49:00.482969 13701 sgd_solver.cpp:105] Iteration 79300, lr = 0.001
I1014 05:49:31.055817 13701 solver.cpp:218] Iteration 79400 (3.27087 iter/s, 30.5729s/100 iters), loss = 0.00244252
I1014 05:49:31.055958 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244281 (* 1 = 0.00244281 loss)
I1014 05:49:31.055966 13701 sgd_solver.cpp:105] Iteration 79400, lr = 0.001
I1014 05:50:01.257148 13701 solver.cpp:330] Iteration 79500, Testing net (#0)
I1014 05:50:17.802546 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:50:18.142206 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14102 (* 1 = 1.14102 loss)
I1014 05:50:18.142220 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7375
I1014 05:50:18.442157 13701 solver.cpp:218] Iteration 79500 (2.11032 iter/s, 47.3862s/100 iters), loss = 0.00713314
I1014 05:50:18.442193 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713343 (* 1 = 0.00713343 loss)
I1014 05:50:18.442200 13701 sgd_solver.cpp:105] Iteration 79500, lr = 0.001
I1014 05:50:48.982427 13701 solver.cpp:218] Iteration 79600 (3.27437 iter/s, 30.5402s/100 iters), loss = 0.00414018
I1014 05:50:48.982560 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414047 (* 1 = 0.00414047 loss)
I1014 05:50:48.982569 13701 sgd_solver.cpp:105] Iteration 79600, lr = 0.001
I1014 05:51:19.538290 13701 solver.cpp:218] Iteration 79700 (3.27271 iter/s, 30.5557s/100 iters), loss = 0.00268657
I1014 05:51:19.538396 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268686 (* 1 = 0.00268686 loss)
I1014 05:51:19.538414 13701 sgd_solver.cpp:105] Iteration 79700, lr = 0.001
I1014 05:51:50.084875 13701 solver.cpp:218] Iteration 79800 (3.2737 iter/s, 30.5465s/100 iters), loss = 0.00341455
I1014 05:51:50.085018 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341485 (* 1 = 0.00341485 loss)
I1014 05:51:50.085026 13701 sgd_solver.cpp:105] Iteration 79800, lr = 0.001
I1014 05:52:20.589756 13701 solver.cpp:218] Iteration 79900 (3.27818 iter/s, 30.5047s/100 iters), loss = 0.00492959
I1014 05:52:20.589864 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492988 (* 1 = 0.00492988 loss)
I1014 05:52:20.589871 13701 sgd_solver.cpp:105] Iteration 79900, lr = 0.001
I1014 05:52:49.619565 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:52:50.835425 13701 solver.cpp:330] Iteration 80000, Testing net (#0)
I1014 05:53:07.379340 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:53:07.718380 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13941 (* 1 = 1.13941 loss)
I1014 05:53:07.718395 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7378
I1014 05:53:08.021502 13701 solver.cpp:218] Iteration 80000 (2.1083 iter/s, 47.4316s/100 iters), loss = 0.00459165
I1014 05:53:08.021531 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459195 (* 1 = 0.00459195 loss)
I1014 05:53:08.021538 13701 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1014 05:53:08.021543 13701 sgd_solver.cpp:105] Iteration 80000, lr = 0.0001
I1014 05:53:38.615627 13701 solver.cpp:218] Iteration 80100 (3.2686 iter/s, 30.5941s/100 iters), loss = 0.0111202
I1014 05:53:38.615792 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111205 (* 1 = 0.0111205 loss)
I1014 05:53:38.615800 13701 sgd_solver.cpp:105] Iteration 80100, lr = 0.0001
I1014 05:54:09.183581 13701 solver.cpp:218] Iteration 80200 (3.27142 iter/s, 30.5678s/100 iters), loss = 0.0055815
I1014 05:54:09.183678 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055818 (* 1 = 0.0055818 loss)
I1014 05:54:09.183696 13701 sgd_solver.cpp:105] Iteration 80200, lr = 0.0001
I1014 05:54:39.750984 13701 solver.cpp:218] Iteration 80300 (3.27147 iter/s, 30.5673s/100 iters), loss = 0.00803056
I1014 05:54:39.751126 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00803085 (* 1 = 0.00803085 loss)
I1014 05:54:39.751133 13701 sgd_solver.cpp:105] Iteration 80300, lr = 0.0001
I1014 05:55:10.301856 13701 solver.cpp:218] Iteration 80400 (3.27324 iter/s, 30.5507s/100 iters), loss = 0.0046264
I1014 05:55:10.301998 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462669 (* 1 = 0.00462669 loss)
I1014 05:55:10.302006 13701 sgd_solver.cpp:105] Iteration 80400, lr = 0.0001
I1014 05:55:40.575826 13701 solver.cpp:330] Iteration 80500, Testing net (#0)
I1014 05:55:57.147938 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:55:57.487624 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13914 (* 1 = 1.13914 loss)
I1014 05:55:57.487639 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7382
I1014 05:55:57.789644 13701 solver.cpp:218] Iteration 80500 (2.10581 iter/s, 47.4877s/100 iters), loss = 0.00663279
I1014 05:55:57.789674 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663308 (* 1 = 0.00663308 loss)
I1014 05:55:57.789681 13701 sgd_solver.cpp:105] Iteration 80500, lr = 0.0001
I1014 05:56:28.349673 13701 solver.cpp:218] Iteration 80600 (3.27225 iter/s, 30.56s/100 iters), loss = 0.00281691
I1014 05:56:28.349798 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281719 (* 1 = 0.00281719 loss)
I1014 05:56:28.349807 13701 sgd_solver.cpp:105] Iteration 80600, lr = 0.0001
I1014 05:56:58.889647 13701 solver.cpp:218] Iteration 80700 (3.27441 iter/s, 30.5399s/100 iters), loss = 0.00320894
I1014 05:56:58.889744 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320923 (* 1 = 0.00320923 loss)
I1014 05:56:58.889761 13701 sgd_solver.cpp:105] Iteration 80700, lr = 0.0001
I1014 05:57:29.440054 13701 solver.cpp:218] Iteration 80800 (3.27329 iter/s, 30.5503s/100 iters), loss = 0.0062135
I1014 05:57:29.440196 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00621379 (* 1 = 0.00621379 loss)
I1014 05:57:29.440204 13701 sgd_solver.cpp:105] Iteration 80800, lr = 0.0001
I1014 05:58:00.018304 13701 solver.cpp:218] Iteration 80900 (3.27031 iter/s, 30.5781s/100 iters), loss = 0.00337405
I1014 05:58:00.018399 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337434 (* 1 = 0.00337434 loss)
I1014 05:58:00.018406 13701 sgd_solver.cpp:105] Iteration 80900, lr = 0.0001
I1014 05:58:29.042888 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:58:30.258442 13701 solver.cpp:330] Iteration 81000, Testing net (#0)
I1014 05:58:46.855731 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 05:58:47.192642 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13886 (* 1 = 1.13886 loss)
I1014 05:58:47.192657 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7378
I1014 05:58:47.493959 13701 solver.cpp:218] Iteration 81000 (2.10635 iter/s, 47.4756s/100 iters), loss = 0.00700153
I1014 05:58:47.493995 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700182 (* 1 = 0.00700182 loss)
I1014 05:58:47.494002 13701 sgd_solver.cpp:105] Iteration 81000, lr = 0.0001
I1014 05:59:18.063827 13701 solver.cpp:218] Iteration 81100 (3.2712 iter/s, 30.5698s/100 iters), loss = 0.00654908
I1014 05:59:18.063988 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00654937 (* 1 = 0.00654937 loss)
I1014 05:59:18.064009 13701 sgd_solver.cpp:105] Iteration 81100, lr = 0.0001
I1014 05:59:48.587771 13701 solver.cpp:218] Iteration 81200 (3.27613 iter/s, 30.5238s/100 iters), loss = 0.00369011
I1014 05:59:48.587906 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036904 (* 1 = 0.0036904 loss)
I1014 05:59:48.587913 13701 sgd_solver.cpp:105] Iteration 81200, lr = 0.0001
I1014 06:00:19.124060 13701 solver.cpp:218] Iteration 81300 (3.27481 iter/s, 30.5362s/100 iters), loss = 0.00824436
I1014 06:00:19.124204 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00824464 (* 1 = 0.00824464 loss)
I1014 06:00:19.124213 13701 sgd_solver.cpp:105] Iteration 81300, lr = 0.0001
I1014 06:00:49.630161 13701 solver.cpp:218] Iteration 81400 (3.27805 iter/s, 30.506s/100 iters), loss = 0.00528728
I1014 06:00:49.630265 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00528757 (* 1 = 0.00528757 loss)
I1014 06:00:49.630272 13701 sgd_solver.cpp:105] Iteration 81400, lr = 0.0001
I1014 06:01:19.857277 13701 solver.cpp:330] Iteration 81500, Testing net (#0)
I1014 06:01:36.430583 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:01:36.769606 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13883 (* 1 = 1.13883 loss)
I1014 06:01:36.769621 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7376
I1014 06:01:37.070412 13701 solver.cpp:218] Iteration 81500 (2.10792 iter/s, 47.4402s/100 iters), loss = 0.00522861
I1014 06:01:37.070442 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052289 (* 1 = 0.0052289 loss)
I1014 06:01:37.070449 13701 sgd_solver.cpp:105] Iteration 81500, lr = 0.0001
I1014 06:02:07.569089 13701 solver.cpp:218] Iteration 81600 (3.27883 iter/s, 30.4986s/100 iters), loss = 0.00313574
I1014 06:02:07.569238 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00313603 (* 1 = 0.00313603 loss)
I1014 06:02:07.569258 13701 sgd_solver.cpp:105] Iteration 81600, lr = 0.0001
I1014 06:02:38.078603 13701 solver.cpp:218] Iteration 81700 (3.27768 iter/s, 30.5094s/100 iters), loss = 0.00347738
I1014 06:02:38.078714 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347767 (* 1 = 0.00347767 loss)
I1014 06:02:38.078722 13701 sgd_solver.cpp:105] Iteration 81700, lr = 0.0001
I1014 06:03:08.599512 13701 solver.cpp:218] Iteration 81800 (3.27645 iter/s, 30.5208s/100 iters), loss = 0.00674608
I1014 06:03:08.599650 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00674637 (* 1 = 0.00674637 loss)
I1014 06:03:08.599658 13701 sgd_solver.cpp:105] Iteration 81800, lr = 0.0001
I1014 06:03:39.054158 13701 solver.cpp:218] Iteration 81900 (3.28359 iter/s, 30.4545s/100 iters), loss = 0.00492057
I1014 06:03:39.054263 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492086 (* 1 = 0.00492086 loss)
I1014 06:03:39.054280 13701 sgd_solver.cpp:105] Iteration 81900, lr = 0.0001
I1014 06:04:08.016857 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:04:09.242149 13701 solver.cpp:330] Iteration 82000, Testing net (#0)
I1014 06:04:25.849376 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:04:26.188159 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13868 (* 1 = 1.13868 loss)
I1014 06:04:26.188174 13701 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1014 06:04:26.488360 13701 solver.cpp:218] Iteration 82000 (2.10819 iter/s, 47.4341s/100 iters), loss = 0.00921475
I1014 06:04:26.488395 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00921504 (* 1 = 0.00921504 loss)
I1014 06:04:26.488402 13701 sgd_solver.cpp:105] Iteration 82000, lr = 0.0001
I1014 06:04:57.017194 13701 solver.cpp:218] Iteration 82100 (3.27559 iter/s, 30.5288s/100 iters), loss = 0.00823804
I1014 06:04:57.017323 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823832 (* 1 = 0.00823832 loss)
I1014 06:04:57.017331 13701 sgd_solver.cpp:105] Iteration 82100, lr = 0.0001
I1014 06:05:27.519978 13701 solver.cpp:218] Iteration 82200 (3.2784 iter/s, 30.5027s/100 iters), loss = 0.00484192
I1014 06:05:27.520057 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0048422 (* 1 = 0.0048422 loss)
I1014 06:05:27.520076 13701 sgd_solver.cpp:105] Iteration 82200, lr = 0.0001
I1014 06:05:58.010818 13701 solver.cpp:218] Iteration 82300 (3.27968 iter/s, 30.4908s/100 iters), loss = 0.00874142
I1014 06:05:58.010916 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00874171 (* 1 = 0.00874171 loss)
I1014 06:05:58.010923 13701 sgd_solver.cpp:105] Iteration 82300, lr = 0.0001
I1014 06:06:28.564787 13701 solver.cpp:218] Iteration 82400 (3.27291 iter/s, 30.5539s/100 iters), loss = 0.0103264
I1014 06:06:28.564920 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103266 (* 1 = 0.0103266 loss)
I1014 06:06:28.564929 13701 sgd_solver.cpp:105] Iteration 82400, lr = 0.0001
I1014 06:06:58.806617 13701 solver.cpp:330] Iteration 82500, Testing net (#0)
I1014 06:07:15.431196 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:07:15.771481 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13852 (* 1 = 1.13852 loss)
I1014 06:07:15.771497 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7375
I1014 06:07:16.075033 13701 solver.cpp:218] Iteration 82500 (2.10481 iter/s, 47.5101s/100 iters), loss = 0.00515141
I1014 06:07:16.075065 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515169 (* 1 = 0.00515169 loss)
I1014 06:07:16.075073 13701 sgd_solver.cpp:105] Iteration 82500, lr = 0.0001
I1014 06:07:46.621609 13701 solver.cpp:218] Iteration 82600 (3.27369 iter/s, 30.5465s/100 iters), loss = 0.00325424
I1014 06:07:46.621752 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325453 (* 1 = 0.00325453 loss)
I1014 06:07:46.621762 13701 sgd_solver.cpp:105] Iteration 82600, lr = 0.0001
I1014 06:08:17.167668 13701 solver.cpp:218] Iteration 82700 (3.27376 iter/s, 30.5459s/100 iters), loss = 0.00385802
I1014 06:08:17.167780 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038583 (* 1 = 0.0038583 loss)
I1014 06:08:17.167796 13701 sgd_solver.cpp:105] Iteration 82700, lr = 0.0001
I1014 06:08:47.690707 13701 solver.cpp:218] Iteration 82800 (3.27622 iter/s, 30.5229s/100 iters), loss = 0.00473497
I1014 06:08:47.691071 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473525 (* 1 = 0.00473525 loss)
I1014 06:08:47.691079 13701 sgd_solver.cpp:105] Iteration 82800, lr = 0.0001
I1014 06:09:18.285995 13701 solver.cpp:218] Iteration 82900 (3.26852 iter/s, 30.5949s/100 iters), loss = 0.00435427
I1014 06:09:18.286136 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435455 (* 1 = 0.00435455 loss)
I1014 06:09:18.286146 13701 sgd_solver.cpp:105] Iteration 82900, lr = 0.0001
I1014 06:09:47.330313 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:09:48.553577 13701 solver.cpp:330] Iteration 83000, Testing net (#0)
I1014 06:10:05.133992 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:10:05.472930 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13833 (* 1 = 1.13833 loss)
I1014 06:10:05.472946 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7378
I1014 06:10:05.775941 13701 solver.cpp:218] Iteration 83000 (2.10571 iter/s, 47.4898s/100 iters), loss = 0.00584727
I1014 06:10:05.775977 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00584755 (* 1 = 0.00584755 loss)
I1014 06:10:05.775985 13701 sgd_solver.cpp:105] Iteration 83000, lr = 0.0001
I1014 06:10:36.333348 13701 solver.cpp:218] Iteration 83100 (3.27253 iter/s, 30.5574s/100 iters), loss = 0.00703377
I1014 06:10:36.333834 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00703406 (* 1 = 0.00703406 loss)
I1014 06:10:36.333843 13701 sgd_solver.cpp:105] Iteration 83100, lr = 0.0001
I1014 06:11:06.895028 13701 solver.cpp:218] Iteration 83200 (3.27212 iter/s, 30.5612s/100 iters), loss = 0.00324835
I1014 06:11:06.895165 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324863 (* 1 = 0.00324863 loss)
I1014 06:11:06.895172 13701 sgd_solver.cpp:105] Iteration 83200, lr = 0.0001
I1014 06:11:37.450117 13701 solver.cpp:218] Iteration 83300 (3.27279 iter/s, 30.555s/100 iters), loss = 0.0101245
I1014 06:11:37.450254 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101248 (* 1 = 0.0101248 loss)
I1014 06:11:37.450261 13701 sgd_solver.cpp:105] Iteration 83300, lr = 0.0001
I1014 06:12:08.011477 13701 solver.cpp:218] Iteration 83400 (3.27212 iter/s, 30.5612s/100 iters), loss = 0.00394303
I1014 06:12:08.011555 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394331 (* 1 = 0.00394331 loss)
I1014 06:12:08.011572 13701 sgd_solver.cpp:105] Iteration 83400, lr = 0.0001
I1014 06:12:38.278475 13701 solver.cpp:330] Iteration 83500, Testing net (#0)
I1014 06:12:54.850423 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:12:55.189159 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13815 (* 1 = 1.13815 loss)
I1014 06:12:55.189175 13701 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1014 06:12:55.490558 13701 solver.cpp:218] Iteration 83500 (2.10619 iter/s, 47.479s/100 iters), loss = 0.00715831
I1014 06:12:55.490591 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715859 (* 1 = 0.00715859 loss)
I1014 06:12:55.490597 13701 sgd_solver.cpp:105] Iteration 83500, lr = 0.0001
I1014 06:13:26.075953 13701 solver.cpp:218] Iteration 83600 (3.26954 iter/s, 30.5854s/100 iters), loss = 0.00574803
I1014 06:13:26.076064 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574831 (* 1 = 0.00574831 loss)
I1014 06:13:26.076072 13701 sgd_solver.cpp:105] Iteration 83600, lr = 0.0001
I1014 06:13:56.639199 13701 solver.cpp:218] Iteration 83700 (3.27191 iter/s, 30.5632s/100 iters), loss = 0.00449952
I1014 06:13:56.640069 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449981 (* 1 = 0.00449981 loss)
I1014 06:13:56.640085 13701 sgd_solver.cpp:105] Iteration 83700, lr = 0.0001
I1014 06:14:27.187093 13701 solver.cpp:218] Iteration 83800 (3.27364 iter/s, 30.547s/100 iters), loss = 0.0028223
I1014 06:14:27.187199 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282258 (* 1 = 0.00282258 loss)
I1014 06:14:27.187216 13701 sgd_solver.cpp:105] Iteration 83800, lr = 0.0001
I1014 06:14:57.719162 13701 solver.cpp:218] Iteration 83900 (3.27525 iter/s, 30.532s/100 iters), loss = 0.00388407
I1014 06:14:57.719288 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388435 (* 1 = 0.00388435 loss)
I1014 06:14:57.719297 13701 sgd_solver.cpp:105] Iteration 83900, lr = 0.0001
I1014 06:15:26.773869 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:15:27.992696 13701 solver.cpp:330] Iteration 84000, Testing net (#0)
I1014 06:15:44.606825 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:15:44.947485 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13783 (* 1 = 1.13783 loss)
I1014 06:15:44.947499 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7382
I1014 06:15:45.250037 13701 solver.cpp:218] Iteration 84000 (2.1039 iter/s, 47.5308s/100 iters), loss = 0.00474972
I1014 06:15:45.250072 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475 (* 1 = 0.00475 loss)
I1014 06:15:45.250079 13701 sgd_solver.cpp:105] Iteration 84000, lr = 0.0001
I1014 06:16:15.763511 13701 solver.cpp:218] Iteration 84100 (3.27724 iter/s, 30.5134s/100 iters), loss = 0.00505962
I1014 06:16:15.763653 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050599 (* 1 = 0.0050599 loss)
I1014 06:16:15.763659 13701 sgd_solver.cpp:105] Iteration 84100, lr = 0.0001
I1014 06:16:46.280531 13701 solver.cpp:218] Iteration 84200 (3.27687 iter/s, 30.5169s/100 iters), loss = 0.00423027
I1014 06:16:46.280679 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423055 (* 1 = 0.00423055 loss)
I1014 06:16:46.280689 13701 sgd_solver.cpp:105] Iteration 84200, lr = 0.0001
I1014 06:17:16.793908 13701 solver.cpp:218] Iteration 84300 (3.27727 iter/s, 30.5132s/100 iters), loss = 0.00784964
I1014 06:17:16.794030 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784993 (* 1 = 0.00784993 loss)
I1014 06:17:16.794049 13701 sgd_solver.cpp:105] Iteration 84300, lr = 0.0001
I1014 06:17:47.291070 13701 solver.cpp:218] Iteration 84400 (3.27901 iter/s, 30.4971s/100 iters), loss = 0.00458228
I1014 06:17:47.291187 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458256 (* 1 = 0.00458256 loss)
I1014 06:17:47.291203 13701 sgd_solver.cpp:105] Iteration 84400, lr = 0.0001
I1014 06:18:17.466410 13701 solver.cpp:330] Iteration 84500, Testing net (#0)
I1014 06:18:34.054085 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:18:34.391067 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13756 (* 1 = 1.13756 loss)
I1014 06:18:34.391084 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1014 06:18:34.690910 13701 solver.cpp:218] Iteration 84500 (2.10972 iter/s, 47.3997s/100 iters), loss = 0.004612
I1014 06:18:34.690943 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461228 (* 1 = 0.00461228 loss)
I1014 06:18:34.690949 13701 sgd_solver.cpp:105] Iteration 84500, lr = 0.0001
I1014 06:19:05.225920 13701 solver.cpp:218] Iteration 84600 (3.27493 iter/s, 30.535s/100 iters), loss = 0.00332896
I1014 06:19:05.226023 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332924 (* 1 = 0.00332924 loss)
I1014 06:19:05.226042 13701 sgd_solver.cpp:105] Iteration 84600, lr = 0.0001
I1014 06:19:35.738672 13701 solver.cpp:218] Iteration 84700 (3.27733 iter/s, 30.5127s/100 iters), loss = 0.00290989
I1014 06:19:35.738811 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291017 (* 1 = 0.00291017 loss)
I1014 06:19:35.738821 13701 sgd_solver.cpp:105] Iteration 84700, lr = 0.0001
I1014 06:20:06.245153 13701 solver.cpp:218] Iteration 84800 (3.27801 iter/s, 30.5063s/100 iters), loss = 0.00653745
I1014 06:20:06.245286 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653773 (* 1 = 0.00653773 loss)
I1014 06:20:06.245296 13701 sgd_solver.cpp:105] Iteration 84800, lr = 0.0001
I1014 06:20:36.767907 13701 solver.cpp:218] Iteration 84900 (3.27626 iter/s, 30.5226s/100 iters), loss = 0.00302984
I1014 06:20:36.768016 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303012 (* 1 = 0.00303012 loss)
I1014 06:20:36.768024 13701 sgd_solver.cpp:105] Iteration 84900, lr = 0.0001
I1014 06:21:05.761819 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:21:06.975886 13701 solver.cpp:330] Iteration 85000, Testing net (#0)
I1014 06:21:23.601835 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:21:23.943058 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13747 (* 1 = 1.13747 loss)
I1014 06:21:23.943074 13701 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1014 06:21:24.243330 13701 solver.cpp:218] Iteration 85000 (2.10636 iter/s, 47.4753s/100 iters), loss = 0.0110352
I1014 06:21:24.243365 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110355 (* 1 = 0.0110355 loss)
I1014 06:21:24.243371 13701 sgd_solver.cpp:105] Iteration 85000, lr = 0.0001
I1014 06:21:54.714540 13701 solver.cpp:218] Iteration 85100 (3.28179 iter/s, 30.4712s/100 iters), loss = 0.0071737
I1014 06:21:54.714682 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00717398 (* 1 = 0.00717398 loss)
I1014 06:21:54.714690 13701 sgd_solver.cpp:105] Iteration 85100, lr = 0.0001
I1014 06:22:25.234167 13701 solver.cpp:218] Iteration 85200 (3.27659 iter/s, 30.5195s/100 iters), loss = 0.00612255
I1014 06:22:25.234297 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612283 (* 1 = 0.00612283 loss)
I1014 06:22:25.234303 13701 sgd_solver.cpp:105] Iteration 85200, lr = 0.0001
I1014 06:22:55.720693 13701 solver.cpp:218] Iteration 85300 (3.28015 iter/s, 30.4864s/100 iters), loss = 0.00725708
I1014 06:22:55.720835 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725736 (* 1 = 0.00725736 loss)
I1014 06:22:55.720842 13701 sgd_solver.cpp:105] Iteration 85300, lr = 0.0001
I1014 06:23:26.209589 13701 solver.cpp:218] Iteration 85400 (3.2799 iter/s, 30.4888s/100 iters), loss = 0.00270816
I1014 06:23:26.209722 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270844 (* 1 = 0.00270844 loss)
I1014 06:23:26.209731 13701 sgd_solver.cpp:105] Iteration 85400, lr = 0.0001
I1014 06:23:56.417117 13701 solver.cpp:330] Iteration 85500, Testing net (#0)
I1014 06:24:12.974973 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:24:13.314677 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13721 (* 1 = 1.13721 loss)
I1014 06:24:13.314693 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7385
I1014 06:24:13.615922 13701 solver.cpp:218] Iteration 85500 (2.10943 iter/s, 47.4062s/100 iters), loss = 0.00851133
I1014 06:24:13.615952 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0085116 (* 1 = 0.0085116 loss)
I1014 06:24:13.615959 13701 sgd_solver.cpp:105] Iteration 85500, lr = 0.0001
I1014 06:24:44.183833 13701 solver.cpp:218] Iteration 85600 (3.27141 iter/s, 30.5679s/100 iters), loss = 0.00402138
I1014 06:24:44.183943 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402165 (* 1 = 0.00402165 loss)
I1014 06:24:44.183959 13701 sgd_solver.cpp:105] Iteration 85600, lr = 0.0001
I1014 06:25:14.746261 13701 solver.cpp:218] Iteration 85700 (3.272 iter/s, 30.5623s/100 iters), loss = 0.00387608
I1014 06:25:14.746366 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387636 (* 1 = 0.00387636 loss)
I1014 06:25:14.746383 13701 sgd_solver.cpp:105] Iteration 85700, lr = 0.0001
I1014 06:25:45.260131 13701 solver.cpp:218] Iteration 85800 (3.27721 iter/s, 30.5138s/100 iters), loss = 0.00519711
I1014 06:25:45.260232 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00519738 (* 1 = 0.00519738 loss)
I1014 06:25:45.260239 13701 sgd_solver.cpp:105] Iteration 85800, lr = 0.0001
I1014 06:26:15.795191 13701 solver.cpp:218] Iteration 85900 (3.27493 iter/s, 30.535s/100 iters), loss = 0.00352722
I1014 06:26:15.795301 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035275 (* 1 = 0.0035275 loss)
I1014 06:26:15.795318 13701 sgd_solver.cpp:105] Iteration 85900, lr = 0.0001
I1014 06:26:44.760272 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:26:45.978865 13701 solver.cpp:330] Iteration 86000, Testing net (#0)
I1014 06:27:02.546566 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:27:02.888494 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13709 (* 1 = 1.13709 loss)
I1014 06:27:02.888507 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7379
I1014 06:27:03.190879 13701 solver.cpp:218] Iteration 86000 (2.1099 iter/s, 47.3956s/100 iters), loss = 0.00270303
I1014 06:27:03.190913 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270331 (* 1 = 0.00270331 loss)
I1014 06:27:03.190922 13701 sgd_solver.cpp:105] Iteration 86000, lr = 0.0001
I1014 06:27:33.702317 13701 solver.cpp:218] Iteration 86100 (3.27746 iter/s, 30.5114s/100 iters), loss = 0.0106504
I1014 06:27:33.702425 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106507 (* 1 = 0.0106507 loss)
I1014 06:27:33.702441 13701 sgd_solver.cpp:105] Iteration 86100, lr = 0.0001
I1014 06:28:04.195116 13701 solver.cpp:218] Iteration 86200 (3.27947 iter/s, 30.4927s/100 iters), loss = 0.00856826
I1014 06:28:04.195770 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00856854 (* 1 = 0.00856854 loss)
I1014 06:28:04.195777 13701 sgd_solver.cpp:105] Iteration 86200, lr = 0.0001
I1014 06:28:34.681015 13701 solver.cpp:218] Iteration 86300 (3.28027 iter/s, 30.4853s/100 iters), loss = 0.0107523
I1014 06:28:34.681381 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107526 (* 1 = 0.0107526 loss)
I1014 06:28:34.681391 13701 sgd_solver.cpp:105] Iteration 86300, lr = 0.0001
I1014 06:29:05.259367 13701 solver.cpp:218] Iteration 86400 (3.27033 iter/s, 30.578s/100 iters), loss = 0.00480263
I1014 06:29:05.259480 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00480291 (* 1 = 0.00480291 loss)
I1014 06:29:05.259497 13701 sgd_solver.cpp:105] Iteration 86400, lr = 0.0001
I1014 06:29:35.493640 13701 solver.cpp:330] Iteration 86500, Testing net (#0)
I1014 06:29:52.056870 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:29:52.395484 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13681 (* 1 = 1.13681 loss)
I1014 06:29:52.395499 13701 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1014 06:29:52.696039 13701 solver.cpp:218] Iteration 86500 (2.10808 iter/s, 47.4366s/100 iters), loss = 0.00718385
I1014 06:29:52.696070 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00718413 (* 1 = 0.00718413 loss)
I1014 06:29:52.696077 13701 sgd_solver.cpp:105] Iteration 86500, lr = 0.0001
I1014 06:30:23.208652 13701 solver.cpp:218] Iteration 86600 (3.27734 iter/s, 30.5126s/100 iters), loss = 0.00462154
I1014 06:30:23.208766 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462182 (* 1 = 0.00462182 loss)
I1014 06:30:23.208783 13701 sgd_solver.cpp:105] Iteration 86600, lr = 0.0001
I1014 06:30:53.750641 13701 solver.cpp:218] Iteration 86700 (3.27419 iter/s, 30.5419s/100 iters), loss = 0.00336697
I1014 06:30:53.750751 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00336725 (* 1 = 0.00336725 loss)
I1014 06:30:53.750768 13701 sgd_solver.cpp:105] Iteration 86700, lr = 0.0001
I1014 06:31:24.258858 13701 solver.cpp:218] Iteration 86800 (3.27782 iter/s, 30.5081s/100 iters), loss = 0.00641064
I1014 06:31:24.258975 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641093 (* 1 = 0.00641093 loss)
I1014 06:31:24.258992 13701 sgd_solver.cpp:105] Iteration 86800, lr = 0.0001
I1014 06:31:54.826923 13701 solver.cpp:218] Iteration 86900 (3.2714 iter/s, 30.568s/100 iters), loss = 0.00323289
I1014 06:31:54.827033 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323317 (* 1 = 0.00323317 loss)
I1014 06:31:54.827039 13701 sgd_solver.cpp:105] Iteration 86900, lr = 0.0001
I1014 06:32:23.831389 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:32:25.057551 13701 solver.cpp:330] Iteration 87000, Testing net (#0)
I1014 06:32:41.646605 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:32:41.988376 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13648 (* 1 = 1.13648 loss)
I1014 06:32:41.988392 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7382
I1014 06:32:42.290329 13701 solver.cpp:218] Iteration 87000 (2.10689 iter/s, 47.4633s/100 iters), loss = 0.00535412
I1014 06:32:42.290364 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053544 (* 1 = 0.0053544 loss)
I1014 06:32:42.290372 13701 sgd_solver.cpp:105] Iteration 87000, lr = 0.0001
I1014 06:33:12.872684 13701 solver.cpp:218] Iteration 87100 (3.26986 iter/s, 30.5823s/100 iters), loss = 0.0106192
I1014 06:33:12.873287 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106195 (* 1 = 0.0106195 loss)
I1014 06:33:12.873296 13701 sgd_solver.cpp:105] Iteration 87100, lr = 0.0001
I1014 06:33:43.421701 13701 solver.cpp:218] Iteration 87200 (3.27349 iter/s, 30.5484s/100 iters), loss = 0.00338222
I1014 06:33:43.421824 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033825 (* 1 = 0.0033825 loss)
I1014 06:33:43.421842 13701 sgd_solver.cpp:105] Iteration 87200, lr = 0.0001
I1014 06:34:13.956599 13701 solver.cpp:218] Iteration 87300 (3.27495 iter/s, 30.5348s/100 iters), loss = 0.0127029
I1014 06:34:13.956712 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127032 (* 1 = 0.0127032 loss)
I1014 06:34:13.956728 13701 sgd_solver.cpp:105] Iteration 87300, lr = 0.0001
I1014 06:34:44.472162 13701 solver.cpp:218] Iteration 87400 (3.27703 iter/s, 30.5155s/100 iters), loss = 0.00255825
I1014 06:34:44.472259 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255853 (* 1 = 0.00255853 loss)
I1014 06:34:44.472265 13701 sgd_solver.cpp:105] Iteration 87400, lr = 0.0001
I1014 06:35:14.704993 13701 solver.cpp:330] Iteration 87500, Testing net (#0)
I1014 06:35:31.311888 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:35:31.650616 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13645 (* 1 = 1.13645 loss)
I1014 06:35:31.650631 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7382
I1014 06:35:31.950453 13701 solver.cpp:218] Iteration 87500 (2.10623 iter/s, 47.4782s/100 iters), loss = 0.00400288
I1014 06:35:31.950484 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400316 (* 1 = 0.00400316 loss)
I1014 06:35:31.950491 13701 sgd_solver.cpp:105] Iteration 87500, lr = 0.0001
I1014 06:36:02.478220 13701 solver.cpp:218] Iteration 87600 (3.27571 iter/s, 30.5277s/100 iters), loss = 0.00924767
I1014 06:36:02.478338 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00924796 (* 1 = 0.00924796 loss)
I1014 06:36:02.478344 13701 sgd_solver.cpp:105] Iteration 87600, lr = 0.0001
I1014 06:36:33.016369 13701 solver.cpp:218] Iteration 87700 (3.2746 iter/s, 30.538s/100 iters), loss = 0.00413863
I1014 06:36:33.016484 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413892 (* 1 = 0.00413892 loss)
I1014 06:36:33.016499 13701 sgd_solver.cpp:105] Iteration 87700, lr = 0.0001
I1014 06:37:03.545332 13701 solver.cpp:218] Iteration 87800 (3.27559 iter/s, 30.5289s/100 iters), loss = 0.0037093
I1014 06:37:03.545402 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370958 (* 1 = 0.00370958 loss)
I1014 06:37:03.545408 13701 sgd_solver.cpp:105] Iteration 87800, lr = 0.0001
I1014 06:37:34.098011 13701 solver.cpp:218] Iteration 87900 (3.27304 iter/s, 30.5526s/100 iters), loss = 0.00280815
I1014 06:37:34.098093 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280844 (* 1 = 0.00280844 loss)
I1014 06:37:34.098107 13701 sgd_solver.cpp:105] Iteration 87900, lr = 0.0001
I1014 06:38:03.160233 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:38:04.381062 13701 solver.cpp:330] Iteration 88000, Testing net (#0)
I1014 06:38:20.977524 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:38:21.315302 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13621 (* 1 = 1.13621 loss)
I1014 06:38:21.315318 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7386
I1014 06:38:21.617012 13701 solver.cpp:218] Iteration 88000 (2.10442 iter/s, 47.5189s/100 iters), loss = 0.00553143
I1014 06:38:21.617041 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553172 (* 1 = 0.00553172 loss)
I1014 06:38:21.617058 13701 sgd_solver.cpp:105] Iteration 88000, lr = 0.0001
I1014 06:38:52.112500 13701 solver.cpp:218] Iteration 88100 (3.27918 iter/s, 30.4955s/100 iters), loss = 0.00690162
I1014 06:38:52.112646 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00690191 (* 1 = 0.00690191 loss)
I1014 06:38:52.112655 13701 sgd_solver.cpp:105] Iteration 88100, lr = 0.0001
I1014 06:39:22.627642 13701 solver.cpp:218] Iteration 88200 (3.27708 iter/s, 30.515s/100 iters), loss = 0.00634995
I1014 06:39:22.627768 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00635023 (* 1 = 0.00635023 loss)
I1014 06:39:22.627776 13701 sgd_solver.cpp:105] Iteration 88200, lr = 0.0001
I1014 06:39:53.171593 13701 solver.cpp:218] Iteration 88300 (3.27398 iter/s, 30.5438s/100 iters), loss = 0.0154007
I1014 06:39:53.171749 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015401 (* 1 = 0.015401 loss)
I1014 06:39:53.171756 13701 sgd_solver.cpp:105] Iteration 88300, lr = 0.0001
I1014 06:40:23.689013 13701 solver.cpp:218] Iteration 88400 (3.27683 iter/s, 30.5173s/100 iters), loss = 0.00541578
I1014 06:40:23.689146 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00541606 (* 1 = 0.00541606 loss)
I1014 06:40:23.689153 13701 sgd_solver.cpp:105] Iteration 88400, lr = 0.0001
I1014 06:40:53.936887 13701 solver.cpp:330] Iteration 88500, Testing net (#0)
I1014 06:41:10.512804 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:41:10.852424 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13603 (* 1 = 1.13603 loss)
I1014 06:41:10.852442 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7384
I1014 06:41:11.152719 13701 solver.cpp:218] Iteration 88500 (2.10688 iter/s, 47.4636s/100 iters), loss = 0.00452417
I1014 06:41:11.152755 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452445 (* 1 = 0.00452445 loss)
I1014 06:41:11.152762 13701 sgd_solver.cpp:105] Iteration 88500, lr = 0.0001
I1014 06:41:41.675860 13701 solver.cpp:218] Iteration 88600 (3.27621 iter/s, 30.5231s/100 iters), loss = 0.00575971
I1014 06:41:41.676002 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575999 (* 1 = 0.00575999 loss)
I1014 06:41:41.676008 13701 sgd_solver.cpp:105] Iteration 88600, lr = 0.0001
I1014 06:42:12.171969 13701 solver.cpp:218] Iteration 88700 (3.27912 iter/s, 30.496s/100 iters), loss = 0.00328726
I1014 06:42:12.172107 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328754 (* 1 = 0.00328754 loss)
I1014 06:42:12.172116 13701 sgd_solver.cpp:105] Iteration 88700, lr = 0.0001
I1014 06:42:42.683516 13701 solver.cpp:218] Iteration 88800 (3.27746 iter/s, 30.5114s/100 iters), loss = 0.00512226
I1014 06:42:42.683614 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512255 (* 1 = 0.00512255 loss)
I1014 06:42:42.683620 13701 sgd_solver.cpp:105] Iteration 88800, lr = 0.0001
I1014 06:43:13.176709 13701 solver.cpp:218] Iteration 88900 (3.27943 iter/s, 30.4931s/100 iters), loss = 0.00388924
I1014 06:43:13.176832 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388953 (* 1 = 0.00388953 loss)
I1014 06:43:13.176839 13701 sgd_solver.cpp:105] Iteration 88900, lr = 0.0001
I1014 06:43:42.106387 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:43:43.327574 13701 solver.cpp:330] Iteration 89000, Testing net (#0)
I1014 06:43:59.911483 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:44:00.252436 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13592 (* 1 = 1.13592 loss)
I1014 06:44:00.252454 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7385
I1014 06:44:00.553454 13701 solver.cpp:218] Iteration 89000 (2.11075 iter/s, 47.3766s/100 iters), loss = 0.00594116
I1014 06:44:00.553488 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594144 (* 1 = 0.00594144 loss)
I1014 06:44:00.553494 13701 sgd_solver.cpp:105] Iteration 89000, lr = 0.0001
I1014 06:44:31.133477 13701 solver.cpp:218] Iteration 89100 (3.27011 iter/s, 30.58s/100 iters), loss = 0.0123892
I1014 06:44:31.133586 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123895 (* 1 = 0.0123895 loss)
I1014 06:44:31.133594 13701 sgd_solver.cpp:105] Iteration 89100, lr = 0.0001
I1014 06:45:01.657742 13701 solver.cpp:218] Iteration 89200 (3.27609 iter/s, 30.5242s/100 iters), loss = 0.00529534
I1014 06:45:01.657850 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529561 (* 1 = 0.00529561 loss)
I1014 06:45:01.657858 13701 sgd_solver.cpp:105] Iteration 89200, lr = 0.0001
I1014 06:45:32.206359 13701 solver.cpp:218] Iteration 89300 (3.27348 iter/s, 30.5485s/100 iters), loss = 0.0333165
I1014 06:45:32.206506 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333168 (* 1 = 0.0333168 loss)
I1014 06:45:32.206526 13701 sgd_solver.cpp:105] Iteration 89300, lr = 0.0001
I1014 06:46:02.742622 13701 solver.cpp:218] Iteration 89400 (3.27481 iter/s, 30.5361s/100 iters), loss = 0.00332786
I1014 06:46:02.742753 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332814 (* 1 = 0.00332814 loss)
I1014 06:46:02.742761 13701 sgd_solver.cpp:105] Iteration 89400, lr = 0.0001
I1014 06:46:33.014806 13701 solver.cpp:330] Iteration 89500, Testing net (#0)
I1014 06:46:49.557756 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:46:49.897517 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13568 (* 1 = 1.13568 loss)
I1014 06:46:49.897532 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7386
I1014 06:46:50.202169 13701 solver.cpp:218] Iteration 89500 (2.10706 iter/s, 47.4594s/100 iters), loss = 0.00705784
I1014 06:46:50.202199 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705812 (* 1 = 0.00705812 loss)
I1014 06:46:50.202206 13701 sgd_solver.cpp:105] Iteration 89500, lr = 0.0001
I1014 06:47:20.732476 13701 solver.cpp:218] Iteration 89600 (3.27544 iter/s, 30.5303s/100 iters), loss = 0.00318329
I1014 06:47:20.732619 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318357 (* 1 = 0.00318357 loss)
I1014 06:47:20.732626 13701 sgd_solver.cpp:105] Iteration 89600, lr = 0.0001
I1014 06:47:51.245602 13701 solver.cpp:218] Iteration 89700 (3.27729 iter/s, 30.513s/100 iters), loss = 0.00348458
I1014 06:47:51.245693 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348486 (* 1 = 0.00348486 loss)
I1014 06:47:51.245718 13701 sgd_solver.cpp:105] Iteration 89700, lr = 0.0001
I1014 06:48:21.791287 13701 solver.cpp:218] Iteration 89800 (3.27379 iter/s, 30.5456s/100 iters), loss = 0.00258017
I1014 06:48:21.791396 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258045 (* 1 = 0.00258045 loss)
I1014 06:48:21.791404 13701 sgd_solver.cpp:105] Iteration 89800, lr = 0.0001
I1014 06:48:52.281157 13701 solver.cpp:218] Iteration 89900 (3.27979 iter/s, 30.4898s/100 iters), loss = 0.00448953
I1014 06:48:52.281255 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448981 (* 1 = 0.00448981 loss)
I1014 06:48:52.281262 13701 sgd_solver.cpp:105] Iteration 89900, lr = 0.0001
I1014 06:49:21.282608 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:49:22.494208 13701 solver.cpp:330] Iteration 90000, Testing net (#0)
I1014 06:49:39.027176 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:49:39.365615 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13558 (* 1 = 1.13558 loss)
I1014 06:49:39.365631 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7385
I1014 06:49:39.664885 13701 solver.cpp:218] Iteration 90000 (2.11043 iter/s, 47.3836s/100 iters), loss = 0.00233566
I1014 06:49:39.664914 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233594 (* 1 = 0.00233594 loss)
I1014 06:49:39.664921 13701 sgd_solver.cpp:105] Iteration 90000, lr = 0.0001
I1014 06:50:10.200295 13701 solver.cpp:218] Iteration 90100 (3.27489 iter/s, 30.5354s/100 iters), loss = 0.0155652
I1014 06:50:10.200403 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155655 (* 1 = 0.0155655 loss)
I1014 06:50:10.200410 13701 sgd_solver.cpp:105] Iteration 90100, lr = 0.0001
I1014 06:50:40.702468 13701 solver.cpp:218] Iteration 90200 (3.27847 iter/s, 30.5021s/100 iters), loss = 0.00412498
I1014 06:50:40.702610 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412526 (* 1 = 0.00412526 loss)
I1014 06:50:40.702620 13701 sgd_solver.cpp:105] Iteration 90200, lr = 0.0001
I1014 06:51:11.236147 13701 solver.cpp:218] Iteration 90300 (3.27509 iter/s, 30.5335s/100 iters), loss = 0.0116853
I1014 06:51:11.236325 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116855 (* 1 = 0.0116855 loss)
I1014 06:51:11.236335 13701 sgd_solver.cpp:105] Iteration 90300, lr = 0.0001
I1014 06:51:41.777747 13701 solver.cpp:218] Iteration 90400 (3.27424 iter/s, 30.5414s/100 iters), loss = 0.00405126
I1014 06:51:41.777859 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405154 (* 1 = 0.00405154 loss)
I1014 06:51:41.777879 13701 sgd_solver.cpp:105] Iteration 90400, lr = 0.0001
I1014 06:52:12.024647 13701 solver.cpp:330] Iteration 90500, Testing net (#0)
I1014 06:52:28.617869 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:52:28.957340 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13542 (* 1 = 1.13542 loss)
I1014 06:52:28.957355 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7385
I1014 06:52:29.256847 13701 solver.cpp:218] Iteration 90500 (2.10619 iter/s, 47.479s/100 iters), loss = 0.0106927
I1014 06:52:29.256884 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010693 (* 1 = 0.010693 loss)
I1014 06:52:29.256891 13701 sgd_solver.cpp:105] Iteration 90500, lr = 0.0001
I1014 06:52:59.811475 13701 solver.cpp:218] Iteration 90600 (3.27283 iter/s, 30.5546s/100 iters), loss = 0.0052029
I1014 06:52:59.811609 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520318 (* 1 = 0.00520318 loss)
I1014 06:52:59.811619 13701 sgd_solver.cpp:105] Iteration 90600, lr = 0.0001
I1014 06:53:30.289037 13701 solver.cpp:218] Iteration 90700 (3.28112 iter/s, 30.4774s/100 iters), loss = 0.00312777
I1014 06:53:30.289151 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312804 (* 1 = 0.00312804 loss)
I1014 06:53:30.289160 13701 sgd_solver.cpp:105] Iteration 90700, lr = 0.0001
I1014 06:54:00.805574 13701 solver.cpp:218] Iteration 90800 (3.27692 iter/s, 30.5164s/100 iters), loss = 0.00568234
I1014 06:54:00.806427 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568261 (* 1 = 0.00568261 loss)
I1014 06:54:00.806444 13701 sgd_solver.cpp:105] Iteration 90800, lr = 0.0001
I1014 06:54:31.335263 13701 solver.cpp:218] Iteration 90900 (3.27559 iter/s, 30.5289s/100 iters), loss = 0.00852781
I1014 06:54:31.335407 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00852808 (* 1 = 0.00852808 loss)
I1014 06:54:31.335417 13701 sgd_solver.cpp:105] Iteration 90900, lr = 0.0001
I1014 06:55:00.319541 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:55:01.527640 13701 solver.cpp:330] Iteration 91000, Testing net (#0)
I1014 06:55:18.095331 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:55:18.433773 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13516 (* 1 = 1.13516 loss)
I1014 06:55:18.433789 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7383
I1014 06:55:18.733422 13701 solver.cpp:218] Iteration 91000 (2.10979 iter/s, 47.398s/100 iters), loss = 0.00428135
I1014 06:55:18.733453 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428162 (* 1 = 0.00428162 loss)
I1014 06:55:18.733459 13701 sgd_solver.cpp:105] Iteration 91000, lr = 0.0001
I1014 06:55:49.284191 13701 solver.cpp:218] Iteration 91100 (3.27324 iter/s, 30.5507s/100 iters), loss = 0.0113486
I1014 06:55:49.284330 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113489 (* 1 = 0.0113489 loss)
I1014 06:55:49.284337 13701 sgd_solver.cpp:105] Iteration 91100, lr = 0.0001
I1014 06:56:19.770225 13701 solver.cpp:218] Iteration 91200 (3.2802 iter/s, 30.4859s/100 iters), loss = 0.00745831
I1014 06:56:19.770359 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745858 (* 1 = 0.00745858 loss)
I1014 06:56:19.770365 13701 sgd_solver.cpp:105] Iteration 91200, lr = 0.0001
I1014 06:56:50.262485 13701 solver.cpp:218] Iteration 91300 (3.27953 iter/s, 30.4921s/100 iters), loss = 0.010959
I1014 06:56:50.262624 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109593 (* 1 = 0.0109593 loss)
I1014 06:56:50.262642 13701 sgd_solver.cpp:105] Iteration 91300, lr = 0.0001
I1014 06:57:20.806303 13701 solver.cpp:218] Iteration 91400 (3.274 iter/s, 30.5437s/100 iters), loss = 0.00427981
I1014 06:57:20.806469 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428008 (* 1 = 0.00428008 loss)
I1014 06:57:20.806486 13701 sgd_solver.cpp:105] Iteration 91400, lr = 0.0001
I1014 06:57:51.067620 13701 solver.cpp:330] Iteration 91500, Testing net (#0)
I1014 06:58:07.645128 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 06:58:07.985950 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13504 (* 1 = 1.13504 loss)
I1014 06:58:07.985965 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7384
I1014 06:58:08.286689 13701 solver.cpp:218] Iteration 91500 (2.10614 iter/s, 47.4802s/100 iters), loss = 0.00559987
I1014 06:58:08.286722 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00560014 (* 1 = 0.00560014 loss)
I1014 06:58:08.286731 13701 sgd_solver.cpp:105] Iteration 91500, lr = 0.0001
I1014 06:58:38.813997 13701 solver.cpp:218] Iteration 91600 (3.27576 iter/s, 30.5273s/100 iters), loss = 0.00556819
I1014 06:58:38.814095 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556846 (* 1 = 0.00556846 loss)
I1014 06:58:38.814102 13701 sgd_solver.cpp:105] Iteration 91600, lr = 0.0001
I1014 06:59:09.350316 13701 solver.cpp:218] Iteration 91700 (3.2748 iter/s, 30.5362s/100 iters), loss = 0.00554204
I1014 06:59:09.350461 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554231 (* 1 = 0.00554231 loss)
I1014 06:59:09.350469 13701 sgd_solver.cpp:105] Iteration 91700, lr = 0.0001
I1014 06:59:39.857949 13701 solver.cpp:218] Iteration 91800 (3.27788 iter/s, 30.5075s/100 iters), loss = 0.00377734
I1014 06:59:39.858093 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377761 (* 1 = 0.00377761 loss)
I1014 06:59:39.858103 13701 sgd_solver.cpp:105] Iteration 91800, lr = 0.0001
I1014 07:00:10.311450 13701 solver.cpp:218] Iteration 91900 (3.28371 iter/s, 30.4534s/100 iters), loss = 0.00390381
I1014 07:00:10.311560 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00390408 (* 1 = 0.00390408 loss)
I1014 07:00:10.311568 13701 sgd_solver.cpp:105] Iteration 91900, lr = 0.0001
I1014 07:00:39.299329 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:00:40.512712 13701 solver.cpp:330] Iteration 92000, Testing net (#0)
I1014 07:00:57.085160 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:00:57.423074 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13492 (* 1 = 1.13492 loss)
I1014 07:00:57.423089 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7388
I1014 07:00:57.721904 13701 solver.cpp:218] Iteration 92000 (2.10924 iter/s, 47.4104s/100 iters), loss = 0.00628431
I1014 07:00:57.721933 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628458 (* 1 = 0.00628458 loss)
I1014 07:00:57.721940 13701 sgd_solver.cpp:105] Iteration 92000, lr = 0.0001
I1014 07:01:28.268648 13701 solver.cpp:218] Iteration 92100 (3.27367 iter/s, 30.5467s/100 iters), loss = 0.00768857
I1014 07:01:28.268792 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00768884 (* 1 = 0.00768884 loss)
I1014 07:01:28.268800 13701 sgd_solver.cpp:105] Iteration 92100, lr = 0.0001
I1014 07:01:58.833626 13701 solver.cpp:218] Iteration 92200 (3.27173 iter/s, 30.5648s/100 iters), loss = 0.00788666
I1014 07:01:58.833763 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00788693 (* 1 = 0.00788693 loss)
I1014 07:01:58.833770 13701 sgd_solver.cpp:105] Iteration 92200, lr = 0.0001
I1014 07:02:29.359737 13701 solver.cpp:218] Iteration 92300 (3.2759 iter/s, 30.526s/100 iters), loss = 0.0187055
I1014 07:02:29.359848 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187058 (* 1 = 0.0187058 loss)
I1014 07:02:29.359866 13701 sgd_solver.cpp:105] Iteration 92300, lr = 0.0001
I1014 07:02:59.844159 13701 solver.cpp:218] Iteration 92400 (3.28037 iter/s, 30.4843s/100 iters), loss = 0.00510644
I1014 07:02:59.844286 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510671 (* 1 = 0.00510671 loss)
I1014 07:02:59.844302 13701 sgd_solver.cpp:105] Iteration 92400, lr = 0.0001
I1014 07:03:30.079620 13701 solver.cpp:330] Iteration 92500, Testing net (#0)
I1014 07:03:46.692497 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:03:47.032133 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13479 (* 1 = 1.13479 loss)
I1014 07:03:47.032147 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7378
I1014 07:03:47.334228 13701 solver.cpp:218] Iteration 92500 (2.10571 iter/s, 47.49s/100 iters), loss = 0.00536647
I1014 07:03:47.334261 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536674 (* 1 = 0.00536674 loss)
I1014 07:03:47.334270 13701 sgd_solver.cpp:105] Iteration 92500, lr = 0.0001
I1014 07:04:17.795260 13701 solver.cpp:218] Iteration 92600 (3.28289 iter/s, 30.461s/100 iters), loss = 0.00324642
I1014 07:04:17.795341 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324669 (* 1 = 0.00324669 loss)
I1014 07:04:17.795356 13701 sgd_solver.cpp:105] Iteration 92600, lr = 0.0001
I1014 07:04:48.296147 13701 solver.cpp:218] Iteration 92700 (3.2786 iter/s, 30.5008s/100 iters), loss = 0.00755893
I1014 07:04:48.296259 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0075592 (* 1 = 0.0075592 loss)
I1014 07:04:48.296267 13701 sgd_solver.cpp:105] Iteration 92700, lr = 0.0001
I1014 07:05:18.821391 13701 solver.cpp:218] Iteration 92800 (3.27599 iter/s, 30.5251s/100 iters), loss = 0.00335331
I1014 07:05:18.821534 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335359 (* 1 = 0.00335359 loss)
I1014 07:05:18.821542 13701 sgd_solver.cpp:105] Iteration 92800, lr = 0.0001
I1014 07:05:49.300282 13701 solver.cpp:218] Iteration 92900 (3.28097 iter/s, 30.4788s/100 iters), loss = 0.00399516
I1014 07:05:49.300381 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399543 (* 1 = 0.00399543 loss)
I1014 07:05:49.300390 13701 sgd_solver.cpp:105] Iteration 92900, lr = 0.0001
I1014 07:06:18.268314 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:06:19.490278 13701 solver.cpp:330] Iteration 93000, Testing net (#0)
I1014 07:06:36.064440 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:06:36.403442 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13453 (* 1 = 1.13453 loss)
I1014 07:06:36.403457 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1014 07:06:36.704740 13701 solver.cpp:218] Iteration 93000 (2.10951 iter/s, 47.4044s/100 iters), loss = 0.00373578
I1014 07:06:36.704769 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373605 (* 1 = 0.00373605 loss)
I1014 07:06:36.704777 13701 sgd_solver.cpp:105] Iteration 93000, lr = 0.0001
I1014 07:07:07.175812 13701 solver.cpp:218] Iteration 93100 (3.2818 iter/s, 30.471s/100 iters), loss = 0.009516
I1014 07:07:07.175932 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951627 (* 1 = 0.00951627 loss)
I1014 07:07:07.175951 13701 sgd_solver.cpp:105] Iteration 93100, lr = 0.0001
I1014 07:07:37.687081 13701 solver.cpp:218] Iteration 93200 (3.27749 iter/s, 30.5112s/100 iters), loss = 0.00469252
I1014 07:07:37.687330 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469279 (* 1 = 0.00469279 loss)
I1014 07:07:37.687340 13701 sgd_solver.cpp:105] Iteration 93200, lr = 0.0001
I1014 07:08:08.195456 13701 solver.cpp:218] Iteration 93300 (3.27781 iter/s, 30.5081s/100 iters), loss = 0.00789205
I1014 07:08:08.195593 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00789233 (* 1 = 0.00789233 loss)
I1014 07:08:08.195603 13701 sgd_solver.cpp:105] Iteration 93300, lr = 0.0001
I1014 07:08:38.723882 13701 solver.cpp:218] Iteration 93400 (3.27565 iter/s, 30.5283s/100 iters), loss = 0.00666034
I1014 07:08:38.724041 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666062 (* 1 = 0.00666062 loss)
I1014 07:08:38.724050 13701 sgd_solver.cpp:105] Iteration 93400, lr = 0.0001
I1014 07:09:08.913414 13701 solver.cpp:330] Iteration 93500, Testing net (#0)
I1014 07:09:25.500813 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:09:25.842515 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13458 (* 1 = 1.13458 loss)
I1014 07:09:25.842530 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7378
I1014 07:09:26.144405 13701 solver.cpp:218] Iteration 93500 (2.1088 iter/s, 47.4204s/100 iters), loss = 0.0044281
I1014 07:09:26.144443 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442837 (* 1 = 0.00442837 loss)
I1014 07:09:26.144449 13701 sgd_solver.cpp:105] Iteration 93500, lr = 0.0001
I1014 07:09:56.669836 13701 solver.cpp:218] Iteration 93600 (3.27596 iter/s, 30.5254s/100 iters), loss = 0.00491331
I1014 07:09:56.669955 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491358 (* 1 = 0.00491358 loss)
I1014 07:09:56.669962 13701 sgd_solver.cpp:105] Iteration 93600, lr = 0.0001
I1014 07:10:27.145946 13701 solver.cpp:218] Iteration 93700 (3.28127 iter/s, 30.476s/100 iters), loss = 0.00332786
I1014 07:10:27.148473 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332813 (* 1 = 0.00332813 loss)
I1014 07:10:27.148481 13701 sgd_solver.cpp:105] Iteration 93700, lr = 0.0001
I1014 07:10:57.629050 13701 solver.cpp:218] Iteration 93800 (3.28078 iter/s, 30.4806s/100 iters), loss = 0.00711158
I1014 07:10:57.629166 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00711186 (* 1 = 0.00711186 loss)
I1014 07:10:57.629173 13701 sgd_solver.cpp:105] Iteration 93800, lr = 0.0001
I1014 07:11:28.121186 13701 solver.cpp:218] Iteration 93900 (3.27955 iter/s, 30.492s/100 iters), loss = 0.0058768
I1014 07:11:28.121325 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00587708 (* 1 = 0.00587708 loss)
I1014 07:11:28.121335 13701 sgd_solver.cpp:105] Iteration 93900, lr = 0.0001
I1014 07:11:57.132797 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:11:58.357399 13701 solver.cpp:330] Iteration 94000, Testing net (#0)
I1014 07:12:14.954514 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:12:15.293192 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13463 (* 1 = 1.13463 loss)
I1014 07:12:15.293210 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1014 07:12:15.594379 13701 solver.cpp:218] Iteration 94000 (2.10646 iter/s, 47.4731s/100 iters), loss = 0.00664844
I1014 07:12:15.594409 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664872 (* 1 = 0.00664872 loss)
I1014 07:12:15.594416 13701 sgd_solver.cpp:105] Iteration 94000, lr = 0.0001
I1014 07:12:46.082353 13701 solver.cpp:218] Iteration 94100 (3.27998 iter/s, 30.4879s/100 iters), loss = 0.00502217
I1014 07:12:46.082501 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502244 (* 1 = 0.00502244 loss)
I1014 07:12:46.082510 13701 sgd_solver.cpp:105] Iteration 94100, lr = 0.0001
I1014 07:13:16.570956 13701 solver.cpp:218] Iteration 94200 (3.27993 iter/s, 30.4885s/100 iters), loss = 0.00518601
I1014 07:13:16.571079 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00518629 (* 1 = 0.00518629 loss)
I1014 07:13:16.571085 13701 sgd_solver.cpp:105] Iteration 94200, lr = 0.0001
I1014 07:13:47.039806 13701 solver.cpp:218] Iteration 94300 (3.28205 iter/s, 30.4687s/100 iters), loss = 0.00885104
I1014 07:13:47.039907 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00885131 (* 1 = 0.00885131 loss)
I1014 07:13:47.039916 13701 sgd_solver.cpp:105] Iteration 94300, lr = 0.0001
I1014 07:14:17.509037 13701 solver.cpp:218] Iteration 94400 (3.28201 iter/s, 30.4691s/100 iters), loss = 0.00359069
I1014 07:14:17.509160 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359096 (* 1 = 0.00359096 loss)
I1014 07:14:17.509167 13701 sgd_solver.cpp:105] Iteration 94400, lr = 0.0001
I1014 07:14:47.697870 13701 solver.cpp:330] Iteration 94500, Testing net (#0)
I1014 07:15:04.248864 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:15:04.586555 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13442 (* 1 = 1.13442 loss)
I1014 07:15:04.586570 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7378
I1014 07:15:04.888139 13701 solver.cpp:218] Iteration 94500 (2.11064 iter/s, 47.379s/100 iters), loss = 0.00446463
I1014 07:15:04.888173 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0044649 (* 1 = 0.0044649 loss)
I1014 07:15:04.888180 13701 sgd_solver.cpp:105] Iteration 94500, lr = 0.0001
I1014 07:15:35.422639 13701 solver.cpp:218] Iteration 94600 (3.27499 iter/s, 30.5345s/100 iters), loss = 0.00491844
I1014 07:15:35.422786 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491871 (* 1 = 0.00491871 loss)
I1014 07:15:35.422794 13701 sgd_solver.cpp:105] Iteration 94600, lr = 0.0001
I1014 07:16:05.980058 13701 solver.cpp:218] Iteration 94700 (3.27254 iter/s, 30.5573s/100 iters), loss = 0.00454081
I1014 07:16:05.980190 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454109 (* 1 = 0.00454109 loss)
I1014 07:16:05.980199 13701 sgd_solver.cpp:105] Iteration 94700, lr = 0.0001
I1014 07:16:36.443281 13701 solver.cpp:218] Iteration 94800 (3.28266 iter/s, 30.4631s/100 iters), loss = 0.0113313
I1014 07:16:36.443408 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113316 (* 1 = 0.0113316 loss)
I1014 07:16:36.443416 13701 sgd_solver.cpp:105] Iteration 94800, lr = 0.0001
I1014 07:17:06.968895 13701 solver.cpp:218] Iteration 94900 (3.27595 iter/s, 30.5255s/100 iters), loss = 0.00967779
I1014 07:17:06.969003 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00967806 (* 1 = 0.00967806 loss)
I1014 07:17:06.969010 13701 sgd_solver.cpp:105] Iteration 94900, lr = 0.0001
I1014 07:17:35.936879 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:17:37.159584 13701 solver.cpp:330] Iteration 95000, Testing net (#0)
I1014 07:17:53.792121 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:17:54.132997 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13422 (* 1 = 1.13422 loss)
I1014 07:17:54.133013 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7383
I1014 07:17:54.432714 13701 solver.cpp:218] Iteration 95000 (2.10687 iter/s, 47.4637s/100 iters), loss = 0.00671736
I1014 07:17:54.432747 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671763 (* 1 = 0.00671763 loss)
I1014 07:17:54.432754 13701 sgd_solver.cpp:105] Iteration 95000, lr = 0.0001
I1014 07:18:24.915056 13701 solver.cpp:218] Iteration 95100 (3.28059 iter/s, 30.4823s/100 iters), loss = 0.0144068
I1014 07:18:24.915206 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144071 (* 1 = 0.0144071 loss)
I1014 07:18:24.915217 13701 sgd_solver.cpp:105] Iteration 95100, lr = 0.0001
I1014 07:18:55.405561 13701 solver.cpp:218] Iteration 95200 (3.27972 iter/s, 30.4904s/100 iters), loss = 0.00526821
I1014 07:18:55.405695 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00526847 (* 1 = 0.00526847 loss)
I1014 07:18:55.405704 13701 sgd_solver.cpp:105] Iteration 95200, lr = 0.0001
I1014 07:19:25.900391 13701 solver.cpp:218] Iteration 95300 (3.27926 iter/s, 30.4947s/100 iters), loss = 0.00942399
I1014 07:19:25.900499 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00942425 (* 1 = 0.00942425 loss)
I1014 07:19:25.900506 13701 sgd_solver.cpp:105] Iteration 95300, lr = 0.0001
I1014 07:19:56.372164 13701 solver.cpp:218] Iteration 95400 (3.28174 iter/s, 30.4717s/100 iters), loss = 0.00507567
I1014 07:19:56.372274 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507593 (* 1 = 0.00507593 loss)
I1014 07:19:56.372292 13701 sgd_solver.cpp:105] Iteration 95400, lr = 0.0001
I1014 07:20:26.507587 13701 solver.cpp:330] Iteration 95500, Testing net (#0)
I1014 07:20:43.091574 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:20:43.429723 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13403 (* 1 = 1.13403 loss)
I1014 07:20:43.429738 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7384
I1014 07:20:43.729718 13701 solver.cpp:218] Iteration 95500 (2.1116 iter/s, 47.3575s/100 iters), loss = 0.00495065
I1014 07:20:43.729746 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495091 (* 1 = 0.00495091 loss)
I1014 07:20:43.729753 13701 sgd_solver.cpp:105] Iteration 95500, lr = 0.0001
I1014 07:21:14.223150 13701 solver.cpp:218] Iteration 95600 (3.2794 iter/s, 30.4934s/100 iters), loss = 0.00398857
I1014 07:21:14.223263 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398884 (* 1 = 0.00398884 loss)
I1014 07:21:14.223269 13701 sgd_solver.cpp:105] Iteration 95600, lr = 0.0001
I1014 07:21:44.751790 13701 solver.cpp:218] Iteration 95700 (3.27562 iter/s, 30.5285s/100 iters), loss = 0.00560097
I1014 07:21:44.751891 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00560123 (* 1 = 0.00560123 loss)
I1014 07:21:44.751899 13701 sgd_solver.cpp:105] Iteration 95700, lr = 0.0001
I1014 07:22:15.289901 13701 solver.cpp:218] Iteration 95800 (3.27461 iter/s, 30.538s/100 iters), loss = 0.00407017
I1014 07:22:15.290020 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407044 (* 1 = 0.00407044 loss)
I1014 07:22:15.290038 13701 sgd_solver.cpp:105] Iteration 95800, lr = 0.0001
I1014 07:22:45.758431 13701 solver.cpp:218] Iteration 95900 (3.28209 iter/s, 30.4684s/100 iters), loss = 0.00430823
I1014 07:22:45.758536 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430849 (* 1 = 0.00430849 loss)
I1014 07:22:45.758544 13701 sgd_solver.cpp:105] Iteration 95900, lr = 0.0001
I1014 07:23:14.714795 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:23:15.931370 13701 solver.cpp:330] Iteration 96000, Testing net (#0)
I1014 07:23:32.534662 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:23:32.873432 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13392 (* 1 = 1.13392 loss)
I1014 07:23:32.873447 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7384
I1014 07:23:33.174554 13701 solver.cpp:218] Iteration 96000 (2.10899 iter/s, 47.416s/100 iters), loss = 0.00628424
I1014 07:23:33.174587 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628451 (* 1 = 0.00628451 loss)
I1014 07:23:33.174594 13701 sgd_solver.cpp:105] Iteration 96000, lr = 0.0001
I1014 07:24:03.646582 13701 solver.cpp:218] Iteration 96100 (3.2817 iter/s, 30.472s/100 iters), loss = 0.00780105
I1014 07:24:03.646692 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00780131 (* 1 = 0.00780131 loss)
I1014 07:24:03.646708 13701 sgd_solver.cpp:105] Iteration 96100, lr = 0.0001
I1014 07:24:34.150275 13701 solver.cpp:218] Iteration 96200 (3.2783 iter/s, 30.5036s/100 iters), loss = 0.00779324
I1014 07:24:34.150362 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00779351 (* 1 = 0.00779351 loss)
I1014 07:24:34.150379 13701 sgd_solver.cpp:105] Iteration 96200, lr = 0.0001
I1014 07:25:04.594310 13701 solver.cpp:218] Iteration 96300 (3.28472 iter/s, 30.444s/100 iters), loss = 0.0254687
I1014 07:25:04.594514 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025469 (* 1 = 0.025469 loss)
I1014 07:25:04.594532 13701 sgd_solver.cpp:105] Iteration 96300, lr = 0.0001
I1014 07:25:35.074589 13701 solver.cpp:218] Iteration 96400 (3.28083 iter/s, 30.4801s/100 iters), loss = 0.00303602
I1014 07:25:35.074733 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303629 (* 1 = 0.00303629 loss)
I1014 07:25:35.074741 13701 sgd_solver.cpp:105] Iteration 96400, lr = 0.0001
I1014 07:26:05.260442 13701 solver.cpp:330] Iteration 96500, Testing net (#0)
I1014 07:26:21.808398 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:26:22.145800 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13376 (* 1 = 1.13376 loss)
I1014 07:26:22.145817 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1014 07:26:22.444977 13701 solver.cpp:218] Iteration 96500 (2.11103 iter/s, 47.3703s/100 iters), loss = 0.00575624
I1014 07:26:22.445013 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575651 (* 1 = 0.00575651 loss)
I1014 07:26:22.445019 13701 sgd_solver.cpp:105] Iteration 96500, lr = 0.0001
I1014 07:26:52.976884 13701 solver.cpp:218] Iteration 96600 (3.27527 iter/s, 30.5319s/100 iters), loss = 0.00283999
I1014 07:26:52.977054 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284026 (* 1 = 0.00284026 loss)
I1014 07:26:52.977064 13701 sgd_solver.cpp:105] Iteration 96600, lr = 0.0001
I1014 07:27:23.484105 13701 solver.cpp:218] Iteration 96700 (3.27793 iter/s, 30.5071s/100 iters), loss = 0.00491164
I1014 07:27:23.484236 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491191 (* 1 = 0.00491191 loss)
I1014 07:27:23.484244 13701 sgd_solver.cpp:105] Iteration 96700, lr = 0.0001
I1014 07:27:53.995914 13701 solver.cpp:218] Iteration 96800 (3.27743 iter/s, 30.5117s/100 iters), loss = 0.00731282
I1014 07:27:53.996042 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731309 (* 1 = 0.00731309 loss)
I1014 07:27:53.996050 13701 sgd_solver.cpp:105] Iteration 96800, lr = 0.0001
I1014 07:28:24.482272 13701 solver.cpp:218] Iteration 96900 (3.28017 iter/s, 30.4862s/100 iters), loss = 0.0063153
I1014 07:28:24.482406 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00631556 (* 1 = 0.00631556 loss)
I1014 07:28:24.482414 13701 sgd_solver.cpp:105] Iteration 96900, lr = 0.0001
I1014 07:28:53.466625 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:28:54.682896 13701 solver.cpp:330] Iteration 97000, Testing net (#0)
I1014 07:29:11.315953 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:29:11.656133 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1336 (* 1 = 1.1336 loss)
I1014 07:29:11.656148 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7378
I1014 07:29:11.958777 13701 solver.cpp:218] Iteration 97000 (2.10631 iter/s, 47.4764s/100 iters), loss = 0.00681881
I1014 07:29:11.958807 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00681907 (* 1 = 0.00681907 loss)
I1014 07:29:11.958814 13701 sgd_solver.cpp:105] Iteration 97000, lr = 0.0001
I1014 07:29:42.454778 13701 solver.cpp:218] Iteration 97100 (3.27912 iter/s, 30.496s/100 iters), loss = 0.00767666
I1014 07:29:42.454916 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00767693 (* 1 = 0.00767693 loss)
I1014 07:29:42.454926 13701 sgd_solver.cpp:105] Iteration 97100, lr = 0.0001
I1014 07:30:12.991096 13701 solver.cpp:218] Iteration 97200 (3.2748 iter/s, 30.5362s/100 iters), loss = 0.00741427
I1014 07:30:12.991231 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00741454 (* 1 = 0.00741454 loss)
I1014 07:30:12.991238 13701 sgd_solver.cpp:105] Iteration 97200, lr = 0.0001
I1014 07:30:43.494427 13701 solver.cpp:218] Iteration 97300 (3.27834 iter/s, 30.5032s/100 iters), loss = 0.0117563
I1014 07:30:43.494571 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117565 (* 1 = 0.0117565 loss)
I1014 07:30:43.494580 13701 sgd_solver.cpp:105] Iteration 97300, lr = 0.0001
I1014 07:31:14.002663 13701 solver.cpp:218] Iteration 97400 (3.27782 iter/s, 30.5081s/100 iters), loss = 0.0086826
I1014 07:31:14.002794 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868287 (* 1 = 0.00868287 loss)
I1014 07:31:14.002801 13701 sgd_solver.cpp:105] Iteration 97400, lr = 0.0001
I1014 07:31:44.207300 13701 solver.cpp:330] Iteration 97500, Testing net (#0)
I1014 07:32:00.819679 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:32:01.159497 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13349 (* 1 = 1.13349 loss)
I1014 07:32:01.159513 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1014 07:32:01.460216 13701 solver.cpp:218] Iteration 97500 (2.10715 iter/s, 47.4574s/100 iters), loss = 0.00450146
I1014 07:32:01.460252 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450172 (* 1 = 0.00450172 loss)
I1014 07:32:01.460268 13701 sgd_solver.cpp:105] Iteration 97500, lr = 0.0001
I1014 07:32:31.944388 13701 solver.cpp:218] Iteration 97600 (3.28039 iter/s, 30.4841s/100 iters), loss = 0.0036993
I1014 07:32:31.945533 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369956 (* 1 = 0.00369956 loss)
I1014 07:32:31.945550 13701 sgd_solver.cpp:105] Iteration 97600, lr = 0.0001
I1014 07:33:02.463486 13701 solver.cpp:218] Iteration 97700 (3.27676 iter/s, 30.518s/100 iters), loss = 0.00354633
I1014 07:33:02.463582 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354659 (* 1 = 0.00354659 loss)
I1014 07:33:02.463600 13701 sgd_solver.cpp:105] Iteration 97700, lr = 0.0001
I1014 07:33:32.965211 13701 solver.cpp:218] Iteration 97800 (3.27851 iter/s, 30.5016s/100 iters), loss = 0.00336794
I1014 07:33:32.965349 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033682 (* 1 = 0.0033682 loss)
I1014 07:33:32.965358 13701 sgd_solver.cpp:105] Iteration 97800, lr = 0.0001
I1014 07:34:03.517000 13701 solver.cpp:218] Iteration 97900 (3.27314 iter/s, 30.5517s/100 iters), loss = 0.00386911
I1014 07:34:03.517145 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386937 (* 1 = 0.00386937 loss)
I1014 07:34:03.517153 13701 sgd_solver.cpp:105] Iteration 97900, lr = 0.0001
I1014 07:34:32.542958 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:34:33.760591 13701 solver.cpp:330] Iteration 98000, Testing net (#0)
I1014 07:34:50.323220 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:34:50.663421 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13331 (* 1 = 1.13331 loss)
I1014 07:34:50.663435 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7385
I1014 07:34:50.967134 13701 solver.cpp:218] Iteration 98000 (2.10748 iter/s, 47.45s/100 iters), loss = 0.00554585
I1014 07:34:50.967166 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554611 (* 1 = 0.00554611 loss)
I1014 07:34:50.967173 13701 sgd_solver.cpp:105] Iteration 98000, lr = 0.0001
I1014 07:35:21.495829 13701 solver.cpp:218] Iteration 98100 (3.27561 iter/s, 30.5287s/100 iters), loss = 0.00810328
I1014 07:35:21.496466 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810354 (* 1 = 0.00810354 loss)
I1014 07:35:21.496484 13701 sgd_solver.cpp:105] Iteration 98100, lr = 0.0001
I1014 07:35:52.002490 13701 solver.cpp:218] Iteration 98200 (3.27804 iter/s, 30.506s/100 iters), loss = 0.00425917
I1014 07:35:52.002599 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425944 (* 1 = 0.00425944 loss)
I1014 07:35:52.002605 13701 sgd_solver.cpp:105] Iteration 98200, lr = 0.0001
I1014 07:36:22.560362 13701 solver.cpp:218] Iteration 98300 (3.27249 iter/s, 30.5578s/100 iters), loss = 0.00953698
I1014 07:36:22.560492 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00953724 (* 1 = 0.00953724 loss)
I1014 07:36:22.560501 13701 sgd_solver.cpp:105] Iteration 98300, lr = 0.0001
I1014 07:36:53.067653 13701 solver.cpp:218] Iteration 98400 (3.27792 iter/s, 30.5072s/100 iters), loss = 0.00372941
I1014 07:36:53.067792 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372968 (* 1 = 0.00372968 loss)
I1014 07:36:53.067800 13701 sgd_solver.cpp:105] Iteration 98400, lr = 0.0001
I1014 07:37:23.336741 13701 solver.cpp:330] Iteration 98500, Testing net (#0)
I1014 07:37:39.922576 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:37:40.262770 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13315 (* 1 = 1.13315 loss)
I1014 07:37:40.262785 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7383
I1014 07:37:40.562849 13701 solver.cpp:218] Iteration 98500 (2.10548 iter/s, 47.4951s/100 iters), loss = 0.0079804
I1014 07:37:40.562885 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00798066 (* 1 = 0.00798066 loss)
I1014 07:37:40.562892 13701 sgd_solver.cpp:105] Iteration 98500, lr = 0.0001
I1014 07:38:11.096318 13701 solver.cpp:218] Iteration 98600 (3.2751 iter/s, 30.5334s/100 iters), loss = 0.0111587
I1014 07:38:11.096493 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011159 (* 1 = 0.011159 loss)
I1014 07:38:11.096501 13701 sgd_solver.cpp:105] Iteration 98600, lr = 0.0001
I1014 07:38:41.587391 13701 solver.cpp:218] Iteration 98700 (3.27967 iter/s, 30.4909s/100 iters), loss = 0.003644
I1014 07:38:41.587548 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364427 (* 1 = 0.00364427 loss)
I1014 07:38:41.587558 13701 sgd_solver.cpp:105] Iteration 98700, lr = 0.0001
I1014 07:39:12.122172 13701 solver.cpp:218] Iteration 98800 (3.27497 iter/s, 30.5346s/100 iters), loss = 0.00617818
I1014 07:39:12.122283 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00617844 (* 1 = 0.00617844 loss)
I1014 07:39:12.122301 13701 sgd_solver.cpp:105] Iteration 98800, lr = 0.0001
I1014 07:39:42.635365 13701 solver.cpp:218] Iteration 98900 (3.27728 iter/s, 30.5131s/100 iters), loss = 0.00616338
I1014 07:39:42.635473 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616364 (* 1 = 0.00616364 loss)
I1014 07:39:42.635489 13701 sgd_solver.cpp:105] Iteration 98900, lr = 0.0001
I1014 07:40:11.582566 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:40:12.794528 13701 solver.cpp:330] Iteration 99000, Testing net (#0)
I1014 07:40:29.376762 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:40:29.718617 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13303 (* 1 = 1.13303 loss)
I1014 07:40:29.718633 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7379
I1014 07:40:30.025418 13701 solver.cpp:218] Iteration 99000 (2.11015 iter/s, 47.39s/100 iters), loss = 0.00475428
I1014 07:40:30.025451 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475454 (* 1 = 0.00475454 loss)
I1014 07:40:30.025460 13701 sgd_solver.cpp:105] Iteration 99000, lr = 0.0001
I1014 07:41:00.517575 13701 solver.cpp:218] Iteration 99100 (3.27954 iter/s, 30.4921s/100 iters), loss = 0.00781528
I1014 07:41:00.518483 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00781554 (* 1 = 0.00781554 loss)
I1014 07:41:00.518501 13701 sgd_solver.cpp:105] Iteration 99100, lr = 0.0001
I1014 07:41:31.055922 13701 solver.cpp:218] Iteration 99200 (3.27467 iter/s, 30.5375s/100 iters), loss = 0.00380424
I1014 07:41:31.056046 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038045 (* 1 = 0.0038045 loss)
I1014 07:41:31.056054 13701 sgd_solver.cpp:105] Iteration 99200, lr = 0.0001
I1014 07:42:01.521401 13701 solver.cpp:218] Iteration 99300 (3.28242 iter/s, 30.4654s/100 iters), loss = 0.00715649
I1014 07:42:01.521555 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715675 (* 1 = 0.00715675 loss)
I1014 07:42:01.521564 13701 sgd_solver.cpp:105] Iteration 99300, lr = 0.0001
I1014 07:42:32.024269 13701 solver.cpp:218] Iteration 99400 (3.2784 iter/s, 30.5027s/100 iters), loss = 0.00563775
I1014 07:42:32.024379 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563801 (* 1 = 0.00563801 loss)
I1014 07:42:32.024385 13701 sgd_solver.cpp:105] Iteration 99400, lr = 0.0001
I1014 07:43:02.249733 13701 solver.cpp:330] Iteration 99500, Testing net (#0)
I1014 07:43:18.840620 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:43:19.181748 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1329 (* 1 = 1.1329 loss)
I1014 07:43:19.181764 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1014 07:43:19.483924 13701 solver.cpp:218] Iteration 99500 (2.10706 iter/s, 47.4596s/100 iters), loss = 0.00461963
I1014 07:43:19.483954 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461989 (* 1 = 0.00461989 loss)
I1014 07:43:19.483961 13701 sgd_solver.cpp:105] Iteration 99500, lr = 0.0001
I1014 07:43:49.960604 13701 solver.cpp:218] Iteration 99600 (3.2812 iter/s, 30.4767s/100 iters), loss = 0.00497855
I1014 07:43:49.960786 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497881 (* 1 = 0.00497881 loss)
I1014 07:43:49.960811 13701 sgd_solver.cpp:105] Iteration 99600, lr = 0.0001
I1014 07:44:20.441804 13701 solver.cpp:218] Iteration 99700 (3.28073 iter/s, 30.481s/100 iters), loss = 0.00570192
I1014 07:44:20.441972 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570218 (* 1 = 0.00570218 loss)
I1014 07:44:20.441993 13701 sgd_solver.cpp:105] Iteration 99700, lr = 0.0001
I1014 07:44:50.894035 13701 solver.cpp:218] Iteration 99800 (3.28385 iter/s, 30.4521s/100 iters), loss = 0.00470121
I1014 07:44:50.894186 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00470147 (* 1 = 0.00470147 loss)
I1014 07:44:50.894209 13701 sgd_solver.cpp:105] Iteration 99800, lr = 0.0001
I1014 07:45:21.385413 13701 solver.cpp:218] Iteration 99900 (3.27963 iter/s, 30.4912s/100 iters), loss = 0.00398026
I1014 07:45:21.385565 13701 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398053 (* 1 = 0.00398053 loss)
I1014 07:45:21.385589 13701 sgd_solver.cpp:105] Iteration 99900, lr = 0.0001
I1014 07:45:50.328868 13707 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:45:51.550139 13701 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/WRN/WRN_penlu_1_2study_2decay_iter_100000.caffemodel
I1014 07:46:08.646711 13701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/WRN/WRN_penlu_1_2study_2decay_iter_100000.solverstate
I1014 07:46:08.867386 13701 solver.cpp:310] Iteration 100000, loss = 0.00556483
I1014 07:46:08.867410 13701 solver.cpp:330] Iteration 100000, Testing net (#0)
I1014 07:46:24.791780 13708 data_layer.cpp:73] Restarting data prefetching from start.
I1014 07:46:25.121197 13701 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13273 (* 1 = 1.13273 loss)
I1014 07:46:25.121213 13701 solver.cpp:397]     Test net output #1: accuracy = 0.7376
I1014 07:46:25.121218 13701 solver.cpp:315] Optimization Done.
I1014 07:46:25.121220 13701 caffe.cpp:259] Optimization Done.
