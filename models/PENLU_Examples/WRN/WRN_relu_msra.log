I1012 21:57:23.057546 11428 caffe.cpp:218] Using GPUs 0
I1012 21:57:23.088775 11428 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1012 21:57:23.303486 11428 solver.cpp:44] Initializing solver from parameters: 
test_iter: 200
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 120000
snapshot_prefix: "xn/PENLU/snapshot/WRN/WRN_relu_msra"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/WRN/WRN_relu_msra.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
stepvalue: 60000
stepvalue: 90000
stepvalue: 110000
type: "Nesterov"
I1012 21:57:23.303616 11428 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_relu_msra.prototxt
I1012 21:57:23.304803 11428 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_relu_msra.prototxt
I1012 21:57:23.304813 11428 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1012 21:57:23.304953 11428 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1012 21:57:23.305022 11428 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1012 21:57:23.305407 11428 net.cpp:51] Initializing net from parameters: 
name: "wrn_28_10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar100/cifar100_train_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution4"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution4"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Eltwise1"
  top: "Eltwise1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution5"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution5"
  top: "Convolution6"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution6"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Eltwise2"
  top: "Eltwise2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution7"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution7"
  top: "Convolution8"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Eltwise3"
  top: "Eltwise3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution13"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Eltwise5"
  top: "Eltwise5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Eltwise6"
  top: "Eltwise6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Eltwise7"
  top: "Eltwise7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution22"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution21"
  bottom: "Convolution22"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Eltwise9"
  top: "Eltwise9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution24"
  bottom: "Eltwise9"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Eltwise10"
  top: "Eltwise10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution25"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution26"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Eltwise11"
  top: "Eltwise11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution27"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution28"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise12"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 100
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
I1012 21:57:23.305851 11428 layer_factory.hpp:77] Creating layer cifar
I1012 21:57:23.305986 11428 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar100/cifar100_train_lmdb
I1012 21:57:23.306017 11428 net.cpp:84] Creating Layer cifar
I1012 21:57:23.306035 11428 net.cpp:380] cifar -> data
I1012 21:57:23.306063 11428 net.cpp:380] cifar -> label
I1012 21:57:23.306084 11428 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto
I1012 21:57:23.307494 11428 data_layer.cpp:45] output data size: 50,3,28,28
I1012 21:57:23.308845 11428 net.cpp:122] Setting up cifar
I1012 21:57:23.308857 11428 net.cpp:129] Top shape: 50 3 28 28 (117600)
I1012 21:57:23.308862 11428 net.cpp:129] Top shape: 50 (50)
I1012 21:57:23.308876 11428 net.cpp:137] Memory required for data: 470600
I1012 21:57:23.308884 11428 layer_factory.hpp:77] Creating layer Convolution1
I1012 21:57:23.308903 11428 net.cpp:84] Creating Layer Convolution1
I1012 21:57:23.308917 11428 net.cpp:406] Convolution1 <- data
I1012 21:57:23.308938 11428 net.cpp:380] Convolution1 -> Convolution1
I1012 21:57:23.455447 11428 net.cpp:122] Setting up Convolution1
I1012 21:57:23.455471 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:23.455474 11428 net.cpp:137] Memory required for data: 2979400
I1012 21:57:23.455490 11428 layer_factory.hpp:77] Creating layer BatchNorm1
I1012 21:57:23.455513 11428 net.cpp:84] Creating Layer BatchNorm1
I1012 21:57:23.455528 11428 net.cpp:406] BatchNorm1 <- Convolution1
I1012 21:57:23.455533 11428 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1012 21:57:23.455693 11428 net.cpp:122] Setting up BatchNorm1
I1012 21:57:23.455700 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:23.455703 11428 net.cpp:137] Memory required for data: 5488200
I1012 21:57:23.455711 11428 layer_factory.hpp:77] Creating layer Scale1
I1012 21:57:23.455731 11428 net.cpp:84] Creating Layer Scale1
I1012 21:57:23.455735 11428 net.cpp:406] Scale1 <- Convolution1
I1012 21:57:23.455740 11428 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1012 21:57:23.455798 11428 layer_factory.hpp:77] Creating layer Scale1
I1012 21:57:23.455927 11428 net.cpp:122] Setting up Scale1
I1012 21:57:23.455943 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:23.455946 11428 net.cpp:137] Memory required for data: 7997000
I1012 21:57:23.455951 11428 layer_factory.hpp:77] Creating layer ReLU1
I1012 21:57:23.455957 11428 net.cpp:84] Creating Layer ReLU1
I1012 21:57:23.455961 11428 net.cpp:406] ReLU1 <- Convolution1
I1012 21:57:23.455976 11428 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1012 21:57:23.456121 11428 net.cpp:122] Setting up ReLU1
I1012 21:57:23.456128 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:23.456147 11428 net.cpp:137] Memory required for data: 10505800
I1012 21:57:23.456151 11428 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1012 21:57:23.456171 11428 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1012 21:57:23.456174 11428 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1012 21:57:23.456179 11428 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1012 21:57:23.456194 11428 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1012 21:57:23.456251 11428 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1012 21:57:23.456265 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:23.456270 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:23.456284 11428 net.cpp:137] Memory required for data: 15523400
I1012 21:57:23.456288 11428 layer_factory.hpp:77] Creating layer Convolution2
I1012 21:57:23.456306 11428 net.cpp:84] Creating Layer Convolution2
I1012 21:57:23.456310 11428 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1012 21:57:23.456328 11428 net.cpp:380] Convolution2 -> Convolution2
I1012 21:57:23.458498 11428 net.cpp:122] Setting up Convolution2
I1012 21:57:23.458508 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.458523 11428 net.cpp:137] Memory required for data: 40611400
I1012 21:57:23.458528 11428 layer_factory.hpp:77] Creating layer BatchNorm2
I1012 21:57:23.458546 11428 net.cpp:84] Creating Layer BatchNorm2
I1012 21:57:23.458551 11428 net.cpp:406] BatchNorm2 <- Convolution2
I1012 21:57:23.458556 11428 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1012 21:57:23.458686 11428 net.cpp:122] Setting up BatchNorm2
I1012 21:57:23.458693 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.458698 11428 net.cpp:137] Memory required for data: 65699400
I1012 21:57:23.458716 11428 layer_factory.hpp:77] Creating layer Scale2
I1012 21:57:23.458724 11428 net.cpp:84] Creating Layer Scale2
I1012 21:57:23.458727 11428 net.cpp:406] Scale2 <- Convolution2
I1012 21:57:23.458732 11428 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1012 21:57:23.458758 11428 layer_factory.hpp:77] Creating layer Scale2
I1012 21:57:23.458859 11428 net.cpp:122] Setting up Scale2
I1012 21:57:23.458866 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.458870 11428 net.cpp:137] Memory required for data: 90787400
I1012 21:57:23.458886 11428 layer_factory.hpp:77] Creating layer ReLU2
I1012 21:57:23.458892 11428 net.cpp:84] Creating Layer ReLU2
I1012 21:57:23.458896 11428 net.cpp:406] ReLU2 <- Convolution2
I1012 21:57:23.458901 11428 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1012 21:57:23.459345 11428 net.cpp:122] Setting up ReLU2
I1012 21:57:23.459355 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.459359 11428 net.cpp:137] Memory required for data: 115875400
I1012 21:57:23.459363 11428 layer_factory.hpp:77] Creating layer Convolution3
I1012 21:57:23.459372 11428 net.cpp:84] Creating Layer Convolution3
I1012 21:57:23.459377 11428 net.cpp:406] Convolution3 <- Convolution2
I1012 21:57:23.459383 11428 net.cpp:380] Convolution3 -> Convolution3
I1012 21:57:23.465673 11428 net.cpp:122] Setting up Convolution3
I1012 21:57:23.465683 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.465687 11428 net.cpp:137] Memory required for data: 140963400
I1012 21:57:23.465693 11428 layer_factory.hpp:77] Creating layer Convolution4
I1012 21:57:23.465703 11428 net.cpp:84] Creating Layer Convolution4
I1012 21:57:23.465714 11428 net.cpp:406] Convolution4 <- Convolution1_ReLU1_0_split_1
I1012 21:57:23.465721 11428 net.cpp:380] Convolution4 -> Convolution4
I1012 21:57:23.466626 11428 net.cpp:122] Setting up Convolution4
I1012 21:57:23.466648 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.466663 11428 net.cpp:137] Memory required for data: 166051400
I1012 21:57:23.466670 11428 layer_factory.hpp:77] Creating layer Eltwise1
I1012 21:57:23.466681 11428 net.cpp:84] Creating Layer Eltwise1
I1012 21:57:23.466687 11428 net.cpp:406] Eltwise1 <- Convolution3
I1012 21:57:23.466694 11428 net.cpp:406] Eltwise1 <- Convolution4
I1012 21:57:23.466704 11428 net.cpp:380] Eltwise1 -> Eltwise1
I1012 21:57:23.466734 11428 net.cpp:122] Setting up Eltwise1
I1012 21:57:23.466743 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.466751 11428 net.cpp:137] Memory required for data: 191139400
I1012 21:57:23.466756 11428 layer_factory.hpp:77] Creating layer BatchNorm3
I1012 21:57:23.466768 11428 net.cpp:84] Creating Layer BatchNorm3
I1012 21:57:23.466775 11428 net.cpp:406] BatchNorm3 <- Eltwise1
I1012 21:57:23.466784 11428 net.cpp:367] BatchNorm3 -> Eltwise1 (in-place)
I1012 21:57:23.466938 11428 net.cpp:122] Setting up BatchNorm3
I1012 21:57:23.466946 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.466951 11428 net.cpp:137] Memory required for data: 216227400
I1012 21:57:23.466967 11428 layer_factory.hpp:77] Creating layer Scale3
I1012 21:57:23.466976 11428 net.cpp:84] Creating Layer Scale3
I1012 21:57:23.466982 11428 net.cpp:406] Scale3 <- Eltwise1
I1012 21:57:23.466991 11428 net.cpp:367] Scale3 -> Eltwise1 (in-place)
I1012 21:57:23.467030 11428 layer_factory.hpp:77] Creating layer Scale3
I1012 21:57:23.467157 11428 net.cpp:122] Setting up Scale3
I1012 21:57:23.467166 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.467170 11428 net.cpp:137] Memory required for data: 241315400
I1012 21:57:23.467175 11428 layer_factory.hpp:77] Creating layer ReLU3
I1012 21:57:23.467185 11428 net.cpp:84] Creating Layer ReLU3
I1012 21:57:23.467190 11428 net.cpp:406] ReLU3 <- Eltwise1
I1012 21:57:23.467198 11428 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1012 21:57:23.467653 11428 net.cpp:122] Setting up ReLU3
I1012 21:57:23.467663 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.467676 11428 net.cpp:137] Memory required for data: 266403400
I1012 21:57:23.467680 11428 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1012 21:57:23.467687 11428 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1012 21:57:23.467692 11428 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1012 21:57:23.467697 11428 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1012 21:57:23.467705 11428 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1012 21:57:23.467766 11428 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1012 21:57:23.467772 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.467784 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.467787 11428 net.cpp:137] Memory required for data: 316579400
I1012 21:57:23.467800 11428 layer_factory.hpp:77] Creating layer Convolution5
I1012 21:57:23.467808 11428 net.cpp:84] Creating Layer Convolution5
I1012 21:57:23.467811 11428 net.cpp:406] Convolution5 <- Eltwise1_ReLU3_0_split_0
I1012 21:57:23.467818 11428 net.cpp:380] Convolution5 -> Convolution5
I1012 21:57:23.473670 11428 net.cpp:122] Setting up Convolution5
I1012 21:57:23.473680 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.473695 11428 net.cpp:137] Memory required for data: 341667400
I1012 21:57:23.473700 11428 layer_factory.hpp:77] Creating layer BatchNorm4
I1012 21:57:23.473706 11428 net.cpp:84] Creating Layer BatchNorm4
I1012 21:57:23.473711 11428 net.cpp:406] BatchNorm4 <- Convolution5
I1012 21:57:23.473716 11428 net.cpp:367] BatchNorm4 -> Convolution5 (in-place)
I1012 21:57:23.473850 11428 net.cpp:122] Setting up BatchNorm4
I1012 21:57:23.473857 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.473879 11428 net.cpp:137] Memory required for data: 366755400
I1012 21:57:23.473887 11428 layer_factory.hpp:77] Creating layer Scale4
I1012 21:57:23.473894 11428 net.cpp:84] Creating Layer Scale4
I1012 21:57:23.473898 11428 net.cpp:406] Scale4 <- Convolution5
I1012 21:57:23.473903 11428 net.cpp:367] Scale4 -> Convolution5 (in-place)
I1012 21:57:23.473937 11428 layer_factory.hpp:77] Creating layer Scale4
I1012 21:57:23.474016 11428 net.cpp:122] Setting up Scale4
I1012 21:57:23.474022 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.474026 11428 net.cpp:137] Memory required for data: 391843400
I1012 21:57:23.474032 11428 layer_factory.hpp:77] Creating layer ReLU4
I1012 21:57:23.474038 11428 net.cpp:84] Creating Layer ReLU4
I1012 21:57:23.474042 11428 net.cpp:406] ReLU4 <- Convolution5
I1012 21:57:23.474047 11428 net.cpp:367] ReLU4 -> Convolution5 (in-place)
I1012 21:57:23.474479 11428 net.cpp:122] Setting up ReLU4
I1012 21:57:23.474489 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.474493 11428 net.cpp:137] Memory required for data: 416931400
I1012 21:57:23.474498 11428 layer_factory.hpp:77] Creating layer Convolution6
I1012 21:57:23.474506 11428 net.cpp:84] Creating Layer Convolution6
I1012 21:57:23.474510 11428 net.cpp:406] Convolution6 <- Convolution5
I1012 21:57:23.474517 11428 net.cpp:380] Convolution6 -> Convolution6
I1012 21:57:23.481165 11428 net.cpp:122] Setting up Convolution6
I1012 21:57:23.481176 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.481180 11428 net.cpp:137] Memory required for data: 442019400
I1012 21:57:23.481186 11428 layer_factory.hpp:77] Creating layer Eltwise2
I1012 21:57:23.481194 11428 net.cpp:84] Creating Layer Eltwise2
I1012 21:57:23.481197 11428 net.cpp:406] Eltwise2 <- Convolution6
I1012 21:57:23.481202 11428 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1012 21:57:23.481209 11428 net.cpp:380] Eltwise2 -> Eltwise2
I1012 21:57:23.481231 11428 net.cpp:122] Setting up Eltwise2
I1012 21:57:23.481237 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.481241 11428 net.cpp:137] Memory required for data: 467107400
I1012 21:57:23.481245 11428 layer_factory.hpp:77] Creating layer BatchNorm5
I1012 21:57:23.481251 11428 net.cpp:84] Creating Layer BatchNorm5
I1012 21:57:23.481256 11428 net.cpp:406] BatchNorm5 <- Eltwise2
I1012 21:57:23.481261 11428 net.cpp:367] BatchNorm5 -> Eltwise2 (in-place)
I1012 21:57:23.481386 11428 net.cpp:122] Setting up BatchNorm5
I1012 21:57:23.481392 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.481396 11428 net.cpp:137] Memory required for data: 492195400
I1012 21:57:23.481403 11428 layer_factory.hpp:77] Creating layer Scale5
I1012 21:57:23.481410 11428 net.cpp:84] Creating Layer Scale5
I1012 21:57:23.481413 11428 net.cpp:406] Scale5 <- Eltwise2
I1012 21:57:23.481420 11428 net.cpp:367] Scale5 -> Eltwise2 (in-place)
I1012 21:57:23.481446 11428 layer_factory.hpp:77] Creating layer Scale5
I1012 21:57:23.481523 11428 net.cpp:122] Setting up Scale5
I1012 21:57:23.481528 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.481533 11428 net.cpp:137] Memory required for data: 517283400
I1012 21:57:23.481537 11428 layer_factory.hpp:77] Creating layer ReLU5
I1012 21:57:23.481544 11428 net.cpp:84] Creating Layer ReLU5
I1012 21:57:23.481547 11428 net.cpp:406] ReLU5 <- Eltwise2
I1012 21:57:23.481554 11428 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1012 21:57:23.481675 11428 net.cpp:122] Setting up ReLU5
I1012 21:57:23.481683 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.481688 11428 net.cpp:137] Memory required for data: 542371400
I1012 21:57:23.481691 11428 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1012 21:57:23.481696 11428 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1012 21:57:23.481700 11428 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1012 21:57:23.481706 11428 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1012 21:57:23.481712 11428 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1012 21:57:23.481748 11428 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1012 21:57:23.481755 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.481758 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.481762 11428 net.cpp:137] Memory required for data: 592547400
I1012 21:57:23.481766 11428 layer_factory.hpp:77] Creating layer Convolution7
I1012 21:57:23.481775 11428 net.cpp:84] Creating Layer Convolution7
I1012 21:57:23.481779 11428 net.cpp:406] Convolution7 <- Eltwise2_ReLU5_0_split_0
I1012 21:57:23.481786 11428 net.cpp:380] Convolution7 -> Convolution7
I1012 21:57:23.488198 11428 net.cpp:122] Setting up Convolution7
I1012 21:57:23.488211 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.488215 11428 net.cpp:137] Memory required for data: 617635400
I1012 21:57:23.488225 11428 layer_factory.hpp:77] Creating layer BatchNorm6
I1012 21:57:23.488242 11428 net.cpp:84] Creating Layer BatchNorm6
I1012 21:57:23.488248 11428 net.cpp:406] BatchNorm6 <- Convolution7
I1012 21:57:23.488255 11428 net.cpp:367] BatchNorm6 -> Convolution7 (in-place)
I1012 21:57:23.488397 11428 net.cpp:122] Setting up BatchNorm6
I1012 21:57:23.488404 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.488416 11428 net.cpp:137] Memory required for data: 642723400
I1012 21:57:23.488425 11428 layer_factory.hpp:77] Creating layer Scale6
I1012 21:57:23.488442 11428 net.cpp:84] Creating Layer Scale6
I1012 21:57:23.488448 11428 net.cpp:406] Scale6 <- Convolution7
I1012 21:57:23.488464 11428 net.cpp:367] Scale6 -> Convolution7 (in-place)
I1012 21:57:23.488528 11428 layer_factory.hpp:77] Creating layer Scale6
I1012 21:57:23.488641 11428 net.cpp:122] Setting up Scale6
I1012 21:57:23.488647 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.488651 11428 net.cpp:137] Memory required for data: 667811400
I1012 21:57:23.488654 11428 layer_factory.hpp:77] Creating layer ReLU6
I1012 21:57:23.488659 11428 net.cpp:84] Creating Layer ReLU6
I1012 21:57:23.488673 11428 net.cpp:406] ReLU6 <- Convolution7
I1012 21:57:23.488678 11428 net.cpp:367] ReLU6 -> Convolution7 (in-place)
I1012 21:57:23.488802 11428 net.cpp:122] Setting up ReLU6
I1012 21:57:23.488811 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.488813 11428 net.cpp:137] Memory required for data: 692899400
I1012 21:57:23.488817 11428 layer_factory.hpp:77] Creating layer Convolution8
I1012 21:57:23.488826 11428 net.cpp:84] Creating Layer Convolution8
I1012 21:57:23.488829 11428 net.cpp:406] Convolution8 <- Convolution7
I1012 21:57:23.488836 11428 net.cpp:380] Convolution8 -> Convolution8
I1012 21:57:23.495393 11428 net.cpp:122] Setting up Convolution8
I1012 21:57:23.495404 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.495409 11428 net.cpp:137] Memory required for data: 717987400
I1012 21:57:23.495412 11428 layer_factory.hpp:77] Creating layer Eltwise3
I1012 21:57:23.495422 11428 net.cpp:84] Creating Layer Eltwise3
I1012 21:57:23.495437 11428 net.cpp:406] Eltwise3 <- Convolution8
I1012 21:57:23.495453 11428 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1012 21:57:23.495460 11428 net.cpp:380] Eltwise3 -> Eltwise3
I1012 21:57:23.495496 11428 net.cpp:122] Setting up Eltwise3
I1012 21:57:23.495513 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.495517 11428 net.cpp:137] Memory required for data: 743075400
I1012 21:57:23.495529 11428 layer_factory.hpp:77] Creating layer BatchNorm7
I1012 21:57:23.495535 11428 net.cpp:84] Creating Layer BatchNorm7
I1012 21:57:23.495549 11428 net.cpp:406] BatchNorm7 <- Eltwise3
I1012 21:57:23.495553 11428 net.cpp:367] BatchNorm7 -> Eltwise3 (in-place)
I1012 21:57:23.495731 11428 net.cpp:122] Setting up BatchNorm7
I1012 21:57:23.495738 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.495740 11428 net.cpp:137] Memory required for data: 768163400
I1012 21:57:23.495746 11428 layer_factory.hpp:77] Creating layer Scale7
I1012 21:57:23.495762 11428 net.cpp:84] Creating Layer Scale7
I1012 21:57:23.495766 11428 net.cpp:406] Scale7 <- Eltwise3
I1012 21:57:23.495790 11428 net.cpp:367] Scale7 -> Eltwise3 (in-place)
I1012 21:57:23.495841 11428 layer_factory.hpp:77] Creating layer Scale7
I1012 21:57:23.495937 11428 net.cpp:122] Setting up Scale7
I1012 21:57:23.495944 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.495962 11428 net.cpp:137] Memory required for data: 793251400
I1012 21:57:23.495967 11428 layer_factory.hpp:77] Creating layer ReLU7
I1012 21:57:23.495987 11428 net.cpp:84] Creating Layer ReLU7
I1012 21:57:23.495991 11428 net.cpp:406] ReLU7 <- Eltwise3
I1012 21:57:23.496009 11428 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1012 21:57:23.496158 11428 net.cpp:122] Setting up ReLU7
I1012 21:57:23.496166 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.496181 11428 net.cpp:137] Memory required for data: 818339400
I1012 21:57:23.496184 11428 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1012 21:57:23.496191 11428 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1012 21:57:23.496196 11428 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1012 21:57:23.496201 11428 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1012 21:57:23.496206 11428 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1012 21:57:23.496235 11428 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1012 21:57:23.496240 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.496245 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.496248 11428 net.cpp:137] Memory required for data: 868515400
I1012 21:57:23.496253 11428 layer_factory.hpp:77] Creating layer Convolution9
I1012 21:57:23.496260 11428 net.cpp:84] Creating Layer Convolution9
I1012 21:57:23.496264 11428 net.cpp:406] Convolution9 <- Eltwise3_ReLU7_0_split_0
I1012 21:57:23.496271 11428 net.cpp:380] Convolution9 -> Convolution9
I1012 21:57:23.502442 11428 net.cpp:122] Setting up Convolution9
I1012 21:57:23.502452 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.502459 11428 net.cpp:137] Memory required for data: 893603400
I1012 21:57:23.502465 11428 layer_factory.hpp:77] Creating layer BatchNorm8
I1012 21:57:23.502470 11428 net.cpp:84] Creating Layer BatchNorm8
I1012 21:57:23.502475 11428 net.cpp:406] BatchNorm8 <- Convolution9
I1012 21:57:23.502480 11428 net.cpp:367] BatchNorm8 -> Convolution9 (in-place)
I1012 21:57:23.502622 11428 net.cpp:122] Setting up BatchNorm8
I1012 21:57:23.502629 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.502642 11428 net.cpp:137] Memory required for data: 918691400
I1012 21:57:23.502650 11428 layer_factory.hpp:77] Creating layer Scale8
I1012 21:57:23.502655 11428 net.cpp:84] Creating Layer Scale8
I1012 21:57:23.502658 11428 net.cpp:406] Scale8 <- Convolution9
I1012 21:57:23.502663 11428 net.cpp:367] Scale8 -> Convolution9 (in-place)
I1012 21:57:23.502691 11428 layer_factory.hpp:77] Creating layer Scale8
I1012 21:57:23.502771 11428 net.cpp:122] Setting up Scale8
I1012 21:57:23.502777 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.502781 11428 net.cpp:137] Memory required for data: 943779400
I1012 21:57:23.502787 11428 layer_factory.hpp:77] Creating layer ReLU8
I1012 21:57:23.502794 11428 net.cpp:84] Creating Layer ReLU8
I1012 21:57:23.502797 11428 net.cpp:406] ReLU8 <- Convolution9
I1012 21:57:23.502801 11428 net.cpp:367] ReLU8 -> Convolution9 (in-place)
I1012 21:57:23.502921 11428 net.cpp:122] Setting up ReLU8
I1012 21:57:23.502929 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.502933 11428 net.cpp:137] Memory required for data: 968867400
I1012 21:57:23.502938 11428 layer_factory.hpp:77] Creating layer Convolution10
I1012 21:57:23.502944 11428 net.cpp:84] Creating Layer Convolution10
I1012 21:57:23.502949 11428 net.cpp:406] Convolution10 <- Convolution9
I1012 21:57:23.502954 11428 net.cpp:380] Convolution10 -> Convolution10
I1012 21:57:23.509616 11428 net.cpp:122] Setting up Convolution10
I1012 21:57:23.509627 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.509632 11428 net.cpp:137] Memory required for data: 993955400
I1012 21:57:23.509645 11428 layer_factory.hpp:77] Creating layer Eltwise4
I1012 21:57:23.509652 11428 net.cpp:84] Creating Layer Eltwise4
I1012 21:57:23.509657 11428 net.cpp:406] Eltwise4 <- Convolution10
I1012 21:57:23.509662 11428 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I1012 21:57:23.509670 11428 net.cpp:380] Eltwise4 -> Eltwise4
I1012 21:57:23.509691 11428 net.cpp:122] Setting up Eltwise4
I1012 21:57:23.509697 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.509701 11428 net.cpp:137] Memory required for data: 1019043400
I1012 21:57:23.509704 11428 layer_factory.hpp:77] Creating layer Eltwise4_Eltwise4_0_split
I1012 21:57:23.509711 11428 net.cpp:84] Creating Layer Eltwise4_Eltwise4_0_split
I1012 21:57:23.509716 11428 net.cpp:406] Eltwise4_Eltwise4_0_split <- Eltwise4
I1012 21:57:23.509721 11428 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I1012 21:57:23.509727 11428 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I1012 21:57:23.509752 11428 net.cpp:122] Setting up Eltwise4_Eltwise4_0_split
I1012 21:57:23.509757 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.509763 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:23.509766 11428 net.cpp:137] Memory required for data: 1069219400
I1012 21:57:23.509770 11428 layer_factory.hpp:77] Creating layer Convolution11
I1012 21:57:23.509778 11428 net.cpp:84] Creating Layer Convolution11
I1012 21:57:23.509783 11428 net.cpp:406] Convolution11 <- Eltwise4_Eltwise4_0_split_0
I1012 21:57:23.509788 11428 net.cpp:380] Convolution11 -> Convolution11
I1012 21:57:23.521868 11428 net.cpp:122] Setting up Convolution11
I1012 21:57:23.521885 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.521888 11428 net.cpp:137] Memory required for data: 1081763400
I1012 21:57:23.521894 11428 layer_factory.hpp:77] Creating layer BatchNorm9
I1012 21:57:23.521914 11428 net.cpp:84] Creating Layer BatchNorm9
I1012 21:57:23.521922 11428 net.cpp:406] BatchNorm9 <- Convolution11
I1012 21:57:23.521939 11428 net.cpp:367] BatchNorm9 -> Convolution11 (in-place)
I1012 21:57:23.522112 11428 net.cpp:122] Setting up BatchNorm9
I1012 21:57:23.522119 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.522122 11428 net.cpp:137] Memory required for data: 1094307400
I1012 21:57:23.522128 11428 layer_factory.hpp:77] Creating layer Scale9
I1012 21:57:23.522135 11428 net.cpp:84] Creating Layer Scale9
I1012 21:57:23.522148 11428 net.cpp:406] Scale9 <- Convolution11
I1012 21:57:23.522155 11428 net.cpp:367] Scale9 -> Convolution11 (in-place)
I1012 21:57:23.522213 11428 layer_factory.hpp:77] Creating layer Scale9
I1012 21:57:23.522337 11428 net.cpp:122] Setting up Scale9
I1012 21:57:23.522343 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.522346 11428 net.cpp:137] Memory required for data: 1106851400
I1012 21:57:23.522351 11428 layer_factory.hpp:77] Creating layer ReLU9
I1012 21:57:23.522357 11428 net.cpp:84] Creating Layer ReLU9
I1012 21:57:23.522361 11428 net.cpp:406] ReLU9 <- Convolution11
I1012 21:57:23.522374 11428 net.cpp:367] ReLU9 -> Convolution11 (in-place)
I1012 21:57:23.522517 11428 net.cpp:122] Setting up ReLU9
I1012 21:57:23.522526 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.522538 11428 net.cpp:137] Memory required for data: 1119395400
I1012 21:57:23.522541 11428 layer_factory.hpp:77] Creating layer Convolution12
I1012 21:57:23.522550 11428 net.cpp:84] Creating Layer Convolution12
I1012 21:57:23.522555 11428 net.cpp:406] Convolution12 <- Convolution11
I1012 21:57:23.522560 11428 net.cpp:380] Convolution12 -> Convolution12
I1012 21:57:23.544039 11428 net.cpp:122] Setting up Convolution12
I1012 21:57:23.544051 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.544055 11428 net.cpp:137] Memory required for data: 1131939400
I1012 21:57:23.544060 11428 layer_factory.hpp:77] Creating layer Convolution13
I1012 21:57:23.544070 11428 net.cpp:84] Creating Layer Convolution13
I1012 21:57:23.544095 11428 net.cpp:406] Convolution13 <- Eltwise4_Eltwise4_0_split_1
I1012 21:57:23.544103 11428 net.cpp:380] Convolution13 -> Convolution13
I1012 21:57:23.546331 11428 net.cpp:122] Setting up Convolution13
I1012 21:57:23.546344 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.546347 11428 net.cpp:137] Memory required for data: 1144483400
I1012 21:57:23.546352 11428 layer_factory.hpp:77] Creating layer Eltwise5
I1012 21:57:23.546360 11428 net.cpp:84] Creating Layer Eltwise5
I1012 21:57:23.546362 11428 net.cpp:406] Eltwise5 <- Convolution12
I1012 21:57:23.546377 11428 net.cpp:406] Eltwise5 <- Convolution13
I1012 21:57:23.546394 11428 net.cpp:380] Eltwise5 -> Eltwise5
I1012 21:57:23.546430 11428 net.cpp:122] Setting up Eltwise5
I1012 21:57:23.546452 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.546455 11428 net.cpp:137] Memory required for data: 1157027400
I1012 21:57:23.546458 11428 layer_factory.hpp:77] Creating layer BatchNorm10
I1012 21:57:23.546473 11428 net.cpp:84] Creating Layer BatchNorm10
I1012 21:57:23.546478 11428 net.cpp:406] BatchNorm10 <- Eltwise5
I1012 21:57:23.546491 11428 net.cpp:367] BatchNorm10 -> Eltwise5 (in-place)
I1012 21:57:23.546669 11428 net.cpp:122] Setting up BatchNorm10
I1012 21:57:23.546675 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.546679 11428 net.cpp:137] Memory required for data: 1169571400
I1012 21:57:23.546684 11428 layer_factory.hpp:77] Creating layer Scale10
I1012 21:57:23.546690 11428 net.cpp:84] Creating Layer Scale10
I1012 21:57:23.546694 11428 net.cpp:406] Scale10 <- Eltwise5
I1012 21:57:23.546708 11428 net.cpp:367] Scale10 -> Eltwise5 (in-place)
I1012 21:57:23.546773 11428 layer_factory.hpp:77] Creating layer Scale10
I1012 21:57:23.546856 11428 net.cpp:122] Setting up Scale10
I1012 21:57:23.546864 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.546866 11428 net.cpp:137] Memory required for data: 1182115400
I1012 21:57:23.546872 11428 layer_factory.hpp:77] Creating layer ReLU10
I1012 21:57:23.546878 11428 net.cpp:84] Creating Layer ReLU10
I1012 21:57:23.546881 11428 net.cpp:406] ReLU10 <- Eltwise5
I1012 21:57:23.546896 11428 net.cpp:367] ReLU10 -> Eltwise5 (in-place)
I1012 21:57:23.547412 11428 net.cpp:122] Setting up ReLU10
I1012 21:57:23.547422 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.547427 11428 net.cpp:137] Memory required for data: 1194659400
I1012 21:57:23.547431 11428 layer_factory.hpp:77] Creating layer Eltwise5_ReLU10_0_split
I1012 21:57:23.547437 11428 net.cpp:84] Creating Layer Eltwise5_ReLU10_0_split
I1012 21:57:23.547441 11428 net.cpp:406] Eltwise5_ReLU10_0_split <- Eltwise5
I1012 21:57:23.547448 11428 net.cpp:380] Eltwise5_ReLU10_0_split -> Eltwise5_ReLU10_0_split_0
I1012 21:57:23.547456 11428 net.cpp:380] Eltwise5_ReLU10_0_split -> Eltwise5_ReLU10_0_split_1
I1012 21:57:23.547487 11428 net.cpp:122] Setting up Eltwise5_ReLU10_0_split
I1012 21:57:23.547494 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.547499 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.547503 11428 net.cpp:137] Memory required for data: 1219747400
I1012 21:57:23.547507 11428 layer_factory.hpp:77] Creating layer Convolution14
I1012 21:57:23.547514 11428 net.cpp:84] Creating Layer Convolution14
I1012 21:57:23.547519 11428 net.cpp:406] Convolution14 <- Eltwise5_ReLU10_0_split_0
I1012 21:57:23.547526 11428 net.cpp:380] Convolution14 -> Convolution14
I1012 21:57:23.569380 11428 net.cpp:122] Setting up Convolution14
I1012 21:57:23.569394 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.569398 11428 net.cpp:137] Memory required for data: 1232291400
I1012 21:57:23.569422 11428 layer_factory.hpp:77] Creating layer BatchNorm11
I1012 21:57:23.569432 11428 net.cpp:84] Creating Layer BatchNorm11
I1012 21:57:23.569437 11428 net.cpp:406] BatchNorm11 <- Convolution14
I1012 21:57:23.569443 11428 net.cpp:367] BatchNorm11 -> Convolution14 (in-place)
I1012 21:57:23.569605 11428 net.cpp:122] Setting up BatchNorm11
I1012 21:57:23.569612 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.569638 11428 net.cpp:137] Memory required for data: 1244835400
I1012 21:57:23.569654 11428 layer_factory.hpp:77] Creating layer Scale11
I1012 21:57:23.569675 11428 net.cpp:84] Creating Layer Scale11
I1012 21:57:23.569680 11428 net.cpp:406] Scale11 <- Convolution14
I1012 21:57:23.569685 11428 net.cpp:367] Scale11 -> Convolution14 (in-place)
I1012 21:57:23.569730 11428 layer_factory.hpp:77] Creating layer Scale11
I1012 21:57:23.569811 11428 net.cpp:122] Setting up Scale11
I1012 21:57:23.569818 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.569821 11428 net.cpp:137] Memory required for data: 1257379400
I1012 21:57:23.569828 11428 layer_factory.hpp:77] Creating layer ReLU11
I1012 21:57:23.569833 11428 net.cpp:84] Creating Layer ReLU11
I1012 21:57:23.569838 11428 net.cpp:406] ReLU11 <- Convolution14
I1012 21:57:23.569842 11428 net.cpp:367] ReLU11 -> Convolution14 (in-place)
I1012 21:57:23.570322 11428 net.cpp:122] Setting up ReLU11
I1012 21:57:23.570332 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.570335 11428 net.cpp:137] Memory required for data: 1269923400
I1012 21:57:23.570339 11428 layer_factory.hpp:77] Creating layer Convolution15
I1012 21:57:23.570348 11428 net.cpp:84] Creating Layer Convolution15
I1012 21:57:23.570353 11428 net.cpp:406] Convolution15 <- Convolution14
I1012 21:57:23.570358 11428 net.cpp:380] Convolution15 -> Convolution15
I1012 21:57:23.592736 11428 net.cpp:122] Setting up Convolution15
I1012 21:57:23.592754 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.592758 11428 net.cpp:137] Memory required for data: 1282467400
I1012 21:57:23.592774 11428 layer_factory.hpp:77] Creating layer Eltwise6
I1012 21:57:23.592792 11428 net.cpp:84] Creating Layer Eltwise6
I1012 21:57:23.592798 11428 net.cpp:406] Eltwise6 <- Convolution15
I1012 21:57:23.592813 11428 net.cpp:406] Eltwise6 <- Eltwise5_ReLU10_0_split_1
I1012 21:57:23.592819 11428 net.cpp:380] Eltwise6 -> Eltwise6
I1012 21:57:23.592844 11428 net.cpp:122] Setting up Eltwise6
I1012 21:57:23.592859 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.592872 11428 net.cpp:137] Memory required for data: 1295011400
I1012 21:57:23.592875 11428 layer_factory.hpp:77] Creating layer BatchNorm12
I1012 21:57:23.592890 11428 net.cpp:84] Creating Layer BatchNorm12
I1012 21:57:23.592895 11428 net.cpp:406] BatchNorm12 <- Eltwise6
I1012 21:57:23.592909 11428 net.cpp:367] BatchNorm12 -> Eltwise6 (in-place)
I1012 21:57:23.593068 11428 net.cpp:122] Setting up BatchNorm12
I1012 21:57:23.593075 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.593078 11428 net.cpp:137] Memory required for data: 1307555400
I1012 21:57:23.593085 11428 layer_factory.hpp:77] Creating layer Scale12
I1012 21:57:23.593091 11428 net.cpp:84] Creating Layer Scale12
I1012 21:57:23.593093 11428 net.cpp:406] Scale12 <- Eltwise6
I1012 21:57:23.593107 11428 net.cpp:367] Scale12 -> Eltwise6 (in-place)
I1012 21:57:23.593161 11428 layer_factory.hpp:77] Creating layer Scale12
I1012 21:57:23.593264 11428 net.cpp:122] Setting up Scale12
I1012 21:57:23.593271 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.593284 11428 net.cpp:137] Memory required for data: 1320099400
I1012 21:57:23.593291 11428 layer_factory.hpp:77] Creating layer ReLU12
I1012 21:57:23.593297 11428 net.cpp:84] Creating Layer ReLU12
I1012 21:57:23.593300 11428 net.cpp:406] ReLU12 <- Eltwise6
I1012 21:57:23.593305 11428 net.cpp:367] ReLU12 -> Eltwise6 (in-place)
I1012 21:57:23.593441 11428 net.cpp:122] Setting up ReLU12
I1012 21:57:23.593447 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.593451 11428 net.cpp:137] Memory required for data: 1332643400
I1012 21:57:23.593466 11428 layer_factory.hpp:77] Creating layer Eltwise6_ReLU12_0_split
I1012 21:57:23.593477 11428 net.cpp:84] Creating Layer Eltwise6_ReLU12_0_split
I1012 21:57:23.593482 11428 net.cpp:406] Eltwise6_ReLU12_0_split <- Eltwise6
I1012 21:57:23.593497 11428 net.cpp:380] Eltwise6_ReLU12_0_split -> Eltwise6_ReLU12_0_split_0
I1012 21:57:23.593523 11428 net.cpp:380] Eltwise6_ReLU12_0_split -> Eltwise6_ReLU12_0_split_1
I1012 21:57:23.593556 11428 net.cpp:122] Setting up Eltwise6_ReLU12_0_split
I1012 21:57:23.593562 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.593567 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.593570 11428 net.cpp:137] Memory required for data: 1357731400
I1012 21:57:23.593575 11428 layer_factory.hpp:77] Creating layer Convolution16
I1012 21:57:23.593585 11428 net.cpp:84] Creating Layer Convolution16
I1012 21:57:23.593590 11428 net.cpp:406] Convolution16 <- Eltwise6_ReLU12_0_split_0
I1012 21:57:23.593595 11428 net.cpp:380] Convolution16 -> Convolution16
I1012 21:57:23.616051 11428 net.cpp:122] Setting up Convolution16
I1012 21:57:23.616068 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.616072 11428 net.cpp:137] Memory required for data: 1370275400
I1012 21:57:23.616088 11428 layer_factory.hpp:77] Creating layer BatchNorm13
I1012 21:57:23.616109 11428 net.cpp:84] Creating Layer BatchNorm13
I1012 21:57:23.616116 11428 net.cpp:406] BatchNorm13 <- Convolution16
I1012 21:57:23.616130 11428 net.cpp:367] BatchNorm13 -> Convolution16 (in-place)
I1012 21:57:23.616320 11428 net.cpp:122] Setting up BatchNorm13
I1012 21:57:23.616328 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.616330 11428 net.cpp:137] Memory required for data: 1382819400
I1012 21:57:23.616336 11428 layer_factory.hpp:77] Creating layer Scale13
I1012 21:57:23.616343 11428 net.cpp:84] Creating Layer Scale13
I1012 21:57:23.616356 11428 net.cpp:406] Scale13 <- Convolution16
I1012 21:57:23.616363 11428 net.cpp:367] Scale13 -> Convolution16 (in-place)
I1012 21:57:23.616422 11428 layer_factory.hpp:77] Creating layer Scale13
I1012 21:57:23.616559 11428 net.cpp:122] Setting up Scale13
I1012 21:57:23.616564 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.616578 11428 net.cpp:137] Memory required for data: 1395363400
I1012 21:57:23.616585 11428 layer_factory.hpp:77] Creating layer ReLU13
I1012 21:57:23.616603 11428 net.cpp:84] Creating Layer ReLU13
I1012 21:57:23.616607 11428 net.cpp:406] ReLU13 <- Convolution16
I1012 21:57:23.616621 11428 net.cpp:367] ReLU13 -> Convolution16 (in-place)
I1012 21:57:23.616799 11428 net.cpp:122] Setting up ReLU13
I1012 21:57:23.616807 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.616827 11428 net.cpp:137] Memory required for data: 1407907400
I1012 21:57:23.616829 11428 layer_factory.hpp:77] Creating layer Convolution17
I1012 21:57:23.616849 11428 net.cpp:84] Creating Layer Convolution17
I1012 21:57:23.616853 11428 net.cpp:406] Convolution17 <- Convolution16
I1012 21:57:23.616859 11428 net.cpp:380] Convolution17 -> Convolution17
I1012 21:57:23.639837 11428 net.cpp:122] Setting up Convolution17
I1012 21:57:23.639856 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.639860 11428 net.cpp:137] Memory required for data: 1420451400
I1012 21:57:23.639866 11428 layer_factory.hpp:77] Creating layer Eltwise7
I1012 21:57:23.639886 11428 net.cpp:84] Creating Layer Eltwise7
I1012 21:57:23.639891 11428 net.cpp:406] Eltwise7 <- Convolution17
I1012 21:57:23.639906 11428 net.cpp:406] Eltwise7 <- Eltwise6_ReLU12_0_split_1
I1012 21:57:23.639914 11428 net.cpp:380] Eltwise7 -> Eltwise7
I1012 21:57:23.639961 11428 net.cpp:122] Setting up Eltwise7
I1012 21:57:23.639967 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.639971 11428 net.cpp:137] Memory required for data: 1432995400
I1012 21:57:23.639973 11428 layer_factory.hpp:77] Creating layer BatchNorm14
I1012 21:57:23.639981 11428 net.cpp:84] Creating Layer BatchNorm14
I1012 21:57:23.639983 11428 net.cpp:406] BatchNorm14 <- Eltwise7
I1012 21:57:23.639998 11428 net.cpp:367] BatchNorm14 -> Eltwise7 (in-place)
I1012 21:57:23.640187 11428 net.cpp:122] Setting up BatchNorm14
I1012 21:57:23.640192 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.640195 11428 net.cpp:137] Memory required for data: 1445539400
I1012 21:57:23.640221 11428 layer_factory.hpp:77] Creating layer Scale14
I1012 21:57:23.640229 11428 net.cpp:84] Creating Layer Scale14
I1012 21:57:23.640249 11428 net.cpp:406] Scale14 <- Eltwise7
I1012 21:57:23.640252 11428 net.cpp:367] Scale14 -> Eltwise7 (in-place)
I1012 21:57:23.640308 11428 layer_factory.hpp:77] Creating layer Scale14
I1012 21:57:23.640413 11428 net.cpp:122] Setting up Scale14
I1012 21:57:23.640419 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.640432 11428 net.cpp:137] Memory required for data: 1458083400
I1012 21:57:23.640437 11428 layer_factory.hpp:77] Creating layer ReLU14
I1012 21:57:23.640444 11428 net.cpp:84] Creating Layer ReLU14
I1012 21:57:23.640449 11428 net.cpp:406] ReLU14 <- Eltwise7
I1012 21:57:23.640452 11428 net.cpp:367] ReLU14 -> Eltwise7 (in-place)
I1012 21:57:23.640620 11428 net.cpp:122] Setting up ReLU14
I1012 21:57:23.640628 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.640632 11428 net.cpp:137] Memory required for data: 1470627400
I1012 21:57:23.640635 11428 layer_factory.hpp:77] Creating layer Eltwise7_ReLU14_0_split
I1012 21:57:23.640641 11428 net.cpp:84] Creating Layer Eltwise7_ReLU14_0_split
I1012 21:57:23.640645 11428 net.cpp:406] Eltwise7_ReLU14_0_split <- Eltwise7
I1012 21:57:23.640650 11428 net.cpp:380] Eltwise7_ReLU14_0_split -> Eltwise7_ReLU14_0_split_0
I1012 21:57:23.640655 11428 net.cpp:380] Eltwise7_ReLU14_0_split -> Eltwise7_ReLU14_0_split_1
I1012 21:57:23.640687 11428 net.cpp:122] Setting up Eltwise7_ReLU14_0_split
I1012 21:57:23.640693 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.640698 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.640702 11428 net.cpp:137] Memory required for data: 1495715400
I1012 21:57:23.640707 11428 layer_factory.hpp:77] Creating layer Convolution18
I1012 21:57:23.640715 11428 net.cpp:84] Creating Layer Convolution18
I1012 21:57:23.640719 11428 net.cpp:406] Convolution18 <- Eltwise7_ReLU14_0_split_0
I1012 21:57:23.640727 11428 net.cpp:380] Convolution18 -> Convolution18
I1012 21:57:23.662577 11428 net.cpp:122] Setting up Convolution18
I1012 21:57:23.662590 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.662592 11428 net.cpp:137] Memory required for data: 1508259400
I1012 21:57:23.662609 11428 layer_factory.hpp:77] Creating layer BatchNorm15
I1012 21:57:23.662627 11428 net.cpp:84] Creating Layer BatchNorm15
I1012 21:57:23.662632 11428 net.cpp:406] BatchNorm15 <- Convolution18
I1012 21:57:23.662638 11428 net.cpp:367] BatchNorm15 -> Convolution18 (in-place)
I1012 21:57:23.662812 11428 net.cpp:122] Setting up BatchNorm15
I1012 21:57:23.662819 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.662833 11428 net.cpp:137] Memory required for data: 1520803400
I1012 21:57:23.662840 11428 layer_factory.hpp:77] Creating layer Scale15
I1012 21:57:23.662858 11428 net.cpp:84] Creating Layer Scale15
I1012 21:57:23.662861 11428 net.cpp:406] Scale15 <- Convolution18
I1012 21:57:23.662866 11428 net.cpp:367] Scale15 -> Convolution18 (in-place)
I1012 21:57:23.662910 11428 layer_factory.hpp:77] Creating layer Scale15
I1012 21:57:23.662997 11428 net.cpp:122] Setting up Scale15
I1012 21:57:23.663002 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.663007 11428 net.cpp:137] Memory required for data: 1533347400
I1012 21:57:23.663012 11428 layer_factory.hpp:77] Creating layer ReLU15
I1012 21:57:23.663018 11428 net.cpp:84] Creating Layer ReLU15
I1012 21:57:23.663023 11428 net.cpp:406] ReLU15 <- Convolution18
I1012 21:57:23.663028 11428 net.cpp:367] ReLU15 -> Convolution18 (in-place)
I1012 21:57:23.663149 11428 net.cpp:122] Setting up ReLU15
I1012 21:57:23.663157 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.663161 11428 net.cpp:137] Memory required for data: 1545891400
I1012 21:57:23.663166 11428 layer_factory.hpp:77] Creating layer Convolution19
I1012 21:57:23.663173 11428 net.cpp:84] Creating Layer Convolution19
I1012 21:57:23.663177 11428 net.cpp:406] Convolution19 <- Convolution18
I1012 21:57:23.663183 11428 net.cpp:380] Convolution19 -> Convolution19
I1012 21:57:23.685451 11428 net.cpp:122] Setting up Convolution19
I1012 21:57:23.685472 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.685477 11428 net.cpp:137] Memory required for data: 1558435400
I1012 21:57:23.685493 11428 layer_factory.hpp:77] Creating layer Eltwise8
I1012 21:57:23.685518 11428 net.cpp:84] Creating Layer Eltwise8
I1012 21:57:23.685523 11428 net.cpp:406] Eltwise8 <- Convolution19
I1012 21:57:23.685529 11428 net.cpp:406] Eltwise8 <- Eltwise7_ReLU14_0_split_1
I1012 21:57:23.685535 11428 net.cpp:380] Eltwise8 -> Eltwise8
I1012 21:57:23.685571 11428 net.cpp:122] Setting up Eltwise8
I1012 21:57:23.685586 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.685590 11428 net.cpp:137] Memory required for data: 1570979400
I1012 21:57:23.685595 11428 layer_factory.hpp:77] Creating layer Eltwise8_Eltwise8_0_split
I1012 21:57:23.685611 11428 net.cpp:84] Creating Layer Eltwise8_Eltwise8_0_split
I1012 21:57:23.685626 11428 net.cpp:406] Eltwise8_Eltwise8_0_split <- Eltwise8
I1012 21:57:23.685631 11428 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I1012 21:57:23.685637 11428 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I1012 21:57:23.685667 11428 net.cpp:122] Setting up Eltwise8_Eltwise8_0_split
I1012 21:57:23.685680 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.685685 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:23.685699 11428 net.cpp:137] Memory required for data: 1596067400
I1012 21:57:23.685703 11428 layer_factory.hpp:77] Creating layer Convolution20
I1012 21:57:23.685714 11428 net.cpp:84] Creating Layer Convolution20
I1012 21:57:23.685719 11428 net.cpp:406] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I1012 21:57:23.685724 11428 net.cpp:380] Convolution20 -> Convolution20
I1012 21:57:23.728250 11428 net.cpp:122] Setting up Convolution20
I1012 21:57:23.728271 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.728276 11428 net.cpp:137] Memory required for data: 1602339400
I1012 21:57:23.728281 11428 layer_factory.hpp:77] Creating layer BatchNorm16
I1012 21:57:23.728302 11428 net.cpp:84] Creating Layer BatchNorm16
I1012 21:57:23.728307 11428 net.cpp:406] BatchNorm16 <- Convolution20
I1012 21:57:23.728313 11428 net.cpp:367] BatchNorm16 -> Convolution20 (in-place)
I1012 21:57:23.728504 11428 net.cpp:122] Setting up BatchNorm16
I1012 21:57:23.728512 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.728514 11428 net.cpp:137] Memory required for data: 1608611400
I1012 21:57:23.728520 11428 layer_factory.hpp:77] Creating layer Scale16
I1012 21:57:23.728536 11428 net.cpp:84] Creating Layer Scale16
I1012 21:57:23.728540 11428 net.cpp:406] Scale16 <- Convolution20
I1012 21:57:23.728545 11428 net.cpp:367] Scale16 -> Convolution20 (in-place)
I1012 21:57:23.728585 11428 layer_factory.hpp:77] Creating layer Scale16
I1012 21:57:23.728688 11428 net.cpp:122] Setting up Scale16
I1012 21:57:23.728694 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.728708 11428 net.cpp:137] Memory required for data: 1614883400
I1012 21:57:23.728713 11428 layer_factory.hpp:77] Creating layer ReLU16
I1012 21:57:23.728718 11428 net.cpp:84] Creating Layer ReLU16
I1012 21:57:23.728721 11428 net.cpp:406] ReLU16 <- Convolution20
I1012 21:57:23.728739 11428 net.cpp:367] ReLU16 -> Convolution20 (in-place)
I1012 21:57:23.728899 11428 net.cpp:122] Setting up ReLU16
I1012 21:57:23.728905 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.728919 11428 net.cpp:137] Memory required for data: 1621155400
I1012 21:57:23.728922 11428 layer_factory.hpp:77] Creating layer Convolution21
I1012 21:57:23.728940 11428 net.cpp:84] Creating Layer Convolution21
I1012 21:57:23.728945 11428 net.cpp:406] Convolution21 <- Convolution20
I1012 21:57:23.728950 11428 net.cpp:380] Convolution21 -> Convolution21
I1012 21:57:23.812549 11428 net.cpp:122] Setting up Convolution21
I1012 21:57:23.812582 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.812610 11428 net.cpp:137] Memory required for data: 1627427400
I1012 21:57:23.812618 11428 layer_factory.hpp:77] Creating layer Convolution22
I1012 21:57:23.812633 11428 net.cpp:84] Creating Layer Convolution22
I1012 21:57:23.812647 11428 net.cpp:406] Convolution22 <- Eltwise8_Eltwise8_0_split_1
I1012 21:57:23.812654 11428 net.cpp:380] Convolution22 -> Convolution22
I1012 21:57:23.817971 11428 net.cpp:122] Setting up Convolution22
I1012 21:57:23.817993 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.817997 11428 net.cpp:137] Memory required for data: 1633699400
I1012 21:57:23.818002 11428 layer_factory.hpp:77] Creating layer Eltwise9
I1012 21:57:23.818018 11428 net.cpp:84] Creating Layer Eltwise9
I1012 21:57:23.818023 11428 net.cpp:406] Eltwise9 <- Convolution21
I1012 21:57:23.818027 11428 net.cpp:406] Eltwise9 <- Convolution22
I1012 21:57:23.818033 11428 net.cpp:380] Eltwise9 -> Eltwise9
I1012 21:57:23.818063 11428 net.cpp:122] Setting up Eltwise9
I1012 21:57:23.818069 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.818084 11428 net.cpp:137] Memory required for data: 1639971400
I1012 21:57:23.818086 11428 layer_factory.hpp:77] Creating layer BatchNorm17
I1012 21:57:23.818101 11428 net.cpp:84] Creating Layer BatchNorm17
I1012 21:57:23.818105 11428 net.cpp:406] BatchNorm17 <- Eltwise9
I1012 21:57:23.818120 11428 net.cpp:367] BatchNorm17 -> Eltwise9 (in-place)
I1012 21:57:23.818285 11428 net.cpp:122] Setting up BatchNorm17
I1012 21:57:23.818292 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.818305 11428 net.cpp:137] Memory required for data: 1646243400
I1012 21:57:23.818311 11428 layer_factory.hpp:77] Creating layer Scale17
I1012 21:57:23.818328 11428 net.cpp:84] Creating Layer Scale17
I1012 21:57:23.818332 11428 net.cpp:406] Scale17 <- Eltwise9
I1012 21:57:23.818338 11428 net.cpp:367] Scale17 -> Eltwise9 (in-place)
I1012 21:57:23.818377 11428 layer_factory.hpp:77] Creating layer Scale17
I1012 21:57:23.818481 11428 net.cpp:122] Setting up Scale17
I1012 21:57:23.818488 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.818491 11428 net.cpp:137] Memory required for data: 1652515400
I1012 21:57:23.818507 11428 layer_factory.hpp:77] Creating layer ReLU17
I1012 21:57:23.818516 11428 net.cpp:84] Creating Layer ReLU17
I1012 21:57:23.818519 11428 net.cpp:406] ReLU17 <- Eltwise9
I1012 21:57:23.818524 11428 net.cpp:367] ReLU17 -> Eltwise9 (in-place)
I1012 21:57:23.818992 11428 net.cpp:122] Setting up ReLU17
I1012 21:57:23.819002 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.819018 11428 net.cpp:137] Memory required for data: 1658787400
I1012 21:57:23.819022 11428 layer_factory.hpp:77] Creating layer Eltwise9_ReLU17_0_split
I1012 21:57:23.819028 11428 net.cpp:84] Creating Layer Eltwise9_ReLU17_0_split
I1012 21:57:23.819033 11428 net.cpp:406] Eltwise9_ReLU17_0_split <- Eltwise9
I1012 21:57:23.819038 11428 net.cpp:380] Eltwise9_ReLU17_0_split -> Eltwise9_ReLU17_0_split_0
I1012 21:57:23.819046 11428 net.cpp:380] Eltwise9_ReLU17_0_split -> Eltwise9_ReLU17_0_split_1
I1012 21:57:23.819088 11428 net.cpp:122] Setting up Eltwise9_ReLU17_0_split
I1012 21:57:23.819094 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.819099 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.819113 11428 net.cpp:137] Memory required for data: 1671331400
I1012 21:57:23.819118 11428 layer_factory.hpp:77] Creating layer Convolution23
I1012 21:57:23.819124 11428 net.cpp:84] Creating Layer Convolution23
I1012 21:57:23.819129 11428 net.cpp:406] Convolution23 <- Eltwise9_ReLU17_0_split_0
I1012 21:57:23.819135 11428 net.cpp:380] Convolution23 -> Convolution23
I1012 21:57:23.902199 11428 net.cpp:122] Setting up Convolution23
I1012 21:57:23.902225 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.902227 11428 net.cpp:137] Memory required for data: 1677603400
I1012 21:57:23.902235 11428 layer_factory.hpp:77] Creating layer BatchNorm18
I1012 21:57:23.902256 11428 net.cpp:84] Creating Layer BatchNorm18
I1012 21:57:23.902261 11428 net.cpp:406] BatchNorm18 <- Convolution23
I1012 21:57:23.902298 11428 net.cpp:367] BatchNorm18 -> Convolution23 (in-place)
I1012 21:57:23.902463 11428 net.cpp:122] Setting up BatchNorm18
I1012 21:57:23.902470 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.902473 11428 net.cpp:137] Memory required for data: 1683875400
I1012 21:57:23.902479 11428 layer_factory.hpp:77] Creating layer Scale18
I1012 21:57:23.902487 11428 net.cpp:84] Creating Layer Scale18
I1012 21:57:23.902500 11428 net.cpp:406] Scale18 <- Convolution23
I1012 21:57:23.902505 11428 net.cpp:367] Scale18 -> Convolution23 (in-place)
I1012 21:57:23.902567 11428 layer_factory.hpp:77] Creating layer Scale18
I1012 21:57:23.902693 11428 net.cpp:122] Setting up Scale18
I1012 21:57:23.902699 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.902712 11428 net.cpp:137] Memory required for data: 1690147400
I1012 21:57:23.902717 11428 layer_factory.hpp:77] Creating layer ReLU18
I1012 21:57:23.902722 11428 net.cpp:84] Creating Layer ReLU18
I1012 21:57:23.902739 11428 net.cpp:406] ReLU18 <- Convolution23
I1012 21:57:23.902743 11428 net.cpp:367] ReLU18 -> Convolution23 (in-place)
I1012 21:57:23.903342 11428 net.cpp:122] Setting up ReLU18
I1012 21:57:23.903352 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.903354 11428 net.cpp:137] Memory required for data: 1696419400
I1012 21:57:23.903358 11428 layer_factory.hpp:77] Creating layer Convolution24
I1012 21:57:23.903367 11428 net.cpp:84] Creating Layer Convolution24
I1012 21:57:23.903380 11428 net.cpp:406] Convolution24 <- Convolution23
I1012 21:57:23.903388 11428 net.cpp:380] Convolution24 -> Convolution24
I1012 21:57:23.986889 11428 net.cpp:122] Setting up Convolution24
I1012 21:57:23.986912 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.986915 11428 net.cpp:137] Memory required for data: 1702691400
I1012 21:57:23.986922 11428 layer_factory.hpp:77] Creating layer Eltwise10
I1012 21:57:23.986943 11428 net.cpp:84] Creating Layer Eltwise10
I1012 21:57:23.986948 11428 net.cpp:406] Eltwise10 <- Convolution24
I1012 21:57:23.986954 11428 net.cpp:406] Eltwise10 <- Eltwise9_ReLU17_0_split_1
I1012 21:57:23.986960 11428 net.cpp:380] Eltwise10 -> Eltwise10
I1012 21:57:23.986985 11428 net.cpp:122] Setting up Eltwise10
I1012 21:57:23.987000 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.987004 11428 net.cpp:137] Memory required for data: 1708963400
I1012 21:57:23.987016 11428 layer_factory.hpp:77] Creating layer BatchNorm19
I1012 21:57:23.987025 11428 net.cpp:84] Creating Layer BatchNorm19
I1012 21:57:23.987036 11428 net.cpp:406] BatchNorm19 <- Eltwise10
I1012 21:57:23.987040 11428 net.cpp:367] BatchNorm19 -> Eltwise10 (in-place)
I1012 21:57:23.987236 11428 net.cpp:122] Setting up BatchNorm19
I1012 21:57:23.987241 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.987244 11428 net.cpp:137] Memory required for data: 1715235400
I1012 21:57:23.987251 11428 layer_factory.hpp:77] Creating layer Scale19
I1012 21:57:23.987257 11428 net.cpp:84] Creating Layer Scale19
I1012 21:57:23.987270 11428 net.cpp:406] Scale19 <- Eltwise10
I1012 21:57:23.987277 11428 net.cpp:367] Scale19 -> Eltwise10 (in-place)
I1012 21:57:23.987339 11428 layer_factory.hpp:77] Creating layer Scale19
I1012 21:57:23.987481 11428 net.cpp:122] Setting up Scale19
I1012 21:57:23.987488 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.987490 11428 net.cpp:137] Memory required for data: 1721507400
I1012 21:57:23.987495 11428 layer_factory.hpp:77] Creating layer ReLU19
I1012 21:57:23.987500 11428 net.cpp:84] Creating Layer ReLU19
I1012 21:57:23.987504 11428 net.cpp:406] ReLU19 <- Eltwise10
I1012 21:57:23.987519 11428 net.cpp:367] ReLU19 -> Eltwise10 (in-place)
I1012 21:57:23.987671 11428 net.cpp:122] Setting up ReLU19
I1012 21:57:23.987679 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.987699 11428 net.cpp:137] Memory required for data: 1727779400
I1012 21:57:23.987701 11428 layer_factory.hpp:77] Creating layer Eltwise10_ReLU19_0_split
I1012 21:57:23.987741 11428 net.cpp:84] Creating Layer Eltwise10_ReLU19_0_split
I1012 21:57:23.987745 11428 net.cpp:406] Eltwise10_ReLU19_0_split <- Eltwise10
I1012 21:57:23.987751 11428 net.cpp:380] Eltwise10_ReLU19_0_split -> Eltwise10_ReLU19_0_split_0
I1012 21:57:23.987756 11428 net.cpp:380] Eltwise10_ReLU19_0_split -> Eltwise10_ReLU19_0_split_1
I1012 21:57:23.987799 11428 net.cpp:122] Setting up Eltwise10_ReLU19_0_split
I1012 21:57:23.987807 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.987810 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:23.987812 11428 net.cpp:137] Memory required for data: 1740323400
I1012 21:57:23.987815 11428 layer_factory.hpp:77] Creating layer Convolution25
I1012 21:57:23.987823 11428 net.cpp:84] Creating Layer Convolution25
I1012 21:57:23.987838 11428 net.cpp:406] Convolution25 <- Eltwise10_ReLU19_0_split_0
I1012 21:57:23.987843 11428 net.cpp:380] Convolution25 -> Convolution25
I1012 21:57:24.071866 11428 net.cpp:122] Setting up Convolution25
I1012 21:57:24.071902 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.071907 11428 net.cpp:137] Memory required for data: 1746595400
I1012 21:57:24.071913 11428 layer_factory.hpp:77] Creating layer BatchNorm20
I1012 21:57:24.071926 11428 net.cpp:84] Creating Layer BatchNorm20
I1012 21:57:24.071933 11428 net.cpp:406] BatchNorm20 <- Convolution25
I1012 21:57:24.071943 11428 net.cpp:367] BatchNorm20 -> Convolution25 (in-place)
I1012 21:57:24.072149 11428 net.cpp:122] Setting up BatchNorm20
I1012 21:57:24.072158 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.072162 11428 net.cpp:137] Memory required for data: 1752867400
I1012 21:57:24.072170 11428 layer_factory.hpp:77] Creating layer Scale20
I1012 21:57:24.072177 11428 net.cpp:84] Creating Layer Scale20
I1012 21:57:24.072182 11428 net.cpp:406] Scale20 <- Convolution25
I1012 21:57:24.072188 11428 net.cpp:367] Scale20 -> Convolution25 (in-place)
I1012 21:57:24.072227 11428 layer_factory.hpp:77] Creating layer Scale20
I1012 21:57:24.072317 11428 net.cpp:122] Setting up Scale20
I1012 21:57:24.072324 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.072329 11428 net.cpp:137] Memory required for data: 1759139400
I1012 21:57:24.072335 11428 layer_factory.hpp:77] Creating layer ReLU20
I1012 21:57:24.072340 11428 net.cpp:84] Creating Layer ReLU20
I1012 21:57:24.072345 11428 net.cpp:406] ReLU20 <- Convolution25
I1012 21:57:24.072350 11428 net.cpp:367] ReLU20 -> Convolution25 (in-place)
I1012 21:57:24.072487 11428 net.cpp:122] Setting up ReLU20
I1012 21:57:24.072495 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.072500 11428 net.cpp:137] Memory required for data: 1765411400
I1012 21:57:24.072504 11428 layer_factory.hpp:77] Creating layer Convolution26
I1012 21:57:24.072515 11428 net.cpp:84] Creating Layer Convolution26
I1012 21:57:24.072518 11428 net.cpp:406] Convolution26 <- Convolution25
I1012 21:57:24.072525 11428 net.cpp:380] Convolution26 -> Convolution26
I1012 21:57:24.156227 11428 net.cpp:122] Setting up Convolution26
I1012 21:57:24.156250 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.156255 11428 net.cpp:137] Memory required for data: 1771683400
I1012 21:57:24.156262 11428 layer_factory.hpp:77] Creating layer Eltwise11
I1012 21:57:24.156282 11428 net.cpp:84] Creating Layer Eltwise11
I1012 21:57:24.156288 11428 net.cpp:406] Eltwise11 <- Convolution26
I1012 21:57:24.156306 11428 net.cpp:406] Eltwise11 <- Eltwise10_ReLU19_0_split_1
I1012 21:57:24.156312 11428 net.cpp:380] Eltwise11 -> Eltwise11
I1012 21:57:24.156364 11428 net.cpp:122] Setting up Eltwise11
I1012 21:57:24.156380 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.156383 11428 net.cpp:137] Memory required for data: 1777955400
I1012 21:57:24.156397 11428 layer_factory.hpp:77] Creating layer BatchNorm21
I1012 21:57:24.156404 11428 net.cpp:84] Creating Layer BatchNorm21
I1012 21:57:24.156406 11428 net.cpp:406] BatchNorm21 <- Eltwise11
I1012 21:57:24.156411 11428 net.cpp:367] BatchNorm21 -> Eltwise11 (in-place)
I1012 21:57:24.156620 11428 net.cpp:122] Setting up BatchNorm21
I1012 21:57:24.156627 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.156641 11428 net.cpp:137] Memory required for data: 1784227400
I1012 21:57:24.156673 11428 layer_factory.hpp:77] Creating layer Scale21
I1012 21:57:24.156689 11428 net.cpp:84] Creating Layer Scale21
I1012 21:57:24.156702 11428 net.cpp:406] Scale21 <- Eltwise11
I1012 21:57:24.156707 11428 net.cpp:367] Scale21 -> Eltwise11 (in-place)
I1012 21:57:24.156780 11428 layer_factory.hpp:77] Creating layer Scale21
I1012 21:57:24.156918 11428 net.cpp:122] Setting up Scale21
I1012 21:57:24.156924 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.156926 11428 net.cpp:137] Memory required for data: 1790499400
I1012 21:57:24.156931 11428 layer_factory.hpp:77] Creating layer ReLU21
I1012 21:57:24.156937 11428 net.cpp:84] Creating Layer ReLU21
I1012 21:57:24.156940 11428 net.cpp:406] ReLU21 <- Eltwise11
I1012 21:57:24.156955 11428 net.cpp:367] ReLU21 -> Eltwise11 (in-place)
I1012 21:57:24.157116 11428 net.cpp:122] Setting up ReLU21
I1012 21:57:24.157124 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.157127 11428 net.cpp:137] Memory required for data: 1796771400
I1012 21:57:24.157130 11428 layer_factory.hpp:77] Creating layer Eltwise11_ReLU21_0_split
I1012 21:57:24.157135 11428 net.cpp:84] Creating Layer Eltwise11_ReLU21_0_split
I1012 21:57:24.157140 11428 net.cpp:406] Eltwise11_ReLU21_0_split <- Eltwise11
I1012 21:57:24.157155 11428 net.cpp:380] Eltwise11_ReLU21_0_split -> Eltwise11_ReLU21_0_split_0
I1012 21:57:24.157161 11428 net.cpp:380] Eltwise11_ReLU21_0_split -> Eltwise11_ReLU21_0_split_1
I1012 21:57:24.157215 11428 net.cpp:122] Setting up Eltwise11_ReLU21_0_split
I1012 21:57:24.157232 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.157235 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.157250 11428 net.cpp:137] Memory required for data: 1809315400
I1012 21:57:24.157253 11428 layer_factory.hpp:77] Creating layer Convolution27
I1012 21:57:24.157272 11428 net.cpp:84] Creating Layer Convolution27
I1012 21:57:24.157276 11428 net.cpp:406] Convolution27 <- Eltwise11_ReLU21_0_split_0
I1012 21:57:24.157292 11428 net.cpp:380] Convolution27 -> Convolution27
I1012 21:57:24.240977 11428 net.cpp:122] Setting up Convolution27
I1012 21:57:24.241000 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.241004 11428 net.cpp:137] Memory required for data: 1815587400
I1012 21:57:24.241013 11428 layer_factory.hpp:77] Creating layer BatchNorm22
I1012 21:57:24.241024 11428 net.cpp:84] Creating Layer BatchNorm22
I1012 21:57:24.241040 11428 net.cpp:406] BatchNorm22 <- Convolution27
I1012 21:57:24.241046 11428 net.cpp:367] BatchNorm22 -> Convolution27 (in-place)
I1012 21:57:24.241225 11428 net.cpp:122] Setting up BatchNorm22
I1012 21:57:24.241232 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.241235 11428 net.cpp:137] Memory required for data: 1821859400
I1012 21:57:24.241242 11428 layer_factory.hpp:77] Creating layer Scale22
I1012 21:57:24.241250 11428 net.cpp:84] Creating Layer Scale22
I1012 21:57:24.241252 11428 net.cpp:406] Scale22 <- Convolution27
I1012 21:57:24.241267 11428 net.cpp:367] Scale22 -> Convolution27 (in-place)
I1012 21:57:24.241313 11428 layer_factory.hpp:77] Creating layer Scale22
I1012 21:57:24.241421 11428 net.cpp:122] Setting up Scale22
I1012 21:57:24.241428 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.241432 11428 net.cpp:137] Memory required for data: 1828131400
I1012 21:57:24.241447 11428 layer_factory.hpp:77] Creating layer ReLU22
I1012 21:57:24.241453 11428 net.cpp:84] Creating Layer ReLU22
I1012 21:57:24.241458 11428 net.cpp:406] ReLU22 <- Convolution27
I1012 21:57:24.241463 11428 net.cpp:367] ReLU22 -> Convolution27 (in-place)
I1012 21:57:24.241600 11428 net.cpp:122] Setting up ReLU22
I1012 21:57:24.241608 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.241612 11428 net.cpp:137] Memory required for data: 1834403400
I1012 21:57:24.241626 11428 layer_factory.hpp:77] Creating layer Convolution28
I1012 21:57:24.241647 11428 net.cpp:84] Creating Layer Convolution28
I1012 21:57:24.241652 11428 net.cpp:406] Convolution28 <- Convolution27
I1012 21:57:24.241658 11428 net.cpp:380] Convolution28 -> Convolution28
I1012 21:57:24.325290 11428 net.cpp:122] Setting up Convolution28
I1012 21:57:24.325314 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.325318 11428 net.cpp:137] Memory required for data: 1840675400
I1012 21:57:24.325327 11428 layer_factory.hpp:77] Creating layer Eltwise12
I1012 21:57:24.325350 11428 net.cpp:84] Creating Layer Eltwise12
I1012 21:57:24.325356 11428 net.cpp:406] Eltwise12 <- Convolution28
I1012 21:57:24.325364 11428 net.cpp:406] Eltwise12 <- Eltwise11_ReLU21_0_split_1
I1012 21:57:24.325371 11428 net.cpp:380] Eltwise12 -> Eltwise12
I1012 21:57:24.325410 11428 net.cpp:122] Setting up Eltwise12
I1012 21:57:24.325417 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.325419 11428 net.cpp:137] Memory required for data: 1846947400
I1012 21:57:24.325423 11428 layer_factory.hpp:77] Creating layer Pooling1
I1012 21:57:24.325429 11428 net.cpp:84] Creating Layer Pooling1
I1012 21:57:24.325433 11428 net.cpp:406] Pooling1 <- Eltwise12
I1012 21:57:24.325438 11428 net.cpp:380] Pooling1 -> Pooling1
I1012 21:57:24.326023 11428 net.cpp:122] Setting up Pooling1
I1012 21:57:24.326035 11428 net.cpp:129] Top shape: 50 640 1 1 (32000)
I1012 21:57:24.326038 11428 net.cpp:137] Memory required for data: 1847075400
I1012 21:57:24.326052 11428 layer_factory.hpp:77] Creating layer InnerProduct1
I1012 21:57:24.326064 11428 net.cpp:84] Creating Layer InnerProduct1
I1012 21:57:24.326069 11428 net.cpp:406] InnerProduct1 <- Pooling1
I1012 21:57:24.326074 11428 net.cpp:380] InnerProduct1 -> InnerProduct1
I1012 21:57:24.326248 11428 net.cpp:122] Setting up InnerProduct1
I1012 21:57:24.326256 11428 net.cpp:129] Top shape: 50 100 (5000)
I1012 21:57:24.326259 11428 net.cpp:137] Memory required for data: 1847095400
I1012 21:57:24.326274 11428 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1012 21:57:24.326282 11428 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1012 21:57:24.326287 11428 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1012 21:57:24.326292 11428 net.cpp:406] SoftmaxWithLoss1 <- label
I1012 21:57:24.326297 11428 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1012 21:57:24.326305 11428 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1012 21:57:24.327086 11428 net.cpp:122] Setting up SoftmaxWithLoss1
I1012 21:57:24.327097 11428 net.cpp:129] Top shape: (1)
I1012 21:57:24.327111 11428 net.cpp:132]     with loss weight 1
I1012 21:57:24.327126 11428 net.cpp:137] Memory required for data: 1847095404
I1012 21:57:24.327129 11428 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1012 21:57:24.327134 11428 net.cpp:198] InnerProduct1 needs backward computation.
I1012 21:57:24.327137 11428 net.cpp:198] Pooling1 needs backward computation.
I1012 21:57:24.327142 11428 net.cpp:198] Eltwise12 needs backward computation.
I1012 21:57:24.327145 11428 net.cpp:198] Convolution28 needs backward computation.
I1012 21:57:24.327149 11428 net.cpp:198] ReLU22 needs backward computation.
I1012 21:57:24.327162 11428 net.cpp:198] Scale22 needs backward computation.
I1012 21:57:24.327167 11428 net.cpp:198] BatchNorm22 needs backward computation.
I1012 21:57:24.327170 11428 net.cpp:198] Convolution27 needs backward computation.
I1012 21:57:24.327175 11428 net.cpp:198] Eltwise11_ReLU21_0_split needs backward computation.
I1012 21:57:24.327179 11428 net.cpp:198] ReLU21 needs backward computation.
I1012 21:57:24.327193 11428 net.cpp:198] Scale21 needs backward computation.
I1012 21:57:24.327195 11428 net.cpp:198] BatchNorm21 needs backward computation.
I1012 21:57:24.327199 11428 net.cpp:198] Eltwise11 needs backward computation.
I1012 21:57:24.327214 11428 net.cpp:198] Convolution26 needs backward computation.
I1012 21:57:24.327217 11428 net.cpp:198] ReLU20 needs backward computation.
I1012 21:57:24.327221 11428 net.cpp:198] Scale20 needs backward computation.
I1012 21:57:24.327245 11428 net.cpp:198] BatchNorm20 needs backward computation.
I1012 21:57:24.327250 11428 net.cpp:198] Convolution25 needs backward computation.
I1012 21:57:24.327253 11428 net.cpp:198] Eltwise10_ReLU19_0_split needs backward computation.
I1012 21:57:24.327270 11428 net.cpp:198] ReLU19 needs backward computation.
I1012 21:57:24.327273 11428 net.cpp:198] Scale19 needs backward computation.
I1012 21:57:24.327287 11428 net.cpp:198] BatchNorm19 needs backward computation.
I1012 21:57:24.327291 11428 net.cpp:198] Eltwise10 needs backward computation.
I1012 21:57:24.327306 11428 net.cpp:198] Convolution24 needs backward computation.
I1012 21:57:24.327311 11428 net.cpp:198] ReLU18 needs backward computation.
I1012 21:57:24.327314 11428 net.cpp:198] Scale18 needs backward computation.
I1012 21:57:24.327318 11428 net.cpp:198] BatchNorm18 needs backward computation.
I1012 21:57:24.327322 11428 net.cpp:198] Convolution23 needs backward computation.
I1012 21:57:24.327327 11428 net.cpp:198] Eltwise9_ReLU17_0_split needs backward computation.
I1012 21:57:24.327330 11428 net.cpp:198] ReLU17 needs backward computation.
I1012 21:57:24.327334 11428 net.cpp:198] Scale17 needs backward computation.
I1012 21:57:24.327338 11428 net.cpp:198] BatchNorm17 needs backward computation.
I1012 21:57:24.327342 11428 net.cpp:198] Eltwise9 needs backward computation.
I1012 21:57:24.327347 11428 net.cpp:198] Convolution22 needs backward computation.
I1012 21:57:24.327352 11428 net.cpp:198] Convolution21 needs backward computation.
I1012 21:57:24.327355 11428 net.cpp:198] ReLU16 needs backward computation.
I1012 21:57:24.327359 11428 net.cpp:198] Scale16 needs backward computation.
I1012 21:57:24.327363 11428 net.cpp:198] BatchNorm16 needs backward computation.
I1012 21:57:24.327366 11428 net.cpp:198] Convolution20 needs backward computation.
I1012 21:57:24.327373 11428 net.cpp:198] Eltwise8_Eltwise8_0_split needs backward computation.
I1012 21:57:24.327376 11428 net.cpp:198] Eltwise8 needs backward computation.
I1012 21:57:24.327381 11428 net.cpp:198] Convolution19 needs backward computation.
I1012 21:57:24.327385 11428 net.cpp:198] ReLU15 needs backward computation.
I1012 21:57:24.327389 11428 net.cpp:198] Scale15 needs backward computation.
I1012 21:57:24.327394 11428 net.cpp:198] BatchNorm15 needs backward computation.
I1012 21:57:24.327396 11428 net.cpp:198] Convolution18 needs backward computation.
I1012 21:57:24.327401 11428 net.cpp:198] Eltwise7_ReLU14_0_split needs backward computation.
I1012 21:57:24.327405 11428 net.cpp:198] ReLU14 needs backward computation.
I1012 21:57:24.327409 11428 net.cpp:198] Scale14 needs backward computation.
I1012 21:57:24.327414 11428 net.cpp:198] BatchNorm14 needs backward computation.
I1012 21:57:24.327417 11428 net.cpp:198] Eltwise7 needs backward computation.
I1012 21:57:24.327421 11428 net.cpp:198] Convolution17 needs backward computation.
I1012 21:57:24.327425 11428 net.cpp:198] ReLU13 needs backward computation.
I1012 21:57:24.327430 11428 net.cpp:198] Scale13 needs backward computation.
I1012 21:57:24.327433 11428 net.cpp:198] BatchNorm13 needs backward computation.
I1012 21:57:24.327437 11428 net.cpp:198] Convolution16 needs backward computation.
I1012 21:57:24.327441 11428 net.cpp:198] Eltwise6_ReLU12_0_split needs backward computation.
I1012 21:57:24.327446 11428 net.cpp:198] ReLU12 needs backward computation.
I1012 21:57:24.327450 11428 net.cpp:198] Scale12 needs backward computation.
I1012 21:57:24.327453 11428 net.cpp:198] BatchNorm12 needs backward computation.
I1012 21:57:24.327457 11428 net.cpp:198] Eltwise6 needs backward computation.
I1012 21:57:24.327462 11428 net.cpp:198] Convolution15 needs backward computation.
I1012 21:57:24.327466 11428 net.cpp:198] ReLU11 needs backward computation.
I1012 21:57:24.327471 11428 net.cpp:198] Scale11 needs backward computation.
I1012 21:57:24.327474 11428 net.cpp:198] BatchNorm11 needs backward computation.
I1012 21:57:24.327478 11428 net.cpp:198] Convolution14 needs backward computation.
I1012 21:57:24.327482 11428 net.cpp:198] Eltwise5_ReLU10_0_split needs backward computation.
I1012 21:57:24.327491 11428 net.cpp:198] ReLU10 needs backward computation.
I1012 21:57:24.327495 11428 net.cpp:198] Scale10 needs backward computation.
I1012 21:57:24.327498 11428 net.cpp:198] BatchNorm10 needs backward computation.
I1012 21:57:24.327502 11428 net.cpp:198] Eltwise5 needs backward computation.
I1012 21:57:24.327507 11428 net.cpp:198] Convolution13 needs backward computation.
I1012 21:57:24.327512 11428 net.cpp:198] Convolution12 needs backward computation.
I1012 21:57:24.327515 11428 net.cpp:198] ReLU9 needs backward computation.
I1012 21:57:24.327519 11428 net.cpp:198] Scale9 needs backward computation.
I1012 21:57:24.327523 11428 net.cpp:198] BatchNorm9 needs backward computation.
I1012 21:57:24.327527 11428 net.cpp:198] Convolution11 needs backward computation.
I1012 21:57:24.327531 11428 net.cpp:198] Eltwise4_Eltwise4_0_split needs backward computation.
I1012 21:57:24.327535 11428 net.cpp:198] Eltwise4 needs backward computation.
I1012 21:57:24.327539 11428 net.cpp:198] Convolution10 needs backward computation.
I1012 21:57:24.327544 11428 net.cpp:198] ReLU8 needs backward computation.
I1012 21:57:24.327548 11428 net.cpp:198] Scale8 needs backward computation.
I1012 21:57:24.327553 11428 net.cpp:198] BatchNorm8 needs backward computation.
I1012 21:57:24.327556 11428 net.cpp:198] Convolution9 needs backward computation.
I1012 21:57:24.327560 11428 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1012 21:57:24.327564 11428 net.cpp:198] ReLU7 needs backward computation.
I1012 21:57:24.327569 11428 net.cpp:198] Scale7 needs backward computation.
I1012 21:57:24.327572 11428 net.cpp:198] BatchNorm7 needs backward computation.
I1012 21:57:24.327576 11428 net.cpp:198] Eltwise3 needs backward computation.
I1012 21:57:24.327580 11428 net.cpp:198] Convolution8 needs backward computation.
I1012 21:57:24.327584 11428 net.cpp:198] ReLU6 needs backward computation.
I1012 21:57:24.327589 11428 net.cpp:198] Scale6 needs backward computation.
I1012 21:57:24.327592 11428 net.cpp:198] BatchNorm6 needs backward computation.
I1012 21:57:24.327596 11428 net.cpp:198] Convolution7 needs backward computation.
I1012 21:57:24.327600 11428 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1012 21:57:24.327605 11428 net.cpp:198] ReLU5 needs backward computation.
I1012 21:57:24.327608 11428 net.cpp:198] Scale5 needs backward computation.
I1012 21:57:24.327612 11428 net.cpp:198] BatchNorm5 needs backward computation.
I1012 21:57:24.327616 11428 net.cpp:198] Eltwise2 needs backward computation.
I1012 21:57:24.327621 11428 net.cpp:198] Convolution6 needs backward computation.
I1012 21:57:24.327626 11428 net.cpp:198] ReLU4 needs backward computation.
I1012 21:57:24.327630 11428 net.cpp:198] Scale4 needs backward computation.
I1012 21:57:24.327635 11428 net.cpp:198] BatchNorm4 needs backward computation.
I1012 21:57:24.327638 11428 net.cpp:198] Convolution5 needs backward computation.
I1012 21:57:24.327642 11428 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1012 21:57:24.327646 11428 net.cpp:198] ReLU3 needs backward computation.
I1012 21:57:24.327651 11428 net.cpp:198] Scale3 needs backward computation.
I1012 21:57:24.327654 11428 net.cpp:198] BatchNorm3 needs backward computation.
I1012 21:57:24.327658 11428 net.cpp:198] Eltwise1 needs backward computation.
I1012 21:57:24.327662 11428 net.cpp:198] Convolution4 needs backward computation.
I1012 21:57:24.327667 11428 net.cpp:198] Convolution3 needs backward computation.
I1012 21:57:24.327672 11428 net.cpp:198] ReLU2 needs backward computation.
I1012 21:57:24.327675 11428 net.cpp:198] Scale2 needs backward computation.
I1012 21:57:24.327679 11428 net.cpp:198] BatchNorm2 needs backward computation.
I1012 21:57:24.327682 11428 net.cpp:198] Convolution2 needs backward computation.
I1012 21:57:24.327687 11428 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1012 21:57:24.327692 11428 net.cpp:198] ReLU1 needs backward computation.
I1012 21:57:24.327695 11428 net.cpp:198] Scale1 needs backward computation.
I1012 21:57:24.327703 11428 net.cpp:198] BatchNorm1 needs backward computation.
I1012 21:57:24.327708 11428 net.cpp:198] Convolution1 needs backward computation.
I1012 21:57:24.327713 11428 net.cpp:200] cifar does not need backward computation.
I1012 21:57:24.327716 11428 net.cpp:242] This network produces output SoftmaxWithLoss1
I1012 21:57:24.327764 11428 net.cpp:255] Network initialization done.
I1012 21:57:24.329179 11428 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_relu_msra.prototxt
I1012 21:57:24.329190 11428 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1012 21:57:24.329195 11428 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_relu_msra.prototxt
I1012 21:57:24.329273 11428 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1012 21:57:24.329617 11428 net.cpp:51] Initializing net from parameters: 
name: "wrn_28_10"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar100/cifar100_test_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution4"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution4"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Eltwise1"
  top: "Eltwise1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution5"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution5"
  top: "Convolution5"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution5"
  top: "Convolution6"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution6"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Eltwise2"
  top: "Eltwise2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution7"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution7"
  top: "Convolution8"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Eltwise3"
  top: "Eltwise3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution13"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Eltwise5"
  top: "Eltwise5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Eltwise6"
  top: "Eltwise6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Eltwise7"
  top: "Eltwise7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution22"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution21"
  bottom: "Convolution22"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Eltwise9"
  top: "Eltwise9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution24"
  bottom: "Eltwise9"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Eltwise10"
  top: "Eltwise10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution25"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution26"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Eltwise11"
  top: "Eltwise11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution27"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution28"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise12"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 100
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I1012 21:57:24.329901 11428 layer_factory.hpp:77] Creating layer cifar
I1012 21:57:24.329953 11428 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar100/cifar100_test_lmdb
I1012 21:57:24.329965 11428 net.cpp:84] Creating Layer cifar
I1012 21:57:24.329972 11428 net.cpp:380] cifar -> data
I1012 21:57:24.329978 11428 net.cpp:380] cifar -> label
I1012 21:57:24.329985 11428 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto
I1012 21:57:24.330116 11428 data_layer.cpp:45] output data size: 50,3,28,28
I1012 21:57:24.331307 11428 net.cpp:122] Setting up cifar
I1012 21:57:24.331316 11428 net.cpp:129] Top shape: 50 3 28 28 (117600)
I1012 21:57:24.331321 11428 net.cpp:129] Top shape: 50 (50)
I1012 21:57:24.331324 11428 net.cpp:137] Memory required for data: 470600
I1012 21:57:24.331327 11428 layer_factory.hpp:77] Creating layer label_cifar_1_split
I1012 21:57:24.331333 11428 net.cpp:84] Creating Layer label_cifar_1_split
I1012 21:57:24.331337 11428 net.cpp:406] label_cifar_1_split <- label
I1012 21:57:24.331342 11428 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1012 21:57:24.331348 11428 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1012 21:57:24.331413 11428 net.cpp:122] Setting up label_cifar_1_split
I1012 21:57:24.331419 11428 net.cpp:129] Top shape: 50 (50)
I1012 21:57:24.331423 11428 net.cpp:129] Top shape: 50 (50)
I1012 21:57:24.331426 11428 net.cpp:137] Memory required for data: 471000
I1012 21:57:24.331429 11428 layer_factory.hpp:77] Creating layer Convolution1
I1012 21:57:24.331439 11428 net.cpp:84] Creating Layer Convolution1
I1012 21:57:24.331442 11428 net.cpp:406] Convolution1 <- data
I1012 21:57:24.331446 11428 net.cpp:380] Convolution1 -> Convolution1
I1012 21:57:24.332569 11428 net.cpp:122] Setting up Convolution1
I1012 21:57:24.332579 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:24.332582 11428 net.cpp:137] Memory required for data: 2979800
I1012 21:57:24.332592 11428 layer_factory.hpp:77] Creating layer BatchNorm1
I1012 21:57:24.332599 11428 net.cpp:84] Creating Layer BatchNorm1
I1012 21:57:24.332602 11428 net.cpp:406] BatchNorm1 <- Convolution1
I1012 21:57:24.332607 11428 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1012 21:57:24.332773 11428 net.cpp:122] Setting up BatchNorm1
I1012 21:57:24.332780 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:24.332790 11428 net.cpp:137] Memory required for data: 5488600
I1012 21:57:24.332799 11428 layer_factory.hpp:77] Creating layer Scale1
I1012 21:57:24.332805 11428 net.cpp:84] Creating Layer Scale1
I1012 21:57:24.332810 11428 net.cpp:406] Scale1 <- Convolution1
I1012 21:57:24.332814 11428 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1012 21:57:24.332849 11428 layer_factory.hpp:77] Creating layer Scale1
I1012 21:57:24.332948 11428 net.cpp:122] Setting up Scale1
I1012 21:57:24.332955 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:24.332958 11428 net.cpp:137] Memory required for data: 7997400
I1012 21:57:24.332963 11428 layer_factory.hpp:77] Creating layer ReLU1
I1012 21:57:24.332969 11428 net.cpp:84] Creating Layer ReLU1
I1012 21:57:24.332973 11428 net.cpp:406] ReLU1 <- Convolution1
I1012 21:57:24.332978 11428 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1012 21:57:24.333173 11428 net.cpp:122] Setting up ReLU1
I1012 21:57:24.333181 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:24.333184 11428 net.cpp:137] Memory required for data: 10506200
I1012 21:57:24.333189 11428 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1012 21:57:24.333194 11428 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1012 21:57:24.333197 11428 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1012 21:57:24.333201 11428 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1012 21:57:24.333207 11428 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1012 21:57:24.333240 11428 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1012 21:57:24.333245 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:24.333250 11428 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1012 21:57:24.333253 11428 net.cpp:137] Memory required for data: 15523800
I1012 21:57:24.333256 11428 layer_factory.hpp:77] Creating layer Convolution2
I1012 21:57:24.333268 11428 net.cpp:84] Creating Layer Convolution2
I1012 21:57:24.333272 11428 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1012 21:57:24.333278 11428 net.cpp:380] Convolution2 -> Convolution2
I1012 21:57:24.334825 11428 net.cpp:122] Setting up Convolution2
I1012 21:57:24.334834 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.334838 11428 net.cpp:137] Memory required for data: 40611800
I1012 21:57:24.334843 11428 layer_factory.hpp:77] Creating layer BatchNorm2
I1012 21:57:24.334851 11428 net.cpp:84] Creating Layer BatchNorm2
I1012 21:57:24.334856 11428 net.cpp:406] BatchNorm2 <- Convolution2
I1012 21:57:24.334861 11428 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1012 21:57:24.335021 11428 net.cpp:122] Setting up BatchNorm2
I1012 21:57:24.335027 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.335031 11428 net.cpp:137] Memory required for data: 65699800
I1012 21:57:24.335041 11428 layer_factory.hpp:77] Creating layer Scale2
I1012 21:57:24.335047 11428 net.cpp:84] Creating Layer Scale2
I1012 21:57:24.335050 11428 net.cpp:406] Scale2 <- Convolution2
I1012 21:57:24.335054 11428 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1012 21:57:24.335089 11428 layer_factory.hpp:77] Creating layer Scale2
I1012 21:57:24.335182 11428 net.cpp:122] Setting up Scale2
I1012 21:57:24.335187 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.335194 11428 net.cpp:137] Memory required for data: 90787800
I1012 21:57:24.335199 11428 layer_factory.hpp:77] Creating layer ReLU2
I1012 21:57:24.335204 11428 net.cpp:84] Creating Layer ReLU2
I1012 21:57:24.335207 11428 net.cpp:406] ReLU2 <- Convolution2
I1012 21:57:24.335216 11428 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1012 21:57:24.335382 11428 net.cpp:122] Setting up ReLU2
I1012 21:57:24.335389 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.335393 11428 net.cpp:137] Memory required for data: 115875800
I1012 21:57:24.335397 11428 layer_factory.hpp:77] Creating layer Convolution3
I1012 21:57:24.335403 11428 net.cpp:84] Creating Layer Convolution3
I1012 21:57:24.335413 11428 net.cpp:406] Convolution3 <- Convolution2
I1012 21:57:24.335418 11428 net.cpp:380] Convolution3 -> Convolution3
I1012 21:57:24.342625 11428 net.cpp:122] Setting up Convolution3
I1012 21:57:24.342636 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.342639 11428 net.cpp:137] Memory required for data: 140963800
I1012 21:57:24.342644 11428 layer_factory.hpp:77] Creating layer Convolution4
I1012 21:57:24.342653 11428 net.cpp:84] Creating Layer Convolution4
I1012 21:57:24.342658 11428 net.cpp:406] Convolution4 <- Convolution1_ReLU1_0_split_1
I1012 21:57:24.342664 11428 net.cpp:380] Convolution4 -> Convolution4
I1012 21:57:24.343596 11428 net.cpp:122] Setting up Convolution4
I1012 21:57:24.343605 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.343608 11428 net.cpp:137] Memory required for data: 166051800
I1012 21:57:24.343613 11428 layer_factory.hpp:77] Creating layer Eltwise1
I1012 21:57:24.343618 11428 net.cpp:84] Creating Layer Eltwise1
I1012 21:57:24.343622 11428 net.cpp:406] Eltwise1 <- Convolution3
I1012 21:57:24.343627 11428 net.cpp:406] Eltwise1 <- Convolution4
I1012 21:57:24.343631 11428 net.cpp:380] Eltwise1 -> Eltwise1
I1012 21:57:24.343652 11428 net.cpp:122] Setting up Eltwise1
I1012 21:57:24.343657 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.343660 11428 net.cpp:137] Memory required for data: 191139800
I1012 21:57:24.343663 11428 layer_factory.hpp:77] Creating layer BatchNorm3
I1012 21:57:24.343669 11428 net.cpp:84] Creating Layer BatchNorm3
I1012 21:57:24.343672 11428 net.cpp:406] BatchNorm3 <- Eltwise1
I1012 21:57:24.343677 11428 net.cpp:367] BatchNorm3 -> Eltwise1 (in-place)
I1012 21:57:24.343828 11428 net.cpp:122] Setting up BatchNorm3
I1012 21:57:24.343833 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.343837 11428 net.cpp:137] Memory required for data: 216227800
I1012 21:57:24.343844 11428 layer_factory.hpp:77] Creating layer Scale3
I1012 21:57:24.343850 11428 net.cpp:84] Creating Layer Scale3
I1012 21:57:24.343853 11428 net.cpp:406] Scale3 <- Eltwise1
I1012 21:57:24.343858 11428 net.cpp:367] Scale3 -> Eltwise1 (in-place)
I1012 21:57:24.343890 11428 layer_factory.hpp:77] Creating layer Scale3
I1012 21:57:24.343979 11428 net.cpp:122] Setting up Scale3
I1012 21:57:24.343986 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.343987 11428 net.cpp:137] Memory required for data: 241315800
I1012 21:57:24.343992 11428 layer_factory.hpp:77] Creating layer ReLU3
I1012 21:57:24.343998 11428 net.cpp:84] Creating Layer ReLU3
I1012 21:57:24.344002 11428 net.cpp:406] ReLU3 <- Eltwise1
I1012 21:57:24.344005 11428 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1012 21:57:24.344130 11428 net.cpp:122] Setting up ReLU3
I1012 21:57:24.344136 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.344139 11428 net.cpp:137] Memory required for data: 266403800
I1012 21:57:24.344142 11428 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1012 21:57:24.344147 11428 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1012 21:57:24.344151 11428 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1012 21:57:24.344154 11428 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1012 21:57:24.344161 11428 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1012 21:57:24.344192 11428 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1012 21:57:24.344197 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.344199 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.344202 11428 net.cpp:137] Memory required for data: 316579800
I1012 21:57:24.344205 11428 layer_factory.hpp:77] Creating layer Convolution5
I1012 21:57:24.344211 11428 net.cpp:84] Creating Layer Convolution5
I1012 21:57:24.344215 11428 net.cpp:406] Convolution5 <- Eltwise1_ReLU3_0_split_0
I1012 21:57:24.344220 11428 net.cpp:380] Convolution5 -> Convolution5
I1012 21:57:24.350829 11428 net.cpp:122] Setting up Convolution5
I1012 21:57:24.350838 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.350850 11428 net.cpp:137] Memory required for data: 341667800
I1012 21:57:24.350855 11428 layer_factory.hpp:77] Creating layer BatchNorm4
I1012 21:57:24.350862 11428 net.cpp:84] Creating Layer BatchNorm4
I1012 21:57:24.350865 11428 net.cpp:406] BatchNorm4 <- Convolution5
I1012 21:57:24.350870 11428 net.cpp:367] BatchNorm4 -> Convolution5 (in-place)
I1012 21:57:24.351032 11428 net.cpp:122] Setting up BatchNorm4
I1012 21:57:24.351038 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.351042 11428 net.cpp:137] Memory required for data: 366755800
I1012 21:57:24.351047 11428 layer_factory.hpp:77] Creating layer Scale4
I1012 21:57:24.351052 11428 net.cpp:84] Creating Layer Scale4
I1012 21:57:24.351055 11428 net.cpp:406] Scale4 <- Convolution5
I1012 21:57:24.351059 11428 net.cpp:367] Scale4 -> Convolution5 (in-place)
I1012 21:57:24.351092 11428 layer_factory.hpp:77] Creating layer Scale4
I1012 21:57:24.351184 11428 net.cpp:122] Setting up Scale4
I1012 21:57:24.351189 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.351192 11428 net.cpp:137] Memory required for data: 391843800
I1012 21:57:24.351197 11428 layer_factory.hpp:77] Creating layer ReLU4
I1012 21:57:24.351203 11428 net.cpp:84] Creating Layer ReLU4
I1012 21:57:24.351207 11428 net.cpp:406] ReLU4 <- Convolution5
I1012 21:57:24.351210 11428 net.cpp:367] ReLU4 -> Convolution5 (in-place)
I1012 21:57:24.351339 11428 net.cpp:122] Setting up ReLU4
I1012 21:57:24.351347 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.351351 11428 net.cpp:137] Memory required for data: 416931800
I1012 21:57:24.351353 11428 layer_factory.hpp:77] Creating layer Convolution6
I1012 21:57:24.351359 11428 net.cpp:84] Creating Layer Convolution6
I1012 21:57:24.351362 11428 net.cpp:406] Convolution6 <- Convolution5
I1012 21:57:24.351368 11428 net.cpp:380] Convolution6 -> Convolution6
I1012 21:57:24.358558 11428 net.cpp:122] Setting up Convolution6
I1012 21:57:24.358579 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.358583 11428 net.cpp:137] Memory required for data: 442019800
I1012 21:57:24.358589 11428 layer_factory.hpp:77] Creating layer Eltwise2
I1012 21:57:24.358599 11428 net.cpp:84] Creating Layer Eltwise2
I1012 21:57:24.358604 11428 net.cpp:406] Eltwise2 <- Convolution6
I1012 21:57:24.358608 11428 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1012 21:57:24.358615 11428 net.cpp:380] Eltwise2 -> Eltwise2
I1012 21:57:24.358654 11428 net.cpp:122] Setting up Eltwise2
I1012 21:57:24.358659 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.358674 11428 net.cpp:137] Memory required for data: 467107800
I1012 21:57:24.358676 11428 layer_factory.hpp:77] Creating layer BatchNorm5
I1012 21:57:24.358683 11428 net.cpp:84] Creating Layer BatchNorm5
I1012 21:57:24.358690 11428 net.cpp:406] BatchNorm5 <- Eltwise2
I1012 21:57:24.358696 11428 net.cpp:367] BatchNorm5 -> Eltwise2 (in-place)
I1012 21:57:24.358860 11428 net.cpp:122] Setting up BatchNorm5
I1012 21:57:24.358867 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.358872 11428 net.cpp:137] Memory required for data: 492195800
I1012 21:57:24.358881 11428 layer_factory.hpp:77] Creating layer Scale5
I1012 21:57:24.358891 11428 net.cpp:84] Creating Layer Scale5
I1012 21:57:24.358896 11428 net.cpp:406] Scale5 <- Eltwise2
I1012 21:57:24.358901 11428 net.cpp:367] Scale5 -> Eltwise2 (in-place)
I1012 21:57:24.358938 11428 layer_factory.hpp:77] Creating layer Scale5
I1012 21:57:24.359036 11428 net.cpp:122] Setting up Scale5
I1012 21:57:24.359043 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.359047 11428 net.cpp:137] Memory required for data: 517283800
I1012 21:57:24.359055 11428 layer_factory.hpp:77] Creating layer ReLU5
I1012 21:57:24.359063 11428 net.cpp:84] Creating Layer ReLU5
I1012 21:57:24.359068 11428 net.cpp:406] ReLU5 <- Eltwise2
I1012 21:57:24.359074 11428 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1012 21:57:24.359560 11428 net.cpp:122] Setting up ReLU5
I1012 21:57:24.359572 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.359586 11428 net.cpp:137] Memory required for data: 542371800
I1012 21:57:24.359591 11428 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1012 21:57:24.359599 11428 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1012 21:57:24.359604 11428 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1012 21:57:24.359611 11428 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1012 21:57:24.359621 11428 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1012 21:57:24.359658 11428 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1012 21:57:24.359666 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.359671 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.359676 11428 net.cpp:137] Memory required for data: 592547800
I1012 21:57:24.359681 11428 layer_factory.hpp:77] Creating layer Convolution7
I1012 21:57:24.359693 11428 net.cpp:84] Creating Layer Convolution7
I1012 21:57:24.359696 11428 net.cpp:406] Convolution7 <- Eltwise2_ReLU5_0_split_0
I1012 21:57:24.359705 11428 net.cpp:380] Convolution7 -> Convolution7
I1012 21:57:24.365664 11428 net.cpp:122] Setting up Convolution7
I1012 21:57:24.365674 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.365676 11428 net.cpp:137] Memory required for data: 617635800
I1012 21:57:24.365686 11428 layer_factory.hpp:77] Creating layer BatchNorm6
I1012 21:57:24.365692 11428 net.cpp:84] Creating Layer BatchNorm6
I1012 21:57:24.365696 11428 net.cpp:406] BatchNorm6 <- Convolution7
I1012 21:57:24.365701 11428 net.cpp:367] BatchNorm6 -> Convolution7 (in-place)
I1012 21:57:24.365866 11428 net.cpp:122] Setting up BatchNorm6
I1012 21:57:24.365871 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.365875 11428 net.cpp:137] Memory required for data: 642723800
I1012 21:57:24.365880 11428 layer_factory.hpp:77] Creating layer Scale6
I1012 21:57:24.365885 11428 net.cpp:84] Creating Layer Scale6
I1012 21:57:24.365890 11428 net.cpp:406] Scale6 <- Convolution7
I1012 21:57:24.365895 11428 net.cpp:367] Scale6 -> Convolution7 (in-place)
I1012 21:57:24.365942 11428 layer_factory.hpp:77] Creating layer Scale6
I1012 21:57:24.366048 11428 net.cpp:122] Setting up Scale6
I1012 21:57:24.366053 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.366056 11428 net.cpp:137] Memory required for data: 667811800
I1012 21:57:24.366061 11428 layer_factory.hpp:77] Creating layer ReLU6
I1012 21:57:24.366066 11428 net.cpp:84] Creating Layer ReLU6
I1012 21:57:24.366070 11428 net.cpp:406] ReLU6 <- Convolution7
I1012 21:57:24.366075 11428 net.cpp:367] ReLU6 -> Convolution7 (in-place)
I1012 21:57:24.366550 11428 net.cpp:122] Setting up ReLU6
I1012 21:57:24.366559 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.366562 11428 net.cpp:137] Memory required for data: 692899800
I1012 21:57:24.366565 11428 layer_factory.hpp:77] Creating layer Convolution8
I1012 21:57:24.366575 11428 net.cpp:84] Creating Layer Convolution8
I1012 21:57:24.366580 11428 net.cpp:406] Convolution8 <- Convolution7
I1012 21:57:24.366585 11428 net.cpp:380] Convolution8 -> Convolution8
I1012 21:57:24.373486 11428 net.cpp:122] Setting up Convolution8
I1012 21:57:24.373495 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.373498 11428 net.cpp:137] Memory required for data: 717987800
I1012 21:57:24.373503 11428 layer_factory.hpp:77] Creating layer Eltwise3
I1012 21:57:24.373509 11428 net.cpp:84] Creating Layer Eltwise3
I1012 21:57:24.373513 11428 net.cpp:406] Eltwise3 <- Convolution8
I1012 21:57:24.373517 11428 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1012 21:57:24.373522 11428 net.cpp:380] Eltwise3 -> Eltwise3
I1012 21:57:24.373548 11428 net.cpp:122] Setting up Eltwise3
I1012 21:57:24.373553 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.373556 11428 net.cpp:137] Memory required for data: 743075800
I1012 21:57:24.373559 11428 layer_factory.hpp:77] Creating layer BatchNorm7
I1012 21:57:24.373565 11428 net.cpp:84] Creating Layer BatchNorm7
I1012 21:57:24.373576 11428 net.cpp:406] BatchNorm7 <- Eltwise3
I1012 21:57:24.373581 11428 net.cpp:367] BatchNorm7 -> Eltwise3 (in-place)
I1012 21:57:24.373744 11428 net.cpp:122] Setting up BatchNorm7
I1012 21:57:24.373750 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.373754 11428 net.cpp:137] Memory required for data: 768163800
I1012 21:57:24.373759 11428 layer_factory.hpp:77] Creating layer Scale7
I1012 21:57:24.373765 11428 net.cpp:84] Creating Layer Scale7
I1012 21:57:24.373769 11428 net.cpp:406] Scale7 <- Eltwise3
I1012 21:57:24.373773 11428 net.cpp:367] Scale7 -> Eltwise3 (in-place)
I1012 21:57:24.373806 11428 layer_factory.hpp:77] Creating layer Scale7
I1012 21:57:24.373903 11428 net.cpp:122] Setting up Scale7
I1012 21:57:24.373908 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.373911 11428 net.cpp:137] Memory required for data: 793251800
I1012 21:57:24.373929 11428 layer_factory.hpp:77] Creating layer ReLU7
I1012 21:57:24.373936 11428 net.cpp:84] Creating Layer ReLU7
I1012 21:57:24.373939 11428 net.cpp:406] ReLU7 <- Eltwise3
I1012 21:57:24.373944 11428 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1012 21:57:24.374084 11428 net.cpp:122] Setting up ReLU7
I1012 21:57:24.374090 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.374094 11428 net.cpp:137] Memory required for data: 818339800
I1012 21:57:24.374097 11428 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1012 21:57:24.374102 11428 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1012 21:57:24.374106 11428 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1012 21:57:24.374110 11428 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1012 21:57:24.374115 11428 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1012 21:57:24.374150 11428 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1012 21:57:24.374155 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.374157 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.374161 11428 net.cpp:137] Memory required for data: 868515800
I1012 21:57:24.374163 11428 layer_factory.hpp:77] Creating layer Convolution9
I1012 21:57:24.374171 11428 net.cpp:84] Creating Layer Convolution9
I1012 21:57:24.374174 11428 net.cpp:406] Convolution9 <- Eltwise3_ReLU7_0_split_0
I1012 21:57:24.374179 11428 net.cpp:380] Convolution9 -> Convolution9
I1012 21:57:24.380481 11428 net.cpp:122] Setting up Convolution9
I1012 21:57:24.380491 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.380496 11428 net.cpp:137] Memory required for data: 893603800
I1012 21:57:24.380499 11428 layer_factory.hpp:77] Creating layer BatchNorm8
I1012 21:57:24.380506 11428 net.cpp:84] Creating Layer BatchNorm8
I1012 21:57:24.380509 11428 net.cpp:406] BatchNorm8 <- Convolution9
I1012 21:57:24.380514 11428 net.cpp:367] BatchNorm8 -> Convolution9 (in-place)
I1012 21:57:24.380679 11428 net.cpp:122] Setting up BatchNorm8
I1012 21:57:24.380684 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.380687 11428 net.cpp:137] Memory required for data: 918691800
I1012 21:57:24.380694 11428 layer_factory.hpp:77] Creating layer Scale8
I1012 21:57:24.380698 11428 net.cpp:84] Creating Layer Scale8
I1012 21:57:24.380702 11428 net.cpp:406] Scale8 <- Convolution9
I1012 21:57:24.380707 11428 net.cpp:367] Scale8 -> Convolution9 (in-place)
I1012 21:57:24.380739 11428 layer_factory.hpp:77] Creating layer Scale8
I1012 21:57:24.380832 11428 net.cpp:122] Setting up Scale8
I1012 21:57:24.380838 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.380841 11428 net.cpp:137] Memory required for data: 943779800
I1012 21:57:24.380846 11428 layer_factory.hpp:77] Creating layer ReLU8
I1012 21:57:24.380851 11428 net.cpp:84] Creating Layer ReLU8
I1012 21:57:24.380854 11428 net.cpp:406] ReLU8 <- Convolution9
I1012 21:57:24.380858 11428 net.cpp:367] ReLU8 -> Convolution9 (in-place)
I1012 21:57:24.380990 11428 net.cpp:122] Setting up ReLU8
I1012 21:57:24.380996 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.381000 11428 net.cpp:137] Memory required for data: 968867800
I1012 21:57:24.381009 11428 layer_factory.hpp:77] Creating layer Convolution10
I1012 21:57:24.381017 11428 net.cpp:84] Creating Layer Convolution10
I1012 21:57:24.381021 11428 net.cpp:406] Convolution10 <- Convolution9
I1012 21:57:24.381026 11428 net.cpp:380] Convolution10 -> Convolution10
I1012 21:57:24.388100 11428 net.cpp:122] Setting up Convolution10
I1012 21:57:24.388123 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.388128 11428 net.cpp:137] Memory required for data: 993955800
I1012 21:57:24.388134 11428 layer_factory.hpp:77] Creating layer Eltwise4
I1012 21:57:24.388139 11428 net.cpp:84] Creating Layer Eltwise4
I1012 21:57:24.388144 11428 net.cpp:406] Eltwise4 <- Convolution10
I1012 21:57:24.388150 11428 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I1012 21:57:24.388156 11428 net.cpp:380] Eltwise4 -> Eltwise4
I1012 21:57:24.388191 11428 net.cpp:122] Setting up Eltwise4
I1012 21:57:24.388198 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.388211 11428 net.cpp:137] Memory required for data: 1019043800
I1012 21:57:24.388214 11428 layer_factory.hpp:77] Creating layer Eltwise4_Eltwise4_0_split
I1012 21:57:24.388219 11428 net.cpp:84] Creating Layer Eltwise4_Eltwise4_0_split
I1012 21:57:24.388223 11428 net.cpp:406] Eltwise4_Eltwise4_0_split <- Eltwise4
I1012 21:57:24.388228 11428 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I1012 21:57:24.388234 11428 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I1012 21:57:24.388265 11428 net.cpp:122] Setting up Eltwise4_Eltwise4_0_split
I1012 21:57:24.388272 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.388275 11428 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1012 21:57:24.388279 11428 net.cpp:137] Memory required for data: 1069219800
I1012 21:57:24.388283 11428 layer_factory.hpp:77] Creating layer Convolution11
I1012 21:57:24.388291 11428 net.cpp:84] Creating Layer Convolution11
I1012 21:57:24.388295 11428 net.cpp:406] Convolution11 <- Eltwise4_Eltwise4_0_split_0
I1012 21:57:24.388301 11428 net.cpp:380] Convolution11 -> Convolution11
I1012 21:57:24.400037 11428 net.cpp:122] Setting up Convolution11
I1012 21:57:24.400048 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.400051 11428 net.cpp:137] Memory required for data: 1081763800
I1012 21:57:24.400058 11428 layer_factory.hpp:77] Creating layer BatchNorm9
I1012 21:57:24.400065 11428 net.cpp:84] Creating Layer BatchNorm9
I1012 21:57:24.400069 11428 net.cpp:406] BatchNorm9 <- Convolution11
I1012 21:57:24.400076 11428 net.cpp:367] BatchNorm9 -> Convolution11 (in-place)
I1012 21:57:24.400259 11428 net.cpp:122] Setting up BatchNorm9
I1012 21:57:24.400265 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.400279 11428 net.cpp:137] Memory required for data: 1094307800
I1012 21:57:24.400285 11428 layer_factory.hpp:77] Creating layer Scale9
I1012 21:57:24.400292 11428 net.cpp:84] Creating Layer Scale9
I1012 21:57:24.400296 11428 net.cpp:406] Scale9 <- Convolution11
I1012 21:57:24.400300 11428 net.cpp:367] Scale9 -> Convolution11 (in-place)
I1012 21:57:24.400339 11428 layer_factory.hpp:77] Creating layer Scale9
I1012 21:57:24.400436 11428 net.cpp:122] Setting up Scale9
I1012 21:57:24.400442 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.400446 11428 net.cpp:137] Memory required for data: 1106851800
I1012 21:57:24.400451 11428 layer_factory.hpp:77] Creating layer ReLU9
I1012 21:57:24.400458 11428 net.cpp:84] Creating Layer ReLU9
I1012 21:57:24.400462 11428 net.cpp:406] ReLU9 <- Convolution11
I1012 21:57:24.400466 11428 net.cpp:367] ReLU9 -> Convolution11 (in-place)
I1012 21:57:24.400593 11428 net.cpp:122] Setting up ReLU9
I1012 21:57:24.400600 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.400604 11428 net.cpp:137] Memory required for data: 1119395800
I1012 21:57:24.400609 11428 layer_factory.hpp:77] Creating layer Convolution12
I1012 21:57:24.400616 11428 net.cpp:84] Creating Layer Convolution12
I1012 21:57:24.400629 11428 net.cpp:406] Convolution12 <- Convolution11
I1012 21:57:24.400635 11428 net.cpp:380] Convolution12 -> Convolution12
I1012 21:57:24.423477 11428 net.cpp:122] Setting up Convolution12
I1012 21:57:24.423506 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.423509 11428 net.cpp:137] Memory required for data: 1131939800
I1012 21:57:24.423516 11428 layer_factory.hpp:77] Creating layer Convolution13
I1012 21:57:24.423526 11428 net.cpp:84] Creating Layer Convolution13
I1012 21:57:24.423530 11428 net.cpp:406] Convolution13 <- Eltwise4_Eltwise4_0_split_1
I1012 21:57:24.423547 11428 net.cpp:380] Convolution13 -> Convolution13
I1012 21:57:24.425612 11428 net.cpp:122] Setting up Convolution13
I1012 21:57:24.425624 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.425637 11428 net.cpp:137] Memory required for data: 1144483800
I1012 21:57:24.425642 11428 layer_factory.hpp:77] Creating layer Eltwise5
I1012 21:57:24.425649 11428 net.cpp:84] Creating Layer Eltwise5
I1012 21:57:24.425654 11428 net.cpp:406] Eltwise5 <- Convolution12
I1012 21:57:24.425659 11428 net.cpp:406] Eltwise5 <- Convolution13
I1012 21:57:24.425665 11428 net.cpp:380] Eltwise5 -> Eltwise5
I1012 21:57:24.425698 11428 net.cpp:122] Setting up Eltwise5
I1012 21:57:24.425704 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.425717 11428 net.cpp:137] Memory required for data: 1157027800
I1012 21:57:24.425720 11428 layer_factory.hpp:77] Creating layer BatchNorm10
I1012 21:57:24.425726 11428 net.cpp:84] Creating Layer BatchNorm10
I1012 21:57:24.425729 11428 net.cpp:406] BatchNorm10 <- Eltwise5
I1012 21:57:24.425734 11428 net.cpp:367] BatchNorm10 -> Eltwise5 (in-place)
I1012 21:57:24.425920 11428 net.cpp:122] Setting up BatchNorm10
I1012 21:57:24.425937 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.425940 11428 net.cpp:137] Memory required for data: 1169571800
I1012 21:57:24.425961 11428 layer_factory.hpp:77] Creating layer Scale10
I1012 21:57:24.425976 11428 net.cpp:84] Creating Layer Scale10
I1012 21:57:24.425978 11428 net.cpp:406] Scale10 <- Eltwise5
I1012 21:57:24.425985 11428 net.cpp:367] Scale10 -> Eltwise5 (in-place)
I1012 21:57:24.426028 11428 layer_factory.hpp:77] Creating layer Scale10
I1012 21:57:24.426126 11428 net.cpp:122] Setting up Scale10
I1012 21:57:24.426132 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.426136 11428 net.cpp:137] Memory required for data: 1182115800
I1012 21:57:24.426142 11428 layer_factory.hpp:77] Creating layer ReLU10
I1012 21:57:24.426148 11428 net.cpp:84] Creating Layer ReLU10
I1012 21:57:24.426151 11428 net.cpp:406] ReLU10 <- Eltwise5
I1012 21:57:24.426157 11428 net.cpp:367] ReLU10 -> Eltwise5 (in-place)
I1012 21:57:24.426287 11428 net.cpp:122] Setting up ReLU10
I1012 21:57:24.426295 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.426298 11428 net.cpp:137] Memory required for data: 1194659800
I1012 21:57:24.426302 11428 layer_factory.hpp:77] Creating layer Eltwise5_ReLU10_0_split
I1012 21:57:24.426308 11428 net.cpp:84] Creating Layer Eltwise5_ReLU10_0_split
I1012 21:57:24.426312 11428 net.cpp:406] Eltwise5_ReLU10_0_split <- Eltwise5
I1012 21:57:24.426318 11428 net.cpp:380] Eltwise5_ReLU10_0_split -> Eltwise5_ReLU10_0_split_0
I1012 21:57:24.426327 11428 net.cpp:380] Eltwise5_ReLU10_0_split -> Eltwise5_ReLU10_0_split_1
I1012 21:57:24.426365 11428 net.cpp:122] Setting up Eltwise5_ReLU10_0_split
I1012 21:57:24.426371 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.426376 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.426379 11428 net.cpp:137] Memory required for data: 1219747800
I1012 21:57:24.426383 11428 layer_factory.hpp:77] Creating layer Convolution14
I1012 21:57:24.426393 11428 net.cpp:84] Creating Layer Convolution14
I1012 21:57:24.426396 11428 net.cpp:406] Convolution14 <- Eltwise5_ReLU10_0_split_0
I1012 21:57:24.426403 11428 net.cpp:380] Convolution14 -> Convolution14
I1012 21:57:24.449241 11428 net.cpp:122] Setting up Convolution14
I1012 21:57:24.449261 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.449275 11428 net.cpp:137] Memory required for data: 1232291800
I1012 21:57:24.449301 11428 layer_factory.hpp:77] Creating layer BatchNorm11
I1012 21:57:24.449332 11428 net.cpp:84] Creating Layer BatchNorm11
I1012 21:57:24.449337 11428 net.cpp:406] BatchNorm11 <- Convolution14
I1012 21:57:24.449357 11428 net.cpp:367] BatchNorm11 -> Convolution14 (in-place)
I1012 21:57:24.449584 11428 net.cpp:122] Setting up BatchNorm11
I1012 21:57:24.449590 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.449594 11428 net.cpp:137] Memory required for data: 1244835800
I1012 21:57:24.449600 11428 layer_factory.hpp:77] Creating layer Scale11
I1012 21:57:24.449606 11428 net.cpp:84] Creating Layer Scale11
I1012 21:57:24.449620 11428 net.cpp:406] Scale11 <- Convolution14
I1012 21:57:24.449626 11428 net.cpp:367] Scale11 -> Convolution14 (in-place)
I1012 21:57:24.449728 11428 layer_factory.hpp:77] Creating layer Scale11
I1012 21:57:24.449856 11428 net.cpp:122] Setting up Scale11
I1012 21:57:24.449863 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.449877 11428 net.cpp:137] Memory required for data: 1257379800
I1012 21:57:24.449882 11428 layer_factory.hpp:77] Creating layer ReLU11
I1012 21:57:24.449888 11428 net.cpp:84] Creating Layer ReLU11
I1012 21:57:24.449894 11428 net.cpp:406] ReLU11 <- Convolution14
I1012 21:57:24.449913 11428 net.cpp:367] ReLU11 -> Convolution14 (in-place)
I1012 21:57:24.450075 11428 net.cpp:122] Setting up ReLU11
I1012 21:57:24.450083 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.450098 11428 net.cpp:137] Memory required for data: 1269923800
I1012 21:57:24.450101 11428 layer_factory.hpp:77] Creating layer Convolution15
I1012 21:57:24.450120 11428 net.cpp:84] Creating Layer Convolution15
I1012 21:57:24.450125 11428 net.cpp:406] Convolution15 <- Convolution14
I1012 21:57:24.450140 11428 net.cpp:380] Convolution15 -> Convolution15
I1012 21:57:24.471953 11428 net.cpp:122] Setting up Convolution15
I1012 21:57:24.471977 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.471981 11428 net.cpp:137] Memory required for data: 1282467800
I1012 21:57:24.471995 11428 layer_factory.hpp:77] Creating layer Eltwise6
I1012 21:57:24.472003 11428 net.cpp:84] Creating Layer Eltwise6
I1012 21:57:24.472018 11428 net.cpp:406] Eltwise6 <- Convolution15
I1012 21:57:24.472038 11428 net.cpp:406] Eltwise6 <- Eltwise5_ReLU10_0_split_1
I1012 21:57:24.472043 11428 net.cpp:380] Eltwise6 -> Eltwise6
I1012 21:57:24.472101 11428 net.cpp:122] Setting up Eltwise6
I1012 21:57:24.472116 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.472120 11428 net.cpp:137] Memory required for data: 1295011800
I1012 21:57:24.472132 11428 layer_factory.hpp:77] Creating layer BatchNorm12
I1012 21:57:24.472138 11428 net.cpp:84] Creating Layer BatchNorm12
I1012 21:57:24.472153 11428 net.cpp:406] BatchNorm12 <- Eltwise6
I1012 21:57:24.472158 11428 net.cpp:367] BatchNorm12 -> Eltwise6 (in-place)
I1012 21:57:24.472345 11428 net.cpp:122] Setting up BatchNorm12
I1012 21:57:24.472352 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.472354 11428 net.cpp:137] Memory required for data: 1307555800
I1012 21:57:24.472360 11428 layer_factory.hpp:77] Creating layer Scale12
I1012 21:57:24.472378 11428 net.cpp:84] Creating Layer Scale12
I1012 21:57:24.472383 11428 net.cpp:406] Scale12 <- Eltwise6
I1012 21:57:24.472400 11428 net.cpp:367] Scale12 -> Eltwise6 (in-place)
I1012 21:57:24.472450 11428 layer_factory.hpp:77] Creating layer Scale12
I1012 21:57:24.472548 11428 net.cpp:122] Setting up Scale12
I1012 21:57:24.472554 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.472558 11428 net.cpp:137] Memory required for data: 1320099800
I1012 21:57:24.472563 11428 layer_factory.hpp:77] Creating layer ReLU12
I1012 21:57:24.472574 11428 net.cpp:84] Creating Layer ReLU12
I1012 21:57:24.472579 11428 net.cpp:406] ReLU12 <- Eltwise6
I1012 21:57:24.472584 11428 net.cpp:367] ReLU12 -> Eltwise6 (in-place)
I1012 21:57:24.473086 11428 net.cpp:122] Setting up ReLU12
I1012 21:57:24.473096 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.473100 11428 net.cpp:137] Memory required for data: 1332643800
I1012 21:57:24.473104 11428 layer_factory.hpp:77] Creating layer Eltwise6_ReLU12_0_split
I1012 21:57:24.473111 11428 net.cpp:84] Creating Layer Eltwise6_ReLU12_0_split
I1012 21:57:24.473116 11428 net.cpp:406] Eltwise6_ReLU12_0_split <- Eltwise6
I1012 21:57:24.473121 11428 net.cpp:380] Eltwise6_ReLU12_0_split -> Eltwise6_ReLU12_0_split_0
I1012 21:57:24.473129 11428 net.cpp:380] Eltwise6_ReLU12_0_split -> Eltwise6_ReLU12_0_split_1
I1012 21:57:24.473165 11428 net.cpp:122] Setting up Eltwise6_ReLU12_0_split
I1012 21:57:24.473171 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.473176 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.473181 11428 net.cpp:137] Memory required for data: 1357731800
I1012 21:57:24.473183 11428 layer_factory.hpp:77] Creating layer Convolution16
I1012 21:57:24.473191 11428 net.cpp:84] Creating Layer Convolution16
I1012 21:57:24.473196 11428 net.cpp:406] Convolution16 <- Eltwise6_ReLU12_0_split_0
I1012 21:57:24.473202 11428 net.cpp:380] Convolution16 -> Convolution16
I1012 21:57:24.495162 11428 net.cpp:122] Setting up Convolution16
I1012 21:57:24.495182 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.495185 11428 net.cpp:137] Memory required for data: 1370275800
I1012 21:57:24.495192 11428 layer_factory.hpp:77] Creating layer BatchNorm13
I1012 21:57:24.495210 11428 net.cpp:84] Creating Layer BatchNorm13
I1012 21:57:24.495226 11428 net.cpp:406] BatchNorm13 <- Convolution16
I1012 21:57:24.495234 11428 net.cpp:367] BatchNorm13 -> Convolution16 (in-place)
I1012 21:57:24.495437 11428 net.cpp:122] Setting up BatchNorm13
I1012 21:57:24.495445 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.495457 11428 net.cpp:137] Memory required for data: 1382819800
I1012 21:57:24.495465 11428 layer_factory.hpp:77] Creating layer Scale13
I1012 21:57:24.495489 11428 net.cpp:84] Creating Layer Scale13
I1012 21:57:24.495503 11428 net.cpp:406] Scale13 <- Convolution16
I1012 21:57:24.495512 11428 net.cpp:367] Scale13 -> Convolution16 (in-place)
I1012 21:57:24.495565 11428 layer_factory.hpp:77] Creating layer Scale13
I1012 21:57:24.495685 11428 net.cpp:122] Setting up Scale13
I1012 21:57:24.495692 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.495698 11428 net.cpp:137] Memory required for data: 1395363800
I1012 21:57:24.495718 11428 layer_factory.hpp:77] Creating layer ReLU13
I1012 21:57:24.495724 11428 net.cpp:84] Creating Layer ReLU13
I1012 21:57:24.495728 11428 net.cpp:406] ReLU13 <- Convolution16
I1012 21:57:24.495735 11428 net.cpp:367] ReLU13 -> Convolution16 (in-place)
I1012 21:57:24.496259 11428 net.cpp:122] Setting up ReLU13
I1012 21:57:24.496269 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.496275 11428 net.cpp:137] Memory required for data: 1407907800
I1012 21:57:24.496291 11428 layer_factory.hpp:77] Creating layer Convolution17
I1012 21:57:24.496304 11428 net.cpp:84] Creating Layer Convolution17
I1012 21:57:24.496309 11428 net.cpp:406] Convolution17 <- Convolution16
I1012 21:57:24.496317 11428 net.cpp:380] Convolution17 -> Convolution17
I1012 21:57:24.518936 11428 net.cpp:122] Setting up Convolution17
I1012 21:57:24.518966 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.518971 11428 net.cpp:137] Memory required for data: 1420451800
I1012 21:57:24.518978 11428 layer_factory.hpp:77] Creating layer Eltwise7
I1012 21:57:24.518999 11428 net.cpp:84] Creating Layer Eltwise7
I1012 21:57:24.519006 11428 net.cpp:406] Eltwise7 <- Convolution17
I1012 21:57:24.519011 11428 net.cpp:406] Eltwise7 <- Eltwise6_ReLU12_0_split_1
I1012 21:57:24.519019 11428 net.cpp:380] Eltwise7 -> Eltwise7
I1012 21:57:24.519080 11428 net.cpp:122] Setting up Eltwise7
I1012 21:57:24.519096 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.519099 11428 net.cpp:137] Memory required for data: 1432995800
I1012 21:57:24.519114 11428 layer_factory.hpp:77] Creating layer BatchNorm14
I1012 21:57:24.519135 11428 net.cpp:84] Creating Layer BatchNorm14
I1012 21:57:24.519138 11428 net.cpp:406] BatchNorm14 <- Eltwise7
I1012 21:57:24.519153 11428 net.cpp:367] BatchNorm14 -> Eltwise7 (in-place)
I1012 21:57:24.519366 11428 net.cpp:122] Setting up BatchNorm14
I1012 21:57:24.519373 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.519387 11428 net.cpp:137] Memory required for data: 1445539800
I1012 21:57:24.519392 11428 layer_factory.hpp:77] Creating layer Scale14
I1012 21:57:24.519409 11428 net.cpp:84] Creating Layer Scale14
I1012 21:57:24.519413 11428 net.cpp:406] Scale14 <- Eltwise7
I1012 21:57:24.519418 11428 net.cpp:367] Scale14 -> Eltwise7 (in-place)
I1012 21:57:24.519479 11428 layer_factory.hpp:77] Creating layer Scale14
I1012 21:57:24.519621 11428 net.cpp:122] Setting up Scale14
I1012 21:57:24.519628 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.519641 11428 net.cpp:137] Memory required for data: 1458083800
I1012 21:57:24.519646 11428 layer_factory.hpp:77] Creating layer ReLU14
I1012 21:57:24.519667 11428 net.cpp:84] Creating Layer ReLU14
I1012 21:57:24.519670 11428 net.cpp:406] ReLU14 <- Eltwise7
I1012 21:57:24.519685 11428 net.cpp:367] ReLU14 -> Eltwise7 (in-place)
I1012 21:57:24.519862 11428 net.cpp:122] Setting up ReLU14
I1012 21:57:24.519870 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.519884 11428 net.cpp:137] Memory required for data: 1470627800
I1012 21:57:24.519888 11428 layer_factory.hpp:77] Creating layer Eltwise7_ReLU14_0_split
I1012 21:57:24.519896 11428 net.cpp:84] Creating Layer Eltwise7_ReLU14_0_split
I1012 21:57:24.519901 11428 net.cpp:406] Eltwise7_ReLU14_0_split <- Eltwise7
I1012 21:57:24.519918 11428 net.cpp:380] Eltwise7_ReLU14_0_split -> Eltwise7_ReLU14_0_split_0
I1012 21:57:24.519927 11428 net.cpp:380] Eltwise7_ReLU14_0_split -> Eltwise7_ReLU14_0_split_1
I1012 21:57:24.519976 11428 net.cpp:122] Setting up Eltwise7_ReLU14_0_split
I1012 21:57:24.519984 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.519999 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.520004 11428 net.cpp:137] Memory required for data: 1495715800
I1012 21:57:24.520009 11428 layer_factory.hpp:77] Creating layer Convolution18
I1012 21:57:24.520020 11428 net.cpp:84] Creating Layer Convolution18
I1012 21:57:24.520025 11428 net.cpp:406] Convolution18 <- Eltwise7_ReLU14_0_split_0
I1012 21:57:24.520035 11428 net.cpp:380] Convolution18 -> Convolution18
I1012 21:57:24.542647 11428 net.cpp:122] Setting up Convolution18
I1012 21:57:24.542668 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.542671 11428 net.cpp:137] Memory required for data: 1508259800
I1012 21:57:24.542678 11428 layer_factory.hpp:77] Creating layer BatchNorm15
I1012 21:57:24.542690 11428 net.cpp:84] Creating Layer BatchNorm15
I1012 21:57:24.542709 11428 net.cpp:406] BatchNorm15 <- Convolution18
I1012 21:57:24.542717 11428 net.cpp:367] BatchNorm15 -> Convolution18 (in-place)
I1012 21:57:24.542914 11428 net.cpp:122] Setting up BatchNorm15
I1012 21:57:24.542922 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.542924 11428 net.cpp:137] Memory required for data: 1520803800
I1012 21:57:24.542930 11428 layer_factory.hpp:77] Creating layer Scale15
I1012 21:57:24.542951 11428 net.cpp:84] Creating Layer Scale15
I1012 21:57:24.542956 11428 net.cpp:406] Scale15 <- Convolution18
I1012 21:57:24.542963 11428 net.cpp:367] Scale15 -> Convolution18 (in-place)
I1012 21:57:24.543018 11428 layer_factory.hpp:77] Creating layer Scale15
I1012 21:57:24.543139 11428 net.cpp:122] Setting up Scale15
I1012 21:57:24.543146 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.543149 11428 net.cpp:137] Memory required for data: 1533347800
I1012 21:57:24.543154 11428 layer_factory.hpp:77] Creating layer ReLU15
I1012 21:57:24.543175 11428 net.cpp:84] Creating Layer ReLU15
I1012 21:57:24.543180 11428 net.cpp:406] ReLU15 <- Convolution18
I1012 21:57:24.543184 11428 net.cpp:367] ReLU15 -> Convolution18 (in-place)
I1012 21:57:24.543397 11428 net.cpp:122] Setting up ReLU15
I1012 21:57:24.543404 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.543408 11428 net.cpp:137] Memory required for data: 1545891800
I1012 21:57:24.543411 11428 layer_factory.hpp:77] Creating layer Convolution19
I1012 21:57:24.543431 11428 net.cpp:84] Creating Layer Convolution19
I1012 21:57:24.543434 11428 net.cpp:406] Convolution19 <- Convolution18
I1012 21:57:24.543450 11428 net.cpp:380] Convolution19 -> Convolution19
I1012 21:57:24.565440 11428 net.cpp:122] Setting up Convolution19
I1012 21:57:24.565464 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.565467 11428 net.cpp:137] Memory required for data: 1558435800
I1012 21:57:24.565474 11428 layer_factory.hpp:77] Creating layer Eltwise8
I1012 21:57:24.565491 11428 net.cpp:84] Creating Layer Eltwise8
I1012 21:57:24.565497 11428 net.cpp:406] Eltwise8 <- Convolution19
I1012 21:57:24.565505 11428 net.cpp:406] Eltwise8 <- Eltwise7_ReLU14_0_split_1
I1012 21:57:24.565510 11428 net.cpp:380] Eltwise8 -> Eltwise8
I1012 21:57:24.565551 11428 net.cpp:122] Setting up Eltwise8
I1012 21:57:24.565565 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.565578 11428 net.cpp:137] Memory required for data: 1570979800
I1012 21:57:24.565582 11428 layer_factory.hpp:77] Creating layer Eltwise8_Eltwise8_0_split
I1012 21:57:24.565589 11428 net.cpp:84] Creating Layer Eltwise8_Eltwise8_0_split
I1012 21:57:24.565608 11428 net.cpp:406] Eltwise8_Eltwise8_0_split <- Eltwise8
I1012 21:57:24.565623 11428 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I1012 21:57:24.565629 11428 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I1012 21:57:24.565692 11428 net.cpp:122] Setting up Eltwise8_Eltwise8_0_split
I1012 21:57:24.565699 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.565716 11428 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1012 21:57:24.565721 11428 net.cpp:137] Memory required for data: 1596067800
I1012 21:57:24.565737 11428 layer_factory.hpp:77] Creating layer Convolution20
I1012 21:57:24.565749 11428 net.cpp:84] Creating Layer Convolution20
I1012 21:57:24.565754 11428 net.cpp:406] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I1012 21:57:24.565763 11428 net.cpp:380] Convolution20 -> Convolution20
I1012 21:57:24.608299 11428 net.cpp:122] Setting up Convolution20
I1012 21:57:24.608321 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.608325 11428 net.cpp:137] Memory required for data: 1602339800
I1012 21:57:24.608332 11428 layer_factory.hpp:77] Creating layer BatchNorm16
I1012 21:57:24.608345 11428 net.cpp:84] Creating Layer BatchNorm16
I1012 21:57:24.608361 11428 net.cpp:406] BatchNorm16 <- Convolution20
I1012 21:57:24.608382 11428 net.cpp:367] BatchNorm16 -> Convolution20 (in-place)
I1012 21:57:24.608618 11428 net.cpp:122] Setting up BatchNorm16
I1012 21:57:24.608624 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.608628 11428 net.cpp:137] Memory required for data: 1608611800
I1012 21:57:24.608633 11428 layer_factory.hpp:77] Creating layer Scale16
I1012 21:57:24.608640 11428 net.cpp:84] Creating Layer Scale16
I1012 21:57:24.608654 11428 net.cpp:406] Scale16 <- Convolution20
I1012 21:57:24.608660 11428 net.cpp:367] Scale16 -> Convolution20 (in-place)
I1012 21:57:24.608737 11428 layer_factory.hpp:77] Creating layer Scale16
I1012 21:57:24.608903 11428 net.cpp:122] Setting up Scale16
I1012 21:57:24.608911 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.608923 11428 net.cpp:137] Memory required for data: 1614883800
I1012 21:57:24.608928 11428 layer_factory.hpp:77] Creating layer ReLU16
I1012 21:57:24.608935 11428 net.cpp:84] Creating Layer ReLU16
I1012 21:57:24.608952 11428 net.cpp:406] ReLU16 <- Convolution20
I1012 21:57:24.608958 11428 net.cpp:367] ReLU16 -> Convolution20 (in-place)
I1012 21:57:24.609148 11428 net.cpp:122] Setting up ReLU16
I1012 21:57:24.609154 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.609191 11428 net.cpp:137] Memory required for data: 1621155800
I1012 21:57:24.609195 11428 layer_factory.hpp:77] Creating layer Convolution21
I1012 21:57:24.609215 11428 net.cpp:84] Creating Layer Convolution21
I1012 21:57:24.609218 11428 net.cpp:406] Convolution21 <- Convolution20
I1012 21:57:24.609225 11428 net.cpp:380] Convolution21 -> Convolution21
I1012 21:57:24.692749 11428 net.cpp:122] Setting up Convolution21
I1012 21:57:24.692771 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.692775 11428 net.cpp:137] Memory required for data: 1627427800
I1012 21:57:24.692781 11428 layer_factory.hpp:77] Creating layer Convolution22
I1012 21:57:24.692797 11428 net.cpp:84] Creating Layer Convolution22
I1012 21:57:24.692816 11428 net.cpp:406] Convolution22 <- Eltwise8_Eltwise8_0_split_1
I1012 21:57:24.692834 11428 net.cpp:380] Convolution22 -> Convolution22
I1012 21:57:24.698557 11428 net.cpp:122] Setting up Convolution22
I1012 21:57:24.698568 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.698572 11428 net.cpp:137] Memory required for data: 1633699800
I1012 21:57:24.698577 11428 layer_factory.hpp:77] Creating layer Eltwise9
I1012 21:57:24.698583 11428 net.cpp:84] Creating Layer Eltwise9
I1012 21:57:24.698587 11428 net.cpp:406] Eltwise9 <- Convolution21
I1012 21:57:24.698601 11428 net.cpp:406] Eltwise9 <- Convolution22
I1012 21:57:24.698607 11428 net.cpp:380] Eltwise9 -> Eltwise9
I1012 21:57:24.698653 11428 net.cpp:122] Setting up Eltwise9
I1012 21:57:24.698660 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.698673 11428 net.cpp:137] Memory required for data: 1639971800
I1012 21:57:24.698676 11428 layer_factory.hpp:77] Creating layer BatchNorm17
I1012 21:57:24.698693 11428 net.cpp:84] Creating Layer BatchNorm17
I1012 21:57:24.698695 11428 net.cpp:406] BatchNorm17 <- Eltwise9
I1012 21:57:24.698711 11428 net.cpp:367] BatchNorm17 -> Eltwise9 (in-place)
I1012 21:57:24.698904 11428 net.cpp:122] Setting up BatchNorm17
I1012 21:57:24.698910 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.698925 11428 net.cpp:137] Memory required for data: 1646243800
I1012 21:57:24.698931 11428 layer_factory.hpp:77] Creating layer Scale17
I1012 21:57:24.698947 11428 net.cpp:84] Creating Layer Scale17
I1012 21:57:24.698951 11428 net.cpp:406] Scale17 <- Eltwise9
I1012 21:57:24.698956 11428 net.cpp:367] Scale17 -> Eltwise9 (in-place)
I1012 21:57:24.699004 11428 layer_factory.hpp:77] Creating layer Scale17
I1012 21:57:24.699126 11428 net.cpp:122] Setting up Scale17
I1012 21:57:24.699132 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.699136 11428 net.cpp:137] Memory required for data: 1652515800
I1012 21:57:24.699152 11428 layer_factory.hpp:77] Creating layer ReLU17
I1012 21:57:24.699159 11428 net.cpp:84] Creating Layer ReLU17
I1012 21:57:24.699163 11428 net.cpp:406] ReLU17 <- Eltwise9
I1012 21:57:24.699168 11428 net.cpp:367] ReLU17 -> Eltwise9 (in-place)
I1012 21:57:24.699309 11428 net.cpp:122] Setting up ReLU17
I1012 21:57:24.699317 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.699321 11428 net.cpp:137] Memory required for data: 1658787800
I1012 21:57:24.699335 11428 layer_factory.hpp:77] Creating layer Eltwise9_ReLU17_0_split
I1012 21:57:24.699342 11428 net.cpp:84] Creating Layer Eltwise9_ReLU17_0_split
I1012 21:57:24.699347 11428 net.cpp:406] Eltwise9_ReLU17_0_split <- Eltwise9
I1012 21:57:24.699352 11428 net.cpp:380] Eltwise9_ReLU17_0_split -> Eltwise9_ReLU17_0_split_0
I1012 21:57:24.699358 11428 net.cpp:380] Eltwise9_ReLU17_0_split -> Eltwise9_ReLU17_0_split_1
I1012 21:57:24.699405 11428 net.cpp:122] Setting up Eltwise9_ReLU17_0_split
I1012 21:57:24.699412 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.699416 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.699430 11428 net.cpp:137] Memory required for data: 1671331800
I1012 21:57:24.699434 11428 layer_factory.hpp:77] Creating layer Convolution23
I1012 21:57:24.699443 11428 net.cpp:84] Creating Layer Convolution23
I1012 21:57:24.699447 11428 net.cpp:406] Convolution23 <- Eltwise9_ReLU17_0_split_0
I1012 21:57:24.699463 11428 net.cpp:380] Convolution23 -> Convolution23
I1012 21:57:24.783172 11428 net.cpp:122] Setting up Convolution23
I1012 21:57:24.783195 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.783200 11428 net.cpp:137] Memory required for data: 1677603800
I1012 21:57:24.783206 11428 layer_factory.hpp:77] Creating layer BatchNorm18
I1012 21:57:24.783226 11428 net.cpp:84] Creating Layer BatchNorm18
I1012 21:57:24.783232 11428 net.cpp:406] BatchNorm18 <- Convolution23
I1012 21:57:24.783251 11428 net.cpp:367] BatchNorm18 -> Convolution23 (in-place)
I1012 21:57:24.783454 11428 net.cpp:122] Setting up BatchNorm18
I1012 21:57:24.783462 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.783465 11428 net.cpp:137] Memory required for data: 1683875800
I1012 21:57:24.783471 11428 layer_factory.hpp:77] Creating layer Scale18
I1012 21:57:24.783478 11428 net.cpp:84] Creating Layer Scale18
I1012 21:57:24.783494 11428 net.cpp:406] Scale18 <- Convolution23
I1012 21:57:24.783500 11428 net.cpp:367] Scale18 -> Convolution23 (in-place)
I1012 21:57:24.783572 11428 layer_factory.hpp:77] Creating layer Scale18
I1012 21:57:24.783707 11428 net.cpp:122] Setting up Scale18
I1012 21:57:24.783713 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.783716 11428 net.cpp:137] Memory required for data: 1690147800
I1012 21:57:24.783721 11428 layer_factory.hpp:77] Creating layer ReLU18
I1012 21:57:24.783726 11428 net.cpp:84] Creating Layer ReLU18
I1012 21:57:24.783730 11428 net.cpp:406] ReLU18 <- Convolution23
I1012 21:57:24.783745 11428 net.cpp:367] ReLU18 -> Convolution23 (in-place)
I1012 21:57:24.783905 11428 net.cpp:122] Setting up ReLU18
I1012 21:57:24.783912 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.783915 11428 net.cpp:137] Memory required for data: 1696419800
I1012 21:57:24.783918 11428 layer_factory.hpp:77] Creating layer Convolution24
I1012 21:57:24.783926 11428 net.cpp:84] Creating Layer Convolution24
I1012 21:57:24.783941 11428 net.cpp:406] Convolution24 <- Convolution23
I1012 21:57:24.783946 11428 net.cpp:380] Convolution24 -> Convolution24
I1012 21:57:24.868053 11428 net.cpp:122] Setting up Convolution24
I1012 21:57:24.868074 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.868078 11428 net.cpp:137] Memory required for data: 1702691800
I1012 21:57:24.868085 11428 layer_factory.hpp:77] Creating layer Eltwise10
I1012 21:57:24.868094 11428 net.cpp:84] Creating Layer Eltwise10
I1012 21:57:24.868110 11428 net.cpp:406] Eltwise10 <- Convolution24
I1012 21:57:24.868118 11428 net.cpp:406] Eltwise10 <- Eltwise9_ReLU17_0_split_1
I1012 21:57:24.868127 11428 net.cpp:380] Eltwise10 -> Eltwise10
I1012 21:57:24.868168 11428 net.cpp:122] Setting up Eltwise10
I1012 21:57:24.868175 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.868188 11428 net.cpp:137] Memory required for data: 1708963800
I1012 21:57:24.868191 11428 layer_factory.hpp:77] Creating layer BatchNorm19
I1012 21:57:24.868206 11428 net.cpp:84] Creating Layer BatchNorm19
I1012 21:57:24.868223 11428 net.cpp:406] BatchNorm19 <- Eltwise10
I1012 21:57:24.868232 11428 net.cpp:367] BatchNorm19 -> Eltwise10 (in-place)
I1012 21:57:24.868422 11428 net.cpp:122] Setting up BatchNorm19
I1012 21:57:24.868428 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.868433 11428 net.cpp:137] Memory required for data: 1715235800
I1012 21:57:24.868453 11428 layer_factory.hpp:77] Creating layer Scale19
I1012 21:57:24.868461 11428 net.cpp:84] Creating Layer Scale19
I1012 21:57:24.868465 11428 net.cpp:406] Scale19 <- Eltwise10
I1012 21:57:24.868472 11428 net.cpp:367] Scale19 -> Eltwise10 (in-place)
I1012 21:57:24.868523 11428 layer_factory.hpp:77] Creating layer Scale19
I1012 21:57:24.868646 11428 net.cpp:122] Setting up Scale19
I1012 21:57:24.868654 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.868659 11428 net.cpp:137] Memory required for data: 1721507800
I1012 21:57:24.868676 11428 layer_factory.hpp:77] Creating layer ReLU19
I1012 21:57:24.868695 11428 net.cpp:84] Creating Layer ReLU19
I1012 21:57:24.868700 11428 net.cpp:406] ReLU19 <- Eltwise10
I1012 21:57:24.868707 11428 net.cpp:367] ReLU19 -> Eltwise10 (in-place)
I1012 21:57:24.868849 11428 net.cpp:122] Setting up ReLU19
I1012 21:57:24.868858 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.868873 11428 net.cpp:137] Memory required for data: 1727779800
I1012 21:57:24.868880 11428 layer_factory.hpp:77] Creating layer Eltwise10_ReLU19_0_split
I1012 21:57:24.868887 11428 net.cpp:84] Creating Layer Eltwise10_ReLU19_0_split
I1012 21:57:24.868892 11428 net.cpp:406] Eltwise10_ReLU19_0_split <- Eltwise10
I1012 21:57:24.868901 11428 net.cpp:380] Eltwise10_ReLU19_0_split -> Eltwise10_ReLU19_0_split_0
I1012 21:57:24.868908 11428 net.cpp:380] Eltwise10_ReLU19_0_split -> Eltwise10_ReLU19_0_split_1
I1012 21:57:24.868957 11428 net.cpp:122] Setting up Eltwise10_ReLU19_0_split
I1012 21:57:24.868964 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.868980 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.868985 11428 net.cpp:137] Memory required for data: 1740323800
I1012 21:57:24.868990 11428 layer_factory.hpp:77] Creating layer Convolution25
I1012 21:57:24.869001 11428 net.cpp:84] Creating Layer Convolution25
I1012 21:57:24.869006 11428 net.cpp:406] Convolution25 <- Eltwise10_ReLU19_0_split_0
I1012 21:57:24.869014 11428 net.cpp:380] Convolution25 -> Convolution25
I1012 21:57:24.952878 11428 net.cpp:122] Setting up Convolution25
I1012 21:57:24.952904 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.952908 11428 net.cpp:137] Memory required for data: 1746595800
I1012 21:57:24.952916 11428 layer_factory.hpp:77] Creating layer BatchNorm20
I1012 21:57:24.952929 11428 net.cpp:84] Creating Layer BatchNorm20
I1012 21:57:24.952936 11428 net.cpp:406] BatchNorm20 <- Convolution25
I1012 21:57:24.952947 11428 net.cpp:367] BatchNorm20 -> Convolution25 (in-place)
I1012 21:57:24.953155 11428 net.cpp:122] Setting up BatchNorm20
I1012 21:57:24.953162 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.953166 11428 net.cpp:137] Memory required for data: 1752867800
I1012 21:57:24.953172 11428 layer_factory.hpp:77] Creating layer Scale20
I1012 21:57:24.953179 11428 net.cpp:84] Creating Layer Scale20
I1012 21:57:24.953186 11428 net.cpp:406] Scale20 <- Convolution25
I1012 21:57:24.953203 11428 net.cpp:367] Scale20 -> Convolution25 (in-place)
I1012 21:57:24.953258 11428 layer_factory.hpp:77] Creating layer Scale20
I1012 21:57:24.953366 11428 net.cpp:122] Setting up Scale20
I1012 21:57:24.953372 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.953375 11428 net.cpp:137] Memory required for data: 1759139800
I1012 21:57:24.953380 11428 layer_factory.hpp:77] Creating layer ReLU20
I1012 21:57:24.953387 11428 net.cpp:84] Creating Layer ReLU20
I1012 21:57:24.953392 11428 net.cpp:406] ReLU20 <- Convolution25
I1012 21:57:24.953399 11428 net.cpp:367] ReLU20 -> Convolution25 (in-place)
I1012 21:57:24.953965 11428 net.cpp:122] Setting up ReLU20
I1012 21:57:24.953975 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:24.953979 11428 net.cpp:137] Memory required for data: 1765411800
I1012 21:57:24.953982 11428 layer_factory.hpp:77] Creating layer Convolution26
I1012 21:57:24.953991 11428 net.cpp:84] Creating Layer Convolution26
I1012 21:57:24.953999 11428 net.cpp:406] Convolution26 <- Convolution25
I1012 21:57:24.954007 11428 net.cpp:380] Convolution26 -> Convolution26
I1012 21:57:25.037657 11428 net.cpp:122] Setting up Convolution26
I1012 21:57:25.037680 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.037685 11428 net.cpp:137] Memory required for data: 1771683800
I1012 21:57:25.037693 11428 layer_factory.hpp:77] Creating layer Eltwise11
I1012 21:57:25.037705 11428 net.cpp:84] Creating Layer Eltwise11
I1012 21:57:25.037713 11428 net.cpp:406] Eltwise11 <- Convolution26
I1012 21:57:25.037721 11428 net.cpp:406] Eltwise11 <- Eltwise10_ReLU19_0_split_1
I1012 21:57:25.037729 11428 net.cpp:380] Eltwise11 -> Eltwise11
I1012 21:57:25.037781 11428 net.cpp:122] Setting up Eltwise11
I1012 21:57:25.037788 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.037791 11428 net.cpp:137] Memory required for data: 1777955800
I1012 21:57:25.037794 11428 layer_factory.hpp:77] Creating layer BatchNorm21
I1012 21:57:25.037801 11428 net.cpp:84] Creating Layer BatchNorm21
I1012 21:57:25.037806 11428 net.cpp:406] BatchNorm21 <- Eltwise11
I1012 21:57:25.037812 11428 net.cpp:367] BatchNorm21 -> Eltwise11 (in-place)
I1012 21:57:25.038012 11428 net.cpp:122] Setting up BatchNorm21
I1012 21:57:25.038019 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.038023 11428 net.cpp:137] Memory required for data: 1784227800
I1012 21:57:25.038046 11428 layer_factory.hpp:77] Creating layer Scale21
I1012 21:57:25.038055 11428 net.cpp:84] Creating Layer Scale21
I1012 21:57:25.038060 11428 net.cpp:406] Scale21 <- Eltwise11
I1012 21:57:25.038066 11428 net.cpp:367] Scale21 -> Eltwise11 (in-place)
I1012 21:57:25.038112 11428 layer_factory.hpp:77] Creating layer Scale21
I1012 21:57:25.038218 11428 net.cpp:122] Setting up Scale21
I1012 21:57:25.038225 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.038230 11428 net.cpp:137] Memory required for data: 1790499800
I1012 21:57:25.038239 11428 layer_factory.hpp:77] Creating layer ReLU21
I1012 21:57:25.038244 11428 net.cpp:84] Creating Layer ReLU21
I1012 21:57:25.038249 11428 net.cpp:406] ReLU21 <- Eltwise11
I1012 21:57:25.038255 11428 net.cpp:367] ReLU21 -> Eltwise11 (in-place)
I1012 21:57:25.038426 11428 net.cpp:122] Setting up ReLU21
I1012 21:57:25.038434 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.038440 11428 net.cpp:137] Memory required for data: 1796771800
I1012 21:57:25.038446 11428 layer_factory.hpp:77] Creating layer Eltwise11_ReLU21_0_split
I1012 21:57:25.038455 11428 net.cpp:84] Creating Layer Eltwise11_ReLU21_0_split
I1012 21:57:25.038460 11428 net.cpp:406] Eltwise11_ReLU21_0_split <- Eltwise11
I1012 21:57:25.038467 11428 net.cpp:380] Eltwise11_ReLU21_0_split -> Eltwise11_ReLU21_0_split_0
I1012 21:57:25.038475 11428 net.cpp:380] Eltwise11_ReLU21_0_split -> Eltwise11_ReLU21_0_split_1
I1012 21:57:25.038522 11428 net.cpp:122] Setting up Eltwise11_ReLU21_0_split
I1012 21:57:25.038529 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.038537 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.038542 11428 net.cpp:137] Memory required for data: 1809315800
I1012 21:57:25.038547 11428 layer_factory.hpp:77] Creating layer Convolution27
I1012 21:57:25.038558 11428 net.cpp:84] Creating Layer Convolution27
I1012 21:57:25.038561 11428 net.cpp:406] Convolution27 <- Eltwise11_ReLU21_0_split_0
I1012 21:57:25.038569 11428 net.cpp:380] Convolution27 -> Convolution27
I1012 21:57:25.122275 11428 net.cpp:122] Setting up Convolution27
I1012 21:57:25.122300 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.122304 11428 net.cpp:137] Memory required for data: 1815587800
I1012 21:57:25.122313 11428 layer_factory.hpp:77] Creating layer BatchNorm22
I1012 21:57:25.122334 11428 net.cpp:84] Creating Layer BatchNorm22
I1012 21:57:25.122342 11428 net.cpp:406] BatchNorm22 <- Convolution27
I1012 21:57:25.122351 11428 net.cpp:367] BatchNorm22 -> Convolution27 (in-place)
I1012 21:57:25.122566 11428 net.cpp:122] Setting up BatchNorm22
I1012 21:57:25.122573 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.122576 11428 net.cpp:137] Memory required for data: 1821859800
I1012 21:57:25.122583 11428 layer_factory.hpp:77] Creating layer Scale22
I1012 21:57:25.122589 11428 net.cpp:84] Creating Layer Scale22
I1012 21:57:25.122603 11428 net.cpp:406] Scale22 <- Convolution27
I1012 21:57:25.122609 11428 net.cpp:367] Scale22 -> Convolution27 (in-place)
I1012 21:57:25.122666 11428 layer_factory.hpp:77] Creating layer Scale22
I1012 21:57:25.122793 11428 net.cpp:122] Setting up Scale22
I1012 21:57:25.122800 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.122803 11428 net.cpp:137] Memory required for data: 1828131800
I1012 21:57:25.122808 11428 layer_factory.hpp:77] Creating layer ReLU22
I1012 21:57:25.122840 11428 net.cpp:84] Creating Layer ReLU22
I1012 21:57:25.122845 11428 net.cpp:406] ReLU22 <- Convolution27
I1012 21:57:25.122849 11428 net.cpp:367] ReLU22 -> Convolution27 (in-place)
I1012 21:57:25.123003 11428 net.cpp:122] Setting up ReLU22
I1012 21:57:25.123011 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.123014 11428 net.cpp:137] Memory required for data: 1834403800
I1012 21:57:25.123018 11428 layer_factory.hpp:77] Creating layer Convolution28
I1012 21:57:25.123028 11428 net.cpp:84] Creating Layer Convolution28
I1012 21:57:25.123033 11428 net.cpp:406] Convolution28 <- Convolution27
I1012 21:57:25.123050 11428 net.cpp:380] Convolution28 -> Convolution28
I1012 21:57:25.206938 11428 net.cpp:122] Setting up Convolution28
I1012 21:57:25.206960 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.206964 11428 net.cpp:137] Memory required for data: 1840675800
I1012 21:57:25.206974 11428 layer_factory.hpp:77] Creating layer Eltwise12
I1012 21:57:25.206997 11428 net.cpp:84] Creating Layer Eltwise12
I1012 21:57:25.207007 11428 net.cpp:406] Eltwise12 <- Convolution28
I1012 21:57:25.207016 11428 net.cpp:406] Eltwise12 <- Eltwise11_ReLU21_0_split_1
I1012 21:57:25.207024 11428 net.cpp:380] Eltwise12 -> Eltwise12
I1012 21:57:25.207072 11428 net.cpp:122] Setting up Eltwise12
I1012 21:57:25.207079 11428 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1012 21:57:25.207082 11428 net.cpp:137] Memory required for data: 1846947800
I1012 21:57:25.207085 11428 layer_factory.hpp:77] Creating layer Pooling1
I1012 21:57:25.207093 11428 net.cpp:84] Creating Layer Pooling1
I1012 21:57:25.207096 11428 net.cpp:406] Pooling1 <- Eltwise12
I1012 21:57:25.207103 11428 net.cpp:380] Pooling1 -> Pooling1
I1012 21:57:25.207283 11428 net.cpp:122] Setting up Pooling1
I1012 21:57:25.207291 11428 net.cpp:129] Top shape: 50 640 1 1 (32000)
I1012 21:57:25.207294 11428 net.cpp:137] Memory required for data: 1847075800
I1012 21:57:25.207298 11428 layer_factory.hpp:77] Creating layer InnerProduct1
I1012 21:57:25.207304 11428 net.cpp:84] Creating Layer InnerProduct1
I1012 21:57:25.207307 11428 net.cpp:406] InnerProduct1 <- Pooling1
I1012 21:57:25.207324 11428 net.cpp:380] InnerProduct1 -> InnerProduct1
I1012 21:57:25.207502 11428 net.cpp:122] Setting up InnerProduct1
I1012 21:57:25.207509 11428 net.cpp:129] Top shape: 50 100 (5000)
I1012 21:57:25.207515 11428 net.cpp:137] Memory required for data: 1847095800
I1012 21:57:25.207533 11428 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1012 21:57:25.207541 11428 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1012 21:57:25.207546 11428 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1012 21:57:25.207554 11428 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1012 21:57:25.207562 11428 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1012 21:57:25.207607 11428 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1012 21:57:25.207613 11428 net.cpp:129] Top shape: 50 100 (5000)
I1012 21:57:25.207619 11428 net.cpp:129] Top shape: 50 100 (5000)
I1012 21:57:25.207624 11428 net.cpp:137] Memory required for data: 1847135800
I1012 21:57:25.207630 11428 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1012 21:57:25.207638 11428 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1012 21:57:25.207643 11428 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1012 21:57:25.207650 11428 net.cpp:406] SoftmaxWithLoss1 <- label_cifar_1_split_0
I1012 21:57:25.207657 11428 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1012 21:57:25.207666 11428 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1012 21:57:25.207895 11428 net.cpp:122] Setting up SoftmaxWithLoss1
I1012 21:57:25.207904 11428 net.cpp:129] Top shape: (1)
I1012 21:57:25.207911 11428 net.cpp:132]     with loss weight 1
I1012 21:57:25.207921 11428 net.cpp:137] Memory required for data: 1847135804
I1012 21:57:25.207938 11428 layer_factory.hpp:77] Creating layer accuracy
I1012 21:57:25.207948 11428 net.cpp:84] Creating Layer accuracy
I1012 21:57:25.207953 11428 net.cpp:406] accuracy <- InnerProduct1_InnerProduct1_0_split_1
I1012 21:57:25.207960 11428 net.cpp:406] accuracy <- label_cifar_1_split_1
I1012 21:57:25.207968 11428 net.cpp:380] accuracy -> accuracy
I1012 21:57:25.207978 11428 net.cpp:122] Setting up accuracy
I1012 21:57:25.207984 11428 net.cpp:129] Top shape: (1)
I1012 21:57:25.207989 11428 net.cpp:137] Memory required for data: 1847135808
I1012 21:57:25.207995 11428 net.cpp:200] accuracy does not need backward computation.
I1012 21:57:25.208001 11428 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1012 21:57:25.208008 11428 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1012 21:57:25.208014 11428 net.cpp:198] InnerProduct1 needs backward computation.
I1012 21:57:25.208019 11428 net.cpp:198] Pooling1 needs backward computation.
I1012 21:57:25.208024 11428 net.cpp:198] Eltwise12 needs backward computation.
I1012 21:57:25.208029 11428 net.cpp:198] Convolution28 needs backward computation.
I1012 21:57:25.208035 11428 net.cpp:198] ReLU22 needs backward computation.
I1012 21:57:25.208040 11428 net.cpp:198] Scale22 needs backward computation.
I1012 21:57:25.208045 11428 net.cpp:198] BatchNorm22 needs backward computation.
I1012 21:57:25.208050 11428 net.cpp:198] Convolution27 needs backward computation.
I1012 21:57:25.208056 11428 net.cpp:198] Eltwise11_ReLU21_0_split needs backward computation.
I1012 21:57:25.208062 11428 net.cpp:198] ReLU21 needs backward computation.
I1012 21:57:25.208067 11428 net.cpp:198] Scale21 needs backward computation.
I1012 21:57:25.208072 11428 net.cpp:198] BatchNorm21 needs backward computation.
I1012 21:57:25.208077 11428 net.cpp:198] Eltwise11 needs backward computation.
I1012 21:57:25.208084 11428 net.cpp:198] Convolution26 needs backward computation.
I1012 21:57:25.208089 11428 net.cpp:198] ReLU20 needs backward computation.
I1012 21:57:25.208094 11428 net.cpp:198] Scale20 needs backward computation.
I1012 21:57:25.208101 11428 net.cpp:198] BatchNorm20 needs backward computation.
I1012 21:57:25.208106 11428 net.cpp:198] Convolution25 needs backward computation.
I1012 21:57:25.208111 11428 net.cpp:198] Eltwise10_ReLU19_0_split needs backward computation.
I1012 21:57:25.208117 11428 net.cpp:198] ReLU19 needs backward computation.
I1012 21:57:25.208122 11428 net.cpp:198] Scale19 needs backward computation.
I1012 21:57:25.208127 11428 net.cpp:198] BatchNorm19 needs backward computation.
I1012 21:57:25.208132 11428 net.cpp:198] Eltwise10 needs backward computation.
I1012 21:57:25.208137 11428 net.cpp:198] Convolution24 needs backward computation.
I1012 21:57:25.208142 11428 net.cpp:198] ReLU18 needs backward computation.
I1012 21:57:25.208148 11428 net.cpp:198] Scale18 needs backward computation.
I1012 21:57:25.208153 11428 net.cpp:198] BatchNorm18 needs backward computation.
I1012 21:57:25.208158 11428 net.cpp:198] Convolution23 needs backward computation.
I1012 21:57:25.208163 11428 net.cpp:198] Eltwise9_ReLU17_0_split needs backward computation.
I1012 21:57:25.208169 11428 net.cpp:198] ReLU17 needs backward computation.
I1012 21:57:25.208174 11428 net.cpp:198] Scale17 needs backward computation.
I1012 21:57:25.208179 11428 net.cpp:198] BatchNorm17 needs backward computation.
I1012 21:57:25.208184 11428 net.cpp:198] Eltwise9 needs backward computation.
I1012 21:57:25.208190 11428 net.cpp:198] Convolution22 needs backward computation.
I1012 21:57:25.208196 11428 net.cpp:198] Convolution21 needs backward computation.
I1012 21:57:25.208201 11428 net.cpp:198] ReLU16 needs backward computation.
I1012 21:57:25.208206 11428 net.cpp:198] Scale16 needs backward computation.
I1012 21:57:25.208212 11428 net.cpp:198] BatchNorm16 needs backward computation.
I1012 21:57:25.208217 11428 net.cpp:198] Convolution20 needs backward computation.
I1012 21:57:25.208222 11428 net.cpp:198] Eltwise8_Eltwise8_0_split needs backward computation.
I1012 21:57:25.208228 11428 net.cpp:198] Eltwise8 needs backward computation.
I1012 21:57:25.208240 11428 net.cpp:198] Convolution19 needs backward computation.
I1012 21:57:25.208245 11428 net.cpp:198] ReLU15 needs backward computation.
I1012 21:57:25.208251 11428 net.cpp:198] Scale15 needs backward computation.
I1012 21:57:25.208256 11428 net.cpp:198] BatchNorm15 needs backward computation.
I1012 21:57:25.208261 11428 net.cpp:198] Convolution18 needs backward computation.
I1012 21:57:25.208267 11428 net.cpp:198] Eltwise7_ReLU14_0_split needs backward computation.
I1012 21:57:25.208272 11428 net.cpp:198] ReLU14 needs backward computation.
I1012 21:57:25.208278 11428 net.cpp:198] Scale14 needs backward computation.
I1012 21:57:25.208283 11428 net.cpp:198] BatchNorm14 needs backward computation.
I1012 21:57:25.208288 11428 net.cpp:198] Eltwise7 needs backward computation.
I1012 21:57:25.208294 11428 net.cpp:198] Convolution17 needs backward computation.
I1012 21:57:25.208299 11428 net.cpp:198] ReLU13 needs backward computation.
I1012 21:57:25.208304 11428 net.cpp:198] Scale13 needs backward computation.
I1012 21:57:25.208309 11428 net.cpp:198] BatchNorm13 needs backward computation.
I1012 21:57:25.208315 11428 net.cpp:198] Convolution16 needs backward computation.
I1012 21:57:25.208320 11428 net.cpp:198] Eltwise6_ReLU12_0_split needs backward computation.
I1012 21:57:25.208326 11428 net.cpp:198] ReLU12 needs backward computation.
I1012 21:57:25.208331 11428 net.cpp:198] Scale12 needs backward computation.
I1012 21:57:25.208336 11428 net.cpp:198] BatchNorm12 needs backward computation.
I1012 21:57:25.208341 11428 net.cpp:198] Eltwise6 needs backward computation.
I1012 21:57:25.208348 11428 net.cpp:198] Convolution15 needs backward computation.
I1012 21:57:25.208353 11428 net.cpp:198] ReLU11 needs backward computation.
I1012 21:57:25.208358 11428 net.cpp:198] Scale11 needs backward computation.
I1012 21:57:25.208362 11428 net.cpp:198] BatchNorm11 needs backward computation.
I1012 21:57:25.208369 11428 net.cpp:198] Convolution14 needs backward computation.
I1012 21:57:25.208374 11428 net.cpp:198] Eltwise5_ReLU10_0_split needs backward computation.
I1012 21:57:25.208379 11428 net.cpp:198] ReLU10 needs backward computation.
I1012 21:57:25.208384 11428 net.cpp:198] Scale10 needs backward computation.
I1012 21:57:25.208389 11428 net.cpp:198] BatchNorm10 needs backward computation.
I1012 21:57:25.208395 11428 net.cpp:198] Eltwise5 needs backward computation.
I1012 21:57:25.208401 11428 net.cpp:198] Convolution13 needs backward computation.
I1012 21:57:25.208406 11428 net.cpp:198] Convolution12 needs backward computation.
I1012 21:57:25.208411 11428 net.cpp:198] ReLU9 needs backward computation.
I1012 21:57:25.208416 11428 net.cpp:198] Scale9 needs backward computation.
I1012 21:57:25.208422 11428 net.cpp:198] BatchNorm9 needs backward computation.
I1012 21:57:25.208427 11428 net.cpp:198] Convolution11 needs backward computation.
I1012 21:57:25.208432 11428 net.cpp:198] Eltwise4_Eltwise4_0_split needs backward computation.
I1012 21:57:25.208438 11428 net.cpp:198] Eltwise4 needs backward computation.
I1012 21:57:25.208443 11428 net.cpp:198] Convolution10 needs backward computation.
I1012 21:57:25.208449 11428 net.cpp:198] ReLU8 needs backward computation.
I1012 21:57:25.208454 11428 net.cpp:198] Scale8 needs backward computation.
I1012 21:57:25.208461 11428 net.cpp:198] BatchNorm8 needs backward computation.
I1012 21:57:25.208465 11428 net.cpp:198] Convolution9 needs backward computation.
I1012 21:57:25.208472 11428 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1012 21:57:25.208477 11428 net.cpp:198] ReLU7 needs backward computation.
I1012 21:57:25.208482 11428 net.cpp:198] Scale7 needs backward computation.
I1012 21:57:25.208487 11428 net.cpp:198] BatchNorm7 needs backward computation.
I1012 21:57:25.208492 11428 net.cpp:198] Eltwise3 needs backward computation.
I1012 21:57:25.208498 11428 net.cpp:198] Convolution8 needs backward computation.
I1012 21:57:25.208503 11428 net.cpp:198] ReLU6 needs backward computation.
I1012 21:57:25.208508 11428 net.cpp:198] Scale6 needs backward computation.
I1012 21:57:25.208518 11428 net.cpp:198] BatchNorm6 needs backward computation.
I1012 21:57:25.208523 11428 net.cpp:198] Convolution7 needs backward computation.
I1012 21:57:25.208529 11428 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1012 21:57:25.208534 11428 net.cpp:198] ReLU5 needs backward computation.
I1012 21:57:25.208539 11428 net.cpp:198] Scale5 needs backward computation.
I1012 21:57:25.208544 11428 net.cpp:198] BatchNorm5 needs backward computation.
I1012 21:57:25.208550 11428 net.cpp:198] Eltwise2 needs backward computation.
I1012 21:57:25.208556 11428 net.cpp:198] Convolution6 needs backward computation.
I1012 21:57:25.208561 11428 net.cpp:198] ReLU4 needs backward computation.
I1012 21:57:25.208566 11428 net.cpp:198] Scale4 needs backward computation.
I1012 21:57:25.208571 11428 net.cpp:198] BatchNorm4 needs backward computation.
I1012 21:57:25.208576 11428 net.cpp:198] Convolution5 needs backward computation.
I1012 21:57:25.208582 11428 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1012 21:57:25.208587 11428 net.cpp:198] ReLU3 needs backward computation.
I1012 21:57:25.208593 11428 net.cpp:198] Scale3 needs backward computation.
I1012 21:57:25.208598 11428 net.cpp:198] BatchNorm3 needs backward computation.
I1012 21:57:25.208603 11428 net.cpp:198] Eltwise1 needs backward computation.
I1012 21:57:25.208609 11428 net.cpp:198] Convolution4 needs backward computation.
I1012 21:57:25.208616 11428 net.cpp:198] Convolution3 needs backward computation.
I1012 21:57:25.208621 11428 net.cpp:198] ReLU2 needs backward computation.
I1012 21:57:25.208626 11428 net.cpp:198] Scale2 needs backward computation.
I1012 21:57:25.208631 11428 net.cpp:198] BatchNorm2 needs backward computation.
I1012 21:57:25.208636 11428 net.cpp:198] Convolution2 needs backward computation.
I1012 21:57:25.208642 11428 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1012 21:57:25.208647 11428 net.cpp:198] ReLU1 needs backward computation.
I1012 21:57:25.208652 11428 net.cpp:198] Scale1 needs backward computation.
I1012 21:57:25.208657 11428 net.cpp:198] BatchNorm1 needs backward computation.
I1012 21:57:25.208662 11428 net.cpp:198] Convolution1 needs backward computation.
I1012 21:57:25.208668 11428 net.cpp:200] label_cifar_1_split does not need backward computation.
I1012 21:57:25.208674 11428 net.cpp:200] cifar does not need backward computation.
I1012 21:57:25.208679 11428 net.cpp:242] This network produces output SoftmaxWithLoss1
I1012 21:57:25.208684 11428 net.cpp:242] This network produces output accuracy
I1012 21:57:25.208734 11428 net.cpp:255] Network initialization done.
I1012 21:57:25.209018 11428 solver.cpp:56] Solver scaffolding done.
I1012 21:57:25.213346 11428 caffe.cpp:248] Starting Optimization
I1012 21:57:25.213354 11428 solver.cpp:272] Solving wrn_28_10
I1012 21:57:25.213361 11428 solver.cpp:273] Learning Rate Policy: multistep
I1012 21:57:25.551359 11428 solver.cpp:218] Iteration 0 (0.67357 iter/s, 0.337973s/100 iters), loss = 4.60517
I1012 21:57:25.551393 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 4.60517 (* 1 = 4.60517 loss)
I1012 21:57:25.551419 11428 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1012 21:57:53.370158 11428 solver.cpp:218] Iteration 100 (3.59471 iter/s, 27.8187s/100 iters), loss = 4.19523
I1012 21:57:53.370321 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 4.19523 (* 1 = 4.19523 loss)
I1012 21:57:53.370328 11428 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1012 21:58:21.475266 11428 solver.cpp:218] Iteration 200 (3.5581 iter/s, 28.1049s/100 iters), loss = 4.07277
I1012 21:58:21.475298 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 4.07277 (* 1 = 4.07277 loss)
I1012 21:58:21.475306 11428 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1012 21:58:50.002256 11428 solver.cpp:218] Iteration 300 (3.50546 iter/s, 28.5269s/100 iters), loss = 4.11246
I1012 21:58:50.002408 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 4.11246 (* 1 = 4.11246 loss)
I1012 21:58:50.002418 11428 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1012 21:59:18.770555 11428 solver.cpp:218] Iteration 400 (3.47607 iter/s, 28.7681s/100 iters), loss = 3.74645
I1012 21:59:18.770586 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.74645 (* 1 = 3.74645 loss)
I1012 21:59:18.770593 11428 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1012 21:59:47.309697 11428 solver.cpp:330] Iteration 500, Testing net (#0)
I1012 22:00:02.625972 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:00:02.942765 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 3.53875 (* 1 = 3.53875 loss)
I1012 22:00:02.942783 11428 solver.cpp:397]     Test net output #1: accuracy = 0.1537
I1012 22:00:03.227003 11428 solver.cpp:218] Iteration 500 (2.2494 iter/s, 44.4563s/100 iters), loss = 3.64104
I1012 22:00:03.227035 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.64104 (* 1 = 3.64104 loss)
I1012 22:00:03.227044 11428 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1012 22:00:32.177726 11428 solver.cpp:218] Iteration 600 (3.45415 iter/s, 28.9506s/100 iters), loss = 3.548
I1012 22:00:32.177803 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.548 (* 1 = 3.548 loss)
I1012 22:00:32.177822 11428 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1012 22:01:01.174772 11428 solver.cpp:218] Iteration 700 (3.44864 iter/s, 28.9969s/100 iters), loss = 2.90173
I1012 22:01:01.174805 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.90173 (* 1 = 2.90173 loss)
I1012 22:01:01.174813 11428 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1012 22:01:30.272511 11428 solver.cpp:218] Iteration 800 (3.4367 iter/s, 29.0977s/100 iters), loss = 2.80285
I1012 22:01:30.272655 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.80285 (* 1 = 2.80285 loss)
I1012 22:01:30.272665 11428 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1012 22:01:59.399590 11428 solver.cpp:218] Iteration 900 (3.43325 iter/s, 29.1269s/100 iters), loss = 2.84878
I1012 22:01:59.399632 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.84878 (* 1 = 2.84878 loss)
I1012 22:01:59.399639 11428 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1012 22:02:27.066691 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:02:28.233847 11428 solver.cpp:330] Iteration 1000, Testing net (#0)
I1012 22:02:43.658345 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:02:43.973598 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.94946 (* 1 = 2.94946 loss)
I1012 22:02:43.973614 11428 solver.cpp:397]     Test net output #1: accuracy = 0.2537
I1012 22:02:44.262065 11428 solver.cpp:218] Iteration 1000 (2.22904 iter/s, 44.8624s/100 iters), loss = 2.59162
I1012 22:02:44.262102 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.59162 (* 1 = 2.59162 loss)
I1012 22:02:44.262111 11428 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1012 22:03:13.539757 11428 solver.cpp:218] Iteration 1100 (3.41558 iter/s, 29.2776s/100 iters), loss = 2.85038
I1012 22:03:13.539902 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.85038 (* 1 = 2.85038 loss)
I1012 22:03:13.539912 11428 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1012 22:03:42.823441 11428 solver.cpp:218] Iteration 1200 (3.41489 iter/s, 29.2835s/100 iters), loss = 2.76963
I1012 22:03:42.823472 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.76963 (* 1 = 2.76963 loss)
I1012 22:03:42.823479 11428 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1012 22:04:12.198495 11428 solver.cpp:218] Iteration 1300 (3.40425 iter/s, 29.375s/100 iters), loss = 2.70132
I1012 22:04:12.198606 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.70132 (* 1 = 2.70132 loss)
I1012 22:04:12.198614 11428 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1012 22:04:41.593941 11428 solver.cpp:218] Iteration 1400 (3.4019 iter/s, 29.3953s/100 iters), loss = 2.45706
I1012 22:04:41.593973 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.45706 (* 1 = 2.45706 loss)
I1012 22:04:41.593981 11428 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1012 22:05:10.694653 11428 solver.cpp:330] Iteration 1500, Testing net (#0)
I1012 22:05:26.275255 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:05:26.594482 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.58428 (* 1 = 2.58428 loss)
I1012 22:05:26.594498 11428 solver.cpp:397]     Test net output #1: accuracy = 0.3261
I1012 22:05:26.883029 11428 solver.cpp:218] Iteration 1500 (2.20804 iter/s, 45.289s/100 iters), loss = 2.5281
I1012 22:05:26.883060 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.5281 (* 1 = 2.5281 loss)
I1012 22:05:26.883069 11428 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1012 22:05:56.283278 11428 solver.cpp:218] Iteration 1600 (3.40134 iter/s, 29.4002s/100 iters), loss = 2.5847
I1012 22:05:56.283418 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.5847 (* 1 = 2.5847 loss)
I1012 22:05:56.283427 11428 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1012 22:06:25.727547 11428 solver.cpp:218] Iteration 1700 (3.39626 iter/s, 29.4441s/100 iters), loss = 2.53862
I1012 22:06:25.727578 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.53862 (* 1 = 2.53862 loss)
I1012 22:06:25.727586 11428 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1012 22:06:55.152043 11428 solver.cpp:218] Iteration 1800 (3.39853 iter/s, 29.4245s/100 iters), loss = 1.87692
I1012 22:06:55.152180 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.87692 (* 1 = 1.87692 loss)
I1012 22:06:55.152191 11428 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1012 22:07:24.671262 11428 solver.cpp:218] Iteration 1900 (3.38764 iter/s, 29.5191s/100 iters), loss = 2.2784
I1012 22:07:24.671293 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.2784 (* 1 = 2.2784 loss)
I1012 22:07:24.671301 11428 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1012 22:07:52.729609 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:07:53.928076 11428 solver.cpp:330] Iteration 2000, Testing net (#0)
I1012 22:08:09.568987 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:08:09.890873 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.29654 (* 1 = 2.29654 loss)
I1012 22:08:09.890892 11428 solver.cpp:397]     Test net output #1: accuracy = 0.3909
I1012 22:08:10.183550 11428 solver.cpp:218] Iteration 2000 (2.19721 iter/s, 45.5123s/100 iters), loss = 1.88118
I1012 22:08:10.183583 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.88118 (* 1 = 1.88118 loss)
I1012 22:08:10.183591 11428 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1012 22:08:39.707164 11428 solver.cpp:218] Iteration 2100 (3.38712 iter/s, 29.5236s/100 iters), loss = 2.08435
I1012 22:08:39.707260 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.08435 (* 1 = 2.08435 loss)
I1012 22:08:39.707278 11428 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1012 22:09:09.256198 11428 solver.cpp:218] Iteration 2200 (3.38422 iter/s, 29.5489s/100 iters), loss = 2.22757
I1012 22:09:09.256229 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.22757 (* 1 = 2.22757 loss)
I1012 22:09:09.256237 11428 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1012 22:09:38.826531 11428 solver.cpp:218] Iteration 2300 (3.38177 iter/s, 29.5703s/100 iters), loss = 2.27624
I1012 22:09:38.826673 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.27624 (* 1 = 2.27624 loss)
I1012 22:09:38.826694 11428 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1012 22:10:08.401865 11428 solver.cpp:218] Iteration 2400 (3.38121 iter/s, 29.5752s/100 iters), loss = 1.92988
I1012 22:10:08.401899 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.92988 (* 1 = 1.92988 loss)
I1012 22:10:08.401906 11428 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1012 22:10:37.972139 11428 solver.cpp:330] Iteration 2500, Testing net (#0)
I1012 22:10:53.911898 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:10:54.233093 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.1149 (* 1 = 2.1149 loss)
I1012 22:10:54.233147 11428 solver.cpp:397]     Test net output #1: accuracy = 0.4255
I1012 22:10:54.521798 11428 solver.cpp:218] Iteration 2500 (2.16826 iter/s, 46.1199s/100 iters), loss = 1.88168
I1012 22:10:54.521914 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.88168 (* 1 = 1.88168 loss)
I1012 22:10:54.521942 11428 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1012 22:11:24.502902 11428 solver.cpp:218] Iteration 2600 (3.33545 iter/s, 29.981s/100 iters), loss = 2.06935
I1012 22:11:24.503034 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.06935 (* 1 = 2.06935 loss)
I1012 22:11:24.503054 11428 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1012 22:11:54.640100 11428 solver.cpp:218] Iteration 2700 (3.31817 iter/s, 30.1371s/100 iters), loss = 1.85615
I1012 22:11:54.640208 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.85615 (* 1 = 1.85615 loss)
I1012 22:11:54.640228 11428 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1012 22:12:24.279067 11428 solver.cpp:218] Iteration 2800 (3.37395 iter/s, 29.6389s/100 iters), loss = 1.47688
I1012 22:12:24.279099 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.47688 (* 1 = 1.47688 loss)
I1012 22:12:24.279106 11428 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1012 22:12:53.911084 11428 solver.cpp:218] Iteration 2900 (3.37473 iter/s, 29.632s/100 iters), loss = 1.93278
I1012 22:12:53.911224 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.93278 (* 1 = 1.93278 loss)
I1012 22:12:53.911232 11428 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1012 22:13:22.056397 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:13:23.248613 11428 solver.cpp:330] Iteration 3000, Testing net (#0)
I1012 22:13:38.975013 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:13:39.295781 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.96664 (* 1 = 1.96664 loss)
I1012 22:13:39.295797 11428 solver.cpp:397]     Test net output #1: accuracy = 0.4658
I1012 22:13:39.588086 11428 solver.cpp:218] Iteration 3000 (2.18929 iter/s, 45.6769s/100 iters), loss = 1.44297
I1012 22:13:39.588131 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.44297 (* 1 = 1.44297 loss)
I1012 22:13:39.588140 11428 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1012 22:14:09.221654 11428 solver.cpp:218] Iteration 3100 (3.37457 iter/s, 29.6334s/100 iters), loss = 1.81031
I1012 22:14:09.221767 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.81031 (* 1 = 1.81031 loss)
I1012 22:14:09.221787 11428 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1012 22:14:38.875746 11428 solver.cpp:218] Iteration 3200 (3.37223 iter/s, 29.654s/100 iters), loss = 1.89634
I1012 22:14:38.875778 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.89634 (* 1 = 1.89634 loss)
I1012 22:14:38.875787 11428 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1012 22:15:08.494436 11428 solver.cpp:218] Iteration 3300 (3.37625 iter/s, 29.6187s/100 iters), loss = 1.98281
I1012 22:15:08.494570 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.98281 (* 1 = 1.98281 loss)
I1012 22:15:08.494580 11428 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1012 22:15:38.154006 11428 solver.cpp:218] Iteration 3400 (3.37161 iter/s, 29.6594s/100 iters), loss = 1.65962
I1012 22:15:38.154047 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.65962 (* 1 = 1.65962 loss)
I1012 22:15:38.154055 11428 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1012 22:16:07.510870 11428 solver.cpp:330] Iteration 3500, Testing net (#0)
I1012 22:16:23.246314 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:16:23.567185 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.89498 (* 1 = 1.89498 loss)
I1012 22:16:23.567200 11428 solver.cpp:397]     Test net output #1: accuracy = 0.481
I1012 22:16:23.858700 11428 solver.cpp:218] Iteration 3500 (2.18796 iter/s, 45.7047s/100 iters), loss = 1.55137
I1012 22:16:23.858734 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55137 (* 1 = 1.55137 loss)
I1012 22:16:23.858752 11428 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1012 22:16:53.518682 11428 solver.cpp:218] Iteration 3600 (3.37155 iter/s, 29.66s/100 iters), loss = 1.75201
I1012 22:16:53.518820 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.75201 (* 1 = 1.75201 loss)
I1012 22:16:53.518828 11428 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1012 22:17:23.185775 11428 solver.cpp:218] Iteration 3700 (3.37075 iter/s, 29.667s/100 iters), loss = 1.67853
I1012 22:17:23.185806 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.67853 (* 1 = 1.67853 loss)
I1012 22:17:23.185813 11428 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1012 22:17:52.868897 11428 solver.cpp:218] Iteration 3800 (3.36892 iter/s, 29.6831s/100 iters), loss = 1.17482
I1012 22:17:52.869014 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17482 (* 1 = 1.17482 loss)
I1012 22:17:52.869021 11428 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1012 22:18:22.504354 11428 solver.cpp:218] Iteration 3900 (3.37435 iter/s, 29.6354s/100 iters), loss = 1.63743
I1012 22:18:22.504385 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.63743 (* 1 = 1.63743 loss)
I1012 22:18:22.504392 11428 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1012 22:18:50.684603 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:18:51.867641 11428 solver.cpp:330] Iteration 4000, Testing net (#0)
I1012 22:19:07.579390 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:19:07.900014 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.80853 (* 1 = 1.80853 loss)
I1012 22:19:07.900032 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5016
I1012 22:19:08.190152 11428 solver.cpp:218] Iteration 4000 (2.18886 iter/s, 45.6858s/100 iters), loss = 1.35471
I1012 22:19:08.190187 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.35471 (* 1 = 1.35471 loss)
I1012 22:19:08.190194 11428 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1012 22:19:37.877408 11428 solver.cpp:218] Iteration 4100 (3.36845 iter/s, 29.6872s/100 iters), loss = 1.71291
I1012 22:19:37.877508 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.71291 (* 1 = 1.71291 loss)
I1012 22:19:37.877526 11428 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1012 22:20:07.529289 11428 solver.cpp:218] Iteration 4200 (3.37248 iter/s, 29.6518s/100 iters), loss = 1.6451
I1012 22:20:07.529320 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.6451 (* 1 = 1.6451 loss)
I1012 22:20:07.529327 11428 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1012 22:20:37.209688 11428 solver.cpp:218] Iteration 4300 (3.36923 iter/s, 29.6804s/100 iters), loss = 1.64122
I1012 22:20:37.209839 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.64122 (* 1 = 1.64122 loss)
I1012 22:20:37.209847 11428 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1012 22:21:06.916545 11428 solver.cpp:218] Iteration 4400 (3.36624 iter/s, 29.7067s/100 iters), loss = 1.51513
I1012 22:21:06.916579 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.51513 (* 1 = 1.51513 loss)
I1012 22:21:06.916586 11428 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1012 22:21:36.264138 11428 solver.cpp:330] Iteration 4500, Testing net (#0)
I1012 22:21:51.952481 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:21:52.273049 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.75638 (* 1 = 1.75638 loss)
I1012 22:21:52.273066 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5164
I1012 22:21:52.562831 11428 solver.cpp:218] Iteration 4500 (2.19076 iter/s, 45.6463s/100 iters), loss = 1.31914
I1012 22:21:52.562863 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31914 (* 1 = 1.31914 loss)
I1012 22:21:52.562871 11428 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1012 22:22:22.219398 11428 solver.cpp:218] Iteration 4600 (3.37194 iter/s, 29.6565s/100 iters), loss = 1.59502
I1012 22:22:22.219532 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.59502 (* 1 = 1.59502 loss)
I1012 22:22:22.219550 11428 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1012 22:22:51.898479 11428 solver.cpp:218] Iteration 4700 (3.36939 iter/s, 29.679s/100 iters), loss = 1.31747
I1012 22:22:51.898510 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31747 (* 1 = 1.31747 loss)
I1012 22:22:51.898517 11428 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1012 22:23:21.579921 11428 solver.cpp:218] Iteration 4800 (3.36911 iter/s, 29.6814s/100 iters), loss = 1.00794
I1012 22:23:21.580063 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00794 (* 1 = 1.00794 loss)
I1012 22:23:21.580073 11428 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1012 22:23:51.329193 11428 solver.cpp:218] Iteration 4900 (3.36144 iter/s, 29.7491s/100 iters), loss = 1.42837
I1012 22:23:51.329226 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.42837 (* 1 = 1.42837 loss)
I1012 22:23:51.329232 11428 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1012 22:24:19.538822 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:24:20.721680 11428 solver.cpp:330] Iteration 5000, Testing net (#0)
I1012 22:24:36.469159 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:24:36.791579 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.66886 (* 1 = 1.66886 loss)
I1012 22:24:36.791594 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5426
I1012 22:24:37.084375 11428 solver.cpp:218] Iteration 5000 (2.18555 iter/s, 45.7552s/100 iters), loss = 1.12252
I1012 22:24:37.084405 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12252 (* 1 = 1.12252 loss)
I1012 22:24:37.084414 11428 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1012 22:25:06.800052 11428 solver.cpp:218] Iteration 5100 (3.36525 iter/s, 29.7155s/100 iters), loss = 1.43398
I1012 22:25:06.800199 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.43398 (* 1 = 1.43398 loss)
I1012 22:25:06.800207 11428 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1012 22:25:36.504675 11428 solver.cpp:218] Iteration 5200 (3.36649 iter/s, 29.7045s/100 iters), loss = 1.36138
I1012 22:25:36.504709 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.36138 (* 1 = 1.36138 loss)
I1012 22:25:36.504717 11428 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1012 22:26:06.217031 11428 solver.cpp:218] Iteration 5300 (3.36561 iter/s, 29.7123s/100 iters), loss = 1.43089
I1012 22:26:06.218819 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.43089 (* 1 = 1.43089 loss)
I1012 22:26:06.218848 11428 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1012 22:26:35.958396 11428 solver.cpp:218] Iteration 5400 (3.36252 iter/s, 29.7396s/100 iters), loss = 1.25279
I1012 22:26:35.958428 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25279 (* 1 = 1.25279 loss)
I1012 22:26:35.958436 11428 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1012 22:27:05.389439 11428 solver.cpp:330] Iteration 5500, Testing net (#0)
I1012 22:27:21.127966 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:27:21.449569 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.666 (* 1 = 1.666 loss)
I1012 22:27:21.449586 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5403
I1012 22:27:21.743142 11428 solver.cpp:218] Iteration 5500 (2.18413 iter/s, 45.7847s/100 iters), loss = 1.3156
I1012 22:27:21.743177 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.3156 (* 1 = 1.3156 loss)
I1012 22:27:21.743187 11428 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1012 22:27:51.410154 11428 solver.cpp:218] Iteration 5600 (3.37075 iter/s, 29.667s/100 iters), loss = 1.39971
I1012 22:27:51.410279 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.39971 (* 1 = 1.39971 loss)
I1012 22:27:51.410290 11428 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1012 22:28:21.095170 11428 solver.cpp:218] Iteration 5700 (3.36872 iter/s, 29.6849s/100 iters), loss = 1.12475
I1012 22:28:21.095207 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12475 (* 1 = 1.12475 loss)
I1012 22:28:21.095217 11428 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1012 22:28:50.801841 11428 solver.cpp:218] Iteration 5800 (3.36625 iter/s, 29.7066s/100 iters), loss = 1.00796
I1012 22:28:50.801950 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00796 (* 1 = 1.00796 loss)
I1012 22:28:50.801964 11428 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1012 22:29:20.456176 11428 solver.cpp:218] Iteration 5900 (3.3722 iter/s, 29.6542s/100 iters), loss = 1.23046
I1012 22:29:20.456209 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.23046 (* 1 = 1.23046 loss)
I1012 22:29:20.456219 11428 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1012 22:29:48.694481 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:29:49.885107 11428 solver.cpp:330] Iteration 6000, Testing net (#0)
I1012 22:30:05.602588 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:30:05.925979 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58111 (* 1 = 1.58111 loss)
I1012 22:30:05.925995 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5631
I1012 22:30:06.218421 11428 solver.cpp:218] Iteration 6000 (2.18521 iter/s, 45.7622s/100 iters), loss = 0.935187
I1012 22:30:06.218462 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.935187 (* 1 = 0.935187 loss)
I1012 22:30:06.218473 11428 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1012 22:30:35.993068 11428 solver.cpp:218] Iteration 6100 (3.35857 iter/s, 29.7746s/100 iters), loss = 1.3507
I1012 22:30:35.993192 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.3507 (* 1 = 1.3507 loss)
I1012 22:30:35.993204 11428 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1012 22:31:05.739112 11428 solver.cpp:218] Iteration 6200 (3.3618 iter/s, 29.7459s/100 iters), loss = 1.1537
I1012 22:31:05.739151 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.1537 (* 1 = 1.1537 loss)
I1012 22:31:05.739159 11428 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1012 22:31:35.430742 11428 solver.cpp:218] Iteration 6300 (3.36796 iter/s, 29.6916s/100 iters), loss = 1.31582
I1012 22:31:35.431259 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31582 (* 1 = 1.31582 loss)
I1012 22:31:35.431268 11428 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1012 22:32:05.167141 11428 solver.cpp:218] Iteration 6400 (3.36294 iter/s, 29.7359s/100 iters), loss = 1.35334
I1012 22:32:05.167178 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.35334 (* 1 = 1.35334 loss)
I1012 22:32:05.167187 11428 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1012 22:32:34.566227 11428 solver.cpp:330] Iteration 6500, Testing net (#0)
I1012 22:32:50.269140 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:32:50.589745 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5843 (* 1 = 1.5843 loss)
I1012 22:32:50.589762 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5682
I1012 22:32:50.880798 11428 solver.cpp:218] Iteration 6500 (2.18753 iter/s, 45.7136s/100 iters), loss = 1.00667
I1012 22:32:50.880847 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00667 (* 1 = 1.00667 loss)
I1012 22:32:50.880870 11428 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1012 22:33:20.583315 11428 solver.cpp:218] Iteration 6600 (3.36672 iter/s, 29.7025s/100 iters), loss = 1.24054
I1012 22:33:20.583427 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.24054 (* 1 = 1.24054 loss)
I1012 22:33:20.583434 11428 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1012 22:33:50.331243 11428 solver.cpp:218] Iteration 6700 (3.36159 iter/s, 29.7478s/100 iters), loss = 1.15437
I1012 22:33:50.331276 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15437 (* 1 = 1.15437 loss)
I1012 22:33:50.331284 11428 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1012 22:34:20.014760 11428 solver.cpp:218] Iteration 6800 (3.36888 iter/s, 29.6835s/100 iters), loss = 0.850954
I1012 22:34:20.014894 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.850954 (* 1 = 0.850954 loss)
I1012 22:34:20.014904 11428 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1012 22:34:49.686224 11428 solver.cpp:218] Iteration 6900 (3.37026 iter/s, 29.6713s/100 iters), loss = 1.30541
I1012 22:34:49.686256 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.30541 (* 1 = 1.30541 loss)
I1012 22:34:49.686262 11428 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1012 22:35:17.866533 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:35:19.051698 11428 solver.cpp:330] Iteration 7000, Testing net (#0)
I1012 22:35:34.770800 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:35:35.093840 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54545 (* 1 = 1.54545 loss)
I1012 22:35:35.093858 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5738
I1012 22:35:35.387002 11428 solver.cpp:218] Iteration 7000 (2.18815 iter/s, 45.7008s/100 iters), loss = 0.928698
I1012 22:35:35.387037 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.928698 (* 1 = 0.928698 loss)
I1012 22:35:35.387045 11428 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1012 22:36:05.057569 11428 solver.cpp:218] Iteration 7100 (3.37035 iter/s, 29.6705s/100 iters), loss = 1.12531
I1012 22:36:05.057718 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12531 (* 1 = 1.12531 loss)
I1012 22:36:05.057739 11428 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1012 22:36:34.740236 11428 solver.cpp:218] Iteration 7200 (3.36898 iter/s, 29.6825s/100 iters), loss = 1.00279
I1012 22:36:34.740268 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00279 (* 1 = 1.00279 loss)
I1012 22:36:34.740275 11428 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1012 22:37:04.387300 11428 solver.cpp:218] Iteration 7300 (3.37302 iter/s, 29.647s/100 iters), loss = 1.25987
I1012 22:37:04.387398 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25987 (* 1 = 1.25987 loss)
I1012 22:37:04.387405 11428 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1012 22:37:34.117566 11428 solver.cpp:218] Iteration 7400 (3.36359 iter/s, 29.7302s/100 iters), loss = 0.983498
I1012 22:37:34.117599 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.983498 (* 1 = 0.983498 loss)
I1012 22:37:34.117606 11428 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1012 22:38:03.503564 11428 solver.cpp:330] Iteration 7500, Testing net (#0)
I1012 22:38:19.199862 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:38:19.520397 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55674 (* 1 = 1.55674 loss)
I1012 22:38:19.520413 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5782
I1012 22:38:19.811944 11428 solver.cpp:218] Iteration 7500 (2.18845 iter/s, 45.6944s/100 iters), loss = 0.995262
I1012 22:38:19.811982 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.995262 (* 1 = 0.995262 loss)
I1012 22:38:19.811990 11428 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1012 22:38:49.520279 11428 solver.cpp:218] Iteration 7600 (3.36607 iter/s, 29.7083s/100 iters), loss = 1.15269
I1012 22:38:49.520418 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.15269 (* 1 = 1.15269 loss)
I1012 22:38:49.520428 11428 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1012 22:39:19.213788 11428 solver.cpp:218] Iteration 7700 (3.36775 iter/s, 29.6934s/100 iters), loss = 1.03652
I1012 22:39:19.213825 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03652 (* 1 = 1.03652 loss)
I1012 22:39:19.213832 11428 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1012 22:39:48.901057 11428 solver.cpp:218] Iteration 7800 (3.36845 iter/s, 29.6872s/100 iters), loss = 0.767263
I1012 22:39:48.901219 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.767263 (* 1 = 0.767263 loss)
I1012 22:39:48.901228 11428 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1012 22:40:18.538722 11428 solver.cpp:218] Iteration 7900 (3.3741 iter/s, 29.6375s/100 iters), loss = 1.1544
I1012 22:40:18.538753 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.1544 (* 1 = 1.1544 loss)
I1012 22:40:18.538761 11428 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1012 22:40:46.745456 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:40:47.933727 11428 solver.cpp:330] Iteration 8000, Testing net (#0)
I1012 22:41:03.667075 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:41:03.988220 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.45558 (* 1 = 1.45558 loss)
I1012 22:41:03.988237 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5973
I1012 22:41:04.281684 11428 solver.cpp:218] Iteration 8000 (2.18613 iter/s, 45.7429s/100 iters), loss = 0.717248
I1012 22:41:04.281725 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.717248 (* 1 = 0.717248 loss)
I1012 22:41:04.281734 11428 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1012 22:41:33.988644 11428 solver.cpp:218] Iteration 8100 (3.36625 iter/s, 29.7067s/100 iters), loss = 1.09977
I1012 22:41:33.988752 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09977 (* 1 = 1.09977 loss)
I1012 22:41:33.988759 11428 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1012 22:42:03.662556 11428 solver.cpp:218] Iteration 8200 (3.36997 iter/s, 29.6738s/100 iters), loss = 0.804439
I1012 22:42:03.662588 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.804439 (* 1 = 0.804439 loss)
I1012 22:42:03.662596 11428 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1012 22:42:33.357038 11428 solver.cpp:218] Iteration 8300 (3.36763 iter/s, 29.6945s/100 iters), loss = 1.02524
I1012 22:42:33.357175 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02524 (* 1 = 1.02524 loss)
I1012 22:42:33.357183 11428 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1012 22:43:03.081116 11428 solver.cpp:218] Iteration 8400 (3.36429 iter/s, 29.7239s/100 iters), loss = 0.850855
I1012 22:43:03.081149 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.850855 (* 1 = 0.850855 loss)
I1012 22:43:03.081157 11428 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1012 22:43:32.543227 11428 solver.cpp:330] Iteration 8500, Testing net (#0)
I1012 22:43:48.238296 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:43:48.559908 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.506 (* 1 = 1.506 loss)
I1012 22:43:48.559926 11428 solver.cpp:397]     Test net output #1: accuracy = 0.5847
I1012 22:43:48.852891 11428 solver.cpp:218] Iteration 8500 (2.18475 iter/s, 45.7718s/100 iters), loss = 1.14702
I1012 22:43:48.852929 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14702 (* 1 = 1.14702 loss)
I1012 22:43:48.852938 11428 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1012 22:44:18.534318 11428 solver.cpp:218] Iteration 8600 (3.36914 iter/s, 29.6811s/100 iters), loss = 1.09416
I1012 22:44:18.534457 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09416 (* 1 = 1.09416 loss)
I1012 22:44:18.534466 11428 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1012 22:44:48.218446 11428 solver.cpp:218] Iteration 8700 (3.36882 iter/s, 29.684s/100 iters), loss = 0.952349
I1012 22:44:48.218478 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.952349 (* 1 = 0.952349 loss)
I1012 22:44:48.218485 11428 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1012 22:45:17.892607 11428 solver.cpp:218] Iteration 8800 (3.36994 iter/s, 29.6741s/100 iters), loss = 0.633494
I1012 22:45:17.892710 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.633494 (* 1 = 0.633494 loss)
I1012 22:45:17.892719 11428 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1012 22:45:47.595968 11428 solver.cpp:218] Iteration 8900 (3.36663 iter/s, 29.7033s/100 iters), loss = 1.03231
I1012 22:45:47.595998 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03231 (* 1 = 1.03231 loss)
I1012 22:45:47.596004 11428 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1012 22:46:15.893506 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:46:17.084568 11428 solver.cpp:330] Iteration 9000, Testing net (#0)
I1012 22:46:32.769248 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:46:33.089965 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.43998 (* 1 = 1.43998 loss)
I1012 22:46:33.089982 11428 solver.cpp:397]     Test net output #1: accuracy = 0.603
I1012 22:46:33.380802 11428 solver.cpp:218] Iteration 9000 (2.18413 iter/s, 45.7848s/100 iters), loss = 0.680345
I1012 22:46:33.380836 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.680345 (* 1 = 0.680345 loss)
I1012 22:46:33.380843 11428 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1012 22:47:03.086207 11428 solver.cpp:218] Iteration 9100 (3.3664 iter/s, 29.7053s/100 iters), loss = 1.09251
I1012 22:47:03.086335 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09251 (* 1 = 1.09251 loss)
I1012 22:47:03.086344 11428 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1012 22:47:32.784039 11428 solver.cpp:218] Iteration 9200 (3.36726 iter/s, 29.6977s/100 iters), loss = 0.799912
I1012 22:47:32.784070 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.799912 (* 1 = 0.799912 loss)
I1012 22:47:32.784077 11428 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1012 22:48:02.491065 11428 solver.cpp:218] Iteration 9300 (3.36621 iter/s, 29.707s/100 iters), loss = 1.0599
I1012 22:48:02.491204 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.0599 (* 1 = 1.0599 loss)
I1012 22:48:02.491214 11428 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1012 22:48:32.214223 11428 solver.cpp:218] Iteration 9400 (3.36439 iter/s, 29.723s/100 iters), loss = 1.03314
I1012 22:48:32.214256 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03314 (* 1 = 1.03314 loss)
I1012 22:48:32.214262 11428 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1012 22:49:01.572584 11428 solver.cpp:330] Iteration 9500, Testing net (#0)
I1012 22:49:17.265601 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:49:17.586882 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48482 (* 1 = 1.48482 loss)
I1012 22:49:17.586899 11428 solver.cpp:397]     Test net output #1: accuracy = 0.601
I1012 22:49:17.877177 11428 solver.cpp:218] Iteration 9500 (2.18996 iter/s, 45.6629s/100 iters), loss = 0.948787
I1012 22:49:17.877218 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.948787 (* 1 = 0.948787 loss)
I1012 22:49:17.877226 11428 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I1012 22:49:47.597048 11428 solver.cpp:218] Iteration 9600 (3.36476 iter/s, 29.7198s/100 iters), loss = 1.12029
I1012 22:49:47.597146 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12029 (* 1 = 1.12029 loss)
I1012 22:49:47.597163 11428 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I1012 22:50:17.285871 11428 solver.cpp:218] Iteration 9700 (3.36828 iter/s, 29.6887s/100 iters), loss = 0.959397
I1012 22:50:17.285902 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.959398 (* 1 = 0.959398 loss)
I1012 22:50:17.285909 11428 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I1012 22:50:46.963207 11428 solver.cpp:218] Iteration 9800 (3.36958 iter/s, 29.6773s/100 iters), loss = 0.693885
I1012 22:50:46.963351 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.693885 (* 1 = 0.693885 loss)
I1012 22:50:46.963361 11428 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I1012 22:51:16.643512 11428 solver.cpp:218] Iteration 9900 (3.36925 iter/s, 29.6802s/100 iters), loss = 1.06595
I1012 22:51:16.643543 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06595 (* 1 = 1.06595 loss)
I1012 22:51:16.643550 11428 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I1012 22:51:44.850153 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:51:46.030295 11428 solver.cpp:330] Iteration 10000, Testing net (#0)
I1012 22:52:01.721324 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:52:02.041813 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44719 (* 1 = 1.44719 loss)
I1012 22:52:02.041829 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6055
I1012 22:52:02.334623 11428 solver.cpp:218] Iteration 10000 (2.18861 iter/s, 45.6911s/100 iters), loss = 0.610391
I1012 22:52:02.334689 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.610391 (* 1 = 0.610391 loss)
I1012 22:52:02.334697 11428 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I1012 22:52:31.987673 11428 solver.cpp:218] Iteration 10100 (3.37235 iter/s, 29.6529s/100 iters), loss = 0.983671
I1012 22:52:31.987789 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.983671 (* 1 = 0.983671 loss)
I1012 22:52:31.987797 11428 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I1012 22:53:01.668671 11428 solver.cpp:218] Iteration 10200 (3.36917 iter/s, 29.6809s/100 iters), loss = 0.936409
I1012 22:53:01.668701 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.936409 (* 1 = 0.936409 loss)
I1012 22:53:01.668709 11428 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I1012 22:53:31.365880 11428 solver.cpp:218] Iteration 10300 (3.36732 iter/s, 29.6972s/100 iters), loss = 0.89422
I1012 22:53:31.366017 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.89422 (* 1 = 0.89422 loss)
I1012 22:53:31.366037 11428 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I1012 22:54:01.030272 11428 solver.cpp:218] Iteration 10400 (3.37106 iter/s, 29.6643s/100 iters), loss = 0.785175
I1012 22:54:01.030305 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.785175 (* 1 = 0.785175 loss)
I1012 22:54:01.030313 11428 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I1012 22:54:30.387060 11428 solver.cpp:330] Iteration 10500, Testing net (#0)
I1012 22:54:46.064288 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:54:46.383649 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.46637 (* 1 = 1.46637 loss)
I1012 22:54:46.383666 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6101
I1012 22:54:46.675485 11428 solver.cpp:218] Iteration 10500 (2.19081 iter/s, 45.6452s/100 iters), loss = 0.974683
I1012 22:54:46.675535 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.974683 (* 1 = 0.974683 loss)
I1012 22:54:46.675552 11428 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I1012 22:55:16.331529 11428 solver.cpp:218] Iteration 10600 (3.372 iter/s, 29.656s/100 iters), loss = 0.850257
I1012 22:55:16.331620 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.850257 (* 1 = 0.850257 loss)
I1012 22:55:16.331629 11428 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I1012 22:55:45.989028 11428 solver.cpp:218] Iteration 10700 (3.37184 iter/s, 29.6574s/100 iters), loss = 0.804289
I1012 22:55:45.989058 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.804289 (* 1 = 0.804289 loss)
I1012 22:55:45.989066 11428 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I1012 22:56:15.644830 11428 solver.cpp:218] Iteration 10800 (3.37202 iter/s, 29.6558s/100 iters), loss = 0.754713
I1012 22:56:15.644942 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.754713 (* 1 = 0.754713 loss)
I1012 22:56:15.644949 11428 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I1012 22:56:45.276232 11428 solver.cpp:218] Iteration 10900 (3.37481 iter/s, 29.6313s/100 iters), loss = 0.72015
I1012 22:56:45.276268 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.72015 (* 1 = 0.72015 loss)
I1012 22:56:45.276275 11428 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I1012 22:57:13.470963 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:57:14.653313 11428 solver.cpp:330] Iteration 11000, Testing net (#0)
I1012 22:57:30.385607 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 22:57:30.705606 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44497 (* 1 = 1.44497 loss)
I1012 22:57:30.705621 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6065
I1012 22:57:30.996682 11428 solver.cpp:218] Iteration 11000 (2.18721 iter/s, 45.7204s/100 iters), loss = 0.566479
I1012 22:57:30.996717 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.566479 (* 1 = 0.566479 loss)
I1012 22:57:30.996726 11428 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I1012 22:58:00.682643 11428 solver.cpp:218] Iteration 11100 (3.3686 iter/s, 29.6859s/100 iters), loss = 0.781667
I1012 22:58:00.682783 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.781667 (* 1 = 0.781667 loss)
I1012 22:58:00.682792 11428 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I1012 22:58:30.327178 11428 solver.cpp:218] Iteration 11200 (3.37332 iter/s, 29.6444s/100 iters), loss = 0.840446
I1012 22:58:30.327214 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.840446 (* 1 = 0.840446 loss)
I1012 22:58:30.327221 11428 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I1012 22:59:00.021967 11428 solver.cpp:218] Iteration 11300 (3.3676 iter/s, 29.6948s/100 iters), loss = 0.771134
I1012 22:59:00.022111 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.771134 (* 1 = 0.771134 loss)
I1012 22:59:00.022121 11428 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I1012 22:59:29.675338 11428 solver.cpp:218] Iteration 11400 (3.37231 iter/s, 29.6532s/100 iters), loss = 0.800142
I1012 22:59:29.675382 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.800142 (* 1 = 0.800142 loss)
I1012 22:59:29.675390 11428 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I1012 22:59:59.075920 11428 solver.cpp:330] Iteration 11500, Testing net (#0)
I1012 23:00:14.757616 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:00:15.079066 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.4553 (* 1 = 1.4553 loss)
I1012 23:00:15.079092 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6114
I1012 23:00:15.373457 11428 solver.cpp:218] Iteration 11500 (2.18828 iter/s, 45.6981s/100 iters), loss = 0.863713
I1012 23:00:15.373494 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.863713 (* 1 = 0.863713 loss)
I1012 23:00:15.373502 11428 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I1012 23:00:44.993017 11428 solver.cpp:218] Iteration 11600 (3.37615 iter/s, 29.6195s/100 iters), loss = 0.88158
I1012 23:00:44.993099 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.88158 (* 1 = 0.88158 loss)
I1012 23:00:44.993116 11428 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I1012 23:01:14.607895 11428 solver.cpp:218] Iteration 11700 (3.37669 iter/s, 29.6148s/100 iters), loss = 0.688688
I1012 23:01:14.607928 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.688688 (* 1 = 0.688688 loss)
I1012 23:01:14.607936 11428 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I1012 23:01:44.225035 11428 solver.cpp:218] Iteration 11800 (3.37643 iter/s, 29.6171s/100 iters), loss = 0.580049
I1012 23:01:44.225148 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.580048 (* 1 = 0.580048 loss)
I1012 23:01:44.225167 11428 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I1012 23:02:13.852344 11428 solver.cpp:218] Iteration 11900 (3.37528 iter/s, 29.6272s/100 iters), loss = 0.815209
I1012 23:02:13.852375 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.815209 (* 1 = 0.815209 loss)
I1012 23:02:13.852382 11428 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I1012 23:02:42.044807 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:02:43.248374 11428 solver.cpp:330] Iteration 12000, Testing net (#0)
I1012 23:02:58.952839 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:02:59.272297 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.45165 (* 1 = 1.45165 loss)
I1012 23:02:59.272315 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6115
I1012 23:02:59.562638 11428 solver.cpp:218] Iteration 12000 (2.18769 iter/s, 45.7103s/100 iters), loss = 0.583805
I1012 23:02:59.562669 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583805 (* 1 = 0.583805 loss)
I1012 23:02:59.562677 11428 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I1012 23:03:29.225402 11428 solver.cpp:218] Iteration 12100 (3.37123 iter/s, 29.6627s/100 iters), loss = 0.94719
I1012 23:03:29.225514 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.94719 (* 1 = 0.94719 loss)
I1012 23:03:29.225522 11428 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I1012 23:03:58.854567 11428 solver.cpp:218] Iteration 12200 (3.37506 iter/s, 29.6291s/100 iters), loss = 0.574636
I1012 23:03:58.854598 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.574635 (* 1 = 0.574635 loss)
I1012 23:03:58.854605 11428 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I1012 23:04:28.552577 11428 solver.cpp:218] Iteration 12300 (3.36723 iter/s, 29.698s/100 iters), loss = 0.811685
I1012 23:04:28.552728 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.811685 (* 1 = 0.811685 loss)
I1012 23:04:28.552738 11428 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I1012 23:04:58.220482 11428 solver.cpp:218] Iteration 12400 (3.37066 iter/s, 29.6678s/100 iters), loss = 0.76284
I1012 23:04:58.220515 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.76284 (* 1 = 0.76284 loss)
I1012 23:04:58.220521 11428 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I1012 23:05:27.557981 11428 solver.cpp:330] Iteration 12500, Testing net (#0)
I1012 23:05:43.308428 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:05:43.630456 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48225 (* 1 = 1.48225 loss)
I1012 23:05:43.630472 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6148
I1012 23:05:43.922664 11428 solver.cpp:218] Iteration 12500 (2.18808 iter/s, 45.7022s/100 iters), loss = 0.938552
I1012 23:05:43.922698 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.938552 (* 1 = 0.938552 loss)
I1012 23:05:43.922716 11428 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I1012 23:06:13.553081 11428 solver.cpp:218] Iteration 12600 (3.37493 iter/s, 29.6302s/100 iters), loss = 0.692517
I1012 23:06:13.553218 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.692517 (* 1 = 0.692517 loss)
I1012 23:06:13.553227 11428 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I1012 23:06:43.198431 11428 solver.cpp:218] Iteration 12700 (3.37322 iter/s, 29.6452s/100 iters), loss = 0.626446
I1012 23:06:43.198462 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.626446 (* 1 = 0.626446 loss)
I1012 23:06:43.198469 11428 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I1012 23:07:12.817543 11428 solver.cpp:218] Iteration 12800 (3.3762 iter/s, 29.6191s/100 iters), loss = 0.479917
I1012 23:07:12.817648 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479917 (* 1 = 0.479917 loss)
I1012 23:07:12.817656 11428 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I1012 23:07:42.464951 11428 solver.cpp:218] Iteration 12900 (3.37299 iter/s, 29.6473s/100 iters), loss = 0.797428
I1012 23:07:42.464982 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.797428 (* 1 = 0.797428 loss)
I1012 23:07:42.464989 11428 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I1012 23:08:10.608892 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:08:11.784641 11428 solver.cpp:330] Iteration 13000, Testing net (#0)
I1012 23:08:27.472223 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:08:27.793720 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44708 (* 1 = 1.44708 loss)
I1012 23:08:27.793735 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6204
I1012 23:08:28.086058 11428 solver.cpp:218] Iteration 13000 (2.19197 iter/s, 45.6211s/100 iters), loss = 0.436905
I1012 23:08:28.086138 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436905 (* 1 = 0.436905 loss)
I1012 23:08:28.086154 11428 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I1012 23:08:57.725832 11428 solver.cpp:218] Iteration 13100 (3.37388 iter/s, 29.6394s/100 iters), loss = 0.719621
I1012 23:08:57.725946 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.719621 (* 1 = 0.719621 loss)
I1012 23:08:57.725955 11428 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I1012 23:09:27.320747 11428 solver.cpp:218] Iteration 13200 (3.37897 iter/s, 29.5948s/100 iters), loss = 0.755308
I1012 23:09:27.320778 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.755308 (* 1 = 0.755308 loss)
I1012 23:09:27.320786 11428 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I1012 23:09:56.956135 11428 solver.cpp:218] Iteration 13300 (3.37435 iter/s, 29.6354s/100 iters), loss = 0.498799
I1012 23:09:56.956295 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498799 (* 1 = 0.498799 loss)
I1012 23:09:56.956305 11428 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I1012 23:10:26.585552 11428 solver.cpp:218] Iteration 13400 (3.37504 iter/s, 29.6293s/100 iters), loss = 0.544299
I1012 23:10:26.585582 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.544299 (* 1 = 0.544299 loss)
I1012 23:10:26.585589 11428 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I1012 23:10:55.951774 11428 solver.cpp:330] Iteration 13500, Testing net (#0)
I1012 23:11:11.588912 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:11:11.910207 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.47015 (* 1 = 1.47015 loss)
I1012 23:11:11.910223 11428 solver.cpp:397]     Test net output #1: accuracy = 0.617
I1012 23:11:12.200918 11428 solver.cpp:218] Iteration 13500 (2.19224 iter/s, 45.6154s/100 iters), loss = 0.767273
I1012 23:11:12.200954 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.767273 (* 1 = 0.767273 loss)
I1012 23:11:12.200961 11428 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I1012 23:11:41.856845 11428 solver.cpp:218] Iteration 13600 (3.37201 iter/s, 29.6559s/100 iters), loss = 0.65979
I1012 23:11:41.856950 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.65979 (* 1 = 0.65979 loss)
I1012 23:11:41.856957 11428 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I1012 23:12:11.491698 11428 solver.cpp:218] Iteration 13700 (3.37442 iter/s, 29.6348s/100 iters), loss = 0.517897
I1012 23:12:11.491730 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.517897 (* 1 = 0.517897 loss)
I1012 23:12:11.491739 11428 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I1012 23:12:41.119652 11428 solver.cpp:218] Iteration 13800 (3.37519 iter/s, 29.6279s/100 iters), loss = 0.402069
I1012 23:12:41.119793 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402069 (* 1 = 0.402069 loss)
I1012 23:12:41.119803 11428 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I1012 23:13:10.776298 11428 solver.cpp:218] Iteration 13900 (3.37194 iter/s, 29.6565s/100 iters), loss = 0.880557
I1012 23:13:10.776329 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.880558 (* 1 = 0.880558 loss)
I1012 23:13:10.776335 11428 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I1012 23:13:38.874235 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:13:40.066272 11428 solver.cpp:330] Iteration 14000, Testing net (#0)
I1012 23:13:55.733047 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:13:56.054582 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44097 (* 1 = 1.44097 loss)
I1012 23:13:56.054600 11428 solver.cpp:397]     Test net output #1: accuracy = 0.626
I1012 23:13:56.347625 11428 solver.cpp:218] Iteration 14000 (2.19436 iter/s, 45.5713s/100 iters), loss = 0.446463
I1012 23:13:56.347663 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446464 (* 1 = 0.446464 loss)
I1012 23:13:56.347683 11428 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I1012 23:14:25.990072 11428 solver.cpp:218] Iteration 14100 (3.37358 iter/s, 29.6421s/100 iters), loss = 0.583687
I1012 23:14:25.990233 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583688 (* 1 = 0.583688 loss)
I1012 23:14:25.990243 11428 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I1012 23:14:55.617280 11428 solver.cpp:218] Iteration 14200 (3.37529 iter/s, 29.6271s/100 iters), loss = 0.784685
I1012 23:14:55.617311 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.784685 (* 1 = 0.784685 loss)
I1012 23:14:55.617319 11428 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I1012 23:15:25.237895 11428 solver.cpp:218] Iteration 14300 (3.37603 iter/s, 29.6206s/100 iters), loss = 0.584055
I1012 23:15:25.238006 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.584055 (* 1 = 0.584055 loss)
I1012 23:15:25.238015 11428 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I1012 23:15:54.836565 11428 solver.cpp:218] Iteration 14400 (3.37854 iter/s, 29.5986s/100 iters), loss = 0.583207
I1012 23:15:54.836598 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583207 (* 1 = 0.583207 loss)
I1012 23:15:54.836606 11428 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I1012 23:16:24.169783 11428 solver.cpp:330] Iteration 14500, Testing net (#0)
I1012 23:16:39.887568 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:16:40.206454 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48486 (* 1 = 1.48486 loss)
I1012 23:16:40.206473 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6212
I1012 23:16:40.497437 11428 solver.cpp:218] Iteration 14500 (2.19006 iter/s, 45.6609s/100 iters), loss = 0.682343
I1012 23:16:40.497483 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.682343 (* 1 = 0.682343 loss)
I1012 23:16:40.497490 11428 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I1012 23:17:10.130367 11428 solver.cpp:218] Iteration 14600 (3.37463 iter/s, 29.6329s/100 iters), loss = 0.62529
I1012 23:17:10.130455 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.62529 (* 1 = 0.62529 loss)
I1012 23:17:10.130478 11428 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I1012 23:17:39.801734 11428 solver.cpp:218] Iteration 14700 (3.37026 iter/s, 29.6713s/100 iters), loss = 0.512563
I1012 23:17:39.801767 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512564 (* 1 = 0.512564 loss)
I1012 23:17:39.801774 11428 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I1012 23:18:09.433692 11428 solver.cpp:218] Iteration 14800 (3.37474 iter/s, 29.6319s/100 iters), loss = 0.627465
I1012 23:18:09.433801 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.627465 (* 1 = 0.627465 loss)
I1012 23:18:09.433810 11428 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I1012 23:18:39.142277 11428 solver.cpp:218] Iteration 14900 (3.36604 iter/s, 29.7085s/100 iters), loss = 0.724381
I1012 23:18:39.142308 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.724381 (* 1 = 0.724381 loss)
I1012 23:18:39.142315 11428 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I1012 23:19:07.319244 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:19:08.499560 11428 solver.cpp:330] Iteration 15000, Testing net (#0)
I1012 23:19:24.210135 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:19:24.532816 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.42336 (* 1 = 1.42336 loss)
I1012 23:19:24.532832 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6344
I1012 23:19:24.826339 11428 solver.cpp:218] Iteration 15000 (2.18895 iter/s, 45.684s/100 iters), loss = 0.383315
I1012 23:19:24.826391 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383315 (* 1 = 0.383315 loss)
I1012 23:19:24.826409 11428 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I1012 23:19:54.440053 11428 solver.cpp:218] Iteration 15100 (3.37682 iter/s, 29.6137s/100 iters), loss = 0.478646
I1012 23:19:54.440219 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.478646 (* 1 = 0.478646 loss)
I1012 23:19:54.440230 11428 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I1012 23:20:24.060276 11428 solver.cpp:218] Iteration 15200 (3.37609 iter/s, 29.6201s/100 iters), loss = 0.43164
I1012 23:20:24.060308 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43164 (* 1 = 0.43164 loss)
I1012 23:20:24.060315 11428 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I1012 23:20:53.697988 11428 solver.cpp:218] Iteration 15300 (3.37408 iter/s, 29.6377s/100 iters), loss = 0.603696
I1012 23:20:53.698088 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603696 (* 1 = 0.603696 loss)
I1012 23:20:53.698096 11428 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I1012 23:21:23.273947 11428 solver.cpp:218] Iteration 15400 (3.38113 iter/s, 29.5759s/100 iters), loss = 0.533629
I1012 23:21:23.273978 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.533629 (* 1 = 0.533629 loss)
I1012 23:21:23.273986 11428 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I1012 23:21:52.594992 11428 solver.cpp:330] Iteration 15500, Testing net (#0)
I1012 23:22:08.330276 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:22:08.652405 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50707 (* 1 = 1.50707 loss)
I1012 23:22:08.652421 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6173
I1012 23:22:08.945317 11428 solver.cpp:218] Iteration 15500 (2.18956 iter/s, 45.6714s/100 iters), loss = 0.825239
I1012 23:22:08.945353 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.825239 (* 1 = 0.825239 loss)
I1012 23:22:08.945360 11428 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I1012 23:22:38.585196 11428 solver.cpp:218] Iteration 15600 (3.37386 iter/s, 29.6397s/100 iters), loss = 0.688558
I1012 23:22:38.585335 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.688558 (* 1 = 0.688558 loss)
I1012 23:22:38.585343 11428 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I1012 23:23:08.211526 11428 solver.cpp:218] Iteration 15700 (3.37539 iter/s, 29.6262s/100 iters), loss = 0.671888
I1012 23:23:08.211560 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.671888 (* 1 = 0.671888 loss)
I1012 23:23:08.211566 11428 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I1012 23:23:37.887018 11428 solver.cpp:218] Iteration 15800 (3.36979 iter/s, 29.6755s/100 iters), loss = 0.363977
I1012 23:23:37.887162 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363977 (* 1 = 0.363977 loss)
I1012 23:23:37.887172 11428 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I1012 23:24:07.502514 11428 solver.cpp:218] Iteration 15900 (3.37663 iter/s, 29.6154s/100 iters), loss = 0.792644
I1012 23:24:07.502559 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.792644 (* 1 = 0.792644 loss)
I1012 23:24:07.502568 11428 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I1012 23:24:35.687058 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:24:36.891259 11428 solver.cpp:330] Iteration 16000, Testing net (#0)
I1012 23:24:52.509543 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:24:52.828603 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.4788 (* 1 = 1.4788 loss)
I1012 23:24:52.828620 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6312
I1012 23:24:53.120214 11428 solver.cpp:218] Iteration 16000 (2.19213 iter/s, 45.6177s/100 iters), loss = 0.291733
I1012 23:24:53.120249 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291733 (* 1 = 0.291733 loss)
I1012 23:24:53.120256 11428 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I1012 23:25:22.746402 11428 solver.cpp:218] Iteration 16100 (3.3754 iter/s, 29.6262s/100 iters), loss = 0.463997
I1012 23:25:22.746511 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463997 (* 1 = 0.463997 loss)
I1012 23:25:22.746520 11428 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I1012 23:25:52.370646 11428 solver.cpp:218] Iteration 16200 (3.37562 iter/s, 29.6242s/100 iters), loss = 0.391932
I1012 23:25:52.370688 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391932 (* 1 = 0.391932 loss)
I1012 23:25:52.370697 11428 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I1012 23:26:21.990754 11428 solver.cpp:218] Iteration 16300 (3.37609 iter/s, 29.6201s/100 iters), loss = 0.568378
I1012 23:26:21.990891 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.568379 (* 1 = 0.568379 loss)
I1012 23:26:21.990900 11428 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I1012 23:26:51.645589 11428 solver.cpp:218] Iteration 16400 (3.37214 iter/s, 29.6547s/100 iters), loss = 0.453101
I1012 23:26:51.645619 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453101 (* 1 = 0.453101 loss)
I1012 23:26:51.645625 11428 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I1012 23:27:21.019431 11428 solver.cpp:330] Iteration 16500, Testing net (#0)
I1012 23:27:36.685221 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:27:37.005815 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53108 (* 1 = 1.53108 loss)
I1012 23:27:37.005831 11428 solver.cpp:397]     Test net output #1: accuracy = 0.62
I1012 23:27:37.296043 11428 solver.cpp:218] Iteration 16500 (2.19056 iter/s, 45.6504s/100 iters), loss = 0.457457
I1012 23:27:37.296078 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457457 (* 1 = 0.457457 loss)
I1012 23:27:37.296087 11428 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I1012 23:28:06.947226 11428 solver.cpp:218] Iteration 16600 (3.37255 iter/s, 29.6512s/100 iters), loss = 0.714821
I1012 23:28:06.947367 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.714821 (* 1 = 0.714821 loss)
I1012 23:28:06.947377 11428 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I1012 23:28:36.588413 11428 solver.cpp:218] Iteration 16700 (3.3737 iter/s, 29.6411s/100 iters), loss = 0.402268
I1012 23:28:36.588444 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402268 (* 1 = 0.402268 loss)
I1012 23:28:36.588451 11428 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I1012 23:29:06.202374 11428 solver.cpp:218] Iteration 16800 (3.37679 iter/s, 29.6139s/100 iters), loss = 0.453444
I1012 23:29:06.202486 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453444 (* 1 = 0.453444 loss)
I1012 23:29:06.202504 11428 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I1012 23:29:35.814713 11428 solver.cpp:218] Iteration 16900 (3.37698 iter/s, 29.6122s/100 iters), loss = 0.553512
I1012 23:29:35.814744 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.553512 (* 1 = 0.553512 loss)
I1012 23:29:35.814752 11428 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I1012 23:30:04.015524 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:30:05.189561 11428 solver.cpp:330] Iteration 17000, Testing net (#0)
I1012 23:30:20.891315 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:30:21.211349 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48652 (* 1 = 1.48652 loss)
I1012 23:30:21.211366 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6249
I1012 23:30:21.503038 11428 solver.cpp:218] Iteration 17000 (2.18874 iter/s, 45.6883s/100 iters), loss = 0.350481
I1012 23:30:21.503073 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350481 (* 1 = 0.350481 loss)
I1012 23:30:21.503080 11428 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I1012 23:30:51.166205 11428 solver.cpp:218] Iteration 17100 (3.37119 iter/s, 29.6631s/100 iters), loss = 0.516868
I1012 23:30:51.166316 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.516868 (* 1 = 0.516868 loss)
I1012 23:30:51.166333 11428 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I1012 23:31:20.855981 11428 solver.cpp:218] Iteration 17200 (3.36817 iter/s, 29.6897s/100 iters), loss = 0.468676
I1012 23:31:20.856014 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468676 (* 1 = 0.468676 loss)
I1012 23:31:20.856021 11428 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I1012 23:31:50.500958 11428 solver.cpp:218] Iteration 17300 (3.37326 iter/s, 29.645s/100 iters), loss = 0.583797
I1012 23:31:50.501078 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.583797 (* 1 = 0.583797 loss)
I1012 23:31:50.501086 11428 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I1012 23:32:20.149688 11428 solver.cpp:218] Iteration 17400 (3.37284 iter/s, 29.6486s/100 iters), loss = 0.313998
I1012 23:32:20.149720 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313998 (* 1 = 0.313998 loss)
I1012 23:32:20.149729 11428 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I1012 23:32:49.522382 11428 solver.cpp:330] Iteration 17500, Testing net (#0)
I1012 23:33:05.162192 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:33:05.482586 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5332 (* 1 = 1.5332 loss)
I1012 23:33:05.482604 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6214
I1012 23:33:05.773609 11428 solver.cpp:218] Iteration 17500 (2.19183 iter/s, 45.6239s/100 iters), loss = 0.535315
I1012 23:33:05.773660 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535315 (* 1 = 0.535315 loss)
I1012 23:33:05.773684 11428 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I1012 23:33:35.472339 11428 solver.cpp:218] Iteration 17600 (3.36715 iter/s, 29.6987s/100 iters), loss = 0.633097
I1012 23:33:35.472486 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.633097 (* 1 = 0.633097 loss)
I1012 23:33:35.472496 11428 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I1012 23:34:05.144562 11428 solver.cpp:218] Iteration 17700 (3.37017 iter/s, 29.6721s/100 iters), loss = 0.506831
I1012 23:34:05.144595 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.506831 (* 1 = 0.506831 loss)
I1012 23:34:05.144603 11428 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I1012 23:34:34.808140 11428 solver.cpp:218] Iteration 17800 (3.37114 iter/s, 29.6636s/100 iters), loss = 0.404711
I1012 23:34:34.808282 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404711 (* 1 = 0.404711 loss)
I1012 23:34:34.808290 11428 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I1012 23:35:04.429813 11428 solver.cpp:218] Iteration 17900 (3.37592 iter/s, 29.6215s/100 iters), loss = 0.451881
I1012 23:35:04.429846 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451881 (* 1 = 0.451881 loss)
I1012 23:35:04.429853 11428 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I1012 23:35:32.645429 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:35:33.826766 11428 solver.cpp:330] Iteration 18000, Testing net (#0)
I1012 23:35:49.504890 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:35:49.824751 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44524 (* 1 = 1.44524 loss)
I1012 23:35:49.824767 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6349
I1012 23:35:50.119287 11428 solver.cpp:218] Iteration 18000 (2.18869 iter/s, 45.6895s/100 iters), loss = 0.375693
I1012 23:35:50.119323 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375693 (* 1 = 0.375693 loss)
I1012 23:35:50.119331 11428 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I1012 23:36:19.776393 11428 solver.cpp:218] Iteration 18100 (3.3719 iter/s, 29.6569s/100 iters), loss = 0.58997
I1012 23:36:19.776501 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.58997 (* 1 = 0.58997 loss)
I1012 23:36:19.776510 11428 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I1012 23:36:49.433452 11428 solver.cpp:218] Iteration 18200 (3.37189 iter/s, 29.657s/100 iters), loss = 0.425886
I1012 23:36:49.433485 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425887 (* 1 = 0.425887 loss)
I1012 23:36:49.433491 11428 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I1012 23:37:19.081457 11428 solver.cpp:218] Iteration 18300 (3.37291 iter/s, 29.648s/100 iters), loss = 0.56645
I1012 23:37:19.081629 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.56645 (* 1 = 0.56645 loss)
I1012 23:37:19.081638 11428 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I1012 23:37:48.716040 11428 solver.cpp:218] Iteration 18400 (3.37445 iter/s, 29.6344s/100 iters), loss = 0.5359
I1012 23:37:48.716070 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.5359 (* 1 = 0.5359 loss)
I1012 23:37:48.716078 11428 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I1012 23:38:18.048166 11428 solver.cpp:330] Iteration 18500, Testing net (#0)
I1012 23:38:33.723037 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:38:34.044570 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.52602 (* 1 = 1.52602 loss)
I1012 23:38:34.044587 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6319
I1012 23:38:34.336704 11428 solver.cpp:218] Iteration 18500 (2.19199 iter/s, 45.6207s/100 iters), loss = 0.740035
I1012 23:38:34.336735 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.740035 (* 1 = 0.740035 loss)
I1012 23:38:34.336743 11428 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I1012 23:39:03.940950 11428 solver.cpp:218] Iteration 18600 (3.3779 iter/s, 29.6042s/100 iters), loss = 0.686017
I1012 23:39:03.941094 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.686017 (* 1 = 0.686017 loss)
I1012 23:39:03.941104 11428 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I1012 23:39:33.598940 11428 solver.cpp:218] Iteration 18700 (3.37179 iter/s, 29.6579s/100 iters), loss = 0.532999
I1012 23:39:33.598971 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.532999 (* 1 = 0.532999 loss)
I1012 23:39:33.598978 11428 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I1012 23:40:03.234400 11428 solver.cpp:218] Iteration 18800 (3.37434 iter/s, 29.6354s/100 iters), loss = 0.330097
I1012 23:40:03.234546 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330097 (* 1 = 0.330097 loss)
I1012 23:40:03.234555 11428 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I1012 23:40:32.859743 11428 solver.cpp:218] Iteration 18900 (3.3755 iter/s, 29.6252s/100 iters), loss = 0.392902
I1012 23:40:32.859776 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392902 (* 1 = 0.392902 loss)
I1012 23:40:32.859784 11428 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I1012 23:41:01.024647 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:41:02.205746 11428 solver.cpp:330] Iteration 19000, Testing net (#0)
I1012 23:41:17.850620 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:41:18.173724 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50966 (* 1 = 1.50966 loss)
I1012 23:41:18.173753 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6351
I1012 23:41:18.464695 11428 solver.cpp:218] Iteration 19000 (2.19274 iter/s, 45.6049s/100 iters), loss = 0.387425
I1012 23:41:18.464730 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387425 (* 1 = 0.387425 loss)
I1012 23:41:18.464749 11428 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I1012 23:41:48.071338 11428 solver.cpp:218] Iteration 19100 (3.37766 iter/s, 29.6063s/100 iters), loss = 0.398931
I1012 23:41:48.071475 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398931 (* 1 = 0.398931 loss)
I1012 23:41:48.071485 11428 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I1012 23:42:17.689106 11428 solver.cpp:218] Iteration 19200 (3.37637 iter/s, 29.6176s/100 iters), loss = 0.439075
I1012 23:42:17.689138 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439075 (* 1 = 0.439075 loss)
I1012 23:42:17.689146 11428 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I1012 23:42:47.320130 11428 solver.cpp:218] Iteration 19300 (3.37484 iter/s, 29.631s/100 iters), loss = 0.451027
I1012 23:42:47.320276 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451027 (* 1 = 0.451027 loss)
I1012 23:42:47.320286 11428 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I1012 23:43:16.950354 11428 solver.cpp:218] Iteration 19400 (3.37495 iter/s, 29.6301s/100 iters), loss = 0.443886
I1012 23:43:16.950397 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443886 (* 1 = 0.443886 loss)
I1012 23:43:16.950403 11428 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I1012 23:43:46.253504 11428 solver.cpp:330] Iteration 19500, Testing net (#0)
I1012 23:44:01.876982 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:44:02.196084 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56307 (* 1 = 1.56307 loss)
I1012 23:44:02.196100 11428 solver.cpp:397]     Test net output #1: accuracy = 0.629
I1012 23:44:02.486557 11428 solver.cpp:218] Iteration 19500 (2.19606 iter/s, 45.5362s/100 iters), loss = 0.584546
I1012 23:44:02.486589 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.584546 (* 1 = 0.584546 loss)
I1012 23:44:02.486598 11428 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I1012 23:44:32.068462 11428 solver.cpp:218] Iteration 19600 (3.38045 iter/s, 29.5819s/100 iters), loss = 0.476184
I1012 23:44:32.068611 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476184 (* 1 = 0.476184 loss)
I1012 23:44:32.068622 11428 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I1012 23:45:01.674669 11428 solver.cpp:218] Iteration 19700 (3.37769 iter/s, 29.6061s/100 iters), loss = 0.313484
I1012 23:45:01.674700 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313484 (* 1 = 0.313484 loss)
I1012 23:45:01.674707 11428 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I1012 23:45:31.256454 11428 solver.cpp:218] Iteration 19800 (3.38046 iter/s, 29.5818s/100 iters), loss = 0.460139
I1012 23:45:31.256568 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46014 (* 1 = 0.46014 loss)
I1012 23:45:31.256577 11428 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I1012 23:46:00.862120 11428 solver.cpp:218] Iteration 19900 (3.37774 iter/s, 29.6056s/100 iters), loss = 0.486844
I1012 23:46:00.862152 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486844 (* 1 = 0.486844 loss)
I1012 23:46:00.862159 11428 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I1012 23:46:29.025565 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:46:30.205332 11428 solver.cpp:330] Iteration 20000, Testing net (#0)
I1012 23:46:45.819319 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:46:46.140483 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.49221 (* 1 = 1.49221 loss)
I1012 23:46:46.140499 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6421
I1012 23:46:46.431177 11428 solver.cpp:218] Iteration 20000 (2.19447 iter/s, 45.569s/100 iters), loss = 0.286452
I1012 23:46:46.431221 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286453 (* 1 = 0.286453 loss)
I1012 23:46:46.431236 11428 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I1012 23:47:16.098333 11428 solver.cpp:218] Iteration 20100 (3.37074 iter/s, 29.6671s/100 iters), loss = 0.335654
I1012 23:47:16.098482 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335654 (* 1 = 0.335654 loss)
I1012 23:47:16.098492 11428 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I1012 23:47:45.701658 11428 solver.cpp:218] Iteration 20200 (3.37801 iter/s, 29.6032s/100 iters), loss = 0.312998
I1012 23:47:45.701689 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312999 (* 1 = 0.312999 loss)
I1012 23:47:45.701697 11428 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I1012 23:48:15.315582 11428 solver.cpp:218] Iteration 20300 (3.37679 iter/s, 29.6139s/100 iters), loss = 0.513392
I1012 23:48:15.315744 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.513392 (* 1 = 0.513392 loss)
I1012 23:48:15.315765 11428 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I1012 23:48:44.945053 11428 solver.cpp:218] Iteration 20400 (3.37504 iter/s, 29.6293s/100 iters), loss = 0.415619
I1012 23:48:44.945086 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415619 (* 1 = 0.415619 loss)
I1012 23:48:44.945094 11428 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I1012 23:49:14.286583 11428 solver.cpp:330] Iteration 20500, Testing net (#0)
I1012 23:49:29.947378 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:49:30.268004 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60738 (* 1 = 1.60738 loss)
I1012 23:49:30.268031 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6237
I1012 23:49:30.559705 11428 solver.cpp:218] Iteration 20500 (2.19228 iter/s, 45.6146s/100 iters), loss = 0.439806
I1012 23:49:30.559742 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439807 (* 1 = 0.439807 loss)
I1012 23:49:30.559751 11428 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I1012 23:50:00.239565 11428 solver.cpp:218] Iteration 20600 (3.36929 iter/s, 29.6798s/100 iters), loss = 0.602178
I1012 23:50:00.239691 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.602178 (* 1 = 0.602178 loss)
I1012 23:50:00.239701 11428 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I1012 23:50:29.795498 11428 solver.cpp:218] Iteration 20700 (3.38343 iter/s, 29.5558s/100 iters), loss = 0.287053
I1012 23:50:29.795531 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287053 (* 1 = 0.287053 loss)
I1012 23:50:29.795537 11428 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I1012 23:50:59.362227 11428 solver.cpp:218] Iteration 20800 (3.38218 iter/s, 29.5667s/100 iters), loss = 0.391349
I1012 23:50:59.362357 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391349 (* 1 = 0.391349 loss)
I1012 23:50:59.362366 11428 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I1012 23:51:28.967130 11428 solver.cpp:218] Iteration 20900 (3.37783 iter/s, 29.6048s/100 iters), loss = 0.491981
I1012 23:51:28.967164 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.491982 (* 1 = 0.491982 loss)
I1012 23:51:28.967171 11428 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I1012 23:51:57.079591 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:51:58.269121 11428 solver.cpp:330] Iteration 21000, Testing net (#0)
I1012 23:52:13.946074 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:52:14.262871 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.52358 (* 1 = 1.52358 loss)
I1012 23:52:14.262887 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6374
I1012 23:52:14.553230 11428 solver.cpp:218] Iteration 21000 (2.19365 iter/s, 45.5861s/100 iters), loss = 0.158973
I1012 23:52:14.553261 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158974 (* 1 = 0.158974 loss)
I1012 23:52:14.553269 11428 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I1012 23:52:44.182566 11428 solver.cpp:218] Iteration 21100 (3.37504 iter/s, 29.6293s/100 iters), loss = 0.330856
I1012 23:52:44.182667 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330856 (* 1 = 0.330856 loss)
I1012 23:52:44.182674 11428 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I1012 23:53:13.817133 11428 solver.cpp:218] Iteration 21200 (3.37445 iter/s, 29.6345s/100 iters), loss = 0.427826
I1012 23:53:13.817168 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427826 (* 1 = 0.427826 loss)
I1012 23:53:13.817175 11428 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I1012 23:53:43.436995 11428 solver.cpp:218] Iteration 21300 (3.37612 iter/s, 29.6198s/100 iters), loss = 0.328231
I1012 23:53:43.437090 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328232 (* 1 = 0.328232 loss)
I1012 23:53:43.437099 11428 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I1012 23:54:13.023197 11428 solver.cpp:218] Iteration 21400 (3.37996 iter/s, 29.5861s/100 iters), loss = 0.24114
I1012 23:54:13.023229 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24114 (* 1 = 0.24114 loss)
I1012 23:54:13.023236 11428 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I1012 23:54:42.282575 11428 solver.cpp:330] Iteration 21500, Testing net (#0)
I1012 23:54:57.928643 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:54:58.249516 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63028 (* 1 = 1.63028 loss)
I1012 23:54:58.249531 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6256
I1012 23:54:58.542626 11428 solver.cpp:218] Iteration 21500 (2.19686 iter/s, 45.5194s/100 iters), loss = 0.358411
I1012 23:54:58.542659 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358412 (* 1 = 0.358412 loss)
I1012 23:54:58.542666 11428 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I1012 23:55:28.198784 11428 solver.cpp:218] Iteration 21600 (3.372 iter/s, 29.656s/100 iters), loss = 0.600794
I1012 23:55:28.198890 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.600794 (* 1 = 0.600794 loss)
I1012 23:55:28.198899 11428 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I1012 23:55:57.796561 11428 solver.cpp:218] Iteration 21700 (3.37864 iter/s, 29.5977s/100 iters), loss = 0.312601
I1012 23:55:57.796592 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312601 (* 1 = 0.312601 loss)
I1012 23:55:57.796600 11428 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I1012 23:56:27.409363 11428 solver.cpp:218] Iteration 21800 (3.37692 iter/s, 29.6128s/100 iters), loss = 0.317523
I1012 23:56:27.409500 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317523 (* 1 = 0.317523 loss)
I1012 23:56:27.409510 11428 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I1012 23:56:57.008235 11428 solver.cpp:218] Iteration 21900 (3.37852 iter/s, 29.5987s/100 iters), loss = 0.408746
I1012 23:56:57.008268 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408746 (* 1 = 0.408746 loss)
I1012 23:56:57.008275 11428 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I1012 23:57:25.104779 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:57:26.294901 11428 solver.cpp:330] Iteration 22000, Testing net (#0)
I1012 23:57:41.937860 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1012 23:57:42.263133 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5056 (* 1 = 1.5056 loss)
I1012 23:57:42.263149 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6458
I1012 23:57:42.557694 11428 solver.cpp:218] Iteration 22000 (2.19542 iter/s, 45.5494s/100 iters), loss = 0.305787
I1012 23:57:42.557729 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305787 (* 1 = 0.305787 loss)
I1012 23:57:42.557737 11428 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I1012 23:58:12.236116 11428 solver.cpp:218] Iteration 22100 (3.36945 iter/s, 29.6784s/100 iters), loss = 0.450062
I1012 23:58:12.236220 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450062 (* 1 = 0.450062 loss)
I1012 23:58:12.236229 11428 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I1012 23:58:41.868235 11428 solver.cpp:218] Iteration 22200 (3.37473 iter/s, 29.632s/100 iters), loss = 0.547325
I1012 23:58:41.868268 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.547325 (* 1 = 0.547325 loss)
I1012 23:58:41.868274 11428 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I1012 23:59:11.450793 11428 solver.cpp:218] Iteration 22300 (3.38037 iter/s, 29.5825s/100 iters), loss = 0.479248
I1012 23:59:11.450935 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479248 (* 1 = 0.479248 loss)
I1012 23:59:11.450945 11428 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I1012 23:59:41.070528 11428 solver.cpp:218] Iteration 22400 (3.37614 iter/s, 29.6196s/100 iters), loss = 0.319715
I1012 23:59:41.070561 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319716 (* 1 = 0.319716 loss)
I1012 23:59:41.070569 11428 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I1013 00:00:10.442369 11428 solver.cpp:330] Iteration 22500, Testing net (#0)
I1013 00:00:26.074151 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:00:26.395508 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55514 (* 1 = 1.55514 loss)
I1013 00:00:26.395524 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6352
I1013 00:00:26.687486 11428 solver.cpp:218] Iteration 22500 (2.19217 iter/s, 45.6169s/100 iters), loss = 0.407147
I1013 00:00:26.687544 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407148 (* 1 = 0.407148 loss)
I1013 00:00:26.687562 11428 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I1013 00:00:56.246937 11428 solver.cpp:218] Iteration 22600 (3.38303 iter/s, 29.5593s/100 iters), loss = 0.294716
I1013 00:00:56.247114 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294716 (* 1 = 0.294716 loss)
I1013 00:00:56.247125 11428 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I1013 00:01:25.839483 11428 solver.cpp:218] Iteration 22700 (3.37925 iter/s, 29.5924s/100 iters), loss = 0.414567
I1013 00:01:25.839515 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414568 (* 1 = 0.414568 loss)
I1013 00:01:25.839522 11428 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I1013 00:01:55.440286 11428 solver.cpp:218] Iteration 22800 (3.37829 iter/s, 29.6008s/100 iters), loss = 0.509003
I1013 00:01:55.440392 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509003 (* 1 = 0.509003 loss)
I1013 00:01:55.440412 11428 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I1013 00:02:25.040130 11428 solver.cpp:218] Iteration 22900 (3.37841 iter/s, 29.5998s/100 iters), loss = 0.383255
I1013 00:02:25.040163 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383255 (* 1 = 0.383255 loss)
I1013 00:02:25.040170 11428 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I1013 00:02:53.158494 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:02:54.340561 11428 solver.cpp:330] Iteration 23000, Testing net (#0)
I1013 00:03:10.005775 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:03:10.325815 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53599 (* 1 = 1.53599 loss)
I1013 00:03:10.325832 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6435
I1013 00:03:10.616947 11428 solver.cpp:218] Iteration 23000 (2.1941 iter/s, 45.5768s/100 iters), loss = 0.195846
I1013 00:03:10.616983 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195847 (* 1 = 0.195847 loss)
I1013 00:03:10.616991 11428 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I1013 00:03:40.255306 11428 solver.cpp:218] Iteration 23100 (3.37401 iter/s, 29.6383s/100 iters), loss = 0.311515
I1013 00:03:40.255394 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311516 (* 1 = 0.311516 loss)
I1013 00:03:40.255414 11428 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I1013 00:04:09.871065 11428 solver.cpp:218] Iteration 23200 (3.37659 iter/s, 29.6157s/100 iters), loss = 0.282908
I1013 00:04:09.871098 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282909 (* 1 = 0.282909 loss)
I1013 00:04:09.871107 11428 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I1013 00:04:39.445641 11428 solver.cpp:218] Iteration 23300 (3.38129 iter/s, 29.5746s/100 iters), loss = 0.409942
I1013 00:04:39.445791 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409942 (* 1 = 0.409942 loss)
I1013 00:04:39.445801 11428 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I1013 00:05:09.080253 11428 solver.cpp:218] Iteration 23400 (3.37445 iter/s, 29.6345s/100 iters), loss = 0.390605
I1013 00:05:09.080288 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390605 (* 1 = 0.390605 loss)
I1013 00:05:09.080296 11428 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I1013 00:05:38.397006 11428 solver.cpp:330] Iteration 23500, Testing net (#0)
I1013 00:05:54.007253 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:05:54.327105 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58298 (* 1 = 1.58298 loss)
I1013 00:05:54.327122 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6371
I1013 00:05:54.617986 11428 solver.cpp:218] Iteration 23500 (2.19598 iter/s, 45.5377s/100 iters), loss = 0.524763
I1013 00:05:54.618016 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524763 (* 1 = 0.524763 loss)
I1013 00:05:54.618026 11428 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I1013 00:06:24.203348 11428 solver.cpp:218] Iteration 23600 (3.38005 iter/s, 29.5853s/100 iters), loss = 0.466407
I1013 00:06:24.203517 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466408 (* 1 = 0.466408 loss)
I1013 00:06:24.203537 11428 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I1013 00:06:53.814085 11428 solver.cpp:218] Iteration 23700 (3.37717 iter/s, 29.6106s/100 iters), loss = 0.245015
I1013 00:06:53.814121 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245016 (* 1 = 0.245016 loss)
I1013 00:06:53.814129 11428 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I1013 00:07:23.408228 11428 solver.cpp:218] Iteration 23800 (3.37905 iter/s, 29.5941s/100 iters), loss = 0.354267
I1013 00:07:23.408331 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354268 (* 1 = 0.354268 loss)
I1013 00:07:23.408350 11428 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I1013 00:07:53.028995 11428 solver.cpp:218] Iteration 23900 (3.37602 iter/s, 29.6207s/100 iters), loss = 0.417277
I1013 00:07:53.029027 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417277 (* 1 = 0.417277 loss)
I1013 00:07:53.029036 11428 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I1013 00:08:21.113613 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:08:22.290607 11428 solver.cpp:330] Iteration 24000, Testing net (#0)
I1013 00:08:37.897374 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:08:38.218529 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50228 (* 1 = 1.50228 loss)
I1013 00:08:38.218545 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6497
I1013 00:08:38.509999 11428 solver.cpp:218] Iteration 24000 (2.19872 iter/s, 45.481s/100 iters), loss = 0.282135
I1013 00:08:38.510032 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282136 (* 1 = 0.282136 loss)
I1013 00:08:38.510040 11428 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I1013 00:09:08.139273 11428 solver.cpp:218] Iteration 24100 (3.37504 iter/s, 29.6292s/100 iters), loss = 0.355163
I1013 00:09:08.139420 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355163 (* 1 = 0.355163 loss)
I1013 00:09:08.139428 11428 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I1013 00:09:37.633199 11428 solver.cpp:218] Iteration 24200 (3.39054 iter/s, 29.4938s/100 iters), loss = 0.551518
I1013 00:09:37.633231 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.551518 (* 1 = 0.551518 loss)
I1013 00:09:37.633239 11428 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I1013 00:10:07.101786 11428 solver.cpp:218] Iteration 24300 (3.39345 iter/s, 29.4686s/100 iters), loss = 0.431288
I1013 00:10:07.101902 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431289 (* 1 = 0.431289 loss)
I1013 00:10:07.101912 11428 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I1013 00:10:36.592514 11428 solver.cpp:218] Iteration 24400 (3.39091 iter/s, 29.4906s/100 iters), loss = 0.426977
I1013 00:10:36.592547 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426978 (* 1 = 0.426978 loss)
I1013 00:10:36.592555 11428 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I1013 00:11:05.789484 11428 solver.cpp:330] Iteration 24500, Testing net (#0)
I1013 00:11:21.342183 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:11:21.660868 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54524 (* 1 = 1.54524 loss)
I1013 00:11:21.660886 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6401
I1013 00:11:21.948020 11428 solver.cpp:218] Iteration 24500 (2.2048 iter/s, 45.3555s/100 iters), loss = 0.319124
I1013 00:11:21.948056 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319125 (* 1 = 0.319125 loss)
I1013 00:11:21.948065 11428 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I1013 00:11:51.442457 11428 solver.cpp:218] Iteration 24600 (3.39047 iter/s, 29.4944s/100 iters), loss = 0.343439
I1013 00:11:51.442636 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34344 (* 1 = 0.34344 loss)
I1013 00:11:51.442647 11428 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I1013 00:12:20.946724 11428 solver.cpp:218] Iteration 24700 (3.38936 iter/s, 29.5041s/100 iters), loss = 0.410792
I1013 00:12:20.946758 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410793 (* 1 = 0.410793 loss)
I1013 00:12:20.946765 11428 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I1013 00:12:50.425417 11428 solver.cpp:218] Iteration 24800 (3.39228 iter/s, 29.4787s/100 iters), loss = 0.217617
I1013 00:12:50.425565 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217617 (* 1 = 0.217617 loss)
I1013 00:12:50.425575 11428 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I1013 00:13:19.921039 11428 solver.cpp:218] Iteration 24900 (3.39035 iter/s, 29.4955s/100 iters), loss = 0.252431
I1013 00:13:19.921072 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252432 (* 1 = 0.252432 loss)
I1013 00:13:19.921080 11428 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I1013 00:13:47.943660 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:13:49.124990 11428 solver.cpp:330] Iteration 25000, Testing net (#0)
I1013 00:14:04.675082 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:14:04.993618 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53365 (* 1 = 1.53365 loss)
I1013 00:14:04.993634 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6446
I1013 00:14:05.282642 11428 solver.cpp:218] Iteration 25000 (2.20451 iter/s, 45.3616s/100 iters), loss = 0.332024
I1013 00:14:05.282676 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332025 (* 1 = 0.332025 loss)
I1013 00:14:05.282685 11428 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I1013 00:14:34.787365 11428 solver.cpp:218] Iteration 25100 (3.38929 iter/s, 29.5047s/100 iters), loss = 0.28446
I1013 00:14:34.787510 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28446 (* 1 = 0.28446 loss)
I1013 00:14:34.787520 11428 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I1013 00:15:04.288293 11428 solver.cpp:218] Iteration 25200 (3.38974 iter/s, 29.5008s/100 iters), loss = 0.244472
I1013 00:15:04.288326 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244473 (* 1 = 0.244473 loss)
I1013 00:15:04.288333 11428 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I1013 00:15:33.795047 11428 solver.cpp:218] Iteration 25300 (3.38906 iter/s, 29.5067s/100 iters), loss = 0.373497
I1013 00:15:33.795192 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373498 (* 1 = 0.373498 loss)
I1013 00:15:33.795202 11428 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I1013 00:16:03.303124 11428 solver.cpp:218] Iteration 25400 (3.38892 iter/s, 29.5079s/100 iters), loss = 0.11994
I1013 00:16:03.303155 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119941 (* 1 = 0.119941 loss)
I1013 00:16:03.303164 11428 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I1013 00:16:32.531683 11428 solver.cpp:330] Iteration 25500, Testing net (#0)
I1013 00:16:48.092960 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:16:48.411890 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60238 (* 1 = 1.60238 loss)
I1013 00:16:48.411906 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6394
I1013 00:16:48.698626 11428 solver.cpp:218] Iteration 25500 (2.20286 iter/s, 45.3955s/100 iters), loss = 0.466535
I1013 00:16:48.698660 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466536 (* 1 = 0.466536 loss)
I1013 00:16:48.698668 11428 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I1013 00:17:18.215420 11428 solver.cpp:218] Iteration 25600 (3.3879 iter/s, 29.5168s/100 iters), loss = 0.329524
I1013 00:17:18.215557 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329525 (* 1 = 0.329525 loss)
I1013 00:17:18.215567 11428 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I1013 00:17:47.731142 11428 solver.cpp:218] Iteration 25700 (3.38804 iter/s, 29.5156s/100 iters), loss = 0.424937
I1013 00:17:47.731178 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424938 (* 1 = 0.424938 loss)
I1013 00:17:47.731186 11428 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I1013 00:18:17.271224 11428 solver.cpp:218] Iteration 25800 (3.38523 iter/s, 29.5401s/100 iters), loss = 0.296038
I1013 00:18:17.271386 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296039 (* 1 = 0.296039 loss)
I1013 00:18:17.271396 11428 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I1013 00:18:46.801175 11428 solver.cpp:218] Iteration 25900 (3.38641 iter/s, 29.5298s/100 iters), loss = 0.498797
I1013 00:18:46.801208 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498798 (* 1 = 0.498798 loss)
I1013 00:18:46.801215 11428 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I1013 00:19:14.857808 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:19:16.038063 11428 solver.cpp:330] Iteration 26000, Testing net (#0)
I1013 00:19:31.592656 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:19:31.910035 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58402 (* 1 = 1.58402 loss)
I1013 00:19:31.910053 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6401
I1013 00:19:32.200562 11428 solver.cpp:218] Iteration 26000 (2.20267 iter/s, 45.3994s/100 iters), loss = 0.175329
I1013 00:19:32.200597 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175329 (* 1 = 0.175329 loss)
I1013 00:19:32.200604 11428 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I1013 00:20:01.710306 11428 solver.cpp:218] Iteration 26100 (3.38871 iter/s, 29.5097s/100 iters), loss = 0.220962
I1013 00:20:01.710463 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220963 (* 1 = 0.220963 loss)
I1013 00:20:01.710482 11428 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I1013 00:20:31.232231 11428 solver.cpp:218] Iteration 26200 (3.38733 iter/s, 29.5218s/100 iters), loss = 0.268207
I1013 00:20:31.232262 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268208 (* 1 = 0.268208 loss)
I1013 00:20:31.232270 11428 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I1013 00:21:00.766897 11428 solver.cpp:218] Iteration 26300 (3.38585 iter/s, 29.5346s/100 iters), loss = 0.275977
I1013 00:21:00.767040 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275978 (* 1 = 0.275978 loss)
I1013 00:21:00.767048 11428 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I1013 00:21:30.285670 11428 solver.cpp:218] Iteration 26400 (3.38769 iter/s, 29.5186s/100 iters), loss = 0.219897
I1013 00:21:30.285701 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219898 (* 1 = 0.219898 loss)
I1013 00:21:30.285708 11428 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I1013 00:21:59.505105 11428 solver.cpp:330] Iteration 26500, Testing net (#0)
I1013 00:22:15.062185 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:22:15.380127 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60992 (* 1 = 1.60992 loss)
I1013 00:22:15.380142 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6409
I1013 00:22:15.669734 11428 solver.cpp:218] Iteration 26500 (2.20342 iter/s, 45.3841s/100 iters), loss = 0.312574
I1013 00:22:15.669770 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312574 (* 1 = 0.312574 loss)
I1013 00:22:15.669778 11428 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I1013 00:22:45.150871 11428 solver.cpp:218] Iteration 26600 (3.392 iter/s, 29.4811s/100 iters), loss = 0.335925
I1013 00:22:45.151012 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335926 (* 1 = 0.335926 loss)
I1013 00:22:45.151022 11428 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I1013 00:23:14.650336 11428 solver.cpp:218] Iteration 26700 (3.38991 iter/s, 29.4993s/100 iters), loss = 0.242147
I1013 00:23:14.650367 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242148 (* 1 = 0.242148 loss)
I1013 00:23:14.650375 11428 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I1013 00:23:44.116027 11428 solver.cpp:218] Iteration 26800 (3.39378 iter/s, 29.4657s/100 iters), loss = 0.254375
I1013 00:23:44.116166 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254376 (* 1 = 0.254376 loss)
I1013 00:23:44.116185 11428 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I1013 00:24:13.610972 11428 solver.cpp:218] Iteration 26900 (3.39043 iter/s, 29.4948s/100 iters), loss = 0.199002
I1013 00:24:13.611006 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199003 (* 1 = 0.199003 loss)
I1013 00:24:13.611013 11428 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I1013 00:24:41.629082 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:24:42.807979 11428 solver.cpp:330] Iteration 27000, Testing net (#0)
I1013 00:24:58.355643 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:24:58.674437 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58664 (* 1 = 1.58664 loss)
I1013 00:24:58.674453 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6434
I1013 00:24:58.964087 11428 solver.cpp:218] Iteration 27000 (2.20492 iter/s, 45.3531s/100 iters), loss = 0.183531
I1013 00:24:58.964120 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183532 (* 1 = 0.183532 loss)
I1013 00:24:58.964128 11428 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I1013 00:25:28.444432 11428 solver.cpp:218] Iteration 27100 (3.39209 iter/s, 29.4803s/100 iters), loss = 0.338334
I1013 00:25:28.444574 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338335 (* 1 = 0.338335 loss)
I1013 00:25:28.444584 11428 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I1013 00:25:57.915716 11428 solver.cpp:218] Iteration 27200 (3.39315 iter/s, 29.4712s/100 iters), loss = 0.235983
I1013 00:25:57.915750 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235984 (* 1 = 0.235984 loss)
I1013 00:25:57.915757 11428 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I1013 00:26:27.378216 11428 solver.cpp:218] Iteration 27300 (3.39415 iter/s, 29.4625s/100 iters), loss = 0.519171
I1013 00:26:27.378362 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519172 (* 1 = 0.519172 loss)
I1013 00:26:27.378371 11428 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I1013 00:26:56.838793 11428 solver.cpp:218] Iteration 27400 (3.39438 iter/s, 29.4604s/100 iters), loss = 0.576789
I1013 00:26:56.838829 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.57679 (* 1 = 0.57679 loss)
I1013 00:26:56.838836 11428 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I1013 00:27:26.035118 11428 solver.cpp:330] Iteration 27500, Testing net (#0)
I1013 00:27:41.573631 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:27:41.892197 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58744 (* 1 = 1.58744 loss)
I1013 00:27:41.892215 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6412
I1013 00:27:42.180866 11428 solver.cpp:218] Iteration 27500 (2.20546 iter/s, 45.3421s/100 iters), loss = 0.297137
I1013 00:27:42.180901 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297138 (* 1 = 0.297138 loss)
I1013 00:27:42.180908 11428 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I1013 00:28:11.671382 11428 solver.cpp:218] Iteration 27600 (3.39092 iter/s, 29.4905s/100 iters), loss = 0.205335
I1013 00:28:11.671526 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205335 (* 1 = 0.205335 loss)
I1013 00:28:11.671536 11428 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I1013 00:28:41.197960 11428 solver.cpp:218] Iteration 27700 (3.38679 iter/s, 29.5264s/100 iters), loss = 0.317571
I1013 00:28:41.197993 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317572 (* 1 = 0.317572 loss)
I1013 00:28:41.198001 11428 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I1013 00:29:10.721668 11428 solver.cpp:218] Iteration 27800 (3.38711 iter/s, 29.5237s/100 iters), loss = 0.1651
I1013 00:29:10.721812 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165101 (* 1 = 0.165101 loss)
I1013 00:29:10.721822 11428 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I1013 00:29:40.240116 11428 solver.cpp:218] Iteration 27900 (3.38773 iter/s, 29.5183s/100 iters), loss = 0.239956
I1013 00:29:40.240149 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239957 (* 1 = 0.239957 loss)
I1013 00:29:40.240157 11428 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I1013 00:30:08.284494 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:30:09.464371 11428 solver.cpp:330] Iteration 28000, Testing net (#0)
I1013 00:30:25.012274 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:30:25.330298 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56655 (* 1 = 1.56655 loss)
I1013 00:30:25.330315 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6449
I1013 00:30:25.621199 11428 solver.cpp:218] Iteration 28000 (2.20356 iter/s, 45.3811s/100 iters), loss = 0.165362
I1013 00:30:25.621239 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165363 (* 1 = 0.165363 loss)
I1013 00:30:25.621248 11428 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I1013 00:30:55.101254 11428 solver.cpp:218] Iteration 28100 (3.39213 iter/s, 29.48s/100 iters), loss = 0.232457
I1013 00:30:55.101369 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232458 (* 1 = 0.232458 loss)
I1013 00:30:55.101388 11428 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I1013 00:31:24.610613 11428 solver.cpp:218] Iteration 28200 (3.38877 iter/s, 29.5093s/100 iters), loss = 0.327651
I1013 00:31:24.610648 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327652 (* 1 = 0.327652 loss)
I1013 00:31:24.610656 11428 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I1013 00:31:54.109325 11428 solver.cpp:218] Iteration 28300 (3.38998 iter/s, 29.4987s/100 iters), loss = 0.315881
I1013 00:31:54.109455 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315882 (* 1 = 0.315882 loss)
I1013 00:31:54.109464 11428 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I1013 00:32:23.609503 11428 solver.cpp:218] Iteration 28400 (3.38982 iter/s, 29.5001s/100 iters), loss = 0.224126
I1013 00:32:23.609534 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224127 (* 1 = 0.224127 loss)
I1013 00:32:23.609541 11428 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I1013 00:32:52.828995 11428 solver.cpp:330] Iteration 28500, Testing net (#0)
I1013 00:33:08.379997 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:33:08.699620 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57747 (* 1 = 1.57747 loss)
I1013 00:33:08.699636 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6431
I1013 00:33:08.988768 11428 solver.cpp:218] Iteration 28500 (2.20365 iter/s, 45.3793s/100 iters), loss = 0.2237
I1013 00:33:08.988814 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223701 (* 1 = 0.223701 loss)
I1013 00:33:08.988822 11428 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I1013 00:33:38.466667 11428 solver.cpp:218] Iteration 28600 (3.39238 iter/s, 29.4779s/100 iters), loss = 0.325582
I1013 00:33:38.466806 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325583 (* 1 = 0.325583 loss)
I1013 00:33:38.466815 11428 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I1013 00:34:07.956811 11428 solver.cpp:218] Iteration 28700 (3.39098 iter/s, 29.49s/100 iters), loss = 0.351045
I1013 00:34:07.956842 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351046 (* 1 = 0.351046 loss)
I1013 00:34:07.956851 11428 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I1013 00:34:37.453428 11428 solver.cpp:218] Iteration 28800 (3.39022 iter/s, 29.4966s/100 iters), loss = 0.36766
I1013 00:34:37.453562 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367661 (* 1 = 0.367661 loss)
I1013 00:34:37.453579 11428 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I1013 00:35:06.960857 11428 solver.cpp:218] Iteration 28900 (3.38899 iter/s, 29.5073s/100 iters), loss = 0.404018
I1013 00:35:06.960889 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404019 (* 1 = 0.404019 loss)
I1013 00:35:06.960896 11428 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I1013 00:35:34.990805 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:35:36.170140 11428 solver.cpp:330] Iteration 29000, Testing net (#0)
I1013 00:35:51.713896 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:35:52.032253 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57942 (* 1 = 1.57942 loss)
I1013 00:35:52.032269 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6406
I1013 00:35:52.322690 11428 solver.cpp:218] Iteration 29000 (2.2045 iter/s, 45.3618s/100 iters), loss = 0.361219
I1013 00:35:52.322726 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36122 (* 1 = 0.36122 loss)
I1013 00:35:52.322732 11428 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I1013 00:36:21.788846 11428 solver.cpp:218] Iteration 29100 (3.39373 iter/s, 29.4661s/100 iters), loss = 0.29941
I1013 00:36:21.788995 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299411 (* 1 = 0.299411 loss)
I1013 00:36:21.789005 11428 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I1013 00:36:51.268337 11428 solver.cpp:218] Iteration 29200 (3.3922 iter/s, 29.4794s/100 iters), loss = 0.320993
I1013 00:36:51.268381 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320995 (* 1 = 0.320995 loss)
I1013 00:36:51.268389 11428 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I1013 00:37:20.758348 11428 solver.cpp:218] Iteration 29300 (3.39098 iter/s, 29.49s/100 iters), loss = 0.417844
I1013 00:37:20.758467 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417846 (* 1 = 0.417846 loss)
I1013 00:37:20.758486 11428 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I1013 00:37:50.225560 11428 solver.cpp:218] Iteration 29400 (3.39361 iter/s, 29.4671s/100 iters), loss = 0.20782
I1013 00:37:50.225594 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207821 (* 1 = 0.207821 loss)
I1013 00:37:50.225600 11428 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I1013 00:38:19.409425 11428 solver.cpp:330] Iteration 29500, Testing net (#0)
I1013 00:38:34.950631 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:38:35.268803 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59528 (* 1 = 1.59528 loss)
I1013 00:38:35.268821 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6431
I1013 00:38:35.556191 11428 solver.cpp:218] Iteration 29500 (2.20601 iter/s, 45.3306s/100 iters), loss = 0.378543
I1013 00:38:35.556228 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378544 (* 1 = 0.378544 loss)
I1013 00:38:35.556236 11428 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I1013 00:39:05.067062 11428 solver.cpp:218] Iteration 29600 (3.38858 iter/s, 29.5108s/100 iters), loss = 0.29817
I1013 00:39:05.067203 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298171 (* 1 = 0.298171 loss)
I1013 00:39:05.067214 11428 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I1013 00:39:34.584210 11428 solver.cpp:218] Iteration 29700 (3.38788 iter/s, 29.517s/100 iters), loss = 0.295397
I1013 00:39:34.584242 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295397 (* 1 = 0.295397 loss)
I1013 00:39:34.584250 11428 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I1013 00:40:04.073742 11428 solver.cpp:218] Iteration 29800 (3.39104 iter/s, 29.4895s/100 iters), loss = 0.221626
I1013 00:40:04.073885 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221627 (* 1 = 0.221627 loss)
I1013 00:40:04.073895 11428 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I1013 00:40:33.572419 11428 solver.cpp:218] Iteration 29900 (3.39 iter/s, 29.4985s/100 iters), loss = 0.466512
I1013 00:40:33.572449 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466513 (* 1 = 0.466513 loss)
I1013 00:40:33.572456 11428 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I1013 00:41:01.598080 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:41:02.777719 11428 solver.cpp:330] Iteration 30000, Testing net (#0)
I1013 00:41:18.322278 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:41:18.640085 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55002 (* 1 = 1.55002 loss)
I1013 00:41:18.640101 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6487
I1013 00:41:18.928417 11428 solver.cpp:218] Iteration 30000 (2.20478 iter/s, 45.356s/100 iters), loss = 0.129605
I1013 00:41:18.928450 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129606 (* 1 = 0.129606 loss)
I1013 00:41:18.928457 11428 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I1013 00:41:48.454881 11428 solver.cpp:218] Iteration 30100 (3.38679 iter/s, 29.5264s/100 iters), loss = 0.218443
I1013 00:41:48.455008 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218444 (* 1 = 0.218444 loss)
I1013 00:41:48.455015 11428 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I1013 00:42:17.984232 11428 solver.cpp:218] Iteration 30200 (3.38647 iter/s, 29.5292s/100 iters), loss = 0.292965
I1013 00:42:17.984264 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292966 (* 1 = 0.292966 loss)
I1013 00:42:17.984272 11428 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I1013 00:42:47.518950 11428 solver.cpp:218] Iteration 30300 (3.38585 iter/s, 29.5347s/100 iters), loss = 0.364444
I1013 00:42:47.519090 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364445 (* 1 = 0.364445 loss)
I1013 00:42:47.519099 11428 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I1013 00:43:17.041996 11428 solver.cpp:218] Iteration 30400 (3.3872 iter/s, 29.5229s/100 iters), loss = 0.47297
I1013 00:43:17.042028 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472971 (* 1 = 0.472971 loss)
I1013 00:43:17.042035 11428 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I1013 00:43:46.285081 11428 solver.cpp:330] Iteration 30500, Testing net (#0)
I1013 00:44:01.832438 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:44:02.150954 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62765 (* 1 = 1.62765 loss)
I1013 00:44:02.150969 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6389
I1013 00:44:02.440114 11428 solver.cpp:218] Iteration 30500 (2.20274 iter/s, 45.3981s/100 iters), loss = 0.435998
I1013 00:44:02.440143 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435999 (* 1 = 0.435999 loss)
I1013 00:44:02.440151 11428 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I1013 00:44:31.945456 11428 solver.cpp:218] Iteration 30600 (3.38922 iter/s, 29.5053s/100 iters), loss = 0.199731
I1013 00:44:31.945600 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199732 (* 1 = 0.199732 loss)
I1013 00:44:31.945608 11428 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I1013 00:45:01.452471 11428 solver.cpp:218] Iteration 30700 (3.38904 iter/s, 29.5069s/100 iters), loss = 0.295494
I1013 00:45:01.452504 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295495 (* 1 = 0.295495 loss)
I1013 00:45:01.452512 11428 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I1013 00:45:30.969619 11428 solver.cpp:218] Iteration 30800 (3.38786 iter/s, 29.5171s/100 iters), loss = 0.396845
I1013 00:45:30.969779 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396846 (* 1 = 0.396846 loss)
I1013 00:45:30.969789 11428 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I1013 00:46:00.480944 11428 solver.cpp:218] Iteration 30900 (3.38855 iter/s, 29.5112s/100 iters), loss = 0.250804
I1013 00:46:00.480975 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250805 (* 1 = 0.250805 loss)
I1013 00:46:00.480983 11428 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I1013 00:46:28.504673 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:46:29.684996 11428 solver.cpp:330] Iteration 31000, Testing net (#0)
I1013 00:46:45.225662 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:46:45.541870 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57106 (* 1 = 1.57106 loss)
I1013 00:46:45.541887 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6488
I1013 00:46:45.831380 11428 solver.cpp:218] Iteration 31000 (2.20505 iter/s, 45.3504s/100 iters), loss = 0.102948
I1013 00:46:45.831414 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102949 (* 1 = 0.102949 loss)
I1013 00:46:45.831423 11428 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I1013 00:47:15.330471 11428 solver.cpp:218] Iteration 31100 (3.38994 iter/s, 29.4991s/100 iters), loss = 0.370785
I1013 00:47:15.330572 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370786 (* 1 = 0.370786 loss)
I1013 00:47:15.330580 11428 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I1013 00:47:44.822008 11428 solver.cpp:218] Iteration 31200 (3.39081 iter/s, 29.4914s/100 iters), loss = 0.237492
I1013 00:47:44.822043 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237494 (* 1 = 0.237494 loss)
I1013 00:47:44.822052 11428 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I1013 00:48:14.300612 11428 solver.cpp:218] Iteration 31300 (3.39229 iter/s, 29.4786s/100 iters), loss = 0.218386
I1013 00:48:14.300755 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218387 (* 1 = 0.218387 loss)
I1013 00:48:14.300765 11428 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I1013 00:48:43.790211 11428 solver.cpp:218] Iteration 31400 (3.39104 iter/s, 29.4895s/100 iters), loss = 0.245393
I1013 00:48:43.790246 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245394 (* 1 = 0.245394 loss)
I1013 00:48:43.790254 11428 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I1013 00:49:12.973551 11428 solver.cpp:330] Iteration 31500, Testing net (#0)
I1013 00:49:28.511651 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:49:28.830605 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54002 (* 1 = 1.54002 loss)
I1013 00:49:28.830621 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6517
I1013 00:49:29.120263 11428 solver.cpp:218] Iteration 31500 (2.20604 iter/s, 45.33s/100 iters), loss = 0.382602
I1013 00:49:29.120297 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382603 (* 1 = 0.382603 loss)
I1013 00:49:29.120306 11428 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I1013 00:49:58.590235 11428 solver.cpp:218] Iteration 31600 (3.39329 iter/s, 29.4699s/100 iters), loss = 0.234142
I1013 00:49:58.590380 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234143 (* 1 = 0.234143 loss)
I1013 00:49:58.590390 11428 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I1013 00:50:28.045063 11428 solver.cpp:218] Iteration 31700 (3.39504 iter/s, 29.4547s/100 iters), loss = 0.394328
I1013 00:50:28.045094 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394329 (* 1 = 0.394329 loss)
I1013 00:50:28.045100 11428 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I1013 00:50:57.509860 11428 solver.cpp:218] Iteration 31800 (3.39388 iter/s, 29.4648s/100 iters), loss = 0.199337
I1013 00:50:57.509955 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199338 (* 1 = 0.199338 loss)
I1013 00:50:57.509963 11428 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I1013 00:51:26.965586 11428 solver.cpp:218] Iteration 31900 (3.39493 iter/s, 29.4557s/100 iters), loss = 0.305325
I1013 00:51:26.965616 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305326 (* 1 = 0.305326 loss)
I1013 00:51:26.965625 11428 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I1013 00:51:54.973655 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:51:56.155292 11428 solver.cpp:330] Iteration 32000, Testing net (#0)
I1013 00:52:11.695133 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:52:12.012425 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58091 (* 1 = 1.58091 loss)
I1013 00:52:12.012442 11428 solver.cpp:397]     Test net output #1: accuracy = 0.653
I1013 00:52:12.301087 11428 solver.cpp:218] Iteration 32000 (2.20578 iter/s, 45.3355s/100 iters), loss = 0.123152
I1013 00:52:12.301121 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123154 (* 1 = 0.123154 loss)
I1013 00:52:12.301128 11428 sgd_solver.cpp:105] Iteration 32000, lr = 0.01
I1013 00:52:41.785099 11428 solver.cpp:218] Iteration 32100 (3.39167 iter/s, 29.484s/100 iters), loss = 0.330042
I1013 00:52:41.785214 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330043 (* 1 = 0.330043 loss)
I1013 00:52:41.785223 11428 sgd_solver.cpp:105] Iteration 32100, lr = 0.01
I1013 00:53:11.263779 11428 solver.cpp:218] Iteration 32200 (3.39229 iter/s, 29.4786s/100 iters), loss = 0.566813
I1013 00:53:11.263823 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.566814 (* 1 = 0.566814 loss)
I1013 00:53:11.263831 11428 sgd_solver.cpp:105] Iteration 32200, lr = 0.01
I1013 00:53:40.740962 11428 solver.cpp:218] Iteration 32300 (3.39246 iter/s, 29.4771s/100 iters), loss = 0.48469
I1013 00:53:40.741062 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.484691 (* 1 = 0.484691 loss)
I1013 00:53:40.741073 11428 sgd_solver.cpp:105] Iteration 32300, lr = 0.01
I1013 00:54:10.215704 11428 solver.cpp:218] Iteration 32400 (3.39275 iter/s, 29.4747s/100 iters), loss = 0.258318
I1013 00:54:10.215742 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258319 (* 1 = 0.258319 loss)
I1013 00:54:10.215750 11428 sgd_solver.cpp:105] Iteration 32400, lr = 0.01
I1013 00:54:39.409375 11428 solver.cpp:330] Iteration 32500, Testing net (#0)
I1013 00:54:54.948115 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:54:55.266515 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.64528 (* 1 = 1.64528 loss)
I1013 00:54:55.266531 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6386
I1013 00:54:55.557051 11428 solver.cpp:218] Iteration 32500 (2.20549 iter/s, 45.3413s/100 iters), loss = 0.366286
I1013 00:54:55.557085 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366287 (* 1 = 0.366287 loss)
I1013 00:54:55.557092 11428 sgd_solver.cpp:105] Iteration 32500, lr = 0.01
I1013 00:55:25.046187 11428 solver.cpp:218] Iteration 32600 (3.39108 iter/s, 29.4891s/100 iters), loss = 0.19785
I1013 00:55:25.046283 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197851 (* 1 = 0.197851 loss)
I1013 00:55:25.046291 11428 sgd_solver.cpp:105] Iteration 32600, lr = 0.01
I1013 00:55:54.548147 11428 solver.cpp:218] Iteration 32700 (3.38962 iter/s, 29.5019s/100 iters), loss = 0.278268
I1013 00:55:54.548178 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278269 (* 1 = 0.278269 loss)
I1013 00:55:54.548187 11428 sgd_solver.cpp:105] Iteration 32700, lr = 0.01
I1013 00:56:24.046871 11428 solver.cpp:218] Iteration 32800 (3.38998 iter/s, 29.4987s/100 iters), loss = 0.110142
I1013 00:56:24.047019 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110143 (* 1 = 0.110143 loss)
I1013 00:56:24.047030 11428 sgd_solver.cpp:105] Iteration 32800, lr = 0.01
I1013 00:56:53.542986 11428 solver.cpp:218] Iteration 32900 (3.39029 iter/s, 29.496s/100 iters), loss = 0.350508
I1013 00:56:53.543018 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350509 (* 1 = 0.350509 loss)
I1013 00:56:53.543025 11428 sgd_solver.cpp:105] Iteration 32900, lr = 0.01
I1013 00:57:21.587824 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:57:22.770023 11428 solver.cpp:330] Iteration 33000, Testing net (#0)
I1013 00:57:38.314213 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 00:57:38.630926 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54248 (* 1 = 1.54248 loss)
I1013 00:57:38.630944 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6482
I1013 00:57:38.920444 11428 solver.cpp:218] Iteration 33000 (2.20374 iter/s, 45.3774s/100 iters), loss = 0.20148
I1013 00:57:38.920478 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201481 (* 1 = 0.201481 loss)
I1013 00:57:38.920486 11428 sgd_solver.cpp:105] Iteration 33000, lr = 0.01
I1013 00:58:08.378679 11428 solver.cpp:218] Iteration 33100 (3.39464 iter/s, 29.4582s/100 iters), loss = 0.261098
I1013 00:58:08.378846 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261099 (* 1 = 0.261099 loss)
I1013 00:58:08.378857 11428 sgd_solver.cpp:105] Iteration 33100, lr = 0.01
I1013 00:58:37.842422 11428 solver.cpp:218] Iteration 33200 (3.39402 iter/s, 29.4636s/100 iters), loss = 0.216854
I1013 00:58:37.842453 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216855 (* 1 = 0.216855 loss)
I1013 00:58:37.842460 11428 sgd_solver.cpp:105] Iteration 33200, lr = 0.01
I1013 00:59:07.329681 11428 solver.cpp:218] Iteration 33300 (3.3913 iter/s, 29.4872s/100 iters), loss = 0.472521
I1013 00:59:07.329826 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472522 (* 1 = 0.472522 loss)
I1013 00:59:07.329835 11428 sgd_solver.cpp:105] Iteration 33300, lr = 0.01
I1013 00:59:36.805800 11428 solver.cpp:218] Iteration 33400 (3.39259 iter/s, 29.476s/100 iters), loss = 0.326459
I1013 00:59:36.805835 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32646 (* 1 = 0.32646 loss)
I1013 00:59:36.805841 11428 sgd_solver.cpp:105] Iteration 33400, lr = 0.01
I1013 01:00:05.986193 11428 solver.cpp:330] Iteration 33500, Testing net (#0)
I1013 01:00:21.534790 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:00:21.853299 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58667 (* 1 = 1.58667 loss)
I1013 01:00:21.853317 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6452
I1013 01:00:22.141844 11428 solver.cpp:218] Iteration 33500 (2.20575 iter/s, 45.336s/100 iters), loss = 0.174009
I1013 01:00:22.141878 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174009 (* 1 = 0.174009 loss)
I1013 01:00:22.141886 11428 sgd_solver.cpp:105] Iteration 33500, lr = 0.01
I1013 01:00:51.611737 11428 solver.cpp:218] Iteration 33600 (3.3933 iter/s, 29.4699s/100 iters), loss = 0.309305
I1013 01:00:51.611825 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309306 (* 1 = 0.309306 loss)
I1013 01:00:51.611850 11428 sgd_solver.cpp:105] Iteration 33600, lr = 0.01
I1013 01:01:21.089607 11428 solver.cpp:218] Iteration 33700 (3.39238 iter/s, 29.4778s/100 iters), loss = 0.166586
I1013 01:01:21.089639 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166586 (* 1 = 0.166586 loss)
I1013 01:01:21.089648 11428 sgd_solver.cpp:105] Iteration 33700, lr = 0.01
I1013 01:01:50.556905 11428 solver.cpp:218] Iteration 33800 (3.39359 iter/s, 29.4673s/100 iters), loss = 0.128662
I1013 01:01:50.556980 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128663 (* 1 = 0.128663 loss)
I1013 01:01:50.556993 11428 sgd_solver.cpp:105] Iteration 33800, lr = 0.01
I1013 01:02:20.034917 11428 solver.cpp:218] Iteration 33900 (3.39237 iter/s, 29.4779s/100 iters), loss = 0.471898
I1013 01:02:20.034955 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471899 (* 1 = 0.471899 loss)
I1013 01:02:20.034965 11428 sgd_solver.cpp:105] Iteration 33900, lr = 0.01
I1013 01:02:48.037858 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:02:49.212146 11428 solver.cpp:330] Iteration 34000, Testing net (#0)
I1013 01:03:04.758071 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:03:05.076704 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5861 (* 1 = 1.5861 loss)
I1013 01:03:05.076721 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6506
I1013 01:03:05.366758 11428 solver.cpp:218] Iteration 34000 (2.20596 iter/s, 45.3318s/100 iters), loss = 0.160906
I1013 01:03:05.366796 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160907 (* 1 = 0.160907 loss)
I1013 01:03:05.366806 11428 sgd_solver.cpp:105] Iteration 34000, lr = 0.01
I1013 01:03:34.846635 11428 solver.cpp:218] Iteration 34100 (3.39215 iter/s, 29.4799s/100 iters), loss = 0.288812
I1013 01:03:34.846820 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288813 (* 1 = 0.288813 loss)
I1013 01:03:34.846849 11428 sgd_solver.cpp:105] Iteration 34100, lr = 0.01
I1013 01:04:04.343581 11428 solver.cpp:218] Iteration 34200 (3.3902 iter/s, 29.4968s/100 iters), loss = 0.127973
I1013 01:04:04.343614 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127974 (* 1 = 0.127974 loss)
I1013 01:04:04.343622 11428 sgd_solver.cpp:105] Iteration 34200, lr = 0.01
I1013 01:04:33.825048 11428 solver.cpp:218] Iteration 34300 (3.39196 iter/s, 29.4814s/100 iters), loss = 0.22745
I1013 01:04:33.825196 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227451 (* 1 = 0.227451 loss)
I1013 01:04:33.825203 11428 sgd_solver.cpp:105] Iteration 34300, lr = 0.01
I1013 01:05:03.328205 11428 solver.cpp:218] Iteration 34400 (3.38948 iter/s, 29.503s/100 iters), loss = 0.159973
I1013 01:05:03.328236 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159974 (* 1 = 0.159974 loss)
I1013 01:05:03.328244 11428 sgd_solver.cpp:105] Iteration 34400, lr = 0.01
I1013 01:05:32.544098 11428 solver.cpp:330] Iteration 34500, Testing net (#0)
I1013 01:05:48.084008 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:05:48.402215 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60889 (* 1 = 1.60889 loss)
I1013 01:05:48.402231 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6476
I1013 01:05:48.691990 11428 solver.cpp:218] Iteration 34500 (2.2044 iter/s, 45.3638s/100 iters), loss = 0.112769
I1013 01:05:48.692026 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112769 (* 1 = 0.112769 loss)
I1013 01:05:48.692034 11428 sgd_solver.cpp:105] Iteration 34500, lr = 0.01
I1013 01:06:18.171589 11428 solver.cpp:218] Iteration 34600 (3.39218 iter/s, 29.4796s/100 iters), loss = 0.480683
I1013 01:06:18.171736 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480684 (* 1 = 0.480684 loss)
I1013 01:06:18.171746 11428 sgd_solver.cpp:105] Iteration 34600, lr = 0.01
I1013 01:06:47.645947 11428 solver.cpp:218] Iteration 34700 (3.3928 iter/s, 29.4742s/100 iters), loss = 0.26235
I1013 01:06:47.645990 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262351 (* 1 = 0.262351 loss)
I1013 01:06:47.646008 11428 sgd_solver.cpp:105] Iteration 34700, lr = 0.01
I1013 01:07:17.127420 11428 solver.cpp:218] Iteration 34800 (3.39196 iter/s, 29.4814s/100 iters), loss = 0.26144
I1013 01:07:17.127532 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26144 (* 1 = 0.26144 loss)
I1013 01:07:17.127549 11428 sgd_solver.cpp:105] Iteration 34800, lr = 0.01
I1013 01:07:46.605418 11428 solver.cpp:218] Iteration 34900 (3.39237 iter/s, 29.4779s/100 iters), loss = 0.37737
I1013 01:07:46.605451 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377371 (* 1 = 0.377371 loss)
I1013 01:07:46.605458 11428 sgd_solver.cpp:105] Iteration 34900, lr = 0.01
I1013 01:08:14.616849 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:08:15.792366 11428 solver.cpp:330] Iteration 35000, Testing net (#0)
I1013 01:08:31.335496 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:08:31.651469 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62243 (* 1 = 1.62243 loss)
I1013 01:08:31.651484 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6426
I1013 01:08:31.940201 11428 solver.cpp:218] Iteration 35000 (2.20581 iter/s, 45.3348s/100 iters), loss = 0.411618
I1013 01:08:31.940234 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411619 (* 1 = 0.411619 loss)
I1013 01:08:31.940243 11428 sgd_solver.cpp:105] Iteration 35000, lr = 0.01
I1013 01:09:01.418823 11428 solver.cpp:218] Iteration 35100 (3.39229 iter/s, 29.4786s/100 iters), loss = 0.288315
I1013 01:09:01.418952 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288315 (* 1 = 0.288315 loss)
I1013 01:09:01.418962 11428 sgd_solver.cpp:105] Iteration 35100, lr = 0.01
I1013 01:09:30.910742 11428 solver.cpp:218] Iteration 35200 (3.39077 iter/s, 29.4918s/100 iters), loss = 0.403166
I1013 01:09:30.910778 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403166 (* 1 = 0.403166 loss)
I1013 01:09:30.910785 11428 sgd_solver.cpp:105] Iteration 35200, lr = 0.01
I1013 01:10:00.412467 11428 solver.cpp:218] Iteration 35300 (3.38964 iter/s, 29.5017s/100 iters), loss = 0.424975
I1013 01:10:00.412618 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424975 (* 1 = 0.424975 loss)
I1013 01:10:00.412628 11428 sgd_solver.cpp:105] Iteration 35300, lr = 0.01
I1013 01:10:29.896365 11428 solver.cpp:218] Iteration 35400 (3.3917 iter/s, 29.4838s/100 iters), loss = 0.32865
I1013 01:10:29.896395 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328651 (* 1 = 0.328651 loss)
I1013 01:10:29.896402 11428 sgd_solver.cpp:105] Iteration 35400, lr = 0.01
I1013 01:10:59.093083 11428 solver.cpp:330] Iteration 35500, Testing net (#0)
I1013 01:11:14.630210 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:11:14.949111 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60262 (* 1 = 1.60262 loss)
I1013 01:11:14.949128 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6481
I1013 01:11:15.236974 11428 solver.cpp:218] Iteration 35500 (2.20553 iter/s, 45.3406s/100 iters), loss = 0.351106
I1013 01:11:15.237007 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351107 (* 1 = 0.351107 loss)
I1013 01:11:15.237015 11428 sgd_solver.cpp:105] Iteration 35500, lr = 0.01
I1013 01:11:44.699035 11428 solver.cpp:218] Iteration 35600 (3.3942 iter/s, 29.462s/100 iters), loss = 0.111346
I1013 01:11:44.699179 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111347 (* 1 = 0.111347 loss)
I1013 01:11:44.699188 11428 sgd_solver.cpp:105] Iteration 35600, lr = 0.01
I1013 01:12:14.160945 11428 solver.cpp:218] Iteration 35700 (3.39423 iter/s, 29.4618s/100 iters), loss = 0.284483
I1013 01:12:14.160979 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284484 (* 1 = 0.284484 loss)
I1013 01:12:14.160987 11428 sgd_solver.cpp:105] Iteration 35700, lr = 0.01
I1013 01:12:43.632282 11428 solver.cpp:218] Iteration 35800 (3.39313 iter/s, 29.4713s/100 iters), loss = 0.208108
I1013 01:12:43.632393 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208109 (* 1 = 0.208109 loss)
I1013 01:12:43.632411 11428 sgd_solver.cpp:105] Iteration 35800, lr = 0.01
I1013 01:13:13.102059 11428 solver.cpp:218] Iteration 35900 (3.39332 iter/s, 29.4697s/100 iters), loss = 0.407644
I1013 01:13:13.102092 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407644 (* 1 = 0.407644 loss)
I1013 01:13:13.102099 11428 sgd_solver.cpp:105] Iteration 35900, lr = 0.01
I1013 01:13:41.106081 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:13:42.283591 11428 solver.cpp:330] Iteration 36000, Testing net (#0)
I1013 01:13:57.821133 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:13:58.137537 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56189 (* 1 = 1.56189 loss)
I1013 01:13:58.137553 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6518
I1013 01:13:58.425391 11428 solver.cpp:218] Iteration 36000 (2.20637 iter/s, 45.3233s/100 iters), loss = 0.106271
I1013 01:13:58.425433 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106271 (* 1 = 0.106271 loss)
I1013 01:13:58.425441 11428 sgd_solver.cpp:105] Iteration 36000, lr = 0.01
I1013 01:14:27.890121 11428 solver.cpp:218] Iteration 36100 (3.39389 iter/s, 29.4647s/100 iters), loss = 0.415509
I1013 01:14:27.890266 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41551 (* 1 = 0.41551 loss)
I1013 01:14:27.890276 11428 sgd_solver.cpp:105] Iteration 36100, lr = 0.01
I1013 01:14:57.349294 11428 solver.cpp:218] Iteration 36200 (3.39454 iter/s, 29.459s/100 iters), loss = 0.372728
I1013 01:14:57.349326 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372729 (* 1 = 0.372729 loss)
I1013 01:14:57.349334 11428 sgd_solver.cpp:105] Iteration 36200, lr = 0.01
I1013 01:15:26.835170 11428 solver.cpp:218] Iteration 36300 (3.39146 iter/s, 29.4859s/100 iters), loss = 0.114554
I1013 01:15:26.835306 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114555 (* 1 = 0.114555 loss)
I1013 01:15:26.835315 11428 sgd_solver.cpp:105] Iteration 36300, lr = 0.01
I1013 01:15:56.294785 11428 solver.cpp:218] Iteration 36400 (3.39449 iter/s, 29.4595s/100 iters), loss = 0.261858
I1013 01:15:56.294817 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261859 (* 1 = 0.261859 loss)
I1013 01:15:56.294826 11428 sgd_solver.cpp:105] Iteration 36400, lr = 0.01
I1013 01:16:25.469298 11428 solver.cpp:330] Iteration 36500, Testing net (#0)
I1013 01:16:41.004783 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:16:41.321370 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.6475 (* 1 = 1.6475 loss)
I1013 01:16:41.321386 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6386
I1013 01:16:41.610875 11428 solver.cpp:218] Iteration 36500 (2.20672 iter/s, 45.3161s/100 iters), loss = 0.310115
I1013 01:16:41.610908 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310116 (* 1 = 0.310116 loss)
I1013 01:16:41.610915 11428 sgd_solver.cpp:105] Iteration 36500, lr = 0.01
I1013 01:17:11.102583 11428 solver.cpp:218] Iteration 36600 (3.39079 iter/s, 29.4917s/100 iters), loss = 0.598092
I1013 01:17:11.102695 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.598094 (* 1 = 0.598094 loss)
I1013 01:17:11.102705 11428 sgd_solver.cpp:105] Iteration 36600, lr = 0.01
I1013 01:17:40.585047 11428 solver.cpp:218] Iteration 36700 (3.39186 iter/s, 29.4824s/100 iters), loss = 0.115075
I1013 01:17:40.585080 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115076 (* 1 = 0.115076 loss)
I1013 01:17:40.585088 11428 sgd_solver.cpp:105] Iteration 36700, lr = 0.01
I1013 01:18:10.062218 11428 solver.cpp:218] Iteration 36800 (3.39246 iter/s, 29.4771s/100 iters), loss = 0.147106
I1013 01:18:10.062361 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147107 (* 1 = 0.147107 loss)
I1013 01:18:10.062371 11428 sgd_solver.cpp:105] Iteration 36800, lr = 0.01
I1013 01:18:39.526748 11428 solver.cpp:218] Iteration 36900 (3.39393 iter/s, 29.4644s/100 iters), loss = 0.193922
I1013 01:18:39.526780 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193923 (* 1 = 0.193923 loss)
I1013 01:18:39.526787 11428 sgd_solver.cpp:105] Iteration 36900, lr = 0.01
I1013 01:19:07.556979 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:19:08.738629 11428 solver.cpp:330] Iteration 37000, Testing net (#0)
I1013 01:19:24.277712 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:19:24.595260 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57225 (* 1 = 1.57225 loss)
I1013 01:19:24.595275 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6515
I1013 01:19:24.883635 11428 solver.cpp:218] Iteration 37000 (2.20474 iter/s, 45.3569s/100 iters), loss = 0.257106
I1013 01:19:24.883669 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257107 (* 1 = 0.257107 loss)
I1013 01:19:24.883677 11428 sgd_solver.cpp:105] Iteration 37000, lr = 0.01
I1013 01:19:54.360256 11428 solver.cpp:218] Iteration 37100 (3.39252 iter/s, 29.4766s/100 iters), loss = 0.245216
I1013 01:19:54.360370 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245217 (* 1 = 0.245217 loss)
I1013 01:19:54.360378 11428 sgd_solver.cpp:105] Iteration 37100, lr = 0.01
I1013 01:20:23.842377 11428 solver.cpp:218] Iteration 37200 (3.3919 iter/s, 29.482s/100 iters), loss = 0.166044
I1013 01:20:23.842409 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166045 (* 1 = 0.166045 loss)
I1013 01:20:23.842417 11428 sgd_solver.cpp:105] Iteration 37200, lr = 0.01
I1013 01:20:53.309321 11428 solver.cpp:218] Iteration 37300 (3.39364 iter/s, 29.4669s/100 iters), loss = 0.215249
I1013 01:20:53.309442 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21525 (* 1 = 0.21525 loss)
I1013 01:20:53.309451 11428 sgd_solver.cpp:105] Iteration 37300, lr = 0.01
I1013 01:21:22.790678 11428 solver.cpp:218] Iteration 37400 (3.39199 iter/s, 29.4813s/100 iters), loss = 0.194954
I1013 01:21:22.790710 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194955 (* 1 = 0.194955 loss)
I1013 01:21:22.790719 11428 sgd_solver.cpp:105] Iteration 37400, lr = 0.01
I1013 01:21:51.987478 11428 solver.cpp:330] Iteration 37500, Testing net (#0)
I1013 01:22:07.528580 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:22:07.846916 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61019 (* 1 = 1.61019 loss)
I1013 01:22:07.846933 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6436
I1013 01:22:08.137825 11428 solver.cpp:218] Iteration 37500 (2.20521 iter/s, 45.3471s/100 iters), loss = 0.176713
I1013 01:22:08.137861 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176714 (* 1 = 0.176714 loss)
I1013 01:22:08.137868 11428 sgd_solver.cpp:105] Iteration 37500, lr = 0.01
I1013 01:22:37.629070 11428 solver.cpp:218] Iteration 37600 (3.39084 iter/s, 29.4912s/100 iters), loss = 0.473734
I1013 01:22:37.629218 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.473735 (* 1 = 0.473735 loss)
I1013 01:22:37.629228 11428 sgd_solver.cpp:105] Iteration 37600, lr = 0.01
I1013 01:23:07.373375 11428 solver.cpp:218] Iteration 37700 (3.362 iter/s, 29.7442s/100 iters), loss = 0.112503
I1013 01:23:07.373417 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112504 (* 1 = 0.112504 loss)
I1013 01:23:07.373425 11428 sgd_solver.cpp:105] Iteration 37700, lr = 0.01
I1013 01:23:36.995543 11428 solver.cpp:218] Iteration 37800 (3.37585 iter/s, 29.6221s/100 iters), loss = 0.160285
I1013 01:23:36.995656 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160286 (* 1 = 0.160286 loss)
I1013 01:23:36.995673 11428 sgd_solver.cpp:105] Iteration 37800, lr = 0.01
I1013 01:24:06.635840 11428 solver.cpp:218] Iteration 37900 (3.3738 iter/s, 29.6402s/100 iters), loss = 0.225564
I1013 01:24:06.635870 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225565 (* 1 = 0.225565 loss)
I1013 01:24:06.635877 11428 sgd_solver.cpp:105] Iteration 37900, lr = 0.01
I1013 01:24:34.773080 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:24:35.949571 11428 solver.cpp:330] Iteration 38000, Testing net (#0)
I1013 01:24:51.659929 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:24:51.979074 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56731 (* 1 = 1.56731 loss)
I1013 01:24:51.979091 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6536
I1013 01:24:52.268460 11428 solver.cpp:218] Iteration 38000 (2.19142 iter/s, 45.6326s/100 iters), loss = 0.0877876
I1013 01:24:52.268493 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0877886 (* 1 = 0.0877886 loss)
I1013 01:24:52.268502 11428 sgd_solver.cpp:105] Iteration 38000, lr = 0.01
I1013 01:25:21.816120 11428 solver.cpp:218] Iteration 38100 (3.38437 iter/s, 29.5476s/100 iters), loss = 0.248655
I1013 01:25:21.816257 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248656 (* 1 = 0.248656 loss)
I1013 01:25:21.816265 11428 sgd_solver.cpp:105] Iteration 38100, lr = 0.01
I1013 01:25:51.396714 11428 solver.cpp:218] Iteration 38200 (3.38061 iter/s, 29.5805s/100 iters), loss = 0.386807
I1013 01:25:51.396746 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386808 (* 1 = 0.386808 loss)
I1013 01:25:51.396754 11428 sgd_solver.cpp:105] Iteration 38200, lr = 0.01
I1013 01:26:20.984735 11428 solver.cpp:218] Iteration 38300 (3.37975 iter/s, 29.588s/100 iters), loss = 0.294307
I1013 01:26:20.984866 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294309 (* 1 = 0.294309 loss)
I1013 01:26:20.984879 11428 sgd_solver.cpp:105] Iteration 38300, lr = 0.01
I1013 01:26:50.615656 11428 solver.cpp:218] Iteration 38400 (3.37487 iter/s, 29.6308s/100 iters), loss = 0.220999
I1013 01:26:50.615689 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221 (* 1 = 0.221 loss)
I1013 01:26:50.615697 11428 sgd_solver.cpp:105] Iteration 38400, lr = 0.01
I1013 01:27:19.942498 11428 solver.cpp:330] Iteration 38500, Testing net (#0)
I1013 01:27:35.633275 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:27:35.954622 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.64116 (* 1 = 1.64116 loss)
I1013 01:27:35.954639 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6453
I1013 01:27:36.246801 11428 solver.cpp:218] Iteration 38500 (2.19149 iter/s, 45.6311s/100 iters), loss = 0.223279
I1013 01:27:36.246870 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22328 (* 1 = 0.22328 loss)
I1013 01:27:36.246878 11428 sgd_solver.cpp:105] Iteration 38500, lr = 0.01
I1013 01:28:05.830490 11428 solver.cpp:218] Iteration 38600 (3.38026 iter/s, 29.5836s/100 iters), loss = 0.299756
I1013 01:28:05.830639 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299758 (* 1 = 0.299758 loss)
I1013 01:28:05.830658 11428 sgd_solver.cpp:105] Iteration 38600, lr = 0.01
I1013 01:28:35.433065 11428 solver.cpp:218] Iteration 38700 (3.3781 iter/s, 29.6024s/100 iters), loss = 0.440646
I1013 01:28:35.433095 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440647 (* 1 = 0.440647 loss)
I1013 01:28:35.433102 11428 sgd_solver.cpp:105] Iteration 38700, lr = 0.01
I1013 01:29:05.006322 11428 solver.cpp:218] Iteration 38800 (3.38144 iter/s, 29.5732s/100 iters), loss = 0.112852
I1013 01:29:05.006429 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112853 (* 1 = 0.112853 loss)
I1013 01:29:05.006446 11428 sgd_solver.cpp:105] Iteration 38800, lr = 0.01
I1013 01:29:34.587712 11428 solver.cpp:218] Iteration 38900 (3.38051 iter/s, 29.5813s/100 iters), loss = 0.276352
I1013 01:29:34.587745 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276353 (* 1 = 0.276353 loss)
I1013 01:29:34.587762 11428 sgd_solver.cpp:105] Iteration 38900, lr = 0.01
I1013 01:30:02.699177 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:30:03.874102 11428 solver.cpp:330] Iteration 39000, Testing net (#0)
I1013 01:30:19.464454 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:30:19.783303 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57507 (* 1 = 1.57507 loss)
I1013 01:30:19.783321 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6514
I1013 01:30:20.073848 11428 solver.cpp:218] Iteration 39000 (2.19847 iter/s, 45.4861s/100 iters), loss = 0.195371
I1013 01:30:20.073885 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195372 (* 1 = 0.195372 loss)
I1013 01:30:20.073896 11428 sgd_solver.cpp:105] Iteration 39000, lr = 0.01
I1013 01:30:49.730629 11428 solver.cpp:218] Iteration 39100 (3.37191 iter/s, 29.6568s/100 iters), loss = 0.262938
I1013 01:30:49.730767 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262939 (* 1 = 0.262939 loss)
I1013 01:30:49.730777 11428 sgd_solver.cpp:105] Iteration 39100, lr = 0.01
I1013 01:31:19.299700 11428 solver.cpp:218] Iteration 39200 (3.38193 iter/s, 29.5689s/100 iters), loss = 0.115917
I1013 01:31:19.299731 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115918 (* 1 = 0.115918 loss)
I1013 01:31:19.299737 11428 sgd_solver.cpp:105] Iteration 39200, lr = 0.01
I1013 01:31:48.910961 11428 solver.cpp:218] Iteration 39300 (3.3771 iter/s, 29.6112s/100 iters), loss = 0.153907
I1013 01:31:48.911103 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153908 (* 1 = 0.153908 loss)
I1013 01:31:48.911111 11428 sgd_solver.cpp:105] Iteration 39300, lr = 0.01
I1013 01:32:18.500190 11428 solver.cpp:218] Iteration 39400 (3.37962 iter/s, 29.5891s/100 iters), loss = 0.199762
I1013 01:32:18.500222 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199763 (* 1 = 0.199763 loss)
I1013 01:32:18.500229 11428 sgd_solver.cpp:105] Iteration 39400, lr = 0.01
I1013 01:32:47.775523 11428 solver.cpp:330] Iteration 39500, Testing net (#0)
I1013 01:33:03.377012 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:33:03.697059 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60678 (* 1 = 1.60678 loss)
I1013 01:33:03.697077 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6491
I1013 01:33:03.987608 11428 solver.cpp:218] Iteration 39500 (2.19841 iter/s, 45.4874s/100 iters), loss = 0.201843
I1013 01:33:03.987642 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201844 (* 1 = 0.201844 loss)
I1013 01:33:03.987648 11428 sgd_solver.cpp:105] Iteration 39500, lr = 0.01
I1013 01:33:33.570785 11428 solver.cpp:218] Iteration 39600 (3.3803 iter/s, 29.5832s/100 iters), loss = 0.180529
I1013 01:33:33.570890 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18053 (* 1 = 0.18053 loss)
I1013 01:33:33.570906 11428 sgd_solver.cpp:105] Iteration 39600, lr = 0.01
I1013 01:34:03.180498 11428 solver.cpp:218] Iteration 39700 (3.37728 iter/s, 29.6096s/100 iters), loss = 0.188804
I1013 01:34:03.180528 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188805 (* 1 = 0.188805 loss)
I1013 01:34:03.180536 11428 sgd_solver.cpp:105] Iteration 39700, lr = 0.01
I1013 01:34:32.775189 11428 solver.cpp:218] Iteration 39800 (3.37899 iter/s, 29.5947s/100 iters), loss = 0.190412
I1013 01:34:32.775316 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190413 (* 1 = 0.190413 loss)
I1013 01:34:32.775324 11428 sgd_solver.cpp:105] Iteration 39800, lr = 0.01
I1013 01:35:02.324789 11428 solver.cpp:218] Iteration 39900 (3.38415 iter/s, 29.5495s/100 iters), loss = 0.257788
I1013 01:35:02.324820 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257789 (* 1 = 0.257789 loss)
I1013 01:35:02.324828 11428 sgd_solver.cpp:105] Iteration 39900, lr = 0.01
I1013 01:35:30.464862 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:35:31.649528 11428 solver.cpp:330] Iteration 40000, Testing net (#0)
I1013 01:35:47.279114 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:35:47.598318 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50796 (* 1 = 1.50796 loss)
I1013 01:35:47.598335 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6638
I1013 01:35:47.886605 11428 solver.cpp:218] Iteration 40000 (2.19482 iter/s, 45.5618s/100 iters), loss = 0.146731
I1013 01:35:47.886639 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146732 (* 1 = 0.146732 loss)
I1013 01:35:47.886647 11428 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1013 01:36:17.481647 11428 solver.cpp:218] Iteration 40100 (3.37895 iter/s, 29.595s/100 iters), loss = 0.224577
I1013 01:36:17.481787 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224579 (* 1 = 0.224579 loss)
I1013 01:36:17.481796 11428 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1013 01:36:47.094521 11428 solver.cpp:218] Iteration 40200 (3.37692 iter/s, 29.6127s/100 iters), loss = 0.248365
I1013 01:36:47.094553 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248367 (* 1 = 0.248367 loss)
I1013 01:36:47.094561 11428 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1013 01:37:16.696962 11428 solver.cpp:218] Iteration 40300 (3.3781 iter/s, 29.6024s/100 iters), loss = 0.245145
I1013 01:37:16.697101 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245147 (* 1 = 0.245147 loss)
I1013 01:37:16.697110 11428 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1013 01:37:46.295526 11428 solver.cpp:218] Iteration 40400 (3.37856 iter/s, 29.5984s/100 iters), loss = 0.262305
I1013 01:37:46.295557 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262306 (* 1 = 0.262306 loss)
I1013 01:37:46.295564 11428 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1013 01:38:15.596500 11428 solver.cpp:330] Iteration 40500, Testing net (#0)
I1013 01:38:31.242444 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:38:31.566701 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60602 (* 1 = 1.60602 loss)
I1013 01:38:31.566720 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6479
I1013 01:38:31.860152 11428 solver.cpp:218] Iteration 40500 (2.19469 iter/s, 45.5646s/100 iters), loss = 0.210641
I1013 01:38:31.860188 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210642 (* 1 = 0.210642 loss)
I1013 01:38:31.860195 11428 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1013 01:39:01.487998 11428 solver.cpp:218] Iteration 40600 (3.37521 iter/s, 29.6278s/100 iters), loss = 0.266204
I1013 01:39:01.488103 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266205 (* 1 = 0.266205 loss)
I1013 01:39:01.488112 11428 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1013 01:39:31.016378 11428 solver.cpp:218] Iteration 40700 (3.38658 iter/s, 29.5283s/100 iters), loss = 0.273947
I1013 01:39:31.016413 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273948 (* 1 = 0.273948 loss)
I1013 01:39:31.016422 11428 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1013 01:40:00.535496 11428 solver.cpp:218] Iteration 40800 (3.38764 iter/s, 29.5191s/100 iters), loss = 0.232254
I1013 01:40:00.535607 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232255 (* 1 = 0.232255 loss)
I1013 01:40:00.535626 11428 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1013 01:40:30.117457 11428 solver.cpp:218] Iteration 40900 (3.38045 iter/s, 29.5819s/100 iters), loss = 0.195732
I1013 01:40:30.117491 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195733 (* 1 = 0.195733 loss)
I1013 01:40:30.117507 11428 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1013 01:40:58.221529 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:40:59.409385 11428 solver.cpp:330] Iteration 41000, Testing net (#0)
I1013 01:41:15.046785 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:41:15.365947 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59383 (* 1 = 1.59383 loss)
I1013 01:41:15.365963 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6479
I1013 01:41:15.656504 11428 solver.cpp:218] Iteration 41000 (2.19592 iter/s, 45.539s/100 iters), loss = 0.0892075
I1013 01:41:15.656538 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0892088 (* 1 = 0.0892088 loss)
I1013 01:41:15.656546 11428 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1013 01:41:45.175808 11428 solver.cpp:218] Iteration 41100 (3.38762 iter/s, 29.5193s/100 iters), loss = 0.378612
I1013 01:41:45.175951 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378613 (* 1 = 0.378613 loss)
I1013 01:41:45.175961 11428 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1013 01:42:14.705473 11428 solver.cpp:218] Iteration 41200 (3.38644 iter/s, 29.5295s/100 iters), loss = 0.239802
I1013 01:42:14.705507 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239803 (* 1 = 0.239803 loss)
I1013 01:42:14.705513 11428 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1013 01:42:44.307610 11428 solver.cpp:218] Iteration 41300 (3.37814 iter/s, 29.6021s/100 iters), loss = 0.094728
I1013 01:42:44.307754 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0947292 (* 1 = 0.0947292 loss)
I1013 01:42:44.307763 11428 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1013 01:43:13.829319 11428 solver.cpp:218] Iteration 41400 (3.38735 iter/s, 29.5216s/100 iters), loss = 0.268576
I1013 01:43:13.829352 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268577 (* 1 = 0.268577 loss)
I1013 01:43:13.829361 11428 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1013 01:43:43.111057 11428 solver.cpp:330] Iteration 41500, Testing net (#0)
I1013 01:43:58.805357 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:43:59.124902 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63853 (* 1 = 1.63853 loss)
I1013 01:43:59.124917 11428 solver.cpp:397]     Test net output #1: accuracy = 0.648
I1013 01:43:59.416240 11428 solver.cpp:218] Iteration 41500 (2.19361 iter/s, 45.5869s/100 iters), loss = 0.201479
I1013 01:43:59.416275 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20148 (* 1 = 0.20148 loss)
I1013 01:43:59.416282 11428 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1013 01:44:28.999085 11428 solver.cpp:218] Iteration 41600 (3.38034 iter/s, 29.5828s/100 iters), loss = 0.365541
I1013 01:44:28.999230 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365542 (* 1 = 0.365542 loss)
I1013 01:44:28.999240 11428 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1013 01:44:58.556615 11428 solver.cpp:218] Iteration 41700 (3.38325 iter/s, 29.5574s/100 iters), loss = 0.288317
I1013 01:44:58.556648 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288318 (* 1 = 0.288318 loss)
I1013 01:44:58.556655 11428 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1013 01:45:28.129421 11428 solver.cpp:218] Iteration 41800 (3.38149 iter/s, 29.5728s/100 iters), loss = 0.195741
I1013 01:45:28.129560 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195742 (* 1 = 0.195742 loss)
I1013 01:45:28.129570 11428 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1013 01:45:57.707978 11428 solver.cpp:218] Iteration 41900 (3.38084 iter/s, 29.5784s/100 iters), loss = 0.219448
I1013 01:45:57.708011 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219449 (* 1 = 0.219449 loss)
I1013 01:45:57.708019 11428 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1013 01:46:25.811695 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:46:26.999383 11428 solver.cpp:330] Iteration 42000, Testing net (#0)
I1013 01:46:42.644768 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:46:42.962401 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5793 (* 1 = 1.5793 loss)
I1013 01:46:42.962417 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6561
I1013 01:46:43.250985 11428 solver.cpp:218] Iteration 42000 (2.19573 iter/s, 45.543s/100 iters), loss = 0.252133
I1013 01:46:43.251019 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252134 (* 1 = 0.252134 loss)
I1013 01:46:43.251026 11428 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1013 01:47:12.794258 11428 solver.cpp:218] Iteration 42100 (3.38487 iter/s, 29.5432s/100 iters), loss = 0.0982004
I1013 01:47:12.794405 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0982015 (* 1 = 0.0982015 loss)
I1013 01:47:12.794415 11428 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1013 01:47:42.330585 11428 solver.cpp:218] Iteration 42200 (3.38568 iter/s, 29.5362s/100 iters), loss = 0.198186
I1013 01:47:42.330617 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198188 (* 1 = 0.198188 loss)
I1013 01:47:42.330624 11428 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1013 01:48:11.930342 11428 solver.cpp:218] Iteration 42300 (3.37841 iter/s, 29.5997s/100 iters), loss = 0.189932
I1013 01:48:11.930485 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189934 (* 1 = 0.189934 loss)
I1013 01:48:11.930506 11428 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1013 01:48:41.483134 11428 solver.cpp:218] Iteration 42400 (3.38379 iter/s, 29.5527s/100 iters), loss = 0.164373
I1013 01:48:41.483165 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164374 (* 1 = 0.164374 loss)
I1013 01:48:41.483173 11428 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1013 01:49:10.770469 11428 solver.cpp:330] Iteration 42500, Testing net (#0)
I1013 01:49:26.366240 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:49:26.683724 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57491 (* 1 = 1.57491 loss)
I1013 01:49:26.683751 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6534
I1013 01:49:26.974005 11428 solver.cpp:218] Iteration 42500 (2.19824 iter/s, 45.4909s/100 iters), loss = 0.201068
I1013 01:49:26.974043 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201069 (* 1 = 0.201069 loss)
I1013 01:49:26.974061 11428 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1013 01:49:56.538075 11428 solver.cpp:218] Iteration 42600 (3.38249 iter/s, 29.564s/100 iters), loss = 0.200207
I1013 01:49:56.538205 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200208 (* 1 = 0.200208 loss)
I1013 01:49:56.538224 11428 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1013 01:50:26.092758 11428 solver.cpp:218] Iteration 42700 (3.38357 iter/s, 29.5546s/100 iters), loss = 0.266247
I1013 01:50:26.092794 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266248 (* 1 = 0.266248 loss)
I1013 01:50:26.092802 11428 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1013 01:50:55.613157 11428 solver.cpp:218] Iteration 42800 (3.38749 iter/s, 29.5204s/100 iters), loss = 0.184963
I1013 01:50:55.613298 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184964 (* 1 = 0.184964 loss)
I1013 01:50:55.613307 11428 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1013 01:51:25.149561 11428 solver.cpp:218] Iteration 42900 (3.38567 iter/s, 29.5363s/100 iters), loss = 0.185347
I1013 01:51:25.149593 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185348 (* 1 = 0.185348 loss)
I1013 01:51:25.149601 11428 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1013 01:51:53.240466 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:51:54.416419 11428 solver.cpp:330] Iteration 43000, Testing net (#0)
I1013 01:52:09.998828 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:52:10.323042 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60448 (* 1 = 1.60448 loss)
I1013 01:52:10.323058 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6522
I1013 01:52:10.618468 11428 solver.cpp:218] Iteration 43000 (2.19931 iter/s, 45.4689s/100 iters), loss = 0.388651
I1013 01:52:10.618505 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388652 (* 1 = 0.388652 loss)
I1013 01:52:10.618513 11428 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1013 01:52:40.177029 11428 solver.cpp:218] Iteration 43100 (3.38312 iter/s, 29.5585s/100 iters), loss = 0.277124
I1013 01:52:40.177129 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277125 (* 1 = 0.277125 loss)
I1013 01:52:40.177137 11428 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1013 01:53:09.736776 11428 solver.cpp:218] Iteration 43200 (3.38299 iter/s, 29.5597s/100 iters), loss = 0.230386
I1013 01:53:09.736809 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230388 (* 1 = 0.230388 loss)
I1013 01:53:09.736817 11428 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1013 01:53:39.299896 11428 solver.cpp:218] Iteration 43300 (3.3826 iter/s, 29.5631s/100 iters), loss = 0.234799
I1013 01:53:39.300009 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2348 (* 1 = 0.2348 loss)
I1013 01:53:39.300026 11428 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1013 01:54:08.866994 11428 solver.cpp:218] Iteration 43400 (3.38215 iter/s, 29.567s/100 iters), loss = 0.0904309
I1013 01:54:08.867028 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0904321 (* 1 = 0.0904321 loss)
I1013 01:54:08.867036 11428 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1013 01:54:38.168038 11428 solver.cpp:330] Iteration 43500, Testing net (#0)
I1013 01:54:53.759428 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:54:54.078645 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63767 (* 1 = 1.63767 loss)
I1013 01:54:54.078660 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6452
I1013 01:54:54.368194 11428 solver.cpp:218] Iteration 43500 (2.19775 iter/s, 45.5012s/100 iters), loss = 0.30656
I1013 01:54:54.368225 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306562 (* 1 = 0.306562 loss)
I1013 01:54:54.368233 11428 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1013 01:55:23.964422 11428 solver.cpp:218] Iteration 43600 (3.37881 iter/s, 29.5962s/100 iters), loss = 0.190645
I1013 01:55:23.964558 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190646 (* 1 = 0.190646 loss)
I1013 01:55:23.964567 11428 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1013 01:55:53.482038 11428 solver.cpp:218] Iteration 43700 (3.38782 iter/s, 29.5175s/100 iters), loss = 0.250216
I1013 01:55:53.482069 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250218 (* 1 = 0.250218 loss)
I1013 01:55:53.482076 11428 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1013 01:56:23.048808 11428 solver.cpp:218] Iteration 43800 (3.38218 iter/s, 29.5667s/100 iters), loss = 0.443957
I1013 01:56:23.048910 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443959 (* 1 = 0.443959 loss)
I1013 01:56:23.048918 11428 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1013 01:56:52.611841 11428 solver.cpp:218] Iteration 43900 (3.38261 iter/s, 29.5629s/100 iters), loss = 0.294645
I1013 01:56:52.611872 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294646 (* 1 = 0.294646 loss)
I1013 01:56:52.611881 11428 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1013 01:57:20.681660 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:57:21.876353 11428 solver.cpp:330] Iteration 44000, Testing net (#0)
I1013 01:57:37.481533 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 01:57:37.799933 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56258 (* 1 = 1.56258 loss)
I1013 01:57:37.799952 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6618
I1013 01:57:38.089809 11428 solver.cpp:218] Iteration 44000 (2.19887 iter/s, 45.478s/100 iters), loss = 0.140669
I1013 01:57:38.089846 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14067 (* 1 = 0.14067 loss)
I1013 01:57:38.089856 11428 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1013 01:58:07.675716 11428 solver.cpp:218] Iteration 44100 (3.37999 iter/s, 29.5859s/100 iters), loss = 0.11111
I1013 01:58:07.675829 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111111 (* 1 = 0.111111 loss)
I1013 01:58:07.675846 11428 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1013 01:58:37.154021 11428 solver.cpp:218] Iteration 44200 (3.39234 iter/s, 29.4782s/100 iters), loss = 0.309551
I1013 01:58:37.154054 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309552 (* 1 = 0.309552 loss)
I1013 01:58:37.154062 11428 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1013 01:59:06.729022 11428 solver.cpp:218] Iteration 44300 (3.38124 iter/s, 29.575s/100 iters), loss = 0.153539
I1013 01:59:06.729174 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15354 (* 1 = 0.15354 loss)
I1013 01:59:06.729184 11428 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1013 01:59:36.266371 11428 solver.cpp:218] Iteration 44400 (3.38556 iter/s, 29.5372s/100 iters), loss = 0.18648
I1013 01:59:36.266405 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186481 (* 1 = 0.186481 loss)
I1013 01:59:36.266414 11428 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1013 02:00:05.538275 11428 solver.cpp:330] Iteration 44500, Testing net (#0)
I1013 02:00:21.144917 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:00:21.464793 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61024 (* 1 = 1.61024 loss)
I1013 02:00:21.464809 11428 solver.cpp:397]     Test net output #1: accuracy = 0.651
I1013 02:00:21.755465 11428 solver.cpp:218] Iteration 44500 (2.19833 iter/s, 45.4891s/100 iters), loss = 0.448812
I1013 02:00:21.755499 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448813 (* 1 = 0.448813 loss)
I1013 02:00:21.755507 11428 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1013 02:00:51.353385 11428 solver.cpp:218] Iteration 44600 (3.37862 iter/s, 29.5979s/100 iters), loss = 0.198799
I1013 02:00:51.353512 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1988 (* 1 = 0.1988 loss)
I1013 02:00:51.353520 11428 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1013 02:01:20.900486 11428 solver.cpp:218] Iteration 44700 (3.38444 iter/s, 29.547s/100 iters), loss = 0.201523
I1013 02:01:20.900519 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201525 (* 1 = 0.201525 loss)
I1013 02:01:20.900527 11428 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1013 02:01:50.423480 11428 solver.cpp:218] Iteration 44800 (3.38719 iter/s, 29.523s/100 iters), loss = 0.15449
I1013 02:01:50.423595 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154491 (* 1 = 0.154491 loss)
I1013 02:01:50.423604 11428 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1013 02:02:19.952175 11428 solver.cpp:218] Iteration 44900 (3.38655 iter/s, 29.5286s/100 iters), loss = 0.225639
I1013 02:02:19.952206 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22564 (* 1 = 0.22564 loss)
I1013 02:02:19.952214 11428 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1013 02:02:48.027832 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:02:49.220130 11428 solver.cpp:330] Iteration 45000, Testing net (#0)
I1013 02:03:04.849212 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:03:05.167584 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57033 (* 1 = 1.57033 loss)
I1013 02:03:05.167601 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6539
I1013 02:03:05.458807 11428 solver.cpp:218] Iteration 45000 (2.19748 iter/s, 45.5066s/100 iters), loss = 0.119464
I1013 02:03:05.458840 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119465 (* 1 = 0.119465 loss)
I1013 02:03:05.458848 11428 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1013 02:03:35.037740 11428 solver.cpp:218] Iteration 45100 (3.38079 iter/s, 29.5789s/100 iters), loss = 0.317311
I1013 02:03:35.037853 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317312 (* 1 = 0.317312 loss)
I1013 02:03:35.037871 11428 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1013 02:04:04.566972 11428 solver.cpp:218] Iteration 45200 (3.38649 iter/s, 29.5291s/100 iters), loss = 0.329233
I1013 02:04:04.567008 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329234 (* 1 = 0.329234 loss)
I1013 02:04:04.567014 11428 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1013 02:04:34.105639 11428 solver.cpp:218] Iteration 45300 (3.3854 iter/s, 29.5386s/100 iters), loss = 0.184225
I1013 02:04:34.105780 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184226 (* 1 = 0.184226 loss)
I1013 02:04:34.105790 11428 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1013 02:05:03.634896 11428 solver.cpp:218] Iteration 45400 (3.38649 iter/s, 29.5291s/100 iters), loss = 0.242891
I1013 02:05:03.634928 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242892 (* 1 = 0.242892 loss)
I1013 02:05:03.634935 11428 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1013 02:05:32.848928 11428 solver.cpp:330] Iteration 45500, Testing net (#0)
I1013 02:05:48.539340 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:05:48.859241 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63186 (* 1 = 1.63186 loss)
I1013 02:05:48.859258 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6459
I1013 02:05:49.149160 11428 solver.cpp:218] Iteration 45500 (2.19711 iter/s, 45.5142s/100 iters), loss = 0.203229
I1013 02:05:49.149195 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20323 (* 1 = 0.20323 loss)
I1013 02:05:49.149204 11428 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1013 02:06:18.675987 11428 solver.cpp:218] Iteration 45600 (3.38675 iter/s, 29.5268s/100 iters), loss = 0.147341
I1013 02:06:18.676136 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147342 (* 1 = 0.147342 loss)
I1013 02:06:18.676146 11428 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1013 02:06:48.214129 11428 solver.cpp:218] Iteration 45700 (3.38547 iter/s, 29.538s/100 iters), loss = 0.146844
I1013 02:06:48.214162 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146845 (* 1 = 0.146845 loss)
I1013 02:06:48.214170 11428 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1013 02:07:17.790486 11428 solver.cpp:218] Iteration 45800 (3.38108 iter/s, 29.5763s/100 iters), loss = 0.166317
I1013 02:07:17.791163 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166319 (* 1 = 0.166319 loss)
I1013 02:07:17.791173 11428 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1013 02:07:47.353503 11428 solver.cpp:218] Iteration 45900 (3.38268 iter/s, 29.5623s/100 iters), loss = 0.167832
I1013 02:07:47.353548 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167834 (* 1 = 0.167834 loss)
I1013 02:07:47.353555 11428 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1013 02:08:15.472103 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:08:16.657913 11428 solver.cpp:330] Iteration 46000, Testing net (#0)
I1013 02:08:32.268816 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:08:32.587000 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54655 (* 1 = 1.54655 loss)
I1013 02:08:32.587016 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6625
I1013 02:08:32.877800 11428 solver.cpp:218] Iteration 46000 (2.19663 iter/s, 45.5243s/100 iters), loss = 0.0921041
I1013 02:08:32.877842 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0921054 (* 1 = 0.0921054 loss)
I1013 02:08:32.877849 11428 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1013 02:09:02.436338 11428 solver.cpp:218] Iteration 46100 (3.38312 iter/s, 29.5585s/100 iters), loss = 0.281355
I1013 02:09:02.436484 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281357 (* 1 = 0.281357 loss)
I1013 02:09:02.436493 11428 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1013 02:09:32.032961 11428 solver.cpp:218] Iteration 46200 (3.37878 iter/s, 29.5965s/100 iters), loss = 0.0906734
I1013 02:09:32.032992 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0906747 (* 1 = 0.0906747 loss)
I1013 02:09:32.033000 11428 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1013 02:10:01.578733 11428 solver.cpp:218] Iteration 46300 (3.38458 iter/s, 29.5457s/100 iters), loss = 0.26625
I1013 02:10:01.578835 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266251 (* 1 = 0.266251 loss)
I1013 02:10:01.578842 11428 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1013 02:10:31.162741 11428 solver.cpp:218] Iteration 46400 (3.38022 iter/s, 29.5839s/100 iters), loss = 0.343194
I1013 02:10:31.162777 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343195 (* 1 = 0.343195 loss)
I1013 02:10:31.162786 11428 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1013 02:11:00.445245 11428 solver.cpp:330] Iteration 46500, Testing net (#0)
I1013 02:11:16.051966 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:11:16.374964 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63041 (* 1 = 1.63041 loss)
I1013 02:11:16.374980 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6439
I1013 02:11:16.669266 11428 solver.cpp:218] Iteration 46500 (2.19749 iter/s, 45.5065s/100 iters), loss = 0.235742
I1013 02:11:16.669302 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235744 (* 1 = 0.235744 loss)
I1013 02:11:16.669311 11428 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1013 02:11:46.256419 11428 solver.cpp:218] Iteration 46600 (3.37985 iter/s, 29.5871s/100 iters), loss = 0.293456
I1013 02:11:46.256563 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293457 (* 1 = 0.293457 loss)
I1013 02:11:46.256583 11428 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1013 02:12:15.781945 11428 solver.cpp:218] Iteration 46700 (3.38692 iter/s, 29.5254s/100 iters), loss = 0.184905
I1013 02:12:15.781980 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184906 (* 1 = 0.184906 loss)
I1013 02:12:15.781986 11428 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1013 02:12:45.317749 11428 solver.cpp:218] Iteration 46800 (3.38572 iter/s, 29.5358s/100 iters), loss = 0.20712
I1013 02:12:45.317879 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207122 (* 1 = 0.207122 loss)
I1013 02:12:45.317899 11428 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1013 02:13:14.876502 11428 solver.cpp:218] Iteration 46900 (3.38311 iter/s, 29.5586s/100 iters), loss = 0.115201
I1013 02:13:14.876533 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115203 (* 1 = 0.115203 loss)
I1013 02:13:14.876540 11428 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1013 02:13:42.988473 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:13:44.163555 11428 solver.cpp:330] Iteration 47000, Testing net (#0)
I1013 02:13:59.791903 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:14:00.111243 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61479 (* 1 = 1.61479 loss)
I1013 02:14:00.111259 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6565
I1013 02:14:00.404088 11428 solver.cpp:218] Iteration 47000 (2.19647 iter/s, 45.5276s/100 iters), loss = 0.144053
I1013 02:14:00.404125 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144054 (* 1 = 0.144054 loss)
I1013 02:14:00.404134 11428 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1013 02:14:29.932631 11428 solver.cpp:218] Iteration 47100 (3.38656 iter/s, 29.5285s/100 iters), loss = 0.217608
I1013 02:14:29.932770 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217609 (* 1 = 0.217609 loss)
I1013 02:14:29.932780 11428 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1013 02:14:59.487020 11428 solver.cpp:218] Iteration 47200 (3.38361 iter/s, 29.5543s/100 iters), loss = 0.274286
I1013 02:14:59.487052 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274287 (* 1 = 0.274287 loss)
I1013 02:14:59.487061 11428 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1013 02:15:29.041802 11428 solver.cpp:218] Iteration 47300 (3.38355 iter/s, 29.5548s/100 iters), loss = 0.123334
I1013 02:15:29.041908 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123336 (* 1 = 0.123336 loss)
I1013 02:15:29.041921 11428 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1013 02:15:58.600297 11428 solver.cpp:218] Iteration 47400 (3.38313 iter/s, 29.5584s/100 iters), loss = 0.34565
I1013 02:15:58.600328 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345652 (* 1 = 0.345652 loss)
I1013 02:15:58.600337 11428 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1013 02:16:27.884764 11428 solver.cpp:330] Iteration 47500, Testing net (#0)
I1013 02:16:43.488771 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:16:43.807335 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60689 (* 1 = 1.60689 loss)
I1013 02:16:43.807353 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6486
I1013 02:16:44.097862 11428 solver.cpp:218] Iteration 47500 (2.19792 iter/s, 45.4975s/100 iters), loss = 0.1763
I1013 02:16:44.097895 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176301 (* 1 = 0.176301 loss)
I1013 02:16:44.097904 11428 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1013 02:17:13.715147 11428 solver.cpp:218] Iteration 47600 (3.37641 iter/s, 29.6173s/100 iters), loss = 0.416513
I1013 02:17:13.715291 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416514 (* 1 = 0.416514 loss)
I1013 02:17:13.715301 11428 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1013 02:17:43.267954 11428 solver.cpp:218] Iteration 47700 (3.38379 iter/s, 29.5527s/100 iters), loss = 0.246408
I1013 02:17:43.267987 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24641 (* 1 = 0.24641 loss)
I1013 02:17:43.267995 11428 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1013 02:18:12.800681 11428 solver.cpp:218] Iteration 47800 (3.38608 iter/s, 29.5327s/100 iters), loss = 0.134379
I1013 02:18:12.800822 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13438 (* 1 = 0.13438 loss)
I1013 02:18:12.800832 11428 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1013 02:18:42.361515 11428 solver.cpp:218] Iteration 47900 (3.38287 iter/s, 29.5607s/100 iters), loss = 0.110269
I1013 02:18:42.361546 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11027 (* 1 = 0.11027 loss)
I1013 02:18:42.361554 11428 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1013 02:19:10.425364 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:19:11.624130 11428 solver.cpp:330] Iteration 48000, Testing net (#0)
I1013 02:19:27.264564 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:19:27.581532 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57279 (* 1 = 1.57279 loss)
I1013 02:19:27.581548 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6611
I1013 02:19:27.871628 11428 solver.cpp:218] Iteration 48000 (2.19731 iter/s, 45.5101s/100 iters), loss = 0.0796721
I1013 02:19:27.871666 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0796734 (* 1 = 0.0796734 loss)
I1013 02:19:27.871675 11428 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1013 02:19:57.399879 11428 solver.cpp:218] Iteration 48100 (3.38659 iter/s, 29.5282s/100 iters), loss = 0.206056
I1013 02:19:57.399991 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206058 (* 1 = 0.206058 loss)
I1013 02:19:57.399999 11428 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1013 02:20:26.991961 11428 solver.cpp:218] Iteration 48200 (3.37929 iter/s, 29.592s/100 iters), loss = 0.261319
I1013 02:20:26.991992 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26132 (* 1 = 0.26132 loss)
I1013 02:20:26.991999 11428 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1013 02:20:56.567637 11428 solver.cpp:218] Iteration 48300 (3.38116 iter/s, 29.5757s/100 iters), loss = 0.15558
I1013 02:20:56.567749 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155581 (* 1 = 0.155581 loss)
I1013 02:20:56.567769 11428 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1013 02:21:26.117019 11428 solver.cpp:218] Iteration 48400 (3.38418 iter/s, 29.5493s/100 iters), loss = 0.0510831
I1013 02:21:26.117055 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0510844 (* 1 = 0.0510844 loss)
I1013 02:21:26.117063 11428 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1013 02:21:55.354579 11428 solver.cpp:330] Iteration 48500, Testing net (#0)
I1013 02:22:10.973126 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:22:11.299496 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.6048 (* 1 = 1.6048 loss)
I1013 02:22:11.299513 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6545
I1013 02:22:11.593379 11428 solver.cpp:218] Iteration 48500 (2.19895 iter/s, 45.4763s/100 iters), loss = 0.391753
I1013 02:22:11.593415 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391754 (* 1 = 0.391754 loss)
I1013 02:22:11.593432 11428 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1013 02:22:41.201510 11428 solver.cpp:218] Iteration 48600 (3.37745 iter/s, 29.6081s/100 iters), loss = 0.138555
I1013 02:22:41.201637 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138556 (* 1 = 0.138556 loss)
I1013 02:22:41.201645 11428 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1013 02:23:10.770917 11428 solver.cpp:218] Iteration 48700 (3.38189 iter/s, 29.5693s/100 iters), loss = 0.369727
I1013 02:23:10.770951 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369728 (* 1 = 0.369728 loss)
I1013 02:23:10.770959 11428 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1013 02:23:40.376634 11428 solver.cpp:218] Iteration 48800 (3.37773 iter/s, 29.6057s/100 iters), loss = 0.194013
I1013 02:23:40.376801 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194015 (* 1 = 0.194015 loss)
I1013 02:23:40.376821 11428 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1013 02:24:09.996426 11428 solver.cpp:218] Iteration 48900 (3.37614 iter/s, 29.6196s/100 iters), loss = 0.166583
I1013 02:24:09.996456 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166585 (* 1 = 0.166585 loss)
I1013 02:24:09.996464 11428 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1013 02:24:38.119637 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:24:39.303033 11428 solver.cpp:330] Iteration 49000, Testing net (#0)
I1013 02:24:54.968452 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:24:55.289741 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57935 (* 1 = 1.57935 loss)
I1013 02:24:55.289757 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6603
I1013 02:24:55.582703 11428 solver.cpp:218] Iteration 49000 (2.19364 iter/s, 45.5863s/100 iters), loss = 0.224779
I1013 02:24:55.582746 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224781 (* 1 = 0.224781 loss)
I1013 02:24:55.582754 11428 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1013 02:25:25.143134 11428 solver.cpp:218] Iteration 49100 (3.38294 iter/s, 29.5601s/100 iters), loss = 0.254641
I1013 02:25:25.143272 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254643 (* 1 = 0.254643 loss)
I1013 02:25:25.143280 11428 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1013 02:25:54.745043 11428 solver.cpp:218] Iteration 49200 (3.37818 iter/s, 29.6018s/100 iters), loss = 0.121502
I1013 02:25:54.745075 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121503 (* 1 = 0.121503 loss)
I1013 02:25:54.745084 11428 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1013 02:26:24.320232 11428 solver.cpp:218] Iteration 49300 (3.38122 iter/s, 29.5752s/100 iters), loss = 0.293538
I1013 02:26:24.320365 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29354 (* 1 = 0.29354 loss)
I1013 02:26:24.320375 11428 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1013 02:26:53.867403 11428 solver.cpp:218] Iteration 49400 (3.38443 iter/s, 29.547s/100 iters), loss = 0.175013
I1013 02:26:53.867434 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175015 (* 1 = 0.175015 loss)
I1013 02:26:53.867440 11428 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1013 02:27:23.187162 11428 solver.cpp:330] Iteration 49500, Testing net (#0)
I1013 02:27:38.828402 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:27:39.149364 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.6074 (* 1 = 1.6074 loss)
I1013 02:27:39.149380 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6499
I1013 02:27:39.442440 11428 solver.cpp:218] Iteration 49500 (2.19418 iter/s, 45.575s/100 iters), loss = 0.248164
I1013 02:27:39.442479 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248165 (* 1 = 0.248165 loss)
I1013 02:27:39.442487 11428 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1013 02:28:09.028942 11428 solver.cpp:218] Iteration 49600 (3.37995 iter/s, 29.5862s/100 iters), loss = 0.0884261
I1013 02:28:09.029085 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0884274 (* 1 = 0.0884274 loss)
I1013 02:28:09.029094 11428 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1013 02:28:38.604418 11428 solver.cpp:218] Iteration 49700 (3.38119 iter/s, 29.5753s/100 iters), loss = 0.221749
I1013 02:28:38.604449 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22175 (* 1 = 0.22175 loss)
I1013 02:28:38.604456 11428 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1013 02:29:08.174916 11428 solver.cpp:218] Iteration 49800 (3.38175 iter/s, 29.5705s/100 iters), loss = 0.162017
I1013 02:29:08.175004 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162018 (* 1 = 0.162018 loss)
I1013 02:29:08.175022 11428 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1013 02:29:37.729041 11428 solver.cpp:218] Iteration 49900 (3.38363 iter/s, 29.554s/100 iters), loss = 0.494041
I1013 02:29:37.729073 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494042 (* 1 = 0.494042 loss)
I1013 02:29:37.729079 11428 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1013 02:30:05.783700 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:30:06.965867 11428 solver.cpp:330] Iteration 50000, Testing net (#0)
I1013 02:30:22.557163 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:30:22.876325 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63543 (* 1 = 1.63543 loss)
I1013 02:30:22.876341 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6454
I1013 02:30:23.166512 11428 solver.cpp:218] Iteration 50000 (2.20083 iter/s, 45.4375s/100 iters), loss = 0.33779
I1013 02:30:23.166546 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337791 (* 1 = 0.337791 loss)
I1013 02:30:23.166554 11428 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1013 02:30:52.717912 11428 solver.cpp:218] Iteration 50100 (3.38394 iter/s, 29.5514s/100 iters), loss = 0.148543
I1013 02:30:52.718068 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148544 (* 1 = 0.148544 loss)
I1013 02:30:52.718078 11428 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1013 02:31:22.212247 11428 solver.cpp:218] Iteration 50200 (3.3905 iter/s, 29.4942s/100 iters), loss = 0.158904
I1013 02:31:22.212283 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158905 (* 1 = 0.158905 loss)
I1013 02:31:22.212291 11428 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1013 02:31:51.807482 11428 solver.cpp:218] Iteration 50300 (3.37893 iter/s, 29.5952s/100 iters), loss = 0.197631
I1013 02:31:51.807623 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197632 (* 1 = 0.197632 loss)
I1013 02:31:51.807649 11428 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1013 02:32:21.312391 11428 solver.cpp:218] Iteration 50400 (3.38928 iter/s, 29.5048s/100 iters), loss = 0.234675
I1013 02:32:21.312425 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234676 (* 1 = 0.234676 loss)
I1013 02:32:21.312433 11428 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1013 02:32:50.578393 11428 solver.cpp:330] Iteration 50500, Testing net (#0)
I1013 02:33:06.175561 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:33:06.493827 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60229 (* 1 = 1.60229 loss)
I1013 02:33:06.493844 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6512
I1013 02:33:06.782977 11428 solver.cpp:218] Iteration 50500 (2.19922 iter/s, 45.4706s/100 iters), loss = 0.20343
I1013 02:33:06.783010 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203431 (* 1 = 0.203431 loss)
I1013 02:33:06.783016 11428 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1013 02:33:36.318861 11428 solver.cpp:218] Iteration 50600 (3.38572 iter/s, 29.5359s/100 iters), loss = 0.268048
I1013 02:33:36.318964 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268049 (* 1 = 0.268049 loss)
I1013 02:33:36.318972 11428 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1013 02:34:05.875545 11428 solver.cpp:218] Iteration 50700 (3.38334 iter/s, 29.5566s/100 iters), loss = 0.248161
I1013 02:34:05.875578 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248162 (* 1 = 0.248162 loss)
I1013 02:34:05.875586 11428 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1013 02:34:35.392932 11428 solver.cpp:218] Iteration 50800 (3.38784 iter/s, 29.5174s/100 iters), loss = 0.0979164
I1013 02:34:35.393071 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0979176 (* 1 = 0.0979176 loss)
I1013 02:34:35.393079 11428 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1013 02:35:04.947140 11428 solver.cpp:218] Iteration 50900 (3.38363 iter/s, 29.5541s/100 iters), loss = 0.243656
I1013 02:35:04.947173 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243657 (* 1 = 0.243657 loss)
I1013 02:35:04.947180 11428 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1013 02:35:33.032902 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:35:34.215611 11428 solver.cpp:330] Iteration 51000, Testing net (#0)
I1013 02:35:49.830670 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:35:50.148818 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59149 (* 1 = 1.59149 loss)
I1013 02:35:50.148833 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6535
I1013 02:35:50.439486 11428 solver.cpp:218] Iteration 51000 (2.19817 iter/s, 45.4923s/100 iters), loss = 0.20542
I1013 02:35:50.439519 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205421 (* 1 = 0.205421 loss)
I1013 02:35:50.439528 11428 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1013 02:36:19.965797 11428 solver.cpp:218] Iteration 51100 (3.38681 iter/s, 29.5263s/100 iters), loss = 0.199358
I1013 02:36:19.965946 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199359 (* 1 = 0.199359 loss)
I1013 02:36:19.965966 11428 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1013 02:36:49.499333 11428 solver.cpp:218] Iteration 51200 (3.386 iter/s, 29.5334s/100 iters), loss = 0.289654
I1013 02:36:49.499366 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289655 (* 1 = 0.289655 loss)
I1013 02:36:49.499374 11428 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1013 02:37:19.023744 11428 solver.cpp:218] Iteration 51300 (3.38703 iter/s, 29.5244s/100 iters), loss = 0.180482
I1013 02:37:19.023844 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180483 (* 1 = 0.180483 loss)
I1013 02:37:19.023852 11428 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1013 02:37:48.551120 11428 solver.cpp:218] Iteration 51400 (3.3867 iter/s, 29.5273s/100 iters), loss = 0.264112
I1013 02:37:48.551156 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264113 (* 1 = 0.264113 loss)
I1013 02:37:48.551164 11428 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1013 02:38:17.782455 11428 solver.cpp:330] Iteration 51500, Testing net (#0)
I1013 02:38:33.328763 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:38:33.647186 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62326 (* 1 = 1.62326 loss)
I1013 02:38:33.647202 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6519
I1013 02:38:33.937100 11428 solver.cpp:218] Iteration 51500 (2.20332 iter/s, 45.386s/100 iters), loss = 0.358636
I1013 02:38:33.937131 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358638 (* 1 = 0.358638 loss)
I1013 02:38:33.937139 11428 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1013 02:39:03.457119 11428 solver.cpp:218] Iteration 51600 (3.38753 iter/s, 29.52s/100 iters), loss = 0.349725
I1013 02:39:03.457235 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349726 (* 1 = 0.349726 loss)
I1013 02:39:03.457253 11428 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1013 02:39:32.959825 11428 solver.cpp:218] Iteration 51700 (3.38953 iter/s, 29.5026s/100 iters), loss = 0.228839
I1013 02:39:32.959856 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22884 (* 1 = 0.22884 loss)
I1013 02:39:32.959864 11428 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1013 02:40:02.455682 11428 solver.cpp:218] Iteration 51800 (3.39031 iter/s, 29.4958s/100 iters), loss = 0.0586352
I1013 02:40:02.455840 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0586365 (* 1 = 0.0586365 loss)
I1013 02:40:02.455850 11428 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1013 02:40:31.943526 11428 solver.cpp:218] Iteration 51900 (3.39124 iter/s, 29.4877s/100 iters), loss = 0.143187
I1013 02:40:31.943558 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143189 (* 1 = 0.143189 loss)
I1013 02:40:31.943565 11428 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1013 02:40:59.983489 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:41:01.165453 11428 solver.cpp:330] Iteration 52000, Testing net (#0)
I1013 02:41:16.716150 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:41:17.033651 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56246 (* 1 = 1.56246 loss)
I1013 02:41:17.033668 11428 solver.cpp:397]     Test net output #1: accuracy = 0.659
I1013 02:41:17.320673 11428 solver.cpp:218] Iteration 52000 (2.20375 iter/s, 45.3771s/100 iters), loss = 0.0995381
I1013 02:41:17.320708 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0995395 (* 1 = 0.0995395 loss)
I1013 02:41:17.320718 11428 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1013 02:41:46.815827 11428 solver.cpp:218] Iteration 52100 (3.39039 iter/s, 29.4951s/100 iters), loss = 0.322343
I1013 02:41:46.816179 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322344 (* 1 = 0.322344 loss)
I1013 02:41:46.816189 11428 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1013 02:42:16.321828 11428 solver.cpp:218] Iteration 52200 (3.38918 iter/s, 29.5057s/100 iters), loss = 0.0652354
I1013 02:42:16.321866 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0652369 (* 1 = 0.0652369 loss)
I1013 02:42:16.321883 11428 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1013 02:42:45.838999 11428 solver.cpp:218] Iteration 52300 (3.38786 iter/s, 29.5171s/100 iters), loss = 0.164531
I1013 02:42:45.839139 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164532 (* 1 = 0.164532 loss)
I1013 02:42:45.839149 11428 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1013 02:43:15.346738 11428 solver.cpp:218] Iteration 52400 (3.38896 iter/s, 29.5076s/100 iters), loss = 0.17342
I1013 02:43:15.346770 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173422 (* 1 = 0.173422 loss)
I1013 02:43:15.346776 11428 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1013 02:43:44.558068 11428 solver.cpp:330] Iteration 52500, Testing net (#0)
I1013 02:44:00.109452 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:44:00.428519 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61919 (* 1 = 1.61919 loss)
I1013 02:44:00.428534 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6566
I1013 02:44:00.717469 11428 solver.cpp:218] Iteration 52500 (2.20406 iter/s, 45.3707s/100 iters), loss = 0.222555
I1013 02:44:00.717504 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222557 (* 1 = 0.222557 loss)
I1013 02:44:00.717514 11428 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1013 02:44:30.200707 11428 solver.cpp:218] Iteration 52600 (3.39176 iter/s, 29.4832s/100 iters), loss = 0.171136
I1013 02:44:30.200852 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171138 (* 1 = 0.171138 loss)
I1013 02:44:30.200861 11428 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1013 02:44:59.671262 11428 solver.cpp:218] Iteration 52700 (3.39323 iter/s, 29.4704s/100 iters), loss = 0.0843152
I1013 02:44:59.671293 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0843167 (* 1 = 0.0843167 loss)
I1013 02:44:59.671300 11428 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1013 02:45:29.158563 11428 solver.cpp:218] Iteration 52800 (3.39129 iter/s, 29.4873s/100 iters), loss = 0.0969533
I1013 02:45:29.158675 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0969548 (* 1 = 0.0969548 loss)
I1013 02:45:29.158684 11428 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1013 02:45:58.613852 11428 solver.cpp:218] Iteration 52900 (3.39499 iter/s, 29.4552s/100 iters), loss = 0.274491
I1013 02:45:58.613894 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274493 (* 1 = 0.274493 loss)
I1013 02:45:58.613903 11428 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1013 02:46:26.631170 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:46:27.809175 11428 solver.cpp:330] Iteration 53000, Testing net (#0)
I1013 02:46:43.357522 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:46:43.673444 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57988 (* 1 = 1.57988 loss)
I1013 02:46:43.673461 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6552
I1013 02:46:43.961961 11428 solver.cpp:218] Iteration 53000 (2.20516 iter/s, 45.3481s/100 iters), loss = 0.0568367
I1013 02:46:43.961992 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568381 (* 1 = 0.0568381 loss)
I1013 02:46:43.961999 11428 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1013 02:47:13.448657 11428 solver.cpp:218] Iteration 53100 (3.39136 iter/s, 29.4867s/100 iters), loss = 0.4053
I1013 02:47:13.448807 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405301 (* 1 = 0.405301 loss)
I1013 02:47:13.448817 11428 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1013 02:47:42.937822 11428 solver.cpp:218] Iteration 53200 (3.39109 iter/s, 29.489s/100 iters), loss = 0.286418
I1013 02:47:42.937853 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28642 (* 1 = 0.28642 loss)
I1013 02:47:42.937860 11428 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1013 02:48:12.438504 11428 solver.cpp:218] Iteration 53300 (3.38975 iter/s, 29.5007s/100 iters), loss = 0.172671
I1013 02:48:12.438648 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172672 (* 1 = 0.172672 loss)
I1013 02:48:12.438658 11428 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1013 02:48:41.924314 11428 solver.cpp:218] Iteration 53400 (3.39148 iter/s, 29.4857s/100 iters), loss = 0.15197
I1013 02:48:41.924345 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151972 (* 1 = 0.151972 loss)
I1013 02:48:41.924352 11428 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1013 02:49:11.138298 11428 solver.cpp:330] Iteration 53500, Testing net (#0)
I1013 02:49:26.683676 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:49:27.001114 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60107 (* 1 = 1.60107 loss)
I1013 02:49:27.001150 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6575
I1013 02:49:27.288900 11428 solver.cpp:218] Iteration 53500 (2.20436 iter/s, 45.3646s/100 iters), loss = 0.158877
I1013 02:49:27.288936 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158879 (* 1 = 0.158879 loss)
I1013 02:49:27.288944 11428 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1013 02:49:56.812263 11428 solver.cpp:218] Iteration 53600 (3.38715 iter/s, 29.5233s/100 iters), loss = 0.168487
I1013 02:49:56.812376 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168489 (* 1 = 0.168489 loss)
I1013 02:49:56.812393 11428 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1013 02:50:26.352468 11428 solver.cpp:218] Iteration 53700 (3.38523 iter/s, 29.5401s/100 iters), loss = 0.128852
I1013 02:50:26.352502 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128853 (* 1 = 0.128853 loss)
I1013 02:50:26.352510 11428 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1013 02:50:55.870892 11428 solver.cpp:218] Iteration 53800 (3.38772 iter/s, 29.5184s/100 iters), loss = 0.0730106
I1013 02:50:55.871035 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0730121 (* 1 = 0.0730121 loss)
I1013 02:50:55.871044 11428 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1013 02:51:25.373107 11428 solver.cpp:218] Iteration 53900 (3.38959 iter/s, 29.5021s/100 iters), loss = 0.252086
I1013 02:51:25.373139 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252087 (* 1 = 0.252087 loss)
I1013 02:51:25.373147 11428 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1013 02:51:53.423732 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:51:54.601505 11428 solver.cpp:330] Iteration 54000, Testing net (#0)
I1013 02:52:10.145352 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:52:10.463459 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62816 (* 1 = 1.62816 loss)
I1013 02:52:10.463474 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6526
I1013 02:52:10.753360 11428 solver.cpp:218] Iteration 54000 (2.2036 iter/s, 45.3802s/100 iters), loss = 0.0751179
I1013 02:52:10.753394 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0751193 (* 1 = 0.0751193 loss)
I1013 02:52:10.753402 11428 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1013 02:52:40.279944 11428 solver.cpp:218] Iteration 54100 (3.38678 iter/s, 29.5266s/100 iters), loss = 0.157429
I1013 02:52:40.280066 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15743 (* 1 = 0.15743 loss)
I1013 02:52:40.280074 11428 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1013 02:53:09.802773 11428 solver.cpp:218] Iteration 54200 (3.38722 iter/s, 29.5227s/100 iters), loss = 0.229628
I1013 02:53:09.802805 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229629 (* 1 = 0.229629 loss)
I1013 02:53:09.802812 11428 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1013 02:53:39.336681 11428 solver.cpp:218] Iteration 54300 (3.38594 iter/s, 29.5339s/100 iters), loss = 0.284285
I1013 02:53:39.336783 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284287 (* 1 = 0.284287 loss)
I1013 02:53:39.336802 11428 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1013 02:54:08.881690 11428 solver.cpp:218] Iteration 54400 (3.38468 iter/s, 29.5449s/100 iters), loss = 0.177834
I1013 02:54:08.881728 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177835 (* 1 = 0.177835 loss)
I1013 02:54:08.881738 11428 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1013 02:54:38.144162 11428 solver.cpp:330] Iteration 54500, Testing net (#0)
I1013 02:54:53.688037 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:54:54.005857 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61324 (* 1 = 1.61324 loss)
I1013 02:54:54.005875 11428 solver.cpp:397]     Test net output #1: accuracy = 0.654
I1013 02:54:54.296103 11428 solver.cpp:218] Iteration 54500 (2.20195 iter/s, 45.4144s/100 iters), loss = 0.196946
I1013 02:54:54.296139 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196947 (* 1 = 0.196947 loss)
I1013 02:54:54.296151 11428 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1013 02:55:23.824770 11428 solver.cpp:218] Iteration 54600 (3.38654 iter/s, 29.5286s/100 iters), loss = 0.151214
I1013 02:55:23.824864 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151215 (* 1 = 0.151215 loss)
I1013 02:55:23.824877 11428 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1013 02:55:53.345618 11428 solver.cpp:218] Iteration 54700 (3.38745 iter/s, 29.5208s/100 iters), loss = 0.259995
I1013 02:55:53.345654 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259997 (* 1 = 0.259997 loss)
I1013 02:55:53.345662 11428 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1013 02:56:22.847518 11428 solver.cpp:218] Iteration 54800 (3.38962 iter/s, 29.5019s/100 iters), loss = 0.198008
I1013 02:56:22.849889 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198009 (* 1 = 0.198009 loss)
I1013 02:56:22.849898 11428 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1013 02:56:52.372356 11428 solver.cpp:218] Iteration 54900 (3.38725 iter/s, 29.5225s/100 iters), loss = 0.217998
I1013 02:56:52.372390 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218 (* 1 = 0.218 loss)
I1013 02:56:52.372397 11428 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1013 02:57:20.409452 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:57:21.590442 11428 solver.cpp:330] Iteration 55000, Testing net (#0)
I1013 02:57:37.129257 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 02:57:37.447304 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.52811 (* 1 = 1.52811 loss)
I1013 02:57:37.447319 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6692
I1013 02:57:37.737273 11428 solver.cpp:218] Iteration 55000 (2.20435 iter/s, 45.3649s/100 iters), loss = 0.196889
I1013 02:57:37.737308 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196891 (* 1 = 0.196891 loss)
I1013 02:57:37.737315 11428 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1013 02:58:07.211935 11428 solver.cpp:218] Iteration 55100 (3.39275 iter/s, 29.4746s/100 iters), loss = 0.234609
I1013 02:58:07.212095 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23461 (* 1 = 0.23461 loss)
I1013 02:58:07.212105 11428 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1013 02:58:36.695358 11428 solver.cpp:218] Iteration 55200 (3.39175 iter/s, 29.4833s/100 iters), loss = 0.363418
I1013 02:58:36.695391 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363419 (* 1 = 0.363419 loss)
I1013 02:58:36.695401 11428 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1013 02:59:06.165446 11428 solver.cpp:218] Iteration 55300 (3.39327 iter/s, 29.4701s/100 iters), loss = 0.308765
I1013 02:59:06.165591 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308766 (* 1 = 0.308766 loss)
I1013 02:59:06.165601 11428 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1013 02:59:35.645925 11428 solver.cpp:218] Iteration 55400 (3.39209 iter/s, 29.4803s/100 iters), loss = 0.134126
I1013 02:59:35.645957 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134128 (* 1 = 0.134128 loss)
I1013 02:59:35.645964 11428 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1013 03:00:04.831473 11428 solver.cpp:330] Iteration 55500, Testing net (#0)
I1013 03:00:20.378703 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:00:20.697232 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60133 (* 1 = 1.60133 loss)
I1013 03:00:20.697247 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6582
I1013 03:00:20.986497 11428 solver.cpp:218] Iteration 55500 (2.20553 iter/s, 45.3406s/100 iters), loss = 0.334645
I1013 03:00:20.986531 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334647 (* 1 = 0.334647 loss)
I1013 03:00:20.986538 11428 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1013 03:00:50.499162 11428 solver.cpp:218] Iteration 55600 (3.38838 iter/s, 29.5126s/100 iters), loss = 0.21082
I1013 03:00:50.499302 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210821 (* 1 = 0.210821 loss)
I1013 03:00:50.499321 11428 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1013 03:01:20.006260 11428 solver.cpp:218] Iteration 55700 (3.38903 iter/s, 29.507s/100 iters), loss = 0.168584
I1013 03:01:20.006292 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168585 (* 1 = 0.168585 loss)
I1013 03:01:20.006300 11428 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1013 03:01:49.484877 11428 solver.cpp:218] Iteration 55800 (3.39229 iter/s, 29.4786s/100 iters), loss = 0.261178
I1013 03:01:49.484992 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26118 (* 1 = 0.26118 loss)
I1013 03:01:49.484999 11428 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1013 03:02:18.981173 11428 solver.cpp:218] Iteration 55900 (3.39027 iter/s, 29.4962s/100 iters), loss = 0.220735
I1013 03:02:18.981206 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220737 (* 1 = 0.220737 loss)
I1013 03:02:18.981215 11428 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1013 03:02:47.002734 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:02:48.181988 11428 solver.cpp:330] Iteration 56000, Testing net (#0)
I1013 03:03:03.733266 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:03:04.051610 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55878 (* 1 = 1.55878 loss)
I1013 03:03:04.051626 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6597
I1013 03:03:04.341060 11428 solver.cpp:218] Iteration 56000 (2.20459 iter/s, 45.3599s/100 iters), loss = 0.184601
I1013 03:03:04.341105 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184602 (* 1 = 0.184602 loss)
I1013 03:03:04.341114 11428 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1013 03:03:33.840560 11428 solver.cpp:218] Iteration 56100 (3.38989 iter/s, 29.4995s/100 iters), loss = 0.120634
I1013 03:03:33.840692 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120635 (* 1 = 0.120635 loss)
I1013 03:03:33.840711 11428 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1013 03:04:03.330852 11428 solver.cpp:218] Iteration 56200 (3.39096 iter/s, 29.4902s/100 iters), loss = 0.170773
I1013 03:04:03.330884 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170774 (* 1 = 0.170774 loss)
I1013 03:04:03.330893 11428 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1013 03:04:32.830015 11428 solver.cpp:218] Iteration 56300 (3.38993 iter/s, 29.4991s/100 iters), loss = 0.25928
I1013 03:04:32.830134 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259281 (* 1 = 0.259281 loss)
I1013 03:04:32.830144 11428 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1013 03:05:02.356362 11428 solver.cpp:218] Iteration 56400 (3.38682 iter/s, 29.5262s/100 iters), loss = 0.120252
I1013 03:05:02.356395 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120253 (* 1 = 0.120253 loss)
I1013 03:05:02.356403 11428 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1013 03:05:31.581648 11428 solver.cpp:330] Iteration 56500, Testing net (#0)
I1013 03:05:47.124078 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:05:47.441793 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57735 (* 1 = 1.57735 loss)
I1013 03:05:47.441810 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6569
I1013 03:05:47.732389 11428 solver.cpp:218] Iteration 56500 (2.20381 iter/s, 45.376s/100 iters), loss = 0.338562
I1013 03:05:47.732422 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338563 (* 1 = 0.338563 loss)
I1013 03:05:47.732430 11428 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1013 03:06:17.207234 11428 solver.cpp:218] Iteration 56600 (3.39273 iter/s, 29.4748s/100 iters), loss = 0.268581
I1013 03:06:17.207384 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268582 (* 1 = 0.268582 loss)
I1013 03:06:17.207392 11428 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1013 03:06:46.665251 11428 solver.cpp:218] Iteration 56700 (3.39468 iter/s, 29.4579s/100 iters), loss = 0.242345
I1013 03:06:46.665282 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242347 (* 1 = 0.242347 loss)
I1013 03:06:46.665290 11428 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1013 03:07:16.146670 11428 solver.cpp:218] Iteration 56800 (3.39197 iter/s, 29.4814s/100 iters), loss = 0.203827
I1013 03:07:16.146817 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203828 (* 1 = 0.203828 loss)
I1013 03:07:16.146826 11428 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1013 03:07:45.625919 11428 solver.cpp:218] Iteration 56900 (3.39223 iter/s, 29.4791s/100 iters), loss = 0.186835
I1013 03:07:45.625952 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186836 (* 1 = 0.186836 loss)
I1013 03:07:45.625959 11428 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1013 03:08:13.657783 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:08:14.840095 11428 solver.cpp:330] Iteration 57000, Testing net (#0)
I1013 03:08:30.401293 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:08:30.718711 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60252 (* 1 = 1.60252 loss)
I1013 03:08:30.718729 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6536
I1013 03:08:31.008288 11428 solver.cpp:218] Iteration 57000 (2.2035 iter/s, 45.3824s/100 iters), loss = 0.302462
I1013 03:08:31.008319 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302463 (* 1 = 0.302463 loss)
I1013 03:08:31.008327 11428 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1013 03:09:00.518959 11428 solver.cpp:218] Iteration 57100 (3.38861 iter/s, 29.5107s/100 iters), loss = 0.309576
I1013 03:09:00.519106 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309577 (* 1 = 0.309577 loss)
I1013 03:09:00.519116 11428 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1013 03:09:30.040236 11428 solver.cpp:218] Iteration 57200 (3.3874 iter/s, 29.5211s/100 iters), loss = 0.344946
I1013 03:09:30.040268 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344947 (* 1 = 0.344947 loss)
I1013 03:09:30.040276 11428 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1013 03:09:59.554359 11428 solver.cpp:218] Iteration 57300 (3.38821 iter/s, 29.5141s/100 iters), loss = 0.147394
I1013 03:09:59.554456 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147395 (* 1 = 0.147395 loss)
I1013 03:09:59.554476 11428 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1013 03:10:29.060808 11428 solver.cpp:218] Iteration 57400 (3.3891 iter/s, 29.5064s/100 iters), loss = 0.314091
I1013 03:10:29.060839 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314092 (* 1 = 0.314092 loss)
I1013 03:10:29.060847 11428 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1013 03:10:58.280527 11428 solver.cpp:330] Iteration 57500, Testing net (#0)
I1013 03:11:13.827034 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:11:14.146757 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57171 (* 1 = 1.57171 loss)
I1013 03:11:14.146775 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6554
I1013 03:11:14.436592 11428 solver.cpp:218] Iteration 57500 (2.20382 iter/s, 45.3758s/100 iters), loss = 0.114088
I1013 03:11:14.436635 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114089 (* 1 = 0.114089 loss)
I1013 03:11:14.436645 11428 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1013 03:11:43.926683 11428 solver.cpp:218] Iteration 57600 (3.39097 iter/s, 29.4901s/100 iters), loss = 0.168326
I1013 03:11:43.926827 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168328 (* 1 = 0.168328 loss)
I1013 03:11:43.926836 11428 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1013 03:12:13.415442 11428 solver.cpp:218] Iteration 57700 (3.39114 iter/s, 29.4886s/100 iters), loss = 0.0741764
I1013 03:12:13.415473 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0741777 (* 1 = 0.0741777 loss)
I1013 03:12:13.415480 11428 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1013 03:12:42.906944 11428 solver.cpp:218] Iteration 57800 (3.39081 iter/s, 29.4915s/100 iters), loss = 0.221616
I1013 03:12:42.907086 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221617 (* 1 = 0.221617 loss)
I1013 03:12:42.907095 11428 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1013 03:13:12.387851 11428 solver.cpp:218] Iteration 57900 (3.39204 iter/s, 29.4808s/100 iters), loss = 0.154215
I1013 03:13:12.387883 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154216 (* 1 = 0.154216 loss)
I1013 03:13:12.387890 11428 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1013 03:13:40.394795 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:13:41.577416 11428 solver.cpp:330] Iteration 58000, Testing net (#0)
I1013 03:13:57.116542 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:13:57.434423 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58803 (* 1 = 1.58803 loss)
I1013 03:13:57.434450 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6572
I1013 03:13:57.722308 11428 solver.cpp:218] Iteration 58000 (2.20583 iter/s, 45.3344s/100 iters), loss = 0.176619
I1013 03:13:57.722342 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17662 (* 1 = 0.17662 loss)
I1013 03:13:57.722349 11428 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1013 03:14:27.179894 11428 solver.cpp:218] Iteration 58100 (3.39471 iter/s, 29.4576s/100 iters), loss = 0.163208
I1013 03:14:27.180006 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163209 (* 1 = 0.163209 loss)
I1013 03:14:27.180013 11428 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1013 03:14:56.634086 11428 solver.cpp:218] Iteration 58200 (3.39511 iter/s, 29.4541s/100 iters), loss = 0.100195
I1013 03:14:56.634130 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100196 (* 1 = 0.100196 loss)
I1013 03:14:56.634137 11428 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1013 03:15:26.106276 11428 solver.cpp:218] Iteration 58300 (3.39303 iter/s, 29.4722s/100 iters), loss = 0.309637
I1013 03:15:26.106431 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309638 (* 1 = 0.309638 loss)
I1013 03:15:26.106439 11428 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1013 03:15:55.598896 11428 solver.cpp:218] Iteration 58400 (3.3907 iter/s, 29.4925s/100 iters), loss = 0.272393
I1013 03:15:55.598929 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272395 (* 1 = 0.272395 loss)
I1013 03:15:55.598937 11428 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1013 03:16:24.814982 11428 solver.cpp:330] Iteration 58500, Testing net (#0)
I1013 03:16:40.365483 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:16:40.683042 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58483 (* 1 = 1.58483 loss)
I1013 03:16:40.683068 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6618
I1013 03:16:40.971021 11428 solver.cpp:218] Iteration 58500 (2.204 iter/s, 45.3721s/100 iters), loss = 0.173833
I1013 03:16:40.971051 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173834 (* 1 = 0.173834 loss)
I1013 03:16:40.971060 11428 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1013 03:17:10.427942 11428 solver.cpp:218] Iteration 58600 (3.39479 iter/s, 29.4569s/100 iters), loss = 0.273704
I1013 03:17:10.428086 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273706 (* 1 = 0.273706 loss)
I1013 03:17:10.428105 11428 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1013 03:17:39.906585 11428 solver.cpp:218] Iteration 58700 (3.3923 iter/s, 29.4785s/100 iters), loss = 0.125422
I1013 03:17:39.906618 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125423 (* 1 = 0.125423 loss)
I1013 03:17:39.906626 11428 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1013 03:18:09.394623 11428 solver.cpp:218] Iteration 58800 (3.39121 iter/s, 29.488s/100 iters), loss = 0.112982
I1013 03:18:09.394726 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112983 (* 1 = 0.112983 loss)
I1013 03:18:09.394733 11428 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1013 03:18:38.849052 11428 solver.cpp:218] Iteration 58900 (3.39509 iter/s, 29.4543s/100 iters), loss = 0.256926
I1013 03:18:38.849083 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256927 (* 1 = 0.256927 loss)
I1013 03:18:38.849090 11428 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1013 03:19:06.859259 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:19:08.035395 11428 solver.cpp:330] Iteration 59000, Testing net (#0)
I1013 03:19:23.571143 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:19:23.890655 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57689 (* 1 = 1.57689 loss)
I1013 03:19:23.890671 11428 solver.cpp:397]     Test net output #1: accuracy = 0.659
I1013 03:19:24.182003 11428 solver.cpp:218] Iteration 59000 (2.2059 iter/s, 45.3329s/100 iters), loss = 0.179325
I1013 03:19:24.182036 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179326 (* 1 = 0.179326 loss)
I1013 03:19:24.182059 11428 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1013 03:19:53.651970 11428 solver.cpp:218] Iteration 59100 (3.39329 iter/s, 29.4699s/100 iters), loss = 0.136923
I1013 03:19:53.652082 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136925 (* 1 = 0.136925 loss)
I1013 03:19:53.652091 11428 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1013 03:20:23.124492 11428 solver.cpp:218] Iteration 59200 (3.393 iter/s, 29.4724s/100 iters), loss = 0.246479
I1013 03:20:23.124524 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246481 (* 1 = 0.246481 loss)
I1013 03:20:23.124532 11428 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1013 03:20:52.592551 11428 solver.cpp:218] Iteration 59300 (3.39351 iter/s, 29.468s/100 iters), loss = 0.250409
I1013 03:20:52.592700 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25041 (* 1 = 0.25041 loss)
I1013 03:20:52.592708 11428 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1013 03:21:22.059804 11428 solver.cpp:218] Iteration 59400 (3.39361 iter/s, 29.4671s/100 iters), loss = 0.144874
I1013 03:21:22.059839 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144875 (* 1 = 0.144875 loss)
I1013 03:21:22.059845 11428 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1013 03:21:51.226974 11428 solver.cpp:330] Iteration 59500, Testing net (#0)
I1013 03:22:06.774808 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:22:07.093147 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55702 (* 1 = 1.55702 loss)
I1013 03:22:07.093163 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6571
I1013 03:22:07.382854 11428 solver.cpp:218] Iteration 59500 (2.20638 iter/s, 45.323s/100 iters), loss = 0.37694
I1013 03:22:07.382889 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376941 (* 1 = 0.376941 loss)
I1013 03:22:07.382897 11428 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1013 03:22:36.852699 11428 solver.cpp:218] Iteration 59600 (3.3933 iter/s, 29.4698s/100 iters), loss = 0.147677
I1013 03:22:36.852811 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147679 (* 1 = 0.147679 loss)
I1013 03:22:36.852819 11428 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1013 03:23:06.314306 11428 solver.cpp:218] Iteration 59700 (3.39426 iter/s, 29.4615s/100 iters), loss = 0.258187
I1013 03:23:06.314338 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258188 (* 1 = 0.258188 loss)
I1013 03:23:06.314345 11428 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1013 03:23:35.800472 11428 solver.cpp:218] Iteration 59800 (3.39142 iter/s, 29.4861s/100 iters), loss = 0.19789
I1013 03:23:35.800582 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197891 (* 1 = 0.197891 loss)
I1013 03:23:35.800590 11428 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1013 03:24:05.277637 11428 solver.cpp:218] Iteration 59900 (3.39247 iter/s, 29.4771s/100 iters), loss = 0.358518
I1013 03:24:05.277669 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358519 (* 1 = 0.358519 loss)
I1013 03:24:05.277676 11428 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1013 03:24:33.292929 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:24:34.475795 11428 solver.cpp:330] Iteration 60000, Testing net (#0)
I1013 03:24:50.017129 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:24:50.335721 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55764 (* 1 = 1.55764 loss)
I1013 03:24:50.335737 11428 solver.cpp:397]     Test net output #1: accuracy = 0.6607
I1013 03:24:50.625146 11428 solver.cpp:218] Iteration 60000 (2.20519 iter/s, 45.3475s/100 iters), loss = 0.0590664
I1013 03:24:50.625181 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0590677 (* 1 = 0.0590677 loss)
I1013 03:24:50.625188 11428 sgd_solver.cpp:46] MultiStep Status: Iteration 60000, step = 1
I1013 03:24:50.625192 11428 sgd_solver.cpp:105] Iteration 60000, lr = 0.001
I1013 03:25:20.095852 11428 solver.cpp:218] Iteration 60100 (3.3932 iter/s, 29.4707s/100 iters), loss = 0.30619
I1013 03:25:20.095996 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306191 (* 1 = 0.306191 loss)
I1013 03:25:20.096005 11428 sgd_solver.cpp:105] Iteration 60100, lr = 0.001
I1013 03:25:49.567847 11428 solver.cpp:218] Iteration 60200 (3.39307 iter/s, 29.4719s/100 iters), loss = 0.117294
I1013 03:25:49.567879 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117296 (* 1 = 0.117296 loss)
I1013 03:25:49.567888 11428 sgd_solver.cpp:105] Iteration 60200, lr = 0.001
I1013 03:26:19.029330 11428 solver.cpp:218] Iteration 60300 (3.39426 iter/s, 29.4615s/100 iters), loss = 0.115864
I1013 03:26:19.029455 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115865 (* 1 = 0.115865 loss)
I1013 03:26:19.029464 11428 sgd_solver.cpp:105] Iteration 60300, lr = 0.001
I1013 03:26:48.483924 11428 solver.cpp:218] Iteration 60400 (3.39507 iter/s, 29.4545s/100 iters), loss = 0.190978
I1013 03:26:48.483958 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190979 (* 1 = 0.190979 loss)
I1013 03:26:48.483964 11428 sgd_solver.cpp:105] Iteration 60400, lr = 0.001
I1013 03:27:17.666980 11428 solver.cpp:330] Iteration 60500, Testing net (#0)
I1013 03:27:33.209666 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:27:33.527020 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.25137 (* 1 = 1.25137 loss)
I1013 03:27:33.527038 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7166
I1013 03:27:33.817301 11428 solver.cpp:218] Iteration 60500 (2.20588 iter/s, 45.3334s/100 iters), loss = 0.0410714
I1013 03:27:33.817335 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410727 (* 1 = 0.0410727 loss)
I1013 03:27:33.817347 11428 sgd_solver.cpp:105] Iteration 60500, lr = 0.001
I1013 03:28:03.279556 11428 solver.cpp:218] Iteration 60600 (3.39418 iter/s, 29.4622s/100 iters), loss = 0.0894778
I1013 03:28:03.279698 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.089479 (* 1 = 0.089479 loss)
I1013 03:28:03.279707 11428 sgd_solver.cpp:105] Iteration 60600, lr = 0.001
I1013 03:28:32.729859 11428 solver.cpp:218] Iteration 60700 (3.39557 iter/s, 29.4502s/100 iters), loss = 0.100036
I1013 03:28:32.729892 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100037 (* 1 = 0.100037 loss)
I1013 03:28:32.729899 11428 sgd_solver.cpp:105] Iteration 60700, lr = 0.001
I1013 03:29:02.196972 11428 solver.cpp:218] Iteration 60800 (3.39362 iter/s, 29.4671s/100 iters), loss = 0.11675
I1013 03:29:02.197087 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116751 (* 1 = 0.116751 loss)
I1013 03:29:02.197094 11428 sgd_solver.cpp:105] Iteration 60800, lr = 0.001
I1013 03:29:31.659560 11428 solver.cpp:218] Iteration 60900 (3.39415 iter/s, 29.4625s/100 iters), loss = 0.00966148
I1013 03:29:31.659593 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00966266 (* 1 = 0.00966266 loss)
I1013 03:29:31.659601 11428 sgd_solver.cpp:105] Iteration 60900, lr = 0.001
I1013 03:29:59.655534 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:30:00.833873 11428 solver.cpp:330] Iteration 61000, Testing net (#0)
I1013 03:30:16.384078 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:30:16.702371 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.2183 (* 1 = 1.2183 loss)
I1013 03:30:16.702386 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7237
I1013 03:30:16.992048 11428 solver.cpp:218] Iteration 61000 (2.20592 iter/s, 45.3325s/100 iters), loss = 0.0078144
I1013 03:30:16.992081 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00781559 (* 1 = 0.00781559 loss)
I1013 03:30:16.992089 11428 sgd_solver.cpp:105] Iteration 61000, lr = 0.001
I1013 03:30:46.448788 11428 solver.cpp:218] Iteration 61100 (3.39481 iter/s, 29.4567s/100 iters), loss = 0.0543618
I1013 03:30:46.448894 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054363 (* 1 = 0.054363 loss)
I1013 03:30:46.448904 11428 sgd_solver.cpp:105] Iteration 61100, lr = 0.001
I1013 03:31:15.917546 11428 solver.cpp:218] Iteration 61200 (3.39344 iter/s, 29.4687s/100 iters), loss = 0.0850149
I1013 03:31:15.917579 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0850161 (* 1 = 0.0850161 loss)
I1013 03:31:15.917587 11428 sgd_solver.cpp:105] Iteration 61200, lr = 0.001
I1013 03:31:45.375965 11428 solver.cpp:218] Iteration 61300 (3.39462 iter/s, 29.4584s/100 iters), loss = 0.122631
I1013 03:31:45.376073 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122632 (* 1 = 0.122632 loss)
I1013 03:31:45.376091 11428 sgd_solver.cpp:105] Iteration 61300, lr = 0.001
I1013 03:32:14.828740 11428 solver.cpp:218] Iteration 61400 (3.39528 iter/s, 29.4527s/100 iters), loss = 0.0369915
I1013 03:32:14.828773 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369927 (* 1 = 0.0369927 loss)
I1013 03:32:14.828781 11428 sgd_solver.cpp:105] Iteration 61400, lr = 0.001
I1013 03:32:43.992332 11428 solver.cpp:330] Iteration 61500, Testing net (#0)
I1013 03:32:59.537202 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:32:59.853850 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20807 (* 1 = 1.20807 loss)
I1013 03:32:59.853864 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7239
I1013 03:33:00.142639 11428 solver.cpp:218] Iteration 61500 (2.20683 iter/s, 45.3139s/100 iters), loss = 0.0244435
I1013 03:33:00.142676 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244446 (* 1 = 0.0244446 loss)
I1013 03:33:00.142684 11428 sgd_solver.cpp:105] Iteration 61500, lr = 0.001
I1013 03:33:29.580512 11428 solver.cpp:218] Iteration 61600 (3.39699 iter/s, 29.4378s/100 iters), loss = 0.0354946
I1013 03:33:29.580659 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354958 (* 1 = 0.0354958 loss)
I1013 03:33:29.580667 11428 sgd_solver.cpp:105] Iteration 61600, lr = 0.001
I1013 03:33:59.046792 11428 solver.cpp:218] Iteration 61700 (3.39373 iter/s, 29.4661s/100 iters), loss = 0.0132897
I1013 03:33:59.046824 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132908 (* 1 = 0.0132908 loss)
I1013 03:33:59.046831 11428 sgd_solver.cpp:105] Iteration 61700, lr = 0.001
I1013 03:34:28.516331 11428 solver.cpp:218] Iteration 61800 (3.39334 iter/s, 29.4695s/100 iters), loss = 0.0218888
I1013 03:34:28.516443 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02189 (* 1 = 0.02189 loss)
I1013 03:34:28.516450 11428 sgd_solver.cpp:105] Iteration 61800, lr = 0.001
I1013 03:34:57.987126 11428 solver.cpp:218] Iteration 61900 (3.3932 iter/s, 29.4707s/100 iters), loss = 0.00756216
I1013 03:34:57.987157 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00756333 (* 1 = 0.00756333 loss)
I1013 03:34:57.987164 11428 sgd_solver.cpp:105] Iteration 61900, lr = 0.001
I1013 03:35:25.987298 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:35:27.164664 11428 solver.cpp:330] Iteration 62000, Testing net (#0)
I1013 03:35:42.710808 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:35:43.027897 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19786 (* 1 = 1.19786 loss)
I1013 03:35:43.027914 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7271
I1013 03:35:43.316130 11428 solver.cpp:218] Iteration 62000 (2.20609 iter/s, 45.329s/100 iters), loss = 0.0180949
I1013 03:35:43.316165 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180961 (* 1 = 0.0180961 loss)
I1013 03:35:43.316174 11428 sgd_solver.cpp:105] Iteration 62000, lr = 0.001
I1013 03:36:12.786942 11428 solver.cpp:218] Iteration 62100 (3.39319 iter/s, 29.4708s/100 iters), loss = 0.0754708
I1013 03:36:12.787061 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.075472 (* 1 = 0.075472 loss)
I1013 03:36:12.787081 11428 sgd_solver.cpp:105] Iteration 62100, lr = 0.001
I1013 03:36:42.263098 11428 solver.cpp:218] Iteration 62200 (3.39258 iter/s, 29.4761s/100 iters), loss = 0.0256296
I1013 03:36:42.263128 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256308 (* 1 = 0.0256308 loss)
I1013 03:36:42.263135 11428 sgd_solver.cpp:105] Iteration 62200, lr = 0.001
I1013 03:37:11.745450 11428 solver.cpp:218] Iteration 62300 (3.39186 iter/s, 29.4823s/100 iters), loss = 0.0814871
I1013 03:37:11.745594 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0814883 (* 1 = 0.0814883 loss)
I1013 03:37:11.745605 11428 sgd_solver.cpp:105] Iteration 62300, lr = 0.001
I1013 03:37:41.210798 11428 solver.cpp:218] Iteration 62400 (3.39383 iter/s, 29.4652s/100 iters), loss = 0.0581835
I1013 03:37:41.210830 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0581847 (* 1 = 0.0581847 loss)
I1013 03:37:41.210837 11428 sgd_solver.cpp:105] Iteration 62400, lr = 0.001
I1013 03:38:10.390864 11428 solver.cpp:330] Iteration 62500, Testing net (#0)
I1013 03:38:25.938529 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:38:26.255911 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1974 (* 1 = 1.1974 loss)
I1013 03:38:26.255928 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7284
I1013 03:38:26.546070 11428 solver.cpp:218] Iteration 62500 (2.20579 iter/s, 45.3353s/100 iters), loss = 0.0537793
I1013 03:38:26.546106 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0537805 (* 1 = 0.0537805 loss)
I1013 03:38:26.546114 11428 sgd_solver.cpp:105] Iteration 62500, lr = 0.001
I1013 03:38:56.000660 11428 solver.cpp:218] Iteration 62600 (3.39506 iter/s, 29.4546s/100 iters), loss = 0.0121007
I1013 03:38:56.000779 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121019 (* 1 = 0.0121019 loss)
I1013 03:38:56.000797 11428 sgd_solver.cpp:105] Iteration 62600, lr = 0.001
I1013 03:39:25.473847 11428 solver.cpp:218] Iteration 62700 (3.39293 iter/s, 29.4731s/100 iters), loss = 0.011302
I1013 03:39:25.473882 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113031 (* 1 = 0.0113031 loss)
I1013 03:39:25.473891 11428 sgd_solver.cpp:105] Iteration 62700, lr = 0.001
I1013 03:39:54.950696 11428 solver.cpp:218] Iteration 62800 (3.3925 iter/s, 29.4768s/100 iters), loss = 0.0452461
I1013 03:39:54.950837 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452473 (* 1 = 0.0452473 loss)
I1013 03:39:54.950845 11428 sgd_solver.cpp:105] Iteration 62800, lr = 0.001
I1013 03:40:24.420219 11428 solver.cpp:218] Iteration 62900 (3.39335 iter/s, 29.4694s/100 iters), loss = 0.0052086
I1013 03:40:24.420251 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520975 (* 1 = 0.00520975 loss)
I1013 03:40:24.420258 11428 sgd_solver.cpp:105] Iteration 62900, lr = 0.001
I1013 03:40:52.414355 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:40:53.595183 11428 solver.cpp:330] Iteration 63000, Testing net (#0)
I1013 03:41:09.144376 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:41:09.462671 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18948 (* 1 = 1.18948 loss)
I1013 03:41:09.462687 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7316
I1013 03:41:09.751754 11428 solver.cpp:218] Iteration 63000 (2.20597 iter/s, 45.3315s/100 iters), loss = 0.00885369
I1013 03:41:09.751790 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00885482 (* 1 = 0.00885482 loss)
I1013 03:41:09.751797 11428 sgd_solver.cpp:105] Iteration 63000, lr = 0.001
I1013 03:41:39.212975 11428 solver.cpp:218] Iteration 63100 (3.3943 iter/s, 29.4612s/100 iters), loss = 0.0231748
I1013 03:41:39.213089 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023176 (* 1 = 0.023176 loss)
I1013 03:41:39.213107 11428 sgd_solver.cpp:105] Iteration 63100, lr = 0.001
I1013 03:42:08.699426 11428 solver.cpp:218] Iteration 63200 (3.3914 iter/s, 29.4864s/100 iters), loss = 0.0174175
I1013 03:42:08.699463 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174186 (* 1 = 0.0174186 loss)
I1013 03:42:08.699471 11428 sgd_solver.cpp:105] Iteration 63200, lr = 0.001
I1013 03:42:38.165659 11428 solver.cpp:218] Iteration 63300 (3.39372 iter/s, 29.4662s/100 iters), loss = 0.0122163
I1013 03:42:38.165807 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122174 (* 1 = 0.0122174 loss)
I1013 03:42:38.165815 11428 sgd_solver.cpp:105] Iteration 63300, lr = 0.001
I1013 03:43:07.653864 11428 solver.cpp:218] Iteration 63400 (3.3912 iter/s, 29.4881s/100 iters), loss = 0.0139048
I1013 03:43:07.653898 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139059 (* 1 = 0.0139059 loss)
I1013 03:43:07.653905 11428 sgd_solver.cpp:105] Iteration 63400, lr = 0.001
I1013 03:43:36.833726 11428 solver.cpp:330] Iteration 63500, Testing net (#0)
I1013 03:43:52.383576 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:43:52.700320 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19022 (* 1 = 1.19022 loss)
I1013 03:43:52.700336 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7292
I1013 03:43:52.990298 11428 solver.cpp:218] Iteration 63500 (2.20573 iter/s, 45.3364s/100 iters), loss = 0.0136294
I1013 03:43:52.990334 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136306 (* 1 = 0.0136306 loss)
I1013 03:43:52.990345 11428 sgd_solver.cpp:105] Iteration 63500, lr = 0.001
I1013 03:44:22.446291 11428 solver.cpp:218] Iteration 63600 (3.3949 iter/s, 29.456s/100 iters), loss = 0.0101148
I1013 03:44:22.446439 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101159 (* 1 = 0.0101159 loss)
I1013 03:44:22.446465 11428 sgd_solver.cpp:105] Iteration 63600, lr = 0.001
I1013 03:44:51.908607 11428 solver.cpp:218] Iteration 63700 (3.39418 iter/s, 29.4622s/100 iters), loss = 0.010247
I1013 03:44:51.908641 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102481 (* 1 = 0.0102481 loss)
I1013 03:44:51.908651 11428 sgd_solver.cpp:105] Iteration 63700, lr = 0.001
I1013 03:45:21.367300 11428 solver.cpp:218] Iteration 63800 (3.39459 iter/s, 29.4587s/100 iters), loss = 0.00518986
I1013 03:45:21.367440 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005191 (* 1 = 0.005191 loss)
I1013 03:45:21.367460 11428 sgd_solver.cpp:105] Iteration 63800, lr = 0.001
I1013 03:45:50.848634 11428 solver.cpp:218] Iteration 63900 (3.39199 iter/s, 29.4812s/100 iters), loss = 0.00546032
I1013 03:45:50.848665 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546146 (* 1 = 0.00546146 loss)
I1013 03:45:50.848672 11428 sgd_solver.cpp:105] Iteration 63900, lr = 0.001
I1013 03:46:18.847084 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:46:20.027047 11428 solver.cpp:330] Iteration 64000, Testing net (#0)
I1013 03:46:35.575022 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:46:35.893306 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18649 (* 1 = 1.18649 loss)
I1013 03:46:35.893322 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7323
I1013 03:46:36.181941 11428 solver.cpp:218] Iteration 64000 (2.20588 iter/s, 45.3333s/100 iters), loss = 0.00396901
I1013 03:46:36.181977 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397014 (* 1 = 0.00397014 loss)
I1013 03:46:36.181985 11428 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I1013 03:47:05.629029 11428 solver.cpp:218] Iteration 64100 (3.39592 iter/s, 29.4471s/100 iters), loss = 0.0194675
I1013 03:47:05.629175 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194686 (* 1 = 0.0194686 loss)
I1013 03:47:05.629185 11428 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I1013 03:47:35.091295 11428 solver.cpp:218] Iteration 64200 (3.39419 iter/s, 29.4621s/100 iters), loss = 0.0218655
I1013 03:47:35.091325 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218666 (* 1 = 0.0218666 loss)
I1013 03:47:35.091332 11428 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I1013 03:48:04.538955 11428 solver.cpp:218] Iteration 64300 (3.39586 iter/s, 29.4476s/100 iters), loss = 0.0254541
I1013 03:48:04.539113 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254552 (* 1 = 0.0254552 loss)
I1013 03:48:04.539121 11428 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I1013 03:48:33.996563 11428 solver.cpp:218] Iteration 64400 (3.39473 iter/s, 29.4575s/100 iters), loss = 0.0244856
I1013 03:48:33.996596 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244868 (* 1 = 0.0244868 loss)
I1013 03:48:33.996603 11428 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I1013 03:49:03.170927 11428 solver.cpp:330] Iteration 64500, Testing net (#0)
I1013 03:49:18.719447 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:49:19.038938 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18382 (* 1 = 1.18382 loss)
I1013 03:49:19.038954 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7317
I1013 03:49:19.330715 11428 solver.cpp:218] Iteration 64500 (2.20584 iter/s, 45.3341s/100 iters), loss = 0.0155729
I1013 03:49:19.330749 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015574 (* 1 = 0.015574 loss)
I1013 03:49:19.330757 11428 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I1013 03:49:48.935046 11428 solver.cpp:218] Iteration 64600 (3.37789 iter/s, 29.6043s/100 iters), loss = 0.00871542
I1013 03:49:48.935184 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00871654 (* 1 = 0.00871654 loss)
I1013 03:49:48.935205 11428 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I1013 03:50:18.444566 11428 solver.cpp:218] Iteration 64700 (3.38875 iter/s, 29.5094s/100 iters), loss = 0.0232166
I1013 03:50:18.444598 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232177 (* 1 = 0.0232177 loss)
I1013 03:50:18.444607 11428 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I1013 03:50:47.963057 11428 solver.cpp:218] Iteration 64800 (3.38771 iter/s, 29.5185s/100 iters), loss = 0.0113623
I1013 03:50:47.963181 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113634 (* 1 = 0.0113634 loss)
I1013 03:50:47.963189 11428 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I1013 03:51:17.487598 11428 solver.cpp:218] Iteration 64900 (3.38703 iter/s, 29.5244s/100 iters), loss = 0.00544478
I1013 03:51:17.487632 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544592 (* 1 = 0.00544592 loss)
I1013 03:51:17.487639 11428 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I1013 03:51:45.533680 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:51:46.707111 11428 solver.cpp:330] Iteration 65000, Testing net (#0)
I1013 03:52:02.347599 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:52:02.666338 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18486 (* 1 = 1.18486 loss)
I1013 03:52:02.666354 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7323
I1013 03:52:02.953783 11428 solver.cpp:218] Iteration 65000 (2.19944 iter/s, 45.4662s/100 iters), loss = 0.0251329
I1013 03:52:02.953814 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025134 (* 1 = 0.025134 loss)
I1013 03:52:02.953824 11428 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I1013 03:52:32.423305 11428 solver.cpp:218] Iteration 65100 (3.39334 iter/s, 29.4695s/100 iters), loss = 0.0207868
I1013 03:52:32.423451 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020788 (* 1 = 0.020788 loss)
I1013 03:52:32.423461 11428 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I1013 03:53:01.950372 11428 solver.cpp:218] Iteration 65200 (3.38674 iter/s, 29.5269s/100 iters), loss = 0.0228167
I1013 03:53:01.950404 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228178 (* 1 = 0.0228178 loss)
I1013 03:53:01.950412 11428 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I1013 03:53:31.457862 11428 solver.cpp:218] Iteration 65300 (3.38897 iter/s, 29.5075s/100 iters), loss = 0.0160368
I1013 03:53:31.458001 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016038 (* 1 = 0.016038 loss)
I1013 03:53:31.458010 11428 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I1013 03:54:00.955677 11428 solver.cpp:218] Iteration 65400 (3.3901 iter/s, 29.4977s/100 iters), loss = 0.043661
I1013 03:54:00.955710 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436622 (* 1 = 0.0436622 loss)
I1013 03:54:00.955718 11428 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I1013 03:54:30.151221 11428 solver.cpp:330] Iteration 65500, Testing net (#0)
I1013 03:54:45.775939 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:54:46.096205 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18073 (* 1 = 1.18073 loss)
I1013 03:54:46.096221 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7334
I1013 03:54:46.387593 11428 solver.cpp:218] Iteration 65500 (2.2011 iter/s, 45.4319s/100 iters), loss = 0.0241382
I1013 03:54:46.387629 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241393 (* 1 = 0.0241393 loss)
I1013 03:54:46.387646 11428 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I1013 03:55:15.903612 11428 solver.cpp:218] Iteration 65600 (3.38799 iter/s, 29.516s/100 iters), loss = 0.00557897
I1013 03:55:15.903764 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055801 (* 1 = 0.0055801 loss)
I1013 03:55:15.903774 11428 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I1013 03:55:45.465309 11428 solver.cpp:218] Iteration 65700 (3.38277 iter/s, 29.5616s/100 iters), loss = 0.00826612
I1013 03:55:45.465342 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00826726 (* 1 = 0.00826726 loss)
I1013 03:55:45.465348 11428 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I1013 03:56:15.061770 11428 solver.cpp:218] Iteration 65800 (3.37879 iter/s, 29.5964s/100 iters), loss = 0.00535359
I1013 03:56:15.061926 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535473 (* 1 = 0.00535473 loss)
I1013 03:56:15.061946 11428 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I1013 03:56:44.587030 11428 solver.cpp:218] Iteration 65900 (3.38695 iter/s, 29.5251s/100 iters), loss = 0.0033076
I1013 03:56:44.587062 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330875 (* 1 = 0.00330875 loss)
I1013 03:56:44.587070 11428 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I1013 03:57:12.638880 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:57:13.816149 11428 solver.cpp:330] Iteration 66000, Testing net (#0)
I1013 03:57:29.422929 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 03:57:29.740272 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17975 (* 1 = 1.17975 loss)
I1013 03:57:29.740288 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7336
I1013 03:57:30.031033 11428 solver.cpp:218] Iteration 66000 (2.20051 iter/s, 45.444s/100 iters), loss = 0.00898803
I1013 03:57:30.031064 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00898917 (* 1 = 0.00898917 loss)
I1013 03:57:30.031071 11428 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I1013 03:57:59.587153 11428 solver.cpp:218] Iteration 66100 (3.3834 iter/s, 29.5561s/100 iters), loss = 0.0117916
I1013 03:57:59.587254 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117928 (* 1 = 0.0117928 loss)
I1013 03:57:59.587271 11428 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I1013 03:58:29.066222 11428 solver.cpp:218] Iteration 66200 (3.39225 iter/s, 29.479s/100 iters), loss = 0.0172507
I1013 03:58:29.066257 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172519 (* 1 = 0.0172519 loss)
I1013 03:58:29.066264 11428 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I1013 03:58:58.603276 11428 solver.cpp:218] Iteration 66300 (3.38558 iter/s, 29.537s/100 iters), loss = 0.0096727
I1013 03:58:58.603425 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00967384 (* 1 = 0.00967384 loss)
I1013 03:58:58.603433 11428 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I1013 03:59:28.111868 11428 solver.cpp:218] Iteration 66400 (3.38886 iter/s, 29.5085s/100 iters), loss = 0.0201128
I1013 03:59:28.111901 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201139 (* 1 = 0.0201139 loss)
I1013 03:59:28.111909 11428 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I1013 03:59:57.405824 11428 solver.cpp:330] Iteration 66500, Testing net (#0)
I1013 04:00:12.993847 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:00:13.313024 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17931 (* 1 = 1.17931 loss)
I1013 04:00:13.313041 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7346
I1013 04:00:13.602454 11428 solver.cpp:218] Iteration 66500 (2.19826 iter/s, 45.4906s/100 iters), loss = 0.00499535
I1013 04:00:13.602489 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499649 (* 1 = 0.00499649 loss)
I1013 04:00:13.602497 11428 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I1013 04:00:43.127009 11428 solver.cpp:218] Iteration 66600 (3.38701 iter/s, 29.5245s/100 iters), loss = 0.00594182
I1013 04:00:43.127135 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594297 (* 1 = 0.00594297 loss)
I1013 04:00:43.127153 11428 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I1013 04:01:12.716997 11428 solver.cpp:218] Iteration 66700 (3.37953 iter/s, 29.5899s/100 iters), loss = 0.00914623
I1013 04:01:12.717031 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914737 (* 1 = 0.00914737 loss)
I1013 04:01:12.717038 11428 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I1013 04:01:42.262610 11428 solver.cpp:218] Iteration 66800 (3.3846 iter/s, 29.5456s/100 iters), loss = 0.0053642
I1013 04:01:42.262728 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536535 (* 1 = 0.00536535 loss)
I1013 04:01:42.262748 11428 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I1013 04:02:11.772578 11428 solver.cpp:218] Iteration 66900 (3.3887 iter/s, 29.5099s/100 iters), loss = 0.00713099
I1013 04:02:11.772613 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713214 (* 1 = 0.00713214 loss)
I1013 04:02:11.772619 11428 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I1013 04:02:39.786129 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:02:40.966521 11428 solver.cpp:330] Iteration 67000, Testing net (#0)
I1013 04:02:56.571504 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:02:56.895337 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17849 (* 1 = 1.17849 loss)
I1013 04:02:56.895354 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7339
I1013 04:02:57.187466 11428 solver.cpp:218] Iteration 67000 (2.20192 iter/s, 45.4149s/100 iters), loss = 0.00407065
I1013 04:02:57.187497 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040718 (* 1 = 0.0040718 loss)
I1013 04:02:57.187505 11428 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I1013 04:03:26.777882 11428 solver.cpp:218] Iteration 67100 (3.37948 iter/s, 29.5904s/100 iters), loss = 0.00733535
I1013 04:03:26.778029 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073365 (* 1 = 0.0073365 loss)
I1013 04:03:26.778039 11428 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I1013 04:03:56.308766 11428 solver.cpp:218] Iteration 67200 (3.3863 iter/s, 29.5307s/100 iters), loss = 0.0122731
I1013 04:03:56.308799 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122742 (* 1 = 0.0122742 loss)
I1013 04:03:56.308806 11428 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I1013 04:04:25.848467 11428 solver.cpp:218] Iteration 67300 (3.38528 iter/s, 29.5397s/100 iters), loss = 0.0144735
I1013 04:04:25.848577 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144746 (* 1 = 0.0144746 loss)
I1013 04:04:25.848593 11428 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I1013 04:04:55.405908 11428 solver.cpp:218] Iteration 67400 (3.38325 iter/s, 29.5574s/100 iters), loss = 0.012787
I1013 04:04:55.405944 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127881 (* 1 = 0.0127881 loss)
I1013 04:04:55.405951 11428 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I1013 04:05:24.659564 11428 solver.cpp:330] Iteration 67500, Testing net (#0)
I1013 04:05:40.260107 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:05:40.579743 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17555 (* 1 = 1.17555 loss)
I1013 04:05:40.579761 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7347
I1013 04:05:40.868021 11428 solver.cpp:218] Iteration 67500 (2.19963 iter/s, 45.4621s/100 iters), loss = 0.00942465
I1013 04:05:40.868053 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0094258 (* 1 = 0.0094258 loss)
I1013 04:05:40.868062 11428 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I1013 04:06:10.383496 11428 solver.cpp:218] Iteration 67600 (3.38806 iter/s, 29.5155s/100 iters), loss = 0.0079411
I1013 04:06:10.383625 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794225 (* 1 = 0.00794225 loss)
I1013 04:06:10.383633 11428 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I1013 04:06:39.903399 11428 solver.cpp:218] Iteration 67700 (3.38756 iter/s, 29.5198s/100 iters), loss = 0.014559
I1013 04:06:39.903440 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145601 (* 1 = 0.0145601 loss)
I1013 04:06:39.903447 11428 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I1013 04:07:09.399255 11428 solver.cpp:218] Iteration 67800 (3.39031 iter/s, 29.4958s/100 iters), loss = 0.00494645
I1013 04:07:09.399391 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0049476 (* 1 = 0.0049476 loss)
I1013 04:07:09.399400 11428 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I1013 04:07:38.897842 11428 solver.cpp:218] Iteration 67900 (3.39001 iter/s, 29.4985s/100 iters), loss = 0.00191051
I1013 04:07:38.897874 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191166 (* 1 = 0.00191166 loss)
I1013 04:07:38.897882 11428 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I1013 04:08:06.968474 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:08:08.145654 11428 solver.cpp:330] Iteration 68000, Testing net (#0)
I1013 04:08:23.785822 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:08:24.105954 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17225 (* 1 = 1.17225 loss)
I1013 04:08:24.105971 11428 solver.cpp:397]     Test net output #1: accuracy = 0.737
I1013 04:08:24.395853 11428 solver.cpp:218] Iteration 68000 (2.1979 iter/s, 45.498s/100 iters), loss = 0.0071729
I1013 04:08:24.395887 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00717405 (* 1 = 0.00717405 loss)
I1013 04:08:24.395895 11428 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I1013 04:08:53.911411 11428 solver.cpp:218] Iteration 68100 (3.38805 iter/s, 29.5155s/100 iters), loss = 0.0112264
I1013 04:08:53.911509 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112275 (* 1 = 0.0112275 loss)
I1013 04:08:53.911526 11428 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I1013 04:09:23.425395 11428 solver.cpp:218] Iteration 68200 (3.38823 iter/s, 29.5139s/100 iters), loss = 0.0165571
I1013 04:09:23.425427 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165582 (* 1 = 0.0165582 loss)
I1013 04:09:23.425436 11428 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I1013 04:09:53.016908 11428 solver.cpp:218] Iteration 68300 (3.37935 iter/s, 29.5915s/100 iters), loss = 0.00690486
I1013 04:09:53.017022 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006906 (* 1 = 0.006906 loss)
I1013 04:09:53.017040 11428 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I1013 04:10:22.523227 11428 solver.cpp:218] Iteration 68400 (3.38912 iter/s, 29.5062s/100 iters), loss = 0.00709925
I1013 04:10:22.523260 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710039 (* 1 = 0.00710039 loss)
I1013 04:10:22.523268 11428 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I1013 04:10:51.730126 11428 solver.cpp:330] Iteration 68500, Testing net (#0)
I1013 04:11:07.333724 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:11:07.651048 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1709 (* 1 = 1.1709 loss)
I1013 04:11:07.651064 11428 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1013 04:11:07.942154 11428 solver.cpp:218] Iteration 68500 (2.20173 iter/s, 45.4189s/100 iters), loss = 0.00581377
I1013 04:11:07.942185 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581491 (* 1 = 0.00581491 loss)
I1013 04:11:07.942193 11428 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I1013 04:11:37.532140 11428 solver.cpp:218] Iteration 68600 (3.37952 iter/s, 29.59s/100 iters), loss = 0.00373668
I1013 04:11:37.532306 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373782 (* 1 = 0.00373782 loss)
I1013 04:11:37.532328 11428 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I1013 04:12:07.063222 11428 solver.cpp:218] Iteration 68700 (3.38628 iter/s, 29.5309s/100 iters), loss = 0.00558144
I1013 04:12:07.063254 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558258 (* 1 = 0.00558258 loss)
I1013 04:12:07.063263 11428 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I1013 04:12:36.598908 11428 solver.cpp:218] Iteration 68800 (3.38574 iter/s, 29.5357s/100 iters), loss = 0.0142188
I1013 04:12:36.599021 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01422 (* 1 = 0.01422 loss)
I1013 04:12:36.599030 11428 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I1013 04:13:06.138882 11428 solver.cpp:218] Iteration 68900 (3.38525 iter/s, 29.5399s/100 iters), loss = 0.00259995
I1013 04:13:06.138926 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260108 (* 1 = 0.00260108 loss)
I1013 04:13:06.138933 11428 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I1013 04:13:34.208359 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:13:35.391935 11428 solver.cpp:330] Iteration 69000, Testing net (#0)
I1013 04:13:50.973254 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:13:51.293828 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16971 (* 1 = 1.16971 loss)
I1013 04:13:51.293845 11428 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1013 04:13:51.585651 11428 solver.cpp:218] Iteration 69000 (2.20038 iter/s, 45.4467s/100 iters), loss = 0.00483013
I1013 04:13:51.585691 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483127 (* 1 = 0.00483127 loss)
I1013 04:13:51.585700 11428 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I1013 04:14:21.167954 11428 solver.cpp:218] Iteration 69100 (3.38041 iter/s, 29.5822s/100 iters), loss = 0.00562139
I1013 04:14:21.168092 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562253 (* 1 = 0.00562253 loss)
I1013 04:14:21.168100 11428 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I1013 04:14:50.684567 11428 solver.cpp:218] Iteration 69200 (3.38794 iter/s, 29.5165s/100 iters), loss = 0.0164022
I1013 04:14:50.684599 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164033 (* 1 = 0.0164033 loss)
I1013 04:14:50.684607 11428 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I1013 04:15:20.213078 11428 solver.cpp:218] Iteration 69300 (3.38656 iter/s, 29.5285s/100 iters), loss = 0.0137865
I1013 04:15:20.213222 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137876 (* 1 = 0.0137876 loss)
I1013 04:15:20.213232 11428 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I1013 04:15:49.754242 11428 solver.cpp:218] Iteration 69400 (3.38512 iter/s, 29.541s/100 iters), loss = 0.00900215
I1013 04:15:49.754286 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00900328 (* 1 = 0.00900328 loss)
I1013 04:15:49.754292 11428 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I1013 04:16:18.994360 11428 solver.cpp:330] Iteration 69500, Testing net (#0)
I1013 04:16:34.577126 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:16:34.897637 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1711 (* 1 = 1.1711 loss)
I1013 04:16:34.897652 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7386
I1013 04:16:35.189373 11428 solver.cpp:218] Iteration 69500 (2.20094 iter/s, 45.4351s/100 iters), loss = 0.018133
I1013 04:16:35.189407 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181341 (* 1 = 0.0181341 loss)
I1013 04:16:35.189415 11428 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I1013 04:17:04.732084 11428 solver.cpp:218] Iteration 69600 (3.38494 iter/s, 29.5427s/100 iters), loss = 0.00297564
I1013 04:17:04.732174 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297677 (* 1 = 0.00297677 loss)
I1013 04:17:04.732192 11428 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I1013 04:17:34.179205 11428 solver.cpp:218] Iteration 69700 (3.39593 iter/s, 29.447s/100 iters), loss = 0.00830945
I1013 04:17:34.179239 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831058 (* 1 = 0.00831058 loss)
I1013 04:17:34.179246 11428 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I1013 04:18:03.698232 11428 solver.cpp:218] Iteration 69800 (3.38765 iter/s, 29.519s/100 iters), loss = 0.00339594
I1013 04:18:03.698396 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339707 (* 1 = 0.00339707 loss)
I1013 04:18:03.698405 11428 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I1013 04:18:33.222128 11428 solver.cpp:218] Iteration 69900 (3.3871 iter/s, 29.5237s/100 iters), loss = 0.00176249
I1013 04:18:33.222157 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176363 (* 1 = 0.00176363 loss)
I1013 04:18:33.222165 11428 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I1013 04:19:01.233316 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:19:02.419605 11428 solver.cpp:330] Iteration 70000, Testing net (#0)
I1013 04:19:18.072026 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:19:18.391525 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16709 (* 1 = 1.16709 loss)
I1013 04:19:18.391540 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7393
I1013 04:19:18.679545 11428 solver.cpp:218] Iteration 70000 (2.19986 iter/s, 45.4574s/100 iters), loss = 0.00695864
I1013 04:19:18.679579 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695977 (* 1 = 0.00695977 loss)
I1013 04:19:18.679587 11428 sgd_solver.cpp:105] Iteration 70000, lr = 0.001
I1013 04:19:48.193555 11428 solver.cpp:218] Iteration 70100 (3.38822 iter/s, 29.514s/100 iters), loss = 0.0068979
I1013 04:19:48.193701 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00689903 (* 1 = 0.00689903 loss)
I1013 04:19:48.193711 11428 sgd_solver.cpp:105] Iteration 70100, lr = 0.001
I1013 04:20:17.741888 11428 solver.cpp:218] Iteration 70200 (3.3843 iter/s, 29.5482s/100 iters), loss = 0.0178861
I1013 04:20:17.741940 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178872 (* 1 = 0.0178872 loss)
I1013 04:20:17.741957 11428 sgd_solver.cpp:105] Iteration 70200, lr = 0.001
I1013 04:20:47.258625 11428 solver.cpp:218] Iteration 70300 (3.38791 iter/s, 29.5167s/100 iters), loss = 0.00787261
I1013 04:20:47.258705 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00787374 (* 1 = 0.00787374 loss)
I1013 04:20:47.258723 11428 sgd_solver.cpp:105] Iteration 70300, lr = 0.001
I1013 04:21:16.749322 11428 solver.cpp:218] Iteration 70400 (3.39091 iter/s, 29.4906s/100 iters), loss = 0.0133032
I1013 04:21:16.749361 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133044 (* 1 = 0.0133044 loss)
I1013 04:21:16.749368 11428 sgd_solver.cpp:105] Iteration 70400, lr = 0.001
I1013 04:21:45.959717 11428 solver.cpp:330] Iteration 70500, Testing net (#0)
I1013 04:22:01.539093 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:22:01.861446 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16326 (* 1 = 1.16326 loss)
I1013 04:22:01.861462 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7375
I1013 04:22:02.154598 11428 solver.cpp:218] Iteration 70500 (2.20239 iter/s, 45.4053s/100 iters), loss = 0.021462
I1013 04:22:02.154634 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214632 (* 1 = 0.0214632 loss)
I1013 04:22:02.154654 11428 sgd_solver.cpp:105] Iteration 70500, lr = 0.001
I1013 04:22:31.678028 11428 solver.cpp:218] Iteration 70600 (3.38716 iter/s, 29.5232s/100 iters), loss = 0.00509438
I1013 04:22:31.678225 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00509551 (* 1 = 0.00509551 loss)
I1013 04:22:31.678244 11428 sgd_solver.cpp:105] Iteration 70600, lr = 0.001
I1013 04:23:01.159338 11428 solver.cpp:218] Iteration 70700 (3.392 iter/s, 29.4811s/100 iters), loss = 0.00298244
I1013 04:23:01.159371 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298357 (* 1 = 0.00298357 loss)
I1013 04:23:01.159379 11428 sgd_solver.cpp:105] Iteration 70700, lr = 0.001
I1013 04:23:30.640199 11428 solver.cpp:218] Iteration 70800 (3.39203 iter/s, 29.4808s/100 iters), loss = 0.0158761
I1013 04:23:30.640328 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158772 (* 1 = 0.0158772 loss)
I1013 04:23:30.640336 11428 sgd_solver.cpp:105] Iteration 70800, lr = 0.001
I1013 04:24:00.125946 11428 solver.cpp:218] Iteration 70900 (3.39148 iter/s, 29.4856s/100 iters), loss = 0.00563764
I1013 04:24:00.125978 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563876 (* 1 = 0.00563876 loss)
I1013 04:24:00.125986 11428 sgd_solver.cpp:105] Iteration 70900, lr = 0.001
I1013 04:24:28.115007 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:24:29.301069 11428 solver.cpp:330] Iteration 71000, Testing net (#0)
I1013 04:24:44.941274 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:24:45.260906 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16374 (* 1 = 1.16374 loss)
I1013 04:24:45.260923 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7383
I1013 04:24:45.551420 11428 solver.cpp:218] Iteration 71000 (2.20141 iter/s, 45.4255s/100 iters), loss = 0.00515373
I1013 04:24:45.551457 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515485 (* 1 = 0.00515485 loss)
I1013 04:24:45.551465 11428 sgd_solver.cpp:105] Iteration 71000, lr = 0.001
I1013 04:25:15.048764 11428 solver.cpp:218] Iteration 71100 (3.39014 iter/s, 29.4973s/100 iters), loss = 0.0192324
I1013 04:25:15.048915 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192336 (* 1 = 0.0192336 loss)
I1013 04:25:15.048925 11428 sgd_solver.cpp:105] Iteration 71100, lr = 0.001
I1013 04:25:44.546936 11428 solver.cpp:218] Iteration 71200 (3.39006 iter/s, 29.498s/100 iters), loss = 0.0109516
I1013 04:25:44.546970 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109528 (* 1 = 0.0109528 loss)
I1013 04:25:44.546978 11428 sgd_solver.cpp:105] Iteration 71200, lr = 0.001
I1013 04:26:14.073603 11428 solver.cpp:218] Iteration 71300 (3.38677 iter/s, 29.5266s/100 iters), loss = 0.00676256
I1013 04:26:14.073720 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00676369 (* 1 = 0.00676369 loss)
I1013 04:26:14.073738 11428 sgd_solver.cpp:105] Iteration 71300, lr = 0.001
I1013 04:26:43.567569 11428 solver.cpp:218] Iteration 71400 (3.39054 iter/s, 29.4939s/100 iters), loss = 0.00877126
I1013 04:26:43.567602 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877239 (* 1 = 0.00877239 loss)
I1013 04:26:43.567610 11428 sgd_solver.cpp:105] Iteration 71400, lr = 0.001
I1013 04:27:12.838613 11428 solver.cpp:330] Iteration 71500, Testing net (#0)
I1013 04:27:28.416699 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:27:28.735692 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15993 (* 1 = 1.15993 loss)
I1013 04:27:28.735710 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7393
I1013 04:27:29.025853 11428 solver.cpp:218] Iteration 71500 (2.19982 iter/s, 45.4583s/100 iters), loss = 0.00655004
I1013 04:27:29.025884 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00655116 (* 1 = 0.00655116 loss)
I1013 04:27:29.025892 11428 sgd_solver.cpp:105] Iteration 71500, lr = 0.001
I1013 04:27:58.576367 11428 solver.cpp:218] Iteration 71600 (3.38404 iter/s, 29.5505s/100 iters), loss = 0.0055812
I1013 04:27:58.576510 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558233 (* 1 = 0.00558233 loss)
I1013 04:27:58.576519 11428 sgd_solver.cpp:105] Iteration 71600, lr = 0.001
I1013 04:28:28.120539 11428 solver.cpp:218] Iteration 71700 (3.38478 iter/s, 29.544s/100 iters), loss = 0.00579893
I1013 04:28:28.120573 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00580005 (* 1 = 0.00580005 loss)
I1013 04:28:28.120580 11428 sgd_solver.cpp:105] Iteration 71700, lr = 0.001
I1013 04:28:57.664046 11428 solver.cpp:218] Iteration 71800 (3.38484 iter/s, 29.5435s/100 iters), loss = 0.00529863
I1013 04:28:57.664204 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529975 (* 1 = 0.00529975 loss)
I1013 04:28:57.664214 11428 sgd_solver.cpp:105] Iteration 71800, lr = 0.001
I1013 04:29:27.126453 11428 solver.cpp:218] Iteration 71900 (3.39417 iter/s, 29.4623s/100 iters), loss = 0.00418249
I1013 04:29:27.126485 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418361 (* 1 = 0.00418361 loss)
I1013 04:29:27.126492 11428 sgd_solver.cpp:105] Iteration 71900, lr = 0.001
I1013 04:29:55.140617 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:29:56.314347 11428 solver.cpp:330] Iteration 72000, Testing net (#0)
I1013 04:30:11.934908 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:30:12.256894 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16017 (* 1 = 1.16017 loss)
I1013 04:30:12.256909 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7392
I1013 04:30:12.551101 11428 solver.cpp:218] Iteration 72000 (2.20145 iter/s, 45.4246s/100 iters), loss = 0.0113704
I1013 04:30:12.551136 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113715 (* 1 = 0.0113715 loss)
I1013 04:30:12.551143 11428 sgd_solver.cpp:105] Iteration 72000, lr = 0.001
I1013 04:30:42.040833 11428 solver.cpp:218] Iteration 72100 (3.39101 iter/s, 29.4897s/100 iters), loss = 0.00693269
I1013 04:30:42.040940 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693382 (* 1 = 0.00693382 loss)
I1013 04:30:42.040948 11428 sgd_solver.cpp:105] Iteration 72100, lr = 0.001
I1013 04:31:11.527261 11428 solver.cpp:218] Iteration 72200 (3.3914 iter/s, 29.4863s/100 iters), loss = 0.0143483
I1013 04:31:11.527292 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143494 (* 1 = 0.0143494 loss)
I1013 04:31:11.527300 11428 sgd_solver.cpp:105] Iteration 72200, lr = 0.001
I1013 04:31:41.020593 11428 solver.cpp:218] Iteration 72300 (3.3906 iter/s, 29.4933s/100 iters), loss = 0.00759663
I1013 04:31:41.020717 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00759775 (* 1 = 0.00759775 loss)
I1013 04:31:41.020726 11428 sgd_solver.cpp:105] Iteration 72300, lr = 0.001
I1013 04:32:10.473222 11428 solver.cpp:218] Iteration 72400 (3.3953 iter/s, 29.4525s/100 iters), loss = 0.00518011
I1013 04:32:10.473253 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00518123 (* 1 = 0.00518123 loss)
I1013 04:32:10.473261 11428 sgd_solver.cpp:105] Iteration 72400, lr = 0.001
I1013 04:32:39.693682 11428 solver.cpp:330] Iteration 72500, Testing net (#0)
I1013 04:32:55.232189 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:32:55.550596 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15969 (* 1 = 1.15969 loss)
I1013 04:32:55.550612 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7391
I1013 04:32:55.839674 11428 solver.cpp:218] Iteration 72500 (2.20427 iter/s, 45.3664s/100 iters), loss = 0.0146001
I1013 04:32:55.839710 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146012 (* 1 = 0.0146012 loss)
I1013 04:32:55.839718 11428 sgd_solver.cpp:105] Iteration 72500, lr = 0.001
I1013 04:33:25.317764 11428 solver.cpp:218] Iteration 72600 (3.39235 iter/s, 29.4781s/100 iters), loss = 0.0046788
I1013 04:33:25.317863 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467992 (* 1 = 0.00467992 loss)
I1013 04:33:25.317873 11428 sgd_solver.cpp:105] Iteration 72600, lr = 0.001
I1013 04:33:54.839885 11428 solver.cpp:218] Iteration 72700 (3.3873 iter/s, 29.522s/100 iters), loss = 0.00481399
I1013 04:33:54.839917 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481511 (* 1 = 0.00481511 loss)
I1013 04:33:54.839926 11428 sgd_solver.cpp:105] Iteration 72700, lr = 0.001
I1013 04:34:24.346846 11428 solver.cpp:218] Iteration 72800 (3.38903 iter/s, 29.5069s/100 iters), loss = 0.00228656
I1013 04:34:24.347455 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228768 (* 1 = 0.00228768 loss)
I1013 04:34:24.347465 11428 sgd_solver.cpp:105] Iteration 72800, lr = 0.001
I1013 04:34:53.850224 11428 solver.cpp:218] Iteration 72900 (3.38951 iter/s, 29.5028s/100 iters), loss = 0.00193806
I1013 04:34:53.850255 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193918 (* 1 = 0.00193918 loss)
I1013 04:34:53.850261 11428 sgd_solver.cpp:105] Iteration 72900, lr = 0.001
I1013 04:35:21.910770 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:35:23.092381 11428 solver.cpp:330] Iteration 73000, Testing net (#0)
I1013 04:35:38.732256 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:35:39.052129 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15967 (* 1 = 1.15967 loss)
I1013 04:35:39.052145 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7389
I1013 04:35:39.342969 11428 solver.cpp:218] Iteration 73000 (2.19815 iter/s, 45.4927s/100 iters), loss = 0.0074874
I1013 04:35:39.343003 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00748852 (* 1 = 0.00748852 loss)
I1013 04:35:39.343013 11428 sgd_solver.cpp:105] Iteration 73000, lr = 0.001
I1013 04:36:08.818132 11428 solver.cpp:218] Iteration 73100 (3.39269 iter/s, 29.4751s/100 iters), loss = 0.0104144
I1013 04:36:08.818251 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104155 (* 1 = 0.0104155 loss)
I1013 04:36:08.818259 11428 sgd_solver.cpp:105] Iteration 73100, lr = 0.001
I1013 04:36:38.302685 11428 solver.cpp:218] Iteration 73200 (3.39162 iter/s, 29.4844s/100 iters), loss = 0.00723478
I1013 04:36:38.302717 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00723591 (* 1 = 0.00723591 loss)
I1013 04:36:38.302726 11428 sgd_solver.cpp:105] Iteration 73200, lr = 0.001
I1013 04:37:07.787349 11428 solver.cpp:218] Iteration 73300 (3.3916 iter/s, 29.4846s/100 iters), loss = 0.0087726
I1013 04:37:07.787482 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877372 (* 1 = 0.00877372 loss)
I1013 04:37:07.787499 11428 sgd_solver.cpp:105] Iteration 73300, lr = 0.001
I1013 04:37:37.304580 11428 solver.cpp:218] Iteration 73400 (3.38786 iter/s, 29.5171s/100 iters), loss = 0.00241584
I1013 04:37:37.304615 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241696 (* 1 = 0.00241696 loss)
I1013 04:37:37.304622 11428 sgd_solver.cpp:105] Iteration 73400, lr = 0.001
I1013 04:38:06.462359 11428 solver.cpp:330] Iteration 73500, Testing net (#0)
I1013 04:38:22.077327 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:38:22.396308 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15657 (* 1 = 1.15657 loss)
I1013 04:38:22.396323 11428 solver.cpp:397]     Test net output #1: accuracy = 0.74
I1013 04:38:22.686460 11428 solver.cpp:218] Iteration 73500 (2.20352 iter/s, 45.3819s/100 iters), loss = 0.0106966
I1013 04:38:22.686501 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106977 (* 1 = 0.0106977 loss)
I1013 04:38:22.686509 11428 sgd_solver.cpp:105] Iteration 73500, lr = 0.001
I1013 04:38:52.202988 11428 solver.cpp:218] Iteration 73600 (3.38794 iter/s, 29.5165s/100 iters), loss = 0.00484893
I1013 04:38:52.203133 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00485005 (* 1 = 0.00485005 loss)
I1013 04:38:52.203145 11428 sgd_solver.cpp:105] Iteration 73600, lr = 0.001
I1013 04:39:21.704483 11428 solver.cpp:218] Iteration 73700 (3.38967 iter/s, 29.5014s/100 iters), loss = 0.00448333
I1013 04:39:21.704517 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448445 (* 1 = 0.00448445 loss)
I1013 04:39:21.704525 11428 sgd_solver.cpp:105] Iteration 73700, lr = 0.001
I1013 04:39:51.240154 11428 solver.cpp:218] Iteration 73800 (3.38574 iter/s, 29.5356s/100 iters), loss = 0.0102453
I1013 04:39:51.240332 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102464 (* 1 = 0.0102464 loss)
I1013 04:39:51.240342 11428 sgd_solver.cpp:105] Iteration 73800, lr = 0.001
I1013 04:40:20.731061 11428 solver.cpp:218] Iteration 73900 (3.39089 iter/s, 29.4908s/100 iters), loss = 0.00357367
I1013 04:40:20.731092 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357478 (* 1 = 0.00357478 loss)
I1013 04:40:20.731099 11428 sgd_solver.cpp:105] Iteration 73900, lr = 0.001
I1013 04:40:48.754138 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:40:49.939270 11428 solver.cpp:330] Iteration 74000, Testing net (#0)
I1013 04:41:05.552471 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:41:05.872655 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1564 (* 1 = 1.1564 loss)
I1013 04:41:05.872673 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7396
I1013 04:41:06.163887 11428 solver.cpp:218] Iteration 74000 (2.20105 iter/s, 45.4328s/100 iters), loss = 0.00595078
I1013 04:41:06.163933 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059519 (* 1 = 0.0059519 loss)
I1013 04:41:06.163940 11428 sgd_solver.cpp:105] Iteration 74000, lr = 0.001
I1013 04:41:35.645367 11428 solver.cpp:218] Iteration 74100 (3.39196 iter/s, 29.4814s/100 iters), loss = 0.00570085
I1013 04:41:35.645514 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570197 (* 1 = 0.00570197 loss)
I1013 04:41:35.645524 11428 sgd_solver.cpp:105] Iteration 74100, lr = 0.001
I1013 04:42:05.186810 11428 solver.cpp:218] Iteration 74200 (3.38509 iter/s, 29.5413s/100 iters), loss = 0.00892197
I1013 04:42:05.186841 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00892309 (* 1 = 0.00892309 loss)
I1013 04:42:05.186848 11428 sgd_solver.cpp:105] Iteration 74200, lr = 0.001
I1013 04:42:34.697680 11428 solver.cpp:218] Iteration 74300 (3.38858 iter/s, 29.5108s/100 iters), loss = 0.0126965
I1013 04:42:34.697824 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126976 (* 1 = 0.0126976 loss)
I1013 04:42:34.697832 11428 sgd_solver.cpp:105] Iteration 74300, lr = 0.001
I1013 04:43:04.227038 11428 solver.cpp:218] Iteration 74400 (3.38648 iter/s, 29.5292s/100 iters), loss = 0.00599682
I1013 04:43:04.227072 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599793 (* 1 = 0.00599793 loss)
I1013 04:43:04.227079 11428 sgd_solver.cpp:105] Iteration 74400, lr = 0.001
I1013 04:43:33.474464 11428 solver.cpp:330] Iteration 74500, Testing net (#0)
I1013 04:43:49.089184 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:43:49.408437 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15717 (* 1 = 1.15717 loss)
I1013 04:43:49.408453 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7397
I1013 04:43:49.697557 11428 solver.cpp:218] Iteration 74500 (2.19923 iter/s, 45.4705s/100 iters), loss = 0.00796408
I1013 04:43:49.697592 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796519 (* 1 = 0.00796519 loss)
I1013 04:43:49.697598 11428 sgd_solver.cpp:105] Iteration 74500, lr = 0.001
I1013 04:44:19.177971 11428 solver.cpp:218] Iteration 74600 (3.39209 iter/s, 29.4804s/100 iters), loss = 0.00500831
I1013 04:44:19.178113 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500942 (* 1 = 0.00500942 loss)
I1013 04:44:19.178123 11428 sgd_solver.cpp:105] Iteration 74600, lr = 0.001
I1013 04:44:48.704077 11428 solver.cpp:218] Iteration 74700 (3.38685 iter/s, 29.526s/100 iters), loss = 0.00429299
I1013 04:44:48.704110 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429411 (* 1 = 0.00429411 loss)
I1013 04:44:48.704118 11428 sgd_solver.cpp:105] Iteration 74700, lr = 0.001
I1013 04:45:18.207180 11428 solver.cpp:218] Iteration 74800 (3.38948 iter/s, 29.5031s/100 iters), loss = 0.00353229
I1013 04:45:18.207262 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035334 (* 1 = 0.0035334 loss)
I1013 04:45:18.207279 11428 sgd_solver.cpp:105] Iteration 74800, lr = 0.001
I1013 04:45:47.742230 11428 solver.cpp:218] Iteration 74900 (3.38582 iter/s, 29.535s/100 iters), loss = 0.00283156
I1013 04:45:47.742262 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283267 (* 1 = 0.00283267 loss)
I1013 04:45:47.742269 11428 sgd_solver.cpp:105] Iteration 74900, lr = 0.001
I1013 04:46:15.801810 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:46:16.982888 11428 solver.cpp:330] Iteration 75000, Testing net (#0)
I1013 04:46:32.601694 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:46:32.921306 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15487 (* 1 = 1.15487 loss)
I1013 04:46:32.921324 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 04:46:33.210978 11428 solver.cpp:218] Iteration 75000 (2.19931 iter/s, 45.4687s/100 iters), loss = 0.0054634
I1013 04:46:33.211012 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546451 (* 1 = 0.00546451 loss)
I1013 04:46:33.211019 11428 sgd_solver.cpp:105] Iteration 75000, lr = 0.001
I1013 04:47:02.729305 11428 solver.cpp:218] Iteration 75100 (3.38773 iter/s, 29.5183s/100 iters), loss = 0.00692067
I1013 04:47:02.729444 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692177 (* 1 = 0.00692177 loss)
I1013 04:47:02.729454 11428 sgd_solver.cpp:105] Iteration 75100, lr = 0.001
I1013 04:47:32.255363 11428 solver.cpp:218] Iteration 75200 (3.38685 iter/s, 29.5259s/100 iters), loss = 0.0074946
I1013 04:47:32.255396 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074957 (* 1 = 0.0074957 loss)
I1013 04:47:32.255404 11428 sgd_solver.cpp:105] Iteration 75200, lr = 0.001
I1013 04:48:01.791613 11428 solver.cpp:218] Iteration 75300 (3.38567 iter/s, 29.5362s/100 iters), loss = 0.00618201
I1013 04:48:01.791750 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618312 (* 1 = 0.00618312 loss)
I1013 04:48:01.791760 11428 sgd_solver.cpp:105] Iteration 75300, lr = 0.001
I1013 04:48:31.361481 11428 solver.cpp:218] Iteration 75400 (3.38184 iter/s, 29.5697s/100 iters), loss = 0.0144274
I1013 04:48:31.361513 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144285 (* 1 = 0.0144285 loss)
I1013 04:48:31.361522 11428 sgd_solver.cpp:105] Iteration 75400, lr = 0.001
I1013 04:49:00.605382 11428 solver.cpp:330] Iteration 75500, Testing net (#0)
I1013 04:49:16.188930 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:49:16.506662 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15175 (* 1 = 1.15175 loss)
I1013 04:49:16.506678 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7388
I1013 04:49:16.797574 11428 solver.cpp:218] Iteration 75500 (2.20089 iter/s, 45.4361s/100 iters), loss = 0.00621481
I1013 04:49:16.797610 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00621592 (* 1 = 0.00621592 loss)
I1013 04:49:16.797617 11428 sgd_solver.cpp:105] Iteration 75500, lr = 0.001
I1013 04:49:46.342697 11428 solver.cpp:218] Iteration 75600 (3.38466 iter/s, 29.5451s/100 iters), loss = 0.00226999
I1013 04:49:46.342841 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227109 (* 1 = 0.00227109 loss)
I1013 04:49:46.342860 11428 sgd_solver.cpp:105] Iteration 75600, lr = 0.001
I1013 04:50:15.876847 11428 solver.cpp:218] Iteration 75700 (3.38593 iter/s, 29.534s/100 iters), loss = 0.00412719
I1013 04:50:15.876878 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041283 (* 1 = 0.0041283 loss)
I1013 04:50:15.876885 11428 sgd_solver.cpp:105] Iteration 75700, lr = 0.001
I1013 04:50:45.376070 11428 solver.cpp:218] Iteration 75800 (3.38992 iter/s, 29.4992s/100 iters), loss = 0.00238643
I1013 04:50:45.376183 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238754 (* 1 = 0.00238754 loss)
I1013 04:50:45.376190 11428 sgd_solver.cpp:105] Iteration 75800, lr = 0.001
I1013 04:51:14.967466 11428 solver.cpp:218] Iteration 75900 (3.37937 iter/s, 29.5913s/100 iters), loss = 0.00313142
I1013 04:51:14.967496 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00313253 (* 1 = 0.00313253 loss)
I1013 04:51:14.967505 11428 sgd_solver.cpp:105] Iteration 75900, lr = 0.001
I1013 04:51:42.981698 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:51:44.168159 11428 solver.cpp:330] Iteration 76000, Testing net (#0)
I1013 04:51:59.777150 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:52:00.096268 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.151 (* 1 = 1.151 loss)
I1013 04:52:00.096285 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7394
I1013 04:52:00.388032 11428 solver.cpp:218] Iteration 76000 (2.20165 iter/s, 45.4206s/100 iters), loss = 0.00187052
I1013 04:52:00.388068 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187163 (* 1 = 0.00187163 loss)
I1013 04:52:00.388077 11428 sgd_solver.cpp:105] Iteration 76000, lr = 0.001
I1013 04:52:29.915460 11428 solver.cpp:218] Iteration 76100 (3.38668 iter/s, 29.5274s/100 iters), loss = 0.00613577
I1013 04:52:29.915561 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613687 (* 1 = 0.00613687 loss)
I1013 04:52:29.915570 11428 sgd_solver.cpp:105] Iteration 76100, lr = 0.001
I1013 04:52:59.440984 11428 solver.cpp:218] Iteration 76200 (3.38691 iter/s, 29.5254s/100 iters), loss = 0.012651
I1013 04:52:59.441016 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126522 (* 1 = 0.0126522 loss)
I1013 04:52:59.441025 11428 sgd_solver.cpp:105] Iteration 76200, lr = 0.001
I1013 04:53:28.948232 11428 solver.cpp:218] Iteration 76300 (3.389 iter/s, 29.5072s/100 iters), loss = 0.00744425
I1013 04:53:28.948346 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00744536 (* 1 = 0.00744536 loss)
I1013 04:53:28.948355 11428 sgd_solver.cpp:105] Iteration 76300, lr = 0.001
I1013 04:53:58.453757 11428 solver.cpp:218] Iteration 76400 (3.38921 iter/s, 29.5054s/100 iters), loss = 0.0070309
I1013 04:53:58.453788 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00703201 (* 1 = 0.00703201 loss)
I1013 04:53:58.453796 11428 sgd_solver.cpp:105] Iteration 76400, lr = 0.001
I1013 04:54:27.674037 11428 solver.cpp:330] Iteration 76500, Testing net (#0)
I1013 04:54:43.310158 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:54:43.630179 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14801 (* 1 = 1.14801 loss)
I1013 04:54:43.630195 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7385
I1013 04:54:43.921243 11428 solver.cpp:218] Iteration 76500 (2.19937 iter/s, 45.4675s/100 iters), loss = 0.0114939
I1013 04:54:43.921277 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011495 (* 1 = 0.011495 loss)
I1013 04:54:43.921286 11428 sgd_solver.cpp:105] Iteration 76500, lr = 0.001
I1013 04:55:13.411216 11428 solver.cpp:218] Iteration 76600 (3.39099 iter/s, 29.4899s/100 iters), loss = 0.0130425
I1013 04:55:13.411339 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130436 (* 1 = 0.0130436 loss)
I1013 04:55:13.411346 11428 sgd_solver.cpp:105] Iteration 76600, lr = 0.001
I1013 04:55:42.924939 11428 solver.cpp:218] Iteration 76700 (3.38827 iter/s, 29.5136s/100 iters), loss = 0.00573864
I1013 04:55:42.924973 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573976 (* 1 = 0.00573976 loss)
I1013 04:55:42.924981 11428 sgd_solver.cpp:105] Iteration 76700, lr = 0.001
I1013 04:56:12.496146 11428 solver.cpp:218] Iteration 76800 (3.38167 iter/s, 29.5712s/100 iters), loss = 0.0045614
I1013 04:56:12.496285 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456251 (* 1 = 0.00456251 loss)
I1013 04:56:12.496294 11428 sgd_solver.cpp:105] Iteration 76800, lr = 0.001
I1013 04:56:42.017936 11428 solver.cpp:218] Iteration 76900 (3.38734 iter/s, 29.5217s/100 iters), loss = 0.00241623
I1013 04:56:42.017972 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241734 (* 1 = 0.00241734 loss)
I1013 04:56:42.017980 11428 sgd_solver.cpp:105] Iteration 76900, lr = 0.001
I1013 04:57:10.066138 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:57:11.247280 11428 solver.cpp:330] Iteration 77000, Testing net (#0)
I1013 04:57:26.834380 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 04:57:27.153091 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1465 (* 1 = 1.1465 loss)
I1013 04:57:27.153108 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7389
I1013 04:57:27.441961 11428 solver.cpp:218] Iteration 77000 (2.20148 iter/s, 45.424s/100 iters), loss = 0.0063463
I1013 04:57:27.441995 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00634742 (* 1 = 0.00634742 loss)
I1013 04:57:27.442003 11428 sgd_solver.cpp:105] Iteration 77000, lr = 0.001
I1013 04:57:56.995800 11428 solver.cpp:218] Iteration 77100 (3.38366 iter/s, 29.5538s/100 iters), loss = 0.00564882
I1013 04:57:56.995952 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00564994 (* 1 = 0.00564994 loss)
I1013 04:57:56.995962 11428 sgd_solver.cpp:105] Iteration 77100, lr = 0.001
I1013 04:58:26.543644 11428 solver.cpp:218] Iteration 77200 (3.38436 iter/s, 29.5477s/100 iters), loss = 0.00536829
I1013 04:58:26.543678 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053694 (* 1 = 0.0053694 loss)
I1013 04:58:26.543685 11428 sgd_solver.cpp:105] Iteration 77200, lr = 0.001
I1013 04:58:56.021221 11428 solver.cpp:218] Iteration 77300 (3.39241 iter/s, 29.4776s/100 iters), loss = 0.0102569
I1013 04:58:56.021368 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102581 (* 1 = 0.0102581 loss)
I1013 04:58:56.021376 11428 sgd_solver.cpp:105] Iteration 77300, lr = 0.001
I1013 04:59:25.575605 11428 solver.cpp:218] Iteration 77400 (3.38361 iter/s, 29.5542s/100 iters), loss = 0.0108458
I1013 04:59:25.575649 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108469 (* 1 = 0.0108469 loss)
I1013 04:59:25.575655 11428 sgd_solver.cpp:105] Iteration 77400, lr = 0.001
I1013 04:59:54.791191 11428 solver.cpp:330] Iteration 77500, Testing net (#0)
I1013 05:00:10.370991 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:00:10.697502 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14485 (* 1 = 1.14485 loss)
I1013 05:00:10.697518 11428 solver.cpp:397]     Test net output #1: accuracy = 0.739
I1013 05:00:10.992359 11428 solver.cpp:218] Iteration 77500 (2.20183 iter/s, 45.4167s/100 iters), loss = 0.00869253
I1013 05:00:10.992394 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869364 (* 1 = 0.00869364 loss)
I1013 05:00:10.992403 11428 sgd_solver.cpp:105] Iteration 77500, lr = 0.001
I1013 05:00:40.475759 11428 solver.cpp:218] Iteration 77600 (3.39175 iter/s, 29.4833s/100 iters), loss = 0.00768685
I1013 05:00:40.475900 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00768796 (* 1 = 0.00768796 loss)
I1013 05:00:40.475909 11428 sgd_solver.cpp:105] Iteration 77600, lr = 0.001
I1013 05:01:10.002707 11428 solver.cpp:218] Iteration 77700 (3.38675 iter/s, 29.5268s/100 iters), loss = 0.0051965
I1013 05:01:10.002740 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00519761 (* 1 = 0.00519761 loss)
I1013 05:01:10.002748 11428 sgd_solver.cpp:105] Iteration 77700, lr = 0.001
I1013 05:01:39.483201 11428 solver.cpp:218] Iteration 77800 (3.39208 iter/s, 29.4805s/100 iters), loss = 0.00253846
I1013 05:01:39.483345 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253957 (* 1 = 0.00253957 loss)
I1013 05:01:39.483353 11428 sgd_solver.cpp:105] Iteration 77800, lr = 0.001
I1013 05:02:09.005532 11428 solver.cpp:218] Iteration 77900 (3.38728 iter/s, 29.5222s/100 iters), loss = 0.00383889
I1013 05:02:09.005566 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383999 (* 1 = 0.00383999 loss)
I1013 05:02:09.005574 11428 sgd_solver.cpp:105] Iteration 77900, lr = 0.001
I1013 05:02:37.020205 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:02:38.193276 11428 solver.cpp:330] Iteration 78000, Testing net (#0)
I1013 05:02:53.837020 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:02:54.159898 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1438 (* 1 = 1.1438 loss)
I1013 05:02:54.159914 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7391
I1013 05:02:54.449885 11428 solver.cpp:218] Iteration 78000 (2.20049 iter/s, 45.4443s/100 iters), loss = 0.00880653
I1013 05:02:54.449924 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00880764 (* 1 = 0.00880764 loss)
I1013 05:02:54.449945 11428 sgd_solver.cpp:105] Iteration 78000, lr = 0.001
I1013 05:03:23.972292 11428 solver.cpp:218] Iteration 78100 (3.38727 iter/s, 29.5223s/100 iters), loss = 0.00671468
I1013 05:03:23.972440 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671578 (* 1 = 0.00671578 loss)
I1013 05:03:23.972451 11428 sgd_solver.cpp:105] Iteration 78100, lr = 0.001
I1013 05:03:53.478482 11428 solver.cpp:218] Iteration 78200 (3.38914 iter/s, 29.5061s/100 iters), loss = 0.00361845
I1013 05:03:53.478514 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361955 (* 1 = 0.00361955 loss)
I1013 05:03:53.478521 11428 sgd_solver.cpp:105] Iteration 78200, lr = 0.001
I1013 05:04:22.987181 11428 solver.cpp:218] Iteration 78300 (3.38883 iter/s, 29.5087s/100 iters), loss = 0.0216583
I1013 05:04:22.987298 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216594 (* 1 = 0.0216594 loss)
I1013 05:04:22.987306 11428 sgd_solver.cpp:105] Iteration 78300, lr = 0.001
I1013 05:04:52.567345 11428 solver.cpp:218] Iteration 78400 (3.38066 iter/s, 29.5801s/100 iters), loss = 0.00391547
I1013 05:04:52.567378 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391657 (* 1 = 0.00391657 loss)
I1013 05:04:52.567384 11428 sgd_solver.cpp:105] Iteration 78400, lr = 0.001
I1013 05:05:21.828404 11428 solver.cpp:330] Iteration 78500, Testing net (#0)
I1013 05:05:37.442404 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:05:37.764371 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14122 (* 1 = 1.14122 loss)
I1013 05:05:37.764389 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7383
I1013 05:05:38.055229 11428 solver.cpp:218] Iteration 78500 (2.19839 iter/s, 45.4879s/100 iters), loss = 0.00863092
I1013 05:05:38.055294 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00863203 (* 1 = 0.00863203 loss)
I1013 05:05:38.055306 11428 sgd_solver.cpp:105] Iteration 78500, lr = 0.001
I1013 05:06:07.561261 11428 solver.cpp:218] Iteration 78600 (3.38915 iter/s, 29.5059s/100 iters), loss = 0.00940641
I1013 05:06:07.561364 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00940751 (* 1 = 0.00940751 loss)
I1013 05:06:07.561377 11428 sgd_solver.cpp:105] Iteration 78600, lr = 0.001
I1013 05:06:37.058248 11428 solver.cpp:218] Iteration 78700 (3.39019 iter/s, 29.4969s/100 iters), loss = 0.00484623
I1013 05:06:37.058285 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00484734 (* 1 = 0.00484734 loss)
I1013 05:06:37.058295 11428 sgd_solver.cpp:105] Iteration 78700, lr = 0.001
I1013 05:07:06.593098 11428 solver.cpp:218] Iteration 78800 (3.38583 iter/s, 29.5348s/100 iters), loss = 0.00165416
I1013 05:07:06.593243 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165526 (* 1 = 0.00165526 loss)
I1013 05:07:06.593256 11428 sgd_solver.cpp:105] Iteration 78800, lr = 0.001
I1013 05:07:36.101641 11428 solver.cpp:218] Iteration 78900 (3.38886 iter/s, 29.5084s/100 iters), loss = 0.00197582
I1013 05:07:36.101678 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197692 (* 1 = 0.00197692 loss)
I1013 05:07:36.101687 11428 sgd_solver.cpp:105] Iteration 78900, lr = 0.001
I1013 05:08:04.159325 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:08:05.332058 11428 solver.cpp:330] Iteration 79000, Testing net (#0)
I1013 05:08:20.965483 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:08:21.283048 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13912 (* 1 = 1.13912 loss)
I1013 05:08:21.283066 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7385
I1013 05:08:21.571771 11428 solver.cpp:218] Iteration 79000 (2.19925 iter/s, 45.4701s/100 iters), loss = 0.00417895
I1013 05:08:21.571806 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418005 (* 1 = 0.00418005 loss)
I1013 05:08:21.571815 11428 sgd_solver.cpp:105] Iteration 79000, lr = 0.001
I1013 05:08:51.083551 11428 solver.cpp:218] Iteration 79100 (3.38848 iter/s, 29.5118s/100 iters), loss = 0.00791085
I1013 05:08:51.083647 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00791195 (* 1 = 0.00791195 loss)
I1013 05:08:51.083667 11428 sgd_solver.cpp:105] Iteration 79100, lr = 0.001
I1013 05:09:20.631014 11428 solver.cpp:218] Iteration 79200 (3.3844 iter/s, 29.5474s/100 iters), loss = 0.0119629
I1013 05:09:20.631047 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011964 (* 1 = 0.011964 loss)
I1013 05:09:20.631053 11428 sgd_solver.cpp:105] Iteration 79200, lr = 0.001
I1013 05:09:50.195566 11428 solver.cpp:218] Iteration 79300 (3.38243 iter/s, 29.5645s/100 iters), loss = 0.00459039
I1013 05:09:50.195678 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459149 (* 1 = 0.00459149 loss)
I1013 05:09:50.195688 11428 sgd_solver.cpp:105] Iteration 79300, lr = 0.001
I1013 05:10:19.683748 11428 solver.cpp:218] Iteration 79400 (3.3912 iter/s, 29.4881s/100 iters), loss = 0.00452328
I1013 05:10:19.683778 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452438 (* 1 = 0.00452438 loss)
I1013 05:10:19.683784 11428 sgd_solver.cpp:105] Iteration 79400, lr = 0.001
I1013 05:10:48.907503 11428 solver.cpp:330] Iteration 79500, Testing net (#0)
I1013 05:11:04.465963 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:11:04.785193 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13626 (* 1 = 1.13626 loss)
I1013 05:11:04.785209 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7387
I1013 05:11:05.076109 11428 solver.cpp:218] Iteration 79500 (2.20301 iter/s, 45.3923s/100 iters), loss = 0.011468
I1013 05:11:05.076144 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114691 (* 1 = 0.0114691 loss)
I1013 05:11:05.076153 11428 sgd_solver.cpp:105] Iteration 79500, lr = 0.001
I1013 05:11:34.655771 11428 solver.cpp:218] Iteration 79600 (3.3807 iter/s, 29.5796s/100 iters), loss = 0.00263134
I1013 05:11:34.655911 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263244 (* 1 = 0.00263244 loss)
I1013 05:11:34.655921 11428 sgd_solver.cpp:105] Iteration 79600, lr = 0.001
I1013 05:12:04.188957 11428 solver.cpp:218] Iteration 79700 (3.38604 iter/s, 29.5331s/100 iters), loss = 0.00434076
I1013 05:12:04.188994 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434186 (* 1 = 0.00434186 loss)
I1013 05:12:04.189002 11428 sgd_solver.cpp:105] Iteration 79700, lr = 0.001
I1013 05:12:33.698321 11428 solver.cpp:218] Iteration 79800 (3.38876 iter/s, 29.5093s/100 iters), loss = 0.00487644
I1013 05:12:33.698405 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487754 (* 1 = 0.00487754 loss)
I1013 05:12:33.698422 11428 sgd_solver.cpp:105] Iteration 79800, lr = 0.001
I1013 05:13:03.223340 11428 solver.cpp:218] Iteration 79900 (3.38697 iter/s, 29.5249s/100 iters), loss = 0.0021018
I1013 05:13:03.223381 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210289 (* 1 = 0.00210289 loss)
I1013 05:13:03.223390 11428 sgd_solver.cpp:105] Iteration 79900, lr = 0.001
I1013 05:13:31.290804 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:13:32.466943 11428 solver.cpp:330] Iteration 80000, Testing net (#0)
I1013 05:13:48.126497 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:13:48.446715 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13439 (* 1 = 1.13439 loss)
I1013 05:13:48.446743 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7387
I1013 05:13:48.739140 11428 solver.cpp:218] Iteration 80000 (2.19704 iter/s, 45.5158s/100 iters), loss = 0.010093
I1013 05:13:48.739172 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100941 (* 1 = 0.0100941 loss)
I1013 05:13:48.739181 11428 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1013 05:14:18.241284 11428 solver.cpp:218] Iteration 80100 (3.38959 iter/s, 29.5021s/100 iters), loss = 0.0114199
I1013 05:14:18.241403 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011421 (* 1 = 0.011421 loss)
I1013 05:14:18.241413 11428 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1013 05:14:47.715636 11428 solver.cpp:218] Iteration 80200 (3.39279 iter/s, 29.4742s/100 iters), loss = 0.00406007
I1013 05:14:47.715669 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406117 (* 1 = 0.00406117 loss)
I1013 05:14:47.715679 11428 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1013 05:15:17.230584 11428 solver.cpp:218] Iteration 80300 (3.38812 iter/s, 29.5149s/100 iters), loss = 0.00418431
I1013 05:15:17.230700 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418541 (* 1 = 0.00418541 loss)
I1013 05:15:17.230713 11428 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1013 05:15:46.725483 11428 solver.cpp:218] Iteration 80400 (3.39043 iter/s, 29.4948s/100 iters), loss = 0.0067609
I1013 05:15:46.725518 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006762 (* 1 = 0.006762 loss)
I1013 05:15:46.725528 11428 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1013 05:16:15.947983 11428 solver.cpp:330] Iteration 80500, Testing net (#0)
I1013 05:16:31.624234 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:16:31.944820 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13343 (* 1 = 1.13343 loss)
I1013 05:16:31.944839 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7395
I1013 05:16:32.236238 11428 solver.cpp:218] Iteration 80500 (2.19728 iter/s, 45.5107s/100 iters), loss = 0.00893377
I1013 05:16:32.236276 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00893487 (* 1 = 0.00893487 loss)
I1013 05:16:32.236286 11428 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1013 05:17:01.742118 11428 solver.cpp:218] Iteration 80600 (3.38916 iter/s, 29.5058s/100 iters), loss = 0.00419338
I1013 05:17:01.742228 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419448 (* 1 = 0.00419448 loss)
I1013 05:17:01.742240 11428 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1013 05:17:31.280719 11428 solver.cpp:218] Iteration 80700 (3.38541 iter/s, 29.5385s/100 iters), loss = 0.00914572
I1013 05:17:31.280755 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914682 (* 1 = 0.00914682 loss)
I1013 05:17:31.280766 11428 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1013 05:18:00.793326 11428 solver.cpp:218] Iteration 80800 (3.38839 iter/s, 29.5126s/100 iters), loss = 0.00181612
I1013 05:18:00.793457 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181722 (* 1 = 0.00181722 loss)
I1013 05:18:00.793471 11428 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1013 05:18:30.303839 11428 solver.cpp:218] Iteration 80900 (3.38864 iter/s, 29.5104s/100 iters), loss = 0.00239065
I1013 05:18:30.303874 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239175 (* 1 = 0.00239175 loss)
I1013 05:18:30.303884 11428 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1013 05:18:58.375080 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:18:59.551463 11428 solver.cpp:330] Iteration 81000, Testing net (#0)
I1013 05:19:15.154398 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:19:15.475908 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13146 (* 1 = 1.13146 loss)
I1013 05:19:15.475926 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7388
I1013 05:19:15.767489 11428 solver.cpp:218] Iteration 81000 (2.19956 iter/s, 45.4636s/100 iters), loss = 0.00306882
I1013 05:19:15.767521 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306992 (* 1 = 0.00306992 loss)
I1013 05:19:15.767529 11428 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1013 05:19:45.281718 11428 solver.cpp:218] Iteration 81100 (3.3882 iter/s, 29.5142s/100 iters), loss = 0.0074027
I1013 05:19:45.281852 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074038 (* 1 = 0.0074038 loss)
I1013 05:19:45.281860 11428 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1013 05:20:14.795730 11428 solver.cpp:218] Iteration 81200 (3.38823 iter/s, 29.5139s/100 iters), loss = 0.00610281
I1013 05:20:14.795763 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00610392 (* 1 = 0.00610392 loss)
I1013 05:20:14.795769 11428 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1013 05:20:44.311704 11428 solver.cpp:218] Iteration 81300 (3.388 iter/s, 29.516s/100 iters), loss = 0.00597159
I1013 05:20:44.311847 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059727 (* 1 = 0.0059727 loss)
I1013 05:20:44.311858 11428 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1013 05:21:13.809190 11428 solver.cpp:218] Iteration 81400 (3.39014 iter/s, 29.4974s/100 iters), loss = 0.00579274
I1013 05:21:13.809221 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579385 (* 1 = 0.00579385 loss)
I1013 05:21:13.809228 11428 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1013 05:21:43.029695 11428 solver.cpp:330] Iteration 81500, Testing net (#0)
I1013 05:21:58.681643 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:21:59.001534 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13014 (* 1 = 1.13014 loss)
I1013 05:21:59.001551 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7393
I1013 05:21:59.293324 11428 solver.cpp:218] Iteration 81500 (2.19857 iter/s, 45.4841s/100 iters), loss = 0.00538888
I1013 05:21:59.293356 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538999 (* 1 = 0.00538999 loss)
I1013 05:21:59.293365 11428 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1013 05:22:28.796548 11428 solver.cpp:218] Iteration 81600 (3.38947 iter/s, 29.5032s/100 iters), loss = 0.00271314
I1013 05:22:28.796690 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271426 (* 1 = 0.00271426 loss)
I1013 05:22:28.796699 11428 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1013 05:22:58.276525 11428 solver.cpp:218] Iteration 81700 (3.39215 iter/s, 29.4798s/100 iters), loss = 0.00443787
I1013 05:22:58.276556 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443899 (* 1 = 0.00443899 loss)
I1013 05:22:58.276564 11428 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1013 05:23:27.776841 11428 solver.cpp:218] Iteration 81800 (3.3898 iter/s, 29.5003s/100 iters), loss = 0.00231701
I1013 05:23:27.776984 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231813 (* 1 = 0.00231813 loss)
I1013 05:23:27.776993 11428 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1013 05:23:57.305404 11428 solver.cpp:218] Iteration 81900 (3.38657 iter/s, 29.5284s/100 iters), loss = 0.0017148
I1013 05:23:57.305436 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171591 (* 1 = 0.00171591 loss)
I1013 05:23:57.305444 11428 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1013 05:24:25.399870 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:24:26.588379 11428 solver.cpp:330] Iteration 82000, Testing net (#0)
I1013 05:24:42.247079 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:24:42.567718 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12801 (* 1 = 1.12801 loss)
I1013 05:24:42.567735 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 05:24:42.859326 11428 solver.cpp:218] Iteration 82000 (2.1952 iter/s, 45.5539s/100 iters), loss = 0.00268947
I1013 05:24:42.859356 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00269057 (* 1 = 0.00269057 loss)
I1013 05:24:42.859364 11428 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1013 05:25:12.374814 11428 solver.cpp:218] Iteration 82100 (3.38806 iter/s, 29.5154s/100 iters), loss = 0.0053122
I1013 05:25:12.374981 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053133 (* 1 = 0.0053133 loss)
I1013 05:25:12.374991 11428 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1013 05:25:41.866137 11428 solver.cpp:218] Iteration 82200 (3.39085 iter/s, 29.4912s/100 iters), loss = 0.00550527
I1013 05:25:41.866168 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550637 (* 1 = 0.00550637 loss)
I1013 05:25:41.866175 11428 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1013 05:26:11.411216 11428 solver.cpp:218] Iteration 82300 (3.38466 iter/s, 29.5451s/100 iters), loss = 0.00431524
I1013 05:26:11.411331 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431634 (* 1 = 0.00431634 loss)
I1013 05:26:11.411340 11428 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1013 05:26:40.916453 11428 solver.cpp:218] Iteration 82400 (3.38924 iter/s, 29.5051s/100 iters), loss = 0.00685994
I1013 05:26:40.916486 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00686105 (* 1 = 0.00686105 loss)
I1013 05:26:40.916493 11428 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1013 05:27:10.161798 11428 solver.cpp:330] Iteration 82500, Testing net (#0)
I1013 05:27:25.800762 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:27:26.120913 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12751 (* 1 = 1.12751 loss)
I1013 05:27:26.120929 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7395
I1013 05:27:26.410662 11428 solver.cpp:218] Iteration 82500 (2.19808 iter/s, 45.4942s/100 iters), loss = 0.00700489
I1013 05:27:26.410696 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700599 (* 1 = 0.00700599 loss)
I1013 05:27:26.410704 11428 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1013 05:27:55.889937 11428 solver.cpp:218] Iteration 82600 (3.39222 iter/s, 29.4792s/100 iters), loss = 0.00572979
I1013 05:27:55.890081 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573089 (* 1 = 0.00573089 loss)
I1013 05:27:55.890090 11428 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1013 05:28:25.437019 11428 solver.cpp:218] Iteration 82700 (3.38444 iter/s, 29.547s/100 iters), loss = 0.0066389
I1013 05:28:25.437052 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664001 (* 1 = 0.00664001 loss)
I1013 05:28:25.437059 11428 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1013 05:28:55.009222 11428 solver.cpp:218] Iteration 82800 (3.38156 iter/s, 29.5722s/100 iters), loss = 0.00609754
I1013 05:28:55.009325 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609864 (* 1 = 0.00609864 loss)
I1013 05:28:55.009333 11428 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1013 05:29:24.488494 11428 solver.cpp:218] Iteration 82900 (3.39223 iter/s, 29.4792s/100 iters), loss = 0.00500418
I1013 05:29:24.488528 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500529 (* 1 = 0.00500529 loss)
I1013 05:29:24.488536 11428 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1013 05:29:52.560459 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:29:53.737620 11428 solver.cpp:330] Iteration 83000, Testing net (#0)
I1013 05:30:09.389169 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:30:09.707880 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12649 (* 1 = 1.12649 loss)
I1013 05:30:09.707896 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 05:30:09.997732 11428 solver.cpp:218] Iteration 83000 (2.19736 iter/s, 45.5092s/100 iters), loss = 0.00739188
I1013 05:30:09.997766 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00739298 (* 1 = 0.00739298 loss)
I1013 05:30:09.997776 11428 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1013 05:30:39.518615 11428 solver.cpp:218] Iteration 83100 (3.38744 iter/s, 29.5209s/100 iters), loss = 0.00580912
I1013 05:30:39.518748 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581022 (* 1 = 0.00581022 loss)
I1013 05:30:39.518759 11428 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1013 05:31:09.051975 11428 solver.cpp:218] Iteration 83200 (3.38601 iter/s, 29.5332s/100 iters), loss = 0.00664366
I1013 05:31:09.052006 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664476 (* 1 = 0.00664476 loss)
I1013 05:31:09.052013 11428 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1013 05:31:38.592895 11428 solver.cpp:218] Iteration 83300 (3.38514 iter/s, 29.5409s/100 iters), loss = 0.00725646
I1013 05:31:38.593037 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725757 (* 1 = 0.00725757 loss)
I1013 05:31:38.593047 11428 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1013 05:32:08.122707 11428 solver.cpp:218] Iteration 83400 (3.38642 iter/s, 29.5297s/100 iters), loss = 0.00579606
I1013 05:32:08.122741 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579716 (* 1 = 0.00579716 loss)
I1013 05:32:08.122748 11428 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1013 05:32:37.355135 11428 solver.cpp:330] Iteration 83500, Testing net (#0)
I1013 05:32:52.957646 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:32:53.276763 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12364 (* 1 = 1.12364 loss)
I1013 05:32:53.276780 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7396
I1013 05:32:53.567942 11428 solver.cpp:218] Iteration 83500 (2.20045 iter/s, 45.4452s/100 iters), loss = 0.00350603
I1013 05:32:53.567976 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350713 (* 1 = 0.00350713 loss)
I1013 05:32:53.567984 11428 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1013 05:33:23.115936 11428 solver.cpp:218] Iteration 83600 (3.38433 iter/s, 29.548s/100 iters), loss = 0.00326548
I1013 05:33:23.116080 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326658 (* 1 = 0.00326658 loss)
I1013 05:33:23.116089 11428 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1013 05:33:52.617779 11428 solver.cpp:218] Iteration 83700 (3.38963 iter/s, 29.5017s/100 iters), loss = 0.00473261
I1013 05:33:52.617810 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047337 (* 1 = 0.0047337 loss)
I1013 05:33:52.617817 11428 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1013 05:34:22.162240 11428 solver.cpp:218] Iteration 83800 (3.38473 iter/s, 29.5444s/100 iters), loss = 0.00424968
I1013 05:34:22.162358 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425077 (* 1 = 0.00425077 loss)
I1013 05:34:22.162369 11428 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1013 05:34:51.655903 11428 solver.cpp:218] Iteration 83900 (3.39057 iter/s, 29.4936s/100 iters), loss = 0.00217024
I1013 05:34:51.655936 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217134 (* 1 = 0.00217134 loss)
I1013 05:34:51.655943 11428 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1013 05:35:19.758967 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:35:20.952785 11428 solver.cpp:330] Iteration 84000, Testing net (#0)
I1013 05:35:36.578447 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:35:36.896533 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12281 (* 1 = 1.12281 loss)
I1013 05:35:36.896549 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7394
I1013 05:35:37.185672 11428 solver.cpp:218] Iteration 84000 (2.19637 iter/s, 45.5298s/100 iters), loss = 0.00321716
I1013 05:35:37.185705 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321826 (* 1 = 0.00321826 loss)
I1013 05:35:37.185712 11428 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1013 05:36:06.716680 11428 solver.cpp:218] Iteration 84100 (3.38627 iter/s, 29.531s/100 iters), loss = 0.00607924
I1013 05:36:06.716800 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00608034 (* 1 = 0.00608034 loss)
I1013 05:36:06.716809 11428 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1013 05:36:36.232045 11428 solver.cpp:218] Iteration 84200 (3.38808 iter/s, 29.5153s/100 iters), loss = 0.00691812
I1013 05:36:36.232077 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691922 (* 1 = 0.00691922 loss)
I1013 05:36:36.232085 11428 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1013 05:37:05.768272 11428 solver.cpp:218] Iteration 84300 (3.38568 iter/s, 29.5362s/100 iters), loss = 0.00374974
I1013 05:37:05.768414 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375083 (* 1 = 0.00375083 loss)
I1013 05:37:05.768424 11428 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1013 05:37:35.276018 11428 solver.cpp:218] Iteration 84400 (3.38896 iter/s, 29.5076s/100 iters), loss = 0.0071554
I1013 05:37:35.276052 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00715649 (* 1 = 0.00715649 loss)
I1013 05:37:35.276059 11428 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1013 05:38:04.516376 11428 solver.cpp:330] Iteration 84500, Testing net (#0)
I1013 05:38:20.150108 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:38:20.471338 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12122 (* 1 = 1.12122 loss)
I1013 05:38:20.471354 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7391
I1013 05:38:20.762840 11428 solver.cpp:218] Iteration 84500 (2.19844 iter/s, 45.4868s/100 iters), loss = 0.00704175
I1013 05:38:20.762876 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704284 (* 1 = 0.00704284 loss)
I1013 05:38:20.762882 11428 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1013 05:38:50.255965 11428 solver.cpp:218] Iteration 84600 (3.39063 iter/s, 29.4931s/100 iters), loss = 0.00446434
I1013 05:38:50.256067 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446543 (* 1 = 0.00446543 loss)
I1013 05:38:50.256075 11428 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1013 05:39:19.790614 11428 solver.cpp:218] Iteration 84700 (3.38586 iter/s, 29.5346s/100 iters), loss = 0.00536224
I1013 05:39:19.790647 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536333 (* 1 = 0.00536333 loss)
I1013 05:39:19.790655 11428 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1013 05:39:49.343053 11428 solver.cpp:218] Iteration 84800 (3.38382 iter/s, 29.5524s/100 iters), loss = 0.00208363
I1013 05:39:49.343173 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208472 (* 1 = 0.00208472 loss)
I1013 05:39:49.343192 11428 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1013 05:40:18.806005 11428 solver.cpp:218] Iteration 84900 (3.3941 iter/s, 29.4628s/100 iters), loss = 0.00263483
I1013 05:40:18.806036 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263593 (* 1 = 0.00263593 loss)
I1013 05:40:18.806044 11428 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1013 05:40:46.870009 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:40:48.061291 11428 solver.cpp:330] Iteration 85000, Testing net (#0)
I1013 05:41:03.649938 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:41:03.970295 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.11992 (* 1 = 1.11992 loss)
I1013 05:41:03.970317 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7386
I1013 05:41:04.259630 11428 solver.cpp:218] Iteration 85000 (2.20005 iter/s, 45.4536s/100 iters), loss = 0.00417847
I1013 05:41:04.259686 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417957 (* 1 = 0.00417957 loss)
I1013 05:41:04.259694 11428 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1013 05:41:33.753967 11428 solver.cpp:218] Iteration 85100 (3.39048 iter/s, 29.4943s/100 iters), loss = 0.00947302
I1013 05:41:33.754093 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00947411 (* 1 = 0.00947411 loss)
I1013 05:41:33.754103 11428 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1013 05:42:03.237608 11428 solver.cpp:218] Iteration 85200 (3.39172 iter/s, 29.4835s/100 iters), loss = 0.0023959
I1013 05:42:03.237642 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002397 (* 1 = 0.002397 loss)
I1013 05:42:03.237649 11428 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1013 05:42:32.741780 11428 solver.cpp:218] Iteration 85300 (3.38935 iter/s, 29.5041s/100 iters), loss = 0.00503953
I1013 05:42:32.741950 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00504063 (* 1 = 0.00504063 loss)
I1013 05:42:32.741960 11428 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1013 05:43:02.243588 11428 solver.cpp:218] Iteration 85400 (3.38964 iter/s, 29.5017s/100 iters), loss = 0.00730217
I1013 05:43:02.243625 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00730327 (* 1 = 0.00730327 loss)
I1013 05:43:02.243633 11428 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1013 05:43:31.439785 11428 solver.cpp:330] Iteration 85500, Testing net (#0)
I1013 05:43:47.011818 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:43:47.330651 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1177 (* 1 = 1.1177 loss)
I1013 05:43:47.330667 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7381
I1013 05:43:47.620740 11428 solver.cpp:218] Iteration 85500 (2.20375 iter/s, 45.3771s/100 iters), loss = 0.00445793
I1013 05:43:47.620775 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445903 (* 1 = 0.00445903 loss)
I1013 05:43:47.620784 11428 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1013 05:44:17.120841 11428 solver.cpp:218] Iteration 85600 (3.38982 iter/s, 29.5001s/100 iters), loss = 0.00316238
I1013 05:44:17.120982 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316348 (* 1 = 0.00316348 loss)
I1013 05:44:17.120992 11428 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1013 05:44:46.626857 11428 solver.cpp:218] Iteration 85700 (3.38915 iter/s, 29.5059s/100 iters), loss = 0.00670692
I1013 05:44:46.626888 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670802 (* 1 = 0.00670802 loss)
I1013 05:44:46.626895 11428 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1013 05:45:16.152288 11428 solver.cpp:218] Iteration 85800 (3.38691 iter/s, 29.5254s/100 iters), loss = 0.00683274
I1013 05:45:16.152432 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683384 (* 1 = 0.00683384 loss)
I1013 05:45:16.152442 11428 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1013 05:45:45.665614 11428 solver.cpp:218] Iteration 85900 (3.38831 iter/s, 29.5132s/100 iters), loss = 0.00284512
I1013 05:45:45.665647 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284621 (* 1 = 0.00284621 loss)
I1013 05:45:45.665653 11428 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1013 05:46:13.712460 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:46:14.904125 11428 solver.cpp:330] Iteration 86000, Testing net (#0)
I1013 05:46:30.561619 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:46:30.881757 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.11755 (* 1 = 1.11755 loss)
I1013 05:46:30.881772 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7389
I1013 05:46:31.173976 11428 solver.cpp:218] Iteration 86000 (2.1974 iter/s, 45.5083s/100 iters), loss = 0.00233066
I1013 05:46:31.174013 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233175 (* 1 = 0.00233175 loss)
I1013 05:46:31.174021 11428 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1013 05:47:00.675153 11428 solver.cpp:218] Iteration 86100 (3.3897 iter/s, 29.5011s/100 iters), loss = 0.00717532
I1013 05:47:00.675295 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00717642 (* 1 = 0.00717642 loss)
I1013 05:47:00.675305 11428 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1013 05:47:30.181567 11428 solver.cpp:218] Iteration 86200 (3.38911 iter/s, 29.5063s/100 iters), loss = 0.00433371
I1013 05:47:30.181598 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433481 (* 1 = 0.00433481 loss)
I1013 05:47:30.181607 11428 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1013 05:47:59.700917 11428 solver.cpp:218] Iteration 86300 (3.38761 iter/s, 29.5193s/100 iters), loss = 0.00611917
I1013 05:47:59.701079 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612027 (* 1 = 0.00612027 loss)
I1013 05:47:59.701092 11428 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1013 05:48:29.221443 11428 solver.cpp:218] Iteration 86400 (3.38749 iter/s, 29.5204s/100 iters), loss = 0.00550264
I1013 05:48:29.221477 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550374 (* 1 = 0.00550374 loss)
I1013 05:48:29.221484 11428 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1013 05:48:58.469432 11428 solver.cpp:330] Iteration 86500, Testing net (#0)
I1013 05:49:14.082639 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:49:14.401842 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.11553 (* 1 = 1.11553 loss)
I1013 05:49:14.401859 11428 solver.cpp:397]     Test net output #1: accuracy = 0.74
I1013 05:49:14.690767 11428 solver.cpp:218] Iteration 86500 (2.19929 iter/s, 45.4693s/100 iters), loss = 0.00692125
I1013 05:49:14.690798 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692235 (* 1 = 0.00692235 loss)
I1013 05:49:14.690805 11428 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1013 05:49:44.260149 11428 solver.cpp:218] Iteration 86600 (3.38188 iter/s, 29.5694s/100 iters), loss = 0.0030139
I1013 05:49:44.260298 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003015 (* 1 = 0.003015 loss)
I1013 05:49:44.260308 11428 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1013 05:50:13.799556 11428 solver.cpp:218] Iteration 86700 (3.38532 iter/s, 29.5393s/100 iters), loss = 0.00576267
I1013 05:50:13.799589 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576378 (* 1 = 0.00576378 loss)
I1013 05:50:13.799597 11428 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1013 05:50:43.340823 11428 solver.cpp:218] Iteration 86800 (3.3851 iter/s, 29.5412s/100 iters), loss = 0.00424486
I1013 05:50:43.340939 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424596 (* 1 = 0.00424596 loss)
I1013 05:50:43.340947 11428 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1013 05:51:12.862195 11428 solver.cpp:218] Iteration 86900 (3.38739 iter/s, 29.5213s/100 iters), loss = 0.00203498
I1013 05:51:12.862227 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203608 (* 1 = 0.00203608 loss)
I1013 05:51:12.862236 11428 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1013 05:51:40.922605 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:51:42.096460 11428 solver.cpp:330] Iteration 87000, Testing net (#0)
I1013 05:51:57.686549 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:51:58.003742 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.11385 (* 1 = 1.11385 loss)
I1013 05:51:58.003758 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7393
I1013 05:51:58.288710 11428 solver.cpp:218] Iteration 87000 (2.20136 iter/s, 45.4265s/100 iters), loss = 0.0112622
I1013 05:51:58.288746 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112633 (* 1 = 0.0112633 loss)
I1013 05:51:58.288754 11428 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1013 05:52:27.864570 11428 solver.cpp:218] Iteration 87100 (3.38114 iter/s, 29.5758s/100 iters), loss = 0.0094988
I1013 05:52:27.864713 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0094999 (* 1 = 0.0094999 loss)
I1013 05:52:27.864723 11428 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1013 05:52:57.323843 11428 solver.cpp:218] Iteration 87200 (3.39453 iter/s, 29.4591s/100 iters), loss = 0.00854651
I1013 05:52:57.323876 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00854762 (* 1 = 0.00854762 loss)
I1013 05:52:57.323884 11428 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1013 05:53:26.813040 11428 solver.cpp:218] Iteration 87300 (3.39108 iter/s, 29.4892s/100 iters), loss = 0.00256247
I1013 05:53:26.813180 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256358 (* 1 = 0.00256358 loss)
I1013 05:53:26.813215 11428 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1013 05:53:56.303081 11428 solver.cpp:218] Iteration 87400 (3.39099 iter/s, 29.4899s/100 iters), loss = 0.00632188
I1013 05:53:56.303114 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00632298 (* 1 = 0.00632298 loss)
I1013 05:53:56.303122 11428 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1013 05:54:25.514345 11428 solver.cpp:330] Iteration 87500, Testing net (#0)
I1013 05:54:41.151512 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:54:41.469787 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.11342 (* 1 = 1.11342 loss)
I1013 05:54:41.469804 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7384
I1013 05:54:41.757690 11428 solver.cpp:218] Iteration 87500 (2.2 iter/s, 45.4546s/100 iters), loss = 0.00504428
I1013 05:54:41.757722 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00504538 (* 1 = 0.00504538 loss)
I1013 05:54:41.757731 11428 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1013 05:55:11.271076 11428 solver.cpp:218] Iteration 87600 (3.3883 iter/s, 29.5134s/100 iters), loss = 0.00421019
I1013 05:55:11.271191 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421129 (* 1 = 0.00421129 loss)
I1013 05:55:11.271199 11428 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1013 05:55:40.811141 11428 solver.cpp:218] Iteration 87700 (3.38524 iter/s, 29.54s/100 iters), loss = 0.0110521
I1013 05:55:40.811172 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110532 (* 1 = 0.0110532 loss)
I1013 05:55:40.811180 11428 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1013 05:56:10.335564 11428 solver.cpp:218] Iteration 87800 (3.38703 iter/s, 29.5244s/100 iters), loss = 0.00915701
I1013 05:56:10.335677 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915811 (* 1 = 0.00915811 loss)
I1013 05:56:10.335685 11428 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1013 05:56:39.806076 11428 solver.cpp:218] Iteration 87900 (3.39323 iter/s, 29.4704s/100 iters), loss = 0.00485082
I1013 05:56:39.806107 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00485193 (* 1 = 0.00485193 loss)
I1013 05:56:39.806113 11428 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1013 05:57:07.851917 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:57:09.044507 11428 solver.cpp:330] Iteration 88000, Testing net (#0)
I1013 05:57:24.669746 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 05:57:24.986441 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.11266 (* 1 = 1.11266 loss)
I1013 05:57:24.986457 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7401
I1013 05:57:25.276310 11428 solver.cpp:218] Iteration 88000 (2.19924 iter/s, 45.4702s/100 iters), loss = 0.00200843
I1013 05:57:25.276345 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200953 (* 1 = 0.00200953 loss)
I1013 05:57:25.276352 11428 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1013 05:57:54.829335 11428 solver.cpp:218] Iteration 88100 (3.38375 iter/s, 29.553s/100 iters), loss = 0.00491678
I1013 05:57:54.829483 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491789 (* 1 = 0.00491789 loss)
I1013 05:57:54.829493 11428 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1013 05:58:24.346320 11428 solver.cpp:218] Iteration 88200 (3.3879 iter/s, 29.5168s/100 iters), loss = 0.00554377
I1013 05:58:24.346352 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554488 (* 1 = 0.00554488 loss)
I1013 05:58:24.346360 11428 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1013 05:58:53.876848 11428 solver.cpp:218] Iteration 88300 (3.38633 iter/s, 29.5305s/100 iters), loss = 0.00577807
I1013 05:58:53.876971 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00577918 (* 1 = 0.00577918 loss)
I1013 05:58:53.876989 11428 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1013 05:59:23.389528 11428 solver.cpp:218] Iteration 88400 (3.38839 iter/s, 29.5126s/100 iters), loss = 0.00394753
I1013 05:59:23.389561 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394864 (* 1 = 0.00394864 loss)
I1013 05:59:23.389569 11428 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1013 05:59:52.614691 11428 solver.cpp:330] Iteration 88500, Testing net (#0)
I1013 06:00:08.208294 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:00:08.527638 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10994 (* 1 = 1.10994 loss)
I1013 06:00:08.527654 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7402
I1013 06:00:08.818480 11428 solver.cpp:218] Iteration 88500 (2.20124 iter/s, 45.4289s/100 iters), loss = 0.011774
I1013 06:00:08.818511 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117751 (* 1 = 0.0117751 loss)
I1013 06:00:08.818518 11428 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1013 06:00:38.366310 11428 solver.cpp:218] Iteration 88600 (3.38435 iter/s, 29.5478s/100 iters), loss = 0.00571795
I1013 06:00:38.366407 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571906 (* 1 = 0.00571906 loss)
I1013 06:00:38.366415 11428 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1013 06:01:07.893033 11428 solver.cpp:218] Iteration 88700 (3.38677 iter/s, 29.5266s/100 iters), loss = 0.00615532
I1013 06:01:07.893065 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615643 (* 1 = 0.00615643 loss)
I1013 06:01:07.893074 11428 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1013 06:01:37.390883 11428 solver.cpp:218] Iteration 88800 (3.39008 iter/s, 29.4978s/100 iters), loss = 0.00320238
I1013 06:01:37.390983 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320348 (* 1 = 0.00320348 loss)
I1013 06:01:37.391002 11428 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1013 06:02:06.934542 11428 solver.cpp:218] Iteration 88900 (3.38483 iter/s, 29.5436s/100 iters), loss = 0.00167764
I1013 06:02:06.934577 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167875 (* 1 = 0.00167875 loss)
I1013 06:02:06.934586 11428 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1013 06:02:34.998029 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:02:36.178855 11428 solver.cpp:330] Iteration 89000, Testing net (#0)
I1013 06:02:51.778028 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:02:52.098569 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10871 (* 1 = 1.10871 loss)
I1013 06:02:52.098587 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7401
I1013 06:02:52.390269 11428 solver.cpp:218] Iteration 89000 (2.19994 iter/s, 45.4557s/100 iters), loss = 0.00347952
I1013 06:02:52.390302 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348062 (* 1 = 0.00348062 loss)
I1013 06:02:52.390311 11428 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1013 06:03:21.952260 11428 solver.cpp:218] Iteration 89100 (3.38273 iter/s, 29.5619s/100 iters), loss = 0.00538335
I1013 06:03:21.952401 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538446 (* 1 = 0.00538446 loss)
I1013 06:03:21.952412 11428 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1013 06:03:51.455075 11428 solver.cpp:218] Iteration 89200 (3.38952 iter/s, 29.5027s/100 iters), loss = 0.00432683
I1013 06:03:51.455106 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432793 (* 1 = 0.00432793 loss)
I1013 06:03:51.455112 11428 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1013 06:04:20.987957 11428 solver.cpp:218] Iteration 89300 (3.38606 iter/s, 29.5329s/100 iters), loss = 0.00456352
I1013 06:04:20.988047 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456463 (* 1 = 0.00456463 loss)
I1013 06:04:20.988059 11428 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1013 06:04:50.514669 11428 solver.cpp:218] Iteration 89400 (3.38677 iter/s, 29.5266s/100 iters), loss = 0.00451286
I1013 06:04:50.514703 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451396 (* 1 = 0.00451396 loss)
I1013 06:04:50.514710 11428 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1013 06:05:19.766577 11428 solver.cpp:330] Iteration 89500, Testing net (#0)
I1013 06:05:35.342221 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:05:35.659801 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10818 (* 1 = 1.10818 loss)
I1013 06:05:35.659816 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 06:05:35.948545 11428 solver.cpp:218] Iteration 89500 (2.201 iter/s, 45.4339s/100 iters), loss = 0.00848811
I1013 06:05:35.948578 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00848922 (* 1 = 0.00848922 loss)
I1013 06:05:35.948586 11428 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1013 06:06:05.484472 11428 solver.cpp:218] Iteration 89600 (3.38571 iter/s, 29.5359s/100 iters), loss = 0.00333115
I1013 06:06:05.484583 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333225 (* 1 = 0.00333225 loss)
I1013 06:06:05.484591 11428 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1013 06:06:35.003136 11428 solver.cpp:218] Iteration 89700 (3.3877 iter/s, 29.5186s/100 iters), loss = 0.00468883
I1013 06:06:35.003172 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00468993 (* 1 = 0.00468993 loss)
I1013 06:06:35.003180 11428 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1013 06:07:04.492146 11428 solver.cpp:218] Iteration 89800 (3.3911 iter/s, 29.489s/100 iters), loss = 0.00363186
I1013 06:07:04.492254 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363296 (* 1 = 0.00363296 loss)
I1013 06:07:04.492271 11428 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1013 06:07:33.971967 11428 solver.cpp:218] Iteration 89900 (3.39216 iter/s, 29.4797s/100 iters), loss = 0.00249655
I1013 06:07:33.972000 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249765 (* 1 = 0.00249765 loss)
I1013 06:07:33.972007 11428 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1013 06:08:01.989593 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:08:03.178447 11428 solver.cpp:330] Iteration 90000, Testing net (#0)
I1013 06:08:18.802877 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:08:19.127331 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10699 (* 1 = 1.10699 loss)
I1013 06:08:19.127347 11428 solver.cpp:397]     Test net output #1: accuracy = 0.74
I1013 06:08:19.419147 11428 solver.cpp:218] Iteration 90000 (2.20036 iter/s, 45.4472s/100 iters), loss = 0.0019957
I1013 06:08:19.419180 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019968 (* 1 = 0.0019968 loss)
I1013 06:08:19.419188 11428 sgd_solver.cpp:46] MultiStep Status: Iteration 90000, step = 2
I1013 06:08:19.419191 11428 sgd_solver.cpp:105] Iteration 90000, lr = 0.0001
I1013 06:08:48.894768 11428 solver.cpp:218] Iteration 90100 (3.39264 iter/s, 29.4756s/100 iters), loss = 0.00508265
I1013 06:08:48.894919 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508376 (* 1 = 0.00508376 loss)
I1013 06:08:48.894929 11428 sgd_solver.cpp:105] Iteration 90100, lr = 0.0001
I1013 06:09:18.410766 11428 solver.cpp:218] Iteration 90200 (3.38801 iter/s, 29.5159s/100 iters), loss = 0.00908142
I1013 06:09:18.410799 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00908253 (* 1 = 0.00908253 loss)
I1013 06:09:18.410805 11428 sgd_solver.cpp:105] Iteration 90200, lr = 0.0001
I1013 06:09:47.908905 11428 solver.cpp:218] Iteration 90300 (3.39005 iter/s, 29.4981s/100 iters), loss = 0.00457038
I1013 06:09:47.909031 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457148 (* 1 = 0.00457148 loss)
I1013 06:09:47.909040 11428 sgd_solver.cpp:105] Iteration 90300, lr = 0.0001
I1013 06:10:17.429210 11428 solver.cpp:218] Iteration 90400 (3.38751 iter/s, 29.5202s/100 iters), loss = 0.00387723
I1013 06:10:17.429244 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387833 (* 1 = 0.00387833 loss)
I1013 06:10:17.429251 11428 sgd_solver.cpp:105] Iteration 90400, lr = 0.0001
I1013 06:10:46.623328 11428 solver.cpp:330] Iteration 90500, Testing net (#0)
I1013 06:11:02.193420 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:11:02.511742 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10669 (* 1 = 1.10669 loss)
I1013 06:11:02.511759 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7402
I1013 06:11:02.801511 11428 solver.cpp:218] Iteration 90500 (2.20399 iter/s, 45.3723s/100 iters), loss = 0.00626148
I1013 06:11:02.801542 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00626258 (* 1 = 0.00626258 loss)
I1013 06:11:02.801549 11428 sgd_solver.cpp:105] Iteration 90500, lr = 0.0001
I1013 06:11:32.357040 11428 solver.cpp:218] Iteration 90600 (3.38346 iter/s, 29.5555s/100 iters), loss = 0.00249261
I1013 06:11:32.357192 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249371 (* 1 = 0.00249371 loss)
I1013 06:11:32.357201 11428 sgd_solver.cpp:105] Iteration 90600, lr = 0.0001
I1013 06:12:01.857511 11428 solver.cpp:218] Iteration 90700 (3.38979 iter/s, 29.5003s/100 iters), loss = 0.00483774
I1013 06:12:01.857544 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483884 (* 1 = 0.00483884 loss)
I1013 06:12:01.857553 11428 sgd_solver.cpp:105] Iteration 90700, lr = 0.0001
I1013 06:12:31.327888 11428 solver.cpp:218] Iteration 90800 (3.39324 iter/s, 29.4704s/100 iters), loss = 0.00731289
I1013 06:12:31.328033 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731399 (* 1 = 0.00731399 loss)
I1013 06:12:31.328042 11428 sgd_solver.cpp:105] Iteration 90800, lr = 0.0001
I1013 06:13:00.839499 11428 solver.cpp:218] Iteration 90900 (3.38851 iter/s, 29.5115s/100 iters), loss = 0.00185926
I1013 06:13:00.839531 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186036 (* 1 = 0.00186036 loss)
I1013 06:13:00.839540 11428 sgd_solver.cpp:105] Iteration 90900, lr = 0.0001
I1013 06:13:28.898449 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:13:30.077716 11428 solver.cpp:330] Iteration 91000, Testing net (#0)
I1013 06:13:45.607609 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:13:45.925422 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10651 (* 1 = 1.10651 loss)
I1013 06:13:45.925438 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7402
I1013 06:13:46.215423 11428 solver.cpp:218] Iteration 91000 (2.20381 iter/s, 45.3759s/100 iters), loss = 0.00257965
I1013 06:13:46.215459 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258075 (* 1 = 0.00258075 loss)
I1013 06:13:46.215467 11428 sgd_solver.cpp:105] Iteration 91000, lr = 0.0001
I1013 06:14:15.808651 11428 solver.cpp:218] Iteration 91100 (3.37915 iter/s, 29.5932s/100 iters), loss = 0.00479882
I1013 06:14:15.808751 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479991 (* 1 = 0.00479991 loss)
I1013 06:14:15.808759 11428 sgd_solver.cpp:105] Iteration 91100, lr = 0.0001
I1013 06:14:45.310319 11428 solver.cpp:218] Iteration 91200 (3.38965 iter/s, 29.5016s/100 iters), loss = 0.00536147
I1013 06:14:45.310353 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536256 (* 1 = 0.00536256 loss)
I1013 06:14:45.310360 11428 sgd_solver.cpp:105] Iteration 91200, lr = 0.0001
I1013 06:15:14.869971 11428 solver.cpp:218] Iteration 91300 (3.38299 iter/s, 29.5596s/100 iters), loss = 0.00743335
I1013 06:15:14.870084 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00743445 (* 1 = 0.00743445 loss)
I1013 06:15:14.870091 11428 sgd_solver.cpp:105] Iteration 91300, lr = 0.0001
I1013 06:15:44.419561 11428 solver.cpp:218] Iteration 91400 (3.38415 iter/s, 29.5495s/100 iters), loss = 0.00809873
I1013 06:15:44.419595 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00809983 (* 1 = 0.00809983 loss)
I1013 06:15:44.419603 11428 sgd_solver.cpp:105] Iteration 91400, lr = 0.0001
I1013 06:16:13.676363 11428 solver.cpp:330] Iteration 91500, Testing net (#0)
I1013 06:16:29.263036 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:16:29.582191 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10615 (* 1 = 1.10615 loss)
I1013 06:16:29.582207 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 06:16:29.872246 11428 solver.cpp:218] Iteration 91500 (2.20009 iter/s, 45.4527s/100 iters), loss = 0.00578203
I1013 06:16:29.872279 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00578312 (* 1 = 0.00578312 loss)
I1013 06:16:29.872287 11428 sgd_solver.cpp:105] Iteration 91500, lr = 0.0001
I1013 06:16:59.362666 11428 solver.cpp:218] Iteration 91600 (3.39093 iter/s, 29.4904s/100 iters), loss = 0.00251503
I1013 06:16:59.362819 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251613 (* 1 = 0.00251613 loss)
I1013 06:16:59.362828 11428 sgd_solver.cpp:105] Iteration 91600, lr = 0.0001
I1013 06:17:28.933020 11428 solver.cpp:218] Iteration 91700 (3.38178 iter/s, 29.5702s/100 iters), loss = 0.0046473
I1013 06:17:28.933053 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00464839 (* 1 = 0.00464839 loss)
I1013 06:17:28.933061 11428 sgd_solver.cpp:105] Iteration 91700, lr = 0.0001
I1013 06:17:58.441428 11428 solver.cpp:218] Iteration 91800 (3.38887 iter/s, 29.5084s/100 iters), loss = 0.00235174
I1013 06:17:58.441543 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235283 (* 1 = 0.00235283 loss)
I1013 06:17:58.441551 11428 sgd_solver.cpp:105] Iteration 91800, lr = 0.0001
I1013 06:18:27.949334 11428 solver.cpp:218] Iteration 91900 (3.38893 iter/s, 29.5078s/100 iters), loss = 0.0033216
I1013 06:18:27.949368 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332269 (* 1 = 0.00332269 loss)
I1013 06:18:27.949375 11428 sgd_solver.cpp:105] Iteration 91900, lr = 0.0001
I1013 06:18:55.994252 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:18:57.170238 11428 solver.cpp:330] Iteration 92000, Testing net (#0)
I1013 06:19:12.784560 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:19:13.106624 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10598 (* 1 = 1.10598 loss)
I1013 06:19:13.106642 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7407
I1013 06:19:13.397641 11428 solver.cpp:218] Iteration 92000 (2.2003 iter/s, 45.4483s/100 iters), loss = 0.00580896
I1013 06:19:13.397686 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581005 (* 1 = 0.00581005 loss)
I1013 06:19:13.397696 11428 sgd_solver.cpp:105] Iteration 92000, lr = 0.0001
I1013 06:19:42.900121 11428 solver.cpp:218] Iteration 92100 (3.38956 iter/s, 29.5024s/100 iters), loss = 0.0063797
I1013 06:19:42.900241 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00638079 (* 1 = 0.00638079 loss)
I1013 06:19:42.900249 11428 sgd_solver.cpp:105] Iteration 92100, lr = 0.0001
I1013 06:20:12.422257 11428 solver.cpp:218] Iteration 92200 (3.3873 iter/s, 29.522s/100 iters), loss = 0.0039862
I1013 06:20:12.422294 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398729 (* 1 = 0.00398729 loss)
I1013 06:20:12.422302 11428 sgd_solver.cpp:105] Iteration 92200, lr = 0.0001
I1013 06:20:41.904352 11428 solver.cpp:218] Iteration 92300 (3.39189 iter/s, 29.4821s/100 iters), loss = 0.00393338
I1013 06:20:41.904502 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393448 (* 1 = 0.00393448 loss)
I1013 06:20:41.904512 11428 sgd_solver.cpp:105] Iteration 92300, lr = 0.0001
I1013 06:21:11.413584 11428 solver.cpp:218] Iteration 92400 (3.38879 iter/s, 29.5091s/100 iters), loss = 0.00746734
I1013 06:21:11.413617 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00746843 (* 1 = 0.00746843 loss)
I1013 06:21:11.413625 11428 sgd_solver.cpp:105] Iteration 92400, lr = 0.0001
I1013 06:21:40.656816 11428 solver.cpp:330] Iteration 92500, Testing net (#0)
I1013 06:21:56.211719 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:21:56.530079 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10581 (* 1 = 1.10581 loss)
I1013 06:21:56.530095 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7403
I1013 06:21:56.818225 11428 solver.cpp:218] Iteration 92500 (2.20242 iter/s, 45.4046s/100 iters), loss = 0.00319885
I1013 06:21:56.818258 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319994 (* 1 = 0.00319994 loss)
I1013 06:21:56.818265 11428 sgd_solver.cpp:105] Iteration 92500, lr = 0.0001
I1013 06:22:26.336505 11428 solver.cpp:218] Iteration 92600 (3.38773 iter/s, 29.5183s/100 iters), loss = 0.00239731
I1013 06:22:26.336623 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023984 (* 1 = 0.0023984 loss)
I1013 06:22:26.336640 11428 sgd_solver.cpp:105] Iteration 92600, lr = 0.0001
I1013 06:22:55.855936 11428 solver.cpp:218] Iteration 92700 (3.38761 iter/s, 29.5193s/100 iters), loss = 0.00412761
I1013 06:22:55.855964 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041287 (* 1 = 0.0041287 loss)
I1013 06:22:55.855973 11428 sgd_solver.cpp:105] Iteration 92700, lr = 0.0001
I1013 06:23:25.367326 11428 solver.cpp:218] Iteration 92800 (3.38852 iter/s, 29.5114s/100 iters), loss = 0.00253386
I1013 06:23:25.367470 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253495 (* 1 = 0.00253495 loss)
I1013 06:23:25.367478 11428 sgd_solver.cpp:105] Iteration 92800, lr = 0.0001
I1013 06:23:54.817026 11428 solver.cpp:218] Iteration 92900 (3.39564 iter/s, 29.4496s/100 iters), loss = 0.00391171
I1013 06:23:54.817059 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039128 (* 1 = 0.0039128 loss)
I1013 06:23:54.817067 11428 sgd_solver.cpp:105] Iteration 92900, lr = 0.0001
I1013 06:24:22.837750 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:24:24.028556 11428 solver.cpp:330] Iteration 93000, Testing net (#0)
I1013 06:24:39.615427 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:24:39.935220 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10567 (* 1 = 1.10567 loss)
I1013 06:24:39.935235 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7408
I1013 06:24:40.223522 11428 solver.cpp:218] Iteration 93000 (2.20233 iter/s, 45.4065s/100 iters), loss = 0.00627855
I1013 06:24:40.223558 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00627965 (* 1 = 0.00627965 loss)
I1013 06:24:40.223565 11428 sgd_solver.cpp:105] Iteration 93000, lr = 0.0001
I1013 06:25:09.772703 11428 solver.cpp:218] Iteration 93100 (3.38419 iter/s, 29.5492s/100 iters), loss = 0.00386194
I1013 06:25:09.772850 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386303 (* 1 = 0.00386303 loss)
I1013 06:25:09.772861 11428 sgd_solver.cpp:105] Iteration 93100, lr = 0.0001
I1013 06:25:39.320116 11428 solver.cpp:218] Iteration 93200 (3.38441 iter/s, 29.5473s/100 iters), loss = 0.0035385
I1013 06:25:39.320148 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035396 (* 1 = 0.0035396 loss)
I1013 06:25:39.320156 11428 sgd_solver.cpp:105] Iteration 93200, lr = 0.0001
I1013 06:26:08.862555 11428 solver.cpp:218] Iteration 93300 (3.38496 iter/s, 29.5424s/100 iters), loss = 0.00537013
I1013 06:26:08.862697 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00537123 (* 1 = 0.00537123 loss)
I1013 06:26:08.862707 11428 sgd_solver.cpp:105] Iteration 93300, lr = 0.0001
I1013 06:26:38.353970 11428 solver.cpp:218] Iteration 93400 (3.39083 iter/s, 29.4913s/100 iters), loss = 0.00693663
I1013 06:26:38.354003 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693773 (* 1 = 0.00693773 loss)
I1013 06:26:38.354012 11428 sgd_solver.cpp:105] Iteration 93400, lr = 0.0001
I1013 06:27:07.617976 11428 solver.cpp:330] Iteration 93500, Testing net (#0)
I1013 06:27:23.270247 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:27:23.589488 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10516 (* 1 = 1.10516 loss)
I1013 06:27:23.589504 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 06:27:23.879549 11428 solver.cpp:218] Iteration 93500 (2.19657 iter/s, 45.5256s/100 iters), loss = 0.0061066
I1013 06:27:23.879583 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0061077 (* 1 = 0.0061077 loss)
I1013 06:27:23.879590 11428 sgd_solver.cpp:105] Iteration 93500, lr = 0.0001
I1013 06:27:53.361018 11428 solver.cpp:218] Iteration 93600 (3.39196 iter/s, 29.4814s/100 iters), loss = 0.00463685
I1013 06:27:53.361166 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463795 (* 1 = 0.00463795 loss)
I1013 06:27:53.361186 11428 sgd_solver.cpp:105] Iteration 93600, lr = 0.0001
I1013 06:28:22.895313 11428 solver.cpp:218] Iteration 93700 (3.38591 iter/s, 29.5342s/100 iters), loss = 0.00443846
I1013 06:28:22.895345 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443956 (* 1 = 0.00443956 loss)
I1013 06:28:22.895352 11428 sgd_solver.cpp:105] Iteration 93700, lr = 0.0001
I1013 06:28:52.412573 11428 solver.cpp:218] Iteration 93800 (3.38785 iter/s, 29.5172s/100 iters), loss = 0.0061424
I1013 06:28:52.412719 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0061435 (* 1 = 0.0061435 loss)
I1013 06:28:52.412729 11428 sgd_solver.cpp:105] Iteration 93800, lr = 0.0001
I1013 06:29:21.925087 11428 solver.cpp:218] Iteration 93900 (3.38841 iter/s, 29.5124s/100 iters), loss = 0.0030754
I1013 06:29:21.925119 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030765 (* 1 = 0.0030765 loss)
I1013 06:29:21.925127 11428 sgd_solver.cpp:105] Iteration 93900, lr = 0.0001
I1013 06:29:49.936055 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:29:51.116765 11428 solver.cpp:330] Iteration 94000, Testing net (#0)
I1013 06:30:06.703301 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:30:07.026558 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10508 (* 1 = 1.10508 loss)
I1013 06:30:07.026574 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 06:30:07.319355 11428 solver.cpp:218] Iteration 94000 (2.20292 iter/s, 45.3942s/100 iters), loss = 0.00232341
I1013 06:30:07.319393 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232451 (* 1 = 0.00232451 loss)
I1013 06:30:07.319401 11428 sgd_solver.cpp:105] Iteration 94000, lr = 0.0001
I1013 06:30:36.845037 11428 solver.cpp:218] Iteration 94100 (3.38689 iter/s, 29.5257s/100 iters), loss = 0.00513926
I1013 06:30:36.845110 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514035 (* 1 = 0.00514035 loss)
I1013 06:30:36.845120 11428 sgd_solver.cpp:105] Iteration 94100, lr = 0.0001
I1013 06:31:06.345958 11428 solver.cpp:218] Iteration 94200 (3.38973 iter/s, 29.5009s/100 iters), loss = 0.00775333
I1013 06:31:06.345989 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00775442 (* 1 = 0.00775442 loss)
I1013 06:31:06.345998 11428 sgd_solver.cpp:105] Iteration 94200, lr = 0.0001
I1013 06:31:35.860229 11428 solver.cpp:218] Iteration 94300 (3.38819 iter/s, 29.5142s/100 iters), loss = 0.00627979
I1013 06:31:35.860370 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628089 (* 1 = 0.00628089 loss)
I1013 06:31:35.860381 11428 sgd_solver.cpp:105] Iteration 94300, lr = 0.0001
I1013 06:32:05.358556 11428 solver.cpp:218] Iteration 94400 (3.39004 iter/s, 29.4982s/100 iters), loss = 0.00525854
I1013 06:32:05.358587 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00525964 (* 1 = 0.00525964 loss)
I1013 06:32:05.358595 11428 sgd_solver.cpp:105] Iteration 94400, lr = 0.0001
I1013 06:32:34.588932 11428 solver.cpp:330] Iteration 94500, Testing net (#0)
I1013 06:32:50.207396 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:32:50.526914 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10464 (* 1 = 1.10464 loss)
I1013 06:32:50.526932 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 06:32:50.817210 11428 solver.cpp:218] Iteration 94500 (2.1998 iter/s, 45.4586s/100 iters), loss = 0.00954478
I1013 06:32:50.817248 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00954588 (* 1 = 0.00954588 loss)
I1013 06:32:50.817256 11428 sgd_solver.cpp:105] Iteration 94500, lr = 0.0001
I1013 06:33:20.310948 11428 solver.cpp:218] Iteration 94600 (3.39055 iter/s, 29.4937s/100 iters), loss = 0.00418776
I1013 06:33:20.311062 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418886 (* 1 = 0.00418886 loss)
I1013 06:33:20.311069 11428 sgd_solver.cpp:105] Iteration 94600, lr = 0.0001
I1013 06:33:49.827227 11428 solver.cpp:218] Iteration 94700 (3.38797 iter/s, 29.5162s/100 iters), loss = 0.00504972
I1013 06:33:49.827260 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505082 (* 1 = 0.00505082 loss)
I1013 06:33:49.827267 11428 sgd_solver.cpp:105] Iteration 94700, lr = 0.0001
I1013 06:34:19.350201 11428 solver.cpp:218] Iteration 94800 (3.3872 iter/s, 29.5229s/100 iters), loss = 0.00531274
I1013 06:34:19.350345 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00531384 (* 1 = 0.00531384 loss)
I1013 06:34:19.350355 11428 sgd_solver.cpp:105] Iteration 94800, lr = 0.0001
I1013 06:34:48.846278 11428 solver.cpp:218] Iteration 94900 (3.3903 iter/s, 29.4959s/100 iters), loss = 0.0036136
I1013 06:34:48.846310 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036147 (* 1 = 0.0036147 loss)
I1013 06:34:48.846318 11428 sgd_solver.cpp:105] Iteration 94900, lr = 0.0001
I1013 06:35:16.905905 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:35:18.079058 11428 solver.cpp:330] Iteration 95000, Testing net (#0)
I1013 06:35:33.669347 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:35:33.988512 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10452 (* 1 = 1.10452 loss)
I1013 06:35:33.988528 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7408
I1013 06:35:34.279891 11428 solver.cpp:218] Iteration 95000 (2.20101 iter/s, 45.4336s/100 iters), loss = 0.00324841
I1013 06:35:34.279924 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324951 (* 1 = 0.00324951 loss)
I1013 06:35:34.279932 11428 sgd_solver.cpp:105] Iteration 95000, lr = 0.0001
I1013 06:36:03.864074 11428 solver.cpp:218] Iteration 95100 (3.38019 iter/s, 29.5842s/100 iters), loss = 0.00482749
I1013 06:36:03.864220 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482859 (* 1 = 0.00482859 loss)
I1013 06:36:03.864230 11428 sgd_solver.cpp:105] Iteration 95100, lr = 0.0001
I1013 06:36:33.377334 11428 solver.cpp:218] Iteration 95200 (3.38832 iter/s, 29.5131s/100 iters), loss = 0.0039033
I1013 06:36:33.377367 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039044 (* 1 = 0.0039044 loss)
I1013 06:36:33.377373 11428 sgd_solver.cpp:105] Iteration 95200, lr = 0.0001
I1013 06:37:02.920342 11428 solver.cpp:218] Iteration 95300 (3.3849 iter/s, 29.543s/100 iters), loss = 0.00364717
I1013 06:37:02.920486 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364827 (* 1 = 0.00364827 loss)
I1013 06:37:02.920495 11428 sgd_solver.cpp:105] Iteration 95300, lr = 0.0001
I1013 06:37:32.477740 11428 solver.cpp:218] Iteration 95400 (3.38326 iter/s, 29.5573s/100 iters), loss = 0.00461607
I1013 06:37:32.477776 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461717 (* 1 = 0.00461717 loss)
I1013 06:37:32.477782 11428 sgd_solver.cpp:105] Iteration 95400, lr = 0.0001
I1013 06:38:01.769170 11428 solver.cpp:330] Iteration 95500, Testing net (#0)
I1013 06:38:17.344578 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:38:17.664681 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10448 (* 1 = 1.10448 loss)
I1013 06:38:17.664697 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 06:38:17.954524 11428 solver.cpp:218] Iteration 95500 (2.19893 iter/s, 45.4768s/100 iters), loss = 0.00453341
I1013 06:38:17.954556 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453451 (* 1 = 0.00453451 loss)
I1013 06:38:17.954563 11428 sgd_solver.cpp:105] Iteration 95500, lr = 0.0001
I1013 06:38:47.448055 11428 solver.cpp:218] Iteration 95600 (3.39058 iter/s, 29.4935s/100 iters), loss = 0.00354413
I1013 06:38:47.448199 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354523 (* 1 = 0.00354523 loss)
I1013 06:38:47.448207 11428 sgd_solver.cpp:105] Iteration 95600, lr = 0.0001
I1013 06:39:16.957399 11428 solver.cpp:218] Iteration 95700 (3.38877 iter/s, 29.5092s/100 iters), loss = 0.0057053
I1013 06:39:16.957432 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057064 (* 1 = 0.0057064 loss)
I1013 06:39:16.957439 11428 sgd_solver.cpp:105] Iteration 95700, lr = 0.0001
I1013 06:39:46.513869 11428 solver.cpp:218] Iteration 95800 (3.38336 iter/s, 29.5564s/100 iters), loss = 0.00262475
I1013 06:39:46.514019 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262585 (* 1 = 0.00262585 loss)
I1013 06:39:46.514029 11428 sgd_solver.cpp:105] Iteration 95800, lr = 0.0001
I1013 06:40:16.070765 11428 solver.cpp:218] Iteration 95900 (3.38332 iter/s, 29.5568s/100 iters), loss = 0.00214362
I1013 06:40:16.070801 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214472 (* 1 = 0.00214472 loss)
I1013 06:40:16.070807 11428 sgd_solver.cpp:105] Iteration 95900, lr = 0.0001
I1013 06:40:44.172616 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:40:45.365799 11428 solver.cpp:330] Iteration 96000, Testing net (#0)
I1013 06:41:00.959494 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:41:01.277969 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10431 (* 1 = 1.10431 loss)
I1013 06:41:01.277987 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7407
I1013 06:41:01.568336 11428 solver.cpp:218] Iteration 96000 (2.19792 iter/s, 45.4976s/100 iters), loss = 0.00442417
I1013 06:41:01.568367 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442527 (* 1 = 0.00442527 loss)
I1013 06:41:01.568374 11428 sgd_solver.cpp:105] Iteration 96000, lr = 0.0001
I1013 06:41:31.108081 11428 solver.cpp:218] Iteration 96100 (3.38527 iter/s, 29.5397s/100 iters), loss = 0.0054209
I1013 06:41:31.108229 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542201 (* 1 = 0.00542201 loss)
I1013 06:41:31.108239 11428 sgd_solver.cpp:105] Iteration 96100, lr = 0.0001
I1013 06:42:00.653131 11428 solver.cpp:218] Iteration 96200 (3.38468 iter/s, 29.5449s/100 iters), loss = 0.00399786
I1013 06:42:00.653164 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399896 (* 1 = 0.00399896 loss)
I1013 06:42:00.653172 11428 sgd_solver.cpp:105] Iteration 96200, lr = 0.0001
I1013 06:42:30.123188 11428 solver.cpp:218] Iteration 96300 (3.39328 iter/s, 29.47s/100 iters), loss = 0.00611434
I1013 06:42:30.123298 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00611545 (* 1 = 0.00611545 loss)
I1013 06:42:30.123307 11428 sgd_solver.cpp:105] Iteration 96300, lr = 0.0001
I1013 06:42:59.632074 11428 solver.cpp:218] Iteration 96400 (3.38882 iter/s, 29.5088s/100 iters), loss = 0.0049966
I1013 06:42:59.632105 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499771 (* 1 = 0.00499771 loss)
I1013 06:42:59.632113 11428 sgd_solver.cpp:105] Iteration 96400, lr = 0.0001
I1013 06:43:28.868687 11428 solver.cpp:330] Iteration 96500, Testing net (#0)
I1013 06:43:44.485255 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:43:44.803994 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10416 (* 1 = 1.10416 loss)
I1013 06:43:44.804010 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7409
I1013 06:43:45.093122 11428 solver.cpp:218] Iteration 96500 (2.19969 iter/s, 45.461s/100 iters), loss = 0.00616829
I1013 06:43:45.093155 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616939 (* 1 = 0.00616939 loss)
I1013 06:43:45.093163 11428 sgd_solver.cpp:105] Iteration 96500, lr = 0.0001
I1013 06:44:14.587074 11428 solver.cpp:218] Iteration 96600 (3.39053 iter/s, 29.4939s/100 iters), loss = 0.00398072
I1013 06:44:14.587211 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398183 (* 1 = 0.00398183 loss)
I1013 06:44:14.587232 11428 sgd_solver.cpp:105] Iteration 96600, lr = 0.0001
I1013 06:44:44.092919 11428 solver.cpp:218] Iteration 96700 (3.38917 iter/s, 29.5057s/100 iters), loss = 0.00534835
I1013 06:44:44.092952 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00534945 (* 1 = 0.00534945 loss)
I1013 06:44:44.092960 11428 sgd_solver.cpp:105] Iteration 96700, lr = 0.0001
I1013 06:45:13.555634 11428 solver.cpp:218] Iteration 96800 (3.39412 iter/s, 29.4627s/100 iters), loss = 0.00430469
I1013 06:45:13.555773 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043058 (* 1 = 0.0043058 loss)
I1013 06:45:13.555781 11428 sgd_solver.cpp:105] Iteration 96800, lr = 0.0001
I1013 06:45:43.062073 11428 solver.cpp:218] Iteration 96900 (3.38911 iter/s, 29.5063s/100 iters), loss = 0.00149711
I1013 06:45:43.062106 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149821 (* 1 = 0.00149821 loss)
I1013 06:45:43.062114 11428 sgd_solver.cpp:105] Iteration 96900, lr = 0.0001
I1013 06:46:11.077100 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:46:12.255353 11428 solver.cpp:330] Iteration 97000, Testing net (#0)
I1013 06:46:27.837383 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:46:28.156863 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10402 (* 1 = 1.10402 loss)
I1013 06:46:28.156880 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7407
I1013 06:46:28.449076 11428 solver.cpp:218] Iteration 97000 (2.20327 iter/s, 45.387s/100 iters), loss = 0.00330665
I1013 06:46:28.449110 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330776 (* 1 = 0.00330776 loss)
I1013 06:46:28.449120 11428 sgd_solver.cpp:105] Iteration 97000, lr = 0.0001
I1013 06:46:57.978994 11428 solver.cpp:218] Iteration 97100 (3.3864 iter/s, 29.5299s/100 iters), loss = 0.00620716
I1013 06:46:57.979110 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00620826 (* 1 = 0.00620826 loss)
I1013 06:46:57.979118 11428 sgd_solver.cpp:105] Iteration 97100, lr = 0.0001
I1013 06:47:27.491184 11428 solver.cpp:218] Iteration 97200 (3.38844 iter/s, 29.5121s/100 iters), loss = 0.00564908
I1013 06:47:27.491220 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00565018 (* 1 = 0.00565018 loss)
I1013 06:47:27.491228 11428 sgd_solver.cpp:105] Iteration 97200, lr = 0.0001
I1013 06:47:57.006328 11428 solver.cpp:218] Iteration 97300 (3.38809 iter/s, 29.5151s/100 iters), loss = 0.00672687
I1013 06:47:57.006469 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00672797 (* 1 = 0.00672797 loss)
I1013 06:47:57.006477 11428 sgd_solver.cpp:105] Iteration 97300, lr = 0.0001
I1013 06:48:26.507472 11428 solver.cpp:218] Iteration 97400 (3.38971 iter/s, 29.501s/100 iters), loss = 0.00700785
I1013 06:48:26.507504 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700895 (* 1 = 0.00700895 loss)
I1013 06:48:26.507513 11428 sgd_solver.cpp:105] Iteration 97400, lr = 0.0001
I1013 06:48:55.738770 11428 solver.cpp:330] Iteration 97500, Testing net (#0)
I1013 06:49:11.315196 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:49:11.634196 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10384 (* 1 = 1.10384 loss)
I1013 06:49:11.634212 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7408
I1013 06:49:11.923362 11428 solver.cpp:218] Iteration 97500 (2.20187 iter/s, 45.4159s/100 iters), loss = 0.00487066
I1013 06:49:11.923396 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487176 (* 1 = 0.00487176 loss)
I1013 06:49:11.923403 11428 sgd_solver.cpp:105] Iteration 97500, lr = 0.0001
I1013 06:49:41.457414 11428 solver.cpp:218] Iteration 97600 (3.38593 iter/s, 29.534s/100 iters), loss = 0.00476042
I1013 06:49:41.457538 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476152 (* 1 = 0.00476152 loss)
I1013 06:49:41.457558 11428 sgd_solver.cpp:105] Iteration 97600, lr = 0.0001
I1013 06:50:10.948680 11428 solver.cpp:218] Iteration 97700 (3.39085 iter/s, 29.4912s/100 iters), loss = 0.00303196
I1013 06:50:10.948714 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303306 (* 1 = 0.00303306 loss)
I1013 06:50:10.948721 11428 sgd_solver.cpp:105] Iteration 97700, lr = 0.0001
I1013 06:50:40.469624 11428 solver.cpp:218] Iteration 97800 (3.38743 iter/s, 29.5209s/100 iters), loss = 0.002327
I1013 06:50:40.469763 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023281 (* 1 = 0.0023281 loss)
I1013 06:50:40.469772 11428 sgd_solver.cpp:105] Iteration 97800, lr = 0.0001
I1013 06:51:10.000669 11428 solver.cpp:218] Iteration 97900 (3.38628 iter/s, 29.5309s/100 iters), loss = 0.00218669
I1013 06:51:10.000701 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218779 (* 1 = 0.00218779 loss)
I1013 06:51:10.000710 11428 sgd_solver.cpp:105] Iteration 97900, lr = 0.0001
I1013 06:51:37.999780 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:51:39.191565 11428 solver.cpp:330] Iteration 98000, Testing net (#0)
I1013 06:51:54.796721 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:51:55.116600 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10368 (* 1 = 1.10368 loss)
I1013 06:51:55.116617 11428 solver.cpp:397]     Test net output #1: accuracy = 0.741
I1013 06:51:55.412616 11428 solver.cpp:218] Iteration 98000 (2.20206 iter/s, 45.4119s/100 iters), loss = 0.00241443
I1013 06:51:55.412652 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241553 (* 1 = 0.00241553 loss)
I1013 06:51:55.412658 11428 sgd_solver.cpp:105] Iteration 98000, lr = 0.0001
I1013 06:52:24.946889 11428 solver.cpp:218] Iteration 98100 (3.3859 iter/s, 29.5342s/100 iters), loss = 0.00525378
I1013 06:52:24.947048 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00525488 (* 1 = 0.00525488 loss)
I1013 06:52:24.947057 11428 sgd_solver.cpp:105] Iteration 98100, lr = 0.0001
I1013 06:52:54.460897 11428 solver.cpp:218] Iteration 98200 (3.38824 iter/s, 29.5139s/100 iters), loss = 0.0024607
I1013 06:52:54.460930 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0024618 (* 1 = 0.0024618 loss)
I1013 06:52:54.460938 11428 sgd_solver.cpp:105] Iteration 98200, lr = 0.0001
I1013 06:53:23.964290 11428 solver.cpp:218] Iteration 98300 (3.38944 iter/s, 29.5034s/100 iters), loss = 0.0053887
I1013 06:53:23.964393 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053898 (* 1 = 0.0053898 loss)
I1013 06:53:23.964412 11428 sgd_solver.cpp:105] Iteration 98300, lr = 0.0001
I1013 06:53:53.481043 11428 solver.cpp:218] Iteration 98400 (3.38792 iter/s, 29.5167s/100 iters), loss = 0.00405738
I1013 06:53:53.481076 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405848 (* 1 = 0.00405848 loss)
I1013 06:53:53.481084 11428 sgd_solver.cpp:105] Iteration 98400, lr = 0.0001
I1013 06:54:22.692265 11428 solver.cpp:330] Iteration 98500, Testing net (#0)
I1013 06:54:38.350394 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:54:38.670279 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10352 (* 1 = 1.10352 loss)
I1013 06:54:38.670295 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7409
I1013 06:54:38.961570 11428 solver.cpp:218] Iteration 98500 (2.19874 iter/s, 45.4805s/100 iters), loss = 0.0125538
I1013 06:54:38.961607 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125549 (* 1 = 0.0125549 loss)
I1013 06:54:38.961616 11428 sgd_solver.cpp:105] Iteration 98500, lr = 0.0001
I1013 06:55:08.499178 11428 solver.cpp:218] Iteration 98600 (3.38552 iter/s, 29.5376s/100 iters), loss = 0.00326399
I1013 06:55:08.499351 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326509 (* 1 = 0.00326509 loss)
I1013 06:55:08.499372 11428 sgd_solver.cpp:105] Iteration 98600, lr = 0.0001
I1013 06:55:37.998293 11428 solver.cpp:218] Iteration 98700 (3.38995 iter/s, 29.499s/100 iters), loss = 0.00373808
I1013 06:55:37.998327 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373919 (* 1 = 0.00373919 loss)
I1013 06:55:37.998334 11428 sgd_solver.cpp:105] Iteration 98700, lr = 0.0001
I1013 06:56:07.514237 11428 solver.cpp:218] Iteration 98800 (3.388 iter/s, 29.5159s/100 iters), loss = 0.00501671
I1013 06:56:07.514314 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00501781 (* 1 = 0.00501781 loss)
I1013 06:56:07.514333 11428 sgd_solver.cpp:105] Iteration 98800, lr = 0.0001
I1013 06:56:37.050477 11428 solver.cpp:218] Iteration 98900 (3.38568 iter/s, 29.5362s/100 iters), loss = 0.00173097
I1013 06:56:37.050509 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173207 (* 1 = 0.00173207 loss)
I1013 06:56:37.050518 11428 sgd_solver.cpp:105] Iteration 98900, lr = 0.0001
I1013 06:57:05.066645 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:57:06.245362 11428 solver.cpp:330] Iteration 99000, Testing net (#0)
I1013 06:57:21.881417 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 06:57:22.199546 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10346 (* 1 = 1.10346 loss)
I1013 06:57:22.199563 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7412
I1013 06:57:22.489886 11428 solver.cpp:218] Iteration 99000 (2.20073 iter/s, 45.4394s/100 iters), loss = 0.00290805
I1013 06:57:22.489923 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290916 (* 1 = 0.00290916 loss)
I1013 06:57:22.489930 11428 sgd_solver.cpp:105] Iteration 99000, lr = 0.0001
I1013 06:57:52.003072 11428 solver.cpp:218] Iteration 99100 (3.38832 iter/s, 29.5132s/100 iters), loss = 0.00417955
I1013 06:57:52.003213 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418066 (* 1 = 0.00418066 loss)
I1013 06:57:52.003222 11428 sgd_solver.cpp:105] Iteration 99100, lr = 0.0001
I1013 06:58:21.501638 11428 solver.cpp:218] Iteration 99200 (3.39001 iter/s, 29.4984s/100 iters), loss = 0.00557545
I1013 06:58:21.501675 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557656 (* 1 = 0.00557656 loss)
I1013 06:58:21.501683 11428 sgd_solver.cpp:105] Iteration 99200, lr = 0.0001
I1013 06:58:50.985133 11428 solver.cpp:218] Iteration 99300 (3.39173 iter/s, 29.4835s/100 iters), loss = 0.00644108
I1013 06:58:50.985255 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644219 (* 1 = 0.00644219 loss)
I1013 06:58:50.985265 11428 sgd_solver.cpp:105] Iteration 99300, lr = 0.0001
I1013 06:59:20.501384 11428 solver.cpp:218] Iteration 99400 (3.38798 iter/s, 29.5161s/100 iters), loss = 0.00459651
I1013 06:59:20.501416 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459761 (* 1 = 0.00459761 loss)
I1013 06:59:20.501425 11428 sgd_solver.cpp:105] Iteration 99400, lr = 0.0001
I1013 06:59:49.748924 11428 solver.cpp:330] Iteration 99500, Testing net (#0)
I1013 07:00:05.362009 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:00:05.680791 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1033 (* 1 = 1.1033 loss)
I1013 07:00:05.680807 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7407
I1013 07:00:05.972923 11428 solver.cpp:218] Iteration 99500 (2.19918 iter/s, 45.4715s/100 iters), loss = 0.00473466
I1013 07:00:05.972959 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473576 (* 1 = 0.00473576 loss)
I1013 07:00:05.972967 11428 sgd_solver.cpp:105] Iteration 99500, lr = 0.0001
I1013 07:00:35.470837 11428 solver.cpp:218] Iteration 99600 (3.39007 iter/s, 29.4979s/100 iters), loss = 0.00265279
I1013 07:00:35.470996 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265389 (* 1 = 0.00265389 loss)
I1013 07:00:35.471016 11428 sgd_solver.cpp:105] Iteration 99600, lr = 0.0001
I1013 07:01:05.018441 11428 solver.cpp:218] Iteration 99700 (3.38439 iter/s, 29.5475s/100 iters), loss = 0.00387605
I1013 07:01:05.018476 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387715 (* 1 = 0.00387715 loss)
I1013 07:01:05.018483 11428 sgd_solver.cpp:105] Iteration 99700, lr = 0.0001
I1013 07:01:34.557951 11428 solver.cpp:218] Iteration 99800 (3.3853 iter/s, 29.5395s/100 iters), loss = 0.00459673
I1013 07:01:34.558095 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459784 (* 1 = 0.00459784 loss)
I1013 07:01:34.558104 11428 sgd_solver.cpp:105] Iteration 99800, lr = 0.0001
I1013 07:02:04.063143 11428 solver.cpp:218] Iteration 99900 (3.38925 iter/s, 29.5051s/100 iters), loss = 0.00263779
I1013 07:02:04.063189 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026389 (* 1 = 0.0026389 loss)
I1013 07:02:04.063197 11428 sgd_solver.cpp:105] Iteration 99900, lr = 0.0001
I1013 07:02:32.143115 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:02:33.323236 11428 solver.cpp:330] Iteration 100000, Testing net (#0)
I1013 07:02:48.919188 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:02:49.238852 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10322 (* 1 = 1.10322 loss)
I1013 07:02:49.238868 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7411
I1013 07:02:49.528224 11428 solver.cpp:218] Iteration 100000 (2.19949 iter/s, 45.465s/100 iters), loss = 0.00439256
I1013 07:02:49.528254 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439367 (* 1 = 0.00439367 loss)
I1013 07:02:49.528262 11428 sgd_solver.cpp:105] Iteration 100000, lr = 0.0001
I1013 07:03:19.058881 11428 solver.cpp:218] Iteration 100100 (3.38631 iter/s, 29.5306s/100 iters), loss = 0.00474462
I1013 07:03:19.059026 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474572 (* 1 = 0.00474572 loss)
I1013 07:03:19.059046 11428 sgd_solver.cpp:105] Iteration 100100, lr = 0.0001
I1013 07:03:48.582248 11428 solver.cpp:218] Iteration 100200 (3.38716 iter/s, 29.5232s/100 iters), loss = 0.00704532
I1013 07:03:48.582283 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704642 (* 1 = 0.00704642 loss)
I1013 07:03:48.582290 11428 sgd_solver.cpp:105] Iteration 100200, lr = 0.0001
I1013 07:04:18.097797 11428 solver.cpp:218] Iteration 100300 (3.38805 iter/s, 29.5155s/100 iters), loss = 0.00925275
I1013 07:04:18.097951 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00925385 (* 1 = 0.00925385 loss)
I1013 07:04:18.097965 11428 sgd_solver.cpp:105] Iteration 100300, lr = 0.0001
I1013 07:04:47.628861 11428 solver.cpp:218] Iteration 100400 (3.38628 iter/s, 29.5309s/100 iters), loss = 0.00667464
I1013 07:04:47.628895 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667575 (* 1 = 0.00667575 loss)
I1013 07:04:47.628902 11428 sgd_solver.cpp:105] Iteration 100400, lr = 0.0001
I1013 07:05:16.858438 11428 solver.cpp:330] Iteration 100500, Testing net (#0)
I1013 07:05:32.474757 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:05:32.794104 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10316 (* 1 = 1.10316 loss)
I1013 07:05:32.794119 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7411
I1013 07:05:33.082267 11428 solver.cpp:218] Iteration 100500 (2.20006 iter/s, 45.4534s/100 iters), loss = 0.00447217
I1013 07:05:33.082300 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447327 (* 1 = 0.00447327 loss)
I1013 07:05:33.082307 11428 sgd_solver.cpp:105] Iteration 100500, lr = 0.0001
I1013 07:06:02.628356 11428 solver.cpp:218] Iteration 100600 (3.38455 iter/s, 29.5461s/100 iters), loss = 0.00335971
I1013 07:06:02.628525 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00336082 (* 1 = 0.00336082 loss)
I1013 07:06:02.628548 11428 sgd_solver.cpp:105] Iteration 100600, lr = 0.0001
I1013 07:06:32.126237 11428 solver.cpp:218] Iteration 100700 (3.39009 iter/s, 29.4977s/100 iters), loss = 0.00380142
I1013 07:06:32.126271 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380252 (* 1 = 0.00380252 loss)
I1013 07:06:32.126277 11428 sgd_solver.cpp:105] Iteration 100700, lr = 0.0001
I1013 07:07:01.657655 11428 solver.cpp:218] Iteration 100800 (3.38623 iter/s, 29.5314s/100 iters), loss = 0.00364332
I1013 07:07:01.657768 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364442 (* 1 = 0.00364442 loss)
I1013 07:07:01.657776 11428 sgd_solver.cpp:105] Iteration 100800, lr = 0.0001
I1013 07:07:31.206969 11428 solver.cpp:218] Iteration 100900 (3.38418 iter/s, 29.5492s/100 iters), loss = 0.004768
I1013 07:07:31.207001 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047691 (* 1 = 0.0047691 loss)
I1013 07:07:31.207008 11428 sgd_solver.cpp:105] Iteration 100900, lr = 0.0001
I1013 07:07:59.260542 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:08:00.450263 11428 solver.cpp:330] Iteration 101000, Testing net (#0)
I1013 07:08:16.003690 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:08:16.324766 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10314 (* 1 = 1.10314 loss)
I1013 07:08:16.324782 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 07:08:16.616982 11428 solver.cpp:218] Iteration 101000 (2.20216 iter/s, 45.41s/100 iters), loss = 0.00570914
I1013 07:08:16.617043 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571024 (* 1 = 0.00571024 loss)
I1013 07:08:16.617050 11428 sgd_solver.cpp:105] Iteration 101000, lr = 0.0001
I1013 07:08:46.155529 11428 solver.cpp:218] Iteration 101100 (3.38542 iter/s, 29.5384s/100 iters), loss = 0.00424393
I1013 07:08:46.155675 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424503 (* 1 = 0.00424503 loss)
I1013 07:08:46.155685 11428 sgd_solver.cpp:105] Iteration 101100, lr = 0.0001
I1013 07:09:15.634096 11428 solver.cpp:218] Iteration 101200 (3.39231 iter/s, 29.4784s/100 iters), loss = 0.00377608
I1013 07:09:15.634129 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377718 (* 1 = 0.00377718 loss)
I1013 07:09:15.634135 11428 sgd_solver.cpp:105] Iteration 101200, lr = 0.0001
I1013 07:09:45.149556 11428 solver.cpp:218] Iteration 101300 (3.38806 iter/s, 29.5154s/100 iters), loss = 0.00469144
I1013 07:09:45.149708 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469254 (* 1 = 0.00469254 loss)
I1013 07:09:45.149718 11428 sgd_solver.cpp:105] Iteration 101300, lr = 0.0001
I1013 07:10:14.652649 11428 solver.cpp:218] Iteration 101400 (3.38949 iter/s, 29.503s/100 iters), loss = 0.00924043
I1013 07:10:14.652681 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00924154 (* 1 = 0.00924154 loss)
I1013 07:10:14.652689 11428 sgd_solver.cpp:105] Iteration 101400, lr = 0.0001
I1013 07:10:43.864547 11428 solver.cpp:330] Iteration 101500, Testing net (#0)
I1013 07:10:59.495647 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:10:59.814481 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10299 (* 1 = 1.10299 loss)
I1013 07:10:59.814497 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7409
I1013 07:11:00.104887 11428 solver.cpp:218] Iteration 101500 (2.20011 iter/s, 45.4522s/100 iters), loss = 0.0110115
I1013 07:11:00.104921 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110126 (* 1 = 0.0110126 loss)
I1013 07:11:00.104929 11428 sgd_solver.cpp:105] Iteration 101500, lr = 0.0001
I1013 07:11:29.604584 11428 solver.cpp:218] Iteration 101600 (3.38987 iter/s, 29.4997s/100 iters), loss = 0.00482433
I1013 07:11:29.604696 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482543 (* 1 = 0.00482543 loss)
I1013 07:11:29.604704 11428 sgd_solver.cpp:105] Iteration 101600, lr = 0.0001
I1013 07:11:59.137814 11428 solver.cpp:218] Iteration 101700 (3.38603 iter/s, 29.5331s/100 iters), loss = 0.00474294
I1013 07:11:59.137845 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474404 (* 1 = 0.00474404 loss)
I1013 07:11:59.137853 11428 sgd_solver.cpp:105] Iteration 101700, lr = 0.0001
I1013 07:12:28.623158 11428 solver.cpp:218] Iteration 101800 (3.39152 iter/s, 29.4853s/100 iters), loss = 0.00370891
I1013 07:12:28.623307 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371001 (* 1 = 0.00371001 loss)
I1013 07:12:28.623327 11428 sgd_solver.cpp:105] Iteration 101800, lr = 0.0001
I1013 07:12:58.140210 11428 solver.cpp:218] Iteration 101900 (3.38789 iter/s, 29.5169s/100 iters), loss = 0.00255613
I1013 07:12:58.140242 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255723 (* 1 = 0.00255723 loss)
I1013 07:12:58.140250 11428 sgd_solver.cpp:105] Iteration 101900, lr = 0.0001
I1013 07:13:26.217702 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:13:27.397670 11428 solver.cpp:330] Iteration 102000, Testing net (#0)
I1013 07:13:43.013912 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:13:43.332343 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10292 (* 1 = 1.10292 loss)
I1013 07:13:43.332360 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7407
I1013 07:13:43.622360 11428 solver.cpp:218] Iteration 102000 (2.19867 iter/s, 45.4821s/100 iters), loss = 0.00637357
I1013 07:13:43.622395 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00637467 (* 1 = 0.00637467 loss)
I1013 07:13:43.622402 11428 sgd_solver.cpp:105] Iteration 102000, lr = 0.0001
I1013 07:14:13.118458 11428 solver.cpp:218] Iteration 102100 (3.39028 iter/s, 29.4961s/100 iters), loss = 0.00449039
I1013 07:14:13.118607 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449149 (* 1 = 0.00449149 loss)
I1013 07:14:13.118616 11428 sgd_solver.cpp:105] Iteration 102100, lr = 0.0001
I1013 07:14:42.618543 11428 solver.cpp:218] Iteration 102200 (3.38984 iter/s, 29.4999s/100 iters), loss = 0.00469436
I1013 07:14:42.618577 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469546 (* 1 = 0.00469546 loss)
I1013 07:14:42.618587 11428 sgd_solver.cpp:105] Iteration 102200, lr = 0.0001
I1013 07:15:12.152248 11428 solver.cpp:218] Iteration 102300 (3.38596 iter/s, 29.5337s/100 iters), loss = 0.00395523
I1013 07:15:12.152416 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395633 (* 1 = 0.00395633 loss)
I1013 07:15:12.152426 11428 sgd_solver.cpp:105] Iteration 102300, lr = 0.0001
I1013 07:15:41.709487 11428 solver.cpp:218] Iteration 102400 (3.38328 iter/s, 29.5571s/100 iters), loss = 0.00508372
I1013 07:15:41.709519 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508482 (* 1 = 0.00508482 loss)
I1013 07:15:41.709527 11428 sgd_solver.cpp:105] Iteration 102400, lr = 0.0001
I1013 07:16:10.944946 11428 solver.cpp:330] Iteration 102500, Testing net (#0)
I1013 07:16:26.599647 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:16:26.918365 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10279 (* 1 = 1.10279 loss)
I1013 07:16:26.918380 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7403
I1013 07:16:27.208698 11428 solver.cpp:218] Iteration 102500 (2.19784 iter/s, 45.4992s/100 iters), loss = 0.00559533
I1013 07:16:27.208729 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559642 (* 1 = 0.00559642 loss)
I1013 07:16:27.208736 11428 sgd_solver.cpp:105] Iteration 102500, lr = 0.0001
I1013 07:16:56.706702 11428 solver.cpp:218] Iteration 102600 (3.39006 iter/s, 29.498s/100 iters), loss = 0.00504327
I1013 07:16:56.706814 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00504437 (* 1 = 0.00504437 loss)
I1013 07:16:56.706831 11428 sgd_solver.cpp:105] Iteration 102600, lr = 0.0001
I1013 07:17:26.204581 11428 solver.cpp:218] Iteration 102700 (3.39008 iter/s, 29.4978s/100 iters), loss = 0.00410877
I1013 07:17:26.204612 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410987 (* 1 = 0.00410987 loss)
I1013 07:17:26.204630 11428 sgd_solver.cpp:105] Iteration 102700, lr = 0.0001
I1013 07:17:55.679240 11428 solver.cpp:218] Iteration 102800 (3.39275 iter/s, 29.4746s/100 iters), loss = 0.00334386
I1013 07:17:55.679379 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334495 (* 1 = 0.00334495 loss)
I1013 07:17:55.679401 11428 sgd_solver.cpp:105] Iteration 102800, lr = 0.0001
I1013 07:18:25.116865 11428 solver.cpp:218] Iteration 102900 (3.39703 iter/s, 29.4375s/100 iters), loss = 0.00172098
I1013 07:18:25.116899 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172208 (* 1 = 0.00172208 loss)
I1013 07:18:25.116906 11428 sgd_solver.cpp:105] Iteration 102900, lr = 0.0001
I1013 07:18:53.114603 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:18:54.300478 11428 solver.cpp:330] Iteration 103000, Testing net (#0)
I1013 07:19:09.907874 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:19:10.229666 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10271 (* 1 = 1.10271 loss)
I1013 07:19:10.229682 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 07:19:10.523082 11428 solver.cpp:218] Iteration 103000 (2.20234 iter/s, 45.4062s/100 iters), loss = 0.00256563
I1013 07:19:10.523119 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256673 (* 1 = 0.00256673 loss)
I1013 07:19:10.523128 11428 sgd_solver.cpp:105] Iteration 103000, lr = 0.0001
I1013 07:19:39.984333 11428 solver.cpp:218] Iteration 103100 (3.39429 iter/s, 29.4612s/100 iters), loss = 0.00575616
I1013 07:19:39.984436 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575726 (* 1 = 0.00575726 loss)
I1013 07:19:39.984443 11428 sgd_solver.cpp:105] Iteration 103100, lr = 0.0001
I1013 07:20:09.445245 11428 solver.cpp:218] Iteration 103200 (3.39434 iter/s, 29.4608s/100 iters), loss = 0.00836774
I1013 07:20:09.445278 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00836884 (* 1 = 0.00836884 loss)
I1013 07:20:09.445286 11428 sgd_solver.cpp:105] Iteration 103200, lr = 0.0001
I1013 07:20:38.906621 11428 solver.cpp:218] Iteration 103300 (3.39428 iter/s, 29.4613s/100 iters), loss = 0.00428365
I1013 07:20:38.906702 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428474 (* 1 = 0.00428474 loss)
I1013 07:20:38.906710 11428 sgd_solver.cpp:105] Iteration 103300, lr = 0.0001
I1013 07:21:08.367730 11428 solver.cpp:218] Iteration 103400 (3.39431 iter/s, 29.461s/100 iters), loss = 0.00412833
I1013 07:21:08.367763 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412943 (* 1 = 0.00412943 loss)
I1013 07:21:08.367771 11428 sgd_solver.cpp:105] Iteration 103400, lr = 0.0001
I1013 07:21:37.473702 11428 solver.cpp:330] Iteration 103500, Testing net (#0)
I1013 07:21:53.056242 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:21:53.375263 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10261 (* 1 = 1.10261 loss)
I1013 07:21:53.375280 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7403
I1013 07:21:53.666684 11428 solver.cpp:218] Iteration 103500 (2.20756 iter/s, 45.2989s/100 iters), loss = 0.00637211
I1013 07:21:53.666719 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063732 (* 1 = 0.0063732 loss)
I1013 07:21:53.666728 11428 sgd_solver.cpp:105] Iteration 103500, lr = 0.0001
I1013 07:22:23.090095 11428 solver.cpp:218] Iteration 103600 (3.39866 iter/s, 29.4234s/100 iters), loss = 0.00340685
I1013 07:22:23.090167 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340795 (* 1 = 0.00340795 loss)
I1013 07:22:23.090185 11428 sgd_solver.cpp:105] Iteration 103600, lr = 0.0001
I1013 07:22:52.547576 11428 solver.cpp:218] Iteration 103700 (3.39473 iter/s, 29.4574s/100 iters), loss = 0.00543724
I1013 07:22:52.547611 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543834 (* 1 = 0.00543834 loss)
I1013 07:22:52.547619 11428 sgd_solver.cpp:105] Iteration 103700, lr = 0.0001
I1013 07:23:21.987483 11428 solver.cpp:218] Iteration 103800 (3.39675 iter/s, 29.4399s/100 iters), loss = 0.00381817
I1013 07:23:21.987669 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381927 (* 1 = 0.00381927 loss)
I1013 07:23:21.987679 11428 sgd_solver.cpp:105] Iteration 103800, lr = 0.0001
I1013 07:23:51.464607 11428 solver.cpp:218] Iteration 103900 (3.39248 iter/s, 29.477s/100 iters), loss = 0.00446749
I1013 07:23:51.464638 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446859 (* 1 = 0.00446859 loss)
I1013 07:23:51.464645 11428 sgd_solver.cpp:105] Iteration 103900, lr = 0.0001
I1013 07:24:19.447309 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:24:20.624975 11428 solver.cpp:330] Iteration 104000, Testing net (#0)
I1013 07:24:36.138479 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:24:36.455684 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10241 (* 1 = 1.10241 loss)
I1013 07:24:36.455699 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7401
I1013 07:24:36.745206 11428 solver.cpp:218] Iteration 104000 (2.20845 iter/s, 45.2806s/100 iters), loss = 0.00768641
I1013 07:24:36.745239 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00768751 (* 1 = 0.00768751 loss)
I1013 07:24:36.745249 11428 sgd_solver.cpp:105] Iteration 104000, lr = 0.0001
I1013 07:25:06.281385 11428 solver.cpp:218] Iteration 104100 (3.38568 iter/s, 29.5362s/100 iters), loss = 0.00554218
I1013 07:25:06.281487 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554328 (* 1 = 0.00554328 loss)
I1013 07:25:06.281496 11428 sgd_solver.cpp:105] Iteration 104100, lr = 0.0001
I1013 07:25:35.726441 11428 solver.cpp:218] Iteration 104200 (3.39617 iter/s, 29.445s/100 iters), loss = 0.00599287
I1013 07:25:35.726474 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599397 (* 1 = 0.00599397 loss)
I1013 07:25:35.726480 11428 sgd_solver.cpp:105] Iteration 104200, lr = 0.0001
I1013 07:26:05.157346 11428 solver.cpp:218] Iteration 104300 (3.39779 iter/s, 29.4309s/100 iters), loss = 0.00510092
I1013 07:26:05.157455 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510202 (* 1 = 0.00510202 loss)
I1013 07:26:05.157464 11428 sgd_solver.cpp:105] Iteration 104300, lr = 0.0001
I1013 07:26:34.649554 11428 solver.cpp:218] Iteration 104400 (3.39074 iter/s, 29.4921s/100 iters), loss = 0.00545388
I1013 07:26:34.649588 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545497 (* 1 = 0.00545497 loss)
I1013 07:26:34.649596 11428 sgd_solver.cpp:105] Iteration 104400, lr = 0.0001
I1013 07:27:03.767326 11428 solver.cpp:330] Iteration 104500, Testing net (#0)
I1013 07:27:19.305193 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:27:19.621632 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10211 (* 1 = 1.10211 loss)
I1013 07:27:19.621649 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7402
I1013 07:27:19.911892 11428 solver.cpp:218] Iteration 104500 (2.20934 iter/s, 45.2623s/100 iters), loss = 0.00627077
I1013 07:27:19.911926 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00627187 (* 1 = 0.00627187 loss)
I1013 07:27:19.911933 11428 sgd_solver.cpp:105] Iteration 104500, lr = 0.0001
I1013 07:27:49.371147 11428 solver.cpp:218] Iteration 104600 (3.39452 iter/s, 29.4592s/100 iters), loss = 0.00283643
I1013 07:27:49.371258 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283752 (* 1 = 0.00283752 loss)
I1013 07:27:49.371275 11428 sgd_solver.cpp:105] Iteration 104600, lr = 0.0001
I1013 07:28:18.837044 11428 solver.cpp:218] Iteration 104700 (3.39376 iter/s, 29.4658s/100 iters), loss = 0.00397704
I1013 07:28:18.837075 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397814 (* 1 = 0.00397814 loss)
I1013 07:28:18.837083 11428 sgd_solver.cpp:105] Iteration 104700, lr = 0.0001
I1013 07:28:48.280315 11428 solver.cpp:218] Iteration 104800 (3.39636 iter/s, 29.4432s/100 iters), loss = 0.00552772
I1013 07:28:48.280480 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552881 (* 1 = 0.00552881 loss)
I1013 07:28:48.280493 11428 sgd_solver.cpp:105] Iteration 104800, lr = 0.0001
I1013 07:29:17.688571 11428 solver.cpp:218] Iteration 104900 (3.40042 iter/s, 29.4081s/100 iters), loss = 0.00168635
I1013 07:29:17.688606 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168744 (* 1 = 0.00168744 loss)
I1013 07:29:17.688614 11428 sgd_solver.cpp:105] Iteration 104900, lr = 0.0001
I1013 07:29:45.668285 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:29:46.847076 11428 solver.cpp:330] Iteration 105000, Testing net (#0)
I1013 07:30:02.404968 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:30:02.723886 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10199 (* 1 = 1.10199 loss)
I1013 07:30:02.723903 11428 solver.cpp:397]     Test net output #1: accuracy = 0.74
I1013 07:30:03.013247 11428 solver.cpp:218] Iteration 105000 (2.2063 iter/s, 45.3247s/100 iters), loss = 0.00422091
I1013 07:30:03.013281 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004222 (* 1 = 0.004222 loss)
I1013 07:30:03.013289 11428 sgd_solver.cpp:105] Iteration 105000, lr = 0.0001
I1013 07:30:32.403594 11428 solver.cpp:218] Iteration 105100 (3.40248 iter/s, 29.3903s/100 iters), loss = 0.00860162
I1013 07:30:32.403728 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00860271 (* 1 = 0.00860271 loss)
I1013 07:30:32.403748 11428 sgd_solver.cpp:105] Iteration 105100, lr = 0.0001
I1013 07:31:01.803297 11428 solver.cpp:218] Iteration 105200 (3.40141 iter/s, 29.3996s/100 iters), loss = 0.00426519
I1013 07:31:01.803331 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426628 (* 1 = 0.00426628 loss)
I1013 07:31:01.803339 11428 sgd_solver.cpp:105] Iteration 105200, lr = 0.0001
I1013 07:31:31.215220 11428 solver.cpp:218] Iteration 105300 (3.39999 iter/s, 29.4119s/100 iters), loss = 0.00284998
I1013 07:31:31.215323 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285107 (* 1 = 0.00285107 loss)
I1013 07:31:31.215343 11428 sgd_solver.cpp:105] Iteration 105300, lr = 0.0001
I1013 07:32:00.579272 11428 solver.cpp:218] Iteration 105400 (3.40554 iter/s, 29.364s/100 iters), loss = 0.00650355
I1013 07:32:00.579304 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650464 (* 1 = 0.00650464 loss)
I1013 07:32:00.579311 11428 sgd_solver.cpp:105] Iteration 105400, lr = 0.0001
I1013 07:32:29.683923 11428 solver.cpp:330] Iteration 105500, Testing net (#0)
I1013 07:32:45.195468 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:32:45.515542 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10189 (* 1 = 1.10189 loss)
I1013 07:32:45.515559 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 07:32:45.803797 11428 solver.cpp:218] Iteration 105500 (2.21119 iter/s, 45.2245s/100 iters), loss = 0.00605165
I1013 07:32:45.803833 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00605275 (* 1 = 0.00605275 loss)
I1013 07:32:45.803840 11428 sgd_solver.cpp:105] Iteration 105500, lr = 0.0001
I1013 07:33:15.230415 11428 solver.cpp:218] Iteration 105600 (3.39829 iter/s, 29.4266s/100 iters), loss = 0.00269576
I1013 07:33:15.230528 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00269686 (* 1 = 0.00269686 loss)
I1013 07:33:15.230546 11428 sgd_solver.cpp:105] Iteration 105600, lr = 0.0001
I1013 07:33:44.546116 11428 solver.cpp:218] Iteration 105700 (3.41115 iter/s, 29.3156s/100 iters), loss = 0.00497652
I1013 07:33:44.546149 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497762 (* 1 = 0.00497762 loss)
I1013 07:33:44.546156 11428 sgd_solver.cpp:105] Iteration 105700, lr = 0.0001
I1013 07:34:13.877393 11428 solver.cpp:218] Iteration 105800 (3.40933 iter/s, 29.3312s/100 iters), loss = 0.00310904
I1013 07:34:13.877528 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311013 (* 1 = 0.00311013 loss)
I1013 07:34:13.877537 11428 sgd_solver.cpp:105] Iteration 105800, lr = 0.0001
I1013 07:34:43.221053 11428 solver.cpp:218] Iteration 105900 (3.40791 iter/s, 29.3435s/100 iters), loss = 0.00358945
I1013 07:34:43.221086 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359055 (* 1 = 0.00359055 loss)
I1013 07:34:43.221094 11428 sgd_solver.cpp:105] Iteration 105900, lr = 0.0001
I1013 07:35:11.166074 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:35:12.336093 11428 solver.cpp:330] Iteration 106000, Testing net (#0)
I1013 07:35:27.830152 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:35:28.150072 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10169 (* 1 = 1.10169 loss)
I1013 07:35:28.150089 11428 solver.cpp:397]     Test net output #1: accuracy = 0.741
I1013 07:35:28.439730 11428 solver.cpp:218] Iteration 106000 (2.21148 iter/s, 45.2187s/100 iters), loss = 0.00447406
I1013 07:35:28.439762 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447515 (* 1 = 0.00447515 loss)
I1013 07:35:28.439770 11428 sgd_solver.cpp:105] Iteration 106000, lr = 0.0001
I1013 07:35:57.759929 11428 solver.cpp:218] Iteration 106100 (3.41062 iter/s, 29.3202s/100 iters), loss = 0.00457024
I1013 07:35:57.760038 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457133 (* 1 = 0.00457133 loss)
I1013 07:35:57.760047 11428 sgd_solver.cpp:105] Iteration 106100, lr = 0.0001
I1013 07:36:27.123301 11428 solver.cpp:218] Iteration 106200 (3.40562 iter/s, 29.3633s/100 iters), loss = 0.00377056
I1013 07:36:27.123332 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377166 (* 1 = 0.00377166 loss)
I1013 07:36:27.123340 11428 sgd_solver.cpp:105] Iteration 106200, lr = 0.0001
I1013 07:36:56.468839 11428 solver.cpp:218] Iteration 106300 (3.40768 iter/s, 29.3455s/100 iters), loss = 0.00292896
I1013 07:36:56.468962 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293006 (* 1 = 0.00293006 loss)
I1013 07:36:56.468971 11428 sgd_solver.cpp:105] Iteration 106300, lr = 0.0001
I1013 07:37:25.804430 11428 solver.cpp:218] Iteration 106400 (3.40884 iter/s, 29.3355s/100 iters), loss = 0.00539309
I1013 07:37:25.804466 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539419 (* 1 = 0.00539419 loss)
I1013 07:37:25.804474 11428 sgd_solver.cpp:105] Iteration 106400, lr = 0.0001
I1013 07:37:54.863133 11428 solver.cpp:330] Iteration 106500, Testing net (#0)
I1013 07:38:10.332909 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:38:10.649940 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10149 (* 1 = 1.10149 loss)
I1013 07:38:10.649955 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 07:38:10.935762 11428 solver.cpp:218] Iteration 106500 (2.21576 iter/s, 45.1313s/100 iters), loss = 0.0136909
I1013 07:38:10.935809 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013692 (* 1 = 0.013692 loss)
I1013 07:38:10.935817 11428 sgd_solver.cpp:105] Iteration 106500, lr = 0.0001
I1013 07:38:40.230115 11428 solver.cpp:218] Iteration 106600 (3.41363 iter/s, 29.2943s/100 iters), loss = 0.00387999
I1013 07:38:40.230257 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388107 (* 1 = 0.00388107 loss)
I1013 07:38:40.230268 11428 sgd_solver.cpp:105] Iteration 106600, lr = 0.0001
I1013 07:39:09.517202 11428 solver.cpp:218] Iteration 106700 (3.41449 iter/s, 29.287s/100 iters), loss = 0.00538714
I1013 07:39:09.517235 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538823 (* 1 = 0.00538823 loss)
I1013 07:39:09.517243 11428 sgd_solver.cpp:105] Iteration 106700, lr = 0.0001
I1013 07:39:38.843039 11428 solver.cpp:218] Iteration 106800 (3.40997 iter/s, 29.3258s/100 iters), loss = 0.00394554
I1013 07:39:38.843194 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394663 (* 1 = 0.00394663 loss)
I1013 07:39:38.843205 11428 sgd_solver.cpp:105] Iteration 106800, lr = 0.0001
I1013 07:40:08.153416 11428 solver.cpp:218] Iteration 106900 (3.41178 iter/s, 29.3102s/100 iters), loss = 0.00205848
I1013 07:40:08.153450 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205957 (* 1 = 0.00205957 loss)
I1013 07:40:08.153457 11428 sgd_solver.cpp:105] Iteration 106900, lr = 0.0001
I1013 07:40:35.985443 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:40:37.150293 11428 solver.cpp:330] Iteration 107000, Testing net (#0)
I1013 07:40:52.634871 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:40:52.952313 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1014 (* 1 = 1.1014 loss)
I1013 07:40:52.952330 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 07:40:53.240384 11428 solver.cpp:218] Iteration 107000 (2.21794 iter/s, 45.0869s/100 iters), loss = 0.00540123
I1013 07:40:53.240414 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540232 (* 1 = 0.00540232 loss)
I1013 07:40:53.240422 11428 sgd_solver.cpp:105] Iteration 107000, lr = 0.0001
I1013 07:41:22.645249 11428 solver.cpp:218] Iteration 107100 (3.4008 iter/s, 29.4048s/100 iters), loss = 0.00568136
I1013 07:41:22.645396 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568245 (* 1 = 0.00568245 loss)
I1013 07:41:22.645406 11428 sgd_solver.cpp:105] Iteration 107100, lr = 0.0001
I1013 07:41:52.013234 11428 solver.cpp:218] Iteration 107200 (3.40508 iter/s, 29.3678s/100 iters), loss = 0.00418764
I1013 07:41:52.013267 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418873 (* 1 = 0.00418873 loss)
I1013 07:41:52.013276 11428 sgd_solver.cpp:105] Iteration 107200, lr = 0.0001
I1013 07:42:21.359243 11428 solver.cpp:218] Iteration 107300 (3.40762 iter/s, 29.346s/100 iters), loss = 0.00497743
I1013 07:42:21.359381 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497852 (* 1 = 0.00497852 loss)
I1013 07:42:21.359390 11428 sgd_solver.cpp:105] Iteration 107300, lr = 0.0001
I1013 07:42:50.686933 11428 solver.cpp:218] Iteration 107400 (3.40976 iter/s, 29.3276s/100 iters), loss = 0.00325374
I1013 07:42:50.686965 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325483 (* 1 = 0.00325483 loss)
I1013 07:42:50.686972 11428 sgd_solver.cpp:105] Iteration 107400, lr = 0.0001
I1013 07:43:19.780335 11428 solver.cpp:330] Iteration 107500, Testing net (#0)
I1013 07:43:35.305209 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:43:35.621774 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10124 (* 1 = 1.10124 loss)
I1013 07:43:35.621791 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7402
I1013 07:43:35.908227 11428 solver.cpp:218] Iteration 107500 (2.21135 iter/s, 45.2213s/100 iters), loss = 0.00521567
I1013 07:43:35.908264 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521676 (* 1 = 0.00521676 loss)
I1013 07:43:35.908272 11428 sgd_solver.cpp:105] Iteration 107500, lr = 0.0001
I1013 07:44:05.269207 11428 solver.cpp:218] Iteration 107600 (3.40588 iter/s, 29.3609s/100 iters), loss = 0.00255864
I1013 07:44:05.269347 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255973 (* 1 = 0.00255973 loss)
I1013 07:44:05.269357 11428 sgd_solver.cpp:105] Iteration 107600, lr = 0.0001
I1013 07:44:34.627316 11428 solver.cpp:218] Iteration 107700 (3.40623 iter/s, 29.358s/100 iters), loss = 0.00317612
I1013 07:44:34.627348 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317722 (* 1 = 0.00317722 loss)
I1013 07:44:34.627355 11428 sgd_solver.cpp:105] Iteration 107700, lr = 0.0001
I1013 07:45:04.007040 11428 solver.cpp:218] Iteration 107800 (3.40371 iter/s, 29.3797s/100 iters), loss = 0.00231362
I1013 07:45:04.007203 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231471 (* 1 = 0.00231471 loss)
I1013 07:45:04.007213 11428 sgd_solver.cpp:105] Iteration 107800, lr = 0.0001
I1013 07:45:33.391512 11428 solver.cpp:218] Iteration 107900 (3.40318 iter/s, 29.3843s/100 iters), loss = 0.00283802
I1013 07:45:33.391543 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283911 (* 1 = 0.00283911 loss)
I1013 07:45:33.391549 11428 sgd_solver.cpp:105] Iteration 107900, lr = 0.0001
I1013 07:46:01.242224 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:46:02.428970 11428 solver.cpp:330] Iteration 108000, Testing net (#0)
I1013 07:46:17.925449 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:46:18.241415 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10111 (* 1 = 1.10111 loss)
I1013 07:46:18.241430 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 07:46:18.528797 11428 solver.cpp:218] Iteration 108000 (2.21546 iter/s, 45.1373s/100 iters), loss = 0.00266753
I1013 07:46:18.528832 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266862 (* 1 = 0.00266862 loss)
I1013 07:46:18.528841 11428 sgd_solver.cpp:105] Iteration 108000, lr = 0.0001
I1013 07:46:47.865933 11428 solver.cpp:218] Iteration 108100 (3.40865 iter/s, 29.3371s/100 iters), loss = 0.00685312
I1013 07:46:47.866048 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685422 (* 1 = 0.00685422 loss)
I1013 07:46:47.866067 11428 sgd_solver.cpp:105] Iteration 108100, lr = 0.0001
I1013 07:47:17.201782 11428 solver.cpp:218] Iteration 108200 (3.40881 iter/s, 29.3357s/100 iters), loss = 0.00957758
I1013 07:47:17.201812 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957868 (* 1 = 0.00957868 loss)
I1013 07:47:17.201819 11428 sgd_solver.cpp:105] Iteration 108200, lr = 0.0001
I1013 07:47:46.565119 11428 solver.cpp:218] Iteration 108300 (3.40561 iter/s, 29.3633s/100 iters), loss = 0.00460757
I1013 07:47:46.565217 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460866 (* 1 = 0.00460866 loss)
I1013 07:47:46.565225 11428 sgd_solver.cpp:105] Iteration 108300, lr = 0.0001
I1013 07:48:15.857322 11428 solver.cpp:218] Iteration 108400 (3.41389 iter/s, 29.2921s/100 iters), loss = 0.00700202
I1013 07:48:15.857354 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700311 (* 1 = 0.00700311 loss)
I1013 07:48:15.857362 11428 sgd_solver.cpp:105] Iteration 108400, lr = 0.0001
I1013 07:48:44.920208 11428 solver.cpp:330] Iteration 108500, Testing net (#0)
I1013 07:49:00.430856 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:49:00.749130 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10096 (* 1 = 1.10096 loss)
I1013 07:49:00.749146 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 07:49:01.037154 11428 solver.cpp:218] Iteration 108500 (2.21338 iter/s, 45.1798s/100 iters), loss = 0.00404005
I1013 07:49:01.037200 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404115 (* 1 = 0.00404115 loss)
I1013 07:49:01.037209 11428 sgd_solver.cpp:105] Iteration 108500, lr = 0.0001
I1013 07:49:30.413233 11428 solver.cpp:218] Iteration 108600 (3.40413 iter/s, 29.376s/100 iters), loss = 0.00406561
I1013 07:49:30.415594 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406671 (* 1 = 0.00406671 loss)
I1013 07:49:30.415606 11428 sgd_solver.cpp:105] Iteration 108600, lr = 0.0001
I1013 07:49:59.783076 11428 solver.cpp:218] Iteration 108700 (3.40512 iter/s, 29.3675s/100 iters), loss = 0.00471509
I1013 07:49:59.783108 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471618 (* 1 = 0.00471618 loss)
I1013 07:49:59.783116 11428 sgd_solver.cpp:105] Iteration 108700, lr = 0.0001
I1013 07:50:29.102181 11428 solver.cpp:218] Iteration 108800 (3.41075 iter/s, 29.3191s/100 iters), loss = 0.00314592
I1013 07:50:29.102324 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314701 (* 1 = 0.00314701 loss)
I1013 07:50:29.102334 11428 sgd_solver.cpp:105] Iteration 108800, lr = 0.0001
I1013 07:50:58.454557 11428 solver.cpp:218] Iteration 108900 (3.4069 iter/s, 29.3522s/100 iters), loss = 0.0021865
I1013 07:50:58.454591 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218759 (* 1 = 0.00218759 loss)
I1013 07:50:58.454598 11428 sgd_solver.cpp:105] Iteration 108900, lr = 0.0001
I1013 07:51:26.371737 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:51:27.543009 11428 solver.cpp:330] Iteration 109000, Testing net (#0)
I1013 07:51:43.099391 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:51:43.416322 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10087 (* 1 = 1.10087 loss)
I1013 07:51:43.416338 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7407
I1013 07:51:43.704413 11428 solver.cpp:218] Iteration 109000 (2.20995 iter/s, 45.2498s/100 iters), loss = 0.00491228
I1013 07:51:43.704447 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491338 (* 1 = 0.00491338 loss)
I1013 07:51:43.704455 11428 sgd_solver.cpp:105] Iteration 109000, lr = 0.0001
I1013 07:52:13.049933 11428 solver.cpp:218] Iteration 109100 (3.40768 iter/s, 29.3455s/100 iters), loss = 0.00696378
I1013 07:52:13.050086 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00696487 (* 1 = 0.00696487 loss)
I1013 07:52:13.050096 11428 sgd_solver.cpp:105] Iteration 109100, lr = 0.0001
I1013 07:52:42.384228 11428 solver.cpp:218] Iteration 109200 (3.409 iter/s, 29.3341s/100 iters), loss = 0.00513151
I1013 07:52:42.384260 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051326 (* 1 = 0.0051326 loss)
I1013 07:52:42.384268 11428 sgd_solver.cpp:105] Iteration 109200, lr = 0.0001
I1013 07:53:11.725013 11428 solver.cpp:218] Iteration 109300 (3.40823 iter/s, 29.3408s/100 iters), loss = 0.00329968
I1013 07:53:11.725129 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330077 (* 1 = 0.00330077 loss)
I1013 07:53:11.725137 11428 sgd_solver.cpp:105] Iteration 109300, lr = 0.0001
I1013 07:53:41.047933 11428 solver.cpp:218] Iteration 109400 (3.41031 iter/s, 29.3228s/100 iters), loss = 0.00693843
I1013 07:53:41.047966 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693952 (* 1 = 0.00693952 loss)
I1013 07:53:41.047973 11428 sgd_solver.cpp:105] Iteration 109400, lr = 0.0001
I1013 07:54:10.124966 11428 solver.cpp:330] Iteration 109500, Testing net (#0)
I1013 07:54:25.679067 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:54:25.997712 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10075 (* 1 = 1.10075 loss)
I1013 07:54:25.997728 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7403
I1013 07:54:26.286104 11428 solver.cpp:218] Iteration 109500 (2.21052 iter/s, 45.2381s/100 iters), loss = 0.00345441
I1013 07:54:26.286137 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034555 (* 1 = 0.0034555 loss)
I1013 07:54:26.286145 11428 sgd_solver.cpp:105] Iteration 109500, lr = 0.0001
I1013 07:54:55.631081 11428 solver.cpp:218] Iteration 109600 (3.40774 iter/s, 29.3449s/100 iters), loss = 0.00271398
I1013 07:54:55.631201 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271507 (* 1 = 0.00271507 loss)
I1013 07:54:55.631208 11428 sgd_solver.cpp:105] Iteration 109600, lr = 0.0001
I1013 07:55:24.973649 11428 solver.cpp:218] Iteration 109700 (3.40803 iter/s, 29.3425s/100 iters), loss = 0.00464178
I1013 07:55:24.973681 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00464287 (* 1 = 0.00464287 loss)
I1013 07:55:24.973688 11428 sgd_solver.cpp:105] Iteration 109700, lr = 0.0001
I1013 07:55:54.287588 11428 solver.cpp:218] Iteration 109800 (3.41135 iter/s, 29.3139s/100 iters), loss = 0.003722
I1013 07:55:54.287689 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037231 (* 1 = 0.0037231 loss)
I1013 07:55:54.287709 11428 sgd_solver.cpp:105] Iteration 109800, lr = 0.0001
I1013 07:56:23.633119 11428 solver.cpp:218] Iteration 109900 (3.40768 iter/s, 29.3454s/100 iters), loss = 0.00259533
I1013 07:56:23.633152 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259643 (* 1 = 0.00259643 loss)
I1013 07:56:23.633160 11428 sgd_solver.cpp:105] Iteration 109900, lr = 0.0001
I1013 07:56:51.512562 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:56:52.679460 11428 solver.cpp:330] Iteration 110000, Testing net (#0)
I1013 07:57:08.204432 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:57:08.523648 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10064 (* 1 = 1.10064 loss)
I1013 07:57:08.523665 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 07:57:08.813431 11428 solver.cpp:218] Iteration 110000 (2.21335 iter/s, 45.1803s/100 iters), loss = 0.0107639
I1013 07:57:08.813467 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010765 (* 1 = 0.010765 loss)
I1013 07:57:08.813475 11428 sgd_solver.cpp:46] MultiStep Status: Iteration 110000, step = 3
I1013 07:57:08.813479 11428 sgd_solver.cpp:105] Iteration 110000, lr = 1e-05
I1013 07:57:38.193938 11428 solver.cpp:218] Iteration 110100 (3.40362 iter/s, 29.3805s/100 iters), loss = 0.00382019
I1013 07:57:38.194077 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00382128 (* 1 = 0.00382128 loss)
I1013 07:57:38.194085 11428 sgd_solver.cpp:105] Iteration 110100, lr = 1e-05
I1013 07:58:07.516487 11428 solver.cpp:218] Iteration 110200 (3.41036 iter/s, 29.3224s/100 iters), loss = 0.00579523
I1013 07:58:07.516518 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579632 (* 1 = 0.00579632 loss)
I1013 07:58:07.516526 11428 sgd_solver.cpp:105] Iteration 110200, lr = 1e-05
I1013 07:58:36.837239 11428 solver.cpp:218] Iteration 110300 (3.41056 iter/s, 29.3207s/100 iters), loss = 0.00499546
I1013 07:58:36.837342 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499655 (* 1 = 0.00499655 loss)
I1013 07:58:36.837352 11428 sgd_solver.cpp:105] Iteration 110300, lr = 1e-05
I1013 07:59:06.177111 11428 solver.cpp:218] Iteration 110400 (3.40834 iter/s, 29.3398s/100 iters), loss = 0.00685131
I1013 07:59:06.177142 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068524 (* 1 = 0.0068524 loss)
I1013 07:59:06.177150 11428 sgd_solver.cpp:105] Iteration 110400, lr = 1e-05
I1013 07:59:35.232779 11428 solver.cpp:330] Iteration 110500, Testing net (#0)
I1013 07:59:50.756109 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 07:59:51.077303 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10064 (* 1 = 1.10064 loss)
I1013 07:59:51.077319 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 07:59:51.367744 11428 solver.cpp:218] Iteration 110500 (2.21285 iter/s, 45.1906s/100 iters), loss = 0.00493353
I1013 07:59:51.367781 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493462 (* 1 = 0.00493462 loss)
I1013 07:59:51.367792 11428 sgd_solver.cpp:105] Iteration 110500, lr = 1e-05
I1013 08:00:20.732115 11428 solver.cpp:218] Iteration 110600 (3.40549 iter/s, 29.3643s/100 iters), loss = 0.00224901
I1013 08:00:20.732257 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022501 (* 1 = 0.0022501 loss)
I1013 08:00:20.732267 11428 sgd_solver.cpp:105] Iteration 110600, lr = 1e-05
I1013 08:00:50.045974 11428 solver.cpp:218] Iteration 110700 (3.41137 iter/s, 29.3137s/100 iters), loss = 0.0031163
I1013 08:00:50.046006 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311739 (* 1 = 0.00311739 loss)
I1013 08:00:50.046013 11428 sgd_solver.cpp:105] Iteration 110700, lr = 1e-05
I1013 08:01:19.382169 11428 solver.cpp:218] Iteration 110800 (3.40876 iter/s, 29.3362s/100 iters), loss = 0.00295044
I1013 08:01:19.382295 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295153 (* 1 = 0.00295153 loss)
I1013 08:01:19.382303 11428 sgd_solver.cpp:105] Iteration 110800, lr = 1e-05
I1013 08:01:48.721670 11428 solver.cpp:218] Iteration 110900 (3.40839 iter/s, 29.3394s/100 iters), loss = 0.00235313
I1013 08:01:48.721709 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235422 (* 1 = 0.00235422 loss)
I1013 08:01:48.721717 11428 sgd_solver.cpp:105] Iteration 110900, lr = 1e-05
I1013 08:02:16.616613 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:02:17.800499 11428 solver.cpp:330] Iteration 111000, Testing net (#0)
I1013 08:02:33.334069 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:02:33.650514 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10062 (* 1 = 1.10062 loss)
I1013 08:02:33.650532 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 08:02:33.937420 11428 solver.cpp:218] Iteration 111000 (2.21162 iter/s, 45.2157s/100 iters), loss = 0.00618988
I1013 08:02:33.937455 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00619097 (* 1 = 0.00619097 loss)
I1013 08:02:33.937464 11428 sgd_solver.cpp:105] Iteration 111000, lr = 1e-05
I1013 08:03:03.291782 11428 solver.cpp:218] Iteration 111100 (3.40665 iter/s, 29.3543s/100 iters), loss = 0.004384
I1013 08:03:03.291913 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043851 (* 1 = 0.0043851 loss)
I1013 08:03:03.291920 11428 sgd_solver.cpp:105] Iteration 111100, lr = 1e-05
I1013 08:03:32.643744 11428 solver.cpp:218] Iteration 111200 (3.40694 iter/s, 29.3518s/100 iters), loss = 0.0057592
I1013 08:03:32.643779 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057603 (* 1 = 0.0057603 loss)
I1013 08:03:32.643787 11428 sgd_solver.cpp:105] Iteration 111200, lr = 1e-05
I1013 08:04:02.003021 11428 solver.cpp:218] Iteration 111300 (3.40608 iter/s, 29.3592s/100 iters), loss = 0.00660257
I1013 08:04:02.003115 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660366 (* 1 = 0.00660366 loss)
I1013 08:04:02.003136 11428 sgd_solver.cpp:105] Iteration 111300, lr = 1e-05
I1013 08:04:31.319764 11428 solver.cpp:218] Iteration 111400 (3.41103 iter/s, 29.3167s/100 iters), loss = 0.0058626
I1013 08:04:31.319808 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00586369 (* 1 = 0.00586369 loss)
I1013 08:04:31.319823 11428 sgd_solver.cpp:105] Iteration 111400, lr = 1e-05
I1013 08:05:00.377997 11428 solver.cpp:330] Iteration 111500, Testing net (#0)
I1013 08:05:15.888229 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:05:16.207700 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10061 (* 1 = 1.10061 loss)
I1013 08:05:16.207715 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:05:16.494699 11428 solver.cpp:218] Iteration 111500 (2.21362 iter/s, 45.1749s/100 iters), loss = 0.00397393
I1013 08:05:16.494729 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397503 (* 1 = 0.00397503 loss)
I1013 08:05:16.494736 11428 sgd_solver.cpp:105] Iteration 111500, lr = 1e-05
I1013 08:05:45.862352 11428 solver.cpp:218] Iteration 111600 (3.40511 iter/s, 29.3676s/100 iters), loss = 0.00315305
I1013 08:05:45.862493 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315414 (* 1 = 0.00315414 loss)
I1013 08:05:45.862504 11428 sgd_solver.cpp:105] Iteration 111600, lr = 1e-05
I1013 08:06:15.218292 11428 solver.cpp:218] Iteration 111700 (3.40648 iter/s, 29.3558s/100 iters), loss = 0.00480443
I1013 08:06:15.218327 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00480552 (* 1 = 0.00480552 loss)
I1013 08:06:15.218334 11428 sgd_solver.cpp:105] Iteration 111700, lr = 1e-05
I1013 08:06:44.544569 11428 solver.cpp:218] Iteration 111800 (3.40991 iter/s, 29.3262s/100 iters), loss = 0.00255075
I1013 08:06:44.544694 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255185 (* 1 = 0.00255185 loss)
I1013 08:06:44.544703 11428 sgd_solver.cpp:105] Iteration 111800, lr = 1e-05
I1013 08:07:13.910348 11428 solver.cpp:218] Iteration 111900 (3.40534 iter/s, 29.3657s/100 iters), loss = 0.00324067
I1013 08:07:13.910382 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324177 (* 1 = 0.00324177 loss)
I1013 08:07:13.910390 11428 sgd_solver.cpp:105] Iteration 111900, lr = 1e-05
I1013 08:07:41.811496 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:07:42.978659 11428 solver.cpp:330] Iteration 112000, Testing net (#0)
I1013 08:07:58.480861 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:07:58.797183 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10061 (* 1 = 1.10061 loss)
I1013 08:07:58.797199 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:07:59.084833 11428 solver.cpp:218] Iteration 112000 (2.21364 iter/s, 45.1745s/100 iters), loss = 0.00129457
I1013 08:07:59.084870 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129566 (* 1 = 0.00129566 loss)
I1013 08:07:59.084880 11428 sgd_solver.cpp:105] Iteration 112000, lr = 1e-05
I1013 08:08:28.465831 11428 solver.cpp:218] Iteration 112100 (3.40356 iter/s, 29.381s/100 iters), loss = 0.0038614
I1013 08:08:28.465983 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386249 (* 1 = 0.00386249 loss)
I1013 08:08:28.465992 11428 sgd_solver.cpp:105] Iteration 112100, lr = 1e-05
I1013 08:08:57.862912 11428 solver.cpp:218] Iteration 112200 (3.40172 iter/s, 29.3969s/100 iters), loss = 0.00346576
I1013 08:08:57.862947 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346685 (* 1 = 0.00346685 loss)
I1013 08:08:57.862956 11428 sgd_solver.cpp:105] Iteration 112200, lr = 1e-05
I1013 08:09:27.232069 11428 solver.cpp:218] Iteration 112300 (3.40494 iter/s, 29.3691s/100 iters), loss = 0.00641687
I1013 08:09:27.232187 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641796 (* 1 = 0.00641796 loss)
I1013 08:09:27.232206 11428 sgd_solver.cpp:105] Iteration 112300, lr = 1e-05
I1013 08:09:56.597689 11428 solver.cpp:218] Iteration 112400 (3.40536 iter/s, 29.3655s/100 iters), loss = 0.00450239
I1013 08:09:56.597723 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450348 (* 1 = 0.00450348 loss)
I1013 08:09:56.597731 11428 sgd_solver.cpp:105] Iteration 112400, lr = 1e-05
I1013 08:10:25.704005 11428 solver.cpp:330] Iteration 112500, Testing net (#0)
I1013 08:10:41.257442 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:10:41.574760 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1006 (* 1 = 1.1006 loss)
I1013 08:10:41.574777 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 08:10:41.864358 11428 solver.cpp:218] Iteration 112500 (2.20913 iter/s, 45.2666s/100 iters), loss = 0.00609583
I1013 08:10:41.864393 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609692 (* 1 = 0.00609692 loss)
I1013 08:10:41.864401 11428 sgd_solver.cpp:105] Iteration 112500, lr = 1e-05
I1013 08:11:11.259455 11428 solver.cpp:218] Iteration 112600 (3.40193 iter/s, 29.3951s/100 iters), loss = 0.00285731
I1013 08:11:11.259605 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028584 (* 1 = 0.0028584 loss)
I1013 08:11:11.259615 11428 sgd_solver.cpp:105] Iteration 112600, lr = 1e-05
I1013 08:11:40.615438 11428 solver.cpp:218] Iteration 112700 (3.40648 iter/s, 29.3558s/100 iters), loss = 0.00575438
I1013 08:11:40.615470 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575547 (* 1 = 0.00575547 loss)
I1013 08:11:40.615478 11428 sgd_solver.cpp:105] Iteration 112700, lr = 1e-05
I1013 08:12:10.028889 11428 solver.cpp:218] Iteration 112800 (3.39981 iter/s, 29.4134s/100 iters), loss = 0.00365302
I1013 08:12:10.028987 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365411 (* 1 = 0.00365411 loss)
I1013 08:12:10.028998 11428 sgd_solver.cpp:105] Iteration 112800, lr = 1e-05
I1013 08:12:39.379196 11428 solver.cpp:218] Iteration 112900 (3.40713 iter/s, 29.3502s/100 iters), loss = 0.0023757
I1013 08:12:39.379230 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023768 (* 1 = 0.0023768 loss)
I1013 08:12:39.379238 11428 sgd_solver.cpp:105] Iteration 112900, lr = 1e-05
I1013 08:13:07.327153 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:13:08.512555 11428 solver.cpp:330] Iteration 113000, Testing net (#0)
I1013 08:13:24.010412 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:13:24.328135 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10061 (* 1 = 1.10061 loss)
I1013 08:13:24.328150 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 08:13:24.616416 11428 solver.cpp:218] Iteration 113000 (2.21057 iter/s, 45.2372s/100 iters), loss = 0.0026437
I1013 08:13:24.616461 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264479 (* 1 = 0.00264479 loss)
I1013 08:13:24.616469 11428 sgd_solver.cpp:105] Iteration 113000, lr = 1e-05
I1013 08:13:54.020995 11428 solver.cpp:218] Iteration 113100 (3.40084 iter/s, 29.4045s/100 iters), loss = 0.0053136
I1013 08:13:54.021142 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053147 (* 1 = 0.0053147 loss)
I1013 08:13:54.021152 11428 sgd_solver.cpp:105] Iteration 113100, lr = 1e-05
I1013 08:14:23.419096 11428 solver.cpp:218] Iteration 113200 (3.4016 iter/s, 29.398s/100 iters), loss = 0.00535385
I1013 08:14:23.419129 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535494 (* 1 = 0.00535494 loss)
I1013 08:14:23.419137 11428 sgd_solver.cpp:105] Iteration 113200, lr = 1e-05
I1013 08:14:52.783007 11428 solver.cpp:218] Iteration 113300 (3.40554 iter/s, 29.3639s/100 iters), loss = 0.00570385
I1013 08:14:52.783172 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570494 (* 1 = 0.00570494 loss)
I1013 08:14:52.783193 11428 sgd_solver.cpp:105] Iteration 113300, lr = 1e-05
I1013 08:15:22.119473 11428 solver.cpp:218] Iteration 113400 (3.40875 iter/s, 29.3363s/100 iters), loss = 0.00535454
I1013 08:15:22.119505 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535562 (* 1 = 0.00535562 loss)
I1013 08:15:22.119513 11428 sgd_solver.cpp:105] Iteration 113400, lr = 1e-05
I1013 08:15:51.200614 11428 solver.cpp:330] Iteration 113500, Testing net (#0)
I1013 08:16:06.692689 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:16:07.009145 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10058 (* 1 = 1.10058 loss)
I1013 08:16:07.009160 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:16:07.295579 11428 solver.cpp:218] Iteration 113500 (2.21356 iter/s, 45.1761s/100 iters), loss = 0.00453195
I1013 08:16:07.295614 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453304 (* 1 = 0.00453304 loss)
I1013 08:16:07.295622 11428 sgd_solver.cpp:105] Iteration 113500, lr = 1e-05
I1013 08:16:36.641278 11428 solver.cpp:218] Iteration 113600 (3.40766 iter/s, 29.3457s/100 iters), loss = 0.00279348
I1013 08:16:36.641388 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279457 (* 1 = 0.00279457 loss)
I1013 08:16:36.641396 11428 sgd_solver.cpp:105] Iteration 113600, lr = 1e-05
I1013 08:17:05.985828 11428 solver.cpp:218] Iteration 113700 (3.4078 iter/s, 29.3445s/100 iters), loss = 0.0042349
I1013 08:17:05.985862 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423599 (* 1 = 0.00423599 loss)
I1013 08:17:05.985868 11428 sgd_solver.cpp:105] Iteration 113700, lr = 1e-05
I1013 08:17:35.352726 11428 solver.cpp:218] Iteration 113800 (3.4052 iter/s, 29.3669s/100 iters), loss = 0.00608208
I1013 08:17:35.352867 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00608317 (* 1 = 0.00608317 loss)
I1013 08:17:35.352877 11428 sgd_solver.cpp:105] Iteration 113800, lr = 1e-05
I1013 08:18:04.704771 11428 solver.cpp:218] Iteration 113900 (3.40693 iter/s, 29.3519s/100 iters), loss = 0.00137786
I1013 08:18:04.704802 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137895 (* 1 = 0.00137895 loss)
I1013 08:18:04.704810 11428 sgd_solver.cpp:105] Iteration 113900, lr = 1e-05
I1013 08:18:32.576165 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:18:33.753931 11428 solver.cpp:330] Iteration 114000, Testing net (#0)
I1013 08:18:49.254283 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:18:49.571264 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10058 (* 1 = 1.10058 loss)
I1013 08:18:49.571281 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:18:49.858955 11428 solver.cpp:218] Iteration 114000 (2.21464 iter/s, 45.1542s/100 iters), loss = 0.00473177
I1013 08:18:49.858990 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473285 (* 1 = 0.00473285 loss)
I1013 08:18:49.858999 11428 sgd_solver.cpp:105] Iteration 114000, lr = 1e-05
I1013 08:19:19.195329 11428 solver.cpp:218] Iteration 114100 (3.40874 iter/s, 29.3363s/100 iters), loss = 0.00586162
I1013 08:19:19.195459 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00586271 (* 1 = 0.00586271 loss)
I1013 08:19:19.195468 11428 sgd_solver.cpp:105] Iteration 114100, lr = 1e-05
I1013 08:19:48.526280 11428 solver.cpp:218] Iteration 114200 (3.40938 iter/s, 29.3308s/100 iters), loss = 0.00650681
I1013 08:19:48.526317 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650791 (* 1 = 0.00650791 loss)
I1013 08:19:48.526329 11428 sgd_solver.cpp:105] Iteration 114200, lr = 1e-05
I1013 08:20:17.833423 11428 solver.cpp:218] Iteration 114300 (3.41214 iter/s, 29.3071s/100 iters), loss = 0.00511304
I1013 08:20:17.833582 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511414 (* 1 = 0.00511414 loss)
I1013 08:20:17.833593 11428 sgd_solver.cpp:105] Iteration 114300, lr = 1e-05
I1013 08:20:47.145695 11428 solver.cpp:218] Iteration 114400 (3.41156 iter/s, 29.3121s/100 iters), loss = 0.00451625
I1013 08:20:47.145728 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451735 (* 1 = 0.00451735 loss)
I1013 08:20:47.145738 11428 sgd_solver.cpp:105] Iteration 114400, lr = 1e-05
I1013 08:21:16.201918 11428 solver.cpp:330] Iteration 114500, Testing net (#0)
I1013 08:21:31.702333 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:21:32.021425 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10056 (* 1 = 1.10056 loss)
I1013 08:21:32.021442 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7406
I1013 08:21:32.311820 11428 solver.cpp:218] Iteration 114500 (2.21405 iter/s, 45.1661s/100 iters), loss = 0.0080359
I1013 08:21:32.311853 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00803699 (* 1 = 0.00803699 loss)
I1013 08:21:32.311864 11428 sgd_solver.cpp:105] Iteration 114500, lr = 1e-05
I1013 08:22:01.662230 11428 solver.cpp:218] Iteration 114600 (3.40711 iter/s, 29.3504s/100 iters), loss = 0.00261802
I1013 08:22:01.662341 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261911 (* 1 = 0.00261911 loss)
I1013 08:22:01.662355 11428 sgd_solver.cpp:105] Iteration 114600, lr = 1e-05
I1013 08:22:31.029685 11428 solver.cpp:218] Iteration 114700 (3.40514 iter/s, 29.3674s/100 iters), loss = 0.00543077
I1013 08:22:31.029717 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543187 (* 1 = 0.00543187 loss)
I1013 08:22:31.029728 11428 sgd_solver.cpp:105] Iteration 114700, lr = 1e-05
I1013 08:23:00.434824 11428 solver.cpp:218] Iteration 114800 (3.40077 iter/s, 29.4051s/100 iters), loss = 0.00188888
I1013 08:23:00.434978 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188997 (* 1 = 0.00188997 loss)
I1013 08:23:00.435006 11428 sgd_solver.cpp:105] Iteration 114800, lr = 1e-05
I1013 08:23:29.794422 11428 solver.cpp:218] Iteration 114900 (3.40606 iter/s, 29.3595s/100 iters), loss = 0.00315813
I1013 08:23:29.794458 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315922 (* 1 = 0.00315922 loss)
I1013 08:23:29.794469 11428 sgd_solver.cpp:105] Iteration 114900, lr = 1e-05
I1013 08:23:57.648457 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:23:58.816299 11428 solver.cpp:330] Iteration 115000, Testing net (#0)
I1013 08:24:14.391160 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:24:14.708495 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10055 (* 1 = 1.10055 loss)
I1013 08:24:14.708511 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7403
I1013 08:24:14.996279 11428 solver.cpp:218] Iteration 115000 (2.2123 iter/s, 45.2018s/100 iters), loss = 0.00486606
I1013 08:24:14.996316 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486715 (* 1 = 0.00486715 loss)
I1013 08:24:14.996328 11428 sgd_solver.cpp:105] Iteration 115000, lr = 1e-05
I1013 08:24:44.296737 11428 solver.cpp:218] Iteration 115100 (3.41292 iter/s, 29.3004s/100 iters), loss = 0.00390802
I1013 08:24:44.296923 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00390911 (* 1 = 0.00390911 loss)
I1013 08:24:44.296953 11428 sgd_solver.cpp:105] Iteration 115100, lr = 1e-05
I1013 08:25:13.648030 11428 solver.cpp:218] Iteration 115200 (3.40702 iter/s, 29.3511s/100 iters), loss = 0.00606005
I1013 08:25:13.648061 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00606115 (* 1 = 0.00606115 loss)
I1013 08:25:13.648068 11428 sgd_solver.cpp:105] Iteration 115200, lr = 1e-05
I1013 08:25:43.013226 11428 solver.cpp:218] Iteration 115300 (3.4054 iter/s, 29.3652s/100 iters), loss = 0.00542217
I1013 08:25:43.013361 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542326 (* 1 = 0.00542326 loss)
I1013 08:25:43.013372 11428 sgd_solver.cpp:105] Iteration 115300, lr = 1e-05
I1013 08:26:12.351979 11428 solver.cpp:218] Iteration 115400 (3.40848 iter/s, 29.3386s/100 iters), loss = 0.00409975
I1013 08:26:12.352010 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410084 (* 1 = 0.00410084 loss)
I1013 08:26:12.352018 11428 sgd_solver.cpp:105] Iteration 115400, lr = 1e-05
I1013 08:26:41.409940 11428 solver.cpp:330] Iteration 115500, Testing net (#0)
I1013 08:26:56.965620 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:26:57.283349 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10054 (* 1 = 1.10054 loss)
I1013 08:26:57.283365 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:26:57.570152 11428 solver.cpp:218] Iteration 115500 (2.2115 iter/s, 45.2181s/100 iters), loss = 0.00560668
I1013 08:26:57.570184 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00560777 (* 1 = 0.00560777 loss)
I1013 08:26:57.570194 11428 sgd_solver.cpp:105] Iteration 115500, lr = 1e-05
I1013 08:27:26.886196 11428 solver.cpp:218] Iteration 115600 (3.4111 iter/s, 29.316s/100 iters), loss = 0.0027401
I1013 08:27:26.886344 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274118 (* 1 = 0.00274118 loss)
I1013 08:27:26.886354 11428 sgd_solver.cpp:105] Iteration 115600, lr = 1e-05
I1013 08:27:56.185740 11428 solver.cpp:218] Iteration 115700 (3.41304 iter/s, 29.2994s/100 iters), loss = 0.00266614
I1013 08:27:56.185773 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266723 (* 1 = 0.00266723 loss)
I1013 08:27:56.185781 11428 sgd_solver.cpp:105] Iteration 115700, lr = 1e-05
I1013 08:28:25.500761 11428 solver.cpp:218] Iteration 115800 (3.41122 iter/s, 29.315s/100 iters), loss = 0.00435878
I1013 08:28:25.500864 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435987 (* 1 = 0.00435987 loss)
I1013 08:28:25.500872 11428 sgd_solver.cpp:105] Iteration 115800, lr = 1e-05
I1013 08:28:54.809927 11428 solver.cpp:218] Iteration 115900 (3.41191 iter/s, 29.3091s/100 iters), loss = 0.00253797
I1013 08:28:54.809962 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253906 (* 1 = 0.00253906 loss)
I1013 08:28:54.809969 11428 sgd_solver.cpp:105] Iteration 115900, lr = 1e-05
I1013 08:29:22.636121 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:29:23.805164 11428 solver.cpp:330] Iteration 116000, Testing net (#0)
I1013 08:29:39.325440 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:29:39.641793 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10052 (* 1 = 1.10052 loss)
I1013 08:29:39.641809 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:29:39.928386 11428 solver.cpp:218] Iteration 116000 (2.21639 iter/s, 45.1184s/100 iters), loss = 0.00324435
I1013 08:29:39.928431 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324543 (* 1 = 0.00324543 loss)
I1013 08:29:39.928439 11428 sgd_solver.cpp:105] Iteration 116000, lr = 1e-05
I1013 08:30:09.215952 11428 solver.cpp:218] Iteration 116100 (3.41442 iter/s, 29.2875s/100 iters), loss = 0.00736761
I1013 08:30:09.216085 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073687 (* 1 = 0.0073687 loss)
I1013 08:30:09.216094 11428 sgd_solver.cpp:105] Iteration 116100, lr = 1e-05
I1013 08:30:38.525852 11428 solver.cpp:218] Iteration 116200 (3.41183 iter/s, 29.3098s/100 iters), loss = 0.011378
I1013 08:30:38.525887 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113791 (* 1 = 0.0113791 loss)
I1013 08:30:38.525895 11428 sgd_solver.cpp:105] Iteration 116200, lr = 1e-05
I1013 08:31:07.821336 11428 solver.cpp:218] Iteration 116300 (3.4135 iter/s, 29.2954s/100 iters), loss = 0.00317157
I1013 08:31:07.821487 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317266 (* 1 = 0.00317266 loss)
I1013 08:31:07.821511 11428 sgd_solver.cpp:105] Iteration 116300, lr = 1e-05
I1013 08:31:37.126412 11428 solver.cpp:218] Iteration 116400 (3.4124 iter/s, 29.3049s/100 iters), loss = 0.00454038
I1013 08:31:37.126444 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454147 (* 1 = 0.00454147 loss)
I1013 08:31:37.126451 11428 sgd_solver.cpp:105] Iteration 116400, lr = 1e-05
I1013 08:32:06.125738 11428 solver.cpp:330] Iteration 116500, Testing net (#0)
I1013 08:32:21.646518 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:32:21.964192 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10049 (* 1 = 1.10049 loss)
I1013 08:32:21.964210 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:32:22.251802 11428 solver.cpp:218] Iteration 116500 (2.21605 iter/s, 45.1254s/100 iters), loss = 0.00412933
I1013 08:32:22.251832 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413043 (* 1 = 0.00413043 loss)
I1013 08:32:22.251840 11428 sgd_solver.cpp:105] Iteration 116500, lr = 1e-05
I1013 08:32:51.582648 11428 solver.cpp:218] Iteration 116600 (3.40938 iter/s, 29.3308s/100 iters), loss = 0.00463408
I1013 08:32:51.582757 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463517 (* 1 = 0.00463517 loss)
I1013 08:32:51.582777 11428 sgd_solver.cpp:105] Iteration 116600, lr = 1e-05
I1013 08:33:20.888108 11428 solver.cpp:218] Iteration 116700 (3.41235 iter/s, 29.3054s/100 iters), loss = 0.00288239
I1013 08:33:20.888149 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288349 (* 1 = 0.00288349 loss)
I1013 08:33:20.888159 11428 sgd_solver.cpp:105] Iteration 116700, lr = 1e-05
I1013 08:33:50.403178 11428 solver.cpp:218] Iteration 116800 (3.3881 iter/s, 29.515s/100 iters), loss = 0.00259546
I1013 08:33:50.403344 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259656 (* 1 = 0.00259656 loss)
I1013 08:33:50.403367 11428 sgd_solver.cpp:105] Iteration 116800, lr = 1e-05
I1013 08:34:20.337471 11428 solver.cpp:218] Iteration 116900 (3.34067 iter/s, 29.9341s/100 iters), loss = 0.00362074
I1013 08:34:20.337504 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362183 (* 1 = 0.00362183 loss)
I1013 08:34:20.337512 11428 sgd_solver.cpp:105] Iteration 116900, lr = 1e-05
I1013 08:34:48.729849 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:34:49.941618 11428 solver.cpp:330] Iteration 117000, Testing net (#0)
I1013 08:35:05.669270 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:35:05.999389 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10049 (* 1 = 1.10049 loss)
I1013 08:35:05.999408 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:35:06.285363 11428 solver.cpp:218] Iteration 117000 (2.17638 iter/s, 45.9479s/100 iters), loss = 0.00394867
I1013 08:35:06.285389 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394977 (* 1 = 0.00394977 loss)
I1013 08:35:06.285398 11428 sgd_solver.cpp:105] Iteration 117000, lr = 1e-05
I1013 08:35:35.928020 11428 solver.cpp:218] Iteration 117100 (3.37352 iter/s, 29.6426s/100 iters), loss = 0.0080588
I1013 08:35:35.928145 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00805989 (* 1 = 0.00805989 loss)
I1013 08:35:35.928165 11428 sgd_solver.cpp:105] Iteration 117100, lr = 1e-05
I1013 08:36:05.297269 11428 solver.cpp:218] Iteration 117200 (3.40494 iter/s, 29.3691s/100 iters), loss = 0.00900387
I1013 08:36:05.297302 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00900496 (* 1 = 0.00900496 loss)
I1013 08:36:05.297309 11428 sgd_solver.cpp:105] Iteration 117200, lr = 1e-05
I1013 08:36:34.645843 11428 solver.cpp:218] Iteration 117300 (3.40732 iter/s, 29.3485s/100 iters), loss = 0.00573975
I1013 08:36:34.646008 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574085 (* 1 = 0.00574085 loss)
I1013 08:36:34.646018 11428 sgd_solver.cpp:105] Iteration 117300, lr = 1e-05
I1013 08:37:04.014111 11428 solver.cpp:218] Iteration 117400 (3.40505 iter/s, 29.3681s/100 iters), loss = 0.00543086
I1013 08:37:04.014144 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543196 (* 1 = 0.00543196 loss)
I1013 08:37:04.014153 11428 sgd_solver.cpp:105] Iteration 117400, lr = 1e-05
I1013 08:37:33.075186 11428 solver.cpp:330] Iteration 117500, Testing net (#0)
I1013 08:37:48.612637 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:37:48.929327 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10047 (* 1 = 1.10047 loss)
I1013 08:37:48.929343 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 08:37:49.217869 11428 solver.cpp:218] Iteration 117500 (2.21221 iter/s, 45.2037s/100 iters), loss = 0.00391927
I1013 08:37:49.217906 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392037 (* 1 = 0.00392037 loss)
I1013 08:37:49.217918 11428 sgd_solver.cpp:105] Iteration 117500, lr = 1e-05
I1013 08:38:18.547485 11428 solver.cpp:218] Iteration 117600 (3.40953 iter/s, 29.3296s/100 iters), loss = 0.00435041
I1013 08:38:18.547629 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435151 (* 1 = 0.00435151 loss)
I1013 08:38:18.547639 11428 sgd_solver.cpp:105] Iteration 117600, lr = 1e-05
I1013 08:38:47.914793 11428 solver.cpp:218] Iteration 117700 (3.40516 iter/s, 29.3672s/100 iters), loss = 0.00407223
I1013 08:38:47.914827 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407333 (* 1 = 0.00407333 loss)
I1013 08:38:47.914835 11428 sgd_solver.cpp:105] Iteration 117700, lr = 1e-05
I1013 08:39:17.228507 11428 solver.cpp:218] Iteration 117800 (3.41138 iter/s, 29.3137s/100 iters), loss = 0.00364778
I1013 08:39:17.228662 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364887 (* 1 = 0.00364887 loss)
I1013 08:39:17.228672 11428 sgd_solver.cpp:105] Iteration 117800, lr = 1e-05
I1013 08:39:46.545472 11428 solver.cpp:218] Iteration 117900 (3.41101 iter/s, 29.3168s/100 iters), loss = 0.00177842
I1013 08:39:46.545503 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177951 (* 1 = 0.00177951 loss)
I1013 08:39:46.545512 11428 sgd_solver.cpp:105] Iteration 117900, lr = 1e-05
I1013 08:40:14.433943 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:40:15.597975 11428 solver.cpp:330] Iteration 118000, Testing net (#0)
I1013 08:40:31.116575 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:40:31.434669 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10046 (* 1 = 1.10046 loss)
I1013 08:40:31.434684 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7403
I1013 08:40:31.722321 11428 solver.cpp:218] Iteration 118000 (2.21352 iter/s, 45.1768s/100 iters), loss = 0.00890861
I1013 08:40:31.722352 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0089097 (* 1 = 0.0089097 loss)
I1013 08:40:31.722360 11428 sgd_solver.cpp:105] Iteration 118000, lr = 1e-05
I1013 08:41:01.037075 11428 solver.cpp:218] Iteration 118100 (3.41126 iter/s, 29.3147s/100 iters), loss = 0.00334384
I1013 08:41:01.037251 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334493 (* 1 = 0.00334493 loss)
I1013 08:41:01.037271 11428 sgd_solver.cpp:105] Iteration 118100, lr = 1e-05
I1013 08:41:30.368847 11428 solver.cpp:218] Iteration 118200 (3.40929 iter/s, 29.3316s/100 iters), loss = 0.0066814
I1013 08:41:30.368881 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066825 (* 1 = 0.0066825 loss)
I1013 08:41:30.368888 11428 sgd_solver.cpp:105] Iteration 118200, lr = 1e-05
I1013 08:41:59.705591 11428 solver.cpp:218] Iteration 118300 (3.4087 iter/s, 29.3367s/100 iters), loss = 0.00557843
I1013 08:41:59.705718 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557953 (* 1 = 0.00557953 loss)
I1013 08:41:59.705727 11428 sgd_solver.cpp:105] Iteration 118300, lr = 1e-05
I1013 08:42:29.028846 11428 solver.cpp:218] Iteration 118400 (3.41028 iter/s, 29.3231s/100 iters), loss = 0.00435016
I1013 08:42:29.028878 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435126 (* 1 = 0.00435126 loss)
I1013 08:42:29.028887 11428 sgd_solver.cpp:105] Iteration 118400, lr = 1e-05
I1013 08:42:58.046531 11428 solver.cpp:330] Iteration 118500, Testing net (#0)
I1013 08:43:13.567364 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:43:13.883069 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10045 (* 1 = 1.10045 loss)
I1013 08:43:13.883087 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 08:43:14.169353 11428 solver.cpp:218] Iteration 118500 (2.21531 iter/s, 45.1405s/100 iters), loss = 0.00648934
I1013 08:43:14.169380 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00649043 (* 1 = 0.00649043 loss)
I1013 08:43:14.169389 11428 sgd_solver.cpp:105] Iteration 118500, lr = 1e-05
I1013 08:43:43.415150 11428 solver.cpp:218] Iteration 118600 (3.4193 iter/s, 29.2458s/100 iters), loss = 0.00352786
I1013 08:43:43.415262 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352896 (* 1 = 0.00352896 loss)
I1013 08:43:43.415271 11428 sgd_solver.cpp:105] Iteration 118600, lr = 1e-05
I1013 08:44:12.711509 11428 solver.cpp:218] Iteration 118700 (3.41341 iter/s, 29.2963s/100 iters), loss = 0.00499602
I1013 08:44:12.711541 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499712 (* 1 = 0.00499712 loss)
I1013 08:44:12.711550 11428 sgd_solver.cpp:105] Iteration 118700, lr = 1e-05
I1013 08:44:41.969846 11428 solver.cpp:218] Iteration 118800 (3.41783 iter/s, 29.2583s/100 iters), loss = 0.00618478
I1013 08:44:41.969947 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618588 (* 1 = 0.00618588 loss)
I1013 08:44:41.969956 11428 sgd_solver.cpp:105] Iteration 118800, lr = 1e-05
I1013 08:45:11.261734 11428 solver.cpp:218] Iteration 118900 (3.41393 iter/s, 29.2918s/100 iters), loss = 0.00301594
I1013 08:45:11.261765 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301704 (* 1 = 0.00301704 loss)
I1013 08:45:11.261775 11428 sgd_solver.cpp:105] Iteration 118900, lr = 1e-05
I1013 08:45:39.045696 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:45:40.211344 11428 solver.cpp:330] Iteration 119000, Testing net (#0)
I1013 08:45:55.651577 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:45:55.967423 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10045 (* 1 = 1.10045 loss)
I1013 08:45:55.967439 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7404
I1013 08:45:56.253274 11428 solver.cpp:218] Iteration 119000 (2.22264 iter/s, 44.9915s/100 iters), loss = 0.00589846
I1013 08:45:56.253312 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589956 (* 1 = 0.00589956 loss)
I1013 08:45:56.253330 11428 sgd_solver.cpp:105] Iteration 119000, lr = 1e-05
I1013 08:46:25.621155 11428 solver.cpp:218] Iteration 119100 (3.40509 iter/s, 29.3678s/100 iters), loss = 0.00438431
I1013 08:46:25.621281 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438541 (* 1 = 0.00438541 loss)
I1013 08:46:25.621290 11428 sgd_solver.cpp:105] Iteration 119100, lr = 1e-05
I1013 08:46:55.045207 11428 solver.cpp:218] Iteration 119200 (3.39859 iter/s, 29.4239s/100 iters), loss = 0.00546333
I1013 08:46:55.045248 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546442 (* 1 = 0.00546442 loss)
I1013 08:46:55.045256 11428 sgd_solver.cpp:105] Iteration 119200, lr = 1e-05
I1013 08:47:24.683811 11428 solver.cpp:218] Iteration 119300 (3.37398 iter/s, 29.6386s/100 iters), loss = 0.00563172
I1013 08:47:24.686467 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563282 (* 1 = 0.00563282 loss)
I1013 08:47:24.686491 11428 sgd_solver.cpp:105] Iteration 119300, lr = 1e-05
I1013 08:47:54.565649 11428 solver.cpp:218] Iteration 119400 (3.34682 iter/s, 29.8792s/100 iters), loss = 0.00542385
I1013 08:47:54.565692 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542494 (* 1 = 0.00542494 loss)
I1013 08:47:54.565704 11428 sgd_solver.cpp:105] Iteration 119400, lr = 1e-05
I1013 08:48:23.822054 11428 solver.cpp:330] Iteration 119500, Testing net (#0)
I1013 08:48:39.407057 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:48:39.724472 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10044 (* 1 = 1.10044 loss)
I1013 08:48:39.724498 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:48:40.015444 11428 solver.cpp:218] Iteration 119500 (2.20023 iter/s, 45.4498s/100 iters), loss = 0.00445589
I1013 08:48:40.015482 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445699 (* 1 = 0.00445699 loss)
I1013 08:48:40.015491 11428 sgd_solver.cpp:105] Iteration 119500, lr = 1e-05
I1013 08:49:09.347677 11428 solver.cpp:218] Iteration 119600 (3.40922 iter/s, 29.3322s/100 iters), loss = 0.0042346
I1013 08:49:09.347790 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423569 (* 1 = 0.00423569 loss)
I1013 08:49:09.347797 11428 sgd_solver.cpp:105] Iteration 119600, lr = 1e-05
I1013 08:49:38.647480 11428 solver.cpp:218] Iteration 119700 (3.413 iter/s, 29.2997s/100 iters), loss = 0.00580156
I1013 08:49:38.647511 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00580265 (* 1 = 0.00580265 loss)
I1013 08:49:38.647519 11428 sgd_solver.cpp:105] Iteration 119700, lr = 1e-05
I1013 08:50:07.975891 11428 solver.cpp:218] Iteration 119800 (3.40967 iter/s, 29.3284s/100 iters), loss = 0.00333853
I1013 08:50:07.976032 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333962 (* 1 = 0.00333962 loss)
I1013 08:50:07.976042 11428 sgd_solver.cpp:105] Iteration 119800, lr = 1e-05
I1013 08:50:37.405647 11428 solver.cpp:218] Iteration 119900 (3.39794 iter/s, 29.4296s/100 iters), loss = 0.00195821
I1013 08:50:37.405681 11428 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195931 (* 1 = 0.00195931 loss)
I1013 08:50:37.405689 11428 sgd_solver.cpp:105] Iteration 119900, lr = 1e-05
I1013 08:51:05.368033 11437 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:51:06.540575 11428 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/WRN/WRN_relu_msra_iter_120000.caffemodel
I1013 08:51:08.024101 11428 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/WRN/WRN_relu_msra_iter_120000.solverstate
I1013 08:51:08.228097 11428 solver.cpp:310] Iteration 120000, loss = 0.00398821
I1013 08:51:08.228121 11428 solver.cpp:330] Iteration 120000, Testing net (#0)
I1013 08:51:23.703634 11438 data_layer.cpp:73] Restarting data prefetching from start.
I1013 08:51:24.020397 11428 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.10044 (* 1 = 1.10044 loss)
I1013 08:51:24.020414 11428 solver.cpp:397]     Test net output #1: accuracy = 0.7405
I1013 08:51:24.020421 11428 solver.cpp:315] Optimization Done.
I1013 08:51:24.020423 11428 caffe.cpp:259] Optimization Done.
